{"sha": "8c1cfd5aa4a3eb878b7591a688c79dd939684813", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OGMxY2ZkNWFhNGEzZWI4NzhiNzU5MWE2ODhjNzlkZDkzOTY4NDgxMw==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@redhat.com", "date": "2004-12-01T17:57:29Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2004-12-01T17:57:29Z"}, "message": "expr.c (optimize_bitfield_assignment_op): Split out from ...\n\n        * expr.c (optimize_bitfield_assignment_op): Split out from ...\n        (expand_assignment): ... here.  Use handled_component_p to gate\n        get_inner_reference code.  Simplify MEM handling.  Special case\n        CONCAT destinations.\n\nFrom-SVN: r91570", "tree": {"sha": "4bb6a2aea11f8390d7eceada074edb982a74a077", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/4bb6a2aea11f8390d7eceada074edb982a74a077"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/8c1cfd5aa4a3eb878b7591a688c79dd939684813", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8c1cfd5aa4a3eb878b7591a688c79dd939684813", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8c1cfd5aa4a3eb878b7591a688c79dd939684813", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8c1cfd5aa4a3eb878b7591a688c79dd939684813/comments", "author": null, "committer": null, "parents": [{"sha": "d7cf6dd66ad3c1ecb1164b7ef02c95e680fce0a8", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d7cf6dd66ad3c1ecb1164b7ef02c95e680fce0a8", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d7cf6dd66ad3c1ecb1164b7ef02c95e680fce0a8"}], "stats": {"total": 285, "additions": 148, "deletions": 137}, "files": [{"sha": "7048e87cf3ccb98662e1dfb5a524f8fc1d524409", "filename": "gcc/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8c1cfd5aa4a3eb878b7591a688c79dd939684813/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8c1cfd5aa4a3eb878b7591a688c79dd939684813/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=8c1cfd5aa4a3eb878b7591a688c79dd939684813", "patch": "@@ -1,5 +1,10 @@\n 2004-12-01  Richard Henderson  <rth@redhat.com>\n \n+\t* expr.c (optimize_bitfield_assignment_op): Split out from ... \n+\t(expand_assignment): ... here.  Use handled_component_p to gate\n+\tget_inner_reference code.  Simplify MEM handling.  Special case\n+\tCONCAT destinations.\n+\n \t* expmed.c (store_bit_field): Use simplify_gen_subreg instead\n \tof gen_rtx_SUBREG directly.\n "}, {"sha": "a0ccf77af1a8cc32699478724737b6406f415cca", "filename": "gcc/expr.c", "status": "modified", "additions": 143, "deletions": 137, "changes": 280, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8c1cfd5aa4a3eb878b7591a688c79dd939684813/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8c1cfd5aa4a3eb878b7591a688c79dd939684813/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=8c1cfd5aa4a3eb878b7591a688c79dd939684813", "patch": "@@ -3499,6 +3499,124 @@ get_subtarget (rtx x)\n \t  ? 0 : x);\n }\n \n+/* A subroutine of expand_assignment.  Optimize FIELD op= VAL, where\n+   FIELD is a bitfield.  Returns true if the optimization was successful,\n+   and there's nothing else to do.  */\n+\n+static bool\n+optimize_bitfield_assignment_op (unsigned HOST_WIDE_INT bitsize,\n+\t\t\t\t unsigned HOST_WIDE_INT bitpos,\n+\t\t\t\t enum machine_mode mode1, rtx str_rtx,\n+\t\t\t\t tree to, tree src)\n+{\n+  enum machine_mode str_mode = GET_MODE (str_rtx);\n+  unsigned int str_bitsize = GET_MODE_BITSIZE (str_mode);\n+  tree op0, op1;\n+  rtx value, result;\n+  optab binop;\n+\n+  if (mode1 != VOIDmode\n+      || bitsize >= BITS_PER_WORD\n+      || str_bitsize > BITS_PER_WORD\n+      || TREE_SIDE_EFFECTS (to)\n+      || TREE_THIS_VOLATILE (to))\n+    return false;\n+\n+  STRIP_NOPS (src);\n+  if (!BINARY_CLASS_P (src)\n+      || TREE_CODE (TREE_TYPE (src)) != INTEGER_TYPE)\n+    return false;\n+\n+  op0 = TREE_OPERAND (src, 0);\n+  op1 = TREE_OPERAND (src, 1);\n+  STRIP_NOPS (op0);\n+\n+  if (!operand_equal_p (to, op0, 0))\n+    return false;\n+\n+  if (MEM_P (str_rtx))\n+    {\n+      unsigned HOST_WIDE_INT offset1;\n+\n+      if (str_bitsize == 0 || str_bitsize > BITS_PER_WORD)\n+\tstr_mode = word_mode;\n+      str_mode = get_best_mode (bitsize, bitpos,\n+\t\t\t\tMEM_ALIGN (str_rtx), str_mode, 0);\n+      if (str_mode == VOIDmode)\n+\treturn false;\n+      str_bitsize = GET_MODE_BITSIZE (str_mode);\n+\n+      offset1 = bitpos;\n+      bitpos %= str_bitsize;\n+      offset1 = (offset1 - bitpos) / BITS_PER_UNIT;\n+      str_rtx = adjust_address (str_rtx, str_mode, offset1);\n+    }\n+  else if (!REG_P (str_rtx) && GET_CODE (str_rtx) != SUBREG)\n+    return false;\n+\n+  /* If the bit field covers the whole REG/MEM, store_field\n+     will likely generate better code.  */\n+  if (bitsize >= str_bitsize)\n+    return false;\n+\n+  /* We can't handle fields split across multiple entities.  */\n+  if (bitpos + bitsize > str_bitsize)\n+    return false;\n+\n+  if (BYTES_BIG_ENDIAN)\n+    bitpos = str_bitsize - bitpos - bitsize;\n+\n+  switch (TREE_CODE (src))\n+    {\n+    case PLUS_EXPR:\n+    case MINUS_EXPR:\n+      /* For now, just optimize the case of the topmost bitfield\n+\t where we don't need to do any masking and also\n+\t 1 bit bitfields where xor can be used.\n+\t We might win by one instruction for the other bitfields\n+\t too if insv/extv instructions aren't used, so that\n+\t can be added later.  */\n+      if (bitpos + bitsize != str_bitsize\n+\t  && (bitsize != 1 || TREE_CODE (op1) != INTEGER_CST))\n+\tbreak;\n+\n+      value = expand_expr (op1, NULL_RTX, str_mode, 0);\n+      value = convert_modes (str_mode,\n+\t\t\t     TYPE_MODE (TREE_TYPE (op1)), value,\n+\t\t\t     TYPE_UNSIGNED (TREE_TYPE (op1)));\n+\n+      /* We may be accessing data outside the field, which means\n+\t we can alias adjacent data.  */\n+      if (MEM_P (str_rtx))\n+\t{\n+\t  str_rtx = shallow_copy_rtx (str_rtx);\n+\t  set_mem_alias_set (str_rtx, 0);\n+\t  set_mem_expr (str_rtx, 0);\n+\t}\n+\n+      binop = TREE_CODE (src) == PLUS_EXPR ? add_optab : sub_optab;\n+      if (bitsize == 1 && bitpos + bitsize != str_bitsize)\n+\t{\n+\t  value = expand_and (str_mode, value, const1_rtx, NULL);\n+\t  binop = xor_optab;\n+\t}\n+      value = expand_shift (LSHIFT_EXPR, str_mode, value,\n+\t\t\t    build_int_cst (NULL_TREE, bitpos),\n+\t\t\t    NULL_RTX, 1);\n+      result = expand_binop (str_mode, binop, str_rtx,\n+\t\t\t     value, str_rtx, 1, OPTAB_WIDEN);\n+      if (result != str_rtx)\n+\temit_move_insn (str_rtx, result);\n+      return true;\n+\n+    default:\n+      break;\n+    }\n+\n+  return false;\n+}\n+\n+\n /* Expand an assignment that stores the value of FROM into TO.  */\n \n void\n@@ -3520,9 +3638,7 @@ expand_assignment (tree to, tree from)\n      Assignment of an array element at a constant index, and assignment of\n      an array element in an unaligned packed structure field, has the same\n      problem.  */\n-\n-  if (TREE_CODE (to) == COMPONENT_REF || TREE_CODE (to) == BIT_FIELD_REF\n-      || TREE_CODE (to) == ARRAY_REF || TREE_CODE (to) == ARRAY_RANGE_REF\n+  if (handled_component_p (to)\n       || TREE_CODE (TREE_TYPE (to)) == ARRAY_TYPE)\n     {\n       enum machine_mode mode1;\n@@ -3575,153 +3691,43 @@ expand_assignment (tree to, tree from)\n \t\t\t\t   \t\t\t\t   offset));\n \t}\n \n-      if (MEM_P (to_rtx))\n-\t{\n-\t  /* If the field is at offset zero, we could have been given the\n-\t     DECL_RTX of the parent struct.  Don't munge it.  */\n-\t  to_rtx = shallow_copy_rtx (to_rtx);\n-\n-\t  set_mem_attributes_minus_bitpos (to_rtx, to, 0, bitpos);\n-\t}\n-\n-      /* Deal with volatile and readonly fields.  The former is only done\n-\t for MEM.  Also set MEM_KEEP_ALIAS_SET_P if needed.  */\n-      if (volatilep && MEM_P (to_rtx))\n-\t{\n-\t  if (to_rtx == orig_to_rtx)\n-\t    to_rtx = copy_rtx (to_rtx);\n-\t  MEM_VOLATILE_P (to_rtx) = 1;\n-\t}\n-\n-      if (MEM_P (to_rtx) && ! can_address_p (to))\n+      /* Handle expand_expr of a complex value returning a CONCAT.  */\n+      if (GET_CODE (to_rtx) == CONCAT)\n \t{\n-\t  if (to_rtx == orig_to_rtx)\n-\t    to_rtx = copy_rtx (to_rtx);\n-\t  MEM_KEEP_ALIAS_SET_P (to_rtx) = 1;\n+\t  gcc_assert (bitpos == 0 || bitpos == GET_MODE_BITSIZE (mode1));\n+\t  result = store_expr (from, XEXP (to_rtx, bitpos != 0), false);\n \t}\n-\n-      /* Optimize bitfld op= val in certain cases.  */\n-      while (mode1 == VOIDmode\n-\t     && bitsize > 0 && bitsize < BITS_PER_WORD\n-\t     && GET_MODE_BITSIZE (GET_MODE (to_rtx)) <= BITS_PER_WORD\n-\t     && !TREE_SIDE_EFFECTS (to)\n-\t     && !TREE_THIS_VOLATILE (to))\n+      else\n \t{\n-\t  tree src, op0, op1;\n-\t  rtx value, str_rtx = to_rtx;\n-\t  HOST_WIDE_INT bitpos1 = bitpos;\n-\t  optab binop;\n-\n-\t  src = from;\n-\t  STRIP_NOPS (src);\n-\t  if (TREE_CODE (TREE_TYPE (src)) != INTEGER_TYPE\n-\t      || !BINARY_CLASS_P (src))\n-\t    break;\n-\n-\t  op0 = TREE_OPERAND (src, 0);\n-\t  op1 = TREE_OPERAND (src, 1);\n-\t  STRIP_NOPS (op0);\n-\n-\t  if (! operand_equal_p (to, op0, 0))\n-\t    break;\n-\n-\t  if (MEM_P (str_rtx))\n+\t  if (MEM_P (to_rtx))\n \t    {\n-\t      enum machine_mode mode = GET_MODE (str_rtx);\n-\t      HOST_WIDE_INT offset1;\n+\t      /* If the field is at offset zero, we could have been given the\n+\t\t DECL_RTX of the parent struct.  Don't munge it.  */\n+\t      to_rtx = shallow_copy_rtx (to_rtx);\n \n-\t      if (GET_MODE_BITSIZE (mode) == 0\n-\t\t  || GET_MODE_BITSIZE (mode) > BITS_PER_WORD)\n-\t\tmode = word_mode;\n-\t      mode = get_best_mode (bitsize, bitpos1, MEM_ALIGN (str_rtx),\n-\t\t\t\t    mode, 0);\n-\t      if (mode == VOIDmode)\n-\t\tbreak;\n-\n-\t      offset1 = bitpos1;\n-\t      bitpos1 %= GET_MODE_BITSIZE (mode);\n-\t      offset1 = (offset1 - bitpos1) / BITS_PER_UNIT;\n-\t      str_rtx = adjust_address (str_rtx, mode, offset1);\n-\t    }\n-\t  else if (!REG_P (str_rtx) && GET_CODE (str_rtx) != SUBREG)\n-\t    break;\n-\n-\t  /* If the bit field covers the whole REG/MEM, store_field\n-\t     will likely generate better code.  */\n-\t  if (bitsize >= GET_MODE_BITSIZE (GET_MODE (str_rtx)))\n-\t    break;\n-\n-\t  /* We can't handle fields split across multiple entities.  */\n-\t  if (bitpos1 + bitsize > GET_MODE_BITSIZE (GET_MODE (str_rtx)))\n-\t    break;\n+\t      set_mem_attributes_minus_bitpos (to_rtx, to, 0, bitpos);\n \n-\t  if (BYTES_BIG_ENDIAN)\n-\t    bitpos1 = GET_MODE_BITSIZE (GET_MODE (str_rtx)) - bitpos1\n-\t\t      - bitsize;\n-\n-\t  /* Special case some bitfield op= exp.  */\n-\t  switch (TREE_CODE (src))\n-\t    {\n-\t    case PLUS_EXPR:\n-\t    case MINUS_EXPR:\n-\t      /* For now, just optimize the case of the topmost bitfield\n-\t\t where we don't need to do any masking and also\n-\t\t 1 bit bitfields where xor can be used.\n-\t\t We might win by one instruction for the other bitfields\n-\t\t too if insv/extv instructions aren't used, so that\n-\t\t can be added later.  */\n-\t      if (bitpos1 + bitsize != GET_MODE_BITSIZE (GET_MODE (str_rtx))\n-\t\t  && (bitsize != 1 || TREE_CODE (op1) != INTEGER_CST))\n-\t\tbreak;\n-\t      value = expand_expr (op1, NULL_RTX, GET_MODE (str_rtx), 0);\n-\t      value = convert_modes (GET_MODE (str_rtx),\n-\t\t\t\t     TYPE_MODE (TREE_TYPE (op1)), value,\n-\t\t\t\t     TYPE_UNSIGNED (TREE_TYPE (op1)));\n-\n-\t      /* We may be accessing data outside the field, which means\n-\t\t we can alias adjacent data.  */\n-\t      if (MEM_P (str_rtx))\n-\t\t{\n-\t\t  str_rtx = shallow_copy_rtx (str_rtx);\n-\t\t  set_mem_alias_set (str_rtx, 0);\n-\t\t  set_mem_expr (str_rtx, 0);\n-\t\t}\n+\t      /* Deal with volatile and readonly fields.  The former is only\n+\t\t done for MEM.  Also set MEM_KEEP_ALIAS_SET_P if needed.  */\n+\t      if (volatilep)\n+\t\tMEM_VOLATILE_P (to_rtx) = 1;\n \n-\t      binop = TREE_CODE (src) == PLUS_EXPR ? add_optab : sub_optab;\n-\t      if (bitsize == 1\n-\t\t  && bitpos1 + bitsize != GET_MODE_BITSIZE (GET_MODE (str_rtx)))\n-\t\t{\n-\t\t  value = expand_and (GET_MODE (str_rtx), value, const1_rtx,\n-\t\t\t\t      NULL_RTX);\n-\t\t  binop = xor_optab;\n-\t\t}\n-\t      value = expand_shift (LSHIFT_EXPR, GET_MODE (str_rtx), value,\n-\t\t\t\t    build_int_cst (NULL_TREE, bitpos1),\n-\t\t\t\t    NULL_RTX, 1);\n-\t      result = expand_binop (GET_MODE (str_rtx), binop, str_rtx,\n-\t\t\t\t     value, str_rtx, 1, OPTAB_WIDEN);\n-\t      if (result != str_rtx)\n-\t\temit_move_insn (str_rtx, result);\n-\t      free_temp_slots ();\n-\t      pop_temp_slots ();\n-\t      return;\n-\n-\t    default:\n-\t      break;\n+\t      if (!can_address_p (to))\n+\t\tMEM_KEEP_ALIAS_SET_P (to_rtx) = 1;\n \t    }\n \n-\t  break;\n+\t  if (optimize_bitfield_assignment_op (bitsize, bitpos, mode1,\n+\t\t\t\t\t       to_rtx, to, from))\n+\t    result = NULL;\n+\t  else\n+\t    result = store_field (to_rtx, bitsize, bitpos, mode1, from,\n+\t\t\t\t  TREE_TYPE (tem), get_alias_set (to));\n \t}\n \n-      result = store_field (to_rtx, bitsize, bitpos, mode1, from,\n-\t\t\t    TREE_TYPE (tem), get_alias_set (to));\n-\n-      preserve_temp_slots (result);\n+      if (result)\n+\tpreserve_temp_slots (result);\n       free_temp_slots ();\n       pop_temp_slots ();\n-\n-      /* If the value is meaningful, convert RESULT to the proper mode.\n-\t Otherwise, return nothing.  */\n       return;\n     }\n "}]}