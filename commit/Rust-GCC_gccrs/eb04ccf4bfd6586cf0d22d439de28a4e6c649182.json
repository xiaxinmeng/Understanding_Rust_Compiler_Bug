{"sha": "eb04ccf4bfd6586cf0d22d439de28a4e6c649182", "node_id": "C_kwDOANBUbNoAKGViMDRjY2Y0YmZkNjU4NmNmMGQyMmQ0MzlkZTI4YTRlNmM2NDkxODI", "commit": {"author": {"name": "Jonathan Wright", "email": "jonathan.wright@arm.com", "date": "2021-10-07T15:08:33Z"}, "committer": {"name": "Jonathan Wright", "email": "jonathan.wright@arm.com", "date": "2021-11-04T14:55:44Z"}, "message": "aarch64: Pass and return Neon vector-tuple types without a parallel\n\nNeon vector-tuple types can be passed in registers on function call\nand return - there is no need to generate a parallel rtx. This patch\nadds cases to detect vector-tuple modes and generates an appropriate\nregister rtx.\n\nThis change greatly improves code generated when passing Neon vector-\ntuple types between functions; many new test cases are added to\ndefend these improvements.\n\ngcc/ChangeLog:\n\n2021-10-07  Jonathan Wright  <jonathan.wright@arm.com>\n\n\t* config/aarch64/aarch64.c (aarch64_function_value): Generate\n\ta register rtx for Neon vector-tuple modes.\n\t(aarch64_layout_arg): Likewise.\n\ngcc/testsuite/ChangeLog:\n\n\t* gcc.target/aarch64/vector_structure_intrinsics.c: New code\n\tgeneration tests.", "tree": {"sha": "1dcd92b4df93c5e2ae686712b4f83b9c06e5f2f6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/1dcd92b4df93c5e2ae686712b4f83b9c06e5f2f6"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/eb04ccf4bfd6586cf0d22d439de28a4e6c649182", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/eb04ccf4bfd6586cf0d22d439de28a4e6c649182", "html_url": "https://github.com/Rust-GCC/gccrs/commit/eb04ccf4bfd6586cf0d22d439de28a4e6c649182", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/eb04ccf4bfd6586cf0d22d439de28a4e6c649182/comments", "author": {"login": "jwright-arm", "id": 31624044, "node_id": "MDQ6VXNlcjMxNjI0MDQ0", "avatar_url": "https://avatars.githubusercontent.com/u/31624044?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jwright-arm", "html_url": "https://github.com/jwright-arm", "followers_url": "https://api.github.com/users/jwright-arm/followers", "following_url": "https://api.github.com/users/jwright-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jwright-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jwright-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jwright-arm/subscriptions", "organizations_url": "https://api.github.com/users/jwright-arm/orgs", "repos_url": "https://api.github.com/users/jwright-arm/repos", "events_url": "https://api.github.com/users/jwright-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jwright-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "jwright-arm", "id": 31624044, "node_id": "MDQ6VXNlcjMxNjI0MDQ0", "avatar_url": "https://avatars.githubusercontent.com/u/31624044?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jwright-arm", "html_url": "https://github.com/jwright-arm", "followers_url": "https://api.github.com/users/jwright-arm/followers", "following_url": "https://api.github.com/users/jwright-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jwright-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jwright-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jwright-arm/subscriptions", "organizations_url": "https://api.github.com/users/jwright-arm/orgs", "repos_url": "https://api.github.com/users/jwright-arm/repos", "events_url": "https://api.github.com/users/jwright-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jwright-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "511245325a4d3414a951e2d489112e8372eae1b1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/511245325a4d3414a951e2d489112e8372eae1b1", "html_url": "https://github.com/Rust-GCC/gccrs/commit/511245325a4d3414a951e2d489112e8372eae1b1"}], "stats": {"total": 735, "additions": 583, "deletions": 152}, "files": [{"sha": "69f08052ce808c140ed2933ab6b2e2617ca6f669", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/eb04ccf4bfd6586cf0d22d439de28a4e6c649182/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/eb04ccf4bfd6586cf0d22d439de28a4e6c649182/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=eb04ccf4bfd6586cf0d22d439de28a4e6c649182", "patch": "@@ -6473,6 +6473,12 @@ aarch64_function_value (const_tree type, const_tree func,\n \t  gcc_assert (count == 1 && mode == ag_mode);\n \t  return gen_rtx_REG (mode, V0_REGNUM);\n \t}\n+      else if (aarch64_advsimd_full_struct_mode_p (mode)\n+\t       && known_eq (GET_MODE_SIZE (ag_mode), 16))\n+\treturn gen_rtx_REG (mode, V0_REGNUM);\n+      else if (aarch64_advsimd_partial_struct_mode_p (mode)\n+\t       && known_eq (GET_MODE_SIZE (ag_mode), 8))\n+\treturn gen_rtx_REG (mode, V0_REGNUM);\n       else\n \t{\n \t  int i;\n@@ -6768,6 +6774,12 @@ aarch64_layout_arg (cumulative_args_t pcum_v, const function_arg_info &arg)\n \t      gcc_assert (nregs == 1);\n \t      pcum->aapcs_reg = gen_rtx_REG (mode, V0_REGNUM + nvrn);\n \t    }\n+\t  else if (aarch64_advsimd_full_struct_mode_p (mode)\n+\t\t   && known_eq (GET_MODE_SIZE (pcum->aapcs_vfp_rmode), 16))\n+\t    pcum->aapcs_reg = gen_rtx_REG (mode, V0_REGNUM + nvrn);\n+\t  else if (aarch64_advsimd_partial_struct_mode_p (mode)\n+\t\t   && known_eq (GET_MODE_SIZE (pcum->aapcs_vfp_rmode), 8))\n+\t    pcum->aapcs_reg = gen_rtx_REG (mode, V0_REGNUM + nvrn);\n \t  else\n \t    {\n \t      rtx par;"}, {"sha": "100739ab4e67e27a7341b8b1a4ddd9494f0e181d", "filename": "gcc/testsuite/gcc.target/aarch64/vector_structure_intrinsics.c", "status": "modified", "additions": 571, "deletions": 152, "changes": 723, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/eb04ccf4bfd6586cf0d22d439de28a4e6c649182/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvector_structure_intrinsics.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/eb04ccf4bfd6586cf0d22d439de28a4e6c649182/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvector_structure_intrinsics.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvector_structure_intrinsics.c?ref=eb04ccf4bfd6586cf0d22d439de28a4e6c649182", "patch": "@@ -17,6 +17,14 @@ TEST_TBL (vqtbl2q, int8x16_t, int8x16x2_t, uint8x16_t, s8)\n TEST_TBL (vqtbl2q, uint8x16_t, uint8x16x2_t, uint8x16_t, u8)\n TEST_TBL (vqtbl2q, poly8x16_t, poly8x16x2_t, uint8x16_t, p8)\n \n+TEST_TBL (vqtbl3, int8x8_t, int8x16x3_t, uint8x8_t, s8)\n+TEST_TBL (vqtbl3, uint8x8_t, uint8x16x3_t, uint8x8_t, u8)\n+TEST_TBL (vqtbl3, poly8x8_t, poly8x16x3_t, uint8x8_t, p8)\n+\n+TEST_TBL (vqtbl3q, int8x16_t, int8x16x3_t, uint8x16_t, s8)\n+TEST_TBL (vqtbl3q, uint8x16_t, uint8x16x3_t, uint8x16_t, u8)\n+TEST_TBL (vqtbl3q, poly8x16_t, poly8x16x3_t, uint8x16_t, p8)\n+\n TEST_TBL (vqtbl4, int8x8_t, int8x16x4_t, uint8x8_t, s8)\n TEST_TBL (vqtbl4, uint8x8_t, uint8x16x4_t, uint8x8_t, u8)\n TEST_TBL (vqtbl4, poly8x8_t, poly8x16x4_t, uint8x8_t, p8)\n@@ -25,84 +33,57 @@ TEST_TBL (vqtbl4q, int8x16_t, int8x16x4_t, uint8x16_t, s8)\n TEST_TBL (vqtbl4q, uint8x16_t, uint8x16x4_t, uint8x16_t, u8)\n TEST_TBL (vqtbl4q, poly8x16_t, poly8x16x4_t, uint8x16_t, p8)\n \n-#define TEST_TBL3(name, rettype, tbltype, idxtype, ts) \\\n-  rettype test_ ## name ## _ ## ts (idxtype a, tbltype b) \\\n-\t{ \\\n-\t\treturn name ## _ ## ts (b, a); \\\n-\t}\n-\n-TEST_TBL3 (vqtbl3, int8x8_t, int8x16x3_t, uint8x8_t, s8)\n-TEST_TBL3 (vqtbl3, uint8x8_t, uint8x16x3_t, uint8x8_t, u8)\n-TEST_TBL3 (vqtbl3, poly8x8_t, poly8x16x3_t, uint8x8_t, p8)\n-\n-TEST_TBL3 (vqtbl3q, int8x16_t, int8x16x3_t, uint8x16_t, s8)\n-TEST_TBL3 (vqtbl3q, uint8x16_t, uint8x16x3_t, uint8x16_t, u8)\n-TEST_TBL3 (vqtbl3q, poly8x16_t, poly8x16x3_t, uint8x16_t, p8)\n-\n-#define TEST_TBX2(name, rettype, tbltype, idxtype, ts) \\\n-  rettype test_ ## name ## _ ## ts (rettype a, idxtype b, tbltype c) \\\n-\t{ \\\n-\t\treturn name ## _ ## ts (a, c, b); \\\n-\t}\n-\n-TEST_TBX2 (vqtbx2, int8x8_t, int8x16x2_t, uint8x8_t, s8)\n-TEST_TBX2 (vqtbx2, uint8x8_t, uint8x16x2_t, uint8x8_t, u8)\n-TEST_TBX2 (vqtbx2, poly8x8_t, poly8x16x2_t, uint8x8_t, p8)\n-\n-TEST_TBX2 (vqtbx2q, int8x16_t, int8x16x2_t, uint8x16_t, s8)\n-TEST_TBX2 (vqtbx2q, uint8x16_t, uint8x16x2_t, uint8x16_t, u8)\n-TEST_TBX2 (vqtbx2q, poly8x16_t, poly8x16x2_t, uint8x16_t, p8)\n-\n-#define TEST_TBX3(name, rettype, tbltype, idxtype, ts) \\\n+#define TEST_TBX(name, rettype, tbltype, idxtype, ts) \\\n   rettype test_ ## name ## _ ## ts (rettype a, tbltype b, idxtype c) \\\n \t{ \\\n \t\treturn name ## _ ## ts (a, b, c); \\\n \t}\n \n-TEST_TBX3 (vqtbx3, int8x8_t, int8x16x3_t, uint8x8_t, s8)\n-TEST_TBX3 (vqtbx3, uint8x8_t, uint8x16x3_t, uint8x8_t, u8)\n-TEST_TBX3 (vqtbx3, poly8x8_t, poly8x16x3_t, uint8x8_t, p8)\n+TEST_TBX (vqtbx2, int8x8_t, int8x16x2_t, uint8x8_t, s8)\n+TEST_TBX (vqtbx2, uint8x8_t, uint8x16x2_t, uint8x8_t, u8)\n+TEST_TBX (vqtbx2, poly8x8_t, poly8x16x2_t, uint8x8_t, p8)\n \n-TEST_TBX3 (vqtbx3q, int8x16_t, int8x16x3_t, uint8x16_t, s8)\n-TEST_TBX3 (vqtbx3q, uint8x16_t, uint8x16x3_t, uint8x16_t, u8)\n-TEST_TBX3 (vqtbx3q, poly8x16_t, poly8x16x3_t, uint8x16_t, p8)\n+TEST_TBX (vqtbx2q, int8x16_t, int8x16x2_t, uint8x16_t, s8)\n+TEST_TBX (vqtbx2q, uint8x16_t, uint8x16x2_t, uint8x16_t, u8)\n+TEST_TBX (vqtbx2q, poly8x16_t, poly8x16x2_t, uint8x16_t, p8)\n \n-#define TEST_TBX4(name, rettype, tbltype, idxtype, ts) \\\n-  rettype test_ ## name ## _ ## ts (rettype a, idxtype b, idxtype dummy1, \\\n-\t\t\t\t    idxtype dummy2, tbltype c) \\\n-\t{ \\\n-\t\treturn name ## _ ## ts (a, c, b); \\\n-\t}\n+TEST_TBX (vqtbx3, int8x8_t, int8x16x3_t, uint8x8_t, s8)\n+TEST_TBX (vqtbx3, uint8x8_t, uint8x16x3_t, uint8x8_t, u8)\n+TEST_TBX (vqtbx3, poly8x8_t, poly8x16x3_t, uint8x8_t, p8)\n+\n+TEST_TBX (vqtbx3q, int8x16_t, int8x16x3_t, uint8x16_t, s8)\n+TEST_TBX (vqtbx3q, uint8x16_t, uint8x16x3_t, uint8x16_t, u8)\n+TEST_TBX (vqtbx3q, poly8x16_t, poly8x16x3_t, uint8x16_t, p8)\n \n-TEST_TBX4 (vqtbx4, int8x8_t, int8x16x4_t, uint8x8_t, s8)\n-TEST_TBX4 (vqtbx4, uint8x8_t, uint8x16x4_t, uint8x8_t, u8)\n-TEST_TBX4 (vqtbx4, poly8x8_t, poly8x16x4_t, uint8x8_t, p8)\n+TEST_TBX (vqtbx4, int8x8_t, int8x16x4_t, uint8x8_t, s8)\n+TEST_TBX (vqtbx4, uint8x8_t, uint8x16x4_t, uint8x8_t, u8)\n+TEST_TBX (vqtbx4, poly8x8_t, poly8x16x4_t, uint8x8_t, p8)\n \n-TEST_TBX4 (vqtbx4q, int8x16_t, int8x16x4_t, uint8x16_t, s8)\n-TEST_TBX4 (vqtbx4q, uint8x16_t, uint8x16x4_t, uint8x16_t, u8)\n-TEST_TBX4 (vqtbx4q, poly8x16_t, poly8x16x4_t, uint8x16_t, p8)\n+TEST_TBX (vqtbx4q, int8x16_t, int8x16x4_t, uint8x16_t, s8)\n+TEST_TBX (vqtbx4q, uint8x16_t, uint8x16x4_t, uint8x16_t, u8)\n+TEST_TBX (vqtbx4q, poly8x16_t, poly8x16x4_t, uint8x16_t, p8)\n \n #define TEST_STX(name, tbltype, ptrtype, ts) \\\n   void test_ ## name ## _ ## ts (ptrtype a, tbltype b) \\\n \t{ \\\n \t\tname ## _ ## ts (a, b); \\\n \t}\n \n-TEST_STX (vst4q, int8x16x4_t, int8_t*, s8);\n-TEST_STX (vst4q, uint8x16x4_t, uint8_t*, u8);\n-TEST_STX (vst4q, poly8x16x4_t, poly8_t*, p8);\n-TEST_STX (vst4q, int16x8x4_t, int16_t*, s16);\n-TEST_STX (vst4q, uint16x8x4_t, uint16_t*, u16);\n-TEST_STX (vst4q, poly16x8x4_t, poly16_t*, p16);\n-TEST_STX (vst4q, float16x8x4_t, float16_t*, f16);\n-TEST_STX (vst4q, bfloat16x8x4_t, bfloat16_t*, bf16);\n-TEST_STX (vst4q, int32x4x4_t, int32_t*, s32);\n-TEST_STX (vst4q, uint32x4x4_t, uint32_t*, u32);\n-TEST_STX (vst4q, float32x4x4_t, float32_t*, f32);\n-TEST_STX (vst4q, int64x2x4_t, int64_t*, s64);\n-TEST_STX (vst4q, uint64x2x4_t, uint64_t*, u64);\n-TEST_STX (vst4q, float64x2x4_t, float64_t*, f64);\n-TEST_STX (vst4q, poly64x2x4_t, poly64_t*, p64);\n+TEST_STX (vst2, int8x8x2_t, int8_t*, s8);\n+TEST_STX (vst2, uint8x8x2_t, uint8_t*, u8);\n+TEST_STX (vst2, poly8x8x2_t, poly8_t*, p8);\n+TEST_STX (vst2, int16x4x2_t, int16_t*, s16);\n+TEST_STX (vst2, uint16x4x2_t, uint16_t*, u16);\n+TEST_STX (vst2, poly16x4x2_t, poly16_t*, p16);\n+TEST_STX (vst2, float16x4x2_t, float16_t*, f16);\n+TEST_STX (vst2, bfloat16x4x2_t, bfloat16_t*, bf16);\n+TEST_STX (vst2, int32x2x2_t, int32_t*, s32);\n+TEST_STX (vst2, uint32x2x2_t, uint32_t*, u32);\n+TEST_STX (vst2, float32x2x2_t, float32_t*, f32);\n+TEST_STX (vst2, int64x1x2_t, int64_t*, s64);\n+TEST_STX (vst2, uint64x1x2_t, uint64_t*, u64);\n+TEST_STX (vst2, float64x1x2_t, float64_t*, f64);\n+TEST_STX (vst2, poly64x1x2_t, poly64_t*, p64);\n \n TEST_STX (vst2q, int8x16x2_t, int8_t*, s8);\n TEST_STX (vst2q, uint8x16x2_t, uint8_t*, u8);\n@@ -120,49 +101,193 @@ TEST_STX (vst2q, uint64x2x2_t, uint64_t*, u64);\n TEST_STX (vst2q, float64x2x2_t, float64_t*, f64);\n TEST_STX (vst2q, poly64x2x2_t, poly64_t*, p64);\n \n-#define TEST_ST3(name, tbltype, ptrtype, ts) \\\n-  void test_ ## name ## _ ## ts (ptrtype a, int8x8_t dummy, tbltype b) \\\n+TEST_STX (vst3, int8x8x3_t, int8_t*, s8);\n+TEST_STX (vst3, uint8x8x3_t, uint8_t*, u8);\n+TEST_STX (vst3, poly8x8x3_t, poly8_t*, p8);\n+TEST_STX (vst3, int16x4x3_t, int16_t*, s16);\n+TEST_STX (vst3, uint16x4x3_t, uint16_t*, u16);\n+TEST_STX (vst3, poly16x4x3_t, poly16_t*, p16);\n+TEST_STX (vst3, float16x4x3_t, float16_t*, f16);\n+TEST_STX (vst3, bfloat16x4x3_t, bfloat16_t*, bf16);\n+TEST_STX (vst3, int32x2x3_t, int32_t*, s32);\n+TEST_STX (vst3, uint32x2x3_t, uint32_t*, u32);\n+TEST_STX (vst3, float32x2x3_t, float32_t*, f32);\n+TEST_STX (vst3, int64x1x3_t, int64_t*, s64);\n+TEST_STX (vst3, uint64x1x3_t, uint64_t*, u64);\n+TEST_STX (vst3, float64x1x3_t, float64_t*, f64);\n+TEST_STX (vst3, poly64x1x3_t, poly64_t*, p64);\n+\n+TEST_STX (vst3q, int8x16x3_t, int8_t*, s8);\n+TEST_STX (vst3q, uint8x16x3_t, uint8_t*, u8);\n+TEST_STX (vst3q, poly8x16x3_t, poly8_t*, p8);\n+TEST_STX (vst3q, int16x8x3_t, int16_t*, s16);\n+TEST_STX (vst3q, uint16x8x3_t, uint16_t*, u16);\n+TEST_STX (vst3q, poly16x8x3_t, poly16_t*, p16);\n+TEST_STX (vst3q, float16x8x3_t, float16_t*, f16);\n+TEST_STX (vst3q, bfloat16x8x3_t, bfloat16_t*, bf16);\n+TEST_STX (vst3q, int32x4x3_t, int32_t*, s32);\n+TEST_STX (vst3q, uint32x4x3_t, uint32_t*, u32);\n+TEST_STX (vst3q, float32x4x3_t, float32_t*, f32);\n+TEST_STX (vst3q, int64x2x3_t, int64_t*, s64);\n+TEST_STX (vst3q, uint64x2x3_t, uint64_t*, u64);\n+TEST_STX (vst3q, float64x2x3_t, float64_t*, f64);\n+TEST_STX (vst3q, poly64x2x3_t, poly64_t*, p64);\n+\n+TEST_STX (vst4, int8x8x4_t, int8_t*, s8);\n+TEST_STX (vst4, uint8x8x4_t, uint8_t*, u8);\n+TEST_STX (vst4, poly8x8x4_t, poly8_t*, p8);\n+TEST_STX (vst4, int16x4x4_t, int16_t*, s16);\n+TEST_STX (vst4, uint16x4x4_t, uint16_t*, u16);\n+TEST_STX (vst4, poly16x4x4_t, poly16_t*, p16);\n+TEST_STX (vst4, float16x4x4_t, float16_t*, f16);\n+TEST_STX (vst4, bfloat16x4x4_t, bfloat16_t*, bf16);\n+TEST_STX (vst4, int32x2x4_t, int32_t*, s32);\n+TEST_STX (vst4, uint32x2x4_t, uint32_t*, u32);\n+TEST_STX (vst4, float32x2x4_t, float32_t*, f32);\n+TEST_STX (vst4, int64x1x4_t, int64_t*, s64);\n+TEST_STX (vst4, uint64x1x4_t, uint64_t*, u64);\n+TEST_STX (vst4, float64x1x4_t, float64_t*, f64);\n+TEST_STX (vst4, poly64x1x4_t, poly64_t*, p64);\n+\n+TEST_STX (vst4q, int8x16x4_t, int8_t*, s8);\n+TEST_STX (vst4q, uint8x16x4_t, uint8_t*, u8);\n+TEST_STX (vst4q, poly8x16x4_t, poly8_t*, p8);\n+TEST_STX (vst4q, int16x8x4_t, int16_t*, s16);\n+TEST_STX (vst4q, uint16x8x4_t, uint16_t*, u16);\n+TEST_STX (vst4q, poly16x8x4_t, poly16_t*, p16);\n+TEST_STX (vst4q, float16x8x4_t, float16_t*, f16);\n+TEST_STX (vst4q, bfloat16x8x4_t, bfloat16_t*, bf16);\n+TEST_STX (vst4q, int32x4x4_t, int32_t*, s32);\n+TEST_STX (vst4q, uint32x4x4_t, uint32_t*, u32);\n+TEST_STX (vst4q, float32x4x4_t, float32_t*, f32);\n+TEST_STX (vst4q, int64x2x4_t, int64_t*, s64);\n+TEST_STX (vst4q, uint64x2x4_t, uint64_t*, u64);\n+TEST_STX (vst4q, float64x2x4_t, float64_t*, f64);\n+TEST_STX (vst4q, poly64x2x4_t, poly64_t*, p64);\n+\n+#define TEST_LDX(name, rettype, ptrtype, ts) \\\n+  rettype test_ ## name ## _ ## ts (ptrtype a) \\\n \t{ \\\n-\t\tname ## _ ## ts (a, b); \\\n+\t\treturn name ## _ ## ts (a); \\\n \t}\n \n-TEST_ST3 (vst3q, int8x16x3_t, int8_t*, s8);\n-TEST_ST3 (vst3q, uint8x16x3_t, uint8_t*, u8);\n-TEST_ST3 (vst3q, poly8x16x3_t, poly8_t*, p8);\n-TEST_ST3 (vst3q, int16x8x3_t, int16_t*, s16);\n-TEST_ST3 (vst3q, uint16x8x3_t, uint16_t*, u16);\n-TEST_ST3 (vst3q, poly16x8x3_t, poly16_t*, p16);\n-TEST_ST3 (vst3q, float16x8x3_t, float16_t*, f16);\n-TEST_ST3 (vst3q, bfloat16x8x3_t, bfloat16_t*, bf16);\n-TEST_ST3 (vst3q, int32x4x3_t, int32_t*, s32);\n-TEST_ST3 (vst3q, uint32x4x3_t, uint32_t*, u32);\n-TEST_ST3 (vst3q, float32x4x3_t, float32_t*, f32);\n-TEST_ST3 (vst3q, int64x2x3_t, int64_t*, s64);\n-TEST_ST3 (vst3q, uint64x2x3_t, uint64_t*, u64);\n-TEST_ST3 (vst3q, float64x2x3_t, float64_t*, f64);\n-TEST_ST3 (vst3q, poly64x2x3_t, poly64_t*, p64);\n+TEST_LDX (vld2, int8x8x2_t, int8_t*, s8);\n+TEST_LDX (vld2, uint8x8x2_t, uint8_t*, u8);\n+TEST_LDX (vld2, poly8x8x2_t, poly8_t*, p8);\n+TEST_LDX (vld2, int16x4x2_t, int16_t*, s16);\n+TEST_LDX (vld2, uint16x4x2_t, uint16_t*, u16);\n+TEST_LDX (vld2, poly16x4x2_t, poly16_t*, p16);\n+TEST_LDX (vld2, float16x4x2_t, float16_t*, f16);\n+TEST_LDX (vld2, bfloat16x4x2_t, bfloat16_t*, bf16);\n+TEST_LDX (vld2, int32x2x2_t, int32_t*, s32);\n+TEST_LDX (vld2, uint32x2x2_t, uint32_t*, u32);\n+TEST_LDX (vld2, float32x2x2_t, float32_t*, f32);\n+TEST_LDX (vld2, int64x1x2_t, int64_t*, s64);\n+TEST_LDX (vld2, uint64x1x2_t, uint64_t*, u64);\n+TEST_LDX (vld2, float64x1x2_t, float64_t*, f64);\n+TEST_LDX (vld2, poly64x1x2_t, poly64_t*, p64);\n+\n+TEST_LDX (vld2q, int8x16x2_t, int8_t*, s8);\n+TEST_LDX (vld2q, uint8x16x2_t, uint8_t*, u8);\n+TEST_LDX (vld2q, poly8x16x2_t, poly8_t*, p8);\n+TEST_LDX (vld2q, int16x8x2_t, int16_t*, s16);\n+TEST_LDX (vld2q, uint16x8x2_t, uint16_t*, u16);\n+TEST_LDX (vld2q, poly16x8x2_t, poly16_t*, p16);\n+TEST_LDX (vld2q, float16x8x2_t, float16_t*, f16);\n+TEST_LDX (vld2q, bfloat16x8x2_t, bfloat16_t*, bf16);\n+TEST_LDX (vld2q, int32x4x2_t, int32_t*, s32);\n+TEST_LDX (vld2q, uint32x4x2_t, uint32_t*, u32);\n+TEST_LDX (vld2q, float32x4x2_t, float32_t*, f32);\n+TEST_LDX (vld2q, int64x2x2_t, int64_t*, s64);\n+TEST_LDX (vld2q, uint64x2x2_t, uint64_t*, u64);\n+TEST_LDX (vld2q, float64x2x2_t, float64_t*, f64);\n+TEST_LDX (vld2q, poly64x2x2_t, poly64_t*, p64);\n+\n+TEST_LDX (vld3, int8x8x3_t, int8_t*, s8);\n+TEST_LDX (vld3, uint8x8x3_t, uint8_t*, u8);\n+TEST_LDX (vld3, poly8x8x3_t, poly8_t*, p8);\n+TEST_LDX (vld3, int16x4x3_t, int16_t*, s16);\n+TEST_LDX (vld3, uint16x4x3_t, uint16_t*, u16);\n+TEST_LDX (vld3, poly16x4x3_t, poly16_t*, p16);\n+TEST_LDX (vld3, float16x4x3_t, float16_t*, f16);\n+TEST_LDX (vld3, bfloat16x4x3_t, bfloat16_t*, bf16);\n+TEST_LDX (vld3, int32x2x3_t, int32_t*, s32);\n+TEST_LDX (vld3, uint32x2x3_t, uint32_t*, u32);\n+TEST_LDX (vld3, float32x2x3_t, float32_t*, f32);\n+TEST_LDX (vld3, int64x1x3_t, int64_t*, s64);\n+TEST_LDX (vld3, uint64x1x3_t, uint64_t*, u64);\n+TEST_LDX (vld3, float64x1x3_t, float64_t*, f64);\n+TEST_LDX (vld3, poly64x1x3_t, poly64_t*, p64);\n+\n+TEST_LDX (vld3q, int8x16x3_t, int8_t*, s8);\n+TEST_LDX (vld3q, uint8x16x3_t, uint8_t*, u8);\n+TEST_LDX (vld3q, poly8x16x3_t, poly8_t*, p8);\n+TEST_LDX (vld3q, int16x8x3_t, int16_t*, s16);\n+TEST_LDX (vld3q, uint16x8x3_t, uint16_t*, u16);\n+TEST_LDX (vld3q, poly16x8x3_t, poly16_t*, p16);\n+TEST_LDX (vld3q, float16x8x3_t, float16_t*, f16);\n+TEST_LDX (vld3q, bfloat16x8x3_t, bfloat16_t*, bf16);\n+TEST_LDX (vld3q, int32x4x3_t, int32_t*, s32);\n+TEST_LDX (vld3q, uint32x4x3_t, uint32_t*, u32);\n+TEST_LDX (vld3q, float32x4x3_t, float32_t*, f32);\n+TEST_LDX (vld3q, int64x2x3_t, int64_t*, s64);\n+TEST_LDX (vld3q, uint64x2x3_t, uint64_t*, u64);\n+TEST_LDX (vld3q, float64x2x3_t, float64_t*, f64);\n+TEST_LDX (vld3q, poly64x2x3_t, poly64_t*, p64);\n+\n+TEST_LDX (vld4, int8x8x4_t, int8_t*, s8);\n+TEST_LDX (vld4, uint8x8x4_t, uint8_t*, u8);\n+TEST_LDX (vld4, poly8x8x4_t, poly8_t*, p8);\n+TEST_LDX (vld4, int16x4x4_t, int16_t*, s16);\n+TEST_LDX (vld4, uint16x4x4_t, uint16_t*, u16);\n+TEST_LDX (vld4, poly16x4x4_t, poly16_t*, p16);\n+TEST_LDX (vld4, float16x4x4_t, float16_t*, f16);\n+TEST_LDX (vld4, bfloat16x4x4_t, bfloat16_t*, bf16);\n+TEST_LDX (vld4, int32x2x4_t, int32_t*, s32);\n+TEST_LDX (vld4, uint32x2x4_t, uint32_t*, u32);\n+TEST_LDX (vld4, float32x2x4_t, float32_t*, f32);\n+TEST_LDX (vld4, int64x1x4_t, int64_t*, s64);\n+TEST_LDX (vld4, uint64x1x4_t, uint64_t*, u64);\n+TEST_LDX (vld4, float64x1x4_t, float64_t*, f64);\n+TEST_LDX (vld4, poly64x1x4_t, poly64_t*, p64);\n+\n+TEST_LDX (vld4q, int8x16x4_t, int8_t*, s8);\n+TEST_LDX (vld4q, uint8x16x4_t, uint8_t*, u8);\n+TEST_LDX (vld4q, poly8x16x4_t, poly8_t*, p8);\n+TEST_LDX (vld4q, int16x8x4_t, int16_t*, s16);\n+TEST_LDX (vld4q, uint16x8x4_t, uint16_t*, u16);\n+TEST_LDX (vld4q, poly16x8x4_t, poly16_t*, p16);\n+TEST_LDX (vld4q, float16x8x4_t, float16_t*, f16);\n+TEST_LDX (vld4q, bfloat16x8x4_t, bfloat16_t*, bf16);\n+TEST_LDX (vld4q, int32x4x4_t, int32_t*, s32);\n+TEST_LDX (vld4q, uint32x4x4_t, uint32_t*, u32);\n+TEST_LDX (vld4q, float32x4x4_t, float32_t*, f32);\n+TEST_LDX (vld4q, int64x2x4_t, int64_t*, s64);\n+TEST_LDX (vld4q, uint64x2x4_t, uint64_t*, u64);\n+TEST_LDX (vld4q, float64x2x4_t, float64_t*, f64);\n+TEST_LDX (vld4q, poly64x2x4_t, poly64_t*, p64);\n \n #define TEST_STX_LANE(name, tbltype, ptrtype, ts) \\\n   void test_ ## name ## _ ## ts (ptrtype a, tbltype b) \\\n \t{ \\\n-\t\tname ## _ ## ts (a, b, 1); \\\n+\t\tname ## _ ## ts (a, b, 0); \\\n \t}\n \n-TEST_STX_LANE (vst4q_lane, int8x16x4_t, int8_t*, s8);\n-TEST_STX_LANE (vst4q_lane, uint8x16x4_t, uint8_t*, u8);\n-TEST_STX_LANE (vst4q_lane, poly8x16x4_t, poly8_t*, p8);\n-TEST_STX_LANE (vst4q_lane, int16x8x4_t, int16_t*, s16);\n-TEST_STX_LANE (vst4q_lane, uint16x8x4_t, uint16_t*, u16);\n-TEST_STX_LANE (vst4q_lane, poly16x8x4_t, poly16_t*, p16);\n-TEST_STX_LANE (vst4q_lane, float16x8x4_t, float16_t*, f16);\n-TEST_STX_LANE (vst4q_lane, bfloat16x8x4_t, bfloat16_t*, bf16);\n-TEST_STX_LANE (vst4q_lane, int32x4x4_t, int32_t*, s32);\n-TEST_STX_LANE (vst4q_lane, uint32x4x4_t, uint32_t*, u32);\n-TEST_STX_LANE (vst4q_lane, float32x4x4_t, float32_t*, f32);\n-TEST_STX_LANE (vst4q_lane, int64x2x4_t, int64_t*, s64);\n-TEST_STX_LANE (vst4q_lane, uint64x2x4_t, uint64_t*, u64);\n-TEST_STX_LANE (vst4q_lane, float64x2x4_t, float64_t*, f64);\n-TEST_STX_LANE (vst4q_lane, poly64x2x4_t, poly64_t*, p64);\n+TEST_STX_LANE (vst2_lane, int8x8x2_t, int8_t*, s8);\n+TEST_STX_LANE (vst2_lane, uint8x8x2_t, uint8_t*, u8);\n+TEST_STX_LANE (vst2_lane, poly8x8x2_t, poly8_t*, p8);\n+TEST_STX_LANE (vst2_lane, int16x4x2_t, int16_t*, s16);\n+TEST_STX_LANE (vst2_lane, uint16x4x2_t, uint16_t*, u16);\n+TEST_STX_LANE (vst2_lane, poly16x4x2_t, poly16_t*, p16);\n+TEST_STX_LANE (vst2_lane, float16x4x2_t, float16_t*, f16);\n+TEST_STX_LANE (vst2_lane, bfloat16x4x2_t, bfloat16_t*, bf16);\n+TEST_STX_LANE (vst2_lane, int32x2x2_t, int32_t*, s32);\n+TEST_STX_LANE (vst2_lane, uint32x2x2_t, uint32_t*, u32);\n+TEST_STX_LANE (vst2_lane, float32x2x2_t, float32_t*, f32);\n+TEST_STX_LANE (vst2_lane, int64x1x2_t, int64_t*, s64);\n+TEST_STX_LANE (vst2_lane, uint64x1x2_t, uint64_t*, u64);\n+TEST_STX_LANE (vst2_lane, float64x1x2_t, float64_t*, f64);\n+TEST_STX_LANE (vst2_lane, poly64x1x2_t, poly64_t*, p64);\n \n TEST_STX_LANE (vst2q_lane, int8x16x2_t, int8_t*, s8);\n TEST_STX_LANE (vst2q_lane, uint8x16x2_t, uint8_t*, u8);\n@@ -180,49 +305,193 @@ TEST_STX_LANE (vst2q_lane, uint64x2x2_t, uint64_t*, u64);\n TEST_STX_LANE (vst2q_lane, float64x2x2_t, float64_t*, f64);\n TEST_STX_LANE (vst2q_lane, poly64x2x2_t, poly64_t*, p64);\n \n-#define TEST_ST3_LANE(name, tbltype, ptrtype, ts) \\\n-  void test_ ## name ## _ ## ts (ptrtype a, int8x8_t dummy, tbltype b) \\\n+TEST_STX_LANE (vst3_lane, int8x8x3_t, int8_t*, s8);\n+TEST_STX_LANE (vst3_lane, uint8x8x3_t, uint8_t*, u8);\n+TEST_STX_LANE (vst3_lane, poly8x8x3_t, poly8_t*, p8);\n+TEST_STX_LANE (vst3_lane, int16x4x3_t, int16_t*, s16);\n+TEST_STX_LANE (vst3_lane, uint16x4x3_t, uint16_t*, u16);\n+TEST_STX_LANE (vst3_lane, poly16x4x3_t, poly16_t*, p16);\n+TEST_STX_LANE (vst3_lane, float16x4x3_t, float16_t*, f16);\n+TEST_STX_LANE (vst3_lane, bfloat16x4x3_t, bfloat16_t*, bf16);\n+TEST_STX_LANE (vst3_lane, int32x2x3_t, int32_t*, s32);\n+TEST_STX_LANE (vst3_lane, uint32x2x3_t, uint32_t*, u32);\n+TEST_STX_LANE (vst3_lane, float32x2x3_t, float32_t*, f32);\n+TEST_STX_LANE (vst3_lane, int64x1x3_t, int64_t*, s64);\n+TEST_STX_LANE (vst3_lane, uint64x1x3_t, uint64_t*, u64);\n+TEST_STX_LANE (vst3_lane, float64x1x3_t, float64_t*, f64);\n+TEST_STX_LANE (vst3_lane, poly64x1x3_t, poly64_t*, p64);\n+\n+TEST_STX_LANE (vst3q_lane, int8x16x3_t, int8_t*, s8);\n+TEST_STX_LANE (vst3q_lane, uint8x16x3_t, uint8_t*, u8);\n+TEST_STX_LANE (vst3q_lane, poly8x16x3_t, poly8_t*, p8);\n+TEST_STX_LANE (vst3q_lane, int16x8x3_t, int16_t*, s16);\n+TEST_STX_LANE (vst3q_lane, uint16x8x3_t, uint16_t*, u16);\n+TEST_STX_LANE (vst3q_lane, poly16x8x3_t, poly16_t*, p16);\n+TEST_STX_LANE (vst3q_lane, float16x8x3_t, float16_t*, f16);\n+TEST_STX_LANE (vst3q_lane, bfloat16x8x3_t, bfloat16_t*, bf16);\n+TEST_STX_LANE (vst3q_lane, int32x4x3_t, int32_t*, s32);\n+TEST_STX_LANE (vst3q_lane, uint32x4x3_t, uint32_t*, u32);\n+TEST_STX_LANE (vst3q_lane, float32x4x3_t, float32_t*, f32);\n+TEST_STX_LANE (vst3q_lane, int64x2x3_t, int64_t*, s64);\n+TEST_STX_LANE (vst3q_lane, uint64x2x3_t, uint64_t*, u64);\n+TEST_STX_LANE (vst3q_lane, float64x2x3_t, float64_t*, f64);\n+TEST_STX_LANE (vst3q_lane, poly64x2x3_t, poly64_t*, p64);\n+\n+TEST_STX_LANE (vst4_lane, int8x8x4_t, int8_t*, s8);\n+TEST_STX_LANE (vst4_lane, uint8x8x4_t, uint8_t*, u8);\n+TEST_STX_LANE (vst4_lane, poly8x8x4_t, poly8_t*, p8);\n+TEST_STX_LANE (vst4_lane, int16x4x4_t, int16_t*, s16);\n+TEST_STX_LANE (vst4_lane, uint16x4x4_t, uint16_t*, u16);\n+TEST_STX_LANE (vst4_lane, poly16x4x4_t, poly16_t*, p16);\n+TEST_STX_LANE (vst4_lane, float16x4x4_t, float16_t*, f16);\n+TEST_STX_LANE (vst4_lane, bfloat16x4x4_t, bfloat16_t*, bf16);\n+TEST_STX_LANE (vst4_lane, int32x2x4_t, int32_t*, s32);\n+TEST_STX_LANE (vst4_lane, uint32x2x4_t, uint32_t*, u32);\n+TEST_STX_LANE (vst4_lane, float32x2x4_t, float32_t*, f32);\n+TEST_STX_LANE (vst4_lane, int64x1x4_t, int64_t*, s64);\n+TEST_STX_LANE (vst4_lane, uint64x1x4_t, uint64_t*, u64);\n+TEST_STX_LANE (vst4_lane, float64x1x4_t, float64_t*, f64);\n+TEST_STX_LANE (vst4_lane, poly64x1x4_t, poly64_t*, p64);\n+\n+TEST_STX_LANE (vst4q_lane, int8x16x4_t, int8_t*, s8);\n+TEST_STX_LANE (vst4q_lane, uint8x16x4_t, uint8_t*, u8);\n+TEST_STX_LANE (vst4q_lane, poly8x16x4_t, poly8_t*, p8);\n+TEST_STX_LANE (vst4q_lane, int16x8x4_t, int16_t*, s16);\n+TEST_STX_LANE (vst4q_lane, uint16x8x4_t, uint16_t*, u16);\n+TEST_STX_LANE (vst4q_lane, poly16x8x4_t, poly16_t*, p16);\n+TEST_STX_LANE (vst4q_lane, float16x8x4_t, float16_t*, f16);\n+TEST_STX_LANE (vst4q_lane, bfloat16x8x4_t, bfloat16_t*, bf16);\n+TEST_STX_LANE (vst4q_lane, int32x4x4_t, int32_t*, s32);\n+TEST_STX_LANE (vst4q_lane, uint32x4x4_t, uint32_t*, u32);\n+TEST_STX_LANE (vst4q_lane, float32x4x4_t, float32_t*, f32);\n+TEST_STX_LANE (vst4q_lane, int64x2x4_t, int64_t*, s64);\n+TEST_STX_LANE (vst4q_lane, uint64x2x4_t, uint64_t*, u64);\n+TEST_STX_LANE (vst4q_lane, float64x2x4_t, float64_t*, f64);\n+TEST_STX_LANE (vst4q_lane, poly64x2x4_t, poly64_t*, p64);\n+\n+#define TEST_LDX_LANE(name, rettype, ptrtype, ts) \\\n+  rettype test_ ## name ## _ ## ts (ptrtype a, rettype b) \\\n \t{ \\\n-\t\tname ## _ ## ts (a, b, 1); \\\n+\t\treturn name ## _ ## ts (a, b, 0); \\\n \t}\n \n-TEST_ST3_LANE (vst3q_lane, int8x16x3_t, int8_t*, s8);\n-TEST_ST3_LANE (vst3q_lane, uint8x16x3_t, uint8_t*, u8);\n-TEST_ST3_LANE (vst3q_lane, poly8x16x3_t, poly8_t*, p8);\n-TEST_ST3_LANE (vst3q_lane, int16x8x3_t, int16_t*, s16);\n-TEST_ST3_LANE (vst3q_lane, uint16x8x3_t, uint16_t*, u16);\n-TEST_ST3_LANE (vst3q_lane, poly16x8x3_t, poly16_t*, p16);\n-TEST_ST3_LANE (vst3q_lane, float16x8x3_t, float16_t*, f16);\n-TEST_ST3_LANE (vst3q_lane, bfloat16x8x3_t, bfloat16_t*, bf16);\n-TEST_ST3_LANE (vst3q_lane, int32x4x3_t, int32_t*, s32);\n-TEST_ST3_LANE (vst3q_lane, uint32x4x3_t, uint32_t*, u32);\n-TEST_ST3_LANE (vst3q_lane, float32x4x3_t, float32_t*, f32);\n-TEST_ST3_LANE (vst3q_lane, int64x2x3_t, int64_t*, s64);\n-TEST_ST3_LANE (vst3q_lane, uint64x2x3_t, uint64_t*, u64);\n-TEST_ST3_LANE (vst3q_lane, float64x2x3_t, float64_t*, f64);\n-TEST_ST3_LANE (vst3q_lane, poly64x2x3_t, poly64_t*, p64);\n+TEST_LDX_LANE (vld2_lane, int8x8x2_t, int8_t*, s8);\n+TEST_LDX_LANE (vld2_lane, uint8x8x2_t, uint8_t*, u8);\n+TEST_LDX_LANE (vld2_lane, poly8x8x2_t, poly8_t*, p8);\n+TEST_LDX_LANE (vld2_lane, int16x4x2_t, int16_t*, s16);\n+TEST_LDX_LANE (vld2_lane, uint16x4x2_t, uint16_t*, u16);\n+TEST_LDX_LANE (vld2_lane, poly16x4x2_t, poly16_t*, p16);\n+TEST_LDX_LANE (vld2_lane, float16x4x2_t, float16_t*, f16);\n+TEST_LDX_LANE (vld2_lane, bfloat16x4x2_t, bfloat16_t*, bf16);\n+TEST_LDX_LANE (vld2_lane, int32x2x2_t, int32_t*, s32);\n+TEST_LDX_LANE (vld2_lane, uint32x2x2_t, uint32_t*, u32);\n+TEST_LDX_LANE (vld2_lane, float32x2x2_t, float32_t*, f32);\n+TEST_LDX_LANE (vld2_lane, int64x1x2_t, int64_t*, s64);\n+TEST_LDX_LANE (vld2_lane, uint64x1x2_t, uint64_t*, u64);\n+TEST_LDX_LANE (vld2_lane, float64x1x2_t, float64_t*, f64);\n+TEST_LDX_LANE (vld2_lane, poly64x1x2_t, poly64_t*, p64);\n+\n+TEST_LDX_LANE (vld2q_lane, int8x16x2_t, int8_t*, s8);\n+TEST_LDX_LANE (vld2q_lane, uint8x16x2_t, uint8_t*, u8);\n+TEST_LDX_LANE (vld2q_lane, poly8x16x2_t, poly8_t*, p8);\n+TEST_LDX_LANE (vld2q_lane, int16x8x2_t, int16_t*, s16);\n+TEST_LDX_LANE (vld2q_lane, uint16x8x2_t, uint16_t*, u16);\n+TEST_LDX_LANE (vld2q_lane, poly16x8x2_t, poly16_t*, p16);\n+TEST_LDX_LANE (vld2q_lane, float16x8x2_t, float16_t*, f16);\n+TEST_LDX_LANE (vld2q_lane, bfloat16x8x2_t, bfloat16_t*, bf16);\n+TEST_LDX_LANE (vld2q_lane, int32x4x2_t, int32_t*, s32);\n+TEST_LDX_LANE (vld2q_lane, uint32x4x2_t, uint32_t*, u32);\n+TEST_LDX_LANE (vld2q_lane, float32x4x2_t, float32_t*, f32);\n+TEST_LDX_LANE (vld2q_lane, int64x2x2_t, int64_t*, s64);\n+TEST_LDX_LANE (vld2q_lane, uint64x2x2_t, uint64_t*, u64);\n+TEST_LDX_LANE (vld2q_lane, float64x2x2_t, float64_t*, f64);\n+TEST_LDX_LANE (vld2q_lane, poly64x2x2_t, poly64_t*, p64);\n+\n+TEST_LDX_LANE (vld3_lane, int8x8x3_t, int8_t*, s8);\n+TEST_LDX_LANE (vld3_lane, uint8x8x3_t, uint8_t*, u8);\n+TEST_LDX_LANE (vld3_lane, poly8x8x3_t, poly8_t*, p8);\n+TEST_LDX_LANE (vld3_lane, int16x4x3_t, int16_t*, s16);\n+TEST_LDX_LANE (vld3_lane, uint16x4x3_t, uint16_t*, u16);\n+TEST_LDX_LANE (vld3_lane, poly16x4x3_t, poly16_t*, p16);\n+TEST_LDX_LANE (vld3_lane, float16x4x3_t, float16_t*, f16);\n+TEST_LDX_LANE (vld3_lane, bfloat16x4x3_t, bfloat16_t*, bf16);\n+TEST_LDX_LANE (vld3_lane, int32x2x3_t, int32_t*, s32);\n+TEST_LDX_LANE (vld3_lane, uint32x2x3_t, uint32_t*, u32);\n+TEST_LDX_LANE (vld3_lane, float32x2x3_t, float32_t*, f32);\n+TEST_LDX_LANE (vld3_lane, int64x1x3_t, int64_t*, s64);\n+TEST_LDX_LANE (vld3_lane, uint64x1x3_t, uint64_t*, u64);\n+TEST_LDX_LANE (vld3_lane, float64x1x3_t, float64_t*, f64);\n+TEST_LDX_LANE (vld3_lane, poly64x1x3_t, poly64_t*, p64);\n+\n+TEST_LDX_LANE (vld3q_lane, int8x16x3_t, int8_t*, s8);\n+TEST_LDX_LANE (vld3q_lane, uint8x16x3_t, uint8_t*, u8);\n+TEST_LDX_LANE (vld3q_lane, poly8x16x3_t, poly8_t*, p8);\n+TEST_LDX_LANE (vld3q_lane, int16x8x3_t, int16_t*, s16);\n+TEST_LDX_LANE (vld3q_lane, uint16x8x3_t, uint16_t*, u16);\n+TEST_LDX_LANE (vld3q_lane, poly16x8x3_t, poly16_t*, p16);\n+TEST_LDX_LANE (vld3q_lane, float16x8x3_t, float16_t*, f16);\n+TEST_LDX_LANE (vld3q_lane, bfloat16x8x3_t, bfloat16_t*, bf16);\n+TEST_LDX_LANE (vld3q_lane, int32x4x3_t, int32_t*, s32);\n+TEST_LDX_LANE (vld3q_lane, uint32x4x3_t, uint32_t*, u32);\n+TEST_LDX_LANE (vld3q_lane, float32x4x3_t, float32_t*, f32);\n+TEST_LDX_LANE (vld3q_lane, int64x2x3_t, int64_t*, s64);\n+TEST_LDX_LANE (vld3q_lane, uint64x2x3_t, uint64_t*, u64);\n+TEST_LDX_LANE (vld3q_lane, float64x2x3_t, float64_t*, f64);\n+TEST_LDX_LANE (vld3q_lane, poly64x2x3_t, poly64_t*, p64);\n+\n+TEST_LDX_LANE (vld4_lane, int8x8x4_t, int8_t*, s8);\n+TEST_LDX_LANE (vld4_lane, uint8x8x4_t, uint8_t*, u8);\n+TEST_LDX_LANE (vld4_lane, poly8x8x4_t, poly8_t*, p8);\n+TEST_LDX_LANE (vld4_lane, int16x4x4_t, int16_t*, s16);\n+TEST_LDX_LANE (vld4_lane, uint16x4x4_t, uint16_t*, u16);\n+TEST_LDX_LANE (vld4_lane, poly16x4x4_t, poly16_t*, p16);\n+TEST_LDX_LANE (vld4_lane, float16x4x4_t, float16_t*, f16);\n+TEST_LDX_LANE (vld4_lane, bfloat16x4x4_t, bfloat16_t*, bf16);\n+TEST_LDX_LANE (vld4_lane, int32x2x4_t, int32_t*, s32);\n+TEST_LDX_LANE (vld4_lane, uint32x2x4_t, uint32_t*, u32);\n+TEST_LDX_LANE (vld4_lane, float32x2x4_t, float32_t*, f32);\n+TEST_LDX_LANE (vld4_lane, int64x1x4_t, int64_t*, s64);\n+TEST_LDX_LANE (vld4_lane, uint64x1x4_t, uint64_t*, u64);\n+TEST_LDX_LANE (vld4_lane, float64x1x4_t, float64_t*, f64);\n+TEST_LDX_LANE (vld4_lane, poly64x1x4_t, poly64_t*, p64);\n+\n+TEST_LDX_LANE (vld4q_lane, int8x16x4_t, int8_t*, s8);\n+TEST_LDX_LANE (vld4q_lane, uint8x16x4_t, uint8_t*, u8);\n+TEST_LDX_LANE (vld4q_lane, poly8x16x4_t, poly8_t*, p8);\n+TEST_LDX_LANE (vld4q_lane, int16x8x4_t, int16_t*, s16);\n+TEST_LDX_LANE (vld4q_lane, uint16x8x4_t, uint16_t*, u16);\n+TEST_LDX_LANE (vld4q_lane, poly16x8x4_t, poly16_t*, p16);\n+TEST_LDX_LANE (vld4q_lane, float16x8x4_t, float16_t*, f16);\n+TEST_LDX_LANE (vld4q_lane, bfloat16x8x4_t, bfloat16_t*, bf16);\n+TEST_LDX_LANE (vld4q_lane, int32x4x4_t, int32_t*, s32);\n+TEST_LDX_LANE (vld4q_lane, uint32x4x4_t, uint32_t*, u32);\n+TEST_LDX_LANE (vld4q_lane, float32x4x4_t, float32_t*, f32);\n+TEST_LDX_LANE (vld4q_lane, int64x2x4_t, int64_t*, s64);\n+TEST_LDX_LANE (vld4q_lane, uint64x2x4_t, uint64_t*, u64);\n+TEST_LDX_LANE (vld4q_lane, float64x2x4_t, float64_t*, f64);\n+TEST_LDX_LANE (vld4q_lane, poly64x2x4_t, poly64_t*, p64);\n \n #define TEST_ST1xN(name, tbltype, ptrtype, ts, xn) \\\n   void test_ ## name ## _ ## ts ## _ ## xn (ptrtype a, tbltype b) \\\n \t{ \\\n \t\tname ## _ ## ts ## _ ## xn (a, b); \\\n \t}\n \n-TEST_ST1xN (vst1q, int8x16x4_t, int8_t*, s8, x4);\n-TEST_ST1xN (vst1q, uint8x16x4_t, uint8_t*, u8, x4);\n-TEST_ST1xN (vst1q, poly8x16x4_t, poly8_t*, p8, x4);\n-TEST_ST1xN (vst1q, int16x8x4_t, int16_t*, s16, x4);\n-TEST_ST1xN (vst1q, uint16x8x4_t, uint16_t*, u16, x4);\n-TEST_ST1xN (vst1q, poly16x8x4_t, poly16_t*, p16, x4);\n-TEST_ST1xN (vst1q, float16x8x4_t, float16_t*, f16, x4);\n-TEST_ST1xN (vst1q, bfloat16x8x4_t, bfloat16_t*, bf16, x4);\n-TEST_ST1xN (vst1q, int32x4x4_t, int32_t*, s32, x4);\n-TEST_ST1xN (vst1q, uint32x4x4_t, uint32_t*, u32, x4);\n-TEST_ST1xN (vst1q, float32x4x4_t, float32_t*, f32, x4);\n-TEST_ST1xN (vst1q, int64x2x4_t, int64_t*, s64, x4);\n-TEST_ST1xN (vst1q, uint64x2x4_t, uint64_t*, u64, x4);\n-TEST_ST1xN (vst1q, poly64x2x4_t, poly64_t*, p64, x4);\n-TEST_ST1xN (vst1q, float64x2x4_t, float64_t*, f64, x4);\n+TEST_ST1xN (vst1, int8x8x2_t, int8_t*, s8, x2);\n+TEST_ST1xN (vst1, uint8x8x2_t, uint8_t*, u8, x2);\n+TEST_ST1xN (vst1, poly8x8x2_t, poly8_t*, p8, x2);\n+TEST_ST1xN (vst1, int16x4x2_t, int16_t*, s16, x2);\n+TEST_ST1xN (vst1, uint16x4x2_t, uint16_t*, u16, x2);\n+TEST_ST1xN (vst1, poly16x4x2_t, poly16_t*, p16, x2);\n+TEST_ST1xN (vst1, float16x4x2_t, float16_t*, f16, x2);\n+TEST_ST1xN (vst1, bfloat16x4x2_t, bfloat16_t*, bf16, x2);\n+TEST_ST1xN (vst1, int32x2x2_t, int32_t*, s32, x2);\n+TEST_ST1xN (vst1, uint32x2x2_t, uint32_t*, u32, x2);\n+TEST_ST1xN (vst1, float32x2x2_t, float32_t*, f32, x2);\n+TEST_ST1xN (vst1, int64x1x2_t, int64_t*, s64, x2);\n+TEST_ST1xN (vst1, uint64x1x2_t, uint64_t*, u64, x2);\n+TEST_ST1xN (vst1, poly64x1x2_t, poly64_t*, p64, x2);\n+TEST_ST1xN (vst1, float64x1x2_t, float64_t*, f64, x2);\n \n TEST_ST1xN (vst1q, int8x16x2_t, int8_t*, s8, x2);\n TEST_ST1xN (vst1q, uint8x16x2_t, uint8_t*, u8, x2);\n@@ -240,34 +509,184 @@ TEST_ST1xN (vst1q, uint64x2x2_t, uint64_t*, u64, x2);\n TEST_ST1xN (vst1q, poly64x2x2_t, poly64_t*, p64, x2);\n TEST_ST1xN (vst1q, float64x2x2_t, float64_t*, f64, x2);\n \n-#define TEST_ST1x3(name, tbltype, ptrtype, ts, xn) \\\n-  void test_ ## name ## _ ## ts ## _ ## xn (ptrtype a, int8x8_t dummy, \\\n-\t\t\t\t\t    tbltype b) \\\n+TEST_ST1xN (vst1, int8x8x3_t, int8_t*, s8, x3);\n+TEST_ST1xN (vst1, uint8x8x3_t, uint8_t*, u8, x3);\n+TEST_ST1xN (vst1, poly8x8x3_t, poly8_t*, p8, x3);\n+TEST_ST1xN (vst1, int16x4x3_t, int16_t*, s16, x3);\n+TEST_ST1xN (vst1, uint16x4x3_t, uint16_t*, u16, x3);\n+TEST_ST1xN (vst1, poly16x4x3_t, poly16_t*, p16, x3);\n+TEST_ST1xN (vst1, float16x4x3_t, float16_t*, f16, x3);\n+TEST_ST1xN (vst1, bfloat16x4x3_t, bfloat16_t*, bf16, x3);\n+TEST_ST1xN (vst1, int32x2x3_t, int32_t*, s32, x3);\n+TEST_ST1xN (vst1, uint32x2x3_t, uint32_t*, u32, x3);\n+TEST_ST1xN (vst1, float32x2x3_t, float32_t*, f32, x3);\n+TEST_ST1xN (vst1, int64x1x3_t, int64_t*, s64, x3);\n+TEST_ST1xN (vst1, uint64x1x3_t, uint64_t*, u64, x3);\n+TEST_ST1xN (vst1, poly64x1x3_t, poly64_t*, p64, x3);\n+TEST_ST1xN (vst1, float64x1x3_t, float64_t*, f64, x3);\n+\n+TEST_ST1xN (vst1q, int8x16x3_t, int8_t*, s8, x3);\n+TEST_ST1xN (vst1q, uint8x16x3_t, uint8_t*, u8, x3);\n+TEST_ST1xN (vst1q, poly8x16x3_t, poly8_t*, p8, x3);\n+TEST_ST1xN (vst1q, int16x8x3_t, int16_t*, s16, x3);\n+TEST_ST1xN (vst1q, uint16x8x3_t, uint16_t*, u16, x3);\n+TEST_ST1xN (vst1q, poly16x8x3_t, poly16_t*, p16, x3);\n+TEST_ST1xN (vst1q, float16x8x3_t, float16_t*, f16, x3);\n+TEST_ST1xN (vst1q, bfloat16x8x3_t, bfloat16_t*, bf16, x3);\n+TEST_ST1xN (vst1q, int32x4x3_t, int32_t*, s32, x3);\n+TEST_ST1xN (vst1q, uint32x4x3_t, uint32_t*, u32, x3);\n+TEST_ST1xN (vst1q, float32x4x3_t, float32_t*, f32, x3);\n+TEST_ST1xN (vst1q, int64x2x3_t, int64_t*, s64, x3);\n+TEST_ST1xN (vst1q, uint64x2x3_t, uint64_t*, u64, x3);\n+TEST_ST1xN (vst1q, poly64x2x3_t, poly64_t*, p64, x3);\n+TEST_ST1xN (vst1q, float64x2x3_t, float64_t*, f64, x3);\n+\n+TEST_ST1xN (vst1, int8x8x4_t, int8_t*, s8, x4);\n+TEST_ST1xN (vst1, uint8x8x4_t, uint8_t*, u8, x4);\n+TEST_ST1xN (vst1, poly8x8x4_t, poly8_t*, p8, x4);\n+TEST_ST1xN (vst1, int16x4x4_t, int16_t*, s16, x4);\n+TEST_ST1xN (vst1, uint16x4x4_t, uint16_t*, u16, x4);\n+TEST_ST1xN (vst1, poly16x4x4_t, poly16_t*, p16, x4);\n+TEST_ST1xN (vst1, float16x4x4_t, float16_t*, f16, x4);\n+TEST_ST1xN (vst1, bfloat16x4x4_t, bfloat16_t*, bf16, x4);\n+TEST_ST1xN (vst1, int32x2x4_t, int32_t*, s32, x4);\n+TEST_ST1xN (vst1, uint32x2x4_t, uint32_t*, u32, x4);\n+TEST_ST1xN (vst1, float32x2x4_t, float32_t*, f32, x4);\n+TEST_ST1xN (vst1, int64x1x4_t, int64_t*, s64, x4);\n+TEST_ST1xN (vst1, uint64x1x4_t, uint64_t*, u64, x4);\n+TEST_ST1xN (vst1, poly64x1x4_t, poly64_t*, p64, x4);\n+TEST_ST1xN (vst1, float64x1x4_t, float64_t*, f64, x4);\n+\n+TEST_ST1xN (vst1q, int8x16x4_t, int8_t*, s8, x4);\n+TEST_ST1xN (vst1q, uint8x16x4_t, uint8_t*, u8, x4);\n+TEST_ST1xN (vst1q, poly8x16x4_t, poly8_t*, p8, x4);\n+TEST_ST1xN (vst1q, int16x8x4_t, int16_t*, s16, x4);\n+TEST_ST1xN (vst1q, uint16x8x4_t, uint16_t*, u16, x4);\n+TEST_ST1xN (vst1q, poly16x8x4_t, poly16_t*, p16, x4);\n+TEST_ST1xN (vst1q, float16x8x4_t, float16_t*, f16, x4);\n+TEST_ST1xN (vst1q, bfloat16x8x4_t, bfloat16_t*, bf16, x4);\n+TEST_ST1xN (vst1q, int32x4x4_t, int32_t*, s32, x4);\n+TEST_ST1xN (vst1q, uint32x4x4_t, uint32_t*, u32, x4);\n+TEST_ST1xN (vst1q, float32x4x4_t, float32_t*, f32, x4);\n+TEST_ST1xN (vst1q, int64x2x4_t, int64_t*, s64, x4);\n+TEST_ST1xN (vst1q, uint64x2x4_t, uint64_t*, u64, x4);\n+TEST_ST1xN (vst1q, poly64x2x4_t, poly64_t*, p64, x4);\n+TEST_ST1xN (vst1q, float64x2x4_t, float64_t*, f64, x4);\n+\n+#define TEST_LD1xN(name, rettype, ptrtype, ts, xn) \\\n+  rettype test_ ## name ## _ ## ts ## _ ## xn (ptrtype a) \\\n \t{ \\\n-\t\tname ## _ ## ts ## _ ## xn (a, b); \\\n+\t\treturn name ## _ ## ts ## _ ## xn (a); \\\n \t}\n \n-TEST_ST1x3 (vst1q, int8x16x3_t, int8_t*, s8, x3);\n-TEST_ST1x3 (vst1q, uint8x16x3_t, uint8_t*, u8, x3);\n-TEST_ST1x3 (vst1q, poly8x16x3_t, poly8_t*, p8, x3);\n-TEST_ST1x3 (vst1q, int16x8x3_t, int16_t*, s16, x3);\n-TEST_ST1x3 (vst1q, uint16x8x3_t, uint16_t*, u16, x3);\n-TEST_ST1x3 (vst1q, poly16x8x3_t, poly16_t*, p16, x3);\n-TEST_ST1x3 (vst1q, float16x8x3_t, float16_t*, f16, x3);\n-TEST_ST1x3 (vst1q, bfloat16x8x3_t, bfloat16_t*, bf16, x3);\n-TEST_ST1x3 (vst1q, int32x4x3_t, int32_t*, s32, x3);\n-TEST_ST1x3 (vst1q, uint32x4x3_t, uint32_t*, u32, x3);\n-TEST_ST1x3 (vst1q, float32x4x3_t, float32_t*, f32, x3);\n-TEST_ST1x3 (vst1q, int64x2x3_t, int64_t*, s64, x3);\n-TEST_ST1x3 (vst1q, uint64x2x3_t, uint64_t*, u64, x3);\n-TEST_ST1x3 (vst1q, poly64x2x3_t, poly64_t*, p64, x3);\n-TEST_ST1x3 (vst1q, float64x2x3_t, float64_t*, f64, x3);\n+TEST_LD1xN (vld1, int8x8x2_t, int8_t*, s8, x2);\n+TEST_LD1xN (vld1, uint8x8x2_t, uint8_t*, u8, x2);\n+TEST_LD1xN (vld1, poly8x8x2_t, poly8_t*, p8, x2);\n+TEST_LD1xN (vld1, int16x4x2_t, int16_t*, s16, x2);\n+TEST_LD1xN (vld1, uint16x4x2_t, uint16_t*, u16, x2);\n+TEST_LD1xN (vld1, poly16x4x2_t, poly16_t*, p16, x2);\n+TEST_LD1xN (vld1, float16x4x2_t, float16_t*, f16, x2);\n+TEST_LD1xN (vld1, bfloat16x4x2_t, bfloat16_t*, bf16, x2);\n+TEST_LD1xN (vld1, int32x2x2_t, int32_t*, s32, x2);\n+TEST_LD1xN (vld1, uint32x2x2_t, uint32_t*, u32, x2);\n+TEST_LD1xN (vld1, float32x2x2_t, float32_t*, f32, x2);\n+TEST_LD1xN (vld1, int64x1x2_t, int64_t*, s64, x2);\n+TEST_LD1xN (vld1, uint64x1x2_t, uint64_t*, u64, x2);\n+TEST_LD1xN (vld1, poly64x1x2_t, poly64_t*, p64, x2);\n+TEST_LD1xN (vld1, float64x1x2_t, float64_t*, f64, x2);\n+\n+TEST_LD1xN (vld1q, int8x16x2_t, int8_t*, s8, x2);\n+TEST_LD1xN (vld1q, uint8x16x2_t, uint8_t*, u8, x2);\n+TEST_LD1xN (vld1q, poly8x16x2_t, poly8_t*, p8, x2);\n+TEST_LD1xN (vld1q, int16x8x2_t, int16_t*, s16, x2);\n+TEST_LD1xN (vld1q, uint16x8x2_t, uint16_t*, u16, x2);\n+TEST_LD1xN (vld1q, poly16x8x2_t, poly16_t*, p16, x2);\n+TEST_LD1xN (vld1q, float16x8x2_t, float16_t*, f16, x2);\n+TEST_LD1xN (vld1q, bfloat16x8x2_t, bfloat16_t*, bf16, x2);\n+TEST_LD1xN (vld1q, int32x4x2_t, int32_t*, s32, x2);\n+TEST_LD1xN (vld1q, uint32x4x2_t, uint32_t*, u32, x2);\n+TEST_LD1xN (vld1q, float32x4x2_t, float32_t*, f32, x2);\n+TEST_LD1xN (vld1q, int64x2x2_t, int64_t*, s64, x2);\n+TEST_LD1xN (vld1q, uint64x2x2_t, uint64_t*, u64, x2);\n+TEST_LD1xN (vld1q, poly64x2x2_t, poly64_t*, p64, x2);\n+TEST_LD1xN (vld1q, float64x2x2_t, float64_t*, f64, x2);\n+\n+TEST_LD1xN (vld1, int8x8x3_t, int8_t*, s8, x3);\n+TEST_LD1xN (vld1, uint8x8x3_t, uint8_t*, u8, x3);\n+TEST_LD1xN (vld1, poly8x8x3_t, poly8_t*, p8, x3);\n+TEST_LD1xN (vld1, int16x4x3_t, int16_t*, s16, x3);\n+TEST_LD1xN (vld1, uint16x4x3_t, uint16_t*, u16, x3);\n+TEST_LD1xN (vld1, poly16x4x3_t, poly16_t*, p16, x3);\n+TEST_LD1xN (vld1, float16x4x3_t, float16_t*, f16, x3);\n+TEST_LD1xN (vld1, bfloat16x4x3_t, bfloat16_t*, bf16, x3);\n+TEST_LD1xN (vld1, int32x2x3_t, int32_t*, s32, x3);\n+TEST_LD1xN (vld1, uint32x2x3_t, uint32_t*, u32, x3);\n+TEST_LD1xN (vld1, float32x2x3_t, float32_t*, f32, x3);\n+TEST_LD1xN (vld1, int64x1x3_t, int64_t*, s64, x3);\n+TEST_LD1xN (vld1, uint64x1x3_t, uint64_t*, u64, x3);\n+TEST_LD1xN (vld1, poly64x1x3_t, poly64_t*, p64, x3);\n+TEST_LD1xN (vld1, float64x1x3_t, float64_t*, f64, x3);\n+\n+TEST_LD1xN (vld1q, int8x16x3_t, int8_t*, s8, x3);\n+TEST_LD1xN (vld1q, uint8x16x3_t, uint8_t*, u8, x3);\n+TEST_LD1xN (vld1q, poly8x16x3_t, poly8_t*, p8, x3);\n+TEST_LD1xN (vld1q, int16x8x3_t, int16_t*, s16, x3);\n+TEST_LD1xN (vld1q, uint16x8x3_t, uint16_t*, u16, x3);\n+TEST_LD1xN (vld1q, poly16x8x3_t, poly16_t*, p16, x3);\n+TEST_LD1xN (vld1q, float16x8x3_t, float16_t*, f16, x3);\n+TEST_LD1xN (vld1q, bfloat16x8x3_t, bfloat16_t*, bf16, x3);\n+TEST_LD1xN (vld1q, int32x4x3_t, int32_t*, s32, x3);\n+TEST_LD1xN (vld1q, uint32x4x3_t, uint32_t*, u32, x3);\n+TEST_LD1xN (vld1q, float32x4x3_t, float32_t*, f32, x3);\n+TEST_LD1xN (vld1q, int64x2x3_t, int64_t*, s64, x3);\n+TEST_LD1xN (vld1q, uint64x2x3_t, uint64_t*, u64, x3);\n+TEST_LD1xN (vld1q, poly64x2x3_t, poly64_t*, p64, x3);\n+TEST_LD1xN (vld1q, float64x2x3_t, float64_t*, f64, x3);\n+\n+TEST_LD1xN (vld1, int8x8x4_t, int8_t*, s8, x4);\n+TEST_LD1xN (vld1, uint8x8x4_t, uint8_t*, u8, x4);\n+TEST_LD1xN (vld1, poly8x8x4_t, poly8_t*, p8, x4);\n+TEST_LD1xN (vld1, int16x4x4_t, int16_t*, s16, x4);\n+TEST_LD1xN (vld1, uint16x4x4_t, uint16_t*, u16, x4);\n+TEST_LD1xN (vld1, poly16x4x4_t, poly16_t*, p16, x4);\n+TEST_LD1xN (vld1, float16x4x4_t, float16_t*, f16, x4);\n+TEST_LD1xN (vld1, bfloat16x4x4_t, bfloat16_t*, bf16, x4);\n+TEST_LD1xN (vld1, int32x2x4_t, int32_t*, s32, x4);\n+TEST_LD1xN (vld1, uint32x2x4_t, uint32_t*, u32, x4);\n+TEST_LD1xN (vld1, float32x2x4_t, float32_t*, f32, x4);\n+TEST_LD1xN (vld1, int64x1x4_t, int64_t*, s64, x4);\n+TEST_LD1xN (vld1, uint64x1x4_t, uint64_t*, u64, x4);\n+TEST_LD1xN (vld1, poly64x1x4_t, poly64_t*, p64, x4);\n+TEST_LD1xN (vld1, float64x1x4_t, float64_t*, f64, x4);\n+\n+TEST_LD1xN (vld1q, int8x16x4_t, int8_t*, s8, x4);\n+TEST_LD1xN (vld1q, uint8x16x4_t, uint8_t*, u8, x4);\n+TEST_LD1xN (vld1q, poly8x16x4_t, poly8_t*, p8, x4);\n+TEST_LD1xN (vld1q, int16x8x4_t, int16_t*, s16, x4);\n+TEST_LD1xN (vld1q, uint16x8x4_t, uint16_t*, u16, x4);\n+TEST_LD1xN (vld1q, poly16x8x4_t, poly16_t*, p16, x4);\n+TEST_LD1xN (vld1q, float16x8x4_t, float16_t*, f16, x4);\n+TEST_LD1xN (vld1q, bfloat16x8x4_t, bfloat16_t*, bf16, x4);\n+TEST_LD1xN (vld1q, int32x4x4_t, int32_t*, s32, x4);\n+TEST_LD1xN (vld1q, uint32x4x4_t, uint32_t*, u32, x4);\n+TEST_LD1xN (vld1q, float32x4x4_t, float32_t*, f32, x4);\n+TEST_LD1xN (vld1q, int64x2x4_t, int64_t*, s64, x4);\n+TEST_LD1xN (vld1q, uint64x2x4_t, uint64_t*, u64, x4);\n+TEST_LD1xN (vld1q, poly64x2x4_t, poly64_t*, p64, x4);\n+TEST_LD1xN (vld1q, float64x2x4_t, float64_t*, f64, x4);\n \n /* { dg-final { scan-assembler-not \"mov\\\\t\" { target aarch64_little_endian } } } */\n+/* { dg-final { scan-assembler-not \"ldr\\\\t\" { target aarch64_little_endian } } } */\n+/* { dg-final { scan-assembler-not \"str\\\\t\" { target aarch64_little_endian } } } */\n+/* { dg-final { scan-assembler-not \"sp\" { target aarch64_little_endian } } } */\n \n /* { dg-final { scan-assembler-times \"tbl\\\\t\" 18} }  */\n /* { dg-final { scan-assembler-times \"tbx\\\\t\" 18} }  */\n-/* { dg-final { scan-assembler-times \"st4\\\\t\" 30} }  */\n-/* { dg-final { scan-assembler-times \"st3\\\\t\" 30} }  */\n-/* { dg-final { scan-assembler-times \"st2\\\\t\" 30} }  */\n-/* { dg-final { scan-assembler-times \"st1\\\\t\" 45} }  */\n+/* { dg-final { scan-assembler-times \"st4\\\\t\" 56} }  */\n+/* { dg-final { scan-assembler-times \"st3\\\\t\" 56} }  */\n+/* { dg-final { scan-assembler-times \"st2\\\\t\" 56} }  */\n+/* { dg-final { scan-assembler-times \"st1\\\\t\" 102} }  */\n+/* { dg-final { scan-assembler-times \"ld4\\\\t\" 56} }  */\n+/* { dg-final { scan-assembler-times \"ld3\\\\t\" 56} }  */\n+/* { dg-final { scan-assembler-times \"ld2\\\\t\" 56} }  */\n+/* { dg-final { scan-assembler-times \"ld1\\\\t\" 102} }  */"}]}