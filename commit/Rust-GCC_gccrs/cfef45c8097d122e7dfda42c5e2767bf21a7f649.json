{"sha": "cfef45c8097d122e7dfda42c5e2767bf21a7f649", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Y2ZlZjQ1YzgwOTdkMTIyZTdkZmRhNDJjNWUyNzY3YmYyMWE3ZjY0OQ==", "commit": {"author": {"name": "Richard Guenther", "email": "rguenther@suse.de", "date": "2011-03-24T11:23:29Z"}, "committer": {"name": "Richard Biener", "email": "rguenth@gcc.gnu.org", "date": "2011-03-24T11:23:29Z"}, "message": "re PR tree-optimization/46562 (CCP currently needs iteration for &a[i])\n\n2011-03-24  Richard Guenther  <rguenther@suse.de>\n\n\tPR tree-optimization/46562\n\t* tree.c (build_invariant_address): New function.\n\t* tree.h (build_invariant_address): Declare.\n\t* tree-dfa.c (get_addr_base_and_unit_offset): Wrap around\n\ta renamed function moved ...\n\t* tree-flow-inline.h (get_addr_base_and_unit_offset_1): ... here.\n\tTake valueization callback parameter.\n\t* tree-flow.h (gimple_fold_stmt_to_constant): Declare.\n\t* gimple-fold.h: New file.\n\t* tree-ssa-ccp.c (ccp_fold): Use gimple_fold_stmt_to_constant_1.\n\t(ccp_fold, fold_const_aggregate_ref,\n\tfold_ctor_reference, fold_nonarray_ctor_reference,\n\tfold_array_ctor_reference, fold_string_cst_ctor_reference,\n\tget_base_constructor): Move ...\n\t* gimple-fold.c: ... here.\n\t(gimple_fold_stmt_to_constant_1): New function\n\tsplit out from ccp_fold.  Take a valueization callback parameter.\n\tValueize all operands.\n\t(gimple_fold_stmt_to_constant): New wrapper function.\n\t(fold_const_aggregate_ref_1): New function split out from\n\tfold_const_aggregate_ref.  Take a valueization callback parameter.\n\t(fold_const_aggregate_ref): Wrap fold_const_aggregate_ref_1.\n\t* tree-ssa-sccvn.c (simplify_binary_expression): Simplify\n\tinvariant POINTER_PLUS_EXPRs to invariant form.\n\t(vn_valueize): New function.\n\t(try_to_simplify): Simplify by using gimple_fold_stmt_to_constant.\n\t* tree-vrp.c (vrp_valueize): New function.\n\t(vrp_visit_assignment_or_call): Use gimple_fold_stmt_to_constant\n\tto fold statements to constants.\n\t* tree-ssa-pre.c (eliminate): Properly guard propagation of\n\tfunction declarations.\n\t* Makefile.in (tree-ssa-sccvn.o, tree-vrp.o, gimple-fold.o,\n\ttree-ssa-ccp.o): Add gimple-fold.h dependencies.\n\n\t* c-c++-common/pr46562-2.c: New testcase.\n\t* c-c++-common/pr46562.c: Likewise.\n\nFrom-SVN: r171386", "tree": {"sha": "df3f9f4a9233142004cc074157b5b3c2abf3bcb5", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/df3f9f4a9233142004cc074157b5b3c2abf3bcb5"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/cfef45c8097d122e7dfda42c5e2767bf21a7f649", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/cfef45c8097d122e7dfda42c5e2767bf21a7f649", "html_url": "https://github.com/Rust-GCC/gccrs/commit/cfef45c8097d122e7dfda42c5e2767bf21a7f649", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/cfef45c8097d122e7dfda42c5e2767bf21a7f649/comments", "author": {"login": "rguenth", "id": 2046526, "node_id": "MDQ6VXNlcjIwNDY1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/2046526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rguenth", "html_url": "https://github.com/rguenth", "followers_url": "https://api.github.com/users/rguenth/followers", "following_url": "https://api.github.com/users/rguenth/following{/other_user}", "gists_url": "https://api.github.com/users/rguenth/gists{/gist_id}", "starred_url": "https://api.github.com/users/rguenth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rguenth/subscriptions", "organizations_url": "https://api.github.com/users/rguenth/orgs", "repos_url": "https://api.github.com/users/rguenth/repos", "events_url": "https://api.github.com/users/rguenth/events{/privacy}", "received_events_url": "https://api.github.com/users/rguenth/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "f3e8ab1973c02daace2d7be9dbf03be03a7b3669", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f3e8ab1973c02daace2d7be9dbf03be03a7b3669", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f3e8ab1973c02daace2d7be9dbf03be03a7b3669"}], "stats": {"total": 1716, "additions": 984, "deletions": 732}, "files": [{"sha": "9dec3e406fae2d62ab4fca9374ba2254a9ce6172", "filename": "gcc/ChangeLog", "status": "modified", "additions": 36, "deletions": 0, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -1,3 +1,39 @@\n+2011-03-24  Richard Guenther  <rguenther@suse.de>\n+\n+\tPR tree-optimization/46562\n+\t* tree.c (build_invariant_address): New function.\n+\t* tree.h (build_invariant_address): Declare.\n+\t* tree-dfa.c (get_addr_base_and_unit_offset): Wrap around\n+\ta renamed function moved ...\n+\t* tree-flow-inline.h (get_addr_base_and_unit_offset_1): ... here.\n+\tTake valueization callback parameter.\n+\t* tree-flow.h (gimple_fold_stmt_to_constant): Declare.\n+\t* gimple-fold.h: New file.\n+\t* tree-ssa-ccp.c (ccp_fold): Use gimple_fold_stmt_to_constant_1.\n+\t(ccp_fold, fold_const_aggregate_ref,\n+\tfold_ctor_reference, fold_nonarray_ctor_reference,\n+\tfold_array_ctor_reference, fold_string_cst_ctor_reference,\n+\tget_base_constructor): Move ...\n+\t* gimple-fold.c: ... here.\n+\t(gimple_fold_stmt_to_constant_1): New function\n+\tsplit out from ccp_fold.  Take a valueization callback parameter.\n+\tValueize all operands.\n+\t(gimple_fold_stmt_to_constant): New wrapper function.\n+\t(fold_const_aggregate_ref_1): New function split out from\n+\tfold_const_aggregate_ref.  Take a valueization callback parameter.\n+\t(fold_const_aggregate_ref): Wrap fold_const_aggregate_ref_1.\n+\t* tree-ssa-sccvn.c (simplify_binary_expression): Simplify\n+\tinvariant POINTER_PLUS_EXPRs to invariant form.\n+\t(vn_valueize): New function.\n+\t(try_to_simplify): Simplify by using gimple_fold_stmt_to_constant.\n+\t* tree-vrp.c (vrp_valueize): New function.\n+\t(vrp_visit_assignment_or_call): Use gimple_fold_stmt_to_constant\n+\tto fold statements to constants.\n+\t* tree-ssa-pre.c (eliminate): Properly guard propagation of\n+\tfunction declarations.\n+\t* Makefile.in (tree-ssa-sccvn.o, tree-vrp.o, gimple-fold.o,\n+\ttree-ssa-ccp.o): Add gimple-fold.h dependencies.\n+\n 2011-03-24  Richard Sandiford  <richard.sandiford@linaro.org>\n \n \t* config/h8300/predicates.md (jump_address_operand): Fix register"}, {"sha": "3ce80611bf4d04eefedbb28f041383e8aaee041c", "filename": "gcc/Makefile.in", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -2485,12 +2485,12 @@ tree-ssa-sccvn.o : tree-ssa-sccvn.c $(TREE_FLOW_H) $(CONFIG_H) \\\n    $(TM_H) coretypes.h $(TREE_DUMP_H) $(TREE_PASS_H) $(FLAGS_H) $(CFGLOOP_H) \\\n    alloc-pool.h $(BASIC_BLOCK_H) $(BITMAP_H) langhooks.h $(HASHTAB_H) $(GIMPLE_H) \\\n    $(TREE_INLINE_H) tree-iterator.h tree-ssa-propagate.h tree-ssa-sccvn.h \\\n-   $(PARAMS_H) tree-pretty-print.h gimple-pretty-print.h\n+   $(PARAMS_H) tree-pretty-print.h gimple-pretty-print.h gimple-fold.h\n tree-vrp.o : tree-vrp.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(TREE_H) \\\n    $(TREE_FLOW_H) $(TREE_PASS_H) $(TREE_DUMP_H) $(DIAGNOSTIC_H) $(GGC_H) \\\n    $(BASIC_BLOCK_H) tree-ssa-propagate.h $(FLAGS_H) $(TREE_DUMP_H) \\\n    $(CFGLOOP_H) $(SCEV_H) $(TIMEVAR_H) intl.h tree-pretty-print.h \\\n-   gimple-pretty-print.h\n+   gimple-pretty-print.h gimple-fold.h\n tree-cfg.o : tree-cfg.c $(TREE_FLOW_H) $(CONFIG_H) $(SYSTEM_H) \\\n    $(TREE_H) $(TM_P_H) $(EXPR_H) $(GGC_H) $(FLAGS_H) output.h \\\n    $(DIAGNOSTIC_H) $(FUNCTION_H) $(TIMEVAR_H) $(TM_H) coretypes.h \\\n@@ -2638,7 +2638,7 @@ gimple-fold.o : gimple-fold.c $(TREE_FLOW_H) $(CONFIG_H) \\\n    $(SYSTEM_H) $(RTL_H) $(TREE_H) $(TM_P_H) $(EXPR_H) $(GGC_H) output.h \\\n    $(DIAGNOSTIC_H) $(FUNCTION_H) $(TIMEVAR_H) $(TM_H) coretypes.h \\\n    $(TREE_DUMP_H) $(BASIC_BLOCK_H) $(TREE_PASS_H) langhooks.h \\\n-   tree-ssa-propagate.h value-prof.h $(FLAGS_H) $(TARGET_H)\n+   tree-ssa-propagate.h value-prof.h $(FLAGS_H) $(TARGET_H) gimple-fold.h\n gimple-low.o : gimple-low.c $(CONFIG_H) $(SYSTEM_H) $(TREE_H) \\\n    $(DIAGNOSTIC_H) $(GIMPLE_H) $(TREE_INLINE_H) langhooks.h \\\n    $(LANGHOOKS_DEF_H) $(TREE_FLOW_H) $(TIMEVAR_H) $(TM_H) coretypes.h \\\n@@ -3103,7 +3103,7 @@ tree-ssa-ccp.o : tree-ssa-ccp.c $(TREE_FLOW_H) $(CONFIG_H) \\\n    $(DIAGNOSTIC_H) $(FUNCTION_H) $(TIMEVAR_H) $(TM_H) coretypes.h \\\n    $(TREE_DUMP_H) $(BASIC_BLOCK_H) $(TREE_PASS_H) langhooks.h \\\n    tree-ssa-propagate.h value-prof.h $(FLAGS_H) $(TARGET_H) $(DIAGNOSTIC_CORE_H) \\\n-   $(DBGCNT_H) tree-pretty-print.h gimple-pretty-print.h\n+   $(DBGCNT_H) tree-pretty-print.h gimple-pretty-print.h gimple-fold.h\n tree-sra.o : tree-sra.c $(CONFIG_H) $(SYSTEM_H) coretypes.h alloc-pool.h \\\n    $(TM_H) $(TREE_H) $(GIMPLE_H) $(CGRAPH_H) $(TREE_FLOW_H) \\\n    $(IPA_PROP_H) $(DIAGNOSTIC_H) statistics.h $(TREE_DUMP_H) $(TIMEVAR_H) \\"}, {"sha": "367e40e30295a696dd872c09ef77d8d0b27b4cb5", "filename": "gcc/gimple-fold.c", "status": "modified", "additions": 637, "deletions": 0, "changes": 637, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Fgimple-fold.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Fgimple-fold.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-fold.c?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -30,6 +30,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-pass.h\"\n #include \"tree-ssa-propagate.h\"\n #include \"target.h\"\n+#include \"gimple-fold.h\"\n \n /* Return true when DECL can be referenced from current unit.\n    We can get declarations that are not possible to reference for\n@@ -2665,3 +2666,639 @@ maybe_fold_or_comparisons (enum tree_code code1, tree op1a, tree op1b,\n   else\n     return or_comparisons_1 (code2, op2a, op2b, code1, op1a, op1b);\n }\n+\n+\n+/* Fold STMT to a constant using VALUEIZE to valueize SSA names.\n+\n+   Either NULL_TREE, a simplified but non-constant or a constant\n+   is returned.\n+\n+   ???  This should go into a gimple-fold-inline.h file to be eventually\n+   privatized with the single valueize function used in the various TUs\n+   to avoid the indirect function call overhead.  */\n+\n+tree\n+gimple_fold_stmt_to_constant_1 (gimple stmt, tree (*valueize) (tree))\n+{\n+  location_t loc = gimple_location (stmt);\n+  switch (gimple_code (stmt))\n+    {\n+    case GIMPLE_ASSIGN:\n+      {\n+        enum tree_code subcode = gimple_assign_rhs_code (stmt);\n+\n+        switch (get_gimple_rhs_class (subcode))\n+          {\n+          case GIMPLE_SINGLE_RHS:\n+            {\n+              tree rhs = gimple_assign_rhs1 (stmt);\n+              enum tree_code_class kind = TREE_CODE_CLASS (subcode);\n+\n+              if (TREE_CODE (rhs) == SSA_NAME)\n+                {\n+                  /* If the RHS is an SSA_NAME, return its known constant value,\n+                     if any.  */\n+                  return (*valueize) (rhs);\n+                }\n+\t      /* Handle propagating invariant addresses into address\n+\t\t operations.  */\n+\t      else if (TREE_CODE (rhs) == ADDR_EXPR\n+\t\t       && !is_gimple_min_invariant (rhs))\n+\t\t{\n+\t\t  HOST_WIDE_INT offset;\n+\t\t  tree base;\n+\t\t  base = get_addr_base_and_unit_offset_1 (TREE_OPERAND (rhs, 0),\n+\t\t\t\t\t\t\t  &offset,\n+\t\t\t\t\t\t\t  valueize);\n+\t\t  if (base\n+\t\t      && (CONSTANT_CLASS_P (base)\n+\t\t\t  || decl_address_invariant_p (base)))\n+\t\t    return build_invariant_address (TREE_TYPE (rhs),\n+\t\t\t\t\t\t    base, offset);\n+\t\t}\n+\t      else if (TREE_CODE (rhs) == CONSTRUCTOR\n+\t\t       && TREE_CODE (TREE_TYPE (rhs)) == VECTOR_TYPE\n+\t\t       && (CONSTRUCTOR_NELTS (rhs)\n+\t\t\t   == TYPE_VECTOR_SUBPARTS (TREE_TYPE (rhs))))\n+\t\t{\n+\t\t  unsigned i;\n+\t\t  tree val, list;\n+\n+\t\t  list = NULL_TREE;\n+\t\t  FOR_EACH_CONSTRUCTOR_VALUE (CONSTRUCTOR_ELTS (rhs), i, val)\n+\t\t    {\n+\t\t      val = (*valueize) (val);\n+\t\t      if (TREE_CODE (val) == INTEGER_CST\n+\t\t\t  || TREE_CODE (val) == REAL_CST\n+\t\t\t  || TREE_CODE (val) == FIXED_CST)\n+\t\t\tlist = tree_cons (NULL_TREE, val, list);\n+\t\t      else\n+\t\t\treturn NULL_TREE;\n+\t\t    }\n+\n+\t\t  return build_vector (TREE_TYPE (rhs), nreverse (list));\n+\t\t}\n+\n+              if (kind == tcc_reference)\n+\t\t{\n+\t\t  if ((TREE_CODE (rhs) == VIEW_CONVERT_EXPR\n+\t\t       || TREE_CODE (rhs) == REALPART_EXPR\n+\t\t       || TREE_CODE (rhs) == IMAGPART_EXPR)\n+\t\t      && TREE_CODE (TREE_OPERAND (rhs, 0)) == SSA_NAME)\n+\t\t    {\n+\t\t      tree val = (*valueize) (TREE_OPERAND (rhs, 0));\n+\t\t      return fold_unary_loc (EXPR_LOCATION (rhs),\n+\t\t\t\t\t     TREE_CODE (rhs),\n+\t\t\t\t\t     TREE_TYPE (rhs), val);\n+\t\t    }\n+\t\t  else if (TREE_CODE (rhs) == BIT_FIELD_REF\n+\t\t\t   && TREE_CODE (TREE_OPERAND (rhs, 0)) == SSA_NAME)\n+\t\t    {\n+\t\t      tree val = (*valueize) (TREE_OPERAND (rhs, 0));\n+\t\t      return fold_ternary_loc (EXPR_LOCATION (rhs),\n+\t\t\t\t\t       TREE_CODE (rhs),\n+\t\t\t\t\t       TREE_TYPE (rhs), val,\n+\t\t\t\t\t       TREE_OPERAND (rhs, 1),\n+\t\t\t\t\t       TREE_OPERAND (rhs, 2));\n+\t\t    }\n+\t\t  else if (TREE_CODE (rhs) == MEM_REF\n+\t\t\t   && TREE_CODE (TREE_OPERAND (rhs, 0)) == SSA_NAME)\n+\t\t    {\n+\t\t      tree val = (*valueize) (TREE_OPERAND (rhs, 0));\n+\t\t      if (TREE_CODE (val) == ADDR_EXPR\n+\t\t\t  && is_gimple_min_invariant (val))\n+\t\t\t{\n+\t\t\t  tree tem = fold_build2 (MEM_REF, TREE_TYPE (rhs),\n+\t\t\t\t\t\t  unshare_expr (val),\n+\t\t\t\t\t\t  TREE_OPERAND (rhs, 1));\n+\t\t\t  if (tem)\n+\t\t\t    rhs = tem;\n+\t\t\t}\n+\t\t    }\n+\t\t  return fold_const_aggregate_ref_1 (rhs, valueize);\n+\t\t}\n+              else if (kind == tcc_declaration)\n+                return get_symbol_constant_value (rhs);\n+              return rhs;\n+            }\n+\n+          case GIMPLE_UNARY_RHS:\n+            {\n+              /* Handle unary operators that can appear in GIMPLE form.\n+                 Note that we know the single operand must be a constant,\n+                 so this should almost always return a simplified RHS.  */\n+              tree lhs = gimple_assign_lhs (stmt);\n+              tree op0 = (*valueize) (gimple_assign_rhs1 (stmt));\n+\n+\t      /* Conversions are useless for CCP purposes if they are\n+\t\t value-preserving.  Thus the restrictions that\n+\t\t useless_type_conversion_p places for pointer type conversions\n+\t\t do not apply here.  Substitution later will only substitute to\n+\t\t allowed places.  */\n+\t      if (CONVERT_EXPR_CODE_P (subcode)\n+\t\t  && POINTER_TYPE_P (TREE_TYPE (lhs))\n+\t\t  && POINTER_TYPE_P (TREE_TYPE (op0)))\n+\t\t{\n+\t\t  tree tem;\n+\t\t  /* Try to re-construct array references on-the-fly.  */\n+\t\t  if (!useless_type_conversion_p (TREE_TYPE (lhs),\n+\t\t\t\t\t\t  TREE_TYPE (op0))\n+\t\t      && ((tem = maybe_fold_offset_to_address\n+\t\t\t   (loc,\n+\t\t\t    op0, integer_zero_node, TREE_TYPE (lhs)))\n+\t\t\t  != NULL_TREE))\n+\t\t    return tem;\n+\t\t  return op0;\n+\t\t}\n+\n+              return\n+\t\tfold_unary_ignore_overflow_loc (loc, subcode,\n+\t\t\t\t\t\tgimple_expr_type (stmt), op0);\n+            }\n+\n+          case GIMPLE_BINARY_RHS:\n+            {\n+              /* Handle binary operators that can appear in GIMPLE form.  */\n+              tree op0 = (*valueize) (gimple_assign_rhs1 (stmt));\n+              tree op1 = (*valueize) (gimple_assign_rhs2 (stmt));\n+\n+\t      /* Translate &x + CST into an invariant form suitable for\n+\t         further propagation.  */\n+\t      if (gimple_assign_rhs_code (stmt) == POINTER_PLUS_EXPR\n+\t\t  && TREE_CODE (op0) == ADDR_EXPR\n+\t\t  && TREE_CODE (op1) == INTEGER_CST)\n+\t\t{\n+\t\t  tree off = fold_convert (ptr_type_node, op1);\n+\t\t  return build_fold_addr_expr\n+\t\t\t   (fold_build2 (MEM_REF,\n+\t\t\t\t\t TREE_TYPE (TREE_TYPE (op0)),\n+\t\t\t\t\t unshare_expr (op0), off));\n+\t\t}\n+\n+              return fold_binary_loc (loc, subcode,\n+\t\t\t\t      gimple_expr_type (stmt), op0, op1);\n+            }\n+\n+          case GIMPLE_TERNARY_RHS:\n+            {\n+              /* Handle ternary operators that can appear in GIMPLE form.  */\n+              tree op0 = (*valueize) (gimple_assign_rhs1 (stmt));\n+              tree op1 = (*valueize) (gimple_assign_rhs2 (stmt));\n+              tree op2 = (*valueize) (gimple_assign_rhs3 (stmt));\n+\n+              return fold_ternary_loc (loc, subcode,\n+\t\t\t\t       gimple_expr_type (stmt), op0, op1, op2);\n+            }\n+\n+          default:\n+            gcc_unreachable ();\n+          }\n+      }\n+\n+    case GIMPLE_CALL:\n+      {\n+\ttree fn = (*valueize) (gimple_call_fn (stmt));\n+\tif (TREE_CODE (fn) == ADDR_EXPR\n+\t    && TREE_CODE (TREE_OPERAND (fn, 0)) == FUNCTION_DECL\n+\t    && DECL_BUILT_IN (TREE_OPERAND (fn, 0)))\n+\t  {\n+\t    tree *args = XALLOCAVEC (tree, gimple_call_num_args (stmt));\n+\t    tree call, retval;\n+\t    unsigned i;\n+\t    for (i = 0; i < gimple_call_num_args (stmt); ++i)\n+\t      args[i] = (*valueize) (gimple_call_arg (stmt, i));\n+\t    call = build_call_array_loc (loc,\n+\t\t\t\t\t gimple_call_return_type (stmt),\n+\t\t\t\t\t fn, gimple_call_num_args (stmt), args);\n+\t    retval = fold_call_expr (EXPR_LOCATION (call), call, false);\n+\t    if (retval)\n+\t      /* fold_call_expr wraps the result inside a NOP_EXPR.  */\n+\t      STRIP_NOPS (retval);\n+\t    return retval;\n+\t  }\n+\treturn NULL_TREE;\n+      }\n+\n+    default:\n+      return NULL_TREE;\n+    }\n+}\n+\n+/* Fold STMT to a constant using VALUEIZE to valueize SSA names.\n+   Returns NULL_TREE if folding to a constant is not possible, otherwise\n+   returns a constant according to is_gimple_min_invariant.  */\n+\n+tree\n+gimple_fold_stmt_to_constant (gimple stmt, tree (*valueize) (tree))\n+{\n+  tree res = gimple_fold_stmt_to_constant_1 (stmt, valueize);\n+  if (res && is_gimple_min_invariant (res))\n+    return res;\n+  return NULL_TREE;\n+}\n+\n+\n+/* The following set of functions are supposed to fold references using\n+   their constant initializers.  */\n+\n+static tree fold_ctor_reference (tree type, tree ctor,\n+\t\t\t\t unsigned HOST_WIDE_INT offset,\n+\t\t\t\t unsigned HOST_WIDE_INT size);\n+\n+/* See if we can find constructor defining value of BASE.\n+   When we know the consructor with constant offset (such as\n+   base is array[40] and we do know constructor of array), then\n+   BIT_OFFSET is adjusted accordingly.\n+\n+   As a special case, return error_mark_node when constructor\n+   is not explicitly available, but it is known to be zero\n+   such as 'static const int a;'.  */\n+static tree\n+get_base_constructor (tree base, HOST_WIDE_INT *bit_offset,\n+\t\t      tree (*valueize)(tree))\n+{\n+  HOST_WIDE_INT bit_offset2, size, max_size;\n+  if (TREE_CODE (base) == MEM_REF)\n+    {\n+      if (!integer_zerop (TREE_OPERAND (base, 1)))\n+\t{\n+\t  if (!host_integerp (TREE_OPERAND (base, 1), 0))\n+\t    return NULL_TREE;\n+\t  *bit_offset += (mem_ref_offset (base).low\n+\t\t\t  * BITS_PER_UNIT);\n+\t}\n+\n+      if (valueize\n+\t  && TREE_CODE (TREE_OPERAND (base, 0)) == SSA_NAME)\n+\tbase = valueize (TREE_OPERAND (base, 0));\n+      if (!base || TREE_CODE (base) != ADDR_EXPR)\n+        return NULL_TREE;\n+      base = TREE_OPERAND (base, 0);\n+    }\n+\n+  /* Get a CONSTRUCTOR.  If BASE is a VAR_DECL, get its\n+     DECL_INITIAL.  If BASE is a nested reference into another\n+     ARRAY_REF or COMPONENT_REF, make a recursive call to resolve\n+     the inner reference.  */\n+  switch (TREE_CODE (base))\n+    {\n+    case VAR_DECL:\n+      if (!const_value_known_p (base))\n+\treturn NULL_TREE;\n+\n+      /* Fallthru.  */\n+    case CONST_DECL:\n+      if (!DECL_INITIAL (base)\n+\t  && (TREE_STATIC (base) || DECL_EXTERNAL (base)))\n+        return error_mark_node;\n+      return DECL_INITIAL (base);\n+\n+    case ARRAY_REF:\n+    case COMPONENT_REF:\n+      base = get_ref_base_and_extent (base, &bit_offset2, &size, &max_size);\n+      if (max_size == -1 || size != max_size)\n+\treturn NULL_TREE;\n+      *bit_offset +=  bit_offset2;\n+      return get_base_constructor (base, bit_offset, valueize);\n+\n+    case STRING_CST:\n+    case CONSTRUCTOR:\n+      return base;\n+\n+    default:\n+      return NULL_TREE;\n+    }\n+}\n+\n+/* CTOR is STRING_CST.  Fold reference of type TYPE and size SIZE\n+   to the memory at bit OFFSET.\n+\n+   We do only simple job of folding byte accesses.  */\n+\n+static tree\n+fold_string_cst_ctor_reference (tree type, tree ctor,\n+\t\t\t\tunsigned HOST_WIDE_INT offset,\n+\t\t\t\tunsigned HOST_WIDE_INT size)\n+{\n+  if (INTEGRAL_TYPE_P (type)\n+      && (TYPE_MODE (type)\n+\t  == TYPE_MODE (TREE_TYPE (TREE_TYPE (ctor))))\n+      && (GET_MODE_CLASS (TYPE_MODE (TREE_TYPE (TREE_TYPE (ctor))))\n+\t  == MODE_INT)\n+      && GET_MODE_SIZE (TYPE_MODE (TREE_TYPE (TREE_TYPE (ctor)))) == 1\n+      && size == BITS_PER_UNIT\n+      && !(offset % BITS_PER_UNIT))\n+    {\n+      offset /= BITS_PER_UNIT;\n+      if (offset < (unsigned HOST_WIDE_INT) TREE_STRING_LENGTH (ctor))\n+\treturn build_int_cst_type (type, (TREE_STRING_POINTER (ctor)\n+\t\t\t\t   [offset]));\n+      /* Folding\n+\t const char a[20]=\"hello\";\n+\t return a[10];\n+\n+\t might lead to offset greater than string length.  In this case we\n+\t know value is either initialized to 0 or out of bounds.  Return 0\n+\t in both cases.  */\n+      return build_zero_cst (type);\n+    }\n+  return NULL_TREE;\n+}\n+\n+/* CTOR is CONSTRUCTOR of an array type.  Fold reference of type TYPE and size\n+   SIZE to the memory at bit OFFSET.  */\n+\n+static tree\n+fold_array_ctor_reference (tree type, tree ctor,\n+\t\t\t   unsigned HOST_WIDE_INT offset,\n+\t\t\t   unsigned HOST_WIDE_INT size)\n+{\n+  unsigned HOST_WIDE_INT cnt;\n+  tree cfield, cval;\n+  double_int low_bound, elt_size;\n+  double_int index, max_index;\n+  double_int access_index;\n+  tree domain_type = TYPE_DOMAIN (TREE_TYPE (ctor));\n+  HOST_WIDE_INT inner_offset;\n+\n+  /* Compute low bound and elt size.  */\n+  if (domain_type && TYPE_MIN_VALUE (domain_type))\n+    {\n+      /* Static constructors for variably sized objects makes no sense.  */\n+      gcc_assert (TREE_CODE (TYPE_MIN_VALUE (domain_type)) == INTEGER_CST);\n+      low_bound = tree_to_double_int (TYPE_MIN_VALUE (domain_type));\n+    }\n+  else\n+    low_bound = double_int_zero;\n+  /* Static constructors for variably sized objects makes no sense.  */\n+  gcc_assert (TREE_CODE(TYPE_SIZE_UNIT (TREE_TYPE (TREE_TYPE (ctor))))\n+\t      == INTEGER_CST);\n+  elt_size =\n+    tree_to_double_int (TYPE_SIZE_UNIT (TREE_TYPE (TREE_TYPE (ctor))));\n+\n+\n+  /* We can handle only constantly sized accesses that are known to not\n+     be larger than size of array element.  */\n+  if (!TYPE_SIZE_UNIT (type)\n+      || TREE_CODE (TYPE_SIZE_UNIT (type)) != INTEGER_CST\n+      || double_int_cmp (elt_size,\n+\t\t\t tree_to_double_int (TYPE_SIZE_UNIT (type)), 0) < 0)\n+    return NULL_TREE;\n+\n+  /* Compute the array index we look for.  */\n+  access_index = double_int_udiv (uhwi_to_double_int (offset / BITS_PER_UNIT),\n+\t\t\t\t  elt_size, TRUNC_DIV_EXPR);\n+  access_index = double_int_add (access_index, low_bound);\n+\n+  /* And offset within the access.  */\n+  inner_offset = offset % (double_int_to_uhwi (elt_size) * BITS_PER_UNIT);\n+\n+  /* See if the array field is large enough to span whole access.  We do not\n+     care to fold accesses spanning multiple array indexes.  */\n+  if (inner_offset + size > double_int_to_uhwi (elt_size) * BITS_PER_UNIT)\n+    return NULL_TREE;\n+\n+  index = double_int_sub (low_bound, double_int_one);\n+  FOR_EACH_CONSTRUCTOR_ELT (CONSTRUCTOR_ELTS (ctor), cnt, cfield, cval)\n+    {\n+      /* Array constructor might explicitely set index, or specify range\n+\t or leave index NULL meaning that it is next index after previous\n+\t one.  */\n+      if (cfield)\n+\t{\n+\t  if (TREE_CODE (cfield) == INTEGER_CST)\n+\t    max_index = index = tree_to_double_int (cfield);\n+\t  else\n+\t    {\n+\t      gcc_assert (TREE_CODE (cfield) == RANGE_EXPR);\n+\t      index = tree_to_double_int (TREE_OPERAND (cfield, 0));\n+\t      max_index = tree_to_double_int (TREE_OPERAND (cfield, 1));\n+\t    }\n+\t}\n+      else\n+\tmax_index = index = double_int_add (index, double_int_one);\n+\n+      /* Do we have match?  */\n+      if (double_int_cmp (access_index, index, 1) >= 0\n+\t  && double_int_cmp (access_index, max_index, 1) <= 0)\n+\treturn fold_ctor_reference (type, cval, inner_offset, size);\n+    }\n+  /* When memory is not explicitely mentioned in constructor,\n+     it is 0 (or out of range).  */\n+  return build_zero_cst (type);\n+}\n+\n+/* CTOR is CONSTRUCTOR of an aggregate or vector.\n+   Fold reference of type TYPE and size SIZE to the memory at bit OFFSET.  */\n+\n+static tree\n+fold_nonarray_ctor_reference (tree type, tree ctor,\n+\t\t\t      unsigned HOST_WIDE_INT offset,\n+\t\t\t      unsigned HOST_WIDE_INT size)\n+{\n+  unsigned HOST_WIDE_INT cnt;\n+  tree cfield, cval;\n+\n+  FOR_EACH_CONSTRUCTOR_ELT (CONSTRUCTOR_ELTS (ctor), cnt, cfield,\n+\t\t\t    cval)\n+    {\n+      tree byte_offset = DECL_FIELD_OFFSET (cfield);\n+      tree field_offset = DECL_FIELD_BIT_OFFSET (cfield);\n+      tree field_size = DECL_SIZE (cfield);\n+      double_int bitoffset;\n+      double_int byte_offset_cst = tree_to_double_int (byte_offset);\n+      double_int bits_per_unit_cst = uhwi_to_double_int (BITS_PER_UNIT);\n+      double_int bitoffset_end;\n+\n+      /* Variable sized objects in static constructors makes no sense,\n+\t but field_size can be NULL for flexible array members.  */\n+      gcc_assert (TREE_CODE (field_offset) == INTEGER_CST\n+\t\t  && TREE_CODE (byte_offset) == INTEGER_CST\n+\t\t  && (field_size != NULL_TREE\n+\t\t      ? TREE_CODE (field_size) == INTEGER_CST\n+\t\t      : TREE_CODE (TREE_TYPE (cfield)) == ARRAY_TYPE));\n+\n+      /* Compute bit offset of the field.  */\n+      bitoffset = double_int_add (tree_to_double_int (field_offset),\n+\t\t\t\t  double_int_mul (byte_offset_cst,\n+\t\t\t\t\t\t  bits_per_unit_cst));\n+      /* Compute bit offset where the field ends.  */\n+      if (field_size != NULL_TREE)\n+\tbitoffset_end = double_int_add (bitoffset,\n+\t\t\t\t\ttree_to_double_int (field_size));\n+      else\n+\tbitoffset_end = double_int_zero;\n+\n+      /* Is OFFSET in the range (BITOFFSET, BITOFFSET_END)?  */\n+      if (double_int_cmp (uhwi_to_double_int (offset), bitoffset, 0) >= 0\n+\t  && (field_size == NULL_TREE\n+\t      || double_int_cmp (uhwi_to_double_int (offset),\n+\t\t\t\t bitoffset_end, 0) < 0))\n+\t{\n+\t  double_int access_end = double_int_add (uhwi_to_double_int (offset),\n+\t\t\t\t\t\t  uhwi_to_double_int (size));\n+\t  double_int inner_offset = double_int_sub (uhwi_to_double_int (offset),\n+\t\t\t\t\t\t    bitoffset);\n+\t  /* We do have overlap.  Now see if field is large enough to\n+\t     cover the access.  Give up for accesses spanning multiple\n+\t     fields.  */\n+\t  if (double_int_cmp (access_end, bitoffset_end, 0) > 0)\n+\t    return NULL_TREE;\n+\t  return fold_ctor_reference (type, cval,\n+\t\t\t\t      double_int_to_uhwi (inner_offset), size);\n+\t}\n+    }\n+  /* When memory is not explicitely mentioned in constructor, it is 0.  */\n+  return build_zero_cst (type);\n+}\n+\n+/* CTOR is value initializing memory, fold reference of type TYPE and size SIZE\n+   to the memory at bit OFFSET.  */\n+\n+static tree\n+fold_ctor_reference (tree type, tree ctor, unsigned HOST_WIDE_INT offset,\n+\t\t     unsigned HOST_WIDE_INT size)\n+{\n+  tree ret;\n+\n+  /* We found the field with exact match.  */\n+  if (useless_type_conversion_p (type, TREE_TYPE (ctor))\n+      && !offset)\n+    return canonicalize_constructor_val (ctor);\n+\n+  /* We are at the end of walk, see if we can view convert the\n+     result.  */\n+  if (!AGGREGATE_TYPE_P (TREE_TYPE (ctor)) && !offset\n+      /* VIEW_CONVERT_EXPR is defined only for matching sizes.  */\n+      && operand_equal_p (TYPE_SIZE (type),\n+\t\t\t  TYPE_SIZE (TREE_TYPE (ctor)), 0))\n+    {\n+      ret = canonicalize_constructor_val (ctor);\n+      ret = fold_unary (VIEW_CONVERT_EXPR, type, ret);\n+      if (ret)\n+\tSTRIP_NOPS (ret);\n+      return ret;\n+    }\n+  if (TREE_CODE (ctor) == STRING_CST)\n+    return fold_string_cst_ctor_reference (type, ctor, offset, size);\n+  if (TREE_CODE (ctor) == CONSTRUCTOR)\n+    {\n+\n+      if (TREE_CODE (TREE_TYPE (ctor)) == ARRAY_TYPE)\n+\treturn fold_array_ctor_reference (type, ctor, offset, size);\n+      else\n+\treturn fold_nonarray_ctor_reference (type, ctor, offset, size);\n+    }\n+\n+  return NULL_TREE;\n+}\n+\n+/* Return the tree representing the element referenced by T if T is an\n+   ARRAY_REF or COMPONENT_REF into constant aggregates valuezing SSA\n+   names using VALUEIZE.  Return NULL_TREE otherwise.  */\n+\n+tree\n+fold_const_aggregate_ref_1 (tree t, tree (*valueize) (tree))\n+{\n+  tree ctor, idx, base;\n+  HOST_WIDE_INT offset, size, max_size;\n+  tree tem;\n+\n+  if (TREE_CODE_CLASS (TREE_CODE (t)) == tcc_declaration)\n+    return get_symbol_constant_value (t);\n+\n+  tem = fold_read_from_constant_string (t);\n+  if (tem)\n+    return tem;\n+\n+  switch (TREE_CODE (t))\n+    {\n+    case ARRAY_REF:\n+    case ARRAY_RANGE_REF:\n+      /* Constant indexes are handled well by get_base_constructor.\n+\t Only special case variable offsets.\n+\t FIXME: This code can't handle nested references with variable indexes\n+\t (they will be handled only by iteration of ccp).  Perhaps we can bring\n+\t get_ref_base_and_extent here and make it use a valueize callback.  */\n+      if (TREE_CODE (TREE_OPERAND (t, 1)) == SSA_NAME\n+\t  && valueize\n+\t  && (idx = (*valueize) (TREE_OPERAND (t, 1)))\n+\t  && host_integerp (idx, 0))\n+\t{\n+\t  tree low_bound, unit_size;\n+\n+\t  /* If the resulting bit-offset is constant, track it.  */\n+\t  if ((low_bound = array_ref_low_bound (t),\n+\t       host_integerp (low_bound, 0))\n+\t      && (unit_size = array_ref_element_size (t),\n+\t\t  host_integerp (unit_size, 1)))\n+\t    {\n+\t      offset = TREE_INT_CST_LOW (idx);\n+\t      offset -= TREE_INT_CST_LOW (low_bound);\n+\t      offset *= TREE_INT_CST_LOW (unit_size);\n+\t      offset *= BITS_PER_UNIT;\n+\n+\t      base = TREE_OPERAND (t, 0);\n+\t      ctor = get_base_constructor (base, &offset, valueize);\n+\t      /* Empty constructor.  Always fold to 0.  */\n+\t      if (ctor == error_mark_node)\n+\t\treturn build_zero_cst (TREE_TYPE (t));\n+\t      /* Out of bound array access.  Value is undefined,\n+\t\t but don't fold.  */\n+\t      if (offset < 0)\n+\t\treturn NULL_TREE;\n+\t      /* We can not determine ctor.  */\n+\t      if (!ctor)\n+\t\treturn NULL_TREE;\n+\t      return fold_ctor_reference (TREE_TYPE (t), ctor, offset,\n+\t\t\t\t\t  TREE_INT_CST_LOW (unit_size)\n+\t\t\t\t\t  * BITS_PER_UNIT);\n+\t    }\n+\t}\n+      /* Fallthru.  */\n+\n+    case COMPONENT_REF:\n+    case BIT_FIELD_REF:\n+    case TARGET_MEM_REF:\n+    case MEM_REF:\n+      base = get_ref_base_and_extent (t, &offset, &size, &max_size);\n+      ctor = get_base_constructor (base, &offset, valueize);\n+\n+      /* Empty constructor.  Always fold to 0.  */\n+      if (ctor == error_mark_node)\n+\treturn build_zero_cst (TREE_TYPE (t));\n+      /* We do not know precise address.  */\n+      if (max_size == -1 || max_size != size)\n+\treturn NULL_TREE;\n+      /* We can not determine ctor.  */\n+      if (!ctor)\n+\treturn NULL_TREE;\n+\n+      /* Out of bound array access.  Value is undefined, but don't fold.  */\n+      if (offset < 0)\n+\treturn NULL_TREE;\n+\n+      return fold_ctor_reference (TREE_TYPE (t), ctor, offset, size);\n+\n+    case REALPART_EXPR:\n+    case IMAGPART_EXPR:\n+      {\n+\ttree c = fold_const_aggregate_ref_1 (TREE_OPERAND (t, 0), valueize);\n+\tif (c && TREE_CODE (c) == COMPLEX_CST)\n+\t  return fold_build1_loc (EXPR_LOCATION (t),\n+\t\t\t      TREE_CODE (t), TREE_TYPE (t), c);\n+\tbreak;\n+      }\n+\n+    default:\n+      break;\n+    }\n+\n+  return NULL_TREE;\n+}\n+\n+tree\n+fold_const_aggregate_ref (tree t)\n+{\n+  return fold_const_aggregate_ref_1 (t, NULL);\n+}"}, {"sha": "793d68a8538b2e794f5c3404409e5efe19c679a8", "filename": "gcc/gimple-fold.h", "status": "added", "additions": 33, "deletions": 0, "changes": 33, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Fgimple-fold.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Fgimple-fold.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-fold.h?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -0,0 +1,33 @@\n+/* Gimple folding definitions.\n+\n+   Copyright 2011 Free Software Foundation, Inc.\n+   Contributed by Richard Guenther <rguenther@suse.de>\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 3, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#ifndef GCC_GIMPLE_FOLD_H\n+#define GCC_GIMPLE_FOLD_H\n+\n+#include \"coretypes.h\"\n+\n+tree fold_const_aggregate_ref_1 (tree, tree (*) (tree));\n+tree fold_const_aggregate_ref (tree);\n+\n+tree gimple_fold_stmt_to_constant_1 (gimple, tree (*) (tree));\n+tree gimple_fold_stmt_to_constant (gimple, tree (*) (tree));\n+\n+#endif  /* GCC_GIMPLE_FOLD_H */"}, {"sha": "1dde723e3da1bad9034182b39e222a65081e4818", "filename": "gcc/ipa-split.c", "status": "modified", "additions": 26, "deletions": 3, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Fipa-split.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Fipa-split.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-split.c?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -169,8 +169,9 @@ static void\n dump_split_point (FILE * file, struct split_point *current)\n {\n   fprintf (file,\n-\t   \"Split point at BB %i header time:%i header size: %i\"\n-\t   \" split time: %i split size: %i\\n  bbs: \",\n+\t   \"Split point at BB %i\\n\"\n+\t   \"  header time: %i header size: %i\\n\"\n+\t   \"  split time: %i split size: %i\\n  bbs: \",\n \t   current->entry_bb->index, current->header_time,\n \t   current->header_size, current->split_time, current->split_size);\n   dump_bitmap (file, current->split_bbs);\n@@ -1036,12 +1037,13 @@ split_function (struct split_point *split_point)\n \n   /* If RETURN_BB has virtual operand PHIs, they must be removed and the\n      virtual operand marked for renaming as we change the CFG in a way that\n-     tree-inline is not able to compensate for. \n+     tree-inline is not able to compensate for.\n \n      Note this can happen whether or not we have a return value.  If we have\n      a return value, then RETURN_BB may have PHIs for real operands too.  */\n   if (return_bb != EXIT_BLOCK_PTR)\n     {\n+      bool phi_p = false;\n       for (gsi = gsi_start_phis (return_bb); !gsi_end_p (gsi);)\n \t{\n \t  gimple stmt = gsi_stmt (gsi);\n@@ -1052,7 +1054,28 @@ split_function (struct split_point *split_point)\n \t    }\n \t  mark_virtual_phi_result_for_renaming (stmt);\n \t  remove_phi_node (&gsi, true);\n+\t  phi_p = true;\n \t}\n+      /* In reality we have to rename the reaching definition of the\n+\t virtual operand at return_bb as we will eventually release it\n+\t when we remove the code region we outlined.\n+\t So we have to rename all immediate virtual uses of that region\n+\t if we didn't see a PHI definition yet.  */\n+      /* ???  In real reality we want to set the reaching vdef of the\n+         entry of the SESE region as the vuse of the call and the reaching\n+\t vdef of the exit of the SESE region as the vdef of the call.  */\n+      if (!phi_p)\n+\tfor (gsi = gsi_start_bb (return_bb); !gsi_end_p (gsi); gsi_next (&gsi))\n+\t  {\n+\t    gimple stmt = gsi_stmt (gsi);\n+\t    if (gimple_vuse (stmt))\n+\t      {\n+\t\tgimple_set_vuse (stmt, NULL_TREE);\n+\t\tupdate_stmt (stmt);\n+\t      }\n+\t    if (gimple_vdef (stmt))\n+\t      break;\n+\t  }\n     }\n \n   /* Now create the actual clone.  */"}, {"sha": "8bda6a47eec39837098642c85827ed5c28637d58", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -1,3 +1,9 @@\n+2011-03-24  Richard Guenther  <rguenther@suse.de>\n+\n+\tPR tree-optimization/46562\n+\t* c-c++-common/pr46562-2.c: New testcase.\n+\t* c-c++-common/pr46562.c: Likewise.\n+\n 2011-03-24  Ira Rosen  <ira.rosen@linaro.org>\n \n \t* gcc.dg/vect/vect-cselim-1.c: New test."}, {"sha": "5415860c7a74d25599cf5c8bd768e5cc2723818f", "filename": "gcc/testsuite/c-c++-common/pr46562-2.c", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fpr46562-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fpr46562-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fpr46562-2.c?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -0,0 +1,13 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O -fno-tree-ccp -fno-tree-forwprop -fdump-tree-fre\" } */\n+\n+static const int a[4] = {};\n+int foo(void)\n+{\n+  int i = 1;\n+  const int *p = &a[i];\n+  return *p;\n+}\n+\n+/* { dg-final { scan-tree-dump \"= 0;\" \"fre\" } } */\n+/* { dg-final { cleanup-tree-dump \"fre\" } } */"}, {"sha": "30659070f016a3b9c89a0c67f485b28f2364be6a", "filename": "gcc/testsuite/c-c++-common/pr46562.c", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fpr46562.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fpr46562.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fpr46562.c?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -0,0 +1,13 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O -fdump-tree-ccp1\" } */\n+\n+static const int a[4] = {};\n+int foo(void)\n+{\n+  int i = 1;\n+  const int *p = &a[i];\n+  return *p;\n+}\n+\n+/* { dg-final { scan-tree-dump \"return 0;\" \"ccp1\" } } */\n+/* { dg-final { cleanup-tree-dump \"ccp1\" } } */"}, {"sha": "9766f00ddf757d13cd5791f710ea96f798c562b4", "filename": "gcc/tree-dfa.c", "status": "modified", "additions": 1, "deletions": 104, "changes": 105, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree-dfa.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree-dfa.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-dfa.c?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -963,110 +963,7 @@ get_ref_base_and_extent (tree exp, HOST_WIDE_INT *poffset,\n tree\n get_addr_base_and_unit_offset (tree exp, HOST_WIDE_INT *poffset)\n {\n-  HOST_WIDE_INT byte_offset = 0;\n-\n-  /* Compute cumulative byte-offset for nested component-refs and array-refs,\n-     and find the ultimate containing object.  */\n-  while (1)\n-    {\n-      switch (TREE_CODE (exp))\n-\t{\n-\tcase BIT_FIELD_REF:\n-\t  return NULL_TREE;\n-\n-\tcase COMPONENT_REF:\n-\t  {\n-\t    tree field = TREE_OPERAND (exp, 1);\n-\t    tree this_offset = component_ref_field_offset (exp);\n-\t    HOST_WIDE_INT hthis_offset;\n-\n-\t    if (!this_offset\n-\t\t|| TREE_CODE (this_offset) != INTEGER_CST\n-\t\t|| (TREE_INT_CST_LOW (DECL_FIELD_BIT_OFFSET (field))\n-\t\t    % BITS_PER_UNIT))\n-\t      return NULL_TREE;\n-\n-\t    hthis_offset = TREE_INT_CST_LOW (this_offset);\n-\t    hthis_offset += (TREE_INT_CST_LOW (DECL_FIELD_BIT_OFFSET (field))\n-\t\t\t     / BITS_PER_UNIT);\n-\t    byte_offset += hthis_offset;\n-\t  }\n-\t  break;\n-\n-\tcase ARRAY_REF:\n-\tcase ARRAY_RANGE_REF:\n-\t  {\n-\t    tree index = TREE_OPERAND (exp, 1);\n-\t    tree low_bound, unit_size;\n-\n-\t    /* If the resulting bit-offset is constant, track it.  */\n-\t    if (TREE_CODE (index) == INTEGER_CST\n-\t\t&& (low_bound = array_ref_low_bound (exp),\n-\t\t    TREE_CODE (low_bound) == INTEGER_CST)\n-\t\t&& (unit_size = array_ref_element_size (exp),\n-\t\t    TREE_CODE (unit_size) == INTEGER_CST))\n-\t      {\n-\t\tHOST_WIDE_INT hindex = TREE_INT_CST_LOW (index);\n-\n-\t\thindex -= TREE_INT_CST_LOW (low_bound);\n-\t\thindex *= TREE_INT_CST_LOW (unit_size);\n-\t\tbyte_offset += hindex;\n-\t      }\n-\t    else\n-\t      return NULL_TREE;\n-\t  }\n-\t  break;\n-\n-\tcase REALPART_EXPR:\n-\t  break;\n-\n-\tcase IMAGPART_EXPR:\n-\t  byte_offset += TREE_INT_CST_LOW (TYPE_SIZE_UNIT (TREE_TYPE (exp)));\n-\t  break;\n-\n-\tcase VIEW_CONVERT_EXPR:\n-\t  break;\n-\n-\tcase MEM_REF:\n-\t  /* Hand back the decl for MEM[&decl, off].  */\n-\t  if (TREE_CODE (TREE_OPERAND (exp, 0)) == ADDR_EXPR)\n-\t    {\n-\t      if (!integer_zerop (TREE_OPERAND (exp, 1)))\n-\t\t{\n-\t\t  double_int off = mem_ref_offset (exp);\n-\t\t  gcc_assert (off.high == -1 || off.high == 0);\n-\t\t  byte_offset += double_int_to_shwi (off);\n-\t\t}\n-\t      exp = TREE_OPERAND (TREE_OPERAND (exp, 0), 0);\n-\t    }\n-\t  goto done;\n-\n-\tcase TARGET_MEM_REF:\n-\t  /* Hand back the decl for MEM[&decl, off].  */\n-\t  if (TREE_CODE (TMR_BASE (exp)) == ADDR_EXPR)\n-\t    {\n-\t      if (TMR_INDEX (exp) || TMR_INDEX2 (exp))\n-\t\treturn NULL_TREE;\n-\t      if (!integer_zerop (TMR_OFFSET (exp)))\n-\t\t{\n-\t\t  double_int off = mem_ref_offset (exp);\n-\t\t  gcc_assert (off.high == -1 || off.high == 0);\n-\t\t  byte_offset += double_int_to_shwi (off);\n-\t\t}\n-\t      exp = TREE_OPERAND (TMR_BASE (exp), 0);\n-\t    }\n-\t  goto done;\n-\n-\tdefault:\n-\t  goto done;\n-\t}\n-\n-      exp = TREE_OPERAND (exp, 0);\n-    }\n-done:\n-\n-  *poffset = byte_offset;\n-  return exp;\n+  return get_addr_base_and_unit_offset_1 (exp, poffset, NULL);\n }\n \n /* Returns true if STMT references an SSA_NAME that has"}, {"sha": "dcbe355e926220af8c6c517653c01aa7996c86a0", "filename": "gcc/tree-flow-inline.h", "status": "modified", "additions": 135, "deletions": 0, "changes": 135, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree-flow-inline.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree-flow-inline.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-flow-inline.h?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -1227,4 +1227,139 @@ make_ssa_name (tree var, gimple stmt)\n   return make_ssa_name_fn (cfun, var, stmt);\n }\n \n+/* Returns the base object and a constant BITS_PER_UNIT offset in *POFFSET that\n+   denotes the starting address of the memory access EXP.\n+   Returns NULL_TREE if the offset is not constant or any component\n+   is not BITS_PER_UNIT-aligned.\n+   VALUEIZE if non-NULL is used to valueize SSA names.  It should return\n+   its argument or a constant if the argument is known to be constant.  */\n+\n+static inline tree\n+get_addr_base_and_unit_offset_1 (tree exp, HOST_WIDE_INT *poffset,\n+\t\t\t\t tree (*valueize) (tree))\n+{\n+  HOST_WIDE_INT byte_offset = 0;\n+\n+  /* Compute cumulative byte-offset for nested component-refs and array-refs,\n+     and find the ultimate containing object.  */\n+  while (1)\n+    {\n+      switch (TREE_CODE (exp))\n+\t{\n+\tcase BIT_FIELD_REF:\n+\t  return NULL_TREE;\n+\n+\tcase COMPONENT_REF:\n+\t  {\n+\t    tree field = TREE_OPERAND (exp, 1);\n+\t    tree this_offset = component_ref_field_offset (exp);\n+\t    HOST_WIDE_INT hthis_offset;\n+\n+\t    if (!this_offset\n+\t\t|| TREE_CODE (this_offset) != INTEGER_CST\n+\t\t|| (TREE_INT_CST_LOW (DECL_FIELD_BIT_OFFSET (field))\n+\t\t    % BITS_PER_UNIT))\n+\t      return NULL_TREE;\n+\n+\t    hthis_offset = TREE_INT_CST_LOW (this_offset);\n+\t    hthis_offset += (TREE_INT_CST_LOW (DECL_FIELD_BIT_OFFSET (field))\n+\t\t\t     / BITS_PER_UNIT);\n+\t    byte_offset += hthis_offset;\n+\t  }\n+\t  break;\n+\n+\tcase ARRAY_REF:\n+\tcase ARRAY_RANGE_REF:\n+\t  {\n+\t    tree index = TREE_OPERAND (exp, 1);\n+\t    tree low_bound, unit_size;\n+\n+\t    if (valueize\n+\t\t&& TREE_CODE (index) == SSA_NAME)\n+\t      index = (*valueize) (index);\n+\n+\t    /* If the resulting bit-offset is constant, track it.  */\n+\t    if (TREE_CODE (index) == INTEGER_CST\n+\t\t&& (low_bound = array_ref_low_bound (exp),\n+\t\t    TREE_CODE (low_bound) == INTEGER_CST)\n+\t\t&& (unit_size = array_ref_element_size (exp),\n+\t\t    TREE_CODE (unit_size) == INTEGER_CST))\n+\t      {\n+\t\tHOST_WIDE_INT hindex = TREE_INT_CST_LOW (index);\n+\n+\t\thindex -= TREE_INT_CST_LOW (low_bound);\n+\t\thindex *= TREE_INT_CST_LOW (unit_size);\n+\t\tbyte_offset += hindex;\n+\t      }\n+\t    else\n+\t      return NULL_TREE;\n+\t  }\n+\t  break;\n+\n+\tcase REALPART_EXPR:\n+\t  break;\n+\n+\tcase IMAGPART_EXPR:\n+\t  byte_offset += TREE_INT_CST_LOW (TYPE_SIZE_UNIT (TREE_TYPE (exp)));\n+\t  break;\n+\n+\tcase VIEW_CONVERT_EXPR:\n+\t  break;\n+\n+\tcase MEM_REF:\n+\t  {\n+\t    tree base = TREE_OPERAND (exp, 0);\n+\t    if (valueize\n+\t\t&& TREE_CODE (base) == SSA_NAME)\n+\t      base = (*valueize) (base);\n+\n+\t    /* Hand back the decl for MEM[&decl, off].  */\n+\t    if (TREE_CODE (base) == ADDR_EXPR)\n+\t      {\n+\t\tif (!integer_zerop (TREE_OPERAND (exp, 1)))\n+\t\t  {\n+\t\t    double_int off = mem_ref_offset (exp);\n+\t\t    gcc_assert (off.high == -1 || off.high == 0);\n+\t\t    byte_offset += double_int_to_shwi (off);\n+\t\t  }\n+\t\texp = TREE_OPERAND (base, 0);\n+\t      }\n+\t    goto done;\n+\t  }\n+\n+\tcase TARGET_MEM_REF:\n+\t  {\n+\t    tree base = TREE_OPERAND (exp, 0);\n+\t    if (valueize\n+\t\t&& TREE_CODE (base) == SSA_NAME)\n+\t      base = (*valueize) (base);\n+\n+\t    /* Hand back the decl for MEM[&decl, off].  */\n+\t    if (TREE_CODE (base) == ADDR_EXPR)\n+\t      {\n+\t\tif (TMR_INDEX (exp) || TMR_INDEX2 (exp))\n+\t\t  return NULL_TREE;\n+\t\tif (!integer_zerop (TMR_OFFSET (exp)))\n+\t\t  {\n+\t\t    double_int off = mem_ref_offset (exp);\n+\t\t    gcc_assert (off.high == -1 || off.high == 0);\n+\t\t    byte_offset += double_int_to_shwi (off);\n+\t\t  }\n+\t\texp = TREE_OPERAND (base, 0);\n+\t      }\n+\t    goto done;\n+\t  }\n+\n+\tdefault:\n+\t  goto done;\n+\t}\n+\n+      exp = TREE_OPERAND (exp, 0);\n+    }\n+done:\n+\n+  *poffset = byte_offset;\n+  return exp;\n+}\n+\n #endif /* _TREE_FLOW_INLINE_H  */"}, {"sha": "c8ea3acdcd2e9156d789792bc1406c2a6e80b804", "filename": "gcc/tree-flow.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree-flow.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree-flow.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-flow.h?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -594,6 +594,7 @@ extern void ssanames_print_statistics (void);\n \n /* In tree-ssa-ccp.c  */\n tree fold_const_aggregate_ref (tree);\n+tree gimple_fold_stmt_to_constant (gimple, tree (*)(tree));\n \n /* In tree-ssa-dom.c  */\n extern void dump_dominator_optimization_stats (FILE *);"}, {"sha": "059274a3513679f2108397d28a4455e1808d794a", "filename": "gcc/tree-ssa-ccp.c", "status": "modified", "additions": 5, "deletions": 603, "changes": 608, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree-ssa-ccp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree-ssa-ccp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-ccp.c?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -132,6 +132,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"target.h\"\n #include \"diagnostic-core.h\"\n #include \"dbgcnt.h\"\n+#include \"gimple-fold.h\"\n \n \n /* Possible lattice values.  */\n@@ -167,9 +168,6 @@ static prop_value_t *const_val;\n \n static void canonicalize_float_value (prop_value_t *);\n static bool ccp_fold_stmt (gimple_stmt_iterator *);\n-static tree fold_ctor_reference (tree type, tree ctor,\n-\t\t\t\t unsigned HOST_WIDE_INT offset,\n-\t\t\t\t unsigned HOST_WIDE_INT size);\n \n /* Dump constant propagation value VAL to file OUTF prefixed by PREFIX.  */\n \n@@ -1098,220 +1096,6 @@ ccp_fold (gimple stmt)\n   location_t loc = gimple_location (stmt);\n   switch (gimple_code (stmt))\n     {\n-    case GIMPLE_ASSIGN:\n-      {\n-        enum tree_code subcode = gimple_assign_rhs_code (stmt);\n-\n-        switch (get_gimple_rhs_class (subcode))\n-          {\n-          case GIMPLE_SINGLE_RHS:\n-            {\n-              tree rhs = gimple_assign_rhs1 (stmt);\n-              enum tree_code_class kind = TREE_CODE_CLASS (subcode);\n-\n-              if (TREE_CODE (rhs) == SSA_NAME)\n-                {\n-                  /* If the RHS is an SSA_NAME, return its known constant value,\n-                     if any.  */\n-                  return get_constant_value (rhs);\n-                }\n-\t      /* Handle propagating invariant addresses into address operations.\n-\t\t The folding we do here matches that in tree-ssa-forwprop.c.  */\n-\t      else if (TREE_CODE (rhs) == ADDR_EXPR)\n-\t\t{\n-\t\t  tree *base;\n-\t\t  base = &TREE_OPERAND (rhs, 0);\n-\t\t  while (handled_component_p (*base))\n-\t\t    base = &TREE_OPERAND (*base, 0);\n-\t\t  if (TREE_CODE (*base) == MEM_REF\n-\t\t      && TREE_CODE (TREE_OPERAND (*base, 0)) == SSA_NAME)\n-\t\t    {\n-\t\t      tree val = get_constant_value (TREE_OPERAND (*base, 0));\n-\t\t      if (val\n-\t\t\t  && TREE_CODE (val) == ADDR_EXPR)\n-\t\t\t{\n-\t\t\t  tree ret, save = *base;\n-\t\t\t  tree new_base;\n-\t\t\t  new_base = fold_build2 (MEM_REF, TREE_TYPE (*base),\n-\t\t\t\t\t\t  unshare_expr (val),\n-\t\t\t\t\t\t  TREE_OPERAND (*base, 1));\n-\t\t\t  /* We need to return a new tree, not modify the IL\n-\t\t\t     or share parts of it.  So play some tricks to\n-\t\t\t     avoid manually building it.  */\n-\t\t\t  *base = new_base;\n-\t\t\t  ret = unshare_expr (rhs);\n-\t\t\t  recompute_tree_invariant_for_addr_expr (ret);\n-\t\t\t  *base = save;\n-\t\t\t  return ret;\n-\t\t\t}\n-\t\t    }\n-\t\t}\n-\t      else if (TREE_CODE (rhs) == CONSTRUCTOR\n-\t\t       && TREE_CODE (TREE_TYPE (rhs)) == VECTOR_TYPE\n-\t\t       && (CONSTRUCTOR_NELTS (rhs)\n-\t\t\t   == TYPE_VECTOR_SUBPARTS (TREE_TYPE (rhs))))\n-\t\t{\n-\t\t  unsigned i;\n-\t\t  tree val, list;\n-\n-\t\t  list = NULL_TREE;\n-\t\t  FOR_EACH_CONSTRUCTOR_VALUE (CONSTRUCTOR_ELTS (rhs), i, val)\n-\t\t    {\n-\t\t      val = valueize_op (val);\n-\t\t      if (TREE_CODE (val) == INTEGER_CST\n-\t\t\t  || TREE_CODE (val) == REAL_CST\n-\t\t\t  || TREE_CODE (val) == FIXED_CST)\n-\t\t\tlist = tree_cons (NULL_TREE, val, list);\n-\t\t      else\n-\t\t\treturn NULL_TREE;\n-\t\t    }\n-\n-\t\t  return build_vector (TREE_TYPE (rhs), nreverse (list));\n-\t\t}\n-\n-              if (kind == tcc_reference)\n-\t\t{\n-\t\t  if ((TREE_CODE (rhs) == VIEW_CONVERT_EXPR\n-\t\t       || TREE_CODE (rhs) == REALPART_EXPR\n-\t\t       || TREE_CODE (rhs) == IMAGPART_EXPR)\n-\t\t      && TREE_CODE (TREE_OPERAND (rhs, 0)) == SSA_NAME)\n-\t\t    {\n-\t\t      tree val = get_constant_value (TREE_OPERAND (rhs, 0));\n-\t\t      if (val)\n-\t\t\treturn fold_unary_loc (EXPR_LOCATION (rhs),\n-\t\t\t\t\t       TREE_CODE (rhs),\n-\t\t\t\t\t       TREE_TYPE (rhs), val);\n-\t\t    }\n-\t\t  else if (TREE_CODE (rhs) == BIT_FIELD_REF\n-\t\t\t   && TREE_CODE (TREE_OPERAND (rhs, 0)) == SSA_NAME)\n-\t\t    {\n-\t\t      tree val = get_constant_value (TREE_OPERAND (rhs, 0));\n-\t\t      if (val)\n-\t\t\treturn fold_ternary_loc (EXPR_LOCATION (rhs),\n-\t\t\t\t\t\t TREE_CODE (rhs),\n-\t\t\t\t\t\t TREE_TYPE (rhs), val,\n-\t\t\t\t\t\t TREE_OPERAND (rhs, 1),\n-\t\t\t\t\t\t TREE_OPERAND (rhs, 2));\n-\t\t    }\n-\t\t  else if (TREE_CODE (rhs) == MEM_REF\n-\t\t\t   && TREE_CODE (TREE_OPERAND (rhs, 0)) == SSA_NAME)\n-\t\t    {\n-\t\t      tree val = get_constant_value (TREE_OPERAND (rhs, 0));\n-\t\t      if (val\n-\t\t\t  && TREE_CODE (val) == ADDR_EXPR)\n-\t\t\t{\n-\t\t\t  tree tem = fold_build2 (MEM_REF, TREE_TYPE (rhs),\n-\t\t\t\t\t\t  unshare_expr (val),\n-\t\t\t\t\t\t  TREE_OPERAND (rhs, 1));\n-\t\t\t  if (tem)\n-\t\t\t    rhs = tem;\n-\t\t\t}\n-\t\t    }\n-\t\t  return fold_const_aggregate_ref (rhs);\n-\t\t}\n-              else if (kind == tcc_declaration)\n-                return get_symbol_constant_value (rhs);\n-              return rhs;\n-            }\n-\n-          case GIMPLE_UNARY_RHS:\n-            {\n-              /* Handle unary operators that can appear in GIMPLE form.\n-                 Note that we know the single operand must be a constant,\n-                 so this should almost always return a simplified RHS.  */\n-              tree lhs = gimple_assign_lhs (stmt);\n-              tree op0 = valueize_op (gimple_assign_rhs1 (stmt));\n-\n-\t      /* Conversions are useless for CCP purposes if they are\n-\t\t value-preserving.  Thus the restrictions that\n-\t\t useless_type_conversion_p places for pointer type conversions\n-\t\t do not apply here.  Substitution later will only substitute to\n-\t\t allowed places.  */\n-\t      if (CONVERT_EXPR_CODE_P (subcode)\n-\t\t  && POINTER_TYPE_P (TREE_TYPE (lhs))\n-\t\t  && POINTER_TYPE_P (TREE_TYPE (op0)))\n-\t\t{\n-\t\t  tree tem;\n-\t\t  /* Try to re-construct array references on-the-fly.  */\n-\t\t  if (!useless_type_conversion_p (TREE_TYPE (lhs),\n-\t\t\t\t\t\t  TREE_TYPE (op0))\n-\t\t      && ((tem = maybe_fold_offset_to_address\n-\t\t\t   (loc,\n-\t\t\t    op0, integer_zero_node, TREE_TYPE (lhs)))\n-\t\t\t  != NULL_TREE))\n-\t\t    return tem;\n-\t\t  return op0;\n-\t\t}\n-\n-              return\n-\t\tfold_unary_ignore_overflow_loc (loc, subcode,\n-\t\t\t\t\t\tgimple_expr_type (stmt), op0);\n-            }\n-\n-          case GIMPLE_BINARY_RHS:\n-            {\n-              /* Handle binary operators that can appear in GIMPLE form.  */\n-              tree op0 = valueize_op (gimple_assign_rhs1 (stmt));\n-              tree op1 = valueize_op (gimple_assign_rhs2 (stmt));\n-\n-\t      /* Translate &x + CST into an invariant form suitable for\n-\t         further propagation.  */\n-\t      if (gimple_assign_rhs_code (stmt) == POINTER_PLUS_EXPR\n-\t\t  && TREE_CODE (op0) == ADDR_EXPR\n-\t\t  && TREE_CODE (op1) == INTEGER_CST)\n-\t\t{\n-\t\t  tree off = fold_convert (ptr_type_node, op1);\n-\t\t  return build_fold_addr_expr\n-\t\t\t   (fold_build2 (MEM_REF,\n-\t\t\t\t\t TREE_TYPE (TREE_TYPE (op0)),\n-\t\t\t\t\t unshare_expr (op0), off));\n-\t\t}\n-\n-              return fold_binary_loc (loc, subcode,\n-\t\t\t\t      gimple_expr_type (stmt), op0, op1);\n-            }\n-\n-          case GIMPLE_TERNARY_RHS:\n-            {\n-              /* Handle ternary operators that can appear in GIMPLE form.  */\n-              tree op0 = valueize_op (gimple_assign_rhs1 (stmt));\n-              tree op1 = valueize_op (gimple_assign_rhs2 (stmt));\n-              tree op2 = valueize_op (gimple_assign_rhs3 (stmt));\n-\n-              return fold_ternary_loc (loc, subcode,\n-\t\t\t\t       gimple_expr_type (stmt), op0, op1, op2);\n-            }\n-\n-          default:\n-            gcc_unreachable ();\n-          }\n-      }\n-      break;\n-\n-    case GIMPLE_CALL:\n-      {\n-\ttree fn = valueize_op (gimple_call_fn (stmt));\n-\tif (TREE_CODE (fn) == ADDR_EXPR\n-\t    && TREE_CODE (TREE_OPERAND (fn, 0)) == FUNCTION_DECL\n-\t    && DECL_BUILT_IN (TREE_OPERAND (fn, 0)))\n-\t  {\n-\t    tree *args = XALLOCAVEC (tree, gimple_call_num_args (stmt));\n-\t    tree call, retval;\n-\t    unsigned i;\n-\t    for (i = 0; i < gimple_call_num_args (stmt); ++i)\n-\t      args[i] = valueize_op (gimple_call_arg (stmt, i));\n-\t    call = build_call_array_loc (loc,\n-\t\t\t\t\t gimple_call_return_type (stmt),\n-\t\t\t\t\t fn, gimple_call_num_args (stmt), args);\n-\t    retval = fold_call_expr (EXPR_LOCATION (call), call, false);\n-\t    if (retval)\n-\t      /* fold_call_expr wraps the result inside a NOP_EXPR.  */\n-\t      STRIP_NOPS (retval);\n-\t    return retval;\n-\t  }\n-\treturn NULL_TREE;\n-      }\n-\n     case GIMPLE_COND:\n       {\n         /* Handle comparison operators that can appear in GIMPLE form.  */\n@@ -1327,395 +1111,13 @@ ccp_fold (gimple stmt)\n         return valueize_op (gimple_switch_index (stmt));\n       }\n \n-    default:\n-      gcc_unreachable ();\n-    }\n-}\n-\n-/* See if we can find constructor defining value of BASE.\n-   When we know the consructor with constant offset (such as\n-   base is array[40] and we do know constructor of array), then\n-   BIT_OFFSET is adjusted accordingly.\n-\n-   As a special case, return error_mark_node when constructor\n-   is not explicitly available, but it is known to be zero\n-   such as 'static const int a;'.  */\n-static tree\n-get_base_constructor (tree base, HOST_WIDE_INT *bit_offset)\n-{\n-  HOST_WIDE_INT bit_offset2, size, max_size;\n-  if (TREE_CODE (base) == MEM_REF)\n-    {\n-      if (!integer_zerop (TREE_OPERAND (base, 1)))\n-\t{\n-\t  if (!host_integerp (TREE_OPERAND (base, 1), 0))\n-\t    return NULL_TREE;\n-\t  *bit_offset += (mem_ref_offset (base).low\n-\t\t\t  * BITS_PER_UNIT);\n-\t}\n-\n-      base = get_constant_value (TREE_OPERAND (base, 0));\n-      if (!base || TREE_CODE (base) != ADDR_EXPR)\n-        return NULL_TREE;\n-      base = TREE_OPERAND (base, 0);\n-    }\n-\n-  /* Get a CONSTRUCTOR.  If BASE is a VAR_DECL, get its\n-     DECL_INITIAL.  If BASE is a nested reference into another\n-     ARRAY_REF or COMPONENT_REF, make a recursive call to resolve\n-     the inner reference.  */\n-  switch (TREE_CODE (base))\n-    {\n-    case VAR_DECL:\n-      if (!const_value_known_p (base))\n-\treturn NULL_TREE;\n-\n-      /* Fallthru.  */\n-    case CONST_DECL:\n-      if (!DECL_INITIAL (base)\n-\t  && (TREE_STATIC (base) || DECL_EXTERNAL (base)))\n-        return error_mark_node;\n-      return DECL_INITIAL (base);\n-\n-    case ARRAY_REF:\n-    case COMPONENT_REF:\n-      base = get_ref_base_and_extent (base, &bit_offset2, &size, &max_size);\n-      if (max_size == -1 || size != max_size)\n-\treturn NULL_TREE;\n-      *bit_offset +=  bit_offset2;\n-      return get_base_constructor (base, bit_offset);\n-\n-    case STRING_CST:\n-    case CONSTRUCTOR:\n-      return base;\n-\n-    default:\n-      return NULL_TREE;\n-    }\n-}\n-\n-/* CTOR is STRING_CST.  Fold reference of type TYPE and size SIZE\n-   to the memory at bit OFFSET.  \n-\n-   We do only simple job of folding byte accesses.  */\n-\n-static tree\n-fold_string_cst_ctor_reference (tree type, tree ctor, unsigned HOST_WIDE_INT offset,\n-\t\t\t\tunsigned HOST_WIDE_INT size)\n-{\n-  if (INTEGRAL_TYPE_P (type)\n-      && (TYPE_MODE (type)\n-\t  == TYPE_MODE (TREE_TYPE (TREE_TYPE (ctor))))\n-      && (GET_MODE_CLASS (TYPE_MODE (TREE_TYPE (TREE_TYPE (ctor))))\n-\t  == MODE_INT)\n-      && GET_MODE_SIZE (TYPE_MODE (TREE_TYPE (TREE_TYPE (ctor)))) == 1\n-      && size == BITS_PER_UNIT\n-      && !(offset % BITS_PER_UNIT))\n-    {\n-      offset /= BITS_PER_UNIT;\n-      if (offset < (unsigned HOST_WIDE_INT) TREE_STRING_LENGTH (ctor))\n-\treturn build_int_cst_type (type, (TREE_STRING_POINTER (ctor)\n-\t\t\t\t   [offset]));\n-      /* Folding\n-\t const char a[20]=\"hello\";\n-\t return a[10];\n-\n-\t might lead to offset greater than string length.  In this case we\n-\t know value is either initialized to 0 or out of bounds.  Return 0\n-\t in both cases.  */\n-      return build_zero_cst (type);\n-    }\n-  return NULL_TREE;\n-}\n-\n-/* CTOR is CONSTRUCTOR of an array type.  Fold reference of type TYPE and size\n-   SIZE to the memory at bit OFFSET.  */\n-\n-static tree\n-fold_array_ctor_reference (tree type, tree ctor,\n-\t\t\t   unsigned HOST_WIDE_INT offset,\n-\t\t\t   unsigned HOST_WIDE_INT size)\n-{\n-  unsigned HOST_WIDE_INT cnt;\n-  tree cfield, cval;\n-  double_int low_bound, elt_size;\n-  double_int index, max_index;\n-  double_int access_index;\n-  tree domain_type = TYPE_DOMAIN (TREE_TYPE (ctor));\n-  HOST_WIDE_INT inner_offset;\n-\n-  /* Compute low bound and elt size.  */\n-  if (domain_type && TYPE_MIN_VALUE (domain_type))\n-    {\n-      /* Static constructors for variably sized objects makes no sense.  */\n-      gcc_assert (TREE_CODE (TYPE_MIN_VALUE (domain_type)) == INTEGER_CST);\n-      low_bound = tree_to_double_int (TYPE_MIN_VALUE (domain_type));\n-    }\n-  else\n-    low_bound = double_int_zero;\n-  /* Static constructors for variably sized objects makes no sense.  */\n-  gcc_assert (TREE_CODE(TYPE_SIZE_UNIT (TREE_TYPE (TREE_TYPE (ctor))))\n-\t      == INTEGER_CST);\n-  elt_size =\n-    tree_to_double_int (TYPE_SIZE_UNIT (TREE_TYPE (TREE_TYPE (ctor))));\n-\n-\n-  /* We can handle only constantly sized accesses that are known to not\n-     be larger than size of array element.  */\n-  if (!TYPE_SIZE_UNIT (type)\n-      || TREE_CODE (TYPE_SIZE_UNIT (type)) != INTEGER_CST\n-      || double_int_cmp (elt_size,\n-\t\t\t tree_to_double_int (TYPE_SIZE_UNIT (type)), 0) < 0)\n-    return NULL_TREE;\n-\n-  /* Compute the array index we look for.  */\n-  access_index = double_int_udiv (uhwi_to_double_int (offset / BITS_PER_UNIT),\n-\t\t\t\t  elt_size, TRUNC_DIV_EXPR);\n-  access_index = double_int_add (access_index, low_bound);\n-\n-  /* And offset within the access.  */\n-  inner_offset = offset % (double_int_to_uhwi (elt_size) * BITS_PER_UNIT);\n-\n-  /* See if the array field is large enough to span whole access.  We do not\n-     care to fold accesses spanning multiple array indexes.  */\n-  if (inner_offset + size > double_int_to_uhwi (elt_size) * BITS_PER_UNIT)\n-    return NULL_TREE;\n-\n-  index = double_int_sub (low_bound, double_int_one);\n-  FOR_EACH_CONSTRUCTOR_ELT (CONSTRUCTOR_ELTS (ctor), cnt, cfield, cval)\n-    {\n-      /* Array constructor might explicitely set index, or specify range\n-\t or leave index NULL meaning that it is next index after previous\n-\t one.  */\n-      if (cfield)\n-\t{\n-\t  if (TREE_CODE (cfield) == INTEGER_CST)\n-\t    max_index = index = tree_to_double_int (cfield);\n-\t  else\n-\t    {\n-\t      gcc_assert (TREE_CODE (cfield) == RANGE_EXPR);\n-\t      index = tree_to_double_int (TREE_OPERAND (cfield, 0));\n-\t      max_index = tree_to_double_int (TREE_OPERAND (cfield, 1));\n-\t    }\n-\t}\n-      else\n-\tmax_index = index = double_int_add (index, double_int_one);\n-\n-      /* Do we have match?  */\n-      if (double_int_cmp (access_index, index, 1) >= 0\n-\t  && double_int_cmp (access_index, max_index, 1) <= 0)\n-\treturn fold_ctor_reference (type, cval, inner_offset, size);\n-    }\n-  /* When memory is not explicitely mentioned in constructor,\n-     it is 0 (or out of range).  */\n-  return build_zero_cst (type);\n-}\n-\n-/* CTOR is CONSTRUCTOR of an aggregate or vector.\n-   Fold reference of type TYPE and size SIZE to the memory at bit OFFSET.  */\n-\n-static tree\n-fold_nonarray_ctor_reference (tree type, tree ctor,\n-\t\t\t      unsigned HOST_WIDE_INT offset,\n-\t\t\t      unsigned HOST_WIDE_INT size)\n-{\n-  unsigned HOST_WIDE_INT cnt;\n-  tree cfield, cval;\n-\n-  FOR_EACH_CONSTRUCTOR_ELT (CONSTRUCTOR_ELTS (ctor), cnt, cfield,\n-\t\t\t    cval)\n-    {\n-      tree byte_offset = DECL_FIELD_OFFSET (cfield);\n-      tree field_offset = DECL_FIELD_BIT_OFFSET (cfield);\n-      tree field_size = DECL_SIZE (cfield);\n-      double_int bitoffset;\n-      double_int byte_offset_cst = tree_to_double_int (byte_offset);\n-      double_int bits_per_unit_cst = uhwi_to_double_int (BITS_PER_UNIT);\n-      double_int bitoffset_end;\n-\n-      /* Variable sized objects in static constructors makes no sense,\n-\t but field_size can be NULL for flexible array members.  */\n-      gcc_assert (TREE_CODE (field_offset) == INTEGER_CST\n-\t\t  && TREE_CODE (byte_offset) == INTEGER_CST\n-\t\t  && (field_size != NULL_TREE\n-\t\t      ? TREE_CODE (field_size) == INTEGER_CST\n-\t\t      : TREE_CODE (TREE_TYPE (cfield)) == ARRAY_TYPE));\n-\n-      /* Compute bit offset of the field.  */\n-      bitoffset = double_int_add (tree_to_double_int (field_offset),\n-\t\t\t\t  double_int_mul (byte_offset_cst,\n-\t\t\t\t\t\t  bits_per_unit_cst));\n-      /* Compute bit offset where the field ends.  */\n-      if (field_size != NULL_TREE)\n-\tbitoffset_end = double_int_add (bitoffset,\n-\t\t\t\t\ttree_to_double_int (field_size));\n-      else\n-\tbitoffset_end = double_int_zero;\n-\n-      /* Is OFFSET in the range (BITOFFSET, BITOFFSET_END)? */\n-      if (double_int_cmp (uhwi_to_double_int (offset), bitoffset, 0) >= 0\n-\t  && (field_size == NULL_TREE\n-\t      || double_int_cmp (uhwi_to_double_int (offset),\n-\t\t\t\t bitoffset_end, 0) < 0))\n-\t{\n-\t  double_int access_end = double_int_add (uhwi_to_double_int (offset),\n-\t\t\t\t\t\t  uhwi_to_double_int (size));\n-\t  double_int inner_offset = double_int_sub (uhwi_to_double_int (offset),\n-\t\t\t\t\t\t    bitoffset);\n-\t  /* We do have overlap.  Now see if field is large enough to\n-\t     cover the access.  Give up for accesses spanning multiple\n-\t     fields.  */\n-\t  if (double_int_cmp (access_end, bitoffset_end, 0) > 0)\n-\t    return NULL_TREE;\n-\t  return fold_ctor_reference (type, cval,\n-\t\t\t\t      double_int_to_uhwi (inner_offset), size);\n-\t}\n-    }\n-  /* When memory is not explicitely mentioned in constructor, it is 0.  */\n-  return build_zero_cst (type);\n-}\n-\n-/* CTOR is value initializing memory, fold reference of type TYPE and size SIZE\n-   to the memory at bit OFFSET.  */\n-\n-static tree\n-fold_ctor_reference (tree type, tree ctor, unsigned HOST_WIDE_INT offset,\n-\t\t     unsigned HOST_WIDE_INT size)\n-{\n-  tree ret;\n-\n-  /* We found the field with exact match.  */\n-  if (useless_type_conversion_p (type, TREE_TYPE (ctor))\n-      && !offset)\n-    return canonicalize_constructor_val (ctor);\n-\n-  /* We are at the end of walk, see if we can view convert the\n-     result.  */\n-  if (!AGGREGATE_TYPE_P (TREE_TYPE (ctor)) && !offset\n-      /* VIEW_CONVERT_EXPR is defined only for matching sizes.  */\n-      && operand_equal_p (TYPE_SIZE (type),\n-\t\t\t  TYPE_SIZE (TREE_TYPE (ctor)), 0))\n-    {\n-      ret = canonicalize_constructor_val (ctor);\n-      ret = fold_unary (VIEW_CONVERT_EXPR, type, ret);\n-      if (ret)\n-\tSTRIP_NOPS (ret);\n-      return ret;\n-    }\n-  if (TREE_CODE (ctor) == STRING_CST)\n-    return fold_string_cst_ctor_reference (type, ctor, offset, size);\n-  if (TREE_CODE (ctor) == CONSTRUCTOR)\n-    {\n-\n-      if (TREE_CODE (TREE_TYPE (ctor)) == ARRAY_TYPE)\n-\treturn fold_array_ctor_reference (type, ctor, offset, size);\n-      else\n-\treturn fold_nonarray_ctor_reference (type, ctor, offset, size);\n-    }\n-\n-  return NULL_TREE;\n-}\n-\n-/* Return the tree representing the element referenced by T if T is an\n-   ARRAY_REF or COMPONENT_REF into constant aggregates.  Return\n-   NULL_TREE otherwise.  */\n-\n-tree\n-fold_const_aggregate_ref (tree t)\n-{\n-  tree ctor, idx, base;\n-  HOST_WIDE_INT offset, size, max_size;\n-  tree tem;\n-\n-  if (TREE_CODE_CLASS (TREE_CODE (t)) == tcc_declaration)\n-    return get_symbol_constant_value (t);\n-\n-  tem = fold_read_from_constant_string (t);\n-  if (tem)\n-    return tem;\n-\n-  switch (TREE_CODE (t))\n-    {\n-    case ARRAY_REF:\n-    case ARRAY_RANGE_REF:\n-      /* Constant indexes are handled well by get_base_constructor.\n-\t Only special case variable offsets.\n-\t FIXME: This code can't handle nested references with variable indexes\n-\t (they will be handled only by iteration of ccp).  Perhaps we can bring\n-\t get_ref_base_and_extent here and make it use get_constant_value.  */\n-      if (TREE_CODE (TREE_OPERAND (t, 1)) == SSA_NAME\n-\t  && (idx = get_constant_value (TREE_OPERAND (t, 1)))\n-\t  && host_integerp (idx, 0))\n-\t{\n-\t  tree low_bound, unit_size;\n-\n-\t  /* If the resulting bit-offset is constant, track it.  */\n-\t  if ((low_bound = array_ref_low_bound (t),\n-\t       host_integerp (low_bound, 0))\n-\t      && (unit_size = array_ref_element_size (t),\n-\t\t  host_integerp (unit_size, 1)))\n-\t    {\n-\t      offset = TREE_INT_CST_LOW (idx);\n-\t      offset -= TREE_INT_CST_LOW (low_bound);\n-\t      offset *= TREE_INT_CST_LOW (unit_size);\n-\t      offset *= BITS_PER_UNIT;\n-\n-\t      base = TREE_OPERAND (t, 0);\n-\t      ctor = get_base_constructor (base, &offset);\n-\t      /* Empty constructor.  Always fold to 0. */\n-\t      if (ctor == error_mark_node)\n-\t\treturn build_zero_cst (TREE_TYPE (t));\n-\t      /* Out of bound array access.  Value is undefined, but don't fold. */\n-\t      if (offset < 0)\n-\t\treturn NULL_TREE;\n-\t      /* We can not determine ctor.  */\n-\t      if (!ctor)\n-\t\treturn NULL_TREE;\n-\t      return fold_ctor_reference (TREE_TYPE (t), ctor, offset,\n-\t\t\t\t\t  TREE_INT_CST_LOW (unit_size)\n-\t\t\t\t\t  * BITS_PER_UNIT);\n-\t    }\n-\t}\n-      /* Fallthru.  */\n-\t\n-    case COMPONENT_REF:\n-    case BIT_FIELD_REF:\n-    case TARGET_MEM_REF:\n-    case MEM_REF:\n-      base = get_ref_base_and_extent (t, &offset, &size, &max_size);\n-      ctor = get_base_constructor (base, &offset);\n-\n-      /* Empty constructor.  Always fold to 0. */\n-      if (ctor == error_mark_node)\n-\treturn build_zero_cst (TREE_TYPE (t));\n-      /* We do not know precise address.  */\n-      if (max_size == -1 || max_size != size)\n-\treturn NULL_TREE;\n-      /* We can not determine ctor.  */\n-      if (!ctor)\n-\treturn NULL_TREE;\n-\n-      /* Out of bound array access.  Value is undefined, but don't fold. */\n-      if (offset < 0)\n-\treturn NULL_TREE;\n-\n-      return fold_ctor_reference (TREE_TYPE (t), ctor, offset, size);\n-\n-    case REALPART_EXPR:\n-    case IMAGPART_EXPR:\n-      {\n-\ttree c = fold_const_aggregate_ref (TREE_OPERAND (t, 0));\n-\tif (c && TREE_CODE (c) == COMPLEX_CST)\n-\t  return fold_build1_loc (EXPR_LOCATION (t),\n-\t\t\t      TREE_CODE (t), TREE_TYPE (t), c);\n-\tbreak;\n-      }\n+    case GIMPLE_ASSIGN:\n+    case GIMPLE_CALL:\n+      return gimple_fold_stmt_to_constant_1 (stmt, valueize_op);\n \n     default:\n-      break;\n+      gcc_unreachable ();\n     }\n-\n-  return NULL_TREE;\n }\n \n /* Apply the operation CODE in type TYPE to the value, mask pair"}, {"sha": "0a6fa9455debecd56a0aa4258550e84a7be8352c", "filename": "gcc/tree-ssa-pre.c", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree-ssa-pre.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree-ssa-pre.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-pre.c?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -4380,9 +4380,12 @@ eliminate (void)\n \t  if (is_gimple_call (stmt)\n \t      && TREE_CODE (gimple_call_fn (stmt)) == SSA_NAME)\n \t    {\n-\t      tree fn = VN_INFO (gimple_call_fn (stmt))->valnum;\n+\t      tree orig_fn = gimple_call_fn (stmt);\n+\t      tree fn = VN_INFO (orig_fn)->valnum;\n \t      if (TREE_CODE (fn) == ADDR_EXPR\n-\t\t  && TREE_CODE (TREE_OPERAND (fn, 0)) == FUNCTION_DECL)\n+\t\t  && TREE_CODE (TREE_OPERAND (fn, 0)) == FUNCTION_DECL\n+\t\t  && useless_type_conversion_p (TREE_TYPE (orig_fn),\n+\t\t\t\t\t\tTREE_TYPE (fn)))\n \t\t{\n \t\t  bool can_make_abnormal_goto\n \t\t    = stmt_can_make_abnormal_goto (stmt);"}, {"sha": "29b80ea5780c0ec88c8bc42a25a474bd13f83ad2", "filename": "gcc/tree-ssa-sccvn.c", "status": "modified", "additions": 32, "deletions": 14, "changes": 46, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree-ssa-sccvn.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree-ssa-sccvn.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-sccvn.c?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -44,6 +44,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"params.h\"\n #include \"tree-ssa-propagate.h\"\n #include \"tree-ssa-sccvn.h\"\n+#include \"gimple-fold.h\"\n \n /* This algorithm is based on the SCC algorithm presented by Keith\n    Cooper and L. Taylor Simpson in \"SCC-Based Value numbering\"\n@@ -2770,6 +2771,16 @@ simplify_binary_expression (gimple stmt)\n \top1 = SSA_VAL (op1);\n     }\n \n+  /* Pointer plus constant can be represented as invariant address.\n+     Do so to allow further propatation, see also tree forwprop.  */\n+  if (gimple_assign_rhs_code (stmt) == POINTER_PLUS_EXPR\n+      && host_integerp (op1, 1)\n+      && TREE_CODE (op0) == ADDR_EXPR\n+      && is_gimple_min_invariant (op0))\n+    return build_invariant_address (TREE_TYPE (op0),\n+\t\t\t\t    TREE_OPERAND (op0, 0),\n+\t\t\t\t    TREE_INT_CST_LOW (op1));\n+\n   /* Avoid folding if nothing changed.  */\n   if (op0 == gimple_assign_rhs1 (stmt)\n       && op1 == gimple_assign_rhs2 (stmt))\n@@ -2849,6 +2860,19 @@ simplify_unary_expression (gimple stmt)\n   return NULL_TREE;\n }\n \n+/* Valueize NAME if it is an SSA name, otherwise just return it.  */\n+\n+static inline tree\n+vn_valueize (tree name)\n+{\n+  if (TREE_CODE (name) == SSA_NAME)\n+    {\n+      tree tem = SSA_VAL (name);\n+      return tem == VN_TOP ? name : tem;\n+    }\n+  return name;\n+}\n+\n /* Try to simplify RHS using equivalences and constant folding.  */\n \n static tree\n@@ -2862,21 +2886,15 @@ try_to_simplify (gimple stmt)\n       && TREE_CODE (gimple_assign_rhs1 (stmt)) == SSA_NAME)\n     return NULL_TREE;\n \n+  /* First try constant folding based on our current lattice.  */\n+  tem = gimple_fold_stmt_to_constant (stmt, vn_valueize);\n+  if (tem)\n+    return tem;\n+\n+  /* If that didn't work try combining multiple statements.  */\n   switch (TREE_CODE_CLASS (gimple_assign_rhs_code (stmt)))\n     {\n-    case tcc_declaration:\n-      tem = get_symbol_constant_value (gimple_assign_rhs1 (stmt));\n-      if (tem)\n-\treturn tem;\n-      break;\n-\n     case tcc_reference:\n-      /* Do not do full-blown reference lookup here, but simplify\n-\t reads from constant aggregates.  */\n-      tem = fold_const_aggregate_ref (gimple_assign_rhs1 (stmt));\n-      if (tem)\n-\treturn tem;\n-\n       /* Fallthrough for some codes that can operate on registers.  */\n       if (!(TREE_CODE (gimple_assign_rhs1 (stmt)) == REALPART_EXPR\n \t    || TREE_CODE (gimple_assign_rhs1 (stmt)) == IMAGPART_EXPR\n@@ -2886,11 +2904,11 @@ try_to_simplify (gimple stmt)\n \t into binary ops, but it's debatable whether it is worth it. */\n     case tcc_unary:\n       return simplify_unary_expression (stmt);\n-      break;\n+\n     case tcc_comparison:\n     case tcc_binary:\n       return simplify_binary_expression (stmt);\n-      break;\n+\n     default:\n       break;\n     }"}, {"sha": "466c3a0f0da23a4c0783fbf9f00a63e3e8f24e1d", "filename": "gcc/tree-vrp.c", "status": "modified", "additions": 22, "deletions": 2, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree-vrp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree-vrp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vrp.c?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -39,6 +39,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-scalar-evolution.h\"\n #include \"tree-ssa-propagate.h\"\n #include \"tree-chrec.h\"\n+#include \"gimple-fold.h\"\n \n \n /* Type of value ranges.  See value_range_d for a description of these\n@@ -5614,6 +5615,21 @@ vrp_initialize (void)\n     }\n }\n \n+/* Return the singleton value-range for NAME or NAME.  */\n+\n+static inline tree\n+vrp_valueize (tree name)\n+{\n+  if (TREE_CODE (name) == SSA_NAME)\n+    {\n+      value_range_t *vr = get_value_range (name);\n+      if (vr->type == VR_RANGE\n+\t  && (vr->min == vr->max\n+\t      || operand_equal_p (vr->min, vr->max, 0)))\n+\treturn vr->min;\n+    }\n+  return name;\n+}\n \n /* Visit assignment STMT.  If it produces an interesting range, record\n    the SSA name in *OUTPUT_P.  */\n@@ -5637,7 +5653,12 @@ vrp_visit_assignment_or_call (gimple stmt, tree *output_p)\n     {\n       value_range_t new_vr = { VR_UNDEFINED, NULL_TREE, NULL_TREE, NULL };\n \n-      if (code == GIMPLE_CALL)\n+      /* Try folding the statement to a constant first.  */\n+      tree tem = gimple_fold_stmt_to_constant (stmt, vrp_valueize);\n+      if (tem && !is_overflow_infinity (tem))\n+\tset_value_range (&new_vr, VR_RANGE, tem, tem, NULL);\n+      /* Then dispatch to value-range extracting functions.  */\n+      else if (code == GIMPLE_CALL)\n \textract_range_basic (&new_vr, stmt);\n       else\n \textract_range_from_assignment (&new_vr, stmt);\n@@ -6366,7 +6387,6 @@ vrp_visit_stmt (gimple stmt, edge *taken_edge_p, tree *output_p)\n       /* In general, assignments with virtual operands are not useful\n \t for deriving ranges, with the obvious exception of calls to\n \t builtin functions.  */\n-\n       if ((is_gimple_call (stmt)\n \t   && gimple_call_fndecl (stmt) != NULL_TREE\n \t   && DECL_IS_BUILTIN (gimple_call_fndecl (stmt)))"}, {"sha": "f9e3f40d5ee51afd2276312bd429f2b1791cd749", "filename": "gcc/tree.c", "status": "modified", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.c?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -4013,6 +4013,20 @@ reference_alias_ptr_type (const_tree t)\n     return build_pointer_type (TYPE_MAIN_VARIANT (TREE_TYPE (base)));\n }\n \n+/* Return an invariant ADDR_EXPR of type TYPE taking the address of BASE\n+   offsetted by OFFSET units.  */\n+\n+tree\n+build_invariant_address (tree type, tree base, HOST_WIDE_INT offset)\n+{\n+  tree ref = fold_build2 (MEM_REF, TREE_TYPE (type),\n+\t\t\t  build_fold_addr_expr (base),\n+\t\t\t  build_int_cst (ptr_type_node, offset));\n+  tree addr = build1 (ADDR_EXPR, type, ref);\n+  recompute_tree_invariant_for_addr_expr (addr);\n+  return addr;\n+}\n+\n /* Similar except don't specify the TREE_TYPE\n    and leave the TREE_SIDE_EFFECTS as 0.\n    It is permissible for arguments to be null,"}, {"sha": "454d3287b4802923fac663cd8cce19a338afbf1e", "filename": "gcc/tree.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfef45c8097d122e7dfda42c5e2767bf21a7f649/gcc%2Ftree.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.h?ref=cfef45c8097d122e7dfda42c5e2767bf21a7f649", "patch": "@@ -5096,6 +5096,7 @@ extern tree build_simple_mem_ref_loc (location_t, tree);\n \tbuild_simple_mem_ref_loc (UNKNOWN_LOCATION, T)\n extern double_int mem_ref_offset (const_tree);\n extern tree reference_alias_ptr_type (const_tree);\n+extern tree build_invariant_address (tree, tree, HOST_WIDE_INT);\n extern tree constant_boolean_node (int, tree);\n extern tree div_if_zero_remainder (enum tree_code, const_tree, const_tree);\n "}]}