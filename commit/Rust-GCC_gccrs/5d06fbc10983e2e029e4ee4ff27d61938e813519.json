{"sha": "5d06fbc10983e2e029e4ee4ff27d61938e813519", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NWQwNmZiYzEwOTgzZTJlMDI5ZTRlZTRmZjI3ZDYxOTM4ZTgxMzUxOQ==", "commit": {"author": {"name": "Bill Schmidt", "email": "wschmidt@vnet.linux.ibm.com", "date": "2014-09-29T18:41:26Z"}, "committer": {"name": "William Schmidt", "email": "wschmidt@gcc.gnu.org", "date": "2014-09-29T18:41:26Z"}, "message": "ops.c: Remove calls to vec_splat...\n\n2014-09-29  Bill Schmidt  <wschmidt@vnet.linux.ibm.com>\n\n\t* gcc.dg/vmx/ops.c: Remove calls to vec_splat, vec_vsplth,\n\tvec_vspltw, and vec_vspltb for which the second argument is out of\n\trange.\n\nFrom-SVN: r215691", "tree": {"sha": "a6313dfe6c280abfc3069920d3e1205a15566ee1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/a6313dfe6c280abfc3069920d3e1205a15566ee1"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/5d06fbc10983e2e029e4ee4ff27d61938e813519", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5d06fbc10983e2e029e4ee4ff27d61938e813519", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5d06fbc10983e2e029e4ee4ff27d61938e813519", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5d06fbc10983e2e029e4ee4ff27d61938e813519/comments", "author": null, "committer": null, "parents": [{"sha": "d03efd2a58a0a2eda9f8ffbfd0cea59aecdffd29", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d03efd2a58a0a2eda9f8ffbfd0cea59aecdffd29", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d03efd2a58a0a2eda9f8ffbfd0cea59aecdffd29"}], "stats": {"total": 518, "additions": 6, "deletions": 512}, "files": [{"sha": "35f1a91916cc9142990ee2b4f27eab86f24926ff", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5d06fbc10983e2e029e4ee4ff27d61938e813519/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5d06fbc10983e2e029e4ee4ff27d61938e813519/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=5d06fbc10983e2e029e4ee4ff27d61938e813519", "patch": "@@ -1,3 +1,9 @@\n+2014-09-29  Bill Schmidt  <wschmidt@vnet.linux.ibm.com>\n+\n+\t* gcc.dg/vmx/ops.c: Remove calls to vec_splat, vec_vsplth,\n+\tvec_vspltw, and vec_vspltb for which the second argument is out of\n+\trange.\n+\n 2014-09-29  Chen Gang  <gang.chen.5i5j@gmail.com>\n \n \t* gcc.c-torture/compile/calls-void.c: New test."}, {"sha": "6c00e9638282552063205cf32170f86285890c8d", "filename": "gcc/testsuite/gcc.dg/vmx/ops.c", "status": "modified", "additions": 0, "deletions": 512, "changes": 512, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5d06fbc10983e2e029e4ee4ff27d61938e813519/gcc%2Ftestsuite%2Fgcc.dg%2Fvmx%2Fops.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5d06fbc10983e2e029e4ee4ff27d61938e813519/gcc%2Ftestsuite%2Fgcc.dg%2Fvmx%2Fops.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvmx%2Fops.c?ref=5d06fbc10983e2e029e4ee4ff27d61938e813519", "patch": "@@ -337,32 +337,8 @@ void f2() {\n   *var_vec_b16++ = vec_splat(var_vec_b16[0], 5);\n   *var_vec_b16++ = vec_splat(var_vec_b16[0], 6);\n   *var_vec_b16++ = vec_splat(var_vec_b16[0], 7);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 8);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 9);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 10);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 11);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 12);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 13);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 14);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 15);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 16);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 17);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 18);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 19);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 20);\n }\n void f3() {\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 21);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 22);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 23);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 24);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 25);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 26);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 27);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 28);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 29);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 30);\n-  *var_vec_b16++ = vec_splat(var_vec_b16[0], 31);\n   *var_vec_b16++ = vec_srl(var_vec_b16[0], var_vec_u16[1]);\n   *var_vec_b16++ = vec_srl(var_vec_b16[0], var_vec_u32[1]);\n   *var_vec_b16++ = vec_srl(var_vec_b16[0], var_vec_u8[1]);\n@@ -393,30 +369,6 @@ void f3() {\n   *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 5);\n   *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 6);\n   *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 7);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 8);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 9);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 10);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 11);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 12);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 13);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 14);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 15);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 16);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 17);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 18);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 19);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 20);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 21);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 22);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 23);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 24);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 25);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 26);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 27);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 28);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 29);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 30);\n-  *var_vec_b16++ = vec_vsplth(var_vec_b16[0], 31);\n   *var_vec_b16++ = vec_vsr(var_vec_b16[0], var_vec_u16[1]);\n   *var_vec_b16++ = vec_vsr(var_vec_b16[0], var_vec_u32[1]);\n   *var_vec_b16++ = vec_vsr(var_vec_b16[0], var_vec_u8[1]);\n@@ -451,36 +403,8 @@ void f3() {\n   *var_vec_b32++ = vec_splat(var_vec_b32[0], 1);\n   *var_vec_b32++ = vec_splat(var_vec_b32[0], 2);\n   *var_vec_b32++ = vec_splat(var_vec_b32[0], 3);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 4);\n }\n void f4() {\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 5);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 6);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 7);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 8);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 9);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 10);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 11);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 12);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 13);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 14);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 15);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 16);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 17);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 18);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 19);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 20);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 21);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 22);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 23);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 24);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 25);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 26);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 27);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 28);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 29);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 30);\n-  *var_vec_b32++ = vec_splat(var_vec_b32[0], 31);\n   *var_vec_b32++ = vec_srl(var_vec_b32[0], var_vec_u16[1]);\n   *var_vec_b32++ = vec_srl(var_vec_b32[0], var_vec_u32[1]);\n   *var_vec_b32++ = vec_srl(var_vec_b32[0], var_vec_u8[1]);\n@@ -509,34 +433,6 @@ void f4() {\n   *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 1);\n   *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 2);\n   *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 3);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 4);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 5);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 6);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 7);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 8);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 9);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 10);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 11);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 12);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 13);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 14);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 15);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 16);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 17);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 18);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 19);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 20);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 21);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 22);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 23);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 24);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 25);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 26);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 27);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 28);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 29);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 30);\n-  *var_vec_b32++ = vec_vspltw(var_vec_b32[0], 31);\n   *var_vec_b32++ = vec_vsr(var_vec_b32[0], var_vec_u16[1]);\n   *var_vec_b32++ = vec_vsr(var_vec_b32[0], var_vec_u32[1]);\n   *var_vec_b32++ = vec_vsr(var_vec_b32[0], var_vec_u8[1]);\n@@ -583,22 +479,6 @@ void f5() {\n   *var_vec_b8++ = vec_splat(var_vec_b8[0], 13);\n   *var_vec_b8++ = vec_splat(var_vec_b8[0], 14);\n   *var_vec_b8++ = vec_splat(var_vec_b8[0], 15);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 16);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 17);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 18);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 19);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 20);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 21);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 22);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 23);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 24);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 25);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 26);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 27);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 28);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 29);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 30);\n-  *var_vec_b8++ = vec_splat(var_vec_b8[0], 31);\n   *var_vec_b8++ = vec_srl(var_vec_b8[0], var_vec_u16[1]);\n   *var_vec_b8++ = vec_srl(var_vec_b8[0], var_vec_u32[1]);\n   *var_vec_b8++ = vec_srl(var_vec_b8[0], var_vec_u8[1]);\n@@ -635,22 +515,6 @@ void f5() {\n   *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 13);\n   *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 14);\n   *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 15);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 16);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 17);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 18);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 19);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 20);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 21);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 22);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 23);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 24);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 25);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 26);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 27);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 28);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 29);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 30);\n-  *var_vec_b8++ = vec_vspltb(var_vec_b8[0], 31);\n   *var_vec_b8++ = vec_vsr(var_vec_b8[0], var_vec_u16[1]);\n   *var_vec_b8++ = vec_vsr(var_vec_b8[0], var_vec_u32[1]);\n   *var_vec_b8++ = vec_vsr(var_vec_b8[0], var_vec_u8[1]);\n@@ -783,34 +647,6 @@ void f7() {\n   *var_vec_f32++ = vec_splat(var_vec_f32[0], 1);\n   *var_vec_f32++ = vec_splat(var_vec_f32[0], 2);\n   *var_vec_f32++ = vec_splat(var_vec_f32[0], 3);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 4);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 5);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 6);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 7);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 8);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 9);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 10);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 11);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 12);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 13);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 14);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 15);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 16);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 17);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 18);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 19);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 20);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 21);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 22);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 23);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 24);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 25);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 26);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 27);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 28);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 29);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 30);\n-  *var_vec_f32++ = vec_splat(var_vec_f32[0], 31);\n   *var_vec_f32++ = vec_sro(var_vec_f32[0], var_vec_s8[1]);\n   *var_vec_f32++ = vec_sro(var_vec_f32[0], var_vec_u8[1]);\n   *var_vec_f32++ = vec_sub(var_vec_f32[0], var_vec_f32[1]);\n@@ -931,34 +767,6 @@ void f8() {\n   *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 1);\n   *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 2);\n   *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 3);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 4);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 5);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 6);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 7);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 8);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 9);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 10);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 11);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 12);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 13);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 14);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 15);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 16);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 17);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 18);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 19);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 20);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 21);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 22);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 23);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 24);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 25);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 26);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 27);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 28);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 29);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 30);\n-  *var_vec_f32++ = vec_vspltw(var_vec_f32[0], 31);\n   *var_vec_f32++ = vec_vsro(var_vec_f32[0], var_vec_s8[1]);\n   *var_vec_f32++ = vec_vsro(var_vec_f32[0], var_vec_u8[1]);\n   *var_vec_f32++ = vec_vsubfp(var_vec_f32[0], var_vec_f32[1]);\n@@ -1007,30 +815,6 @@ void f9() {\n   *var_vec_p16++ = vec_splat(var_vec_p16[0], 5);\n   *var_vec_p16++ = vec_splat(var_vec_p16[0], 6);\n   *var_vec_p16++ = vec_splat(var_vec_p16[0], 7);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 8);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 9);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 10);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 11);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 12);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 13);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 14);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 15);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 16);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 17);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 18);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 19);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 20);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 21);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 22);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 23);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 24);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 25);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 26);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 27);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 28);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 29);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 30);\n-  *var_vec_p16++ = vec_splat(var_vec_p16[0], 31);\n   *var_vec_p16++ = vec_srl(var_vec_p16[0], var_vec_u16[1]);\n   *var_vec_p16++ = vec_srl(var_vec_p16[0], var_vec_u32[1]);\n   *var_vec_p16++ = vec_srl(var_vec_p16[0], var_vec_u8[1]);\n@@ -1071,30 +855,6 @@ void f10() {\n   *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 5);\n   *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 6);\n   *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 7);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 8);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 9);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 10);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 11);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 12);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 13);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 14);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 15);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 16);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 17);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 18);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 19);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 20);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 21);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 22);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 23);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 24);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 25);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 26);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 27);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 28);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 29);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 30);\n-  *var_vec_p16++ = vec_vsplth(var_vec_p16[0], 31);\n   *var_vec_p16++ = vec_vsr(var_vec_p16[0], var_vec_u16[1]);\n   *var_vec_p16++ = vec_vsr(var_vec_p16[0], var_vec_u32[1]);\n   *var_vec_p16++ = vec_vsr(var_vec_p16[0], var_vec_u8[1]);\n@@ -1180,30 +940,6 @@ void f11() {\n   *var_vec_s16++ = vec_splat(var_vec_s16[0], 5);\n   *var_vec_s16++ = vec_splat(var_vec_s16[0], 6);\n   *var_vec_s16++ = vec_splat(var_vec_s16[0], 7);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 8);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 9);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 10);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 11);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 12);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 13);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 14);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 15);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 16);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 17);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 18);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 19);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 20);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 21);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 22);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 23);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 24);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 25);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 26);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 27);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 28);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 29);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 30);\n-  *var_vec_s16++ = vec_splat(var_vec_s16[0], 31);\n   *var_vec_s16++ = vec_splat_s16( 0);\n   *var_vec_s16++ = vec_splat_s16( 1);\n   *var_vec_s16++ = vec_splat_s16( 2);\n@@ -1321,30 +1057,6 @@ void f12() {\n   *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 5);\n   *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 6);\n   *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 7);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 8);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 9);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 10);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 11);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 12);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 13);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 14);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 15);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 16);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 17);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 18);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 19);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 20);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 21);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 22);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 23);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 24);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 25);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 26);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 27);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 28);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 29);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 30);\n-  *var_vec_s16++ = vec_vsplth(var_vec_s16[0], 31);\n   *var_vec_s16++ = vec_vspltish( 0);\n   *var_vec_s16++ = vec_vspltish( 1);\n   *var_vec_s16++ = vec_vspltish( 2);\n@@ -1505,34 +1217,6 @@ void f14() {\n   *var_vec_s32++ = vec_splat(var_vec_s32[0], 1);\n   *var_vec_s32++ = vec_splat(var_vec_s32[0], 2);\n   *var_vec_s32++ = vec_splat(var_vec_s32[0], 3);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 4);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 5);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 6);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 7);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 8);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 9);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 10);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 11);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 12);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 13);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 14);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 15);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 16);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 17);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 18);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 19);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 20);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 21);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 22);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 23);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 24);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 25);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 26);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 27);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 28);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 29);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 30);\n-  *var_vec_s32++ = vec_splat(var_vec_s32[0], 31);\n   *var_vec_s32++ = vec_splat_s32( 0);\n   *var_vec_s32++ = vec_splat_s32( 1);\n   *var_vec_s32++ = vec_splat_s32( 2);\n@@ -1713,34 +1397,6 @@ void f16() {\n   *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 1);\n   *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 2);\n   *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 3);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 4);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 5);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 6);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 7);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 8);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 9);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 10);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 11);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 12);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 13);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 14);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 15);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 16);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 17);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 18);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 19);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 20);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 21);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 22);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 23);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 24);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 25);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 26);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 27);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 28);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 29);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 30);\n-  *var_vec_s32++ = vec_vspltw(var_vec_s32[0], 31);\n   *var_vec_s32++ = vec_vsr(var_vec_s32[0], var_vec_u16[1]);\n   *var_vec_s32++ = vec_vsr(var_vec_s32[0], var_vec_u32[1]);\n   *var_vec_s32++ = vec_vsr(var_vec_s32[0], var_vec_u8[1]);\n@@ -1847,22 +1503,6 @@ void f17() {\n   *var_vec_s8++ = vec_splat(var_vec_s8[0], 13);\n   *var_vec_s8++ = vec_splat(var_vec_s8[0], 14);\n   *var_vec_s8++ = vec_splat(var_vec_s8[0], 15);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 16);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 17);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 18);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 19);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 20);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 21);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 22);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 23);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 24);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 25);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 26);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 27);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 28);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 29);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 30);\n-  *var_vec_s8++ = vec_splat(var_vec_s8[0], 31);\n   *var_vec_s8++ = vec_splat_s8( 0);\n   *var_vec_s8++ = vec_splat_s8( 1);\n   *var_vec_s8++ = vec_splat_s8( 2);\n@@ -1981,22 +1621,6 @@ void f19() {\n   *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 13);\n   *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 14);\n   *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 15);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 16);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 17);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 18);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 19);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 20);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 21);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 22);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 23);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 24);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 25);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 26);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 27);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 28);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 29);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 30);\n-  *var_vec_s8++ = vec_vspltb(var_vec_s8[0], 31);\n   *var_vec_s8++ = vec_vspltisb( 0);\n   *var_vec_s8++ = vec_vspltisb( 1);\n   *var_vec_s8++ = vec_vspltisb( 2);\n@@ -2126,30 +1750,6 @@ void f20() {\n   *var_vec_u16++ = vec_splat(var_vec_u16[0], 5);\n   *var_vec_u16++ = vec_splat(var_vec_u16[0], 6);\n   *var_vec_u16++ = vec_splat(var_vec_u16[0], 7);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 8);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 9);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 10);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 11);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 12);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 13);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 14);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 15);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 16);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 17);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 18);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 19);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 20);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 21);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 22);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 23);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 24);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 25);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 26);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 27);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 28);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 29);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 30);\n-  *var_vec_u16++ = vec_splat(var_vec_u16[0], 31);\n   *var_vec_u16++ = vec_splat_u16( 0);\n   *var_vec_u16++ = vec_splat_u16( 1);\n   *var_vec_u16++ = vec_splat_u16( 2);\n@@ -2262,32 +1862,8 @@ void f21() {\n   *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 5);\n   *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 6);\n   *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 7);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 8);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 9);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 10);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 11);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 12);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 13);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 14);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 15);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 16);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 17);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 18);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 19);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 20);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 21);\n }\n void f22() {\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 22);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 23);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 24);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 25);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 26);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 27);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 28);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 29);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 30);\n-  *var_vec_u16++ = vec_vsplth(var_vec_u16[0], 31);\n   *var_vec_u16++ = vec_vsr(var_vec_u16[0], var_vec_u16[1]);\n   *var_vec_u16++ = vec_vsr(var_vec_u16[0], var_vec_u32[1]);\n   *var_vec_u16++ = vec_vsr(var_vec_u16[0], var_vec_u8[1]);\n@@ -2412,34 +1988,6 @@ void f23() {\n   *var_vec_u32++ = vec_splat(var_vec_u32[0], 1);\n   *var_vec_u32++ = vec_splat(var_vec_u32[0], 2);\n   *var_vec_u32++ = vec_splat(var_vec_u32[0], 3);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 4);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 5);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 6);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 7);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 8);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 9);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 10);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 11);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 12);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 13);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 14);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 15);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 16);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 17);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 18);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 19);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 20);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 21);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 22);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 23);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 24);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 25);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 26);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 27);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 28);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 29);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 30);\n-  *var_vec_u32++ = vec_splat(var_vec_u32[0], 31);\n   *var_vec_u32++ = vec_splat_u32( 0);\n   *var_vec_u32++ = vec_splat_u32( 1);\n   *var_vec_u32++ = vec_splat_u32( 2);\n@@ -2586,34 +2134,6 @@ void f25() {\n   *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 1);\n   *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 2);\n   *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 3);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 4);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 5);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 6);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 7);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 8);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 9);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 10);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 11);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 12);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 13);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 14);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 15);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 16);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 17);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 18);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 19);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 20);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 21);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 22);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 23);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 24);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 25);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 26);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 27);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 28);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 29);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 30);\n-  *var_vec_u32++ = vec_vspltw(var_vec_u32[0], 31);\n   *var_vec_u32++ = vec_vsr(var_vec_u32[0], var_vec_u16[1]);\n   *var_vec_u32++ = vec_vsr(var_vec_u32[0], var_vec_u32[1]);\n   *var_vec_u32++ = vec_vsr(var_vec_u32[0], var_vec_u8[1]);\n@@ -2734,22 +2254,6 @@ void f26() {\n   *var_vec_u8++ = vec_splat(var_vec_u8[0], 13);\n   *var_vec_u8++ = vec_splat(var_vec_u8[0], 14);\n   *var_vec_u8++ = vec_splat(var_vec_u8[0], 15);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 16);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 17);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 18);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 19);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 20);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 21);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 22);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 23);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 24);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 25);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 26);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 27);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 28);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 29);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 30);\n-  *var_vec_u8++ = vec_splat(var_vec_u8[0], 31);\n   *var_vec_u8++ = vec_splat_u8( 0);\n   *var_vec_u8++ = vec_splat_u8( 1);\n   *var_vec_u8++ = vec_splat_u8( 2);\n@@ -2867,24 +2371,8 @@ void f27() {\n   *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 13);\n   *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 14);\n   *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 15);\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 16);\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 17);\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 18);\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 19);\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 20);\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 21);\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 22);\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 23);\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 24);\n }\n void f28() {\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 25);\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 26);\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 27);\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 28);\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 29);\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 30);\n-  *var_vec_u8++ = vec_vspltb(var_vec_u8[0], 31);\n   *var_vec_u8++ = vec_vsr(var_vec_u8[0], var_vec_u16[1]);\n   *var_vec_u8++ = vec_vsr(var_vec_u8[0], var_vec_u32[1]);\n   *var_vec_u8++ = vec_vsr(var_vec_u8[0], var_vec_u8[1]);"}]}