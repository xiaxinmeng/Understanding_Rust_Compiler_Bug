{"sha": "126ed72b9f48f8530b194532cc281fb761690435", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MTI2ZWQ3MmI5ZjQ4Zjg1MzBiMTk0NTMyY2MyODFmYjc2MTY5MDQzNQ==", "commit": {"author": {"name": "Richard Biener", "email": "rguenther@suse.de", "date": "2020-09-30T15:08:01Z"}, "committer": {"name": "Richard Biener", "email": "rguenther@suse.de", "date": "2020-10-12T13:44:52Z"}, "message": "optimize permutes in SLP, remove vect_attempt_slp_rearrange_stmts\n\nThis introduces a permute optimization phase for SLP which is\nintended to cover the existing permute eliding for SLP reductions\nplus handling commonizing the easy cases.\n\nIt currently uses graphds to compute a postorder on the reverse\nSLP graph and it handles all cases vect_attempt_slp_rearrange_stmts\ndid (hopefully - I've adjusted most testcases that triggered it\na few days ago).  It restricts itself to move around bijective\npermutations to simplify things for now, mainly around constant nodes.\n\nAs a prerequesite it makes the SLP graph cyclic (ugh).  It looks\nlike it would pay off to compute a PRE/POST order visit array\nonce and elide all the recursive SLP graph walks and their\nvisited hash-set.  At least for the time where we do not change\nthe SLP graph during such walk.\n\nI do not like using graphds too much but at least I don't have to\nre-implement yet another RPO walk, so maybe it isn't too bad.\n\nIt now computes permute placement during iteration and thus should\nget cycles more obviously correct.\n\nRichard.\n\n2020-10-06  Richard Biener  <rguenther@suse.de>\n\n\t* tree-vect-data-refs.c (vect_slp_analyze_instance_dependence):\n\tUse SLP_TREE_REPRESENTATIVE.\n\t* tree-vectorizer.h (_slp_tree::vertex): New member used\n\tfor graphds interfacing.\n\t* tree-vect-slp.c (vect_build_slp_tree_2): Allocate space\n\tfor PHI SLP children.\n\t(vect_analyze_slp_backedges): New function filling in SLP\n\tnode children for PHIs that correspond to backedge values.\n\t(vect_analyze_slp): Call vect_analyze_slp_backedges for the\n\tgraph.\n\t(vect_slp_analyze_node_operations): Deal with a cyclic graph.\n\t(vect_schedule_slp_instance): Likewise.\n\t(vect_schedule_slp): Likewise.\n\t(slp_copy_subtree): Remove.\n\t(vect_slp_rearrange_stmts): Likewise.\n\t(vect_attempt_slp_rearrange_stmts): Likewise.\n\t(vect_slp_build_vertices): New functions.\n\t(vect_slp_permute): Likewise.\n\t(vect_slp_perms_eq): Likewise.\n\t(vect_optimize_slp): Remove special code to elide\n\tpermutations with SLP reductions.  Implement generic\n\tpermute optimization.\n\n\t* gcc.dg/vect/bb-slp-50.c: New testcase.\n\t* gcc.dg/vect/bb-slp-51.c: Likewise.", "tree": {"sha": "8175b5cce94f1511c509010df8de015af8e4499f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/8175b5cce94f1511c509010df8de015af8e4499f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/126ed72b9f48f8530b194532cc281fb761690435", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/126ed72b9f48f8530b194532cc281fb761690435", "html_url": "https://github.com/Rust-GCC/gccrs/commit/126ed72b9f48f8530b194532cc281fb761690435", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/126ed72b9f48f8530b194532cc281fb761690435/comments", "author": {"login": "rguenth", "id": 2046526, "node_id": "MDQ6VXNlcjIwNDY1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/2046526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rguenth", "html_url": "https://github.com/rguenth", "followers_url": "https://api.github.com/users/rguenth/followers", "following_url": "https://api.github.com/users/rguenth/following{/other_user}", "gists_url": "https://api.github.com/users/rguenth/gists{/gist_id}", "starred_url": "https://api.github.com/users/rguenth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rguenth/subscriptions", "organizations_url": "https://api.github.com/users/rguenth/orgs", "repos_url": "https://api.github.com/users/rguenth/repos", "events_url": "https://api.github.com/users/rguenth/events{/privacy}", "received_events_url": "https://api.github.com/users/rguenth/received_events", "type": "User", "site_admin": false}, "committer": {"login": "rguenth", "id": 2046526, "node_id": "MDQ6VXNlcjIwNDY1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/2046526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rguenth", "html_url": "https://github.com/rguenth", "followers_url": "https://api.github.com/users/rguenth/followers", "following_url": "https://api.github.com/users/rguenth/following{/other_user}", "gists_url": "https://api.github.com/users/rguenth/gists{/gist_id}", "starred_url": "https://api.github.com/users/rguenth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rguenth/subscriptions", "organizations_url": "https://api.github.com/users/rguenth/orgs", "repos_url": "https://api.github.com/users/rguenth/repos", "events_url": "https://api.github.com/users/rguenth/events{/privacy}", "received_events_url": "https://api.github.com/users/rguenth/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7e7352b2ad089ea68d689f3b79d93e3ee26326f7", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7e7352b2ad089ea68d689f3b79d93e3ee26326f7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/7e7352b2ad089ea68d689f3b79d93e3ee26326f7"}], "stats": {"total": 729, "additions": 503, "deletions": 226}, "files": [{"sha": "80216be4ebf397d5aeda793551da0c5ea4733855", "filename": "gcc/testsuite/gcc.dg/vect/bb-slp-50.c", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/126ed72b9f48f8530b194532cc281fb761690435/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fbb-slp-50.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/126ed72b9f48f8530b194532cc281fb761690435/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fbb-slp-50.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fbb-slp-50.c?ref=126ed72b9f48f8530b194532cc281fb761690435", "patch": "@@ -0,0 +1,20 @@\n+/* { dg-do compile } */\n+/* { dg-require-effective-target vect_double } */\n+\n+double a[2];\n+double b[2];\n+double c[2];\n+double d[2];\n+double e[2];\n+void foo(double x)\n+{\n+  double tembc0 = b[1] + c[1];\n+  double tembc1 = b[0] + c[0];\n+  double temde0 = d[0] + e[1];\n+  double temde1 = d[1] + e[0];\n+  a[0] = tembc0 + temde0;\n+  a[1] = tembc1 + temde1;\n+}\n+\n+/* We should common the permutation on the tembc{0,1} operands.  */\n+/* { dg-final { scan-tree-dump-times \"add new stmt: \\[^\\\\n\\\\r\\]* = VEC_PERM_EXPR\" 2 \"slp2\" } } */"}, {"sha": "1481018428e8a0dbe82f88f2f180085af5c2215e", "filename": "gcc/testsuite/gcc.dg/vect/bb-slp-51.c", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/126ed72b9f48f8530b194532cc281fb761690435/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fbb-slp-51.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/126ed72b9f48f8530b194532cc281fb761690435/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fbb-slp-51.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fbb-slp-51.c?ref=126ed72b9f48f8530b194532cc281fb761690435", "patch": "@@ -0,0 +1,20 @@\n+/* { dg-do compile } */\n+/* { dg-require-effective-target vect_double } */\n+\n+double a[2];\n+double b[2];\n+double c[2];\n+double e[2];\n+void foo(double x)\n+{\n+  double tembc0 = b[1] + c[1];\n+  double tembc1 = b[0] + c[0];\n+  double temde0 = 5 + e[1];\n+  double temde1 = 11 + e[0];\n+  a[0] = tembc0 + temde0;\n+  a[1] = tembc1 + temde1;\n+}\n+\n+/* We should common the permutations on the tembc{0,1} and temde{0,1}\n+   operands.  */\n+/* { dg-final { scan-tree-dump-times \"add new stmt: \\[^\\\\r\\\\n\\]* VEC_PERM_EXPR\" 1 \"slp2\" } } */"}, {"sha": "3ff3088641ab2b0bb3ca08e5ace4a8214ddef925", "filename": "gcc/tree-vect-data-refs.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/126ed72b9f48f8530b194532cc281fb761690435/gcc%2Ftree-vect-data-refs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/126ed72b9f48f8530b194532cc281fb761690435/gcc%2Ftree-vect-data-refs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-data-refs.c?ref=126ed72b9f48f8530b194532cc281fb761690435", "patch": "@@ -841,7 +841,7 @@ vect_slp_analyze_instance_dependence (vec_info *vinfo, slp_instance instance)\n \n   /* The stores of this instance are at the root of the SLP tree.  */\n   slp_tree store = SLP_INSTANCE_TREE (instance);\n-  if (! STMT_VINFO_DATA_REF (SLP_TREE_SCALAR_STMTS (store)[0]))\n+  if (! STMT_VINFO_DATA_REF (SLP_TREE_REPRESENTATIVE (store)))\n     store = NULL;\n \n   /* Verify we can sink stores to the vectorized stmt insert location.  */"}, {"sha": "ff0ecda801bee3dde908b63bc2547af5dde7f6d5", "filename": "gcc/tree-vect-slp.c", "status": "modified", "additions": 460, "deletions": 225, "changes": 685, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/126ed72b9f48f8530b194532cc281fb761690435/gcc%2Ftree-vect-slp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/126ed72b9f48f8530b194532cc281fb761690435/gcc%2Ftree-vect-slp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-slp.c?ref=126ed72b9f48f8530b194532cc281fb761690435", "patch": "@@ -1256,8 +1256,8 @@ vect_build_slp_tree_2 (vec_info *vinfo,\n       if (gimple_assign_rhs_code (stmt) == COND_EXPR)\n \tnops++;\n     }\n-  else if (is_a <gphi *> (stmt_info->stmt))\n-    nops = 0;\n+  else if (gphi *phi = dyn_cast <gphi *> (stmt_info->stmt))\n+    nops = gimple_phi_num_args (phi);\n   else\n     return NULL;\n \n@@ -1294,7 +1294,7 @@ vect_build_slp_tree_2 (vec_info *vinfo,\n       else\n \treturn NULL;\n       (*tree_size)++;\n-      node = vect_create_new_slp_node (stmts, 0);\n+      node = vect_create_new_slp_node (stmts, nops);\n       SLP_TREE_VECTYPE (node) = vectype;\n       return node;\n     }\n@@ -1812,188 +1812,6 @@ vect_mark_slp_stmts_relevant (slp_tree node)\n   vect_mark_slp_stmts_relevant (node, visited);\n }\n \n-/* Copy the SLP subtree rooted at NODE.  */\n-\n-static slp_tree\n-slp_copy_subtree (slp_tree node, hash_map<slp_tree, slp_tree> &map)\n-{\n-  unsigned i;\n-\n-  bool existed_p;\n-  slp_tree &copy_ref = map.get_or_insert (node, &existed_p);\n-  if (existed_p)\n-    return copy_ref;\n-\n-  copy_ref = new _slp_tree;\n-  slp_tree copy = copy_ref;\n-  SLP_TREE_DEF_TYPE (copy) = SLP_TREE_DEF_TYPE (node);\n-  SLP_TREE_VECTYPE (copy) = SLP_TREE_VECTYPE (node);\n-  SLP_TREE_REPRESENTATIVE (copy) = SLP_TREE_REPRESENTATIVE (node);\n-  SLP_TREE_LANES (copy) = SLP_TREE_LANES (node);\n-  copy->max_nunits = node->max_nunits;\n-  SLP_TREE_REF_COUNT (copy) = 0;\n-  if (SLP_TREE_SCALAR_STMTS (node).exists ())\n-    SLP_TREE_SCALAR_STMTS (copy) = SLP_TREE_SCALAR_STMTS (node).copy ();\n-  if (SLP_TREE_SCALAR_OPS (node).exists ())\n-    SLP_TREE_SCALAR_OPS (copy) = SLP_TREE_SCALAR_OPS (node).copy ();\n-  if (SLP_TREE_LOAD_PERMUTATION (node).exists ())\n-    SLP_TREE_LOAD_PERMUTATION (copy) = SLP_TREE_LOAD_PERMUTATION (node).copy ();\n-  if (SLP_TREE_LANE_PERMUTATION (node).exists ())\n-    SLP_TREE_LANE_PERMUTATION (copy) = SLP_TREE_LANE_PERMUTATION (node).copy ();\n-  if (SLP_TREE_CHILDREN (node).exists ())\n-    SLP_TREE_CHILDREN (copy) = SLP_TREE_CHILDREN (node).copy ();\n-  gcc_assert (!SLP_TREE_VEC_STMTS (node).exists ());\n-\n-  slp_tree child;\n-  FOR_EACH_VEC_ELT (SLP_TREE_CHILDREN (copy), i, child)\n-    {\n-      SLP_TREE_CHILDREN (copy)[i] = slp_copy_subtree (child, map);\n-      SLP_TREE_REF_COUNT (SLP_TREE_CHILDREN (copy)[i])++;\n-    }\n-  return copy;\n-}\n-\n-/* Rearrange the statements of NODE according to PERMUTATION.  */\n-\n-static void\n-vect_slp_rearrange_stmts (slp_tree node, unsigned int group_size,\n-                          vec<unsigned> permutation,\n-\t\t\t  hash_set<slp_tree> &visited)\n-{\n-  unsigned int i;\n-  slp_tree child;\n-\n-  if (visited.add (node))\n-    return;\n-\n-  FOR_EACH_VEC_ELT (SLP_TREE_CHILDREN (node), i, child)\n-    vect_slp_rearrange_stmts (child, group_size, permutation, visited);\n-\n-  if (SLP_TREE_SCALAR_STMTS (node).exists ())\n-    {\n-      gcc_assert (group_size == SLP_TREE_SCALAR_STMTS (node).length ());\n-      vec<stmt_vec_info> tmp_stmts;\n-      tmp_stmts.create (group_size);\n-      tmp_stmts.quick_grow (group_size);\n-      stmt_vec_info stmt_info;\n-      FOR_EACH_VEC_ELT (SLP_TREE_SCALAR_STMTS (node), i, stmt_info)\n-\ttmp_stmts[permutation[i]] = stmt_info;\n-      SLP_TREE_SCALAR_STMTS (node).release ();\n-      SLP_TREE_SCALAR_STMTS (node) = tmp_stmts;\n-    }\n-  if (SLP_TREE_SCALAR_OPS (node).exists ())\n-    {\n-      gcc_assert (group_size == SLP_TREE_SCALAR_OPS (node).length ());\n-      vec<tree> tmp_ops;\n-      tmp_ops.create (group_size);\n-      tmp_ops.quick_grow (group_size);\n-      tree op;\n-      FOR_EACH_VEC_ELT (SLP_TREE_SCALAR_OPS (node), i, op)\n-\ttmp_ops[permutation[i]] = op;\n-      SLP_TREE_SCALAR_OPS (node).release ();\n-      SLP_TREE_SCALAR_OPS (node) = tmp_ops;\n-    }\n-  if (SLP_TREE_LANE_PERMUTATION (node).exists ())\n-    {\n-      gcc_assert (group_size == SLP_TREE_LANE_PERMUTATION (node).length ());\n-      for (i = 0; i < group_size; ++i)\n-\tSLP_TREE_LANE_PERMUTATION (node)[i].second\n-\t  = permutation[SLP_TREE_LANE_PERMUTATION (node)[i].second];\n-    }\n-}\n-\n-\n-/* Attempt to reorder stmts in a reduction chain so that we don't\n-   require any load permutation.  Return true if that was possible,\n-   otherwise return false.  */\n-\n-static bool\n-vect_attempt_slp_rearrange_stmts (slp_instance slp_instn)\n-{\n-  unsigned int i, j;\n-  unsigned int lidx;\n-  slp_tree node, load;\n-\n-  if (SLP_INSTANCE_LOADS (slp_instn).is_empty ())\n-    return false;\n-\n-  /* Compare all the permutation sequences to the first one.  We know\n-     that at least one load is permuted.  */\n-  node = SLP_INSTANCE_LOADS (slp_instn)[0];\n-  if (!SLP_TREE_LOAD_PERMUTATION (node).exists ())\n-    return false;\n-  unsigned int group_size = SLP_TREE_LOAD_PERMUTATION (node).length ();\n-  for (i = 1; SLP_INSTANCE_LOADS (slp_instn).iterate (i, &load); ++i)\n-    {\n-      if (!SLP_TREE_LOAD_PERMUTATION (load).exists ()\n-\t  || SLP_TREE_LOAD_PERMUTATION (load).length () != group_size)\n-\treturn false;\n-      FOR_EACH_VEC_ELT (SLP_TREE_LOAD_PERMUTATION (load), j, lidx)\n-\tif (lidx != SLP_TREE_LOAD_PERMUTATION (node)[j])\n-\t  return false;\n-    }\n-\n-  /* Check that the loads in the first sequence are different and there\n-     are no gaps between them and that there is an actual permutation.  */\n-  bool any_permute = false;\n-  auto_sbitmap load_index (group_size);\n-  bitmap_clear (load_index);\n-  FOR_EACH_VEC_ELT (node->load_permutation, i, lidx)\n-    {\n-      if (lidx != i)\n-\tany_permute = true;\n-      if (lidx >= group_size)\n-\treturn false;\n-      if (bitmap_bit_p (load_index, lidx))\n-\treturn false;\n-\n-      bitmap_set_bit (load_index, lidx);\n-    }\n-  if (!any_permute)\n-    return false;\n-  for (i = 0; i < group_size; i++)\n-    if (!bitmap_bit_p (load_index, i))\n-      return false;\n-\n-  /* This permutation is valid for reduction.  Since the order of the\n-     statements in the nodes is not important unless they are memory\n-     accesses, we can rearrange the statements in all the nodes\n-     according to the order of the loads.  */\n-\n-  /* We have to unshare the SLP tree we modify.  */\n-  hash_map<slp_tree, slp_tree> map;\n-  slp_tree unshared = slp_copy_subtree (SLP_INSTANCE_TREE (slp_instn), map);\n-  vect_free_slp_tree (SLP_INSTANCE_TREE (slp_instn));\n-  SLP_TREE_REF_COUNT (unshared)++;\n-  SLP_INSTANCE_TREE (slp_instn) = unshared;\n-  FOR_EACH_VEC_ELT (SLP_INSTANCE_LOADS (slp_instn), i, node)\n-    SLP_INSTANCE_LOADS (slp_instn)[i] = *map.get (node);\n-  node = SLP_INSTANCE_LOADS (slp_instn)[0];\n-\n-  /* Do the actual re-arrangement.  */\n-  hash_set<slp_tree> visited;\n-  vect_slp_rearrange_stmts (SLP_INSTANCE_TREE (slp_instn), group_size,\n-\t\t\t    node->load_permutation, visited);\n-\n-  /* We are done, no actual permutations need to be generated.  */\n-  poly_uint64 unrolling_factor = SLP_INSTANCE_UNROLLING_FACTOR (slp_instn);\n-  FOR_EACH_VEC_ELT (SLP_INSTANCE_LOADS (slp_instn), i, node)\n-    {\n-      stmt_vec_info first_stmt_info = SLP_TREE_SCALAR_STMTS (node)[0];\n-      first_stmt_info = DR_GROUP_FIRST_ELEMENT (first_stmt_info);\n-      /* But we have to keep those permutations that are required because\n-         of handling of gaps.  */\n-      if (known_eq (unrolling_factor, 1U)\n-\t  || (group_size == DR_GROUP_SIZE (first_stmt_info)\n-\t      && DR_GROUP_GAP (first_stmt_info) == 0))\n-\tSLP_TREE_LOAD_PERMUTATION (node).release ();\n-      else\n-\tfor (j = 0; j < SLP_TREE_LOAD_PERMUTATION (node).length (); ++j)\n-\t  SLP_TREE_LOAD_PERMUTATION (node)[j] = j;\n-    }\n-\n-  return true;\n-}\n \n /* Gather loads in the SLP graph NODE and populate the INST loads array.  */\n \n@@ -2458,6 +2276,53 @@ vect_analyze_slp_instance (vec_info *vinfo,\n   return false;\n }\n \n+/* Fill in backedge SLP children in the SLP graph.  */\n+\n+static void\n+vect_analyze_slp_backedges (vec_info *vinfo, slp_tree node,\n+\t\t\t    scalar_stmts_to_slp_tree_map_t *bst_map,\n+\t\t\t    hash_set<slp_tree> &visited)\n+{\n+  if (SLP_TREE_DEF_TYPE (node) != vect_internal_def\n+      || visited.add (node))\n+    return;\n+\n+  slp_tree child;\n+  unsigned i;\n+  FOR_EACH_VEC_ELT (SLP_TREE_CHILDREN (node), i, child)\n+    if (child)\n+      vect_analyze_slp_backedges (vinfo, child, bst_map, visited);\n+\n+  if (gphi *phi = dyn_cast <gphi *> (SLP_TREE_REPRESENTATIVE (node)->stmt))\n+    for (unsigned i = 0; i < gimple_phi_num_args (phi); ++i)\n+      {\n+\tauto_vec<stmt_vec_info, 64> stmts;\n+\tunsigned j;\n+\tstmt_vec_info phi_info;\n+\tFOR_EACH_VEC_ELT (SLP_TREE_SCALAR_STMTS (node), j, phi_info)\n+\t  {\n+\t    tree def = gimple_phi_arg_def (as_a <gphi *>(phi_info->stmt), i);\n+\t    stmt_vec_info def_info = vinfo->lookup_def (def);\n+\t    if (!def_info)\n+\t      break;\n+\t    stmts.safe_push (vect_stmt_to_vectorize (def_info));\n+\t  }\n+\tif (j != SLP_TREE_LANES (node))\n+\t  continue;\n+\tslp_tree *edge_def = bst_map->get (stmts);\n+\tif (edge_def)\n+\t  {\n+\t    /* ???  We're currently not recording non-backedge children\n+\t       of PHIs like external reduction initial values.  Avoid\n+\t       NULL entries in SLP_TREE_CHILDREN for those and thus\n+\t       for now simply only record backedge defs at a\n+\t       SLP_TREE_CHILDREN index possibly not matching that of\n+\t       the corresponding PHI argument index.  */\n+\t    SLP_TREE_CHILDREN (node).quick_push (*edge_def);\n+\t    (*edge_def)->refcnt++;\n+\t  }\n+      }\n+}\n \n /* Check if there are stmts in the loop can be vectorized using SLP.  Build SLP\n    trees of packed scalar stmts if SLP is possible.  */\n@@ -2509,6 +2374,13 @@ vect_analyze_slp (vec_info *vinfo, unsigned max_tree_size)\n \t\t\t\t   max_tree_size);\n     }\n \n+  /* Fill in backedges.  */\n+  slp_instance instance;\n+  hash_set<slp_tree> visited;\n+  FOR_EACH_VEC_ELT (vinfo->slp_instances, i, instance)\n+    vect_analyze_slp_backedges (vinfo, SLP_INSTANCE_TREE (instance),\n+\t\t\t\tbst_map, visited);\n+\n   /* The map keeps a reference on SLP nodes built, release that.  */\n   for (scalar_stmts_to_slp_tree_map_t::iterator it = bst_map->begin ();\n        it != bst_map->end (); ++it)\n@@ -2519,34 +2391,396 @@ vect_analyze_slp (vec_info *vinfo, unsigned max_tree_size)\n   return opt_result::success ();\n }\n \n+/* Fill the vertices and leafs vector with all nodes in the SLP graph.  */\n+\n+static void\n+vect_slp_build_vertices (hash_set<slp_tree> &visited, slp_tree node,\n+\t\t\t vec<slp_tree> &vertices, vec<int> &leafs)\n+{\n+  unsigned i;\n+  slp_tree child;\n+\n+  if (visited.add (node))\n+    return;\n+\n+  node->vertex = vertices.length ();\n+  vertices.safe_push (node);\n+  if (SLP_TREE_CHILDREN (node).is_empty ())\n+    leafs.safe_push (node->vertex);\n+  else\n+    FOR_EACH_VEC_ELT (SLP_TREE_CHILDREN (node), i, child)\n+      vect_slp_build_vertices (visited, child, vertices, leafs);\n+}\n+\n+/* Fill the vertices and leafs vector with all nodes in the SLP graph.  */\n+\n+static void\n+vect_slp_build_vertices (vec_info *info, vec<slp_tree> &vertices,\n+\t\t\t vec<int> &leafs)\n+{\n+  hash_set<slp_tree> visited;\n+  unsigned i;\n+  slp_instance instance;\n+  FOR_EACH_VEC_ELT (info->slp_instances, i, instance)\n+    vect_slp_build_vertices (visited, SLP_INSTANCE_TREE (instance), vertices,\n+\t\t\t     leafs);\n+}\n+\n+/* Apply (reverse) bijectite PERM to VEC.  */\n+\n+template <class T>\n+static void\n+vect_slp_permute (vec<unsigned> perm,\n+\t\t  vec<T> &vec, bool reverse)\n+{\n+  auto_vec<T, 64> saved;\n+  saved.create (vec.length ());\n+  for (unsigned i = 0; i < vec.length (); ++i)\n+    saved.quick_push (vec[i]);\n+\n+  if (reverse)\n+    {\n+      for (unsigned i = 0; i < vec.length (); ++i)\n+\tvec[perm[i]] = saved[i];\n+      for (unsigned i = 0; i < vec.length (); ++i)\n+\tgcc_assert (vec[perm[i]] == saved[i]);\n+    }\n+  else\n+    {\n+      for (unsigned i = 0; i < vec.length (); ++i)\n+\tvec[i] = saved[perm[i]];\n+      for (unsigned i = 0; i < vec.length (); ++i)\n+\tgcc_assert (vec[i] == saved[perm[i]]);\n+    }\n+}\n+\n+/* Return whether permutations PERM_A and PERM_B as recorded in the\n+   PERMS vector are equal.  */\n+\n+static bool\n+vect_slp_perms_eq (const vec<vec<unsigned> > &perms,\n+\t\t   int perm_a, int perm_b)\n+{\n+  return (perm_a == perm_b\n+\t  || (perms[perm_a].length () == perms[perm_b].length ()\n+\t      && memcmp (&perms[perm_a][0], &perms[perm_b][0],\n+\t\t\t sizeof (unsigned) * perms[perm_a].length ()) == 0));\n+}\n+\n+/* Optimize the SLP graph of VINFO.  */\n+\n void\n vect_optimize_slp (vec_info *vinfo)\n {\n-  /* Optimize permutations in SLP reductions.  */\n-  slp_instance instance;\n+  if (vinfo->slp_instances.is_empty ())\n+    return;\n+\n+  slp_tree node;\n   unsigned i;\n-  FOR_EACH_VEC_ELT (vinfo->slp_instances, i, instance)\n+  auto_vec<slp_tree> vertices;\n+  auto_vec<int> leafs;\n+  vect_slp_build_vertices (vinfo, vertices, leafs);\n+\n+  struct graph *slpg = new_graph (vertices.length ());\n+  FOR_EACH_VEC_ELT (vertices, i, node)\n     {\n-      slp_tree node = SLP_INSTANCE_TREE (instance);\n-      stmt_vec_info stmt_info = SLP_TREE_SCALAR_STMTS (node)[0];\n-      /* Reduction (there are no data-refs in the root).\n-\t In reduction chain the order of the loads is not important.  */\n-      if (!STMT_VINFO_DATA_REF (stmt_info)\n-\t  && !REDUC_GROUP_FIRST_ELEMENT (stmt_info)\n-\t  && !SLP_INSTANCE_ROOT_STMT (instance))\n-\tvect_attempt_slp_rearrange_stmts (instance);\n+      unsigned j;\n+      slp_tree child;\n+      FOR_EACH_VEC_ELT (SLP_TREE_CHILDREN (node), j, child)\n+\tadd_edge (slpg, i, child->vertex);\n     }\n \n-  /* Gather all loads in the SLP graph.  */\n-  auto_vec<slp_tree> slp_loads;\n-  hash_set<slp_tree> visited;\n-  FOR_EACH_VEC_ELT (vinfo->slp_instances, i, instance)\n-    vect_gather_slp_loads (slp_loads, SLP_INSTANCE_TREE (instance),\n-\t\t\t   visited);\n+  /* Compute (reverse) postorder on the inverted graph.  */\n+  auto_vec<int> ipo;\n+  graphds_dfs (slpg, &leafs[0], leafs.length (), &ipo, false, NULL, NULL);\n \n-  slp_tree node;\n-  FOR_EACH_VEC_ELT (slp_loads, i, node)\n+  auto_sbitmap n_visited (vertices.length ());\n+  auto_sbitmap n_materialize (vertices.length ());\n+  auto_vec<int> n_perm (vertices.length ());\n+  auto_vec<vec<unsigned> > perms;\n+\n+  bitmap_clear (n_visited);\n+  bitmap_clear (n_materialize);\n+  n_perm.quick_grow_cleared (vertices.length ());\n+  perms.safe_push (vNULL); /* zero is no permute */\n+\n+  /* Produce initial permutations.  */\n+  for (i = 0; i < leafs.length (); ++i)\n+    {\n+      int idx = leafs[i];\n+      slp_tree node = vertices[idx];\n+\n+      /* Handle externals and constants optimistically throughout the\n+\t iteration.  */\n+      if (SLP_TREE_DEF_TYPE (node) == vect_external_def\n+\t  || SLP_TREE_DEF_TYPE (node) == vect_constant_def)\n+\tcontinue;\n+\n+      /* Loads are the only thing generating permutes and leafs do not\n+\t change across iterations.  */\n+      bitmap_set_bit (n_visited, idx);\n+      if (!SLP_TREE_LOAD_PERMUTATION (node).exists ())\n+\tcontinue;\n+\n+      /* If splitting out a SLP_TREE_LANE_PERMUTATION can make the\n+\t node unpermuted, record this permute.  */\n+      stmt_vec_info dr_stmt = SLP_TREE_REPRESENTATIVE (node);\n+      if (!STMT_VINFO_GROUPED_ACCESS (dr_stmt))\n+\tcontinue;\n+      dr_stmt = DR_GROUP_FIRST_ELEMENT (dr_stmt);\n+      unsigned imin = DR_GROUP_SIZE (dr_stmt) + 1, imax = 0;\n+      bool any_permute = false;\n+      for (unsigned j = 0; j < SLP_TREE_LANES (node); ++j)\n+\t{\n+\t  unsigned idx = SLP_TREE_LOAD_PERMUTATION (node)[j];\n+\t  imin = MIN (imin, idx);\n+\t  imax = MAX (imax, idx);\n+\t  if (idx - SLP_TREE_LOAD_PERMUTATION (node)[0] != j)\n+\t    any_permute = true;\n+\t}\n+      /* If there's no permute no need to split one out.  */\n+      if (!any_permute)\n+\tcontinue;\n+      /* If the span doesn't match we'd disrupt VF computation, avoid\n+\t that for now.  */\n+      if (imax - imin + 1 != SLP_TREE_LANES (node))\n+\tcontinue;\n+\n+      /* For now only handle true permutes, like\n+\t vect_attempt_slp_rearrange_stmts did.  This allows us to be lazy\n+\t when permuting constants and invariants keeping the permute\n+\t bijective.  */\n+      auto_sbitmap load_index (SLP_TREE_LANES (node));\n+      bitmap_clear (load_index);\n+      for (unsigned j = 0; j < SLP_TREE_LANES (node); ++j)\n+\tbitmap_set_bit (load_index, SLP_TREE_LOAD_PERMUTATION (node)[j] - imin);\n+      unsigned j;\n+      for (j = 0; j < SLP_TREE_LANES (node); ++j)\n+\tif (!bitmap_bit_p (load_index, j))\n+\t  break;\n+      if (j != SLP_TREE_LANES (node))\n+\tcontinue;\n+\n+      vec<unsigned> perm = vNULL;\n+      perm.safe_grow (SLP_TREE_LANES (node), true);\n+      for (unsigned j = 0; j < SLP_TREE_LANES (node); ++j)\n+\tperm[j] = SLP_TREE_LOAD_PERMUTATION (node)[j] - imin;\n+      perms.safe_push (perm);\n+      n_perm[idx] = perms.length () - 1;\n+    }\n+\n+  /* Propagate permutes along the graph and compute materialization points.  */\n+  bool changed;\n+  unsigned iteration = 0;\n+  do\n+    {\n+      changed = false;\n+      ++iteration;\n+\n+      for (i = vertices.length (); i > 0 ; --i)\n+\t{\n+\t  int idx = ipo[i-1];\n+\t  slp_tree node = vertices[idx];\n+\t  /* For leafs there's nothing to do - we've seeded permutes\n+\t     on those above.  */\n+\t  if (SLP_TREE_DEF_TYPE (node) != vect_internal_def)\n+\t    continue;\n+\n+\t  bitmap_set_bit (n_visited, idx);\n+\n+\t  /* We cannot move a permute across a store.  */\n+\t  if (STMT_VINFO_DATA_REF (SLP_TREE_REPRESENTATIVE (node))\n+\t      && DR_IS_WRITE\n+\t\t   (STMT_VINFO_DATA_REF (SLP_TREE_REPRESENTATIVE (node))))\n+\t    continue;\n+\n+\t  int perm = -1;\n+\t  for (graph_edge *succ = slpg->vertices[idx].succ;\n+\t       succ; succ = succ->succ_next)\n+\t    {\n+\t      int succ_idx = succ->dest;\n+\t      /* Handle unvisited nodes optimistically.  */\n+\t      /* ???  But for constants once we want to handle non-bijective\n+\t\t permutes we have to verify the permute, when unifying lanes,\n+\t\t will not unify different constants.  For example see\n+\t\t gcc.dg/vect/bb-slp-14.c for a case that would break.  */\n+\t      if (!bitmap_bit_p (n_visited, succ_idx))\n+\t\tcontinue;\n+\t      int succ_perm = n_perm[succ_idx];\n+\t      /* Once we materialize succs permutation its output lanes\n+\t\t appear unpermuted to us.  */\n+\t      if (bitmap_bit_p (n_materialize, succ_idx))\n+\t\tsucc_perm = 0;\n+\t      if (perm == -1)\n+\t\tperm = succ_perm;\n+\t      else if (succ_perm == 0)\n+\t\t{\n+\t\t  perm = 0;\n+\t\t  break;\n+\t\t}\n+\t      else if (!vect_slp_perms_eq (perms, perm, succ_perm))\n+\t\t{\n+\t\t  perm = 0;\n+\t\t  break;\n+\t\t}\n+\t    }\n+\n+\t  if (perm == -1)\n+\t    /* Pick up pre-computed leaf values.  */\n+\t    perm = n_perm[idx];\n+\t  else if (!vect_slp_perms_eq (perms, perm, n_perm[idx]))\n+\t    {\n+\t      if (iteration > 1)\n+\t\t/* Make sure we eventually converge.  */\n+\t\tgcc_checking_assert (perm == 0);\n+\t      n_perm[idx] = perm;\n+\t      if (perm == 0)\n+\t\tbitmap_clear_bit (n_materialize, idx);\n+\t      changed = true;\n+\t    }\n+\n+\t  if (perm == 0)\n+\t    continue;\n+\n+\t  /* Elide pruning at materialization points in the first\n+\t     iteration so every node was visited once at least.  */\n+\t  if (iteration == 1)\n+\t    continue;\n+\n+\t  /* Decide on permute materialization.  Look whether there's\n+\t     a use (pred) edge that is permuted differently than us.\n+\t     In that case mark ourselves so the permutation is applied.  */\n+\t  bool all_preds_permuted = slpg->vertices[idx].pred != NULL;\n+\t  for (graph_edge *pred = slpg->vertices[idx].pred;\n+\t       pred; pred = pred->pred_next)\n+\t    {\n+\t      gcc_checking_assert (bitmap_bit_p (n_visited, pred->src));\n+\t      int pred_perm = n_perm[pred->src];\n+\t      if (!vect_slp_perms_eq (perms, perm, pred_perm))\n+\t\t{\n+\t\t  all_preds_permuted = false;\n+\t\t  break;\n+\t\t}\n+\t    }\n+\t  if (!all_preds_permuted)\n+\t    {\n+\t      if (!bitmap_bit_p (n_materialize, idx))\n+\t\tchanged = true;\n+\t      bitmap_set_bit (n_materialize, idx);\n+\t    }\n+\t}\n+    }\n+  while (changed || iteration == 1);\n+\n+  /* Materialize.  */\n+  for (i = 0; i < vertices.length (); ++i)\n+    {\n+      int perm = n_perm[i];\n+      if (perm <= 0)\n+\tcontinue;\n+\n+      slp_tree node = vertices[i];\n+\n+      /* First permute invariant/external original successors.  */\n+      unsigned j;\n+      slp_tree child;\n+      FOR_EACH_VEC_ELT (SLP_TREE_CHILDREN (node), j, child)\n+\t{\n+\t  if (SLP_TREE_DEF_TYPE (child) == vect_internal_def)\n+\t    continue;\n+\n+\t  /* If the vector is uniform there's nothing to do.  */\n+\t  if (vect_slp_tree_uniform_p (child))\n+\t    continue;\n+\n+\t  /* We can end up sharing some externals via two_operator\n+\t     handling.  Be prepared to unshare those.  */\n+\t  if (child->refcnt != 1)\n+\t    {\n+\t      gcc_assert (slpg->vertices[child->vertex].pred->pred_next);\n+\t      SLP_TREE_CHILDREN (node)[j] = child\n+\t\t= vect_create_new_slp_node\n+\t\t    (SLP_TREE_SCALAR_OPS (child).copy ());\n+\t    }\n+\t  vect_slp_permute (perms[perm],\n+\t\t\t    SLP_TREE_SCALAR_OPS (child), true);\n+\t}\n+\n+      if (bitmap_bit_p (n_materialize, i))\n+\t{\n+\t  if (SLP_TREE_LOAD_PERMUTATION (node).exists ())\n+\t    /* For loads simply drop the permutation, the load permutation\n+\t       already performs the desired permutation.  */\n+\t    ;\n+\t  else\n+\t    {\n+\t      if (dump_enabled_p ())\n+\t\tdump_printf_loc (MSG_NOTE, vect_location,\n+\t\t\t\t \"inserting permute node in place of %p\\n\",\n+\t\t\t\t node);\n+\n+\t      /* Make a copy of NODE and in-place change it to a\n+\t\t VEC_PERM node to permute the lanes of the copy.  */\n+\t      slp_tree copy = new _slp_tree;\n+\t      SLP_TREE_CHILDREN (copy) = SLP_TREE_CHILDREN (node);\n+\t      SLP_TREE_CHILDREN (node) = vNULL;\n+\t      SLP_TREE_SCALAR_STMTS (copy)\n+\t\t= SLP_TREE_SCALAR_STMTS (node).copy ();\n+\t      vect_slp_permute (perms[perm],\n+\t\t\t\tSLP_TREE_SCALAR_STMTS (copy), true);\n+\t      gcc_assert (!SLP_TREE_SCALAR_OPS (node).exists ());\n+\t      SLP_TREE_REPRESENTATIVE (copy) = SLP_TREE_REPRESENTATIVE (node);\n+\t      gcc_assert (!SLP_TREE_LOAD_PERMUTATION (node).exists ());\n+\t      SLP_TREE_LANE_PERMUTATION (copy)\n+\t\t= SLP_TREE_LANE_PERMUTATION (node);\n+\t      SLP_TREE_LANE_PERMUTATION (node) = vNULL;\n+\t      SLP_TREE_VECTYPE (copy) = SLP_TREE_VECTYPE (node);\n+\t      copy->refcnt = 1;\n+\t      copy->max_nunits = node->max_nunits;\n+\t      SLP_TREE_DEF_TYPE (copy) = SLP_TREE_DEF_TYPE (node);\n+\t      SLP_TREE_LANES (copy) = SLP_TREE_LANES (node);\n+\t      SLP_TREE_CODE (copy) = SLP_TREE_CODE (node);\n+\n+\t      /* Now turn NODE into a VEC_PERM.  */\n+\t      SLP_TREE_CHILDREN (node).safe_push (copy);\n+\t      SLP_TREE_LANE_PERMUTATION (node).create (SLP_TREE_LANES (node));\n+\t      for (unsigned j = 0; j < SLP_TREE_LANES (node); ++j)\n+\t\tSLP_TREE_LANE_PERMUTATION (node)\n+\t\t  .quick_push (std::make_pair (0, perms[perm][j]));\n+\t      SLP_TREE_CODE (node) = VEC_PERM_EXPR;\n+\t    }\n+\t}\n+      else\n+\t{\n+\t  /* Apply the reverse permutation to our stmts.  */\n+\t  vect_slp_permute (perms[perm],\n+\t\t\t    SLP_TREE_SCALAR_STMTS (node), true);\n+\t  /* And to the load permutation, which we can simply\n+\t     make regular by design.  */\n+\t  if (SLP_TREE_LOAD_PERMUTATION (node).exists ())\n+\t    {\n+\t      /* ???  When we handle non-bijective permutes the idea\n+\t\t is that we can force the load-permutation to be\n+\t\t { min, min + 1, min + 2, ... max }.  But then the\n+\t\t scalar defs might no longer match the lane content\n+\t\t which means wrong-code with live lane vectorization.\n+\t\t So we possibly have to have NULL entries for those.  */\n+\t      vect_slp_permute (perms[perm],\n+\t\t\t\tSLP_TREE_LOAD_PERMUTATION (node), true);\n+\t    }\n+\t}\n+    }\n+\n+  /* Free the perms vector used for propagation.  */\n+  while (!perms.is_empty ())\n+    perms.pop ().release ();\n+  free_graph (slpg);\n+\n+\n+  /* Now elide load permutations that are not necessary.  */\n+  for (i = 0; i < leafs.length (); ++i)\n     {\n+      node = vertices[i];\n       if (!SLP_TREE_LOAD_PERMUTATION (node).exists ())\n \tcontinue;\n \n@@ -2593,7 +2827,8 @@ vect_optimize_slp (vec_info *vinfo)\n \t      /* The load requires permutation when unrolling exposes\n \t\t a gap either because the group is larger than the SLP\n \t\t group-size or because there is a gap between the groups.  */\n-\t      && (known_eq (LOOP_VINFO_VECT_FACTOR (as_a <loop_vec_info> (vinfo)), 1U)\n+\t      && (known_eq (LOOP_VINFO_VECT_FACTOR\n+\t\t\t      (as_a <loop_vec_info> (vinfo)), 1U)\n \t\t  || ((SLP_TREE_LANES (node) == DR_GROUP_SIZE (first_stmt_info))\n \t\t      && DR_GROUP_GAP (first_stmt_info) == 0)))\n \t    {\n@@ -2975,12 +3210,9 @@ vect_slp_analyze_node_operations (vec_info *vinfo, slp_tree node,\n     return true;\n \n   /* If we already analyzed the exact same set of scalar stmts we're done.\n-     We share the generated vector stmts for those.\n-     The SLP graph is acyclic so not caching whether we failed or succeeded\n-     doesn't result in any issue since we throw away the lvisited set\n-     when we fail.  */\n+     We share the generated vector stmts for those.  */\n   if (visited.contains (node)\n-      || lvisited.contains (node))\n+      || lvisited.add (node))\n     return true;\n \n   bool res = true;\n@@ -2993,12 +3225,10 @@ vect_slp_analyze_node_operations (vec_info *vinfo, slp_tree node,\n     }\n \n   if (res)\n-    {\n-      res = vect_slp_analyze_node_operations_1 (vinfo, node, node_instance,\n-\t\t\t\t\t\tcost_vec);\n-      if (res)\n-\tlvisited.add (node);\n-    }\n+    res = vect_slp_analyze_node_operations_1 (vinfo, node, node_instance,\n+\t\t\t\t\t      cost_vec);\n+  if (!res)\n+    lvisited.remove (node);\n \n   /* When the node can be vectorized cost invariant nodes it references.\n      This is not done in DFS order to allow the refering node\n@@ -4685,7 +4915,8 @@ vectorizable_slp_permutation (vec_info *vinfo, gimple_stmt_iterator *gsi,\n \n static void\n vect_schedule_slp_instance (vec_info *vinfo,\n-\t\t\t    slp_tree node, slp_instance instance)\n+\t\t\t    slp_tree node, slp_instance instance,\n+\t\t\t    hash_set<slp_tree> &visited)\n {\n   gimple_stmt_iterator si;\n   int i;\n@@ -4712,8 +4943,12 @@ vect_schedule_slp_instance (vec_info *vinfo,\n       return;\n     }\n \n+  /* ???  If we'd have a way to mark backedges that would be cheaper.  */\n+  if (visited.add (node))\n+    return;\n+\n   FOR_EACH_VEC_ELT (SLP_TREE_CHILDREN (node), i, child)\n-    vect_schedule_slp_instance (vinfo, child, instance);\n+    vect_schedule_slp_instance (vinfo, child, instance, visited);\n \n   gcc_assert (SLP_TREE_NUMBER_OF_VEC_STMTS (node) != 0);\n   SLP_TREE_VEC_STMTS (node).create (SLP_TREE_NUMBER_OF_VEC_STMTS (node));\n@@ -4737,14 +4972,13 @@ vect_schedule_slp_instance (vec_info *vinfo,\n \tlast_stmt_info = vect_find_last_scalar_stmt_in_slp (node);\n       si = gsi_for_stmt (last_stmt_info->stmt);\n     }\n-  else if (SLP_TREE_CHILDREN (node).is_empty ())\n+  else if ((STMT_VINFO_TYPE (SLP_TREE_REPRESENTATIVE (node))\n+\t    == cycle_phi_info_type)\n+\t   || (STMT_VINFO_TYPE (SLP_TREE_REPRESENTATIVE (node))\n+\t       == induc_vec_info_type))\n     {\n-      /* This happens for reduction and induction PHIs where we do not use the\n+      /* For reduction and induction PHIs we do not use the\n \t insertion iterator.  */\n-      gcc_assert (STMT_VINFO_TYPE (SLP_TREE_REPRESENTATIVE (node))\n-\t\t  == cycle_phi_info_type\n-\t\t  || (STMT_VINFO_TYPE (SLP_TREE_REPRESENTATIVE (node))\n-\t\t      == induc_vec_info_type));\n       si = gsi_none ();\n     }\n   else\n@@ -4957,6 +5191,7 @@ vect_schedule_slp (vec_info *vinfo, vec<slp_instance> slp_instances)\n   slp_instance instance;\n   unsigned int i;\n \n+  hash_set<slp_tree> visited;\n   FOR_EACH_VEC_ELT (slp_instances, i, instance)\n     {\n       slp_tree node = SLP_INSTANCE_TREE (instance);\n@@ -4971,7 +5206,7 @@ vect_schedule_slp (vec_info *vinfo, vec<slp_instance> slp_instances)\n \t\t\t\tSLP_INSTANCE_TREE (instance));\n \t}\n       /* Schedule the tree of INSTANCE.  */\n-      vect_schedule_slp_instance (vinfo, node, instance);\n+      vect_schedule_slp_instance (vinfo, node, instance, visited);\n \n       if (SLP_INSTANCE_ROOT_STMT (instance))\n \tvectorize_slp_instance_root_stmt (node, instance);"}, {"sha": "2a8c4a56a8a79add966f78f6978f72a3b287a935", "filename": "gcc/tree-vectorizer.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/126ed72b9f48f8530b194532cc281fb761690435/gcc%2Ftree-vectorizer.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/126ed72b9f48f8530b194532cc281fb761690435/gcc%2Ftree-vectorizer.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vectorizer.h?ref=126ed72b9f48f8530b194532cc281fb761690435", "patch": "@@ -161,6 +161,8 @@ struct _slp_tree {\n   unsigned int lanes;\n   /* The operation of this node.  */\n   enum tree_code code;\n+\n+  int vertex;\n };\n \n "}]}