{"sha": "2310e29f49d5b2c7fe9c6ec920f79192728d0f87", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MjMxMGUyOWY0OWQ1YjJjN2ZlOWM2ZWM5MjBmNzkxOTI3MjhkMGY4Nw==", "commit": {"author": {"name": "Alan Lawrence", "email": "alan.lawrence@arm.com", "date": "2014-12-09T19:37:18Z"}, "committer": {"name": "Alan Lawrence", "email": "alalaw01@gcc.gnu.org", "date": "2014-12-09T19:37:18Z"}, "message": "[AArch64]Fix ICE at -O0 on vld1_lane intrinsics\n\ngcc/:\n\n\t* config/aarch64/arm_neon.h (__AARCH64_NUM_LANES, __aarch64_lane *2):\n\tNew.\n\t(aarch64_vset_lane_any): Redefine using previous, same for BE + LE.\n\t(vset_lane_f32, vset_lane_f64, vset_lane_p8, vset_lane_p16,\n\tvset_lane_s8, vset_lane_s16, vset_lane_s32, vset_lane_s64,\n\tvset_lane_u8, vset_lane_u16, vset_lane_u32, vset_lane_u64): Remove\n\tnumber of lanes.\n\t(vld1_lane_f32, vld1_lane_f64, vld1_lane_p8, vld1_lane_p16,\n\tvld1_lane_s8, vld1_lane_s16, vld1_lane_s32, vld1_lane_s64,\n\tvld1_lane_u8, vld1_lane_u16, vld1_lane_u32, vld1_lane_u64): Call\n\t__aarch64_vset_lane_any rather than vset_lane_xxx.\n\ngcc/testsuite/:\n\n\t* gcc.target/aarch64/vld1_lane-o0.c: New test.\n\nFrom-SVN: r218531", "tree": {"sha": "74b082a0bf5ac48b075e597b767d0187e8d5851a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/74b082a0bf5ac48b075e597b767d0187e8d5851a"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/2310e29f49d5b2c7fe9c6ec920f79192728d0f87", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2310e29f49d5b2c7fe9c6ec920f79192728d0f87", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2310e29f49d5b2c7fe9c6ec920f79192728d0f87", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2310e29f49d5b2c7fe9c6ec920f79192728d0f87/comments", "author": null, "committer": null, "parents": [{"sha": "8f905d691e15b560e9b64d26c2e5ab281c1fb6fd", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8f905d691e15b560e9b64d26c2e5ab281c1fb6fd", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8f905d691e15b560e9b64d26c2e5ab281c1fb6fd"}], "stats": {"total": 402, "additions": 218, "deletions": 184}, "files": [{"sha": "f90982b9acd27fb312d0b90f74176141488dee14", "filename": "gcc/ChangeLog", "status": "modified", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2310e29f49d5b2c7fe9c6ec920f79192728d0f87/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2310e29f49d5b2c7fe9c6ec920f79192728d0f87/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=2310e29f49d5b2c7fe9c6ec920f79192728d0f87", "patch": "@@ -1,3 +1,17 @@\n+2014-12-09  Alan Lawrence  <alan.lawrence@arm.com>\n+\n+\t* config/aarch64/arm_neon.h (__AARCH64_NUM_LANES, __aarch64_lane *2):\n+\tNew.\n+\t(aarch64_vset_lane_any): Redefine using previous, same for BE + LE.\n+\t(vset_lane_f32, vset_lane_f64, vset_lane_p8, vset_lane_p16,\n+\tvset_lane_s8, vset_lane_s16, vset_lane_s32, vset_lane_s64,\n+\tvset_lane_u8, vset_lane_u16, vset_lane_u32, vset_lane_u64): Remove\n+\tnumber of lanes.\n+\t(vld1_lane_f32, vld1_lane_f64, vld1_lane_p8, vld1_lane_p16,\n+\tvld1_lane_s8, vld1_lane_s16, vld1_lane_s32, vld1_lane_s64,\n+\tvld1_lane_u8, vld1_lane_u16, vld1_lane_u32, vld1_lane_u64): Call\n+\t__aarch64_vset_lane_any rather than vset_lane_xxx.\n+\n 2014-12-09  Alan Lawrence  <alan.lawrence@arm.com>\n \n \t* config/aarch64/aarch64.md (absdi2): Remove scratch operand by"}, {"sha": "f86c649562de4ba66c406a494783915821a640a1", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 187, "deletions": 184, "changes": 371, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2310e29f49d5b2c7fe9c6ec920f79192728d0f87/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2310e29f49d5b2c7fe9c6ec920f79192728d0f87/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=2310e29f49d5b2c7fe9c6ec920f79192728d0f87", "patch": "@@ -604,173 +604,28 @@ typedef struct poly16x8x4_t\n #define __aarch64_vdupq_laneq_u64(__a, __b) \\\n    __aarch64_vdup_lane_any (u64, q, q, __a, __b)\n \n-/* vset_lane and vld1_lane internal macro.  */\n+/* Internal macro for lane indices.  */\n+\n+#define __AARCH64_NUM_LANES(__v) (sizeof (__v) / sizeof (__v[0]))\n \n-#ifdef __AARCH64EB__\n /* For big-endian, GCC's vector indices are the opposite way around\n    to the architectural lane indices used by Neon intrinsics.  */\n-#define __aarch64_vset_lane_any(__vec, __index, __val, __lanes) \\\n-  __extension__\t\t\t\t\t\t\t\\\n-  ({\t\t\t\t\t\t\t\t\\\n-    __builtin_aarch64_im_lane_boundsi (__index, __lanes);\t\\\n-    __vec[__lanes - 1 - __index] = __val;\t\t\t\\\n-    __vec;\t\t\t\t\t\t\t\\\n-  })\n+#ifdef __AARCH64EB__\n+#define __aarch64_lane(__vec, __idx) (__AARCH64_NUM_LANES (__vec) - 1 - __idx)\n #else\n-#define __aarch64_vset_lane_any(__vec, __index, __val, __lanes) \\\n-  __extension__\t\t\t\t\t\t\t\\\n-  ({\t\t\t\t\t\t\t\t\\\n-    __builtin_aarch64_im_lane_boundsi (__index, __lanes);\t\\\n-    __vec[__index] = __val;\t\t\t\t\t\\\n-    __vec;\t\t\t\t\t\t\t\\\n-  })\n+#define __aarch64_lane(__vec, __idx) __idx\n #endif\n \n-/* vset_lane  */\n-\n-__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n-vset_lane_f32 (float32_t __elem, float32x2_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 2);\n-}\n-\n-__extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n-vset_lane_f64 (float64_t __elem, float64x1_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 1);\n-}\n-\n-__extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n-vset_lane_p8 (poly8_t __elem, poly8x8_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 8);\n-}\n-\n-__extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n-vset_lane_p16 (poly16_t __elem, poly16x4_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 4);\n-}\n-\n-__extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n-vset_lane_s8 (int8_t __elem, int8x8_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 8);\n-}\n-\n-__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n-vset_lane_s16 (int16_t __elem, int16x4_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 4);\n-}\n-\n-__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n-vset_lane_s32 (int32_t __elem, int32x2_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 2);\n-}\n-\n-__extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n-vset_lane_s64 (int64_t __elem, int64x1_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 1);\n-}\n-\n-__extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n-vset_lane_u8 (uint8_t __elem, uint8x8_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 8);\n-}\n-\n-__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n-vset_lane_u16 (uint16_t __elem, uint16x4_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 4);\n-}\n-\n-__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n-vset_lane_u32 (uint32_t __elem, uint32x2_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 2);\n-}\n-\n-__extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n-vset_lane_u64 (uint64_t __elem, uint64x1_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 1);\n-}\n-\n-__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n-vsetq_lane_f32 (float32_t __elem, float32x4_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 4);\n-}\n-\n-__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n-vsetq_lane_f64 (float64_t __elem, float64x2_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 2);\n-}\n-\n-__extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n-vsetq_lane_p8 (poly8_t __elem, poly8x16_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 16);\n-}\n-\n-__extension__ static __inline poly16x8_t __attribute__ ((__always_inline__))\n-vsetq_lane_p16 (poly16_t __elem, poly16x8_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 8);\n-}\n-\n-__extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n-vsetq_lane_s8 (int8_t __elem, int8x16_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 16);\n-}\n-\n-__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n-vsetq_lane_s16 (int16_t __elem, int16x8_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 8);\n-}\n-\n-__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n-vsetq_lane_s32 (int32_t __elem, int32x4_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 4);\n-}\n-\n-__extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n-vsetq_lane_s64 (int64_t __elem, int64x2_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 2);\n-}\n-\n-__extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n-vsetq_lane_u8 (uint8_t __elem, uint8x16_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 16);\n-}\n-\n-__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n-vsetq_lane_u16 (uint16_t __elem, uint16x8_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 8);\n-}\n-\n-__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n-vsetq_lane_u32 (uint32_t __elem, uint32x4_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 4);\n-}\n+/* vset_lane and vld1_lane internal macro.  */\n \n-__extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n-vsetq_lane_u64 (uint64_t __elem, uint64x2_t __vec, const int __index)\n-{\n-  return __aarch64_vset_lane_any (__vec, __index, __elem, 2);\n-}\n+#define __aarch64_vset_lane_any(__elem, __vec, __index)\t\t\t\\\n+  __extension__\t\t\t\t\t\t\t\t\\\n+  ({\t\t\t\t\t\t\t\t\t\\\n+    __builtin_aarch64_im_lane_boundsi (__index,\t\t\t\\\n+       __AARCH64_NUM_LANES (__vec));\t\t\t\t\t\\\n+    __vec[__aarch64_lane (__vec, __index)] = __elem;\t\t\t\\\n+    __vec;\t\t\t\t\t\t\t\t\\\n+  })\n \n /* vadd  */\n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n@@ -4627,6 +4482,154 @@ vreinterpretq_u32_p16 (poly16x8_t __a)\n   return (uint32x4_t) __a;\n }\n \n+/* vset_lane  */\n+\n+__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n+vset_lane_f32 (float32_t __elem, float32x2_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n+vset_lane_f64 (float64_t __elem, float64x1_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n+vset_lane_p8 (poly8_t __elem, poly8x8_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n+vset_lane_p16 (poly16_t __elem, poly16x4_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n+vset_lane_s8 (int8_t __elem, int8x8_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n+vset_lane_s16 (int16_t __elem, int16x4_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n+vset_lane_s32 (int32_t __elem, int32x2_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n+vset_lane_s64 (int64_t __elem, int64x1_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n+vset_lane_u8 (uint8_t __elem, uint8x8_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vset_lane_u16 (uint16_t __elem, uint16x4_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n+vset_lane_u32 (uint32_t __elem, uint32x2_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n+vset_lane_u64 (uint64_t __elem, uint64x1_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+/* vsetq_lane  */\n+\n+__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n+vsetq_lane_f32 (float32_t __elem, float32x4_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n+vsetq_lane_f64 (float64_t __elem, float64x2_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n+vsetq_lane_p8 (poly8_t __elem, poly8x16_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline poly16x8_t __attribute__ ((__always_inline__))\n+vsetq_lane_p16 (poly16_t __elem, poly16x8_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n+vsetq_lane_s8 (int8_t __elem, int8x16_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n+vsetq_lane_s16 (int16_t __elem, int16x8_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n+vsetq_lane_s32 (int32_t __elem, int32x4_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n+vsetq_lane_s64 (int64_t __elem, int64x2_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n+vsetq_lane_u8 (uint8_t __elem, uint8x16_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vsetq_lane_u16 (uint16_t __elem, uint16x8_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n+vsetq_lane_u32 (uint32_t __elem, uint32x4_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n+__extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n+vsetq_lane_u64 (uint64_t __elem, uint64x2_t __vec, const int __index)\n+{\n+  return __aarch64_vset_lane_any (__elem, __vec, __index);\n+}\n+\n #define __GET_LOW(__TYPE) \\\n   uint64x2_t tmp = vreinterpretq_u64_##__TYPE (__a);  \\\n   uint64x1_t lo = vcreate_u64 (vgetq_lane_u64 (tmp, 0));  \\\n@@ -15730,147 +15733,147 @@ vld1q_dup_u64 (const uint64_t* __a)\n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vld1_lane_f32 (const float32_t *__src, float32x2_t __vec, const int __lane)\n {\n-  return vset_lane_f32 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n vld1_lane_f64 (const float64_t *__src, float64x1_t __vec, const int __lane)\n {\n-  return vset_lane_f64 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n vld1_lane_p8 (const poly8_t *__src, poly8x8_t __vec, const int __lane)\n {\n-  return vset_lane_p8 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n vld1_lane_p16 (const poly16_t *__src, poly16x4_t __vec, const int __lane)\n {\n-  return vset_lane_p16 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n vld1_lane_s8 (const int8_t *__src, int8x8_t __vec, const int __lane)\n {\n-  return vset_lane_s8 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vld1_lane_s16 (const int16_t *__src, int16x4_t __vec, const int __lane)\n {\n-  return vset_lane_s16 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vld1_lane_s32 (const int32_t *__src, int32x2_t __vec, const int __lane)\n {\n-  return vset_lane_s32 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n vld1_lane_s64 (const int64_t *__src, int64x1_t __vec, const int __lane)\n {\n-  return vset_lane_s64 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vld1_lane_u8 (const uint8_t *__src, uint8x8_t __vec, const int __lane)\n {\n-  return vset_lane_u8 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vld1_lane_u16 (const uint16_t *__src, uint16x4_t __vec, const int __lane)\n {\n-  return vset_lane_u16 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vld1_lane_u32 (const uint32_t *__src, uint32x2_t __vec, const int __lane)\n {\n-  return vset_lane_u32 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vld1_lane_u64 (const uint64_t *__src, uint64x1_t __vec, const int __lane)\n {\n-  return vset_lane_u64 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n /* vld1q_lane  */\n \n __extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n vld1q_lane_f32 (const float32_t *__src, float32x4_t __vec, const int __lane)\n {\n-  return vsetq_lane_f32 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n vld1q_lane_f64 (const float64_t *__src, float64x2_t __vec, const int __lane)\n {\n-  return vsetq_lane_f64 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n vld1q_lane_p8 (const poly8_t *__src, poly8x16_t __vec, const int __lane)\n {\n-  return vsetq_lane_p8 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline poly16x8_t __attribute__ ((__always_inline__))\n vld1q_lane_p16 (const poly16_t *__src, poly16x8_t __vec, const int __lane)\n {\n-  return vsetq_lane_p16 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n vld1q_lane_s8 (const int8_t *__src, int8x16_t __vec, const int __lane)\n {\n-  return vsetq_lane_s8 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vld1q_lane_s16 (const int16_t *__src, int16x8_t __vec, const int __lane)\n {\n-  return vsetq_lane_s16 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n vld1q_lane_s32 (const int32_t *__src, int32x4_t __vec, const int __lane)\n {\n-  return vsetq_lane_s32 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n vld1q_lane_s64 (const int64_t *__src, int64x2_t __vec, const int __lane)\n {\n-  return vsetq_lane_s64 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vld1q_lane_u8 (const uint8_t *__src, uint8x16_t __vec, const int __lane)\n {\n-  return vsetq_lane_u8 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vld1q_lane_u16 (const uint16_t *__src, uint16x8_t __vec, const int __lane)\n {\n-  return vsetq_lane_u16 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vld1q_lane_u32 (const uint32_t *__src, uint32x4_t __vec, const int __lane)\n {\n-  return vsetq_lane_u32 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vld1q_lane_u64 (const uint64_t *__src, uint64x2_t __vec, const int __lane)\n {\n-  return vsetq_lane_u64 (*__src, __vec, __lane);\n+  return __aarch64_vset_lane_any (*__src, __vec, __lane);\n }\n \n /* vldn */"}, {"sha": "e409cec125b4d43cb686423b6d076e9218a9ec28", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2310e29f49d5b2c7fe9c6ec920f79192728d0f87/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2310e29f49d5b2c7fe9c6ec920f79192728d0f87/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=2310e29f49d5b2c7fe9c6ec920f79192728d0f87", "patch": "@@ -1,3 +1,7 @@\n+2014-12-09  Alan Lawrence  <alan.lawrence@arm.com>\n+\n+\t* gcc.target/aarch64/vld1_lane-o0.c: New test.\n+\n 2014-12-09  Alan Lawrence  <alan.lawrence@arm.com>\n \n \t* gcc.target/aarch64/vabs_intrinsic_2.c: New test."}, {"sha": "58e0c9d14a1a136fc62a0c678ffffc6f97043bed", "filename": "gcc/testsuite/gcc.target/aarch64/vld1_lane-o0.c", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2310e29f49d5b2c7fe9c6ec920f79192728d0f87/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvld1_lane-o0.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2310e29f49d5b2c7fe9c6ec920f79192728d0f87/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvld1_lane-o0.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvld1_lane-o0.c?ref=2310e29f49d5b2c7fe9c6ec920f79192728d0f87", "patch": "@@ -0,0 +1,13 @@\n+/* PR/63950 Test bounds checking at -O0.  */\n+\n+/* { dg-options \"-std=c99 -O0\" } */\n+\n+#include <arm_neon.h>\n+\n+int\n+main (int argc, char **argv)\n+{\n+  int16x4_t in = vcreate_s16 (0xdeadbeef00000000ULL);\n+  int16_t src = 17;\n+  int16x4_t out = vld1_lane_s16 (&src, in, 1);\n+}"}]}