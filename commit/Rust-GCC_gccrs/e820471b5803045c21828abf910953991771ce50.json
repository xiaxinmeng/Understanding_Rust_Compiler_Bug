{"sha": "e820471b5803045c21828abf910953991771ce50", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTgyMDQ3MWI1ODAzMDQ1YzIxODI4YWJmOTEwOTUzOTkxNzcxY2U1MA==", "commit": {"author": {"name": "Nathan Sidwell", "email": "nathan@gcc.gnu.org", "date": "2005-04-27T08:47:38Z"}, "committer": {"name": "Nathan Sidwell", "email": "nathan@gcc.gnu.org", "date": "2005-04-27T08:47:38Z"}, "message": "ia64.c (ia64_encode_addr_area): Use gcc_assert and gcc_unreachable as appropriate.\n\n\t* config/ia64/ia64.c (ia64_encode_addr_area): Use gcc_assert and\n\tgcc_unreachable as appropriate.\n\t(ia64_expand_load_address, ia64_expand_tls_address,\n\tia64_split_tmode, ia64_split_tmode_move, ia64_expand_compare,\n\tia64_expand_vecint_compare, ia64_expand_vecint_minmax,\n\tnext_scratch_gr_reg, ia64_initial_elimination_offset,\n\tia64_expand_prologue, ia64_expand_epilogue,\n\tia64_output_dwarf_dtprel, ia64_print_operand,\n\tia64_register_move_cost, first_instruction, rws_access_regno,\n\tupdate_set_flags, rtx_needs_barrier, group_barrier_needed_p,\n\tia64_sched_init, ia64_variable_issue,\n\tia64_first_cycle_multipass_dfs_lookahead_guard,\n\tia64_dfa_new_cycle, issue_nops_and_insn, get_template, bundling,\n\tia64_st_address_bypass_p, ia64_ld_address_bypass_p, process_set,\n\tprocess_for_unwind_directive, ia64_hpux_file_end): Likewise.\n\t* config/ia64/ia64.h (ASM_OUTPUT_ADDR_VEC_ELT): Likewise.\n\t* config/ia64/ia64.md (*arm_movdi_vfp, *movdf_vfp): Likewise.\n\t* config/ia64/predicates.md (got_symbolic_operand,\n\tsdata_symbolic_operand): Likewise.\n\t* config/ia64/vect.md (vcondv2sf): Likewise.\n\nFrom-SVN: r98817", "tree": {"sha": "35f7f8dd36a989926323d3ad4c3366629636b736", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/35f7f8dd36a989926323d3ad4c3366629636b736"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e820471b5803045c21828abf910953991771ce50", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e820471b5803045c21828abf910953991771ce50", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e820471b5803045c21828abf910953991771ce50", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e820471b5803045c21828abf910953991771ce50/comments", "author": null, "committer": null, "parents": [{"sha": "5984f989561b06f42c2b9cd311caad8d7dd68400", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5984f989561b06f42c2b9cd311caad8d7dd68400", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5984f989561b06f42c2b9cd311caad8d7dd68400"}], "stats": {"total": 572, "additions": 278, "deletions": 294}, "files": [{"sha": "368698a40b8a08066f4f291bae8bb01c15e0cf30", "filename": "gcc/ChangeLog", "status": "modified", "additions": 36, "deletions": 16, "changes": 52, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e820471b5803045c21828abf910953991771ce50/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e820471b5803045c21828abf910953991771ce50/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=e820471b5803045c21828abf910953991771ce50", "patch": "@@ -1,39 +1,59 @@\n+2005-04-27  Nathan Sidwell  <nathan@codesourcery.com>\n+\n+\t* config/ia64/ia64.c (ia64_encode_addr_area): Use gcc_assert and\n+\tgcc_unreachable as appropriate.\n+\t(ia64_expand_load_address, ia64_expand_tls_address,\n+\tia64_split_tmode, ia64_split_tmode_move, ia64_expand_compare,\n+\tia64_expand_vecint_compare, ia64_expand_vecint_minmax,\n+\tnext_scratch_gr_reg, ia64_initial_elimination_offset,\n+\tia64_expand_prologue, ia64_expand_epilogue,\n+\tia64_output_dwarf_dtprel, ia64_print_operand,\n+\tia64_register_move_cost, first_instruction, rws_access_regno,\n+\tupdate_set_flags, rtx_needs_barrier, group_barrier_needed_p,\n+\tia64_sched_init, ia64_variable_issue,\n+\tia64_first_cycle_multipass_dfs_lookahead_guard,\n+\tia64_dfa_new_cycle, issue_nops_and_insn, get_template, bundling,\n+\tia64_st_address_bypass_p, ia64_ld_address_bypass_p, process_set,\n+\tprocess_for_unwind_directive, ia64_hpux_file_end): Likewise.\n+\t* config/ia64/ia64.h (ASM_OUTPUT_ADDR_VEC_ELT): Likewise.\n+\t* config/ia64/ia64.md (*arm_movdi_vfp, *movdf_vfp): Likewise.\n+\t* config/ia64/predicates.md (got_symbolic_operand,\n+\tsdata_symbolic_operand): Likewise.\n+\t* config/ia64/vect.md (vcondv2sf): Likewise.\n+\n 2005-04-27  Matt Thomas <matt@3am-software.com>\n \n \t* config/vax/vax.c (legitimate_constant_address_p): New.  Formerly\n-\t\tCONSTANT_ADDRESS_P in config/vax/vax.h\n+\tCONSTANT_ADDRESS_P in config/vax/vax.h\n \t(legitimate_constant_p): Added.  Formerly CONSTANT_P in vax.h. \n \t(INDEX_REGISTER_P): New.\n \t(BASE_REGISTER_P): New.\n \t(indirectable_constant_address_p): New.  Adapted from\n-\t\tINDIRECTABLE_CONSTANT_ADDRESS_P in vax.h.\n-\t\tUse SYMBOL_REF_LOCAL_P.\n+\tINDIRECTABLE_CONSTANT_ADDRESS_P in vax.h. Use SYMBOL_REF_LOCAL_P.\n \t(indirectable_address_p): New.  Adapted from\n-\t\tINDIRECTABLE_ADDRESS_P in vax.h.\n+\tINDIRECTABLE_ADDRESS_P in vax.h.\n \t(nonindexed_address_p): New.  Adapted from\n-\t\tGO_IF_NONINDEXED_ADDRESS in vax.h.\n-\t(index_temp_p): New.  Adapted from\n-\t\tINDEX_TERM_P in vax.h.\n-\t(reg_plus_index_p): New.  Adapted from\n-\t\tGO_IF_REG_PLUS_INDEX in vax.h.\n+\tGO_IF_NONINDEXED_ADDRESS in vax.h.\n+\t(index_temp_p): New.  Adapted from INDEX_TERM_P in vax.h.\n+\t(reg_plus_index_p): New.  Adapted from GO_IF_REG_PLUS_INDEX in vax.h.\n \t(legitimate_address_p): New.  Adapted from\n-\t\tGO_IF_LEGITIMATE_ADDRESS in vax.h\n+\tGO_IF_LEGITIMATE_ADDRESS in vax.h.\n \t(vax_mode_dependent_address_p): New.  Adapted from\n-\t\tGO_IF_MODE_DEPENDENT_ADDRESS in vax.h\n+\tGO_IF_MODE_DEPENDENT_ADDRESS in vax.h.\n \t* config/vax/vax.h (CONSTANT_ADDRESS_P): Use\n-\t\tlegitimate_constant_address_p\n+\tlegitimate_constant_address_p.\n \t(CONSTANT_P): Use legitimate_constant_p.\n \t(INDIRECTABLE_CONSTANT_ADDRESS_P): Removed.\n \t(INDIRECTABLE_ADDRESS_P): Removed.\n \t(GO_IF_NONINDEXED_ADDRESS): Removed.\n \t(INDEX_TEMP_P): Removed.\n \t(GO_IF_REG_PLUS_INDEX): Removed.\n-\t(GO_IF_LEGITIMATE_ADDRESS): Use legitimate_address_p.\n-\t\tTwo definitions, depending on whether REG_OK_STRICT is defined.\n+\t(GO_IF_LEGITIMATE_ADDRESS): Use legitimate_address_p. Two\n+\tdefinitions, depending on whether REG_OK_STRICT is defined.\n \t(GO_IF_MODE_DEPENDENT_ADDRESS): Use vax_mode_dependent_address_p.\n-\t\tTwo definitions, depending on whether REG_OK_STRICT is defined.\n+\tTwo definitions, depending on whether REG_OK_STRICT is defined.\n \t* config/vax/vax-protos.h (legitimate_constant_address_p): Prototype\n-\t\tadded.\n+\tadded.\n \t(legitimate_constant_p): Prototype added.\n \t(legitimate_address_p): Prototype added.\n \t(vax_mode_dependent_address_p): Prototype added."}, {"sha": "77ad73b122a0bf3fc7c35b2285b3554ccf49c272", "filename": "gcc/config/ia64/ia64.c", "status": "modified", "additions": 204, "deletions": 228, "changes": 432, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e820471b5803045c21828abf910953991771ce50/gcc%2Fconfig%2Fia64%2Fia64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e820471b5803045c21828abf910953991771ce50/gcc%2Fconfig%2Fia64%2Fia64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fia64%2Fia64.c?ref=e820471b5803045c21828abf910953991771ce50", "patch": "@@ -532,7 +532,7 @@ ia64_encode_addr_area (tree decl, rtx symbol)\n     {\n     case ADDR_AREA_NORMAL: break;\n     case ADDR_AREA_SMALL: flags |= SYMBOL_FLAG_SMALL_ADDR; break;\n-    default: abort ();\n+    default: gcc_unreachable ();\n     }\n   SYMBOL_REF_FLAGS (symbol) = flags;\n }\n@@ -698,10 +698,8 @@ ia64_depz_field_mask (rtx rop, rtx rshift)\n void\n ia64_expand_load_address (rtx dest, rtx src)\n {\n-  if (GET_CODE (src) == SYMBOL_REF && SYMBOL_REF_TLS_MODEL (src))\n-    abort ();\n-  if (GET_CODE (dest) != REG)\n-    abort ();\n+  gcc_assert (GET_CODE (src) != SYMBOL_REF || !SYMBOL_REF_TLS_MODEL (src));\n+  gcc_assert (GET_CODE (dest) == REG);\n \n   /* ILP32 mode still loads 64-bits of data from the GOT.  This avoids\n      having to pointer-extend the value afterward.  Other forms of address\n@@ -870,7 +868,7 @@ ia64_expand_tls_address (enum tls_model tls_kind, rtx op0, rtx op1)\n       break;\n \n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n \n   if (orig_op0 == op0)\n@@ -950,7 +948,7 @@ ia64_split_tmode (rtx out[2], rtx in, bool reversed, bool dead)\n     case CONST_INT:\n     case CONST_DOUBLE:\n       /* Cannot occur reversed.  */\n-      if (reversed) abort ();\n+      gcc_assert (!reversed);\n       \n       if (GET_MODE (in) != TFmode)\n \tsplit_double (in, &out[0], &out[1]);\n@@ -1007,14 +1005,16 @@ ia64_split_tmode (rtx out[2], rtx in, bool reversed, bool dead)\n \t    break;\n \n \t  case POST_INC:\n-\t    if (reversed || dead) abort ();\n+\t    gcc_assert (!reversed && !dead);\n+\t    \n \t    /* Just do the increment in two steps.  */\n \t    out[0] = adjust_automodify_address (in, DImode, 0, 0);\n \t    out[1] = adjust_automodify_address (in, DImode, 0, 8);\n \t    break;\n \n \t  case POST_DEC:\n-\t    if (reversed || dead) abort ();\n+\t    gcc_assert (!reversed && !dead);\n+\t    \n \t    /* Add 8, subtract 24.  */\n \t    base = XEXP (base, 0);\n \t    out[0] = adjust_automodify_address\n@@ -1026,7 +1026,8 @@ ia64_split_tmode (rtx out[2], rtx in, bool reversed, bool dead)\n \t    break;\n \n \t  case POST_MODIFY:\n-\t    if (reversed || dead) abort ();\n+\t    gcc_assert (!reversed && !dead);\n+\n \t    /* Extract and adjust the modification.  This case is\n \t       trickier than the others, because we might have an\n \t       index register, or we might have a combined offset that\n@@ -1045,38 +1046,41 @@ ia64_split_tmode (rtx out[2], rtx in, bool reversed, bool dead)\n \t\tout[1] = adjust_automodify_address (in, DImode, 0, 8);\n \t\tfixup = gen_adddi3 (base, base, GEN_INT (-8));\n \t      }\n-\t    else if (GET_CODE (XEXP (offset, 1)) != CONST_INT)\n-\t      abort ();\n-\t    else if (INTVAL (XEXP (offset, 1)) < -256 + 8)\n-\t      {\n-\t\t/* Again the postmodify cannot be made to match, but\n-\t\t   in this case it's more efficient to get rid of the\n-\t\t   postmodify entirely and fix up with an add insn.  */\n-\t\tout[1] = adjust_automodify_address (in, DImode, base, 8);\n-\t\tfixup = gen_adddi3 (base, base,\n-\t\t\t\t    GEN_INT (INTVAL (XEXP (offset, 1)) - 8));\n-\t      }\n \t    else\n \t      {\n-\t\t/* Combined offset still fits in the displacement field.\n-\t\t   (We cannot overflow it at the high end.)  */\n-\t\tout[1] = adjust_automodify_address\n-\t\t  (in, DImode,\n-\t\t   gen_rtx_POST_MODIFY (Pmode, base,\n-\t\t     gen_rtx_PLUS (Pmode, base,\n-\t\t\t\t   GEN_INT (INTVAL (XEXP (offset, 1)) - 8))),\n-\t\t   8);\n+\t\tgcc_assert (GET_CODE (XEXP (offset, 1)) == CONST_INT);\n+\t\tif (INTVAL (XEXP (offset, 1)) < -256 + 8)\n+\t\t  {\n+\t\t    /* Again the postmodify cannot be made to match,\n+\t\t       but in this case it's more efficient to get rid\n+\t\t       of the postmodify entirely and fix up with an\n+\t\t       add insn.  */\n+\t\t    out[1] = adjust_automodify_address (in, DImode, base, 8);\n+\t\t    fixup = gen_adddi3\n+\t\t      (base, base, GEN_INT (INTVAL (XEXP (offset, 1)) - 8));\n+\t\t  }\n+\t\telse\n+\t\t  {\n+\t\t    /* Combined offset still fits in the displacement field.\n+\t\t       (We cannot overflow it at the high end.)  */\n+\t\t    out[1] = adjust_automodify_address\n+\t\t      (in, DImode, gen_rtx_POST_MODIFY\n+\t\t       (Pmode, base, gen_rtx_PLUS\n+\t\t\t(Pmode, base,\n+\t\t\t GEN_INT (INTVAL (XEXP (offset, 1)) - 8))),\n+\t\t       8);\n+\t\t  }\n \t      }\n \t    break;\n \n \t  default:\n-\t    abort ();\n+\t    gcc_unreachable ();\n \t  }\n \tbreak;\n       }\n \n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n \n   return fixup;\n@@ -1096,7 +1100,7 @@ ia64_split_tmode_move (rtx operands[])\n      the value it points to.  In that case we have to do the loads in\n      the appropriate order so that the pointer is not destroyed too\n      early.  Also we must not generate a postmodify for that second\n-     load, or rws_access_regno will abort.  */\n+     load, or rws_access_regno will die.  */\n   if (GET_CODE (operands[1]) == MEM\n       && reg_overlap_mentioned_p (operands[0], operands[1]))\n     {\n@@ -1189,10 +1193,8 @@ ia64_expand_compare (enum rtx_code code, enum machine_mode mode)\n      do not need to emit another comparison.  */\n   if (GET_MODE (op0) == BImode)\n     {\n-      if ((code == NE || code == EQ) && op1 == const0_rtx)\n-\tcmp = op0;\n-      else\n-\tabort ();\n+      gcc_assert ((code == NE || code == EQ) && op1 == const0_rtx);\n+      cmp = op0;\n     }\n   /* HPUX TFmode compare requires a library call to _U_Qfcmp, which takes a\n      magic number as its third argument, that indicates what to do.\n@@ -1208,8 +1210,8 @@ ia64_expand_compare (enum rtx_code code, enum machine_mode mode)\n       } magic;\n       enum rtx_code ncode;\n       rtx ret, insns;\n-      if (!cmptf_libfunc || GET_MODE (op1) != TFmode)\n-\tabort ();\n+      \n+      gcc_assert (cmptf_libfunc && GET_MODE (op1) == TFmode);\n       switch (code)\n \t{\n \t  /* 1 = equal, 0 = not equal.  Equality operators do\n@@ -1228,7 +1230,7 @@ ia64_expand_compare (enum rtx_code code, enum machine_mode mode)\n \t  /* FUTURE: Implement UNEQ, UNLT, UNLE, UNGT, UNGE, LTGT.\n \t     Expanders for buneq etc. weuld have to be added to ia64.md\n \t     for this to be useful.  */\n-\tdefault: abort ();\n+\tdefault: gcc_unreachable ();\n \t}\n \n       start_sequence ();\n@@ -1309,24 +1311,26 @@ ia64_expand_vecint_compare (enum rtx_code code, enum machine_mode mode,\n \t/* We don't have native unsigned comparisons, but we can generate\n \t   them better than generic code can.  */\n \n-\tif (mode == V2SImode)\n-\t  abort ();\n-\telse if (mode == V8QImode)\n+\tgcc_assert (mode != V2SImode);\n+\tswitch (mode)\n \t  {\n+\t  case V8QImode:\n \t    wmode = V4HImode;\n \t    pack = gen_pack2_sss;\n \t    unpack_l = gen_unpack1_l;\n \t    unpack_h = gen_unpack1_h;\n-\t  }\n-\telse if (mode == V4HImode)\n-\t  {\n+\t    break;\n+\n+\t  case V4HImode:\n \t    wmode = V2SImode;\n \t    pack = gen_pack4_sss;\n \t    unpack_l = gen_unpack2_l;\n \t    unpack_h = gen_unpack2_h;\n+\t    break;\n+\n+\t  default:\n+\t    gcc_unreachable ();\n \t  }\n-\telse\n-\t  abort ();\n \n \t/* Unpack into wider vectors, zero extending the elements.  */\n \n@@ -1354,7 +1358,7 @@ ia64_expand_vecint_compare (enum rtx_code code, enum machine_mode mode,\n       return negate;\n \n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n \n   x = gen_rtx_fmt_ee (code, mode, op0, op1);\n@@ -1509,7 +1513,7 @@ ia64_expand_vecint_minmax (enum rtx_code code, enum machine_mode mode,\n       code = GT;\n       break;\n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n   xops[3] = gen_rtx_fmt_ee (code, VOIDmode, operands[1], operands[2]);\n \n@@ -1774,7 +1778,7 @@ next_scratch_gr_reg (void)\n     }\n \n   /* There must be _something_ available.  */\n-  abort ();\n+  gcc_unreachable ();\n }\n \n /* Helper function for ia64_compute_frame_size, called through\n@@ -2071,39 +2075,49 @@ ia64_initial_elimination_offset (int from, int to)\n   switch (from)\n     {\n     case FRAME_POINTER_REGNUM:\n-      if (to == HARD_FRAME_POINTER_REGNUM)\n+      switch (to)\n \t{\n+\tcase HARD_FRAME_POINTER_REGNUM:\n \t  if (current_function_is_leaf)\n \t    offset = -current_frame_info.total_size;\n \t  else\n \t    offset = -(current_frame_info.total_size\n \t\t       - current_function_outgoing_args_size - 16);\n-\t}\n-      else if (to == STACK_POINTER_REGNUM)\n-\t{\n+\t  break;\n+\n+\tcase STACK_POINTER_REGNUM:\n \t  if (current_function_is_leaf)\n \t    offset = 0;\n \t  else\n \t    offset = 16 + current_function_outgoing_args_size;\n+\t  break;\n+\n+\tdefault:\n+\t  gcc_unreachable ();\n \t}\n-      else\n-\tabort ();\n       break;\n \n     case ARG_POINTER_REGNUM:\n       /* Arguments start above the 16 byte save area, unless stdarg\n \t in which case we store through the 16 byte save area.  */\n-      if (to == HARD_FRAME_POINTER_REGNUM)\n-\toffset = 16 - current_function_pretend_args_size;\n-      else if (to == STACK_POINTER_REGNUM)\n-\toffset = (current_frame_info.total_size\n-\t\t  + 16 - current_function_pretend_args_size);\n-      else\n-\tabort ();\n+      switch (to)\n+\t{\n+\tcase HARD_FRAME_POINTER_REGNUM:\n+\t  offset = 16 - current_function_pretend_args_size;\n+\t  break;\n+\n+\tcase STACK_POINTER_REGNUM:\n+\t  offset = (current_frame_info.total_size\n+\t\t    + 16 - current_function_pretend_args_size);\n+\t  break;\n+\n+\tdefault:\n+\t  gcc_unreachable ();\n+\t}\n       break;\n \n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n \n   return offset;\n@@ -2649,9 +2663,8 @@ ia64_expand_prologue (void)\n     }\n \n   /* We should now be at the base of the gr/br/fr spill area.  */\n-  if (cfa_off != (current_frame_info.spill_cfa_off\n-\t\t  + current_frame_info.spill_size))\n-    abort ();\n+  gcc_assert (cfa_off == (current_frame_info.spill_cfa_off\n+\t\t\t  + current_frame_info.spill_size));\n \n   /* Spill all general registers.  */\n   for (regno = GR_REG (1); regno <= GR_REG (31); ++regno)\n@@ -2704,15 +2717,13 @@ ia64_expand_prologue (void)\n   for (regno = FR_REG (2); regno <= FR_REG (127); ++regno)\n     if (TEST_HARD_REG_BIT (current_frame_info.mask, regno))\n       {\n-        if (cfa_off & 15)\n-\t  abort ();\n+        gcc_assert (!(cfa_off & 15));\n \treg = gen_rtx_REG (XFmode, regno);\n \tdo_spill (gen_fr_spill_x, reg, cfa_off, reg);\n \tcfa_off -= 16;\n       }\n \n-  if (cfa_off != current_frame_info.spill_cfa_off)\n-    abort ();\n+  gcc_assert (cfa_off == current_frame_info.spill_cfa_off);\n \n   finish_spill_pointers ();\n }\n@@ -2824,9 +2835,8 @@ ia64_expand_epilogue (int sibcall_p)\n     }\n \n   /* We should now be at the base of the gr/br/fr spill area.  */\n-  if (cfa_off != (current_frame_info.spill_cfa_off\n-\t\t  + current_frame_info.spill_size))\n-    abort ();\n+  gcc_assert (cfa_off == (current_frame_info.spill_cfa_off\n+\t\t\t  + current_frame_info.spill_size));\n \n   /* The GP may be stored on the stack in the prologue, but it's\n      never restored in the epilogue.  Skip the stack slot.  */\n@@ -2874,8 +2884,7 @@ ia64_expand_epilogue (int sibcall_p)\n   for (regno = FR_REG (2); regno <= FR_REG (127); ++regno)\n     if (TEST_HARD_REG_BIT (current_frame_info.mask, regno))\n       {\n-        if (cfa_off & 15)\n-\t  abort ();\n+        gcc_assert (!(cfa_off & 15));\n \treg = gen_rtx_REG (XFmode, regno);\n \tdo_restore (gen_fr_restore_x, reg, cfa_off);\n \tcfa_off -= 16;\n@@ -2888,8 +2897,7 @@ ia64_expand_epilogue (int sibcall_p)\n       emit_move_insn (reg, ar_unat_save_reg);\n     }\n \n-  if (cfa_off != current_frame_info.spill_cfa_off)\n-    abort ();\n+  gcc_assert (cfa_off == current_frame_info.spill_cfa_off);\n \n   finish_spill_pointers ();\n \n@@ -3931,8 +3939,7 @@ ia64_function_value (tree valtype, tree func ATTRIBUTE_UNUSED)\n void\n ia64_output_dwarf_dtprel (FILE *file, int size, rtx x)\n {\n-  if (size != 8)\n-    abort ();\n+  gcc_assert (size == 8);\n   fputs (\"\\tdata8.ua\\t@dtprel(\", file);\n   output_addr_const (file, x);\n   fputs (\")\", file);\n@@ -4021,10 +4028,11 @@ ia64_print_operand (FILE * file, rtx x, int code)\n \tstr = reg_names [FR_REG (0)];\n       else if (x == CONST1_RTX (GET_MODE (x)))\n \tstr = reg_names [FR_REG (1)];\n-      else if (GET_CODE (x) == REG)\n-\tstr = reg_names [REGNO (x)];\n       else\n-\tabort ();\n+\t{\n+\t  gcc_assert (GET_CODE (x) == REG);\n+\t  str = reg_names [REGNO (x)];\n+\t}\n       fputs (str, file);\n       return;\n \n@@ -4062,13 +4070,12 @@ ia64_print_operand (FILE * file, rtx x, int code)\n \t    x = XEXP (XEXP (XEXP (x, 0), 1), 1);\n \t    if (GET_CODE (x) == CONST_INT)\n \t      value = INTVAL (x);\n-\t    else if (GET_CODE (x) == REG)\n+\t    else\n \t      {\n+\t\tgcc_assert (GET_CODE (x) == REG);\n \t\tfprintf (file, \", %s\", reg_names[REGNO (x)]);\n \t\treturn;\n \t      }\n-\t    else\n-\t      abort ();\n \t    break;\n \n \t  case POST_INC:\n@@ -4350,7 +4357,7 @@ ia64_register_move_cost (enum machine_mode mode, enum reg_class from,\n       break;\n \n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n \n   return 2;\n@@ -4753,8 +4760,8 @@ struct reg_write_state rws_sum[NUM_REGS];\n struct reg_write_state rws_insn[NUM_REGS];\n \n /* Indicates whether this is the first instruction after a stop bit,\n-   in which case we don't need another stop bit.  Without this, we hit\n-   the abort in ia64_variable_issue when scheduling an alloc.  */\n+   in which case we don't need another stop bit.  Without this,\n+   ia64_variable_issue will die when scheduling an alloc.  */\n static int first_instruction;\n \n /* Misc flags needed to compute RAW/WAW dependencies while we are traversing\n@@ -4805,8 +4812,7 @@ rws_access_regno (int regno, struct reg_flags flags, int pred)\n {\n   int need_barrier = 0;\n \n-  if (regno >= NUM_REGS)\n-    abort ();\n+  gcc_assert (regno < NUM_REGS);\n \n   if (! PR_REGNO_P (regno))\n     flags.is_and = flags.is_or = 0;\n@@ -4816,8 +4822,7 @@ rws_access_regno (int regno, struct reg_flags flags, int pred)\n       int write_count;\n \n       /* One insn writes same reg multiple times?  */\n-      if (rws_insn[regno].write_count > 0)\n-\tabort ();\n+      gcc_assert (!rws_insn[regno].write_count);\n \n       /* Update info for current instruction.  */\n       rws_update (rws_insn, regno, flags, pred);\n@@ -4858,7 +4863,7 @@ rws_access_regno (int regno, struct reg_flags flags, int pred)\n \t  break;\n \n \tdefault:\n-\t  abort ();\n+\t  gcc_unreachable ();\n \t}\n     }\n   else\n@@ -4911,7 +4916,7 @@ rws_access_regno (int regno, struct reg_flags flags, int pred)\n \t  break;\n \n \tdefault:\n-\t  abort ();\n+\t  gcc_unreachable ();\n \t}\n     }\n \n@@ -4963,9 +4968,8 @@ update_set_flags (rtx x, struct reg_flags *pflags, int *ppred, rtx *pcond)\n \t  if (GET_CODE (cond) == EQ)\n \t    is_complemented = 1;\n \t  cond = XEXP (cond, 0);\n-\t  if (GET_CODE (cond) != REG\n-\t      && REGNO_REG_CLASS (REGNO (cond)) != PR_REGS)\n-\t    abort ();\n+\t  gcc_assert (GET_CODE (cond) == REG\n+\t\t      || REGNO_REG_CLASS (REGNO (cond)) == PR_REGS);\n \t  *pcond = cond;\n \t  if (XEXP (src, 1) == SET_DEST (x)\n \t      || XEXP (src, 2) == SET_DEST (x))\n@@ -5089,7 +5093,7 @@ rtx_needs_barrier (rtx x, struct reg_flags flags, int pred)\n       need_barrier |= rws_access_regno (AR_EC_REGNUM, new_flags, pred);\n \n       /* Avoid multiple register writes, in case this is a pattern with\n-\t multiple CALL rtx.  This avoids an abort in rws_access_reg.  */\n+\t multiple CALL rtx.  This avoids a failure in rws_access_reg.  */\n       if (! flags.is_sibcall && ! rws_insn[REG_AR_CFM].write_count)\n \t{\n \t  new_flags.is_write = 1;\n@@ -5103,16 +5107,14 @@ rtx_needs_barrier (rtx x, struct reg_flags flags, int pred)\n       /* X is a predicated instruction.  */\n \n       cond = COND_EXEC_TEST (x);\n-      if (pred)\n-\tabort ();\n+      gcc_assert (!pred);\n       need_barrier = rtx_needs_barrier (cond, flags, 0);\n \n       if (GET_CODE (cond) == EQ)\n \tis_complemented = 1;\n       cond = XEXP (cond, 0);\n-      if (GET_CODE (cond) != REG\n-\t  && REGNO_REG_CLASS (REGNO (cond)) != PR_REGS)\n-\tabort ();\n+      gcc_assert (GET_CODE (cond) == REG\n+\t\t  || REGNO_REG_CLASS (REGNO (cond)) == PR_REGS);\n       pred = REGNO (cond);\n       if (is_complemented)\n \t++pred;\n@@ -5133,7 +5135,7 @@ rtx_needs_barrier (rtx x, struct reg_flags flags, int pred)\n \t  || (MEM_VOLATILE_P (x) && TARGET_VOL_ASM_STOP))\n \t{\n \t  /* Avoid writing the register multiple times if we have multiple\n-\t     asm outputs.  This avoids an abort in rws_access_reg.  */\n+\t     asm outputs.  This avoids a failure in rws_access_reg.  */\n \t  if (! rws_insn[REG_VOLATILE].write_count)\n \t    {\n \t      new_flags.is_write = 1;\n@@ -5220,8 +5222,7 @@ rtx_needs_barrier (rtx x, struct reg_flags flags, int pred)\n \n       /* Operators with side-effects.  */\n     case POST_INC:    case POST_DEC:\n-      if (GET_CODE (XEXP (x, 0)) != REG)\n-\tabort ();\n+      gcc_assert (GET_CODE (XEXP (x, 0)) == REG);\n \n       new_flags.is_write = 0;\n       need_barrier  = rws_access_reg (XEXP (x, 0), new_flags, pred);\n@@ -5230,8 +5231,7 @@ rtx_needs_barrier (rtx x, struct reg_flags flags, int pred)\n       break;\n \n     case POST_MODIFY:\n-      if (GET_CODE (XEXP (x, 0)) != REG)\n-\tabort ();\n+      gcc_assert (GET_CODE (XEXP (x, 0)) == REG);\n \n       new_flags.is_write = 0;\n       need_barrier  = rws_access_reg (XEXP (x, 0), new_flags, pred);\n@@ -5262,7 +5262,7 @@ rtx_needs_barrier (rtx x, struct reg_flags flags, int pred)\n       /* VEC_SELECT's second argument is a PARALLEL with integers that\n \t describe the elements selected.  On ia64, those integers are\n \t always constants.  Avoid walking the PARALLEL so that we don't\n-\t get confused with \"normal\" parallels and abort.  */\n+\t get confused with \"normal\" parallels and then die.  */\n       need_barrier = rtx_needs_barrier (XEXP (x, 0), flags, pred);\n       break;\n \n@@ -5318,7 +5318,7 @@ rtx_needs_barrier (rtx x, struct reg_flags flags, int pred)\n \t  break;\n \n \tdefault:\n-\t  abort ();\n+\t  gcc_unreachable ();\n \t}\n       break;\n \n@@ -5351,7 +5351,7 @@ rtx_needs_barrier (rtx x, struct reg_flags flags, int pred)\n \t  return 0;\n \n \tdefault:\n-\t  abort ();\n+\t  gcc_unreachable ();\n \t}\n       break;\n \n@@ -5390,7 +5390,7 @@ rtx_needs_barrier (rtx x, struct reg_flags flags, int pred)\n \t    break;\n \n \t  default:\n-\t    abort ();\n+\t    gcc_unreachable ();\n \t  }\n       break;\n     }\n@@ -5505,7 +5505,7 @@ group_barrier_needed_p (rtx insn)\n       break;\n \n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n \n   if (first_instruction && INSN_P (insn)\n@@ -5861,8 +5861,7 @@ ia64_sched_init (FILE *dump ATTRIBUTE_UNUSED,\n     for (insn = NEXT_INSN (current_sched_info->prev_head);\n \t insn != current_sched_info->next_tail;\n \t insn = NEXT_INSN (insn))\n-      if (SCHED_GROUP_P (insn))\n-\tabort ();\n+      gcc_assert (!SCHED_GROUP_P (insn));\n #endif\n   last_scheduled_insn = NULL_RTX;\n   init_insn_group_barriers ();\n@@ -5994,8 +5993,9 @@ ia64_variable_issue (FILE *dump ATTRIBUTE_UNUSED,\n   memcpy (prev_cycle_state, curr_state, dfa_state_size);\n   if (reload_completed)\n     {\n-      if (group_barrier_needed_p (insn))\n-\tabort ();\n+      int needed = group_barrier_needed_p (insn);\n+      \n+      gcc_assert (!needed);\n       if (GET_CODE (insn) == CALL_INSN)\n \tinit_insn_group_barriers ();\n       stops_p [INSN_UID (insn)] = stop_before_p;\n@@ -6010,8 +6010,7 @@ ia64_variable_issue (FILE *dump ATTRIBUTE_UNUSED,\n static int\n ia64_first_cycle_multipass_dfa_lookahead_guard (rtx insn)\n {\n-  if (insn == NULL_RTX || !INSN_P (insn))\n-    abort ();\n+  gcc_assert (insn  && INSN_P (insn));\n   return (!reload_completed\n \t  || !safe_group_barrier_needed_p (insn));\n }\n@@ -6032,8 +6031,7 @@ ia64_dfa_new_cycle (FILE *dump, int verbose, rtx insn, int last_clock,\n {\n   int setup_clocks_p = FALSE;\n \n-  if (insn == NULL_RTX || !INSN_P (insn))\n-    abort ();\n+  gcc_assert (insn && INSN_P (insn));\n   if ((reload_completed && safe_group_barrier_needed_p (insn))\n       || (last_scheduled_insn\n \t  && (GET_CODE (last_scheduled_insn) == CALL_INSN\n@@ -6361,12 +6359,10 @@ issue_nops_and_insn (struct bundle_state *originator, int before_nops_num,\n   curr_state->accumulated_insns_num\n     = originator->accumulated_insns_num + before_nops_num;\n   curr_state->branch_deviation = originator->branch_deviation;\n-  if (insn == NULL_RTX)\n-    abort ();\n-  else if (INSN_CODE (insn) == CODE_FOR_insn_group_barrier)\n+  gcc_assert (insn);\n+  if (INSN_CODE (insn) == CODE_FOR_insn_group_barrier)\n     {\n-      if (GET_MODE (insn) == TImode)\n-\tabort ();\n+      gcc_assert (GET_MODE (insn) != TImode);\n       if (!try_issue_nops (curr_state, before_nops_num))\n \treturn;\n       if (!try_issue_insn (curr_state, insn))\n@@ -6386,9 +6382,9 @@ issue_nops_and_insn (struct bundle_state *originator, int before_nops_num,\n       if (!try_issue_insn (curr_state, insn))\n \treturn;\n       curr_state->accumulated_insns_num++;\n-      if (GET_CODE (PATTERN (insn)) == ASM_INPUT\n-\t  || asm_noperands (PATTERN (insn)) >= 0)\n-\tabort ();\n+      gcc_assert (GET_CODE (PATTERN (insn)) != ASM_INPUT\n+\t\t  && asm_noperands (PATTERN (insn)) < 0);\n+\n       if (ia64_safe_type (insn) == TYPE_L)\n \tcurr_state->accumulated_insns_num++;\n     }\n@@ -6518,7 +6514,7 @@ get_template (state_t state, int pos)\n       else if (cpu_unit_reservation_p (state, _0mlx_))\n \treturn 9;\n       else\n-\tabort ();\n+\tgcc_unreachable ();\n     case 6:\n       if (cpu_unit_reservation_p (state, _1mmi_))\n \treturn 1;\n@@ -6541,9 +6537,9 @@ get_template (state_t state, int pos)\n       else if (cpu_unit_reservation_p (state, _1mlx_))\n \treturn 9;\n       else\n-\tabort ();\n+\tgcc_unreachable ();\n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n }\n \n@@ -6669,11 +6665,10 @@ bundling (FILE *dump, int verbose, rtx prev_head_insn, rtx tail)\n        insn != NULL_RTX;\n        insn = next_insn)\n     {\n-      if (!INSN_P (insn)\n-\t  || ia64_safe_itanium_class (insn) == ITANIUM_CLASS_IGNORE\n-\t  || GET_CODE (PATTERN (insn)) == USE\n-\t  || GET_CODE (PATTERN (insn)) == CLOBBER)\n-\tabort ();\n+      gcc_assert (INSN_P (insn)\n+\t\t  && ia64_safe_itanium_class (insn) != ITANIUM_CLASS_IGNORE\n+\t\t  && GET_CODE (PATTERN (insn)) != USE\n+\t\t  && GET_CODE (PATTERN (insn)) != CLOBBER);\n       type = ia64_safe_type (insn);\n       next_insn = get_next_important_insn (NEXT_INSN (insn), tail);\n       insn_num++;\n@@ -6713,8 +6708,7 @@ bundling (FILE *dump, int verbose, rtx prev_head_insn, rtx tail)\n \t  issue_nops_and_insn (curr_state, 0, insn, bundle_end_p,\n \t\t\t       only_bundle_end_p);\n \t}\n-      if (index_to_bundle_states [insn_num] == NULL)\n-\tabort ();\n+      gcc_assert (index_to_bundle_states [insn_num]);\n       for (curr_state = index_to_bundle_states [insn_num];\n \t   curr_state != NULL;\n \t   curr_state = curr_state->next)\n@@ -6747,10 +6741,10 @@ bundling (FILE *dump, int verbose, rtx prev_head_insn, rtx tail)\n \t       INSN_UID (insn));\n \t  }\n     }\n-  if (index_to_bundle_states [insn_num] == NULL)\n-    /* We should find a solution because the 2nd insn scheduling has\n-       found one.  */\n-    abort ();\n+  \n+  /* We should find a solution because the 2nd insn scheduling has\n+     found one.  */\n+  gcc_assert (index_to_bundle_states [insn_num]);\n   /* Find a state corresponding to the best insn sequence.  */\n   best_state = NULL;\n   for (curr_state = index_to_bundle_states [insn_num];\n@@ -6828,8 +6822,7 @@ bundling (FILE *dump, int verbose, rtx prev_head_insn, rtx tail)\n       if (max_pos > 3 && template1 < 0)\n \t/* It may happen when we have the stop inside a bundle.  */\n \t{\n-\t  if (pos > 3)\n-\t    abort ();\n+\t  gcc_assert (pos <= 3);\n \t  template1 = get_template (curr_state->dfa_state, 3);\n \t  pos += 3;\n \t}\n@@ -6840,14 +6833,12 @@ bundling (FILE *dump, int verbose, rtx prev_head_insn, rtx tail)\n \t    nop = gen_nop ();\n \t    emit_insn_after (nop, insn);\n \t    pos--;\n-\t    if (pos < 0)\n-\t      abort ();\n+\t    gcc_assert (pos >= 0);\n \t    if (pos % 3 == 0)\n \t      {\n \t\t/* We are at the start of a bundle: emit the template\n \t\t   (it should be defined).  */\n-\t\tif (template0 < 0)\n-\t\t  abort ();\n+\t\tgcc_assert (template0 >= 0);\n \t\tb = gen_bundle_selector (GEN_INT (template0));\n \t\tia64_emit_insn_before (b, nop);\n \t\t/* If we have two bundle window, we make one bundle\n@@ -6866,17 +6857,15 @@ bundling (FILE *dump, int verbose, rtx prev_head_insn, rtx tail)\n       /* Long insn takes 2 slots.  */\n       if (ia64_safe_type (insn) == TYPE_L)\n \tpos--;\n-      if (pos < 0)\n-\tabort ();\n+      gcc_assert (pos >= 0);\n       if (pos % 3 == 0\n \t  && INSN_CODE (insn) != CODE_FOR_insn_group_barrier\n \t  && GET_CODE (PATTERN (insn)) != ASM_INPUT\n \t  && asm_noperands (PATTERN (insn)) < 0)\n \t{\n \t  /* The current insn is at the bundle start: emit the\n \t     template.  */\n-\t  if (template0 < 0)\n-\t    abort ();\n+\t  gcc_assert (template0 >= 0);\n \t  b = gen_bundle_selector (GEN_INT (template0));\n \t  ia64_emit_insn_before (b, insn);\n \t  b = PREV_INSN (insn);\n@@ -6894,14 +6883,12 @@ bundling (FILE *dump, int verbose, rtx prev_head_insn, rtx tail)\n \t  nop = PREV_INSN (insn);\n \t  insn = nop;\n \t  pos--;\n-\t  if (pos < 0)\n-\t    abort ();\n+\t  gcc_assert (pos >= 0);\n \t  if (pos % 3 == 0)\n \t    {\n \t      /* See comment above in analogous place for emitting nops\n \t\t after the insn.  */\n-\t      if (template0 < 0)\n-\t\tabort ();\n+\t      gcc_assert (template0 >= 0);\n \t      b = gen_bundle_selector (GEN_INT (template0));\n \t      ia64_emit_insn_before (b, insn);\n \t      b = PREV_INSN (insn);\n@@ -6921,11 +6908,10 @@ bundling (FILE *dump, int verbose, rtx prev_head_insn, rtx tail)\n \t insn != NULL_RTX;\n \t insn = next_insn)\n       {\n-\tif (!INSN_P (insn)\n-\t    || ia64_safe_itanium_class (insn) == ITANIUM_CLASS_IGNORE\n-\t    || GET_CODE (PATTERN (insn)) == USE\n-\t    || GET_CODE (PATTERN (insn)) == CLOBBER)\n-\t  abort ();\n+\tgcc_assert (INSN_P (insn)\n+\t\t    && ia64_safe_itanium_class (insn) != ITANIUM_CLASS_IGNORE\n+\t\t    && GET_CODE (PATTERN (insn)) != USE\n+\t\t    && GET_CODE (PATTERN (insn)) != CLOBBER);\n \tnext_insn = get_next_important_insn (NEXT_INSN (insn), tail);\n \tif (INSN_UID (insn) < clocks_length && add_cycles [INSN_UID (insn)])\n \t  /* We found a MM-insn which needs additional cycles.  */\n@@ -6963,9 +6949,9 @@ bundling (FILE *dump, int verbose, rtx prev_head_insn, rtx tail)\n \t       bundle start, there are no more 3 insns in the bundle,\n \t       and the MM-insn is not at the start of bundle with\n \t       template MLX.  */\n-\t    if ((pred_stop_p && n == 0) || n > 2\n-\t\t|| (template0 == 9 && n != 0))\n-\t      abort ();\n+\t    gcc_assert ((!pred_stop_p || n)\n+\t\t\t&& n <= 2\n+\t\t\t&& (template0 != 9 || !n));\n \t    /* Put nops after the insn in the bundle.  */\n \t    for (j = 3 - n; j > 0; j --)\n \t      ia64_emit_insn_before (gen_nop (), insn);\n@@ -7170,18 +7156,19 @@ ia64_st_address_bypass_p (rtx producer, rtx consumer)\n {\n   rtx dest, reg, mem;\n \n-  if (producer == NULL_RTX || consumer == NULL_RTX)\n-    abort ();\n+  gcc_assert (producer && consumer);\n   dest = ia64_single_set (producer);\n-  if (dest == NULL_RTX || (reg = SET_DEST (dest)) == NULL_RTX\n-      || (GET_CODE (reg) != REG && GET_CODE (reg) != SUBREG))\n-    abort ();\n+  gcc_assert (dest);\n+  reg = SET_DEST (dest);\n+  gcc_assert (reg);\n   if (GET_CODE (reg) == SUBREG)\n     reg = SUBREG_REG (reg);\n+  gcc_assert (GET_CODE (reg) == REG);\n+  \n   dest = ia64_single_set (consumer);\n-  if (dest == NULL_RTX || (mem = SET_DEST (dest)) == NULL_RTX\n-      || GET_CODE (mem) != MEM)\n-    abort ();\n+  gcc_assert (dest);\n+  mem = SET_DEST (dest);\n+  gcc_assert (mem && GET_CODE (mem) == MEM);\n   return reg_mentioned_p (reg, mem);\n }\n \n@@ -7193,25 +7180,26 @@ ia64_ld_address_bypass_p (rtx producer, rtx consumer)\n {\n   rtx dest, src, reg, mem;\n \n-  if (producer == NULL_RTX || consumer == NULL_RTX)\n-    abort ();\n+  gcc_assert (producer && consumer);\n   dest = ia64_single_set (producer);\n-  if (dest == NULL_RTX || (reg = SET_DEST (dest)) == NULL_RTX\n-      || (GET_CODE (reg) != REG && GET_CODE (reg) != SUBREG))\n-    abort ();\n+  gcc_assert (dest);\n+  reg = SET_DEST (dest);\n+  gcc_assert (reg);\n   if (GET_CODE (reg) == SUBREG)\n     reg = SUBREG_REG (reg);\n+  gcc_assert (GET_CODE (reg) == REG);\n+  \n   src = ia64_single_set (consumer);\n-  if (src == NULL_RTX || (mem = SET_SRC (src)) == NULL_RTX)\n-    abort ();\n+  gcc_assert (src);\n+  mem = SET_SRC (src);\n+  gcc_assert (mem);\n   if (GET_CODE (mem) == UNSPEC && XVECLEN (mem, 0) > 0)\n     mem = XVECEXP (mem, 0, 0);\n   while (GET_CODE (mem) == SUBREG || GET_CODE (mem) == ZERO_EXTEND)\n     mem = XEXP (mem, 0);\n \n   /* Note that LO_SUM is used for GOT loads.  */\n-  if (GET_CODE (mem) != LO_SUM && GET_CODE (mem) != MEM)\n-    abort ();\n+  gcc_assert (GET_CODE (mem) == LO_SUM || GET_CODE (mem) == MEM);\n \n   return reg_mentioned_p (reg, mem);\n }\n@@ -7619,22 +7607,21 @@ process_set (FILE *asm_out_file, rtx pat)\n         {\n \t  rtx op0 = XEXP (src, 0);\n \t  rtx op1 = XEXP (src, 1);\n-\t  if (op0 == dest && GET_CODE (op1) == CONST_INT)\n-\t    {\n-\t      if (INTVAL (op1) < 0)\n-\t\tfprintf (asm_out_file, \"\\t.fframe \"HOST_WIDE_INT_PRINT_DEC\"\\n\",\n-\t\t\t -INTVAL (op1));\n-\t      else\n-\t\tprocess_epilogue ();\n-\t    }\n+\t  \n+\t  gcc_assert (op0 == dest && GET_CODE (op1) == CONST_INT);\n+\t  \n+\t  if (INTVAL (op1) < 0)\n+\t    fprintf (asm_out_file, \"\\t.fframe \"HOST_WIDE_INT_PRINT_DEC\"\\n\",\n+\t\t     -INTVAL (op1));\n \t  else\n-\t    abort ();\n+\t    process_epilogue ();\n \t}\n-      else if (GET_CODE (src) == REG\n-\t       && REGNO (src) == HARD_FRAME_POINTER_REGNUM)\n-\tprocess_epilogue ();\n       else\n-\tabort ();\n+\t{\n+\t  gcc_assert (GET_CODE (src) == REG\n+\t\t      && REGNO (src) == HARD_FRAME_POINTER_REGNUM);\n+\t  process_epilogue ();\n+\t}\n \n       return 1;\n     }\n@@ -7649,44 +7636,39 @@ process_set (FILE *asm_out_file, rtx pat)\n \t{\n \tcase BR_REG (0):\n \t  /* Saving return address pointer.  */\n-\t  if (dest_regno != current_frame_info.reg_save_b0)\n-\t    abort ();\n+\t  gcc_assert (dest_regno == current_frame_info.reg_save_b0);\n \t  fprintf (asm_out_file, \"\\t.save rp, r%d\\n\",\n \t\t   ia64_dbx_register_number (dest_regno));\n \t  return 1;\n \n \tcase PR_REG (0):\n-\t  if (dest_regno != current_frame_info.reg_save_pr)\n-\t    abort ();\n+\t  gcc_assert (dest_regno == current_frame_info.reg_save_pr);\n \t  fprintf (asm_out_file, \"\\t.save pr, r%d\\n\",\n \t\t   ia64_dbx_register_number (dest_regno));\n \t  return 1;\n \n \tcase AR_UNAT_REGNUM:\n-\t  if (dest_regno != current_frame_info.reg_save_ar_unat)\n-\t    abort ();\n+\t  gcc_assert (dest_regno == current_frame_info.reg_save_ar_unat);\n \t  fprintf (asm_out_file, \"\\t.save ar.unat, r%d\\n\",\n \t\t   ia64_dbx_register_number (dest_regno));\n \t  return 1;\n \n \tcase AR_LC_REGNUM:\n-\t  if (dest_regno != current_frame_info.reg_save_ar_lc)\n-\t    abort ();\n+\t  gcc_assert (dest_regno == current_frame_info.reg_save_ar_lc);\n \t  fprintf (asm_out_file, \"\\t.save ar.lc, r%d\\n\",\n \t\t   ia64_dbx_register_number (dest_regno));\n \t  return 1;\n \n \tcase STACK_POINTER_REGNUM:\n-\t  if (dest_regno != HARD_FRAME_POINTER_REGNUM\n-\t      || ! frame_pointer_needed)\n-\t    abort ();\n+\t  gcc_assert (dest_regno == HARD_FRAME_POINTER_REGNUM\n+\t\t      && frame_pointer_needed);\n \t  fprintf (asm_out_file, \"\\t.vframe r%d\\n\",\n \t\t   ia64_dbx_register_number (dest_regno));\n \t  return 1;\n \n \tdefault:\n \t  /* Everything else should indicate being stored to memory.  */\n-\t  abort ();\n+\t  gcc_unreachable ();\n \t}\n     }\n \n@@ -7702,55 +7684,50 @@ process_set (FILE *asm_out_file, rtx pat)\n \t  base = XEXP (dest, 0);\n \t  off = 0;\n \t}\n-      else if (GET_CODE (XEXP (dest, 0)) == PLUS\n-\t       && GET_CODE (XEXP (XEXP (dest, 0), 1)) == CONST_INT)\n+      else\n \t{\n+\t  gcc_assert (GET_CODE (XEXP (dest, 0)) == PLUS\n+\t\t      && GET_CODE (XEXP (XEXP (dest, 0), 1)) == CONST_INT);\n \t  base = XEXP (XEXP (dest, 0), 0);\n \t  off = INTVAL (XEXP (XEXP (dest, 0), 1));\n \t}\n-      else\n-\tabort ();\n \n       if (base == hard_frame_pointer_rtx)\n \t{\n \t  saveop = \".savepsp\";\n \t  off = - off;\n \t}\n-      else if (base == stack_pointer_rtx)\n-\tsaveop = \".savesp\";\n       else\n-\tabort ();\n+\t{\n+\t  gcc_assert (base == stack_pointer_rtx);\n+\t  saveop = \".savesp\";\n+\t}\n \n       src_regno = REGNO (src);\n       switch (src_regno)\n \t{\n \tcase BR_REG (0):\n-\t  if (current_frame_info.reg_save_b0 != 0)\n-\t    abort ();\n+\t  gcc_assert (!current_frame_info.reg_save_b0);\n \t  fprintf (asm_out_file, \"\\t%s rp, %ld\\n\", saveop, off);\n \t  return 1;\n \n \tcase PR_REG (0):\n-\t  if (current_frame_info.reg_save_pr != 0)\n-\t    abort ();\n+\t  gcc_assert (!current_frame_info.reg_save_pr);\n \t  fprintf (asm_out_file, \"\\t%s pr, %ld\\n\", saveop, off);\n \t  return 1;\n \n \tcase AR_LC_REGNUM:\n-\t  if (current_frame_info.reg_save_ar_lc != 0)\n-\t    abort ();\n+\t  gcc_assert (!current_frame_info.reg_save_ar_lc);\n \t  fprintf (asm_out_file, \"\\t%s ar.lc, %ld\\n\", saveop, off);\n \t  return 1;\n \n \tcase AR_PFS_REGNUM:\n-\t  if (current_frame_info.reg_save_ar_pfs != 0)\n-\t    abort ();\n+\t  gcc_assert (!current_frame_info.reg_save_ar_pfs);\n \t  fprintf (asm_out_file, \"\\t%s ar.pfs, %ld\\n\", saveop, off);\n \t  return 1;\n \n \tcase AR_UNAT_REGNUM:\n-\t  if (current_frame_info.reg_save_ar_unat != 0)\n-\t    abort ();\n+\t  gcc_assert (!current_frame_info.reg_save_ar_unat);\n \t  fprintf (asm_out_file, \"\\t%s ar.unat, %ld\\n\", saveop, off);\n \t  return 1;\n \n@@ -7850,7 +7827,7 @@ process_for_unwind_directive (FILE *asm_out_file, rtx insn)\n \t  }\n \n \tdefault:\n-\t  abort ();\n+\t  gcc_unreachable ();\n \t}\n     }\n }\n@@ -7990,8 +7967,7 @@ ia64_hpux_file_end (void)\n       tree decl = p->decl;\n       tree id = DECL_ASSEMBLER_NAME (decl);\n \n-      if (!id)\n-\tabort ();\n+      gcc_assert (id);\n \n       if (!TREE_ASM_WRITTEN (decl) && TREE_SYMBOL_REFERENCED (id))\n         {"}, {"sha": "362064af9e203de1cafb10ba5696ca40e96c1c56", "filename": "gcc/config/ia64/ia64.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e820471b5803045c21828abf910953991771ce50/gcc%2Fconfig%2Fia64%2Fia64.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e820471b5803045c21828abf910953991771ce50/gcc%2Fconfig%2Fia64%2Fia64.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fia64%2Fia64.h?ref=e820471b5803045c21828abf910953991771ce50", "patch": "@@ -1796,7 +1796,7 @@ do {\t\t\t\t\t\t\t\t\t\\\n /* This is how to output an element of a case-vector that is absolute.\n    (Ia64 does not use such vectors, but we must define this macro anyway.)  */\n \n-#define ASM_OUTPUT_ADDR_VEC_ELT(STREAM, VALUE) abort ()\n+#define ASM_OUTPUT_ADDR_VEC_ELT(STREAM, VALUE) gcc_unreachable ()\n \n /* Jump tables only need 8 byte alignment.  */\n "}, {"sha": "a1353f4e70a3860067f7ac1bb6d2b7d280490371", "filename": "gcc/config/ia64/ia64.md", "status": "modified", "additions": 34, "deletions": 46, "changes": 80, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e820471b5803045c21828abf910953991771ce50/gcc%2Fconfig%2Fia64%2Fia64.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e820471b5803045c21828abf910953991771ce50/gcc%2Fconfig%2Fia64%2Fia64.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fia64%2Fia64.md?ref=e820471b5803045c21828abf910953991771ce50", "patch": "@@ -363,9 +363,8 @@\n     \"mov pr = %1, -1\"\n   };\n \n-  if (which_alternative == 2 && ! TARGET_NO_PIC\n-      && symbolic_operand (operands[1], VOIDmode))\n-    abort ();\n+  gcc_assert (which_alternative != 2 || TARGET_NO_PIC\n+              || !symbolic_operand (operands[1], VOIDmode));\n \n   return alt[which_alternative];\n }\n@@ -700,10 +699,11 @@\n \n   if (GET_CODE (op0) == REG && GR_REGNO_P (REGNO (op0)))\n     {\n+      rtx out[2];\n+\n       /* We're hoping to transform everything that deals with XFmode\n \t quantities and GR registers early in the compiler.  */\n-      if (no_new_pseudos)\n-\tabort ();\n+      gcc_assert (!no_new_pseudos);\n \n       /* Struct to register can just use TImode instead.  */\n       if ((GET_CODE (operands[1]) == SUBREG\n@@ -735,27 +735,21 @@\n       if (register_operand (operands[1], XFmode))\n \toperands[1] = spill_xfmode_operand (operands[1], 1);\n \n-      if (GET_CODE (operands[1]) == MEM)\n-\t{\n-\t  rtx out[2];\n-\n-\t  out[WORDS_BIG_ENDIAN] = gen_rtx_REG (DImode, REGNO (op0));\n-\t  out[!WORDS_BIG_ENDIAN] = gen_rtx_REG (DImode, REGNO (op0) + 1);\n+      gcc_assert (GET_CODE (operands[1]) == MEM);\n \n-\t  emit_move_insn (out[0], adjust_address (operands[1], DImode, 0));\n-\t  emit_move_insn (out[1], adjust_address (operands[1], DImode, 8));\n-\t  DONE;\n-\t}\n+      out[WORDS_BIG_ENDIAN] = gen_rtx_REG (DImode, REGNO (op0));\n+      out[!WORDS_BIG_ENDIAN] = gen_rtx_REG (DImode, REGNO (op0) + 1);\n \n-      abort ();\n+      emit_move_insn (out[0], adjust_address (operands[1], DImode, 0));\n+      emit_move_insn (out[1], adjust_address (operands[1], DImode, 8));\n+      DONE;\n     }\n \n   if (GET_CODE (operands[1]) == REG && GR_REGNO_P (REGNO (operands[1])))\n     {\n       /* We're hoping to transform everything that deals with XFmode\n \t quantities and GR registers early in the compiler.  */\n-      if (no_new_pseudos)\n-\tabort ();\n+      gcc_assert (!no_new_pseudos);\n \n       /* Op0 can't be a GR_REG here, as that case is handled above.\n \t If op0 is a register, then we spill op1, so that we now have a\n@@ -768,20 +762,18 @@\n \t  operands[1] = spill_xfmode_operand (op1, 0);\n \t}\n \n-      else if (GET_CODE (operands[0]) == MEM)\n+      else\n \t{\n \t  rtx in[2];\n \n+          gcc_assert (GET_CODE (operands[0]) == MEM);\n \t  in[WORDS_BIG_ENDIAN] = gen_rtx_REG (DImode, REGNO (operands[1]));\n \t  in[!WORDS_BIG_ENDIAN] = gen_rtx_REG (DImode, REGNO (operands[1]) + 1);\n \n \t  emit_move_insn (adjust_address (operands[0], DImode, 0), in[0]);\n \t  emit_move_insn (adjust_address (operands[0], DImode, 8), in[1]);\n \t  DONE;\n \t}\n-\n-      else\n-\tabort ();\n     }\n \n   if (! reload_in_progress && ! reload_completed)\n@@ -2825,14 +2817,14 @@\n   \"TARGET_INLINE_SQRT\"\n {\n   rtx insn;\n-  if (TARGET_INLINE_SQRT == INL_MIN_LAT)\n #if 0\n+  if (TARGET_INLINE_SQRT == INL_MIN_LAT)\n     insn = gen_sqrtsf2_internal_lat (operands[0], operands[1]);\n+  else\n #else\n-    abort ();\n+  gcc_assert (TARGET_INLINE_SQRT != INL_MIN_LAT);\n #endif\n-  else\n-    insn = gen_sqrtsf2_internal_thr (operands[0], operands[1]);\n+  insn = gen_sqrtsf2_internal_thr (operands[0], operands[1]);\n   emit_insn (insn);\n   DONE;\n })\n@@ -3323,14 +3315,14 @@\n   \"TARGET_INLINE_SQRT\"\n {\n   rtx insn;\n-  if (TARGET_INLINE_SQRT == INL_MIN_LAT)\n #if 0\n+  if (TARGET_INLINE_SQRT == INL_MIN_LAT)\n     insn = gen_sqrtdf2_internal_lat (operands[0], operands[1]);\n+  else\n #else\n-    abort ();\n+  gcc_assert (TARGET_INLINE_SQRT != INL_MIN_LAT);\n #endif\n-  else\n-    insn = gen_sqrtdf2_internal_thr (operands[0], operands[1]);\n+  insn = gen_sqrtdf2_internal_thr (operands[0], operands[1]);\n   emit_insn (insn);\n   DONE;\n })\n@@ -3998,14 +3990,14 @@\n   \"TARGET_INLINE_SQRT\"\n {\n   rtx insn;\n-  if (TARGET_INLINE_SQRT == INL_MIN_LAT)\n #if 0\n+  if (TARGET_INLINE_SQRT == INL_MIN_LAT)\n     insn = gen_sqrtxf2_internal_lat (operands[0], operands[1]);\n+  else\n #else\n-    abort ();\n+  gcc_assert (TARGET_INLINE_SQRT != INL_MIN_LAT);\n #endif\n-  else\n-    insn = gen_sqrtxf2_internal_thr (operands[0], operands[1]);\n+  insn = gen_sqrtxf2_internal_thr (operands[0], operands[1]);\n   emit_insn (insn);\n   DONE;\n })\n@@ -4351,7 +4343,7 @@\n \t\t\t  (match_operand:DI 3 \"nonmemory_operand\" \"r\"))\n \t\t (match_operand:DI 4 \"nonmemory_operand\" \"rI\")))]\n   \"reload_in_progress\"\n-  \"* abort ();\"\n+  \"* gcc_unreachable ();\"\n   \"reload_completed\"\n   [(set (match_dup 0) (plus:DI (mult:DI (match_dup 1) (match_dup 2))\n \t\t\t       (match_dup 3)))\n@@ -5103,7 +5095,7 @@\n \t   \"rim,rim,rim, rim, *f, *b,*d*e,*f,*b,*d*e,rO,*f,rOQ,rO,  rK\")))]\n   \"ia64_move_ok (operands[0], operands[2])\n    && ia64_move_ok (operands[0], operands[3])\"\n-  { abort (); }\n+  { gcc_unreachable (); }\n   [(set_attr \"predicable\" \"no\")])\n \n (define_split\n@@ -5206,7 +5198,7 @@\n \t\t    \"rim*f,rO,rO,0,0,0,rim*f,rO,rO\")))]\n   \"ia64_move_ok (operands[0], operands[2])\n    && ia64_move_ok (operands[0], operands[3])\"\n-  { abort (); }\n+  { gcc_unreachable (); }\n   [(set_attr \"predicable\" \"no\")])\n \n (define_insn \"*abssi2_internal\"\n@@ -5605,12 +5597,10 @@\n       start_sequence ();\n       set = single_set (last);\n \n-      if (! rtx_equal_p (SET_DEST (set), op0)\n-\t  || GET_CODE (SET_SRC (set)) != MEM)\n-\tabort ();\n+      gcc_assert (rtx_equal_p (SET_DEST (set), op0)\n+\t\t  && GET_CODE (SET_SRC (set)) == MEM);\n       addr = XEXP (SET_SRC (set), 0);\n-      if (rtx_equal_p (addr, op0))\n-\tabort ();\n+      gcc_assert (!rtx_equal_p (addr, op0));\n     }\n \n   /* Jump table elements are stored pc-relative.  That is, a displacement\n@@ -5958,10 +5948,8 @@\n   int i = (INTVAL (operands[1]));\n   int j = (INTVAL (operands[2]));\n \n-  if (i != 0 && i != 1)\n-    abort ();\n-  if (j < 0 || j > 3)\n-    abort ();\n+  gcc_assert (i == 0 || i == 1);\n+  gcc_assert (j >= 0 && j <= 3);\n   return alt[i][j];\n }\n   [(set_attr \"itanium_class\" \"lfetch\")])"}, {"sha": "554dc79c95f6ec64931d4537ca0ae2800b1d71a1", "filename": "gcc/config/ia64/predicates.md", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e820471b5803045c21828abf910953991771ce50/gcc%2Fconfig%2Fia64%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e820471b5803045c21828abf910953991771ce50/gcc%2Fconfig%2Fia64%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fia64%2Fpredicates.md?ref=e820471b5803045c21828abf910953991771ce50", "patch": "@@ -66,7 +66,7 @@\n       return (INTVAL (op) & 0x3fff) == 0;\n \n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n })\n \n@@ -125,7 +125,7 @@\n       return (offset >= 0 && offset <= size);\n \n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n })\n "}, {"sha": "07e86f9f1717c1132c8ae64a42847d31248b3de2", "filename": "gcc/config/ia64/vect.md", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e820471b5803045c21828abf910953991771ce50/gcc%2Fconfig%2Fia64%2Fvect.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e820471b5803045c21828abf910953991771ce50/gcc%2Fconfig%2Fia64%2Fvect.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fia64%2Fvect.md?ref=e820471b5803045c21828abf910953991771ce50", "patch": "@@ -893,7 +893,7 @@\n       break;\n \n     default:\n-      abort ();\n+      gcc_unreachable ();\n     }\n \n   cmp = gen_reg_rtx (V2SFmode);"}]}