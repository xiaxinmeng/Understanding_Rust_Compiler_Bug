{"sha": "c956e102dfffb7d5fa5e6051a2b35f146ca9c52b", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Yzk1NmUxMDJkZmZmYjdkNWZhNWU2MDUxYTJiMzVmMTQ2Y2E5YzUyYg==", "commit": {"author": {"name": "Mark Shinwell", "email": "shinwell@codesourcery.com", "date": "2007-07-26T12:04:02Z"}, "committer": {"name": "Julian Brown", "email": "jules@gcc.gnu.org", "date": "2007-07-26T12:04:02Z"}, "message": "arm.c (arm_mac_accumulator_is_mul_result): New.\n\n\tgcc/\n\t* config/arm/arm.c (arm_mac_accumulator_is_mul_result): New.\n\t* config/arm/arm-protos.h (arm_mac_accumulator_is_mul_result): New.\n\t* config/arm/cortex-a8.md: New.\n\t* config/arm/cortex-a8-neon.md: New.\n\t* config/arm/neon-schedgen.ml: New.\n\t* config/arm/neon.md (vqh_mnem): New.\n\t(neon_type): New.\n\t(Is_float_mode): New.\n\t(Scalar_mul_8_16): New.\n\t(Is_d_reg): New.\n\t(V_mode_nunits): New.\n\t(All instruction patterns): Annotate with neon_type attribute\n\tvalues.\n\t* config/arm/arm.md: Include cortex-a8.md.\n\t(insn): Add smmla, umaal, smlald, smlsld, clz, mrs, msr and xtab\n\tvalues.\n\tAnnotate instruction patterns accordingly.\n\t(generic_sched): Do not use generic scheduling for Cortex-A8.\n\t(generic_vfp): Do not use generic VFP scheduling for Cortex-A8.\n\n\nCo-Authored-By: Julian Brown <julian@codesourcery.com>\n\nFrom-SVN: r126953", "tree": {"sha": "715d427a46736ff2867acdd2b0f98dfad208453e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/715d427a46736ff2867acdd2b0f98dfad208453e"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/comments", "author": null, "committer": null, "parents": [{"sha": "0c4d4efbde93c9d91498cfa4aea427c31f9426ef", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0c4d4efbde93c9d91498cfa4aea427c31f9426ef", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0c4d4efbde93c9d91498cfa4aea427c31f9426ef"}], "stats": {"total": 3424, "additions": 3209, "deletions": 215}, "files": [{"sha": "aa1e9d30fcf58b4ce902d748ca80e109cbbbfc1c", "filename": "gcc/ChangeLog", "status": "modified", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=c956e102dfffb7d5fa5e6051a2b35f146ca9c52b", "patch": "@@ -1,3 +1,26 @@\n+2007-07-26  Mark Shinwell  <shinwell@codesourcery.com>\n+\t    Julian Brown  <julian@codesourcery.com>\n+\n+\t* config/arm/arm.c (arm_mac_accumulator_is_mul_result): New.\n+\t* config/arm/arm-protos.h (arm_mac_accumulator_is_mul_result): New.\n+\t* config/arm/cortex-a8.md: New.\n+\t* config/arm/cortex-a8-neon.md: New.\n+\t* config/arm/neon-schedgen.ml: New.\n+\t* config/arm/neon.md (vqh_mnem): New.\n+\t(neon_type): New.\n+\t(Is_float_mode): New.\n+\t(Scalar_mul_8_16): New.\n+\t(Is_d_reg): New.\n+\t(V_mode_nunits): New.\n+\t(All instruction patterns): Annotate with neon_type attribute\n+\tvalues.\n+\t* config/arm/arm.md: Include cortex-a8.md.\n+\t(insn): Add smmla, umaal, smlald, smlsld, clz, mrs, msr and xtab\n+\tvalues.\n+\tAnnotate instruction patterns accordingly.\n+\t(generic_sched): Do not use generic scheduling for Cortex-A8.\n+\t(generic_vfp): Do not use generic VFP scheduling for Cortex-A8.\n+\n 2007-07-26  Daniel Jacobowitz  <dan@codesourcery.com>\n \n \t* fold-const.c (fold_read_from_constant_string): Use"}, {"sha": "f2380264eee6239c2d0e994c12b7f7bc8fa272e1", "filename": "gcc/config/arm/arm-protos.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2Fconfig%2Farm%2Farm-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2Fconfig%2Farm%2Farm-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm-protos.h?ref=c956e102dfffb7d5fa5e6051a2b35f146ca9c52b", "patch": "@@ -94,6 +94,7 @@ extern int arm_no_early_store_addr_dep (rtx, rtx);\n extern int arm_no_early_alu_shift_dep (rtx, rtx);\n extern int arm_no_early_alu_shift_value_dep (rtx, rtx);\n extern int arm_no_early_mul_dep (rtx, rtx);\n+extern int arm_mac_accumulator_is_mul_result (rtx, rtx);\n \n extern int tls_mentioned_p (rtx);\n extern int symbol_mentioned_p (rtx);"}, {"sha": "de0fb41c3094c4394eceb369bd6f33d884056776", "filename": "gcc/config/arm/arm.c", "status": "modified", "additions": 33, "deletions": 0, "changes": 33, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2Fconfig%2Farm%2Farm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2Fconfig%2Farm%2Farm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.c?ref=c956e102dfffb7d5fa5e6051a2b35f146ca9c52b", "patch": "@@ -18167,6 +18167,39 @@ arm_cxx_guard_type (void)\n   return TARGET_AAPCS_BASED ? integer_type_node : long_long_integer_type_node;\n }\n \n+/* Return non-zero if the consumer (a multiply-accumulate instruction)\n+   has an accumulator dependency on the result of the producer (a\n+   multiplication instruction) and no other dependency on that result.  */\n+int\n+arm_mac_accumulator_is_mul_result (rtx producer, rtx consumer)\n+{\n+  rtx mul = PATTERN (producer);\n+  rtx mac = PATTERN (consumer);\n+  rtx mul_result;\n+  rtx mac_op0, mac_op1, mac_acc;\n+\n+  if (GET_CODE (mul) == COND_EXEC)\n+    mul = COND_EXEC_CODE (mul);\n+  if (GET_CODE (mac) == COND_EXEC)\n+    mac = COND_EXEC_CODE (mac);\n+\n+  /* Check that mul is of the form (set (...) (mult ...))\n+     and mla is of the form (set (...) (plus (mult ...) (...))).  */\n+  if ((GET_CODE (mul) != SET || GET_CODE (XEXP (mul, 1)) != MULT)\n+      || (GET_CODE (mac) != SET || GET_CODE (XEXP (mac, 1)) != PLUS\n+          || GET_CODE (XEXP (XEXP (mac, 1), 0)) != MULT))\n+    return 0;\n+\n+  mul_result = XEXP (mul, 0);\n+  mac_op0 = XEXP (XEXP (XEXP (mac, 1), 0), 0);\n+  mac_op1 = XEXP (XEXP (XEXP (mac, 1), 0), 1);\n+  mac_acc = XEXP (XEXP (mac, 1), 1);\n+\n+  return (reg_overlap_mentioned_p (mul_result, mac_acc)\n+          && !reg_overlap_mentioned_p (mul_result, mac_op0)\n+          && !reg_overlap_mentioned_p (mul_result, mac_op1));\n+}\n+\n \n /* The EABI says test the least significant bit of a guard variable.  */\n "}, {"sha": "1d5313e409f8f474ca059b0f10bc29ed19f06765", "filename": "gcc/config/arm/arm.md", "status": "modified", "additions": 10, "deletions": 5, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2Fconfig%2Farm%2Farm.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2Fconfig%2Farm%2Farm.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.md?ref=c956e102dfffb7d5fa5e6051a2b35f146ca9c52b", "patch": "@@ -184,7 +184,7 @@\n ;; scheduling information.\n \n (define_attr \"insn\"\n-        \"smulxy,smlaxy,smlalxy,smulwy,smlawx,mul,muls,mla,mlas,umull,umulls,umlal,umlals,smull,smulls,smlal,smlals,smlawy,smuad,smuadx,smlad,smladx,smusd,smusdx,smlsd,smlsdx,smmul,smmulr,other\"\n+        \"mov,mvn,smulxy,smlaxy,smlalxy,smulwy,smlawx,mul,muls,mla,mlas,umull,umulls,umlal,umlals,smull,smulls,smlal,smlals,smlawy,smuad,smuadx,smlad,smladx,smusd,smusdx,smlsd,smlsdx,smmul,smmulr,smmla,umaal,smlald,smlsld,clz,mrs,msr,xtab,other\"\n         (const_string \"other\"))\n \n ; TYPE attribute is used to detect floating point instructions which, if\n@@ -235,8 +235,9 @@\n ; mav_farith\tFloating point arithmetic (4 cycle)\n ; mav_dmult\tDouble multiplies (7 cycle)\n ;\n+\n (define_attr \"type\"\n-\t\"alu,alu_shift,alu_shift_reg,mult,block,float,fdivx,fdivd,fdivs,fmul,ffmul,farith,ffarith,f_flag,float_em,f_load,f_store,f_loads,f_loadd,f_stores,f_stored,f_mem_r,r_mem_f,f_2_r,r_2_f,f_cvt,branch,call,load_byte,load1,load2,load3,load4,store1,store2,store3,store4,mav_farith,mav_dmult\" \n+\t\"alu,alu_shift,alu_shift_reg,mult,block,float,fdivx,fdivd,fdivs,fmul,fmuls,fmuld,fmacs,fmacd,ffmul,farith,ffarith,f_flag,float_em,f_load,f_store,f_loads,f_loadd,f_stores,f_stored,f_mem_r,r_mem_f,f_2_r,r_2_f,f_cvt,branch,call,load_byte,load1,load2,load3,load4,store1,store2,store3,store4,mav_farith,mav_dmult\"\n \t(if_then_else \n \t (eq_attr \"insn\" \"smulxy,smlaxy,smlalxy,smulwy,smlawx,mul,muls,mla,mlas,umull,umulls,umlal,umlals,smull,smulls,smlal,smlals\")\n \t (const_string \"mult\")\n@@ -332,14 +333,14 @@\n \n (define_attr \"generic_sched\" \"yes,no\"\n   (const (if_then_else \n-          (eq_attr \"tune\" \"arm926ejs,arm1020e,arm1026ejs,arm1136js,arm1136jfs\") \n+          (eq_attr \"tune\" \"arm926ejs,arm1020e,arm1026ejs,arm1136js,arm1136jfs,cortexa8\")\n           (const_string \"no\")\n           (const_string \"yes\"))))\n \n (define_attr \"generic_vfp\" \"yes,no\"\n   (const (if_then_else\n \t  (and (eq_attr \"fpu\" \"vfp\")\n-\t       (eq_attr \"tune\" \"!arm1020e,arm1022e\"))\n+\t       (eq_attr \"tune\" \"!arm1020e,arm1022e,cortexa8\"))\n \t  (const_string \"yes\")\n \t  (const_string \"no\"))))\n \n@@ -348,6 +349,7 @@\n (include \"arm1020e.md\")\n (include \"arm1026ejs.md\")\n (include \"arm1136jfs.md\")\n+(include \"cortex-a8.md\")\n \n \f\n ;;---------------------------------------------------------------------------\n@@ -3869,6 +3871,7 @@\n   \"TARGET_INT_SIMD\"\n   \"uxtab%?\\\\t%0, %2, %1\"\n   [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"insn\" \"xtab\")\n    (set_attr \"type\" \"alu_shift\")]\n )\n \n@@ -4242,6 +4245,7 @@\n   \"TARGET_INT_SIMD\"\n   \"sxtab%?\\\\t%0, %2, %1\"\n   [(set_attr \"type\" \"alu_shift\")\n+   (set_attr \"insn\" \"xtab\")\n    (set_attr \"predicable\" \"yes\")]\n )\n \n@@ -10772,7 +10776,8 @@\n \t(clz:SI (match_operand:SI 1 \"s_register_operand\" \"r\")))]\n   \"TARGET_32BIT && arm_arch5\"\n   \"clz%?\\\\t%0, %1\"\n-  [(set_attr \"predicable\" \"yes\")])\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"insn\" \"clz\")])\n \n (define_expand \"ffssi2\"\n   [(set (match_operand:SI 0 \"s_register_operand\" \"\")"}, {"sha": "ed97ed18a7defe68f79697b1bc5ac0e4768805be", "filename": "gcc/config/arm/cortex-a8-neon.md", "status": "added", "additions": 1307, "deletions": 0, "changes": 1307, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2Fconfig%2Farm%2Fcortex-a8-neon.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2Fconfig%2Farm%2Fcortex-a8-neon.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fcortex-a8-neon.md?ref=c956e102dfffb7d5fa5e6051a2b35f146ca9c52b", "patch": "@@ -0,0 +1,1307 @@\n+;; ARM Cortex-A8 NEON scheduling description.\n+;; Copyright (C) 2007 Free Software Foundation, Inc.\n+;; Contributed by CodeSourcery.\n+\n+;; This file is part of GCC.\n+\n+;; GCC is distributed in the hope that it will be useful, but WITHOUT\n+;; ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n+;; or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public\n+;; License for more details.\n+\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING.  If not, write to\n+;; the Free Software Foundation, 51 Franklin Street, Fifth Floor,\n+;; Boston, MA 02110-1301, USA.\n+\n+(define_automaton \"cortex_a8_neon\")\n+\n+;; Only one load, store, permute, MCR or MRC instruction can be issued\n+;; per cycle.\n+(define_cpu_unit \"cortex_a8_neon_issue_perm\" \"cortex_a8_neon\")\n+\n+;; Only one data-processing instruction can be issued per cycle.\n+(define_cpu_unit \"cortex_a8_neon_issue_dp\" \"cortex_a8_neon\")\n+\n+;; The VFPLite unit (non-pipelined).\n+(define_cpu_unit \"cortex_a8_vfplite\" \"cortex_a8_neon\")\n+\n+;; We need a special mutual exclusion (to be used in addition to\n+;; cortex_a8_neon_issue_dp) for the case when an instruction such as\n+;; vmla.f is forwarded from E5 of the floating-point multiply pipeline to\n+;; E2 of the floating-point add pipeline.  On the cycle previous to that\n+;; forward we must prevent issue of any instruction to the floating-point\n+;; add pipeline, but still allow issue of a data-processing instruction\n+;; to any of the other pipelines.\n+(define_cpu_unit \"cortex_a8_neon_issue_fadd\" \"cortex_a8_neon\")\n+\n+;; Patterns of reservation.\n+;; We model the NEON issue units as running in parallel with the core ones.\n+;; We assume that multi-cycle NEON instructions get decomposed into\n+;; micro-ops as they are issued into the NEON pipeline, and not as they\n+;; are issued into the ARM pipeline.  Dual issue may not occur except\n+;; upon the first and last cycles of a multi-cycle instruction, but it\n+;; is unclear whether two multi-cycle instructions can issue together (in\n+;; this model they cannot).  It is also unclear whether a pair of\n+;; a multi-cycle and single-cycle instructions, that could potentially\n+;; issue together, only do so if (say) the single-cycle one precedes\n+;; the other.\n+\n+(define_reservation \"cortex_a8_neon_dp\"\n+                    \"(cortex_a8_alu0|cortex_a8_alu1)+cortex_a8_neon_issue_dp\")\n+(define_reservation \"cortex_a8_neon_dp_2\"\n+                    \"(cortex_a8_alu0|cortex_a8_alu1)+cortex_a8_neon_issue_dp,\\\n+                     cortex_a8_neon_issue_dp\")\n+(define_reservation \"cortex_a8_neon_dp_4\"\n+                    \"(cortex_a8_alu0|cortex_a8_alu1)+cortex_a8_neon_issue_dp,\\\n+                     cortex_a8_neon_issue_dp+cortex_a8_neon_issue_perm,\\\n+                     cortex_a8_neon_issue_dp+cortex_a8_neon_issue_perm,\\\n+                     cortex_a8_neon_issue_dp\")\n+\n+(define_reservation \"cortex_a8_neon_fadd\"\n+                    \"(cortex_a8_alu0|cortex_a8_alu1)+cortex_a8_neon_issue_dp+\\\n+                     cortex_a8_neon_issue_fadd\")\n+(define_reservation \"cortex_a8_neon_fadd_2\"\n+                    \"(cortex_a8_alu0|cortex_a8_alu1)+cortex_a8_neon_issue_dp+\\\n+                     cortex_a8_neon_issue_fadd,\\\n+                     cortex_a8_neon_issue_dp+cortex_a8_neon_issue_fadd\")\n+\n+(define_reservation \"cortex_a8_neon_perm\"\n+                    \"(cortex_a8_alu0|cortex_a8_alu1)+\\\n+                     cortex_a8_neon_issue_perm\")\n+(define_reservation \"cortex_a8_neon_perm_2\"\n+                    \"(cortex_a8_alu0|cortex_a8_alu1)+\\\n+                     cortex_a8_neon_issue_perm,\\\n+                     cortex_a8_neon_issue_perm\")\n+(define_reservation \"cortex_a8_neon_perm_3\"\n+                    \"(cortex_a8_alu0|cortex_a8_alu1)+\\\n+                     cortex_a8_neon_issue_perm,\\\n+                     cortex_a8_neon_issue_dp+cortex_a8_neon_issue_perm,\\\n+                     cortex_a8_neon_issue_perm\")\n+\n+(define_reservation \"cortex_a8_neon_ls\"\n+                    \"cortex_a8_issue_ls+cortex_a8_neon_issue_perm\")\n+(define_reservation \"cortex_a8_neon_ls_2\"\n+                    \"cortex_a8_issue_ls+cortex_a8_neon_issue_perm,\\\n+                     cortex_a8_neon_issue_perm\")\n+(define_reservation \"cortex_a8_neon_ls_3\"\n+                    \"cortex_a8_issue_ls+cortex_a8_neon_issue_perm,\\\n+                     cortex_a8_neon_issue_dp+cortex_a8_neon_issue_perm,\\\n+                     cortex_a8_neon_issue_perm\")\n+(define_reservation \"cortex_a8_neon_ls_4\"\n+                    \"cortex_a8_issue_ls+cortex_a8_neon_issue_perm,\\\n+                     cortex_a8_neon_issue_dp+cortex_a8_neon_issue_perm,\\\n+                     cortex_a8_neon_issue_dp+cortex_a8_neon_issue_perm,\\\n+                     cortex_a8_neon_issue_perm\")\n+(define_reservation \"cortex_a8_neon_ls_5\"\n+                    \"cortex_a8_issue_ls+cortex_a8_neon_issue_perm,\\\n+                     cortex_a8_neon_issue_dp+cortex_a8_neon_issue_perm,\\\n+                     cortex_a8_neon_issue_dp+cortex_a8_neon_issue_perm,\\\n+                     cortex_a8_neon_issue_dp+cortex_a8_neon_issue_perm,\\\n+                     cortex_a8_neon_issue_perm\")\n+\n+(define_reservation \"cortex_a8_neon_fmul_then_fadd\"\n+                    \"(cortex_a8_alu0|cortex_a8_alu1)+cortex_a8_neon_issue_dp,\\\n+\t\t     nothing*3,\\\n+\t\t     cortex_a8_neon_issue_fadd\")\n+(define_reservation \"cortex_a8_neon_fmul_then_fadd_2\"\n+                    \"(cortex_a8_alu0|cortex_a8_alu1)+cortex_a8_neon_issue_dp,\\\n+\t\t     cortex_a8_neon_issue_dp,\\\n+\t\t     nothing*2,\\\n+\t\t     cortex_a8_neon_issue_fadd,\\\n+\t\t     cortex_a8_neon_issue_fadd\")\n+\n+;; VFP instructions can only be single-issued into the NEON pipeline.\n+(define_reservation \"cortex_a8_vfp\"\n+                    \"(cortex_a8_alu0|cortex_a8_alu1)+cortex_a8_neon_issue_dp+\\\n+                     cortex_a8_neon_issue_perm+cortex_a8_vfplite\")\n+\n+;; VFP instructions.\n+;; The VFPLite unit that executes these isn't pipelined; we give the\n+;; worst-case latencies (and choose the double-precision ones where we\n+;; do not distinguish on precision).  We assume RunFast mode is not\n+;; enabled and therefore do not model the possible VFP instruction\n+;; execution in the NEON floating point pipelines, nor additional\n+;; latencies for the processing of subnormals.\n+;;\n+;; TODO: RunFast mode could potentially be enabled when -ffast-math\n+;; is specified.\n+\n+(define_insn_reservation \"cortex_a8_vfp_add_sub\" 10\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"type\" \"farith\"))\n+  \"cortex_a8_vfp,cortex_a8_vfplite*9\")\n+\n+(define_insn_reservation \"cortex_a8_vfp_muls\" 12\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"type\" \"fmuls\"))\n+  \"cortex_a8_vfp,cortex_a8_vfplite*11\")\n+\n+(define_insn_reservation \"cortex_a8_vfp_muld\" 17\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"type\" \"fmuld\"))\n+  \"cortex_a8_vfp,cortex_a8_vfplite*16\")\n+\n+(define_insn_reservation \"cortex_a8_vfp_macs\" 21\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"type\" \"fmacs\"))\n+  \"cortex_a8_vfp,cortex_a8_vfplite*20\")\n+\n+(define_insn_reservation \"cortex_a8_vfp_macd\" 26\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"type\" \"fmacd\"))\n+  \"cortex_a8_vfp,cortex_a8_vfplite*25\")\n+\n+(define_insn_reservation \"cortex_a8_vfp_divs\" 37\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"type\" \"fdivs\"))\n+  \"cortex_a8_vfp,cortex_a8_vfplite*36\")\n+\n+(define_insn_reservation \"cortex_a8_vfp_divd\" 65\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"type\" \"fdivd\"))\n+  \"cortex_a8_vfp,cortex_a8_vfplite*64\")\n+\n+;; Comparisons can actually take 7 cycles sometimes instead of four,\n+;; but given all the other instructions lumped into type=ffarith that\n+;; take four cycles, we pick that latency.\n+(define_insn_reservation \"cortex_a8_vfp_farith\" 4\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"type\" \"ffarith\"))\n+  \"cortex_a8_vfp,cortex_a8_vfplite*3\")\n+\n+(define_insn_reservation \"cortex_a8_vfp_cvt\" 7\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"type\" \"f_cvt\"))\n+  \"cortex_a8_vfp,cortex_a8_vfplite*6\")\n+\n+;; NEON -> core transfers.\n+\n+(define_insn_reservation \"neon_mrc\" 20\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_mrc\"))\n+  \"cortex_a8_neon_ls\")\n+\n+(define_insn_reservation \"neon_mrrc\" 21\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_mrrc\"))\n+  \"cortex_a8_neon_ls_2\")\n+\n+;; The remainder of this file is auto-generated by neon-schedgen.\n+\n+;; Instructions using this reservation read their source operands at N2, and\n+;; produce a result at N3.\n+(define_insn_reservation \"neon_int_1\" 3\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_int_1\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their (D|Q)m operands at N1,\n+;; their (D|Q)n operands at N2, and produce a result at N3.\n+(define_insn_reservation \"neon_int_2\" 3\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_int_2\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their source operands at N1, and\n+;; produce a result at N3.\n+(define_insn_reservation \"neon_int_3\" 3\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_int_3\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their source operands at N2, and\n+;; produce a result at N4.\n+(define_insn_reservation \"neon_int_4\" 4\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_int_4\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their (D|Q)m operands at N1,\n+;; their (D|Q)n operands at N2, and produce a result at N4.\n+(define_insn_reservation \"neon_int_5\" 4\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_int_5\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their source operands at N1, and\n+;; produce a result at N4.\n+(define_insn_reservation \"neon_vqneg_vqabs\" 4\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vqneg_vqabs\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation produce a result at N3.\n+(define_insn_reservation \"neon_vmov\" 3\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vmov\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n+;; produce a result at N6.\n+(define_insn_reservation \"neon_vaba\" 6\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vaba\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n+;; produce a result at N6 on cycle 2.\n+(define_insn_reservation \"neon_vaba_qqq\" 7\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vaba_qqq\"))\n+  \"cortex_a8_neon_dp_2\")\n+\n+;; Instructions using this reservation read their (D|Q)m operands at N1,\n+;; their (D|Q)d operands at N3, and produce a result at N6.\n+(define_insn_reservation \"neon_vsma\" 6\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vsma\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their source operands at N2, and\n+;; produce a result at N6.\n+(define_insn_reservation \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\" 6\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their source operands at N2, and\n+;; produce a result at N6 on cycle 2.\n+(define_insn_reservation \"neon_mul_qqq_8_16_32_ddd_32\" 7\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_mul_qqq_8_16_32_ddd_32\"))\n+  \"cortex_a8_neon_dp_2\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N1, and produce a result at N6 on cycle 2.\n+(define_insn_reservation \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\" 7\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\"))\n+  \"cortex_a8_neon_dp_2\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N2, their (D|Q)d operands at N3, and\n+;; produce a result at N6.\n+(define_insn_reservation \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\" 6\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N2, their (D|Q)d operands at N3, and\n+;; produce a result at N6 on cycle 2.\n+(define_insn_reservation \"neon_mla_qqq_8_16\" 7\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_mla_qqq_8_16\"))\n+  \"cortex_a8_neon_dp_2\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n+;; produce a result at N6 on cycle 2.\n+(define_insn_reservation \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\" 7\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\"))\n+  \"cortex_a8_neon_dp_2\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n+;; produce a result at N6 on cycle 4.\n+(define_insn_reservation \"neon_mla_qqq_32_qqd_32_scalar\" 9\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_mla_qqq_32_qqd_32_scalar\"))\n+  \"cortex_a8_neon_dp_4\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N1, and produce a result at N6.\n+(define_insn_reservation \"neon_mul_ddd_16_scalar_32_16_long_scalar\" 6\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_mul_ddd_16_scalar_32_16_long_scalar\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N1, and produce a result at N6 on cycle 4.\n+(define_insn_reservation \"neon_mul_qqd_32_scalar\" 9\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_mul_qqd_32_scalar\"))\n+  \"cortex_a8_neon_dp_4\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n+;; produce a result at N6.\n+(define_insn_reservation \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\" 6\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their source operands at N1, and\n+;; produce a result at N3.\n+(define_insn_reservation \"neon_shift_1\" 3\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_shift_1\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their source operands at N1, and\n+;; produce a result at N4.\n+(define_insn_reservation \"neon_shift_2\" 4\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_shift_2\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their source operands at N1, and\n+;; produce a result at N3 on cycle 2.\n+(define_insn_reservation \"neon_shift_3\" 4\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_shift_3\"))\n+  \"cortex_a8_neon_dp_2\")\n+\n+;; Instructions using this reservation read their source operands at N1, and\n+;; produce a result at N1.\n+(define_insn_reservation \"neon_vshl_ddd\" 1\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vshl_ddd\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their source operands at N1, and\n+;; produce a result at N4 on cycle 2.\n+(define_insn_reservation \"neon_vqshl_vrshl_vqrshl_qqq\" 5\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vqshl_vrshl_vqrshl_qqq\"))\n+  \"cortex_a8_neon_dp_2\")\n+\n+;; Instructions using this reservation read their (D|Q)m operands at N1,\n+;; their (D|Q)d operands at N3, and produce a result at N6.\n+(define_insn_reservation \"neon_vsra_vrsra\" 6\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vsra_vrsra\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their source operands at N2, and\n+;; produce a result at N5.\n+(define_insn_reservation \"neon_fp_vadd_ddd_vabs_dd\" 5\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_fp_vadd_ddd_vabs_dd\"))\n+  \"cortex_a8_neon_fadd\")\n+\n+;; Instructions using this reservation read their source operands at N2, and\n+;; produce a result at N5 on cycle 2.\n+(define_insn_reservation \"neon_fp_vadd_qqq_vabs_qq\" 6\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_fp_vadd_qqq_vabs_qq\"))\n+  \"cortex_a8_neon_fadd_2\")\n+\n+;; Instructions using this reservation read their source operands at N1, and\n+;; produce a result at N5.\n+(define_insn_reservation \"neon_fp_vsum\" 5\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_fp_vsum\"))\n+  \"cortex_a8_neon_fadd\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N1, and produce a result at N5.\n+(define_insn_reservation \"neon_fp_vmul_ddd\" 5\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_fp_vmul_ddd\"))\n+  \"cortex_a8_neon_dp\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N1, and produce a result at N5 on cycle 2.\n+(define_insn_reservation \"neon_fp_vmul_qqd\" 6\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_fp_vmul_qqd\"))\n+  \"cortex_a8_neon_dp_2\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N2, their (D|Q)d operands at N3, and\n+;; produce a result at N9.\n+(define_insn_reservation \"neon_fp_vmla_ddd\" 9\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_fp_vmla_ddd\"))\n+  \"cortex_a8_neon_fmul_then_fadd\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N2, their (D|Q)d operands at N3, and\n+;; produce a result at N9 on cycle 2.\n+(define_insn_reservation \"neon_fp_vmla_qqq\" 10\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_fp_vmla_qqq\"))\n+  \"cortex_a8_neon_fmul_then_fadd_2\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n+;; produce a result at N9.\n+(define_insn_reservation \"neon_fp_vmla_ddd_scalar\" 9\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_fp_vmla_ddd_scalar\"))\n+  \"cortex_a8_neon_fmul_then_fadd\")\n+\n+;; Instructions using this reservation read their (D|Q)n operands at N2,\n+;; their (D|Q)m operands at N1, their (D|Q)d operands at N3, and\n+;; produce a result at N9 on cycle 2.\n+(define_insn_reservation \"neon_fp_vmla_qqq_scalar\" 10\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_fp_vmla_qqq_scalar\"))\n+  \"cortex_a8_neon_fmul_then_fadd_2\")\n+\n+;; Instructions using this reservation read their source operands at N2, and\n+;; produce a result at N9.\n+(define_insn_reservation \"neon_fp_vrecps_vrsqrts_ddd\" 9\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_fp_vrecps_vrsqrts_ddd\"))\n+  \"cortex_a8_neon_fmul_then_fadd\")\n+\n+;; Instructions using this reservation read their source operands at N2, and\n+;; produce a result at N9 on cycle 2.\n+(define_insn_reservation \"neon_fp_vrecps_vrsqrts_qqq\" 10\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_fp_vrecps_vrsqrts_qqq\"))\n+  \"cortex_a8_neon_fmul_then_fadd_2\")\n+\n+;; Instructions using this reservation read their source operands at N1, and\n+;; produce a result at N2.\n+(define_insn_reservation \"neon_bp_simple\" 2\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_bp_simple\"))\n+  \"cortex_a8_neon_perm\")\n+\n+;; Instructions using this reservation read their source operands at N1, and\n+;; produce a result at N2 on cycle 2.\n+(define_insn_reservation \"neon_bp_2cycle\" 3\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_bp_2cycle\"))\n+  \"cortex_a8_neon_perm_2\")\n+\n+;; Instructions using this reservation read their source operands at N1, and\n+;; produce a result at N2 on cycle 3.\n+(define_insn_reservation \"neon_bp_3cycle\" 4\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_bp_3cycle\"))\n+  \"cortex_a8_neon_perm_3\")\n+\n+;; Instructions using this reservation produce a result at N1.\n+(define_insn_reservation \"neon_ldr\" 1\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_ldr\"))\n+  \"cortex_a8_neon_ls\")\n+\n+;; Instructions using this reservation read their source operands at N1.\n+(define_insn_reservation \"neon_str\" 0\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_str\"))\n+  \"cortex_a8_neon_ls\")\n+\n+;; Instructions using this reservation produce a result at N1 on cycle 2.\n+(define_insn_reservation \"neon_vld1_1_2_regs\" 2\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vld1_1_2_regs\"))\n+  \"cortex_a8_neon_ls_2\")\n+\n+;; Instructions using this reservation produce a result at N1 on cycle 3.\n+(define_insn_reservation \"neon_vld1_3_4_regs\" 3\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vld1_3_4_regs\"))\n+  \"cortex_a8_neon_ls_3\")\n+\n+;; Instructions using this reservation produce a result at N2 on cycle 2.\n+(define_insn_reservation \"neon_vld2_2_regs_vld1_vld2_all_lanes\" 3\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vld2_2_regs_vld1_vld2_all_lanes\"))\n+  \"cortex_a8_neon_ls_2\")\n+\n+;; Instructions using this reservation produce a result at N2 on cycle 3.\n+(define_insn_reservation \"neon_vld2_4_regs\" 4\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vld2_4_regs\"))\n+  \"cortex_a8_neon_ls_3\")\n+\n+;; Instructions using this reservation produce a result at N2 on cycle 4.\n+(define_insn_reservation \"neon_vld3_vld4\" 5\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vld3_vld4\"))\n+  \"cortex_a8_neon_ls_4\")\n+\n+;; Instructions using this reservation read their source operands at N1.\n+(define_insn_reservation \"neon_vst1_1_2_regs_vst2_2_regs\" 0\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vst1_1_2_regs_vst2_2_regs\"))\n+  \"cortex_a8_neon_ls_2\")\n+\n+;; Instructions using this reservation read their source operands at N1.\n+(define_insn_reservation \"neon_vst1_3_4_regs\" 0\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vst1_3_4_regs\"))\n+  \"cortex_a8_neon_ls_3\")\n+\n+;; Instructions using this reservation read their source operands at N1.\n+(define_insn_reservation \"neon_vst2_4_regs_vst3_vst4\" 0\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vst2_4_regs_vst3_vst4\"))\n+  \"cortex_a8_neon_ls_4\")\n+\n+;; Instructions using this reservation read their source operands at N1.\n+(define_insn_reservation \"neon_vst3_vst4\" 0\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vst3_vst4\"))\n+  \"cortex_a8_neon_ls_4\")\n+\n+;; Instructions using this reservation read their source operands at N1, and\n+;; produce a result at N2 on cycle 3.\n+(define_insn_reservation \"neon_vld1_vld2_lane\" 4\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vld1_vld2_lane\"))\n+  \"cortex_a8_neon_ls_3\")\n+\n+;; Instructions using this reservation read their source operands at N1, and\n+;; produce a result at N2 on cycle 5.\n+(define_insn_reservation \"neon_vld3_vld4_lane\" 6\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vld3_vld4_lane\"))\n+  \"cortex_a8_neon_ls_5\")\n+\n+;; Instructions using this reservation read their source operands at N1.\n+(define_insn_reservation \"neon_vst1_vst2_lane\" 0\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vst1_vst2_lane\"))\n+  \"cortex_a8_neon_ls_2\")\n+\n+;; Instructions using this reservation read their source operands at N1.\n+(define_insn_reservation \"neon_vst3_vst4_lane\" 0\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vst3_vst4_lane\"))\n+  \"cortex_a8_neon_ls_3\")\n+\n+;; Instructions using this reservation produce a result at N2 on cycle 2.\n+(define_insn_reservation \"neon_vld3_vld4_all_lanes\" 3\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_vld3_vld4_all_lanes\"))\n+  \"cortex_a8_neon_ls_3\")\n+\n+;; Instructions using this reservation produce a result at N2.\n+(define_insn_reservation \"neon_mcr\" 2\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_mcr\"))\n+  \"cortex_a8_neon_perm\")\n+\n+;; Instructions using this reservation produce a result at N2.\n+(define_insn_reservation \"neon_mcr_2_mcrr\" 2\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"neon_type\" \"neon_mcr_2_mcrr\"))\n+  \"cortex_a8_neon_perm_2\")\n+\n+;; Exceptions to the default latencies.\n+\n+(define_bypass 1 \"neon_mcr_2_mcrr\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 1 \"neon_mcr\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"neon_vld3_vld4_all_lanes\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"neon_vld3_vld4_lane\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"neon_vld1_vld2_lane\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 4 \"neon_vld3_vld4\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"neon_vld2_4_regs\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"neon_vld2_2_regs_vld1_vld2_all_lanes\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"neon_vld1_3_4_regs\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 1 \"neon_vld1_1_2_regs\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 0 \"neon_ldr\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"neon_bp_3cycle\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"neon_bp_2cycle\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 1 \"neon_bp_simple\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 9 \"neon_fp_vrecps_vrsqrts_qqq\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 8 \"neon_fp_vrecps_vrsqrts_ddd\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 9 \"neon_fp_vmla_qqq_scalar\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 8 \"neon_fp_vmla_ddd_scalar\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 9 \"neon_fp_vmla_qqq\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 8 \"neon_fp_vmla_ddd\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"neon_fp_vmul_qqd\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 4 \"neon_fp_vmul_ddd\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 4 \"neon_fp_vsum\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"neon_fp_vadd_qqq_vabs_qq\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 4 \"neon_fp_vadd_ddd_vabs_dd\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"neon_vsra_vrsra\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 4 \"neon_vqshl_vrshl_vqrshl_qqq\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 0 \"neon_vshl_ddd\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"neon_shift_3\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"neon_shift_2\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"neon_shift_1\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 8 \"neon_mul_qqd_32_scalar\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"neon_mul_ddd_16_scalar_32_16_long_scalar\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 8 \"neon_mla_qqq_32_qqd_32_scalar\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 6 \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 6 \"neon_mla_qqq_8_16\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 6 \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 6 \"neon_mul_qqq_8_16_32_ddd_32\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"neon_vsma\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 6 \"neon_vaba_qqq\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 5 \"neon_vaba\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"neon_vmov\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"neon_vqneg_vqabs\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"neon_int_5\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 3 \"neon_int_4\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"neon_int_3\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"neon_int_2\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+\n+(define_bypass 2 \"neon_int_1\"\n+               \"neon_int_1,\\\n+               neon_int_4,\\\n+               neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mul_qqq_8_16_32_ddd_32,\\\n+               neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+               neon_mla_qqq_8_16,\\\n+               neon_fp_vadd_ddd_vabs_dd,\\\n+               neon_fp_vadd_qqq_vabs_qq,\\\n+               neon_fp_vmla_ddd,\\\n+               neon_fp_vmla_qqq,\\\n+               neon_fp_vrecps_vrsqrts_ddd,\\\n+               neon_fp_vrecps_vrsqrts_qqq\")\n+"}, {"sha": "69d44de5720da5122bca9f762e7414c3588f269e", "filename": "gcc/config/arm/cortex-a8.md", "status": "added", "additions": 272, "deletions": 0, "changes": 272, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2Fconfig%2Farm%2Fcortex-a8.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2Fconfig%2Farm%2Fcortex-a8.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fcortex-a8.md?ref=c956e102dfffb7d5fa5e6051a2b35f146ca9c52b", "patch": "@@ -0,0 +1,272 @@\n+;; ARM Cortex-A8 scheduling description.\n+;; Copyright (C) 2007 Free Software Foundation, Inc.\n+;; Contributed by CodeSourcery.\n+\n+;; This file is part of GCC.\n+\n+;; GCC is distributed in the hope that it will be useful, but WITHOUT\n+;; ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n+;; or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public\n+;; License for more details.\n+\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING.  If not, write to\n+;; the Free Software Foundation, 51 Franklin Street, Fifth Floor,\n+;; Boston, MA 02110-1301, USA.\n+\n+(define_automaton \"cortex_a8\")\n+\n+;; Only one load/store instruction can be issued per cycle\n+;; (although reservation of this unit is only required for single\n+;; loads and stores -- see below).\n+(define_cpu_unit \"cortex_a8_issue_ls\" \"cortex_a8\")\n+\n+;; Only one branch instruction can be issued per cycle.\n+(define_cpu_unit \"cortex_a8_issue_branch\" \"cortex_a8\")\n+\n+;; The two ALU pipelines.\n+(define_cpu_unit \"cortex_a8_alu0\" \"cortex_a8\")\n+(define_cpu_unit \"cortex_a8_alu1\" \"cortex_a8\")\n+\n+;; The usual flow of an instruction through the pipelines.\n+(define_reservation \"cortex_a8_default\"\n+                    \"cortex_a8_alu0|cortex_a8_alu1\")\n+\n+;; The flow of a branch instruction through the pipelines.\n+(define_reservation \"cortex_a8_branch\"\n+                    \"(cortex_a8_alu0+cortex_a8_issue_branch)|\\\n+                     (cortex_a8_alu1+cortex_a8_issue_branch)\")\n+\n+;; The flow of a load or store instruction through the pipeline in\n+;; the case where that instruction consists of only one micro-op...\n+(define_reservation \"cortex_a8_load_store_1\"\n+                    \"(cortex_a8_alu0+cortex_a8_issue_ls)|\\\n+                     (cortex_a8_alu1+cortex_a8_issue_ls)\")\n+\n+;; ...and in the case of two micro-ops.  We don't need to reserve\n+;; cortex_a8_issue_ls here because dual issue is altogether forbidden\n+;; during the issue cycle of the first micro-op.  (Instead of modelling\n+;; a separate issue unit, we instead reserve alu0 and alu1 to\n+;; prevent any other instructions from being issued upon that first cycle.)\n+;; Even though the load/store pipeline is usually available in either\n+;; ALU pipe, multi-cycle instructions always issue in pipeline 0.  This\n+;; reservation is therefore the same as cortex_a8_multiply_2 below.\n+(define_reservation \"cortex_a8_load_store_2\"\n+                    \"cortex_a8_alu0+cortex_a8_alu1,\\\n+                     cortex_a8_alu0\")\n+\n+;; The flow of a single-cycle multiplication.\n+(define_reservation \"cortex_a8_multiply\"\n+                    \"cortex_a8_alu0\")\n+\n+;; The flow of a multiplication instruction that gets decomposed into\n+;; two micro-ops.  The two micro-ops will be issued to pipeline 0 on\n+;; successive cycles.  Dual issue cannot happen at the same time as the\n+;; first of the micro-ops.\n+(define_reservation \"cortex_a8_multiply_2\"\n+                    \"cortex_a8_alu0+cortex_a8_alu1,\\\n+                     cortex_a8_alu0\")\n+\n+;; Similarly, the flow of a multiplication instruction that gets\n+;; decomposed into three micro-ops.  Dual issue cannot occur except on\n+;; the cycle upon which the third micro-op is issued.\n+(define_reservation \"cortex_a8_multiply_3\"\n+                    \"cortex_a8_alu0+cortex_a8_alu1,\\\n+                     cortex_a8_alu0+cortex_a8_alu1,\\\n+                     cortex_a8_alu0\")\n+\n+;; The model given here assumes that all instructions are unconditional.\n+\n+;; Data processing instructions, but not move instructions.\n+\n+;; We include CLZ with these since it has the same execution pattern\n+;; (source read in E2 and destination available at the end of that cycle).\n+(define_insn_reservation \"cortex_a8_alu\" 2\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (ior (and (eq_attr \"type\" \"alu\")\n+                (not (eq_attr \"insn\" \"mov,mvn\")))\n+            (eq_attr \"insn\" \"clz\")))\n+  \"cortex_a8_default\")\n+\n+(define_insn_reservation \"cortex_a8_alu_shift\" 2\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (and (eq_attr \"type\" \"alu_shift\")\n+            (not (eq_attr \"insn\" \"mov,mvn\"))))\n+  \"cortex_a8_default\")\n+\n+(define_insn_reservation \"cortex_a8_alu_shift_reg\" 2\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (and (eq_attr \"type\" \"alu_shift_reg\")\n+            (not (eq_attr \"insn\" \"mov,mvn\"))))\n+  \"cortex_a8_default\")\n+\n+;; Move instructions.\n+\n+(define_insn_reservation \"cortex_a8_mov\" 1\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (and (eq_attr \"type\" \"alu,alu_shift,alu_shift_reg\")\n+            (eq_attr \"insn\" \"mov,mvn\")))\n+  \"cortex_a8_default\")\n+\n+;; Exceptions to the default latencies for data processing instructions.\n+\n+;; A move followed by an ALU instruction with no early dep.\n+;; (Such a pair can be issued in parallel, hence latency zero.)\n+(define_bypass 0 \"cortex_a8_mov\" \"cortex_a8_alu\")\n+(define_bypass 0 \"cortex_a8_mov\" \"cortex_a8_alu_shift\"\n+               \"arm_no_early_alu_shift_dep\")\n+(define_bypass 0 \"cortex_a8_mov\" \"cortex_a8_alu_shift_reg\"\n+               \"arm_no_early_alu_shift_value_dep\")\n+\n+;; An ALU instruction followed by an ALU instruction with no early dep.\n+(define_bypass 1 \"cortex_a8_alu,cortex_a8_alu_shift,cortex_a8_alu_shift_reg\"\n+               \"cortex_a8_alu\")\n+(define_bypass 1 \"cortex_a8_alu,cortex_a8_alu_shift,cortex_a8_alu_shift_reg\"\n+               \"cortex_a8_alu_shift\"\n+               \"arm_no_early_alu_shift_dep\")\n+(define_bypass 1 \"cortex_a8_alu,cortex_a8_alu_shift,cortex_a8_alu_shift_reg\"\n+               \"cortex_a8_alu_shift_reg\"\n+               \"arm_no_early_alu_shift_value_dep\")\n+\n+;; Multiplication instructions.  These are categorized according to their\n+;; reservation behaviour and the need below to distinguish certain\n+;; varieties for bypasses.  Results are available at the E5 stage\n+;; (but some of these are multi-cycle instructions which explains the\n+;; latencies below).\n+\n+(define_insn_reservation \"cortex_a8_mul\" 6\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"insn\" \"mul,smulxy,smmul\"))\n+  \"cortex_a8_multiply_2\")\n+\n+(define_insn_reservation \"cortex_a8_mla\" 6\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"insn\" \"mla,smlaxy,smlawy,smmla,smlad,smlsd\"))\n+  \"cortex_a8_multiply_2\")\n+\n+(define_insn_reservation \"cortex_a8_mull\" 7\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"insn\" \"smull,umull,smlal,umlal,umaal,smlalxy\"))\n+  \"cortex_a8_multiply_3\")\n+\n+(define_insn_reservation \"cortex_a8_smulwy\" 5\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"insn\" \"smulwy,smuad,smusd\"))\n+  \"cortex_a8_multiply\")\n+\n+;; smlald and smlsld are multiply-accumulate instructions but do not\n+;; received bypassed data from other multiplication results; thus, they\n+;; cannot go in cortex_a8_mla above.  (See below for bypass details.)\n+(define_insn_reservation \"cortex_a8_smlald\" 6\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"insn\" \"smlald,smlsld\"))\n+  \"cortex_a8_multiply_2\")\n+\n+;; A multiply with a single-register result or an MLA, followed by an\n+;; MLA with an accumulator dependency, has its result forwarded so two\n+;; such instructions can issue back-to-back.\n+(define_bypass 1 \"cortex_a8_mul,cortex_a8_mla,cortex_a8_smulwy\"\n+               \"cortex_a8_mla\"\n+               \"arm_mac_accumulator_is_mul_result\")\n+\n+;; A multiply followed by an ALU instruction needing the multiply\n+;; result only at E2 has lower latency than one needing it at E1.\n+(define_bypass 4 \"cortex_a8_mul,cortex_a8_mla,cortex_a8_mull,\\\n+                  cortex_a8_smulwy,cortex_a8_smlald\"\n+               \"cortex_a8_alu\")\n+(define_bypass 4 \"cortex_a8_mul,cortex_a8_mla,cortex_a8_mull,\\\n+                  cortex_a8_smulwy,cortex_a8_smlald\"\n+               \"cortex_a8_alu_shift\"\n+               \"arm_no_early_alu_shift_dep\")\n+(define_bypass 4 \"cortex_a8_mul,cortex_a8_mla,cortex_a8_mull,\\\n+                  cortex_a8_smulwy,cortex_a8_smlald\"\n+               \"cortex_a8_alu_shift_reg\"\n+               \"arm_no_early_alu_shift_value_dep\")\n+\n+;; Load instructions.\n+;; The presence of any register writeback is ignored here.\n+\n+;; A load result has latency 3 unless the dependent instruction has\n+;; no early dep, in which case it is only latency two.\n+;; We assume 64-bit alignment for doubleword loads.\n+(define_insn_reservation \"cortex_a8_load1_2\" 3\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"type\" \"load1,load2,load_byte\"))\n+  \"cortex_a8_load_store_1\")\n+\n+(define_bypass 2 \"cortex_a8_load1_2\"\n+               \"cortex_a8_alu\")\n+(define_bypass 2 \"cortex_a8_load1_2\"\n+               \"cortex_a8_alu_shift\"\n+               \"arm_no_early_alu_shift_dep\")\n+(define_bypass 2 \"cortex_a8_load1_2\"\n+               \"cortex_a8_alu_shift_reg\"\n+               \"arm_no_early_alu_shift_value_dep\")\n+\n+;; We do not currently model the fact that loads with scaled register\n+;; offsets that are not LSL #2 have an extra cycle latency (they issue\n+;; as two micro-ops).\n+\n+;; A load multiple of three registers is usually issued as two micro-ops.\n+;; The first register will be available at E3 of the first iteration,\n+;; the second at E3 of the second iteration, and the third at E4 of\n+;; the second iteration.  A load multiple of four registers is usually\n+;; issued as two micro-ops.\n+(define_insn_reservation \"cortex_a8_load3_4\" 5\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"type\" \"load3,load4\"))\n+  \"cortex_a8_load_store_2\")\n+\n+(define_bypass 4 \"cortex_a8_load3_4\"\n+               \"cortex_a8_alu\")\n+(define_bypass 4 \"cortex_a8_load3_4\"\n+               \"cortex_a8_alu_shift\"\n+               \"arm_no_early_alu_shift_dep\")\n+(define_bypass 4 \"cortex_a8_load3_4\"\n+               \"cortex_a8_alu_shift_reg\"\n+               \"arm_no_early_alu_shift_value_dep\")\n+\n+;; Store instructions.\n+;; Writeback is again ignored.\n+\n+(define_insn_reservation \"cortex_a8_store1_2\" 0\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"type\" \"store1,store2\"))\n+  \"cortex_a8_load_store_1\")\n+\n+(define_insn_reservation \"cortex_a8_store3_4\" 0\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"type\" \"store3,store4\"))\n+  \"cortex_a8_load_store_2\")\n+\n+;; An ALU instruction acting as a producer for a store instruction\n+;; that only uses the result as the value to be stored (as opposed to\n+;; using it to calculate the address) has latency zero; the store\n+;; reads the value to be stored at the start of E3 and the ALU insn\n+;; writes it at the end of E2.  Move instructions actually produce the\n+;; result at the end of E1, but since we don't have delay slots, the\n+;; scheduling behaviour will be the same.\n+(define_bypass 0 \"cortex_a8_alu,cortex_a8_alu_shift,\\\n+                  cortex_a8_alu_shift_reg,cortex_a8_mov\"\n+               \"cortex_a8_store1_2,cortex_a8_store3_4\"\n+               \"arm_no_early_store_addr_dep\")\n+\n+;; Branch instructions\n+\n+(define_insn_reservation \"cortex_a8_branch\" 0\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"type\" \"branch\"))\n+  \"cortex_a8_branch\")\n+\n+;; Call latencies are not predictable.  A semi-arbitrary very large\n+;; number is used as \"positive infinity\" so that everything should be\n+;; finished by the time of return.\n+(define_insn_reservation \"cortex_a8_call\" 32\n+  (and (eq_attr \"tune\" \"cortexa8\")\n+       (eq_attr \"type\" \"call\"))\n+  \"cortex_a8_issue_branch\")\n+\n+;; NEON (including VFP) instructions.\n+\n+(include \"cortex-a8-neon.md\")\n+"}, {"sha": "b47a0ae7d3ce87e2e4f96fe8d44a252e2c25b910", "filename": "gcc/config/arm/neon-schedgen.ml", "status": "added", "additions": 497, "deletions": 0, "changes": 497, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2Fconfig%2Farm%2Fneon-schedgen.ml", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2Fconfig%2Farm%2Fneon-schedgen.ml", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fneon-schedgen.ml?ref=c956e102dfffb7d5fa5e6051a2b35f146ca9c52b", "patch": "@@ -0,0 +1,497 @@\n+(* Emission of the core of the Cortex-A8 NEON scheduling description.\n+   Copyright (C) 2007 Free Software Foundation, Inc.\n+   Contributed by CodeSourcery.\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2, or (at your option) any later\n+   version.\n+\n+   GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+   WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with GCC; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.\n+*)\n+\n+(* This scheduling description generator works as follows.\n+   - Each group of instructions has source and destination requirements\n+     specified.  The source requirements may be specified using\n+     Source (the stage at which all source operands not otherwise\n+     described are read), Source_m (the stage at which Rm operands are\n+     read), Source_n (likewise for Rn) and Source_d (likewise for Rd).\n+   - For each group of instructions the earliest stage where a source\n+     operand may be required is calculated.\n+   - Each group of instructions is selected in turn as a producer.\n+     The latencies between this group and every other group are then\n+     calculated, yielding up to four values for each combination:\n+\t1. Producer -> consumer Rn latency\n+\t2. Producer -> consumer Rm latency\n+\t3. Producer -> consumer Rd (as a source) latency\n+\t4. Producer -> consumer worst-case latency.\n+     Value 4 is calculated from the destination availability requirements\n+     of the consumer and the earliest source availability requirements\n+     of the producer.\n+   - The largest Value 4 calculated for the current producer is the\n+     worse-case latency, L, for that instruction group.  This value is written\n+     out in a define_insn_reservation for the producer group.\n+   - For each producer and consumer pair, the latencies calculated above\n+     are collated.  The average (of up to four values) is calculated and\n+     if this average is different from the worst-case latency, an\n+     unguarded define_bypass construction is issued for that pair.\n+     (For each pair only one define_bypass construction will be emitted,\n+     and at present we do not emit specific guards.)\n+*)\n+\n+open Utils\n+\n+let n1 = 1 and n2 = 2 and n3 = 3 and n4 = 4 and n5 = 5 and n6 = 6\n+    and n7 = 7 and n8 = 8 and n9 = 9\n+\n+type availability = Source of int\n+                  | Source_n of int\n+                  | Source_m of int\n+                  | Source_d of int\n+                  | Dest of int\n+\t\t  | Dest_n_after of int * int\n+\n+type guard = Guard_none | Guard_only_m | Guard_only_n | Guard_only_d\n+\n+(* Reservation behaviours.  All but the last row here correspond to one\n+   pipeline each.  Each constructor will correspond to one\n+   define_reservation.  *)\n+type reservation =\n+  Mul | Mul_2cycle | Mul_4cycle\n+| Shift | Shift_2cycle\n+| ALU | ALU_2cycle\n+| Fmul | Fmul_2cycle\n+| Fadd | Fadd_2cycle\n+(* | VFP *)\n+| Permute of int\n+| Ls of int\n+| Fmul_then_fadd | Fmul_then_fadd_2\n+\n+(* This table must be kept as short as possible by conflating\n+   entries with the same availability behaviour.\n+\n+   First components: instruction group names\n+   Second components: availability requirements, in the order in which\n+   they should appear in the comments in the .md file.\n+   Third components: reservation info\n+*)\n+let availability_table = [\n+  (* NEON integer ALU instructions.  *)\n+  (* vbit vbif vbsl vorr vbic vnot vcls vclz vcnt vadd vand vorr\n+     veor vbic vorn ddd qqq *)\n+  \"neon_int_1\", [Source n2; Dest n3], ALU;\n+  (* vadd vsub qqd vsub ddd qqq *)\n+  \"neon_int_2\", [Source_m n1; Source_n n2; Dest n3], ALU;\n+  (* vsum vneg dd qq vadd vsub qdd *)\n+  \"neon_int_3\", [Source n1; Dest n3], ALU;\n+  (* vabs vceqz vcgez vcbtz vclez vcltz vadh vradh vsbh vrsbh dqq *)\n+  (* vhadd vrhadd vqadd vtst ddd qqq *)\n+  \"neon_int_4\", [Source n2; Dest n4], ALU;\n+  (* vabd qdd vhsub vqsub vabd vceq vcge vcgt vmax vmin vfmx vfmn ddd ddd *)\n+  \"neon_int_5\", [Source_m n1; Source_n n2; Dest n4], ALU;\n+  (* vqneg vqabs dd qq *)\n+  \"neon_vqneg_vqabs\", [Source n1; Dest n4], ALU;\n+  (* vmov vmvn *)\n+  \"neon_vmov\", [Dest n3], ALU;\n+  (* vaba *)\n+  \"neon_vaba\", [Source_n n2; Source_m n1; Source_d n3; Dest n6], ALU;\n+  \"neon_vaba_qqq\",\n+    [Source_n n2; Source_m n1; Source_d n3; Dest_n_after (1, n6)], ALU_2cycle;\n+  (* vsma *)\n+  \"neon_vsma\", [Source_m n1; Source_d n3; Dest n6], ALU;\n+\n+  (* NEON integer multiply instructions.  *)\n+  (* vmul, vqdmlh, vqrdmlh *)\n+  (* vmul, vqdmul, qdd 16/8 long 32/16 long *)\n+  \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\", [Source n2; Dest n6], Mul;\n+  \"neon_mul_qqq_8_16_32_ddd_32\", [Source n2; Dest_n_after (1, n6)], Mul_2cycle;\n+  (* vmul, vqdmul again *)\n+  \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\",\n+    [Source_n n2; Source_m n1; Dest_n_after (1, n6)], Mul_2cycle;\n+  (* vmla, vmls *)\n+  \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\",\n+    [Source_n n2; Source_m n2; Source_d n3; Dest n6], Mul;\n+  \"neon_mla_qqq_8_16\",\n+    [Source_n n2; Source_m n2; Source_d n3; Dest_n_after (1, n6)], Mul_2cycle;\n+  \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\",\n+    [Source_n n2; Source_m n1; Source_d n3; Dest_n_after (1, n6)], Mul_2cycle;\n+  \"neon_mla_qqq_32_qqd_32_scalar\",\n+    [Source_n n2; Source_m n1; Source_d n3; Dest_n_after (3, n6)], Mul_4cycle;\n+  (* vmul, vqdmulh, vqrdmulh *)\n+  (* vmul, vqdmul *)\n+  \"neon_mul_ddd_16_scalar_32_16_long_scalar\",\n+    [Source_n n2; Source_m n1; Dest n6], Mul;\n+  \"neon_mul_qqd_32_scalar\",\n+    [Source_n n2; Source_m n1; Dest_n_after (3, n6)], Mul_4cycle;\n+  (* vmla, vmls *)\n+  (* vmla, vmla, vqdmla, vqdmls *)\n+  \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\",\n+    [Source_n n2; Source_m n1; Source_d n3; Dest n6], Mul;\n+\n+  (* NEON integer shift instructions.  *)\n+  (* vshr/vshl immediate, vshr_narrow, vshl_vmvh, vsli_vsri_ddd *)\n+  \"neon_shift_1\", [Source n1; Dest n3], Shift;\n+  (* vqshl, vrshr immediate; vqshr, vqmov, vrshr, vqrshr narrow;\n+     vqshl_vrshl_vqrshl_ddd *)\n+  \"neon_shift_2\", [Source n1; Dest n4], Shift;\n+  (* vsli, vsri and vshl for qqq *)\n+  \"neon_shift_3\", [Source n1; Dest_n_after (1, n3)], Shift_2cycle;\n+  \"neon_vshl_ddd\", [Source n1; Dest n1], Shift;\n+  \"neon_vqshl_vrshl_vqrshl_qqq\", [Source n1; Dest_n_after (1, n4)],\n+    Shift_2cycle;\n+  \"neon_vsra_vrsra\", [Source_m n1; Source_d n3; Dest n6], Shift;\n+\n+  (* NEON floating-point instructions.  *)\n+  (* vadd, vsub, vabd, vmul, vceq, vcge, vcgt, vcage, vcagt, vmax, vmin *)\n+  (* vabs, vneg, vceqz, vcgez, vcgtz, vclez, vcltz, vrecpe, vrsqrte, vcvt *)\n+  \"neon_fp_vadd_ddd_vabs_dd\", [Source n2; Dest n5], Fadd;\n+  \"neon_fp_vadd_qqq_vabs_qq\", [Source n2; Dest_n_after (1, n5)],\n+    Fadd_2cycle;\n+  (* vsum, fvmx, vfmn *)\n+  \"neon_fp_vsum\", [Source n1; Dest n5], Fadd;\n+  \"neon_fp_vmul_ddd\", [Source_n n2; Source_m n1; Dest n5], Fmul;\n+  \"neon_fp_vmul_qqd\", [Source_n n2; Source_m n1; Dest_n_after (1, n5)],\n+    Fmul_2cycle;\n+  (* vmla, vmls *)\n+  \"neon_fp_vmla_ddd\",\n+    [Source_n n2; Source_m n2; Source_d n3; Dest n9], Fmul_then_fadd;\n+  \"neon_fp_vmla_qqq\",\n+    [Source_n n2; Source_m n2; Source_d n3; Dest_n_after (1, n9)],\n+    Fmul_then_fadd_2;\n+  \"neon_fp_vmla_ddd_scalar\",\n+    [Source_n n2; Source_m n1; Source_d n3; Dest n9], Fmul_then_fadd;\n+  \"neon_fp_vmla_qqq_scalar\",\n+    [Source_n n2; Source_m n1; Source_d n3; Dest_n_after (1, n9)],\n+    Fmul_then_fadd_2;\n+  \"neon_fp_vrecps_vrsqrts_ddd\", [Source n2; Dest n9], Fmul_then_fadd;\n+  \"neon_fp_vrecps_vrsqrts_qqq\", [Source n2; Dest_n_after (1, n9)],\n+    Fmul_then_fadd_2;\n+\n+  (* NEON byte permute instructions.  *)\n+  (* vmov; vtrn and vswp for dd; vzip for dd; vuzp for dd; vrev; vext for dd *)\n+  \"neon_bp_simple\", [Source n1; Dest n2], Permute 1;\n+  (* vswp for qq; vext for qqq; vtbl with {Dn} or {Dn, Dn1};\n+     similarly for vtbx *)\n+  \"neon_bp_2cycle\", [Source n1; Dest_n_after (1, n2)], Permute 2;\n+  (* all the rest *)\n+  \"neon_bp_3cycle\", [Source n1; Dest_n_after (2, n2)], Permute 3;\n+\n+  (* NEON load/store instructions.  *)\n+  \"neon_ldr\", [Dest n1], Ls 1;\n+  \"neon_str\", [Source n1], Ls 1;\n+  \"neon_vld1_1_2_regs\", [Dest_n_after (1, n1)], Ls 2;\n+  \"neon_vld1_3_4_regs\", [Dest_n_after (2, n1)], Ls 3;\n+  \"neon_vld2_2_regs_vld1_vld2_all_lanes\", [Dest_n_after (1, n2)], Ls 2;\n+  \"neon_vld2_4_regs\", [Dest_n_after (2, n2)], Ls 3;\n+  \"neon_vld3_vld4\", [Dest_n_after (3, n2)], Ls 4;\n+  \"neon_vst1_1_2_regs_vst2_2_regs\", [Source n1], Ls 2;\n+  \"neon_vst1_3_4_regs\", [Source n1], Ls 3;\n+  \"neon_vst2_4_regs_vst3_vst4\", [Source n1], Ls 4;\n+  \"neon_vst3_vst4\", [Source n1], Ls 4;\n+  \"neon_vld1_vld2_lane\", [Source n1; Dest_n_after (2, n2)], Ls 3;\n+  \"neon_vld3_vld4_lane\", [Source n1; Dest_n_after (4, n2)], Ls 5;\n+  \"neon_vst1_vst2_lane\", [Source n1], Ls 2;\n+  \"neon_vst3_vst4_lane\", [Source n1], Ls 3;\n+  \"neon_vld3_vld4_all_lanes\", [Dest_n_after (1, n2)], Ls 3;\n+\n+  (* NEON register transfer instructions.  *)\n+  \"neon_mcr\", [Dest n2], Permute 1;\n+  \"neon_mcr_2_mcrr\", [Dest n2], Permute 2;\n+  (* MRC instructions are in the .tpl file.  *)\n+]\n+\n+(* Augment the tuples in the availability table with an extra component\n+   that describes the earliest stage where a source operand may be\n+   required.  (It is also possible that an entry in the table has no\n+   source requirements.)  *)\n+let calculate_sources =\n+  List.map (fun (name, avail, res) ->\n+              let earliest_stage =\n+                List.fold_left\n+                  (fun cur -> fun info ->\n+                     match info with\n+                       Source stage\n+                     | Source_n stage\n+                     | Source_m stage\n+                     | Source_d stage ->\n+                         (match cur with\n+                           None -> Some stage\n+                         | Some stage' when stage < stage' -> Some stage\n+                         | _ -> cur)\n+                     | _ -> cur) None avail\n+              in\n+                (name, avail, res, earliest_stage))\n+\n+(* Find the stage, if any, at the end of which a group produces a result.  *)\n+let find_dest (attr, avail, _, _) =\n+  try\n+    find_with_result\n+      (fun av -> match av with\n+                   Dest st -> Some (Some st)\n+                 | Dest_n_after (after, st) -> Some (Some (after + st))\n+                 | _ -> None) avail\n+  with Not_found -> None\n+\n+(* Find the worst-case latency between a producer and a consumer.  *)\n+let worst_case_latency producer (_, _, _, earliest_required) =\n+  let dest = find_dest producer in\n+    match earliest_required, dest with\n+      None, _ ->\n+        (* The consumer doesn't have any source requirements.  *)\n+        None\n+    | _, None ->\n+        (* The producer doesn't produce any results (e.g. a store insn).  *)\n+        None\n+    | Some consumed, Some produced -> Some (produced - consumed + 1)\n+\n+(* Helper function for below.  *)\n+let latency_calc f producer (_, avail, _, _) =\n+  try\n+    let source_avail = find_with_result f avail in\n+      match find_dest producer with\n+        None ->\n+          (* The producer does not produce a result.  *)\n+          Some 0\n+      | Some produced ->\n+          let latency = produced - source_avail + 1 in\n+            (* Latencies below zero are raised to zero since we don't have\n+               delay slots.  *)\n+            if latency < 0 then Some 0 else Some latency\n+  with Not_found -> None\n+\n+(* Find any Rm latency between a producer and a consumer.  If no\n+   Rm source requirement is explicitly specified for the consumer,\n+   return \"positive infinity\".  Also return \"positive infinity\" if\n+   the latency matches the supplied worst-case latency for this\n+   producer.  *)\n+let get_m_latency producer consumer =\n+  match latency_calc (fun av -> match av with Source_m stage -> Some stage\n+                                            | _ -> None) producer consumer\n+  with None -> [] | Some latency -> [(Guard_only_m, latency)]\n+\n+(* Likewise for Rn.  *)\n+let get_n_latency producer consumer =\n+  match latency_calc (fun av -> match av with Source_n stage -> Some stage\n+                                            | _ -> None) producer consumer\n+  with None -> [] | Some latency -> [(Guard_only_n, latency)]\n+\n+(* Likewise for Rd.  *)\n+let get_d_latency producer consumer =\n+  match\n+    latency_calc (fun av -> match av with Source_d stage -> Some stage\n+                                        | _ -> None) producer consumer\n+  with None -> [] | Some latency -> [(Guard_only_d, latency)]\n+\n+(* Given a producer and a consumer, work out the latency of the producer\n+   to the consumer in each of the four cases (availability information\n+   permitting) identified at the top of this file.  Return the\n+   consumer, the worst-case unguarded latency and any guarded latencies.  *)\n+let calculate_latencies producer consumer =\n+  let worst = worst_case_latency producer consumer in\n+  let m_latency = get_m_latency producer consumer in\n+  let n_latency = get_n_latency producer consumer in\n+  let d_latency = get_d_latency producer consumer in\n+    (consumer, worst, m_latency @ n_latency @ d_latency)\n+\n+(* Helper function for below.  *)\n+let pick_latency largest worst guards =\n+  let guards =\n+    match worst with\n+      None -> guards\n+    | Some worst -> (Guard_none, worst) :: guards\n+  in\n+  if List.length guards = 0 then None else\n+    let total_latency =\n+      List.fold_left (fun acc -> fun (_, latency) -> acc + latency) 0 guards\n+    in\n+    let average_latency = (float_of_int total_latency) /.\n+                          (float_of_int (List.length guards)) in\n+    let rounded_latency = int_of_float (ceil average_latency) in\n+      if rounded_latency = largest then None\n+      else Some (Guard_none, rounded_latency)\n+\n+(* Collate all bypasses for a particular producer as required in\n+   worst_case_latencies_and_bypasses.  (By this stage there is a maximum\n+   of one bypass from this producer to any particular consumer listed\n+   in LATENCIES.)  Use a hash table to collate bypasses with the\n+   same latency and guard.  *)\n+let collate_bypasses (producer_name, _, _, _) largest latencies =\n+  let ht = Hashtbl.create 42 in\n+  let keys = ref [] in\n+    List.iter (\n+      fun ((consumer, _, _, _), worst, guards) ->\n+        (* Find out which latency to use.  Ignoring latencies that match\n+           the *overall* worst-case latency for this producer (which will\n+           be in define_insn_reservation), we have to examine:\n+\t   1. the latency with no guard between this producer and this\n+              consumer; and\n+\t   2. any guarded latency.  *)\n+        let guard_latency_opt = pick_latency largest worst guards in\n+          match guard_latency_opt with\n+            None -> ()\n+          | Some (guard, latency) ->\n+            begin\n+              (if (try ignore (Hashtbl.find ht (guard, latency)); false\n+                   with Not_found -> true) then\n+                 keys := (guard, latency) :: !keys);\n+              Hashtbl.add ht (guard, latency) consumer\n+            end\n+    ) latencies;\n+    (* The hash table now has bypasses collated so that ones with the\n+       same latency and guard have the same keys.  Walk through all the\n+       keys, extract the associated bypasses, and concatenate the names\n+       of the consumers for each bypass.  *)\n+    List.map (\n+      fun ((guard, latency) as key) ->\n+        let consumers = Hashtbl.find_all ht key in\n+          (producer_name,\n+           String.concat \",\\\\\\n               \" consumers,\n+           latency,\n+           guard)\n+      ) !keys\n+\n+(* For every producer, find the worst-case latency between it and\n+   *any* consumer.  Also determine (if such a thing exists) the\n+   lowest-latency bypass from each producer to each consumer.  Group\n+   the output in such a way that all bypasses with the same producer\n+   and latency are together, and so that bypasses with the worst-case\n+   latency are ignored.  *)\n+let worst_case_latencies_and_bypasses =\n+  let rec f (worst_acc, bypasses_acc) prev xs =\n+    match xs with\n+      [] -> (worst_acc, bypasses_acc)\n+    | ((producer_name, producer_avail, res_string, _) as producer)::next ->\n+      (* For this particular producer, work out the latencies between\n+         it and every consumer.  *)\n+      let latencies =\n+        List.fold_left (fun acc -> fun consumer ->\n+                          (calculate_latencies producer consumer) :: acc)\n+                       [] (prev @ xs)\n+      in\n+        (* Now work out what the overall worst case latency was for this\n+           particular producer.  *)\n+        match latencies with\n+          [] -> assert false\n+        | _ ->\n+          let comp_fn (_, l1, _) (_, l2, _) =\n+            if l1 > l2 then -1 else if l1 = l2 then 0 else 1\n+          in\n+          let largest =\n+            match List.hd (List.sort comp_fn latencies) with\n+              (_, None, _) -> 0 (* Producer has no consumers. *)\n+            | (_, Some worst, _) -> worst\n+          in\n+          (* Having got the largest latency, collect all bypasses for\n+             this producer and filter out those with that larger\n+             latency.  Record the others for later emission.  *)\n+          let bypasses = collate_bypasses producer largest latencies in\n+            (* Go on to process remaining producers, having noted\n+               the result for this one.  *)\n+            f ((producer_name, producer_avail, largest,\n+                res_string) :: worst_acc,\n+               bypasses @ bypasses_acc)\n+              (prev @ [producer]) next\n+  in\n+    f ([], []) []\n+\n+(* Emit a helpful comment for a define_insn_reservation.  *)\n+let write_comment producer avail =\n+  let seen_source = ref false in\n+  let describe info =\n+    let read = if !seen_source then \"\" else \"read \" in\n+    match info with\n+      Source stage ->\n+        seen_source := true;\n+\tPrintf.printf \"%stheir source operands at N%d\" read stage\n+    | Source_n stage ->\n+        seen_source := true;\n+\tPrintf.printf \"%stheir (D|Q)n operands at N%d\" read stage\n+    | Source_m stage ->\n+        seen_source := true;\n+\tPrintf.printf \"%stheir (D|Q)m operands at N%d\" read stage\n+    | Source_d stage ->\n+\tPrintf.printf \"%stheir (D|Q)d operands at N%d\" read stage\n+    | Dest stage ->\n+\tPrintf.printf \"produce a result at N%d\" stage\n+    | Dest_n_after (after, stage) ->\n+\tPrintf.printf \"produce a result at N%d on cycle %d\" stage (after + 1)\n+  in\n+    Printf.printf \";; Instructions using this reservation \";\n+    let rec f infos x =\n+      let sep = if x mod 2 = 1 then \"\" else \"\\n;;\" in\n+      match infos with\n+        [] -> assert false\n+      | [info] -> describe info; Printf.printf \".\\n\"\n+      | info::(_::[] as infos) ->\n+          describe info; Printf.printf \", and%s \" sep; f infos (x+1)\n+      | info::infos -> describe info; Printf.printf \",%s \" sep; f infos (x+1)\n+    in\n+      f avail 0\n+\n+(* Emit a define_insn_reservation for each producer.  The latency\n+   written in will be its worst-case latency.  *)\n+let emit_insn_reservations =\n+  List.iter (\n+     fun (producer, avail, latency, reservation) ->\n+        write_comment producer avail;\n+        Printf.printf \"(define_insn_reservation \\\"%s\\\" %d\\n\" producer latency;\n+        Printf.printf \"  (and (eq_attr \\\"tune\\\" \\\"cortexa8\\\")\\n\";\n+        Printf.printf \"       (eq_attr \\\"neon_type\\\" \\\"%s\\\"))\\n\" producer;\n+        let str =\n+          match reservation with\n+\t    Mul -> \"dp\" | Mul_2cycle -> \"dp_2\" | Mul_4cycle -> \"dp_4\"\n+\t  | Shift -> \"dp\" | Shift_2cycle -> \"dp_2\"\n+\t  | ALU -> \"dp\" | ALU_2cycle -> \"dp_2\"\n+\t  | Fmul -> \"dp\" | Fmul_2cycle -> \"dp_2\"\n+\t  | Fadd -> \"fadd\" | Fadd_2cycle -> \"fadd_2\"\n+\t  | Ls 1 -> \"ls\"\n+          | Ls n -> \"ls_\" ^ (string_of_int n)\n+\t  | Permute 1 -> \"perm\"\n+          | Permute n -> \"perm_\" ^ (string_of_int n)\n+\t  | Fmul_then_fadd -> \"fmul_then_fadd\"\n+\t  | Fmul_then_fadd_2 -> \"fmul_then_fadd_2\"\n+        in\n+          Printf.printf \"  \\\"cortex_a8_neon_%s\\\")\\n\\n\" str\n+    )\n+\n+(* Given a guard description, return the name of the C function to\n+   be used as the guard for define_bypass.  *)\n+let guard_fn g =\n+  match g with\n+    Guard_only_m -> \"arm_neon_only_m_dependency\"\n+  | Guard_only_n -> \"arm_neon_only_n_dependency\"\n+  | Guard_only_d -> \"arm_neon_only_d_dependency\"\n+  | Guard_none -> assert false\n+\n+(* Emit a define_bypass for each bypass.  *)\n+let emit_bypasses =\n+  List.iter (\n+      fun (producer, consumers, latency, guard) ->\n+        Printf.printf \"(define_bypass %d \\\"%s\\\"\\n\" latency producer;\n+        if guard = Guard_none then\n+          Printf.printf \"               \\\"%s\\\")\\n\\n\" consumers\n+        else\n+          begin\n+            Printf.printf \"               \\\"%s\\\"\\n\" consumers;\n+            Printf.printf \"               \\\"%s\\\")\\n\\n\" (guard_fn guard)\n+          end\n+    )\n+\n+(* Program entry point.  *)\n+let main =\n+  let table = calculate_sources availability_table in\n+  let worst_cases, bypasses = worst_case_latencies_and_bypasses table in\n+    emit_insn_reservations (List.rev worst_cases);\n+    Printf.printf \";; Exceptions to the default latencies.\\n\\n\";\n+    emit_bypasses bypasses\n+"}, {"sha": "c62ffc3cff674665f622003de8a4d5ce2ad20c96", "filename": "gcc/config/arm/neon.md", "status": "modified", "additions": 1066, "deletions": 210, "changes": 1276, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2Fconfig%2Farm%2Fneon.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c956e102dfffb7d5fa5e6051a2b35f146ca9c52b/gcc%2Fconfig%2Farm%2Fneon.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fneon.md?ref=c956e102dfffb7d5fa5e6051a2b35f146ca9c52b", "patch": "@@ -416,6 +416,106 @@\n (define_mode_attr scalar_mul_constraint [(V4HI \"x\") (V2SI \"t\") (V2SF \"t\")\n                                          (V8HI \"x\") (V4SI \"t\") (V4SF \"t\")])\n \n+;; Attribute used to permit string comparisons against <VQH_mnem> in\n+;; neon_type attribute definitions.\n+(define_attr \"vqh_mnem\" \"vadd,vmin,vmax\" (const_string \"vadd\"))\n+\n+;; Classification of NEON instructions for scheduling purposes.\n+;; Do not set this attribute and the \"type\" attribute together in\n+;; any one instruction pattern.\n+(define_attr \"neon_type\"\n+   \"neon_int_1,\\\n+   neon_int_2,\\\n+   neon_int_3,\\\n+   neon_int_4,\\\n+   neon_int_5,\\\n+   neon_vqneg_vqabs,\\\n+   neon_vmov,\\\n+   neon_vaba,\\\n+   neon_vsma,\\\n+   neon_vaba_qqq,\\\n+   neon_mul_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+   neon_mul_qqq_8_16_32_ddd_32,\\\n+   neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar,\\\n+   neon_mla_ddd_8_16_qdd_16_8_long_32_16_long,\\\n+   neon_mla_qqq_8_16,\\\n+   neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long,\\\n+   neon_mla_qqq_32_qqd_32_scalar,\\\n+   neon_mul_ddd_16_scalar_32_16_long_scalar,\\\n+   neon_mul_qqd_32_scalar,\\\n+   neon_mla_ddd_16_scalar_qdd_32_16_long_scalar,\\\n+   neon_shift_1,\\\n+   neon_shift_2,\\\n+   neon_shift_3,\\\n+   neon_vshl_ddd,\\\n+   neon_vqshl_vrshl_vqrshl_qqq,\\\n+   neon_vsra_vrsra,\\\n+   neon_fp_vadd_ddd_vabs_dd,\\\n+   neon_fp_vadd_qqq_vabs_qq,\\\n+   neon_fp_vsum,\\\n+   neon_fp_vmul_ddd,\\\n+   neon_fp_vmul_qqd,\\\n+   neon_fp_vmla_ddd,\\\n+   neon_fp_vmla_qqq,\\\n+   neon_fp_vmla_ddd_scalar,\\\n+   neon_fp_vmla_qqq_scalar,\\\n+   neon_fp_vrecps_vrsqrts_ddd,\\\n+   neon_fp_vrecps_vrsqrts_qqq,\\\n+   neon_bp_simple,\\\n+   neon_bp_2cycle,\\\n+   neon_bp_3cycle,\\\n+   neon_ldr,\\\n+   neon_str,\\\n+   neon_vld1_1_2_regs,\\\n+   neon_vld1_3_4_regs,\\\n+   neon_vld2_2_regs_vld1_vld2_all_lanes,\\\n+   neon_vld2_4_regs,\\\n+   neon_vld3_vld4,\\\n+   neon_vst1_1_2_regs_vst2_2_regs,\\\n+   neon_vst1_3_4_regs,\\\n+   neon_vst2_4_regs_vst3_vst4,\\\n+   neon_vst3_vst4,\\\n+   neon_vld1_vld2_lane,\\\n+   neon_vld3_vld4_lane,\\\n+   neon_vst1_vst2_lane,\\\n+   neon_vst3_vst4_lane,\\\n+   neon_vld3_vld4_all_lanes,\\\n+   neon_mcr,\\\n+   neon_mcr_2_mcrr,\\\n+   neon_mrc,\\\n+   neon_mrrc,\\\n+   neon_ldm_2,\\\n+   neon_stm_2,\\\n+   none\"\n+ (const_string \"none\"))\n+\n+;; Predicates used for setting the above attribute.\n+\n+(define_mode_attr Is_float_mode [(V8QI \"false\") (V16QI \"false\")\n+\t\t\t\t (V4HI \"false\") (V8HI \"false\")\n+\t\t\t\t (V2SI \"false\") (V4SI \"false\")\n+\t\t\t\t (V2SF \"true\") (V4SF \"true\")\n+\t\t\t\t (DI \"false\") (V2DI \"false\")])\n+\n+(define_mode_attr Scalar_mul_8_16 [(V8QI \"true\") (V16QI \"true\")\n+\t\t\t\t   (V4HI \"true\") (V8HI \"true\")\n+\t\t\t\t   (V2SI \"false\") (V4SI \"false\")\n+\t\t\t\t   (V2SF \"false\") (V4SF \"false\")\n+\t\t\t\t   (DI \"false\") (V2DI \"false\")])\n+\n+\n+(define_mode_attr Is_d_reg [(V8QI \"true\") (V16QI \"false\")\n+                            (V4HI \"true\") (V8HI  \"false\")\n+                            (V2SI \"true\") (V4SI  \"false\")\n+                            (V2SF \"true\") (V4SF  \"false\")\n+                            (DI   \"true\") (V2DI  \"false\")])\n+\n+(define_mode_attr V_mode_nunits [(V8QI \"8\") (V16QI \"16\")\n+                                 (V4HI \"4\") (V8HI \"8\")\n+                                 (V2SI \"2\") (V4SI \"4\")\n+                                 (V2SF \"2\") (V4SF \"4\")\n+                                 (DI \"1\")   (V2DI \"2\")])\n+\n (define_insn \"*neon_mov<mode>\"\n   [(set (match_operand:VD 0 \"nonimmediate_operand\"\n \t  \"=w,Uv,w, w,  ?r,?w,?r,?r, ?Us\")\n@@ -456,10 +556,12 @@\n     default: return output_move_double (operands);\n     }\n }\n-  [(set_attr \"type\" \"farith,f_stored,farith,f_loadd,f_2_r,r_2_f,*,load2,store2\")\n-   (set_attr \"length\" \"4,4,4,4,4,4,8,8,8\")\n-   (set_attr \"pool_range\"     \"*,*,*,1020,*,*,*,1020,*\")\n-   (set_attr \"neg_pool_range\" \"*,*,*,1008,*,*,*,1008,*\")])\n+ [(set_attr \"neon_type\" \"neon_int_1,*,neon_vmov,*,neon_mrrc,neon_mcr_2_mcrr,*,*,*\")\n+  (set_attr \"type\" \"*,f_stored,*,f_loadd,*,*,alu,load2,store2\")\n+  (set_attr \"insn\" \"*,*,*,*,*,*,mov,*,*\")\n+  (set_attr \"length\" \"4,4,4,4,4,4,8,8,8\")\n+  (set_attr \"pool_range\"     \"*,*,*,1020,*,*,*,1020,*\")\n+  (set_attr \"neg_pool_range\" \"*,*,*,1008,*,*,*,1008,*\")])\n \n (define_insn \"*neon_mov<mode>\"\n   [(set (match_operand:VQXMOV 0 \"nonimmediate_operand\"\n@@ -496,7 +598,10 @@\n     default: return output_move_quad (operands);\n     }\n }\n-  [(set_attr \"type\" \"farith,f_stored,farith,f_loadd,f_2_r,r_2_f,*,load2,store2\")\n+  [(set_attr \"neon_type\" \"neon_int_1,neon_stm_2,neon_vmov,neon_ldm_2,\\\n+                          neon_mrrc,neon_mcr_2_mcrr,*,*,*\")\n+   (set_attr \"type\" \"*,*,*,*,*,*,alu,load4,store4\")\n+   (set_attr \"insn\" \"*,*,*,*,*,*,mov,*,*\")\n    (set_attr \"length\" \"4,8,4,8,8,8,16,8,16\")\n    (set_attr \"pool_range\" \"*,*,*,1020,*,*,*,1020,*\")\n    (set_attr \"neg_pool_range\" \"*,*,*,1008,*,*,*,1008,*\")])\n@@ -624,7 +729,9 @@\n                      (match_operand:SI 2 \"immediate_operand\" \"i\"))))]\n   \"TARGET_NEON\"\n   \"vmov%?.<V_uf_sclr>\\t%P0[%c2], %1\"\n-  [(set_attr \"predicable\" \"yes\")])\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_mcr\")]\n+)\n \n (define_insn \"vec_set<mode>\"\n   [(set (match_operand:VQ 0 \"s_register_operand\" \"+w\")\n@@ -646,7 +753,9 @@\n \n   return \"vmov%?.<V_uf_sclr>\\t%P0[%c2], %1\";\n }\n-  [(set_attr \"predicable\" \"yes\")])\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_mcr\")]\n+)\n \n (define_insn \"vec_setv2di\"\n   [(set (match_operand:V2DI 0 \"s_register_operand\" \"+w\")\n@@ -664,7 +773,9 @@\n \n   return \"vmov%?.64\\t%P0, %Q1, %R1\";\n }\n-  [(set_attr \"predicable\" \"yes\")])\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_mcr_2_mcrr\")]\n+)\n \n (define_insn \"vec_extract<mode>\"\n   [(set (match_operand:<V_elem> 0 \"s_register_operand\" \"=r\")\n@@ -673,7 +784,9 @@\n           (parallel [(match_operand:SI 2 \"immediate_operand\" \"i\")])))]\n   \"TARGET_NEON\"\n   \"vmov%?.<V_uf_sclr>\\t%0, %P1[%c2]\"\n-  [(set_attr \"predicable\" \"yes\")])\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"vec_extract<mode>\"\n   [(set (match_operand:<V_elem> 0 \"s_register_operand\" \"=r\")\n@@ -692,7 +805,9 @@\n \n   return \"vmov%?.<V_uf_sclr>\\t%0, %P1[%c2]\";\n }\n-  [(set_attr \"predicable\" \"yes\")])\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"vec_extractv2di\"\n   [(set (match_operand:DI 0 \"s_register_operand\" \"=r\")\n@@ -707,7 +822,9 @@\n \n   return \"vmov%?.64\\t%Q0, %R0, %P1\";\n }\n-  [(set_attr \"predicable\" \"yes\")])\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_expand \"vec_init<mode>\"\n   [(match_operand:VDQ 0 \"s_register_operand\" \"\")\n@@ -731,21 +848,49 @@\n         (plus:VDQ (match_operand:VDQ 1 \"s_register_operand\" \"w\")\n \t\t  (match_operand:VDQ 2 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vadd.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vadd.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                                  (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                    (const_string \"neon_int_1\")))]\n+)\n \n (define_insn \"*sub<mode>3_neon\"\n   [(set (match_operand:VDQ 0 \"s_register_operand\" \"=w\")\n         (minus:VDQ (match_operand:VDQ 1 \"s_register_operand\" \"w\")\n                    (match_operand:VDQ 2 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vsub.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vsub.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                                  (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                    (const_string \"neon_int_2\")))]\n+)\n \n (define_insn \"*mul<mode>3_neon\"\n   [(set (match_operand:VDQ 0 \"s_register_operand\" \"=w\")\n         (mult:VDQ (match_operand:VDQ 1 \"s_register_operand\" \"w\")\n                   (match_operand:VDQ 2 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vmul.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vmul.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                                  (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (if_then_else\n+                                    (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                                    (const_string \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\")\n+                                    (const_string \"neon_mul_qqq_8_16_32_ddd_32\"))\n+                                  (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                                    (const_string \"neon_mul_qqq_8_16_32_ddd_32\")\n+                                    (const_string \"neon_mul_qqq_8_16_32_ddd_32\")))))]\n+)\n \n (define_insn \"ior<mode>3\"\n   [(set (match_operand:VDQ 0 \"s_register_operand\" \"=w,w\")\n@@ -760,7 +905,9 @@\n \t\t     <MODE>mode, 0, VALID_NEON_QREG_MODE (<MODE>mode));\n     default: gcc_unreachable ();\n     }\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_insn \"iordi3_neon\"\n   [(set (match_operand:DI 0 \"s_register_operand\" \"=w,w\")\n@@ -776,7 +923,9 @@\n \t\t     DImode, 0, VALID_NEON_QREG_MODE (DImode));\n     default: gcc_unreachable ();\n     }\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n ;; The concrete forms of the Neon immediate-logic instructions are vbic and\n ;; vorr. We support the pseudo-instruction vand instead, because that\n@@ -796,7 +945,9 @@\n     \t\t     <MODE>mode, 1, VALID_NEON_QREG_MODE (<MODE>mode));\n     default: gcc_unreachable ();\n     }\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_insn \"anddi3_neon\"\n   [(set (match_operand:DI 0 \"s_register_operand\" \"=w,w\")\n@@ -812,98 +963,142 @@\n     \t\t     DImode, 1, VALID_NEON_QREG_MODE (DImode));\n     default: gcc_unreachable ();\n     }\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_insn \"orn<mode>3_neon\"\n   [(set (match_operand:VDQ 0 \"s_register_operand\" \"=w\")\n \t(ior:VDQ (match_operand:VDQ 1 \"s_register_operand\" \"w\")\n \t\t (not:VDQ (match_operand:VDQ 2 \"s_register_operand\" \"w\"))))]\n   \"TARGET_NEON\"\n-  \"vorn\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vorn\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_insn \"orndi3_neon\"\n   [(set (match_operand:DI 0 \"s_register_operand\" \"=w\")\n \t(unspec:DI [(match_operand:DI 1 \"s_register_operand\" \"w\")\n \t\t    (match_operand:DI 2 \"s_register_operand\" \"w\")]\n                     UNSPEC_VORN))]\n   \"TARGET_NEON\"\n-  \"vorn\\t%P0, %P1, %P2\")\n+  \"vorn\\t%P0, %P1, %P2\"\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_insn \"bic<mode>3_neon\"\n   [(set (match_operand:VDQ 0 \"s_register_operand\" \"=w\")\n \t(and:VDQ (match_operand:VDQ 1 \"s_register_operand\" \"w\")\n \t\t  (not:VDQ (match_operand:VDQ 2 \"s_register_operand\" \"w\"))))]\n   \"TARGET_NEON\"\n-  \"vbic\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vbic\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_insn \"bicdi3_neon\"\n   [(set (match_operand:DI 0 \"s_register_operand\" \"=w\")\n \t(unspec:DI [(match_operand:DI 1 \"s_register_operand\" \"w\")\n \t\t     (match_operand:DI 2 \"s_register_operand\" \"w\")]\n                     UNSPEC_VBIC))]\n   \"TARGET_NEON\"\n-  \"vbic\\t%P0, %P1, %P2\")\n+  \"vbic\\t%P0, %P1, %P2\"\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_insn \"xor<mode>3\"\n   [(set (match_operand:VDQ 0 \"s_register_operand\" \"=w\")\n \t(xor:VDQ (match_operand:VDQ 1 \"s_register_operand\" \"w\")\n \t\t (match_operand:VDQ 2 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"veor\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"veor\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_insn \"xordi3_neon\"\n   [(set (match_operand:DI 0 \"s_register_operand\" \"=w\")\n \t(unspec:DI [(match_operand:DI 1 \"s_register_operand\" \"w\")\n \t\t     (match_operand:DI 2 \"s_register_operand\" \"w\")]\n                     UNSPEC_VEOR))]\n   \"TARGET_NEON\"\n-  \"veor\\t%P0, %P1, %P2\")\n+  \"veor\\t%P0, %P1, %P2\"\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_insn \"one_cmpl<mode>2\"\n   [(set (match_operand:VDQ 0 \"s_register_operand\" \"=w\")\n         (not:VDQ (match_operand:VDQ 1 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vmvn\\t%<V_reg>0, %<V_reg>1\")\n+  \"vmvn\\t%<V_reg>0, %<V_reg>1\"\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_insn \"abs<mode>2\"\n   [(set (match_operand:VDQW 0 \"s_register_operand\" \"=w\")\n \t(abs:VDQW (match_operand:VDQW 1 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vabs.<V_s_elem>\\t%<V_reg>0, %<V_reg>1\")\n+  \"vabs.<V_s_elem>\\t%<V_reg>0, %<V_reg>1\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                                  (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                    (const_string \"neon_int_3\")))]\n+)\n \n (define_insn \"neg<mode>2\"\n   [(set (match_operand:VDQW 0 \"s_register_operand\" \"=w\")\n \t(neg:VDQW (match_operand:VDQW 1 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vneg.<V_s_elem>\\t%<V_reg>0, %<V_reg>1\")\n+  \"vneg.<V_s_elem>\\t%<V_reg>0, %<V_reg>1\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                                  (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                    (const_string \"neon_int_3\")))]\n+)\n \n (define_insn \"*umin<mode>3_neon\"\n   [(set (match_operand:VDQIW 0 \"s_register_operand\" \"=w\")\n \t(umin:VDQIW (match_operand:VDQIW 1 \"s_register_operand\" \"w\")\n \t\t    (match_operand:VDQIW 2 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vmin.<V_u_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vmin.<V_u_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set_attr \"neon_type\" \"neon_int_5\")]\n+)\n \n (define_insn \"*umax<mode>3_neon\"\n   [(set (match_operand:VDQIW 0 \"s_register_operand\" \"=w\")\n \t(umax:VDQIW (match_operand:VDQIW 1 \"s_register_operand\" \"w\")\n \t\t    (match_operand:VDQIW 2 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vmax.<V_u_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vmax.<V_u_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set_attr \"neon_type\" \"neon_int_5\")]\n+)\n \n (define_insn \"*smin<mode>3_neon\"\n   [(set (match_operand:VDQW 0 \"s_register_operand\" \"=w\")\n \t(smin:VDQW (match_operand:VDQW 1 \"s_register_operand\" \"w\")\n \t\t   (match_operand:VDQW 2 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vmin.<V_s_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vmin.<V_s_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                    (const_string \"neon_int_5\")))]\n+)\n \n (define_insn \"*smax<mode>3_neon\"\n   [(set (match_operand:VDQW 0 \"s_register_operand\" \"=w\")\n \t(smax:VDQW (match_operand:VDQW 1 \"s_register_operand\" \"w\")\n \t\t   (match_operand:VDQW 2 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vmax.<V_s_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vmax.<V_s_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                    (const_string \"neon_int_5\")))]\n+)\n \n ; TODO: V2DI shifts are current disabled because there are bugs in the\n ; generic vectorizer code.  It ends up creating a V2DI constructor with\n@@ -914,7 +1109,12 @@\n \t(ashift:VDQIW (match_operand:VDQIW 1 \"s_register_operand\" \"w\")\n \t\t      (match_operand:VDQIW 2 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vshl.<V_s_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vshl.<V_s_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                    (const_string \"neon_vshl_ddd\")\n+                    (const_string \"neon_shift_3\")))]\n+)\n \n ; Used for implementing logical shift-right, which is a left-shift by a negative\n ; amount, with signed operands. This is essentially the same as ashl<mode>3\n@@ -927,7 +1127,12 @@\n \t\t      (match_operand:VDQI 2 \"s_register_operand\" \"w\")]\n \t\t     UNSPEC_ASHIFT_SIGNED))]\n   \"TARGET_NEON\"\n-  \"vshl.<V_s_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vshl.<V_s_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                    (const_string \"neon_vshl_ddd\")\n+                    (const_string \"neon_shift_3\")))]\n+)\n \n ; Used for implementing logical shift-right, which is a left-shift by a negative\n ; amount, with unsigned operands.\n@@ -938,7 +1143,12 @@\n \t\t      (match_operand:VDQI 2 \"s_register_operand\" \"w\")]\n \t\t     UNSPEC_ASHIFT_UNSIGNED))]\n   \"TARGET_NEON\"\n-  \"vshl.<V_u_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vshl.<V_u_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                    (const_string \"neon_vshl_ddd\")\n+                    (const_string \"neon_shift_3\")))]\n+)\n \n (define_expand \"ashr<mode>3\"\n   [(set (match_operand:VDQIW 0 \"s_register_operand\" \"\")\n@@ -976,15 +1186,19 @@\n \t\t\t  (match_operand:VW 1 \"s_register_operand\" \"%w\"))\n \t\t        (match_operand:<V_widen> 2 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vaddw.<V_s_elem>\\t%q0, %q2, %P1\")\n+  \"vaddw.<V_s_elem>\\t%q0, %q2, %P1\"\n+  [(set_attr \"neon_type\" \"neon_int_3\")]\n+)\n \n (define_insn \"widen_usum<mode>3\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n \t(plus:<V_widen> (zero_extend:<V_widen>\n \t\t\t  (match_operand:VW 1 \"s_register_operand\" \"%w\"))\n \t\t        (match_operand:<V_widen> 2 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vaddw.<V_u_elem>\\t%q0, %q2, %P1\")\n+  \"vaddw.<V_u_elem>\\t%q0, %q2, %P1\"\n+  [(set_attr \"neon_type\" \"neon_int_3\")]\n+)\n \n ;; VEXT can be used to synthesize coarse whole-vector shifts with 8-bit\n ;; shift-count granularity. That's good enough for the middle-end's current\n@@ -1062,7 +1276,12 @@\n           (vec_select:V2SI (match_dup 1)\n                            (parallel [(const_int 2) (const_int 3)]))))]\n   \"TARGET_NEON\"\n-  \"<VQH_mnem>.<VQH_sign>32\\t%P0, %e1, %f1\")\n+  \"<VQH_mnem>.<VQH_sign>32\\t%P0, %e1, %f1\"\n+  [(set_attr \"vqh_mnem\" \"<VQH_mnem>\")\n+   (set (attr \"neon_type\")\n+      (if_then_else (eq_attr \"vqh_mnem\" \"vadd\")\n+                    (const_string \"neon_int_1\") (const_string \"neon_int_5\")))]\n+)\n \n (define_insn \"quad_halves_<code>v4sf\"\n   [(set (match_operand:V2SF 0 \"s_register_operand\" \"=w\")\n@@ -1072,7 +1291,12 @@\n           (vec_select:V2SF (match_dup 1)\n                            (parallel [(const_int 2) (const_int 3)]))))]\n   \"TARGET_NEON\"\n-  \"<VQH_mnem>.f32\\t%P0, %e1, %f1\")\n+  \"<VQH_mnem>.f32\\t%P0, %e1, %f1\"\n+  [(set_attr \"vqh_mnem\" \"<VQH_mnem>\")\n+   (set (attr \"neon_type\")\n+      (if_then_else (eq_attr \"vqh_mnem\" \"vadd\")\n+                    (const_string \"neon_int_1\") (const_string \"neon_int_5\")))]\n+)\n \n (define_insn \"quad_halves_<code>v8hi\"\n   [(set (match_operand:V4HI 0 \"s_register_operand\" \"+w\")\n@@ -1084,7 +1308,12 @@\n                            (parallel [(const_int 4) (const_int 5)\n \t\t\t\t      (const_int 6) (const_int 7)]))))]\n   \"TARGET_NEON\"\n-  \"<VQH_mnem>.<VQH_sign>16\\t%P0, %e1, %f1\")\n+  \"<VQH_mnem>.<VQH_sign>16\\t%P0, %e1, %f1\"\n+  [(set_attr \"vqh_mnem\" \"<VQH_mnem>\")\n+   (set (attr \"neon_type\")\n+      (if_then_else (eq_attr \"vqh_mnem\" \"vadd\")\n+                    (const_string \"neon_int_1\") (const_string \"neon_int_5\")))]\n+)\n \n (define_insn \"quad_halves_<code>v16qi\"\n   [(set (match_operand:V8QI 0 \"s_register_operand\" \"+w\")\n@@ -1100,7 +1329,12 @@\n \t\t\t\t      (const_int 12) (const_int 13)\n \t\t\t\t      (const_int 14) (const_int 15)]))))]\n   \"TARGET_NEON\"\n-  \"<VQH_mnem>.<VQH_sign>8\\t%P0, %e1, %f1\")\n+  \"<VQH_mnem>.<VQH_sign>8\\t%P0, %e1, %f1\"\n+  [(set_attr \"vqh_mnem\" \"<VQH_mnem>\")\n+   (set (attr \"neon_type\")\n+      (if_then_else (eq_attr \"vqh_mnem\" \"vadd\")\n+                    (const_string \"neon_int_1\") (const_string \"neon_int_5\")))]\n+)\n \n ; FIXME: We wouldn't need the following insns if we could write subregs of\n ; vector registers. Make an attempt at removing unnecessary moves, though\n@@ -1121,7 +1355,9 @@\n     return \"vmov\\t%e0, %P1\";\n   else\n     return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"move_lo_quad_v4sf\"\n   [(set (match_operand:V4SF 0 \"s_register_operand\" \"+w\")\n@@ -1138,7 +1374,9 @@\n     return \"vmov\\t%e0, %P1\";\n   else\n     return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"move_lo_quad_v8hi\"\n   [(set (match_operand:V8HI 0 \"s_register_operand\" \"+w\")\n@@ -1156,7 +1394,9 @@\n     return \"vmov\\t%e0, %P1\";\n   else\n     return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"move_lo_quad_v16qi\"\n   [(set (match_operand:V16QI 0 \"s_register_operand\" \"+w\")\n@@ -1176,7 +1416,9 @@\n     return \"vmov\\t%e0, %P1\";\n   else\n     return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n ;; Reduction operations\n \n@@ -1210,7 +1452,9 @@\n \t(unspec:V2DI [(match_operand:V2DI 1 \"s_register_operand\" \"w\")]\n \t\t     UNSPEC_VPADD))]\n   \"TARGET_NEON\"\n-  \"vadd.i64\\t%e0, %e1, %f1\")\n+  \"vadd.i64\\t%e0, %e1, %f1\"\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n ;; NEON does not distinguish between signed and unsigned addition except on\n ;; widening operations.\n@@ -1329,39 +1573,65 @@\n \t\t    (match_operand:VD 2 \"s_register_operand\" \"w\")]\n                    UNSPEC_VPADD))]\n   \"TARGET_NEON\"\n-  \"vpadd.<V_if_elem>\\t%P0, %P1, %P2\")\n+  \"vpadd.<V_if_elem>\\t%P0, %P1, %P2\"\n+  ;; Assume this schedules like vadd.\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                                  (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                    (const_string \"neon_int_1\")))]\n+)\n \n (define_insn \"neon_vpsmin<mode>\"\n   [(set (match_operand:VD 0 \"s_register_operand\" \"=w\")\n \t(unspec:VD [(match_operand:VD 1 \"s_register_operand\" \"w\")\n \t\t    (match_operand:VD 2 \"s_register_operand\" \"w\")]\n                    UNSPEC_VPSMIN))]\n   \"TARGET_NEON\"\n-  \"vpmin.<V_s_elem>\\t%P0, %P1, %P2\")\n+  \"vpmin.<V_s_elem>\\t%P0, %P1, %P2\"\n+  ;; Assume this schedules like vmin.\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                    (const_string \"neon_int_5\")))]\n+)\n \n (define_insn \"neon_vpsmax<mode>\"\n   [(set (match_operand:VD 0 \"s_register_operand\" \"=w\")\n \t(unspec:VD [(match_operand:VD 1 \"s_register_operand\" \"w\")\n \t\t    (match_operand:VD 2 \"s_register_operand\" \"w\")]\n                    UNSPEC_VPSMAX))]\n   \"TARGET_NEON\"\n-  \"vpmax.<V_s_elem>\\t%P0, %P1, %P2\")\n+  \"vpmax.<V_s_elem>\\t%P0, %P1, %P2\"\n+  ;; Assume this schedules like vmax.\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                    (const_string \"neon_int_5\")))]\n+)\n \n (define_insn \"neon_vpumin<mode>\"\n   [(set (match_operand:VDI 0 \"s_register_operand\" \"=w\")\n \t(unspec:VDI [(match_operand:VDI 1 \"s_register_operand\" \"w\")\n \t\t     (match_operand:VDI 2 \"s_register_operand\" \"w\")]\n                    UNSPEC_VPUMIN))]\n   \"TARGET_NEON\"\n-  \"vpmin.<V_u_elem>\\t%P0, %P1, %P2\")\n+  \"vpmin.<V_u_elem>\\t%P0, %P1, %P2\"\n+  ;; Assume this schedules like umin.\n+  [(set_attr \"neon_type\" \"neon_int_5\")]\n+)\n \n (define_insn \"neon_vpumax<mode>\"\n   [(set (match_operand:VDI 0 \"s_register_operand\" \"=w\")\n \t(unspec:VDI [(match_operand:VDI 1 \"s_register_operand\" \"w\")\n \t\t     (match_operand:VDI 2 \"s_register_operand\" \"w\")]\n                    UNSPEC_VPUMAX))]\n   \"TARGET_NEON\"\n-  \"vpmax.<V_u_elem>\\t%P0, %P1, %P2\")\n+  \"vpmax.<V_u_elem>\\t%P0, %P1, %P2\"\n+  ;; Assume this schedules like umax.\n+  [(set_attr \"neon_type\" \"neon_int_5\")]\n+)\n \n ;; Saturating arithmetic\n \n@@ -1376,28 +1646,36 @@\n        (ss_plus:VD (match_operand:VD 1 \"s_register_operand\" \"w\")\n                    (match_operand:VD 2 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vqadd.<V_s_elem>\\t%P0, %P1, %P2\")\n+  \"vqadd.<V_s_elem>\\t%P0, %P1, %P2\"\n+  [(set_attr \"neon_type\" \"neon_int_4\")]\n+)\n \n (define_insn \"*us_add<mode>_neon\"\n   [(set (match_operand:VD 0 \"s_register_operand\" \"=w\")\n        (us_plus:VD (match_operand:VD 1 \"s_register_operand\" \"w\")\n                    (match_operand:VD 2 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vqadd.<V_u_elem>\\t%P0, %P1, %P2\")\n+  \"vqadd.<V_u_elem>\\t%P0, %P1, %P2\"\n+  [(set_attr \"neon_type\" \"neon_int_4\")]\n+)\n \n (define_insn \"*ss_sub<mode>_neon\"\n   [(set (match_operand:VD 0 \"s_register_operand\" \"=w\")\n        (ss_minus:VD (match_operand:VD 1 \"s_register_operand\" \"w\")\n                     (match_operand:VD 2 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vqsub.<V_s_elem>\\t%P0, %P1, %P2\")\n+  \"vqsub.<V_s_elem>\\t%P0, %P1, %P2\"\n+  [(set_attr \"neon_type\" \"neon_int_5\")]\n+)\n \n (define_insn \"*us_sub<mode>_neon\"\n   [(set (match_operand:VD 0 \"s_register_operand\" \"=w\")\n        (us_minus:VD (match_operand:VD 1 \"s_register_operand\" \"w\")\n                     (match_operand:VD 2 \"s_register_operand\" \"w\")))]\n   \"TARGET_NEON\"\n-  \"vqsub.<V_u_elem>\\t%P0, %P1, %P2\")\n+  \"vqsub.<V_u_elem>\\t%P0, %P1, %P2\"\n+  [(set_attr \"neon_type\" \"neon_int_5\")]\n+)\n \n ;; Patterns for builtins.\n \n@@ -1410,7 +1688,14 @@\n                       (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                      UNSPEC_VADD))]\n   \"TARGET_NEON\"\n-  \"vadd.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vadd.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                                  (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                    (const_string \"neon_int_1\")))]\n+)\n \n ; operand 3 represents in bits:\n ;  bit 0: signed (vs unsigned).\n@@ -1423,7 +1708,9 @@\n                            (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                           UNSPEC_VADDL))]\n   \"TARGET_NEON\"\n-  \"vaddl.%T3%#<V_sz_elem>\\t%q0, %P1, %P2\")\n+  \"vaddl.%T3%#<V_sz_elem>\\t%q0, %P1, %P2\"\n+  [(set_attr \"neon_type\" \"neon_int_3\")]\n+)\n \n (define_insn \"neon_vaddw<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -1432,7 +1719,9 @@\n                            (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                           UNSPEC_VADDW))]\n   \"TARGET_NEON\"\n-  \"vaddw.%T3%#<V_sz_elem>\\t%q0, %q1, %P2\")\n+  \"vaddw.%T3%#<V_sz_elem>\\t%q0, %q1, %P2\"\n+  [(set_attr \"neon_type\" \"neon_int_2\")]\n+)\n \n ; vhadd and vrhadd.\n \n@@ -1443,7 +1732,9 @@\n \t\t       (match_operand:SI 3 \"immediate_operand\" \"i\")]\n \t\t      UNSPEC_VHADD))]\n   \"TARGET_NEON\"\n-  \"v%O3hadd.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"v%O3hadd.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set_attr \"neon_type\" \"neon_int_4\")]\n+)\n \n (define_insn \"neon_vqadd<mode>\"\n   [(set (match_operand:VDQIX 0 \"s_register_operand\" \"=w\")\n@@ -1452,7 +1743,9 @@\n                        (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                      UNSPEC_VQADD))]\n   \"TARGET_NEON\"\n-  \"vqadd.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vqadd.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set_attr \"neon_type\" \"neon_int_4\")]\n+)\n \n (define_insn \"neon_vaddhn<mode>\"\n   [(set (match_operand:<V_narrow> 0 \"s_register_operand\" \"=w\")\n@@ -1461,7 +1754,9 @@\n                             (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                            UNSPEC_VADDHN))]\n   \"TARGET_NEON\"\n-  \"v%O3addhn.<V_if_elem>\\t%P0, %q1, %q2\")\n+  \"v%O3addhn.<V_if_elem>\\t%P0, %q1, %q2\"\n+  [(set_attr \"neon_type\" \"neon_int_4\")]\n+)\n \n (define_insn \"neon_vmul<mode>\"\n   [(set (match_operand:VDQW 0 \"s_register_operand\" \"=w\")\n@@ -1470,7 +1765,21 @@\n \t\t      (match_operand:SI 3 \"immediate_operand\" \"i\")]\n \t\t     UNSPEC_VMUL))]\n   \"TARGET_NEON\"\n-  \"vmul.%F3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vmul.%F3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                                  (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (if_then_else\n+                                    (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                                    (const_string \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\")\n+                                    (const_string \"neon_mul_qqq_8_16_32_ddd_32\"))\n+                                  (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                                    (const_string \"neon_mul_qqq_8_16_32_ddd_32\")\n+                                    (const_string \"neon_mul_qqq_8_16_32_ddd_32\")))))]\n+)\n \n (define_insn \"neon_vmla<mode>\"\n   [(set (match_operand:VDQW 0 \"s_register_operand\" \"=w\")\n@@ -1480,7 +1789,21 @@\n                      (match_operand:SI 4 \"immediate_operand\" \"i\")]\n                     UNSPEC_VMLA))]\n   \"TARGET_NEON\"\n-  \"vmla.<V_if_elem>\\t%<V_reg>0, %<V_reg>2, %<V_reg>3\")\n+  \"vmla.<V_if_elem>\\t%<V_reg>0, %<V_reg>2, %<V_reg>3\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (const_string \"neon_fp_vmla_ddd\")\n+                                  (const_string \"neon_fp_vmla_qqq\"))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (if_then_else\n+                                    (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                                    (const_string \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\")\n+                                    (const_string \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\"))\n+                                  (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                                    (const_string \"neon_mla_qqq_8_16\")\n+                                    (const_string \"neon_mla_qqq_32_qqd_32_scalar\")))))]\n+)\n \n (define_insn \"neon_vmlal<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -1490,7 +1813,12 @@\n                            (match_operand:SI 4 \"immediate_operand\" \"i\")]\n                           UNSPEC_VMLAL))]\n   \"TARGET_NEON\"\n-  \"vmlal.%T4%#<V_sz_elem>\\t%q0, %P2, %P3\")\n+  \"vmlal.%T4%#<V_sz_elem>\\t%q0, %P2, %P3\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                   (const_string \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\")\n+                   (const_string \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\")))]\n+)\n \n (define_insn \"neon_vmls<mode>\"\n   [(set (match_operand:VDQW 0 \"s_register_operand\" \"=w\")\n@@ -1500,7 +1828,22 @@\n                      (match_operand:SI 4 \"immediate_operand\" \"i\")]\n                     UNSPEC_VMLS))]\n   \"TARGET_NEON\"\n-  \"vmls.<V_if_elem>\\t%<V_reg>0, %<V_reg>2, %<V_reg>3\")\n+  \"vmls.<V_if_elem>\\t%<V_reg>0, %<V_reg>2, %<V_reg>3\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (const_string \"neon_fp_vmla_ddd\")\n+                                  (const_string \"neon_fp_vmla_qqq\"))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (if_then_else\n+                                    (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                                    (const_string \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\")\n+                                    (const_string \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\"))\n+                                  (if_then_else\n+                                    (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                                    (const_string \"neon_mla_qqq_8_16\")\n+                                    (const_string \"neon_mla_qqq_32_qqd_32_scalar\")))))]\n+)\n \n (define_insn \"neon_vmlsl<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -1510,7 +1853,12 @@\n                            (match_operand:SI 4 \"immediate_operand\" \"i\")]\n                           UNSPEC_VMLSL))]\n   \"TARGET_NEON\"\n-  \"vmlsl.%T4%#<V_sz_elem>\\t%q0, %P2, %P3\")\n+  \"vmlsl.%T4%#<V_sz_elem>\\t%q0, %P2, %P3\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                   (const_string \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\")\n+                   (const_string \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\")))]\n+)\n \n (define_insn \"neon_vqdmulh<mode>\"\n   [(set (match_operand:VMDQI 0 \"s_register_operand\" \"=w\")\n@@ -1519,7 +1867,16 @@\n                        (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                       UNSPEC_VQDMULH))]\n   \"TARGET_NEON\"\n-  \"vq%O3dmulh.<V_s_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vq%O3dmulh.<V_s_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+        (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                      (const_string \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\")\n+                      (const_string \"neon_mul_qqq_8_16_32_ddd_32\"))\n+        (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                      (const_string \"neon_mul_qqq_8_16_32_ddd_32\")\n+                      (const_string \"neon_mul_qqq_8_16_32_ddd_32\"))))]\n+)\n \n (define_insn \"neon_vqdmlal<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -1529,7 +1886,12 @@\n                            (match_operand:SI 4 \"immediate_operand\" \"i\")]\n                           UNSPEC_VQDMLAL))]\n   \"TARGET_NEON\"\n-  \"vqdmlal.<V_s_elem>\\t%q0, %P2, %P3\")\n+  \"vqdmlal.<V_s_elem>\\t%q0, %P2, %P3\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                   (const_string \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\")\n+                   (const_string \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\")))]\n+)\n \n (define_insn \"neon_vqdmlsl<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -1539,7 +1901,12 @@\n                            (match_operand:SI 4 \"immediate_operand\" \"i\")]\n                           UNSPEC_VQDMLSL))]\n   \"TARGET_NEON\"\n-  \"vqdmlsl.<V_s_elem>\\t%q0, %P2, %P3\")\n+  \"vqdmlsl.<V_s_elem>\\t%q0, %P2, %P3\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                   (const_string \"neon_mla_ddd_8_16_qdd_16_8_long_32_16_long\")\n+                   (const_string \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\")))]\n+)\n \n (define_insn \"neon_vmull<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -1548,7 +1915,12 @@\n                            (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                           UNSPEC_VMULL))]\n   \"TARGET_NEON\"\n-  \"vmull.%T3%#<V_sz_elem>\\t%q0, %P1, %P2\")\n+  \"vmull.%T3%#<V_sz_elem>\\t%q0, %P1, %P2\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                   (const_string \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\")\n+                   (const_string \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\")))]\n+)\n \n (define_insn \"neon_vqdmull<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -1557,7 +1929,12 @@\n                            (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                           UNSPEC_VQDMULL))]\n   \"TARGET_NEON\"\n-  \"vqdmull.<V_s_elem>\\t%q0, %P1, %P2\")\n+  \"vqdmull.<V_s_elem>\\t%q0, %P1, %P2\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                   (const_string \"neon_mul_ddd_8_16_qdd_16_8_long_32_16_long\")\n+                   (const_string \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\")))]\n+)\n \n (define_insn \"neon_vsub<mode>\"\n   [(set (match_operand:VDQX 0 \"s_register_operand\" \"=w\")\n@@ -1566,7 +1943,14 @@\n                       (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                      UNSPEC_VSUB))]\n   \"TARGET_NEON\"\n-  \"vsub.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vsub.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                                  (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                    (const_string \"neon_int_2\")))]\n+)\n \n (define_insn \"neon_vsubl<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -1575,7 +1959,9 @@\n                            (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                           UNSPEC_VSUBL))]\n   \"TARGET_NEON\"\n-  \"vsubl.%T3%#<V_sz_elem>\\t%q0, %P1, %P2\")\n+  \"vsubl.%T3%#<V_sz_elem>\\t%q0, %P1, %P2\"\n+  [(set_attr \"neon_type\" \"neon_int_2\")]\n+)\n \n (define_insn \"neon_vsubw<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -1584,7 +1970,9 @@\n                            (match_operand:SI 3 \"immediate_operand\" \"i\")]\n \t\t\t  UNSPEC_VSUBW))]\n   \"TARGET_NEON\"\n-  \"vsubw.%T3%#<V_sz_elem>\\t%q0, %q1, %P2\")\n+  \"vsubw.%T3%#<V_sz_elem>\\t%q0, %q1, %P2\"\n+  [(set_attr \"neon_type\" \"neon_int_2\")]\n+)\n \n (define_insn \"neon_vqsub<mode>\"\n   [(set (match_operand:VDQIX 0 \"s_register_operand\" \"=w\")\n@@ -1593,7 +1981,9 @@\n                        (match_operand:SI 3 \"immediate_operand\" \"i\")]\n \t\t      UNSPEC_VQSUB))]\n   \"TARGET_NEON\"\n-  \"vqsub.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vqsub.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set_attr \"neon_type\" \"neon_int_5\")]\n+)\n \n (define_insn \"neon_vhsub<mode>\"\n   [(set (match_operand:VDQIW 0 \"s_register_operand\" \"=w\")\n@@ -1602,7 +1992,9 @@\n                        (match_operand:SI 3 \"immediate_operand\" \"i\")]\n \t\t      UNSPEC_VHSUB))]\n   \"TARGET_NEON\"\n-  \"vhsub.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vhsub.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set_attr \"neon_type\" \"neon_int_5\")]\n+)\n \n (define_insn \"neon_vsubhn<mode>\"\n   [(set (match_operand:<V_narrow> 0 \"s_register_operand\" \"=w\")\n@@ -1611,7 +2003,9 @@\n                             (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                            UNSPEC_VSUBHN))]\n   \"TARGET_NEON\"\n-  \"v%O3subhn.<V_if_elem>\\t%P0, %q1, %q2\")\n+  \"v%O3subhn.<V_if_elem>\\t%P0, %q1, %q2\"\n+  [(set_attr \"neon_type\" \"neon_int_4\")]\n+)\n \n (define_insn \"neon_vceq<mode>\"\n   [(set (match_operand:<V_cmp_result> 0 \"s_register_operand\" \"=w\")\n@@ -1620,7 +2014,14 @@\n                                 (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                                UNSPEC_VCEQ))]\n   \"TARGET_NEON\"\n-  \"vceq.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vceq.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                    (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                  (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                                  (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                    (const_string \"neon_int_5\")))]\n+)\n \n (define_insn \"neon_vcge<mode>\"\n   [(set (match_operand:<V_cmp_result> 0 \"s_register_operand\" \"=w\")\n@@ -1629,7 +2030,14 @@\n                                 (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                                UNSPEC_VCGE))]\n   \"TARGET_NEON\"\n-  \"vcge.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vcge.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                   (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                 (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                                 (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                   (const_string \"neon_int_5\")))]\n+)\n \n (define_insn \"neon_vcgt<mode>\"\n   [(set (match_operand:<V_cmp_result> 0 \"s_register_operand\" \"=w\")\n@@ -1638,7 +2046,14 @@\n                                 (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                                UNSPEC_VCGT))]\n   \"TARGET_NEON\"\n-  \"vcgt.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vcgt.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                   (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                 (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                                 (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                   (const_string \"neon_int_5\")))]\n+)\n \n (define_insn \"neon_vcage<mode>\"\n   [(set (match_operand:<V_cmp_result> 0 \"s_register_operand\" \"=w\")\n@@ -1647,7 +2062,12 @@\n                                 (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                                UNSPEC_VCAGE))]\n   \"TARGET_NEON\"\n-  \"vacge.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vacge.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                   (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                   (const_string \"neon_fp_vadd_qqq_vabs_qq\")))]\n+)\n \n (define_insn \"neon_vcagt<mode>\"\n   [(set (match_operand:<V_cmp_result> 0 \"s_register_operand\" \"=w\")\n@@ -1656,7 +2076,12 @@\n                                 (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                                UNSPEC_VCAGT))]\n   \"TARGET_NEON\"\n-  \"vacgt.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vacgt.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                   (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                   (const_string \"neon_fp_vadd_qqq_vabs_qq\")))]\n+)\n \n (define_insn \"neon_vtst<mode>\"\n   [(set (match_operand:VDQIW 0 \"s_register_operand\" \"=w\")\n@@ -1665,7 +2090,9 @@\n                        (match_operand:SI 3 \"immediate_operand\" \"i\")]\n \t\t      UNSPEC_VTST))]\n   \"TARGET_NEON\"\n-  \"vtst.<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vtst.<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set_attr \"neon_type\" \"neon_int_4\")]\n+)\n \n (define_insn \"neon_vabd<mode>\"\n   [(set (match_operand:VDQW 0 \"s_register_operand\" \"=w\")\n@@ -1674,7 +2101,14 @@\n \t\t      (match_operand:SI 3 \"immediate_operand\" \"i\")]\n \t\t     UNSPEC_VABD))]\n   \"TARGET_NEON\"\n-  \"vabd.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vabd.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                   (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                 (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                                 (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                   (const_string \"neon_int_5\")))]\n+)\n \n (define_insn \"neon_vabdl<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -1683,7 +2117,9 @@\n                            (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                           UNSPEC_VABDL))]\n   \"TARGET_NEON\"\n-  \"vabdl.%T3%#<V_sz_elem>\\t%q0, %P1, %P2\")\n+  \"vabdl.%T3%#<V_sz_elem>\\t%q0, %P1, %P2\"\n+  [(set_attr \"neon_type\" \"neon_int_5\")]\n+)\n \n (define_insn \"neon_vaba<mode>\"\n   [(set (match_operand:VDQIW 0 \"s_register_operand\" \"=w\")\n@@ -1693,7 +2129,11 @@\n                        (match_operand:SI 4 \"immediate_operand\" \"i\")]\n \t\t      UNSPEC_VABA))]\n   \"TARGET_NEON\"\n-  \"vaba.%T4%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>2, %<V_reg>3\")\n+  \"vaba.%T4%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>2, %<V_reg>3\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                   (const_string \"neon_vaba\") (const_string \"neon_vaba_qqq\")))]\n+)\n \n (define_insn \"neon_vabal<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -1703,7 +2143,9 @@\n                            (match_operand:SI 4 \"immediate_operand\" \"i\")]\n                           UNSPEC_VABAL))]\n   \"TARGET_NEON\"\n-  \"vabal.%T4%#<V_sz_elem>\\t%q0, %P2, %P3\")\n+  \"vabal.%T4%#<V_sz_elem>\\t%q0, %P2, %P3\"\n+  [(set_attr \"neon_type\" \"neon_vaba\")]\n+)\n \n (define_insn \"neon_vmax<mode>\"\n   [(set (match_operand:VDQW 0 \"s_register_operand\" \"=w\")\n@@ -1712,7 +2154,14 @@\n \t\t      (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                      UNSPEC_VMAX))]\n   \"TARGET_NEON\"\n-  \"vmax.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vmax.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+    (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                  (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                                (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                  (const_string \"neon_int_5\")))]\n+)\n \n (define_insn \"neon_vmin<mode>\"\n   [(set (match_operand:VDQW 0 \"s_register_operand\" \"=w\")\n@@ -1721,7 +2170,14 @@\n \t\t      (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                      UNSPEC_VMIN))]\n   \"TARGET_NEON\"\n-  \"vmin.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vmin.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+    (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                  (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                                (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                                (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                  (const_string \"neon_int_5\")))]\n+)\n \n (define_expand \"neon_vpadd<mode>\"\n   [(match_operand:VD 0 \"s_register_operand\" \"=w\")\n@@ -1741,7 +2197,10 @@\n                                   (match_operand:SI 2 \"immediate_operand\" \"i\")]\n                                  UNSPEC_VPADDL))]\n   \"TARGET_NEON\"\n-  \"vpaddl.%T2%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1\")\n+  \"vpaddl.%T2%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1\"\n+  ;; Assume this schedules like vaddl.\n+  [(set_attr \"neon_type\" \"neon_int_3\")]\n+)\n \n (define_insn \"neon_vpadal<mode>\"\n   [(set (match_operand:<V_double_width> 0 \"s_register_operand\" \"=w\")\n@@ -1750,7 +2209,10 @@\n                                   (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                                  UNSPEC_VPADAL))]\n   \"TARGET_NEON\"\n-  \"vpadal.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>2\")\n+  \"vpadal.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>2\"\n+  ;; Assume this schedules like vpadd.\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_insn \"neon_vpmax<mode>\"\n   [(set (match_operand:VD 0 \"s_register_operand\" \"=w\")\n@@ -1759,7 +2221,13 @@\n                     (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                    UNSPEC_VPMAX))]\n   \"TARGET_NEON\"\n-  \"vpmax.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vpmax.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  ;; Assume this schedules like vmax.\n+  [(set (attr \"neon_type\")\n+    (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                  (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                  (const_string \"neon_int_5\")))]\n+)\n \n (define_insn \"neon_vpmin<mode>\"\n   [(set (match_operand:VD 0 \"s_register_operand\" \"=w\")\n@@ -1768,7 +2236,13 @@\n                     (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                    UNSPEC_VPMIN))]\n   \"TARGET_NEON\"\n-  \"vpmin.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vpmin.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  ;; Assume this schedules like vmin.\n+  [(set (attr \"neon_type\")\n+    (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                  (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                  (const_string \"neon_int_5\")))]\n+)\n \n (define_insn \"neon_vrecps<mode>\"\n   [(set (match_operand:VCVTF 0 \"s_register_operand\" \"=w\")\n@@ -1777,7 +2251,12 @@\n                        (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                       UNSPEC_VRECPS))]\n   \"TARGET_NEON\"\n-  \"vrecps.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vrecps.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                    (const_string \"neon_fp_vrecps_vrsqrts_ddd\")\n+                    (const_string \"neon_fp_vrecps_vrsqrts_qqq\")))]\n+)\n \n (define_insn \"neon_vrsqrts<mode>\"\n   [(set (match_operand:VCVTF 0 \"s_register_operand\" \"=w\")\n@@ -1786,23 +2265,39 @@\n                        (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                       UNSPEC_VRSQRTS))]\n   \"TARGET_NEON\"\n-  \"vrsqrts.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vrsqrts.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                    (const_string \"neon_fp_vrecps_vrsqrts_ddd\")\n+                    (const_string \"neon_fp_vrecps_vrsqrts_qqq\")))]\n+)\n \n (define_insn \"neon_vabs<mode>\"\n   [(set (match_operand:VDQW 0 \"s_register_operand\" \"=w\")\n \t(unspec:VDQW [(match_operand:VDQW 1 \"s_register_operand\" \"w\")\n \t\t      (match_operand:SI 2 \"immediate_operand\" \"i\")]\n                      UNSPEC_VABS))]\n   \"TARGET_NEON\"\n-  \"vabs.<V_s_elem>\\t%<V_reg>0, %<V_reg>1\")\n+  \"vabs.<V_s_elem>\\t%<V_reg>0, %<V_reg>1\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ior (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                        (ne (symbol_ref \"<Is_float_mode>\") (const_int 0)))\n+                   (if_then_else\n+                      (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                      (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                      (const_string \"neon_fp_vadd_qqq_vabs_qq\"))\n+                   (const_string \"neon_vqneg_vqabs\")))]\n+)\n \n (define_insn \"neon_vqabs<mode>\"\n   [(set (match_operand:VDQIW 0 \"s_register_operand\" \"=w\")\n \t(unspec:VDQIW [(match_operand:VDQIW 1 \"s_register_operand\" \"w\")\n \t\t       (match_operand:SI 2 \"immediate_operand\" \"i\")]\n \t\t      UNSPEC_VQABS))]\n   \"TARGET_NEON\"\n-  \"vqabs.<V_s_elem>\\t%<V_reg>0, %<V_reg>1\")\n+  \"vqabs.<V_s_elem>\\t%<V_reg>0, %<V_reg>1\"\n+  [(set_attr \"neon_type\" \"neon_vqneg_vqabs\")]\n+)\n \n (define_expand \"neon_vneg<mode>\"\n   [(match_operand:VDQW 0 \"s_register_operand\" \"\")\n@@ -1820,47 +2315,65 @@\n \t\t       (match_operand:SI 2 \"immediate_operand\" \"i\")]\n \t\t      UNSPEC_VQNEG))]\n   \"TARGET_NEON\"\n-  \"vqneg.<V_s_elem>\\t%<V_reg>0, %<V_reg>1\")\n+  \"vqneg.<V_s_elem>\\t%<V_reg>0, %<V_reg>1\"\n+  [(set_attr \"neon_type\" \"neon_vqneg_vqabs\")]\n+)\n \n (define_insn \"neon_vcls<mode>\"\n   [(set (match_operand:VDQIW 0 \"s_register_operand\" \"=w\")\n \t(unspec:VDQIW [(match_operand:VDQIW 1 \"s_register_operand\" \"w\")\n \t\t       (match_operand:SI 2 \"immediate_operand\" \"i\")]\n \t\t      UNSPEC_VCLS))]\n   \"TARGET_NEON\"\n-  \"vcls.<V_s_elem>\\t%<V_reg>0, %<V_reg>1\")\n+  \"vcls.<V_s_elem>\\t%<V_reg>0, %<V_reg>1\"\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_insn \"neon_vclz<mode>\"\n   [(set (match_operand:VDQIW 0 \"s_register_operand\" \"=w\")\n \t(unspec:VDQIW [(match_operand:VDQIW 1 \"s_register_operand\" \"w\")\n \t\t       (match_operand:SI 2 \"immediate_operand\" \"i\")]\n \t\t      UNSPEC_VCLZ))]\n   \"TARGET_NEON\"\n-  \"vclz.<V_if_elem>\\t%<V_reg>0, %<V_reg>1\")\n+  \"vclz.<V_if_elem>\\t%<V_reg>0, %<V_reg>1\"\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_insn \"neon_vcnt<mode>\"\n   [(set (match_operand:VE 0 \"s_register_operand\" \"=w\")\n \t(unspec:VE [(match_operand:VE 1 \"s_register_operand\" \"w\")\n                     (match_operand:SI 2 \"immediate_operand\" \"i\")]\n                    UNSPEC_VCNT))]\n   \"TARGET_NEON\"\n-  \"vcnt.<V_sz_elem>\\t%<V_reg>0, %<V_reg>1\")\n+  \"vcnt.<V_sz_elem>\\t%<V_reg>0, %<V_reg>1\"\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_insn \"neon_vrecpe<mode>\"\n   [(set (match_operand:V32 0 \"s_register_operand\" \"=w\")\n \t(unspec:V32 [(match_operand:V32 1 \"s_register_operand\" \"w\")\n                      (match_operand:SI 2 \"immediate_operand\" \"i\")]\n                     UNSPEC_VRECPE))]\n   \"TARGET_NEON\"\n-  \"vrecpe.<V_u_elem>\\t%<V_reg>0, %<V_reg>1\")\n+  \"vrecpe.<V_u_elem>\\t%<V_reg>0, %<V_reg>1\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                    (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                    (const_string \"neon_fp_vadd_qqq_vabs_qq\")))]\n+)\n \n (define_insn \"neon_vrsqrte<mode>\"\n   [(set (match_operand:V32 0 \"s_register_operand\" \"=w\")\n \t(unspec:V32 [(match_operand:V32 1 \"s_register_operand\" \"w\")\n                      (match_operand:SI 2 \"immediate_operand\" \"i\")]\n                     UNSPEC_VRSQRTE))]\n   \"TARGET_NEON\"\n-  \"vrsqrte.<V_u_elem>\\t%<V_reg>0, %<V_reg>1\")\n+  \"vrsqrte.<V_u_elem>\\t%<V_reg>0, %<V_reg>1\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                    (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                    (const_string \"neon_fp_vadd_qqq_vabs_qq\")))]\n+)\n \n (define_expand \"neon_vmvn<mode>\"\n   [(match_operand:VDQIW 0 \"s_register_operand\" \"\")\n@@ -1883,7 +2396,9 @@\n                          UNSPEC_VGET_LANE))]\n   \"TARGET_NEON\"\n   \"vmov%?.%t3%#<V_sz_elem>\\t%0, %P1[%c2]\"\n-  [(set_attr \"predicable\" \"yes\")])\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n ; Operand 2 (lane number) is ignored because we can only extract the zeroth lane\n ; with this insn. Operand 3 (info word) is ignored because it does nothing\n@@ -1897,7 +2412,9 @@\n                   UNSPEC_VGET_LANE))]\n   \"TARGET_NEON\"\n   \"vmov%?\\t%Q0, %R0, %P1  @ di\"\n-  [(set_attr \"predicable\" \"yes\")])\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"neon_vget_lane<mode>\"\n   [(set (match_operand:<V_elem> 0 \"s_register_operand\" \"=r\")\n@@ -1920,7 +2437,9 @@\n \n   return \"\";\n }\n-  [(set_attr \"predicable\" \"yes\")])\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"neon_vget_lanev2di\"\n   [(set (match_operand:DI 0 \"s_register_operand\" \"=r\")\n@@ -1940,8 +2459,9 @@\n \n   return \"\";\n }\n-  [(set_attr \"predicable\" \"yes\")])\n-\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"neon_vset_lane<mode>\"\n   [(set (match_operand:VD 0 \"s_register_operand\" \"=w\")\n@@ -1951,7 +2471,9 @@\n                    UNSPEC_VSET_LANE))]\n   \"TARGET_NEON\"\n   \"vmov%?.<V_sz_elem>\\t%P0[%c3], %1\"\n-  [(set_attr \"predicable\" \"yes\")])\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n ; See neon_vget_lanedi comment for reasons operands 2 & 3 are ignored.\n \n@@ -1963,7 +2485,9 @@\n                    UNSPEC_VSET_LANE))]\n   \"TARGET_NEON\"\n   \"vmov%?\\t%P0, %Q1, %R1  @ di\"\n-  [(set_attr \"predicable\" \"yes\")])\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"neon_vset_lane<mode>\"\n   [(set (match_operand:VQ 0 \"s_register_operand\" \"=w\")\n@@ -1985,7 +2509,9 @@\n \n   return \"\";\n }\n-  [(set_attr \"predicable\" \"yes\")])\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"neon_vset_lanev2di\"\n   [(set (match_operand:V2DI 0 \"s_register_operand\" \"=w\")\n@@ -2005,7 +2531,9 @@\n \n   return \"\";\n }\n-  [(set_attr \"predicable\" \"yes\")])\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_expand \"neon_vcreate<mode>\"\n   [(match_operand:VDX 0 \"s_register_operand\" \"\")\n@@ -2023,15 +2551,20 @@\n                     UNSPEC_VDUP_N))]\n   \"TARGET_NEON\"\n   \"vdup%?.<V_sz_elem>\\t%<V_reg>0, %1\"\n-  [(set_attr \"predicable\" \"yes\")])\n+  ;; Assume this schedules like vmov.\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"neon_vdup_ndi\"\n   [(set (match_operand:DI 0 \"s_register_operand\" \"=w\")\n \t(unspec:DI [(match_operand:DI 1 \"s_register_operand\" \"r\")]\n                    UNSPEC_VDUP_N))]\n   \"TARGET_NEON\"\n   \"vmov%?\\t%P0, %Q1, %R1\"\n-  [(set_attr \"predicable\" \"yes\")])\n+  [(set_attr \"predicable\" \"yes\")\n+   (set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"neon_vdup_nv2di\"\n   [(set (match_operand:V2DI 0 \"s_register_operand\" \"=w\")\n@@ -2040,23 +2573,31 @@\n   \"TARGET_NEON\"\n   \"vmov%?\\t%e0, %Q1, %R1\\;vmov%?\\t%f0, %Q1, %R1\"\n   [(set_attr \"predicable\" \"yes\")\n-   (set_attr \"length\" \"8\")])\n+   (set_attr \"length\" \"8\")\n+   (set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"neon_vdup_lane<mode>\"\n   [(set (match_operand:VD 0 \"s_register_operand\" \"=w\")\n \t(unspec:VD [(match_operand:VD 1 \"s_register_operand\" \"w\")\n \t\t    (match_operand:SI 2 \"immediate_operand\" \"i\")]\n                    UNSPEC_VDUP_LANE))]\n   \"TARGET_NEON\"\n-  \"vdup.<V_sz_elem>\\t%P0, %P1[%c2]\")\n+  \"vdup.<V_sz_elem>\\t%P0, %P1[%c2]\"\n+  ;; Assume this schedules like vmov.\n+  [(set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"neon_vdup_lane<mode>\"\n   [(set (match_operand:VQ 0 \"s_register_operand\" \"=w\")\n \t(unspec:VQ [(match_operand:<V_HALF> 1 \"s_register_operand\" \"w\")\n \t\t    (match_operand:SI 2 \"immediate_operand\" \"i\")]\n                    UNSPEC_VDUP_LANE))]\n   \"TARGET_NEON\"\n-  \"vdup.<V_sz_elem>\\t%q0, %P1[%c2]\")\n+  \"vdup.<V_sz_elem>\\t%q0, %P1[%c2]\"\n+  ;; Assume this schedules like vmov.\n+  [(set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n ; Scalar index is ignored, since only zero is valid here.\n (define_expand \"neon_vdup_lanedi\"\n@@ -2078,7 +2619,9 @@\n                      UNSPEC_VDUP_LANE))]\n   \"TARGET_NEON\"\n   \"vmov\\t%e0, %P1\\;vmov\\t%f0, %P1\"\n-  [(set_attr \"length\" \"8\")])\n+  [(set_attr \"length\" \"8\")\n+   (set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n ;; In this insn, operand 1 should be low, and operand 2 the high part of the\n ;; dest vector.\n@@ -2126,7 +2669,10 @@\n \n   return \"\";\n }\n-  [(set_attr \"length\" \"8\")])\n+  ;; We set the neon_type attribute based on the vmov instructions above.\n+  [(set_attr \"length\" \"8\")\n+   (set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"neon_vget_high<mode>\"\n   [(set (match_operand:<V_HALF> 0 \"s_register_operand\" \"=w\")\n@@ -2141,7 +2687,9 @@\n     return \"vmov\\t%P0, %f1\";\n   else\n     return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"neon_vget_low<mode>\"\n   [(set (match_operand:<V_HALF> 0 \"s_register_operand\" \"=w\")\n@@ -2156,23 +2704,35 @@\n     return \"vmov\\t%P0, %e1\";\n   else\n     return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"neon_vcvt<mode>\"\n   [(set (match_operand:<V_CVTTO> 0 \"s_register_operand\" \"=w\")\n \t(unspec:<V_CVTTO> [(match_operand:VCVTF 1 \"s_register_operand\" \"w\")\n \t\t\t   (match_operand:SI 2 \"immediate_operand\" \"i\")]\n \t\t\t  UNSPEC_VCVT))]\n   \"TARGET_NEON\"\n-  \"vcvt.%T2%#32.f32\\t%<V_reg>0, %<V_reg>1\")\n+  \"vcvt.%T2%#32.f32\\t%<V_reg>0, %<V_reg>1\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                   (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                   (const_string \"neon_fp_vadd_qqq_vabs_qq\")))]\n+)\n \n (define_insn \"neon_vcvt<mode>\"\n   [(set (match_operand:<V_CVTTO> 0 \"s_register_operand\" \"=w\")\n \t(unspec:<V_CVTTO> [(match_operand:VCVTI 1 \"s_register_operand\" \"w\")\n \t\t\t   (match_operand:SI 2 \"immediate_operand\" \"i\")]\n \t\t\t  UNSPEC_VCVT))]\n   \"TARGET_NEON\"\n-  \"vcvt.f32.%T2%#32\\t%<V_reg>0, %<V_reg>1\")\n+  \"vcvt.f32.%T2%#32\\t%<V_reg>0, %<V_reg>1\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                   (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                   (const_string \"neon_fp_vadd_qqq_vabs_qq\")))]\n+)\n \n (define_insn \"neon_vcvt_n<mode>\"\n   [(set (match_operand:<V_CVTTO> 0 \"s_register_operand\" \"=w\")\n@@ -2181,7 +2741,12 @@\n                            (match_operand:SI 3 \"immediate_operand\" \"i\")]\n \t\t\t  UNSPEC_VCVT_N))]\n   \"TARGET_NEON\"\n-  \"vcvt.%T3%#32.f32\\t%<V_reg>0, %<V_reg>1, %2\")\n+  \"vcvt.%T3%#32.f32\\t%<V_reg>0, %<V_reg>1, %2\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                   (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                   (const_string \"neon_fp_vadd_qqq_vabs_qq\")))]\n+)\n \n (define_insn \"neon_vcvt_n<mode>\"\n   [(set (match_operand:<V_CVTTO> 0 \"s_register_operand\" \"=w\")\n@@ -2190,39 +2755,52 @@\n                            (match_operand:SI 3 \"immediate_operand\" \"i\")]\n \t\t\t  UNSPEC_VCVT_N))]\n   \"TARGET_NEON\"\n-  \"vcvt.f32.%T3%#32\\t%<V_reg>0, %<V_reg>1, %2\")\n+  \"vcvt.f32.%T3%#32\\t%<V_reg>0, %<V_reg>1, %2\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                   (const_string \"neon_fp_vadd_ddd_vabs_dd\")\n+                   (const_string \"neon_fp_vadd_qqq_vabs_qq\")))]\n+)\n \n (define_insn \"neon_vmovn<mode>\"\n   [(set (match_operand:<V_narrow> 0 \"s_register_operand\" \"=w\")\n \t(unspec:<V_narrow> [(match_operand:VN 1 \"s_register_operand\" \"w\")\n \t\t\t    (match_operand:SI 2 \"immediate_operand\" \"i\")]\n                            UNSPEC_VMOVN))]\n   \"TARGET_NEON\"\n-  \"vmovn.<V_if_elem>\\t%P0, %q1\")\n+  \"vmovn.<V_if_elem>\\t%P0, %q1\"\n+  [(set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"neon_vqmovn<mode>\"\n   [(set (match_operand:<V_narrow> 0 \"s_register_operand\" \"=w\")\n \t(unspec:<V_narrow> [(match_operand:VN 1 \"s_register_operand\" \"w\")\n \t\t\t    (match_operand:SI 2 \"immediate_operand\" \"i\")]\n                            UNSPEC_VQMOVN))]\n   \"TARGET_NEON\"\n-  \"vqmovn.%T2%#<V_sz_elem>\\t%P0, %q1\")\n+  \"vqmovn.%T2%#<V_sz_elem>\\t%P0, %q1\"\n+  [(set_attr \"neon_type\" \"neon_shift_2\")]\n+)\n \n (define_insn \"neon_vqmovun<mode>\"\n   [(set (match_operand:<V_narrow> 0 \"s_register_operand\" \"=w\")\n \t(unspec:<V_narrow> [(match_operand:VN 1 \"s_register_operand\" \"w\")\n \t\t\t    (match_operand:SI 2 \"immediate_operand\" \"i\")]\n                            UNSPEC_VQMOVUN))]\n   \"TARGET_NEON\"\n-  \"vqmovun.<V_s_elem>\\t%P0, %q1\")\n+  \"vqmovun.<V_s_elem>\\t%P0, %q1\"\n+  [(set_attr \"neon_type\" \"neon_shift_2\")]\n+)\n \n (define_insn \"neon_vmovl<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n \t(unspec:<V_widen> [(match_operand:VW 1 \"s_register_operand\" \"w\")\n \t\t\t   (match_operand:SI 2 \"immediate_operand\" \"i\")]\n                           UNSPEC_VMOVL))]\n   \"TARGET_NEON\"\n-  \"vmovl.%T2%#<V_sz_elem>\\t%q0, %P1\")\n+  \"vmovl.%T2%#<V_sz_elem>\\t%q0, %P1\"\n+  [(set_attr \"neon_type\" \"neon_shift_1\")]\n+)\n \n (define_insn \"neon_vmul_lane<mode>\"\n   [(set (match_operand:VMD 0 \"s_register_operand\" \"=w\")\n@@ -2233,7 +2811,14 @@\n                      (match_operand:SI 4 \"immediate_operand\" \"i\")]\n                     UNSPEC_VMUL_LANE))]\n   \"TARGET_NEON\"\n-  \"vmul.<V_if_elem>\\t%P0, %P1, %P2[%c3]\")\n+  \"vmul.<V_if_elem>\\t%P0, %P1, %P2[%c3]\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                   (const_string \"neon_fp_vmul_ddd\")\n+                   (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                                 (const_string \"neon_mul_ddd_16_scalar_32_16_long_scalar\")\n+                                 (const_string \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\"))))]\n+)\n \n (define_insn \"neon_vmul_lane<mode>\"\n   [(set (match_operand:VMQ 0 \"s_register_operand\" \"=w\")\n@@ -2244,7 +2829,14 @@\n                      (match_operand:SI 4 \"immediate_operand\" \"i\")]\n                     UNSPEC_VMUL_LANE))]\n   \"TARGET_NEON\"\n-  \"vmul.<V_if_elem>\\t%q0, %q1, %P2[%c3]\")\n+  \"vmul.<V_if_elem>\\t%q0, %q1, %P2[%c3]\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                   (const_string \"neon_fp_vmul_qqd\")\n+                   (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                                 (const_string \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\")\n+                                 (const_string \"neon_mul_qqd_32_scalar\"))))]\n+)\n \n (define_insn \"neon_vmull_lane<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -2255,7 +2847,12 @@\n                            (match_operand:SI 4 \"immediate_operand\" \"i\")]\n                           UNSPEC_VMULL_LANE))]\n   \"TARGET_NEON\"\n-  \"vmull.%T4%#<V_sz_elem>\\t%q0, %P1, %P2[%c3]\")\n+  \"vmull.%T4%#<V_sz_elem>\\t%q0, %P1, %P2[%c3]\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                   (const_string \"neon_mul_ddd_16_scalar_32_16_long_scalar\")\n+                   (const_string \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\")))]\n+)\n \n (define_insn \"neon_vqdmull_lane<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -2266,7 +2863,12 @@\n                            (match_operand:SI 4 \"immediate_operand\" \"i\")]\n                           UNSPEC_VQDMULL_LANE))]\n   \"TARGET_NEON\"\n-  \"vqdmull.<V_s_elem>\\t%q0, %P1, %P2[%c3]\")\n+  \"vqdmull.<V_s_elem>\\t%q0, %P1, %P2[%c3]\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                   (const_string \"neon_mul_ddd_16_scalar_32_16_long_scalar\")\n+                   (const_string \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\")))]\n+)\n \n (define_insn \"neon_vqdmulh_lane<mode>\"\n   [(set (match_operand:VMQI 0 \"s_register_operand\" \"=w\")\n@@ -2277,7 +2879,12 @@\n                       (match_operand:SI 4 \"immediate_operand\" \"i\")]\n                       UNSPEC_VQDMULH_LANE))]\n   \"TARGET_NEON\"\n-  \"vq%O4dmulh.%T4%#<V_sz_elem>\\t%q0, %q1, %P2[%c3]\")\n+  \"vq%O4dmulh.%T4%#<V_sz_elem>\\t%q0, %q1, %P2[%c3]\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                   (const_string \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\")\n+                   (const_string \"neon_mul_qqd_32_scalar\")))]\n+)\n \n (define_insn \"neon_vqdmulh_lane<mode>\"\n   [(set (match_operand:VMDI 0 \"s_register_operand\" \"=w\")\n@@ -2288,7 +2895,12 @@\n                       (match_operand:SI 4 \"immediate_operand\" \"i\")]\n                       UNSPEC_VQDMULH_LANE))]\n   \"TARGET_NEON\"\n-  \"vq%O4dmulh.%T4%#<V_sz_elem>\\t%P0, %P1, %P2[%c3]\")\n+  \"vq%O4dmulh.%T4%#<V_sz_elem>\\t%P0, %P1, %P2[%c3]\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                   (const_string \"neon_mul_ddd_16_scalar_32_16_long_scalar\")\n+                   (const_string \"neon_mul_qdd_64_32_long_qqd_16_ddd_32_scalar_64_32_long_scalar\")))]\n+)\n \n (define_insn \"neon_vmla_lane<mode>\"\n   [(set (match_operand:VMD 0 \"s_register_operand\" \"=w\")\n@@ -2300,7 +2912,14 @@\n                      (match_operand:SI 5 \"immediate_operand\" \"i\")]\n                      UNSPEC_VMLA_LANE))]\n   \"TARGET_NEON\"\n-  \"vmla.<V_if_elem>\\t%P0, %P2, %P3[%c4]\")\n+  \"vmla.<V_if_elem>\\t%P0, %P2, %P3[%c4]\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                   (const_string \"neon_fp_vmla_ddd_scalar\")\n+                   (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                                 (const_string \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\")\n+                                 (const_string \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\"))))]\n+)\n \n (define_insn \"neon_vmla_lane<mode>\"\n   [(set (match_operand:VMQ 0 \"s_register_operand\" \"=w\")\n@@ -2312,7 +2931,14 @@\n                      (match_operand:SI 5 \"immediate_operand\" \"i\")]\n                      UNSPEC_VMLA_LANE))]\n   \"TARGET_NEON\"\n-  \"vmla.<V_if_elem>\\t%q0, %q2, %P3[%c4]\")\n+  \"vmla.<V_if_elem>\\t%q0, %q2, %P3[%c4]\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                   (const_string \"neon_fp_vmla_qqq_scalar\")\n+                   (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                                 (const_string \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\")\n+                                 (const_string \"neon_mla_qqq_32_qqd_32_scalar\"))))]\n+)\n \n (define_insn \"neon_vmlal_lane<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -2324,7 +2950,12 @@\n                            (match_operand:SI 5 \"immediate_operand\" \"i\")]\n                           UNSPEC_VMLAL_LANE))]\n   \"TARGET_NEON\"\n-  \"vmlal.%T5%#<V_sz_elem>\\t%q0, %P2, %P3[%c4]\")\n+  \"vmlal.%T5%#<V_sz_elem>\\t%q0, %P2, %P3[%c4]\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                   (const_string \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\")\n+                   (const_string \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\")))]\n+)\n \n (define_insn \"neon_vqdmlal_lane<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -2336,7 +2967,12 @@\n                            (match_operand:SI 5 \"immediate_operand\" \"i\")]\n                           UNSPEC_VQDMLAL_LANE))]\n   \"TARGET_NEON\"\n-  \"vqdmlal.<V_s_elem>\\t%q0, %P2, %P3[%c4]\")\n+  \"vqdmlal.<V_s_elem>\\t%q0, %P2, %P3[%c4]\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                   (const_string \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\")\n+                   (const_string \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\")))]\n+)\n \n (define_insn \"neon_vmls_lane<mode>\"\n   [(set (match_operand:VMD 0 \"s_register_operand\" \"=w\")\n@@ -2348,7 +2984,14 @@\n                      (match_operand:SI 5 \"immediate_operand\" \"i\")]\n                     UNSPEC_VMLS_LANE))]\n   \"TARGET_NEON\"\n-  \"vmls.<V_if_elem>\\t%P0, %P2, %P3[%c4]\")\n+  \"vmls.<V_if_elem>\\t%P0, %P2, %P3[%c4]\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                   (const_string \"neon_fp_vmla_ddd_scalar\")\n+                   (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                                 (const_string \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\")\n+                                 (const_string \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\"))))]\n+)\n \n (define_insn \"neon_vmls_lane<mode>\"\n   [(set (match_operand:VMQ 0 \"s_register_operand\" \"=w\")\n@@ -2360,7 +3003,14 @@\n                      (match_operand:SI 5 \"immediate_operand\" \"i\")]\n                     UNSPEC_VMLS_LANE))]\n   \"TARGET_NEON\"\n-  \"vmls.<V_if_elem>\\t%q0, %q2, %P3[%c4]\")\n+  \"vmls.<V_if_elem>\\t%q0, %q2, %P3[%c4]\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Is_float_mode>\") (const_int 0))\n+                   (const_string \"neon_fp_vmla_qqq_scalar\")\n+                   (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                                 (const_string \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\")\n+                                 (const_string \"neon_mla_qqq_32_qqd_32_scalar\"))))]\n+)\n \n (define_insn \"neon_vmlsl_lane<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -2372,7 +3022,12 @@\n                            (match_operand:SI 5 \"immediate_operand\" \"i\")]\n                           UNSPEC_VMLSL_LANE))]\n   \"TARGET_NEON\"\n-  \"vmlsl.%T5%#<V_sz_elem>\\t%q0, %P2, %P3[%c4]\")\n+  \"vmlsl.%T5%#<V_sz_elem>\\t%q0, %P2, %P3[%c4]\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                   (const_string \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\")\n+                   (const_string \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\")))]\n+)\n \n (define_insn \"neon_vqdmlsl_lane<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -2384,7 +3039,12 @@\n                            (match_operand:SI 5 \"immediate_operand\" \"i\")]\n                           UNSPEC_VQDMLSL_LANE))]\n   \"TARGET_NEON\"\n-  \"vqdmlsl.<V_s_elem>\\t%q0, %P2, %P3[%c4]\")\n+  \"vqdmlsl.<V_s_elem>\\t%q0, %P2, %P3[%c4]\"\n+  [(set (attr \"neon_type\")\n+     (if_then_else (ne (symbol_ref \"<Scalar_mul_8_16>\") (const_int 0))\n+                   (const_string \"neon_mla_ddd_16_scalar_qdd_32_16_long_scalar\")\n+                   (const_string \"neon_mla_ddd_32_qqd_16_ddd_32_scalar_qdd_64_32_long_scalar_qdd_64_32_long\")))]\n+)\n \n ; FIXME: For the \"_n\" multiply/multiply-accumulate insns, we copy a value in a\n ; core register into a temp register, then use a scalar taken from that. This\n@@ -2604,31 +3264,42 @@\n                       (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                      UNSPEC_VEXT))]\n   \"TARGET_NEON\"\n-  \"vext.<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2, %3\")\n+  \"vext.<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2, %3\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                    (const_string \"neon_bp_simple\")\n+                    (const_string \"neon_bp_2cycle\")))]\n+)\n \n (define_insn \"neon_vrev64<mode>\"\n   [(set (match_operand:VDQ 0 \"s_register_operand\" \"=w\")\n \t(unspec:VDQ [(match_operand:VDQ 1 \"s_register_operand\" \"w\")\n \t\t     (match_operand:SI 2 \"immediate_operand\" \"i\")]\n                     UNSPEC_VREV64))]\n   \"TARGET_NEON\"\n-  \"vrev64.<V_sz_elem>\\t%<V_reg>0, %<V_reg>1\")\n+  \"vrev64.<V_sz_elem>\\t%<V_reg>0, %<V_reg>1\"\n+  [(set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"neon_vrev32<mode>\"\n   [(set (match_operand:VX 0 \"s_register_operand\" \"=w\")\n \t(unspec:VX [(match_operand:VX 1 \"s_register_operand\" \"w\")\n \t\t    (match_operand:SI 2 \"immediate_operand\" \"i\")]\n                    UNSPEC_VREV32))]\n   \"TARGET_NEON\"\n-  \"vrev32.<V_sz_elem>\\t%<V_reg>0, %<V_reg>1\")\n+  \"vrev32.<V_sz_elem>\\t%<V_reg>0, %<V_reg>1\"\n+  [(set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n (define_insn \"neon_vrev16<mode>\"\n   [(set (match_operand:VE 0 \"s_register_operand\" \"=w\")\n \t(unspec:VE [(match_operand:VE 1 \"s_register_operand\" \"w\")\n \t\t    (match_operand:SI 2 \"immediate_operand\" \"i\")]\n                    UNSPEC_VREV16))]\n   \"TARGET_NEON\"\n-  \"vrev16.<V_sz_elem>\\t%<V_reg>0, %<V_reg>1\")\n+  \"vrev16.<V_sz_elem>\\t%<V_reg>0, %<V_reg>1\"\n+  [(set_attr \"neon_type\" \"neon_bp_simple\")]\n+)\n \n ; vbsl_* intrinsics may compile to any of vbsl/vbif/vbit depending on register\n ; allocation. For an intrinsic of form:\n@@ -2648,7 +3319,9 @@\n   \"@\n   vbsl\\t%<V_reg>0, %<V_reg>2, %<V_reg>3\n   vbit\\t%<V_reg>0, %<V_reg>2, %<V_reg>1\n-  vbif\\t%<V_reg>0, %<V_reg>3, %<V_reg>1\")\n+  vbif\\t%<V_reg>0, %<V_reg>3, %<V_reg>1\"\n+  [(set_attr \"neon_type\" \"neon_int_1\")]\n+)\n \n (define_expand \"neon_vbsl<mode>\"\n   [(set (match_operand:VDQX 0 \"s_register_operand\" \"\")\n@@ -2669,7 +3342,12 @@\n                        (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                       UNSPEC_VSHL))]\n   \"TARGET_NEON\"\n-  \"v%O3shl.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"v%O3shl.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                    (const_string \"neon_vshl_ddd\")\n+                    (const_string \"neon_shift_3\")))]\n+)\n \n (define_insn \"neon_vqshl<mode>\"\n   [(set (match_operand:VDQIX 0 \"s_register_operand\" \"=w\")\n@@ -2678,7 +3356,12 @@\n                        (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                       UNSPEC_VQSHL))]\n   \"TARGET_NEON\"\n-  \"vq%O3shl.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\")\n+  \"vq%O3shl.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                    (const_string \"neon_shift_2\")\n+                    (const_string \"neon_vqshl_vrshl_vqrshl_qqq\")))]\n+)\n \n (define_insn \"neon_vshr_n<mode>\"\n   [(set (match_operand:VDQIX 0 \"s_register_operand\" \"=w\")\n@@ -2687,7 +3370,9 @@\n                        (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                       UNSPEC_VSHR_N))]\n   \"TARGET_NEON\"\n-  \"v%O3shr.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %2\")\n+  \"v%O3shr.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %2\"\n+  [(set_attr \"neon_type\" \"neon_shift_1\")]\n+)\n \n (define_insn \"neon_vshrn_n<mode>\"\n   [(set (match_operand:<V_narrow> 0 \"s_register_operand\" \"=w\")\n@@ -2696,7 +3381,9 @@\n \t\t\t    (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                            UNSPEC_VSHRN_N))]\n   \"TARGET_NEON\"\n-  \"v%O3shrn.<V_if_elem>\\t%P0, %q1, %2\")\n+  \"v%O3shrn.<V_if_elem>\\t%P0, %q1, %2\"\n+  [(set_attr \"neon_type\" \"neon_shift_1\")]\n+)\n \n (define_insn \"neon_vqshrn_n<mode>\"\n   [(set (match_operand:<V_narrow> 0 \"s_register_operand\" \"=w\")\n@@ -2705,7 +3392,9 @@\n \t\t\t    (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                            UNSPEC_VQSHRN_N))]\n   \"TARGET_NEON\"\n-  \"vq%O3shrn.%T3%#<V_sz_elem>\\t%P0, %q1, %2\")\n+  \"vq%O3shrn.%T3%#<V_sz_elem>\\t%P0, %q1, %2\"\n+  [(set_attr \"neon_type\" \"neon_shift_2\")]\n+)\n \n (define_insn \"neon_vqshrun_n<mode>\"\n   [(set (match_operand:<V_narrow> 0 \"s_register_operand\" \"=w\")\n@@ -2714,7 +3403,9 @@\n \t\t\t    (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                            UNSPEC_VQSHRUN_N))]\n   \"TARGET_NEON\"\n-  \"vq%O3shrun.%T3%#<V_sz_elem>\\t%P0, %q1, %2\")\n+  \"vq%O3shrun.%T3%#<V_sz_elem>\\t%P0, %q1, %2\"\n+  [(set_attr \"neon_type\" \"neon_shift_2\")]\n+)\n \n (define_insn \"neon_vshl_n<mode>\"\n   [(set (match_operand:VDQIX 0 \"s_register_operand\" \"=w\")\n@@ -2723,7 +3414,9 @@\n                        (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                       UNSPEC_VSHL_N))]\n   \"TARGET_NEON\"\n-  \"vshl.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %2\")\n+  \"vshl.<V_if_elem>\\t%<V_reg>0, %<V_reg>1, %2\"\n+  [(set_attr \"neon_type\" \"neon_shift_1\")]\n+)\n \n (define_insn \"neon_vqshl_n<mode>\"\n   [(set (match_operand:VDQIX 0 \"s_register_operand\" \"=w\")\n@@ -2732,7 +3425,9 @@\n                        (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                       UNSPEC_VQSHL_N))]\n   \"TARGET_NEON\"\n-  \"vqshl.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %2\")\n+  \"vqshl.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %2\"\n+  [(set_attr \"neon_type\" \"neon_shift_2\")]\n+)\n \n (define_insn \"neon_vqshlu_n<mode>\"\n   [(set (match_operand:VDQIX 0 \"s_register_operand\" \"=w\")\n@@ -2741,7 +3436,9 @@\n                        (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                       UNSPEC_VQSHLU_N))]\n   \"TARGET_NEON\"\n-  \"vqshlu.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %2\")\n+  \"vqshlu.%T3%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>1, %2\"\n+  [(set_attr \"neon_type\" \"neon_shift_2\")]\n+)\n \n (define_insn \"neon_vshll_n<mode>\"\n   [(set (match_operand:<V_widen> 0 \"s_register_operand\" \"=w\")\n@@ -2750,7 +3447,9 @@\n \t\t\t   (match_operand:SI 3 \"immediate_operand\" \"i\")]\n \t\t\t  UNSPEC_VSHLL_N))]\n   \"TARGET_NEON\"\n-  \"vshll.%T3%#<V_sz_elem>\\t%q0, %P1, %2\")\n+  \"vshll.%T3%#<V_sz_elem>\\t%q0, %P1, %2\"\n+  [(set_attr \"neon_type\" \"neon_shift_1\")]\n+)\n \n (define_insn \"neon_vsra_n<mode>\"\n   [(set (match_operand:VDQIX 0 \"s_register_operand\" \"=w\")\n@@ -2760,7 +3459,9 @@\n                        (match_operand:SI 4 \"immediate_operand\" \"i\")]\n                       UNSPEC_VSRA_N))]\n   \"TARGET_NEON\"\n-  \"v%O4sra.%T4%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>2, %3\")\n+  \"v%O4sra.%T4%#<V_sz_elem>\\t%<V_reg>0, %<V_reg>2, %3\"\n+  [(set_attr \"neon_type\" \"neon_vsra_vrsra\")]\n+)\n \n (define_insn \"neon_vsri_n<mode>\"\n   [(set (match_operand:VDQIX 0 \"s_register_operand\" \"=w\")\n@@ -2769,7 +3470,12 @@\n                        (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                       UNSPEC_VSRI))]\n   \"TARGET_NEON\"\n-  \"vsri.<V_sz_elem>\\t%<V_reg>0, %<V_reg>2, %3\")\n+  \"vsri.<V_sz_elem>\\t%<V_reg>0, %<V_reg>2, %3\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                    (const_string \"neon_shift_1\")\n+                    (const_string \"neon_shift_3\")))]\n+)\n \n (define_insn \"neon_vsli_n<mode>\"\n   [(set (match_operand:VDQIX 0 \"s_register_operand\" \"=w\")\n@@ -2778,15 +3484,22 @@\n                        (match_operand:SI 3 \"immediate_operand\" \"i\")]\n                       UNSPEC_VSLI))]\n   \"TARGET_NEON\"\n-  \"vsli.<V_sz_elem>\\t%<V_reg>0, %<V_reg>2, %3\")\n+  \"vsli.<V_sz_elem>\\t%<V_reg>0, %<V_reg>2, %3\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                    (const_string \"neon_shift_1\")\n+                    (const_string \"neon_shift_3\")))]\n+)\n \n (define_insn \"neon_vtbl1v8qi\"\n   [(set (match_operand:V8QI 0 \"s_register_operand\" \"=w\")\n \t(unspec:V8QI [(match_operand:V8QI 1 \"s_register_operand\" \"w\")\n \t\t      (match_operand:V8QI 2 \"s_register_operand\" \"w\")]\n                      UNSPEC_VTBL))]\n   \"TARGET_NEON\"\n-  \"vtbl.8\\t%P0, {%P1}, %P2\")\n+  \"vtbl.8\\t%P0, {%P1}, %P2\"\n+  [(set_attr \"neon_type\" \"neon_bp_2cycle\")]\n+)\n \n (define_insn \"neon_vtbl2v8qi\"\n   [(set (match_operand:V8QI 0 \"s_register_operand\" \"=w\")\n@@ -2805,7 +3518,9 @@\n   output_asm_insn (\"vtbl.8\\t%P0, {%P1, %P2}, %P3\", ops);\n \n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_bp_2cycle\")]\n+)\n \n (define_insn \"neon_vtbl3v8qi\"\n   [(set (match_operand:V8QI 0 \"s_register_operand\" \"=w\")\n@@ -2825,7 +3540,9 @@\n   output_asm_insn (\"vtbl.8\\t%P0, {%P1, %P2, %P3}, %P4\", ops);\n \n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_bp_3cycle\")]\n+)\n \n (define_insn \"neon_vtbl4v8qi\"\n   [(set (match_operand:V8QI 0 \"s_register_operand\" \"=w\")\n@@ -2846,7 +3563,9 @@\n   output_asm_insn (\"vtbl.8\\t%P0, {%P1, %P2, %P3, %P4}, %P5\", ops);\n \n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_bp_3cycle\")]\n+)\n \n (define_insn \"neon_vtbx1v8qi\"\n   [(set (match_operand:V8QI 0 \"s_register_operand\" \"=w\")\n@@ -2855,7 +3574,9 @@\n \t\t      (match_operand:V8QI 3 \"s_register_operand\" \"w\")]\n                      UNSPEC_VTBX))]\n   \"TARGET_NEON\"\n-  \"vtbx.8\\t%P0, {%P2}, %P3\")\n+  \"vtbx.8\\t%P0, {%P2}, %P3\"\n+  [(set_attr \"neon_type\" \"neon_bp_2cycle\")]\n+)\n \n (define_insn \"neon_vtbx2v8qi\"\n   [(set (match_operand:V8QI 0 \"s_register_operand\" \"=w\")\n@@ -2875,7 +3596,9 @@\n   output_asm_insn (\"vtbx.8\\t%P0, {%P1, %P2}, %P3\", ops);\n \n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_bp_2cycle\")]\n+)\n \n (define_insn \"neon_vtbx3v8qi\"\n   [(set (match_operand:V8QI 0 \"s_register_operand\" \"=w\")\n@@ -2896,7 +3619,9 @@\n   output_asm_insn (\"vtbx.8\\t%P0, {%P1, %P2, %P3}, %P4\", ops);\n \n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_bp_3cycle\")]\n+)\n \n (define_insn \"neon_vtbx4v8qi\"\n   [(set (match_operand:V8QI 0 \"s_register_operand\" \"=w\")\n@@ -2918,7 +3643,9 @@\n   output_asm_insn (\"vtbx.8\\t%P0, {%P1, %P2, %P3, %P4}, %P5\", ops);\n \n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_bp_3cycle\")]\n+)\n \n (define_insn \"neon_vtrn<mode>_internal\"\n   [(set (match_operand:VDQW 0 \"s_register_operand\" \"=w\")\n@@ -2928,7 +3655,12 @@\n         (unspec:VDQW [(match_operand:VDQW 3 \"s_register_operand\" \"2\")]\n \t\t     UNSPEC_VTRN2))]\n   \"TARGET_NEON\"\n-  \"vtrn.<V_sz_elem>\\t%<V_reg>0, %<V_reg>2\")\n+  \"vtrn.<V_sz_elem>\\t%<V_reg>0, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                    (const_string \"neon_bp_simple\")\n+                    (const_string \"neon_bp_3cycle\")))]\n+)\n \n (define_expand \"neon_vtrn<mode>\"\n   [(match_operand:SI 0 \"s_register_operand\" \"r\")\n@@ -2949,7 +3681,12 @@\n         (unspec:VDQW [(match_operand:VDQW 3 \"s_register_operand\" \"2\")]\n \t\t     UNSPEC_VZIP2))]\n   \"TARGET_NEON\"\n-  \"vzip.<V_sz_elem>\\t%<V_reg>0, %<V_reg>2\")\n+  \"vzip.<V_sz_elem>\\t%<V_reg>0, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                    (const_string \"neon_bp_simple\")\n+                    (const_string \"neon_bp_3cycle\")))]\n+)\n \n (define_expand \"neon_vzip<mode>\"\n   [(match_operand:SI 0 \"s_register_operand\" \"r\")\n@@ -2970,7 +3707,12 @@\n         (unspec:VDQW [(match_operand:VDQW 3 \"s_register_operand\" \"2\")]\n \t\t     UNSPEC_VUZP2))]\n   \"TARGET_NEON\"\n-  \"vuzp.<V_sz_elem>\\t%<V_reg>0, %<V_reg>2\")\n+  \"vuzp.<V_sz_elem>\\t%<V_reg>0, %<V_reg>2\"\n+  [(set (attr \"neon_type\")\n+      (if_then_else (ne (symbol_ref \"<Is_d_reg>\") (const_int 0))\n+                    (const_string \"neon_bp_simple\")\n+                    (const_string \"neon_bp_3cycle\")))]\n+)\n \n (define_expand \"neon_vuzp<mode>\"\n   [(match_operand:SI 0 \"s_register_operand\" \"r\")\n@@ -3078,7 +3820,9 @@\n         (unspec:VDQX [(mem:VDQX (match_operand:SI 1 \"s_register_operand\" \"r\"))]\n                     UNSPEC_VLD1))]\n   \"TARGET_NEON\"\n-  \"vld1.<V_sz_elem>\\t%h0, [%1]\")\n+  \"vld1.<V_sz_elem>\\t%h0, [%1]\"\n+  [(set_attr \"neon_type\" \"neon_vld1_1_2_regs\")]\n+)\n \n (define_insn \"neon_vld1_lane<mode>\"\n   [(set (match_operand:VDX 0 \"s_register_operand\" \"=w\")\n@@ -3096,7 +3840,12 @@\n     return \"vld1.<V_sz_elem>\\t%P0, [%1]\";\n   else\n     return \"vld1.<V_sz_elem>\\t{%P0[%c3]}, [%1]\";\n-})\n+}\n+  [(set (attr \"neon_type\")\n+      (if_then_else (eq (const_string \"<V_mode_nunits>\") (const_int 2))\n+                    (const_string \"neon_vld1_1_2_regs\")\n+                    (const_string \"neon_vld1_vld2_lane\")))]\n+)\n \n (define_insn \"neon_vld1_lane<mode>\"\n   [(set (match_operand:VQX 0 \"s_register_operand\" \"=w\")\n@@ -3122,7 +3871,12 @@\n     return \"vld1.<V_sz_elem>\\t%P0, [%1]\";\n   else\n     return \"vld1.<V_sz_elem>\\t{%P0[%c3]}, [%1]\";\n-})\n+}\n+  [(set (attr \"neon_type\")\n+      (if_then_else (eq (const_string \"<V_mode_nunits>\") (const_int 2))\n+                    (const_string \"neon_vld1_1_2_regs\")\n+                    (const_string \"neon_vld1_vld2_lane\")))]\n+)\n \n (define_insn \"neon_vld1_dup<mode>\"\n   [(set (match_operand:VDX 0 \"s_register_operand\" \"=w\")\n@@ -3134,7 +3888,12 @@\n     return \"vld1.<V_sz_elem>\\t{%P0[]}, [%1]\";\n   else\n     return \"vld1.<V_sz_elem>\\t%h0, [%1]\";\n-})\n+}\n+  [(set (attr \"neon_type\")\n+      (if_then_else (gt (const_string \"<V_mode_nunits>\") (const_string \"1\"))\n+                    (const_string \"neon_vld2_2_regs_vld1_vld2_all_lanes\")\n+                    (const_string \"neon_vld1_1_2_regs\")))]\n+)\n \n (define_insn \"neon_vld1_dup<mode>\"\n   [(set (match_operand:VQX 0 \"s_register_operand\" \"=w\")\n@@ -3146,14 +3905,20 @@\n     return \"vld1.<V_sz_elem>\\t{%e0[], %f0[]}, [%1]\";\n   else\n     return \"vld1.<V_sz_elem>\\t%h0, [%1]\";\n-})\n+}\n+  [(set (attr \"neon_type\")\n+      (if_then_else (gt (const_string \"<V_mode_nunits>\") (const_string \"1\"))\n+                    (const_string \"neon_vld2_2_regs_vld1_vld2_all_lanes\")\n+                    (const_string \"neon_vld1_1_2_regs\")))]\n+)\n \n (define_insn \"neon_vst1<mode>\"\n   [(set (mem:VDQX (match_operand:SI 0 \"s_register_operand\" \"r\"))\n \t(unspec:VDQX [(match_operand:VDQX 1 \"s_register_operand\" \"w\")]\n \t\t     UNSPEC_VST1))]\n   \"TARGET_NEON\"\n-  \"vst1.<V_sz_elem>\\t%h1, [%0]\")\n+  \"vst1.<V_sz_elem>\\t%h1, [%0]\"\n+  [(set_attr \"neon_type\" \"neon_vst1_1_2_regs_vst2_2_regs\")])\n \n (define_insn \"neon_vst1_lane<mode>\"\n   [(set (mem:<V_elem> (match_operand:SI 0 \"s_register_operand\" \"r\"))\n@@ -3170,7 +3935,11 @@\n     return \"vst1.<V_sz_elem>\\t{%P1}, [%0]\";\n   else\n     return \"vst1.<V_sz_elem>\\t{%P1[%c2]}, [%0]\";\n-})\n+}\n+  [(set (attr \"neon_type\")\n+      (if_then_else (eq (const_string \"<V_mode_nunits>\") (const_int 1))\n+                    (const_string \"neon_vst1_1_2_regs_vst2_2_regs\")\n+                    (const_string \"neon_vst1_vst2_lane\")))])\n \n (define_insn \"neon_vst1_lane<mode>\"\n   [(set (mem:<V_elem> (match_operand:SI 0 \"s_register_operand\" \"r\"))\n@@ -3195,7 +3964,9 @@\n     return \"vst1.<V_sz_elem>\\t{%P1}, [%0]\";\n   else\n     return \"vst1.<V_sz_elem>\\t{%P1[%c2]}, [%0]\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vst1_vst2_lane\")]\n+)\n \n (define_insn \"neon_vld2<mode>\"\n   [(set (match_operand:TI 0 \"s_register_operand\" \"=w\")\n@@ -3208,15 +3979,21 @@\n     return \"vld1.64\\t%h0, [%1]\";\n   else\n     return \"vld2.<V_sz_elem>\\t%h0, [%1]\";\n-})\n+}\n+  [(set (attr \"neon_type\")\n+      (if_then_else (eq (const_string \"<V_sz_elem>\") (const_string \"64\"))\n+                    (const_string \"neon_vld1_1_2_regs\")\n+                    (const_string \"neon_vld2_2_regs_vld1_vld2_all_lanes\")))]\n+)\n \n (define_insn \"neon_vld2<mode>\"\n   [(set (match_operand:OI 0 \"s_register_operand\" \"=w\")\n         (unspec:OI [(mem:OI (match_operand:SI 1 \"s_register_operand\" \"r\"))\n                     (unspec:VQ [(const_int 0)] UNSPEC_VSTRUCTDUMMY)]\n                    UNSPEC_VLD2))]\n   \"TARGET_NEON\"\n-  \"vld2.<V_sz_elem>\\t%h0, [%1]\")\n+  \"vld2.<V_sz_elem>\\t%h0, [%1]\"\n+  [(set_attr \"neon_type\" \"neon_vld2_2_regs_vld1_vld2_all_lanes\")])\n \n (define_insn \"neon_vld2_lane<mode>\"\n   [(set (match_operand:TI 0 \"s_register_operand\" \"=w\")\n@@ -3239,7 +4016,9 @@\n   ops[3] = operands[3];\n   output_asm_insn (\"vld2.<V_sz_elem>\\t{%P0[%c3], %P1[%c3]}, [%2]\", ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vld1_vld2_lane\")]\n+)\n \n (define_insn \"neon_vld2_lane<mode>\"\n   [(set (match_operand:OI 0 \"s_register_operand\" \"=w\")\n@@ -3267,7 +4046,9 @@\n   ops[3] = GEN_INT (lane);\n   output_asm_insn (\"vld2.<V_sz_elem>\\t{%P0[%c3], %P1[%c3]}, [%2]\", ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vld1_vld2_lane\")]\n+)\n \n (define_insn \"neon_vld2_dup<mode>\"\n   [(set (match_operand:TI 0 \"s_register_operand\" \"=w\")\n@@ -3280,7 +4061,12 @@\n     return \"vld2.<V_sz_elem>\\t{%e0[], %f0[]}, [%1]\";\n   else\n     return \"vld1.<V_sz_elem>\\t%h0, [%1]\";\n-})\n+}\n+  [(set (attr \"neon_type\")\n+      (if_then_else (gt (const_string \"<V_mode_nunits>\") (const_string \"1\"))\n+                    (const_string \"neon_vld2_2_regs_vld1_vld2_all_lanes\")\n+                    (const_string \"neon_vld1_1_2_regs\")))]\n+)\n \n (define_insn \"neon_vst2<mode>\"\n   [(set (mem:TI (match_operand:SI 0 \"s_register_operand\" \"r\"))\n@@ -3293,15 +4079,22 @@\n     return \"vst1.64\\t%h1, [%0]\";\n   else\n     return \"vst2.<V_sz_elem>\\t%h1, [%0]\";\n-})\n+}\n+  [(set (attr \"neon_type\")\n+      (if_then_else (eq (const_string \"<V_sz_elem>\") (const_string \"64\"))\n+                    (const_string \"neon_vst1_1_2_regs_vst2_2_regs\")\n+                    (const_string \"neon_vst1_1_2_regs_vst2_2_regs\")))]\n+)\n \n (define_insn \"neon_vst2<mode>\"\n   [(set (mem:OI (match_operand:SI 0 \"s_register_operand\" \"r\"))\n \t(unspec:OI [(match_operand:OI 1 \"s_register_operand\" \"w\")\n \t\t    (unspec:VQ [(const_int 0)] UNSPEC_VSTRUCTDUMMY)]\n \t\t   UNSPEC_VST2))]\n   \"TARGET_NEON\"\n-  \"vst2.<V_sz_elem>\\t%h1, [%0]\")\n+  \"vst2.<V_sz_elem>\\t%h1, [%0]\"\n+  [(set_attr \"neon_type\" \"neon_vst1_1_2_regs_vst2_2_regs\")]\n+)\n \n (define_insn \"neon_vst2_lane<mode>\"\n   [(set (mem:<V_two_elem> (match_operand:SI 0 \"s_register_operand\" \"r\"))\n@@ -3324,7 +4117,9 @@\n   ops[3] = operands[2];\n   output_asm_insn (\"vst2.<V_sz_elem>\\t{%P1[%c3], %P2[%c3]}, [%0]\", ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vst1_vst2_lane\")]\n+)\n \n (define_insn \"neon_vst2_lane<mode>\"\n   [(set (mem:<V_two_elem> (match_operand:SI 0 \"s_register_operand\" \"r\"))\n@@ -3352,7 +4147,9 @@\n   ops[3] = GEN_INT (lane);\n   output_asm_insn (\"vst2.<V_sz_elem>\\t{%P1[%c3], %P2[%c3]}, [%0]\", ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vst1_vst2_lane\")]\n+)\n \n (define_insn \"neon_vld3<mode>\"\n   [(set (match_operand:EI 0 \"s_register_operand\" \"=w\")\n@@ -3365,7 +4162,12 @@\n     return \"vld1.64\\t%h0, [%1]\";\n   else\n     return \"vld3.<V_sz_elem>\\t%h0, [%1]\";\n-})\n+}\n+  [(set (attr \"neon_type\")\n+      (if_then_else (eq (const_string \"<V_sz_elem>\") (const_string \"64\"))\n+                    (const_string \"neon_vld1_1_2_regs\")\n+                    (const_string \"neon_vld3_vld4\")))]\n+)\n \n (define_expand \"neon_vld3<mode>\"\n   [(match_operand:CI 0 \"s_register_operand\" \"=w\")\n@@ -3399,7 +4201,9 @@\n   ops[3] = operands[2];\n   output_asm_insn (\"vld3.<V_sz_elem>\\t{%P0, %P1, %P2}, [%3]!\", ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vld3_vld4\")]\n+)\n \n (define_insn \"neon_vld3qb<mode>\"\n   [(set (match_operand:CI 0 \"s_register_operand\" \"=w\")\n@@ -3420,7 +4224,9 @@\n   ops[3] = operands[2];\n   output_asm_insn (\"vld3.<V_sz_elem>\\t{%P0, %P1, %P2}, [%3]!\", ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vld3_vld4\")]\n+)\n \n (define_insn \"neon_vld3_lane<mode>\"\n   [(set (match_operand:EI 0 \"s_register_operand\" \"=w\")\n@@ -3445,7 +4251,9 @@\n   output_asm_insn (\"vld3.<V_sz_elem>\\t{%P0[%c4], %P1[%c4], %P2[%c4]}, [%3]\",\n                    ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vld3_vld4_lane\")]\n+)\n \n (define_insn \"neon_vld3_lane<mode>\"\n   [(set (match_operand:CI 0 \"s_register_operand\" \"=w\")\n@@ -3475,7 +4283,9 @@\n   output_asm_insn (\"vld3.<V_sz_elem>\\t{%P0[%c4], %P1[%c4], %P2[%c4]}, [%3]\",\n                    ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vld3_vld4_lane\")]\n+)\n \n (define_insn \"neon_vld3_dup<mode>\"\n   [(set (match_operand:EI 0 \"s_register_operand\" \"=w\")\n@@ -3497,7 +4307,11 @@\n     }\n   else\n     return \"vld1.<V_sz_elem>\\t%h0, [%1]\";\n-})\n+}\n+  [(set (attr \"neon_type\")\n+      (if_then_else (gt (const_string \"<V_mode_nunits>\") (const_string \"1\"))\n+                    (const_string \"neon_vld3_vld4_all_lanes\")\n+                    (const_string \"neon_vld1_1_2_regs\")))])\n \n (define_insn \"neon_vst3<mode>\"\n   [(set (mem:EI (match_operand:SI 0 \"s_register_operand\" \"r\"))\n@@ -3510,7 +4324,11 @@\n     return \"vst1.64\\t%h1, [%0]\";\n   else\n     return \"vst3.<V_sz_elem>\\t%h1, [%0]\";\n-})\n+}\n+  [(set (attr \"neon_type\")\n+      (if_then_else (eq (const_string \"<V_sz_elem>\") (const_string \"64\"))\n+                    (const_string \"neon_vst1_1_2_regs_vst2_2_regs\")\n+                    (const_string \"neon_vst2_4_regs_vst3_vst4\")))])\n \n (define_expand \"neon_vst3<mode>\"\n   [(match_operand:SI 0 \"s_register_operand\" \"+r\")\n@@ -3541,7 +4359,9 @@\n   ops[3] = gen_rtx_REG (DImode, regno + 8);\n   output_asm_insn (\"vst3.<V_sz_elem>\\t{%P1, %P2, %P3}, [%0]!\", ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vst2_4_regs_vst3_vst4\")]\n+)\n \n (define_insn \"neon_vst3qb<mode>\"\n   [(set (mem:EI (match_operand:SI 1 \"s_register_operand\" \"0\"))\n@@ -3561,7 +4381,9 @@\n   ops[3] = gen_rtx_REG (DImode, regno + 10);\n   output_asm_insn (\"vst3.<V_sz_elem>\\t{%P1, %P2, %P3}, [%0]!\", ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vst2_4_regs_vst3_vst4\")]\n+)\n \n (define_insn \"neon_vst3_lane<mode>\"\n   [(set (mem:<V_three_elem> (match_operand:SI 0 \"s_register_operand\" \"r\"))\n@@ -3586,7 +4408,9 @@\n   output_asm_insn (\"vst3.<V_sz_elem>\\t{%P1[%c4], %P2[%c4], %P3[%c4]}, [%0]\",\n                    ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vst3_vst4_lane\")]\n+)\n \n (define_insn \"neon_vst3_lane<mode>\"\n   [(set (mem:<V_three_elem> (match_operand:SI 0 \"s_register_operand\" \"r\"))\n@@ -3616,7 +4440,8 @@\n   output_asm_insn (\"vst3.<V_sz_elem>\\t{%P1[%c4], %P2[%c4], %P3[%c4]}, [%0]\",\n                    ops);\n   return \"\";\n-})\n+}\n+[(set_attr \"neon_type\" \"neon_vst3_vst4_lane\")])\n \n (define_insn \"neon_vld4<mode>\"\n   [(set (match_operand:OI 0 \"s_register_operand\" \"=w\")\n@@ -3629,7 +4454,12 @@\n     return \"vld1.64\\t%h0, [%1]\";\n   else\n     return \"vld4.<V_sz_elem>\\t%h0, [%1]\";\n-})\n+}\n+  [(set (attr \"neon_type\")\n+      (if_then_else (eq (const_string \"<V_sz_elem>\") (const_string \"64\"))\n+                    (const_string \"neon_vld1_1_2_regs\")\n+                    (const_string \"neon_vld3_vld4\")))]\n+)\n \n (define_expand \"neon_vld4<mode>\"\n   [(match_operand:XI 0 \"s_register_operand\" \"=w\")\n@@ -3664,7 +4494,9 @@\n   ops[4] = operands[2];\n   output_asm_insn (\"vld4.<V_sz_elem>\\t{%P0, %P1, %P2, %P3}, [%4]!\", ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vld3_vld4\")]\n+)\n \n (define_insn \"neon_vld4qb<mode>\"\n   [(set (match_operand:XI 0 \"s_register_operand\" \"=w\")\n@@ -3686,7 +4518,9 @@\n   ops[4] = operands[2];\n   output_asm_insn (\"vld4.<V_sz_elem>\\t{%P0, %P1, %P2, %P3}, [%4]!\", ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vld3_vld4\")]\n+)\n \n (define_insn \"neon_vld4_lane<mode>\"\n   [(set (match_operand:OI 0 \"s_register_operand\" \"=w\")\n@@ -3712,7 +4546,9 @@\n   output_asm_insn (\"vld4.<V_sz_elem>\\t{%P0[%c5], %P1[%c5], %P2[%c5], %P3[%c5]}, [%4]\",\n                    ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vld3_vld4_lane\")]\n+)\n \n (define_insn \"neon_vld4_lane<mode>\"\n   [(set (match_operand:XI 0 \"s_register_operand\" \"=w\")\n@@ -3743,7 +4579,9 @@\n   output_asm_insn (\"vld4.<V_sz_elem>\\t{%P0[%c5], %P1[%c5], %P2[%c5], %P3[%c5]}, [%4]\",\n                    ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vld3_vld4_lane\")]\n+)\n \n (define_insn \"neon_vld4_dup<mode>\"\n   [(set (match_operand:OI 0 \"s_register_operand\" \"=w\")\n@@ -3767,7 +4605,12 @@\n     }\n   else\n     return \"vld1.<V_sz_elem>\\t%h0, [%1]\";\n-})\n+}\n+  [(set (attr \"neon_type\")\n+      (if_then_else (gt (const_string \"<V_mode_nunits>\") (const_string \"1\"))\n+                    (const_string \"neon_vld3_vld4_all_lanes\")\n+                    (const_string \"neon_vld1_1_2_regs\")))]\n+)\n \n (define_insn \"neon_vst4<mode>\"\n   [(set (mem:OI (match_operand:SI 0 \"s_register_operand\" \"r\"))\n@@ -3780,7 +4623,12 @@\n     return \"vst1.64\\t%h1, [%0]\";\n   else\n     return \"vst4.<V_sz_elem>\\t%h1, [%0]\";\n-})\n+}\n+  [(set (attr \"neon_type\")\n+      (if_then_else (eq (const_string \"<V_sz_elem>\") (const_string \"64\"))\n+                    (const_string \"neon_vst1_1_2_regs_vst2_2_regs\")\n+                    (const_string \"neon_vst2_4_regs_vst3_vst4\")))]\n+)\n \n (define_expand \"neon_vst4<mode>\"\n   [(match_operand:SI 0 \"s_register_operand\" \"+r\")\n@@ -3812,7 +4660,9 @@\n   ops[4] = gen_rtx_REG (DImode, regno + 12);\n   output_asm_insn (\"vst4.<V_sz_elem>\\t{%P1, %P2, %P3, %P4}, [%0]!\", ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vst2_4_regs_vst3_vst4\")]\n+)\n \n (define_insn \"neon_vst4qb<mode>\"\n   [(set (mem:OI (match_operand:SI 1 \"s_register_operand\" \"0\"))\n@@ -3833,7 +4683,9 @@\n   ops[4] = gen_rtx_REG (DImode, regno + 14);\n   output_asm_insn (\"vst4.<V_sz_elem>\\t{%P1, %P2, %P3, %P4}, [%0]!\", ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vst2_4_regs_vst3_vst4\")]\n+)\n \n (define_insn \"neon_vst4_lane<mode>\"\n   [(set (mem:<V_four_elem> (match_operand:SI 0 \"s_register_operand\" \"r\"))\n@@ -3859,7 +4711,9 @@\n   output_asm_insn (\"vst4.<V_sz_elem>\\t{%P1[%c5], %P2[%c5], %P3[%c5], %P4[%c5]}, [%0]\",\n                    ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vst3_vst4_lane\")]\n+)\n \n (define_insn \"neon_vst4_lane<mode>\"\n   [(set (mem:<V_four_elem> (match_operand:SI 0 \"s_register_operand\" \"r\"))\n@@ -3890,7 +4744,9 @@\n   output_asm_insn (\"vst4.<V_sz_elem>\\t{%P1[%c5], %P2[%c5], %P3[%c5], %P4[%c5]}, [%0]\",\n                    ops);\n   return \"\";\n-})\n+}\n+  [(set_attr \"neon_type\" \"neon_vst3_vst4_lane\")]\n+)\n \n (define_expand \"neon_vand<mode>\"\n   [(match_operand:VDQX 0 \"s_register_operand\" \"\")"}]}