{"sha": "d1f2e4c1027b826cf3ba353e86c37589f63f8efe", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDFmMmU0YzEwMjdiODI2Y2YzYmEzNTNlODZjMzc1ODlmNjNmOGVmZQ==", "commit": {"author": {"name": "Richard Biener", "email": "rguenther@suse.de", "date": "2019-07-18T08:09:16Z"}, "committer": {"name": "Richard Biener", "email": "rguenth@gcc.gnu.org", "date": "2019-07-18T08:09:16Z"}, "message": "tree-ssa-sccvn.c (vn_walk_cb_data::push_partial_def): Refactor branches to make code less indented.\n\n2019-07-18  Richard Biener  <rguenther@suse.de>\n\n\t* tree-ssa-sccvn.c (vn_walk_cb_data::push_partial_def): Refactor\n\tbranches to make code less indented.\n\nFrom-SVN: r273567", "tree": {"sha": "964875eda854419d8cd5bf938131146a461ac3ab", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/964875eda854419d8cd5bf938131146a461ac3ab"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d1f2e4c1027b826cf3ba353e86c37589f63f8efe", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d1f2e4c1027b826cf3ba353e86c37589f63f8efe", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d1f2e4c1027b826cf3ba353e86c37589f63f8efe", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d1f2e4c1027b826cf3ba353e86c37589f63f8efe/comments", "author": {"login": "rguenth", "id": 2046526, "node_id": "MDQ6VXNlcjIwNDY1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/2046526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rguenth", "html_url": "https://github.com/rguenth", "followers_url": "https://api.github.com/users/rguenth/followers", "following_url": "https://api.github.com/users/rguenth/following{/other_user}", "gists_url": "https://api.github.com/users/rguenth/gists{/gist_id}", "starred_url": "https://api.github.com/users/rguenth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rguenth/subscriptions", "organizations_url": "https://api.github.com/users/rguenth/orgs", "repos_url": "https://api.github.com/users/rguenth/repos", "events_url": "https://api.github.com/users/rguenth/events{/privacy}", "received_events_url": "https://api.github.com/users/rguenth/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "b94b6cc0251d4775ac15f43885ed63279edb9581", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b94b6cc0251d4775ac15f43885ed63279edb9581", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b94b6cc0251d4775ac15f43885ed63279edb9581"}], "stats": {"total": 267, "additions": 124, "deletions": 143}, "files": [{"sha": "76baf87d9fc55e74ae28649a1254b73cfb37f335", "filename": "gcc/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d1f2e4c1027b826cf3ba353e86c37589f63f8efe/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d1f2e4c1027b826cf3ba353e86c37589f63f8efe/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=d1f2e4c1027b826cf3ba353e86c37589f63f8efe", "patch": "@@ -1,3 +1,8 @@\n+2019-07-18  Richard Biener  <rguenther@suse.de>\n+\n+\t* tree-ssa-sccvn.c (vn_walk_cb_data::push_partial_def): Refactor\n+\tbranches to make code less indented.\n+\n 2019-07-17  Alexandre Oliva <oliva@adacore.com>\n \n \tPR middle-end/81824"}, {"sha": "f12c9dd3403cb2da6ef6110a770ad2d4bccd0972", "filename": "gcc/tree-ssa-sccvn.c", "status": "modified", "additions": 119, "deletions": 143, "changes": 262, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d1f2e4c1027b826cf3ba353e86c37589f63f8efe/gcc%2Ftree-ssa-sccvn.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d1f2e4c1027b826cf3ba353e86c37589f63f8efe/gcc%2Ftree-ssa-sccvn.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-sccvn.c?ref=d1f2e4c1027b826cf3ba353e86c37589f63f8efe", "patch": "@@ -1746,160 +1746,136 @@ vn_walk_cb_data::push_partial_def (const pd_data &pd, tree vuse,\n       first_range.size = pd.size;\n       first_vuse = vuse;\n       last_vuse_ptr = NULL;\n+      /* Continue looking for partial defs.  */\n+      return NULL;\n+    }\n+\n+  if (!known_ranges)\n+    {\n+      /* ???  Optimize the case where the 2nd partial def completes things.  */\n+      gcc_obstack_init (&ranges_obstack);\n+      known_ranges = splay_tree_new_with_allocator (pd_range_compare, 0, 0,\n+\t\t\t\t\t\t    pd_tree_alloc,\n+\t\t\t\t\t\t    pd_tree_dealloc, this);\n+      splay_tree_insert (known_ranges,\n+\t\t\t (splay_tree_key)&first_range.offset,\n+\t\t\t (splay_tree_value)&first_range);\n+    }\n+\n+  pd_range newr = { pd.offset, pd.size };\n+  splay_tree_node n;\n+  pd_range *r;\n+  /* Lookup the predecessor of offset + 1 and see if we need to merge.  */\n+  HOST_WIDE_INT loffset = newr.offset + 1;\n+  if ((n = splay_tree_predecessor (known_ranges, (splay_tree_key)&loffset))\n+      && ((r = (pd_range *)n->value), true)\n+      && ranges_known_overlap_p (r->offset, r->size + 1,\n+\t\t\t\t newr.offset, newr.size))\n+    {\n+      /* Ignore partial defs already covered.  */\n+      if (known_subrange_p (newr.offset, newr.size, r->offset, r->size))\n+\treturn NULL;\n+      r->size = MAX (r->offset + r->size, newr.offset + newr.size) - r->offset;\n     }\n   else\n     {\n-      if (!known_ranges)\n-\t{\n-\t  /* ???  Optimize the case where the second partial def\n-\t     completes things.  */\n-\t  gcc_obstack_init (&ranges_obstack);\n-\t  known_ranges\n-\t      = splay_tree_new_with_allocator (pd_range_compare, 0, 0,\n-\t\t\t\t\t       pd_tree_alloc,\n-\t\t\t\t\t       pd_tree_dealloc, this);\n-\t  splay_tree_insert (known_ranges,\n-\t\t\t     (splay_tree_key)&first_range.offset,\n-\t\t\t     (splay_tree_value)&first_range);\n-\t}\n-      if (known_ranges)\n+      /* newr.offset wasn't covered yet, insert the range.  */\n+      r = XOBNEW (&ranges_obstack, pd_range);\n+      *r = newr;\n+      splay_tree_insert (known_ranges, (splay_tree_key)&r->offset,\n+\t\t\t (splay_tree_value)r);\n+    }\n+  /* Merge r which now contains newr and is a member of the splay tree with\n+     adjacent overlapping ranges.  */\n+  pd_range *rafter;\n+  while ((n = splay_tree_successor (known_ranges, (splay_tree_key)&r->offset))\n+\t && ((rafter = (pd_range *)n->value), true)\n+\t && ranges_known_overlap_p (r->offset, r->size + 1,\n+\t\t\t\t    rafter->offset, rafter->size))\n+    {\n+      r->size = MAX (r->offset + r->size,\n+\t\t     rafter->offset + rafter->size) - r->offset;\n+      splay_tree_remove (known_ranges, (splay_tree_key)&rafter->offset);\n+    }\n+  partial_defs.safe_push (pd);\n+\n+  /* Now we have merged newr into the range tree.  When we have covered\n+     [offseti, sizei] then the tree will contain exactly one node which has\n+     the desired properties and it will be 'r'.  */\n+  if (!known_subrange_p (0, maxsizei / BITS_PER_UNIT, r->offset, r->size))\n+    /* Continue looking for partial defs.  */\n+    return NULL;\n+\n+  /* Now simply native encode all partial defs in reverse order.  */\n+  unsigned ndefs = partial_defs.length ();\n+  /* We support up to 512-bit values (for V8DFmode).  */\n+  unsigned char buffer[64];\n+  int len;\n+\n+  while (!partial_defs.is_empty ())\n+    {\n+      pd_data pd = partial_defs.pop ();\n+      if (TREE_CODE (pd.rhs) == CONSTRUCTOR)\n+\t/* Empty CONSTRUCTOR.  */\n+\tmemset (buffer + MAX (0, pd.offset),\n+\t\t0, MIN ((HOST_WIDE_INT)sizeof (buffer), pd.size));\n+      else\n \t{\n-\t  pd_range newr = { pd.offset, pd.size };\n-\t  splay_tree_node n;\n-\t  pd_range *r;\n-\t  /* Lookup the predecessor of offset + 1 and see if\n-\t     we need to merge with it.  */\n-\t  HOST_WIDE_INT loffset = newr.offset + 1;\n-\t  if ((n = splay_tree_predecessor (known_ranges,\n-\t\t\t\t\t   (splay_tree_key)&loffset))\n-\t      && ((r = (pd_range *)n->value), true)\n-\t      && ranges_known_overlap_p (r->offset, r->size + 1,\n-\t\t\t\t\t newr.offset, newr.size))\n+\t  unsigned pad = 0;\n+\t  if (BYTES_BIG_ENDIAN\n+\t      && is_a <scalar_mode> (TYPE_MODE (TREE_TYPE (pd.rhs))))\n \t    {\n-\t      /* Ignore partial defs already covered.  */\n-\t      if (known_subrange_p (newr.offset, newr.size,\n-\t\t\t\t    r->offset, r->size))\n-\t\treturn NULL;\n-\t      r->size = MAX (r->offset + r->size,\n-\t\t\t     newr.offset + newr.size) - r->offset;\n+\t      /* On big-endian the padding is at the 'front' so just skip\n+\t\t the initial bytes.  */\n+\t      fixed_size_mode mode\n+\t\t= as_a <fixed_size_mode> (TYPE_MODE (TREE_TYPE (pd.rhs)));\n+\t      pad = GET_MODE_SIZE (mode) - pd.size;\n \t    }\n-\t  else\n-\t    {\n-\t      /* newr.offset wasn't covered yet, insert the\n-\t\t range.  */\n-\t      r = XOBNEW (&ranges_obstack, pd_range);\n-\t      *r = newr;\n-\t      splay_tree_insert (known_ranges,\n-\t\t\t\t (splay_tree_key)&r->offset,\n-\t\t\t\t (splay_tree_value)r);\n-\t    }\n-\t  /* Merge r which now contains newr and is a member\n-\t     of the splay tree with adjacent overlapping ranges.  */\n-\t  pd_range *rafter;\n-\t  while ((n = splay_tree_successor (known_ranges,\n-\t\t\t\t\t    (splay_tree_key)&r->offset))\n-\t\t && ((rafter = (pd_range *)n->value), true)\n-\t\t && ranges_known_overlap_p (r->offset, r->size + 1,\n-\t\t\t\t\t    rafter->offset, rafter->size))\n+\t  len = native_encode_expr (pd.rhs, buffer + MAX (0, pd.offset),\n+\t\t\t\t    sizeof (buffer - MAX (0, pd.offset)),\n+\t\t\t\t    MAX (0, -pd.offset) + pad);\n+\t  if (len <= 0 || len < (pd.size - MAX (0, -pd.offset)))\n \t    {\n-\t      r->size = MAX (r->offset + r->size,\n-\t\t\t     rafter->offset + rafter->size) - r->offset;\n-\t      splay_tree_remove (known_ranges,\n-\t\t\t\t (splay_tree_key)&rafter->offset);\n+\t      if (dump_file && (dump_flags & TDF_DETAILS))\n+\t\tfprintf (dump_file, \"Failed to encode %u \"\n+\t\t\t \"partial definitions\\n\", ndefs);\n+\t      return (void *)-1;\n \t    }\n-\t  partial_defs.safe_push (pd);\n-\n-\t  /* Now we have merged newr into the range tree.\n-\t     When we have covered [offseti, sizei] then the\n-\t     tree will contain exactly one node which has\n-\t     the desired properties and it will be 'r'.  */\n-\t  if (known_subrange_p (0, maxsizei / BITS_PER_UNIT,\n-\t\t\t\tr->offset, r->size))\n-\t    {\n-\t      /* Now simply native encode all partial defs\n-\t\t in reverse order.  */\n-\t      unsigned ndefs = partial_defs.length ();\n-\t      /* We support up to 512-bit values (for V8DFmode).  */\n-\t      unsigned char buffer[64];\n-\t      int len;\n-\n-\t      while (!partial_defs.is_empty ())\n-\t\t{\n-\t\t  pd_data pd = partial_defs.pop ();\n-\t\t  if (TREE_CODE (pd.rhs) == CONSTRUCTOR)\n-\t\t    /* Empty CONSTRUCTOR.  */\n-\t\t    memset (buffer + MAX (0, pd.offset),\n-\t\t\t    0, MIN ((HOST_WIDE_INT)sizeof (buffer), pd.size));\n-\t\t  else\n-\t\t    {\n-\t\t      unsigned pad = 0;\n-\t\t      if (BYTES_BIG_ENDIAN\n-\t\t\t  && is_a <scalar_mode> (TYPE_MODE (TREE_TYPE (pd.rhs))))\n-\t\t\t{\n-\t\t\t  /* On big-endian the padding is at the 'front' so\n-\t\t\t     just skip the initial bytes.  */\n-\t\t\t  fixed_size_mode mode = as_a <fixed_size_mode>\n-\t\t\t\t\t       (TYPE_MODE (TREE_TYPE (pd.rhs)));\n-\t\t\t  pad = GET_MODE_SIZE (mode) - pd.size;\n-\t\t\t}\n-\t\t      len = native_encode_expr (pd.rhs,\n-\t\t\t\t\t\tbuffer + MAX (0, pd.offset),\n-\t\t\t\t\t\tsizeof (buffer - MAX (0, pd.offset)),\n-\t\t\t\t\t\tMAX (0, -pd.offset) + pad);\n-\t\t      if (len <= 0\n-\t\t\t  || len < (pd.size - MAX (0, -pd.offset)))\n-\t\t\t{\n-\t\t\t  if (dump_file && (dump_flags & TDF_DETAILS))\n-\t\t\t    fprintf (dump_file, \"Failed to encode %u \"\n-\t\t\t\t     \"partial definitions\\n\", ndefs);\n-\t\t\t  return (void *)-1;\n-\t\t\t}\n-\t\t    }\n-\t\t}\n+\t}\n+    }\n \n-\t      tree type = vr->type;\n-\t      /* Make sure to interpret in a type that has a range\n-\t\t covering the whole access size.  */\n-\t      if (INTEGRAL_TYPE_P (vr->type)\n-\t\t  && maxsizei != TYPE_PRECISION (vr->type))\n-\t\ttype = build_nonstandard_integer_type (maxsizei,\n-\t\t\t\t\t\t       TYPE_UNSIGNED (type));\n-\t      tree val = native_interpret_expr (type, buffer,\n-\t\t\t\t\t\tmaxsizei / BITS_PER_UNIT);\n-\t      /* If we chop off bits because the types precision doesn't\n-\t\t match the memory access size this is ok when optimizing\n-\t\t reads but not when called from the DSE code during\n-\t\t elimination.  */\n-\t      if (val\n-\t\t  && type != vr->type)\n-\t\t{\n-\t\t  if (! int_fits_type_p (val, vr->type))\n-\t\t    val = NULL_TREE;\n-\t\t  else\n-\t\t    val = fold_convert (vr->type, val);\n-\t\t}\n+  tree type = vr->type;\n+  /* Make sure to interpret in a type that has a range covering the whole\n+     access size.  */\n+  if (INTEGRAL_TYPE_P (vr->type) && maxsizei != TYPE_PRECISION (vr->type))\n+    type = build_nonstandard_integer_type (maxsizei, TYPE_UNSIGNED (type));\n+  tree val = native_interpret_expr (type, buffer, maxsizei / BITS_PER_UNIT);\n+  /* If we chop off bits because the types precision doesn't match the memory\n+     access size this is ok when optimizing reads but not when called from\n+     the DSE code during elimination.  */\n+  if (val && type != vr->type)\n+    {\n+      if (! int_fits_type_p (val, vr->type))\n+\tval = NULL_TREE;\n+      else\n+\tval = fold_convert (vr->type, val);\n+    }\n \n-\t      if (val)\n-\t\t{\n-\t\t  if (dump_file && (dump_flags & TDF_DETAILS))\n-\t\t    fprintf (dump_file, \"Successfully combined %u \"\n-\t\t\t     \"partial definitions\\n\", ndefs);\n-\t\t  return vn_reference_lookup_or_insert_for_pieces\n-\t\t      (first_vuse,\n-\t\t       vr->set, vr->type, vr->operands, val);\n-\t\t}\n-\t      else\n-\t\t{\n-\t\t  if (dump_file && (dump_flags & TDF_DETAILS))\n-\t\t    fprintf (dump_file, \"Failed to interpret %u \"\n-\t\t\t     \"encoded partial definitions\\n\", ndefs);\n-\t\t  return (void *)-1;\n-\t\t}\n-\t    }\n-\t}\n+  if (val)\n+    {\n+      if (dump_file && (dump_flags & TDF_DETAILS))\n+\tfprintf (dump_file,\n+\t\t \"Successfully combined %u partial definitions\\n\", ndefs);\n+      return vn_reference_lookup_or_insert_for_pieces\n+\t\t(first_vuse, vr->set, vr->type, vr->operands, val);\n+    }\n+  else\n+    {\n+      if (dump_file && (dump_flags & TDF_DETAILS))\n+\tfprintf (dump_file,\n+\t\t \"Failed to interpret %u encoded partial definitions\\n\", ndefs);\n+      return (void *)-1;\n     }\n-  /* Continue looking for partial defs.  */\n-  return NULL;\n }\n \n /* Callback for walk_non_aliased_vuses.  Adjusts the vn_reference_t VR_"}]}