{"sha": "76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "node_id": "C_kwDOANBUbNoAKDc2Mjg4ZTFjNWRhNWEzNGUzYzEzZDM3YWM0Y2FiNDFlMGY0NmZmNjE", "commit": {"author": {"name": "H.J. Lu", "email": "hjl.tools@gmail.com", "date": "2021-09-27T17:43:33Z"}, "committer": {"name": "H.J. Lu", "email": "hjl.tools@gmail.com", "date": "2021-10-01T16:02:54Z"}, "message": "libsanitizer: Merge with upstream\n\nMerged revision: 1c2e5fd66ea27d0c51360ba4e22099124a915562", "tree": {"sha": "91841423d03755f702c6a60401338e06c08c8017", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/91841423d03755f702c6a60401338e06c08c8017"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "html_url": "https://github.com/Rust-GCC/gccrs/commit/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/comments", "author": {"login": "hjl-tools", "id": 1072356, "node_id": "MDQ6VXNlcjEwNzIzNTY=", "avatar_url": "https://avatars.githubusercontent.com/u/1072356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hjl-tools", "html_url": "https://github.com/hjl-tools", "followers_url": "https://api.github.com/users/hjl-tools/followers", "following_url": "https://api.github.com/users/hjl-tools/following{/other_user}", "gists_url": "https://api.github.com/users/hjl-tools/gists{/gist_id}", "starred_url": "https://api.github.com/users/hjl-tools/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hjl-tools/subscriptions", "organizations_url": "https://api.github.com/users/hjl-tools/orgs", "repos_url": "https://api.github.com/users/hjl-tools/repos", "events_url": "https://api.github.com/users/hjl-tools/events{/privacy}", "received_events_url": "https://api.github.com/users/hjl-tools/received_events", "type": "User", "site_admin": false}, "committer": {"login": "hjl-tools", "id": 1072356, "node_id": "MDQ6VXNlcjEwNzIzNTY=", "avatar_url": "https://avatars.githubusercontent.com/u/1072356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hjl-tools", "html_url": "https://github.com/hjl-tools", "followers_url": "https://api.github.com/users/hjl-tools/followers", "following_url": "https://api.github.com/users/hjl-tools/following{/other_user}", "gists_url": "https://api.github.com/users/hjl-tools/gists{/gist_id}", "starred_url": "https://api.github.com/users/hjl-tools/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hjl-tools/subscriptions", "organizations_url": "https://api.github.com/users/hjl-tools/orgs", "repos_url": "https://api.github.com/users/hjl-tools/repos", "events_url": "https://api.github.com/users/hjl-tools/events{/privacy}", "received_events_url": "https://api.github.com/users/hjl-tools/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7c99923f8c544ec07109e8333acb2c2388c38a1b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7c99923f8c544ec07109e8333acb2c2388c38a1b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/7c99923f8c544ec07109e8333acb2c2388c38a1b"}], "stats": {"total": 13563, "additions": 7454, "deletions": 6109}, "files": [{"sha": "2094a8beb3e0610243a2e09abe768d54a76f66d2", "filename": "libsanitizer/MERGE", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2FMERGE", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2FMERGE", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2FMERGE?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -1,4 +1,4 @@\n-7704fedfff6ef5676adb6415f3be0ac927d1a746\n+1c2e5fd66ea27d0c51360ba4e22099124a915562\n \n The first line of this file holds the git revision number of the\n last merge done from the master library sources."}, {"sha": "b419019d137d4f17ab981c059ebb23e4b93831fd", "filename": "libsanitizer/asan/asan_fuchsia.cpp", "status": "modified", "additions": 32, "deletions": 3, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_fuchsia.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_fuchsia.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_fuchsia.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -31,7 +31,8 @@ namespace __asan {\n // AsanInitInternal->InitializeHighMemEnd (asan_rtl.cpp).\n // Just do some additional sanity checks here.\n void InitializeShadowMemory() {\n-  if (Verbosity()) PrintAddressSpaceLayout();\n+  if (Verbosity())\n+    PrintAddressSpaceLayout();\n \n   // Make sure SHADOW_OFFSET doesn't use __asan_shadow_memory_dynamic_address.\n   __asan_shadow_memory_dynamic_address = kDefaultShadowSentinel;\n@@ -62,7 +63,34 @@ void AsanOnDeadlySignal(int signo, void *siginfo, void *context) {\n   UNIMPLEMENTED();\n }\n \n-bool PlatformUnpoisonStacks() { return false; }\n+bool PlatformUnpoisonStacks() {\n+  // The current sp might not point to the default stack. This\n+  // could be because we are in a crash stack from fuzzing for example.\n+  // Unpoison the default stack and the current stack page.\n+  AsanThread *curr_thread = GetCurrentThread();\n+  CHECK(curr_thread != nullptr);\n+  uptr top = curr_thread->stack_top();\n+  uptr bottom = curr_thread->stack_bottom();\n+  // The default stack grows from top to bottom. (bottom < top).\n+\n+  uptr local_stack = reinterpret_cast<uptr>(__builtin_frame_address(0));\n+  if (local_stack >= bottom && local_stack <= top) {\n+    // The current stack is the default stack.\n+    // We only need to unpoison from where we are using until the end.\n+    bottom = RoundDownTo(local_stack, GetPageSize());\n+    UnpoisonStack(bottom, top, \"default\");\n+  } else {\n+    // The current stack is not the default stack.\n+    // Unpoison the entire default stack and the current stack page.\n+    UnpoisonStack(bottom, top, \"default\");\n+    bottom = RoundDownTo(local_stack, GetPageSize());\n+    top = bottom + GetPageSize();\n+    UnpoisonStack(bottom, top, \"unknown\");\n+    return true;\n+  }\n+\n+  return false;\n+}\n \n // We can use a plain thread_local variable for TSD.\n static thread_local void *per_thread;\n@@ -148,7 +176,8 @@ static void *BeforeThreadCreateHook(uptr user_id, bool detached,\n                                     uptr stack_size) {\n   EnsureMainThreadIDIsCorrect();\n   // Strict init-order checking is thread-hostile.\n-  if (flags()->strict_init_order) StopInitOrderChecking();\n+  if (flags()->strict_init_order)\n+    StopInitOrderChecking();\n \n   GET_STACK_TRACE_THREAD;\n   u32 parent_tid = GetCurrentTidOrInvalid();"}, {"sha": "9bf378f62071da89513da0cf9ddf4d00dbefb9d6", "filename": "libsanitizer/asan/asan_globals.cpp", "status": "modified", "additions": 26, "deletions": 7, "changes": 33, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_globals.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_globals.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_globals.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -35,7 +35,7 @@ struct ListOfGlobals {\n   ListOfGlobals *next;\n };\n \n-static BlockingMutex mu_for_globals(LINKER_INITIALIZED);\n+static Mutex mu_for_globals;\n static LowLevelAllocator allocator_for_globals;\n static ListOfGlobals *list_of_all_globals;\n \n@@ -108,7 +108,7 @@ static u32 FindRegistrationSite(const Global *g) {\n int GetGlobalsForAddress(uptr addr, Global *globals, u32 *reg_sites,\n                          int max_globals) {\n   if (!flags()->report_globals) return 0;\n-  BlockingMutexLock lock(&mu_for_globals);\n+  Lock lock(&mu_for_globals);\n   int res = 0;\n   for (ListOfGlobals *l = list_of_all_globals; l; l = l->next) {\n     const Global &g = *l->g;\n@@ -154,6 +154,23 @@ static void CheckODRViolationViaIndicator(const Global *g) {\n   }\n }\n \n+// Check ODR violation for given global G by checking if it's already poisoned.\n+// We use this method in case compiler doesn't use private aliases for global\n+// variables.\n+static void CheckODRViolationViaPoisoning(const Global *g) {\n+  if (__asan_region_is_poisoned(g->beg, g->size_with_redzone)) {\n+    // This check may not be enough: if the first global is much larger\n+    // the entire redzone of the second global may be within the first global.\n+    for (ListOfGlobals *l = list_of_all_globals; l; l = l->next) {\n+      if (g->beg == l->g->beg &&\n+          (flags()->detect_odr_violation >= 2 || g->size != l->g->size) &&\n+          !IsODRViolationSuppressed(g->name))\n+        ReportODRViolation(g, FindRegistrationSite(g),\n+                           l->g, FindRegistrationSite(l->g));\n+    }\n+  }\n+}\n+\n // Clang provides two different ways for global variables protection:\n // it can poison the global itself or its private alias. In former\n // case we may poison same symbol multiple times, that can help us to\n@@ -199,6 +216,8 @@ static void RegisterGlobal(const Global *g) {\n     // where two globals with the same name are defined in different modules.\n     if (UseODRIndicator(g))\n       CheckODRViolationViaIndicator(g);\n+    else\n+      CheckODRViolationViaPoisoning(g);\n   }\n   if (CanPoisonMemory())\n     PoisonRedZones(*g);\n@@ -238,7 +257,7 @@ static void UnregisterGlobal(const Global *g) {\n }\n \n void StopInitOrderChecking() {\n-  BlockingMutexLock lock(&mu_for_globals);\n+  Lock lock(&mu_for_globals);\n   if (!flags()->check_initialization_order || !dynamic_init_globals)\n     return;\n   flags()->check_initialization_order = false;\n@@ -340,7 +359,7 @@ void __asan_register_globals(__asan_global *globals, uptr n) {\n   if (!flags()->report_globals) return;\n   GET_STACK_TRACE_MALLOC;\n   u32 stack_id = StackDepotPut(stack);\n-  BlockingMutexLock lock(&mu_for_globals);\n+  Lock lock(&mu_for_globals);\n   if (!global_registration_site_vector) {\n     global_registration_site_vector =\n         new (allocator_for_globals) GlobalRegistrationSiteVector;\n@@ -379,7 +398,7 @@ void __asan_register_globals(__asan_global *globals, uptr n) {\n // We must do this when a shared objects gets dlclosed.\n void __asan_unregister_globals(__asan_global *globals, uptr n) {\n   if (!flags()->report_globals) return;\n-  BlockingMutexLock lock(&mu_for_globals);\n+  Lock lock(&mu_for_globals);\n   for (uptr i = 0; i < n; i++) {\n     if (SANITIZER_WINDOWS && globals[i].beg == 0) {\n       // Skip globals that look like padding from the MSVC incremental linker.\n@@ -405,7 +424,7 @@ void __asan_before_dynamic_init(const char *module_name) {\n   bool strict_init_order = flags()->strict_init_order;\n   CHECK(module_name);\n   CHECK(asan_inited);\n-  BlockingMutexLock lock(&mu_for_globals);\n+  Lock lock(&mu_for_globals);\n   if (flags()->report_globals >= 3)\n     Printf(\"DynInitPoison module: %s\\n\", module_name);\n   for (uptr i = 0, n = dynamic_init_globals->size(); i < n; ++i) {\n@@ -429,7 +448,7 @@ void __asan_after_dynamic_init() {\n       !dynamic_init_globals)\n     return;\n   CHECK(asan_inited);\n-  BlockingMutexLock lock(&mu_for_globals);\n+  Lock lock(&mu_for_globals);\n   // FIXME: Optionally report that we're unpoisoning globals from a module.\n   for (uptr i = 0, n = dynamic_init_globals->size(); i < n; ++i) {\n     DynInitGlobal &dyn_g = (*dynamic_init_globals)[i];"}, {"sha": "b28909152e208e7a2ee953971be91a663275afc4", "filename": "libsanitizer/asan/asan_interceptors.cpp", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_interceptors.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_interceptors.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_interceptors.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -49,8 +49,8 @@ namespace __asan {\n   ASAN_READ_RANGE((ctx), (s),                                   \\\n     common_flags()->strict_string_checks ? (len) + 1 : (n))\n \n-#define ASAN_READ_STRING(ctx, s, n)                             \\\n-  ASAN_READ_STRING_OF_LEN((ctx), (s), REAL(strlen)(s), (n))\n+#  define ASAN_READ_STRING(ctx, s, n) \\\n+    ASAN_READ_STRING_OF_LEN((ctx), (s), internal_strlen(s), (n))\n \n static inline uptr MaybeRealStrnlen(const char *s, uptr maxlen) {\n #if SANITIZER_INTERCEPT_STRNLEN\n@@ -370,9 +370,9 @@ DEFINE_REAL(char*, index, const char *string, int c)\n     ASAN_INTERCEPTOR_ENTER(ctx, strcat);\n     ENSURE_ASAN_INITED();\n     if (flags()->replace_str) {\n-      uptr from_length = REAL(strlen)(from);\n+      uptr from_length = internal_strlen(from);\n       ASAN_READ_RANGE(ctx, from, from_length + 1);\n-      uptr to_length = REAL(strlen)(to);\n+      uptr to_length = internal_strlen(to);\n       ASAN_READ_STRING_OF_LEN(ctx, to, to_length, to_length);\n       ASAN_WRITE_RANGE(ctx, to + to_length, from_length + 1);\n       // If the copying actually happens, the |from| string should not overlap\n@@ -394,7 +394,7 @@ INTERCEPTOR(char*, strncat, char *to, const char *from, uptr size) {\n     uptr from_length = MaybeRealStrnlen(from, size);\n     uptr copy_length = Min(size, from_length + 1);\n     ASAN_READ_RANGE(ctx, from, copy_length);\n-    uptr to_length = REAL(strlen)(to);\n+    uptr to_length = internal_strlen(to);\n     ASAN_READ_STRING_OF_LEN(ctx, to, to_length, to_length);\n     ASAN_WRITE_RANGE(ctx, to + to_length, from_length + 1);\n     if (from_length > 0) {\n@@ -419,7 +419,7 @@ INTERCEPTOR(char *, strcpy, char *to, const char *from) {\n   }\n   ENSURE_ASAN_INITED();\n   if (flags()->replace_str) {\n-    uptr from_size = REAL(strlen)(from) + 1;\n+    uptr from_size = internal_strlen(from) + 1;\n     CHECK_RANGES_OVERLAP(\"strcpy\", to, from_size, from, from_size);\n     ASAN_READ_RANGE(ctx, from, from_size);\n     ASAN_WRITE_RANGE(ctx, to, from_size);\n@@ -432,7 +432,7 @@ INTERCEPTOR(char*, strdup, const char *s) {\n   ASAN_INTERCEPTOR_ENTER(ctx, strdup);\n   if (UNLIKELY(!asan_inited)) return internal_strdup(s);\n   ENSURE_ASAN_INITED();\n-  uptr length = REAL(strlen)(s);\n+  uptr length = internal_strlen(s);\n   if (flags()->replace_str) {\n     ASAN_READ_RANGE(ctx, s, length + 1);\n   }\n@@ -448,7 +448,7 @@ INTERCEPTOR(char*, __strdup, const char *s) {\n   ASAN_INTERCEPTOR_ENTER(ctx, strdup);\n   if (UNLIKELY(!asan_inited)) return internal_strdup(s);\n   ENSURE_ASAN_INITED();\n-  uptr length = REAL(strlen)(s);\n+  uptr length = internal_strlen(s);\n   if (flags()->replace_str) {\n     ASAN_READ_RANGE(ctx, s, length + 1);\n   }\n@@ -581,7 +581,7 @@ INTERCEPTOR(int, atexit, void (*func)()) {\n #if CAN_SANITIZE_LEAKS\n   __lsan::ScopedInterceptorDisabler disabler;\n #endif\n-  // Avoid calling real atexit as it is unrechable on at least on Linux.\n+  // Avoid calling real atexit as it is unreachable on at least on Linux.\n   int res = REAL(__cxa_atexit)((void (*)(void *a))func, nullptr, nullptr);\n   REAL(__cxa_atexit)(AtCxaAtexit, nullptr, nullptr);\n   return res;"}, {"sha": "047b044c8bf47da51e74436dc088b2740fd162dc", "filename": "libsanitizer/asan/asan_interceptors.h", "status": "modified", "additions": 24, "deletions": 28, "changes": 52, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_interceptors.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_interceptors.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_interceptors.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -81,12 +81,7 @@ void InitializePlatformInterceptors();\n #if ASAN_HAS_EXCEPTIONS && !SANITIZER_WINDOWS && !SANITIZER_SOLARIS && \\\n     !SANITIZER_NETBSD\n # define ASAN_INTERCEPT___CXA_THROW 1\n-# if ! defined(ASAN_HAS_CXA_RETHROW_PRIMARY_EXCEPTION) \\\n-     || ASAN_HAS_CXA_RETHROW_PRIMARY_EXCEPTION\n-#   define ASAN_INTERCEPT___CXA_RETHROW_PRIMARY_EXCEPTION 1\n-# else\n-#   define ASAN_INTERCEPT___CXA_RETHROW_PRIMARY_EXCEPTION 0\n-# endif\n+# define ASAN_INTERCEPT___CXA_RETHROW_PRIMARY_EXCEPTION 1\n # if defined(_GLIBCXX_SJLJ_EXCEPTIONS) || (SANITIZER_IOS && defined(__arm__))\n #  define ASAN_INTERCEPT__UNWIND_SJLJ_RAISEEXCEPTION 1\n # else\n@@ -138,29 +133,30 @@ DECLARE_REAL(char*, strncpy, char *to, const char *from, uptr size)\n DECLARE_REAL(uptr, strnlen, const char *s, uptr maxlen)\n DECLARE_REAL(char*, strstr, const char *s1, const char *s2)\n \n-#if !SANITIZER_MAC\n-#define ASAN_INTERCEPT_FUNC(name)                                        \\\n-  do {                                                                   \\\n-    if (!INTERCEPT_FUNCTION(name))                                       \\\n-      VReport(1, \"AddressSanitizer: failed to intercept '%s'\\n\", #name); \\\n-  } while (0)\n-#define ASAN_INTERCEPT_FUNC_VER(name, ver)                                  \\\n-  do {                                                                      \\\n-    if (!INTERCEPT_FUNCTION_VER(name, ver))                                 \\\n-      VReport(1, \"AddressSanitizer: failed to intercept '%s@@%s'\\n\", #name, \\\n-              #ver);                                                        \\\n-  } while (0)\n-#define ASAN_INTERCEPT_FUNC_VER_UNVERSIONED_FALLBACK(name, ver)              \\\n-  do {                                                                       \\\n-    if (!INTERCEPT_FUNCTION_VER(name, ver) && !INTERCEPT_FUNCTION(name))     \\\n-      VReport(1, \"AddressSanitizer: failed to intercept '%s@@%s' or '%s'\\n\", \\\n-              #name, #ver, #name);                                           \\\n-  } while (0)\n-\n-#else\n+#  if !SANITIZER_MAC\n+#    define ASAN_INTERCEPT_FUNC(name)                                        \\\n+      do {                                                                   \\\n+        if (!INTERCEPT_FUNCTION(name))                                       \\\n+          VReport(1, \"AddressSanitizer: failed to intercept '%s'\\n\", #name); \\\n+      } while (0)\n+#    define ASAN_INTERCEPT_FUNC_VER(name, ver)                           \\\n+      do {                                                               \\\n+        if (!INTERCEPT_FUNCTION_VER(name, ver))                          \\\n+          VReport(1, \"AddressSanitizer: failed to intercept '%s@@%s'\\n\", \\\n+                  #name, ver);                                           \\\n+      } while (0)\n+#    define ASAN_INTERCEPT_FUNC_VER_UNVERSIONED_FALLBACK(name, ver)           \\\n+      do {                                                                    \\\n+        if (!INTERCEPT_FUNCTION_VER(name, ver) && !INTERCEPT_FUNCTION(name))  \\\n+          VReport(1,                                                          \\\n+                  \"AddressSanitizer: failed to intercept '%s@@%s' or '%s'\\n\", \\\n+                  #name, ver, #name);                                         \\\n+      } while (0)\n+\n+#  else\n // OS X interceptors don't need to be initialized with INTERCEPT_FUNCTION.\n-#define ASAN_INTERCEPT_FUNC(name)\n-#endif  // SANITIZER_MAC\n+#    define ASAN_INTERCEPT_FUNC(name)\n+#  endif  // SANITIZER_MAC\n \n #endif  // !SANITIZER_FUCHSIA\n "}, {"sha": "e5a7f2007aea8b8208e929e08ee675a55cd252eb", "filename": "libsanitizer/asan/asan_mapping.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_mapping.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_mapping.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_mapping.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -165,7 +165,7 @@ static const u64 kAArch64_ShadowOffset64 = 1ULL << 36;\n static const u64 kRiscv64_ShadowOffset64 = 0xd55550000;\n static const u64 kMIPS32_ShadowOffset32 = 0x0aaa0000;\n static const u64 kMIPS64_ShadowOffset64 = 1ULL << 37;\n-static const u64 kPPC64_ShadowOffset64 = 1ULL << 41;\n+static const u64 kPPC64_ShadowOffset64 = 1ULL << 44;\n static const u64 kSystemZ_ShadowOffset64 = 1ULL << 52;\n static const u64 kSPARC64_ShadowOffset64 = 1ULL << 43;  // 0x80000000000\n static const u64 kFreeBSD_ShadowOffset32 = 1ULL << 30;  // 0x40000000"}, {"sha": "271d8964038399ac941b0d78b883937a4c3c8696", "filename": "libsanitizer/asan/asan_report.cpp", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_report.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_report.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_report.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -32,12 +32,12 @@ namespace __asan {\n static void (*error_report_callback)(const char*);\n static char *error_message_buffer = nullptr;\n static uptr error_message_buffer_pos = 0;\n-static BlockingMutex error_message_buf_mutex(LINKER_INITIALIZED);\n+static Mutex error_message_buf_mutex;\n static const unsigned kAsanBuggyPcPoolSize = 25;\n static __sanitizer::atomic_uintptr_t AsanBuggyPcPool[kAsanBuggyPcPoolSize];\n \n void AppendToErrorMessageBuffer(const char *buffer) {\n-  BlockingMutexLock l(&error_message_buf_mutex);\n+  Lock l(&error_message_buf_mutex);\n   if (!error_message_buffer) {\n     error_message_buffer =\n       (char*)MmapOrDieQuietly(kErrorMessageBufferSize, __func__);\n@@ -155,10 +155,10 @@ class ScopedInErrorReport {\n       DumpProcessMap();\n \n     // Copy the message buffer so that we could start logging without holding a\n-    // lock that gets aquired during printing.\n+    // lock that gets acquired during printing.\n     InternalMmapVector<char> buffer_copy(kErrorMessageBufferSize);\n     {\n-      BlockingMutexLock l(&error_message_buf_mutex);\n+      Lock l(&error_message_buf_mutex);\n       internal_memcpy(buffer_copy.data(),\n                       error_message_buffer, kErrorMessageBufferSize);\n       // Clear error_message_buffer so that if we find other errors\n@@ -490,7 +490,7 @@ void __asan_report_error(uptr pc, uptr bp, uptr sp, uptr addr, int is_write,\n }\n \n void NOINLINE __asan_set_error_report_callback(void (*callback)(const char*)) {\n-  BlockingMutexLock l(&error_message_buf_mutex);\n+  Lock l(&error_message_buf_mutex);\n   error_report_callback = callback;\n }\n "}, {"sha": "bfaa3bc270274c82ee52e9b3367ee7a6203e6c51", "filename": "libsanitizer/asan/asan_rtl.cpp", "status": "modified", "additions": 12, "deletions": 6, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_rtl.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_rtl.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_rtl.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -82,6 +82,17 @@ void ShowStatsAndAbort() {\n   Die();\n }\n \n+NOINLINE\n+static void ReportGenericErrorWrapper(uptr addr, bool is_write, int size,\n+                                      int exp_arg, bool fatal) {\n+  if (__asan_test_only_reported_buggy_pointer) {\n+    *__asan_test_only_reported_buggy_pointer = addr;\n+  } else {\n+    GET_CALLER_PC_BP_SP;\n+    ReportGenericError(pc, bp, sp, addr, is_write, size, exp_arg, fatal);\n+  }\n+}\n+\n // --------------- LowLevelAllocateCallbac ---------- {{{1\n static void OnLowLevelAllocate(uptr ptr, uptr size) {\n   PoisonShadow(ptr, size, kAsanInternalHeapMagic);\n@@ -145,12 +156,7 @@ ASAN_REPORT_ERROR_N(store, true)\n     if (UNLIKELY(size >= SHADOW_GRANULARITY ||                                 \\\n                  ((s8)((addr & (SHADOW_GRANULARITY - 1)) + size - 1)) >=       \\\n                      (s8)s)) {                                                 \\\n-      if (__asan_test_only_reported_buggy_pointer) {                           \\\n-        *__asan_test_only_reported_buggy_pointer = addr;                       \\\n-      } else {                                                                 \\\n-        GET_CALLER_PC_BP_SP;                                                   \\\n-        ReportGenericError(pc, bp, sp, addr, is_write, size, exp_arg, fatal);  \\\n-      }                                                                        \\\n+      ReportGenericErrorWrapper(addr, is_write, size, exp_arg, fatal);         \\\n     }                                                                          \\\n   }\n "}, {"sha": "4182761083337efa8e05788204ea9227ebff2d5b", "filename": "libsanitizer/asan/asan_stats.cpp", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_stats.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_stats.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_stats.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -62,11 +62,11 @@ void AsanStats::MergeFrom(const AsanStats *stats) {\n     dst_ptr[i] += src_ptr[i];\n }\n \n-static BlockingMutex print_lock(LINKER_INITIALIZED);\n+static Mutex print_lock;\n \n static AsanStats unknown_thread_stats(LINKER_INITIALIZED);\n static AsanStats dead_threads_stats(LINKER_INITIALIZED);\n-static BlockingMutex dead_threads_stats_lock(LINKER_INITIALIZED);\n+static Mutex dead_threads_stats_lock;\n // Required for malloc_zone_statistics() on OS X. This can't be stored in\n // per-thread AsanStats.\n static uptr max_malloced_memory;\n@@ -87,7 +87,7 @@ static void GetAccumulatedStats(AsanStats *stats) {\n   }\n   stats->MergeFrom(&unknown_thread_stats);\n   {\n-    BlockingMutexLock lock(&dead_threads_stats_lock);\n+    Lock lock(&dead_threads_stats_lock);\n     stats->MergeFrom(&dead_threads_stats);\n   }\n   // This is not very accurate: we may miss allocation peaks that happen\n@@ -99,7 +99,7 @@ static void GetAccumulatedStats(AsanStats *stats) {\n }\n \n void FlushToDeadThreadStats(AsanStats *stats) {\n-  BlockingMutexLock lock(&dead_threads_stats_lock);\n+  Lock lock(&dead_threads_stats_lock);\n   dead_threads_stats.MergeFrom(stats);\n   stats->Clear();\n }\n@@ -122,7 +122,7 @@ static void PrintAccumulatedStats() {\n   AsanStats stats;\n   GetAccumulatedStats(&stats);\n   // Use lock to keep reports from mixing up.\n-  BlockingMutexLock lock(&print_lock);\n+  Lock lock(&print_lock);\n   stats.Print();\n   StackDepotStats *stack_depot_stats = StackDepotGetStats();\n   Printf(\"Stats: StackDepot: %zd ids; %zdM allocated\\n\","}, {"sha": "d25e8ee4f45fca98a39efdf7ec1a2d8a98f66141", "filename": "libsanitizer/asan/asan_thread.cpp", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_thread.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fasan%2Fasan_thread.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fasan%2Fasan_thread.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -43,11 +43,11 @@ void AsanThreadContext::OnFinished() {\n static ALIGNED(16) char thread_registry_placeholder[sizeof(ThreadRegistry)];\n static ThreadRegistry *asan_thread_registry;\n \n-static BlockingMutex mu_for_thread_context(LINKER_INITIALIZED);\n+static Mutex mu_for_thread_context;\n static LowLevelAllocator allocator_for_thread_context;\n \n static ThreadContextBase *GetAsanThreadContext(u32 tid) {\n-  BlockingMutexLock lock(&mu_for_thread_context);\n+  Lock lock(&mu_for_thread_context);\n   return new(allocator_for_thread_context) AsanThreadContext(tid);\n }\n "}, {"sha": "cfc1bfe8f011aaef62396fd604a0f4957ce03df7", "filename": "libsanitizer/hwasan/Makefile.am", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2FMakefile.am", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2FMakefile.am", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2FMakefile.am?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -28,7 +28,8 @@ hwasan_files = \\\n \thwasan_new_delete.cpp \\\n \thwasan_poisoning.cpp \\\n \thwasan_report.cpp \\\n-\thwasan_setjmp.S \\\n+\thwasan_setjmp_aarch64.S \\\n+\thwasan_setjmp_x86_64.S \\\n \thwasan_tag_mismatch_aarch64.S \\\n \thwasan_thread.cpp \\\n \thwasan_thread_list.cpp \\"}, {"sha": "f63670b50d1617ea836e00d2bd33074db2d4b973", "filename": "libsanitizer/hwasan/Makefile.in", "status": "modified", "additions": 7, "deletions": 5, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2FMakefile.in?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -151,9 +151,9 @@ am__objects_1 = hwasan_allocation_functions.lo hwasan_allocator.lo \\\n \thwasan_fuchsia.lo hwasan_globals.lo hwasan_interceptors.lo \\\n \thwasan_interceptors_vfork.lo hwasan_linux.lo \\\n \thwasan_memintrinsics.lo hwasan_new_delete.lo \\\n-\thwasan_poisoning.lo hwasan_report.lo hwasan_setjmp.lo \\\n-\thwasan_tag_mismatch_aarch64.lo hwasan_thread.lo \\\n-\thwasan_thread_list.lo hwasan_type_test.lo\n+\thwasan_poisoning.lo hwasan_report.lo hwasan_setjmp_aarch64.lo \\\n+\thwasan_setjmp_x86_64.lo hwasan_tag_mismatch_aarch64.lo \\\n+\thwasan_thread.lo hwasan_thread_list.lo hwasan_type_test.lo\n am_libhwasan_la_OBJECTS = $(am__objects_1)\n libhwasan_la_OBJECTS = $(am_libhwasan_la_OBJECTS)\n AM_V_lt = $(am__v_lt_@AM_V@)\n@@ -427,7 +427,8 @@ hwasan_files = \\\n \thwasan_new_delete.cpp \\\n \thwasan_poisoning.cpp \\\n \thwasan_report.cpp \\\n-\thwasan_setjmp.S \\\n+\thwasan_setjmp_aarch64.S \\\n+\thwasan_setjmp_x86_64.S \\\n \thwasan_tag_mismatch_aarch64.S \\\n \thwasan_thread.cpp \\\n \thwasan_thread_list.cpp \\\n@@ -570,7 +571,8 @@ distclean-compile:\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/hwasan_new_delete.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/hwasan_poisoning.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/hwasan_report.Plo@am__quote@\n-@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/hwasan_setjmp.Plo@am__quote@\n+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/hwasan_setjmp_aarch64.Plo@am__quote@\n+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/hwasan_setjmp_x86_64.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/hwasan_tag_mismatch_aarch64.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/hwasan_thread.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/hwasan_thread_list.Plo@am__quote@"}, {"sha": "465419022123fe916b40a67c7952b24dfdcce959", "filename": "libsanitizer/hwasan/hwasan.cpp", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -319,7 +319,7 @@ void __hwasan_init_static() {\n     InitializeSingleGlobal(global);\n }\n \n-void __hwasan_init() {\n+__attribute__((constructor(0))) void __hwasan_init() {\n   CHECK(!hwasan_init_is_running);\n   if (hwasan_inited) return;\n   hwasan_init_is_running = 1;\n@@ -360,6 +360,7 @@ void __hwasan_init() {\n   HwasanTSDThreadInit();\n \n   HwasanAllocatorInit();\n+  HwasanInstallAtForkHandler();\n \n #if HWASAN_CONTAINS_UBSAN\n   __ubsan::InitAsPlugin();"}, {"sha": "371c43f3cbde7fe3fa2690683214f00484242e57", "filename": "libsanitizer/hwasan/hwasan.h", "status": "modified", "additions": 19, "deletions": 6, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -107,6 +107,8 @@ void InitThreads();\n void InitializeInterceptors();\n \n void HwasanAllocatorInit();\n+void HwasanAllocatorLock();\n+void HwasanAllocatorUnlock();\n \n void *hwasan_malloc(uptr size, StackTrace *stack);\n void *hwasan_calloc(uptr nmemb, uptr size, StackTrace *stack);\n@@ -140,6 +142,8 @@ void HwasanAtExit();\n \n void HwasanOnDeadlySignal(int signo, void *info, void *context);\n \n+void HwasanInstallAtForkHandler();\n+\n void UpdateMemoryUsage();\n \n void AppendToErrorMessageBuffer(const char *buffer);\n@@ -183,25 +187,34 @@ void HwasanTagMismatch(uptr addr, uptr access_info, uptr *registers_frame,\n     RunFreeHooks(ptr);            \\\n   } while (false)\n \n-#if HWASAN_WITH_INTERCEPTORS && defined(__aarch64__)\n+#if HWASAN_WITH_INTERCEPTORS\n // For both bionic and glibc __sigset_t is an unsigned long.\n typedef unsigned long __hw_sigset_t;\n // Setjmp and longjmp implementations are platform specific, and hence the\n-// interception code is platform specific too.  As yet we've only implemented\n-// the interception for AArch64.\n-typedef unsigned long long __hw_register_buf[22];\n+// interception code is platform specific too.\n+#  if defined(__aarch64__)\n+constexpr size_t kHwRegisterBufSize = 22;\n+#  elif defined(__x86_64__)\n+constexpr size_t kHwRegisterBufSize = 8;\n+#  endif\n+typedef unsigned long long __hw_register_buf[kHwRegisterBufSize];\n struct __hw_jmp_buf_struct {\n   // NOTE: The machine-dependent definition of `__sigsetjmp'\n   // assume that a `__hw_jmp_buf' begins with a `__hw_register_buf' and that\n   // `__mask_was_saved' follows it.  Do not move these members or add others\n   // before it.\n+  //\n+  // We add a __magic field to our struct to catch cases where libc's setjmp\n+  // populated the jmp_buf instead of our interceptor.\n   __hw_register_buf __jmpbuf; // Calling environment.\n-  int __mask_was_saved;       // Saved the signal mask?\n+  unsigned __mask_was_saved : 1;  // Saved the signal mask?\n+  unsigned __magic : 31;      // Used to distinguish __hw_jmp_buf from jmp_buf.\n   __hw_sigset_t __saved_mask; // Saved signal mask.\n };\n typedef struct __hw_jmp_buf_struct __hw_jmp_buf[1];\n typedef struct __hw_jmp_buf_struct __hw_sigjmp_buf[1];\n-#endif // HWASAN_WITH_INTERCEPTORS && __aarch64__\n+constexpr unsigned kHwJmpBufMagic = 0x248ACE77;\n+#endif  // HWASAN_WITH_INTERCEPTORS\n \n #define ENSURE_HWASAN_INITED()      \\\n   do {                              \\"}, {"sha": "850daedd0b0ea959e7af2a644608b0152751c643", "filename": "libsanitizer/hwasan/hwasan_allocation_functions.cpp", "status": "modified", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_allocation_functions.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_allocation_functions.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_allocation_functions.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -17,6 +17,8 @@\n #include \"sanitizer_common/sanitizer_allocator_interface.h\"\n #include \"sanitizer_common/sanitizer_tls_get_addr.h\"\n \n+#if !SANITIZER_FUCHSIA\n+\n using namespace __hwasan;\n \n static uptr allocated_for_dlsym;\n@@ -36,23 +38,29 @@ static void *AllocateFromLocalPool(uptr size_in_bytes) {\n   return mem;\n }\n \n+extern \"C\" {\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n int __sanitizer_posix_memalign(void **memptr, uptr alignment, uptr size) {\n   GET_MALLOC_STACK_TRACE;\n   CHECK_NE(memptr, 0);\n   int res = hwasan_posix_memalign(memptr, alignment, size, &stack);\n   return res;\n }\n \n+SANITIZER_INTERFACE_ATTRIBUTE\n void *__sanitizer_memalign(uptr alignment, uptr size) {\n   GET_MALLOC_STACK_TRACE;\n   return hwasan_memalign(alignment, size, &stack);\n }\n \n+SANITIZER_INTERFACE_ATTRIBUTE\n void *__sanitizer_aligned_alloc(uptr alignment, uptr size) {\n   GET_MALLOC_STACK_TRACE;\n   return hwasan_aligned_alloc(alignment, size, &stack);\n }\n \n+SANITIZER_INTERFACE_ATTRIBUTE\n void *__sanitizer___libc_memalign(uptr alignment, uptr size) {\n   GET_MALLOC_STACK_TRACE;\n   void *ptr = hwasan_memalign(alignment, size, &stack);\n@@ -61,46 +69,55 @@ void *__sanitizer___libc_memalign(uptr alignment, uptr size) {\n   return ptr;\n }\n \n+SANITIZER_INTERFACE_ATTRIBUTE\n void *__sanitizer_valloc(uptr size) {\n   GET_MALLOC_STACK_TRACE;\n   return hwasan_valloc(size, &stack);\n }\n \n+SANITIZER_INTERFACE_ATTRIBUTE\n void *__sanitizer_pvalloc(uptr size) {\n   GET_MALLOC_STACK_TRACE;\n   return hwasan_pvalloc(size, &stack);\n }\n \n+SANITIZER_INTERFACE_ATTRIBUTE\n void __sanitizer_free(void *ptr) {\n   GET_MALLOC_STACK_TRACE;\n   if (!ptr || UNLIKELY(IsInDlsymAllocPool(ptr)))\n     return;\n   hwasan_free(ptr, &stack);\n }\n \n+SANITIZER_INTERFACE_ATTRIBUTE\n void __sanitizer_cfree(void *ptr) {\n   GET_MALLOC_STACK_TRACE;\n   if (!ptr || UNLIKELY(IsInDlsymAllocPool(ptr)))\n     return;\n   hwasan_free(ptr, &stack);\n }\n \n+SANITIZER_INTERFACE_ATTRIBUTE\n uptr __sanitizer_malloc_usable_size(const void *ptr) {\n   return __sanitizer_get_allocated_size(ptr);\n }\n \n+SANITIZER_INTERFACE_ATTRIBUTE\n struct __sanitizer_struct_mallinfo __sanitizer_mallinfo() {\n   __sanitizer_struct_mallinfo sret;\n   internal_memset(&sret, 0, sizeof(sret));\n   return sret;\n }\n \n+SANITIZER_INTERFACE_ATTRIBUTE\n int __sanitizer_mallopt(int cmd, int value) { return 0; }\n \n+SANITIZER_INTERFACE_ATTRIBUTE\n void __sanitizer_malloc_stats(void) {\n   // FIXME: implement, but don't call REAL(malloc_stats)!\n }\n \n+SANITIZER_INTERFACE_ATTRIBUTE\n void *__sanitizer_calloc(uptr nmemb, uptr size) {\n   GET_MALLOC_STACK_TRACE;\n   if (UNLIKELY(!hwasan_inited))\n@@ -109,6 +126,7 @@ void *__sanitizer_calloc(uptr nmemb, uptr size) {\n   return hwasan_calloc(nmemb, size, &stack);\n }\n \n+SANITIZER_INTERFACE_ATTRIBUTE\n void *__sanitizer_realloc(void *ptr, uptr size) {\n   GET_MALLOC_STACK_TRACE;\n   if (UNLIKELY(IsInDlsymAllocPool(ptr))) {\n@@ -127,11 +145,13 @@ void *__sanitizer_realloc(void *ptr, uptr size) {\n   return hwasan_realloc(ptr, size, &stack);\n }\n \n+SANITIZER_INTERFACE_ATTRIBUTE\n void *__sanitizer_reallocarray(void *ptr, uptr nmemb, uptr size) {\n   GET_MALLOC_STACK_TRACE;\n   return hwasan_reallocarray(ptr, nmemb, size, &stack);\n }\n \n+SANITIZER_INTERFACE_ATTRIBUTE\n void *__sanitizer_malloc(uptr size) {\n   GET_MALLOC_STACK_TRACE;\n   if (UNLIKELY(!hwasan_init_is_running))\n@@ -142,6 +162,8 @@ void *__sanitizer_malloc(uptr size) {\n   return hwasan_malloc(size, &stack);\n }\n \n+}  // extern \"C\"\n+\n #if HWASAN_WITH_INTERCEPTORS\n #  define INTERCEPTOR_ALIAS(RET, FN, ARGS...)                                 \\\n     extern \"C\" SANITIZER_INTERFACE_ATTRIBUTE RET WRAP(FN)(ARGS)               \\\n@@ -170,3 +192,5 @@ INTERCEPTOR_ALIAS(int, mallopt, int cmd, int value);\n INTERCEPTOR_ALIAS(void, malloc_stats, void);\n #  endif\n #endif  // #if HWASAN_WITH_INTERCEPTORS\n+\n+#endif  // SANITIZER_FUCHSIA"}, {"sha": "9e1729964e27703b0b0aeeeb7a6b06031b82490d", "filename": "libsanitizer/hwasan/hwasan_allocator.cpp", "status": "modified", "additions": 44, "deletions": 14, "changes": 58, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_allocator.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_allocator.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_allocator.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -107,6 +107,10 @@ void HwasanAllocatorInit() {\n     tail_magic[i] = GetCurrentThread()->GenerateRandomTag();\n }\n \n+void HwasanAllocatorLock() { allocator.ForceLock(); }\n+\n+void HwasanAllocatorUnlock() { allocator.ForceUnlock(); }\n+\n void AllocatorSwallowThreadLocalCache(AllocatorCache *cache) {\n   allocator.SwallowCache(cache);\n }\n@@ -158,8 +162,11 @@ static void *HwasanAllocate(StackTrace *stack, uptr orig_size, uptr alignment,\n     internal_memset(allocated, flags()->malloc_fill_byte, fill_size);\n   }\n   if (size != orig_size) {\n-    internal_memcpy(reinterpret_cast<u8 *>(allocated) + orig_size, tail_magic,\n-                    size - orig_size - 1);\n+    u8 *tail = reinterpret_cast<u8 *>(allocated) + orig_size;\n+    uptr tail_length = size - orig_size;\n+    internal_memcpy(tail, tail_magic, tail_length - 1);\n+    // Short granule is excluded from magic tail, so we explicitly untag.\n+    tail[tail_length - 1] = 0;\n   }\n \n   void *user_ptr = allocated;\n@@ -201,21 +208,37 @@ static bool PointerAndMemoryTagsMatch(void *tagged_ptr) {\n   return PossiblyShortTagMatches(mem_tag, tagged_uptr, 1);\n }\n \n+static bool CheckInvalidFree(StackTrace *stack, void *untagged_ptr,\n+                             void *tagged_ptr) {\n+  // This function can return true if halt_on_error is false.\n+  if (!MemIsApp(reinterpret_cast<uptr>(untagged_ptr)) ||\n+      !PointerAndMemoryTagsMatch(tagged_ptr)) {\n+    ReportInvalidFree(stack, reinterpret_cast<uptr>(tagged_ptr));\n+    return true;\n+  }\n+  return false;\n+}\n+\n static void HwasanDeallocate(StackTrace *stack, void *tagged_ptr) {\n   CHECK(tagged_ptr);\n   HWASAN_FREE_HOOK(tagged_ptr);\n \n-  if (!PointerAndMemoryTagsMatch(tagged_ptr))\n-    ReportInvalidFree(stack, reinterpret_cast<uptr>(tagged_ptr));\n+  bool in_taggable_region =\n+      InTaggableRegion(reinterpret_cast<uptr>(tagged_ptr));\n+  void *untagged_ptr = in_taggable_region ? UntagPtr(tagged_ptr) : tagged_ptr;\n+\n+  if (CheckInvalidFree(stack, untagged_ptr, tagged_ptr))\n+    return;\n \n-  void *untagged_ptr = InTaggableRegion(reinterpret_cast<uptr>(tagged_ptr))\n-                           ? UntagPtr(tagged_ptr)\n-                           : tagged_ptr;\n   void *aligned_ptr = reinterpret_cast<void *>(\n       RoundDownTo(reinterpret_cast<uptr>(untagged_ptr), kShadowAlignment));\n   tag_t pointer_tag = GetTagFromPointer(reinterpret_cast<uptr>(tagged_ptr));\n   Metadata *meta =\n       reinterpret_cast<Metadata *>(allocator.GetMetaData(aligned_ptr));\n+  if (!meta) {\n+    ReportInvalidFree(stack, reinterpret_cast<uptr>(tagged_ptr));\n+    return;\n+  }\n   uptr orig_size = meta->get_requested_size();\n   u32 free_context_id = StackDepotPut(*stack);\n   u32 alloc_context_id = meta->alloc_context_id;\n@@ -228,7 +251,11 @@ static void HwasanDeallocate(StackTrace *stack, void *tagged_ptr) {\n     CHECK_LT(tail_size, kShadowAlignment);\n     void *tail_beg = reinterpret_cast<void *>(\n         reinterpret_cast<uptr>(aligned_ptr) + orig_size);\n-    if (tail_size && internal_memcmp(tail_beg, tail_magic, tail_size))\n+    tag_t short_granule_memtag = *(reinterpret_cast<tag_t *>(\n+        reinterpret_cast<uptr>(tail_beg) + tail_size));\n+    if (tail_size &&\n+        (internal_memcmp(tail_beg, tail_magic, tail_size) ||\n+         (in_taggable_region && pointer_tag != short_granule_memtag)))\n       ReportTailOverwritten(stack, reinterpret_cast<uptr>(tagged_ptr),\n                             orig_size, tail_magic);\n   }\n@@ -243,8 +270,7 @@ static void HwasanDeallocate(StackTrace *stack, void *tagged_ptr) {\n         Min(TaggedSize(orig_size), (uptr)flags()->max_free_fill_size);\n     internal_memset(aligned_ptr, flags()->free_fill_byte, fill_size);\n   }\n-  if (InTaggableRegion(reinterpret_cast<uptr>(tagged_ptr)) &&\n-      flags()->tag_in_free && malloc_bisect(stack, 0) &&\n+  if (in_taggable_region && flags()->tag_in_free && malloc_bisect(stack, 0) &&\n       atomic_load_relaxed(&hwasan_allocator_tagging_enabled)) {\n     // Always store full 8-bit tags on free to maximize UAF detection.\n     tag_t tag;\n@@ -278,13 +304,15 @@ static void HwasanDeallocate(StackTrace *stack, void *tagged_ptr) {\n \n static void *HwasanReallocate(StackTrace *stack, void *tagged_ptr_old,\n                               uptr new_size, uptr alignment) {\n-  if (!PointerAndMemoryTagsMatch(tagged_ptr_old))\n-    ReportInvalidFree(stack, reinterpret_cast<uptr>(tagged_ptr_old));\n-\n+  void *untagged_ptr_old =\n+      InTaggableRegion(reinterpret_cast<uptr>(tagged_ptr_old))\n+          ? UntagPtr(tagged_ptr_old)\n+          : tagged_ptr_old;\n+  if (CheckInvalidFree(stack, untagged_ptr_old, tagged_ptr_old))\n+    return nullptr;\n   void *tagged_ptr_new =\n       HwasanAllocate(stack, new_size, alignment, false /*zeroise*/);\n   if (tagged_ptr_old && tagged_ptr_new) {\n-    void *untagged_ptr_old =  UntagPtr(tagged_ptr_old);\n     Metadata *meta =\n         reinterpret_cast<Metadata *>(allocator.GetMetaData(untagged_ptr_old));\n     internal_memcpy(\n@@ -305,6 +333,8 @@ static void *HwasanCalloc(StackTrace *stack, uptr nmemb, uptr size) {\n }\n \n HwasanChunkView FindHeapChunkByAddress(uptr address) {\n+  if (!allocator.PointerIsMine(reinterpret_cast<void *>(address)))\n+    return HwasanChunkView();\n   void *block = allocator.GetBlockBegin(reinterpret_cast<void*>(address));\n   if (!block)\n     return HwasanChunkView();"}, {"sha": "7642ba6c0bf08fddee2f820a2b4016b6deec0488", "filename": "libsanitizer/hwasan/hwasan_dynamic_shadow.cpp", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_dynamic_shadow.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_dynamic_shadow.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_dynamic_shadow.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -113,6 +113,15 @@ uptr FindDynamicShadowStart(uptr shadow_size_bytes) {\n }\n \n }  // namespace __hwasan\n+\n+#elif SANITIZER_FUCHSIA\n+\n+namespace __hwasan {\n+\n+void InitShadowGOT() {}\n+\n+}  // namespace __hwasan\n+\n #else\n namespace __hwasan {\n "}, {"sha": "f51e148197b91468055636c663c98e06d95533ee", "filename": "libsanitizer/hwasan/hwasan_fuchsia.cpp", "status": "modified", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_fuchsia.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_fuchsia.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_fuchsia.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -34,6 +34,15 @@ bool InitShadow() {\n   __sanitizer::InitShadowBounds();\n   CHECK_NE(__sanitizer::ShadowBounds.shadow_limit, 0);\n \n+  // These variables are used by MemIsShadow for asserting we have a correct\n+  // shadow address. On Fuchsia, we only have one region of shadow, so the\n+  // bounds of Low shadow can be zero while High shadow represents the true\n+  // bounds. Note that these are inclusive ranges.\n+  kLowShadowStart = 0;\n+  kLowShadowEnd = 0;\n+  kHighShadowStart = __sanitizer::ShadowBounds.shadow_base;\n+  kHighShadowEnd = __sanitizer::ShadowBounds.shadow_limit - 1;\n+\n   return true;\n }\n \n@@ -143,6 +152,14 @@ static void ThreadExitHook(void *hook, thrd_t self) {\n   hwasanThreadList().ReleaseThread(thread);\n }\n \n+uptr TagMemoryAligned(uptr p, uptr size, tag_t tag) {\n+  CHECK(IsAligned(p, kShadowAlignment));\n+  CHECK(IsAligned(size, kShadowAlignment));\n+  __sanitizer_fill_shadow(p, size, tag,\n+                          common_flags()->clear_shadow_mmap_threshold);\n+  return AddTagToPointer(p, tag);\n+}\n+\n // Not implemented because Fuchsia does not use signal handlers.\n void HwasanOnDeadlySignal(int signo, void *info, void *context) {}\n \n@@ -163,6 +180,12 @@ void HwasanTSDThreadInit() {}\n // function is unneeded.\n void InstallAtExitHandler() {}\n \n+void HwasanInstallAtForkHandler() {}\n+\n+// TODO(fxbug.dev/81499): Once we finalize the tagged pointer ABI in zircon, we should come back\n+// here and implement the appropriate check that TBI is enabled.\n+void InitializeOsSupport() {}\n+\n }  // namespace __hwasan\n \n extern \"C\" {"}, {"sha": "f96ed880410269e69854a4cc2b1c4814242f87cd", "filename": "libsanitizer/hwasan/hwasan_interceptors.cpp", "status": "modified", "additions": 48, "deletions": 22, "changes": 70, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_interceptors.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_interceptors.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_interceptors.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -49,15 +49,14 @@ INTERCEPTOR(int, pthread_create, void *th, void *attr, void *(*callback)(void*),\n \n DEFINE_REAL(int, vfork)\n DECLARE_EXTERN_INTERCEPTOR_AND_WRAPPER(int, vfork)\n-#endif // HWASAN_WITH_INTERCEPTORS\n \n-#if HWASAN_WITH_INTERCEPTORS && defined(__aarch64__)\n // Get and/or change the set of blocked signals.\n extern \"C\" int sigprocmask(int __how, const __hw_sigset_t *__restrict __set,\n                            __hw_sigset_t *__restrict __oset);\n #define SIG_BLOCK 0\n #define SIG_SETMASK 2\n extern \"C\" int __sigjmp_save(__hw_sigjmp_buf env, int savemask) {\n+  env[0].__magic = kHwJmpBufMagic;\n   env[0].__mask_was_saved =\n       (savemask && sigprocmask(SIG_BLOCK, (__hw_sigset_t *)0,\n                                &env[0].__saved_mask) == 0);\n@@ -66,8 +65,14 @@ extern \"C\" int __sigjmp_save(__hw_sigjmp_buf env, int savemask) {\n \n static void __attribute__((always_inline))\n InternalLongjmp(__hw_register_buf env, int retval) {\n+#    if defined(__aarch64__)\n+  constexpr size_t kSpIndex = 13;\n+#    elif defined(__x86_64__)\n+  constexpr size_t kSpIndex = 6;\n+#    endif\n+\n   // Clear all memory tags on the stack between here and where we're going.\n-  unsigned long long stack_pointer = env[13];\n+  unsigned long long stack_pointer = env[kSpIndex];\n   // The stack pointer should never be tagged, so we don't need to clear the\n   // tag for this function call.\n   __hwasan_handle_longjmp((void *)stack_pointer);\n@@ -78,6 +83,7 @@ InternalLongjmp(__hw_register_buf env, int retval) {\n   // Must implement this ourselves, since we don't know the order of registers\n   // in different libc implementations and many implementations mangle the\n   // stack pointer so we can't use it without knowing the demangling scheme.\n+#    if defined(__aarch64__)\n   register long int retval_tmp asm(\"x1\") = retval;\n   register void *env_address asm(\"x0\") = &env[0];\n   asm volatile(\"ldp\tx19, x20, [%0, #0<<3];\"\n@@ -100,9 +106,36 @@ InternalLongjmp(__hw_register_buf env, int retval) {\n                \"br\tx30;\"\n                : \"+r\"(env_address)\n                : \"r\"(retval_tmp));\n+#    elif defined(__x86_64__)\n+  register long int retval_tmp asm(\"%rsi\") = retval;\n+  register void *env_address asm(\"%rdi\") = &env[0];\n+  asm volatile(\n+      // Restore registers.\n+      \"mov (0*8)(%0),%%rbx;\"\n+      \"mov (1*8)(%0),%%rbp;\"\n+      \"mov (2*8)(%0),%%r12;\"\n+      \"mov (3*8)(%0),%%r13;\"\n+      \"mov (4*8)(%0),%%r14;\"\n+      \"mov (5*8)(%0),%%r15;\"\n+      \"mov (6*8)(%0),%%rsp;\"\n+      \"mov (7*8)(%0),%%rdx;\"\n+      // Return 1 if retval is 0.\n+      \"mov $1,%%rax;\"\n+      \"test %1,%1;\"\n+      \"cmovnz %1,%%rax;\"\n+      \"jmp *%%rdx;\" ::\"r\"(env_address),\n+      \"r\"(retval_tmp));\n+#    endif\n }\n \n INTERCEPTOR(void, siglongjmp, __hw_sigjmp_buf env, int val) {\n+  if (env[0].__magic != kHwJmpBufMagic) {\n+    Printf(\n+        \"WARNING: Unexpected bad jmp_buf. Either setjmp was not called or \"\n+        \"there is a bug in HWASan.\\n\");\n+    return REAL(siglongjmp)(env, val);\n+  }\n+\n   if (env[0].__mask_was_saved)\n     // Restore the saved signal mask.\n     (void)sigprocmask(SIG_SETMASK, &env[0].__saved_mask,\n@@ -114,32 +147,24 @@ INTERCEPTOR(void, siglongjmp, __hw_sigjmp_buf env, int val) {\n // _setjmp on start_thread.  Hence we have to intercept the longjmp on\n // pthread_exit so the __hw_jmp_buf order matches.\n INTERCEPTOR(void, __libc_longjmp, __hw_jmp_buf env, int val) {\n+  if (env[0].__magic != kHwJmpBufMagic)\n+    return REAL(__libc_longjmp)(env, val);\n   InternalLongjmp(env[0].__jmpbuf, val);\n }\n \n INTERCEPTOR(void, longjmp, __hw_jmp_buf env, int val) {\n+  if (env[0].__magic != kHwJmpBufMagic) {\n+    Printf(\n+        \"WARNING: Unexpected bad jmp_buf. Either setjmp was not called or \"\n+        \"there is a bug in HWASan.\\n\");\n+    return REAL(longjmp)(env, val);\n+  }\n   InternalLongjmp(env[0].__jmpbuf, val);\n }\n #undef SIG_BLOCK\n #undef SIG_SETMASK\n \n-#endif // HWASAN_WITH_INTERCEPTORS && __aarch64__\n-\n-static void BeforeFork() {\n-  StackDepotLockAll();\n-}\n-\n-static void AfterFork() {\n-  StackDepotUnlockAll();\n-}\n-\n-INTERCEPTOR(int, fork, void) {\n-  ENSURE_HWASAN_INITED();\n-  BeforeFork();\n-  int pid = REAL(fork)();\n-  AfterFork();\n-  return pid;\n-}\n+#  endif  // HWASAN_WITH_INTERCEPTORS\n \n namespace __hwasan {\n \n@@ -156,10 +181,11 @@ void InitializeInterceptors() {\n   static int inited = 0;\n   CHECK_EQ(inited, 0);\n \n-  INTERCEPT_FUNCTION(fork);\n-\n #if HWASAN_WITH_INTERCEPTORS\n #if defined(__linux__)\n+  INTERCEPT_FUNCTION(__libc_longjmp);\n+  INTERCEPT_FUNCTION(longjmp);\n+  INTERCEPT_FUNCTION(siglongjmp);\n   INTERCEPT_FUNCTION(vfork);\n #endif  // __linux__\n   INTERCEPT_FUNCTION(pthread_create);"}, {"sha": "ef771add411c9cc2d064c7f408c403b02073fc74", "filename": "libsanitizer/hwasan/hwasan_interface_internal.h", "status": "modified", "additions": 0, "deletions": 48, "changes": 48, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_interface_internal.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_interface_internal.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_interface_internal.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -168,54 +168,6 @@ void __hwasan_thread_exit();\n SANITIZER_INTERFACE_ATTRIBUTE\n void __hwasan_print_memory_usage();\n \n-SANITIZER_INTERFACE_ATTRIBUTE\n-int __sanitizer_posix_memalign(void **memptr, uptr alignment, uptr size);\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-void * __sanitizer_memalign(uptr alignment, uptr size);\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-void * __sanitizer_aligned_alloc(uptr alignment, uptr size);\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-void * __sanitizer___libc_memalign(uptr alignment, uptr size);\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-void * __sanitizer_valloc(uptr size);\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-void * __sanitizer_pvalloc(uptr size);\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-void __sanitizer_free(void *ptr);\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-void __sanitizer_cfree(void *ptr);\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-uptr __sanitizer_malloc_usable_size(const void *ptr);\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-__hwasan::__sanitizer_struct_mallinfo __sanitizer_mallinfo();\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-int __sanitizer_mallopt(int cmd, int value);\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-void __sanitizer_malloc_stats(void);\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-void * __sanitizer_calloc(uptr nmemb, uptr size);\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-void * __sanitizer_realloc(void *ptr, uptr size);\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-void * __sanitizer_reallocarray(void *ptr, uptr nmemb, uptr size);\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-void * __sanitizer_malloc(uptr size);\n-\n SANITIZER_INTERFACE_ATTRIBUTE\n void *__hwasan_memcpy(void *dst, const void *src, uptr size);\n SANITIZER_INTERFACE_ATTRIBUTE"}, {"sha": "a86ec28507f305b2eea76694b28ee7b2fbbf04b3", "filename": "libsanitizer/hwasan/hwasan_linux.cpp", "status": "modified", "additions": 77, "deletions": 70, "changes": 147, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_linux.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_linux.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_linux.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -15,30 +15,30 @@\n #include \"sanitizer_common/sanitizer_platform.h\"\n #if SANITIZER_FREEBSD || SANITIZER_LINUX || SANITIZER_NETBSD\n \n-#include \"hwasan.h\"\n-#include \"hwasan_dynamic_shadow.h\"\n-#include \"hwasan_interface_internal.h\"\n-#include \"hwasan_mapping.h\"\n-#include \"hwasan_report.h\"\n-#include \"hwasan_thread.h\"\n-#include \"hwasan_thread_list.h\"\n-\n-#include <dlfcn.h>\n-#include <elf.h>\n-#include <link.h>\n-#include <pthread.h>\n-#include <signal.h>\n-#include <stdio.h>\n-#include <stdlib.h>\n-#include <sys/resource.h>\n-#include <sys/time.h>\n-#include <unistd.h>\n-#include <unwind.h>\n-#include <sys/prctl.h>\n-#include <errno.h>\n-\n-#include \"sanitizer_common/sanitizer_common.h\"\n-#include \"sanitizer_common/sanitizer_procmaps.h\"\n+#  include <dlfcn.h>\n+#  include <elf.h>\n+#  include <errno.h>\n+#  include <link.h>\n+#  include <pthread.h>\n+#  include <signal.h>\n+#  include <stdio.h>\n+#  include <stdlib.h>\n+#  include <sys/prctl.h>\n+#  include <sys/resource.h>\n+#  include <sys/time.h>\n+#  include <unistd.h>\n+#  include <unwind.h>\n+\n+#  include \"hwasan.h\"\n+#  include \"hwasan_dynamic_shadow.h\"\n+#  include \"hwasan_interface_internal.h\"\n+#  include \"hwasan_mapping.h\"\n+#  include \"hwasan_report.h\"\n+#  include \"hwasan_thread.h\"\n+#  include \"hwasan_thread_list.h\"\n+#  include \"sanitizer_common/sanitizer_common.h\"\n+#  include \"sanitizer_common/sanitizer_procmaps.h\"\n+#  include \"sanitizer_common/sanitizer_stackdepot.h\"\n \n // Configurations of HWASAN_WITH_INTERCEPTORS and SANITIZER_ANDROID.\n //\n@@ -50,10 +50,10 @@\n //    Tested with check-hwasan on x86_64-linux.\n // HWASAN_WITH_INTERCEPTORS=ON, SANITIZER_ANDROID=ON\n //    Tested with check-hwasan on aarch64-linux-android.\n-#if !SANITIZER_ANDROID\n+#  if !SANITIZER_ANDROID\n SANITIZER_INTERFACE_ATTRIBUTE\n THREADLOCAL uptr __hwasan_tls;\n-#endif\n+#  endif\n \n namespace __hwasan {\n \n@@ -111,9 +111,9 @@ static void InitializeShadowBaseAddress(uptr shadow_size_bytes) {\n }\n \n void InitializeOsSupport() {\n-#define PR_SET_TAGGED_ADDR_CTRL 55\n-#define PR_GET_TAGGED_ADDR_CTRL 56\n-#define PR_TAGGED_ADDR_ENABLE (1UL << 0)\n+#  define PR_SET_TAGGED_ADDR_CTRL 55\n+#  define PR_GET_TAGGED_ADDR_CTRL 56\n+#  define PR_TAGGED_ADDR_ENABLE (1UL << 0)\n   // Check we're running on a kernel that can use the tagged address ABI.\n   int local_errno = 0;\n   if (internal_iserror(internal_prctl(PR_GET_TAGGED_ADDR_CTRL, 0, 0, 0, 0),\n@@ -164,9 +164,9 @@ void InitializeOsSupport() {\n       Die();\n     }\n   }\n-#undef PR_SET_TAGGED_ADDR_CTRL\n-#undef PR_GET_TAGGED_ADDR_CTRL\n-#undef PR_TAGGED_ADDR_ENABLE\n+#  undef PR_SET_TAGGED_ADDR_CTRL\n+#  undef PR_GET_TAGGED_ADDR_CTRL\n+#  undef PR_TAGGED_ADDR_ENABLE\n }\n \n bool InitShadow() {\n@@ -241,12 +241,11 @@ bool MemIsApp(uptr p) {\n   CHECK(GetTagFromPointer(p) == 0);\n #  endif\n \n-  return p >= kHighMemStart || (p >= kLowMemStart && p <= kLowMemEnd);\n+  return (p >= kHighMemStart && p <= kHighMemEnd) ||\n+         (p >= kLowMemStart && p <= kLowMemEnd);\n }\n \n-void InstallAtExitHandler() {\n-  atexit(HwasanAtExit);\n-}\n+void InstallAtExitHandler() { atexit(HwasanAtExit); }\n \n // ---------------------- TSD ---------------- {{{1\n \n@@ -262,7 +261,7 @@ extern \"C\" void __hwasan_thread_exit() {\n     hwasanThreadList().ReleaseThread(t);\n }\n \n-#if HWASAN_WITH_INTERCEPTORS\n+#  if HWASAN_WITH_INTERCEPTORS\n static pthread_key_t tsd_key;\n static bool tsd_key_inited = false;\n \n@@ -286,22 +285,18 @@ void HwasanTSDInit() {\n   tsd_key_inited = true;\n   CHECK_EQ(0, pthread_key_create(&tsd_key, HwasanTSDDtor));\n }\n-#else\n+#  else\n void HwasanTSDInit() {}\n void HwasanTSDThreadInit() {}\n-#endif\n+#  endif\n \n-#if SANITIZER_ANDROID\n-uptr *GetCurrentThreadLongPtr() {\n-  return (uptr *)get_android_tls_ptr();\n-}\n-#else\n-uptr *GetCurrentThreadLongPtr() {\n-  return &__hwasan_tls;\n-}\n-#endif\n+#  if SANITIZER_ANDROID\n+uptr *GetCurrentThreadLongPtr() { return (uptr *)get_android_tls_ptr(); }\n+#  else\n+uptr *GetCurrentThreadLongPtr() { return &__hwasan_tls; }\n+#  endif\n \n-#if SANITIZER_ANDROID\n+#  if SANITIZER_ANDROID\n void AndroidTestTlsSlot() {\n   uptr kMagicValue = 0x010203040A0B0C0D;\n   uptr *tls_ptr = GetCurrentThreadLongPtr();\n@@ -316,56 +311,56 @@ void AndroidTestTlsSlot() {\n   }\n   *tls_ptr = old_value;\n }\n-#else\n+#  else\n void AndroidTestTlsSlot() {}\n-#endif\n+#  endif\n \n static AccessInfo GetAccessInfo(siginfo_t *info, ucontext_t *uc) {\n   // Access type is passed in a platform dependent way (see below) and encoded\n   // as 0xXY, where X&1 is 1 for store, 0 for load, and X&2 is 1 if the error is\n   // recoverable. Valid values of Y are 0 to 4, which are interpreted as\n   // log2(access_size), and 0xF, which means that access size is passed via\n   // platform dependent register (see below).\n-#if defined(__aarch64__)\n+#  if defined(__aarch64__)\n   // Access type is encoded in BRK immediate as 0x900 + 0xXY. For Y == 0xF,\n   // access size is stored in X1 register. Access address is always in X0\n   // register.\n   uptr pc = (uptr)info->si_addr;\n   const unsigned code = ((*(u32 *)pc) >> 5) & 0xffff;\n   if ((code & 0xff00) != 0x900)\n-    return AccessInfo{}; // Not ours.\n+    return AccessInfo{};  // Not ours.\n \n   const bool is_store = code & 0x10;\n   const bool recover = code & 0x20;\n   const uptr addr = uc->uc_mcontext.regs[0];\n   const unsigned size_log = code & 0xf;\n   if (size_log > 4 && size_log != 0xf)\n-    return AccessInfo{}; // Not ours.\n+    return AccessInfo{};  // Not ours.\n   const uptr size = size_log == 0xf ? uc->uc_mcontext.regs[1] : 1U << size_log;\n \n-#elif defined(__x86_64__)\n+#  elif defined(__x86_64__)\n   // Access type is encoded in the instruction following INT3 as\n   // NOP DWORD ptr [EAX + 0x40 + 0xXY]. For Y == 0xF, access size is stored in\n   // RSI register. Access address is always in RDI register.\n   uptr pc = (uptr)uc->uc_mcontext.gregs[REG_RIP];\n-  uint8_t *nop = (uint8_t*)pc;\n-  if (*nop != 0x0f || *(nop + 1) != 0x1f || *(nop + 2) != 0x40  ||\n+  uint8_t *nop = (uint8_t *)pc;\n+  if (*nop != 0x0f || *(nop + 1) != 0x1f || *(nop + 2) != 0x40 ||\n       *(nop + 3) < 0x40)\n-    return AccessInfo{}; // Not ours.\n+    return AccessInfo{};  // Not ours.\n   const unsigned code = *(nop + 3);\n \n   const bool is_store = code & 0x10;\n   const bool recover = code & 0x20;\n   const uptr addr = uc->uc_mcontext.gregs[REG_RDI];\n   const unsigned size_log = code & 0xf;\n   if (size_log > 4 && size_log != 0xf)\n-    return AccessInfo{}; // Not ours.\n+    return AccessInfo{};  // Not ours.\n   const uptr size =\n       size_log == 0xf ? uc->uc_mcontext.gregs[REG_RSI] : 1U << size_log;\n \n-#else\n-# error Unsupported architecture\n-#endif\n+#  else\n+#    error Unsupported architecture\n+#  endif\n \n   return AccessInfo{addr, size, is_store, !is_store, recover};\n }\n@@ -378,12 +373,12 @@ static bool HwasanOnSIGTRAP(int signo, siginfo_t *info, ucontext_t *uc) {\n   SignalContext sig{info, uc};\n   HandleTagMismatch(ai, StackTrace::GetNextInstructionPc(sig.pc), sig.bp, uc);\n \n-#if defined(__aarch64__)\n+#  if defined(__aarch64__)\n   uc->uc_mcontext.pc += 4;\n-#elif defined(__x86_64__)\n-#else\n-# error Unsupported architecture\n-#endif\n+#  elif defined(__x86_64__)\n+#  else\n+#    error Unsupported architecture\n+#  endif\n   return true;\n }\n \n@@ -396,7 +391,7 @@ static void OnStackUnwind(const SignalContext &sig, const void *,\n void HwasanOnDeadlySignal(int signo, void *info, void *context) {\n   // Probably a tag mismatch.\n   if (signo == SIGTRAP)\n-    if (HwasanOnSIGTRAP(signo, (siginfo_t *)info, (ucontext_t*)context))\n+    if (HwasanOnSIGTRAP(signo, (siginfo_t *)info, (ucontext_t *)context))\n       return;\n \n   HandleDeadlySignal(info, context, GetTid(), &OnStackUnwind, nullptr);\n@@ -435,6 +430,18 @@ uptr TagMemoryAligned(uptr p, uptr size, tag_t tag) {\n   return AddTagToPointer(p, tag);\n }\n \n-} // namespace __hwasan\n+void HwasanInstallAtForkHandler() {\n+  auto before = []() {\n+    HwasanAllocatorLock();\n+    StackDepotLockAll();\n+  };\n+  auto after = []() {\n+    StackDepotUnlockAll();\n+    HwasanAllocatorUnlock();\n+  };\n+  pthread_atfork(before, after, after);\n+}\n+\n+}  // namespace __hwasan\n \n-#endif // SANITIZER_FREEBSD || SANITIZER_LINUX || SANITIZER_NETBSD\n+#endif  // SANITIZER_FREEBSD || SANITIZER_LINUX || SANITIZER_NETBSD"}, {"sha": "9b3b661b74bdf3ee973d3af418e4ef388af3782d", "filename": "libsanitizer/hwasan/hwasan_report.cpp", "status": "modified", "additions": 59, "deletions": 23, "changes": 82, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_report.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_report.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_report.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -37,15 +37,15 @@ namespace __hwasan {\n class ScopedReport {\n  public:\n   ScopedReport(bool fatal = false) : error_message_(1), fatal(fatal) {\n-    BlockingMutexLock lock(&error_message_lock_);\n+    Lock lock(&error_message_lock_);\n     error_message_ptr_ = fatal ? &error_message_ : nullptr;\n     ++hwasan_report_count;\n   }\n \n   ~ScopedReport() {\n     void (*report_cb)(const char *);\n     {\n-      BlockingMutexLock lock(&error_message_lock_);\n+      Lock lock(&error_message_lock_);\n       report_cb = error_report_callback_;\n       error_message_ptr_ = nullptr;\n     }\n@@ -61,7 +61,7 @@ class ScopedReport {\n   }\n \n   static void MaybeAppendToErrorMessage(const char *msg) {\n-    BlockingMutexLock lock(&error_message_lock_);\n+    Lock lock(&error_message_lock_);\n     if (!error_message_ptr_)\n       return;\n     uptr len = internal_strlen(msg);\n@@ -72,7 +72,7 @@ class ScopedReport {\n   }\n \n   static void SetErrorReportCallback(void (*callback)(const char *)) {\n-    BlockingMutexLock lock(&error_message_lock_);\n+    Lock lock(&error_message_lock_);\n     error_report_callback_ = callback;\n   }\n \n@@ -82,12 +82,12 @@ class ScopedReport {\n   bool fatal;\n \n   static InternalMmapVector<char> *error_message_ptr_;\n-  static BlockingMutex error_message_lock_;\n+  static Mutex error_message_lock_;\n   static void (*error_report_callback_)(const char *);\n };\n \n InternalMmapVector<char> *ScopedReport::error_message_ptr_;\n-BlockingMutex ScopedReport::error_message_lock_;\n+Mutex ScopedReport::error_message_lock_;\n void (*ScopedReport::error_report_callback_)(const char *);\n \n // If there is an active ScopedReport, append to its error message.\n@@ -351,14 +351,16 @@ static void ShowHeapOrGlobalCandidate(uptr untagged_addr, tag_t *candidate,\n       uptr size = GetGlobalSizeFromDescriptor(mem);\n       if (size == 0)\n         // We couldn't find the size of the global from the descriptors.\n-        Printf(\"%p is located to the %s of a global variable in (%s+0x%x)\\n\",\n-               untagged_addr, candidate == left ? \"right\" : \"left\", module_name,\n-               module_address);\n+        Printf(\n+            \"%p is located to the %s of a global variable in \"\n+            \"\\n    #0 0x%x (%s+0x%x)\\n\",\n+            untagged_addr, candidate == left ? \"right\" : \"left\", mem,\n+            module_name, module_address);\n       else\n         Printf(\n             \"%p is located to the %s of a %zd-byte global variable in \"\n-            \"(%s+0x%x)\\n\",\n-            untagged_addr, candidate == left ? \"right\" : \"left\", size,\n+            \"\\n    #0 0x%x (%s+0x%x)\\n\",\n+            untagged_addr, candidate == left ? \"right\" : \"left\", size, mem,\n             module_name, module_address);\n     }\n     Printf(\"%s\", d.Default());\n@@ -372,6 +374,12 @@ void PrintAddressDescription(\n   int num_descriptions_printed = 0;\n   uptr untagged_addr = UntagAddr(tagged_addr);\n \n+  if (MemIsShadow(untagged_addr)) {\n+    Printf(\"%s%p is HWAsan shadow memory.\\n%s\", d.Location(), untagged_addr,\n+           d.Default());\n+    return;\n+  }\n+\n   // Print some very basic information about the address, if it's a heap.\n   HwasanChunkView chunk = FindHeapChunkByAddress(untagged_addr);\n   if (uptr beg = chunk.Beg()) {\n@@ -549,35 +557,64 @@ static void PrintTagsAroundAddr(tag_t *tag_ptr) {\n       \"description of short granule tags\\n\");\n }\n \n+uptr GetTopPc(StackTrace *stack) {\n+  return stack->size ? StackTrace::GetPreviousInstructionPc(stack->trace[0])\n+                     : 0;\n+}\n+\n void ReportInvalidFree(StackTrace *stack, uptr tagged_addr) {\n   ScopedReport R(flags()->halt_on_error);\n \n   uptr untagged_addr = UntagAddr(tagged_addr);\n   tag_t ptr_tag = GetTagFromPointer(tagged_addr);\n-  tag_t *tag_ptr = reinterpret_cast<tag_t*>(MemToShadow(untagged_addr));\n-  tag_t mem_tag = *tag_ptr;\n+  tag_t *tag_ptr = nullptr;\n+  tag_t mem_tag = 0;\n+  if (MemIsApp(untagged_addr)) {\n+    tag_ptr = reinterpret_cast<tag_t *>(MemToShadow(untagged_addr));\n+    if (MemIsShadow(reinterpret_cast<uptr>(tag_ptr)))\n+      mem_tag = *tag_ptr;\n+    else\n+      tag_ptr = nullptr;\n+  }\n   Decorator d;\n   Printf(\"%s\", d.Error());\n-  uptr pc = stack->size ? stack->trace[0] : 0;\n+  uptr pc = GetTopPc(stack);\n   const char *bug_type = \"invalid-free\";\n-  Report(\"ERROR: %s: %s on address %p at pc %p\\n\", SanitizerToolName, bug_type,\n-         untagged_addr, pc);\n+  const Thread *thread = GetCurrentThread();\n+  if (thread) {\n+    Report(\"ERROR: %s: %s on address %p at pc %p on thread T%zd\\n\",\n+           SanitizerToolName, bug_type, untagged_addr, pc, thread->unique_id());\n+  } else {\n+    Report(\"ERROR: %s: %s on address %p at pc %p on unknown thread\\n\",\n+           SanitizerToolName, bug_type, untagged_addr, pc);\n+  }\n   Printf(\"%s\", d.Access());\n-  Printf(\"tags: %02x/%02x (ptr/mem)\\n\", ptr_tag, mem_tag);\n+  if (tag_ptr)\n+    Printf(\"tags: %02x/%02x (ptr/mem)\\n\", ptr_tag, mem_tag);\n   Printf(\"%s\", d.Default());\n \n   stack->Print();\n \n   PrintAddressDescription(tagged_addr, 0, nullptr);\n \n-  PrintTagsAroundAddr(tag_ptr);\n+  if (tag_ptr)\n+    PrintTagsAroundAddr(tag_ptr);\n \n   ReportErrorSummary(bug_type, stack);\n }\n \n void ReportTailOverwritten(StackTrace *stack, uptr tagged_addr, uptr orig_size,\n                            const u8 *expected) {\n   uptr tail_size = kShadowAlignment - (orig_size % kShadowAlignment);\n+  u8 actual_expected[kShadowAlignment];\n+  internal_memcpy(actual_expected, expected, tail_size);\n+  tag_t ptr_tag = GetTagFromPointer(tagged_addr);\n+  // Short granule is stashed in the last byte of the magic string. To avoid\n+  // confusion, make the expected magic string contain the short granule tag.\n+  if (orig_size % kShadowAlignment != 0) {\n+    actual_expected[tail_size - 1] = ptr_tag;\n+  }\n+\n   ScopedReport R(flags()->halt_on_error);\n   Decorator d;\n   uptr untagged_addr = UntagAddr(tagged_addr);\n@@ -614,14 +651,13 @@ void ReportTailOverwritten(StackTrace *stack, uptr tagged_addr, uptr orig_size,\n   s.append(\"Expected:      \");\n   for (uptr i = 0; i < kShadowAlignment - tail_size; i++)\n     s.append(\".. \");\n-  for (uptr i = 0; i < tail_size; i++)\n-    s.append(\"%02x \", expected[i]);\n+  for (uptr i = 0; i < tail_size; i++) s.append(\"%02x \", actual_expected[i]);\n   s.append(\"\\n\");\n   s.append(\"               \");\n   for (uptr i = 0; i < kShadowAlignment - tail_size; i++)\n     s.append(\"   \");\n   for (uptr i = 0; i < tail_size; i++)\n-    s.append(\"%s \", expected[i] != tail[i] ? \"^^\" : \"  \");\n+    s.append(\"%s \", actual_expected[i] != tail[i] ? \"^^\" : \"  \");\n \n   s.append(\"\\nThis error occurs when a buffer overflow overwrites memory\\n\"\n     \"to the right of a heap object, but within the %zd-byte granule, e.g.\\n\"\n@@ -647,11 +683,11 @@ void ReportTagMismatch(StackTrace *stack, uptr tagged_addr, uptr access_size,\n       GetCurrentThread()->stack_allocations());\n \n   Decorator d;\n-  Printf(\"%s\", d.Error());\n   uptr untagged_addr = UntagAddr(tagged_addr);\n   // TODO: when possible, try to print heap-use-after-free, etc.\n   const char *bug_type = \"tag-mismatch\";\n-  uptr pc = stack->size ? stack->trace[0] : 0;\n+  uptr pc = GetTopPc(stack);\n+  Printf(\"%s\", d.Error());\n   Report(\"ERROR: %s: %s on address %p at pc %p\\n\", SanitizerToolName, bug_type,\n          untagged_addr, pc);\n "}, {"sha": "744748a5101f5e37d72216c79dddadd3d37612bd", "filename": "libsanitizer/hwasan/hwasan_setjmp_aarch64.S", "status": "renamed", "additions": 8, "deletions": 13, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_setjmp_aarch64.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_setjmp_aarch64.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_setjmp_aarch64.S?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -1,4 +1,4 @@\n-//===-- hwasan_setjmp.S --------------------------------------------------------===//\n+//===-- hwasan_setjmp_aarch64.S -------------------------------------------===//\n //\n // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n // See https://llvm.org/LICENSE.txt for license information.\n@@ -29,7 +29,7 @@\n // Hence we have to write this function in assembly.\n \n .section .text\n-.file \"hwasan_setjmp.S\"\n+.file \"hwasan_setjmp_aarch64.S\"\n \n .global __interceptor_setjmp\n ASM_TYPE_FUNCTION(__interceptor_setjmp)\n@@ -80,24 +80,19 @@ __interceptor_sigsetjmp:\n ASM_SIZE(__interceptor_sigsetjmp)\n \n \n-.macro ALIAS first second\n-  .globl \\second\n+.macro WEAK_ALIAS first second\n+  .weak \\second\n   .equ \\second\\(), \\first\n .endm\n \n #if SANITIZER_ANDROID\n-ALIAS __interceptor_sigsetjmp, sigsetjmp\n-.weak sigsetjmp\n-\n-ALIAS __interceptor_setjmp_bionic, setjmp\n-.weak setjmp\n+WEAK_ALIAS __interceptor_sigsetjmp, sigsetjmp\n+WEAK_ALIAS __interceptor_setjmp_bionic, setjmp\n #else\n-ALIAS __interceptor_sigsetjmp, __sigsetjmp\n-.weak __sigsetjmp\n+WEAK_ALIAS __interceptor_sigsetjmp, __sigsetjmp\n #endif\n \n-ALIAS __interceptor_setjmp, _setjmp\n-.weak _setjmp\n+WEAK_ALIAS __interceptor_setjmp, _setjmp\n #endif\n \n // We do not need executable stack.", "previous_filename": "libsanitizer/hwasan/hwasan_setjmp.S"}, {"sha": "84512d10b238a5c712c9a5d5a3f6c22e693e662f", "filename": "libsanitizer/hwasan/hwasan_setjmp_x86_64.S", "status": "added", "additions": 80, "deletions": 0, "changes": 80, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_setjmp_x86_64.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_setjmp_x86_64.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_setjmp_x86_64.S?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -0,0 +1,80 @@\n+//===-- hwasan_setjmp_x86_64.S --------------------------------------------===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// setjmp interceptor for x86_64.\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#include \"sanitizer_common/sanitizer_asm.h\"\n+\n+#if HWASAN_WITH_INTERCEPTORS && defined(__x86_64__)\n+#include \"sanitizer_common/sanitizer_platform.h\"\n+\n+// We want to save the context of the calling function.\n+// That requires\n+// 1) No modification of the return address by this function.\n+// 2) No modification of the stack pointer by this function.\n+// 3) (no modification of any other saved register, but that's not really going\n+// to occur, and hence isn't as much of a worry).\n+//\n+// There's essentially no way to ensure that the compiler will not modify the\n+// stack pointer when compiling a C function.\n+// Hence we have to write this function in assembly.\n+//\n+// TODO: Handle Intel CET.\n+\n+.section .text\n+.file \"hwasan_setjmp_x86_64.S\"\n+\n+.global __interceptor_setjmp\n+ASM_TYPE_FUNCTION(__interceptor_setjmp)\n+__interceptor_setjmp:\n+  CFI_STARTPROC\n+  xorl %esi, %esi\n+  jmp\t__interceptor_sigsetjmp\n+  CFI_ENDPROC\n+ASM_SIZE(__interceptor_setjmp)\n+\n+.global __interceptor_sigsetjmp\n+ASM_TYPE_FUNCTION(__interceptor_sigsetjmp)\n+__interceptor_sigsetjmp:\n+  CFI_STARTPROC\n+\n+  // Save callee save registers.\n+  mov %rbx, (0*8)(%rdi)\n+  mov %rbp, (1*8)(%rdi)\n+  mov %r12, (2*8)(%rdi)\n+  mov %r13, (3*8)(%rdi)\n+  mov %r14, (4*8)(%rdi)\n+  mov %r15, (5*8)(%rdi)\n+\n+  // Save SP as it was in caller's frame.\n+  lea 8(%rsp), %rdx\n+  mov %rdx, (6*8)(%rdi)\n+\n+  // Save return address.\n+  mov (%rsp), %rax\n+  mov %rax, (7*8)(%rdi)\n+\n+  jmp __sigjmp_save\n+\n+  CFI_ENDPROC\n+ASM_SIZE(__interceptor_sigsetjmp)\n+\n+\n+.macro WEAK_ALIAS first second\n+  .weak \\second\n+  .equ \\second\\(), \\first\n+.endm\n+\n+WEAK_ALIAS __interceptor_sigsetjmp, __sigsetjmp\n+WEAK_ALIAS __interceptor_setjmp, _setjmp\n+#endif\n+\n+// We do not need executable stack.\n+NO_EXEC_STACK_DIRECTIVE"}, {"sha": "5b65718c4d3b2587354df9e289153303ad2137b9", "filename": "libsanitizer/hwasan/hwasan_thread.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_thread.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_thread.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_thread.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -45,13 +45,13 @@ void Thread::Init(uptr stack_buffer_start, uptr stack_buffer_size,\n   if (auto sz = flags()->heap_history_size)\n     heap_allocations_ = HeapAllocationsRingBuffer::New(sz);\n \n-  InitStackAndTls(state);\n #if !SANITIZER_FUCHSIA\n   // Do not initialize the stack ring buffer just yet on Fuchsia. Threads will\n   // be initialized before we enter the thread itself, so we will instead call\n   // this later.\n   InitStackRingBuffer(stack_buffer_start, stack_buffer_size);\n #endif\n+  InitStackAndTls(state);\n }\n \n void Thread::InitStackRingBuffer(uptr stack_buffer_start,"}, {"sha": "5307073fb40b64220d8f2ec92519678ad2789521", "filename": "libsanitizer/hwasan/hwasan_type_test.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_type_test.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fhwasan%2Fhwasan_type_test.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fhwasan%2Fhwasan_type_test.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -19,7 +19,7 @@\n #define CHECK_TYPE_SIZE_FITS(TYPE) \\\n   COMPILER_CHECK(sizeof(__hw_##TYPE) <= sizeof(TYPE))\n \n-#if HWASAN_WITH_INTERCEPTORS && defined(__aarch64__)\n+#if HWASAN_WITH_INTERCEPTORS\n CHECK_TYPE_SIZE_FITS(jmp_buf);\n CHECK_TYPE_SIZE_FITS(sigjmp_buf);\n #endif"}, {"sha": "9bff21c117b39a211f0d7b5de041363285897ec8", "filename": "libsanitizer/include/sanitizer/asan_interface.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Finclude%2Fsanitizer%2Fasan_interface.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Finclude%2Fsanitizer%2Fasan_interface.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Finclude%2Fsanitizer%2Fasan_interface.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -316,7 +316,7 @@ void *__asan_addr_is_in_fake_stack(void *fake_stack, void *addr, void **beg,\n void __asan_handle_no_return(void);\n \n /// Update allocation stack trace for the given allocation to the current stack\n-/// trace. Returns 1 if successfull, 0 if not.\n+/// trace. Returns 1 if successful, 0 if not.\n int __asan_update_allocation_context(void* addr);\n \n #ifdef __cplusplus"}, {"sha": "692b8f70c9697ece8558f75967e840020736a77a", "filename": "libsanitizer/include/sanitizer/common_interface_defs.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Finclude%2Fsanitizer%2Fcommon_interface_defs.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Finclude%2Fsanitizer%2Fcommon_interface_defs.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Finclude%2Fsanitizer%2Fcommon_interface_defs.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -28,7 +28,7 @@ typedef struct {\n   // Enable sandbox support in sanitizer coverage.\n   int coverage_sandboxed;\n   // File descriptor to write coverage data to. If -1 is passed, a file will\n-  // be pre-opened by __sanitizer_sandobx_on_notify(). This field has no\n+  // be pre-opened by __sanitizer_sandbox_on_notify(). This field has no\n   // effect if coverage_sandboxed == 0.\n   intptr_t coverage_fd;\n   // If non-zero, split the coverage data into well-formed blocks. This is"}, {"sha": "d6209a3ea2b29dd8daa9275167ddde3b6f617573", "filename": "libsanitizer/include/sanitizer/dfsan_interface.h", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Finclude%2Fsanitizer%2Fdfsan_interface.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Finclude%2Fsanitizer%2Fdfsan_interface.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Finclude%2Fsanitizer%2Fdfsan_interface.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -150,8 +150,7 @@ int dfsan_get_track_origins(void);\n #ifdef __cplusplus\n }  // extern \"C\"\n \n-template <typename T>\n-void dfsan_set_label(dfsan_label label, T &data) { // NOLINT\n+template <typename T> void dfsan_set_label(dfsan_label label, T &data) {\n   dfsan_set_label(label, (void *)&data, sizeof(T));\n }\n "}, {"sha": "3f3f1e78dfb8594835935aa0473ad459adc808bc", "filename": "libsanitizer/include/sanitizer/linux_syscall_hooks.h", "status": "modified", "additions": 1067, "deletions": 1053, "changes": 2120, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Finclude%2Fsanitizer%2Flinux_syscall_hooks.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Finclude%2Fsanitizer%2Flinux_syscall_hooks.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Finclude%2Fsanitizer%2Flinux_syscall_hooks.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61"}, {"sha": "2782e61fb8c79d7b1dfd318c4b98ecdbd152ef79", "filename": "libsanitizer/include/sanitizer/tsan_interface.h", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Finclude%2Fsanitizer%2Ftsan_interface.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Finclude%2Fsanitizer%2Ftsan_interface.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Finclude%2Fsanitizer%2Ftsan_interface.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -169,6 +169,9 @@ void __tsan_on_initialize();\n // if TSan should exit as if issues were detected.\n int __tsan_on_finalize(int failed);\n \n+// Release TSan internal memory in a best-effort manner.\n+void __tsan_flush_memory();\n+\n #ifdef __cplusplus\n }  // extern \"C\"\n #endif"}, {"sha": "38b8c058246a251c0a9d5c8e7f962002599bbdfa", "filename": "libsanitizer/interception/interception_win.cpp", "status": "modified", "additions": 47, "deletions": 1, "changes": 48, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Finterception%2Finterception_win.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Finterception%2Finterception_win.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Finterception%2Finterception_win.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -56,7 +56,7 @@\n //                                      tramp:  jmp QWORD [addr]\n //                                       addr:  .bytes <hook>\n //\n-//    Note: <real> is equilavent to <label>.\n+//    Note: <real> is equivalent to <label>.\n //\n // 3) HotPatch\n //\n@@ -398,8 +398,42 @@ static uptr AllocateMemoryForTrampoline(uptr image_address, size_t size) {\n   return allocated_space;\n }\n \n+// The following prologues cannot be patched because of the short jump\n+// jumping to the patching region.\n+\n+// ntdll!wcslen in Win11\n+//   488bc1          mov     rax,rcx\n+//   0fb710          movzx   edx,word ptr [rax]\n+//   4883c002        add     rax,2\n+//   6685d2          test    dx,dx\n+//   75f4            jne     -12\n+static const u8 kPrologueWithShortJump1[] = {\n+    0x48, 0x8b, 0xc1, 0x0f, 0xb7, 0x10, 0x48, 0x83,\n+    0xc0, 0x02, 0x66, 0x85, 0xd2, 0x75, 0xf4,\n+};\n+\n+// ntdll!strrchr in Win11\n+//   4c8bc1          mov     r8,rcx\n+//   8a01            mov     al,byte ptr [rcx]\n+//   48ffc1          inc     rcx\n+//   84c0            test    al,al\n+//   75f7            jne     -9\n+static const u8 kPrologueWithShortJump2[] = {\n+    0x4c, 0x8b, 0xc1, 0x8a, 0x01, 0x48, 0xff, 0xc1,\n+    0x84, 0xc0, 0x75, 0xf7,\n+};\n+\n // Returns 0 on error.\n static size_t GetInstructionSize(uptr address, size_t* rel_offset = nullptr) {\n+#if SANITIZER_WINDOWS64\n+  if (memcmp((u8*)address, kPrologueWithShortJump1,\n+             sizeof(kPrologueWithShortJump1)) == 0 ||\n+      memcmp((u8*)address, kPrologueWithShortJump2,\n+             sizeof(kPrologueWithShortJump2)) == 0) {\n+    return 0;\n+  }\n+#endif\n+\n   switch (*(u64*)address) {\n     case 0x90909090909006EB:  // stub: jmp over 6 x nop.\n       return 8;\n@@ -477,6 +511,14 @@ static size_t GetInstructionSize(uptr address, size_t* rel_offset = nullptr) {\n     case 0xA1:  // A1 XX XX XX XX XX XX XX XX :\n                 //   movabs eax, dword ptr ds:[XXXXXXXX]\n       return 9;\n+\n+    case 0x83:\n+      const u8 next_byte = *(u8*)(address + 1);\n+      const u8 mod = next_byte >> 6;\n+      const u8 rm = next_byte & 7;\n+      if (mod == 1 && rm == 4)\n+        return 5;  // 83 ModR/M SIB Disp8 Imm8\n+                   //   add|or|adc|sbb|and|sub|xor|cmp [r+disp8], imm8\n   }\n \n   switch (*(u16*)address) {\n@@ -493,6 +535,8 @@ static size_t GetInstructionSize(uptr address, size_t* rel_offset = nullptr) {\n     case 0x5641:  // push r14\n     case 0x5741:  // push r15\n     case 0x9066:  // Two-byte NOP\n+    case 0xc084:  // test al, al\n+    case 0x018a:  // mov al, byte ptr [rcx]\n       return 2;\n \n     case 0x058B:  // 8B 05 XX XX XX XX : mov eax, dword ptr [XX XX XX XX]\n@@ -509,6 +553,7 @@ static size_t GetInstructionSize(uptr address, size_t* rel_offset = nullptr) {\n     case 0xd12b48:    // 48 2b d1 : sub rdx, rcx\n     case 0x07c1f6:    // f6 c1 07 : test cl, 0x7\n     case 0xc98548:    // 48 85 C9 : test rcx, rcx\n+    case 0xd28548:    // 48 85 d2 : test rdx, rdx\n     case 0xc0854d:    // 4d 85 c0 : test r8, r8\n     case 0xc2b60f:    // 0f b6 c2 : movzx eax, dl\n     case 0xc03345:    // 45 33 c0 : xor r8d, r8d\n@@ -522,6 +567,7 @@ static size_t GetInstructionSize(uptr address, size_t* rel_offset = nullptr) {\n     case 0xca2b48:    // 48 2b ca : sub rcx, rdx\n     case 0x10b70f:    // 0f b7 10 : movzx edx, WORD PTR [rax]\n     case 0xc00b4d:    // 3d 0b c0 : or r8, r8\n+    case 0xc08b41:    // 41 8b c0 : mov eax, r8d\n     case 0xd18b48:    // 48 8b d1 : mov rdx, rcx\n     case 0xdc8b4c:    // 4c 8b dc : mov r11, rsp\n     case 0xd18b4c:    // 4c 8b d1 : mov r10, rcx"}, {"sha": "45c6ac406f8a195506517bbc13490aa2104e8d95", "filename": "libsanitizer/lsan/lsan_allocator.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Flsan%2Flsan_allocator.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Flsan%2Flsan_allocator.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Flsan%2Flsan_allocator.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -50,7 +50,7 @@ struct ChunkMetadata {\n };\n \n #if defined(__mips64) || defined(__aarch64__) || defined(__i386__) || \\\n-    defined(__arm__) || SANITIZER_RISCV64\n+    defined(__arm__) || SANITIZER_RISCV64 || defined(__hexagon__)\n template <typename AddressSpaceViewTy>\n struct AP32 {\n   static const uptr kSpaceBeg = 0;"}, {"sha": "96a487e037c552c06192a22d792ad735675127b9", "filename": "libsanitizer/lsan/lsan_common.cpp", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Flsan%2Flsan_common.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Flsan%2Flsan_common.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Flsan%2Flsan_common.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -30,7 +30,7 @@ namespace __lsan {\n \n // This mutex is used to prevent races between DoLeakCheck and IgnoreObject, and\n // also to protect the global list of root regions.\n-BlockingMutex global_mutex(LINKER_INITIALIZED);\n+Mutex global_mutex;\n \n Flags lsan_flags;\n \n@@ -742,7 +742,7 @@ static bool has_reported_leaks = false;\n bool HasReportedLeaks() { return has_reported_leaks; }\n \n void DoLeakCheck() {\n-  BlockingMutexLock l(&global_mutex);\n+  Lock l(&global_mutex);\n   static bool already_done;\n   if (already_done) return;\n   already_done = true;\n@@ -751,7 +751,7 @@ void DoLeakCheck() {\n }\n \n static int DoRecoverableLeakCheck() {\n-  BlockingMutexLock l(&global_mutex);\n+  Lock l(&global_mutex);\n   bool have_leaks = CheckForLeaks();\n   return have_leaks ? 1 : 0;\n }\n@@ -954,7 +954,7 @@ void __lsan_ignore_object(const void *p) {\n     return;\n   // Cannot use PointsIntoChunk or LsanMetadata here, since the allocator is not\n   // locked.\n-  BlockingMutexLock l(&global_mutex);\n+  Lock l(&global_mutex);\n   IgnoreObjectResult res = IgnoreObjectLocked(p);\n   if (res == kIgnoreObjectInvalid)\n     VReport(1, \"__lsan_ignore_object(): no heap object found at %p\", p);\n@@ -969,7 +969,7 @@ void __lsan_ignore_object(const void *p) {\n SANITIZER_INTERFACE_ATTRIBUTE\n void __lsan_register_root_region(const void *begin, uptr size) {\n #if CAN_SANITIZE_LEAKS\n-  BlockingMutexLock l(&global_mutex);\n+  Lock l(&global_mutex);\n   CHECK(root_regions);\n   RootRegion region = {reinterpret_cast<uptr>(begin), size};\n   root_regions->push_back(region);\n@@ -980,7 +980,7 @@ void __lsan_register_root_region(const void *begin, uptr size) {\n SANITIZER_INTERFACE_ATTRIBUTE\n void __lsan_unregister_root_region(const void *begin, uptr size) {\n #if CAN_SANITIZE_LEAKS\n-  BlockingMutexLock l(&global_mutex);\n+  Lock l(&global_mutex);\n   CHECK(root_regions);\n   bool removed = false;\n   for (uptr i = 0; i < root_regions->size(); i++) {"}, {"sha": "de9ede217fc34b2f39d6ee3291940a0d03f1a7e4", "filename": "libsanitizer/sanitizer_common/sancov_flags.inc", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsancov_flags.inc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsancov_flags.inc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsancov_flags.inc?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -14,7 +14,7 @@\n #endif\n \n SANCOV_FLAG(bool, symbolize, true,\n-            \"If set, converage information will be symbolized by sancov tool \"\n+            \"If set, coverage information will be symbolized by sancov tool \"\n             \"after dumping.\")\n \n SANCOV_FLAG(bool, help, false, \"Print flags help.\")"}, {"sha": "73b48cb27ddca6e1b5b2d8299d9301058910fc88", "filename": "libsanitizer/sanitizer_common/sanitizer_addrhashmap.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_addrhashmap.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_addrhashmap.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_addrhashmap.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -56,7 +56,7 @@ class AddrHashMap {\n   static const uptr kBucketSize = 3;\n \n   struct Bucket {\n-    RWMutex          mtx;\n+    Mutex mtx;\n     atomic_uintptr_t add;\n     Cell             cells[kBucketSize];\n   };"}, {"sha": "3710947e78cdc9d3bfb9e0fd55a20b7f6d302cec", "filename": "libsanitizer/sanitizer_common/sanitizer_allocator_primary64.h", "status": "modified", "additions": 8, "deletions": 6, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_allocator_primary64.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_allocator_primary64.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_allocator_primary64.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -161,7 +161,7 @@ class SizeClassAllocator64 {\n   void ForceReleaseToOS() {\n     MemoryMapperT memory_mapper(*this);\n     for (uptr class_id = 1; class_id < kNumClasses; class_id++) {\n-      BlockingMutexLock l(&GetRegionInfo(class_id)->mutex);\n+      Lock l(&GetRegionInfo(class_id)->mutex);\n       MaybeReleaseToOS(&memory_mapper, class_id, true /*force*/);\n     }\n   }\n@@ -178,7 +178,7 @@ class SizeClassAllocator64 {\n     uptr region_beg = GetRegionBeginBySizeClass(class_id);\n     CompactPtrT *free_array = GetFreeArray(region_beg);\n \n-    BlockingMutexLock l(&region->mutex);\n+    Lock l(&region->mutex);\n     uptr old_num_chunks = region->num_freed_chunks;\n     uptr new_num_freed_chunks = old_num_chunks + n_chunks;\n     // Failure to allocate free array space while releasing memory is non\n@@ -204,7 +204,7 @@ class SizeClassAllocator64 {\n     uptr region_beg = GetRegionBeginBySizeClass(class_id);\n     CompactPtrT *free_array = GetFreeArray(region_beg);\n \n-    BlockingMutexLock l(&region->mutex);\n+    Lock l(&region->mutex);\n #if SANITIZER_WINDOWS\n     /* On Windows unmapping of memory during __sanitizer_purge_allocator is\n     explicit and immediate, so unmapped regions must be explicitly mapped back\n@@ -282,6 +282,8 @@ class SizeClassAllocator64 {\n     CHECK(kMetadataSize);\n     uptr class_id = GetSizeClass(p);\n     uptr size = ClassIdToSize(class_id);\n+    if (!size)\n+      return nullptr;\n     uptr chunk_idx = GetChunkIdx(reinterpret_cast<uptr>(p), size);\n     uptr region_beg = GetRegionBeginBySizeClass(class_id);\n     return reinterpret_cast<void *>(GetMetadataEnd(region_beg) -\n@@ -315,7 +317,7 @@ class SizeClassAllocator64 {\n     Printf(\n         \"%s %02zd (%6zd): mapped: %6zdK allocs: %7zd frees: %7zd inuse: %6zd \"\n         \"num_freed_chunks %7zd avail: %6zd rss: %6zdK releases: %6zd \"\n-        \"last released: %6zdK region: 0x%zx\\n\",\n+        \"last released: %6lldK region: 0x%zx\\n\",\n         region->exhausted ? \"F\" : \" \", class_id, ClassIdToSize(class_id),\n         region->mapped_user >> 10, region->stats.n_allocated,\n         region->stats.n_freed, in_use, region->num_freed_chunks, avail_chunks,\n@@ -623,7 +625,7 @@ class SizeClassAllocator64 {\n \n   static const uptr kRegionSize = kSpaceSize / kNumClassesRounded;\n   // FreeArray is the array of free-d chunks (stored as 4-byte offsets).\n-  // In the worst case it may reguire kRegionSize/SizeClassMap::kMinSize\n+  // In the worst case it may require kRegionSize/SizeClassMap::kMinSize\n   // elements, but in reality this will not happen. For simplicity we\n   // dedicate 1/8 of the region's virtual space to FreeArray.\n   static const uptr kFreeArraySize = kRegionSize / 8;\n@@ -665,7 +667,7 @@ class SizeClassAllocator64 {\n   };\n \n   struct ALIGNED(SANITIZER_CACHE_LINE_SIZE) RegionInfo {\n-    BlockingMutex mutex;\n+    Mutex mutex;\n     uptr num_freed_chunks;  // Number of elements in the freearray.\n     uptr mapped_free_array;  // Bytes mapped for freearray.\n     uptr allocated_user;  // Bytes allocated for user memory."}, {"sha": "361793f2490ace739145345e8cad8f1dea549632", "filename": "libsanitizer/sanitizer_common/sanitizer_allocator_size_class_map.h", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_allocator_size_class_map.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_allocator_size_class_map.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_allocator_size_class_map.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -193,13 +193,13 @@ class SizeClassMap {\n       uptr cached = MaxCachedHint(s) * s;\n       if (i == kBatchClassID)\n         d = p = l = 0;\n-      Printf(\"c%02zd => s: %zd diff: +%zd %02zd%% l %zd \"\n-             \"cached: %zd %zd; id %zd\\n\",\n-             i, Size(i), d, p, l, MaxCachedHint(s), cached, ClassID(s));\n+      Printf(\n+          \"c%02zu => s: %zu diff: +%zu %02zu%% l %zu cached: %zu %zu; id %zu\\n\",\n+          i, Size(i), d, p, l, MaxCachedHint(s), cached, ClassID(s));\n       total_cached += cached;\n       prev_s = s;\n     }\n-    Printf(\"Total cached: %zd\\n\", total_cached);\n+    Printf(\"Total cached: %zu\\n\", total_cached);\n   }\n \n   static void Validate() {"}, {"sha": "b544542c26a74d4ea4e78aae5d2a86a18f8750d5", "filename": "libsanitizer/sanitizer_common/sanitizer_asm.h", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_asm.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_asm.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_asm.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -6,7 +6,7 @@\n //\n //===----------------------------------------------------------------------===//\n //\n-// Various support for assemebler.\n+// Various support for assembler.\n //\n //===----------------------------------------------------------------------===//\n \n@@ -61,7 +61,7 @@\n #if defined(__ELF__) && (defined(__GNU__) || defined(__FreeBSD__) || \\\n                          defined(__Fuchsia__) || defined(__linux__))\n // clang-format off\n-#define NO_EXEC_STACK_DIRECTIVE .section .note.GNU-stack,\"\",%progbits  // NOLINT\n+#define NO_EXEC_STACK_DIRECTIVE .section .note.GNU-stack,\"\",%progbits\n // clang-format on\n #else\n #define NO_EXEC_STACK_DIRECTIVE"}, {"sha": "f3d3052e5b7c5c22b5171d3c14c5d325618ab1a4", "filename": "libsanitizer/sanitizer_common/sanitizer_atomic_clang_mips.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_atomic_clang_mips.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_atomic_clang_mips.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_atomic_clang_mips.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -18,7 +18,7 @@ namespace __sanitizer {\n \n // MIPS32 does not support atomics > 4 bytes. To address this lack of\n // functionality, the sanitizer library provides helper methods which use an\n-// internal spin lock mechanism to emulate atomic oprations when the size is\n+// internal spin lock mechanism to emulate atomic operations when the size is\n // 8 bytes.\n static void __spin_lock(volatile int *lock) {\n   while (__sync_lock_test_and_set(lock, 1))"}, {"sha": "17c29c75046422aef3f20d89750b368edbd6cf0f", "filename": "libsanitizer/sanitizer_common/sanitizer_common.h", "status": "modified", "additions": 8, "deletions": 12, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_common.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_common.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_common.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -222,8 +222,8 @@ void CatastrophicErrorWrite(const char *buffer, uptr length);\n void RawWrite(const char *buffer);\n bool ColorizeReports();\n void RemoveANSIEscapeSequencesFromString(char *buffer);\n-void Printf(const char *format, ...);\n-void Report(const char *format, ...);\n+void Printf(const char *format, ...) FORMAT(1, 2);\n+void Report(const char *format, ...) FORMAT(1, 2);\n void SetPrintfAndReportCallback(void (*callback)(const char *));\n #define VReport(level, ...)                                              \\\n   do {                                                                   \\\n@@ -618,7 +618,7 @@ class InternalScopedString {\n     buffer_.resize(1);\n     buffer_[0] = '\\0';\n   }\n-  void append(const char *format, ...);\n+  void append(const char *format, ...) FORMAT(2, 3);\n   const char *data() const { return buffer_.data(); }\n   char *data() { return buffer_.data(); }\n \n@@ -697,7 +697,8 @@ enum ModuleArch {\n   kModuleArchARMV7S,\n   kModuleArchARMV7K,\n   kModuleArchARM64,\n-  kModuleArchRISCV64\n+  kModuleArchRISCV64,\n+  kModuleArchHexagon\n };\n \n // Sorts and removes duplicates from the container.\n@@ -764,6 +765,8 @@ inline const char *ModuleArchToString(ModuleArch arch) {\n       return \"arm64\";\n     case kModuleArchRISCV64:\n       return \"riscv64\";\n+    case kModuleArchHexagon:\n+      return \"hexagon\";\n   }\n   CHECK(0 && \"Invalid module arch\");\n   return \"\";\n@@ -1063,17 +1066,10 @@ class ArrayRef {\n   T *end_ = nullptr;\n };\n \n-#define PRINTF_128(v)                                                         \\\n-  (*((u8 *)&v + 0)), (*((u8 *)&v + 1)), (*((u8 *)&v + 2)), (*((u8 *)&v + 3)), \\\n-      (*((u8 *)&v + 4)), (*((u8 *)&v + 5)), (*((u8 *)&v + 6)),                \\\n-      (*((u8 *)&v + 7)), (*((u8 *)&v + 8)), (*((u8 *)&v + 9)),                \\\n-      (*((u8 *)&v + 10)), (*((u8 *)&v + 11)), (*((u8 *)&v + 12)),             \\\n-      (*((u8 *)&v + 13)), (*((u8 *)&v + 14)), (*((u8 *)&v + 15))\n-\n }  // namespace __sanitizer\n \n inline void *operator new(__sanitizer::operator_new_size_type size,\n-                          __sanitizer::LowLevelAllocator &alloc) {  // NOLINT\n+                          __sanitizer::LowLevelAllocator &alloc) {\n   return alloc.Allocate(size);\n }\n "}, {"sha": "9511a3b19a0f790fe0af3fa3be2a7b0ef4483efd", "filename": "libsanitizer/sanitizer_common/sanitizer_common_interceptors.inc", "status": "modified", "additions": 363, "deletions": 289, "changes": 652, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_interceptors.inc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_interceptors.inc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_interceptors.inc?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -204,7 +204,7 @@ extern const short *_tolower_tab_;\n \n #define COMMON_INTERCEPTOR_READ_STRING(ctx, s, n)                   \\\n     COMMON_INTERCEPTOR_READ_RANGE((ctx), (s),                       \\\n-      common_flags()->strict_string_checks ? (REAL(strlen)(s)) + 1 : (n) )\n+      common_flags()->strict_string_checks ? (internal_strlen(s)) + 1 : (n) )\n \n #ifndef COMMON_INTERCEPTOR_ON_DLOPEN\n #define COMMON_INTERCEPTOR_ON_DLOPEN(filename, flag) \\\n@@ -435,7 +435,7 @@ INTERCEPTOR(char*, textdomain, const char *domainname) {\n   if (domainname) COMMON_INTERCEPTOR_READ_STRING(ctx, domainname, 0);\n   char *domain = REAL(textdomain)(domainname);\n   if (domain) {\n-    COMMON_INTERCEPTOR_INITIALIZE_RANGE(domain, REAL(strlen)(domain) + 1);\n+    COMMON_INTERCEPTOR_INITIALIZE_RANGE(domain, internal_strlen(domain) + 1);\n   }\n   return domain;\n }\n@@ -575,8 +575,8 @@ INTERCEPTOR(int, strncasecmp, const char *s1, const char *s2, SIZE_T size) {\n #if SANITIZER_INTERCEPT_STRSTR || SANITIZER_INTERCEPT_STRCASESTR\n static inline void StrstrCheck(void *ctx, char *r, const char *s1,\n                                const char *s2) {\n-    uptr len1 = REAL(strlen)(s1);\n-    uptr len2 = REAL(strlen)(s2);\n+    uptr len1 = internal_strlen(s1);\n+    uptr len2 = internal_strlen(s2);\n     COMMON_INTERCEPTOR_READ_STRING(ctx, s1, r ? r - s1 + len2 : len1 + 1);\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, s2, len2 + 1);\n }\n@@ -640,10 +640,10 @@ INTERCEPTOR(char*, strtok, char *str, const char *delimiters) {\n     // for subsequent calls). We do not need to check strtok's result.\n     // As the delimiters can change, we check them every call.\n     if (str != nullptr) {\n-      COMMON_INTERCEPTOR_READ_RANGE(ctx, str, REAL(strlen)(str) + 1);\n+      COMMON_INTERCEPTOR_READ_RANGE(ctx, str, internal_strlen(str) + 1);\n     }\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, delimiters,\n-                                  REAL(strlen)(delimiters) + 1);\n+                                  internal_strlen(delimiters) + 1);\n     return REAL(strtok)(str, delimiters);\n   } else {\n     // However, when strict_string_checks is disabled we cannot check the\n@@ -657,11 +657,11 @@ INTERCEPTOR(char*, strtok, char *str, const char *delimiters) {\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, delimiters, 1);\n     char *result = REAL(strtok)(str, delimiters);\n     if (result != nullptr) {\n-      COMMON_INTERCEPTOR_READ_RANGE(ctx, result, REAL(strlen)(result) + 1);\n+      COMMON_INTERCEPTOR_READ_RANGE(ctx, result, internal_strlen(result) + 1);\n     } else if (str != nullptr) {\n       // No delimiter were found, it's safe to assume that the entire str was\n       // scanned.\n-      COMMON_INTERCEPTOR_READ_RANGE(ctx, str, REAL(strlen)(str) + 1);\n+      COMMON_INTERCEPTOR_READ_RANGE(ctx, str, internal_strlen(str) + 1);\n     }\n     return result;\n   }\n@@ -706,7 +706,7 @@ INTERCEPTOR(char*, strchr, const char *s, int c) {\n   if (common_flags()->intercept_strchr) {\n     // Keep strlen as macro argument, as macro may ignore it.\n     COMMON_INTERCEPTOR_READ_STRING(ctx, s,\n-      (result ? result - s : REAL(strlen)(s)) + 1);\n+      (result ? result - s : internal_strlen(s)) + 1);\n   }\n   return result;\n }\n@@ -737,7 +737,7 @@ INTERCEPTOR(char*, strrchr, const char *s, int c) {\n     return internal_strrchr(s, c);\n   COMMON_INTERCEPTOR_ENTER(ctx, strrchr, s, c);\n   if (common_flags()->intercept_strchr)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, s, REAL(strlen)(s) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, s, internal_strlen(s) + 1);\n   return REAL(strrchr)(s, c);\n }\n #define INIT_STRRCHR COMMON_INTERCEPT_FUNCTION(strrchr)\n@@ -751,7 +751,7 @@ INTERCEPTOR(SIZE_T, strspn, const char *s1, const char *s2) {\n   COMMON_INTERCEPTOR_ENTER(ctx, strspn, s1, s2);\n   SIZE_T r = REAL(strspn)(s1, s2);\n   if (common_flags()->intercept_strspn) {\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, s2, REAL(strlen)(s2) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, s2, internal_strlen(s2) + 1);\n     COMMON_INTERCEPTOR_READ_STRING(ctx, s1, r + 1);\n   }\n   return r;\n@@ -762,7 +762,7 @@ INTERCEPTOR(SIZE_T, strcspn, const char *s1, const char *s2) {\n   COMMON_INTERCEPTOR_ENTER(ctx, strcspn, s1, s2);\n   SIZE_T r = REAL(strcspn)(s1, s2);\n   if (common_flags()->intercept_strspn) {\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, s2, REAL(strlen)(s2) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, s2, internal_strlen(s2) + 1);\n     COMMON_INTERCEPTOR_READ_STRING(ctx, s1, r + 1);\n   }\n   return r;\n@@ -781,9 +781,9 @@ INTERCEPTOR(char *, strpbrk, const char *s1, const char *s2) {\n   COMMON_INTERCEPTOR_ENTER(ctx, strpbrk, s1, s2);\n   char *r = REAL(strpbrk)(s1, s2);\n   if (common_flags()->intercept_strpbrk) {\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, s2, REAL(strlen)(s2) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, s2, internal_strlen(s2) + 1);\n     COMMON_INTERCEPTOR_READ_STRING(ctx, s1,\n-        r ? r - s1 + 1 : REAL(strlen)(s1) + 1);\n+        r ? r - s1 + 1 : internal_strlen(s1) + 1);\n   }\n   return r;\n }\n@@ -1251,7 +1251,7 @@ INTERCEPTOR(char *, fgets, char *s, SIZE_T size, void *file) {\n   // https://github.com/google/sanitizers/issues/321.\n   char *res = REAL(fgets)(s, size, file);\n   if (res)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, s, REAL(strlen)(s) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, s, internal_strlen(s) + 1);\n   return res;\n }\n #define INIT_FGETS COMMON_INTERCEPT_FUNCTION(fgets)\n@@ -1265,7 +1265,7 @@ INTERCEPTOR_WITH_SUFFIX(int, fputs, char *s, void *file) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, fputs, s, file);\n   if (!SANITIZER_MAC || s) {  // `fputs(NULL, file)` is supported on Darwin.\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, s, REAL(strlen)(s) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, s, internal_strlen(s) + 1);\n   }\n   return REAL(fputs)(s, file);\n }\n@@ -1280,7 +1280,7 @@ INTERCEPTOR(int, puts, char *s) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, puts, s);\n   if (!SANITIZER_MAC || s) {  // `puts(NULL)` is supported on Darwin.\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, s, REAL(strlen)(s) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, s, internal_strlen(s) + 1);\n   }\n   return REAL(puts)(s);\n }\n@@ -1334,7 +1334,7 @@ static void unpoison_tm(void *ctx, __sanitizer_tm *tm) {\n     // Can not use COMMON_INTERCEPTOR_WRITE_RANGE here, because tm->tm_zone\n     // can point to shared memory and tsan would report a data race.\n     COMMON_INTERCEPTOR_INITIALIZE_RANGE(tm->tm_zone,\n-                                        REAL(strlen(tm->tm_zone)) + 1);\n+                                        internal_strlen(tm->tm_zone) + 1);\n   }\n #endif\n }\n@@ -1387,7 +1387,7 @@ INTERCEPTOR(char *, ctime, unsigned long *timep) {\n   char *res = REAL(ctime)(timep);\n   if (res) {\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, timep, sizeof(*timep));\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, REAL(strlen)(res) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, internal_strlen(res) + 1);\n   }\n   return res;\n }\n@@ -1400,7 +1400,7 @@ INTERCEPTOR(char *, ctime_r, unsigned long *timep, char *result) {\n   char *res = REAL(ctime_r)(timep, result);\n   if (res) {\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, timep, sizeof(*timep));\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, REAL(strlen)(res) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, internal_strlen(res) + 1);\n   }\n   return res;\n }\n@@ -1413,7 +1413,7 @@ INTERCEPTOR(char *, asctime, __sanitizer_tm *tm) {\n   char *res = REAL(asctime)(tm);\n   if (res) {\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, tm, sizeof(*tm));\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, REAL(strlen)(res) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, internal_strlen(res) + 1);\n   }\n   return res;\n }\n@@ -1426,7 +1426,7 @@ INTERCEPTOR(char *, asctime_r, __sanitizer_tm *tm, char *result) {\n   char *res = REAL(asctime_r)(tm, result);\n   if (res) {\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, tm, sizeof(*tm));\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, REAL(strlen)(res) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, internal_strlen(res) + 1);\n   }\n   return res;\n }\n@@ -1463,7 +1463,7 @@ INTERCEPTOR(char *, strptime, char *s, char *format, __sanitizer_tm *tm) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, strptime, s, format, tm);\n   if (format)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, format, REAL(strlen)(format) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, format, internal_strlen(format) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -1843,9 +1843,9 @@ INTERCEPTOR(int, ioctl, int d, unsigned long request, ...) {\n   const ioctl_desc *desc = ioctl_lookup(request);\n   ioctl_desc decoded_desc;\n   if (!desc) {\n-    VPrintf(2, \"Decoding unknown ioctl 0x%x\\n\", request);\n+    VPrintf(2, \"Decoding unknown ioctl 0x%lx\\n\", request);\n     if (!ioctl_decode(request, &decoded_desc))\n-      Printf(\"WARNING: failed decoding unknown ioctl 0x%x\\n\", request);\n+      Printf(\"WARNING: failed decoding unknown ioctl 0x%lx\\n\", request);\n     else\n       desc = &decoded_desc;\n   }\n@@ -1869,26 +1869,26 @@ UNUSED static void unpoison_passwd(void *ctx, __sanitizer_passwd *pwd) {\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, pwd, sizeof(*pwd));\n     if (pwd->pw_name)\n       COMMON_INTERCEPTOR_WRITE_RANGE(ctx, pwd->pw_name,\n-                                     REAL(strlen)(pwd->pw_name) + 1);\n+                                     internal_strlen(pwd->pw_name) + 1);\n     if (pwd->pw_passwd)\n       COMMON_INTERCEPTOR_WRITE_RANGE(ctx, pwd->pw_passwd,\n-                                     REAL(strlen)(pwd->pw_passwd) + 1);\n+                                     internal_strlen(pwd->pw_passwd) + 1);\n #if !SANITIZER_ANDROID\n     if (pwd->pw_gecos)\n       COMMON_INTERCEPTOR_WRITE_RANGE(ctx, pwd->pw_gecos,\n-                                     REAL(strlen)(pwd->pw_gecos) + 1);\n+                                     internal_strlen(pwd->pw_gecos) + 1);\n #endif\n #if SANITIZER_MAC || SANITIZER_FREEBSD || SANITIZER_NETBSD\n     if (pwd->pw_class)\n       COMMON_INTERCEPTOR_WRITE_RANGE(ctx, pwd->pw_class,\n-                                     REAL(strlen)(pwd->pw_class) + 1);\n+                                     internal_strlen(pwd->pw_class) + 1);\n #endif\n     if (pwd->pw_dir)\n       COMMON_INTERCEPTOR_WRITE_RANGE(ctx, pwd->pw_dir,\n-                                     REAL(strlen)(pwd->pw_dir) + 1);\n+                                     internal_strlen(pwd->pw_dir) + 1);\n     if (pwd->pw_shell)\n       COMMON_INTERCEPTOR_WRITE_RANGE(ctx, pwd->pw_shell,\n-                                     REAL(strlen)(pwd->pw_shell) + 1);\n+                                     internal_strlen(pwd->pw_shell) + 1);\n   }\n }\n \n@@ -1897,13 +1897,13 @@ UNUSED static void unpoison_group(void *ctx, __sanitizer_group *grp) {\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, grp, sizeof(*grp));\n     if (grp->gr_name)\n       COMMON_INTERCEPTOR_WRITE_RANGE(ctx, grp->gr_name,\n-                                     REAL(strlen)(grp->gr_name) + 1);\n+                                     internal_strlen(grp->gr_name) + 1);\n     if (grp->gr_passwd)\n       COMMON_INTERCEPTOR_WRITE_RANGE(ctx, grp->gr_passwd,\n-                                     REAL(strlen)(grp->gr_passwd) + 1);\n+                                     internal_strlen(grp->gr_passwd) + 1);\n     char **p = grp->gr_mem;\n     for (; *p; ++p) {\n-      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *p, REAL(strlen)(*p) + 1);\n+      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *p, internal_strlen(*p) + 1);\n     }\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, grp->gr_mem,\n                                    (p - grp->gr_mem + 1) * sizeof(*p));\n@@ -1916,7 +1916,7 @@ INTERCEPTOR(__sanitizer_passwd *, getpwnam, const char *name) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, getpwnam, name);\n   if (name)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n   __sanitizer_passwd *res = REAL(getpwnam)(name);\n   unpoison_passwd(ctx, res);\n   return res;\n@@ -1931,7 +1931,7 @@ INTERCEPTOR(__sanitizer_passwd *, getpwuid, u32 uid) {\n INTERCEPTOR(__sanitizer_group *, getgrnam, const char *name) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, getgrnam, name);\n-  COMMON_INTERCEPTOR_READ_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+  COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n   __sanitizer_group *res = REAL(getgrnam)(name);\n   unpoison_group(ctx, res);\n   return res;\n@@ -1957,7 +1957,7 @@ INTERCEPTOR(int, getpwnam_r, const char *name, __sanitizer_passwd *pwd,\n             char *buf, SIZE_T buflen, __sanitizer_passwd **result) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, getpwnam_r, name, pwd, buf, buflen, result);\n-  COMMON_INTERCEPTOR_READ_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+  COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -1984,7 +1984,7 @@ INTERCEPTOR(int, getgrnam_r, const char *name, __sanitizer_group *grp,\n             char *buf, SIZE_T buflen, __sanitizer_group **result) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, getgrnam_r, name, grp, buf, buflen, result);\n-  COMMON_INTERCEPTOR_READ_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+  COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -2229,8 +2229,20 @@ INTERCEPTOR(int, clock_getcpuclockid, pid_t pid,\n   return res;\n }\n \n-#define INIT_CLOCK_GETCPUCLOCKID                  \\\n-  COMMON_INTERCEPT_FUNCTION(clock_getcpuclockid);\n+INTERCEPTOR(int, pthread_getcpuclockid, uptr thread,\n+            __sanitizer_clockid_t *clockid) {\n+  void *ctx;\n+  COMMON_INTERCEPTOR_ENTER(ctx, pthread_getcpuclockid, thread, clockid);\n+  int res = REAL(pthread_getcpuclockid)(thread, clockid);\n+  if (!res && clockid) {\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, clockid, sizeof *clockid);\n+  }\n+  return res;\n+}\n+\n+#define INIT_CLOCK_GETCPUCLOCKID                   \\\n+  COMMON_INTERCEPT_FUNCTION(clock_getcpuclockid);  \\\n+  COMMON_INTERCEPT_FUNCTION(pthread_getcpuclockid);\n #else\n #define INIT_CLOCK_GETCPUCLOCKID\n #endif\n@@ -2289,7 +2301,7 @@ static void unpoison_glob_t(void *ctx, __sanitizer_glob_t *pglob) {\n         ctx, pglob->gl_pathv, (pglob->gl_pathc + 1) * sizeof(*pglob->gl_pathv));\n   for (SIZE_T i = 0; i < pglob->gl_pathc; ++i) {\n     char *p = pglob->gl_pathv[i];\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, p, REAL(strlen)(p) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, p, internal_strlen(p) + 1);\n   }\n }\n \n@@ -2319,19 +2331,19 @@ static void *wrapped_gl_readdir(void *dir) {\n \n static void *wrapped_gl_opendir(const char *s) {\n   COMMON_INTERCEPTOR_UNPOISON_PARAM(1);\n-  COMMON_INTERCEPTOR_INITIALIZE_RANGE(s, REAL(strlen)(s) + 1);\n+  COMMON_INTERCEPTOR_INITIALIZE_RANGE(s, internal_strlen(s) + 1);\n   return pglob_copy->gl_opendir(s);\n }\n \n static int wrapped_gl_lstat(const char *s, void *st) {\n   COMMON_INTERCEPTOR_UNPOISON_PARAM(2);\n-  COMMON_INTERCEPTOR_INITIALIZE_RANGE(s, REAL(strlen)(s) + 1);\n+  COMMON_INTERCEPTOR_INITIALIZE_RANGE(s, internal_strlen(s) + 1);\n   return pglob_copy->gl_lstat(s, st);\n }\n \n static int wrapped_gl_stat(const char *s, void *st) {\n   COMMON_INTERCEPTOR_UNPOISON_PARAM(2);\n-  COMMON_INTERCEPTOR_INITIALIZE_RANGE(s, REAL(strlen)(s) + 1);\n+  COMMON_INTERCEPTOR_INITIALIZE_RANGE(s, internal_strlen(s) + 1);\n   return pglob_copy->gl_stat(s, st);\n }\n \n@@ -2519,7 +2531,7 @@ INTERCEPTOR(char *, inet_ntop, int af, const void *src, char *dst, u32 size) {\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n   char *res = REAL(inet_ntop)(af, src, dst, size);\n-  if (res) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, REAL(strlen)(res) + 1);\n+  if (res) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, internal_strlen(res) + 1);\n   return res;\n }\n INTERCEPTOR(int, inet_pton, int af, const char *src, void *dst) {\n@@ -2548,7 +2560,7 @@ INTERCEPTOR(int, inet_pton, int af, const char *src, void *dst) {\n INTERCEPTOR(int, inet_aton, const char *cp, void *dst) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, inet_aton, cp, dst);\n-  if (cp) COMMON_INTERCEPTOR_READ_RANGE(ctx, cp, REAL(strlen)(cp) + 1);\n+  if (cp) COMMON_INTERCEPTOR_READ_RANGE(ctx, cp, internal_strlen(cp) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -2590,9 +2602,9 @@ INTERCEPTOR(int, getaddrinfo, char *node, char *service,\n             struct __sanitizer_addrinfo **out) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, getaddrinfo, node, service, hints, out);\n-  if (node) COMMON_INTERCEPTOR_READ_RANGE(ctx, node, REAL(strlen)(node) + 1);\n+  if (node) COMMON_INTERCEPTOR_READ_RANGE(ctx, node, internal_strlen(node) + 1);\n   if (service)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, service, REAL(strlen)(service) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, service, internal_strlen(service) + 1);\n   if (hints)\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, hints, sizeof(__sanitizer_addrinfo));\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n@@ -2608,7 +2620,7 @@ INTERCEPTOR(int, getaddrinfo, char *node, char *service,\n         COMMON_INTERCEPTOR_WRITE_RANGE(ctx, p->ai_addr, p->ai_addrlen);\n       if (p->ai_canonname)\n         COMMON_INTERCEPTOR_WRITE_RANGE(ctx, p->ai_canonname,\n-                                       REAL(strlen)(p->ai_canonname) + 1);\n+                                       internal_strlen(p->ai_canonname) + 1);\n       p = p->ai_next;\n     }\n   }\n@@ -2634,9 +2646,9 @@ INTERCEPTOR(int, getnameinfo, void *sockaddr, unsigned salen, char *host,\n       REAL(getnameinfo)(sockaddr, salen, host, hostlen, serv, servlen, flags);\n   if (res == 0) {\n     if (host && hostlen)\n-      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, host, REAL(strlen)(host) + 1);\n+      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, host, internal_strlen(host) + 1);\n     if (serv && servlen)\n-      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, serv, REAL(strlen)(serv) + 1);\n+      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, serv, internal_strlen(serv) + 1);\n   }\n   return res;\n }\n@@ -2669,10 +2681,10 @@ INTERCEPTOR(int, getsockname, int sock_fd, void *addr, int *addrlen) {\n static void write_hostent(void *ctx, struct __sanitizer_hostent *h) {\n   COMMON_INTERCEPTOR_WRITE_RANGE(ctx, h, sizeof(__sanitizer_hostent));\n   if (h->h_name)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, h->h_name, REAL(strlen)(h->h_name) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, h->h_name, internal_strlen(h->h_name) + 1);\n   char **p = h->h_aliases;\n   while (*p) {\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *p, REAL(strlen)(*p) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *p, internal_strlen(*p) + 1);\n     ++p;\n   }\n   COMMON_INTERCEPTOR_WRITE_RANGE(\n@@ -3196,7 +3208,7 @@ INTERCEPTOR(int, sysinfo, void *info) {\n INTERCEPTOR(__sanitizer_dirent *, opendir, const char *path) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, opendir, path);\n-  COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+  COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   __sanitizer_dirent *res = REAL(opendir)(path);\n   if (res)\n     COMMON_INTERCEPTOR_DIR_ACQUIRE(ctx, path);\n@@ -3351,10 +3363,10 @@ INTERCEPTOR(char *, setlocale, int category, char *locale) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, setlocale, category, locale);\n   if (locale)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, locale, REAL(strlen)(locale) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, locale, internal_strlen(locale) + 1);\n   char *res = REAL(setlocale)(category, locale);\n   if (res) {\n-    COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, REAL(strlen)(res) + 1);\n+    COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, internal_strlen(res) + 1);\n     unpoison_ctype_arrays(ctx);\n   }\n   return res;\n@@ -3373,7 +3385,7 @@ INTERCEPTOR(char *, getcwd, char *buf, SIZE_T size) {\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n   char *res = REAL(getcwd)(buf, size);\n-  if (res) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, REAL(strlen)(res) + 1);\n+  if (res) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, internal_strlen(res) + 1);\n   return res;\n }\n #define INIT_GETCWD COMMON_INTERCEPT_FUNCTION(getcwd);\n@@ -3389,7 +3401,7 @@ INTERCEPTOR(char *, get_current_dir_name, int fake) {\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n   char *res = REAL(get_current_dir_name)(fake);\n-  if (res) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, REAL(strlen)(res) + 1);\n+  if (res) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, internal_strlen(res) + 1);\n   return res;\n }\n \n@@ -3663,12 +3675,23 @@ INTERCEPTOR(int, tcgetattr, int fd, void *termios_p) {\n INTERCEPTOR(char *, realpath, const char *path, char *resolved_path) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, realpath, path, resolved_path);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n+\n+  // Workaround a bug in glibc where dlsym(RTLD_NEXT, ...) returns the oldest\n+  // version of a versioned symbol. For realpath(), this gives us something\n+  // (called __old_realpath) that does not handle NULL in the second argument.\n+  // Handle it as part of the interceptor.\n+  char *allocated_path = nullptr;\n+  if (!resolved_path)\n+    allocated_path = resolved_path = (char *)WRAP(malloc)(path_max + 1);\n+\n   char *res = REAL(realpath)(path, resolved_path);\n-  if (res) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, REAL(strlen)(res) + 1);\n+  if (allocated_path && !res)\n+    WRAP(free)(allocated_path);\n+  if (res) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, internal_strlen(res) + 1);\n   return res;\n }\n-#define INIT_REALPATH COMMON_INTERCEPT_FUNCTION_GLIBC_VER_MIN(realpath, \"GLIBC_2.3\");\n+#  define INIT_REALPATH COMMON_INTERCEPT_FUNCTION(realpath);\n #else\n #define INIT_REALPATH\n #endif\n@@ -3677,9 +3700,9 @@ INTERCEPTOR(char *, realpath, const char *path, char *resolved_path) {\n INTERCEPTOR(char *, canonicalize_file_name, const char *path) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, canonicalize_file_name, path);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   char *res = REAL(canonicalize_file_name)(path);\n-  if (res) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, REAL(strlen)(res) + 1);\n+  if (res) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, internal_strlen(res) + 1);\n   return res;\n }\n #define INIT_CANONICALIZE_FILE_NAME \\\n@@ -3740,7 +3763,7 @@ INTERCEPTOR(char *, strerror, int errnum) {\n   COMMON_INTERCEPTOR_ENTER(ctx, strerror, errnum);\n   COMMON_INTERCEPTOR_STRERROR();\n   char *res = REAL(strerror)(errnum);\n-  if (res) COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, REAL(strlen)(res) + 1);\n+  if (res) COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, internal_strlen(res) + 1);\n   return res;\n }\n #define INIT_STRERROR COMMON_INTERCEPT_FUNCTION(strerror);\n@@ -3782,9 +3805,9 @@ INTERCEPTOR(char *, strerror_r, int errnum, char *buf, SIZE_T buflen) {\n   // https://github.com/google/sanitizers/issues/321.\n   char *res = REAL(strerror_r)(errnum, buf, buflen);\n   if (res == buf)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, REAL(strlen)(res) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, internal_strlen(res) + 1);\n   else\n-    COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, REAL(strlen)(res) + 1);\n+    COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, internal_strlen(res) + 1);\n   return res;\n }\n #endif //(_POSIX_C_SOURCE >= 200112L || _XOPEN_SOURCE >= 600) && !_GNU_SOURCE ||\n@@ -3804,7 +3827,7 @@ INTERCEPTOR(int, __xpg_strerror_r, int errnum, char *buf, SIZE_T buflen) {\n   int res = REAL(__xpg_strerror_r)(errnum, buf, buflen);\n   // This version always returns a null-terminated string.\n   if (buf && buflen)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, buf, REAL(strlen)(buf) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, buf, internal_strlen(buf) + 1);\n   return res;\n }\n #define INIT_XPG_STRERROR_R COMMON_INTERCEPT_FUNCTION(__xpg_strerror_r);\n@@ -3840,7 +3863,7 @@ INTERCEPTOR(int, scandir, char *dirp, __sanitizer_dirent ***namelist,\n             scandir_filter_f filter, scandir_compar_f compar) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, scandir, dirp, namelist, filter, compar);\n-  if (dirp) COMMON_INTERCEPTOR_READ_RANGE(ctx, dirp, REAL(strlen)(dirp) + 1);\n+  if (dirp) COMMON_INTERCEPTOR_READ_RANGE(ctx, dirp, internal_strlen(dirp) + 1);\n   scandir_filter = filter;\n   scandir_compar = compar;\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n@@ -3893,7 +3916,7 @@ INTERCEPTOR(int, scandir64, char *dirp, __sanitizer_dirent64 ***namelist,\n             scandir64_filter_f filter, scandir64_compar_f compar) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, scandir64, dirp, namelist, filter, compar);\n-  if (dirp) COMMON_INTERCEPTOR_READ_RANGE(ctx, dirp, REAL(strlen)(dirp) + 1);\n+  if (dirp) COMMON_INTERCEPTOR_READ_RANGE(ctx, dirp, internal_strlen(dirp) + 1);\n   scandir64_filter = filter;\n   scandir64_compar = compar;\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n@@ -3989,19 +4012,20 @@ INTERCEPTOR(int, ppoll, __sanitizer_pollfd *fds, __sanitizer_nfds_t nfds,\n INTERCEPTOR(int, wordexp, char *s, __sanitizer_wordexp_t *p, int flags) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, wordexp, s, p, flags);\n-  if (s) COMMON_INTERCEPTOR_READ_RANGE(ctx, s, REAL(strlen)(s) + 1);\n+  if (s) COMMON_INTERCEPTOR_READ_RANGE(ctx, s, internal_strlen(s) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n   int res = REAL(wordexp)(s, p, flags);\n   if (!res && p) {\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, p, sizeof(*p));\n-    if (p->we_wordc)\n-      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, p->we_wordv,\n-                                     sizeof(*p->we_wordv) * p->we_wordc);\n-    for (uptr i = 0; i < p->we_wordc; ++i) {\n+    uptr we_wordc =\n+        ((flags & wordexp_wrde_dooffs) ? p->we_offs : 0) + p->we_wordc;\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, p->we_wordv,\n+                                   sizeof(*p->we_wordv) * (we_wordc + 1));\n+    for (uptr i = 0; i < we_wordc; ++i) {\n       char *w = p->we_wordv[i];\n-      if (w) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, w, REAL(strlen)(w) + 1);\n+      if (w) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, w, internal_strlen(w) + 1);\n     }\n   }\n   return res;\n@@ -4207,7 +4231,7 @@ INTERCEPTOR(char **, backtrace_symbols, void **buffer, int size) {\n   if (res && size) {\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, size * sizeof(*res));\n     for (int i = 0; i < size; ++i)\n-      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res[i], REAL(strlen(res[i])) + 1);\n+      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res[i], internal_strlen(res[i]) + 1);\n   }\n   return res;\n }\n@@ -4325,16 +4349,16 @@ static void write_mntent(void *ctx, __sanitizer_mntent *mnt) {\n   COMMON_INTERCEPTOR_WRITE_RANGE(ctx, mnt, sizeof(*mnt));\n   if (mnt->mnt_fsname)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, mnt->mnt_fsname,\n-                                   REAL(strlen)(mnt->mnt_fsname) + 1);\n+                                   internal_strlen(mnt->mnt_fsname) + 1);\n   if (mnt->mnt_dir)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, mnt->mnt_dir,\n-                                   REAL(strlen)(mnt->mnt_dir) + 1);\n+                                   internal_strlen(mnt->mnt_dir) + 1);\n   if (mnt->mnt_type)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, mnt->mnt_type,\n-                                   REAL(strlen)(mnt->mnt_type) + 1);\n+                                   internal_strlen(mnt->mnt_type) + 1);\n   if (mnt->mnt_opts)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, mnt->mnt_opts,\n-                                   REAL(strlen)(mnt->mnt_opts) + 1);\n+                                   internal_strlen(mnt->mnt_opts) + 1);\n }\n #endif\n \n@@ -4369,7 +4393,7 @@ INTERCEPTOR(__sanitizer_mntent *, getmntent_r, void *fp,\n INTERCEPTOR(int, statfs, char *path, void *buf) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, statfs, path, buf);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -4398,7 +4422,7 @@ INTERCEPTOR(int, fstatfs, int fd, void *buf) {\n INTERCEPTOR(int, statfs64, char *path, void *buf) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, statfs64, path, buf);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -4427,7 +4451,7 @@ INTERCEPTOR(int, fstatfs64, int fd, void *buf) {\n INTERCEPTOR(int, statvfs, char *path, void *buf) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, statvfs, path, buf);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -4461,7 +4485,7 @@ INTERCEPTOR(int, fstatvfs, int fd, void *buf) {\n INTERCEPTOR(int, statvfs64, char *path, void *buf) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, statvfs64, path, buf);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -4490,7 +4514,7 @@ INTERCEPTOR(int, fstatvfs64, int fd, void *buf) {\n INTERCEPTOR(int, initgroups, char *user, u32 group) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, initgroups, user, group);\n-  if (user) COMMON_INTERCEPTOR_READ_RANGE(ctx, user, REAL(strlen)(user) + 1);\n+  if (user) COMMON_INTERCEPTOR_READ_RANGE(ctx, user, internal_strlen(user) + 1);\n   int res = REAL(initgroups)(user, group);\n   return res;\n }\n@@ -4505,13 +4529,13 @@ INTERCEPTOR(char *, ether_ntoa, __sanitizer_ether_addr *addr) {\n   COMMON_INTERCEPTOR_ENTER(ctx, ether_ntoa, addr);\n   if (addr) COMMON_INTERCEPTOR_READ_RANGE(ctx, addr, sizeof(*addr));\n   char *res = REAL(ether_ntoa)(addr);\n-  if (res) COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, REAL(strlen)(res) + 1);\n+  if (res) COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, internal_strlen(res) + 1);\n   return res;\n }\n INTERCEPTOR(__sanitizer_ether_addr *, ether_aton, char *buf) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, ether_aton, buf);\n-  if (buf) COMMON_INTERCEPTOR_READ_RANGE(ctx, buf, REAL(strlen)(buf) + 1);\n+  if (buf) COMMON_INTERCEPTOR_READ_RANGE(ctx, buf, internal_strlen(buf) + 1);\n   __sanitizer_ether_addr *res = REAL(ether_aton)(buf);\n   if (res) COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, sizeof(*res));\n   return res;\n@@ -4533,14 +4557,14 @@ INTERCEPTOR(int, ether_ntohost, char *hostname, __sanitizer_ether_addr *addr) {\n   // https://github.com/google/sanitizers/issues/321.\n   int res = REAL(ether_ntohost)(hostname, addr);\n   if (!res && hostname)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, hostname, REAL(strlen)(hostname) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, hostname, internal_strlen(hostname) + 1);\n   return res;\n }\n INTERCEPTOR(int, ether_hostton, char *hostname, __sanitizer_ether_addr *addr) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, ether_hostton, hostname, addr);\n   if (hostname)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, hostname, REAL(strlen)(hostname) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, hostname, internal_strlen(hostname) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -4552,15 +4576,15 @@ INTERCEPTOR(int, ether_line, char *line, __sanitizer_ether_addr *addr,\n             char *hostname) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, ether_line, line, addr, hostname);\n-  if (line) COMMON_INTERCEPTOR_READ_RANGE(ctx, line, REAL(strlen)(line) + 1);\n+  if (line) COMMON_INTERCEPTOR_READ_RANGE(ctx, line, internal_strlen(line) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n   int res = REAL(ether_line)(line, addr, hostname);\n   if (!res) {\n     if (addr) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, addr, sizeof(*addr));\n     if (hostname)\n-      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, hostname, REAL(strlen)(hostname) + 1);\n+      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, hostname, internal_strlen(hostname) + 1);\n   }\n   return res;\n }\n@@ -4581,14 +4605,14 @@ INTERCEPTOR(char *, ether_ntoa_r, __sanitizer_ether_addr *addr, char *buf) {\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n   char *res = REAL(ether_ntoa_r)(addr, buf);\n-  if (res) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, REAL(strlen)(res) + 1);\n+  if (res) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, internal_strlen(res) + 1);\n   return res;\n }\n INTERCEPTOR(__sanitizer_ether_addr *, ether_aton_r, char *buf,\n             __sanitizer_ether_addr *addr) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, ether_aton_r, buf, addr);\n-  if (buf) COMMON_INTERCEPTOR_READ_RANGE(ctx, buf, REAL(strlen)(buf) + 1);\n+  if (buf) COMMON_INTERCEPTOR_READ_RANGE(ctx, buf, internal_strlen(buf) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -4854,9 +4878,9 @@ INTERCEPTOR(char *, tmpnam, char *s) {\n       // FIXME: under ASan the call below may write to freed memory and corrupt\n       // its metadata. See\n       // https://github.com/google/sanitizers/issues/321.\n-      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, s, REAL(strlen)(s) + 1);\n+      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, s, internal_strlen(s) + 1);\n     else\n-      COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, REAL(strlen)(res) + 1);\n+      COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, internal_strlen(res) + 1);\n   }\n   return res;\n }\n@@ -4873,7 +4897,7 @@ INTERCEPTOR(char *, tmpnam_r, char *s) {\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n   char *res = REAL(tmpnam_r)(s);\n-  if (res && s) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, s, REAL(strlen)(s) + 1);\n+  if (res && s) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, s, internal_strlen(s) + 1);\n   return res;\n }\n #define INIT_TMPNAM_R COMMON_INTERCEPT_FUNCTION(tmpnam_r);\n@@ -4887,7 +4911,7 @@ INTERCEPTOR(char *, ptsname, int fd) {\n   COMMON_INTERCEPTOR_ENTER(ctx, ptsname, fd);\n   char *res = REAL(ptsname)(fd);\n   if (res != nullptr)\n-    COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, REAL(strlen)(res) + 1);\n+    COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, internal_strlen(res) + 1);\n   return res;\n }\n #define INIT_PTSNAME COMMON_INTERCEPT_FUNCTION(ptsname);\n@@ -4901,7 +4925,7 @@ INTERCEPTOR(int, ptsname_r, int fd, char *name, SIZE_T namesize) {\n   COMMON_INTERCEPTOR_ENTER(ctx, ptsname_r, fd, name, namesize);\n   int res = REAL(ptsname_r)(fd, name, namesize);\n   if (res == 0)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, name, internal_strlen(name) + 1);\n   return res;\n }\n #define INIT_PTSNAME_R COMMON_INTERCEPT_FUNCTION(ptsname_r);\n@@ -4915,7 +4939,7 @@ INTERCEPTOR(char *, ttyname, int fd) {\n   COMMON_INTERCEPTOR_ENTER(ctx, ttyname, fd);\n   char *res = REAL(ttyname)(fd);\n   if (res != nullptr)\n-    COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, REAL(strlen)(res) + 1);\n+    COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, internal_strlen(res) + 1);\n   return res;\n }\n #define INIT_TTYNAME COMMON_INTERCEPT_FUNCTION(ttyname);\n@@ -4929,7 +4953,7 @@ INTERCEPTOR(int, ttyname_r, int fd, char *name, SIZE_T namesize) {\n   COMMON_INTERCEPTOR_ENTER(ctx, ttyname_r, fd, name, namesize);\n   int res = REAL(ttyname_r)(fd, name, namesize);\n   if (res == 0)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, name, internal_strlen(name) + 1);\n   return res;\n }\n #define INIT_TTYNAME_R COMMON_INTERCEPT_FUNCTION(ttyname_r);\n@@ -4941,10 +4965,10 @@ INTERCEPTOR(int, ttyname_r, int fd, char *name, SIZE_T namesize) {\n INTERCEPTOR(char *, tempnam, char *dir, char *pfx) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, tempnam, dir, pfx);\n-  if (dir) COMMON_INTERCEPTOR_READ_RANGE(ctx, dir, REAL(strlen)(dir) + 1);\n-  if (pfx) COMMON_INTERCEPTOR_READ_RANGE(ctx, pfx, REAL(strlen)(pfx) + 1);\n+  if (dir) COMMON_INTERCEPTOR_READ_RANGE(ctx, dir, internal_strlen(dir) + 1);\n+  if (pfx) COMMON_INTERCEPTOR_READ_RANGE(ctx, pfx, internal_strlen(pfx) + 1);\n   char *res = REAL(tempnam)(dir, pfx);\n-  if (res) COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, REAL(strlen)(res) + 1);\n+  if (res) COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, internal_strlen(res) + 1);\n   return res;\n }\n #define INIT_TEMPNAM COMMON_INTERCEPT_FUNCTION(tempnam);\n@@ -5404,7 +5428,7 @@ asm(\n INTERCEPTOR(SSIZE_T, listxattr, const char *path, char *list, SIZE_T size) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, listxattr, path, list, size);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -5417,7 +5441,7 @@ INTERCEPTOR(SSIZE_T, listxattr, const char *path, char *list, SIZE_T size) {\n INTERCEPTOR(SSIZE_T, llistxattr, const char *path, char *list, SIZE_T size) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, llistxattr, path, list, size);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -5448,8 +5472,8 @@ INTERCEPTOR(SSIZE_T, getxattr, const char *path, const char *name, char *value,\n             SIZE_T size) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, getxattr, path, name, value, size);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n-  if (name) COMMON_INTERCEPTOR_READ_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n+  if (name) COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -5461,8 +5485,8 @@ INTERCEPTOR(SSIZE_T, lgetxattr, const char *path, const char *name, char *value,\n             SIZE_T size) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, lgetxattr, path, name, value, size);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n-  if (name) COMMON_INTERCEPTOR_READ_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n+  if (name) COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -5474,7 +5498,7 @@ INTERCEPTOR(SSIZE_T, fgetxattr, int fd, const char *name, char *value,\n             SIZE_T size) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, fgetxattr, fd, name, value, size);\n-  if (name) COMMON_INTERCEPTOR_READ_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+  if (name) COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -5544,7 +5568,7 @@ INTERCEPTOR(int, getifaddrs, __sanitizer_ifaddrs **ifap) {\n       COMMON_INTERCEPTOR_WRITE_RANGE(ctx, p, sizeof(__sanitizer_ifaddrs));\n       if (p->ifa_name)\n         COMMON_INTERCEPTOR_WRITE_RANGE(ctx, p->ifa_name,\n-                                       REAL(strlen)(p->ifa_name) + 1);\n+                                       internal_strlen(p->ifa_name) + 1);\n       if (p->ifa_addr)\n         COMMON_INTERCEPTOR_WRITE_RANGE(ctx, p->ifa_addr, struct_sockaddr_sz);\n       if (p->ifa_netmask)\n@@ -5574,14 +5598,14 @@ INTERCEPTOR(char *, if_indextoname, unsigned int ifindex, char* ifname) {\n   // https://github.com/google/sanitizers/issues/321.\n   char *res = REAL(if_indextoname)(ifindex, ifname);\n   if (res && ifname)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ifname, REAL(strlen)(ifname) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ifname, internal_strlen(ifname) + 1);\n   return res;\n }\n INTERCEPTOR(unsigned int, if_nametoindex, const char* ifname) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, if_nametoindex, ifname);\n   if (ifname)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, ifname, REAL(strlen)(ifname) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, ifname, internal_strlen(ifname) + 1);\n   return REAL(if_nametoindex)(ifname);\n }\n #define INIT_IF_INDEXTONAME                  \\\n@@ -5839,7 +5863,7 @@ INTERCEPTOR(int, xdr_string, __sanitizer_XDR *xdrs, char **p,\n   COMMON_INTERCEPTOR_ENTER(ctx, xdr_string, xdrs, p, maxsize);\n   if (p && xdrs->x_op == __sanitizer_XDR_ENCODE) {\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, p, sizeof(*p));\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, *p, REAL(strlen)(*p) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, *p, internal_strlen(*p) + 1);\n   }\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n@@ -5848,7 +5872,7 @@ INTERCEPTOR(int, xdr_string, __sanitizer_XDR *xdrs, char **p,\n   if (p && xdrs->x_op == __sanitizer_XDR_DECODE) {\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, p, sizeof(*p));\n     if (res && *p)\n-      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *p, REAL(strlen)(*p) + 1);\n+      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *p, internal_strlen(*p) + 1);\n   }\n   return res;\n }\n@@ -6059,8 +6083,8 @@ INTERCEPTOR(int, __woverflow, __sanitizer_FILE *fp, int ch) {\n INTERCEPTOR(__sanitizer_FILE *, fopen, const char *path, const char *mode) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, fopen, path, mode);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n-  COMMON_INTERCEPTOR_READ_RANGE(ctx, mode, REAL(strlen)(mode) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n+  COMMON_INTERCEPTOR_READ_RANGE(ctx, mode, internal_strlen(mode) + 1);\n   __sanitizer_FILE *res = REAL(fopen)(path, mode);\n   COMMON_INTERCEPTOR_FILE_OPEN(ctx, res, path);\n   if (res) unpoison_file(res);\n@@ -6069,7 +6093,7 @@ INTERCEPTOR(__sanitizer_FILE *, fopen, const char *path, const char *mode) {\n INTERCEPTOR(__sanitizer_FILE *, fdopen, int fd, const char *mode) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, fdopen, fd, mode);\n-  COMMON_INTERCEPTOR_READ_RANGE(ctx, mode, REAL(strlen)(mode) + 1);\n+  COMMON_INTERCEPTOR_READ_RANGE(ctx, mode, internal_strlen(mode) + 1);\n   __sanitizer_FILE *res = REAL(fdopen)(fd, mode);\n   if (res) unpoison_file(res);\n   return res;\n@@ -6078,8 +6102,8 @@ INTERCEPTOR(__sanitizer_FILE *, freopen, const char *path, const char *mode,\n             __sanitizer_FILE *fp) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, freopen, path, mode, fp);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n-  COMMON_INTERCEPTOR_READ_RANGE(ctx, mode, REAL(strlen)(mode) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n+  COMMON_INTERCEPTOR_READ_RANGE(ctx, mode, internal_strlen(mode) + 1);\n   COMMON_INTERCEPTOR_FILE_CLOSE(ctx, fp);\n   __sanitizer_FILE *res = REAL(freopen)(path, mode, fp);\n   COMMON_INTERCEPTOR_FILE_OPEN(ctx, res, path);\n@@ -6103,7 +6127,7 @@ INTERCEPTOR(int, flopen, const char *path, int flags, ...) {\n   va_end(ap);\n   COMMON_INTERCEPTOR_ENTER(ctx, flopen, path, flags, mode);\n   if (path) {\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   }\n   return REAL(flopen)(path, flags, mode);\n }\n@@ -6116,7 +6140,7 @@ INTERCEPTOR(int, flopenat, int dirfd, const char *path, int flags, ...) {\n   va_end(ap);\n   COMMON_INTERCEPTOR_ENTER(ctx, flopen, path, flags, mode);\n   if (path) {\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   }\n   return REAL(flopenat)(dirfd, path, flags, mode);\n }\n@@ -6132,8 +6156,8 @@ INTERCEPTOR(int, flopenat, int dirfd, const char *path, int flags, ...) {\n INTERCEPTOR(__sanitizer_FILE *, fopen64, const char *path, const char *mode) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, fopen64, path, mode);\n-  COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n-  COMMON_INTERCEPTOR_READ_RANGE(ctx, mode, REAL(strlen)(mode) + 1);\n+  COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n+  COMMON_INTERCEPTOR_READ_RANGE(ctx, mode, internal_strlen(mode) + 1);\n   __sanitizer_FILE *res = REAL(fopen64)(path, mode);\n   COMMON_INTERCEPTOR_FILE_OPEN(ctx, res, path);\n   if (res) unpoison_file(res);\n@@ -6143,8 +6167,8 @@ INTERCEPTOR(__sanitizer_FILE *, freopen64, const char *path, const char *mode,\n             __sanitizer_FILE *fp) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, freopen64, path, mode, fp);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n-  COMMON_INTERCEPTOR_READ_RANGE(ctx, mode, REAL(strlen)(mode) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n+  COMMON_INTERCEPTOR_READ_RANGE(ctx, mode, internal_strlen(mode) + 1);\n   COMMON_INTERCEPTOR_FILE_CLOSE(ctx, fp);\n   __sanitizer_FILE *res = REAL(freopen64)(path, mode, fp);\n   COMMON_INTERCEPTOR_FILE_OPEN(ctx, res, path);\n@@ -6322,9 +6346,9 @@ INTERCEPTOR(char *, getpass, const char *prompt) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, getpass, prompt);\n   if (prompt)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, prompt, REAL(strlen)(prompt)+1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, prompt, internal_strlen(prompt)+1);\n   char *res = REAL(getpass)(prompt);\n-  if (res) COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, REAL(strlen)(res)+1);\n+  if (res) COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, internal_strlen(res)+1);\n   return res;\n }\n \n@@ -6528,17 +6552,42 @@ INTERCEPTOR(int, sem_getvalue, __sanitizer_sem_t *s, int *sval) {\n   }\n   return res;\n }\n-#define INIT_SEM                                                               \\\n-  COMMON_INTERCEPT_FUNCTION(sem_init);                                         \\\n-  COMMON_INTERCEPT_FUNCTION(sem_destroy);                                      \\\n-  COMMON_INTERCEPT_FUNCTION(sem_wait);                                         \\\n-  COMMON_INTERCEPT_FUNCTION(sem_trywait);                                      \\\n-  COMMON_INTERCEPT_FUNCTION(sem_timedwait);                                    \\\n-  COMMON_INTERCEPT_FUNCTION(sem_post);                                         \\\n-  COMMON_INTERCEPT_FUNCTION(sem_getvalue);\n+\n+INTERCEPTOR(__sanitizer_sem_t *, sem_open, const char *name, int oflag, ...) {\n+  void *ctx;\n+  va_list ap;\n+  va_start(ap, oflag);\n+  u32 mode = va_arg(ap, u32);\n+  u32 value = va_arg(ap, u32);\n+  COMMON_INTERCEPTOR_ENTER(ctx, sem_open, name, oflag, mode, value);\n+  COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n+  __sanitizer_sem_t *s = REAL(sem_open)(name, oflag, mode, value);\n+  if (s)\n+    COMMON_INTERCEPTOR_INITIALIZE_RANGE(s, sizeof(*s));\n+  va_end(ap);\n+  return s;\n+}\n+\n+INTERCEPTOR(int, sem_unlink, const char *name) {\n+  void *ctx;\n+  COMMON_INTERCEPTOR_ENTER(ctx, sem_unlink, name);\n+  COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n+  return REAL(sem_unlink)(name);\n+}\n+\n+#  define INIT_SEM                            \\\n+    COMMON_INTERCEPT_FUNCTION(sem_init);      \\\n+    COMMON_INTERCEPT_FUNCTION(sem_destroy);   \\\n+    COMMON_INTERCEPT_FUNCTION(sem_wait);      \\\n+    COMMON_INTERCEPT_FUNCTION(sem_trywait);   \\\n+    COMMON_INTERCEPT_FUNCTION(sem_timedwait); \\\n+    COMMON_INTERCEPT_FUNCTION(sem_post);      \\\n+    COMMON_INTERCEPT_FUNCTION(sem_getvalue);  \\\n+    COMMON_INTERCEPT_FUNCTION(sem_open);      \\\n+    COMMON_INTERCEPT_FUNCTION(sem_unlink);\n #else\n-#define INIT_SEM\n-#endif // SANITIZER_INTERCEPT_SEM\n+#  define INIT_SEM\n+#endif  // SANITIZER_INTERCEPT_SEM\n \n #if SANITIZER_INTERCEPT_PTHREAD_SETCANCEL\n INTERCEPTOR(int, pthread_setcancelstate, int state, int *oldstate) {\n@@ -6621,7 +6670,7 @@ INTERCEPTOR(char *, ctermid, char *s) {\n   COMMON_INTERCEPTOR_ENTER(ctx, ctermid, s);\n   char *res = REAL(ctermid)(s);\n   if (res) {\n-    COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, REAL(strlen)(res) + 1);\n+    COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, internal_strlen(res) + 1);\n   }\n   return res;\n }\n@@ -6636,7 +6685,7 @@ INTERCEPTOR(char *, ctermid_r, char *s) {\n   COMMON_INTERCEPTOR_ENTER(ctx, ctermid_r, s);\n   char *res = REAL(ctermid_r)(s);\n   if (res) {\n-    COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, REAL(strlen)(res) + 1);\n+    COMMON_INTERCEPTOR_INITIALIZE_RANGE(res, internal_strlen(res) + 1);\n   }\n   return res;\n }\n@@ -6973,8 +7022,8 @@ INTERCEPTOR(SIZE_T, wcsnlen, const wchar_t *s, SIZE_T n) {\n INTERCEPTOR(wchar_t *, wcscat, wchar_t *dst, const wchar_t *src) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, wcscat, dst, src);\n-  SIZE_T src_size = REAL(wcslen)(src);\n-  SIZE_T dst_size = REAL(wcslen)(dst);\n+  SIZE_T src_size = internal_wcslen(src);\n+  SIZE_T dst_size = internal_wcslen(dst);\n   COMMON_INTERCEPTOR_READ_RANGE(ctx, src, (src_size + 1) * sizeof(wchar_t));\n   COMMON_INTERCEPTOR_READ_RANGE(ctx, dst, (dst_size + 1) * sizeof(wchar_t));\n   COMMON_INTERCEPTOR_WRITE_RANGE(ctx, dst + dst_size,\n@@ -6985,8 +7034,8 @@ INTERCEPTOR(wchar_t *, wcscat, wchar_t *dst, const wchar_t *src) {\n INTERCEPTOR(wchar_t *, wcsncat, wchar_t *dst, const wchar_t *src, SIZE_T n) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, wcsncat, dst, src, n);\n-  SIZE_T src_size = REAL(wcsnlen)(src, n);\n-  SIZE_T dst_size = REAL(wcslen)(dst);\n+  SIZE_T src_size = internal_wcsnlen(src, n);\n+  SIZE_T dst_size = internal_wcslen(dst);\n   COMMON_INTERCEPTOR_READ_RANGE(ctx, src,\n                                 Min(src_size + 1, n) * sizeof(wchar_t));\n   COMMON_INTERCEPTOR_READ_RANGE(ctx, dst, (dst_size + 1) * sizeof(wchar_t));\n@@ -7005,7 +7054,7 @@ INTERCEPTOR(wchar_t *, wcsncat, wchar_t *dst, const wchar_t *src, SIZE_T n) {\n INTERCEPTOR(wchar_t *, wcsdup, wchar_t *s) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, wcsdup, s);\n-  SIZE_T len = REAL(wcslen)(s);\n+  SIZE_T len = internal_wcslen(s);\n   COMMON_INTERCEPTOR_READ_RANGE(ctx, s, sizeof(wchar_t) * (len + 1));\n   wchar_t *result = REAL(wcsdup)(s);\n   if (result)\n@@ -7019,9 +7068,9 @@ INTERCEPTOR(wchar_t *, wcsdup, wchar_t *s) {\n #endif\n \n #if SANITIZER_INTERCEPT_STRXFRM\n-static SIZE_T RealStrLen(const char *str) { return REAL(strlen)(str); }\n+static SIZE_T RealStrLen(const char *str) { return internal_strlen(str); }\n \n-static SIZE_T RealStrLen(const wchar_t *str) { return REAL(wcslen)(str); }\n+static SIZE_T RealStrLen(const wchar_t *str) { return internal_wcslen(str); }\n \n #define STRXFRM_INTERCEPTOR_IMPL(strxfrm, dest, src, len, ...)             \\\n   {                                                                        \\\n@@ -7095,7 +7144,7 @@ INTERCEPTOR(int, acct, const char *file) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, acct, file);\n   if (file)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, file, REAL(strlen)(file) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, file, internal_strlen(file) + 1);\n   return REAL(acct)(file);\n }\n #define INIT_ACCT COMMON_INTERCEPT_FUNCTION(acct)\n@@ -7110,7 +7159,7 @@ INTERCEPTOR(const char *, user_from_uid, u32 uid, int nouser) {\n   COMMON_INTERCEPTOR_ENTER(ctx, user_from_uid, uid, nouser);\n   user = REAL(user_from_uid)(uid, nouser);\n   if (user)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, user, REAL(strlen)(user) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, user, internal_strlen(user) + 1);\n   return user;\n }\n #define INIT_USER_FROM_UID COMMON_INTERCEPT_FUNCTION(user_from_uid)\n@@ -7124,7 +7173,7 @@ INTERCEPTOR(int, uid_from_user, const char *name, u32 *uid) {\n   int res;\n   COMMON_INTERCEPTOR_ENTER(ctx, uid_from_user, name, uid);\n   if (name)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n   res = REAL(uid_from_user)(name, uid);\n   if (uid)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, uid, sizeof(*uid));\n@@ -7142,7 +7191,7 @@ INTERCEPTOR(const char *, group_from_gid, u32 gid, int nogroup) {\n   COMMON_INTERCEPTOR_ENTER(ctx, group_from_gid, gid, nogroup);\n   group = REAL(group_from_gid)(gid, nogroup);\n   if (group)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, group, REAL(strlen)(group) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, group, internal_strlen(group) + 1);\n   return group;\n }\n #define INIT_GROUP_FROM_GID COMMON_INTERCEPT_FUNCTION(group_from_gid)\n@@ -7156,7 +7205,7 @@ INTERCEPTOR(int, gid_from_group, const char *group, u32 *gid) {\n   int res;\n   COMMON_INTERCEPTOR_ENTER(ctx, gid_from_group, group, gid);\n   if (group)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, group, REAL(strlen)(group) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, group, internal_strlen(group) + 1);\n   res = REAL(gid_from_group)(group, gid);\n   if (gid)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, gid, sizeof(*gid));\n@@ -7172,7 +7221,7 @@ INTERCEPTOR(int, access, const char *path, int mode) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, access, path, mode);\n   if (path)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   return REAL(access)(path, mode);\n }\n #define INIT_ACCESS COMMON_INTERCEPT_FUNCTION(access)\n@@ -7185,7 +7234,7 @@ INTERCEPTOR(int, faccessat, int fd, const char *path, int mode, int flags) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, faccessat, fd, path, mode, flags);\n   if (path)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   return REAL(faccessat)(fd, path, mode, flags);\n }\n #define INIT_FACCESSAT COMMON_INTERCEPT_FUNCTION(faccessat)\n@@ -7200,7 +7249,7 @@ INTERCEPTOR(int, getgrouplist, const char *name, u32 basegid, u32 *groups,\n   int res;\n   COMMON_INTERCEPTOR_ENTER(ctx, getgrouplist, name, basegid, groups, ngroups);\n   if (name)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n   if (ngroups)\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, ngroups, sizeof(*ngroups));\n   res = REAL(getgrouplist)(name, basegid, groups, ngroups);\n@@ -7224,7 +7273,7 @@ INTERCEPTOR(int, getgroupmembership, const char *name, u32 basegid, u32 *groups,\n   COMMON_INTERCEPTOR_ENTER(ctx, getgroupmembership, name, basegid, groups,\n                            maxgrp, ngroups);\n   if (name)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n   res = REAL(getgroupmembership)(name, basegid, groups, maxgrp, ngroups);\n   if (!res && groups && ngroups) {\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, groups, sizeof(*groups) * (*ngroups));\n@@ -7242,7 +7291,7 @@ INTERCEPTOR(int, getgroupmembership, const char *name, u32 basegid, u32 *groups,\n INTERCEPTOR(SSIZE_T, readlink, const char *path, char *buf, SIZE_T bufsiz) {\n   void* ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, readlink, path, buf, bufsiz);\n-  COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+  COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   SSIZE_T res = REAL(readlink)(path, buf, bufsiz);\n   if (res > 0)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, buf, res);\n@@ -7259,7 +7308,7 @@ INTERCEPTOR(SSIZE_T, readlinkat, int dirfd, const char *path, char *buf,\n             SIZE_T bufsiz) {\n   void* ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, readlinkat, dirfd, path, buf, bufsiz);\n-  COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+  COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   SSIZE_T res = REAL(readlinkat)(dirfd, path, buf, bufsiz);\n   if (res > 0)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, buf, res);\n@@ -7277,7 +7326,7 @@ INTERCEPTOR(int, name_to_handle_at, int dirfd, const char *pathname,\n   void* ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, name_to_handle_at, dirfd, pathname, handle,\n                            mount_id, flags);\n-  COMMON_INTERCEPTOR_READ_RANGE(ctx, pathname, REAL(strlen)(pathname) + 1);\n+  COMMON_INTERCEPTOR_READ_RANGE(ctx, pathname, internal_strlen(pathname) + 1);\n \n   __sanitizer_file_handle *sanitizer_handle =\n       reinterpret_cast<__sanitizer_file_handle*>(handle);\n@@ -7341,7 +7390,7 @@ INTERCEPTOR(SIZE_T, strlcpy, char *dst, char *src, SIZE_T size) {\n         ctx, src, Min(internal_strnlen(src, size), size - 1) + 1);\n   }\n   res = REAL(strlcpy)(dst, src, size);\n-  COMMON_INTERCEPTOR_COPY_STRING(ctx, dst, src, REAL(strlen)(dst) + 1);\n+  COMMON_INTERCEPTOR_COPY_STRING(ctx, dst, src, internal_strlen(dst) + 1);\n   return res;\n }\n \n@@ -7416,7 +7465,7 @@ INTERCEPTOR(char *, devname, u64 dev, u32 type) {\n   COMMON_INTERCEPTOR_ENTER(ctx, devname, dev, type);\n   name = REAL(devname)(dev, type);\n   if (name)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, name, internal_strlen(name) + 1);\n   return name;\n }\n #define INIT_DEVNAME COMMON_INTERCEPT_FUNCTION(devname);\n@@ -7438,7 +7487,7 @@ INTERCEPTOR(DEVNAME_R_RETTYPE, devname_r, u64 dev, u32 type, char *path,\n   COMMON_INTERCEPTOR_ENTER(ctx, devname_r, dev, type, path, len);\n   DEVNAME_R_RETTYPE res = REAL(devname_r)(dev, type, path, len);\n   if (DEVNAME_R_SUCCESS(res))\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, path, internal_strlen(path) + 1);\n   return res;\n }\n #define INIT_DEVNAME_R COMMON_INTERCEPT_FUNCTION(devname_r);\n@@ -7468,7 +7517,7 @@ INTERCEPTOR(void, strmode, u32 mode, char *bp) {\n   COMMON_INTERCEPTOR_ENTER(ctx, strmode, mode, bp);\n   REAL(strmode)(mode, bp);\n   if (bp)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, bp, REAL(strlen)(bp) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, bp, internal_strlen(bp) + 1);\n }\n #define INIT_STRMODE COMMON_INTERCEPT_FUNCTION(strmode)\n #else\n@@ -7488,37 +7537,42 @@ INTERCEPTOR(struct __sanitizer_ttyent *, getttynam, char *name) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, getttynam, name);\n   if (name)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n   struct __sanitizer_ttyent *ttyent = REAL(getttynam)(name);\n   if (ttyent)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ttyent, struct_ttyent_sz);\n   return ttyent;\n }\n+#define INIT_TTYENT \\\n+  COMMON_INTERCEPT_FUNCTION(getttyent); \\\n+  COMMON_INTERCEPT_FUNCTION(getttynam);\n+#else\n+#define INIT_TTYENT\n+#endif\n+\n+#if SANITIZER_INTERCEPT_TTYENTPATH\n INTERCEPTOR(int, setttyentpath, char *path) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, setttyentpath, path);\n   if (path)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   return REAL(setttyentpath)(path);\n }\n-#define INIT_TTYENT \\\n-  COMMON_INTERCEPT_FUNCTION(getttyent); \\\n-  COMMON_INTERCEPT_FUNCTION(getttynam); \\\n-  COMMON_INTERCEPT_FUNCTION(setttyentpath)\n+#define INIT_TTYENTPATH COMMON_INTERCEPT_FUNCTION(setttyentpath);\n #else\n-#define INIT_TTYENT\n+#define INIT_TTYENTPATH\n #endif\n \n #if SANITIZER_INTERCEPT_PROTOENT\n static void write_protoent(void *ctx, struct __sanitizer_protoent *p) {\n   COMMON_INTERCEPTOR_WRITE_RANGE(ctx, p, sizeof(*p));\n \n-  COMMON_INTERCEPTOR_WRITE_RANGE(ctx, p->p_name, REAL(strlen)(p->p_name) + 1);\n+  COMMON_INTERCEPTOR_WRITE_RANGE(ctx, p->p_name, internal_strlen(p->p_name) + 1);\n \n   SIZE_T pp_size = 1; // One handles the trailing \\0\n \n   for (char **pp = p->p_aliases; *pp; ++pp, ++pp_size)\n-      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *pp, REAL(strlen)(*pp) + 1);\n+      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *pp, internal_strlen(*pp) + 1);\n \n   COMMON_INTERCEPTOR_WRITE_RANGE(ctx, p->p_aliases,\n                                   pp_size * sizeof(char **));\n@@ -7537,7 +7591,7 @@ INTERCEPTOR(struct __sanitizer_protoent *, getprotobyname, const char *name) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, getprotobyname, name);\n   if (name)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n   struct __sanitizer_protoent *p = REAL(getprotobyname)(name);\n   if (p)\n     write_protoent(ctx, p);\n@@ -7581,7 +7635,7 @@ INTERCEPTOR(int, getprotobyname_r, const char *name,\n   COMMON_INTERCEPTOR_ENTER(ctx, getprotobyname_r, name, result_buf, buf,\n                            buflen, result);\n   if (name)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n   int res = REAL(getprotobyname_r)(name, result_buf, buf, buflen, result);\n \n   COMMON_INTERCEPTOR_WRITE_RANGE(ctx, result, sizeof *result);\n@@ -7620,12 +7674,12 @@ INTERCEPTOR(struct __sanitizer_netent *, getnetent) {\n   if (n) {\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, n, sizeof(*n));\n \n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, n->n_name, REAL(strlen)(n->n_name) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, n->n_name, internal_strlen(n->n_name) + 1);\n \n     SIZE_T nn_size = 1; // One handles the trailing \\0\n \n     for (char **nn = n->n_aliases; *nn; ++nn, ++nn_size)\n-      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *nn, REAL(strlen)(*nn) + 1);\n+      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *nn, internal_strlen(*nn) + 1);\n \n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, n->n_aliases,\n                                    nn_size * sizeof(char **));\n@@ -7637,17 +7691,17 @@ INTERCEPTOR(struct __sanitizer_netent *, getnetbyname, const char *name) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, getnetbyname, name);\n   if (name)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n   struct __sanitizer_netent *n = REAL(getnetbyname)(name);\n   if (n) {\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, n, sizeof(*n));\n \n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, n->n_name, REAL(strlen)(n->n_name) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, n->n_name, internal_strlen(n->n_name) + 1);\n \n     SIZE_T nn_size = 1; // One handles the trailing \\0\n \n     for (char **nn = n->n_aliases; *nn; ++nn, ++nn_size)\n-      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *nn, REAL(strlen)(*nn) + 1);\n+      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *nn, internal_strlen(*nn) + 1);\n \n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, n->n_aliases,\n                                    nn_size * sizeof(char **));\n@@ -7662,12 +7716,12 @@ INTERCEPTOR(struct __sanitizer_netent *, getnetbyaddr, u32 net, int type) {\n   if (n) {\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, n, sizeof(*n));\n \n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, n->n_name, REAL(strlen)(n->n_name) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, n->n_name, internal_strlen(n->n_name) + 1);\n \n     SIZE_T nn_size = 1; // One handles the trailing \\0\n \n     for (char **nn = n->n_aliases; *nn; ++nn, ++nn_size)\n-      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *nn, REAL(strlen)(*nn) + 1);\n+      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *nn, internal_strlen(*nn) + 1);\n \n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, n->n_aliases,\n                                    nn_size * sizeof(char **));\n@@ -7788,7 +7842,7 @@ INTERCEPTOR(int, regcomp, void *preg, const char *pattern, int cflags) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, regcomp, preg, pattern, cflags);\n   if (pattern)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, pattern, REAL(strlen)(pattern) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, pattern, internal_strlen(pattern) + 1);\n   int res = REAL(regcomp)(preg, pattern, cflags);\n   if (!res)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, preg, struct_regex_sz);\n@@ -7801,7 +7855,7 @@ INTERCEPTOR(int, regexec, const void *preg, const char *string, SIZE_T nmatch,\n   if (preg)\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, preg, struct_regex_sz);\n   if (string)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, string, REAL(strlen)(string) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, string, internal_strlen(string) + 1);\n   int res = REAL(regexec)(preg, string, nmatch, pmatch, eflags);\n   if (!res && pmatch)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, pmatch, nmatch * struct_regmatch_sz);\n@@ -7815,7 +7869,7 @@ INTERCEPTOR(SIZE_T, regerror, int errcode, const void *preg, char *errbuf,\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, preg, struct_regex_sz);\n   SIZE_T res = REAL(regerror)(errcode, preg, errbuf, errbuf_size);\n   if (errbuf)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, errbuf, REAL(strlen)(errbuf) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, errbuf, internal_strlen(errbuf) + 1);\n   return res;\n }\n INTERCEPTOR(void, regfree, const void *preg) {\n@@ -7840,32 +7894,32 @@ INTERCEPTOR(SSIZE_T, regnsub, char *buf, SIZE_T bufsiz, const char *sub,\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, regnsub, buf, bufsiz, sub, rm, str);\n   if (sub)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, sub, REAL(strlen)(sub) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, sub, internal_strlen(sub) + 1);\n   // The implementation demands and hardcodes 10 elements\n   if (rm)\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, rm, 10 * struct_regmatch_sz);\n   if (str)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, str, REAL(strlen)(str) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, str, internal_strlen(str) + 1);\n   SSIZE_T res = REAL(regnsub)(buf, bufsiz, sub, rm, str);\n   if (res > 0 && buf)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, buf, REAL(strlen)(buf) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, buf, internal_strlen(buf) + 1);\n   return res;\n }\n INTERCEPTOR(SSIZE_T, regasub, char **buf, const char *sub,\n             const struct __sanitizer_regmatch *rm, const char *sstr) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, regasub, buf, sub, rm, sstr);\n   if (sub)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, sub, REAL(strlen)(sub) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, sub, internal_strlen(sub) + 1);\n   // Hardcode 10 elements as this is hardcoded size\n   if (rm)\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, rm, 10 * struct_regmatch_sz);\n   if (sstr)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, sstr, REAL(strlen)(sstr) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, sstr, internal_strlen(sstr) + 1);\n   SSIZE_T res = REAL(regasub)(buf, sub, rm, sstr);\n   if (res > 0 && buf) {\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, buf, sizeof(char *));\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *buf, REAL(strlen)(*buf) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *buf, internal_strlen(*buf) + 1);\n   }\n   return res;\n }\n@@ -7887,7 +7941,7 @@ INTERCEPTOR(void *, fts_open, char *const *path_argv, int options,\n       COMMON_INTERCEPTOR_READ_RANGE(ctx, pa, sizeof(char **));\n       if (!*pa)\n         break;\n-      COMMON_INTERCEPTOR_READ_RANGE(ctx, *pa, REAL(strlen)(*pa) + 1);\n+      COMMON_INTERCEPTOR_READ_RANGE(ctx, *pa, internal_strlen(*pa) + 1);\n     }\n   }\n   // TODO(kamil): handle compar callback\n@@ -7979,7 +8033,7 @@ INTERCEPTOR(int, sysctlbyname, char *sname, void *oldp, SIZE_T *oldlenp,\n   COMMON_INTERCEPTOR_ENTER(ctx, sysctlbyname, sname, oldp, oldlenp, newp,\n                            newlen);\n   if (sname)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, sname, REAL(strlen)(sname) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, sname, internal_strlen(sname) + 1);\n   if (oldlenp)\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, oldlenp, sizeof(*oldlenp));\n   if (newp && newlen)\n@@ -8000,7 +8054,7 @@ INTERCEPTOR(int, sysctlnametomib, const char *sname, int *name,\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, sysctlnametomib, sname, name, namelenp);\n   if (sname)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, sname, REAL(strlen)(sname) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, sname, internal_strlen(sname) + 1);\n   if (namelenp)\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, namelenp, sizeof(*namelenp));\n   int res = REAL(sysctlnametomib)(sname, name, namelenp);\n@@ -8040,7 +8094,7 @@ INTERCEPTOR(void *, asysctlbyname, const char *sname, SIZE_T *len) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, asysctlbyname, sname, len);\n   if (sname)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, sname, REAL(strlen)(sname) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, sname, internal_strlen(sname) + 1);\n   void *res = REAL(asysctlbyname)(sname, len);\n   if (res && len) {\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, len, sizeof(*len));\n@@ -8063,7 +8117,7 @@ INTERCEPTOR(int, sysctlgetmibinfo, char *sname, int *name,\n   COMMON_INTERCEPTOR_ENTER(ctx, sysctlgetmibinfo, sname, name, namelenp, cname,\n                            csz, rnode, v);\n   if (sname)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, sname, REAL(strlen)(sname) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, sname, internal_strlen(sname) + 1);\n   if (namelenp)\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, namelenp, sizeof(*namelenp));\n   if (csz)\n@@ -8097,7 +8151,7 @@ INTERCEPTOR(char *, nl_langinfo, long item) {\n   COMMON_INTERCEPTOR_ENTER(ctx, nl_langinfo, item);\n   char *ret = REAL(nl_langinfo)(item);\n   if (ret)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ret, REAL(strlen)(ret) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ret, internal_strlen(ret) + 1);\n   return ret;\n }\n #define INIT_NL_LANGINFO COMMON_INTERCEPT_FUNCTION(nl_langinfo)\n@@ -8117,15 +8171,15 @@ INTERCEPTOR(int, modctl, int operation, void *argp) {\n       COMMON_INTERCEPTOR_READ_RANGE(ctx, ml, sizeof(*ml));\n       if (ml->ml_filename)\n         COMMON_INTERCEPTOR_READ_RANGE(ctx, ml->ml_filename,\n-                                      REAL(strlen)(ml->ml_filename) + 1);\n+                                      internal_strlen(ml->ml_filename) + 1);\n       if (ml->ml_props)\n         COMMON_INTERCEPTOR_READ_RANGE(ctx, ml->ml_props, ml->ml_propslen);\n     }\n     ret = REAL(modctl)(operation, argp);\n   } else if (operation == modctl_unload) {\n     if (argp) {\n       const char *name = (const char *)argp;\n-      COMMON_INTERCEPTOR_READ_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+      COMMON_INTERCEPTOR_READ_RANGE(ctx, name, internal_strlen(name) + 1);\n     }\n     ret = REAL(modctl)(operation, argp);\n   } else if (operation == modctl_stat) {\n@@ -8167,7 +8221,7 @@ INTERCEPTOR(long long, strtonum, const char *nptr, long long minval,\n   if (errstr) {\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, errstr, sizeof(const char *));\n      if (*errstr)\n-      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *errstr, REAL(strlen)(*errstr) + 1);\n+      COMMON_INTERCEPTOR_WRITE_RANGE(ctx, *errstr, internal_strlen(*errstr) + 1);\n   }\n   return ret;\n }\n@@ -8187,7 +8241,7 @@ INTERCEPTOR(char *, fparseln, __sanitizer_FILE *stream, SIZE_T *len,\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, delim, sizeof(delim[0]) * 3);\n   char *ret = REAL(fparseln)(stream, len, lineno, delim, flags);\n   if (ret) {\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ret, REAL(strlen)(ret) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ret, internal_strlen(ret) + 1);\n     if (len)\n       COMMON_INTERCEPTOR_WRITE_RANGE(ctx, len, sizeof(*len));\n     if (lineno)\n@@ -8204,7 +8258,7 @@ INTERCEPTOR(char *, fparseln, __sanitizer_FILE *stream, SIZE_T *len,\n INTERCEPTOR(int, statvfs1, const char *path, void *buf, int flags) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, statvfs1, path, buf, flags);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   int res = REAL(statvfs1)(path, buf, flags);\n   if (!res) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, buf, struct_statvfs_sz);\n   return res;\n@@ -8485,7 +8539,7 @@ INTERCEPTOR(char *, SHA1File, char *filename, char *buf) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, SHA1File, filename, buf);\n   if (filename)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, REAL(strlen)(filename) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, internal_strlen(filename) + 1);\n   char *ret = REAL(SHA1File)(filename, buf);\n   if (ret)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ret, SHA1_return_length);\n@@ -8496,7 +8550,7 @@ INTERCEPTOR(char *, SHA1FileChunk, char *filename, char *buf, OFF_T offset,\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, SHA1FileChunk, filename, buf, offset, length);\n   if (filename)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, REAL(strlen)(filename) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, internal_strlen(filename) + 1);\n   char *ret = REAL(SHA1FileChunk)(filename, buf, offset, length);\n   if (ret)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ret, SHA1_return_length);\n@@ -8572,7 +8626,7 @@ INTERCEPTOR(char *, MD4File, const char *filename, char *buf) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, MD4File, filename, buf);\n   if (filename)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, REAL(strlen)(filename) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, internal_strlen(filename) + 1);\n   char *ret = REAL(MD4File)(filename, buf);\n   if (ret)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ret, MD4_return_length);\n@@ -8655,7 +8709,7 @@ INTERCEPTOR(char *, RMD160File, char *filename, char *buf) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, RMD160File, filename, buf);\n   if (filename)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, REAL(strlen)(filename) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, internal_strlen(filename) + 1);\n   char *ret = REAL(RMD160File)(filename, buf);\n   if (ret)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ret, RMD160_return_length);\n@@ -8666,7 +8720,7 @@ INTERCEPTOR(char *, RMD160FileChunk, char *filename, char *buf, OFF_T offset,\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, RMD160FileChunk, filename, buf, offset, length);\n   if (filename)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, REAL(strlen)(filename) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, internal_strlen(filename) + 1);\n   char *ret = REAL(RMD160FileChunk)(filename, buf, offset, length);\n   if (ret)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ret, RMD160_return_length);\n@@ -8742,7 +8796,7 @@ INTERCEPTOR(char *, MD5File, const char *filename, char *buf) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, MD5File, filename, buf);\n   if (filename)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, REAL(strlen)(filename) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, internal_strlen(filename) + 1);\n   char *ret = REAL(MD5File)(filename, buf);\n   if (ret)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ret, MD5_return_length);\n@@ -8872,7 +8926,7 @@ INTERCEPTOR(char *, MD2File, const char *filename, char *buf) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, MD2File, filename, buf);\n   if (filename)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, REAL(strlen)(filename) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, internal_strlen(filename) + 1);\n   char *ret = REAL(MD2File)(filename, buf);\n   if (ret)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ret, MD2_return_length);\n@@ -8950,7 +9004,7 @@ INTERCEPTOR(char *, MD2Data, const unsigned char *data, unsigned int len,\n     void *ctx; \\\n     COMMON_INTERCEPTOR_ENTER(ctx, SHA##LEN##_File, filename, buf); \\\n     if (filename) \\\n-      COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, REAL(strlen)(filename) + 1);\\\n+      COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, internal_strlen(filename) + 1);\\\n     char *ret = REAL(SHA##LEN##_File)(filename, buf); \\\n     if (ret) \\\n       COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ret, SHA##LEN##_return_length); \\\n@@ -8962,7 +9016,7 @@ INTERCEPTOR(char *, MD2Data, const unsigned char *data, unsigned int len,\n     COMMON_INTERCEPTOR_ENTER(ctx, SHA##LEN##_FileChunk, filename, buf, offset, \\\n   length); \\\n     if (filename) \\\n-      COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, REAL(strlen)(filename) + 1);\\\n+      COMMON_INTERCEPTOR_READ_RANGE(ctx, filename, internal_strlen(filename) + 1);\\\n     char *ret = REAL(SHA##LEN##_FileChunk)(filename, buf, offset, length); \\\n     if (ret) \\\n       COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ret, SHA##LEN##_return_length); \\\n@@ -9026,7 +9080,7 @@ INTERCEPTOR(int, strvis, char *dst, const char *src, int flag) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, strvis, dst, src, flag);\n   if (src)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, REAL(strlen)(src) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, internal_strlen(src) + 1);\n   int len = REAL(strvis)(dst, src, flag);\n   if (dst)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, dst, len + 1);\n@@ -9036,7 +9090,7 @@ INTERCEPTOR(int, stravis, char **dst, const char *src, int flag) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, stravis, dst, src, flag);\n   if (src)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, REAL(strlen)(src) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, internal_strlen(src) + 1);\n   int len = REAL(stravis)(dst, src, flag);\n   if (dst) {\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, dst, sizeof(char *));\n@@ -9049,7 +9103,7 @@ INTERCEPTOR(int, strnvis, char *dst, SIZE_T dlen, const char *src, int flag) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, strnvis, dst, dlen, src, flag);\n   if (src)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, REAL(strlen)(src) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, internal_strlen(src) + 1);\n   int len = REAL(strnvis)(dst, dlen, src, flag);\n   // The interface will be valid even if there is no space for NULL char\n   if (dst && len > 0)\n@@ -9099,7 +9153,7 @@ INTERCEPTOR(char *, svis, char *dst, int c, int flag, int nextc,\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, svis, dst, c, flag, nextc, extra);\n   if (extra)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, extra, REAL(strlen)(extra) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, extra, internal_strlen(extra) + 1);\n   char *end = REAL(svis)(dst, c, flag, nextc, extra);\n   if (dst && end)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, dst, end - dst + 1);\n@@ -9110,7 +9164,7 @@ INTERCEPTOR(char *, snvis, char *dst, SIZE_T dlen, int c, int flag, int nextc,\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, snvis, dst, dlen, c, flag, nextc, extra);\n   if (extra)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, extra, REAL(strlen)(extra) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, extra, internal_strlen(extra) + 1);\n   char *end = REAL(snvis)(dst, dlen, c, flag, nextc, extra);\n   if (dst && end)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, dst,\n@@ -9122,9 +9176,9 @@ INTERCEPTOR(int, strsvis, char *dst, const char *src, int flag,\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, strsvis, dst, src, flag, extra);\n   if (src)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, REAL(strlen)(src) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, internal_strlen(src) + 1);\n   if (extra)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, extra, REAL(strlen)(extra) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, extra, internal_strlen(extra) + 1);\n   int len = REAL(strsvis)(dst, src, flag, extra);\n   if (dst)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, dst, len + 1);\n@@ -9135,9 +9189,9 @@ INTERCEPTOR(int, strsnvis, char *dst, SIZE_T dlen, const char *src, int flag,\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, strsnvis, dst, dlen, src, flag, extra);\n   if (src)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, REAL(strlen)(src) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, internal_strlen(src) + 1);\n   if (extra)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, extra, REAL(strlen)(extra) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, extra, internal_strlen(extra) + 1);\n   int len = REAL(strsnvis)(dst, dlen, src, flag, extra);\n   // The interface will be valid even if there is no space for NULL char\n   if (dst && len >= 0)\n@@ -9151,7 +9205,7 @@ INTERCEPTOR(int, strsvisx, char *dst, const char *src, SIZE_T len, int flag,\n   if (src)\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, src, len);\n   if (extra)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, extra, REAL(strlen)(extra) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, extra, internal_strlen(extra) + 1);\n   int ret = REAL(strsvisx)(dst, src, len, flag, extra);\n   if (dst)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, dst, ret + 1);\n@@ -9164,7 +9218,7 @@ INTERCEPTOR(int, strsnvisx, char *dst, SIZE_T dlen, const char *src, SIZE_T len,\n   if (src)\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, src, len);\n   if (extra)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, extra, REAL(strlen)(extra) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, extra, internal_strlen(extra) + 1);\n   int ret = REAL(strsnvisx)(dst, dlen, src, len, flag, extra);\n   if (dst && ret >= 0)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, dst, ret + 1);\n@@ -9178,7 +9232,7 @@ INTERCEPTOR(int, strsenvisx, char *dst, SIZE_T dlen, const char *src,\n   if (src)\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, src, len);\n   if (extra)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, extra, REAL(strlen)(extra) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, extra, internal_strlen(extra) + 1);\n   // FIXME: only need to be checked when \"flag | VIS_NOLOCALE\" doesn't hold\n   // according to the implementation\n   if (cerr_ptr)\n@@ -9205,7 +9259,7 @@ INTERCEPTOR(int, strunvis, char *dst, const char *src) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, strunvis, dst, src);\n   if (src)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, REAL(strlen)(src) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, internal_strlen(src) + 1);\n   int ret = REAL(strunvis)(dst, src);\n   if (ret != -1)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, dst, ret + 1);\n@@ -9215,7 +9269,7 @@ INTERCEPTOR(int, strnunvis, char *dst, SIZE_T dlen, const char *src) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, strnunvis, dst, dlen, src);\n   if (src)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, REAL(strlen)(src) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, internal_strlen(src) + 1);\n   int ret = REAL(strnunvis)(dst, dlen, src);\n   if (ret != -1)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, dst, ret + 1);\n@@ -9225,7 +9279,7 @@ INTERCEPTOR(int, strunvisx, char *dst, const char *src, int flag) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, strunvisx, dst, src, flag);\n   if (src)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, REAL(strlen)(src) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, internal_strlen(src) + 1);\n   int ret = REAL(strunvisx)(dst, src, flag);\n   if (ret != -1)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, dst, ret + 1);\n@@ -9236,7 +9290,7 @@ INTERCEPTOR(int, strnunvisx, char *dst, SIZE_T dlen, const char *src,\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, strnunvisx, dst, dlen, src, flag);\n   if (src)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, REAL(strlen)(src) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, src, internal_strlen(src) + 1);\n   int ret = REAL(strnunvisx)(dst, dlen, src, flag);\n   if (ret != -1)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, dst, ret + 1);\n@@ -9272,7 +9326,7 @@ INTERCEPTOR(struct __sanitizer_cdbr *, cdbr_open, const char *path, int flags) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, cdbr_open, path, flags);\n   if (path)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   struct __sanitizer_cdbr *cdbr = REAL(cdbr_open)(path, flags);\n   if (cdbr)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, cdbr, sizeof(*cdbr));\n@@ -9464,7 +9518,7 @@ INTERCEPTOR(void *, getfsspec, const char *spec) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, getfsspec, spec);\n   if (spec)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, spec, REAL(strlen)(spec) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, spec, internal_strlen(spec) + 1);\n   void *ret = REAL(getfsspec)(spec);\n   if (ret)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ret, struct_fstab_sz);\n@@ -9475,7 +9529,7 @@ INTERCEPTOR(void *, getfsfile, const char *file) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, getfsfile, file);\n   if (file)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, file, REAL(strlen)(file) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, file, internal_strlen(file) + 1);\n   void *ret = REAL(getfsfile)(file);\n   if (ret)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, ret, struct_fstab_sz);\n@@ -9519,9 +9573,9 @@ INTERCEPTOR(__sanitizer_FILE *, popen, const char *command, const char *type) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, popen, command, type);\n   if (command)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, command, REAL(strlen)(command) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, command, internal_strlen(command) + 1);\n   if (type)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, type, REAL(strlen)(type) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, type, internal_strlen(type) + 1);\n   __sanitizer_FILE *res = REAL(popen)(command, type);\n   COMMON_INTERCEPTOR_FILE_OPEN(ctx, res, nullptr);\n   if (res) unpoison_file(res);\n@@ -9538,25 +9592,25 @@ INTERCEPTOR(__sanitizer_FILE *, popenve, const char *path,\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, popenve, path, argv, envp, type);\n   if (path)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   if (argv) {\n     for (char *const *pa = argv; ; ++pa) {\n       COMMON_INTERCEPTOR_READ_RANGE(ctx, pa, sizeof(char **));\n       if (!*pa)\n         break;\n-      COMMON_INTERCEPTOR_READ_RANGE(ctx, *pa, REAL(strlen)(*pa) + 1);\n+      COMMON_INTERCEPTOR_READ_RANGE(ctx, *pa, internal_strlen(*pa) + 1);\n     }\n   }\n   if (envp) {\n     for (char *const *pa = envp; ; ++pa) {\n       COMMON_INTERCEPTOR_READ_RANGE(ctx, pa, sizeof(char **));\n       if (!*pa)\n         break;\n-      COMMON_INTERCEPTOR_READ_RANGE(ctx, *pa, REAL(strlen)(*pa) + 1);\n+      COMMON_INTERCEPTOR_READ_RANGE(ctx, *pa, internal_strlen(*pa) + 1);\n     }\n   }\n   if (type)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, type, REAL(strlen)(type) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, type, internal_strlen(type) + 1);\n   __sanitizer_FILE *res = REAL(popenve)(path, argv, envp, type);\n   COMMON_INTERCEPTOR_FILE_OPEN(ctx, res, nullptr);\n   if (res) unpoison_file(res);\n@@ -9752,7 +9806,7 @@ INTERCEPTOR(char *, fdevname,  int fd) {\n   COMMON_INTERCEPTOR_FD_ACCESS(ctx, fd);\n   char *name = REAL(fdevname)(fd);\n   if (name) {\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, name, REAL(strlen)(name) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, name, internal_strlen(name) + 1);\n     if (fd > 0)\n       COMMON_INTERCEPTOR_FD_ACQUIRE(ctx, fd);\n   }\n@@ -9765,7 +9819,7 @@ INTERCEPTOR(char *, fdevname_r,  int fd, char *buf, SIZE_T len) {\n   COMMON_INTERCEPTOR_FD_ACCESS(ctx, fd);\n   char *name = REAL(fdevname_r)(fd, buf, len);\n   if (name && buf && len > 0) {\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, buf, REAL(strlen)(buf) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, buf, internal_strlen(buf) + 1);\n     if (fd > 0)\n       COMMON_INTERCEPTOR_FD_ACQUIRE(ctx, fd);\n   }\n@@ -9785,7 +9839,7 @@ INTERCEPTOR(char *, getusershell) {\n   COMMON_INTERCEPTOR_ENTER(ctx, getusershell);\n   char *res = REAL(getusershell)();\n   if (res)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, REAL(strlen)(res) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, internal_strlen(res) + 1);\n   return res;\n }\n \n@@ -9810,7 +9864,7 @@ INTERCEPTOR(int, sl_add, void *sl, char *item) {\n   if (sl)\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, sl, __sanitizer::struct_StringList_sz);\n   if (item)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, item, REAL(strlen)(item) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, item, internal_strlen(item) + 1);\n   int res = REAL(sl_add)(sl, item);\n   if (!res)\n     COMMON_INTERCEPTOR_WRITE_RANGE(ctx, sl, __sanitizer::struct_StringList_sz);\n@@ -9823,10 +9877,10 @@ INTERCEPTOR(char *, sl_find, void *sl, const char *item) {\n   if (sl)\n     COMMON_INTERCEPTOR_READ_RANGE(ctx, sl, __sanitizer::struct_StringList_sz);\n   if (item)\n-    COMMON_INTERCEPTOR_READ_RANGE(ctx, item, REAL(strlen)(item) + 1);\n+    COMMON_INTERCEPTOR_READ_RANGE(ctx, item, internal_strlen(item) + 1);\n   char *res = REAL(sl_find)(sl, item);\n   if (res)\n-    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, REAL(strlen)(res) + 1);\n+    COMMON_INTERCEPTOR_WRITE_RANGE(ctx, res, internal_strlen(res) + 1);\n   return res;\n }\n \n@@ -9912,7 +9966,52 @@ INTERCEPTOR(int, getentropy, void *buf, SIZE_T buflen) {\n #define INIT_GETENTROPY\n #endif\n \n-#if SANITIZER_INTERCEPT_QSORT\n+#if SANITIZER_INTERCEPT_QSORT_R\n+typedef int (*qsort_r_compar_f)(const void *, const void *, void *);\n+struct qsort_r_compar_params {\n+  SIZE_T size;\n+  qsort_r_compar_f compar;\n+  void *arg;\n+};\n+static int wrapped_qsort_r_compar(const void *a, const void *b, void *arg) {\n+  qsort_r_compar_params *params = (qsort_r_compar_params *)arg;\n+  COMMON_INTERCEPTOR_UNPOISON_PARAM(3);\n+  COMMON_INTERCEPTOR_INITIALIZE_RANGE(a, params->size);\n+  COMMON_INTERCEPTOR_INITIALIZE_RANGE(b, params->size);\n+  return params->compar(a, b, params->arg);\n+}\n+\n+INTERCEPTOR(void, qsort_r, void *base, SIZE_T nmemb, SIZE_T size,\n+            qsort_r_compar_f compar, void *arg) {\n+  void *ctx;\n+  COMMON_INTERCEPTOR_ENTER(ctx, qsort_r, base, nmemb, size, compar, arg);\n+  // Run the comparator over all array elements to detect any memory issues.\n+  if (nmemb > 1) {\n+    for (SIZE_T i = 0; i < nmemb - 1; ++i) {\n+      void *p = (void *)((char *)base + i * size);\n+      void *q = (void *)((char *)base + (i + 1) * size);\n+      COMMON_INTERCEPTOR_UNPOISON_PARAM(3);\n+      compar(p, q, arg);\n+    }\n+  }\n+  qsort_r_compar_params params = {size, compar, arg};\n+  REAL(qsort_r)(base, nmemb, size, wrapped_qsort_r_compar, &params);\n+  COMMON_INTERCEPTOR_WRITE_RANGE(ctx, base, nmemb * size);\n+}\n+#  define INIT_QSORT_R COMMON_INTERCEPT_FUNCTION(qsort_r)\n+#else\n+#  define INIT_QSORT_R\n+#endif\n+\n+#if SANITIZER_INTERCEPT_QSORT && SANITIZER_INTERCEPT_QSORT_R\n+INTERCEPTOR(void, qsort, void *base, SIZE_T nmemb, SIZE_T size,\n+            qsort_r_compar_f compar) {\n+  void *ctx;\n+  COMMON_INTERCEPTOR_ENTER(ctx, qsort, base, nmemb, size, compar);\n+  WRAP(qsort_r)(base, nmemb, size, compar, nullptr);\n+}\n+#  define INIT_QSORT COMMON_INTERCEPT_FUNCTION(qsort)\n+#elif SANITIZER_INTERCEPT_QSORT && !SANITIZER_INTERCEPT_QSORT_R\n // Glibc qsort uses a temporary buffer allocated either on stack or on heap.\n // Poisoned memory from there may get copied into the comparator arguments,\n // where it needs to be dealt with. But even that is not enough - the results of\n@@ -9927,7 +10026,7 @@ INTERCEPTOR(int, getentropy, void *buf, SIZE_T buflen) {\n typedef int (*qsort_compar_f)(const void *, const void *);\n static THREADLOCAL qsort_compar_f qsort_compar;\n static THREADLOCAL SIZE_T qsort_size;\n-int wrapped_qsort_compar(const void *a, const void *b) {\n+static int wrapped_qsort_compar(const void *a, const void *b) {\n   COMMON_INTERCEPTOR_UNPOISON_PARAM(2);\n   COMMON_INTERCEPTOR_INITIALIZE_RANGE(a, qsort_size);\n   COMMON_INTERCEPTOR_INITIALIZE_RANGE(b, qsort_size);\n@@ -9969,60 +10068,34 @@ INTERCEPTOR(void, qsort, void *base, SIZE_T nmemb, SIZE_T size,\n   }\n   COMMON_INTERCEPTOR_WRITE_RANGE(ctx, base, nmemb * size);\n }\n-#define INIT_QSORT COMMON_INTERCEPT_FUNCTION(qsort)\n+#  define INIT_QSORT COMMON_INTERCEPT_FUNCTION(qsort)\n #else\n-#define INIT_QSORT\n+#  define INIT_QSORT\n #endif\n \n-#if SANITIZER_INTERCEPT_QSORT_R\n-typedef int (*qsort_r_compar_f)(const void *, const void *, void *);\n-static THREADLOCAL qsort_r_compar_f qsort_r_compar;\n-static THREADLOCAL SIZE_T qsort_r_size;\n-int wrapped_qsort_r_compar(const void *a, const void *b, void *arg) {\n-  COMMON_INTERCEPTOR_UNPOISON_PARAM(3);\n-  COMMON_INTERCEPTOR_INITIALIZE_RANGE(a, qsort_r_size);\n-  COMMON_INTERCEPTOR_INITIALIZE_RANGE(b, qsort_r_size);\n-  return qsort_r_compar(a, b, arg);\n+#if SANITIZER_INTERCEPT_BSEARCH\n+typedef int (*bsearch_compar_f)(const void *, const void *);\n+struct bsearch_compar_params {\n+  const void *key;\n+  bsearch_compar_f compar;\n+};\n+\n+static int wrapped_bsearch_compar(const void *key, const void *b) {\n+  const bsearch_compar_params *params = (const bsearch_compar_params *)key;\n+  COMMON_INTERCEPTOR_UNPOISON_PARAM(2);\n+  return params->compar(params->key, b);\n }\n \n-INTERCEPTOR(void, qsort_r, void *base, SIZE_T nmemb, SIZE_T size,\n-            qsort_r_compar_f compar, void *arg) {\n+INTERCEPTOR(void *, bsearch, const void *key, const void *base, SIZE_T nmemb,\n+            SIZE_T size, bsearch_compar_f compar) {\n   void *ctx;\n-  COMMON_INTERCEPTOR_ENTER(ctx, qsort_r, base, nmemb, size, compar, arg);\n-  // Run the comparator over all array elements to detect any memory issues.\n-  if (nmemb > 1) {\n-    for (SIZE_T i = 0; i < nmemb - 1; ++i) {\n-      void *p = (void *)((char *)base + i * size);\n-      void *q = (void *)((char *)base + (i + 1) * size);\n-      COMMON_INTERCEPTOR_UNPOISON_PARAM(3);\n-      compar(p, q, arg);\n-    }\n-  }\n-  qsort_r_compar_f old_compar = qsort_r_compar;\n-  SIZE_T old_size = qsort_r_size;\n-  // Handle qsort_r() implementations that recurse using an\n-  // interposable function call:\n-  bool already_wrapped = compar == wrapped_qsort_r_compar;\n-  if (already_wrapped) {\n-    // This case should only happen if the qsort() implementation calls itself\n-    // using a preemptible function call (e.g. the FreeBSD libc version).\n-    // Check that the size and comparator arguments are as expected.\n-    CHECK_NE(compar, qsort_r_compar);\n-    CHECK_EQ(qsort_r_size, size);\n-  } else {\n-    qsort_r_compar = compar;\n-    qsort_r_size = size;\n-  }\n-  REAL(qsort_r)(base, nmemb, size, wrapped_qsort_r_compar, arg);\n-  if (!already_wrapped) {\n-    qsort_r_compar = old_compar;\n-    qsort_r_size = old_size;\n-  }\n-  COMMON_INTERCEPTOR_WRITE_RANGE(ctx, base, nmemb * size);\n+  COMMON_INTERCEPTOR_ENTER(ctx, bsearch, key, base, nmemb, size, compar);\n+  bsearch_compar_params params = {key, compar};\n+  return REAL(bsearch)(&params, base, nmemb, size, wrapped_bsearch_compar);\n }\n-#define INIT_QSORT_R COMMON_INTERCEPT_FUNCTION(qsort_r)\n+#  define INIT_BSEARCH COMMON_INTERCEPT_FUNCTION(bsearch)\n #else\n-#define INIT_QSORT_R\n+#  define INIT_BSEARCH\n #endif\n \n #if SANITIZER_INTERCEPT_SIGALTSTACK\n@@ -10391,6 +10464,7 @@ static void InitializeCommonInterceptors() {\n   INIT_GETENTROPY;\n   INIT_QSORT;\n   INIT_QSORT_R;\n+  INIT_BSEARCH;\n   INIT_SIGALTSTACK;\n   INIT_UNAME;\n   INIT___XUNAME;"}, {"sha": "220abb89c3beba8457c1abfe996a72516e282e73", "filename": "libsanitizer/sanitizer_common/sanitizer_common_interceptors_format.inc", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_interceptors_format.inc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_interceptors_format.inc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_interceptors_format.inc?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -324,8 +324,8 @@ static void scanf_common(void *ctx, int n_inputs, bool allowGnuMalloc,\n       continue;\n     int size = scanf_get_value_size(&dir);\n     if (size == FSS_INVALID) {\n-      Report(\"%s: WARNING: unexpected format specifier in scanf interceptor: \",\n-             SanitizerToolName, \"%.*s\\n\", dir.end - dir.begin, dir.begin);\n+      Report(\"%s: WARNING: unexpected format specifier in scanf interceptor: %.*s\\n\",\n+             SanitizerToolName, static_cast<int>(dir.end - dir.begin), dir.begin);\n       break;\n     }\n     void *argp = va_arg(aq, void *);\n@@ -469,7 +469,7 @@ static int printf_get_value_size(PrintfDirective *dir) {\n         break;                                                     \\\n       default:                                                     \\\n         Report(\"WARNING: unexpected floating-point arg size\"       \\\n-               \" in printf interceptor: %d\\n\", size);              \\\n+               \" in printf interceptor: %zu\\n\", static_cast<uptr>(size));             \\\n         return;                                                    \\\n       }                                                            \\\n     } else {                                                       \\\n@@ -484,7 +484,7 @@ static int printf_get_value_size(PrintfDirective *dir) {\n         break;                                                     \\\n       default:                                                     \\\n         Report(\"WARNING: unexpected arg size\"                      \\\n-               \" in printf interceptor: %d\\n\", size);              \\\n+               \" in printf interceptor: %zu\\n\", static_cast<uptr>(size));             \\\n         return;                                                    \\\n       }                                                            \\\n     }                                                              \\\n@@ -530,7 +530,7 @@ static void printf_common(void *ctx, const char *format, va_list aq) {\n         Report(\n             \"%s: WARNING: unexpected format specifier in printf \"\n             \"interceptor: %.*s (reported once per process)\\n\",\n-            SanitizerToolName, dir.end - dir.begin, dir.begin);\n+            SanitizerToolName, static_cast<int>(dir.end - dir.begin), dir.begin);\n       break;\n     }\n     if (dir.convSpecifier == 'n') {"}, {"sha": "f6ac3fa5af18424517230b5cc2862e9038ddd685", "filename": "libsanitizer/sanitizer_common/sanitizer_common_interceptors_netbsd_compat.inc", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_interceptors_netbsd_compat.inc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_interceptors_netbsd_compat.inc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_interceptors_netbsd_compat.inc?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -33,7 +33,7 @@\n INTERCEPTOR(int, statvfs, char *path, void *buf) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, statvfs, path, buf);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   // FIXME: under ASan the call below may write to freed memory and corrupt\n   // its metadata. See\n   // https://github.com/google/sanitizers/issues/321.\n@@ -99,7 +99,7 @@ INTERCEPTOR(int, getvfsstat, void *buf, SIZE_T bufsize, int flags) {\n INTERCEPTOR(int, statvfs1, const char *path, void *buf, int flags) {\n   void *ctx;\n   COMMON_INTERCEPTOR_ENTER(ctx, statvfs1, path, buf, flags);\n-  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, REAL(strlen)(path) + 1);\n+  if (path) COMMON_INTERCEPTOR_READ_RANGE(ctx, path, internal_strlen(path) + 1);\n   int res = REAL(statvfs1)(path, buf, flags);\n   if (!res) COMMON_INTERCEPTOR_WRITE_RANGE(ctx, buf, struct_statvfs90_sz);\n   return res;"}, {"sha": "a20602d8b95a73ab029908a779e8d84edd6cfd26", "filename": "libsanitizer/sanitizer_common/sanitizer_common_nolibc.cpp", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_nolibc.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_nolibc.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_nolibc.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -25,6 +25,7 @@ void LogMessageOnPrintf(const char *str) {}\n #endif\n void WriteToSyslog(const char *buffer) {}\n void Abort() { internal__exit(1); }\n+bool CreateDir(const char *pathname) { return false; }\n #endif // !SANITIZER_WINDOWS\n \n #if !SANITIZER_WINDOWS && !SANITIZER_MAC"}, {"sha": "a38b134085aabde4e4d589bc98de222f0fc297e5", "filename": "libsanitizer/sanitizer_common/sanitizer_common_syscalls.inc", "status": "modified", "additions": 909, "deletions": 650, "changes": 1559, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_syscalls.inc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_syscalls.inc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_common_syscalls.inc?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -43,45 +43,47 @@\n #include \"sanitizer_platform.h\"\n #if SANITIZER_LINUX\n \n-#include \"sanitizer_libc.h\"\n+#  include \"sanitizer_libc.h\"\n \n-#define PRE_SYSCALL(name)                                                      \\\n-  SANITIZER_INTERFACE_ATTRIBUTE void __sanitizer_syscall_pre_impl_##name\n-#define PRE_READ(p, s) COMMON_SYSCALL_PRE_READ_RANGE(p, s)\n-#define PRE_WRITE(p, s) COMMON_SYSCALL_PRE_WRITE_RANGE(p, s)\n+#  define PRE_SYSCALL(name) \\\n+    SANITIZER_INTERFACE_ATTRIBUTE void __sanitizer_syscall_pre_impl_##name\n+#  define PRE_READ(p, s) COMMON_SYSCALL_PRE_READ_RANGE(p, s)\n+#  define PRE_WRITE(p, s) COMMON_SYSCALL_PRE_WRITE_RANGE(p, s)\n \n-#define POST_SYSCALL(name)                                                     \\\n-  SANITIZER_INTERFACE_ATTRIBUTE void __sanitizer_syscall_post_impl_##name\n-#define POST_READ(p, s) COMMON_SYSCALL_POST_READ_RANGE(p, s)\n-#define POST_WRITE(p, s) COMMON_SYSCALL_POST_WRITE_RANGE(p, s)\n+#  define POST_SYSCALL(name) \\\n+    SANITIZER_INTERFACE_ATTRIBUTE void __sanitizer_syscall_post_impl_##name\n+#  define POST_READ(p, s) COMMON_SYSCALL_POST_READ_RANGE(p, s)\n+#  define POST_WRITE(p, s) COMMON_SYSCALL_POST_WRITE_RANGE(p, s)\n \n-#ifndef COMMON_SYSCALL_ACQUIRE\n-# define COMMON_SYSCALL_ACQUIRE(addr) ((void)(addr))\n-#endif\n+#  ifndef COMMON_SYSCALL_ACQUIRE\n+#    define COMMON_SYSCALL_ACQUIRE(addr) ((void)(addr))\n+#  endif\n \n-#ifndef COMMON_SYSCALL_RELEASE\n-# define COMMON_SYSCALL_RELEASE(addr) ((void)(addr))\n-#endif\n+#  ifndef COMMON_SYSCALL_RELEASE\n+#    define COMMON_SYSCALL_RELEASE(addr) ((void)(addr))\n+#  endif\n \n-#ifndef COMMON_SYSCALL_FD_CLOSE\n-# define COMMON_SYSCALL_FD_CLOSE(fd) ((void)(fd))\n-#endif\n+#  ifndef COMMON_SYSCALL_FD_CLOSE\n+#    define COMMON_SYSCALL_FD_CLOSE(fd) ((void)(fd))\n+#  endif\n \n-#ifndef COMMON_SYSCALL_FD_ACQUIRE\n-# define COMMON_SYSCALL_FD_ACQUIRE(fd) ((void)(fd))\n-#endif\n+#  ifndef COMMON_SYSCALL_FD_ACQUIRE\n+#    define COMMON_SYSCALL_FD_ACQUIRE(fd) ((void)(fd))\n+#  endif\n \n-#ifndef COMMON_SYSCALL_FD_RELEASE\n-# define COMMON_SYSCALL_FD_RELEASE(fd) ((void)(fd))\n-#endif\n+#  ifndef COMMON_SYSCALL_FD_RELEASE\n+#    define COMMON_SYSCALL_FD_RELEASE(fd) ((void)(fd))\n+#  endif\n \n-#ifndef COMMON_SYSCALL_PRE_FORK\n-# define COMMON_SYSCALL_PRE_FORK() {}\n-#endif\n+#  ifndef COMMON_SYSCALL_PRE_FORK\n+#    define COMMON_SYSCALL_PRE_FORK() \\\n+      {}\n+#  endif\n \n-#ifndef COMMON_SYSCALL_POST_FORK\n-# define COMMON_SYSCALL_POST_FORK(res) {}\n-#endif\n+#  ifndef COMMON_SYSCALL_POST_FORK\n+#    define COMMON_SYSCALL_POST_FORK(res) \\\n+      {}\n+#  endif\n \n // FIXME: do some kind of PRE_READ for all syscall arguments (int(s) and such).\n \n@@ -130,8 +132,8 @@ struct sanitizer_kernel_sockaddr {\n // Declare it \"void\" to catch sizeof(kernel_sigset_t).\n typedef void kernel_sigset_t;\n \n-static void kernel_write_iovec(const __sanitizer_iovec *iovec,\n-                        SIZE_T iovlen, SIZE_T maxlen) {\n+static void kernel_write_iovec(const __sanitizer_iovec *iovec, SIZE_T iovlen,\n+                               SIZE_T maxlen) {\n   for (SIZE_T i = 0; i < iovlen && maxlen; ++i) {\n     SSIZE_T sz = Min(iovec[i].iov_len, maxlen);\n     POST_WRITE(iovec[i].iov_base, sz);\n@@ -141,8 +143,8 @@ static void kernel_write_iovec(const __sanitizer_iovec *iovec,\n \n // This functions uses POST_READ, because it needs to run after syscall to know\n // the real read range.\n-static void kernel_read_iovec(const __sanitizer_iovec *iovec,\n-                       SIZE_T iovlen, SIZE_T maxlen) {\n+static void kernel_read_iovec(const __sanitizer_iovec *iovec, SIZE_T iovlen,\n+                              SIZE_T maxlen) {\n   POST_READ(iovec, sizeof(*iovec) * iovlen);\n   for (SIZE_T i = 0; i < iovlen && maxlen; ++i) {\n     SSIZE_T sz = Min(iovec[i].iov_len, maxlen);\n@@ -155,8 +157,8 @@ PRE_SYSCALL(recvmsg)(long sockfd, sanitizer_kernel_msghdr *msg, long flags) {\n   PRE_READ(msg, sizeof(*msg));\n }\n \n-POST_SYSCALL(recvmsg)(long res, long sockfd, sanitizer_kernel_msghdr *msg,\n-                      long flags) {\n+POST_SYSCALL(recvmsg)\n+(long res, long sockfd, sanitizer_kernel_msghdr *msg, long flags) {\n   if (res >= 0) {\n     if (msg) {\n       for (unsigned long i = 0; i < msg->msg_iovlen; ++i) {\n@@ -167,13 +169,14 @@ POST_SYSCALL(recvmsg)(long res, long sockfd, sanitizer_kernel_msghdr *msg,\n   }\n }\n \n-PRE_SYSCALL(recvmmsg)(long fd, sanitizer_kernel_mmsghdr *msg, long vlen,\n-                      long flags, void *timeout) {\n+PRE_SYSCALL(recvmmsg)\n+(long fd, sanitizer_kernel_mmsghdr *msg, long vlen, long flags, void *timeout) {\n   PRE_READ(msg, vlen * sizeof(*msg));\n }\n \n-POST_SYSCALL(recvmmsg)(long res, long fd, sanitizer_kernel_mmsghdr *msg,\n-                       long vlen, long flags, void *timeout) {\n+POST_SYSCALL(recvmmsg)\n+(long res, long fd, sanitizer_kernel_mmsghdr *msg, long vlen, long flags,\n+ void *timeout) {\n   if (res >= 0) {\n     if (msg) {\n       for (unsigned long i = 0; i < msg->msg_hdr.msg_iovlen; ++i) {\n@@ -183,7 +186,8 @@ POST_SYSCALL(recvmmsg)(long res, long fd, sanitizer_kernel_mmsghdr *msg,\n       POST_WRITE(msg->msg_hdr.msg_control, msg->msg_hdr.msg_controllen);\n       POST_WRITE(&msg->msg_len, sizeof(msg->msg_len));\n     }\n-    if (timeout) POST_WRITE(timeout, struct_timespec_sz);\n+    if (timeout)\n+      POST_WRITE(timeout, struct_timespec_sz);\n   }\n }\n \n@@ -203,51 +207,59 @@ PRE_SYSCALL(time)(void *tloc) {}\n \n POST_SYSCALL(time)(long res, void *tloc) {\n   if (res >= 0) {\n-    if (tloc) POST_WRITE(tloc, sizeof(long));\n+    if (tloc)\n+      POST_WRITE(tloc, sizeof(long));\n   }\n }\n \n PRE_SYSCALL(stime)(void *tptr) {}\n \n POST_SYSCALL(stime)(long res, void *tptr) {\n   if (res >= 0) {\n-    if (tptr) POST_WRITE(tptr, sizeof(long));\n+    if (tptr)\n+      POST_WRITE(tptr, sizeof(long));\n   }\n }\n \n PRE_SYSCALL(gettimeofday)(void *tv, void *tz) {}\n \n POST_SYSCALL(gettimeofday)(long res, void *tv, void *tz) {\n   if (res >= 0) {\n-    if (tv) POST_WRITE(tv, timeval_sz);\n-    if (tz) POST_WRITE(tz, struct_timezone_sz);\n+    if (tv)\n+      POST_WRITE(tv, timeval_sz);\n+    if (tz)\n+      POST_WRITE(tz, struct_timezone_sz);\n   }\n }\n \n PRE_SYSCALL(settimeofday)(void *tv, void *tz) {}\n \n POST_SYSCALL(settimeofday)(long res, void *tv, void *tz) {\n   if (res >= 0) {\n-    if (tv) POST_WRITE(tv, timeval_sz);\n-    if (tz) POST_WRITE(tz, struct_timezone_sz);\n+    if (tv)\n+      POST_WRITE(tv, timeval_sz);\n+    if (tz)\n+      POST_WRITE(tz, struct_timezone_sz);\n   }\n }\n \n-#if !SANITIZER_ANDROID\n+#  if !SANITIZER_ANDROID\n PRE_SYSCALL(adjtimex)(void *txc_p) {}\n \n POST_SYSCALL(adjtimex)(long res, void *txc_p) {\n   if (res >= 0) {\n-    if (txc_p) POST_WRITE(txc_p, struct_timex_sz);\n+    if (txc_p)\n+      POST_WRITE(txc_p, struct_timex_sz);\n   }\n }\n-#endif\n+#  endif\n \n PRE_SYSCALL(times)(void *tbuf) {}\n \n POST_SYSCALL(times)(long res, void *tbuf) {\n   if (res >= 0) {\n-    if (tbuf) POST_WRITE(tbuf, struct_tms_sz);\n+    if (tbuf)\n+      POST_WRITE(tbuf, struct_tms_sz);\n   }\n }\n \n@@ -259,8 +271,10 @@ PRE_SYSCALL(nanosleep)(void *rqtp, void *rmtp) {}\n \n POST_SYSCALL(nanosleep)(long res, void *rqtp, void *rmtp) {\n   if (res >= 0) {\n-    if (rqtp) POST_WRITE(rqtp, struct_timespec_sz);\n-    if (rmtp) POST_WRITE(rmtp, struct_timespec_sz);\n+    if (rqtp)\n+      POST_WRITE(rqtp, struct_timespec_sz);\n+    if (rmtp)\n+      POST_WRITE(rmtp, struct_timespec_sz);\n   }\n }\n \n@@ -296,19 +310,25 @@ PRE_SYSCALL(getresuid)(void *ruid, void *euid, void *suid) {}\n \n POST_SYSCALL(getresuid)(long res, void *ruid, void *euid, void *suid) {\n   if (res >= 0) {\n-    if (ruid) POST_WRITE(ruid, sizeof(unsigned));\n-    if (euid) POST_WRITE(euid, sizeof(unsigned));\n-    if (suid) POST_WRITE(suid, sizeof(unsigned));\n+    if (ruid)\n+      POST_WRITE(ruid, sizeof(unsigned));\n+    if (euid)\n+      POST_WRITE(euid, sizeof(unsigned));\n+    if (suid)\n+      POST_WRITE(suid, sizeof(unsigned));\n   }\n }\n \n PRE_SYSCALL(getresgid)(void *rgid, void *egid, void *sgid) {}\n \n POST_SYSCALL(getresgid)(long res, void *rgid, void *egid, void *sgid) {\n   if (res >= 0) {\n-    if (rgid) POST_WRITE(rgid, sizeof(unsigned));\n-    if (egid) POST_WRITE(egid, sizeof(unsigned));\n-    if (sgid) POST_WRITE(sgid, sizeof(unsigned));\n+    if (rgid)\n+      POST_WRITE(rgid, sizeof(unsigned));\n+    if (egid)\n+      POST_WRITE(egid, sizeof(unsigned));\n+    if (sgid)\n+      POST_WRITE(sgid, sizeof(unsigned));\n   }\n }\n \n@@ -326,10 +346,11 @@ POST_SYSCALL(getsid)(long res, long pid) {}\n \n PRE_SYSCALL(getgroups)(long gidsetsize, void *grouplist) {}\n \n-POST_SYSCALL(getgroups)(long res, long gidsetsize,\n-                        __sanitizer___kernel_gid_t *grouplist) {\n+POST_SYSCALL(getgroups)\n+(long res, long gidsetsize, __sanitizer___kernel_gid_t *grouplist) {\n   if (res >= 0) {\n-    if (grouplist) POST_WRITE(grouplist, res * sizeof(*grouplist));\n+    if (grouplist)\n+      POST_WRITE(grouplist, res * sizeof(*grouplist));\n   }\n }\n \n@@ -374,11 +395,12 @@ PRE_SYSCALL(setsid)() {}\n POST_SYSCALL(setsid)(long res) {}\n \n PRE_SYSCALL(setgroups)(long gidsetsize, __sanitizer___kernel_gid_t *grouplist) {\n-  if (grouplist) POST_WRITE(grouplist, gidsetsize * sizeof(*grouplist));\n+  if (grouplist)\n+    POST_WRITE(grouplist, gidsetsize * sizeof(*grouplist));\n }\n \n-POST_SYSCALL(setgroups)(long res, long gidsetsize,\n-                        __sanitizer___kernel_gid_t *grouplist) {}\n+POST_SYSCALL(setgroups)\n+(long res, long gidsetsize, __sanitizer___kernel_gid_t *grouplist) {}\n \n PRE_SYSCALL(acct)(const void *name) {\n   if (name)\n@@ -388,17 +410,21 @@ PRE_SYSCALL(acct)(const void *name) {\n POST_SYSCALL(acct)(long res, const void *name) {}\n \n PRE_SYSCALL(capget)(void *header, void *dataptr) {\n-  if (header) PRE_READ(header, __user_cap_header_struct_sz);\n+  if (header)\n+    PRE_READ(header, __user_cap_header_struct_sz);\n }\n \n POST_SYSCALL(capget)(long res, void *header, void *dataptr) {\n   if (res >= 0)\n-    if (dataptr) POST_WRITE(dataptr, __user_cap_data_struct_sz);\n+    if (dataptr)\n+      POST_WRITE(dataptr, __user_cap_data_struct_sz);\n }\n \n PRE_SYSCALL(capset)(void *header, const void *data) {\n-  if (header) PRE_READ(header, __user_cap_header_struct_sz);\n-  if (data) PRE_READ(data, __user_cap_data_struct_sz);\n+  if (header)\n+    PRE_READ(header, __user_cap_header_struct_sz);\n+  if (data)\n+    PRE_READ(data, __user_cap_data_struct_sz);\n }\n \n POST_SYSCALL(capset)(long res, void *header, const void *data) {}\n@@ -411,68 +437,80 @@ PRE_SYSCALL(sigpending)(void *set) {}\n \n POST_SYSCALL(sigpending)(long res, void *set) {\n   if (res >= 0) {\n-    if (set) POST_WRITE(set, old_sigset_t_sz);\n+    if (set)\n+      POST_WRITE(set, old_sigset_t_sz);\n   }\n }\n \n PRE_SYSCALL(sigprocmask)(long how, void *set, void *oset) {}\n \n POST_SYSCALL(sigprocmask)(long res, long how, void *set, void *oset) {\n   if (res >= 0) {\n-    if (set) POST_WRITE(set, old_sigset_t_sz);\n-    if (oset) POST_WRITE(oset, old_sigset_t_sz);\n+    if (set)\n+      POST_WRITE(set, old_sigset_t_sz);\n+    if (oset)\n+      POST_WRITE(oset, old_sigset_t_sz);\n   }\n }\n \n PRE_SYSCALL(getitimer)(long which, void *value) {}\n \n POST_SYSCALL(getitimer)(long res, long which, void *value) {\n   if (res >= 0) {\n-    if (value) POST_WRITE(value, struct_itimerval_sz);\n+    if (value)\n+      POST_WRITE(value, struct_itimerval_sz);\n   }\n }\n \n PRE_SYSCALL(setitimer)(long which, void *value, void *ovalue) {}\n \n POST_SYSCALL(setitimer)(long res, long which, void *value, void *ovalue) {\n   if (res >= 0) {\n-    if (value) POST_WRITE(value, struct_itimerval_sz);\n-    if (ovalue) POST_WRITE(ovalue, struct_itimerval_sz);\n+    if (value)\n+      POST_WRITE(value, struct_itimerval_sz);\n+    if (ovalue)\n+      POST_WRITE(ovalue, struct_itimerval_sz);\n   }\n }\n \n-PRE_SYSCALL(timer_create)(long which_clock, void *timer_event_spec,\n-                          void *created_timer_id) {}\n+PRE_SYSCALL(timer_create)\n+(long which_clock, void *timer_event_spec, void *created_timer_id) {}\n \n-POST_SYSCALL(timer_create)(long res, long which_clock, void *timer_event_spec,\n-                           void *created_timer_id) {\n+POST_SYSCALL(timer_create)\n+(long res, long which_clock, void *timer_event_spec, void *created_timer_id) {\n   if (res >= 0) {\n-    if (timer_event_spec) POST_WRITE(timer_event_spec, struct_sigevent_sz);\n-    if (created_timer_id) POST_WRITE(created_timer_id, sizeof(long));\n+    if (timer_event_spec)\n+      POST_WRITE(timer_event_spec, struct_sigevent_sz);\n+    if (created_timer_id)\n+      POST_WRITE(created_timer_id, sizeof(long));\n   }\n }\n \n PRE_SYSCALL(timer_gettime)(long timer_id, void *setting) {}\n \n POST_SYSCALL(timer_gettime)(long res, long timer_id, void *setting) {\n   if (res >= 0) {\n-    if (setting) POST_WRITE(setting, struct_itimerspec_sz);\n+    if (setting)\n+      POST_WRITE(setting, struct_itimerspec_sz);\n   }\n }\n \n PRE_SYSCALL(timer_getoverrun)(long timer_id) {}\n \n POST_SYSCALL(timer_getoverrun)(long res, long timer_id) {}\n \n-PRE_SYSCALL(timer_settime)(long timer_id, long flags, const void *new_setting,\n-                           void *old_setting) {\n-  if (new_setting) PRE_READ(new_setting, struct_itimerspec_sz);\n+PRE_SYSCALL(timer_settime)\n+(long timer_id, long flags, const void *new_setting, void *old_setting) {\n+  if (new_setting)\n+    PRE_READ(new_setting, struct_itimerspec_sz);\n }\n \n-POST_SYSCALL(timer_settime)(long res, long timer_id, long flags,\n-                            const void *new_setting, void *old_setting) {\n+POST_SYSCALL(timer_settime)\n+(long res, long timer_id, long flags, const void *new_setting,\n+ void *old_setting) {\n   if (res >= 0) {\n-    if (old_setting) POST_WRITE(old_setting, struct_itimerspec_sz);\n+    if (old_setting)\n+      POST_WRITE(old_setting, struct_itimerspec_sz);\n   }\n }\n \n@@ -481,7 +519,8 @@ PRE_SYSCALL(timer_delete)(long timer_id) {}\n POST_SYSCALL(timer_delete)(long res, long timer_id) {}\n \n PRE_SYSCALL(clock_settime)(long which_clock, const void *tp) {\n-  if (tp) PRE_READ(tp, struct_timespec_sz);\n+  if (tp)\n+    PRE_READ(tp, struct_timespec_sz);\n }\n \n POST_SYSCALL(clock_settime)(long res, long which_clock, const void *tp) {}\n@@ -490,37 +529,42 @@ PRE_SYSCALL(clock_gettime)(long which_clock, void *tp) {}\n \n POST_SYSCALL(clock_gettime)(long res, long which_clock, void *tp) {\n   if (res >= 0) {\n-    if (tp) POST_WRITE(tp, struct_timespec_sz);\n+    if (tp)\n+      POST_WRITE(tp, struct_timespec_sz);\n   }\n }\n \n-#if !SANITIZER_ANDROID\n+#  if !SANITIZER_ANDROID\n PRE_SYSCALL(clock_adjtime)(long which_clock, void *tx) {}\n \n POST_SYSCALL(clock_adjtime)(long res, long which_clock, void *tx) {\n   if (res >= 0) {\n-    if (tx) POST_WRITE(tx, struct_timex_sz);\n+    if (tx)\n+      POST_WRITE(tx, struct_timex_sz);\n   }\n }\n-#endif\n+#  endif\n \n PRE_SYSCALL(clock_getres)(long which_clock, void *tp) {}\n \n POST_SYSCALL(clock_getres)(long res, long which_clock, void *tp) {\n   if (res >= 0) {\n-    if (tp) POST_WRITE(tp, struct_timespec_sz);\n+    if (tp)\n+      POST_WRITE(tp, struct_timespec_sz);\n   }\n }\n \n-PRE_SYSCALL(clock_nanosleep)(long which_clock, long flags, const void *rqtp,\n-                             void *rmtp) {\n-  if (rqtp) PRE_READ(rqtp, struct_timespec_sz);\n+PRE_SYSCALL(clock_nanosleep)\n+(long which_clock, long flags, const void *rqtp, void *rmtp) {\n+  if (rqtp)\n+    PRE_READ(rqtp, struct_timespec_sz);\n }\n \n-POST_SYSCALL(clock_nanosleep)(long res, long which_clock, long flags,\n-                              const void *rqtp, void *rmtp) {\n+POST_SYSCALL(clock_nanosleep)\n+(long res, long which_clock, long flags, const void *rqtp, void *rmtp) {\n   if (res >= 0) {\n-    if (rmtp) POST_WRITE(rmtp, struct_timespec_sz);\n+    if (rmtp)\n+      POST_WRITE(rmtp, struct_timespec_sz);\n   }\n }\n \n@@ -532,12 +576,14 @@ PRE_SYSCALL(sched_setscheduler)(long pid, long policy, void *param) {}\n \n POST_SYSCALL(sched_setscheduler)(long res, long pid, long policy, void *param) {\n   if (res >= 0) {\n-    if (param) POST_WRITE(param, struct_sched_param_sz);\n+    if (param)\n+      POST_WRITE(param, struct_sched_param_sz);\n   }\n }\n \n PRE_SYSCALL(sched_setparam)(long pid, void *param) {\n-  if (param) PRE_READ(param, struct_sched_param_sz);\n+  if (param)\n+    PRE_READ(param, struct_sched_param_sz);\n }\n \n POST_SYSCALL(sched_setparam)(long res, long pid, void *param) {}\n@@ -550,23 +596,26 @@ PRE_SYSCALL(sched_getparam)(long pid, void *param) {}\n \n POST_SYSCALL(sched_getparam)(long res, long pid, void *param) {\n   if (res >= 0) {\n-    if (param) POST_WRITE(param, struct_sched_param_sz);\n+    if (param)\n+      POST_WRITE(param, struct_sched_param_sz);\n   }\n }\n \n PRE_SYSCALL(sched_setaffinity)(long pid, long len, void *user_mask_ptr) {\n-  if (user_mask_ptr) PRE_READ(user_mask_ptr, len);\n+  if (user_mask_ptr)\n+    PRE_READ(user_mask_ptr, len);\n }\n \n-POST_SYSCALL(sched_setaffinity)(long res, long pid, long len,\n-                                void *user_mask_ptr) {}\n+POST_SYSCALL(sched_setaffinity)\n+(long res, long pid, long len, void *user_mask_ptr) {}\n \n PRE_SYSCALL(sched_getaffinity)(long pid, long len, void *user_mask_ptr) {}\n \n-POST_SYSCALL(sched_getaffinity)(long res, long pid, long len,\n-                                void *user_mask_ptr) {\n+POST_SYSCALL(sched_getaffinity)\n+(long res, long pid, long len, void *user_mask_ptr) {\n   if (res >= 0) {\n-    if (user_mask_ptr) POST_WRITE(user_mask_ptr, len);\n+    if (user_mask_ptr)\n+      POST_WRITE(user_mask_ptr, len);\n   }\n }\n \n@@ -586,7 +635,8 @@ PRE_SYSCALL(sched_rr_get_interval)(long pid, void *interval) {}\n \n POST_SYSCALL(sched_rr_get_interval)(long res, long pid, void *interval) {\n   if (res >= 0) {\n-    if (interval) POST_WRITE(interval, struct_timespec_sz);\n+    if (interval)\n+      POST_WRITE(interval, struct_timespec_sz);\n   }\n }\n \n@@ -610,13 +660,14 @@ PRE_SYSCALL(restart_syscall)() {}\n \n POST_SYSCALL(restart_syscall)(long res) {}\n \n-PRE_SYSCALL(kexec_load)(long entry, long nr_segments, void *segments,\n-                        long flags) {}\n+PRE_SYSCALL(kexec_load)\n+(long entry, long nr_segments, void *segments, long flags) {}\n \n-POST_SYSCALL(kexec_load)(long res, long entry, long nr_segments, void *segments,\n-                         long flags) {\n+POST_SYSCALL(kexec_load)\n+(long res, long entry, long nr_segments, void *segments, long flags) {\n   if (res >= 0) {\n-    if (segments) POST_WRITE(segments, struct_kexec_segment_sz);\n+    if (segments)\n+      POST_WRITE(segments, struct_kexec_segment_sz);\n   }\n }\n \n@@ -630,38 +681,44 @@ POST_SYSCALL(exit_group)(long res, long error_code) {}\n \n PRE_SYSCALL(wait4)(long pid, void *stat_addr, long options, void *ru) {}\n \n-POST_SYSCALL(wait4)(long res, long pid, void *stat_addr, long options,\n-                    void *ru) {\n+POST_SYSCALL(wait4)\n+(long res, long pid, void *stat_addr, long options, void *ru) {\n   if (res >= 0) {\n-    if (stat_addr) POST_WRITE(stat_addr, sizeof(int));\n-    if (ru) POST_WRITE(ru, struct_rusage_sz);\n+    if (stat_addr)\n+      POST_WRITE(stat_addr, sizeof(int));\n+    if (ru)\n+      POST_WRITE(ru, struct_rusage_sz);\n   }\n }\n \n-PRE_SYSCALL(waitid)(long which, long pid, void *infop, long options, void *ru) {\n-}\n+PRE_SYSCALL(waitid)\n+(long which, long pid, void *infop, long options, void *ru) {}\n \n-POST_SYSCALL(waitid)(long res, long which, long pid, void *infop, long options,\n-                     void *ru) {\n+POST_SYSCALL(waitid)\n+(long res, long which, long pid, void *infop, long options, void *ru) {\n   if (res >= 0) {\n-    if (infop) POST_WRITE(infop, siginfo_t_sz);\n-    if (ru) POST_WRITE(ru, struct_rusage_sz);\n+    if (infop)\n+      POST_WRITE(infop, siginfo_t_sz);\n+    if (ru)\n+      POST_WRITE(ru, struct_rusage_sz);\n   }\n }\n \n PRE_SYSCALL(waitpid)(long pid, void *stat_addr, long options) {}\n \n POST_SYSCALL(waitpid)(long res, long pid, void *stat_addr, long options) {\n   if (res >= 0) {\n-    if (stat_addr) POST_WRITE(stat_addr, sizeof(int));\n+    if (stat_addr)\n+      POST_WRITE(stat_addr, sizeof(int));\n   }\n }\n \n PRE_SYSCALL(set_tid_address)(void *tidptr) {}\n \n POST_SYSCALL(set_tid_address)(long res, void *tidptr) {\n   if (res >= 0) {\n-    if (tidptr) POST_WRITE(tidptr, sizeof(int));\n+    if (tidptr)\n+      POST_WRITE(tidptr, sizeof(int));\n   }\n }\n \n@@ -682,41 +739,49 @@ POST_SYSCALL(delete_module)(long res, const void *name_user, long flags) {}\n \n PRE_SYSCALL(rt_sigprocmask)(long how, void *set, void *oset, long sigsetsize) {}\n \n-POST_SYSCALL(rt_sigprocmask)(long res, long how, kernel_sigset_t *set,\n-                             kernel_sigset_t *oset, long sigsetsize) {\n+POST_SYSCALL(rt_sigprocmask)\n+(long res, long how, kernel_sigset_t *set, kernel_sigset_t *oset,\n+ long sigsetsize) {\n   if (res >= 0) {\n-    if (set) POST_WRITE(set, sigsetsize);\n-    if (oset) POST_WRITE(oset, sigsetsize);\n+    if (set)\n+      POST_WRITE(set, sigsetsize);\n+    if (oset)\n+      POST_WRITE(oset, sigsetsize);\n   }\n }\n \n PRE_SYSCALL(rt_sigpending)(void *set, long sigsetsize) {}\n \n POST_SYSCALL(rt_sigpending)(long res, kernel_sigset_t *set, long sigsetsize) {\n   if (res >= 0) {\n-    if (set) POST_WRITE(set, sigsetsize);\n+    if (set)\n+      POST_WRITE(set, sigsetsize);\n   }\n }\n \n-PRE_SYSCALL(rt_sigtimedwait)(const kernel_sigset_t *uthese, void *uinfo,\n-                             const void *uts, long sigsetsize) {\n-  if (uthese) PRE_READ(uthese, sigsetsize);\n-  if (uts) PRE_READ(uts, struct_timespec_sz);\n+PRE_SYSCALL(rt_sigtimedwait)\n+(const kernel_sigset_t *uthese, void *uinfo, const void *uts, long sigsetsize) {\n+  if (uthese)\n+    PRE_READ(uthese, sigsetsize);\n+  if (uts)\n+    PRE_READ(uts, struct_timespec_sz);\n }\n \n-POST_SYSCALL(rt_sigtimedwait)(long res, const void *uthese, void *uinfo,\n-                              const void *uts, long sigsetsize) {\n+POST_SYSCALL(rt_sigtimedwait)\n+(long res, const void *uthese, void *uinfo, const void *uts, long sigsetsize) {\n   if (res >= 0) {\n-    if (uinfo) POST_WRITE(uinfo, siginfo_t_sz);\n+    if (uinfo)\n+      POST_WRITE(uinfo, siginfo_t_sz);\n   }\n }\n \n PRE_SYSCALL(rt_tgsigqueueinfo)(long tgid, long pid, long sig, void *uinfo) {}\n \n-POST_SYSCALL(rt_tgsigqueueinfo)(long res, long tgid, long pid, long sig,\n-                                void *uinfo) {\n+POST_SYSCALL(rt_tgsigqueueinfo)\n+(long res, long tgid, long pid, long sig, void *uinfo) {\n   if (res >= 0) {\n-    if (uinfo) POST_WRITE(uinfo, siginfo_t_sz);\n+    if (uinfo)\n+      POST_WRITE(uinfo, siginfo_t_sz);\n   }\n }\n \n@@ -736,7 +801,8 @@ PRE_SYSCALL(rt_sigqueueinfo)(long pid, long sig, void *uinfo) {}\n \n POST_SYSCALL(rt_sigqueueinfo)(long res, long pid, long sig, void *uinfo) {\n   if (res >= 0) {\n-    if (uinfo) POST_WRITE(uinfo, siginfo_t_sz);\n+    if (uinfo)\n+      POST_WRITE(uinfo, siginfo_t_sz);\n   }\n }\n \n@@ -772,11 +838,11 @@ PRE_SYSCALL(bdflush)(long func, long data) {}\n \n POST_SYSCALL(bdflush)(long res, long func, long data) {}\n \n-PRE_SYSCALL(mount)(void *dev_name, void *dir_name, void *type, long flags,\n-                   void *data) {}\n+PRE_SYSCALL(mount)\n+(void *dev_name, void *dir_name, void *type, long flags, void *data) {}\n \n-POST_SYSCALL(mount)(long res, void *dev_name, void *dir_name, void *type,\n-                    long flags, void *data) {\n+POST_SYSCALL(mount)\n+(long res, void *dev_name, void *dir_name, void *type, long flags, void *data) {\n   if (res >= 0) {\n     if (dev_name)\n       POST_WRITE(dev_name,\n@@ -826,19 +892,21 @@ PRE_SYSCALL(stat)(const void *filename, void *statbuf) {\n \n POST_SYSCALL(stat)(long res, const void *filename, void *statbuf) {\n   if (res >= 0) {\n-    if (statbuf) POST_WRITE(statbuf, struct___old_kernel_stat_sz);\n+    if (statbuf)\n+      POST_WRITE(statbuf, struct___old_kernel_stat_sz);\n   }\n }\n \n-#if !SANITIZER_ANDROID\n+#  if !SANITIZER_ANDROID\n PRE_SYSCALL(statfs)(const void *path, void *buf) {\n   if (path)\n     PRE_READ(path, __sanitizer::internal_strlen((const char *)path) + 1);\n }\n \n POST_SYSCALL(statfs)(long res, const void *path, void *buf) {\n   if (res >= 0) {\n-    if (buf) POST_WRITE(buf, struct_statfs_sz);\n+    if (buf)\n+      POST_WRITE(buf, struct_statfs_sz);\n   }\n }\n \n@@ -849,26 +917,29 @@ PRE_SYSCALL(statfs64)(const void *path, long sz, void *buf) {\n \n POST_SYSCALL(statfs64)(long res, const void *path, long sz, void *buf) {\n   if (res >= 0) {\n-    if (buf) POST_WRITE(buf, struct_statfs64_sz);\n+    if (buf)\n+      POST_WRITE(buf, struct_statfs64_sz);\n   }\n }\n \n PRE_SYSCALL(fstatfs)(long fd, void *buf) {}\n \n POST_SYSCALL(fstatfs)(long res, long fd, void *buf) {\n   if (res >= 0) {\n-    if (buf) POST_WRITE(buf, struct_statfs_sz);\n+    if (buf)\n+      POST_WRITE(buf, struct_statfs_sz);\n   }\n }\n \n PRE_SYSCALL(fstatfs64)(long fd, long sz, void *buf) {}\n \n POST_SYSCALL(fstatfs64)(long res, long fd, long sz, void *buf) {\n   if (res >= 0) {\n-    if (buf) POST_WRITE(buf, struct_statfs64_sz);\n+    if (buf)\n+      POST_WRITE(buf, struct_statfs64_sz);\n   }\n }\n-#endif // !SANITIZER_ANDROID\n+#  endif  // !SANITIZER_ANDROID\n \n PRE_SYSCALL(lstat)(const void *filename, void *statbuf) {\n   if (filename)\n@@ -878,15 +949,17 @@ PRE_SYSCALL(lstat)(const void *filename, void *statbuf) {\n \n POST_SYSCALL(lstat)(long res, const void *filename, void *statbuf) {\n   if (res >= 0) {\n-    if (statbuf) POST_WRITE(statbuf, struct___old_kernel_stat_sz);\n+    if (statbuf)\n+      POST_WRITE(statbuf, struct___old_kernel_stat_sz);\n   }\n }\n \n PRE_SYSCALL(fstat)(long fd, void *statbuf) {}\n \n POST_SYSCALL(fstat)(long res, long fd, void *statbuf) {\n   if (res >= 0) {\n-    if (statbuf) POST_WRITE(statbuf, struct___old_kernel_stat_sz);\n+    if (statbuf)\n+      POST_WRITE(statbuf, struct___old_kernel_stat_sz);\n   }\n }\n \n@@ -898,7 +971,8 @@ PRE_SYSCALL(newstat)(const void *filename, void *statbuf) {\n \n POST_SYSCALL(newstat)(long res, const void *filename, void *statbuf) {\n   if (res >= 0) {\n-    if (statbuf) POST_WRITE(statbuf, struct_kernel_stat_sz);\n+    if (statbuf)\n+      POST_WRITE(statbuf, struct_kernel_stat_sz);\n   }\n }\n \n@@ -910,27 +984,30 @@ PRE_SYSCALL(newlstat)(const void *filename, void *statbuf) {\n \n POST_SYSCALL(newlstat)(long res, const void *filename, void *statbuf) {\n   if (res >= 0) {\n-    if (statbuf) POST_WRITE(statbuf, struct_kernel_stat_sz);\n+    if (statbuf)\n+      POST_WRITE(statbuf, struct_kernel_stat_sz);\n   }\n }\n \n PRE_SYSCALL(newfstat)(long fd, void *statbuf) {}\n \n POST_SYSCALL(newfstat)(long res, long fd, void *statbuf) {\n   if (res >= 0) {\n-    if (statbuf) POST_WRITE(statbuf, struct_kernel_stat_sz);\n+    if (statbuf)\n+      POST_WRITE(statbuf, struct_kernel_stat_sz);\n   }\n }\n \n-#if !SANITIZER_ANDROID\n+#  if !SANITIZER_ANDROID\n PRE_SYSCALL(ustat)(long dev, void *ubuf) {}\n \n POST_SYSCALL(ustat)(long res, long dev, void *ubuf) {\n   if (res >= 0) {\n-    if (ubuf) POST_WRITE(ubuf, struct_ustat_sz);\n+    if (ubuf)\n+      POST_WRITE(ubuf, struct_ustat_sz);\n   }\n }\n-#endif  // !SANITIZER_ANDROID\n+#  endif  // !SANITIZER_ANDROID\n \n PRE_SYSCALL(stat64)(const void *filename, void *statbuf) {\n   if (filename)\n@@ -940,15 +1017,17 @@ PRE_SYSCALL(stat64)(const void *filename, void *statbuf) {\n \n POST_SYSCALL(stat64)(long res, const void *filename, void *statbuf) {\n   if (res >= 0) {\n-    if (statbuf) POST_WRITE(statbuf, struct_kernel_stat64_sz);\n+    if (statbuf)\n+      POST_WRITE(statbuf, struct_kernel_stat64_sz);\n   }\n }\n \n PRE_SYSCALL(fstat64)(long fd, void *statbuf) {}\n \n POST_SYSCALL(fstat64)(long res, long fd, void *statbuf) {\n   if (res >= 0) {\n-    if (statbuf) POST_WRITE(statbuf, struct_kernel_stat64_sz);\n+    if (statbuf)\n+      POST_WRITE(statbuf, struct_kernel_stat64_sz);\n   }\n }\n \n@@ -960,71 +1039,80 @@ PRE_SYSCALL(lstat64)(const void *filename, void *statbuf) {\n \n POST_SYSCALL(lstat64)(long res, const void *filename, void *statbuf) {\n   if (res >= 0) {\n-    if (statbuf) POST_WRITE(statbuf, struct_kernel_stat64_sz);\n+    if (statbuf)\n+      POST_WRITE(statbuf, struct_kernel_stat64_sz);\n   }\n }\n \n-PRE_SYSCALL(setxattr)(const void *path, const void *name, const void *value,\n-                      long size, long flags) {\n+PRE_SYSCALL(setxattr)\n+(const void *path, const void *name, const void *value, long size, long flags) {\n   if (path)\n     PRE_READ(path, __sanitizer::internal_strlen((const char *)path) + 1);\n   if (name)\n     PRE_READ(name, __sanitizer::internal_strlen((const char *)name) + 1);\n-  if (value) PRE_READ(value, size);\n+  if (value)\n+    PRE_READ(value, size);\n }\n \n-POST_SYSCALL(setxattr)(long res, const void *path, const void *name,\n-                       const void *value, long size, long flags) {}\n+POST_SYSCALL(setxattr)\n+(long res, const void *path, const void *name, const void *value, long size,\n+ long flags) {}\n \n-PRE_SYSCALL(lsetxattr)(const void *path, const void *name, const void *value,\n-                       long size, long flags) {\n+PRE_SYSCALL(lsetxattr)\n+(const void *path, const void *name, const void *value, long size, long flags) {\n   if (path)\n     PRE_READ(path, __sanitizer::internal_strlen((const char *)path) + 1);\n   if (name)\n     PRE_READ(name, __sanitizer::internal_strlen((const char *)name) + 1);\n-  if (value) PRE_READ(value, size);\n+  if (value)\n+    PRE_READ(value, size);\n }\n \n-POST_SYSCALL(lsetxattr)(long res, const void *path, const void *name,\n-                        const void *value, long size, long flags) {}\n+POST_SYSCALL(lsetxattr)\n+(long res, const void *path, const void *name, const void *value, long size,\n+ long flags) {}\n \n-PRE_SYSCALL(fsetxattr)(long fd, const void *name, const void *value, long size,\n-                       long flags) {\n+PRE_SYSCALL(fsetxattr)\n+(long fd, const void *name, const void *value, long size, long flags) {\n   if (name)\n     PRE_READ(name, __sanitizer::internal_strlen((const char *)name) + 1);\n-  if (value) PRE_READ(value, size);\n+  if (value)\n+    PRE_READ(value, size);\n }\n \n-POST_SYSCALL(fsetxattr)(long res, long fd, const void *name, const void *value,\n-                        long size, long flags) {}\n+POST_SYSCALL(fsetxattr)\n+(long res, long fd, const void *name, const void *value, long size,\n+ long flags) {}\n \n-PRE_SYSCALL(getxattr)(const void *path, const void *name, void *value,\n-                      long size) {\n+PRE_SYSCALL(getxattr)\n+(const void *path, const void *name, void *value, long size) {\n   if (path)\n     PRE_READ(path, __sanitizer::internal_strlen((const char *)path) + 1);\n   if (name)\n     PRE_READ(name, __sanitizer::internal_strlen((const char *)name) + 1);\n }\n \n-POST_SYSCALL(getxattr)(long res, const void *path, const void *name,\n-                       void *value, long size) {\n+POST_SYSCALL(getxattr)\n+(long res, const void *path, const void *name, void *value, long size) {\n   if (size && res > 0) {\n-    if (value) POST_WRITE(value, res);\n+    if (value)\n+      POST_WRITE(value, res);\n   }\n }\n \n-PRE_SYSCALL(lgetxattr)(const void *path, const void *name, void *value,\n-                       long size) {\n+PRE_SYSCALL(lgetxattr)\n+(const void *path, const void *name, void *value, long size) {\n   if (path)\n     PRE_READ(path, __sanitizer::internal_strlen((const char *)path) + 1);\n   if (name)\n     PRE_READ(name, __sanitizer::internal_strlen((const char *)name) + 1);\n }\n \n-POST_SYSCALL(lgetxattr)(long res, const void *path, const void *name,\n-                        void *value, long size) {\n+POST_SYSCALL(lgetxattr)\n+(long res, const void *path, const void *name, void *value, long size) {\n   if (size && res > 0) {\n-    if (value) POST_WRITE(value, res);\n+    if (value)\n+      POST_WRITE(value, res);\n   }\n }\n \n@@ -1033,10 +1121,11 @@ PRE_SYSCALL(fgetxattr)(long fd, const void *name, void *value, long size) {\n     PRE_READ(name, __sanitizer::internal_strlen((const char *)name) + 1);\n }\n \n-POST_SYSCALL(fgetxattr)(long res, long fd, const void *name, void *value,\n-                        long size) {\n+POST_SYSCALL(fgetxattr)\n+(long res, long fd, const void *name, void *value, long size) {\n   if (size && res > 0) {\n-    if (value) POST_WRITE(value, res);\n+    if (value)\n+      POST_WRITE(value, res);\n   }\n }\n \n@@ -1047,7 +1136,8 @@ PRE_SYSCALL(listxattr)(const void *path, void *list, long size) {\n \n POST_SYSCALL(listxattr)(long res, const void *path, void *list, long size) {\n   if (size && res > 0) {\n-    if (list) POST_WRITE(list, res);\n+    if (list)\n+      POST_WRITE(list, res);\n   }\n }\n \n@@ -1058,15 +1148,17 @@ PRE_SYSCALL(llistxattr)(const void *path, void *list, long size) {\n \n POST_SYSCALL(llistxattr)(long res, const void *path, void *list, long size) {\n   if (size && res > 0) {\n-    if (list) POST_WRITE(list, res);\n+    if (list)\n+      POST_WRITE(list, res);\n   }\n }\n \n PRE_SYSCALL(flistxattr)(long fd, void *list, long size) {}\n \n POST_SYSCALL(flistxattr)(long res, long fd, void *list, long size) {\n   if (size && res > 0) {\n-    if (list) POST_WRITE(list, res);\n+    if (list)\n+      POST_WRITE(list, res);\n   }\n }\n \n@@ -1103,17 +1195,17 @@ PRE_SYSCALL(mprotect)(long start, long len, long prot) {}\n \n POST_SYSCALL(mprotect)(long res, long start, long len, long prot) {}\n \n-PRE_SYSCALL(mremap)(long addr, long old_len, long new_len, long flags,\n-                    long new_addr) {}\n+PRE_SYSCALL(mremap)\n+(long addr, long old_len, long new_len, long flags, long new_addr) {}\n \n-POST_SYSCALL(mremap)(long res, long addr, long old_len, long new_len,\n-                     long flags, long new_addr) {}\n+POST_SYSCALL(mremap)\n+(long res, long addr, long old_len, long new_len, long flags, long new_addr) {}\n \n-PRE_SYSCALL(remap_file_pages)(long start, long size, long prot, long pgoff,\n-                              long flags) {}\n+PRE_SYSCALL(remap_file_pages)\n+(long start, long size, long prot, long pgoff, long flags) {}\n \n-POST_SYSCALL(remap_file_pages)(long res, long start, long size, long prot,\n-                               long pgoff, long flags) {}\n+POST_SYSCALL(remap_file_pages)\n+(long res, long start, long size, long prot, long pgoff, long flags) {}\n \n PRE_SYSCALL(msync)(long start, long len, long flags) {}\n \n@@ -1189,7 +1281,8 @@ PRE_SYSCALL(link)(const void *oldname, const void *newname) {\n POST_SYSCALL(link)(long res, const void *oldname, const void *newname) {}\n \n PRE_SYSCALL(symlink)(const void *old, const void *new_) {\n-  if (old) PRE_READ(old, __sanitizer::internal_strlen((const char *)old) + 1);\n+  if (old)\n+    PRE_READ(old, __sanitizer::internal_strlen((const char *)old) + 1);\n   if (new_)\n     PRE_READ(new_, __sanitizer::internal_strlen((const char *)new_) + 1);\n }\n@@ -1237,14 +1330,16 @@ PRE_SYSCALL(pipe)(void *fildes) {}\n \n POST_SYSCALL(pipe)(long res, void *fildes) {\n   if (res >= 0)\n-    if (fildes) POST_WRITE(fildes, sizeof(int) * 2);\n+    if (fildes)\n+      POST_WRITE(fildes, sizeof(int) * 2);\n }\n \n PRE_SYSCALL(pipe2)(void *fildes, long flags) {}\n \n POST_SYSCALL(pipe2)(long res, void *fildes, long flags) {\n   if (res >= 0)\n-    if (fildes) POST_WRITE(fildes, sizeof(int) * 2);\n+    if (fildes)\n+      POST_WRITE(fildes, sizeof(int) * 2);\n }\n \n PRE_SYSCALL(dup)(long fildes) {}\n@@ -1272,33 +1367,41 @@ PRE_SYSCALL(flock)(long fd, long cmd) {}\n POST_SYSCALL(flock)(long res, long fd, long cmd) {}\n \n PRE_SYSCALL(io_setup)(long nr_reqs, void **ctx) {\n-  if (ctx) PRE_WRITE(ctx, sizeof(*ctx));\n+  if (ctx)\n+    PRE_WRITE(ctx, sizeof(*ctx));\n }\n \n POST_SYSCALL(io_setup)(long res, long nr_reqs, void **ctx) {\n   if (res >= 0) {\n-    if (ctx) POST_WRITE(ctx, sizeof(*ctx));\n+    if (ctx)\n+      POST_WRITE(ctx, sizeof(*ctx));\n     // (*ctx) is actually a pointer to a kernel mapped page, and there are\n     // people out there who are crazy enough to peek into that page's 32-byte\n     // header.\n-    if (*ctx) POST_WRITE(*ctx, 32);\n+    if (*ctx)\n+      POST_WRITE(*ctx, 32);\n   }\n }\n \n PRE_SYSCALL(io_destroy)(long ctx) {}\n \n POST_SYSCALL(io_destroy)(long res, long ctx) {}\n \n-PRE_SYSCALL(io_getevents)(long ctx_id, long min_nr, long nr,\n-                          __sanitizer_io_event *ioevpp, void *timeout) {\n-  if (timeout) PRE_READ(timeout, struct_timespec_sz);\n+PRE_SYSCALL(io_getevents)\n+(long ctx_id, long min_nr, long nr, __sanitizer_io_event *ioevpp,\n+ void *timeout) {\n+  if (timeout)\n+    PRE_READ(timeout, struct_timespec_sz);\n }\n \n-POST_SYSCALL(io_getevents)(long res, long ctx_id, long min_nr, long nr,\n-                           __sanitizer_io_event *ioevpp, void *timeout) {\n+POST_SYSCALL(io_getevents)\n+(long res, long ctx_id, long min_nr, long nr, __sanitizer_io_event *ioevpp,\n+ void *timeout) {\n   if (res >= 0) {\n-    if (ioevpp) POST_WRITE(ioevpp, res * sizeof(*ioevpp));\n-    if (timeout) POST_WRITE(timeout, struct_timespec_sz);\n+    if (ioevpp)\n+      POST_WRITE(ioevpp, res * sizeof(*ioevpp));\n+    if (timeout)\n+      POST_WRITE(timeout, struct_timespec_sz);\n   }\n   for (long i = 0; i < res; i++) {\n     // We synchronize io_submit -> io_getevents/io_cancel using the\n@@ -1308,26 +1411,26 @@ POST_SYSCALL(io_getevents)(long res, long ctx_id, long min_nr, long nr,\n     // synchronize on 0. But there does not seem to be a better solution\n     // (except wrapping all operations in own context, which is unreliable).\n     // We can not reliably extract fildes in io_getevents.\n-    COMMON_SYSCALL_ACQUIRE((void*)ioevpp[i].data);\n+    COMMON_SYSCALL_ACQUIRE((void *)ioevpp[i].data);\n   }\n }\n \n PRE_SYSCALL(io_submit)(long ctx_id, long nr, __sanitizer_iocb **iocbpp) {\n   for (long i = 0; i < nr; ++i) {\n     uptr op = iocbpp[i]->aio_lio_opcode;\n-    void *data = (void*)iocbpp[i]->aio_data;\n-    void *buf = (void*)iocbpp[i]->aio_buf;\n+    void *data = (void *)iocbpp[i]->aio_data;\n+    void *buf = (void *)iocbpp[i]->aio_buf;\n     uptr len = (uptr)iocbpp[i]->aio_nbytes;\n     if (op == iocb_cmd_pwrite && buf && len) {\n       PRE_READ(buf, len);\n     } else if (op == iocb_cmd_pread && buf && len) {\n       POST_WRITE(buf, len);\n     } else if (op == iocb_cmd_pwritev) {\n-      __sanitizer_iovec *iovec = (__sanitizer_iovec*)buf;\n+      __sanitizer_iovec *iovec = (__sanitizer_iovec *)buf;\n       for (uptr v = 0; v < len; v++)\n         PRE_READ(iovec[v].iov_base, iovec[v].iov_len);\n     } else if (op == iocb_cmd_preadv) {\n-      __sanitizer_iovec *iovec = (__sanitizer_iovec*)buf;\n+      __sanitizer_iovec *iovec = (__sanitizer_iovec *)buf;\n       for (uptr v = 0; v < len; v++)\n         POST_WRITE(iovec[v].iov_base, iovec[v].iov_len);\n     }\n@@ -1336,19 +1439,18 @@ PRE_SYSCALL(io_submit)(long ctx_id, long nr, __sanitizer_iocb **iocbpp) {\n   }\n }\n \n-POST_SYSCALL(io_submit)(long res, long ctx_id, long nr,\n-    __sanitizer_iocb **iocbpp) {}\n+POST_SYSCALL(io_submit)\n+(long res, long ctx_id, long nr, __sanitizer_iocb **iocbpp) {}\n \n-PRE_SYSCALL(io_cancel)(long ctx_id, __sanitizer_iocb *iocb,\n-    __sanitizer_io_event *result) {\n-}\n+PRE_SYSCALL(io_cancel)\n+(long ctx_id, __sanitizer_iocb *iocb, __sanitizer_io_event *result) {}\n \n-POST_SYSCALL(io_cancel)(long res, long ctx_id, __sanitizer_iocb *iocb,\n-    __sanitizer_io_event *result) {\n+POST_SYSCALL(io_cancel)\n+(long res, long ctx_id, __sanitizer_iocb *iocb, __sanitizer_io_event *result) {\n   if (res == 0) {\n     if (result) {\n       // See comment in io_getevents.\n-      COMMON_SYSCALL_ACQUIRE((void*)result->data);\n+      COMMON_SYSCALL_ACQUIRE((void *)result->data);\n       POST_WRITE(result, sizeof(*result));\n     }\n     if (iocb)\n@@ -1358,19 +1460,23 @@ POST_SYSCALL(io_cancel)(long res, long ctx_id, __sanitizer_iocb *iocb,\n \n PRE_SYSCALL(sendfile)(long out_fd, long in_fd, void *offset, long count) {}\n \n-POST_SYSCALL(sendfile)(long res, long out_fd, long in_fd,\n-                       __sanitizer___kernel_off_t *offset, long count) {\n+POST_SYSCALL(sendfile)\n+(long res, long out_fd, long in_fd, __sanitizer___kernel_off_t *offset,\n+ long count) {\n   if (res >= 0) {\n-    if (offset) POST_WRITE(offset, sizeof(*offset));\n+    if (offset)\n+      POST_WRITE(offset, sizeof(*offset));\n   }\n }\n \n PRE_SYSCALL(sendfile64)(long out_fd, long in_fd, void *offset, long count) {}\n \n-POST_SYSCALL(sendfile64)(long res, long out_fd, long in_fd,\n-                         __sanitizer___kernel_loff_t *offset, long count) {\n+POST_SYSCALL(sendfile64)\n+(long res, long out_fd, long in_fd, __sanitizer___kernel_loff_t *offset,\n+ long count) {\n   if (res >= 0) {\n-    if (offset) POST_WRITE(offset, sizeof(*offset));\n+    if (offset)\n+      POST_WRITE(offset, sizeof(*offset));\n   }\n }\n \n@@ -1402,9 +1508,7 @@ PRE_SYSCALL(open)(const void *filename, long flags, long mode) {\n \n POST_SYSCALL(open)(long res, const void *filename, long flags, long mode) {}\n \n-PRE_SYSCALL(close)(long fd) {\n-  COMMON_SYSCALL_FD_CLOSE((int)fd);\n-}\n+PRE_SYSCALL(close)(long fd) { COMMON_SYSCALL_FD_CLOSE((int)fd); }\n \n POST_SYSCALL(close)(long res, long fd) {}\n \n@@ -1440,7 +1544,7 @@ PRE_SYSCALL(fchown)(long fd, long user, long group) {}\n \n POST_SYSCALL(fchown)(long res, long fd, long user, long group) {}\n \n-#if SANITIZER_USES_UID16_SYSCALLS\n+#  if SANITIZER_USES_UID16_SYSCALLS\n PRE_SYSCALL(chown16)(const void *filename, long user, long group) {\n   if (filename)\n     PRE_READ(filename,\n@@ -1483,13 +1587,16 @@ POST_SYSCALL(setresuid16)(long res, long ruid, long euid, long suid) {}\n \n PRE_SYSCALL(getresuid16)(void *ruid, void *euid, void *suid) {}\n \n-POST_SYSCALL(getresuid16)(long res, __sanitizer___kernel_old_uid_t *ruid,\n-                          __sanitizer___kernel_old_uid_t *euid,\n-                          __sanitizer___kernel_old_uid_t *suid) {\n+POST_SYSCALL(getresuid16)\n+(long res, __sanitizer___kernel_old_uid_t *ruid,\n+ __sanitizer___kernel_old_uid_t *euid, __sanitizer___kernel_old_uid_t *suid) {\n   if (res >= 0) {\n-    if (ruid) POST_WRITE(ruid, sizeof(*ruid));\n-    if (euid) POST_WRITE(euid, sizeof(*euid));\n-    if (suid) POST_WRITE(suid, sizeof(*suid));\n+    if (ruid)\n+      POST_WRITE(ruid, sizeof(*ruid));\n+    if (euid)\n+      POST_WRITE(euid, sizeof(*euid));\n+    if (suid)\n+      POST_WRITE(suid, sizeof(*suid));\n   }\n }\n \n@@ -1499,13 +1606,16 @@ POST_SYSCALL(setresgid16)(long res, long rgid, long egid, long sgid) {}\n \n PRE_SYSCALL(getresgid16)(void *rgid, void *egid, void *sgid) {}\n \n-POST_SYSCALL(getresgid16)(long res, __sanitizer___kernel_old_gid_t *rgid,\n-                          __sanitizer___kernel_old_gid_t *egid,\n-                          __sanitizer___kernel_old_gid_t *sgid) {\n+POST_SYSCALL(getresgid16)\n+(long res, __sanitizer___kernel_old_gid_t *rgid,\n+ __sanitizer___kernel_old_gid_t *egid, __sanitizer___kernel_old_gid_t *sgid) {\n   if (res >= 0) {\n-    if (rgid) POST_WRITE(rgid, sizeof(*rgid));\n-    if (egid) POST_WRITE(egid, sizeof(*egid));\n-    if (sgid) POST_WRITE(sgid, sizeof(*sgid));\n+    if (rgid)\n+      POST_WRITE(rgid, sizeof(*rgid));\n+    if (egid)\n+      POST_WRITE(egid, sizeof(*egid));\n+    if (sgid)\n+      POST_WRITE(sgid, sizeof(*sgid));\n   }\n }\n \n@@ -1517,23 +1627,25 @@ PRE_SYSCALL(setfsgid16)(long gid) {}\n \n POST_SYSCALL(setfsgid16)(long res, long gid) {}\n \n-PRE_SYSCALL(getgroups16)(long gidsetsize,\n-                         __sanitizer___kernel_old_gid_t *grouplist) {}\n+PRE_SYSCALL(getgroups16)\n+(long gidsetsize, __sanitizer___kernel_old_gid_t *grouplist) {}\n \n-POST_SYSCALL(getgroups16)(long res, long gidsetsize,\n-                          __sanitizer___kernel_old_gid_t *grouplist) {\n+POST_SYSCALL(getgroups16)\n+(long res, long gidsetsize, __sanitizer___kernel_old_gid_t *grouplist) {\n   if (res >= 0) {\n-    if (grouplist) POST_WRITE(grouplist, res * sizeof(*grouplist));\n+    if (grouplist)\n+      POST_WRITE(grouplist, res * sizeof(*grouplist));\n   }\n }\n \n-PRE_SYSCALL(setgroups16)(long gidsetsize,\n-                         __sanitizer___kernel_old_gid_t *grouplist) {\n-  if (grouplist) POST_WRITE(grouplist, gidsetsize * sizeof(*grouplist));\n+PRE_SYSCALL(setgroups16)\n+(long gidsetsize, __sanitizer___kernel_old_gid_t *grouplist) {\n+  if (grouplist)\n+    POST_WRITE(grouplist, gidsetsize * sizeof(*grouplist));\n }\n \n-POST_SYSCALL(setgroups16)(long res, long gidsetsize,\n-                          __sanitizer___kernel_old_gid_t *grouplist) {}\n+POST_SYSCALL(setgroups16)\n+(long res, long gidsetsize, __sanitizer___kernel_old_gid_t *grouplist) {}\n \n PRE_SYSCALL(getuid16)() {}\n \n@@ -1550,7 +1662,7 @@ POST_SYSCALL(getgid16)(long res) {}\n PRE_SYSCALL(getegid16)() {}\n \n POST_SYSCALL(getegid16)(long res) {}\n-#endif // SANITIZER_USES_UID16_SYSCALLS\n+#  endif  // SANITIZER_USES_UID16_SYSCALLS\n \n PRE_SYSCALL(utime)(void *filename, void *times) {}\n \n@@ -1559,7 +1671,8 @@ POST_SYSCALL(utime)(long res, void *filename, void *times) {\n     if (filename)\n       POST_WRITE(filename,\n                  __sanitizer::internal_strlen((const char *)filename) + 1);\n-    if (times) POST_WRITE(times, struct_utimbuf_sz);\n+    if (times)\n+      POST_WRITE(times, struct_utimbuf_sz);\n   }\n }\n \n@@ -1570,99 +1683,113 @@ POST_SYSCALL(utimes)(long res, void *filename, void *utimes) {\n     if (filename)\n       POST_WRITE(filename,\n                  __sanitizer::internal_strlen((const char *)filename) + 1);\n-    if (utimes) POST_WRITE(utimes, timeval_sz);\n+    if (utimes)\n+      POST_WRITE(utimes, timeval_sz);\n   }\n }\n \n PRE_SYSCALL(lseek)(long fd, long offset, long origin) {}\n \n POST_SYSCALL(lseek)(long res, long fd, long offset, long origin) {}\n \n-PRE_SYSCALL(llseek)(long fd, long offset_high, long offset_low, void *result,\n-                    long origin) {}\n+PRE_SYSCALL(llseek)\n+(long fd, long offset_high, long offset_low, void *result, long origin) {}\n \n-POST_SYSCALL(llseek)(long res, long fd, long offset_high, long offset_low,\n-                     void *result, long origin) {\n+POST_SYSCALL(llseek)\n+(long res, long fd, long offset_high, long offset_low, void *result,\n+ long origin) {\n   if (res >= 0) {\n-    if (result) POST_WRITE(result, sizeof(long long));\n+    if (result)\n+      POST_WRITE(result, sizeof(long long));\n   }\n }\n \n PRE_SYSCALL(readv)(long fd, const __sanitizer_iovec *vec, long vlen) {}\n \n-POST_SYSCALL(readv)(long res, long fd, const __sanitizer_iovec *vec,\n-                    long vlen) {\n+POST_SYSCALL(readv)\n+(long res, long fd, const __sanitizer_iovec *vec, long vlen) {\n   if (res >= 0) {\n-    if (vec) kernel_write_iovec(vec, vlen, res);\n+    if (vec)\n+      kernel_write_iovec(vec, vlen, res);\n   }\n }\n \n PRE_SYSCALL(write)(long fd, const void *buf, long count) {\n-  if (buf) PRE_READ(buf, count);\n+  if (buf)\n+    PRE_READ(buf, count);\n }\n \n POST_SYSCALL(write)(long res, long fd, const void *buf, long count) {}\n \n PRE_SYSCALL(writev)(long fd, const __sanitizer_iovec *vec, long vlen) {}\n \n-POST_SYSCALL(writev)(long res, long fd, const __sanitizer_iovec *vec,\n-                     long vlen) {\n+POST_SYSCALL(writev)\n+(long res, long fd, const __sanitizer_iovec *vec, long vlen) {\n   if (res >= 0) {\n-    if (vec) kernel_read_iovec(vec, vlen, res);\n+    if (vec)\n+      kernel_read_iovec(vec, vlen, res);\n   }\n }\n \n-#ifdef _LP64\n+#  ifdef _LP64\n PRE_SYSCALL(pread64)(long fd, void *buf, long count, long pos) {}\n \n POST_SYSCALL(pread64)(long res, long fd, void *buf, long count, long pos) {\n   if (res >= 0) {\n-    if (buf) POST_WRITE(buf, res);\n+    if (buf)\n+      POST_WRITE(buf, res);\n   }\n }\n \n PRE_SYSCALL(pwrite64)(long fd, const void *buf, long count, long pos) {\n-  if (buf) PRE_READ(buf, count);\n+  if (buf)\n+    PRE_READ(buf, count);\n }\n \n-POST_SYSCALL(pwrite64)(long res, long fd, const void *buf, long count,\n-                       long pos) {}\n-#else\n+POST_SYSCALL(pwrite64)\n+(long res, long fd, const void *buf, long count, long pos) {}\n+#  else\n PRE_SYSCALL(pread64)(long fd, void *buf, long count, long pos0, long pos1) {}\n \n-POST_SYSCALL(pread64)(long res, long fd, void *buf, long count, long pos0,\n-                      long pos1) {\n+POST_SYSCALL(pread64)\n+(long res, long fd, void *buf, long count, long pos0, long pos1) {\n   if (res >= 0) {\n-    if (buf) POST_WRITE(buf, res);\n+    if (buf)\n+      POST_WRITE(buf, res);\n   }\n }\n \n-PRE_SYSCALL(pwrite64)(long fd, const void *buf, long count, long pos0,\n-                      long pos1) {\n-  if (buf) PRE_READ(buf, count);\n+PRE_SYSCALL(pwrite64)\n+(long fd, const void *buf, long count, long pos0, long pos1) {\n+  if (buf)\n+    PRE_READ(buf, count);\n }\n \n-POST_SYSCALL(pwrite64)(long res, long fd, const void *buf, long count,\n-                       long pos0, long pos1) {}\n-#endif\n+POST_SYSCALL(pwrite64)\n+(long res, long fd, const void *buf, long count, long pos0, long pos1) {}\n+#  endif\n \n-PRE_SYSCALL(preadv)(long fd, const __sanitizer_iovec *vec, long vlen,\n-                    long pos_l, long pos_h) {}\n+PRE_SYSCALL(preadv)\n+(long fd, const __sanitizer_iovec *vec, long vlen, long pos_l, long pos_h) {}\n \n-POST_SYSCALL(preadv)(long res, long fd, const __sanitizer_iovec *vec, long vlen,\n-                     long pos_l, long pos_h) {\n+POST_SYSCALL(preadv)\n+(long res, long fd, const __sanitizer_iovec *vec, long vlen, long pos_l,\n+ long pos_h) {\n   if (res >= 0) {\n-    if (vec) kernel_write_iovec(vec, vlen, res);\n+    if (vec)\n+      kernel_write_iovec(vec, vlen, res);\n   }\n }\n \n-PRE_SYSCALL(pwritev)(long fd, const __sanitizer_iovec *vec, long vlen,\n-                     long pos_l, long pos_h) {}\n+PRE_SYSCALL(pwritev)\n+(long fd, const __sanitizer_iovec *vec, long vlen, long pos_l, long pos_h) {}\n \n-POST_SYSCALL(pwritev)(long res, long fd, const __sanitizer_iovec *vec,\n-                      long vlen, long pos_l, long pos_h) {\n+POST_SYSCALL(pwritev)\n+(long res, long fd, const __sanitizer_iovec *vec, long vlen, long pos_l,\n+ long pos_h) {\n   if (res >= 0) {\n-    if (vec) kernel_read_iovec(vec, vlen, res);\n+    if (vec)\n+      kernel_read_iovec(vec, vlen, res);\n   }\n }\n \n@@ -1717,127 +1844,145 @@ PRE_SYSCALL(quotactl)(long cmd, const void *special, long id, void *addr) {\n     PRE_READ(special, __sanitizer::internal_strlen((const char *)special) + 1);\n }\n \n-POST_SYSCALL(quotactl)(long res, long cmd, const void *special, long id,\n-                       void *addr) {}\n+POST_SYSCALL(quotactl)\n+(long res, long cmd, const void *special, long id, void *addr) {}\n \n PRE_SYSCALL(getdents)(long fd, void *dirent, long count) {}\n \n POST_SYSCALL(getdents)(long res, long fd, void *dirent, long count) {\n   if (res >= 0) {\n-    if (dirent) POST_WRITE(dirent, res);\n+    if (dirent)\n+      POST_WRITE(dirent, res);\n   }\n }\n \n PRE_SYSCALL(getdents64)(long fd, void *dirent, long count) {}\n \n POST_SYSCALL(getdents64)(long res, long fd, void *dirent, long count) {\n   if (res >= 0) {\n-    if (dirent) POST_WRITE(dirent, res);\n+    if (dirent)\n+      POST_WRITE(dirent, res);\n   }\n }\n \n-PRE_SYSCALL(setsockopt)(long fd, long level, long optname, void *optval,\n-                        long optlen) {}\n+PRE_SYSCALL(setsockopt)\n+(long fd, long level, long optname, void *optval, long optlen) {}\n \n-POST_SYSCALL(setsockopt)(long res, long fd, long level, long optname,\n-                         void *optval, long optlen) {\n+POST_SYSCALL(setsockopt)\n+(long res, long fd, long level, long optname, void *optval, long optlen) {\n   if (res >= 0) {\n     if (optval)\n       POST_WRITE(optval,\n                  __sanitizer::internal_strlen((const char *)optval) + 1);\n   }\n }\n \n-PRE_SYSCALL(getsockopt)(long fd, long level, long optname, void *optval,\n-                        void *optlen) {}\n+PRE_SYSCALL(getsockopt)\n+(long fd, long level, long optname, void *optval, void *optlen) {}\n \n-POST_SYSCALL(getsockopt)(long res, long fd, long level, long optname,\n-                         void *optval, void *optlen) {\n+POST_SYSCALL(getsockopt)\n+(long res, long fd, long level, long optname, void *optval, void *optlen) {\n   if (res >= 0) {\n     if (optval)\n       POST_WRITE(optval,\n                  __sanitizer::internal_strlen((const char *)optval) + 1);\n-    if (optlen) POST_WRITE(optlen, sizeof(int));\n+    if (optlen)\n+      POST_WRITE(optlen, sizeof(int));\n   }\n }\n \n PRE_SYSCALL(bind)(long arg0, sanitizer_kernel_sockaddr *arg1, long arg2) {}\n \n-POST_SYSCALL(bind)(long res, long arg0, sanitizer_kernel_sockaddr *arg1,\n-                   long arg2) {\n+POST_SYSCALL(bind)\n+(long res, long arg0, sanitizer_kernel_sockaddr *arg1, long arg2) {\n   if (res >= 0) {\n-    if (arg1) POST_WRITE(arg1, sizeof(*arg1));\n+    if (arg1)\n+      POST_WRITE(arg1, sizeof(*arg1));\n   }\n }\n \n PRE_SYSCALL(connect)(long arg0, sanitizer_kernel_sockaddr *arg1, long arg2) {}\n \n-POST_SYSCALL(connect)(long res, long arg0, sanitizer_kernel_sockaddr *arg1,\n-                      long arg2) {\n+POST_SYSCALL(connect)\n+(long res, long arg0, sanitizer_kernel_sockaddr *arg1, long arg2) {\n   if (res >= 0) {\n-    if (arg1) POST_WRITE(arg1, sizeof(*arg1));\n+    if (arg1)\n+      POST_WRITE(arg1, sizeof(*arg1));\n   }\n }\n \n PRE_SYSCALL(accept)(long arg0, sanitizer_kernel_sockaddr *arg1, void *arg2) {}\n \n-POST_SYSCALL(accept)(long res, long arg0, sanitizer_kernel_sockaddr *arg1,\n-                     void *arg2) {\n+POST_SYSCALL(accept)\n+(long res, long arg0, sanitizer_kernel_sockaddr *arg1, void *arg2) {\n   if (res >= 0) {\n-    if (arg1) POST_WRITE(arg1, sizeof(*arg1));\n-    if (arg2) POST_WRITE(arg2, sizeof(unsigned));\n+    if (arg1)\n+      POST_WRITE(arg1, sizeof(*arg1));\n+    if (arg2)\n+      POST_WRITE(arg2, sizeof(unsigned));\n   }\n }\n \n-PRE_SYSCALL(accept4)(long arg0, sanitizer_kernel_sockaddr *arg1, void *arg2,\n-                     long arg3) {}\n+PRE_SYSCALL(accept4)\n+(long arg0, sanitizer_kernel_sockaddr *arg1, void *arg2, long arg3) {}\n \n-POST_SYSCALL(accept4)(long res, long arg0, sanitizer_kernel_sockaddr *arg1,\n-                      void *arg2, long arg3) {\n+POST_SYSCALL(accept4)\n+(long res, long arg0, sanitizer_kernel_sockaddr *arg1, void *arg2, long arg3) {\n   if (res >= 0) {\n-    if (arg1) POST_WRITE(arg1, sizeof(*arg1));\n-    if (arg2) POST_WRITE(arg2, sizeof(unsigned));\n+    if (arg1)\n+      POST_WRITE(arg1, sizeof(*arg1));\n+    if (arg2)\n+      POST_WRITE(arg2, sizeof(unsigned));\n   }\n }\n \n-PRE_SYSCALL(getsockname)(long arg0, sanitizer_kernel_sockaddr *arg1,\n-                         void *arg2) {}\n+PRE_SYSCALL(getsockname)\n+(long arg0, sanitizer_kernel_sockaddr *arg1, void *arg2) {}\n \n-POST_SYSCALL(getsockname)(long res, long arg0, sanitizer_kernel_sockaddr *arg1,\n-                          void *arg2) {\n+POST_SYSCALL(getsockname)\n+(long res, long arg0, sanitizer_kernel_sockaddr *arg1, void *arg2) {\n   if (res >= 0) {\n-    if (arg1) POST_WRITE(arg1, sizeof(*arg1));\n-    if (arg2) POST_WRITE(arg2, sizeof(unsigned));\n+    if (arg1)\n+      POST_WRITE(arg1, sizeof(*arg1));\n+    if (arg2)\n+      POST_WRITE(arg2, sizeof(unsigned));\n   }\n }\n \n-PRE_SYSCALL(getpeername)(long arg0, sanitizer_kernel_sockaddr *arg1,\n-                         void *arg2) {}\n+PRE_SYSCALL(getpeername)\n+(long arg0, sanitizer_kernel_sockaddr *arg1, void *arg2) {}\n \n-POST_SYSCALL(getpeername)(long res, long arg0, sanitizer_kernel_sockaddr *arg1,\n-                          void *arg2) {\n+POST_SYSCALL(getpeername)\n+(long res, long arg0, sanitizer_kernel_sockaddr *arg1, void *arg2) {\n   if (res >= 0) {\n-    if (arg1) POST_WRITE(arg1, sizeof(*arg1));\n-    if (arg2) POST_WRITE(arg2, sizeof(unsigned));\n+    if (arg1)\n+      POST_WRITE(arg1, sizeof(*arg1));\n+    if (arg2)\n+      POST_WRITE(arg2, sizeof(unsigned));\n   }\n }\n \n PRE_SYSCALL(send)(long arg0, void *arg1, long arg2, long arg3) {}\n \n POST_SYSCALL(send)(long res, long arg0, void *arg1, long arg2, long arg3) {\n   if (res) {\n-    if (arg1) POST_READ(arg1, res);\n+    if (arg1)\n+      POST_READ(arg1, res);\n   }\n }\n \n-PRE_SYSCALL(sendto)(long arg0, void *arg1, long arg2, long arg3,\n-                    sanitizer_kernel_sockaddr *arg4, long arg5) {}\n+PRE_SYSCALL(sendto)\n+(long arg0, void *arg1, long arg2, long arg3, sanitizer_kernel_sockaddr *arg4,\n+ long arg5) {}\n \n-POST_SYSCALL(sendto)(long res, long arg0, void *arg1, long arg2, long arg3,\n-                     sanitizer_kernel_sockaddr *arg4, long arg5) {\n+POST_SYSCALL(sendto)\n+(long res, long arg0, void *arg1, long arg2, long arg3,\n+ sanitizer_kernel_sockaddr *arg4, long arg5) {\n   if (res >= 0) {\n-    if (arg1) POST_READ(arg1, res);\n-    if (arg4) POST_WRITE(arg4, sizeof(*arg4));\n+    if (arg1)\n+      POST_READ(arg1, res);\n+    if (arg4)\n+      POST_WRITE(arg4, sizeof(*arg4));\n   }\n }\n \n@@ -1857,19 +2002,25 @@ PRE_SYSCALL(recv)(long arg0, void *buf, long len, long flags) {}\n \n POST_SYSCALL(recv)(long res, void *buf, long len, long flags) {\n   if (res >= 0) {\n-    if (buf) POST_WRITE(buf, res);\n+    if (buf)\n+      POST_WRITE(buf, res);\n   }\n }\n \n-PRE_SYSCALL(recvfrom)(long arg0, void *buf, long len, long flags,\n-                      sanitizer_kernel_sockaddr *arg4, void *arg5) {}\n+PRE_SYSCALL(recvfrom)\n+(long arg0, void *buf, long len, long flags, sanitizer_kernel_sockaddr *arg4,\n+ void *arg5) {}\n \n-POST_SYSCALL(recvfrom)(long res, long arg0, void *buf, long len, long flags,\n-                       sanitizer_kernel_sockaddr *arg4, void *arg5) {\n+POST_SYSCALL(recvfrom)\n+(long res, long arg0, void *buf, long len, long flags,\n+ sanitizer_kernel_sockaddr *arg4, void *arg5) {\n   if (res >= 0) {\n-    if (buf) POST_WRITE(buf, res);\n-    if (arg4) POST_WRITE(arg4, sizeof(*arg4));\n-    if (arg5) POST_WRITE(arg5, sizeof(int));\n+    if (buf)\n+      POST_WRITE(buf, res);\n+    if (arg4)\n+      POST_WRITE(arg4, sizeof(*arg4));\n+    if (arg5)\n+      POST_WRITE(arg5, sizeof(int));\n   }\n }\n \n@@ -1881,14 +2032,16 @@ PRE_SYSCALL(socketpair)(long arg0, long arg1, long arg2, int *sv) {}\n \n POST_SYSCALL(socketpair)(long res, long arg0, long arg1, long arg2, int *sv) {\n   if (res >= 0)\n-    if (sv) POST_WRITE(sv, sizeof(int) * 2);\n+    if (sv)\n+      POST_WRITE(sv, sizeof(int) * 2);\n }\n \n PRE_SYSCALL(socketcall)(long call, void *args) {}\n \n POST_SYSCALL(socketcall)(long res, long call, void *args) {\n   if (res >= 0) {\n-    if (args) POST_WRITE(args, sizeof(long));\n+    if (args)\n+      POST_WRITE(args, sizeof(long));\n   }\n }\n \n@@ -1898,25 +2051,31 @@ POST_SYSCALL(listen)(long res, long arg0, long arg1) {}\n \n PRE_SYSCALL(poll)(void *ufds, long nfds, long timeout) {}\n \n-POST_SYSCALL(poll)(long res, __sanitizer_pollfd *ufds, long nfds,\n-                   long timeout) {\n+POST_SYSCALL(poll)\n+(long res, __sanitizer_pollfd *ufds, long nfds, long timeout) {\n   if (res >= 0) {\n-    if (ufds) POST_WRITE(ufds, nfds * sizeof(*ufds));\n+    if (ufds)\n+      POST_WRITE(ufds, nfds * sizeof(*ufds));\n   }\n }\n \n-PRE_SYSCALL(select)(long n, __sanitizer___kernel_fd_set *inp,\n-                    __sanitizer___kernel_fd_set *outp,\n-                    __sanitizer___kernel_fd_set *exp, void *tvp) {}\n+PRE_SYSCALL(select)\n+(long n, __sanitizer___kernel_fd_set *inp, __sanitizer___kernel_fd_set *outp,\n+ __sanitizer___kernel_fd_set *exp, void *tvp) {}\n \n-POST_SYSCALL(select)(long res, long n, __sanitizer___kernel_fd_set *inp,\n-                     __sanitizer___kernel_fd_set *outp,\n-                     __sanitizer___kernel_fd_set *exp, void *tvp) {\n+POST_SYSCALL(select)\n+(long res, long n, __sanitizer___kernel_fd_set *inp,\n+ __sanitizer___kernel_fd_set *outp, __sanitizer___kernel_fd_set *exp,\n+ void *tvp) {\n   if (res >= 0) {\n-    if (inp) POST_WRITE(inp, sizeof(*inp));\n-    if (outp) POST_WRITE(outp, sizeof(*outp));\n-    if (exp) POST_WRITE(exp, sizeof(*exp));\n-    if (tvp) POST_WRITE(tvp, timeval_sz);\n+    if (inp)\n+      POST_WRITE(inp, sizeof(*inp));\n+    if (outp)\n+      POST_WRITE(outp, sizeof(*outp));\n+    if (exp)\n+      POST_WRITE(exp, sizeof(*exp));\n+    if (tvp)\n+      POST_WRITE(tvp, timeval_sz);\n   }\n }\n \n@@ -1936,29 +2095,55 @@ PRE_SYSCALL(epoll_ctl)(long epfd, long op, long fd, void *event) {}\n \n POST_SYSCALL(epoll_ctl)(long res, long epfd, long op, long fd, void *event) {\n   if (res >= 0) {\n-    if (event) POST_WRITE(event, struct_epoll_event_sz);\n+    if (event)\n+      POST_WRITE(event, struct_epoll_event_sz);\n   }\n }\n \n-PRE_SYSCALL(epoll_wait)(long epfd, void *events, long maxevents, long timeout) {\n+PRE_SYSCALL(epoll_wait)\n+(long epfd, void *events, long maxevents, long timeout) {}\n+\n+POST_SYSCALL(epoll_wait)\n+(long res, long epfd, void *events, long maxevents, long timeout) {\n+  if (res >= 0) {\n+    if (events)\n+      POST_WRITE(events, res * struct_epoll_event_sz);\n+  }\n+}\n+\n+PRE_SYSCALL(epoll_pwait)\n+(long epfd, void *events, long maxevents, long timeout,\n+ const kernel_sigset_t *sigmask, long sigsetsize) {\n+  if (sigmask)\n+    PRE_READ(sigmask, sigsetsize);\n }\n \n-POST_SYSCALL(epoll_wait)(long res, long epfd, void *events, long maxevents,\n-                         long timeout) {\n+POST_SYSCALL(epoll_pwait)\n+(long res, long epfd, void *events, long maxevents, long timeout,\n+ const void *sigmask, long sigsetsize) {\n   if (res >= 0) {\n-    if (events) POST_WRITE(events, struct_epoll_event_sz);\n+    if (events)\n+      POST_WRITE(events, res * struct_epoll_event_sz);\n   }\n }\n \n-PRE_SYSCALL(epoll_pwait)(long epfd, void *events, long maxevents, long timeout,\n-                         const kernel_sigset_t *sigmask, long sigsetsize) {\n-  if (sigmask) PRE_READ(sigmask, sigsetsize);\n+PRE_SYSCALL(epoll_pwait2)\n+(long epfd, void *events, long maxevents,\n+ const sanitizer_kernel_timespec *timeout, const kernel_sigset_t *sigmask,\n+ long sigsetsize) {\n+  if (timeout)\n+    PRE_READ(timeout, sizeof(timeout));\n+  if (sigmask)\n+    PRE_READ(sigmask, sigsetsize);\n }\n \n-POST_SYSCALL(epoll_pwait)(long res, long epfd, void *events, long maxevents,\n-                          long timeout, const void *sigmask, long sigsetsize) {\n+POST_SYSCALL(epoll_pwait2)\n+(long res, long epfd, void *events, long maxevents,\n+ const sanitizer_kernel_timespec *timeout, const void *sigmask,\n+ long sigsetsize) {\n   if (res >= 0) {\n-    if (events) POST_WRITE(events, struct_epoll_event_sz);\n+    if (events)\n+      POST_WRITE(events, res * struct_epoll_event_sz);\n   }\n }\n \n@@ -1993,69 +2178,78 @@ PRE_SYSCALL(newuname)(void *name) {}\n \n POST_SYSCALL(newuname)(long res, void *name) {\n   if (res >= 0) {\n-    if (name) POST_WRITE(name, struct_new_utsname_sz);\n+    if (name)\n+      POST_WRITE(name, struct_new_utsname_sz);\n   }\n }\n \n PRE_SYSCALL(uname)(void *arg0) {}\n \n POST_SYSCALL(uname)(long res, void *arg0) {\n   if (res >= 0) {\n-    if (arg0) POST_WRITE(arg0, struct_old_utsname_sz);\n+    if (arg0)\n+      POST_WRITE(arg0, struct_old_utsname_sz);\n   }\n }\n \n PRE_SYSCALL(olduname)(void *arg0) {}\n \n POST_SYSCALL(olduname)(long res, void *arg0) {\n   if (res >= 0) {\n-    if (arg0) POST_WRITE(arg0, struct_oldold_utsname_sz);\n+    if (arg0)\n+      POST_WRITE(arg0, struct_oldold_utsname_sz);\n   }\n }\n \n PRE_SYSCALL(getrlimit)(long resource, void *rlim) {}\n \n POST_SYSCALL(getrlimit)(long res, long resource, void *rlim) {\n   if (res >= 0) {\n-    if (rlim) POST_WRITE(rlim, struct_rlimit_sz);\n+    if (rlim)\n+      POST_WRITE(rlim, struct_rlimit_sz);\n   }\n }\n \n PRE_SYSCALL(old_getrlimit)(long resource, void *rlim) {}\n \n POST_SYSCALL(old_getrlimit)(long res, long resource, void *rlim) {\n   if (res >= 0) {\n-    if (rlim) POST_WRITE(rlim, struct_rlimit_sz);\n+    if (rlim)\n+      POST_WRITE(rlim, struct_rlimit_sz);\n   }\n }\n \n PRE_SYSCALL(setrlimit)(long resource, void *rlim) {}\n \n POST_SYSCALL(setrlimit)(long res, long resource, void *rlim) {\n   if (res >= 0) {\n-    if (rlim) POST_WRITE(rlim, struct_rlimit_sz);\n+    if (rlim)\n+      POST_WRITE(rlim, struct_rlimit_sz);\n   }\n }\n \n-#if !SANITIZER_ANDROID\n-PRE_SYSCALL(prlimit64)(long pid, long resource, const void *new_rlim,\n-                       void *old_rlim) {\n-  if (new_rlim) PRE_READ(new_rlim, struct_rlimit64_sz);\n+#  if !SANITIZER_ANDROID\n+PRE_SYSCALL(prlimit64)\n+(long pid, long resource, const void *new_rlim, void *old_rlim) {\n+  if (new_rlim)\n+    PRE_READ(new_rlim, struct_rlimit64_sz);\n }\n \n-POST_SYSCALL(prlimit64)(long res, long pid, long resource, const void *new_rlim,\n-                        void *old_rlim) {\n+POST_SYSCALL(prlimit64)\n+(long res, long pid, long resource, const void *new_rlim, void *old_rlim) {\n   if (res >= 0) {\n-    if (old_rlim) POST_WRITE(old_rlim, struct_rlimit64_sz);\n+    if (old_rlim)\n+      POST_WRITE(old_rlim, struct_rlimit64_sz);\n   }\n }\n-#endif\n+#  endif\n \n PRE_SYSCALL(getrusage)(long who, void *ru) {}\n \n POST_SYSCALL(getrusage)(long res, long who, void *ru) {\n   if (res >= 0) {\n-    if (ru) POST_WRITE(ru, struct_rusage_sz);\n+    if (ru)\n+      POST_WRITE(ru, struct_rusage_sz);\n   }\n }\n \n@@ -2068,31 +2262,34 @@ PRE_SYSCALL(msgget)(long key, long msgflg) {}\n POST_SYSCALL(msgget)(long res, long key, long msgflg) {}\n \n PRE_SYSCALL(msgsnd)(long msqid, void *msgp, long msgsz, long msgflg) {\n-  if (msgp) PRE_READ(msgp, msgsz);\n+  if (msgp)\n+    PRE_READ(msgp, msgsz);\n }\n \n-POST_SYSCALL(msgsnd)(long res, long msqid, void *msgp, long msgsz,\n-                     long msgflg) {}\n+POST_SYSCALL(msgsnd)\n+(long res, long msqid, void *msgp, long msgsz, long msgflg) {}\n \n-PRE_SYSCALL(msgrcv)(long msqid, void *msgp, long msgsz, long msgtyp,\n-                    long msgflg) {}\n+PRE_SYSCALL(msgrcv)\n+(long msqid, void *msgp, long msgsz, long msgtyp, long msgflg) {}\n \n-POST_SYSCALL(msgrcv)(long res, long msqid, void *msgp, long msgsz, long msgtyp,\n-                     long msgflg) {\n+POST_SYSCALL(msgrcv)\n+(long res, long msqid, void *msgp, long msgsz, long msgtyp, long msgflg) {\n   if (res >= 0) {\n-    if (msgp) POST_WRITE(msgp, res);\n+    if (msgp)\n+      POST_WRITE(msgp, res);\n   }\n }\n \n-#if !SANITIZER_ANDROID\n+#  if !SANITIZER_ANDROID\n PRE_SYSCALL(msgctl)(long msqid, long cmd, void *buf) {}\n \n POST_SYSCALL(msgctl)(long res, long msqid, long cmd, void *buf) {\n   if (res >= 0) {\n-    if (buf) POST_WRITE(buf, struct_msqid_ds_sz);\n+    if (buf)\n+      POST_WRITE(buf, struct_msqid_ds_sz);\n   }\n }\n-#endif\n+#  endif\n \n PRE_SYSCALL(semget)(long key, long nsems, long semflg) {}\n \n@@ -2106,13 +2303,14 @@ PRE_SYSCALL(semctl)(long semid, long semnum, long cmd, void *arg) {}\n \n POST_SYSCALL(semctl)(long res, long semid, long semnum, long cmd, void *arg) {}\n \n-PRE_SYSCALL(semtimedop)(long semid, void *sops, long nsops,\n-                        const void *timeout) {\n-  if (timeout) PRE_READ(timeout, struct_timespec_sz);\n+PRE_SYSCALL(semtimedop)\n+(long semid, void *sops, long nsops, const void *timeout) {\n+  if (timeout)\n+    PRE_READ(timeout, struct_timespec_sz);\n }\n \n-POST_SYSCALL(semtimedop)(long res, long semid, void *sops, long nsops,\n-                         const void *timeout) {}\n+POST_SYSCALL(semtimedop)\n+(long res, long semid, void *sops, long nsops, const void *timeout) {}\n \n PRE_SYSCALL(shmat)(long shmid, void *shmaddr, long shmflg) {}\n \n@@ -2138,18 +2336,20 @@ POST_SYSCALL(shmdt)(long res, void *shmaddr) {\n   }\n }\n \n-PRE_SYSCALL(ipc)(long call, long first, long second, long third, void *ptr,\n-                 long fifth) {}\n+PRE_SYSCALL(ipc)\n+(long call, long first, long second, long third, void *ptr, long fifth) {}\n \n-POST_SYSCALL(ipc)(long res, long call, long first, long second, long third,\n-                  void *ptr, long fifth) {}\n+POST_SYSCALL(ipc)\n+(long res, long call, long first, long second, long third, void *ptr,\n+ long fifth) {}\n \n-#if !SANITIZER_ANDROID\n+#  if !SANITIZER_ANDROID\n PRE_SYSCALL(shmctl)(long shmid, long cmd, void *buf) {}\n \n POST_SYSCALL(shmctl)(long res, long shmid, long cmd, void *buf) {\n   if (res >= 0) {\n-    if (buf) POST_WRITE(buf, sizeof(__sanitizer_shmid_ds));\n+    if (buf)\n+      POST_WRITE(buf, sizeof(__sanitizer_shmid_ds));\n   }\n }\n \n@@ -2158,10 +2358,11 @@ PRE_SYSCALL(mq_open)(const void *name, long oflag, long mode, void *attr) {\n     PRE_READ(name, __sanitizer::internal_strlen((const char *)name) + 1);\n }\n \n-POST_SYSCALL(mq_open)(long res, const void *name, long oflag, long mode,\n-                      void *attr) {\n+POST_SYSCALL(mq_open)\n+(long res, const void *name, long oflag, long mode, void *attr) {\n   if (res >= 0) {\n-    if (attr) POST_WRITE(attr, struct_mq_attr_sz);\n+    if (attr)\n+      POST_WRITE(attr, struct_mq_attr_sz);\n   }\n }\n \n@@ -2172,62 +2373,73 @@ PRE_SYSCALL(mq_unlink)(const void *name) {\n \n POST_SYSCALL(mq_unlink)(long res, const void *name) {}\n \n-PRE_SYSCALL(mq_timedsend)(long mqdes, const void *msg_ptr, long msg_len,\n-                          long msg_prio, const void *abs_timeout) {\n-  if (msg_ptr) PRE_READ(msg_ptr, msg_len);\n-  if (abs_timeout) PRE_READ(abs_timeout, struct_timespec_sz);\n+PRE_SYSCALL(mq_timedsend)\n+(long mqdes, const void *msg_ptr, long msg_len, long msg_prio,\n+ const void *abs_timeout) {\n+  if (msg_ptr)\n+    PRE_READ(msg_ptr, msg_len);\n+  if (abs_timeout)\n+    PRE_READ(abs_timeout, struct_timespec_sz);\n }\n \n-POST_SYSCALL(mq_timedsend)(long res, long mqdes, const void *msg_ptr,\n-                           long msg_len, long msg_prio,\n-                           const void *abs_timeout) {}\n+POST_SYSCALL(mq_timedsend)\n+(long res, long mqdes, const void *msg_ptr, long msg_len, long msg_prio,\n+ const void *abs_timeout) {}\n \n-PRE_SYSCALL(mq_timedreceive)(long mqdes, void *msg_ptr, long msg_len,\n-                             void *msg_prio, const void *abs_timeout) {\n-  if (abs_timeout) PRE_READ(abs_timeout, struct_timespec_sz);\n+PRE_SYSCALL(mq_timedreceive)\n+(long mqdes, void *msg_ptr, long msg_len, void *msg_prio,\n+ const void *abs_timeout) {\n+  if (abs_timeout)\n+    PRE_READ(abs_timeout, struct_timespec_sz);\n }\n \n-POST_SYSCALL(mq_timedreceive)(long res, long mqdes, void *msg_ptr, long msg_len,\n-                              int *msg_prio, const void *abs_timeout) {\n+POST_SYSCALL(mq_timedreceive)\n+(long res, long mqdes, void *msg_ptr, long msg_len, int *msg_prio,\n+ const void *abs_timeout) {\n   if (res >= 0) {\n-    if (msg_ptr) POST_WRITE(msg_ptr, res);\n-    if (msg_prio) POST_WRITE(msg_prio, sizeof(*msg_prio));\n+    if (msg_ptr)\n+      POST_WRITE(msg_ptr, res);\n+    if (msg_prio)\n+      POST_WRITE(msg_prio, sizeof(*msg_prio));\n   }\n }\n \n PRE_SYSCALL(mq_notify)(long mqdes, const void *notification) {\n-  if (notification) PRE_READ(notification, struct_sigevent_sz);\n+  if (notification)\n+    PRE_READ(notification, struct_sigevent_sz);\n }\n \n POST_SYSCALL(mq_notify)(long res, long mqdes, const void *notification) {}\n \n PRE_SYSCALL(mq_getsetattr)(long mqdes, const void *mqstat, void *omqstat) {\n-  if (mqstat) PRE_READ(mqstat, struct_mq_attr_sz);\n+  if (mqstat)\n+    PRE_READ(mqstat, struct_mq_attr_sz);\n }\n \n-POST_SYSCALL(mq_getsetattr)(long res, long mqdes, const void *mqstat,\n-                            void *omqstat) {\n+POST_SYSCALL(mq_getsetattr)\n+(long res, long mqdes, const void *mqstat, void *omqstat) {\n   if (res >= 0) {\n-    if (omqstat) POST_WRITE(omqstat, struct_mq_attr_sz);\n+    if (omqstat)\n+      POST_WRITE(omqstat, struct_mq_attr_sz);\n   }\n }\n-#endif  // SANITIZER_ANDROID\n+#  endif  // SANITIZER_ANDROID\n \n PRE_SYSCALL(pciconfig_iobase)(long which, long bus, long devfn) {}\n \n POST_SYSCALL(pciconfig_iobase)(long res, long which, long bus, long devfn) {}\n \n-PRE_SYSCALL(pciconfig_read)(long bus, long dfn, long off, long len, void *buf) {\n-}\n+PRE_SYSCALL(pciconfig_read)\n+(long bus, long dfn, long off, long len, void *buf) {}\n \n-POST_SYSCALL(pciconfig_read)(long res, long bus, long dfn, long off, long len,\n-                             void *buf) {}\n+POST_SYSCALL(pciconfig_read)\n+(long res, long bus, long dfn, long off, long len, void *buf) {}\n \n-PRE_SYSCALL(pciconfig_write)(long bus, long dfn, long off, long len,\n-                             void *buf) {}\n+PRE_SYSCALL(pciconfig_write)\n+(long bus, long dfn, long off, long len, void *buf) {}\n \n-POST_SYSCALL(pciconfig_write)(long res, long bus, long dfn, long off, long len,\n-                              void *buf) {}\n+POST_SYSCALL(pciconfig_write)\n+(long res, long bus, long dfn, long off, long len, void *buf) {}\n \n PRE_SYSCALL(swapon)(const void *specialfile, long swap_flags) {\n   if (specialfile)\n@@ -2247,8 +2459,10 @@ POST_SYSCALL(swapoff)(long res, const void *specialfile) {}\n \n PRE_SYSCALL(sysctl)(__sanitizer___sysctl_args *args) {\n   if (args) {\n-    if (args->name) PRE_READ(args->name, args->nlen * sizeof(*args->name));\n-    if (args->newval) PRE_READ(args->name, args->newlen);\n+    if (args->name)\n+      PRE_READ(args->name, args->nlen * sizeof(*args->name));\n+    if (args->newval)\n+      PRE_READ(args->name, args->newlen);\n   }\n }\n \n@@ -2265,7 +2479,8 @@ PRE_SYSCALL(sysinfo)(void *info) {}\n \n POST_SYSCALL(sysinfo)(long res, void *info) {\n   if (res >= 0) {\n-    if (info) POST_WRITE(info, struct_sysinfo_sz);\n+    if (info)\n+      POST_WRITE(info, struct_sysinfo_sz);\n   }\n }\n \n@@ -2294,10 +2509,10 @@ PRE_SYSCALL(ni_syscall)() {}\n POST_SYSCALL(ni_syscall)(long res) {}\n \n PRE_SYSCALL(ptrace)(long request, long pid, long addr, long data) {\n-#if !SANITIZER_ANDROID &&                                                   \\\n-    (defined(__i386) || defined(__x86_64) || defined(__mips64) ||           \\\n-     defined(__powerpc64__) || defined(__aarch64__) || defined(__s390__) || \\\n-     SANITIZER_RISCV64)\n+#  if !SANITIZER_ANDROID &&                                                   \\\n+      (defined(__i386) || defined(__x86_64) || defined(__mips64) ||           \\\n+       defined(__powerpc64__) || defined(__aarch64__) || defined(__s390__) || \\\n+       SANITIZER_RISCV64)\n   if (data) {\n     if (request == ptrace_setregs) {\n       PRE_READ((void *)data, struct_user_regs_struct_sz);\n@@ -2312,14 +2527,14 @@ PRE_SYSCALL(ptrace)(long request, long pid, long addr, long data) {\n       PRE_READ(iov->iov_base, iov->iov_len);\n     }\n   }\n-#endif\n+#  endif\n }\n \n POST_SYSCALL(ptrace)(long res, long request, long pid, long addr, long data) {\n-#if !SANITIZER_ANDROID &&                                                   \\\n-    (defined(__i386) || defined(__x86_64) || defined(__mips64) ||           \\\n-     defined(__powerpc64__) || defined(__aarch64__) || defined(__s390__) || \\\n-     SANITIZER_RISCV64)\n+#  if !SANITIZER_ANDROID &&                                                   \\\n+      (defined(__i386) || defined(__x86_64) || defined(__mips64) ||           \\\n+       defined(__powerpc64__) || defined(__aarch64__) || defined(__s390__) || \\\n+       SANITIZER_RISCV64)\n   if (res >= 0 && data) {\n     // Note that this is different from the interceptor in\n     // sanitizer_common_interceptors.inc.\n@@ -2340,23 +2555,26 @@ POST_SYSCALL(ptrace)(long res, long request, long pid, long addr, long data) {\n       POST_WRITE((void *)data, sizeof(void *));\n     }\n   }\n-#endif\n+#  endif\n }\n \n-PRE_SYSCALL(add_key)(const void *_type, const void *_description,\n-                     const void *_payload, long plen, long destringid) {\n+PRE_SYSCALL(add_key)\n+(const void *_type, const void *_description, const void *_payload, long plen,\n+ long destringid) {\n   if (_type)\n     PRE_READ(_type, __sanitizer::internal_strlen((const char *)_type) + 1);\n   if (_description)\n     PRE_READ(_description,\n              __sanitizer::internal_strlen((const char *)_description) + 1);\n }\n \n-POST_SYSCALL(add_key)(long res, const void *_type, const void *_description,\n-                      const void *_payload, long plen, long destringid) {}\n+POST_SYSCALL(add_key)\n+(long res, const void *_type, const void *_description, const void *_payload,\n+ long plen, long destringid) {}\n \n-PRE_SYSCALL(request_key)(const void *_type, const void *_description,\n-                         const void *_callout_info, long destringid) {\n+PRE_SYSCALL(request_key)\n+(const void *_type, const void *_description, const void *_callout_info,\n+ long destringid) {\n   if (_type)\n     PRE_READ(_type, __sanitizer::internal_strlen((const char *)_type) + 1);\n   if (_description)\n@@ -2367,13 +2585,14 @@ PRE_SYSCALL(request_key)(const void *_type, const void *_description,\n              __sanitizer::internal_strlen((const char *)_callout_info) + 1);\n }\n \n-POST_SYSCALL(request_key)(long res, const void *_type, const void *_description,\n-                          const void *_callout_info, long destringid) {}\n+POST_SYSCALL(request_key)\n+(long res, const void *_type, const void *_description,\n+ const void *_callout_info, long destringid) {}\n \n PRE_SYSCALL(keyctl)(long cmd, long arg2, long arg3, long arg4, long arg5) {}\n \n-POST_SYSCALL(keyctl)(long res, long cmd, long arg2, long arg3, long arg4,\n-                     long arg5) {}\n+POST_SYSCALL(keyctl)\n+(long res, long cmd, long arg2, long arg3, long arg4, long arg5) {}\n \n PRE_SYSCALL(ioprio_set)(long which, long who, long ioprio) {}\n \n@@ -2387,50 +2606,62 @@ PRE_SYSCALL(set_mempolicy)(long mode, void *nmask, long maxnode) {}\n \n POST_SYSCALL(set_mempolicy)(long res, long mode, void *nmask, long maxnode) {\n   if (res >= 0) {\n-    if (nmask) POST_WRITE(nmask, sizeof(long));\n+    if (nmask)\n+      POST_WRITE(nmask, sizeof(long));\n   }\n }\n \n-PRE_SYSCALL(migrate_pages)(long pid, long maxnode, const void *from,\n-                           const void *to) {\n-  if (from) PRE_READ(from, sizeof(long));\n-  if (to) PRE_READ(to, sizeof(long));\n+PRE_SYSCALL(migrate_pages)\n+(long pid, long maxnode, const void *from, const void *to) {\n+  if (from)\n+    PRE_READ(from, sizeof(long));\n+  if (to)\n+    PRE_READ(to, sizeof(long));\n }\n \n-POST_SYSCALL(migrate_pages)(long res, long pid, long maxnode, const void *from,\n-                            const void *to) {}\n+POST_SYSCALL(migrate_pages)\n+(long res, long pid, long maxnode, const void *from, const void *to) {}\n \n-PRE_SYSCALL(move_pages)(long pid, long nr_pages, const void **pages,\n-                        const int *nodes, int *status, long flags) {\n-  if (pages) PRE_READ(pages, nr_pages * sizeof(*pages));\n-  if (nodes) PRE_READ(nodes, nr_pages * sizeof(*nodes));\n+PRE_SYSCALL(move_pages)\n+(long pid, long nr_pages, const void **pages, const int *nodes, int *status,\n+ long flags) {\n+  if (pages)\n+    PRE_READ(pages, nr_pages * sizeof(*pages));\n+  if (nodes)\n+    PRE_READ(nodes, nr_pages * sizeof(*nodes));\n }\n \n-POST_SYSCALL(move_pages)(long res, long pid, long nr_pages, const void **pages,\n-                         const int *nodes, int *status, long flags) {\n+POST_SYSCALL(move_pages)\n+(long res, long pid, long nr_pages, const void **pages, const int *nodes,\n+ int *status, long flags) {\n   if (res >= 0) {\n-    if (status) POST_WRITE(status, nr_pages * sizeof(*status));\n+    if (status)\n+      POST_WRITE(status, nr_pages * sizeof(*status));\n   }\n }\n \n-PRE_SYSCALL(mbind)(long start, long len, long mode, void *nmask, long maxnode,\n-                   long flags) {}\n+PRE_SYSCALL(mbind)\n+(long start, long len, long mode, void *nmask, long maxnode, long flags) {}\n \n-POST_SYSCALL(mbind)(long res, long start, long len, long mode, void *nmask,\n-                    long maxnode, long flags) {\n+POST_SYSCALL(mbind)\n+(long res, long start, long len, long mode, void *nmask, long maxnode,\n+ long flags) {\n   if (res >= 0) {\n-    if (nmask) POST_WRITE(nmask, sizeof(long));\n+    if (nmask)\n+      POST_WRITE(nmask, sizeof(long));\n   }\n }\n \n-PRE_SYSCALL(get_mempolicy)(void *policy, void *nmask, long maxnode, long addr,\n-                           long flags) {}\n+PRE_SYSCALL(get_mempolicy)\n+(void *policy, void *nmask, long maxnode, long addr, long flags) {}\n \n-POST_SYSCALL(get_mempolicy)(long res, void *policy, void *nmask, long maxnode,\n-                            long addr, long flags) {\n+POST_SYSCALL(get_mempolicy)\n+(long res, void *policy, void *nmask, long maxnode, long addr, long flags) {\n   if (res >= 0) {\n-    if (policy) POST_WRITE(policy, sizeof(int));\n-    if (nmask) POST_WRITE(nmask, sizeof(long));\n+    if (policy)\n+      POST_WRITE(policy, sizeof(int));\n+    if (nmask)\n+      POST_WRITE(nmask, sizeof(long));\n   }\n }\n \n@@ -2447,8 +2678,8 @@ PRE_SYSCALL(inotify_add_watch)(long fd, const void *path, long mask) {\n     PRE_READ(path, __sanitizer::internal_strlen((const char *)path) + 1);\n }\n \n-POST_SYSCALL(inotify_add_watch)(long res, long fd, const void *path,\n-                                long mask) {}\n+POST_SYSCALL(inotify_add_watch)\n+(long res, long fd, const void *path, long mask) {}\n \n PRE_SYSCALL(inotify_rm_watch)(long fd, long wd) {}\n \n@@ -2458,8 +2689,10 @@ PRE_SYSCALL(spu_run)(long fd, void *unpc, void *ustatus) {}\n \n POST_SYSCALL(spu_run)(long res, long fd, unsigned *unpc, unsigned *ustatus) {\n   if (res >= 0) {\n-    if (unpc) POST_WRITE(unpc, sizeof(*unpc));\n-    if (ustatus) POST_WRITE(ustatus, sizeof(*ustatus));\n+    if (unpc)\n+      POST_WRITE(unpc, sizeof(*unpc));\n+    if (ustatus)\n+      POST_WRITE(ustatus, sizeof(*ustatus));\n   }\n }\n \n@@ -2468,17 +2701,17 @@ PRE_SYSCALL(spu_create)(const void *name, long flags, long mode, long fd) {\n     PRE_READ(name, __sanitizer::internal_strlen((const char *)name) + 1);\n }\n \n-POST_SYSCALL(spu_create)(long res, const void *name, long flags, long mode,\n-                         long fd) {}\n+POST_SYSCALL(spu_create)\n+(long res, const void *name, long flags, long mode, long fd) {}\n \n PRE_SYSCALL(mknodat)(long dfd, const void *filename, long mode, long dev) {\n   if (filename)\n     PRE_READ(filename,\n              __sanitizer::internal_strlen((const char *)filename) + 1);\n }\n \n-POST_SYSCALL(mknodat)(long res, long dfd, const void *filename, long mode,\n-                      long dev) {}\n+POST_SYSCALL(mknodat)\n+(long res, long dfd, const void *filename, long mode, long dev) {}\n \n PRE_SYSCALL(mkdirat)(long dfd, const void *pathname, long mode) {\n   if (pathname)\n@@ -2503,41 +2736,45 @@ PRE_SYSCALL(symlinkat)(const void *oldname, long newdfd, const void *newname) {\n     PRE_READ(newname, __sanitizer::internal_strlen((const char *)newname) + 1);\n }\n \n-POST_SYSCALL(symlinkat)(long res, const void *oldname, long newdfd,\n-                        const void *newname) {}\n+POST_SYSCALL(symlinkat)\n+(long res, const void *oldname, long newdfd, const void *newname) {}\n \n-PRE_SYSCALL(linkat)(long olddfd, const void *oldname, long newdfd,\n-                    const void *newname, long flags) {\n+PRE_SYSCALL(linkat)\n+(long olddfd, const void *oldname, long newdfd, const void *newname,\n+ long flags) {\n   if (oldname)\n     PRE_READ(oldname, __sanitizer::internal_strlen((const char *)oldname) + 1);\n   if (newname)\n     PRE_READ(newname, __sanitizer::internal_strlen((const char *)newname) + 1);\n }\n \n-POST_SYSCALL(linkat)(long res, long olddfd, const void *oldname, long newdfd,\n-                     const void *newname, long flags) {}\n+POST_SYSCALL(linkat)\n+(long res, long olddfd, const void *oldname, long newdfd, const void *newname,\n+ long flags) {}\n \n-PRE_SYSCALL(renameat)(long olddfd, const void *oldname, long newdfd,\n-                      const void *newname) {\n+PRE_SYSCALL(renameat)\n+(long olddfd, const void *oldname, long newdfd, const void *newname) {\n   if (oldname)\n     PRE_READ(oldname, __sanitizer::internal_strlen((const char *)oldname) + 1);\n   if (newname)\n     PRE_READ(newname, __sanitizer::internal_strlen((const char *)newname) + 1);\n }\n \n-POST_SYSCALL(renameat)(long res, long olddfd, const void *oldname, long newdfd,\n-                       const void *newname) {}\n+POST_SYSCALL(renameat)\n+(long res, long olddfd, const void *oldname, long newdfd, const void *newname) {\n+}\n \n PRE_SYSCALL(futimesat)(long dfd, const void *filename, void *utimes) {\n   if (filename)\n     PRE_READ(filename,\n              __sanitizer::internal_strlen((const char *)filename) + 1);\n }\n \n-POST_SYSCALL(futimesat)(long res, long dfd, const void *filename,\n-                        void *utimes) {\n+POST_SYSCALL(futimesat)\n+(long res, long dfd, const void *filename, void *utimes) {\n   if (res >= 0) {\n-    if (utimes) POST_WRITE(utimes, timeval_sz);\n+    if (utimes)\n+      POST_WRITE(utimes, timeval_sz);\n   }\n }\n \n@@ -2557,50 +2794,52 @@ PRE_SYSCALL(fchmodat)(long dfd, const void *filename, long mode) {\n \n POST_SYSCALL(fchmodat)(long res, long dfd, const void *filename, long mode) {}\n \n-PRE_SYSCALL(fchownat)(long dfd, const void *filename, long user, long group,\n-                      long flag) {\n+PRE_SYSCALL(fchownat)\n+(long dfd, const void *filename, long user, long group, long flag) {\n   if (filename)\n     PRE_READ(filename,\n              __sanitizer::internal_strlen((const char *)filename) + 1);\n }\n \n-POST_SYSCALL(fchownat)(long res, long dfd, const void *filename, long user,\n-                       long group, long flag) {}\n+POST_SYSCALL(fchownat)\n+(long res, long dfd, const void *filename, long user, long group, long flag) {}\n \n PRE_SYSCALL(openat)(long dfd, const void *filename, long flags, long mode) {\n   if (filename)\n     PRE_READ(filename,\n              __sanitizer::internal_strlen((const char *)filename) + 1);\n }\n \n-POST_SYSCALL(openat)(long res, long dfd, const void *filename, long flags,\n-                     long mode) {}\n+POST_SYSCALL(openat)\n+(long res, long dfd, const void *filename, long flags, long mode) {}\n \n-PRE_SYSCALL(newfstatat)(long dfd, const void *filename, void *statbuf,\n-                        long flag) {\n+PRE_SYSCALL(newfstatat)\n+(long dfd, const void *filename, void *statbuf, long flag) {\n   if (filename)\n     PRE_READ(filename,\n              __sanitizer::internal_strlen((const char *)filename) + 1);\n }\n \n-POST_SYSCALL(newfstatat)(long res, long dfd, const void *filename,\n-                         void *statbuf, long flag) {\n+POST_SYSCALL(newfstatat)\n+(long res, long dfd, const void *filename, void *statbuf, long flag) {\n   if (res >= 0) {\n-    if (statbuf) POST_WRITE(statbuf, struct_kernel_stat_sz);\n+    if (statbuf)\n+      POST_WRITE(statbuf, struct_kernel_stat_sz);\n   }\n }\n \n-PRE_SYSCALL(fstatat64)(long dfd, const void *filename, void *statbuf,\n-                       long flag) {\n+PRE_SYSCALL(fstatat64)\n+(long dfd, const void *filename, void *statbuf, long flag) {\n   if (filename)\n     PRE_READ(filename,\n              __sanitizer::internal_strlen((const char *)filename) + 1);\n }\n \n-POST_SYSCALL(fstatat64)(long res, long dfd, const void *filename, void *statbuf,\n-                        long flag) {\n+POST_SYSCALL(fstatat64)\n+(long res, long dfd, const void *filename, void *statbuf, long flag) {\n   if (res >= 0) {\n-    if (statbuf) POST_WRITE(statbuf, struct_kernel_stat64_sz);\n+    if (statbuf)\n+      POST_WRITE(statbuf, struct_kernel_stat64_sz);\n   }\n }\n \n@@ -2609,50 +2848,55 @@ PRE_SYSCALL(readlinkat)(long dfd, const void *path, void *buf, long bufsiz) {\n     PRE_READ(path, __sanitizer::internal_strlen((const char *)path) + 1);\n }\n \n-POST_SYSCALL(readlinkat)(long res, long dfd, const void *path, void *buf,\n-                         long bufsiz) {\n+POST_SYSCALL(readlinkat)\n+(long res, long dfd, const void *path, void *buf, long bufsiz) {\n   if (res >= 0) {\n     if (buf)\n       POST_WRITE(buf, __sanitizer::internal_strlen((const char *)buf) + 1);\n   }\n }\n \n-PRE_SYSCALL(utimensat)(long dfd, const void *filename, void *utimes,\n-                       long flags) {\n+PRE_SYSCALL(utimensat)\n+(long dfd, const void *filename, void *utimes, long flags) {\n   if (filename)\n     PRE_READ(filename,\n              __sanitizer::internal_strlen((const char *)filename) + 1);\n }\n \n-POST_SYSCALL(utimensat)(long res, long dfd, const void *filename, void *utimes,\n-                        long flags) {\n+POST_SYSCALL(utimensat)\n+(long res, long dfd, const void *filename, void *utimes, long flags) {\n   if (res >= 0) {\n-    if (utimes) POST_WRITE(utimes, struct_timespec_sz);\n+    if (utimes)\n+      POST_WRITE(utimes, struct_timespec_sz);\n   }\n }\n \n PRE_SYSCALL(unshare)(long unshare_flags) {}\n \n POST_SYSCALL(unshare)(long res, long unshare_flags) {}\n \n-PRE_SYSCALL(splice)(long fd_in, void *off_in, long fd_out, void *off_out,\n-                    long len, long flags) {}\n+PRE_SYSCALL(splice)\n+(long fd_in, void *off_in, long fd_out, void *off_out, long len, long flags) {}\n \n-POST_SYSCALL(splice)(long res, long fd_in, void *off_in, long fd_out,\n-                     void *off_out, long len, long flags) {\n+POST_SYSCALL(splice)\n+(long res, long fd_in, void *off_in, long fd_out, void *off_out, long len,\n+ long flags) {\n   if (res >= 0) {\n-    if (off_in) POST_WRITE(off_in, sizeof(long long));\n-    if (off_out) POST_WRITE(off_out, sizeof(long long));\n+    if (off_in)\n+      POST_WRITE(off_in, sizeof(long long));\n+    if (off_out)\n+      POST_WRITE(off_out, sizeof(long long));\n   }\n }\n \n-PRE_SYSCALL(vmsplice)(long fd, const __sanitizer_iovec *iov, long nr_segs,\n-                      long flags) {}\n+PRE_SYSCALL(vmsplice)\n+(long fd, const __sanitizer_iovec *iov, long nr_segs, long flags) {}\n \n-POST_SYSCALL(vmsplice)(long res, long fd, const __sanitizer_iovec *iov,\n-                       long nr_segs, long flags) {\n+POST_SYSCALL(vmsplice)\n+(long res, long fd, const __sanitizer_iovec *iov, long nr_segs, long flags) {\n   if (res >= 0) {\n-    if (iov) kernel_read_iovec(iov, nr_segs, res);\n+    if (iov)\n+      kernel_read_iovec(iov, nr_segs, res);\n   }\n }\n \n@@ -2662,8 +2906,8 @@ POST_SYSCALL(tee)(long res, long fdin, long fdout, long len, long flags) {}\n \n PRE_SYSCALL(get_robust_list)(long pid, void *head_ptr, void *len_ptr) {}\n \n-POST_SYSCALL(get_robust_list)(long res, long pid, void *head_ptr,\n-                              void *len_ptr) {}\n+POST_SYSCALL(get_robust_list)\n+(long res, long pid, void *head_ptr, void *len_ptr) {}\n \n PRE_SYSCALL(set_robust_list)(void *head, long len) {}\n \n@@ -2673,51 +2917,58 @@ PRE_SYSCALL(getcpu)(void *cpu, void *node, void *cache) {}\n \n POST_SYSCALL(getcpu)(long res, void *cpu, void *node, void *cache) {\n   if (res >= 0) {\n-    if (cpu) POST_WRITE(cpu, sizeof(unsigned));\n-    if (node) POST_WRITE(node, sizeof(unsigned));\n+    if (cpu)\n+      POST_WRITE(cpu, sizeof(unsigned));\n+    if (node)\n+      POST_WRITE(node, sizeof(unsigned));\n     // The third argument to this system call is nowadays unused.\n   }\n }\n \n PRE_SYSCALL(signalfd)(long ufd, void *user_mask, long sizemask) {}\n \n-POST_SYSCALL(signalfd)(long res, long ufd, kernel_sigset_t *user_mask,\n-                       long sizemask) {\n+POST_SYSCALL(signalfd)\n+(long res, long ufd, kernel_sigset_t *user_mask, long sizemask) {\n   if (res >= 0) {\n-    if (user_mask) POST_WRITE(user_mask, sizemask);\n+    if (user_mask)\n+      POST_WRITE(user_mask, sizemask);\n   }\n }\n \n PRE_SYSCALL(signalfd4)(long ufd, void *user_mask, long sizemask, long flags) {}\n \n-POST_SYSCALL(signalfd4)(long res, long ufd, kernel_sigset_t *user_mask,\n-                        long sizemask, long flags) {\n+POST_SYSCALL(signalfd4)\n+(long res, long ufd, kernel_sigset_t *user_mask, long sizemask, long flags) {\n   if (res >= 0) {\n-    if (user_mask) POST_WRITE(user_mask, sizemask);\n+    if (user_mask)\n+      POST_WRITE(user_mask, sizemask);\n   }\n }\n \n PRE_SYSCALL(timerfd_create)(long clockid, long flags) {}\n \n POST_SYSCALL(timerfd_create)(long res, long clockid, long flags) {}\n \n-PRE_SYSCALL(timerfd_settime)(long ufd, long flags, const void *utmr,\n-                             void *otmr) {\n-  if (utmr) PRE_READ(utmr, struct_itimerspec_sz);\n+PRE_SYSCALL(timerfd_settime)\n+(long ufd, long flags, const void *utmr, void *otmr) {\n+  if (utmr)\n+    PRE_READ(utmr, struct_itimerspec_sz);\n }\n \n-POST_SYSCALL(timerfd_settime)(long res, long ufd, long flags, const void *utmr,\n-                              void *otmr) {\n+POST_SYSCALL(timerfd_settime)\n+(long res, long ufd, long flags, const void *utmr, void *otmr) {\n   if (res >= 0) {\n-    if (otmr) POST_WRITE(otmr, struct_itimerspec_sz);\n+    if (otmr)\n+      POST_WRITE(otmr, struct_itimerspec_sz);\n   }\n }\n \n PRE_SYSCALL(timerfd_gettime)(long ufd, void *otmr) {}\n \n POST_SYSCALL(timerfd_gettime)(long res, long ufd, void *otmr) {\n   if (res >= 0) {\n-    if (otmr) POST_WRITE(otmr, struct_itimerspec_sz);\n+    if (otmr)\n+      POST_WRITE(otmr, struct_itimerspec_sz);\n   }\n }\n \n@@ -2735,141 +2986,149 @@ POST_SYSCALL(old_readdir)(long res, long arg0, void *arg1, long arg2) {\n   // Missing definition of 'struct old_linux_dirent'.\n }\n \n-PRE_SYSCALL(pselect6)(long arg0, __sanitizer___kernel_fd_set *arg1,\n-                      __sanitizer___kernel_fd_set *arg2,\n-                      __sanitizer___kernel_fd_set *arg3, void *arg4,\n-                      void *arg5) {}\n+PRE_SYSCALL(pselect6)\n+(long arg0, __sanitizer___kernel_fd_set *arg1,\n+ __sanitizer___kernel_fd_set *arg2, __sanitizer___kernel_fd_set *arg3,\n+ void *arg4, void *arg5) {}\n \n-POST_SYSCALL(pselect6)(long res, long arg0, __sanitizer___kernel_fd_set *arg1,\n-                       __sanitizer___kernel_fd_set *arg2,\n-                       __sanitizer___kernel_fd_set *arg3, void *arg4,\n-                       void *arg5) {\n+POST_SYSCALL(pselect6)\n+(long res, long arg0, __sanitizer___kernel_fd_set *arg1,\n+ __sanitizer___kernel_fd_set *arg2, __sanitizer___kernel_fd_set *arg3,\n+ void *arg4, void *arg5) {\n   if (res >= 0) {\n-    if (arg1) POST_WRITE(arg1, sizeof(*arg1));\n-    if (arg2) POST_WRITE(arg2, sizeof(*arg2));\n-    if (arg3) POST_WRITE(arg3, sizeof(*arg3));\n-    if (arg4) POST_WRITE(arg4, struct_timespec_sz);\n+    if (arg1)\n+      POST_WRITE(arg1, sizeof(*arg1));\n+    if (arg2)\n+      POST_WRITE(arg2, sizeof(*arg2));\n+    if (arg3)\n+      POST_WRITE(arg3, sizeof(*arg3));\n+    if (arg4)\n+      POST_WRITE(arg4, struct_timespec_sz);\n   }\n }\n \n-PRE_SYSCALL(ppoll)(__sanitizer_pollfd *arg0, long arg1, void *arg2,\n-                   const kernel_sigset_t *arg3, long arg4) {\n-  if (arg3) PRE_READ(arg3, arg4);\n+PRE_SYSCALL(ppoll)\n+(__sanitizer_pollfd *arg0, long arg1, void *arg2, const kernel_sigset_t *arg3,\n+ long arg4) {\n+  if (arg3)\n+    PRE_READ(arg3, arg4);\n }\n \n-POST_SYSCALL(ppoll)(long res, __sanitizer_pollfd *arg0, long arg1, void *arg2,\n-                    const void *arg3, long arg4) {\n+POST_SYSCALL(ppoll)\n+(long res, __sanitizer_pollfd *arg0, long arg1, void *arg2, const void *arg3,\n+ long arg4) {\n   if (res >= 0) {\n-    if (arg0) POST_WRITE(arg0, sizeof(*arg0));\n-    if (arg2) POST_WRITE(arg2, struct_timespec_sz);\n+    if (arg0)\n+      POST_WRITE(arg0, sizeof(*arg0));\n+    if (arg2)\n+      POST_WRITE(arg2, struct_timespec_sz);\n   }\n }\n \n PRE_SYSCALL(syncfs)(long fd) {}\n \n POST_SYSCALL(syncfs)(long res, long fd) {}\n \n-PRE_SYSCALL(perf_event_open)(__sanitizer_perf_event_attr *attr_uptr, long pid,\n-                             long cpu, long group_fd, long flags) {\n-  if (attr_uptr) PRE_READ(attr_uptr, attr_uptr->size);\n+PRE_SYSCALL(perf_event_open)\n+(__sanitizer_perf_event_attr *attr_uptr, long pid, long cpu, long group_fd,\n+ long flags) {\n+  if (attr_uptr)\n+    PRE_READ(attr_uptr, attr_uptr->size);\n }\n \n-POST_SYSCALL(perf_event_open)(long res, __sanitizer_perf_event_attr *attr_uptr,\n-                              long pid, long cpu, long group_fd, long flags) {}\n+POST_SYSCALL(perf_event_open)\n+(long res, __sanitizer_perf_event_attr *attr_uptr, long pid, long cpu,\n+ long group_fd, long flags) {}\n \n-PRE_SYSCALL(mmap_pgoff)(long addr, long len, long prot, long flags, long fd,\n-                        long pgoff) {}\n+PRE_SYSCALL(mmap_pgoff)\n+(long addr, long len, long prot, long flags, long fd, long pgoff) {}\n \n-POST_SYSCALL(mmap_pgoff)(long res, long addr, long len, long prot, long flags,\n-                         long fd, long pgoff) {}\n+POST_SYSCALL(mmap_pgoff)\n+(long res, long addr, long len, long prot, long flags, long fd, long pgoff) {}\n \n PRE_SYSCALL(old_mmap)(void *arg) {}\n \n POST_SYSCALL(old_mmap)(long res, void *arg) {}\n \n-PRE_SYSCALL(name_to_handle_at)(long dfd, const void *name, void *handle,\n-                               void *mnt_id, long flag) {}\n+PRE_SYSCALL(name_to_handle_at)\n+(long dfd, const void *name, void *handle, void *mnt_id, long flag) {}\n \n-POST_SYSCALL(name_to_handle_at)(long res, long dfd, const void *name,\n-                                void *handle, void *mnt_id, long flag) {}\n+POST_SYSCALL(name_to_handle_at)\n+(long res, long dfd, const void *name, void *handle, void *mnt_id, long flag) {}\n \n PRE_SYSCALL(open_by_handle_at)(long mountdirfd, void *handle, long flags) {}\n \n-POST_SYSCALL(open_by_handle_at)(long res, long mountdirfd, void *handle,\n-                                long flags) {}\n+POST_SYSCALL(open_by_handle_at)\n+(long res, long mountdirfd, void *handle, long flags) {}\n \n PRE_SYSCALL(setns)(long fd, long nstype) {}\n \n POST_SYSCALL(setns)(long res, long fd, long nstype) {}\n \n-PRE_SYSCALL(process_vm_readv)(long pid, const __sanitizer_iovec *lvec,\n-                              long liovcnt, const void *rvec, long riovcnt,\n-                              long flags) {}\n+PRE_SYSCALL(process_vm_readv)\n+(long pid, const __sanitizer_iovec *lvec, long liovcnt, const void *rvec,\n+ long riovcnt, long flags) {}\n \n-POST_SYSCALL(process_vm_readv)(long res, long pid,\n-                               const __sanitizer_iovec *lvec, long liovcnt,\n-                               const void *rvec, long riovcnt, long flags) {\n+POST_SYSCALL(process_vm_readv)\n+(long res, long pid, const __sanitizer_iovec *lvec, long liovcnt,\n+ const void *rvec, long riovcnt, long flags) {\n   if (res >= 0) {\n-    if (lvec) kernel_write_iovec(lvec, liovcnt, res);\n+    if (lvec)\n+      kernel_write_iovec(lvec, liovcnt, res);\n   }\n }\n \n-PRE_SYSCALL(process_vm_writev)(long pid, const __sanitizer_iovec *lvec,\n-                               long liovcnt, const void *rvec, long riovcnt,\n-                               long flags) {}\n+PRE_SYSCALL(process_vm_writev)\n+(long pid, const __sanitizer_iovec *lvec, long liovcnt, const void *rvec,\n+ long riovcnt, long flags) {}\n \n-POST_SYSCALL(process_vm_writev)(long res, long pid,\n-                                const __sanitizer_iovec *lvec, long liovcnt,\n-                                const void *rvec, long riovcnt, long flags) {\n+POST_SYSCALL(process_vm_writev)\n+(long res, long pid, const __sanitizer_iovec *lvec, long liovcnt,\n+ const void *rvec, long riovcnt, long flags) {\n   if (res >= 0) {\n-    if (lvec) kernel_read_iovec(lvec, liovcnt, res);\n+    if (lvec)\n+      kernel_read_iovec(lvec, liovcnt, res);\n   }\n }\n \n-PRE_SYSCALL(fork)() {\n-  COMMON_SYSCALL_PRE_FORK();\n-}\n+PRE_SYSCALL(fork)() { COMMON_SYSCALL_PRE_FORK(); }\n \n-POST_SYSCALL(fork)(long res) {\n-  COMMON_SYSCALL_POST_FORK(res);\n-}\n+POST_SYSCALL(fork)(long res) { COMMON_SYSCALL_POST_FORK(res); }\n \n-PRE_SYSCALL(vfork)() {\n-  COMMON_SYSCALL_PRE_FORK();\n-}\n+PRE_SYSCALL(vfork)() { COMMON_SYSCALL_PRE_FORK(); }\n \n-POST_SYSCALL(vfork)(long res) {\n-  COMMON_SYSCALL_POST_FORK(res);\n-}\n+POST_SYSCALL(vfork)(long res) { COMMON_SYSCALL_POST_FORK(res); }\n \n-PRE_SYSCALL(sigaction)(long signum, const __sanitizer_kernel_sigaction_t *act,\n-                       __sanitizer_kernel_sigaction_t *oldact) {\n+PRE_SYSCALL(sigaction)\n+(long signum, const __sanitizer_kernel_sigaction_t *act,\n+ __sanitizer_kernel_sigaction_t *oldact) {\n   if (act) {\n     PRE_READ(&act->sigaction, sizeof(act->sigaction));\n     PRE_READ(&act->sa_flags, sizeof(act->sa_flags));\n     PRE_READ(&act->sa_mask, sizeof(act->sa_mask));\n   }\n }\n \n-POST_SYSCALL(sigaction)(long res, long signum,\n-                        const __sanitizer_kernel_sigaction_t *act,\n-                        __sanitizer_kernel_sigaction_t *oldact) {\n-  if (res >= 0 && oldact) POST_WRITE(oldact, sizeof(*oldact));\n+POST_SYSCALL(sigaction)\n+(long res, long signum, const __sanitizer_kernel_sigaction_t *act,\n+ __sanitizer_kernel_sigaction_t *oldact) {\n+  if (res >= 0 && oldact)\n+    POST_WRITE(oldact, sizeof(*oldact));\n }\n \n-PRE_SYSCALL(rt_sigaction)(long signum,\n-                          const __sanitizer_kernel_sigaction_t *act,\n-                          __sanitizer_kernel_sigaction_t *oldact, SIZE_T sz) {\n+PRE_SYSCALL(rt_sigaction)\n+(long signum, const __sanitizer_kernel_sigaction_t *act,\n+ __sanitizer_kernel_sigaction_t *oldact, SIZE_T sz) {\n   if (act) {\n     PRE_READ(&act->sigaction, sizeof(act->sigaction));\n     PRE_READ(&act->sa_flags, sizeof(act->sa_flags));\n     PRE_READ(&act->sa_mask, sz);\n   }\n }\n \n-POST_SYSCALL(rt_sigaction)(long res, long signum,\n-                           const __sanitizer_kernel_sigaction_t *act,\n-                           __sanitizer_kernel_sigaction_t *oldact, SIZE_T sz) {\n+POST_SYSCALL(rt_sigaction)\n+(long res, long signum, const __sanitizer_kernel_sigaction_t *act,\n+ __sanitizer_kernel_sigaction_t *oldact, SIZE_T sz) {\n   if (res >= 0 && oldact) {\n     SIZE_T oldact_sz = ((char *)&oldact->sa_mask) - ((char *)oldact) + sz;\n     POST_WRITE(oldact, oldact_sz);\n@@ -2906,11 +3165,11 @@ POST_SYSCALL(sigaltstack)(long res, void *ss, void *oss) {\n }\n }  // extern \"C\"\n \n-#undef PRE_SYSCALL\n-#undef PRE_READ\n-#undef PRE_WRITE\n-#undef POST_SYSCALL\n-#undef POST_READ\n-#undef POST_WRITE\n+#  undef PRE_SYSCALL\n+#  undef PRE_READ\n+#  undef PRE_WRITE\n+#  undef POST_SYSCALL\n+#  undef POST_READ\n+#  undef POST_WRITE\n \n #endif  // SANITIZER_LINUX"}, {"sha": "1d0dbe592b9372e043c2c2f4b86b041d3af480f1", "filename": "libsanitizer/sanitizer_common/sanitizer_coverage_fuchsia.cpp", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_coverage_fuchsia.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_coverage_fuchsia.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_coverage_fuchsia.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -51,6 +51,8 @@ constexpr const char kSancovSinkName[] = \"sancov\";\n // This class relies on zero-initialization.\n class TracePcGuardController final {\n  public:\n+  constexpr TracePcGuardController() {}\n+\n   // For each PC location being tracked, there is a u32 reserved in global\n   // data called the \"guard\".  At startup, we assign each guard slot a\n   // unique index into the big results array.  Later during runtime, the\n@@ -87,7 +89,7 @@ class TracePcGuardController final {\n   }\n \n   void Dump() {\n-    BlockingMutexLock locked(&setup_lock_);\n+    Lock locked(&setup_lock_);\n     if (array_) {\n       CHECK_NE(vmo_, ZX_HANDLE_INVALID);\n \n@@ -114,7 +116,7 @@ class TracePcGuardController final {\n   // We can always spare the 32G of address space.\n   static constexpr size_t MappingSize = sizeof(uptr) << 32;\n \n-  BlockingMutex setup_lock_ = BlockingMutex(LINKER_INITIALIZED);\n+  Mutex setup_lock_;\n   uptr *array_ = nullptr;\n   u32 next_index_ = 0;\n   zx_handle_t vmo_ = {};\n@@ -123,7 +125,7 @@ class TracePcGuardController final {\n   size_t DataSize() const { return next_index_ * sizeof(uintptr_t); }\n \n   u32 Setup(u32 num_guards) {\n-    BlockingMutexLock locked(&setup_lock_);\n+    Lock locked(&setup_lock_);\n     DCHECK(common_flags()->coverage);\n \n     if (next_index_ == 0) {"}, {"sha": "56220df2ac18b71f4b5fd363a737197280c056d7", "filename": "libsanitizer/sanitizer_common/sanitizer_coverage_libcdep_new.cpp", "status": "modified", "additions": 61, "deletions": 4, "changes": 65, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_coverage_libcdep_new.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_coverage_libcdep_new.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_coverage_libcdep_new.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -73,7 +73,7 @@ static void SanitizerDumpCoverage(const uptr* unsorted_pcs, uptr len) {\n     if (!pc) continue;\n \n     if (!__sanitizer_get_module_and_offset_for_pc(pc, nullptr, 0, &pcs[i])) {\n-      Printf(\"ERROR: unknown pc 0x%x (may happen if dlclose is used)\\n\", pc);\n+      Printf(\"ERROR: unknown pc 0x%zx (may happen if dlclose is used)\\n\", pc);\n       continue;\n     }\n     uptr module_base = pc - pcs[i];\n@@ -151,6 +151,55 @@ class TracePcGuardController {\n \n static TracePcGuardController pc_guard_controller;\n \n+// A basic default implementation of callbacks for\n+// -fsanitize-coverage=inline-8bit-counters,pc-table.\n+// Use TOOL_OPTIONS (UBSAN_OPTIONS, etc) to dump the coverage data:\n+// * cov_8bit_counters_out=PATH to dump the 8bit counters.\n+// * cov_pcs_out=PATH to dump the pc table.\n+//\n+// Most users will still need to define their own callbacks for greater\n+// flexibility.\n+namespace SingletonCounterCoverage {\n+\n+static char *counters_beg, *counters_end;\n+static const uptr *pcs_beg, *pcs_end;\n+\n+static void DumpCoverage() {\n+  const char* file_path = common_flags()->cov_8bit_counters_out;\n+  if (file_path && internal_strlen(file_path)) {\n+    fd_t fd = OpenFile(file_path);\n+    FileCloser file_closer(fd);\n+    uptr size = counters_end - counters_beg;\n+    WriteToFile(fd, counters_beg, size);\n+    if (common_flags()->verbosity)\n+      __sanitizer::Printf(\"cov_8bit_counters_out: written %zd bytes to %s\\n\",\n+                          size, file_path);\n+  }\n+  file_path = common_flags()->cov_pcs_out;\n+  if (file_path && internal_strlen(file_path)) {\n+    fd_t fd = OpenFile(file_path);\n+    FileCloser file_closer(fd);\n+    uptr size = (pcs_end - pcs_beg) * sizeof(uptr);\n+    WriteToFile(fd, pcs_beg, size);\n+    if (common_flags()->verbosity)\n+      __sanitizer::Printf(\"cov_pcs_out: written %zd bytes to %s\\n\", size,\n+                          file_path);\n+  }\n+}\n+\n+static void Cov8bitCountersInit(char* beg, char* end) {\n+  counters_beg = beg;\n+  counters_end = end;\n+  Atexit(DumpCoverage);\n+}\n+\n+static void CovPcsInit(const uptr* beg, const uptr* end) {\n+  pcs_beg = beg;\n+  pcs_end = end;\n+}\n+\n+}  // namespace SingletonCounterCoverage\n+\n }  // namespace\n }  // namespace __sancov\n \n@@ -191,7 +240,9 @@ SANITIZER_INTERFACE_ATTRIBUTE void __sanitizer_cov_dump() {\n SANITIZER_INTERFACE_ATTRIBUTE void __sanitizer_cov_reset() {\n   __sancov::pc_guard_controller.Reset();\n }\n-// Default empty implementations (weak). Users should redefine them.\n+// Default implementations (weak).\n+// Either empty or very simple.\n+// Most users should redefine them.\n SANITIZER_INTERFACE_WEAK_DEF(void, __sanitizer_cov_trace_cmp, void) {}\n SANITIZER_INTERFACE_WEAK_DEF(void, __sanitizer_cov_trace_cmp1, void) {}\n SANITIZER_INTERFACE_WEAK_DEF(void, __sanitizer_cov_trace_cmp2, void) {}\n@@ -206,9 +257,15 @@ SANITIZER_INTERFACE_WEAK_DEF(void, __sanitizer_cov_trace_div4, void) {}\n SANITIZER_INTERFACE_WEAK_DEF(void, __sanitizer_cov_trace_div8, void) {}\n SANITIZER_INTERFACE_WEAK_DEF(void, __sanitizer_cov_trace_gep, void) {}\n SANITIZER_INTERFACE_WEAK_DEF(void, __sanitizer_cov_trace_pc_indir, void) {}\n-SANITIZER_INTERFACE_WEAK_DEF(void, __sanitizer_cov_8bit_counters_init, void) {}\n+SANITIZER_INTERFACE_WEAK_DEF(void, __sanitizer_cov_8bit_counters_init,\n+                             char* start, char* end) {\n+  __sancov::SingletonCounterCoverage::Cov8bitCountersInit(start, end);\n+}\n SANITIZER_INTERFACE_WEAK_DEF(void, __sanitizer_cov_bool_flag_init, void) {}\n-SANITIZER_INTERFACE_WEAK_DEF(void, __sanitizer_cov_pcs_init, void) {}\n+SANITIZER_INTERFACE_WEAK_DEF(void, __sanitizer_cov_pcs_init, const uptr* beg,\n+                             const uptr* end) {\n+  __sancov::SingletonCounterCoverage::CovPcsInit(beg, end);\n+}\n }  // extern \"C\"\n // Weak definition for code instrumented with -fsanitize-coverage=stack-depth\n // and later linked with code containing a strong definition."}, {"sha": "5492560df914b774da9da7fc13bd718d6ff9a4b0", "filename": "libsanitizer/sanitizer_common/sanitizer_file.cpp", "status": "modified", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_file.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_file.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_file.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -75,6 +75,20 @@ void ReportFile::ReopenIfNecessary() {\n   fd_pid = pid;\n }\n \n+static void RecursiveCreateParentDirs(char *path) {\n+  if (path[0] == '\\0')\n+    return;\n+  for (int i = 1; path[i] != '\\0'; ++i) {\n+    char save = path[i];\n+    if (!IsPathSeparator(path[i]))\n+      continue;\n+    path[i] = '\\0';\n+    /* Some of these will fail, because the directory exists, ignore it. */\n+    CreateDir(path);\n+    path[i] = save;\n+  }\n+}\n+\n void ReportFile::SetReportPath(const char *path) {\n   if (path) {\n     uptr len = internal_strlen(path);\n@@ -95,6 +109,7 @@ void ReportFile::SetReportPath(const char *path) {\n     fd = kStdoutFd;\n   } else {\n     internal_snprintf(path_prefix, kMaxPathLength, \"%s\", path);\n+    RecursiveCreateParentDirs(path_prefix);\n   }\n }\n "}, {"sha": "3d7916171c1efeb01cf4b42dd757108f064df60c", "filename": "libsanitizer/sanitizer_common/sanitizer_file.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_file.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_file.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_file.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -81,6 +81,8 @@ bool FileExists(const char *filename);\n char *FindPathToBinary(const char *name);\n bool IsPathSeparator(const char c);\n bool IsAbsolutePath(const char *path);\n+// Returns true on success, false on failure.\n+bool CreateDir(const char *pathname);\n // Starts a subprocess and returs its pid.\n // If *_fd parameters are not kInvalidFd their corresponding input/output\n // streams will be redirect to the file. The files will always be closed"}, {"sha": "3ccc6a6fa5377e3cc8d7f58676268ad1a8a913eb", "filename": "libsanitizer/sanitizer_common/sanitizer_flag_parser.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_flag_parser.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_flag_parser.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_flag_parser.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -138,7 +138,7 @@ inline bool FlagHandler<uptr>::Parse(const char *value) {\n \n template <>\n inline bool FlagHandler<uptr>::Format(char *buffer, uptr size) {\n-  uptr num_symbols_should_write = internal_snprintf(buffer, size, \"%p\", *t_);\n+  uptr num_symbols_should_write = internal_snprintf(buffer, size, \"0x%zx\", *t_);\n   return num_symbols_should_write < size;\n }\n "}, {"sha": "95da82b1a1dadd77420a20be3328ccf838c4dd74", "filename": "libsanitizer/sanitizer_common/sanitizer_flags.inc", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_flags.inc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_flags.inc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_flags.inc?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -160,6 +160,10 @@ COMMON_FLAG(\n COMMON_FLAG(const char *, coverage_dir, \".\",\n             \"Target directory for coverage dumps. Defaults to the current \"\n             \"directory.\")\n+COMMON_FLAG(const char *, cov_8bit_counters_out, \"\",\n+    \"If non-empty, write 8bit counters to this file. \")\n+COMMON_FLAG(const char *, cov_pcs_out, \"\",\n+    \"If non-empty, write the coverage pc table to this file. \")\n COMMON_FLAG(bool, full_address_space, false,\n             \"Sanitize complete address space; \"\n             \"by default kernel area on 32-bit platforms will not be sanitized\")"}, {"sha": "de4c985e4e4ee5ed51fa8e5084dbde89482563fe", "filename": "libsanitizer/sanitizer_common/sanitizer_fuchsia.cpp", "status": "modified", "additions": 0, "deletions": 41, "changes": 41, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_fuchsia.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_fuchsia.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_fuchsia.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -112,47 +112,6 @@ void FutexWake(atomic_uint32_t *p, u32 count) {\n   CHECK_EQ(status, ZX_OK);\n }\n \n-enum MutexState : int { MtxUnlocked = 0, MtxLocked = 1, MtxSleeping = 2 };\n-\n-BlockingMutex::BlockingMutex() {\n-  // NOTE!  It's important that this use internal_memset, because plain\n-  // memset might be intercepted (e.g., actually be __asan_memset).\n-  // Defining this so the compiler initializes each field, e.g.:\n-  //   BlockingMutex::BlockingMutex() : BlockingMutex(LINKER_INITIALIZED) {}\n-  // might result in the compiler generating a call to memset, which would\n-  // have the same problem.\n-  internal_memset(this, 0, sizeof(*this));\n-}\n-\n-void BlockingMutex::Lock() {\n-  CHECK_EQ(owner_, 0);\n-  atomic_uint32_t *m = reinterpret_cast<atomic_uint32_t *>(&opaque_storage_);\n-  if (atomic_exchange(m, MtxLocked, memory_order_acquire) == MtxUnlocked)\n-    return;\n-  while (atomic_exchange(m, MtxSleeping, memory_order_acquire) != MtxUnlocked) {\n-    zx_status_t status =\n-        _zx_futex_wait(reinterpret_cast<zx_futex_t *>(m), MtxSleeping,\n-                       ZX_HANDLE_INVALID, ZX_TIME_INFINITE);\n-    if (status != ZX_ERR_BAD_STATE)  // Normal race.\n-      CHECK_EQ(status, ZX_OK);\n-  }\n-}\n-\n-void BlockingMutex::Unlock() {\n-  atomic_uint32_t *m = reinterpret_cast<atomic_uint32_t *>(&opaque_storage_);\n-  u32 v = atomic_exchange(m, MtxUnlocked, memory_order_release);\n-  CHECK_NE(v, MtxUnlocked);\n-  if (v == MtxSleeping) {\n-    zx_status_t status = _zx_futex_wake(reinterpret_cast<zx_futex_t *>(m), 1);\n-    CHECK_EQ(status, ZX_OK);\n-  }\n-}\n-\n-void BlockingMutex::CheckLocked() const {\n-  auto m = reinterpret_cast<atomic_uint32_t const *>(&opaque_storage_);\n-  CHECK_NE(MtxUnlocked, atomic_load(m, memory_order_relaxed));\n-}\n-\n uptr GetPageSize() { return _zx_system_get_page_size(); }\n \n uptr GetMmapGranularity() { return _zx_system_get_page_size(); }"}, {"sha": "9683b97ab91d6b0aab5ca7b34441ef9ce7e65e71", "filename": "libsanitizer/sanitizer_common/sanitizer_interceptors_ioctl_netbsd.inc", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_interceptors_ioctl_netbsd.inc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_interceptors_ioctl_netbsd.inc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_interceptors_ioctl_netbsd.inc?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -1406,7 +1406,7 @@ static void ioctl_table_fill() {\n   _(URIO_SEND_COMMAND, READWRITE, struct_urio_command_sz);\n   _(URIO_RECV_COMMAND, READWRITE, struct_urio_command_sz);\n #undef _\n-} // NOLINT\n+}\n \n static bool ioctl_initialized = false;\n "}, {"sha": "1600d31c30c0c428174ba1bede354eea4e716e48", "filename": "libsanitizer/sanitizer_common/sanitizer_interface_internal.h", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_interface_internal.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_interface_internal.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_interface_internal.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -111,12 +111,13 @@ extern \"C\" {\n   SANITIZER_INTERFACE_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE\n   void __sanitizer_cov_trace_pc_guard_init(__sanitizer::u32*,\n                                            __sanitizer::u32*);\n-  SANITIZER_INTERFACE_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE\n-  void __sanitizer_cov_8bit_counters_init();\n+  SANITIZER_INTERFACE_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE void\n+  __sanitizer_cov_8bit_counters_init(char *, char *);\n   SANITIZER_INTERFACE_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE void\n   __sanitizer_cov_bool_flag_init();\n   SANITIZER_INTERFACE_ATTRIBUTE SANITIZER_WEAK_ATTRIBUTE void\n-  __sanitizer_cov_pcs_init();\n+  __sanitizer_cov_pcs_init(const __sanitizer::uptr *,\n+                           const __sanitizer::uptr *);\n } // extern \"C\"\n \n #endif  // SANITIZER_INTERFACE_INTERNAL_H"}, {"sha": "e97cc9ac0df17ac0abaac959733856ca3d5a793a", "filename": "libsanitizer/sanitizer_common/sanitizer_internal_defs.h", "status": "modified", "additions": 34, "deletions": 12, "changes": 46, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_internal_defs.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_internal_defs.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_internal_defs.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -125,6 +125,10 @@\n # define __has_attribute(x) 0\n #endif\n \n+#if !defined(__has_cpp_attribute)\n+#  define __has_cpp_attribute(x) 0\n+#endif\n+\n // For portability reasons we do not include stddef.h, stdint.h or any other\n // system header, but we do need some basic types that are not defined\n // in a portable way by the language itself.\n@@ -135,8 +139,13 @@ namespace __sanitizer {\n typedef unsigned long long uptr;\n typedef signed long long sptr;\n #else\n+#  if (SANITIZER_WORDSIZE == 64) || SANITIZER_MAC || SANITIZER_WINDOWS\n typedef unsigned long uptr;\n typedef signed long sptr;\n+#  else\n+typedef unsigned int uptr;\n+typedef signed int sptr;\n+#  endif\n #endif  // defined(_WIN64)\n #if defined(__x86_64__)\n // Since x32 uses ILP32 data model in 64-bit hardware mode, we must use\n@@ -168,10 +177,9 @@ typedef long pid_t;\n typedef int pid_t;\n #endif\n \n-#if SANITIZER_FREEBSD || SANITIZER_NETBSD || \\\n-    SANITIZER_MAC || \\\n+#if SANITIZER_FREEBSD || SANITIZER_NETBSD || SANITIZER_MAC ||             \\\n     (SANITIZER_SOLARIS && (defined(_LP64) || _FILE_OFFSET_BITS == 64)) || \\\n-    (SANITIZER_LINUX && defined(__x86_64__))\n+    (SANITIZER_LINUX && (defined(__x86_64__) || defined(__hexagon__)))\n typedef u64 OFF_T;\n #else\n typedef uptr OFF_T;\n@@ -250,6 +258,12 @@ typedef u64 tid_t;\n # define NOEXCEPT throw()\n #endif\n \n+#if __has_cpp_attribute(clang::fallthrough)\n+#  define FALLTHROUGH [[clang::fallthrough]]\n+#else\n+#  define FALLTHROUGH\n+#endif\n+\n // Unaligned versions of basic types.\n typedef ALIGNED(1) u16 uu16;\n typedef ALIGNED(1) u32 uu32;\n@@ -277,14 +291,16 @@ void NORETURN CheckFailed(const char *file, int line, const char *cond,\n                           u64 v1, u64 v2);\n \n // Check macro\n-#define RAW_CHECK_MSG(expr, msg) do { \\\n-  if (UNLIKELY(!(expr))) { \\\n-    RawWrite(msg); \\\n-    Die(); \\\n-  } \\\n-} while (0)\n+#define RAW_CHECK_MSG(expr, msg, ...)          \\\n+  do {                                         \\\n+    if (UNLIKELY(!(expr))) {                   \\\n+      const char* msgs[] = {msg, __VA_ARGS__}; \\\n+      for (const char* m : msgs) RawWrite(m);  \\\n+      Die();                                   \\\n+    }                                          \\\n+  } while (0)\n \n-#define RAW_CHECK(expr) RAW_CHECK_MSG(expr, #expr)\n+#define RAW_CHECK(expr, ...) RAW_CHECK_MSG(expr, #expr \"\\n\", __VA_ARGS__)\n \n #define CHECK_IMPL(c1, op, c2) \\\n   do { \\\n@@ -409,8 +425,14 @@ inline void Trap() {\n     (void)enable_fp;                      \\\n   } while (0)\n \n-constexpr u32 kInvalidTid = -1;\n-constexpr u32 kMainTid = 0;\n+// Internal thread identifier allocated by ThreadRegistry.\n+typedef u32 Tid;\n+constexpr Tid kInvalidTid = -1;\n+constexpr Tid kMainTid = 0;\n+\n+// Stack depot stack identifier.\n+typedef u32 StackID;\n+const StackID kInvalidStackID = 0;\n \n }  // namespace __sanitizer\n "}, {"sha": "d3076f0da48914f2bb41cb44929fd4af513b9dac", "filename": "libsanitizer/sanitizer_common/sanitizer_libc.cpp", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_libc.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_libc.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_libc.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -258,6 +258,18 @@ s64 internal_simple_strtoll(const char *nptr, const char **endptr, int base) {\n   }\n }\n \n+uptr internal_wcslen(const wchar_t *s) {\n+  uptr i = 0;\n+  while (s[i]) i++;\n+  return i;\n+}\n+\n+uptr internal_wcsnlen(const wchar_t *s, uptr maxlen) {\n+  uptr i = 0;\n+  while (i < maxlen && s[i]) i++;\n+  return i;\n+}\n+\n bool mem_is_zero(const char *beg, uptr size) {\n   CHECK_LE(size, 1ULL << FIRST_32_SECOND_64(30, 40));  // Sanity check.\n   const char *end = beg + size;"}, {"sha": "39a212665d0aef73bb9d5b67339887f4b2aa0318", "filename": "libsanitizer/sanitizer_common/sanitizer_libc.h", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_libc.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_libc.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_libc.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -49,7 +49,10 @@ char *internal_strrchr(const char *s, int c);\n char *internal_strstr(const char *haystack, const char *needle);\n // Works only for base=10 and doesn't set errno.\n s64 internal_simple_strtoll(const char *nptr, const char **endptr, int base);\n-int internal_snprintf(char *buffer, uptr length, const char *format, ...);\n+int internal_snprintf(char *buffer, uptr length, const char *format, ...)\n+    FORMAT(3, 4);\n+uptr internal_wcslen(const wchar_t *s);\n+uptr internal_wcsnlen(const wchar_t *s, uptr maxlen);\n \n // Return true if all bytes in [mem, mem+size) are zero.\n // Optimized for the case when the result is true."}, {"sha": "caaba3155a7becfb97bd9fe669bd0138d37d4c88", "filename": "libsanitizer/sanitizer_common/sanitizer_libignore.cpp", "status": "modified", "additions": 4, "deletions": 29, "changes": 33, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_libignore.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_libignore.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_libignore.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -22,9 +22,9 @@ LibIgnore::LibIgnore(LinkerInitialized) {\n }\n \n void LibIgnore::AddIgnoredLibrary(const char *name_templ) {\n-  BlockingMutexLock lock(&mutex_);\n+  Lock lock(&mutex_);\n   if (count_ >= kMaxLibs) {\n-    Report(\"%s: too many ignored libraries (max: %d)\\n\", SanitizerToolName,\n+    Report(\"%s: too many ignored libraries (max: %zu)\\n\", SanitizerToolName,\n            kMaxLibs);\n     Die();\n   }\n@@ -36,7 +36,7 @@ void LibIgnore::AddIgnoredLibrary(const char *name_templ) {\n }\n \n void LibIgnore::OnLibraryLoaded(const char *name) {\n-  BlockingMutexLock lock(&mutex_);\n+  Lock lock(&mutex_);\n   // Try to match suppressions with symlink target.\n   InternalMmapVector<char> buf(kMaxPathLength);\n   if (name && internal_readlink(name, buf.data(), buf.size() - 1) > 0 &&\n@@ -84,7 +84,6 @@ void LibIgnore::OnLibraryLoaded(const char *name) {\n         ignored_code_ranges_[idx].begin = range.beg;\n         ignored_code_ranges_[idx].end = range.end;\n         atomic_store(&ignored_ranges_count_, idx + 1, memory_order_release);\n-        atomic_store(&enabled_, 1, memory_order_release);\n         break;\n       }\n     }\n@@ -106,7 +105,7 @@ void LibIgnore::OnLibraryLoaded(const char *name) {\n           continue;\n         if (IsPcInstrumented(range.beg) && IsPcInstrumented(range.end - 1))\n           continue;\n-        VReport(1, \"Adding instrumented range %p-%p from library '%s'\\n\",\n+        VReport(1, \"Adding instrumented range 0x%zx-0x%zx from library '%s'\\n\",\n                 range.beg, range.end, mod.full_name());\n         const uptr idx =\n             atomic_load(&instrumented_ranges_count_, memory_order_relaxed);\n@@ -115,7 +114,6 @@ void LibIgnore::OnLibraryLoaded(const char *name) {\n         instrumented_code_ranges_[idx].end = range.end;\n         atomic_store(&instrumented_ranges_count_, idx + 1,\n                      memory_order_release);\n-        atomic_store(&enabled_, 1, memory_order_release);\n       }\n     }\n   }\n@@ -125,29 +123,6 @@ void LibIgnore::OnLibraryUnloaded() {\n   OnLibraryLoaded(nullptr);\n }\n \n-bool LibIgnore::IsIgnoredSlow(uptr pc, bool *pc_in_ignored_lib) const {\n-  const uptr n = atomic_load(&ignored_ranges_count_, memory_order_acquire);\n-  for (uptr i = 0; i < n; i++) {\n-    if (IsInRange(pc, ignored_code_ranges_[i])) {\n-      *pc_in_ignored_lib = true;\n-      return true;\n-    }\n-  }\n-  *pc_in_ignored_lib = false;\n-  if (track_instrumented_libs_ && !IsPcInstrumented(pc))\n-    return true;\n-  return false;\n-}\n-\n-bool LibIgnore::IsPcInstrumented(uptr pc) const {\n-  const uptr n = atomic_load(&instrumented_ranges_count_, memory_order_acquire);\n-  for (uptr i = 0; i < n; i++) {\n-    if (IsInRange(pc, instrumented_code_ranges_[i]))\n-      return true;\n-  }\n-  return false;\n-}\n-\n } // namespace __sanitizer\n \n #endif  // SANITIZER_FREEBSD || SANITIZER_LINUX || SANITIZER_MAC ||"}, {"sha": "18e4d83ed77fb8d3a9db0f12e974b308fc3ac948", "filename": "libsanitizer/sanitizer_common/sanitizer_libignore.h", "status": "modified", "additions": 25, "deletions": 12, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_libignore.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_libignore.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_libignore.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -45,6 +45,9 @@ class LibIgnore {\n   // \"pc_in_ignored_lib\" if the PC is in an ignored library, false otherwise.\n   bool IsIgnored(uptr pc, bool *pc_in_ignored_lib) const;\n \n+  // Checks whether the provided PC belongs to an instrumented module.\n+  bool IsPcInstrumented(uptr pc) const;\n+\n  private:\n   struct Lib {\n     char *templ;\n@@ -58,10 +61,6 @@ class LibIgnore {\n     uptr end;\n   };\n \n-  // Checks whether the provided PC belongs to an instrumented module.\n-  bool IsPcInstrumented(uptr pc) const;\n-  bool IsIgnoredSlow(uptr pc, bool *pc_in_ignored_lib) const;\n-\n   inline bool IsInRange(uptr pc, const LibCodeRange &range) const {\n     return (pc >= range.begin && pc < range.end);\n   }\n@@ -71,16 +70,14 @@ class LibIgnore {\n   static const uptr kMaxLibs = 1024;\n \n   // Hot part:\n-  atomic_uintptr_t enabled_;\n-\n   atomic_uintptr_t ignored_ranges_count_;\n   LibCodeRange ignored_code_ranges_[kMaxIgnoredRanges];\n \n   atomic_uintptr_t instrumented_ranges_count_;\n   LibCodeRange instrumented_code_ranges_[kMaxInstrumentedRanges];\n \n   // Cold part:\n-  BlockingMutex mutex_;\n+  Mutex mutex_;\n   uptr count_;\n   Lib libs_[kMaxLibs];\n   bool track_instrumented_libs_;\n@@ -90,11 +87,27 @@ class LibIgnore {\n   void operator = (const LibIgnore&);  // not implemented\n };\n \n-ALWAYS_INLINE\n-bool LibIgnore::IsIgnored(uptr pc, bool *pc_in_ignored_lib) const {\n-  if (LIKELY(atomic_load(&enabled_, memory_order_acquire) == 0))\n-    return false;\n-  return IsIgnoredSlow(pc, pc_in_ignored_lib);\n+inline bool LibIgnore::IsIgnored(uptr pc, bool *pc_in_ignored_lib) const {\n+  const uptr n = atomic_load(&ignored_ranges_count_, memory_order_acquire);\n+  for (uptr i = 0; i < n; i++) {\n+    if (IsInRange(pc, ignored_code_ranges_[i])) {\n+      *pc_in_ignored_lib = true;\n+      return true;\n+    }\n+  }\n+  *pc_in_ignored_lib = false;\n+  if (track_instrumented_libs_ && !IsPcInstrumented(pc))\n+    return true;\n+  return false;\n+}\n+\n+inline bool LibIgnore::IsPcInstrumented(uptr pc) const {\n+  const uptr n = atomic_load(&instrumented_ranges_count_, memory_order_acquire);\n+  for (uptr i = 0; i < n; i++) {\n+    if (IsInRange(pc, instrumented_code_ranges_[i]))\n+      return true;\n+  }\n+  return false;\n }\n \n }  // namespace __sanitizer"}, {"sha": "ea3e5bdbc754a15a10446d6d142ec372715f9ea9", "filename": "libsanitizer/sanitizer_common/sanitizer_linux.cpp", "status": "modified", "additions": 30, "deletions": 53, "changes": 83, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_linux.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_linux.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_linux.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -158,9 +158,11 @@ namespace __sanitizer {\n #include \"sanitizer_syscall_linux_aarch64.inc\"\n #elif SANITIZER_LINUX && defined(__arm__)\n #include \"sanitizer_syscall_linux_arm.inc\"\n-#else\n-#include \"sanitizer_syscall_generic.inc\"\n-#endif\n+#  elif SANITIZER_LINUX && defined(__hexagon__)\n+#    include \"sanitizer_syscall_linux_hexagon.inc\"\n+#  else\n+#    include \"sanitizer_syscall_generic.inc\"\n+#  endif\n \n // --------------- sanitizer_libc.h\n #if !SANITIZER_SOLARIS && !SANITIZER_NETBSD\n@@ -415,7 +417,7 @@ uptr internal_unlink(const char *path) {\n }\n \n uptr internal_rename(const char *oldpath, const char *newpath) {\n-#if defined(__riscv)\n+#if defined(__riscv) && defined(__linux__)\n   return internal_syscall(SYSCALL(renameat2), AT_FDCWD, (uptr)oldpath, AT_FDCWD,\n                           (uptr)newpath, 0);\n #elif SANITIZER_USES_CANONICAL_LINUX_SYSCALLS\n@@ -659,48 +661,6 @@ void FutexWake(atomic_uint32_t *p, u32 count) {\n #    endif\n }\n \n-enum { MtxUnlocked = 0, MtxLocked = 1, MtxSleeping = 2 };\n-\n-BlockingMutex::BlockingMutex() {\n-  internal_memset(this, 0, sizeof(*this));\n-}\n-\n-void BlockingMutex::Lock() {\n-  CHECK_EQ(owner_, 0);\n-  atomic_uint32_t *m = reinterpret_cast<atomic_uint32_t *>(&opaque_storage_);\n-  if (atomic_exchange(m, MtxLocked, memory_order_acquire) == MtxUnlocked)\n-    return;\n-  while (atomic_exchange(m, MtxSleeping, memory_order_acquire) != MtxUnlocked) {\n-#if SANITIZER_FREEBSD\n-    _umtx_op(m, UMTX_OP_WAIT_UINT, MtxSleeping, 0, 0);\n-#elif SANITIZER_NETBSD\n-    sched_yield(); /* No userspace futex-like synchronization */\n-#else\n-    internal_syscall(SYSCALL(futex), (uptr)m, FUTEX_WAIT_PRIVATE, MtxSleeping,\n-                     0, 0, 0);\n-#endif\n-  }\n-}\n-\n-void BlockingMutex::Unlock() {\n-  atomic_uint32_t *m = reinterpret_cast<atomic_uint32_t *>(&opaque_storage_);\n-  u32 v = atomic_exchange(m, MtxUnlocked, memory_order_release);\n-  CHECK_NE(v, MtxUnlocked);\n-  if (v == MtxSleeping) {\n-#if SANITIZER_FREEBSD\n-    _umtx_op(m, UMTX_OP_WAKE, 1, 0, 0);\n-#elif SANITIZER_NETBSD\n-                   /* No userspace futex-like synchronization */\n-#else\n-    internal_syscall(SYSCALL(futex), (uptr)m, FUTEX_WAKE_PRIVATE, 1, 0, 0, 0);\n-#endif\n-  }\n-}\n-\n-void BlockingMutex::CheckLocked() const {\n-  auto m = reinterpret_cast<atomic_uint32_t const *>(&opaque_storage_);\n-  CHECK_NE(MtxUnlocked, atomic_load(m, memory_order_relaxed));\n-}\n #  endif  // !SANITIZER_SOLARIS\n \n // ----------------- sanitizer_linux.h\n@@ -1217,7 +1177,8 @@ void ForEachMappedRegion(link_map *map, void (*cb)(const void *, uptr)) {\n }\n #endif\n \n-#if defined(__x86_64__) && SANITIZER_LINUX\n+#if SANITIZER_LINUX\n+#if defined(__x86_64__)\n // We cannot use glibc's clone wrapper, because it messes with the child\n // task's TLS. It writes the PID and TID of the child task to its thread\n // descriptor, but in our case the child task shares the thread descriptor with\n@@ -1556,7 +1517,7 @@ uptr internal_clone(int (*fn)(void *), void *child_stack, int flags, void *arg,\n              : \"cr0\", \"cr1\", \"memory\", \"ctr\", \"r0\", \"r27\", \"r28\", \"r29\");\n   return res;\n }\n-#elif defined(__i386__) && SANITIZER_LINUX\n+#elif defined(__i386__)\n uptr internal_clone(int (*fn)(void *), void *child_stack, int flags, void *arg,\n                     int *parent_tidptr, void *newtls, int *child_tidptr) {\n   int res;\n@@ -1621,7 +1582,7 @@ uptr internal_clone(int (*fn)(void *), void *child_stack, int flags, void *arg,\n                        : \"memory\");\n   return res;\n }\n-#elif defined(__arm__) && SANITIZER_LINUX\n+#elif defined(__arm__)\n uptr internal_clone(int (*fn)(void *), void *child_stack, int flags, void *arg,\n                     int *parent_tidptr, void *newtls, int *child_tidptr) {\n   unsigned int res;\n@@ -1687,7 +1648,8 @@ uptr internal_clone(int (*fn)(void *), void *child_stack, int flags, void *arg,\n                        : \"memory\");\n   return res;\n }\n-#endif  // defined(__x86_64__) && SANITIZER_LINUX\n+#endif\n+#endif  // SANITIZER_LINUX\n \n #if SANITIZER_LINUX\n int internal_uname(struct utsname *buf) {\n@@ -1917,7 +1879,11 @@ SignalContext::WriteFlag SignalContext::GetWriteFlag() const {\n   u32 instr = *(u32 *)pc;\n   return (instr >> 21) & 1 ? WRITE: READ;\n #elif defined(__riscv)\n+#if SANITIZER_FREEBSD\n+  unsigned long pc = ucontext->uc_mcontext.mc_gpregs.gp_sepc;\n+#else\n   unsigned long pc = ucontext->uc_mcontext.__gregs[REG_PC];\n+#endif\n   unsigned faulty_instruction = *(uint16_t *)pc;\n \n #if defined(__riscv_compressed)\n@@ -2136,12 +2102,23 @@ static void GetPcSpBp(void *context, uptr *pc, uptr *sp, uptr *bp) {\n   *sp = ucontext->uc_mcontext.gregs[15];\n #elif defined(__riscv)\n   ucontext_t *ucontext = (ucontext_t*)context;\n+#    if SANITIZER_FREEBSD\n+  *pc = ucontext->uc_mcontext.mc_gpregs.gp_sepc;\n+  *bp = ucontext->uc_mcontext.mc_gpregs.gp_s[0];\n+  *sp = ucontext->uc_mcontext.mc_gpregs.gp_sp;\n+#    else\n   *pc = ucontext->uc_mcontext.__gregs[REG_PC];\n   *bp = ucontext->uc_mcontext.__gregs[REG_S0];\n   *sp = ucontext->uc_mcontext.__gregs[REG_SP];\n-#else\n-# error \"Unsupported arch\"\n-#endif\n+#    endif\n+#  elif defined(__hexagon__)\n+  ucontext_t *ucontext = (ucontext_t *)context;\n+  *pc = ucontext->uc_mcontext.pc;\n+  *bp = ucontext->uc_mcontext.r30;\n+  *sp = ucontext->uc_mcontext.r29;\n+#  else\n+#    error \"Unsupported arch\"\n+#  endif\n }\n \n void SignalContext::InitPcSpBp() { GetPcSpBp(context, &pc, &sp, &bp); }"}, {"sha": "7ce9e25da342d8d70312d956a68b137f29326eb8", "filename": "libsanitizer/sanitizer_common/sanitizer_linux_libcdep.cpp", "status": "modified", "additions": 0, "deletions": 4, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_linux_libcdep.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_linux_libcdep.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_linux_libcdep.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -759,13 +759,9 @@ u32 GetNumberOfCPUs() {\n #elif SANITIZER_SOLARIS\n   return sysconf(_SC_NPROCESSORS_ONLN);\n #else\n-#if defined(CPU_COUNT)\n   cpu_set_t CPUs;\n   CHECK_EQ(sched_getaffinity(0, sizeof(cpu_set_t), &CPUs), 0);\n   return CPU_COUNT(&CPUs);\n-#else\n-  return 1;\n-#endif\n #endif\n }\n "}, {"sha": "a47cfc945cd855b30d6f10b2aacb03705ffee15e", "filename": "libsanitizer/sanitizer_common/sanitizer_local_address_space_view.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_local_address_space_view.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_local_address_space_view.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_local_address_space_view.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -17,7 +17,7 @@\n // instantiated with the `LocalAddressSpaceView` type. This type is used to\n // load any pointers in instance methods. This implementation is effectively\n // a no-op. When an object is to be used in an out-of-process manner it is\n-// instansiated with the `RemoteAddressSpaceView` type.\n+// instantiated with the `RemoteAddressSpaceView` type.\n //\n // By making `AddressSpaceView` a template parameter of an object, it can\n // change its implementation at compile time which has no run time overhead."}, {"sha": "b8839f197d2c1fb89f032258692ea399a6421d5f", "filename": "libsanitizer/sanitizer_common/sanitizer_mac.cpp", "status": "modified", "additions": 7, "deletions": 34, "changes": 41, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_mac.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_mac.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_mac.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -37,7 +37,7 @@\n extern char **environ;\n #endif\n \n-#if defined(__has_include) && __has_include(<os/trace.h>) && defined(__BLOCKS__)\n+#if defined(__has_include) && __has_include(<os/trace.h>)\n #define SANITIZER_OS_TRACE 1\n #include <os/trace.h>\n #else\n@@ -70,15 +70,7 @@ extern \"C\" {\n #include <mach/mach_time.h>\n #include <mach/vm_statistics.h>\n #include <malloc/malloc.h>\n-#if defined(__has_builtin) && __has_builtin(__builtin_os_log_format)\n-# include <os/log.h>\n-#else\n-   /* Without support for __builtin_os_log_format, fall back to the older\n-      method.  */\n-# define OS_LOG_DEFAULT 0\n-# define os_log_error(A,B,C) \\\n-  asl_log(nullptr, nullptr, ASL_LEVEL_ERR, \"%s\", (C));\n-#endif\n+#include <os/log.h>\n #include <pthread.h>\n #include <sched.h>\n #include <signal.h>\n@@ -524,25 +516,6 @@ void FutexWait(atomic_uint32_t *p, u32 cmp) {\n \n void FutexWake(atomic_uint32_t *p, u32 count) {}\n \n-BlockingMutex::BlockingMutex() {\n-  internal_memset(this, 0, sizeof(*this));\n-}\n-\n-void BlockingMutex::Lock() {\n-  CHECK(sizeof(OSSpinLock) <= sizeof(opaque_storage_));\n-  CHECK_EQ(OS_SPINLOCK_INIT, 0);\n-  CHECK_EQ(owner_, 0);\n-  OSSpinLockLock((OSSpinLock*)&opaque_storage_);\n-}\n-\n-void BlockingMutex::Unlock() {\n-  OSSpinLockUnlock((OSSpinLock*)&opaque_storage_);\n-}\n-\n-void BlockingMutex::CheckLocked() const {\n-  CHECK_NE(*(OSSpinLock*)&opaque_storage_, 0);\n-}\n-\n u64 NanoTime() {\n   timeval tv;\n   internal_memset(&tv, 0, sizeof(tv));\n@@ -792,8 +765,8 @@ void *internal_start_thread(void *(*func)(void *arg), void *arg) {\n void internal_join_thread(void *th) { pthread_join((pthread_t)th, 0); }\n \n #if !SANITIZER_GO\n-static BlockingMutex syslog_lock(LINKER_INITIALIZED);\n-#endif\n+static Mutex syslog_lock;\n+#  endif\n \n void WriteOneLineToSyslog(const char *s) {\n #if !SANITIZER_GO\n@@ -808,7 +781,7 @@ void WriteOneLineToSyslog(const char *s) {\n \n // buffer to store crash report application information\n static char crashreporter_info_buff[__sanitizer::kErrorMessageBufferSize] = {};\n-static BlockingMutex crashreporter_info_mutex(LINKER_INITIALIZED);\n+static Mutex crashreporter_info_mutex;\n \n extern \"C\" {\n // Integrate with crash reporter libraries.\n@@ -838,7 +811,7 @@ asm(\".desc ___crashreporter_info__, 0x10\");\n }  // extern \"C\"\n \n static void CRAppendCrashLogMessage(const char *msg) {\n-  BlockingMutexLock l(&crashreporter_info_mutex);\n+  Lock l(&crashreporter_info_mutex);\n   internal_strlcat(crashreporter_info_buff, msg,\n                    sizeof(crashreporter_info_buff));\n #if HAVE_CRASHREPORTERCLIENT_H\n@@ -882,7 +855,7 @@ void LogFullErrorReport(const char *buffer) {\n   // the reporting thread holds the thread registry mutex, and asl_log waits\n   // for GCD to dispatch a new thread, the process will deadlock, because the\n   // pthread_create wrapper needs to acquire the lock as well.\n-  BlockingMutexLock l(&syslog_lock);\n+  Lock l(&syslog_lock);\n   if (common_flags()->log_to_syslog)\n     WriteToSyslog(buffer);\n "}, {"sha": "0b6af5a3c0edc649c4d65dfd1a6ca1bce13aa9b9", "filename": "libsanitizer/sanitizer_common/sanitizer_mac.h", "status": "modified", "additions": 0, "deletions": 20, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_mac.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_mac.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_mac.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -14,26 +14,6 @@\n \n #include \"sanitizer_common.h\"\n #include \"sanitizer_platform.h\"\n-\n-/* TARGET_OS_OSX is not present in SDKs before Darwin16 (macOS 10.12) use\n-   TARGET_OS_MAC (we have no support for iOS in any form for these versions,\n-   so there's no ambiguity).  */\n-#if !defined(TARGET_OS_OSX) && TARGET_OS_MAC\n-# define TARGET_OS_OSX 1\n-#endif\n-\n-/* Other TARGET_OS_xxx are not present on earlier versions, define them to\n-   0 (we have no support for them; they are not valid targets anyway).  */\n-#ifndef TARGET_OS_IOS\n-#define TARGET_OS_IOS 0\n-#endif\n-#ifndef TARGET_OS_TV\n-#define TARGET_OS_TV 0\n-#endif\n-#ifndef TARGET_OS_WATCH\n-#define TARGET_OS_WATCH 0\n-#endif\n-\n #if SANITIZER_MAC\n #include \"sanitizer_posix.h\"\n "}, {"sha": "1c177d8e7cca3aa3948cd984a22035fbc544f098", "filename": "libsanitizer/sanitizer_common/sanitizer_mutex.cpp", "status": "modified", "additions": 186, "deletions": 0, "changes": 186, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_mutex.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_mutex.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_mutex.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -16,6 +16,18 @@\n \n namespace __sanitizer {\n \n+void StaticSpinMutex::LockSlow() {\n+  for (int i = 0;; i++) {\n+    if (i < 100)\n+      proc_yield(1);\n+    else\n+      internal_sched_yield();\n+    if (atomic_load(&state_, memory_order_relaxed) == 0 &&\n+        atomic_exchange(&state_, 1, memory_order_acquire) == 0)\n+      return;\n+  }\n+}\n+\n void Semaphore::Wait() {\n   u32 count = atomic_load(&state_, memory_order_relaxed);\n   for (;;) {\n@@ -36,4 +48,178 @@ void Semaphore::Post(u32 count) {\n   FutexWake(&state_, count);\n }\n \n+#if SANITIZER_CHECK_DEADLOCKS\n+// An empty mutex meta table, it effectively disables deadlock detection.\n+// Each tool can override the table to define own mutex hierarchy and\n+// enable deadlock detection.\n+// The table defines a static mutex type hierarchy (what mutex types can be locked\n+// under what mutex types). This table is checked to be acyclic and then\n+// actual mutex lock/unlock operations are checked to adhere to this hierarchy.\n+// The checking happens on mutex types rather than on individual mutex instances\n+// because doing it on mutex instances will both significantly complicate\n+// the implementation, worsen performance and memory overhead and is mostly\n+// unnecessary (we almost never lock multiple mutexes of the same type recursively).\n+static constexpr int kMutexTypeMax = 20;\n+SANITIZER_WEAK_ATTRIBUTE MutexMeta mutex_meta[kMutexTypeMax] = {};\n+SANITIZER_WEAK_ATTRIBUTE void PrintMutexPC(uptr pc) {}\n+static StaticSpinMutex mutex_meta_mtx;\n+static int mutex_type_count = -1;\n+// Adjacency matrix of what mutexes can be locked under what mutexes.\n+static bool mutex_can_lock[kMutexTypeMax][kMutexTypeMax];\n+// Mutex types with MutexMulti mark.\n+static bool mutex_multi[kMutexTypeMax];\n+\n+void DebugMutexInit() {\n+  // Build adjacency matrix.\n+  bool leaf[kMutexTypeMax];\n+  internal_memset(&leaf, 0, sizeof(leaf));\n+  int cnt[kMutexTypeMax];\n+  internal_memset(&cnt, 0, sizeof(cnt));\n+  for (int t = 0; t < kMutexTypeMax; t++) {\n+    mutex_type_count = t;\n+    if (!mutex_meta[t].name)\n+      break;\n+    CHECK_EQ(t, mutex_meta[t].type);\n+    for (uptr j = 0; j < ARRAY_SIZE(mutex_meta[t].can_lock); j++) {\n+      MutexType z = mutex_meta[t].can_lock[j];\n+      if (z == MutexInvalid)\n+        break;\n+      if (z == MutexLeaf) {\n+        CHECK(!leaf[t]);\n+        leaf[t] = true;\n+        continue;\n+      }\n+      if (z == MutexMulti) {\n+        mutex_multi[t] = true;\n+        continue;\n+      }\n+      CHECK_LT(z, kMutexTypeMax);\n+      CHECK(!mutex_can_lock[t][z]);\n+      mutex_can_lock[t][z] = true;\n+      cnt[t]++;\n+    }\n+  }\n+  // Indicates the array is not properly terminated.\n+  CHECK_LT(mutex_type_count, kMutexTypeMax);\n+  // Add leaf mutexes.\n+  for (int t = 0; t < mutex_type_count; t++) {\n+    if (!leaf[t])\n+      continue;\n+    CHECK_EQ(cnt[t], 0);\n+    for (int z = 0; z < mutex_type_count; z++) {\n+      if (z == MutexInvalid || t == z || leaf[z])\n+        continue;\n+      CHECK(!mutex_can_lock[z][t]);\n+      mutex_can_lock[z][t] = true;\n+    }\n+  }\n+  // Build the transitive closure and check that the graphs is acyclic.\n+  u32 trans[kMutexTypeMax];\n+  static_assert(sizeof(trans[0]) * 8 >= kMutexTypeMax,\n+                \"kMutexTypeMax does not fit into u32, switch to u64\");\n+  internal_memset(&trans, 0, sizeof(trans));\n+  for (int i = 0; i < mutex_type_count; i++) {\n+    for (int j = 0; j < mutex_type_count; j++)\n+      if (mutex_can_lock[i][j])\n+        trans[i] |= 1 << j;\n+  }\n+  for (int k = 0; k < mutex_type_count; k++) {\n+    for (int i = 0; i < mutex_type_count; i++) {\n+      if (trans[i] & (1 << k))\n+        trans[i] |= trans[k];\n+    }\n+  }\n+  for (int i = 0; i < mutex_type_count; i++) {\n+    if (trans[i] & (1 << i)) {\n+      Printf(\"Mutex %s participates in a cycle\\n\", mutex_meta[i].name);\n+      Die();\n+    }\n+  }\n+}\n+\n+struct InternalDeadlockDetector {\n+  struct LockDesc {\n+    u64 seq;\n+    uptr pc;\n+    int recursion;\n+  };\n+  int initialized;\n+  u64 sequence;\n+  LockDesc locked[kMutexTypeMax];\n+\n+  void Lock(MutexType type, uptr pc) {\n+    if (!Initialize(type))\n+      return;\n+    CHECK_LT(type, mutex_type_count);\n+    // Find the last locked mutex type.\n+    // This is the type we will use for hierarchy checks.\n+    u64 max_seq = 0;\n+    MutexType max_idx = MutexInvalid;\n+    for (int i = 0; i != mutex_type_count; i++) {\n+      if (locked[i].seq == 0)\n+        continue;\n+      CHECK_NE(locked[i].seq, max_seq);\n+      if (max_seq < locked[i].seq) {\n+        max_seq = locked[i].seq;\n+        max_idx = (MutexType)i;\n+      }\n+    }\n+    if (max_idx == type && mutex_multi[type]) {\n+      // Recursive lock of the same type.\n+      CHECK_EQ(locked[type].seq, max_seq);\n+      CHECK(locked[type].pc);\n+      locked[type].recursion++;\n+      return;\n+    }\n+    if (max_idx != MutexInvalid && !mutex_can_lock[max_idx][type]) {\n+      Printf(\"%s: internal deadlock: can't lock %s under %s mutex\\n\", SanitizerToolName,\n+             mutex_meta[type].name, mutex_meta[max_idx].name);\n+      PrintMutexPC(pc);\n+      CHECK(0);\n+    }\n+    locked[type].seq = ++sequence;\n+    locked[type].pc = pc;\n+    locked[type].recursion = 1;\n+  }\n+\n+  void Unlock(MutexType type) {\n+    if (!Initialize(type))\n+      return;\n+    CHECK_LT(type, mutex_type_count);\n+    CHECK(locked[type].seq);\n+    CHECK_GT(locked[type].recursion, 0);\n+    if (--locked[type].recursion)\n+      return;\n+    locked[type].seq = 0;\n+    locked[type].pc = 0;\n+  }\n+\n+  void CheckNoLocks() {\n+    for (int i = 0; i < mutex_type_count; i++) CHECK_EQ(locked[i].recursion, 0);\n+  }\n+\n+  bool Initialize(MutexType type) {\n+    if (type == MutexUnchecked || type == MutexInvalid)\n+      return false;\n+    CHECK_GT(type, MutexInvalid);\n+    if (initialized != 0)\n+      return initialized > 0;\n+    initialized = -1;\n+    SpinMutexLock lock(&mutex_meta_mtx);\n+    if (mutex_type_count < 0)\n+      DebugMutexInit();\n+    initialized = mutex_type_count ? 1 : -1;\n+    return initialized > 0;\n+  }\n+};\n+\n+static THREADLOCAL InternalDeadlockDetector deadlock_detector;\n+\n+void CheckedMutex::LockImpl(uptr pc) { deadlock_detector.Lock(type_, pc); }\n+\n+void CheckedMutex::UnlockImpl() { deadlock_detector.Unlock(type_); }\n+\n+void CheckedMutex::CheckNoLocksImpl() { deadlock_detector.CheckNoLocks(); }\n+#endif\n+\n }  // namespace __sanitizer"}, {"sha": "7479d35f2a594416c776e296c8309449aa44901e", "filename": "libsanitizer/sanitizer_common/sanitizer_mutex.h", "status": "modified", "additions": 168, "deletions": 157, "changes": 325, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_mutex.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_mutex.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_mutex.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -27,7 +27,7 @@ class MUTEX StaticSpinMutex {\n   }\n \n   void Lock() ACQUIRE() {\n-    if (TryLock())\n+    if (LIKELY(TryLock()))\n       return;\n     LockSlow();\n   }\n@@ -45,17 +45,7 @@ class MUTEX StaticSpinMutex {\n  private:\n   atomic_uint8_t state_;\n \n-  void NOINLINE LockSlow() {\n-    for (int i = 0;; i++) {\n-      if (i < 10)\n-        proc_yield(10);\n-      else\n-        internal_sched_yield();\n-      if (atomic_load(&state_, memory_order_relaxed) == 0\n-          && atomic_exchange(&state_, 1, memory_order_acquire) == 0)\n-        return;\n-    }\n-  }\n+  void LockSlow();\n };\n \n class MUTEX SpinMutex : public StaticSpinMutex {\n@@ -64,7 +54,6 @@ class MUTEX SpinMutex : public StaticSpinMutex {\n     Init();\n   }\n \n- private:\n   SpinMutex(const SpinMutex &) = delete;\n   void operator=(const SpinMutex &) = delete;\n };\n@@ -85,15 +74,94 @@ class Semaphore {\n   atomic_uint32_t state_ = {0};\n };\n \n+typedef int MutexType;\n+\n+enum {\n+  // Used as sentinel and to catch unassigned types\n+  // (should not be used as real Mutex type).\n+  MutexInvalid = 0,\n+  MutexThreadRegistry,\n+  // Each tool own mutexes must start at this number.\n+  MutexLastCommon,\n+  // Type for legacy mutexes that are not checked for deadlocks.\n+  MutexUnchecked = -1,\n+  // Special marks that can be used in MutexMeta::can_lock table.\n+  // The leaf mutexes can be locked under any other non-leaf mutex,\n+  // but no other mutex can be locked while under a leaf mutex.\n+  MutexLeaf = -1,\n+  // Multiple mutexes of this type can be locked at the same time.\n+  MutexMulti = -3,\n+};\n+\n+// Go linker does not support THREADLOCAL variables,\n+// so we can't use per-thread state.\n+#define SANITIZER_CHECK_DEADLOCKS \\\n+  (SANITIZER_DEBUG && !SANITIZER_GO && SANITIZER_SUPPORTS_THREADLOCAL)\n+\n+#if SANITIZER_CHECK_DEADLOCKS\n+struct MutexMeta {\n+  MutexType type;\n+  const char *name;\n+  // The table fixes what mutexes can be locked under what mutexes.\n+  // If the entry for MutexTypeFoo contains MutexTypeBar,\n+  // then Bar mutex can be locked while under Foo mutex.\n+  // Can also contain the special MutexLeaf/MutexMulti marks.\n+  MutexType can_lock[10];\n+};\n+#endif\n+\n+class CheckedMutex {\n+ public:\n+  explicit constexpr CheckedMutex(MutexType type)\n+#if SANITIZER_CHECK_DEADLOCKS\n+      : type_(type)\n+#endif\n+  {\n+  }\n+\n+  ALWAYS_INLINE void Lock() {\n+#if SANITIZER_CHECK_DEADLOCKS\n+    LockImpl(GET_CALLER_PC());\n+#endif\n+  }\n+\n+  ALWAYS_INLINE void Unlock() {\n+#if SANITIZER_CHECK_DEADLOCKS\n+    UnlockImpl();\n+#endif\n+  }\n+\n+  // Checks that the current thread does not hold any mutexes\n+  // (e.g. when returning from a runtime function to user code).\n+  static void CheckNoLocks() {\n+#if SANITIZER_CHECK_DEADLOCKS\n+    CheckNoLocksImpl();\n+#endif\n+  }\n+\n+ private:\n+#if SANITIZER_CHECK_DEADLOCKS\n+  const MutexType type_;\n+\n+  void LockImpl(uptr pc);\n+  void UnlockImpl();\n+  static void CheckNoLocksImpl();\n+#endif\n+};\n+\n // Reader-writer mutex.\n-class MUTEX Mutex2 {\n+// Derive from CheckedMutex for the purposes of EBO.\n+// We could make it a field marked with [[no_unique_address]],\n+// but this attribute is not supported by some older compilers.\n+class MUTEX Mutex : CheckedMutex {\n  public:\n-  constexpr Mutex2() {}\n+  explicit constexpr Mutex(MutexType type = MutexUnchecked)\n+      : CheckedMutex(type) {}\n \n   void Lock() ACQUIRE() {\n+    CheckedMutex::Lock();\n     u64 reset_mask = ~0ull;\n     u64 state = atomic_load_relaxed(&state_);\n-    const uptr kMaxSpinIters = 1500;\n     for (uptr spin_iters = 0;; spin_iters++) {\n       u64 new_state;\n       bool locked = (state & (kWriterLock | kReaderLockMask)) != 0;\n@@ -122,8 +190,6 @@ class MUTEX Mutex2 {\n         // We've incremented waiting writers, so now block.\n         writers_.Wait();\n         spin_iters = 0;\n-        state = atomic_load(&state_, memory_order_relaxed);\n-        DCHECK_NE(state & kWriterSpinWait, 0);\n       } else {\n         // We've set kWriterSpinWait, but we are still in active spinning.\n       }\n@@ -132,10 +198,13 @@ class MUTEX Mutex2 {\n       // Either way we need to reset kWriterSpinWait\n       // next time we take the lock or block again.\n       reset_mask = ~kWriterSpinWait;\n+      state = atomic_load(&state_, memory_order_relaxed);\n+      DCHECK_NE(state & kWriterSpinWait, 0);\n     }\n   }\n \n   void Unlock() RELEASE() {\n+    CheckedMutex::Unlock();\n     bool wake_writer;\n     u64 wake_readers;\n     u64 new_state;\n@@ -144,17 +213,16 @@ class MUTEX Mutex2 {\n       DCHECK_NE(state & kWriterLock, 0);\n       DCHECK_EQ(state & kReaderLockMask, 0);\n       new_state = state & ~kWriterLock;\n-      wake_writer =\n-          (state & kWriterSpinWait) == 0 && (state & kWaitingWriterMask) != 0;\n+      wake_writer = (state & (kWriterSpinWait | kReaderSpinWait)) == 0 &&\n+                    (state & kWaitingWriterMask) != 0;\n       if (wake_writer)\n         new_state = (new_state - kWaitingWriterInc) | kWriterSpinWait;\n       wake_readers =\n-          (state & (kWriterSpinWait | kWaitingWriterMask)) != 0\n+          wake_writer || (state & kWriterSpinWait) != 0\n               ? 0\n               : ((state & kWaitingReaderMask) >> kWaitingReaderShift);\n       if (wake_readers)\n-        new_state = (new_state & ~kWaitingReaderMask) +\n-                    (wake_readers << kReaderLockShift);\n+        new_state = (new_state & ~kWaitingReaderMask) | kReaderSpinWait;\n     } while (UNLIKELY(!atomic_compare_exchange_weak(&state_, &state, new_state,\n                                                     memory_order_release)));\n     if (UNLIKELY(wake_writer))\n@@ -164,34 +232,53 @@ class MUTEX Mutex2 {\n   }\n \n   void ReadLock() ACQUIRE_SHARED() {\n-    bool locked;\n-    u64 new_state;\n+    CheckedMutex::Lock();\n+    u64 reset_mask = ~0ull;\n     u64 state = atomic_load_relaxed(&state_);\n-    do {\n-      locked =\n-          (state & kReaderLockMask) == 0 &&\n-          (state & (kWriterLock | kWriterSpinWait | kWaitingWriterMask)) != 0;\n+    for (uptr spin_iters = 0;; spin_iters++) {\n+      bool locked = (state & kWriterLock) != 0;\n+      u64 new_state;\n+      if (LIKELY(!locked)) {\n+        new_state = (state + kReaderLockInc) & reset_mask;\n+      } else if (spin_iters > kMaxSpinIters) {\n+        new_state = (state + kWaitingReaderInc) & reset_mask;\n+      } else if ((state & kReaderSpinWait) == 0) {\n+        // Active spinning, but denote our presence so that unlocking\n+        // thread does not wake up other threads.\n+        new_state = state | kReaderSpinWait;\n+      } else {\n+        // Active spinning.\n+        state = atomic_load(&state_, memory_order_relaxed);\n+        continue;\n+      }\n+      if (UNLIKELY(!atomic_compare_exchange_weak(&state_, &state, new_state,\n+                                                 memory_order_acquire)))\n+        continue;\n       if (LIKELY(!locked))\n-        new_state = state + kReaderLockInc;\n-      else\n-        new_state = state + kWaitingReaderInc;\n-    } while (UNLIKELY(!atomic_compare_exchange_weak(&state_, &state, new_state,\n-                                                    memory_order_acquire)));\n-    if (UNLIKELY(locked))\n-      readers_.Wait();\n-    DCHECK_EQ(atomic_load_relaxed(&state_) & kWriterLock, 0);\n-    DCHECK_NE(atomic_load_relaxed(&state_) & kReaderLockMask, 0);\n+        return;  // We've locked the mutex.\n+      if (spin_iters > kMaxSpinIters) {\n+        // We've incremented waiting readers, so now block.\n+        readers_.Wait();\n+        spin_iters = 0;\n+      } else {\n+        // We've set kReaderSpinWait, but we are still in active spinning.\n+      }\n+      reset_mask = ~kReaderSpinWait;\n+      state = atomic_load(&state_, memory_order_relaxed);\n+    }\n   }\n \n   void ReadUnlock() RELEASE_SHARED() {\n+    CheckedMutex::Unlock();\n     bool wake;\n     u64 new_state;\n     u64 state = atomic_load_relaxed(&state_);\n     do {\n       DCHECK_NE(state & kReaderLockMask, 0);\n-      DCHECK_EQ(state & (kWaitingReaderMask | kWriterLock), 0);\n+      DCHECK_EQ(state & kWriterLock, 0);\n       new_state = state - kReaderLockInc;\n-      wake = (new_state & (kReaderLockMask | kWriterSpinWait)) == 0 &&\n+      wake = (new_state &\n+              (kReaderLockMask | kWriterSpinWait | kReaderSpinWait)) == 0 &&\n              (new_state & kWaitingWriterMask) != 0;\n       if (wake)\n         new_state = (new_state - kWaitingWriterInc) | kWriterSpinWait;\n@@ -235,16 +322,14 @@ class MUTEX Mutex2 {\n   //  - a writer is awake and spin-waiting\n   //    the flag is used to prevent thundering herd problem\n   //    (new writers are not woken if this flag is set)\n+  //  - a reader is awake and spin-waiting\n   //\n-  // Writer support active spinning, readers does not.\n+  // Both writers and readers use active spinning before blocking.\n   // But readers are more aggressive and always take the mutex\n   // if there are any other readers.\n-  // Writers hand off the mutex to readers: after wake up readers\n-  // already assume ownership of the mutex (don't need to do any\n-  // state updates). But the mutex is not handed off to writers,\n-  // after wake up writers compete to lock the mutex again.\n-  // This is needed to allow repeated write locks even in presence\n-  // of other blocked writers.\n+  // After wake up both writers and readers compete to lock the\n+  // mutex again. This is needed to allow repeated locks even in presence\n+  // of other blocked threads.\n   static constexpr u64 kCounterWidth = 20;\n   static constexpr u64 kReaderLockShift = 0;\n   static constexpr u64 kReaderLockInc = 1ull << kReaderLockShift;\n@@ -260,119 +345,18 @@ class MUTEX Mutex2 {\n                                             << kWaitingWriterShift;\n   static constexpr u64 kWriterLock = 1ull << (3 * kCounterWidth);\n   static constexpr u64 kWriterSpinWait = 1ull << (3 * kCounterWidth + 1);\n+  static constexpr u64 kReaderSpinWait = 1ull << (3 * kCounterWidth + 2);\n+\n+  static constexpr uptr kMaxSpinIters = 1500;\n \n-  Mutex2(const Mutex2 &) = delete;\n-  void operator=(const Mutex2 &) = delete;\n+  Mutex(LinkerInitialized) = delete;\n+  Mutex(const Mutex &) = delete;\n+  void operator=(const Mutex &) = delete;\n };\n \n void FutexWait(atomic_uint32_t *p, u32 cmp);\n void FutexWake(atomic_uint32_t *p, u32 count);\n \n-class MUTEX BlockingMutex {\n- public:\n-  explicit constexpr BlockingMutex(LinkerInitialized)\n-      : opaque_storage_ {0, }, owner_ {0} {}\n-  BlockingMutex();\n-  void Lock() ACQUIRE();\n-  void Unlock() RELEASE();\n-\n-  // This function does not guarantee an explicit check that the calling thread\n-  // is the thread which owns the mutex. This behavior, while more strictly\n-  // correct, causes problems in cases like StopTheWorld, where a parent thread\n-  // owns the mutex but a child checks that it is locked. Rather than\n-  // maintaining complex state to work around those situations, the check only\n-  // checks that the mutex is owned, and assumes callers to be generally\n-  // well-behaved.\n-  void CheckLocked() const CHECK_LOCKED();\n-\n- private:\n-  // Solaris mutex_t has a member that requires 64-bit alignment.\n-  ALIGNED(8) uptr opaque_storage_[10];\n-  uptr owner_;  // for debugging\n-};\n-\n-// Reader-writer spin mutex.\n-class MUTEX RWMutex {\n- public:\n-  RWMutex() {\n-    atomic_store(&state_, kUnlocked, memory_order_relaxed);\n-  }\n-\n-  ~RWMutex() {\n-    CHECK_EQ(atomic_load(&state_, memory_order_relaxed), kUnlocked);\n-  }\n-\n-  void Lock() ACQUIRE() {\n-    u32 cmp = kUnlocked;\n-    if (atomic_compare_exchange_strong(&state_, &cmp, kWriteLock,\n-                                       memory_order_acquire))\n-      return;\n-    LockSlow();\n-  }\n-\n-  void Unlock() RELEASE() {\n-    u32 prev = atomic_fetch_sub(&state_, kWriteLock, memory_order_release);\n-    DCHECK_NE(prev & kWriteLock, 0);\n-    (void)prev;\n-  }\n-\n-  void ReadLock() ACQUIRE_SHARED() {\n-    u32 prev = atomic_fetch_add(&state_, kReadLock, memory_order_acquire);\n-    if ((prev & kWriteLock) == 0)\n-      return;\n-    ReadLockSlow();\n-  }\n-\n-  void ReadUnlock() RELEASE_SHARED() {\n-    u32 prev = atomic_fetch_sub(&state_, kReadLock, memory_order_release);\n-    DCHECK_EQ(prev & kWriteLock, 0);\n-    DCHECK_GT(prev & ~kWriteLock, 0);\n-    (void)prev;\n-  }\n-\n-  void CheckLocked() const CHECK_LOCKED() {\n-    CHECK_NE(atomic_load(&state_, memory_order_relaxed), kUnlocked);\n-  }\n-\n- private:\n-  atomic_uint32_t state_;\n-\n-  enum {\n-    kUnlocked = 0,\n-    kWriteLock = 1,\n-    kReadLock = 2\n-  };\n-\n-  void NOINLINE LockSlow() {\n-    for (int i = 0;; i++) {\n-      if (i < 10)\n-        proc_yield(10);\n-      else\n-        internal_sched_yield();\n-      u32 cmp = atomic_load(&state_, memory_order_relaxed);\n-      if (cmp == kUnlocked &&\n-          atomic_compare_exchange_weak(&state_, &cmp, kWriteLock,\n-                                       memory_order_acquire))\n-          return;\n-    }\n-  }\n-\n-  void NOINLINE ReadLockSlow() {\n-    for (int i = 0;; i++) {\n-      if (i < 10)\n-        proc_yield(10);\n-      else\n-        internal_sched_yield();\n-      u32 prev = atomic_load(&state_, memory_order_acquire);\n-      if ((prev & kWriteLock) == 0)\n-        return;\n-    }\n-  }\n-\n-  RWMutex(const RWMutex &) = delete;\n-  void operator=(const RWMutex &) = delete;\n-};\n-\n template <typename MutexType>\n class SCOPED_LOCK GenericScopedLock {\n  public:\n@@ -405,10 +389,37 @@ class SCOPED_LOCK GenericScopedReadLock {\n   void operator=(const GenericScopedReadLock &) = delete;\n };\n \n+template <typename MutexType>\n+class SCOPED_LOCK GenericScopedRWLock {\n+ public:\n+  ALWAYS_INLINE explicit GenericScopedRWLock(MutexType *mu, bool write)\n+      ACQUIRE(mu)\n+      : mu_(mu), write_(write) {\n+    if (write_)\n+      mu_->Lock();\n+    else\n+      mu_->ReadLock();\n+  }\n+\n+  ALWAYS_INLINE ~GenericScopedRWLock() RELEASE() {\n+    if (write_)\n+      mu_->Unlock();\n+    else\n+      mu_->ReadUnlock();\n+  }\n+\n+ private:\n+  MutexType *mu_;\n+  bool write_;\n+\n+  GenericScopedRWLock(const GenericScopedRWLock &) = delete;\n+  void operator=(const GenericScopedRWLock &) = delete;\n+};\n+\n typedef GenericScopedLock<StaticSpinMutex> SpinMutexLock;\n-typedef GenericScopedLock<BlockingMutex> BlockingMutexLock;\n-typedef GenericScopedLock<RWMutex> RWMutexLock;\n-typedef GenericScopedReadLock<RWMutex> RWMutexReadLock;\n+typedef GenericScopedLock<Mutex> Lock;\n+typedef GenericScopedReadLock<Mutex> ReadLock;\n+typedef GenericScopedRWLock<Mutex> RWLock;\n \n }  // namespace __sanitizer\n "}, {"sha": "3153de34e5a3f6c793915e6790dfba399221915d", "filename": "libsanitizer/sanitizer_common/sanitizer_platform.h", "status": "modified", "additions": 20, "deletions": 5, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -281,11 +281,12 @@\n // mandated by the upstream linux community for all new ports. Other ports\n // may still use legacy syscalls.\n #ifndef SANITIZER_USES_CANONICAL_LINUX_SYSCALLS\n-# if (defined(__aarch64__) || defined(__riscv)) && SANITIZER_LINUX\n-# define SANITIZER_USES_CANONICAL_LINUX_SYSCALLS 1\n-# else\n-# define SANITIZER_USES_CANONICAL_LINUX_SYSCALLS 0\n-# endif\n+#  if (defined(__aarch64__) || defined(__riscv) || defined(__hexagon__)) && \\\n+      SANITIZER_LINUX\n+#    define SANITIZER_USES_CANONICAL_LINUX_SYSCALLS 1\n+#  else\n+#    define SANITIZER_USES_CANONICAL_LINUX_SYSCALLS 0\n+#  endif\n #endif\n \n // udi16 syscalls can only be used when the following conditions are\n@@ -377,4 +378,18 @@\n #define SANITIZER_SUPPORTS_INIT_FOR_DLOPEN 0\n #endif\n \n+// SANITIZER_SUPPORTS_THREADLOCAL\n+// 1 - THREADLOCAL macro is supported by target\n+// 0 - THREADLOCAL macro is not supported by target\n+#ifndef __has_feature\n+// TODO: Support other compilers here\n+#  define SANITIZER_SUPPORTS_THREADLOCAL 1\n+#else\n+#  if __has_feature(tls)\n+#    define SANITIZER_SUPPORTS_THREADLOCAL 1\n+#  else\n+#    define SANITIZER_SUPPORTS_THREADLOCAL 0\n+#  endif\n+#endif\n+\n #endif // SANITIZER_PLATFORM_H"}, {"sha": "02c51d9fb0d24d7d91fd8935536a6f3c908ecde3", "filename": "libsanitizer/sanitizer_common/sanitizer_platform_interceptors.h", "status": "modified", "additions": 17, "deletions": 10, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_interceptors.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_interceptors.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_interceptors.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -229,7 +229,8 @@\n   (SI_MAC || SI_LINUX_NOT_ANDROID || SI_SOLARIS)\n #define SANITIZER_INTERCEPT_CLOCK_GETTIME \\\n   (SI_FREEBSD || SI_NETBSD || SI_LINUX || SI_SOLARIS)\n-#define SANITIZER_INTERCEPT_CLOCK_GETCPUCLOCKID SI_LINUX\n+#define SANITIZER_INTERCEPT_CLOCK_GETCPUCLOCKID \\\n+  (SI_LINUX || SI_FREEBSD || SI_NETBSD)\n #define SANITIZER_INTERCEPT_GETITIMER SI_POSIX\n #define SANITIZER_INTERCEPT_TIME SI_POSIX\n #define SANITIZER_INTERCEPT_GLOB (SI_GLIBC || SI_SOLARIS)\n@@ -251,7 +252,8 @@\n #define SANITIZER_INTERCEPT_GETHOSTENT_R (SI_FREEBSD || SI_GLIBC || SI_SOLARIS)\n #define SANITIZER_INTERCEPT_GETSOCKOPT SI_POSIX\n #define SANITIZER_INTERCEPT_ACCEPT SI_POSIX\n-#define SANITIZER_INTERCEPT_ACCEPT4 (SI_LINUX_NOT_ANDROID || SI_NETBSD)\n+#define SANITIZER_INTERCEPT_ACCEPT4 \\\n+  (SI_LINUX_NOT_ANDROID || SI_NETBSD || SI_FREEBSD)\n #define SANITIZER_INTERCEPT_PACCEPT SI_NETBSD\n #define SANITIZER_INTERCEPT_MODF SI_POSIX\n #define SANITIZER_INTERCEPT_RECVMSG SI_POSIX\n@@ -309,7 +311,7 @@\n #define SANITIZER_INTERCEPT_PPOLL SI_LINUX_NOT_ANDROID || SI_SOLARIS\n #define SANITIZER_INTERCEPT_WORDEXP                                          \\\n   (SI_FREEBSD || SI_NETBSD || (SI_MAC && !SI_IOS) || SI_LINUX_NOT_ANDROID || \\\n-   SI_SOLARIS)  // NOLINT\n+   SI_SOLARIS)\n #define SANITIZER_INTERCEPT_SIGWAIT SI_POSIX\n #define SANITIZER_INTERCEPT_SIGWAITINFO SI_LINUX_NOT_ANDROID || SI_SOLARIS\n #define SANITIZER_INTERCEPT_SIGTIMEDWAIT SI_LINUX_NOT_ANDROID || SI_SOLARIS\n@@ -337,7 +339,7 @@\n #define SANITIZER_INTERCEPT_ETHER_R (SI_FREEBSD || SI_LINUX_NOT_ANDROID)\n #define SANITIZER_INTERCEPT_SHMCTL                                       \\\n   (((SI_FREEBSD || SI_LINUX_NOT_ANDROID) && SANITIZER_WORDSIZE == 64) || \\\n-   SI_NETBSD || SI_SOLARIS)  // NOLINT\n+   SI_NETBSD || SI_SOLARIS)\n #define SANITIZER_INTERCEPT_RANDOM_R SI_GLIBC\n #define SANITIZER_INTERCEPT_PTHREAD_ATTR_GET SI_POSIX\n #define SANITIZER_INTERCEPT_PTHREAD_ATTR_GETINHERITSCHED \\\n@@ -445,7 +447,8 @@\n #define SANITIZER_INTERCEPT_SEM \\\n   (SI_LINUX || SI_FREEBSD || SI_NETBSD || SI_SOLARIS)\n #define SANITIZER_INTERCEPT_PTHREAD_SETCANCEL SI_POSIX\n-#define SANITIZER_INTERCEPT_MINCORE (SI_LINUX || SI_NETBSD || SI_SOLARIS)\n+#define SANITIZER_INTERCEPT_MINCORE \\\n+  (SI_LINUX || SI_NETBSD || SI_FREEBSD || SI_SOLARIS)\n #define SANITIZER_INTERCEPT_PROCESS_VM_READV SI_LINUX\n #define SANITIZER_INTERCEPT_CTERMID \\\n   (SI_LINUX || SI_MAC || SI_FREEBSD || SI_NETBSD || SI_SOLARIS)\n@@ -496,7 +499,8 @@\n #define SANITIZER_INTERCEPT_GID_FROM_GROUP SI_NETBSD\n #define SANITIZER_INTERCEPT_ACCESS (SI_NETBSD || SI_FREEBSD)\n #define SANITIZER_INTERCEPT_FACCESSAT (SI_NETBSD || SI_FREEBSD)\n-#define SANITIZER_INTERCEPT_GETGROUPLIST SI_NETBSD\n+#define SANITIZER_INTERCEPT_GETGROUPLIST \\\n+  (SI_NETBSD || SI_FREEBSD || SI_LINUX)\n #define SANITIZER_INTERCEPT_STRLCPY \\\n   (SI_NETBSD || SI_FREEBSD || SI_MAC || SI_ANDROID)\n \n@@ -517,10 +521,11 @@\n #define SANITIZER_INTERCEPT_DEVNAME_R (SI_NETBSD || SI_FREEBSD)\n #define SANITIZER_INTERCEPT_FGETLN (SI_NETBSD || SI_FREEBSD)\n #define SANITIZER_INTERCEPT_STRMODE (SI_NETBSD || SI_FREEBSD)\n-#define SANITIZER_INTERCEPT_TTYENT SI_NETBSD\n-#define SANITIZER_INTERCEPT_PROTOENT (SI_NETBSD || SI_LINUX)\n+#define SANITIZER_INTERCEPT_TTYENT (SI_NETBSD || SI_FREEBSD)\n+#define SANITIZER_INTERCEPT_TTYENTPATH SI_NETBSD\n+#define SANITIZER_INTERCEPT_PROTOENT (SI_LINUX || SI_NETBSD || SI_FREEBSD)\n #define SANITIZER_INTERCEPT_PROTOENT_R SI_GLIBC\n-#define SANITIZER_INTERCEPT_NETENT SI_NETBSD\n+#define SANITIZER_INTERCEPT_NETENT (SI_LINUX || SI_NETBSD || SI_FREEBSD)\n #define SANITIZER_INTERCEPT_SETVBUF \\\n   (SI_NETBSD || SI_FREEBSD || SI_LINUX || SI_MAC)\n #define SANITIZER_INTERCEPT_GETMNTINFO (SI_NETBSD || SI_FREEBSD || SI_MAC)\n@@ -536,7 +541,7 @@\n #define SANITIZER_INTERCEPT_MODCTL SI_NETBSD\n #define SANITIZER_INTERCEPT_CAPSICUM SI_FREEBSD\n #define SANITIZER_INTERCEPT_STRTONUM (SI_NETBSD || SI_FREEBSD)\n-#define SANITIZER_INTERCEPT_FPARSELN SI_NETBSD\n+#define SANITIZER_INTERCEPT_FPARSELN (SI_NETBSD || SI_FREEBSD)\n #define SANITIZER_INTERCEPT_STATVFS1 SI_NETBSD\n #define SANITIZER_INTERCEPT_STRTOI SI_NETBSD\n #define SANITIZER_INTERCEPT_CAPSICUM SI_FREEBSD\n@@ -571,6 +576,8 @@\n #define SANITIZER_INTERCEPT_QSORT \\\n   (SI_POSIX && !SI_IOSSIM && !SI_WATCHOS && !SI_TVOS && !SI_ANDROID)\n #define SANITIZER_INTERCEPT_QSORT_R SI_GLIBC\n+#define SANITIZER_INTERCEPT_BSEARCH \\\n+  (SI_POSIX && !SI_IOSSIM && !SI_WATCHOS && !SI_TVOS && !SI_ANDROID)\n // sigaltstack on i386 macOS cannot be intercepted due to setjmp()\n // calling it and assuming that it does not clobber registers.\n #define SANITIZER_INTERCEPT_SIGALTSTACK \\"}, {"sha": "bfe3eea464d64b6988e209f03a64851e67e86522", "filename": "libsanitizer/sanitizer_common/sanitizer_platform_limits_freebsd.cpp", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_freebsd.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_freebsd.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_freebsd.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -74,6 +74,7 @@\n #include <term.h>\n #include <termios.h>\n #include <time.h>\n+#include <ttyent.h>\n #include <utime.h>\n #include <utmpx.h>\n #include <vis.h>\n@@ -170,9 +171,12 @@ uptr __sanitizer_in_addr_sz(int af) {\n unsigned struct_ElfW_Phdr_sz = sizeof(Elf_Phdr);\n int glob_nomatch = GLOB_NOMATCH;\n int glob_altdirfunc = GLOB_ALTDIRFUNC;\n+const int wordexp_wrde_dooffs = WRDE_DOOFFS;\n \n unsigned path_max = PATH_MAX;\n \n+int struct_ttyent_sz = sizeof(struct ttyent);\n+\n // ioctl arguments\n unsigned struct_ifreq_sz = sizeof(struct ifreq);\n unsigned struct_termios_sz = sizeof(struct termios);"}, {"sha": "89022ca6422c94804a75b792fdd0907aa11be6ac", "filename": "libsanitizer/sanitizer_common/sanitizer_platform_limits_freebsd.h", "status": "modified", "additions": 95, "deletions": 69, "changes": 164, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_freebsd.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_freebsd.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_freebsd.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -16,26 +16,26 @@\n \n #if SANITIZER_FREEBSD\n \n-#include \"sanitizer_internal_defs.h\"\n-#include \"sanitizer_platform.h\"\n-#include \"sanitizer_platform_limits_posix.h\"\n+#  include \"sanitizer_internal_defs.h\"\n+#  include \"sanitizer_platform.h\"\n+#  include \"sanitizer_platform_limits_posix.h\"\n \n // Get sys/_types.h, because that tells us whether 64-bit inodes are\n // used in struct dirent below.\n-#include <sys/_types.h>\n+#  include <sys/_types.h>\n \n namespace __sanitizer {\n void *__sanitizer_get_link_map_by_dlopen_handle(void *handle);\n-#define GET_LINK_MAP_BY_DLOPEN_HANDLE(handle) \\\n-  (link_map *)__sanitizer_get_link_map_by_dlopen_handle(handle)\n+#  define GET_LINK_MAP_BY_DLOPEN_HANDLE(handle) \\\n+    (link_map *)__sanitizer_get_link_map_by_dlopen_handle(handle)\n \n extern unsigned struct_utsname_sz;\n extern unsigned struct_stat_sz;\n-#if defined(__powerpc64__)\n+#  if defined(__powerpc64__)\n const unsigned struct___old_kernel_stat_sz = 0;\n-#else\n+#  else\n const unsigned struct___old_kernel_stat_sz = 32;\n-#endif\n+#  endif\n extern unsigned struct_rusage_sz;\n extern unsigned siginfo_t_sz;\n extern unsigned struct_itimerval_sz;\n@@ -114,11 +114,24 @@ struct __sanitizer_ipc_perm {\n   long key;\n };\n \n-#if !defined(__i386__)\n+struct __sanitizer_protoent {\n+  char *p_name;\n+  char **p_aliases;\n+  int p_proto;\n+};\n+\n+struct __sanitizer_netent {\n+  char *n_name;\n+  char **n_aliases;\n+  int n_addrtype;\n+  u32 n_net;\n+};\n+\n+#  if !defined(__i386__)\n typedef long long __sanitizer_time_t;\n-#else\n+#  else\n typedef long __sanitizer_time_t;\n-#endif\n+#  endif\n \n struct __sanitizer_shmid_ds {\n   __sanitizer_ipc_perm shm_perm;\n@@ -147,7 +160,7 @@ struct __sanitizer_ifaddrs {\n   unsigned int ifa_flags;\n   void *ifa_addr;     // (struct sockaddr *)\n   void *ifa_netmask;  // (struct sockaddr *)\n-#undef ifa_dstaddr\n+#  undef ifa_dstaddr\n   void *ifa_dstaddr;  // (struct sockaddr *)\n   void *ifa_data;\n };\n@@ -229,12 +242,12 @@ struct __sanitizer_cmsghdr {\n };\n \n struct __sanitizer_dirent {\n-#if defined(__INO64)\n+#  if defined(__INO64)\n   unsigned long long d_fileno;\n   unsigned long long d_off;\n-#else\n+#  else\n   unsigned int d_fileno;\n-#endif\n+#  endif\n   unsigned short d_reclen;\n   // more fields that we don't care about\n };\n@@ -243,23 +256,23 @@ struct __sanitizer_dirent {\n typedef int __sanitizer_clock_t;\n typedef int __sanitizer_clockid_t;\n \n-#if defined(_LP64) || defined(__x86_64__) || defined(__powerpc__) || \\\n-    defined(__mips__)\n+#  if defined(_LP64) || defined(__x86_64__) || defined(__powerpc__) || \\\n+      defined(__mips__)\n typedef unsigned __sanitizer___kernel_uid_t;\n typedef unsigned __sanitizer___kernel_gid_t;\n-#else\n+#  else\n typedef unsigned short __sanitizer___kernel_uid_t;\n typedef unsigned short __sanitizer___kernel_gid_t;\n-#endif\n+#  endif\n typedef long long __sanitizer___kernel_off_t;\n \n-#if defined(__powerpc__) || defined(__mips__)\n+#  if defined(__powerpc__) || defined(__mips__)\n typedef unsigned int __sanitizer___kernel_old_uid_t;\n typedef unsigned int __sanitizer___kernel_old_gid_t;\n-#else\n+#  else\n typedef unsigned short __sanitizer___kernel_old_uid_t;\n typedef unsigned short __sanitizer___kernel_old_gid_t;\n-#endif\n+#  endif\n \n typedef long long __sanitizer___kernel_loff_t;\n typedef struct {\n@@ -366,9 +379,12 @@ struct __sanitizer_glob_t {\n \n extern int glob_nomatch;\n extern int glob_altdirfunc;\n+extern const int wordexp_wrde_dooffs;\n \n extern unsigned path_max;\n \n+extern int struct_ttyent_sz;\n+\n struct __sanitizer_wordexp_t {\n   uptr we_wordc;\n   char **we_wordv;\n@@ -398,39 +414,49 @@ struct __sanitizer_ifconf {\n   } ifc_ifcu;\n };\n \n-#define IOC_NRBITS 8\n-#define IOC_TYPEBITS 8\n-#if defined(__powerpc__) || defined(__powerpc64__) || defined(__mips__)\n-#define IOC_SIZEBITS 13\n-#define IOC_DIRBITS 3\n-#define IOC_NONE 1U\n-#define IOC_WRITE 4U\n-#define IOC_READ 2U\n-#else\n-#define IOC_SIZEBITS 14\n-#define IOC_DIRBITS 2\n-#define IOC_NONE 0U\n-#define IOC_WRITE 1U\n-#define IOC_READ 2U\n-#endif\n-#define IOC_NRMASK ((1 << IOC_NRBITS) - 1)\n-#define IOC_TYPEMASK ((1 << IOC_TYPEBITS) - 1)\n-#define IOC_SIZEMASK ((1 << IOC_SIZEBITS) - 1)\n-#if defined(IOC_DIRMASK)\n-#undef IOC_DIRMASK\n-#endif\n-#define IOC_DIRMASK ((1 << IOC_DIRBITS) - 1)\n-#define IOC_NRSHIFT 0\n-#define IOC_TYPESHIFT (IOC_NRSHIFT + IOC_NRBITS)\n-#define IOC_SIZESHIFT (IOC_TYPESHIFT + IOC_TYPEBITS)\n-#define IOC_DIRSHIFT (IOC_SIZESHIFT + IOC_SIZEBITS)\n-#define EVIOC_EV_MAX 0x1f\n-#define EVIOC_ABS_MAX 0x3f\n-\n-#define IOC_DIR(nr) (((nr) >> IOC_DIRSHIFT) & IOC_DIRMASK)\n-#define IOC_TYPE(nr) (((nr) >> IOC_TYPESHIFT) & IOC_TYPEMASK)\n-#define IOC_NR(nr) (((nr) >> IOC_NRSHIFT) & IOC_NRMASK)\n-#define IOC_SIZE(nr) (((nr) >> IOC_SIZESHIFT) & IOC_SIZEMASK)\n+struct __sanitizer__ttyent {\n+  char *ty_name;\n+  char *ty_getty;\n+  char *ty_type;\n+  int ty_status;\n+  char *ty_window;\n+  char *ty_comment;\n+  char *ty_group;\n+};\n+\n+#  define IOC_NRBITS 8\n+#  define IOC_TYPEBITS 8\n+#  if defined(__powerpc__) || defined(__powerpc64__) || defined(__mips__)\n+#    define IOC_SIZEBITS 13\n+#    define IOC_DIRBITS 3\n+#    define IOC_NONE 1U\n+#    define IOC_WRITE 4U\n+#    define IOC_READ 2U\n+#  else\n+#    define IOC_SIZEBITS 14\n+#    define IOC_DIRBITS 2\n+#    define IOC_NONE 0U\n+#    define IOC_WRITE 1U\n+#    define IOC_READ 2U\n+#  endif\n+#  define IOC_NRMASK ((1 << IOC_NRBITS) - 1)\n+#  define IOC_TYPEMASK ((1 << IOC_TYPEBITS) - 1)\n+#  define IOC_SIZEMASK ((1 << IOC_SIZEBITS) - 1)\n+#  if defined(IOC_DIRMASK)\n+#    undef IOC_DIRMASK\n+#  endif\n+#  define IOC_DIRMASK ((1 << IOC_DIRBITS) - 1)\n+#  define IOC_NRSHIFT 0\n+#  define IOC_TYPESHIFT (IOC_NRSHIFT + IOC_NRBITS)\n+#  define IOC_SIZESHIFT (IOC_TYPESHIFT + IOC_TYPEBITS)\n+#  define IOC_DIRSHIFT (IOC_SIZESHIFT + IOC_SIZEBITS)\n+#  define EVIOC_EV_MAX 0x1f\n+#  define EVIOC_ABS_MAX 0x3f\n+\n+#  define IOC_DIR(nr) (((nr) >> IOC_DIRSHIFT) & IOC_DIRMASK)\n+#  define IOC_TYPE(nr) (((nr) >> IOC_TYPESHIFT) & IOC_TYPEMASK)\n+#  define IOC_NR(nr) (((nr) >> IOC_NRSHIFT) & IOC_NRMASK)\n+#  define IOC_SIZE(nr) (((nr) >> IOC_SIZESHIFT) & IOC_SIZEMASK)\n \n extern unsigned struct_ifreq_sz;\n extern unsigned struct_termios_sz;\n@@ -632,24 +658,24 @@ extern unsigned struct_fstab_sz;\n extern unsigned struct_StringList_sz;\n }  // namespace __sanitizer\n \n-#define CHECK_TYPE_SIZE(TYPE) \\\n-  COMPILER_CHECK(sizeof(__sanitizer_##TYPE) == sizeof(TYPE))\n+#  define CHECK_TYPE_SIZE(TYPE) \\\n+    COMPILER_CHECK(sizeof(__sanitizer_##TYPE) == sizeof(TYPE))\n \n-#define CHECK_SIZE_AND_OFFSET(CLASS, MEMBER)                      \\\n-  COMPILER_CHECK(sizeof(((__sanitizer_##CLASS *)NULL)->MEMBER) == \\\n-                 sizeof(((CLASS *)NULL)->MEMBER));                \\\n-  COMPILER_CHECK(offsetof(__sanitizer_##CLASS, MEMBER) ==         \\\n-                 offsetof(CLASS, MEMBER))\n+#  define CHECK_SIZE_AND_OFFSET(CLASS, MEMBER)                      \\\n+    COMPILER_CHECK(sizeof(((__sanitizer_##CLASS *)NULL)->MEMBER) == \\\n+                   sizeof(((CLASS *)NULL)->MEMBER));                \\\n+    COMPILER_CHECK(offsetof(__sanitizer_##CLASS, MEMBER) ==         \\\n+                   offsetof(CLASS, MEMBER))\n \n // For sigaction, which is a function and struct at the same time,\n // and thus requires explicit \"struct\" in sizeof() expression.\n-#define CHECK_STRUCT_SIZE_AND_OFFSET(CLASS, MEMBER)                      \\\n-  COMPILER_CHECK(sizeof(((struct __sanitizer_##CLASS *)NULL)->MEMBER) == \\\n-                 sizeof(((struct CLASS *)NULL)->MEMBER));                \\\n-  COMPILER_CHECK(offsetof(struct __sanitizer_##CLASS, MEMBER) ==         \\\n-                 offsetof(struct CLASS, MEMBER))\n+#  define CHECK_STRUCT_SIZE_AND_OFFSET(CLASS, MEMBER)                      \\\n+    COMPILER_CHECK(sizeof(((struct __sanitizer_##CLASS *)NULL)->MEMBER) == \\\n+                   sizeof(((struct CLASS *)NULL)->MEMBER));                \\\n+    COMPILER_CHECK(offsetof(struct __sanitizer_##CLASS, MEMBER) ==         \\\n+                   offsetof(struct CLASS, MEMBER))\n \n-#define SIGACTION_SYMNAME sigaction\n+#  define SIGACTION_SYMNAME sigaction\n \n #endif\n "}, {"sha": "9d577570ea1e2e219b4a08c64f450794d6a145d7", "filename": "libsanitizer/sanitizer_common/sanitizer_platform_limits_linux.cpp", "status": "modified", "additions": 29, "deletions": 32, "changes": 61, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_linux.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_linux.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_linux.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -26,37 +26,34 @@\n \n // With old kernels (and even new kernels on powerpc) asm/stat.h uses types that\n // are not defined anywhere in userspace headers. Fake them. This seems to work\n-// fine with newer headers, too.  Beware that with <sys/stat.h>, struct stat\n-// takes the form of struct stat64 on 32-bit platforms if _FILE_OFFSET_BITS=64.\n-// Also, for some platforms (e.g. mips) there are additional members in the\n-// <sys/stat.h> struct stat:s.\n+// fine with newer headers, too.\n #include <linux/posix_types.h>\n-#if defined(__x86_64__)\n-#include <sys/stat.h>\n-#else\n-#define ino_t __kernel_ino_t\n-#define mode_t __kernel_mode_t\n-#define nlink_t __kernel_nlink_t\n-#define uid_t __kernel_uid_t\n-#define gid_t __kernel_gid_t\n-#define off_t __kernel_off_t\n-#define time_t __kernel_time_t\n+#  if defined(__x86_64__) || defined(__mips__) || defined(__hexagon__)\n+#    include <sys/stat.h>\n+#  else\n+#    define ino_t __kernel_ino_t\n+#    define mode_t __kernel_mode_t\n+#    define nlink_t __kernel_nlink_t\n+#    define uid_t __kernel_uid_t\n+#    define gid_t __kernel_gid_t\n+#    define off_t __kernel_off_t\n+#    define time_t __kernel_time_t\n // This header seems to contain the definitions of _kernel_ stat* structs.\n-#include <asm/stat.h>\n-#undef ino_t\n-#undef mode_t\n-#undef nlink_t\n-#undef uid_t\n-#undef gid_t\n-#undef off_t\n-#endif\n-\n-#include <linux/aio_abi.h>\n-\n-#if !SANITIZER_ANDROID\n-#include <sys/statfs.h>\n-#include <linux/perf_event.h>\n-#endif\n+#    include <asm/stat.h>\n+#    undef ino_t\n+#    undef mode_t\n+#    undef nlink_t\n+#    undef uid_t\n+#    undef gid_t\n+#    undef off_t\n+#  endif\n+\n+#  include <linux/aio_abi.h>\n+\n+#  if !SANITIZER_ANDROID\n+#    include <sys/statfs.h>\n+#    include <linux/perf_event.h>\n+#  endif\n \n using namespace __sanitizer;\n \n@@ -66,9 +63,9 @@ namespace __sanitizer {\n #endif\n }  // namespace __sanitizer\n \n-#if !defined(__powerpc64__) && !defined(__x86_64__) && !defined(__aarch64__)\\\n-                            && !defined(__mips__) && !defined(__s390__)\\\n-                            && !defined(__sparc__) && !defined(__riscv)\n+#  if !defined(__powerpc64__) && !defined(__x86_64__) &&                   \\\n+      !defined(__aarch64__) && !defined(__mips__) && !defined(__s390__) && \\\n+      !defined(__sparc__) && !defined(__riscv) && !defined(__hexagon__)\n COMPILER_CHECK(struct___old_kernel_stat_sz == sizeof(struct __old_kernel_stat));\n #endif\n "}, {"sha": "531e07f2d4c57f1dc8e61d2f8116b6a1b8e5c806", "filename": "libsanitizer/sanitizer_common/sanitizer_platform_limits_netbsd.cpp", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_netbsd.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_netbsd.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_netbsd.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -666,6 +666,7 @@ unsigned struct_ElfW_Phdr_sz = sizeof(Elf_Phdr);\n \n int glob_nomatch = GLOB_NOMATCH;\n int glob_altdirfunc = GLOB_ALTDIRFUNC;\n+const int wordexp_wrde_dooffs = WRDE_DOOFFS;\n \n unsigned path_max = PATH_MAX;\n "}, {"sha": "9407803fc9c399d9bf42637796ce85aa2abb2a43", "filename": "libsanitizer/sanitizer_common/sanitizer_platform_limits_netbsd.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_netbsd.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_netbsd.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_netbsd.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -394,6 +394,7 @@ struct __sanitizer_glob_t {\n \n extern int glob_nomatch;\n extern int glob_altdirfunc;\n+extern const int wordexp_wrde_dooffs;\n \n extern unsigned path_max;\n "}, {"sha": "a1c452855ae77b6bed99fb35d55b56e991606a13", "filename": "libsanitizer/sanitizer_common/sanitizer_platform_limits_posix.cpp", "status": "modified", "additions": 15, "deletions": 10, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_posix.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_posix.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_posix.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -91,10 +91,10 @@\n #if SANITIZER_LINUX\n # include <utime.h>\n # include <sys/ptrace.h>\n-#if defined(__mips64) || defined(__aarch64__) || defined(__arm__) || \\\n-    SANITIZER_RISCV64\n-#  include <asm/ptrace.h>\n-#  ifdef __arm__\n+#    if defined(__mips64) || defined(__aarch64__) || defined(__arm__) || \\\n+        defined(__hexagon__) || SANITIZER_RISCV64\n+#      include <asm/ptrace.h>\n+#      ifdef __arm__\n typedef struct user_fpregs elf_fpregset_t;\n #   define ARM_VFPREGS_SIZE_ASAN (32 * 8 /*fpregs*/ + 4 /*fpscr*/)\n #   if !defined(ARM_VFPREGS_SIZE)\n@@ -242,12 +242,13 @@ namespace __sanitizer {\n     defined(__powerpc64__) || defined(__arch64__) || defined(__sparcv9) || \\\n     defined(__x86_64__) || SANITIZER_RISCV64\n #define SIZEOF_STRUCT_USTAT 32\n-#elif defined(__arm__) || defined(__i386__) || defined(__mips__) \\\n-  || defined(__powerpc__) || defined(__s390__) || defined(__sparc__)\n-#define SIZEOF_STRUCT_USTAT 20\n-#else\n-#error Unknown size of struct ustat\n-#endif\n+#    elif defined(__arm__) || defined(__i386__) || defined(__mips__) ||    \\\n+        defined(__powerpc__) || defined(__s390__) || defined(__sparc__) || \\\n+        defined(__hexagon__)\n+#      define SIZEOF_STRUCT_USTAT 20\n+#    else\n+#      error Unknown size of struct ustat\n+#    endif\n   unsigned struct_ustat_sz = SIZEOF_STRUCT_USTAT;\n   unsigned struct_rlimit64_sz = sizeof(struct rlimit64);\n   unsigned struct_statvfs64_sz = sizeof(struct statvfs64);\n@@ -312,6 +313,10 @@ unsigned struct_ElfW_Phdr_sz = sizeof(Elf_Phdr);\n   int glob_altdirfunc = GLOB_ALTDIRFUNC;\n #endif\n \n+#  if !SANITIZER_ANDROID\n+  const int wordexp_wrde_dooffs = WRDE_DOOFFS;\n+#  endif  // !SANITIZER_ANDROID\n+\n #if SANITIZER_LINUX && !SANITIZER_ANDROID &&                               \\\n     (defined(__i386) || defined(__x86_64) || defined(__mips64) ||          \\\n      defined(__powerpc64__) || defined(__aarch64__) || defined(__arm__) || \\"}, {"sha": "d69b344dd613d6e2f25c39d839cbf5a899ddf81d", "filename": "libsanitizer/sanitizer_common/sanitizer_platform_limits_posix.h", "status": "modified", "additions": 23, "deletions": 9, "changes": 32, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_posix.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_posix.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_posix.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -83,7 +83,7 @@ const unsigned struct_kernel_stat64_sz = 104;\n #elif defined(__mips__)\n const unsigned struct_kernel_stat_sz = SANITIZER_ANDROID\n                                            ? FIRST_32_SECOND_64(104, 128)\n-                                           : FIRST_32_SECOND_64(144, 216);\n+                                           : FIRST_32_SECOND_64(160, 216);\n const unsigned struct_kernel_stat64_sz = 104;\n #elif defined(__s390__) && !defined(__s390x__)\n const unsigned struct_kernel_stat_sz = 64;\n@@ -102,7 +102,10 @@ const unsigned struct_kernel_stat64_sz = 104;\n #elif SANITIZER_RISCV64\n const unsigned struct_kernel_stat_sz = 128;\n const unsigned struct_kernel_stat64_sz = 0;  // RISCV64 does not use stat64\n-#endif\n+#    elif defined(__hexagon__)\n+const unsigned struct_kernel_stat_sz = 128;\n+const unsigned struct_kernel_stat64_sz = 0;\n+#    endif\n struct __sanitizer_perf_event_attr {\n   unsigned type;\n   unsigned size;\n@@ -367,7 +370,7 @@ struct __sanitizer_group {\n   char **gr_mem;\n };\n \n-#if defined(__x86_64__) && !defined(_LP64)\n+#  if (defined(__x86_64__) && !defined(_LP64)) || defined(__hexagon__)\n typedef long long __sanitizer_time_t;\n #else\n typedef long __sanitizer_time_t;\n@@ -475,23 +478,23 @@ struct __sanitizer_dirent {\n   unsigned short d_reclen;\n   // more fields that we don't care about\n };\n-#elif SANITIZER_ANDROID || defined(__x86_64__)\n+#  elif SANITIZER_ANDROID || defined(__x86_64__) || defined(__hexagon__)\n struct __sanitizer_dirent {\n   unsigned long long d_ino;\n   unsigned long long d_off;\n   unsigned short d_reclen;\n   // more fields that we don't care about\n };\n-#else\n+#  else\n struct __sanitizer_dirent {\n   uptr d_ino;\n   uptr d_off;\n   unsigned short d_reclen;\n   // more fields that we don't care about\n };\n-#endif\n+#  endif\n \n-#if SANITIZER_LINUX && !SANITIZER_ANDROID\n+#  if SANITIZER_LINUX && !SANITIZER_ANDROID\n struct __sanitizer_dirent64 {\n   unsigned long long d_ino;\n   unsigned long long d_off;\n@@ -511,8 +514,8 @@ typedef int __sanitizer_clockid_t;\n #endif\n \n #if SANITIZER_LINUX\n-#if defined(_LP64) || defined(__x86_64__) || defined(__powerpc__) || \\\n-    defined(__mips__)\n+#    if defined(_LP64) || defined(__x86_64__) || defined(__powerpc__) || \\\n+        defined(__mips__) || defined(__hexagon__)\n typedef unsigned __sanitizer___kernel_uid_t;\n typedef unsigned __sanitizer___kernel_gid_t;\n #else\n@@ -712,6 +715,13 @@ struct __sanitizer_protoent {\n   int p_proto;\n };\n \n+struct __sanitizer_netent {\n+  char *n_name;\n+  char **n_aliases;\n+  int n_addrtype;\n+  u32 n_net;\n+};\n+\n struct __sanitizer_addrinfo {\n   int ai_flags;\n   int ai_family;\n@@ -773,6 +783,10 @@ extern int glob_altdirfunc;\n \n extern unsigned path_max;\n \n+#  if !SANITIZER_ANDROID\n+extern const int wordexp_wrde_dooffs;\n+#  endif  // !SANITIZER_ANDROID\n+\n struct __sanitizer_wordexp_t {\n   uptr we_wordc;\n   char **we_wordv;"}, {"sha": "a113cb0d34903f1e5dd690453a12dc38c0248ba4", "filename": "libsanitizer/sanitizer_common/sanitizer_platform_limits_solaris.cpp", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_solaris.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_solaris.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_solaris.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -123,6 +123,7 @@ namespace __sanitizer {\n   unsigned struct_ElfW_Phdr_sz = sizeof(ElfW(Phdr));\n \n   int glob_nomatch = GLOB_NOMATCH;\n+  const int wordexp_wrde_dooffs = WRDE_DOOFFS;\n \n   unsigned path_max = PATH_MAX;\n "}, {"sha": "cbab577bcf26c847301c898c9c6523f42c7fd4f0", "filename": "libsanitizer/sanitizer_common/sanitizer_platform_limits_solaris.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_solaris.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_solaris.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_platform_limits_solaris.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -341,6 +341,7 @@ struct __sanitizer_glob_t {\n \n extern int glob_nomatch;\n extern int glob_altdirfunc;\n+extern const int wordexp_wrde_dooffs;\n \n extern unsigned path_max;\n "}, {"sha": "f91e26e74b87ccd070cec3d5cd37d8efe8e2389a", "filename": "libsanitizer/sanitizer_common/sanitizer_posix.h", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_posix.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_posix.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_posix.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -20,10 +20,7 @@\n #include \"sanitizer_platform_limits_posix.h\"\n #include \"sanitizer_platform_limits_solaris.h\"\n \n-#if !SANITIZER_POSIX\n-// Make it hard to accidentally use any of functions declared in this file:\n-#error This file should only be included on POSIX\n-#endif\n+#if SANITIZER_POSIX\n \n namespace __sanitizer {\n \n@@ -126,4 +123,6 @@ void DecorateMapping(uptr addr, uptr size, const char *name);\n \n }  // namespace __sanitizer\n \n+#endif  // SANITIZER_POSIX\n+\n #endif  // SANITIZER_POSIX_H"}, {"sha": "eed02ce4f6aa668a43ecffa592189a8874700674", "filename": "libsanitizer/sanitizer_common/sanitizer_posix_libcdep.cpp", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_posix_libcdep.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_posix_libcdep.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_posix_libcdep.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -151,6 +151,8 @@ int Atexit(void (*function)(void)) {\n #endif\n }\n \n+bool CreateDir(const char *pathname) { return mkdir(pathname, 0755) == 0; }\n+\n bool SupportsColoredOutput(fd_t fd) {\n   return isatty(fd) != 0;\n }"}, {"sha": "79aee8ba628231c960fc15a3b2e06f9997a2dc56", "filename": "libsanitizer/sanitizer_common/sanitizer_printf.cpp", "status": "modified", "additions": 13, "deletions": 24, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_printf.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_printf.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_printf.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -20,10 +20,6 @@\n #include <stdio.h>\n #include <stdarg.h>\n \n-#if defined(__x86_64__)\n-#  include <emmintrin.h>\n-#endif\n-\n #if SANITIZER_WINDOWS && defined(_MSC_VER) && _MSC_VER < 1800 &&               \\\n       !defined(va_copy)\n # define va_copy(dst, src) ((dst) = (src))\n@@ -132,8 +128,8 @@ static int AppendPointer(char **buff, const char *buff_end, u64 ptr_value) {\n int VSNPrintf(char *buff, int buff_length,\n               const char *format, va_list args) {\n   static const char *kPrintfFormatsHelp =\n-      \"Supported Printf formats: %([0-9]*)?(z|ll)?{d,u,x,X,V}; %p; \"\n-      \"%[-]([0-9]*)?(\\\\.\\\\*)?s; %c\\n\";\n+      \"Supported Printf formats: %([0-9]*)?(z|l|ll)?{d,u,x,X}; %p; \"\n+      \"%[-]([0-9]*)?(\\\\.\\\\*)?s; %c\\nProvided format: \";\n   RAW_CHECK(format);\n   RAW_CHECK(buff_length > 0);\n   const char *buff_end = &buff[buff_length - 1];\n@@ -164,16 +160,19 @@ int VSNPrintf(char *buff, int buff_length,\n     }\n     bool have_z = (*cur == 'z');\n     cur += have_z;\n-    bool have_ll = !have_z && (cur[0] == 'l' && cur[1] == 'l');\n+    bool have_l = cur[0] == 'l' && cur[1] != 'l';\n+    cur += have_l;\n+    bool have_ll = cur[0] == 'l' && cur[1] == 'l';\n     cur += have_ll * 2;\n-    const bool have_length = have_z || have_ll;\n+    const bool have_length = have_z || have_l || have_ll;\n     const bool have_flags = have_width || have_length;\n     // At the moment only %s supports precision and left-justification.\n     CHECK(!((precision >= 0 || left_justified) && *cur != 's'));\n     switch (*cur) {\n       case 'd': {\n         s64 dval = have_ll  ? va_arg(args, s64)\n                    : have_z ? va_arg(args, sptr)\n+                   : have_l ? va_arg(args, long)\n                             : va_arg(args, int);\n         result += AppendSignedDecimal(&buff, buff_end, dval, width,\n                                       pad_with_zero);\n@@ -184,44 +183,38 @@ int VSNPrintf(char *buff, int buff_length,\n       case 'X': {\n         u64 uval = have_ll  ? va_arg(args, u64)\n                    : have_z ? va_arg(args, uptr)\n+                   : have_l ? va_arg(args, unsigned long)\n                             : va_arg(args, unsigned);\n         bool uppercase = (*cur == 'X');\n         result += AppendUnsigned(&buff, buff_end, uval, (*cur == 'u') ? 10 : 16,\n                                  width, pad_with_zero, uppercase);\n         break;\n       }\n-      case 'V': {\n-        for (uptr i = 0; i < 16; i++) {\n-          unsigned x = va_arg(args, unsigned);\n-          result += AppendUnsigned(&buff, buff_end, x, 16, 2, true, false);\n-        }\n-        break;\n-      }\n       case 'p': {\n-        RAW_CHECK_MSG(!have_flags, kPrintfFormatsHelp);\n+        RAW_CHECK(!have_flags, kPrintfFormatsHelp, format);\n         result += AppendPointer(&buff, buff_end, va_arg(args, uptr));\n         break;\n       }\n       case 's': {\n-        RAW_CHECK_MSG(!have_length, kPrintfFormatsHelp);\n+        RAW_CHECK(!have_length, kPrintfFormatsHelp, format);\n         // Only left-justified width is supported.\n         CHECK(!have_width || left_justified);\n         result += AppendString(&buff, buff_end, left_justified ? -width : width,\n                                precision, va_arg(args, char*));\n         break;\n       }\n       case 'c': {\n-        RAW_CHECK_MSG(!have_flags, kPrintfFormatsHelp);\n+        RAW_CHECK(!have_flags, kPrintfFormatsHelp, format);\n         result += AppendChar(&buff, buff_end, va_arg(args, int));\n         break;\n       }\n       case '%' : {\n-        RAW_CHECK_MSG(!have_flags, kPrintfFormatsHelp);\n+        RAW_CHECK(!have_flags, kPrintfFormatsHelp, format);\n         result += AppendChar(&buff, buff_end, '%');\n         break;\n       }\n       default: {\n-        RAW_CHECK_MSG(false, kPrintfFormatsHelp);\n+        RAW_CHECK(false, kPrintfFormatsHelp, format);\n       }\n     }\n   }\n@@ -317,7 +310,6 @@ static void NOINLINE SharedPrintfCode(bool append_pid, const char *format,\n                            format, args);\n }\n \n-FORMAT(1, 2)\n void Printf(const char *format, ...) {\n   va_list args;\n   va_start(args, format);\n@@ -326,7 +318,6 @@ void Printf(const char *format, ...) {\n }\n \n // Like Printf, but prints the current PID before the output string.\n-FORMAT(1, 2)\n void Report(const char *format, ...) {\n   va_list args;\n   va_start(args, format);\n@@ -338,7 +329,6 @@ void Report(const char *format, ...) {\n // Returns the number of symbols that should have been written to buffer\n // (not including trailing '\\0'). Thus, the string is truncated\n // iff return value is not less than \"length\".\n-FORMAT(3, 4)\n int internal_snprintf(char *buffer, uptr length, const char *format, ...) {\n   va_list args;\n   va_start(args, format);\n@@ -347,7 +337,6 @@ int internal_snprintf(char *buffer, uptr length, const char *format, ...) {\n   return needed_length;\n }\n \n-FORMAT(2, 3)\n void InternalScopedString::append(const char *format, ...) {\n   uptr prev_len = length();\n "}, {"sha": "475e577d9982e8104addcf241b24a92e1821f29a", "filename": "libsanitizer/sanitizer_common/sanitizer_signal_interceptors.inc", "status": "modified", "additions": 10, "deletions": 2, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_signal_interceptors.inc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_signal_interceptors.inc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_signal_interceptors.inc?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -29,8 +29,16 @@ using namespace __sanitizer;\n #endif\n \n #ifndef SIGNAL_INTERCEPTOR_SIGACTION_IMPL\n-#define SIGNAL_INTERCEPTOR_SIGACTION_IMPL(signum, act, oldact) \\\n-  { return REAL(sigaction_symname)(signum, act, oldact); }\n+#  define SIGNAL_INTERCEPTOR_SIGACTION_IMPL(signum, act, oldact)              \\\n+    {                                                                         \\\n+      if (!REAL(sigaction_symname)) {                                         \\\n+        Printf(                                                               \\\n+            \"Warning: REAL(sigaction_symname) == nullptr. This may happen \"   \\\n+            \"if you link with ubsan statically. Sigaction will not work.\\n\"); \\\n+        return -1;                                                            \\\n+      }                                                                       \\\n+      return REAL(sigaction_symname)(signum, act, oldact);                    \\\n+    }\n #endif\n \n #if SANITIZER_INTERCEPT_BSD_SIGNAL"}, {"sha": "62c40affc9ac5b4d04578c0e5e2e4f6fabbb794a", "filename": "libsanitizer/sanitizer_common/sanitizer_solaris.cpp", "status": "modified", "additions": 0, "deletions": 22, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_solaris.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_solaris.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_solaris.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -225,28 +225,6 @@ void FutexWait(atomic_uint32_t *p, u32 cmp) {\n \n void FutexWake(atomic_uint32_t *p, u32 count) {}\n \n-BlockingMutex::BlockingMutex() {\n-  CHECK(sizeof(mutex_t) <= sizeof(opaque_storage_));\n-  internal_memset(this, 0, sizeof(*this));\n-  CHECK_EQ(mutex_init((mutex_t *)&opaque_storage_, USYNC_THREAD, NULL), 0);\n-}\n-\n-void BlockingMutex::Lock() {\n-  CHECK(sizeof(mutex_t) <= sizeof(opaque_storage_));\n-  CHECK_NE(owner_, (uptr)thr_self());\n-  CHECK_EQ(mutex_lock((mutex_t *)&opaque_storage_), 0);\n-  CHECK(!owner_);\n-  owner_ = (uptr)thr_self();\n-}\n-\n-void BlockingMutex::Unlock() {\n-  CHECK(owner_ == (uptr)thr_self());\n-  owner_ = 0;\n-  CHECK_EQ(mutex_unlock((mutex_t *)&opaque_storage_), 0);\n-}\n-\n-void BlockingMutex::CheckLocked() const { CHECK_EQ((uptr)thr_self(), owner_); }\n-\n }  // namespace __sanitizer\n \n #endif  // SANITIZER_SOLARIS"}, {"sha": "4707c6c5d00b3da3198114594d42d383e6e7317b", "filename": "libsanitizer/sanitizer_common/sanitizer_stacktrace.cpp", "status": "modified", "additions": 8, "deletions": 14, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -22,7 +22,8 @@ namespace __sanitizer {\n uptr StackTrace::GetNextInstructionPc(uptr pc) {\n #if defined(__sparc__) || defined(__mips__)\n   return pc + 8;\n-#elif defined(__powerpc__) || defined(__arm__) || defined(__aarch64__)\n+#elif defined(__powerpc__) || defined(__arm__) || defined(__aarch64__) || \\\n+    defined(__hexagon__)\n   return pc + 4;\n #elif SANITIZER_RISCV64\n   // Current check order is 4 -> 2 -> 6 -> 8\n@@ -64,7 +65,7 @@ void BufferedStackTrace::Init(const uptr *pcs, uptr cnt, uptr extra_top_pc) {\n   top_frame_bp = 0;\n }\n \n-// Sparc implemention is in its own file.\n+// Sparc implementation is in its own file.\n #if !defined(__sparc__)\n \n // In GCC on ARM bp points to saved lr, not fp, so we should check the next\n@@ -85,8 +86,8 @@ static inline uhwptr *GetCanonicFrame(uptr bp,\n   // Nope, this does not look right either. This means the frame after next does\n   // not have a valid frame pointer, but we can still extract the caller PC.\n   // Unfortunately, there is no way to decide between GCC and LLVM frame\n-  // layouts. Assume GCC.\n-  return bp_prev - 1;\n+  // layouts. Assume LLVM.\n+  return bp_prev;\n #else\n   return (uhwptr*)bp;\n #endif\n@@ -109,21 +110,14 @@ void BufferedStackTrace::UnwindFast(uptr pc, uptr bp, uptr stack_top,\n          IsAligned((uptr)frame, sizeof(*frame)) &&\n          size < max_depth) {\n #ifdef __powerpc__\n-    // PowerPC ABIs specify that the return address is saved on the\n-    // *caller's* stack frame.  Thus we must dereference the back chain\n-    // to find the caller frame before extracting it.\n+    // PowerPC ABIs specify that the return address is saved at offset\n+    // 16 of the *caller's* stack frame.  Thus we must dereference the\n+    // back chain to find the caller frame before extracting it.\n     uhwptr *caller_frame = (uhwptr*)frame[0];\n     if (!IsValidFrame((uptr)caller_frame, stack_top, bottom) ||\n         !IsAligned((uptr)caller_frame, sizeof(uhwptr)))\n       break;\n-    // For most ABIs the offset where the return address is saved is two\n-    // register sizes.  The exception is the SVR4 ABI, which uses an\n-    // offset of only one register size.\n-#ifdef _CALL_SYSV\n-    uhwptr pc1 = caller_frame[1];\n-#else\n     uhwptr pc1 = caller_frame[2];\n-#endif\n #elif defined(__s390__)\n     uhwptr pc1 = frame[14];\n #elif defined(__riscv)"}, {"sha": "2d1c03f732217402339851669fc8a76776ee0e7a", "filename": "libsanitizer/sanitizer_common/sanitizer_stacktrace_libcdep.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace_libcdep.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace_libcdep.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace_libcdep.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -64,7 +64,7 @@ class StackTraceTextPrinter {\n       if (dedup_token_->length())\n         dedup_token_->append(\"--\");\n       if (stack->info.function != nullptr)\n-        dedup_token_->append(stack->info.function);\n+        dedup_token_->append(\"%s\", stack->info.function);\n     }\n   }\n "}, {"sha": "ad638a84a5933bc0642a6325e07438803f146ecf", "filename": "libsanitizer/sanitizer_common/sanitizer_stacktrace_printer.cpp", "status": "modified", "additions": 5, "deletions": 6, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace_printer.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace_printer.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace_printer.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -129,7 +129,7 @@ void RenderFrame(InternalScopedString *buffer, const char *format, int frame_no,\n       break;\n     // Frame number and all fields of AddressInfo structure.\n     case 'n':\n-      buffer->append(\"%zu\", frame_no);\n+      buffer->append(\"%u\", frame_no);\n       break;\n     case 'p':\n       buffer->append(\"0x%zx\", address);\n@@ -198,8 +198,7 @@ void RenderFrame(InternalScopedString *buffer, const char *format, int frame_no,\n       }\n       break;\n     default:\n-      Report(\"Unsupported specifier in stack frame format: %c (0x%zx)!\\n\", *p,\n-             *p);\n+      Report(\"Unsupported specifier in stack frame format: %c (%p)!\\n\", *p, p);\n       Die();\n     }\n   }\n@@ -244,14 +243,14 @@ void RenderData(InternalScopedString *buffer, const char *format,\n         buffer->append(\"%s\", StripPathPrefix(DI->file, strip_path_prefix));\n         break;\n       case 'l':\n-        buffer->append(\"%d\", DI->line);\n+        buffer->append(\"%zu\", DI->line);\n         break;\n       case 'g':\n         buffer->append(\"%s\", DI->name);\n         break;\n       default:\n-        Report(\"Unsupported specifier in stack frame format: %c (0x%zx)!\\n\", *p,\n-               *p);\n+        Report(\"Unsupported specifier in stack frame format: %c (%p)!\\n\", *p,\n+               p);\n         Die();\n     }\n   }"}, {"sha": "1e635a66978f36422335e70a65c4c217c24b4352", "filename": "libsanitizer/sanitizer_common/sanitizer_stacktrace_sparc.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace_sparc.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace_sparc.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_stacktrace_sparc.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -9,7 +9,7 @@\n // This file is shared between AddressSanitizer and ThreadSanitizer\n // run-time libraries.\n //\n-// Implemention of fast stack unwinding for Sparc.\n+// Implementation of fast stack unwinding for Sparc.\n //===----------------------------------------------------------------------===//\n \n #if defined(__sparc__)"}, {"sha": "403bda1174cc46b7a9998e26be388c2173e93850", "filename": "libsanitizer/sanitizer_common/sanitizer_stoptheworld_linux_libcdep.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_stoptheworld_linux_libcdep.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_stoptheworld_linux_libcdep.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_stoptheworld_linux_libcdep.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -108,7 +108,7 @@ struct TracerThreadArgument {\n   void *callback_argument;\n   // The tracer thread waits on this mutex while the parent finishes its\n   // preparations.\n-  BlockingMutex mutex;\n+  Mutex mutex;\n   // Tracer thread signals its completion by setting done.\n   atomic_uintptr_t done;\n   uptr parent_pid;"}, {"sha": "701db72619a3d47c4f44b7096c6a8775be460f86", "filename": "libsanitizer/sanitizer_common/sanitizer_stoptheworld_netbsd_libcdep.cpp", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_stoptheworld_netbsd_libcdep.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_stoptheworld_netbsd_libcdep.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_stoptheworld_netbsd_libcdep.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -68,7 +68,7 @@ class SuspendedThreadsListNetBSD final : public SuspendedThreadsList {\n struct TracerThreadArgument {\n   StopTheWorldCallback callback;\n   void *callback_argument;\n-  BlockingMutex mutex;\n+  Mutex mutex;\n   atomic_uintptr_t done;\n   uptr parent_pid;\n };"}, {"sha": "42bd157fa62791a89badc05dccb84cf1f59c1e67", "filename": "libsanitizer/sanitizer_common/sanitizer_symbolizer.h", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -158,7 +158,7 @@ class Symbolizer final {\n   // its method should be protected by |mu_|.\n   class ModuleNameOwner {\n    public:\n-    explicit ModuleNameOwner(BlockingMutex *synchronized_by)\n+    explicit ModuleNameOwner(Mutex *synchronized_by)\n         : last_match_(nullptr), mu_(synchronized_by) {\n       storage_.reserve(kInitialCapacity);\n     }\n@@ -169,7 +169,7 @@ class Symbolizer final {\n     InternalMmapVector<const char*> storage_;\n     const char *last_match_;\n \n-    BlockingMutex *mu_;\n+    Mutex *mu_;\n   } module_names_;\n \n   /// Platform-specific function for creating a Symbolizer object.\n@@ -192,7 +192,7 @@ class Symbolizer final {\n   // Mutex locked from public methods of |Symbolizer|, so that the internals\n   // (including individual symbolizer tools and platform-specific methods) are\n   // always synchronized.\n-  BlockingMutex mu_;\n+  Mutex mu_;\n \n   IntrusiveList<SymbolizerTool> tools_;\n "}, {"sha": "b8670941a05ec019bc6786e634e073663deba560", "filename": "libsanitizer/sanitizer_common/sanitizer_symbolizer_internal.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer_internal.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer_internal.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer_internal.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -21,7 +21,7 @@ namespace __sanitizer {\n \n // Parsing helpers, 'str' is searched for delimiter(s) and a string or uptr\n // is extracted. When extracting a string, a newly allocated (using\n-// InternalAlloc) and null-terminataed buffer is returned. They return a pointer\n+// InternalAlloc) and null-terminated buffer is returned. They return a pointer\n // to the next characted after the found delimiter.\n const char *ExtractToken(const char *str, const char *delims, char **result);\n const char *ExtractInt(const char *str, const char *delims, int *result);"}, {"sha": "3fc994fd3deb2b387f5a168300d72470cd403baa", "filename": "libsanitizer/sanitizer_common/sanitizer_symbolizer_libcdep.cpp", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer_libcdep.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer_libcdep.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_symbolizer_libcdep.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -83,7 +83,7 @@ const char *ExtractTokenUpToDelimiter(const char *str, const char *delimiter,\n }\n \n SymbolizedStack *Symbolizer::SymbolizePC(uptr addr) {\n-  BlockingMutexLock l(&mu_);\n+  Lock l(&mu_);\n   const char *module_name = nullptr;\n   uptr module_offset;\n   ModuleArch arch;\n@@ -103,7 +103,7 @@ SymbolizedStack *Symbolizer::SymbolizePC(uptr addr) {\n }\n \n bool Symbolizer::SymbolizeData(uptr addr, DataInfo *info) {\n-  BlockingMutexLock l(&mu_);\n+  Lock l(&mu_);\n   const char *module_name = nullptr;\n   uptr module_offset;\n   ModuleArch arch;\n@@ -124,7 +124,7 @@ bool Symbolizer::SymbolizeData(uptr addr, DataInfo *info) {\n }\n \n bool Symbolizer::SymbolizeFrame(uptr addr, FrameInfo *info) {\n-  BlockingMutexLock l(&mu_);\n+  Lock l(&mu_);\n   const char *module_name = nullptr;\n   if (!FindModuleNameAndOffsetForAddress(\n           addr, &module_name, &info->module_offset, &info->module_arch))\n@@ -141,7 +141,7 @@ bool Symbolizer::SymbolizeFrame(uptr addr, FrameInfo *info) {\n \n bool Symbolizer::GetModuleNameAndOffsetForPC(uptr pc, const char **module_name,\n                                              uptr *module_address) {\n-  BlockingMutexLock l(&mu_);\n+  Lock l(&mu_);\n   const char *internal_module_name = nullptr;\n   ModuleArch arch;\n   if (!FindModuleNameAndOffsetForAddress(pc, &internal_module_name,\n@@ -154,15 +154,15 @@ bool Symbolizer::GetModuleNameAndOffsetForPC(uptr pc, const char **module_name,\n }\n \n void Symbolizer::Flush() {\n-  BlockingMutexLock l(&mu_);\n+  Lock l(&mu_);\n   for (auto &tool : tools_) {\n     SymbolizerScope sym_scope(this);\n     tool.Flush();\n   }\n }\n \n const char *Symbolizer::Demangle(const char *name) {\n-  BlockingMutexLock l(&mu_);\n+  Lock l(&mu_);\n   for (auto &tool : tools_) {\n     SymbolizerScope sym_scope(this);\n     if (const char *demangled = tool.Demangle(name))"}, {"sha": "553bff7503b4323be697eabc67e41733a5877844", "filename": "libsanitizer/sanitizer_common/sanitizer_syscall_linux_hexagon.inc", "status": "added", "additions": 131, "deletions": 0, "changes": 131, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_syscall_linux_hexagon.inc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_syscall_linux_hexagon.inc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_syscall_linux_hexagon.inc?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -0,0 +1,131 @@\n+//===-- sanitizer_syscall_linux_hexagon.inc ---------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// Implementations of internal_syscall and internal_iserror for Linux/hexagon.\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#define SYSCALL(name) __NR_##name\n+\n+#define __internal_syscall_LL_E(x) \\\n+  ((union {                        \\\n+    long long ll;                  \\\n+    long l[2];                     \\\n+  }){.ll = x})                     \\\n+      .l[0],                       \\\n+      ((union {                    \\\n+        long long ll;              \\\n+        long l[2];                 \\\n+      }){.ll = x})                 \\\n+          .l[1]\n+#define __internal_syscall_LL_O(x) 0, __SYSCALL_LL_E((x))\n+\n+#define __asm_syscall(...)                                                 \\\n+  do {                                                                     \\\n+    __asm__ __volatile__(\"trap0(#1)\" : \"=r\"(r0) : __VA_ARGS__ : \"memory\"); \\\n+    return r0;                                                             \\\n+  } while (0)\n+\n+#define __internal_syscall0(n) (__internal_syscall)(n)\n+\n+static uptr __internal_syscall(long n) {\n+  register u32 r6 __asm__(\"r6\") = n;\n+  register u32 r0 __asm__(\"r0\");\n+  __asm_syscall(\"r\"(r6));\n+}\n+\n+#define __internal_syscall1(n, a1) (__internal_syscall)(n, (long)(a1))\n+\n+static uptr __internal_syscall(long n, long a) {\n+  register u32 r6 __asm__(\"r6\") = n;\n+  register u32 r0 __asm__(\"r0\") = a;\n+  __asm_syscall(\"r\"(r6), \"0\"(r0));\n+}\n+\n+#define __internal_syscall2(n, a1, a2) \\\n+  (__internal_syscall)(n, (long)(a1), (long)(a2))\n+\n+static uptr __internal_syscall(long n, long a, long b) {\n+  register u32 r6 __asm__(\"r6\") = n;\n+  register u32 r0 __asm__(\"r0\") = a;\n+  register u32 r1 __asm__(\"r1\") = b;\n+  __asm_syscall(\"r\"(r6), \"0\"(r0), \"r\"(r1));\n+}\n+\n+#define __internal_syscall3(n, a1, a2, a3) \\\n+  (__internal_syscall)(n, (long)(a1), (long)(a2), (long)(a3))\n+\n+static uptr __internal_syscall(long n, long a, long b, long c) {\n+  register u32 r6 __asm__(\"r6\") = n;\n+  register u32 r0 __asm__(\"r0\") = a;\n+  register u32 r1 __asm__(\"r1\") = b;\n+  register u32 r2 __asm__(\"r2\") = c;\n+  __asm_syscall(\"r\"(r6), \"0\"(r0), \"r\"(r1), \"r\"(r2));\n+}\n+\n+#define __internal_syscall4(n, a1, a2, a3, a4) \\\n+  (__internal_syscall)(n, (long)(a1), (long)(a2), (long)(a3), (long)(a4))\n+\n+static uptr __internal_syscall(long n, long a, long b, long c, long d) {\n+  register u32 r6 __asm__(\"r6\") = n;\n+  register u32 r0 __asm__(\"r0\") = a;\n+  register u32 r1 __asm__(\"r1\") = b;\n+  register u32 r2 __asm__(\"r2\") = c;\n+  register u32 r3 __asm__(\"r3\") = d;\n+  __asm_syscall(\"r\"(r6), \"0\"(r0), \"r\"(r1), \"r\"(r2), \"r\"(r3));\n+}\n+\n+#define __internal_syscall5(n, a1, a2, a3, a4, a5)                        \\\n+  (__internal_syscall)(n, (long)(a1), (long)(a2), (long)(a3), (long)(a4), \\\n+                       (long)(a5))\n+\n+static uptr __internal_syscall(long n, long a, long b, long c, long d, long e) {\n+  register u32 r6 __asm__(\"r6\") = n;\n+  register u32 r0 __asm__(\"r0\") = a;\n+  register u32 r1 __asm__(\"r1\") = b;\n+  register u32 r2 __asm__(\"r2\") = c;\n+  register u32 r3 __asm__(\"r3\") = d;\n+  register u32 r4 __asm__(\"r4\") = e;\n+  __asm_syscall(\"r\"(r6), \"0\"(r0), \"r\"(r1), \"r\"(r2), \"r\"(r3), \"r\"(r4));\n+}\n+\n+#define __internal_syscall6(n, a1, a2, a3, a4, a5, a6)                    \\\n+  (__internal_syscall)(n, (long)(a1), (long)(a2), (long)(a3), (long)(a4), \\\n+                       (long)(a5), (long)(a6))\n+\n+static uptr __internal_syscall(long n, long a, long b, long c, long d, long e,\n+                               long f) {\n+  register u32 r6 __asm__(\"r6\") = n;\n+  register u32 r0 __asm__(\"r0\") = a;\n+  register u32 r1 __asm__(\"r1\") = b;\n+  register u32 r2 __asm__(\"r2\") = c;\n+  register u32 r3 __asm__(\"r3\") = d;\n+  register u32 r4 __asm__(\"r4\") = e;\n+  register u32 r5 __asm__(\"r5\") = f;\n+  __asm_syscall(\"r\"(r6), \"0\"(r0), \"r\"(r1), \"r\"(r2), \"r\"(r3), \"r\"(r4), \"r\"(r5));\n+}\n+\n+#define __SYSCALL_NARGS_X(a1, a2, a3, a4, a5, a6, a7, a8, n, ...) n\n+#define __SYSCALL_NARGS(...) \\\n+  __SYSCALL_NARGS_X(__VA_ARGS__, 7, 6, 5, 4, 3, 2, 1, 0, )\n+#define __SYSCALL_CONCAT_X(a, b) a##b\n+#define __SYSCALL_CONCAT(a, b) __SYSCALL_CONCAT_X(a, b)\n+#define __SYSCALL_DISP(b, ...) \\\n+  __SYSCALL_CONCAT(b, __SYSCALL_NARGS(__VA_ARGS__))(__VA_ARGS__)\n+\n+#define internal_syscall(...) __SYSCALL_DISP(__internal_syscall, __VA_ARGS__)\n+\n+// Helper function used to avoid clobbering of errno.\n+bool internal_iserror(uptr retval, int *rverrno) {\n+  if (retval >= (uptr)-4095) {\n+    if (rverrno)\n+      *rverrno = -retval;\n+    return true;\n+  }\n+  return false;\n+}"}, {"sha": "a34b8c15aa5b01c0b377f9309dbbca7be001e9ca", "filename": "libsanitizer/sanitizer_common/sanitizer_thread_registry.cpp", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_thread_registry.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_thread_registry.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_thread_registry.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -119,21 +119,21 @@ ThreadRegistry::ThreadRegistry(ThreadContextFactory factory, u32 max_threads,\n \n void ThreadRegistry::GetNumberOfThreads(uptr *total, uptr *running,\n                                         uptr *alive) {\n-  BlockingMutexLock l(&mtx_);\n+  ThreadRegistryLock l(this);\n   if (total)\n     *total = threads_.size();\n   if (running) *running = running_threads_;\n   if (alive) *alive = alive_threads_;\n }\n \n uptr ThreadRegistry::GetMaxAliveThreads() {\n-  BlockingMutexLock l(&mtx_);\n+  ThreadRegistryLock l(this);\n   return max_alive_threads_;\n }\n \n u32 ThreadRegistry::CreateThread(uptr user_id, bool detached, u32 parent_tid,\n                                  void *arg) {\n-  BlockingMutexLock l(&mtx_);\n+  ThreadRegistryLock l(this);\n   u32 tid = kInvalidTid;\n   ThreadContextBase *tctx = QuarantinePop();\n   if (tctx) {\n@@ -179,7 +179,7 @@ void ThreadRegistry::RunCallbackForEachThreadLocked(ThreadCallback cb,\n }\n \n u32 ThreadRegistry::FindThread(FindThreadCallback cb, void *arg) {\n-  BlockingMutexLock l(&mtx_);\n+  ThreadRegistryLock l(this);\n   for (u32 tid = 0; tid < threads_.size(); tid++) {\n     ThreadContextBase *tctx = threads_[tid];\n     if (tctx != 0 && cb(tctx, arg))\n@@ -211,7 +211,7 @@ ThreadContextBase *ThreadRegistry::FindThreadContextByOsIDLocked(tid_t os_id) {\n }\n \n void ThreadRegistry::SetThreadName(u32 tid, const char *name) {\n-  BlockingMutexLock l(&mtx_);\n+  ThreadRegistryLock l(this);\n   ThreadContextBase *tctx = threads_[tid];\n   CHECK_NE(tctx, 0);\n   CHECK_EQ(SANITIZER_FUCHSIA ? ThreadStatusCreated : ThreadStatusRunning,\n@@ -220,7 +220,7 @@ void ThreadRegistry::SetThreadName(u32 tid, const char *name) {\n }\n \n void ThreadRegistry::SetThreadNameByUserId(uptr user_id, const char *name) {\n-  BlockingMutexLock l(&mtx_);\n+  ThreadRegistryLock l(this);\n   for (u32 tid = 0; tid < threads_.size(); tid++) {\n     ThreadContextBase *tctx = threads_[tid];\n     if (tctx != 0 && tctx->user_id == user_id &&\n@@ -232,7 +232,7 @@ void ThreadRegistry::SetThreadNameByUserId(uptr user_id, const char *name) {\n }\n \n void ThreadRegistry::DetachThread(u32 tid, void *arg) {\n-  BlockingMutexLock l(&mtx_);\n+  ThreadRegistryLock l(this);\n   ThreadContextBase *tctx = threads_[tid];\n   CHECK_NE(tctx, 0);\n   if (tctx->status == ThreadStatusInvalid) {\n@@ -252,7 +252,7 @@ void ThreadRegistry::JoinThread(u32 tid, void *arg) {\n   bool destroyed = false;\n   do {\n     {\n-      BlockingMutexLock l(&mtx_);\n+      ThreadRegistryLock l(this);\n       ThreadContextBase *tctx = threads_[tid];\n       CHECK_NE(tctx, 0);\n       if (tctx->status == ThreadStatusInvalid) {\n@@ -275,7 +275,7 @@ void ThreadRegistry::JoinThread(u32 tid, void *arg) {\n // thread before trying to create it, and then failed to actually\n // create it, and so never called StartThread.\n ThreadStatus ThreadRegistry::FinishThread(u32 tid) {\n-  BlockingMutexLock l(&mtx_);\n+  ThreadRegistryLock l(this);\n   CHECK_GT(alive_threads_, 0);\n   alive_threads_--;\n   ThreadContextBase *tctx = threads_[tid];\n@@ -301,7 +301,7 @@ ThreadStatus ThreadRegistry::FinishThread(u32 tid) {\n \n void ThreadRegistry::StartThread(u32 tid, tid_t os_id, ThreadType thread_type,\n                                  void *arg) {\n-  BlockingMutexLock l(&mtx_);\n+  ThreadRegistryLock l(this);\n   running_threads_++;\n   ThreadContextBase *tctx = threads_[tid];\n   CHECK_NE(tctx, 0);\n@@ -334,7 +334,7 @@ ThreadContextBase *ThreadRegistry::QuarantinePop() {\n }\n \n void ThreadRegistry::SetThreadUserId(u32 tid, uptr user_id) {\n-  BlockingMutexLock l(&mtx_);\n+  ThreadRegistryLock l(this);\n   ThreadContextBase *tctx = threads_[tid];\n   CHECK_NE(tctx, 0);\n   CHECK_NE(tctx->status, ThreadStatusInvalid);"}, {"sha": "a8a4d4d86a03eb33722ce87cfa36e85279f8ecf3", "filename": "libsanitizer/sanitizer_common/sanitizer_thread_registry.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_thread_registry.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_thread_registry.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_thread_registry.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -135,7 +135,7 @@ class MUTEX ThreadRegistry {\n   const u32 thread_quarantine_size_;\n   const u32 max_reuse_;\n \n-  BlockingMutex mtx_;\n+  Mutex mtx_;\n \n   u64 total_threads_;   // Total number of created threads. May be greater than\n                         // max_threads_ if contexts were reused."}, {"sha": "ce5e85df1553eddf73bdce5c3f05731253ef41d5", "filename": "libsanitizer/sanitizer_common/sanitizer_tls_get_addr.cpp", "status": "modified", "additions": 10, "deletions": 9, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_tls_get_addr.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_tls_get_addr.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_tls_get_addr.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -44,7 +44,7 @@ static atomic_uintptr_t number_of_live_dtls;\n static const uptr kDestroyedThread = -1;\n \n static void DTLS_Deallocate(DTLS::DTVBlock *block) {\n-  VReport(2, \"__tls_get_addr: DTLS_Deallocate %p %zd\\n\", block);\n+  VReport(2, \"__tls_get_addr: DTLS_Deallocate %p\\n\", block);\n   UnmapOrDie(block, sizeof(DTLS::DTVBlock));\n   atomic_fetch_sub(&number_of_live_dtls, 1, memory_order_relaxed);\n }\n@@ -117,26 +117,27 @@ DTLS::DTV *DTLS_on_tls_get_addr(void *arg_void, void *res,\n     return 0;\n   uptr tls_size = 0;\n   uptr tls_beg = reinterpret_cast<uptr>(res) - arg->offset - kDtvOffset;\n-  VReport(2, \"__tls_get_addr: %p {%p,%p} => %p; tls_beg: %p; sp: %p \"\n-             \"num_live_dtls %zd\\n\",\n+  VReport(2,\n+          \"__tls_get_addr: %p {0x%zx,0x%zx} => %p; tls_beg: 0x%zx; sp: %p \"\n+          \"num_live_dtls %zd\\n\",\n           arg, arg->dso_id, arg->offset, res, tls_beg, &tls_beg,\n           atomic_load(&number_of_live_dtls, memory_order_relaxed));\n   if (dtls.last_memalign_ptr == tls_beg) {\n     tls_size = dtls.last_memalign_size;\n-    VReport(2, \"__tls_get_addr: glibc <=2.18 suspected; tls={%p,%p}\\n\",\n-        tls_beg, tls_size);\n+    VReport(2, \"__tls_get_addr: glibc <=2.18 suspected; tls={0x%zx,0x%zx}\\n\",\n+            tls_beg, tls_size);\n   } else if (tls_beg >= static_tls_begin && tls_beg < static_tls_end) {\n     // This is the static TLS block which was initialized / unpoisoned at thread\n     // creation.\n-    VReport(2, \"__tls_get_addr: static tls: %p\\n\", tls_beg);\n+    VReport(2, \"__tls_get_addr: static tls: 0x%zx\\n\", tls_beg);\n     tls_size = 0;\n   } else if ((tls_beg % 4096) == sizeof(Glibc_2_19_tls_header)) {\n     // We may want to check gnu_get_libc_version().\n     Glibc_2_19_tls_header *header = (Glibc_2_19_tls_header *)tls_beg - 1;\n     tls_size = header->size;\n     tls_beg = header->start;\n-    VReport(2, \"__tls_get_addr: glibc >=2.19 suspected; tls={%p %p}\\n\",\n-        tls_beg, tls_size);\n+    VReport(2, \"__tls_get_addr: glibc >=2.19 suspected; tls={0x%zx 0x%zx}\\n\",\n+            tls_beg, tls_size);\n   } else {\n     VReport(2, \"__tls_get_addr: Can't guess glibc version\\n\");\n     // This may happen inside the DTOR of main thread, so just ignore it.\n@@ -149,7 +150,7 @@ DTLS::DTV *DTLS_on_tls_get_addr(void *arg_void, void *res,\n \n void DTLS_on_libc_memalign(void *ptr, uptr size) {\n   if (!common_flags()->intercept_tls_get_addr) return;\n-  VReport(2, \"DTLS_on_libc_memalign: %p %p\\n\", ptr, size);\n+  VReport(2, \"DTLS_on_libc_memalign: %p 0x%zx\\n\", ptr, size);\n   dtls.last_memalign_ptr = reinterpret_cast<uptr>(ptr);\n   dtls.last_memalign_size = size;\n }"}, {"sha": "811aa497d97dc801055262c93ff496f39aadaf95", "filename": "libsanitizer/sanitizer_common/sanitizer_win.cpp", "status": "modified", "additions": 3, "deletions": 21, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_win.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fsanitizer_common%2Fsanitizer_win.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fsanitizer_common%2Fsanitizer_win.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -16,6 +16,7 @@\n \n #define WIN32_LEAN_AND_MEAN\n #define NOGDI\n+#include <direct.h>\n #include <windows.h>\n #include <io.h>\n #include <psapi.h>\n@@ -565,6 +566,8 @@ void Abort() {\n   internal__exit(3);\n }\n \n+bool CreateDir(const char *pathname) { return _mkdir(pathname) == 0; }\n+\n #if !SANITIZER_GO\n // Read the file to extract the ImageBase field from the PE header. If ASLR is\n // disabled and this virtual address is available, the loader will typically\n@@ -827,27 +830,6 @@ void FutexWake(atomic_uint32_t *p, u32 count) {\n     WakeByAddressAll(p);\n }\n \n-// ---------------------- BlockingMutex ---------------- {{{1\n-\n-BlockingMutex::BlockingMutex() {\n-  CHECK(sizeof(SRWLOCK) <= sizeof(opaque_storage_));\n-  internal_memset(this, 0, sizeof(*this));\n-}\n-\n-void BlockingMutex::Lock() {\n-  AcquireSRWLockExclusive((PSRWLOCK)opaque_storage_);\n-  CHECK_EQ(owner_, 0);\n-  owner_ = GetThreadSelf();\n-}\n-\n-void BlockingMutex::Unlock() {\n-  CheckLocked();\n-  owner_ = 0;\n-  ReleaseSRWLockExclusive((PSRWLOCK)opaque_storage_);\n-}\n-\n-void BlockingMutex::CheckLocked() const { CHECK_EQ(owner_, GetThreadSelf()); }\n-\n uptr GetTlsSize() {\n   return 0;\n }"}, {"sha": "9dc11f79072b90a0a70789920be457c63c8e357b", "filename": "libsanitizer/tsan/Makefile.am", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2FMakefile.am", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2FMakefile.am", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2FMakefile.am?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -29,7 +29,6 @@ tsan_files = \\\n \ttsan_malloc_mac.cpp \\\n \ttsan_md5.cpp \\\n \ttsan_mman.cpp \\\n-\ttsan_mutex.cpp \\\n \ttsan_mutexset.cpp \\\n \ttsan_new_delete.cpp \\\n \ttsan_platform_linux.cpp \\\n@@ -45,7 +44,8 @@ tsan_files = \\\n \ttsan_stack_trace.cpp \\\n \ttsan_suppressions.cpp \\\n \ttsan_symbolize.cpp \\\n-\ttsan_sync.cpp \n+\ttsan_sync.cpp \\\n+\ttsan_vector_clock.cpp\n \n libtsan_la_SOURCES = $(tsan_files)\n EXTRA_libtsan_la_SOURCES = tsan_rtl_amd64.S tsan_rtl_aarch64.S tsan_rtl_mips64.S tsan_rtl_ppc64.S tsan_rtl_s390x.S"}, {"sha": "921a78c7484703f6c9aa9a3cd9af4aacdcb873eb", "filename": "libsanitizer/tsan/Makefile.in", "status": "modified", "additions": 7, "deletions": 6, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2FMakefile.in?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -150,12 +150,13 @@ am__objects_1 = tsan_clock.lo tsan_debugging.lo tsan_external.lo \\\n \ttsan_interceptors_posix.lo tsan_interceptors_mac.lo \\\n \ttsan_interface_ann.lo tsan_interface_atomic.lo \\\n \ttsan_interface.lo tsan_interface_java.lo tsan_malloc_mac.lo \\\n-\ttsan_md5.lo tsan_mman.lo tsan_mutex.lo tsan_mutexset.lo \\\n-\ttsan_new_delete.lo tsan_platform_linux.lo tsan_platform_mac.lo \\\n+\ttsan_md5.lo tsan_mman.lo tsan_mutexset.lo tsan_new_delete.lo \\\n+\ttsan_platform_linux.lo tsan_platform_mac.lo \\\n \ttsan_platform_posix.lo tsan_platform_windows.lo tsan_report.lo \\\n \ttsan_rtl.lo tsan_rtl_mutex.lo tsan_rtl_proc.lo \\\n \ttsan_rtl_report.lo tsan_rtl_thread.lo tsan_stack_trace.lo \\\n-\ttsan_suppressions.lo tsan_symbolize.lo tsan_sync.lo\n+\ttsan_suppressions.lo tsan_symbolize.lo tsan_sync.lo \\\n+\ttsan_vector_clock.lo\n am_libtsan_la_OBJECTS = $(am__objects_1)\n libtsan_la_OBJECTS = $(am_libtsan_la_OBJECTS)\n AM_V_lt = $(am__v_lt_@AM_V@)\n@@ -431,7 +432,6 @@ tsan_files = \\\n \ttsan_malloc_mac.cpp \\\n \ttsan_md5.cpp \\\n \ttsan_mman.cpp \\\n-\ttsan_mutex.cpp \\\n \ttsan_mutexset.cpp \\\n \ttsan_new_delete.cpp \\\n \ttsan_platform_linux.cpp \\\n@@ -447,7 +447,8 @@ tsan_files = \\\n \ttsan_stack_trace.cpp \\\n \ttsan_suppressions.cpp \\\n \ttsan_symbolize.cpp \\\n-\ttsan_sync.cpp \n+\ttsan_sync.cpp \\\n+\ttsan_vector_clock.cpp\n \n libtsan_la_SOURCES = $(tsan_files)\n EXTRA_libtsan_la_SOURCES = tsan_rtl_amd64.S tsan_rtl_aarch64.S tsan_rtl_mips64.S tsan_rtl_ppc64.S tsan_rtl_s390x.S\n@@ -594,7 +595,6 @@ distclean-compile:\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_malloc_mac.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_md5.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_mman.Plo@am__quote@\n-@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_mutex.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_mutexset.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_new_delete.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_platform_linux.Plo@am__quote@\n@@ -616,6 +616,7 @@ distclean-compile:\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_suppressions.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_symbolize.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_sync.Plo@am__quote@\n+@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/tsan_vector_clock.Plo@am__quote@\n \n .S.o:\n @am__fastdepCCAS_TRUE@\t$(AM_V_CPPAS)$(CPPASCOMPILE) -MT $@ -MD -MP -MF $(DEPDIR)/$*.Tpo -c -o $@ $<"}, {"sha": "d122b67c0aaa5fc9016d5d208120d38e75a543dc", "filename": "libsanitizer/tsan/tsan_clock.cpp", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_clock.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_clock.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_clock.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -72,9 +72,9 @@\n // clk_ - variable size vector clock, low kClkBits hold timestamp,\n //   the remaining bits hold \"acquired\" flag (the actual value is thread's\n //   reused counter);\n-//   if acquried == thr->reused_, then the respective thread has already\n+//   if acquired == thr->reused_, then the respective thread has already\n //   acquired this clock (except possibly for dirty elements).\n-// dirty_ - holds up to two indeces in the vector clock that other threads\n+// dirty_ - holds up to two indices in the vector clock that other threads\n //   need to acquire regardless of \"acquired\" flag value;\n // release_store_tid_ - denotes that the clock state is a result of\n //   release-store operation by the thread with release_store_tid_ index.\n@@ -272,7 +272,7 @@ void ThreadClock::ReleaseStore(ClockCache *c, SyncClock *dst) {\n     // we could update the existing clock and cache it, or replace it with the\n     // currently cached clock and release the old one. And for a shared\n     // existing clock, we could replace it with the currently cached;\n-    // or unshare, update and cache. But, for simplicity, we currnetly reuse\n+    // or unshare, update and cache. But, for simplicity, we currently reuse\n     // cached clock only when the target clock is empty.\n     dst->tab_ = ctx->clock_alloc.Map(cached_idx_);\n     dst->tab_idx_ = cached_idx_;\n@@ -285,7 +285,7 @@ void ThreadClock::ReleaseStore(ClockCache *c, SyncClock *dst) {\n     dst->dirty_[0].epoch = clk_[tid_];\n     dst->release_store_tid_ = tid_;\n     dst->release_store_reused_ = reused_;\n-    // Rememeber that we don't need to acquire it in future.\n+    // Remember that we don't need to acquire it in future.\n     dst->elem(tid_).reused = reused_;\n     // Grab a reference.\n     atomic_fetch_add(ref_ptr(dst->tab_), 1, memory_order_relaxed);\n@@ -316,7 +316,7 @@ void ThreadClock::ReleaseStore(ClockCache *c, SyncClock *dst) {\n   for (uptr i = 0; i < kDirtyTids; i++) dst->dirty_[i].set_tid(kInvalidTid);\n   dst->release_store_tid_ = tid_;\n   dst->release_store_reused_ = reused_;\n-  // Rememeber that we don't need to acquire it in future.\n+  // Remember that we don't need to acquire it in future.\n   dst->elem(tid_).reused = reused_;\n \n   // If the resulting clock is cachable, cache it for future release operations."}, {"sha": "11cbc0c0b86b64c6a30486d1d59f1e1ff283fecb", "filename": "libsanitizer/tsan/tsan_clock.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_clock.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_clock.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_clock.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -213,7 +213,7 @@ class ThreadClock {\n   // We reuse it for subsequent store-release operations without intervening\n   // acquire operations. Since it is shared (and thus constant), clock value\n   // for the current thread is then stored in dirty entries in the SyncClock.\n-  // We host a refernece to the table while it is cached here.\n+  // We host a reference to the table while it is cached here.\n   u32 cached_idx_;\n   u16 cached_size_;\n   u16 cached_blocks_;"}, {"sha": "1d3c3849a446303759ff9bd9a480a66730c9a524", "filename": "libsanitizer/tsan/tsan_debugging.cpp", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_debugging.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_debugging.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_debugging.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -195,9 +195,9 @@ const char *__tsan_locate_address(uptr addr, char *name, uptr name_size,\n   const char *region_kind = nullptr;\n   if (name && name_size > 0) name[0] = 0;\n \n-  if (IsMetaMem(addr)) {\n+  if (IsMetaMem(reinterpret_cast<u32 *>(addr))) {\n     region_kind = \"meta shadow\";\n-  } else if (IsShadowMem(addr)) {\n+  } else if (IsShadowMem(reinterpret_cast<RawShadow *>(addr))) {\n     region_kind = \"shadow\";\n   } else {\n     bool is_stack = false;\n@@ -215,9 +215,9 @@ const char *__tsan_locate_address(uptr addr, char *name, uptr name_size,\n     } else {\n       // TODO(kuba.brecka): We should not lock. This is supposed to be called\n       // from within the debugger when other threads are stopped.\n-      ctx->thread_registry->Lock();\n+      ctx->thread_registry.Lock();\n       ThreadContext *tctx = IsThreadStackOrTls(addr, &is_stack);\n-      ctx->thread_registry->Unlock();\n+      ctx->thread_registry.Unlock();\n       if (tctx) {\n         region_kind = is_stack ? \"stack\" : \"tls\";\n       } else {\n@@ -252,7 +252,7 @@ int __tsan_get_alloc_stack(uptr addr, uptr *trace, uptr size, int *thread_id,\n   *thread_id = b->tid;\n   // No locking.  This is supposed to be called from within the debugger when\n   // other threads are stopped.\n-  ThreadContextBase *tctx = ctx->thread_registry->GetThreadLocked(b->tid);\n+  ThreadContextBase *tctx = ctx->thread_registry.GetThreadLocked(b->tid);\n   *os_id = tctx->os_id;\n \n   StackTrace stack = StackDepotGet(b->stk);"}, {"sha": "fe0c1da31599b18bbf885d4f1a1ad8a4a4a671b4", "filename": "libsanitizer/tsan/tsan_defs.h", "status": "modified", "additions": 62, "deletions": 4, "changes": 66, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_defs.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_defs.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_defs.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -15,8 +15,27 @@\n \n #include \"sanitizer_common/sanitizer_internal_defs.h\"\n #include \"sanitizer_common/sanitizer_libc.h\"\n+#include \"sanitizer_common/sanitizer_mutex.h\"\n #include \"ubsan/ubsan_platform.h\"\n \n+#ifndef TSAN_VECTORIZE\n+#  define TSAN_VECTORIZE __SSE4_2__\n+#endif\n+\n+#if TSAN_VECTORIZE\n+// <emmintrin.h> transitively includes <stdlib.h>,\n+// and it's prohibited to include std headers into tsan runtime.\n+// So we do this dirty trick.\n+#  define _MM_MALLOC_H_INCLUDED\n+#  define __MM_MALLOC_H\n+#  include <emmintrin.h>\n+#  include <smmintrin.h>\n+#  define VECTOR_ALIGNED ALIGNED(16)\n+typedef __m128i m128;\n+#else\n+#  define VECTOR_ALIGNED\n+#endif\n+\n // Setup defaults for compile definitions.\n #ifndef TSAN_NO_HISTORY\n # define TSAN_NO_HISTORY 0\n@@ -32,6 +51,19 @@\n \n namespace __tsan {\n \n+constexpr uptr kByteBits = 8;\n+\n+// Thread slot ID.\n+enum class Sid : u8 {};\n+constexpr uptr kThreadSlotCount = 256;\n+constexpr Sid kFreeSid = static_cast<Sid>(255);\n+\n+// Abstract time unit, vector clock element.\n+enum class Epoch : u16 {};\n+constexpr uptr kEpochBits = 14;\n+constexpr Epoch kEpochZero = static_cast<Epoch>(0);\n+constexpr Epoch kEpochOver = static_cast<Epoch>(1 << kEpochBits);\n+\n const int kClkBits = 42;\n const unsigned kMaxTidReuse = (1 << (64 - kClkBits)) - 1;\n \n@@ -74,8 +106,9 @@ const uptr kShadowCnt = 4;\n // That many user bytes are mapped onto a single shadow cell.\n const uptr kShadowCell = 8;\n \n-// Size of a single shadow value (u64).\n-const uptr kShadowSize = 8;\n+// Single shadow value.\n+typedef u64 RawShadow;\n+const uptr kShadowSize = sizeof(RawShadow);\n \n // Shadow memory is kShadowMultiplier times larger than user memory.\n const uptr kShadowMultiplier = kShadowSize * kShadowCnt / kShadowCell;\n@@ -87,6 +120,9 @@ const uptr kMetaShadowCell = 8;\n // Size of a single meta shadow value (u32).\n const uptr kMetaShadowSize = 4;\n \n+// All addresses and PCs are assumed to be compressable to that many bits.\n+const uptr kCompressedAddrBits = 44;\n+\n #if TSAN_NO_HISTORY\n const bool kCollectHistory = false;\n #else\n@@ -153,12 +189,23 @@ struct ReportStack;\n class ReportDesc;\n class RegionAlloc;\n \n+typedef uptr AccessType;\n+\n+enum : AccessType {\n+  kAccessWrite = 0,\n+  kAccessRead = 1 << 0,\n+  kAccessAtomic = 1 << 1,\n+  kAccessVptr = 1 << 2,  // read or write of an object virtual table pointer\n+  kAccessFree = 1 << 3,  // synthetic memory access during memory freeing\n+  kAccessExternalPC = 1 << 4,  // access PC can have kExternalPCBit set\n+};\n+\n // Descriptor of user's memory block.\n struct MBlock {\n   u64  siz : 48;\n   u64  tag : 16;\n-  u32  stk;\n-  u16  tid;\n+  StackID stk;\n+  Tid tid;\n };\n \n COMPILER_CHECK(sizeof(MBlock) == 16);\n@@ -172,6 +219,17 @@ enum ExternalTag : uptr {\n   // as 16-bit values, see tsan_defs.h.\n };\n \n+enum MutexType {\n+  MutexTypeTrace = MutexLastCommon,\n+  MutexTypeReport,\n+  MutexTypeSyncVar,\n+  MutexTypeAnnotations,\n+  MutexTypeAtExit,\n+  MutexTypeFired,\n+  MutexTypeRacy,\n+  MutexTypeGlobalProc,\n+};\n+\n }  // namespace __tsan\n \n #endif  // TSAN_DEFS_H"}, {"sha": "9e15f74a0615219fbb0d27a3388d391c1fb2a31e", "filename": "libsanitizer/tsan/tsan_dense_alloc.h", "status": "modified", "additions": 19, "deletions": 16, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_dense_alloc.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_dense_alloc.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_dense_alloc.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -20,7 +20,6 @@\n \n #include \"sanitizer_common/sanitizer_common.h\"\n #include \"tsan_defs.h\"\n-#include \"tsan_mutex.h\"\n \n namespace __tsan {\n \n@@ -50,11 +49,7 @@ class DenseSlabAlloc {\n   static_assert(sizeof(T) > sizeof(IndexT),\n                 \"it doesn't make sense to use dense alloc\");\n \n-  explicit DenseSlabAlloc(LinkerInitialized, const char *name) {\n-    freelist_ = 0;\n-    fillpos_ = 0;\n-    name_ = name;\n-  }\n+  DenseSlabAlloc(LinkerInitialized, const char *name) : name_(name) {}\n \n   explicit DenseSlabAlloc(const char *name)\n       : DenseSlabAlloc(LINKER_INITIALIZED, name) {\n@@ -90,6 +85,8 @@ class DenseSlabAlloc {\n   }\n \n   void FlushCache(Cache *c) {\n+    if (!c->pos)\n+      return;\n     SpinMutexLock lock(&mtx_);\n     while (c->pos) {\n       IndexT idx = c->cache[--c->pos];\n@@ -103,33 +100,39 @@ class DenseSlabAlloc {\n     internal_memset(c->cache, 0, sizeof(c->cache));\n   }\n \n+  uptr AllocatedMemory() const {\n+    return atomic_load_relaxed(&fillpos_) * kL2Size * sizeof(T);\n+  }\n+\n  private:\n   T *map_[kL1Size];\n   SpinMutex mtx_;\n-  IndexT freelist_;\n-  uptr fillpos_;\n-  const char *name_;\n+  IndexT freelist_ = {0};\n+  atomic_uintptr_t fillpos_ = {0};\n+  const char *const name_;\n \n   void Refill(Cache *c) {\n     SpinMutexLock lock(&mtx_);\n     if (freelist_ == 0) {\n-      if (fillpos_ == kL1Size) {\n+      uptr fillpos = atomic_load_relaxed(&fillpos_);\n+      if (fillpos == kL1Size) {\n         Printf(\"ThreadSanitizer: %s overflow (%zu*%zu). Dying.\\n\",\n             name_, kL1Size, kL2Size);\n         Die();\n       }\n-      VPrintf(2, \"ThreadSanitizer: growing %s: %zu out of %zu*%zu\\n\",\n-          name_, fillpos_, kL1Size, kL2Size);\n+      VPrintf(2, \"ThreadSanitizer: growing %s: %zu out of %zu*%zu\\n\", name_,\n+              fillpos, kL1Size, kL2Size);\n       T *batch = (T*)MmapOrDie(kL2Size * sizeof(T), name_);\n       // Reserve 0 as invalid index.\n-      IndexT start = fillpos_ == 0 ? 1 : 0;\n+      IndexT start = fillpos == 0 ? 1 : 0;\n       for (IndexT i = start; i < kL2Size; i++) {\n         new(batch + i) T;\n-        *(IndexT*)(batch + i) = i + 1 + fillpos_ * kL2Size;\n+        *(IndexT *)(batch + i) = i + 1 + fillpos * kL2Size;\n       }\n       *(IndexT*)(batch + kL2Size - 1) = 0;\n-      freelist_ = fillpos_ * kL2Size + start;\n-      map_[fillpos_++] = batch;\n+      freelist_ = fillpos * kL2Size + start;\n+      map_[fillpos] = batch;\n+      atomic_store_relaxed(&fillpos_, fillpos + 1);\n     }\n     for (uptr i = 0; i < Cache::kSize / 2 && freelist_ != 0; i++) {\n       IndexT idx = freelist_;"}, {"sha": "19ae174f20a595db3acf3d493569c0577d055561", "filename": "libsanitizer/tsan/tsan_external.cpp", "status": "modified", "additions": 10, "deletions": 9, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_external.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_external.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_external.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -10,9 +10,12 @@\n //\n //===----------------------------------------------------------------------===//\n #include \"tsan_rtl.h\"\n-#include \"tsan_interceptors.h\"\n #include \"sanitizer_common/sanitizer_ptrauth.h\"\n \n+#if !SANITIZER_GO\n+#  include \"tsan_interceptors.h\"\n+#endif\n+\n namespace __tsan {\n \n #define CALLERPC ((uptr)__builtin_return_address(0))\n@@ -57,16 +60,14 @@ uptr TagFromShadowStackFrame(uptr pc) {\n \n #if !SANITIZER_GO\n \n-typedef void(*AccessFunc)(ThreadState *, uptr, uptr, int);\n-void ExternalAccess(void *addr, uptr caller_pc, void *tag, AccessFunc access) {\n+void ExternalAccess(void *addr, uptr caller_pc, void *tag, AccessType typ) {\n   CHECK_LT(tag, atomic_load(&used_tags, memory_order_relaxed));\n   ThreadState *thr = cur_thread();\n   if (caller_pc) FuncEntry(thr, caller_pc);\n   InsertShadowStackFrameForTag(thr, (uptr)tag);\n   bool in_ignored_lib;\n-  if (!caller_pc || !libignore()->IsIgnored(caller_pc, &in_ignored_lib)) {\n-    access(thr, CALLERPC, (uptr)addr, kSizeLog1);\n-  }\n+  if (!caller_pc || !libignore()->IsIgnored(caller_pc, &in_ignored_lib))\n+    MemoryAccess(thr, CALLERPC, (uptr)addr, 1, typ);\n   FuncExit(thr);\n   if (caller_pc) FuncExit(thr);\n }\n@@ -92,7 +93,7 @@ void __tsan_external_register_header(void *tag, const char *header) {\n   header = internal_strdup(header);\n   char *old_header =\n       (char *)atomic_exchange(header_ptr, (uptr)header, memory_order_seq_cst);\n-  if (old_header) internal_free(old_header);\n+  Free(old_header);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n@@ -111,12 +112,12 @@ void __tsan_external_assign_tag(void *addr, void *tag) {\n \n SANITIZER_INTERFACE_ATTRIBUTE\n void __tsan_external_read(void *addr, void *caller_pc, void *tag) {\n-  ExternalAccess(addr, STRIP_PAC_PC(caller_pc), tag, MemoryRead);\n+  ExternalAccess(addr, STRIP_PAC_PC(caller_pc), tag, kAccessRead);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n void __tsan_external_write(void *addr, void *caller_pc, void *tag) {\n-  ExternalAccess(addr, STRIP_PAC_PC(caller_pc), tag, MemoryWrite);\n+  ExternalAccess(addr, STRIP_PAC_PC(caller_pc), tag, kAccessWrite);\n }\n }  // extern \"C\"\n "}, {"sha": "255ffa8daf7604a6225d387471b393ac403d3074", "filename": "libsanitizer/tsan/tsan_fd.cpp", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_fd.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_fd.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_fd.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -26,8 +26,8 @@ struct FdSync {\n \n struct FdDesc {\n   FdSync *sync;\n-  int creation_tid;\n-  u32 creation_stack;\n+  Tid creation_tid;\n+  StackID creation_stack;\n };\n \n struct FdContext {\n@@ -115,7 +115,7 @@ static void init(ThreadState *thr, uptr pc, int fd, FdSync *s,\n     MemoryRangeImitateWrite(thr, pc, (uptr)d, 8);\n   } else {\n     // See the dup-related comment in FdClose.\n-    MemoryRead(thr, pc, (uptr)d, kSizeLog8);\n+    MemoryAccess(thr, pc, (uptr)d, 8, kAccessRead);\n   }\n }\n \n@@ -140,7 +140,7 @@ void FdOnFork(ThreadState *thr, uptr pc) {\n   }\n }\n \n-bool FdLocation(uptr addr, int *fd, int *tid, u32 *stack) {\n+bool FdLocation(uptr addr, int *fd, Tid *tid, StackID *stack) {\n   for (int l1 = 0; l1 < kTableSizeL1; l1++) {\n     FdDesc *tab = (FdDesc*)atomic_load(&fdctx.tab[l1], memory_order_relaxed);\n     if (tab == 0)\n@@ -163,7 +163,7 @@ void FdAcquire(ThreadState *thr, uptr pc, int fd) {\n   FdDesc *d = fddesc(thr, pc, fd);\n   FdSync *s = d->sync;\n   DPrintf(\"#%d: FdAcquire(%d) -> %p\\n\", thr->tid, fd, s);\n-  MemoryRead(thr, pc, (uptr)d, kSizeLog8);\n+  MemoryAccess(thr, pc, (uptr)d, 8, kAccessRead);\n   if (s)\n     Acquire(thr, pc, (uptr)s);\n }\n@@ -174,7 +174,7 @@ void FdRelease(ThreadState *thr, uptr pc, int fd) {\n   FdDesc *d = fddesc(thr, pc, fd);\n   FdSync *s = d->sync;\n   DPrintf(\"#%d: FdRelease(%d) -> %p\\n\", thr->tid, fd, s);\n-  MemoryRead(thr, pc, (uptr)d, kSizeLog8);\n+  MemoryAccess(thr, pc, (uptr)d, 8, kAccessRead);\n   if (s)\n     Release(thr, pc, (uptr)s);\n }\n@@ -184,7 +184,7 @@ void FdAccess(ThreadState *thr, uptr pc, int fd) {\n   if (bogusfd(fd))\n     return;\n   FdDesc *d = fddesc(thr, pc, fd);\n-  MemoryRead(thr, pc, (uptr)d, kSizeLog8);\n+  MemoryAccess(thr, pc, (uptr)d, 8, kAccessRead);\n }\n \n void FdClose(ThreadState *thr, uptr pc, int fd, bool write) {\n@@ -194,7 +194,7 @@ void FdClose(ThreadState *thr, uptr pc, int fd, bool write) {\n   FdDesc *d = fddesc(thr, pc, fd);\n   if (write) {\n     // To catch races between fd usage and close.\n-    MemoryWrite(thr, pc, (uptr)d, kSizeLog8);\n+    MemoryAccess(thr, pc, (uptr)d, 8, kAccessWrite);\n   } else {\n     // This path is used only by dup2/dup3 calls.\n     // We do read instead of write because there is a number of legitimate\n@@ -204,15 +204,15 @@ void FdClose(ThreadState *thr, uptr pc, int fd, bool write) {\n     // 2. Some daemons dup /dev/null in place of stdin/stdout.\n     // On the other hand we have not seen cases when write here catches real\n     // bugs.\n-    MemoryRead(thr, pc, (uptr)d, kSizeLog8);\n+    MemoryAccess(thr, pc, (uptr)d, 8, kAccessRead);\n   }\n   // We need to clear it, because if we do not intercept any call out there\n   // that creates fd, we will hit false postives.\n   MemoryResetRange(thr, pc, (uptr)d, 8);\n   unref(thr, pc, d->sync);\n   d->sync = 0;\n-  d->creation_tid = 0;\n-  d->creation_stack = 0;\n+  d->creation_tid = kInvalidTid;\n+  d->creation_stack = kInvalidStackID;\n }\n \n void FdFileCreate(ThreadState *thr, uptr pc, int fd) {\n@@ -228,7 +228,7 @@ void FdDup(ThreadState *thr, uptr pc, int oldfd, int newfd, bool write) {\n     return;\n   // Ignore the case when user dups not yet connected socket.\n   FdDesc *od = fddesc(thr, pc, oldfd);\n-  MemoryRead(thr, pc, (uptr)od, kSizeLog8);\n+  MemoryAccess(thr, pc, (uptr)od, 8, kAccessRead);\n   FdClose(thr, pc, newfd, write);\n   init(thr, pc, newfd, ref(od->sync), write);\n }"}, {"sha": "d9648178481c6704c62c400cf9a5b047a4d9e7fa", "filename": "libsanitizer/tsan/tsan_fd.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_fd.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_fd.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_fd.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -53,7 +53,7 @@ void FdSocketCreate(ThreadState *thr, uptr pc, int fd);\n void FdSocketAccept(ThreadState *thr, uptr pc, int fd, int newfd);\n void FdSocketConnecting(ThreadState *thr, uptr pc, int fd);\n void FdSocketConnect(ThreadState *thr, uptr pc, int fd);\n-bool FdLocation(uptr addr, int *fd, int *tid, u32 *stack);\n+bool FdLocation(uptr addr, int *fd, Tid *tid, StackID *stack);\n void FdOnFork(ThreadState *thr, uptr pc);\n \n uptr File2addr(const char *path);"}, {"sha": "ee89862d17bd89440ed8a1b09ee11406b7846849", "filename": "libsanitizer/tsan/tsan_flags.cpp", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_flags.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_flags.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_flags.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -55,6 +55,7 @@ void InitializeFlags(Flags *f, const char *env, const char *env_option_name) {\n     // Override some common flags defaults.\n     CommonFlags cf;\n     cf.CopyFrom(*common_flags());\n+    cf.external_symbolizer_path = GetEnv(\"TSAN_SYMBOLIZER_PATH\");\n     cf.allow_addr2line = true;\n     if (SANITIZER_GO) {\n       // Does not work as expected for Go: runtime handles SIGABRT and crashes."}, {"sha": "7954a4307fa1e04e381f144b2339c9db7f2aff23", "filename": "libsanitizer/tsan/tsan_flags.inc", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_flags.inc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_flags.inc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_flags.inc?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -43,7 +43,6 @@ TSAN_FLAG(\n     bool, force_seq_cst_atomics, false,\n     \"If set, all atomics are effectively sequentially consistent (seq_cst), \"\n     \"regardless of what user actually specified.\")\n-TSAN_FLAG(bool, print_benign, false, \"Print matched \\\"benign\\\" races at exit.\")\n TSAN_FLAG(bool, halt_on_error, false, \"Exit after first reported error.\")\n TSAN_FLAG(int, atexit_sleep_ms, 1000,\n           \"Sleep in main thread before exiting for that many ms \""}, {"sha": "1fca1cf4f9fcf254ccf838eb1e58751b77058f1e", "filename": "libsanitizer/tsan/tsan_ignoreset.cpp", "status": "modified", "additions": 2, "deletions": 10, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_ignoreset.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_ignoreset.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_ignoreset.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -19,7 +19,7 @@ IgnoreSet::IgnoreSet()\n     : size_() {\n }\n \n-void IgnoreSet::Add(u32 stack_id) {\n+void IgnoreSet::Add(StackID stack_id) {\n   if (size_ == kMaxSize)\n     return;\n   for (uptr i = 0; i < size_; i++) {\n@@ -29,15 +29,7 @@ void IgnoreSet::Add(u32 stack_id) {\n   stacks_[size_++] = stack_id;\n }\n \n-void IgnoreSet::Reset() {\n-  size_ = 0;\n-}\n-\n-uptr IgnoreSet::Size() const {\n-  return size_;\n-}\n-\n-u32 IgnoreSet::At(uptr i) const {\n+StackID IgnoreSet::At(uptr i) const {\n   CHECK_LT(i, size_);\n   CHECK_LE(size_, kMaxSize);\n   return stacks_[i];"}, {"sha": "4e2511291ce4d608c83dac318156748bd9682d23", "filename": "libsanitizer/tsan/tsan_ignoreset.h", "status": "modified", "additions": 6, "deletions": 7, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_ignoreset.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_ignoreset.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_ignoreset.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -19,17 +19,16 @@ namespace __tsan {\n \n class IgnoreSet {\n  public:\n-  static const uptr kMaxSize = 16;\n-\n   IgnoreSet();\n-  void Add(u32 stack_id);\n-  void Reset();\n-  uptr Size() const;\n-  u32 At(uptr i) const;\n+  void Add(StackID stack_id);\n+  void Reset() { size_ = 0; }\n+  uptr Size() const { return size_; }\n+  StackID At(uptr i) const;\n \n  private:\n+  static constexpr uptr kMaxSize = 16;\n   uptr size_;\n-  u32 stacks_[kMaxSize];\n+  StackID stacks_[kMaxSize];\n };\n \n }  // namespace __tsan"}, {"sha": "d7d8be219dbe547a2a2d2d609926741ea09c95f2", "filename": "libsanitizer/tsan/tsan_ilist.h", "status": "added", "additions": 189, "deletions": 0, "changes": 189, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_ilist.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_ilist.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_ilist.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -0,0 +1,189 @@\n+//===-- tsan_ilist.h --------------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of ThreadSanitizer (TSan), a race detector.\n+//\n+//===----------------------------------------------------------------------===//\n+#ifndef TSAN_ILIST_H\n+#define TSAN_ILIST_H\n+\n+#include \"sanitizer_common/sanitizer_internal_defs.h\"\n+\n+namespace __tsan {\n+\n+class INode {\n+ public:\n+  INode() = default;\n+\n+ private:\n+  INode* next_ = nullptr;\n+  INode* prev_ = nullptr;\n+\n+  template <typename Base, INode Base::*Node, typename Elem>\n+  friend class IList;\n+  INode(const INode&) = delete;\n+  void operator=(const INode&) = delete;\n+};\n+\n+// Intrusive doubly-linked list.\n+//\n+// The node class (MyNode) needs to include \"INode foo\" field,\n+// then the list can be declared as IList<MyNode, &MyNode::foo>.\n+// This design allows to link MyNode into multiple lists using\n+// different INode fields.\n+// The optional Elem template argument allows to specify node MDT\n+// (most derived type) if it's different from MyNode.\n+template <typename Base, INode Base::*Node, typename Elem = Base>\n+class IList {\n+ public:\n+  IList();\n+\n+  void PushFront(Elem* e);\n+  void PushBack(Elem* e);\n+  void Remove(Elem* e);\n+\n+  Elem* PopFront();\n+  Elem* PopBack();\n+  Elem* Front();\n+  Elem* Back();\n+\n+  // Prev links point towards front of the queue.\n+  Elem* Prev(Elem* e);\n+  // Next links point towards back of the queue.\n+  Elem* Next(Elem* e);\n+\n+  uptr Size() const;\n+  bool Empty() const;\n+  bool Queued(Elem* e) const;\n+\n+ private:\n+  INode node_;\n+  uptr size_ = 0;\n+\n+  void Push(Elem* e, INode* after);\n+  static INode* ToNode(Elem* e);\n+  static Elem* ToElem(INode* n);\n+\n+  IList(const IList&) = delete;\n+  void operator=(const IList&) = delete;\n+};\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+IList<Base, Node, Elem>::IList() {\n+  node_.next_ = node_.prev_ = &node_;\n+}\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+void IList<Base, Node, Elem>::PushFront(Elem* e) {\n+  Push(e, &node_);\n+}\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+void IList<Base, Node, Elem>::PushBack(Elem* e) {\n+  Push(e, node_.prev_);\n+}\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+void IList<Base, Node, Elem>::Push(Elem* e, INode* after) {\n+  INode* n = ToNode(e);\n+  DCHECK_EQ(n->next_, nullptr);\n+  DCHECK_EQ(n->prev_, nullptr);\n+  INode* next = after->next_;\n+  n->next_ = next;\n+  n->prev_ = after;\n+  next->prev_ = n;\n+  after->next_ = n;\n+  size_++;\n+}\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+void IList<Base, Node, Elem>::Remove(Elem* e) {\n+  INode* n = ToNode(e);\n+  INode* next = n->next_;\n+  INode* prev = n->prev_;\n+  DCHECK(next);\n+  DCHECK(prev);\n+  DCHECK(size_);\n+  next->prev_ = prev;\n+  prev->next_ = next;\n+  n->prev_ = n->next_ = nullptr;\n+  size_--;\n+}\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+Elem* IList<Base, Node, Elem>::PopFront() {\n+  Elem* e = Front();\n+  if (e)\n+    Remove(e);\n+  return e;\n+}\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+Elem* IList<Base, Node, Elem>::PopBack() {\n+  Elem* e = Back();\n+  if (e)\n+    Remove(e);\n+  return e;\n+}\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+Elem* IList<Base, Node, Elem>::Front() {\n+  return size_ ? ToElem(node_.next_) : nullptr;\n+}\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+Elem* IList<Base, Node, Elem>::Back() {\n+  return size_ ? ToElem(node_.prev_) : nullptr;\n+}\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+Elem* IList<Base, Node, Elem>::Prev(Elem* e) {\n+  INode* n = ToNode(e);\n+  DCHECK(n->prev_);\n+  return n->prev_ != &node_ ? ToElem(n->prev_) : nullptr;\n+}\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+Elem* IList<Base, Node, Elem>::Next(Elem* e) {\n+  INode* n = ToNode(e);\n+  DCHECK(n->next_);\n+  return n->next_ != &node_ ? ToElem(n->next_) : nullptr;\n+}\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+uptr IList<Base, Node, Elem>::Size() const {\n+  return size_;\n+}\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+bool IList<Base, Node, Elem>::Empty() const {\n+  return size_ == 0;\n+}\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+bool IList<Base, Node, Elem>::Queued(Elem* e) const {\n+  INode* n = ToNode(e);\n+  DCHECK_EQ(!n->next_, !n->prev_);\n+  return n->next_;\n+}\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+INode* IList<Base, Node, Elem>::ToNode(Elem* e) {\n+  return &(e->*Node);\n+}\n+\n+template <typename Base, INode Base::*Node, typename Elem>\n+Elem* IList<Base, Node, Elem>::ToElem(INode* n) {\n+  return static_cast<Elem*>(reinterpret_cast<Base*>(\n+      reinterpret_cast<uptr>(n) -\n+      reinterpret_cast<uptr>(&(reinterpret_cast<Elem*>(0)->*Node))));\n+}\n+\n+}  // namespace __tsan\n+\n+#endif"}, {"sha": "a855d1d8deab8c9f8e4c9c31faddb775121d4f97", "filename": "libsanitizer/tsan/tsan_interceptors.h", "status": "modified", "additions": 21, "deletions": 14, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interceptors.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interceptors.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_interceptors.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -10,13 +10,22 @@ class ScopedInterceptor {\n  public:\n   ScopedInterceptor(ThreadState *thr, const char *fname, uptr pc);\n   ~ScopedInterceptor();\n-  void DisableIgnores();\n-  void EnableIgnores();\n+  void DisableIgnores() {\n+    if (UNLIKELY(ignoring_))\n+      DisableIgnoresImpl();\n+  }\n+  void EnableIgnores() {\n+    if (UNLIKELY(ignoring_))\n+      EnableIgnoresImpl();\n+  }\n+\n  private:\n   ThreadState *const thr_;\n-  const uptr pc_;\n   bool in_ignored_lib_;\n   bool ignoring_;\n+\n+  void DisableIgnoresImpl();\n+  void EnableIgnoresImpl();\n };\n \n LibIgnore *libignore();\n@@ -36,18 +45,16 @@ inline bool in_symbolizer() {\n   const uptr caller_pc = GET_CALLER_PC();      \\\n   ScopedInterceptor si(thr, #func, caller_pc); \\\n   const uptr pc = GET_CURRENT_PC();            \\\n-  (void)pc;                                    \\\n-  /**/\n+  (void)pc;\n \n-#define SCOPED_TSAN_INTERCEPTOR(func, ...) \\\n-    SCOPED_INTERCEPTOR_RAW(func, __VA_ARGS__); \\\n-    if (REAL(func) == 0) { \\\n-      Report(\"FATAL: ThreadSanitizer: failed to intercept %s\\n\", #func); \\\n-      Die(); \\\n-    }                                                    \\\n-    if (!thr->is_inited || thr->ignore_interceptors || thr->in_ignored_lib) \\\n-      return REAL(func)(__VA_ARGS__); \\\n-/**/\n+#define SCOPED_TSAN_INTERCEPTOR(func, ...)                                \\\n+  SCOPED_INTERCEPTOR_RAW(func, __VA_ARGS__);                              \\\n+  if (REAL(func) == 0) {                                                  \\\n+    Report(\"FATAL: ThreadSanitizer: failed to intercept %s\\n\", #func);    \\\n+    Die();                                                                \\\n+  }                                                                       \\\n+  if (!thr->is_inited || thr->ignore_interceptors || thr->in_ignored_lib) \\\n+    return REAL(func)(__VA_ARGS__);\n \n #define SCOPED_TSAN_INTERCEPTOR_USER_CALLBACK_START() \\\n     si.DisableIgnores();"}, {"sha": "ed064150d005cd6e0228b21d8841ab0f889ca292", "filename": "libsanitizer/tsan/tsan_interceptors_mac.cpp", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interceptors_mac.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interceptors_mac.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_interceptors_mac.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -365,7 +365,7 @@ static uptr GetOrCreateSyncAddress(uptr addr, ThreadState *thr, uptr pc) {\n   if (h.created()) {\n     ThreadIgnoreBegin(thr, pc);\n     *h = (uptr) user_alloc(thr, pc, /*size=*/1);\n-    ThreadIgnoreEnd(thr, pc);\n+    ThreadIgnoreEnd(thr);\n   }\n   return *h;\n }\n@@ -405,8 +405,8 @@ TSAN_INTERCEPTOR(int, swapcontext, ucontext_t *oucp, const ucontext_t *ucp) {\n   {\n     SCOPED_INTERCEPTOR_RAW(swapcontext, oucp, ucp);\n   }\n-  // Bacause of swapcontext() semantics we have no option but to copy its\n-  // impementation here\n+  // Because of swapcontext() semantics we have no option but to copy its\n+  // implementation here\n   if (!oucp || !ucp) {\n     errno = EINVAL;\n     return -1;"}, {"sha": "d3e4c8f03714cf41169cded4f548017a0d907f1d", "filename": "libsanitizer/tsan/tsan_interceptors_posix.cpp", "status": "modified", "additions": 218, "deletions": 199, "changes": 417, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interceptors_posix.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interceptors_posix.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_interceptors_posix.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -96,9 +96,6 @@ extern \"C\" void _exit(int status);\n extern \"C\" int fileno_unlocked(void *stream);\n extern \"C\" int dirfd(void *dirp);\n #endif\n-#if SANITIZER_GLIBC\n-extern \"C\" int mallopt(int param, int value);\n-#endif\n #if SANITIZER_NETBSD\n extern __sanitizer_FILE __sF[];\n #else\n@@ -161,15 +158,13 @@ const int SIG_SETMASK = 2;\n namespace __tsan {\n struct SignalDesc {\n   bool armed;\n-  bool sigaction;\n   __sanitizer_siginfo siginfo;\n   ucontext_t ctx;\n };\n \n struct ThreadSignalContext {\n   int int_signal_send;\n   atomic_uintptr_t in_blocking_func;\n-  atomic_uintptr_t have_pending_signals;\n   SignalDesc pending_signals[kSigCount];\n   // emptyset and oldset are too big for stack.\n   __sanitizer_sigset_t emptyset;\n@@ -196,12 +191,10 @@ struct InterceptorContext {\n   unsigned finalize_key;\n #endif\n \n-  BlockingMutex atexit_mu;\n+  Mutex atexit_mu;\n   Vector<struct AtExitCtx *> AtExitStack;\n \n-  InterceptorContext()\n-      : libignore(LINKER_INITIALIZED), AtExitStack() {\n-  }\n+  InterceptorContext() : libignore(LINKER_INITIALIZED), atexit_mu(MutexTypeAtExit), AtExitStack() {}\n };\n \n static ALIGNED(64) char interceptor_placeholder[sizeof(InterceptorContext)];\n@@ -250,8 +243,8 @@ static ThreadSignalContext *SigCtx(ThreadState *thr) {\n \n ScopedInterceptor::ScopedInterceptor(ThreadState *thr, const char *fname,\n                                      uptr pc)\n-    : thr_(thr), pc_(pc), in_ignored_lib_(false), ignoring_(false) {\n-  Initialize(thr);\n+    : thr_(thr), in_ignored_lib_(false), ignoring_(false) {\n+  LazyInitialize(thr);\n   if (!thr_->is_inited) return;\n   if (!thr_->ignore_interceptors) FuncEntry(thr, pc);\n   DPrintf(\"#%d: intercept %s()\\n\", thr_->tid, fname);\n@@ -267,29 +260,29 @@ ScopedInterceptor::~ScopedInterceptor() {\n   if (!thr_->ignore_interceptors) {\n     ProcessPendingSignals(thr_);\n     FuncExit(thr_);\n-    CheckNoLocks(thr_);\n+    CheckedMutex::CheckNoLocks();\n   }\n }\n \n-void ScopedInterceptor::EnableIgnores() {\n-  if (ignoring_) {\n-    ThreadIgnoreBegin(thr_, pc_, /*save_stack=*/false);\n-    if (flags()->ignore_noninstrumented_modules) thr_->suppress_reports++;\n-    if (in_ignored_lib_) {\n-      DCHECK(!thr_->in_ignored_lib);\n-      thr_->in_ignored_lib = true;\n-    }\n+NOINLINE\n+void ScopedInterceptor::EnableIgnoresImpl() {\n+  ThreadIgnoreBegin(thr_, 0);\n+  if (flags()->ignore_noninstrumented_modules)\n+    thr_->suppress_reports++;\n+  if (in_ignored_lib_) {\n+    DCHECK(!thr_->in_ignored_lib);\n+    thr_->in_ignored_lib = true;\n   }\n }\n \n-void ScopedInterceptor::DisableIgnores() {\n-  if (ignoring_) {\n-    ThreadIgnoreEnd(thr_, pc_);\n-    if (flags()->ignore_noninstrumented_modules) thr_->suppress_reports--;\n-    if (in_ignored_lib_) {\n-      DCHECK(thr_->in_ignored_lib);\n-      thr_->in_ignored_lib = false;\n-    }\n+NOINLINE\n+void ScopedInterceptor::DisableIgnoresImpl() {\n+  ThreadIgnoreEnd(thr_);\n+  if (flags()->ignore_noninstrumented_modules)\n+    thr_->suppress_reports--;\n+  if (in_ignored_lib_) {\n+    DCHECK(thr_->in_ignored_lib);\n+    thr_->in_ignored_lib = false;\n   }\n }\n \n@@ -325,7 +318,7 @@ struct BlockingCall {\n       , ctx(SigCtx(thr)) {\n     for (;;) {\n       atomic_store(&ctx->in_blocking_func, 1, memory_order_relaxed);\n-      if (atomic_load(&ctx->have_pending_signals, memory_order_relaxed) == 0)\n+      if (atomic_load(&thr->pending_signals, memory_order_relaxed) == 0)\n         break;\n       atomic_store(&ctx->in_blocking_func, 0, memory_order_relaxed);\n       ProcessPendingSignals(thr);\n@@ -377,7 +370,7 @@ static void at_exit_wrapper() {\n   AtExitCtx *ctx;\n   {\n     // Ensure thread-safety.\n-    BlockingMutexLock l(&interceptor_ctx()->atexit_mu);\n+    Lock l(&interceptor_ctx()->atexit_mu);\n \n     // Pop AtExitCtx from the top of the stack of callback functions\n     uptr element = interceptor_ctx()->AtExitStack.Size() - 1;\n@@ -387,14 +380,14 @@ static void at_exit_wrapper() {\n \n   Acquire(cur_thread(), (uptr)0, (uptr)ctx);\n   ((void(*)())ctx->f)();\n-  InternalFree(ctx);\n+  Free(ctx);\n }\n \n static void cxa_at_exit_wrapper(void *arg) {\n   Acquire(cur_thread(), 0, (uptr)arg);\n   AtExitCtx *ctx = (AtExitCtx*)arg;\n   ((void(*)(void *arg))ctx->f)(ctx->arg);\n-  InternalFree(ctx);\n+  Free(ctx);\n }\n \n static int setup_at_exit_wrapper(ThreadState *thr, uptr pc, void(*f)(),\n@@ -420,7 +413,7 @@ TSAN_INTERCEPTOR(int, __cxa_atexit, void (*f)(void *a), void *arg, void *dso) {\n \n static int setup_at_exit_wrapper(ThreadState *thr, uptr pc, void(*f)(),\n       void *arg, void *dso) {\n-  AtExitCtx *ctx = (AtExitCtx*)InternalAlloc(sizeof(AtExitCtx));\n+  auto *ctx = New<AtExitCtx>();\n   ctx->f = f;\n   ctx->arg = arg;\n   Release(thr, pc, (uptr)ctx);\n@@ -433,7 +426,10 @@ static int setup_at_exit_wrapper(ThreadState *thr, uptr pc, void(*f)(),\n     // Store ctx in a local stack-like structure\n \n     // Ensure thread-safety.\n-    BlockingMutexLock l(&interceptor_ctx()->atexit_mu);\n+    Lock l(&interceptor_ctx()->atexit_mu);\n+    // __cxa_atexit calls calloc. If we don't ignore interceptors, we will fail\n+    // due to atexit_mu held on exit from the calloc interceptor.\n+    ScopedIgnoreInterceptors ignore;\n \n     res = REAL(__cxa_atexit)((void (*)(void *a))at_exit_wrapper, 0, 0);\n     // Push AtExitCtx on the top of the stack of callback functions\n@@ -443,7 +439,7 @@ static int setup_at_exit_wrapper(ThreadState *thr, uptr pc, void(*f)(),\n   } else {\n     res = REAL(__cxa_atexit)(cxa_at_exit_wrapper, ctx, dso);\n   }\n-  ThreadIgnoreEnd(thr, pc);\n+  ThreadIgnoreEnd(thr);\n   return res;\n }\n \n@@ -454,22 +450,22 @@ static void on_exit_wrapper(int status, void *arg) {\n   Acquire(thr, pc, (uptr)arg);\n   AtExitCtx *ctx = (AtExitCtx*)arg;\n   ((void(*)(int status, void *arg))ctx->f)(status, ctx->arg);\n-  InternalFree(ctx);\n+  Free(ctx);\n }\n \n TSAN_INTERCEPTOR(int, on_exit, void(*f)(int, void*), void *arg) {\n   if (in_symbolizer())\n     return 0;\n   SCOPED_TSAN_INTERCEPTOR(on_exit, f, arg);\n-  AtExitCtx *ctx = (AtExitCtx*)InternalAlloc(sizeof(AtExitCtx));\n+  auto *ctx = New<AtExitCtx>();\n   ctx->f = (void(*)())f;\n   ctx->arg = arg;\n   Release(thr, pc, (uptr)ctx);\n   // Memory allocation in __cxa_atexit will race with free during exit,\n   // because we do not see synchronization around atexit callback list.\n   ThreadIgnoreBegin(thr, pc);\n   int res = REAL(on_exit)(on_exit_wrapper, ctx);\n-  ThreadIgnoreEnd(thr, pc);\n+  ThreadIgnoreEnd(thr);\n   return res;\n }\n #define TSAN_MAYBE_INTERCEPT_ON_EXIT TSAN_INTERCEPT(on_exit)\n@@ -848,6 +844,53 @@ TSAN_INTERCEPTOR(int, posix_memalign, void **memptr, uptr align, uptr sz) {\n }\n #endif\n \n+// Both __cxa_guard_acquire and pthread_once 0-initialize\n+// the object initially. pthread_once does not have any\n+// other ABI requirements. __cxa_guard_acquire assumes\n+// that any non-0 value in the first byte means that\n+// initialization is completed. Contents of the remaining\n+// bytes are up to us.\n+constexpr u32 kGuardInit = 0;\n+constexpr u32 kGuardDone = 1;\n+constexpr u32 kGuardRunning = 1 << 16;\n+constexpr u32 kGuardWaiter = 1 << 17;\n+\n+static int guard_acquire(ThreadState *thr, uptr pc, atomic_uint32_t *g,\n+                         bool blocking_hooks = true) {\n+  if (blocking_hooks)\n+    OnPotentiallyBlockingRegionBegin();\n+  auto on_exit = at_scope_exit([blocking_hooks] {\n+    if (blocking_hooks)\n+      OnPotentiallyBlockingRegionEnd();\n+  });\n+\n+  for (;;) {\n+    u32 cmp = atomic_load(g, memory_order_acquire);\n+    if (cmp == kGuardInit) {\n+      if (atomic_compare_exchange_strong(g, &cmp, kGuardRunning,\n+                                         memory_order_relaxed))\n+        return 1;\n+    } else if (cmp == kGuardDone) {\n+      if (!thr->in_ignored_lib)\n+        Acquire(thr, pc, (uptr)g);\n+      return 0;\n+    } else {\n+      if ((cmp & kGuardWaiter) ||\n+          atomic_compare_exchange_strong(g, &cmp, cmp | kGuardWaiter,\n+                                         memory_order_relaxed))\n+        FutexWait(g, cmp | kGuardWaiter);\n+    }\n+  }\n+}\n+\n+static void guard_release(ThreadState *thr, uptr pc, atomic_uint32_t *g) {\n+  if (!thr->in_ignored_lib)\n+    Release(thr, pc, (uptr)g);\n+  u32 old = atomic_exchange(g, kGuardDone, memory_order_release);\n+  if (old & kGuardWaiter)\n+    FutexWake(g, 1 << 30);\n+}\n+\n // __cxa_guard_acquire and friends need to be intercepted in a special way -\n // regular interceptors will break statically-linked libstdc++. Linux\n // interceptors are especially defined as weak functions (so that they don't\n@@ -868,31 +911,17 @@ TSAN_INTERCEPTOR(int, posix_memalign, void **memptr, uptr align, uptr sz) {\n // Used in thread-safe function static initialization.\n STDCXX_INTERCEPTOR(int, __cxa_guard_acquire, atomic_uint32_t *g) {\n   SCOPED_INTERCEPTOR_RAW(__cxa_guard_acquire, g);\n-  OnPotentiallyBlockingRegionBegin();\n-  auto on_exit = at_scope_exit(&OnPotentiallyBlockingRegionEnd);\n-  for (;;) {\n-    u32 cmp = atomic_load(g, memory_order_acquire);\n-    if (cmp == 0) {\n-      if (atomic_compare_exchange_strong(g, &cmp, 1<<16, memory_order_relaxed))\n-        return 1;\n-    } else if (cmp == 1) {\n-      Acquire(thr, pc, (uptr)g);\n-      return 0;\n-    } else {\n-      internal_sched_yield();\n-    }\n-  }\n+  return guard_acquire(thr, pc, g);\n }\n \n STDCXX_INTERCEPTOR(void, __cxa_guard_release, atomic_uint32_t *g) {\n   SCOPED_INTERCEPTOR_RAW(__cxa_guard_release, g);\n-  Release(thr, pc, (uptr)g);\n-  atomic_store(g, 1, memory_order_release);\n+  guard_release(thr, pc, g);\n }\n \n STDCXX_INTERCEPTOR(void, __cxa_guard_abort, atomic_uint32_t *g) {\n   SCOPED_INTERCEPTOR_RAW(__cxa_guard_abort, g);\n-  atomic_store(g, 0, memory_order_relaxed);\n+  atomic_store(g, kGuardInit, memory_order_relaxed);\n }\n \n namespace __tsan {\n@@ -934,14 +963,15 @@ static void thread_finalize(void *v) {\n struct ThreadParam {\n   void* (*callback)(void *arg);\n   void *param;\n-  atomic_uintptr_t tid;\n+  Tid tid;\n+  Semaphore created;\n+  Semaphore started;\n };\n \n extern \"C\" void *__tsan_thread_start_func(void *arg) {\n   ThreadParam *p = (ThreadParam*)arg;\n   void* (*callback)(void *arg) = p->callback;\n   void *param = p->param;\n-  int tid = 0;\n   {\n     cur_thread_init();\n     ThreadState *thr = cur_thread();\n@@ -954,14 +984,13 @@ extern \"C\" void *__tsan_thread_start_func(void *arg) {\n       Printf(\"ThreadSanitizer: failed to set thread key\\n\");\n       Die();\n     }\n-    ThreadIgnoreEnd(thr, 0);\n+    ThreadIgnoreEnd(thr);\n #endif\n-    while ((tid = atomic_load(&p->tid, memory_order_acquire)) == 0)\n-      internal_sched_yield();\n+    p->created.Wait();\n     Processor *proc = ProcCreate();\n     ProcWire(proc, thr);\n-    ThreadStart(thr, tid, GetTid(), ThreadType::Regular);\n-    atomic_store(&p->tid, 0, memory_order_release);\n+    ThreadStart(thr, p->tid, GetTid(), ThreadType::Regular);\n+    p->started.Post();\n   }\n   void *res = callback(param);\n   // Prevent the callback from being tail called,\n@@ -983,9 +1012,11 @@ TSAN_INTERCEPTOR(int, pthread_create,\n           \"fork is not supported. Dying (set die_after_fork=0 to override)\\n\");\n       Die();\n     } else {\n-      VPrintf(1, \"ThreadSanitizer: starting new threads after multi-threaded \"\n-          \"fork is not supported (pid %d). Continuing because of \"\n-          \"die_after_fork=0, but you are on your own\\n\", internal_getpid());\n+      VPrintf(1,\n+              \"ThreadSanitizer: starting new threads after multi-threaded \"\n+              \"fork is not supported (pid %lu). Continuing because of \"\n+              \"die_after_fork=0, but you are on your own\\n\",\n+              internal_getpid());\n     }\n   }\n   __sanitizer_pthread_attr_t myattr;\n@@ -1000,28 +1031,27 @@ TSAN_INTERCEPTOR(int, pthread_create,\n   ThreadParam p;\n   p.callback = callback;\n   p.param = param;\n-  atomic_store(&p.tid, 0, memory_order_relaxed);\n+  p.tid = kMainTid;\n   int res = -1;\n   {\n     // Otherwise we see false positives in pthread stack manipulation.\n     ScopedIgnoreInterceptors ignore;\n     ThreadIgnoreBegin(thr, pc);\n     res = REAL(pthread_create)(th, attr, __tsan_thread_start_func, &p);\n-    ThreadIgnoreEnd(thr, pc);\n+    ThreadIgnoreEnd(thr);\n   }\n   if (res == 0) {\n-    int tid = ThreadCreate(thr, pc, *(uptr*)th, IsStateDetached(detached));\n-    CHECK_NE(tid, 0);\n+    p.tid = ThreadCreate(thr, pc, *(uptr *)th, IsStateDetached(detached));\n+    CHECK_NE(p.tid, kMainTid);\n     // Synchronization on p.tid serves two purposes:\n     // 1. ThreadCreate must finish before the new thread starts.\n     //    Otherwise the new thread can call pthread_detach, but the pthread_t\n     //    identifier is not yet registered in ThreadRegistry by ThreadCreate.\n     // 2. ThreadStart must finish before this thread continues.\n     //    Otherwise, this thread can call pthread_detach and reset thr->sync\n     //    before the new thread got a chance to acquire from it in ThreadStart.\n-    atomic_store(&p.tid, tid, memory_order_release);\n-    while (atomic_load(&p.tid, memory_order_acquire) != 0)\n-      internal_sched_yield();\n+    p.created.Post();\n+    p.started.Wait();\n   }\n   if (attr == &myattr)\n     pthread_attr_destroy(&myattr);\n@@ -1030,10 +1060,10 @@ TSAN_INTERCEPTOR(int, pthread_create,\n \n TSAN_INTERCEPTOR(int, pthread_join, void *th, void **ret) {\n   SCOPED_INTERCEPTOR_RAW(pthread_join, th, ret);\n-  int tid = ThreadConsumeTid(thr, pc, (uptr)th);\n+  Tid tid = ThreadConsumeTid(thr, pc, (uptr)th);\n   ThreadIgnoreBegin(thr, pc);\n   int res = BLOCK_REAL(pthread_join)(th, ret);\n-  ThreadIgnoreEnd(thr, pc);\n+  ThreadIgnoreEnd(thr);\n   if (res == 0) {\n     ThreadJoin(thr, pc, tid);\n   }\n@@ -1044,7 +1074,7 @@ DEFINE_REAL_PTHREAD_FUNCTIONS\n \n TSAN_INTERCEPTOR(int, pthread_detach, void *th) {\n   SCOPED_INTERCEPTOR_RAW(pthread_detach, th);\n-  int tid = ThreadConsumeTid(thr, pc, (uptr)th);\n+  Tid tid = ThreadConsumeTid(thr, pc, (uptr)th);\n   int res = REAL(pthread_detach)(th);\n   if (res == 0) {\n     ThreadDetach(thr, pc, tid);\n@@ -1065,10 +1095,10 @@ TSAN_INTERCEPTOR(void, pthread_exit, void *retval) {\n #if SANITIZER_LINUX\n TSAN_INTERCEPTOR(int, pthread_tryjoin_np, void *th, void **ret) {\n   SCOPED_INTERCEPTOR_RAW(pthread_tryjoin_np, th, ret);\n-  int tid = ThreadConsumeTid(thr, pc, (uptr)th);\n+  Tid tid = ThreadConsumeTid(thr, pc, (uptr)th);\n   ThreadIgnoreBegin(thr, pc);\n   int res = REAL(pthread_tryjoin_np)(th, ret);\n-  ThreadIgnoreEnd(thr, pc);\n+  ThreadIgnoreEnd(thr);\n   if (res == 0)\n     ThreadJoin(thr, pc, tid);\n   else\n@@ -1079,10 +1109,10 @@ TSAN_INTERCEPTOR(int, pthread_tryjoin_np, void *th, void **ret) {\n TSAN_INTERCEPTOR(int, pthread_timedjoin_np, void *th, void **ret,\n                  const struct timespec *abstime) {\n   SCOPED_INTERCEPTOR_RAW(pthread_timedjoin_np, th, ret, abstime);\n-  int tid = ThreadConsumeTid(thr, pc, (uptr)th);\n+  Tid tid = ThreadConsumeTid(thr, pc, (uptr)th);\n   ThreadIgnoreBegin(thr, pc);\n   int res = BLOCK_REAL(pthread_timedjoin_np)(th, ret, abstime);\n-  ThreadIgnoreEnd(thr, pc);\n+  ThreadIgnoreEnd(thr);\n   if (res == 0)\n     ThreadJoin(thr, pc, tid);\n   else\n@@ -1446,24 +1476,24 @@ TSAN_INTERCEPTOR(int, pthread_rwlock_unlock, void *m) {\n #if !SANITIZER_MAC\n TSAN_INTERCEPTOR(int, pthread_barrier_init, void *b, void *a, unsigned count) {\n   SCOPED_TSAN_INTERCEPTOR(pthread_barrier_init, b, a, count);\n-  MemoryWrite(thr, pc, (uptr)b, kSizeLog1);\n+  MemoryAccess(thr, pc, (uptr)b, 1, kAccessWrite);\n   int res = REAL(pthread_barrier_init)(b, a, count);\n   return res;\n }\n \n TSAN_INTERCEPTOR(int, pthread_barrier_destroy, void *b) {\n   SCOPED_TSAN_INTERCEPTOR(pthread_barrier_destroy, b);\n-  MemoryWrite(thr, pc, (uptr)b, kSizeLog1);\n+  MemoryAccess(thr, pc, (uptr)b, 1, kAccessWrite);\n   int res = REAL(pthread_barrier_destroy)(b);\n   return res;\n }\n \n TSAN_INTERCEPTOR(int, pthread_barrier_wait, void *b) {\n   SCOPED_TSAN_INTERCEPTOR(pthread_barrier_wait, b);\n   Release(thr, pc, (uptr)b);\n-  MemoryRead(thr, pc, (uptr)b, kSizeLog1);\n+  MemoryAccess(thr, pc, (uptr)b, 1, kAccessRead);\n   int res = REAL(pthread_barrier_wait)(b);\n-  MemoryRead(thr, pc, (uptr)b, kSizeLog1);\n+  MemoryAccess(thr, pc, (uptr)b, 1, kAccessRead);\n   if (res == 0 || res == PTHREAD_BARRIER_SERIAL_THREAD) {\n     Acquire(thr, pc, (uptr)b);\n   }\n@@ -1485,20 +1515,11 @@ TSAN_INTERCEPTOR(int, pthread_once, void *o, void (*f)()) {\n   else\n     a = static_cast<atomic_uint32_t*>(o);\n \n-  u32 v = atomic_load(a, memory_order_acquire);\n-  if (v == 0 && atomic_compare_exchange_strong(a, &v, 1,\n-                                               memory_order_relaxed)) {\n+  // Mac OS X appears to use pthread_once() where calling BlockingRegion hooks\n+  // result in crashes due to too little stack space.\n+  if (guard_acquire(thr, pc, a, !SANITIZER_MAC)) {\n     (*f)();\n-    if (!thr->in_ignored_lib)\n-      Release(thr, pc, (uptr)o);\n-    atomic_store(a, 2, memory_order_release);\n-  } else {\n-    while (v != 2) {\n-      internal_sched_yield();\n-      v = atomic_load(a, memory_order_acquire);\n-    }\n-    if (!thr->in_ignored_lib)\n-      Acquire(thr, pc, (uptr)o);\n+    guard_release(thr, pc, a);\n   }\n   return 0;\n }\n@@ -1932,45 +1953,68 @@ TSAN_INTERCEPTOR(int, pthread_sigmask, int how, const __sanitizer_sigset_t *set,\n \n namespace __tsan {\n \n+static void ReportErrnoSpoiling(ThreadState *thr, uptr pc) {\n+  VarSizeStackTrace stack;\n+  // StackTrace::GetNestInstructionPc(pc) is used because return address is\n+  // expected, OutputReport() will undo this.\n+  ObtainCurrentStack(thr, StackTrace::GetNextInstructionPc(pc), &stack);\n+  ThreadRegistryLock l(&ctx->thread_registry);\n+  ScopedReport rep(ReportTypeErrnoInSignal);\n+  if (!IsFiredSuppression(ctx, ReportTypeErrnoInSignal, stack)) {\n+    rep.AddStack(stack, true);\n+    OutputReport(thr, rep);\n+  }\n+}\n+\n static void CallUserSignalHandler(ThreadState *thr, bool sync, bool acquire,\n-                                  bool sigact, int sig,\n-                                  __sanitizer_siginfo *info, void *uctx) {\n+                                  int sig, __sanitizer_siginfo *info,\n+                                  void *uctx) {\n   __sanitizer_sigaction *sigactions = interceptor_ctx()->sigactions;\n   if (acquire)\n     Acquire(thr, 0, (uptr)&sigactions[sig]);\n   // Signals are generally asynchronous, so if we receive a signals when\n   // ignores are enabled we should disable ignores. This is critical for sync\n-  // and interceptors, because otherwise we can miss syncronization and report\n+  // and interceptors, because otherwise we can miss synchronization and report\n   // false races.\n   int ignore_reads_and_writes = thr->ignore_reads_and_writes;\n   int ignore_interceptors = thr->ignore_interceptors;\n   int ignore_sync = thr->ignore_sync;\n+  // For symbolizer we only process SIGSEGVs synchronously\n+  // (bug in symbolizer or in tsan). But we want to reset\n+  // in_symbolizer to fail gracefully. Symbolizer and user code\n+  // use different memory allocators, so if we don't reset\n+  // in_symbolizer we can get memory allocated with one being\n+  // feed with another, which can cause more crashes.\n+  int in_symbolizer = thr->in_symbolizer;\n   if (!ctx->after_multithreaded_fork) {\n     thr->ignore_reads_and_writes = 0;\n     thr->fast_state.ClearIgnoreBit();\n     thr->ignore_interceptors = 0;\n     thr->ignore_sync = 0;\n+    thr->in_symbolizer = 0;\n   }\n   // Ensure that the handler does not spoil errno.\n   const int saved_errno = errno;\n   errno = 99;\n   // This code races with sigaction. Be careful to not read sa_sigaction twice.\n   // Also need to remember pc for reporting before the call,\n   // because the handler can reset it.\n-  volatile uptr pc =\n-      sigact ? (uptr)sigactions[sig].sigaction : (uptr)sigactions[sig].handler;\n+  volatile uptr pc = (sigactions[sig].sa_flags & SA_SIGINFO)\n+                         ? (uptr)sigactions[sig].sigaction\n+                         : (uptr)sigactions[sig].handler;\n   if (pc != sig_dfl && pc != sig_ign) {\n-    if (sigact)\n-      ((__sanitizer_sigactionhandler_ptr)pc)(sig, info, uctx);\n-    else\n-      ((__sanitizer_sighandler_ptr)pc)(sig);\n+    // The callback can be either sa_handler or sa_sigaction.\n+    // They have different signatures, but we assume that passing\n+    // additional arguments to sa_handler works and is harmless.\n+    ((__sanitizer_sigactionhandler_ptr)pc)(sig, info, uctx);\n   }\n   if (!ctx->after_multithreaded_fork) {\n     thr->ignore_reads_and_writes = ignore_reads_and_writes;\n     if (ignore_reads_and_writes)\n       thr->fast_state.SetIgnoreBit();\n     thr->ignore_interceptors = ignore_interceptors;\n     thr->ignore_sync = ignore_sync;\n+    thr->in_symbolizer = in_symbolizer;\n   }\n   // We do not detect errno spoiling for SIGTERM,\n   // because some SIGTERM handlers do spoil errno but reraise SIGTERM,\n@@ -1980,27 +2024,16 @@ static void CallUserSignalHandler(ThreadState *thr, bool sync, bool acquire,\n   // from rtl_generic_sighandler) we have not yet received the reraised\n   // signal; and it looks too fragile to intercept all ways to reraise a signal.\n   if (ShouldReport(thr, ReportTypeErrnoInSignal) && !sync && sig != SIGTERM &&\n-      errno != 99) {\n-    VarSizeStackTrace stack;\n-    // StackTrace::GetNestInstructionPc(pc) is used because return address is\n-    // expected, OutputReport() will undo this.\n-    ObtainCurrentStack(thr, StackTrace::GetNextInstructionPc(pc), &stack);\n-    ThreadRegistryLock l(ctx->thread_registry);\n-    ScopedReport rep(ReportTypeErrnoInSignal);\n-    if (!IsFiredSuppression(ctx, ReportTypeErrnoInSignal, stack)) {\n-      rep.AddStack(stack, true);\n-      OutputReport(thr, rep);\n-    }\n-  }\n+      errno != 99)\n+    ReportErrnoSpoiling(thr, pc);\n   errno = saved_errno;\n }\n \n-void ProcessPendingSignals(ThreadState *thr) {\n+void ProcessPendingSignalsImpl(ThreadState *thr) {\n+  atomic_store(&thr->pending_signals, 0, memory_order_relaxed);\n   ThreadSignalContext *sctx = SigCtx(thr);\n-  if (sctx == 0 ||\n-      atomic_load(&sctx->have_pending_signals, memory_order_relaxed) == 0)\n+  if (sctx == 0)\n     return;\n-  atomic_store(&sctx->have_pending_signals, 0, memory_order_relaxed);\n   atomic_fetch_add(&thr->in_signal_handler, 1, memory_order_relaxed);\n   internal_sigfillset(&sctx->emptyset);\n   int res = REAL(pthread_sigmask)(SIG_SETMASK, &sctx->emptyset, &sctx->oldset);\n@@ -2009,8 +2042,8 @@ void ProcessPendingSignals(ThreadState *thr) {\n     SignalDesc *signal = &sctx->pending_signals[sig];\n     if (signal->armed) {\n       signal->armed = false;\n-      CallUserSignalHandler(thr, false, true, signal->sigaction, sig,\n-          &signal->siginfo, &signal->ctx);\n+      CallUserSignalHandler(thr, false, true, sig, &signal->siginfo,\n+                            &signal->ctx);\n     }\n   }\n   res = REAL(pthread_sigmask)(SIG_SETMASK, &sctx->oldset, 0);\n@@ -2027,9 +2060,7 @@ static bool is_sync_signal(ThreadSignalContext *sctx, int sig) {\n          (sctx && sig == sctx->int_signal_send);\n }\n \n-void ALWAYS_INLINE rtl_generic_sighandler(bool sigact, int sig,\n-                                          __sanitizer_siginfo *info,\n-                                          void *ctx) {\n+void sighandler(int sig, __sanitizer_siginfo *info, void *ctx) {\n   cur_thread_init();\n   ThreadState *thr = cur_thread();\n   ThreadSignalContext *sctx = SigCtx(thr);\n@@ -2047,7 +2078,7 @@ void ALWAYS_INLINE rtl_generic_sighandler(bool sigact, int sig,\n     atomic_fetch_add(&thr->in_signal_handler, 1, memory_order_relaxed);\n     if (sctx && atomic_load(&sctx->in_blocking_func, memory_order_relaxed)) {\n       atomic_store(&sctx->in_blocking_func, 0, memory_order_relaxed);\n-      CallUserSignalHandler(thr, sync, true, sigact, sig, info, ctx);\n+      CallUserSignalHandler(thr, sync, true, sig, info, ctx);\n       atomic_store(&sctx->in_blocking_func, 1, memory_order_relaxed);\n     } else {\n       // Be very conservative with when we do acquire in this case.\n@@ -2056,7 +2087,7 @@ void ALWAYS_INLINE rtl_generic_sighandler(bool sigact, int sig,\n       // SIGSYS looks relatively safe -- it's synchronous and can actually\n       // need some global state.\n       bool acq = (sig == SIGSYS);\n-      CallUserSignalHandler(thr, sync, acq, sigact, sig, info, ctx);\n+      CallUserSignalHandler(thr, sync, acq, sig, info, ctx);\n     }\n     atomic_fetch_add(&thr->in_signal_handler, -1, memory_order_relaxed);\n     return;\n@@ -2067,23 +2098,12 @@ void ALWAYS_INLINE rtl_generic_sighandler(bool sigact, int sig,\n   SignalDesc *signal = &sctx->pending_signals[sig];\n   if (signal->armed == false) {\n     signal->armed = true;\n-    signal->sigaction = sigact;\n-    if (info)\n-      internal_memcpy(&signal->siginfo, info, sizeof(*info));\n-    if (ctx)\n-      internal_memcpy(&signal->ctx, ctx, sizeof(signal->ctx));\n-    atomic_store(&sctx->have_pending_signals, 1, memory_order_relaxed);\n+    internal_memcpy(&signal->siginfo, info, sizeof(*info));\n+    internal_memcpy(&signal->ctx, ctx, sizeof(signal->ctx));\n+    atomic_store(&thr->pending_signals, 1, memory_order_relaxed);\n   }\n }\n \n-static void rtl_sighandler(int sig) {\n-  rtl_generic_sighandler(false, sig, 0, 0);\n-}\n-\n-static void rtl_sigaction(int sig, __sanitizer_siginfo *info, void *ctx) {\n-  rtl_generic_sighandler(true, sig, info, ctx);\n-}\n-\n TSAN_INTERCEPTOR(int, raise, int sig) {\n   SCOPED_TSAN_INTERCEPTOR(raise, sig);\n   ThreadSignalContext *sctx = SigCtx(thr);\n@@ -2142,7 +2162,7 @@ TSAN_INTERCEPTOR(int, getaddrinfo, void *node, void *service,\n   // inside of getaddrinfo. So ignore memory accesses.\n   ThreadIgnoreBegin(thr, pc);\n   int res = REAL(getaddrinfo)(node, service, hints, rv);\n-  ThreadIgnoreEnd(thr, pc);\n+  ThreadIgnoreEnd(thr);\n   return res;\n }\n \n@@ -2206,7 +2226,7 @@ struct dl_iterate_phdr_data {\n };\n \n static bool IsAppNotRodata(uptr addr) {\n-  return IsAppMem(addr) && *(u64*)MemToShadow(addr) != kShadowRodata;\n+  return IsAppMem(addr) && *MemToShadow(addr) != kShadowRodata;\n }\n \n static int dl_iterate_phdr_cb(__sanitizer_dl_phdr_info *info, SIZE_T size,\n@@ -2249,7 +2269,6 @@ static int OnExit(ThreadState *thr) {\n \n struct TsanInterceptorContext {\n   ThreadState *thr;\n-  const uptr caller_pc;\n   const uptr pc;\n };\n \n@@ -2290,17 +2309,17 @@ static void HandleRecvmsg(ThreadState *thr, uptr pc,\n                     ((TsanInterceptorContext *) ctx)->pc, (uptr) ptr, size, \\\n                     false)\n \n-#define COMMON_INTERCEPTOR_ENTER(ctx, func, ...)      \\\n-  SCOPED_TSAN_INTERCEPTOR(func, __VA_ARGS__);         \\\n-  TsanInterceptorContext _ctx = {thr, caller_pc, pc}; \\\n-  ctx = (void *)&_ctx;                                \\\n-  (void) ctx;\n+#define COMMON_INTERCEPTOR_ENTER(ctx, func, ...) \\\n+  SCOPED_TSAN_INTERCEPTOR(func, __VA_ARGS__);    \\\n+  TsanInterceptorContext _ctx = {thr, pc};       \\\n+  ctx = (void *)&_ctx;                           \\\n+  (void)ctx;\n \n #define COMMON_INTERCEPTOR_ENTER_NOIGNORE(ctx, func, ...) \\\n   SCOPED_INTERCEPTOR_RAW(func, __VA_ARGS__);              \\\n-  TsanInterceptorContext _ctx = {thr, caller_pc, pc};     \\\n+  TsanInterceptorContext _ctx = {thr, pc};                \\\n   ctx = (void *)&_ctx;                                    \\\n-  (void) ctx;\n+  (void)ctx;\n \n #define COMMON_INTERCEPTOR_FILE_OPEN(ctx, file, path) \\\n   if (path)                                           \\\n@@ -2347,7 +2366,7 @@ static void HandleRecvmsg(ThreadState *thr, uptr pc,\n   ThreadSetName(((TsanInterceptorContext *) ctx)->thr, name)\n \n #define COMMON_INTERCEPTOR_SET_PTHREAD_NAME(ctx, thread, name) \\\n-  __tsan::ctx->thread_registry->SetThreadNameByUserId(thread, name)\n+  __tsan::ctx->thread_registry.SetThreadNameByUserId(thread, name)\n \n #define COMMON_INTERCEPTOR_BLOCK_REAL(name) BLOCK_REAL(name)\n \n@@ -2419,9 +2438,13 @@ static __sanitizer_sighandler_ptr signal_impl(int sig,\n int sigaction_impl(int sig, const __sanitizer_sigaction *act,\n                    __sanitizer_sigaction *old) {\n   // Note: if we call REAL(sigaction) directly for any reason without proxying\n-  // the signal handler through rtl_sigaction, very bad things will happen.\n+  // the signal handler through sighandler, very bad things will happen.\n   // The handler will run synchronously and corrupt tsan per-thread state.\n   SCOPED_INTERCEPTOR_RAW(sigaction, sig, act, old);\n+  if (sig <= 0 || sig >= kSigCount) {\n+    errno = errno_EINVAL;\n+    return -1;\n+  }\n   __sanitizer_sigaction *sigactions = interceptor_ctx()->sigactions;\n   __sanitizer_sigaction old_stored;\n   if (old) internal_memcpy(&old_stored, &sigactions[sig], sizeof(old_stored));\n@@ -2443,22 +2466,17 @@ int sigaction_impl(int sig, const __sanitizer_sigaction *act,\n #endif\n     internal_memcpy(&newact, act, sizeof(newact));\n     internal_sigfillset(&newact.sa_mask);\n-    if ((uptr)act->handler != sig_ign && (uptr)act->handler != sig_dfl) {\n-      if (newact.sa_flags & SA_SIGINFO)\n-        newact.sigaction = rtl_sigaction;\n-      else\n-        newact.handler = rtl_sighandler;\n+    if ((act->sa_flags & SA_SIGINFO) ||\n+        ((uptr)act->handler != sig_ign && (uptr)act->handler != sig_dfl)) {\n+      newact.sa_flags |= SA_SIGINFO;\n+      newact.sigaction = sighandler;\n     }\n     ReleaseStore(thr, pc, (uptr)&sigactions[sig]);\n     act = &newact;\n   }\n   int res = REAL(sigaction)(sig, act, old);\n-  if (res == 0 && old) {\n-    uptr cb = (uptr)old->sigaction;\n-    if (cb == (uptr)rtl_sigaction || cb == (uptr)rtl_sighandler) {\n-      internal_memcpy(old, &old_stored, sizeof(*old));\n-    }\n-  }\n+  if (res == 0 && old && old->sigaction == sighandler)\n+    internal_memcpy(old, &old_stored, sizeof(*old));\n   return res;\n }\n \n@@ -2474,20 +2492,16 @@ static __sanitizer_sighandler_ptr signal_impl(int sig,\n   return old.handler;\n }\n \n-#define TSAN_SYSCALL() \\\n+#define TSAN_SYSCALL()             \\\n   ThreadState *thr = cur_thread(); \\\n-  if (thr->ignore_interceptors) \\\n-    return; \\\n-  ScopedSyscall scoped_syscall(thr) \\\n-/**/\n+  if (thr->ignore_interceptors)    \\\n+    return;                        \\\n+  ScopedSyscall scoped_syscall(thr)\n \n struct ScopedSyscall {\n   ThreadState *thr;\n \n-  explicit ScopedSyscall(ThreadState *thr)\n-      : thr(thr) {\n-    Initialize(thr);\n-  }\n+  explicit ScopedSyscall(ThreadState *thr) : thr(thr) { LazyInitialize(thr); }\n \n   ~ScopedSyscall() {\n     ProcessPendingSignals(thr);\n@@ -2503,12 +2517,12 @@ static void syscall_access_range(uptr pc, uptr p, uptr s, bool write) {\n static USED void syscall_acquire(uptr pc, uptr addr) {\n   TSAN_SYSCALL();\n   Acquire(thr, pc, addr);\n-  DPrintf(\"syscall_acquire(%p)\\n\", addr);\n+  DPrintf(\"syscall_acquire(0x%zx))\\n\", addr);\n }\n \n static USED void syscall_release(uptr pc, uptr addr) {\n   TSAN_SYSCALL();\n-  DPrintf(\"syscall_release(%p)\\n\", addr);\n+  DPrintf(\"syscall_release(0x%zx)\\n\", addr);\n   Release(thr, pc, addr);\n }\n \n@@ -2520,12 +2534,12 @@ static void syscall_fd_close(uptr pc, int fd) {\n static USED void syscall_fd_acquire(uptr pc, int fd) {\n   TSAN_SYSCALL();\n   FdAcquire(thr, pc, fd);\n-  DPrintf(\"syscall_fd_acquire(%p)\\n\", fd);\n+  DPrintf(\"syscall_fd_acquire(%d)\\n\", fd);\n }\n \n static USED void syscall_fd_release(uptr pc, int fd) {\n   TSAN_SYSCALL();\n-  DPrintf(\"syscall_fd_release(%p)\\n\", fd);\n+  DPrintf(\"syscall_fd_release(%d)\\n\", fd);\n   FdRelease(thr, pc, fd);\n }\n \n@@ -2695,12 +2709,6 @@ void InitializeInterceptors() {\n   REAL(memcpy) = internal_memcpy;\n #endif\n \n-  // Instruct libc malloc to consume less memory.\n-#if SANITIZER_GLIBC\n-  mallopt(1, 0);  // M_MXFAST\n-  mallopt(-3, 32*1024);  // M_MMAP_THRESHOLD\n-#endif\n-\n   new(interceptor_ctx()) InterceptorContext();\n \n   InitializeCommonInterceptors();\n@@ -2915,25 +2923,36 @@ void InitializeInterceptors() {\n // Note that no_sanitize_thread attribute does not turn off atomic interception\n // so attaching it to the function defined in user code does not help.\n // That's why we now have what we have.\n-extern \"C\" SANITIZER_INTERFACE_ATTRIBUTE\n-void __tsan_testonly_barrier_init(u64 *barrier, u32 count) {\n-  if (count >= (1 << 8)) {\n-      Printf(\"barrier_init: count is too large (%d)\\n\", count);\n-      Die();\n+constexpr u32 kBarrierThreadBits = 10;\n+constexpr u32 kBarrierThreads = 1 << kBarrierThreadBits;\n+\n+extern \"C\" SANITIZER_INTERFACE_ATTRIBUTE void __tsan_testonly_barrier_init(\n+    atomic_uint32_t *barrier, u32 num_threads) {\n+  if (num_threads >= kBarrierThreads) {\n+    Printf(\"barrier_init: count is too large (%d)\\n\", num_threads);\n+    Die();\n   }\n-  // 8 lsb is thread count, the remaining are count of entered threads.\n-  *barrier = count;\n+  // kBarrierThreadBits lsb is thread count,\n+  // the remaining are count of entered threads.\n+  atomic_store(barrier, num_threads, memory_order_relaxed);\n }\n \n-extern \"C\" SANITIZER_INTERFACE_ATTRIBUTE\n-void __tsan_testonly_barrier_wait(u64 *barrier) {\n-  unsigned old = __atomic_fetch_add(barrier, 1 << 8, __ATOMIC_RELAXED);\n-  unsigned old_epoch = (old >> 8) / (old & 0xff);\n+static u32 barrier_epoch(u32 value) {\n+  return (value >> kBarrierThreadBits) / (value & (kBarrierThreads - 1));\n+}\n+\n+extern \"C\" SANITIZER_INTERFACE_ATTRIBUTE void __tsan_testonly_barrier_wait(\n+    atomic_uint32_t *barrier) {\n+  u32 old = atomic_fetch_add(barrier, kBarrierThreads, memory_order_relaxed);\n+  u32 old_epoch = barrier_epoch(old);\n+  if (barrier_epoch(old + kBarrierThreads) != old_epoch) {\n+    FutexWake(barrier, (1 << 30));\n+    return;\n+  }\n   for (;;) {\n-    unsigned cur = __atomic_load_n(barrier, __ATOMIC_RELAXED);\n-    unsigned cur_epoch = (cur >> 8) / (cur & 0xff);\n-    if (cur_epoch != old_epoch)\n+    u32 cur = atomic_load(barrier, memory_order_relaxed);\n+    if (barrier_epoch(cur) != old_epoch)\n       return;\n-    internal_sched_yield();\n+    FutexWait(barrier, cur);\n   }\n }"}, {"sha": "704c06a1c78e7200bee33c19aa45e5614238ffb4", "filename": "libsanitizer/tsan/tsan_interface.cpp", "status": "modified", "additions": 24, "deletions": 72, "changes": 96, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interface.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interface.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_interface.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -30,98 +30,50 @@ void __tsan_flush_memory() {\n }\n \n void __tsan_read16(void *addr) {\n-  MemoryRead(cur_thread(), CALLERPC, (uptr)addr, kSizeLog8);\n-  MemoryRead(cur_thread(), CALLERPC, (uptr)addr + 8, kSizeLog8);\n+  uptr pc = CALLERPC;\n+  ThreadState *thr = cur_thread();\n+  MemoryAccess(thr, pc, (uptr)addr, 8, kAccessRead);\n+  MemoryAccess(thr, pc, (uptr)addr + 8, 8, kAccessRead);\n }\n \n void __tsan_write16(void *addr) {\n-  MemoryWrite(cur_thread(), CALLERPC, (uptr)addr, kSizeLog8);\n-  MemoryWrite(cur_thread(), CALLERPC, (uptr)addr + 8, kSizeLog8);\n+  uptr pc = CALLERPC;\n+  ThreadState *thr = cur_thread();\n+  MemoryAccess(thr, pc, (uptr)addr, 8, kAccessWrite);\n+  MemoryAccess(thr, pc, (uptr)addr + 8, 8, kAccessWrite);\n }\n \n void __tsan_read16_pc(void *addr, void *pc) {\n-  MemoryRead(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, kSizeLog8);\n-  MemoryRead(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr + 8, kSizeLog8);\n+  uptr pc_no_pac = STRIP_PAC_PC(pc);\n+  ThreadState *thr = cur_thread();\n+  MemoryAccess(thr, pc_no_pac, (uptr)addr, 8, kAccessRead);\n+  MemoryAccess(thr, pc_no_pac, (uptr)addr + 8, 8, kAccessRead);\n }\n \n void __tsan_write16_pc(void *addr, void *pc) {\n-  MemoryWrite(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, kSizeLog8);\n-  MemoryWrite(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr + 8, kSizeLog8);\n+  uptr pc_no_pac = STRIP_PAC_PC(pc);\n+  ThreadState *thr = cur_thread();\n+  MemoryAccess(thr, pc_no_pac, (uptr)addr, 8, kAccessWrite);\n+  MemoryAccess(thr, pc_no_pac, (uptr)addr + 8, 8, kAccessWrite);\n }\n \n // __tsan_unaligned_read/write calls are emitted by compiler.\n \n-void __tsan_unaligned_read2(const void *addr) {\n-  UnalignedMemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 2, false, false);\n-}\n-\n-void __tsan_unaligned_read4(const void *addr) {\n-  UnalignedMemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 4, false, false);\n-}\n-\n-void __tsan_unaligned_read8(const void *addr) {\n-  UnalignedMemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 8, false, false);\n-}\n-\n void __tsan_unaligned_read16(const void *addr) {\n-  UnalignedMemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 16, false, false);\n-}\n-\n-void __tsan_unaligned_write2(void *addr) {\n-  UnalignedMemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 2, true, false);\n-}\n-\n-void __tsan_unaligned_write4(void *addr) {\n-  UnalignedMemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 4, true, false);\n-}\n-\n-void __tsan_unaligned_write8(void *addr) {\n-  UnalignedMemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 8, true, false);\n+  uptr pc = CALLERPC;\n+  ThreadState *thr = cur_thread();\n+  UnalignedMemoryAccess(thr, pc, (uptr)addr, 8, kAccessRead);\n+  UnalignedMemoryAccess(thr, pc, (uptr)addr + 8, 8, kAccessRead);\n }\n \n void __tsan_unaligned_write16(void *addr) {\n-  UnalignedMemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 16, true, false);\n+  uptr pc = CALLERPC;\n+  ThreadState *thr = cur_thread();\n+  UnalignedMemoryAccess(thr, pc, (uptr)addr, 8, kAccessWrite);\n+  UnalignedMemoryAccess(thr, pc, (uptr)addr + 8, 8, kAccessWrite);\n }\n \n-// __sanitizer_unaligned_load/store are for user instrumentation.\n-\n extern \"C\" {\n-SANITIZER_INTERFACE_ATTRIBUTE\n-u16 __sanitizer_unaligned_load16(const uu16 *addr) {\n-  __tsan_unaligned_read2(addr);\n-  return *addr;\n-}\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-u32 __sanitizer_unaligned_load32(const uu32 *addr) {\n-  __tsan_unaligned_read4(addr);\n-  return *addr;\n-}\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-u64 __sanitizer_unaligned_load64(const uu64 *addr) {\n-  __tsan_unaligned_read8(addr);\n-  return *addr;\n-}\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-void __sanitizer_unaligned_store16(uu16 *addr, u16 v) {\n-  __tsan_unaligned_write2(addr);\n-  *addr = v;\n-}\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-void __sanitizer_unaligned_store32(uu32 *addr, u32 v) {\n-  __tsan_unaligned_write4(addr);\n-  *addr = v;\n-}\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-void __sanitizer_unaligned_store64(uu64 *addr, u64 v) {\n-  __tsan_unaligned_write8(addr);\n-  *addr = v;\n-}\n-\n SANITIZER_INTERFACE_ATTRIBUTE\n void *__tsan_get_current_fiber() {\n   return cur_thread();"}, {"sha": "711f064174c2c3ec83eb31b91464ba577907a547", "filename": "libsanitizer/tsan/tsan_interface.h", "status": "modified", "additions": 2, "deletions": 8, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interface.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interface.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_interface.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -95,9 +95,9 @@ SANITIZER_INTERFACE_ATTRIBUTE\n void __tsan_write_range(void *addr, unsigned long size);\n \n SANITIZER_INTERFACE_ATTRIBUTE\n-void __tsan_read_range_pc(void *addr, unsigned long size, void *pc);  // NOLINT\n+void __tsan_read_range_pc(void *addr, unsigned long size, void *pc);\n SANITIZER_INTERFACE_ATTRIBUTE\n-void __tsan_write_range_pc(void *addr, unsigned long size, void *pc);  // NOLINT\n+void __tsan_write_range_pc(void *addr, unsigned long size, void *pc);\n \n // User may provide function that would be called right when TSan detects\n // an error. The argument 'report' is an opaque pointer that can be used to\n@@ -417,12 +417,6 @@ SANITIZER_INTERFACE_ATTRIBUTE\n void __tsan_go_atomic64_compare_exchange(ThreadState *thr, uptr cpc, uptr pc,\n                                          u8 *a);\n \n-SANITIZER_INTERFACE_ATTRIBUTE\n-void __tsan_on_initialize();\n-\n-SANITIZER_INTERFACE_ATTRIBUTE\n-int __tsan_on_finalize(int failed);\n-\n }  // extern \"C\"\n \n }  // namespace __tsan"}, {"sha": "0031800e851f4b102384cc36cb0be09faed7a2fa", "filename": "libsanitizer/tsan/tsan_interface.inc", "status": "added", "additions": 182, "deletions": 0, "changes": 182, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interface.inc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interface.inc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_interface.inc?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -0,0 +1,182 @@\n+//===-- tsan_interface.inc --------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of ThreadSanitizer (TSan), a race detector.\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#include \"sanitizer_common/sanitizer_ptrauth.h\"\n+#include \"tsan_interface.h\"\n+#include \"tsan_rtl.h\"\n+\n+#define CALLERPC ((uptr)__builtin_return_address(0))\n+\n+using namespace __tsan;\n+\n+void __tsan_read1(void *addr) {\n+  MemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 1, kAccessRead);\n+}\n+\n+void __tsan_read2(void *addr) {\n+  MemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 2, kAccessRead);\n+}\n+\n+void __tsan_read4(void *addr) {\n+  MemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 4, kAccessRead);\n+}\n+\n+void __tsan_read8(void *addr) {\n+  MemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 8, kAccessRead);\n+}\n+\n+void __tsan_write1(void *addr) {\n+  MemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 1, kAccessWrite);\n+}\n+\n+void __tsan_write2(void *addr) {\n+  MemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 2, kAccessWrite);\n+}\n+\n+void __tsan_write4(void *addr) {\n+  MemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 4, kAccessWrite);\n+}\n+\n+void __tsan_write8(void *addr) {\n+  MemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 8, kAccessWrite);\n+}\n+\n+void __tsan_read1_pc(void *addr, void *pc) {\n+  MemoryAccess(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, 1, kAccessRead | kAccessExternalPC);\n+}\n+\n+void __tsan_read2_pc(void *addr, void *pc) {\n+  MemoryAccess(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, 2, kAccessRead | kAccessExternalPC);\n+}\n+\n+void __tsan_read4_pc(void *addr, void *pc) {\n+  MemoryAccess(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, 4, kAccessRead | kAccessExternalPC);\n+}\n+\n+void __tsan_read8_pc(void *addr, void *pc) {\n+  MemoryAccess(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, 8, kAccessRead | kAccessExternalPC);\n+}\n+\n+void __tsan_write1_pc(void *addr, void *pc) {\n+  MemoryAccess(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, 1, kAccessWrite | kAccessExternalPC);\n+}\n+\n+void __tsan_write2_pc(void *addr, void *pc) {\n+  MemoryAccess(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, 2, kAccessWrite | kAccessExternalPC);\n+}\n+\n+void __tsan_write4_pc(void *addr, void *pc) {\n+  MemoryAccess(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, 4, kAccessWrite | kAccessExternalPC);\n+}\n+\n+void __tsan_write8_pc(void *addr, void *pc) {\n+  MemoryAccess(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, 8, kAccessWrite | kAccessExternalPC);\n+}\n+\n+ALWAYS_INLINE USED void __tsan_unaligned_read2(const void *addr) {\n+  UnalignedMemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 2, kAccessRead);\n+}\n+\n+ALWAYS_INLINE USED void __tsan_unaligned_read4(const void *addr) {\n+  UnalignedMemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 4, kAccessRead);\n+}\n+\n+ALWAYS_INLINE USED void __tsan_unaligned_read8(const void *addr) {\n+  UnalignedMemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 8, kAccessRead);\n+}\n+\n+ALWAYS_INLINE USED void __tsan_unaligned_write2(void *addr) {\n+  UnalignedMemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 2, kAccessWrite);\n+}\n+\n+ALWAYS_INLINE USED void __tsan_unaligned_write4(void *addr) {\n+  UnalignedMemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 4, kAccessWrite);\n+}\n+\n+ALWAYS_INLINE USED void __tsan_unaligned_write8(void *addr) {\n+  UnalignedMemoryAccess(cur_thread(), CALLERPC, (uptr)addr, 8, kAccessWrite);\n+}\n+\n+extern \"C\" {\n+// __sanitizer_unaligned_load/store are for user instrumentation.\n+SANITIZER_INTERFACE_ATTRIBUTE\n+u16 __sanitizer_unaligned_load16(const uu16 *addr) {\n+  __tsan_unaligned_read2(addr);\n+  return *addr;\n+}\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+u32 __sanitizer_unaligned_load32(const uu32 *addr) {\n+  __tsan_unaligned_read4(addr);\n+  return *addr;\n+}\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+u64 __sanitizer_unaligned_load64(const uu64 *addr) {\n+  __tsan_unaligned_read8(addr);\n+  return *addr;\n+}\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __sanitizer_unaligned_store16(uu16 *addr, u16 v) {\n+  *addr = v;\n+  __tsan_unaligned_write2(addr);\n+}\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __sanitizer_unaligned_store32(uu32 *addr, u32 v) {\n+  *addr = v;\n+  __tsan_unaligned_write4(addr);\n+}\n+\n+SANITIZER_INTERFACE_ATTRIBUTE\n+void __sanitizer_unaligned_store64(uu64 *addr, u64 v) {\n+  *addr = v;\n+  __tsan_unaligned_write8(addr);\n+}\n+}\n+\n+void __tsan_vptr_update(void **vptr_p, void *new_val) {\n+  if (*vptr_p == new_val)\n+    return;\n+  MemoryAccess(cur_thread(), CALLERPC, (uptr)vptr_p, sizeof(*vptr_p),\n+               kAccessWrite | kAccessVptr);\n+}\n+\n+void __tsan_vptr_read(void **vptr_p) {\n+  MemoryAccess(cur_thread(), CALLERPC, (uptr)vptr_p, sizeof(*vptr_p),\n+               kAccessRead | kAccessVptr);\n+}\n+\n+void __tsan_func_entry(void *pc) { FuncEntry(cur_thread(), STRIP_PAC_PC(pc)); }\n+\n+void __tsan_func_exit() { FuncExit(cur_thread()); }\n+\n+void __tsan_ignore_thread_begin() { ThreadIgnoreBegin(cur_thread(), CALLERPC); }\n+\n+void __tsan_ignore_thread_end() { ThreadIgnoreEnd(cur_thread()); }\n+\n+void __tsan_read_range(void *addr, uptr size) {\n+  MemoryAccessRange(cur_thread(), CALLERPC, (uptr)addr, size, false);\n+}\n+\n+void __tsan_write_range(void *addr, uptr size) {\n+  MemoryAccessRange(cur_thread(), CALLERPC, (uptr)addr, size, true);\n+}\n+\n+void __tsan_read_range_pc(void *addr, uptr size, void *pc) {\n+  MemoryAccessRange(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, size, false);\n+}\n+\n+void __tsan_write_range_pc(void *addr, uptr size, void *pc) {\n+  MemoryAccessRange(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, size, true);\n+}"}, {"sha": "6bd72e18d942580691b99530fac2f2c46be33cf2", "filename": "libsanitizer/tsan/tsan_interface_ann.cpp", "status": "modified", "additions": 31, "deletions": 141, "changes": 172, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interface_ann.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interface_ann.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_interface_ann.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -15,7 +15,6 @@\n #include \"sanitizer_common/sanitizer_stacktrace.h\"\n #include \"sanitizer_common/sanitizer_vector.h\"\n #include \"tsan_interface_ann.h\"\n-#include \"tsan_mutex.h\"\n #include \"tsan_report.h\"\n #include \"tsan_rtl.h\"\n #include \"tsan_mman.h\"\n@@ -38,21 +37,20 @@ class ScopedAnnotation {\n \n   ~ScopedAnnotation() {\n     FuncExit(thr_);\n-    CheckNoLocks(thr_);\n+    CheckedMutex::CheckNoLocks();\n   }\n  private:\n   ThreadState *const thr_;\n };\n \n-#define SCOPED_ANNOTATION_RET(typ, ret) \\\n-    if (!flags()->enable_annotations) \\\n-      return ret; \\\n-    ThreadState *thr = cur_thread(); \\\n-    const uptr caller_pc = (uptr)__builtin_return_address(0); \\\n-    ScopedAnnotation sa(thr, __func__, caller_pc); \\\n-    const uptr pc = StackTrace::GetCurrentPc(); \\\n-    (void)pc; \\\n-/**/\n+#define SCOPED_ANNOTATION_RET(typ, ret)                     \\\n+  if (!flags()->enable_annotations)                         \\\n+    return ret;                                             \\\n+  ThreadState *thr = cur_thread();                          \\\n+  const uptr caller_pc = (uptr)__builtin_return_address(0); \\\n+  ScopedAnnotation sa(thr, __func__, caller_pc);            \\\n+  const uptr pc = StackTrace::GetCurrentPc();               \\\n+  (void)pc;\n \n #define SCOPED_ANNOTATION(typ) SCOPED_ANNOTATION_RET(typ, )\n \n@@ -72,7 +70,6 @@ struct ExpectRace {\n \n struct DynamicAnnContext {\n   Mutex mtx;\n-  ExpectRace expect;\n   ExpectRace benign;\n \n   DynamicAnnContext() : mtx(MutexTypeAnnotations) {}\n@@ -91,7 +88,7 @@ static void AddExpectRace(ExpectRace *list,\n       return;\n     }\n   }\n-  race = (ExpectRace*)internal_alloc(MBlockExpectRace, sizeof(ExpectRace));\n+  race = static_cast<ExpectRace *>(Alloc(sizeof(ExpectRace)));\n   race->addr = addr;\n   race->size = size;\n   race->file = f;\n@@ -138,81 +135,12 @@ static void InitList(ExpectRace *list) {\n \n void InitializeDynamicAnnotations() {\n   dyn_ann_ctx = new(dyn_ann_ctx_placeholder) DynamicAnnContext;\n-  InitList(&dyn_ann_ctx->expect);\n   InitList(&dyn_ann_ctx->benign);\n }\n \n bool IsExpectedReport(uptr addr, uptr size) {\n   ReadLock lock(&dyn_ann_ctx->mtx);\n-  if (CheckContains(&dyn_ann_ctx->expect, addr, size))\n-    return true;\n-  if (CheckContains(&dyn_ann_ctx->benign, addr, size))\n-    return true;\n-  return false;\n-}\n-\n-static void CollectMatchedBenignRaces(Vector<ExpectRace> *matched,\n-    int *unique_count, int *hit_count, atomic_uintptr_t ExpectRace::*counter) {\n-  ExpectRace *list = &dyn_ann_ctx->benign;\n-  for (ExpectRace *race = list->next; race != list; race = race->next) {\n-    (*unique_count)++;\n-    const uptr cnt = atomic_load_relaxed(&(race->*counter));\n-    if (cnt == 0)\n-      continue;\n-    *hit_count += cnt;\n-    uptr i = 0;\n-    for (; i < matched->Size(); i++) {\n-      ExpectRace *race0 = &(*matched)[i];\n-      if (race->line == race0->line\n-          && internal_strcmp(race->file, race0->file) == 0\n-          && internal_strcmp(race->desc, race0->desc) == 0) {\n-        atomic_fetch_add(&(race0->*counter), cnt, memory_order_relaxed);\n-        break;\n-      }\n-    }\n-    if (i == matched->Size())\n-      matched->PushBack(*race);\n-  }\n-}\n-\n-void PrintMatchedBenignRaces() {\n-  Lock lock(&dyn_ann_ctx->mtx);\n-  int unique_count = 0;\n-  int hit_count = 0;\n-  int add_count = 0;\n-  Vector<ExpectRace> hit_matched;\n-  CollectMatchedBenignRaces(&hit_matched, &unique_count, &hit_count,\n-      &ExpectRace::hitcount);\n-  Vector<ExpectRace> add_matched;\n-  CollectMatchedBenignRaces(&add_matched, &unique_count, &add_count,\n-      &ExpectRace::addcount);\n-  if (hit_matched.Size()) {\n-    Printf(\"ThreadSanitizer: Matched %d \\\"benign\\\" races (pid=%d):\\n\",\n-        hit_count, (int)internal_getpid());\n-    for (uptr i = 0; i < hit_matched.Size(); i++) {\n-      Printf(\"%d %s:%d %s\\n\",\n-          atomic_load_relaxed(&hit_matched[i].hitcount),\n-          hit_matched[i].file, hit_matched[i].line, hit_matched[i].desc);\n-    }\n-  }\n-  if (hit_matched.Size()) {\n-    Printf(\"ThreadSanitizer: Annotated %d \\\"benign\\\" races, %d unique\"\n-           \" (pid=%d):\\n\",\n-        add_count, unique_count, (int)internal_getpid());\n-    for (uptr i = 0; i < add_matched.Size(); i++) {\n-      Printf(\"%d %s:%d %s\\n\",\n-          atomic_load_relaxed(&add_matched[i].addcount),\n-          add_matched[i].file, add_matched[i].line, add_matched[i].desc);\n-    }\n-  }\n-}\n-\n-static void ReportMissedExpectedRace(ExpectRace *race) {\n-  Printf(\"==================\\n\");\n-  Printf(\"WARNING: ThreadSanitizer: missed expected data race\\n\");\n-  Printf(\"  %s addr=%zx %s:%d\\n\",\n-      race->desc, race->addr, race->file, race->line);\n-  Printf(\"==================\\n\");\n+  return CheckContains(&dyn_ann_ctx->benign, addr, size);\n }\n }  // namespace __tsan\n \n@@ -230,20 +158,16 @@ void INTERFACE_ATTRIBUTE AnnotateHappensAfter(char *f, int l, uptr addr) {\n }\n \n void INTERFACE_ATTRIBUTE AnnotateCondVarSignal(char *f, int l, uptr cv) {\n-  SCOPED_ANNOTATION(AnnotateCondVarSignal);\n }\n \n void INTERFACE_ATTRIBUTE AnnotateCondVarSignalAll(char *f, int l, uptr cv) {\n-  SCOPED_ANNOTATION(AnnotateCondVarSignalAll);\n }\n \n void INTERFACE_ATTRIBUTE AnnotateMutexIsNotPHB(char *f, int l, uptr mu) {\n-  SCOPED_ANNOTATION(AnnotateMutexIsNotPHB);\n }\n \n void INTERFACE_ATTRIBUTE AnnotateCondVarWait(char *f, int l, uptr cv,\n                                              uptr lock) {\n-  SCOPED_ANNOTATION(AnnotateCondVarWait);\n }\n \n void INTERFACE_ATTRIBUTE AnnotateRWLockCreate(char *f, int l, uptr m) {\n@@ -280,86 +204,56 @@ void INTERFACE_ATTRIBUTE AnnotateRWLockReleased(char *f, int l, uptr m,\n }\n \n void INTERFACE_ATTRIBUTE AnnotateTraceMemory(char *f, int l, uptr mem) {\n-  SCOPED_ANNOTATION(AnnotateTraceMemory);\n }\n \n void INTERFACE_ATTRIBUTE AnnotateFlushState(char *f, int l) {\n-  SCOPED_ANNOTATION(AnnotateFlushState);\n }\n \n void INTERFACE_ATTRIBUTE AnnotateNewMemory(char *f, int l, uptr mem,\n                                            uptr size) {\n-  SCOPED_ANNOTATION(AnnotateNewMemory);\n }\n \n void INTERFACE_ATTRIBUTE AnnotateNoOp(char *f, int l, uptr mem) {\n-  SCOPED_ANNOTATION(AnnotateNoOp);\n }\n \n void INTERFACE_ATTRIBUTE AnnotateFlushExpectedRaces(char *f, int l) {\n-  SCOPED_ANNOTATION(AnnotateFlushExpectedRaces);\n-  Lock lock(&dyn_ann_ctx->mtx);\n-  while (dyn_ann_ctx->expect.next != &dyn_ann_ctx->expect) {\n-    ExpectRace *race = dyn_ann_ctx->expect.next;\n-    if (atomic_load_relaxed(&race->hitcount) == 0) {\n-      ctx->nmissed_expected++;\n-      ReportMissedExpectedRace(race);\n-    }\n-    race->prev->next = race->next;\n-    race->next->prev = race->prev;\n-    internal_free(race);\n-  }\n }\n \n void INTERFACE_ATTRIBUTE AnnotateEnableRaceDetection(\n     char *f, int l, int enable) {\n-  SCOPED_ANNOTATION(AnnotateEnableRaceDetection);\n-  // FIXME: Reconsider this functionality later. It may be irrelevant.\n }\n \n void INTERFACE_ATTRIBUTE AnnotateMutexIsUsedAsCondVar(\n     char *f, int l, uptr mu) {\n-  SCOPED_ANNOTATION(AnnotateMutexIsUsedAsCondVar);\n }\n \n void INTERFACE_ATTRIBUTE AnnotatePCQGet(\n     char *f, int l, uptr pcq) {\n-  SCOPED_ANNOTATION(AnnotatePCQGet);\n }\n \n void INTERFACE_ATTRIBUTE AnnotatePCQPut(\n     char *f, int l, uptr pcq) {\n-  SCOPED_ANNOTATION(AnnotatePCQPut);\n }\n \n void INTERFACE_ATTRIBUTE AnnotatePCQDestroy(\n     char *f, int l, uptr pcq) {\n-  SCOPED_ANNOTATION(AnnotatePCQDestroy);\n }\n \n void INTERFACE_ATTRIBUTE AnnotatePCQCreate(\n     char *f, int l, uptr pcq) {\n-  SCOPED_ANNOTATION(AnnotatePCQCreate);\n }\n \n void INTERFACE_ATTRIBUTE AnnotateExpectRace(\n     char *f, int l, uptr mem, char *desc) {\n-  SCOPED_ANNOTATION(AnnotateExpectRace);\n-  Lock lock(&dyn_ann_ctx->mtx);\n-  AddExpectRace(&dyn_ann_ctx->expect,\n-                f, l, mem, 1, desc);\n-  DPrintf(\"Add expected race: %s addr=%zx %s:%d\\n\", desc, mem, f, l);\n }\n \n-static void BenignRaceImpl(\n-    char *f, int l, uptr mem, uptr size, char *desc) {\n+static void BenignRaceImpl(char *f, int l, uptr mem, uptr size, char *desc) {\n   Lock lock(&dyn_ann_ctx->mtx);\n   AddExpectRace(&dyn_ann_ctx->benign,\n                 f, l, mem, size, desc);\n   DPrintf(\"Add benign race: %s addr=%zx %s:%d\\n\", desc, mem, f, l);\n }\n \n-// FIXME: Turn it off later. WTF is benign race?1?? Go talk to Hans Boehm.\n void INTERFACE_ATTRIBUTE AnnotateBenignRaceSized(\n     char *f, int l, uptr mem, uptr size, char *desc) {\n   SCOPED_ANNOTATION(AnnotateBenignRaceSized);\n@@ -379,7 +273,7 @@ void INTERFACE_ATTRIBUTE AnnotateIgnoreReadsBegin(char *f, int l) {\n \n void INTERFACE_ATTRIBUTE AnnotateIgnoreReadsEnd(char *f, int l) {\n   SCOPED_ANNOTATION(AnnotateIgnoreReadsEnd);\n-  ThreadIgnoreEnd(thr, pc);\n+  ThreadIgnoreEnd(thr);\n }\n \n void INTERFACE_ATTRIBUTE AnnotateIgnoreWritesBegin(char *f, int l) {\n@@ -389,7 +283,7 @@ void INTERFACE_ATTRIBUTE AnnotateIgnoreWritesBegin(char *f, int l) {\n \n void INTERFACE_ATTRIBUTE AnnotateIgnoreWritesEnd(char *f, int l) {\n   SCOPED_ANNOTATION(AnnotateIgnoreWritesEnd);\n-  ThreadIgnoreEnd(thr, pc);\n+  ThreadIgnoreEnd(thr);\n }\n \n void INTERFACE_ATTRIBUTE AnnotateIgnoreSyncBegin(char *f, int l) {\n@@ -399,17 +293,15 @@ void INTERFACE_ATTRIBUTE AnnotateIgnoreSyncBegin(char *f, int l) {\n \n void INTERFACE_ATTRIBUTE AnnotateIgnoreSyncEnd(char *f, int l) {\n   SCOPED_ANNOTATION(AnnotateIgnoreSyncEnd);\n-  ThreadIgnoreSyncEnd(thr, pc);\n+  ThreadIgnoreSyncEnd(thr);\n }\n \n void INTERFACE_ATTRIBUTE AnnotatePublishMemoryRange(\n     char *f, int l, uptr addr, uptr size) {\n-  SCOPED_ANNOTATION(AnnotatePublishMemoryRange);\n }\n \n void INTERFACE_ATTRIBUTE AnnotateUnpublishMemoryRange(\n     char *f, int l, uptr addr, uptr size) {\n-  SCOPED_ANNOTATION(AnnotateUnpublishMemoryRange);\n }\n \n void INTERFACE_ATTRIBUTE AnnotateThreadName(\n@@ -422,11 +314,9 @@ void INTERFACE_ATTRIBUTE AnnotateThreadName(\n // WTFAnnotateHappensAfter(). Those are being used by Webkit to annotate\n // atomic operations, which should be handled by ThreadSanitizer correctly.\n void INTERFACE_ATTRIBUTE WTFAnnotateHappensBefore(char *f, int l, uptr addr) {\n-  SCOPED_ANNOTATION(AnnotateHappensBefore);\n }\n \n void INTERFACE_ATTRIBUTE WTFAnnotateHappensAfter(char *f, int l, uptr addr) {\n-  SCOPED_ANNOTATION(AnnotateHappensAfter);\n }\n \n void INTERFACE_ATTRIBUTE WTFAnnotateBenignRaceSized(\n@@ -478,15 +368,15 @@ void __tsan_mutex_pre_lock(void *m, unsigned flagz) {\n     else\n       MutexPreLock(thr, pc, (uptr)m);\n   }\n-  ThreadIgnoreBegin(thr, pc, /*save_stack=*/false);\n-  ThreadIgnoreSyncBegin(thr, pc, /*save_stack=*/false);\n+  ThreadIgnoreBegin(thr, 0);\n+  ThreadIgnoreSyncBegin(thr, 0);\n }\n \n INTERFACE_ATTRIBUTE\n void __tsan_mutex_post_lock(void *m, unsigned flagz, int rec) {\n   SCOPED_ANNOTATION(__tsan_mutex_post_lock);\n-  ThreadIgnoreSyncEnd(thr, pc);\n-  ThreadIgnoreEnd(thr, pc);\n+  ThreadIgnoreSyncEnd(thr);\n+  ThreadIgnoreEnd(thr);\n   if (!(flagz & MutexFlagTryLockFailed)) {\n     if (flagz & MutexFlagReadLock)\n       MutexPostReadLock(thr, pc, (uptr)m, flagz);\n@@ -505,44 +395,44 @@ int __tsan_mutex_pre_unlock(void *m, unsigned flagz) {\n   } else {\n     ret = MutexUnlock(thr, pc, (uptr)m, flagz);\n   }\n-  ThreadIgnoreBegin(thr, pc, /*save_stack=*/false);\n-  ThreadIgnoreSyncBegin(thr, pc, /*save_stack=*/false);\n+  ThreadIgnoreBegin(thr, 0);\n+  ThreadIgnoreSyncBegin(thr, 0);\n   return ret;\n }\n \n INTERFACE_ATTRIBUTE\n void __tsan_mutex_post_unlock(void *m, unsigned flagz) {\n   SCOPED_ANNOTATION(__tsan_mutex_post_unlock);\n-  ThreadIgnoreSyncEnd(thr, pc);\n-  ThreadIgnoreEnd(thr, pc);\n+  ThreadIgnoreSyncEnd(thr);\n+  ThreadIgnoreEnd(thr);\n }\n \n INTERFACE_ATTRIBUTE\n void __tsan_mutex_pre_signal(void *addr, unsigned flagz) {\n   SCOPED_ANNOTATION(__tsan_mutex_pre_signal);\n-  ThreadIgnoreBegin(thr, pc, /*save_stack=*/false);\n-  ThreadIgnoreSyncBegin(thr, pc, /*save_stack=*/false);\n+  ThreadIgnoreBegin(thr, 0);\n+  ThreadIgnoreSyncBegin(thr, 0);\n }\n \n INTERFACE_ATTRIBUTE\n void __tsan_mutex_post_signal(void *addr, unsigned flagz) {\n   SCOPED_ANNOTATION(__tsan_mutex_post_signal);\n-  ThreadIgnoreSyncEnd(thr, pc);\n-  ThreadIgnoreEnd(thr, pc);\n+  ThreadIgnoreSyncEnd(thr);\n+  ThreadIgnoreEnd(thr);\n }\n \n INTERFACE_ATTRIBUTE\n void __tsan_mutex_pre_divert(void *addr, unsigned flagz) {\n   SCOPED_ANNOTATION(__tsan_mutex_pre_divert);\n   // Exit from ignore region started in __tsan_mutex_pre_lock/unlock/signal.\n-  ThreadIgnoreSyncEnd(thr, pc);\n-  ThreadIgnoreEnd(thr, pc);\n+  ThreadIgnoreSyncEnd(thr);\n+  ThreadIgnoreEnd(thr);\n }\n \n INTERFACE_ATTRIBUTE\n void __tsan_mutex_post_divert(void *addr, unsigned flagz) {\n   SCOPED_ANNOTATION(__tsan_mutex_post_divert);\n-  ThreadIgnoreBegin(thr, pc, /*save_stack=*/false);\n-  ThreadIgnoreSyncBegin(thr, pc, /*save_stack=*/false);\n+  ThreadIgnoreBegin(thr, 0);\n+  ThreadIgnoreSyncBegin(thr, 0);\n }\n }  // extern \"C\""}, {"sha": "24ba3bb1f65df4e3148c3a4098922fdf75b6b1d3", "filename": "libsanitizer/tsan/tsan_interface_atomic.cpp", "status": "modified", "additions": 147, "deletions": 176, "changes": 323, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interface_atomic.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interface_atomic.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_interface_atomic.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -32,6 +32,7 @@ using namespace __tsan;\n static StaticSpinMutex mutex128;\n #endif\n \n+#if SANITIZER_DEBUG\n static bool IsLoadOrder(morder mo) {\n   return mo == mo_relaxed || mo == mo_consume\n       || mo == mo_acquire || mo == mo_seq_cst;\n@@ -40,6 +41,7 @@ static bool IsLoadOrder(morder mo) {\n static bool IsStoreOrder(morder mo) {\n   return mo == mo_relaxed || mo == mo_release || mo == mo_seq_cst;\n }\n+#endif\n \n static bool IsReleaseOrder(morder mo) {\n   return mo == mo_release || mo == mo_acq_rel || mo == mo_seq_cst;\n@@ -161,16 +163,16 @@ a128 func_cas(volatile a128 *v, a128 cmp, a128 xch) {\n }\n #endif\n \n-template<typename T>\n-static int SizeLog() {\n+template <typename T>\n+static int AccessSize() {\n   if (sizeof(T) <= 1)\n-    return kSizeLog1;\n+    return 1;\n   else if (sizeof(T) <= 2)\n-    return kSizeLog2;\n+    return 2;\n   else if (sizeof(T) <= 4)\n-    return kSizeLog4;\n+    return 4;\n   else\n-    return kSizeLog8;\n+    return 8;\n   // For 16-byte atomics we also use 8-byte memory access,\n   // this leads to false negatives only in very obscure cases.\n }\n@@ -202,7 +204,7 @@ static memory_order to_mo(morder mo) {\n   case mo_acq_rel: return memory_order_acq_rel;\n   case mo_seq_cst: return memory_order_seq_cst;\n   }\n-  CHECK(0);\n+  DCHECK(0);\n   return memory_order_seq_cst;\n }\n \n@@ -218,27 +220,28 @@ static a128 NoTsanAtomicLoad(const volatile a128 *a, morder mo) {\n }\n #endif\n \n-template<typename T>\n+template <typename T>\n static T AtomicLoad(ThreadState *thr, uptr pc, const volatile T *a, morder mo) {\n-  CHECK(IsLoadOrder(mo));\n+  DCHECK(IsLoadOrder(mo));\n   // This fast-path is critical for performance.\n   // Assume the access is atomic.\n   if (!IsAcquireOrder(mo)) {\n-    MemoryReadAtomic(thr, pc, (uptr)a, SizeLog<T>());\n+    MemoryAccess(thr, pc, (uptr)a, AccessSize<T>(),\n+                 kAccessRead | kAccessAtomic);\n     return NoTsanAtomicLoad(a, mo);\n   }\n   // Don't create sync object if it does not exist yet. For example, an atomic\n   // pointer is initialized to nullptr and then periodically acquire-loaded.\n   T v = NoTsanAtomicLoad(a, mo);\n-  SyncVar *s = ctx->metamap.GetIfExistsAndLock((uptr)a, false);\n+  SyncVar *s = ctx->metamap.GetSyncIfExists((uptr)a);\n   if (s) {\n+    ReadLock l(&s->mtx);\n     AcquireImpl(thr, pc, &s->clock);\n     // Re-read under sync mutex because we need a consistent snapshot\n     // of the value and the clock we acquire.\n     v = NoTsanAtomicLoad(a, mo);\n-    s->mtx.ReadUnlock();\n   }\n-  MemoryReadAtomic(thr, pc, (uptr)a, SizeLog<T>());\n+  MemoryAccess(thr, pc, (uptr)a, AccessSize<T>(), kAccessRead | kAccessAtomic);\n   return v;\n }\n \n@@ -254,11 +257,11 @@ static void NoTsanAtomicStore(volatile a128 *a, a128 v, morder mo) {\n }\n #endif\n \n-template<typename T>\n+template <typename T>\n static void AtomicStore(ThreadState *thr, uptr pc, volatile T *a, T v,\n-    morder mo) {\n-  CHECK(IsStoreOrder(mo));\n-  MemoryWriteAtomic(thr, pc, (uptr)a, SizeLog<T>());\n+                        morder mo) {\n+  DCHECK(IsStoreOrder(mo));\n+  MemoryAccess(thr, pc, (uptr)a, AccessSize<T>(), kAccessWrite | kAccessAtomic);\n   // This fast-path is critical for performance.\n   // Assume the access is atomic.\n   // Strictly saying even relaxed store cuts off release sequence,\n@@ -268,35 +271,32 @@ static void AtomicStore(ThreadState *thr, uptr pc, volatile T *a, T v,\n     return;\n   }\n   __sync_synchronize();\n-  SyncVar *s = ctx->metamap.GetOrCreateAndLock(thr, pc, (uptr)a, true);\n+  SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, (uptr)a, false);\n+  Lock l(&s->mtx);\n   thr->fast_state.IncrementEpoch();\n   // Can't increment epoch w/o writing to the trace as well.\n   TraceAddEvent(thr, thr->fast_state, EventTypeMop, 0);\n   ReleaseStoreImpl(thr, pc, &s->clock);\n   NoTsanAtomicStore(a, v, mo);\n-  s->mtx.Unlock();\n }\n \n-template<typename T, T (*F)(volatile T *v, T op)>\n+template <typename T, T (*F)(volatile T *v, T op)>\n static T AtomicRMW(ThreadState *thr, uptr pc, volatile T *a, T v, morder mo) {\n-  MemoryWriteAtomic(thr, pc, (uptr)a, SizeLog<T>());\n-  SyncVar *s = 0;\n-  if (mo != mo_relaxed) {\n-    s = ctx->metamap.GetOrCreateAndLock(thr, pc, (uptr)a, true);\n-    thr->fast_state.IncrementEpoch();\n-    // Can't increment epoch w/o writing to the trace as well.\n-    TraceAddEvent(thr, thr->fast_state, EventTypeMop, 0);\n-    if (IsAcqRelOrder(mo))\n-      AcquireReleaseImpl(thr, pc, &s->clock);\n-    else if (IsReleaseOrder(mo))\n-      ReleaseImpl(thr, pc, &s->clock);\n-    else if (IsAcquireOrder(mo))\n-      AcquireImpl(thr, pc, &s->clock);\n-  }\n-  v = F(a, v);\n-  if (s)\n-    s->mtx.Unlock();\n-  return v;\n+  MemoryAccess(thr, pc, (uptr)a, AccessSize<T>(), kAccessWrite | kAccessAtomic);\n+  if (LIKELY(mo == mo_relaxed))\n+    return F(a, v);\n+  SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, (uptr)a, false);\n+  Lock l(&s->mtx);\n+  thr->fast_state.IncrementEpoch();\n+  // Can't increment epoch w/o writing to the trace as well.\n+  TraceAddEvent(thr, thr->fast_state, EventTypeMop, 0);\n+  if (IsAcqRelOrder(mo))\n+    AcquireReleaseImpl(thr, pc, &s->clock);\n+  else if (IsReleaseOrder(mo))\n+    ReleaseImpl(thr, pc, &s->clock);\n+  else if (IsAcquireOrder(mo))\n+    AcquireImpl(thr, pc, &s->clock);\n+  return F(a, v);\n }\n \n template<typename T>\n@@ -399,47 +399,44 @@ static T NoTsanAtomicCAS(volatile T *a, T c, T v, morder mo, morder fmo) {\n   return c;\n }\n \n-template<typename T>\n-static bool AtomicCAS(ThreadState *thr, uptr pc,\n-    volatile T *a, T *c, T v, morder mo, morder fmo) {\n+template <typename T>\n+static bool AtomicCAS(ThreadState *thr, uptr pc, volatile T *a, T *c, T v,\n+                      morder mo, morder fmo) {\n   // 31.7.2.18: \"The failure argument shall not be memory_order_release\n   // nor memory_order_acq_rel\". LLVM (2021-05) fallbacks to Monotonic\n   // (mo_relaxed) when those are used.\n-  CHECK(IsLoadOrder(fmo));\n-\n-  MemoryWriteAtomic(thr, pc, (uptr)a, SizeLog<T>());\n-  SyncVar *s = 0;\n-  bool write_lock = IsReleaseOrder(mo);\n-\n-  if (mo != mo_relaxed || fmo != mo_relaxed)\n-    s = ctx->metamap.GetOrCreateAndLock(thr, pc, (uptr)a, write_lock);\n+  DCHECK(IsLoadOrder(fmo));\n+\n+  MemoryAccess(thr, pc, (uptr)a, AccessSize<T>(), kAccessWrite | kAccessAtomic);\n+  if (LIKELY(mo == mo_relaxed && fmo == mo_relaxed)) {\n+    T cc = *c;\n+    T pr = func_cas(a, cc, v);\n+    if (pr == cc)\n+      return true;\n+    *c = pr;\n+    return false;\n+  }\n \n+  bool release = IsReleaseOrder(mo);\n+  SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, (uptr)a, false);\n+  RWLock l(&s->mtx, release);\n   T cc = *c;\n   T pr = func_cas(a, cc, v);\n   bool success = pr == cc;\n   if (!success) {\n     *c = pr;\n     mo = fmo;\n   }\n+  thr->fast_state.IncrementEpoch();\n+  // Can't increment epoch w/o writing to the trace as well.\n+  TraceAddEvent(thr, thr->fast_state, EventTypeMop, 0);\n \n-  if (s) {\n-    thr->fast_state.IncrementEpoch();\n-    // Can't increment epoch w/o writing to the trace as well.\n-    TraceAddEvent(thr, thr->fast_state, EventTypeMop, 0);\n-\n-    if (success && IsAcqRelOrder(mo))\n-      AcquireReleaseImpl(thr, pc, &s->clock);\n-    else if (success && IsReleaseOrder(mo))\n-      ReleaseImpl(thr, pc, &s->clock);\n-    else if (IsAcquireOrder(mo))\n-      AcquireImpl(thr, pc, &s->clock);\n-\n-    if (write_lock)\n-      s->mtx.Unlock();\n-    else\n-      s->mtx.ReadUnlock();\n-  }\n-\n+  if (success && IsAcqRelOrder(mo))\n+    AcquireReleaseImpl(thr, pc, &s->clock);\n+  else if (success && IsReleaseOrder(mo))\n+    ReleaseImpl(thr, pc, &s->clock);\n+  else if (IsAcquireOrder(mo))\n+    AcquireImpl(thr, pc, &s->clock);\n   return success;\n }\n \n@@ -483,380 +480,356 @@ static morder convert_morder(morder mo) {\n   return (morder)(mo & 0x7fff);\n }\n \n-#define SCOPED_ATOMIC(func, ...) \\\n-    ThreadState *const thr = cur_thread(); \\\n-    if (UNLIKELY(thr->ignore_sync || thr->ignore_interceptors)) { \\\n-      ProcessPendingSignals(thr); \\\n-      return NoTsanAtomic##func(__VA_ARGS__); \\\n-    } \\\n-    const uptr callpc = (uptr)__builtin_return_address(0); \\\n-    uptr pc = StackTrace::GetCurrentPc(); \\\n-    mo = convert_morder(mo); \\\n-    ScopedAtomic sa(thr, callpc, a, mo, __func__); \\\n-    return Atomic##func(thr, pc, __VA_ARGS__); \\\n-/**/\n-\n-class ScopedAtomic {\n- public:\n-  ScopedAtomic(ThreadState *thr, uptr pc, const volatile void *a,\n-               morder mo, const char *func)\n-      : thr_(thr) {\n-    FuncEntry(thr_, pc);\n-    DPrintf(\"#%d: %s(%p, %d)\\n\", thr_->tid, func, a, mo);\n-  }\n-  ~ScopedAtomic() {\n-    ProcessPendingSignals(thr_);\n-    FuncExit(thr_);\n-  }\n- private:\n-  ThreadState *thr_;\n-};\n+#  define ATOMIC_IMPL(func, ...)                                \\\n+    ThreadState *const thr = cur_thread();                      \\\n+    ProcessPendingSignals(thr);                                 \\\n+    if (UNLIKELY(thr->ignore_sync || thr->ignore_interceptors)) \\\n+      return NoTsanAtomic##func(__VA_ARGS__);                   \\\n+    mo = convert_morder(mo);                                    \\\n+    return Atomic##func(thr, GET_CALLER_PC(), __VA_ARGS__);\n \n extern \"C\" {\n SANITIZER_INTERFACE_ATTRIBUTE\n a8 __tsan_atomic8_load(const volatile a8 *a, morder mo) {\n-  SCOPED_ATOMIC(Load, a, mo);\n+  ATOMIC_IMPL(Load, a, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a16 __tsan_atomic16_load(const volatile a16 *a, morder mo) {\n-  SCOPED_ATOMIC(Load, a, mo);\n+  ATOMIC_IMPL(Load, a, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a32 __tsan_atomic32_load(const volatile a32 *a, morder mo) {\n-  SCOPED_ATOMIC(Load, a, mo);\n+  ATOMIC_IMPL(Load, a, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a64 __tsan_atomic64_load(const volatile a64 *a, morder mo) {\n-  SCOPED_ATOMIC(Load, a, mo);\n+  ATOMIC_IMPL(Load, a, mo);\n }\n \n #if __TSAN_HAS_INT128\n SANITIZER_INTERFACE_ATTRIBUTE\n a128 __tsan_atomic128_load(const volatile a128 *a, morder mo) {\n-  SCOPED_ATOMIC(Load, a, mo);\n+  ATOMIC_IMPL(Load, a, mo);\n }\n #endif\n \n SANITIZER_INTERFACE_ATTRIBUTE\n void __tsan_atomic8_store(volatile a8 *a, a8 v, morder mo) {\n-  SCOPED_ATOMIC(Store, a, v, mo);\n+  ATOMIC_IMPL(Store, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n void __tsan_atomic16_store(volatile a16 *a, a16 v, morder mo) {\n-  SCOPED_ATOMIC(Store, a, v, mo);\n+  ATOMIC_IMPL(Store, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n void __tsan_atomic32_store(volatile a32 *a, a32 v, morder mo) {\n-  SCOPED_ATOMIC(Store, a, v, mo);\n+  ATOMIC_IMPL(Store, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n void __tsan_atomic64_store(volatile a64 *a, a64 v, morder mo) {\n-  SCOPED_ATOMIC(Store, a, v, mo);\n+  ATOMIC_IMPL(Store, a, v, mo);\n }\n \n #if __TSAN_HAS_INT128\n SANITIZER_INTERFACE_ATTRIBUTE\n void __tsan_atomic128_store(volatile a128 *a, a128 v, morder mo) {\n-  SCOPED_ATOMIC(Store, a, v, mo);\n+  ATOMIC_IMPL(Store, a, v, mo);\n }\n #endif\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a8 __tsan_atomic8_exchange(volatile a8 *a, a8 v, morder mo) {\n-  SCOPED_ATOMIC(Exchange, a, v, mo);\n+  ATOMIC_IMPL(Exchange, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a16 __tsan_atomic16_exchange(volatile a16 *a, a16 v, morder mo) {\n-  SCOPED_ATOMIC(Exchange, a, v, mo);\n+  ATOMIC_IMPL(Exchange, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a32 __tsan_atomic32_exchange(volatile a32 *a, a32 v, morder mo) {\n-  SCOPED_ATOMIC(Exchange, a, v, mo);\n+  ATOMIC_IMPL(Exchange, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a64 __tsan_atomic64_exchange(volatile a64 *a, a64 v, morder mo) {\n-  SCOPED_ATOMIC(Exchange, a, v, mo);\n+  ATOMIC_IMPL(Exchange, a, v, mo);\n }\n \n #if __TSAN_HAS_INT128\n SANITIZER_INTERFACE_ATTRIBUTE\n a128 __tsan_atomic128_exchange(volatile a128 *a, a128 v, morder mo) {\n-  SCOPED_ATOMIC(Exchange, a, v, mo);\n+  ATOMIC_IMPL(Exchange, a, v, mo);\n }\n #endif\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a8 __tsan_atomic8_fetch_add(volatile a8 *a, a8 v, morder mo) {\n-  SCOPED_ATOMIC(FetchAdd, a, v, mo);\n+  ATOMIC_IMPL(FetchAdd, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a16 __tsan_atomic16_fetch_add(volatile a16 *a, a16 v, morder mo) {\n-  SCOPED_ATOMIC(FetchAdd, a, v, mo);\n+  ATOMIC_IMPL(FetchAdd, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a32 __tsan_atomic32_fetch_add(volatile a32 *a, a32 v, morder mo) {\n-  SCOPED_ATOMIC(FetchAdd, a, v, mo);\n+  ATOMIC_IMPL(FetchAdd, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a64 __tsan_atomic64_fetch_add(volatile a64 *a, a64 v, morder mo) {\n-  SCOPED_ATOMIC(FetchAdd, a, v, mo);\n+  ATOMIC_IMPL(FetchAdd, a, v, mo);\n }\n \n #if __TSAN_HAS_INT128\n SANITIZER_INTERFACE_ATTRIBUTE\n a128 __tsan_atomic128_fetch_add(volatile a128 *a, a128 v, morder mo) {\n-  SCOPED_ATOMIC(FetchAdd, a, v, mo);\n+  ATOMIC_IMPL(FetchAdd, a, v, mo);\n }\n #endif\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a8 __tsan_atomic8_fetch_sub(volatile a8 *a, a8 v, morder mo) {\n-  SCOPED_ATOMIC(FetchSub, a, v, mo);\n+  ATOMIC_IMPL(FetchSub, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a16 __tsan_atomic16_fetch_sub(volatile a16 *a, a16 v, morder mo) {\n-  SCOPED_ATOMIC(FetchSub, a, v, mo);\n+  ATOMIC_IMPL(FetchSub, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a32 __tsan_atomic32_fetch_sub(volatile a32 *a, a32 v, morder mo) {\n-  SCOPED_ATOMIC(FetchSub, a, v, mo);\n+  ATOMIC_IMPL(FetchSub, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a64 __tsan_atomic64_fetch_sub(volatile a64 *a, a64 v, morder mo) {\n-  SCOPED_ATOMIC(FetchSub, a, v, mo);\n+  ATOMIC_IMPL(FetchSub, a, v, mo);\n }\n \n #if __TSAN_HAS_INT128\n SANITIZER_INTERFACE_ATTRIBUTE\n a128 __tsan_atomic128_fetch_sub(volatile a128 *a, a128 v, morder mo) {\n-  SCOPED_ATOMIC(FetchSub, a, v, mo);\n+  ATOMIC_IMPL(FetchSub, a, v, mo);\n }\n #endif\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a8 __tsan_atomic8_fetch_and(volatile a8 *a, a8 v, morder mo) {\n-  SCOPED_ATOMIC(FetchAnd, a, v, mo);\n+  ATOMIC_IMPL(FetchAnd, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a16 __tsan_atomic16_fetch_and(volatile a16 *a, a16 v, morder mo) {\n-  SCOPED_ATOMIC(FetchAnd, a, v, mo);\n+  ATOMIC_IMPL(FetchAnd, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a32 __tsan_atomic32_fetch_and(volatile a32 *a, a32 v, morder mo) {\n-  SCOPED_ATOMIC(FetchAnd, a, v, mo);\n+  ATOMIC_IMPL(FetchAnd, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a64 __tsan_atomic64_fetch_and(volatile a64 *a, a64 v, morder mo) {\n-  SCOPED_ATOMIC(FetchAnd, a, v, mo);\n+  ATOMIC_IMPL(FetchAnd, a, v, mo);\n }\n \n #if __TSAN_HAS_INT128\n SANITIZER_INTERFACE_ATTRIBUTE\n a128 __tsan_atomic128_fetch_and(volatile a128 *a, a128 v, morder mo) {\n-  SCOPED_ATOMIC(FetchAnd, a, v, mo);\n+  ATOMIC_IMPL(FetchAnd, a, v, mo);\n }\n #endif\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a8 __tsan_atomic8_fetch_or(volatile a8 *a, a8 v, morder mo) {\n-  SCOPED_ATOMIC(FetchOr, a, v, mo);\n+  ATOMIC_IMPL(FetchOr, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a16 __tsan_atomic16_fetch_or(volatile a16 *a, a16 v, morder mo) {\n-  SCOPED_ATOMIC(FetchOr, a, v, mo);\n+  ATOMIC_IMPL(FetchOr, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a32 __tsan_atomic32_fetch_or(volatile a32 *a, a32 v, morder mo) {\n-  SCOPED_ATOMIC(FetchOr, a, v, mo);\n+  ATOMIC_IMPL(FetchOr, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a64 __tsan_atomic64_fetch_or(volatile a64 *a, a64 v, morder mo) {\n-  SCOPED_ATOMIC(FetchOr, a, v, mo);\n+  ATOMIC_IMPL(FetchOr, a, v, mo);\n }\n \n #if __TSAN_HAS_INT128\n SANITIZER_INTERFACE_ATTRIBUTE\n a128 __tsan_atomic128_fetch_or(volatile a128 *a, a128 v, morder mo) {\n-  SCOPED_ATOMIC(FetchOr, a, v, mo);\n+  ATOMIC_IMPL(FetchOr, a, v, mo);\n }\n #endif\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a8 __tsan_atomic8_fetch_xor(volatile a8 *a, a8 v, morder mo) {\n-  SCOPED_ATOMIC(FetchXor, a, v, mo);\n+  ATOMIC_IMPL(FetchXor, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a16 __tsan_atomic16_fetch_xor(volatile a16 *a, a16 v, morder mo) {\n-  SCOPED_ATOMIC(FetchXor, a, v, mo);\n+  ATOMIC_IMPL(FetchXor, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a32 __tsan_atomic32_fetch_xor(volatile a32 *a, a32 v, morder mo) {\n-  SCOPED_ATOMIC(FetchXor, a, v, mo);\n+  ATOMIC_IMPL(FetchXor, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a64 __tsan_atomic64_fetch_xor(volatile a64 *a, a64 v, morder mo) {\n-  SCOPED_ATOMIC(FetchXor, a, v, mo);\n+  ATOMIC_IMPL(FetchXor, a, v, mo);\n }\n \n #if __TSAN_HAS_INT128\n SANITIZER_INTERFACE_ATTRIBUTE\n a128 __tsan_atomic128_fetch_xor(volatile a128 *a, a128 v, morder mo) {\n-  SCOPED_ATOMIC(FetchXor, a, v, mo);\n+  ATOMIC_IMPL(FetchXor, a, v, mo);\n }\n #endif\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a8 __tsan_atomic8_fetch_nand(volatile a8 *a, a8 v, morder mo) {\n-  SCOPED_ATOMIC(FetchNand, a, v, mo);\n+  ATOMIC_IMPL(FetchNand, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a16 __tsan_atomic16_fetch_nand(volatile a16 *a, a16 v, morder mo) {\n-  SCOPED_ATOMIC(FetchNand, a, v, mo);\n+  ATOMIC_IMPL(FetchNand, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a32 __tsan_atomic32_fetch_nand(volatile a32 *a, a32 v, morder mo) {\n-  SCOPED_ATOMIC(FetchNand, a, v, mo);\n+  ATOMIC_IMPL(FetchNand, a, v, mo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a64 __tsan_atomic64_fetch_nand(volatile a64 *a, a64 v, morder mo) {\n-  SCOPED_ATOMIC(FetchNand, a, v, mo);\n+  ATOMIC_IMPL(FetchNand, a, v, mo);\n }\n \n #if __TSAN_HAS_INT128\n SANITIZER_INTERFACE_ATTRIBUTE\n a128 __tsan_atomic128_fetch_nand(volatile a128 *a, a128 v, morder mo) {\n-  SCOPED_ATOMIC(FetchNand, a, v, mo);\n+  ATOMIC_IMPL(FetchNand, a, v, mo);\n }\n #endif\n \n SANITIZER_INTERFACE_ATTRIBUTE\n int __tsan_atomic8_compare_exchange_strong(volatile a8 *a, a8 *c, a8 v,\n     morder mo, morder fmo) {\n-  SCOPED_ATOMIC(CAS, a, c, v, mo, fmo);\n+  ATOMIC_IMPL(CAS, a, c, v, mo, fmo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n int __tsan_atomic16_compare_exchange_strong(volatile a16 *a, a16 *c, a16 v,\n     morder mo, morder fmo) {\n-  SCOPED_ATOMIC(CAS, a, c, v, mo, fmo);\n+  ATOMIC_IMPL(CAS, a, c, v, mo, fmo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n int __tsan_atomic32_compare_exchange_strong(volatile a32 *a, a32 *c, a32 v,\n     morder mo, morder fmo) {\n-  SCOPED_ATOMIC(CAS, a, c, v, mo, fmo);\n+  ATOMIC_IMPL(CAS, a, c, v, mo, fmo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n int __tsan_atomic64_compare_exchange_strong(volatile a64 *a, a64 *c, a64 v,\n     morder mo, morder fmo) {\n-  SCOPED_ATOMIC(CAS, a, c, v, mo, fmo);\n+  ATOMIC_IMPL(CAS, a, c, v, mo, fmo);\n }\n \n #if __TSAN_HAS_INT128\n SANITIZER_INTERFACE_ATTRIBUTE\n int __tsan_atomic128_compare_exchange_strong(volatile a128 *a, a128 *c, a128 v,\n     morder mo, morder fmo) {\n-  SCOPED_ATOMIC(CAS, a, c, v, mo, fmo);\n+  ATOMIC_IMPL(CAS, a, c, v, mo, fmo);\n }\n #endif\n \n SANITIZER_INTERFACE_ATTRIBUTE\n int __tsan_atomic8_compare_exchange_weak(volatile a8 *a, a8 *c, a8 v,\n     morder mo, morder fmo) {\n-  SCOPED_ATOMIC(CAS, a, c, v, mo, fmo);\n+  ATOMIC_IMPL(CAS, a, c, v, mo, fmo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n int __tsan_atomic16_compare_exchange_weak(volatile a16 *a, a16 *c, a16 v,\n     morder mo, morder fmo) {\n-  SCOPED_ATOMIC(CAS, a, c, v, mo, fmo);\n+  ATOMIC_IMPL(CAS, a, c, v, mo, fmo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n int __tsan_atomic32_compare_exchange_weak(volatile a32 *a, a32 *c, a32 v,\n     morder mo, morder fmo) {\n-  SCOPED_ATOMIC(CAS, a, c, v, mo, fmo);\n+  ATOMIC_IMPL(CAS, a, c, v, mo, fmo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n int __tsan_atomic64_compare_exchange_weak(volatile a64 *a, a64 *c, a64 v,\n     morder mo, morder fmo) {\n-  SCOPED_ATOMIC(CAS, a, c, v, mo, fmo);\n+  ATOMIC_IMPL(CAS, a, c, v, mo, fmo);\n }\n \n #if __TSAN_HAS_INT128\n SANITIZER_INTERFACE_ATTRIBUTE\n int __tsan_atomic128_compare_exchange_weak(volatile a128 *a, a128 *c, a128 v,\n     morder mo, morder fmo) {\n-  SCOPED_ATOMIC(CAS, a, c, v, mo, fmo);\n+  ATOMIC_IMPL(CAS, a, c, v, mo, fmo);\n }\n #endif\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a8 __tsan_atomic8_compare_exchange_val(volatile a8 *a, a8 c, a8 v,\n     morder mo, morder fmo) {\n-  SCOPED_ATOMIC(CAS, a, c, v, mo, fmo);\n+  ATOMIC_IMPL(CAS, a, c, v, mo, fmo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a16 __tsan_atomic16_compare_exchange_val(volatile a16 *a, a16 c, a16 v,\n     morder mo, morder fmo) {\n-  SCOPED_ATOMIC(CAS, a, c, v, mo, fmo);\n+  ATOMIC_IMPL(CAS, a, c, v, mo, fmo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a32 __tsan_atomic32_compare_exchange_val(volatile a32 *a, a32 c, a32 v,\n     morder mo, morder fmo) {\n-  SCOPED_ATOMIC(CAS, a, c, v, mo, fmo);\n+  ATOMIC_IMPL(CAS, a, c, v, mo, fmo);\n }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n a64 __tsan_atomic64_compare_exchange_val(volatile a64 *a, a64 c, a64 v,\n     morder mo, morder fmo) {\n-  SCOPED_ATOMIC(CAS, a, c, v, mo, fmo);\n+  ATOMIC_IMPL(CAS, a, c, v, mo, fmo);\n }\n \n #if __TSAN_HAS_INT128\n SANITIZER_INTERFACE_ATTRIBUTE\n a128 __tsan_atomic128_compare_exchange_val(volatile a128 *a, a128 c, a128 v,\n     morder mo, morder fmo) {\n-  SCOPED_ATOMIC(CAS, a, c, v, mo, fmo);\n+  ATOMIC_IMPL(CAS, a, c, v, mo, fmo);\n }\n #endif\n \n SANITIZER_INTERFACE_ATTRIBUTE\n-void __tsan_atomic_thread_fence(morder mo) {\n-  char* a = 0;\n-  SCOPED_ATOMIC(Fence, mo);\n-}\n+void __tsan_atomic_thread_fence(morder mo) { ATOMIC_IMPL(Fence, mo); }\n \n SANITIZER_INTERFACE_ATTRIBUTE\n void __tsan_atomic_signal_fence(morder mo) {\n@@ -867,25 +840,23 @@ void __tsan_atomic_signal_fence(morder mo) {\n \n // Go\n \n-#define ATOMIC(func, ...) \\\n-    if (thr->ignore_sync) { \\\n-      NoTsanAtomic##func(__VA_ARGS__); \\\n-    } else { \\\n-      FuncEntry(thr, cpc); \\\n+#  define ATOMIC(func, ...)               \\\n+    if (thr->ignore_sync) {               \\\n+      NoTsanAtomic##func(__VA_ARGS__);    \\\n+    } else {                              \\\n+      FuncEntry(thr, cpc);                \\\n       Atomic##func(thr, pc, __VA_ARGS__); \\\n-      FuncExit(thr); \\\n-    } \\\n-/**/\n-\n-#define ATOMIC_RET(func, ret, ...) \\\n-    if (thr->ignore_sync) { \\\n-      (ret) = NoTsanAtomic##func(__VA_ARGS__); \\\n-    } else { \\\n-      FuncEntry(thr, cpc); \\\n+      FuncExit(thr);                      \\\n+    }\n+\n+#  define ATOMIC_RET(func, ret, ...)              \\\n+    if (thr->ignore_sync) {                       \\\n+      (ret) = NoTsanAtomic##func(__VA_ARGS__);    \\\n+    } else {                                      \\\n+      FuncEntry(thr, cpc);                        \\\n       (ret) = Atomic##func(thr, pc, __VA_ARGS__); \\\n-      FuncExit(thr); \\\n-    } \\\n-/**/\n+      FuncExit(thr);                              \\\n+    }\n \n extern \"C\" {\n SANITIZER_INTERFACE_ATTRIBUTE"}, {"sha": "5e77d4d3d288b97a892ea78f09cb41fd60a66d22", "filename": "libsanitizer/tsan/tsan_interface_inl.h", "status": "removed", "additions": 0, "deletions": 133, "changes": 133, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7c99923f8c544ec07109e8333acb2c2388c38a1b/libsanitizer%2Ftsan%2Ftsan_interface_inl.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7c99923f8c544ec07109e8333acb2c2388c38a1b/libsanitizer%2Ftsan%2Ftsan_interface_inl.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_interface_inl.h?ref=7c99923f8c544ec07109e8333acb2c2388c38a1b", "patch": "@@ -1,133 +0,0 @@\n-//===-- tsan_interface_inl.h ------------------------------------*- C++ -*-===//\n-//\n-// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n-// See https://llvm.org/LICENSE.txt for license information.\n-// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n-//\n-//===----------------------------------------------------------------------===//\n-//\n-// This file is a part of ThreadSanitizer (TSan), a race detector.\n-//\n-//===----------------------------------------------------------------------===//\n-\n-#include \"tsan_interface.h\"\n-#include \"tsan_rtl.h\"\n-#include \"sanitizer_common/sanitizer_ptrauth.h\"\n-\n-#define CALLERPC ((uptr)__builtin_return_address(0))\n-\n-using namespace __tsan;\n-\n-void __tsan_read1(void *addr) {\n-  MemoryRead(cur_thread(), CALLERPC, (uptr)addr, kSizeLog1);\n-}\n-\n-void __tsan_read2(void *addr) {\n-  MemoryRead(cur_thread(), CALLERPC, (uptr)addr, kSizeLog2);\n-}\n-\n-void __tsan_read4(void *addr) {\n-  MemoryRead(cur_thread(), CALLERPC, (uptr)addr, kSizeLog4);\n-}\n-\n-void __tsan_read8(void *addr) {\n-  MemoryRead(cur_thread(), CALLERPC, (uptr)addr, kSizeLog8);\n-}\n-\n-void __tsan_write1(void *addr) {\n-  MemoryWrite(cur_thread(), CALLERPC, (uptr)addr, kSizeLog1);\n-}\n-\n-void __tsan_write2(void *addr) {\n-  MemoryWrite(cur_thread(), CALLERPC, (uptr)addr, kSizeLog2);\n-}\n-\n-void __tsan_write4(void *addr) {\n-  MemoryWrite(cur_thread(), CALLERPC, (uptr)addr, kSizeLog4);\n-}\n-\n-void __tsan_write8(void *addr) {\n-  MemoryWrite(cur_thread(), CALLERPC, (uptr)addr, kSizeLog8);\n-}\n-\n-void __tsan_read1_pc(void *addr, void *pc) {\n-  MemoryRead(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, kSizeLog1);\n-}\n-\n-void __tsan_read2_pc(void *addr, void *pc) {\n-  MemoryRead(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, kSizeLog2);\n-}\n-\n-void __tsan_read4_pc(void *addr, void *pc) {\n-  MemoryRead(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, kSizeLog4);\n-}\n-\n-void __tsan_read8_pc(void *addr, void *pc) {\n-  MemoryRead(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, kSizeLog8);\n-}\n-\n-void __tsan_write1_pc(void *addr, void *pc) {\n-  MemoryWrite(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, kSizeLog1);\n-}\n-\n-void __tsan_write2_pc(void *addr, void *pc) {\n-  MemoryWrite(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, kSizeLog2);\n-}\n-\n-void __tsan_write4_pc(void *addr, void *pc) {\n-  MemoryWrite(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, kSizeLog4);\n-}\n-\n-void __tsan_write8_pc(void *addr, void *pc) {\n-  MemoryWrite(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, kSizeLog8);\n-}\n-\n-void __tsan_vptr_update(void **vptr_p, void *new_val) {\n-  CHECK_EQ(sizeof(vptr_p), 8);\n-  if (*vptr_p != new_val) {\n-    ThreadState *thr = cur_thread();\n-    thr->is_vptr_access = true;\n-    MemoryWrite(thr, CALLERPC, (uptr)vptr_p, kSizeLog8);\n-    thr->is_vptr_access = false;\n-  }\n-}\n-\n-void __tsan_vptr_read(void **vptr_p) {\n-  CHECK_EQ(sizeof(vptr_p), 8);\n-  ThreadState *thr = cur_thread();\n-  thr->is_vptr_access = true;\n-  MemoryRead(thr, CALLERPC, (uptr)vptr_p, kSizeLog8);\n-  thr->is_vptr_access = false;\n-}\n-\n-void __tsan_func_entry(void *pc) {\n-  FuncEntry(cur_thread(), STRIP_PAC_PC(pc));\n-}\n-\n-void __tsan_func_exit() {\n-  FuncExit(cur_thread());\n-}\n-\n-void __tsan_ignore_thread_begin() {\n-  ThreadIgnoreBegin(cur_thread(), CALLERPC);\n-}\n-\n-void __tsan_ignore_thread_end() {\n-  ThreadIgnoreEnd(cur_thread(), CALLERPC);\n-}\n-\n-void __tsan_read_range(void *addr, uptr size) {\n-  MemoryAccessRange(cur_thread(), CALLERPC, (uptr)addr, size, false);\n-}\n-\n-void __tsan_write_range(void *addr, uptr size) {\n-  MemoryAccessRange(cur_thread(), CALLERPC, (uptr)addr, size, true);\n-}\n-\n-void __tsan_read_range_pc(void *addr, uptr size, void *pc) {\n-  MemoryAccessRange(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, size, false);\n-}\n-\n-void __tsan_write_range_pc(void *addr, uptr size, void *pc) {\n-  MemoryAccessRange(cur_thread(), STRIP_PAC_PC(pc), (uptr)addr, size, true);\n-}"}, {"sha": "c090c1f08cbeb8df3f350079c99418d2aa3fff6e", "filename": "libsanitizer/tsan/tsan_interface_java.cpp", "status": "modified", "additions": 141, "deletions": 150, "changes": 291, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interface_java.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_interface_java.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_interface_java.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -12,7 +12,6 @@\n \n #include \"tsan_interface_java.h\"\n #include \"tsan_rtl.h\"\n-#include \"tsan_mutex.h\"\n #include \"sanitizer_common/sanitizer_internal_defs.h\"\n #include \"sanitizer_common/sanitizer_common.h\"\n #include \"sanitizer_common/sanitizer_placement_new.h\"\n@@ -35,127 +34,115 @@ struct JavaContext {\n   }\n };\n \n-class ScopedJavaFunc {\n- public:\n-  ScopedJavaFunc(ThreadState *thr, uptr pc)\n-      : thr_(thr) {\n-    Initialize(thr_);\n-    FuncEntry(thr, pc);\n-  }\n-\n-  ~ScopedJavaFunc() {\n-    FuncExit(thr_);\n-    // FIXME(dvyukov): process pending signals.\n-  }\n-\n- private:\n-  ThreadState *thr_;\n-};\n-\n static u64 jctx_buf[sizeof(JavaContext) / sizeof(u64) + 1];\n static JavaContext *jctx;\n \n+MBlock *JavaHeapBlock(uptr addr, uptr *start) {\n+  if (!jctx || addr < jctx->heap_begin ||\n+      addr >= jctx->heap_begin + jctx->heap_size)\n+    return nullptr;\n+  for (uptr p = RoundDown(addr, kMetaShadowCell); p >= jctx->heap_begin;\n+       p -= kMetaShadowCell) {\n+    MBlock *b = ctx->metamap.GetBlock(p);\n+    if (!b)\n+      continue;\n+    if (p + b->siz <= addr)\n+      return nullptr;\n+    *start = p;\n+    return b;\n+  }\n+  return nullptr;\n+}\n+\n }  // namespace __tsan\n \n-#define SCOPED_JAVA_FUNC(func) \\\n+#define JAVA_FUNC_ENTER(func)      \\\n   ThreadState *thr = cur_thread(); \\\n-  const uptr caller_pc = GET_CALLER_PC(); \\\n-  const uptr pc = StackTrace::GetCurrentPc(); \\\n-  (void)pc; \\\n-  ScopedJavaFunc scoped(thr, caller_pc); \\\n-/**/\n+  (void)thr;\n \n void __tsan_java_init(jptr heap_begin, jptr heap_size) {\n-  SCOPED_JAVA_FUNC(__tsan_java_init);\n-  DPrintf(\"#%d: java_init(%p, %p)\\n\", thr->tid, heap_begin, heap_size);\n-  CHECK_EQ(jctx, 0);\n-  CHECK_GT(heap_begin, 0);\n-  CHECK_GT(heap_size, 0);\n-  CHECK_EQ(heap_begin % kHeapAlignment, 0);\n-  CHECK_EQ(heap_size % kHeapAlignment, 0);\n-  CHECK_LT(heap_begin, heap_begin + heap_size);\n+  JAVA_FUNC_ENTER(__tsan_java_init);\n+  Initialize(thr);\n+  DPrintf(\"#%d: java_init(0x%zx, 0x%zx)\\n\", thr->tid, heap_begin, heap_size);\n+  DCHECK_EQ(jctx, 0);\n+  DCHECK_GT(heap_begin, 0);\n+  DCHECK_GT(heap_size, 0);\n+  DCHECK_EQ(heap_begin % kHeapAlignment, 0);\n+  DCHECK_EQ(heap_size % kHeapAlignment, 0);\n+  DCHECK_LT(heap_begin, heap_begin + heap_size);\n   jctx = new(jctx_buf) JavaContext(heap_begin, heap_size);\n }\n \n int  __tsan_java_fini() {\n-  SCOPED_JAVA_FUNC(__tsan_java_fini);\n+  JAVA_FUNC_ENTER(__tsan_java_fini);\n   DPrintf(\"#%d: java_fini()\\n\", thr->tid);\n-  CHECK_NE(jctx, 0);\n+  DCHECK_NE(jctx, 0);\n   // FIXME(dvyukov): this does not call atexit() callbacks.\n   int status = Finalize(thr);\n   DPrintf(\"#%d: java_fini() = %d\\n\", thr->tid, status);\n   return status;\n }\n \n void __tsan_java_alloc(jptr ptr, jptr size) {\n-  SCOPED_JAVA_FUNC(__tsan_java_alloc);\n-  DPrintf(\"#%d: java_alloc(%p, %p)\\n\", thr->tid, ptr, size);\n-  CHECK_NE(jctx, 0);\n-  CHECK_NE(size, 0);\n-  CHECK_EQ(ptr % kHeapAlignment, 0);\n-  CHECK_EQ(size % kHeapAlignment, 0);\n-  CHECK_GE(ptr, jctx->heap_begin);\n-  CHECK_LE(ptr + size, jctx->heap_begin + jctx->heap_size);\n-\n-  OnUserAlloc(thr, pc, ptr, size, false);\n+  JAVA_FUNC_ENTER(__tsan_java_alloc);\n+  DPrintf(\"#%d: java_alloc(0x%zx, 0x%zx)\\n\", thr->tid, ptr, size);\n+  DCHECK_NE(jctx, 0);\n+  DCHECK_NE(size, 0);\n+  DCHECK_EQ(ptr % kHeapAlignment, 0);\n+  DCHECK_EQ(size % kHeapAlignment, 0);\n+  DCHECK_GE(ptr, jctx->heap_begin);\n+  DCHECK_LE(ptr + size, jctx->heap_begin + jctx->heap_size);\n+\n+  OnUserAlloc(thr, 0, ptr, size, false);\n }\n \n void __tsan_java_free(jptr ptr, jptr size) {\n-  SCOPED_JAVA_FUNC(__tsan_java_free);\n-  DPrintf(\"#%d: java_free(%p, %p)\\n\", thr->tid, ptr, size);\n-  CHECK_NE(jctx, 0);\n-  CHECK_NE(size, 0);\n-  CHECK_EQ(ptr % kHeapAlignment, 0);\n-  CHECK_EQ(size % kHeapAlignment, 0);\n-  CHECK_GE(ptr, jctx->heap_begin);\n-  CHECK_LE(ptr + size, jctx->heap_begin + jctx->heap_size);\n+  JAVA_FUNC_ENTER(__tsan_java_free);\n+  DPrintf(\"#%d: java_free(0x%zx, 0x%zx)\\n\", thr->tid, ptr, size);\n+  DCHECK_NE(jctx, 0);\n+  DCHECK_NE(size, 0);\n+  DCHECK_EQ(ptr % kHeapAlignment, 0);\n+  DCHECK_EQ(size % kHeapAlignment, 0);\n+  DCHECK_GE(ptr, jctx->heap_begin);\n+  DCHECK_LE(ptr + size, jctx->heap_begin + jctx->heap_size);\n \n   ctx->metamap.FreeRange(thr->proc(), ptr, size);\n }\n \n void __tsan_java_move(jptr src, jptr dst, jptr size) {\n-  SCOPED_JAVA_FUNC(__tsan_java_move);\n-  DPrintf(\"#%d: java_move(%p, %p, %p)\\n\", thr->tid, src, dst, size);\n-  CHECK_NE(jctx, 0);\n-  CHECK_NE(size, 0);\n-  CHECK_EQ(src % kHeapAlignment, 0);\n-  CHECK_EQ(dst % kHeapAlignment, 0);\n-  CHECK_EQ(size % kHeapAlignment, 0);\n-  CHECK_GE(src, jctx->heap_begin);\n-  CHECK_LE(src + size, jctx->heap_begin + jctx->heap_size);\n-  CHECK_GE(dst, jctx->heap_begin);\n-  CHECK_LE(dst + size, jctx->heap_begin + jctx->heap_size);\n-  CHECK_NE(dst, src);\n-  CHECK_NE(size, 0);\n+  JAVA_FUNC_ENTER(__tsan_java_move);\n+  DPrintf(\"#%d: java_move(0x%zx, 0x%zx, 0x%zx)\\n\", thr->tid, src, dst, size);\n+  DCHECK_NE(jctx, 0);\n+  DCHECK_NE(size, 0);\n+  DCHECK_EQ(src % kHeapAlignment, 0);\n+  DCHECK_EQ(dst % kHeapAlignment, 0);\n+  DCHECK_EQ(size % kHeapAlignment, 0);\n+  DCHECK_GE(src, jctx->heap_begin);\n+  DCHECK_LE(src + size, jctx->heap_begin + jctx->heap_size);\n+  DCHECK_GE(dst, jctx->heap_begin);\n+  DCHECK_LE(dst + size, jctx->heap_begin + jctx->heap_size);\n+  DCHECK_NE(dst, src);\n+  DCHECK_NE(size, 0);\n \n   // Assuming it's not running concurrently with threads that do\n   // memory accesses and mutex operations (stop-the-world phase).\n   ctx->metamap.MoveMemory(src, dst, size);\n \n-  // Move shadow.\n-  u64 *s = (u64*)MemToShadow(src);\n-  u64 *d = (u64*)MemToShadow(dst);\n-  u64 *send = (u64*)MemToShadow(src + size);\n-  uptr inc = 1;\n-  if (dst > src) {\n-    s = (u64*)MemToShadow(src + size) - 1;\n-    d = (u64*)MemToShadow(dst + size) - 1;\n-    send = (u64*)MemToShadow(src) - 1;\n-    inc = -1;\n-  }\n-  for (; s != send; s += inc, d += inc) {\n-    *d = *s;\n-    *s = 0;\n-  }\n+  // Clear the destination shadow range.\n+  // We used to move shadow from src to dst, but the trace format does not\n+  // support that anymore as it contains addresses of accesses.\n+  RawShadow *d = MemToShadow(dst);\n+  RawShadow *dend = MemToShadow(dst + size);\n+  internal_memset(d, 0, (dend - d) * sizeof(*d));\n }\n \n jptr __tsan_java_find(jptr *from_ptr, jptr to) {\n-  SCOPED_JAVA_FUNC(__tsan_java_find);\n-  DPrintf(\"#%d: java_find(&%p, %p)\\n\", *from_ptr, to);\n-  CHECK_EQ((*from_ptr) % kHeapAlignment, 0);\n-  CHECK_EQ(to % kHeapAlignment, 0);\n-  CHECK_GE(*from_ptr, jctx->heap_begin);\n-  CHECK_LE(to, jctx->heap_begin + jctx->heap_size);\n+  JAVA_FUNC_ENTER(__tsan_java_find);\n+  DPrintf(\"#%d: java_find(&0x%zx, 0x%zx)\\n\", thr->tid, *from_ptr, to);\n+  DCHECK_EQ((*from_ptr) % kHeapAlignment, 0);\n+  DCHECK_EQ(to % kHeapAlignment, 0);\n+  DCHECK_GE(*from_ptr, jctx->heap_begin);\n+  DCHECK_LE(to, jctx->heap_begin + jctx->heap_size);\n   for (uptr from = *from_ptr; from < to; from += kHeapAlignment) {\n     MBlock *b = ctx->metamap.GetBlock(from);\n     if (b) {\n@@ -167,101 +154,105 @@ jptr __tsan_java_find(jptr *from_ptr, jptr to) {\n }\n \n void __tsan_java_finalize() {\n-  SCOPED_JAVA_FUNC(__tsan_java_finalize);\n-  DPrintf(\"#%d: java_mutex_finalize()\\n\", thr->tid);\n-  AcquireGlobal(thr, 0);\n+  JAVA_FUNC_ENTER(__tsan_java_finalize);\n+  DPrintf(\"#%d: java_finalize()\\n\", thr->tid);\n+  AcquireGlobal(thr);\n }\n \n void __tsan_java_mutex_lock(jptr addr) {\n-  SCOPED_JAVA_FUNC(__tsan_java_mutex_lock);\n-  DPrintf(\"#%d: java_mutex_lock(%p)\\n\", thr->tid, addr);\n-  CHECK_NE(jctx, 0);\n-  CHECK_GE(addr, jctx->heap_begin);\n-  CHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n-\n-  MutexPostLock(thr, pc, addr, MutexFlagLinkerInit | MutexFlagWriteReentrant |\n-      MutexFlagDoPreLockOnPostLock);\n+  JAVA_FUNC_ENTER(__tsan_java_mutex_lock);\n+  DPrintf(\"#%d: java_mutex_lock(0x%zx)\\n\", thr->tid, addr);\n+  DCHECK_NE(jctx, 0);\n+  DCHECK_GE(addr, jctx->heap_begin);\n+  DCHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n+\n+  MutexPostLock(thr, 0, addr,\n+                MutexFlagLinkerInit | MutexFlagWriteReentrant |\n+                    MutexFlagDoPreLockOnPostLock);\n }\n \n void __tsan_java_mutex_unlock(jptr addr) {\n-  SCOPED_JAVA_FUNC(__tsan_java_mutex_unlock);\n-  DPrintf(\"#%d: java_mutex_unlock(%p)\\n\", thr->tid, addr);\n-  CHECK_NE(jctx, 0);\n-  CHECK_GE(addr, jctx->heap_begin);\n-  CHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n+  JAVA_FUNC_ENTER(__tsan_java_mutex_unlock);\n+  DPrintf(\"#%d: java_mutex_unlock(0x%zx)\\n\", thr->tid, addr);\n+  DCHECK_NE(jctx, 0);\n+  DCHECK_GE(addr, jctx->heap_begin);\n+  DCHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n \n-  MutexUnlock(thr, pc, addr);\n+  MutexUnlock(thr, 0, addr);\n }\n \n void __tsan_java_mutex_read_lock(jptr addr) {\n-  SCOPED_JAVA_FUNC(__tsan_java_mutex_read_lock);\n-  DPrintf(\"#%d: java_mutex_read_lock(%p)\\n\", thr->tid, addr);\n-  CHECK_NE(jctx, 0);\n-  CHECK_GE(addr, jctx->heap_begin);\n-  CHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n-\n-  MutexPostReadLock(thr, pc, addr, MutexFlagLinkerInit |\n-      MutexFlagWriteReentrant | MutexFlagDoPreLockOnPostLock);\n+  JAVA_FUNC_ENTER(__tsan_java_mutex_read_lock);\n+  DPrintf(\"#%d: java_mutex_read_lock(0x%zx)\\n\", thr->tid, addr);\n+  DCHECK_NE(jctx, 0);\n+  DCHECK_GE(addr, jctx->heap_begin);\n+  DCHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n+\n+  MutexPostReadLock(thr, 0, addr,\n+                    MutexFlagLinkerInit | MutexFlagWriteReentrant |\n+                        MutexFlagDoPreLockOnPostLock);\n }\n \n void __tsan_java_mutex_read_unlock(jptr addr) {\n-  SCOPED_JAVA_FUNC(__tsan_java_mutex_read_unlock);\n-  DPrintf(\"#%d: java_mutex_read_unlock(%p)\\n\", thr->tid, addr);\n-  CHECK_NE(jctx, 0);\n-  CHECK_GE(addr, jctx->heap_begin);\n-  CHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n+  JAVA_FUNC_ENTER(__tsan_java_mutex_read_unlock);\n+  DPrintf(\"#%d: java_mutex_read_unlock(0x%zx)\\n\", thr->tid, addr);\n+  DCHECK_NE(jctx, 0);\n+  DCHECK_GE(addr, jctx->heap_begin);\n+  DCHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n \n-  MutexReadUnlock(thr, pc, addr);\n+  MutexReadUnlock(thr, 0, addr);\n }\n \n void __tsan_java_mutex_lock_rec(jptr addr, int rec) {\n-  SCOPED_JAVA_FUNC(__tsan_java_mutex_lock_rec);\n-  DPrintf(\"#%d: java_mutex_lock_rec(%p, %d)\\n\", thr->tid, addr, rec);\n-  CHECK_NE(jctx, 0);\n-  CHECK_GE(addr, jctx->heap_begin);\n-  CHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n-  CHECK_GT(rec, 0);\n-\n-  MutexPostLock(thr, pc, addr, MutexFlagLinkerInit | MutexFlagWriteReentrant |\n-      MutexFlagDoPreLockOnPostLock | MutexFlagRecursiveLock, rec);\n+  JAVA_FUNC_ENTER(__tsan_java_mutex_lock_rec);\n+  DPrintf(\"#%d: java_mutex_lock_rec(0x%zx, %d)\\n\", thr->tid, addr, rec);\n+  DCHECK_NE(jctx, 0);\n+  DCHECK_GE(addr, jctx->heap_begin);\n+  DCHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n+  DCHECK_GT(rec, 0);\n+\n+  MutexPostLock(thr, 0, addr,\n+                MutexFlagLinkerInit | MutexFlagWriteReentrant |\n+                    MutexFlagDoPreLockOnPostLock | MutexFlagRecursiveLock,\n+                rec);\n }\n \n int __tsan_java_mutex_unlock_rec(jptr addr) {\n-  SCOPED_JAVA_FUNC(__tsan_java_mutex_unlock_rec);\n-  DPrintf(\"#%d: java_mutex_unlock_rec(%p)\\n\", thr->tid, addr);\n-  CHECK_NE(jctx, 0);\n-  CHECK_GE(addr, jctx->heap_begin);\n-  CHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n+  JAVA_FUNC_ENTER(__tsan_java_mutex_unlock_rec);\n+  DPrintf(\"#%d: java_mutex_unlock_rec(0x%zx)\\n\", thr->tid, addr);\n+  DCHECK_NE(jctx, 0);\n+  DCHECK_GE(addr, jctx->heap_begin);\n+  DCHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n \n-  return MutexUnlock(thr, pc, addr, MutexFlagRecursiveUnlock);\n+  return MutexUnlock(thr, 0, addr, MutexFlagRecursiveUnlock);\n }\n \n void __tsan_java_acquire(jptr addr) {\n-  SCOPED_JAVA_FUNC(__tsan_java_acquire);\n-  DPrintf(\"#%d: java_acquire(%p)\\n\", thr->tid, addr);\n-  CHECK_NE(jctx, 0);\n-  CHECK_GE(addr, jctx->heap_begin);\n-  CHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n+  JAVA_FUNC_ENTER(__tsan_java_acquire);\n+  DPrintf(\"#%d: java_acquire(0x%zx)\\n\", thr->tid, addr);\n+  DCHECK_NE(jctx, 0);\n+  DCHECK_GE(addr, jctx->heap_begin);\n+  DCHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n \n-  Acquire(thr, caller_pc, addr);\n+  Acquire(thr, 0, addr);\n }\n \n void __tsan_java_release(jptr addr) {\n-  SCOPED_JAVA_FUNC(__tsan_java_release);\n-  DPrintf(\"#%d: java_release(%p)\\n\", thr->tid, addr);\n-  CHECK_NE(jctx, 0);\n-  CHECK_GE(addr, jctx->heap_begin);\n-  CHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n+  JAVA_FUNC_ENTER(__tsan_java_release);\n+  DPrintf(\"#%d: java_release(0x%zx)\\n\", thr->tid, addr);\n+  DCHECK_NE(jctx, 0);\n+  DCHECK_GE(addr, jctx->heap_begin);\n+  DCHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n \n-  Release(thr, caller_pc, addr);\n+  Release(thr, 0, addr);\n }\n \n void __tsan_java_release_store(jptr addr) {\n-  SCOPED_JAVA_FUNC(__tsan_java_release);\n-  DPrintf(\"#%d: java_release_store(%p)\\n\", thr->tid, addr);\n-  CHECK_NE(jctx, 0);\n-  CHECK_GE(addr, jctx->heap_begin);\n-  CHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n+  JAVA_FUNC_ENTER(__tsan_java_release);\n+  DPrintf(\"#%d: java_release_store(0x%zx)\\n\", thr->tid, addr);\n+  DCHECK_NE(jctx, 0);\n+  DCHECK_GE(addr, jctx->heap_begin);\n+  DCHECK_LT(addr, jctx->heap_begin + jctx->heap_size);\n \n-  ReleaseStore(thr, caller_pc, addr);\n+  ReleaseStore(thr, 0, addr);\n }"}, {"sha": "f1b6768c5921be7e9b352877870ff945e19e6c0c", "filename": "libsanitizer/tsan/tsan_mman.cpp", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_mman.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_mman.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_mman.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -148,7 +148,7 @@ static void SignalUnsafeCall(ThreadState *thr, uptr pc) {\n   ObtainCurrentStack(thr, pc, &stack);\n   if (IsFiredSuppression(ctx, ReportTypeSignalUnsafe, stack))\n     return;\n-  ThreadRegistryLock l(ctx->thread_registry);\n+  ThreadRegistryLock l(&ctx->thread_registry);\n   ScopedReport rep(ReportTypeSignalUnsafe);\n   rep.AddStack(stack, true);\n   OutputReport(thr, rep);\n@@ -218,7 +218,7 @@ void *user_reallocarray(ThreadState *thr, uptr pc, void *p, uptr size, uptr n) {\n }\n \n void OnUserAlloc(ThreadState *thr, uptr pc, uptr p, uptr sz, bool write) {\n-  DPrintf(\"#%d: alloc(%zu) = %p\\n\", thr->tid, sz, p);\n+  DPrintf(\"#%d: alloc(%zu) = 0x%zx\\n\", thr->tid, sz, p);\n   ctx->metamap.AllocBlock(thr, pc, p, sz);\n   if (write && thr->ignore_reads_and_writes == 0)\n     MemoryRangeImitateWrite(thr, pc, (uptr)p, sz);\n@@ -229,7 +229,7 @@ void OnUserAlloc(ThreadState *thr, uptr pc, uptr p, uptr sz, bool write) {\n void OnUserFree(ThreadState *thr, uptr pc, uptr p, bool write) {\n   CHECK_NE(p, (void*)0);\n   uptr sz = ctx->metamap.FreeBlock(thr->proc(), p);\n-  DPrintf(\"#%d: free(%p, %zu)\\n\", thr->tid, p, sz);\n+  DPrintf(\"#%d: free(0x%zx, %zu)\\n\", thr->tid, p, sz);\n   if (write && thr->ignore_reads_and_writes == 0)\n     MemoryRangeFreed(thr, pc, (uptr)p, sz);\n }\n@@ -336,7 +336,7 @@ void invoke_free_hook(void *ptr) {\n   RunFreeHooks(ptr);\n }\n \n-void *internal_alloc(MBlockType typ, uptr sz) {\n+void *Alloc(uptr sz) {\n   ThreadState *thr = cur_thread();\n   if (thr->nomalloc) {\n     thr->nomalloc = 0;  // CHECK calls internal_malloc().\n@@ -345,7 +345,7 @@ void *internal_alloc(MBlockType typ, uptr sz) {\n   return InternalAlloc(sz, &thr->proc()->internal_alloc_cache);\n }\n \n-void internal_free(void *p) {\n+void FreeImpl(void *p) {\n   ThreadState *thr = cur_thread();\n   if (thr->nomalloc) {\n     thr->nomalloc = 0;  // CHECK calls internal_malloc()."}, {"sha": "efea5e5abdec7a97d7ca0b619900ef26aaf97cca", "filename": "libsanitizer/tsan/tsan_mman.h", "status": "modified", "additions": 18, "deletions": 31, "changes": 49, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_mman.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_mman.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_mman.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -47,42 +47,29 @@ uptr user_alloc_usable_size(const void *p);\n void invoke_malloc_hook(void *ptr, uptr size);\n void invoke_free_hook(void *ptr);\n \n-enum MBlockType {\n-  MBlockScopedBuf,\n-  MBlockString,\n-  MBlockStackTrace,\n-  MBlockShadowStack,\n-  MBlockSync,\n-  MBlockClock,\n-  MBlockThreadContex,\n-  MBlockDeadInfo,\n-  MBlockRacyStacks,\n-  MBlockRacyAddresses,\n-  MBlockAtExit,\n-  MBlockFlag,\n-  MBlockReport,\n-  MBlockReportMop,\n-  MBlockReportThread,\n-  MBlockReportMutex,\n-  MBlockReportLoc,\n-  MBlockReportStack,\n-  MBlockSuppression,\n-  MBlockExpectRace,\n-  MBlockSignal,\n-  MBlockJmpBuf,\n+// For internal data structures.\n+void *Alloc(uptr sz);\n+void FreeImpl(void *p);\n \n-  // This must be the last.\n-  MBlockTypeCount\n-};\n+template <typename T, typename... Args>\n+T *New(Args &&...args) {\n+  return new (Alloc(sizeof(T))) T(static_cast<Args &&>(args)...);\n+}\n \n-// For internal data structures.\n-void *internal_alloc(MBlockType typ, uptr sz);\n-void internal_free(void *p);\n+template <typename T>\n+void Free(T *&p) {\n+  if (p == nullptr)\n+    return;\n+  FreeImpl(p);\n+  p = nullptr;\n+}\n \n template <typename T>\n-void DestroyAndFree(T *p) {\n+void DestroyAndFree(T *&p) {\n+  if (p == nullptr)\n+    return;\n   p->~T();\n-  internal_free(p);\n+  Free(p);\n }\n \n }  // namespace __tsan"}, {"sha": "d8b1826ee47bba38fba5309ad58ab0817dc356b9", "filename": "libsanitizer/tsan/tsan_mutex.cpp", "status": "removed", "additions": 0, "deletions": 280, "changes": 280, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7c99923f8c544ec07109e8333acb2c2388c38a1b/libsanitizer%2Ftsan%2Ftsan_mutex.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7c99923f8c544ec07109e8333acb2c2388c38a1b/libsanitizer%2Ftsan%2Ftsan_mutex.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_mutex.cpp?ref=7c99923f8c544ec07109e8333acb2c2388c38a1b", "patch": "@@ -1,280 +0,0 @@\n-//===-- tsan_mutex.cpp ----------------------------------------------------===//\n-//\n-// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n-// See https://llvm.org/LICENSE.txt for license information.\n-// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n-//\n-//===----------------------------------------------------------------------===//\n-//\n-// This file is a part of ThreadSanitizer (TSan), a race detector.\n-//\n-//===----------------------------------------------------------------------===//\n-#include \"sanitizer_common/sanitizer_libc.h\"\n-#include \"tsan_mutex.h\"\n-#include \"tsan_platform.h\"\n-#include \"tsan_rtl.h\"\n-\n-namespace __tsan {\n-\n-// Simple reader-writer spin-mutex. Optimized for not-so-contended case.\n-// Readers have preference, can possibly starvate writers.\n-\n-// The table fixes what mutexes can be locked under what mutexes.\n-// E.g. if the row for MutexTypeThreads contains MutexTypeReport,\n-// then Report mutex can be locked while under Threads mutex.\n-// The leaf mutexes can be locked under any other mutexes.\n-// Recursive locking is not supported.\n-#if SANITIZER_DEBUG && !SANITIZER_GO\n-const MutexType MutexTypeLeaf = (MutexType)-1;\n-static MutexType CanLockTab[MutexTypeCount][MutexTypeCount] = {\n-  /*0  MutexTypeInvalid*/     {},\n-  /*1  MutexTypeTrace*/       {MutexTypeLeaf},\n-  /*2  MutexTypeThreads*/     {MutexTypeReport},\n-  /*3  MutexTypeReport*/      {MutexTypeSyncVar,\n-                               MutexTypeMBlock, MutexTypeJavaMBlock},\n-  /*4  MutexTypeSyncVar*/     {MutexTypeDDetector},\n-  /*5  MutexTypeSyncTab*/     {},  // unused\n-  /*6  MutexTypeSlab*/        {MutexTypeLeaf},\n-  /*7  MutexTypeAnnotations*/ {},\n-  /*8  MutexTypeAtExit*/      {MutexTypeSyncVar},\n-  /*9  MutexTypeMBlock*/      {MutexTypeSyncVar},\n-  /*10 MutexTypeJavaMBlock*/  {MutexTypeSyncVar},\n-  /*11 MutexTypeDDetector*/   {},\n-  /*12 MutexTypeFired*/       {MutexTypeLeaf},\n-  /*13 MutexTypeRacy*/        {MutexTypeLeaf},\n-  /*14 MutexTypeGlobalProc*/  {},\n-};\n-\n-static bool CanLockAdj[MutexTypeCount][MutexTypeCount];\n-#endif\n-\n-void InitializeMutex() {\n-#if SANITIZER_DEBUG && !SANITIZER_GO\n-  // Build the \"can lock\" adjacency matrix.\n-  // If [i][j]==true, then one can lock mutex j while under mutex i.\n-  const int N = MutexTypeCount;\n-  int cnt[N] = {};\n-  bool leaf[N] = {};\n-  for (int i = 1; i < N; i++) {\n-    for (int j = 0; j < N; j++) {\n-      MutexType z = CanLockTab[i][j];\n-      if (z == MutexTypeInvalid)\n-        continue;\n-      if (z == MutexTypeLeaf) {\n-        CHECK(!leaf[i]);\n-        leaf[i] = true;\n-        continue;\n-      }\n-      CHECK(!CanLockAdj[i][(int)z]);\n-      CanLockAdj[i][(int)z] = true;\n-      cnt[i]++;\n-    }\n-  }\n-  for (int i = 0; i < N; i++) {\n-    CHECK(!leaf[i] || cnt[i] == 0);\n-  }\n-  // Add leaf mutexes.\n-  for (int i = 0; i < N; i++) {\n-    if (!leaf[i])\n-      continue;\n-    for (int j = 0; j < N; j++) {\n-      if (i == j || leaf[j] || j == MutexTypeInvalid)\n-        continue;\n-      CHECK(!CanLockAdj[j][i]);\n-      CanLockAdj[j][i] = true;\n-    }\n-  }\n-  // Build the transitive closure.\n-  bool CanLockAdj2[MutexTypeCount][MutexTypeCount];\n-  for (int i = 0; i < N; i++) {\n-    for (int j = 0; j < N; j++) {\n-      CanLockAdj2[i][j] = CanLockAdj[i][j];\n-    }\n-  }\n-  for (int k = 0; k < N; k++) {\n-    for (int i = 0; i < N; i++) {\n-      for (int j = 0; j < N; j++) {\n-        if (CanLockAdj2[i][k] && CanLockAdj2[k][j]) {\n-          CanLockAdj2[i][j] = true;\n-        }\n-      }\n-    }\n-  }\n-#if 0\n-  Printf(\"Can lock graph:\\n\");\n-  for (int i = 0; i < N; i++) {\n-    for (int j = 0; j < N; j++) {\n-      Printf(\"%d \", CanLockAdj[i][j]);\n-    }\n-    Printf(\"\\n\");\n-  }\n-  Printf(\"Can lock graph closure:\\n\");\n-  for (int i = 0; i < N; i++) {\n-    for (int j = 0; j < N; j++) {\n-      Printf(\"%d \", CanLockAdj2[i][j]);\n-    }\n-    Printf(\"\\n\");\n-  }\n-#endif\n-  // Verify that the graph is acyclic.\n-  for (int i = 0; i < N; i++) {\n-    if (CanLockAdj2[i][i]) {\n-      Printf(\"Mutex %d participates in a cycle\\n\", i);\n-      Die();\n-    }\n-  }\n-#endif\n-}\n-\n-InternalDeadlockDetector::InternalDeadlockDetector() {\n-  // Rely on zero initialization because some mutexes can be locked before ctor.\n-}\n-\n-#if SANITIZER_DEBUG && !SANITIZER_GO\n-void InternalDeadlockDetector::Lock(MutexType t) {\n-  // Printf(\"LOCK %d @%zu\\n\", t, seq_ + 1);\n-  CHECK_GT(t, MutexTypeInvalid);\n-  CHECK_LT(t, MutexTypeCount);\n-  u64 max_seq = 0;\n-  u64 max_idx = MutexTypeInvalid;\n-  for (int i = 0; i != MutexTypeCount; i++) {\n-    if (locked_[i] == 0)\n-      continue;\n-    CHECK_NE(locked_[i], max_seq);\n-    if (max_seq < locked_[i]) {\n-      max_seq = locked_[i];\n-      max_idx = i;\n-    }\n-  }\n-  locked_[t] = ++seq_;\n-  if (max_idx == MutexTypeInvalid)\n-    return;\n-  // Printf(\"  last %d @%zu\\n\", max_idx, max_seq);\n-  if (!CanLockAdj[max_idx][t]) {\n-    Printf(\"ThreadSanitizer: internal deadlock detected\\n\");\n-    Printf(\"ThreadSanitizer: can't lock %d while under %zu\\n\",\n-               t, (uptr)max_idx);\n-    CHECK(0);\n-  }\n-}\n-\n-void InternalDeadlockDetector::Unlock(MutexType t) {\n-  // Printf(\"UNLO %d @%zu #%zu\\n\", t, seq_, locked_[t]);\n-  CHECK(locked_[t]);\n-  locked_[t] = 0;\n-}\n-\n-void InternalDeadlockDetector::CheckNoLocks() {\n-  for (int i = 0; i != MutexTypeCount; i++) {\n-    CHECK_EQ(locked_[i], 0);\n-  }\n-}\n-#endif\n-\n-void CheckNoLocks(ThreadState *thr) {\n-#if SANITIZER_DEBUG && !SANITIZER_GO\n-  thr->internal_deadlock_detector.CheckNoLocks();\n-#endif\n-}\n-\n-const uptr kUnlocked = 0;\n-const uptr kWriteLock = 1;\n-const uptr kReadLock = 2;\n-\n-class Backoff {\n- public:\n-  Backoff()\n-    : iter_() {\n-  }\n-\n-  bool Do() {\n-    if (iter_++ < kActiveSpinIters)\n-      proc_yield(kActiveSpinCnt);\n-    else\n-      internal_sched_yield();\n-    return true;\n-  }\n-\n-  u64 Contention() const {\n-    u64 active = iter_ % kActiveSpinIters;\n-    u64 passive = iter_ - active;\n-    return active + 10 * passive;\n-  }\n-\n- private:\n-  int iter_;\n-  static const int kActiveSpinIters = 10;\n-  static const int kActiveSpinCnt = 20;\n-};\n-\n-Mutex::Mutex(MutexType type) {\n-  CHECK_GT(type, MutexTypeInvalid);\n-  CHECK_LT(type, MutexTypeCount);\n-#if SANITIZER_DEBUG\n-  type_ = type;\n-#endif\n-  atomic_store(&state_, kUnlocked, memory_order_relaxed);\n-}\n-\n-Mutex::~Mutex() {\n-  CHECK_EQ(atomic_load(&state_, memory_order_relaxed), kUnlocked);\n-}\n-\n-void Mutex::Lock() {\n-#if SANITIZER_DEBUG && !SANITIZER_GO\n-  cur_thread()->internal_deadlock_detector.Lock(type_);\n-#endif\n-  uptr cmp = kUnlocked;\n-  if (atomic_compare_exchange_strong(&state_, &cmp, kWriteLock,\n-                                     memory_order_acquire))\n-    return;\n-  for (Backoff backoff; backoff.Do();) {\n-    if (atomic_load(&state_, memory_order_relaxed) == kUnlocked) {\n-      cmp = kUnlocked;\n-      if (atomic_compare_exchange_weak(&state_, &cmp, kWriteLock,\n-                                       memory_order_acquire)) {\n-        return;\n-      }\n-    }\n-  }\n-}\n-\n-void Mutex::Unlock() {\n-  uptr prev = atomic_fetch_sub(&state_, kWriteLock, memory_order_release);\n-  (void)prev;\n-  DCHECK_NE(prev & kWriteLock, 0);\n-#if SANITIZER_DEBUG && !SANITIZER_GO\n-  cur_thread()->internal_deadlock_detector.Unlock(type_);\n-#endif\n-}\n-\n-void Mutex::ReadLock() {\n-#if SANITIZER_DEBUG && !SANITIZER_GO\n-  cur_thread()->internal_deadlock_detector.Lock(type_);\n-#endif\n-  uptr prev = atomic_fetch_add(&state_, kReadLock, memory_order_acquire);\n-  if ((prev & kWriteLock) == 0)\n-    return;\n-  for (Backoff backoff; backoff.Do();) {\n-    prev = atomic_load(&state_, memory_order_acquire);\n-    if ((prev & kWriteLock) == 0) {\n-      return;\n-    }\n-  }\n-}\n-\n-void Mutex::ReadUnlock() {\n-  uptr prev = atomic_fetch_sub(&state_, kReadLock, memory_order_release);\n-  (void)prev;\n-  DCHECK_EQ(prev & kWriteLock, 0);\n-  DCHECK_GT(prev & ~kWriteLock, 0);\n-#if SANITIZER_DEBUG && !SANITIZER_GO\n-  cur_thread()->internal_deadlock_detector.Unlock(type_);\n-#endif\n-}\n-\n-void Mutex::CheckLocked() {\n-  CHECK_NE(atomic_load(&state_, memory_order_relaxed), 0);\n-}\n-\n-}  // namespace __tsan"}, {"sha": "9a579eaf9144a18c6cd8aada8334cf601315b06c", "filename": "libsanitizer/tsan/tsan_mutex.h", "status": "removed", "additions": 0, "deletions": 87, "changes": 87, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7c99923f8c544ec07109e8333acb2c2388c38a1b/libsanitizer%2Ftsan%2Ftsan_mutex.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7c99923f8c544ec07109e8333acb2c2388c38a1b/libsanitizer%2Ftsan%2Ftsan_mutex.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_mutex.h?ref=7c99923f8c544ec07109e8333acb2c2388c38a1b", "patch": "@@ -1,87 +0,0 @@\n-//===-- tsan_mutex.h --------------------------------------------*- C++ -*-===//\n-//\n-// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n-// See https://llvm.org/LICENSE.txt for license information.\n-// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n-//\n-//===----------------------------------------------------------------------===//\n-//\n-// This file is a part of ThreadSanitizer (TSan), a race detector.\n-//\n-//===----------------------------------------------------------------------===//\n-#ifndef TSAN_MUTEX_H\n-#define TSAN_MUTEX_H\n-\n-#include \"sanitizer_common/sanitizer_atomic.h\"\n-#include \"sanitizer_common/sanitizer_mutex.h\"\n-#include \"tsan_defs.h\"\n-\n-namespace __tsan {\n-\n-enum MutexType {\n-  MutexTypeInvalid,\n-  MutexTypeTrace,\n-  MutexTypeThreads,\n-  MutexTypeReport,\n-  MutexTypeSyncVar,\n-  MutexTypeSyncTab,\n-  MutexTypeSlab,\n-  MutexTypeAnnotations,\n-  MutexTypeAtExit,\n-  MutexTypeMBlock,\n-  MutexTypeJavaMBlock,\n-  MutexTypeDDetector,\n-  MutexTypeFired,\n-  MutexTypeRacy,\n-  MutexTypeGlobalProc,\n-\n-  // This must be the last.\n-  MutexTypeCount\n-};\n-\n-class Mutex {\n- public:\n-  explicit Mutex(MutexType type);\n-  ~Mutex();\n-\n-  void Lock();\n-  void Unlock();\n-\n-  void ReadLock();\n-  void ReadUnlock();\n-\n-  void CheckLocked();\n-\n- private:\n-  atomic_uintptr_t state_;\n-#if SANITIZER_DEBUG\n-  MutexType type_;\n-#endif\n-\n-  Mutex(const Mutex&);\n-  void operator = (const Mutex&);\n-};\n-\n-typedef GenericScopedLock<Mutex> Lock;\n-typedef GenericScopedReadLock<Mutex> ReadLock;\n-\n-class InternalDeadlockDetector {\n- public:\n-  InternalDeadlockDetector();\n-  void Lock(MutexType t);\n-  void Unlock(MutexType t);\n-  void CheckNoLocks();\n- private:\n-  u64 seq_;\n-  u64 locked_[MutexTypeCount];\n-};\n-\n-void InitializeMutex();\n-\n-// Checks that the current thread does not hold any runtime locks\n-// (e.g. when returning from an interceptor).\n-void CheckNoLocks(ThreadState *thr);\n-\n-}  // namespace __tsan\n-\n-#endif  // TSAN_MUTEX_H"}, {"sha": "efc0e4195a12d8d8bf2c011c3a16347b4ede61a6", "filename": "libsanitizer/tsan/tsan_mutexset.cpp", "status": "modified", "additions": 43, "deletions": 4, "changes": 47, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_mutexset.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_mutexset.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_mutexset.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -14,11 +14,7 @@\n \n namespace __tsan {\n \n-const uptr MutexSet::kMaxSize;\n-\n MutexSet::MutexSet() {\n-  size_ = 0;\n-  internal_memset(&descs_, 0, sizeof(descs_));\n }\n \n void MutexSet::Add(u64 id, bool write, u64 epoch) {\n@@ -44,9 +40,12 @@ void MutexSet::Add(u64 id, bool write, u64 epoch) {\n     CHECK_EQ(size_, kMaxSize - 1);\n   }\n   // Add new mutex descriptor.\n+  descs_[size_].addr = 0;\n+  descs_[size_].stack_id = kInvalidStackID;\n   descs_[size_].id = id;\n   descs_[size_].write = write;\n   descs_[size_].epoch = epoch;\n+  descs_[size_].seq = seq_++;\n   descs_[size_].count = 1;\n   size_++;\n }\n@@ -70,6 +69,46 @@ void MutexSet::Remove(u64 id) {\n   }\n }\n \n+void MutexSet::AddAddr(uptr addr, StackID stack_id, bool write) {\n+  // Look up existing mutex with the same id.\n+  for (uptr i = 0; i < size_; i++) {\n+    if (descs_[i].addr == addr) {\n+      descs_[i].count++;\n+      descs_[i].seq = seq_++;\n+      return;\n+    }\n+  }\n+  // On overflow, find the oldest mutex and drop it.\n+  if (size_ == kMaxSize) {\n+    uptr min = 0;\n+    for (uptr i = 0; i < size_; i++) {\n+      if (descs_[i].seq < descs_[min].seq)\n+        min = i;\n+    }\n+    RemovePos(min);\n+    CHECK_EQ(size_, kMaxSize - 1);\n+  }\n+  // Add new mutex descriptor.\n+  descs_[size_].addr = addr;\n+  descs_[size_].stack_id = stack_id;\n+  descs_[size_].id = 0;\n+  descs_[size_].write = write;\n+  descs_[size_].epoch = 0;\n+  descs_[size_].seq = seq_++;\n+  descs_[size_].count = 1;\n+  size_++;\n+}\n+\n+void MutexSet::DelAddr(uptr addr, bool destroy) {\n+  for (uptr i = 0; i < size_; i++) {\n+    if (descs_[i].addr == addr) {\n+      if (destroy || --descs_[i].count == 0)\n+        RemovePos(i);\n+      return;\n+    }\n+  }\n+}\n+\n void MutexSet::RemovePos(uptr i) {\n   CHECK_LT(i, size_);\n   descs_[i] = descs_[size_ - 1];"}, {"sha": "a448cee5a87731a94f3eb38761cc00e7b58eb21c", "filename": "libsanitizer/tsan/tsan_mutexset.h", "status": "modified", "additions": 19, "deletions": 10, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_mutexset.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_mutexset.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_mutexset.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -21,34 +21,42 @@ class MutexSet {\n  public:\n   // Holds limited number of mutexes.\n   // The oldest mutexes are discarded on overflow.\n-  static const uptr kMaxSize = 16;\n+  static constexpr uptr kMaxSize = 16;\n   struct Desc {\n+    uptr addr;\n+    StackID stack_id;\n     u64 id;\n     u64 epoch;\n-    int count;\n+    u32 seq;\n+    u32 count;\n     bool write;\n+\n+    Desc() { internal_memset(this, 0, sizeof(*this)); }\n+    Desc(const Desc& other) { *this = other; }\n+    Desc& operator=(const MutexSet::Desc& other) {\n+      internal_memcpy(this, &other, sizeof(*this));\n+      return *this;\n+    }\n   };\n \n   MutexSet();\n   // The 'id' is obtained from SyncVar::GetId().\n   void Add(u64 id, bool write, u64 epoch);\n   void Del(u64 id, bool write);\n   void Remove(u64 id);  // Removes the mutex completely (if it's destroyed).\n+  void AddAddr(uptr addr, StackID stack_id, bool write);\n+  void DelAddr(uptr addr, bool destroy = false);\n   uptr Size() const;\n   Desc Get(uptr i) const;\n \n-  void operator=(const MutexSet &other) {\n-    internal_memcpy(this, &other, sizeof(*this));\n-  }\n-\n  private:\n #if !SANITIZER_GO\n-  uptr size_;\n+  u32 seq_ = 0;\n+  uptr size_ = 0;\n   Desc descs_[kMaxSize];\n-#endif\n \n   void RemovePos(uptr i);\n-  MutexSet(const MutexSet&);\n+#endif\n };\n \n // Go does not have mutexes, so do not spend memory and time.\n@@ -59,7 +67,8 @@ MutexSet::MutexSet() {}\n void MutexSet::Add(u64 id, bool write, u64 epoch) {}\n void MutexSet::Del(u64 id, bool write) {}\n void MutexSet::Remove(u64 id) {}\n-void MutexSet::RemovePos(uptr i) {}\n+void MutexSet::AddAddr(uptr addr, StackID stack_id, bool write) {}\n+void MutexSet::DelAddr(uptr addr, bool destroy) {}\n uptr MutexSet::Size() const { return 0; }\n MutexSet::Desc MutexSet::Get(uptr i) const { return Desc(); }\n #endif"}, {"sha": "fc27a5656aadf1e02d5083f23474f233c9df66eb", "filename": "libsanitizer/tsan/tsan_platform.h", "status": "modified", "additions": 433, "deletions": 656, "changes": 1089, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_platform.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_platform.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_platform.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -23,21 +23,19 @@\n \n namespace __tsan {\n \n-#if defined(__x86_64__)\n-#define HAS_48_BIT_ADDRESS_SPACE 1\n-#elif SANITIZER_IOSSIM // arm64 iOS simulators (order of #if matters)\n-#define HAS_48_BIT_ADDRESS_SPACE 1\n-#elif SANITIZER_IOS // arm64 iOS devices (order of #if matters)\n-#define HAS_48_BIT_ADDRESS_SPACE 0\n-#elif SANITIZER_MAC // arm64 macOS (order of #if matters)\n-#define HAS_48_BIT_ADDRESS_SPACE 1\n-#else\n-#define HAS_48_BIT_ADDRESS_SPACE 0\n-#endif\n-\n-#if !SANITIZER_GO\n+enum {\n+  // App memory is not mapped onto shadow memory range.\n+  kBrokenMapping = 1 << 0,\n+  // Mapping app memory and back does not produce the same address,\n+  // this can lead to wrong addresses in reports and potentially\n+  // other bad consequences.\n+  kBrokenReverseMapping = 1 << 1,\n+  // Mapping is non-linear for linear user range.\n+  // This is bad and can lead to unpredictable memory corruptions, etc\n+  // because range access functions assume linearity.\n+  kBrokenLinearity = 1 << 2,\n+};\n \n-#if HAS_48_BIT_ADDRESS_SPACE\n /*\n C/C++ on linux/x86_64 and freebsd/x86_64\n 0000 0000 1000 - 0080 0000 0000: main binary and/or MAP_32BIT mappings (512GB)\n@@ -65,9 +63,8 @@ C/C++ on netbsd/amd64 can reuse the same mapping:\n  * Stack on NetBSD/amd64 has prereserved 128MB.\n  * Heap grows downwards (top-down).\n  * ASLR must be disabled per-process or globally.\n-\n */\n-struct Mapping {\n+struct Mapping48AddressSpace {\n   static const uptr kMetaShadowBeg = 0x300000000000ull;\n   static const uptr kMetaShadowEnd = 0x340000000000ull;\n   static const uptr kTraceMemBeg   = 0x600000000000ull;\n@@ -82,13 +79,12 @@ struct Mapping {\n   static const uptr kMidAppMemEnd  = 0x568000000000ull;\n   static const uptr kHiAppMemBeg   = 0x7e8000000000ull;\n   static const uptr kHiAppMemEnd   = 0x800000000000ull;\n-  static const uptr kAppMemMsk     = 0x780000000000ull;\n-  static const uptr kAppMemXor     = 0x040000000000ull;\n+  static const uptr kShadowMsk = 0x780000000000ull;\n+  static const uptr kShadowXor = 0x040000000000ull;\n+  static const uptr kShadowAdd = 0x000000000000ull;\n   static const uptr kVdsoBeg       = 0xf000000000000000ull;\n };\n \n-#define TSAN_MID_APP_RANGE 1\n-#elif defined(__mips64)\n /*\n C/C++ on linux/mips64 (40-bit VMA)\n 0000 0000 00 - 0100 0000 00: -                                           (4 GB)\n@@ -105,7 +101,7 @@ fe00 0000 00 - ff00 0000 00: heap                                        (4 GB)\n ff00 0000 00 - ff80 0000 00: -                                           (2 GB)\n ff80 0000 00 - ffff ffff ff: modules and main thread stack              (<2 GB)\n */\n-struct Mapping40 {\n+struct MappingMips64_40 {\n   static const uptr kMetaShadowBeg = 0x4000000000ull;\n   static const uptr kMetaShadowEnd = 0x5000000000ull;\n   static const uptr kTraceMemBeg   = 0xb000000000ull;\n@@ -120,14 +116,12 @@ struct Mapping40 {\n   static const uptr kMidAppMemEnd  = 0xab00000000ull;\n   static const uptr kHiAppMemBeg   = 0xff80000000ull;\n   static const uptr kHiAppMemEnd   = 0xffffffffffull;\n-  static const uptr kAppMemMsk     = 0xf800000000ull;\n-  static const uptr kAppMemXor     = 0x0800000000ull;\n+  static const uptr kShadowMsk = 0xf800000000ull;\n+  static const uptr kShadowXor = 0x0800000000ull;\n+  static const uptr kShadowAdd = 0x0000000000ull;\n   static const uptr kVdsoBeg       = 0xfffff00000ull;\n };\n \n-#define TSAN_MID_APP_RANGE 1\n-#define TSAN_RUNTIME_VMA 1\n-#elif defined(__aarch64__) && defined(__APPLE__)\n /*\n C/C++ on Darwin/iOS/ARM64 (36-bit VMA, 64 GB VM)\n 0000 0000 00 - 0100 0000 00: -                                    (4 GB)\n@@ -141,7 +135,7 @@ C/C++ on Darwin/iOS/ARM64 (36-bit VMA, 64 GB VM)\n 0f00 0000 00 - 0fc0 0000 00: traces                               (3 GB)\n 0fc0 0000 00 - 1000 0000 00: -\n */\n-struct Mapping {\n+struct MappingAppleAarch64 {\n   static const uptr kLoAppMemBeg   = 0x0100000000ull;\n   static const uptr kLoAppMemEnd   = 0x0200000000ull;\n   static const uptr kHeapMemBeg    = 0x0200000000ull;\n@@ -154,18 +148,14 @@ struct Mapping {\n   static const uptr kTraceMemEnd   = 0x0fc0000000ull;\n   static const uptr kHiAppMemBeg   = 0x0fc0000000ull;\n   static const uptr kHiAppMemEnd   = 0x0fc0000000ull;\n-  static const uptr kAppMemMsk     =          0x0ull;\n-  static const uptr kAppMemXor     =          0x0ull;\n+  static const uptr kShadowMsk = 0x0ull;\n+  static const uptr kShadowXor = 0x0ull;\n+  static const uptr kShadowAdd = 0x0ull;\n   static const uptr kVdsoBeg       = 0x7000000000000000ull;\n+  static const uptr kMidAppMemBeg = 0;\n+  static const uptr kMidAppMemEnd = 0;\n };\n \n-#elif defined(__aarch64__) && !defined(__APPLE__)\n-// AArch64 supports multiple VMA which leads to multiple address transformation\n-// functions.  To support these multiple VMAS transformations and mappings TSAN\n-// runtime for AArch64 uses an external memory read (vmaSize) to select which\n-// mapping to use.  Although slower, it make a same instrumented binary run on\n-// multiple kernels.\n-\n /*\n C/C++ on linux/aarch64 (39-bit VMA)\n 0000 0010 00 - 0100 0000 00: main binary\n@@ -181,7 +171,7 @@ C/C++ on linux/aarch64 (39-bit VMA)\n 7c00 0000 00 - 7d00 0000 00: heap\n 7d00 0000 00 - 7fff ffff ff: modules and main thread stack\n */\n-struct Mapping39 {\n+struct MappingAarch64_39 {\n   static const uptr kLoAppMemBeg   = 0x0000001000ull;\n   static const uptr kLoAppMemEnd   = 0x0100000000ull;\n   static const uptr kShadowBeg     = 0x0800000000ull;\n@@ -196,8 +186,9 @@ struct Mapping39 {\n   static const uptr kHeapMemEnd    = 0x7d00000000ull;\n   static const uptr kHiAppMemBeg   = 0x7e00000000ull;\n   static const uptr kHiAppMemEnd   = 0x7fffffffffull;\n-  static const uptr kAppMemMsk     = 0x7800000000ull;\n-  static const uptr kAppMemXor     = 0x0200000000ull;\n+  static const uptr kShadowMsk = 0x7800000000ull;\n+  static const uptr kShadowXor = 0x0200000000ull;\n+  static const uptr kShadowAdd = 0x0000000000ull;\n   static const uptr kVdsoBeg       = 0x7f00000000ull;\n };\n \n@@ -216,7 +207,8 @@ C/C++ on linux/aarch64 (42-bit VMA)\n 3e000 0000 00 - 3f000 0000 00: heap\n 3f000 0000 00 - 3ffff ffff ff: modules and main thread stack\n */\n-struct Mapping42 {\n+struct MappingAarch64_42 {\n+  static const uptr kBroken = kBrokenReverseMapping;\n   static const uptr kLoAppMemBeg   = 0x00000001000ull;\n   static const uptr kLoAppMemEnd   = 0x01000000000ull;\n   static const uptr kShadowBeg     = 0x10000000000ull;\n@@ -231,12 +223,13 @@ struct Mapping42 {\n   static const uptr kHeapMemEnd    = 0x3f000000000ull;\n   static const uptr kHiAppMemBeg   = 0x3f000000000ull;\n   static const uptr kHiAppMemEnd   = 0x3ffffffffffull;\n-  static const uptr kAppMemMsk     = 0x3c000000000ull;\n-  static const uptr kAppMemXor     = 0x04000000000ull;\n+  static const uptr kShadowMsk = 0x3c000000000ull;\n+  static const uptr kShadowXor = 0x04000000000ull;\n+  static const uptr kShadowAdd = 0x00000000000ull;\n   static const uptr kVdsoBeg       = 0x37f00000000ull;\n };\n \n-struct Mapping48 {\n+struct MappingAarch64_48 {\n   static const uptr kLoAppMemBeg   = 0x0000000001000ull;\n   static const uptr kLoAppMemEnd   = 0x0000200000000ull;\n   static const uptr kShadowBeg     = 0x0002000000000ull;\n@@ -251,22 +244,12 @@ struct Mapping48 {\n   static const uptr kHeapMemEnd    = 0x0ffff00000000ull;\n   static const uptr kHiAppMemBeg   = 0x0ffff00000000ull;\n   static const uptr kHiAppMemEnd   = 0x1000000000000ull;\n-  static const uptr kAppMemMsk     = 0x0fff800000000ull;\n-  static const uptr kAppMemXor     = 0x0000800000000ull;\n+  static const uptr kShadowMsk = 0x0fff800000000ull;\n+  static const uptr kShadowXor = 0x0000800000000ull;\n+  static const uptr kShadowAdd = 0x0000000000000ull;\n   static const uptr kVdsoBeg       = 0xffff000000000ull;\n };\n \n-// Indicates the runtime will define the memory regions at runtime.\n-#define TSAN_RUNTIME_VMA 1\n-// Indicates that mapping defines a mid range memory segment.\n-#define TSAN_MID_APP_RANGE 1\n-#elif defined(__powerpc64__)\n-// PPC64 supports multiple VMA which leads to multiple address transformation\n-// functions.  To support these multiple VMAS transformations and mappings TSAN\n-// runtime for PPC64 uses an external memory read (vmaSize) to select which\n-// mapping to use.  Although slower, it make a same instrumented binary run on\n-// multiple kernels.\n-\n /*\n C/C++ on linux/powerpc64 (44-bit VMA)\n 0000 0000 0100 - 0001 0000 0000: main binary\n@@ -281,7 +264,9 @@ C/C++ on linux/powerpc64 (44-bit VMA)\n 0f50 0000 0000 - 0f60 0000 0000: -\n 0f60 0000 0000 - 1000 0000 0000: modules and main thread stack\n */\n-struct Mapping44 {\n+struct MappingPPC64_44 {\n+  static const uptr kBroken =\n+      kBrokenMapping | kBrokenReverseMapping | kBrokenLinearity;\n   static const uptr kMetaShadowBeg = 0x0b0000000000ull;\n   static const uptr kMetaShadowEnd = 0x0d0000000000ull;\n   static const uptr kTraceMemBeg   = 0x0d0000000000ull;\n@@ -294,9 +279,12 @@ struct Mapping44 {\n   static const uptr kHeapMemEnd    = 0x0f5000000000ull;\n   static const uptr kHiAppMemBeg   = 0x0f6000000000ull;\n   static const uptr kHiAppMemEnd   = 0x100000000000ull; // 44 bits\n-  static const uptr kAppMemMsk     = 0x0f0000000000ull;\n-  static const uptr kAppMemXor     = 0x002100000000ull;\n+  static const uptr kShadowMsk = 0x0f0000000000ull;\n+  static const uptr kShadowXor = 0x002100000000ull;\n+  static const uptr kShadowAdd = 0x000000000000ull;\n   static const uptr kVdsoBeg       = 0x3c0000000000000ull;\n+  static const uptr kMidAppMemBeg = 0;\n+  static const uptr kMidAppMemEnd = 0;\n };\n \n /*\n@@ -313,7 +301,7 @@ C/C++ on linux/powerpc64 (46-bit VMA)\n 3e00 0000 0000 - 3e80 0000 0000: -\n 3e80 0000 0000 - 4000 0000 0000: modules and main thread stack\n */\n-struct Mapping46 {\n+struct MappingPPC64_46 {\n   static const uptr kMetaShadowBeg = 0x100000000000ull;\n   static const uptr kMetaShadowEnd = 0x200000000000ull;\n   static const uptr kTraceMemBeg   = 0x200000000000ull;\n@@ -326,9 +314,12 @@ struct Mapping46 {\n   static const uptr kLoAppMemEnd   = 0x010000000000ull;\n   static const uptr kHiAppMemBeg   = 0x3e8000000000ull;\n   static const uptr kHiAppMemEnd   = 0x400000000000ull; // 46 bits\n-  static const uptr kAppMemMsk     = 0x3c0000000000ull;\n-  static const uptr kAppMemXor     = 0x020000000000ull;\n+  static const uptr kShadowMsk = 0x3c0000000000ull;\n+  static const uptr kShadowXor = 0x020000000000ull;\n+  static const uptr kShadowAdd = 0x000000000000ull;\n   static const uptr kVdsoBeg       = 0x7800000000000000ull;\n+  static const uptr kMidAppMemBeg = 0;\n+  static const uptr kMidAppMemEnd = 0;\n };\n \n /*\n@@ -345,7 +336,7 @@ C/C++ on linux/powerpc64 (47-bit VMA)\n 7e00 0000 0000 - 7e80 0000 0000: -\n 7e80 0000 0000 - 8000 0000 0000: modules and main thread stack\n */\n-struct Mapping47 {\n+struct MappingPPC64_47 {\n   static const uptr kMetaShadowBeg = 0x100000000000ull;\n   static const uptr kMetaShadowEnd = 0x200000000000ull;\n   static const uptr kTraceMemBeg   = 0x200000000000ull;\n@@ -358,14 +349,14 @@ struct Mapping47 {\n   static const uptr kLoAppMemEnd   = 0x010000000000ull;\n   static const uptr kHiAppMemBeg   = 0x7e8000000000ull;\n   static const uptr kHiAppMemEnd   = 0x800000000000ull; // 47 bits\n-  static const uptr kAppMemMsk     = 0x7c0000000000ull;\n-  static const uptr kAppMemXor     = 0x020000000000ull;\n+  static const uptr kShadowMsk = 0x7c0000000000ull;\n+  static const uptr kShadowXor = 0x020000000000ull;\n+  static const uptr kShadowAdd = 0x000000000000ull;\n   static const uptr kVdsoBeg       = 0x7800000000000000ull;\n+  static const uptr kMidAppMemBeg = 0;\n+  static const uptr kMidAppMemEnd = 0;\n };\n \n-// Indicates the runtime will define the memory regions at runtime.\n-#define TSAN_RUNTIME_VMA 1\n-#elif defined(__s390x__)\n /*\n C/C++ on linux/s390x\n While the kernel provides a 64-bit address space, we have to restrict ourselves\n@@ -380,7 +371,7 @@ a000 0000 0000 - b000 0000 0000: traces - 16TiB (max history * 128k threads)\n b000 0000 0000 - be00 0000 0000: -\n be00 0000 0000 - c000 0000 0000: heap - 2TiB (max supported by the allocator)\n */\n-struct Mapping {\n+struct MappingS390x {\n   static const uptr kMetaShadowBeg = 0x900000000000ull;\n   static const uptr kMetaShadowEnd = 0x980000000000ull;\n   static const uptr kTraceMemBeg   = 0xa00000000000ull;\n@@ -393,13 +384,13 @@ struct Mapping {\n   static const uptr kLoAppMemEnd   = 0x0e0000000000ull;\n   static const uptr kHiAppMemBeg   = 0xc00000004000ull;\n   static const uptr kHiAppMemEnd   = 0xc00000004000ull;\n-  static const uptr kAppMemMsk     = 0xb00000000000ull;\n-  static const uptr kAppMemXor     = 0x100000000000ull;\n+  static const uptr kShadowMsk = 0xb00000000000ull;\n+  static const uptr kShadowXor = 0x100000000000ull;\n+  static const uptr kShadowAdd = 0x000000000000ull;\n   static const uptr kVdsoBeg       = 0xfffffffff000ull;\n+  static const uptr kMidAppMemBeg = 0;\n+  static const uptr kMidAppMemEnd = 0;\n };\n-#endif\n-\n-#elif SANITIZER_GO && !SANITIZER_WINDOWS && HAS_48_BIT_ADDRESS_SPACE\n \n /* Go on linux, darwin and freebsd on x86_64\n 0000 0000 1000 - 0000 1000 0000: executable\n@@ -414,46 +405,59 @@ struct Mapping {\n 6200 0000 0000 - 8000 0000 0000: -\n */\n \n-struct Mapping {\n+struct MappingGo48 {\n   static const uptr kMetaShadowBeg = 0x300000000000ull;\n   static const uptr kMetaShadowEnd = 0x400000000000ull;\n   static const uptr kTraceMemBeg   = 0x600000000000ull;\n   static const uptr kTraceMemEnd   = 0x620000000000ull;\n   static const uptr kShadowBeg     = 0x200000000000ull;\n   static const uptr kShadowEnd     = 0x238000000000ull;\n-  static const uptr kAppMemBeg     = 0x000000001000ull;\n-  static const uptr kAppMemEnd     = 0x00e000000000ull;\n+  static const uptr kLoAppMemBeg = 0x000000001000ull;\n+  static const uptr kLoAppMemEnd = 0x00e000000000ull;\n+  static const uptr kMidAppMemBeg = 0;\n+  static const uptr kMidAppMemEnd = 0;\n+  static const uptr kHiAppMemBeg = 0;\n+  static const uptr kHiAppMemEnd = 0;\n+  static const uptr kHeapMemBeg = 0;\n+  static const uptr kHeapMemEnd = 0;\n+  static const uptr kVdsoBeg = 0;\n+  static const uptr kShadowMsk = 0;\n+  static const uptr kShadowXor = 0;\n+  static const uptr kShadowAdd = 0x200000000000ull;\n };\n \n-#elif SANITIZER_GO && SANITIZER_WINDOWS\n-\n /* Go on windows\n 0000 0000 1000 - 0000 1000 0000: executable\n 0000 1000 0000 - 00f8 0000 0000: -\n 00c0 0000 0000 - 00e0 0000 0000: heap\n 00e0 0000 0000 - 0100 0000 0000: -\n 0100 0000 0000 - 0500 0000 0000: shadow\n-0500 0000 0000 - 0560 0000 0000: -\n-0560 0000 0000 - 0760 0000 0000: traces\n-0760 0000 0000 - 07d0 0000 0000: metainfo (memory blocks and sync objects)\n+0500 0000 0000 - 0700 0000 0000: traces\n+0700 0000 0000 - 0770 0000 0000: metainfo (memory blocks and sync objects)\n 07d0 0000 0000 - 8000 0000 0000: -\n */\n \n-struct Mapping {\n-  static const uptr kMetaShadowBeg = 0x076000000000ull;\n-  static const uptr kMetaShadowEnd = 0x07d000000000ull;\n-  static const uptr kTraceMemBeg   = 0x056000000000ull;\n-  static const uptr kTraceMemEnd   = 0x076000000000ull;\n+struct MappingGoWindows {\n+  static const uptr kMetaShadowBeg = 0x070000000000ull;\n+  static const uptr kMetaShadowEnd = 0x077000000000ull;\n+  static const uptr kTraceMemBeg = 0x050000000000ull;\n+  static const uptr kTraceMemEnd = 0x070000000000ull;\n   static const uptr kShadowBeg     = 0x010000000000ull;\n   static const uptr kShadowEnd     = 0x050000000000ull;\n-  static const uptr kAppMemBeg     = 0x000000001000ull;\n-  static const uptr kAppMemEnd     = 0x00e000000000ull;\n+  static const uptr kLoAppMemBeg = 0x000000001000ull;\n+  static const uptr kLoAppMemEnd = 0x00e000000000ull;\n+  static const uptr kMidAppMemBeg = 0;\n+  static const uptr kMidAppMemEnd = 0;\n+  static const uptr kHiAppMemBeg = 0;\n+  static const uptr kHiAppMemEnd = 0;\n+  static const uptr kHeapMemBeg = 0;\n+  static const uptr kHeapMemEnd = 0;\n+  static const uptr kVdsoBeg = 0;\n+  static const uptr kShadowMsk = 0;\n+  static const uptr kShadowXor = 0;\n+  static const uptr kShadowAdd = 0x010000000000ull;\n };\n \n-#elif SANITIZER_GO && defined(__powerpc64__)\n-\n-/* Only Mapping46 and Mapping47 are currently supported for powercp64 on Go. */\n-\n /* Go on linux/powerpc64 (46-bit VMA)\n 0000 0000 1000 - 0000 1000 0000: executable\n 0000 1000 0000 - 00c0 0000 0000: -\n@@ -467,15 +471,25 @@ struct Mapping {\n 3800 0000 0000 - 4000 0000 0000: -\n */\n \n-struct Mapping46 {\n+struct MappingGoPPC64_46 {\n   static const uptr kMetaShadowBeg = 0x240000000000ull;\n   static const uptr kMetaShadowEnd = 0x340000000000ull;\n   static const uptr kTraceMemBeg   = 0x360000000000ull;\n   static const uptr kTraceMemEnd   = 0x380000000000ull;\n   static const uptr kShadowBeg     = 0x200000000000ull;\n   static const uptr kShadowEnd     = 0x238000000000ull;\n-  static const uptr kAppMemBeg     = 0x000000001000ull;\n-  static const uptr kAppMemEnd     = 0x00e000000000ull;\n+  static const uptr kLoAppMemBeg = 0x000000001000ull;\n+  static const uptr kLoAppMemEnd = 0x00e000000000ull;\n+  static const uptr kMidAppMemBeg = 0;\n+  static const uptr kMidAppMemEnd = 0;\n+  static const uptr kHiAppMemBeg = 0;\n+  static const uptr kHiAppMemEnd = 0;\n+  static const uptr kHeapMemBeg = 0;\n+  static const uptr kHeapMemEnd = 0;\n+  static const uptr kVdsoBeg = 0;\n+  static const uptr kShadowMsk = 0;\n+  static const uptr kShadowXor = 0;\n+  static const uptr kShadowAdd = 0x200000000000ull;\n };\n \n /* Go on linux/powerpc64 (47-bit VMA)\n@@ -491,21 +505,27 @@ struct Mapping46 {\n 6200 0000 0000 - 8000 0000 0000: -\n */\n \n-struct Mapping47 {\n+struct MappingGoPPC64_47 {\n   static const uptr kMetaShadowBeg = 0x300000000000ull;\n   static const uptr kMetaShadowEnd = 0x400000000000ull;\n   static const uptr kTraceMemBeg   = 0x600000000000ull;\n   static const uptr kTraceMemEnd   = 0x620000000000ull;\n   static const uptr kShadowBeg     = 0x200000000000ull;\n   static const uptr kShadowEnd     = 0x300000000000ull;\n-  static const uptr kAppMemBeg     = 0x000000001000ull;\n-  static const uptr kAppMemEnd     = 0x00e000000000ull;\n+  static const uptr kLoAppMemBeg = 0x000000001000ull;\n+  static const uptr kLoAppMemEnd = 0x00e000000000ull;\n+  static const uptr kMidAppMemBeg = 0;\n+  static const uptr kMidAppMemEnd = 0;\n+  static const uptr kHiAppMemBeg = 0;\n+  static const uptr kHiAppMemEnd = 0;\n+  static const uptr kHeapMemBeg = 0;\n+  static const uptr kHeapMemEnd = 0;\n+  static const uptr kVdsoBeg = 0;\n+  static const uptr kShadowMsk = 0;\n+  static const uptr kShadowXor = 0;\n+  static const uptr kShadowAdd = 0x200000000000ull;\n };\n \n-#define TSAN_RUNTIME_VMA 1\n-\n-#elif SANITIZER_GO && defined(__aarch64__)\n-\n /* Go on linux/aarch64 (48-bit VMA) and darwin/aarch64 (47-bit VMA)\n 0000 0000 1000 - 0000 1000 0000: executable\n 0000 1000 0000 - 00c0 0000 0000: -\n@@ -518,22 +538,27 @@ struct Mapping47 {\n 6000 0000 0000 - 6200 0000 0000: traces\n 6200 0000 0000 - 8000 0000 0000: -\n */\n-\n-struct Mapping {\n+struct MappingGoAarch64 {\n   static const uptr kMetaShadowBeg = 0x300000000000ull;\n   static const uptr kMetaShadowEnd = 0x400000000000ull;\n   static const uptr kTraceMemBeg   = 0x600000000000ull;\n   static const uptr kTraceMemEnd   = 0x620000000000ull;\n   static const uptr kShadowBeg     = 0x200000000000ull;\n   static const uptr kShadowEnd     = 0x300000000000ull;\n-  static const uptr kAppMemBeg     = 0x000000001000ull;\n-  static const uptr kAppMemEnd     = 0x00e000000000ull;\n+  static const uptr kLoAppMemBeg = 0x000000001000ull;\n+  static const uptr kLoAppMemEnd = 0x00e000000000ull;\n+  static const uptr kMidAppMemBeg = 0;\n+  static const uptr kMidAppMemEnd = 0;\n+  static const uptr kHiAppMemBeg = 0;\n+  static const uptr kHiAppMemEnd = 0;\n+  static const uptr kHeapMemBeg = 0;\n+  static const uptr kHeapMemEnd = 0;\n+  static const uptr kVdsoBeg = 0;\n+  static const uptr kShadowMsk = 0;\n+  static const uptr kShadowXor = 0;\n+  static const uptr kShadowAdd = 0x200000000000ull;\n };\n \n-// Indicates the runtime will define the memory regions at runtime.\n-#define TSAN_RUNTIME_VMA 1\n-\n-#elif SANITIZER_GO && defined(__mips64)\n /*\n Go on linux/mips64 (47-bit VMA)\n 0000 0000 1000 - 0000 1000 0000: executable\n@@ -547,20 +572,27 @@ Go on linux/mips64 (47-bit VMA)\n 6000 0000 0000 - 6200 0000 0000: traces\n 6200 0000 0000 - 8000 0000 0000: -\n */\n-struct Mapping47 {\n+struct MappingGoMips64_47 {\n   static const uptr kMetaShadowBeg = 0x300000000000ull;\n   static const uptr kMetaShadowEnd = 0x400000000000ull;\n   static const uptr kTraceMemBeg = 0x600000000000ull;\n   static const uptr kTraceMemEnd = 0x620000000000ull;\n   static const uptr kShadowBeg = 0x200000000000ull;\n   static const uptr kShadowEnd = 0x300000000000ull;\n-  static const uptr kAppMemBeg = 0x000000001000ull;\n-  static const uptr kAppMemEnd = 0x00e000000000ull;\n+  static const uptr kLoAppMemBeg = 0x000000001000ull;\n+  static const uptr kLoAppMemEnd = 0x00e000000000ull;\n+  static const uptr kMidAppMemBeg = 0;\n+  static const uptr kMidAppMemEnd = 0;\n+  static const uptr kHiAppMemBeg = 0;\n+  static const uptr kHiAppMemEnd = 0;\n+  static const uptr kHeapMemBeg = 0;\n+  static const uptr kHeapMemEnd = 0;\n+  static const uptr kVdsoBeg = 0;\n+  static const uptr kShadowMsk = 0;\n+  static const uptr kShadowXor = 0;\n+  static const uptr kShadowAdd = 0x200000000000ull;\n };\n \n-#define TSAN_RUNTIME_VMA 1\n-\n-#elif SANITIZER_GO && defined(__s390x__)\n /*\n Go on linux/s390x\n 0000 0000 1000 - 1000 0000 0000: executable and heap - 16 TiB\n@@ -571,630 +603,375 @@ Go on linux/s390x\n 9800 0000 0000 - a000 0000 0000: -\n a000 0000 0000 - b000 0000 0000: traces - 16TiB (max history * 128k threads)\n */\n-struct Mapping {\n+struct MappingGoS390x {\n   static const uptr kMetaShadowBeg = 0x900000000000ull;\n   static const uptr kMetaShadowEnd = 0x980000000000ull;\n   static const uptr kTraceMemBeg   = 0xa00000000000ull;\n   static const uptr kTraceMemEnd   = 0xb00000000000ull;\n   static const uptr kShadowBeg     = 0x400000000000ull;\n   static const uptr kShadowEnd     = 0x800000000000ull;\n-  static const uptr kAppMemBeg     = 0x000000001000ull;\n-  static const uptr kAppMemEnd     = 0x100000000000ull;\n+  static const uptr kLoAppMemBeg = 0x000000001000ull;\n+  static const uptr kLoAppMemEnd = 0x100000000000ull;\n+  static const uptr kMidAppMemBeg = 0;\n+  static const uptr kMidAppMemEnd = 0;\n+  static const uptr kHiAppMemBeg = 0;\n+  static const uptr kHiAppMemEnd = 0;\n+  static const uptr kHeapMemBeg = 0;\n+  static const uptr kHeapMemEnd = 0;\n+  static const uptr kVdsoBeg = 0;\n+  static const uptr kShadowMsk = 0;\n+  static const uptr kShadowXor = 0;\n+  static const uptr kShadowAdd = 0x400000000000ull;\n };\n \n-#else\n-# error \"Unknown platform\"\n-#endif\n-\n-\n-#ifdef TSAN_RUNTIME_VMA\n extern uptr vmaSize;\n-#endif\n-\n-\n-enum MappingType {\n-  MAPPING_LO_APP_BEG,\n-  MAPPING_LO_APP_END,\n-  MAPPING_HI_APP_BEG,\n-  MAPPING_HI_APP_END,\n-#ifdef TSAN_MID_APP_RANGE\n-  MAPPING_MID_APP_BEG,\n-  MAPPING_MID_APP_END,\n-#endif\n-  MAPPING_HEAP_BEG,\n-  MAPPING_HEAP_END,\n-  MAPPING_APP_BEG,\n-  MAPPING_APP_END,\n-  MAPPING_SHADOW_BEG,\n-  MAPPING_SHADOW_END,\n-  MAPPING_META_SHADOW_BEG,\n-  MAPPING_META_SHADOW_END,\n-  MAPPING_TRACE_BEG,\n-  MAPPING_TRACE_END,\n-  MAPPING_VDSO_BEG,\n-};\n-\n-template<typename Mapping, int Type>\n-uptr MappingImpl(void) {\n-  switch (Type) {\n-#if !SANITIZER_GO\n-    case MAPPING_LO_APP_BEG: return Mapping::kLoAppMemBeg;\n-    case MAPPING_LO_APP_END: return Mapping::kLoAppMemEnd;\n-# ifdef TSAN_MID_APP_RANGE\n-    case MAPPING_MID_APP_BEG: return Mapping::kMidAppMemBeg;\n-    case MAPPING_MID_APP_END: return Mapping::kMidAppMemEnd;\n-# endif\n-    case MAPPING_HI_APP_BEG: return Mapping::kHiAppMemBeg;\n-    case MAPPING_HI_APP_END: return Mapping::kHiAppMemEnd;\n-    case MAPPING_HEAP_BEG: return Mapping::kHeapMemBeg;\n-    case MAPPING_HEAP_END: return Mapping::kHeapMemEnd;\n-    case MAPPING_VDSO_BEG: return Mapping::kVdsoBeg;\n-#else\n-    case MAPPING_APP_BEG: return Mapping::kAppMemBeg;\n-    case MAPPING_APP_END: return Mapping::kAppMemEnd;\n-#endif\n-    case MAPPING_SHADOW_BEG: return Mapping::kShadowBeg;\n-    case MAPPING_SHADOW_END: return Mapping::kShadowEnd;\n-    case MAPPING_META_SHADOW_BEG: return Mapping::kMetaShadowBeg;\n-    case MAPPING_META_SHADOW_END: return Mapping::kMetaShadowEnd;\n-    case MAPPING_TRACE_BEG: return Mapping::kTraceMemBeg;\n-    case MAPPING_TRACE_END: return Mapping::kTraceMemEnd;\n-  }\n-}\n \n-template<int Type>\n-uptr MappingArchImpl(void) {\n-#if defined(__aarch64__) && !defined(__APPLE__) && !SANITIZER_GO\n+template <typename Func, typename Arg>\n+ALWAYS_INLINE auto SelectMapping(Arg arg) {\n+#if SANITIZER_GO\n+#  if defined(__powerpc64__)\n   switch (vmaSize) {\n-    case 39: return MappingImpl<Mapping39, Type>();\n-    case 42: return MappingImpl<Mapping42, Type>();\n-    case 48: return MappingImpl<Mapping48, Type>();\n+    case 46:\n+      return Func::template Apply<MappingGoPPC64_46>(arg);\n+    case 47:\n+      return Func::template Apply<MappingGoPPC64_47>(arg);\n   }\n-  DCHECK(0);\n-  return 0;\n-#elif defined(__powerpc64__)\n+#  elif defined(__mips64)\n+  return Func::template Apply<MappingGoMips64_47>(arg);\n+#  elif defined(__s390x__)\n+  return Func::template Apply<MappingGoS390x>(arg);\n+#  elif defined(__aarch64__)\n+  return Func::template Apply<MappingGoAarch64>(arg);\n+#  elif SANITIZER_WINDOWS\n+  return Func::template Apply<MappingGoWindows>(arg);\n+#  else\n+  return Func::template Apply<MappingGo48>(arg);\n+#  endif\n+#else  // SANITIZER_GO\n+#  if defined(__x86_64__) || SANITIZER_IOSSIM || SANITIZER_MAC && !SANITIZER_IOS\n+  return Func::template Apply<Mapping48AddressSpace>(arg);\n+#  elif defined(__aarch64__) && defined(__APPLE__)\n+  return Func::template Apply<MappingAppleAarch64>(arg);\n+#  elif defined(__aarch64__) && !defined(__APPLE__)\n   switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 44: return MappingImpl<Mapping44, Type>();\n-#endif\n-    case 46: return MappingImpl<Mapping46, Type>();\n-    case 47: return MappingImpl<Mapping47, Type>();\n+    case 39:\n+      return Func::template Apply<MappingAarch64_39>(arg);\n+    case 42:\n+      return Func::template Apply<MappingAarch64_42>(arg);\n+    case 48:\n+      return Func::template Apply<MappingAarch64_48>(arg);\n   }\n-  DCHECK(0);\n-  return 0;\n-#elif defined(__mips64)\n+#  elif defined(__powerpc64__)\n   switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 40: return MappingImpl<Mapping40, Type>();\n-#else\n-    case 47: return MappingImpl<Mapping47, Type>();\n-#endif\n+    case 44:\n+      return Func::template Apply<MappingPPC64_44>(arg);\n+    case 46:\n+      return Func::template Apply<MappingPPC64_46>(arg);\n+    case 47:\n+      return Func::template Apply<MappingPPC64_47>(arg);\n   }\n-  DCHECK(0);\n-  return 0;\n-#else\n-  return MappingImpl<Mapping, Type>();\n-#endif\n+#  elif defined(__mips64)\n+  return Func::template Apply<MappingMips64_40>(arg);\n+#  elif defined(__s390x__)\n+  return Func::template Apply<MappingS390x>(arg);\n+#  else\n+#    error \"unsupported platform\"\n+#  endif\n+#endif\n+  Die();\n+}\n+\n+template <typename Func>\n+void ForEachMapping() {\n+  Func::template Apply<Mapping48AddressSpace>();\n+  Func::template Apply<MappingMips64_40>();\n+  Func::template Apply<MappingAppleAarch64>();\n+  Func::template Apply<MappingAarch64_39>();\n+  Func::template Apply<MappingAarch64_42>();\n+  Func::template Apply<MappingAarch64_48>();\n+  Func::template Apply<MappingPPC64_44>();\n+  Func::template Apply<MappingPPC64_46>();\n+  Func::template Apply<MappingPPC64_47>();\n+  Func::template Apply<MappingS390x>();\n+  Func::template Apply<MappingGo48>();\n+  Func::template Apply<MappingGoWindows>();\n+  Func::template Apply<MappingGoPPC64_46>();\n+  Func::template Apply<MappingGoPPC64_47>();\n+  Func::template Apply<MappingGoAarch64>();\n+  Func::template Apply<MappingGoMips64_47>();\n+  Func::template Apply<MappingGoS390x>();\n }\n \n-#if !SANITIZER_GO\n-ALWAYS_INLINE\n-uptr LoAppMemBeg(void) {\n-  return MappingArchImpl<MAPPING_LO_APP_BEG>();\n-}\n-ALWAYS_INLINE\n-uptr LoAppMemEnd(void) {\n-  return MappingArchImpl<MAPPING_LO_APP_END>();\n-}\n+enum MappingType {\n+  kLoAppMemBeg,\n+  kLoAppMemEnd,\n+  kHiAppMemBeg,\n+  kHiAppMemEnd,\n+  kMidAppMemBeg,\n+  kMidAppMemEnd,\n+  kHeapMemBeg,\n+  kHeapMemEnd,\n+  kShadowBeg,\n+  kShadowEnd,\n+  kMetaShadowBeg,\n+  kMetaShadowEnd,\n+  kTraceMemBeg,\n+  kTraceMemEnd,\n+  kVdsoBeg,\n+};\n \n-#ifdef TSAN_MID_APP_RANGE\n-ALWAYS_INLINE\n-uptr MidAppMemBeg(void) {\n-  return MappingArchImpl<MAPPING_MID_APP_BEG>();\n-}\n-ALWAYS_INLINE\n-uptr MidAppMemEnd(void) {\n-  return MappingArchImpl<MAPPING_MID_APP_END>();\n-}\n-#endif\n+struct MappingField {\n+  template <typename Mapping>\n+  static uptr Apply(MappingType type) {\n+    switch (type) {\n+      case kLoAppMemBeg:\n+        return Mapping::kLoAppMemBeg;\n+      case kLoAppMemEnd:\n+        return Mapping::kLoAppMemEnd;\n+      case kMidAppMemBeg:\n+        return Mapping::kMidAppMemBeg;\n+      case kMidAppMemEnd:\n+        return Mapping::kMidAppMemEnd;\n+      case kHiAppMemBeg:\n+        return Mapping::kHiAppMemBeg;\n+      case kHiAppMemEnd:\n+        return Mapping::kHiAppMemEnd;\n+      case kHeapMemBeg:\n+        return Mapping::kHeapMemBeg;\n+      case kHeapMemEnd:\n+        return Mapping::kHeapMemEnd;\n+      case kVdsoBeg:\n+        return Mapping::kVdsoBeg;\n+      case kShadowBeg:\n+        return Mapping::kShadowBeg;\n+      case kShadowEnd:\n+        return Mapping::kShadowEnd;\n+      case kMetaShadowBeg:\n+        return Mapping::kMetaShadowBeg;\n+      case kMetaShadowEnd:\n+        return Mapping::kMetaShadowEnd;\n+      case kTraceMemBeg:\n+        return Mapping::kTraceMemBeg;\n+      case kTraceMemEnd:\n+        return Mapping::kTraceMemEnd;\n+    }\n+    Die();\n+  }\n+};\n \n ALWAYS_INLINE\n-uptr HeapMemBeg(void) {\n-  return MappingArchImpl<MAPPING_HEAP_BEG>();\n-}\n+uptr LoAppMemBeg(void) { return SelectMapping<MappingField>(kLoAppMemBeg); }\n ALWAYS_INLINE\n-uptr HeapMemEnd(void) {\n-  return MappingArchImpl<MAPPING_HEAP_END>();\n-}\n+uptr LoAppMemEnd(void) { return SelectMapping<MappingField>(kLoAppMemEnd); }\n \n ALWAYS_INLINE\n-uptr HiAppMemBeg(void) {\n-  return MappingArchImpl<MAPPING_HI_APP_BEG>();\n-}\n+uptr MidAppMemBeg(void) { return SelectMapping<MappingField>(kMidAppMemBeg); }\n ALWAYS_INLINE\n-uptr HiAppMemEnd(void) {\n-  return MappingArchImpl<MAPPING_HI_APP_END>();\n-}\n+uptr MidAppMemEnd(void) { return SelectMapping<MappingField>(kMidAppMemEnd); }\n \n ALWAYS_INLINE\n-uptr VdsoBeg(void) {\n-  return MappingArchImpl<MAPPING_VDSO_BEG>();\n-}\n-\n-#else\n+uptr HeapMemBeg(void) { return SelectMapping<MappingField>(kHeapMemBeg); }\n+ALWAYS_INLINE\n+uptr HeapMemEnd(void) { return SelectMapping<MappingField>(kHeapMemEnd); }\n \n ALWAYS_INLINE\n-uptr AppMemBeg(void) {\n-  return MappingArchImpl<MAPPING_APP_BEG>();\n-}\n+uptr HiAppMemBeg(void) { return SelectMapping<MappingField>(kHiAppMemBeg); }\n ALWAYS_INLINE\n-uptr AppMemEnd(void) {\n-  return MappingArchImpl<MAPPING_APP_END>();\n-}\n-\n-#endif\n+uptr HiAppMemEnd(void) { return SelectMapping<MappingField>(kHiAppMemEnd); }\n \n-static inline\n-bool GetUserRegion(int i, uptr *start, uptr *end) {\n-  switch (i) {\n-  default:\n-    return false;\n-#if !SANITIZER_GO\n-  case 0:\n-    *start = LoAppMemBeg();\n-    *end = LoAppMemEnd();\n-    return true;\n-  case 1:\n-    *start = HiAppMemBeg();\n-    *end = HiAppMemEnd();\n-    return true;\n-  case 2:\n-    *start = HeapMemBeg();\n-    *end = HeapMemEnd();\n-    return true;\n-# ifdef TSAN_MID_APP_RANGE\n-  case 3:\n-    *start = MidAppMemBeg();\n-    *end = MidAppMemEnd();\n-    return true;\n-# endif\n-#else\n-  case 0:\n-    *start = AppMemBeg();\n-    *end = AppMemEnd();\n-    return true;\n-#endif\n-  }\n-}\n+ALWAYS_INLINE\n+uptr VdsoBeg(void) { return SelectMapping<MappingField>(kVdsoBeg); }\n \n ALWAYS_INLINE\n-uptr ShadowBeg(void) {\n-  return MappingArchImpl<MAPPING_SHADOW_BEG>();\n-}\n+uptr ShadowBeg(void) { return SelectMapping<MappingField>(kShadowBeg); }\n ALWAYS_INLINE\n-uptr ShadowEnd(void) {\n-  return MappingArchImpl<MAPPING_SHADOW_END>();\n-}\n+uptr ShadowEnd(void) { return SelectMapping<MappingField>(kShadowEnd); }\n \n ALWAYS_INLINE\n-uptr MetaShadowBeg(void) {\n-  return MappingArchImpl<MAPPING_META_SHADOW_BEG>();\n-}\n+uptr MetaShadowBeg(void) { return SelectMapping<MappingField>(kMetaShadowBeg); }\n ALWAYS_INLINE\n-uptr MetaShadowEnd(void) {\n-  return MappingArchImpl<MAPPING_META_SHADOW_END>();\n-}\n+uptr MetaShadowEnd(void) { return SelectMapping<MappingField>(kMetaShadowEnd); }\n \n ALWAYS_INLINE\n-uptr TraceMemBeg(void) {\n-  return MappingArchImpl<MAPPING_TRACE_BEG>();\n-}\n+uptr TraceMemBeg(void) { return SelectMapping<MappingField>(kTraceMemBeg); }\n ALWAYS_INLINE\n-uptr TraceMemEnd(void) {\n-  return MappingArchImpl<MAPPING_TRACE_END>();\n-}\n-\n+uptr TraceMemEnd(void) { return SelectMapping<MappingField>(kTraceMemEnd); }\n \n-template<typename Mapping>\n-bool IsAppMemImpl(uptr mem) {\n-#if !SANITIZER_GO\n+struct IsAppMemImpl {\n+  template <typename Mapping>\n+  static bool Apply(uptr mem) {\n   return (mem >= Mapping::kHeapMemBeg && mem < Mapping::kHeapMemEnd) ||\n-# ifdef TSAN_MID_APP_RANGE\n          (mem >= Mapping::kMidAppMemBeg && mem < Mapping::kMidAppMemEnd) ||\n-# endif\n          (mem >= Mapping::kLoAppMemBeg && mem < Mapping::kLoAppMemEnd) ||\n          (mem >= Mapping::kHiAppMemBeg && mem < Mapping::kHiAppMemEnd);\n-#else\n-  return mem >= Mapping::kAppMemBeg && mem < Mapping::kAppMemEnd;\n-#endif\n-}\n-\n-ALWAYS_INLINE\n-bool IsAppMem(uptr mem) {\n-#if defined(__aarch64__) && !defined(__APPLE__) && !SANITIZER_GO\n-  switch (vmaSize) {\n-    case 39: return IsAppMemImpl<Mapping39>(mem);\n-    case 42: return IsAppMemImpl<Mapping42>(mem);\n-    case 48: return IsAppMemImpl<Mapping48>(mem);\n-  }\n-  DCHECK(0);\n-  return false;\n-#elif defined(__powerpc64__)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 44: return IsAppMemImpl<Mapping44>(mem);\n-#endif\n-    case 46: return IsAppMemImpl<Mapping46>(mem);\n-    case 47: return IsAppMemImpl<Mapping47>(mem);\n   }\n-  DCHECK(0);\n-  return false;\n-#elif defined(__mips64)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 40: return IsAppMemImpl<Mapping40>(mem);\n-#else\n-    case 47: return IsAppMemImpl<Mapping47>(mem);\n-#endif\n-  }\n-  DCHECK(0);\n-  return false;\n-#else\n-  return IsAppMemImpl<Mapping>(mem);\n-#endif\n-}\n+};\n \n+ALWAYS_INLINE\n+bool IsAppMem(uptr mem) { return SelectMapping<IsAppMemImpl>(mem); }\n \n-template<typename Mapping>\n-bool IsShadowMemImpl(uptr mem) {\n-  return mem >= Mapping::kShadowBeg && mem <= Mapping::kShadowEnd;\n-}\n+struct IsShadowMemImpl {\n+  template <typename Mapping>\n+  static bool Apply(uptr mem) {\n+    return mem >= Mapping::kShadowBeg && mem <= Mapping::kShadowEnd;\n+  }\n+};\n \n ALWAYS_INLINE\n-bool IsShadowMem(uptr mem) {\n-#if defined(__aarch64__) && !defined(__APPLE__) && !SANITIZER_GO\n-  switch (vmaSize) {\n-    case 39: return IsShadowMemImpl<Mapping39>(mem);\n-    case 42: return IsShadowMemImpl<Mapping42>(mem);\n-    case 48: return IsShadowMemImpl<Mapping48>(mem);\n-  }\n-  DCHECK(0);\n-  return false;\n-#elif defined(__powerpc64__)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 44: return IsShadowMemImpl<Mapping44>(mem);\n-#endif\n-    case 46: return IsShadowMemImpl<Mapping46>(mem);\n-    case 47: return IsShadowMemImpl<Mapping47>(mem);\n-  }\n-  DCHECK(0);\n-  return false;\n-#elif defined(__mips64)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 40: return IsShadowMemImpl<Mapping40>(mem);\n-#else\n-    case 47: return IsShadowMemImpl<Mapping47>(mem);\n-#endif\n-  }\n-  DCHECK(0);\n-  return false;\n-#else\n-  return IsShadowMemImpl<Mapping>(mem);\n-#endif\n+bool IsShadowMem(RawShadow *p) {\n+  return SelectMapping<IsShadowMemImpl>(reinterpret_cast<uptr>(p));\n }\n \n-\n-template<typename Mapping>\n-bool IsMetaMemImpl(uptr mem) {\n-  return mem >= Mapping::kMetaShadowBeg && mem <= Mapping::kMetaShadowEnd;\n-}\n+struct IsMetaMemImpl {\n+  template <typename Mapping>\n+  static bool Apply(uptr mem) {\n+    return mem >= Mapping::kMetaShadowBeg && mem <= Mapping::kMetaShadowEnd;\n+  }\n+};\n \n ALWAYS_INLINE\n-bool IsMetaMem(uptr mem) {\n-#if defined(__aarch64__) && !defined(__APPLE__) && !SANITIZER_GO\n-  switch (vmaSize) {\n-    case 39: return IsMetaMemImpl<Mapping39>(mem);\n-    case 42: return IsMetaMemImpl<Mapping42>(mem);\n-    case 48: return IsMetaMemImpl<Mapping48>(mem);\n-  }\n-  DCHECK(0);\n-  return false;\n-#elif defined(__powerpc64__)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 44: return IsMetaMemImpl<Mapping44>(mem);\n-#endif\n-    case 46: return IsMetaMemImpl<Mapping46>(mem);\n-    case 47: return IsMetaMemImpl<Mapping47>(mem);\n+bool IsMetaMem(const u32 *p) {\n+  return SelectMapping<IsMetaMemImpl>(reinterpret_cast<uptr>(p));\n+}\n+\n+struct MemToShadowImpl {\n+  template <typename Mapping>\n+  static uptr Apply(uptr x) {\n+    DCHECK(IsAppMemImpl::Apply<Mapping>(x));\n+    return (((x) & ~(Mapping::kShadowMsk | (kShadowCell - 1))) ^\n+            Mapping::kShadowXor) *\n+               kShadowMultiplier +\n+           Mapping::kShadowAdd;\n   }\n-  DCHECK(0);\n-  return false;\n-#elif defined(__mips64)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 40: return IsMetaMemImpl<Mapping40>(mem);\n-#else\n-    case 47: return IsMetaMemImpl<Mapping47>(mem);\n-#endif\n-  }\n-  DCHECK(0);\n-  return false;\n-#else\n-  return IsMetaMemImpl<Mapping>(mem);\n-#endif\n-}\n-\n-\n-template<typename Mapping>\n-uptr MemToShadowImpl(uptr x) {\n-  DCHECK(IsAppMem(x));\n-#if !SANITIZER_GO\n-  return (((x) & ~(Mapping::kAppMemMsk | (kShadowCell - 1)))\n-      ^ Mapping::kAppMemXor) * kShadowCnt;\n-#else\n-# ifndef SANITIZER_WINDOWS\n-  return ((x & ~(kShadowCell - 1)) * kShadowCnt) | Mapping::kShadowBeg;\n-# else\n-  return ((x & ~(kShadowCell - 1)) * kShadowCnt) + Mapping::kShadowBeg;\n-# endif\n-#endif\n-}\n+};\n \n ALWAYS_INLINE\n-uptr MemToShadow(uptr x) {\n-#if defined(__aarch64__) && !defined(__APPLE__) && !SANITIZER_GO\n-  switch (vmaSize) {\n-    case 39: return MemToShadowImpl<Mapping39>(x);\n-    case 42: return MemToShadowImpl<Mapping42>(x);\n-    case 48: return MemToShadowImpl<Mapping48>(x);\n-  }\n-  DCHECK(0);\n-  return 0;\n-#elif defined(__powerpc64__)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 44: return MemToShadowImpl<Mapping44>(x);\n-#endif\n-    case 46: return MemToShadowImpl<Mapping46>(x);\n-    case 47: return MemToShadowImpl<Mapping47>(x);\n-  }\n-  DCHECK(0);\n-  return 0;\n-#elif defined(__mips64)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 40: return MemToShadowImpl<Mapping40>(x);\n-#else\n-    case 47: return MemToShadowImpl<Mapping47>(x);\n-#endif\n-  }\n-  DCHECK(0);\n-  return 0;\n-#else\n-  return MemToShadowImpl<Mapping>(x);\n-#endif\n+RawShadow *MemToShadow(uptr x) {\n+  return reinterpret_cast<RawShadow *>(SelectMapping<MemToShadowImpl>(x));\n }\n \n-\n-template<typename Mapping>\n-u32 *MemToMetaImpl(uptr x) {\n-  DCHECK(IsAppMem(x));\n-#if !SANITIZER_GO\n-  return (u32*)(((((x) & ~(Mapping::kAppMemMsk | (kMetaShadowCell - 1)))) /\n-      kMetaShadowCell * kMetaShadowSize) | Mapping::kMetaShadowBeg);\n-#else\n-# ifndef SANITIZER_WINDOWS\n-  return (u32*)(((x & ~(kMetaShadowCell - 1)) / \\\n-      kMetaShadowCell * kMetaShadowSize) | Mapping::kMetaShadowBeg);\n-# else\n-  return (u32*)(((x & ~(kMetaShadowCell - 1)) / \\\n-      kMetaShadowCell * kMetaShadowSize) + Mapping::kMetaShadowBeg);\n-# endif\n-#endif\n-}\n+struct MemToMetaImpl {\n+  template <typename Mapping>\n+  static u32 *Apply(uptr x) {\n+    DCHECK(IsAppMemImpl::Apply<Mapping>(x));\n+    return (u32 *)(((((x) & ~(Mapping::kShadowMsk | (kMetaShadowCell - 1)))) /\n+                    kMetaShadowCell * kMetaShadowSize) |\n+                   Mapping::kMetaShadowBeg);\n+  }\n+};\n \n ALWAYS_INLINE\n-u32 *MemToMeta(uptr x) {\n-#if defined(__aarch64__) && !defined(__APPLE__) && !SANITIZER_GO\n-  switch (vmaSize) {\n-    case 39: return MemToMetaImpl<Mapping39>(x);\n-    case 42: return MemToMetaImpl<Mapping42>(x);\n-    case 48: return MemToMetaImpl<Mapping48>(x);\n-  }\n-  DCHECK(0);\n-  return 0;\n-#elif defined(__powerpc64__)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 44: return MemToMetaImpl<Mapping44>(x);\n-#endif\n-    case 46: return MemToMetaImpl<Mapping46>(x);\n-    case 47: return MemToMetaImpl<Mapping47>(x);\n+u32 *MemToMeta(uptr x) { return SelectMapping<MemToMetaImpl>(x); }\n+\n+struct ShadowToMemImpl {\n+  template <typename Mapping>\n+  static uptr Apply(uptr sp) {\n+    if (!IsShadowMemImpl::Apply<Mapping>(sp))\n+      return 0;\n+    // The shadow mapping is non-linear and we've lost some bits, so we don't\n+    // have an easy way to restore the original app address. But the mapping is\n+    // a bijection, so we try to restore the address as belonging to\n+    // low/mid/high range consecutively and see if shadow->app->shadow mapping\n+    // gives us the same address.\n+    uptr p =\n+        ((sp - Mapping::kShadowAdd) / kShadowMultiplier) ^ Mapping::kShadowXor;\n+    if (p >= Mapping::kLoAppMemBeg && p < Mapping::kLoAppMemEnd &&\n+        MemToShadowImpl::Apply<Mapping>(p) == sp)\n+      return p;\n+    if (Mapping::kMidAppMemBeg) {\n+      uptr p_mid = p + (Mapping::kMidAppMemBeg & Mapping::kShadowMsk);\n+      if (p_mid >= Mapping::kMidAppMemBeg && p_mid < Mapping::kMidAppMemEnd &&\n+          MemToShadowImpl::Apply<Mapping>(p_mid) == sp)\n+        return p_mid;\n+    }\n+    return p | Mapping::kShadowMsk;\n   }\n-  DCHECK(0);\n-  return 0;\n-#elif defined(__mips64)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 40: return MemToMetaImpl<Mapping40>(x);\n-#else\n-    case 47: return MemToMetaImpl<Mapping47>(x);\n-#endif\n-  }\n-  DCHECK(0);\n-  return 0;\n-#else\n-  return MemToMetaImpl<Mapping>(x);\n-#endif\n-}\n-\n-\n-template<typename Mapping>\n-uptr ShadowToMemImpl(uptr s) {\n-  DCHECK(IsShadowMem(s));\n-#if !SANITIZER_GO\n-  // The shadow mapping is non-linear and we've lost some bits, so we don't have\n-  // an easy way to restore the original app address. But the mapping is a\n-  // bijection, so we try to restore the address as belonging to low/mid/high\n-  // range consecutively and see if shadow->app->shadow mapping gives us the\n-  // same address.\n-  uptr p = (s / kShadowCnt) ^ Mapping::kAppMemXor;\n-  if (p >= Mapping::kLoAppMemBeg && p < Mapping::kLoAppMemEnd &&\n-      MemToShadow(p) == s)\n-    return p;\n-# ifdef TSAN_MID_APP_RANGE\n-  p = ((s / kShadowCnt) ^ Mapping::kAppMemXor) +\n-      (Mapping::kMidAppMemBeg & Mapping::kAppMemMsk);\n-  if (p >= Mapping::kMidAppMemBeg && p < Mapping::kMidAppMemEnd &&\n-      MemToShadow(p) == s)\n-    return p;\n-# endif\n-  return ((s / kShadowCnt) ^ Mapping::kAppMemXor) | Mapping::kAppMemMsk;\n-#else  // #if !SANITIZER_GO\n-# ifndef SANITIZER_WINDOWS\n-  return (s & ~Mapping::kShadowBeg) / kShadowCnt;\n-# else\n-  return (s - Mapping::kShadowBeg) / kShadowCnt;\n-# endif // SANITIZER_WINDOWS\n-#endif\n-}\n+};\n \n ALWAYS_INLINE\n-uptr ShadowToMem(uptr s) {\n-#if defined(__aarch64__) && !defined(__APPLE__) && !SANITIZER_GO\n-  switch (vmaSize) {\n-    case 39: return ShadowToMemImpl<Mapping39>(s);\n-    case 42: return ShadowToMemImpl<Mapping42>(s);\n-    case 48: return ShadowToMemImpl<Mapping48>(s);\n-  }\n-  DCHECK(0);\n-  return 0;\n-#elif defined(__powerpc64__)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 44: return ShadowToMemImpl<Mapping44>(s);\n-#endif\n-    case 46: return ShadowToMemImpl<Mapping46>(s);\n-    case 47: return ShadowToMemImpl<Mapping47>(s);\n+uptr ShadowToMem(RawShadow *s) {\n+  return SelectMapping<ShadowToMemImpl>(reinterpret_cast<uptr>(s));\n+}\n+\n+// Compresses addr to kCompressedAddrBits stored in least significant bits.\n+ALWAYS_INLINE uptr CompressAddr(uptr addr) {\n+  return addr & ((1ull << kCompressedAddrBits) - 1);\n+}\n+\n+struct RestoreAddrImpl {\n+  typedef uptr Result;\n+  template <typename Mapping>\n+  static Result Apply(uptr addr) {\n+    // To restore the address we go over all app memory ranges and check if top\n+    // 3 bits of the compressed addr match that of the app range. If yes, we\n+    // assume that the compressed address come from that range and restore the\n+    // missing top bits to match the app range address.\n+    static constexpr uptr ranges[] = {\n+        Mapping::kLoAppMemBeg,  Mapping::kLoAppMemEnd, Mapping::kMidAppMemBeg,\n+        Mapping::kMidAppMemEnd, Mapping::kHiAppMemBeg, Mapping::kHiAppMemEnd,\n+        Mapping::kHeapMemBeg,   Mapping::kHeapMemEnd,\n+    };\n+    const uptr indicator = 0x0e0000000000ull;\n+    const uptr ind_lsb = 1ull << LeastSignificantSetBitIndex(indicator);\n+    for (uptr i = 0; i < ARRAY_SIZE(ranges); i += 2) {\n+      uptr beg = ranges[i];\n+      uptr end = ranges[i + 1];\n+      if (beg == end)\n+        continue;\n+      for (uptr p = beg; p < end; p = RoundDown(p + ind_lsb, ind_lsb)) {\n+        if ((addr & indicator) == (p & indicator))\n+          return addr | (p & ~(ind_lsb - 1));\n+      }\n+    }\n+    Printf(\"ThreadSanitizer: failed to restore address 0x%zx\\n\", addr);\n+    Die();\n   }\n-  DCHECK(0);\n-  return 0;\n-#elif defined(__mips64)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 40: return ShadowToMemImpl<Mapping40>(s);\n-#else\n-    case 47: return ShadowToMemImpl<Mapping47>(s);\n-#endif\n-  }\n-  DCHECK(0);\n-  return 0;\n-#else\n-  return ShadowToMemImpl<Mapping>(s);\n-#endif\n-}\n-\n+};\n \n+// Restores compressed addr from kCompressedAddrBits to full representation.\n+// This is called only during reporting and is not performance-critical.\n+inline uptr RestoreAddr(uptr addr) {\n+  return SelectMapping<RestoreAddrImpl>(addr);\n+}\n \n // The additional page is to catch shadow stack overflow as paging fault.\n // Windows wants 64K alignment for mmaps.\n const uptr kTotalTraceSize = (kTraceSize * sizeof(Event) + sizeof(Trace)\n     + (64 << 10) + (64 << 10) - 1) & ~((64 << 10) - 1);\n \n-template<typename Mapping>\n-uptr GetThreadTraceImpl(int tid) {\n-  uptr p = Mapping::kTraceMemBeg + (uptr)tid * kTotalTraceSize;\n-  DCHECK_LT(p, Mapping::kTraceMemEnd);\n-  return p;\n-}\n+struct GetThreadTraceImpl {\n+  template <typename Mapping>\n+  static uptr Apply(uptr tid) {\n+    uptr p = Mapping::kTraceMemBeg + tid * kTotalTraceSize;\n+    DCHECK_LT(p, Mapping::kTraceMemEnd);\n+    return p;\n+  }\n+};\n \n ALWAYS_INLINE\n-uptr GetThreadTrace(int tid) {\n-#if defined(__aarch64__) && !defined(__APPLE__) && !SANITIZER_GO\n-  switch (vmaSize) {\n-    case 39: return GetThreadTraceImpl<Mapping39>(tid);\n-    case 42: return GetThreadTraceImpl<Mapping42>(tid);\n-    case 48: return GetThreadTraceImpl<Mapping48>(tid);\n-  }\n-  DCHECK(0);\n-  return 0;\n-#elif defined(__powerpc64__)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 44: return GetThreadTraceImpl<Mapping44>(tid);\n-#endif\n-    case 46: return GetThreadTraceImpl<Mapping46>(tid);\n-    case 47: return GetThreadTraceImpl<Mapping47>(tid);\n-  }\n-  DCHECK(0);\n-  return 0;\n-#elif defined(__mips64)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 40: return GetThreadTraceImpl<Mapping40>(tid);\n-#else\n-    case 47: return GetThreadTraceImpl<Mapping47>(tid);\n-#endif\n+uptr GetThreadTrace(int tid) { return SelectMapping<GetThreadTraceImpl>(tid); }\n+\n+struct GetThreadTraceHeaderImpl {\n+  template <typename Mapping>\n+  static uptr Apply(uptr tid) {\n+    uptr p = Mapping::kTraceMemBeg + tid * kTotalTraceSize +\n+             kTraceSize * sizeof(Event);\n+    DCHECK_LT(p, Mapping::kTraceMemEnd);\n+    return p;\n   }\n-  DCHECK(0);\n-  return 0;\n-#else\n-  return GetThreadTraceImpl<Mapping>(tid);\n-#endif\n-}\n-\n-\n-template<typename Mapping>\n-uptr GetThreadTraceHeaderImpl(int tid) {\n-  uptr p = Mapping::kTraceMemBeg + (uptr)tid * kTotalTraceSize\n-      + kTraceSize * sizeof(Event);\n-  DCHECK_LT(p, Mapping::kTraceMemEnd);\n-  return p;\n-}\n+};\n \n ALWAYS_INLINE\n uptr GetThreadTraceHeader(int tid) {\n-#if defined(__aarch64__) && !defined(__APPLE__) && !SANITIZER_GO\n-  switch (vmaSize) {\n-    case 39: return GetThreadTraceHeaderImpl<Mapping39>(tid);\n-    case 42: return GetThreadTraceHeaderImpl<Mapping42>(tid);\n-    case 48: return GetThreadTraceHeaderImpl<Mapping48>(tid);\n-  }\n-  DCHECK(0);\n-  return 0;\n-#elif defined(__powerpc64__)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 44: return GetThreadTraceHeaderImpl<Mapping44>(tid);\n-#endif\n-    case 46: return GetThreadTraceHeaderImpl<Mapping46>(tid);\n-    case 47: return GetThreadTraceHeaderImpl<Mapping47>(tid);\n-  }\n-  DCHECK(0);\n-  return 0;\n-#elif defined(__mips64)\n-  switch (vmaSize) {\n-#if !SANITIZER_GO\n-    case 40: return GetThreadTraceHeaderImpl<Mapping40>(tid);\n-#else\n-    case 47: return GetThreadTraceHeaderImpl<Mapping47>(tid);\n-#endif\n-  }\n-  DCHECK(0);\n-  return 0;\n-#else\n-  return GetThreadTraceHeaderImpl<Mapping>(tid);\n-#endif\n+  return SelectMapping<GetThreadTraceHeaderImpl>(tid);\n }\n \n void InitializePlatform();\n void InitializePlatformEarly();\n void CheckAndProtect();\n void InitializeShadowMemoryPlatform();\n void FlushShadowMemory();\n-void WriteMemoryProfile(char *buf, uptr buf_size, uptr nthread, uptr nlive);\n+void WriteMemoryProfile(char *buf, uptr buf_size, u64 uptime_ns);\n int ExtractResolvFDs(void *state, int *fds, int nfd);\n int ExtractRecvmsgFDs(void *msg, int *fds, int nfd);\n uptr ExtractLongJmpSp(uptr *env);"}, {"sha": "6134a1be2bf5c69d3a0b8c5620097005c8da09e0", "filename": "libsanitizer/tsan/tsan_platform_linux.cpp", "status": "modified", "additions": 58, "deletions": 51, "changes": 109, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_platform_linux.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_platform_linux.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_platform_linux.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -85,21 +85,19 @@ static void InitializeLongjmpXorKey();\n static uptr longjmp_xor_key;\n #endif\n \n-#ifdef TSAN_RUNTIME_VMA\n // Runtime detected VMA size.\n uptr vmaSize;\n-#endif\n \n enum {\n-  MemTotal  = 0,\n-  MemShadow = 1,\n-  MemMeta   = 2,\n-  MemFile   = 3,\n-  MemMmap   = 4,\n-  MemTrace  = 5,\n-  MemHeap   = 6,\n-  MemOther  = 7,\n-  MemCount  = 8,\n+  MemTotal,\n+  MemShadow,\n+  MemMeta,\n+  MemFile,\n+  MemMmap,\n+  MemTrace,\n+  MemHeap,\n+  MemOther,\n+  MemCount,\n };\n \n void FillProfileCallback(uptr p, uptr rss, bool file,\n@@ -109,39 +107,47 @@ void FillProfileCallback(uptr p, uptr rss, bool file,\n     mem[MemShadow] += rss;\n   else if (p >= MetaShadowBeg() && p < MetaShadowEnd())\n     mem[MemMeta] += rss;\n-#if !SANITIZER_GO\n+  else if ((p >= LoAppMemBeg() && p < LoAppMemEnd()) ||\n+           (p >= MidAppMemBeg() && p < MidAppMemEnd()) ||\n+           (p >= HiAppMemBeg() && p < HiAppMemEnd()))\n+    mem[file ? MemFile : MemMmap] += rss;\n   else if (p >= HeapMemBeg() && p < HeapMemEnd())\n     mem[MemHeap] += rss;\n-  else if (p >= LoAppMemBeg() && p < LoAppMemEnd())\n-    mem[file ? MemFile : MemMmap] += rss;\n-  else if (p >= HiAppMemBeg() && p < HiAppMemEnd())\n-    mem[file ? MemFile : MemMmap] += rss;\n-#else\n-  else if (p >= AppMemBeg() && p < AppMemEnd())\n-    mem[file ? MemFile : MemMmap] += rss;\n-#endif\n   else if (p >= TraceMemBeg() && p < TraceMemEnd())\n     mem[MemTrace] += rss;\n   else\n     mem[MemOther] += rss;\n }\n \n-void WriteMemoryProfile(char *buf, uptr buf_size, uptr nthread, uptr nlive) {\n+void WriteMemoryProfile(char *buf, uptr buf_size, u64 uptime_ns) {\n   uptr mem[MemCount];\n-  internal_memset(mem, 0, sizeof(mem[0]) * MemCount);\n-  __sanitizer::GetMemoryProfile(FillProfileCallback, mem, 7);\n+  internal_memset(mem, 0, sizeof(mem));\n+  GetMemoryProfile(FillProfileCallback, mem, MemCount);\n+  auto meta = ctx->metamap.GetMemoryStats();\n   StackDepotStats *stacks = StackDepotGetStats();\n-  internal_snprintf(buf, buf_size,\n-      \"RSS %zd MB: shadow:%zd meta:%zd file:%zd mmap:%zd\"\n-      \" trace:%zd heap:%zd other:%zd stacks=%zd[%zd] nthr=%zd/%zd\\n\",\n-      mem[MemTotal] >> 20, mem[MemShadow] >> 20, mem[MemMeta] >> 20,\n-      mem[MemFile] >> 20, mem[MemMmap] >> 20, mem[MemTrace] >> 20,\n-      mem[MemHeap] >> 20, mem[MemOther] >> 20,\n-      stacks->allocated >> 20, stacks->n_uniq_ids,\n-      nlive, nthread);\n+  uptr nthread, nlive;\n+  ctx->thread_registry.GetNumberOfThreads(&nthread, &nlive);\n+  uptr internal_stats[AllocatorStatCount];\n+  internal_allocator()->GetStats(internal_stats);\n+  // All these are allocated from the common mmap region.\n+  mem[MemMmap] -= meta.mem_block + meta.sync_obj + stacks->allocated +\n+                  internal_stats[AllocatorStatMapped];\n+  if (s64(mem[MemMmap]) < 0)\n+    mem[MemMmap] = 0;\n+  internal_snprintf(\n+      buf, buf_size,\n+      \"%llus: RSS %zd MB: shadow:%zd meta:%zd file:%zd mmap:%zd\"\n+      \" trace:%zd heap:%zd other:%zd intalloc:%zd memblocks:%zd syncobj:%zu\"\n+      \" stacks=%zd[%zd] nthr=%zd/%zd\\n\",\n+      uptime_ns / (1000 * 1000 * 1000), mem[MemTotal] >> 20,\n+      mem[MemShadow] >> 20, mem[MemMeta] >> 20, mem[MemFile] >> 20,\n+      mem[MemMmap] >> 20, mem[MemTrace] >> 20, mem[MemHeap] >> 20,\n+      mem[MemOther] >> 20, internal_stats[AllocatorStatMapped] >> 20,\n+      meta.mem_block >> 20, meta.sync_obj >> 20, stacks->allocated >> 20,\n+      stacks->n_uniq_ids, nlive, nthread);\n }\n \n-#if SANITIZER_LINUX\n+#  if SANITIZER_LINUX\n void FlushShadowMemoryCallback(\n     const SuspendedThreadsList &suspended_threads_list,\n     void *argument) {\n@@ -178,12 +184,13 @@ static void MapRodata() {\n   internal_unlink(name);  // Unlink it now, so that we can reuse the buffer.\n   fd_t fd = openrv;\n   // Fill the file with kShadowRodata.\n-  const uptr kMarkerSize = 512 * 1024 / sizeof(u64);\n-  InternalMmapVector<u64> marker(kMarkerSize);\n+  const uptr kMarkerSize = 512 * 1024 / sizeof(RawShadow);\n+  InternalMmapVector<RawShadow> marker(kMarkerSize);\n   // volatile to prevent insertion of memset\n-  for (volatile u64 *p = marker.data(); p < marker.data() + kMarkerSize; p++)\n+  for (volatile RawShadow *p = marker.data(); p < marker.data() + kMarkerSize;\n+       p++)\n     *p = kShadowRodata;\n-  internal_write(fd, marker.data(), marker.size() * sizeof(u64));\n+  internal_write(fd, marker.data(), marker.size() * sizeof(RawShadow));\n   // Map the file into memory.\n   uptr page = internal_mmap(0, GetPageSizeCached(), PROT_READ | PROT_WRITE,\n                             MAP_PRIVATE | MAP_ANONYMOUS, fd, 0);\n@@ -203,9 +210,10 @@ static void MapRodata() {\n       char *shadow_start = (char *)MemToShadow(segment.start);\n       char *shadow_end = (char *)MemToShadow(segment.end);\n       for (char *p = shadow_start; p < shadow_end;\n-           p += marker.size() * sizeof(u64)) {\n-        internal_mmap(p, Min<uptr>(marker.size() * sizeof(u64), shadow_end - p),\n-                      PROT_READ, MAP_PRIVATE | MAP_FIXED, fd, 0);\n+           p += marker.size() * sizeof(RawShadow)) {\n+        internal_mmap(\n+            p, Min<uptr>(marker.size() * sizeof(RawShadow), shadow_end - p),\n+            PROT_READ, MAP_PRIVATE | MAP_FIXED, fd, 0);\n       }\n     }\n   }\n@@ -219,7 +227,6 @@ void InitializeShadowMemoryPlatform() {\n #endif  // #if !SANITIZER_GO\n \n void InitializePlatformEarly() {\n-#ifdef TSAN_RUNTIME_VMA\n   vmaSize =\n     (MostSignificantSetBitIndex(GET_CURRENT_FRAME()) + 1);\n #if defined(__aarch64__)\n@@ -265,7 +272,6 @@ void InitializePlatformEarly() {\n   }\n # endif\n #endif\n-#endif\n }\n \n void InitializePlatform() {\n@@ -341,7 +347,7 @@ int ExtractResolvFDs(void *state, int *fds, int nfd) {\n }\n \n // Extract file descriptors passed via UNIX domain sockets.\n-// This is requried to properly handle \"open\" of these fds.\n+// This is required to properly handle \"open\" of these fds.\n // see 'man recvmsg' and 'man 3 cmsg'.\n int ExtractRecvmsgFDs(void *msgp, int *fds, int nfd) {\n   int res = 0;\n@@ -447,18 +453,19 @@ static void InitializeLongjmpXorKey() {\n }\n #endif\n \n+extern \"C\" void __tsan_tls_initialization() {}\n+\n void ImitateTlsWrite(ThreadState *thr, uptr tls_addr, uptr tls_size) {\n-  // Check that the thr object is in tls;\n   const uptr thr_beg = (uptr)thr;\n   const uptr thr_end = (uptr)thr + sizeof(*thr);\n-  CHECK_GE(thr_beg, tls_addr);\n-  CHECK_LE(thr_beg, tls_addr + tls_size);\n-  CHECK_GE(thr_end, tls_addr);\n-  CHECK_LE(thr_end, tls_addr + tls_size);\n-  // Since the thr object is huge, skip it.\n-  MemoryRangeImitateWrite(thr, /*pc=*/2, tls_addr, thr_beg - tls_addr);\n-  MemoryRangeImitateWrite(thr, /*pc=*/2, thr_end,\n-                          tls_addr + tls_size - thr_end);\n+  // ThreadState is normally allocated in TLS and is large,\n+  // so we skip it. But unit tests allocate ThreadState outside of TLS.\n+  if (thr_beg < tls_addr || thr_end >= tls_addr + tls_size)\n+    return;\n+  const uptr pc = StackTrace::GetNextInstructionPc(\n+      reinterpret_cast<uptr>(__tsan_tls_initialization));\n+  MemoryRangeImitateWrite(thr, pc, tls_addr, thr_beg - tls_addr);\n+  MemoryRangeImitateWrite(thr, pc, thr_end, tls_addr + tls_size - thr_end);\n }\n \n // Note: this function runs with async signals enabled,"}, {"sha": "f2aff7786e0e47d62153c870d100c08efd1aad9b", "filename": "libsanitizer/tsan/tsan_platform_mac.cpp", "status": "modified", "additions": 12, "deletions": 10, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_platform_mac.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_platform_mac.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_platform_mac.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -139,7 +139,7 @@ static void RegionMemUsage(uptr start, uptr end, uptr *res, uptr *dirty) {\n   *dirty = dirty_pages * GetPageSizeCached();\n }\n \n-void WriteMemoryProfile(char *buf, uptr buf_size, uptr nthread, uptr nlive) {\n+void WriteMemoryProfile(char *buf, uptr buf_size, u64 uptime_ns) {\n   uptr shadow_res, shadow_dirty;\n   uptr meta_res, meta_dirty;\n   uptr trace_res, trace_dirty;\n@@ -156,10 +156,12 @@ void WriteMemoryProfile(char *buf, uptr buf_size, uptr nthread, uptr nlive) {\n   RegionMemUsage(HeapMemBeg(), HeapMemEnd(), &heap_res, &heap_dirty);\n #else  // !SANITIZER_GO\n   uptr app_res, app_dirty;\n-  RegionMemUsage(AppMemBeg(), AppMemEnd(), &app_res, &app_dirty);\n+  RegionMemUsage(LoAppMemBeg(), LoAppMemEnd(), &app_res, &app_dirty);\n #endif\n \n   StackDepotStats *stacks = StackDepotGetStats();\n+  uptr nthread, nlive;\n+  ctx->thread_registry.GetNumberOfThreads(&nthread, &nlive);\n   internal_snprintf(buf, buf_size,\n     \"shadow   (0x%016zx-0x%016zx): resident %zd kB, dirty %zd kB\\n\"\n     \"meta     (0x%016zx-0x%016zx): resident %zd kB, dirty %zd kB\\n\"\n@@ -169,7 +171,7 @@ void WriteMemoryProfile(char *buf, uptr buf_size, uptr nthread, uptr nlive) {\n     \"high app (0x%016zx-0x%016zx): resident %zd kB, dirty %zd kB\\n\"\n     \"heap     (0x%016zx-0x%016zx): resident %zd kB, dirty %zd kB\\n\"\n #else  // !SANITIZER_GO\n-    \"app      (0x%016zx-0x%016zx): resident %zd kB, dirty %zd kB\\n\"\n+      \"app      (0x%016zx-0x%016zx): resident %zd kB, dirty %zd kB\\n\"\n #endif\n     \"stacks: %zd unique IDs, %zd kB allocated\\n\"\n     \"threads: %zd total, %zd live\\n\"\n@@ -182,13 +184,13 @@ void WriteMemoryProfile(char *buf, uptr buf_size, uptr nthread, uptr nlive) {\n     HiAppMemBeg(), HiAppMemEnd(), high_res / 1024, high_dirty / 1024,\n     HeapMemBeg(), HeapMemEnd(), heap_res / 1024, heap_dirty / 1024,\n #else  // !SANITIZER_GO\n-    AppMemBeg(), AppMemEnd(), app_res / 1024, app_dirty / 1024,\n+      LoAppMemBeg(), LoAppMemEnd(), app_res / 1024, app_dirty / 1024,\n #endif\n     stacks->n_uniq_ids, stacks->allocated / 1024,\n     nthread, nlive);\n }\n \n-#if !SANITIZER_GO\n+#  if !SANITIZER_GO\n void InitializeShadowMemoryPlatform() { }\n \n // On OS X, GCD worker threads are created without a call to pthread_create. We\n@@ -215,8 +217,8 @@ static void my_pthread_introspection_hook(unsigned int event, pthread_t thread,\n       Processor *proc = ProcCreate();\n       ProcWire(proc, thr);\n       ThreadState *parent_thread_state = nullptr;  // No parent.\n-      int tid = ThreadCreate(parent_thread_state, 0, (uptr)thread, true);\n-      CHECK_NE(tid, 0);\n+      Tid tid = ThreadCreate(parent_thread_state, 0, (uptr)thread, true);\n+      CHECK_NE(tid, kMainTid);\n       ThreadStart(thr, tid, GetTid(), ThreadType::Worker);\n     }\n   } else if (event == PTHREAD_INTROSPECTION_THREAD_TERMINATE) {\n@@ -234,11 +236,11 @@ static void my_pthread_introspection_hook(unsigned int event, pthread_t thread,\n #endif\n \n void InitializePlatformEarly() {\n-#if !SANITIZER_GO && !HAS_48_BIT_ADDRESS_SPACE\n+#  if !SANITIZER_GO && SANITIZER_IOS\n   uptr max_vm = GetMaxUserVirtualAddress() + 1;\n-  if (max_vm != Mapping::kHiAppMemEnd) {\n+  if (max_vm != HiAppMemEnd()) {\n     Printf(\"ThreadSanitizer: unsupported vm address limit %p, expected %p.\\n\",\n-           max_vm, Mapping::kHiAppMemEnd);\n+           max_vm, HiAppMemEnd());\n     Die();\n   }\n #endif"}, {"sha": "763ac444377e0d47a3672c9131caaa78b9988a6e", "filename": "libsanitizer/tsan/tsan_platform_posix.cpp", "status": "modified", "additions": 22, "deletions": 15, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_platform_posix.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_platform_posix.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_platform_posix.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -14,12 +14,14 @@\n #include \"sanitizer_common/sanitizer_platform.h\"\n #if SANITIZER_POSIX\n \n-#include \"sanitizer_common/sanitizer_common.h\"\n-#include \"sanitizer_common/sanitizer_errno.h\"\n-#include \"sanitizer_common/sanitizer_libc.h\"\n-#include \"sanitizer_common/sanitizer_procmaps.h\"\n-#include \"tsan_platform.h\"\n-#include \"tsan_rtl.h\"\n+#  include <dlfcn.h>\n+\n+#  include \"sanitizer_common/sanitizer_common.h\"\n+#  include \"sanitizer_common/sanitizer_errno.h\"\n+#  include \"sanitizer_common/sanitizer_libc.h\"\n+#  include \"sanitizer_common/sanitizer_procmaps.h\"\n+#  include \"tsan_platform.h\"\n+#  include \"tsan_rtl.h\"\n \n namespace __tsan {\n \n@@ -29,6 +31,7 @@ static const char kShadowMemoryMappingHint[] =\n     \"HINT: if %s is not supported in your environment, you may set \"\n     \"TSAN_OPTIONS=%s=0\\n\";\n \n+#  if !SANITIZER_GO\n static void DontDumpShadow(uptr addr, uptr size) {\n   if (common_flags()->use_madv_dontdump)\n     if (!DontDumpShadowMemory(addr, size)) {\n@@ -39,7 +42,6 @@ static void DontDumpShadow(uptr addr, uptr size) {\n     }\n }\n \n-#if !SANITIZER_GO\n void InitializeShadowMemory() {\n   // Map memory shadow.\n   if (!MmapFixedSuperNoReserve(ShadowBeg(), ShadowEnd() - ShadowBeg(),\n@@ -70,6 +72,11 @@ void InitializeShadowMemory() {\n       meta, meta + meta_size, meta_size >> 30);\n \n   InitializeShadowMemoryPlatform();\n+\n+  on_initialize = reinterpret_cast<void (*)(void)>(\n+      dlsym(RTLD_DEFAULT, \"__tsan_on_initialize\"));\n+  on_finalize =\n+      reinterpret_cast<int (*)(int)>(dlsym(RTLD_DEFAULT, \"__tsan_on_finalize\"));\n }\n \n static bool TryProtectRange(uptr beg, uptr end) {\n@@ -98,24 +105,24 @@ void CheckAndProtect() {\n       continue;\n     if (segment.start >= VdsoBeg())  // vdso\n       break;\n-    Printf(\"FATAL: ThreadSanitizer: unexpected memory mapping %p-%p\\n\",\n+    Printf(\"FATAL: ThreadSanitizer: unexpected memory mapping 0x%zx-0x%zx\\n\",\n            segment.start, segment.end);\n     Die();\n   }\n \n-#if defined(__aarch64__) && defined(__APPLE__) && !HAS_48_BIT_ADDRESS_SPACE\n+#    if defined(__aarch64__) && defined(__APPLE__) && SANITIZER_IOS\n   ProtectRange(HeapMemEnd(), ShadowBeg());\n   ProtectRange(ShadowEnd(), MetaShadowBeg());\n   ProtectRange(MetaShadowEnd(), TraceMemBeg());\n #else\n   ProtectRange(LoAppMemEnd(), ShadowBeg());\n   ProtectRange(ShadowEnd(), MetaShadowBeg());\n-#ifdef TSAN_MID_APP_RANGE\n-  ProtectRange(MetaShadowEnd(), MidAppMemBeg());\n-  ProtectRange(MidAppMemEnd(), TraceMemBeg());\n-#else\n-  ProtectRange(MetaShadowEnd(), TraceMemBeg());\n-#endif\n+  if (MidAppMemBeg()) {\n+    ProtectRange(MetaShadowEnd(), MidAppMemBeg());\n+    ProtectRange(MidAppMemEnd(), TraceMemBeg());\n+  } else {\n+    ProtectRange(MetaShadowEnd(), TraceMemBeg());\n+  }\n   // Memory for traces is mapped lazily in MapThreadTrace.\n   // Protect the whole range for now, so that user does not map something here.\n   ProtectRange(TraceMemBeg(), TraceMemEnd());"}, {"sha": "fea893768c79f15d1e8f489a4d22d2663686f017", "filename": "libsanitizer/tsan/tsan_platform_windows.cpp", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_platform_windows.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_platform_windows.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_platform_windows.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -23,8 +23,7 @@ namespace __tsan {\n void FlushShadowMemory() {\n }\n \n-void WriteMemoryProfile(char *buf, uptr buf_size, uptr nthread, uptr nlive) {\n-}\n+void WriteMemoryProfile(char *buf, uptr buf_size, u64 uptime_ns) {}\n \n void InitializePlatformEarly() {\n }"}, {"sha": "a926c3761ccf917ce2226cbaa732144afb80bf9f", "filename": "libsanitizer/tsan/tsan_report.cpp", "status": "modified", "additions": 34, "deletions": 43, "changes": 77, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_report.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_report.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_report.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -19,22 +19,6 @@\n \n namespace __tsan {\n \n-ReportStack::ReportStack() : frames(nullptr), suppressable(false) {}\n-\n-ReportStack *ReportStack::New() {\n-  void *mem = internal_alloc(MBlockReportStack, sizeof(ReportStack));\n-  return new(mem) ReportStack();\n-}\n-\n-ReportLocation::ReportLocation(ReportLocationType type)\n-    : type(type), global(), heap_chunk_start(0), heap_chunk_size(0), tid(0),\n-      fd(0), suppressable(false), stack(nullptr) {}\n-\n-ReportLocation *ReportLocation::New(ReportLocationType type) {\n-  void *mem = internal_alloc(MBlockReportStack, sizeof(ReportLocation));\n-  return new(mem) ReportLocation(type);\n-}\n-\n class Decorator: public __sanitizer::SanitizerCommonDecorator {\n  public:\n   Decorator() : SanitizerCommonDecorator() { }\n@@ -68,7 +52,7 @@ ReportDesc::~ReportDesc() {\n #if !SANITIZER_GO\n \n const int kThreadBufSize = 32;\n-const char *thread_name(char *buf, int tid) {\n+const char *thread_name(char *buf, Tid tid) {\n   if (tid == kMainTid)\n     return \"main thread\";\n   internal_snprintf(buf, kThreadBufSize, \"thread T%d\", tid);\n@@ -189,23 +173,25 @@ static void PrintLocation(const ReportLocation *loc) {\n   if (loc->type == ReportLocationGlobal) {\n     const DataInfo &global = loc->global;\n     if (global.size != 0)\n-      Printf(\"  Location is global '%s' of size %zu at %p (%s+%p)\\n\\n\",\n-             global.name, global.size, global.start,\n+      Printf(\"  Location is global '%s' of size %zu at %p (%s+0x%zx)\\n\\n\",\n+             global.name, global.size, reinterpret_cast<void *>(global.start),\n              StripModuleName(global.module), global.module_offset);\n     else\n-      Printf(\"  Location is global '%s' at %p (%s+%p)\\n\\n\", global.name,\n-             global.start, StripModuleName(global.module),\n-             global.module_offset);\n+      Printf(\"  Location is global '%s' at %p (%s+0x%zx)\\n\\n\", global.name,\n+             reinterpret_cast<void *>(global.start),\n+             StripModuleName(global.module), global.module_offset);\n   } else if (loc->type == ReportLocationHeap) {\n     char thrbuf[kThreadBufSize];\n     const char *object_type = GetObjectTypeFromTag(loc->external_tag);\n     if (!object_type) {\n       Printf(\"  Location is heap block of size %zu at %p allocated by %s:\\n\",\n-             loc->heap_chunk_size, loc->heap_chunk_start,\n+             loc->heap_chunk_size,\n+             reinterpret_cast<void *>(loc->heap_chunk_start),\n              thread_name(thrbuf, loc->tid));\n     } else {\n       Printf(\"  Location is %s of size %zu at %p allocated by %s:\\n\",\n-             object_type, loc->heap_chunk_size, loc->heap_chunk_start,\n+             object_type, loc->heap_chunk_size,\n+             reinterpret_cast<void *>(loc->heap_chunk_start),\n              thread_name(thrbuf, loc->tid));\n     }\n     print_stack = true;\n@@ -225,13 +211,14 @@ static void PrintLocation(const ReportLocation *loc) {\n \n static void PrintMutexShort(const ReportMutex *rm, const char *after) {\n   Decorator d;\n-  Printf(\"%sM%zd%s%s\", d.Mutex(), rm->id, d.Default(), after);\n+  Printf(\"%sM%lld%s%s\", d.Mutex(), rm->id, d.Default(), after);\n }\n \n static void PrintMutexShortWithAddress(const ReportMutex *rm,\n                                        const char *after) {\n   Decorator d;\n-  Printf(\"%sM%zd (%p)%s%s\", d.Mutex(), rm->id, rm->addr, d.Default(), after);\n+  Printf(\"%sM%lld (%p)%s%s\", d.Mutex(), rm->id,\n+         reinterpret_cast<void *>(rm->addr), d.Default(), after);\n }\n \n static void PrintMutex(const ReportMutex *rm) {\n@@ -242,7 +229,8 @@ static void PrintMutex(const ReportMutex *rm) {\n     Printf(\"%s\", d.Default());\n   } else {\n     Printf(\"%s\", d.Mutex());\n-    Printf(\"  Mutex M%llu (%p) created at:\\n\", rm->id, rm->addr);\n+    Printf(\"  Mutex M%llu (%p) created at:\\n\", rm->id,\n+           reinterpret_cast<void *>(rm->addr));\n     Printf(\"%s\", d.Default());\n     PrintStack(rm->stack);\n   }\n@@ -259,12 +247,13 @@ static void PrintThread(const ReportThread *rt) {\n   char thrbuf[kThreadBufSize];\n   const char *thread_status = rt->running ? \"running\" : \"finished\";\n   if (rt->thread_type == ThreadType::Worker) {\n-    Printf(\" (tid=%zu, %s) is a GCD worker thread\\n\", rt->os_id, thread_status);\n+    Printf(\" (tid=%llu, %s) is a GCD worker thread\\n\", rt->os_id,\n+           thread_status);\n     Printf(\"\\n\");\n     Printf(\"%s\", d.Default());\n     return;\n   }\n-  Printf(\" (tid=%zu, %s) created by %s\", rt->os_id, thread_status,\n+  Printf(\" (tid=%llu, %s) created by %s\", rt->os_id, thread_status,\n          thread_name(thrbuf, rt->parent_tid));\n   if (rt->stack)\n     Printf(\" at:\");\n@@ -394,7 +383,7 @@ void PrintReport(const ReportDesc *rep) {\n \n #else  // #if !SANITIZER_GO\n \n-const u32 kMainGoroutineId = 1;\n+const Tid kMainGoroutineId = 1;\n \n void PrintStack(const ReportStack *ent) {\n   if (ent == 0 || ent->frames == 0) {\n@@ -405,16 +394,17 @@ void PrintStack(const ReportStack *ent) {\n   for (int i = 0; frame; frame = frame->next, i++) {\n     const AddressInfo &info = frame->info;\n     Printf(\"  %s()\\n      %s:%d +0x%zx\\n\", info.function,\n-        StripPathPrefix(info.file, common_flags()->strip_path_prefix),\n-        info.line, (void *)info.module_offset);\n+           StripPathPrefix(info.file, common_flags()->strip_path_prefix),\n+           info.line, info.module_offset);\n   }\n }\n \n static void PrintMop(const ReportMop *mop, bool first) {\n   Printf(\"\\n\");\n   Printf(\"%s at %p by \",\n-      (first ? (mop->write ? \"Write\" : \"Read\")\n-             : (mop->write ? \"Previous write\" : \"Previous read\")), mop->addr);\n+         (first ? (mop->write ? \"Write\" : \"Read\")\n+                : (mop->write ? \"Previous write\" : \"Previous read\")),\n+         reinterpret_cast<void *>(mop->addr));\n   if (mop->tid == kMainGoroutineId)\n     Printf(\"main goroutine:\\n\");\n   else\n@@ -426,8 +416,8 @@ static void PrintLocation(const ReportLocation *loc) {\n   switch (loc->type) {\n   case ReportLocationHeap: {\n     Printf(\"\\n\");\n-    Printf(\"Heap block of size %zu at %p allocated by \",\n-        loc->heap_chunk_size, loc->heap_chunk_start);\n+    Printf(\"Heap block of size %zu at %p allocated by \", loc->heap_chunk_size,\n+           reinterpret_cast<void *>(loc->heap_chunk_start));\n     if (loc->tid == kMainGoroutineId)\n       Printf(\"main goroutine:\\n\");\n     else\n@@ -438,8 +428,9 @@ static void PrintLocation(const ReportLocation *loc) {\n   case ReportLocationGlobal: {\n     Printf(\"\\n\");\n     Printf(\"Global var %s of size %zu at %p declared at %s:%zu\\n\",\n-        loc->global.name, loc->global.size, loc->global.start,\n-        loc->global.file, loc->global.line);\n+           loc->global.name, loc->global.size,\n+           reinterpret_cast<void *>(loc->global.start), loc->global.file,\n+           loc->global.line);\n     break;\n   }\n   default:\n@@ -469,13 +460,13 @@ void PrintReport(const ReportDesc *rep) {\n   } else if (rep->typ == ReportTypeDeadlock) {\n     Printf(\"WARNING: DEADLOCK\\n\");\n     for (uptr i = 0; i < rep->mutexes.Size(); i++) {\n-      Printf(\"Goroutine %d lock mutex %d while holding mutex %d:\\n\",\n-          999, rep->mutexes[i]->id,\n-          rep->mutexes[(i+1) % rep->mutexes.Size()]->id);\n+      Printf(\"Goroutine %d lock mutex %llu while holding mutex %llu:\\n\", 999,\n+             rep->mutexes[i]->id,\n+             rep->mutexes[(i + 1) % rep->mutexes.Size()]->id);\n       PrintStack(rep->stacks[2*i]);\n       Printf(\"\\n\");\n-      Printf(\"Mutex %d was previously locked here:\\n\",\n-          rep->mutexes[(i+1) % rep->mutexes.Size()]->id);\n+      Printf(\"Mutex %llu was previously locked here:\\n\",\n+             rep->mutexes[(i + 1) % rep->mutexes.Size()]->id);\n       PrintStack(rep->stacks[2*i + 1]);\n       Printf(\"\\n\");\n     }"}, {"sha": "d68c2db88828f1565f287131770d4a2b3235e512", "filename": "libsanitizer/tsan/tsan_report.h", "status": "modified", "additions": 14, "deletions": 22, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_report.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_report.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_report.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -38,12 +38,8 @@ enum ReportType {\n };\n \n struct ReportStack {\n-  SymbolizedStack *frames;\n-  bool suppressable;\n-  static ReportStack *New();\n-\n- private:\n-  ReportStack();\n+  SymbolizedStack *frames = nullptr;\n+  bool suppressable = false;\n };\n \n struct ReportMopMutex {\n@@ -73,28 +69,24 @@ enum ReportLocationType {\n };\n \n struct ReportLocation {\n-  ReportLocationType type;\n-  DataInfo global;\n-  uptr heap_chunk_start;\n-  uptr heap_chunk_size;\n-  uptr external_tag;\n-  int tid;\n-  int fd;\n-  bool suppressable;\n-  ReportStack *stack;\n-\n-  static ReportLocation *New(ReportLocationType type);\n- private:\n-  explicit ReportLocation(ReportLocationType type);\n+  ReportLocationType type = ReportLocationGlobal;\n+  DataInfo global = {};\n+  uptr heap_chunk_start = 0;\n+  uptr heap_chunk_size = 0;\n+  uptr external_tag = 0;\n+  Tid tid = kInvalidTid;\n+  int fd = 0;\n+  bool suppressable = false;\n+  ReportStack *stack = nullptr;\n };\n \n struct ReportThread {\n-  int id;\n+  Tid id;\n   tid_t os_id;\n   bool running;\n   ThreadType thread_type;\n   char *name;\n-  u32 parent_tid;\n+  Tid parent_tid;\n   ReportStack *stack;\n };\n \n@@ -114,7 +106,7 @@ class ReportDesc {\n   Vector<ReportLocation*> locs;\n   Vector<ReportMutex*> mutexes;\n   Vector<ReportThread*> threads;\n-  Vector<int> unique_tids;\n+  Vector<Tid> unique_tids;\n   ReportStack *sleep;\n   int count;\n "}, {"sha": "d67928224545cf7916d8428637261123a2c41e3e", "filename": "libsanitizer/tsan/tsan_rtl.cpp", "status": "modified", "additions": 319, "deletions": 158, "changes": 477, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_rtl.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_rtl.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_rtl.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -28,16 +28,6 @@\n #include \"tsan_symbolize.h\"\n #include \"ubsan/ubsan_init.h\"\n \n-#ifdef __SSE3__\n-// <emmintrin.h> transitively includes <stdlib.h>,\n-// and it's prohibited to include std headers into tsan runtime.\n-// So we do this dirty trick.\n-#define _MM_MALLOC_H_INCLUDED\n-#define __MM_MALLOC_H\n-#include <emmintrin.h>\n-typedef __m128i m128;\n-#endif\n-\n volatile int __tsan_resumed = 0;\n \n extern \"C\" void __tsan_resume() {\n@@ -46,6 +36,11 @@ extern \"C\" void __tsan_resume() {\n \n namespace __tsan {\n \n+#if !SANITIZER_GO\n+void (*on_initialize)(void);\n+int (*on_finalize)(int);\n+#endif\n+\n #if !SANITIZER_GO && !SANITIZER_MAC\n __attribute__((tls_model(\"initial-exec\")))\n THREADLOCAL char cur_thread_placeholder[sizeof(ThreadState)] ALIGNED(64);\n@@ -62,24 +57,21 @@ void OnInitialize();\n SANITIZER_WEAK_CXX_DEFAULT_IMPL\n bool OnFinalize(bool failed) {\n #if !SANITIZER_GO\n-  if (auto *ptr = dlsym(RTLD_DEFAULT, \"__tsan_on_finalize\"))\n-    return reinterpret_cast<decltype(&__tsan_on_finalize)>(ptr)(failed);\n+  if (on_finalize)\n+    return on_finalize(failed);\n #endif\n   return failed;\n }\n SANITIZER_WEAK_CXX_DEFAULT_IMPL\n void OnInitialize() {\n #if !SANITIZER_GO\n-  if (auto *ptr = dlsym(RTLD_DEFAULT, \"__tsan_on_initialize\")) {\n-    return reinterpret_cast<decltype(&__tsan_on_initialize)>(ptr)();\n-  }\n+  if (on_initialize)\n+    on_initialize();\n #endif\n }\n #endif\n \n-static ALIGNED(64) char thread_registry_placeholder[sizeof(ThreadRegistry)];\n-\n-static ThreadContextBase *CreateThreadContext(u32 tid) {\n+static ThreadContextBase *CreateThreadContext(Tid tid) {\n   // Map thread trace when context is created.\n   char name[50];\n   internal_snprintf(name, sizeof(name), \"trace %u\", tid);\n@@ -98,13 +90,12 @@ static ThreadContextBase *CreateThreadContext(u32 tid) {\n     ReleaseMemoryPagesToOS(hdr_end, hdr + sizeof(Trace));\n     uptr unused = hdr + sizeof(Trace) - hdr_end;\n     if (hdr_end != (uptr)MmapFixedNoAccess(hdr_end, unused)) {\n-      Report(\"ThreadSanitizer: failed to mprotect(%p, %p)\\n\",\n-          hdr_end, unused);\n+      Report(\"ThreadSanitizer: failed to mprotect [0x%zx-0x%zx) \\n\", hdr_end,\n+             unused);\n       CHECK(\"unable to mprotect\" && 0);\n     }\n   }\n-  void *mem = internal_alloc(MBlockThreadContex, sizeof(ThreadContext));\n-  return new(mem) ThreadContext(tid);\n+  return New<ThreadContext>(tid);\n }\n \n #if !SANITIZER_GO\n@@ -117,9 +108,8 @@ Context::Context()\n     : initialized(),\n       report_mtx(MutexTypeReport),\n       nreported(),\n-      nmissed_expected(),\n-      thread_registry(new (thread_registry_placeholder) ThreadRegistry(\n-          CreateThreadContext, kMaxTid, kThreadQuarantineSize, kMaxTidReuse)),\n+      thread_registry(CreateThreadContext, kMaxTid, kThreadQuarantineSize,\n+                      kMaxTidReuse),\n       racy_mtx(MutexTypeRacy),\n       racy_stacks(),\n       racy_addresses(),\n@@ -129,7 +119,7 @@ Context::Context()\n }\n \n // The objects are allocated in TLS, so one may rely on zero-initialization.\n-ThreadState::ThreadState(Context *ctx, u32 tid, int unique_id, u64 epoch,\n+ThreadState::ThreadState(Context *ctx, Tid tid, int unique_id, u64 epoch,\n                          unsigned reuse_count, uptr stk_addr, uptr stk_size,\n                          uptr tls_addr, uptr tls_size)\n     : fast_state(tid, epoch)\n@@ -155,16 +145,49 @@ ThreadState::ThreadState(Context *ctx, u32 tid, int unique_id, u64 epoch,\n       last_sleep_clock(tid)\n #endif\n {\n+  CHECK_EQ(reinterpret_cast<uptr>(this) % SANITIZER_CACHE_LINE_SIZE, 0);\n+#if !SANITIZER_GO\n+  shadow_stack_pos = shadow_stack;\n+  shadow_stack_end = shadow_stack + kShadowStackSize;\n+#else\n+  // Setup dynamic shadow stack.\n+  const int kInitStackSize = 8;\n+  shadow_stack = (uptr *)Alloc(kInitStackSize * sizeof(uptr));\n+  shadow_stack_pos = shadow_stack;\n+  shadow_stack_end = shadow_stack + kInitStackSize;\n+#endif\n }\n \n #if !SANITIZER_GO\n-static void MemoryProfiler(Context *ctx, fd_t fd, int i) {\n-  uptr n_threads;\n-  uptr n_running_threads;\n-  ctx->thread_registry->GetNumberOfThreads(&n_threads, &n_running_threads);\n+void MemoryProfiler(u64 uptime) {\n+  if (ctx->memprof_fd == kInvalidFd)\n+    return;\n   InternalMmapVector<char> buf(4096);\n-  WriteMemoryProfile(buf.data(), buf.size(), n_threads, n_running_threads);\n-  WriteToFile(fd, buf.data(), internal_strlen(buf.data()));\n+  WriteMemoryProfile(buf.data(), buf.size(), uptime);\n+  WriteToFile(ctx->memprof_fd, buf.data(), internal_strlen(buf.data()));\n+}\n+\n+void InitializeMemoryProfiler() {\n+  ctx->memprof_fd = kInvalidFd;\n+  const char *fname = flags()->profile_memory;\n+  if (!fname || !fname[0])\n+    return;\n+  if (internal_strcmp(fname, \"stdout\") == 0) {\n+    ctx->memprof_fd = 1;\n+  } else if (internal_strcmp(fname, \"stderr\") == 0) {\n+    ctx->memprof_fd = 2;\n+  } else {\n+    InternalScopedString filename;\n+    filename.append(\"%s.%d\", fname, (int)internal_getpid());\n+    ctx->memprof_fd = OpenFile(filename.data(), WrOnly);\n+    if (ctx->memprof_fd == kInvalidFd) {\n+      Printf(\"ThreadSanitizer: failed to open memory profile file '%s'\\n\",\n+             filename.data());\n+      return;\n+    }\n+  }\n+  MemoryProfiler(0);\n+  MaybeSpawnBackgroundThread();\n }\n \n static void *BackgroundThread(void *arg) {\n@@ -175,25 +198,7 @@ static void *BackgroundThread(void *arg) {\n   cur_thread_init();\n   cur_thread()->ignore_interceptors++;\n   const u64 kMs2Ns = 1000 * 1000;\n-\n-  fd_t mprof_fd = kInvalidFd;\n-  if (flags()->profile_memory && flags()->profile_memory[0]) {\n-    if (internal_strcmp(flags()->profile_memory, \"stdout\") == 0) {\n-      mprof_fd = 1;\n-    } else if (internal_strcmp(flags()->profile_memory, \"stderr\") == 0) {\n-      mprof_fd = 2;\n-    } else {\n-      InternalScopedString filename;\n-      filename.append(\"%s.%d\", flags()->profile_memory, (int)internal_getpid());\n-      fd_t fd = OpenFile(filename.data(), WrOnly);\n-      if (fd == kInvalidFd) {\n-        Printf(\"ThreadSanitizer: failed to open memory profile file '%s'\\n\",\n-               filename.data());\n-      } else {\n-        mprof_fd = fd;\n-      }\n-    }\n-  }\n+  const u64 start = NanoTime();\n \n   u64 last_flush = NanoTime();\n   uptr last_rss = 0;\n@@ -211,7 +216,6 @@ static void *BackgroundThread(void *arg) {\n         last_flush = NanoTime();\n       }\n     }\n-    // GetRSS can be expensive on huge programs, so don't do it every 100ms.\n     if (flags()->memory_limit_mb > 0) {\n       uptr rss = GetRSS();\n       uptr limit = uptr(flags()->memory_limit_mb) << 20;\n@@ -227,9 +231,7 @@ static void *BackgroundThread(void *arg) {\n       last_rss = rss;\n     }\n \n-    // Write memory profile if requested.\n-    if (mprof_fd != kInvalidFd)\n-      MemoryProfiler(ctx, mprof_fd, i);\n+    MemoryProfiler(now - start);\n \n     // Flush symbolizer cache if requested.\n     if (flags()->flush_symbolizer_ms > 0) {\n@@ -260,7 +262,8 @@ static void StopBackgroundThread() {\n #endif\n \n void DontNeedShadowFor(uptr addr, uptr size) {\n-  ReleaseMemoryPagesToOS(MemToShadow(addr), MemToShadow(addr + size));\n+  ReleaseMemoryPagesToOS(reinterpret_cast<uptr>(MemToShadow(addr)),\n+                         reinterpret_cast<uptr>(MemToShadow(addr + size)));\n }\n \n #if !SANITIZER_GO\n@@ -297,7 +300,7 @@ void MapShadow(uptr addr, uptr size) {\n                                  \"meta shadow\"))\n       Die();\n   } else {\n-    // Mapping continous heap.\n+    // Mapping continuous heap.\n     // Windows wants 64K alignment.\n     meta_begin = RoundDownTo(meta_begin, 64 << 10);\n     meta_end = RoundUpTo(meta_end, 64 << 10);\n@@ -310,58 +313,22 @@ void MapShadow(uptr addr, uptr size) {\n       Die();\n     mapped_meta_end = meta_end;\n   }\n-  VPrintf(2, \"mapped meta shadow for (%p-%p) at (%p-%p)\\n\",\n-      addr, addr+size, meta_begin, meta_end);\n+  VPrintf(2, \"mapped meta shadow for (0x%zx-0x%zx) at (0x%zx-0x%zx)\\n\", addr,\n+          addr + size, meta_begin, meta_end);\n }\n \n void MapThreadTrace(uptr addr, uptr size, const char *name) {\n-  DPrintf(\"#0: Mapping trace at %p-%p(0x%zx)\\n\", addr, addr + size, size);\n+  DPrintf(\"#0: Mapping trace at 0x%zx-0x%zx(0x%zx)\\n\", addr, addr + size, size);\n   CHECK_GE(addr, TraceMemBeg());\n   CHECK_LE(addr + size, TraceMemEnd());\n   CHECK_EQ(addr, addr & ~((64 << 10) - 1));  // windows wants 64K alignment\n   if (!MmapFixedSuperNoReserve(addr, size, name)) {\n-    Printf(\"FATAL: ThreadSanitizer can not mmap thread trace (%p/%p)\\n\",\n-        addr, size);\n+    Printf(\"FATAL: ThreadSanitizer can not mmap thread trace (0x%zx/0x%zx)\\n\",\n+           addr, size);\n     Die();\n   }\n }\n \n-static void CheckShadowMapping() {\n-  uptr beg, end;\n-  for (int i = 0; GetUserRegion(i, &beg, &end); i++) {\n-    // Skip cases for empty regions (heap definition for architectures that\n-    // do not use 64-bit allocator).\n-    if (beg == end)\n-      continue;\n-    VPrintf(3, \"checking shadow region %p-%p\\n\", beg, end);\n-    uptr prev = 0;\n-    for (uptr p0 = beg; p0 <= end; p0 += (end - beg) / 4) {\n-      for (int x = -(int)kShadowCell; x <= (int)kShadowCell; x += kShadowCell) {\n-        const uptr p = RoundDown(p0 + x, kShadowCell);\n-        if (p < beg || p >= end)\n-          continue;\n-        const uptr s = MemToShadow(p);\n-        const uptr m = (uptr)MemToMeta(p);\n-        VPrintf(3, \"  checking pointer %p: shadow=%p meta=%p\\n\", p, s, m);\n-        CHECK(IsAppMem(p));\n-        CHECK(IsShadowMem(s));\n-        CHECK_EQ(p, ShadowToMem(s));\n-        CHECK(IsMetaMem(m));\n-        if (prev) {\n-          // Ensure that shadow and meta mappings are linear within a single\n-          // user range. Lots of code that processes memory ranges assumes it.\n-          const uptr prev_s = MemToShadow(prev);\n-          const uptr prev_m = (uptr)MemToMeta(prev);\n-          CHECK_EQ(s - prev_s, (p - prev) * kShadowMultiplier);\n-          CHECK_EQ((m - prev_m) / kMetaShadowSize,\n-                   (p - prev) / kMetaShadowCell);\n-        }\n-        prev = p;\n-      }\n-    }\n-  }\n-}\n-\n #if !SANITIZER_GO\n static void OnStackUnwind(const SignalContext &sig, const void *,\n                           BufferedStackTrace *stack) {\n@@ -386,9 +353,10 @@ void CheckUnwind() {\n   PrintCurrentStackSlow(StackTrace::GetCurrentPc());\n }\n \n+bool is_initialized;\n+\n void Initialize(ThreadState *thr) {\n   // Thread safe because done before all threads exist.\n-  static bool is_initialized = false;\n   if (is_initialized)\n     return;\n   is_initialized = true;\n@@ -420,9 +388,7 @@ void Initialize(ThreadState *thr) {\n   Processor *proc = ProcCreate();\n   ProcWire(proc, thr);\n   InitializeInterceptors();\n-  CheckShadowMapping();\n   InitializePlatform();\n-  InitializeMutex();\n   InitializeDynamicAnnotations();\n #if !SANITIZER_GO\n   InitializeShadowMemory();\n@@ -441,8 +407,8 @@ void Initialize(ThreadState *thr) {\n           (int)internal_getpid());\n \n   // Initialize thread 0.\n-  int tid = ThreadCreate(thr, 0, 0, true);\n-  CHECK_EQ(tid, 0);\n+  Tid tid = ThreadCreate(thr, 0, 0, true);\n+  CHECK_EQ(tid, kMainTid);\n   ThreadStart(thr, tid, GetTid(), ThreadType::Regular);\n #if TSAN_CONTAINS_UBSAN\n   __ubsan::InitAsPlugin();\n@@ -451,6 +417,7 @@ void Initialize(ThreadState *thr) {\n \n #if !SANITIZER_GO\n   Symbolizer::LateInitialize();\n+  InitializeMemoryProfiler();\n #endif\n \n   if (flags()->stop_on_start) {\n@@ -507,18 +474,8 @@ int Finalize(ThreadState *thr) {\n #endif\n   }\n \n-  if (ctx->nmissed_expected) {\n-    failed = true;\n-    Printf(\"ThreadSanitizer: missed %d expected races\\n\",\n-        ctx->nmissed_expected);\n-  }\n-\n   if (common_flags()->print_suppressions)\n     PrintMatchedSuppressions();\n-#if !SANITIZER_GO\n-  if (flags()->print_benign)\n-    PrintMatchedBenignRaces();\n-#endif\n \n   failed = OnFinalize(failed);\n \n@@ -527,7 +484,7 @@ int Finalize(ThreadState *thr) {\n \n #if !SANITIZER_GO\n void ForkBefore(ThreadState *thr, uptr pc) NO_THREAD_SAFETY_ANALYSIS {\n-  ctx->thread_registry->Lock();\n+  ctx->thread_registry.Lock();\n   ctx->report_mtx.Lock();\n   ScopedErrorReportLock::Lock();\n   // Suppress all reports in the pthread_atfork callbacks.\n@@ -546,18 +503,18 @@ void ForkParentAfter(ThreadState *thr, uptr pc) NO_THREAD_SAFETY_ANALYSIS {\n   thr->ignore_interceptors--;\n   ScopedErrorReportLock::Unlock();\n   ctx->report_mtx.Unlock();\n-  ctx->thread_registry->Unlock();\n+  ctx->thread_registry.Unlock();\n }\n \n void ForkChildAfter(ThreadState *thr, uptr pc) NO_THREAD_SAFETY_ANALYSIS {\n   thr->suppress_reports--;  // Enabled in ForkBefore.\n   thr->ignore_interceptors--;\n   ScopedErrorReportLock::Unlock();\n   ctx->report_mtx.Unlock();\n-  ctx->thread_registry->Unlock();\n+  ctx->thread_registry.Unlock();\n \n   uptr nthread = 0;\n-  ctx->thread_registry->GetNumberOfThreads(0, 0, &nthread /* alive threads */);\n+  ctx->thread_registry.GetNumberOfThreads(0, 0, &nthread /* alive threads */);\n   VPrintf(1, \"ThreadSanitizer: forked new process with pid %d,\"\n       \" parent had %d threads\\n\", (int)internal_getpid(), (int)nthread);\n   if (nthread == 1) {\n@@ -579,19 +536,18 @@ NOINLINE\n void GrowShadowStack(ThreadState *thr) {\n   const int sz = thr->shadow_stack_end - thr->shadow_stack;\n   const int newsz = 2 * sz;\n-  uptr *newstack = (uptr*)internal_alloc(MBlockShadowStack,\n-      newsz * sizeof(uptr));\n+  auto *newstack = (uptr *)Alloc(newsz * sizeof(uptr));\n   internal_memcpy(newstack, thr->shadow_stack, sz * sizeof(uptr));\n-  internal_free(thr->shadow_stack);\n+  Free(thr->shadow_stack);\n   thr->shadow_stack = newstack;\n   thr->shadow_stack_pos = newstack + sz;\n   thr->shadow_stack_end = newstack + newsz;\n }\n #endif\n \n-u32 CurrentStackId(ThreadState *thr, uptr pc) {\n+StackID CurrentStackId(ThreadState *thr, uptr pc) {\n   if (!thr->is_inited)  // May happen during bootstrap.\n-    return 0;\n+    return kInvalidStackID;\n   if (pc != 0) {\n #if !SANITIZER_GO\n     DCHECK_LT(thr->shadow_stack_pos, thr->shadow_stack_end);\n@@ -602,13 +558,195 @@ u32 CurrentStackId(ThreadState *thr, uptr pc) {\n     thr->shadow_stack_pos[0] = pc;\n     thr->shadow_stack_pos++;\n   }\n-  u32 id = StackDepotPut(\n+  StackID id = StackDepotPut(\n       StackTrace(thr->shadow_stack, thr->shadow_stack_pos - thr->shadow_stack));\n   if (pc != 0)\n     thr->shadow_stack_pos--;\n   return id;\n }\n \n+namespace v3 {\n+\n+ALWAYS_INLINE USED bool TryTraceMemoryAccess(ThreadState *thr, uptr pc,\n+                                             uptr addr, uptr size,\n+                                             AccessType typ) {\n+  DCHECK(size == 1 || size == 2 || size == 4 || size == 8);\n+  if (!kCollectHistory)\n+    return true;\n+  EventAccess *ev;\n+  if (UNLIKELY(!TraceAcquire(thr, &ev)))\n+    return false;\n+  u64 size_log = size == 1 ? 0 : size == 2 ? 1 : size == 4 ? 2 : 3;\n+  uptr pc_delta = pc - thr->trace_prev_pc + (1 << (EventAccess::kPCBits - 1));\n+  thr->trace_prev_pc = pc;\n+  if (LIKELY(pc_delta < (1 << EventAccess::kPCBits))) {\n+    ev->is_access = 1;\n+    ev->is_read = !!(typ & kAccessRead);\n+    ev->is_atomic = !!(typ & kAccessAtomic);\n+    ev->size_log = size_log;\n+    ev->pc_delta = pc_delta;\n+    DCHECK_EQ(ev->pc_delta, pc_delta);\n+    ev->addr = CompressAddr(addr);\n+    TraceRelease(thr, ev);\n+    return true;\n+  }\n+  auto *evex = reinterpret_cast<EventAccessExt *>(ev);\n+  evex->is_access = 0;\n+  evex->is_func = 0;\n+  evex->type = EventType::kAccessExt;\n+  evex->is_read = !!(typ & kAccessRead);\n+  evex->is_atomic = !!(typ & kAccessAtomic);\n+  evex->size_log = size_log;\n+  evex->addr = CompressAddr(addr);\n+  evex->pc = pc;\n+  TraceRelease(thr, evex);\n+  return true;\n+}\n+\n+ALWAYS_INLINE USED bool TryTraceMemoryAccessRange(ThreadState *thr, uptr pc,\n+                                                  uptr addr, uptr size,\n+                                                  AccessType typ) {\n+  if (!kCollectHistory)\n+    return true;\n+  EventAccessRange *ev;\n+  if (UNLIKELY(!TraceAcquire(thr, &ev)))\n+    return false;\n+  thr->trace_prev_pc = pc;\n+  ev->is_access = 0;\n+  ev->is_func = 0;\n+  ev->type = EventType::kAccessRange;\n+  ev->is_read = !!(typ & kAccessRead);\n+  ev->is_free = !!(typ & kAccessFree);\n+  ev->size_lo = size;\n+  ev->pc = CompressAddr(pc);\n+  ev->addr = CompressAddr(addr);\n+  ev->size_hi = size >> EventAccessRange::kSizeLoBits;\n+  TraceRelease(thr, ev);\n+  return true;\n+}\n+\n+void TraceMemoryAccessRange(ThreadState *thr, uptr pc, uptr addr, uptr size,\n+                            AccessType typ) {\n+  if (LIKELY(TryTraceMemoryAccessRange(thr, pc, addr, size, typ)))\n+    return;\n+  TraceSwitchPart(thr);\n+  UNUSED bool res = TryTraceMemoryAccessRange(thr, pc, addr, size, typ);\n+  DCHECK(res);\n+}\n+\n+void TraceFunc(ThreadState *thr, uptr pc) {\n+  if (LIKELY(TryTraceFunc(thr, pc)))\n+    return;\n+  TraceSwitchPart(thr);\n+  UNUSED bool res = TryTraceFunc(thr, pc);\n+  DCHECK(res);\n+}\n+\n+void TraceMutexLock(ThreadState *thr, EventType type, uptr pc, uptr addr,\n+                    StackID stk) {\n+  DCHECK(type == EventType::kLock || type == EventType::kRLock);\n+  if (!kCollectHistory)\n+    return;\n+  EventLock ev;\n+  ev.is_access = 0;\n+  ev.is_func = 0;\n+  ev.type = type;\n+  ev.pc = CompressAddr(pc);\n+  ev.stack_lo = stk;\n+  ev.stack_hi = stk >> EventLock::kStackIDLoBits;\n+  ev._ = 0;\n+  ev.addr = CompressAddr(addr);\n+  TraceEvent(thr, ev);\n+}\n+\n+void TraceMutexUnlock(ThreadState *thr, uptr addr) {\n+  if (!kCollectHistory)\n+    return;\n+  EventUnlock ev;\n+  ev.is_access = 0;\n+  ev.is_func = 0;\n+  ev.type = EventType::kUnlock;\n+  ev._ = 0;\n+  ev.addr = CompressAddr(addr);\n+  TraceEvent(thr, ev);\n+}\n+\n+void TraceTime(ThreadState *thr) {\n+  if (!kCollectHistory)\n+    return;\n+  EventTime ev;\n+  ev.is_access = 0;\n+  ev.is_func = 0;\n+  ev.type = EventType::kTime;\n+  ev.sid = static_cast<u64>(thr->sid);\n+  ev.epoch = static_cast<u64>(thr->epoch);\n+  ev._ = 0;\n+  TraceEvent(thr, ev);\n+}\n+\n+NOINLINE\n+void TraceSwitchPart(ThreadState *thr) {\n+  Trace *trace = &thr->tctx->trace;\n+  Event *pos = reinterpret_cast<Event *>(atomic_load_relaxed(&thr->trace_pos));\n+  DCHECK_EQ(reinterpret_cast<uptr>(pos + 1) & TracePart::kAlignment, 0);\n+  auto *part = trace->parts.Back();\n+  DPrintf(\"TraceSwitchPart part=%p pos=%p\\n\", part, pos);\n+  if (part) {\n+    // We can get here when we still have space in the current trace part.\n+    // The fast-path check in TraceAcquire has false positives in the middle of\n+    // the part. Check if we are indeed at the end of the current part or not,\n+    // and fill any gaps with NopEvent's.\n+    Event *end = &part->events[TracePart::kSize];\n+    DCHECK_GE(pos, &part->events[0]);\n+    DCHECK_LE(pos, end);\n+    if (pos + 1 < end) {\n+      if ((reinterpret_cast<uptr>(pos) & TracePart::kAlignment) ==\n+          TracePart::kAlignment)\n+        *pos++ = NopEvent;\n+      *pos++ = NopEvent;\n+      DCHECK_LE(pos + 2, end);\n+      atomic_store_relaxed(&thr->trace_pos, reinterpret_cast<uptr>(pos));\n+      // Ensure we setup trace so that the next TraceAcquire\n+      // won't detect trace part end.\n+      Event *ev;\n+      CHECK(TraceAcquire(thr, &ev));\n+      return;\n+    }\n+    // We are indeed at the end.\n+    for (; pos < end; pos++) *pos = NopEvent;\n+  }\n+#if !SANITIZER_GO\n+  if (ctx->after_multithreaded_fork) {\n+    // We just need to survive till exec.\n+    CHECK(part);\n+    atomic_store_relaxed(&thr->trace_pos,\n+                         reinterpret_cast<uptr>(&part->events[0]));\n+    return;\n+  }\n+#endif\n+  part = new (MmapOrDie(sizeof(TracePart), \"TracePart\")) TracePart();\n+  part->trace = trace;\n+  thr->trace_prev_pc = 0;\n+  {\n+    Lock lock(&trace->mtx);\n+    trace->parts.PushBack(part);\n+    atomic_store_relaxed(&thr->trace_pos,\n+                         reinterpret_cast<uptr>(&part->events[0]));\n+  }\n+  // Make this part self-sufficient by restoring the current stack\n+  // and mutex set in the beginning of the trace.\n+  TraceTime(thr);\n+  for (uptr *pos = &thr->shadow_stack[0]; pos < thr->shadow_stack_pos; pos++)\n+    CHECK(TryTraceFunc(thr, *pos));\n+  for (uptr i = 0; i < thr->mset.Size(); i++) {\n+    MutexSet::Desc d = thr->mset.Get(i);\n+    TraceMutexLock(thr, d.write ? EventType::kLock : EventType::kRLock, 0,\n+                   d.addr, d.stack_id);\n+  }\n+}\n+\n+}  // namespace v3\n+\n void TraceSwitch(ThreadState *thr) {\n #if !SANITIZER_GO\n   if (ctx->after_multithreaded_fork)\n@@ -625,9 +763,7 @@ void TraceSwitch(ThreadState *thr) {\n   thr->nomalloc--;\n }\n \n-Trace *ThreadTrace(int tid) {\n-  return (Trace*)GetThreadTraceHeader(tid);\n-}\n+Trace *ThreadTrace(Tid tid) { return (Trace *)GetThreadTraceHeader(tid); }\n \n uptr TraceTopPC(ThreadState *thr) {\n   Event *events = (Event*)GetThreadTrace(thr->tid);\n@@ -716,28 +852,28 @@ void MemoryAccessImpl1(ThreadState *thr, uptr addr,\n   // threads, which is not enough for the unrolled loop.\n #if SANITIZER_DEBUG\n   for (int idx = 0; idx < 4; idx++) {\n-#include \"tsan_update_shadow_word_inl.h\"\n+#  include \"tsan_update_shadow_word.inc\"\n   }\n #else\n   int idx = 0;\n-#include \"tsan_update_shadow_word_inl.h\"\n+#  include \"tsan_update_shadow_word.inc\"\n   idx = 1;\n   if (stored) {\n-#include \"tsan_update_shadow_word_inl.h\"\n+#  include \"tsan_update_shadow_word.inc\"\n   } else {\n-#include \"tsan_update_shadow_word_inl.h\"\n+#  include \"tsan_update_shadow_word.inc\"\n   }\n   idx = 2;\n   if (stored) {\n-#include \"tsan_update_shadow_word_inl.h\"\n+#  include \"tsan_update_shadow_word.inc\"\n   } else {\n-#include \"tsan_update_shadow_word_inl.h\"\n+#  include \"tsan_update_shadow_word.inc\"\n   }\n   idx = 3;\n   if (stored) {\n-#include \"tsan_update_shadow_word_inl.h\"\n+#  include \"tsan_update_shadow_word.inc\"\n   } else {\n-#include \"tsan_update_shadow_word_inl.h\"\n+#  include \"tsan_update_shadow_word.inc\"\n   }\n #endif\n \n@@ -753,8 +889,11 @@ void MemoryAccessImpl1(ThreadState *thr, uptr addr,\n   return;\n }\n \n-void UnalignedMemoryAccess(ThreadState *thr, uptr pc, uptr addr,\n-    int size, bool kAccessIsWrite, bool kIsAtomic) {\n+void UnalignedMemoryAccess(ThreadState *thr, uptr pc, uptr addr, uptr size,\n+                           AccessType typ) {\n+  DCHECK(!(typ & kAccessAtomic));\n+  const bool kAccessIsWrite = !(typ & kAccessRead);\n+  const bool kIsAtomic = false;\n   while (size) {\n     int size1 = 1;\n     int kAccessSizeLog = kSizeLog1;\n@@ -789,10 +928,11 @@ bool ContainsSameAccessSlow(u64 *s, u64 a, u64 sync_epoch, bool is_write) {\n   return false;\n }\n \n-#if defined(__SSE3__)\n-#define SHUF(v0, v1, i0, i1, i2, i3) _mm_castps_si128(_mm_shuffle_ps( \\\n-    _mm_castsi128_ps(v0), _mm_castsi128_ps(v1), \\\n-    (i0)*1 + (i1)*4 + (i2)*16 + (i3)*64))\n+#if TSAN_VECTORIZE\n+#  define SHUF(v0, v1, i0, i1, i2, i3)                    \\\n+    _mm_castps_si128(_mm_shuffle_ps(_mm_castsi128_ps(v0), \\\n+                                    _mm_castsi128_ps(v1), \\\n+                                    (i0)*1 + (i1)*4 + (i2)*16 + (i3)*64))\n ALWAYS_INLINE\n bool ContainsSameAccessFast(u64 *s, u64 a, u64 sync_epoch, bool is_write) {\n   // This is an optimized version of ContainsSameAccessSlow.\n@@ -849,7 +989,7 @@ bool ContainsSameAccessFast(u64 *s, u64 a, u64 sync_epoch, bool is_write) {\n \n ALWAYS_INLINE\n bool ContainsSameAccess(u64 *s, u64 a, u64 sync_epoch, bool is_write) {\n-#if defined(__SSE3__)\n+#if TSAN_VECTORIZE\n   bool res = ContainsSameAccessFast(s, a, sync_epoch, is_write);\n   // NOTE: this check can fail if the shadow is concurrently mutated\n   // by other threads. But it still can be useful if you modify\n@@ -864,7 +1004,7 @@ bool ContainsSameAccess(u64 *s, u64 a, u64 sync_epoch, bool is_write) {\n ALWAYS_INLINE USED\n void MemoryAccess(ThreadState *thr, uptr pc, uptr addr,\n     int kAccessSizeLog, bool kAccessIsWrite, bool kIsAtomic) {\n-  u64 *shadow_mem = (u64*)MemToShadow(addr);\n+  RawShadow *shadow_mem = MemToShadow(addr);\n   DPrintf2(\"#%d: MemoryAccess: @%p %p size=%d\"\n       \" is_write=%d shadow_mem=%p {%zx, %zx, %zx, %zx}\\n\",\n       (int)thr->fast_state.tid(), (void*)pc, (void*)addr,\n@@ -876,9 +1016,9 @@ void MemoryAccess(ThreadState *thr, uptr pc, uptr addr,\n     Printf(\"Access to non app mem %zx\\n\", addr);\n     DCHECK(IsAppMem(addr));\n   }\n-  if (!IsShadowMem((uptr)shadow_mem)) {\n+  if (!IsShadowMem(shadow_mem)) {\n     Printf(\"Bad shadow addr %p (%zx)\\n\", shadow_mem, addr);\n-    DCHECK(IsShadowMem((uptr)shadow_mem));\n+    DCHECK(IsShadowMem(shadow_mem));\n   }\n #endif\n \n@@ -953,9 +1093,9 @@ static void MemoryRangeSet(ThreadState *thr, uptr pc, uptr addr, uptr size,\n   size = (size + (kShadowCell - 1)) & ~(kShadowCell - 1);\n   // UnmapOrDie/MmapFixedNoReserve does not work on Windows.\n   if (SANITIZER_WINDOWS || size < common_flags()->clear_shadow_mmap_threshold) {\n-    u64 *p = (u64*)MemToShadow(addr);\n-    CHECK(IsShadowMem((uptr)p));\n-    CHECK(IsShadowMem((uptr)(p + size * kShadowCnt / kShadowCell - 1)));\n+    RawShadow *p = MemToShadow(addr);\n+    CHECK(IsShadowMem(p));\n+    CHECK(IsShadowMem(p + size * kShadowCnt / kShadowCell - 1));\n     // FIXME: may overwrite a part outside the region\n     for (uptr i = 0; i < size / kShadowCell * kShadowCnt;) {\n       p[i++] = val;\n@@ -965,17 +1105,17 @@ static void MemoryRangeSet(ThreadState *thr, uptr pc, uptr addr, uptr size,\n   } else {\n     // The region is big, reset only beginning and end.\n     const uptr kPageSize = GetPageSizeCached();\n-    u64 *begin = (u64*)MemToShadow(addr);\n-    u64 *end = begin + size / kShadowCell * kShadowCnt;\n-    u64 *p = begin;\n+    RawShadow *begin = MemToShadow(addr);\n+    RawShadow *end = begin + size / kShadowCell * kShadowCnt;\n+    RawShadow *p = begin;\n     // Set at least first kPageSize/2 to page boundary.\n     while ((p < begin + kPageSize / kShadowSize / 2) || ((uptr)p % kPageSize)) {\n       *p++ = val;\n       for (uptr j = 1; j < kShadowCnt; j++)\n         *p++ = 0;\n     }\n     // Reset middle part.\n-    u64 *p1 = p;\n+    RawShadow *p1 = p;\n     p = RoundDown(end, kPageSize);\n     if (!MmapFixedSuperNoReserve((uptr)p1, (uptr)p - (uptr)p1))\n       Die();\n@@ -1070,18 +1210,18 @@ void FuncExit(ThreadState *thr) {\n   thr->shadow_stack_pos--;\n }\n \n-void ThreadIgnoreBegin(ThreadState *thr, uptr pc, bool save_stack) {\n+void ThreadIgnoreBegin(ThreadState *thr, uptr pc) {\n   DPrintf(\"#%d: ThreadIgnoreBegin\\n\", thr->tid);\n   thr->ignore_reads_and_writes++;\n   CHECK_GT(thr->ignore_reads_and_writes, 0);\n   thr->fast_state.SetIgnoreBit();\n #if !SANITIZER_GO\n-  if (save_stack && !ctx->after_multithreaded_fork)\n+  if (pc && !ctx->after_multithreaded_fork)\n     thr->mop_ignore_set.Add(CurrentStackId(thr, pc));\n #endif\n }\n \n-void ThreadIgnoreEnd(ThreadState *thr, uptr pc) {\n+void ThreadIgnoreEnd(ThreadState *thr) {\n   DPrintf(\"#%d: ThreadIgnoreEnd\\n\", thr->tid);\n   CHECK_GT(thr->ignore_reads_and_writes, 0);\n   thr->ignore_reads_and_writes--;\n@@ -1101,17 +1241,17 @@ uptr __tsan_testonly_shadow_stack_current_size() {\n }\n #endif\n \n-void ThreadIgnoreSyncBegin(ThreadState *thr, uptr pc, bool save_stack) {\n+void ThreadIgnoreSyncBegin(ThreadState *thr, uptr pc) {\n   DPrintf(\"#%d: ThreadIgnoreSyncBegin\\n\", thr->tid);\n   thr->ignore_sync++;\n   CHECK_GT(thr->ignore_sync, 0);\n #if !SANITIZER_GO\n-  if (save_stack && !ctx->after_multithreaded_fork)\n+  if (pc && !ctx->after_multithreaded_fork)\n     thr->sync_ignore_set.Add(CurrentStackId(thr, pc));\n #endif\n }\n \n-void ThreadIgnoreSyncEnd(ThreadState *thr, uptr pc) {\n+void ThreadIgnoreSyncEnd(ThreadState *thr) {\n   DPrintf(\"#%d: ThreadIgnoreSyncEnd\\n\", thr->tid);\n   CHECK_GT(thr->ignore_sync, 0);\n   thr->ignore_sync--;\n@@ -1133,7 +1273,28 @@ void build_consistency_release() {}\n \n }  // namespace __tsan\n \n+#if SANITIZER_CHECK_DEADLOCKS\n+namespace __sanitizer {\n+using namespace __tsan;\n+MutexMeta mutex_meta[] = {\n+    {MutexInvalid, \"Invalid\", {}},\n+    {MutexThreadRegistry, \"ThreadRegistry\", {}},\n+    {MutexTypeTrace, \"Trace\", {MutexLeaf}},\n+    {MutexTypeReport, \"Report\", {MutexTypeSyncVar}},\n+    {MutexTypeSyncVar, \"SyncVar\", {}},\n+    {MutexTypeAnnotations, \"Annotations\", {}},\n+    {MutexTypeAtExit, \"AtExit\", {MutexTypeSyncVar}},\n+    {MutexTypeFired, \"Fired\", {MutexLeaf}},\n+    {MutexTypeRacy, \"Racy\", {MutexLeaf}},\n+    {MutexTypeGlobalProc, \"GlobalProc\", {}},\n+    {},\n+};\n+\n+void PrintMutexPC(uptr pc) { StackTrace(&pc, 1).Print(); }\n+}  // namespace __sanitizer\n+#endif\n+\n #if !SANITIZER_GO\n // Must be included in this file to make sure everything is inlined.\n-#include \"tsan_interface_inl.h\"\n+#  include \"tsan_interface.inc\"\n #endif"}, {"sha": "4f50656a1ea89e100e8a1db47824fff739d40e2a", "filename": "libsanitizer/tsan/tsan_rtl.h", "status": "modified", "additions": 194, "deletions": 305, "changes": 499, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_rtl.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_rtl.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_rtl.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -37,14 +37,15 @@\n #include \"tsan_clock.h\"\n #include \"tsan_defs.h\"\n #include \"tsan_flags.h\"\n+#include \"tsan_ignoreset.h\"\n #include \"tsan_mman.h\"\n-#include \"tsan_sync.h\"\n-#include \"tsan_trace.h\"\n-#include \"tsan_report.h\"\n-#include \"tsan_platform.h\"\n #include \"tsan_mutexset.h\"\n-#include \"tsan_ignoreset.h\"\n+#include \"tsan_platform.h\"\n+#include \"tsan_report.h\"\n+#include \"tsan_shadow.h\"\n #include \"tsan_stack_trace.h\"\n+#include \"tsan_sync.h\"\n+#include \"tsan_trace.h\"\n \n #if SANITIZER_WORDSIZE != 64\n # error \"ThreadSanitizer is supported only on 64-bit platforms\"\n@@ -69,6 +70,11 @@ struct AP32 {\n typedef SizeClassAllocator32<AP32> PrimaryAllocator;\n #else\n struct AP64 {  // Allocator64 parameters. Deliberately using a short name.\n+#    if defined(__s390x__)\n+  typedef MappingS390x Mapping;\n+#    else\n+  typedef Mapping48AddressSpace Mapping;\n+#    endif\n   static const uptr kSpaceBeg = Mapping::kHeapMemBeg;\n   static const uptr kSpaceSize = Mapping::kHeapMemEnd - Mapping::kHeapMemBeg;\n   static const uptr kMetadataSize = 0;\n@@ -84,240 +90,6 @@ typedef Allocator::AllocatorCache AllocatorCache;\n Allocator *allocator();\n #endif\n \n-const u64 kShadowRodata = (u64)-1;  // .rodata shadow marker\n-\n-// FastState (from most significant bit):\n-//   ignore          : 1\n-//   tid             : kTidBits\n-//   unused          : -\n-//   history_size    : 3\n-//   epoch           : kClkBits\n-class FastState {\n- public:\n-  FastState(u64 tid, u64 epoch) {\n-    x_ = tid << kTidShift;\n-    x_ |= epoch;\n-    DCHECK_EQ(tid, this->tid());\n-    DCHECK_EQ(epoch, this->epoch());\n-    DCHECK_EQ(GetIgnoreBit(), false);\n-  }\n-\n-  explicit FastState(u64 x)\n-      : x_(x) {\n-  }\n-\n-  u64 raw() const {\n-    return x_;\n-  }\n-\n-  u64 tid() const {\n-    u64 res = (x_ & ~kIgnoreBit) >> kTidShift;\n-    return res;\n-  }\n-\n-  u64 TidWithIgnore() const {\n-    u64 res = x_ >> kTidShift;\n-    return res;\n-  }\n-\n-  u64 epoch() const {\n-    u64 res = x_ & ((1ull << kClkBits) - 1);\n-    return res;\n-  }\n-\n-  void IncrementEpoch() {\n-    u64 old_epoch = epoch();\n-    x_ += 1;\n-    DCHECK_EQ(old_epoch + 1, epoch());\n-    (void)old_epoch;\n-  }\n-\n-  void SetIgnoreBit() { x_ |= kIgnoreBit; }\n-  void ClearIgnoreBit() { x_ &= ~kIgnoreBit; }\n-  bool GetIgnoreBit() const { return (s64)x_ < 0; }\n-\n-  void SetHistorySize(int hs) {\n-    CHECK_GE(hs, 0);\n-    CHECK_LE(hs, 7);\n-    x_ = (x_ & ~(kHistoryMask << kHistoryShift)) | (u64(hs) << kHistoryShift);\n-  }\n-\n-  ALWAYS_INLINE\n-  int GetHistorySize() const {\n-    return (int)((x_ >> kHistoryShift) & kHistoryMask);\n-  }\n-\n-  void ClearHistorySize() {\n-    SetHistorySize(0);\n-  }\n-\n-  ALWAYS_INLINE\n-  u64 GetTracePos() const {\n-    const int hs = GetHistorySize();\n-    // When hs == 0, the trace consists of 2 parts.\n-    const u64 mask = (1ull << (kTracePartSizeBits + hs + 1)) - 1;\n-    return epoch() & mask;\n-  }\n-\n- private:\n-  friend class Shadow;\n-  static const int kTidShift = 64 - kTidBits - 1;\n-  static const u64 kIgnoreBit = 1ull << 63;\n-  static const u64 kFreedBit = 1ull << 63;\n-  static const u64 kHistoryShift = kClkBits;\n-  static const u64 kHistoryMask = 7;\n-  u64 x_;\n-};\n-\n-// Shadow (from most significant bit):\n-//   freed           : 1\n-//   tid             : kTidBits\n-//   is_atomic       : 1\n-//   is_read         : 1\n-//   size_log        : 2\n-//   addr0           : 3\n-//   epoch           : kClkBits\n-class Shadow : public FastState {\n- public:\n-  explicit Shadow(u64 x)\n-      : FastState(x) {\n-  }\n-\n-  explicit Shadow(const FastState &s)\n-      : FastState(s.x_) {\n-    ClearHistorySize();\n-  }\n-\n-  void SetAddr0AndSizeLog(u64 addr0, unsigned kAccessSizeLog) {\n-    DCHECK_EQ((x_ >> kClkBits) & 31, 0);\n-    DCHECK_LE(addr0, 7);\n-    DCHECK_LE(kAccessSizeLog, 3);\n-    x_ |= ((kAccessSizeLog << 3) | addr0) << kClkBits;\n-    DCHECK_EQ(kAccessSizeLog, size_log());\n-    DCHECK_EQ(addr0, this->addr0());\n-  }\n-\n-  void SetWrite(unsigned kAccessIsWrite) {\n-    DCHECK_EQ(x_ & kReadBit, 0);\n-    if (!kAccessIsWrite)\n-      x_ |= kReadBit;\n-    DCHECK_EQ(kAccessIsWrite, IsWrite());\n-  }\n-\n-  void SetAtomic(bool kIsAtomic) {\n-    DCHECK(!IsAtomic());\n-    if (kIsAtomic)\n-      x_ |= kAtomicBit;\n-    DCHECK_EQ(IsAtomic(), kIsAtomic);\n-  }\n-\n-  bool IsAtomic() const {\n-    return x_ & kAtomicBit;\n-  }\n-\n-  bool IsZero() const {\n-    return x_ == 0;\n-  }\n-\n-  static inline bool TidsAreEqual(const Shadow s1, const Shadow s2) {\n-    u64 shifted_xor = (s1.x_ ^ s2.x_) >> kTidShift;\n-    DCHECK_EQ(shifted_xor == 0, s1.TidWithIgnore() == s2.TidWithIgnore());\n-    return shifted_xor == 0;\n-  }\n-\n-  static ALWAYS_INLINE\n-  bool Addr0AndSizeAreEqual(const Shadow s1, const Shadow s2) {\n-    u64 masked_xor = ((s1.x_ ^ s2.x_) >> kClkBits) & 31;\n-    return masked_xor == 0;\n-  }\n-\n-  static ALWAYS_INLINE bool TwoRangesIntersect(Shadow s1, Shadow s2,\n-      unsigned kS2AccessSize) {\n-    bool res = false;\n-    u64 diff = s1.addr0() - s2.addr0();\n-    if ((s64)diff < 0) {  // s1.addr0 < s2.addr0\n-      // if (s1.addr0() + size1) > s2.addr0()) return true;\n-      if (s1.size() > -diff)\n-        res = true;\n-    } else {\n-      // if (s2.addr0() + kS2AccessSize > s1.addr0()) return true;\n-      if (kS2AccessSize > diff)\n-        res = true;\n-    }\n-    DCHECK_EQ(res, TwoRangesIntersectSlow(s1, s2));\n-    DCHECK_EQ(res, TwoRangesIntersectSlow(s2, s1));\n-    return res;\n-  }\n-\n-  u64 ALWAYS_INLINE addr0() const { return (x_ >> kClkBits) & 7; }\n-  u64 ALWAYS_INLINE size() const { return 1ull << size_log(); }\n-  bool ALWAYS_INLINE IsWrite() const { return !IsRead(); }\n-  bool ALWAYS_INLINE IsRead() const { return x_ & kReadBit; }\n-\n-  // The idea behind the freed bit is as follows.\n-  // When the memory is freed (or otherwise unaccessible) we write to the shadow\n-  // values with tid/epoch related to the free and the freed bit set.\n-  // During memory accesses processing the freed bit is considered\n-  // as msb of tid. So any access races with shadow with freed bit set\n-  // (it is as if write from a thread with which we never synchronized before).\n-  // This allows us to detect accesses to freed memory w/o additional\n-  // overheads in memory access processing and at the same time restore\n-  // tid/epoch of free.\n-  void MarkAsFreed() {\n-     x_ |= kFreedBit;\n-  }\n-\n-  bool IsFreed() const {\n-    return x_ & kFreedBit;\n-  }\n-\n-  bool GetFreedAndReset() {\n-    bool res = x_ & kFreedBit;\n-    x_ &= ~kFreedBit;\n-    return res;\n-  }\n-\n-  bool ALWAYS_INLINE IsBothReadsOrAtomic(bool kIsWrite, bool kIsAtomic) const {\n-    bool v = x_ & ((u64(kIsWrite ^ 1) << kReadShift)\n-        | (u64(kIsAtomic) << kAtomicShift));\n-    DCHECK_EQ(v, (!IsWrite() && !kIsWrite) || (IsAtomic() && kIsAtomic));\n-    return v;\n-  }\n-\n-  bool ALWAYS_INLINE IsRWNotWeaker(bool kIsWrite, bool kIsAtomic) const {\n-    bool v = ((x_ >> kReadShift) & 3)\n-        <= u64((kIsWrite ^ 1) | (kIsAtomic << 1));\n-    DCHECK_EQ(v, (IsAtomic() < kIsAtomic) ||\n-        (IsAtomic() == kIsAtomic && !IsWrite() <= !kIsWrite));\n-    return v;\n-  }\n-\n-  bool ALWAYS_INLINE IsRWWeakerOrEqual(bool kIsWrite, bool kIsAtomic) const {\n-    bool v = ((x_ >> kReadShift) & 3)\n-        >= u64((kIsWrite ^ 1) | (kIsAtomic << 1));\n-    DCHECK_EQ(v, (IsAtomic() > kIsAtomic) ||\n-        (IsAtomic() == kIsAtomic && !IsWrite() >= !kIsWrite));\n-    return v;\n-  }\n-\n- private:\n-  static const u64 kReadShift   = 5 + kClkBits;\n-  static const u64 kReadBit     = 1ull << kReadShift;\n-  static const u64 kAtomicShift = 6 + kClkBits;\n-  static const u64 kAtomicBit   = 1ull << kAtomicShift;\n-\n-  u64 size_log() const { return (x_ >> (3 + kClkBits)) & 3; }\n-\n-  static bool TwoRangesIntersectSlow(const Shadow s1, const Shadow s2) {\n-    if (s1.addr0() == s2.addr0()) return true;\n-    if (s1.addr0() < s2.addr0() && s1.addr0() + s1.size() > s2.addr0())\n-      return true;\n-    if (s2.addr0() < s1.addr0() && s2.addr0() + s2.size() > s1.addr0())\n-      return true;\n-    return false;\n-  }\n-};\n-\n struct ThreadSignalContext;\n \n struct JmpBuf {\n@@ -380,27 +152,30 @@ struct ThreadState {\n   // We do not distinguish beteween ignoring reads and writes\n   // for better performance.\n   int ignore_reads_and_writes;\n+  atomic_sint32_t pending_signals;\n   int ignore_sync;\n   int suppress_reports;\n   // Go does not support ignores.\n #if !SANITIZER_GO\n   IgnoreSet mop_ignore_set;\n   IgnoreSet sync_ignore_set;\n-#endif\n-  // C/C++ uses fixed size shadow stack embed into Trace.\n+  // C/C++ uses fixed size shadow stack.\n+  uptr shadow_stack[kShadowStackSize];\n+#else\n   // Go uses malloc-allocated shadow stack with dynamic size.\n   uptr *shadow_stack;\n+#endif\n   uptr *shadow_stack_end;\n   uptr *shadow_stack_pos;\n-  u64 *racy_shadow_addr;\n-  u64 racy_state[2];\n+  RawShadow *racy_shadow_addr;\n+  RawShadow racy_state[2];\n   MutexSet mset;\n   ThreadClock clock;\n #if !SANITIZER_GO\n   Vector<JmpBuf> jmp_bufs;\n   int ignore_interceptors;\n #endif\n-  const u32 tid;\n+  const Tid tid;\n   const int unique_id;\n   bool in_symbolizer;\n   bool in_ignored_lib;\n@@ -414,9 +189,6 @@ struct ThreadState {\n   const uptr tls_size;\n   ThreadContext *tctx;\n \n-#if SANITIZER_DEBUG && !SANITIZER_GO\n-  InternalDeadlockDetector internal_deadlock_detector;\n-#endif\n   DDLogicalThread *dd_lt;\n \n   // Current wired Processor, or nullptr. Required to handle any events.\n@@ -431,7 +203,7 @@ struct ThreadState {\n   ThreadSignalContext *signal_ctx;\n \n #if !SANITIZER_GO\n-  u32 last_sleep_stack_id;\n+  StackID last_sleep_stack_id;\n   ThreadClock last_sleep_clock;\n #endif\n \n@@ -441,10 +213,17 @@ struct ThreadState {\n \n   const ReportDesc *current_report;\n \n-  explicit ThreadState(Context *ctx, u32 tid, int unique_id, u64 epoch,\n+  // Current position in tctx->trace.Back()->events (Event*).\n+  atomic_uintptr_t trace_pos;\n+  // PC of the last memory access, used to compute PC deltas in the trace.\n+  uptr trace_prev_pc;\n+  Sid sid;\n+  Epoch epoch;\n+\n+  explicit ThreadState(Context *ctx, Tid tid, int unique_id, u64 epoch,\n                        unsigned reuse_count, uptr stk_addr, uptr stk_size,\n                        uptr tls_addr, uptr tls_size);\n-};\n+} ALIGNED(SANITIZER_CACHE_LINE_SIZE);\n \n #if !SANITIZER_GO\n #if SANITIZER_MAC || SANITIZER_ANDROID\n@@ -472,17 +251,19 @@ inline void cur_thread_finalize() { }\n \n class ThreadContext final : public ThreadContextBase {\n  public:\n-  explicit ThreadContext(int tid);\n+  explicit ThreadContext(Tid tid);\n   ~ThreadContext();\n   ThreadState *thr;\n-  u32 creation_stack_id;\n+  StackID creation_stack_id;\n   SyncClock sync;\n   // Epoch at which the thread had started.\n   // If we see an event from the thread stamped by an older epoch,\n   // the event is from a dead thread that shared tid with this thread.\n   u64 epoch0;\n   u64 epoch1;\n \n+  v3::Trace trace;\n+\n   // Override superclass callbacks.\n   void OnDead() override;\n   void OnJoined(void *arg) override;\n@@ -495,13 +276,7 @@ class ThreadContext final : public ThreadContextBase {\n \n struct RacyStacks {\n   MD5Hash hash[2];\n-  bool operator==(const RacyStacks &other) const {\n-    if (hash[0] == other.hash[0] && hash[1] == other.hash[1])\n-      return true;\n-    if (hash[0] == other.hash[1] && hash[1] == other.hash[0])\n-      return true;\n-    return false;\n-  }\n+  bool operator==(const RacyStacks &other) const;\n };\n \n struct RacyAddress {\n@@ -527,13 +302,12 @@ struct Context {\n \n   Mutex report_mtx;\n   int nreported;\n-  int nmissed_expected;\n   atomic_uint64_t last_symbolize_time_ns;\n \n   void *background_thread;\n   atomic_uint32_t stop_background_thread;\n \n-  ThreadRegistry *thread_registry;\n+  ThreadRegistry thread_registry;\n \n   Mutex racy_mtx;\n   Vector<RacyStacks> racy_stacks;\n@@ -546,9 +320,9 @@ struct Context {\n   ClockAlloc clock_alloc;\n \n   Flags flags;\n+  fd_t memprof_fd;\n \n-  u64 int_alloc_cnt[MBlockTypeCount];\n-  u64 int_alloc_siz[MBlockTypeCount];\n+  Mutex slot_mtx;\n };\n \n extern Context *ctx;  // The one and the only global runtime context.\n@@ -581,12 +355,12 @@ class ScopedReportBase {\n                        const MutexSet *mset);\n   void AddStack(StackTrace stack, bool suppressable = false);\n   void AddThread(const ThreadContext *tctx, bool suppressable = false);\n-  void AddThread(int unique_tid, bool suppressable = false);\n-  void AddUniqueTid(int unique_tid);\n+  void AddThread(Tid unique_tid, bool suppressable = false);\n+  void AddUniqueTid(Tid unique_tid);\n   void AddMutex(const SyncVar *s);\n   u64 AddMutex(u64 id);\n   void AddLocation(uptr addr, uptr size);\n-  void AddSleep(u32 stack_id);\n+  void AddSleep(StackID stack_id);\n   void SetCount(int count);\n \n   const ReportDesc *GetReport() const;\n@@ -618,7 +392,7 @@ class ScopedReport : public ScopedReportBase {\n \n bool ShouldReport(ThreadState *thr, ReportType typ);\n ThreadContext *IsThreadStackOrTls(uptr addr, bool *is_stack);\n-void RestoreStack(int tid, const u64 epoch, VarSizeStackTrace *stk,\n+void RestoreStack(Tid tid, const u64 epoch, VarSizeStackTrace *stk,\n                   MutexSet *mset, uptr *tag = nullptr);\n \n // The stack could look like:\n@@ -671,7 +445,6 @@ void ReportRace(ThreadState *thr);\n bool OutputReport(ThreadState *thr, const ScopedReport &srep);\n bool IsFiredSuppression(Context *ctx, ReportType type, StackTrace trace);\n bool IsExpectedReport(uptr addr, uptr size);\n-void PrintMatchedBenignRaces();\n \n #if defined(TSAN_DEBUG_OUTPUT) && TSAN_DEBUG_OUTPUT >= 1\n # define DPrintf Printf\n@@ -685,10 +458,11 @@ void PrintMatchedBenignRaces();\n # define DPrintf2(...)\n #endif\n \n-u32 CurrentStackId(ThreadState *thr, uptr pc);\n-ReportStack *SymbolizeStackId(u32 stack_id);\n+StackID CurrentStackId(ThreadState *thr, uptr pc);\n+ReportStack *SymbolizeStackId(StackID stack_id);\n void PrintCurrentStack(ThreadState *thr, uptr pc);\n void PrintCurrentStackSlow(uptr pc);  // uses libunwind\n+MBlock *JavaHeapBlock(uptr addr, uptr *start);\n \n void Initialize(ThreadState *thr);\n void MaybeSpawnBackgroundThread();\n@@ -704,34 +478,44 @@ void MemoryAccessImpl(ThreadState *thr, uptr addr,\n     u64 *shadow_mem, Shadow cur);\n void MemoryAccessRange(ThreadState *thr, uptr pc, uptr addr,\n     uptr size, bool is_write);\n-void MemoryAccessRangeStep(ThreadState *thr, uptr pc, uptr addr,\n-    uptr size, uptr step, bool is_write);\n-void UnalignedMemoryAccess(ThreadState *thr, uptr pc, uptr addr,\n-    int size, bool kAccessIsWrite, bool kIsAtomic);\n+void UnalignedMemoryAccess(ThreadState *thr, uptr pc, uptr addr, uptr size,\n+                           AccessType typ);\n \n const int kSizeLog1 = 0;\n const int kSizeLog2 = 1;\n const int kSizeLog4 = 2;\n const int kSizeLog8 = 3;\n \n-void ALWAYS_INLINE MemoryRead(ThreadState *thr, uptr pc,\n-                                     uptr addr, int kAccessSizeLog) {\n-  MemoryAccess(thr, pc, addr, kAccessSizeLog, false, false);\n-}\n-\n-void ALWAYS_INLINE MemoryWrite(ThreadState *thr, uptr pc,\n-                                      uptr addr, int kAccessSizeLog) {\n-  MemoryAccess(thr, pc, addr, kAccessSizeLog, true, false);\n-}\n-\n-void ALWAYS_INLINE MemoryReadAtomic(ThreadState *thr, uptr pc,\n-                                           uptr addr, int kAccessSizeLog) {\n-  MemoryAccess(thr, pc, addr, kAccessSizeLog, false, true);\n-}\n-\n-void ALWAYS_INLINE MemoryWriteAtomic(ThreadState *thr, uptr pc,\n-                                            uptr addr, int kAccessSizeLog) {\n-  MemoryAccess(thr, pc, addr, kAccessSizeLog, true, true);\n+ALWAYS_INLINE\n+void MemoryAccess(ThreadState *thr, uptr pc, uptr addr, uptr size,\n+                  AccessType typ) {\n+  int size_log;\n+  switch (size) {\n+    case 1:\n+      size_log = kSizeLog1;\n+      break;\n+    case 2:\n+      size_log = kSizeLog2;\n+      break;\n+    case 4:\n+      size_log = kSizeLog4;\n+      break;\n+    default:\n+      DCHECK_EQ(size, 8);\n+      size_log = kSizeLog8;\n+      break;\n+  }\n+  bool is_write = !(typ & kAccessRead);\n+  bool is_atomic = typ & kAccessAtomic;\n+  if (typ & kAccessVptr)\n+    thr->is_vptr_access = true;\n+  if (typ & kAccessFree)\n+    thr->is_freeing = true;\n+  MemoryAccess(thr, pc, addr, size_log, is_write, is_atomic);\n+  if (typ & kAccessVptr)\n+    thr->is_vptr_access = false;\n+  if (typ & kAccessFree)\n+    thr->is_freeing = false;\n }\n \n void MemoryResetRange(ThreadState *thr, uptr pc, uptr addr, uptr size);\n@@ -740,26 +524,26 @@ void MemoryRangeImitateWrite(ThreadState *thr, uptr pc, uptr addr, uptr size);\n void MemoryRangeImitateWriteOrResetRange(ThreadState *thr, uptr pc, uptr addr,\n                                          uptr size);\n \n-void ThreadIgnoreBegin(ThreadState *thr, uptr pc, bool save_stack = true);\n-void ThreadIgnoreEnd(ThreadState *thr, uptr pc);\n-void ThreadIgnoreSyncBegin(ThreadState *thr, uptr pc, bool save_stack = true);\n-void ThreadIgnoreSyncEnd(ThreadState *thr, uptr pc);\n+void ThreadIgnoreBegin(ThreadState *thr, uptr pc);\n+void ThreadIgnoreEnd(ThreadState *thr);\n+void ThreadIgnoreSyncBegin(ThreadState *thr, uptr pc);\n+void ThreadIgnoreSyncEnd(ThreadState *thr);\n \n void FuncEntry(ThreadState *thr, uptr pc);\n void FuncExit(ThreadState *thr);\n \n-int ThreadCreate(ThreadState *thr, uptr pc, uptr uid, bool detached);\n-void ThreadStart(ThreadState *thr, int tid, tid_t os_id,\n+Tid ThreadCreate(ThreadState *thr, uptr pc, uptr uid, bool detached);\n+void ThreadStart(ThreadState *thr, Tid tid, tid_t os_id,\n                  ThreadType thread_type);\n void ThreadFinish(ThreadState *thr);\n-int ThreadConsumeTid(ThreadState *thr, uptr pc, uptr uid);\n-void ThreadJoin(ThreadState *thr, uptr pc, int tid);\n-void ThreadDetach(ThreadState *thr, uptr pc, int tid);\n+Tid ThreadConsumeTid(ThreadState *thr, uptr pc, uptr uid);\n+void ThreadJoin(ThreadState *thr, uptr pc, Tid tid);\n+void ThreadDetach(ThreadState *thr, uptr pc, Tid tid);\n void ThreadFinalize(ThreadState *thr);\n void ThreadSetName(ThreadState *thr, const char *name);\n int ThreadCount(ThreadState *thr);\n-void ProcessPendingSignals(ThreadState *thr);\n-void ThreadNotJoined(ThreadState *thr, uptr pc, int tid, uptr uid);\n+void ProcessPendingSignalsImpl(ThreadState *thr);\n+void ThreadNotJoined(ThreadState *thr, uptr pc, Tid tid, uptr uid);\n \n Processor *ProcCreate();\n void ProcDestroy(Processor *proc);\n@@ -788,7 +572,7 @@ void Acquire(ThreadState *thr, uptr pc, uptr addr);\n // handle Go finalizers. Namely, finalizer goroutine executes AcquireGlobal\n // right before executing finalizers. This provides a coarse, but simple\n // approximation of the actual required synchronization.\n-void AcquireGlobal(ThreadState *thr, uptr pc);\n+void AcquireGlobal(ThreadState *thr);\n void Release(ThreadState *thr, uptr pc, uptr addr);\n void ReleaseStoreAcquire(ThreadState *thr, uptr pc, uptr addr);\n void ReleaseStore(ThreadState *thr, uptr pc, uptr addr);\n@@ -824,7 +608,7 @@ void TraceSwitch(ThreadState *thr);\n uptr TraceTopPC(ThreadState *thr);\n uptr TraceSize();\n uptr TraceParts();\n-Trace *ThreadTrace(int tid);\n+Trace *ThreadTrace(Tid tid);\n \n extern \"C\" void __tsan_trace_switch();\n void ALWAYS_INLINE TraceAddEvent(ThreadState *thr, FastState fs,\n@@ -864,6 +648,111 @@ enum FiberSwitchFlags {\n   FiberSwitchFlagNoSync = 1 << 0, // __tsan_switch_to_fiber_no_sync\n };\n \n+ALWAYS_INLINE void ProcessPendingSignals(ThreadState *thr) {\n+  if (UNLIKELY(atomic_load_relaxed(&thr->pending_signals)))\n+    ProcessPendingSignalsImpl(thr);\n+}\n+\n+extern bool is_initialized;\n+\n+ALWAYS_INLINE\n+void LazyInitialize(ThreadState *thr) {\n+  // If we can use .preinit_array, assume that __tsan_init\n+  // called from .preinit_array initializes runtime before\n+  // any instrumented code.\n+#if !SANITIZER_CAN_USE_PREINIT_ARRAY\n+  if (UNLIKELY(!is_initialized))\n+    Initialize(thr);\n+#endif\n+}\n+\n+namespace v3 {\n+\n+void TraceSwitchPart(ThreadState *thr);\n+bool RestoreStack(Tid tid, EventType type, Sid sid, Epoch epoch, uptr addr,\n+                  uptr size, AccessType typ, VarSizeStackTrace *pstk,\n+                  MutexSet *pmset, uptr *ptag);\n+\n+template <typename EventT>\n+ALWAYS_INLINE WARN_UNUSED_RESULT bool TraceAcquire(ThreadState *thr,\n+                                                   EventT **ev) {\n+  Event *pos = reinterpret_cast<Event *>(atomic_load_relaxed(&thr->trace_pos));\n+#if SANITIZER_DEBUG\n+  // TraceSwitch acquires these mutexes,\n+  // so we lock them here to detect deadlocks more reliably.\n+  { Lock lock(&ctx->slot_mtx); }\n+  { Lock lock(&thr->tctx->trace.mtx); }\n+  TracePart *current = thr->tctx->trace.parts.Back();\n+  if (current) {\n+    DCHECK_GE(pos, &current->events[0]);\n+    DCHECK_LE(pos, &current->events[TracePart::kSize]);\n+  } else {\n+    DCHECK_EQ(pos, nullptr);\n+  }\n+#endif\n+  // TracePart is allocated with mmap and is at least 4K aligned.\n+  // So the following check is a faster way to check for part end.\n+  // It may have false positives in the middle of the trace,\n+  // they are filtered out in TraceSwitch.\n+  if (UNLIKELY(((uptr)(pos + 1) & TracePart::kAlignment) == 0))\n+    return false;\n+  *ev = reinterpret_cast<EventT *>(pos);\n+  return true;\n+}\n+\n+template <typename EventT>\n+ALWAYS_INLINE void TraceRelease(ThreadState *thr, EventT *evp) {\n+  DCHECK_LE(evp + 1, &thr->tctx->trace.parts.Back()->events[TracePart::kSize]);\n+  atomic_store_relaxed(&thr->trace_pos, (uptr)(evp + 1));\n+}\n+\n+template <typename EventT>\n+void TraceEvent(ThreadState *thr, EventT ev) {\n+  EventT *evp;\n+  if (!TraceAcquire(thr, &evp)) {\n+    TraceSwitchPart(thr);\n+    UNUSED bool res = TraceAcquire(thr, &evp);\n+    DCHECK(res);\n+  }\n+  *evp = ev;\n+  TraceRelease(thr, evp);\n+}\n+\n+ALWAYS_INLINE WARN_UNUSED_RESULT bool TryTraceFunc(ThreadState *thr,\n+                                                   uptr pc = 0) {\n+  if (!kCollectHistory)\n+    return true;\n+  EventFunc *ev;\n+  if (UNLIKELY(!TraceAcquire(thr, &ev)))\n+    return false;\n+  ev->is_access = 0;\n+  ev->is_func = 1;\n+  ev->pc = pc;\n+  TraceRelease(thr, ev);\n+  return true;\n+}\n+\n+WARN_UNUSED_RESULT\n+bool TryTraceMemoryAccess(ThreadState *thr, uptr pc, uptr addr, uptr size,\n+                          AccessType typ);\n+WARN_UNUSED_RESULT\n+bool TryTraceMemoryAccessRange(ThreadState *thr, uptr pc, uptr addr, uptr size,\n+                               AccessType typ);\n+void TraceMemoryAccessRange(ThreadState *thr, uptr pc, uptr addr, uptr size,\n+                            AccessType typ);\n+void TraceFunc(ThreadState *thr, uptr pc = 0);\n+void TraceMutexLock(ThreadState *thr, EventType type, uptr pc, uptr addr,\n+                    StackID stk);\n+void TraceMutexUnlock(ThreadState *thr, uptr addr);\n+void TraceTime(ThreadState *thr);\n+\n+}  // namespace v3\n+\n+#if !SANITIZER_GO\n+extern void (*on_initialize)(void);\n+extern int (*on_finalize)(int);\n+#endif\n+\n }  // namespace __tsan\n \n #endif  // TSAN_RTL_H"}, {"sha": "7d6b41116aa6f4a24977e344874dbb7bfe9688b9", "filename": "libsanitizer/tsan/tsan_rtl_mutex.cpp", "status": "modified", "additions": 214, "deletions": 205, "changes": 419, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_rtl_mutex.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_rtl_mutex.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_rtl_mutex.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -35,7 +35,7 @@ struct Callback final : public DDCallback {\n     DDCallback::lt = thr->dd_lt;\n   }\n \n-  u32 Unwind() override { return CurrentStackId(thr, pc); }\n+  StackID Unwind() override { return CurrentStackId(thr, pc); }\n   int UniqueTid() override { return thr->unique_id; }\n };\n \n@@ -53,7 +53,7 @@ static void ReportMutexMisuse(ThreadState *thr, uptr pc, ReportType typ,\n     return;\n   if (!ShouldReport(thr, typ))\n     return;\n-  ThreadRegistryLock l(ctx->thread_registry);\n+  ThreadRegistryLock l(&ctx->thread_registry);\n   ScopedReport rep(typ);\n   rep.AddMutex(mid);\n   VarSizeStackTrace trace;\n@@ -68,46 +68,49 @@ void MutexCreate(ThreadState *thr, uptr pc, uptr addr, u32 flagz) {\n   if (!(flagz & MutexFlagLinkerInit) && IsAppMem(addr)) {\n     CHECK(!thr->is_freeing);\n     thr->is_freeing = true;\n-    MemoryWrite(thr, pc, addr, kSizeLog1);\n+    MemoryAccess(thr, pc, addr, 1, kAccessWrite);\n     thr->is_freeing = false;\n   }\n-  SyncVar *s = ctx->metamap.GetOrCreateAndLock(thr, pc, addr, true);\n+  SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, addr, true);\n+  Lock l(&s->mtx);\n   s->SetFlags(flagz & MutexCreationFlagMask);\n+  // Save stack in the case the sync object was created before as atomic.\n   if (!SANITIZER_GO && s->creation_stack_id == 0)\n     s->creation_stack_id = CurrentStackId(thr, pc);\n-  s->mtx.Unlock();\n }\n \n void MutexDestroy(ThreadState *thr, uptr pc, uptr addr, u32 flagz) {\n   DPrintf(\"#%d: MutexDestroy %zx\\n\", thr->tid, addr);\n-  SyncVar *s = ctx->metamap.GetIfExistsAndLock(addr, true);\n-  if (s == 0)\n-    return;\n-  if ((flagz & MutexFlagLinkerInit)\n-      || s->IsFlagSet(MutexFlagLinkerInit)\n-      || ((flagz & MutexFlagNotStatic) && !s->IsFlagSet(MutexFlagNotStatic))) {\n-    // Destroy is no-op for linker-initialized mutexes.\n-    s->mtx.Unlock();\n-    return;\n-  }\n-  if (common_flags()->detect_deadlocks) {\n-    Callback cb(thr, pc);\n-    ctx->dd->MutexDestroy(&cb, &s->dd);\n-    ctx->dd->MutexInit(&cb, &s->dd);\n-  }\n   bool unlock_locked = false;\n-  if (flags()->report_destroy_locked && s->owner_tid != kInvalidTid &&\n-      !s->IsFlagSet(MutexFlagBroken)) {\n-    s->SetFlags(MutexFlagBroken);\n-    unlock_locked = true;\n+  u64 mid = 0;\n+  u64 last_lock = 0;\n+  {\n+    SyncVar *s = ctx->metamap.GetSyncIfExists(addr);\n+    if (s == 0)\n+      return;\n+    Lock l(&s->mtx);\n+    if ((flagz & MutexFlagLinkerInit) || s->IsFlagSet(MutexFlagLinkerInit) ||\n+        ((flagz & MutexFlagNotStatic) && !s->IsFlagSet(MutexFlagNotStatic))) {\n+      // Destroy is no-op for linker-initialized mutexes.\n+      return;\n+    }\n+    if (common_flags()->detect_deadlocks) {\n+      Callback cb(thr, pc);\n+      ctx->dd->MutexDestroy(&cb, &s->dd);\n+      ctx->dd->MutexInit(&cb, &s->dd);\n+    }\n+    if (flags()->report_destroy_locked && s->owner_tid != kInvalidTid &&\n+        !s->IsFlagSet(MutexFlagBroken)) {\n+      s->SetFlags(MutexFlagBroken);\n+      unlock_locked = true;\n+    }\n+    mid = s->GetId();\n+    last_lock = s->last_lock;\n+    if (!unlock_locked)\n+      s->Reset(thr->proc());  // must not reset it before the report is printed\n   }\n-  u64 mid = s->GetId();\n-  u64 last_lock = s->last_lock;\n-  if (!unlock_locked)\n-    s->Reset(thr->proc());  // must not reset it before the report is printed\n-  s->mtx.Unlock();\n   if (unlock_locked && ShouldReport(thr, ReportTypeMutexDestroyLocked)) {\n-    ThreadRegistryLock l(ctx->thread_registry);\n+    ThreadRegistryLock l(&ctx->thread_registry);\n     ScopedReport rep(ReportTypeMutexDestroyLocked);\n     rep.AddMutex(mid);\n     VarSizeStackTrace trace;\n@@ -119,38 +122,35 @@ void MutexDestroy(ThreadState *thr, uptr pc, uptr addr, u32 flagz) {\n     rep.AddLocation(addr, 1);\n     OutputReport(thr, rep);\n \n-    SyncVar *s = ctx->metamap.GetIfExistsAndLock(addr, true);\n+    SyncVar *s = ctx->metamap.GetSyncIfExists(addr);\n     if (s != 0) {\n+      Lock l(&s->mtx);\n       s->Reset(thr->proc());\n-      s->mtx.Unlock();\n     }\n   }\n   thr->mset.Remove(mid);\n   // Imitate a memory write to catch unlock-destroy races.\n   // Do this outside of sync mutex, because it can report a race which locks\n   // sync mutexes.\n-  if (IsAppMem(addr)) {\n-    CHECK(!thr->is_freeing);\n-    thr->is_freeing = true;\n-    MemoryWrite(thr, pc, addr, kSizeLog1);\n-    thr->is_freeing = false;\n-  }\n+  if (IsAppMem(addr))\n+    MemoryAccess(thr, pc, addr, 1, kAccessWrite | kAccessFree);\n   // s will be destroyed and freed in MetaMap::FreeBlock.\n }\n \n void MutexPreLock(ThreadState *thr, uptr pc, uptr addr, u32 flagz) {\n   DPrintf(\"#%d: MutexPreLock %zx flagz=0x%x\\n\", thr->tid, addr, flagz);\n   if (!(flagz & MutexFlagTryLock) && common_flags()->detect_deadlocks) {\n-    SyncVar *s = ctx->metamap.GetOrCreateAndLock(thr, pc, addr, false);\n-    s->UpdateFlags(flagz);\n-    if (s->owner_tid != thr->tid) {\n-      Callback cb(thr, pc);\n-      ctx->dd->MutexBeforeLock(&cb, &s->dd, true);\n-      s->mtx.ReadUnlock();\n-      ReportDeadlock(thr, pc, ctx->dd->GetReport(&cb));\n-    } else {\n-      s->mtx.ReadUnlock();\n+    SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, addr, true);\n+    {\n+      ReadLock l(&s->mtx);\n+      s->UpdateFlags(flagz);\n+      if (s->owner_tid != thr->tid) {\n+        Callback cb(thr, pc);\n+        ctx->dd->MutexBeforeLock(&cb, &s->dd, true);\n+      }\n     }\n+    Callback cb(thr, pc);\n+    ReportDeadlock(thr, pc, ctx->dd->GetReport(&cb));\n   }\n }\n \n@@ -162,43 +162,45 @@ void MutexPostLock(ThreadState *thr, uptr pc, uptr addr, u32 flagz, int rec) {\n   else\n     rec = 1;\n   if (IsAppMem(addr))\n-    MemoryReadAtomic(thr, pc, addr, kSizeLog1);\n-  SyncVar *s = ctx->metamap.GetOrCreateAndLock(thr, pc, addr, true);\n-  s->UpdateFlags(flagz);\n-  thr->fast_state.IncrementEpoch();\n-  TraceAddEvent(thr, thr->fast_state, EventTypeLock, s->GetId());\n-  bool report_double_lock = false;\n-  if (s->owner_tid == kInvalidTid) {\n-    CHECK_EQ(s->recursion, 0);\n-    s->owner_tid = thr->tid;\n-    s->last_lock = thr->fast_state.raw();\n-  } else if (s->owner_tid == thr->tid) {\n-    CHECK_GT(s->recursion, 0);\n-  } else if (flags()->report_mutex_bugs && !s->IsFlagSet(MutexFlagBroken)) {\n-    s->SetFlags(MutexFlagBroken);\n-    report_double_lock = true;\n-  }\n-  const bool first = s->recursion == 0;\n-  s->recursion += rec;\n-  if (first) {\n-    AcquireImpl(thr, pc, &s->clock);\n-    AcquireImpl(thr, pc, &s->read_clock);\n-  } else if (!s->IsFlagSet(MutexFlagWriteReentrant)) {\n-  }\n-  thr->mset.Add(s->GetId(), true, thr->fast_state.epoch());\n+    MemoryAccess(thr, pc, addr, 1, kAccessRead | kAccessAtomic);\n+  u64 mid = 0;\n   bool pre_lock = false;\n-  if (first && common_flags()->detect_deadlocks) {\n-    pre_lock = (flagz & MutexFlagDoPreLockOnPostLock) &&\n-        !(flagz & MutexFlagTryLock);\n-    Callback cb(thr, pc);\n-    if (pre_lock)\n-      ctx->dd->MutexBeforeLock(&cb, &s->dd, true);\n-    ctx->dd->MutexAfterLock(&cb, &s->dd, true, flagz & MutexFlagTryLock);\n+  bool first = false;\n+  bool report_double_lock = false;\n+  {\n+    SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, addr, true);\n+    Lock l(&s->mtx);\n+    s->UpdateFlags(flagz);\n+    thr->fast_state.IncrementEpoch();\n+    TraceAddEvent(thr, thr->fast_state, EventTypeLock, s->GetId());\n+    if (s->owner_tid == kInvalidTid) {\n+      CHECK_EQ(s->recursion, 0);\n+      s->owner_tid = thr->tid;\n+      s->last_lock = thr->fast_state.raw();\n+    } else if (s->owner_tid == thr->tid) {\n+      CHECK_GT(s->recursion, 0);\n+    } else if (flags()->report_mutex_bugs && !s->IsFlagSet(MutexFlagBroken)) {\n+      s->SetFlags(MutexFlagBroken);\n+      report_double_lock = true;\n+    }\n+    first = s->recursion == 0;\n+    s->recursion += rec;\n+    if (first) {\n+      AcquireImpl(thr, pc, &s->clock);\n+      AcquireImpl(thr, pc, &s->read_clock);\n+    } else if (!s->IsFlagSet(MutexFlagWriteReentrant)) {\n+    }\n+    thr->mset.Add(s->GetId(), true, thr->fast_state.epoch());\n+    if (first && common_flags()->detect_deadlocks) {\n+      pre_lock =\n+          (flagz & MutexFlagDoPreLockOnPostLock) && !(flagz & MutexFlagTryLock);\n+      Callback cb(thr, pc);\n+      if (pre_lock)\n+        ctx->dd->MutexBeforeLock(&cb, &s->dd, true);\n+      ctx->dd->MutexAfterLock(&cb, &s->dd, true, flagz & MutexFlagTryLock);\n+    }\n+    mid = s->GetId();\n   }\n-  u64 mid = s->GetId();\n-  s->mtx.Unlock();\n-  // Can't touch s after this point.\n-  s = 0;\n   if (report_double_lock)\n     ReportMutexMisuse(thr, pc, ReportTypeMutexDoubleLock, addr, mid);\n   if (first && pre_lock && common_flags()->detect_deadlocks) {\n@@ -210,35 +212,37 @@ void MutexPostLock(ThreadState *thr, uptr pc, uptr addr, u32 flagz, int rec) {\n int MutexUnlock(ThreadState *thr, uptr pc, uptr addr, u32 flagz) {\n   DPrintf(\"#%d: MutexUnlock %zx flagz=0x%x\\n\", thr->tid, addr, flagz);\n   if (IsAppMem(addr))\n-    MemoryReadAtomic(thr, pc, addr, kSizeLog1);\n-  SyncVar *s = ctx->metamap.GetOrCreateAndLock(thr, pc, addr, true);\n-  thr->fast_state.IncrementEpoch();\n-  TraceAddEvent(thr, thr->fast_state, EventTypeUnlock, s->GetId());\n-  int rec = 0;\n+    MemoryAccess(thr, pc, addr, 1, kAccessRead | kAccessAtomic);\n+  u64 mid = 0;\n   bool report_bad_unlock = false;\n-  if (!SANITIZER_GO && (s->recursion == 0 || s->owner_tid != thr->tid)) {\n-    if (flags()->report_mutex_bugs && !s->IsFlagSet(MutexFlagBroken)) {\n-      s->SetFlags(MutexFlagBroken);\n-      report_bad_unlock = true;\n-    }\n-  } else {\n-    rec = (flagz & MutexFlagRecursiveUnlock) ? s->recursion : 1;\n-    s->recursion -= rec;\n-    if (s->recursion == 0) {\n-      s->owner_tid = kInvalidTid;\n-      ReleaseStoreImpl(thr, pc, &s->clock);\n+  int rec = 0;\n+  {\n+    SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, addr, true);\n+    Lock l(&s->mtx);\n+    thr->fast_state.IncrementEpoch();\n+    TraceAddEvent(thr, thr->fast_state, EventTypeUnlock, s->GetId());\n+    if (!SANITIZER_GO && (s->recursion == 0 || s->owner_tid != thr->tid)) {\n+      if (flags()->report_mutex_bugs && !s->IsFlagSet(MutexFlagBroken)) {\n+        s->SetFlags(MutexFlagBroken);\n+        report_bad_unlock = true;\n+      }\n     } else {\n+      rec = (flagz & MutexFlagRecursiveUnlock) ? s->recursion : 1;\n+      s->recursion -= rec;\n+      if (s->recursion == 0) {\n+        s->owner_tid = kInvalidTid;\n+        ReleaseStoreImpl(thr, pc, &s->clock);\n+      } else {\n+      }\n     }\n+    thr->mset.Del(s->GetId(), true);\n+    if (common_flags()->detect_deadlocks && s->recursion == 0 &&\n+        !report_bad_unlock) {\n+      Callback cb(thr, pc);\n+      ctx->dd->MutexBeforeUnlock(&cb, &s->dd, true);\n+    }\n+    mid = s->GetId();\n   }\n-  thr->mset.Del(s->GetId(), true);\n-  if (common_flags()->detect_deadlocks && s->recursion == 0 &&\n-      !report_bad_unlock) {\n-    Callback cb(thr, pc);\n-    ctx->dd->MutexBeforeUnlock(&cb, &s->dd, true);\n-  }\n-  u64 mid = s->GetId();\n-  s->mtx.Unlock();\n-  // Can't touch s after this point.\n   if (report_bad_unlock)\n     ReportMutexMisuse(thr, pc, ReportTypeMutexBadUnlock, addr, mid);\n   if (common_flags()->detect_deadlocks && !report_bad_unlock) {\n@@ -251,46 +255,50 @@ int MutexUnlock(ThreadState *thr, uptr pc, uptr addr, u32 flagz) {\n void MutexPreReadLock(ThreadState *thr, uptr pc, uptr addr, u32 flagz) {\n   DPrintf(\"#%d: MutexPreReadLock %zx flagz=0x%x\\n\", thr->tid, addr, flagz);\n   if (!(flagz & MutexFlagTryLock) && common_flags()->detect_deadlocks) {\n-    SyncVar *s = ctx->metamap.GetOrCreateAndLock(thr, pc, addr, false);\n-    s->UpdateFlags(flagz);\n+    {\n+      SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, addr, true);\n+      ReadLock l(&s->mtx);\n+      s->UpdateFlags(flagz);\n+      Callback cb(thr, pc);\n+      ctx->dd->MutexBeforeLock(&cb, &s->dd, false);\n+    }\n     Callback cb(thr, pc);\n-    ctx->dd->MutexBeforeLock(&cb, &s->dd, false);\n-    s->mtx.ReadUnlock();\n     ReportDeadlock(thr, pc, ctx->dd->GetReport(&cb));\n   }\n }\n \n void MutexPostReadLock(ThreadState *thr, uptr pc, uptr addr, u32 flagz) {\n   DPrintf(\"#%d: MutexPostReadLock %zx flagz=0x%x\\n\", thr->tid, addr, flagz);\n   if (IsAppMem(addr))\n-    MemoryReadAtomic(thr, pc, addr, kSizeLog1);\n-  SyncVar *s = ctx->metamap.GetOrCreateAndLock(thr, pc, addr, false);\n-  s->UpdateFlags(flagz);\n-  thr->fast_state.IncrementEpoch();\n-  TraceAddEvent(thr, thr->fast_state, EventTypeRLock, s->GetId());\n+    MemoryAccess(thr, pc, addr, 1, kAccessRead | kAccessAtomic);\n+  u64 mid = 0;\n   bool report_bad_lock = false;\n-  if (s->owner_tid != kInvalidTid) {\n-    if (flags()->report_mutex_bugs && !s->IsFlagSet(MutexFlagBroken)) {\n-      s->SetFlags(MutexFlagBroken);\n-      report_bad_lock = true;\n-    }\n-  }\n-  AcquireImpl(thr, pc, &s->clock);\n-  s->last_lock = thr->fast_state.raw();\n-  thr->mset.Add(s->GetId(), false, thr->fast_state.epoch());\n   bool pre_lock = false;\n-  if (common_flags()->detect_deadlocks) {\n-    pre_lock = (flagz & MutexFlagDoPreLockOnPostLock) &&\n-        !(flagz & MutexFlagTryLock);\n-    Callback cb(thr, pc);\n-    if (pre_lock)\n-      ctx->dd->MutexBeforeLock(&cb, &s->dd, false);\n-    ctx->dd->MutexAfterLock(&cb, &s->dd, false, flagz & MutexFlagTryLock);\n+  {\n+    SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, addr, true);\n+    ReadLock l(&s->mtx);\n+    s->UpdateFlags(flagz);\n+    thr->fast_state.IncrementEpoch();\n+    TraceAddEvent(thr, thr->fast_state, EventTypeRLock, s->GetId());\n+    if (s->owner_tid != kInvalidTid) {\n+      if (flags()->report_mutex_bugs && !s->IsFlagSet(MutexFlagBroken)) {\n+        s->SetFlags(MutexFlagBroken);\n+        report_bad_lock = true;\n+      }\n+    }\n+    AcquireImpl(thr, pc, &s->clock);\n+    s->last_lock = thr->fast_state.raw();\n+    thr->mset.Add(s->GetId(), false, thr->fast_state.epoch());\n+    if (common_flags()->detect_deadlocks) {\n+      pre_lock =\n+          (flagz & MutexFlagDoPreLockOnPostLock) && !(flagz & MutexFlagTryLock);\n+      Callback cb(thr, pc);\n+      if (pre_lock)\n+        ctx->dd->MutexBeforeLock(&cb, &s->dd, false);\n+      ctx->dd->MutexAfterLock(&cb, &s->dd, false, flagz & MutexFlagTryLock);\n+    }\n+    mid = s->GetId();\n   }\n-  u64 mid = s->GetId();\n-  s->mtx.ReadUnlock();\n-  // Can't touch s after this point.\n-  s = 0;\n   if (report_bad_lock)\n     ReportMutexMisuse(thr, pc, ReportTypeMutexBadReadLock, addr, mid);\n   if (pre_lock  && common_flags()->detect_deadlocks) {\n@@ -302,25 +310,27 @@ void MutexPostReadLock(ThreadState *thr, uptr pc, uptr addr, u32 flagz) {\n void MutexReadUnlock(ThreadState *thr, uptr pc, uptr addr) {\n   DPrintf(\"#%d: MutexReadUnlock %zx\\n\", thr->tid, addr);\n   if (IsAppMem(addr))\n-    MemoryReadAtomic(thr, pc, addr, kSizeLog1);\n-  SyncVar *s = ctx->metamap.GetOrCreateAndLock(thr, pc, addr, true);\n-  thr->fast_state.IncrementEpoch();\n-  TraceAddEvent(thr, thr->fast_state, EventTypeRUnlock, s->GetId());\n+    MemoryAccess(thr, pc, addr, 1, kAccessRead | kAccessAtomic);\n+  u64 mid = 0;\n   bool report_bad_unlock = false;\n-  if (s->owner_tid != kInvalidTid) {\n-    if (flags()->report_mutex_bugs && !s->IsFlagSet(MutexFlagBroken)) {\n-      s->SetFlags(MutexFlagBroken);\n-      report_bad_unlock = true;\n+  {\n+    SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, addr, true);\n+    Lock l(&s->mtx);\n+    thr->fast_state.IncrementEpoch();\n+    TraceAddEvent(thr, thr->fast_state, EventTypeRUnlock, s->GetId());\n+    if (s->owner_tid != kInvalidTid) {\n+      if (flags()->report_mutex_bugs && !s->IsFlagSet(MutexFlagBroken)) {\n+        s->SetFlags(MutexFlagBroken);\n+        report_bad_unlock = true;\n+      }\n     }\n+    ReleaseImpl(thr, pc, &s->read_clock);\n+    if (common_flags()->detect_deadlocks && s->recursion == 0) {\n+      Callback cb(thr, pc);\n+      ctx->dd->MutexBeforeUnlock(&cb, &s->dd, false);\n+    }\n+    mid = s->GetId();\n   }\n-  ReleaseImpl(thr, pc, &s->read_clock);\n-  if (common_flags()->detect_deadlocks && s->recursion == 0) {\n-    Callback cb(thr, pc);\n-    ctx->dd->MutexBeforeUnlock(&cb, &s->dd, false);\n-  }\n-  u64 mid = s->GetId();\n-  s->mtx.Unlock();\n-  // Can't touch s after this point.\n   thr->mset.Del(mid, false);\n   if (report_bad_unlock)\n     ReportMutexMisuse(thr, pc, ReportTypeMutexBadReadUnlock, addr, mid);\n@@ -333,39 +343,41 @@ void MutexReadUnlock(ThreadState *thr, uptr pc, uptr addr) {\n void MutexReadOrWriteUnlock(ThreadState *thr, uptr pc, uptr addr) {\n   DPrintf(\"#%d: MutexReadOrWriteUnlock %zx\\n\", thr->tid, addr);\n   if (IsAppMem(addr))\n-    MemoryReadAtomic(thr, pc, addr, kSizeLog1);\n-  SyncVar *s = ctx->metamap.GetOrCreateAndLock(thr, pc, addr, true);\n-  bool write = true;\n+    MemoryAccess(thr, pc, addr, 1, kAccessRead | kAccessAtomic);\n+  u64 mid = 0;\n   bool report_bad_unlock = false;\n-  if (s->owner_tid == kInvalidTid) {\n-    // Seems to be read unlock.\n-    write = false;\n-    thr->fast_state.IncrementEpoch();\n-    TraceAddEvent(thr, thr->fast_state, EventTypeRUnlock, s->GetId());\n-    ReleaseImpl(thr, pc, &s->read_clock);\n-  } else if (s->owner_tid == thr->tid) {\n-    // Seems to be write unlock.\n-    thr->fast_state.IncrementEpoch();\n-    TraceAddEvent(thr, thr->fast_state, EventTypeUnlock, s->GetId());\n-    CHECK_GT(s->recursion, 0);\n-    s->recursion--;\n-    if (s->recursion == 0) {\n-      s->owner_tid = kInvalidTid;\n-      ReleaseStoreImpl(thr, pc, &s->clock);\n-    } else {\n+  {\n+    SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, addr, true);\n+    Lock l(&s->mtx);\n+    bool write = true;\n+    if (s->owner_tid == kInvalidTid) {\n+      // Seems to be read unlock.\n+      write = false;\n+      thr->fast_state.IncrementEpoch();\n+      TraceAddEvent(thr, thr->fast_state, EventTypeRUnlock, s->GetId());\n+      ReleaseImpl(thr, pc, &s->read_clock);\n+    } else if (s->owner_tid == thr->tid) {\n+      // Seems to be write unlock.\n+      thr->fast_state.IncrementEpoch();\n+      TraceAddEvent(thr, thr->fast_state, EventTypeUnlock, s->GetId());\n+      CHECK_GT(s->recursion, 0);\n+      s->recursion--;\n+      if (s->recursion == 0) {\n+        s->owner_tid = kInvalidTid;\n+        ReleaseStoreImpl(thr, pc, &s->clock);\n+      } else {\n+      }\n+    } else if (!s->IsFlagSet(MutexFlagBroken)) {\n+      s->SetFlags(MutexFlagBroken);\n+      report_bad_unlock = true;\n     }\n-  } else if (!s->IsFlagSet(MutexFlagBroken)) {\n-    s->SetFlags(MutexFlagBroken);\n-    report_bad_unlock = true;\n-  }\n-  thr->mset.Del(s->GetId(), write);\n-  if (common_flags()->detect_deadlocks && s->recursion == 0) {\n-    Callback cb(thr, pc);\n-    ctx->dd->MutexBeforeUnlock(&cb, &s->dd, write);\n+    thr->mset.Del(s->GetId(), write);\n+    if (common_flags()->detect_deadlocks && s->recursion == 0) {\n+      Callback cb(thr, pc);\n+      ctx->dd->MutexBeforeUnlock(&cb, &s->dd, write);\n+    }\n+    mid = s->GetId();\n   }\n-  u64 mid = s->GetId();\n-  s->mtx.Unlock();\n-  // Can't touch s after this point.\n   if (report_bad_unlock)\n     ReportMutexMisuse(thr, pc, ReportTypeMutexBadUnlock, addr, mid);\n   if (common_flags()->detect_deadlocks) {\n@@ -376,29 +388,27 @@ void MutexReadOrWriteUnlock(ThreadState *thr, uptr pc, uptr addr) {\n \n void MutexRepair(ThreadState *thr, uptr pc, uptr addr) {\n   DPrintf(\"#%d: MutexRepair %zx\\n\", thr->tid, addr);\n-  SyncVar *s = ctx->metamap.GetOrCreateAndLock(thr, pc, addr, true);\n+  SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, addr, true);\n+  Lock l(&s->mtx);\n   s->owner_tid = kInvalidTid;\n   s->recursion = 0;\n-  s->mtx.Unlock();\n }\n \n void MutexInvalidAccess(ThreadState *thr, uptr pc, uptr addr) {\n   DPrintf(\"#%d: MutexInvalidAccess %zx\\n\", thr->tid, addr);\n-  SyncVar *s = ctx->metamap.GetOrCreateAndLock(thr, pc, addr, true);\n-  u64 mid = s->GetId();\n-  s->mtx.Unlock();\n-  ReportMutexMisuse(thr, pc, ReportTypeMutexInvalidAccess, addr, mid);\n+  SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, addr, true);\n+  ReportMutexMisuse(thr, pc, ReportTypeMutexInvalidAccess, addr, s->GetId());\n }\n \n void Acquire(ThreadState *thr, uptr pc, uptr addr) {\n   DPrintf(\"#%d: Acquire %zx\\n\", thr->tid, addr);\n   if (thr->ignore_sync)\n     return;\n-  SyncVar *s = ctx->metamap.GetIfExistsAndLock(addr, false);\n+  SyncVar *s = ctx->metamap.GetSyncIfExists(addr);\n   if (!s)\n     return;\n+  ReadLock l(&s->mtx);\n   AcquireImpl(thr, pc, &s->clock);\n-  s->mtx.ReadUnlock();\n }\n \n static void UpdateClockCallback(ThreadContextBase *tctx_base, void *arg) {\n@@ -412,49 +422,48 @@ static void UpdateClockCallback(ThreadContextBase *tctx_base, void *arg) {\n   thr->clock.set(&thr->proc()->clock_cache, tctx->tid, epoch);\n }\n \n-void AcquireGlobal(ThreadState *thr, uptr pc) {\n+void AcquireGlobal(ThreadState *thr) {\n   DPrintf(\"#%d: AcquireGlobal\\n\", thr->tid);\n   if (thr->ignore_sync)\n     return;\n-  ThreadRegistryLock l(ctx->thread_registry);\n-  ctx->thread_registry->RunCallbackForEachThreadLocked(\n-      UpdateClockCallback, thr);\n+  ThreadRegistryLock l(&ctx->thread_registry);\n+  ctx->thread_registry.RunCallbackForEachThreadLocked(UpdateClockCallback, thr);\n }\n \n void ReleaseStoreAcquire(ThreadState *thr, uptr pc, uptr addr) {\n   DPrintf(\"#%d: ReleaseStoreAcquire %zx\\n\", thr->tid, addr);\n   if (thr->ignore_sync)\n     return;\n-  SyncVar *s = ctx->metamap.GetOrCreateAndLock(thr, pc, addr, true);\n+  SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, addr, false);\n+  Lock l(&s->mtx);\n   thr->fast_state.IncrementEpoch();\n   // Can't increment epoch w/o writing to the trace as well.\n   TraceAddEvent(thr, thr->fast_state, EventTypeMop, 0);\n   ReleaseStoreAcquireImpl(thr, pc, &s->clock);\n-  s->mtx.Unlock();\n }\n \n void Release(ThreadState *thr, uptr pc, uptr addr) {\n   DPrintf(\"#%d: Release %zx\\n\", thr->tid, addr);\n   if (thr->ignore_sync)\n     return;\n-  SyncVar *s = ctx->metamap.GetOrCreateAndLock(thr, pc, addr, true);\n+  SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, addr, false);\n+  Lock l(&s->mtx);\n   thr->fast_state.IncrementEpoch();\n   // Can't increment epoch w/o writing to the trace as well.\n   TraceAddEvent(thr, thr->fast_state, EventTypeMop, 0);\n   ReleaseImpl(thr, pc, &s->clock);\n-  s->mtx.Unlock();\n }\n \n void ReleaseStore(ThreadState *thr, uptr pc, uptr addr) {\n   DPrintf(\"#%d: ReleaseStore %zx\\n\", thr->tid, addr);\n   if (thr->ignore_sync)\n     return;\n-  SyncVar *s = ctx->metamap.GetOrCreateAndLock(thr, pc, addr, true);\n+  SyncVar *s = ctx->metamap.GetSyncOrCreate(thr, pc, addr, false);\n+  Lock l(&s->mtx);\n   thr->fast_state.IncrementEpoch();\n   // Can't increment epoch w/o writing to the trace as well.\n   TraceAddEvent(thr, thr->fast_state, EventTypeMop, 0);\n   ReleaseStoreImpl(thr, pc, &s->clock);\n-  s->mtx.Unlock();\n }\n \n #if !SANITIZER_GO\n@@ -468,13 +477,13 @@ static void UpdateSleepClockCallback(ThreadContextBase *tctx_base, void *arg) {\n }\n \n void AfterSleep(ThreadState *thr, uptr pc) {\n-  DPrintf(\"#%d: AfterSleep %zx\\n\", thr->tid);\n+  DPrintf(\"#%d: AfterSleep\\n\", thr->tid);\n   if (thr->ignore_sync)\n     return;\n   thr->last_sleep_stack_id = CurrentStackId(thr, pc);\n-  ThreadRegistryLock l(ctx->thread_registry);\n-  ctx->thread_registry->RunCallbackForEachThreadLocked(\n-      UpdateSleepClockCallback, thr);\n+  ThreadRegistryLock l(&ctx->thread_registry);\n+  ctx->thread_registry.RunCallbackForEachThreadLocked(UpdateSleepClockCallback,\n+                                                      thr);\n }\n #endif\n \n@@ -520,7 +529,7 @@ void AcquireReleaseImpl(ThreadState *thr, uptr pc, SyncClock *c) {\n void ReportDeadlock(ThreadState *thr, uptr pc, DDReport *r) {\n   if (r == 0 || !ShouldReport(thr, ReportTypeDeadlock))\n     return;\n-  ThreadRegistryLock l(ctx->thread_registry);\n+  ThreadRegistryLock l(&ctx->thread_registry);\n   ScopedReport rep(ReportTypeDeadlock);\n   for (int i = 0; i < r->n; i++) {\n     rep.AddMutex(r->loop[i].mtx_ctx0);"}, {"sha": "8285e21aa1ec7a797dfcf4840ee5a7851106b497", "filename": "libsanitizer/tsan/tsan_rtl_ppc64.S", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_rtl_ppc64.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_rtl_ppc64.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_rtl_ppc64.S?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -1,6 +1,5 @@\n #include \"tsan_ppc_regs.h\"\n \n-        .machine altivec\n         .section .text\n         .hidden __tsan_setjmp\n         .globl _setjmp"}, {"sha": "1f0bcb35ae9f634d7be9a55efe459198bc1e40ea", "filename": "libsanitizer/tsan/tsan_rtl_report.cpp", "status": "modified", "additions": 277, "deletions": 51, "changes": 328, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_rtl_report.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_rtl_report.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_rtl_report.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -68,8 +68,10 @@ static void StackStripMain(SymbolizedStack *frames) {\n   } else if (last && 0 == internal_strcmp(last, \"__tsan_thread_start_func\")) {\n     last_frame->ClearAll();\n     last_frame2->next = nullptr;\n-  // Strip global ctors init.\n-  } else if (last && 0 == internal_strcmp(last, \"__do_global_ctors_aux\")) {\n+    // Strip global ctors init, .preinit_array and main caller.\n+  } else if (last && (0 == internal_strcmp(last, \"__do_global_ctors_aux\") ||\n+                      0 == internal_strcmp(last, \"__libc_csu_init\") ||\n+                      0 == internal_strcmp(last, \"__libc_start_main\"))) {\n     last_frame->ClearAll();\n     last_frame2->next = nullptr;\n   // If both are 0, then we probably just failed to symbolize.\n@@ -120,7 +122,7 @@ static ReportStack *SymbolizeStack(StackTrace trace) {\n   }\n   StackStripMain(top);\n \n-  ReportStack *stack = ReportStack::New();\n+  auto *stack = New<ReportStack>();\n   stack->frames = top;\n   return stack;\n }\n@@ -129,10 +131,10 @@ bool ShouldReport(ThreadState *thr, ReportType typ) {\n   // We set thr->suppress_reports in the fork context.\n   // Taking any locking in the fork context can lead to deadlocks.\n   // If any locks are already taken, it's too late to do this check.\n-  CheckNoLocks(thr);\n+  CheckedMutex::CheckNoLocks();\n   // For the same reason check we didn't lock thread_registry yet.\n   if (SANITIZER_DEBUG)\n-    ThreadRegistryLock l(ctx->thread_registry);\n+    ThreadRegistryLock l(&ctx->thread_registry);\n   if (!flags()->report_bugs || thr->suppress_reports)\n     return false;\n   switch (typ) {\n@@ -154,9 +156,8 @@ bool ShouldReport(ThreadState *thr, ReportType typ) {\n }\n \n ScopedReportBase::ScopedReportBase(ReportType typ, uptr tag) {\n-  ctx->thread_registry->CheckLocked();\n-  void *mem = internal_alloc(MBlockReport, sizeof(ReportDesc));\n-  rep_ = new(mem) ReportDesc;\n+  ctx->thread_registry.CheckLocked();\n+  rep_ = New<ReportDesc>();\n   rep_->typ = typ;\n   rep_->tag = tag;\n   ctx->report_mtx.Lock();\n@@ -165,7 +166,6 @@ ScopedReportBase::ScopedReportBase(ReportType typ, uptr tag) {\n ScopedReportBase::~ScopedReportBase() {\n   ctx->report_mtx.Unlock();\n   DestroyAndFree(rep_);\n-  rep_ = nullptr;\n }\n \n void ScopedReportBase::AddStack(StackTrace stack, bool suppressable) {\n@@ -176,8 +176,7 @@ void ScopedReportBase::AddStack(StackTrace stack, bool suppressable) {\n \n void ScopedReportBase::AddMemoryAccess(uptr addr, uptr external_tag, Shadow s,\n                                        StackTrace stack, const MutexSet *mset) {\n-  void *mem = internal_alloc(MBlockReportMop, sizeof(ReportMop));\n-  ReportMop *mop = new(mem) ReportMop;\n+  auto *mop = New<ReportMop>();\n   rep_->mops.PushBack(mop);\n   mop->tid = s.tid();\n   mop->addr = addr + s.addr0();\n@@ -196,7 +195,7 @@ void ScopedReportBase::AddMemoryAccess(uptr addr, uptr external_tag, Shadow s,\n   }\n }\n \n-void ScopedReportBase::AddUniqueTid(int unique_tid) {\n+void ScopedReportBase::AddUniqueTid(Tid unique_tid) {\n   rep_->unique_tids.PushBack(unique_tid);\n }\n \n@@ -205,8 +204,7 @@ void ScopedReportBase::AddThread(const ThreadContext *tctx, bool suppressable) {\n     if ((u32)rep_->threads[i]->id == tctx->tid)\n       return;\n   }\n-  void *mem = internal_alloc(MBlockReportThread, sizeof(ReportThread));\n-  ReportThread *rt = new(mem) ReportThread;\n+  auto *rt = New<ReportThread>();\n   rep_->threads.PushBack(rt);\n   rt->id = tctx->tid;\n   rt->os_id = tctx->os_id;\n@@ -226,17 +224,17 @@ static bool FindThreadByUidLockedCallback(ThreadContextBase *tctx, void *arg) {\n   return tctx->unique_id == (u32)unique_id;\n }\n \n-static ThreadContext *FindThreadByUidLocked(int unique_id) {\n-  ctx->thread_registry->CheckLocked();\n+static ThreadContext *FindThreadByUidLocked(Tid unique_id) {\n+  ctx->thread_registry.CheckLocked();\n   return static_cast<ThreadContext *>(\n-      ctx->thread_registry->FindThreadContextLocked(\n+      ctx->thread_registry.FindThreadContextLocked(\n           FindThreadByUidLockedCallback, &unique_id));\n }\n \n-static ThreadContext *FindThreadByTidLocked(int tid) {\n-  ctx->thread_registry->CheckLocked();\n-  return static_cast<ThreadContext*>(\n-      ctx->thread_registry->GetThreadLocked(tid));\n+static ThreadContext *FindThreadByTidLocked(Tid tid) {\n+  ctx->thread_registry.CheckLocked();\n+  return static_cast<ThreadContext *>(\n+      ctx->thread_registry.GetThreadLocked(tid));\n }\n \n static bool IsInStackOrTls(ThreadContextBase *tctx_base, void *arg) {\n@@ -251,10 +249,10 @@ static bool IsInStackOrTls(ThreadContextBase *tctx_base, void *arg) {\n }\n \n ThreadContext *IsThreadStackOrTls(uptr addr, bool *is_stack) {\n-  ctx->thread_registry->CheckLocked();\n-  ThreadContext *tctx = static_cast<ThreadContext*>(\n-      ctx->thread_registry->FindThreadContextLocked(IsInStackOrTls,\n-                                                    (void*)addr));\n+  ctx->thread_registry.CheckLocked();\n+  ThreadContext *tctx =\n+      static_cast<ThreadContext *>(ctx->thread_registry.FindThreadContextLocked(\n+          IsInStackOrTls, (void *)addr));\n   if (!tctx)\n     return 0;\n   ThreadState *thr = tctx->thr;\n@@ -264,7 +262,7 @@ ThreadContext *IsThreadStackOrTls(uptr addr, bool *is_stack) {\n }\n #endif\n \n-void ScopedReportBase::AddThread(int unique_tid, bool suppressable) {\n+void ScopedReportBase::AddThread(Tid unique_tid, bool suppressable) {\n #if !SANITIZER_GO\n   if (const ThreadContext *tctx = FindThreadByUidLocked(unique_tid))\n     AddThread(tctx, suppressable);\n@@ -276,8 +274,7 @@ void ScopedReportBase::AddMutex(const SyncVar *s) {\n     if (rep_->mutexes[i]->id == s->uid)\n       return;\n   }\n-  void *mem = internal_alloc(MBlockReportMutex, sizeof(ReportMutex));\n-  ReportMutex *rm = new(mem) ReportMutex;\n+  auto *rm = New<ReportMutex>();\n   rep_->mutexes.PushBack(rm);\n   rm->id = s->uid;\n   rm->addr = s->addr;\n@@ -289,18 +286,17 @@ u64 ScopedReportBase::AddMutex(u64 id) {\n   u64 uid = 0;\n   u64 mid = id;\n   uptr addr = SyncVar::SplitId(id, &uid);\n-  SyncVar *s = ctx->metamap.GetIfExistsAndLock(addr, true);\n+  SyncVar *s = ctx->metamap.GetSyncIfExists(addr);\n   // Check that the mutex is still alive.\n   // Another mutex can be created at the same address,\n   // so check uid as well.\n   if (s && s->CheckId(uid)) {\n+    Lock l(&s->mtx);\n     mid = s->uid;\n     AddMutex(s);\n   } else {\n     AddDeadMutex(id);\n   }\n-  if (s)\n-    s->mtx.Unlock();\n   return mid;\n }\n \n@@ -309,8 +305,7 @@ void ScopedReportBase::AddDeadMutex(u64 id) {\n     if (rep_->mutexes[i]->id == id)\n       return;\n   }\n-  void *mem = internal_alloc(MBlockReportMutex, sizeof(ReportMutex));\n-  ReportMutex *rm = new(mem) ReportMutex;\n+  auto *rm = New<ReportMutex>();\n   rep_->mutexes.PushBack(rm);\n   rm->id = id;\n   rm->addr = 0;\n@@ -323,10 +318,11 @@ void ScopedReportBase::AddLocation(uptr addr, uptr size) {\n     return;\n #if !SANITIZER_GO\n   int fd = -1;\n-  int creat_tid = kInvalidTid;\n-  u32 creat_stack = 0;\n+  Tid creat_tid = kInvalidTid;\n+  StackID creat_stack = 0;\n   if (FdLocation(addr, &fd, &creat_tid, &creat_stack)) {\n-    ReportLocation *loc = ReportLocation::New(ReportLocationFD);\n+    auto *loc = New<ReportLocation>();\n+    loc->type = ReportLocationFD;\n     loc->fd = fd;\n     loc->tid = creat_tid;\n     loc->stack = SymbolizeStackId(creat_stack);\n@@ -337,15 +333,19 @@ void ScopedReportBase::AddLocation(uptr addr, uptr size) {\n     return;\n   }\n   MBlock *b = 0;\n+  uptr block_begin = 0;\n   Allocator *a = allocator();\n   if (a->PointerIsMine((void*)addr)) {\n-    void *block_begin = a->GetBlockBegin((void*)addr);\n+    block_begin = (uptr)a->GetBlockBegin((void *)addr);\n     if (block_begin)\n-      b = ctx->metamap.GetBlock((uptr)block_begin);\n+      b = ctx->metamap.GetBlock(block_begin);\n   }\n+  if (!b)\n+    b = JavaHeapBlock(addr, &block_begin);\n   if (b != 0) {\n     ThreadContext *tctx = FindThreadByTidLocked(b->tid);\n-    ReportLocation *loc = ReportLocation::New(ReportLocationHeap);\n+    auto *loc = New<ReportLocation>();\n+    loc->type = ReportLocationHeap;\n     loc->heap_chunk_start = (uptr)allocator()->GetBlockBegin((void *)addr);\n     loc->heap_chunk_size = b->siz;\n     loc->external_tag = b->tag;\n@@ -358,8 +358,8 @@ void ScopedReportBase::AddLocation(uptr addr, uptr size) {\n   }\n   bool is_stack = false;\n   if (ThreadContext *tctx = IsThreadStackOrTls(addr, &is_stack)) {\n-    ReportLocation *loc =\n-        ReportLocation::New(is_stack ? ReportLocationStack : ReportLocationTLS);\n+    auto *loc = New<ReportLocation>();\n+    loc->type = is_stack ? ReportLocationStack : ReportLocationTLS;\n     loc->tid = tctx->tid;\n     rep_->locs.PushBack(loc);\n     AddThread(tctx);\n@@ -373,7 +373,7 @@ void ScopedReportBase::AddLocation(uptr addr, uptr size) {\n }\n \n #if !SANITIZER_GO\n-void ScopedReportBase::AddSleep(u32 stack_id) {\n+void ScopedReportBase::AddSleep(StackID stack_id) {\n   rep_->sleep = SymbolizeStackId(stack_id);\n }\n #endif\n@@ -387,7 +387,7 @@ ScopedReport::ScopedReport(ReportType typ, uptr tag)\n \n ScopedReport::~ScopedReport() {}\n \n-void RestoreStack(int tid, const u64 epoch, VarSizeStackTrace *stk,\n+void RestoreStack(Tid tid, const u64 epoch, VarSizeStackTrace *stk,\n                   MutexSet *mset, uptr *tag) {\n   // This function restores stack trace and mutex set for the thread/epoch.\n   // It does so by getting stack trace and mutex set at the beginning of\n@@ -450,6 +450,234 @@ void RestoreStack(int tid, const u64 epoch, VarSizeStackTrace *stk,\n   ExtractTagFromStack(stk, tag);\n }\n \n+namespace v3 {\n+\n+// Replays the trace up to last_pos position in the last part\n+// or up to the provided epoch/sid (whichever is earlier)\n+// and calls the provided function f for each event.\n+template <typename Func>\n+void TraceReplay(Trace *trace, TracePart *last, Event *last_pos, Sid sid,\n+                 Epoch epoch, Func f) {\n+  TracePart *part = trace->parts.Front();\n+  Sid ev_sid = kFreeSid;\n+  Epoch ev_epoch = kEpochOver;\n+  for (;;) {\n+    DCHECK_EQ(part->trace, trace);\n+    // Note: an event can't start in the last element.\n+    // Since an event can take up to 2 elements,\n+    // we ensure we have at least 2 before adding an event.\n+    Event *end = &part->events[TracePart::kSize - 1];\n+    if (part == last)\n+      end = last_pos;\n+    for (Event *evp = &part->events[0]; evp < end; evp++) {\n+      Event *evp0 = evp;\n+      if (!evp->is_access && !evp->is_func) {\n+        switch (evp->type) {\n+          case EventType::kTime: {\n+            auto *ev = reinterpret_cast<EventTime *>(evp);\n+            ev_sid = static_cast<Sid>(ev->sid);\n+            ev_epoch = static_cast<Epoch>(ev->epoch);\n+            if (ev_sid == sid && ev_epoch > epoch)\n+              return;\n+            break;\n+          }\n+          case EventType::kAccessExt:\n+            FALLTHROUGH;\n+          case EventType::kAccessRange:\n+            FALLTHROUGH;\n+          case EventType::kLock:\n+            FALLTHROUGH;\n+          case EventType::kRLock:\n+            // These take 2 Event elements.\n+            evp++;\n+            break;\n+          case EventType::kUnlock:\n+            // This takes 1 Event element.\n+            break;\n+        }\n+      }\n+      CHECK_NE(ev_sid, kFreeSid);\n+      CHECK_NE(ev_epoch, kEpochOver);\n+      f(ev_sid, ev_epoch, evp0);\n+    }\n+    if (part == last)\n+      return;\n+    part = trace->parts.Next(part);\n+    CHECK(part);\n+  }\n+  CHECK(0);\n+}\n+\n+static void RestoreStackMatch(VarSizeStackTrace *pstk, MutexSet *pmset,\n+                              Vector<uptr> *stack, MutexSet *mset, uptr pc,\n+                              bool *found) {\n+  DPrintf2(\"    MATCHED\\n\");\n+  *pmset = *mset;\n+  stack->PushBack(pc);\n+  pstk->Init(&(*stack)[0], stack->Size());\n+  stack->PopBack();\n+  *found = true;\n+}\n+\n+// Checks if addr1|size1 is fully contained in addr2|size2.\n+// We check for fully contained instread of just overlapping\n+// because a memory access is always traced once, but can be\n+// split into multiple accesses in the shadow.\n+static constexpr bool IsWithinAccess(uptr addr1, uptr size1, uptr addr2,\n+                                     uptr size2) {\n+  return addr1 >= addr2 && addr1 + size1 <= addr2 + size2;\n+}\n+\n+// Replays the trace of thread tid up to the target event identified\n+// by sid/epoch/addr/size/typ and restores and returns stack, mutex set\n+// and tag for that event. If there are multiple such events, it returns\n+// the last one. Returns false if the event is not present in the trace.\n+bool RestoreStack(Tid tid, EventType type, Sid sid, Epoch epoch, uptr addr,\n+                  uptr size, AccessType typ, VarSizeStackTrace *pstk,\n+                  MutexSet *pmset, uptr *ptag) {\n+  // This function restores stack trace and mutex set for the thread/epoch.\n+  // It does so by getting stack trace and mutex set at the beginning of\n+  // trace part, and then replaying the trace till the given epoch.\n+  DPrintf2(\"RestoreStack: tid=%u sid=%u@%u addr=0x%zx/%zu typ=%x\\n\", tid,\n+           static_cast<int>(sid), static_cast<int>(epoch), addr, size,\n+           static_cast<int>(typ));\n+  ctx->slot_mtx.CheckLocked();  // needed to prevent trace part recycling\n+  ctx->thread_registry.CheckLocked();\n+  ThreadContext *tctx =\n+      static_cast<ThreadContext *>(ctx->thread_registry.GetThreadLocked(tid));\n+  Trace *trace = &tctx->trace;\n+  // Snapshot first/last parts and the current position in the last part.\n+  TracePart *first_part;\n+  TracePart *last_part;\n+  Event *last_pos;\n+  {\n+    Lock lock(&trace->mtx);\n+    first_part = trace->parts.Front();\n+    if (!first_part)\n+      return false;\n+    last_part = trace->parts.Back();\n+    last_pos = trace->final_pos;\n+    if (tctx->thr)\n+      last_pos = (Event *)atomic_load_relaxed(&tctx->thr->trace_pos);\n+  }\n+  // Too large for stack.\n+  alignas(MutexSet) static char mset_storage[sizeof(MutexSet)];\n+  MutexSet &mset = *new (mset_storage) MutexSet();\n+  Vector<uptr> stack;\n+  uptr prev_pc = 0;\n+  bool found = false;\n+  bool is_read = typ & kAccessRead;\n+  bool is_atomic = typ & kAccessAtomic;\n+  bool is_free = typ & kAccessFree;\n+  TraceReplay(\n+      trace, last_part, last_pos, sid, epoch,\n+      [&](Sid ev_sid, Epoch ev_epoch, Event *evp) {\n+        bool match = ev_sid == sid && ev_epoch == epoch;\n+        if (evp->is_access) {\n+          if (evp->is_func == 0 && evp->type == EventType::kAccessExt &&\n+              evp->_ == 0)  // NopEvent\n+            return;\n+          auto *ev = reinterpret_cast<EventAccess *>(evp);\n+          uptr ev_addr = RestoreAddr(ev->addr);\n+          uptr ev_size = 1 << ev->size_log;\n+          uptr ev_pc =\n+              prev_pc + ev->pc_delta - (1 << (EventAccess::kPCBits - 1));\n+          prev_pc = ev_pc;\n+          DPrintf2(\"  Access: pc=0x%zx addr=0x%zx/%zu type=%u/%u\\n\", ev_pc,\n+                   ev_addr, ev_size, ev->is_read, ev->is_atomic);\n+          if (match && type == EventType::kAccessExt &&\n+              IsWithinAccess(addr, size, ev_addr, ev_size) &&\n+              is_read == ev->is_read && is_atomic == ev->is_atomic && !is_free)\n+            RestoreStackMatch(pstk, pmset, &stack, &mset, ev_pc, &found);\n+          return;\n+        }\n+        if (evp->is_func) {\n+          auto *ev = reinterpret_cast<EventFunc *>(evp);\n+          if (ev->pc) {\n+            DPrintf2(\"  FuncEnter: pc=0x%llx\\n\", ev->pc);\n+            stack.PushBack(ev->pc);\n+          } else {\n+            DPrintf2(\"  FuncExit\\n\");\n+            CHECK(stack.Size());\n+            stack.PopBack();\n+          }\n+          return;\n+        }\n+        switch (evp->type) {\n+          case EventType::kAccessExt: {\n+            auto *ev = reinterpret_cast<EventAccessExt *>(evp);\n+            uptr ev_addr = RestoreAddr(ev->addr);\n+            uptr ev_size = 1 << ev->size_log;\n+            prev_pc = ev->pc;\n+            DPrintf2(\"  AccessExt: pc=0x%llx addr=0x%zx/%zu type=%u/%u\\n\",\n+                     ev->pc, ev_addr, ev_size, ev->is_read, ev->is_atomic);\n+            if (match && type == EventType::kAccessExt &&\n+                IsWithinAccess(addr, size, ev_addr, ev_size) &&\n+                is_read == ev->is_read && is_atomic == ev->is_atomic &&\n+                !is_free)\n+              RestoreStackMatch(pstk, pmset, &stack, &mset, ev->pc, &found);\n+            break;\n+          }\n+          case EventType::kAccessRange: {\n+            auto *ev = reinterpret_cast<EventAccessRange *>(evp);\n+            uptr ev_addr = RestoreAddr(ev->addr);\n+            uptr ev_size =\n+                (ev->size_hi << EventAccessRange::kSizeLoBits) + ev->size_lo;\n+            uptr ev_pc = RestoreAddr(ev->pc);\n+            prev_pc = ev_pc;\n+            DPrintf2(\"  Range: pc=0x%zx addr=0x%zx/%zu type=%u/%u\\n\", ev_pc,\n+                     ev_addr, ev_size, ev->is_read, ev->is_free);\n+            if (match && type == EventType::kAccessExt &&\n+                IsWithinAccess(addr, size, ev_addr, ev_size) &&\n+                is_read == ev->is_read && !is_atomic && is_free == ev->is_free)\n+              RestoreStackMatch(pstk, pmset, &stack, &mset, ev_pc, &found);\n+            break;\n+          }\n+          case EventType::kLock:\n+            FALLTHROUGH;\n+          case EventType::kRLock: {\n+            auto *ev = reinterpret_cast<EventLock *>(evp);\n+            bool is_write = ev->type == EventType::kLock;\n+            uptr ev_addr = RestoreAddr(ev->addr);\n+            uptr ev_pc = RestoreAddr(ev->pc);\n+            StackID stack_id =\n+                (ev->stack_hi << EventLock::kStackIDLoBits) + ev->stack_lo;\n+            DPrintf2(\"  Lock: pc=0x%zx addr=0x%zx stack=%u write=%d\\n\", ev_pc,\n+                     ev_addr, stack_id, is_write);\n+            mset.AddAddr(ev_addr, stack_id, is_write);\n+            // Events with ev_pc == 0 are written to the beginning of trace\n+            // part as initial mutex set (are not real).\n+            if (match && type == EventType::kLock && addr == ev_addr && ev_pc)\n+              RestoreStackMatch(pstk, pmset, &stack, &mset, ev_pc, &found);\n+            break;\n+          }\n+          case EventType::kUnlock: {\n+            auto *ev = reinterpret_cast<EventUnlock *>(evp);\n+            uptr ev_addr = RestoreAddr(ev->addr);\n+            DPrintf2(\"  Unlock: addr=0x%zx\\n\", ev_addr);\n+            mset.DelAddr(ev_addr);\n+            break;\n+          }\n+          case EventType::kTime:\n+            // TraceReplay already extracted sid/epoch from it,\n+            // nothing else to do here.\n+            break;\n+        }\n+      });\n+  ExtractTagFromStack(pstk, ptag);\n+  return found;\n+}\n+\n+}  // namespace v3\n+\n+bool RacyStacks::operator==(const RacyStacks &other) const {\n+  if (hash[0] == other.hash[0] && hash[1] == other.hash[1])\n+    return true;\n+  if (hash[0] == other.hash[1] && hash[1] == other.hash[0])\n+    return true;\n+  return false;\n+}\n+\n static bool FindRacyStacks(const RacyStacks &hash) {\n   for (uptr i = 0; i < ctx->racy_stacks.Size(); i++) {\n     if (hash == ctx->racy_stacks[i]) {\n@@ -596,7 +824,7 @@ static bool RaceBetweenAtomicAndFree(ThreadState *thr) {\n }\n \n void ReportRace(ThreadState *thr) {\n-  CheckNoLocks(thr);\n+  CheckedMutex::CheckNoLocks();\n \n   // Symbolizer makes lots of intercepted calls. If we try to process them,\n   // at best it will cause deadlocks on internal mutexes.\n@@ -614,7 +842,7 @@ void ReportRace(ThreadState *thr) {\n     thr->racy_state[1] = s.raw();\n   }\n \n-  uptr addr = ShadowToMem((uptr)thr->racy_shadow_addr);\n+  uptr addr = ShadowToMem(thr->racy_shadow_addr);\n   uptr addr_min = 0;\n   uptr addr_max = 0;\n   {\n@@ -692,7 +920,7 @@ void ReportRace(ThreadState *thr) {\n     }\n   }\n \n-  ThreadRegistryLock l0(ctx->thread_registry);\n+  ThreadRegistryLock l0(&ctx->thread_registry);\n   ScopedReport rep(typ, tag);\n   for (uptr i = 0; i < kMop; i++) {\n     Shadow s(thr->racy_state[i]);\n@@ -702,8 +930,8 @@ void ReportRace(ThreadState *thr) {\n \n   for (uptr i = 0; i < kMop; i++) {\n     FastState s(thr->racy_state[i]);\n-    ThreadContext *tctx = static_cast<ThreadContext*>(\n-        ctx->thread_registry->GetThreadLocked(s.tid()));\n+    ThreadContext *tctx = static_cast<ThreadContext *>(\n+        ctx->thread_registry.GetThreadLocked(s.tid()));\n     if (s.epoch() < tctx->epoch0 || s.epoch() > tctx->epoch1)\n       continue;\n     rep.AddThread(tctx);\n@@ -738,9 +966,7 @@ void PrintCurrentStack(ThreadState *thr, uptr pc) {\n ALWAYS_INLINE USED void PrintCurrentStackSlow(uptr pc) {\n #if !SANITIZER_GO\n   uptr bp = GET_CURRENT_FRAME();\n-  BufferedStackTrace *ptrace =\n-      new(internal_alloc(MBlockStackTrace, sizeof(BufferedStackTrace)))\n-          BufferedStackTrace();\n+  auto *ptrace = New<BufferedStackTrace>();\n   ptrace->Unwind(pc, bp, nullptr, false);\n \n   for (uptr i = 0; i < ptrace->size / 2; i++) {"}, {"sha": "61133a4a3e7eacfb28dc58d9de6b90c7662f7504", "filename": "libsanitizer/tsan/tsan_rtl_thread.cpp", "status": "modified", "additions": 148, "deletions": 158, "changes": 306, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_rtl_thread.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_rtl_thread.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_rtl_thread.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -21,143 +21,30 @@ namespace __tsan {\n \n // ThreadContext implementation.\n \n-ThreadContext::ThreadContext(int tid)\n-  : ThreadContextBase(tid)\n-  , thr()\n-  , sync()\n-  , epoch0()\n-  , epoch1() {\n-}\n+ThreadContext::ThreadContext(Tid tid)\n+    : ThreadContextBase(tid), thr(), sync(), epoch0(), epoch1() {}\n \n #if !SANITIZER_GO\n ThreadContext::~ThreadContext() {\n }\n #endif\n \n-void ThreadContext::OnDead() {\n-  CHECK_EQ(sync.size(), 0);\n-}\n-\n-void ThreadContext::OnJoined(void *arg) {\n-  ThreadState *caller_thr = static_cast<ThreadState *>(arg);\n-  AcquireImpl(caller_thr, 0, &sync);\n-  sync.Reset(&caller_thr->proc()->clock_cache);\n-}\n-\n-struct OnCreatedArgs {\n-  ThreadState *thr;\n-  uptr pc;\n-};\n-\n-void ThreadContext::OnCreated(void *arg) {\n-  thr = 0;\n-  if (tid == kMainTid)\n-    return;\n-  OnCreatedArgs *args = static_cast<OnCreatedArgs *>(arg);\n-  if (!args->thr)  // GCD workers don't have a parent thread.\n-    return;\n-  args->thr->fast_state.IncrementEpoch();\n-  // Can't increment epoch w/o writing to the trace as well.\n-  TraceAddEvent(args->thr, args->thr->fast_state, EventTypeMop, 0);\n-  ReleaseImpl(args->thr, 0, &sync);\n-  creation_stack_id = CurrentStackId(args->thr, args->pc);\n-}\n-\n void ThreadContext::OnReset() {\n   CHECK_EQ(sync.size(), 0);\n   uptr trace_p = GetThreadTrace(tid);\n   ReleaseMemoryPagesToOS(trace_p, trace_p + TraceSize() * sizeof(Event));\n   //!!! ReleaseMemoryToOS(GetThreadTraceHeader(tid), sizeof(Trace));\n }\n \n-void ThreadContext::OnDetached(void *arg) {\n-  ThreadState *thr1 = static_cast<ThreadState*>(arg);\n-  sync.Reset(&thr1->proc()->clock_cache);\n-}\n-\n-struct OnStartedArgs {\n-  ThreadState *thr;\n-  uptr stk_addr;\n-  uptr stk_size;\n-  uptr tls_addr;\n-  uptr tls_size;\n-};\n-\n-void ThreadContext::OnStarted(void *arg) {\n-  OnStartedArgs *args = static_cast<OnStartedArgs*>(arg);\n-  thr = args->thr;\n-  // RoundUp so that one trace part does not contain events\n-  // from different threads.\n-  epoch0 = RoundUp(epoch1 + 1, kTracePartSize);\n-  epoch1 = (u64)-1;\n-  new(thr) ThreadState(ctx, tid, unique_id, epoch0, reuse_count,\n-      args->stk_addr, args->stk_size, args->tls_addr, args->tls_size);\n-#if !SANITIZER_GO\n-  thr->shadow_stack = &ThreadTrace(thr->tid)->shadow_stack[0];\n-  thr->shadow_stack_pos = thr->shadow_stack;\n-  thr->shadow_stack_end = thr->shadow_stack + kShadowStackSize;\n-#else\n-  // Setup dynamic shadow stack.\n-  const int kInitStackSize = 8;\n-  thr->shadow_stack = (uptr*)internal_alloc(MBlockShadowStack,\n-      kInitStackSize * sizeof(uptr));\n-  thr->shadow_stack_pos = thr->shadow_stack;\n-  thr->shadow_stack_end = thr->shadow_stack + kInitStackSize;\n-#endif\n-  if (common_flags()->detect_deadlocks)\n-    thr->dd_lt = ctx->dd->CreateLogicalThread(unique_id);\n-  thr->fast_state.SetHistorySize(flags()->history_size);\n-  // Commit switch to the new part of the trace.\n-  // TraceAddEvent will reset stack0/mset0 in the new part for us.\n-  TraceAddEvent(thr, thr->fast_state, EventTypeMop, 0);\n-\n-  thr->fast_synch_epoch = epoch0;\n-  AcquireImpl(thr, 0, &sync);\n-  sync.Reset(&thr->proc()->clock_cache);\n-  thr->is_inited = true;\n-  DPrintf(\"#%d: ThreadStart epoch=%zu stk_addr=%zx stk_size=%zx \"\n-          \"tls_addr=%zx tls_size=%zx\\n\",\n-          tid, (uptr)epoch0, args->stk_addr, args->stk_size,\n-          args->tls_addr, args->tls_size);\n-}\n-\n-void ThreadContext::OnFinished() {\n-#if SANITIZER_GO\n-  internal_free(thr->shadow_stack);\n-  thr->shadow_stack = nullptr;\n-  thr->shadow_stack_pos = nullptr;\n-  thr->shadow_stack_end = nullptr;\n-#endif\n-  if (!detached) {\n-    thr->fast_state.IncrementEpoch();\n-    // Can't increment epoch w/o writing to the trace as well.\n-    TraceAddEvent(thr, thr->fast_state, EventTypeMop, 0);\n-    ReleaseImpl(thr, 0, &sync);\n-  }\n-  epoch1 = thr->fast_state.epoch();\n-\n-  if (common_flags()->detect_deadlocks)\n-    ctx->dd->DestroyLogicalThread(thr->dd_lt);\n-  thr->clock.ResetCached(&thr->proc()->clock_cache);\n-#if !SANITIZER_GO\n-  thr->last_sleep_clock.ResetCached(&thr->proc()->clock_cache);\n-#endif\n-#if !SANITIZER_GO\n-  PlatformCleanUpThreadState(thr);\n-#endif\n-  thr->~ThreadState();\n-  thr = 0;\n-}\n-\n #if !SANITIZER_GO\n struct ThreadLeak {\n   ThreadContext *tctx;\n   int count;\n };\n \n-static void MaybeReportThreadLeak(ThreadContextBase *tctx_base, void *arg) {\n-  Vector<ThreadLeak> &leaks = *(Vector<ThreadLeak>*)arg;\n-  ThreadContext *tctx = static_cast<ThreadContext*>(tctx_base);\n+static void CollectThreadLeaks(ThreadContextBase *tctx_base, void *arg) {\n+  auto &leaks = *static_cast<Vector<ThreadLeak> *>(arg);\n+  auto *tctx = static_cast<ThreadContext *>(tctx_base);\n   if (tctx->detached || tctx->status != ThreadStatusFinished)\n     return;\n   for (uptr i = 0; i < leaks.Size(); i++) {\n@@ -166,8 +53,7 @@ static void MaybeReportThreadLeak(ThreadContextBase *tctx_base, void *arg) {\n       return;\n     }\n   }\n-  ThreadLeak leak = {tctx, 1};\n-  leaks.PushBack(leak);\n+  leaks.PushBack({tctx, 1});\n }\n #endif\n \n@@ -206,10 +92,10 @@ void ThreadFinalize(ThreadState *thr) {\n #if !SANITIZER_GO\n   if (!ShouldReport(thr, ReportTypeThreadLeak))\n     return;\n-  ThreadRegistryLock l(ctx->thread_registry);\n+  ThreadRegistryLock l(&ctx->thread_registry);\n   Vector<ThreadLeak> leaks;\n-  ctx->thread_registry->RunCallbackForEachThreadLocked(\n-      MaybeReportThreadLeak, &leaks);\n+  ctx->thread_registry.RunCallbackForEachThreadLocked(CollectThreadLeaks,\n+                                                      &leaks);\n   for (uptr i = 0; i < leaks.Size(); i++) {\n     ScopedReport rep(ReportTypeThreadLeak);\n     rep.AddThread(leaks[i].tctx, true);\n@@ -221,20 +107,48 @@ void ThreadFinalize(ThreadState *thr) {\n \n int ThreadCount(ThreadState *thr) {\n   uptr result;\n-  ctx->thread_registry->GetNumberOfThreads(0, 0, &result);\n+  ctx->thread_registry.GetNumberOfThreads(0, 0, &result);\n   return (int)result;\n }\n \n-int ThreadCreate(ThreadState *thr, uptr pc, uptr uid, bool detached) {\n+struct OnCreatedArgs {\n+  ThreadState *thr;\n+  uptr pc;\n+};\n+\n+Tid ThreadCreate(ThreadState *thr, uptr pc, uptr uid, bool detached) {\n   OnCreatedArgs args = { thr, pc };\n   u32 parent_tid = thr ? thr->tid : kInvalidTid;  // No parent for GCD workers.\n-  int tid =\n-      ctx->thread_registry->CreateThread(uid, detached, parent_tid, &args);\n+  Tid tid = ctx->thread_registry.CreateThread(uid, detached, parent_tid, &args);\n   DPrintf(\"#%d: ThreadCreate tid=%d uid=%zu\\n\", parent_tid, tid, uid);\n   return tid;\n }\n \n-void ThreadStart(ThreadState *thr, int tid, tid_t os_id,\n+void ThreadContext::OnCreated(void *arg) {\n+  thr = 0;\n+  if (tid == kMainTid)\n+    return;\n+  OnCreatedArgs *args = static_cast<OnCreatedArgs *>(arg);\n+  if (!args->thr)  // GCD workers don't have a parent thread.\n+    return;\n+  args->thr->fast_state.IncrementEpoch();\n+  // Can't increment epoch w/o writing to the trace as well.\n+  TraceAddEvent(args->thr, args->thr->fast_state, EventTypeMop, 0);\n+  ReleaseImpl(args->thr, 0, &sync);\n+  creation_stack_id = CurrentStackId(args->thr, args->pc);\n+}\n+\n+extern \"C\" void __tsan_stack_initialization() {}\n+\n+struct OnStartedArgs {\n+  ThreadState *thr;\n+  uptr stk_addr;\n+  uptr stk_size;\n+  uptr tls_addr;\n+  uptr tls_size;\n+};\n+\n+void ThreadStart(ThreadState *thr, Tid tid, tid_t os_id,\n                  ThreadType thread_type) {\n   uptr stk_addr = 0;\n   uptr stk_size = 0;\n@@ -244,22 +158,13 @@ void ThreadStart(ThreadState *thr, int tid, tid_t os_id,\n   if (thread_type != ThreadType::Fiber)\n     GetThreadStackAndTls(tid == kMainTid, &stk_addr, &stk_size, &tls_addr,\n                          &tls_size);\n-\n-  if (tid != kMainTid) {\n-    if (stk_addr && stk_size)\n-      MemoryRangeImitateWrite(thr, /*pc=*/ 1, stk_addr, stk_size);\n-\n-    if (tls_addr && tls_size) ImitateTlsWrite(thr, tls_addr, tls_size);\n-  }\n #endif\n \n-  ThreadRegistry *tr = ctx->thread_registry;\n+  ThreadRegistry *tr = &ctx->thread_registry;\n   OnStartedArgs args = { thr, stk_addr, stk_size, tls_addr, tls_size };\n   tr->StartThread(tid, os_id, thread_type, &args);\n \n-  tr->Lock();\n-  thr->tctx = (ThreadContext*)tr->GetThreadLocked(tid);\n-  tr->Unlock();\n+  while (!thr->tctx->trace.parts.Empty()) thr->tctx->trace.parts.PopBack();\n \n #if !SANITIZER_GO\n   if (ctx->after_multithreaded_fork) {\n@@ -268,6 +173,51 @@ void ThreadStart(ThreadState *thr, int tid, tid_t os_id,\n     ThreadIgnoreSyncBegin(thr, 0);\n   }\n #endif\n+\n+#if !SANITIZER_GO\n+  // Don't imitate stack/TLS writes for the main thread,\n+  // because its initialization is synchronized with all\n+  // subsequent threads anyway.\n+  if (tid != kMainTid) {\n+    if (stk_addr && stk_size) {\n+      const uptr pc = StackTrace::GetNextInstructionPc(\n+          reinterpret_cast<uptr>(__tsan_stack_initialization));\n+      MemoryRangeImitateWrite(thr, pc, stk_addr, stk_size);\n+    }\n+\n+    if (tls_addr && tls_size)\n+      ImitateTlsWrite(thr, tls_addr, tls_size);\n+  }\n+#endif\n+}\n+\n+void ThreadContext::OnStarted(void *arg) {\n+  OnStartedArgs *args = static_cast<OnStartedArgs *>(arg);\n+  thr = args->thr;\n+  // RoundUp so that one trace part does not contain events\n+  // from different threads.\n+  epoch0 = RoundUp(epoch1 + 1, kTracePartSize);\n+  epoch1 = (u64)-1;\n+  new (thr)\n+      ThreadState(ctx, tid, unique_id, epoch0, reuse_count, args->stk_addr,\n+                  args->stk_size, args->tls_addr, args->tls_size);\n+  if (common_flags()->detect_deadlocks)\n+    thr->dd_lt = ctx->dd->CreateLogicalThread(unique_id);\n+  thr->fast_state.SetHistorySize(flags()->history_size);\n+  // Commit switch to the new part of the trace.\n+  // TraceAddEvent will reset stack0/mset0 in the new part for us.\n+  TraceAddEvent(thr, thr->fast_state, EventTypeMop, 0);\n+\n+  thr->fast_synch_epoch = epoch0;\n+  AcquireImpl(thr, 0, &sync);\n+  sync.Reset(&thr->proc()->clock_cache);\n+  thr->tctx = this;\n+  thr->is_inited = true;\n+  DPrintf(\n+      \"#%d: ThreadStart epoch=%zu stk_addr=%zx stk_size=%zx \"\n+      \"tls_addr=%zx tls_size=%zx\\n\",\n+      tid, (uptr)epoch0, args->stk_addr, args->stk_size, args->tls_addr,\n+      args->tls_size);\n }\n \n void ThreadFinish(ThreadState *thr) {\n@@ -277,7 +227,34 @@ void ThreadFinish(ThreadState *thr) {\n   if (thr->tls_addr && thr->tls_size)\n     DontNeedShadowFor(thr->tls_addr, thr->tls_size);\n   thr->is_dead = true;\n-  ctx->thread_registry->FinishThread(thr->tid);\n+  ctx->thread_registry.FinishThread(thr->tid);\n+}\n+\n+void ThreadContext::OnFinished() {\n+#if SANITIZER_GO\n+  Free(thr->shadow_stack);\n+  thr->shadow_stack_pos = nullptr;\n+  thr->shadow_stack_end = nullptr;\n+#endif\n+  if (!detached) {\n+    thr->fast_state.IncrementEpoch();\n+    // Can't increment epoch w/o writing to the trace as well.\n+    TraceAddEvent(thr, thr->fast_state, EventTypeMop, 0);\n+    ReleaseImpl(thr, 0, &sync);\n+  }\n+  epoch1 = thr->fast_state.epoch();\n+\n+  if (common_flags()->detect_deadlocks)\n+    ctx->dd->DestroyLogicalThread(thr->dd_lt);\n+  thr->clock.ResetCached(&thr->proc()->clock_cache);\n+#if !SANITIZER_GO\n+  thr->last_sleep_clock.ResetCached(&thr->proc()->clock_cache);\n+#endif\n+#if !SANITIZER_GO\n+  PlatformCleanUpThreadState(thr);\n+#endif\n+  thr->~ThreadState();\n+  thr = 0;\n }\n \n struct ConsumeThreadContext {\n@@ -302,43 +279,56 @@ static bool ConsumeThreadByUid(ThreadContextBase *tctx, void *arg) {\n   return false;\n }\n \n-int ThreadConsumeTid(ThreadState *thr, uptr pc, uptr uid) {\n+Tid ThreadConsumeTid(ThreadState *thr, uptr pc, uptr uid) {\n   ConsumeThreadContext findCtx = {uid, nullptr};\n-  ctx->thread_registry->FindThread(ConsumeThreadByUid, &findCtx);\n-  int tid = findCtx.tctx ? findCtx.tctx->tid : kInvalidTid;\n+  ctx->thread_registry.FindThread(ConsumeThreadByUid, &findCtx);\n+  Tid tid = findCtx.tctx ? findCtx.tctx->tid : kInvalidTid;\n   DPrintf(\"#%d: ThreadTid uid=%zu tid=%d\\n\", thr->tid, uid, tid);\n   return tid;\n }\n \n-void ThreadJoin(ThreadState *thr, uptr pc, int tid) {\n+void ThreadJoin(ThreadState *thr, uptr pc, Tid tid) {\n   CHECK_GT(tid, 0);\n   CHECK_LT(tid, kMaxTid);\n   DPrintf(\"#%d: ThreadJoin tid=%d\\n\", thr->tid, tid);\n-  ctx->thread_registry->JoinThread(tid, thr);\n+  ctx->thread_registry.JoinThread(tid, thr);\n }\n \n-void ThreadDetach(ThreadState *thr, uptr pc, int tid) {\n+void ThreadContext::OnJoined(void *arg) {\n+  ThreadState *caller_thr = static_cast<ThreadState *>(arg);\n+  AcquireImpl(caller_thr, 0, &sync);\n+  sync.Reset(&caller_thr->proc()->clock_cache);\n+}\n+\n+void ThreadContext::OnDead() { CHECK_EQ(sync.size(), 0); }\n+\n+void ThreadDetach(ThreadState *thr, uptr pc, Tid tid) {\n   CHECK_GT(tid, 0);\n   CHECK_LT(tid, kMaxTid);\n-  ctx->thread_registry->DetachThread(tid, thr);\n+  ctx->thread_registry.DetachThread(tid, thr);\n+}\n+\n+void ThreadContext::OnDetached(void *arg) {\n+  ThreadState *thr1 = static_cast<ThreadState *>(arg);\n+  sync.Reset(&thr1->proc()->clock_cache);\n }\n \n-void ThreadNotJoined(ThreadState *thr, uptr pc, int tid, uptr uid) {\n+void ThreadNotJoined(ThreadState *thr, uptr pc, Tid tid, uptr uid) {\n   CHECK_GT(tid, 0);\n   CHECK_LT(tid, kMaxTid);\n-  ctx->thread_registry->SetThreadUserId(tid, uid);\n+  ctx->thread_registry.SetThreadUserId(tid, uid);\n }\n \n void ThreadSetName(ThreadState *thr, const char *name) {\n-  ctx->thread_registry->SetThreadName(thr->tid, name);\n+  ctx->thread_registry.SetThreadName(thr->tid, name);\n }\n \n void MemoryAccessRange(ThreadState *thr, uptr pc, uptr addr,\n                        uptr size, bool is_write) {\n   if (size == 0)\n     return;\n \n-  u64 *shadow_mem = (u64*)MemToShadow(addr);\n+  RawShadow *shadow_mem = MemToShadow(addr);\n   DPrintf2(\"#%d: MemoryAccessRange: @%p %p size=%d is_write=%d\\n\",\n       thr->tid, (void*)pc, (void*)addr,\n       (int)size, is_write);\n@@ -352,14 +342,14 @@ void MemoryAccessRange(ThreadState *thr, uptr pc, uptr addr,\n     Printf(\"Access to non app mem %zx\\n\", addr + size - 1);\n     DCHECK(IsAppMem(addr + size - 1));\n   }\n-  if (!IsShadowMem((uptr)shadow_mem)) {\n+  if (!IsShadowMem(shadow_mem)) {\n     Printf(\"Bad shadow addr %p (%zx)\\n\", shadow_mem, addr);\n-    DCHECK(IsShadowMem((uptr)shadow_mem));\n+    DCHECK(IsShadowMem(shadow_mem));\n   }\n-  if (!IsShadowMem((uptr)(shadow_mem + size * kShadowCnt / 8 - 1))) {\n+  if (!IsShadowMem(shadow_mem + size * kShadowCnt / 8 - 1)) {\n     Printf(\"Bad shadow addr %p (%zx)\\n\",\n                shadow_mem + size * kShadowCnt / 8 - 1, addr + size - 1);\n-    DCHECK(IsShadowMem((uptr)(shadow_mem + size * kShadowCnt / 8 - 1)));\n+    DCHECK(IsShadowMem(shadow_mem + size * kShadowCnt / 8 - 1));\n   }\n #endif\n \n@@ -421,10 +411,10 @@ void FiberSwitchImpl(ThreadState *from, ThreadState *to) {\n }\n \n ThreadState *FiberCreate(ThreadState *thr, uptr pc, unsigned flags) {\n-  void *mem = internal_alloc(MBlockThreadContex, sizeof(ThreadState));\n+  void *mem = Alloc(sizeof(ThreadState));\n   ThreadState *fiber = static_cast<ThreadState *>(mem);\n   internal_memset(fiber, 0, sizeof(*fiber));\n-  int tid = ThreadCreate(thr, pc, 0, true);\n+  Tid tid = ThreadCreate(thr, pc, 0, true);\n   FiberSwitchImpl(thr, fiber);\n   ThreadStart(fiber, tid, 0, ThreadType::Fiber);\n   FiberSwitchImpl(fiber, thr);\n@@ -435,7 +425,7 @@ void FiberDestroy(ThreadState *thr, uptr pc, ThreadState *fiber) {\n   FiberSwitchImpl(thr, fiber);\n   ThreadFinish(fiber);\n   FiberSwitchImpl(fiber, thr);\n-  internal_free(fiber);\n+  Free(fiber);\n }\n \n void FiberSwitch(ThreadState *thr, uptr pc,"}, {"sha": "8b7bc341713e87ed0c440761b376ec9855fcf40d", "filename": "libsanitizer/tsan/tsan_shadow.h", "status": "added", "additions": 233, "deletions": 0, "changes": 233, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_shadow.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_shadow.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_shadow.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -0,0 +1,233 @@\n+//===-- tsan_shadow.h -------------------------------------------*- C++ -*-===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+\n+#ifndef TSAN_SHADOW_H\n+#define TSAN_SHADOW_H\n+\n+#include \"tsan_defs.h\"\n+#include \"tsan_trace.h\"\n+\n+namespace __tsan {\n+\n+// FastState (from most significant bit):\n+//   ignore          : 1\n+//   tid             : kTidBits\n+//   unused          : -\n+//   history_size    : 3\n+//   epoch           : kClkBits\n+class FastState {\n+ public:\n+  FastState(u64 tid, u64 epoch) {\n+    x_ = tid << kTidShift;\n+    x_ |= epoch;\n+    DCHECK_EQ(tid, this->tid());\n+    DCHECK_EQ(epoch, this->epoch());\n+    DCHECK_EQ(GetIgnoreBit(), false);\n+  }\n+\n+  explicit FastState(u64 x) : x_(x) {}\n+\n+  u64 raw() const { return x_; }\n+\n+  u64 tid() const {\n+    u64 res = (x_ & ~kIgnoreBit) >> kTidShift;\n+    return res;\n+  }\n+\n+  u64 TidWithIgnore() const {\n+    u64 res = x_ >> kTidShift;\n+    return res;\n+  }\n+\n+  u64 epoch() const {\n+    u64 res = x_ & ((1ull << kClkBits) - 1);\n+    return res;\n+  }\n+\n+  void IncrementEpoch() {\n+    u64 old_epoch = epoch();\n+    x_ += 1;\n+    DCHECK_EQ(old_epoch + 1, epoch());\n+    (void)old_epoch;\n+  }\n+\n+  void SetIgnoreBit() { x_ |= kIgnoreBit; }\n+  void ClearIgnoreBit() { x_ &= ~kIgnoreBit; }\n+  bool GetIgnoreBit() const { return (s64)x_ < 0; }\n+\n+  void SetHistorySize(int hs) {\n+    CHECK_GE(hs, 0);\n+    CHECK_LE(hs, 7);\n+    x_ = (x_ & ~(kHistoryMask << kHistoryShift)) | (u64(hs) << kHistoryShift);\n+  }\n+\n+  ALWAYS_INLINE\n+  int GetHistorySize() const {\n+    return (int)((x_ >> kHistoryShift) & kHistoryMask);\n+  }\n+\n+  void ClearHistorySize() { SetHistorySize(0); }\n+\n+  ALWAYS_INLINE\n+  u64 GetTracePos() const {\n+    const int hs = GetHistorySize();\n+    // When hs == 0, the trace consists of 2 parts.\n+    const u64 mask = (1ull << (kTracePartSizeBits + hs + 1)) - 1;\n+    return epoch() & mask;\n+  }\n+\n+ private:\n+  friend class Shadow;\n+  static const int kTidShift = 64 - kTidBits - 1;\n+  static const u64 kIgnoreBit = 1ull << 63;\n+  static const u64 kFreedBit = 1ull << 63;\n+  static const u64 kHistoryShift = kClkBits;\n+  static const u64 kHistoryMask = 7;\n+  u64 x_;\n+};\n+\n+// Shadow (from most significant bit):\n+//   freed           : 1\n+//   tid             : kTidBits\n+//   is_atomic       : 1\n+//   is_read         : 1\n+//   size_log        : 2\n+//   addr0           : 3\n+//   epoch           : kClkBits\n+class Shadow : public FastState {\n+ public:\n+  explicit Shadow(u64 x) : FastState(x) {}\n+\n+  explicit Shadow(const FastState &s) : FastState(s.x_) { ClearHistorySize(); }\n+\n+  void SetAddr0AndSizeLog(u64 addr0, unsigned kAccessSizeLog) {\n+    DCHECK_EQ((x_ >> kClkBits) & 31, 0);\n+    DCHECK_LE(addr0, 7);\n+    DCHECK_LE(kAccessSizeLog, 3);\n+    x_ |= ((kAccessSizeLog << 3) | addr0) << kClkBits;\n+    DCHECK_EQ(kAccessSizeLog, size_log());\n+    DCHECK_EQ(addr0, this->addr0());\n+  }\n+\n+  void SetWrite(unsigned kAccessIsWrite) {\n+    DCHECK_EQ(x_ & kReadBit, 0);\n+    if (!kAccessIsWrite)\n+      x_ |= kReadBit;\n+    DCHECK_EQ(kAccessIsWrite, IsWrite());\n+  }\n+\n+  void SetAtomic(bool kIsAtomic) {\n+    DCHECK(!IsAtomic());\n+    if (kIsAtomic)\n+      x_ |= kAtomicBit;\n+    DCHECK_EQ(IsAtomic(), kIsAtomic);\n+  }\n+\n+  bool IsAtomic() const { return x_ & kAtomicBit; }\n+\n+  bool IsZero() const { return x_ == 0; }\n+\n+  static inline bool TidsAreEqual(const Shadow s1, const Shadow s2) {\n+    u64 shifted_xor = (s1.x_ ^ s2.x_) >> kTidShift;\n+    DCHECK_EQ(shifted_xor == 0, s1.TidWithIgnore() == s2.TidWithIgnore());\n+    return shifted_xor == 0;\n+  }\n+\n+  static ALWAYS_INLINE bool Addr0AndSizeAreEqual(const Shadow s1,\n+                                                 const Shadow s2) {\n+    u64 masked_xor = ((s1.x_ ^ s2.x_) >> kClkBits) & 31;\n+    return masked_xor == 0;\n+  }\n+\n+  static ALWAYS_INLINE bool TwoRangesIntersect(Shadow s1, Shadow s2,\n+                                               unsigned kS2AccessSize) {\n+    bool res = false;\n+    u64 diff = s1.addr0() - s2.addr0();\n+    if ((s64)diff < 0) {  // s1.addr0 < s2.addr0\n+      // if (s1.addr0() + size1) > s2.addr0()) return true;\n+      if (s1.size() > -diff)\n+        res = true;\n+    } else {\n+      // if (s2.addr0() + kS2AccessSize > s1.addr0()) return true;\n+      if (kS2AccessSize > diff)\n+        res = true;\n+    }\n+    DCHECK_EQ(res, TwoRangesIntersectSlow(s1, s2));\n+    DCHECK_EQ(res, TwoRangesIntersectSlow(s2, s1));\n+    return res;\n+  }\n+\n+  u64 ALWAYS_INLINE addr0() const { return (x_ >> kClkBits) & 7; }\n+  u64 ALWAYS_INLINE size() const { return 1ull << size_log(); }\n+  bool ALWAYS_INLINE IsWrite() const { return !IsRead(); }\n+  bool ALWAYS_INLINE IsRead() const { return x_ & kReadBit; }\n+\n+  // The idea behind the freed bit is as follows.\n+  // When the memory is freed (or otherwise unaccessible) we write to the shadow\n+  // values with tid/epoch related to the free and the freed bit set.\n+  // During memory accesses processing the freed bit is considered\n+  // as msb of tid. So any access races with shadow with freed bit set\n+  // (it is as if write from a thread with which we never synchronized before).\n+  // This allows us to detect accesses to freed memory w/o additional\n+  // overheads in memory access processing and at the same time restore\n+  // tid/epoch of free.\n+  void MarkAsFreed() { x_ |= kFreedBit; }\n+\n+  bool IsFreed() const { return x_ & kFreedBit; }\n+\n+  bool GetFreedAndReset() {\n+    bool res = x_ & kFreedBit;\n+    x_ &= ~kFreedBit;\n+    return res;\n+  }\n+\n+  bool ALWAYS_INLINE IsBothReadsOrAtomic(bool kIsWrite, bool kIsAtomic) const {\n+    bool v = x_ & ((u64(kIsWrite ^ 1) << kReadShift) |\n+                   (u64(kIsAtomic) << kAtomicShift));\n+    DCHECK_EQ(v, (!IsWrite() && !kIsWrite) || (IsAtomic() && kIsAtomic));\n+    return v;\n+  }\n+\n+  bool ALWAYS_INLINE IsRWNotWeaker(bool kIsWrite, bool kIsAtomic) const {\n+    bool v = ((x_ >> kReadShift) & 3) <= u64((kIsWrite ^ 1) | (kIsAtomic << 1));\n+    DCHECK_EQ(v, (IsAtomic() < kIsAtomic) ||\n+                     (IsAtomic() == kIsAtomic && !IsWrite() <= !kIsWrite));\n+    return v;\n+  }\n+\n+  bool ALWAYS_INLINE IsRWWeakerOrEqual(bool kIsWrite, bool kIsAtomic) const {\n+    bool v = ((x_ >> kReadShift) & 3) >= u64((kIsWrite ^ 1) | (kIsAtomic << 1));\n+    DCHECK_EQ(v, (IsAtomic() > kIsAtomic) ||\n+                     (IsAtomic() == kIsAtomic && !IsWrite() >= !kIsWrite));\n+    return v;\n+  }\n+\n+ private:\n+  static const u64 kReadShift = 5 + kClkBits;\n+  static const u64 kReadBit = 1ull << kReadShift;\n+  static const u64 kAtomicShift = 6 + kClkBits;\n+  static const u64 kAtomicBit = 1ull << kAtomicShift;\n+\n+  u64 size_log() const { return (x_ >> (3 + kClkBits)) & 3; }\n+\n+  static bool TwoRangesIntersectSlow(const Shadow s1, const Shadow s2) {\n+    if (s1.addr0() == s2.addr0())\n+      return true;\n+    if (s1.addr0() < s2.addr0() && s1.addr0() + s1.size() > s2.addr0())\n+      return true;\n+    if (s2.addr0() < s1.addr0() && s2.addr0() + s2.size() > s1.addr0())\n+      return true;\n+    return false;\n+  }\n+};\n+\n+const RawShadow kShadowRodata = (RawShadow)-1;  // .rodata shadow marker\n+\n+}  // namespace __tsan\n+\n+#endif"}, {"sha": "9bbaafb3a85f595a9b37439f0a4dd45e6e54a774", "filename": "libsanitizer/tsan/tsan_stack_trace.cpp", "status": "modified", "additions": 4, "deletions": 8, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_stack_trace.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_stack_trace.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_stack_trace.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -23,14 +23,10 @@ VarSizeStackTrace::~VarSizeStackTrace() {\n }\n \n void VarSizeStackTrace::ResizeBuffer(uptr new_size) {\n-  if (trace_buffer) {\n-    internal_free(trace_buffer);\n-  }\n-  trace_buffer =\n-      (new_size > 0)\n-          ? (uptr *)internal_alloc(MBlockStackTrace,\n-                                   new_size * sizeof(trace_buffer[0]))\n-          : nullptr;\n+  Free(trace_buffer);\n+  trace_buffer = (new_size > 0)\n+                     ? (uptr *)Alloc(new_size * sizeof(trace_buffer[0]))\n+                     : nullptr;\n   trace = trace_buffer;\n   size = new_size;\n }"}, {"sha": "2e2744d2eae782943fd68ec932c9795224a2ebc9", "filename": "libsanitizer/tsan/tsan_symbolize.cpp", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_symbolize.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_symbolize.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_symbolize.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -110,7 +110,8 @@ ReportLocation *SymbolizeData(uptr addr) {\n   DataInfo info;\n   if (!Symbolizer::GetOrInit()->SymbolizeData(addr, &info))\n     return 0;\n-  ReportLocation *ent = ReportLocation::New(ReportLocationGlobal);\n+  auto *ent = New<ReportLocation>();\n+  ent->type = ReportLocationGlobal;\n   internal_memcpy(&ent->global, &info, sizeof(info));\n   return ent;\n }"}, {"sha": "f042abab74e5ebdaa46d38e38dcd25f52caabd76", "filename": "libsanitizer/tsan/tsan_sync.cpp", "status": "modified", "additions": 22, "deletions": 36, "changes": 58, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_sync.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_sync.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_sync.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -20,21 +20,22 @@ void DDMutexInit(ThreadState *thr, uptr pc, SyncVar *s);\n \n SyncVar::SyncVar() : mtx(MutexTypeSyncVar) { Reset(0); }\n \n-void SyncVar::Init(ThreadState *thr, uptr pc, uptr addr, u64 uid) {\n+void SyncVar::Init(ThreadState *thr, uptr pc, uptr addr, u64 uid,\n+                   bool save_stack) {\n   this->addr = addr;\n   this->uid = uid;\n   this->next = 0;\n \n-  creation_stack_id = 0;\n-  if (!SANITIZER_GO)  // Go does not use them\n+  creation_stack_id = kInvalidStackID;\n+  if (save_stack && !SANITIZER_GO)  // Go does not use them\n     creation_stack_id = CurrentStackId(thr, pc);\n   if (common_flags()->detect_deadlocks)\n     DDMutexInit(thr, pc, this);\n }\n \n void SyncVar::Reset(Processor *proc) {\n   uid = 0;\n-  creation_stack_id = 0;\n+  creation_stack_id = kInvalidStackID;\n   owner_tid = kInvalidTid;\n   last_lock = 0;\n   recursion = 0;\n@@ -190,63 +191,41 @@ MBlock* MetaMap::GetBlock(uptr p) {\n   }\n }\n \n-SyncVar* MetaMap::GetOrCreateAndLock(ThreadState *thr, uptr pc,\n-                              uptr addr, bool write_lock) {\n-  return GetAndLock(thr, pc, addr, write_lock, true);\n-}\n-\n-SyncVar* MetaMap::GetIfExistsAndLock(uptr addr, bool write_lock) {\n-  return GetAndLock(0, 0, addr, write_lock, false);\n-}\n-\n-SyncVar* MetaMap::GetAndLock(ThreadState *thr, uptr pc,\n-                             uptr addr, bool write_lock, bool create) {\n+SyncVar *MetaMap::GetSync(ThreadState *thr, uptr pc, uptr addr, bool create,\n+                          bool save_stack) {\n   u32 *meta = MemToMeta(addr);\n   u32 idx0 = *meta;\n   u32 myidx = 0;\n-  SyncVar *mys = 0;\n+  SyncVar *mys = nullptr;\n   for (;;) {\n-    u32 idx = idx0;\n-    for (;;) {\n-      if (idx == 0)\n-        break;\n-      if (idx & kFlagBlock)\n-        break;\n+    for (u32 idx = idx0; idx && !(idx & kFlagBlock);) {\n       DCHECK(idx & kFlagSync);\n       SyncVar * s = sync_alloc_.Map(idx & ~kFlagMask);\n-      if (s->addr == addr) {\n-        if (myidx != 0) {\n+      if (LIKELY(s->addr == addr)) {\n+        if (UNLIKELY(myidx != 0)) {\n           mys->Reset(thr->proc());\n           sync_alloc_.Free(&thr->proc()->sync_cache, myidx);\n         }\n-        if (write_lock)\n-          s->mtx.Lock();\n-        else\n-          s->mtx.ReadLock();\n         return s;\n       }\n       idx = s->next;\n     }\n     if (!create)\n-      return 0;\n-    if (*meta != idx0) {\n+      return nullptr;\n+    if (UNLIKELY(*meta != idx0)) {\n       idx0 = *meta;\n       continue;\n     }\n \n-    if (myidx == 0) {\n+    if (LIKELY(myidx == 0)) {\n       const u64 uid = atomic_fetch_add(&uid_gen_, 1, memory_order_relaxed);\n       myidx = sync_alloc_.Alloc(&thr->proc()->sync_cache);\n       mys = sync_alloc_.Map(myidx);\n-      mys->Init(thr, pc, addr, uid);\n+      mys->Init(thr, pc, addr, uid, save_stack);\n     }\n     mys->next = idx0;\n     if (atomic_compare_exchange_strong((atomic_uint32_t*)meta, &idx0,\n         myidx | kFlagSync, memory_order_release)) {\n-      if (write_lock)\n-        mys->mtx.Lock();\n-      else\n-        mys->mtx.ReadLock();\n       return mys;\n     }\n   }\n@@ -290,4 +269,11 @@ void MetaMap::OnProcIdle(Processor *proc) {\n   sync_alloc_.FlushCache(&proc->sync_cache);\n }\n \n+MetaMap::MemoryStats MetaMap::GetMemoryStats() const {\n+  MemoryStats stats;\n+  stats.mem_block = block_alloc_.AllocatedMemory();\n+  stats.sync_obj = sync_alloc_.AllocatedMemory();\n+  return stats;\n+}\n+\n }  // namespace __tsan"}, {"sha": "fc8fa288a841808cb52f78c7d0f6062a6c2b770e", "filename": "libsanitizer/tsan/tsan_sync.h", "status": "modified", "additions": 23, "deletions": 13, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_sync.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_sync.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_sync.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -17,7 +17,6 @@\n #include \"sanitizer_common/sanitizer_deadlock_detector_interface.h\"\n #include \"tsan_defs.h\"\n #include \"tsan_clock.h\"\n-#include \"tsan_mutex.h\"\n #include \"tsan_dense_alloc.h\"\n \n namespace __tsan {\n@@ -47,14 +46,16 @@ enum MutexFlags {\n                                  MutexFlagNotStatic,\n };\n \n+// SyncVar is a descriptor of a user synchronization object\n+// (mutex or an atomic variable).\n struct SyncVar {\n   SyncVar();\n \n   uptr addr;  // overwritten by DenseSlabAlloc freelist\n   Mutex mtx;\n   u64 uid;  // Globally unique id.\n-  u32 creation_stack_id;\n-  u32 owner_tid;  // Set only by exclusive owners.\n+  StackID creation_stack_id;\n+  Tid owner_tid;  // Set only by exclusive owners.\n   u64 last_lock;\n   int recursion;\n   atomic_uint32_t flags;\n@@ -65,7 +66,7 @@ struct SyncVar {\n   // with the mtx. This reduces contention for hot sync objects.\n   SyncClock clock;\n \n-  void Init(ThreadState *thr, uptr pc, uptr addr, u64 uid);\n+  void Init(ThreadState *thr, uptr pc, uptr addr, u64 uid, bool save_stack);\n   void Reset(Processor *proc);\n \n   u64 GetId() const {\n@@ -102,10 +103,8 @@ struct SyncVar {\n   }\n };\n \n-/* MetaMap allows to map arbitrary user pointers onto various descriptors.\n-   Currently it maps pointers to heap block descriptors and sync var descs.\n-   It uses 1/2 direct shadow, see tsan_platform.h.\n-*/\n+// MetaMap maps app addresses to heap block (MBlock) and sync var (SyncVar)\n+// descriptors. It uses 1/2 direct shadow, see tsan_platform.h for the mapping.\n class MetaMap {\n  public:\n   MetaMap();\n@@ -116,14 +115,25 @@ class MetaMap {\n   void ResetRange(Processor *proc, uptr p, uptr sz);\n   MBlock* GetBlock(uptr p);\n \n-  SyncVar* GetOrCreateAndLock(ThreadState *thr, uptr pc,\n-                              uptr addr, bool write_lock);\n-  SyncVar* GetIfExistsAndLock(uptr addr, bool write_lock);\n+  SyncVar *GetSyncOrCreate(ThreadState *thr, uptr pc, uptr addr,\n+                           bool save_stack) {\n+    return GetSync(thr, pc, addr, true, save_stack);\n+  }\n+  SyncVar *GetSyncIfExists(uptr addr) {\n+    return GetSync(nullptr, 0, addr, false, false);\n+  }\n \n   void MoveMemory(uptr src, uptr dst, uptr sz);\n \n   void OnProcIdle(Processor *proc);\n \n+  struct MemoryStats {\n+    uptr mem_block;\n+    uptr sync_obj;\n+  };\n+\n+  MemoryStats GetMemoryStats() const;\n+\n  private:\n   static const u32 kFlagMask  = 3u << 30;\n   static const u32 kFlagBlock = 1u << 30;\n@@ -134,8 +144,8 @@ class MetaMap {\n   SyncAlloc sync_alloc_;\n   atomic_uint64_t uid_gen_;\n \n-  SyncVar* GetAndLock(ThreadState *thr, uptr pc, uptr addr, bool write_lock,\n-                      bool create);\n+  SyncVar *GetSync(ThreadState *thr, uptr pc, uptr addr, bool create,\n+                   bool save_stack);\n };\n \n }  // namespace __tsan"}, {"sha": "a771ad9f52fd3c2da55d9ee444caf467b89aa54e", "filename": "libsanitizer/tsan/tsan_trace.h", "status": "modified", "additions": 151, "deletions": 2, "changes": 153, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_trace.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_trace.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_trace.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -13,9 +13,9 @@\n #define TSAN_TRACE_H\n \n #include \"tsan_defs.h\"\n-#include \"tsan_mutex.h\"\n-#include \"tsan_stack_trace.h\"\n+#include \"tsan_ilist.h\"\n #include \"tsan_mutexset.h\"\n+#include \"tsan_stack_trace.h\"\n \n namespace __tsan {\n \n@@ -68,6 +68,155 @@ struct Trace {\n   Trace() : mtx(MutexTypeTrace) {}\n };\n \n+namespace v3 {\n+\n+enum class EventType : u64 {\n+  kAccessExt,\n+  kAccessRange,\n+  kLock,\n+  kRLock,\n+  kUnlock,\n+  kTime,\n+};\n+\n+// \"Base\" type for all events for type dispatch.\n+struct Event {\n+  // We use variable-length type encoding to give more bits to some event\n+  // types that need them. If is_access is set, this is EventAccess.\n+  // Otherwise, if is_func is set, this is EventFunc.\n+  // Otherwise type denotes the type.\n+  u64 is_access : 1;\n+  u64 is_func : 1;\n+  EventType type : 3;\n+  u64 _ : 59;\n+};\n+static_assert(sizeof(Event) == 8, \"bad Event size\");\n+\n+// Nop event used as padding and does not affect state during replay.\n+static constexpr Event NopEvent = {1, 0, EventType::kAccessExt, 0};\n+\n+// Compressed memory access can represent only some events with PCs\n+// close enough to each other. Otherwise we fall back to EventAccessExt.\n+struct EventAccess {\n+  static constexpr uptr kPCBits = 15;\n+\n+  u64 is_access : 1;  // = 1\n+  u64 is_read : 1;\n+  u64 is_atomic : 1;\n+  u64 size_log : 2;\n+  u64 pc_delta : kPCBits;  // signed delta from the previous memory access PC\n+  u64 addr : kCompressedAddrBits;\n+};\n+static_assert(sizeof(EventAccess) == 8, \"bad EventAccess size\");\n+\n+// Function entry (pc != 0) or exit (pc == 0).\n+struct EventFunc {\n+  u64 is_access : 1;  // = 0\n+  u64 is_func : 1;    // = 1\n+  u64 pc : 62;\n+};\n+static_assert(sizeof(EventFunc) == 8, \"bad EventFunc size\");\n+\n+// Extended memory access with full PC.\n+struct EventAccessExt {\n+  u64 is_access : 1;   // = 0\n+  u64 is_func : 1;     // = 0\n+  EventType type : 3;  // = EventType::kAccessExt\n+  u64 is_read : 1;\n+  u64 is_atomic : 1;\n+  u64 size_log : 2;\n+  u64 _ : 11;\n+  u64 addr : kCompressedAddrBits;\n+  u64 pc;\n+};\n+static_assert(sizeof(EventAccessExt) == 16, \"bad EventAccessExt size\");\n+\n+// Access to a memory range.\n+struct EventAccessRange {\n+  static constexpr uptr kSizeLoBits = 13;\n+\n+  u64 is_access : 1;   // = 0\n+  u64 is_func : 1;     // = 0\n+  EventType type : 3;  // = EventType::kAccessRange\n+  u64 is_read : 1;\n+  u64 is_free : 1;\n+  u64 size_lo : kSizeLoBits;\n+  u64 pc : kCompressedAddrBits;\n+  u64 addr : kCompressedAddrBits;\n+  u64 size_hi : 64 - kCompressedAddrBits;\n+};\n+static_assert(sizeof(EventAccessRange) == 16, \"bad EventAccessRange size\");\n+\n+// Mutex lock.\n+struct EventLock {\n+  static constexpr uptr kStackIDLoBits = 15;\n+\n+  u64 is_access : 1;   // = 0\n+  u64 is_func : 1;     // = 0\n+  EventType type : 3;  // = EventType::kLock or EventType::kRLock\n+  u64 pc : kCompressedAddrBits;\n+  u64 stack_lo : kStackIDLoBits;\n+  u64 stack_hi : sizeof(StackID) * kByteBits - kStackIDLoBits;\n+  u64 _ : 3;\n+  u64 addr : kCompressedAddrBits;\n+};\n+static_assert(sizeof(EventLock) == 16, \"bad EventLock size\");\n+\n+// Mutex unlock.\n+struct EventUnlock {\n+  u64 is_access : 1;   // = 0\n+  u64 is_func : 1;     // = 0\n+  EventType type : 3;  // = EventType::kUnlock\n+  u64 _ : 15;\n+  u64 addr : kCompressedAddrBits;\n+};\n+static_assert(sizeof(EventUnlock) == 8, \"bad EventUnlock size\");\n+\n+// Time change event.\n+struct EventTime {\n+  u64 is_access : 1;   // = 0\n+  u64 is_func : 1;     // = 0\n+  EventType type : 3;  // = EventType::kTime\n+  u64 sid : sizeof(Sid) * kByteBits;\n+  u64 epoch : kEpochBits;\n+  u64 _ : 64 - 5 - sizeof(Sid) * kByteBits - kEpochBits;\n+};\n+static_assert(sizeof(EventTime) == 8, \"bad EventTime size\");\n+\n+struct Trace;\n+\n+struct TraceHeader {\n+  Trace* trace = nullptr;  // back-pointer to Trace containing this part\n+  INode trace_parts;       // in Trace::parts\n+};\n+\n+struct TracePart : TraceHeader {\n+  static constexpr uptr kByteSize = 256 << 10;\n+  static constexpr uptr kSize =\n+      (kByteSize - sizeof(TraceHeader)) / sizeof(Event);\n+  // TraceAcquire does a fast event pointer overflow check by comparing\n+  // pointer into TracePart::events with kAlignment mask. Since TracePart's\n+  // are allocated page-aligned, this check detects end of the array\n+  // (it also have false positives in the middle that are filtered separately).\n+  // This also requires events to be the last field.\n+  static constexpr uptr kAlignment = 0xff0;\n+  Event events[kSize];\n+\n+  TracePart() {}\n+};\n+static_assert(sizeof(TracePart) == TracePart::kByteSize, \"bad TracePart size\");\n+\n+struct Trace {\n+  Mutex mtx;\n+  IList<TraceHeader, &TraceHeader::trace_parts, TracePart> parts;\n+  Event* final_pos =\n+      nullptr;  // final position in the last part for finished threads\n+\n+  Trace() : mtx(MutexTypeTrace) {}\n+};\n+\n+}  // namespace v3\n+\n }  // namespace __tsan\n \n #endif  // TSAN_TRACE_H"}, {"sha": "a58ef0f17efa197bc2e6d9f253c7d0b8d3a509ca", "filename": "libsanitizer/tsan/tsan_update_shadow_word.inc", "status": "renamed", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_update_shadow_word.inc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_update_shadow_word.inc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_update_shadow_word.inc?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -1,4 +1,4 @@\n-//===-- tsan_update_shadow_word_inl.h ---------------------------*- C++ -*-===//\n+//===-- tsan_update_shadow_word.inc -----------------------------*- C++ -*-===//\n //\n // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n // See https://llvm.org/LICENSE.txt for license information.", "previous_filename": "libsanitizer/tsan/tsan_update_shadow_word_inl.h"}, {"sha": "278298565d3f8dd1ff26bf496ab254ebe16193d0", "filename": "libsanitizer/tsan/tsan_vector_clock.cpp", "status": "added", "additions": 126, "deletions": 0, "changes": 126, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_vector_clock.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_vector_clock.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_vector_clock.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61", "patch": "@@ -0,0 +1,126 @@\n+//===-- tsan_vector_clock.cpp ---------------------------------------------===//\n+//\n+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n+// See https://llvm.org/LICENSE.txt for license information.\n+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n+//\n+//===----------------------------------------------------------------------===//\n+//\n+// This file is a part of ThreadSanitizer (TSan), a race detector.\n+//\n+//===----------------------------------------------------------------------===//\n+#include \"tsan_vector_clock.h\"\n+\n+#include \"sanitizer_common/sanitizer_placement_new.h\"\n+#include \"tsan_mman.h\"\n+\n+namespace __tsan {\n+\n+#if TSAN_VECTORIZE\n+const uptr kVectorClockSize = kThreadSlotCount * sizeof(Epoch) / sizeof(m128);\n+#endif\n+\n+VectorClock::VectorClock() { Reset(); }\n+\n+void VectorClock::Reset() {\n+#if !TSAN_VECTORIZE\n+  for (uptr i = 0; i < kThreadSlotCount; i++)\n+    clk_[i] = kEpochZero;\n+#else\n+  m128 z = _mm_setzero_si128();\n+  m128* vclk = reinterpret_cast<m128*>(clk_);\n+  for (uptr i = 0; i < kVectorClockSize; i++) _mm_store_si128(&vclk[i], z);\n+#endif\n+}\n+\n+void VectorClock::Acquire(const VectorClock* src) {\n+  if (!src)\n+    return;\n+#if !TSAN_VECTORIZE\n+  for (uptr i = 0; i < kThreadSlotCount; i++)\n+    clk_[i] = max(clk_[i], src->clk_[i]);\n+#else\n+  m128* __restrict vdst = reinterpret_cast<m128*>(clk_);\n+  m128 const* __restrict vsrc = reinterpret_cast<m128 const*>(src->clk_);\n+  for (uptr i = 0; i < kVectorClockSize; i++) {\n+    m128 s = _mm_load_si128(&vsrc[i]);\n+    m128 d = _mm_load_si128(&vdst[i]);\n+    m128 m = _mm_max_epu16(s, d);\n+    _mm_store_si128(&vdst[i], m);\n+  }\n+#endif\n+}\n+\n+static VectorClock* AllocClock(VectorClock** dstp) {\n+  if (UNLIKELY(!*dstp))\n+    *dstp = New<VectorClock>();\n+  return *dstp;\n+}\n+\n+void VectorClock::Release(VectorClock** dstp) const {\n+  VectorClock* dst = AllocClock(dstp);\n+  dst->Acquire(this);\n+}\n+\n+void VectorClock::ReleaseStore(VectorClock** dstp) const {\n+  VectorClock* dst = AllocClock(dstp);\n+  *dst = *this;\n+}\n+\n+VectorClock& VectorClock::operator=(const VectorClock& other) {\n+#if !TSAN_VECTORIZE\n+  for (uptr i = 0; i < kThreadSlotCount; i++)\n+    clk_[i] = other.clk_[i];\n+#else\n+  m128* __restrict vdst = reinterpret_cast<m128*>(clk_);\n+  m128 const* __restrict vsrc = reinterpret_cast<m128 const*>(other.clk_);\n+  for (uptr i = 0; i < kVectorClockSize; i++) {\n+    m128 s = _mm_load_si128(&vsrc[i]);\n+    _mm_store_si128(&vdst[i], s);\n+  }\n+#endif\n+  return *this;\n+}\n+\n+void VectorClock::ReleaseStoreAcquire(VectorClock** dstp) {\n+  VectorClock* dst = AllocClock(dstp);\n+#if !TSAN_VECTORIZE\n+  for (uptr i = 0; i < kThreadSlotCount; i++) {\n+    Epoch tmp = dst->clk_[i];\n+    dst->clk_[i] = clk_[i];\n+    clk_[i] = max(clk_[i], tmp);\n+  }\n+#else\n+  m128* __restrict vdst = reinterpret_cast<m128*>(dst->clk_);\n+  m128* __restrict vclk = reinterpret_cast<m128*>(clk_);\n+  for (uptr i = 0; i < kVectorClockSize; i++) {\n+    m128 t = _mm_load_si128(&vdst[i]);\n+    m128 c = _mm_load_si128(&vclk[i]);\n+    m128 m = _mm_max_epu16(c, t);\n+    _mm_store_si128(&vdst[i], c);\n+    _mm_store_si128(&vclk[i], m);\n+  }\n+#endif\n+}\n+\n+void VectorClock::ReleaseAcquire(VectorClock** dstp) {\n+  VectorClock* dst = AllocClock(dstp);\n+#if !TSAN_VECTORIZE\n+  for (uptr i = 0; i < kThreadSlotCount; i++) {\n+    dst->clk_[i] = max(dst->clk_[i], clk_[i]);\n+    clk_[i] = dst->clk_[i];\n+  }\n+#else\n+  m128* __restrict vdst = reinterpret_cast<m128*>(dst->clk_);\n+  m128* __restrict vclk = reinterpret_cast<m128*>(clk_);\n+  for (uptr i = 0; i < kVectorClockSize; i++) {\n+    m128 c = _mm_load_si128(&vclk[i]);\n+    m128 d = _mm_load_si128(&vdst[i]);\n+    m128 m = _mm_max_epu16(c, d);\n+    _mm_store_si128(&vdst[i], m);\n+    _mm_store_si128(&vclk[i], m);\n+  }\n+#endif\n+}\n+\n+}  // namespace __tsan"}, {"sha": "63b206302190d18215a1f2a6426dd36610813a4a", "filename": "libsanitizer/tsan/tsan_vector_clock.h", "status": "added", "additions": 0, "deletions": 0, "changes": 0, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_vector_clock.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Ftsan%2Ftsan_vector_clock.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Ftsan%2Ftsan_vector_clock.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61"}, {"sha": "8de51bc1877010382821d3d194982416c0325a38", "filename": "libsanitizer/ubsan/ubsan_diag.cpp", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fubsan%2Fubsan_diag.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fubsan%2Fubsan_diag.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fubsan%2Fubsan_diag.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61"}, {"sha": "25cefd46ce27ced7fb6092d8d04b5074c56ebe95", "filename": "libsanitizer/ubsan/ubsan_flags.cpp", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fubsan%2Fubsan_flags.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fubsan%2Fubsan_flags.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fubsan%2Fubsan_flags.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61"}, {"sha": "e201e6bba22078e3d873aeb5792b98ecd860cdaa", "filename": "libsanitizer/ubsan/ubsan_handlers.cpp", "status": "modified", "additions": 0, "deletions": 15, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fubsan%2Fubsan_handlers.cpp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fubsan%2Fubsan_handlers.cpp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fubsan%2Fubsan_handlers.cpp?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61"}, {"sha": "219fb15de55fe02a4544422095baa0d8532baaa0", "filename": "libsanitizer/ubsan/ubsan_handlers.h", "status": "modified", "additions": 0, "deletions": 8, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fubsan%2Fubsan_handlers.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fubsan%2Fubsan_handlers.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fubsan%2Fubsan_handlers.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61"}, {"sha": "d2cc2e10bd2f023b8d9aa1685a79a192a6d1e1e8", "filename": "libsanitizer/ubsan/ubsan_platform.h", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fubsan%2Fubsan_platform.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/76288e1c5da5a34e3c13d37ac4cab41e0f46ff61/libsanitizer%2Fubsan%2Fubsan_platform.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libsanitizer%2Fubsan%2Fubsan_platform.h?ref=76288e1c5da5a34e3c13d37ac4cab41e0f46ff61"}]}