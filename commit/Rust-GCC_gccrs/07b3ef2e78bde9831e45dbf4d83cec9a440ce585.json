{"sha": "07b3ef2e78bde9831e45dbf4d83cec9a440ce585", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MDdiM2VmMmU3OGJkZTk4MzFlNDVkYmY0ZDgzY2VjOWE0NDBjZTU4NQ==", "commit": {"author": {"name": "Jan Hubicka", "email": "jh@suse.cz", "date": "2010-04-18T10:52:26Z"}, "committer": {"name": "Jan Hubicka", "email": "hubicka@gcc.gnu.org", "date": "2010-04-18T10:52:26Z"}, "message": "i386.md (UNSPEC_SSE_PROLOGUE_SAVE_LOW): New.\n\n\t* i386.md (UNSPEC_SSE_PROLOGUE_SAVE_LOW): New.\n\t(sse_prologue_save_insn expander): Use new pattern.\n\t(sse_prologue_save_insn1): New pattern and splitter.\n\t(sse_prologue_save_insn): Update to deal also with 64bit aligned\n\tblocks.\n\t* i386.c (setup_incoming_varargs_64): Do not compute jump destination here.\n\t(ix86_gimplify_va_arg): Update alignment needed.\n\t(ix86_local_alignment): Do not align all local arrays\n\tto 128bit.\n\nFrom-SVN: r158483", "tree": {"sha": "04b7c8385388a495de58e395735aa2986c5d78f9", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/04b7c8385388a495de58e395735aa2986c5d78f9"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/07b3ef2e78bde9831e45dbf4d83cec9a440ce585", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/07b3ef2e78bde9831e45dbf4d83cec9a440ce585", "html_url": "https://github.com/Rust-GCC/gccrs/commit/07b3ef2e78bde9831e45dbf4d83cec9a440ce585", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/07b3ef2e78bde9831e45dbf4d83cec9a440ce585/comments", "author": null, "committer": null, "parents": [{"sha": "0d29aedcb87015fc3281e644cebde452d8b41007", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0d29aedcb87015fc3281e644cebde452d8b41007", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0d29aedcb87015fc3281e644cebde452d8b41007"}], "stats": {"total": 190, "additions": 148, "deletions": 42}, "files": [{"sha": "912670d50ddcd0ce0fb0197ebe95fba9b659fb5d", "filename": "gcc/ChangeLog", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/07b3ef2e78bde9831e45dbf4d83cec9a440ce585/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/07b3ef2e78bde9831e45dbf4d83cec9a440ce585/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=07b3ef2e78bde9831e45dbf4d83cec9a440ce585", "patch": "@@ -1,3 +1,15 @@\n+2010-04-18  Jan Hubicka  <jh@suse.cz>\n+\n+\t* i386.md (UNSPEC_SSE_PROLOGUE_SAVE_LOW): New.\n+\t(sse_prologue_save_insn expander): Use new pattern.\n+\t(sse_prologue_save_insn1): New pattern and splitter.\n+\t(sse_prologue_save_insn): Update to deal also with 64bit aligned\n+\tblocks.\n+\t* i386.c (setup_incoming_varargs_64): Do not compute jump destination here.\n+\t(ix86_gimplify_va_arg): Update alignment needed.\n+\t(ix86_local_alignment): Do not align all local arrays\n+\tto 128bit.\n+\n 2010-04-17  Jan Hubicka  <jh@suse.cz>\n \n \t* ipa-inline.c (cgraph_early_inlining): Handle flattening too."}, {"sha": "7376d1b48e72c797bf31e488024d20fb08e4832d", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 24, "deletions": 32, "changes": 56, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/07b3ef2e78bde9831e45dbf4d83cec9a440ce585/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/07b3ef2e78bde9831e45dbf4d83cec9a440ce585/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=07b3ef2e78bde9831e45dbf4d83cec9a440ce585", "patch": "@@ -6790,7 +6790,6 @@ setup_incoming_varargs_64 (CUMULATIVE_ARGS *cum)\n {\n   rtx save_area, mem;\n   rtx label;\n-  rtx label_ref;\n   rtx tmp_reg;\n   rtx nsse_reg;\n   alias_set_type set;\n@@ -6841,35 +6840,9 @@ setup_incoming_varargs_64 (CUMULATIVE_ARGS *cum)\n \t SSE saves.  We need some preparation work to get this working.  */\n \n       label = gen_label_rtx ();\n-      label_ref = gen_rtx_LABEL_REF (Pmode, label);\n \n-      /* Compute address to jump to :\n-         label - eax*4 + nnamed_sse_arguments*4 Or\n-         label - eax*5 + nnamed_sse_arguments*5 for AVX.  */\n-      tmp_reg = gen_reg_rtx (Pmode);\n       nsse_reg = gen_reg_rtx (Pmode);\n       emit_insn (gen_zero_extendqidi2 (nsse_reg, gen_rtx_REG (QImode, AX_REG)));\n-      emit_insn (gen_rtx_SET (VOIDmode, tmp_reg,\n-\t\t\t      gen_rtx_MULT (Pmode, nsse_reg,\n-\t\t\t\t\t    GEN_INT (4))));\n-\n-      /* vmovaps is one byte longer than movaps.  */\n-      if (TARGET_AVX)\n-\temit_insn (gen_rtx_SET (VOIDmode, tmp_reg,\n-\t\t\t\tgen_rtx_PLUS (Pmode, tmp_reg,\n-\t\t\t\t\t      nsse_reg)));\n-\n-      if (cum->sse_regno)\n-\temit_move_insn\n-\t  (nsse_reg,\n-\t   gen_rtx_CONST (DImode,\n-\t\t\t  gen_rtx_PLUS (DImode,\n-\t\t\t\t\tlabel_ref,\n-\t\t\t\t\tGEN_INT (cum->sse_regno\n-\t\t\t\t\t\t * (TARGET_AVX ? 5 : 4)))));\n-      else\n-\temit_move_insn (nsse_reg, label_ref);\n-      emit_insn (gen_subdi3 (nsse_reg, nsse_reg, tmp_reg));\n \n       /* Compute address of memory block we save into.  We always use pointer\n \t pointing 127 bytes after first byte to store - this is needed to keep\n@@ -6882,11 +6855,12 @@ setup_incoming_varargs_64 (CUMULATIVE_ARGS *cum)\n       mem = gen_rtx_MEM (BLKmode, plus_constant (tmp_reg, -127));\n       MEM_NOTRAP_P (mem) = 1;\n       set_mem_alias_set (mem, set);\n-      set_mem_align (mem, BITS_PER_WORD);\n+      set_mem_align (mem, 64);\n \n       /* And finally do the dirty job!  */\n       emit_insn (gen_sse_prologue_save (mem, nsse_reg,\n-\t\t\t\t\tGEN_INT (cum->sse_regno), label));\n+\t\t\t\t\tGEN_INT (cum->sse_regno), label,\n+\t\t\t\t\tgen_reg_rtx (Pmode)));\n     }\n }\n \n@@ -7047,7 +7021,7 @@ ix86_gimplify_va_arg (tree valist, tree type, gimple_seq *pre_p,\n   int indirect_p = 0;\n   tree ptrtype;\n   enum machine_mode nat_mode;\n-  int arg_boundary;\n+  unsigned int arg_boundary;\n \n   /* Only 64bit target needs something special.  */\n   if (!TARGET_64BIT || is_va_list_char_pointer (TREE_TYPE (valist)))\n@@ -7279,6 +7253,8 @@ ix86_gimplify_va_arg (tree valist, tree type, gimple_seq *pre_p,\n       t = build2 (BIT_AND_EXPR, TREE_TYPE (t), t,\n \t\t  size_int (-align));\n       t = fold_convert (TREE_TYPE (ovf), t);\n+      if (crtl->stack_alignment_needed < arg_boundary)\n+\tcrtl->stack_alignment_needed = arg_boundary;\n     }\n   gimplify_expr (&t, pre_p, NULL, is_gimple_val, fb_rvalue);\n   gimplify_assign (addr, t, pre_p);\n@@ -20099,10 +20075,26 @@ ix86_local_alignment (tree exp, enum machine_mode mode,\n     }\n \n   /* x86-64 ABI requires arrays greater than 16 bytes to be aligned\n-     to 16byte boundary.  */\n-  if (TARGET_64BIT)\n+     to 16byte boundary.  Exact wording is:\n+\n+     An array uses the same alignment as its elements, except that a local or\n+     global array variable of length at least 16 bytes or\n+     a C99 variable-length array variable always has alignment of at least 16 bytes.\n+\n+     This was added to allow use of aligned SSE instructions at arrays.  This\n+     rule is meant for static storage (where compiler can not do the analysis\n+     by itself).  We follow it for automatic variables only when convenient.\n+     We fully control everything in the function compiled and functions from\n+     other unit can not rely on the alignment.\n+\n+     Exclude va_list type.  It is the common case of local array where\n+     we can not benefit from the alignment.  */\n+  if (TARGET_64BIT && optimize_function_for_speed_p (cfun)\n+      && TARGET_SSE)\n     {\n       if (AGGREGATE_TYPE_P (type)\n+\t   && (TYPE_MAIN_VARIANT (type)\n+\t       != TYPE_MAIN_VARIANT (va_list_type_node))\n \t   && TYPE_SIZE (type)\n \t   && TREE_CODE (TYPE_SIZE (type)) == INTEGER_CST\n \t   && (TREE_INT_CST_LOW (TYPE_SIZE (type)) >= 16"}, {"sha": "fbc15522673b8fd6d962fdbb206b3d2b1d74ea23", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 112, "deletions": 10, "changes": 122, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/07b3ef2e78bde9831e45dbf4d83cec9a440ce585/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/07b3ef2e78bde9831e45dbf4d83cec9a440ce585/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=07b3ef2e78bde9831e45dbf4d83cec9a440ce585", "patch": "@@ -85,6 +85,7 @@\n    (UNSPEC_SET_RIP\t\t16)\n    (UNSPEC_SET_GOT_OFFSET\t17)\n    (UNSPEC_MEMORY_BLOCKAGE\t18)\n+   (UNSPEC_SSE_PROLOGUE_SAVE_LOW 19)\n \n    ; TLS support\n    (UNSPEC_TP\t\t\t20)\n@@ -18441,15 +18442,24 @@\n \t\t\t\t(reg:DI XMM5_REG)\n \t\t\t\t(reg:DI XMM6_REG)\n \t\t\t\t(reg:DI XMM7_REG)] UNSPEC_SSE_PROLOGUE_SAVE))\n-\t      (use (match_operand:DI 1 \"register_operand\" \"\"))\n+\t      (clobber (match_operand:DI 1 \"register_operand\" \"\"))\n \t      (use (match_operand:DI 2 \"immediate_operand\" \"\"))\n-\t      (use (label_ref:DI (match_operand 3 \"\" \"\")))])]\n+\t      (use (label_ref:DI (match_operand 3 \"\" \"\")))\n+\t      (clobber (match_operand:DI 4 \"register_operand\" \"\"))\n+\t      (use (match_dup 1))])]\n   \"TARGET_64BIT\"\n   \"\")\n \n-(define_insn \"*sse_prologue_save_insn\"\n+;; Pre-reload version of prologue save.  Until after prologue generation we don't know\n+;; what the size of save instruction will be.\n+;; Operand 0+operand 6 is the memory save area\n+;; Operand 1 is number of registers to save (will get overwritten to operand 5)\n+;; Operand 2 is number of non-vaargs SSE arguments\n+;; Operand 3 is label starting the save block\n+;; Operand 4 is used for temporary computation of jump address\n+(define_insn \"*sse_prologue_save_insn1\"\n   [(set (mem:BLK (plus:DI (match_operand:DI 0 \"register_operand\" \"R\")\n-\t\t\t  (match_operand:DI 4 \"const_int_operand\" \"n\")))\n+\t\t\t  (match_operand:DI 6 \"const_int_operand\" \"n\")))\n \t(unspec:BLK [(reg:DI XMM0_REG)\n \t\t     (reg:DI XMM1_REG)\n \t\t     (reg:DI XMM2_REG)\n@@ -18458,9 +18468,98 @@\n \t\t     (reg:DI XMM5_REG)\n \t\t     (reg:DI XMM6_REG)\n \t\t     (reg:DI XMM7_REG)] UNSPEC_SSE_PROLOGUE_SAVE))\n+   (clobber (match_operand:DI 1 \"register_operand\" \"=r\"))\n+   (use (match_operand:DI 2 \"const_int_operand\" \"i\"))\n+   (use (label_ref:DI (match_operand 3 \"\" \"X\")))\n+   (clobber (match_operand:DI 4 \"register_operand\" \"=&r\"))\n+   (use (match_operand:DI 5 \"register_operand\" \"1\"))]\n+  \"TARGET_64BIT\n+   && INTVAL (operands[6]) + X86_64_SSE_REGPARM_MAX * 16 - 16 < 128\n+   && INTVAL (operands[6]) + INTVAL (operands[2]) * 16 >= -128\"\n+  \"#\"\n+  [(set_attr \"type\" \"other\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"mode\" \"DI\")])\n+\n+;; We know size of save instruction; expand the computation of jump address\n+;; in the jumptable.\n+(define_split\n+  [(parallel [(set (match_operand:BLK 0 \"\" \"\")\n+\t\t    (unspec:BLK [(reg:DI XMM0_REG)\n+\t\t\t\t (reg:DI XMM1_REG)\n+\t\t\t\t (reg:DI XMM2_REG)\n+\t\t\t\t (reg:DI XMM3_REG)\n+\t\t\t\t (reg:DI XMM4_REG)\n+\t\t\t\t (reg:DI XMM5_REG)\n+\t\t\t\t (reg:DI XMM6_REG)\n+\t\t\t\t (reg:DI XMM7_REG)] UNSPEC_SSE_PROLOGUE_SAVE))\n+\t       (clobber (match_operand:DI 1 \"register_operand\" \"\"))\n+\t       (use (match_operand:DI 2 \"const_int_operand\" \"\"))\n+\t       (use (match_operand 3 \"\" \"\"))\n+\t       (clobber (match_operand:DI 4 \"register_operand\" \"\"))\n+\t       (use (match_operand:DI 5 \"register_operand\" \"\"))])]\n+  \"reload_completed\"\n+  [(parallel [(set (match_dup 0)\n+\t\t   (unspec:BLK [(reg:DI XMM0_REG)\n+\t\t\t\t(reg:DI XMM1_REG)\n+\t\t\t\t(reg:DI XMM2_REG)\n+\t\t\t\t(reg:DI XMM3_REG)\n+\t\t\t\t(reg:DI XMM4_REG)\n+\t\t\t\t(reg:DI XMM5_REG)\n+\t\t\t\t(reg:DI XMM6_REG)\n+\t\t\t\t(reg:DI XMM7_REG)] UNSPEC_SSE_PROLOGUE_SAVE_LOW))\n+\t      (use (match_dup 1))\n+\t      (use (match_dup 2))\n+\t      (use (match_dup 3))\n+\t      (use (match_dup 5))])]\n+{\n+  /* Movaps is 4 bytes, AVX and movsd is 5 bytes.  */\n+  int size = 4 + (TARGET_AVX || crtl->stack_alignment_needed < 128);\n+\n+  /* Compute address to jump to:\n+     label - eax*size + nnamed_sse_arguments*size. */\n+  if (size == 5)\n+    emit_insn (gen_rtx_SET (VOIDmode, operands[4],\n+\t\t\t    gen_rtx_PLUS\n+\t\t\t      (Pmode,\n+\t\t\t       gen_rtx_MULT (Pmode, operands[1],\n+\t\t\t\t\t     GEN_INT (4)),\n+\t\t\t       operands[1])));\n+  else  if (size == 4)\n+    emit_insn (gen_rtx_SET (VOIDmode, operands[4],\n+\t\t\t    gen_rtx_MULT (Pmode, operands[1],\n+\t\t\t\t\t  GEN_INT (4))));\n+  else\n+    gcc_unreachable ();\n+  if (INTVAL (operands[2]))\n+    emit_move_insn\n+      (operands[1],\n+       gen_rtx_CONST (DImode,\n+\t\t      gen_rtx_PLUS (DImode,\n+\t\t\t\t    operands[3],\n+\t\t\t\t    GEN_INT (INTVAL (operands[2])\n+\t\t\t\t\t     * size))));\n+  else\n+    emit_move_insn (operands[1], operands[3]);\n+  emit_insn (gen_subdi3 (operands[1], operands[1], operands[4]));\n+  operands[5] = GEN_INT (size);\n+})\n+\n+(define_insn \"sse_prologue_save_insn\"\n+  [(set (mem:BLK (plus:DI (match_operand:DI 0 \"register_operand\" \"R\")\n+\t\t\t  (match_operand:DI 4 \"const_int_operand\" \"n\")))\n+\t(unspec:BLK [(reg:DI XMM0_REG)\n+\t\t     (reg:DI XMM1_REG)\n+\t\t     (reg:DI XMM2_REG)\n+\t\t     (reg:DI XMM3_REG)\n+\t\t     (reg:DI XMM4_REG)\n+\t\t     (reg:DI XMM5_REG)\n+\t\t     (reg:DI XMM6_REG)\n+\t\t     (reg:DI XMM7_REG)] UNSPEC_SSE_PROLOGUE_SAVE_LOW))\n    (use (match_operand:DI 1 \"register_operand\" \"r\"))\n    (use (match_operand:DI 2 \"const_int_operand\" \"i\"))\n-   (use (label_ref:DI (match_operand 3 \"\" \"X\")))]\n+   (use (label_ref:DI (match_operand 3 \"\" \"X\")))\n+   (use (match_operand:DI 5 \"const_int_operand\" \"i\"))]\n   \"TARGET_64BIT\n    && INTVAL (operands[4]) + X86_64_SSE_REGPARM_MAX * 16 - 16 < 128\n    && INTVAL (operands[4]) + INTVAL (operands[2]) * 16 >= -128\"\n@@ -18480,7 +18579,10 @@\n       PUT_MODE (operands[4], TImode);\n       if (GET_CODE (XEXP (operands[0], 0)) != PLUS)\n         output_asm_insn (\"rex\", operands);\n-      output_asm_insn (\"%vmovaps\\t{%5, %4|%4, %5}\", operands);\n+      if (crtl->stack_alignment_needed < 128)\n+        output_asm_insn (\"%vmovsd\\t{%5, %4|%4, %5}\", operands);\n+      else\n+        output_asm_insn (\"%vmovaps\\t{%5, %4|%4, %5}\", operands);\n     }\n   (*targetm.asm_out.internal_label) (asm_out_file, \"L\",\n \t\t\t\t     CODE_LABEL_NUMBER (operands[3]));\n@@ -18489,11 +18591,11 @@\n   [(set_attr \"type\" \"other\")\n    (set_attr \"length_immediate\" \"0\")\n    (set_attr \"length_address\" \"0\")\n+   ;; 2 bytes for jump and opernds[4] bytes for each save.\n    (set (attr \"length\")\n-     (if_then_else\n-       (eq (symbol_ref \"TARGET_AVX\") (const_int 0))\n-       (const_string \"34\")\n-       (const_string \"42\")))\n+     (plus (const_int 2)\n+\t   (mult (symbol_ref (\"INTVAL (operands[5])\"))\n+\t\t (symbol_ref (\"X86_64_SSE_REGPARM_MAX - INTVAL (operands[2])\")))))\n    (set_attr \"memory\" \"store\")\n    (set_attr \"modrm\" \"0\")\n    (set_attr \"prefix\" \"maybe_vex\")"}]}