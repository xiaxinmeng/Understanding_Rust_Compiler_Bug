{"sha": "ab5d223376e8ef78ee7d5266cae80a9587ffb80e", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YWI1ZDIyMzM3NmU4ZWY3OGVlN2Q1MjY2Y2FlODBhOTU4N2ZmYjgwZQ==", "commit": {"author": {"name": "Eric Botcazou", "email": "ebotcazou@adacore.com", "date": "2016-12-18T08:33:38Z"}, "committer": {"name": "Eric Botcazou", "email": "ebotcazou@gcc.gnu.org", "date": "2016-12-18T08:33:38Z"}, "message": "lra-constraints.c (process_address): Add forward declaration.\n\n\t* lra-constraints.c (process_address): Add forward declaration.\n\t(simplify_operand_subreg): In the MEM case, if the adjusted memory\n\treference is not sufficient aligned and the address was invalid,\n\treload the address before reloading the original memory reference.\n\tFix long lines and add a final return for the sake of clarity.\n\nFrom-SVN: r243782", "tree": {"sha": "c7ad9a5ffe87315078843364e3dea2f9a8f68470", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/c7ad9a5ffe87315078843364e3dea2f9a8f68470"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/ab5d223376e8ef78ee7d5266cae80a9587ffb80e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ab5d223376e8ef78ee7d5266cae80a9587ffb80e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ab5d223376e8ef78ee7d5266cae80a9587ffb80e", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ab5d223376e8ef78ee7d5266cae80a9587ffb80e/comments", "author": null, "committer": null, "parents": [{"sha": "54b890f3e4cbdcbda18b92b7412f82d978d6830c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/54b890f3e4cbdcbda18b92b7412f82d978d6830c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/54b890f3e4cbdcbda18b92b7412f82d978d6830c"}], "stats": {"total": 44, "additions": 31, "deletions": 13}, "files": [{"sha": "5cd7c33a23f2938a2482e6404daccf3b494bae70", "filename": "gcc/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ab5d223376e8ef78ee7d5266cae80a9587ffb80e/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ab5d223376e8ef78ee7d5266cae80a9587ffb80e/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=ab5d223376e8ef78ee7d5266cae80a9587ffb80e", "patch": "@@ -1,3 +1,11 @@\n+2016-12-18  Eric Botcazou  <ebotcazou@adacore.com>\n+\n+\t* lra-constraints.c (process_address): Add forward declaration.\n+\t(simplify_operand_subreg): In the MEM case, if the adjusted memory\n+\treference is not sufficient aligned and the address was invalid,\n+\treload the address before reloading the original memory reference.\n+\tFix long lines and add a final return for the sake of clarity.\n+\n 2016-12-17  Jakub Jelinek  <jakub@redhat.com>\n \n \tPR sanitizer/78832"}, {"sha": "7d80c6f0a110c44954234e97bd36f80607bff05a", "filename": "gcc/lra-constraints.c", "status": "modified", "additions": 23, "deletions": 13, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ab5d223376e8ef78ee7d5266cae80a9587ffb80e/gcc%2Flra-constraints.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ab5d223376e8ef78ee7d5266cae80a9587ffb80e/gcc%2Flra-constraints.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flra-constraints.c?ref=ab5d223376e8ef78ee7d5266cae80a9587ffb80e", "patch": "@@ -1454,6 +1454,7 @@ insert_move_for_subreg (rtx_insn **before, rtx_insn **after, rtx origreg,\n }\n \n static int valid_address_p (machine_mode mode, rtx addr, addr_space_t as);\n+static bool process_address (int, bool, rtx_insn **, rtx_insn **);\n \n /* Make reloads for subreg in operand NOP with internal subreg mode\n    REG_MODE, add new reloads for further processing.  Return true if\n@@ -1480,13 +1481,13 @@ simplify_operand_subreg (int nop, machine_mode reg_mode)\n   type = curr_static_id->operand[nop].type;\n   if (MEM_P (reg))\n     {\n-      rtx subst;\n-\n+      const bool addr_was_valid\n+\t= valid_address_p (innermode, XEXP (reg, 0), MEM_ADDR_SPACE (reg));\n       alter_subreg (curr_id->operand_loc[nop], false);\n-      subst = *curr_id->operand_loc[nop];\n+      rtx subst = *curr_id->operand_loc[nop];\n       lra_assert (MEM_P (subst));\n-      if (! valid_address_p (innermode, XEXP (reg, 0),\n-\t\t\t     MEM_ADDR_SPACE (reg))\n+\n+      if (!addr_was_valid\n \t  || valid_address_p (GET_MODE (subst), XEXP (subst, 0),\n \t\t\t      MEM_ADDR_SPACE (subst))\n \t  || ((get_constraint_type (lookup_constraint\n@@ -1503,10 +1504,10 @@ simplify_operand_subreg (int nop, machine_mode reg_mode)\n \t\t\t\t\t\t    ADDRESS, SCRATCH)][0]],\n \t\t\t\t  MEM_ADDR_SPACE (subst))))\n \t{\n-\t  /* If we change address for paradoxical subreg of memory, the\n+\t  /* If we change the address for a paradoxical subreg of memory, the\n \t     address might violate the necessary alignment or the access might\n-\t     be slow.  So take this into consideration.  We should not worry\n-\t     about access beyond allocated memory for paradoxical memory\n+\t     be slow.  So take this into consideration.  We need not worry\n+\t     about accesses beyond allocated memory for paradoxical memory\n \t     subregs as we don't substitute such equiv memory (see processing\n \t     equivalences in function lra_constraints) and because for spilled\n \t     pseudos we allocate stack memory enough for the biggest\n@@ -1517,28 +1518,36 @@ simplify_operand_subreg (int nop, machine_mode reg_mode)\n \t\t  && SLOW_UNALIGNED_ACCESS (innermode, MEM_ALIGN (reg))))\n \t    return true;\n \n+\t  *curr_id->operand_loc[nop] = operand;\n+\n+\t  /* But if the address was not valid, we cannot reload the MEM without\n+\t     reloading the address first.  */\n+\t  if (!addr_was_valid)\n+\t    process_address (nop, false, &before, &after);\n+\n \t  /* INNERMODE is fast, MODE slow.  Reload the mem in INNERMODE.  */\n \t  enum reg_class rclass\n \t    = (enum reg_class) targetm.preferred_reload_class (reg, ALL_REGS);\n-\t  if (get_reload_reg (curr_static_id->operand[nop].type, innermode, reg,\n-\t\t\t      rclass, TRUE, \"slow mem\", &new_reg))\n+\t  if (get_reload_reg (curr_static_id->operand[nop].type, innermode,\n+\t\t\t      reg, rclass, TRUE, \"slow mem\", &new_reg))\n \t    {\n \t      bool insert_before, insert_after;\n \t      bitmap_set_bit (&lra_subreg_reload_pseudos, REGNO (new_reg));\n \n \t      insert_before = (type != OP_OUT\n-\t\t\t       || GET_MODE_SIZE (innermode) > GET_MODE_SIZE (mode));\n+\t\t\t       || GET_MODE_SIZE (innermode)\n+\t\t\t\t    > GET_MODE_SIZE (mode));\n \t      insert_after = type != OP_IN;\n \t      insert_move_for_subreg (insert_before ? &before : NULL,\n \t\t\t\t      insert_after ? &after : NULL,\n \t\t\t\t      reg, new_reg);\n \t    }\n-\t  *curr_id->operand_loc[nop] = operand;\n \t  SUBREG_REG (operand) = new_reg;\n \n \t  /* Convert to MODE.  */\n \t  reg = operand;\n-\t  rclass = (enum reg_class) targetm.preferred_reload_class (reg, ALL_REGS);\n+\t  rclass\n+\t    = (enum reg_class) targetm.preferred_reload_class (reg, ALL_REGS);\n \t  if (get_reload_reg (curr_static_id->operand[nop].type, mode, reg,\n \t\t\t      rclass, TRUE, \"slow mem\", &new_reg))\n \t    {\n@@ -1561,6 +1570,7 @@ simplify_operand_subreg (int nop, machine_mode reg_mode)\n \t the memory.  Typical case is when the index scale should\n \t correspond the memory.  */\n       *curr_id->operand_loc[nop] = operand;\n+      return false;\n     }\n   else if (REG_P (reg) && REGNO (reg) < FIRST_PSEUDO_REGISTER)\n     {"}]}