{"sha": "f6fff8a6fcd8375aa1056671fcd8de76304e8973", "node_id": "C_kwDOANBUbNoAKGY2ZmZmOGE2ZmNkODM3NWFhMTA1NjY3MWZjZDhkZTc2MzA0ZTg5NzM", "commit": {"author": {"name": "Andrew Stubbs", "email": "ams@codesourcery.com", "date": "2022-12-01T17:30:21Z"}, "committer": {"name": "Andrew Stubbs", "email": "ams@codesourcery.com", "date": "2023-02-02T11:47:03Z"}, "message": "amdgcn, libgomp: Manually allocated stacks\n\nSwitch from using stacks in the \"private segment\" to using a memory block\nallocated on the host side.  The primary reason is to permit the reverse\noffload implementation to access values located on the device stack, but\nthere may also be performance benefits, especially with repeated kernel\ninvocations.\n\nThis implementation unifies the stacks with the \"team arena\" optimization\nfeature, and now allows both to have run-time configurable sizes.\n\nA new ABI is needed, so all libraries must be rebuilt, and newlib must be\nversion 4.3.0.20230120 or newer.\n\ngcc/ChangeLog:\n\n\t* config/gcn/gcn-run.cc: Include libgomp-gcn.h.\n\t(struct kernargs): Replace the common content with kernargs_abi.\n\t(struct heap): Delete.\n\t(main): Read GCN_STACK_SIZE envvar.\n\tAllocate space for the device stacks.\n\tWrite the new kernargs fields.\n\t* config/gcn/gcn.cc (gcn_option_override): Remove stack_size_opt.\n\t(default_requested_args): Remove PRIVATE_SEGMENT_BUFFER_ARG and\n\tPRIVATE_SEGMENT_WAVE_OFFSET_ARG.\n\t(gcn_addr_space_convert): Mask the QUEUE_PTR_ARG content.\n\t(gcn_expand_prologue): Move the TARGET_PACKED_WORK_ITEMS to the top.\n\tSet up the stacks from the values in the kernargs, not private.\n\t(gcn_expand_builtin_1): Match the stack configuration in the prologue.\n\t(gcn_hsa_declare_function_name): Turn off the private segment.\n\t(gcn_conditional_register_usage): Ensure QUEUE_PTR is fixed.\n\t* config/gcn/gcn.h (FIXED_REGISTERS): Fix the QUEUE_PTR register.\n\t* config/gcn/gcn.opt (mstack-size): Change the description.\n\ninclude/ChangeLog:\n\n\t* gomp-constants.h (GOMP_VERSION_GCN): Bump.\n\nlibgomp/ChangeLog:\n\n\t* config/gcn/libgomp-gcn.h (DEFAULT_GCN_STACK_SIZE): New define.\n\t(DEFAULT_TEAM_ARENA_SIZE): New define.\n\t(struct heap): Move to this file.\n\t(struct kernargs_abi): Likewise.\n\t* config/gcn/team.c (gomp_gcn_enter_kernel): Use team arena size from\n\tthe kernargs.\n\t* libgomp.h: Include libgomp-gcn.h.\n\t(TEAM_ARENA_SIZE): Remove.\n\t(team_malloc): Update the error message.\n\t* plugin/plugin-gcn.c (struct kernargs): Move common content to\n\tstruct kernargs_abi.\n\t(struct agent_info): Rename team arenas to ephemeral memories.\n\t(struct team_arena_list): Rename ....\n\t(struct ephemeral_memories_list): to this.\n\t(struct heap): Delete.\n\t(team_arena_size): New variable.\n\t(stack_size): New variable.\n\t(print_kernel_dispatch): Update debug messages.\n\t(init_environment_variables): Read GCN_TEAM_ARENA_SIZE.\n\tRead GCN_STACK_SIZE.\n\t(get_team_arena): Rename ...\n\t(configure_ephemeral_memories): ... to this, and set up stacks.\n\t(release_team_arena): Rename ...\n\t(release_ephemeral_memories): ... to this.\n\t(destroy_team_arenas): Rename ...\n\t(destroy_ephemeral_memories): ... to this.\n\t(create_kernel_dispatch): Add num_threads parameter.\n\tAdjust for kernargs_abi refactor and ephemeral memories.\n\t(release_kernel_dispatch): Adjust for ephemeral memories.\n\t(run_kernel): Pass thread-count to create_kernel_dispatch.\n\t(GOMP_OFFLOAD_init_device): Adjust for ephemeral memories.\n\t(GOMP_OFFLOAD_fini_device): Adjust for ephemeral memories.\n\ngcc/testsuite/ChangeLog:\n\n\t* gcc.c-torture/execute/pr47237.c: Xfail on amdgcn.\n\t* gcc.dg/builtin-apply3.c: Xfail for amdgcn.\n\t* gcc.dg/builtin-apply4.c: Xfail for amdgcn.\n\t* gcc.dg/torture/stackalign/builtin-apply-3.c: Xfail for amdgcn.\n\t* gcc.dg/torture/stackalign/builtin-apply-4.c: Xfail for amdgcn.", "tree": {"sha": "5c5cd81a56864b4601ec8a13cd5e6fa728113c75", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/5c5cd81a56864b4601ec8a13cd5e6fa728113c75"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/f6fff8a6fcd8375aa1056671fcd8de76304e8973", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f6fff8a6fcd8375aa1056671fcd8de76304e8973", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f6fff8a6fcd8375aa1056671fcd8de76304e8973", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f6fff8a6fcd8375aa1056671fcd8de76304e8973/comments", "author": {"login": "ams-cs", "id": 2235130, "node_id": "MDQ6VXNlcjIyMzUxMzA=", "avatar_url": "https://avatars.githubusercontent.com/u/2235130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ams-cs", "html_url": "https://github.com/ams-cs", "followers_url": "https://api.github.com/users/ams-cs/followers", "following_url": "https://api.github.com/users/ams-cs/following{/other_user}", "gists_url": "https://api.github.com/users/ams-cs/gists{/gist_id}", "starred_url": "https://api.github.com/users/ams-cs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ams-cs/subscriptions", "organizations_url": "https://api.github.com/users/ams-cs/orgs", "repos_url": "https://api.github.com/users/ams-cs/repos", "events_url": "https://api.github.com/users/ams-cs/events{/privacy}", "received_events_url": "https://api.github.com/users/ams-cs/received_events", "type": "User", "site_admin": false}, "committer": {"login": "ams-cs", "id": 2235130, "node_id": "MDQ6VXNlcjIyMzUxMzA=", "avatar_url": "https://avatars.githubusercontent.com/u/2235130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ams-cs", "html_url": "https://github.com/ams-cs", "followers_url": "https://api.github.com/users/ams-cs/followers", "following_url": "https://api.github.com/users/ams-cs/following{/other_user}", "gists_url": "https://api.github.com/users/ams-cs/gists{/gist_id}", "starred_url": "https://api.github.com/users/ams-cs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ams-cs/subscriptions", "organizations_url": "https://api.github.com/users/ams-cs/orgs", "repos_url": "https://api.github.com/users/ams-cs/repos", "events_url": "https://api.github.com/users/ams-cs/events{/privacy}", "received_events_url": "https://api.github.com/users/ams-cs/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "8da7476c5fa8870c2fcded48d3de95978434c1be", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8da7476c5fa8870c2fcded48d3de95978434c1be", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8da7476c5fa8870c2fcded48d3de95978434c1be"}], "stats": {"total": 565, "additions": 332, "deletions": 233}, "files": [{"sha": "4232a17b784528a0dc9e7179af1d6695675c02b0", "filename": "gcc/config/gcn/gcn-run.cc", "status": "modified", "additions": 27, "deletions": 35, "changes": 62, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Fconfig%2Fgcn%2Fgcn-run.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Fconfig%2Fgcn%2Fgcn-run.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fgcn%2Fgcn-run.cc?ref=f6fff8a6fcd8375aa1056671fcd8de76304e8973", "patch": "@@ -35,6 +35,7 @@\n #include <signal.h>\n \n #include \"hsa.h\"\n+#include \"../../../libgomp/config/gcn/libgomp-gcn.h\"\n \n #ifndef HSA_RUNTIME_LIB\n #define HSA_RUNTIME_LIB \"libhsa-runtime64.so.1\"\n@@ -487,39 +488,16 @@ device_malloc (size_t size, hsa_region_t region)\n    automatically assign the exit value to *return_value.  */\n struct kernargs\n {\n-  /* Kernargs.  */\n-  int32_t argc;\n-  int64_t argv;\n-  int64_t out_ptr;\n-  int64_t heap_ptr;\n-\n-  /* Output data.  */\n-  struct output\n-  {\n-    int return_value;\n-    unsigned int next_output;\n-    struct printf_data\n-    {\n-      int written;\n-      char msg[128];\n-      int type;\n-      union\n-      {\n-\tint64_t ivalue;\n-\tdouble dvalue;\n-\tchar text[128];\n-      };\n-    } queue[1024];\n-    unsigned int consumed;\n-  } output_data;\n+  union {\n+    struct {\n+      int32_t argc;\n+      int64_t argv;\n+    } args;\n+    struct kernargs_abi abi;\n+  };\n+  struct output output_data;\n };\n \n-struct heap\n-{\n-  int64_t size;\n-  char data[0];\n-} heap;\n-\n /* Print any console output from the kernel.\n    We print all entries from \"consumed\" to the next entry without a \"written\"\n    flag, or \"next_output\" is reached.  The buffer is circular, but the\n@@ -687,6 +665,16 @@ main (int argc, char *argv[])\n   for (int i = 0; i < kernel_argc; i++)\n     args_size += strlen (kernel_argv[i]) + 1;\n \n+  /* The device stack can be adjusted via an environment variable.  */\n+  char *envvar = getenv (\"GCN_STACK_SIZE\");\n+  int stack_size = 1 * 1024 * 1024;  /* 1MB default.  */\n+  if (envvar)\n+    {\n+      int val = atoi (envvar);\n+      if (val)\n+\tstack_size = val;\n+    }\n+\n   /* Allocate device memory for both function parameters and the argv\n      data.  */\n   struct kernargs *kernargs = device_malloc (sizeof (*kernargs),\n@@ -702,11 +690,12 @@ main (int argc, char *argv[])\n   XHSA (hsa_fns.hsa_memory_assign_agent_fn (heap, device,\n \t\t\t\t\t    HSA_ACCESS_PERMISSION_RW),\n \t\"Assign heap to device agent\");\n+  void *stack = device_malloc (stack_size, heap_region);\n \n   /* Write the data to the target.  */\n-  kernargs->argc = kernel_argc;\n-  kernargs->argv = (int64_t) args->argv_data;\n-  kernargs->out_ptr = (int64_t) &kernargs->output_data;\n+  kernargs->args.argc = kernel_argc;\n+  kernargs->args.argv = (int64_t) args->argv_data;\n+  kernargs->abi.out_ptr = (int64_t) &kernargs->output_data;\n   kernargs->output_data.return_value = 0xcafe0000; /* Default return value. */\n   kernargs->output_data.next_output = 0;\n   for (unsigned i = 0; i < (sizeof (kernargs->output_data.queue)\n@@ -721,8 +710,11 @@ main (int argc, char *argv[])\n       memcpy (&args->strings[offset], kernel_argv[i], arg_len + 1);\n       offset += arg_len;\n     }\n-  kernargs->heap_ptr = (int64_t) heap;\n+  kernargs->abi.heap_ptr = (int64_t) heap;\n   hsa_fns.hsa_memory_copy_fn (&heap->size, &heap_size, sizeof (heap_size));\n+  kernargs->abi.arena_ptr = 0;\n+  kernargs->abi.stack_ptr = (int64_t) stack;\n+  kernargs->abi.stack_size_per_thread = stack_size;\n \n   /* Run constructors on the GPU.  */\n   run (init_array_kernel, kernargs);"}, {"sha": "23ab01e75d81777843ab2e3ccdb24e80e0407a69", "filename": "gcc/config/gcn/gcn.cc", "status": "modified", "additions": 118, "deletions": 74, "changes": 192, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Fconfig%2Fgcn%2Fgcn.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Fconfig%2Fgcn%2Fgcn.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fgcn%2Fgcn.cc?ref=f6fff8a6fcd8375aa1056671fcd8de76304e8973", "patch": "@@ -138,21 +138,6 @@ gcn_option_override (void)\n       : ISA_UNKNOWN);\n   gcc_assert (gcn_isa != ISA_UNKNOWN);\n \n-  /* The default stack size needs to be small for offload kernels because\n-     there may be many, many threads.  Also, a smaller stack gives a\n-     measureable performance boost.  But, a small stack is insufficient\n-     for running the testsuite, so we use a larger default for the stand\n-     alone case.  */\n-  if (stack_size_opt == -1)\n-    {\n-      if (flag_openacc || flag_openmp)\n-\t/* 512 bytes per work item = 32kB total.  */\n-\tstack_size_opt = 512 * 64;\n-      else\n-\t/* 1MB total.  */\n-\tstack_size_opt = 1048576;\n-    }\n-\n   /* Reserve 1Kb (somewhat arbitrarily) of LDS space for reduction results and\n      worker broadcasts.  */\n   if (gang_private_size_opt == -1)\n@@ -228,11 +213,9 @@ static const struct gcn_kernel_arg_type\n };\n \n static const long default_requested_args\n-\t= (1 << PRIVATE_SEGMENT_BUFFER_ARG)\n-\t  | (1 << DISPATCH_PTR_ARG)\n+\t= (1 << DISPATCH_PTR_ARG)\n \t  | (1 << QUEUE_PTR_ARG)\n \t  | (1 << KERNARG_SEGMENT_PTR_ARG)\n-\t  | (1 << PRIVATE_SEGMENT_WAVE_OFFSET_ARG)\n \t  | (1 << WORKGROUP_ID_X_ARG)\n \t  | (1 << WORK_ITEM_ID_X_ARG)\n \t  | (1 << WORK_ITEM_ID_Y_ARG)\n@@ -1865,10 +1848,14 @@ gcn_addr_space_convert (rtx op, tree from_type, tree to_type)\n \n   if (AS_LDS_P (as_from) && AS_FLAT_P (as_to))\n     {\n-      rtx queue = gen_rtx_REG (DImode,\n-\t\t\t       cfun->machine->args.reg[QUEUE_PTR_ARG]);\n+      /* The high bits of the QUEUE_PTR_ARG register are used by\n+\t GCN_BUILTIN_FIRST_CALL_THIS_THREAD_P, so mask them out.  */\n+      rtx queue_reg = gen_rtx_REG (DImode,\n+\t\t\t\t   cfun->machine->args.reg[QUEUE_PTR_ARG]);\n+      rtx queue_ptr = gen_reg_rtx (DImode);\n+      emit_insn (gen_anddi3 (queue_ptr, queue_reg, GEN_INT (0xffffffffffff)));\n       rtx group_seg_aperture_hi = gen_rtx_MEM (SImode,\n-\t\t\t\t     gen_rtx_PLUS (DImode, queue,\n+\t\t\t\t     gen_rtx_PLUS (DImode, queue_ptr,\n \t\t\t\t\t\t   gen_int_mode (64, SImode)));\n       rtx tmp = gen_reg_rtx (DImode);\n \n@@ -2521,6 +2508,11 @@ gcn_conditional_register_usage (void)\n       fixed_regs[cfun->machine->args.reg[DISPATCH_PTR_ARG]] = 1;\n       fixed_regs[cfun->machine->args.reg[DISPATCH_PTR_ARG] + 1] = 1;\n     }\n+  if (cfun->machine->args.reg[QUEUE_PTR_ARG] >= 0)\n+    {\n+      fixed_regs[cfun->machine->args.reg[QUEUE_PTR_ARG]] = 1;\n+      fixed_regs[cfun->machine->args.reg[QUEUE_PTR_ARG] + 1] = 1;\n+    }\n   if (cfun->machine->args.reg[WORKGROUP_ID_X_ARG] >= 0)\n     fixed_regs[cfun->machine->args.reg[WORKGROUP_ID_X_ARG]] = 1;\n   if (cfun->machine->args.reg[WORK_ITEM_ID_X_ARG] >= 0)\n@@ -3346,10 +3338,56 @@ gcn_expand_prologue ()\n     }\n   else\n     {\n-      rtx wave_offset = gen_rtx_REG (SImode,\n-\t\t\t\t     cfun->machine->args.\n-\t\t\t\t     reg[PRIVATE_SEGMENT_WAVE_OFFSET_ARG]);\n+      if (TARGET_PACKED_WORK_ITEMS)\n+\t{\n+\t  /* v0 conatins the X, Y and Z dimensions all in one.\n+\t     Expand them out for ABI compatibility.  */\n+\t  /* TODO: implement and use zero_extract.  */\n+\t  rtx v1 = gen_rtx_REG (V64SImode, VGPR_REGNO (1));\n+\t  emit_insn (gen_andv64si3 (v1, gen_rtx_REG (V64SImode, VGPR_REGNO (0)),\n+\t\t\t\t    gen_rtx_CONST_INT (VOIDmode, 0x3FF << 10)));\n+\t  emit_insn (gen_lshrv64si3 (v1, v1, gen_rtx_CONST_INT (VOIDmode, 10)));\n+\t  emit_insn (gen_prologue_use (v1));\n+\n+\t  rtx v2 = gen_rtx_REG (V64SImode, VGPR_REGNO (2));\n+\t  emit_insn (gen_andv64si3 (v2, gen_rtx_REG (V64SImode, VGPR_REGNO (0)),\n+\t\t\t\t    gen_rtx_CONST_INT (VOIDmode, 0x3FF << 20)));\n+\t  emit_insn (gen_lshrv64si3 (v2, v2, gen_rtx_CONST_INT (VOIDmode, 20)));\n+\t  emit_insn (gen_prologue_use (v2));\n+\t}\n+\n+      /* We no longer use the private segment for the stack (it's not\n+\t accessible to reverse offload), so we must calculate a wave offset\n+\t from the grid dimensions and stack size, which is calculated on the\n+\t host, and passed in the kernargs region.\n+\t See libgomp-gcn.h for details.  */\n+      rtx wave_offset = gen_rtx_REG (SImode, FIRST_PARM_REG);\n+\n+      rtx num_waves_mem = gcn_oacc_dim_size (1);\n+      rtx num_waves = gen_rtx_REG (SImode, FIRST_PARM_REG+1);\n+      set_mem_addr_space (num_waves_mem, ADDR_SPACE_SCALAR_FLAT);\n+      emit_move_insn (num_waves, num_waves_mem);\n+\n+      rtx workgroup_num = gcn_oacc_dim_pos (0);\n+      rtx wave_num = gen_rtx_REG (SImode, FIRST_PARM_REG+2);\n+      emit_move_insn(wave_num, gcn_oacc_dim_pos (1));\n \n+      rtx thread_id = gen_rtx_REG (SImode, FIRST_PARM_REG+3);\n+      emit_insn (gen_mulsi3 (thread_id, num_waves, workgroup_num));\n+      emit_insn (gen_addsi3_scc (thread_id, thread_id, wave_num));\n+\n+      rtx kernarg_reg = gen_rtx_REG (DImode, cfun->machine->args.reg\n+\t\t\t\t     [KERNARG_SEGMENT_PTR_ARG]);\n+      rtx stack_size_mem = gen_rtx_MEM (SImode,\n+\t\t\t\t\tgen_rtx_PLUS (DImode, kernarg_reg,\n+\t\t\t\t\t\t      GEN_INT (52)));\n+      set_mem_addr_space (stack_size_mem, ADDR_SPACE_SCALAR_FLAT);\n+      emit_move_insn (wave_offset, stack_size_mem);\n+\n+      emit_insn (gen_mulsi3 (wave_offset, wave_offset, thread_id));\n+\n+      /* The FLAT_SCRATCH_INIT is not usually needed, but can be enabled\n+\t via the function attributes.  */\n       if (cfun->machine->args.requested & (1 << FLAT_SCRATCH_INIT_ARG))\n \t{\n \t  rtx fs_init_lo =\n@@ -3386,10 +3424,12 @@ gcn_expand_prologue ()\n       HOST_WIDE_INT sp_adjust = (offsets->local_vars\n \t\t\t\t + offsets->outgoing_args_size);\n \n-      /* Initialise FP and SP from the buffer descriptor in s[0:3].  */\n-      emit_move_insn (fp_lo, gen_rtx_REG (SImode, 0));\n-      emit_insn (gen_andsi3_scc (fp_hi, gen_rtx_REG (SImode, 1),\n-\t\t\t\t gen_int_mode (0xffff, SImode)));\n+      /* Initialize FP and SP from space allocated on the host.  */\n+      rtx stack_addr_mem = gen_rtx_MEM (DImode,\n+\t\t\t\t\tgen_rtx_PLUS (DImode, kernarg_reg,\n+\t\t\t\t\t\t      GEN_INT (40)));\n+      set_mem_addr_space (stack_addr_mem, ADDR_SPACE_SCALAR_FLAT);\n+      emit_move_insn (fp, stack_addr_mem);\n       rtx scc = gen_rtx_REG (BImode, SCC_REG);\n       emit_insn (gen_addsi3_scalar_carry (fp_lo, fp_lo, wave_offset, scc));\n       emit_insn (gen_addcsi3_scalar_zero (fp_hi, fp_hi, scc));\n@@ -3445,25 +3485,6 @@ gcn_expand_prologue ()\n     emit_insn (gen_prologue_use (gen_rtx_REG (SImode, M0_REG)));\n   }\n \n-  if (TARGET_PACKED_WORK_ITEMS\n-      && cfun && cfun->machine && !cfun->machine->normal_function)\n-  {\n-    /* v0 conatins the X, Y and Z dimensions all in one.\n-       Expand them out for ABI compatibility.  */\n-    /* TODO: implement and use zero_extract.  */\n-    rtx v1 = gen_rtx_REG (V64SImode, VGPR_REGNO (1));\n-    emit_insn (gen_andv64si3 (v1, gen_rtx_REG (V64SImode, VGPR_REGNO (0)),\n-\t       gen_rtx_CONST_INT (VOIDmode, 0x3FF << 10)));\n-    emit_insn (gen_lshrv64si3 (v1, v1, gen_rtx_CONST_INT (VOIDmode, 10)));\n-    emit_insn (gen_prologue_use (v1));\n-\n-    rtx v2 = gen_rtx_REG (V64SImode, VGPR_REGNO (2));\n-    emit_insn (gen_andv64si3 (v2, gen_rtx_REG (V64SImode, VGPR_REGNO (0)),\n-\t       gen_rtx_CONST_INT (VOIDmode, 0x3FF << 20)));\n-    emit_insn (gen_lshrv64si3 (v2, v2, gen_rtx_CONST_INT (VOIDmode, 20)));\n-    emit_insn (gen_prologue_use (v2));\n-  }\n-\n   if (cfun && cfun->machine && !cfun->machine->normal_function && flag_openmp)\n     {\n       /* OpenMP kernels have an implicit call to gomp_gcn_enter_kernel.  */\n@@ -4504,26 +4525,53 @@ gcn_expand_builtin_1 (tree exp, rtx target, rtx /*subtarget */ ,\n \t   cf. struct hsa_kernel_dispatch_packet_s in the HSA doc.  */\n \trtx ptr;\n \tif (cfun->machine->args.reg[DISPATCH_PTR_ARG] >= 0\n-\t    && cfun->machine->args.reg[PRIVATE_SEGMENT_BUFFER_ARG] >= 0)\n+\t    && cfun->machine->args.reg[KERNARG_SEGMENT_PTR_ARG] >= 0)\n \t  {\n-\t    rtx size_rtx = gen_rtx_REG (DImode,\n-\t\t\t     cfun->machine->args.reg[DISPATCH_PTR_ARG]);\n-\t    size_rtx = gen_rtx_MEM (SImode,\n-\t\t\t\t    gen_rtx_PLUS (DImode, size_rtx,\n-\t\t\t\t\t\t  GEN_INT (6*2 + 3*4)));\n-\t    size_rtx = gen_rtx_MULT (SImode, size_rtx, GEN_INT (64));\n-\n-\t    ptr = gen_rtx_REG (DImode,\n-\t\t    cfun->machine->args.reg[PRIVATE_SEGMENT_BUFFER_ARG]);\n-\t    ptr = gen_rtx_AND (DImode, ptr, GEN_INT (0x0000ffffffffffff));\n-\t    ptr = gen_rtx_PLUS (DImode, ptr, size_rtx);\n-\t    if (cfun->machine->args.reg[PRIVATE_SEGMENT_WAVE_OFFSET_ARG] >= 0)\n-\t      {\n-\t\trtx off;\n-\t\toff = gen_rtx_REG (SImode,\n-\t\t      cfun->machine->args.reg[PRIVATE_SEGMENT_WAVE_OFFSET_ARG]);\n-\t\tptr = gen_rtx_PLUS (DImode, ptr, off);\n-\t      }\n+\t    rtx num_waves_mem = gcn_oacc_dim_size (1);\n+\t    rtx num_waves = gen_reg_rtx (SImode);\n+\t    set_mem_addr_space (num_waves_mem, ADDR_SPACE_SCALAR_FLAT);\n+\t    emit_move_insn (num_waves, num_waves_mem);\n+\n+\t    rtx workgroup_num = gcn_oacc_dim_pos (0);\n+\t    rtx wave_num = gen_reg_rtx (SImode);\n+\t    emit_move_insn(wave_num, gcn_oacc_dim_pos (1));\n+\n+\t    rtx thread_id = gen_reg_rtx (SImode);\n+\t    emit_insn (gen_mulsi3 (thread_id, num_waves, workgroup_num));\n+\t    emit_insn (gen_addsi3_scc (thread_id, thread_id, wave_num));\n+\n+\t    rtx kernarg_reg = gen_rtx_REG (DImode, cfun->machine->args.reg\n+\t\t\t\t\t   [KERNARG_SEGMENT_PTR_ARG]);\n+\t    rtx stack_size_mem = gen_rtx_MEM (SImode,\n+\t\t\t\t\t      gen_rtx_PLUS (DImode,\n+\t\t\t\t\t\t\t    kernarg_reg,\n+\t\t\t\t\t\t\t    GEN_INT (52)));\n+\t    set_mem_addr_space (stack_size_mem, ADDR_SPACE_SCALAR_FLAT);\n+\t    rtx stack_size = gen_reg_rtx (SImode);\n+\t    emit_move_insn (stack_size, stack_size_mem);\n+\n+\t    rtx wave_offset = gen_reg_rtx (SImode);\n+\t    emit_insn (gen_mulsi3 (wave_offset, stack_size, thread_id));\n+\n+\t    rtx stack_limit_offset = gen_reg_rtx (SImode);\n+\t    emit_insn (gen_addsi3 (stack_limit_offset, wave_offset,\n+\t\t\t\t   stack_size));\n+\n+\t    rtx stack_limit_offset_di = gen_reg_rtx (DImode);\n+\t    emit_move_insn (gen_rtx_SUBREG (SImode, stack_limit_offset_di, 4),\n+\t\t\t    const0_rtx);\n+\t    emit_move_insn (gen_rtx_SUBREG (SImode, stack_limit_offset_di, 0),\n+\t\t\t    stack_limit_offset);\n+\n+\t    rtx stack_addr_mem = gen_rtx_MEM (DImode,\n+\t\t\t\t\t      gen_rtx_PLUS (DImode,\n+\t\t\t\t\t\t\t    kernarg_reg,\n+\t\t\t\t\t\t\t    GEN_INT (40)));\n+\t    set_mem_addr_space (stack_addr_mem, ADDR_SPACE_SCALAR_FLAT);\n+\t    rtx stack_addr = gen_reg_rtx (DImode);\n+\t    emit_move_insn (stack_addr, stack_addr_mem);\n+\n+\t    ptr = gen_rtx_PLUS (DImode, stack_addr, stack_limit_offset_di);\n \t  }\n \telse\n \t  {\n@@ -4551,11 +4599,11 @@ gcn_expand_builtin_1 (tree exp, rtx target, rtx /*subtarget */ ,\n \t   whether it was the first call.  */\n \trtx result = gen_reg_rtx (BImode);\n \temit_move_insn (result, const0_rtx);\n-\tif (cfun->machine->args.reg[PRIVATE_SEGMENT_BUFFER_ARG] >= 0)\n+\tif (cfun->machine->args.reg[QUEUE_PTR_ARG] >= 0)\n \t  {\n \t    rtx not_first = gen_label_rtx ();\n \t    rtx reg = gen_rtx_REG (DImode,\n-\t\t\tcfun->machine->args.reg[PRIVATE_SEGMENT_BUFFER_ARG]);\n+\t\t\tcfun->machine->args.reg[QUEUE_PTR_ARG]);\n \t    reg = gcn_operand_part (DImode, reg, 1);\n \t    rtx cmp = force_reg (SImode,\n \t\t\t\t gen_rtx_LSHIFTRT (SImode, reg, GEN_INT (16)));\n@@ -6041,16 +6089,13 @@ gcn_hsa_declare_function_name (FILE *file, const char *name, tree)\n \t   \"\\t  .amdhsa_reserve_vcc\\t1\\n\"\n \t   \"\\t  .amdhsa_reserve_flat_scratch\\t0\\n\"\n \t   \"\\t  .amdhsa_reserve_xnack_mask\\t%i\\n\"\n-\t   \"\\t  .amdhsa_private_segment_fixed_size\\t%i\\n\"\n+\t   \"\\t  .amdhsa_private_segment_fixed_size\\t0\\n\"\n \t   \"\\t  .amdhsa_group_segment_fixed_size\\t%u\\n\"\n \t   \"\\t  .amdhsa_float_denorm_mode_32\\t3\\n\"\n \t   \"\\t  .amdhsa_float_denorm_mode_16_64\\t3\\n\",\n \t   vgpr,\n \t   sgpr,\n \t   xnack_enabled,\n-\t   /* workitem_private_segment_bytes_size needs to be\n-\t      one 64th the wave-front stack size.  */\n-\t   stack_size_opt / 64,\n \t   LDS_SIZE);\n   if (gcn_arch == PROCESSOR_GFX90a)\n     fprintf (file,\n@@ -6075,15 +6120,14 @@ gcn_hsa_declare_function_name (FILE *file, const char *name, tree)\n \t   \"            .kernarg_segment_size: %i\\n\"\n \t   \"            .kernarg_segment_align: %i\\n\"\n \t   \"            .group_segment_fixed_size: %u\\n\"\n-\t   \"            .private_segment_fixed_size: %i\\n\"\n+\t   \"            .private_segment_fixed_size: 0\\n\"\n \t   \"            .wavefront_size: 64\\n\"\n \t   \"            .sgpr_count: %i\\n\"\n \t   \"            .vgpr_count: %i\\n\"\n \t   \"            .max_flat_workgroup_size: 1024\\n\",\n \t   cfun->machine->kernarg_segment_byte_size,\n \t   cfun->machine->kernarg_segment_alignment,\n \t   LDS_SIZE,\n-\t   stack_size_opt / 64,\n \t   sgpr, vgpr);\n   if (gcn_arch == PROCESSOR_GFX90a)\n     fprintf (file, \"            .agpr_count: 0\\n\"); // AGPRs are not used, yet"}, {"sha": "4ff9a5d4d12c21c16aac6fe09376f651e9db760e", "filename": "gcc/config/gcn/gcn.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Fconfig%2Fgcn%2Fgcn.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Fconfig%2Fgcn%2Fgcn.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fgcn%2Fgcn.h?ref=f6fff8a6fcd8375aa1056671fcd8de76304e8973", "patch": "@@ -183,7 +183,7 @@\n \f\n #define FIXED_REGISTERS {\t\t\t    \\\n     /* Scalars.  */\t\t\t\t    \\\n-    1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\t\t    \\\n+    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\t\t    \\\n /*\t\tfp    sp    lr.  */\t\t    \\\n     1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\t\t    \\\n /*  exec_save, cc_save */\t\t\t    \\"}, {"sha": "c5c32bdc833d4d2b94dfc1c3065c67591c74e2d2", "filename": "gcc/config/gcn/gcn.opt", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Fconfig%2Fgcn%2Fgcn.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Fconfig%2Fgcn%2Fgcn.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fgcn%2Fgcn.opt?ref=f6fff8a6fcd8375aa1056671fcd8de76304e8973", "patch": "@@ -69,7 +69,7 @@ int stack_size_opt = -1\n \n mstack-size=\n Target RejectNegative Joined UInteger Var(stack_size_opt) Init(-1)\n--mstack-size=<number>\tSet the private segment size per wave-front, in bytes.\n+Obsolete; use GCN_STACK_SIZE at runtime.\n \n int gang_private_size_opt = -1\n "}, {"sha": "944bdb7c93aee6b78629001639f6b1faee93f623", "filename": "gcc/testsuite/gcc.c-torture/execute/pr47237.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Ftestsuite%2Fgcc.c-torture%2Fexecute%2Fpr47237.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Ftestsuite%2Fgcc.c-torture%2Fexecute%2Fpr47237.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.c-torture%2Fexecute%2Fpr47237.c?ref=f6fff8a6fcd8375aa1056671fcd8de76304e8973", "patch": "@@ -1,4 +1,4 @@\n-/* { dg-xfail-if \"can cause stack underflow\" { nios2-*-* } } */\n+/* { dg-xfail-run-if \"can cause stack underflow\" { nios2-*-* amdgcn-*-* } } */\n /* { dg-require-effective-target untyped_assembly } */\n #define INTEGER_ARG  5\n "}, {"sha": "8fc20030ed76c7cd6e848d584c4d25995cae8686", "filename": "gcc/testsuite/gcc.dg/builtin-apply3.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Ftestsuite%2Fgcc.dg%2Fbuiltin-apply3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Ftestsuite%2Fgcc.dg%2Fbuiltin-apply3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fbuiltin-apply3.c?ref=f6fff8a6fcd8375aa1056671fcd8de76304e8973", "patch": "@@ -6,6 +6,7 @@\n \n /* { dg-do run } */\n /* { dg-require-effective-target untyped_assembly } */\n+/* { dg-xfail-run-if \"can cause stack underflow\" { amdgcn-*-* } } */\n \n \n #define INTEGER_ARG  5"}, {"sha": "aa491c18de4f46469310a2072b22407d3f927c4a", "filename": "gcc/testsuite/gcc.dg/builtin-apply4.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Ftestsuite%2Fgcc.dg%2Fbuiltin-apply4.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Ftestsuite%2Fgcc.dg%2Fbuiltin-apply4.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fbuiltin-apply4.c?ref=f6fff8a6fcd8375aa1056671fcd8de76304e8973", "patch": "@@ -3,6 +3,7 @@\n /* { dg-additional-options \"-mno-mmx\" { target { { i?86-*-* x86_64-*-* } && ia32 } } } */\n /* { dg-do run } */\n /* { dg-require-effective-target untyped_assembly } */\n+/* { dg-xfail-run-if \"can cause stack underflow\" { amdgcn-*-* } } */\n \n extern void abort (void);\n "}, {"sha": "8fc20030ed76c7cd6e848d584c4d25995cae8686", "filename": "gcc/testsuite/gcc.dg/torture/stackalign/builtin-apply-3.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fstackalign%2Fbuiltin-apply-3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fstackalign%2Fbuiltin-apply-3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fstackalign%2Fbuiltin-apply-3.c?ref=f6fff8a6fcd8375aa1056671fcd8de76304e8973", "patch": "@@ -6,6 +6,7 @@\n \n /* { dg-do run } */\n /* { dg-require-effective-target untyped_assembly } */\n+/* { dg-xfail-run-if \"can cause stack underflow\" { amdgcn-*-* } } */\n \n \n #define INTEGER_ARG  5"}, {"sha": "94b20123724de571211843cd3d5723b5abd87fba", "filename": "gcc/testsuite/gcc.dg/torture/stackalign/builtin-apply-4.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fstackalign%2Fbuiltin-apply-4.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fff8a6fcd8375aa1056671fcd8de76304e8973/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fstackalign%2Fbuiltin-apply-4.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fstackalign%2Fbuiltin-apply-4.c?ref=f6fff8a6fcd8375aa1056671fcd8de76304e8973", "patch": "@@ -2,6 +2,7 @@\n /* { dg-do run } */\n /* { dg-additional-options \"-fgnu89-inline\" } */\n /* { dg-require-effective-target untyped_assembly } */\n+/* { dg-xfail-run-if \"can cause stack underflow\" { amdgcn-*-* } } */\n \n extern void abort (void);\n "}, {"sha": "1b9b07dc245249a081d396b4c8b0634aa14bf523", "filename": "include/gomp-constants.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fff8a6fcd8375aa1056671fcd8de76304e8973/include%2Fgomp-constants.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fff8a6fcd8375aa1056671fcd8de76304e8973/include%2Fgomp-constants.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/include%2Fgomp-constants.h?ref=f6fff8a6fcd8375aa1056671fcd8de76304e8973", "patch": "@@ -284,7 +284,7 @@ enum gomp_map_kind\n    to the plugin interface defined in libgomp/libgomp.h.  */\n #define GOMP_VERSION\t2\n #define GOMP_VERSION_NVIDIA_PTX 1\n-#define GOMP_VERSION_GCN 2\n+#define GOMP_VERSION_GCN 3\n \n #define GOMP_VERSION_PACK(LIB, DEV) (((LIB) << 16) | (DEV))\n #define GOMP_VERSION_LIB(PACK) (((PACK) >> 16) & 0xffff)"}, {"sha": "f62b7dde0e78d459f51b12a3897b60fca82a7dbd", "filename": "libgomp/config/gcn/libgomp-gcn.h", "status": "modified", "additions": 34, "deletions": 0, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fff8a6fcd8375aa1056671fcd8de76304e8973/libgomp%2Fconfig%2Fgcn%2Flibgomp-gcn.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fff8a6fcd8375aa1056671fcd8de76304e8973/libgomp%2Fconfig%2Fgcn%2Flibgomp-gcn.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Fconfig%2Fgcn%2Flibgomp-gcn.h?ref=f6fff8a6fcd8375aa1056671fcd8de76304e8973", "patch": "@@ -30,6 +30,40 @@\n #ifndef LIBGOMP_GCN_H\n #define LIBGOMP_GCN_H 1\n \n+#define DEFAULT_GCN_STACK_SIZE (32*1024)\n+#define DEFAULT_TEAM_ARENA_SIZE (64*1024)\n+\n+struct heap\n+{\n+  int64_t size;\n+  char data[0];\n+};\n+\n+/* This struct defines the (unofficial) ABI-defined values the compiler\n+   expects to find in first bytes of the kernargs space.\n+   The plugin may choose to place additional data later in the kernargs\n+   memory allocation, but those are not in any fixed location.  */\n+struct kernargs_abi {\n+  /* Leave space for the real kernel arguments.\n+     OpenACC and OpenMP only use one pointer.  */\n+  int64_t dummy1;\n+  int64_t dummy2;\n+\n+  /* A pointer to struct output, below, for console output data.  */\n+  int64_t out_ptr;\t\t/* Offset 16.  */\n+\n+  /* A pointer to struct heap.  */\n+  int64_t heap_ptr;\t\t/* Offset 24.  */\n+\n+  /* A pointer to the ephemeral memory areas.\n+     The team arena is only needed for OpenMP.\n+     Each should have enough space for all the teams and threads.  */\n+  int64_t arena_ptr;\t\t/* Offset 32.  */\n+  int64_t stack_ptr;\t\t/* Offset 40.  */\n+  int arena_size_per_team;\t/* Offset 48.  */\n+  int stack_size_per_thread;\t/* Offset 52.  */\n+};\n+\n /* This struct is also used in Newlib's libc/sys/amdgcn/write.c.  */\n struct output\n {"}, {"sha": "f03207c84e35a0e548705716f0aa823b91e5a747", "filename": "libgomp/config/gcn/team.c", "status": "modified", "additions": 5, "deletions": 3, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fff8a6fcd8375aa1056671fcd8de76304e8973/libgomp%2Fconfig%2Fgcn%2Fteam.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fff8a6fcd8375aa1056671fcd8de76304e8973/libgomp%2Fconfig%2Fgcn%2Fteam.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Fconfig%2Fgcn%2Fteam.c?ref=f6fff8a6fcd8375aa1056671fcd8de76304e8973", "patch": "@@ -60,14 +60,16 @@ gomp_gcn_enter_kernel (void)\n       /* Initialize the team arena for optimized memory allocation.\n          The arena has been allocated on the host side, and the address\n          passed in via the kernargs.  Each team takes a small slice of it.  */\n-      void **kernargs = (void**) __builtin_gcn_kernarg_ptr ();\n-      void *team_arena = (kernargs[4] + TEAM_ARENA_SIZE*teamid);\n+      struct kernargs_abi *kernargs =\n+\t(struct kernargs_abi*) __builtin_gcn_kernarg_ptr ();\n+      void *team_arena = ((void*)kernargs->arena_ptr\n+\t\t\t  + kernargs->arena_size_per_team * teamid);\n       void * __lds *arena_start = (void * __lds *)TEAM_ARENA_START;\n       void * __lds *arena_free = (void * __lds *)TEAM_ARENA_FREE;\n       void * __lds *arena_end = (void * __lds *)TEAM_ARENA_END;\n       *arena_start = team_arena;\n       *arena_free = team_arena;\n-      *arena_end = team_arena + TEAM_ARENA_SIZE;\n+      *arena_end = team_arena + kernargs->arena_size_per_team;\n \n       /* Allocate and initialize the team-local-storage data.  */\n       struct gomp_thread *thrs = team_malloc_cleared (sizeof (*thrs)"}, {"sha": "ba8fe348aba85c9e109b32d17214fc827862d073", "filename": "libgomp/libgomp.h", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fff8a6fcd8375aa1056671fcd8de76304e8973/libgomp%2Flibgomp.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fff8a6fcd8375aa1056671fcd8de76304e8973/libgomp%2Flibgomp.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Flibgomp.h?ref=f6fff8a6fcd8375aa1056671fcd8de76304e8973", "patch": "@@ -112,8 +112,8 @@ extern void gomp_aligned_free (void *);\n /* Optimized allocators for team-specific data that will die with the team.  */\n \n #ifdef __AMDGCN__\n+#include \"libgomp-gcn.h\"\n /* The arena is initialized in config/gcn/team.c.  */\n-#define TEAM_ARENA_SIZE  64*1024  /* Must match the value in plugin-gcn.c.  */\n #define TEAM_ARENA_START 16  /* LDS offset of free pointer.  */\n #define TEAM_ARENA_FREE  24  /* LDS offset of free pointer.  */\n #define TEAM_ARENA_END   32  /* LDS offset of end pointer.  */\n@@ -135,7 +135,8 @@ team_malloc (size_t size)\n     {\n       /* While this is experimental, let's make sure we know when OOM\n \t happens.  */\n-      const char msg[] = \"GCN team arena exhausted\\n\";\n+      const char msg[] = \"GCN team arena exhausted;\"\n+\t\t\t \" configure with GCN_TEAM_ARENA_SIZE=bytes\\n\";\n       write (2, msg, sizeof(msg)-1);\n \n       /* Fall back to using the heap (slowly).  */"}, {"sha": "a7b35059ab3c6cc8d98bd63851a204605f95b5c5", "filename": "libgomp/plugin/plugin-gcn.c", "status": "modified", "additions": 137, "deletions": 115, "changes": 252, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f6fff8a6fcd8375aa1056671fcd8de76304e8973/libgomp%2Fplugin%2Fplugin-gcn.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f6fff8a6fcd8375aa1056671fcd8de76304e8973/libgomp%2Fplugin%2Fplugin-gcn.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Fplugin%2Fplugin-gcn.c?ref=f6fff8a6fcd8375aa1056671fcd8de76304e8973", "patch": "@@ -237,20 +237,7 @@ struct kernel_dispatch\n    in libgomp target code.  */\n \n struct kernargs {\n-  /* Leave space for the real kernel arguments.\n-     OpenACC and OpenMP only use one pointer.  */\n-  int64_t dummy1;\n-  int64_t dummy2;\n-\n-  /* A pointer to struct output, below, for console output data.  */\n-  int64_t out_ptr;\n-\n-  /* A pointer to struct heap, below.  */\n-  int64_t heap_ptr;\n-\n-  /* A pointer to an ephemeral memory arena.\n-    Only needed for OpenMP.  */\n-  int64_t arena_ptr;\n+  struct kernargs_abi abi;\n \n   /* Output data.  */\n   struct output output_data;\n@@ -426,9 +413,9 @@ struct agent_info\n   /* The HSA memory region from which to allocate device data.  */\n   hsa_region_t data_region;\n \n-  /* Allocated team arenas.  */\n-  struct team_arena_list *team_arena_list;\n-  pthread_mutex_t team_arena_write_lock;\n+  /* Allocated ephemeral memories (team arena and stack space).  */\n+  struct ephemeral_memories_list *ephemeral_memories_list;\n+  pthread_mutex_t ephemeral_memories_write_lock;\n \n   /* Read-write lock that protects kernels which are running or about to be run\n      from interference with loading and unloading of images.  Needs to be\n@@ -510,17 +497,18 @@ struct module_info\n };\n \n /* A linked list of memory arenas allocated on the device.\n-   These are only used by OpenMP, as a means to optimize per-team malloc.  */\n+   These are used by OpenMP, as a means to optimize per-team malloc,\n+   and for host-accessible stack space.  */\n \n-struct team_arena_list\n+struct ephemeral_memories_list\n {\n-  struct team_arena_list *next;\n+  struct ephemeral_memories_list *next;\n \n-  /* The number of teams determines the size of the allocation.  */\n-  int num_teams;\n-  /* The device address of the arena itself.  */\n-  void *arena;\n-  /* A flag to prevent two asynchronous kernels trying to use the same arena.\n+  /* The size is determined by the number of teams and threads.  */\n+  size_t size;\n+  /* The device address allocated memory.  */\n+  void *address;\n+  /* A flag to prevent two asynchronous kernels trying to use the same memory.\n      The mutex is locked until the kernel exits.  */\n   pthread_mutex_t in_use;\n };\n@@ -539,15 +527,6 @@ struct hsa_context_info\n   char driver_version_s[30];\n };\n \n-/* Format of the on-device heap.\n-\n-   This must match the definition in Newlib and gcn-run.  */\n-\n-struct heap {\n-  int64_t size;\n-  char data[0];\n-};\n-\n /* }}}  */\n /* {{{ Global variables  */\n \n@@ -565,6 +544,11 @@ static struct hsa_runtime_fn_info hsa_fns;\n \n static size_t gcn_kernel_heap_size = DEFAULT_GCN_HEAP_SIZE;\n \n+/* Ephemeral memory sizes for each kernel launch.  */\n+\n+static int team_arena_size = DEFAULT_TEAM_ARENA_SIZE;\n+static int stack_size = DEFAULT_GCN_STACK_SIZE;\n+\n /* Flag to decide whether print to stderr information about what is going on.\n    Set in init_debug depending on environment variables.  */\n \n@@ -1020,9 +1004,13 @@ print_kernel_dispatch (struct kernel_dispatch *dispatch, unsigned indent)\n   fprintf (stderr, \"%*squeue: %p\\n\", indent, \"\", dispatch->queue);\n   fprintf (stderr, \"%*skernarg_address: %p\\n\", indent, \"\", kernargs);\n   fprintf (stderr, \"%*sheap address: %p\\n\", indent, \"\",\n-\t   (void*)kernargs->heap_ptr);\n-  fprintf (stderr, \"%*sarena address: %p\\n\", indent, \"\",\n-\t   (void*)kernargs->arena_ptr);\n+\t   (void*)kernargs->abi.heap_ptr);\n+  fprintf (stderr, \"%*sarena address: %p (%d bytes per workgroup)\\n\", indent,\n+\t   \"\", (void*)kernargs->abi.arena_ptr,\n+\t   kernargs->abi.arena_size_per_team);\n+  fprintf (stderr, \"%*sstack address: %p (%d bytes per wavefront)\\n\", indent,\n+\t   \"\", (void*)kernargs->abi.stack_ptr,\n+\t   kernargs->abi.stack_size_per_thread);\n   fprintf (stderr, \"%*sobject: %lu\\n\", indent, \"\", dispatch->object);\n   fprintf (stderr, \"%*sprivate_segment_size: %u\\n\", indent, \"\",\n \t   dispatch->private_segment_size);\n@@ -1082,6 +1070,22 @@ init_environment_variables (void)\n       if (tmp)\n \tgcn_kernel_heap_size = tmp;\n     }\n+\n+  const char *arena = secure_getenv (\"GCN_TEAM_ARENA_SIZE\");\n+  if (arena)\n+    {\n+      int tmp = atoi (arena);\n+      if (tmp)\n+\tteam_arena_size = tmp;;\n+    }\n+\n+  const char *stack = secure_getenv (\"GCN_STACK_SIZE\");\n+  if (stack)\n+    {\n+      int tmp = atoi (stack);\n+      if (tmp)\n+\tstack_size = tmp;;\n+    }\n }\n \n /* Return malloc'd string with name of SYMBOL.  */\n@@ -1693,85 +1697,103 @@ isa_code(const char *isa) {\n /* }}}  */\n /* {{{ Run  */\n \n-/* Create or reuse a team arena.\n+/* Create or reuse a team arena and stack space.\n  \n    Team arenas are used by OpenMP to avoid calling malloc multiple times\n    while setting up each team.  This is purely a performance optimization.\n \n-   Allocating an arena also costs performance, albeit on the host side, so\n-   this function will reuse an existing arena if a large enough one is idle.\n-   The arena is released, but not deallocated, when the kernel exits.  */\n+   The stack space is used by all kernels.  We must allocate it in such a\n+   way that the reverse offload implmentation can access the data.\n \n-static void *\n-get_team_arena (struct agent_info *agent, int num_teams)\n+   Allocating this memory costs performance, so this function will reuse an\n+   existing allocation if a large enough one is idle.\n+   The memory lock is released, but not deallocated, when the kernel exits.  */\n+\n+static void\n+configure_ephemeral_memories (struct kernel_info *kernel,\n+\t\t\t      struct kernargs_abi *kernargs, int num_teams,\n+\t\t\t      int num_threads)\n {\n-  struct team_arena_list **next_ptr = &agent->team_arena_list;\n-  struct team_arena_list *item;\n+  struct agent_info *agent = kernel->agent;\n+  struct ephemeral_memories_list **next_ptr = &agent->ephemeral_memories_list;\n+  struct ephemeral_memories_list *item;\n+\n+  int actual_arena_size = (kernel->kind == KIND_OPENMP\n+\t\t\t   ? team_arena_size : 0);\n+  int actual_arena_total_size = actual_arena_size * num_teams;\n+  size_t size = (actual_arena_total_size\n+\t\t + num_teams * num_threads * stack_size);\n \n   for (item = *next_ptr; item; next_ptr = &item->next, item = item->next)\n     {\n-      if (item->num_teams < num_teams)\n+      if (item->size < size)\n \tcontinue;\n \n-      if (pthread_mutex_trylock (&item->in_use))\n-\tcontinue;\n-\n-      return item->arena;\n+      if (pthread_mutex_trylock (&item->in_use) == 0)\n+\tbreak;\n     }\n \n-  GCN_DEBUG (\"Creating a new arena for %d teams\\n\", num_teams);\n-\n-  if (pthread_mutex_lock (&agent->team_arena_write_lock))\n+  if (!item)\n     {\n-      GOMP_PLUGIN_error (\"Could not lock a GCN agent program mutex\");\n-      return false;\n-    }\n-  item = malloc (sizeof (*item));\n-  item->num_teams = num_teams;\n-  item->next = NULL;\n-  *next_ptr = item;\n+      GCN_DEBUG (\"Creating a new %sstack for %d teams with %d threads\"\n+\t\t \" (%zd bytes)\\n\", (actual_arena_size ? \"arena and \" : \"\"),\n+\t\t num_teams, num_threads, size);\n \n-  if (pthread_mutex_init (&item->in_use, NULL))\n-    {\n-      GOMP_PLUGIN_error (\"Failed to initialize a GCN team arena write mutex\");\n-      return false;\n-    }\n-  if (pthread_mutex_lock (&item->in_use))\n-    {\n-      GOMP_PLUGIN_error (\"Could not lock a GCN agent program mutex\");\n-      return false;\n-    }\n-  if (pthread_mutex_unlock (&agent->team_arena_write_lock))\n-    {\n-      GOMP_PLUGIN_error (\"Could not unlock a GCN agent program mutex\");\n-      return false;\n-    }\n+      if (pthread_mutex_lock (&agent->ephemeral_memories_write_lock))\n+\t{\n+\t  GOMP_PLUGIN_error (\"Could not lock a GCN agent program mutex\");\n+\t  return;\n+\t}\n+      item = malloc (sizeof (*item));\n+      item->size = size;\n+      item->next = NULL;\n+      *next_ptr = item;\n \n-  const int TEAM_ARENA_SIZE = 64*1024;  /* Must match libgomp.h.  */\n-  hsa_status_t status;\n-  status = hsa_fns.hsa_memory_allocate_fn (agent->data_region,\n-\t\t\t\t\t   TEAM_ARENA_SIZE*num_teams,\n-\t\t\t\t\t   &item->arena);\n-  if (status != HSA_STATUS_SUCCESS)\n-    hsa_fatal (\"Could not allocate memory for GCN kernel arena\", status);\n-  status = hsa_fns.hsa_memory_assign_agent_fn (item->arena, agent->id,\n-\t\t\t\t\t       HSA_ACCESS_PERMISSION_RW);\n-  if (status != HSA_STATUS_SUCCESS)\n-    hsa_fatal (\"Could not assign arena memory to device\", status);\n+      if (pthread_mutex_init (&item->in_use, NULL))\n+\t{\n+\t  GOMP_PLUGIN_error (\"Failed to initialize a GCN memory write mutex\");\n+\t  return;\n+\t}\n+      if (pthread_mutex_lock (&item->in_use))\n+\t{\n+\t  GOMP_PLUGIN_error (\"Could not lock a GCN agent program mutex\");\n+\t  return;\n+\t}\n+      if (pthread_mutex_unlock (&agent->ephemeral_memories_write_lock))\n+\t{\n+\t  GOMP_PLUGIN_error (\"Could not unlock a GCN agent program mutex\");\n+\t  return;\n+\t}\n+\n+      hsa_status_t status;\n+      status = hsa_fns.hsa_memory_allocate_fn (agent->data_region, size,\n+\t\t\t\t\t       &item->address);\n+      if (status != HSA_STATUS_SUCCESS)\n+\thsa_fatal (\"Could not allocate memory for GCN kernel arena\", status);\n+      status = hsa_fns.hsa_memory_assign_agent_fn (item->address, agent->id,\n+\t\t\t\t\t\t   HSA_ACCESS_PERMISSION_RW);\n+      if (status != HSA_STATUS_SUCCESS)\n+\thsa_fatal (\"Could not assign arena & stack memory to device\", status);\n+    }\n \n-  return item->arena;\n+  kernargs->arena_ptr = (actual_arena_total_size\n+\t\t\t ? (uint64_t)item->address\n+\t\t\t : 0);\n+  kernargs->stack_ptr = (uint64_t)item->address + actual_arena_total_size;\n+  kernargs->arena_size_per_team = actual_arena_size;\n+  kernargs->stack_size_per_thread = stack_size;\n }\n \n-/* Mark a team arena available for reuse.  */\n+/* Mark an ephemeral memory space available for reuse.  */\n \n static void\n-release_team_arena (struct agent_info* agent, void *arena)\n+release_ephemeral_memories (struct agent_info* agent, void *address)\n {\n-  struct team_arena_list *item;\n+  struct ephemeral_memories_list *item;\n \n-  for (item = agent->team_arena_list; item; item = item->next)\n+  for (item = agent->ephemeral_memories_list; item; item = item->next)\n     {\n-      if (item->arena == arena)\n+      if (item->address == address)\n \t{\n \t  if (pthread_mutex_unlock (&item->in_use))\n \t    GOMP_PLUGIN_error (\"Could not unlock a GCN agent program mutex\");\n@@ -1784,22 +1806,22 @@ release_team_arena (struct agent_info* agent, void *arena)\n /* Clean up all the allocated team arenas.  */\n \n static bool\n-destroy_team_arenas (struct agent_info *agent)\n+destroy_ephemeral_memories (struct agent_info *agent)\n {\n-  struct team_arena_list *item, *next;\n+  struct ephemeral_memories_list *item, *next;\n \n-  for (item = agent->team_arena_list; item; item = next)\n+  for (item = agent->ephemeral_memories_list; item; item = next)\n     {\n       next = item->next;\n-      hsa_fns.hsa_memory_free_fn (item->arena);\n+      hsa_fns.hsa_memory_free_fn (item->address);\n       if (pthread_mutex_destroy (&item->in_use))\n \t{\n-\t  GOMP_PLUGIN_error (\"Failed to destroy a GCN team arena mutex\");\n+\t  GOMP_PLUGIN_error (\"Failed to destroy a GCN memory mutex\");\n \t  return false;\n \t}\n       free (item);\n     }\n-  agent->team_arena_list = NULL;\n+  agent->ephemeral_memories_list = NULL;\n \n   return true;\n }\n@@ -1871,7 +1893,8 @@ alloc_by_agent (struct agent_info *agent, size_t size)\n    the necessary device signals and memory allocations.  */\n \n static struct kernel_dispatch *\n-create_kernel_dispatch (struct kernel_info *kernel, int num_teams)\n+create_kernel_dispatch (struct kernel_info *kernel, int num_teams,\n+\t\t\tint num_threads)\n {\n   struct agent_info *agent = kernel->agent;\n   struct kernel_dispatch *shadow\n@@ -1906,7 +1929,7 @@ create_kernel_dispatch (struct kernel_info *kernel, int num_teams)\n   struct kernargs *kernargs = shadow->kernarg_address;\n \n   /* Zero-initialize the output_data (minimum needed).  */\n-  kernargs->out_ptr = (int64_t)&kernargs->output_data;\n+  kernargs->abi.out_ptr = (int64_t)&kernargs->output_data;\n   kernargs->output_data.next_output = 0;\n   for (unsigned i = 0;\n        i < (sizeof (kernargs->output_data.queue)\n@@ -1916,13 +1939,10 @@ create_kernel_dispatch (struct kernel_info *kernel, int num_teams)\n   kernargs->output_data.consumed = 0;\n \n   /* Pass in the heap location.  */\n-  kernargs->heap_ptr = (int64_t)kernel->module->heap;\n+  kernargs->abi.heap_ptr = (int64_t)kernel->module->heap;\n \n-  /* Create an arena.  */\n-  if (kernel->kind == KIND_OPENMP)\n-    kernargs->arena_ptr = (int64_t)get_team_arena (agent, num_teams);\n-  else\n-    kernargs->arena_ptr = 0;\n+  /* Create the ephemeral memory spaces.  */\n+  configure_ephemeral_memories (kernel, &kernargs->abi, num_teams, num_threads);\n \n   /* Ensure we can recognize unset return values.  */\n   kernargs->output_data.return_value = 0xcafe0000;\n@@ -2006,9 +2026,10 @@ release_kernel_dispatch (struct kernel_dispatch *shadow)\n   GCN_DEBUG (\"Released kernel dispatch: %p\\n\", shadow);\n \n   struct kernargs *kernargs = shadow->kernarg_address;\n-  void *arena = (void *)kernargs->arena_ptr;\n-  if (arena)\n-    release_team_arena (shadow->agent, arena);\n+  void *addr = (void *)kernargs->abi.arena_ptr;\n+  if (!addr)\n+    addr = (void *)kernargs->abi.stack_ptr;\n+  release_ephemeral_memories (shadow->agent, addr);\n \n   hsa_fns.hsa_memory_free_fn (shadow->kernarg_address);\n \n@@ -2238,7 +2259,8 @@ run_kernel (struct kernel_info *kernel, void *vars,\n \t     packet->workgroup_size_z);\n \n   struct kernel_dispatch *shadow\n-    = create_kernel_dispatch (kernel, packet->grid_size_x);\n+    = create_kernel_dispatch (kernel, packet->grid_size_x,\n+\t\t\t      packet->grid_size_z);\n   shadow->queue = command_q;\n \n   if (debug)\n@@ -3280,14 +3302,14 @@ GOMP_OFFLOAD_init_device (int n)\n       GOMP_PLUGIN_error (\"Failed to initialize a GCN agent queue mutex\");\n       return false;\n     }\n-  if (pthread_mutex_init (&agent->team_arena_write_lock, NULL))\n+  if (pthread_mutex_init (&agent->ephemeral_memories_write_lock, NULL))\n     {\n       GOMP_PLUGIN_error (\"Failed to initialize a GCN team arena write mutex\");\n       return false;\n     }\n   agent->async_queues = NULL;\n   agent->omp_async_queue = NULL;\n-  agent->team_arena_list = NULL;\n+  agent->ephemeral_memories_list = NULL;\n \n   uint32_t queue_size;\n   hsa_status_t status;\n@@ -3640,7 +3662,7 @@ GOMP_OFFLOAD_fini_device (int n)\n       agent->module = NULL;\n     }\n \n-  if (!destroy_team_arenas (agent))\n+  if (!destroy_ephemeral_memories (agent))\n     return false;\n \n   if (!destroy_hsa_program (agent))\n@@ -3666,9 +3688,9 @@ GOMP_OFFLOAD_fini_device (int n)\n       GOMP_PLUGIN_error (\"Failed to destroy a GCN agent queue mutex\");\n       return false;\n     }\n-  if (pthread_mutex_destroy (&agent->team_arena_write_lock))\n+  if (pthread_mutex_destroy (&agent->ephemeral_memories_write_lock))\n     {\n-      GOMP_PLUGIN_error (\"Failed to destroy a GCN team arena mutex\");\n+      GOMP_PLUGIN_error (\"Failed to destroy a GCN memory mutex\");\n       return false;\n     }\n   agent->initialized = false;"}]}