{"sha": "aec7ae7deaef9d52541da07c387066ad6ceb3d87", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YWVjN2FlN2RlYWVmOWQ1MjU0MWRhMDdjMzg3MDY2YWQ2Y2ViM2Q4Nw==", "commit": {"author": {"name": "Jakub Jelinek", "email": "jakub@redhat.com", "date": "2011-11-07T15:59:07Z"}, "committer": {"name": "Jakub Jelinek", "email": "jakub@gcc.gnu.org", "date": "2011-11-07T15:59:07Z"}, "message": "re PR tree-optimization/50789 (Gather vectorization)\n\n\tPR tree-optimization/50789\n\t* tree-vect-stmts.c (process_use): Add force argument, avoid\n\texist_non_indexing_operands_for_use_p check if true.\n\t(vect_mark_stmts_to_be_vectorized): Adjust callers.  Handle\n\tSTMT_VINFO_GATHER_P.\n\t(gen_perm_mask): New function.\n\t(perm_mask_for_reverse): Use it.\n\t(reverse_vec_element): Rename to...\n\t(permute_vec_elements): ... this.  Add Y and MASK_VEC arguments,\n\tgeneralize for any permutations.\n\t(vectorizable_load): Adjust caller.  Handle STMT_VINFO_GATHER_P.\n\t* target.def (TARGET_VECTORIZE_BUILTIN_GATHER): New hook.\n\t* doc/tm.texi.in (TARGET_VECTORIZE_BUILTIN_GATHER): Document it.\n\t* doc/tm.texi: Regenerate.\n\t* tree-data-ref.c (initialize_data_dependence_relation,\n\tcompute_self_dependence): No longer static.\n\t* tree-data-ref.h (initialize_data_dependence_relation,\n\tcompute_self_dependence): New prototypes.\n\t* tree-vect-data-refs.c (vect_check_gather): New function.\n\t(vect_analyze_data_refs): Detect possible gather load data\n\trefs.\n\t* tree-vectorizer.h (struct _stmt_vec_info): Add gather_p field.\n\t(STMT_VINFO_GATHER_P): Define.\n\t(vect_check_gather): New prototype.\n\t* config/i386/i386-builtin-types.def: Add types for alternate\n\tgather builtins.\n\t* config/i386/sse.md (AVXMODE48P_DI): Remove.\n\t(VEC_GATHER_MODE): Rename mode_attr to...\n\t(VEC_GATHER_IDXSI): ... this.\n\t(VEC_GATHER_IDXDI, VEC_GATHER_SRCDI): New mode_attrs.\n\t(avx2_gathersi<mode>, *avx2_gathersi<mode>): Use <VEC_GATHER_IDXSI>\n\tinstead of <VEC_GATHER_MODE>.\n\t(avx2_gatherdi<mode>): Use <VEC_GATHER_IDXDI> instead of\n\t<<AVXMODE48P_DI> and <VEC_GATHER_SRCDI> instead of VEC_GATHER_MODE\n\ton src and mask operands.\n\t(*avx2_gatherdi<mode>): Likewise.  Use VEC_GATHER_MODE iterator\n\tinstead of AVXMODE48P_DI.\n\t(avx2_gatherdi<mode>256, *avx2_gatherdi<mode>256): Removed.\n\t* config/i386/i386.c (enum ix86_builtins): Add\n\tIX86_BUILTIN_GATHERALTSIV4DF, IX86_BUILTIN_GATHERALTDIV8SF,\n\tIX86_BUILTIN_GATHERALTSIV4DI and IX86_BUILTIN_GATHERALTDIV8SI.\n\t(ix86_init_mmx_sse_builtins): Create those builtins.\n\t(ix86_expand_builtin): Handle those builtins and adjust expansions\n\tof other gather builtins.\n\t(ix86_vectorize_builtin_gather): New function.\n\t(TARGET_VECTORIZE_BUILTIN_GATHER): Define.\n\n\t* gcc.target/i386/avx2-gather-1.c: New test.\n\t* gcc.target/i386/avx2-gather-2.c: New test.\n\t* gcc.target/i386/avx2-gather-3.c: New test.\n\t* gcc.target/i386/avx2-gather-4.c: New test.\n\nFrom-SVN: r181089", "tree": {"sha": "f56ca4ced37752007fdc3ce936daa06795357ad2", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/f56ca4ced37752007fdc3ce936daa06795357ad2"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/aec7ae7deaef9d52541da07c387066ad6ceb3d87", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/aec7ae7deaef9d52541da07c387066ad6ceb3d87", "html_url": "https://github.com/Rust-GCC/gccrs/commit/aec7ae7deaef9d52541da07c387066ad6ceb3d87", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/aec7ae7deaef9d52541da07c387066ad6ceb3d87/comments", "author": {"login": "jakubjelinek", "id": 9370665, "node_id": "MDQ6VXNlcjkzNzA2NjU=", "avatar_url": "https://avatars.githubusercontent.com/u/9370665?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jakubjelinek", "html_url": "https://github.com/jakubjelinek", "followers_url": "https://api.github.com/users/jakubjelinek/followers", "following_url": "https://api.github.com/users/jakubjelinek/following{/other_user}", "gists_url": "https://api.github.com/users/jakubjelinek/gists{/gist_id}", "starred_url": "https://api.github.com/users/jakubjelinek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jakubjelinek/subscriptions", "organizations_url": "https://api.github.com/users/jakubjelinek/orgs", "repos_url": "https://api.github.com/users/jakubjelinek/repos", "events_url": "https://api.github.com/users/jakubjelinek/events{/privacy}", "received_events_url": "https://api.github.com/users/jakubjelinek/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "571b34b25eec4909165272e2d5a7084866ddaf96", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/571b34b25eec4909165272e2d5a7084866ddaf96", "html_url": "https://github.com/Rust-GCC/gccrs/commit/571b34b25eec4909165272e2d5a7084866ddaf96"}], "stats": {"total": 1402, "additions": 1279, "deletions": 123}, "files": [{"sha": "0d0db8a391dcba34e0041ea671e618fbb05b7fed", "filename": "gcc/ChangeLog", "status": "modified", "additions": 49, "deletions": 0, "changes": 49, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -1,3 +1,52 @@\n+2011-11-07  Jakub Jelinek  <jakub@redhat.com>\n+\n+\tPR tree-optimization/50789\n+\t* tree-vect-stmts.c (process_use): Add force argument, avoid\n+\texist_non_indexing_operands_for_use_p check if true.\n+\t(vect_mark_stmts_to_be_vectorized): Adjust callers.  Handle\n+\tSTMT_VINFO_GATHER_P.\n+\t(gen_perm_mask): New function.\n+\t(perm_mask_for_reverse): Use it.\n+\t(reverse_vec_element): Rename to...\n+\t(permute_vec_elements): ... this.  Add Y and MASK_VEC arguments,\n+\tgeneralize for any permutations.\n+\t(vectorizable_load): Adjust caller.  Handle STMT_VINFO_GATHER_P.\n+\t* target.def (TARGET_VECTORIZE_BUILTIN_GATHER): New hook.\n+\t* doc/tm.texi.in (TARGET_VECTORIZE_BUILTIN_GATHER): Document it.\n+\t* doc/tm.texi: Regenerate.\n+\t* tree-data-ref.c (initialize_data_dependence_relation,\n+\tcompute_self_dependence): No longer static.\n+\t* tree-data-ref.h (initialize_data_dependence_relation,\n+\tcompute_self_dependence): New prototypes.\n+\t* tree-vect-data-refs.c (vect_check_gather): New function.\n+\t(vect_analyze_data_refs): Detect possible gather load data\n+\trefs.\n+\t* tree-vectorizer.h (struct _stmt_vec_info): Add gather_p field.\n+\t(STMT_VINFO_GATHER_P): Define.\n+\t(vect_check_gather): New prototype.\n+\t* config/i386/i386-builtin-types.def: Add types for alternate\n+\tgather builtins.\n+\t* config/i386/sse.md (AVXMODE48P_DI): Remove.\n+\t(VEC_GATHER_MODE): Rename mode_attr to...\n+\t(VEC_GATHER_IDXSI): ... this.\n+\t(VEC_GATHER_IDXDI, VEC_GATHER_SRCDI): New mode_attrs.\n+\t(avx2_gathersi<mode>, *avx2_gathersi<mode>): Use <VEC_GATHER_IDXSI>\n+\tinstead of <VEC_GATHER_MODE>.\n+\t(avx2_gatherdi<mode>): Use <VEC_GATHER_IDXDI> instead of\n+\t<<AVXMODE48P_DI> and <VEC_GATHER_SRCDI> instead of VEC_GATHER_MODE\n+\ton src and mask operands.\n+\t(*avx2_gatherdi<mode>): Likewise.  Use VEC_GATHER_MODE iterator\n+\tinstead of AVXMODE48P_DI.\n+\t(avx2_gatherdi<mode>256, *avx2_gatherdi<mode>256): Removed.\n+\t* config/i386/i386.c (enum ix86_builtins): Add\n+\tIX86_BUILTIN_GATHERALTSIV4DF, IX86_BUILTIN_GATHERALTDIV8SF,\n+\tIX86_BUILTIN_GATHERALTSIV4DI and IX86_BUILTIN_GATHERALTDIV8SI.\n+\t(ix86_init_mmx_sse_builtins): Create those builtins.\n+\t(ix86_expand_builtin): Handle those builtins and adjust expansions\n+\tof other gather builtins.\n+\t(ix86_vectorize_builtin_gather): New function.\n+\t(TARGET_VECTORIZE_BUILTIN_GATHER): Define.\n+\n 2011-11-07  Uros Bizjak  <ubizjak@gmail.com>\n \n \t* config/i386/f16cintrin: Remove extra _X86INTRIN_H_INCLUDED check."}, {"sha": "84667488780c645600d45cc646817a9a643c724e", "filename": "gcc/config/i386/i386-builtin-types.def", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Fconfig%2Fi386%2Fi386-builtin-types.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Fconfig%2Fi386%2Fi386-builtin-types.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-builtin-types.def?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -432,20 +432,24 @@ DEF_FUNCTION_TYPE (V8QI, QI, QI, QI, QI, QI, QI, QI, QI)\n \n DEF_FUNCTION_TYPE (V2DF, V2DF, PCDOUBLE, V4SI, V2DF, INT)\n DEF_FUNCTION_TYPE (V4DF, V4DF, PCDOUBLE, V4SI, V4DF, INT)\n+DEF_FUNCTION_TYPE (V4DF, V4DF, PCDOUBLE, V8SI, V4DF, INT)\n DEF_FUNCTION_TYPE (V2DF, V2DF, PCDOUBLE, V2DI, V2DF, INT)\n DEF_FUNCTION_TYPE (V4DF, V4DF, PCDOUBLE, V4DI, V4DF, INT)\n DEF_FUNCTION_TYPE (V4SF, V4SF, PCFLOAT, V4SI, V4SF, INT)\n DEF_FUNCTION_TYPE (V8SF, V8SF, PCFLOAT, V8SI, V8SF, INT)\n DEF_FUNCTION_TYPE (V4SF, V4SF, PCFLOAT, V2DI, V4SF, INT)\n DEF_FUNCTION_TYPE (V4SF, V4SF, PCFLOAT, V4DI, V4SF, INT)\n+DEF_FUNCTION_TYPE (V8SF, V8SF, PCFLOAT, V4DI, V8SF, INT)\n DEF_FUNCTION_TYPE (V2DI, V2DI, PCINT64, V4SI, V2DI, INT)\n DEF_FUNCTION_TYPE (V4DI, V4DI, PCINT64, V4SI, V4DI, INT)\n+DEF_FUNCTION_TYPE (V4DI, V4DI, PCINT64, V8SI, V4DI, INT)\n DEF_FUNCTION_TYPE (V2DI, V2DI, PCINT64, V2DI, V2DI, INT)\n DEF_FUNCTION_TYPE (V4DI, V4DI, PCINT64, V4DI, V4DI, INT)\n DEF_FUNCTION_TYPE (V4SI, V4SI, PCINT, V4SI, V4SI, INT)\n DEF_FUNCTION_TYPE (V8SI, V8SI, PCINT, V8SI, V8SI, INT)\n DEF_FUNCTION_TYPE (V4SI, V4SI, PCINT, V2DI, V4SI, INT)\n DEF_FUNCTION_TYPE (V4SI, V4SI, PCINT, V4DI, V4SI, INT)\n+DEF_FUNCTION_TYPE (V8SI, V8SI, PCINT, V4DI, V8SI, INT)\n \n DEF_FUNCTION_TYPE_ALIAS (V2DF_FTYPE_V2DF, ROUND)\n DEF_FUNCTION_TYPE_ALIAS (V4DF_FTYPE_V4DF, ROUND)"}, {"sha": "4d7d2cf1d4aa9402cf4dc693033e32380f7b374b", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 158, "deletions": 5, "changes": 163, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -25190,6 +25190,13 @@ enum ix86_builtins\n   IX86_BUILTIN_GATHERDIV4SI,\n   IX86_BUILTIN_GATHERDIV8SI,\n \n+  /* Alternate 4 element gather for the vectorizer where\n+     all operands are 32-byte wide.  */\n+  IX86_BUILTIN_GATHERALTSIV4DF,\n+  IX86_BUILTIN_GATHERALTDIV8SF,\n+  IX86_BUILTIN_GATHERALTSIV4DI,\n+  IX86_BUILTIN_GATHERALTDIV8SI,\n+\n   /* TFmode support builtins.  */\n   IX86_BUILTIN_INFQ,\n   IX86_BUILTIN_HUGE_VALQ,\n@@ -26968,6 +26975,22 @@ ix86_init_mmx_sse_builtins (void)\n \t       V4SI_FTYPE_V4SI_PCINT_V4DI_V4SI_INT,\n \t       IX86_BUILTIN_GATHERDIV8SI);\n \n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gatheraltsiv4df \",\n+\t       V4DF_FTYPE_V4DF_PCDOUBLE_V8SI_V4DF_INT,\n+\t       IX86_BUILTIN_GATHERALTSIV4DF);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gatheraltdiv4sf256 \",\n+\t       V8SF_FTYPE_V8SF_PCFLOAT_V4DI_V8SF_INT,\n+\t       IX86_BUILTIN_GATHERALTDIV8SF);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gatheraltsiv4di \",\n+\t       V4DI_FTYPE_V4DI_PCINT64_V8SI_V4DI_INT,\n+\t       IX86_BUILTIN_GATHERALTSIV4DI);\n+\n+  def_builtin (OPTION_MASK_ISA_AVX2, \"__builtin_ia32_gatheraltdiv4si256 \",\n+\t       V8SI_FTYPE_V8SI_PCINT_V4DI_V8SI_INT,\n+\t       IX86_BUILTIN_GATHERALTDIV8SI);\n+\n   /* MMX access to the vec_init patterns.  */\n   def_builtin_const (OPTION_MASK_ISA_MMX, \"__builtin_ia32_vec_init_v2si\",\n \t\t     V2SI_FTYPE_INT_INT, IX86_BUILTIN_VEC_INIT_V2SI);\n@@ -28954,7 +28977,7 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n       icode = CODE_FOR_avx2_gatherdiv4sf;\n       goto gather_gen;\n     case IX86_BUILTIN_GATHERDIV8SF:\n-      icode = CODE_FOR_avx2_gatherdiv4sf256;\n+      icode = CODE_FOR_avx2_gatherdiv8sf;\n       goto gather_gen;\n     case IX86_BUILTIN_GATHERSIV2DI:\n       icode = CODE_FOR_avx2_gathersiv2di;\n@@ -28978,7 +29001,20 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n       icode = CODE_FOR_avx2_gatherdiv4si;\n       goto gather_gen;\n     case IX86_BUILTIN_GATHERDIV8SI:\n-      icode = CODE_FOR_avx2_gatherdiv4si256;\n+      icode = CODE_FOR_avx2_gatherdiv8si;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERALTSIV4DF:\n+      icode = CODE_FOR_avx2_gathersiv4df;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERALTDIV8SF:\n+      icode = CODE_FOR_avx2_gatherdiv8sf;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERALTSIV4DI:\n+      icode = CODE_FOR_avx2_gathersiv4df;\n+      goto gather_gen;\n+    case IX86_BUILTIN_GATHERALTDIV8SI:\n+      icode = CODE_FOR_avx2_gatherdiv8si;\n+      goto gather_gen;\n \n     gather_gen:\n       arg0 = CALL_EXPR_ARG (exp, 0);\n@@ -28997,8 +29033,39 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n       mode3 = insn_data[icode].operand[4].mode;\n       mode4 = insn_data[icode].operand[5].mode;\n \n-      if (target == NULL_RTX)\n-\ttarget = gen_reg_rtx (insn_data[icode].operand[0].mode);\n+      if (target == NULL_RTX\n+\t  || GET_MODE (target) != insn_data[icode].operand[0].mode)\n+\tsubtarget = gen_reg_rtx (insn_data[icode].operand[0].mode);\n+      else\n+\tsubtarget = target;\n+\n+      if (fcode == IX86_BUILTIN_GATHERALTSIV4DF\n+\t  || fcode == IX86_BUILTIN_GATHERALTSIV4DI)\n+\t{\n+\t  rtx half = gen_reg_rtx (V4SImode);\n+\t  if (!nonimmediate_operand (op2, V8SImode))\n+\t    op2 = copy_to_mode_reg (V8SImode, op2);\n+\t  emit_insn (gen_vec_extract_lo_v8si (half, op2));\n+\t  op2 = half;\n+\t}\n+      else if (fcode == IX86_BUILTIN_GATHERALTDIV8SF\n+\t       || fcode == IX86_BUILTIN_GATHERALTDIV8SI)\n+\t{\n+\t  rtx (*gen) (rtx, rtx);\n+\t  rtx half = gen_reg_rtx (mode0);\n+\t  if (mode0 == V4SFmode)\n+\t    gen = gen_vec_extract_lo_v8sf;\n+\t  else\n+\t    gen = gen_vec_extract_lo_v8si;\n+\t  if (!nonimmediate_operand (op0, GET_MODE (op0)))\n+\t    op0 = copy_to_mode_reg (GET_MODE (op0), op0);\n+\t  emit_insn (gen (half, op0));\n+\t  op0 = half;\n+\t  if (!nonimmediate_operand (op3, GET_MODE (op3)))\n+\t    op3 = copy_to_mode_reg (GET_MODE (op3), op3);\n+\t  emit_insn (gen (half, op3));\n+\t  op3 = half;\n+\t}\n \n       /* Force memory operand only with base register here.  But we\n \t don't want to do it on memory operand for other builtin\n@@ -29020,10 +29087,26 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n           error (\"last argument must be scale 1, 2, 4, 8\");\n           return const0_rtx;\n \t}\n-      pat = GEN_FCN (icode) (target, op0, op1, op2, op3, op4);\n+      pat = GEN_FCN (icode) (subtarget, op0, op1, op2, op3, op4);\n       if (! pat)\n \treturn const0_rtx;\n       emit_insn (pat);\n+\n+      if (fcode == IX86_BUILTIN_GATHERDIV8SF\n+\t  || fcode == IX86_BUILTIN_GATHERDIV8SI)\n+\t{\n+\t  enum machine_mode tmode = GET_MODE (subtarget) == V8SFmode\n+\t\t\t\t    ? V4SFmode : V4SImode;\n+\t  if (target == NULL_RTX)\n+\t    target = gen_reg_rtx (tmode);\n+\t  if (tmode == V4SFmode)\n+\t    emit_insn (gen_vec_extract_lo_v8sf (target, subtarget));\n+\t  else\n+\t    emit_insn (gen_vec_extract_lo_v8si (target, subtarget));\n+\t}\n+      else\n+\ttarget = subtarget;\n+\n       return target;\n \n     default:\n@@ -29528,6 +29611,73 @@ ix86_veclibabi_acml (enum built_in_function fn, tree type_out, tree type_in)\n   return new_fndecl;\n }\n \n+/* Returns a decl of a function that implements gather load with\n+   memory type MEM_VECTYPE and index type INDEX_VECTYPE and SCALE.\n+   Return NULL_TREE if it is not available.  */\n+\n+static tree\n+ix86_vectorize_builtin_gather (const_tree mem_vectype,\n+\t\t\t       const_tree index_type, int scale)\n+{\n+  bool si;\n+  enum ix86_builtins code;\n+\n+  if (! TARGET_AVX2)\n+    return NULL_TREE;\n+\n+  if ((TREE_CODE (index_type) != INTEGER_TYPE\n+       && !POINTER_TYPE_P (index_type))\n+      || (TYPE_MODE (index_type) != SImode\n+\t  && TYPE_MODE (index_type) != DImode))\n+    return NULL_TREE;\n+\n+  if (TYPE_PRECISION (index_type) > POINTER_SIZE)\n+    return NULL_TREE;\n+\n+  /* v*gather* insn sign extends index to pointer mode.  */\n+  if (TYPE_PRECISION (index_type) < POINTER_SIZE\n+      && TYPE_UNSIGNED (index_type))\n+    return NULL_TREE;\n+\n+  if (scale <= 0\n+      || scale > 8\n+      || (scale & (scale - 1)) != 0)\n+    return NULL_TREE;\n+\n+  si = TYPE_MODE (index_type) == SImode;\n+  switch (TYPE_MODE (mem_vectype))\n+    {\n+    case V2DFmode:\n+      code = si ? IX86_BUILTIN_GATHERSIV2DF : IX86_BUILTIN_GATHERDIV2DF;\n+      break;\n+    case V4DFmode:\n+      code = si ? IX86_BUILTIN_GATHERALTSIV4DF : IX86_BUILTIN_GATHERDIV4DF;\n+      break;\n+    case V2DImode:\n+      code = si ? IX86_BUILTIN_GATHERSIV2DI : IX86_BUILTIN_GATHERDIV2DI;\n+      break;\n+    case V4DImode:\n+      code = si ? IX86_BUILTIN_GATHERALTSIV4DI : IX86_BUILTIN_GATHERDIV4DI;\n+      break;\n+    case V4SFmode:\n+      code = si ? IX86_BUILTIN_GATHERSIV4SF : IX86_BUILTIN_GATHERDIV4SF;\n+      break;\n+    case V8SFmode:\n+      code = si ? IX86_BUILTIN_GATHERSIV8SF : IX86_BUILTIN_GATHERALTDIV8SF;\n+      break;\n+    case V4SImode:\n+      code = si ? IX86_BUILTIN_GATHERSIV4SI : IX86_BUILTIN_GATHERDIV4SI;\n+      break;\n+    case V8SImode:\n+      code = si ? IX86_BUILTIN_GATHERSIV8SI : IX86_BUILTIN_GATHERALTDIV8SI;\n+      break;\n+    default:\n+      return NULL_TREE;\n+    }\n+\n+  return ix86_builtins[code];\n+}\n+\n /* Returns a code for a target-specific builtin that implements\n    reciprocal of the function, or NULL_TREE if not available.  */\n \n@@ -37727,6 +37877,9 @@ ix86_autovectorize_vector_sizes (void)\n #define TARGET_VECTORIZE_BUILTIN_VECTORIZED_FUNCTION \\\n   ix86_builtin_vectorized_function\n \n+#undef TARGET_VECTORIZE_BUILTIN_GATHER\n+#define TARGET_VECTORIZE_BUILTIN_GATHER ix86_vectorize_builtin_gather\n+\n #undef TARGET_BUILTIN_RECIPROCAL\n #define TARGET_BUILTIN_RECIPROCAL ix86_builtin_reciprocal\n "}, {"sha": "e3de9ecdd24f1bd1dfcf04ce480a6f24c2d475f7", "filename": "gcc/config/i386/sse.md", "status": "modified", "additions": 26, "deletions": 63, "changes": 89, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -316,14 +316,6 @@\n ;; Mix-n-match\n (define_mode_iterator AVX256MODE2P [V8SI V8SF V4DF])\n \n-(define_mode_iterator AVXMODE48P_DI\n-\t\t      [V2DI V2DF V4DI V4DF V4SF V4SI])\n-(define_mode_attr AVXMODE48P_DI\n-\t\t      [(V2DI \"V2DI\") (V2DF \"V2DI\")\n-\t\t       (V4DI \"V4DI\") (V4DF \"V4DI\")\n-\t\t       (V4SI \"V2DI\") (V4SF \"V2DI\")\n-\t\t       (V8SI \"V4DI\") (V8SF \"V4DI\")])\n-\n (define_mode_iterator FMAMODE [SF DF V4SF V2DF V8SF V4DF])\n \n ;; Mapping of immediate bits for blend instructions\n@@ -12518,11 +12510,21 @@\n ;; For gather* insn patterns\n (define_mode_iterator VEC_GATHER_MODE\n \t\t      [V2DI V2DF V4DI V4DF V4SI V4SF V8SI V8SF])\n-(define_mode_attr VEC_GATHER_MODE\n+(define_mode_attr VEC_GATHER_IDXSI\n \t\t      [(V2DI \"V4SI\") (V2DF \"V4SI\")\n \t\t       (V4DI \"V4SI\") (V4DF \"V4SI\")\n \t\t       (V4SI \"V4SI\") (V4SF \"V4SI\")\n \t\t       (V8SI \"V8SI\") (V8SF \"V8SI\")])\n+(define_mode_attr VEC_GATHER_IDXDI\n+\t\t      [(V2DI \"V2DI\") (V2DF \"V2DI\")\n+\t\t       (V4DI \"V4DI\") (V4DF \"V4DI\")\n+\t\t       (V4SI \"V2DI\") (V4SF \"V2DI\")\n+\t\t       (V8SI \"V4DI\") (V8SF \"V4DI\")])\n+(define_mode_attr VEC_GATHER_SRCDI\n+\t\t      [(V2DI \"V2DI\") (V2DF \"V2DF\")\n+\t\t       (V4DI \"V4DI\") (V4DF \"V4DF\")\n+\t\t       (V4SI \"V4SI\") (V4SF \"V4SF\")\n+\t\t       (V8SI \"V4SI\") (V8SF \"V4SF\")])\n \n (define_expand \"avx2_gathersi<mode>\"\n   [(parallel [(set (match_operand:VEC_GATHER_MODE 0 \"register_operand\" \"\")\n@@ -12531,7 +12533,8 @@\n \t\t      (mem:<ssescalarmode>\n \t\t\t(match_par_dup 7\n \t\t\t  [(match_operand 2 \"vsib_address_operand\" \"\")\n-\t\t\t   (match_operand:<VEC_GATHER_MODE> 3 \"register_operand\" \"\")\n+\t\t\t   (match_operand:<VEC_GATHER_IDXSI>\n+\t\t\t      3 \"register_operand\" \"\")\n \t\t\t   (match_operand:SI 5 \"const1248_operand \" \"\")]))\n \t\t      (mem:BLK (scratch))\n \t\t      (match_operand:VEC_GATHER_MODE 4 \"register_operand\" \"\")]\n@@ -12551,7 +12554,7 @@\n \t   (match_operator:<ssescalarmode> 7 \"vsib_mem_operator\"\n \t     [(unspec:P\n \t\t[(match_operand:P 3 \"vsib_address_operand\" \"p\")\n-\t\t (match_operand:<VEC_GATHER_MODE> 4 \"register_operand\" \"x\")\n+\t\t (match_operand:<VEC_GATHER_IDXSI> 4 \"register_operand\" \"x\")\n \t\t (match_operand:SI 6 \"const1248_operand\" \"n\")]\n \t\tUNSPEC_VSIBADDR)])\n \t   (mem:BLK (scratch))\n@@ -12567,14 +12570,16 @@\n (define_expand \"avx2_gatherdi<mode>\"\n   [(parallel [(set (match_operand:VEC_GATHER_MODE 0 \"register_operand\" \"\")\n \t\t   (unspec:VEC_GATHER_MODE\n-\t\t     [(match_operand:VEC_GATHER_MODE 1 \"register_operand\" \"\")\n+\t\t     [(match_operand:<VEC_GATHER_SRCDI> 1 \"register_operand\" \"\")\n \t\t      (mem:<ssescalarmode>\n \t\t\t(match_par_dup 7\n \t\t\t  [(match_operand 2 \"vsib_address_operand\" \"\")\n-\t\t\t   (match_operand:<AVXMODE48P_DI> 3 \"register_operand\" \"\")\n+\t\t\t   (match_operand:<VEC_GATHER_IDXDI>\n+\t\t\t      3 \"register_operand\" \"\")\n \t\t\t   (match_operand:SI 5 \"const1248_operand \" \"\")]))\n \t\t      (mem:BLK (scratch))\n-\t\t      (match_operand:VEC_GATHER_MODE 4 \"register_operand\" \"\")]\n+\t\t      (match_operand:<VEC_GATHER_SRCDI>\n+\t\t\t4 \"register_operand\" \"\")]\n \t\t     UNSPEC_GATHER))\n \t      (clobber (match_scratch:VEC_GATHER_MODE 6 \"\"))])]\n   \"TARGET_AVX2\"\n@@ -12585,63 +12590,21 @@\n })\n \n (define_insn \"*avx2_gatherdi<mode>\"\n-  [(set (match_operand:AVXMODE48P_DI 0 \"register_operand\" \"=&x\")\n-\t(unspec:AVXMODE48P_DI\n-\t  [(match_operand:AVXMODE48P_DI 2 \"register_operand\" \"0\")\n+  [(set (match_operand:VEC_GATHER_MODE 0 \"register_operand\" \"=&x\")\n+\t(unspec:VEC_GATHER_MODE\n+\t  [(match_operand:<VEC_GATHER_SRCDI> 2 \"register_operand\" \"0\")\n \t   (match_operator:<ssescalarmode> 7 \"vsib_mem_operator\"\n \t     [(unspec:P\n \t\t[(match_operand:P 3 \"vsib_address_operand\" \"p\")\n-\t\t (match_operand:<AVXMODE48P_DI> 4 \"register_operand\" \"x\")\n+\t\t (match_operand:<VEC_GATHER_IDXDI> 4 \"register_operand\" \"x\")\n \t\t (match_operand:SI 6 \"const1248_operand\" \"n\")]\n \t\tUNSPEC_VSIBADDR)])\n \t   (mem:BLK (scratch))\n-\t   (match_operand:AVXMODE48P_DI 5 \"register_operand\" \"1\")]\n+\t   (match_operand:<VEC_GATHER_SRCDI> 5 \"register_operand\" \"1\")]\n \t  UNSPEC_GATHER))\n-   (clobber (match_scratch:AVXMODE48P_DI 1 \"=&x\"))]\n-  \"TARGET_AVX2\"\n-  \"v<sseintprefix>gatherq<ssemodesuffix>\\t{%1, %7, %0|%0, %7, %1}\"\n-  [(set_attr \"type\" \"ssemov\")\n-   (set_attr \"prefix\" \"vex\")\n-   (set_attr \"mode\" \"<sseinsnmode>\")])\n-\n-;; Special handling for VEX.256 with float arguments\n-;; since there're still xmms as operands\n-(define_expand \"avx2_gatherdi<mode>256\"\n-  [(parallel [(set (match_operand:VI4F_128 0 \"register_operand\" \"\")\n-\t\t   (unspec:VI4F_128\n-\t\t     [(match_operand:VI4F_128 1 \"register_operand\" \"\")\n-\t\t      (mem:<ssescalarmode>\n-\t\t\t(match_par_dup 7\n-\t\t\t  [(match_operand 2 \"vsib_address_operand\" \"\")\n-\t\t\t   (match_operand:V4DI 3 \"register_operand\" \"\")\n-\t\t\t   (match_operand:SI 5 \"const1248_operand \" \"\")]))\n-\t\t      (mem:BLK (scratch))\n-\t\t      (match_operand:VI4F_128 4 \"register_operand\" \"\")]\n-\t\t     UNSPEC_GATHER))\n-\t      (clobber (match_scratch:VI4F_128 6 \"\"))])]\n-  \"TARGET_AVX2\"\n-{\n-  operands[7]\n-    = gen_rtx_UNSPEC (Pmode, gen_rtvec (3, operands[2], operands[3],\n-\t\t\t\t\toperands[5]), UNSPEC_VSIBADDR);\n-})\n-\n-(define_insn \"*avx2_gatherdi<mode>256\"\n-  [(set (match_operand:VI4F_128 0 \"register_operand\" \"=x\")\n-\t(unspec:VI4F_128\n-\t  [(match_operand:VI4F_128 2 \"register_operand\" \"0\")\n-\t   (match_operator:<ssescalarmode> 7 \"vsib_mem_operator\"\n-\t     [(unspec:P\n-\t\t[(match_operand:P 3 \"vsib_address_operand\" \"p\")\n-\t\t (match_operand:V4DI 4 \"register_operand\" \"x\")\n-\t\t (match_operand:SI 6 \"const1248_operand\" \"n\")]\n-\t\tUNSPEC_VSIBADDR)])\n-\t   (mem:BLK (scratch))\n-\t   (match_operand:VI4F_128 5 \"register_operand\" \"1\")]\n-\t  UNSPEC_GATHER)) \n-   (clobber (match_scratch:VI4F_128 1 \"=&x\"))]\n+   (clobber (match_scratch:VEC_GATHER_MODE 1 \"=&x\"))]\n   \"TARGET_AVX2\"\n-  \"v<sseintprefix>gatherq<ssemodesuffix>\\t{%1, %7, %0|%0, %7, %1}\"\n+  \"v<sseintprefix>gatherq<ssemodesuffix>\\t{%5, %7, %2|%2, %7, %5}\"\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"<sseinsnmode>\")])"}, {"sha": "fed770265b97f7175262e3422e54a4e14c219be7", "filename": "gcc/doc/tm.texi", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Fdoc%2Ftm.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Fdoc%2Ftm.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Ftm.texi?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -5758,6 +5758,14 @@ mode returned by @code{TARGET_VECTORIZE_PREFERRED_SIMD_MODE}.\n The default is zero which means to not iterate over other vector sizes.\n @end deftypefn\n \n+@deftypefn {Target Hook} tree TARGET_VECTORIZE_BUILTIN_GATHER (const_tree @var{mem_vectype}, const_tree @var{index_type}, int @var{scale})\n+Target builtin that implements vector gather operation.  @var{mem_vectype}\n+is the vector type of the load and @var{index_type} is scalar type of\n+the index, scaled by @var{scale}.\n+The default is @code{NULL_TREE} which means to not vectorize gather\n+loads.\n+@end deftypefn\n+\n @node Anchored Addresses\n @section Anchored Addresses\n @cindex anchored addresses"}, {"sha": "f0c6ce0a77118c082d2b969a75314145989efc25", "filename": "gcc/doc/tm.texi.in", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Fdoc%2Ftm.texi.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Fdoc%2Ftm.texi.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Ftm.texi.in?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -5696,6 +5696,14 @@ mode returned by @code{TARGET_VECTORIZE_PREFERRED_SIMD_MODE}.\n The default is zero which means to not iterate over other vector sizes.\n @end deftypefn\n \n+@hook TARGET_VECTORIZE_BUILTIN_GATHER\n+Target builtin that implements vector gather operation.  @var{mem_vectype}\n+is the vector type of the load and @var{index_type} is scalar type of\n+the index, scaled by @var{scale}.\n+The default is @code{NULL_TREE} which means to not vectorize gather\n+loads.\n+@end deftypefn\n+\n @node Anchored Addresses\n @section Anchored Addresses\n @cindex anchored addresses"}, {"sha": "a83088d29004e196921de51790b79cc7104bc2d5", "filename": "gcc/target.def", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftarget.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftarget.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftarget.def?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -1021,6 +1021,14 @@ DEFHOOK\n  (void),\n  default_autovectorize_vector_sizes)\n \n+/* Target builtin that implements vector gather operation.  */\n+DEFHOOK\n+(builtin_gather,\n+ \"\",\n+ tree,\n+ (const_tree mem_vectype, const_tree index_type, int scale),\n+ NULL)\n+\n HOOK_VECTOR_END (vectorize)\n \n #undef HOOK_PREFIX"}, {"sha": "46f702a66b54889a690a80197a0befee3aae3954", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -1,3 +1,11 @@\n+2011-11-07  Jakub Jelinek  <jakub@redhat.com>\n+\n+\tPR tree-optimization/50789\n+\t* gcc.target/i386/avx2-gather-1.c: New test.\n+\t* gcc.target/i386/avx2-gather-2.c: New test.\n+\t* gcc.target/i386/avx2-gather-3.c: New test.\n+\t* gcc.target/i386/avx2-gather-4.c: New test.\n+\n 2011-11-07  Uros Bizjak  <ubizjak@gmail.com>\n \n \t* gcc.target/i386/pr49781-1.c (dg-options): Add -mtune=generic."}, {"sha": "7ed567dc491761f0d3629b355dc85c2f95c613d6", "filename": "gcc/testsuite/gcc.target/i386/avx2-gather-1.c", "status": "added", "additions": 215, "deletions": 0, "changes": 215, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx2-gather-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx2-gather-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx2-gather-1.c?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -0,0 +1,215 @@\n+/* { dg-do run } */\n+/* { dg-require-effective-target avx2 } */\n+/* { dg-options \"-O3 -mavx2\" } */\n+\n+#include \"avx2-check.h\"\n+\n+#define N 1024\n+float vf1[N+16], vf2[N];\n+double vd1[N+16], vd2[N];\n+int k[N];\n+long l[N];\n+short n[N];\n+\n+__attribute__((noinline, noclone)) void\n+f1 (void)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    vf2[i] = vf1[k[i]];\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f2 (void)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    n[i] = (int) vf1[k[i]];\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f3 (int x)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    vf2[i] = vf1[k[i] + x];\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f4 (int x)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    n[i] = (int) vf1[k[i] + x];\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f5 (void)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    vd2[i] = vd1[k[i]];\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f6 (void)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    n[i] = (int) vd1[k[i]];\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f7 (int x)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    vd2[i] = vd1[k[i] + x];\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f8 (int x)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    n[i] = (int) vd1[k[i] + x];\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f9 (void)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    vf2[i] = vf1[l[i]];\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f10 (void)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    n[i] = (int) vf1[l[i]];\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f11 (long x)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    vf2[i] = vf1[l[i] + x];\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f12 (long x)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    n[i] = (int) vf1[l[i] + x];\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f13 (void)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    vd2[i] = vd1[l[i]];\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f14 (void)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    n[i] = (int) vd1[l[i]];\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f15 (long x)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    vd2[i] = vd1[l[i] + x];\n+}\n+\n+__attribute__((noinline, noclone)) void\n+f16 (long x)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    n[i] = (int) vd1[l[i] + x];\n+}\n+\n+static void\n+avx2_test (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < N + 16; i++)\n+    {\n+      asm (\"\");\n+      vf1[i] = 17.0f + i;\n+      vd1[i] = 19.0 + i;\n+    }\n+  for (i = 0; i < N; i++)\n+    {\n+      asm (\"\");\n+      k[i] = (i * 731) & (N - 1);\n+      l[i] = (i * 657) & (N - 1);\n+    }\n+\n+  f1 ();\n+  f2 ();\n+  for (i = 0; i < N; i++)\n+    if (vf2[i] != ((i * 731) & (N - 1)) + 17\n+\t|| n[i] != ((i * 731) & (N - 1)) + 17)\n+      abort ();\n+\n+  f3 (12);\n+  f4 (14);\n+  for (i = 0; i < N; i++)\n+    if (vf2[i] != ((i * 731) & (N - 1)) + 17 + 12\n+\t|| n[i] != ((i * 731) & (N - 1)) + 17 + 14)\n+      abort ();\n+\n+  f5 ();\n+  f6 ();\n+  for (i = 0; i < N; i++)\n+    if (vd2[i] != ((i * 731) & (N - 1)) + 19\n+\t|| n[i] != ((i * 731) & (N - 1)) + 19)\n+      abort ();\n+\n+  f7 (7);\n+  f8 (9);\n+  for (i = 0; i < N; i++)\n+    if (vd2[i] != ((i * 731) & (N - 1)) + 19 + 7\n+\t|| n[i] != ((i * 731) & (N - 1)) + 19 + 9)\n+      abort ();\n+\n+  f9 ();\n+  f10 ();\n+  for (i = 0; i < N; i++)\n+    if (vf2[i] != ((i * 657) & (N - 1)) + 17\n+\t|| n[i] != ((i * 657) & (N - 1)) + 17)\n+      abort ();\n+\n+  f11 (2);\n+  f12 (4);\n+  for (i = 0; i < N; i++)\n+    if (vf2[i] != ((i * 657) & (N - 1)) + 17 + 2\n+\t|| n[i] != ((i * 657) & (N - 1)) + 17 + 4)\n+      abort ();\n+\n+  f13 ();\n+  f14 ();\n+  for (i = 0; i < N; i++)\n+    if (vd2[i] != ((i * 657) & (N - 1)) + 19\n+\t|| n[i] != ((i * 657) & (N - 1)) + 19)\n+      abort ();\n+\n+  f15 (13);\n+  f16 (15);\n+  for (i = 0; i < N; i++)\n+    if (vd2[i] != ((i * 657) & (N - 1)) + 19 + 13\n+\t|| n[i] != ((i * 657) & (N - 1)) + 19 + 15)\n+      abort ();\n+}"}, {"sha": "8a7fe95a238be72d6c436e673ec35f9470e828f0", "filename": "gcc/testsuite/gcc.target/i386/avx2-gather-2.c", "status": "added", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx2-gather-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx2-gather-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx2-gather-2.c?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -0,0 +1,7 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O3 -mavx2 -fdump-tree-vect-details\" } */\n+\n+#include \"avx2-gather-1.c\"\n+\n+/* { dg-final { scan-tree-dump-times \"note: vectorized 1 loops in function\" 16 \"vect\" } } */\n+/* { dg-final { cleanup-tree-dump \"vect\" } } */"}, {"sha": "fb6289c0e7e07f502b015105334b4ea39008cfec", "filename": "gcc/testsuite/gcc.target/i386/avx2-gather-3.c", "status": "added", "additions": 167, "deletions": 0, "changes": 167, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx2-gather-3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx2-gather-3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx2-gather-3.c?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -0,0 +1,167 @@\n+/* { dg-do run } */\n+/* { dg-require-effective-target avx2 } */\n+/* { dg-options \"-O3 -mavx2 -ffast-math\" } */\n+\n+#include \"avx2-check.h\"\n+\n+#define N 1024\n+float f[N];\n+double d[N];\n+int k[N];\n+float *l[N];\n+double *n[N];\n+int **m[N];\n+long **o[N];\n+long q[N];\n+long *r[N];\n+int *s[N];\n+\n+__attribute__((noinline, noclone)) float\n+f1 (void)\n+{\n+  int i;\n+  float g = 0.0;\n+  for (i = 0; i < N / 2; i++)\n+    g += f[k[i]];\n+  return g;\n+}\n+\n+__attribute__((noinline, noclone)) float\n+f2 (float *p)\n+{\n+  int i;\n+  float g = 0.0;\n+  for (i = 0; i < N / 2; i++)\n+    g += p[k[i]];\n+  return g;\n+}\n+\n+__attribute__((noinline, noclone)) float\n+f3 (void)\n+{\n+  int i;\n+  float g = 0.0;\n+  for (i = 0; i < N / 2; i++)\n+    g += *l[i];\n+  return g;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f4 (void)\n+{\n+  int i;\n+  int g = 0;\n+  for (i = 0; i < N / 2; i++)\n+    g += **m[i];\n+  return g;\n+}\n+\n+__attribute__((noinline, noclone)) double\n+f5 (void)\n+{\n+  int i;\n+  double g = 0.0;\n+  for (i = 0; i < N / 2; i++)\n+    g += d[k[i]];\n+  return g;\n+}\n+\n+__attribute__((noinline, noclone)) double\n+f6 (double *p)\n+{\n+  int i;\n+  double g = 0.0;\n+  for (i = 0; i < N / 2; i++)\n+    g += p[k[i]];\n+  return g;\n+}\n+\n+__attribute__((noinline, noclone)) double\n+f7 (void)\n+{\n+  int i;\n+  double g = 0.0;\n+  for (i = 0; i < N / 2; i++)\n+    g += *n[i];\n+  return g;\n+}\n+\n+__attribute__((noinline, noclone)) int\n+f8 (void)\n+{\n+  int i;\n+  int g = 0;\n+  for (i = 0; i < N / 2; i++)\n+    g += **o[i];\n+  return g;\n+}\n+\n+__attribute__((noinline, noclone)) float\n+f9 (void)\n+{\n+  int i;\n+  float g = 0.0;\n+  for (i = 0; i < N / 2; i++)\n+    g += f[q[i]];\n+  return g;\n+}\n+\n+__attribute__((noinline, noclone)) float\n+f10 (float *p)\n+{\n+  int i;\n+  float g = 0.0;\n+  for (i = 0; i < N / 2; i++)\n+    g += p[q[i]];\n+  return g;\n+}\n+\n+__attribute__((noinline, noclone)) double\n+f11 (void)\n+{\n+  int i;\n+  double g = 0.0;\n+  for (i = 0; i < N / 2; i++)\n+    g += d[q[i]];\n+  return g;\n+}\n+\n+__attribute__((noinline, noclone)) double\n+f12 (double *p)\n+{\n+  int i;\n+  double g = 0.0;\n+  for (i = 0; i < N / 2; i++)\n+    g += p[q[i]];\n+  return g;\n+}\n+\n+static void\n+avx2_test (void)\n+{\n+  int i;\n+\n+  for (i = 0; i < N; i++)\n+    {\n+      asm (\"\");\n+      f[i] = -256.0f + i;\n+      d[i] = -258.0 + i;\n+      k[i] = (i * 731) & (N - 1);\n+      q[i] = (i * 657) & (N - 1);\n+      l[i] = &f[(i * 239) & (N - 1)];\n+      n[i] = &d[(i * 271) & (N - 1)];\n+      r[i] = &q[(i * 323) & (N - 1)];\n+      s[i] = &k[(i * 565) & (N - 1)];\n+      m[i] = &s[(i * 13) & (N - 1)];\n+      o[i] = &r[(i * 19) & (N - 1)];\n+    }\n+\n+  if (f1 () != 136448.0f || f2 (f) != 136448.0f || f3 () != 130304.0)\n+    abort ();\n+  if (f4 () != 261376 || f5 () != 135424.0 || f6 (d) != 135424.0)\n+    abort ();\n+  if (f7 () != 129280.0 || f8 () != 259840L || f9 () != 130816.0f)\n+    abort ();\n+  if (f10 (f) != 130816.0f || f11 () != 129792.0 || f12 (d) != 129792.0)\n+    abort ();\n+}"}, {"sha": "440a9c9b1646c9d137483068324fcbd4b54cff4a", "filename": "gcc/testsuite/gcc.target/i386/avx2-gather-4.c", "status": "added", "additions": 38, "deletions": 0, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx2-gather-4.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx2-gather-4.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx2-gather-4.c?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -0,0 +1,38 @@\n+/* { dg-do run } */\n+/* { dg-require-effective-target avx2 } */\n+/* { dg-options \"-O3 -mavx2\" } */\n+\n+#include \"avx2-check.h\"\n+\n+#define N 1024\n+int a[N], b[N], c[N], d[N];\n+\n+__attribute__((noinline, noclone)) void\n+foo (float *__restrict p, float *__restrict q, float *__restrict r,\n+     long s1, long s2, long s3)\n+{\n+  int i;\n+  for (i = 0; i < N; i++)\n+    p[i] = q[a[i] * s1 + b[i] * s2 + s3] * r[c[i] * s1 + d[i] * s2 + s3];\n+}\n+\n+static void\n+avx2_test (void)\n+{\n+  int i;\n+  float e[N], f[N], g[N];\n+  for (i = 0; i < N; i++)\n+    {\n+      a[i] = (i * 7) & (N / 8 - 1);\n+      b[i] = (i * 13) & (N / 8 - 1);\n+      c[i] = (i * 23) & (N / 8 - 1);\n+      d[i] = (i * 5) & (N / 8 - 1);\n+      e[i] = 16.5 + i;\n+      f[i] = 127.5 - i;\n+    }\n+  foo (g, e, f, 3, 2, 4);\n+  for (i = 0; i < N; i++)\n+    if (g[i] != (float) ((20.5 + a[i] * 3 + b[i] * 2)\n+\t\t\t * (123.5 - c[i] * 3 - d[i] * 2)))\n+      abort ();\n+}"}, {"sha": "89d123d65e9742bc91d9dc8a5bdf59b953711a9e", "filename": "gcc/tree-data-ref.c", "status": "modified", "additions": 2, "deletions": 4, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftree-data-ref.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftree-data-ref.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-data-ref.c?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -1351,13 +1351,11 @@ dr_may_alias_p (const struct data_reference *a, const struct data_reference *b,\n   return refs_may_alias_p (addr_a, addr_b);\n }\n \n-static void compute_self_dependence (struct data_dependence_relation *);\n-\n /* Initialize a data dependence relation between data accesses A and\n    B.  NB_LOOPS is the number of loops surrounding the references: the\n    size of the classic distance/direction vectors.  */\n \n-static struct data_dependence_relation *\n+struct data_dependence_relation *\n initialize_data_dependence_relation (struct data_reference *a,\n \t\t\t\t     struct data_reference *b,\n  \t\t\t\t     VEC (loop_p, heap) *loop_nest)\n@@ -4121,7 +4119,7 @@ compute_affine_dependence (struct data_dependence_relation *ddr,\n /* This computes the dependence relation for the same data\n    reference into DDR.  */\n \n-static void\n+void\n compute_self_dependence (struct data_dependence_relation *ddr)\n {\n   unsigned int i;"}, {"sha": "0f12962fc93ca6f5cab901289655cb7794ccd804", "filename": "gcc/tree-data-ref.h", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftree-data-ref.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftree-data-ref.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-data-ref.h?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -1,5 +1,5 @@\n /* Data references and dependences detectors.\n-   Copyright (C) 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010\n+   Copyright (C) 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011\n    Free Software Foundation, Inc.\n    Contributed by Sebastian Pop <pop@cri.ensmp.fr>\n \n@@ -423,6 +423,9 @@ extern bool graphite_find_data_references_in_stmt (loop_p, loop_p, gimple,\n \t\t\t\t\t\t   VEC (data_reference_p, heap) **);\n struct data_reference *create_data_ref (loop_p, loop_p, tree, gimple, bool);\n extern bool find_loop_nest (struct loop *, VEC (loop_p, heap) **);\n+extern struct data_dependence_relation *initialize_data_dependence_relation\n+     (struct data_reference *, struct data_reference *, VEC (loop_p, heap) *); \n+extern void compute_self_dependence (struct data_dependence_relation *);\n extern void compute_all_dependences (VEC (data_reference_p, heap) *,\n \t\t\t\t     VEC (ddr_p, heap) **, VEC (loop_p, heap) *,\n \t\t\t\t     bool);"}, {"sha": "0ff8ee83d40a371a742fddae8a7109da41d2c1b5", "filename": "gcc/tree-vect-data-refs.c", "status": "modified", "additions": 330, "deletions": 16, "changes": 346, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftree-vect-data-refs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftree-vect-data-refs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-data-refs.c?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -2497,6 +2497,199 @@ vect_prune_runtime_alias_test_list (loop_vec_info loop_vinfo)\n   return true;\n }\n \n+/* Check whether a non-affine read in stmt is suitable for gather load\n+   and if so, return a builtin decl for that operation.  */\n+\n+tree\n+vect_check_gather (gimple stmt, loop_vec_info loop_vinfo, tree *basep,\n+\t\t   tree *offp, int *scalep)\n+{\n+  HOST_WIDE_INT scale = 1, pbitpos, pbitsize;\n+  struct loop *loop = LOOP_VINFO_LOOP (loop_vinfo);\n+  stmt_vec_info stmt_info = vinfo_for_stmt (stmt);\n+  struct data_reference *dr = STMT_VINFO_DATA_REF (stmt_info);\n+  tree offtype = NULL_TREE;\n+  tree decl, base, off;\n+  enum machine_mode pmode;\n+  int punsignedp, pvolatilep;\n+\n+  /* The gather builtins need address of the form\n+     loop_invariant + vector * {1, 2, 4, 8}\n+     or\n+     loop_invariant + sign_extend (vector) * { 1, 2, 4, 8 }.\n+     Unfortunately DR_BASE_ADDRESS/DR_OFFSET can be a mixture\n+     of loop invariants/SSA_NAMEs defined in the loop, with casts,\n+     multiplications and additions in it.  To get a vector, we need\n+     a single SSA_NAME that will be defined in the loop and will\n+     contain everything that is not loop invariant and that can be\n+     vectorized.  The following code attempts to find such a preexistng\n+     SSA_NAME OFF and put the loop invariants into a tree BASE\n+     that can be gimplified before the loop.  */\n+  base = get_inner_reference (DR_REF (dr), &pbitsize, &pbitpos, &off,\n+\t\t\t      &pmode, &punsignedp, &pvolatilep, false);\n+  gcc_assert (base != NULL_TREE && (pbitpos % BITS_PER_UNIT) == 0);\n+\n+  if (TREE_CODE (base) == MEM_REF)\n+    {\n+      if (!integer_zerop (TREE_OPERAND (base, 1)))\n+\t{\n+\t  if (off == NULL_TREE)\n+\t    {\n+\t      double_int moff = mem_ref_offset (base);\n+\t      off = double_int_to_tree (sizetype, moff);\n+\t    }\n+\t  else\n+\t    off = size_binop (PLUS_EXPR, off,\n+\t\t\t      fold_convert (sizetype, TREE_OPERAND (base, 1)));\n+\t}\n+      base = TREE_OPERAND (base, 0);\n+    }\n+  else\n+    base = build_fold_addr_expr (base);\n+\n+  if (off == NULL_TREE)\n+    off = size_zero_node;\n+\n+  /* If base is not loop invariant, either off is 0, then we start with just\n+     the constant offset in the loop invariant BASE and continue with base\n+     as OFF, otherwise give up.\n+     We could handle that case by gimplifying the addition of base + off\n+     into some SSA_NAME and use that as off, but for now punt.  */\n+  if (!expr_invariant_in_loop_p (loop, base))\n+    {\n+      if (!integer_zerop (off))\n+\treturn NULL_TREE;\n+      off = base;\n+      base = size_int (pbitpos / BITS_PER_UNIT);\n+    }\n+  /* Otherwise put base + constant offset into the loop invariant BASE\n+     and continue with OFF.  */\n+  else\n+    {\n+      base = fold_convert (sizetype, base);\n+      base = size_binop (PLUS_EXPR, base, size_int (pbitpos / BITS_PER_UNIT));\n+    }\n+\n+  /* OFF at this point may be either a SSA_NAME or some tree expression\n+     from get_inner_reference.  Try to peel off loop invariants from it\n+     into BASE as long as possible.  */\n+  STRIP_NOPS (off);\n+  while (offtype == NULL_TREE)\n+    {\n+      enum tree_code code;\n+      tree op0, op1, add = NULL_TREE;\n+\n+      if (TREE_CODE (off) == SSA_NAME)\n+\t{\n+\t  gimple def_stmt = SSA_NAME_DEF_STMT (off);\n+\n+\t  if (expr_invariant_in_loop_p (loop, off))\n+\t    return NULL_TREE;\n+\n+\t  if (gimple_code (def_stmt) != GIMPLE_ASSIGN)\n+\t    break;\n+\n+\t  op0 = gimple_assign_rhs1 (def_stmt);\n+\t  code = gimple_assign_rhs_code (def_stmt);\n+\t  op1 = gimple_assign_rhs2 (def_stmt);\n+\t}\n+      else\n+\t{\n+\t  if (get_gimple_rhs_class (TREE_CODE (off)) == GIMPLE_TERNARY_RHS)\n+\t    return NULL_TREE;\n+\t  code = TREE_CODE (off);\n+\t  extract_ops_from_tree (off, &code, &op0, &op1);\n+\t}\n+      switch (code)\n+\t{\n+\tcase POINTER_PLUS_EXPR:\n+\tcase PLUS_EXPR:\n+\t  if (expr_invariant_in_loop_p (loop, op0))\n+\t    {\n+\t      add = op0;\n+\t      off = op1;\n+\t    do_add:\n+\t      add = fold_convert (sizetype, add);\n+\t      if (scale != 1)\n+\t\tadd = size_binop (MULT_EXPR, add, size_int (scale));\n+\t      base = size_binop (PLUS_EXPR, base, add);\n+\t      continue;\n+\t    }\n+\t  if (expr_invariant_in_loop_p (loop, op1))\n+\t    {\n+\t      add = op1;\n+\t      off = op0;\n+\t      goto do_add;\n+\t    }\n+\t  break;\n+\tcase MINUS_EXPR:\n+\t  if (expr_invariant_in_loop_p (loop, op1))\n+\t    {\n+\t      add = fold_convert (sizetype, op1);\n+\t      add = size_binop (MINUS_EXPR, size_zero_node, add);\n+\t      off = op0;\n+\t      goto do_add;\n+\t    }\n+\t  break;\n+\tcase MULT_EXPR:\n+\t  if (scale == 1 && host_integerp (op1, 0))\n+\t    {\n+\t      scale = tree_low_cst (op1, 0);\n+\t      off = op0;\n+\t      continue;\n+\t    }\n+\t  break;\n+\tcase SSA_NAME:\n+\t  off = op0;\n+\t  continue;\n+\tCASE_CONVERT:\n+\t  if (!POINTER_TYPE_P (TREE_TYPE (op0))\n+\t      && !INTEGRAL_TYPE_P (TREE_TYPE (op0)))\n+\t    break;\n+\t  if (TYPE_PRECISION (TREE_TYPE (op0))\n+\t      == TYPE_PRECISION (TREE_TYPE (off)))\n+\t    {\n+\t      off = op0;\n+\t      continue;\n+\t    }\n+\t  if (TYPE_PRECISION (TREE_TYPE (op0))\n+\t      < TYPE_PRECISION (TREE_TYPE (off)))\n+\t    {\n+\t      off = op0;\n+\t      offtype = TREE_TYPE (off);\n+\t      STRIP_NOPS (off);\n+\t      continue;\n+\t    }\n+\t  break;\n+\tdefault:\n+\t  break;\n+\t}\n+      break;\n+    }\n+\n+  /* If at the end OFF still isn't a SSA_NAME or isn't\n+     defined in the loop, punt.  */\n+  if (TREE_CODE (off) != SSA_NAME\n+      || expr_invariant_in_loop_p (loop, off))\n+    return NULL_TREE;\n+\n+  if (offtype == NULL_TREE)\n+    offtype = TREE_TYPE (off);\n+\n+  decl = targetm.vectorize.builtin_gather (STMT_VINFO_VECTYPE (stmt_info),\n+\t\t\t\t\t   offtype, scale);\n+  if (decl == NULL_TREE)\n+    return NULL_TREE;\n+\n+  if (basep)\n+    *basep = base;\n+  if (offp)\n+    *offp = off;\n+  if (scalep)\n+    *scalep = scale;\n+  return decl;\n+}\n+\n \n /* Function vect_analyze_data_refs.\n \n@@ -2573,6 +2766,7 @@ vect_analyze_data_refs (loop_vec_info loop_vinfo,\n       gimple stmt;\n       stmt_vec_info stmt_info;\n       tree base, offset, init;\n+      bool gather = false;\n       int vf;\n \n       if (!dr || !DR_REF (dr))\n@@ -2594,22 +2788,51 @@ vect_analyze_data_refs (loop_vec_info loop_vinfo,\n \n       /* Check that analysis of the data-ref succeeded.  */\n       if (!DR_BASE_ADDRESS (dr) || !DR_OFFSET (dr) || !DR_INIT (dr)\n-          || !DR_STEP (dr))\n+\t  || !DR_STEP (dr))\n         {\n-          if (vect_print_dump_info (REPORT_UNVECTORIZED_LOCATIONS))\n-            {\n-              fprintf (vect_dump, \"not vectorized: data ref analysis failed \");\n-              print_gimple_stmt (vect_dump, stmt, 0, TDF_SLIM);\n-            }\n+\t  /* If target supports vector gather loads, see if they can't\n+\t     be used.  */\n+\t  if (loop_vinfo\n+\t      && DR_IS_READ (dr)\n+\t      && !TREE_THIS_VOLATILE (DR_REF (dr))\n+\t      && targetm.vectorize.builtin_gather != NULL\n+\t      && !nested_in_vect_loop_p (loop, stmt))\n+\t    {\n+\t      struct data_reference *newdr\n+\t\t= create_data_ref (NULL, loop_containing_stmt (stmt),\n+\t\t\t\t   DR_REF (dr), stmt, true);\n+\t      gcc_assert (newdr != NULL && DR_REF (newdr));\n+\t      if (DR_BASE_ADDRESS (newdr)\n+\t\t  && DR_OFFSET (newdr)\n+\t\t  && DR_INIT (newdr)\n+\t\t  && DR_STEP (newdr)\n+\t\t  && integer_zerop (DR_STEP (newdr)))\n+\t\t{\n+\t\t  dr = newdr;\n+\t\t  gather = true;\n+\t\t}\n+\t      else\n+\t\tfree_data_ref (newdr);\n+\t    }\n \n-          if (bb_vinfo)\n-            {\n-              STMT_VINFO_VECTORIZABLE (stmt_info) = false;\n-              stop_bb_analysis = true;\n-              continue;\n-            }\n+\t  if (!gather)\n+\t    {\n+\t      if (vect_print_dump_info (REPORT_UNVECTORIZED_LOCATIONS))\n+\t\t{\n+\t\t  fprintf (vect_dump, \"not vectorized: data ref analysis \"\n+\t\t\t\t      \"failed \");\n+\t\t  print_gimple_stmt (vect_dump, stmt, 0, TDF_SLIM);\n+\t\t}\n \n-          return false;\n+\t      if (bb_vinfo)\n+\t\t{\n+\t\t  STMT_VINFO_VECTORIZABLE (stmt_info) = false;\n+\t\t  stop_bb_analysis = true;\n+\t\t  continue;\n+\t\t}\n+\n+\t      return false;\n+\t    }\n         }\n \n       if (TREE_CODE (DR_BASE_ADDRESS (dr)) == INTEGER_CST)\n@@ -2625,7 +2848,9 @@ vect_analyze_data_refs (loop_vec_info loop_vinfo,\n               continue;\n             }\n \n-           return false;\n+\t  if (gather)\n+\t    free_data_ref (dr);\n+\t  return false;\n         }\n \n       if (TREE_THIS_VOLATILE (DR_REF (dr)))\n@@ -2666,6 +2891,8 @@ vect_analyze_data_refs (loop_vec_info loop_vinfo,\n               continue;\n             }\n \n+\t  if (gather)\n+\t    free_data_ref (dr);\n           return false;\n         }\n \n@@ -2791,6 +3018,8 @@ vect_analyze_data_refs (loop_vec_info loop_vinfo,\n               continue;\n             }\n \n+\t  if (gather)\n+\t    free_data_ref (dr);\n           return false;\n         }\n \n@@ -2818,15 +3047,100 @@ vect_analyze_data_refs (loop_vec_info loop_vinfo,\n               stop_bb_analysis = true;\n               continue;\n             }\n-          else\n-            return false;\n+\n+\t  if (gather)\n+\t    {\n+\t      STMT_VINFO_DATA_REF (stmt_info) = NULL;\n+\t      free_data_ref (dr);\n+\t    }\n+\t  return false;\n         }\n \n       /* Adjust the minimal vectorization factor according to the\n \t vector type.  */\n       vf = TYPE_VECTOR_SUBPARTS (STMT_VINFO_VECTYPE (stmt_info));\n       if (vf > *min_vf)\n \t*min_vf = vf;\n+\n+      if (gather)\n+\t{\n+\t  unsigned int j, k, n;\n+\t  struct data_reference *olddr\n+\t    = VEC_index (data_reference_p, datarefs, i);\n+\t  VEC (ddr_p, heap) *ddrs = LOOP_VINFO_DDRS (loop_vinfo);\n+\t  struct data_dependence_relation *ddr, *newddr;\n+\t  bool bad = false;\n+\t  tree off;\n+\t  VEC (loop_p, heap) *nest = LOOP_VINFO_LOOP_NEST (loop_vinfo);\n+\n+\t  if (!vect_check_gather (stmt, loop_vinfo, NULL, &off, NULL)\n+\t      || get_vectype_for_scalar_type (TREE_TYPE (off)) == NULL_TREE)\n+\t    {\n+\t      if (vect_print_dump_info (REPORT_UNVECTORIZED_LOCATIONS))\n+\t\t{\n+\t\t  fprintf (vect_dump,\n+\t\t\t   \"not vectorized: not suitable for gather \");\n+\t\t  print_gimple_stmt (vect_dump, stmt, 0, TDF_SLIM);\n+\t\t}\n+\t      return false;\n+\t    }\n+\n+\t  n = VEC_length (data_reference_p, datarefs) - 1;\n+\t  for (j = 0, k = i - 1; j < i; j++)\n+\t    {\n+\t      ddr = VEC_index (ddr_p, ddrs, k);\n+\t      gcc_assert (DDR_B (ddr) == olddr);\n+\t      newddr = initialize_data_dependence_relation (DDR_A (ddr), dr,\n+\t\t\t\t\t\t\t    nest);\n+\t      VEC_replace (ddr_p, ddrs, k, newddr);\n+\t      free_dependence_relation (ddr);\n+\t      if (!bad\n+\t\t  && DR_IS_WRITE (DDR_A (newddr))\n+\t\t  && DDR_ARE_DEPENDENT (newddr) != chrec_known)\n+\t\tbad = true;\n+\t      k += --n;\n+\t    }\n+\n+\t  k++;\n+\t  n = k + VEC_length (data_reference_p, datarefs) - i - 1;\n+\t  for (; k < n; k++)\n+\t    {\n+\t      ddr = VEC_index (ddr_p, ddrs, k);\n+\t      gcc_assert (DDR_A (ddr) == olddr);\n+\t      newddr = initialize_data_dependence_relation (dr, DDR_B (ddr),\n+\t\t\t\t\t\t\t    nest);\n+\t      VEC_replace (ddr_p, ddrs, k, newddr);\n+\t      free_dependence_relation (ddr);\n+\t      if (!bad\n+\t\t  && DR_IS_WRITE (DDR_B (newddr))\n+\t\t  && DDR_ARE_DEPENDENT (newddr) != chrec_known)\n+\t\tbad = true;\n+\t    }\n+\n+\t  k = VEC_length (ddr_p, ddrs)\n+\t      - VEC_length (data_reference_p, datarefs) + i;\n+\t  ddr = VEC_index (ddr_p, ddrs, k);\n+\t  gcc_assert (DDR_A (ddr) == olddr && DDR_B (ddr) == olddr);\n+\t  newddr = initialize_data_dependence_relation (dr, dr, nest);\n+\t  compute_self_dependence (newddr);\n+\t  VEC_replace (ddr_p, ddrs, k, newddr);\n+\t  free_dependence_relation (ddr);\n+\t  VEC_replace (data_reference_p, datarefs, i, dr);\n+\n+\t  if (bad)\n+\t    {\n+\t      if (vect_print_dump_info (REPORT_UNVECTORIZED_LOCATIONS))\n+\t\t{\n+\t\t  fprintf (vect_dump,\n+\t\t\t   \"not vectorized: data dependence conflict\"\n+\t\t\t   \" prevents gather\");\n+\t\t  print_gimple_stmt (vect_dump, stmt, 0, TDF_SLIM);\n+\t\t}\n+\t      return false;\n+\t    }\n+\n+\t  STMT_VINFO_GATHER_P (stmt_info) = true;\n+\t}\n     }\n \n   return true;"}, {"sha": "8b9a2cfa3c78093f59a7f7ca615574f2aed78d4c", "filename": "gcc/tree-vect-stmts.c", "status": "modified", "additions": 241, "deletions": 34, "changes": 275, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftree-vect-stmts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftree-vect-stmts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-stmts.c?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -332,6 +332,8 @@ exist_non_indexing_operands_for_use_p (tree use, gimple stmt)\n    - LIVE_P, RELEVANT - enum values to be set in the STMT_VINFO of the stmt\n      that defined USE.  This is done by calling mark_relevant and passing it\n      the WORKLIST (to add DEF_STMT to the WORKLIST in case it is relevant).\n+   - FORCE is true if exist_non_indexing_operands_for_use_p check shouldn't\n+     be performed.\n \n    Outputs:\n    Generally, LIVE_P and RELEVANT are used to define the liveness and\n@@ -351,7 +353,8 @@ exist_non_indexing_operands_for_use_p (tree use, gimple stmt)\n \n static bool\n process_use (gimple stmt, tree use, loop_vec_info loop_vinfo, bool live_p,\n-\t     enum vect_relevant relevant, VEC(gimple,heap) **worklist)\n+\t     enum vect_relevant relevant, VEC(gimple,heap) **worklist,\n+\t     bool force)\n {\n   struct loop *loop = LOOP_VINFO_LOOP (loop_vinfo);\n   stmt_vec_info stmt_vinfo = vinfo_for_stmt (stmt);\n@@ -363,7 +366,7 @@ process_use (gimple stmt, tree use, loop_vec_info loop_vinfo, bool live_p,\n \n   /* case 1: we are only interested in uses that need to be vectorized.  Uses\n      that are used for address computation are not considered relevant.  */\n-  if (!exist_non_indexing_operands_for_use_p (use, stmt))\n+  if (!force && !exist_non_indexing_operands_for_use_p (use, stmt))\n      return true;\n \n   if (!vect_is_simple_use (use, loop_vinfo, NULL, &def_stmt, &def, &dt))\n@@ -646,7 +649,7 @@ vect_mark_stmts_to_be_vectorized (loop_vec_info loop_vinfo)\n             break;\n         }\n \n-      if (is_pattern_stmt_p (vinfo_for_stmt (stmt)))\n+      if (is_pattern_stmt_p (stmt_vinfo))\n         {\n           /* Pattern statements are not inserted into the code, so\n              FOR_EACH_PHI_OR_STMT_USE optimizes their operands out, and we\n@@ -660,9 +663,9 @@ vect_mark_stmts_to_be_vectorized (loop_vec_info loop_vinfo)\n \t      if (rhs_code == COND_EXPR && COMPARISON_CLASS_P (op))\n \t\t{\n \t\t  if (!process_use (stmt, TREE_OPERAND (op, 0), loop_vinfo,\n-\t\t\t\t    live_p, relevant, &worklist)\n+\t\t\t\t    live_p, relevant, &worklist, false)\n \t\t      || !process_use (stmt, TREE_OPERAND (op, 1), loop_vinfo,\n-\t\t\t\t       live_p, relevant, &worklist))\n+\t\t\t\t       live_p, relevant, &worklist, false))\n \t\t    {\n \t\t      VEC_free (gimple, heap, worklist);\n \t\t      return false;\n@@ -673,7 +676,7 @@ vect_mark_stmts_to_be_vectorized (loop_vec_info loop_vinfo)\n                 {\n \t\t  op = gimple_op (stmt, i);\n                   if (!process_use (stmt, op, loop_vinfo, live_p, relevant,\n-                                    &worklist))\n+\t\t\t\t    &worklist, false))\n                     {\n                       VEC_free (gimple, heap, worklist);\n                       return false;\n@@ -686,7 +689,7 @@ vect_mark_stmts_to_be_vectorized (loop_vec_info loop_vinfo)\n                 {\n                   tree arg = gimple_call_arg (stmt, i);\n                   if (!process_use (stmt, arg, loop_vinfo, live_p, relevant,\n-                                    &worklist))\n+\t\t\t\t    &worklist, false))\n                     {\n                       VEC_free (gimple, heap, worklist);\n                       return false;\n@@ -699,12 +702,25 @@ vect_mark_stmts_to_be_vectorized (loop_vec_info loop_vinfo)\n           {\n             tree op = USE_FROM_PTR (use_p);\n             if (!process_use (stmt, op, loop_vinfo, live_p, relevant,\n-                              &worklist))\n+\t\t\t      &worklist, false))\n               {\n                 VEC_free (gimple, heap, worklist);\n                 return false;\n               }\n           }\n+\n+      if (STMT_VINFO_GATHER_P (stmt_vinfo))\n+\t{\n+\t  tree off;\n+\t  tree decl = vect_check_gather (stmt, loop_vinfo, NULL, &off, NULL);\n+\t  gcc_assert (decl);\n+\t  if (!process_use (stmt, off, loop_vinfo, live_p, relevant,\n+\t\t\t    &worklist, true))\n+\t    {\n+\t      VEC_free (gimple, heap, worklist);\n+\t      return false;\n+\t    }\n+\t}\n     } /* while worklist */\n \n   VEC_free (gimple, heap, worklist);\n@@ -3914,23 +3930,17 @@ vectorizable_store (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n   return true;\n }\n \n-/* Given a vector type VECTYPE returns a builtin DECL to be used\n-   for vector permutation and returns the mask that implements\n-   reversal of the vector elements.  If that is impossible to do,\n-   returns NULL.  */\n+/* Given a vector type VECTYPE and permutation SEL returns\n+   the VECTOR_CST mask that implements the permutation of the\n+   vector elements.  If that is impossible to do, returns NULL.  */\n \n static tree\n-perm_mask_for_reverse (tree vectype)\n+gen_perm_mask (tree vectype, unsigned char *sel)\n {\n   tree mask_elt_type, mask_type, mask_vec;\n   int i, nunits;\n-  unsigned char *sel;\n \n   nunits = TYPE_VECTOR_SUBPARTS (vectype);\n-  sel = XALLOCAVEC (unsigned char, nunits);\n-\n-  for (i = 0; i < nunits; ++i)\n-    sel[i] = nunits - 1 - i;\n \n   if (!can_vec_perm_p (TYPE_MODE (vectype), false, sel))\n     return NULL;\n@@ -3941,33 +3951,52 @@ perm_mask_for_reverse (tree vectype)\n   mask_type = get_vectype_for_scalar_type (mask_elt_type);\n \n   mask_vec = NULL;\n-  for (i = 0; i < nunits; i++)\n-    mask_vec = tree_cons (NULL, build_int_cst (mask_elt_type, i), mask_vec);\n+  for (i = nunits - 1; i >= 0; i--)\n+    mask_vec = tree_cons (NULL, build_int_cst (mask_elt_type, sel[i]),\n+\t\t\t  mask_vec);\n   mask_vec = build_vector (mask_type, mask_vec);\n \n   return mask_vec;\n }\n \n-/* Given a vector variable X, that was generated for the scalar LHS of\n-   STMT, generate instructions to reverse the vector elements of X,\n-   insert them a *GSI and return the permuted vector variable.  */\n+/* Given a vector type VECTYPE returns the VECTOR_CST mask that implements\n+   reversal of the vector elements.  If that is impossible to do,\n+   returns NULL.  */\n \n static tree\n-reverse_vec_elements (tree x, gimple stmt, gimple_stmt_iterator *gsi)\n+perm_mask_for_reverse (tree vectype)\n+{\n+  int i, nunits;\n+  unsigned char *sel;\n+\n+  nunits = TYPE_VECTOR_SUBPARTS (vectype);\n+  sel = XALLOCAVEC (unsigned char, nunits);\n+\n+  for (i = 0; i < nunits; ++i)\n+    sel[i] = nunits - 1 - i;\n+\n+  return gen_perm_mask (vectype, sel);\n+}\n+\n+/* Given a vector variable X and Y, that was generated for the scalar\n+   STMT, generate instructions to permute the vector elements of X and Y\n+   using permutation mask MASK_VEC, insert them at *GSI and return the\n+   permuted vector variable.  */\n+\n+static tree\n+permute_vec_elements (tree x, tree y, tree mask_vec, gimple stmt,\n+\t\t      gimple_stmt_iterator *gsi)\n {\n   tree vectype = TREE_TYPE (x);\n-  tree mask_vec, perm_dest, data_ref;\n+  tree perm_dest, data_ref;\n   gimple perm_stmt;\n \n-  mask_vec = perm_mask_for_reverse (vectype);\n-\n   perm_dest = vect_create_destination_var (gimple_assign_lhs (stmt), vectype);\n+  data_ref = make_ssa_name (perm_dest, NULL);\n \n   /* Generate the permute statement.  */\n-  perm_stmt = gimple_build_assign_with_ops3 (VEC_PERM_EXPR, perm_dest,\n-\t\t\t\t\t     x, x, mask_vec);\n-  data_ref = make_ssa_name (perm_dest, perm_stmt);\n-  gimple_set_lhs (perm_stmt, data_ref);\n+  perm_stmt = gimple_build_assign_with_ops3 (VEC_PERM_EXPR, data_ref,\n+\t\t\t\t\t     x, y, mask_vec);\n   vect_finish_stmt_generation (stmt, perm_stmt, gsi);\n \n   return data_ref;\n@@ -4026,6 +4055,10 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n   bb_vec_info bb_vinfo = STMT_VINFO_BB_VINFO (stmt_info);\n   int vf;\n   tree aggr_type;\n+  tree gather_base = NULL_TREE, gather_off = NULL_TREE;\n+  tree gather_off_vectype = NULL_TREE, gather_decl = NULL_TREE;\n+  int gather_scale = 1;\n+  enum vect_def_type gather_dt = vect_unknown_def_type;\n \n   if (loop_vinfo)\n     {\n@@ -4106,7 +4139,7 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n     {\n       strided_load = true;\n       /* FORNOW */\n-      gcc_assert (! nested_in_vect_loop);\n+      gcc_assert (! nested_in_vect_loop && !STMT_VINFO_GATHER_P (stmt_info));\n \n       first_stmt = GROUP_FIRST_ELEMENT (stmt_info);\n       if (!slp && !PURE_SLP_STMT (stmt_info))\n@@ -4121,7 +4154,7 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \n   if (negative)\n     {\n-      gcc_assert (!strided_load);\n+      gcc_assert (!strided_load && !STMT_VINFO_GATHER_P (stmt_info));\n       alignment_support_scheme = vect_supportable_dr_alignment (dr, false);\n       if (alignment_support_scheme != dr_aligned\n \t  && alignment_support_scheme != dr_unaligned_supported)\n@@ -4138,6 +4171,23 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \t}\n     }\n \n+  if (STMT_VINFO_GATHER_P (stmt_info))\n+    {\n+      gimple def_stmt;\n+      tree def;\n+      gather_decl = vect_check_gather (stmt, loop_vinfo, &gather_base,\n+\t\t\t\t       &gather_off, &gather_scale);\n+      gcc_assert (gather_decl);\n+      if (!vect_is_simple_use_1 (gather_off, loop_vinfo, bb_vinfo,\n+\t\t\t\t &def_stmt, &def, &gather_dt,\n+\t\t\t\t &gather_off_vectype))\n+\t{\n+\t  if (vect_print_dump_info (REPORT_DETAILS))\n+\t    fprintf (vect_dump, \"gather index use not simple.\");\n+\t  return false;\n+\t}\n+    }\n+\n   if (!vec_stmt) /* transformation not required.  */\n     {\n       STMT_VINFO_TYPE (stmt_info) = load_vec_info_type;\n@@ -4150,6 +4200,161 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \n   /** Transform.  **/\n \n+  if (STMT_VINFO_GATHER_P (stmt_info))\n+    {\n+      tree vec_oprnd0 = NULL_TREE, op;\n+      tree arglist = TYPE_ARG_TYPES (TREE_TYPE (gather_decl));\n+      tree rettype, srctype, ptrtype, idxtype, masktype, scaletype;\n+      tree ptr, mask, var, scale, perm_mask = NULL_TREE, prev_res = NULL_TREE;\n+      edge pe = loop_preheader_edge (loop);\n+      gimple_seq seq;\n+      basic_block new_bb;\n+      enum { NARROW, NONE, WIDEN } modifier;\n+      int gather_off_nunits = TYPE_VECTOR_SUBPARTS (gather_off_vectype);\n+\n+      if (nunits == gather_off_nunits)\n+\tmodifier = NONE;\n+      else if (nunits == gather_off_nunits / 2)\n+\t{\n+\t  unsigned char *sel = XALLOCAVEC (unsigned char, gather_off_nunits);\n+\t  modifier = WIDEN;\n+\n+\t  for (i = 0; i < gather_off_nunits; ++i)\n+\t    sel[i] = i | nunits;\n+\n+\t  perm_mask = gen_perm_mask (gather_off_vectype, sel);\n+\t  gcc_assert (perm_mask != NULL_TREE);\n+\t}\n+      else if (nunits == gather_off_nunits * 2)\n+\t{\n+\t  unsigned char *sel = XALLOCAVEC (unsigned char, nunits);\n+\t  modifier = NARROW;\n+\n+\t  for (i = 0; i < nunits; ++i)\n+\t    sel[i] = i < gather_off_nunits\n+\t\t     ? i : i + nunits - gather_off_nunits;\n+\n+\t  perm_mask = gen_perm_mask (vectype, sel);\n+\t  gcc_assert (perm_mask != NULL_TREE);\n+\t  ncopies *= 2;\n+\t}\n+      else\n+\tgcc_unreachable ();\n+\n+      rettype = TREE_TYPE (TREE_TYPE (gather_decl));\n+      srctype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n+      ptrtype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n+      idxtype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n+      masktype = TREE_VALUE (arglist); arglist = TREE_CHAIN (arglist);\n+      scaletype = TREE_VALUE (arglist);\n+      gcc_checking_assert (types_compatible_p (srctype, rettype)\n+\t\t\t   && types_compatible_p (srctype, masktype));\n+\n+      vec_dest = vect_create_destination_var (scalar_dest, vectype);\n+\n+      ptr = fold_convert (ptrtype, gather_base);\n+      if (!is_gimple_min_invariant (ptr))\n+\t{\n+\t  ptr = force_gimple_operand (ptr, &seq, true, NULL_TREE);\n+\t  new_bb = gsi_insert_seq_on_edge_immediate (pe, seq);\n+\t  gcc_assert (!new_bb);\n+\t}\n+\n+      /* Currently we support only unconditional gather loads,\n+\t so mask should be all ones.  */\n+      if (TREE_CODE (TREE_TYPE (masktype)) == INTEGER_TYPE)\n+\tmask = build_int_cst (TREE_TYPE (masktype), -1);\n+      else if (SCALAR_FLOAT_TYPE_P (TREE_TYPE (masktype)))\n+\t{\n+\t  REAL_VALUE_TYPE r;\n+\t  long tmp[6];\n+\t  for (j = 0; j < 6; ++j)\n+\t    tmp[j] = -1;\n+\t  real_from_target (&r, tmp, TYPE_MODE (TREE_TYPE (masktype)));\n+\t  mask = build_real (TREE_TYPE (masktype), r);\n+\t}\n+      else\n+\tgcc_unreachable ();\n+      mask = build_vector_from_val (masktype, mask);\n+      mask = vect_init_vector (stmt, mask, masktype, NULL);\n+\n+      scale = build_int_cst (scaletype, gather_scale);\n+\n+      prev_stmt_info = NULL;\n+      for (j = 0; j < ncopies; ++j)\n+\t{\n+\t  if (modifier == WIDEN && (j & 1))\n+\t    op = permute_vec_elements (vec_oprnd0, vec_oprnd0,\n+\t\t\t\t       perm_mask, stmt, gsi);\n+\t  else if (j == 0)\n+\t    op = vec_oprnd0\n+\t      = vect_get_vec_def_for_operand (gather_off, stmt, NULL);\n+\t  else\n+\t    op = vec_oprnd0\n+\t      = vect_get_vec_def_for_stmt_copy (gather_dt, vec_oprnd0);\n+\n+\t  if (!useless_type_conversion_p (idxtype, TREE_TYPE (op)))\n+\t    {\n+\t      gcc_assert (TYPE_VECTOR_SUBPARTS (TREE_TYPE (op))\n+\t\t\t  == TYPE_VECTOR_SUBPARTS (idxtype));\n+\t      var = vect_get_new_vect_var (idxtype, vect_simple_var, NULL);\n+\t      add_referenced_var (var);\n+\t      var = make_ssa_name (var, NULL);\n+\t      op = build1 (VIEW_CONVERT_EXPR, idxtype, op);\n+\t      new_stmt\n+\t\t= gimple_build_assign_with_ops (VIEW_CONVERT_EXPR, var,\n+\t\t\t\t\t\top, NULL_TREE);\n+\t      vect_finish_stmt_generation (stmt, new_stmt, gsi);\n+\t      op = var;\n+\t    }\n+\n+\t  new_stmt\n+\t    = gimple_build_call (gather_decl, 5, mask, ptr, op, mask, scale);\n+\n+\t  if (!useless_type_conversion_p (vectype, rettype))\n+\t    {\n+\t      gcc_assert (TYPE_VECTOR_SUBPARTS (vectype)\n+\t\t\t  == TYPE_VECTOR_SUBPARTS (rettype));\n+\t      var = vect_get_new_vect_var (rettype, vect_simple_var, NULL);\n+\t      add_referenced_var (var);\n+\t      op = make_ssa_name (var, new_stmt);\n+\t      gimple_call_set_lhs (new_stmt, op);\n+\t      vect_finish_stmt_generation (stmt, new_stmt, gsi);\n+\t      var = make_ssa_name (vec_dest, NULL);\n+\t      op = build1 (VIEW_CONVERT_EXPR, vectype, op);\n+\t      new_stmt\n+\t\t= gimple_build_assign_with_ops (VIEW_CONVERT_EXPR, var, op,\n+\t\t\t\t\t\tNULL_TREE);\n+\t    }\n+\t  else\n+\t    {\n+\t      var = make_ssa_name (vec_dest, new_stmt);\n+\t      gimple_call_set_lhs (new_stmt, var);\n+\t    }\n+\n+\t  vect_finish_stmt_generation (stmt, new_stmt, gsi);\n+\n+\t  if (modifier == NARROW)\n+\t    {\n+\t      if ((j & 1) == 0)\n+\t\t{\n+\t\t  prev_res = var;\n+\t\t  continue;\n+\t\t}\n+\t      var = permute_vec_elements (prev_res, var,\n+\t\t\t\t\t  perm_mask, stmt, gsi);\n+\t      new_stmt = SSA_NAME_DEF_STMT (var);\n+\t    }\n+\n+\t  if (prev_stmt_info == NULL)\n+\t    STMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt;\n+\t  else\n+\t    STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt;\n+\t  prev_stmt_info = vinfo_for_stmt (new_stmt);\n+\t}\n+      return true;\n+    }\n+\n   if (strided_load)\n     {\n       first_stmt = GROUP_FIRST_ELEMENT (stmt_info);\n@@ -4541,7 +4746,9 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \n \t      if (negative)\n \t\t{\n-\t\t  new_temp = reverse_vec_elements (new_temp, stmt, gsi);\n+\t\t  tree perm_mask = perm_mask_for_reverse (vectype);\n+\t\t  new_temp = permute_vec_elements (new_temp, new_temp,\n+\t\t\t\t\t\t   perm_mask, stmt, gsi);\n \t\t  new_stmt = SSA_NAME_DEF_STMT (new_temp);\n \t\t}\n "}, {"sha": "927c0bd8cb5763542db56d82202c4c056658f67f", "filename": "gcc/tree-vectorizer.h", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftree-vectorizer.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aec7ae7deaef9d52541da07c387066ad6ceb3d87/gcc%2Ftree-vectorizer.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vectorizer.h?ref=aec7ae7deaef9d52541da07c387066ad6ceb3d87", "patch": "@@ -535,6 +535,9 @@ typedef struct _stmt_vec_info {\n   /* Is this statement vectorizable or should it be skipped in (partial)\n      vectorization.  */\n   bool vectorizable;\n+\n+  /* For loads only, true if this is a gather load.  */\n+  bool gather_p;\n } *stmt_vec_info;\n \n /* Access Functions.  */\n@@ -548,6 +551,7 @@ typedef struct _stmt_vec_info {\n #define STMT_VINFO_VEC_STMT(S)             (S)->vectorized_stmt\n #define STMT_VINFO_VECTORIZABLE(S)         (S)->vectorizable\n #define STMT_VINFO_DATA_REF(S)             (S)->data_ref_info\n+#define STMT_VINFO_GATHER_P(S)\t\t   (S)->gather_p\n \n #define STMT_VINFO_DR_BASE_ADDRESS(S)      (S)->dr_base_address\n #define STMT_VINFO_DR_INIT(S)              (S)->dr_init\n@@ -858,6 +862,8 @@ extern bool vect_analyze_data_refs_alignment (loop_vec_info, bb_vec_info);\n extern bool vect_verify_datarefs_alignment (loop_vec_info, bb_vec_info);\n extern bool vect_analyze_data_ref_accesses (loop_vec_info, bb_vec_info);\n extern bool vect_prune_runtime_alias_test_list (loop_vec_info);\n+extern tree vect_check_gather (gimple, loop_vec_info, tree *, tree *,\n+\t\t\t       int *);\n extern bool vect_analyze_data_refs (loop_vec_info, bb_vec_info, int *);\n extern tree vect_create_data_ref_ptr (gimple, tree, struct loop *, tree,\n \t\t\t\t      tree *, gimple_stmt_iterator *,"}]}