{"sha": "86f8e47f9df3cb0adf9b6cd6e48d7c89e2556721", "node_id": "C_kwDOANBUbNoAKDg2ZjhlNDdmOWRmM2NiMGFkZjliNmNkNmU0OGQ3Yzg5ZTI1NTY3MjE", "commit": {"author": {"name": "mxlol233", "email": "mxlol233@outlook.com", "date": "2023-01-11T12:36:13Z"}, "committer": {"name": "Arthur Cohen", "email": "arthur.cohen@embecosm.com", "date": "2023-04-06T08:47:17Z"}, "message": "gccrs: diagnostics: Add underline for tokens in diagnostics.\n\nCurrently, the diagnostics only point to the corresponding token's\nstart position by carets, and lack of underlines for full token.  This\ncommit add support for such underlines in diagnostics by encoding range\ninformation in location_t.\n\ngcc/rust/ChangeLog:\n\n\t* lex/rust-lex.cc (Lexer::build_token): Make location enclose entire token.\n\t(Lexer::parse_byte_char): Likewise.\n\t(Lexer::parse_byte_string): Likewise.\n\t(Lexer::parse_raw_byte_string): Likewise.\n\t(Lexer::parse_raw_identifier): Likewise.\n\t(Lexer::parse_string): Likewise.\n\t(Lexer::parse_identifier_or_keyword): Likewise.\n\t(Lexer::parse_raw_string): Likewise.\n\t(Lexer::parse_non_decimal_int_literal): Likewise.\n\t(Lexer::parse_decimal_int_or_float): Likewise.\n\t(Lexer::parse_char_or_lifetime): Likewise.\n\ngcc/testsuite/ChangeLog:\n\n\t* rust/compile/diagnostic_underline.rs: New test.\n\nSigned-off-by: Xiao Ma <mxlol233@outlook.com>", "tree": {"sha": "56541e7c3b397a1f4fbebc4cc676f56785791f8c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/56541e7c3b397a1f4fbebc4cc676f56785791f8c"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/86f8e47f9df3cb0adf9b6cd6e48d7c89e2556721", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/86f8e47f9df3cb0adf9b6cd6e48d7c89e2556721", "html_url": "https://github.com/Rust-GCC/gccrs/commit/86f8e47f9df3cb0adf9b6cd6e48d7c89e2556721", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/86f8e47f9df3cb0adf9b6cd6e48d7c89e2556721/comments", "author": {"login": "TuringKi", "id": 9394223, "node_id": "MDQ6VXNlcjkzOTQyMjM=", "avatar_url": "https://avatars.githubusercontent.com/u/9394223?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TuringKi", "html_url": "https://github.com/TuringKi", "followers_url": "https://api.github.com/users/TuringKi/followers", "following_url": "https://api.github.com/users/TuringKi/following{/other_user}", "gists_url": "https://api.github.com/users/TuringKi/gists{/gist_id}", "starred_url": "https://api.github.com/users/TuringKi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TuringKi/subscriptions", "organizations_url": "https://api.github.com/users/TuringKi/orgs", "repos_url": "https://api.github.com/users/TuringKi/repos", "events_url": "https://api.github.com/users/TuringKi/events{/privacy}", "received_events_url": "https://api.github.com/users/TuringKi/received_events", "type": "User", "site_admin": false}, "committer": {"login": "CohenArthur", "id": 43524065, "node_id": "MDQ6VXNlcjQzNTI0MDY1", "avatar_url": "https://avatars.githubusercontent.com/u/43524065?v=4", "gravatar_id": "", "url": "https://api.github.com/users/CohenArthur", "html_url": "https://github.com/CohenArthur", "followers_url": "https://api.github.com/users/CohenArthur/followers", "following_url": "https://api.github.com/users/CohenArthur/following{/other_user}", "gists_url": "https://api.github.com/users/CohenArthur/gists{/gist_id}", "starred_url": "https://api.github.com/users/CohenArthur/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/CohenArthur/subscriptions", "organizations_url": "https://api.github.com/users/CohenArthur/orgs", "repos_url": "https://api.github.com/users/CohenArthur/repos", "events_url": "https://api.github.com/users/CohenArthur/events{/privacy}", "received_events_url": "https://api.github.com/users/CohenArthur/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "8e2abbef4cc04adf048730b1a608cf95b6d5cc4f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8e2abbef4cc04adf048730b1a608cf95b6d5cc4f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8e2abbef4cc04adf048730b1a608cf95b6d5cc4f"}], "stats": {"total": 72, "additions": 72, "deletions": 0}, "files": [{"sha": "9967cecb2e252c4d57948fb8f53f67d8112eeb09", "filename": "gcc/rust/lex/rust-lex.cc", "status": "modified", "additions": 57, "deletions": 0, "changes": 57, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/86f8e47f9df3cb0adf9b6cd6e48d7c89e2556721/gcc%2Frust%2Flex%2Frust-lex.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/86f8e47f9df3cb0adf9b6cd6e48d7c89e2556721/gcc%2Frust%2Flex%2Frust-lex.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Flex%2Frust-lex.cc?ref=86f8e47f9df3cb0adf9b6cd6e48d7c89e2556721", "patch": "@@ -447,6 +447,7 @@ Lexer::build_token ()\n \t      // match arm arrow\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (MATCH_ARROW, loc);\n \t    }\n@@ -455,6 +456,7 @@ Lexer::build_token ()\n \t      // equality operator\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (EQUAL_EQUAL, loc);\n \t    }\n@@ -473,6 +475,7 @@ Lexer::build_token ()\n \t      // return type specifier\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (RETURN_TYPE, loc);\n \t    }\n@@ -481,6 +484,7 @@ Lexer::build_token ()\n \t      // minus-assign\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (MINUS_EQ, loc);\n \t    }\n@@ -496,6 +500,7 @@ Lexer::build_token ()\n \t      // add-assign\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (PLUS_EQ, loc);\n \t    }\n@@ -517,6 +522,7 @@ Lexer::build_token ()\n \t      // multiplication-assign\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (ASTERISK_EQ, loc);\n \t    }\n@@ -535,6 +541,7 @@ Lexer::build_token ()\n \t      // division-assign\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (DIV_EQ, loc);\n \t    }\n@@ -602,6 +609,8 @@ Lexer::build_token ()\n \t      start_line (current_line, max_column_hint);\n \n \t      str.shrink_to_fit ();\n+\n+\t      loc += str.size () - 1;\n \t      if (is_inner)\n \t\treturn Token::make_inner_doc_comment (loc, std::move (str));\n \t      else\n@@ -756,6 +765,8 @@ Lexer::build_token ()\n \t\t}\n \n \t      str.shrink_to_fit ();\n+\n+\t      loc += str.size () - 1;\n \t      if (is_inner)\n \t\treturn Token::make_inner_doc_comment (loc, std::move (str));\n \t      else\n@@ -773,6 +784,7 @@ Lexer::build_token ()\n \t      // modulo-assign\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (PERCENT_EQ, loc);\n \t    }\n@@ -788,6 +800,7 @@ Lexer::build_token ()\n \t      // xor-assign?\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (CARET_EQ, loc);\n \t    }\n@@ -805,6 +818,7 @@ Lexer::build_token ()\n \t\t  // left-shift assign\n \t\t  skip_input (1);\n \t\t  current_column += 3;\n+\t\t  loc += 2;\n \n \t\t  return Token::make (LEFT_SHIFT_EQ, loc);\n \t\t}\n@@ -813,6 +827,7 @@ Lexer::build_token ()\n \t\t  // left-shift\n \t\t  skip_input ();\n \t\t  current_column += 2;\n+\t\t  loc += 1;\n \n \t\t  return Token::make (LEFT_SHIFT, loc);\n \t\t}\n@@ -822,6 +837,7 @@ Lexer::build_token ()\n \t      // smaller than or equal to\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (LESS_OR_EQUAL, loc);\n \t    }\n@@ -840,6 +856,7 @@ Lexer::build_token ()\n \t\t  // right-shift-assign\n \t\t  skip_input (1);\n \t\t  current_column += 3;\n+\t\t  loc += 2;\n \n \t\t  return Token::make (RIGHT_SHIFT_EQ, loc);\n \t\t}\n@@ -848,6 +865,7 @@ Lexer::build_token ()\n \t\t  // right-shift\n \t\t  skip_input ();\n \t\t  current_column += 2;\n+\t\t  loc += 1;\n \n \t\t  return Token::make (RIGHT_SHIFT, loc);\n \t\t}\n@@ -857,6 +875,7 @@ Lexer::build_token ()\n \t      // larger than or equal to\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (GREATER_OR_EQUAL, loc);\n \t    }\n@@ -872,6 +891,7 @@ Lexer::build_token ()\n \t      // scope resolution ::\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (SCOPE_RESOLUTION, loc);\n \t    }\n@@ -888,6 +908,7 @@ Lexer::build_token ()\n \t      // not equal boolean operator\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (NOT_EQUAL, loc);\n \t    }\n@@ -937,6 +958,7 @@ Lexer::build_token ()\n \t      // bitwise or-assign?\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (PIPE_EQ, loc);\n \t    }\n@@ -945,6 +967,7 @@ Lexer::build_token ()\n \t      // logical or\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (OR, loc);\n \t    }\n@@ -961,6 +984,7 @@ Lexer::build_token ()\n \t      // bitwise and-assign?\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (AMP_EQ, loc);\n \t    }\n@@ -969,6 +993,7 @@ Lexer::build_token ()\n \t      // logical and\n \t      skip_input ();\n \t      current_column += 2;\n+\t      loc += 1;\n \n \t      return Token::make (LOGICAL_AND, loc);\n \t    }\n@@ -987,6 +1012,7 @@ Lexer::build_token ()\n \t\t  // ellipsis\n \t\t  skip_input (1);\n \t\t  current_column += 3;\n+\t\t  loc += 2;\n \n \t\t  return Token::make (ELLIPSIS, loc);\n \t\t}\n@@ -995,6 +1021,7 @@ Lexer::build_token ()\n \t\t  // ..=\n \t\t  skip_input (1);\n \t\t  current_column += 3;\n+\t\t  loc += 2;\n \n \t\t  return Token::make (DOT_DOT_EQ, loc);\n \t\t}\n@@ -1003,6 +1030,7 @@ Lexer::build_token ()\n \t\t  // ..\n \t\t  skip_input ();\n \t\t  current_column += 2;\n+\t\t  loc += 1;\n \n \t\t  return Token::make (DOT_DOT, loc);\n \t\t}\n@@ -1717,6 +1745,8 @@ Lexer::parse_byte_char (Location loc)\n \n   current_column += length;\n \n+  loc += length - 1;\n+\n   return Token::make_byte_char (loc, byte_char);\n }\n \n@@ -1781,6 +1811,7 @@ Lexer::parse_byte_string (Location loc)\n     }\n \n   str.shrink_to_fit ();\n+  loc += str.size () - 1;\n \n   return Token::make_byte_string (loc, std::move (str));\n }\n@@ -1861,6 +1892,8 @@ Lexer::parse_raw_byte_string (Location loc)\n \n   current_column += length;\n \n+  loc += length - 1;\n+\n   str.shrink_to_fit ();\n \n   return Token::make_byte_string (loc, std::move (str));\n@@ -1912,6 +1945,7 @@ Lexer::parse_raw_identifier (Location loc)\n   else\n     {\n       str.shrink_to_fit ();\n+      loc += length - 1;\n \n       return Token::make_identifier (loc, std::move (str));\n     }\n@@ -2009,6 +2043,8 @@ Lexer::parse_string (Location loc)\n     }\n \n   str.shrink_to_fit ();\n+  loc += length - 1;\n+\n   return Token::make_string (loc, std::move (str));\n }\n \n@@ -2043,6 +2079,8 @@ Lexer::parse_identifier_or_keyword (Location loc)\n \n   str.shrink_to_fit ();\n \n+  loc += length - 1;\n+\n   TokenId keyword = classify_keyword (str);\n   if (keyword == IDENTIFIER)\n     return Token::make_identifier (loc, std::move (str));\n@@ -2120,6 +2158,8 @@ Lexer::parse_raw_string (Location loc, int initial_hash_count)\n \n   current_column += length;\n \n+  loc += length - 1;\n+\n   str.shrink_to_fit ();\n \n   return Token::make_string (loc, std::move (str));\n@@ -2183,6 +2223,9 @@ Lexer::parse_non_decimal_int_literal (Location loc, IsDigitFunc is_digit_func,\n \t\t\t\t\t\t : \"<insert unknown base>\")));\n       return nullptr;\n     }\n+\n+  loc += length - 1;\n+\n   return Token::make_int (loc, std::move (existent_str), type_hint);\n }\n \n@@ -2275,6 +2318,8 @@ Lexer::parse_decimal_int_or_float (Location loc)\n \n       current_column += length;\n \n+      loc += length - 1;\n+\n       str.shrink_to_fit ();\n       return Token::make_float (loc, std::move (str), type_hint);\n     }\n@@ -2295,6 +2340,8 @@ Lexer::parse_decimal_int_or_float (Location loc)\n \n       current_column += length;\n \n+      loc += length - 1;\n+\n       str.shrink_to_fit ();\n       return Token::make_float (loc, std::move (str), CORETYPE_UNKNOWN);\n     }\n@@ -2324,6 +2371,8 @@ Lexer::parse_decimal_int_or_float (Location loc)\n \n       current_column += length;\n \n+      loc += length - 1;\n+\n       str.shrink_to_fit ();\n       return Token::make_float (loc, std::move (str), type_hint);\n     }\n@@ -2345,6 +2394,8 @@ Lexer::parse_decimal_int_or_float (Location loc)\n \n       current_column += length;\n \n+      loc += length - 1;\n+\n       str.shrink_to_fit ();\n       return Token::make_int (loc, std::move (str), type_hint);\n     }\n@@ -2382,6 +2433,8 @@ Lexer::parse_char_or_lifetime (Location loc)\n \n       current_column += length;\n \n+      loc += length - 1;\n+\n       return Token::make_char (loc, current_char32);\n     }\n   else\n@@ -2399,6 +2452,8 @@ Lexer::parse_char_or_lifetime (Location loc)\n \t  // TODO fix due to different widths of utf-8 chars?\n \t  current_column += 3;\n \n+\t  loc += 2;\n+\n \t  return Token::make_char (loc, current_char32);\n \t}\n       else if (ISDIGIT (current_char32.value) || ISALPHA (current_char32.value)\n@@ -2421,6 +2476,8 @@ Lexer::parse_char_or_lifetime (Location loc)\n \n \t  current_column += length;\n \n+\t  loc += length - 1;\n+\n \t  str.shrink_to_fit ();\n \t  return Token::make_lifetime (loc, std::move (str));\n \t}"}, {"sha": "fcbf468e1c89c71409fc3ceb4c870ddb8d6bd259", "filename": "gcc/testsuite/rust/compile/diagnostic_underline.rs", "status": "added", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/86f8e47f9df3cb0adf9b6cd6e48d7c89e2556721/gcc%2Ftestsuite%2Frust%2Fcompile%2Fdiagnostic_underline.rs", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/86f8e47f9df3cb0adf9b6cd6e48d7c89e2556721/gcc%2Ftestsuite%2Frust%2Fcompile%2Fdiagnostic_underline.rs", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Frust%2Fcompile%2Fdiagnostic_underline.rs?ref=86f8e47f9df3cb0adf9b6cd6e48d7c89e2556721", "patch": "@@ -0,0 +1,15 @@\n+// { dg-additional-options \"-quiet\" }\n+\n+/* { dg-options \"-fdiagnostics-show-caret\" } */\n+\n+\n+fn barbarbar() {}\n+\n+const fn foo() { \n+    barbarbar();// { dg-error \"only functions marked as 'const' are allowed to be called from constant contexts\" }\n+/* { dg-begin-multiline-output \"\" }\n+     barbarbar();//\n+     ^~~~~~~~~\n+{ dg-end-multiline-output \"\" } */\n+}\n+"}]}