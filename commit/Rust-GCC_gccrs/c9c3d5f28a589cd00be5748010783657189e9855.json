{"sha": "c9c3d5f28a589cd00be5748010783657189e9855", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YzljM2Q1ZjI4YTU4OWNkMDBiZTU3NDgwMTA3ODM2NTcxODllOTg1NQ==", "commit": {"author": {"name": "Nathan Sidwell", "email": "nathan@acm.org", "date": "2020-11-18T18:24:12Z"}, "committer": {"name": "Nathan Sidwell", "email": "nathan@acm.org", "date": "2020-11-18T18:24:12Z"}, "message": "preprocessor: C++ module-directives\n\nC++20 modules introduces a new kind of preprocessor directive -- a\nmodule directive.  These are directives but without the leading '#'.\nWe have to detect them by sniffing the start of a logical line.  When\ndetected we replace the initial identifiers with unspellable tokens\nand pass them through to the language parser the same way deferred\npragmas are.  There's a PRAGMA_EOL at the logical end of line too.\n\nOne additional complication is that we have to do header-name lexing\nafter the initial tokens, and that requires changes in the macro-aware\npiece of the preprocessor.  The above sniffer sets a counter in the\nlexer state, and that triggers at the appropriate point.  We then do\nthe same header-name lexing that occurs on a #include directive or\nhas_include pseudo-macro.  Except that the header name ends up in the\ntoken stream.\n\nA couple of token emitters need to deal with the new token possibility.\n\n\tgcc/c-family/\n\t* c-lex.c (c_lex_with_flags): CPP_HEADER_NAMEs can now be seen.\n\tlibcpp/\n\t* include/cpplib.h (struct cpp_options): Add module_directives\n\toption.\n\t(NODE_MODULE): New node flag.\n\t(struct cpp_hashnode): Make rid-code a bitfield, increase bits in\n\tflags and swap with type field.\n\t* init.c (post_options): Create module-directive identifier nodes.\n\t* internal.h (struct lexer_state): Add directive_file_token &\n\tn_modules fields.  Add module node enumerator.\n\t* lex.c (cpp_maybe_module_directive): New.\n\t(_cpp_lex_token): Call it.\n\t(cpp_output_token): Add '\"' around CPP_HEADER_NAME token.\n\t(do_peek_ident, do_peek_module): New.\n\t(cpp_directives_only): Detect module-directive lines.\n\t* macro.c (cpp_get_token_1): Deal with directive_file_token\n\ttriggering.", "tree": {"sha": "9a1b904ee5ea9b639bd2b43fa16050edd3321044", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/9a1b904ee5ea9b639bd2b43fa16050edd3321044"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/c9c3d5f28a589cd00be5748010783657189e9855", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c9c3d5f28a589cd00be5748010783657189e9855", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c9c3d5f28a589cd00be5748010783657189e9855", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c9c3d5f28a589cd00be5748010783657189e9855/comments", "author": {"login": "urnathan", "id": 13103001, "node_id": "MDQ6VXNlcjEzMTAzMDAx", "avatar_url": "https://avatars.githubusercontent.com/u/13103001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/urnathan", "html_url": "https://github.com/urnathan", "followers_url": "https://api.github.com/users/urnathan/followers", "following_url": "https://api.github.com/users/urnathan/following{/other_user}", "gists_url": "https://api.github.com/users/urnathan/gists{/gist_id}", "starred_url": "https://api.github.com/users/urnathan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/urnathan/subscriptions", "organizations_url": "https://api.github.com/users/urnathan/orgs", "repos_url": "https://api.github.com/users/urnathan/repos", "events_url": "https://api.github.com/users/urnathan/events{/privacy}", "received_events_url": "https://api.github.com/users/urnathan/received_events", "type": "User", "site_admin": false}, "committer": {"login": "urnathan", "id": 13103001, "node_id": "MDQ6VXNlcjEzMTAzMDAx", "avatar_url": "https://avatars.githubusercontent.com/u/13103001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/urnathan", "html_url": "https://github.com/urnathan", "followers_url": "https://api.github.com/users/urnathan/followers", "following_url": "https://api.github.com/users/urnathan/following{/other_user}", "gists_url": "https://api.github.com/users/urnathan/gists{/gist_id}", "starred_url": "https://api.github.com/users/urnathan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/urnathan/subscriptions", "organizations_url": "https://api.github.com/users/urnathan/orgs", "repos_url": "https://api.github.com/users/urnathan/repos", "events_url": "https://api.github.com/users/urnathan/events{/privacy}", "received_events_url": "https://api.github.com/users/urnathan/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "7ceb899e9343493f646434f74a149395f3913d9a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7ceb899e9343493f646434f74a149395f3913d9a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/7ceb899e9343493f646434f74a149395f3913d9a"}], "stats": {"total": 518, "additions": 514, "deletions": 4}, "files": [{"sha": "c8d33d0c9d1995c2b3004289e6ff2c7ec4e2bb04", "filename": "gcc/c-family/c-lex.c", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c9c3d5f28a589cd00be5748010783657189e9855/gcc%2Fc-family%2Fc-lex.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c9c3d5f28a589cd00be5748010783657189e9855/gcc%2Fc-family%2Fc-lex.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-family%2Fc-lex.c?ref=c9c3d5f28a589cd00be5748010783657189e9855", "patch": "@@ -667,8 +667,11 @@ c_lex_with_flags (tree *value, location_t *loc, unsigned char *cpp_flags,\n       *value = build_int_cst (integer_type_node, tok->val.pragma);\n       break;\n \n-      /* These tokens should not be visible outside cpplib.  */\n     case CPP_HEADER_NAME:\n+      *value = build_string (tok->val.str.len, (const char *)tok->val.str.text);\n+      break;\n+\n+      /* This token should not be visible outside cpplib.  */\n     case CPP_MACRO_ARG:\n       gcc_unreachable ();\n "}, {"sha": "630f2e055d129536e21813f701dd265f778382ba", "filename": "libcpp/include/cpplib.h", "status": "modified", "additions": 7, "deletions": 3, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c9c3d5f28a589cd00be5748010783657189e9855/libcpp%2Finclude%2Fcpplib.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c9c3d5f28a589cd00be5748010783657189e9855/libcpp%2Finclude%2Fcpplib.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libcpp%2Finclude%2Fcpplib.h?ref=c9c3d5f28a589cd00be5748010783657189e9855", "patch": "@@ -487,6 +487,9 @@ struct cpp_options\n   /* Nonzero for the '::' token.  */\n   unsigned char scope;\n \n+  /* Nonzero means tokenize C++20 module directives.  */\n+  unsigned char module_directives;\n+\n   /* Holds the name of the target (execution) character set.  */\n   const char *narrow_charset;\n \n@@ -842,6 +845,7 @@ struct GTY(()) cpp_macro {\n #define NODE_USED\t(1 << 5)\t/* Dumped with -dU.  */\n #define NODE_CONDITIONAL (1 << 6)\t/* Conditional macro */\n #define NODE_WARN_OPERATOR (1 << 7)\t/* Warn about C++ named operator.  */\n+#define NODE_MODULE (1 << 8)\t\t/* C++-20 module-related name.  */\n \n /* Different flavors of hash node.  */\n enum node_type\n@@ -900,11 +904,11 @@ struct GTY(()) cpp_hashnode {\n   unsigned int directive_index : 7;\t/* If is_directive,\n \t\t\t\t\t   then index into directive table.\n \t\t\t\t\t   Otherwise, a NODE_OPERATOR.  */\n-  unsigned char rid_code;\t\t/* Rid code - for front ends.  */\n+  unsigned int rid_code : 8;\t\t/* Rid code - for front ends.  */\n+  unsigned int flags : 9;\t\t/* CPP flags.  */\n   ENUM_BITFIELD(node_type) type : 2;\t/* CPP node type.  */\n-  unsigned int flags : 8;\t\t/* CPP flags.  */\n \n-  /* 6 bits spare (plus another 32 on 64-bit hosts).  */\n+  /* 5 bits spare (plus another 32 on 64-bit hosts).  */\n \n   union _cpp_hashnode_value GTY ((desc (\"%1.type\"))) value;\n };"}, {"sha": "fc826583d3a1199dc0bdc7547ba9aede6375a582", "filename": "libcpp/init.c", "status": "modified", "additions": 23, "deletions": 0, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c9c3d5f28a589cd00be5748010783657189e9855/libcpp%2Finit.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c9c3d5f28a589cd00be5748010783657189e9855/libcpp%2Finit.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libcpp%2Finit.c?ref=c9c3d5f28a589cd00be5748010783657189e9855", "patch": "@@ -843,4 +843,27 @@ post_options (cpp_reader *pfile)\n       CPP_OPTION (pfile, trigraphs) = 0;\n       CPP_OPTION (pfile, warn_trigraphs) = 0;\n     }\n+\n+  if (CPP_OPTION (pfile, module_directives))\n+    {\n+      /* These unspellable tokens have a leading space.  */\n+      const char *const inits[spec_nodes::M_HWM]\n+\t= {\"export \", \"module \", \"import \", \"__import\"};\n+\n+      for (int ix = 0; ix != spec_nodes::M_HWM; ix++)\n+\t{\n+\t  cpp_hashnode *node = cpp_lookup (pfile, UC (inits[ix]),\n+\t\t\t\t\t   strlen (inits[ix]));\n+\n+\t  /* Token we pass to the compiler.  */\n+\t  pfile->spec_nodes.n_modules[ix][1] = node;\n+\n+\t  if (ix != spec_nodes::M__IMPORT)\n+\t    /* Token we recognize when lexing, drop the trailing ' '.  */\n+\t    node = cpp_lookup (pfile, NODE_NAME (node), NODE_LEN (node) - 1);\n+\n+\t  node->flags |= NODE_MODULE;\n+\t  pfile->spec_nodes.n_modules[ix][0] = node;\n+\t}\n+    }\n }"}, {"sha": "4c1100bbdeb2132bcce094b91b84548701a09d31", "filename": "libcpp/internal.h", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c9c3d5f28a589cd00be5748010783657189e9855/libcpp%2Finternal.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c9c3d5f28a589cd00be5748010783657189e9855/libcpp%2Finternal.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libcpp%2Finternal.h?ref=c9c3d5f28a589cd00be5748010783657189e9855", "patch": "@@ -280,6 +280,9 @@ struct lexer_state\n   /* Nonzero when tokenizing a deferred pragma.  */\n   unsigned char in_deferred_pragma;\n \n+  /* Count to token that is a header-name.  */\n+  unsigned char directive_file_token;\n+\n   /* Nonzero if the deferred pragma being handled allows macro expansion.  */\n   unsigned char pragma_allow_expansion;\n };\n@@ -292,6 +295,12 @@ struct spec_nodes\n   cpp_hashnode *n_false;\t\t/* C++ keyword false */\n   cpp_hashnode *n__VA_ARGS__;\t\t/* C99 vararg macros */\n   cpp_hashnode *n__VA_OPT__;\t\t/* C++ vararg macros */\n+\n+  enum {M_EXPORT, M_MODULE, M_IMPORT, M__IMPORT, M_HWM};\n+  \n+  /* C++20 modules, only set when module_directives is in effect.\n+     incoming variants [0], outgoing ones [1] */\n+  cpp_hashnode *n_modules[M_HWM][2];\n };\n \n typedef struct _cpp_line_note _cpp_line_note;"}, {"sha": "2343ed5aa0030843c3dd9aa9524aea1b8d5c89a8", "filename": "libcpp/lex.c", "status": "modified", "additions": 392, "deletions": 0, "changes": 392, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c9c3d5f28a589cd00be5748010783657189e9855/libcpp%2Flex.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c9c3d5f28a589cd00be5748010783657189e9855/libcpp%2Flex.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libcpp%2Flex.c?ref=c9c3d5f28a589cd00be5748010783657189e9855", "patch": "@@ -2615,6 +2615,150 @@ _cpp_temp_token (cpp_reader *pfile)\n   return result;\n }\n \n+/* We're at the beginning of a logical line (so not in\n+  directives-mode) and RESULT is a CPP_NAME with NODE_MODULE set.  See\n+  if we should enter deferred_pragma mode to tokenize the rest of the\n+  line as a module control-line.  */\n+\n+static void\n+cpp_maybe_module_directive (cpp_reader *pfile, cpp_token *result)\n+{\n+  unsigned backup = 0; /* Tokens we peeked.  */\n+  cpp_hashnode *node = result->val.node.node;\n+  cpp_token *peek = result;\n+  cpp_token *keyword = peek;\n+  cpp_hashnode *(&n_modules)[spec_nodes::M_HWM][2] = pfile->spec_nodes.n_modules;\n+  int header_count = 0;\n+\n+  /* Make sure the incoming state is as we expect it.  This way we\n+     can restore it using constants.  */\n+  gcc_checking_assert (!pfile->state.in_deferred_pragma\n+\t\t       && !pfile->state.skipping\n+\t\t       && !pfile->state.parsing_args\n+\t\t       && !pfile->state.angled_headers\n+\t\t       && (pfile->state.save_comments\n+\t\t\t   == !CPP_OPTION (pfile, discard_comments)));\n+\n+  /* Enter directives mode sufficiently for peeking.  We don't have\n+     to actually set in_directive.  */\n+  pfile->state.in_deferred_pragma = true;\n+\n+  /* These two fields are needed to process tokenization in deferred\n+     pragma mode.  They are not used outside deferred pragma mode or\n+     directives mode.  */\n+  pfile->state.pragma_allow_expansion = true;\n+  pfile->directive_line = result->src_loc;\n+\n+  /* Saving comments is incompatible with directives mode.   */\n+  pfile->state.save_comments = 0;\n+\n+  if (node == n_modules[spec_nodes::M_EXPORT][0])\n+    {\n+      peek = _cpp_lex_direct (pfile);\n+      keyword = peek;\n+      backup++;\n+      if (keyword->type != CPP_NAME)\n+\tgoto not_module;\n+      node = keyword->val.node.node;\n+      if (!(node->flags & NODE_MODULE))\n+\tgoto not_module;\n+    }\n+\n+  if (node == n_modules[spec_nodes::M__IMPORT][0])\n+    /* __import  */\n+    header_count = backup + 2 + 16;\n+  else if (node == n_modules[spec_nodes::M_IMPORT][0])\n+    /* import  */\n+    header_count = backup + 2 + (CPP_OPTION (pfile, preprocessed) ? 16 : 0);\n+  else if (node == n_modules[spec_nodes::M_MODULE][0])\n+    ; /* module  */\n+  else\n+    goto not_module;\n+\n+  /* We've seen [export] {module|import|__import}.  Check the next token.  */\n+  if (header_count)\n+    /* After '{,__}import' a header name may appear.  */\n+    pfile->state.angled_headers = true;\n+  peek = _cpp_lex_direct (pfile);\n+  backup++;\n+\n+  /* ... import followed by identifier, ':', '<' or\n+     header-name preprocessing tokens, or module\n+     followed by cpp-identifier, ':' or ';' preprocessing\n+     tokens.  C++ keywords are not yet relevant.  */\n+  if (peek->type == CPP_NAME\n+      || peek->type == CPP_COLON\n+      ||  (header_count\n+\t   ? (peek->type == CPP_LESS\n+\t      || (peek->type == CPP_STRING && peek->val.str.text[0] != 'R')\n+\t      || peek->type == CPP_HEADER_NAME)\n+\t   : peek->type == CPP_SEMICOLON))\n+    {\n+      pfile->state.pragma_allow_expansion = !CPP_OPTION (pfile, preprocessed);\n+      if (!pfile->state.pragma_allow_expansion)\n+\tpfile->state.prevent_expansion++;\n+\n+      if (!header_count && linemap_included_from\n+\t  (LINEMAPS_LAST_ORDINARY_MAP (pfile->line_table)))\n+\tcpp_error_with_line (pfile, CPP_DL_ERROR, keyword->src_loc, 0,\n+\t\t\t     \"module control-line cannot be in included file\");\n+\n+      /* The first one or two tokens cannot be macro names.  */\n+      for (int ix = backup; ix--;)\n+\t{\n+\t  cpp_token *tok = ix ? keyword : result;\n+\t  cpp_hashnode *node = tok->val.node.node;\n+\n+\t  /* Don't attempt to expand the token.  */\n+\t  tok->flags |= NO_EXPAND;\n+\t  if (_cpp_defined_macro_p (node)\n+\t      && !cpp_fun_like_macro_p (node))\n+\t    cpp_error_with_line (pfile, CPP_DL_ERROR, tok->src_loc, 0, \n+\t\t\t\t \"module control-line \\\"%s\\\" cannot be\"\n+\t\t\t\t \" an object-like macro\",\n+\t\t\t\t NODE_NAME (node));\n+\t}\n+\n+      /* Map to underbar variants.  */\n+      keyword->val.node.node = n_modules[header_count\n+\t\t\t\t\t ? spec_nodes::M_IMPORT\n+\t\t\t\t\t : spec_nodes::M_MODULE][1];\n+      if (backup != 1)\n+\tresult->val.node.node = n_modules[spec_nodes::M_EXPORT][1];\n+\n+      /* Maybe tell the tokenizer we expect a header-name down the\n+\t road.  */\n+      pfile->state.directive_file_token = header_count;\n+    }\n+  else\n+    {\n+    not_module:\n+      /* Drop out of directive mode.  */\n+      /* We aaserted save_comments had this value upon entry.  */\n+      pfile->state.save_comments\n+\t= !CPP_OPTION (pfile, discard_comments);\n+      pfile->state.in_deferred_pragma = false;\n+      /* Do not let this remain on.  */\n+      pfile->state.angled_headers = false;\n+    }\n+\n+  /* In either case we want to backup the peeked tokens.  */\n+  if (backup)\n+    {\n+      /* If we saw EOL, we should drop it, because this isn't a module\n+\t control-line after all.  */\n+      bool eol = peek->type == CPP_PRAGMA_EOL;\n+      if (!eol || backup > 1)\n+\t{\n+\t  /* Put put the peeked tokens back  */\n+\t  _cpp_backup_tokens_direct (pfile, backup);\n+\t  /* But if the last one was an EOL, forget it.  */\n+\t  if (eol)\n+\t    pfile->lookaheads--;\n+\t}\n+    }\n+}\n+\n /* Lex a token into RESULT (external interface).  Takes care of issues\n    like directive handling, token lookahead, multiple include\n    optimization and skipping.  */\n@@ -2663,6 +2807,21 @@ _cpp_lex_token (cpp_reader *pfile)\n \t    }\n \t  else if (pfile->state.in_deferred_pragma)\n \t    result = &pfile->directive_result;\n+\t  else if (result->type == CPP_NAME\n+\t\t   && (result->val.node.node->flags & NODE_MODULE)\n+\t\t   && !pfile->state.skipping\n+\t\t   /* Unlike regular directives, we do not deal with\n+\t\t      tokenizing module directives as macro arguments.\n+\t\t      That's not permitted.  */\n+\t\t   && !pfile->state.parsing_args)\n+\t    {\n+\t      /* P1857.  Before macro expansion, At start of logical\n+\t\t line ... */\n+\t      /* We don't have to consider lookaheads at this point.  */\n+\t      gcc_checking_assert (!pfile->lookaheads);\n+\n+\t      cpp_maybe_module_directive (pfile, result);\n+\t    }\n \n \t  if (pfile->cb.line_change && !pfile->state.skipping)\n \t    pfile->cb.line_change (pfile, result, pfile->state.parsing_args);\n@@ -3461,7 +3620,11 @@ cpp_output_token (const cpp_token *token, FILE *fp)\n       break;\n \n     case SPELL_LITERAL:\n+      if (token->type == CPP_HEADER_NAME)\n+\tfputc ('\"', fp);\n       fwrite (token->val.str.text, 1, token->val.str.len, fp);\n+      if (token->type == CPP_HEADER_NAME)\n+\tfputc ('\"', fp);\n       break;\n \n     case SPELL_NONE:\n@@ -3947,6 +4110,188 @@ do_peek_prev (const unsigned char *peek, const unsigned char *bound)\n     return peek;\n }\n \n+/* If PEEK[-1] is identifier MATCH, scan past it and trailing white\n+   space.  Otherwise return NULL.  */\n+\n+static const unsigned char *\n+do_peek_ident (const char *match, const unsigned char *peek,\n+\t       const unsigned char *limit)\n+{\n+  for (; *++match; peek++)\n+    if (*peek != *match)\n+      {\n+\tpeek = do_peek_next (peek, limit);\n+\tif (*peek != *match)\n+\t  return NULL;\n+      }\n+\n+  /* Must now not be looking at an identifier char.  */\n+  peek = do_peek_next (peek, limit);\n+  if (ISIDNUM (*peek))\n+    return NULL;\n+\n+  /* Skip control-line whitespace.  */\n+ ws:\n+  while (*peek == ' ' || *peek == '\\t')\n+    peek++;\n+  if (__builtin_expect (*peek == '\\\\', false))\n+    {\n+      peek = do_peek_backslash (peek, limit);\n+      if (*peek != '\\\\')\n+\tgoto ws;\n+    }\n+\n+  return peek;\n+}\n+\n+/* Are we looking at a module control line starting as PEEK - 1?  */\n+\n+static bool\n+do_peek_module (cpp_reader *pfile, unsigned char c,\n+\t\tconst unsigned char *peek, const unsigned char *limit)\n+{\n+  bool import = false;\n+\n+  if (__builtin_expect (c == 'e', false))\n+    {\n+      if (!((peek[0] == 'x' || peek[0] == '\\\\')\n+\t    && (peek = do_peek_ident (\"export\", peek, limit))))\n+\treturn false;\n+\n+      /* export, peek for import or module.  No need to peek __import\n+\t here.  */\n+      if (peek[0] == 'i')\n+\t{\n+\t  if (!((peek[1] == 'm' || peek[1] == '\\\\')\n+\t\t&& (peek = do_peek_ident (\"import\", peek + 1, limit))))\n+\t    return false;\n+\t  import = true;\n+\t}\n+      else if (peek[0] == 'm')\n+\t{\n+\t  if (!((peek[1] == 'o' || peek[1] == '\\\\')\n+\t\t&& (peek = do_peek_ident (\"module\", peek + 1, limit))))\n+\t    return false;\n+\t}\n+      else\n+\treturn false;\n+    }\n+  else if (__builtin_expect (c == 'i', false))\n+    {\n+      if (!((peek[0] == 'm' || peek[0] == '\\\\')\n+\t    && (peek = do_peek_ident (\"import\", peek, limit))))\n+\treturn false;\n+      import = true;\n+    }\n+  else if (__builtin_expect (c == '_', false))\n+    {\n+      /* Needed for translated includes.   */\n+      if (!((peek[0] == '_' || peek[0] == '\\\\')\n+\t    && (peek = do_peek_ident (\"__import\", peek, limit))))\n+\treturn false;\n+      import = true;\n+    }\n+  else if (__builtin_expect (c == 'm', false))\n+    {\n+      if (!((peek[0] == 'o' || peek[0] == '\\\\')\n+\t    && (peek = do_peek_ident (\"module\", peek, limit))))\n+\treturn false;\n+    }\n+  else\n+    return false;\n+\n+  /* Peek the next character to see if it's good enough.  We'll be at\n+     the first non-whitespace char, including skipping an escaped\n+     newline.  */\n+  /* ... import followed by identifier, ':', '<' or header-name\n+     preprocessing tokens, or module followed by identifier, ':' or\n+     ';' preprocessing tokens.  */\n+  unsigned char p = *peek++;\n+      \n+  /* A character literal is ... single quotes, ... optionally preceded\n+     by u8, u, U, or L */\n+  /* A string-literal is a ... double quotes, optionally prefixed by\n+     R, u8, u8R, u, uR, U, UR, L, or LR */\n+  if (p == 'u')\n+    {\n+      peek = do_peek_next (peek, limit);\n+      if (*peek == '8')\n+\t{\n+\t  peek++;\n+\t  goto peek_u8;\n+\t}\n+      goto peek_u;\n+    }\n+  else if (p == 'U' || p == 'L')\n+    {\n+    peek_u8:\n+      peek = do_peek_next (peek, limit);\n+    peek_u:\n+      if (*peek == '\\\"' || *peek == '\\'')\n+\treturn false;\n+\n+      if (*peek == 'R')\n+\tgoto peek_R;\n+      /* Identifier. Ok.  */\n+    }\n+  else if (p == 'R')\n+    {\n+    peek_R:\n+      if (CPP_OPTION (pfile, rliterals))\n+\t{\n+\t  peek = do_peek_next (peek, limit);\n+\t  if (*peek == '\\\"')\n+\t    return false;\n+\t}\n+      /* Identifier. Ok.  */\n+    }\n+  else if ('Z' - 'A' == 25\n+\t   ? ((p >= 'A' && p <= 'Z') || (p >= 'a' && p <= 'z') || p == '_')\n+\t   : ISIDST (p))\n+    {\n+      /* Identifier.  Ok. */\n+    }\n+  else if (p == '<')\n+    {\n+      /* Maybe angle header, ok for import.  Reject\n+\t '<=', '<<' digraph:'<:'.  */\n+      if (!import)\n+\treturn false;\n+      peek = do_peek_next (peek, limit);\n+      if (*peek == '=' || *peek == '<'\n+\t  || (*peek == ':' && CPP_OPTION (pfile, digraphs)))\n+\treturn false;\n+    }\n+  else if (p == ';')\n+    {\n+      /* SEMICOLON, ok for module.  */\n+      if (import)\n+\treturn false;\n+    }\n+  else if (p == '\"')\n+    {\n+      /* STRING, ok for import.  */\n+      if (!import)\n+\treturn false;\n+    }\n+  else if (p == ':')\n+    {\n+      /* Maybe COLON, ok.  Reject '::', digraph:':>'.  */\n+      peek = do_peek_next (peek, limit);\n+      if (*peek == ':' || (*peek == '>' && CPP_OPTION (pfile, digraphs)))\n+\treturn false;\n+    }\n+  else\n+    /* FIXME: Detect a unicode character, excluding those not\n+       permitted as the initial character. [lex.name]/1.  I presume\n+       we need to check the \\[uU] spellings, and directly using\n+       Unicode in say UTF8 form?  Or perhaps we do the phase-1\n+       conversion of UTF8 to universal-character-names?  */\n+    return false;\n+\n+  return true;\n+}\n+\n /* Directives-only scanning.  Somewhat more relaxed than correct\n    parsing -- some ill-formed programs will not be rejected.  */\n \n@@ -3955,6 +4300,8 @@ cpp_directive_only_process (cpp_reader *pfile,\n \t\t\t    void *data,\n \t\t\t    void (*cb) (cpp_reader *, CPP_DO_task, void *, ...))\n {\n+  bool module_p = CPP_OPTION (pfile, module_directives);\n+\n   do\n     {\n     restart:\n@@ -4347,6 +4694,51 @@ cpp_directive_only_process (cpp_reader *pfile,\n \t      }\n \t      goto dflt;\n \n+\t    case '_':\n+\t    case 'e':\n+\t    case 'i':\n+\t    case 'm':\n+\t      if (bol && module_p && !pfile->state.skipping\n+\t\t  && do_peek_module (pfile, c, pos, limit))\n+\t\t{\n+\t\t  /* We've seen the start of a module control line.\n+\t\t     Start up the tokenizer.  */\n+\t\t  pos--; /* Backup over the first character.  */\n+\n+\t\t  /* Backup over whitespace to start of line.  */\n+\t\t  while (pos > line_start\n+\t\t\t && (pos[-1] == ' ' || pos[-1] == '\\t'))\n+\t\t    pos--;\n+\n+\t\t  if (pos > base)\n+\t\t    cb (pfile, CPP_DO_print, data, line_count, base, pos - base);\n+\n+\t\t  /* Prep things for directive handling. */\n+\t\t  buffer->next_line = pos;\n+\t\t  buffer->need_line = true;\n+\n+\t\t  /* Now get tokens until the PRAGMA_EOL.  */\n+\t\t  do\n+\t\t    {\n+\t\t      location_t spelling;\n+\t\t      const cpp_token *tok\n+\t\t\t= cpp_get_token_with_location (pfile, &spelling);\n+\n+\t\t      gcc_assert (pfile->state.in_deferred_pragma\n+\t\t\t\t  || tok->type == CPP_PRAGMA_EOL);\n+\t\t      cb (pfile, CPP_DO_token, data, tok, spelling);\n+\t\t    }\n+\t\t  while (pfile->state.in_deferred_pragma);\n+\n+\t\t  if (pfile->buffer->next_line < pfile->buffer->rlimit)\n+\t\t    cb (pfile, CPP_DO_location, data,\n+\t\t\tpfile->line_table->highest_line);\n+\n+\t\t  pfile->mi_valid = false;\n+\t\t  goto restart;\n+\t\t}\n+\t      goto dflt;\n+\n \t    default:\n \t    dflt:\n \t      bol = false;"}, {"sha": "ddcf3b4f63a02eee64a93be0fa0d015c70f20b79", "filename": "libcpp/macro.c", "status": "modified", "additions": 79, "deletions": 0, "changes": 79, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c9c3d5f28a589cd00be5748010783657189e9855/libcpp%2Fmacro.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c9c3d5f28a589cd00be5748010783657189e9855/libcpp%2Fmacro.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libcpp%2Fmacro.c?ref=c9c3d5f28a589cd00be5748010783657189e9855", "patch": "@@ -2963,6 +2963,85 @@ cpp_get_token_1 (cpp_reader *pfile, location_t *location)\n     }\n \n   pfile->about_to_expand_macro_p = saved_about_to_expand_macro;\n+\n+  if (pfile->state.directive_file_token\n+      && !pfile->state.parsing_args\n+      && !(result->type == CPP_PADDING || result->type == CPP_COMMENT)\n+      && !(15 & --pfile->state.directive_file_token))\n+    {\n+      /* Do header-name frobbery.  Concatenate < ... > as approprate.\n+\t Do header search if needed, and finally drop the outer <> or\n+\t \"\".  */\n+      pfile->state.angled_headers = false;\n+\n+      /* Do angle-header reconstitution.  Then do include searching.\n+\t We'll always end up with a \"\"-quoted header-name in that\n+\t case.  If searching finds nothing, we emit a diagnostic and\n+\t an empty string.  */\n+      size_t len = 0;\n+      char *fname = NULL;\n+\n+      cpp_token *tmp = _cpp_temp_token (pfile);\n+      *tmp = *result;\n+\n+      tmp->type = CPP_HEADER_NAME;\n+      bool need_search = !pfile->state.directive_file_token;\n+      pfile->state.directive_file_token = 0;\n+\n+      bool angle = result->type != CPP_STRING;\n+      if (result->type == CPP_HEADER_NAME\n+\t  || (result->type == CPP_STRING && result->val.str.text[0] != 'R'))\n+\t{\n+\t  len = result->val.str.len - 2;\n+\t  fname = XNEWVEC (char, len + 1);\n+\t  memcpy (fname, result->val.str.text + 1, len);\n+\t  fname[len] = 0;\n+\t}\n+      else if (result->type == CPP_LESS)\n+\tfname = _cpp_bracket_include (pfile);\n+\n+      if (fname)\n+\t{\n+\t  /* We have a header-name.  Look it up.  This will emit an\n+\t     unfound diagnostic.  Canonicalize the found name.  */\n+\t  const char *found = fname;\n+\n+\t  if (need_search)\n+\t    {\n+\t      found = cpp_find_header_unit (pfile, fname, angle, tmp->src_loc);\n+\t      if (!found)\n+\t\tfound = \"\";\n+\t      len = strlen (found);\n+\t    }\n+\t  /* Force a leading './' if it's not absolute.  */\n+\t  bool dotme = (found[0] == '.' ? !IS_DIR_SEPARATOR (found[1])\n+\t\t\t: found[0] && !IS_ABSOLUTE_PATH (found));\n+\n+\t  if (BUFF_ROOM (pfile->u_buff) < len + 1 + dotme * 2)\n+\t    _cpp_extend_buff (pfile, &pfile->u_buff, len + 1 + dotme * 2);\n+\t  unsigned char *buf = BUFF_FRONT (pfile->u_buff);\n+\t  size_t pos = 0;\n+\t      \n+\t  if (dotme)\n+\t    {\n+\t      buf[pos++] = '.';\n+\t      /* Apparently '/' is unconditional.  */\n+\t      buf[pos++] = '/';\n+\t    }\n+\t  memcpy (&buf[pos], found, len);\n+\t  pos += len;\n+\t  buf[pos] = 0;\n+\n+\t  tmp->val.str.len = pos;\n+\t  tmp->val.str.text = buf;\n+\n+\t  tmp->type = CPP_HEADER_NAME;\n+\t  XDELETEVEC (fname);\n+\t  \n+\t  result = tmp;\n+\t}\n+    }\n+\n   return result;\n }\n "}]}