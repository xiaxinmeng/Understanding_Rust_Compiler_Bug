{"sha": "02ce5d903e74829a10d98fc25cbe84c3b4d5f023", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MDJjZTVkOTAzZTc0ODI5YTEwZDk4ZmMyNWNiZTg0YzNiNGQ1ZjAyMw==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@linaro.org", "date": "2017-12-20T12:53:05Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2017-12-20T12:53:05Z"}, "message": "poly_int: dse.c\n\nThis patch makes RTL DSE use poly_int for offsets and sizes.\nThe local phase can optimise them normally but the global phase\ntreats them as wild accesses.\n\n2017-12-20  Richard Sandiford  <richard.sandiford@linaro.org>\n\t    Alan Hayward  <alan.hayward@arm.com>\n\t    David Sherwood  <david.sherwood@arm.com>\n\ngcc/\n\t* dse.c (store_info): Change offset and width from HOST_WIDE_INT\n\tto poly_int64.  Update commentary for positions_needed.large.\n\t(read_info_type): Change offset and width from HOST_WIDE_INT\n\tto poly_int64.\n\t(set_usage_bits): Likewise.\n\t(canon_address): Return the offset as a poly_int64 rather than\n\ta HOST_WIDE_INT.  Use strip_offset_and_add.\n\t(set_all_positions_unneeded, any_positions_needed_p): Use\n\tpositions_needed.large to track stores with non-constant widths.\n\t(all_positions_needed_p): Likewise.  Take the offset and width\n\tas poly_int64s rather than ints.  Assert that rhs is nonnull.\n\t(record_store): Cope with non-constant offsets and widths.\n\tNullify the rhs of an earlier store if we can't tell which bytes\n\tof it are needed.\n\t(find_shift_sequence): Take the access_size and shift as poly_int64s\n\trather than ints.\n\t(get_stored_val): Take the read_offset and read_width as poly_int64s\n\trather than HOST_WIDE_INTs.\n\t(check_mem_read_rtx, scan_stores, scan_reads, dse_step5): Handle\n\tnon-constant offsets and widths.\n\nCo-Authored-By: Alan Hayward <alan.hayward@arm.com>\nCo-Authored-By: David Sherwood <david.sherwood@arm.com>\n\nFrom-SVN: r255873", "tree": {"sha": "fea5aa2938a6f0b90ac0e97c3a2860fbbc2675cd", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/fea5aa2938a6f0b90ac0e97c3a2860fbbc2675cd"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/02ce5d903e74829a10d98fc25cbe84c3b4d5f023", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/02ce5d903e74829a10d98fc25cbe84c3b4d5f023", "html_url": "https://github.com/Rust-GCC/gccrs/commit/02ce5d903e74829a10d98fc25cbe84c3b4d5f023", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/02ce5d903e74829a10d98fc25cbe84c3b4d5f023/comments", "author": null, "committer": null, "parents": [{"sha": "b9c257340bd20ec0e7debffc62ed3e3901c2908d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b9c257340bd20ec0e7debffc62ed3e3901c2908d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b9c257340bd20ec0e7debffc62ed3e3901c2908d"}], "stats": {"total": 264, "additions": 186, "deletions": 78}, "files": [{"sha": "b0db7c2483e044a376c2d83132c34918c21c2c01", "filename": "gcc/ChangeLog", "status": "modified", "additions": 25, "deletions": 0, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/02ce5d903e74829a10d98fc25cbe84c3b4d5f023/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/02ce5d903e74829a10d98fc25cbe84c3b4d5f023/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=02ce5d903e74829a10d98fc25cbe84c3b4d5f023", "patch": "@@ -1,3 +1,28 @@\n+2017-12-20  Richard Sandiford  <richard.sandiford@linaro.org>\n+\t    Alan Hayward  <alan.hayward@arm.com>\n+\t    David Sherwood  <david.sherwood@arm.com>\n+\n+\t* dse.c (store_info): Change offset and width from HOST_WIDE_INT\n+\tto poly_int64.  Update commentary for positions_needed.large.\n+\t(read_info_type): Change offset and width from HOST_WIDE_INT\n+\tto poly_int64.\n+\t(set_usage_bits): Likewise.\n+\t(canon_address): Return the offset as a poly_int64 rather than\n+\ta HOST_WIDE_INT.  Use strip_offset_and_add.\n+\t(set_all_positions_unneeded, any_positions_needed_p): Use\n+\tpositions_needed.large to track stores with non-constant widths.\n+\t(all_positions_needed_p): Likewise.  Take the offset and width\n+\tas poly_int64s rather than ints.  Assert that rhs is nonnull.\n+\t(record_store): Cope with non-constant offsets and widths.\n+\tNullify the rhs of an earlier store if we can't tell which bytes\n+\tof it are needed.\n+\t(find_shift_sequence): Take the access_size and shift as poly_int64s\n+\trather than ints.\n+\t(get_stored_val): Take the read_offset and read_width as poly_int64s\n+\trather than HOST_WIDE_INTs.\n+\t(check_mem_read_rtx, scan_stores, scan_reads, dse_step5): Handle\n+\tnon-constant offsets and widths.\n+\n 2017-12-20  Richard Sandiford  <richard.sandiford@linaro.org>\n \t    Alan Hayward  <alan.hayward@arm.com>\n \t    David Sherwood  <david.sherwood@arm.com>"}, {"sha": "d196b79d41d7eaa73a22e92b865cef2cb4c36e9c", "filename": "gcc/dse.c", "status": "modified", "additions": 161, "deletions": 78, "changes": 239, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/02ce5d903e74829a10d98fc25cbe84c3b4d5f023/gcc%2Fdse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/02ce5d903e74829a10d98fc25cbe84c3b4d5f023/gcc%2Fdse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdse.c?ref=02ce5d903e74829a10d98fc25cbe84c3b4d5f023", "patch": "@@ -244,11 +244,11 @@ struct store_info\n   rtx mem_addr;\n \n   /* The offset of the first byte associated with the operation.  */\n-  HOST_WIDE_INT offset;\n+  poly_int64 offset;\n \n   /* The number of bytes covered by the operation.  This is always exact\n      and known (rather than -1).  */\n-  HOST_WIDE_INT width;\n+  poly_int64 width;\n \n   union\n     {\n@@ -259,12 +259,19 @@ struct store_info\n \n       struct\n \t{\n-\t  /* A bitmap with one bit per byte.  Cleared bit means the position\n-\t     is needed.  Used if IS_LARGE is false.  */\n+\t  /* A bitmap with one bit per byte, or null if the number of\n+\t     bytes isn't known at compile time.  A cleared bit means\n+\t     the position is needed.  Used if IS_LARGE is true.  */\n \t  bitmap bmap;\n \n-\t  /* Number of set bits (i.e. unneeded bytes) in BITMAP.  If it is\n-\t     equal to WIDTH, the whole store is unused.  */\n+\t  /* When BITMAP is nonnull, this counts the number of set bits\n+\t     (i.e. unneeded bytes) in the bitmap.  If it is equal to\n+\t     WIDTH, the whole store is unused.\n+\n+\t     When BITMAP is null:\n+\t     - the store is definitely not needed when COUNT == 1\n+\t     - all the store is needed when COUNT == 0 and RHS is nonnull\n+\t     - otherwise we don't know which parts of the store are needed.  */\n \t  int count;\n \t} large;\n     } positions_needed;\n@@ -308,10 +315,10 @@ struct read_info_type\n   int group_id;\n \n   /* The offset of the first byte associated with the operation.  */\n-  HOST_WIDE_INT offset;\n+  poly_int64 offset;\n \n   /* The number of bytes covered by the operation, or -1 if not known.  */\n-  HOST_WIDE_INT width;\n+  poly_int64 width;\n \n   /* The mem being read.  */\n   rtx mem;\n@@ -940,13 +947,18 @@ can_escape (tree expr)\n    OFFSET and WIDTH.  */\n \n static void\n-set_usage_bits (group_info *group, HOST_WIDE_INT offset, HOST_WIDE_INT width,\n+set_usage_bits (group_info *group, poly_int64 offset, poly_int64 width,\n                 tree expr)\n {\n-  HOST_WIDE_INT i;\n+  /* Non-constant offsets and widths act as global kills, so there's no point\n+     trying to use them to derive global DSE candidates.  */\n+  HOST_WIDE_INT i, const_offset, const_width;\n   bool expr_escapes = can_escape (expr);\n-  if (offset > -MAX_OFFSET && offset + width < MAX_OFFSET)\n-    for (i=offset; i<offset+width; i++)\n+  if (offset.is_constant (&const_offset)\n+      && width.is_constant (&const_width)\n+      && const_offset > -MAX_OFFSET\n+      && const_offset + const_width < MAX_OFFSET)\n+    for (i = const_offset; i < const_offset + const_width; ++i)\n       {\n \tbitmap store1;\n \tbitmap store2;\n@@ -1080,7 +1092,7 @@ const_or_frame_p (rtx x)\n static bool\n canon_address (rtx mem,\n \t       int *group_id,\n-\t       HOST_WIDE_INT *offset,\n+\t       poly_int64 *offset,\n \t       cselib_val **base)\n {\n   machine_mode address_mode = get_address_mode (mem);\n@@ -1147,21 +1159,19 @@ canon_address (rtx mem,\n       if (GET_CODE (address) == CONST)\n \taddress = XEXP (address, 0);\n \n-      if (GET_CODE (address) == PLUS\n-\t  && CONST_INT_P (XEXP (address, 1)))\n-\t{\n-\t  *offset = INTVAL (XEXP (address, 1));\n-\t  address = XEXP (address, 0);\n-\t}\n+      address = strip_offset_and_add (address, offset);\n \n       if (ADDR_SPACE_GENERIC_P (MEM_ADDR_SPACE (mem))\n \t  && const_or_frame_p (address))\n \t{\n \t  group_info *group = get_group_info (address);\n \n \t  if (dump_file && (dump_flags & TDF_DETAILS))\n-\t    fprintf (dump_file, \"  gid=%d offset=%d \\n\",\n-\t\t     group->id, (int)*offset);\n+\t    {\n+\t      fprintf (dump_file, \"  gid=%d offset=\", group->id);\n+\t      print_dec (*offset, dump_file);\n+\t      fprintf (dump_file, \"\\n\");\n+\t    }\n \t  *base = NULL;\n \t  *group_id = group->id;\n \t  return true;\n@@ -1178,8 +1188,12 @@ canon_address (rtx mem,\n       return false;\n     }\n   if (dump_file && (dump_flags & TDF_DETAILS))\n-    fprintf (dump_file, \"  varying cselib base=%u:%u offset = %d\\n\",\n-\t     (*base)->uid, (*base)->hash, (int)*offset);\n+    {\n+      fprintf (dump_file, \"  varying cselib base=%u:%u offset = \",\n+\t       (*base)->uid, (*base)->hash);\n+      print_dec (*offset, dump_file);\n+      fprintf (dump_file, \"\\n\");\n+    }\n   return true;\n }\n \n@@ -1228,9 +1242,17 @@ set_all_positions_unneeded (store_info *s_info)\n {\n   if (__builtin_expect (s_info->is_large, false))\n     {\n-      bitmap_set_range (s_info->positions_needed.large.bmap,\n-\t\t\t0, s_info->width);\n-      s_info->positions_needed.large.count = s_info->width;\n+      HOST_WIDE_INT width;\n+      if (s_info->width.is_constant (&width))\n+\t{\n+\t  bitmap_set_range (s_info->positions_needed.large.bmap, 0, width);\n+\t  s_info->positions_needed.large.count = width;\n+\t}\n+      else\n+\t{\n+\t  gcc_checking_assert (!s_info->positions_needed.large.bmap);\n+\t  s_info->positions_needed.large.count = 1;\n+\t}\n     }\n   else\n     s_info->positions_needed.small_bitmask = HOST_WIDE_INT_0U;\n@@ -1242,35 +1264,64 @@ static inline bool\n any_positions_needed_p (store_info *s_info)\n {\n   if (__builtin_expect (s_info->is_large, false))\n-    return s_info->positions_needed.large.count < s_info->width;\n+    {\n+      HOST_WIDE_INT width;\n+      if (s_info->width.is_constant (&width))\n+\t{\n+\t  gcc_checking_assert (s_info->positions_needed.large.bmap);\n+\t  return s_info->positions_needed.large.count < width;\n+\t}\n+      else\n+\t{\n+\t  gcc_checking_assert (!s_info->positions_needed.large.bmap);\n+\t  return s_info->positions_needed.large.count == 0;\n+\t}\n+    }\n   else\n     return (s_info->positions_needed.small_bitmask != HOST_WIDE_INT_0U);\n }\n \n /* Return TRUE if all bytes START through START+WIDTH-1 from S_INFO\n-   store are needed.  */\n+   store are known to be needed.  */\n \n static inline bool\n-all_positions_needed_p (store_info *s_info, int start, int width)\n+all_positions_needed_p (store_info *s_info, poly_int64 start,\n+\t\t\tpoly_int64 width)\n {\n+  gcc_assert (s_info->rhs);\n+  if (!s_info->width.is_constant ())\n+    {\n+      gcc_assert (s_info->is_large\n+\t\t  && !s_info->positions_needed.large.bmap);\n+      return s_info->positions_needed.large.count == 0;\n+    }\n+\n+  /* Otherwise, if START and WIDTH are non-constant, we're asking about\n+     a non-constant region of a constant-sized store.  We can't say for\n+     sure that all positions are needed.  */\n+  HOST_WIDE_INT const_start, const_width;\n+  if (!start.is_constant (&const_start)\n+      || !width.is_constant (&const_width))\n+    return false;\n+\n   if (__builtin_expect (s_info->is_large, false))\n     {\n-      int end = start + width;\n-      while (start < end)\n-\tif (bitmap_bit_p (s_info->positions_needed.large.bmap, start++))\n+      for (HOST_WIDE_INT i = const_start; i < const_start + const_width; ++i)\n+\tif (bitmap_bit_p (s_info->positions_needed.large.bmap, i))\n \t  return false;\n       return true;\n     }\n   else\n     {\n-      unsigned HOST_WIDE_INT mask = lowpart_bitmask (width) << start;\n+      unsigned HOST_WIDE_INT mask\n+\t= lowpart_bitmask (const_width) << const_start;\n       return (s_info->positions_needed.small_bitmask & mask) == mask;\n     }\n }\n \n \n-static rtx get_stored_val (store_info *, machine_mode, HOST_WIDE_INT,\n-\t\t\t   HOST_WIDE_INT, basic_block, bool);\n+static rtx get_stored_val (store_info *, machine_mode, poly_int64,\n+\t\t\t   poly_int64, basic_block, bool);\n \n \n /* BODY is an instruction pattern that belongs to INSN.  Return 1 if\n@@ -1281,8 +1332,8 @@ static int\n record_store (rtx body, bb_info_t bb_info)\n {\n   rtx mem, rhs, const_rhs, mem_addr;\n-  HOST_WIDE_INT offset = 0;\n-  HOST_WIDE_INT width = 0;\n+  poly_int64 offset = 0;\n+  poly_int64 width = 0;\n   insn_info_t insn_info = bb_info->last_insn;\n   store_info *store_info = NULL;\n   int group_id;\n@@ -1356,7 +1407,7 @@ record_store (rtx body, bb_info_t bb_info)\n   else\n     width = GET_MODE_SIZE (GET_MODE (mem));\n \n-  if (offset > HOST_WIDE_INT_MAX - width)\n+  if (!endpoint_representable_p (offset, width))\n     {\n       clear_rhs_from_active_local_stores ();\n       return 0;\n@@ -1443,7 +1494,7 @@ record_store (rtx body, bb_info_t bb_info)\n       group_info *group = rtx_group_vec[group_id];\n       mem_addr = group->canon_base_addr;\n     }\n-  if (offset)\n+  if (maybe_ne (offset, 0))\n     mem_addr = plus_constant (get_address_mode (mem), mem_addr, offset);\n \n   while (ptr)\n@@ -1503,18 +1554,27 @@ record_store (rtx body, bb_info_t bb_info)\n \t\t}\n \t    }\n \n+\t  HOST_WIDE_INT begin_unneeded, const_s_width, const_width;\n \t  if (known_subrange_p (s_info->offset, s_info->width, offset, width))\n \t    /* The new store touches every byte that S_INFO does.  */\n \t    set_all_positions_unneeded (s_info);\n-\t  else\n+\t  else if ((offset - s_info->offset).is_constant (&begin_unneeded)\n+\t\t   && s_info->width.is_constant (&const_s_width)\n+\t\t   && width.is_constant (&const_width))\n \t    {\n-\t      HOST_WIDE_INT begin_unneeded = offset - s_info->offset;\n-\t      HOST_WIDE_INT end_unneeded = begin_unneeded + width;\n+\t      HOST_WIDE_INT end_unneeded = begin_unneeded + const_width;\n \t      begin_unneeded = MAX (begin_unneeded, 0);\n-\t      end_unneeded = MIN (end_unneeded, s_info->width);\n+\t      end_unneeded = MIN (end_unneeded, const_s_width);\n \t      for (i = begin_unneeded; i < end_unneeded; ++i)\n \t\tset_position_unneeded (s_info, i);\n \t    }\n+\t  else\n+\t    {\n+\t      /* We don't know which parts of S_INFO are needed and\n+\t\t which aren't, so invalidate the RHS.  */\n+\t      s_info->rhs = NULL;\n+\t      s_info->const_rhs = NULL;\n+\t    }\n \t}\n       else if (s_info->rhs)\n \t/* Need to see if it is possible for this store to overwrite\n@@ -1560,7 +1620,14 @@ record_store (rtx body, bb_info_t bb_info)\n   store_info->mem = mem;\n   store_info->mem_addr = mem_addr;\n   store_info->cse_base = base;\n-  if (width > HOST_BITS_PER_WIDE_INT)\n+  HOST_WIDE_INT const_width;\n+  if (!width.is_constant (&const_width))\n+    {\n+      store_info->is_large = true;\n+      store_info->positions_needed.large.count = 0;\n+      store_info->positions_needed.large.bmap = NULL;\n+    }\n+  else if (const_width > HOST_BITS_PER_WIDE_INT)\n     {\n       store_info->is_large = true;\n       store_info->positions_needed.large.count = 0;\n@@ -1569,7 +1636,8 @@ record_store (rtx body, bb_info_t bb_info)\n   else\n     {\n       store_info->is_large = false;\n-      store_info->positions_needed.small_bitmask = lowpart_bitmask (width);\n+      store_info->positions_needed.small_bitmask\n+\t= lowpart_bitmask (const_width);\n     }\n   store_info->group_id = group_id;\n   store_info->offset = offset;\n@@ -1604,10 +1672,10 @@ dump_insn_info (const char * start, insn_info_t insn_info)\n    shift.  */\n \n static rtx\n-find_shift_sequence (int access_size,\n+find_shift_sequence (poly_int64 access_size,\n \t\t     store_info *store_info,\n \t\t     machine_mode read_mode,\n-\t\t     int shift, bool speed, bool require_cst)\n+\t\t     poly_int64 shift, bool speed, bool require_cst)\n {\n   machine_mode store_mode = GET_MODE (store_info->mem);\n   scalar_int_mode new_mode;\n@@ -1743,11 +1811,11 @@ look_for_hardregs (rtx x, const_rtx pat ATTRIBUTE_UNUSED, void *data)\n \n static rtx\n get_stored_val (store_info *store_info, machine_mode read_mode,\n-\t\tHOST_WIDE_INT read_offset, HOST_WIDE_INT read_width,\n+\t\tpoly_int64 read_offset, poly_int64 read_width,\n \t\tbasic_block bb, bool require_cst)\n {\n   machine_mode store_mode = GET_MODE (store_info->mem);\n-  HOST_WIDE_INT gap;\n+  poly_int64 gap;\n   rtx read_reg;\n \n   /* To get here the read is within the boundaries of the write so\n@@ -1761,10 +1829,10 @@ get_stored_val (store_info *store_info, machine_mode read_mode,\n   else\n     gap = read_offset - store_info->offset;\n \n-  if (gap != 0)\n+  if (maybe_ne (gap, 0))\n     {\n-      HOST_WIDE_INT shift = gap * BITS_PER_UNIT;\n-      HOST_WIDE_INT access_size = GET_MODE_SIZE (read_mode) + gap;\n+      poly_int64 shift = gap * BITS_PER_UNIT;\n+      poly_int64 access_size = GET_MODE_SIZE (read_mode) + gap;\n       read_reg = find_shift_sequence (access_size, store_info, read_mode,\n \t\t\t\t      shift, optimize_bb_for_speed_p (bb),\n \t\t\t\t      require_cst);\n@@ -1983,8 +2051,8 @@ check_mem_read_rtx (rtx *loc, bb_info_t bb_info)\n {\n   rtx mem = *loc, mem_addr;\n   insn_info_t insn_info;\n-  HOST_WIDE_INT offset = 0;\n-  HOST_WIDE_INT width = 0;\n+  poly_int64 offset = 0;\n+  poly_int64 width = 0;\n   cselib_val *base = NULL;\n   int group_id;\n   read_info_t read_info;\n@@ -2019,9 +2087,7 @@ check_mem_read_rtx (rtx *loc, bb_info_t bb_info)\n   else\n     width = GET_MODE_SIZE (GET_MODE (mem));\n \n-  if (width == -1\n-      ? offset == HOST_WIDE_INT_MIN\n-      : offset > HOST_WIDE_INT_MAX - width)\n+  if (!endpoint_representable_p (offset, known_eq (width, -1) ? 1 : width))\n     {\n       if (dump_file && (dump_flags & TDF_DETAILS))\n \tfprintf (dump_file, \" adding wild read, due to overflow.\\n\");\n@@ -2043,7 +2109,7 @@ check_mem_read_rtx (rtx *loc, bb_info_t bb_info)\n       group_info *group = rtx_group_vec[group_id];\n       mem_addr = group->canon_base_addr;\n     }\n-  if (offset)\n+  if (maybe_ne (offset, 0))\n     mem_addr = plus_constant (get_address_mode (mem), mem_addr, offset);\n \n   if (group_id >= 0)\n@@ -2055,7 +2121,7 @@ check_mem_read_rtx (rtx *loc, bb_info_t bb_info)\n \n       if (dump_file && (dump_flags & TDF_DETAILS))\n \t{\n-\t  if (width == -1)\n+\t  if (!known_size_p (width))\n \t    fprintf (dump_file, \" processing const load gid=%d[BLK]\\n\",\n \t\t     group_id);\n \t  else\n@@ -2089,7 +2155,7 @@ check_mem_read_rtx (rtx *loc, bb_info_t bb_info)\n \t    {\n \t      /* This is a block mode load.  We may get lucky and\n \t\t canon_true_dependence may save the day.  */\n-\t      if (width == -1)\n+\t      if (!known_size_p (width))\n \t\tremove\n \t\t  = canon_true_dependence (store_info->mem,\n \t\t\t\t\t   GET_MODE (store_info->mem),\n@@ -2820,13 +2886,17 @@ scan_stores (store_info *store_info, bitmap gen, bitmap kill)\n {\n   while (store_info)\n     {\n-      HOST_WIDE_INT i;\n+      HOST_WIDE_INT i, offset, width;\n       group_info *group_info\n \t= rtx_group_vec[store_info->group_id];\n-      if (group_info->process_globally)\n+      /* We can (conservatively) ignore stores whose bounds aren't known;\n+\t they simply don't generate new global dse opportunities.  */\n+      if (group_info->process_globally\n+\t  && store_info->offset.is_constant (&offset)\n+\t  && store_info->width.is_constant (&width))\n \t{\n-\t  HOST_WIDE_INT end = store_info->offset + store_info->width;\n-\t  for (i = store_info->offset; i < end; i++)\n+\t  HOST_WIDE_INT end = offset + width;\n+\t  for (i = offset; i < end; i++)\n \t    {\n \t      int index = get_bitmap_index (group_info, i);\n \t      if (index != 0)\n@@ -2886,7 +2956,12 @@ scan_reads (insn_info_t insn_info, bitmap gen, bitmap kill)\n \t    {\n \t      if (i == read_info->group_id)\n \t\t{\n-\t\t  if (!known_size_p (read_info->width))\n+\t\t  HOST_WIDE_INT offset, width;\n+\t\t  /* Reads with non-constant size kill all DSE opportunities\n+\t\t     in the group.  */\n+\t\t  if (!read_info->offset.is_constant (&offset)\n+\t\t      || !read_info->width.is_constant (&width)\n+\t\t      || !known_size_p (width))\n \t\t    {\n \t\t      /* Handle block mode reads.  */\n \t\t      if (kill)\n@@ -2898,8 +2973,8 @@ scan_reads (insn_info_t insn_info, bitmap gen, bitmap kill)\n \t\t      /* The groups are the same, just process the\n \t\t\t offsets.  */\n \t\t      HOST_WIDE_INT j;\n-\t\t      HOST_WIDE_INT end = read_info->offset + read_info->width;\n-\t\t      for (j = read_info->offset; j < end; j++)\n+\t\t      HOST_WIDE_INT end = offset + width;\n+\t\t      for (j = offset; j < end; j++)\n \t\t\t{\n \t\t\t  int index = get_bitmap_index (group, j);\n \t\t\t  if (index != 0)\n@@ -3315,22 +3390,30 @@ dse_step5 (void)\n \t      while (!store_info->is_set)\n \t\tstore_info = store_info->next;\n \n-\t      HOST_WIDE_INT i;\n+\t      HOST_WIDE_INT i, offset, width;\n \t      group_info *group_info = rtx_group_vec[store_info->group_id];\n \n-\t      HOST_WIDE_INT end = store_info->offset + store_info->width;\n-\t      for (i = store_info->offset; i < end; i++)\n+\t      if (!store_info->offset.is_constant (&offset)\n+\t\t  || !store_info->width.is_constant (&width))\n+\t\tdeleted = false;\n+\t      else\n \t\t{\n-\t\t  int index = get_bitmap_index (group_info, i);\n-\n-\t\t  if (dump_file && (dump_flags & TDF_DETAILS))\n-\t\t    fprintf (dump_file, \"i = %d, index = %d\\n\", (int)i, index);\n-\t\t  if (index == 0 || !bitmap_bit_p (v, index))\n+\t\t  HOST_WIDE_INT end = offset + width;\n+\t\t  for (i = offset; i < end; i++)\n \t\t    {\n+\t\t      int index = get_bitmap_index (group_info, i);\n+\n \t\t      if (dump_file && (dump_flags & TDF_DETAILS))\n-\t\t\tfprintf (dump_file, \"failing at i = %d\\n\", (int)i);\n-\t\t      deleted = false;\n-\t\t      break;\n+\t\t\tfprintf (dump_file, \"i = %d, index = %d\\n\",\n+\t\t\t\t (int) i, index);\n+\t\t      if (index == 0 || !bitmap_bit_p (v, index))\n+\t\t\t{\n+\t\t\t  if (dump_file && (dump_flags & TDF_DETAILS))\n+\t\t\t    fprintf (dump_file, \"failing at i = %d\\n\",\n+\t\t\t\t     (int) i);\n+\t\t\t  deleted = false;\n+\t\t\t  break;\n+\t\t\t}\n \t\t    }\n \t\t}\n \t      if (deleted)"}]}