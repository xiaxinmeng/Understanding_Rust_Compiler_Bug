{"sha": "10de9cf4f3765526a1a82a4a7d14908b58c6538c", "node_id": "C_kwDOANBUbNoAKDEwZGU5Y2Y0ZjM3NjU1MjZhMWE4MmE0YTdkMTQ5MDhiNThjNjUzOGM", "commit": {"author": {"name": "bors[bot]", "email": "26634292+bors[bot]@users.noreply.github.com", "date": "2022-02-23T09:17:08Z"}, "committer": {"name": "GitHub", "email": "noreply@github.com", "date": "2022-02-23T09:17:08Z"}, "message": "Merge #956\n\n956: Substitute repetitions r=CohenArthur a=CohenArthur\n\nNeeds #955 \r\n\r\nThis PR splits up the `substitute_tokens` function into multiple smaller functions. Still a draft until I can get repetitions working.\r\n\r\nCloses #960 \r\nCloses #961 \n\nCo-authored-by: Arthur Cohen <arthur.cohen@embecosm.com>", "tree": {"sha": "74a005cad16ea7ccd00f95720523c2f569de0fa1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/74a005cad16ea7ccd00f95720523c2f569de0fa1"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/10de9cf4f3765526a1a82a4a7d14908b58c6538c", "comment_count": 0, "verification": {"verified": true, "reason": "valid", "signature": "-----BEGIN PGP SIGNATURE-----\n\nwsBcBAABCAAQBQJiFfuUCRBK7hj4Ov3rIwAAYowIACW0fHEeH6BXDVSxSlqzAClb\nUPBz85mVuqFKCyNjYSJ7xXO7g9MlIvfrUSV4PhMOYMmRF0Wp6LWKzXnmFFh1gdmq\nrUnAjo0oWs+l59WcGVcA3QO9Hg+XeUzu29VRiFfmECuyQGjLSqEurqkGSYPqlNWs\nK5JveXSA1ZPQQppLfhF2i7HxglQWkOOCUCh/QnN/zszQ0YYT9TMxXGhhMl065Jxh\nZ386xysnkt8KBOQp4bK8R3ffwO+bM9d8lgnLey03h7yMQzIRdxOyMyg8sidLPH8G\nlN07yEOFkA19SG5TBzxoEPV9HiNJRnZ/AgeeS46fjqhCIuc4m9wQqOmgi5OWARw=\n=E12t\n-----END PGP SIGNATURE-----\n", "payload": "tree 74a005cad16ea7ccd00f95720523c2f569de0fa1\nparent e0f261f1aea2c9968a07442ca5d4eab813f86a58\nparent 92a62562c804b8cc400383bc4b0acb9e79e22a93\nauthor bors[bot] <26634292+bors[bot]@users.noreply.github.com> 1645607828 +0000\ncommitter GitHub <noreply@github.com> 1645607828 +0000\n\nMerge #956\n\n956: Substitute repetitions r=CohenArthur a=CohenArthur\n\nNeeds #955 \r\n\r\nThis PR splits up the `substitute_tokens` function into multiple smaller functions. Still a draft until I can get repetitions working.\r\n\r\nCloses #960 \r\nCloses #961 \n\nCo-authored-by: Arthur Cohen <arthur.cohen@embecosm.com>\n"}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/10de9cf4f3765526a1a82a4a7d14908b58c6538c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/10de9cf4f3765526a1a82a4a7d14908b58c6538c", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/10de9cf4f3765526a1a82a4a7d14908b58c6538c/comments", "author": {"login": "bors[bot]", "id": 26634292, "node_id": "MDM6Qm90MjY2MzQyOTI=", "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bors%5Bbot%5D", "html_url": "https://github.com/apps/bors", "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers", "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}", "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}", "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions", "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs", "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos", "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}", "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events", "type": "Bot", "site_admin": false}, "committer": {"login": "web-flow", "id": 19864447, "node_id": "MDQ6VXNlcjE5ODY0NDQ3", "avatar_url": "https://avatars.githubusercontent.com/u/19864447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/web-flow", "html_url": "https://github.com/web-flow", "followers_url": "https://api.github.com/users/web-flow/followers", "following_url": "https://api.github.com/users/web-flow/following{/other_user}", "gists_url": "https://api.github.com/users/web-flow/gists{/gist_id}", "starred_url": "https://api.github.com/users/web-flow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/web-flow/subscriptions", "organizations_url": "https://api.github.com/users/web-flow/orgs", "repos_url": "https://api.github.com/users/web-flow/repos", "events_url": "https://api.github.com/users/web-flow/events{/privacy}", "received_events_url": "https://api.github.com/users/web-flow/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e0f261f1aea2c9968a07442ca5d4eab813f86a58", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e0f261f1aea2c9968a07442ca5d4eab813f86a58", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e0f261f1aea2c9968a07442ca5d4eab813f86a58"}, {"sha": "92a62562c804b8cc400383bc4b0acb9e79e22a93", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/92a62562c804b8cc400383bc4b0acb9e79e22a93", "html_url": "https://github.com/Rust-GCC/gccrs/commit/92a62562c804b8cc400383bc4b0acb9e79e22a93"}], "stats": {"total": 519, "additions": 432, "deletions": 87}, "files": [{"sha": "dfd0b3ef0bc6fc6cc47a1b07edeb492169468011", "filename": "gcc/rust/ast/rust-ast.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Frust%2Fast%2Frust-ast.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Frust%2Fast%2Frust-ast.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Fast%2Frust-ast.h?ref=10de9cf4f3765526a1a82a4a7d14908b58c6538c", "patch": "@@ -204,6 +204,7 @@ class Token : public TokenTree, public MacroMatch\n   std::vector<std::unique_ptr<Token> > to_token_stream () const override;\n \n   TokenId get_id () const { return tok_ref->get_id (); }\n+  const std::string &get_str () const { return tok_ref->get_str (); }\n \n   Location get_locus () const { return tok_ref->get_locus (); }\n "}, {"sha": "b54aa0155a7e58f072b4636265e32d5dce321425", "filename": "gcc/rust/expand/rust-macro-expand.cc", "status": "modified", "additions": 233, "deletions": 74, "changes": 307, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Frust%2Fexpand%2Frust-macro-expand.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Frust%2Fexpand%2Frust-macro-expand.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Fexpand%2Frust-macro-expand.cc?ref=10de9cf4f3765526a1a82a4a7d14908b58c6538c", "patch": "@@ -3118,7 +3118,7 @@ MacroExpander::expand_decl_macro (Location invoc_locus,\n \n   // find matching arm\n   AST::MacroRule *matched_rule = nullptr;\n-  std::map<std::string, MatchedFragment> matched_fragments;\n+  std::map<std::string, std::vector<MatchedFragment>> matched_fragments;\n   for (auto &rule : rules_def.get_rules ())\n     {\n       sub_stack.push ();\n@@ -3127,9 +3127,9 @@ MacroExpander::expand_decl_macro (Location invoc_locus,\n \n       if (did_match_rule)\n \t{\n-\t  for (auto &frag : matched_fragments)\n-\t    rust_debug (\"matched fragment: %s\",\n-\t\t\tfrag.second.as_string ().c_str ());\n+\t  for (auto &kv : matched_fragments)\n+\t    rust_debug (\"[fragment]: %s (%ld)\", kv.first.c_str (),\n+\t\t\tkv.second.size ());\n \n \t  matched_rule = &rule;\n \t  break;\n@@ -3535,9 +3535,8 @@ MacroExpander::match_matcher (Parser<MacroInvocLexer> &parser,\n \n \t    // matched fragment get the offset in the token stream\n \t    size_t offs_end = source.get_offs ();\n-\t    sub_stack.peek ().insert (\n-\t      {fragment->get_ident (),\n-\t       MatchedFragment (fragment->get_ident (), offs_begin, offs_end)});\n+\t    sub_stack.insert_fragment (\n+\t      MatchedFragment (fragment->get_ident (), offs_begin, offs_end));\n \t  }\n \t  break;\n \n@@ -3611,7 +3610,6 @@ MacroExpander::match_n_matches (\n   match_amount = 0;\n \n   const MacroInvocLexer &source = parser.get_token_source ();\n-  std::vector<std::string> fragment_identifiers;\n   while (true)\n     {\n       // If the current token is a closing macro delimiter, break away.\n@@ -3633,12 +3631,9 @@ MacroExpander::match_n_matches (\n \n \t\t// matched fragment get the offset in the token stream\n \t\tsize_t offs_end = source.get_offs ();\n-\t\tsub_stack.peek ().insert (\n-\t\t  {fragment->get_ident (),\n-\t\t   MatchedFragment (fragment->get_ident (), offs_begin,\n-\t\t\t\t    offs_end)});\n-\n-\t\tfragment_identifiers.emplace_back (fragment->get_ident ());\n+\t\tsub_stack.insert_fragment (\n+\t\t  MatchedFragment (fragment->get_ident (), offs_begin,\n+\t\t\t\t   offs_end));\n \t      }\n \t      break;\n \n@@ -3677,21 +3672,10 @@ MacroExpander::match_n_matches (\n \n   // Check if the amount of matches we got is valid: Is it more than the lower\n   // bound and less than the higher bound?\n-  auto result = hi_bound ? match_amount >= lo_bound && match_amount <= hi_bound\n-\t\t\t : match_amount >= lo_bound;\n-\n-  // We can now set the amount to each fragment we matched in the substack\n-  auto &stack_map = sub_stack.peek ();\n-  for (auto &fragment_id : fragment_identifiers)\n-    {\n-      auto it = stack_map.find (fragment_id);\n-\n-      rust_assert (it != stack_map.end ());\n+  bool did_meet_lo_bound = match_amount >= lo_bound;\n+  bool did_meet_hi_bound = hi_bound ? match_amount <= hi_bound : true;\n \n-      it->second.set_match_amount (match_amount);\n-    }\n-\n-  return result;\n+  return did_meet_lo_bound && did_meet_hi_bound;\n }\n \n bool\n@@ -3733,14 +3717,41 @@ MacroExpander::match_repetition (Parser<MacroInvocLexer> &parser,\n   rust_debug_loc (rep.get_match_locus (), \"%s matched %lu times\",\n \t\t  res ? \"successfully\" : \"unsuccessfully\", match_amount);\n \n+  // We can now set the amount to each fragment we matched in the substack\n+  auto &stack_map = sub_stack.peek ();\n+  for (auto &match : rep.get_matches ())\n+    {\n+      if (match->get_macro_match_type ()\n+\t  == AST::MacroMatch::MacroMatchType::Fragment)\n+\t{\n+\t  auto fragment = static_cast<AST::MacroMatchFragment *> (match.get ());\n+\t  auto it = stack_map.find (fragment->get_ident ());\n+\n+\t  // If we can't find the fragment, but the result was valid, then\n+\t  // it's a zero-matched fragment and we can insert it\n+\t  if (it == stack_map.end ())\n+\t    {\n+\t      sub_stack.insert_fragment (\n+\t\tMatchedFragment::zero (fragment->get_ident ()));\n+\t    }\n+\t  else\n+\t    {\n+\t      // We can just set the repetition amount on the first match\n+\t      // FIXME: Make this more ergonomic and similar to what we fetch\n+\t      // in `substitute_repetition`\n+\t      it->second[0].set_match_amount (match_amount);\n+\t    }\n+\t}\n+    }\n+\n   return res;\n }\n \n AST::ASTFragment\n MacroExpander::transcribe_rule (\n   AST::MacroRule &match_rule, AST::DelimTokenTree &invoc_token_tree,\n-  std::map<std::string, MatchedFragment> &matched_fragments, bool semicolon,\n-  ContextType ctx)\n+  std::map<std::string, std::vector<MatchedFragment>> &matched_fragments,\n+  bool semicolon, ContextType ctx)\n {\n   // we can manipulate the token tree to substitute the dollar identifiers so\n   // that when we call parse its already substituted for us\n@@ -3874,11 +3885,193 @@ MacroExpander::transcribe_rule (\n   return AST::ASTFragment (std::move (nodes));\n }\n \n+std::vector<std::unique_ptr<AST::Token>>\n+MacroExpander::substitute_metavar (\n+  std::vector<std::unique_ptr<AST::Token>> &input,\n+  std::map<std::string, std::vector<MatchedFragment>> &fragments,\n+  std::unique_ptr<AST::Token> &metavar)\n+{\n+  auto metavar_name = metavar->get_str ();\n+\n+  std::vector<std::unique_ptr<AST::Token>> expanded;\n+  auto it = fragments.find (metavar_name);\n+  if (it == fragments.end ())\n+    {\n+      // Return a copy of the original token\n+      expanded.push_back (metavar->clone_token ());\n+    }\n+  else\n+    {\n+      // Replace\n+      // We only care about the vector when expanding repetitions. Just access\n+      // the first element of the vector.\n+      // FIXME: Clean this up so it makes more sense\n+      auto &frag = it->second[0];\n+      for (size_t offs = frag.token_offset_begin; offs < frag.token_offset_end;\n+\t   offs++)\n+\t{\n+\t  auto &tok = input.at (offs);\n+\t  expanded.push_back (tok->clone_token ());\n+\t}\n+    }\n+\n+  return expanded;\n+}\n+\n+std::vector<std::unique_ptr<AST::Token>>\n+MacroExpander::substitute_repetition (\n+  std::vector<std::unique_ptr<AST::Token>> &input,\n+  std::vector<std::unique_ptr<AST::Token>> &macro,\n+  std::map<std::string, std::vector<MatchedFragment>> &fragments,\n+  size_t pattern_start, size_t pattern_end)\n+{\n+  rust_assert (pattern_end < macro.size ());\n+\n+  rust_debug (\"pattern start: %lu\", pattern_start);\n+  rust_debug (\"pattern end: %lu\", pattern_end);\n+\n+  std::vector<std::unique_ptr<AST::Token>> expanded;\n+\n+  // Find the first fragment and get the amount of repetitions that we should\n+  // perform\n+  size_t repeat_amount = 0;\n+  for (size_t i = pattern_start; i < pattern_end; i++)\n+    {\n+      if (macro.at (i)->get_id () == DOLLAR_SIGN)\n+\t{\n+\t  auto &frag_token = macro.at (i + 1);\n+\t  if (frag_token->get_id () == IDENTIFIER)\n+\t    {\n+\t      auto it = fragments.find (frag_token->get_str ());\n+\t      if (it == fragments.end ())\n+\t\t{\n+\t\t  // If the repetition is not anything we know (ie no declared\n+\t\t  // metavars, or metavars which aren't present in the\n+\t\t  // fragment), we can just error out. No need to paste the\n+\t\t  // tokens as if nothing had happened.\n+\t\t  rust_error_at (frag_token->get_locus (),\n+\t\t\t\t \"metavar %s used in repetition does not exist\",\n+\t\t\t\t frag_token->get_str ().c_str ());\n+\t\t  // FIXME:\n+\t\t  return expanded;\n+\t\t}\n+\n+\t      // FIXME: Refactor, ugly\n+\t      repeat_amount = it->second[0].match_amount;\n+\t    }\n+\t}\n+    }\n+\n+  rust_debug (\"repetition amount to use: %lu\", repeat_amount);\n+  std::vector<std::unique_ptr<AST::Token>> new_macro;\n+\n+  // We want to generate a \"new macro\" to substitute with. This new macro\n+  // should contain only the tokens inside the pattern\n+  for (size_t tok_idx = pattern_start; tok_idx < pattern_end; tok_idx++)\n+    new_macro.emplace_back (macro.at (tok_idx)->clone_token ());\n+\n+  // Then, we want to create a subset of the matches so that\n+  // `substitute_tokens()` can only see one fragment per metavar. Let's say we\n+  // have the following user input: (1 145 'h')\n+  // on the following match arm: ($($lit:literal)*)\n+  // which causes the following matches: { \"lit\": [1, 145, 'h'] }\n+  //\n+  // The pattern (new_macro) is `$lit:literal`\n+  // The first time we expand it, we want $lit to have the following token: 1\n+  // The second time, 145\n+  // The third and final time, 'h'\n+  //\n+  // In order to do so we must create \"sub maps\", which only contain parts of\n+  // the original matches\n+  // sub-maps: [ { \"lit\": 1 }, { \"lit\": 145 }, { \"lit\": 'h' } ]\n+  //\n+  // and give them to `substitute_tokens` one by one.\n+\n+  for (size_t i = 0; i < repeat_amount; i++)\n+    {\n+      std::map<std::string, std::vector<MatchedFragment>> sub_map;\n+      for (auto &kv_match : fragments)\n+\t{\n+\t  std::vector<MatchedFragment> sub_vec;\n+\t  sub_vec.emplace_back (kv_match.second[i]);\n+\n+\t  sub_map.insert ({kv_match.first, sub_vec});\n+\t}\n+\n+      auto new_tokens = substitute_tokens (input, new_macro, sub_map);\n+\n+      for (auto &new_token : new_tokens)\n+\texpanded.emplace_back (new_token->clone_token ());\n+    }\n+\n+  // FIXME: We also need to make sure that all subsequent fragments\n+  // contain the same amount of repetitions as the first one\n+\n+  return expanded;\n+}\n+\n+std::pair<std::vector<std::unique_ptr<AST::Token>>, size_t>\n+MacroExpander::substitute_token (\n+  std::vector<std::unique_ptr<AST::Token>> &input,\n+  std::vector<std::unique_ptr<AST::Token>> &macro,\n+  std::map<std::string, std::vector<MatchedFragment>> &fragments,\n+  size_t token_idx)\n+{\n+  auto &token = macro.at (token_idx);\n+  switch (token->get_id ())\n+    {\n+    case IDENTIFIER:\n+      rust_debug (\"expanding metavar: %s\", token->get_str ().c_str ());\n+      return {substitute_metavar (input, fragments, token), 1};\n+      case LEFT_PAREN: {\n+\t// We need to parse up until the closing delimiter and expand this\n+\t// fragment->n times.\n+\trust_debug (\"expanding repetition\");\n+\tstd::vector<std::unique_ptr<AST::Token>> repetition_pattern;\n+\tsize_t pattern_start = token_idx + 1;\n+\tsize_t pattern_end = pattern_start;\n+\tfor (; pattern_end < macro.size ()\n+\t       && macro.at (pattern_end)->get_id () != RIGHT_PAREN;\n+\t     pattern_end++)\n+\t  ;\n+\n+\t// FIXME: This skips whitespaces... Is that okay??\n+\t// FIXME: Is there any existing parsing function that allows us to parse\n+\t// a macro pattern?\n+\n+\t// FIXME: Add error handling in the case we haven't found a matching\n+\t// closing delimiter\n+\n+\t// FIXME: We need to parse the repetition token now\n+\n+\treturn {\n+\t  substitute_repetition (input, macro, fragments, pattern_start,\n+\t\t\t\t pattern_end),\n+\t  // + 2 for the opening and closing parentheses which are mandatory\n+\t  // + 1 for the repetitor (+, *, ?)\n+\t  pattern_end - pattern_start + 3};\n+      }\n+      // TODO: We need to check if the $ was alone. In that case, do\n+      // not error out: Simply act as if there was an empty identifier\n+      // with no associated fragment and paste the dollar sign in the\n+      // transcription. Unsure how to do that since we always have at\n+      // least the closing curly brace after an empty $...\n+    default:\n+      rust_error_at (token->get_locus (),\n+\t\t     \"unexpected token in macro transcribe: expected \"\n+\t\t     \"%<(%> or identifier after %<$%>, got %<%s%>\",\n+\t\t     get_token_description (token->get_id ()));\n+    }\n+\n+  // FIXME: gcc_unreachable() error case?\n+  return {std::vector<std::unique_ptr<AST::Token>> (), 0};\n+}\n+\n std::vector<std::unique_ptr<AST::Token>>\n MacroExpander::substitute_tokens (\n   std::vector<std::unique_ptr<AST::Token>> &input,\n   std::vector<std::unique_ptr<AST::Token>> &macro,\n-  std::map<std::string, MatchedFragment> &fragments)\n+  std::map<std::string, std::vector<MatchedFragment>> &fragments)\n {\n   std::vector<std::unique_ptr<AST::Token>> replaced_tokens;\n \n@@ -3887,54 +4080,20 @@ MacroExpander::substitute_tokens (\n       auto &tok = macro.at (i);\n       if (tok->get_id () == DOLLAR_SIGN)\n \t{\n-\t  std::vector<std::unique_ptr<AST::Token>> parsed_toks;\n+\t  // Aaaaah, if only we had C++17 :)\n+\t  // auto [expanded, tok_to_skip] = ...\n+\t  auto p = substitute_token (input, macro, fragments, i + 1);\n+\t  auto expanded = std::move (p.first);\n+\t  auto tok_to_skip = p.second;\n \n-\t  std::string ident;\n-\t  for (size_t offs = i; i < macro.size (); offs++)\n-\t    {\n-\t      auto &tok = macro.at (offs);\n-\t      if (tok->get_id () == DOLLAR_SIGN && offs == i)\n-\t\t{\n-\t\t  parsed_toks.push_back (tok->clone_token ());\n-\t\t}\n-\t      else if (tok->get_id () == IDENTIFIER)\n-\t\t{\n-\t\t  rust_assert (tok->as_string ().size () == 1);\n-\t\t  ident.push_back (tok->as_string ().at (0));\n-\t\t  parsed_toks.push_back (tok->clone_token ());\n-\t\t}\n-\t      else\n-\t\t{\n-\t\t  break;\n-\t\t}\n-\t    }\n+\t  i += tok_to_skip;\n \n-\t  // lookup the ident\n-\t  auto it = fragments.find (ident);\n-\t  if (it == fragments.end ())\n-\t    {\n-\t      // just leave the tokens in\n-\t      for (auto &tok : parsed_toks)\n-\t\t{\n-\t\t  replaced_tokens.push_back (tok->clone_token ());\n-\t\t}\n-\t    }\n-\t  else\n-\t    {\n-\t      // replace\n-\t      MatchedFragment &frag = it->second;\n-\t      for (size_t offs = frag.token_offset_begin;\n-\t\t   offs < frag.token_offset_end; offs++)\n-\t\t{\n-\t\t  auto &tok = input.at (offs);\n-\t\t  replaced_tokens.push_back (tok->clone_token ());\n-\t\t}\n-\t    }\n-\t  i += parsed_toks.size () - 1;\n+\t  for (auto &token : expanded)\n+\t    replaced_tokens.emplace_back (token->clone_token ());\n \t}\n       else\n \t{\n-\t  replaced_tokens.push_back (tok->clone_token ());\n+\t  replaced_tokens.emplace_back (tok->clone_token ());\n \t}\n     }\n "}, {"sha": "eeafdb81816ee3de1438f1870b95fc599fc31f5a", "filename": "gcc/rust/expand/rust-macro-expand.h", "status": "modified", "additions": 96, "deletions": 13, "changes": 109, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Frust%2Fexpand%2Frust-macro-expand.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Frust%2Fexpand%2Frust-macro-expand.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frust%2Fexpand%2Frust-macro-expand.h?ref=10de9cf4f3765526a1a82a4a7d14908b58c6538c", "patch": "@@ -57,11 +57,21 @@ struct MatchedFragment\n   size_t match_amount;\n \n   MatchedFragment (std::string identifier, size_t token_offset_begin,\n-\t\t   size_t token_offset_end, size_t match_amount = 0)\n+\t\t   size_t token_offset_end, size_t match_amount = 1)\n     : fragment_ident (identifier), token_offset_begin (token_offset_begin),\n       token_offset_end (token_offset_end), match_amount (match_amount)\n   {}\n \n+  /**\n+   * Create a valid fragment matched zero times. This is useful for repetitions\n+   * which allow the absence of a fragment, such as * and ?\n+   */\n+  static MatchedFragment zero (std::string identifier)\n+  {\n+    // We don't need offsets since there is \"no match\"\n+    return MatchedFragment (identifier, 0, 0, 0);\n+  }\n+\n   std::string as_string () const\n   {\n     return fragment_ident + \"=\" + std::to_string (token_offset_begin) + \":\"\n@@ -79,17 +89,38 @@ class SubstitutionScope\n \n   void push () { stack.push_back ({}); }\n \n-  std::map<std::string, MatchedFragment> pop ()\n+  std::map<std::string, std::vector<MatchedFragment>> pop ()\n   {\n     auto top = stack.back ();\n     stack.pop_back ();\n     return top;\n   }\n \n-  std::map<std::string, MatchedFragment> &peek () { return stack.back (); }\n+  std::map<std::string, std::vector<MatchedFragment>> &peek ()\n+  {\n+    return stack.back ();\n+  }\n+\n+  void insert_fragment (MatchedFragment fragment)\n+  {\n+    auto &current_map = stack.back ();\n+    auto it = current_map.find (fragment.fragment_ident);\n+\n+    if (it == current_map.end ())\n+      {\n+\tauto new_frags = std::vector<MatchedFragment> ();\n+\tnew_frags.emplace_back (fragment);\n+\tcurrent_map.insert ({fragment.fragment_ident, new_frags});\n+      }\n+    else\n+      {\n+\tauto &frags = it->second;\n+\tfrags.emplace_back (fragment);\n+      }\n+  }\n \n private:\n-  std::vector<std::map<std::string, MatchedFragment>> stack;\n+  std::vector<std::map<std::string, std::vector<MatchedFragment>>> stack;\n };\n \n // Object used to store shared data (between functions) for macro expansion.\n@@ -141,11 +172,10 @@ struct MacroExpander\n   bool try_match_rule (AST::MacroRule &match_rule,\n \t\t       AST::DelimTokenTree &invoc_token_tree);\n \n-  AST::ASTFragment\n-  transcribe_rule (AST::MacroRule &match_rule,\n-\t\t   AST::DelimTokenTree &invoc_token_tree,\n-\t\t   std::map<std::string, MatchedFragment> &matched_fragments,\n-\t\t   bool semicolon, ContextType ctx);\n+  AST::ASTFragment transcribe_rule (\n+    AST::MacroRule &match_rule, AST::DelimTokenTree &invoc_token_tree,\n+    std::map<std::string, std::vector<MatchedFragment>> &matched_fragments,\n+    bool semicolon, ContextType ctx);\n \n   bool match_fragment (Parser<MacroInvocLexer> &parser,\n \t\t       AST::MacroMatchFragment &fragment);\n@@ -183,10 +213,63 @@ struct MacroExpander\n \t\t\tsize_t &match_amount, size_t lo_bound = 0,\n \t\t\tsize_t hi_bound = 0);\n \n-  static std::vector<std::unique_ptr<AST::Token>>\n-  substitute_tokens (std::vector<std::unique_ptr<AST::Token>> &input,\n-\t\t     std::vector<std::unique_ptr<AST::Token>> &macro,\n-\t\t     std::map<std::string, MatchedFragment> &fragments);\n+  /**\n+   * Substitute a metavariable by its given fragment in a transcribing context,\n+   * i.e. replacing $var with the associated fragment.\n+   *\n+   * @param input Tokens given to the transcribing context\n+   * @param fragments Fragments given to the macro substitution\n+   * @param metavar Metavariable to try and replace\n+   *\n+   * @return A token containing the associated fragment expanded into tokens if\n+   * any, or the cloned token if no fragment was associated\n+   */\n+  static std::vector<std::unique_ptr<AST::Token>> substitute_metavar (\n+    std::vector<std::unique_ptr<AST::Token>> &input,\n+    std::map<std::string, std::vector<MatchedFragment>> &fragments,\n+    std::unique_ptr<AST::Token> &metavar);\n+\n+  /**\n+   * Substitute a macro repetition by its given fragments\n+   *\n+   * @param input Tokens given to the transcribing context\n+   * @param fragments Fragments given to the macro substitution\n+   * @param pattern_start Start index of the pattern tokens\n+   * @param pattern_end Index  Amount of tokens in the pattern\n+   *\n+   * @return A vector containing the repeated pattern\n+   */\n+  static std::vector<std::unique_ptr<AST::Token>> substitute_repetition (\n+    std::vector<std::unique_ptr<AST::Token>> &input,\n+    std::vector<std::unique_ptr<AST::Token>> &macro,\n+    std::map<std::string, std::vector<MatchedFragment>> &fragments,\n+    size_t pattern_start, size_t pattern_end);\n+\n+  /**\n+   * Substitute a given token by its appropriate representation\n+   *\n+   * @param macro Tokens used in the macro declaration\n+   * @param input Tokens given to the transcribing context\n+   * @param fragments Fragments given to the macro substitution\n+   * @param token Current token to try and substitute\n+   *\n+   * @return A token containing the associated fragment expanded into tokens if\n+   * any, or the cloned token if no fragment was associated, as well as the\n+   * amount of tokens that should be skipped before the next invocation. Since\n+   * this function may consume more than just one token, it is important to skip\n+   * ahead of the input to avoid mis-substitutions\n+   */\n+  static std::pair<std::vector<std::unique_ptr<AST::Token>>, size_t>\n+  substitute_token (\n+    std::vector<std::unique_ptr<AST::Token>> &input,\n+    std::vector<std::unique_ptr<AST::Token>> &macro,\n+    std::map<std::string, std::vector<MatchedFragment>> &fragments,\n+    size_t token_idx);\n+\n+  static std::vector<std::unique_ptr<AST::Token>> substitute_tokens (\n+    std::vector<std::unique_ptr<AST::Token>> &input,\n+    std::vector<std::unique_ptr<AST::Token>> &macro,\n+    std::map<std::string, std::vector<MatchedFragment>> &fragments);\n \n   void push_context (ContextType t) { context.push_back (t); }\n "}, {"sha": "f1fc34eab908da4ad2c00a464af8acc9f755d48c", "filename": "gcc/testsuite/rust/execute/torture/macros10.rs", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Ftestsuite%2Frust%2Fexecute%2Ftorture%2Fmacros10.rs", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Ftestsuite%2Frust%2Fexecute%2Ftorture%2Fmacros10.rs", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Frust%2Fexecute%2Ftorture%2Fmacros10.rs?ref=10de9cf4f3765526a1a82a4a7d14908b58c6538c", "patch": "@@ -0,0 +1,20 @@\n+// { dg-output \"18\\n\" }\n+extern \"C\" {\n+    fn printf(s: *const i8, ...);\n+}\n+\n+fn print_int(value: i32) {\n+    let s = \"%d\\n\\0\" as *const str as *const i8;\n+    printf(s, value);\n+}\n+\n+macro_rules! add_exprs {\n+    ($($e:expr)*) => (0 $(+ $e)*)\n+}\n+\n+fn main() -> i32 {\n+    // 1 + 2 + 15 => 18\n+    print_int(add_exprs!(1 2 15));\n+\n+    0\n+}"}, {"sha": "7ce7d800f47582185ff1e85b4fb4e9a2646c64d0", "filename": "gcc/testsuite/rust/execute/torture/macros11.rs", "status": "added", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Ftestsuite%2Frust%2Fexecute%2Ftorture%2Fmacros11.rs", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Ftestsuite%2Frust%2Fexecute%2Ftorture%2Fmacros11.rs", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Frust%2Fexecute%2Ftorture%2Fmacros11.rs?ref=10de9cf4f3765526a1a82a4a7d14908b58c6538c", "patch": "@@ -0,0 +1,22 @@\n+// { dg-output \"2\" }\n+extern \"C\" {\n+    fn printf(s: *const i8, ...);\n+}\n+\n+fn print_int(value: i32) {\n+    let s = \"%d\\n\\0\";\n+    let s_p = s as *const str;\n+    let c_p = s_p as *const i8;\n+    unsafe { printf(c_p, value); }\n+}\n+\n+macro_rules! add_exprs {\n+    ($($e:expr)?) => (0 $(+ $e)?)\n+}\n+\n+fn main() -> i32 {\n+    // 2\n+    print_int(add_exprs!(2));\n+\n+    0\n+}"}, {"sha": "ff4a862fe606c8145008b985486560a825baccc6", "filename": "gcc/testsuite/rust/execute/torture/macros12.rs", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Ftestsuite%2Frust%2Fexecute%2Ftorture%2Fmacros12.rs", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Ftestsuite%2Frust%2Fexecute%2Ftorture%2Fmacros12.rs", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Frust%2Fexecute%2Ftorture%2Fmacros12.rs?ref=10de9cf4f3765526a1a82a4a7d14908b58c6538c", "patch": "@@ -0,0 +1,20 @@\n+// { dg-output \"0\\n\" }\n+extern \"C\" {\n+    fn printf(s: *const i8, ...);\n+}\n+\n+fn print_int(value: i32) {\n+    let s = \"%d\\n\\0\" as *const str as *const i8;\n+    printf(s, value);\n+}\n+\n+macro_rules! add_exprs {\n+    ($($e:expr)?) => (0 $(+ $e)?)\n+}\n+\n+fn main() -> i32 {\n+    // 0\n+    print_int(add_exprs!());\n+\n+    0\n+}"}, {"sha": "af5dfe84ee3860f73cb633212bc0d480b45a1b29", "filename": "gcc/testsuite/rust/execute/torture/macros13.rs", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Ftestsuite%2Frust%2Fexecute%2Ftorture%2Fmacros13.rs", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Ftestsuite%2Frust%2Fexecute%2Ftorture%2Fmacros13.rs", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Frust%2Fexecute%2Ftorture%2Fmacros13.rs?ref=10de9cf4f3765526a1a82a4a7d14908b58c6538c", "patch": "@@ -0,0 +1,20 @@\n+// { dg-output \"18\\n\" }\n+extern \"C\" {\n+    fn printf(s: *const i8, ...);\n+}\n+\n+fn print_int(value: i32) {\n+    let s = \"%d\\n\\0\" as *const str as *const i8;\n+    printf(s, value);\n+}\n+\n+macro_rules! add_exprs {\n+    ($($e:expr)+) => (0 $(+ $e)+)\n+}\n+\n+fn main() -> i32 {\n+    // 1 + 2 + 15 => 18\n+    print_int(add_exprs!(1 2 15));\n+\n+    0\n+}"}, {"sha": "2dc95e3e3be55d0341650e9661b3af1fff835273", "filename": "gcc/testsuite/rust/execute/torture/macros14.rs", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Ftestsuite%2Frust%2Fexecute%2Ftorture%2Fmacros14.rs", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/10de9cf4f3765526a1a82a4a7d14908b58c6538c/gcc%2Ftestsuite%2Frust%2Fexecute%2Ftorture%2Fmacros14.rs", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Frust%2Fexecute%2Ftorture%2Fmacros14.rs?ref=10de9cf4f3765526a1a82a4a7d14908b58c6538c", "patch": "@@ -0,0 +1,20 @@\n+// { dg-output \"15\\n\" }\n+extern \"C\" {\n+    fn printf(s: *const i8, ...);\n+}\n+\n+fn print_int(value: i32) {\n+    let s = \"%d\\n\\0\" as *const str as *const i8;\n+    printf(s, value);\n+}\n+\n+macro_rules! add_exprs {\n+    ($($e:expr)*) => (15 $(+ $e)*)\n+}\n+\n+fn main() -> i32 {\n+    // 15\n+    print_int(add_exprs!());\n+\n+    0\n+}"}]}