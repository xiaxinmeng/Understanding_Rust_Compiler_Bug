{"sha": "8261494856f9478e0393d5bd9be26961d16f266f", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ODI2MTQ5NDg1NmY5NDc4ZTAzOTNkNWJkOWJlMjY5NjFkMTZmMjY2Zg==", "commit": {"author": {"name": "Ramana Radhakrishnan", "email": "ramana.radhakrishnan@arm.com", "date": "2014-11-14T09:44:17Z"}, "committer": {"name": "Ramana Radhakrishnan", "email": "ramana@gcc.gnu.org", "date": "2014-11-14T09:44:17Z"}, "message": "re PR target/63724 ([AArch64] Inefficient immediate expansion and hoisting.)\n\nFix PR target/63724\n\n2014-11-14  Ramana Radhakrishnan  <ramana.radhakrishnan@arm.com>\n\n\tPR target/63724\n        * config/aarch64/aarch64.c (aarch64_expand_mov_immediate): Split out\n        numerical immediate handling to...\n        (aarch64_internal_mov_immediate): ...this. New.\n        (aarch64_rtx_costs): Use aarch64_internal_mov_immediate.\n        (aarch64_mov_operand_p): Relax predicate.\n        * config/aarch64/aarch64.md (mov<mode>:GPI): Do not expand CONST_INTs.\n        (*movsi_aarch64): Turn into define_insn_and_split and new alternative\n        for 'n'.\n        (*movdi_aarch64): Likewise.\n\nFrom-SVN: r217546", "tree": {"sha": "405852c9f46c6941a9f2aa536cd399b84b7c1478", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/405852c9f46c6941a9f2aa536cd399b84b7c1478"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/8261494856f9478e0393d5bd9be26961d16f266f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8261494856f9478e0393d5bd9be26961d16f266f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8261494856f9478e0393d5bd9be26961d16f266f", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8261494856f9478e0393d5bd9be26961d16f266f/comments", "author": null, "committer": null, "parents": [{"sha": "a7f24614b3c58d03f40d55fe195056dd8423f8f5", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a7f24614b3c58d03f40d55fe195056dd8423f8f5", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a7f24614b3c58d03f40d55fe195056dd8423f8f5"}], "stats": {"total": 426, "additions": 259, "deletions": 167}, "files": [{"sha": "4a200018fc7512a3c9374dfdea29c15b78defb46", "filename": "gcc/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8261494856f9478e0393d5bd9be26961d16f266f/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8261494856f9478e0393d5bd9be26961d16f266f/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=8261494856f9478e0393d5bd9be26961d16f266f", "patch": "@@ -1,3 +1,16 @@\n+2014-11-14  Ramana Radhakrishnan  <ramana.radhakrishnan@arm.com>\n+\n+\tPR target/63724\n+        * config/aarch64/aarch64.c (aarch64_expand_mov_immediate): Split out\n+        numerical immediate handling to...\n+        (aarch64_internal_mov_immediate): ...this. New.\n+        (aarch64_rtx_costs): Use aarch64_internal_mov_immediate.\n+        (aarch64_mov_operand_p): Relax predicate.\n+        * config/aarch64/aarch64.md (mov<mode>:GPI): Do not expand CONST_INTs.\n+        (*movsi_aarch64): Turn into define_insn_and_split and new alternative\n+        for 'n'.\n+        (*movdi_aarch64): Likewise.\n+\n 2014-11-14  Richard Biener  <rguenther@suse.de>\n \n \t* match.pd: Implement more binary patterns exercised by"}, {"sha": "92937bb87b48d0f935c1e1c344a7193d1e8c4538", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 213, "deletions": 151, "changes": 364, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8261494856f9478e0393d5bd9be26961d16f266f/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8261494856f9478e0393d5bd9be26961d16f266f/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=8261494856f9478e0393d5bd9be26961d16f266f", "patch": "@@ -1046,107 +1046,41 @@ aarch64_add_offset (machine_mode mode, rtx temp, rtx reg, HOST_WIDE_INT offset)\n   return plus_constant (mode, reg, offset);\n }\n \n-void\n-aarch64_expand_mov_immediate (rtx dest, rtx imm)\n+static int\n+aarch64_internal_mov_immediate (rtx dest, rtx imm, bool generate,\n+\t\t\t\tmachine_mode mode)\n {\n-  machine_mode mode = GET_MODE (dest);\n   unsigned HOST_WIDE_INT mask;\n   int i;\n   bool first;\n   unsigned HOST_WIDE_INT val;\n   bool subtargets;\n   rtx subtarget;\n   int one_match, zero_match, first_not_ffff_match;\n-\n-  gcc_assert (mode == SImode || mode == DImode);\n-\n-  /* Check on what type of symbol it is.  */\n-  if (GET_CODE (imm) == SYMBOL_REF\n-      || GET_CODE (imm) == LABEL_REF\n-      || GET_CODE (imm) == CONST)\n-    {\n-      rtx mem, base, offset;\n-      enum aarch64_symbol_type sty;\n-\n-      /* If we have (const (plus symbol offset)), separate out the offset\n-\t before we start classifying the symbol.  */\n-      split_const (imm, &base, &offset);\n-\n-      sty = aarch64_classify_symbol (base, SYMBOL_CONTEXT_ADR);\n-      switch (sty)\n-\t{\n-\tcase SYMBOL_FORCE_TO_MEM:\n-\t  if (offset != const0_rtx\n-\t      && targetm.cannot_force_const_mem (mode, imm))\n-\t    {\n-\t      gcc_assert (can_create_pseudo_p ());\n-\t      base = aarch64_force_temporary (mode, dest, base);\n-\t      base = aarch64_add_offset (mode, NULL, base, INTVAL (offset));\n-\t      aarch64_emit_move (dest, base);\n-\t      return;\n-\t    }\n-\t  mem = force_const_mem (ptr_mode, imm);\n-\t  gcc_assert (mem);\n-\t  if (mode != ptr_mode)\n-\t    mem = gen_rtx_ZERO_EXTEND (mode, mem);\n-\t  emit_insn (gen_rtx_SET (VOIDmode, dest, mem));\n-\t  return;\n-\n-        case SYMBOL_SMALL_TLSGD:\n-        case SYMBOL_SMALL_TLSDESC:\n-        case SYMBOL_SMALL_GOTTPREL:\n-\tcase SYMBOL_SMALL_GOT:\n-\tcase SYMBOL_TINY_GOT:\n-\t  if (offset != const0_rtx)\n-\t    {\n-\t      gcc_assert(can_create_pseudo_p ());\n-\t      base = aarch64_force_temporary (mode, dest, base);\n-\t      base = aarch64_add_offset (mode, NULL, base, INTVAL (offset));\n-\t      aarch64_emit_move (dest, base);\n-\t      return;\n-\t    }\n-\t  /* FALLTHRU */\n-\n-        case SYMBOL_SMALL_TPREL:\n-\tcase SYMBOL_SMALL_ABSOLUTE:\n-\tcase SYMBOL_TINY_ABSOLUTE:\n-\t  aarch64_load_symref_appropriately (dest, imm, sty);\n-\t  return;\n-\n-\tdefault:\n-\t  gcc_unreachable ();\n-\t}\n-    }\n+  int num_insns = 0;\n \n   if (CONST_INT_P (imm) && aarch64_move_imm (INTVAL (imm), mode))\n     {\n-      emit_insn (gen_rtx_SET (VOIDmode, dest, imm));\n-      return;\n-    }\n-\n-  if (!CONST_INT_P (imm))\n-    {\n-      if (GET_CODE (imm) == HIGH)\n+      if (generate)\n \temit_insn (gen_rtx_SET (VOIDmode, dest, imm));\n-      else\n-        {\n-\t  rtx mem = force_const_mem (mode, imm);\n-\t  gcc_assert (mem);\n-\t  emit_insn (gen_rtx_SET (VOIDmode, dest, mem));\n-\t}\n-\n-      return;\n+      num_insns++;\n+      return num_insns;\n     }\n \n   if (mode == SImode)\n     {\n       /* We know we can't do this in 1 insn, and we must be able to do it\n \t in two; so don't mess around looking for sequences that don't buy\n \t us anything.  */\n-      emit_insn (gen_rtx_SET (VOIDmode, dest, GEN_INT (INTVAL (imm) & 0xffff)));\n-      emit_insn (gen_insv_immsi (dest, GEN_INT (16),\n-\t\t\t\t GEN_INT ((INTVAL (imm) >> 16) & 0xffff)));\n-      return;\n+      if (generate)\n+\t{\n+\t  emit_insn (gen_rtx_SET (VOIDmode, dest,\n+\t\t\t\t  GEN_INT (INTVAL (imm) & 0xffff)));\n+\t  emit_insn (gen_insv_immsi (dest, GEN_INT (16),\n+\t\t\t\t     GEN_INT ((INTVAL (imm) >> 16) & 0xffff)));\n+\t}\n+      num_insns += 2;\n+      return num_insns;\n     }\n \n   /* Remaining cases are all for DImode.  */\n@@ -1176,11 +1110,15 @@ aarch64_expand_mov_immediate (rtx dest, rtx imm)\n     {\n       /* Set one of the quarters and then insert back into result.  */\n       mask = 0xffffll << first_not_ffff_match;\n-      emit_insn (gen_rtx_SET (VOIDmode, dest, GEN_INT (val | mask)));\n-      emit_insn (gen_insv_immdi (dest, GEN_INT (first_not_ffff_match),\n-\t\t\t\t GEN_INT ((val >> first_not_ffff_match)\n-\t\t\t\t\t  & 0xffff)));\n-      return;\n+      if (generate)\n+\t{\n+\t  emit_insn (gen_rtx_SET (VOIDmode, dest, GEN_INT (val | mask)));\n+\t  emit_insn (gen_insv_immdi (dest, GEN_INT (first_not_ffff_match),\n+\t\t\t\t     GEN_INT ((val >> first_not_ffff_match)\n+\t\t\t\t\t      & 0xffff)));\n+\t}\n+      num_insns += 2;\n+      return num_insns;\n     }\n \n   if (zero_match == 2)\n@@ -1193,42 +1131,55 @@ aarch64_expand_mov_immediate (rtx dest, rtx imm)\n \n       if (aarch64_uimm12_shift (val - (val & mask)))\n \t{\n-\t  subtarget = subtargets ? gen_reg_rtx (DImode) : dest;\n-\n-\t  emit_insn (gen_rtx_SET (VOIDmode, subtarget, GEN_INT (val & mask)));\n-\t  emit_insn (gen_adddi3 (dest, subtarget,\n-\t\t\t\t GEN_INT (val - (val & mask))));\n-\t  return;\n+\t  if (generate)\n+\t    {\n+\t      subtarget = subtargets ? gen_reg_rtx (DImode) : dest;\n+\t      emit_insn (gen_rtx_SET (VOIDmode, subtarget,\n+\t\t\t\t      GEN_INT (val & mask)));\n+\t      emit_insn (gen_adddi3 (dest, subtarget,\n+\t\t\t\t     GEN_INT (val - (val & mask))));\n+\t    }\n+\t  num_insns += 2;\n+\t  return num_insns;\n \t}\n       else if (aarch64_uimm12_shift (-(val - ((val + comp) & mask))))\n \t{\n-\t  subtarget = subtargets ? gen_reg_rtx (DImode) : dest;\n-\n-\t  emit_insn (gen_rtx_SET (VOIDmode, subtarget,\n-\t\t\t\t  GEN_INT ((val + comp) & mask)));\n-\t  emit_insn (gen_adddi3 (dest, subtarget,\n-\t\t\t\t GEN_INT (val - ((val + comp) & mask))));\n-\t  return;\n+\t  if (generate)\n+\t    {\n+\t      subtarget = subtargets ? gen_reg_rtx (DImode) : dest;\n+\t      emit_insn (gen_rtx_SET (VOIDmode, subtarget,\n+\t\t\t\t      GEN_INT ((val + comp) & mask)));\n+\t      emit_insn (gen_adddi3 (dest, subtarget,\n+\t\t\t\t     GEN_INT (val - ((val + comp) & mask))));\n+\t    }\n+\t  num_insns += 2;\n+\t  return num_insns;\n \t}\n       else if (aarch64_uimm12_shift (val - ((val - comp) | ~mask)))\n \t{\n-\t  subtarget = subtargets ? gen_reg_rtx (DImode) : dest;\n-\n-\t  emit_insn (gen_rtx_SET (VOIDmode, subtarget,\n-\t\t\t\t  GEN_INT ((val - comp) | ~mask)));\n-\t  emit_insn (gen_adddi3 (dest, subtarget,\n-\t\t\t\t GEN_INT (val - ((val - comp) | ~mask))));\n-\t  return;\n+\t  if (generate)\n+\t    {\n+\t      subtarget = subtargets ? gen_reg_rtx (DImode) : dest;\n+\t      emit_insn (gen_rtx_SET (VOIDmode, subtarget,\n+\t\t\t\t      GEN_INT ((val - comp) | ~mask)));\n+\t      emit_insn (gen_adddi3 (dest, subtarget,\n+\t\t\t\t     GEN_INT (val - ((val - comp) | ~mask))));\n+\t    }\n+\t  num_insns += 2;\n+\t  return num_insns;\n \t}\n       else if (aarch64_uimm12_shift (-(val - (val | ~mask))))\n \t{\n-\t  subtarget = subtargets ? gen_reg_rtx (DImode) : dest;\n-\n-\t  emit_insn (gen_rtx_SET (VOIDmode, subtarget,\n-\t\t\t\t  GEN_INT (val | ~mask)));\n-\t  emit_insn (gen_adddi3 (dest, subtarget,\n-\t\t\t\t GEN_INT (val - (val | ~mask))));\n-\t  return;\n+\t  if (generate)\n+\t    {\n+\t      subtarget = subtargets ? gen_reg_rtx (DImode) : dest;\n+\t      emit_insn (gen_rtx_SET (VOIDmode, subtarget,\n+\t\t\t\t      GEN_INT (val | ~mask)));\n+\t      emit_insn (gen_adddi3 (dest, subtarget,\n+\t\t\t\t     GEN_INT (val - (val | ~mask))));\n+\t    }\n+\t  num_insns += 2;\n+\t  return num_insns;\n \t}\n     }\n \n@@ -1242,23 +1193,31 @@ aarch64_expand_mov_immediate (rtx dest, rtx imm)\n       if (aarch64_uimm12_shift (val - aarch64_bitmasks[i])\n \t  || aarch64_uimm12_shift (-val + aarch64_bitmasks[i]))\n \t{\n-\t  subtarget = subtargets ? gen_reg_rtx (DImode) : dest;\n-\t  emit_insn (gen_rtx_SET (VOIDmode, subtarget,\n-\t\t\t\t  GEN_INT (aarch64_bitmasks[i])));\n-\t  emit_insn (gen_adddi3 (dest, subtarget,\n-\t\t\t\t GEN_INT (val - aarch64_bitmasks[i])));\n-\t  return;\n+\t  if (generate)\n+\t    {\n+\t      subtarget = subtargets ? gen_reg_rtx (DImode) : dest;\n+\t      emit_insn (gen_rtx_SET (VOIDmode, subtarget,\n+\t\t\t\t      GEN_INT (aarch64_bitmasks[i])));\n+\t      emit_insn (gen_adddi3 (dest, subtarget,\n+\t\t\t\t     GEN_INT (val - aarch64_bitmasks[i])));\n+\t    }\n+\t  num_insns += 2;\n+\t  return num_insns;\n \t}\n \n       for (j = 0; j < 64; j += 16, mask <<= 16)\n \t{\n \t  if ((aarch64_bitmasks[i] & ~mask) == (val & ~mask))\n \t    {\n-\t      emit_insn (gen_rtx_SET (VOIDmode, dest,\n-\t\t\t\t      GEN_INT (aarch64_bitmasks[i])));\n-\t      emit_insn (gen_insv_immdi (dest, GEN_INT (j),\n-\t\t\t\t\t GEN_INT ((val >> j) & 0xffff)));\n-\t      return;\n+\t      if (generate)\n+\t\t{\n+\t\t  emit_insn (gen_rtx_SET (VOIDmode, dest,\n+\t\t\t\t\t  GEN_INT (aarch64_bitmasks[i])));\n+\t\t  emit_insn (gen_insv_immdi (dest, GEN_INT (j),\n+\t\t\t\t\t     GEN_INT ((val >> j) & 0xffff)));\n+\t\t}\n+\t      num_insns += 2;\n+\t      return num_insns;\n \t    }\n \t}\n     }\n@@ -1273,12 +1232,16 @@ aarch64_expand_mov_immediate (rtx dest, rtx imm)\n \t  for (j = i + 1; j < AARCH64_NUM_BITMASKS; j++)\n \t    if (val == (aarch64_bitmasks[i] | aarch64_bitmasks[j]))\n \t      {\n-\t\tsubtarget = subtargets ? gen_reg_rtx (mode) : dest;\n-\t\temit_insn (gen_rtx_SET (VOIDmode, subtarget,\n-\t\t\t\t\tGEN_INT (aarch64_bitmasks[i])));\n-\t\temit_insn (gen_iordi3 (dest, subtarget,\n-\t\t\t\t       GEN_INT (aarch64_bitmasks[j])));\n-\t\treturn;\n+\t\tif (generate)\n+\t\t  {\n+\t\t    subtarget = subtargets ? gen_reg_rtx (mode) : dest;\n+\t\t    emit_insn (gen_rtx_SET (VOIDmode, subtarget,\n+\t\t\t\t\t    GEN_INT (aarch64_bitmasks[i])));\n+\t\t    emit_insn (gen_iordi3 (dest, subtarget,\n+\t\t\t\t\t   GEN_INT (aarch64_bitmasks[j])));\n+\t\t  }\n+\t\tnum_insns += 2;\n+\t\treturn num_insns;\n \t      }\n \t}\n       else if ((val & aarch64_bitmasks[i]) == val)\n@@ -1288,13 +1251,16 @@ aarch64_expand_mov_immediate (rtx dest, rtx imm)\n \t  for (j = i + 1; j < AARCH64_NUM_BITMASKS; j++)\n \t    if (val == (aarch64_bitmasks[j] & aarch64_bitmasks[i]))\n \t      {\n-\n-\t\tsubtarget = subtargets ? gen_reg_rtx (mode) : dest;\n-\t\temit_insn (gen_rtx_SET (VOIDmode, subtarget,\n-\t\t\t\t\tGEN_INT (aarch64_bitmasks[j])));\n-\t\temit_insn (gen_anddi3 (dest, subtarget,\n-\t\t\t\t       GEN_INT (aarch64_bitmasks[i])));\n-\t\treturn;\n+\t\tif (generate)\n+\t\t  {\n+\t\t    subtarget = subtargets ? gen_reg_rtx (mode) : dest;\n+\t\t    emit_insn (gen_rtx_SET (VOIDmode, subtarget,\n+\t\t\t\t\t    GEN_INT (aarch64_bitmasks[j])));\n+\t\t    emit_insn (gen_anddi3 (dest, subtarget,\n+\t\t\t\t\t   GEN_INT (aarch64_bitmasks[i])));\n+\t\t  }\n+\t\tnum_insns += 2;\n+\t\treturn num_insns;\n \t      }\n \t}\n     }\n@@ -1303,18 +1269,24 @@ aarch64_expand_mov_immediate (rtx dest, rtx imm)\n     {\n       /* Set either first three quarters or all but the third.\t */\n       mask = 0xffffll << (16 - first_not_ffff_match);\n-      emit_insn (gen_rtx_SET (VOIDmode, dest,\n-\t\t\t      GEN_INT (val | mask | 0xffffffff00000000ull)));\n+      if (generate)\n+\temit_insn (gen_rtx_SET (VOIDmode, dest,\n+\t\t\t\tGEN_INT (val | mask | 0xffffffff00000000ull)));\n+      num_insns ++;\n \n       /* Now insert other two quarters.\t */\n       for (i = first_not_ffff_match + 16, mask <<= (first_not_ffff_match << 1);\n \t   i < 64; i += 16, mask <<= 16)\n \t{\n \t  if ((val & mask) != mask)\n-\t    emit_insn (gen_insv_immdi (dest, GEN_INT (i),\n-\t\t\t\t       GEN_INT ((val >> i) & 0xffff)));\n+\t    {\n+\t      if (generate)\n+\t\temit_insn (gen_insv_immdi (dest, GEN_INT (i),\n+\t\t\t\t\t   GEN_INT ((val >> i) & 0xffff)));\n+\t      num_insns ++;\n+\t    }\n \t}\n-      return;\n+      return num_insns;\n     }\n \n  simple_sequence:\n@@ -1326,15 +1298,106 @@ aarch64_expand_mov_immediate (rtx dest, rtx imm)\n \t{\n \t  if (first)\n \t    {\n-\t      emit_insn (gen_rtx_SET (VOIDmode, dest,\n-\t\t\t\t      GEN_INT (val & mask)));\n+\t      if (generate)\n+\t\temit_insn (gen_rtx_SET (VOIDmode, dest,\n+\t\t\t\t\tGEN_INT (val & mask)));\n+\t      num_insns ++;\n \t      first = false;\n \t    }\n \t  else\n-\t    emit_insn (gen_insv_immdi (dest, GEN_INT (i),\n-\t\t\t\t       GEN_INT ((val >> i) & 0xffff)));\n+\t    {\n+\t      if (generate)\n+\t\temit_insn (gen_insv_immdi (dest, GEN_INT (i),\n+\t\t\t\t\t   GEN_INT ((val >> i) & 0xffff)));\n+\t      num_insns ++;\n+\t    }\n+\t}\n+    }\n+\n+  return num_insns;\n+}\n+\n+\n+void\n+aarch64_expand_mov_immediate (rtx dest, rtx imm)\n+{\n+  machine_mode mode = GET_MODE (dest);\n+\n+  gcc_assert (mode == SImode || mode == DImode);\n+\n+  /* Check on what type of symbol it is.  */\n+  if (GET_CODE (imm) == SYMBOL_REF\n+      || GET_CODE (imm) == LABEL_REF\n+      || GET_CODE (imm) == CONST)\n+    {\n+      rtx mem, base, offset;\n+      enum aarch64_symbol_type sty;\n+\n+      /* If we have (const (plus symbol offset)), separate out the offset\n+\t before we start classifying the symbol.  */\n+      split_const (imm, &base, &offset);\n+\n+      sty = aarch64_classify_symbol (base, SYMBOL_CONTEXT_ADR);\n+      switch (sty)\n+\t{\n+\tcase SYMBOL_FORCE_TO_MEM:\n+\t  if (offset != const0_rtx\n+\t      && targetm.cannot_force_const_mem (mode, imm))\n+\t    {\n+\t      gcc_assert (can_create_pseudo_p ());\n+\t      base = aarch64_force_temporary (mode, dest, base);\n+\t      base = aarch64_add_offset (mode, NULL, base, INTVAL (offset));\n+\t      aarch64_emit_move (dest, base);\n+\t      return;\n+\t    }\n+\t  mem = force_const_mem (ptr_mode, imm);\n+\t  gcc_assert (mem);\n+\t  if (mode != ptr_mode)\n+\t    mem = gen_rtx_ZERO_EXTEND (mode, mem);\n+\t  emit_insn (gen_rtx_SET (VOIDmode, dest, mem));\n+\t  return;\n+\n+        case SYMBOL_SMALL_TLSGD:\n+        case SYMBOL_SMALL_TLSDESC:\n+        case SYMBOL_SMALL_GOTTPREL:\n+\tcase SYMBOL_SMALL_GOT:\n+\tcase SYMBOL_TINY_GOT:\n+\t  if (offset != const0_rtx)\n+\t    {\n+\t      gcc_assert(can_create_pseudo_p ());\n+\t      base = aarch64_force_temporary (mode, dest, base);\n+\t      base = aarch64_add_offset (mode, NULL, base, INTVAL (offset));\n+\t      aarch64_emit_move (dest, base);\n+\t      return;\n+\t    }\n+\t  /* FALLTHRU */\n+\n+        case SYMBOL_SMALL_TPREL:\n+\tcase SYMBOL_SMALL_ABSOLUTE:\n+\tcase SYMBOL_TINY_ABSOLUTE:\n+\t  aarch64_load_symref_appropriately (dest, imm, sty);\n+\t  return;\n+\n+\tdefault:\n+\t  gcc_unreachable ();\n+\t}\n+    }\n+\n+  if (!CONST_INT_P (imm))\n+    {\n+      if (GET_CODE (imm) == HIGH)\n+\temit_insn (gen_rtx_SET (VOIDmode, dest, imm));\n+      else\n+        {\n+\t  rtx mem = force_const_mem (mode, imm);\n+\t  gcc_assert (mem);\n+\t  emit_insn (gen_rtx_SET (VOIDmode, dest, mem));\n \t}\n+\n+      return;\n     }\n+\n+  aarch64_internal_mov_immediate (dest, imm, true, GET_MODE (dest));\n }\n \n static bool\n@@ -5240,9 +5303,8 @@ aarch64_rtx_costs (rtx x, int code, int outer ATTRIBUTE_UNUSED,\n \t     proportionally expensive to the number of instructions\n \t     required to build that constant.  This is true whether we\n \t     are compiling for SPEED or otherwise.  */\n-\t  *cost = COSTS_N_INSNS (aarch64_build_constant (0,\n-\t\t\t\t\t\t\t INTVAL (x),\n-\t\t\t\t\t\t\t false));\n+\t  *cost = COSTS_N_INSNS (aarch64_internal_mov_immediate\n+\t\t\t\t (NULL_RTX, x, false, mode));\n \t}\n       return true;\n \n@@ -8041,7 +8103,7 @@ aarch64_mov_operand_p (rtx x,\n       && aarch64_valid_symref (XEXP (x, 0), GET_MODE (XEXP (x, 0))))\n     return true;\n \n-  if (CONST_INT_P (x) && aarch64_move_imm (INTVAL (x), mode))\n+  if (CONST_INT_P (x))\n     return true;\n \n   if (GET_CODE (x) == SYMBOL_REF && mode == DImode && CONSTANT_ADDRESS_P (x))"}, {"sha": "142e8b10597e9c2327b03df74203a5b530ec13ec", "filename": "gcc/config/aarch64/aarch64.md", "status": "modified", "additions": 33, "deletions": 16, "changes": 49, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8261494856f9478e0393d5bd9be26961d16f266f/gcc%2Fconfig%2Faarch64%2Faarch64.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8261494856f9478e0393d5bd9be26961d16f266f/gcc%2Fconfig%2Faarch64%2Faarch64.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.md?ref=8261494856f9478e0393d5bd9be26961d16f266f", "patch": "@@ -746,24 +746,28 @@\n     if (GET_CODE (operands[0]) == MEM && operands[1] != const0_rtx)\n       operands[1] = force_reg (<MODE>mode, operands[1]);\n \n-    if (CONSTANT_P (operands[1]))\n-      {\n-\taarch64_expand_mov_immediate (operands[0], operands[1]);\n-\tDONE;\n-      }\n+    /* FIXME: RR we still need to fix up what we are doing with\n+       symbol_refs and other types of constants.  */\n+    if (CONSTANT_P (operands[1])\n+        && !CONST_INT_P (operands[1]))\n+     {\n+       aarch64_expand_mov_immediate (operands[0], operands[1]);\n+       DONE;\n+     }\n   \"\n )\n \n-(define_insn \"*movsi_aarch64\"\n-  [(set (match_operand:SI 0 \"nonimmediate_operand\" \"=r,k,r,r,r,*w,m,  m,r,r  ,*w, r,*w\")\n-\t(match_operand:SI 1 \"aarch64_mov_operand\"  \" r,r,k,M,m, m,rZ,*w,S,Ush,rZ,*w,*w\"))]\n+(define_insn_and_split \"*movsi_aarch64\"\n+  [(set (match_operand:SI 0 \"nonimmediate_operand\" \"=r,k,r,r,r,r,*w,m,  m,r,r  ,*w, r,*w\")\n+\t(match_operand:SI 1 \"aarch64_mov_operand\"  \" r,r,k,M,n,m, m,rZ,*w,S,Ush,rZ,*w,*w\"))]\n   \"(register_operand (operands[0], SImode)\n     || aarch64_reg_or_zero (operands[1], SImode))\"\n   \"@\n    mov\\\\t%w0, %w1\n    mov\\\\t%w0, %w1\n    mov\\\\t%w0, %w1\n    mov\\\\t%w0, %1\n+   #\n    ldr\\\\t%w0, %1\n    ldr\\\\t%s0, %1\n    str\\\\t%w1, %0\n@@ -773,21 +777,28 @@\n    fmov\\\\t%s0, %w1\n    fmov\\\\t%w0, %s1\n    fmov\\\\t%s0, %s1\"\n-  [(set_attr \"type\" \"mov_reg,mov_reg,mov_reg,mov_imm,load1,load1,store1,store1,\\\n+   \"CONST_INT_P (operands[1]) && !aarch64_move_imm (INTVAL (operands[1]), SImode)\"\n+   [(const_int 0)]\n+   \"{\n+       aarch64_expand_mov_immediate (operands[0], operands[1]);\n+       DONE;\n+    }\"\n+  [(set_attr \"type\" \"mov_reg,mov_reg,mov_reg,mov_imm,mov_imm,load1,load1,store1,store1,\\\n                      adr,adr,f_mcr,f_mrc,fmov\")\n-   (set_attr \"fp\" \"*,*,*,*,*,yes,*,yes,*,*,yes,yes,yes\")]\n+   (set_attr \"fp\" \"*,*,*,*,*,*,yes,*,yes,*,*,yes,yes,yes\")]\n )\n \n-(define_insn \"*movdi_aarch64\"\n-  [(set (match_operand:DI 0 \"nonimmediate_operand\" \"=r,k,r,r,r,*w,m,  m,r,r,  *w, r,*w,w\")\n-\t(match_operand:DI 1 \"aarch64_mov_operand\"  \" r,r,k,N,m, m,rZ,*w,S,Ush,rZ,*w,*w,Dd\"))]\n+(define_insn_and_split \"*movdi_aarch64\"\n+  [(set (match_operand:DI 0 \"nonimmediate_operand\" \"=r,k,r,r,r,r,*w,m,  m,r,r,  *w, r,*w,w\")\n+\t(match_operand:DI 1 \"aarch64_mov_operand\"  \" r,r,k,N,n,m, m,rZ,*w,S,Ush,rZ,*w,*w,Dd\"))]\n   \"(register_operand (operands[0], DImode)\n     || aarch64_reg_or_zero (operands[1], DImode))\"\n   \"@\n    mov\\\\t%x0, %x1\n    mov\\\\t%0, %x1\n    mov\\\\t%x0, %1\n    mov\\\\t%x0, %1\n+   #\n    ldr\\\\t%x0, %1\n    ldr\\\\t%d0, %1\n    str\\\\t%x1, %0\n@@ -798,10 +809,16 @@\n    fmov\\\\t%x0, %d1\n    fmov\\\\t%d0, %d1\n    movi\\\\t%d0, %1\"\n-  [(set_attr \"type\" \"mov_reg,mov_reg,mov_reg,mov_imm,load1,load1,store1,store1,\\\n+   \"(CONST_INT_P (operands[1]) && !aarch64_move_imm (INTVAL (operands[1]), DImode))\"\n+   [(const_int 0)]\n+   \"{\n+       aarch64_expand_mov_immediate (operands[0], operands[1]);\n+       DONE;\n+    }\"\n+  [(set_attr \"type\" \"mov_reg,mov_reg,mov_reg,mov_imm,mov_imm,load1,load1,store1,store1,\\\n                      adr,adr,f_mcr,f_mrc,fmov,fmov\")\n-   (set_attr \"fp\" \"*,*,*,*,*,yes,*,yes,*,*,yes,yes,yes,*\")\n-   (set_attr \"simd\" \"*,*,*,*,*,*,*,*,*,*,*,*,*,yes\")]\n+   (set_attr \"fp\" \"*,*,*,*,*,*,yes,*,yes,*,*,yes,yes,yes,*\")\n+   (set_attr \"simd\" \"*,*,*,*,*,*,*,*,*,*,*,*,*,*,yes\")]\n )\n \n (define_insn \"insv_imm<mode>\""}]}