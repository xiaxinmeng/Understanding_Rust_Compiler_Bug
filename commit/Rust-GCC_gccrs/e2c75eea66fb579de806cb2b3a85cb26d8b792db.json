{"sha": "e2c75eea66fb579de806cb2b3a85cb26d8b792db", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTJjNzVlZWE2NmZiNTc5ZGU4MDZjYjJiM2E4NWNiMjZkOGI3OTJkYg==", "commit": {"author": {"name": "James Greenhalgh", "email": "james.greenhalgh@arm.com", "date": "2014-06-06T13:16:40Z"}, "committer": {"name": "James Greenhalgh", "email": "jgreenhalgh@gcc.gnu.org", "date": "2014-06-06T13:16:40Z"}, "message": "[AArch64] Implement movmem for the benefit of inline memcpy\n\ngcc/\n\n\t* config/aarch64/aarch64-protos.h (aarch64_expand_movmem): New.\n\t* config/aarch64/aarch64.c (aarch64_move_pointer): New.\n\t(aarch64_progress_pointer): Likewise.\n\t(aarch64_copy_one_part_and_move_pointers): Likewise.\n\t(aarch64_expand_movmen): Likewise.\n\t* config/aarch64/aarch64.h (MOVE_RATIO): Set low.\n\t* config/aarch64/aarch64.md (movmem<mode>): New.\n\ngcc/testsuite/\n\n\t* gcc.dg/tree-ssa/pr42585.c: Skip for AArch64.\n\t* gcc.dg/tree-ssa/sra-12.c: Likewise.\n\nFrom-SVN: r211314", "tree": {"sha": "9ee38e98bba72e87d2e78b7609c2878f2d926b6c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/9ee38e98bba72e87d2e78b7609c2878f2d926b6c"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e2c75eea66fb579de806cb2b3a85cb26d8b792db", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e2c75eea66fb579de806cb2b3a85cb26d8b792db", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e2c75eea66fb579de806cb2b3a85cb26d8b792db", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e2c75eea66fb579de806cb2b3a85cb26d8b792db/comments", "author": {"login": "jgreenhalgh-arm", "id": 6104025, "node_id": "MDQ6VXNlcjYxMDQwMjU=", "avatar_url": "https://avatars.githubusercontent.com/u/6104025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jgreenhalgh-arm", "html_url": "https://github.com/jgreenhalgh-arm", "followers_url": "https://api.github.com/users/jgreenhalgh-arm/followers", "following_url": "https://api.github.com/users/jgreenhalgh-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jgreenhalgh-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jgreenhalgh-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jgreenhalgh-arm/subscriptions", "organizations_url": "https://api.github.com/users/jgreenhalgh-arm/orgs", "repos_url": "https://api.github.com/users/jgreenhalgh-arm/repos", "events_url": "https://api.github.com/users/jgreenhalgh-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jgreenhalgh-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "4ed689957552caedec3c15251a126b2074bd1df2", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4ed689957552caedec3c15251a126b2074bd1df2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4ed689957552caedec3c15251a126b2074bd1df2"}], "stats": {"total": 210, "additions": 202, "deletions": 8}, "files": [{"sha": "9d2e20129a664cfc7a8742af6bb83158bbf5df05", "filename": "gcc/ChangeLog", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=e2c75eea66fb579de806cb2b3a85cb26d8b792db", "patch": "@@ -1,3 +1,13 @@\n+2014-06-06  James Greenhalgh  <james.greenhalgh@arm.com>\n+\n+\t* config/aarch64/aarch64-protos.h (aarch64_expand_movmem): New.\n+\t* config/aarch64/aarch64.c (aarch64_move_pointer): New.\n+\t(aarch64_progress_pointer): Likewise.\n+\t(aarch64_copy_one_part_and_move_pointers): Likewise.\n+\t(aarch64_expand_movmen): Likewise.\n+\t* config/aarch64/aarch64.h (MOVE_RATIO): Set low.\n+\t* config/aarch64/aarch64.md (movmem<mode>): New.\n+\n 2014-06-06  Bingfeng Mei  <bmei@broadcom.com>\n \n \t* targhooks.c (default_add_stmt_cost): Call target specific"}, {"sha": "c4f75b36a173a11b09120b8943da40c7e1eee9f5", "filename": "gcc/config/aarch64/aarch64-protos.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h?ref=e2c75eea66fb579de806cb2b3a85cb26d8b792db", "patch": "@@ -180,6 +180,7 @@ bool aarch64_cannot_change_mode_class (enum machine_mode,\n enum aarch64_symbol_type\n aarch64_classify_symbolic_expression (rtx, enum aarch64_symbol_context);\n bool aarch64_constant_address_p (rtx);\n+bool aarch64_expand_movmem (rtx *);\n bool aarch64_float_const_zero_rtx_p (rtx);\n bool aarch64_function_arg_regno_p (unsigned);\n bool aarch64_gen_movmemqi (rtx *);"}, {"sha": "a8b1523a838660653a83848e5646e3f779088185", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 158, "deletions": 0, "changes": 158, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=e2c75eea66fb579de806cb2b3a85cb26d8b792db", "patch": "@@ -9409,6 +9409,164 @@ aarch64_modes_tieable_p (enum machine_mode mode1, enum machine_mode mode2)\n   return false;\n }\n \n+/* Return a new RTX holding the result of moving POINTER forward by\n+   AMOUNT bytes.  */\n+\n+static rtx\n+aarch64_move_pointer (rtx pointer, int amount)\n+{\n+  rtx next = plus_constant (Pmode, XEXP (pointer, 0), amount);\n+\n+  return adjust_automodify_address (pointer, GET_MODE (pointer),\n+\t\t\t\t    next, amount);\n+}\n+\n+/* Return a new RTX holding the result of moving POINTER forward by the\n+   size of the mode it points to.  */\n+\n+static rtx\n+aarch64_progress_pointer (rtx pointer)\n+{\n+  HOST_WIDE_INT amount = GET_MODE_SIZE (GET_MODE (pointer));\n+\n+  return aarch64_move_pointer (pointer, amount);\n+}\n+\n+/* Copy one MODE sized block from SRC to DST, then progress SRC and DST by\n+   MODE bytes.  */\n+\n+static void\n+aarch64_copy_one_block_and_progress_pointers (rtx *src, rtx *dst,\n+\t\t\t\t\t      enum machine_mode mode)\n+{\n+  rtx reg = gen_reg_rtx (mode);\n+\n+  /* \"Cast\" the pointers to the correct mode.  */\n+  *src = adjust_address (*src, mode, 0);\n+  *dst = adjust_address (*dst, mode, 0);\n+  /* Emit the memcpy.  */\n+  emit_move_insn (reg, *src);\n+  emit_move_insn (*dst, reg);\n+  /* Move the pointers forward.  */\n+  *src = aarch64_progress_pointer (*src);\n+  *dst = aarch64_progress_pointer (*dst);\n+}\n+\n+/* Expand movmem, as if from a __builtin_memcpy.  Return true if\n+   we succeed, otherwise return false.  */\n+\n+bool\n+aarch64_expand_movmem (rtx *operands)\n+{\n+  unsigned int n;\n+  rtx dst = operands[0];\n+  rtx src = operands[1];\n+  rtx base;\n+  bool speed_p = !optimize_function_for_size_p (cfun);\n+\n+  /* When optimizing for size, give a better estimate of the length of a\n+     memcpy call, but use the default otherwise.  */\n+  unsigned int max_instructions = (speed_p ? 15 : AARCH64_CALL_RATIO) / 2;\n+\n+  /* We can't do anything smart if the amount to copy is not constant.  */\n+  if (!CONST_INT_P (operands[2]))\n+    return false;\n+\n+  n = UINTVAL (operands[2]);\n+\n+  /* Try to keep the number of instructions low.  For cases below 16 bytes we\n+     need to make at most two moves.  For cases above 16 bytes it will be one\n+     move for each 16 byte chunk, then at most two additional moves.  */\n+  if (((n / 16) + (n % 16 ? 2 : 0)) > max_instructions)\n+    return false;\n+\n+  base = copy_to_mode_reg (Pmode, XEXP (dst, 0));\n+  dst = adjust_automodify_address (dst, VOIDmode, base, 0);\n+\n+  base = copy_to_mode_reg (Pmode, XEXP (src, 0));\n+  src = adjust_automodify_address (src, VOIDmode, base, 0);\n+\n+  /* Simple cases.  Copy 0-3 bytes, as (if applicable) a 2-byte, then a\n+     1-byte chunk.  */\n+  if (n < 4)\n+    {\n+      if (n >= 2)\n+\t{\n+\t  aarch64_copy_one_block_and_progress_pointers (&src, &dst, HImode);\n+\t  n -= 2;\n+\t}\n+\n+      if (n == 1)\n+\taarch64_copy_one_block_and_progress_pointers (&src, &dst, QImode);\n+\n+      return true;\n+    }\n+\n+  /* Copy 4-8 bytes.  First a 4-byte chunk, then (if applicable) a second\n+     4-byte chunk, partially overlapping with the previously copied chunk.  */\n+  if (n < 8)\n+    {\n+      aarch64_copy_one_block_and_progress_pointers (&src, &dst, SImode);\n+      n -= 4;\n+      if (n > 0)\n+\t{\n+\t  int move = n - 4;\n+\n+\t  src = aarch64_move_pointer (src, move);\n+\t  dst = aarch64_move_pointer (dst, move);\n+\t  aarch64_copy_one_block_and_progress_pointers (&src, &dst, SImode);\n+\t}\n+      return true;\n+    }\n+\n+  /* Copy more than 8 bytes.  Copy chunks of 16 bytes until we run out of\n+     them, then (if applicable) an 8-byte chunk.  */\n+  while (n >= 8)\n+    {\n+      if (n / 16)\n+\t{\n+\t  aarch64_copy_one_block_and_progress_pointers (&src, &dst, TImode);\n+\t  n -= 16;\n+\t}\n+      else\n+\t{\n+\t  aarch64_copy_one_block_and_progress_pointers (&src, &dst, DImode);\n+\t  n -= 8;\n+\t}\n+    }\n+\n+  /* Finish the final bytes of the copy.  We can always do this in one\n+     instruction.  We either copy the exact amount we need, or partially\n+     overlap with the previous chunk we copied and copy 8-bytes.  */\n+  if (n == 0)\n+    return true;\n+  else if (n == 1)\n+    aarch64_copy_one_block_and_progress_pointers (&src, &dst, QImode);\n+  else if (n == 2)\n+    aarch64_copy_one_block_and_progress_pointers (&src, &dst, HImode);\n+  else if (n == 4)\n+    aarch64_copy_one_block_and_progress_pointers (&src, &dst, SImode);\n+  else\n+    {\n+      if (n == 3)\n+\t{\n+\t  src = aarch64_move_pointer (src, -1);\n+\t  dst = aarch64_move_pointer (dst, -1);\n+\t  aarch64_copy_one_block_and_progress_pointers (&src, &dst, SImode);\n+\t}\n+      else\n+\t{\n+\t  int move = n - 8;\n+\n+\t  src = aarch64_move_pointer (src, move);\n+\t  dst = aarch64_move_pointer (dst, move);\n+\t  aarch64_copy_one_block_and_progress_pointers (&src, &dst, DImode);\n+\t}\n+    }\n+\n+  return true;\n+}\n+\n #undef TARGET_ADDRESS_COST\n #define TARGET_ADDRESS_COST aarch64_address_cost\n "}, {"sha": "a191162daf8d25f1cd8c40560b69236941fb0267", "filename": "gcc/config/aarch64/aarch64.h", "status": "modified", "additions": 7, "deletions": 5, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2Fconfig%2Faarch64%2Faarch64.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2Fconfig%2Faarch64%2Faarch64.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.h?ref=e2c75eea66fb579de806cb2b3a85cb26d8b792db", "patch": "@@ -672,12 +672,14 @@ do {\t\t\t\t\t\t\t\t\t     \\\n /* The base cost overhead of a memcpy call, for MOVE_RATIO and friends.  */\n #define AARCH64_CALL_RATIO 8\n \n-/* When optimizing for size, give a better estimate of the length of a memcpy\n-   call, but use the default otherwise.  But move_by_pieces_ninsns() counts\n-   memory-to-memory moves, and we'll have to generate a load & store for each,\n-   so halve the value to take that into account.  */\n+/* MOVE_RATIO dictates when we will use the move_by_pieces infrastructure.\n+   move_by_pieces will continually copy the largest safe chunks.  So a\n+   7-byte copy is a 4-byte + 2-byte + byte copy.  This proves inefficient\n+   for both size and speed of copy, so we will instead use the \"movmem\"\n+   standard name to implement the copy.  This logic does not apply when\n+   targeting -mstrict-align, so keep a sensible default in that case.  */\n #define MOVE_RATIO(speed) \\\n-  (((speed) ? 15 : AARCH64_CALL_RATIO) / 2)\n+  (!STRICT_ALIGNMENT ? 2 : (((speed) ? 15 : AARCH64_CALL_RATIO) / 2))\n \n /* For CLEAR_RATIO, when optimizing for size, give a better estimate\n    of the length of a memset call, but use the default otherwise.  */"}, {"sha": "661d784b93e60fd2f636f5b5f03c10c6d53493dd", "filename": "gcc/config/aarch64/aarch64.md", "status": "modified", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2Fconfig%2Faarch64%2Faarch64.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2Fconfig%2Faarch64%2Faarch64.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.md?ref=e2c75eea66fb579de806cb2b3a85cb26d8b792db", "patch": "@@ -883,6 +883,24 @@\n   }\n )\n \n+;; 0 is dst\n+;; 1 is src\n+;; 2 is size of move in bytes\n+;; 3 is alignment\n+\n+(define_expand \"movmemdi\"\n+  [(match_operand:BLK 0 \"memory_operand\")\n+   (match_operand:BLK 1 \"memory_operand\")\n+   (match_operand:DI 2 \"immediate_operand\")\n+   (match_operand:DI 3 \"immediate_operand\")]\n+   \"!STRICT_ALIGNMENT\"\n+{\n+  if (aarch64_expand_movmem (operands))\n+    DONE;\n+  FAIL;\n+}\n+)\n+\n ;; Operands 1 and 3 are tied together by the final condition; so we allow\n ;; fairly lax checking on the second memory operation.\n (define_insn \"load_pair<mode>\""}, {"sha": "d616616b545aae406f64bc3cfb5fcc6e7ff190f7", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=e2c75eea66fb579de806cb2b3a85cb26d8b792db", "patch": "@@ -1,3 +1,8 @@\n+2014-06-06  James Greenhalgh  <james.greenhalgh@arm.com>\n+\n+\t* gcc.dg/tree-ssa/pr42585.c: Skip for AArch64.\n+\t* gcc.dg/tree-ssa/sra-12.c: Likewise.\n+\n 2014-06-06  Thomas Preud'homme  <thomas.preudhomme@arm.com>\n \n \t* gcc.c-torture/execute/bswap-2.c: Add alignment constraints to"}, {"sha": "07f575db15767acb32da8712ce876f7ba19d8591", "filename": "gcc/testsuite/gcc.dg/tree-ssa/pr42585.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr42585.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr42585.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr42585.c?ref=e2c75eea66fb579de806cb2b3a85cb26d8b792db", "patch": "@@ -35,6 +35,6 @@ Cyc_string_ungetc (int ignore, struct _fat_ptr *sptr)\n /* Whether the structs are totally scalarized or not depends on the\n    MOVE_RATIO macro definition in the back end.  The scalarization will\n    not take place when using small values for MOVE_RATIO.  */\n-/* { dg-final { scan-tree-dump-times \"struct _fat_ptr _ans\" 0 \"optimized\" { target { ! \"arm*-*-* avr-*-* nds32*-*-* powerpc*-*-* s390*-*-* sh*-*-*\" } } } } */\n-/* { dg-final { scan-tree-dump-times \"struct _fat_ptr _T2\" 0 \"optimized\" { target { ! \"arm*-*-* avr-*-* nds32*-*-* powerpc*-*-* s390*-*-* sh*-*-*\" } } } } */\n+/* { dg-final { scan-tree-dump-times \"struct _fat_ptr _ans\" 0 \"optimized\" { target { ! \"aarch64*-*-* arm*-*-* avr-*-* nds32*-*-* powerpc*-*-* s390*-*-* sh*-*-*\" } } } } */\n+/* { dg-final { scan-tree-dump-times \"struct _fat_ptr _T2\" 0 \"optimized\" { target { ! \"aarch64*-*-* arm*-*-* avr-*-* nds32*-*-* powerpc*-*-* s390*-*-* sh*-*-*\" } } } } */\n /* { dg-final { cleanup-tree-dump \"optimized\" } } */"}, {"sha": "45aa9631d8b6dddbf4ff2d7fef6994b4cd41a472", "filename": "gcc/testsuite/gcc.dg/tree-ssa/sra-12.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fsra-12.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2c75eea66fb579de806cb2b3a85cb26d8b792db/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fsra-12.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fsra-12.c?ref=e2c75eea66fb579de806cb2b3a85cb26d8b792db", "patch": "@@ -21,5 +21,5 @@ int foo (struct S *p)\n   *p = l;\n }\n \n-/* { dg-final { scan-tree-dump-times \"l;\" 0 \"release_ssa\" { target { ! \"avr*-*-* nds32*-*-*\" } } } } */\n+/* { dg-final { scan-tree-dump-times \"l;\" 0 \"release_ssa\" { target { ! \"aarch64*-*-* avr*-*-* nds32*-*-*\" } } } } */\n /* { dg-final { cleanup-tree-dump \"release_ssa\" } } */"}]}