{"sha": "779aea46cc3b6b1a62f989ee0c04e68803733ba0", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Nzc5YWVhNDZjYzNiNmIxYTYyZjk4OWVlMGMwNGU2ODgwMzczM2JhMA==", "commit": {"author": {"name": "James Greenhalgh", "email": "james.greenhalgh@arm.com", "date": "2013-09-16T09:50:21Z"}, "committer": {"name": "James Greenhalgh", "email": "jgreenhalgh@gcc.gnu.org", "date": "2013-09-16T09:50:21Z"}, "message": "[AArch64] Implement vmul<q>_lane<q>_<fsu><16,32,64> intrinsics in C\n\ngcc/\n\t* config/aarch64/aarch64-simd.md (aarch64_mul3_elt<mode>): New.\n\t(aarch64_mul3_elt_<vswap_width_name><mode>): Likewise.\n\t(aarch64_mul3_elt_to_128df): Likewise.\n\t(aarch64_mul3_elt_to_64v2df): Likewise.\n\t* config/aarch64/iterators.md (VEL): Also handle DFmode.\n\t(VMUL): New.\n\t(VMUL_CHANGE_NLANES) Likewise.\n\t(h_con): Likewise.\n\t(f): Likewise.\n\t* config/aarch64/arm_neon.h\n\t(vmul<q>_lane<q>_<suf><16,32,64>): Convert to C implementation.\n\ngcc/testsuite/\n\t* gcc.target/aarch64/mul_intrinsic_1.c: New.\n\t* gcc.target/aarch64/fmul_intrinsic_1.c: Likewise.\n\nFrom-SVN: r202624", "tree": {"sha": "4d1dcfabd30aa74d7ff264150aab3706bc9769e6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/4d1dcfabd30aa74d7ff264150aab3706bc9769e6"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/779aea46cc3b6b1a62f989ee0c04e68803733ba0", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/779aea46cc3b6b1a62f989ee0c04e68803733ba0", "html_url": "https://github.com/Rust-GCC/gccrs/commit/779aea46cc3b6b1a62f989ee0c04e68803733ba0", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/779aea46cc3b6b1a62f989ee0c04e68803733ba0/comments", "author": {"login": "jgreenhalgh-arm", "id": 6104025, "node_id": "MDQ6VXNlcjYxMDQwMjU=", "avatar_url": "https://avatars.githubusercontent.com/u/6104025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jgreenhalgh-arm", "html_url": "https://github.com/jgreenhalgh-arm", "followers_url": "https://api.github.com/users/jgreenhalgh-arm/followers", "following_url": "https://api.github.com/users/jgreenhalgh-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jgreenhalgh-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jgreenhalgh-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jgreenhalgh-arm/subscriptions", "organizations_url": "https://api.github.com/users/jgreenhalgh-arm/orgs", "repos_url": "https://api.github.com/users/jgreenhalgh-arm/repos", "events_url": "https://api.github.com/users/jgreenhalgh-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jgreenhalgh-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "a407a750a7578c3c1ab9881b032f008c7be99684", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a407a750a7578c3c1ab9881b032f008c7be99684", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a407a750a7578c3c1ab9881b032f008c7be99684"}], "stats": {"total": 733, "additions": 446, "deletions": 287}, "files": [{"sha": "aaab5ece33576b6266f3ca185b6acb9c4d1e44e2", "filename": "gcc/ChangeLog", "status": "modified", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/779aea46cc3b6b1a62f989ee0c04e68803733ba0/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/779aea46cc3b6b1a62f989ee0c04e68803733ba0/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=779aea46cc3b6b1a62f989ee0c04e68803733ba0", "patch": "@@ -1,3 +1,17 @@\n+2013-09-16  James Greenhalgh  <james.greenhalgh@arm.com>\n+\n+\t* config/aarch64/aarch64-simd.md (aarch64_mul3_elt<mode>): New.\n+\t(aarch64_mul3_elt_<vswap_width_name><mode>): Likewise.\n+\t(aarch64_mul3_elt_to_128df): Likewise.\n+\t(aarch64_mul3_elt_to_64v2df): Likewise.\n+\t* config/aarch64/iterators.md (VEL): Also handle DFmode.\n+\t(VMUL): New.\n+\t(VMUL_CHANGE_NLANES) Likewise.\n+\t(h_con): Likewise.\n+\t(f): Likewise.\n+\t* config/aarch64/arm_neon.h\n+\t(vmul<q>_lane<q>_<suf><16,32,64>): Convert to C implementation.\n+\n 2013-09-16  James Greenhalgh  <james.greenhalgh@arm.com>\n \n \t* config/aarch64/arm_neon.h"}, {"sha": "04d5794ffcae73a8b33844f3147e4315747deb69", "filename": "gcc/config/aarch64/aarch64-simd.md", "status": "modified", "additions": 53, "deletions": 0, "changes": 53, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/779aea46cc3b6b1a62f989ee0c04e68803733ba0/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/779aea46cc3b6b1a62f989ee0c04e68803733ba0/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md?ref=779aea46cc3b6b1a62f989ee0c04e68803733ba0", "patch": "@@ -582,6 +582,59 @@\n    (set_attr \"simd_mode\" \"<MODE>\")]\n )\n \n+(define_insn \"*aarch64_mul3_elt<mode>\"\n+ [(set (match_operand:VMUL 0 \"register_operand\" \"=w\")\n+    (mult:VMUL\n+      (vec_duplicate:VMUL\n+\t  (vec_select:<VEL>\n+\t    (match_operand:VMUL 1 \"register_operand\" \"<h_con>\")\n+\t    (parallel [(match_operand:SI 2 \"immediate_operand\")])))\n+      (match_operand:VMUL 3 \"register_operand\" \"w\")))]\n+  \"TARGET_SIMD\"\n+  \"<f>mul\\\\t%0.<Vtype>, %3.<Vtype>, %1.<Vetype>[%2]\"\n+  [(set_attr \"simd_type\" \"simd_<f>mul_elt\")\n+   (set_attr \"simd_mode\" \"<MODE>\")]\n+)\n+\n+(define_insn \"*aarch64_mul3_elt_<vswap_width_name><mode>\"\n+  [(set (match_operand:VMUL_CHANGE_NLANES 0 \"register_operand\" \"=w\")\n+     (mult:VMUL_CHANGE_NLANES\n+       (vec_duplicate:VMUL_CHANGE_NLANES\n+\t  (vec_select:<VEL>\n+\t    (match_operand:<VSWAP_WIDTH> 1 \"register_operand\" \"<h_con>\")\n+\t    (parallel [(match_operand:SI 2 \"immediate_operand\")])))\n+      (match_operand:VMUL_CHANGE_NLANES 3 \"register_operand\" \"w\")))]\n+  \"TARGET_SIMD\"\n+  \"<f>mul\\\\t%0.<Vtype>, %3.<Vtype>, %1.<Vetype>[%2]\"\n+  [(set_attr \"simd_type\" \"simd_<f>mul_elt\")\n+   (set_attr \"simd_mode\" \"<MODE>\")]\n+)\n+\n+(define_insn \"*aarch64_mul3_elt_to_128df\"\n+  [(set (match_operand:V2DF 0 \"register_operand\" \"=w\")\n+     (mult:V2DF\n+       (vec_duplicate:V2DF\n+\t (match_operand:DF 2 \"register_operand\" \"w\"))\n+      (match_operand:V2DF 1 \"register_operand\" \"w\")))]\n+  \"TARGET_SIMD\"\n+  \"fmul\\\\t%0.2d, %1.2d, %2.d[0]\"\n+  [(set_attr \"simd_type\" \"simd_fmul_elt\")\n+   (set_attr \"simd_mode\" \"V2DF\")]\n+)\n+\n+(define_insn \"*aarch64_mul3_elt_to_64v2df\"\n+  [(set (match_operand:DF 0 \"register_operand\" \"=w\")\n+     (mult:DF\n+       (vec_select:DF\n+\t (match_operand:V2DF 1 \"register_operand\" \"w\")\n+\t (parallel [(match_operand:SI 2 \"immediate_operand\")]))\n+       (match_operand:DF 3 \"register_operand\" \"w\")))]\n+  \"TARGET_SIMD\"\n+  \"fmul\\\\t%0.2d, %3.2d, %1.d[%2]\"\n+  [(set_attr \"simd_type\" \"simd_fmul_elt\")\n+   (set_attr \"simd_mode\" \"V2DF\")]\n+)\n+\n (define_insn \"neg<mode>2\"\n   [(set (match_operand:VDQ 0 \"register_operand\" \"=w\")\n \t(neg:VDQ (match_operand:VDQ 1 \"register_operand\" \"w\")))]"}, {"sha": "6c9dd79a69508139bfb09631941396aa042a05cc", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 152, "deletions": 286, "changes": 438, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/779aea46cc3b6b1a62f989ee0c04e68803733ba0/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/779aea46cc3b6b1a62f989ee0c04e68803733ba0/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=779aea46cc3b6b1a62f989ee0c04e68803733ba0", "patch": "@@ -9501,136 +9501,6 @@ vmovq_n_u64 (uint64_t a)\n   return result;\n }\n \n-#define vmul_lane_f32(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       float32x2_t b_ = (b);                                            \\\n-       float32x2_t a_ = (a);                                            \\\n-       float32x2_t result;                                              \\\n-       __asm__ (\"fmul %0.2s,%1.2s,%2.s[%3]\"                             \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmul_lane_s16(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int16x4_t b_ = (b);                                              \\\n-       int16x4_t a_ = (a);                                              \\\n-       int16x4_t result;                                                \\\n-       __asm__ (\"mul %0.4h,%1.4h,%2.h[%3]\"                              \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmul_lane_s32(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int32x2_t b_ = (b);                                              \\\n-       int32x2_t a_ = (a);                                              \\\n-       int32x2_t result;                                                \\\n-       __asm__ (\"mul %0.2s,%1.2s,%2.s[%3]\"                              \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmul_lane_u16(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint16x4_t b_ = (b);                                             \\\n-       uint16x4_t a_ = (a);                                             \\\n-       uint16x4_t result;                                               \\\n-       __asm__ (\"mul %0.4h,%1.4h,%2.h[%3]\"                              \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmul_lane_u32(a, b, c)                                          \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint32x2_t b_ = (b);                                             \\\n-       uint32x2_t a_ = (a);                                             \\\n-       uint32x2_t result;                                               \\\n-       __asm__ (\"mul %0.2s, %1.2s, %2.s[%3]\"                            \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmul_laneq_f32(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       float32x4_t b_ = (b);                                            \\\n-       float32x2_t a_ = (a);                                            \\\n-       float32x2_t result;                                              \\\n-       __asm__ (\"fmul %0.2s, %1.2s, %2.s[%3]\"                           \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmul_laneq_s16(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int16x8_t b_ = (b);                                              \\\n-       int16x4_t a_ = (a);                                              \\\n-       int16x4_t result;                                                \\\n-       __asm__ (\"mul %0.4h, %1.4h, %2.h[%3]\"                            \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmul_laneq_s32(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int32x4_t b_ = (b);                                              \\\n-       int32x2_t a_ = (a);                                              \\\n-       int32x2_t result;                                                \\\n-       __asm__ (\"mul %0.2s, %1.2s, %2.s[%3]\"                            \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmul_laneq_u16(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint16x8_t b_ = (b);                                             \\\n-       uint16x4_t a_ = (a);                                             \\\n-       uint16x4_t result;                                               \\\n-       __asm__ (\"mul %0.4h, %1.4h, %2.h[%3]\"                            \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmul_laneq_u32(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint32x4_t b_ = (b);                                             \\\n-       uint32x2_t a_ = (a);                                             \\\n-       uint32x2_t result;                                               \\\n-       __asm__ (\"mul %0.2s, %1.2s, %2.s[%3]\"                            \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vmul_n_f32 (float32x2_t a, float32_t b)\n {\n@@ -10149,162 +10019,6 @@ vmull_u32 (uint32x2_t a, uint32x2_t b)\n   return result;\n }\n \n-#define vmulq_lane_f32(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       float32x2_t b_ = (b);                                            \\\n-       float32x4_t a_ = (a);                                            \\\n-       float32x4_t result;                                              \\\n-       __asm__ (\"fmul %0.4s, %1.4s, %2.s[%3]\"                           \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmulq_lane_f64(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       float64x1_t b_ = (b);                                            \\\n-       float64x2_t a_ = (a);                                            \\\n-       float64x2_t result;                                              \\\n-       __asm__ (\"fmul %0.2d,%1.2d,%2.d[%3]\"                             \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmulq_lane_s16(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int16x4_t b_ = (b);                                              \\\n-       int16x8_t a_ = (a);                                              \\\n-       int16x8_t result;                                                \\\n-       __asm__ (\"mul %0.8h,%1.8h,%2.h[%3]\"                              \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"x\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmulq_lane_s32(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int32x2_t b_ = (b);                                              \\\n-       int32x4_t a_ = (a);                                              \\\n-       int32x4_t result;                                                \\\n-       __asm__ (\"mul %0.4s,%1.4s,%2.s[%3]\"                              \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmulq_lane_u16(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint16x4_t b_ = (b);                                             \\\n-       uint16x8_t a_ = (a);                                             \\\n-       uint16x8_t result;                                               \\\n-       __asm__ (\"mul %0.8h,%1.8h,%2.h[%3]\"                              \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"x\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmulq_lane_u32(a, b, c)                                         \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint32x2_t b_ = (b);                                             \\\n-       uint32x4_t a_ = (a);                                             \\\n-       uint32x4_t result;                                               \\\n-       __asm__ (\"mul %0.4s, %1.4s, %2.s[%3]\"                            \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmulq_laneq_f32(a, b, c)                                        \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       float32x4_t b_ = (b);                                            \\\n-       float32x4_t a_ = (a);                                            \\\n-       float32x4_t result;                                              \\\n-       __asm__ (\"fmul %0.4s, %1.4s, %2.s[%3]\"                           \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmulq_laneq_f64(a, b, c)                                        \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       float64x2_t b_ = (b);                                            \\\n-       float64x2_t a_ = (a);                                            \\\n-       float64x2_t result;                                              \\\n-       __asm__ (\"fmul %0.2d,%1.2d,%2.d[%3]\"                             \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmulq_laneq_s16(a, b, c)                                        \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int16x8_t b_ = (b);                                              \\\n-       int16x8_t a_ = (a);                                              \\\n-       int16x8_t result;                                                \\\n-       __asm__ (\"mul %0.8h, %1.8h, %2.h[%3]\"                            \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"x\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmulq_laneq_s32(a, b, c)                                        \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int32x4_t b_ = (b);                                              \\\n-       int32x4_t a_ = (a);                                              \\\n-       int32x4_t result;                                                \\\n-       __asm__ (\"mul %0.4s, %1.4s, %2.s[%3]\"                            \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmulq_laneq_u16(a, b, c)                                        \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint16x8_t b_ = (b);                                             \\\n-       uint16x8_t a_ = (a);                                             \\\n-       uint16x8_t result;                                               \\\n-       __asm__ (\"mul %0.8h, %1.8h, %2.h[%3]\"                            \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"x\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vmulq_laneq_u32(a, b, c)                                        \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint32x4_t b_ = (b);                                             \\\n-       uint32x4_t a_ = (a);                                             \\\n-       uint32x4_t result;                                               \\\n-       __asm__ (\"mul %0.4s, %1.4s, %2.s[%3]\"                            \\\n-                : \"=w\"(result)                                          \\\n-                : \"w\"(a_), \"w\"(b_), \"i\"(c)                              \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n __extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n vmulq_n_f32 (float32x4_t a, float32_t b)\n {\n@@ -21435,6 +21149,158 @@ vmlsq_f64 (float64x2_t a, float64x2_t b, float64x2_t c)\n   return a - b * c;\n }\n \n+/* vmul_lane  */\n+\n+__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n+vmul_lane_f32 (float32x2_t __a, float32x2_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vget_lane_f32 (__b, __lane);\n+}\n+\n+__extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n+vmul_lane_f64 (float64x1_t __a, float64x1_t __b, const int __lane)\n+{\n+  return __a * __b;\n+}\n+\n+__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n+vmul_lane_s16 (int16x4_t __a, int16x4_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vget_lane_s16 (__b, __lane);\n+}\n+\n+__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n+vmul_lane_s32 (int32x2_t __a, int32x2_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vget_lane_s32 (__b, __lane);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vmul_lane_u16 (uint16x4_t __a, uint16x4_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vget_lane_u16 (__b, __lane);\n+}\n+\n+__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n+vmul_lane_u32 (uint32x2_t __a, uint32x2_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vget_lane_u32 (__b, __lane);\n+}\n+\n+/* vmul_laneq  */\n+\n+__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n+vmul_laneq_f32 (float32x2_t __a, float32x4_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vgetq_lane_f32 (__b, __lane);\n+}\n+\n+__extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n+vmul_laneq_f64 (float64x1_t __a, float64x2_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vgetq_lane_f64 (__b, __lane);\n+}\n+\n+__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n+vmul_laneq_s16 (int16x4_t __a, int16x8_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vgetq_lane_s16 (__b, __lane);\n+}\n+\n+__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n+vmul_laneq_s32 (int32x2_t __a, int32x4_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vgetq_lane_s32 (__b, __lane);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vmul_laneq_u16 (uint16x4_t __a, uint16x8_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vgetq_lane_u16 (__b, __lane);\n+}\n+\n+__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n+vmul_laneq_u32 (uint32x2_t __a, uint32x4_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vgetq_lane_u32 (__b, __lane);\n+}\n+\n+/* vmulq_lane  */\n+\n+__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n+vmulq_lane_f32 (float32x4_t __a, float32x2_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vget_lane_f32 (__b, __lane);\n+}\n+\n+__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n+vmulq_lane_f64 (float64x2_t __a, float64x1_t __b, const int __lane)\n+{\n+  return __a * __b;\n+}\n+\n+__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n+vmulq_lane_s16 (int16x8_t __a, int16x4_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vget_lane_s16 (__b, __lane);\n+}\n+\n+__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n+vmulq_lane_s32 (int32x4_t __a, int32x2_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vget_lane_s32 (__b, __lane);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vmulq_lane_u16 (uint16x8_t __a, uint16x4_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vget_lane_u16 (__b, __lane);\n+}\n+\n+__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n+vmulq_lane_u32 (uint32x4_t __a, uint32x2_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vget_lane_u32 (__b, __lane);\n+}\n+\n+/* vmulq_laneq  */\n+\n+__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n+vmulq_laneq_f32 (float32x4_t __a, float32x4_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vgetq_lane_f32 (__b, __lane);\n+}\n+\n+__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n+vmulq_laneq_f64 (float64x2_t __a, float64x2_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vgetq_lane_f64 (__b, __lane);\n+}\n+\n+__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n+vmulq_laneq_s16 (int16x8_t __a, int16x8_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vgetq_lane_s16 (__b, __lane);\n+}\n+\n+__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n+vmulq_laneq_s32 (int32x4_t __a, int32x4_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vgetq_lane_s32 (__b, __lane);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vmulq_laneq_u16 (uint16x8_t __a, uint16x8_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vgetq_lane_u16 (__b, __lane);\n+}\n+\n+__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n+vmulq_laneq_u32 (uint32x4_t __a, uint32x4_t __b, const int __lane)\n+{\n+  return __a * __aarch64_vgetq_lane_u32 (__b, __lane);\n+}\n+\n /* vqabs */\n \n __extension__ static __inline int64x2_t __attribute__ ((__always_inline__))"}, {"sha": "a6b3117c8a278a205a6e9e6ca1aaf56a227c3837", "filename": "gcc/config/aarch64/iterators.md", "status": "modified", "additions": 23, "deletions": 1, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/779aea46cc3b6b1a62f989ee0c04e68803733ba0/gcc%2Fconfig%2Faarch64%2Fiterators.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/779aea46cc3b6b1a62f989ee0c04e68803733ba0/gcc%2Fconfig%2Faarch64%2Fiterators.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Fiterators.md?ref=779aea46cc3b6b1a62f989ee0c04e68803733ba0", "patch": "@@ -169,6 +169,12 @@\n ;; Double scalar modes\n (define_mode_iterator DX [DI DF])\n \n+;; Modes available for <f>mul lane operations.\n+(define_mode_iterator VMUL [V4HI V8HI V2SI V4SI V2SF V4SF V2DF])\n+\n+;; Modes available for <f>mul lane operations changing lane count.\n+(define_mode_iterator VMUL_CHANGE_NLANES [V4HI V8HI V2SI V4SI V2SF V4SF])\n+\n ;; ------------------------------------------------------------------\n ;; Unspec enumerations for Advance SIMD. These could well go into\n ;; aarch64.md but for their use in int_iterators here.\n@@ -358,7 +364,7 @@\n                         (V2SI \"SI\") (V4SI \"SI\")\n                         (DI \"DI\")   (V2DI \"DI\")\n                         (V2SF \"SF\") (V4SF \"SF\")\n-                        (V2DF \"DF\")\n+                        (V2DF \"DF\") (DF \"DF\")\n \t\t\t(SI   \"SI\") (HI   \"HI\")\n \t\t\t(QI   \"QI\")])\n \n@@ -541,6 +547,22 @@\n \t\t\t\t    (V2SF \"to_128\") (V4SF  \"to_64\")\n \t\t\t\t    (DF   \"to_128\") (V2DF  \"to_64\")])\n \n+;; For certain vector-by-element multiplication instructions we must\n+;; constrain the HI cases to use only V0-V15.  This is covered by\n+;; the 'x' constraint.  All other modes may use the 'w' constraint.\n+(define_mode_attr h_con [(V2SI \"w\") (V4SI \"w\")\n+\t\t\t (V4HI \"x\") (V8HI \"x\")\n+\t\t\t (V2SF \"w\") (V4SF \"w\")\n+\t\t\t (V2DF \"w\") (DF \"w\")])\n+\n+;; Defined to 'f' for types whose element type is a float type.\n+(define_mode_attr f [(V8QI \"\")  (V16QI \"\")\n+\t\t     (V4HI \"\")  (V8HI  \"\")\n+\t\t     (V2SI \"\")  (V4SI  \"\")\n+\t\t     (DI   \"\")  (V2DI  \"\")\n+\t\t     (V2SF \"f\") (V4SF  \"f\")\n+\t\t     (V2DF \"f\") (DF    \"f\")])\n+\n ;; -------------------------------------------------------------------\n ;; Code Iterators\n ;; -------------------------------------------------------------------"}, {"sha": "17ae8ee15503d5eaa4b3e1c0e3b892df065f15df", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/779aea46cc3b6b1a62f989ee0c04e68803733ba0/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/779aea46cc3b6b1a62f989ee0c04e68803733ba0/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=779aea46cc3b6b1a62f989ee0c04e68803733ba0", "patch": "@@ -1,3 +1,8 @@\n+2013-09-16  James Greenhalgh  <james.greenhalgh@arm.com>\n+\n+\t* gcc.target/aarch64/mul_intrinsic_1.c: New.\n+\t* gcc.target/aarch64/fmul_intrinsic_1.c: Likewise.\n+\n 2013-09-16  Richard Biener  <rguenther@suse.de>\n \n \t* gcc.dg/tree-ssa/ldist-22.c: New testcase."}, {"sha": "f6e32f4bf7781e1a102a037abc36dab37da6689d", "filename": "gcc/testsuite/gcc.target/aarch64/fmul_intrinsic_1.c", "status": "added", "additions": 116, "deletions": 0, "changes": 116, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/779aea46cc3b6b1a62f989ee0c04e68803733ba0/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Ffmul_intrinsic_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/779aea46cc3b6b1a62f989ee0c04e68803733ba0/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Ffmul_intrinsic_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Ffmul_intrinsic_1.c?ref=779aea46cc3b6b1a62f989ee0c04e68803733ba0", "patch": "@@ -0,0 +1,116 @@\n+/* { dg-do run } */\n+/* { dg-options \"-O3 --save-temps\" } */\n+\n+#include <arm_neon.h>\n+\n+#define DELTA 0.0001\n+extern void abort (void);\n+extern double fabs (double);\n+\n+#define TEST_VMUL(q1, q2, size, in1_lanes, in2_lanes)\t\t\t\\\n+static void\t\t\t\t\t\t\t\t\\\n+test_vmul##q1##_lane##q2##_f##size (float##size##_t * res,\t\t\\\n+\t\t\t\t   const float##size##_t *in1,\t\t\\\n+\t\t\t\t   const float##size##_t *in2)\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+  float##size##x##in1_lanes##_t a = vld1##q1##_f##size (res);\t\t\\\n+  float##size##x##in1_lanes##_t b = vld1##q1##_f##size (in1);\t\t\\\n+  float##size##x##in2_lanes##_t c;\t\t\t\t\t\\\n+  if (in2_lanes > 1)\t\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\t\t\\\n+      c = vld1##q2##_f##size (in2);\t\t\t\t\t\\\n+      a = vmul##q1##_lane##q2##_f##size (b, c, 1);\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+  else\t\t\t\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\t\t\\\n+      c = vld1##q2##_f##size (in2 + 1);\t\t\t\t\t\\\n+      a = vmul##q1##_lane##q2##_f##size (b, c, 0);\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+  vst1##q1##_f##size (res, a);\t\t\t\t\t\t\\\n+}\n+\n+#define BUILD_VARS(width, n_lanes, n_half_lanes)\t\t\\\n+TEST_VMUL ( ,  , width, n_half_lanes, n_half_lanes)\t\t\\\n+TEST_VMUL (q,  , width, n_lanes, n_half_lanes)\t\t\t\\\n+TEST_VMUL ( , q, width, n_half_lanes, n_lanes)\t\t\t\\\n+TEST_VMUL (q, q, width, n_lanes, n_lanes)\n+\n+BUILD_VARS (32, 4, 2)\n+BUILD_VARS (64, 2, 1)\n+\n+#define POOL2 {0.0, 1.0}\n+#define POOL4 {0.0, 1.0, 2.0, 3.0}\n+#define EMPTY2 {0.0, 0.0}\n+#define EMPTY4 {0.0, 0.0, 0.0, 0.0}\n+\n+#define BUILD_TEST(size, lanes)\t\t\t\t\t\\\n+static void\t\t\t\t\t\t\t\\\n+test_f##size (void)\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\\\n+  int i;\t\t\t\t\t\t\t\\\n+  float##size##_t pool[lanes] = POOL##lanes;\t\t\t\\\n+  float##size##_t res[lanes] = EMPTY##lanes;\t\t\t\\\n+  float##size##_t res2[lanes] = EMPTY##lanes;\t\t\t\\\n+  float##size##_t res3[lanes] = EMPTY##lanes;\t\t\t\\\n+  float##size##_t res4[lanes] = EMPTY##lanes;\t\t\t\\\n+\t\t\t\t\t\t\t\t\\\n+  /* Avoid constant folding the multiplication.  */\t\t\\\n+  asm volatile (\"\" : : : \"memory\");\t\t\t\t\\\n+  test_vmul_lane_f##size (res, pool, pool);\t\t\t\\\n+  /* Avoid fusing multiplication and subtraction.  */\t\t\\\n+  asm volatile (\"\" : :\"Q\" (res) : \"memory\");\t\t\t\\\n+  for (i = 0; i < lanes / 2; i++)\t\t\t\t\\\n+    if (fabs (res[i] - pool[i]) > DELTA)\t\t\t\\\n+      abort ();\t\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\\\n+  test_vmulq_lane_f##size (res2, pool, pool);\t\t\t\\\n+  /* Avoid fusing multiplication and subtraction.  */\t\t\\\n+  asm volatile (\"\" : :\"Q\" (res2) : \"memory\");\t\t\t\\\n+  for (i = 0; i < lanes; i++)\t\t\t\t\t\\\n+    if (fabs (res2[i] - pool[i]) > DELTA)\t\t\t\\\n+      abort ();\t\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\\\n+  test_vmul_laneq_f##size (res3, pool, pool);\t\t\t\\\n+  /* Avoid fusing multiplication and subtraction.  */\t\t\\\n+  asm volatile (\"\" : :\"Q\" (res3) : \"memory\");\t\t\t\\\n+  for (i = 0; i < lanes / 2; i++)\t\t\t\t\\\n+    if (fabs (res3[i] - pool[i]) > DELTA)\t\t\t\\\n+      abort ();\t\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\\\n+  test_vmulq_laneq_f##size (res4, pool, pool);\t\t\t\\\n+  /* Avoid fusing multiplication and subtraction.  */\t\t\\\n+  asm volatile (\"\" : :\"Q\" (res4) : \"memory\");\t\t\t\\\n+  for (i = 0; i < lanes; i++)\t\t\t\t\t\\\n+    if (fabs (res4[i] - pool[i]) > DELTA)\t\t\t\\\n+      abort ();\t\t\t\t\t\t\t\\\n+}\n+\n+BUILD_TEST (32, 4)\n+BUILD_TEST (64, 2)\n+\n+int\n+main (int argc, char **argv)\n+{\n+  test_f32 ();\n+  test_f64 ();\n+  return 0;\n+}\n+\n+/* vmul_laneq_f32.\n+   vmul_lane_f32.  */\n+/* { dg-final { scan-assembler-times \"fmul\\\\tv\\[0-9\\]+\\.2s, v\\[0-9\\]+\\.2s, v\\[0-9\\]+\\.s\\\\\\[\\[0-9\\]+\\\\\\]\" 2 } } */\n+\n+/* vmulq_lane_f32.\n+   vmulq_laneq_f32.  */\n+/* { dg-final { scan-assembler-times \"fmul\\\\tv\\[0-9\\]+\\.4s, v\\[0-9\\]+\\.4s, v\\[0-9\\]+\\.s\\\\\\[\\[0-9\\]+\\\\\\]\" 2 } } */\n+\n+/* vmul_lane_f64.  */\n+/* { dg-final { scan-assembler-times \"fmul\\\\td\\[0-9\\]+, d\\[0-9\\]+, d\\[0-9\\]+\" 1 } } */\n+\n+/* vmul_laneq_f64.\n+   vmulq_lane_f64.\n+   vmulq_laneq_f64.  */\n+/* { dg-final { scan-assembler-times \"fmul\\\\tv\\[0-9\\]+\\.2d, v\\[0-9\\]+\\.2d, v\\[0-9\\]+\\.d\\\\\\[\\[0-9\\]+\\\\\\]\" 3 } } */\n+\n+/* { dg-final { cleanup-saved-temps } } */\n+"}, {"sha": "dabe10e15e536e12733d1d13f5523a35ebf8c9c7", "filename": "gcc/testsuite/gcc.target/aarch64/mul_intrinsic_1.c", "status": "added", "additions": 83, "deletions": 0, "changes": 83, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/779aea46cc3b6b1a62f989ee0c04e68803733ba0/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fmul_intrinsic_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/779aea46cc3b6b1a62f989ee0c04e68803733ba0/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fmul_intrinsic_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fmul_intrinsic_1.c?ref=779aea46cc3b6b1a62f989ee0c04e68803733ba0", "patch": "@@ -0,0 +1,83 @@\n+/* { dg-do run } */\n+/* { dg-options \"-O3 --save-temps\" } */\n+\n+#include <arm_neon.h>\n+\n+extern void abort (void);\n+\n+#define MAPs(size, xx) int##size##xx##_t\n+#define MAPu(size, xx) uint##size##xx##_t\n+\n+\n+#define TEST_VMUL(q, su, size, in1_lanes, in2_lanes)\t\t\\\n+static void\t\t\t\t\t\t\t\\\n+test_vmulq_lane##q##_##su##size (MAP##su (size, ) * res,\t\\\n+\t\t\t\t const MAP##su(size, ) *in1,\t\\\n+\t\t\t\t const MAP##su(size, ) *in2)\t\\\n+{\t\t\t\t\t\t\t\t\\\n+  MAP##su (size, x##in1_lanes) a = vld1q_##su##size (in1);\t\\\n+  MAP##su (size, x##in2_lanes) b = vld1##q##_##su##size (in2);\t\\\n+  a = vmulq_lane##q##_##su##size (a, b, 1);\t\t\t\\\n+  vst1q_##su##size (res, a);\t\t\t\t\t\\\n+}\n+\n+#define BUILD_VARS(width, n_lanes, n_half_lanes)\t\t\\\n+TEST_VMUL (, s, width, n_lanes, n_half_lanes)\t\t\t\\\n+TEST_VMUL (q, s, width, n_lanes, n_lanes)\t\t\t\\\n+TEST_VMUL (, u, width, n_lanes, n_half_lanes)\t\t\t\\\n+TEST_VMUL (q, u, width, n_lanes, n_lanes)\t\t\t\\\n+\n+BUILD_VARS (32, 4, 2)\n+BUILD_VARS (16, 8, 4)\n+\n+#define POOL4 {0, 1, 2, 3}\n+#define POOL8 {0, 1, 2, 3, 4, 5, 6, 7}\n+#define EMPTY4 {0, 0, 0, 0}\n+#define EMPTY8 {0, 0, 0, 0, 0, 0, 0, 0}\n+\n+#define BUILD_TEST(su, size, lanes)\t\t\t\t\\\n+static void\t\t\t\t\t\t\t\\\n+test_##su##size (void)\t\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\\\n+  int i;\t\t\t\t\t\t\t\\\n+  MAP##su (size,) pool[lanes] = POOL##lanes;\t\t\t\\\n+  MAP##su (size,) res[lanes] = EMPTY##lanes;\t\t\t\\\n+  MAP##su (size,) res2[lanes] = EMPTY##lanes;\t\t\t\\\n+\t\t\t\t\t\t\t\t\\\n+  /* Forecfully avoid optimization.  */\t\t\t\t\\\n+  asm volatile (\"\" : : : \"memory\");\t\t\t\t\\\n+  test_vmulq_lane_##su##size (res, pool, pool);\t\t\t\\\n+  for (i = 0; i < lanes; i++)\t\t\t\t\t\\\n+    if (res[i] != pool[i])\t\t\t\t\t\\\n+      abort ();\t\t\t\t\t\t\t\\\n+\t\t\t\t\t\t\t\t\\\n+  /* Forecfully avoid optimization.  */\t\t\t\t\\\n+  asm volatile (\"\" : : : \"memory\");\t\t\t\t\\\n+  test_vmulq_laneq_##su##size (res2, pool, pool);\t\t\\\n+  for (i = 0; i < lanes; i++)\t\t\t\t\t\\\n+    if (res2[i] != pool[i])\t\t\t\t\t\\\n+      abort ();\t\t\t\t\t\t\t\\\n+}\n+\n+#undef BUILD_VARS\n+#define BUILD_VARS(size, lanes)\t\t\t\t\t\\\n+BUILD_TEST (s, size, lanes)\t\t\t\t\t\\\n+BUILD_TEST (u, size, lanes)\n+\n+BUILD_VARS (32, 4)\n+BUILD_VARS (16, 8)\n+\n+int\n+main (int argc, char **argv)\n+{\n+  test_s32 ();\n+  test_u32 ();\n+  test_s16 ();\n+  test_u16 ();\n+  return 0;\n+}\n+\n+/* { dg-final { scan-assembler-times \"mul\\\\tv\\[0-9\\]+\\.4s, v\\[0-9\\]+\\.4s, v\\[0-9\\]+\\.s\\\\\\[\\[0-9\\]+\\\\\\]\" 4 } } */\n+/* { dg-final { scan-assembler-times \"mul\\\\tv\\[0-9\\]+\\.8h, v\\[0-9\\]+\\.8h, v\\[0-9\\]+\\.h\\\\\\[\\[0-9\\]+\\\\\\]\" 4 } } */\n+/* { dg-final { cleanup-saved-temps } } */\n+"}]}