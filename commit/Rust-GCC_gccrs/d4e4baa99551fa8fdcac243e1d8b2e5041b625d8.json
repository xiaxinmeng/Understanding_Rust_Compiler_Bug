{"sha": "d4e4baa99551fa8fdcac243e1d8b2e5041b625d8", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDRlNGJhYTk5NTUxZmE4ZmRjYWMyNDNlMWQ4YjJlNTA0MWI2MjVkOA==", "commit": {"author": {"name": "Alexandre Oliva", "email": "aoliva@redhat.com", "date": "2001-10-05T03:48:18Z"}, "committer": {"name": "Alexandre Oliva", "email": "aoliva@gcc.gnu.org", "date": "2001-10-05T03:48:18Z"}, "message": "Makefile.in (tree-inline.o): Depend on newly-included headers.\n\n* Makefile.in (tree-inline.o): Depend on newly-included headers.\n* tree-inline.c: Include headers needed for the functions moved in.\n(struct inline_data, INSNS_PER_STMT): Moved from cp/optimize.c.\n(remap_decl, remap_block, copy_scopy_stmt, copy_body_r): Likewise.\n(copy_body, initialize_inlined_parameters): Likewise.\n(declare_return_variable, inlinable_function_p): Likewise.\n(expand_call_inline, expand_calls_inline): Likewise.\n(optimize_inline_calls, clone_body): Likewise.\n(walk_tree, walk_tree_without_duplicates): Moved from cp/tree.c.\n(copy_tree_r, remap_save_expr): Likewise.\n\nFrom-SVN: r46023", "tree": {"sha": "ebb879c92ceeb02c9de5981f233afe5e572bf0ce", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/ebb879c92ceeb02c9de5981f233afe5e572bf0ce"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d4e4baa99551fa8fdcac243e1d8b2e5041b625d8", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d4e4baa99551fa8fdcac243e1d8b2e5041b625d8", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d4e4baa99551fa8fdcac243e1d8b2e5041b625d8", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d4e4baa99551fa8fdcac243e1d8b2e5041b625d8/comments", "author": null, "committer": null, "parents": [{"sha": "bc4c7159d8a4797ec093f042bb8e74aab7d28b0d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bc4c7159d8a4797ec093f042bb8e74aab7d28b0d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/bc4c7159d8a4797ec093f042bb8e74aab7d28b0d"}], "stats": {"total": 1327, "additions": 1325, "deletions": 2}, "files": [{"sha": "a1b97df97bc181d4086ee775327528e6f31f84d3", "filename": "gcc/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d4e4baa99551fa8fdcac243e1d8b2e5041b625d8/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d4e4baa99551fa8fdcac243e1d8b2e5041b625d8/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=d4e4baa99551fa8fdcac243e1d8b2e5041b625d8", "patch": "@@ -1,3 +1,16 @@\n+2001-10-05  Alexandre Oliva  <aoliva@redhat.com>\n+\n+\t* Makefile.in (tree-inline.o): Depend on newly-included headers.\n+\t* tree-inline.c: Include headers needed for the functions moved in.\n+\t(struct inline_data, INSNS_PER_STMT): Moved from cp/optimize.c.\n+\t(remap_decl, remap_block, copy_scopy_stmt, copy_body_r): Likewise.\n+\t(copy_body, initialize_inlined_parameters): Likewise.\n+\t(declare_return_variable, inlinable_function_p): Likewise.\n+\t(expand_call_inline, expand_calls_inline): Likewise.\n+\t(optimize_inline_calls, clone_body): Likewise.\n+\t(walk_tree, walk_tree_without_duplicates): Moved from cp/tree.c.\n+\t(copy_tree_r, remap_save_expr): Likewise.\n+\n 2001-10-04  Alexandre Oliva  <aoliva@redhat.com>\n \n \t* Makefile.in (OBJS): Added tree-inline.o."}, {"sha": "e16aedec507f6bf548ba52dbfeb9caa5f1e783f5", "filename": "gcc/Makefile.in", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d4e4baa99551fa8fdcac243e1d8b2e5041b625d8/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d4e4baa99551fa8fdcac243e1d8b2e5041b625d8/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=d4e4baa99551fa8fdcac243e1d8b2e5041b625d8", "patch": "@@ -1351,8 +1351,10 @@ convert.o: convert.c $(CONFIG_H) $(SYSTEM_H) $(TREE_H) flags.h convert.h toplev.\n \n tree.o : tree.c $(CONFIG_H) $(SYSTEM_H) $(TREE_H) flags.h function.h toplev.h \\\n    $(GGC_H) $(HASHTAB_H) $(TARGET_H) output.h $(TM_P_H)\n-tree-inline.o : tree-inline.c $(CONFIG_H) $(SYSTEM_H) $(TREE_H) \\\n-   tree-inline.h\n+tree-inline.o : tree-inline.c $(CONFIG_H) $(SYSTEM_H) $(TREE_H) $(RTL_H) \\\n+   expr.h flags.h params.h input.h insn-config.h $(INTEGRATE_H) \\\n+   $(VARRAY_H) $(HASHTAB_H) $(SPLAY_TREE_H) \\\n+   $(C_COMMON_H) tree-inline.h\n print-tree.o : print-tree.c $(CONFIG_H) $(SYSTEM_H) $(TREE_H) $(GGC_H)\n stor-layout.o : stor-layout.c $(CONFIG_H) $(SYSTEM_H) $(TREE_H) flags.h \\\n    function.h $(EXPR_H) $(RTL_H) toplev.h $(GGC_H) $(TM_P_H)"}, {"sha": "e24d39b18f0c9d8f28f6982b67c7d9a8ae886c59", "filename": "gcc/tree-inline.c", "status": "modified", "additions": 1308, "deletions": 0, "changes": 1308, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d4e4baa99551fa8fdcac243e1d8b2e5041b625d8/gcc%2Ftree-inline.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d4e4baa99551fa8fdcac243e1d8b2e5041b625d8/gcc%2Ftree-inline.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-inline.c?ref=d4e4baa99551fa8fdcac243e1d8b2e5041b625d8", "patch": "@@ -23,6 +23,20 @@ Boston, MA 02111-1307, USA.  */\n #include \"system.h\"\n #include \"tree.h\"\n #include \"tree-inline.h\"\n+#include \"rtl.h\"\n+#include \"expr.h\"\n+#include \"flags.h\"\n+#include \"params.h\"\n+#include \"input.h\"\n+#include \"insn-config.h\"\n+#include \"integrate.h\"\n+#include \"varray.h\"\n+#include \"hashtab.h\"\n+#include \"splay-tree.h\"\n+\n+/* This should be eventually be generalized to other languages, but\n+   this would require a shared function-as-trees infrastructure.  */\n+#include \"c-common.h\" \n \n /* Definitions of language hooks.  */\n \n@@ -41,3 +55,1297 @@ treeopt_anon_aggr_type_p *lang_anon_aggr_type_p;\n    candidates.  */\n \n int flag_inline_trees = 0;\n+\n+/* To Do:\n+\n+   o In order to make inlining-on-trees work, we pessimized\n+     function-local static constants.  In particular, they are now\n+     always output, even when not addressed.  Fix this by treating\n+     function-local static constants just like global static\n+     constants; the back-end already knows not to output them if they\n+     are not needed.\n+\n+   o Provide heuristics to clamp inlining of recursive template\n+     calls?  */\n+\n+/* Data required for function inlining.  */\n+\n+typedef struct inline_data\n+{\n+  /* A stack of the functions we are inlining.  For example, if we are\n+     compiling `f', which calls `g', which calls `h', and we are\n+     inlining the body of `h', the stack will contain, `h', followed\n+     by `g', followed by `f'.  The first few elements of the stack may\n+     contain other functions that we know we should not recurse into,\n+     even though they are not directly being inlined.  */\n+  varray_type fns;\n+  /* The index of the first element of FNS that really represents an\n+     inlined function.  */\n+  unsigned first_inlined_fn;\n+  /* The label to jump to when a return statement is encountered.  If\n+     this value is NULL, then return statements will simply be\n+     remapped as return statements, rather than as jumps.  */\n+  tree ret_label;\n+  /* The map from local declarations in the inlined function to\n+     equivalents in the function into which it is being inlined.  */\n+  splay_tree decl_map;\n+  /* Nonzero if we are currently within the cleanup for a\n+     TARGET_EXPR.  */\n+  int in_target_cleanup_p;\n+  /* A stack of the TARGET_EXPRs that we are currently processing.  */\n+  varray_type target_exprs;\n+  /* A list of the functions current function has inlined.  */\n+  varray_type inlined_fns;\n+  /* The approximate number of statements we have inlined in the\n+     current call stack.  */\n+  int inlined_stmts;\n+  /* We use the same mechanism to build clones that we do to perform\n+     inlining.  However, there are a few places where we need to\n+     distinguish between those two situations.  This flag is true if\n+     we are cloning, rather than inlining.  */\n+  bool cloning_p;\n+  /* Hash table used to prevent walk_tree from visiting the same node\n+     umpteen million times.  */\n+  htab_t tree_pruner;\n+} inline_data;\n+\n+/* Prototypes.  */\n+\n+static tree initialize_inlined_parameters PARAMS ((inline_data *, tree, tree));\n+static tree declare_return_variable PARAMS ((inline_data *, tree *));\n+static tree copy_body_r PARAMS ((tree *, int *, void *));\n+static tree copy_body PARAMS ((inline_data *));\n+static tree expand_call_inline PARAMS ((tree *, int *, void *));\n+static void expand_calls_inline PARAMS ((tree *, inline_data *));\n+static int inlinable_function_p PARAMS ((tree, inline_data *));\n+static tree remap_decl PARAMS ((tree, inline_data *));\n+static void remap_block PARAMS ((tree, tree, inline_data *));\n+static void copy_scope_stmt PARAMS ((tree *, int *, inline_data *));\n+\n+/* The approximate number of instructions per statement.  This number\n+   need not be particularly accurate; it is used only to make\n+   decisions about when a function is too big to inline.  */\n+#define INSNS_PER_STMT (10)\n+\n+/* Remap DECL during the copying of the BLOCK tree for the function.  */\n+\n+static tree\n+remap_decl (decl, id)\n+     tree decl;\n+     inline_data *id;\n+{\n+  splay_tree_node n;\n+  tree fn;\n+\n+  /* We only remap local variables in the current function.  */\n+  fn = VARRAY_TOP_TREE (id->fns);\n+  if (! LANG_AUTO_VAR_IN_FN_P (decl, fn))\n+    return NULL_TREE;\n+\n+  /* See if we have remapped this declaration.  */\n+  n = splay_tree_lookup (id->decl_map, (splay_tree_key) decl);\n+  /* If we didn't already have an equivalent for this declaration,\n+     create one now.  */\n+  if (!n)\n+    {\n+      tree t;\n+\n+      /* Make a copy of the variable or label.  */\n+      t = copy_decl_for_inlining (decl, fn,\n+\t\t\t\t  VARRAY_TREE (id->fns, 0));\n+\n+      /* The decl T could be a dynamic array or other variable size type,\n+\t in which case some fields need to be remapped because they may\n+\t contain SAVE_EXPRs.  */\n+      walk_tree (&DECL_SIZE (t), copy_body_r, id, NULL);\n+      walk_tree (&DECL_SIZE_UNIT (t), copy_body_r, id, NULL);\n+      if (TREE_TYPE (t) && TREE_CODE (TREE_TYPE (t)) == ARRAY_TYPE\n+\t  && TYPE_DOMAIN (TREE_TYPE (t)))\n+\t{\n+\t  TREE_TYPE (t) = copy_node (TREE_TYPE (t));\n+\t  TYPE_DOMAIN (TREE_TYPE (t))\n+\t    = copy_node (TYPE_DOMAIN (TREE_TYPE (t)));\n+\t  walk_tree (&TYPE_MAX_VALUE (TYPE_DOMAIN (TREE_TYPE (t))),\n+\t\t     copy_body_r, id, NULL);\n+\t}\n+\n+      if (! DECL_NAME (t) && TREE_TYPE (t)\n+\t  && LANG_ANON_AGGR_TYPE_P (TREE_TYPE (t)))\n+\t{\n+\t  /* For a VAR_DECL of anonymous type, we must also copy the\n+\t     member VAR_DECLS here and rechain the\n+\t     DECL_ANON_UNION_ELEMS. */\n+\t  tree members = NULL;\n+\t  tree src;\n+\t  \n+\t  for (src = DECL_ANON_UNION_ELEMS (t); src;\n+\t       src = TREE_CHAIN (src))\n+\t    {\n+\t      tree member = remap_decl (TREE_VALUE (src), id);\n+\n+\t      if (TREE_PURPOSE (src))\n+\t\tabort ();\n+\t      members = tree_cons (NULL, member, members);\n+\t    }\n+\t  DECL_ANON_UNION_ELEMS (t) = nreverse (members);\n+\t}\n+      \n+      /* Remember it, so that if we encounter this local entity\n+\t again we can reuse this copy.  */\n+      n = splay_tree_insert (id->decl_map,\n+\t\t\t     (splay_tree_key) decl,\n+\t\t\t     (splay_tree_value) t);\n+    }\n+\n+  return (tree) n->value;\n+}\n+\n+/* Copy the SCOPE_STMT_BLOCK associated with SCOPE_STMT to contain\n+   remapped versions of the variables therein.  And hook the new block\n+   into the block-tree.  If non-NULL, the DECLS are declarations to\n+   add to use instead of the BLOCK_VARS in the old block.  */\n+\n+static void\n+remap_block (scope_stmt, decls, id)\n+     tree scope_stmt;\n+     tree decls;\n+     inline_data *id;\n+{\n+  /* We cannot do this in the cleanup for a TARGET_EXPR since we do\n+     not know whether or not expand_expr will actually write out the\n+     code we put there.  If it does not, then we'll have more BLOCKs\n+     than block-notes, and things will go awry.  At some point, we\n+     should make the back-end handle BLOCK notes in a tidier way,\n+     without requiring a strict correspondence to the block-tree; then\n+     this check can go.  */\n+  if (id->in_target_cleanup_p)\n+    {\n+      SCOPE_STMT_BLOCK (scope_stmt) = NULL_TREE;\n+      return;\n+    }\n+\n+  /* If this is the beginning of a scope, remap the associated BLOCK.  */\n+  if (SCOPE_BEGIN_P (scope_stmt) && SCOPE_STMT_BLOCK (scope_stmt))\n+    {\n+      tree old_block;\n+      tree new_block;\n+      tree old_var;\n+      tree fn;\n+\n+      /* Make the new block.  */\n+      old_block = SCOPE_STMT_BLOCK (scope_stmt);\n+      new_block = make_node (BLOCK);\n+      TREE_USED (new_block) = TREE_USED (old_block);\n+      BLOCK_ABSTRACT_ORIGIN (new_block) = old_block;\n+      SCOPE_STMT_BLOCK (scope_stmt) = new_block;\n+\n+      /* Remap its variables.  */\n+      for (old_var = decls ? decls : BLOCK_VARS (old_block);\n+\t   old_var;\n+\t   old_var = TREE_CHAIN (old_var))\n+\t{\n+\t  tree new_var;\n+\n+\t  /* Remap the variable.  */\n+\t  new_var = remap_decl (old_var, id);\n+\t  /* If we didn't remap this variable, so we can't mess with\n+\t     its TREE_CHAIN.  If we remapped this variable to\n+\t     something other than a declaration (say, if we mapped it\n+\t     to a constant), then we must similarly omit any mention\n+\t     of it here.  */\n+\t  if (!new_var || !DECL_P (new_var))\n+\t    ;\n+\t  else\n+\t    {\n+\t      TREE_CHAIN (new_var) = BLOCK_VARS (new_block);\n+\t      BLOCK_VARS (new_block) = new_var;\n+\t    }\n+\t}\n+      /* We put the BLOCK_VARS in reverse order; fix that now.  */\n+      BLOCK_VARS (new_block) = nreverse (BLOCK_VARS (new_block));\n+      fn = VARRAY_TREE (id->fns, 0);\n+      if (id->cloning_p)\n+\t/* We're building a clone; DECL_INITIAL is still\n+\t   error_mark_node, and current_binding_level is the parm\n+\t   binding level.  */\n+\tinsert_block (new_block);\n+      else\n+\t{\n+\t  /* Attach this new block after the DECL_INITIAL block for the\n+\t     function into which this block is being inlined.  In\n+\t     rest_of_compilation we will straighten out the BLOCK tree.  */\n+\t  tree *first_block;\n+\t  if (DECL_INITIAL (fn))\n+\t    first_block = &BLOCK_CHAIN (DECL_INITIAL (fn));\n+\t  else\n+\t    first_block = &DECL_INITIAL (fn);\n+\t  BLOCK_CHAIN (new_block) = *first_block;\n+\t  *first_block = new_block;\n+\t}\n+      /* Remember the remapped block.  */\n+      splay_tree_insert (id->decl_map,\n+\t\t\t (splay_tree_key) old_block,\n+\t\t\t (splay_tree_value) new_block);\n+    }\n+  /* If this is the end of a scope, set the SCOPE_STMT_BLOCK to be the\n+     remapped block.  */\n+  else if (SCOPE_END_P (scope_stmt) && SCOPE_STMT_BLOCK (scope_stmt))\n+    {\n+      splay_tree_node n;\n+\n+      /* Find this block in the table of remapped things.  */\n+      n = splay_tree_lookup (id->decl_map,\n+\t\t\t     (splay_tree_key) SCOPE_STMT_BLOCK (scope_stmt));\n+      if (! n)\n+\tabort ();\n+      SCOPE_STMT_BLOCK (scope_stmt) = (tree) n->value;\n+    }\n+}\n+\n+/* Copy the SCOPE_STMT pointed to by TP.  */\n+\n+static void\n+copy_scope_stmt (tp, walk_subtrees, id)\n+     tree *tp;\n+     int *walk_subtrees;\n+     inline_data *id;\n+{\n+  tree block;\n+\n+  /* Remember whether or not this statement was nullified.  When\n+     making a copy, copy_tree_r always sets SCOPE_NULLIFIED_P (and\n+     doesn't copy the SCOPE_STMT_BLOCK) to free callers from having to\n+     deal with copying BLOCKs if they do not wish to do so.  */\n+  block = SCOPE_STMT_BLOCK (*tp);\n+  /* Copy (and replace) the statement.  */\n+  copy_tree_r (tp, walk_subtrees, NULL);\n+  /* Restore the SCOPE_STMT_BLOCK.  */\n+  SCOPE_STMT_BLOCK (*tp) = block;\n+\n+  /* Remap the associated block.  */\n+  remap_block (*tp, NULL_TREE, id);\n+}\n+\n+/* Called from copy_body via walk_tree.  DATA is really an\n+   `inline_data *'.  */\n+\n+static tree\n+copy_body_r (tp, walk_subtrees, data)\n+     tree *tp;\n+     int *walk_subtrees;\n+     void *data;\n+{\n+  inline_data* id;\n+  tree fn;\n+\n+  /* Set up.  */\n+  id = (inline_data *) data;\n+  fn = VARRAY_TOP_TREE (id->fns);\n+\n+#if 0\n+  /* All automatic variables should have a DECL_CONTEXT indicating\n+     what function they come from.  */\n+  if ((TREE_CODE (*tp) == VAR_DECL || TREE_CODE (*tp) == LABEL_DECL)\n+      && DECL_NAMESPACE_SCOPE_P (*tp))\n+    if (! DECL_EXTERNAL (*tp) && ! TREE_STATIC (*tp))\n+      abort ();\n+#endif\n+\n+  /* If this is a RETURN_STMT, change it into an EXPR_STMT and a\n+     GOTO_STMT with the RET_LABEL as its target.  */\n+  if (TREE_CODE (*tp) == RETURN_STMT && id->ret_label)\n+    {\n+      tree return_stmt = *tp;\n+      tree goto_stmt;\n+\n+      /* Build the GOTO_STMT.  */\n+      goto_stmt = build_stmt (GOTO_STMT, id->ret_label);\n+      TREE_CHAIN (goto_stmt) = TREE_CHAIN (return_stmt);\n+\n+      /* If we're returning something, just turn that into an\n+\t assignment into the equivalent of the original\n+\t RESULT_DECL.  */\n+      if (RETURN_EXPR (return_stmt))\n+\t{\n+\t  *tp = build_stmt (EXPR_STMT,\n+\t\t\t    RETURN_EXPR (return_stmt));\n+\t  STMT_IS_FULL_EXPR_P (*tp) = 1;\n+\t  /* And then jump to the end of the function.  */\n+\t  TREE_CHAIN (*tp) = goto_stmt;\n+\t}\n+      /* If we're not returning anything just do the jump.  */\n+      else\n+\t*tp = goto_stmt;\n+    }\n+  /* Local variables and labels need to be replaced by equivalent\n+     variables.  We don't want to copy static variables; there's only\n+     one of those, no matter how many times we inline the containing\n+     function.  */\n+  else if (LANG_AUTO_VAR_IN_FN_P (*tp, fn))\n+    {\n+      tree new_decl;\n+\n+      /* Remap the declaration.  */\n+      new_decl = remap_decl (*tp, id);\n+      if (! new_decl)\n+\tabort ();\n+      /* Replace this variable with the copy.  */\n+      STRIP_TYPE_NOPS (new_decl);\n+      *tp = new_decl;\n+    }\n+#if 0\n+  else if (nonstatic_local_decl_p (*tp)\n+\t   && DECL_CONTEXT (*tp) != VARRAY_TREE (id->fns, 0))\n+    abort ();\n+#endif\n+  else if (TREE_CODE (*tp) == SAVE_EXPR)\n+    remap_save_expr (tp, id->decl_map, VARRAY_TREE (id->fns, 0),\n+\t\t     walk_subtrees);\n+  else if (TREE_CODE (*tp) == UNSAVE_EXPR)\n+    /* UNSAVE_EXPRs should not be generated until expansion time.  */\n+    abort ();\n+  /* For a SCOPE_STMT, we must copy the associated block so that we\n+     can write out debugging information for the inlined variables.  */\n+  else if (TREE_CODE (*tp) == SCOPE_STMT && !id->in_target_cleanup_p)\n+    copy_scope_stmt (tp, walk_subtrees, id);\n+  /* Otherwise, just copy the node.  Note that copy_tree_r already\n+     knows not to copy VAR_DECLs, etc., so this is safe.  */\n+  else\n+    {\n+      copy_tree_r (tp, walk_subtrees, NULL);\n+\n+      /* The copied TARGET_EXPR has never been expanded, even if the\n+\t original node was expanded already.  */\n+      if (TREE_CODE (*tp) == TARGET_EXPR && TREE_OPERAND (*tp, 3))\n+\t{\n+\t  TREE_OPERAND (*tp, 1) = TREE_OPERAND (*tp, 3);\n+\t  TREE_OPERAND (*tp, 3) = NULL_TREE;\n+\t}\n+      else if (TREE_CODE (*tp) == MODIFY_EXPR\n+\t       && TREE_OPERAND (*tp, 0) == TREE_OPERAND (*tp, 1)\n+\t       && LANG_AUTO_VAR_IN_FN_P (TREE_OPERAND (*tp, 0), fn))\n+\t{\n+\t  /* Some assignments VAR = VAR; don't generate any rtl code\n+\t     and thus don't count as variable modification.  Avoid\n+\t     keeping bogosities like 0 = 0.  */\n+\t  tree decl = TREE_OPERAND (*tp, 0), value;\n+\t  splay_tree_node n;\n+\n+\t  n = splay_tree_lookup (id->decl_map, (splay_tree_key) decl);\n+\t  if (n)\n+\t    {\n+\t      value = (tree) n->value;\n+\t      STRIP_TYPE_NOPS (value);\n+\t      if (TREE_CONSTANT (value) || TREE_READONLY_DECL_P (value))\n+\t\t*tp = value;\n+\t    }\n+\t}\n+    }\n+\n+  /* Keep iterating.  */\n+  return NULL_TREE;\n+}\n+\n+/* Make a copy of the body of FN so that it can be inserted inline in\n+   another function.  */\n+\n+static tree\n+copy_body (id)\n+     inline_data *id;\n+{\n+  tree body;\n+\n+  body = DECL_SAVED_TREE (VARRAY_TOP_TREE (id->fns));\n+  walk_tree (&body, copy_body_r, id, NULL);\n+\n+  return body;\n+}\n+\n+/* Generate code to initialize the parameters of the function at the\n+   top of the stack in ID from the ARGS (presented as a TREE_LIST).  */\n+\n+static tree\n+initialize_inlined_parameters (id, args, fn)\n+     inline_data *id;\n+     tree args;\n+     tree fn;\n+{\n+  tree init_stmts;\n+  tree parms;\n+  tree a;\n+  tree p;\n+\n+  /* Figure out what the parameters are.  */\n+  parms = DECL_ARGUMENTS (fn);\n+\n+  /* Start with no initializations whatsoever.  */\n+  init_stmts = NULL_TREE;\n+\n+  /* Loop through the parameter declarations, replacing each with an\n+     equivalent VAR_DECL, appropriately initialized.  */\n+  for (p = parms, a = args; p; a = TREE_CHAIN (a), p = TREE_CHAIN (p))\n+    {\n+      tree init_stmt;\n+      tree var;\n+      tree value;\n+\n+      /* Find the initializer.  */\n+      value = TREE_VALUE (a);\n+      /* If the parameter is never assigned to, we may not need to\n+\t create a new variable here at all.  Instead, we may be able\n+\t to just use the argument value.  */\n+      if (TREE_READONLY (p)\n+\t  && !TREE_ADDRESSABLE (p)\n+\t  && !TREE_SIDE_EFFECTS (value))\n+\t{\n+\t  /* Simplify the value, if possible.  */\n+\t  value = fold (decl_constant_value (value));\n+\n+\t  /* We can't risk substituting complex expressions.  They\n+\t     might contain variables that will be assigned to later.\n+\t     Theoretically, we could check the expression to see if\n+\t     all of the variables that determine its value are\n+\t     read-only, but we don't bother.  */\n+\t  if (TREE_CONSTANT (value) || TREE_READONLY_DECL_P (value))\n+\t    {\n+\t      /* If this is a declaration, wrap it a NOP_EXPR so that\n+\t\t we don't try to put the VALUE on the list of\n+\t\t BLOCK_VARS.  */\n+\t      if (DECL_P (value))\n+\t\tvalue = build1 (NOP_EXPR, TREE_TYPE (value), value);\n+\n+\t      splay_tree_insert (id->decl_map,\n+\t\t\t\t (splay_tree_key) p,\n+\t\t\t\t (splay_tree_value) value);\n+\t      continue;\n+\t    }\n+\t}\n+\n+      /* Make an equivalent VAR_DECL.  */\n+      var = copy_decl_for_inlining (p, fn, VARRAY_TREE (id->fns, 0));\n+      /* Register the VAR_DECL as the equivalent for the PARM_DECL;\n+\t that way, when the PARM_DECL is encountered, it will be\n+\t automatically replaced by the VAR_DECL.  */\n+      splay_tree_insert (id->decl_map,\n+\t\t\t (splay_tree_key) p,\n+\t\t\t (splay_tree_value) var);\n+\n+      /* Declare this new variable.  */\n+      init_stmt = build_stmt (DECL_STMT, var);\n+      TREE_CHAIN (init_stmt) = init_stmts;\n+      init_stmts = init_stmt;\n+\n+      /* Initialize this VAR_DECL from the equivalent argument.  If\n+\t the argument is an object, created via a constructor or copy,\n+\t this will not result in an extra copy: the TARGET_EXPR\n+\t representing the argument will be bound to VAR, and the\n+\t object will be constructed in VAR.  */\n+      if (! TYPE_NEEDS_CONSTRUCTING (TREE_TYPE (p)))\n+\tDECL_INITIAL (var) = value;\n+      else\n+\t{\n+\t  /* Even if P was TREE_READONLY, the new VAR should not be.\n+\t     In the original code, we would have constructed a\n+\t     temporary, and then the function body would have never\n+\t     changed the value of P.  However, now, we will be\n+\t     constructing VAR directly.  The constructor body may\n+\t     change its value multiple times as it is being\n+\t     constructed.  Therefore, it must not be TREE_READONLY;\n+\t     the back-end assumes that TREE_READONLY variable is\n+\t     assigned to only once.  */\n+\t  TREE_READONLY (var) = 0;\n+\n+\t  /* Build a run-time initialization.  */\n+\t  init_stmt = build_stmt (EXPR_STMT,\n+\t\t\t\t  build (INIT_EXPR, TREE_TYPE (p),\n+\t\t\t\t\t var, value));\n+\t  /* Add this initialization to the list.  Note that we want the\n+\t     declaration *after* the initialization because we are going\n+\t     to reverse all the initialization statements below.  */\n+\t  TREE_CHAIN (init_stmt) = init_stmts;\n+\t  init_stmts = init_stmt;\n+\t}\n+    }\n+\n+  /* The initialization statements have been built up in reverse\n+     order.  Straighten them out now.  */\n+  return nreverse (init_stmts);\n+}\n+\n+/* Declare a return variable to replace the RESULT_DECL for the\n+   function we are calling.  An appropriate DECL_STMT is returned.\n+   The USE_STMT is filled in to contain a use of the declaration to\n+   indicate the return value of the function.  */\n+\n+static tree\n+declare_return_variable (id, use_stmt)\n+     struct inline_data *id;\n+     tree *use_stmt;\n+{\n+  tree fn = VARRAY_TOP_TREE (id->fns);\n+  tree result = DECL_RESULT (fn);\n+  tree var;\n+  int need_return_decl = 1;\n+\n+  /* We don't need to do anything for functions that don't return\n+     anything.  */\n+  if (!result || VOID_TYPE_P (TREE_TYPE (result)))\n+    {\n+      *use_stmt = NULL_TREE;\n+      return NULL_TREE;\n+    }\n+\n+  var = LANG_COPY_RES_DECL_FOR_INLINING (result, fn, VARRAY_TREE (id->fns, 0),\n+\t\t\t\t\t id->decl_map, &need_return_decl,\n+\t\t\t\t\t &id->target_exprs);\n+\n+  /* Register the VAR_DECL as the equivalent for the RESULT_DECL; that\n+     way, when the RESULT_DECL is encountered, it will be\n+     automatically replaced by the VAR_DECL.  */\n+  splay_tree_insert (id->decl_map,\n+\t\t     (splay_tree_key) result,\n+\t\t     (splay_tree_value) var);\n+\n+  /* Build the USE_STMT.  */\n+  *use_stmt = build_stmt (EXPR_STMT, var);\n+\n+  /* Build the declaration statement if FN does not return an\n+     aggregate.  */\n+  if (need_return_decl)\n+    return build_stmt (DECL_STMT, var);\n+  /* If FN does return an aggregate, there's no need to declare the\n+     return variable; we're using a variable in our caller's frame.  */\n+  else\n+    return NULL_TREE;\n+}\n+\n+/* Returns non-zero if FN is a function that can be inlined.  */\n+\n+static int\n+inlinable_function_p (fn, id)\n+     tree fn;\n+     inline_data *id;\n+{\n+  int inlinable;\n+\n+  /* If we've already decided this function shouldn't be inlined,\n+     there's no need to check again.  */\n+  if (DECL_UNINLINABLE (fn))\n+    return 0;\n+\n+  /* Assume it is not inlinable.  */\n+  inlinable = 0;\n+\n+  /* If we're not inlining things, then nothing is inlinable.  */\n+  if (!flag_inline_trees)\n+    ;\n+  /* If the function was not declared `inline', then we don't inline\n+     it.  */\n+  else if (!DECL_INLINE (fn))\n+    ;\n+  /* We can't inline functions that are too big.  Only allow a single\n+     function to eat up half of our budget.  Make special allowance\n+     for extern inline functions, though.  */\n+  else if (! LANG_DISREGARD_INLINE_LIMITS (fn)\n+\t   && DECL_NUM_STMTS (fn) * INSNS_PER_STMT > MAX_INLINE_INSNS / 2)\n+    ;\n+  /* All is well.  We can inline this function.  Traditionally, GCC\n+     has refused to inline functions using alloca, or functions whose\n+     values are returned in a PARALLEL, and a few other such obscure\n+     conditions.  We are not equally constrained at the tree level.  */\n+  else\n+    inlinable = 1;\n+\n+  /* Squirrel away the result so that we don't have to check again.  */\n+  DECL_UNINLINABLE (fn) = !inlinable;\n+\n+  /* Even if this function is not itself too big to inline, it might\n+     be that we've done so much inlining already that we don't want to\n+     risk too much inlining any more and thus halve the acceptable\n+     size.  */\n+  if (! LANG_DISREGARD_INLINE_LIMITS (fn)\n+      && ((DECL_NUM_STMTS (fn) + id->inlined_stmts) * INSNS_PER_STMT\n+\t  > MAX_INLINE_INSNS)\n+      && DECL_NUM_STMTS (fn) * INSNS_PER_STMT > MAX_INLINE_INSNS / 4)\n+    inlinable = 0;\n+\n+  if (inlinable && LANG_CANNOT_INLINE_TREE_FN (&fn))\n+    inlinable = 0;\n+  \n+  /* If we don't have the function body available, we can't inline\n+     it.  */\n+  if (!DECL_SAVED_TREE (fn))\n+    inlinable = 0;\n+\n+  /* Check again, language hooks may have modified it.  */\n+  if (! inlinable || DECL_UNINLINABLE (fn))\n+    return 0;\n+\n+  /* Don't do recursive inlining, either.  We don't record this in\n+     DECL_UNINLINABLE; we may be able to inline this function later.  */\n+  if (inlinable)\n+    {\n+      size_t i;\n+\n+      for (i = 0; i < VARRAY_ACTIVE_SIZE (id->fns); ++i)\n+\tif (VARRAY_TREE (id->fns, i) == fn)\n+\t  return 0;\n+\n+      if (inlinable && DECL_INLINED_FNS (fn))\n+\t{\n+\t  int j;\n+\t  tree inlined_fns = DECL_INLINED_FNS (fn);\n+\n+\t  for (j = 0; j < TREE_VEC_LENGTH (inlined_fns); ++j)\n+\t    if (TREE_VEC_ELT (inlined_fns, j) == VARRAY_TREE (id->fns, 0))\n+\t      return 0;\n+\t}\n+    }\n+\n+  /* Return the result.  */\n+  return inlinable;\n+}\n+\n+/* If *TP is a CALL_EXPR, replace it with its inline expansion.  */\n+\n+static tree\n+expand_call_inline (tp, walk_subtrees, data)\n+     tree *tp;\n+     int *walk_subtrees;\n+     void *data;\n+{\n+  inline_data *id;\n+  tree t;\n+  tree expr;\n+  tree chain;\n+  tree fn;\n+  tree scope_stmt;\n+  tree use_stmt;\n+  tree arg_inits;\n+  tree *inlined_body;\n+  splay_tree st;\n+\n+  /* See what we've got.  */\n+  id = (inline_data *) data;\n+  t = *tp;\n+\n+  /* Recurse, but letting recursive invocations know that we are\n+     inside the body of a TARGET_EXPR.  */\n+  if (TREE_CODE (*tp) == TARGET_EXPR)\n+    {\n+      int i, len = first_rtl_op (TARGET_EXPR);\n+\n+      /* We're walking our own subtrees.  */\n+      *walk_subtrees = 0;\n+\n+      /* Push *TP on the stack of pending TARGET_EXPRs.  */\n+      VARRAY_PUSH_TREE (id->target_exprs, *tp);\n+\n+      /* Actually walk over them.  This loop is the body of\n+\t walk_trees, omitting the case where the TARGET_EXPR\n+\t itself is handled.  */\n+      for (i = 0; i < len; ++i)\n+\t{\n+\t  if (i == 2)\n+\t    ++id->in_target_cleanup_p;\n+\t  walk_tree (&TREE_OPERAND (*tp, i), expand_call_inline, data,\n+\t\t     id->tree_pruner);\n+\t  if (i == 2)\n+\t    --id->in_target_cleanup_p;\n+\t}\n+\n+      /* We're done with this TARGET_EXPR now.  */\n+      VARRAY_POP (id->target_exprs);\n+\n+      return NULL_TREE;\n+    }\n+\n+  if (TYPE_P (t))\n+    /* Because types were not copied in copy_body, CALL_EXPRs beneath\n+       them should not be expanded.  This can happen if the type is a\n+       dynamic array type, for example.  */\n+    *walk_subtrees = 0;\n+\n+  /* From here on, we're only interested in CALL_EXPRs.  */\n+  if (TREE_CODE (t) != CALL_EXPR)\n+    return NULL_TREE;\n+\n+  /* First, see if we can figure out what function is being called.\n+     If we cannot, then there is no hope of inlining the function.  */\n+  fn = get_callee_fndecl (t);\n+  if (!fn)\n+    return NULL_TREE;\n+\n+  /* Don't try to inline functions that are not well-suited to\n+     inlining.  */\n+  if (!inlinable_function_p (fn, id))\n+    return NULL_TREE;\n+\n+  /* Set the current filename and line number to the function we are\n+     inlining so that when we create new _STMT nodes here they get\n+     line numbers corresponding to the function we are calling.  We\n+     wrap the whole inlined body in an EXPR_WITH_FILE_AND_LINE as well\n+     because individual statements don't record the filename.  */\n+  push_srcloc (fn->decl.filename, fn->decl.linenum);\n+\n+  /* Build a statement-expression containing code to initialize the\n+     arguments, the actual inline expansion of the body, and a label\n+     for the return statements within the function to jump to.  The\n+     type of the statement expression is the return type of the\n+     function call.  */\n+  expr = build1 (STMT_EXPR, TREE_TYPE (TREE_TYPE (fn)), NULL_TREE);\n+\n+  /* Local declarations will be replaced by their equivalents in this\n+     map.  */\n+  st = id->decl_map;\n+  id->decl_map = splay_tree_new (splay_tree_compare_pointers,\n+\t\t\t\t NULL, NULL);\n+\n+  /* Initialize the parameters.  */\n+  arg_inits = initialize_inlined_parameters (id, TREE_OPERAND (t, 1), fn);\n+  /* Expand any inlined calls in the initializers.  Do this before we\n+     push FN on the stack of functions we are inlining; we want to\n+     inline calls to FN that appear in the initializers for the\n+     parameters.  */\n+  expand_calls_inline (&arg_inits, id);\n+  /* And add them to the tree.  */\n+  STMT_EXPR_STMT (expr) = chainon (STMT_EXPR_STMT (expr), arg_inits);\n+\n+  /* Record the function we are about to inline so that we can avoid\n+     recursing into it.  */\n+  VARRAY_PUSH_TREE (id->fns, fn);\n+\n+  /* Record the function we are about to inline if optimize_function\n+     has not been called on it yet and we don't have it in the list.  */\n+  if (! DECL_INLINED_FNS (fn))\n+    {\n+      int i;\n+\n+      for (i = VARRAY_ACTIVE_SIZE (id->inlined_fns) - 1; i >= 0; i--)\n+\tif (VARRAY_TREE (id->inlined_fns, i) == fn)\n+\t  break;\n+      if (i < 0)\n+\tVARRAY_PUSH_TREE (id->inlined_fns, fn);\n+    }\n+\n+  /* Return statements in the function body will be replaced by jumps\n+     to the RET_LABEL.  */\n+  id->ret_label = build_decl (LABEL_DECL, NULL_TREE, NULL_TREE);\n+  DECL_CONTEXT (id->ret_label) = VARRAY_TREE (id->fns, 0);\n+\n+  /* Create a block to put the parameters in.  We have to do this\n+     after the parameters have been remapped because remapping\n+     parameters is different from remapping ordinary variables.  */\n+  scope_stmt = build_stmt (SCOPE_STMT, DECL_INITIAL (fn));\n+  SCOPE_BEGIN_P (scope_stmt) = 1;\n+  SCOPE_NO_CLEANUPS_P (scope_stmt) = 1;\n+  remap_block (scope_stmt, DECL_ARGUMENTS (fn), id);\n+  TREE_CHAIN (scope_stmt) = STMT_EXPR_STMT (expr);\n+  STMT_EXPR_STMT (expr) = scope_stmt;\n+\n+  /* Tell the debugging backends that this block represents the\n+     outermost scope of the inlined function.  */\n+  if (SCOPE_STMT_BLOCK (scope_stmt))\n+    BLOCK_ABSTRACT_ORIGIN (SCOPE_STMT_BLOCK (scope_stmt)) = DECL_ORIGIN (fn);\n+\n+  /* Declare the return variable for the function.  */\n+  STMT_EXPR_STMT (expr)\n+    = chainon (STMT_EXPR_STMT (expr),\n+\t       declare_return_variable (id, &use_stmt));\n+\n+  /* After we've initialized the parameters, we insert the body of the\n+     function itself.  */\n+  inlined_body = &STMT_EXPR_STMT (expr);\n+  while (*inlined_body)\n+    inlined_body = &TREE_CHAIN (*inlined_body);\n+  *inlined_body = copy_body (id);\n+\n+  /* Close the block for the parameters.  */\n+  scope_stmt = build_stmt (SCOPE_STMT, DECL_INITIAL (fn));\n+  SCOPE_NO_CLEANUPS_P (scope_stmt) = 1;\n+  if (! DECL_INITIAL (fn)\n+      || TREE_CODE (DECL_INITIAL (fn)) != BLOCK)\n+    abort ();\n+  remap_block (scope_stmt, NULL_TREE, id);\n+  STMT_EXPR_STMT (expr)\n+    = chainon (STMT_EXPR_STMT (expr), scope_stmt);\n+\n+  /* After the body of the function comes the RET_LABEL.  This must come\n+     before we evaluate the returned value below, because that evalulation\n+     may cause RTL to be generated.  */\n+  STMT_EXPR_STMT (expr)\n+    = chainon (STMT_EXPR_STMT (expr),\n+\t       build_stmt (LABEL_STMT, id->ret_label));\n+\n+  /* Finally, mention the returned value so that the value of the\n+     statement-expression is the returned value of the function.  */\n+  STMT_EXPR_STMT (expr) = chainon (STMT_EXPR_STMT (expr), use_stmt);\n+\n+  /* Clean up.  */\n+  splay_tree_delete (id->decl_map);\n+  id->decl_map = st;\n+\n+  /* The new expression has side-effects if the old one did.  */\n+  TREE_SIDE_EFFECTS (expr) = TREE_SIDE_EFFECTS (t);\n+\n+  /* Replace the call by the inlined body.  Wrap it in an\n+     EXPR_WITH_FILE_LOCATION so that we'll get debugging line notes\n+     pointing to the right place.  */\n+  chain = TREE_CHAIN (*tp);\n+  *tp = build_expr_wfl (expr, DECL_SOURCE_FILE (fn), DECL_SOURCE_LINE (fn),\n+\t\t\t/*col=*/0);\n+  EXPR_WFL_EMIT_LINE_NOTE (*tp) = 1;\n+  TREE_CHAIN (*tp) = chain;\n+  pop_srcloc ();\n+\n+  /* If the value of the new expression is ignored, that's OK.  We\n+     don't warn about this for CALL_EXPRs, so we shouldn't warn about\n+     the equivalent inlined version either.  */\n+  TREE_USED (*tp) = 1;\n+\n+  /* Our function now has more statements than it did before.  */\n+  DECL_NUM_STMTS (VARRAY_TREE (id->fns, 0)) += DECL_NUM_STMTS (fn);\n+  id->inlined_stmts += DECL_NUM_STMTS (fn);\n+\n+  /* Recurse into the body of the just inlined function.  */\n+  expand_calls_inline (inlined_body, id);\n+  VARRAY_POP (id->fns);\n+\n+  /* If we've returned to the top level, clear out the record of how\n+     much inlining has been done.  */\n+  if (VARRAY_ACTIVE_SIZE (id->fns) == id->first_inlined_fn)\n+    id->inlined_stmts = 0;\n+\n+  /* Don't walk into subtrees.  We've already handled them above.  */\n+  *walk_subtrees = 0;\n+\n+  /* Keep iterating.  */\n+  return NULL_TREE;\n+}\n+\n+/* Walk over the entire tree *TP, replacing CALL_EXPRs with inline\n+   expansions as appropriate.  */\n+\n+static void\n+expand_calls_inline (tp, id)\n+     tree *tp;\n+     inline_data *id;\n+{\n+  /* Search through *TP, replacing all calls to inline functions by\n+     appropriate equivalents.  Use walk_tree in no-duplicates mode\n+     to avoid exponential time complexity.  (We can't just use\n+     walk_tree_without_duplicates, because of the special TARGET_EXPR\n+     handling in expand_calls.  The hash table is set up in\n+     optimize_function.  */\n+  walk_tree (tp, expand_call_inline, id, id->tree_pruner);\n+}\n+\n+/* Expand calls to inline functions in the body of FN.  */\n+\n+void\n+optimize_inline_calls (fn)\n+     tree fn;\n+{\n+  inline_data id;\n+  tree prev_fn;\n+  \n+  /* Clear out ID.  */\n+  memset (&id, 0, sizeof (id));\n+\n+  /* Don't allow recursion into FN.  */\n+  VARRAY_TREE_INIT (id.fns, 32, \"fns\");\n+  VARRAY_PUSH_TREE (id.fns, fn);\n+  /* Or any functions that aren't finished yet.  */\n+  prev_fn = NULL_TREE;\n+  if (current_function_decl)\n+    {\n+      VARRAY_PUSH_TREE (id.fns, current_function_decl);\n+      prev_fn = current_function_decl;\n+    }\n+\n+  prev_fn = LANG_ADD_PENDING_FN_DECLS (&id.fns, prev_fn);\n+  \n+  /* Create the stack of TARGET_EXPRs.  */\n+  VARRAY_TREE_INIT (id.target_exprs, 32, \"target_exprs\");\n+\n+  /* Create the list of functions this call will inline.  */\n+  VARRAY_TREE_INIT (id.inlined_fns, 32, \"inlined_fns\");\n+\n+  /* Keep track of the low-water mark, i.e., the point where the first\n+     real inlining is represented in ID.FNS.  */\n+  id.first_inlined_fn = VARRAY_ACTIVE_SIZE (id.fns);\n+\n+  /* Replace all calls to inline functions with the bodies of those\n+     functions.  */\n+  id.tree_pruner = htab_create (37, htab_hash_pointer,\n+\t\t\t\thtab_eq_pointer, NULL);\n+  expand_calls_inline (&DECL_SAVED_TREE (fn), &id);\n+\n+  /* Clean up.  */\n+  htab_delete (id.tree_pruner);\n+  VARRAY_FREE (id.fns);\n+  VARRAY_FREE (id.target_exprs);\n+  if (DECL_LANG_SPECIFIC (fn))\n+    {\n+      tree ifn = make_tree_vec (VARRAY_ACTIVE_SIZE (id.inlined_fns));\n+      \n+      memcpy (&TREE_VEC_ELT (ifn, 0), &VARRAY_TREE (id.inlined_fns, 0),\n+\t      VARRAY_ACTIVE_SIZE (id.inlined_fns) * sizeof (tree));\n+      DECL_INLINED_FNS (fn) = ifn;\n+    }\n+  VARRAY_FREE (id.inlined_fns);\n+}\n+\n+/* FN is a function that has a complete body, and CLONE is a function\n+   whose body is to be set to a copy of FN, mapping argument\n+   declarations according to the ARG_MAP splay_tree.  */\n+\n+void\n+clone_body (clone, fn, arg_map)\n+     tree clone, fn;\n+     void *arg_map;\n+{\n+  inline_data id;\n+\n+  /* Clone the body, as if we were making an inline call.  But, remap\n+     the parameters in the callee to the parameters of caller.  If\n+     there's an in-charge parameter, map it to an appropriate\n+     constant.  */\n+  memset (&id, 0, sizeof (id));\n+  VARRAY_TREE_INIT (id.fns, 2, \"fns\");\n+  VARRAY_PUSH_TREE (id.fns, clone);\n+  VARRAY_PUSH_TREE (id.fns, fn);\n+  id.decl_map = (splay_tree)arg_map;\n+\n+  /* Cloning is treated slightly differently from inlining.  Set\n+     CLONING_P so that it's clear which operation we're performing.  */\n+  id.cloning_p = true;\n+\n+  /* Actually copy the body.  */\n+  TREE_CHAIN (DECL_SAVED_TREE (clone)) = copy_body (&id);\n+\n+  /* Clean up.  */\n+  VARRAY_FREE (id.fns);\n+}\n+\n+/* Apply FUNC to all the sub-trees of TP in a pre-order traversal.\n+   FUNC is called with the DATA and the address of each sub-tree.  If\n+   FUNC returns a non-NULL value, the traversal is aborted, and the\n+   value returned by FUNC is returned.  If HTAB is non-NULL it is used\n+   to record the nodes visited, and to avoid visiting a node more than\n+   once.  */\n+\n+tree \n+walk_tree (tp, func, data, htab_)\n+     tree *tp;\n+     walk_tree_fn func;\n+     void *data;\n+     void *htab_;\n+{\n+  htab_t htab = (htab_t) htab_;\n+  enum tree_code code;\n+  int walk_subtrees;\n+  tree result;\n+  \n+#define WALK_SUBTREE(NODE)\t\t\t\t\\\n+  do\t\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\\\n+      result = walk_tree (&(NODE), func, data, htab);\t\\\n+      if (result)\t\t\t\t\t\\\n+\treturn result;\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\\\n+  while (0)\n+\n+  /* Skip empty subtrees.  */\n+  if (!*tp)\n+    return NULL_TREE;\n+\n+  if (htab)\n+    {\n+      void **slot;\n+      \n+      /* Don't walk the same tree twice, if the user has requested\n+         that we avoid doing so. */\n+      if (htab_find (htab, *tp))\n+\treturn NULL_TREE;\n+      /* If we haven't already seen this node, add it to the table. */\n+      slot = htab_find_slot (htab, *tp, INSERT);\n+      *slot = *tp;\n+    }\n+\n+  /* Call the function.  */\n+  walk_subtrees = 1;\n+  result = (*func) (tp, &walk_subtrees, data);\n+\n+  /* If we found something, return it.  */\n+  if (result)\n+    return result;\n+\n+  code = TREE_CODE (*tp);\n+\n+  /* Even if we didn't, FUNC may have decided that there was nothing\n+     interesting below this point in the tree.  */\n+  if (!walk_subtrees)\n+    {\n+      if (statement_code_p (code) || code == TREE_LIST\n+\t  || LANG_TREE_CHAIN_MATTERS_P (*tp))\n+\t/* But we still need to check our siblings.  */\n+\treturn walk_tree (&TREE_CHAIN (*tp), func, data, htab);\n+      else\n+\treturn NULL_TREE;\n+    }\n+\n+  /* Handle common cases up front.  */\n+  if (IS_EXPR_CODE_CLASS (TREE_CODE_CLASS (code))\n+      || TREE_CODE_CLASS (code) == 'r'\n+      || TREE_CODE_CLASS (code) == 's')\n+    {\n+      int i, len;\n+\n+      /* Set lineno here so we get the right instantiation context\n+\t if we call instantiate_decl from inlinable_function_p.  */\n+      if (statement_code_p (code) && !STMT_LINENO_FOR_FN_P (*tp))\n+\tlineno = STMT_LINENO (*tp);\n+\n+      /* Walk over all the sub-trees of this operand.  */\n+      len = first_rtl_op (code);\n+      /* TARGET_EXPRs are peculiar: operands 1 and 3 can be the same.\n+\t But, we only want to walk once.  */\n+      if (code == TARGET_EXPR\n+\t  && TREE_OPERAND (*tp, 3) == TREE_OPERAND (*tp, 1))\n+\t--len;\n+      /* Go through the subtrees.  We need to do this in forward order so\n+         that the scope of a FOR_EXPR is handled properly.  */\n+      for (i = 0; i < len; ++i)\n+\tWALK_SUBTREE (TREE_OPERAND (*tp, i));\n+\n+      /* For statements, we also walk the chain so that we cover the\n+\t entire statement tree.  */\n+      if (statement_code_p (code))\n+\t{\n+\t  if (code == DECL_STMT \n+\t      && DECL_STMT_DECL (*tp) \n+\t      && DECL_P (DECL_STMT_DECL (*tp)))\n+\t    {\n+\t      /* Walk the DECL_INITIAL and DECL_SIZE.  We don't want to walk\n+\t\t into declarations that are just mentioned, rather than\n+\t\t declared; they don't really belong to this part of the tree.\n+\t\t And, we can see cycles: the initializer for a declaration can\n+\t\t refer to the declaration itself.  */\n+\t      WALK_SUBTREE (DECL_INITIAL (DECL_STMT_DECL (*tp)));\n+\t      WALK_SUBTREE (DECL_SIZE (DECL_STMT_DECL (*tp)));\n+\t      WALK_SUBTREE (DECL_SIZE_UNIT (DECL_STMT_DECL (*tp)));\n+\t    }\n+\n+\t  /* This can be tail-recursion optimized if we write it this way.  */\n+\t  return walk_tree (&TREE_CHAIN (*tp), func, data, htab);\n+\t}\n+\n+      /* We didn't find what we were looking for.  */\n+      return NULL_TREE;\n+    }\n+  else if (TREE_CODE_CLASS (code) == 'd')\n+    {\n+      WALK_SUBTREE (TREE_TYPE (*tp));\n+\n+      /* We didn't find what we were looking for.  */\n+      return NULL_TREE;\n+    }\n+\n+  result = LANG_WALK_SUBTREES (tp, &walk_subtrees, func, data, htab);\n+  if (result || ! walk_subtrees)\n+    return result;\n+\n+  /* Not one of the easy cases.  We must explicitly go through the\n+     children.  */\n+  switch (code)\n+    {\n+    case ERROR_MARK:\n+    case IDENTIFIER_NODE:\n+    case INTEGER_CST:\n+    case REAL_CST:\n+    case STRING_CST:\n+    case REAL_TYPE:\n+    case COMPLEX_TYPE:\n+    case VECTOR_TYPE:\n+    case VOID_TYPE:\n+    case BOOLEAN_TYPE:\n+    case UNION_TYPE:\n+    case ENUMERAL_TYPE:\n+    case BLOCK:\n+    case RECORD_TYPE:\n+      /* None of thse have subtrees other than those already walked\n+         above.  */\n+      break;\n+\n+    case POINTER_TYPE:\n+    case REFERENCE_TYPE:\n+      WALK_SUBTREE (TREE_TYPE (*tp));\n+      break;\n+\n+    case TREE_LIST:\n+      WALK_SUBTREE (TREE_VALUE (*tp));\n+      WALK_SUBTREE (TREE_CHAIN (*tp));\n+      break;\n+\n+    case TREE_VEC:\n+      {\n+\tint len = TREE_VEC_LENGTH (*tp);\n+\twhile (len--)\n+\t  WALK_SUBTREE (TREE_VEC_ELT (*tp, len));\n+      }\n+      break;\n+\n+    case COMPLEX_CST:\n+      WALK_SUBTREE (TREE_REALPART (*tp));\n+      WALK_SUBTREE (TREE_IMAGPART (*tp));\n+      break;\n+\n+    case CONSTRUCTOR:\n+      WALK_SUBTREE (CONSTRUCTOR_ELTS (*tp));\n+      break;\n+\n+    case METHOD_TYPE:\n+      WALK_SUBTREE (TYPE_METHOD_BASETYPE (*tp));\n+      /* Fall through.  */\n+\n+    case FUNCTION_TYPE:\n+      WALK_SUBTREE (TREE_TYPE (*tp));\n+      {\n+\ttree arg = TYPE_ARG_TYPES (*tp);\n+\n+\t/* We never want to walk into default arguments.  */\n+\tfor (; arg; arg = TREE_CHAIN (arg))\n+\t  WALK_SUBTREE (TREE_VALUE (arg));\n+      }\n+      break;\n+\n+    case ARRAY_TYPE:\n+      WALK_SUBTREE (TREE_TYPE (*tp));\n+      WALK_SUBTREE (TYPE_DOMAIN (*tp));\n+      break;\n+\n+    case INTEGER_TYPE:\n+      WALK_SUBTREE (TYPE_MIN_VALUE (*tp));\n+      WALK_SUBTREE (TYPE_MAX_VALUE (*tp));\n+      break;\n+\n+    case OFFSET_TYPE:\n+      WALK_SUBTREE (TREE_TYPE (*tp));\n+      WALK_SUBTREE (TYPE_OFFSET_BASETYPE (*tp));\n+      break;\n+\n+    default:\n+      abort ();\n+    }\n+\n+  /* We didn't find what we were looking for.  */\n+  return NULL_TREE;\n+\n+#undef WALK_SUBTREE\n+}\n+\n+/* Like walk_tree, but does not walk duplicate nodes more than \n+   once.  */\n+\n+tree \n+walk_tree_without_duplicates (tp, func, data)\n+     tree *tp;\n+     walk_tree_fn func;\n+     void *data;\n+{\n+  tree result;\n+  htab_t htab;\n+\n+  htab = htab_create (37, htab_hash_pointer, htab_eq_pointer, NULL);\n+  result = walk_tree (tp, func, data, htab);\n+  htab_delete (htab);\n+  return result;\n+}\n+\n+/* Passed to walk_tree.  Copies the node pointed to, if appropriate.  */\n+\n+tree\n+copy_tree_r (tp, walk_subtrees, data)\n+     tree *tp;\n+     int *walk_subtrees;\n+     void *data ATTRIBUTE_UNUSED;\n+{\n+  enum tree_code code = TREE_CODE (*tp);\n+\n+  /* We make copies of most nodes.  */\n+  if (IS_EXPR_CODE_CLASS (TREE_CODE_CLASS (code))\n+      || TREE_CODE_CLASS (code) == 'r'\n+      || TREE_CODE_CLASS (code) == 'c'\n+      || TREE_CODE_CLASS (code) == 's'\n+      || code == TREE_LIST\n+      || code == TREE_VEC\n+      || LANG_TREE_CHAIN_MATTERS_P (*tp))\n+    {\n+      /* Because the chain gets clobbered when we make a copy, we save it\n+\t here.  */\n+      tree chain = TREE_CHAIN (*tp);\n+\n+      /* Copy the node.  */\n+      *tp = copy_node (*tp);\n+\n+      /* Now, restore the chain, if appropriate.  That will cause\n+\t walk_tree to walk into the chain as well.  */\n+      if (code == PARM_DECL || code == TREE_LIST\n+\t  || LANG_TREE_CHAIN_MATTERS_P (*tp)\n+\t  || statement_code_p (code))\n+\tTREE_CHAIN (*tp) = chain;\n+\n+      /* For now, we don't update BLOCKs when we make copies.  So, we\n+\t have to nullify all scope-statements.  */\n+      if (TREE_CODE (*tp) == SCOPE_STMT)\n+\tSCOPE_STMT_BLOCK (*tp) = NULL_TREE;\n+    }\n+  else if (TREE_CODE_CLASS (code) == 't')\n+    /* There's no need to copy types, or anything beneath them.  */\n+    *walk_subtrees = 0;\n+\n+  return NULL_TREE;\n+}\n+\n+/* The SAVE_EXPR pointed to by TP is being copied.  If ST contains\n+   information indicating to what new SAVE_EXPR this one should be\n+   mapped, use that one.  Otherwise, create a new node and enter it in\n+   ST.  FN is the function into which the copy will be placed.  */\n+\n+void\n+remap_save_expr (tp, st_, fn, walk_subtrees)\n+     tree *tp;\n+     void *st_;\n+     tree fn;\n+     int *walk_subtrees;\n+{\n+  splay_tree st = (splay_tree) st_;\n+  splay_tree_node n;\n+\n+  /* See if we already encountered this SAVE_EXPR.  */\n+  n = splay_tree_lookup (st, (splay_tree_key) *tp);\n+      \n+  /* If we didn't already remap this SAVE_EXPR, do so now.  */\n+  if (!n)\n+    {\n+      tree t = copy_node (*tp);\n+\n+      /* The SAVE_EXPR is now part of the function into which we\n+\t are inlining this body.  */\n+      SAVE_EXPR_CONTEXT (t) = fn;\n+      /* And we haven't evaluated it yet.  */\n+      SAVE_EXPR_RTL (t) = NULL_RTX;\n+      /* Remember this SAVE_EXPR.  */\n+      n = splay_tree_insert (st,\n+\t\t\t     (splay_tree_key) *tp,\n+\t\t\t     (splay_tree_value) t);\n+    }\n+  else\n+    /* We've already walked into this SAVE_EXPR, so we needn't do it\n+       again.  */\n+    *walk_subtrees = 0;\n+\n+  /* Replace this SAVE_EXPR with the copy.  */\n+  *tp = (tree) n->value;\n+}"}]}