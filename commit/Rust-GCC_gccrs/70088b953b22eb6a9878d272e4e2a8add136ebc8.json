{"sha": "70088b953b22eb6a9878d272e4e2a8add136ebc8", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NzAwODhiOTUzYjIyZWI2YTk4NzhkMjcyZTRlMmE4YWRkMTM2ZWJjOA==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@linaro.org", "date": "2018-03-02T09:46:43Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2018-03-02T09:46:43Z"}, "message": "Avoid &LOOP_VINFO_MASKS for bb vectorisation (PR 84634)\n\nWe were computing &LOOP_VINFO_MASKS even for bb vectorisation,\nwhich is UB.\n\n2018-03-02  Richard Sandiford  <richard.sandiford@linaro.org>\n\ngcc/\n\tPR tree-optimization/84634\n\t* tree-vect-stmts.c (vectorizable_store, vectorizable_load): Replace\n\tmasks and masked_loop_p with a single loop_masks, making sure it's\n\tnull for bb vectorization.\n\nFrom-SVN: r258131", "tree": {"sha": "30a81e1764819990fcd27b036d7ab3045ad54b66", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/30a81e1764819990fcd27b036d7ab3045ad54b66"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/70088b953b22eb6a9878d272e4e2a8add136ebc8", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/70088b953b22eb6a9878d272e4e2a8add136ebc8", "html_url": "https://github.com/Rust-GCC/gccrs/commit/70088b953b22eb6a9878d272e4e2a8add136ebc8", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/70088b953b22eb6a9878d272e4e2a8add136ebc8/comments", "author": null, "committer": null, "parents": [{"sha": "962e91fcf043edab3684dd0564efd3df219d3cb1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/962e91fcf043edab3684dd0564efd3df219d3cb1", "html_url": "https://github.com/Rust-GCC/gccrs/commit/962e91fcf043edab3684dd0564efd3df219d3cb1"}], "stats": {"total": 47, "additions": 31, "deletions": 16}, "files": [{"sha": "4cadd4d2ca82a444b9c834c810b8df96518b51a7", "filename": "gcc/ChangeLog", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/70088b953b22eb6a9878d272e4e2a8add136ebc8/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/70088b953b22eb6a9878d272e4e2a8add136ebc8/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=70088b953b22eb6a9878d272e4e2a8add136ebc8", "patch": "@@ -1,3 +1,10 @@\n+2018-03-02  Richard Sandiford  <richard.sandiford@linaro.org>\n+\n+\tPR tree-optimization/84634\n+\t* tree-vect-stmts.c (vectorizable_store, vectorizable_load): Replace\n+\tmasks and masked_loop_p with a single loop_masks, making sure it's\n+\tnull for bb vectorization.\n+\n 2018-03-02  Richard Sandiford  <richard.sandiford@linaro.org>\n \n \t* tree-vect-data-refs.c (vect_analyze_data_ref_dependence)"}, {"sha": "7cdabe1106bed343611f1f8560759318a7686840", "filename": "gcc/tree-vect-stmts.c", "status": "modified", "additions": 24, "deletions": 16, "changes": 40, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/70088b953b22eb6a9878d272e4e2a8add136ebc8/gcc%2Ftree-vect-stmts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/70088b953b22eb6a9878d272e4e2a8add136ebc8/gcc%2Ftree-vect-stmts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-stmts.c?ref=70088b953b22eb6a9878d272e4e2a8add136ebc8", "patch": "@@ -6703,13 +6703,16 @@ vectorizable_store (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \n   alignment_support_scheme = vect_supportable_dr_alignment (first_dr, false);\n   gcc_assert (alignment_support_scheme);\n-  bool masked_loop_p = (loop_vinfo && LOOP_VINFO_FULLY_MASKED_P (loop_vinfo));\n+  vec_loop_masks *loop_masks\n+    = (loop_vinfo && LOOP_VINFO_FULLY_MASKED_P (loop_vinfo)\n+       ? &LOOP_VINFO_MASKS (loop_vinfo)\n+       : NULL);\n   /* Targets with store-lane instructions must not require explicit\n      realignment.  vect_supportable_dr_alignment always returns either\n      dr_aligned or dr_unaligned_supported for masked operations.  */\n   gcc_assert ((memory_access_type != VMAT_LOAD_STORE_LANES\n \t       && !mask\n-\t       && !masked_loop_p)\n+\t       && !loop_masks)\n \t      || alignment_support_scheme == dr_aligned\n \t      || alignment_support_scheme == dr_unaligned_supported);\n \n@@ -6783,7 +6786,6 @@ vectorizable_store (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \n   prev_stmt_info = NULL;\n   tree vec_mask = NULL_TREE;\n-  vec_loop_masks *masks = &LOOP_VINFO_MASKS (loop_vinfo);\n   for (j = 0; j < ncopies; j++)\n     {\n \n@@ -6900,8 +6902,9 @@ vectorizable_store (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \t    }\n \n \t  tree final_mask = NULL;\n-\t  if (masked_loop_p)\n-\t    final_mask = vect_get_loop_mask (gsi, masks, ncopies, vectype, j);\n+\t  if (loop_masks)\n+\t    final_mask = vect_get_loop_mask (gsi, loop_masks, ncopies,\n+\t\t\t\t\t     vectype, j);\n \t  if (vec_mask)\n \t    final_mask = prepare_load_store_mask (mask_vectype, final_mask,\n \t\t\t\t\t\t  vec_mask, gsi);\n@@ -6949,8 +6952,9 @@ vectorizable_store (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \t      unsigned align, misalign;\n \n \t      tree final_mask = NULL_TREE;\n-\t      if (masked_loop_p)\n-\t\tfinal_mask = vect_get_loop_mask (gsi, masks, vec_num * ncopies,\n+\t      if (loop_masks)\n+\t\tfinal_mask = vect_get_loop_mask (gsi, loop_masks,\n+\t\t\t\t\t\t vec_num * ncopies,\n \t\t\t\t\t\t vectype, vec_num * j + i);\n \t      if (vec_mask)\n \t\tfinal_mask = prepare_load_store_mask (mask_vectype, final_mask,\n@@ -6960,7 +6964,7 @@ vectorizable_store (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \t\t{\n \t\t  tree scale = size_int (gs_info.scale);\n \t\t  gcall *call;\n-\t\t  if (masked_loop_p)\n+\t\t  if (loop_masks)\n \t\t    call = gimple_build_call_internal\n \t\t      (IFN_MASK_SCATTER_STORE, 5, dataref_ptr, vec_offset,\n \t\t       scale, vec_oprnd, final_mask);\n@@ -7790,13 +7794,16 @@ vectorizable_load (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \n   alignment_support_scheme = vect_supportable_dr_alignment (first_dr, false);\n   gcc_assert (alignment_support_scheme);\n-  bool masked_loop_p = (loop_vinfo && LOOP_VINFO_FULLY_MASKED_P (loop_vinfo));\n+  vec_loop_masks *loop_masks\n+    = (loop_vinfo && LOOP_VINFO_FULLY_MASKED_P (loop_vinfo)\n+       ? &LOOP_VINFO_MASKS (loop_vinfo)\n+       : NULL);\n   /* Targets with store-lane instructions must not require explicit\n      realignment.  vect_supportable_dr_alignment always returns either\n      dr_aligned or dr_unaligned_supported for masked operations.  */\n   gcc_assert ((memory_access_type != VMAT_LOAD_STORE_LANES\n \t       && !mask\n-\t       && !masked_loop_p)\n+\t       && !loop_masks)\n \t      || alignment_support_scheme == dr_aligned\n \t      || alignment_support_scheme == dr_unaligned_supported);\n \n@@ -7956,7 +7963,6 @@ vectorizable_load (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n   tree vec_mask = NULL_TREE;\n   prev_stmt_info = NULL;\n   poly_uint64 group_elt = 0;\n-  vec_loop_masks *masks = &LOOP_VINFO_MASKS (loop_vinfo);\n   for (j = 0; j < ncopies; j++)\n     {\n       /* 1. Create the vector or array pointer update chain.  */\n@@ -8037,8 +8043,9 @@ vectorizable_load (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \t  vec_array = create_vector_array (vectype, vec_num);\n \n \t  tree final_mask = NULL_TREE;\n-\t  if (masked_loop_p)\n-\t    final_mask = vect_get_loop_mask (gsi, masks, ncopies, vectype, j);\n+\t  if (loop_masks)\n+\t    final_mask = vect_get_loop_mask (gsi, loop_masks, ncopies,\n+\t\t\t\t\t     vectype, j);\n \t  if (vec_mask)\n \t    final_mask = prepare_load_store_mask (mask_vectype, final_mask,\n \t\t\t\t\t\t  vec_mask, gsi);\n@@ -8083,9 +8090,10 @@ vectorizable_load (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \t  for (i = 0; i < vec_num; i++)\n \t    {\n \t      tree final_mask = NULL_TREE;\n-\t      if (masked_loop_p\n+\t      if (loop_masks\n \t\t  && memory_access_type != VMAT_INVARIANT)\n-\t\tfinal_mask = vect_get_loop_mask (gsi, masks, vec_num * ncopies,\n+\t\tfinal_mask = vect_get_loop_mask (gsi, loop_masks,\n+\t\t\t\t\t\t vec_num * ncopies,\n \t\t\t\t\t\t vectype, vec_num * j + i);\n \t      if (vec_mask)\n \t\tfinal_mask = prepare_load_store_mask (mask_vectype, final_mask,\n@@ -8107,7 +8115,7 @@ vectorizable_load (gimple *stmt, gimple_stmt_iterator *gsi, gimple **vec_stmt,\n \t\t      {\n \t\t\ttree scale = size_int (gs_info.scale);\n \t\t\tgcall *call;\n-\t\t\tif (masked_loop_p)\n+\t\t\tif (loop_masks)\n \t\t\t  call = gimple_build_call_internal\n \t\t\t    (IFN_MASK_GATHER_LOAD, 4, dataref_ptr,\n \t\t\t     vec_offset, scale, final_mask);"}]}