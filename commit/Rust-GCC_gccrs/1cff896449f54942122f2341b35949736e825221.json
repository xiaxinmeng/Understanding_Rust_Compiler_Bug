{"sha": "1cff896449f54942122f2341b35949736e825221", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MWNmZjg5NjQ0OWY1NDk0MjEyMmYyMzQxYjM1OTQ5NzM2ZTgyNTIyMQ==", "commit": {"author": {"name": "Ansgar Esztermann", "email": "ansgar@gcc.gnu.org", "date": "2003-03-13T16:05:23Z"}, "committer": {"name": "Ansgar Esztermann", "email": "ansgar@gcc.gnu.org", "date": "2003-03-13T16:05:23Z"}, "message": "Makefile.in (dojump.o): New target.\n\n2003-03-13  Ansgar Esztermann  <ansgar@thphy.uni-duesseldorf.de>\n\n\t* Makefile.in (dojump.o): New target.\n\n\t* dojump.c: New file.\n\t(init_pending_stack_adjust): Moved here from expr.c.\n\t(clear_pending_stack_adjust): Likewise.\n\t(do_pending_stack_adjust): Likewise.\n\t(jumpifnot): Likewise.\n\t(jumpif): Likewise.\n\t(do_jump): Likewise.\n\t(do_jump_by_parts_greater): Likewise.\n\t(do_jump_by_parts_greater_rtx): Likewise.\n\t(do_jump_by_parts_equality): Likewise.\n\t(do_jump_by_parts_equality_rtx): Likewise.\n\t(compare_from_rtx): Likewise.\n\t(do_compare_rtx_and_jump): Likewise.\n\t(do_compare_and_jump): Likewise.\n\n\t* expr.c (init_pending_stack_adjust): Removed to dojump.c.\n\t(clear_pending_stack_adjust): Likewise.\n\t(do_pending_stack_adjust): Likewise.\n\t(jumpifnot): Likewise.\n\t(jumpif): Likewise.\n\t(do_jump): Likewise.\n\t(do_jump_by_parts_greater): Likewise.\n\t(do_jump_by_parts_greater_rtx): Likewise.\n\t(do_jump_by_parts_equality): Likewise.\n\t(do_jump_by_parts_equality_rtx): Likewise.\n\t(compare_from_rtx): Likewise.\n\t(do_compare_rtx_and_jump): Likewise.\n\t(do_compare_and_jump): Likewise.\n\t(placeholder_list): Made declaration extern.\n\n\t* expr.h (placeholder_list): Declare.\n\nFrom-SVN: r64309", "tree": {"sha": "3f8d72c92b61aea9035a9bb9e6d44c030f8e1785", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/3f8d72c92b61aea9035a9bb9e6d44c030f8e1785"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/1cff896449f54942122f2341b35949736e825221", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1cff896449f54942122f2341b35949736e825221", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1cff896449f54942122f2341b35949736e825221", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1cff896449f54942122f2341b35949736e825221/comments", "author": null, "committer": null, "parents": [{"sha": "3bd104d1e8d2f637108626acef15d19c74b29195", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3bd104d1e8d2f637108626acef15d19c74b29195", "html_url": "https://github.com/Rust-GCC/gccrs/commit/3bd104d1e8d2f637108626acef15d19c74b29195"}], "stats": {"total": 2001, "additions": 1021, "deletions": 980}, "files": [{"sha": "e041fcff241af889af838f77f2a72428a30ccac5", "filename": "gcc/Makefile.in", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1cff896449f54942122f2341b35949736e825221/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1cff896449f54942122f2341b35949736e825221/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=1cff896449f54942122f2341b35949736e825221", "patch": "@@ -801,7 +801,7 @@ OBJS = alias.o bb-reorder.o bitmap.o builtins.o caller-save.o calls.o\t   \\\n  cfg.o cfganal.o cfgbuild.o cfgcleanup.o cfglayout.o cfgloop.o\t\t   \\\n  cfgloopanal.o cfgloopmanip.o loop-init.o loop-unswitch.o loop-unroll.o\t   \\\n  cfgrtl.o combine.o conflict.o convert.o cse.o cselib.o dbxout.o\t   \\\n- debug.o df.o diagnostic.o doloop.o dominance.o\t\t                   \\\n+ debug.o df.o diagnostic.o dojump.o doloop.o dominance.o\t\t         \\\n  dwarf2asm.o dwarf2out.o dwarfout.o emit-rtl.o except.o explow.o\t   \\\n  expmed.o expr.o final.o flow.o fold-const.o function.o gcse.o\t\t   \\\n  genrtl.o ggc-common.o global.o graph.o gtype-desc.o\t\t\t   \\\n@@ -1516,6 +1516,9 @@ expr.o : expr.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) $(TREE_H) f\n    function.h $(REGS_H) $(EXPR_H) $(OPTABS_H) libfuncs.h insn-attr.h insn-config.h \\\n    $(RECOG_H) output.h typeclass.h hard-reg-set.h toplev.h hard-reg-set.h \\\n    except.h reload.h $(GGC_H) langhooks.h intl.h $(TM_P_H) real.h\n+dojump.o : dojump.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) $(TREE_H) \\\n+   flags.h function.h $(EXPR_H) $(OPTABS_H) insn-attr.h insn-config.h \\\n+   langhooks.h\n builtins.o : builtins.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) $(RTL_H) $(TREE_H)\\\n    flags.h $(TARGET_H) function.h $(REGS_H) $(EXPR_H) $(OPTABS_H) insn-config.h \\\n    $(RECOG_H) output.h typeclass.h hard-reg-set.h toplev.h hard-reg-set.h \\"}, {"sha": "d028769223bee04443fc843cf1e9713d72ef662c", "filename": "gcc/dojump.c", "status": "added", "additions": 1014, "deletions": 0, "changes": 1014, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1cff896449f54942122f2341b35949736e825221/gcc%2Fdojump.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1cff896449f54942122f2341b35949736e825221/gcc%2Fdojump.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdojump.c?ref=1cff896449f54942122f2341b35949736e825221", "patch": "@@ -0,0 +1,1014 @@\n+/* Convert tree expression to rtl instructions, for GNU compiler.\n+   Copyright (C) 1988, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,\n+   2000, 2001, 2002, 2003 Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 2, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING.  If not, write to the Free\n+Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n+02111-1307, USA.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"rtl.h\"\n+#include \"tree.h\"\n+#include \"flags.h\"\n+#include \"function.h\"\n+#include \"insn-config.h\"\n+#include \"insn-attr.h\"\n+/* Include expr.h after insn-config.h so we get HAVE_conditional_move.  */\n+#include \"expr.h\"\n+#include \"optabs.h\"\n+#include \"langhooks.h\"\n+\n+static void do_jump_by_parts_greater PARAMS ((tree, int, rtx, rtx));\n+static void do_jump_by_parts_equality PARAMS ((tree, rtx, rtx));\n+static void do_compare_and_jump\tPARAMS ((tree, enum rtx_code, enum rtx_code,\n+\t\t\t\t\t rtx, rtx));\n+\n+/* At the start of a function, record that we have no previously-pushed\n+   arguments waiting to be popped.  */\n+\n+void\n+init_pending_stack_adjust ()\n+{\n+  pending_stack_adjust = 0;\n+}\n+\n+/* When exiting from function, if safe, clear out any pending stack adjust\n+   so the adjustment won't get done.\n+\n+   Note, if the current function calls alloca, then it must have a\n+   frame pointer regardless of the value of flag_omit_frame_pointer.  */\n+\n+void\n+clear_pending_stack_adjust ()\n+{\n+#ifdef EXIT_IGNORE_STACK\n+  if (optimize > 0\n+      && (! flag_omit_frame_pointer || current_function_calls_alloca)\n+      && EXIT_IGNORE_STACK\n+      && ! (DECL_INLINE (current_function_decl) && ! flag_no_inline)\n+      && ! flag_inline_functions)\n+    {\n+      stack_pointer_delta -= pending_stack_adjust,\n+      pending_stack_adjust = 0;\n+    }\n+#endif\n+}\n+\n+/* Pop any previously-pushed arguments that have not been popped yet.  */\n+\n+void\n+do_pending_stack_adjust ()\n+{\n+  if (inhibit_defer_pop == 0)\n+    {\n+      if (pending_stack_adjust != 0)\n+        adjust_stack (GEN_INT (pending_stack_adjust));\n+      pending_stack_adjust = 0;\n+    }\n+}\n+\f\n+/* Expand conditional expressions.  */\n+\n+/* Generate code to evaluate EXP and jump to LABEL if the value is zero.\n+   LABEL is an rtx of code CODE_LABEL, in this function and all the\n+   functions here.  */\n+\n+void\n+jumpifnot (exp, label)\n+     tree exp;\n+     rtx label;\n+{\n+  do_jump (exp, label, NULL_RTX);\n+}\n+\n+/* Generate code to evaluate EXP and jump to LABEL if the value is nonzero.  */\n+\n+void\n+jumpif (exp, label)\n+     tree exp;\n+     rtx label;\n+{\n+  do_jump (exp, NULL_RTX, label);\n+}\n+\n+/* Generate code to evaluate EXP and jump to IF_FALSE_LABEL if\n+   the result is zero, or IF_TRUE_LABEL if the result is one.\n+   Either of IF_FALSE_LABEL and IF_TRUE_LABEL may be zero,\n+   meaning fall through in that case.\n+\n+   do_jump always does any pending stack adjust except when it does not\n+   actually perform a jump.  An example where there is no jump\n+   is when EXP is `(foo (), 0)' and IF_FALSE_LABEL is null.\n+\n+   This function is responsible for optimizing cases such as\n+   &&, || and comparison operators in EXP.  */\n+\n+void\n+do_jump (exp, if_false_label, if_true_label)\n+     tree exp;\n+     rtx if_false_label, if_true_label;\n+{\n+  enum tree_code code = TREE_CODE (exp);\n+  /* Some cases need to create a label to jump to\n+     in order to properly fall through.\n+     These cases set DROP_THROUGH_LABEL nonzero.  */\n+  rtx drop_through_label = 0;\n+  rtx temp;\n+  int i;\n+  tree type;\n+  enum machine_mode mode;\n+\n+#ifdef MAX_INTEGER_COMPUTATION_MODE\n+  check_max_integer_computation_mode (exp);\n+#endif\n+\n+  emit_queue ();\n+\n+  switch (code)\n+    {\n+    case ERROR_MARK:\n+      break;\n+\n+    case INTEGER_CST:\n+      temp = integer_zerop (exp) ? if_false_label : if_true_label;\n+      if (temp)\n+        emit_jump (temp);\n+      break;\n+\n+#if 0\n+      /* This is not true with #pragma weak  */\n+    case ADDR_EXPR:\n+      /* The address of something can never be zero.  */\n+      if (if_true_label)\n+        emit_jump (if_true_label);\n+      break;\n+#endif\n+\n+    case NOP_EXPR:\n+      if (TREE_CODE (TREE_OPERAND (exp, 0)) == COMPONENT_REF\n+          || TREE_CODE (TREE_OPERAND (exp, 0)) == BIT_FIELD_REF\n+          || TREE_CODE (TREE_OPERAND (exp, 0)) == ARRAY_REF\n+          || TREE_CODE (TREE_OPERAND (exp, 0)) == ARRAY_RANGE_REF)\n+        goto normal;\n+    case CONVERT_EXPR:\n+      /* If we are narrowing the operand, we have to do the compare in the\n+         narrower mode.  */\n+      if ((TYPE_PRECISION (TREE_TYPE (exp))\n+           < TYPE_PRECISION (TREE_TYPE (TREE_OPERAND (exp, 0)))))\n+        goto normal;\n+    case NON_LVALUE_EXPR:\n+    case REFERENCE_EXPR:\n+    case ABS_EXPR:\n+    case NEGATE_EXPR:\n+    case LROTATE_EXPR:\n+    case RROTATE_EXPR:\n+      /* These cannot change zero->nonzero or vice versa.  */\n+      do_jump (TREE_OPERAND (exp, 0), if_false_label, if_true_label);\n+      break;\n+\n+    case WITH_RECORD_EXPR:\n+      /* Put the object on the placeholder list, recurse through our first\n+         operand, and pop the list.  */\n+      placeholder_list = tree_cons (TREE_OPERAND (exp, 1), NULL_TREE,\n+                                    placeholder_list);\n+      do_jump (TREE_OPERAND (exp, 0), if_false_label, if_true_label);\n+      placeholder_list = TREE_CHAIN (placeholder_list);\n+      break;\n+\n+#if 0\n+      /* This is never less insns than evaluating the PLUS_EXPR followed by\n+         a test and can be longer if the test is eliminated.  */\n+    case PLUS_EXPR:\n+      /* Reduce to minus.  */\n+      exp = build (MINUS_EXPR, TREE_TYPE (exp),\n+                   TREE_OPERAND (exp, 0),\n+                   fold (build1 (NEGATE_EXPR, TREE_TYPE (TREE_OPERAND (exp, 1)),\n+                                 TREE_OPERAND (exp, 1))));\n+      /* Process as MINUS.  */\n+#endif\n+\n+    case MINUS_EXPR:\n+      /* Nonzero iff operands of minus differ.  */\n+      do_compare_and_jump (build (NE_EXPR, TREE_TYPE (exp),\n+                                  TREE_OPERAND (exp, 0),\n+                                  TREE_OPERAND (exp, 1)),\n+                           NE, NE, if_false_label, if_true_label);\n+      break;\n+\n+    case BIT_AND_EXPR:\n+      /* If we are AND'ing with a small constant, do this comparison in the\n+         smallest type that fits.  If the machine doesn't have comparisons\n+         that small, it will be converted back to the wider comparison.\n+         This helps if we are testing the sign bit of a narrower object.\n+         combine can't do this for us because it can't know whether a\n+         ZERO_EXTRACT or a compare in a smaller mode exists, but we do.  */\n+\n+      if (! SLOW_BYTE_ACCESS\n+          && TREE_CODE (TREE_OPERAND (exp, 1)) == INTEGER_CST\n+          && TYPE_PRECISION (TREE_TYPE (exp)) <= HOST_BITS_PER_WIDE_INT\n+          && (i = tree_floor_log2 (TREE_OPERAND (exp, 1))) >= 0\n+          && (mode = mode_for_size (i + 1, MODE_INT, 0)) != BLKmode\n+          && (type = (*lang_hooks.types.type_for_mode) (mode, 1)) != 0\n+          && TYPE_PRECISION (type) < TYPE_PRECISION (TREE_TYPE (exp))\n+          && (cmp_optab->handlers[(int) TYPE_MODE (type)].insn_code\n+              != CODE_FOR_nothing))\n+        {\n+          do_jump (convert (type, exp), if_false_label, if_true_label);\n+          break;\n+        }\n+      goto normal;\n+\n+    case TRUTH_NOT_EXPR:\n+      do_jump (TREE_OPERAND (exp, 0), if_true_label, if_false_label);\n+      break;\n+\n+    case TRUTH_ANDIF_EXPR:\n+      if (if_false_label == 0)\n+        if_false_label = drop_through_label = gen_label_rtx ();\n+      do_jump (TREE_OPERAND (exp, 0), if_false_label, NULL_RTX);\n+      start_cleanup_deferral ();\n+      do_jump (TREE_OPERAND (exp, 1), if_false_label, if_true_label);\n+      end_cleanup_deferral ();\n+      break;\n+\n+    case TRUTH_ORIF_EXPR:\n+      if (if_true_label == 0)\n+        if_true_label = drop_through_label = gen_label_rtx ();\n+      do_jump (TREE_OPERAND (exp, 0), NULL_RTX, if_true_label);\n+      start_cleanup_deferral ();\n+      do_jump (TREE_OPERAND (exp, 1), if_false_label, if_true_label);\n+      end_cleanup_deferral ();\n+      break;\n+\n+    case COMPOUND_EXPR:\n+      push_temp_slots ();\n+      expand_expr (TREE_OPERAND (exp, 0), const0_rtx, VOIDmode, 0);\n+      preserve_temp_slots (NULL_RTX);\n+      free_temp_slots ();\n+      pop_temp_slots ();\n+      emit_queue ();\n+      do_pending_stack_adjust ();\n+      do_jump (TREE_OPERAND (exp, 1), if_false_label, if_true_label);\n+      break;\n+\n+    case COMPONENT_REF:\n+    case BIT_FIELD_REF:\n+    case ARRAY_REF:\n+    case ARRAY_RANGE_REF:\n+      {\n+        HOST_WIDE_INT bitsize, bitpos;\n+        int unsignedp;\n+        enum machine_mode mode;\n+        tree type;\n+        tree offset;\n+        int volatilep = 0;\n+\n+        /* Get description of this reference.  We don't actually care\n+           about the underlying object here.  */\n+        get_inner_reference (exp, &bitsize, &bitpos, &offset, &mode,\n+                             &unsignedp, &volatilep);\n+\n+        type = (*lang_hooks.types.type_for_size) (bitsize, unsignedp);\n+        if (! SLOW_BYTE_ACCESS\n+            && type != 0 && bitsize >= 0\n+            && TYPE_PRECISION (type) < TYPE_PRECISION (TREE_TYPE (exp))\n+            && (cmp_optab->handlers[(int) TYPE_MODE (type)].insn_code\n+          != CODE_FOR_nothing))\n+          {\n+            do_jump (convert (type, exp), if_false_label, if_true_label);\n+            break;\n+          }\n+        goto normal;\n+      }\n+\n+    case COND_EXPR:\n+      /* Do (a ? 1 : 0) and (a ? 0 : 1) as special cases.  */\n+      if (integer_onep (TREE_OPERAND (exp, 1))\n+          && integer_zerop (TREE_OPERAND (exp, 2)))\n+        do_jump (TREE_OPERAND (exp, 0), if_false_label, if_true_label);\n+\n+      else if (integer_zerop (TREE_OPERAND (exp, 1))\n+               && integer_onep (TREE_OPERAND (exp, 2)))\n+        do_jump (TREE_OPERAND (exp, 0), if_true_label, if_false_label);\n+\n+      else\n+      {\n+        rtx label1 = gen_label_rtx ();\n+        drop_through_label = gen_label_rtx ();\n+\n+        do_jump (TREE_OPERAND (exp, 0), label1, NULL_RTX);\n+\n+        start_cleanup_deferral ();\n+        /* Now the THEN-expression.  */\n+        do_jump (TREE_OPERAND (exp, 1),\n+                 if_false_label ? if_false_label : drop_through_label,\n+                 if_true_label ? if_true_label : drop_through_label);\n+        /* In case the do_jump just above never jumps.  */\n+        do_pending_stack_adjust ();\n+        emit_label (label1);\n+\n+        /* Now the ELSE-expression.  */\n+        do_jump (TREE_OPERAND (exp, 2),\n+           if_false_label ? if_false_label : drop_through_label,\n+           if_true_label ? if_true_label : drop_through_label);\n+        end_cleanup_deferral ();\n+      }\n+      break;\n+\n+    case EQ_EXPR:\n+      {\n+        tree inner_type = TREE_TYPE (TREE_OPERAND (exp, 0));\n+\n+        if (GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_COMPLEX_FLOAT\n+            || GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_COMPLEX_INT)\n+          {\n+            tree exp0 = save_expr (TREE_OPERAND (exp, 0));\n+            tree exp1 = save_expr (TREE_OPERAND (exp, 1));\n+            do_jump\n+              (fold\n+               (build (TRUTH_ANDIF_EXPR, TREE_TYPE (exp),\n+                 fold (build (EQ_EXPR, TREE_TYPE (exp),\n+                  fold (build1 (REALPART_EXPR,\n+                    TREE_TYPE (inner_type),\n+                    exp0)),\n+                  fold (build1 (REALPART_EXPR,\n+                    TREE_TYPE (inner_type),\n+                    exp1)))),\n+                 fold (build (EQ_EXPR, TREE_TYPE (exp),\n+                  fold (build1 (IMAGPART_EXPR,\n+                    TREE_TYPE (inner_type),\n+                    exp0)),\n+                  fold (build1 (IMAGPART_EXPR,\n+                    TREE_TYPE (inner_type),\n+                    exp1)))))),\n+               if_false_label, if_true_label);\n+          }\n+\n+        else if (integer_zerop (TREE_OPERAND (exp, 1)))\n+          do_jump (TREE_OPERAND (exp, 0), if_true_label, if_false_label);\n+\n+        else if (GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_INT\n+                 && !can_compare_p (EQ, TYPE_MODE (inner_type), ccp_jump))\n+          do_jump_by_parts_equality (exp, if_false_label, if_true_label);\n+        else\n+          do_compare_and_jump (exp, EQ, EQ, if_false_label, if_true_label);\n+        break;\n+      }\n+\n+    case NE_EXPR:\n+      {\n+        tree inner_type = TREE_TYPE (TREE_OPERAND (exp, 0));\n+\n+        if (GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_COMPLEX_FLOAT\n+            || GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_COMPLEX_INT)\n+          {\n+            tree exp0 = save_expr (TREE_OPERAND (exp, 0));\n+            tree exp1 = save_expr (TREE_OPERAND (exp, 1));\n+            do_jump\n+              (fold\n+               (build (TRUTH_ORIF_EXPR, TREE_TYPE (exp),\n+                 fold (build (NE_EXPR, TREE_TYPE (exp),\n+                  fold (build1 (REALPART_EXPR,\n+                    TREE_TYPE (inner_type),\n+                    exp0)),\n+                  fold (build1 (REALPART_EXPR,\n+                    TREE_TYPE (inner_type),\n+                    exp1)))),\n+                 fold (build (NE_EXPR, TREE_TYPE (exp),\n+                    fold (build1 (IMAGPART_EXPR,\n+                      TREE_TYPE (inner_type),\n+                      exp0)),\n+                    fold (build1 (IMAGPART_EXPR,\n+                      TREE_TYPE (inner_type),\n+                      exp1)))))),\n+               if_false_label, if_true_label);\n+          }\n+\n+        else if (integer_zerop (TREE_OPERAND (exp, 1)))\n+          do_jump (TREE_OPERAND (exp, 0), if_false_label, if_true_label);\n+\n+        else if (GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_INT\n+           && !can_compare_p (NE, TYPE_MODE (inner_type), ccp_jump))\n+          do_jump_by_parts_equality (exp, if_true_label, if_false_label);\n+        else\n+          do_compare_and_jump (exp, NE, NE, if_false_label, if_true_label);\n+        break;\n+      }\n+\n+    case LT_EXPR:\n+      mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n+      if (GET_MODE_CLASS (mode) == MODE_INT\n+          && ! can_compare_p (LT, mode, ccp_jump))\n+        do_jump_by_parts_greater (exp, 1, if_false_label, if_true_label);\n+      else\n+        do_compare_and_jump (exp, LT, LTU, if_false_label, if_true_label);\n+      break;\n+\n+    case LE_EXPR:\n+      mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n+      if (GET_MODE_CLASS (mode) == MODE_INT\n+          && ! can_compare_p (LE, mode, ccp_jump))\n+        do_jump_by_parts_greater (exp, 0, if_true_label, if_false_label);\n+      else\n+        do_compare_and_jump (exp, LE, LEU, if_false_label, if_true_label);\n+      break;\n+\n+    case GT_EXPR:\n+      mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n+      if (GET_MODE_CLASS (mode) == MODE_INT\n+          && ! can_compare_p (GT, mode, ccp_jump))\n+        do_jump_by_parts_greater (exp, 0, if_false_label, if_true_label);\n+      else\n+        do_compare_and_jump (exp, GT, GTU, if_false_label, if_true_label);\n+      break;\n+\n+    case GE_EXPR:\n+      mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n+      if (GET_MODE_CLASS (mode) == MODE_INT\n+          && ! can_compare_p (GE, mode, ccp_jump))\n+        do_jump_by_parts_greater (exp, 1, if_true_label, if_false_label);\n+      else\n+        do_compare_and_jump (exp, GE, GEU, if_false_label, if_true_label);\n+      break;\n+\n+    case UNORDERED_EXPR:\n+    case ORDERED_EXPR:\n+      {\n+        enum rtx_code cmp, rcmp;\n+        int do_rev;\n+\n+        if (code == UNORDERED_EXPR)\n+          cmp = UNORDERED, rcmp = ORDERED;\n+        else\n+          cmp = ORDERED, rcmp = UNORDERED;\n+        mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n+\n+        do_rev = 0;\n+        if (! can_compare_p (cmp, mode, ccp_jump)\n+            && (can_compare_p (rcmp, mode, ccp_jump)\n+          /* If the target doesn't provide either UNORDERED or ORDERED\n+             comparisons, canonicalize on UNORDERED for the library.  */\n+          || rcmp == UNORDERED))\n+          do_rev = 1;\n+\n+        if (! do_rev)\n+          do_compare_and_jump (exp, cmp, cmp, if_false_label, if_true_label);\n+        else\n+          do_compare_and_jump (exp, rcmp, rcmp, if_true_label, if_false_label);\n+      }\n+      break;\n+\n+    {\n+      enum rtx_code rcode1;\n+      enum tree_code tcode2;\n+\n+      case UNLT_EXPR:\n+        rcode1 = UNLT;\n+        tcode2 = LT_EXPR;\n+        goto unordered_bcc;\n+      case UNLE_EXPR:\n+        rcode1 = UNLE;\n+        tcode2 = LE_EXPR;\n+        goto unordered_bcc;\n+      case UNGT_EXPR:\n+        rcode1 = UNGT;\n+        tcode2 = GT_EXPR;\n+        goto unordered_bcc;\n+      case UNGE_EXPR:\n+        rcode1 = UNGE;\n+        tcode2 = GE_EXPR;\n+        goto unordered_bcc;\n+      case UNEQ_EXPR:\n+        rcode1 = UNEQ;\n+        tcode2 = EQ_EXPR;\n+        goto unordered_bcc;\n+\n+      unordered_bcc:\n+        mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n+        if (can_compare_p (rcode1, mode, ccp_jump))\n+          do_compare_and_jump (exp, rcode1, rcode1, if_false_label,\n+                               if_true_label);\n+        else\n+          {\n+            tree op0 = save_expr (TREE_OPERAND (exp, 0));\n+            tree op1 = save_expr (TREE_OPERAND (exp, 1));\n+            tree cmp0, cmp1;\n+\n+            /* If the target doesn't support combined unordered\n+               compares, decompose into UNORDERED + comparison.  */\n+            cmp0 = fold (build (UNORDERED_EXPR, TREE_TYPE (exp), op0, op1));\n+            cmp1 = fold (build (tcode2, TREE_TYPE (exp), op0, op1));\n+            exp = build (TRUTH_ORIF_EXPR, TREE_TYPE (exp), cmp0, cmp1);\n+            do_jump (exp, if_false_label, if_true_label);\n+          }\n+      }\n+      break;\n+\n+      /* Special case:\n+          __builtin_expect (<test>, 0)\tand\n+          __builtin_expect (<test>, 1)\n+\n+         We need to do this here, so that <test> is not converted to a SCC\n+         operation on machines that use condition code registers and COMPARE\n+         like the PowerPC, and then the jump is done based on whether the SCC\n+         operation produced a 1 or 0.  */\n+    case CALL_EXPR:\n+      /* Check for a built-in function.  */\n+      if (TREE_CODE (TREE_OPERAND (exp, 0)) == ADDR_EXPR)\n+        {\n+          tree fndecl = TREE_OPERAND (TREE_OPERAND (exp, 0), 0);\n+          tree arglist = TREE_OPERAND (exp, 1);\n+\n+      if (TREE_CODE (fndecl) == FUNCTION_DECL\n+          && DECL_BUILT_IN (fndecl)\n+          && DECL_FUNCTION_CODE (fndecl) == BUILT_IN_EXPECT\n+          && arglist != NULL_TREE\n+          && TREE_CHAIN (arglist) != NULL_TREE)\n+        {\n+          rtx seq = expand_builtin_expect_jump (exp, if_false_label,\n+                                                if_true_label);\n+\n+          if (seq != NULL_RTX)\n+            {\n+              emit_insn (seq);\n+              return;\n+            }\n+        }\n+    }\n+      /* fall through and generate the normal code.  */\n+\n+    default:\n+    normal:\n+      temp = expand_expr (exp, NULL_RTX, VOIDmode, 0);\n+#if 0\n+      /* This is not needed any more and causes poor code since it causes\n+         comparisons and tests from non-SI objects to have different code\n+         sequences.  */\n+      /* Copy to register to avoid generating bad insns by cse\n+         from (set (mem ...) (arithop))  (set (cc0) (mem ...)).  */\n+      if (!cse_not_expected && GET_CODE (temp) == MEM)\n+        temp = copy_to_reg (temp);\n+#endif\n+      do_pending_stack_adjust ();\n+      /* Do any postincrements in the expression that was tested.  */\n+      emit_queue ();\n+\n+      if (GET_CODE (temp) == CONST_INT\n+          || (GET_CODE (temp) == CONST_DOUBLE && GET_MODE (temp) == VOIDmode)\n+          || GET_CODE (temp) == LABEL_REF)\n+        {\n+          rtx target = temp == const0_rtx ? if_false_label : if_true_label;\n+          if (target)\n+            emit_jump (target);\n+        }\n+      else if (GET_MODE_CLASS (GET_MODE (temp)) == MODE_INT\n+               && ! can_compare_p (NE, GET_MODE (temp), ccp_jump))\n+        /* Note swapping the labels gives us not-equal.  */\n+        do_jump_by_parts_equality_rtx (temp, if_true_label, if_false_label);\n+      else if (GET_MODE (temp) != VOIDmode)\n+        do_compare_rtx_and_jump (temp, CONST0_RTX (GET_MODE (temp)),\n+                                 NE, TREE_UNSIGNED (TREE_TYPE (exp)),\n+                                 GET_MODE (temp), NULL_RTX,\n+                                 if_false_label, if_true_label);\n+      else\n+        abort ();\n+    }\n+\n+  if (drop_through_label)\n+    {\n+      /* If do_jump produces code that might be jumped around,\n+         do any stack adjusts from that code, before the place\n+         where control merges in.  */\n+      do_pending_stack_adjust ();\n+      emit_label (drop_through_label);\n+    }\n+}\n+\f\n+/* Given a comparison expression EXP for values too wide to be compared\n+   with one insn, test the comparison and jump to the appropriate label.\n+   The code of EXP is ignored; we always test GT if SWAP is 0,\n+   and LT if SWAP is 1.  */\n+\n+static void\n+do_jump_by_parts_greater (exp, swap, if_false_label, if_true_label)\n+     tree exp;\n+     int swap;\n+     rtx if_false_label, if_true_label;\n+{\n+  rtx op0 = expand_expr (TREE_OPERAND (exp, swap), NULL_RTX, VOIDmode, 0);\n+  rtx op1 = expand_expr (TREE_OPERAND (exp, !swap), NULL_RTX, VOIDmode, 0);\n+  enum machine_mode mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n+  int unsignedp = TREE_UNSIGNED (TREE_TYPE (TREE_OPERAND (exp, 0)));\n+\n+  do_jump_by_parts_greater_rtx (mode, unsignedp, op0, op1, if_false_label, if_true_label);\n+}\n+\n+/* Compare OP0 with OP1, word at a time, in mode MODE.\n+   UNSIGNEDP says to do unsigned comparison.\n+   Jump to IF_TRUE_LABEL if OP0 is greater, IF_FALSE_LABEL otherwise.  */\n+\n+void\n+do_jump_by_parts_greater_rtx (mode, unsignedp, op0, op1, if_false_label, if_true_label)\n+     enum machine_mode mode;\n+     int unsignedp;\n+     rtx op0, op1;\n+     rtx if_false_label, if_true_label;\n+{\n+  int nwords = (GET_MODE_SIZE (mode) / UNITS_PER_WORD);\n+  rtx drop_through_label = 0;\n+  int i;\n+\n+  if (! if_true_label || ! if_false_label)\n+    drop_through_label = gen_label_rtx ();\n+  if (! if_true_label)\n+    if_true_label = drop_through_label;\n+  if (! if_false_label)\n+    if_false_label = drop_through_label;\n+\n+  /* Compare a word at a time, high order first.  */\n+  for (i = 0; i < nwords; i++)\n+    {\n+      rtx op0_word, op1_word;\n+\n+      if (WORDS_BIG_ENDIAN)\n+        {\n+          op0_word = operand_subword_force (op0, i, mode);\n+          op1_word = operand_subword_force (op1, i, mode);\n+        }\n+      else\n+        {\n+          op0_word = operand_subword_force (op0, nwords - 1 - i, mode);\n+          op1_word = operand_subword_force (op1, nwords - 1 - i, mode);\n+        }\n+\n+      /* All but high-order word must be compared as unsigned.  */\n+      do_compare_rtx_and_jump (op0_word, op1_word, GT,\n+                               (unsignedp || i > 0), word_mode, NULL_RTX,\n+                               NULL_RTX, if_true_label);\n+\n+      /* Consider lower words only if these are equal.  */\n+      do_compare_rtx_and_jump (op0_word, op1_word, NE, unsignedp, word_mode,\n+                               NULL_RTX, NULL_RTX, if_false_label);\n+    }\n+\n+  if (if_false_label)\n+    emit_jump (if_false_label);\n+  if (drop_through_label)\n+    emit_label (drop_through_label);\n+}\n+\n+/* Given an EQ_EXPR expression EXP for values too wide to be compared\n+   with one insn, test the comparison and jump to the appropriate label.  */\n+\n+static void\n+do_jump_by_parts_equality (exp, if_false_label, if_true_label)\n+     tree exp;\n+     rtx if_false_label, if_true_label;\n+{\n+  rtx op0 = expand_expr (TREE_OPERAND (exp, 0), NULL_RTX, VOIDmode, 0);\n+  rtx op1 = expand_expr (TREE_OPERAND (exp, 1), NULL_RTX, VOIDmode, 0);\n+  enum machine_mode mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n+  int nwords = (GET_MODE_SIZE (mode) / UNITS_PER_WORD);\n+  int i;\n+  rtx drop_through_label = 0;\n+\n+  if (! if_false_label)\n+    drop_through_label = if_false_label = gen_label_rtx ();\n+\n+  for (i = 0; i < nwords; i++)\n+    do_compare_rtx_and_jump (operand_subword_force (op0, i, mode),\n+                             operand_subword_force (op1, i, mode),\n+                             EQ, TREE_UNSIGNED (TREE_TYPE (exp)),\n+                             word_mode, NULL_RTX, if_false_label, NULL_RTX);\n+\n+  if (if_true_label)\n+    emit_jump (if_true_label);\n+  if (drop_through_label)\n+    emit_label (drop_through_label);\n+}\n+\f\n+/* Jump according to whether OP0 is 0.\n+   We assume that OP0 has an integer mode that is too wide\n+   for the available compare insns.  */\n+\n+void\n+do_jump_by_parts_equality_rtx (op0, if_false_label, if_true_label)\n+     rtx op0;\n+     rtx if_false_label, if_true_label;\n+{\n+  int nwords = GET_MODE_SIZE (GET_MODE (op0)) / UNITS_PER_WORD;\n+  rtx part;\n+  int i;\n+  rtx drop_through_label = 0;\n+\n+  /* The fastest way of doing this comparison on almost any machine is to\n+     \"or\" all the words and compare the result.  If all have to be loaded\n+     from memory and this is a very wide item, it's possible this may\n+     be slower, but that's highly unlikely.  */\n+\n+  part = gen_reg_rtx (word_mode);\n+  emit_move_insn (part, operand_subword_force (op0, 0, GET_MODE (op0)));\n+  for (i = 1; i < nwords && part != 0; i++)\n+    part = expand_binop (word_mode, ior_optab, part,\n+                         operand_subword_force (op0, i, GET_MODE (op0)),\n+                         part, 1, OPTAB_WIDEN);\n+\n+  if (part != 0)\n+    {\n+      do_compare_rtx_and_jump (part, const0_rtx, EQ, 1, word_mode,\n+                               NULL_RTX, if_false_label, if_true_label);\n+\n+      return;\n+    }\n+\n+  /* If we couldn't do the \"or\" simply, do this with a series of compares.  */\n+  if (! if_false_label)\n+    drop_through_label = if_false_label = gen_label_rtx ();\n+\n+  for (i = 0; i < nwords; i++)\n+    do_compare_rtx_and_jump (operand_subword_force (op0, i, GET_MODE (op0)),\n+                             const0_rtx, EQ, 1, word_mode, NULL_RTX,\n+                             if_false_label, NULL_RTX);\n+\n+  if (if_true_label)\n+    emit_jump (if_true_label);\n+\n+  if (drop_through_label)\n+    emit_label (drop_through_label);\n+}\n+\f\n+/* Generate code for a comparison of OP0 and OP1 with rtx code CODE.\n+   (including code to compute the values to be compared)\n+   and set (CC0) according to the result.\n+   The decision as to signed or unsigned comparison must be made by the caller.\n+\n+   We force a stack adjustment unless there are currently\n+   things pushed on the stack that aren't yet used.\n+\n+   If MODE is BLKmode, SIZE is an RTX giving the size of the objects being\n+   compared.  */\n+\n+rtx\n+compare_from_rtx (op0, op1, code, unsignedp, mode, size)\n+     rtx op0, op1;\n+     enum rtx_code code;\n+     int unsignedp;\n+     enum machine_mode mode;\n+     rtx size;\n+{\n+  enum rtx_code ucode;\n+  rtx tem;\n+\n+  /* If one operand is constant, make it the second one.  Only do this\n+     if the other operand is not constant as well.  */\n+\n+  if (swap_commutative_operands_p (op0, op1))\n+    {\n+      tem = op0;\n+      op0 = op1;\n+      op1 = tem;\n+      code = swap_condition (code);\n+    }\n+\n+  if (flag_force_mem)\n+    {\n+      op0 = force_not_mem (op0);\n+      op1 = force_not_mem (op1);\n+    }\n+\n+  do_pending_stack_adjust ();\n+\n+  ucode = unsignedp ? unsigned_condition (code) : code;\n+  if ((tem = simplify_relational_operation (ucode, mode, op0, op1)) != 0)\n+    return tem;\n+\n+#if 0\n+  /* There's no need to do this now that combine.c can eliminate lots of\n+     sign extensions.  This can be less efficient in certain cases on other\n+     machines.  */\n+\n+  /* If this is a signed equality comparison, we can do it as an\n+     unsigned comparison since zero-extension is cheaper than sign\n+     extension and comparisons with zero are done as unsigned.  This is\n+     the case even on machines that can do fast sign extension, since\n+     zero-extension is easier to combine with other operations than\n+     sign-extension is.  If we are comparing against a constant, we must\n+     convert it to what it would look like unsigned.  */\n+  if ((code == EQ || code == NE) && ! unsignedp\n+      && GET_MODE_BITSIZE (GET_MODE (op0)) <= HOST_BITS_PER_WIDE_INT)\n+    {\n+      if (GET_CODE (op1) == CONST_INT\n+          && (INTVAL (op1) & GET_MODE_MASK (GET_MODE (op0))) != INTVAL (op1))\n+        op1 = GEN_INT (INTVAL (op1) & GET_MODE_MASK (GET_MODE (op0)));\n+      unsignedp = 1;\n+    }\n+#endif\n+\n+  emit_cmp_insn (op0, op1, code, size, mode, unsignedp);\n+\n+#if HAVE_cc0\n+  return gen_rtx_fmt_ee (code, VOIDmode, cc0_rtx, const0_rtx);\n+#else\n+  return gen_rtx_fmt_ee (code, VOIDmode, op0, op1);\n+#endif\n+}\n+\n+/* Like do_compare_and_jump but expects the values to compare as two rtx's.\n+   The decision as to signed or unsigned comparison must be made by the caller.\n+\n+   If MODE is BLKmode, SIZE is an RTX giving the size of the objects being\n+   compared.  */\n+\n+void\n+do_compare_rtx_and_jump (op0, op1, code, unsignedp, mode, size,\n+                         if_false_label, if_true_label)\n+     rtx op0, op1;\n+     enum rtx_code code;\n+     int unsignedp;\n+     enum machine_mode mode;\n+     rtx size;\n+     rtx if_false_label, if_true_label;\n+{\n+  enum rtx_code ucode;\n+  rtx tem;\n+  int dummy_true_label = 0;\n+\n+  /* Reverse the comparison if that is safe and we want to jump if it is\n+     false.  */\n+  if (! if_true_label && ! FLOAT_MODE_P (mode))\n+    {\n+      if_true_label = if_false_label;\n+      if_false_label = 0;\n+      code = reverse_condition (code);\n+    }\n+\n+  /* If one operand is constant, make it the second one.  Only do this\n+     if the other operand is not constant as well.  */\n+\n+  if (swap_commutative_operands_p (op0, op1))\n+    {\n+      tem = op0;\n+      op0 = op1;\n+      op1 = tem;\n+      code = swap_condition (code);\n+    }\n+\n+  if (flag_force_mem)\n+    {\n+      op0 = force_not_mem (op0);\n+      op1 = force_not_mem (op1);\n+    }\n+\n+  do_pending_stack_adjust ();\n+\n+  ucode = unsignedp ? unsigned_condition (code) : code;\n+  if ((tem = simplify_relational_operation (ucode, mode, op0, op1)) != 0)\n+    {\n+      if (tem == const_true_rtx)\n+        {\n+          if (if_true_label)\n+            emit_jump (if_true_label);\n+        }\n+      else\n+        {\n+          if (if_false_label)\n+            emit_jump (if_false_label);\n+        }\n+      return;\n+    }\n+\n+#if 0\n+  /* There's no need to do this now that combine.c can eliminate lots of\n+     sign extensions.  This can be less efficient in certain cases on other\n+     machines.  */\n+\n+  /* If this is a signed equality comparison, we can do it as an\n+     unsigned comparison since zero-extension is cheaper than sign\n+     extension and comparisons with zero are done as unsigned.  This is\n+     the case even on machines that can do fast sign extension, since\n+     zero-extension is easier to combine with other operations than\n+     sign-extension is.  If we are comparing against a constant, we must\n+     convert it to what it would look like unsigned.  */\n+  if ((code == EQ || code == NE) && ! unsignedp\n+      && GET_MODE_BITSIZE (GET_MODE (op0)) <= HOST_BITS_PER_WIDE_INT)\n+    {\n+      if (GET_CODE (op1) == CONST_INT\n+          && (INTVAL (op1) & GET_MODE_MASK (GET_MODE (op0))) != INTVAL (op1))\n+        op1 = GEN_INT (INTVAL (op1) & GET_MODE_MASK (GET_MODE (op0)));\n+      unsignedp = 1;\n+    }\n+#endif\n+\n+  if (! if_true_label)\n+    {\n+      dummy_true_label = 1;\n+      if_true_label = gen_label_rtx ();\n+    }\n+\n+  emit_cmp_and_jump_insns (op0, op1, code, size, mode, unsignedp,\n+                           if_true_label);\n+\n+  if (if_false_label)\n+    emit_jump (if_false_label);\n+  if (dummy_true_label)\n+    emit_label (if_true_label);\n+}\n+\n+/* Generate code for a comparison expression EXP (including code to compute\n+   the values to be compared) and a conditional jump to IF_FALSE_LABEL and/or\n+   IF_TRUE_LABEL.  One of the labels can be NULL_RTX, in which case the\n+   generated code will drop through.\n+   SIGNED_CODE should be the rtx operation for this comparison for\n+   signed data; UNSIGNED_CODE, likewise for use if data is unsigned.\n+\n+   We force a stack adjustment unless there are currently\n+   things pushed on the stack that aren't yet used.  */\n+\n+static void\n+do_compare_and_jump (exp, signed_code, unsigned_code, if_false_label,\n+                     if_true_label)\n+     tree exp;\n+     enum rtx_code signed_code, unsigned_code;\n+     rtx if_false_label, if_true_label;\n+{\n+  rtx op0, op1;\n+  tree type;\n+  enum machine_mode mode;\n+  int unsignedp;\n+  enum rtx_code code;\n+\n+  /* Don't crash if the comparison was erroneous.  */\n+  op0 = expand_expr (TREE_OPERAND (exp, 0), NULL_RTX, VOIDmode, 0);\n+  if (TREE_CODE (TREE_OPERAND (exp, 0)) == ERROR_MARK)\n+    return;\n+\n+  op1 = expand_expr (TREE_OPERAND (exp, 1), NULL_RTX, VOIDmode, 0);\n+  if (TREE_CODE (TREE_OPERAND (exp, 1)) == ERROR_MARK)\n+    return;\n+\n+  type = TREE_TYPE (TREE_OPERAND (exp, 0));\n+  mode = TYPE_MODE (type);\n+  if (TREE_CODE (TREE_OPERAND (exp, 0)) == INTEGER_CST\n+      && (TREE_CODE (TREE_OPERAND (exp, 1)) != INTEGER_CST\n+          || (GET_MODE_BITSIZE (mode)\n+              > GET_MODE_BITSIZE (TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp,\n+                                                                      1)))))))\n+    {\n+      /* op0 might have been replaced by promoted constant, in which\n+         case the type of second argument should be used.  */\n+      type = TREE_TYPE (TREE_OPERAND (exp, 1));\n+      mode = TYPE_MODE (type);\n+    }\n+  unsignedp = TREE_UNSIGNED (type);\n+  code = unsignedp ? unsigned_code : signed_code;\n+\n+#ifdef HAVE_canonicalize_funcptr_for_compare\n+  /* If function pointers need to be \"canonicalized\" before they can\n+     be reliably compared, then canonicalize them.  */\n+  if (HAVE_canonicalize_funcptr_for_compare\n+      && TREE_CODE (TREE_TYPE (TREE_OPERAND (exp, 0))) == POINTER_TYPE\n+      && (TREE_CODE (TREE_TYPE (TREE_TYPE (TREE_OPERAND (exp, 0))))\n+          == FUNCTION_TYPE))\n+    {\n+      rtx new_op0 = gen_reg_rtx (mode);\n+\n+      emit_insn (gen_canonicalize_funcptr_for_compare (new_op0, op0));\n+      op0 = new_op0;\n+    }\n+\n+  if (HAVE_canonicalize_funcptr_for_compare\n+      && TREE_CODE (TREE_TYPE (TREE_OPERAND (exp, 1))) == POINTER_TYPE\n+      && (TREE_CODE (TREE_TYPE (TREE_TYPE (TREE_OPERAND (exp, 1))))\n+          == FUNCTION_TYPE))\n+    {\n+      rtx new_op1 = gen_reg_rtx (mode);\n+\n+      emit_insn (gen_canonicalize_funcptr_for_compare (new_op1, op1));\n+      op1 = new_op1;\n+    }\n+#endif\n+\n+  /* Do any postincrements in the expression that was tested.  */\n+  emit_queue ();\n+\n+  do_compare_rtx_and_jump (op0, op1, code, unsignedp, mode,\n+                           ((mode == BLKmode)\n+                            ? expr_size (TREE_OPERAND (exp, 0)) : NULL_RTX),\n+                           if_false_label, if_true_label);\n+}"}, {"sha": "e5d746234f99741acf59562360a48c213275f878", "filename": "gcc/expr.c", "status": "modified", "additions": 1, "deletions": 979, "changes": 980, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1cff896449f54942122f2341b35949736e825221/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1cff896449f54942122f2341b35949736e825221/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=1cff896449f54942122f2341b35949736e825221", "patch": "@@ -95,7 +95,7 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n int cse_not_expected;\n \n /* Chain of pending expressions for PLACEHOLDER_EXPR to replace.  */\n-static tree placeholder_list = 0;\n+tree placeholder_list = 0;\n \n /* This structure is used by move_by_pieces to describe the move to\n    be performed.  */\n@@ -170,10 +170,6 @@ static HOST_WIDE_INT highest_pow2_factor PARAMS ((tree));\n static HOST_WIDE_INT highest_pow2_factor_for_type PARAMS ((tree, tree));\n static int is_aligning_offset\tPARAMS ((tree, tree));\n static rtx expand_increment\tPARAMS ((tree, int, int));\n-static void do_jump_by_parts_greater PARAMS ((tree, int, rtx, rtx));\n-static void do_jump_by_parts_equality PARAMS ((tree, rtx, rtx));\n-static void do_compare_and_jump\tPARAMS ((tree, enum rtx_code, enum rtx_code,\n-\t\t\t\t\t rtx, rtx));\n static rtx do_store_flag\tPARAMS ((tree, rtx, enum machine_mode, int));\n #ifdef PUSH_ROUNDING\n static void emit_single_push_insn PARAMS ((enum machine_mode, rtx, tree));\n@@ -9784,980 +9780,6 @@ expand_increment (exp, post, ignore)\n   return temp;\n }\n \f\n-/* At the start of a function, record that we have no previously-pushed\n-   arguments waiting to be popped.  */\n-\n-void\n-init_pending_stack_adjust ()\n-{\n-  pending_stack_adjust = 0;\n-}\n-\n-/* When exiting from function, if safe, clear out any pending stack adjust\n-   so the adjustment won't get done.\n-\n-   Note, if the current function calls alloca, then it must have a\n-   frame pointer regardless of the value of flag_omit_frame_pointer.  */\n-\n-void\n-clear_pending_stack_adjust ()\n-{\n-#ifdef EXIT_IGNORE_STACK\n-  if (optimize > 0\n-      && (! flag_omit_frame_pointer || current_function_calls_alloca)\n-      && EXIT_IGNORE_STACK\n-      && ! (DECL_INLINE (current_function_decl) && ! flag_no_inline)\n-      && ! flag_inline_functions)\n-    {\n-      stack_pointer_delta -= pending_stack_adjust,\n-      pending_stack_adjust = 0;\n-    }\n-#endif\n-}\n-\n-/* Pop any previously-pushed arguments that have not been popped yet.  */\n-\n-void\n-do_pending_stack_adjust ()\n-{\n-  if (inhibit_defer_pop == 0)\n-    {\n-      if (pending_stack_adjust != 0)\n-\tadjust_stack (GEN_INT (pending_stack_adjust));\n-      pending_stack_adjust = 0;\n-    }\n-}\n-\f\n-/* Expand conditional expressions.  */\n-\n-/* Generate code to evaluate EXP and jump to LABEL if the value is zero.\n-   LABEL is an rtx of code CODE_LABEL, in this function and all the\n-   functions here.  */\n-\n-void\n-jumpifnot (exp, label)\n-     tree exp;\n-     rtx label;\n-{\n-  do_jump (exp, label, NULL_RTX);\n-}\n-\n-/* Generate code to evaluate EXP and jump to LABEL if the value is nonzero.  */\n-\n-void\n-jumpif (exp, label)\n-     tree exp;\n-     rtx label;\n-{\n-  do_jump (exp, NULL_RTX, label);\n-}\n-\n-/* Generate code to evaluate EXP and jump to IF_FALSE_LABEL if\n-   the result is zero, or IF_TRUE_LABEL if the result is one.\n-   Either of IF_FALSE_LABEL and IF_TRUE_LABEL may be zero,\n-   meaning fall through in that case.\n-\n-   do_jump always does any pending stack adjust except when it does not\n-   actually perform a jump.  An example where there is no jump\n-   is when EXP is `(foo (), 0)' and IF_FALSE_LABEL is null.\n-\n-   This function is responsible for optimizing cases such as\n-   &&, || and comparison operators in EXP.  */\n-\n-void\n-do_jump (exp, if_false_label, if_true_label)\n-     tree exp;\n-     rtx if_false_label, if_true_label;\n-{\n-  enum tree_code code = TREE_CODE (exp);\n-  /* Some cases need to create a label to jump to\n-     in order to properly fall through.\n-     These cases set DROP_THROUGH_LABEL nonzero.  */\n-  rtx drop_through_label = 0;\n-  rtx temp;\n-  int i;\n-  tree type;\n-  enum machine_mode mode;\n-\n-#ifdef MAX_INTEGER_COMPUTATION_MODE\n-  check_max_integer_computation_mode (exp);\n-#endif\n-\n-  emit_queue ();\n-\n-  switch (code)\n-    {\n-    case ERROR_MARK:\n-      break;\n-\n-    case INTEGER_CST:\n-      temp = integer_zerop (exp) ? if_false_label : if_true_label;\n-      if (temp)\n-\temit_jump (temp);\n-      break;\n-\n-#if 0\n-      /* This is not true with #pragma weak  */\n-    case ADDR_EXPR:\n-      /* The address of something can never be zero.  */\n-      if (if_true_label)\n-\temit_jump (if_true_label);\n-      break;\n-#endif\n-\n-    case NOP_EXPR:\n-      if (TREE_CODE (TREE_OPERAND (exp, 0)) == COMPONENT_REF\n-\t  || TREE_CODE (TREE_OPERAND (exp, 0)) == BIT_FIELD_REF\n-\t  || TREE_CODE (TREE_OPERAND (exp, 0)) == ARRAY_REF\n-\t  || TREE_CODE (TREE_OPERAND (exp, 0)) == ARRAY_RANGE_REF)\n-\tgoto normal;\n-    case CONVERT_EXPR:\n-      /* If we are narrowing the operand, we have to do the compare in the\n-\t narrower mode.  */\n-      if ((TYPE_PRECISION (TREE_TYPE (exp))\n-\t   < TYPE_PRECISION (TREE_TYPE (TREE_OPERAND (exp, 0)))))\n-\tgoto normal;\n-    case NON_LVALUE_EXPR:\n-    case REFERENCE_EXPR:\n-    case ABS_EXPR:\n-    case NEGATE_EXPR:\n-    case LROTATE_EXPR:\n-    case RROTATE_EXPR:\n-      /* These cannot change zero->nonzero or vice versa.  */\n-      do_jump (TREE_OPERAND (exp, 0), if_false_label, if_true_label);\n-      break;\n-\n-    case WITH_RECORD_EXPR:\n-      /* Put the object on the placeholder list, recurse through our first\n-\t operand, and pop the list.  */\n-      placeholder_list = tree_cons (TREE_OPERAND (exp, 1), NULL_TREE,\n-\t\t\t\t    placeholder_list);\n-      do_jump (TREE_OPERAND (exp, 0), if_false_label, if_true_label);\n-      placeholder_list = TREE_CHAIN (placeholder_list);\n-      break;\n-\n-#if 0\n-      /* This is never less insns than evaluating the PLUS_EXPR followed by\n-\t a test and can be longer if the test is eliminated.  */\n-    case PLUS_EXPR:\n-      /* Reduce to minus.  */\n-      exp = build (MINUS_EXPR, TREE_TYPE (exp),\n-\t\t   TREE_OPERAND (exp, 0),\n-\t\t   fold (build1 (NEGATE_EXPR, TREE_TYPE (TREE_OPERAND (exp, 1)),\n-\t\t\t\t TREE_OPERAND (exp, 1))));\n-      /* Process as MINUS.  */\n-#endif\n-\n-    case MINUS_EXPR:\n-      /* Nonzero iff operands of minus differ.  */\n-      do_compare_and_jump (build (NE_EXPR, TREE_TYPE (exp),\n-\t\t\t\t  TREE_OPERAND (exp, 0),\n-\t\t\t\t  TREE_OPERAND (exp, 1)),\n-\t\t\t   NE, NE, if_false_label, if_true_label);\n-      break;\n-\n-    case BIT_AND_EXPR:\n-      /* If we are AND'ing with a small constant, do this comparison in the\n-\t smallest type that fits.  If the machine doesn't have comparisons\n-\t that small, it will be converted back to the wider comparison.\n-\t This helps if we are testing the sign bit of a narrower object.\n-\t combine can't do this for us because it can't know whether a\n-\t ZERO_EXTRACT or a compare in a smaller mode exists, but we do.  */\n-\n-      if (! SLOW_BYTE_ACCESS\n-\t  && TREE_CODE (TREE_OPERAND (exp, 1)) == INTEGER_CST\n-\t  && TYPE_PRECISION (TREE_TYPE (exp)) <= HOST_BITS_PER_WIDE_INT\n-\t  && (i = tree_floor_log2 (TREE_OPERAND (exp, 1))) >= 0\n-\t  && (mode = mode_for_size (i + 1, MODE_INT, 0)) != BLKmode\n-\t  && (type = (*lang_hooks.types.type_for_mode) (mode, 1)) != 0\n-\t  && TYPE_PRECISION (type) < TYPE_PRECISION (TREE_TYPE (exp))\n-\t  && (cmp_optab->handlers[(int) TYPE_MODE (type)].insn_code\n-\t      != CODE_FOR_nothing))\n-\t{\n-\t  do_jump (convert (type, exp), if_false_label, if_true_label);\n-\t  break;\n-\t}\n-      goto normal;\n-\n-    case TRUTH_NOT_EXPR:\n-      do_jump (TREE_OPERAND (exp, 0), if_true_label, if_false_label);\n-      break;\n-\n-    case TRUTH_ANDIF_EXPR:\n-      if (if_false_label == 0)\n-\tif_false_label = drop_through_label = gen_label_rtx ();\n-      do_jump (TREE_OPERAND (exp, 0), if_false_label, NULL_RTX);\n-      start_cleanup_deferral ();\n-      do_jump (TREE_OPERAND (exp, 1), if_false_label, if_true_label);\n-      end_cleanup_deferral ();\n-      break;\n-\n-    case TRUTH_ORIF_EXPR:\n-      if (if_true_label == 0)\n-\tif_true_label = drop_through_label = gen_label_rtx ();\n-      do_jump (TREE_OPERAND (exp, 0), NULL_RTX, if_true_label);\n-      start_cleanup_deferral ();\n-      do_jump (TREE_OPERAND (exp, 1), if_false_label, if_true_label);\n-      end_cleanup_deferral ();\n-      break;\n-\n-    case COMPOUND_EXPR:\n-      push_temp_slots ();\n-      expand_expr (TREE_OPERAND (exp, 0), const0_rtx, VOIDmode, 0);\n-      preserve_temp_slots (NULL_RTX);\n-      free_temp_slots ();\n-      pop_temp_slots ();\n-      emit_queue ();\n-      do_pending_stack_adjust ();\n-      do_jump (TREE_OPERAND (exp, 1), if_false_label, if_true_label);\n-      break;\n-\n-    case COMPONENT_REF:\n-    case BIT_FIELD_REF:\n-    case ARRAY_REF:\n-    case ARRAY_RANGE_REF:\n-      {\n-\tHOST_WIDE_INT bitsize, bitpos;\n-\tint unsignedp;\n-\tenum machine_mode mode;\n-\ttree type;\n-\ttree offset;\n-\tint volatilep = 0;\n-\n-\t/* Get description of this reference.  We don't actually care\n-\t   about the underlying object here.  */\n-\tget_inner_reference (exp, &bitsize, &bitpos, &offset, &mode,\n-\t\t\t     &unsignedp, &volatilep);\n-\n-\ttype = (*lang_hooks.types.type_for_size) (bitsize, unsignedp);\n-\tif (! SLOW_BYTE_ACCESS\n-\t    && type != 0 && bitsize >= 0\n-\t    && TYPE_PRECISION (type) < TYPE_PRECISION (TREE_TYPE (exp))\n-\t    && (cmp_optab->handlers[(int) TYPE_MODE (type)].insn_code\n-\t\t!= CODE_FOR_nothing))\n-\t  {\n-\t    do_jump (convert (type, exp), if_false_label, if_true_label);\n-\t    break;\n-\t  }\n-\tgoto normal;\n-      }\n-\n-    case COND_EXPR:\n-      /* Do (a ? 1 : 0) and (a ? 0 : 1) as special cases.  */\n-      if (integer_onep (TREE_OPERAND (exp, 1))\n-\t  && integer_zerop (TREE_OPERAND (exp, 2)))\n-\tdo_jump (TREE_OPERAND (exp, 0), if_false_label, if_true_label);\n-\n-      else if (integer_zerop (TREE_OPERAND (exp, 1))\n-\t       && integer_onep (TREE_OPERAND (exp, 2)))\n-\tdo_jump (TREE_OPERAND (exp, 0), if_true_label, if_false_label);\n-\n-      else\n-\t{\n-\t  rtx label1 = gen_label_rtx ();\n-\t  drop_through_label = gen_label_rtx ();\n-\n-\t  do_jump (TREE_OPERAND (exp, 0), label1, NULL_RTX);\n-\n-\t  start_cleanup_deferral ();\n-\t  /* Now the THEN-expression.  */\n-\t  do_jump (TREE_OPERAND (exp, 1),\n-\t\t   if_false_label ? if_false_label : drop_through_label,\n-\t\t   if_true_label ? if_true_label : drop_through_label);\n-\t  /* In case the do_jump just above never jumps.  */\n-\t  do_pending_stack_adjust ();\n-\t  emit_label (label1);\n-\n-\t  /* Now the ELSE-expression.  */\n-\t  do_jump (TREE_OPERAND (exp, 2),\n-\t\t   if_false_label ? if_false_label : drop_through_label,\n-\t\t   if_true_label ? if_true_label : drop_through_label);\n-\t  end_cleanup_deferral ();\n-\t}\n-      break;\n-\n-    case EQ_EXPR:\n-      {\n-\ttree inner_type = TREE_TYPE (TREE_OPERAND (exp, 0));\n-\n-\tif (GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_COMPLEX_FLOAT\n-\t    || GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_COMPLEX_INT)\n-\t  {\n-\t    tree exp0 = save_expr (TREE_OPERAND (exp, 0));\n-\t    tree exp1 = save_expr (TREE_OPERAND (exp, 1));\n-\t    do_jump\n-\t      (fold\n-\t       (build (TRUTH_ANDIF_EXPR, TREE_TYPE (exp),\n-\t\t       fold (build (EQ_EXPR, TREE_TYPE (exp),\n-\t\t\t\t    fold (build1 (REALPART_EXPR,\n-\t\t\t\t\t\t  TREE_TYPE (inner_type),\n-\t\t\t\t\t\t  exp0)),\n-\t\t\t\t    fold (build1 (REALPART_EXPR,\n-\t\t\t\t\t\t  TREE_TYPE (inner_type),\n-\t\t\t\t\t\t  exp1)))),\n-\t\t       fold (build (EQ_EXPR, TREE_TYPE (exp),\n-\t\t\t\t    fold (build1 (IMAGPART_EXPR,\n-\t\t\t\t\t\t  TREE_TYPE (inner_type),\n-\t\t\t\t\t\t  exp0)),\n-\t\t\t\t    fold (build1 (IMAGPART_EXPR,\n-\t\t\t\t\t\t  TREE_TYPE (inner_type),\n-\t\t\t\t\t\t  exp1)))))),\n-\t       if_false_label, if_true_label);\n-\t  }\n-\n-\telse if (integer_zerop (TREE_OPERAND (exp, 1)))\n-\t  do_jump (TREE_OPERAND (exp, 0), if_true_label, if_false_label);\n-\n-\telse if (GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_INT\n-\t\t && !can_compare_p (EQ, TYPE_MODE (inner_type), ccp_jump))\n-\t  do_jump_by_parts_equality (exp, if_false_label, if_true_label);\n-\telse\n-\t  do_compare_and_jump (exp, EQ, EQ, if_false_label, if_true_label);\n-\tbreak;\n-      }\n-\n-    case NE_EXPR:\n-      {\n-\ttree inner_type = TREE_TYPE (TREE_OPERAND (exp, 0));\n-\n-\tif (GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_COMPLEX_FLOAT\n-\t    || GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_COMPLEX_INT)\n-\t  {\n-\t    tree exp0 = save_expr (TREE_OPERAND (exp, 0));\n-\t    tree exp1 = save_expr (TREE_OPERAND (exp, 1));\n-\t    do_jump\n-\t      (fold\n-\t       (build (TRUTH_ORIF_EXPR, TREE_TYPE (exp),\n-\t\t       fold (build (NE_EXPR, TREE_TYPE (exp),\n-\t\t\t\t    fold (build1 (REALPART_EXPR,\n-\t\t\t\t\t\t  TREE_TYPE (inner_type),\n-\t\t\t\t\t\t  exp0)),\n-\t\t\t\t    fold (build1 (REALPART_EXPR,\n-\t\t\t\t\t\t  TREE_TYPE (inner_type),\n-\t\t\t\t\t\t  exp1)))),\n-\t\t       fold (build (NE_EXPR, TREE_TYPE (exp),\n-\t\t\t\t    fold (build1 (IMAGPART_EXPR,\n-\t\t\t\t\t\t  TREE_TYPE (inner_type),\n-\t\t\t\t\t\t  exp0)),\n-\t\t\t\t    fold (build1 (IMAGPART_EXPR,\n-\t\t\t\t\t\t  TREE_TYPE (inner_type),\n-\t\t\t\t\t\t  exp1)))))),\n-\t       if_false_label, if_true_label);\n-\t  }\n-\n-\telse if (integer_zerop (TREE_OPERAND (exp, 1)))\n-\t  do_jump (TREE_OPERAND (exp, 0), if_false_label, if_true_label);\n-\n-\telse if (GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_INT\n-\t\t && !can_compare_p (NE, TYPE_MODE (inner_type), ccp_jump))\n-\t  do_jump_by_parts_equality (exp, if_true_label, if_false_label);\n-\telse\n-\t  do_compare_and_jump (exp, NE, NE, if_false_label, if_true_label);\n-\tbreak;\n-      }\n-\n-    case LT_EXPR:\n-      mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n-      if (GET_MODE_CLASS (mode) == MODE_INT\n-\t  && ! can_compare_p (LT, mode, ccp_jump))\n-\tdo_jump_by_parts_greater (exp, 1, if_false_label, if_true_label);\n-      else\n-\tdo_compare_and_jump (exp, LT, LTU, if_false_label, if_true_label);\n-      break;\n-\n-    case LE_EXPR:\n-      mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n-      if (GET_MODE_CLASS (mode) == MODE_INT\n-\t  && ! can_compare_p (LE, mode, ccp_jump))\n-\tdo_jump_by_parts_greater (exp, 0, if_true_label, if_false_label);\n-      else\n-\tdo_compare_and_jump (exp, LE, LEU, if_false_label, if_true_label);\n-      break;\n-\n-    case GT_EXPR:\n-      mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n-      if (GET_MODE_CLASS (mode) == MODE_INT\n-\t  && ! can_compare_p (GT, mode, ccp_jump))\n-\tdo_jump_by_parts_greater (exp, 0, if_false_label, if_true_label);\n-      else\n-\tdo_compare_and_jump (exp, GT, GTU, if_false_label, if_true_label);\n-      break;\n-\n-    case GE_EXPR:\n-      mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n-      if (GET_MODE_CLASS (mode) == MODE_INT\n-\t  && ! can_compare_p (GE, mode, ccp_jump))\n-\tdo_jump_by_parts_greater (exp, 1, if_true_label, if_false_label);\n-      else\n-\tdo_compare_and_jump (exp, GE, GEU, if_false_label, if_true_label);\n-      break;\n-\n-    case UNORDERED_EXPR:\n-    case ORDERED_EXPR:\n-      {\n-\tenum rtx_code cmp, rcmp;\n-\tint do_rev;\n-\n-\tif (code == UNORDERED_EXPR)\n-\t  cmp = UNORDERED, rcmp = ORDERED;\n-\telse\n-\t  cmp = ORDERED, rcmp = UNORDERED;\n-\tmode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n-\n-\tdo_rev = 0;\n-\tif (! can_compare_p (cmp, mode, ccp_jump)\n-\t    && (can_compare_p (rcmp, mode, ccp_jump)\n-\t\t/* If the target doesn't provide either UNORDERED or ORDERED\n-\t\t   comparisons, canonicalize on UNORDERED for the library.  */\n-\t\t|| rcmp == UNORDERED))\n-\t  do_rev = 1;\n-\n-\tif (! do_rev)\n-\t  do_compare_and_jump (exp, cmp, cmp, if_false_label, if_true_label);\n-\telse\n-\t  do_compare_and_jump (exp, rcmp, rcmp, if_true_label, if_false_label);\n-      }\n-      break;\n-\n-    {\n-      enum rtx_code rcode1;\n-      enum tree_code tcode2;\n-\n-      case UNLT_EXPR:\n-\trcode1 = UNLT;\n-\ttcode2 = LT_EXPR;\n-\tgoto unordered_bcc;\n-      case UNLE_EXPR:\n-\trcode1 = UNLE;\n-\ttcode2 = LE_EXPR;\n-\tgoto unordered_bcc;\n-      case UNGT_EXPR:\n-\trcode1 = UNGT;\n-\ttcode2 = GT_EXPR;\n-\tgoto unordered_bcc;\n-      case UNGE_EXPR:\n-\trcode1 = UNGE;\n-\ttcode2 = GE_EXPR;\n-\tgoto unordered_bcc;\n-      case UNEQ_EXPR:\n-\trcode1 = UNEQ;\n-\ttcode2 = EQ_EXPR;\n-\tgoto unordered_bcc;\n-\n-      unordered_bcc:\n-\tmode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n-\tif (can_compare_p (rcode1, mode, ccp_jump))\n-\t  do_compare_and_jump (exp, rcode1, rcode1, if_false_label,\n-\t\t\t       if_true_label);\n-\telse\n-\t  {\n-\t    tree op0 = save_expr (TREE_OPERAND (exp, 0));\n-\t    tree op1 = save_expr (TREE_OPERAND (exp, 1));\n-\t    tree cmp0, cmp1;\n-\n-\t    /* If the target doesn't support combined unordered\n-\t       compares, decompose into UNORDERED + comparison.  */\n-\t    cmp0 = fold (build (UNORDERED_EXPR, TREE_TYPE (exp), op0, op1));\n-\t    cmp1 = fold (build (tcode2, TREE_TYPE (exp), op0, op1));\n-\t    exp = build (TRUTH_ORIF_EXPR, TREE_TYPE (exp), cmp0, cmp1);\n-\t    do_jump (exp, if_false_label, if_true_label);\n-\t  }\n-      }\n-      break;\n-\n-      /* Special case:\n-\t\t__builtin_expect (<test>, 0)\tand\n-\t\t__builtin_expect (<test>, 1)\n-\n-\t We need to do this here, so that <test> is not converted to a SCC\n-\t operation on machines that use condition code registers and COMPARE\n-\t like the PowerPC, and then the jump is done based on whether the SCC\n-\t operation produced a 1 or 0.  */\n-    case CALL_EXPR:\n-      /* Check for a built-in function.  */\n-      if (TREE_CODE (TREE_OPERAND (exp, 0)) == ADDR_EXPR)\n-\t{\n-\t  tree fndecl = TREE_OPERAND (TREE_OPERAND (exp, 0), 0);\n-\t  tree arglist = TREE_OPERAND (exp, 1);\n-\n-\t  if (TREE_CODE (fndecl) == FUNCTION_DECL\n-\t      && DECL_BUILT_IN (fndecl)\n-\t      && DECL_FUNCTION_CODE (fndecl) == BUILT_IN_EXPECT\n-\t      && arglist != NULL_TREE\n-\t      && TREE_CHAIN (arglist) != NULL_TREE)\n-\t    {\n-\t      rtx seq = expand_builtin_expect_jump (exp, if_false_label,\n-\t\t\t\t\t\t    if_true_label);\n-\n-\t      if (seq != NULL_RTX)\n-\t\t{\n-\t\t  emit_insn (seq);\n-\t\t  return;\n-\t\t}\n-\t    }\n-\t}\n-      /* fall through and generate the normal code.  */\n-\n-    default:\n-    normal:\n-      temp = expand_expr (exp, NULL_RTX, VOIDmode, 0);\n-#if 0\n-      /* This is not needed any more and causes poor code since it causes\n-\t comparisons and tests from non-SI objects to have different code\n-\t sequences.  */\n-      /* Copy to register to avoid generating bad insns by cse\n-\t from (set (mem ...) (arithop))  (set (cc0) (mem ...)).  */\n-      if (!cse_not_expected && GET_CODE (temp) == MEM)\n-\ttemp = copy_to_reg (temp);\n-#endif\n-      do_pending_stack_adjust ();\n-      /* Do any postincrements in the expression that was tested.  */\n-      emit_queue ();\n-\n-      if (GET_CODE (temp) == CONST_INT\n-\t  || (GET_CODE (temp) == CONST_DOUBLE && GET_MODE (temp) == VOIDmode)\n-\t  || GET_CODE (temp) == LABEL_REF)\n-\t{\n-\t  rtx target = temp == const0_rtx ? if_false_label : if_true_label;\n-\t  if (target)\n-\t    emit_jump (target);\n-\t}\n-      else if (GET_MODE_CLASS (GET_MODE (temp)) == MODE_INT\n-\t       && ! can_compare_p (NE, GET_MODE (temp), ccp_jump))\n-\t/* Note swapping the labels gives us not-equal.  */\n-\tdo_jump_by_parts_equality_rtx (temp, if_true_label, if_false_label);\n-      else if (GET_MODE (temp) != VOIDmode)\n-\tdo_compare_rtx_and_jump (temp, CONST0_RTX (GET_MODE (temp)),\n-\t\t\t\t NE, TREE_UNSIGNED (TREE_TYPE (exp)),\n-\t\t\t\t GET_MODE (temp), NULL_RTX,\n-\t\t\t\t if_false_label, if_true_label);\n-      else\n-\tabort ();\n-    }\n-\n-  if (drop_through_label)\n-    {\n-      /* If do_jump produces code that might be jumped around,\n-\t do any stack adjusts from that code, before the place\n-\t where control merges in.  */\n-      do_pending_stack_adjust ();\n-      emit_label (drop_through_label);\n-    }\n-}\n-\f\n-/* Given a comparison expression EXP for values too wide to be compared\n-   with one insn, test the comparison and jump to the appropriate label.\n-   The code of EXP is ignored; we always test GT if SWAP is 0,\n-   and LT if SWAP is 1.  */\n-\n-static void\n-do_jump_by_parts_greater (exp, swap, if_false_label, if_true_label)\n-     tree exp;\n-     int swap;\n-     rtx if_false_label, if_true_label;\n-{\n-  rtx op0 = expand_expr (TREE_OPERAND (exp, swap), NULL_RTX, VOIDmode, 0);\n-  rtx op1 = expand_expr (TREE_OPERAND (exp, !swap), NULL_RTX, VOIDmode, 0);\n-  enum machine_mode mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n-  int unsignedp = TREE_UNSIGNED (TREE_TYPE (TREE_OPERAND (exp, 0)));\n-\n-  do_jump_by_parts_greater_rtx (mode, unsignedp, op0, op1, if_false_label, if_true_label);\n-}\n-\n-/* Compare OP0 with OP1, word at a time, in mode MODE.\n-   UNSIGNEDP says to do unsigned comparison.\n-   Jump to IF_TRUE_LABEL if OP0 is greater, IF_FALSE_LABEL otherwise.  */\n-\n-void\n-do_jump_by_parts_greater_rtx (mode, unsignedp, op0, op1, if_false_label, if_true_label)\n-     enum machine_mode mode;\n-     int unsignedp;\n-     rtx op0, op1;\n-     rtx if_false_label, if_true_label;\n-{\n-  int nwords = (GET_MODE_SIZE (mode) / UNITS_PER_WORD);\n-  rtx drop_through_label = 0;\n-  int i;\n-\n-  if (! if_true_label || ! if_false_label)\n-    drop_through_label = gen_label_rtx ();\n-  if (! if_true_label)\n-    if_true_label = drop_through_label;\n-  if (! if_false_label)\n-    if_false_label = drop_through_label;\n-\n-  /* Compare a word at a time, high order first.  */\n-  for (i = 0; i < nwords; i++)\n-    {\n-      rtx op0_word, op1_word;\n-\n-      if (WORDS_BIG_ENDIAN)\n-\t{\n-\t  op0_word = operand_subword_force (op0, i, mode);\n-\t  op1_word = operand_subword_force (op1, i, mode);\n-\t}\n-      else\n-\t{\n-\t  op0_word = operand_subword_force (op0, nwords - 1 - i, mode);\n-\t  op1_word = operand_subword_force (op1, nwords - 1 - i, mode);\n-\t}\n-\n-      /* All but high-order word must be compared as unsigned.  */\n-      do_compare_rtx_and_jump (op0_word, op1_word, GT,\n-\t\t\t       (unsignedp || i > 0), word_mode, NULL_RTX,\n-\t\t\t       NULL_RTX, if_true_label);\n-\n-      /* Consider lower words only if these are equal.  */\n-      do_compare_rtx_and_jump (op0_word, op1_word, NE, unsignedp, word_mode,\n-\t\t\t       NULL_RTX, NULL_RTX, if_false_label);\n-    }\n-\n-  if (if_false_label)\n-    emit_jump (if_false_label);\n-  if (drop_through_label)\n-    emit_label (drop_through_label);\n-}\n-\n-/* Given an EQ_EXPR expression EXP for values too wide to be compared\n-   with one insn, test the comparison and jump to the appropriate label.  */\n-\n-static void\n-do_jump_by_parts_equality (exp, if_false_label, if_true_label)\n-     tree exp;\n-     rtx if_false_label, if_true_label;\n-{\n-  rtx op0 = expand_expr (TREE_OPERAND (exp, 0), NULL_RTX, VOIDmode, 0);\n-  rtx op1 = expand_expr (TREE_OPERAND (exp, 1), NULL_RTX, VOIDmode, 0);\n-  enum machine_mode mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));\n-  int nwords = (GET_MODE_SIZE (mode) / UNITS_PER_WORD);\n-  int i;\n-  rtx drop_through_label = 0;\n-\n-  if (! if_false_label)\n-    drop_through_label = if_false_label = gen_label_rtx ();\n-\n-  for (i = 0; i < nwords; i++)\n-    do_compare_rtx_and_jump (operand_subword_force (op0, i, mode),\n-\t\t\t     operand_subword_force (op1, i, mode),\n-\t\t\t     EQ, TREE_UNSIGNED (TREE_TYPE (exp)),\n-\t\t\t     word_mode, NULL_RTX, if_false_label, NULL_RTX);\n-\n-  if (if_true_label)\n-    emit_jump (if_true_label);\n-  if (drop_through_label)\n-    emit_label (drop_through_label);\n-}\n-\f\n-/* Jump according to whether OP0 is 0.\n-   We assume that OP0 has an integer mode that is too wide\n-   for the available compare insns.  */\n-\n-void\n-do_jump_by_parts_equality_rtx (op0, if_false_label, if_true_label)\n-     rtx op0;\n-     rtx if_false_label, if_true_label;\n-{\n-  int nwords = GET_MODE_SIZE (GET_MODE (op0)) / UNITS_PER_WORD;\n-  rtx part;\n-  int i;\n-  rtx drop_through_label = 0;\n-\n-  /* The fastest way of doing this comparison on almost any machine is to\n-     \"or\" all the words and compare the result.  If all have to be loaded\n-     from memory and this is a very wide item, it's possible this may\n-     be slower, but that's highly unlikely.  */\n-\n-  part = gen_reg_rtx (word_mode);\n-  emit_move_insn (part, operand_subword_force (op0, 0, GET_MODE (op0)));\n-  for (i = 1; i < nwords && part != 0; i++)\n-    part = expand_binop (word_mode, ior_optab, part,\n-\t\t\t operand_subword_force (op0, i, GET_MODE (op0)),\n-\t\t\t part, 1, OPTAB_WIDEN);\n-\n-  if (part != 0)\n-    {\n-      do_compare_rtx_and_jump (part, const0_rtx, EQ, 1, word_mode,\n-\t\t\t       NULL_RTX, if_false_label, if_true_label);\n-\n-      return;\n-    }\n-\n-  /* If we couldn't do the \"or\" simply, do this with a series of compares.  */\n-  if (! if_false_label)\n-    drop_through_label = if_false_label = gen_label_rtx ();\n-\n-  for (i = 0; i < nwords; i++)\n-    do_compare_rtx_and_jump (operand_subword_force (op0, i, GET_MODE (op0)),\n-\t\t\t     const0_rtx, EQ, 1, word_mode, NULL_RTX,\n-\t\t\t     if_false_label, NULL_RTX);\n-\n-  if (if_true_label)\n-    emit_jump (if_true_label);\n-\n-  if (drop_through_label)\n-    emit_label (drop_through_label);\n-}\n-\f\n-/* Generate code for a comparison of OP0 and OP1 with rtx code CODE.\n-   (including code to compute the values to be compared)\n-   and set (CC0) according to the result.\n-   The decision as to signed or unsigned comparison must be made by the caller.\n-\n-   We force a stack adjustment unless there are currently\n-   things pushed on the stack that aren't yet used.\n-\n-   If MODE is BLKmode, SIZE is an RTX giving the size of the objects being\n-   compared.  */\n-\n-rtx\n-compare_from_rtx (op0, op1, code, unsignedp, mode, size)\n-     rtx op0, op1;\n-     enum rtx_code code;\n-     int unsignedp;\n-     enum machine_mode mode;\n-     rtx size;\n-{\n-  enum rtx_code ucode;\n-  rtx tem;\n-\n-  /* If one operand is constant, make it the second one.  Only do this\n-     if the other operand is not constant as well.  */\n-\n-  if (swap_commutative_operands_p (op0, op1))\n-    {\n-      tem = op0;\n-      op0 = op1;\n-      op1 = tem;\n-      code = swap_condition (code);\n-    }\n-\n-  if (flag_force_mem)\n-    {\n-      op0 = force_not_mem (op0);\n-      op1 = force_not_mem (op1);\n-    }\n-\n-  do_pending_stack_adjust ();\n-\n-  ucode = unsignedp ? unsigned_condition (code) : code;\n-  if ((tem = simplify_relational_operation (ucode, mode, op0, op1)) != 0)\n-    return tem;\n-\n-#if 0\n-  /* There's no need to do this now that combine.c can eliminate lots of\n-     sign extensions.  This can be less efficient in certain cases on other\n-     machines.  */\n-\n-  /* If this is a signed equality comparison, we can do it as an\n-     unsigned comparison since zero-extension is cheaper than sign\n-     extension and comparisons with zero are done as unsigned.  This is\n-     the case even on machines that can do fast sign extension, since\n-     zero-extension is easier to combine with other operations than\n-     sign-extension is.  If we are comparing against a constant, we must\n-     convert it to what it would look like unsigned.  */\n-  if ((code == EQ || code == NE) && ! unsignedp\n-      && GET_MODE_BITSIZE (GET_MODE (op0)) <= HOST_BITS_PER_WIDE_INT)\n-    {\n-      if (GET_CODE (op1) == CONST_INT\n-\t  && (INTVAL (op1) & GET_MODE_MASK (GET_MODE (op0))) != INTVAL (op1))\n-\top1 = GEN_INT (INTVAL (op1) & GET_MODE_MASK (GET_MODE (op0)));\n-      unsignedp = 1;\n-    }\n-#endif\n-\n-  emit_cmp_insn (op0, op1, code, size, mode, unsignedp);\n-\n-#if HAVE_cc0\n-  return gen_rtx_fmt_ee (code, VOIDmode, cc0_rtx, const0_rtx);\n-#else\n-  return gen_rtx_fmt_ee (code, VOIDmode, op0, op1);\n-#endif\n-}\n-\n-/* Like do_compare_and_jump but expects the values to compare as two rtx's.\n-   The decision as to signed or unsigned comparison must be made by the caller.\n-\n-   If MODE is BLKmode, SIZE is an RTX giving the size of the objects being\n-   compared.  */\n-\n-void\n-do_compare_rtx_and_jump (op0, op1, code, unsignedp, mode, size,\n-\t\t\t if_false_label, if_true_label)\n-     rtx op0, op1;\n-     enum rtx_code code;\n-     int unsignedp;\n-     enum machine_mode mode;\n-     rtx size;\n-     rtx if_false_label, if_true_label;\n-{\n-  enum rtx_code ucode;\n-  rtx tem;\n-  int dummy_true_label = 0;\n-\n-  /* Reverse the comparison if that is safe and we want to jump if it is\n-     false.  */\n-  if (! if_true_label && ! FLOAT_MODE_P (mode))\n-    {\n-      if_true_label = if_false_label;\n-      if_false_label = 0;\n-      code = reverse_condition (code);\n-    }\n-\n-  /* If one operand is constant, make it the second one.  Only do this\n-     if the other operand is not constant as well.  */\n-\n-  if (swap_commutative_operands_p (op0, op1))\n-    {\n-      tem = op0;\n-      op0 = op1;\n-      op1 = tem;\n-      code = swap_condition (code);\n-    }\n-\n-  if (flag_force_mem)\n-    {\n-      op0 = force_not_mem (op0);\n-      op1 = force_not_mem (op1);\n-    }\n-\n-  do_pending_stack_adjust ();\n-\n-  ucode = unsignedp ? unsigned_condition (code) : code;\n-  if ((tem = simplify_relational_operation (ucode, mode, op0, op1)) != 0)\n-    {\n-      if (tem == const_true_rtx)\n-\t{\n-\t  if (if_true_label)\n-\t    emit_jump (if_true_label);\n-\t}\n-      else\n-\t{\n-\t  if (if_false_label)\n-\t    emit_jump (if_false_label);\n-\t}\n-      return;\n-    }\n-\n-#if 0\n-  /* There's no need to do this now that combine.c can eliminate lots of\n-     sign extensions.  This can be less efficient in certain cases on other\n-     machines.  */\n-\n-  /* If this is a signed equality comparison, we can do it as an\n-     unsigned comparison since zero-extension is cheaper than sign\n-     extension and comparisons with zero are done as unsigned.  This is\n-     the case even on machines that can do fast sign extension, since\n-     zero-extension is easier to combine with other operations than\n-     sign-extension is.  If we are comparing against a constant, we must\n-     convert it to what it would look like unsigned.  */\n-  if ((code == EQ || code == NE) && ! unsignedp\n-      && GET_MODE_BITSIZE (GET_MODE (op0)) <= HOST_BITS_PER_WIDE_INT)\n-    {\n-      if (GET_CODE (op1) == CONST_INT\n-\t  && (INTVAL (op1) & GET_MODE_MASK (GET_MODE (op0))) != INTVAL (op1))\n-\top1 = GEN_INT (INTVAL (op1) & GET_MODE_MASK (GET_MODE (op0)));\n-      unsignedp = 1;\n-    }\n-#endif\n-\n-  if (! if_true_label)\n-    {\n-      dummy_true_label = 1;\n-      if_true_label = gen_label_rtx ();\n-    }\n-\n-  emit_cmp_and_jump_insns (op0, op1, code, size, mode, unsignedp,\n-\t\t\t   if_true_label);\n-\n-  if (if_false_label)\n-    emit_jump (if_false_label);\n-  if (dummy_true_label)\n-    emit_label (if_true_label);\n-}\n-\n-/* Generate code for a comparison expression EXP (including code to compute\n-   the values to be compared) and a conditional jump to IF_FALSE_LABEL and/or\n-   IF_TRUE_LABEL.  One of the labels can be NULL_RTX, in which case the\n-   generated code will drop through.\n-   SIGNED_CODE should be the rtx operation for this comparison for\n-   signed data; UNSIGNED_CODE, likewise for use if data is unsigned.\n-\n-   We force a stack adjustment unless there are currently\n-   things pushed on the stack that aren't yet used.  */\n-\n-static void\n-do_compare_and_jump (exp, signed_code, unsigned_code, if_false_label,\n-\t\t     if_true_label)\n-     tree exp;\n-     enum rtx_code signed_code, unsigned_code;\n-     rtx if_false_label, if_true_label;\n-{\n-  rtx op0, op1;\n-  tree type;\n-  enum machine_mode mode;\n-  int unsignedp;\n-  enum rtx_code code;\n-\n-  /* Don't crash if the comparison was erroneous.  */\n-  op0 = expand_expr (TREE_OPERAND (exp, 0), NULL_RTX, VOIDmode, 0);\n-  if (TREE_CODE (TREE_OPERAND (exp, 0)) == ERROR_MARK)\n-    return;\n-\n-  op1 = expand_expr (TREE_OPERAND (exp, 1), NULL_RTX, VOIDmode, 0);\n-  if (TREE_CODE (TREE_OPERAND (exp, 1)) == ERROR_MARK)\n-    return;\n-\n-  type = TREE_TYPE (TREE_OPERAND (exp, 0));\n-  mode = TYPE_MODE (type);\n-  if (TREE_CODE (TREE_OPERAND (exp, 0)) == INTEGER_CST\n-      && (TREE_CODE (TREE_OPERAND (exp, 1)) != INTEGER_CST\n-\t  || (GET_MODE_BITSIZE (mode)\n-\t      > GET_MODE_BITSIZE (TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp,\n-\t\t\t\t\t\t\t\t      1)))))))\n-    {\n-      /* op0 might have been replaced by promoted constant, in which\n-\t case the type of second argument should be used.  */\n-      type = TREE_TYPE (TREE_OPERAND (exp, 1));\n-      mode = TYPE_MODE (type);\n-    }\n-  unsignedp = TREE_UNSIGNED (type);\n-  code = unsignedp ? unsigned_code : signed_code;\n-\n-#ifdef HAVE_canonicalize_funcptr_for_compare\n-  /* If function pointers need to be \"canonicalized\" before they can\n-     be reliably compared, then canonicalize them.  */\n-  if (HAVE_canonicalize_funcptr_for_compare\n-      && TREE_CODE (TREE_TYPE (TREE_OPERAND (exp, 0))) == POINTER_TYPE\n-      && (TREE_CODE (TREE_TYPE (TREE_TYPE (TREE_OPERAND (exp, 0))))\n-\t  == FUNCTION_TYPE))\n-    {\n-      rtx new_op0 = gen_reg_rtx (mode);\n-\n-      emit_insn (gen_canonicalize_funcptr_for_compare (new_op0, op0));\n-      op0 = new_op0;\n-    }\n-\n-  if (HAVE_canonicalize_funcptr_for_compare\n-      && TREE_CODE (TREE_TYPE (TREE_OPERAND (exp, 1))) == POINTER_TYPE\n-      && (TREE_CODE (TREE_TYPE (TREE_TYPE (TREE_OPERAND (exp, 1))))\n-\t  == FUNCTION_TYPE))\n-    {\n-      rtx new_op1 = gen_reg_rtx (mode);\n-\n-      emit_insn (gen_canonicalize_funcptr_for_compare (new_op1, op1));\n-      op1 = new_op1;\n-    }\n-#endif\n-\n-  /* Do any postincrements in the expression that was tested.  */\n-  emit_queue ();\n-\n-  do_compare_rtx_and_jump (op0, op1, code, unsignedp, mode,\n-\t\t\t   ((mode == BLKmode)\n-\t\t\t    ? expr_size (TREE_OPERAND (exp, 0)) : NULL_RTX),\n-\t\t\t   if_false_label, if_true_label);\n-}\n-\f\n /* Generate code to calculate EXP using a store-flag instruction\n    and return an rtx for the result.  EXP is either a comparison\n    or a TRUTH_NOT_EXPR whose operand is a comparison."}, {"sha": "cf794fc7401fdd8b301ceadbeb77c0326c087f0b", "filename": "gcc/expr.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1cff896449f54942122f2341b35949736e825221/gcc%2Fexpr.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1cff896449f54942122f2341b35949736e825221/gcc%2Fexpr.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.h?ref=1cff896449f54942122f2341b35949736e825221", "patch": "@@ -791,3 +791,5 @@ extern void mark_seen_cases\t\t\tPARAMS ((tree, unsigned char *,\n #endif\n \n extern int vector_mode_valid_p\t\tPARAMS ((enum machine_mode));\n+\n+extern tree placeholder_list;"}]}