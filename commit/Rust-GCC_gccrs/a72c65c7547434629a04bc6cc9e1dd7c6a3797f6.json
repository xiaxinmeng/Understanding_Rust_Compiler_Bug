{"sha": "a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YTcyYzY1Yzc1NDc0MzQ2MjlhMDRiYzZjYzllMWRkN2M2YTM3OTdmNg==", "commit": {"author": {"name": "Michael Meissner", "email": "meissner@linux.vnet.ibm.com", "date": "2009-07-23T16:05:37Z"}, "committer": {"name": "Michael Meissner", "email": "meissner@gcc.gnu.org", "date": "2009-07-23T16:05:37Z"}, "message": "Commit patch #3 of 4 for Power7 VSX support\n\nCo-Authored-By: Pat Haugen <pthaugen@us.ibm.com>\nCo-Authored-By: Revital Eres <eres@il.ibm.com>\n\nFrom-SVN: r150018", "tree": {"sha": "3563fee0c177c70c7fbbba2a98aa91c416b6d658", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/3563fee0c177c70c7fbbba2a98aa91c416b6d658"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/comments", "author": null, "committer": null, "parents": [{"sha": "230411604449fe6e7efc5b66bce492e926c0609f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/230411604449fe6e7efc5b66bce492e926c0609f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/230411604449fe6e7efc5b66bce492e926c0609f"}], "stats": {"total": 4709, "additions": 3106, "deletions": 1603}, "files": [{"sha": "fa53669ca2a9de92672ae14a7d5de3d6a3a87ecd", "filename": "boehm-gc/ChangeLog", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/boehm-gc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/boehm-gc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2FChangeLog?ref=a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "patch": "@@ -1,3 +1,12 @@\n+2009-07-17  Michael Meissner  <meissner@linux.vnet.ibm.com>\n+\n+\tPR boehm-gc/40785\n+\t* include/private/gc_locks.h (GC_test_and_set): If GCC 4.4, use\n+\tthe __sync_lock_test_and _set and __sync_lock_release builtins on\n+\tthe powerpc.  If not GCC 4.4, fix up the constraints so that it\n+\tbuilds without error.\n+\t(GC_clear): Ditto.\n+\n 2009-07-17  Kai Tietz  <kai.tietz@onevision.com>\n \n \t* configure.ac: Add rule for mingw targets to add -DGC_BUILD=1 to"}, {"sha": "d1bb2e4521a4a2adbe09c83dc21d57afa3740606", "filename": "boehm-gc/include/private/gc_locks.h", "status": "modified", "additions": 11, "deletions": 25, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/boehm-gc%2Finclude%2Fprivate%2Fgc_locks.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/boehm-gc%2Finclude%2Fprivate%2Fgc_locks.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/boehm-gc%2Finclude%2Fprivate%2Fgc_locks.h?ref=a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "patch": "@@ -139,49 +139,35 @@\n #      define GC_TEST_AND_SET_DEFINED\n #    endif\n #    if defined(POWERPC)\n-#     if 0 /* CPP_WORDSZ == 64  totally broken to use int locks with ldarx */\n-        inline static int GC_test_and_set(volatile unsigned int *addr) {\n-          unsigned long oldval;\n-          unsigned long temp = 1; /* locked value */\n-\n-          __asm__ __volatile__(\n-               \"1:\\tldarx %0,0,%3\\n\"   /* load and reserve               */\n-               \"\\tcmpdi %0, 0\\n\"       /* if load is                     */\n-               \"\\tbne 2f\\n\"            /*   non-zero, return already set */\n-               \"\\tstdcx. %2,0,%1\\n\"    /* else store conditional         */\n-               \"\\tbne- 1b\\n\"           /* retry if lost reservation      */\n-               \"\\tsync\\n\"              /* import barrier                 */\n-               \"2:\\t\\n\"                /* oldval is zero if we set       */\n-              : \"=&r\"(oldval), \"=p\"(addr)\n-              : \"r\"(temp), \"1\"(addr)\n-              : \"cr0\",\"memory\");\n-          return (int)oldval;\n-        }\n+#     define GC_TEST_AND_SET_DEFINED\n+#     define GC_CLEAR_DEFINED\n+#     if (__GNUC__>4)||((__GNUC__==4)&&(__GNUC_MINOR__>=4))\n+#       define GC_test_and_set(addr) __sync_lock_test_and_set (addr, 1)\n+#       define GC_clear(addr) __sync_lock_release (addr)\n #     else\n         inline static int GC_test_and_set(volatile unsigned int *addr) {\n           int oldval;\n           int temp = 1; /* locked value */\n \n           __asm__ __volatile__(\n-               \"1:\\tlwarx %0,0,%3\\n\"   /* load and reserve               */\n+               \"\\n1:\\n\"\n+\t       \"\\tlwarx %0,%y3\\n\"      /* load and reserve, 32-bits      */\n                \"\\tcmpwi %0, 0\\n\"       /* if load is                     */\n                \"\\tbne 2f\\n\"            /*   non-zero, return already set */\n-               \"\\tstwcx. %2,0,%1\\n\"    /* else store conditional         */\n+               \"\\tstwcx. %2,%y3\\n\"     /* else store conditional         */\n                \"\\tbne- 1b\\n\"           /* retry if lost reservation      */\n                \"\\tsync\\n\"              /* import barrier                 */\n                \"2:\\t\\n\"                /* oldval is zero if we set       */\n-              : \"=&r\"(oldval), \"=p\"(addr)\n-              : \"r\"(temp), \"1\"(addr)\n+              : \"=&r\"(oldval), \"=m\"(addr)\n+              : \"r\"(temp), \"Z\"(addr)\n               : \"cr0\",\"memory\");\n           return oldval;\n         }\n-#     endif\n-#     define GC_TEST_AND_SET_DEFINED\n       inline static void GC_clear(volatile unsigned int *addr) {\n \t__asm__ __volatile__(\"lwsync\" : : : \"memory\");\n         *(addr) = 0;\n       }\n-#     define GC_CLEAR_DEFINED\n+#    endif\n #    endif\n #    if defined(ALPHA) \n         inline static int GC_test_and_set(volatile unsigned int * addr)"}, {"sha": "e12299f95cecd8327c2f5c3d7bbffc70aeb6dea0", "filename": "gcc/ChangeLog", "status": "modified", "additions": 185, "deletions": 0, "changes": 185, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "patch": "@@ -1,3 +1,188 @@\n+2009-07-22  Michael Meissner  <meissner@linux.vnet.ibm.com>\n+\t    Pat Haugen  <pthaugen@us.ibm.com>\n+\t    Revital Eres <ERES@il.ibm.com>\n+\n+\t* config/rs6000/vector.md: New file.  Move most of the vector\n+\texpander support here from altivec.md to allow for the VSX vector\n+\tunit in the future.  Add support for secondary_reload patterns.\n+\tRewrite the patterns for vector comparison, and vector comparison\n+\tpredicate instructions so that the RTL expresses the desired\n+\tbehavior, instead of using unspec.\n+\n+\t* config/rs6000/constraints.md (\"f\" constraint): Use\n+\trs6000_constraints to hold the precalculated register class.\n+\t(\"d\" constraint): Ditto.\n+\t(\"wd\" constraint): New constraint for VSX.\n+\t(\"wf\" constraint): Ditto.\n+\t(\"ws\" constraint): Ditto.\n+\t(\"wa\" constraint): Ditto.\n+\t(\"wZ\" constraint): Ditto.\n+\t(\"j\" constraint): Ditto.\n+\n+\t* config/rs6000/predicates.md (vsx_register_operand): New\n+\tpredicate for VSX.\n+\t(vfloat_operand): New predicate for vector.md.\n+\t(vint_operand): Ditto.\n+\t(vlogical_operand): Ditto.\n+\t(easy_fp_constant): If VSX, 0.0 is an easy constant.\n+\t(easy_vector_constant): Add VSX support.\n+\t(altivec_indexed_or_indirect_operand): New predicate for\n+\trecognizing Altivec style memory references with AND -16.\n+\n+\t* config/rs6000/rs6000.c (rs6000_vector_reload): New static global\n+\tfor vector secondary reload support.\n+\t(rs6000_vector_reg_class): Delete, replacing it with rs6000_constraints.\n+\t(rs6000_vsx_reg_class): Ditto.\n+\t(rs6000_constraints): New array to hold the register classes of\n+\teach of the register constraints that can vary at runtime.\n+\t(builtin_mode_to_type): New static array for builtin function type\n+\tcreation.\n+\t(builtin_hash_table): New static hash table for builtin function\n+\ttype creation.\n+\t(TARGET_SECONDARY_RELOAD): Define target hook.\n+\t(TARGET_IRA_COVER_CLASSES): Ditto.\n+\t(rs6000_hard_regno_nregs_internal): If -mvsx, floating point\n+\tregisters are 128 bits if VSX memory reference instructions are\n+\tused.\n+\t(rs6000_hard_regno_mode_ok): For VSX, only check if the VSX memory\n+\tunit is being used.\n+\t(rs6000_debug_vector_unit): Move into rs6000_debug_reg_global.\n+\t(rs6000_debug_reg_global): Move -mdebug=reg statements here.\n+\tPrint several of the scheduling related parameters.\n+\t(rs6000_init_hard_regno_mode_ok): Switch to putting constraints in\n+\trs6000_constraints instead of rs6000_vector_reg_class.  Move\n+\t-mdebug=reg code to rs6000_debug_reg_global.  Add support for\n+\t-mvsx-align-128 debug switch.  Drop testing float_p if VSX or\n+\tAltivec.  Add VSX support.  Setup for secondary reload support on\n+\tAltivec/VSX registers.\n+\t(rs6000_override_options): Make power7 set the scheduling groups\n+\tlike the power5.  Add support for new debug switches to override\n+\tthe scheduling defaults.  Temporarily disable -mcpu=power7 from\n+\tsetting -mvsx.  Add support for debug switches -malways-hint,\n+\t-msched-groups, and -malign-branch-targets.\n+\t(rs6000_buitlin_conversion): Add support for returning unsigned\n+\tvector conversion functions to fix regressions due to stricter\n+\ttype checking.\n+\t(rs6000_builtin_mul_widen_even): Ditto.\n+\t(rs6000_builtin_mul_widen_odd): Ditto.\n+\t(rs6000_builtin_vec_perm): Ditto.\n+\t(rs6000_vec_const_move): On VSX, use xxlxor to clear register.\n+\t(rs6000_expand_vector_init): Initial VSX support for using xxlxor\n+\tto zero a register.\n+\t(rs6000_emit_move): Fixup invalid const symbol_ref+reg that is\n+\tgenerated upstream.\n+\t(bdesc_3arg): Add builtins for unsigned types.  Add builtins for\n+\tVSX types for bit operations.  Changes to accomidate vector.md.\n+\t(bdesc_2arg): Ditto.\n+\t(bdesc_1arg): Ditto.\n+\t(struct builtin_description_predicates): Rewrite predicate\n+\thandling so that RTL describes the operation, instead of passing\n+\tthe instruction to be used as a string argument.\n+\t(bdesc_altivec_preds): Ditto.\n+\t(altivec_expand_predicate_builtin): Ditto.\n+\t(altivec_expand_builtin): Ditto.\n+\t(rs6000_expand_ternop_builtin): Use a switch instead of an if\n+\tstatement for vsldoi support.\n+\t(altivec_expand_ld_builtin): Change to use new names from\n+\tvector.md.\n+\t(altivec_expand_st_builtin): Ditto.\n+\t(paired_expand_builtin): Whitespace changes.\n+\t(rs6000_init_builtins): Add V2DF/V2DI types.  Initialize the\n+\tbuiltin_mode_to_type table for secondary reload.  Call\n+\tbuiltin_function_type to build random builtin functions.\n+\t(altivec_init_builtins): Change to use builtin_function_type to\n+\tcreate builtin function types dynamically as we need them.\n+\t(builtin_hash_function): New support for hashing the tree types\n+\tfor builtin function as we need it, rather than trying to build\n+\tall of the trees that we need.  Add initial preliminary VSX\n+\tsupport.\n+\t(builtin_function_type): Ditto.\n+\t(builtin_function_eq): Ditto.\n+\t(builtin_hash_struct): Ditto.\n+\t(rs6000_init_builtins): Ditto.\n+\t(rs6000_common_init_builtins): Ditto.\n+\t(altivec_init_builtins): Ditto.\n+\t(rs6000_common_init_builtins): Ditto.\n+\t(enum reload_reg_type): New enum for simplifing reg classes.\n+\t(rs6000_reload_register_type): Simplify register classes into GPR,\n+\tVector, and other registers.\n+\tAltivec and VSX addresses in reload.\n+\t(rs6000_secondary_reload_inner): Ditto.\n+\t(rs6000_ira_cover_classes): New target hook, that returns the\n+\tappropriate cover classes, based on -mvsx being used or not.\n+\t(rs6000_secondary_reload_class): Add VSX support.\n+\t(get_vec_cmp_insn): Delete, rewrite vector conditionals.\n+\t(get_vsel_insn): Ditto.\n+\t(rs6000_emit_vector_compare): Rewrite vector conditional support\n+\tso that where we can, we use RTL operators, instead of blindly use\n+\tUNSPEC.\n+\t(rs6000_emit_vector_select): Ditto.\n+\t(rs6000_emit_vector_cond_expr): Ditto.\n+\t(rs6000_emit_minmax): Directly generate min/max under altivec,\n+\tvsx.\n+\t(create_TOC_reference): Add -mdebug=addr support.\n+\t(emit_frame_save): VSX loads/stores need register indexed\n+\taddressing.\n+\n+\t* config/rs6000/rs6000.md: Include vector.md.\n+\n+\t* config/rs6000/t-rs6000 (MD_INCLUDES): Add vector.md.\n+\n+\t* config/rs6000/rs6000-c.c (altivec_overloaded_builtins): Add\n+\tsupport for V2DI, V2DF in logical, permute, select operations.\n+\n+\t* config/rs6000/rs6000.opt (-mvsx-scalar-double): Add new debug\n+\tswitch for vsx/power7.\n+\t(-mvsx-scalar-memory): Ditto.\n+\t(-mvsx-align-128): Ditto.\n+\t(-mallow-movmisalign): Ditto.\n+\t(-mallow-df-permute): Ditto.\n+\t(-msched-groups): Ditto.\n+\t(-malways-hint): Ditto.\n+\t(-malign-branch-targets): Ditto.\n+\t\n+\t* config/rs6000/rs6000.h (IRA_COVER_CLASSES): Delete, use target\n+\thook instead.\n+\t(IRA_COVER_CLASSES_PRE_VSX): Cover classes if not -mvsx.\n+\t(IRA_COVER_CLASSES_VSX): Cover classes if -mvsx.\n+\t(rs6000_vector_reg_class): Delete.\n+\t(rs6000_vsx_reg_class): Ditto.\n+\t(enum rs6000_reg_class_enum): New enum for the constraints that\n+\tvary based on target switches.\n+\t(rs6000_constraints): New array to hold the register class for all\n+\tof the register constraints that vary based on the switches used.\n+\t(ALTIVEC_BUILTIN_*_UNS): Add unsigned builtin functions.\n+\t(enum rs6000_builtins): Add unsigned varients for the builtin\n+\tdeclarations returned by target hooks for expanding multiplies,\n+\tselect, and permute operations.  Add VSX builtins.\n+\t(enum rs6000_builtin_type_index): Add entries for VSX.\n+\t(V2DI_type_node): Ditto.\n+\t(V2DF_type_node): Ditto.\n+\t(unsigned_V2DI_type_node): Ditto.\n+\t(bool_long_type_node): Ditto.\n+\t(intDI_type_internal_node): Ditto.\n+\t(uintDI_type_internal_node): Ditto.\n+\t(double_type_internal_node): Ditto.\n+\n+\t* config/rs6000/altivec.md (whole file): Move all expanders to\n+\tvector.md from altivec.md.  Rename insn matching functions to be\n+\taltivec_foo.\n+\t(UNSPEC_VCMP*): Delete, rewrite vector comparisons.\n+\t(altivec_vcmp*): Ditto.\n+\t(UNSPEC_VPERM_UNS): New, add for unsigned types using vperm.\n+\t(VM): New iterator for moves that includes the VSX types.\n+\t(altivec_vperm_<mode>): Add VSX types.  Add unsigned types.\n+\t(altivec_vperm_<mode>_uns): New, for unsigned types.\n+\t(altivec_vsel_*): Rewrite vector comparisons and predicate\n+\tbuiltins.\n+\t(altivec_eq<mode>): Ditto.\n+\t(altivec_gt<mode>): Ditto.\n+\t(altivec_gtu<mode>): Ditto.\n+\t(altivec_eqv4sf): Ditto.\n+\t(altivec_gev4sf): Ditto.\n+\t(altivec_gtv4sf): Ditto.\n+\t(altivec_vcmpbfp_p): Ditto.\n+\n 2009-07-23  Richard Earnshaw  <rearnsha@arm.com>\n \n \t(split for ior/xor with shift and zero-extend): Cast op3 to "}, {"sha": "58af47c15ce9cf56ce1973eea8d89b139ce94390", "filename": "gcc/config/rs6000/altivec.md", "status": "modified", "additions": 291, "deletions": 689, "changes": 980, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Faltivec.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Faltivec.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Faltivec.md?ref=a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "patch": "@@ -21,18 +21,7 @@\n \n (define_constants\n   [(UNSPEC_VCMPBFP       50)\n-   (UNSPEC_VCMPEQUB      51)\n-   (UNSPEC_VCMPEQUH      52)\n-   (UNSPEC_VCMPEQUW      53)\n-   (UNSPEC_VCMPEQFP      54)\n-   (UNSPEC_VCMPGEFP      55)\n-   (UNSPEC_VCMPGTUB      56)\n-   (UNSPEC_VCMPGTSB      57)\n-   (UNSPEC_VCMPGTUH      58)\n-   (UNSPEC_VCMPGTSH      59)\n-   (UNSPEC_VCMPGTUW      60)\n-   (UNSPEC_VCMPGTSW      61)\n-   (UNSPEC_VCMPGTFP      62)\n+   ;; 51-62 deleted\n    (UNSPEC_VMSUMU        65)\n    (UNSPEC_VMSUMM        66)\n    (UNSPEC_VMSUMSHM      68)\n@@ -63,7 +52,7 @@\n    (UNSPEC_VPKSHUS      101)\n    (UNSPEC_VPKUWUS      102)\n    (UNSPEC_VPKSWUS      103)\n-   (UNSPEC_VRL          104)\n+   ;; 104 deleted\n    (UNSPEC_VSLV4SI      110)\n    (UNSPEC_VSLO         111)\n    (UNSPEC_VSR          118)\n@@ -76,6 +65,7 @@\n    (UNSPEC_VSUM2SWS     134)\n    (UNSPEC_VSUMSWS      135)\n    (UNSPEC_VPERM        144)\n+   (UNSPEC_VPERM_UNS    145)\n    (UNSPEC_VRFIP        148)\n    (UNSPEC_VRFIN        149)\n    (UNSPEC_VRFIM        150)\n@@ -87,18 +77,15 @@\n    (UNSPEC_VEXPTEFP     156)\n    (UNSPEC_VRSQRTEFP    157)\n    (UNSPEC_VREFP        158)\n-   (UNSPEC_VSEL4SI      159)\n-   (UNSPEC_VSEL4SF      160)\n-   (UNSPEC_VSEL8HI      161)\n-   (UNSPEC_VSEL16QI     162)\n+   ;; 159-162 deleted\n    (UNSPEC_VLSDOI       163)\n    (UNSPEC_VUPKHSB      167)\n    (UNSPEC_VUPKHPX      168)\n    (UNSPEC_VUPKHSH      169)\n    (UNSPEC_VUPKLSB      170)\n    (UNSPEC_VUPKLPX      171)\n    (UNSPEC_VUPKLSH      172)\n-   (UNSPEC_PREDICATE    173)\n+   ;; 173 deleted\n    (UNSPEC_DST          190)\n    (UNSPEC_DSTT         191)\n    (UNSPEC_DSTST        192)\n@@ -111,7 +98,7 @@\n    (UNSPEC_STVE         203)\n    (UNSPEC_SET_VSCR     213)\n    (UNSPEC_GET_VRSAVE   214)\n-   (UNSPEC_REALIGN_LOAD 215)\n+   ;; 215 deleted\n    (UNSPEC_REDUC_PLUS   217)\n    (UNSPEC_VECSH        219)\n    (UNSPEC_EXTEVEN_V4SI 220)\n@@ -125,11 +112,11 @@\n    (UNSPEC_INTERHI_V4SI 228)\n    (UNSPEC_INTERHI_V8HI 229)\n    (UNSPEC_INTERHI_V16QI 230)\n-   (UNSPEC_INTERHI_V4SF 231)\n+   ;; delete 231\n    (UNSPEC_INTERLO_V4SI 232)\n    (UNSPEC_INTERLO_V8HI 233)\n    (UNSPEC_INTERLO_V16QI 234)\n-   (UNSPEC_INTERLO_V4SF 235)\n+   ;; delete 235\n    (UNSPEC_LVLX         236)\n    (UNSPEC_LVLXL        237)\n    (UNSPEC_LVRX         238)\n@@ -176,39 +163,20 @@\n (define_mode_iterator VF [V4SF])\n ;; Vec modes, pity mode iterators are not composable\n (define_mode_iterator V [V4SI V8HI V16QI V4SF])\n+;; Vec modes for move/logical/permute ops, include vector types for move not\n+;; otherwise handled by altivec (v2df, v2di, ti)\n+(define_mode_iterator VM [V4SI V8HI V16QI V4SF V2DF V2DI TI])\n \n-(define_mode_attr VI_char [(V4SI \"w\") (V8HI \"h\") (V16QI \"b\")])\n-\n-;; Generic LVX load instruction.\n-(define_insn \"altivec_lvx_<mode>\"\n-  [(set (match_operand:V 0 \"altivec_register_operand\" \"=v\")\n-\t(match_operand:V 1 \"memory_operand\" \"Z\"))]\n-  \"TARGET_ALTIVEC\"\n-  \"lvx %0,%y1\"\n-  [(set_attr \"type\" \"vecload\")])\n+;; Like VM, except don't do TImode\n+(define_mode_iterator VM2 [V4SI V8HI V16QI V4SF V2DF V2DI])\n \n-;; Generic STVX store instruction.\n-(define_insn \"altivec_stvx_<mode>\"\n-  [(set (match_operand:V 0 \"memory_operand\" \"=Z\")\n-\t(match_operand:V 1 \"altivec_register_operand\" \"v\"))]\n-  \"TARGET_ALTIVEC\"\n-  \"stvx %1,%y0\"\n-  [(set_attr \"type\" \"vecstore\")])\n+(define_mode_attr VI_char [(V4SI \"w\") (V8HI \"h\") (V16QI \"b\")])\n \n ;; Vector move instructions.\n-(define_expand \"mov<mode>\"\n-  [(set (match_operand:V 0 \"nonimmediate_operand\" \"\")\n-\t(match_operand:V 1 \"any_operand\" \"\"))]\n-  \"TARGET_ALTIVEC\"\n-{\n-  rs6000_emit_move (operands[0], operands[1], <MODE>mode);\n-  DONE;\n-})\n-\n-(define_insn \"*mov<mode>_internal\"\n-  [(set (match_operand:V 0 \"nonimmediate_operand\" \"=Z,v,v,o,r,r,v\")\n-\t(match_operand:V 1 \"input_operand\" \"v,Z,v,r,o,r,W\"))]\n-  \"TARGET_ALTIVEC \n+(define_insn \"*altivec_mov<mode>\"\n+  [(set (match_operand:VM2 0 \"nonimmediate_operand\" \"=Z,v,v,*o,*r,*r,v,v\")\n+\t(match_operand:VM2 1 \"input_operand\" \"v,Z,v,r,o,r,j,W\"))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\n    && (register_operand (operands[0], <MODE>mode) \n        || register_operand (operands[1], <MODE>mode))\"\n {\n@@ -220,52 +188,42 @@\n     case 3: return \"#\";\n     case 4: return \"#\";\n     case 5: return \"#\";\n-    case 6: return output_vec_const_move (operands);\n+    case 6: return \"vxor %0,%0,%0\";\n+    case 7: return output_vec_const_move (operands);\n     default: gcc_unreachable ();\n     }\n }\n-  [(set_attr \"type\" \"vecstore,vecload,vecsimple,store,load,*,*\")])\n-\n-(define_split\n-  [(set (match_operand:V4SI 0 \"nonimmediate_operand\" \"\")\n-        (match_operand:V4SI 1 \"input_operand\" \"\"))]\n-  \"TARGET_ALTIVEC && reload_completed\n-   && gpr_or_gpr_p (operands[0], operands[1])\"\n-  [(pc)]\n-{\n-  rs6000_split_multireg_move (operands[0], operands[1]); DONE;\n-})\n-\n-(define_split\n-  [(set (match_operand:V8HI 0 \"nonimmediate_operand\" \"\")\n-        (match_operand:V8HI 1 \"input_operand\" \"\"))]\n-  \"TARGET_ALTIVEC && reload_completed\n-   && gpr_or_gpr_p (operands[0], operands[1])\"\n-  [(pc)]\n-{ rs6000_split_multireg_move (operands[0], operands[1]); DONE; })\n-\n-(define_split\n-  [(set (match_operand:V16QI 0 \"nonimmediate_operand\" \"\")\n-        (match_operand:V16QI 1 \"input_operand\" \"\"))]\n-  \"TARGET_ALTIVEC && reload_completed\n-   && gpr_or_gpr_p (operands[0], operands[1])\"\n-  [(pc)]\n-{ rs6000_split_multireg_move (operands[0], operands[1]); DONE; })\n-\n-(define_split\n-  [(set (match_operand:V4SF 0 \"nonimmediate_operand\" \"\")\n-        (match_operand:V4SF 1 \"input_operand\" \"\"))]\n-  \"TARGET_ALTIVEC && reload_completed\n-   && gpr_or_gpr_p (operands[0], operands[1])\"\n-  [(pc)]\n+  [(set_attr \"type\" \"vecstore,vecload,vecsimple,store,load,*,vecsimple,*\")])\n+\n+;; Unlike other altivec moves, allow the GPRs, since a normal use of TImode\n+;; is for unions.  However for plain data movement, slightly favor the vector\n+;; loads\n+(define_insn \"*altivec_movti\"\n+  [(set (match_operand:TI 0 \"nonimmediate_operand\" \"=Z,v,v,?o,?r,?r,v,v\")\n+\t(match_operand:TI 1 \"input_operand\" \"v,Z,v,r,o,r,j,W\"))]\n+  \"VECTOR_MEM_ALTIVEC_P (TImode)\n+   && (register_operand (operands[0], TImode) \n+       || register_operand (operands[1], TImode))\"\n {\n-  rs6000_split_multireg_move (operands[0], operands[1]); DONE;\n-})\n+  switch (which_alternative)\n+    {\n+    case 0: return \"stvx %1,%y0\";\n+    case 1: return \"lvx %0,%y1\";\n+    case 2: return \"vor %0,%1,%1\";\n+    case 3: return \"#\";\n+    case 4: return \"#\";\n+    case 5: return \"#\";\n+    case 6: return \"vxor %0,%0,%0\";\n+    case 7: return output_vec_const_move (operands);\n+    default: gcc_unreachable ();\n+    }\n+}\n+  [(set_attr \"type\" \"vecstore,vecload,vecsimple,store,load,*,vecsimple,*\")])\n \n (define_split\n-  [(set (match_operand:V 0 \"altivec_register_operand\" \"\")\n-\t(match_operand:V 1 \"easy_vector_constant_add_self\" \"\"))]\n-  \"TARGET_ALTIVEC && reload_completed\"\n+  [(set (match_operand:VM 0 \"altivec_register_operand\" \"\")\n+\t(match_operand:VM 1 \"easy_vector_constant_add_self\" \"\"))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode) && reload_completed\"\n   [(set (match_dup 0) (match_dup 3))\n    (set (match_dup 0) (match_dup 4))]\n {\n@@ -346,11 +304,11 @@\n   \"vaddu<VI_char>m %0,%1,%2\"\n   [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"addv4sf3\"\n+(define_insn \"*altivec_addv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n         (plus:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")\n \t \t   (match_operand:V4SF 2 \"register_operand\" \"v\")))]\n-  \"TARGET_ALTIVEC\"\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n   \"vaddfp %0,%1,%2\"\n   [(set_attr \"type\" \"vecfloat\")])\n \n@@ -392,11 +350,11 @@\n   \"vsubu<VI_char>m %0,%1,%2\"\n   [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"subv4sf3\"\n+(define_insn \"*altivec_subv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n         (minus:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")\n                     (match_operand:V4SF 2 \"register_operand\" \"v\")))]\n-  \"TARGET_ALTIVEC\"\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n   \"vsubfp %0,%1,%2\"\n   [(set_attr \"type\" \"vecfloat\")])\n \n@@ -457,131 +415,93 @@\n   \"vcmpbfp %0,%1,%2\"\n   [(set_attr \"type\" \"veccmp\")])\n \n-(define_insn \"altivec_vcmpequb\"\n-  [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n-        (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n-                       (match_operand:V16QI 2 \"register_operand\" \"v\")] \n-                       UNSPEC_VCMPEQUB))]\n+(define_insn \"*altivec_eq<mode>\"\n+  [(set (match_operand:VI 0 \"altivec_register_operand\" \"=v\")\n+\t(eq:VI (match_operand:VI 1 \"altivec_register_operand\" \"v\")\n+\t       (match_operand:VI 2 \"altivec_register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n-  \"vcmpequb %0,%1,%2\"\n-  [(set_attr \"type\" \"vecsimple\")])\n+  \"vcmpequ<VI_char> %0,%1,%2\"\n+  [(set_attr \"type\" \"veccmp\")])\n \n-(define_insn \"altivec_vcmpequh\"\n-  [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n-        (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n-                      (match_operand:V8HI 2 \"register_operand\" \"v\")] \n-                      UNSPEC_VCMPEQUH))]\n+(define_insn \"*altivec_gt<mode>\"\n+  [(set (match_operand:VI 0 \"altivec_register_operand\" \"=v\")\n+\t(gt:VI (match_operand:VI 1 \"altivec_register_operand\" \"v\")\n+\t       (match_operand:VI 2 \"altivec_register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n-  \"vcmpequh %0,%1,%2\"\n-  [(set_attr \"type\" \"vecsimple\")])\n+  \"vcmpgts<VI_char> %0,%1,%2\"\n+  [(set_attr \"type\" \"veccmp\")])\n \n-(define_insn \"altivec_vcmpequw\"\n-  [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 2 \"register_operand\" \"v\")] \n-\t              UNSPEC_VCMPEQUW))]\n+(define_insn \"*altivec_gtu<mode>\"\n+  [(set (match_operand:VI 0 \"altivec_register_operand\" \"=v\")\n+\t(gtu:VI (match_operand:VI 1 \"altivec_register_operand\" \"v\")\n+\t\t(match_operand:VI 2 \"altivec_register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n-  \"vcmpequw %0,%1,%2\"\n-  [(set_attr \"type\" \"vecsimple\")])\n+  \"vcmpgtu<VI_char> %0,%1,%2\"\n+  [(set_attr \"type\" \"veccmp\")])\n \n-(define_insn \"altivec_vcmpeqfp\"\n-  [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SF 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SF 2 \"register_operand\" \"v\")] \n-\t              UNSPEC_VCMPEQFP))]\n-  \"TARGET_ALTIVEC\"\n+(define_insn \"*altivec_eqv4sf\"\n+  [(set (match_operand:V4SF 0 \"altivec_register_operand\" \"=v\")\n+\t(eq:V4SF (match_operand:V4SF 1 \"altivec_register_operand\" \"v\")\n+\t\t (match_operand:V4SF 2 \"altivec_register_operand\" \"v\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n   \"vcmpeqfp %0,%1,%2\"\n   [(set_attr \"type\" \"veccmp\")])\n \n-(define_insn \"altivec_vcmpgefp\"\n-  [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SF 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SF 2 \"register_operand\" \"v\")] \n-\t\t     UNSPEC_VCMPGEFP))]\n-  \"TARGET_ALTIVEC\"\n-  \"vcmpgefp %0,%1,%2\"\n+(define_insn \"*altivec_gtv4sf\"\n+  [(set (match_operand:V4SF 0 \"altivec_register_operand\" \"=v\")\n+\t(gt:V4SF (match_operand:V4SF 1 \"altivec_register_operand\" \"v\")\n+\t\t (match_operand:V4SF 2 \"altivec_register_operand\" \"v\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n+  \"vcmpgtfp %0,%1,%2\"\n   [(set_attr \"type\" \"veccmp\")])\n \n-(define_insn \"altivec_vcmpgtub\"\n-  [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n-        (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n-                       (match_operand:V16QI 2 \"register_operand\" \"v\")] \n-\t\t      UNSPEC_VCMPGTUB))]\n-  \"TARGET_ALTIVEC\"\n-  \"vcmpgtub %0,%1,%2\"\n-  [(set_attr \"type\" \"vecsimple\")])\n-\n-(define_insn \"altivec_vcmpgtsb\"\n-  [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n-        (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n-                       (match_operand:V16QI 2 \"register_operand\" \"v\")] \n-\t\t      UNSPEC_VCMPGTSB))]\n-  \"TARGET_ALTIVEC\"\n-  \"vcmpgtsb %0,%1,%2\"\n-  [(set_attr \"type\" \"vecsimple\")])\n-\n-(define_insn \"altivec_vcmpgtuh\"\n-  [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n-        (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n-                      (match_operand:V8HI 2 \"register_operand\" \"v\")] \n-\t\t     UNSPEC_VCMPGTUH))]\n-  \"TARGET_ALTIVEC\"\n-  \"vcmpgtuh %0,%1,%2\"\n-  [(set_attr \"type\" \"vecsimple\")])\n-\n-(define_insn \"altivec_vcmpgtsh\"\n-  [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n-        (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n-                      (match_operand:V8HI 2 \"register_operand\" \"v\")] \n-\t\t     UNSPEC_VCMPGTSH))]\n-  \"TARGET_ALTIVEC\"\n-  \"vcmpgtsh %0,%1,%2\"\n-  [(set_attr \"type\" \"vecsimple\")])\n-\n-(define_insn \"altivec_vcmpgtuw\"\n-  [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 2 \"register_operand\" \"v\")] \n-\t\t     UNSPEC_VCMPGTUW))]\n-  \"TARGET_ALTIVEC\"\n-  \"vcmpgtuw %0,%1,%2\"\n-  [(set_attr \"type\" \"vecsimple\")])\n+(define_insn \"*altivec_gev4sf\"\n+  [(set (match_operand:V4SF 0 \"altivec_register_operand\" \"=v\")\n+\t(ge:V4SF (match_operand:V4SF 1 \"altivec_register_operand\" \"v\")\n+\t\t (match_operand:V4SF 2 \"altivec_register_operand\" \"v\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n+  \"vcmpgefp %0,%1,%2\"\n+  [(set_attr \"type\" \"veccmp\")])\n \n-(define_insn \"altivec_vcmpgtsw\"\n-  [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 2 \"register_operand\" \"v\")] \n-\t\t     UNSPEC_VCMPGTSW))]\n-  \"TARGET_ALTIVEC\"\n-  \"vcmpgtsw %0,%1,%2\"\n-  [(set_attr \"type\" \"vecsimple\")])\n+(define_insn \"*altivec_vsel<mode>\"\n+  [(set (match_operand:VM 0 \"altivec_register_operand\" \"=v\")\n+\t(if_then_else:VM\n+\t (ne:CC (match_operand:VM 1 \"altivec_register_operand\" \"v\")\n+\t\t(const_int 0))\n+\t (match_operand:VM 2 \"altivec_register_operand\" \"v\")\n+\t (match_operand:VM 3 \"altivec_register_operand\" \"v\")))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"vsel %0,%3,%2,%1\"\n+  [(set_attr \"type\" \"vecperm\")])\n \n-(define_insn \"altivec_vcmpgtfp\"\n-  [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SF 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SF 2 \"register_operand\" \"v\")] \n-\t\t     UNSPEC_VCMPGTFP))]\n-  \"TARGET_ALTIVEC\"\n-  \"vcmpgtfp %0,%1,%2\"\n-  [(set_attr \"type\" \"veccmp\")])\n+(define_insn \"*altivec_vsel<mode>_uns\"\n+  [(set (match_operand:VM 0 \"altivec_register_operand\" \"=v\")\n+\t(if_then_else:VM\n+\t (ne:CCUNS (match_operand:VM 1 \"altivec_register_operand\" \"v\")\n+\t\t   (const_int 0))\n+\t (match_operand:VM 2 \"altivec_register_operand\" \"v\")\n+\t (match_operand:VM 3 \"altivec_register_operand\" \"v\")))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"vsel %0,%3,%2,%1\"\n+  [(set_attr \"type\" \"vecperm\")])\n \n ;; Fused multiply add\n (define_insn \"altivec_vmaddfp\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n \t(plus:V4SF (mult:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")\n \t\t\t      (match_operand:V4SF 2 \"register_operand\" \"v\"))\n \t  \t   (match_operand:V4SF 3 \"register_operand\" \"v\")))]\n-  \"TARGET_ALTIVEC\"\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n   \"vmaddfp %0,%1,%2,%3\"\n   [(set_attr \"type\" \"vecfloat\")])\n \n ;; We do multiply as a fused multiply-add with an add of a -0.0 vector.\n \n-(define_expand \"mulv4sf3\"\n+(define_expand \"altivec_mulv4sf3\"\n   [(use (match_operand:V4SF 0 \"register_operand\" \"\"))\n    (use (match_operand:V4SF 1 \"register_operand\" \"\"))\n    (use (match_operand:V4SF 2 \"register_operand\" \"\"))]\n-  \"TARGET_ALTIVEC && TARGET_FUSED_MADD\"\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode) && TARGET_FUSED_MADD\"\n   \"\n {\n   rtx neg0;\n@@ -631,7 +551,7 @@\n    emit_insn (gen_altivec_vspltisw (sixteen,  gen_rtx_CONST_INT (V4SImode, -16)));\n  \n    swap = gen_reg_rtx (V4SImode);\n-   emit_insn (gen_altivec_vrlw (swap, operands[2], sixteen));\n+   emit_insn (gen_vrotlv4si3 (swap, operands[2], sixteen));\n  \n    one = gen_reg_rtx (V8HImode);\n    convert_move (one, operands[1], 0);\n@@ -684,7 +604,7 @@\n \t(neg:V4SF (minus:V4SF (mult:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")\n \t\t\t       (match_operand:V4SF 2 \"register_operand\" \"v\"))\n \t  \t    (match_operand:V4SF 3 \"register_operand\" \"v\"))))]\n-  \"TARGET_ALTIVEC\"\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n   \"vnmsubfp %0,%1,%2,%3\"\n   [(set_attr \"type\" \"vecfloat\")])\n \n@@ -758,11 +678,11 @@\n   \"vmaxs<VI_char> %0,%1,%2\"\n   [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"smaxv4sf3\"\n+(define_insn \"*altivec_smaxv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n         (smax:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")\n                    (match_operand:V4SF 2 \"register_operand\" \"v\")))]\n-  \"TARGET_ALTIVEC\"\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n   \"vmaxfp %0,%1,%2\"\n   [(set_attr \"type\" \"veccmp\")])\n \n@@ -782,11 +702,11 @@\n   \"vmins<VI_char> %0,%1,%2\"\n   [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"sminv4sf3\"\n+(define_insn \"*altivec_sminv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n         (smin:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")\n                    (match_operand:V4SF 2 \"register_operand\" \"v\")))]\n-  \"TARGET_ALTIVEC\"\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n   \"vminfp %0,%1,%2\"\n   [(set_attr \"type\" \"veccmp\")])\n \n@@ -901,11 +821,11 @@\n \t\t\t\t\t\t    (const_int 3)\n \t\t\t\t\t\t    (const_int 1)]))\n \t\t      (const_int 5)))]\n-  \"TARGET_ALTIVEC\"\n+  \"VECTOR_MEM_ALTIVEC_P (V4SImode)\"\n   \"vmrghw %0,%1,%2\"\n   [(set_attr \"type\" \"vecperm\")])\n \n-(define_insn \"altivec_vmrghsf\"\n+(define_insn \"*altivec_vmrghsf\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n         (vec_merge:V4SF (vec_select:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")\n                                          (parallel [(const_int 0)\n@@ -918,7 +838,7 @@\n                                                     (const_int 3)\n                                                     (const_int 1)]))\n                       (const_int 5)))]\n-  \"TARGET_ALTIVEC\"\n+  \"VECTOR_MEM_ALTIVEC_P (V4SFmode)\"\n   \"vmrghw %0,%1,%2\"\n   [(set_attr \"type\" \"vecperm\")])\n \n@@ -990,35 +910,37 @@\n \n (define_insn \"altivec_vmrglw\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (vec_merge:V4SI (vec_select:V4SI (match_operand:V4SI 1 \"register_operand\" \"v\")\n-\t\t\t\t\t (parallel [(const_int 2)\n-\t\t\t\t\t \t    (const_int 0)\n-\t\t\t\t\t\t    (const_int 3)\n-\t\t\t\t\t\t    (const_int 1)]))\n-                        (vec_select:V4SI (match_operand:V4SI 2 \"register_operand\" \"v\")\n-\t\t\t\t\t (parallel [(const_int 0)\n-\t\t\t\t\t \t    (const_int 2)\n-\t\t\t\t\t\t    (const_int 1)\n-\t\t\t\t\t\t    (const_int 3)]))\n-\t\t      (const_int 5)))]\n-  \"TARGET_ALTIVEC\"\n+        (vec_merge:V4SI\n+\t (vec_select:V4SI (match_operand:V4SI 1 \"register_operand\" \"v\")\n+\t\t\t  (parallel [(const_int 2)\n+\t\t\t\t     (const_int 0)\n+\t\t\t\t     (const_int 3)\n+\t\t\t\t     (const_int 1)]))\n+\t (vec_select:V4SI (match_operand:V4SI 2 \"register_operand\" \"v\")\n+\t\t\t  (parallel [(const_int 0)\n+\t\t\t\t     (const_int 2)\n+\t\t\t\t     (const_int 1)\n+\t\t\t\t     (const_int 3)]))\n+\t (const_int 5)))]\n+  \"VECTOR_MEM_ALTIVEC_P (V4SImode)\"\n   \"vmrglw %0,%1,%2\"\n   [(set_attr \"type\" \"vecperm\")])\n \n-(define_insn \"altivec_vmrglsf\"\n+(define_insn \"*altivec_vmrglsf\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n-        (vec_merge:V4SF (vec_select:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")\n-                                         (parallel [(const_int 2)\n-                                                    (const_int 0)\n-                                                    (const_int 3)\n-                                                    (const_int 1)]))\n-                        (vec_select:V4SF (match_operand:V4SF 2 \"register_operand\" \"v\")\n-                                         (parallel [(const_int 0)\n-                                                    (const_int 2)\n-                                                    (const_int 1)\n-                                                    (const_int 3)]))\n-                      (const_int 5)))]\n-  \"TARGET_ALTIVEC\"\n+        (vec_merge:V4SF\n+\t (vec_select:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")\n+\t\t\t  (parallel [(const_int 2)\n+\t\t\t\t     (const_int 0)\n+\t\t\t\t     (const_int 3)\n+\t\t\t\t     (const_int 1)]))\n+\t (vec_select:V4SF (match_operand:V4SF 2 \"register_operand\" \"v\")\n+\t\t\t  (parallel [(const_int 0)\n+\t\t\t\t     (const_int 2)\n+\t\t\t\t     (const_int 1)\n+\t\t\t\t     (const_int 3)]))\n+\t (const_int 5)))]\n+  \"VECTOR_MEM_ALTIVEC_P (V4SFmode)\"\n   \"vmrglw %0,%1,%2\"\n   [(set_attr \"type\" \"vecperm\")])\n \n@@ -1095,68 +1017,53 @@\n   [(set_attr \"type\" \"veccomplex\")])\n \n \n-;; logical ops\n+;; logical ops.  Have the logical ops follow the memory ops in\n+;; terms of whether to prefer VSX or Altivec\n \n-(define_insn \"and<mode>3\"\n-  [(set (match_operand:VI 0 \"register_operand\" \"=v\")\n-        (and:VI (match_operand:VI 1 \"register_operand\" \"v\")\n-                (match_operand:VI 2 \"register_operand\" \"v\")))]\n-  \"TARGET_ALTIVEC\"\n+(define_insn \"*altivec_and<mode>3\"\n+  [(set (match_operand:VM 0 \"register_operand\" \"=v\")\n+        (and:VM (match_operand:VM 1 \"register_operand\" \"v\")\n+\t\t(match_operand:VM 2 \"register_operand\" \"v\")))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n   \"vand %0,%1,%2\"\n   [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"ior<mode>3\"\n-  [(set (match_operand:VI 0 \"register_operand\" \"=v\")\n-        (ior:VI (match_operand:VI 1 \"register_operand\" \"v\")\n-                (match_operand:VI 2 \"register_operand\" \"v\")))]\n-  \"TARGET_ALTIVEC\"\n+(define_insn \"*altivec_ior<mode>3\"\n+  [(set (match_operand:VM 0 \"register_operand\" \"=v\")\n+        (ior:VM (match_operand:VM 1 \"register_operand\" \"v\")\n+\t\t(match_operand:VM 2 \"register_operand\" \"v\")))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n   \"vor %0,%1,%2\"\n   [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"xor<mode>3\"\n-  [(set (match_operand:VI 0 \"register_operand\" \"=v\")\n-        (xor:VI (match_operand:VI 1 \"register_operand\" \"v\")\n-                (match_operand:VI 2 \"register_operand\" \"v\")))]\n-  \"TARGET_ALTIVEC\"\n+(define_insn \"*altivec_xor<mode>3\"\n+  [(set (match_operand:VM 0 \"register_operand\" \"=v\")\n+        (xor:VM (match_operand:VM 1 \"register_operand\" \"v\")\n+\t\t(match_operand:VM 2 \"register_operand\" \"v\")))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n   \"vxor %0,%1,%2\"\n   [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"xorv4sf3\"\n-  [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n-        (xor:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")\n-                  (match_operand:V4SF 2 \"register_operand\" \"v\")))]\n-  \"TARGET_ALTIVEC\"\n-  \"vxor %0,%1,%2\" \n-  [(set_attr \"type\" \"vecsimple\")])\n-\n-(define_insn \"one_cmpl<mode>2\"\n-  [(set (match_operand:VI 0 \"register_operand\" \"=v\")\n-        (not:VI (match_operand:VI 1 \"register_operand\" \"v\")))]\n-  \"TARGET_ALTIVEC\"\n+(define_insn \"*altivec_one_cmpl<mode>2\"\n+  [(set (match_operand:VM 0 \"register_operand\" \"=v\")\n+        (not:VM (match_operand:VM 1 \"register_operand\" \"v\")))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n   \"vnor %0,%1,%1\"\n   [(set_attr \"type\" \"vecsimple\")])\n   \n-(define_insn \"altivec_nor<mode>3\"\n-  [(set (match_operand:VI 0 \"register_operand\" \"=v\")\n-        (not:VI (ior:VI (match_operand:VI 1 \"register_operand\" \"v\")\n-                        (match_operand:VI 2 \"register_operand\" \"v\"))))]\n-  \"TARGET_ALTIVEC\"\n+(define_insn \"*altivec_nor<mode>3\"\n+  [(set (match_operand:VM 0 \"register_operand\" \"=v\")\n+        (not:VM (ior:VM (match_operand:VM 1 \"register_operand\" \"v\")\n+\t\t\t(match_operand:VM 2 \"register_operand\" \"v\"))))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n   \"vnor %0,%1,%2\"\n   [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"andc<mode>3\"\n-  [(set (match_operand:VI 0 \"register_operand\" \"=v\")\n-        (and:VI (not:VI (match_operand:VI 2 \"register_operand\" \"v\"))\n-                (match_operand:VI 1 \"register_operand\" \"v\")))]\n-  \"TARGET_ALTIVEC\"\n-  \"vandc %0,%1,%2\"\n-  [(set_attr \"type\" \"vecsimple\")])\n-\n-(define_insn \"*andc3_v4sf\"\n-  [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n-        (and:V4SF (not:V4SF (match_operand:V4SF 2 \"register_operand\" \"v\"))\n-                  (match_operand:V4SF 1 \"register_operand\" \"v\")))]\n-  \"TARGET_ALTIVEC\"\n+(define_insn \"*altivec_andc<mode>3\"\n+  [(set (match_operand:VM 0 \"register_operand\" \"=v\")\n+        (and:VM (not:VM (match_operand:VM 2 \"register_operand\" \"v\"))\n+\t\t(match_operand:VM 1 \"register_operand\" \"v\")))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n   \"vandc %0,%1,%2\"\n   [(set_attr \"type\" \"vecsimple\")])\n \n@@ -1247,11 +1154,10 @@\n   \"vpkswus %0,%1,%2\"\n   [(set_attr \"type\" \"vecperm\")])\n \n-(define_insn \"altivec_vrl<VI_char>\"\n+(define_insn \"*altivec_vrl<VI_char>\"\n   [(set (match_operand:VI 0 \"register_operand\" \"=v\")\n-        (unspec:VI [(match_operand:VI 1 \"register_operand\" \"v\")\n-                    (match_operand:VI 2 \"register_operand\" \"v\")]\n-\t\t   UNSPEC_VRL))]\n+        (rotate:VI (match_operand:VI 1 \"register_operand\" \"v\")\n+\t\t   (match_operand:VI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vrl<VI_char> %0,%1,%2\"\n   [(set_attr \"type\" \"vecsimple\")])\n@@ -1274,26 +1180,26 @@\n   \"vslo %0,%1,%2\"\n   [(set_attr \"type\" \"vecperm\")])\n \n-(define_insn \"vashl<mode>3\"\n+(define_insn \"*altivec_vsl<VI_char>\"\n   [(set (match_operand:VI 0 \"register_operand\" \"=v\")\n         (ashift:VI (match_operand:VI 1 \"register_operand\" \"v\")\n-                   (match_operand:VI 2 \"register_operand\" \"v\") ))]\n+\t\t   (match_operand:VI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vsl<VI_char> %0,%1,%2\"\n   [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"vlshr<mode>3\"\n+(define_insn \"*altivec_vsr<VI_char>\"\n   [(set (match_operand:VI 0 \"register_operand\" \"=v\")\n         (lshiftrt:VI (match_operand:VI 1 \"register_operand\" \"v\")\n-                    (match_operand:VI 2 \"register_operand\" \"v\") ))]\n+\t\t     (match_operand:VI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vsr<VI_char> %0,%1,%2\"\n   [(set_attr \"type\" \"vecsimple\")])\n \n-(define_insn \"vashr<mode>3\"\n+(define_insn \"*altivec_vsra<VI_char>\"\n   [(set (match_operand:VI 0 \"register_operand\" \"=v\")\n         (ashiftrt:VI (match_operand:VI 1 \"register_operand\" \"v\")\n-                    (match_operand:VI 2 \"register_operand\" \"v\") ))]\n+\t\t     (match_operand:VI 2 \"register_operand\" \"v\")))]\n   \"TARGET_ALTIVEC\"\n   \"vsra<VI_char> %0,%1,%2\"\n   [(set_attr \"type\" \"vecsimple\")])\n@@ -1386,13 +1292,13 @@\n   \"vspltw %0,%1,%2\"\n   [(set_attr \"type\" \"vecperm\")])\n \n-(define_insn \"*altivec_vspltsf\"\n+(define_insn \"altivec_vspltsf\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n \t(vec_duplicate:V4SF\n \t (vec_select:SF (match_operand:V4SF 1 \"register_operand\" \"v\")\n \t\t\t(parallel\n \t\t\t [(match_operand:QI 2 \"u5bit_cint_operand\" \"i\")]))))]\n-  \"TARGET_ALTIVEC\"\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n   \"vspltw %0,%1,%2\"\n   [(set_attr \"type\" \"vecperm\")])\n \n@@ -1404,19 +1310,29 @@\n   \"vspltis<VI_char> %0,%1\"\n   [(set_attr \"type\" \"vecperm\")])\n \n-(define_insn \"ftruncv4sf2\"\n+(define_insn \"*altivec_ftruncv4sf2\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n   \t(fix:V4SF (match_operand:V4SF 1 \"register_operand\" \"v\")))]\n-  \"TARGET_ALTIVEC\"\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n   \"vrfiz %0,%1\"\n   [(set_attr \"type\" \"vecfloat\")])\n \n (define_insn \"altivec_vperm_<mode>\"\n-  [(set (match_operand:V 0 \"register_operand\" \"=v\")\n-\t(unspec:V [(match_operand:V 1 \"register_operand\" \"v\")\n-\t\t   (match_operand:V 2 \"register_operand\" \"v\")\n-\t\t   (match_operand:V16QI 3 \"register_operand\" \"v\")]\n-\t\t  UNSPEC_VPERM))]\n+  [(set (match_operand:VM 0 \"register_operand\" \"=v\")\n+\t(unspec:VM [(match_operand:VM 1 \"register_operand\" \"v\")\n+\t\t    (match_operand:VM 2 \"register_operand\" \"v\")\n+\t\t    (match_operand:V16QI 3 \"register_operand\" \"v\")]\n+\t\t   UNSPEC_VPERM))]\n+  \"TARGET_ALTIVEC\"\n+  \"vperm %0,%1,%2,%3\"\n+  [(set_attr \"type\" \"vecperm\")])\n+\n+(define_insn \"altivec_vperm_<mode>_uns\"\n+  [(set (match_operand:VM 0 \"register_operand\" \"=v\")\n+\t(unspec:VM [(match_operand:VM 1 \"register_operand\" \"v\")\n+\t\t    (match_operand:VM 2 \"register_operand\" \"v\")\n+\t\t    (match_operand:V16QI 3 \"register_operand\" \"v\")]\n+\t\t   UNSPEC_VPERM_UNS))]\n   \"TARGET_ALTIVEC\"\n   \"vperm %0,%1,%2,%3\"\n   [(set_attr \"type\" \"vecperm\")])\n@@ -1515,185 +1431,11 @@\n   \"vrefp %0,%1\"\n   [(set_attr \"type\" \"vecfloat\")])\n \n-(define_expand \"vcondv4si\"\n-        [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-              (if_then_else:V4SI\n-                (match_operator 3 \"comparison_operator\"\n-                  [(match_operand:V4SI 4 \"register_operand\" \"v\")\n-                   (match_operand:V4SI 5 \"register_operand\" \"v\")])\n-               (match_operand:V4SI 1 \"register_operand\" \"v\")\n-               (match_operand:V4SI 2 \"register_operand\" \"v\")))]\n-\t\"TARGET_ALTIVEC\"\n-\t\"\n-{\n-\tif (rs6000_emit_vector_cond_expr (operands[0], operands[1], operands[2],\n-\t\t\t\t\t  operands[3], operands[4], operands[5]))\n-\tDONE;\n-\telse\n-\tFAIL;\n-}\n-\t\")\n-\n-(define_expand \"vconduv4si\"\n-        [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-              (if_then_else:V4SI\n-                (match_operator 3 \"comparison_operator\"\n-                  [(match_operand:V4SI 4 \"register_operand\" \"v\")\n-                   (match_operand:V4SI 5 \"register_operand\" \"v\")])\n-               (match_operand:V4SI 1 \"register_operand\" \"v\")\n-               (match_operand:V4SI 2 \"register_operand\" \"v\")))]\n-\t\"TARGET_ALTIVEC\"\n-\t\"\n-{\n-\tif (rs6000_emit_vector_cond_expr (operands[0], operands[1], operands[2],\n-\t\t\t\t\t  operands[3], operands[4], operands[5]))\n-\tDONE;\n-\telse\n-\tFAIL;\n-}\n-\t\")\n-\n-(define_expand \"vcondv4sf\"\n-        [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n-              (if_then_else:V4SF\n-                (match_operator 3 \"comparison_operator\"\n-                  [(match_operand:V4SF 4 \"register_operand\" \"v\")\n-                   (match_operand:V4SF 5 \"register_operand\" \"v\")])\n-               (match_operand:V4SF 1 \"register_operand\" \"v\")\n-               (match_operand:V4SF 2 \"register_operand\" \"v\")))]\n-\t\"TARGET_ALTIVEC\"\n-\t\"\n-{\n-\tif (rs6000_emit_vector_cond_expr (operands[0], operands[1], operands[2],\n-\t\t\t\t\t  operands[3], operands[4], operands[5]))\n-\tDONE;\n-\telse\n-\tFAIL;\n-}\n-\t\")\n-\n-(define_expand \"vcondv8hi\"\n-        [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n-              (if_then_else:V8HI\n-                (match_operator 3 \"comparison_operator\"\n-                  [(match_operand:V8HI 4 \"register_operand\" \"v\")\n-                   (match_operand:V8HI 5 \"register_operand\" \"v\")])\n-               (match_operand:V8HI 1 \"register_operand\" \"v\")\n-               (match_operand:V8HI 2 \"register_operand\" \"v\")))]\n-\t\"TARGET_ALTIVEC\"\n-\t\"\n-{\n-\tif (rs6000_emit_vector_cond_expr (operands[0], operands[1], operands[2],\n-\t\t\t\t\t  operands[3], operands[4], operands[5]))\n-\tDONE;\n-\telse\n-\tFAIL;\n-}\n-\t\")\n-\n-(define_expand \"vconduv8hi\"\n-        [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n-              (if_then_else:V8HI\n-                (match_operator 3 \"comparison_operator\"\n-                  [(match_operand:V8HI 4 \"register_operand\" \"v\")\n-                   (match_operand:V8HI 5 \"register_operand\" \"v\")])\n-               (match_operand:V8HI 1 \"register_operand\" \"v\")\n-               (match_operand:V8HI 2 \"register_operand\" \"v\")))]\n-\t\"TARGET_ALTIVEC\"\n-\t\"\n-{\n-\tif (rs6000_emit_vector_cond_expr (operands[0], operands[1], operands[2],\n-\t\t\t\t\t  operands[3], operands[4], operands[5]))\n-\tDONE;\n-\telse\n-\tFAIL;\n-}\n-\t\")\n-\n-(define_expand \"vcondv16qi\"\n-        [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n-              (if_then_else:V16QI\n-                (match_operator 3 \"comparison_operator\"\n-                  [(match_operand:V16QI 4 \"register_operand\" \"v\")\n-                   (match_operand:V16QI 5 \"register_operand\" \"v\")])\n-               (match_operand:V16QI 1 \"register_operand\" \"v\")\n-               (match_operand:V16QI 2 \"register_operand\" \"v\")))]\n-\t\"TARGET_ALTIVEC\"\n-\t\"\n-{\n-\tif (rs6000_emit_vector_cond_expr (operands[0], operands[1], operands[2],\n-\t\t\t\t\t  operands[3], operands[4], operands[5]))\n-\tDONE;\n-\telse\n-\tFAIL;\n-}\n-\t\")\n-\n-(define_expand \"vconduv16qi\"\n-        [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n-              (if_then_else:V16QI\n-                (match_operator 3 \"comparison_operator\"\n-                  [(match_operand:V16QI 4 \"register_operand\" \"v\")\n-                   (match_operand:V16QI 5 \"register_operand\" \"v\")])\n-               (match_operand:V16QI 1 \"register_operand\" \"v\")\n-               (match_operand:V16QI 2 \"register_operand\" \"v\")))]\n-\t\"TARGET_ALTIVEC\"\n-\t\"\n-{\n-\tif (rs6000_emit_vector_cond_expr (operands[0], operands[1], operands[2],\n-\t\t\t\t\t  operands[3], operands[4], operands[5]))\n-\tDONE;\n-\telse\n-\tFAIL;\n-}\n-\t\")\n-\n-\n-(define_insn \"altivec_vsel_v4si\"\n-  [(set (match_operand:V4SI 0 \"register_operand\" \"=v\")\n-        (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 2 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 3 \"register_operand\" \"v\")] \n-\t\t     UNSPEC_VSEL4SI))]\n-  \"TARGET_ALTIVEC\"\n-  \"vsel %0,%1,%2,%3\"\n-  [(set_attr \"type\" \"vecperm\")])\n-\n-(define_insn \"altivec_vsel_v4sf\"\n-  [(set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n-        (unspec:V4SF [(match_operand:V4SF 1 \"register_operand\" \"v\")\n-                      (match_operand:V4SF 2 \"register_operand\" \"v\")\n-                      (match_operand:V4SI 3 \"register_operand\" \"v\")] \n-\t              UNSPEC_VSEL4SF))]\n-  \"TARGET_ALTIVEC\"\n-  \"vsel %0,%1,%2,%3\"\n-  [(set_attr \"type\" \"vecperm\")])\n-\n-(define_insn \"altivec_vsel_v8hi\"\n-  [(set (match_operand:V8HI 0 \"register_operand\" \"=v\")\n-        (unspec:V8HI [(match_operand:V8HI 1 \"register_operand\" \"v\")\n-                      (match_operand:V8HI 2 \"register_operand\" \"v\")\n-                      (match_operand:V8HI 3 \"register_operand\" \"v\")] \n-\t\t     UNSPEC_VSEL8HI))]\n-  \"TARGET_ALTIVEC\"\n-  \"vsel %0,%1,%2,%3\"\n-  [(set_attr \"type\" \"vecperm\")])\n-\n-(define_insn \"altivec_vsel_v16qi\"\n-  [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n-        (unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n-                       (match_operand:V16QI 2 \"register_operand\" \"v\")\n-                       (match_operand:V16QI 3 \"register_operand\" \"v\")] \n-\t\t      UNSPEC_VSEL16QI))]\n-  \"TARGET_ALTIVEC\"\n-  \"vsel %0,%1,%2,%3\"\n-  [(set_attr \"type\" \"vecperm\")])\n-\n (define_insn \"altivec_vsldoi_<mode>\"\n-  [(set (match_operand:V 0 \"register_operand\" \"=v\")\n-        (unspec:V [(match_operand:V 1 \"register_operand\" \"v\")\n-\t\t   (match_operand:V 2 \"register_operand\" \"v\")\n-                   (match_operand:QI 3 \"immediate_operand\" \"i\")]\n+  [(set (match_operand:VM 0 \"register_operand\" \"=v\")\n+        (unspec:VM [(match_operand:VM 1 \"register_operand\" \"v\")\n+\t\t    (match_operand:VM 2 \"register_operand\" \"v\")\n+\t\t    (match_operand:QI 3 \"immediate_operand\" \"i\")]\n \t\t  UNSPEC_VLSDOI))]\n   \"TARGET_ALTIVEC\"\n   \"vsldoi %0,%1,%2,%3\"\n@@ -1747,50 +1489,92 @@\n   \"vupklsh %0,%1\"\n   [(set_attr \"type\" \"vecperm\")])\n \n-;; AltiVec predicates.\n+;; Compare vectors producing a vector result and a predicate, setting CR6 to\n+;; indicate a combined status\n+(define_insn \"*altivec_vcmpequ<VI_char>_p\"\n+  [(set (reg:CC 74)\n+\t(unspec:CC [(eq:CC (match_operand:VI 1 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:VI 2 \"register_operand\" \"v\"))]\n+\t\t   UNSPEC_PREDICATE))\n+   (set (match_operand:VI 0 \"register_operand\" \"=v\")\n+\t(eq:VI (match_dup 1)\n+\t       (match_dup 2)))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"vcmpequ<VI_char>. %0,%1,%2\"\n+  [(set_attr \"type\" \"veccmp\")])\n \n-(define_expand \"cr6_test_for_zero\"\n-  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n-\t(eq:SI (reg:CC 74)\n-\t       (const_int 0)))]\n-  \"TARGET_ALTIVEC\"\n-  \"\")\t\n+(define_insn \"*altivec_vcmpgts<VI_char>_p\"\n+  [(set (reg:CC 74)\n+\t(unspec:CC [(gt:CC (match_operand:VI 1 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:VI 2 \"register_operand\" \"v\"))]\n+\t\t   UNSPEC_PREDICATE))\n+   (set (match_operand:VI 0 \"register_operand\" \"=v\")\n+\t(gt:VI (match_dup 1)\n+\t       (match_dup 2)))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"vcmpgts<VI_char>. %0,%1,%2\"\n+  [(set_attr \"type\" \"veccmp\")])\n \n-(define_expand \"cr6_test_for_zero_reverse\"\n-  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n-\t(eq:SI (reg:CC 74)\n-\t       (const_int 0)))\n-   (set (match_dup 0) (minus:SI (const_int 1) (match_dup 0)))]\n-  \"TARGET_ALTIVEC\"\n-  \"\")\n+(define_insn \"*altivec_vcmpgtu<VI_char>_p\"\n+  [(set (reg:CC 74)\n+\t(unspec:CC [(gtu:CC (match_operand:VI 1 \"register_operand\" \"v\")\n+\t\t\t    (match_operand:VI 2 \"register_operand\" \"v\"))]\n+\t\t   UNSPEC_PREDICATE))\n+   (set (match_operand:VI 0 \"register_operand\" \"=v\")\n+\t(gtu:VI (match_dup 1)\n+\t\t(match_dup 2)))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"vcmpgtu<VI_char>. %0,%1,%2\"\n+  [(set_attr \"type\" \"veccmp\")])\n \n-(define_expand \"cr6_test_for_lt\"\n-  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n-\t(lt:SI (reg:CC 74)\n-\t       (const_int 0)))]\n-  \"TARGET_ALTIVEC\"\n-  \"\")\n+(define_insn \"*altivec_vcmpeqfp_p\"\n+  [(set (reg:CC 74)\n+\t(unspec:CC [(eq:CC (match_operand:V4SF 1 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:V4SF 2 \"register_operand\" \"v\"))]\n+\t\t   UNSPEC_PREDICATE))\n+   (set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n+\t(eq:V4SF (match_dup 1)\n+\t\t (match_dup 2)))]\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n+  \"vcmpeqfp. %0,%1,%2\"\n+  [(set_attr \"type\" \"veccmp\")])\n \n-(define_expand \"cr6_test_for_lt_reverse\"\n-  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n-\t(lt:SI (reg:CC 74)\n-\t       (const_int 0)))\n-   (set (match_dup 0) (minus:SI (const_int 1) (match_dup 0)))]\n-  \"TARGET_ALTIVEC\"\n-  \"\")\n+(define_insn \"*altivec_vcmpgtfp_p\"\n+  [(set (reg:CC 74)\n+\t(unspec:CC [(gt:CC (match_operand:V4SF 1 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:V4SF 2 \"register_operand\" \"v\"))]\n+\t\t   UNSPEC_PREDICATE))\n+   (set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n+\t(gt:V4SF (match_dup 1)\n+\t\t (match_dup 2)))]\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n+  \"vcmpgtfp. %0,%1,%2\"\n+  [(set_attr \"type\" \"veccmp\")])\n \n-;; We can get away with generating the opcode on the fly (%3 below)\n-;; because all the predicates have the same scheduling parameters.\n+(define_insn \"*altivec_vcmpgefp_p\"\n+  [(set (reg:CC 74)\n+\t(unspec:CC [(ge:CC (match_operand:V4SF 1 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:V4SF 2 \"register_operand\" \"v\"))]\n+\t\t   UNSPEC_PREDICATE))\n+   (set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n+\t(ge:V4SF (match_dup 1)\n+\t\t (match_dup 2)))]\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n+  \"vcmpgefp. %0,%1,%2\"\n+  [(set_attr \"type\" \"veccmp\")])\n \n-(define_insn \"altivec_predicate_<mode>\"\n+(define_insn \"altivec_vcmpbfp_p\"\n   [(set (reg:CC 74)\n-\t(unspec:CC [(match_operand:V 1 \"register_operand\" \"v\")\n-\t\t    (match_operand:V 2 \"register_operand\" \"v\")\n-\t\t    (match_operand 3 \"any_operand\" \"\")] UNSPEC_PREDICATE))\n-   (clobber (match_scratch:V 0 \"=v\"))]\n-  \"TARGET_ALTIVEC\"\n-  \"%3 %0,%1,%2\"\n-[(set_attr \"type\" \"veccmp\")])\n+\t(unspec:CC [(match_operand:V4SF 1 \"register_operand\" \"v\")\n+\t\t    (match_operand:V4SF 2 \"register_operand\" \"v\")]\n+\t\t   UNSPEC_VCMPBFP))\n+   (set (match_operand:V4SF 0 \"register_operand\" \"=v\")\n+        (unspec:V4SF [(match_dup 1)\n+                      (match_dup 2)] \n+                      UNSPEC_VCMPBFP))]\n+  \"VECTOR_UNIT_ALTIVEC_OR_VSX_P (V4SFmode)\"\n+  \"vcmpbfp. %0,%1,%2\"\n+  [(set_attr \"type\" \"veccmp\")])\n \n (define_insn \"altivec_mtvscr\"\n   [(set (reg:SI 110)\n@@ -1959,95 +1743,6 @@\n   \"stvewx %1,%y0\"\n   [(set_attr \"type\" \"vecstore\")])\n \n-(define_expand \"vec_init<mode>\"\n-  [(match_operand:V 0 \"register_operand\" \"\")\n-   (match_operand 1 \"\" \"\")]\n-  \"TARGET_ALTIVEC\"\n-{\n-  rs6000_expand_vector_init (operands[0], operands[1]);\n-  DONE;\n-})\n-\n-(define_expand \"vec_setv4si\"\n-  [(match_operand:V4SI 0 \"register_operand\" \"\")\n-   (match_operand:SI 1 \"register_operand\" \"\")\n-   (match_operand 2 \"const_int_operand\" \"\")]\n-  \"TARGET_ALTIVEC\"\n-{\n-  rs6000_expand_vector_set (operands[0], operands[1], INTVAL (operands[2]));\n-  DONE;\n-})\n-\n-(define_expand \"vec_setv8hi\"\n-  [(match_operand:V8HI 0 \"register_operand\" \"\")\n-   (match_operand:HI 1 \"register_operand\" \"\")\n-   (match_operand 2 \"const_int_operand\" \"\")]\n-  \"TARGET_ALTIVEC\"\n-{\n-  rs6000_expand_vector_set (operands[0], operands[1], INTVAL (operands[2]));\n-  DONE;\n-})\n-\n-(define_expand \"vec_setv16qi\"\n-  [(match_operand:V16QI 0 \"register_operand\" \"\")\n-   (match_operand:QI 1 \"register_operand\" \"\")\n-   (match_operand 2 \"const_int_operand\" \"\")]\n-  \"TARGET_ALTIVEC\"\n-{\n-  rs6000_expand_vector_set (operands[0], operands[1], INTVAL (operands[2]));\n-  DONE;\n-})\n-\n-(define_expand \"vec_setv4sf\"\n-  [(match_operand:V4SF 0 \"register_operand\" \"\")\n-   (match_operand:SF 1 \"register_operand\" \"\")\n-   (match_operand 2 \"const_int_operand\" \"\")]\n-  \"TARGET_ALTIVEC\"\n-{\n-  rs6000_expand_vector_set (operands[0], operands[1], INTVAL (operands[2]));\n-  DONE;\n-})\n-\n-(define_expand \"vec_extractv4si\"\n-  [(match_operand:SI 0 \"register_operand\" \"\")\n-   (match_operand:V4SI 1 \"register_operand\" \"\")\n-   (match_operand 2 \"const_int_operand\" \"\")]\n-  \"TARGET_ALTIVEC\"\n-{\n-  rs6000_expand_vector_extract (operands[0], operands[1], INTVAL (operands[2]));\n-  DONE;\n-})\n-\n-(define_expand \"vec_extractv8hi\"\n-  [(match_operand:HI 0 \"register_operand\" \"\")\n-   (match_operand:V8HI 1 \"register_operand\" \"\")\n-   (match_operand 2 \"const_int_operand\" \"\")]\n-  \"TARGET_ALTIVEC\"\n-{\n-  rs6000_expand_vector_extract (operands[0], operands[1], INTVAL (operands[2]));\n-  DONE;\n-})\n-\n-(define_expand \"vec_extractv16qi\"\n-  [(match_operand:QI 0 \"register_operand\" \"\")\n-   (match_operand:V16QI 1 \"register_operand\" \"\")\n-   (match_operand 2 \"const_int_operand\" \"\")]\n-  \"TARGET_ALTIVEC\"\n-{\n-  rs6000_expand_vector_extract (operands[0], operands[1], INTVAL (operands[2]));\n-  DONE;\n-})\n-\n-(define_expand \"vec_extractv4sf\"\n-  [(match_operand:SF 0 \"register_operand\" \"\")\n-   (match_operand:V4SF 1 \"register_operand\" \"\")\n-   (match_operand 2 \"const_int_operand\" \"\")]\n-  \"TARGET_ALTIVEC\"\n-{\n-  rs6000_expand_vector_extract (operands[0], operands[1], INTVAL (operands[2]));\n-  DONE;\n-})\n-\n ;; Generate\n ;;    vspltis? SCRATCH0,0\n ;;    vsubu?m SCRATCH2,SCRATCH1,%1\n@@ -2069,7 +1764,7 @@\n ;;    vspltisw SCRATCH1,-1\n ;;    vslw SCRATCH2,SCRATCH1,SCRATCH1\n ;;    vandc %0,%1,SCRATCH2\n-(define_expand \"absv4sf2\"\n+(define_expand \"altivec_absv4sf2\"\n   [(set (match_dup 2)\n \t(vec_duplicate:V4SI (const_int -1)))\n    (set (match_dup 3)\n@@ -2102,66 +1797,6 @@\n   operands[3] = gen_reg_rtx (GET_MODE (operands[0]));\n })\n \n-;; Vector shift left in bits. Currently supported ony for shift\n-;; amounts that can be expressed as byte shifts (divisible by 8).\n-;; General shift amounts can be supported using vslo + vsl. We're\n-;; not expecting to see these yet (the vectorizer currently\n-;; generates only shifts divisible by byte_size).\n-(define_expand \"vec_shl_<mode>\"\n-  [(set (match_operand:V 0 \"register_operand\" \"=v\")\n-        (unspec:V [(match_operand:V 1 \"register_operand\" \"v\")\n-                   (match_operand:QI 2 \"reg_or_short_operand\" \"\")]\n-\t\t  UNSPEC_VECSH))]\n-  \"TARGET_ALTIVEC\"\n-  \"\n-{\n-  rtx bitshift = operands[2];\n-  rtx byteshift = gen_reg_rtx (QImode);\n-  HOST_WIDE_INT bitshift_val;\n-  HOST_WIDE_INT byteshift_val;\n-\n-  if (! CONSTANT_P (bitshift))\n-    FAIL;\n-  bitshift_val = INTVAL (bitshift);\n-  if (bitshift_val & 0x7)\n-    FAIL;\n-  byteshift_val = bitshift_val >> 3;\n-  byteshift = gen_rtx_CONST_INT (QImode, byteshift_val);\n-  emit_insn (gen_altivec_vsldoi_<mode> (operands[0], operands[1], operands[1],\n-                                        byteshift));\n-  DONE;\n-}\")\n-\n-;; Vector shift left in bits. Currently supported ony for shift\n-;; amounts that can be expressed as byte shifts (divisible by 8).\n-;; General shift amounts can be supported using vsro + vsr. We're\n-;; not expecting to see these yet (the vectorizer currently\n-;; generates only shifts divisible by byte_size).\n-(define_expand \"vec_shr_<mode>\"\n-  [(set (match_operand:V 0 \"register_operand\" \"=v\")\n-        (unspec:V [(match_operand:V 1 \"register_operand\" \"v\")\n-                   (match_operand:QI 2 \"reg_or_short_operand\" \"\")]\n-\t\t  UNSPEC_VECSH))]\n-  \"TARGET_ALTIVEC\"\n-  \"\n-{\n-  rtx bitshift = operands[2];\n-  rtx byteshift = gen_reg_rtx (QImode);\n-  HOST_WIDE_INT bitshift_val;\n-  HOST_WIDE_INT byteshift_val;\n- \n-  if (! CONSTANT_P (bitshift))\n-    FAIL;\n-  bitshift_val = INTVAL (bitshift);\n-  if (bitshift_val & 0x7)\n-    FAIL;\n-  byteshift_val = 16 - (bitshift_val >> 3);\n-  byteshift = gen_rtx_CONST_INT (QImode, byteshift_val);\n-  emit_insn (gen_altivec_vsldoi_<mode> (operands[0], operands[1], operands[1],\n-                                        byteshift));\n-  DONE;\n-}\")\n-\n (define_insn \"altivec_vsumsws_nomode\"\n   [(set (match_operand 0 \"register_operand\" \"=v\")\n         (unspec:V4SI [(match_operand:V4SI 1 \"register_operand\" \"v\")\n@@ -2204,16 +1839,6 @@\n   DONE;\n }\")\n \n-(define_insn \"vec_realign_load_<mode>\"\n-  [(set (match_operand:V 0 \"register_operand\" \"=v\")\n-        (unspec:V [(match_operand:V 1 \"register_operand\" \"v\")\n-                   (match_operand:V 2 \"register_operand\" \"v\")\n-                   (match_operand:V16QI 3 \"register_operand\" \"v\")]\n-\t\t  UNSPEC_REALIGN_LOAD))]\n-  \"TARGET_ALTIVEC\"\n-  \"vperm %0,%1,%2,%3\"\n-  [(set_attr \"type\" \"vecperm\")])\n-\n (define_expand \"neg<mode>2\"\n   [(use (match_operand:VI 0 \"register_operand\" \"\"))\n    (use (match_operand:VI 1 \"register_operand\" \"\"))]\n@@ -2665,7 +2290,7 @@\n   DONE;\n }\")\n \n-(define_expand \"negv4sf2\"\n+(define_expand \"altivec_negv4sf2\"\n   [(use (match_operand:V4SF 0 \"register_operand\" \"\"))\n    (use (match_operand:V4SF 1 \"register_operand\" \"\"))]\n   \"TARGET_ALTIVEC\"\n@@ -2994,29 +2619,6 @@\n   emit_insn (gen_vpkuhum_nomode (operands[0], operands[1], operands[2]));\n   DONE;\n }\")\n-(define_expand \"vec_interleave_highv4sf\"\n- [(set (match_operand:V4SF 0 \"register_operand\" \"\")\n-        (unspec:V4SF [(match_operand:V4SF 1 \"register_operand\" \"\")\n-                      (match_operand:V4SF 2 \"register_operand\" \"\")]\n-                      UNSPEC_INTERHI_V4SF))]\n-  \"TARGET_ALTIVEC\"\n-  \"\n-{ \n-  emit_insn (gen_altivec_vmrghsf (operands[0], operands[1], operands[2]));\n-  DONE;\n-}\")\n-\n-(define_expand \"vec_interleave_lowv4sf\"\n- [(set (match_operand:V4SF 0 \"register_operand\" \"\")\n-        (unspec:V4SF [(match_operand:V4SF 1 \"register_operand\" \"\")\n-                      (match_operand:V4SF 2 \"register_operand\" \"\")]\n-                      UNSPEC_INTERLO_V4SF))]\n-  \"TARGET_ALTIVEC\"\n-  \"\n-{\n-  emit_insn (gen_altivec_vmrglsf (operands[0], operands[1], operands[2]));\n-  DONE;\n-}\")\n \n (define_expand \"vec_interleave_high<mode>\"\n  [(set (match_operand:VI 0 \"register_operand\" \"\")"}, {"sha": "81326aa6d5769e937a28a5a215d8bab93a6c7f3a", "filename": "gcc/config/rs6000/constraints.md", "status": "modified", "additions": 30, "deletions": 4, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Fconstraints.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Fconstraints.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fconstraints.md?ref=a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "patch": "@@ -17,14 +17,14 @@\n ;; along with GCC; see the file COPYING3.  If not see\n ;; <http://www.gnu.org/licenses/>.\n \n+;; Available constraint letters: \"e\", \"k\", \"u\", \"A\", \"B\", \"C\", \"D\"\n+\n ;; Register constraints\n \n-(define_register_constraint \"f\" \"TARGET_HARD_FLOAT && TARGET_FPRS\n-\t\t\t \t ? FLOAT_REGS : NO_REGS\"\n+(define_register_constraint \"f\" \"rs6000_constraints[RS6000_CONSTRAINT_f]\"\n   \"@internal\")\n \n-(define_register_constraint \"d\" \"TARGET_HARD_FLOAT && TARGET_FPRS && TARGET_DOUBLE_FLOAT\n-\t\t\t \t ? FLOAT_REGS : NO_REGS\"\n+(define_register_constraint \"d\" \"rs6000_constraints[RS6000_CONSTRAINT_d]\"\n   \"@internal\")\n \n (define_register_constraint \"b\" \"BASE_REGS\"\n@@ -54,6 +54,28 @@\n (define_register_constraint \"z\" \"XER_REGS\"\n   \"@internal\")\n \n+;; Use w as a prefix to add VSX modes\n+;; vector double (V2DF)\n+(define_register_constraint \"wd\" \"rs6000_constraints[RS6000_CONSTRAINT_wd]\"\n+  \"@internal\")\n+\n+;; vector float (V4SF)\n+(define_register_constraint \"wf\" \"rs6000_constraints[RS6000_CONSTRAINT_wf]\"\n+  \"@internal\")\n+\n+;; scalar double (DF)\n+(define_register_constraint \"ws\" \"rs6000_constraints[RS6000_CONSTRAINT_ws]\"\n+  \"@internal\")\n+\n+;; any VSX register\n+(define_register_constraint \"wa\" \"rs6000_constraints[RS6000_CONSTRAINT_wa]\"\n+  \"@internal\")\n+\n+;; Altivec style load/store that ignores the bottom bits of the address\n+(define_memory_constraint \"wZ\"\n+  \"Indexed or indirect memory operand, ignoring the bottom 4 bits\"\n+  (match_operand 0 \"altivec_indexed_or_indirect_operand\"))\n+\n ;; Integer constraints\n \n (define_constraint \"I\"\n@@ -173,3 +195,7 @@ usually better to use @samp{m} or @samp{es} in @code{asm} statements)\"\n (define_constraint \"W\"\n   \"vector constant that does not require memory\"\n   (match_operand 0 \"easy_vector_constant\"))\n+\n+(define_constraint \"j\"\n+  \"Zero vector constant\"\n+  (match_test \"(op == const0_rtx || op == CONST0_RTX (GET_MODE (op)))\"))"}, {"sha": "3e5c1a1a8df9b5751b76d4124019103a03bd331a", "filename": "gcc/config/rs6000/predicates.md", "status": "modified", "additions": 60, "deletions": 2, "changes": 62, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fpredicates.md?ref=a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "patch": "@@ -38,6 +38,37 @@\n \t\t     || ALTIVEC_REGNO_P (REGNO (op))\n \t\t     || REGNO (op) > LAST_VIRTUAL_REGISTER\")))\n \n+;; Return 1 if op is a VSX register.\n+(define_predicate \"vsx_register_operand\"\n+   (and (match_operand 0 \"register_operand\")\n+\t(match_test \"GET_CODE (op) != REG\n+\t\t     || VSX_REGNO_P (REGNO (op))\n+\t\t     || REGNO (op) > LAST_VIRTUAL_REGISTER\")))\n+\n+;; Return 1 if op is a vector register that operates on floating point vectors\n+;; (either altivec or VSX).\n+(define_predicate \"vfloat_operand\"\n+   (and (match_operand 0 \"register_operand\")\n+\t(match_test \"GET_CODE (op) != REG\n+\t\t     || VFLOAT_REGNO_P (REGNO (op))\n+\t\t     || REGNO (op) > LAST_VIRTUAL_REGISTER\")))\n+\n+;; Return 1 if op is a vector register that operates on integer vectors\n+;; (only altivec, VSX doesn't support integer vectors)\n+(define_predicate \"vint_operand\"\n+   (and (match_operand 0 \"register_operand\")\n+\t(match_test \"GET_CODE (op) != REG\n+\t\t     || VINT_REGNO_P (REGNO (op))\n+\t\t     || REGNO (op) > LAST_VIRTUAL_REGISTER\")))\n+\n+;; Return 1 if op is a vector register to do logical operations on (and, or,\n+;; xor, etc.)\n+(define_predicate \"vlogical_operand\"\n+   (and (match_operand 0 \"register_operand\")\n+\t(match_test \"GET_CODE (op) != REG\n+\t\t     || VLOGICAL_REGNO_P (REGNO (op))\n+\t\t     || REGNO (op) > LAST_VIRTUAL_REGISTER\")))\n+\n ;; Return 1 if op is XER register.\n (define_predicate \"xer_operand\"\n   (and (match_code \"reg\")\n@@ -234,6 +265,10 @@\n \t      && num_insns_constant_wide ((HOST_WIDE_INT) k[3]) == 1);\n \n     case DFmode:\n+      /* The constant 0.f is easy under VSX.  */\n+      if (op == CONST0_RTX (DFmode) && VECTOR_UNIT_VSX_P (DFmode))\n+\treturn 1;\n+\n       /* Force constants to memory before reload to utilize\n \t compress_float_constant.\n \t Avoid this when flag_unsafe_math_optimizations is enabled\n@@ -292,6 +327,9 @@\n   if (TARGET_PAIRED_FLOAT)\n     return false;\n \n+  if ((VSX_VECTOR_MODE (mode) || mode == TImode) && zero_constant (op, mode))\n+    return true;\n+\n   if (ALTIVEC_VECTOR_MODE (mode))\n     {\n       if (zero_constant (op, mode))\n@@ -394,16 +432,36 @@\n   (match_code \"mem\")\n {\n   op = XEXP (op, 0);\n-  if (TARGET_ALTIVEC\n-      && ALTIVEC_VECTOR_MODE (mode)\n+  if (VECTOR_MEM_ALTIVEC_P (mode)\n       && GET_CODE (op) == AND\n       && GET_CODE (XEXP (op, 1)) == CONST_INT\n       && INTVAL (XEXP (op, 1)) == -16)\n     op = XEXP (op, 0);\n \n+  else if (VECTOR_MEM_VSX_P (mode)\n+\t   && GET_CODE (op) == PRE_MODIFY)\n+    op = XEXP (op, 1);\n+\n   return indexed_or_indirect_address (op, mode);\n })\n \n+;; Return 1 if the operand is an indexed or indirect memory operand with an\n+;; AND -16 in it, used to recognize when we need to switch to Altivec loads\n+;; to realign loops instead of VSX (altivec silently ignores the bottom bits,\n+;; while VSX uses the full address and traps)\n+(define_predicate \"altivec_indexed_or_indirect_operand\"\n+  (match_code \"mem\")\n+{\n+  op = XEXP (op, 0);\n+  if (VECTOR_MEM_ALTIVEC_OR_VSX_P (mode)\n+      && GET_CODE (op) == AND\n+      && GET_CODE (XEXP (op, 1)) == CONST_INT\n+      && INTVAL (XEXP (op, 1)) == -16)\n+    return indexed_or_indirect_address (XEXP (op, 0), mode);\n+\n+  return 0;\n+})\n+\n ;; Return 1 if the operand is an indexed or indirect address.\n (define_special_predicate \"indexed_or_indirect_address\"\n   (and (match_test \"REG_P (op)"}, {"sha": "3b3ba96b5cd121735524a6c137b7f83846bc1ca4", "filename": "gcc/config/rs6000/rs6000-c.c", "status": "modified", "additions": 48, "deletions": 0, "changes": 48, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Frs6000-c.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Frs6000-c.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000-c.c?ref=a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "patch": "@@ -670,6 +670,12 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_bool_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_AND, ALTIVEC_BUILTIN_VAND,\n     RS6000_BTI_V4SF, RS6000_BTI_bool_V4SI, RS6000_BTI_V4SF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_AND, ALTIVEC_BUILTIN_VAND,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_AND, ALTIVEC_BUILTIN_VAND,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_AND, ALTIVEC_BUILTIN_VAND,\n+    RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_AND, ALTIVEC_BUILTIN_VAND,\n     RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_AND, ALTIVEC_BUILTIN_VAND,\n@@ -718,6 +724,12 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_bool_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_ANDC, ALTIVEC_BUILTIN_VANDC,\n     RS6000_BTI_V4SF, RS6000_BTI_bool_V4SI, RS6000_BTI_V4SF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_ANDC, ALTIVEC_BUILTIN_VANDC,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_ANDC, ALTIVEC_BUILTIN_VANDC,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_ANDC, ALTIVEC_BUILTIN_VANDC,\n+    RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_ANDC, ALTIVEC_BUILTIN_VANDC,\n     RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_ANDC, ALTIVEC_BUILTIN_VANDC,\n@@ -1482,6 +1494,8 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_unsigned_V8HI, RS6000_BTI_unsigned_V16QI, RS6000_BTI_unsigned_V16QI, 0 },\n   { ALTIVEC_BUILTIN_VEC_NOR, ALTIVEC_BUILTIN_VNOR,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_NOR, ALTIVEC_BUILTIN_VNOR,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_NOR, ALTIVEC_BUILTIN_VNOR,\n     RS6000_BTI_V4SI, RS6000_BTI_V4SI, RS6000_BTI_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_NOR, ALTIVEC_BUILTIN_VNOR,\n@@ -1506,6 +1520,12 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_bool_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_OR, ALTIVEC_BUILTIN_VOR,\n     RS6000_BTI_V4SF, RS6000_BTI_bool_V4SI, RS6000_BTI_V4SF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_OR, ALTIVEC_BUILTIN_VOR,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_OR, ALTIVEC_BUILTIN_VOR,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_OR, ALTIVEC_BUILTIN_VOR,\n+    RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_OR, ALTIVEC_BUILTIN_VOR,\n     RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_OR, ALTIVEC_BUILTIN_VOR,\n@@ -2122,6 +2142,12 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_bool_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_XOR, ALTIVEC_BUILTIN_VXOR,\n     RS6000_BTI_V4SF, RS6000_BTI_bool_V4SI, RS6000_BTI_V4SF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_XOR, ALTIVEC_BUILTIN_VXOR,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, 0 },\n+  { ALTIVEC_BUILTIN_VEC_XOR, ALTIVEC_BUILTIN_VXOR,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, 0 },\n+  { ALTIVEC_BUILTIN_VEC_XOR, ALTIVEC_BUILTIN_VXOR,\n+    RS6000_BTI_V2DF, RS6000_BTI_bool_V4SI, RS6000_BTI_V2DF, 0 },\n   { ALTIVEC_BUILTIN_VEC_XOR, ALTIVEC_BUILTIN_VXOR,\n     RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, RS6000_BTI_bool_V4SI, 0 },\n   { ALTIVEC_BUILTIN_VEC_XOR, ALTIVEC_BUILTIN_VXOR,\n@@ -2366,6 +2392,10 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_unsigned_V4SI, RS6000_BTI_unsigned_V8HI, RS6000_BTI_unsigned_V8HI, RS6000_BTI_unsigned_V4SI },\n   { ALTIVEC_BUILTIN_VEC_NMSUB, ALTIVEC_BUILTIN_VNMSUBFP,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF },\n+  { ALTIVEC_BUILTIN_VEC_PERM, ALTIVEC_BUILTIN_VPERM_2DF,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_unsigned_V16QI },\n+  { ALTIVEC_BUILTIN_VEC_PERM, ALTIVEC_BUILTIN_VPERM_2DI,\n+    RS6000_BTI_V2DI, RS6000_BTI_V2DI, RS6000_BTI_V2DI, RS6000_BTI_unsigned_V16QI },\n   { ALTIVEC_BUILTIN_VEC_PERM, ALTIVEC_BUILTIN_VPERM_4SF,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_unsigned_V16QI },\n   { ALTIVEC_BUILTIN_VEC_PERM, ALTIVEC_BUILTIN_VPERM_4SI,\n@@ -2392,10 +2422,28 @@ const struct altivec_builtin_types altivec_overloaded_builtins[] = {\n     RS6000_BTI_bool_V16QI, RS6000_BTI_bool_V16QI, RS6000_BTI_bool_V16QI, RS6000_BTI_unsigned_V16QI },\n   { ALTIVEC_BUILTIN_VEC_PERM, ALTIVEC_BUILTIN_VPERM_16QI,\n     RS6000_BTI_bool_V16QI, RS6000_BTI_bool_V16QI, RS6000_BTI_bool_V16QI, RS6000_BTI_bool_V16QI },\n+  { ALTIVEC_BUILTIN_VEC_SEL, ALTIVEC_BUILTIN_VSEL_2DF,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_bool_V2DI },\n+  { ALTIVEC_BUILTIN_VEC_SEL, ALTIVEC_BUILTIN_VSEL_2DF,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_unsigned_V2DI },\n+  { ALTIVEC_BUILTIN_VEC_SEL, ALTIVEC_BUILTIN_VSEL_2DF,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DI },\n+  { ALTIVEC_BUILTIN_VEC_SEL, ALTIVEC_BUILTIN_VSEL_2DF,\n+    RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF, RS6000_BTI_V2DF },\n+  { ALTIVEC_BUILTIN_VEC_SEL, ALTIVEC_BUILTIN_VSEL_2DI,\n+    RS6000_BTI_V2DI, RS6000_BTI_V2DI, RS6000_BTI_V2DI, RS6000_BTI_bool_V2DI },\n+  { ALTIVEC_BUILTIN_VEC_SEL, ALTIVEC_BUILTIN_VSEL_2DI,\n+    RS6000_BTI_V2DI, RS6000_BTI_V2DI, RS6000_BTI_V2DI, RS6000_BTI_unsigned_V2DI },\n+  { ALTIVEC_BUILTIN_VEC_SEL, ALTIVEC_BUILTIN_VSEL_2DI,\n+    RS6000_BTI_V2DI, RS6000_BTI_V2DI, RS6000_BTI_V2DI, RS6000_BTI_V2DI },\n   { ALTIVEC_BUILTIN_VEC_SEL, ALTIVEC_BUILTIN_VSEL_4SF,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_bool_V4SI },\n   { ALTIVEC_BUILTIN_VEC_SEL, ALTIVEC_BUILTIN_VSEL_4SF,\n     RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_unsigned_V4SI },\n+  { ALTIVEC_BUILTIN_VEC_SEL, ALTIVEC_BUILTIN_VSEL_4SI,\n+    RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF },\n+  { ALTIVEC_BUILTIN_VEC_SEL, ALTIVEC_BUILTIN_VSEL_4SI,\n+    RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SF, RS6000_BTI_V4SI },\n   { ALTIVEC_BUILTIN_VEC_SEL, ALTIVEC_BUILTIN_VSEL_4SI,\n     RS6000_BTI_V4SI, RS6000_BTI_V4SI, RS6000_BTI_V4SI, RS6000_BTI_bool_V4SI },\n   { ALTIVEC_BUILTIN_VEC_SEL, ALTIVEC_BUILTIN_VSEL_4SI,"}, {"sha": "b077c83c2dbc929255eff8af6f5992ec3f0c8c9a", "filename": "gcc/config/rs6000/rs6000.c", "status": "modified", "additions": 1463, "deletions": 876, "changes": 2339, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Frs6000.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Frs6000.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.c?ref=a72c65c7547434629a04bc6cc9e1dd7c6a3797f6"}, {"sha": "3153243b30d792eadaad91dbe5ff79d9165eb574", "filename": "gcc/config/rs6000/rs6000.h", "status": "modified", "additions": 275, "deletions": 7, "changes": 282, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Frs6000.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Frs6000.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.h?ref=a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "patch": "@@ -1280,12 +1280,24 @@ enum reg_class\n    purpose.  Any move between two registers of a cover class should be\n    cheaper than load or store of the registers.  The macro value is\n    array of register classes with LIM_REG_CLASSES used as the end\n-   marker.  */\n+   marker.\n \n-#define IRA_COVER_CLASSES\t\t\t\t\t\t     \\\n+   We need two IRA_COVER_CLASSES, one for pre-VSX, and the other for VSX to\n+   account for the Altivec and Floating registers being subsets of the VSX\n+   register set.  */\n+\n+#define IRA_COVER_CLASSES_PRE_VSX\t\t\t\t\t     \\\n {\t\t\t\t\t\t\t\t\t     \\\n-  GENERAL_REGS, SPECIAL_REGS, FLOAT_REGS, ALTIVEC_REGS,\t\t\t     \\\n-  /*VRSAVE_REGS,*/ VSCR_REGS, SPE_ACC_REGS, SPEFSCR_REGS,\t\t     \\\n+  GENERAL_REGS, SPECIAL_REGS, FLOAT_REGS, ALTIVEC_REGS, /* VSX_REGS, */\t     \\\n+  /* VRSAVE_REGS,*/ VSCR_REGS, SPE_ACC_REGS, SPEFSCR_REGS,\t\t     \\\n+  /* MQ_REGS, LINK_REGS, CTR_REGS, */\t\t\t\t\t     \\\n+  CR_REGS, XER_REGS, LIM_REG_CLASSES\t\t\t\t\t     \\\n+}\n+\n+#define IRA_COVER_CLASSES_VSX\t\t\t\t\t\t     \\\n+{\t\t\t\t\t\t\t\t\t     \\\n+  GENERAL_REGS, SPECIAL_REGS, /* FLOAT_REGS, ALTIVEC_REGS, */ VSX_REGS,\t     \\\n+  /* VRSAVE_REGS,*/ VSCR_REGS, SPE_ACC_REGS, SPEFSCR_REGS,\t\t     \\\n   /* MQ_REGS, LINK_REGS, CTR_REGS, */\t\t\t\t\t     \\\n   CR_REGS, XER_REGS, LIM_REG_CLASSES\t\t\t\t\t     \\\n }\n@@ -1306,9 +1318,20 @@ extern enum reg_class rs6000_regno_regclass[FIRST_PSEUDO_REGISTER];\n #define REGNO_REG_CLASS(REGNO) rs6000_regno_regclass[(REGNO)]\n #endif\n \n-/* Register classes for altivec registers (and eventually other vector\n-   units).  */\n-extern enum reg_class rs6000_vector_reg_class[];\n+/* Register classes for various constraints that are based on the target\n+   switches.  */\n+enum r6000_reg_class_enum {\n+  RS6000_CONSTRAINT_d,\t\t/* fpr registers for double values */\n+  RS6000_CONSTRAINT_f,\t\t/* fpr registers for single values */\n+  RS6000_CONSTRAINT_v,\t\t/* Altivec registers */\n+  RS6000_CONSTRAINT_wa,\t\t/* Any VSX register */\n+  RS6000_CONSTRAINT_wd,\t\t/* VSX register for V2DF */\n+  RS6000_CONSTRAINT_wf,\t\t/* VSX register for V4SF */\n+  RS6000_CONSTRAINT_ws,\t\t/* VSX register for DF */\n+  RS6000_CONSTRAINT_MAX\n+};\n+\n+extern enum reg_class rs6000_constraints[RS6000_CONSTRAINT_MAX];\n \n /* The class value for index registers, and the one for base regs.  */\n #define INDEX_REG_CLASS GENERAL_REGS\n@@ -2493,24 +2516,40 @@ enum rs6000_builtins\n   ALTIVEC_BUILTIN_VMINSW,\n   ALTIVEC_BUILTIN_VMINFP,\n   ALTIVEC_BUILTIN_VMULEUB,\n+  ALTIVEC_BUILTIN_VMULEUB_UNS,\n   ALTIVEC_BUILTIN_VMULESB,\n   ALTIVEC_BUILTIN_VMULEUH,\n+  ALTIVEC_BUILTIN_VMULEUH_UNS,\n   ALTIVEC_BUILTIN_VMULESH,\n   ALTIVEC_BUILTIN_VMULOUB,\n+  ALTIVEC_BUILTIN_VMULOUB_UNS,\n   ALTIVEC_BUILTIN_VMULOSB,\n   ALTIVEC_BUILTIN_VMULOUH,\n+  ALTIVEC_BUILTIN_VMULOUH_UNS,\n   ALTIVEC_BUILTIN_VMULOSH,\n   ALTIVEC_BUILTIN_VNMSUBFP,\n   ALTIVEC_BUILTIN_VNOR,\n   ALTIVEC_BUILTIN_VOR,\n+  ALTIVEC_BUILTIN_VSEL_2DF,\t\t/* needed for VSX */\n+  ALTIVEC_BUILTIN_VSEL_2DI,\t\t/* needed for VSX */\n   ALTIVEC_BUILTIN_VSEL_4SI,\n   ALTIVEC_BUILTIN_VSEL_4SF,\n   ALTIVEC_BUILTIN_VSEL_8HI,\n   ALTIVEC_BUILTIN_VSEL_16QI,\n+  ALTIVEC_BUILTIN_VSEL_2DI_UNS,\n+  ALTIVEC_BUILTIN_VSEL_4SI_UNS,\n+  ALTIVEC_BUILTIN_VSEL_8HI_UNS,\n+  ALTIVEC_BUILTIN_VSEL_16QI_UNS,\n+  ALTIVEC_BUILTIN_VPERM_2DF,\t\t/* needed for VSX */\n+  ALTIVEC_BUILTIN_VPERM_2DI,\t\t/* needed for VSX */\n   ALTIVEC_BUILTIN_VPERM_4SI,\n   ALTIVEC_BUILTIN_VPERM_4SF,\n   ALTIVEC_BUILTIN_VPERM_8HI,\n   ALTIVEC_BUILTIN_VPERM_16QI,\n+  ALTIVEC_BUILTIN_VPERM_2DI_UNS,\n+  ALTIVEC_BUILTIN_VPERM_4SI_UNS,\n+  ALTIVEC_BUILTIN_VPERM_8HI_UNS,\n+  ALTIVEC_BUILTIN_VPERM_16QI_UNS,\n   ALTIVEC_BUILTIN_VPKUHUM,\n   ALTIVEC_BUILTIN_VPKUWUM,\n   ALTIVEC_BUILTIN_VPKPX,\n@@ -3138,6 +3177,219 @@ enum rs6000_builtins\n   RS6000_BUILTIN_RSQRTF,\n   RS6000_BUILTIN_BSWAP_HI,\n \n+  /* VSX builtins.  */\n+  VSX_BUILTIN_LXSDUX,\n+  VSX_BUILTIN_LXSDX,\n+  VSX_BUILTIN_LXVD2UX,\n+  VSX_BUILTIN_LXVD2X,\n+  VSX_BUILTIN_LXVDSX,\n+  VSX_BUILTIN_LXVW4UX,\n+  VSX_BUILTIN_LXVW4X,\n+  VSX_BUILTIN_STXSDUX,\n+  VSX_BUILTIN_STXSDX,\n+  VSX_BUILTIN_STXVD2UX,\n+  VSX_BUILTIN_STXVD2X,\n+  VSX_BUILTIN_STXVW4UX,\n+  VSX_BUILTIN_STXVW4X,\n+  VSX_BUILTIN_XSABSDP,\n+  VSX_BUILTIN_XSADDDP,\n+  VSX_BUILTIN_XSCMPODP,\n+  VSX_BUILTIN_XSCMPUDP,\n+  VSX_BUILTIN_XSCPSGNDP,\n+  VSX_BUILTIN_XSCVDPSP,\n+  VSX_BUILTIN_XSCVDPSXDS,\n+  VSX_BUILTIN_XSCVDPSXWS,\n+  VSX_BUILTIN_XSCVDPUXDS,\n+  VSX_BUILTIN_XSCVDPUXWS,\n+  VSX_BUILTIN_XSCVSPDP,\n+  VSX_BUILTIN_XSCVSXDDP,\n+  VSX_BUILTIN_XSCVUXDDP,\n+  VSX_BUILTIN_XSDIVDP,\n+  VSX_BUILTIN_XSMADDADP,\n+  VSX_BUILTIN_XSMADDMDP,\n+  VSX_BUILTIN_XSMAXDP,\n+  VSX_BUILTIN_XSMINDP,\n+  VSX_BUILTIN_XSMOVDP,\n+  VSX_BUILTIN_XSMSUBADP,\n+  VSX_BUILTIN_XSMSUBMDP,\n+  VSX_BUILTIN_XSMULDP,\n+  VSX_BUILTIN_XSNABSDP,\n+  VSX_BUILTIN_XSNEGDP,\n+  VSX_BUILTIN_XSNMADDADP,\n+  VSX_BUILTIN_XSNMADDMDP,\n+  VSX_BUILTIN_XSNMSUBADP,\n+  VSX_BUILTIN_XSNMSUBMDP,\n+  VSX_BUILTIN_XSRDPI,\n+  VSX_BUILTIN_XSRDPIC,\n+  VSX_BUILTIN_XSRDPIM,\n+  VSX_BUILTIN_XSRDPIP,\n+  VSX_BUILTIN_XSRDPIZ,\n+  VSX_BUILTIN_XSREDP,\n+  VSX_BUILTIN_XSRSQRTEDP,\n+  VSX_BUILTIN_XSSQRTDP,\n+  VSX_BUILTIN_XSSUBDP,\n+  VSX_BUILTIN_XSTDIVDP_FE,\n+  VSX_BUILTIN_XSTDIVDP_FG,\n+  VSX_BUILTIN_XSTSQRTDP_FE,\n+  VSX_BUILTIN_XSTSQRTDP_FG,\n+  VSX_BUILTIN_XVABSDP,\n+  VSX_BUILTIN_XVABSSP,\n+  VSX_BUILTIN_XVADDDP,\n+  VSX_BUILTIN_XVADDSP,\n+  VSX_BUILTIN_XVCMPEQDP,\n+  VSX_BUILTIN_XVCMPEQSP,\n+  VSX_BUILTIN_XVCMPGEDP,\n+  VSX_BUILTIN_XVCMPGESP,\n+  VSX_BUILTIN_XVCMPGTDP,\n+  VSX_BUILTIN_XVCMPGTSP,\n+  VSX_BUILTIN_XVCMPEQDP_P,\n+  VSX_BUILTIN_XVCMPEQSP_P,\n+  VSX_BUILTIN_XVCMPGEDP_P,\n+  VSX_BUILTIN_XVCMPGESP_P,\n+  VSX_BUILTIN_XVCMPGTDP_P,\n+  VSX_BUILTIN_XVCMPGTSP_P,\n+  VSX_BUILTIN_XVCPSGNDP,\n+  VSX_BUILTIN_XVCPSGNSP,\n+  VSX_BUILTIN_XVCVDPSP,\n+  VSX_BUILTIN_XVCVDPSXDS,\n+  VSX_BUILTIN_XVCVDPSXWS,\n+  VSX_BUILTIN_XVCVDPUXDS,\n+  VSX_BUILTIN_XVCVDPUXDS_UNS,\n+  VSX_BUILTIN_XVCVDPUXWS,\n+  VSX_BUILTIN_XVCVSPDP,\n+  VSX_BUILTIN_XVCVSPSXDS,\n+  VSX_BUILTIN_XVCVSPSXWS,\n+  VSX_BUILTIN_XVCVSPUXDS,\n+  VSX_BUILTIN_XVCVSPUXWS,\n+  VSX_BUILTIN_XVCVSXDDP,\n+  VSX_BUILTIN_XVCVSXDSP,\n+  VSX_BUILTIN_XVCVSXWDP,\n+  VSX_BUILTIN_XVCVSXWSP,\n+  VSX_BUILTIN_XVCVUXDDP,\n+  VSX_BUILTIN_XVCVUXDDP_UNS,\n+  VSX_BUILTIN_XVCVUXDSP,\n+  VSX_BUILTIN_XVCVUXWDP,\n+  VSX_BUILTIN_XVCVUXWSP,\n+  VSX_BUILTIN_XVDIVDP,\n+  VSX_BUILTIN_XVDIVSP,\n+  VSX_BUILTIN_XVMADDDP,\n+  VSX_BUILTIN_XVMADDSP,\n+  VSX_BUILTIN_XVMAXDP,\n+  VSX_BUILTIN_XVMAXSP,\n+  VSX_BUILTIN_XVMINDP,\n+  VSX_BUILTIN_XVMINSP,\n+  VSX_BUILTIN_XVMSUBDP,\n+  VSX_BUILTIN_XVMSUBSP,\n+  VSX_BUILTIN_XVMULDP,\n+  VSX_BUILTIN_XVMULSP,\n+  VSX_BUILTIN_XVNABSDP,\n+  VSX_BUILTIN_XVNABSSP,\n+  VSX_BUILTIN_XVNEGDP,\n+  VSX_BUILTIN_XVNEGSP,\n+  VSX_BUILTIN_XVNMADDDP,\n+  VSX_BUILTIN_XVNMADDSP,\n+  VSX_BUILTIN_XVNMSUBDP,\n+  VSX_BUILTIN_XVNMSUBSP,\n+  VSX_BUILTIN_XVRDPI,\n+  VSX_BUILTIN_XVRDPIC,\n+  VSX_BUILTIN_XVRDPIM,\n+  VSX_BUILTIN_XVRDPIP,\n+  VSX_BUILTIN_XVRDPIZ,\n+  VSX_BUILTIN_XVREDP,\n+  VSX_BUILTIN_XVRESP,\n+  VSX_BUILTIN_XVRSPI,\n+  VSX_BUILTIN_XVRSPIC,\n+  VSX_BUILTIN_XVRSPIM,\n+  VSX_BUILTIN_XVRSPIP,\n+  VSX_BUILTIN_XVRSPIZ,\n+  VSX_BUILTIN_XVRSQRTEDP,\n+  VSX_BUILTIN_XVRSQRTESP,\n+  VSX_BUILTIN_XVSQRTDP,\n+  VSX_BUILTIN_XVSQRTSP,\n+  VSX_BUILTIN_XVSUBDP,\n+  VSX_BUILTIN_XVSUBSP,\n+  VSX_BUILTIN_XVTDIVDP_FE,\n+  VSX_BUILTIN_XVTDIVDP_FG,\n+  VSX_BUILTIN_XVTDIVSP_FE,\n+  VSX_BUILTIN_XVTDIVSP_FG,\n+  VSX_BUILTIN_XVTSQRTDP_FE,\n+  VSX_BUILTIN_XVTSQRTDP_FG,\n+  VSX_BUILTIN_XVTSQRTSP_FE,\n+  VSX_BUILTIN_XVTSQRTSP_FG,\n+  VSX_BUILTIN_XXSEL_2DI,\n+  VSX_BUILTIN_XXSEL_2DF,\n+  VSX_BUILTIN_XXSEL_4SI,\n+  VSX_BUILTIN_XXSEL_4SF,\n+  VSX_BUILTIN_XXSEL_8HI,\n+  VSX_BUILTIN_XXSEL_16QI,\n+  VSX_BUILTIN_XXSEL_2DI_UNS,\n+  VSX_BUILTIN_XXSEL_4SI_UNS,\n+  VSX_BUILTIN_XXSEL_8HI_UNS,\n+  VSX_BUILTIN_XXSEL_16QI_UNS,\n+  VSX_BUILTIN_VPERM_2DI,\n+  VSX_BUILTIN_VPERM_2DF,\n+  VSX_BUILTIN_VPERM_4SI,\n+  VSX_BUILTIN_VPERM_4SF,\n+  VSX_BUILTIN_VPERM_8HI,\n+  VSX_BUILTIN_VPERM_16QI,\n+  VSX_BUILTIN_VPERM_2DI_UNS,\n+  VSX_BUILTIN_VPERM_4SI_UNS,\n+  VSX_BUILTIN_VPERM_8HI_UNS,\n+  VSX_BUILTIN_VPERM_16QI_UNS,\n+  VSX_BUILTIN_XXPERMDI_2DF,\n+  VSX_BUILTIN_XXPERMDI_2DI,\n+  VSX_BUILTIN_XXPERMDI_4SF,\n+  VSX_BUILTIN_XXPERMDI_4SI,\n+  VSX_BUILTIN_XXPERMDI_8HI,\n+  VSX_BUILTIN_XXPERMDI_16QI,\n+  VSX_BUILTIN_CONCAT_2DF,\n+  VSX_BUILTIN_CONCAT_2DI,\n+  VSX_BUILTIN_SET_2DF,\n+  VSX_BUILTIN_SET_2DI,\n+  VSX_BUILTIN_SPLAT_2DF,\n+  VSX_BUILTIN_SPLAT_2DI,\n+  VSX_BUILTIN_XXMRGHW_4SF,\n+  VSX_BUILTIN_XXMRGHW_4SI,\n+  VSX_BUILTIN_XXMRGLW_4SF,\n+  VSX_BUILTIN_XXMRGLW_4SI,\n+  VSX_BUILTIN_XXSLDWI_16QI,\n+  VSX_BUILTIN_XXSLDWI_8HI,\n+  VSX_BUILTIN_XXSLDWI_4SI,\n+  VSX_BUILTIN_XXSLDWI_4SF,\n+  VSX_BUILTIN_XXSLDWI_2DI,\n+  VSX_BUILTIN_XXSLDWI_2DF,\n+  VSX_BUILTIN_VEC_INIT_V2DF,\n+  VSX_BUILTIN_VEC_INIT_V2DI,\n+  VSX_BUILTIN_VEC_SET_V2DF,\n+  VSX_BUILTIN_VEC_SET_V2DI,\n+  VSX_BUILTIN_VEC_EXT_V2DF,\n+  VSX_BUILTIN_VEC_EXT_V2DI,\n+\n+  /* VSX overloaded builtins, add the overloaded functions not present in\n+     Altivec.  */\n+  VSX_BUILTIN_VEC_MUL,\n+  VSX_BUILTIN_OVERLOADED_FIRST = VSX_BUILTIN_VEC_MUL,\n+  VSX_BUILTIN_VEC_MSUB,\n+  VSX_BUILTIN_VEC_NMADD,\n+  VSX_BUITLIN_VEC_NMSUB,\n+  VSX_BUILTIN_VEC_DIV,\n+  VSX_BUILTIN_VEC_XXMRGHW,\n+  VSX_BUILTIN_VEC_XXMRGLW,\n+  VSX_BUILTIN_VEC_XXPERMDI,\n+  VSX_BUILTIN_VEC_XXSLDWI,\n+  VSX_BUILTIN_VEC_XXSPLTD,\n+  VSX_BUILTIN_VEC_XXSPLTW,\n+  VSX_BUILTIN_OVERLOADED_LAST = VSX_BUILTIN_VEC_XXSPLTW,\n+\n+  /* Combined VSX/Altivec builtins.  */\n+  VECTOR_BUILTIN_FLOAT_V4SI_V4SF,\n+  VECTOR_BUILTIN_UNSFLOAT_V4SI_V4SF,\n+  VECTOR_BUILTIN_FIX_V4SF_V4SI,\n+  VECTOR_BUILTIN_FIXUNS_V4SF_V4SI,\n+\n+  /* Power7 builtins, that aren't VSX instructions.  */\n+  POWER7_BUILTIN_BPERMD,\n+\n   RS6000_BUILTIN_COUNT\n };\n \n@@ -3151,20 +3403,25 @@ enum rs6000_builtin_type_index\n   RS6000_BTI_V16QI,\n   RS6000_BTI_V2SI,\n   RS6000_BTI_V2SF,\n+  RS6000_BTI_V2DI,\n+  RS6000_BTI_V2DF,\n   RS6000_BTI_V4HI,\n   RS6000_BTI_V4SI,\n   RS6000_BTI_V4SF,\n   RS6000_BTI_V8HI,\n   RS6000_BTI_unsigned_V16QI,\n   RS6000_BTI_unsigned_V8HI,\n   RS6000_BTI_unsigned_V4SI,\n+  RS6000_BTI_unsigned_V2DI,\n   RS6000_BTI_bool_char,          /* __bool char */\n   RS6000_BTI_bool_short,         /* __bool short */\n   RS6000_BTI_bool_int,           /* __bool int */\n+  RS6000_BTI_bool_long,\t\t /* __bool long */\n   RS6000_BTI_pixel,              /* __pixel */\n   RS6000_BTI_bool_V16QI,         /* __vector __bool char */\n   RS6000_BTI_bool_V8HI,          /* __vector __bool short */\n   RS6000_BTI_bool_V4SI,          /* __vector __bool int */\n+  RS6000_BTI_bool_V2DI,          /* __vector __bool long */\n   RS6000_BTI_pixel_V8HI,         /* __vector __pixel */\n   RS6000_BTI_long,\t         /* long_integer_type_node */\n   RS6000_BTI_unsigned_long,      /* long_unsigned_type_node */\n@@ -3174,7 +3431,10 @@ enum rs6000_builtin_type_index\n   RS6000_BTI_UINTHI,\t\t /* unsigned_intHI_type_node */\n   RS6000_BTI_INTSI,\t\t /* intSI_type_node */\n   RS6000_BTI_UINTSI,\t\t /* unsigned_intSI_type_node */\n+  RS6000_BTI_INTDI,\t\t /* intDI_type_node */\n+  RS6000_BTI_UINTDI,\t\t /* unsigned_intDI_type_node */\n   RS6000_BTI_float,\t         /* float_type_node */\n+  RS6000_BTI_double,\t         /* double_type_node */\n   RS6000_BTI_void,\t         /* void_type_node */\n   RS6000_BTI_MAX\n };\n@@ -3185,6 +3445,8 @@ enum rs6000_builtin_type_index\n #define opaque_p_V2SI_type_node       (rs6000_builtin_types[RS6000_BTI_opaque_p_V2SI])\n #define opaque_V4SI_type_node         (rs6000_builtin_types[RS6000_BTI_opaque_V4SI])\n #define V16QI_type_node               (rs6000_builtin_types[RS6000_BTI_V16QI])\n+#define V2DI_type_node                (rs6000_builtin_types[RS6000_BTI_V2DI])\n+#define V2DF_type_node                (rs6000_builtin_types[RS6000_BTI_V2DF])\n #define V2SI_type_node                (rs6000_builtin_types[RS6000_BTI_V2SI])\n #define V2SF_type_node                (rs6000_builtin_types[RS6000_BTI_V2SF])\n #define V4HI_type_node                (rs6000_builtin_types[RS6000_BTI_V4HI])\n@@ -3194,13 +3456,16 @@ enum rs6000_builtin_type_index\n #define unsigned_V16QI_type_node      (rs6000_builtin_types[RS6000_BTI_unsigned_V16QI])\n #define unsigned_V8HI_type_node       (rs6000_builtin_types[RS6000_BTI_unsigned_V8HI])\n #define unsigned_V4SI_type_node       (rs6000_builtin_types[RS6000_BTI_unsigned_V4SI])\n+#define unsigned_V2DI_type_node       (rs6000_builtin_types[RS6000_BTI_unsigned_V2DI])\n #define bool_char_type_node           (rs6000_builtin_types[RS6000_BTI_bool_char])\n #define bool_short_type_node          (rs6000_builtin_types[RS6000_BTI_bool_short])\n #define bool_int_type_node            (rs6000_builtin_types[RS6000_BTI_bool_int])\n+#define bool_long_type_node           (rs6000_builtin_types[RS6000_BTI_bool_long])\n #define pixel_type_node               (rs6000_builtin_types[RS6000_BTI_pixel])\n #define bool_V16QI_type_node\t      (rs6000_builtin_types[RS6000_BTI_bool_V16QI])\n #define bool_V8HI_type_node\t      (rs6000_builtin_types[RS6000_BTI_bool_V8HI])\n #define bool_V4SI_type_node\t      (rs6000_builtin_types[RS6000_BTI_bool_V4SI])\n+#define bool_V2DI_type_node\t      (rs6000_builtin_types[RS6000_BTI_bool_V2DI])\n #define pixel_V8HI_type_node\t      (rs6000_builtin_types[RS6000_BTI_pixel_V8HI])\n \n #define long_integer_type_internal_node  (rs6000_builtin_types[RS6000_BTI_long])\n@@ -3211,7 +3476,10 @@ enum rs6000_builtin_type_index\n #define uintHI_type_internal_node\t (rs6000_builtin_types[RS6000_BTI_UINTHI])\n #define intSI_type_internal_node\t (rs6000_builtin_types[RS6000_BTI_INTSI])\n #define uintSI_type_internal_node\t (rs6000_builtin_types[RS6000_BTI_UINTSI])\n+#define intDI_type_internal_node\t (rs6000_builtin_types[RS6000_BTI_INTDI])\n+#define uintDI_type_internal_node\t (rs6000_builtin_types[RS6000_BTI_UINTDI])\n #define float_type_internal_node\t (rs6000_builtin_types[RS6000_BTI_float])\n+#define double_type_internal_node\t (rs6000_builtin_types[RS6000_BTI_double])\n #define void_type_internal_node\t\t (rs6000_builtin_types[RS6000_BTI_void])\n \n extern GTY(()) tree rs6000_builtin_types[RS6000_BTI_MAX];"}, {"sha": "ae1ea99d0a3445bcb86e3fc05f2608ca2cb86005", "filename": "gcc/config/rs6000/rs6000.md", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Frs6000.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Frs6000.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.md?ref=a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "patch": "@@ -15322,6 +15322,7 @@\n \f\n \n (include \"sync.md\")\n+(include \"vector.md\")\n (include \"altivec.md\")\n (include \"spe.md\")\n (include \"dfp.md\")"}, {"sha": "ac61ffc582ee460ecc9f450daf7d96eef285c9fa", "filename": "gcc/config/rs6000/rs6000.opt", "status": "modified", "additions": 32, "deletions": 0, "changes": 32, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Frs6000.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Frs6000.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.opt?ref=a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "patch": "@@ -119,6 +119,38 @@ mvsx\n Target Report Mask(VSX)\n Use vector/scalar (VSX) instructions\n \n+mvsx-scalar-double\n+Target Undocumented Report Var(TARGET_VSX_SCALAR_DOUBLE) Init(-1)\n+; If -mvsx, use VSX arithmetic instructions for scalar double (on by default)\n+\n+mvsx-scalar-memory\n+Target Undocumented Report Var(TARGET_VSX_SCALAR_MEMORY)\n+; If -mvsx, use VSX scalar memory reference instructions for scalar double (off by default)\n+\n+mvsx-align-128\n+Target Undocumented Report Var(TARGET_VSX_ALIGN_128)\n+; If -mvsx, set alignment to 128 bits instead of 32/64\n+\n+mallow-movmisalign\n+Target Undocumented Var(TARGET_ALLOW_MOVMISALIGN) Init(-1)\n+; Allow/disallow the movmisalign in DF/DI vectors\n+\n+mallow-df-permute\n+Target Undocumented Var(TARGET_ALLOW_DF_PERMUTE)\n+; Allow/disallow permutation of DF/DI vectors\n+\n+msched-groups\n+Target Undocumented Report Var(TARGET_SCHED_GROUPS) Init(-1)\n+; Explicitly set/unset whether rs6000_sched_groups is set\n+\n+malways-hint\n+Target Undocumented Report Var(TARGET_ALWAYS_HINT) Init(-1)\n+; Explicitly set/unset whether rs6000_always_hint is set\n+\n+malign-branch-targets\n+Target Undocumented Report Var(TARGET_ALIGN_BRANCH_TARGETS) Init(-1)\n+; Explicitly set/unset whether rs6000_align_branch_targets is set\n+\n mupdate\n Target Report Var(TARGET_UPDATE) Init(1)\n Generate load/store with update instructions"}, {"sha": "0b8e311078dd047a7432a065cc4d30af44314723", "filename": "gcc/config/rs6000/t-rs6000", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Ft-rs6000", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Ft-rs6000", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Ft-rs6000?ref=a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "patch": "@@ -59,6 +59,7 @@ MD_INCLUDES = $(srcdir)/config/rs6000/rios1.md \\\n \t$(srcdir)/config/rs6000/constraints.md \\\n \t$(srcdir)/config/rs6000/darwin.md \\\n \t$(srcdir)/config/rs6000/sync.md \\\n+\t$(srcdir)/config/rs6000/vector.md \\\n \t$(srcdir)/config/rs6000/altivec.md \\\n \t$(srcdir)/config/rs6000/spe.md \\\n \t$(srcdir)/config/rs6000/dfp.md \\"}, {"sha": "1546db7a74f7f07ea2bde8291ae90aef0a1cb4c8", "filename": "gcc/config/rs6000/vector.md", "status": "added", "additions": 700, "deletions": 0, "changes": 700, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Fvector.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a72c65c7547434629a04bc6cc9e1dd7c6a3797f6/gcc%2Fconfig%2Frs6000%2Fvector.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Fvector.md?ref=a72c65c7547434629a04bc6cc9e1dd7c6a3797f6", "patch": "@@ -0,0 +1,700 @@\n+;; Expander definitions for vector support.  No instructions are in this file,\n+;; this file provides the generic vector expander, and the actual vector\n+;; instructions will be in altivec.md.\n+\n+;; Copyright (C) 2009\n+;; Free Software Foundation, Inc.\n+;; Contributed by Michael Meissner <meissner@linux.vnet.ibm.com>\n+\n+;; This file is part of GCC.\n+\n+;; GCC is free software; you can redistribute it and/or modify it\n+;; under the terms of the GNU General Public License as published\n+;; by the Free Software Foundation; either version 3, or (at your\n+;; option) any later version.\n+\n+;; GCC is distributed in the hope that it will be useful, but WITHOUT\n+;; ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n+;; or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public\n+;; License for more details.\n+\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+\n+;; Vector int modes\n+(define_mode_iterator VEC_I [V16QI V8HI V4SI])\n+\n+;; Vector float modes\n+(define_mode_iterator VEC_F [V4SF])\n+\n+;; Vector arithmetic modes\n+(define_mode_iterator VEC_A [V16QI V8HI V4SI V4SF])\n+\n+;; Vector modes that need alginment via permutes\n+(define_mode_iterator VEC_K [V16QI V8HI V4SI V4SF])\n+\n+;; Vector logical modes\n+(define_mode_iterator VEC_L [V16QI V8HI V4SI V2DI V4SF V2DF TI])\n+\n+;; Vector modes for moves.  Don't do TImode here.\n+(define_mode_iterator VEC_M [V16QI V8HI V4SI V2DI V4SF V2DF])\n+\n+;; Vector comparison modes\n+(define_mode_iterator VEC_C [V16QI V8HI V4SI V4SF V2DF])\n+\n+;; Vector init/extract modes\n+(define_mode_iterator VEC_E [V16QI V8HI V4SI V2DI V4SF V2DF])\n+\n+;; Vector reload iterator\n+(define_mode_iterator VEC_R [V16QI V8HI V4SI V2DI V4SF V2DF DF TI])\n+\n+;; Base type from vector mode\n+(define_mode_attr VEC_base [(V16QI \"QI\")\n+\t\t\t    (V8HI  \"HI\")\n+\t\t\t    (V4SI  \"SI\")\n+\t\t\t    (V2DI  \"DI\")\n+\t\t\t    (V4SF  \"SF\")\n+\t\t\t    (V2DF  \"DF\")\n+\t\t\t    (TI    \"TI\")])\n+\n+;; Same size integer type for floating point data\n+(define_mode_attr VEC_int [(V4SF  \"v4si\")\n+\t\t\t   (V2DF  \"v2di\")])\n+\n+(define_mode_attr VEC_INT [(V4SF  \"V4SI\")\n+\t\t\t   (V2DF  \"V2DI\")])\n+\n+;; constants for unspec\n+(define_constants\n+  [(UNSPEC_PREDICATE\t400)])\n+\n+\f\n+;; Vector move instructions.\n+(define_expand \"mov<mode>\"\n+  [(set (match_operand:VEC_M 0 \"nonimmediate_operand\" \"\")\n+\t(match_operand:VEC_M 1 \"any_operand\" \"\"))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+{\n+  if (can_create_pseudo_p ())\n+    {\n+      if (CONSTANT_P (operands[1])\n+\t  && !easy_vector_constant (operands[1], <MODE>mode))\n+\toperands[1] = force_const_mem (<MODE>mode, operands[1]);\n+\n+      else if (!vlogical_operand (operands[0], <MODE>mode)\n+\t       && !vlogical_operand (operands[1], <MODE>mode))\n+\toperands[1] = force_reg (<MODE>mode, operands[1]);\n+    }\n+})\n+\n+;; Generic vector floating point load/store instructions.\n+(define_expand \"vector_load_<mode>\"\n+  [(set (match_operand:VEC_M 0 \"vfloat_operand\" \"\")\n+\t(match_operand:VEC_M 1 \"memory_operand\" \"\"))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"vector_store_<mode>\"\n+  [(set (match_operand:VEC_M 0 \"memory_operand\" \"\")\n+\t(match_operand:VEC_M 1 \"vfloat_operand\" \"\"))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+;; Splits if a GPR register was chosen for the move\n+(define_split\n+  [(set (match_operand:VEC_L 0 \"nonimmediate_operand\" \"\")\n+        (match_operand:VEC_L 1 \"input_operand\" \"\"))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\n+   && reload_completed\n+   && gpr_or_gpr_p (operands[0], operands[1])\"\n+  [(pc)]\n+{\n+  rs6000_split_multireg_move (operands[0], operands[1]);\n+  DONE;\n+})\n+\n+\f\n+;; Reload patterns for vector operations.  We may need an addtional base\n+;; register to convert the reg+offset addressing to reg+reg for vector\n+;; registers and reg+reg or (reg+reg)&(-16) addressing to just an index\n+;; register for gpr registers.\n+(define_expand \"reload_<VEC_R:mode>_<P:mptrsize>_store\"\n+  [(parallel [(match_operand:VEC_R 0 \"memory_operand\" \"m\")\n+              (match_operand:VEC_R 1 \"gpc_reg_operand\" \"r\")\n+              (match_operand:P 2 \"register_operand\" \"=&b\")])]\n+  \"<P:tptrsize>\"\n+{\n+  rs6000_secondary_reload_inner (operands[1], operands[0], operands[2], true);\n+  DONE;\n+})\n+\n+(define_expand \"reload_<VEC_R:mode>_<P:mptrsize>_load\"\n+  [(parallel [(match_operand:VEC_R 0 \"gpc_reg_operand\" \"=&r\")\n+              (match_operand:VEC_R 1 \"memory_operand\" \"m\")\n+              (match_operand:P 2 \"register_operand\" \"=&b\")])]\n+  \"<P:tptrsize>\"\n+{\n+  rs6000_secondary_reload_inner (operands[0], operands[1], operands[2], false);\n+  DONE;\n+})\n+\n+;; Reload sometimes tries to move the address to a GPR, and can generate\n+;; invalid RTL for addresses involving AND -16.  Allow addresses involving\n+;; reg+reg, reg+small constant, or just reg, all wrapped in an AND -16.\n+\n+(define_insn_and_split \"*vec_reload_and_plus_<mptrsize>\"\n+  [(set (match_operand:P 0 \"gpc_reg_operand\" \"=b\")\n+\t(and:P (plus:P (match_operand:P 1 \"gpc_reg_operand\" \"r\")\n+\t\t       (match_operand:P 2 \"reg_or_cint_operand\" \"rI\"))\n+\t       (const_int -16)))]\n+  \"TARGET_ALTIVEC && (reload_in_progress || reload_completed)\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(set (match_dup 0)\n+\t(plus:P (match_dup 1)\n+\t\t(match_dup 2)))\n+   (parallel [(set (match_dup 0)\n+\t\t   (and:P (match_dup 0)\n+\t\t\t  (const_int -16)))\n+\t      (clobber:CC (scratch:CC))])])\n+\n+;; The normal ANDSI3/ANDDI3 won't match if reload decides to move an AND -16\n+;; address to a register because there is no clobber of a (scratch), so we add\n+;; it here.\n+(define_insn_and_split \"*vec_reload_and_reg_<mptrsize>\"\n+  [(set (match_operand:P 0 \"gpc_reg_operand\" \"=b\")\n+\t(and:P (match_operand:P 1 \"gpc_reg_operand\" \"r\")\n+\t       (const_int -16)))]\n+  \"TARGET_ALTIVEC && (reload_in_progress || reload_completed)\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(parallel [(set (match_dup 0)\n+\t\t   (and:P (match_dup 1)\n+\t\t\t  (const_int -16)))\n+\t      (clobber:CC (scratch:CC))])])\n+\f\n+;; Generic floating point vector arithmetic support\n+(define_expand \"add<mode>3\"\n+  [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+\t(plus:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\")\n+\t\t    (match_operand:VEC_F 2 \"vfloat_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"sub<mode>3\"\n+  [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+\t(minus:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\")\n+\t\t     (match_operand:VEC_F 2 \"vfloat_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"mul<mode>3\"\n+  [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+\t(mult:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\")\n+\t\t    (match_operand:VEC_F 2 \"vfloat_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode) && TARGET_FUSED_MADD\"\n+  \"\n+{\n+  emit_insn (gen_altivec_mulv4sf3 (operands[0], operands[1], operands[2]));\n+  DONE;\n+}\")\n+\n+(define_expand \"neg<mode>2\"\n+  [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+\t(neg:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\n+{\n+  emit_insn (gen_altivec_negv4sf2 (operands[0], operands[1]));\n+  DONE;\n+}\")\n+\n+(define_expand \"abs<mode>2\"\n+  [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+\t(abs:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\n+{\n+  emit_insn (gen_altivec_absv4sf2 (operands[0], operands[1]));\n+  DONE;\n+}\")\n+\n+(define_expand \"smin<mode>3\"\n+  [(set (match_operand:VEC_F 0 \"register_operand\" \"\")\n+        (smin:VEC_F (match_operand:VEC_F 1 \"register_operand\" \"\")\n+\t\t    (match_operand:VEC_F 2 \"register_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"smax<mode>3\"\n+  [(set (match_operand:VEC_F 0 \"register_operand\" \"\")\n+        (smax:VEC_F (match_operand:VEC_F 1 \"register_operand\" \"\")\n+\t\t    (match_operand:VEC_F 2 \"register_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+\n+(define_expand \"ftrunc<mode>2\"\n+  [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+  \t(fix:VEC_F (match_operand:VEC_F 1 \"vfloat_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+\f\n+;; Vector comparisons\n+(define_expand \"vcond<mode>\"\n+  [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+\t(if_then_else:VEC_F\n+\t (match_operator 3 \"comparison_operator\"\n+\t\t\t [(match_operand:VEC_F 4 \"vfloat_operand\" \"\")\n+\t\t\t  (match_operand:VEC_F 5 \"vfloat_operand\" \"\")])\n+\t (match_operand:VEC_F 1 \"vfloat_operand\" \"\")\n+\t (match_operand:VEC_F 2 \"vfloat_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\n+{\n+  if (rs6000_emit_vector_cond_expr (operands[0], operands[1], operands[2],\n+\t\t\t\t    operands[3], operands[4], operands[5]))\n+    DONE;\n+  else\n+    FAIL;\n+}\")\n+\n+(define_expand \"vcond<mode>\"\n+  [(set (match_operand:VEC_I 0 \"vint_operand\" \"\")\n+\t(if_then_else:VEC_I\n+\t (match_operator 3 \"comparison_operator\"\n+\t\t\t [(match_operand:VEC_I 4 \"vint_operand\" \"\")\n+\t\t\t  (match_operand:VEC_I 5 \"vint_operand\" \"\")])\n+\t (match_operand:VEC_I 1 \"vint_operand\" \"\")\n+\t (match_operand:VEC_I 2 \"vint_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\n+{\n+  if (rs6000_emit_vector_cond_expr (operands[0], operands[1], operands[2],\n+\t\t\t\t    operands[3], operands[4], operands[5]))\n+    DONE;\n+  else\n+    FAIL;\n+}\")\n+\n+(define_expand \"vcondu<mode>\"\n+  [(set (match_operand:VEC_I 0 \"vint_operand\" \"\")\n+\t(if_then_else:VEC_I\n+\t (match_operator 3 \"comparison_operator\"\n+\t\t\t [(match_operand:VEC_I 4 \"vint_operand\" \"\")\n+\t\t\t  (match_operand:VEC_I 5 \"vint_operand\" \"\")])\n+\t (match_operand:VEC_I 1 \"vint_operand\" \"\")\n+\t (match_operand:VEC_I 2 \"vint_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\n+{\n+  if (rs6000_emit_vector_cond_expr (operands[0], operands[1], operands[2],\n+\t\t\t\t    operands[3], operands[4], operands[5]))\n+    DONE;\n+  else\n+    FAIL;\n+}\")\n+\n+(define_expand \"vector_eq<mode>\"\n+  [(set (match_operand:VEC_C 0 \"vlogical_operand\" \"\")\n+\t(eq:VEC_C (match_operand:VEC_C 1 \"vlogical_operand\" \"\")\n+\t\t  (match_operand:VEC_C 2 \"vlogical_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"vector_gt<mode>\"\n+  [(set (match_operand:VEC_C 0 \"vlogical_operand\" \"\")\n+\t(gt:VEC_C (match_operand:VEC_C 1 \"vlogical_operand\" \"\")\n+\t\t  (match_operand:VEC_C 2 \"vlogical_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"vector_ge<mode>\"\n+  [(set (match_operand:VEC_C 0 \"vlogical_operand\" \"\")\n+\t(ge:VEC_C (match_operand:VEC_C 1 \"vlogical_operand\" \"\")\n+\t\t  (match_operand:VEC_C 2 \"vlogical_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"vector_gtu<mode>\"\n+  [(set (match_operand:VEC_I 0 \"vint_operand\" \"\")\n+\t(gtu:VEC_I (match_operand:VEC_I 1 \"vint_operand\" \"\")\n+\t\t   (match_operand:VEC_I 2 \"vint_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"vector_geu<mode>\"\n+  [(set (match_operand:VEC_I 0 \"vint_operand\" \"\")\n+\t(geu:VEC_I (match_operand:VEC_I 1 \"vint_operand\" \"\")\n+\t\t   (match_operand:VEC_I 2 \"vint_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+;; Note the arguments for __builtin_altivec_vsel are op2, op1, mask\n+;; which is in the reverse order that we want\n+(define_expand \"vector_select_<mode>\"\n+  [(set (match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n+\t(if_then_else:VEC_L\n+\t (ne:CC (match_operand:VEC_L 3 \"vlogical_operand\" \"\")\n+\t\t(const_int 0))\n+\t (match_operand:VEC_L 2 \"vlogical_operand\" \"\")\n+\t (match_operand:VEC_L 1 \"vlogical_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"vector_select_<mode>_uns\"\n+  [(set (match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n+\t(if_then_else:VEC_L\n+\t (ne:CCUNS (match_operand:VEC_L 3 \"vlogical_operand\" \"\")\n+\t\t   (const_int 0))\n+\t (match_operand:VEC_L 2 \"vlogical_operand\" \"\")\n+\t (match_operand:VEC_L 1 \"vlogical_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+;; Expansions that compare vectors producing a vector result and a predicate,\n+;; setting CR6 to indicate a combined status\n+(define_expand \"vector_eq_<mode>_p\"\n+  [(parallel\n+    [(set (reg:CC 74)\n+\t  (unspec:CC [(eq:CC (match_operand:VEC_A 1 \"vlogical_operand\" \"\")\n+\t\t\t     (match_operand:VEC_A 2 \"vlogical_operand\" \"\"))]\n+\t\t     UNSPEC_PREDICATE))\n+     (set (match_operand:VEC_A 0 \"vlogical_operand\" \"\")\n+\t  (eq:VEC_A (match_dup 1)\n+\t\t    (match_dup 2)))])]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"vector_gt_<mode>_p\"\n+  [(parallel\n+    [(set (reg:CC 74)\n+\t  (unspec:CC [(gt:CC (match_operand:VEC_A 1 \"vlogical_operand\" \"\")\n+\t\t\t     (match_operand:VEC_A 2 \"vlogical_operand\" \"\"))]\n+\t\t     UNSPEC_PREDICATE))\n+     (set (match_operand:VEC_A 0 \"vlogical_operand\" \"\")\n+\t  (gt:VEC_A (match_dup 1)\n+\t\t    (match_dup 2)))])]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"vector_ge_<mode>_p\"\n+  [(parallel\n+    [(set (reg:CC 74)\n+\t  (unspec:CC [(ge:CC (match_operand:VEC_F 1 \"vfloat_operand\" \"\")\n+\t\t\t     (match_operand:VEC_F 2 \"vfloat_operand\" \"\"))]\n+\t\t     UNSPEC_PREDICATE))\n+     (set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+\t  (ge:VEC_F (match_dup 1)\n+\t\t    (match_dup 2)))])]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"vector_gtu_<mode>_p\"\n+  [(parallel\n+    [(set (reg:CC 74)\n+\t  (unspec:CC [(gtu:CC (match_operand:VEC_I 1 \"vint_operand\" \"\")\n+\t\t\t      (match_operand:VEC_I 2 \"vint_operand\" \"\"))]\n+\t\t     UNSPEC_PREDICATE))\n+     (set (match_operand:VEC_I 0 \"vlogical_operand\" \"\")\n+\t  (gtu:VEC_I (match_dup 1)\n+\t\t     (match_dup 2)))])]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+;; AltiVec predicates.\n+\n+(define_expand \"cr6_test_for_zero\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(eq:SI (reg:CC 74)\n+\t       (const_int 0)))]\n+  \"TARGET_ALTIVEC\"\n+  \"\")\t\n+\n+(define_expand \"cr6_test_for_zero_reverse\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(eq:SI (reg:CC 74)\n+\t       (const_int 0)))\n+   (set (match_dup 0) (minus:SI (const_int 1) (match_dup 0)))]\n+  \"TARGET_ALTIVEC\"\n+  \"\")\n+\n+(define_expand \"cr6_test_for_lt\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(lt:SI (reg:CC 74)\n+\t       (const_int 0)))]\n+  \"TARGET_ALTIVEC\"\n+  \"\")\n+\n+(define_expand \"cr6_test_for_lt_reverse\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(lt:SI (reg:CC 74)\n+\t       (const_int 0)))\n+   (set (match_dup 0) (minus:SI (const_int 1) (match_dup 0)))]\n+  \"TARGET_ALTIVEC\"\n+  \"\")\n+\n+\f\n+;; Vector logical instructions\n+(define_expand \"xor<mode>3\"\n+  [(set (match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n+        (xor:VEC_L (match_operand:VEC_L 1 \"vlogical_operand\" \"\")\n+\t\t   (match_operand:VEC_L 2 \"vlogical_operand\" \"\")))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"ior<mode>3\"\n+  [(set (match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n+        (ior:VEC_L (match_operand:VEC_L 1 \"vlogical_operand\" \"\")\n+\t\t   (match_operand:VEC_L 2 \"vlogical_operand\" \"\")))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"and<mode>3\"\n+  [(set (match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n+        (and:VEC_L (match_operand:VEC_L 1 \"vlogical_operand\" \"\")\n+\t\t   (match_operand:VEC_L 2 \"vlogical_operand\" \"\")))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"one_cmpl<mode>2\"\n+  [(set (match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n+        (not:VEC_L (match_operand:VEC_L 1 \"vlogical_operand\" \"\")))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+  \n+(define_expand \"nor<mode>3\"\n+  [(set (match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n+        (not:VEC_L (ior:VEC_L (match_operand:VEC_L 1 \"vlogical_operand\" \"\")\n+\t\t\t      (match_operand:VEC_L 2 \"vlogical_operand\" \"\"))))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+(define_expand \"andc<mode>3\"\n+  [(set (match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n+        (and:VEC_L (not:VEC_L (match_operand:VEC_L 2 \"vlogical_operand\" \"\"))\n+\t\t   (match_operand:VEC_L 1 \"vlogical_operand\" \"\")))]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+  \"\")\n+\n+;; Same size conversions\n+(define_expand \"float<VEC_int><mode>2\"\n+  [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+\t(float:VEC_F (match_operand:<VEC_INT> 1 \"vint_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\n+{\n+  emit_insn (gen_altivec_vcfsx (operands[0], operands[1], const0_rtx));\n+  DONE;\n+}\")\n+\n+(define_expand \"unsigned_float<VEC_int><mode>2\"\n+  [(set (match_operand:VEC_F 0 \"vfloat_operand\" \"\")\n+\t(unsigned_float:VEC_F (match_operand:<VEC_INT> 1 \"vint_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\n+{\n+  emit_insn (gen_altivec_vcfux (operands[0], operands[1], const0_rtx));\n+  DONE;\n+}\")\n+\n+(define_expand \"fix_trunc<mode><VEC_int>2\"\n+  [(set (match_operand:<VEC_INT> 0 \"vint_operand\" \"\")\n+\t(fix:<VEC_INT> (match_operand:VEC_F 1 \"vfloat_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\n+{\n+  emit_insn (gen_altivec_vctsxs (operands[0], operands[1], const0_rtx));\n+  DONE;\n+}\")\n+\n+(define_expand \"fixuns_trunc<mode><VEC_int>2\"\n+  [(set (match_operand:<VEC_INT> 0 \"vint_operand\" \"\")\n+\t(unsigned_fix:<VEC_INT> (match_operand:VEC_F 1 \"vfloat_operand\" \"\")))]\n+  \"VECTOR_UNIT_ALTIVEC_P (<MODE>mode)\"\n+  \"\n+{\n+  emit_insn (gen_altivec_vctuxs (operands[0], operands[1], const0_rtx));\n+  DONE;\n+}\")\n+\n+\f\n+;; Vector initialization, set, extract\n+(define_expand \"vec_init<mode>\"\n+  [(match_operand:VEC_E 0 \"vlogical_operand\" \"\")\n+   (match_operand:VEC_E 1 \"\" \"\")]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+{\n+  rs6000_expand_vector_init (operands[0], operands[1]);\n+  DONE;\n+})\n+\n+(define_expand \"vec_set<mode>\"\n+  [(match_operand:VEC_E 0 \"vlogical_operand\" \"\")\n+   (match_operand:<VEC_base> 1 \"register_operand\" \"\")\n+   (match_operand 2 \"const_int_operand\" \"\")]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+{\n+  rs6000_expand_vector_set (operands[0], operands[1], INTVAL (operands[2]));\n+  DONE;\n+})\n+\n+(define_expand \"vec_extract<mode>\"\n+  [(match_operand:<VEC_base> 0 \"register_operand\" \"\")\n+   (match_operand:VEC_E 1 \"vlogical_operand\" \"\")\n+   (match_operand 2 \"const_int_operand\" \"\")]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+{\n+  rs6000_expand_vector_extract (operands[0], operands[1],\n+\t\t\t\tINTVAL (operands[2]));\n+  DONE;\n+})\n+\n+;; Interleave patterns\n+(define_expand \"vec_interleave_highv4sf\"\n+  [(set (match_operand:V4SF 0 \"vfloat_operand\" \"\")\n+        (vec_merge:V4SF\n+\t (vec_select:V4SF (match_operand:V4SF 1 \"vfloat_operand\" \"\")\n+\t\t\t  (parallel [(const_int 0)\n+\t\t\t\t     (const_int 2)\n+\t\t\t\t     (const_int 1)\n+\t\t\t\t     (const_int 3)]))\n+\t (vec_select:V4SF (match_operand:V4SF 2 \"vfloat_operand\" \"\")\n+\t\t\t  (parallel [(const_int 2)\n+\t\t\t\t     (const_int 0)\n+\t\t\t\t     (const_int 3)\n+\t\t\t\t     (const_int 1)]))\n+\t (const_int 5)))]\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n+  \"\")\n+\n+(define_expand \"vec_interleave_lowv4sf\"\n+  [(set (match_operand:V4SF 0 \"vfloat_operand\" \"\")\n+        (vec_merge:V4SF\n+\t (vec_select:V4SF (match_operand:V4SF 1 \"vfloat_operand\" \"\")\n+\t\t\t  (parallel [(const_int 2)\n+\t\t\t\t     (const_int 0)\n+\t\t\t\t     (const_int 3)\n+\t\t\t\t     (const_int 1)]))\n+\t (vec_select:V4SF (match_operand:V4SF 2 \"vfloat_operand\" \"\")\n+\t\t\t  (parallel [(const_int 0)\n+\t\t\t\t     (const_int 2)\n+\t\t\t\t     (const_int 1)\n+\t\t\t\t     (const_int 3)]))\n+\t (const_int 5)))]\n+  \"VECTOR_UNIT_ALTIVEC_P (V4SFmode)\"\n+  \"\")\n+\n+\f\n+;; Align vector loads with a permute.\n+(define_expand \"vec_realign_load_<mode>\"\n+  [(match_operand:VEC_K 0 \"vlogical_operand\" \"\")\n+   (match_operand:VEC_K 1 \"vlogical_operand\" \"\")\n+   (match_operand:VEC_K 2 \"vlogical_operand\" \"\")\n+   (match_operand:V16QI 3 \"vlogical_operand\" \"\")]\n+  \"VECTOR_MEM_ALTIVEC_P (<MODE>mode)\"\n+{\n+  emit_insn (gen_altivec_vperm_<mode> (operands[0], operands[1], operands[2],\n+\t\t\t\t       operands[3]));\n+  DONE;\n+})\n+\n+\f\n+;; Vector shift left in bits.  Currently supported ony for shift\n+;; amounts that can be expressed as byte shifts (divisible by 8).\n+;; General shift amounts can be supported using vslo + vsl. We're\n+;; not expecting to see these yet (the vectorizer currently\n+;; generates only shifts divisible by byte_size).\n+(define_expand \"vec_shl_<mode>\"\n+  [(match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n+   (match_operand:VEC_L 1 \"vlogical_operand\" \"\")\n+   (match_operand:QI 2 \"reg_or_short_operand\" \"\")]\n+  \"TARGET_ALTIVEC\"\n+  \"\n+{\n+  rtx bitshift = operands[2];\n+  rtx shift;\n+  rtx insn;\n+  HOST_WIDE_INT bitshift_val;\n+  HOST_WIDE_INT byteshift_val;\n+\n+  if (! CONSTANT_P (bitshift))\n+    FAIL;\n+  bitshift_val = INTVAL (bitshift);\n+  if (bitshift_val & 0x7)\n+    FAIL;\n+  byteshift_val = bitshift_val >> 3;\n+  shift = gen_rtx_CONST_INT (QImode, byteshift_val);\n+  insn = gen_altivec_vsldoi_<mode> (operands[0], operands[1], operands[1],\n+\t\t\t\t    shift);\n+\n+  emit_insn (insn);\n+  DONE;\n+}\")\n+\n+;; Vector shift right in bits. Currently supported ony for shift\n+;; amounts that can be expressed as byte shifts (divisible by 8).\n+;; General shift amounts can be supported using vsro + vsr. We're\n+;; not expecting to see these yet (the vectorizer currently\n+;; generates only shifts divisible by byte_size).\n+(define_expand \"vec_shr_<mode>\"\n+  [(match_operand:VEC_L 0 \"vlogical_operand\" \"\")\n+   (match_operand:VEC_L 1 \"vlogical_operand\" \"\")\n+   (match_operand:QI 2 \"reg_or_short_operand\" \"\")]\n+  \"TARGET_ALTIVEC\"\n+  \"\n+{\n+  rtx bitshift = operands[2];\n+  rtx shift;\n+  rtx insn;\n+  HOST_WIDE_INT bitshift_val;\n+  HOST_WIDE_INT byteshift_val;\n+ \n+  if (! CONSTANT_P (bitshift))\n+    FAIL;\n+  bitshift_val = INTVAL (bitshift);\n+  if (bitshift_val & 0x7)\n+    FAIL;\n+  byteshift_val = 16 - (bitshift_val >> 3);\n+  shift = gen_rtx_CONST_INT (QImode, byteshift_val);\n+  insn = gen_altivec_vsldoi_<mode> (operands[0], operands[1], operands[1],\n+\t\t\t\t    shift);\n+\n+  emit_insn (insn);\n+  DONE;\n+}\")\n+\n+;; Expanders for rotate each element in a vector\n+(define_expand \"vrotl<mode>3\"\n+  [(set (match_operand:VEC_I 0 \"vint_operand\" \"\")\n+\t(rotate:VEC_I (match_operand:VEC_I 1 \"vint_operand\" \"\")\n+\t\t      (match_operand:VEC_I 2 \"vint_operand\" \"\")))]\n+  \"TARGET_ALTIVEC\"\n+  \"\")\n+\n+;; Expanders for arithmetic shift left on each vector element\n+(define_expand \"vashl<mode>3\"\n+  [(set (match_operand:VEC_I 0 \"vint_operand\" \"\")\n+\t(ashift:VEC_I (match_operand:VEC_I 1 \"vint_operand\" \"\")\n+\t\t      (match_operand:VEC_I 2 \"vint_operand\" \"\")))]\n+  \"TARGET_ALTIVEC\"\n+  \"\")\n+\n+;; Expanders for logical shift right on each vector element\n+(define_expand \"vlshr<mode>3\"\n+  [(set (match_operand:VEC_I 0 \"vint_operand\" \"\")\n+\t(lshiftrt:VEC_I (match_operand:VEC_I 1 \"vint_operand\" \"\")\n+\t\t\t(match_operand:VEC_I 2 \"vint_operand\" \"\")))]\n+  \"TARGET_ALTIVEC\"\n+  \"\")\n+\n+;; Expanders for arithmetic shift right on each vector element\n+(define_expand \"vashr<mode>3\"\n+  [(set (match_operand:VEC_I 0 \"vint_operand\" \"\")\n+\t(ashiftrt:VEC_I (match_operand:VEC_I 1 \"vint_operand\" \"\")\n+\t\t\t(match_operand:VEC_I 2 \"vint_operand\" \"\")))]\n+  \"TARGET_ALTIVEC\"\n+  \"\")"}]}