{"sha": "cd36a4518d14aae18ac89a6232e009ee2bcb6008", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Y2QzNmE0NTE4ZDE0YWFlMThhYzg5YTYyMzJlMDA5ZWUyYmNiNjAwOA==", "commit": {"author": {"name": "Segher Boessenkool", "email": "segher@kernel.crashing.org", "date": "2016-11-18T09:14:52Z"}, "committer": {"name": "Segher Boessenkool", "email": "segher@gcc.gnu.org", "date": "2016-11-18T09:14:52Z"}, "message": "bb-reorder: Improve compgotos pass (PR71785)\n\nFor code like the testcase in PR71785 GCC factors all the indirect branches\nto a single dispatcher that then everything jumps to.  This is because\nhaving many indirect branches with each many jump targets does not scale\nin large parts of the compiler.  Very late in the pass pipeline (right\nbefore peephole2) the indirect branches are then unfactored again, by\nthe duplicate_computed_gotos pass.\n\nThis pass works by replacing branches to such a common dispatcher by a\ncopy of the dispatcher.  For code like this testcase this does not work\nso well: most cases do a single addition instruction right before the\ndispatcher, but not all, and we end up with only two indirect jumps: the\none without the addition, and the one with the addition in its own basic\nblock, and now everything else jumps _there_.\n\nThis patch rewrites the algorithm to deal with this.  It also makes it\nsimpler: it does not need the \"candidates\" array anymore, it does not\nneed RTL layout mode, it does not need cleanup_cfg, and it does not\nneed to keep track of what blocks it already visited.\n\n\n\tPR rtl-optimization/71785\n\t* bb-reorder.c (maybe_duplicate_computed_goto): New function.\n\t(duplicate_computed_gotos): New function.\n\t(pass_duplicate_computed_gotos::execute): Rewrite.\n\nFrom-SVN: r242584", "tree": {"sha": "ebde0fe578dbf7c9d17463b5f7cca801f81a5bb9", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/ebde0fe578dbf7c9d17463b5f7cca801f81a5bb9"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/cd36a4518d14aae18ac89a6232e009ee2bcb6008", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/cd36a4518d14aae18ac89a6232e009ee2bcb6008", "html_url": "https://github.com/Rust-GCC/gccrs/commit/cd36a4518d14aae18ac89a6232e009ee2bcb6008", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/cd36a4518d14aae18ac89a6232e009ee2bcb6008/comments", "author": {"login": "segher", "id": 417629, "node_id": "MDQ6VXNlcjQxNzYyOQ==", "avatar_url": "https://avatars.githubusercontent.com/u/417629?v=4", "gravatar_id": "", "url": "https://api.github.com/users/segher", "html_url": "https://github.com/segher", "followers_url": "https://api.github.com/users/segher/followers", "following_url": "https://api.github.com/users/segher/following{/other_user}", "gists_url": "https://api.github.com/users/segher/gists{/gist_id}", "starred_url": "https://api.github.com/users/segher/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/segher/subscriptions", "organizations_url": "https://api.github.com/users/segher/orgs", "repos_url": "https://api.github.com/users/segher/repos", "events_url": "https://api.github.com/users/segher/events{/privacy}", "received_events_url": "https://api.github.com/users/segher/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "9bd0f0bc6b3ff066b6a0e0fff1791d66545689fd", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9bd0f0bc6b3ff066b6a0e0fff1791d66545689fd", "html_url": "https://github.com/Rust-GCC/gccrs/commit/9bd0f0bc6b3ff066b6a0e0fff1791d66545689fd"}], "stats": {"total": 222, "additions": 101, "deletions": 121}, "files": [{"sha": "c79a433ccc86e0d3196d3231d3d39745d129b351", "filename": "gcc/ChangeLog", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cd36a4518d14aae18ac89a6232e009ee2bcb6008/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cd36a4518d14aae18ac89a6232e009ee2bcb6008/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=cd36a4518d14aae18ac89a6232e009ee2bcb6008", "patch": "@@ -1,3 +1,10 @@\n+2016-11-18  Segher Boessenkool  <segher@kernel.crashing.org>\n+\n+\tPR rtl-optimization/71785\n+\t* bb-reorder.c (maybe_duplicate_computed_goto): New function.\n+\t(duplicate_computed_gotos): New function.\n+\t(pass_duplicate_computed_gotos::execute): Rewrite.\n+\n 2016-11-17  Jeff Law  <law@redhat.com>\n \n \tPR target/47192"}, {"sha": "6873b4f9089f0a8f83567193dd586b10cf26c9be", "filename": "gcc/bb-reorder.c", "status": "modified", "additions": 94, "deletions": 121, "changes": 215, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cd36a4518d14aae18ac89a6232e009ee2bcb6008/gcc%2Fbb-reorder.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cd36a4518d14aae18ac89a6232e009ee2bcb6008/gcc%2Fbb-reorder.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbb-reorder.c?ref=cd36a4518d14aae18ac89a6232e009ee2bcb6008", "patch": "@@ -2586,11 +2586,101 @@ make_pass_reorder_blocks (gcc::context *ctxt)\n   return new pass_reorder_blocks (ctxt);\n }\n \n+/* Duplicate a block (that we already know ends in a computed jump) into its\n+   predecessors, where possible.  Return whether anything is changed.  */\n+static bool\n+maybe_duplicate_computed_goto (basic_block bb, int max_size)\n+{\n+  if (single_pred_p (bb))\n+    return false;\n+\n+  /* Make sure that the block is small enough.  */\n+  rtx_insn *insn;\n+  FOR_BB_INSNS (bb, insn)\n+    if (INSN_P (insn))\n+      {\n+\tmax_size -= get_attr_min_length (insn);\n+\tif (max_size < 0)\n+\t   return false;\n+      }\n+\n+  bool changed = false;\n+  edge e;\n+  edge_iterator ei;\n+  for (ei = ei_start (bb->preds); (e = ei_safe_edge (ei)); )\n+    {\n+      basic_block pred = e->src;\n+\n+      /* Do not duplicate BB into PRED if that is the last predecessor, or if\n+\t we cannot merge a copy of BB with PRED.  */\n+      if (single_pred_p (bb)\n+\t  || !single_succ_p (pred)\n+\t  || e->flags & EDGE_COMPLEX\n+\t  || pred->index < NUM_FIXED_BLOCKS\n+\t  || (JUMP_P (BB_END (pred)) && !simplejump_p (BB_END (pred)))\n+\t  || (JUMP_P (BB_END (pred)) && CROSSING_JUMP_P (BB_END (pred))))\n+\t{\n+\t  ei_next (&ei);\n+\t  continue;\n+\t}\n+\n+      if (dump_file)\n+\tfprintf (dump_file, \"Duplicating computed goto bb %d into bb %d\\n\",\n+\t\t bb->index, e->src->index);\n+\n+      /* Remember if PRED can be duplicated; if so, the copy of BB merged\n+\t with PRED can be duplicated as well.  */\n+      bool can_dup_more = can_duplicate_block_p (pred);\n+\n+      /* Make a copy of BB, merge it into PRED.  */\n+      basic_block copy = duplicate_block (bb, e, NULL);\n+      emit_barrier_after_bb (copy);\n+      reorder_insns_nobb (BB_HEAD (copy), BB_END (copy), BB_END (pred));\n+      merge_blocks (pred, copy);\n+\n+      changed = true;\n+\n+      /* Try to merge the resulting merged PRED into further predecessors.  */\n+      if (can_dup_more)\n+\tmaybe_duplicate_computed_goto (pred, max_size);\n+    }\n+\n+  return changed;\n+}\n+\n /* Duplicate the blocks containing computed gotos.  This basically unfactors\n    computed gotos that were factored early on in the compilation process to\n-   speed up edge based data flow.  We used to not unfactoring them again,\n-   which can seriously pessimize code with many computed jumps in the source\n-   code, such as interpreters.  See e.g. PR15242.  */\n+   speed up edge based data flow.  We used to not unfactor them again, which\n+   can seriously pessimize code with many computed jumps in the source code,\n+   such as interpreters.  See e.g. PR15242.  */\n+static void\n+duplicate_computed_gotos (function *fun)\n+{\n+  /* We are estimating the length of uncond jump insn only once\n+     since the code for getting the insn length always returns\n+     the minimal length now.  */\n+  if (uncond_jump_length == 0)\n+    uncond_jump_length = get_uncond_jump_length ();\n+\n+  /* Never copy a block larger than this.  */\n+  int max_size\n+    = uncond_jump_length * PARAM_VALUE (PARAM_MAX_GOTO_DUPLICATION_INSNS);\n+\n+  bool changed = false;\n+\n+  /* Try to duplicate all blocks that end in a computed jump and that\n+     can be duplicated at all.  */\n+  basic_block bb;\n+  FOR_EACH_BB_FN (bb, fun)\n+    if (computed_jump_p (BB_END (bb)) && can_duplicate_block_p (bb))\n+      changed |= maybe_duplicate_computed_goto (bb, max_size);\n+\n+  /* Duplicating blocks will redirect edges and may cause hot blocks\n+    previously reached by both hot and cold blocks to become dominated\n+    only by cold blocks.  */\n+  if (changed)\n+    fixup_partitions ();\n+}\n \n namespace {\n \n@@ -2633,125 +2723,8 @@ pass_duplicate_computed_gotos::gate (function *fun)\n unsigned int\n pass_duplicate_computed_gotos::execute (function *fun)\n {\n-  basic_block bb, new_bb;\n-  bitmap candidates;\n-  int max_size;\n-  bool changed = false;\n-\n-  if (n_basic_blocks_for_fn (fun) <= NUM_FIXED_BLOCKS + 1)\n-    return 0;\n-\n-  clear_bb_flags ();\n-  cfg_layout_initialize (0);\n-\n-  /* We are estimating the length of uncond jump insn only once\n-     since the code for getting the insn length always returns\n-     the minimal length now.  */\n-  if (uncond_jump_length == 0)\n-    uncond_jump_length = get_uncond_jump_length ();\n-\n-  max_size\n-    = uncond_jump_length * PARAM_VALUE (PARAM_MAX_GOTO_DUPLICATION_INSNS);\n-  candidates = BITMAP_ALLOC (NULL);\n-\n-  /* Look for blocks that end in a computed jump, and see if such blocks\n-     are suitable for unfactoring.  If a block is a candidate for unfactoring,\n-     mark it in the candidates.  */\n-  FOR_EACH_BB_FN (bb, fun)\n-    {\n-      rtx_insn *insn;\n-      edge e;\n-      edge_iterator ei;\n-      int size, all_flags;\n-\n-      /* Build the reorder chain for the original order of blocks.  */\n-      if (bb->next_bb != EXIT_BLOCK_PTR_FOR_FN (fun))\n-\tbb->aux = bb->next_bb;\n-\n-      /* Obviously the block has to end in a computed jump.  */\n-      if (!computed_jump_p (BB_END (bb)))\n-\tcontinue;\n-\n-      /* Only consider blocks that can be duplicated.  */\n-      if (CROSSING_JUMP_P (BB_END (bb))\n-\t  || !can_duplicate_block_p (bb))\n-\tcontinue;\n-\n-      /* Make sure that the block is small enough.  */\n-      size = 0;\n-      FOR_BB_INSNS (bb, insn)\n-\tif (INSN_P (insn))\n-\t  {\n-\t    size += get_attr_min_length (insn);\n-\t    if (size > max_size)\n-\t       break;\n-\t  }\n-      if (size > max_size)\n-\tcontinue;\n-\n-      /* Final check: there must not be any incoming abnormal edges.  */\n-      all_flags = 0;\n-      FOR_EACH_EDGE (e, ei, bb->preds)\n-\tall_flags |= e->flags;\n-      if (all_flags & EDGE_COMPLEX)\n-\tcontinue;\n-\n-      bitmap_set_bit (candidates, bb->index);\n-    }\n-\n-  /* Nothing to do if there is no computed jump here.  */\n-  if (bitmap_empty_p (candidates))\n-    goto done;\n-\n-  /* Duplicate computed gotos.  */\n-  FOR_EACH_BB_FN (bb, fun)\n-    {\n-      if (bb->flags & BB_VISITED)\n-\tcontinue;\n-\n-      bb->flags |= BB_VISITED;\n-\n-      /* BB must have one outgoing edge.  That edge must not lead to\n-\t the exit block or the next block.\n-\t The destination must have more than one predecessor.  */\n-      if (!single_succ_p (bb)\n-\t  || single_succ (bb) == EXIT_BLOCK_PTR_FOR_FN (fun)\n-\t  || single_succ (bb) == bb->next_bb\n-\t  || single_pred_p (single_succ (bb)))\n-\tcontinue;\n-\n-      /* The successor block has to be a duplication candidate.  */\n-      if (!bitmap_bit_p (candidates, single_succ (bb)->index))\n-\tcontinue;\n-\n-      /* Don't duplicate a partition crossing edge, which requires difficult\n-         fixup.  */\n-      if (JUMP_P (BB_END (bb)) && CROSSING_JUMP_P (BB_END (bb)))\n-\tcontinue;\n-\n-      new_bb = duplicate_block (single_succ (bb), single_succ_edge (bb), bb);\n-      new_bb->aux = bb->aux;\n-      bb->aux = new_bb;\n-      new_bb->flags |= BB_VISITED;\n-      changed = true;\n-    }\n-\n- done:\n-  if (changed)\n-    {\n-      /* Duplicating blocks above will redirect edges and may cause hot\n-\t blocks previously reached by both hot and cold blocks to become\n-\t dominated only by cold blocks.  */\n-      fixup_partitions ();\n-\n-      /* Merge the duplicated blocks into predecessors, when possible.  */\n-      cfg_layout_finalize ();\n-      cleanup_cfg (0);\n-    }\n-  else\n-    cfg_layout_finalize ();\n+  duplicate_computed_gotos (fun);\n \n-  BITMAP_FREE (candidates);\n   return 0;\n }\n "}]}