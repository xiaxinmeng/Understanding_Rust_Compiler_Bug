{"sha": "ae9270466ed530df375bcaf6b3d834dbef6e3965", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YWU5MjcwNDY2ZWQ1MzBkZjM3NWJjYWY2YjNkODM0ZGJlZjZlMzk2NQ==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@linaro.org", "date": "2017-08-30T11:14:49Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2017-08-30T11:14:49Z"}, "message": "[39/77] Two changes to the get_best_mode interface\n\nget_best_mode always returns a scalar_int_mode on success,\nso this patch makes that explicit in the type system.  Also,\nthe \"largest_mode\" argument is used simply to provide a maximum\nsize, and in practice that size is always a compile-time constant,\neven when the concept of variable-sized modes is added later.\nThe patch therefore passes the size directly.\n\n2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n\t    Alan Hayward  <alan.hayward@arm.com>\n\t    David Sherwood  <david.sherwood@arm.com>\n\ngcc/\n\t* machmode.h (bit_field_mode_iterator::next_mode): Take a pointer\n\tto a scalar_int_mode instead of a machine_mode.\n\t(bit_field_mode_iterator::m_mode): Change type to opt_scalar_int_mode.\n\t(get_best_mode): Return a boolean and use a pointer argument to store\n\tthe selected mode.  Replace the limit mode parameter with a bit limit.\n\t* expmed.c (adjust_bit_field_mem_for_reg): Use scalar_int_mode\n\tfor the values returned by bit_field_mode_iterator::next_mode.\n\t(store_bit_field): Update call to get_best_mode.\n\t(store_fixed_bit_field): Likewise.\n\t(extract_fixed_bit_field): Likewise.\n\t* expr.c (optimize_bitfield_assignment_op): Likewise.\n\t* fold-const.c (optimize_bit_field_compare): Likewise.\n\t(fold_truth_andor_1): Likewise.\n\t* stor-layout.c (bit_field_mode_iterator::next_mode): As above.\n\tUpdate for new type of m_mode.\n\t(get_best_mode): As above.\n\nCo-Authored-By: Alan Hayward <alan.hayward@arm.com>\nCo-Authored-By: David Sherwood <david.sherwood@arm.com>\n\nFrom-SVN: r251491", "tree": {"sha": "ab6119ee9f8a12e6d5463797916b7995fad7bf4a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/ab6119ee9f8a12e6d5463797916b7995fad7bf4a"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/ae9270466ed530df375bcaf6b3d834dbef6e3965", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ae9270466ed530df375bcaf6b3d834dbef6e3965", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ae9270466ed530df375bcaf6b3d834dbef6e3965", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ae9270466ed530df375bcaf6b3d834dbef6e3965/comments", "author": null, "committer": null, "parents": [{"sha": "0ef40942d026e60b28d384b0fb2ff203bf1beca1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0ef40942d026e60b28d384b0fb2ff203bf1beca1", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0ef40942d026e60b28d384b0fb2ff203bf1beca1"}], "stats": {"total": 157, "additions": 90, "deletions": 67}, "files": [{"sha": "ac4425102014d3b79d71430a47cc9283be0826ea", "filename": "gcc/ChangeLog", "status": "modified", "additions": 21, "deletions": 0, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ae9270466ed530df375bcaf6b3d834dbef6e3965/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ae9270466ed530df375bcaf6b3d834dbef6e3965/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=ae9270466ed530df375bcaf6b3d834dbef6e3965", "patch": "@@ -1,3 +1,24 @@\n+2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n+\t    Alan Hayward  <alan.hayward@arm.com>\n+\t    David Sherwood  <david.sherwood@arm.com>\n+\n+\t* machmode.h (bit_field_mode_iterator::next_mode): Take a pointer\n+\tto a scalar_int_mode instead of a machine_mode.\n+\t(bit_field_mode_iterator::m_mode): Change type to opt_scalar_int_mode.\n+\t(get_best_mode): Return a boolean and use a pointer argument to store\n+\tthe selected mode.  Replace the limit mode parameter with a bit limit.\n+\t* expmed.c (adjust_bit_field_mem_for_reg): Use scalar_int_mode\n+\tfor the values returned by bit_field_mode_iterator::next_mode.\n+\t(store_bit_field): Update call to get_best_mode.\n+\t(store_fixed_bit_field): Likewise.\n+\t(extract_fixed_bit_field): Likewise.\n+\t* expr.c (optimize_bitfield_assignment_op): Likewise.\n+\t* fold-const.c (optimize_bit_field_compare): Likewise.\n+\t(fold_truth_andor_1): Likewise.\n+\t* stor-layout.c (bit_field_mode_iterator::next_mode): As above.\n+\tUpdate for new type of m_mode.\n+\t(get_best_mode): As above.\n+\n 2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n \t    Alan Hayward  <alan.hayward@arm.com>\n \t    David Sherwood  <david.sherwood@arm.com>"}, {"sha": "641bc244a30f1df55b01513f31449f081c74c4d4", "filename": "gcc/expmed.c", "status": "modified", "additions": 19, "deletions": 18, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ae9270466ed530df375bcaf6b3d834dbef6e3965/gcc%2Fexpmed.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ae9270466ed530df375bcaf6b3d834dbef6e3965/gcc%2Fexpmed.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpmed.c?ref=ae9270466ed530df375bcaf6b3d834dbef6e3965", "patch": "@@ -461,7 +461,7 @@ adjust_bit_field_mem_for_reg (enum extraction_pattern pattern,\n   bit_field_mode_iterator iter (bitsize, bitnum, bitregion_start,\n \t\t\t\tbitregion_end, MEM_ALIGN (op0),\n \t\t\t\tMEM_VOLATILE_P (op0));\n-  machine_mode best_mode;\n+  scalar_int_mode best_mode;\n   if (iter.next_mode (&best_mode))\n     {\n       /* We can use a memory in BEST_MODE.  See whether this is true for\n@@ -479,7 +479,7 @@ adjust_bit_field_mem_for_reg (enum extraction_pattern pattern,\n \t\t\t\t\t    fieldmode))\n \t    limit_mode = insn.field_mode;\n \n-\t  machine_mode wider_mode;\n+\t  scalar_int_mode wider_mode;\n \t  while (iter.next_mode (&wider_mode)\n \t\t && GET_MODE_SIZE (wider_mode) <= GET_MODE_SIZE (limit_mode))\n \t    best_mode = wider_mode;\n@@ -1095,7 +1095,8 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n      bit region.  */\n   if (MEM_P (str_rtx) && bitregion_start > 0)\n     {\n-      machine_mode bestmode;\n+      scalar_int_mode best_mode;\n+      machine_mode addr_mode = VOIDmode;\n       HOST_WIDE_INT offset, size;\n \n       gcc_assert ((bitregion_start % BITS_PER_UNIT) == 0);\n@@ -1105,11 +1106,13 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n       size = (bitnum + bitsize + BITS_PER_UNIT - 1) / BITS_PER_UNIT;\n       bitregion_end -= bitregion_start;\n       bitregion_start = 0;\n-      bestmode = get_best_mode (bitsize, bitnum,\n-\t\t\t\tbitregion_start, bitregion_end,\n-\t\t\t\tMEM_ALIGN (str_rtx), VOIDmode,\n-\t\t\t\tMEM_VOLATILE_P (str_rtx));\n-      str_rtx = adjust_bitfield_address_size (str_rtx, bestmode, offset, size);\n+      if (get_best_mode (bitsize, bitnum,\n+\t\t\t bitregion_start, bitregion_end,\n+\t\t\t MEM_ALIGN (str_rtx), INT_MAX,\n+\t\t\t MEM_VOLATILE_P (str_rtx), &best_mode))\n+\taddr_mode = best_mode;\n+      str_rtx = adjust_bitfield_address_size (str_rtx, addr_mode,\n+\t\t\t\t\t      offset, size);\n     }\n \n   if (!store_bit_field_1 (str_rtx, bitsize, bitnum,\n@@ -1143,10 +1146,10 @@ store_fixed_bit_field (rtx op0, unsigned HOST_WIDE_INT bitsize,\n       if (GET_MODE_BITSIZE (mode) == 0\n \t  || GET_MODE_BITSIZE (mode) > GET_MODE_BITSIZE (word_mode))\n \tmode = word_mode;\n-      mode = get_best_mode (bitsize, bitnum, bitregion_start, bitregion_end,\n-\t\t\t    MEM_ALIGN (op0), mode, MEM_VOLATILE_P (op0));\n-\n-      if (mode == VOIDmode)\n+      scalar_int_mode best_mode;\n+      if (!get_best_mode (bitsize, bitnum, bitregion_start, bitregion_end,\n+\t\t\t  MEM_ALIGN (op0), GET_MODE_BITSIZE (mode),\n+\t\t\t  MEM_VOLATILE_P (op0), &best_mode))\n \t{\n \t  /* The only way this should occur is if the field spans word\n \t     boundaries.  */\n@@ -1155,7 +1158,7 @@ store_fixed_bit_field (rtx op0, unsigned HOST_WIDE_INT bitsize,\n \t  return;\n \t}\n \n-      op0 = narrow_bit_field_mem (op0, mode, bitsize, bitnum, &bitnum);\n+      op0 = narrow_bit_field_mem (op0, best_mode, bitsize, bitnum, &bitnum);\n     }\n \n   store_fixed_bit_field_1 (op0, bitsize, bitnum, value, reverse);\n@@ -1998,11 +2001,9 @@ extract_fixed_bit_field (machine_mode tmode, rtx op0,\n {\n   if (MEM_P (op0))\n     {\n-      machine_mode mode\n-\t= get_best_mode (bitsize, bitnum, 0, 0, MEM_ALIGN (op0), word_mode,\n-\t\t\t MEM_VOLATILE_P (op0));\n-\n-      if (mode == VOIDmode)\n+      scalar_int_mode mode;\n+      if (!get_best_mode (bitsize, bitnum, 0, 0, MEM_ALIGN (op0),\n+\t\t\t  BITS_PER_WORD, MEM_VOLATILE_P (op0), &mode))\n \t/* The only way this should occur is if the field spans word\n \t   boundaries.  */\n \treturn extract_split_bit_field (op0, bitsize, bitnum, unsignedp,"}, {"sha": "0006377d9891fae72559a3069778a96f7de22e0c", "filename": "gcc/expr.c", "status": "modified", "additions": 7, "deletions": 6, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ae9270466ed530df375bcaf6b3d834dbef6e3965/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ae9270466ed530df375bcaf6b3d834dbef6e3965/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=ae9270466ed530df375bcaf6b3d834dbef6e3965", "patch": "@@ -4682,13 +4682,14 @@ optimize_bitfield_assignment_op (unsigned HOST_WIDE_INT bitsize,\n       unsigned HOST_WIDE_INT offset1;\n \n       if (str_bitsize == 0 || str_bitsize > BITS_PER_WORD)\n-\tstr_mode = word_mode;\n-      str_mode = get_best_mode (bitsize, bitpos,\n-\t\t\t\tbitregion_start, bitregion_end,\n-\t\t\t\tMEM_ALIGN (str_rtx), str_mode, 0);\n-      if (str_mode == VOIDmode)\n+\tstr_bitsize = BITS_PER_WORD;\n+\n+      scalar_int_mode best_mode;\n+      if (!get_best_mode (bitsize, bitpos, bitregion_start, bitregion_end,\n+\t\t\t  MEM_ALIGN (str_rtx), str_bitsize, false, &best_mode))\n \treturn false;\n-      str_bitsize = GET_MODE_BITSIZE (str_mode);\n+      str_mode = best_mode;\n+      str_bitsize = GET_MODE_BITSIZE (best_mode);\n \n       offset1 = bitpos;\n       bitpos %= str_bitsize;"}, {"sha": "492d7f16169226ac5c0cb6863827df07688879cd", "filename": "gcc/fold-const.c", "status": "modified", "additions": 14, "deletions": 16, "changes": 30, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ae9270466ed530df375bcaf6b3d834dbef6e3965/gcc%2Ffold-const.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ae9270466ed530df375bcaf6b3d834dbef6e3965/gcc%2Ffold-const.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffold-const.c?ref=ae9270466ed530df375bcaf6b3d834dbef6e3965", "patch": "@@ -3934,7 +3934,8 @@ optimize_bit_field_compare (location_t loc, enum tree_code code,\n   tree type = TREE_TYPE (lhs);\n   tree unsigned_type;\n   int const_p = TREE_CODE (rhs) == INTEGER_CST;\n-  machine_mode lmode, rmode, nmode;\n+  machine_mode lmode, rmode;\n+  scalar_int_mode nmode;\n   int lunsignedp, runsignedp;\n   int lreversep, rreversep;\n   int lvolatilep = 0, rvolatilep = 0;\n@@ -3981,12 +3982,11 @@ optimize_bit_field_compare (location_t loc, enum tree_code code,\n \n   /* See if we can find a mode to refer to this field.  We should be able to,\n      but fail if we can't.  */\n-  nmode = get_best_mode (lbitsize, lbitpos, bitstart, bitend,\n-\t\t\t const_p ? TYPE_ALIGN (TREE_TYPE (linner))\n-\t\t\t : MIN (TYPE_ALIGN (TREE_TYPE (linner)),\n-\t\t\t\tTYPE_ALIGN (TREE_TYPE (rinner))),\n-\t\t\t word_mode, false);\n-  if (nmode == VOIDmode)\n+  if (!get_best_mode (lbitsize, lbitpos, bitstart, bitend,\n+\t\t      const_p ? TYPE_ALIGN (TREE_TYPE (linner))\n+\t\t      : MIN (TYPE_ALIGN (TREE_TYPE (linner)),\n+\t\t\t     TYPE_ALIGN (TREE_TYPE (rinner))),\n+\t\t      BITS_PER_WORD, false, &nmode))\n     return 0;\n \n   /* Set signed and unsigned types of the precision of this mode for the\n@@ -5591,7 +5591,7 @@ fold_truth_andor_1 (location_t loc, enum tree_code code, tree truth_type,\n   int ll_unsignedp, lr_unsignedp, rl_unsignedp, rr_unsignedp;\n   int ll_reversep, lr_reversep, rl_reversep, rr_reversep;\n   machine_mode ll_mode, lr_mode, rl_mode, rr_mode;\n-  machine_mode lnmode, rnmode;\n+  scalar_int_mode lnmode, rnmode;\n   tree ll_mask, lr_mask, rl_mask, rr_mask;\n   tree ll_and_mask, lr_and_mask, rl_and_mask, rr_and_mask;\n   tree l_const, r_const;\n@@ -5777,10 +5777,9 @@ fold_truth_andor_1 (location_t loc, enum tree_code code, tree truth_type,\n      to be relative to a field of that size.  */\n   first_bit = MIN (ll_bitpos, rl_bitpos);\n   end_bit = MAX (ll_bitpos + ll_bitsize, rl_bitpos + rl_bitsize);\n-  lnmode = get_best_mode (end_bit - first_bit, first_bit, 0, 0,\n-\t\t\t  TYPE_ALIGN (TREE_TYPE (ll_inner)), word_mode,\n-\t\t\t  volatilep);\n-  if (lnmode == VOIDmode)\n+  if (!get_best_mode (end_bit - first_bit, first_bit, 0, 0,\n+\t\t      TYPE_ALIGN (TREE_TYPE (ll_inner)), BITS_PER_WORD,\n+\t\t      volatilep, &lnmode))\n     return 0;\n \n   lnbitsize = GET_MODE_BITSIZE (lnmode);\n@@ -5842,10 +5841,9 @@ fold_truth_andor_1 (location_t loc, enum tree_code code, tree truth_type,\n \n       first_bit = MIN (lr_bitpos, rr_bitpos);\n       end_bit = MAX (lr_bitpos + lr_bitsize, rr_bitpos + rr_bitsize);\n-      rnmode = get_best_mode (end_bit - first_bit, first_bit, 0, 0,\n-\t\t\t      TYPE_ALIGN (TREE_TYPE (lr_inner)), word_mode,\n-\t\t\t      volatilep);\n-      if (rnmode == VOIDmode)\n+      if (!get_best_mode (end_bit - first_bit, first_bit, 0, 0,\n+\t\t\t  TYPE_ALIGN (TREE_TYPE (lr_inner)), BITS_PER_WORD,\n+\t\t\t  volatilep, &rnmode))\n \treturn 0;\n \n       rnbitsize = GET_MODE_BITSIZE (rnmode);"}, {"sha": "5f3e031324ec4656aa1d4a30cf7abd0eff54093d", "filename": "gcc/machmode.h", "status": "modified", "additions": 5, "deletions": 7, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ae9270466ed530df375bcaf6b3d834dbef6e3965/gcc%2Fmachmode.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ae9270466ed530df375bcaf6b3d834dbef6e3965/gcc%2Fmachmode.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fmachmode.h?ref=ae9270466ed530df375bcaf6b3d834dbef6e3965", "patch": "@@ -617,11 +617,11 @@ class bit_field_mode_iterator\n   bit_field_mode_iterator (HOST_WIDE_INT, HOST_WIDE_INT,\n \t\t\t   HOST_WIDE_INT, HOST_WIDE_INT,\n \t\t\t   unsigned int, bool);\n-  bool next_mode (machine_mode *);\n+  bool next_mode (scalar_int_mode *);\n   bool prefer_smaller_modes ();\n \n private:\n-  machine_mode m_mode;\n+  opt_scalar_int_mode m_mode;\n   /* We use signed values here because the bit position can be negative\n      for invalid input such as gcc.dg/pr48335-8.c.  */\n   HOST_WIDE_INT m_bitsize;\n@@ -635,11 +635,9 @@ class bit_field_mode_iterator\n \n /* Find the best mode to use to access a bit field.  */\n \n-extern machine_mode get_best_mode (int, int,\n-\t\t\t\t\tunsigned HOST_WIDE_INT,\n-\t\t\t\t\tunsigned HOST_WIDE_INT,\n-\t\t\t\t\tunsigned int,\n-\t\t\t\t\tmachine_mode, bool);\n+extern bool get_best_mode (int, int, unsigned HOST_WIDE_INT,\n+\t\t\t   unsigned HOST_WIDE_INT, unsigned int,\n+\t\t\t   unsigned HOST_WIDE_INT, bool, scalar_int_mode *);\n \n /* Determine alignment, 1<=result<=BIGGEST_ALIGNMENT.  */\n "}, {"sha": "707c077f1c9adcd809ad605c575b367052cf6353", "filename": "gcc/stor-layout.c", "status": "modified", "additions": 24, "deletions": 20, "changes": 44, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ae9270466ed530df375bcaf6b3d834dbef6e3965/gcc%2Fstor-layout.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ae9270466ed530df375bcaf6b3d834dbef6e3965/gcc%2Fstor-layout.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstor-layout.c?ref=ae9270466ed530df375bcaf6b3d834dbef6e3965", "patch": "@@ -2748,15 +2748,15 @@ ::bit_field_mode_iterator (HOST_WIDE_INT bitsize, HOST_WIDE_INT bitpos,\n    available, storing it in *OUT_MODE if so.  */\n \n bool\n-bit_field_mode_iterator::next_mode (machine_mode *out_mode)\n+bit_field_mode_iterator::next_mode (scalar_int_mode *out_mode)\n {\n-  for (; m_mode != VOIDmode;\n-       m_mode = GET_MODE_WIDER_MODE (m_mode).else_void ())\n+  scalar_int_mode mode;\n+  for (; m_mode.exists (&mode); m_mode = GET_MODE_WIDER_MODE (mode))\n     {\n-      unsigned int unit = GET_MODE_BITSIZE (m_mode);\n+      unsigned int unit = GET_MODE_BITSIZE (mode);\n \n       /* Skip modes that don't have full precision.  */\n-      if (unit != GET_MODE_PRECISION (m_mode))\n+      if (unit != GET_MODE_PRECISION (mode))\n \tcontinue;\n \n       /* Stop if the mode is too wide to handle efficiently.  */\n@@ -2783,12 +2783,12 @@ bit_field_mode_iterator::next_mode (machine_mode *out_mode)\n \tbreak;\n \n       /* Stop if the mode requires too much alignment.  */\n-      if (GET_MODE_ALIGNMENT (m_mode) > m_align\n-\t  && SLOW_UNALIGNED_ACCESS (m_mode, m_align))\n+      if (GET_MODE_ALIGNMENT (mode) > m_align\n+\t  && SLOW_UNALIGNED_ACCESS (mode, m_align))\n \tbreak;\n \n-      *out_mode = m_mode;\n-      m_mode = GET_MODE_WIDER_MODE (m_mode).else_void ();\n+      *out_mode = mode;\n+      m_mode = GET_MODE_WIDER_MODE (mode);\n       m_count++;\n       return true;\n     }\n@@ -2815,12 +2815,14 @@ bit_field_mode_iterator::prefer_smaller_modes ()\n    memory access to that range.  Otherwise, we are allowed to touch\n    any adjacent non bit-fields.\n \n-   The underlying object is known to be aligned to a boundary of ALIGN bits.\n-   If LARGEST_MODE is not VOIDmode, it means that we should not use a mode\n-   larger than LARGEST_MODE (usually SImode).\n+   The chosen mode must have no more than LARGEST_MODE_BITSIZE bits.\n+   INT_MAX is a suitable value for LARGEST_MODE_BITSIZE if the caller\n+   doesn't want to apply a specific limit.\n \n    If no mode meets all these conditions, we return VOIDmode.\n \n+   The underlying object is known to be aligned to a boundary of ALIGN bits.\n+\n    If VOLATILEP is false and SLOW_BYTE_ACCESS is false, we return the\n    smallest mode meeting these conditions.\n \n@@ -2831,17 +2833,18 @@ bit_field_mode_iterator::prefer_smaller_modes ()\n    If VOLATILEP is true the narrow_volatile_bitfields target hook is used to\n    decide which of the above modes should be used.  */\n \n-machine_mode\n+bool\n get_best_mode (int bitsize, int bitpos,\n \t       unsigned HOST_WIDE_INT bitregion_start,\n \t       unsigned HOST_WIDE_INT bitregion_end,\n \t       unsigned int align,\n-\t       machine_mode largest_mode, bool volatilep)\n+\t       unsigned HOST_WIDE_INT largest_mode_bitsize, bool volatilep,\n+\t       scalar_int_mode *best_mode)\n {\n   bit_field_mode_iterator iter (bitsize, bitpos, bitregion_start,\n \t\t\t\tbitregion_end, align, volatilep);\n-  machine_mode widest_mode = VOIDmode;\n-  machine_mode mode;\n+  scalar_int_mode mode;\n+  bool found = false;\n   while (iter.next_mode (&mode)\n \t /* ??? For historical reasons, reject modes that would normally\n \t    receive greater alignment, even if unaligned accesses are\n@@ -2900,14 +2903,15 @@ get_best_mode (int bitsize, int bitpos,\n \t    so that the final bitfield reference still has a MEM_EXPR\n \t    and MEM_OFFSET.  */\n \t && GET_MODE_ALIGNMENT (mode) <= align\n-\t && (largest_mode == VOIDmode\n-\t     || GET_MODE_SIZE (mode) <= GET_MODE_SIZE (largest_mode)))\n+\t && GET_MODE_BITSIZE (mode) <= largest_mode_bitsize)\n     {\n-      widest_mode = mode;\n+      *best_mode = mode;\n+      found = true;\n       if (iter.prefer_smaller_modes ())\n \tbreak;\n     }\n-  return widest_mode;\n+\n+  return found;\n }\n \n /* Gets minimal and maximal values for MODE (signed or unsigned depending on"}]}