{"sha": "2a837de28ee94b4ec201059a9a7aaa852e6808da", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MmE4MzdkZTI4ZWU5NGI0ZWMyMDEwNTlhOWE3YWFhODUyZTY4MDhkYQ==", "commit": {"author": {"name": "Martin Sebor", "email": "msebor@redhat.com", "date": "2021-07-28T21:28:10Z"}, "committer": {"name": "Martin Sebor", "email": "msebor@redhat.com", "date": "2021-07-28T22:02:17Z"}, "message": "Add new gimple-ssa-warn-access pass.\n\ngcc/ChangeLog:\n\n\t* Makefile.in (OBJS): Add gimple-ssa-warn-access.o and pointer-query.o.\n\t* attribs.h (fndecl_dealloc_argno): Move fndecl_dealloc_argno to tree.h.\n\t* builtins.c (compute_objsize_r): Move to pointer-query.cc.\n\t(access_ref::access_ref): Same.\n\t(access_ref::phi): Same.\n\t(access_ref::get_ref): Same.\n\t(access_ref::size_remaining): Same.\n\t(access_ref::offset_in_range): Same.\n\t(access_ref::add_offset): Same.\n\t(access_ref::inform_access): Same.\n\t(ssa_name_limit_t::visit_phi): Same.\n\t(ssa_name_limit_t::leave_phi): Same.\n\t(ssa_name_limit_t::next): Same.\n\t(ssa_name_limit_t::next_phi): Same.\n\t(ssa_name_limit_t::~ssa_name_limit_t): Same.\n\t(pointer_query::pointer_query): Same.\n\t(pointer_query::get_ref): Same.\n\t(pointer_query::put_ref): Same.\n\t(pointer_query::flush_cache): Same.\n\t(warn_string_no_nul): Move to gimple-ssa-warn-access.cc.\n\t(check_nul_terminated_array): Same.\n\t(unterminated_array): Same.\n\t(maybe_warn_for_bound): Same.\n\t(check_read_access): Same.\n\t(warn_for_access): Same.\n\t(get_size_range): Same.\n\t(check_access): Same.\n\t(gimple_call_alloc_size): Move to tree.c.\n\t(gimple_parm_array_size): Move to pointer-query.cc.\n\t(get_offset_range): Same.\n\t(gimple_call_return_array): Same.\n\t(handle_min_max_size): Same.\n\t(handle_array_ref): Same.\n\t(handle_mem_ref): Same.\n\t(compute_objsize): Same.\n\t(gimple_call_alloc_p): Move to gimple-ssa-warn-access.cc.\n\t(call_dealloc_argno): Same.\n\t(fndecl_dealloc_argno): Same.\n\t(new_delete_mismatch_p): Same.\n\t(matching_alloc_calls_p): Same.\n\t(warn_dealloc_offset): Same.\n\t(maybe_emit_free_warning): Same.\n\t* builtins.h (check_nul_terminated_array): Move to\n\tgimple-ssa-warn-access.h.\n\t(check_nul_terminated_array): Same.\n\t(warn_string_no_nul): Same.\n\t(unterminated_array): Same.\n\t(class ssa_name_limit_t): Same.\n\t(class pointer_query): Same.\n\t(struct access_ref): Same.\n\t(class range_query): Same.\n\t(struct access_data): Same.\n\t(gimple_call_alloc_size): Same.\n\t(gimple_parm_array_size): Same.\n\t(compute_objsize): Same.\n\t(class access_data): Same.\n\t(maybe_emit_free_warning): Same.\n\t* calls.c (initialize_argument_information): Remove call to\n\tmaybe_emit_free_warning.\n\t* gimple-array-bounds.cc: Include new header..\n\t* gimple-fold.c: Same.\n\t* gimple-ssa-sprintf.c: Same.\n\t* gimple-ssa-warn-restrict.c: Same.\n\t* passes.def: Add pass_warn_access.\n\t* tree-pass.h (make_pass_warn_access): Declare.\n\t* tree-ssa-strlen.c: Include new headers.\n\t* tree.c (fndecl_dealloc_argno): Move here from builtins.c.\n\t* tree.h (fndecl_dealloc_argno): Move here from attribs.h.\n\t* gimple-ssa-warn-access.cc: New file.\n\t* gimple-ssa-warn-access.h: New file.\n\t* pointer-query.cc: New file.\n\t* pointer-query.h: New file.\n\ngcc/cp/ChangeLog:\n\n\t* init.c: Include new header.", "tree": {"sha": "69c62e5581139c45d20f695344749058b7ae0978", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/69c62e5581139c45d20f695344749058b7ae0978"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/2a837de28ee94b4ec201059a9a7aaa852e6808da", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2a837de28ee94b4ec201059a9a7aaa852e6808da", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2a837de28ee94b4ec201059a9a7aaa852e6808da", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2a837de28ee94b4ec201059a9a7aaa852e6808da/comments", "author": {"login": "msebor", "id": 381149, "node_id": "MDQ6VXNlcjM4MTE0OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/381149?v=4", "gravatar_id": "", "url": "https://api.github.com/users/msebor", "html_url": "https://github.com/msebor", "followers_url": "https://api.github.com/users/msebor/followers", "following_url": "https://api.github.com/users/msebor/following{/other_user}", "gists_url": "https://api.github.com/users/msebor/gists{/gist_id}", "starred_url": "https://api.github.com/users/msebor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/msebor/subscriptions", "organizations_url": "https://api.github.com/users/msebor/orgs", "repos_url": "https://api.github.com/users/msebor/repos", "events_url": "https://api.github.com/users/msebor/events{/privacy}", "received_events_url": "https://api.github.com/users/msebor/received_events", "type": "User", "site_admin": false}, "committer": {"login": "msebor", "id": 381149, "node_id": "MDQ6VXNlcjM4MTE0OQ==", "avatar_url": "https://avatars.githubusercontent.com/u/381149?v=4", "gravatar_id": "", "url": "https://api.github.com/users/msebor", "html_url": "https://github.com/msebor", "followers_url": "https://api.github.com/users/msebor/followers", "following_url": "https://api.github.com/users/msebor/following{/other_user}", "gists_url": "https://api.github.com/users/msebor/gists{/gist_id}", "starred_url": "https://api.github.com/users/msebor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/msebor/subscriptions", "organizations_url": "https://api.github.com/users/msebor/orgs", "repos_url": "https://api.github.com/users/msebor/repos", "events_url": "https://api.github.com/users/msebor/events{/privacy}", "received_events_url": "https://api.github.com/users/msebor/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "f471739e636734c2b4933cc4cb4ebad6cb2083ad", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f471739e636734c2b4933cc4cb4ebad6cb2083ad", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f471739e636734c2b4933cc4cb4ebad6cb2083ad"}], "stats": {"total": 19440, "additions": 9855, "deletions": 9585}, "files": [{"sha": "98eb479a125e2bdd936eac011b8df506d9ee702d", "filename": "gcc/Makefile.in", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -1414,6 +1414,7 @@ OBJS = \\\n \tgimple-ssa-store-merging.o \\\n \tgimple-ssa-strength-reduction.o \\\n \tgimple-ssa-sprintf.o \\\n+\tgimple-ssa-warn-access.o \\\n \tgimple-ssa-warn-alloca.o \\\n \tgimple-ssa-warn-restrict.o \\\n \tgimple-streamer-in.o \\\n@@ -1524,6 +1525,7 @@ OBJS = \\\n \tordered-hash-map-tests.o \\\n \tpasses.o \\\n \tplugin.o \\\n+\tpointer-query.o \\\n \tpostreload-gcse.o \\\n \tpostreload.o \\\n \tpredict.o \\"}, {"sha": "87231b954c6e776dbce3903d9d9e913d58021260", "filename": "gcc/attribs.h", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fattribs.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fattribs.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fattribs.h?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -316,6 +316,4 @@ extern void init_attr_rdwr_indices (rdwr_map *, tree);\n extern attr_access *get_parm_access (rdwr_map &, tree,\n \t\t\t\t     tree = current_function_decl);\n \n-extern unsigned fndecl_dealloc_argno (tree fndecl);\n-\n #endif // GCC_ATTRIBS_H"}, {"sha": "845a8bb12012c76e7d874058e347967858cfbc62", "filename": "gcc/builtins.c", "status": "modified", "additions": 5847, "deletions": 9362, "changes": 15209, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fbuiltins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fbuiltins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.c?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da"}, {"sha": "b580635a09f03406b9c0edbf5510e233d3bfa37a", "filename": "gcc/builtins.h", "status": "modified", "additions": 1, "deletions": 214, "changes": 215, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fbuiltins.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fbuiltins.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.h?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -149,223 +149,10 @@ extern bool target_char_cst_p (tree t, char *p);\n extern internal_fn associated_internal_fn (tree);\n extern internal_fn replacement_internal_fn (gcall *);\n \n-extern bool check_nul_terminated_array (tree, tree, tree = NULL_TREE);\n-extern void warn_string_no_nul (location_t, tree, const char *, tree,\n-\t\t\t\ttree, tree = NULL_TREE, bool = false,\n-\t\t\t\tconst wide_int[2] = NULL);\n-extern tree unterminated_array (tree, tree * = NULL, bool * = NULL);\n extern bool builtin_with_linkage_p (tree);\n \n-/* Describes recursion limits used by functions that follow use-def\n-   chains of SSA_NAMEs.  */\n-\n-class ssa_name_limit_t\n-{\n-  bitmap visited;         /* Bitmap of visited SSA_NAMEs.  */\n-  unsigned ssa_def_max;   /* Longest chain of SSA_NAMEs to follow.  */\n-\n-  /* Not copyable or assignable.  */\n-  DISABLE_COPY_AND_ASSIGN (ssa_name_limit_t);\n-\n-public:\n-\n-  ssa_name_limit_t ()\n-    : visited (),\n-      ssa_def_max (param_ssa_name_def_chain_limit) { }\n-\n-  /* Set a bit for the PHI in VISITED and return true if it wasn't\n-     already set.  */\n-  bool visit_phi (tree);\n-  /* Clear a bit for the PHI in VISITED.  */\n-  void leave_phi (tree);\n-  /* Return false if the SSA_NAME chain length counter has reached\n-     the limit, otherwise increment the counter and return true.  */\n-  bool next ();\n-\n-  /* If the SSA_NAME has already been \"seen\" return a positive value.\n-     Otherwise add it to VISITED.  If the SSA_NAME limit has been\n-     reached, return a negative value.  Otherwise return zero.  */\n-  int next_phi (tree);\n-\n-  ~ssa_name_limit_t ();\n-};\n-\n-class pointer_query;\n-\n-/* Describes a reference to an object used in an access.  */\n-struct access_ref\n-{\n-  /* Set the bounds of the reference to at most as many bytes\n-     as the first argument or unknown when null, and at least\n-     one when the second argument is true unless the first one\n-     is a constant zero.  */\n-  access_ref (tree = NULL_TREE, bool = false);\n-\n-  /* Return the PHI node REF refers to or null if it doesn't.  */\n-  gphi *phi () const;\n-\n-  /* Return the object to which REF refers.  */\n-  tree get_ref (vec<access_ref> *, access_ref * = NULL, int = 1,\n-\t\tssa_name_limit_t * = NULL, pointer_query * = NULL) const;\n-\n-  /* Return true if OFFRNG is the constant zero.  */\n-  bool offset_zero () const\n-  {\n-    return offrng[0] == 0 && offrng[1] == 0;\n-  }\n-\n-  /* Return true if OFFRNG is bounded to a subrange of offset values\n-     valid for the largest possible object.  */\n-  bool offset_bounded () const;\n-\n-  /* Return the maximum amount of space remaining and if non-null, set\n-     argument to the minimum.  */\n-  offset_int size_remaining (offset_int * = NULL) const;\n-\n-/* Return true if the offset and object size are in range for SIZE.  */\n-  bool offset_in_range (const offset_int &) const;\n-\n-  /* Return true if *THIS is an access to a declared object.  */\n-  bool ref_declared () const\n-  {\n-    return DECL_P (ref) && base0 && deref < 1;\n-  }\n-\n-  /* Set the size range to the maximum.  */\n-  void set_max_size_range ()\n-  {\n-    sizrng[0] = 0;\n-    sizrng[1] = wi::to_offset (max_object_size ());\n-  }\n-\n-  /* Add OFF to the offset range.  */\n-  void add_offset (const offset_int &off)\n-  {\n-    add_offset (off, off);\n-  }\n-\n-  /* Add the range [MIN, MAX] to the offset range.  */\n-  void add_offset (const offset_int &, const offset_int &);\n-\n-  /* Add the maximum representable offset to the offset range.  */\n-  void add_max_offset ()\n-  {\n-    offset_int maxoff = wi::to_offset (TYPE_MAX_VALUE (ptrdiff_type_node));\n-    add_offset (-maxoff - 1, maxoff);\n-  }\n-\n-  /* Issue an informational message describing the target of an access\n-     with the given mode.  */\n-  void inform_access (access_mode) const;\n-\n-  /* Reference to the accessed object(s).  */\n-  tree ref;\n-\n-  /* Range of byte offsets into and sizes of the object(s).  */\n-  offset_int offrng[2];\n-  offset_int sizrng[2];\n-  /* The minimum and maximum offset computed.  */\n-  offset_int offmax[2];\n-  /* Range of the bound of the access: denotes that the access\n-     is at least BNDRNG[0] bytes but no more than BNDRNG[1].\n-     For string functions the size of the actual access is\n-     further constrained by the length of the string.  */\n-  offset_int bndrng[2];\n-\n-  /* Used to fold integer expressions when called from front ends.  */\n-  tree (*eval)(tree);\n-  /* Positive when REF is dereferenced, negative when its address is\n-     taken.  */\n-  int deref;\n-  /* Set if trailing one-element arrays should be treated as flexible\n-     array members.  */\n-  bool trail1special;\n-  /* Set if valid offsets must start at zero (for declared and allocated\n-     objects but not for others referenced by pointers).  */\n-  bool base0;\n-  /* Set if REF refers to a function array parameter not declared\n-     static.  */\n-  bool parmarray;\n-};\n-\n-class range_query;\n-\n-/* Queries and caches compute_objsize results.  */\n-class pointer_query\n-{\n-  DISABLE_COPY_AND_ASSIGN (pointer_query);\n-\n-public:\n-  /* Type of the two-level cache object defined by clients of the class\n-     to have pointer SSA_NAMEs cached for speedy access.  */\n-  struct cache_type\n-  {\n-    /* 1-based indices into cache.  */\n-    vec<unsigned> indices;\n-    /* The cache itself.  */\n-    vec<access_ref> access_refs;\n-  };\n-\n-  /* Construct an object with the given Ranger instance and cache.  */\n-  explicit pointer_query (range_query * = NULL, cache_type * = NULL);\n-\n-  /* Retrieve the access_ref for a variable from cache if it's there.  */\n-  const access_ref* get_ref (tree, int = 1) const;\n-\n-  /* Retrieve the access_ref for a variable from cache or compute it.  */\n-  bool get_ref (tree, access_ref*, int = 1);\n-\n-  /* Add an access_ref for the SSA_NAME to the cache.  */\n-  void put_ref (tree, const access_ref&, int = 1);\n-\n-  /* Flush the cache.  */\n-  void flush_cache ();\n-\n-  /* A Ranger instance.  May be null to use global ranges.  */\n-  range_query *rvals;\n-  /* Cache of SSA_NAMEs.  May be null to disable caching.  */\n-  cache_type *var_cache;\n-\n-  /* Cache performance counters.  */\n-  mutable unsigned hits;\n-  mutable unsigned misses;\n-  mutable unsigned failures;\n-  mutable unsigned depth;\n-  mutable unsigned max_depth;\n-};\n-\n-/* Describes a pair of references used in an access by built-in\n-   functions like memcpy.  */\n-struct access_data\n-{\n-  /* Set the access to at most MAXWRITE and MAXREAD bytes, and\n-     at least 1 when MINWRITE or MINREAD, respectively, is set.  */\n-  access_data (tree expr, access_mode mode,\n-\t       tree maxwrite = NULL_TREE, bool minwrite = false,\n-\t       tree maxread = NULL_TREE, bool minread = false)\n-    : call (expr),\n-      dst (maxwrite, minwrite), src (maxread, minread), mode (mode) { }\n-\n-  /* Built-in function call.  */\n-  tree call;\n-  /* Destination and source of the access.  */\n-  access_ref dst, src;\n-  /* Read-only for functions like memcmp or strlen, write-only\n-     for memset, read-write for memcpy or strcat.  */\n-  access_mode mode;\n-};\n-\n-extern tree gimple_call_alloc_size (gimple *, wide_int[2] = NULL,\n-\t\t\t\t    range_query * = NULL);\n-extern tree gimple_parm_array_size (tree, wide_int[2], bool * = NULL);\n-\n-extern tree compute_objsize (tree, int, access_ref *, range_query * = NULL);\n-/* Legacy/transitional API.  Should not be used in new code.  */\n-extern tree compute_objsize (tree, int, access_ref *, pointer_query *);\n-extern tree compute_objsize (tree, int, tree * = NULL, tree * = NULL,\n-\t\t\t     range_query * = NULL);\n+class access_data;\n extern bool check_access (tree, tree, tree, tree, tree,\n \t\t\t  access_mode, const access_data * = NULL);\n-extern void maybe_emit_free_warning (tree);\n \n #endif /* GCC_BUILTINS_H */"}, {"sha": "795d21414c18ac13bebe6fdedf716ab1bbd69c5e", "filename": "gcc/calls.c", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fcalls.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fcalls.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcalls.c?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -60,6 +60,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"gimple-fold.h\"\n #include \"attr-fnspec.h\"\n #include \"value-query.h\"\n+#include \"pointer-query.h\"\n \n #include \"tree-pretty-print.h\"\n \n@@ -2628,10 +2629,6 @@ initialize_argument_information (int num_actuals ATTRIBUTE_UNUSED,\n \n   /* Check attribute access arguments.  */\n   maybe_warn_rdwr_sizes (&rdwr_idx, fndecl, fntype, exp);\n-\n-  /* Check calls to operator new for mismatched forms and attempts\n-     to deallocate unallocated objects.  */\n-  maybe_emit_free_warning (exp);\n }\n \n /* Update ARGS_SIZE to contain the total size for the argument block."}, {"sha": "229c84e1d74d9e92ea40c52e72e44bdeafffc3d0", "filename": "gcc/cp/init.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fcp%2Finit.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fcp%2Finit.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Finit.c?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -34,7 +34,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"attribs.h\"\n #include \"asan.h\"\n #include \"stor-layout.h\"\n-#include \"builtins.h\"\n+#include \"pointer-query.h\"\n \n static bool begin_init_stmts (tree *, tree *);\n static tree finish_init_stmts (bool, tree, tree);"}, {"sha": "3a5c2dd0be88b3e08d290a0b7d7913f4ff3408e3", "filename": "gcc/gimple-array-bounds.cc", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fgimple-array-bounds.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fgimple-array-bounds.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-array-bounds.cc?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -37,7 +37,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"domwalk.h\"\n #include \"tree-cfg.h\"\n #include \"attribs.h\"\n-#include \"builtins.h\"\n+#include \"pointer-query.h\"\n \n // This purposely returns a value_range, not a value_range_equiv, to\n // break the dependency on equivalences for this pass."}, {"sha": "ad7b140173fa5c04ac9fbb1d5d4bd16aaa58baab", "filename": "gcc/gimple-fold.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fgimple-fold.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fgimple-fold.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-fold.c?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -30,6 +30,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"ssa.h\"\n #include \"cgraph.h\"\n #include \"gimple-pretty-print.h\"\n+#include \"gimple-ssa-warn-access.h\"\n #include \"gimple-ssa-warn-restrict.h\"\n #include \"fold-const.h\"\n #include \"stmt.h\""}, {"sha": "8e90b7cfc43c54d5d29208dd6519bab46aae093e", "filename": "gcc/gimple-ssa-sprintf.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fgimple-ssa-sprintf.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fgimple-ssa-sprintf.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-ssa-sprintf.c?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -71,6 +71,7 @@ along with GCC; see the file COPYING3.  If not see\n \n #include \"attribs.h\"\n #include \"builtins.h\"\n+#include \"pointer-query.h\"\n #include \"stor-layout.h\"\n \n #include \"realmpfr.h\""}, {"sha": "e4d98b2ec2845978d1f5d5fdb942f1d0cefd2892", "filename": "gcc/gimple-ssa-warn-access.cc", "status": "added", "additions": 1765, "deletions": 0, "changes": 1765, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fgimple-ssa-warn-access.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fgimple-ssa-warn-access.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-ssa-warn-access.cc?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -0,0 +1,1765 @@\n+/* Pass to detect and issue warnings for invalid accesses, including\n+   invalid or mismatched allocation/deallocation calls.\n+\n+   Copyright (C) 2020-2021 Free Software Foundation, Inc.\n+   Contributed by Martin Sebor <msebor@redhat.com>.\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 3, or (at your option) any later\n+   version.\n+\n+   GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+   WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with GCC; see the file COPYING3.  If not see\n+   <http://www.gnu.org/licenses/>.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"backend.h\"\n+#include \"tree.h\"\n+#include \"gimple.h\"\n+#include \"tree-pass.h\"\n+#include \"builtins.h\"\n+#include \"ssa.h\"\n+#include \"gimple-pretty-print.h\"\n+#include \"gimple-ssa-warn-access.h\"\n+#include \"gimple-ssa-warn-restrict.h\"\n+#include \"diagnostic-core.h\"\n+#include \"fold-const.h\"\n+#include \"gimple-fold.h\"\n+#include \"gimple-iterator.h\"\n+#include \"tree-dfa.h\"\n+#include \"tree-ssa.h\"\n+#include \"tree-cfg.h\"\n+#include \"tree-object-size.h\"\n+#include \"calls.h\"\n+#include \"cfgloop.h\"\n+#include \"intl.h\"\n+#include \"gimple-range.h\"\n+#include \"stringpool.h\"\n+#include \"attribs.h\"\n+#include \"demangle.h\"\n+#include \"pointer-query.h\"\n+\n+/* For a call EXPR at LOC to a function FNAME that expects a string\n+   in the argument ARG, issue a diagnostic due to it being a called\n+   with an argument that is a character array with no terminating\n+   NUL.  SIZE is the EXACT size of the array, and BNDRNG the number\n+   of characters in which the NUL is expected.  Either EXPR or FNAME\n+   may be null but noth both.  SIZE may be null when BNDRNG is null.  */\n+\n+void\n+warn_string_no_nul (location_t loc, tree expr, const char *fname,\n+\t\t    tree arg, tree decl, tree size /* = NULL_TREE */,\n+\t\t    bool exact /* = false */,\n+\t\t    const wide_int bndrng[2] /* = NULL */)\n+{\n+  const opt_code opt = OPT_Wstringop_overread;\n+  if ((expr && warning_suppressed_p (expr, opt))\n+      || warning_suppressed_p (arg, opt))\n+    return;\n+\n+  loc = expansion_point_location_if_in_system_header (loc);\n+  bool warned;\n+\n+  /* Format the bound range as a string to keep the nuber of messages\n+     from exploding.  */\n+  char bndstr[80];\n+  *bndstr = 0;\n+  if (bndrng)\n+    {\n+      if (bndrng[0] == bndrng[1])\n+\tsprintf (bndstr, \"%llu\", (unsigned long long) bndrng[0].to_uhwi ());\n+      else\n+\tsprintf (bndstr, \"[%llu, %llu]\",\n+\t\t (unsigned long long) bndrng[0].to_uhwi (),\n+\t\t (unsigned long long) bndrng[1].to_uhwi ());\n+    }\n+\n+  const tree maxobjsize = max_object_size ();\n+  const wide_int maxsiz = wi::to_wide (maxobjsize);\n+  if (expr)\n+    {\n+      tree func = get_callee_fndecl (expr);\n+      if (bndrng)\n+\t{\n+\t  if (wi::ltu_p (maxsiz, bndrng[0]))\n+\t    warned = warning_at (loc, opt,\n+\t\t\t\t \"%qD specified bound %s exceeds \"\n+\t\t\t\t \"maximum object size %E\",\n+\t\t\t\t func, bndstr, maxobjsize);\n+\t  else\n+\t    {\n+\t      bool maybe = wi::to_wide (size) == bndrng[0];\n+\t      warned = warning_at (loc, opt,\n+\t\t\t\t   exact\n+\t\t\t\t   ? G_(\"%qD specified bound %s exceeds \"\n+\t\t\t\t\t\"the size %E of unterminated array\")\n+\t\t\t\t   : (maybe\n+\t\t\t\t      ? G_(\"%qD specified bound %s may \"\n+\t\t\t\t\t   \"exceed the size of at most %E \"\n+\t\t\t\t\t   \"of unterminated array\")\n+\t\t\t\t      : G_(\"%qD specified bound %s exceeds \"\n+\t\t\t\t\t   \"the size of at most %E \"\n+\t\t\t\t\t   \"of unterminated array\")),\n+\t\t\t\t   func, bndstr, size);\n+\t    }\n+\t}\n+      else\n+\twarned = warning_at (loc, opt,\n+\t\t\t     \"%qD argument missing terminating nul\",\n+\t\t\t     func);\n+    }\n+  else\n+    {\n+      if (bndrng)\n+\t{\n+\t  if (wi::ltu_p (maxsiz, bndrng[0]))\n+\t    warned = warning_at (loc, opt,\n+\t\t\t\t \"%qs specified bound %s exceeds \"\n+\t\t\t\t \"maximum object size %E\",\n+\t\t\t\t fname, bndstr, maxobjsize);\n+\t  else\n+\t    {\n+\t      bool maybe = wi::to_wide (size) == bndrng[0];\n+\t      warned = warning_at (loc, opt,\n+\t\t\t\t   exact\n+\t\t\t\t   ? G_(\"%qs specified bound %s exceeds \"\n+\t\t\t\t\t\"the size %E of unterminated array\")\n+\t\t\t\t   : (maybe\n+\t\t\t\t      ? G_(\"%qs specified bound %s may \"\n+\t\t\t\t\t   \"exceed the size of at most %E \"\n+\t\t\t\t\t   \"of unterminated array\")\n+\t\t\t\t      : G_(\"%qs specified bound %s exceeds \"\n+\t\t\t\t\t   \"the size of at most %E \"\n+\t\t\t\t\t   \"of unterminated array\")),\n+\t\t\t\t   fname, bndstr, size);\n+\t    }\n+\t}\n+      else\n+\twarned = warning_at (loc, opt,\n+\t\t\t     \"%qs argument missing terminating nul\",\n+\t\t\t     fname);\n+    }\n+\n+  if (warned)\n+    {\n+      inform (DECL_SOURCE_LOCATION (decl),\n+\t      \"referenced argument declared here\");\n+      suppress_warning (arg, opt);\n+      if (expr)\n+\tsuppress_warning (expr, opt);\n+    }\n+}\n+\n+/* For a call EXPR (which may be null) that expects a string argument\n+   SRC as an argument, returns false if SRC is a character array with\n+   no terminating NUL.  When nonnull, BOUND is the number of characters\n+   in which to expect the terminating NUL.  RDONLY is true for read-only\n+   accesses such as strcmp, false for read-write such as strcpy.  When\n+   EXPR is also issues a warning.  */\n+\n+bool\n+check_nul_terminated_array (tree expr, tree src,\n+\t\t\t    tree bound /* = NULL_TREE */)\n+{\n+  /* The constant size of the array SRC points to.  The actual size\n+     may be less of EXACT is true, but not more.  */\n+  tree size;\n+  /* True if SRC involves a non-constant offset into the array.  */\n+  bool exact;\n+  /* The unterminated constant array SRC points to.  */\n+  tree nonstr = unterminated_array (src, &size, &exact);\n+  if (!nonstr)\n+    return true;\n+\n+  /* NONSTR refers to the non-nul terminated constant array and SIZE\n+     is the constant size of the array in bytes.  EXACT is true when\n+     SIZE is exact.  */\n+\n+  wide_int bndrng[2];\n+  if (bound)\n+    {\n+      value_range r;\n+\n+      get_global_range_query ()->range_of_expr (r, bound);\n+\n+      if (r.kind () != VR_RANGE)\n+\treturn true;\n+\n+      bndrng[0] = r.lower_bound ();\n+      bndrng[1] = r.upper_bound ();\n+\n+      if (exact)\n+\t{\n+\t  if (wi::leu_p (bndrng[0], wi::to_wide (size)))\n+\t    return true;\n+\t}\n+      else if (wi::lt_p (bndrng[0], wi::to_wide (size), UNSIGNED))\n+\treturn true;\n+    }\n+\n+  if (expr)\n+    warn_string_no_nul (EXPR_LOCATION (expr), expr, NULL, src, nonstr,\n+\t\t\tsize, exact, bound ? bndrng : NULL);\n+\n+  return false;\n+}\n+\n+/* If EXP refers to an unterminated constant character array return\n+   the declaration of the object of which the array is a member or\n+   element and if SIZE is not null, set *SIZE to the size of\n+   the unterminated array and set *EXACT if the size is exact or\n+   clear it otherwise.  Otherwise return null.  */\n+\n+tree\n+unterminated_array (tree exp, tree *size /* = NULL */, bool *exact /* = NULL */)\n+{\n+  /* C_STRLEN will return NULL and set DECL in the info\n+     structure if EXP references a unterminated array.  */\n+  c_strlen_data lendata = { };\n+  tree len = c_strlen (exp, 1, &lendata);\n+  if (len == NULL_TREE && lendata.minlen && lendata.decl)\n+     {\n+       if (size)\n+\t{\n+\t  len = lendata.minlen;\n+\t  if (lendata.off)\n+\t    {\n+\t      /* Constant offsets are already accounted for in LENDATA.MINLEN,\n+\t\t but not in a SSA_NAME + CST expression.  */\n+\t      if (TREE_CODE (lendata.off) == INTEGER_CST)\n+\t\t*exact = true;\n+\t      else if (TREE_CODE (lendata.off) == PLUS_EXPR\n+\t\t       && TREE_CODE (TREE_OPERAND (lendata.off, 1)) == INTEGER_CST)\n+\t\t{\n+\t\t  /* Subtract the offset from the size of the array.  */\n+\t\t  *exact = false;\n+\t\t  tree temp = TREE_OPERAND (lendata.off, 1);\n+\t\t  temp = fold_convert (ssizetype, temp);\n+\t\t  len = fold_build2 (MINUS_EXPR, ssizetype, len, temp);\n+\t\t}\n+\t      else\n+\t\t*exact = false;\n+\t    }\n+\t  else\n+\t    *exact = true;\n+\n+\t  *size = len;\n+\t}\n+       return lendata.decl;\n+     }\n+\n+  return NULL_TREE;\n+}\n+\n+/* Issue a warning OPT for a bounded call EXP with a bound in RANGE\n+   accessing an object with SIZE.  */\n+\n+bool\n+maybe_warn_for_bound (opt_code opt, location_t loc, tree exp, tree func,\n+\t\t      tree bndrng[2], tree size,\n+\t\t      const access_data *pad /* = NULL */)\n+{\n+  if (!bndrng[0] || warning_suppressed_p (exp, opt))\n+    return false;\n+\n+  tree maxobjsize = max_object_size ();\n+\n+  bool warned = false;\n+\n+  if (opt == OPT_Wstringop_overread)\n+    {\n+      bool maybe = pad && pad->src.phi ();\n+\n+      if (tree_int_cst_lt (maxobjsize, bndrng[0]))\n+\t{\n+\t  if (bndrng[0] == bndrng[1])\n+\t    warned = (func\n+\t\t      ? warning_at (loc, opt,\n+\t\t\t\t    (maybe\n+\t\t\t\t     ? G_(\"%qD specified bound %E may \"\n+\t\t\t\t\t  \"exceed maximum object size %E\")\n+\t\t\t\t     : G_(\"%qD specified bound %E \"\n+\t\t\t\t\t  \"exceeds maximum object size %E\")),\n+\t\t\t\t    func, bndrng[0], maxobjsize)\n+\t\t      : warning_at (loc, opt,\n+\t\t\t\t    (maybe\n+\t\t\t\t     ? G_(\"specified bound %E may \"\n+\t\t\t\t\t  \"exceed maximum object size %E\")\n+\t\t\t\t     : G_(\"specified bound %E \"\n+\t\t\t\t\t  \"exceeds maximum object size %E\")),\n+\t\t\t\t    bndrng[0], maxobjsize));\n+\t  else\n+\t    warned = (func\n+\t\t      ? warning_at (loc, opt,\n+\t\t\t\t    (maybe\n+\t\t\t\t     ? G_(\"%qD specified bound [%E, %E] may \"\n+\t\t\t\t\t  \"exceed maximum object size %E\")\n+\t\t\t\t     : G_(\"%qD specified bound [%E, %E] \"\n+\t\t\t\t\t  \"exceeds maximum object size %E\")),\n+\t\t\t\t    func,\n+\t\t\t\t    bndrng[0], bndrng[1], maxobjsize)\n+\t\t      : warning_at (loc, opt,\n+\t\t\t\t    (maybe\n+\t\t\t\t     ? G_(\"specified bound [%E, %E] may \"\n+\t\t\t\t\t  \"exceed maximum object size %E\")\n+\t\t\t\t     : G_(\"specified bound [%E, %E] \"\n+\t\t\t\t\t  \"exceeds maximum object size %E\")),\n+\t\t\t\t    bndrng[0], bndrng[1], maxobjsize));\n+\t}\n+      else if (!size || tree_int_cst_le (bndrng[0], size))\n+\treturn false;\n+      else if (tree_int_cst_equal (bndrng[0], bndrng[1]))\n+\twarned = (func\n+\t\t  ? warning_at (loc, opt,\n+\t\t\t\t(maybe\n+\t\t\t\t ? G_(\"%qD specified bound %E may exceed \"\n+\t\t\t\t      \"source size %E\")\n+\t\t\t\t : G_(\"%qD specified bound %E exceeds \"\n+\t\t\t\t      \"source size %E\")),\n+\t\t\t\tfunc, bndrng[0], size)\n+\t\t  : warning_at (loc, opt,\n+\t\t\t\t(maybe\n+\t\t\t\t ? G_(\"specified bound %E may exceed \"\n+\t\t\t\t      \"source size %E\")\n+\t\t\t\t : G_(\"specified bound %E exceeds \"\n+\t\t\t\t      \"source size %E\")),\n+\t\t\t\tbndrng[0], size));\n+      else\n+\twarned = (func\n+\t\t  ? warning_at (loc, opt,\n+\t\t\t\t(maybe\n+\t\t\t\t ? G_(\"%qD specified bound [%E, %E] may \"\n+\t\t\t\t      \"exceed source size %E\")\n+\t\t\t\t : G_(\"%qD specified bound [%E, %E] exceeds \"\n+\t\t\t\t      \"source size %E\")),\n+\t\t\t\tfunc, bndrng[0], bndrng[1], size)\n+\t\t  : warning_at (loc, opt,\n+\t\t\t\t(maybe\n+\t\t\t\t ? G_(\"specified bound [%E, %E] may exceed \"\n+\t\t\t\t      \"source size %E\")\n+\t\t\t\t : G_(\"specified bound [%E, %E] exceeds \"\n+\t\t\t\t      \"source size %E\")),\n+\t\t\t\tbndrng[0], bndrng[1], size));\n+      if (warned)\n+\t{\n+\t  if (pad && pad->src.ref)\n+\t    {\n+\t      if (DECL_P (pad->src.ref))\n+\t\tinform (DECL_SOURCE_LOCATION (pad->src.ref),\n+\t\t\t\"source object declared here\");\n+\t      else if (EXPR_HAS_LOCATION (pad->src.ref))\n+\t\tinform (EXPR_LOCATION (pad->src.ref),\n+\t\t\t\"source object allocated here\");\n+\t    }\n+\t  suppress_warning (exp, opt);\n+\t}\n+\n+      return warned;\n+    }\n+\n+  bool maybe = pad && pad->dst.phi ();\n+  if (tree_int_cst_lt (maxobjsize, bndrng[0]))\n+    {\n+      if (bndrng[0] == bndrng[1])\n+\twarned = (func\n+\t\t  ? warning_at (loc, opt,\n+\t\t\t\t(maybe\n+\t\t\t\t ? G_(\"%qD specified size %E may \"\n+\t\t\t\t      \"exceed maximum object size %E\")\n+\t\t\t\t : G_(\"%qD specified size %E \"\n+\t\t\t\t      \"exceeds maximum object size %E\")),\n+\t\t\t\tfunc, bndrng[0], maxobjsize)\n+\t\t  : warning_at (loc, opt,\n+\t\t\t\t(maybe\n+\t\t\t\t ? G_(\"specified size %E may exceed \"\n+\t\t\t\t      \"maximum object size %E\")\n+\t\t\t\t : G_(\"specified size %E exceeds \"\n+\t\t\t\t      \"maximum object size %E\")),\n+\t\t\t\tbndrng[0], maxobjsize));\n+      else\n+\twarned = (func\n+\t\t  ? warning_at (loc, opt,\n+\t\t\t\t(maybe\n+\t\t\t\t ? G_(\"%qD specified size between %E and %E \"\n+\t\t\t\t      \"may exceed maximum object size %E\")\n+\t\t\t\t : G_(\"%qD specified size between %E and %E \"\n+\t\t\t\t      \"exceeds maximum object size %E\")),\n+\t\t\t\tfunc, bndrng[0], bndrng[1], maxobjsize)\n+\t\t  : warning_at (loc, opt,\n+\t\t\t\t(maybe\n+\t\t\t\t ? G_(\"specified size between %E and %E \"\n+\t\t\t\t      \"may exceed maximum object size %E\")\n+\t\t\t\t : G_(\"specified size between %E and %E \"\n+\t\t\t\t      \"exceeds maximum object size %E\")),\n+\t\t\t\tbndrng[0], bndrng[1], maxobjsize));\n+    }\n+  else if (!size || tree_int_cst_le (bndrng[0], size))\n+    return false;\n+  else if (tree_int_cst_equal (bndrng[0], bndrng[1]))\n+    warned = (func\n+\t      ? warning_at (loc, opt,\n+\t\t\t    (maybe\n+\t\t\t     ? G_(\"%qD specified bound %E may exceed \"\n+\t\t\t\t  \"destination size %E\")\n+\t\t\t     : G_(\"%qD specified bound %E exceeds \"\n+\t\t\t\t  \"destination size %E\")),\n+\t\t\t    func, bndrng[0], size)\n+\t      : warning_at (loc, opt,\n+\t\t\t    (maybe\n+\t\t\t     ? G_(\"specified bound %E may exceed \"\n+\t\t\t\t  \"destination size %E\")\n+\t\t\t     : G_(\"specified bound %E exceeds \"\n+\t\t\t\t  \"destination size %E\")),\n+\t\t\t    bndrng[0], size));\n+  else\n+    warned = (func\n+\t      ? warning_at (loc, opt,\n+\t\t\t    (maybe\n+\t\t\t     ? G_(\"%qD specified bound [%E, %E] may exceed \"\n+\t\t\t\t  \"destination size %E\")\n+\t\t\t     : G_(\"%qD specified bound [%E, %E] exceeds \"\n+\t\t\t\t  \"destination size %E\")),\n+\t\t\t    func, bndrng[0], bndrng[1], size)\n+\t      : warning_at (loc, opt,\n+\t\t\t    (maybe\n+\t\t\t     ? G_(\"specified bound [%E, %E] exceeds \"\n+\t\t\t\t  \"destination size %E\")\n+\t\t\t     : G_(\"specified bound [%E, %E] exceeds \"\n+\t\t\t\t  \"destination size %E\")),\n+\t\t\t    bndrng[0], bndrng[1], size));\n+\n+  if (warned)\n+    {\n+      if (pad && pad->dst.ref)\n+\t{\n+\t  if (DECL_P (pad->dst.ref))\n+\t    inform (DECL_SOURCE_LOCATION (pad->dst.ref),\n+\t\t    \"destination object declared here\");\n+\t  else if (EXPR_HAS_LOCATION (pad->dst.ref))\n+\t    inform (EXPR_LOCATION (pad->dst.ref),\n+\t\t    \"destination object allocated here\");\n+\t}\n+      suppress_warning (exp, opt);\n+    }\n+\n+  return warned;\n+}\n+\n+/* For an expression EXP issue an access warning controlled by option OPT\n+   with access to a region SIZE bytes in size in the RANGE of sizes.\n+   WRITE is true for a write access, READ for a read access, neither for\n+   call that may or may not perform an access but for which the range\n+   is expected to valid.\n+   Returns true when a warning has been issued.  */\n+\n+static bool\n+warn_for_access (location_t loc, tree func, tree exp, int opt, tree range[2],\n+\t\t tree size, bool write, bool read, bool maybe)\n+{\n+  bool warned = false;\n+\n+  if (write && read)\n+    {\n+      if (tree_int_cst_equal (range[0], range[1]))\n+\twarned = (func\n+\t\t  ? warning_n (loc, opt, tree_to_uhwi (range[0]),\n+\t\t\t       (maybe\n+\t\t\t\t? G_(\"%qD may access %E byte in a region \"\n+\t\t\t\t     \"of size %E\")\n+\t\t\t\t: G_(\"%qD accessing %E byte in a region \"\n+\t\t\t\t     \"of size %E\")),\n+\t\t\t\t(maybe\n+\t\t\t\t ? G_ (\"%qD may access %E bytes in a region \"\n+\t\t\t\t       \"of size %E\")\n+\t\t\t\t : G_ (\"%qD accessing %E bytes in a region \"\n+\t\t\t\t       \"of size %E\")),\n+\t\t\t       func, range[0], size)\n+\t\t  : warning_n (loc, opt, tree_to_uhwi (range[0]),\n+\t\t\t       (maybe\n+\t\t\t\t? G_(\"may access %E byte in a region \"\n+\t\t\t\t     \"of size %E\")\n+\t\t\t\t: G_(\"accessing %E byte in a region \"\n+\t\t\t\t     \"of size %E\")),\n+\t\t\t       (maybe\n+\t\t\t\t? G_(\"may access %E bytes in a region \"\n+\t\t\t\t     \"of size %E\")\n+\t\t\t\t: G_(\"accessing %E bytes in a region \"\n+\t\t\t\t     \"of size %E\")),\n+\t\t\t       range[0], size));\n+      else if (tree_int_cst_sign_bit (range[1]))\n+\t{\n+\t  /* Avoid printing the upper bound if it's invalid.  */\n+\t  warned = (func\n+\t\t    ? warning_at (loc, opt,\n+\t\t\t\t  (maybe\n+\t\t\t\t   ? G_(\"%qD may access %E or more bytes \"\n+\t\t\t\t\t\"in a region of size %E\")\n+\t\t\t\t   : G_(\"%qD accessing %E or more bytes \"\n+\t\t\t\t\t\"in a region of size %E\")),\n+\t\t\t\t  func, range[0], size)\n+\t\t    : warning_at (loc, opt,\n+\t\t\t\t  (maybe\n+\t\t\t\t   ? G_(\"may access %E or more bytes \"\n+\t\t\t\t\t\"in a region of size %E\")\n+\t\t\t\t   : G_(\"accessing %E or more bytes \"\n+\t\t\t\t\t\"in a region of size %E\")),\n+\t\t\t\t  range[0], size));\n+\t}\n+      else\n+\twarned = (func\n+\t\t  ? warning_at (loc, opt,\n+\t\t\t\t(maybe\n+\t\t\t\t ? G_(\"%qD may access between %E and %E \"\n+\t\t\t\t      \"bytes in a region of size %E\")\n+\t\t\t\t : G_(\"%qD accessing between %E and %E \"\n+\t\t\t\t      \"bytes in a region of size %E\")),\n+\t\t\t\tfunc, range[0], range[1], size)\n+\t\t  : warning_at (loc, opt,\n+\t\t\t\t(maybe\n+\t\t\t\t ? G_(\"may access between %E and %E bytes \"\n+\t\t\t\t      \"in a region of size %E\")\n+\t\t\t\t : G_(\"accessing between %E and %E bytes \"\n+\t\t\t\t      \"in a region of size %E\")),\n+\t\t\t\trange[0], range[1], size));\n+      return warned;\n+    }\n+\n+  if (write)\n+    {\n+      if (tree_int_cst_equal (range[0], range[1]))\n+\twarned = (func\n+\t\t  ? warning_n (loc, opt, tree_to_uhwi (range[0]),\n+\t\t\t       (maybe\n+\t\t\t\t? G_(\"%qD may write %E byte into a region \"\n+\t\t\t\t     \"of size %E\")\n+\t\t\t\t: G_(\"%qD writing %E byte into a region \"\n+\t\t\t\t     \"of size %E overflows the destination\")),\n+\t\t\t       (maybe\n+\t\t\t\t? G_(\"%qD may write %E bytes into a region \"\n+\t\t\t\t     \"of size %E\")\n+\t\t\t\t: G_(\"%qD writing %E bytes into a region \"\n+\t\t\t\t     \"of size %E overflows the destination\")),\n+\t\t\t       func, range[0], size)\n+\t\t  : warning_n (loc, opt, tree_to_uhwi (range[0]),\n+\t\t\t       (maybe\n+\t\t\t\t? G_(\"may write %E byte into a region \"\n+\t\t\t\t     \"of size %E\")\n+\t\t\t\t: G_(\"writing %E byte into a region \"\n+\t\t\t\t     \"of size %E overflows the destination\")),\n+\t\t\t       (maybe\n+\t\t\t\t? G_(\"may write %E bytes into a region \"\n+\t\t\t\t     \"of size %E\")\n+\t\t\t\t: G_(\"writing %E bytes into a region \"\n+\t\t\t\t     \"of size %E overflows the destination\")),\n+\t\t\t       range[0], size));\n+      else if (tree_int_cst_sign_bit (range[1]))\n+\t{\n+\t  /* Avoid printing the upper bound if it's invalid.  */\n+\t  warned = (func\n+\t\t    ? warning_at (loc, opt,\n+\t\t\t\t  (maybe\n+\t\t\t\t   ? G_(\"%qD may write %E or more bytes \"\n+\t\t\t\t\t\"into a region of size %E\")\n+\t\t\t\t   : G_(\"%qD writing %E or more bytes \"\n+\t\t\t\t\t\"into a region of size %E overflows \"\n+\t\t\t\t\t\"the destination\")),\n+\t\t\t\t  func, range[0], size)\n+\t\t    : warning_at (loc, opt,\n+\t\t\t\t  (maybe\n+\t\t\t\t   ? G_(\"may write %E or more bytes into \"\n+\t\t\t\t\t\"a region of size %E\")\n+\t\t\t\t   : G_(\"writing %E or more bytes into \"\n+\t\t\t\t\t\"a region of size %E overflows \"\n+\t\t\t\t\t\"the destination\")),\n+\t\t\t\t  range[0], size));\n+\t}\n+      else\n+\twarned = (func\n+\t\t  ? warning_at (loc, opt,\n+\t\t\t\t(maybe\n+\t\t\t\t ? G_(\"%qD may write between %E and %E bytes \"\n+\t\t\t\t      \"into a region of size %E\")\n+\t\t\t\t : G_(\"%qD writing between %E and %E bytes \"\n+\t\t\t\t      \"into a region of size %E overflows \"\n+\t\t\t\t      \"the destination\")),\n+\t\t\t\tfunc, range[0], range[1], size)\n+\t\t  : warning_at (loc, opt,\n+\t\t\t\t(maybe\n+\t\t\t\t ? G_(\"may write between %E and %E bytes \"\n+\t\t\t\t      \"into a region of size %E\")\n+\t\t\t\t : G_(\"writing between %E and %E bytes \"\n+\t\t\t\t      \"into a region of size %E overflows \"\n+\t\t\t\t      \"the destination\")),\n+\t\t\t\trange[0], range[1], size));\n+      return warned;\n+    }\n+\n+  if (read)\n+    {\n+      if (tree_int_cst_equal (range[0], range[1]))\n+\twarned = (func\n+\t\t  ? warning_n (loc, OPT_Wstringop_overread,\n+\t\t\t       tree_to_uhwi (range[0]),\n+\t\t\t       (maybe\n+\t\t\t\t? G_(\"%qD may read %E byte from a region \"\n+\t\t\t\t     \"of size %E\")\n+\t\t\t\t: G_(\"%qD reading %E byte from a region \"\n+\t\t\t\t     \"of size %E\")),\n+\t\t\t       (maybe\n+\t\t\t\t? G_(\"%qD may read %E bytes from a region \"\n+\t\t\t\t     \"of size %E\")\n+\t\t\t\t: G_(\"%qD reading %E bytes from a region \"\n+\t\t\t\t     \"of size %E\")),\n+\t\t\t       func, range[0], size)\n+\t\t  : warning_n (loc, OPT_Wstringop_overread,\n+\t\t\t       tree_to_uhwi (range[0]),\n+\t\t\t       (maybe\n+\t\t\t\t? G_(\"may read %E byte from a region \"\n+\t\t\t\t     \"of size %E\")\n+\t\t\t\t: G_(\"reading %E byte from a region \"\n+\t\t\t\t     \"of size %E\")),\n+\t\t\t       (maybe\n+\t\t\t\t? G_(\"may read %E bytes from a region \"\n+\t\t\t\t     \"of size %E\")\n+\t\t\t\t: G_(\"reading %E bytes from a region \"\n+\t\t\t\t     \"of size %E\")),\n+\t\t\t       range[0], size));\n+      else if (tree_int_cst_sign_bit (range[1]))\n+\t{\n+\t  /* Avoid printing the upper bound if it's invalid.  */\n+\t  warned = (func\n+\t\t    ? warning_at (loc, OPT_Wstringop_overread,\n+\t\t\t\t  (maybe\n+\t\t\t\t   ? G_(\"%qD may read %E or more bytes \"\n+\t\t\t\t\t\"from a region of size %E\")\n+\t\t\t\t   : G_(\"%qD reading %E or more bytes \"\n+\t\t\t\t\t\"from a region of size %E\")),\n+\t\t\t\t  func, range[0], size)\n+\t\t    : warning_at (loc, OPT_Wstringop_overread,\n+\t\t\t\t  (maybe\n+\t\t\t\t   ? G_(\"may read %E or more bytes \"\n+\t\t\t\t\t\"from a region of size %E\")\n+\t\t\t\t   : G_(\"reading %E or more bytes \"\n+\t\t\t\t\t\"from a region of size %E\")),\n+\t\t\t\t  range[0], size));\n+\t}\n+      else\n+\twarned = (func\n+\t\t  ? warning_at (loc, OPT_Wstringop_overread,\n+\t\t\t\t(maybe\n+\t\t\t\t ? G_(\"%qD may read between %E and %E bytes \"\n+\t\t\t\t      \"from a region of size %E\")\n+\t\t\t\t : G_(\"%qD reading between %E and %E bytes \"\n+\t\t\t\t      \"from a region of size %E\")),\n+\t\t\t\tfunc, range[0], range[1], size)\n+\t\t  : warning_at (loc, opt,\n+\t\t\t\t(maybe\n+\t\t\t\t ? G_(\"may read between %E and %E bytes \"\n+\t\t\t\t      \"from a region of size %E\")\n+\t\t\t\t : G_(\"reading between %E and %E bytes \"\n+\t\t\t\t      \"from a region of size %E\")),\n+\t\t\t\trange[0], range[1], size));\n+\n+      if (warned)\n+\tsuppress_warning (exp, OPT_Wstringop_overread);\n+\n+      return warned;\n+    }\n+\n+  if (tree_int_cst_equal (range[0], range[1])\n+      || tree_int_cst_sign_bit (range[1]))\n+    warned = (func\n+\t      ? warning_n (loc, OPT_Wstringop_overread,\n+\t\t\t   tree_to_uhwi (range[0]),\n+\t\t\t   \"%qD expecting %E byte in a region of size %E\",\n+\t\t\t   \"%qD expecting %E bytes in a region of size %E\",\n+\t\t\t   func, range[0], size)\n+\t      : warning_n (loc, OPT_Wstringop_overread,\n+\t\t\t   tree_to_uhwi (range[0]),\n+\t\t\t   \"expecting %E byte in a region of size %E\",\n+\t\t\t   \"expecting %E bytes in a region of size %E\",\n+\t\t\t   range[0], size));\n+  else if (tree_int_cst_sign_bit (range[1]))\n+    {\n+      /* Avoid printing the upper bound if it's invalid.  */\n+      warned = (func\n+\t\t? warning_at (loc, OPT_Wstringop_overread,\n+\t\t\t      \"%qD expecting %E or more bytes in a region \"\n+\t\t\t      \"of size %E\",\n+\t\t\t      func, range[0], size)\n+\t\t: warning_at (loc, OPT_Wstringop_overread,\n+\t\t\t      \"expecting %E or more bytes in a region \"\n+\t\t\t      \"of size %E\",\n+\t\t\t      range[0], size));\n+    }\n+  else\n+    warned = (func\n+\t      ? warning_at (loc, OPT_Wstringop_overread,\n+\t\t\t    \"%qD expecting between %E and %E bytes in \"\n+\t\t\t    \"a region of size %E\",\n+\t\t\t    func, range[0], range[1], size)\n+\t      : warning_at (loc, OPT_Wstringop_overread,\n+\t\t\t    \"expecting between %E and %E bytes in \"\n+\t\t\t    \"a region of size %E\",\n+\t\t\t    range[0], range[1], size));\n+\n+  if (warned)\n+    suppress_warning (exp, OPT_Wstringop_overread);\n+\n+  return warned;\n+}\n+\n+/* Helper to set RANGE to the range of BOUND if it's nonnull, bounded\n+   by BNDRNG if nonnull and valid.  */\n+\n+void\n+get_size_range (tree bound, tree range[2], const offset_int bndrng[2])\n+{\n+  if (bound)\n+    get_size_range (bound, range);\n+\n+  if (!bndrng || (bndrng[0] == 0 && bndrng[1] == HOST_WIDE_INT_M1U))\n+    return;\n+\n+  if (range[0] && TREE_CODE (range[0]) == INTEGER_CST)\n+    {\n+      offset_int r[] =\n+\t{ wi::to_offset (range[0]), wi::to_offset (range[1]) };\n+      if (r[0] < bndrng[0])\n+\trange[0] = wide_int_to_tree (sizetype, bndrng[0]);\n+      if (bndrng[1] < r[1])\n+\trange[1] = wide_int_to_tree (sizetype, bndrng[1]);\n+    }\n+  else\n+    {\n+      range[0] = wide_int_to_tree (sizetype, bndrng[0]);\n+      range[1] = wide_int_to_tree (sizetype, bndrng[1]);\n+    }\n+}\n+\n+/* Try to verify that the sizes and lengths of the arguments to a string\n+   manipulation function given by EXP are within valid bounds and that\n+   the operation does not lead to buffer overflow or read past the end.\n+   Arguments other than EXP may be null.  When non-null, the arguments\n+   have the following meaning:\n+   DST is the destination of a copy call or NULL otherwise.\n+   SRC is the source of a copy call or NULL otherwise.\n+   DSTWRITE is the number of bytes written into the destination obtained\n+   from the user-supplied size argument to the function (such as in\n+   memcpy(DST, SRCs, DSTWRITE) or strncpy(DST, DRC, DSTWRITE).\n+   MAXREAD is the user-supplied bound on the length of the source sequence\n+   (such as in strncat(d, s, N).  It specifies the upper limit on the number\n+   of bytes to write.  If NULL, it's taken to be the same as DSTWRITE.\n+   SRCSTR is the source string (such as in strcpy(DST, SRC)) when the\n+   expression EXP is a string function call (as opposed to a memory call\n+   like memcpy).  As an exception, SRCSTR can also be an integer denoting\n+   the precomputed size of the source string or object (for functions like\n+   memcpy).\n+   DSTSIZE is the size of the destination object.\n+\n+   When DSTWRITE is null LEN is checked to verify that it doesn't exceed\n+   SIZE_MAX.\n+\n+   WRITE is true for write accesses, READ is true for reads.  Both are\n+   false for simple size checks in calls to functions that neither read\n+   from nor write to the region.\n+\n+   When nonnull, PAD points to a more detailed description of the access.\n+\n+   If the call is successfully verified as safe return true, otherwise\n+   return false.  */\n+\n+bool\n+check_access (tree exp, tree dstwrite,\n+\t      tree maxread, tree srcstr, tree dstsize,\n+\t      access_mode mode, const access_data *pad /* = NULL */)\n+{\n+  /* The size of the largest object is half the address space, or\n+     PTRDIFF_MAX.  (This is way too permissive.)  */\n+  tree maxobjsize = max_object_size ();\n+\n+  /* Either an approximate/minimum the length of the source string for\n+     string functions or the size of the source object for raw memory\n+     functions.  */\n+  tree slen = NULL_TREE;\n+\n+  /* The range of the access in bytes; first set to the write access\n+     for functions that write and then read for those that also (or\n+     just) read.  */\n+  tree range[2] = { NULL_TREE, NULL_TREE };\n+\n+  /* Set to true when the exact number of bytes written by a string\n+     function like strcpy is not known and the only thing that is\n+     known is that it must be at least one (for the terminating nul).  */\n+  bool at_least_one = false;\n+  if (srcstr)\n+    {\n+      /* SRCSTR is normally a pointer to string but as a special case\n+\t it can be an integer denoting the length of a string.  */\n+      if (POINTER_TYPE_P (TREE_TYPE (srcstr)))\n+\t{\n+\t  if (!check_nul_terminated_array (exp, srcstr, maxread))\n+\t    return false;\n+\t  /* Try to determine the range of lengths the source string\n+\t     refers to.  If it can be determined and is less than\n+\t     the upper bound given by MAXREAD add one to it for\n+\t     the terminating nul.  Otherwise, set it to one for\n+\t     the same reason, or to MAXREAD as appropriate.  */\n+\t  c_strlen_data lendata = { };\n+\t  get_range_strlen (srcstr, &lendata, /* eltsize = */ 1);\n+\t  range[0] = lendata.minlen;\n+\t  range[1] = lendata.maxbound ? lendata.maxbound : lendata.maxlen;\n+\t  if (range[0]\n+\t      && TREE_CODE (range[0]) == INTEGER_CST\n+\t      && TREE_CODE (range[1]) == INTEGER_CST\n+\t      && (!maxread || TREE_CODE (maxread) == INTEGER_CST))\n+\t    {\n+\t      if (maxread && tree_int_cst_le (maxread, range[0]))\n+\t\trange[0] = range[1] = maxread;\n+\t      else\n+\t\trange[0] = fold_build2 (PLUS_EXPR, size_type_node,\n+\t\t\t\t\trange[0], size_one_node);\n+\n+\t      if (maxread && tree_int_cst_le (maxread, range[1]))\n+\t\trange[1] = maxread;\n+\t      else if (!integer_all_onesp (range[1]))\n+\t\trange[1] = fold_build2 (PLUS_EXPR, size_type_node,\n+\t\t\t\t\trange[1], size_one_node);\n+\n+\t      slen = range[0];\n+\t    }\n+\t  else\n+\t    {\n+\t      at_least_one = true;\n+\t      slen = size_one_node;\n+\t    }\n+\t}\n+      else\n+\tslen = srcstr;\n+    }\n+\n+  if (!dstwrite && !maxread)\n+    {\n+      /* When the only available piece of data is the object size\n+\t there is nothing to do.  */\n+      if (!slen)\n+\treturn true;\n+\n+      /* Otherwise, when the length of the source sequence is known\n+\t (as with strlen), set DSTWRITE to it.  */\n+      if (!range[0])\n+\tdstwrite = slen;\n+    }\n+\n+  if (!dstsize)\n+    dstsize = maxobjsize;\n+\n+  /* Set RANGE to that of DSTWRITE if non-null, bounded by PAD->DST.BNDRNG\n+     if valid.  */\n+  get_size_range (dstwrite, range, pad ? pad->dst.bndrng : NULL);\n+\n+  tree func = get_callee_fndecl (exp);\n+  /* Read vs write access by built-ins can be determined from the const\n+     qualifiers on the pointer argument.  In the absence of attribute\n+     access, non-const qualified pointer arguments to user-defined\n+     functions are assumed to both read and write the objects.  */\n+  const bool builtin = func ? fndecl_built_in_p (func) : false;\n+\n+  /* First check the number of bytes to be written against the maximum\n+     object size.  */\n+  if (range[0]\n+      && TREE_CODE (range[0]) == INTEGER_CST\n+      && tree_int_cst_lt (maxobjsize, range[0]))\n+    {\n+      location_t loc = EXPR_LOCATION (exp);\n+      maybe_warn_for_bound (OPT_Wstringop_overflow_, loc, exp, func, range,\n+\t\t\t    NULL_TREE, pad);\n+      return false;\n+    }\n+\n+  /* The number of bytes to write is \"exact\" if DSTWRITE is non-null,\n+     constant, and in range of unsigned HOST_WIDE_INT.  */\n+  bool exactwrite = dstwrite && tree_fits_uhwi_p (dstwrite);\n+\n+  /* Next check the number of bytes to be written against the destination\n+     object size.  */\n+  if (range[0] || !exactwrite || integer_all_onesp (dstwrite))\n+    {\n+      if (range[0]\n+\t  && TREE_CODE (range[0]) == INTEGER_CST\n+\t  && ((tree_fits_uhwi_p (dstsize)\n+\t       && tree_int_cst_lt (dstsize, range[0]))\n+\t      || (dstwrite\n+\t\t  && tree_fits_uhwi_p (dstwrite)\n+\t\t  && tree_int_cst_lt (dstwrite, range[0]))))\n+\t{\n+\t  const opt_code opt = OPT_Wstringop_overflow_;\n+\t  if (warning_suppressed_p (exp, opt)\n+\t      || (pad && pad->dst.ref\n+\t\t  && warning_suppressed_p (pad->dst.ref, opt)))\n+\t    return false;\n+\n+\t  location_t loc = EXPR_LOCATION (exp);\n+\t  bool warned = false;\n+\t  if (dstwrite == slen && at_least_one)\n+\t    {\n+\t      /* This is a call to strcpy with a destination of 0 size\n+\t\t and a source of unknown length.  The call will write\n+\t\t at least one byte past the end of the destination.  */\n+\t      warned = (func\n+\t\t\t? warning_at (loc, opt,\n+\t\t\t\t      \"%qD writing %E or more bytes into \"\n+\t\t\t\t      \"a region of size %E overflows \"\n+\t\t\t\t      \"the destination\",\n+\t\t\t\t      func, range[0], dstsize)\n+\t\t\t: warning_at (loc, opt,\n+\t\t\t\t      \"writing %E or more bytes into \"\n+\t\t\t\t      \"a region of size %E overflows \"\n+\t\t\t\t      \"the destination\",\n+\t\t\t\t      range[0], dstsize));\n+\t    }\n+\t  else\n+\t    {\n+\t      const bool read\n+\t\t= mode == access_read_only || mode == access_read_write;\n+\t      const bool write\n+\t\t= mode == access_write_only || mode == access_read_write;\n+\t      const bool maybe = pad && pad->dst.parmarray;\n+\t      warned = warn_for_access (loc, func, exp,\n+\t\t\t\t\tOPT_Wstringop_overflow_,\n+\t\t\t\t\trange, dstsize,\n+\t\t\t\t\twrite, read && !builtin, maybe);\n+\t    }\n+\n+\t  if (warned)\n+\t    {\n+\t      suppress_warning (exp, OPT_Wstringop_overflow_);\n+\t      if (pad)\n+\t\tpad->dst.inform_access (pad->mode);\n+\t    }\n+\n+\t  /* Return error when an overflow has been detected.  */\n+\t  return false;\n+\t}\n+    }\n+\n+  /* Check the maximum length of the source sequence against the size\n+     of the destination object if known, or against the maximum size\n+     of an object.  */\n+  if (maxread)\n+    {\n+      /* Set RANGE to that of MAXREAD, bounded by PAD->SRC.BNDRNG if\n+\t PAD is nonnull and BNDRNG is valid.  */\n+      get_size_range (maxread, range, pad ? pad->src.bndrng : NULL);\n+\n+      location_t loc = EXPR_LOCATION (exp);\n+      tree size = dstsize;\n+      if (pad && pad->mode == access_read_only)\n+\tsize = wide_int_to_tree (sizetype, pad->src.sizrng[1]);\n+\n+      if (range[0] && maxread && tree_fits_uhwi_p (size))\n+\t{\n+\t  if (tree_int_cst_lt (maxobjsize, range[0]))\n+\t    {\n+\t      maybe_warn_for_bound (OPT_Wstringop_overread, loc, exp, func,\n+\t\t\t\t    range, size, pad);\n+\t      return false;\n+\t    }\n+\n+\t  if (size != maxobjsize && tree_int_cst_lt (size, range[0]))\n+\t    {\n+\t      opt_code opt = (dstwrite || mode != access_read_only\n+\t\t\t      ? OPT_Wstringop_overflow_\n+\t\t\t      : OPT_Wstringop_overread);\n+\t      maybe_warn_for_bound (opt, loc, exp, func, range, size, pad);\n+\t      return false;\n+\t    }\n+\t}\n+\n+      maybe_warn_nonstring_arg (func, exp);\n+    }\n+\n+  /* Check for reading past the end of SRC.  */\n+  bool overread = (slen\n+\t\t   && slen == srcstr\n+\t\t   && dstwrite\n+\t\t   && range[0]\n+\t\t   && TREE_CODE (slen) == INTEGER_CST\n+\t\t   && tree_int_cst_lt (slen, range[0]));\n+  /* If none is determined try to get a better answer based on the details\n+     in PAD.  */\n+  if (!overread\n+      && pad\n+      && pad->src.sizrng[1] >= 0\n+      && pad->src.offrng[0] >= 0\n+      && (pad->src.offrng[1] < 0\n+\t  || pad->src.offrng[0] <= pad->src.offrng[1]))\n+    {\n+      /* Set RANGE to that of MAXREAD, bounded by PAD->SRC.BNDRNG if\n+\t PAD is nonnull and BNDRNG is valid.  */\n+      get_size_range (maxread, range, pad ? pad->src.bndrng : NULL);\n+      /* Set OVERREAD for reads starting just past the end of an object.  */\n+      overread = pad->src.sizrng[1] - pad->src.offrng[0] < pad->src.bndrng[0];\n+      range[0] = wide_int_to_tree (sizetype, pad->src.bndrng[0]);\n+      slen = size_zero_node;\n+    }\n+\n+  if (overread)\n+    {\n+      const opt_code opt = OPT_Wstringop_overread;\n+      if (warning_suppressed_p (exp, opt)\n+\t  || (srcstr && warning_suppressed_p (srcstr, opt))\n+\t  || (pad && pad->src.ref\n+\t      && warning_suppressed_p (pad->src.ref, opt)))\n+\treturn false;\n+\n+      location_t loc = EXPR_LOCATION (exp);\n+      const bool read\n+\t= mode == access_read_only || mode == access_read_write;\n+      const bool maybe = pad && pad->dst.parmarray;\n+      if (warn_for_access (loc, func, exp, opt, range, slen, false, read,\n+\t\t\t   maybe))\n+\t{\n+\t  suppress_warning (exp, opt);\n+\t  if (pad)\n+\t    pad->src.inform_access (access_read_only);\n+\t}\n+      return false;\n+    }\n+\n+  return true;\n+}\n+\n+/* Return true if STMT is a call to an allocation function.  Unless\n+   ALL_ALLOC is set, consider only functions that return dynmamically\n+   allocated objects.  Otherwise return true even for all forms of\n+   alloca (including VLA).  */\n+\n+static bool\n+fndecl_alloc_p (tree fndecl, bool all_alloc)\n+{\n+  if (!fndecl)\n+    return false;\n+\n+  /* A call to operator new isn't recognized as one to a built-in.  */\n+  if (DECL_IS_OPERATOR_NEW_P (fndecl))\n+    return true;\n+\n+  if (fndecl_built_in_p (fndecl, BUILT_IN_NORMAL))\n+    {\n+      switch (DECL_FUNCTION_CODE (fndecl))\n+\t{\n+\tcase BUILT_IN_ALLOCA:\n+\tcase BUILT_IN_ALLOCA_WITH_ALIGN:\n+\t  return all_alloc;\n+\tcase BUILT_IN_ALIGNED_ALLOC:\n+\tcase BUILT_IN_CALLOC:\n+\tcase BUILT_IN_GOMP_ALLOC:\n+\tcase BUILT_IN_MALLOC:\n+\tcase BUILT_IN_REALLOC:\n+\tcase BUILT_IN_STRDUP:\n+\tcase BUILT_IN_STRNDUP:\n+\t  return true;\n+\tdefault:\n+\t  break;\n+\t}\n+    }\n+\n+  /* A function is considered an allocation function if it's declared\n+     with attribute malloc with an argument naming its associated\n+     deallocation function.  */\n+  tree attrs = DECL_ATTRIBUTES (fndecl);\n+  if (!attrs)\n+    return false;\n+\n+  for (tree allocs = attrs;\n+       (allocs = lookup_attribute (\"malloc\", allocs));\n+       allocs = TREE_CHAIN (allocs))\n+    {\n+      tree args = TREE_VALUE (allocs);\n+      if (!args)\n+\tcontinue;\n+\n+      if (TREE_VALUE (args))\n+\treturn true;\n+    }\n+\n+  return false;\n+}\n+\n+/* Return true if STMT is a call to an allocation function.  A wrapper\n+   around fndecl_alloc_p.  */\n+\n+static bool\n+gimple_call_alloc_p (gimple *stmt, bool all_alloc = false)\n+{\n+  return fndecl_alloc_p (gimple_call_fndecl (stmt), all_alloc);\n+}\n+\n+/* Return true if DELC doesn't refer to an operator delete that's\n+   suitable to call with a pointer returned from the operator new\n+   described by NEWC.  */\n+\n+static bool\n+new_delete_mismatch_p (const demangle_component &newc,\n+\t\t       const demangle_component &delc)\n+{\n+  if (newc.type != delc.type)\n+    return true;\n+\n+  switch (newc.type)\n+    {\n+    case DEMANGLE_COMPONENT_NAME:\n+      {\n+\tint len = newc.u.s_name.len;\n+\tconst char *news = newc.u.s_name.s;\n+\tconst char *dels = delc.u.s_name.s;\n+\tif (len != delc.u.s_name.len || memcmp (news, dels, len))\n+\t  return true;\n+\n+\tif (news[len] == 'n')\n+\t  {\n+\t    if (news[len + 1] == 'a')\n+\t      return dels[len] != 'd' || dels[len + 1] != 'a';\n+\t    if (news[len + 1] == 'w')\n+\t      return dels[len] != 'd' || dels[len + 1] != 'l';\n+\t  }\n+\treturn false;\n+      }\n+\n+    case DEMANGLE_COMPONENT_OPERATOR:\n+      /* Operator mismatches are handled above.  */\n+      return false;\n+\n+    case DEMANGLE_COMPONENT_EXTENDED_OPERATOR:\n+      if (newc.u.s_extended_operator.args != delc.u.s_extended_operator.args)\n+\treturn true;\n+      return new_delete_mismatch_p (*newc.u.s_extended_operator.name,\n+\t\t\t\t    *delc.u.s_extended_operator.name);\n+\n+    case DEMANGLE_COMPONENT_FIXED_TYPE:\n+      if (newc.u.s_fixed.accum != delc.u.s_fixed.accum\n+\t  || newc.u.s_fixed.sat != delc.u.s_fixed.sat)\n+\treturn true;\n+      return new_delete_mismatch_p (*newc.u.s_fixed.length,\n+\t\t\t\t    *delc.u.s_fixed.length);\n+\n+    case DEMANGLE_COMPONENT_CTOR:\n+      if (newc.u.s_ctor.kind != delc.u.s_ctor.kind)\n+\treturn true;\n+      return new_delete_mismatch_p (*newc.u.s_ctor.name,\n+\t\t\t\t    *delc.u.s_ctor.name);\n+\n+    case DEMANGLE_COMPONENT_DTOR:\n+      if (newc.u.s_dtor.kind != delc.u.s_dtor.kind)\n+\treturn true;\n+      return new_delete_mismatch_p (*newc.u.s_dtor.name,\n+\t\t\t\t    *delc.u.s_dtor.name);\n+\n+    case DEMANGLE_COMPONENT_BUILTIN_TYPE:\n+      {\n+\t/* The demangler API provides no better way to compare built-in\n+\t   types except to by comparing their demangled names. */\n+\tsize_t nsz, dsz;\n+\tdemangle_component *pnc = const_cast<demangle_component *>(&newc);\n+\tdemangle_component *pdc = const_cast<demangle_component *>(&delc);\n+\tchar *nts = cplus_demangle_print (0, pnc, 16, &nsz);\n+\tchar *dts = cplus_demangle_print (0, pdc, 16, &dsz);\n+\tif (!nts != !dts)\n+\t  return true;\n+\tbool mismatch = strcmp (nts, dts);\n+\tfree (nts);\n+\tfree (dts);\n+\treturn mismatch;\n+      }\n+\n+    case DEMANGLE_COMPONENT_SUB_STD:\n+      if (newc.u.s_string.len != delc.u.s_string.len)\n+\treturn true;\n+      return memcmp (newc.u.s_string.string, delc.u.s_string.string,\n+\t\t     newc.u.s_string.len);\n+\n+    case DEMANGLE_COMPONENT_FUNCTION_PARAM:\n+    case DEMANGLE_COMPONENT_TEMPLATE_PARAM:\n+      return newc.u.s_number.number != delc.u.s_number.number;\n+\n+    case DEMANGLE_COMPONENT_CHARACTER:\n+      return newc.u.s_character.character != delc.u.s_character.character;\n+\n+    case DEMANGLE_COMPONENT_DEFAULT_ARG:\n+    case DEMANGLE_COMPONENT_LAMBDA:\n+      if (newc.u.s_unary_num.num != delc.u.s_unary_num.num)\n+\treturn true;\n+      return new_delete_mismatch_p (*newc.u.s_unary_num.sub,\n+\t\t\t\t    *delc.u.s_unary_num.sub);\n+    default:\n+      break;\n+    }\n+\n+  if (!newc.u.s_binary.left != !delc.u.s_binary.left)\n+    return true;\n+\n+  if (!newc.u.s_binary.left)\n+    return false;\n+\n+  if (new_delete_mismatch_p (*newc.u.s_binary.left, *delc.u.s_binary.left)\n+      || !newc.u.s_binary.right != !delc.u.s_binary.right)\n+    return true;\n+\n+  if (newc.u.s_binary.right)\n+    return new_delete_mismatch_p (*newc.u.s_binary.right,\n+\t\t\t\t  *delc.u.s_binary.right);\n+  return false;\n+}\n+\n+/* Return true if DELETE_DECL is an operator delete that's not suitable\n+   to call with a pointer returned fron NEW_DECL.  */\n+\n+static bool\n+new_delete_mismatch_p (tree new_decl, tree delete_decl)\n+{\n+  tree new_name = DECL_ASSEMBLER_NAME (new_decl);\n+  tree delete_name = DECL_ASSEMBLER_NAME (delete_decl);\n+\n+  /* valid_new_delete_pair_p() returns a conservative result (currently\n+     it only handles global operators).  A true result is reliable but\n+     a false result doesn't necessarily mean the operators don't match.  */\n+  if (valid_new_delete_pair_p (new_name, delete_name))\n+    return false;\n+\n+  /* For anything not handled by valid_new_delete_pair_p() such as member\n+     operators compare the individual demangled components of the mangled\n+     name.  */\n+  const char *new_str = IDENTIFIER_POINTER (new_name);\n+  const char *del_str = IDENTIFIER_POINTER (delete_name);\n+\n+  void *np = NULL, *dp = NULL;\n+  demangle_component *ndc = cplus_demangle_v3_components (new_str, 0, &np);\n+  demangle_component *ddc = cplus_demangle_v3_components (del_str, 0, &dp);\n+  bool mismatch = new_delete_mismatch_p (*ndc, *ddc);\n+  free (np);\n+  free (dp);\n+  return mismatch;\n+}\n+\n+/* ALLOC_DECL and DEALLOC_DECL are pair of allocation and deallocation\n+   functions.  Return true if the latter is suitable to deallocate objects\n+   allocated by calls to the former.  */\n+\n+static bool\n+matching_alloc_calls_p (tree alloc_decl, tree dealloc_decl)\n+{\n+  /* Set to alloc_kind_t::builtin if ALLOC_DECL is associated with\n+     a built-in deallocator.  */\n+  enum class alloc_kind_t { none, builtin, user }\n+  alloc_dealloc_kind = alloc_kind_t::none;\n+\n+  if (DECL_IS_OPERATOR_NEW_P (alloc_decl))\n+    {\n+      if (DECL_IS_OPERATOR_DELETE_P (dealloc_decl))\n+\t/* Return true iff both functions are of the same array or\n+\t   singleton form and false otherwise.  */\n+\treturn !new_delete_mismatch_p (alloc_decl, dealloc_decl);\n+\n+      /* Return false for deallocation functions that are known not\n+\t to match.  */\n+      if (fndecl_built_in_p (dealloc_decl, BUILT_IN_FREE)\n+\t  || fndecl_built_in_p (dealloc_decl, BUILT_IN_REALLOC))\n+\treturn false;\n+      /* Otherwise proceed below to check the deallocation function's\n+\t \"*dealloc\" attributes to look for one that mentions this operator\n+\t new.  */\n+    }\n+  else if (fndecl_built_in_p (alloc_decl, BUILT_IN_NORMAL))\n+    {\n+      switch (DECL_FUNCTION_CODE (alloc_decl))\n+\t{\n+\tcase BUILT_IN_ALLOCA:\n+\tcase BUILT_IN_ALLOCA_WITH_ALIGN:\n+\t  return false;\n+\n+\tcase BUILT_IN_ALIGNED_ALLOC:\n+\tcase BUILT_IN_CALLOC:\n+\tcase BUILT_IN_GOMP_ALLOC:\n+\tcase BUILT_IN_MALLOC:\n+\tcase BUILT_IN_REALLOC:\n+\tcase BUILT_IN_STRDUP:\n+\tcase BUILT_IN_STRNDUP:\n+\t  if (DECL_IS_OPERATOR_DELETE_P (dealloc_decl))\n+\t    return false;\n+\n+\t  if (fndecl_built_in_p (dealloc_decl, BUILT_IN_FREE)\n+\t      || fndecl_built_in_p (dealloc_decl, BUILT_IN_REALLOC))\n+\t    return true;\n+\n+\t  alloc_dealloc_kind = alloc_kind_t::builtin;\n+\t  break;\n+\n+\tdefault:\n+\t  break;\n+\t}\n+    }\n+\n+  /* Set if DEALLOC_DECL both allocates and deallocates.  */\n+  alloc_kind_t realloc_kind = alloc_kind_t::none;\n+\n+  if (fndecl_built_in_p (dealloc_decl, BUILT_IN_NORMAL))\n+    {\n+      built_in_function dealloc_code = DECL_FUNCTION_CODE (dealloc_decl);\n+      if (dealloc_code == BUILT_IN_REALLOC)\n+\trealloc_kind = alloc_kind_t::builtin;\n+\n+      for (tree amats = DECL_ATTRIBUTES (alloc_decl);\n+\t   (amats = lookup_attribute (\"malloc\", amats));\n+\t   amats = TREE_CHAIN (amats))\n+\t{\n+\t  tree args = TREE_VALUE (amats);\n+\t  if (!args)\n+\t    continue;\n+\n+\t  tree fndecl = TREE_VALUE (args);\n+\t  if (!fndecl || !DECL_P (fndecl))\n+\t    continue;\n+\n+\t  if (fndecl_built_in_p (fndecl, BUILT_IN_NORMAL)\n+\t      && dealloc_code == DECL_FUNCTION_CODE (fndecl))\n+\t    return true;\n+\t}\n+    }\n+\n+  const bool alloc_builtin = fndecl_built_in_p (alloc_decl, BUILT_IN_NORMAL);\n+  alloc_kind_t realloc_dealloc_kind = alloc_kind_t::none;\n+\n+  /* If DEALLOC_DECL has an internal \"*dealloc\" attribute scan the list\n+     of its associated allocation functions for ALLOC_DECL.\n+     If the corresponding ALLOC_DECL is found they're a matching pair,\n+     otherwise they're not.\n+     With DDATS set to the Deallocator's *Dealloc ATtributes...  */\n+  for (tree ddats = DECL_ATTRIBUTES (dealloc_decl);\n+       (ddats = lookup_attribute (\"*dealloc\", ddats));\n+       ddats = TREE_CHAIN (ddats))\n+    {\n+      tree args = TREE_VALUE (ddats);\n+      if (!args)\n+\tcontinue;\n+\n+      tree alloc = TREE_VALUE (args);\n+      if (!alloc)\n+\tcontinue;\n+\n+      if (alloc == DECL_NAME (dealloc_decl))\n+\trealloc_kind = alloc_kind_t::user;\n+\n+      if (DECL_P (alloc))\n+\t{\n+\t  gcc_checking_assert (fndecl_built_in_p (alloc, BUILT_IN_NORMAL));\n+\n+\t  switch (DECL_FUNCTION_CODE (alloc))\n+\t    {\n+\t    case BUILT_IN_ALIGNED_ALLOC:\n+\t    case BUILT_IN_CALLOC:\n+\t    case BUILT_IN_GOMP_ALLOC:\n+\t    case BUILT_IN_MALLOC:\n+\t    case BUILT_IN_REALLOC:\n+\t    case BUILT_IN_STRDUP:\n+\t    case BUILT_IN_STRNDUP:\n+\t      realloc_dealloc_kind = alloc_kind_t::builtin;\n+\t      break;\n+\t    default:\n+\t      break;\n+\t    }\n+\n+\t  if (!alloc_builtin)\n+\t    continue;\n+\n+\t  if (DECL_FUNCTION_CODE (alloc) != DECL_FUNCTION_CODE (alloc_decl))\n+\t    continue;\n+\n+\t  return true;\n+\t}\n+\n+      if (alloc == DECL_NAME (alloc_decl))\n+\treturn true;\n+    }\n+\n+  if (realloc_kind == alloc_kind_t::none)\n+    return false;\n+\n+  hash_set<tree> common_deallocs;\n+  /* Special handling for deallocators.  Iterate over both the allocator's\n+     and the reallocator's associated deallocator functions looking for\n+     the first one in common.  If one is found, the de/reallocator is\n+     a match for the allocator even though the latter isn't directly\n+     associated with the former.  This simplifies declarations in system\n+     headers.\n+     With AMATS set to the Allocator's Malloc ATtributes,\n+     and  RMATS set to Reallocator's Malloc ATtributes...  */\n+  for (tree amats = DECL_ATTRIBUTES (alloc_decl),\n+\t rmats = DECL_ATTRIBUTES (dealloc_decl);\n+       (amats = lookup_attribute (\"malloc\", amats))\n+\t || (rmats = lookup_attribute (\"malloc\", rmats));\n+       amats = amats ? TREE_CHAIN (amats) : NULL_TREE,\n+\t rmats = rmats ? TREE_CHAIN (rmats) : NULL_TREE)\n+    {\n+      if (tree args = amats ? TREE_VALUE (amats) : NULL_TREE)\n+\tif (tree adealloc = TREE_VALUE (args))\n+\t  {\n+\t    if (DECL_P (adealloc)\n+\t\t&& fndecl_built_in_p (adealloc, BUILT_IN_NORMAL))\n+\t      {\n+\t\tbuilt_in_function fncode = DECL_FUNCTION_CODE (adealloc);\n+\t\tif (fncode == BUILT_IN_FREE || fncode == BUILT_IN_REALLOC)\n+\t\t  {\n+\t\t    if (realloc_kind == alloc_kind_t::builtin)\n+\t\t      return true;\n+\t\t    alloc_dealloc_kind = alloc_kind_t::builtin;\n+\t\t  }\n+\t\tcontinue;\n+\t      }\n+\n+\t    common_deallocs.add (adealloc);\n+\t  }\n+\n+      if (tree args = rmats ? TREE_VALUE (rmats) : NULL_TREE)\n+\tif (tree ddealloc = TREE_VALUE (args))\n+\t  {\n+\t    if (DECL_P (ddealloc)\n+\t\t&& fndecl_built_in_p (ddealloc, BUILT_IN_NORMAL))\n+\t      {\n+\t\tbuilt_in_function fncode = DECL_FUNCTION_CODE (ddealloc);\n+\t\tif (fncode == BUILT_IN_FREE || fncode == BUILT_IN_REALLOC)\n+\t\t  {\n+\t\t    if (alloc_dealloc_kind == alloc_kind_t::builtin)\n+\t\t      return true;\n+\t\t    realloc_dealloc_kind = alloc_kind_t::builtin;\n+\t\t  }\n+\t\tcontinue;\n+\t      }\n+\n+\t    if (common_deallocs.add (ddealloc))\n+\t      return true;\n+\t  }\n+    }\n+\n+  /* Succeed only if ALLOC_DECL and the reallocator DEALLOC_DECL share\n+     a built-in deallocator.  */\n+  return  (alloc_dealloc_kind == alloc_kind_t::builtin\n+\t   && realloc_dealloc_kind == alloc_kind_t::builtin);\n+}\n+\n+/* Return true if DEALLOC_DECL is a function suitable to deallocate\n+   objectes allocated by the ALLOC call.  */\n+\n+static bool\n+matching_alloc_calls_p (gimple *alloc, tree dealloc_decl)\n+{\n+  tree alloc_decl = gimple_call_fndecl (alloc);\n+  if (!alloc_decl)\n+    return true;\n+\n+  return matching_alloc_calls_p (alloc_decl, dealloc_decl);\n+}\n+\n+/* Diagnose a call EXP to deallocate a pointer referenced by AREF if it\n+   includes a nonzero offset.  Such a pointer cannot refer to the beginning\n+   of an allocated object.  A negative offset may refer to it only if\n+   the target pointer is unknown.  */\n+\n+static bool\n+warn_dealloc_offset (location_t loc, gimple *call, const access_ref &aref)\n+{\n+  if (aref.deref || aref.offrng[0] <= 0 || aref.offrng[1] <= 0)\n+    return false;\n+\n+  tree dealloc_decl = gimple_call_fndecl (call);\n+  if (!dealloc_decl)\n+    return false;\n+\n+  if (DECL_IS_OPERATOR_DELETE_P (dealloc_decl)\n+      && !DECL_IS_REPLACEABLE_OPERATOR (dealloc_decl))\n+    {\n+      /* A call to a user-defined operator delete with a pointer plus offset\n+\t may be valid if it's returned from an unknown function (i.e., one\n+\t that's not operator new).  */\n+      if (TREE_CODE (aref.ref) == SSA_NAME)\n+\t{\n+\t  gimple *def_stmt = SSA_NAME_DEF_STMT (aref.ref);\n+\t  if (is_gimple_call (def_stmt))\n+\t    {\n+\t      tree alloc_decl = gimple_call_fndecl (def_stmt);\n+\t      if (!alloc_decl || !DECL_IS_OPERATOR_NEW_P (alloc_decl))\n+\t\treturn false;\n+\t    }\n+\t}\n+    }\n+\n+  char offstr[80];\n+  offstr[0] = '\\0';\n+  if (wi::fits_shwi_p (aref.offrng[0]))\n+    {\n+      if (aref.offrng[0] == aref.offrng[1]\n+\t  || !wi::fits_shwi_p (aref.offrng[1]))\n+\tsprintf (offstr, \" %lli\",\n+\t\t (long long)aref.offrng[0].to_shwi ());\n+      else\n+\tsprintf (offstr, \" [%lli, %lli]\",\n+\t\t (long long)aref.offrng[0].to_shwi (),\n+\t\t (long long)aref.offrng[1].to_shwi ());\n+    }\n+\n+  if (!warning_at (loc, OPT_Wfree_nonheap_object,\n+\t\t   \"%qD called on pointer %qE with nonzero offset%s\",\n+\t\t   dealloc_decl, aref.ref, offstr))\n+    return false;\n+\n+  if (DECL_P (aref.ref))\n+    inform (DECL_SOURCE_LOCATION (aref.ref), \"declared here\");\n+  else if (TREE_CODE (aref.ref) == SSA_NAME)\n+    {\n+      gimple *def_stmt = SSA_NAME_DEF_STMT (aref.ref);\n+      if (is_gimple_call (def_stmt))\n+\t{\n+\t  location_t def_loc = gimple_location (def_stmt);\n+\t  tree alloc_decl = gimple_call_fndecl (def_stmt);\n+\t  if (alloc_decl)\n+\t    inform (def_loc,\n+\t\t    \"returned from %qD\", alloc_decl);\n+\t  else if (tree alloc_fntype = gimple_call_fntype (def_stmt))\n+\t    inform (def_loc,\n+\t\t    \"returned from %qT\", alloc_fntype);\n+\t  else\n+\t    inform (def_loc,  \"obtained here\");\n+\t}\n+    }\n+\n+  return true;\n+}\n+\n+/* Issue a warning if a deallocation function such as free, realloc,\n+   or C++ operator delete is called with an argument not returned by\n+   a matching allocation function such as malloc or the corresponding\n+   form of C++ operatorn new.  */\n+\n+void\n+maybe_emit_free_warning (gcall *call)\n+{\n+  tree fndecl = gimple_call_fndecl (call);\n+  if (!fndecl)\n+    return;\n+\n+  unsigned argno = fndecl_dealloc_argno (fndecl);\n+  if ((unsigned) gimple_call_num_args (call) <= argno)\n+    return;\n+\n+  tree ptr = gimple_call_arg (call, argno);\n+  if (integer_zerop (ptr))\n+    return;\n+\n+  access_ref aref;\n+  if (!compute_objsize (ptr, 0, &aref))\n+    return;\n+\n+  tree ref = aref.ref;\n+  if (integer_zerop (ref))\n+    return;\n+\n+  tree dealloc_decl = fndecl;\n+  location_t loc = gimple_location (call);\n+\n+  if (DECL_P (ref) || EXPR_P (ref))\n+    {\n+      /* Diagnose freeing a declared object.  */\n+      if (aref.ref_declared ()\n+\t  && warning_at (loc, OPT_Wfree_nonheap_object,\n+\t\t\t \"%qD called on unallocated object %qD\",\n+\t\t\t dealloc_decl, ref))\n+\t{\n+\t  loc = (DECL_P (ref)\n+\t\t ? DECL_SOURCE_LOCATION (ref)\n+\t\t : EXPR_LOCATION (ref));\n+\t  inform (loc, \"declared here\");\n+\t  return;\n+\t}\n+\n+      /* Diagnose freeing a pointer that includes a positive offset.\n+\t Such a pointer cannot refer to the beginning of an allocated\n+\t object.  A negative offset may refer to it.  */\n+      if (aref.sizrng[0] != aref.sizrng[1]\n+\t  && warn_dealloc_offset (loc, call, aref))\n+\treturn;\n+    }\n+  else if (CONSTANT_CLASS_P (ref))\n+    {\n+      if (warning_at (loc, OPT_Wfree_nonheap_object,\n+\t\t      \"%qD called on a pointer to an unallocated \"\n+\t\t      \"object %qE\", dealloc_decl, ref))\n+\t{\n+\t  if (TREE_CODE (ptr) == SSA_NAME)\n+\t    {\n+\t      gimple *def_stmt = SSA_NAME_DEF_STMT (ptr);\n+\t      if (is_gimple_assign (def_stmt))\n+\t\t{\n+\t\t  location_t loc = gimple_location (def_stmt);\n+\t\t  inform (loc, \"assigned here\");\n+\t\t}\n+\t    }\n+\t  return;\n+\t}\n+    }\n+  else if (TREE_CODE (ref) == SSA_NAME)\n+    {\n+      /* Also warn if the pointer argument refers to the result\n+\t of an allocation call like alloca or VLA.  */\n+      gimple *def_stmt = SSA_NAME_DEF_STMT (ref);\n+      if (is_gimple_call (def_stmt))\n+\t{\n+\t  bool warned = false;\n+\t  if (gimple_call_alloc_p (def_stmt))\n+\t    {\n+\t      if (matching_alloc_calls_p (def_stmt, dealloc_decl))\n+\t\t{\n+\t\t  if (warn_dealloc_offset (loc, call, aref))\n+\t\t    return;\n+\t\t}\n+\t      else\n+\t\t{\n+\t\t  tree alloc_decl = gimple_call_fndecl (def_stmt);\n+\t\t  const opt_code opt =\n+\t\t    (DECL_IS_OPERATOR_NEW_P (alloc_decl)\n+\t\t     || DECL_IS_OPERATOR_DELETE_P (dealloc_decl)\n+\t\t     ? OPT_Wmismatched_new_delete\n+\t\t     : OPT_Wmismatched_dealloc);\n+\t\t  warned = warning_at (loc, opt,\n+\t\t\t\t       \"%qD called on pointer returned \"\n+\t\t\t\t       \"from a mismatched allocation \"\n+\t\t\t\t       \"function\", dealloc_decl);\n+\t\t}\n+\t    }\n+\t  else if (gimple_call_builtin_p (def_stmt, BUILT_IN_ALLOCA)\n+\t\t   || gimple_call_builtin_p (def_stmt,\n+\t\t\t\t\t     BUILT_IN_ALLOCA_WITH_ALIGN))\n+\t    warned = warning_at (loc, OPT_Wfree_nonheap_object,\n+\t\t\t\t \"%qD called on pointer to \"\n+\t\t\t\t \"an unallocated object\",\n+\t\t\t\t dealloc_decl);\n+\t  else if (warn_dealloc_offset (loc, call, aref))\n+\t    return;\n+\n+\t  if (warned)\n+\t    {\n+\t      tree fndecl = gimple_call_fndecl (def_stmt);\n+\t      inform (gimple_location (def_stmt),\n+\t\t      \"returned from %qD\", fndecl);\n+\t      return;\n+\t    }\n+\t}\n+      else if (gimple_nop_p (def_stmt))\n+\t{\n+\t  ref = SSA_NAME_VAR (ref);\n+\t  /* Diagnose freeing a pointer that includes a positive offset.  */\n+\t  if (TREE_CODE (ref) == PARM_DECL\n+\t      && !aref.deref\n+\t      && aref.sizrng[0] != aref.sizrng[1]\n+\t      && aref.offrng[0] > 0 && aref.offrng[1] > 0\n+\t      && warn_dealloc_offset (loc, call, aref))\n+\t    return;\n+\t}\n+    }\n+}\n+\n+namespace {\n+\n+const pass_data pass_data_waccess = {\n+  GIMPLE_PASS,\n+  \"waccess\",\n+  OPTGROUP_NONE,\n+  TV_NONE,\n+  PROP_cfg, /* properties_required  */\n+  0,\t    /* properties_provided  */\n+  0,\t    /* properties_destroyed  */\n+  0,\t    /* properties_start */\n+  0,\t    /* properties_finish */\n+};\n+\n+/* Pass to detect invalid accesses.  */\n+class pass_waccess : public gimple_opt_pass\n+{\n+ public:\n+  pass_waccess (gcc::context *ctxt)\n+    : gimple_opt_pass (pass_data_waccess, ctxt), m_ranger ()\n+    { }\n+\n+  opt_pass *clone () { return new pass_waccess (m_ctxt); }\n+\n+  virtual bool gate (function *);\n+  virtual unsigned int execute (function *);\n+\n+  void check (basic_block);\n+  void check (gcall *);\n+\n+private:\n+  gimple_ranger *m_ranger;\n+};\n+\n+/* Return true when any checks performed by the pass are enabled.  */\n+\n+bool\n+pass_waccess::gate (function *)\n+{\n+  return (warn_free_nonheap_object\n+\t  || warn_mismatched_alloc\n+\t  || warn_mismatched_new_delete);\n+}\n+\n+/* Check call STMT for invalid accesses.  */\n+\n+void\n+pass_waccess::check (gcall *stmt)\n+{\n+  maybe_emit_free_warning (stmt);\n+}\n+\n+/* Check basic block BB for invalid accesses.  */\n+\n+void\n+pass_waccess::check (basic_block bb)\n+{\n+  /* Iterate over statements, looking for function calls.  */\n+  for (auto si = gsi_start_bb (bb); !gsi_end_p (si); gsi_next (&si))\n+    {\n+      if (gcall *call = dyn_cast <gcall *> (gsi_stmt (si)))\n+\tcheck (call);\n+    }\n+}\n+\n+/* Check function FUN for invalid accesses.  */\n+\n+unsigned\n+pass_waccess::execute (function *fun)\n+{\n+  basic_block bb;\n+  FOR_EACH_BB_FN (bb, fun)\n+    check (bb);\n+\n+  return 0;\n+}\n+\n+}   // namespace\n+\n+/* Return a new instance of the pass.  */\n+\n+gimple_opt_pass *\n+make_pass_warn_access (gcc::context *ctxt)\n+{\n+  return new pass_waccess (ctxt);\n+}"}, {"sha": "6197574cf449039596bc0728a929364a0c617a08", "filename": "gcc/gimple-ssa-warn-access.h", "status": "added", "additions": 37, "deletions": 0, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fgimple-ssa-warn-access.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fgimple-ssa-warn-access.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-ssa-warn-access.h?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -0,0 +1,37 @@\n+/* Pass to detect and issue warnings for invalid accesses, including\n+   invalid or mismatched allocation/deallocation calls.\n+\n+   Copyright (C) 2020-2021 Free Software Foundation, Inc.\n+   Contributed by Martin Sebor <msebor@redhat.com>.\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 3, or (at your option) any later\n+   version.\n+\n+   GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+   WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with GCC; see the file COPYING3.  If not see\n+   <http://www.gnu.org/licenses/>.  */\n+\n+#ifndef GCC_GIMPLE_SSA_WARN_ACCESS_H\n+#define GCC_GIMPLE_SSA_WARN_ACCESS_H\n+\n+extern bool check_nul_terminated_array (tree, tree, tree = NULL_TREE);\n+extern void warn_string_no_nul (location_t, tree, const char *, tree,\n+\t\t\t\ttree, tree = NULL_TREE, bool = false,\n+\t\t\t\tconst wide_int[2] = NULL);\n+extern tree unterminated_array (tree, tree * = NULL, bool * = NULL);\n+extern void get_size_range (tree, tree[2], const offset_int[2]);\n+\n+class access_data;\n+extern bool maybe_warn_for_bound (opt_code, location_t, tree, tree,\n+\t\t\t\t  tree[2], tree, const access_data * = NULL);\n+\n+#endif   // GCC_GIMPLE_SSA_WARN_ACCESS_H"}, {"sha": "404acb03195bab76a7976eba7196d8d46669d600", "filename": "gcc/gimple-ssa-warn-restrict.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fgimple-ssa-warn-restrict.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fgimple-ssa-warn-restrict.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-ssa-warn-restrict.c?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -26,7 +26,7 @@\n #include \"tree.h\"\n #include \"gimple.h\"\n #include \"tree-pass.h\"\n-#include \"builtins.h\"\n+#include \"pointer-query.h\"\n #include \"ssa.h\"\n #include \"gimple-pretty-print.h\"\n #include \"gimple-ssa-warn-restrict.h\""}, {"sha": "e2858368b7dd73277da1858369bead44574d00b1", "filename": "gcc/passes.def", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fpasses.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fpasses.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpasses.def?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -419,6 +419,7 @@ along with GCC; see the file COPYING3.  If not see\n   NEXT_PASS (pass_gimple_isel);\n   NEXT_PASS (pass_cleanup_cfg_post_optimizing);\n   NEXT_PASS (pass_warn_function_noreturn);\n+  NEXT_PASS (pass_warn_access);\n \n   NEXT_PASS (pass_expand);\n "}, {"sha": "bc7cac092f5519ba02d5c2fb30eb28e1d2dcc912", "filename": "gcc/pointer-query.cc", "status": "added", "additions": 1895, "deletions": 0, "changes": 1895, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fpointer-query.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fpointer-query.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpointer-query.cc?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -0,0 +1,1895 @@\n+/* Definitions of the pointer_query and related classes.\n+\n+   Copyright (C) 2020-2021 Free Software Foundation, Inc.\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 3, or (at your option) any later\n+   version.\n+\n+   GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+   WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with GCC; see the file COPYING3.  If not see\n+   <http://www.gnu.org/licenses/>.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"backend.h\"\n+#include \"target.h\"\n+#include \"rtl.h\"\n+#include \"tree.h\"\n+#include \"memmodel.h\"\n+#include \"gimple.h\"\n+#include \"predict.h\"\n+#include \"tm_p.h\"\n+#include \"stringpool.h\"\n+#include \"tree-vrp.h\"\n+#include \"tree-ssanames.h\"\n+#include \"expmed.h\"\n+#include \"optabs.h\"\n+#include \"emit-rtl.h\"\n+#include \"recog.h\"\n+#include \"diagnostic-core.h\"\n+#include \"alias.h\"\n+#include \"fold-const.h\"\n+#include \"fold-const-call.h\"\n+#include \"gimple-ssa-warn-restrict.h\"\n+#include \"stor-layout.h\"\n+#include \"calls.h\"\n+#include \"varasm.h\"\n+#include \"tree-object-size.h\"\n+#include \"tree-ssa-strlen.h\"\n+#include \"realmpfr.h\"\n+#include \"cfgrtl.h\"\n+#include \"except.h\"\n+#include \"dojump.h\"\n+#include \"explow.h\"\n+#include \"stmt.h\"\n+#include \"expr.h\"\n+#include \"libfuncs.h\"\n+#include \"output.h\"\n+#include \"typeclass.h\"\n+#include \"langhooks.h\"\n+#include \"value-prof.h\"\n+#include \"builtins.h\"\n+#include \"stringpool.h\"\n+#include \"attribs.h\"\n+#include \"asan.h\"\n+#include \"internal-fn.h\"\n+#include \"case-cfn-macros.h\"\n+#include \"gimple-fold.h\"\n+#include \"intl.h\"\n+#include \"tree-dfa.h\"\n+#include \"gimple-iterator.h\"\n+#include \"gimple-ssa.h\"\n+#include \"tree-ssa-live.h\"\n+#include \"tree-outof-ssa.h\"\n+#include \"attr-fnspec.h\"\n+#include \"gimple-range.h\"\n+\n+#include \"pointer-query.h\"\n+\n+static bool compute_objsize_r (tree, int, access_ref *, ssa_name_limit_t &,\n+\t\t\t       pointer_query *);\n+\n+/* Wrapper around the wide_int overload of get_range that accepts\n+   offset_int instead.  For middle end expressions returns the same\n+   result.  For a subset of nonconstamt expressions emitted by the front\n+   end determines a more precise range than would be possible otherwise.  */\n+\n+static bool\n+get_offset_range (tree x, gimple *stmt, offset_int r[2], range_query *rvals)\n+{\n+  offset_int add = 0;\n+  if (TREE_CODE (x) == PLUS_EXPR)\n+    {\n+      /* Handle constant offsets in pointer addition expressions seen\n+\t n the front end IL.  */\n+      tree op = TREE_OPERAND (x, 1);\n+      if (TREE_CODE (op) == INTEGER_CST)\n+\t{\n+\t  op = fold_convert (signed_type_for (TREE_TYPE (op)), op);\n+\t  add = wi::to_offset (op);\n+\t  x = TREE_OPERAND (x, 0);\n+\t}\n+    }\n+\n+  if (TREE_CODE (x) == NOP_EXPR)\n+    /* Also handle conversions to sizetype seen in the front end IL.  */\n+    x = TREE_OPERAND (x, 0);\n+\n+  tree type = TREE_TYPE (x);\n+  if (!INTEGRAL_TYPE_P (type) && !POINTER_TYPE_P (type))\n+    return false;\n+\n+   if (TREE_CODE (x) != INTEGER_CST\n+      && TREE_CODE (x) != SSA_NAME)\n+    {\n+      if (TYPE_UNSIGNED (type)\n+\t  && TYPE_PRECISION (type) == TYPE_PRECISION (sizetype))\n+\ttype = signed_type_for (type);\n+\n+      r[0] = wi::to_offset (TYPE_MIN_VALUE (type)) + add;\n+      r[1] = wi::to_offset (TYPE_MAX_VALUE (type)) + add;\n+      return x;\n+    }\n+\n+  wide_int wr[2];\n+  if (!get_range (x, stmt, wr, rvals))\n+    return false;\n+\n+  signop sgn = SIGNED;\n+  /* Only convert signed integers or unsigned sizetype to a signed\n+     offset and avoid converting large positive values in narrower\n+     types to negative offsets.  */\n+  if (TYPE_UNSIGNED (type)\n+      && wr[0].get_precision () < TYPE_PRECISION (sizetype))\n+    sgn = UNSIGNED;\n+\n+  r[0] = offset_int::from (wr[0], sgn);\n+  r[1] = offset_int::from (wr[1], sgn);\n+  return true;\n+}\n+\n+/* Return the argument that the call STMT to a built-in function returns\n+   or null if it doesn't.  On success, set OFFRNG[] to the range of offsets\n+   from the argument reflected in the value returned by the built-in if it\n+   can be determined, otherwise to 0 and HWI_M1U respectively.  Set\n+   *PAST_END for functions like mempcpy that might return a past the end\n+   pointer (most functions return a dereferenceable pointer to an existing\n+   element of an array).  */\n+\n+static tree\n+gimple_call_return_array (gimple *stmt, offset_int offrng[2], bool *past_end,\n+\t\t\t  range_query *rvals)\n+{\n+  /* Clear and set below for the rare function(s) that might return\n+     a past-the-end pointer.  */\n+  *past_end = false;\n+\n+  {\n+    /* Check for attribute fn spec to see if the function returns one\n+       of its arguments.  */\n+    attr_fnspec fnspec = gimple_call_fnspec (as_a <gcall *>(stmt));\n+    unsigned int argno;\n+    if (fnspec.returns_arg (&argno))\n+      {\n+\t/* Functions return the first argument (not a range).  */\n+\toffrng[0] = offrng[1] = 0;\n+\treturn gimple_call_arg (stmt, argno);\n+      }\n+  }\n+\n+  if (gimple_call_num_args (stmt) < 1)\n+    return NULL_TREE;\n+\n+  tree fn = gimple_call_fndecl (stmt);\n+  if (!gimple_call_builtin_p (stmt, BUILT_IN_NORMAL))\n+    {\n+      /* See if this is a call to placement new.  */\n+      if (!fn\n+\t  || !DECL_IS_OPERATOR_NEW_P (fn)\n+\t  || DECL_IS_REPLACEABLE_OPERATOR_NEW_P (fn))\n+\treturn NULL_TREE;\n+\n+      /* Check the mangling, keeping in mind that operator new takes\n+\t a size_t which could be unsigned int or unsigned long.  */\n+      tree fname = DECL_ASSEMBLER_NAME (fn);\n+      if (!id_equal (fname, \"_ZnwjPv\")       // ordinary form\n+\t  && !id_equal (fname, \"_ZnwmPv\")    // ordinary form\n+\t  && !id_equal (fname, \"_ZnajPv\")    // array form\n+\t  && !id_equal (fname, \"_ZnamPv\"))   // array form\n+\treturn NULL_TREE;\n+\n+      if (gimple_call_num_args (stmt) != 2)\n+\treturn NULL_TREE;\n+\n+      /* Allocation functions return a pointer to the beginning.  */\n+      offrng[0] = offrng[1] = 0;\n+      return gimple_call_arg (stmt, 1);\n+    }\n+\n+  switch (DECL_FUNCTION_CODE (fn))\n+    {\n+    case BUILT_IN_MEMCPY:\n+    case BUILT_IN_MEMCPY_CHK:\n+    case BUILT_IN_MEMMOVE:\n+    case BUILT_IN_MEMMOVE_CHK:\n+    case BUILT_IN_MEMSET:\n+    case BUILT_IN_STRCAT:\n+    case BUILT_IN_STRCAT_CHK:\n+    case BUILT_IN_STRCPY:\n+    case BUILT_IN_STRCPY_CHK:\n+    case BUILT_IN_STRNCAT:\n+    case BUILT_IN_STRNCAT_CHK:\n+    case BUILT_IN_STRNCPY:\n+    case BUILT_IN_STRNCPY_CHK:\n+      /* Functions return the first argument (not a range).  */\n+      offrng[0] = offrng[1] = 0;\n+      return gimple_call_arg (stmt, 0);\n+\n+    case BUILT_IN_MEMPCPY:\n+    case BUILT_IN_MEMPCPY_CHK:\n+      {\n+\t/* The returned pointer is in a range constrained by the smaller\n+\t   of the upper bound of the size argument and the source object\n+\t   size.  */\n+\toffrng[0] = 0;\n+\toffrng[1] = HOST_WIDE_INT_M1U;\n+\ttree off = gimple_call_arg (stmt, 2);\n+\tbool off_valid = get_offset_range (off, stmt, offrng, rvals);\n+\tif (!off_valid || offrng[0] != offrng[1])\n+\t  {\n+\t    /* If the offset is either indeterminate or in some range,\n+\t       try to constrain its upper bound to at most the size\n+\t       of the source object.  */\n+\t    access_ref aref;\n+\t    tree src = gimple_call_arg (stmt, 1);\n+\t    if (compute_objsize (src, 1, &aref, rvals)\n+\t\t&& aref.sizrng[1] < offrng[1])\n+\t      offrng[1] = aref.sizrng[1];\n+\t  }\n+\n+\t/* Mempcpy may return a past-the-end pointer.  */\n+\t*past_end = true;\n+\treturn gimple_call_arg (stmt, 0);\n+      }\n+\n+    case BUILT_IN_MEMCHR:\n+      {\n+\ttree off = gimple_call_arg (stmt, 2);\n+\tif (get_offset_range (off, stmt, offrng, rvals))\n+\t  offrng[1] -= 1;\n+\telse\n+\t  offrng[1] = HOST_WIDE_INT_M1U;\n+\n+\toffrng[0] = 0;\n+\treturn gimple_call_arg (stmt, 0);\n+      }\n+\n+    case BUILT_IN_STRCHR:\n+    case BUILT_IN_STRRCHR:\n+    case BUILT_IN_STRSTR:\n+      offrng[0] = 0;\n+      offrng[1] = HOST_WIDE_INT_M1U;\n+      return gimple_call_arg (stmt, 0);\n+\n+    case BUILT_IN_STPCPY:\n+    case BUILT_IN_STPCPY_CHK:\n+      {\n+\taccess_ref aref;\n+\ttree src = gimple_call_arg (stmt, 1);\n+\tif (compute_objsize (src, 1, &aref, rvals))\n+\t  offrng[1] = aref.sizrng[1] - 1;\n+\telse\n+\t  offrng[1] = HOST_WIDE_INT_M1U;\n+\t\n+\toffrng[0] = 0;\n+\treturn gimple_call_arg (stmt, 0);\n+      }\n+\n+    case BUILT_IN_STPNCPY:\n+    case BUILT_IN_STPNCPY_CHK:\n+      {\n+\t/* The returned pointer is in a range between the first argument\n+\t   and it plus the smaller of the upper bound of the size argument\n+\t   and the source object size.  */\n+\toffrng[1] = HOST_WIDE_INT_M1U;\n+\ttree off = gimple_call_arg (stmt, 2);\n+\tif (!get_offset_range (off, stmt, offrng, rvals)\n+\t    || offrng[0] != offrng[1])\n+\t  {\n+\t    /* If the offset is either indeterminate or in some range,\n+\t       try to constrain its upper bound to at most the size\n+\t       of the source object.  */\n+\t    access_ref aref;\n+\t    tree src = gimple_call_arg (stmt, 1);\n+\t    if (compute_objsize (src, 1, &aref, rvals)\n+\t\t&& aref.sizrng[1] < offrng[1])\n+\t      offrng[1] = aref.sizrng[1];\n+\t  }\n+\n+\t/* When the source is the empty string the returned pointer is\n+\t   a copy of the argument.  Otherwise stpcpy can also return\n+\t   a past-the-end pointer.  */\n+\toffrng[0] = 0;\n+\t*past_end = true;\n+\treturn gimple_call_arg (stmt, 0);\n+      }\n+\n+    default:\n+      break;\n+    }\n+\n+  return NULL_TREE;\n+}\n+\n+/* If STMT is a call to an allocation function, returns the constant\n+   maximum size of the object allocated by the call represented as\n+   sizetype.  If nonnull, sets RNG1[] to the range of the size.\n+   When nonnull, uses RVALS for range information, otherwise gets global\n+   range info.\n+   Returns null when STMT is not a call to a valid allocation function.  */\n+\n+tree\n+gimple_call_alloc_size (gimple *stmt, wide_int rng1[2] /* = NULL */,\n+\t\t\trange_query * /* = NULL */)\n+{\n+  if (!stmt || !is_gimple_call (stmt))\n+    return NULL_TREE;\n+\n+  tree allocfntype;\n+  if (tree fndecl = gimple_call_fndecl (stmt))\n+    allocfntype = TREE_TYPE (fndecl);\n+  else\n+    allocfntype = gimple_call_fntype (stmt);\n+\n+  if (!allocfntype)\n+    return NULL_TREE;\n+\n+  unsigned argidx1 = UINT_MAX, argidx2 = UINT_MAX;\n+  tree at = lookup_attribute (\"alloc_size\", TYPE_ATTRIBUTES (allocfntype));\n+  if (!at)\n+    {\n+      if (!gimple_call_builtin_p (stmt, BUILT_IN_ALLOCA_WITH_ALIGN))\n+\treturn NULL_TREE;\n+\n+      argidx1 = 0;\n+    }\n+\n+  unsigned nargs = gimple_call_num_args (stmt);\n+\n+  if (argidx1 == UINT_MAX)\n+    {\n+      tree atval = TREE_VALUE (at);\n+      if (!atval)\n+\treturn NULL_TREE;\n+\n+      argidx1 = TREE_INT_CST_LOW (TREE_VALUE (atval)) - 1;\n+      if (nargs <= argidx1)\n+\treturn NULL_TREE;\n+\n+      atval = TREE_CHAIN (atval);\n+      if (atval)\n+\t{\n+\t  argidx2 = TREE_INT_CST_LOW (TREE_VALUE (atval)) - 1;\n+\t  if (nargs <= argidx2)\n+\t    return NULL_TREE;\n+\t}\n+    }\n+\n+  tree size = gimple_call_arg (stmt, argidx1);\n+\n+  wide_int rng1_buf[2];\n+  /* If RNG1 is not set, use the buffer.  */\n+  if (!rng1)\n+    rng1 = rng1_buf;\n+\n+  /* Use maximum precision to avoid overflow below.  */\n+  const int prec = ADDR_MAX_PRECISION;\n+\n+  {\n+    tree r[2];\n+    /* Determine the largest valid range size, including zero.  */\n+    if (!get_size_range (size, r, SR_ALLOW_ZERO | SR_USE_LARGEST))\n+      return NULL_TREE;\n+    rng1[0] = wi::to_wide (r[0], prec);\n+    rng1[1] = wi::to_wide (r[1], prec);\n+  }\n+\n+  if (argidx2 > nargs && TREE_CODE (size) == INTEGER_CST)\n+    return fold_convert (sizetype, size);\n+\n+  /* To handle ranges do the math in wide_int and return the product\n+     of the upper bounds as a constant.  Ignore anti-ranges.  */\n+  tree n = argidx2 < nargs ? gimple_call_arg (stmt, argidx2) : integer_one_node;\n+  wide_int rng2[2];\n+  {\n+    tree r[2];\n+      /* As above, use the full non-negative range on failure.  */\n+    if (!get_size_range (n, r, SR_ALLOW_ZERO | SR_USE_LARGEST))\n+      return NULL_TREE;\n+    rng2[0] = wi::to_wide (r[0], prec);\n+    rng2[1] = wi::to_wide (r[1], prec);\n+  }\n+\n+  /* Compute products of both bounds for the caller but return the lesser\n+     of SIZE_MAX and the product of the upper bounds as a constant.  */\n+  rng1[0] = rng1[0] * rng2[0];\n+  rng1[1] = rng1[1] * rng2[1];\n+\n+  const tree size_max = TYPE_MAX_VALUE (sizetype);\n+  if (wi::gtu_p (rng1[1], wi::to_wide (size_max, prec)))\n+    {\n+      rng1[1] = wi::to_wide (size_max, prec);\n+      return size_max;\n+    }\n+\n+  return wide_int_to_tree (sizetype, rng1[1]);\n+}\n+\n+/* For an access to an object referenced to by the function parameter PTR\n+   of pointer type, and set RNG[] to the range of sizes of the object\n+   obtainedfrom the attribute access specification for the current function.\n+   Set STATIC_ARRAY if the array parameter has been declared [static].\n+   Return the function parameter on success and null otherwise.  */\n+\n+tree\n+gimple_parm_array_size (tree ptr, wide_int rng[2],\n+\t\t\tbool *static_array /* = NULL */)\n+{\n+  /* For a function argument try to determine the byte size of the array\n+     from the current function declaratation (e.g., attribute access or\n+     related).  */\n+  tree var = SSA_NAME_VAR (ptr);\n+  if (TREE_CODE (var) != PARM_DECL)\n+    return NULL_TREE;\n+\n+  const unsigned prec = TYPE_PRECISION (sizetype);\n+\n+  rdwr_map rdwr_idx;\n+  attr_access *access = get_parm_access (rdwr_idx, var);\n+  if (!access)\n+    return NULL_TREE;\n+\n+  if (access->sizarg != UINT_MAX)\n+    {\n+      /* TODO: Try to extract the range from the argument based on\n+\t those of subsequent assertions or based on known calls to\n+\t the current function.  */\n+      return NULL_TREE;\n+    }\n+\n+  if (!access->minsize)\n+    return NULL_TREE;\n+\n+  /* Only consider ordinary array bound at level 2 (or above if it's\n+     ever added).  */\n+  if (warn_array_parameter < 2 && !access->static_p)\n+    return NULL_TREE;\n+\n+  if (static_array)\n+    *static_array = access->static_p;\n+\n+  rng[0] = wi::zero (prec);\n+  rng[1] = wi::uhwi (access->minsize, prec);\n+  /* Multiply the array bound encoded in the attribute by the size\n+     of what the pointer argument to which it decays points to.  */\n+  tree eltype = TREE_TYPE (TREE_TYPE (ptr));\n+  tree size = TYPE_SIZE_UNIT (eltype);\n+  if (!size || TREE_CODE (size) != INTEGER_CST)\n+    return NULL_TREE;\n+\n+  rng[1] *= wi::to_wide (size, prec);\n+  return var;\n+}\n+\n+access_ref::access_ref (tree bound /* = NULL_TREE */,\n+\t\t\tbool minaccess /* = false */)\n+: ref (), eval ([](tree x){ return x; }), deref (), trail1special (true),\n+  base0 (true), parmarray ()\n+{\n+  /* Set to valid.  */\n+  offrng[0] = offrng[1] = 0;\n+  offmax[0] = offmax[1] = 0;\n+  /* Invalidate.   */\n+  sizrng[0] = sizrng[1] = -1;\n+\n+  /* Set the default bounds of the access and adjust below.  */\n+  bndrng[0] = minaccess ? 1 : 0;\n+  bndrng[1] = HOST_WIDE_INT_M1U;\n+\n+  /* When BOUND is nonnull and a range can be extracted from it,\n+     set the bounds of the access to reflect both it and MINACCESS.\n+     BNDRNG[0] is the size of the minimum access.  */\n+  tree rng[2];\n+  if (bound && get_size_range (bound, rng, SR_ALLOW_ZERO))\n+    {\n+      bndrng[0] = wi::to_offset (rng[0]);\n+      bndrng[1] = wi::to_offset (rng[1]);\n+      bndrng[0] = bndrng[0] > 0 && minaccess ? 1 : 0;\n+    }\n+}\n+\n+/* Return the PHI node REF refers to or null if it doesn't.  */\n+\n+gphi *\n+access_ref::phi () const\n+{\n+  if (!ref || TREE_CODE (ref) != SSA_NAME)\n+    return NULL;\n+\n+  gimple *def_stmt = SSA_NAME_DEF_STMT (ref);\n+  if (gimple_code (def_stmt) != GIMPLE_PHI)\n+    return NULL;\n+\n+  return as_a <gphi *> (def_stmt);\n+}\n+\n+/* Determine and return the largest object to which *THIS.  If *THIS\n+   refers to a PHI and PREF is nonnull, fill *PREF with the details\n+   of the object determined by compute_objsize(ARG, OSTYPE) for each\n+   PHI argument ARG.  */\n+\n+tree\n+access_ref::get_ref (vec<access_ref> *all_refs,\n+\t\t     access_ref *pref /* = NULL */,\n+\t\t     int ostype /* = 1 */,\n+\t\t     ssa_name_limit_t *psnlim /* = NULL */,\n+\t\t     pointer_query *qry /* = NULL */) const\n+{\n+  gphi *phi_stmt = this->phi ();\n+  if (!phi_stmt)\n+    return ref;\n+\n+  /* FIXME: Calling get_ref() with a null PSNLIM is dangerous and might\n+     cause unbounded recursion.  */\n+  ssa_name_limit_t snlim_buf;\n+  if (!psnlim)\n+    psnlim = &snlim_buf;\n+\n+  if (!psnlim->visit_phi (ref))\n+    return NULL_TREE;\n+\n+  /* Reflects the range of offsets of all PHI arguments refer to the same\n+     object (i.e., have the same REF).  */\n+  access_ref same_ref;\n+  /* The conservative result of the PHI reflecting the offset and size\n+     of the largest PHI argument, regardless of whether or not they all\n+     refer to the same object.  */\n+  pointer_query empty_qry;\n+  if (!qry)\n+    qry = &empty_qry;\n+\n+  access_ref phi_ref;\n+  if (pref)\n+    {\n+      phi_ref = *pref;\n+      same_ref = *pref;\n+    }\n+\n+  /* Set if any argument is a function array (or VLA) parameter not\n+     declared [static].  */\n+  bool parmarray = false;\n+  /* The size of the smallest object referenced by the PHI arguments.  */\n+  offset_int minsize = 0;\n+  const offset_int maxobjsize = wi::to_offset (max_object_size ());\n+  /* The offset of the PHI, not reflecting those of its arguments.  */\n+  const offset_int orng[2] = { phi_ref.offrng[0], phi_ref.offrng[1] };\n+\n+  const unsigned nargs = gimple_phi_num_args (phi_stmt);\n+  for (unsigned i = 0; i < nargs; ++i)\n+    {\n+      access_ref phi_arg_ref;\n+      tree arg = gimple_phi_arg_def (phi_stmt, i);\n+      if (!compute_objsize_r (arg, ostype, &phi_arg_ref, *psnlim, qry)\n+\t  || phi_arg_ref.sizrng[0] < 0)\n+\t/* A PHI with all null pointer arguments.  */\n+\treturn NULL_TREE;\n+\n+      /* Add PREF's offset to that of the argument.  */\n+      phi_arg_ref.add_offset (orng[0], orng[1]);\n+      if (TREE_CODE (arg) == SSA_NAME)\n+\tqry->put_ref (arg, phi_arg_ref);\n+\n+      if (all_refs)\n+\tall_refs->safe_push (phi_arg_ref);\n+\n+      const bool arg_known_size = (phi_arg_ref.sizrng[0] != 0\n+\t\t\t\t   || phi_arg_ref.sizrng[1] != maxobjsize);\n+\n+      parmarray |= phi_arg_ref.parmarray;\n+\n+      const bool nullp = integer_zerop (arg) && (i || i + 1 < nargs);\n+\n+      if (phi_ref.sizrng[0] < 0)\n+\t{\n+\t  if (!nullp)\n+\t    same_ref = phi_arg_ref;\n+\t  phi_ref = phi_arg_ref;\n+\t  if (arg_known_size)\n+\t    minsize = phi_arg_ref.sizrng[0];\n+\t  continue;\n+\t}\n+\n+      const bool phi_known_size = (phi_ref.sizrng[0] != 0\n+\t\t\t\t   || phi_ref.sizrng[1] != maxobjsize);\n+\n+      if (phi_known_size && phi_arg_ref.sizrng[0] < minsize)\n+\tminsize = phi_arg_ref.sizrng[0];\n+\n+      /* Disregard null pointers in PHIs with two or more arguments.\n+\t TODO: Handle this better!  */\n+      if (nullp)\n+\tcontinue;\n+\n+      /* Determine the amount of remaining space in the argument.  */\n+      offset_int argrem[2];\n+      argrem[1] = phi_arg_ref.size_remaining (argrem);\n+\n+      /* Determine the amount of remaining space computed so far and\n+\t if the remaining space in the argument is more use it instead.  */\n+      offset_int phirem[2];\n+      phirem[1] = phi_ref.size_remaining (phirem);\n+\n+      if (phi_arg_ref.ref != same_ref.ref)\n+\tsame_ref.ref = NULL_TREE;\n+\n+      if (phirem[1] < argrem[1]\n+\t  || (phirem[1] == argrem[1]\n+\t      && phi_ref.sizrng[1] < phi_arg_ref.sizrng[1]))\n+\t/* Use the argument with the most space remaining as the result,\n+\t   or the larger one if the space is equal.  */\n+\tphi_ref = phi_arg_ref;\n+\n+      /* Set SAME_REF.OFFRNG to the maximum range of all arguments.  */\n+      if (phi_arg_ref.offrng[0] < same_ref.offrng[0])\n+\tsame_ref.offrng[0] = phi_arg_ref.offrng[0];\n+      if (same_ref.offrng[1] < phi_arg_ref.offrng[1])\n+\tsame_ref.offrng[1] = phi_arg_ref.offrng[1];\n+    }\n+\n+  if (!same_ref.ref && same_ref.offrng[0] != 0)\n+    /* Clear BASE0 if not all the arguments refer to the same object and\n+       if not all their offsets are zero-based.  This allows the final\n+       PHI offset to out of bounds for some arguments but not for others\n+       (or negative even of all the arguments are BASE0), which is overly\n+       permissive.  */\n+    phi_ref.base0 = false;\n+\n+  if (same_ref.ref)\n+    phi_ref = same_ref;\n+  else\n+    {\n+      /* Replace the lower bound of the largest argument with the size\n+\t of the smallest argument, and set PARMARRAY if any argument\n+\t was one.  */\n+      phi_ref.sizrng[0] = minsize;\n+      phi_ref.parmarray = parmarray;\n+    }\n+\n+  if (phi_ref.sizrng[0] < 0)\n+    {\n+      /* Fail if none of the PHI's arguments resulted in updating PHI_REF\n+\t (perhaps because they have all been already visited by prior\n+\t recursive calls).  */\n+      psnlim->leave_phi (ref);\n+      return NULL_TREE;\n+    }\n+\n+  /* Avoid changing *THIS.  */\n+  if (pref && pref != this)\n+    *pref = phi_ref;\n+\n+  psnlim->leave_phi (ref);\n+\n+  return phi_ref.ref;\n+}\n+\n+/* Return the maximum amount of space remaining and if non-null, set\n+   argument to the minimum.  */\n+\n+offset_int\n+access_ref::size_remaining (offset_int *pmin /* = NULL */) const\n+{\n+  offset_int minbuf;\n+  if (!pmin)\n+    pmin = &minbuf;\n+\n+  /* add_offset() ensures the offset range isn't inverted.  */\n+  gcc_checking_assert (offrng[0] <= offrng[1]);\n+\n+  if (base0)\n+    {\n+      /* The offset into referenced object is zero-based (i.e., it's\n+\t not referenced by a pointer into middle of some unknown object).  */\n+      if (offrng[0] < 0 && offrng[1] < 0)\n+\t{\n+\t  /* If the offset is negative the remaining size is zero.  */\n+\t  *pmin = 0;\n+\t  return 0;\n+\t}\n+\n+      if (sizrng[1] <= offrng[0])\n+\t{\n+\t  /* If the starting offset is greater than or equal to the upper\n+\t     bound on the size of the object, the space remaining is zero.\n+\t     As a special case, if it's equal, set *PMIN to -1 to let\n+\t     the caller know the offset is valid and just past the end.  */\n+\t  *pmin = sizrng[1] == offrng[0] ? -1 : 0;\n+\t  return 0;\n+\t}\n+\n+      /* Otherwise return the size minus the lower bound of the offset.  */\n+      offset_int or0 = offrng[0] < 0 ? 0 : offrng[0];\n+\n+      *pmin = sizrng[0] - or0;\n+      return sizrng[1] - or0;\n+    }\n+\n+  /* The offset to the referenced object isn't zero-based (i.e., it may\n+     refer to a byte other than the first.  The size of such an object\n+     is constrained only by the size of the address space (the result\n+     of max_object_size()).  */\n+  if (sizrng[1] <= offrng[0])\n+    {\n+      *pmin = 0;\n+      return 0;\n+    }\n+\n+  offset_int or0 = offrng[0] < 0 ? 0 : offrng[0];\n+\n+  *pmin = sizrng[0] - or0;\n+  return sizrng[1] - or0;\n+}\n+\n+/* Return true if the offset and object size are in range for SIZE.  */\n+\n+bool\n+access_ref::offset_in_range (const offset_int &size) const\n+{\n+  if (size_remaining () < size)\n+    return false;\n+\n+  if (base0)\n+    return offmax[0] >= 0 && offmax[1] <= sizrng[1];\n+\n+  offset_int maxoff = wi::to_offset (TYPE_MAX_VALUE (ptrdiff_type_node));\n+  return offmax[0] > -maxoff && offmax[1] < maxoff;\n+}\n+\n+/* Add the range [MIN, MAX] to the offset range.  For known objects (with\n+   zero-based offsets) at least one of whose offset's bounds is in range,\n+   constrain the other (or both) to the bounds of the object (i.e., zero\n+   and the upper bound of its size).  This improves the quality of\n+   diagnostics.  */\n+\n+void access_ref::add_offset (const offset_int &min, const offset_int &max)\n+{\n+  if (min <= max)\n+    {\n+      /* To add an ordinary range just add it to the bounds.  */\n+      offrng[0] += min;\n+      offrng[1] += max;\n+    }\n+  else if (!base0)\n+    {\n+      /* To add an inverted range to an offset to an unknown object\n+\t expand it to the maximum.  */\n+      add_max_offset ();\n+      return;\n+    }\n+  else\n+    {\n+      /* To add an inverted range to an offset to an known object set\n+\t the upper bound to the maximum representable offset value\n+\t (which may be greater than MAX_OBJECT_SIZE).\n+\t The lower bound is either the sum of the current offset and\n+\t MIN when abs(MAX) is greater than the former, or zero otherwise.\n+\t Zero because then then inverted range includes the negative of\n+\t the lower bound.  */\n+      offset_int maxoff = wi::to_offset (TYPE_MAX_VALUE (ptrdiff_type_node));\n+      offrng[1] = maxoff;\n+\n+      if (max >= 0)\n+\t{\n+\t  offrng[0] = 0;\n+\t  if (offmax[0] > 0)\n+\t    offmax[0] = 0;\n+\t  return;\n+\t}\n+\n+      offset_int absmax = wi::abs (max);\n+      if (offrng[0] < absmax)\n+\t{\n+\t  offrng[0] += min;\n+\t  /* Cap the lower bound at the upper (set to MAXOFF above)\n+\t     to avoid inadvertently recreating an inverted range.  */\n+\t  if (offrng[1] < offrng[0])\n+\t    offrng[0] = offrng[1];\n+\t}\n+      else\n+\toffrng[0] = 0;\n+    }\n+\n+  /* Set the minimum and maximmum computed so far. */\n+  if (offrng[1] < 0 && offrng[1] < offmax[0])\n+    offmax[0] = offrng[1];\n+  if (offrng[0] > 0 && offrng[0] > offmax[1])\n+    offmax[1] = offrng[0];\n+\n+  if (!base0)\n+    return;\n+\n+  /* When referencing a known object check to see if the offset computed\n+     so far is in bounds... */\n+  offset_int remrng[2];\n+  remrng[1] = size_remaining (remrng);\n+  if (remrng[1] > 0 || remrng[0] < 0)\n+    {\n+      /* ...if so, constrain it so that neither bound exceeds the size of\n+\t the object.  Out of bounds offsets are left unchanged, and, for\n+\t better or worse, become in bounds later.  They should be detected\n+\t and diagnosed at the point they first become invalid by\n+\t -Warray-bounds.  */\n+      if (offrng[0] < 0)\n+\toffrng[0] = 0;\n+      if (offrng[1] > sizrng[1])\n+\toffrng[1] = sizrng[1];\n+    }\n+}\n+\n+/* Issue one inform message describing each target of an access REF.\n+   WRITE is set for a write access and clear for a read access.  */\n+\n+void\n+access_ref::inform_access (access_mode mode) const\n+{\n+  const access_ref &aref = *this;\n+  if (!aref.ref)\n+    return;\n+\n+  if (aref.phi ())\n+    {\n+      /* Set MAXREF to refer to the largest object and fill ALL_REFS\n+\t with data for all objects referenced by the PHI arguments.  */\n+      access_ref maxref;\n+      auto_vec<access_ref> all_refs;\n+      if (!get_ref (&all_refs, &maxref))\n+\treturn;\n+\n+      /* Except for MAXREF, the rest of the arguments' offsets need not\n+\t reflect one added to the PHI itself.  Determine the latter from\n+\t MAXREF on which the result is based.  */\n+      const offset_int orng[] =\n+\t{\n+\t  offrng[0] - maxref.offrng[0],\n+\t  wi::smax (offrng[1] - maxref.offrng[1], offrng[0]),\n+\t};\n+\n+      /* Add the final PHI's offset to that of each of the arguments\n+\t and recurse to issue an inform message for it.  */\n+      for (unsigned i = 0; i != all_refs.length (); ++i)\n+\t{\n+\t  /* Skip any PHIs; those could lead to infinite recursion.  */\n+\t  if (all_refs[i].phi ())\n+\t    continue;\n+\n+\t  all_refs[i].add_offset (orng[0], orng[1]);\n+\t  all_refs[i].inform_access (mode);\n+\t}\n+      return;\n+    }\n+\n+  /* Convert offset range and avoid including a zero range since it\n+     isn't necessarily meaningful.  */\n+  HOST_WIDE_INT diff_min = tree_to_shwi (TYPE_MIN_VALUE (ptrdiff_type_node));\n+  HOST_WIDE_INT diff_max = tree_to_shwi (TYPE_MAX_VALUE (ptrdiff_type_node));\n+  HOST_WIDE_INT minoff;\n+  HOST_WIDE_INT maxoff = diff_max;\n+  if (wi::fits_shwi_p (aref.offrng[0]))\n+    minoff = aref.offrng[0].to_shwi ();\n+  else\n+    minoff = aref.offrng[0] < 0 ? diff_min : diff_max;\n+\n+  if (wi::fits_shwi_p (aref.offrng[1]))\n+    maxoff = aref.offrng[1].to_shwi ();\n+\n+  if (maxoff <= diff_min || maxoff >= diff_max)\n+    /* Avoid mentioning an upper bound that's equal to or in excess\n+       of the maximum of ptrdiff_t.  */\n+    maxoff = minoff;\n+\n+  /* Convert size range and always include it since all sizes are\n+     meaningful. */\n+  unsigned long long minsize = 0, maxsize = 0;\n+  if (wi::fits_shwi_p (aref.sizrng[0])\n+      && wi::fits_shwi_p (aref.sizrng[1]))\n+    {\n+      minsize = aref.sizrng[0].to_shwi ();\n+      maxsize = aref.sizrng[1].to_shwi ();\n+    }\n+\n+  /* SIZRNG doesn't necessarily have the same range as the allocation\n+     size determined by gimple_call_alloc_size ().  */\n+  char sizestr[80];\n+  if (minsize == maxsize)\n+    sprintf (sizestr, \"%llu\", minsize);\n+  else\n+    sprintf (sizestr, \"[%llu, %llu]\", minsize, maxsize);\n+\n+  char offstr[80];\n+  if (minoff == 0\n+      && (maxoff == 0 || aref.sizrng[1] <= maxoff))\n+    offstr[0] = '\\0';\n+  else if (minoff == maxoff)\n+    sprintf (offstr, \"%lli\", (long long) minoff);\n+  else\n+    sprintf (offstr, \"[%lli, %lli]\", (long long) minoff, (long long) maxoff);\n+\n+  location_t loc = UNKNOWN_LOCATION;\n+\n+  tree ref = this->ref;\n+  tree allocfn = NULL_TREE;\n+  if (TREE_CODE (ref) == SSA_NAME)\n+    {\n+      gimple *stmt = SSA_NAME_DEF_STMT (ref);\n+      if (is_gimple_call (stmt))\n+\t{\n+\t  loc = gimple_location (stmt);\n+\t  if (gimple_call_builtin_p (stmt, BUILT_IN_ALLOCA_WITH_ALIGN))\n+\t    {\n+\t      /* Strip the SSA_NAME suffix from the variable name and\n+\t\t recreate an identifier with the VLA's original name.  */\n+\t      ref = gimple_call_lhs (stmt);\n+\t      if (SSA_NAME_IDENTIFIER (ref))\n+\t\t{\n+\t\t  ref = SSA_NAME_IDENTIFIER (ref);\n+\t\t  const char *id = IDENTIFIER_POINTER (ref);\n+\t\t  size_t len = strcspn (id, \".$\");\n+\t\t  if (!len)\n+\t\t    len = strlen (id);\n+\t\t  ref = get_identifier_with_length (id, len);\n+\t\t}\n+\t    }\n+\t  else\n+\t    {\n+\t      /* Except for VLAs, retrieve the allocation function.  */\n+\t      allocfn = gimple_call_fndecl (stmt);\n+\t      if (!allocfn)\n+\t\tallocfn = gimple_call_fn (stmt);\n+\t      if (TREE_CODE (allocfn) == SSA_NAME)\n+\t\t{\n+\t\t  /* For an ALLOC_CALL via a function pointer make a small\n+\t\t     effort to determine the destination of the pointer.  */\n+\t\t  gimple *def = SSA_NAME_DEF_STMT (allocfn);\n+\t\t  if (gimple_assign_single_p (def))\n+\t\t    {\n+\t\t      tree rhs = gimple_assign_rhs1 (def);\n+\t\t      if (DECL_P (rhs))\n+\t\t\tallocfn = rhs;\n+\t\t      else if (TREE_CODE (rhs) == COMPONENT_REF)\n+\t\t\tallocfn = TREE_OPERAND (rhs, 1);\n+\t\t    }\n+\t\t}\n+\t    }\n+\t}\n+      else if (gimple_nop_p (stmt))\n+\t/* Handle DECL_PARM below.  */\n+\tref = SSA_NAME_VAR (ref);\n+    }\n+\n+  if (DECL_P (ref))\n+    loc = DECL_SOURCE_LOCATION (ref);\n+  else if (EXPR_P (ref) && EXPR_HAS_LOCATION (ref))\n+    loc = EXPR_LOCATION (ref);\n+  else if (TREE_CODE (ref) != IDENTIFIER_NODE\n+\t   && TREE_CODE (ref) != SSA_NAME)\n+    return;\n+\n+  if (mode == access_read_write || mode == access_write_only)\n+    {\n+      if (allocfn == NULL_TREE)\n+\t{\n+\t  if (*offstr)\n+\t    inform (loc, \"at offset %s into destination object %qE of size %s\",\n+\t\t    offstr, ref, sizestr);\n+\t  else\n+\t    inform (loc, \"destination object %qE of size %s\", ref, sizestr);\n+\t  return;\n+\t}\n+\n+      if (*offstr)\n+\tinform (loc,\n+\t\t\"at offset %s into destination object of size %s \"\n+\t\t\"allocated by %qE\", offstr, sizestr, allocfn);\n+      else\n+\tinform (loc, \"destination object of size %s allocated by %qE\",\n+\t\tsizestr, allocfn);\n+      return;\n+    }\n+\n+  if (mode == access_read_only)\n+    {\n+      if (allocfn == NULL_TREE)\n+\t{\n+\t  if (*offstr)\n+\t    inform (loc, \"at offset %s into source object %qE of size %s\",\n+\t\t    offstr, ref, sizestr);\n+\t  else\n+\t    inform (loc, \"source object %qE of size %s\", ref, sizestr);\n+\n+\t  return;\n+\t}\n+\n+      if (*offstr)\n+\tinform (loc,\n+\t\t\"at offset %s into source object of size %s allocated by %qE\",\n+\t\toffstr, sizestr, allocfn);\n+      else\n+\tinform (loc, \"source object of size %s allocated by %qE\",\n+\t\tsizestr, allocfn);\n+      return;\n+    }\n+\n+  if (allocfn == NULL_TREE)\n+    {\n+      if (*offstr)\n+\tinform (loc, \"at offset %s into object %qE of size %s\",\n+\t\toffstr, ref, sizestr);\n+      else\n+\tinform (loc, \"object %qE of size %s\", ref, sizestr);\n+\n+      return;\n+    }\n+\n+  if (*offstr)\n+    inform (loc,\n+\t    \"at offset %s into object of size %s allocated by %qE\",\n+\t    offstr, sizestr, allocfn);\n+  else\n+    inform (loc, \"object of size %s allocated by %qE\",\n+\t    sizestr, allocfn);\n+}\n+\n+/* Set a bit for the PHI in VISITED and return true if it wasn't\n+   already set.  */\n+\n+bool\n+ssa_name_limit_t::visit_phi (tree ssa_name)\n+{\n+  if (!visited)\n+    visited = BITMAP_ALLOC (NULL);\n+\n+  /* Return false if SSA_NAME has already been visited.  */\n+  return bitmap_set_bit (visited, SSA_NAME_VERSION (ssa_name));\n+}\n+\n+/* Clear a bit for the PHI in VISITED.  */\n+\n+void\n+ssa_name_limit_t::leave_phi (tree ssa_name)\n+{\n+  /* Return false if SSA_NAME has already been visited.  */\n+  bitmap_clear_bit (visited, SSA_NAME_VERSION (ssa_name));\n+}\n+\n+/* Return false if the SSA_NAME chain length counter has reached\n+   the limit, otherwise increment the counter and return true.  */\n+\n+bool\n+ssa_name_limit_t::next ()\n+{\n+  /* Return a negative value to let caller avoid recursing beyond\n+     the specified limit.  */\n+  if (ssa_def_max == 0)\n+    return false;\n+\n+  --ssa_def_max;\n+  return true;\n+}\n+\n+/* If the SSA_NAME has already been \"seen\" return a positive value.\n+   Otherwise add it to VISITED.  If the SSA_NAME limit has been\n+   reached, return a negative value.  Otherwise return zero.  */\n+\n+int\n+ssa_name_limit_t::next_phi (tree ssa_name)\n+{\n+  {\n+    gimple *def_stmt = SSA_NAME_DEF_STMT (ssa_name);\n+    /* Return a positive value if the PHI has already been visited.  */\n+    if (gimple_code (def_stmt) == GIMPLE_PHI\n+\t&& !visit_phi (ssa_name))\n+      return 1;\n+  }\n+\n+  /* Return a negative value to let caller avoid recursing beyond\n+     the specified limit.  */\n+  if (ssa_def_max == 0)\n+    return -1;\n+\n+  --ssa_def_max;\n+\n+  return 0;\n+}\n+\n+ssa_name_limit_t::~ssa_name_limit_t ()\n+{\n+  if (visited)\n+    BITMAP_FREE (visited);\n+}\n+\n+/* Default ctor.  Initialize object with pointers to the range_query\n+   and cache_type instances to use or null.  */\n+\n+pointer_query::pointer_query (range_query *qry /* = NULL */,\n+\t\t\t      cache_type *cache /* = NULL */)\n+: rvals (qry), var_cache (cache), hits (), misses (),\n+  failures (), depth (), max_depth ()\n+{\n+  /* No op.  */\n+}\n+\n+/* Return a pointer to the cached access_ref instance for the SSA_NAME\n+   PTR if it's there or null otherwise.  */\n+\n+const access_ref *\n+pointer_query::get_ref (tree ptr, int ostype /* = 1 */) const\n+{\n+  if (!var_cache)\n+    {\n+      ++misses;\n+      return NULL;\n+    }\n+\n+  unsigned version = SSA_NAME_VERSION (ptr);\n+  unsigned idx = version << 1 | (ostype & 1);\n+  if (var_cache->indices.length () <= idx)\n+    {\n+      ++misses;\n+      return NULL;\n+    }\n+\n+  unsigned cache_idx = var_cache->indices[idx];\n+  if (var_cache->access_refs.length () <= cache_idx)\n+    {\n+      ++misses;\n+      return NULL;\n+    }\n+\n+  access_ref &cache_ref = var_cache->access_refs[cache_idx];\n+  if (cache_ref.ref)\n+    {\n+      ++hits;\n+      return &cache_ref;\n+    }\n+\n+  ++misses;\n+  return NULL;\n+}\n+\n+/* Retrieve the access_ref instance for a variable from the cache if it's\n+   there or compute it and insert it into the cache if it's nonnonull.  */\n+\n+bool\n+pointer_query::get_ref (tree ptr, access_ref *pref, int ostype /* = 1 */)\n+{\n+  const unsigned version\n+    = TREE_CODE (ptr) == SSA_NAME ? SSA_NAME_VERSION (ptr) : 0;\n+\n+  if (var_cache && version)\n+    {\n+      unsigned idx = version << 1 | (ostype & 1);\n+      if (idx < var_cache->indices.length ())\n+\t{\n+\t  unsigned cache_idx = var_cache->indices[idx] - 1;\n+\t  if (cache_idx < var_cache->access_refs.length ()\n+\t      && var_cache->access_refs[cache_idx].ref)\n+\t    {\n+\t      ++hits;\n+\t      *pref = var_cache->access_refs[cache_idx];\n+\t      return true;\n+\t    }\n+\t}\n+\n+      ++misses;\n+    }\n+\n+  if (!compute_objsize (ptr, ostype, pref, this))\n+    {\n+      ++failures;\n+      return false;\n+    }\n+\n+  return true;\n+}\n+\n+/* Add a copy of the access_ref REF for the SSA_NAME to the cache if it's\n+   nonnull.  */\n+\n+void\n+pointer_query::put_ref (tree ptr, const access_ref &ref, int ostype /* = 1 */)\n+{\n+  /* Only add populated/valid entries.  */\n+  if (!var_cache || !ref.ref || ref.sizrng[0] < 0)\n+    return;\n+\n+  /* Add REF to the two-level cache.  */\n+  unsigned version = SSA_NAME_VERSION (ptr);\n+  unsigned idx = version << 1 | (ostype & 1);\n+\n+  /* Grow INDICES if necessary.  An index is valid if it's nonzero.\n+     Its value minus one is the index into ACCESS_REFS.  Not all\n+     entries are valid.  */\n+  if (var_cache->indices.length () <= idx)\n+    var_cache->indices.safe_grow_cleared (idx + 1);\n+\n+  if (!var_cache->indices[idx])\n+    var_cache->indices[idx] = var_cache->access_refs.length () + 1;\n+\n+  /* Grow ACCESS_REF cache if necessary.  An entry is valid if its\n+     REF member is nonnull.  All entries except for the last two\n+     are valid.  Once nonnull, the REF value must stay unchanged.  */\n+  unsigned cache_idx = var_cache->indices[idx];\n+  if (var_cache->access_refs.length () <= cache_idx)\n+    var_cache->access_refs.safe_grow_cleared (cache_idx + 1);\n+\n+  access_ref cache_ref = var_cache->access_refs[cache_idx - 1];\n+  if (cache_ref.ref)\n+  {\n+    gcc_checking_assert (cache_ref.ref == ref.ref);\n+    return;\n+  }\n+\n+  cache_ref = ref;\n+}\n+\n+/* Flush the cache if it's nonnull.  */\n+\n+void\n+pointer_query::flush_cache ()\n+{\n+  if (!var_cache)\n+    return;\n+  var_cache->indices.release ();\n+  var_cache->access_refs.release ();\n+}\n+\n+/* A helper of compute_objsize_r() to determine the size from an assignment\n+   statement STMT with the RHS of either MIN_EXPR or MAX_EXPR.  */\n+\n+static bool\n+handle_min_max_size (gimple *stmt, int ostype, access_ref *pref,\n+\t\t     ssa_name_limit_t &snlim, pointer_query *qry)\n+{\n+  tree_code code = gimple_assign_rhs_code (stmt);\n+\n+  tree ptr = gimple_assign_rhs1 (stmt);\n+\n+  /* In a valid MAX_/MIN_EXPR both operands must refer to the same array.\n+     Determine the size/offset of each and use the one with more or less\n+     space remaining, respectively.  If either fails, use the information\n+     determined from the other instead, adjusted up or down as appropriate\n+     for the expression.  */\n+  access_ref aref[2] = { *pref, *pref };\n+  if (!compute_objsize_r (ptr, ostype, &aref[0], snlim, qry))\n+    {\n+      aref[0].base0 = false;\n+      aref[0].offrng[0] = aref[0].offrng[1] = 0;\n+      aref[0].add_max_offset ();\n+      aref[0].set_max_size_range ();\n+    }\n+\n+  ptr = gimple_assign_rhs2 (stmt);\n+  if (!compute_objsize_r (ptr, ostype, &aref[1], snlim, qry))\n+    {\n+      aref[1].base0 = false;\n+      aref[1].offrng[0] = aref[1].offrng[1] = 0;\n+      aref[1].add_max_offset ();\n+      aref[1].set_max_size_range ();\n+    }\n+\n+  if (!aref[0].ref && !aref[1].ref)\n+    /* Fail if the identity of neither argument could be determined.  */\n+    return false;\n+\n+  bool i0 = false;\n+  if (aref[0].ref && aref[0].base0)\n+    {\n+      if (aref[1].ref && aref[1].base0)\n+\t{\n+\t  /* If the object referenced by both arguments has been determined\n+\t     set *PREF to the one with more or less space remainng, whichever\n+\t     is appopriate for CODE.\n+\t     TODO: Indicate when the objects are distinct so it can be\n+\t     diagnosed.  */\n+\t  i0 = code == MAX_EXPR;\n+\t  const bool i1 = !i0;\n+\n+\t  if (aref[i0].size_remaining () < aref[i1].size_remaining ())\n+\t    *pref = aref[i1];\n+\t  else\n+\t    *pref = aref[i0];\n+\t  return true;\n+\t}\n+\n+      /* If only the object referenced by one of the arguments could be\n+\t determined, use it and...  */\n+      *pref = aref[0];\n+      i0 = true;\n+    }\n+  else\n+    *pref = aref[1];\n+\n+  const bool i1 = !i0;\n+  /* ...see if the offset obtained from the other pointer can be used\n+     to tighten up the bound on the offset obtained from the first.  */\n+  if ((code == MAX_EXPR && aref[i1].offrng[1] < aref[i0].offrng[0])\n+      || (code == MIN_EXPR && aref[i0].offrng[0] < aref[i1].offrng[1]))\n+    {\n+      pref->offrng[0] = aref[i0].offrng[0];\n+      pref->offrng[1] = aref[i0].offrng[1];\n+    }\n+  return true;\n+}\n+\n+/* A helper of compute_objsize_r() to determine the size from ARRAY_REF\n+   AREF.  ADDR is true if PTR is the operand of ADDR_EXPR.  Return true\n+   on success and false on failure.  */\n+\n+static bool\n+handle_array_ref (tree aref, bool addr, int ostype, access_ref *pref,\n+\t\t  ssa_name_limit_t &snlim, pointer_query *qry)\n+{\n+  gcc_assert (TREE_CODE (aref) == ARRAY_REF);\n+\n+  ++pref->deref;\n+\n+  tree arefop = TREE_OPERAND (aref, 0);\n+  tree reftype = TREE_TYPE (arefop);\n+  if (!addr && TREE_CODE (TREE_TYPE (reftype)) == POINTER_TYPE)\n+    /* Avoid arrays of pointers.  FIXME: Hande pointers to arrays\n+       of known bound.  */\n+    return false;\n+\n+  if (!compute_objsize_r (arefop, ostype, pref, snlim, qry))\n+    return false;\n+\n+  offset_int orng[2];\n+  tree off = pref->eval (TREE_OPERAND (aref, 1));\n+  range_query *const rvals = qry ? qry->rvals : NULL;\n+  if (!get_offset_range (off, NULL, orng, rvals))\n+    {\n+      /* Set ORNG to the maximum offset representable in ptrdiff_t.  */\n+      orng[1] = wi::to_offset (TYPE_MAX_VALUE (ptrdiff_type_node));\n+      orng[0] = -orng[1] - 1;\n+    }\n+\n+  /* Convert the array index range determined above to a byte\n+     offset.  */\n+  tree lowbnd = array_ref_low_bound (aref);\n+  if (!integer_zerop (lowbnd) && tree_fits_uhwi_p (lowbnd))\n+    {\n+      /* Adjust the index by the low bound of the array domain\n+\t (normally zero but 1 in Fortran).  */\n+      unsigned HOST_WIDE_INT lb = tree_to_uhwi (lowbnd);\n+      orng[0] -= lb;\n+      orng[1] -= lb;\n+    }\n+\n+  tree eltype = TREE_TYPE (aref);\n+  tree tpsize = TYPE_SIZE_UNIT (eltype);\n+  if (!tpsize || TREE_CODE (tpsize) != INTEGER_CST)\n+    {\n+      pref->add_max_offset ();\n+      return true;\n+    }\n+\n+  offset_int sz = wi::to_offset (tpsize);\n+  orng[0] *= sz;\n+  orng[1] *= sz;\n+\n+  if (ostype && TREE_CODE (eltype) == ARRAY_TYPE)\n+    {\n+      /* Except for the permissive raw memory functions which use\n+\t the size of the whole object determined above, use the size\n+\t of the referenced array.  Because the overall offset is from\n+\t the beginning of the complete array object add this overall\n+\t offset to the size of array.  */\n+      offset_int sizrng[2] =\n+\t{\n+\t pref->offrng[0] + orng[0] + sz,\n+\t pref->offrng[1] + orng[1] + sz\n+\t};\n+      if (sizrng[1] < sizrng[0])\n+\tstd::swap (sizrng[0], sizrng[1]);\n+      if (sizrng[0] >= 0 && sizrng[0] <= pref->sizrng[0])\n+\tpref->sizrng[0] = sizrng[0];\n+      if (sizrng[1] >= 0 && sizrng[1] <= pref->sizrng[1])\n+\tpref->sizrng[1] = sizrng[1];\n+    }\n+\n+  pref->add_offset (orng[0], orng[1]);\n+  return true;\n+}\n+\n+/* A helper of compute_objsize_r() to determine the size from MEM_REF\n+   MREF.  Return true on success and false on failure.  */\n+\n+static bool\n+handle_mem_ref (tree mref, int ostype, access_ref *pref,\n+\t\tssa_name_limit_t &snlim, pointer_query *qry)\n+{\n+  gcc_assert (TREE_CODE (mref) == MEM_REF);\n+\n+  ++pref->deref;\n+\n+  if (VECTOR_TYPE_P (TREE_TYPE (mref)))\n+    {\n+      /* Hack: Handle MEM_REFs of vector types as those to complete\n+\t objects; those may be synthesized from multiple assignments\n+\t to consecutive data members (see PR 93200 and 96963).\n+\t FIXME: Vectorized assignments should only be present after\n+\t vectorization so this hack is only necessary after it has\n+\t run and could be avoided in calls from prior passes (e.g.,\n+\t tree-ssa-strlen.c).\n+\t FIXME: Deal with this more generally, e.g., by marking up\n+\t such MEM_REFs at the time they're created.  */\n+      ostype = 0;\n+    }\n+\n+  tree mrefop = TREE_OPERAND (mref, 0);\n+  if (!compute_objsize_r (mrefop, ostype, pref, snlim, qry))\n+    return false;\n+\n+  offset_int orng[2];\n+  tree off = pref->eval (TREE_OPERAND (mref, 1));\n+  range_query *const rvals = qry ? qry->rvals : NULL;\n+  if (!get_offset_range (off, NULL, orng, rvals))\n+    {\n+      /* Set ORNG to the maximum offset representable in ptrdiff_t.  */\n+      orng[1] = wi::to_offset (TYPE_MAX_VALUE (ptrdiff_type_node));\n+      orng[0] = -orng[1] - 1;\n+    }\n+\n+  pref->add_offset (orng[0], orng[1]);\n+  return true;\n+}\n+\n+/* Helper to compute the size of the object referenced by the PTR\n+   expression which must have pointer type, using Object Size type\n+   OSTYPE (only the least significant 2 bits are used).\n+   On success, sets PREF->REF to the DECL of the referenced object\n+   if it's unique, otherwise to null, PREF->OFFRNG to the range of\n+   offsets into it, and PREF->SIZRNG to the range of sizes of\n+   the object(s).\n+   SNLIM is used to avoid visiting the same PHI operand multiple\n+   times, and, when nonnull, RVALS to determine range information.\n+   Returns true on success, false when a meaningful size (or range)\n+   cannot be determined.\n+\n+   The function is intended for diagnostics and should not be used\n+   to influence code generation or optimization.  */\n+\n+static bool\n+compute_objsize_r (tree ptr, int ostype, access_ref *pref,\n+\t\t   ssa_name_limit_t &snlim, pointer_query *qry)\n+{\n+  STRIP_NOPS (ptr);\n+\n+  const bool addr = TREE_CODE (ptr) == ADDR_EXPR;\n+  if (addr)\n+    {\n+      --pref->deref;\n+      ptr = TREE_OPERAND (ptr, 0);\n+    }\n+\n+  if (DECL_P (ptr))\n+    {\n+      pref->ref = ptr;\n+\n+      if (!addr && POINTER_TYPE_P (TREE_TYPE (ptr)))\n+\t{\n+\t  /* Set the maximum size if the reference is to the pointer\n+\t     itself (as opposed to what it points to), and clear\n+\t     BASE0 since the offset isn't necessarily zero-based.  */\n+\t  pref->set_max_size_range ();\n+\t  pref->base0 = false;\n+\t  return true;\n+\t}\n+\n+      if (tree size = decl_init_size (ptr, false))\n+\tif (TREE_CODE (size) == INTEGER_CST)\n+\t  {\n+\t    pref->sizrng[0] = pref->sizrng[1] = wi::to_offset (size);\n+\t    return true;\n+\t  }\n+\n+      pref->set_max_size_range ();\n+      return true;\n+    }\n+\n+  const tree_code code = TREE_CODE (ptr);\n+  range_query *const rvals = qry ? qry->rvals : NULL;\n+\n+  if (code == BIT_FIELD_REF)\n+    {\n+      tree ref = TREE_OPERAND (ptr, 0);\n+      if (!compute_objsize_r (ref, ostype, pref, snlim, qry))\n+\treturn false;\n+\n+      offset_int off = wi::to_offset (pref->eval (TREE_OPERAND (ptr, 2)));\n+      pref->add_offset (off / BITS_PER_UNIT);\n+      return true;\n+    }\n+\n+  if (code == COMPONENT_REF)\n+    {\n+      tree ref = TREE_OPERAND (ptr, 0);\n+      if (TREE_CODE (TREE_TYPE (ref)) == UNION_TYPE)\n+\t/* In accesses through union types consider the entire unions\n+\t   rather than just their members.  */\n+\tostype = 0;\n+      tree field = TREE_OPERAND (ptr, 1);\n+\n+      if (ostype == 0)\n+\t{\n+\t  /* In OSTYPE zero (for raw memory functions like memcpy), use\n+\t     the maximum size instead if the identity of the enclosing\n+\t     object cannot be determined.  */\n+\t  if (!compute_objsize_r (ref, ostype, pref, snlim, qry))\n+\t    return false;\n+\n+\t  /* Otherwise, use the size of the enclosing object and add\n+\t     the offset of the member to the offset computed so far.  */\n+\t  tree offset = byte_position (field);\n+\t  if (TREE_CODE (offset) == INTEGER_CST)\n+\t    pref->add_offset (wi::to_offset (offset));\n+\t  else\n+\t    pref->add_max_offset ();\n+\n+\t  if (!pref->ref)\n+\t    /* REF may have been already set to an SSA_NAME earlier\n+\t       to provide better context for diagnostics.  In that case,\n+\t       leave it unchanged.  */\n+\t    pref->ref = ref;\n+\t  return true;\n+\t}\n+\n+      pref->ref = field;\n+\n+      if (!addr && POINTER_TYPE_P (TREE_TYPE (field)))\n+\t{\n+\t  /* Set maximum size if the reference is to the pointer member\n+\t     itself (as opposed to what it points to).  */\n+\t  pref->set_max_size_range ();\n+\t  return true;\n+\t}\n+\n+      /* SAM is set for array members that might need special treatment.  */\n+      special_array_member sam;\n+      tree size = component_ref_size (ptr, &sam);\n+      if (sam == special_array_member::int_0)\n+\tpref->sizrng[0] = pref->sizrng[1] = 0;\n+      else if (!pref->trail1special && sam == special_array_member::trail_1)\n+\tpref->sizrng[0] = pref->sizrng[1] = 1;\n+      else if (size && TREE_CODE (size) == INTEGER_CST)\n+\tpref->sizrng[0] = pref->sizrng[1] = wi::to_offset (size);\n+      else\n+\t{\n+\t  /* When the size of the member is unknown it's either a flexible\n+\t     array member or a trailing special array member (either zero\n+\t     length or one-element).  Set the size to the maximum minus\n+\t     the constant size of the type.  */\n+\t  pref->sizrng[0] = 0;\n+\t  pref->sizrng[1] = wi::to_offset (TYPE_MAX_VALUE (ptrdiff_type_node));\n+\t  if (tree recsize = TYPE_SIZE_UNIT (TREE_TYPE (ref)))\n+\t    if (TREE_CODE (recsize) == INTEGER_CST)\n+\t      pref->sizrng[1] -= wi::to_offset (recsize);\n+\t}\n+      return true;\n+    }\n+\n+  if (code == ARRAY_REF)\n+    return handle_array_ref (ptr, addr, ostype, pref, snlim, qry);\n+\n+  if (code == MEM_REF)\n+    return handle_mem_ref (ptr, ostype, pref, snlim, qry);\n+\n+  if (code == TARGET_MEM_REF)\n+    {\n+      tree ref = TREE_OPERAND (ptr, 0);\n+      if (!compute_objsize_r (ref, ostype, pref, snlim, qry))\n+\treturn false;\n+\n+      /* TODO: Handle remaining operands.  Until then, add maximum offset.  */\n+      pref->ref = ptr;\n+      pref->add_max_offset ();\n+      return true;\n+    }\n+\n+  if (code == INTEGER_CST)\n+    {\n+      /* Pointer constants other than null are most likely the result\n+\t of erroneous null pointer addition/subtraction.  Set size to\n+\t zero.  For null pointers, set size to the maximum for now\n+\t since those may be the result of jump threading.  */\n+      if (integer_zerop (ptr))\n+\tpref->set_max_size_range ();\n+      else\n+\tpref->sizrng[0] = pref->sizrng[1] = 0;\n+      pref->ref = ptr;\n+\n+      return true;\n+    }\n+\n+  if (code == STRING_CST)\n+    {\n+      pref->sizrng[0] = pref->sizrng[1] = TREE_STRING_LENGTH (ptr);\n+      pref->ref = ptr;\n+      return true;\n+    }\n+\n+  if (code == POINTER_PLUS_EXPR)\n+    {\n+      tree ref = TREE_OPERAND (ptr, 0);\n+      if (!compute_objsize_r (ref, ostype, pref, snlim, qry))\n+\treturn false;\n+\n+      /* Clear DEREF since the offset is being applied to the target\n+\t of the dereference.  */\n+      pref->deref = 0;\n+\n+      offset_int orng[2];\n+      tree off = pref->eval (TREE_OPERAND (ptr, 1));\n+      if (get_offset_range (off, NULL, orng, rvals))\n+\tpref->add_offset (orng[0], orng[1]);\n+      else\n+\tpref->add_max_offset ();\n+      return true;\n+    }\n+\n+  if (code == VIEW_CONVERT_EXPR)\n+    {\n+      ptr = TREE_OPERAND (ptr, 0);\n+      return compute_objsize_r (ptr, ostype, pref, snlim, qry);\n+    }\n+\n+  if (code == SSA_NAME)\n+    {\n+      if (!snlim.next ())\n+\treturn false;\n+\n+      /* Only process an SSA_NAME if the recursion limit has not yet\n+\t been reached.  */\n+      if (qry)\n+\t{\n+\t  if (++qry->depth)\n+\t    qry->max_depth = qry->depth;\n+\t  if (const access_ref *cache_ref = qry->get_ref (ptr))\n+\t    {\n+\t      /* If the pointer is in the cache set *PREF to what it refers\n+\t\t to and return success.  */\n+\t      *pref = *cache_ref;\n+\t      return true;\n+\t    }\n+\t}\n+\n+      gimple *stmt = SSA_NAME_DEF_STMT (ptr);\n+      if (is_gimple_call (stmt))\n+\t{\n+\t  /* If STMT is a call to an allocation function get the size\n+\t     from its argument(s).  If successful, also set *PREF->REF\n+\t     to PTR for the caller to include in diagnostics.  */\n+\t  wide_int wr[2];\n+\t  if (gimple_call_alloc_size (stmt, wr, rvals))\n+\t    {\n+\t      pref->ref = ptr;\n+\t      pref->sizrng[0] = offset_int::from (wr[0], UNSIGNED);\n+\t      pref->sizrng[1] = offset_int::from (wr[1], UNSIGNED);\n+\t      /* Constrain both bounds to a valid size.  */\n+\t      offset_int maxsize = wi::to_offset (max_object_size ());\n+\t      if (pref->sizrng[0] > maxsize)\n+\t\tpref->sizrng[0] = maxsize;\n+\t      if (pref->sizrng[1] > maxsize)\n+\t\tpref->sizrng[1] = maxsize;\n+\t    }\n+\t  else\n+\t    {\n+\t      /* For functions known to return one of their pointer arguments\n+\t\t try to determine what the returned pointer points to, and on\n+\t\t success add OFFRNG which was set to the offset added by\n+\t\t the function (e.g., memchr) to the overall offset.  */\n+\t      bool past_end;\n+\t      offset_int offrng[2];\n+\t      if (tree ret = gimple_call_return_array (stmt, offrng,\n+\t\t\t\t\t\t       &past_end, rvals))\n+\t\t{\n+\t\t  if (!compute_objsize_r (ret, ostype, pref, snlim, qry))\n+\t\t    return false;\n+\n+\t\t  /* Cap OFFRNG[1] to at most the remaining size of\n+\t\t     the object.  */\n+\t\t  offset_int remrng[2];\n+\t\t  remrng[1] = pref->size_remaining (remrng);\n+\t\t  if (remrng[1] != 0 && !past_end)\n+\t\t    /* Decrement the size for functions that never return\n+\t\t       a past-the-end pointer.  */\n+\t\t    remrng[1] -= 1;\n+\n+\t\t  if (remrng[1] < offrng[1])\n+\t\t    offrng[1] = remrng[1];\n+\t\t  pref->add_offset (offrng[0], offrng[1]);\n+\t\t}\n+\t      else\n+\t\t{\n+\t\t  /* For other calls that might return arbitrary pointers\n+\t\t     including into the middle of objects set the size\n+\t\t     range to maximum, clear PREF->BASE0, and also set\n+\t\t     PREF->REF to include in diagnostics.  */\n+\t\t  pref->set_max_size_range ();\n+\t\t  pref->base0 = false;\n+\t\t  pref->ref = ptr;\n+\t\t}\n+\t    }\n+\t  qry->put_ref (ptr, *pref);\n+\t  return true;\n+\t}\n+\n+      if (gimple_nop_p (stmt))\n+\t{\n+\t  /* For a function argument try to determine the byte size\n+\t     of the array from the current function declaratation\n+\t     (e.g., attribute access or related).  */\n+\t  wide_int wr[2];\n+\t  bool static_array = false;\n+\t  if (tree ref = gimple_parm_array_size (ptr, wr, &static_array))\n+\t    {\n+\t      pref->parmarray = !static_array;\n+\t      pref->sizrng[0] = offset_int::from (wr[0], UNSIGNED);\n+\t      pref->sizrng[1] = offset_int::from (wr[1], UNSIGNED);\n+\t      pref->ref = ref;\n+\t      qry->put_ref (ptr, *pref);\n+\t      return true;\n+\t    }\n+\n+\t  pref->set_max_size_range ();\n+\t  pref->base0 = false;\n+\t  pref->ref = ptr;\n+\t  qry->put_ref (ptr, *pref);\n+\t  return true;\n+\t}\n+\n+      if (gimple_code (stmt) == GIMPLE_PHI)\n+\t{\n+\t  pref->ref = ptr;\n+\t  access_ref phi_ref = *pref;\n+\t  if (!pref->get_ref (NULL, &phi_ref, ostype, &snlim, qry))\n+\t    return false;\n+\t  *pref = phi_ref;\n+\t  pref->ref = ptr;\n+\t  qry->put_ref (ptr, *pref);\n+\t  return true;\n+\t}\n+\n+      if (!is_gimple_assign (stmt))\n+\t{\n+\t  /* Clear BASE0 since the assigned pointer might point into\n+\t     the middle of the object, set the maximum size range and,\n+\t     if the SSA_NAME refers to a function argumnent, set\n+\t     PREF->REF to it.  */\n+\t  pref->base0 = false;\n+\t  pref->set_max_size_range ();\n+\t  pref->ref = ptr;\n+\t  return true;\n+\t}\n+\n+      tree_code code = gimple_assign_rhs_code (stmt);\n+\n+      if (code == MAX_EXPR || code == MIN_EXPR)\n+\t{\n+\t  if (!handle_min_max_size (stmt, ostype, pref, snlim, qry))\n+\t    return false;\n+\t  qry->put_ref (ptr, *pref);\n+\t  return true;\n+\t}\n+\n+      tree rhs = gimple_assign_rhs1 (stmt);\n+\n+      if (code == ASSERT_EXPR)\n+\t{\n+\t  rhs = TREE_OPERAND (rhs, 0);\n+\t  return compute_objsize_r (rhs, ostype, pref, snlim, qry);\n+\t}\n+\n+      if (code == POINTER_PLUS_EXPR\n+\t  && TREE_CODE (TREE_TYPE (rhs)) == POINTER_TYPE)\n+\t{\n+\t  /* Compute the size of the object first. */\n+\t  if (!compute_objsize_r (rhs, ostype, pref, snlim, qry))\n+\t    return false;\n+\n+\t  offset_int orng[2];\n+\t  tree off = gimple_assign_rhs2 (stmt);\n+\t  if (get_offset_range (off, stmt, orng, rvals))\n+\t    pref->add_offset (orng[0], orng[1]);\n+\t  else\n+\t    pref->add_max_offset ();\n+\t  qry->put_ref (ptr, *pref);\n+\t  return true;\n+\t}\n+\n+      if (code == ADDR_EXPR\n+\t  || code == SSA_NAME)\n+\treturn compute_objsize_r (rhs, ostype, pref, snlim, qry);\n+\n+      /* (This could also be an assignment from a nonlocal pointer.)  Save\n+\t PTR to mention in diagnostics but otherwise treat it as a pointer\n+\t to an unknown object.  */\n+      pref->ref = rhs;\n+      pref->base0 = false;\n+      pref->set_max_size_range ();\n+      return true;\n+    }\n+\n+  /* Assume all other expressions point into an unknown object\n+     of the maximum valid size.  */\n+  pref->ref = ptr;\n+  pref->base0 = false;\n+  pref->set_max_size_range ();\n+  if (TREE_CODE (ptr) == SSA_NAME)\n+    qry->put_ref (ptr, *pref);\n+  return true;\n+}\n+\n+/* A \"public\" wrapper around the above.  Clients should use this overload\n+   instead.  */\n+\n+tree\n+compute_objsize (tree ptr, int ostype, access_ref *pref,\n+\t\t range_query *rvals /* = NULL */)\n+{\n+  pointer_query qry;\n+  qry.rvals = rvals;\n+  ssa_name_limit_t snlim;\n+  if (!compute_objsize_r (ptr, ostype, pref, snlim, &qry))\n+    return NULL_TREE;\n+\n+  offset_int maxsize = pref->size_remaining ();\n+  if (pref->base0 && pref->offrng[0] < 0 && pref->offrng[1] >= 0)\n+    pref->offrng[0] = 0;\n+  return wide_int_to_tree (sizetype, maxsize);\n+}\n+\n+/* Transitional wrapper.  The function should be removed once callers\n+   transition to the pointer_query API.  */\n+\n+tree\n+compute_objsize (tree ptr, int ostype, access_ref *pref, pointer_query *ptr_qry)\n+{\n+  pointer_query qry;\n+  if (ptr_qry)\n+    ptr_qry->depth = 0;\n+  else\n+    ptr_qry = &qry;\n+\n+  ssa_name_limit_t snlim;\n+  if (!compute_objsize_r (ptr, ostype, pref, snlim, ptr_qry))\n+    return NULL_TREE;\n+\n+  offset_int maxsize = pref->size_remaining ();\n+  if (pref->base0 && pref->offrng[0] < 0 && pref->offrng[1] >= 0)\n+    pref->offrng[0] = 0;\n+  return wide_int_to_tree (sizetype, maxsize);\n+}\n+\n+/* Legacy wrapper around the above.  The function should be removed\n+   once callers transition to one of the two above.  */\n+\n+tree\n+compute_objsize (tree ptr, int ostype, tree *pdecl /* = NULL */,\n+\t\t tree *poff /* = NULL */, range_query *rvals /* = NULL */)\n+{\n+  /* Set the initial offsets to zero and size to negative to indicate\n+     none has been computed yet.  */\n+  access_ref ref;\n+  tree size = compute_objsize (ptr, ostype, &ref, rvals);\n+  if (!size || !ref.base0)\n+    return NULL_TREE;\n+\n+  if (pdecl)\n+    *pdecl = ref.ref;\n+\n+  if (poff)\n+    *poff = wide_int_to_tree (ptrdiff_type_node, ref.offrng[ref.offrng[0] < 0]);\n+\n+  return size;\n+}"}, {"sha": "6168c809ccc96243f691803d70c30352235935bd", "filename": "gcc/pointer-query.h", "status": "added", "additions": 234, "deletions": 0, "changes": 234, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fpointer-query.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Fpointer-query.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpointer-query.h?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -0,0 +1,234 @@\n+/* Definitions of the pointer_query and related classes.\n+\n+   Copyright (C) 2020-2021 Free Software Foundation, Inc.\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 3, or (at your option) any later\n+   version.\n+\n+   GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+   WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with GCC; see the file COPYING3.  If not see\n+   <http://www.gnu.org/licenses/>.  */\n+\n+#ifndef GCC_POINTER_QUERY_H\n+#define GCC_POINTER_QUERY_H\n+\n+/* Describes recursion limits used by functions that follow use-def\n+   chains of SSA_NAMEs.  */\n+\n+class ssa_name_limit_t\n+{\n+  bitmap visited;         /* Bitmap of visited SSA_NAMEs.  */\n+  unsigned ssa_def_max;   /* Longest chain of SSA_NAMEs to follow.  */\n+\n+  /* Not copyable or assignable.  */\n+  DISABLE_COPY_AND_ASSIGN (ssa_name_limit_t);\n+\n+public:\n+\n+  ssa_name_limit_t ()\n+    : visited (),\n+      ssa_def_max (param_ssa_name_def_chain_limit) { }\n+\n+  /* Set a bit for the PHI in VISITED and return true if it wasn't\n+     already set.  */\n+  bool visit_phi (tree);\n+  /* Clear a bit for the PHI in VISITED.  */\n+  void leave_phi (tree);\n+  /* Return false if the SSA_NAME chain length counter has reached\n+     the limit, otherwise increment the counter and return true.  */\n+  bool next ();\n+\n+  /* If the SSA_NAME has already been \"seen\" return a positive value.\n+     Otherwise add it to VISITED.  If the SSA_NAME limit has been\n+     reached, return a negative value.  Otherwise return zero.  */\n+  int next_phi (tree);\n+\n+  ~ssa_name_limit_t ();\n+};\n+\n+class pointer_query;\n+\n+/* Describes a reference to an object used in an access.  */\n+struct access_ref\n+{\n+  /* Set the bounds of the reference to at most as many bytes\n+     as the first argument or unknown when null, and at least\n+     one when the second argument is true unless the first one\n+     is a constant zero.  */\n+  access_ref (tree = NULL_TREE, bool = false);\n+\n+  /* Return the PHI node REF refers to or null if it doesn't.  */\n+  gphi *phi () const;\n+\n+  /* Return the object to which REF refers.  */\n+  tree get_ref (vec<access_ref> *, access_ref * = NULL, int = 1,\n+\t\tssa_name_limit_t * = NULL, pointer_query * = NULL) const;\n+\n+  /* Return true if OFFRNG is the constant zero.  */\n+  bool offset_zero () const\n+  {\n+    return offrng[0] == 0 && offrng[1] == 0;\n+  }\n+\n+  /* Return true if OFFRNG is bounded to a subrange of offset values\n+     valid for the largest possible object.  */\n+  bool offset_bounded () const;\n+\n+  /* Return the maximum amount of space remaining and if non-null, set\n+     argument to the minimum.  */\n+  offset_int size_remaining (offset_int * = NULL) const;\n+\n+/* Return true if the offset and object size are in range for SIZE.  */\n+  bool offset_in_range (const offset_int &) const;\n+\n+  /* Return true if *THIS is an access to a declared object.  */\n+  bool ref_declared () const\n+  {\n+    return DECL_P (ref) && base0 && deref < 1;\n+  }\n+\n+  /* Set the size range to the maximum.  */\n+  void set_max_size_range ()\n+  {\n+    sizrng[0] = 0;\n+    sizrng[1] = wi::to_offset (max_object_size ());\n+  }\n+\n+  /* Add OFF to the offset range.  */\n+  void add_offset (const offset_int &off)\n+  {\n+    add_offset (off, off);\n+  }\n+\n+  /* Add the range [MIN, MAX] to the offset range.  */\n+  void add_offset (const offset_int &, const offset_int &);\n+\n+  /* Add the maximum representable offset to the offset range.  */\n+  void add_max_offset ()\n+  {\n+    offset_int maxoff = wi::to_offset (TYPE_MAX_VALUE (ptrdiff_type_node));\n+    add_offset (-maxoff - 1, maxoff);\n+  }\n+\n+  /* Issue an informational message describing the target of an access\n+     with the given mode.  */\n+  void inform_access (access_mode) const;\n+\n+  /* Reference to the accessed object(s).  */\n+  tree ref;\n+\n+  /* Range of byte offsets into and sizes of the object(s).  */\n+  offset_int offrng[2];\n+  offset_int sizrng[2];\n+  /* The minimum and maximum offset computed.  */\n+  offset_int offmax[2];\n+  /* Range of the bound of the access: denotes that the access\n+     is at least BNDRNG[0] bytes but no more than BNDRNG[1].\n+     For string functions the size of the actual access is\n+     further constrained by the length of the string.  */\n+  offset_int bndrng[2];\n+\n+  /* Used to fold integer expressions when called from front ends.  */\n+  tree (*eval)(tree);\n+  /* Positive when REF is dereferenced, negative when its address is\n+     taken.  */\n+  int deref;\n+  /* Set if trailing one-element arrays should be treated as flexible\n+     array members.  */\n+  bool trail1special;\n+  /* Set if valid offsets must start at zero (for declared and allocated\n+     objects but not for others referenced by pointers).  */\n+  bool base0;\n+  /* Set if REF refers to a function array parameter not declared\n+     static.  */\n+  bool parmarray;\n+};\n+\n+class range_query;\n+\n+/* Queries and caches compute_objsize results.  */\n+class pointer_query\n+{\n+  DISABLE_COPY_AND_ASSIGN (pointer_query);\n+\n+public:\n+  /* Type of the two-level cache object defined by clients of the class\n+     to have pointer SSA_NAMEs cached for speedy access.  */\n+  struct cache_type\n+  {\n+    /* 1-based indices into cache.  */\n+    vec<unsigned> indices;\n+    /* The cache itself.  */\n+    vec<access_ref> access_refs;\n+  };\n+\n+  /* Construct an object with the given Ranger instance and cache.  */\n+  explicit pointer_query (range_query * = NULL, cache_type * = NULL);\n+\n+  /* Retrieve the access_ref for a variable from cache if it's there.  */\n+  const access_ref* get_ref (tree, int = 1) const;\n+\n+  /* Retrieve the access_ref for a variable from cache or compute it.  */\n+  bool get_ref (tree, access_ref*, int = 1);\n+\n+  /* Add an access_ref for the SSA_NAME to the cache.  */\n+  void put_ref (tree, const access_ref&, int = 1);\n+\n+  /* Flush the cache.  */\n+  void flush_cache ();\n+\n+  /* A Ranger instance.  May be null to use global ranges.  */\n+  range_query *rvals;\n+  /* Cache of SSA_NAMEs.  May be null to disable caching.  */\n+  cache_type *var_cache;\n+\n+  /* Cache performance counters.  */\n+  mutable unsigned hits;\n+  mutable unsigned misses;\n+  mutable unsigned failures;\n+  mutable unsigned depth;\n+  mutable unsigned max_depth;\n+};\n+\n+/* Describes a pair of references used in an access by built-in\n+   functions like memcpy.  */\n+struct access_data\n+{\n+  /* Set the access to at most MAXWRITE and MAXREAD bytes, and\n+     at least 1 when MINWRITE or MINREAD, respectively, is set.  */\n+  access_data (tree expr, access_mode mode,\n+\t       tree maxwrite = NULL_TREE, bool minwrite = false,\n+\t       tree maxread = NULL_TREE, bool minread = false)\n+    : call (expr),\n+      dst (maxwrite, minwrite), src (maxread, minread), mode (mode) { }\n+\n+  /* Built-in function call.  */\n+  tree call;\n+  /* Destination and source of the access.  */\n+  access_ref dst, src;\n+  /* Read-only for functions like memcmp or strlen, write-only\n+     for memset, read-write for memcpy or strcat.  */\n+  access_mode mode;\n+};\n+\n+class range_query;\n+extern tree gimple_call_alloc_size (gimple *, wide_int[2] = NULL,\n+\t\t\t\t    range_query * = NULL);\n+extern tree gimple_parm_array_size (tree, wide_int[2], bool * = NULL);\n+\n+extern tree compute_objsize (tree, int, access_ref *, range_query * = NULL);\n+/* Legacy/transitional API.  Should not be used in new code.  */\n+extern tree compute_objsize (tree, int, access_ref *, pointer_query *);\n+extern tree compute_objsize (tree, int, tree * = NULL, tree * = NULL,\n+\t\t\t     range_query * = NULL);\n+\n+#endif   // GCC_POINTER_QUERY_H"}, {"sha": "1f5b1370a95a448a2b54fe64c21a00cc1ba04303", "filename": "gcc/tree-pass.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Ftree-pass.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Ftree-pass.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-pass.h?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -428,6 +428,7 @@ extern gimple_opt_pass *make_pass_oacc_device_lower (gcc::context *ctxt);\n extern gimple_opt_pass *make_pass_omp_device_lower (gcc::context *ctxt);\n extern gimple_opt_pass *make_pass_object_sizes (gcc::context *ctxt);\n extern gimple_opt_pass *make_pass_early_object_sizes (gcc::context *ctxt);\n+extern gimple_opt_pass *make_pass_warn_access (gcc::context *ctxt);\n extern gimple_opt_pass *make_pass_warn_printf (gcc::context *ctxt);\n extern gimple_opt_pass *make_pass_strlen (gcc::context *ctxt);\n extern gimple_opt_pass *make_pass_fold_builtins (gcc::context *ctxt);"}, {"sha": "15391da81048b148f312d87af2522910282a511b", "filename": "gcc/tree-ssa-strlen.c", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Ftree-ssa-strlen.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Ftree-ssa-strlen.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-strlen.c?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -30,6 +30,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"ssa.h\"\n #include \"cgraph.h\"\n #include \"gimple-pretty-print.h\"\n+#include \"gimple-ssa-warn-access.h\"\n #include \"gimple-ssa-warn-restrict.h\"\n #include \"fold-const.h\"\n #include \"stor-layout.h\"\n@@ -47,6 +48,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"tree-ssa-strlen.h\"\n #include \"tree-hash-traits.h\"\n #include \"builtins.h\"\n+#include \"pointer-query.h\"\n #include \"target.h\"\n #include \"diagnostic-core.h\"\n #include \"diagnostic.h\""}, {"sha": "e923e67b694287c012d91f4e83bc0af92f03b788", "filename": "gcc/tree.c", "status": "modified", "additions": 59, "deletions": 0, "changes": 59, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Ftree.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Ftree.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.c?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -14380,6 +14380,65 @@ valid_new_delete_pair_p (tree new_asm, tree delete_asm)\n   return false;\n }\n \n+/* Return the zero-based number corresponding to the argument being\n+   deallocated if FNDECL is a deallocation function or an out-of-bounds\n+   value if it isn't.  */\n+\n+unsigned\n+fndecl_dealloc_argno (tree fndecl)\n+{\n+  /* A call to operator delete isn't recognized as one to a built-in.  */\n+  if (DECL_IS_OPERATOR_DELETE_P (fndecl))\n+    {\n+      if (DECL_IS_REPLACEABLE_OPERATOR (fndecl))\n+\treturn 0;\n+\n+      /* Avoid placement delete that's not been inlined.  */\n+      tree fname = DECL_ASSEMBLER_NAME (fndecl);\n+      if (id_equal (fname, \"_ZdlPvS_\")       // ordinary form\n+\t  || id_equal (fname, \"_ZdaPvS_\"))   // array form\n+\treturn UINT_MAX;\n+      return 0;\n+    }\n+\n+  /* TODO: Handle user-defined functions with attribute malloc?  Handle\n+     known non-built-ins like fopen?  */\n+  if (fndecl_built_in_p (fndecl, BUILT_IN_NORMAL))\n+    {\n+      switch (DECL_FUNCTION_CODE (fndecl))\n+\t{\n+\tcase BUILT_IN_FREE:\n+\tcase BUILT_IN_REALLOC:\n+\t  return 0;\n+\tdefault:\n+\t  break;\n+\t}\n+      return UINT_MAX;\n+    }\n+\n+  tree attrs = DECL_ATTRIBUTES (fndecl);\n+  if (!attrs)\n+    return UINT_MAX;\n+\n+  for (tree atfree = attrs;\n+       (atfree = lookup_attribute (\"*dealloc\", atfree));\n+       atfree = TREE_CHAIN (atfree))\n+    {\n+      tree alloc = TREE_VALUE (atfree);\n+      if (!alloc)\n+\tcontinue;\n+\n+      tree pos = TREE_CHAIN (alloc);\n+      if (!pos)\n+\treturn 0;\n+\n+      pos = TREE_VALUE (pos);\n+      return TREE_INT_CST_LOW (pos) - 1;\n+    }\n+\n+  return UINT_MAX;\n+}\n+\n #if CHECKING_P\n \n namespace selftest {"}, {"sha": "972ceb370f87385a2e3555ab70777453f20d73b5", "filename": "gcc/tree.h", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Ftree.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2a837de28ee94b4ec201059a9a7aaa852e6808da/gcc%2Ftree.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.h?ref=2a837de28ee94b4ec201059a9a7aaa852e6808da", "patch": "@@ -6468,4 +6468,9 @@ extern void suppress_warning (tree, opt_code = all_warnings, bool = true)\n /* Copy warning disposition from one expression to another.  */\n extern void copy_warning (tree, const_tree);\n \n+/* Return the zero-based number corresponding to the argument being\n+   deallocated if FNDECL is a deallocation function or an out-of-bounds\n+   value if it isn't.  */\n+extern unsigned fndecl_dealloc_argno (tree);\n+\n #endif  /* GCC_TREE_H  */"}]}