{"sha": "d8251d001b3507ffb80b26f4d17f1daa99a5dc4a", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDgyNTFkMDAxYjM1MDdmZmI4MGIyNmY0ZDE3ZjFkYWE5OWE1ZGM0YQ==", "commit": {"author": {"name": "Hristian Kirtchev", "email": "kirtchev@adacore.com", "date": "2018-08-21T14:44:41Z"}, "committer": {"name": "Pierre-Marie de Rodat", "email": "pmderodat@gcc.gnu.org", "date": "2018-08-21T14:44:41Z"}, "message": "[Ada] Dynamically resizable, load factor-based hash table\n\nThis patch introduces a dynamically resizable, load factor-based hash\ntable in unit GNAT.Dynamic_HTables.\n\n2018-08-21  Hristian Kirtchev  <kirtchev@adacore.com>\n\ngcc/ada/\n\n\t* libgnat/g-dynhta.adb, libgnat/g-dynhta.ads: New package\n\tDynamic_HTable.\n\ngcc/testsuite/\n\n\t* gnat.dg/dynhash.adb: New testcase.\n\nFrom-SVN: r263709", "tree": {"sha": "7c67c739e2cc9d5d9580bff4999fa3d7cd340002", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/7c67c739e2cc9d5d9580bff4999fa3d7cd340002"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d8251d001b3507ffb80b26f4d17f1daa99a5dc4a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d8251d001b3507ffb80b26f4d17f1daa99a5dc4a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d8251d001b3507ffb80b26f4d17f1daa99a5dc4a", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d8251d001b3507ffb80b26f4d17f1daa99a5dc4a/comments", "author": {"login": "kirtchev-adacore", "id": 60669983, "node_id": "MDQ6VXNlcjYwNjY5OTgz", "avatar_url": "https://avatars.githubusercontent.com/u/60669983?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kirtchev-adacore", "html_url": "https://github.com/kirtchev-adacore", "followers_url": "https://api.github.com/users/kirtchev-adacore/followers", "following_url": "https://api.github.com/users/kirtchev-adacore/following{/other_user}", "gists_url": "https://api.github.com/users/kirtchev-adacore/gists{/gist_id}", "starred_url": "https://api.github.com/users/kirtchev-adacore/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kirtchev-adacore/subscriptions", "organizations_url": "https://api.github.com/users/kirtchev-adacore/orgs", "repos_url": "https://api.github.com/users/kirtchev-adacore/repos", "events_url": "https://api.github.com/users/kirtchev-adacore/events{/privacy}", "received_events_url": "https://api.github.com/users/kirtchev-adacore/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "f20b5ef46d7338e626286721a74e3fd3385e8be0", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f20b5ef46d7338e626286721a74e3fd3385e8be0", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f20b5ef46d7338e626286721a74e3fd3385e8be0"}], "stats": {"total": 1903, "additions": 1870, "deletions": 33}, "files": [{"sha": "31420a3d663f0ad852e463e6c5461500f0550f56", "filename": "gcc/ada/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d8251d001b3507ffb80b26f4d17f1daa99a5dc4a/gcc%2Fada%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d8251d001b3507ffb80b26f4d17f1daa99a5dc4a/gcc%2Fada%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fada%2FChangeLog?ref=d8251d001b3507ffb80b26f4d17f1daa99a5dc4a", "patch": "@@ -1,3 +1,8 @@\n+2018-08-21  Hristian Kirtchev  <kirtchev@adacore.com>\n+\n+\t* libgnat/g-dynhta.adb, libgnat/g-dynhta.ads: New package\n+\tDynamic_HTable.\n+\n 2018-08-21  Javier Miranda  <miranda@adacore.com>\n \n \t* checks.ads (Determine_Range): Adding documentation."}, {"sha": "b093e7928910d11ac0edfab26e96d836bb88721a", "filename": "gcc/ada/libgnat/g-dynhta.adb", "status": "modified", "additions": 830, "deletions": 4, "changes": 834, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d8251d001b3507ffb80b26f4d17f1daa99a5dc4a/gcc%2Fada%2Flibgnat%2Fg-dynhta.adb", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d8251d001b3507ffb80b26f4d17f1daa99a5dc4a/gcc%2Fada%2Flibgnat%2Fg-dynhta.adb", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fada%2Flibgnat%2Fg-dynhta.adb?ref=d8251d001b3507ffb80b26f4d17f1daa99a5dc4a", "patch": "@@ -38,11 +38,10 @@ package body GNAT.Dynamic_HTables is\n    -------------------\n \n    package body Static_HTable is\n-\n       function Get_Non_Null (T : Instance) return Elmt_Ptr;\n       --  Returns Null_Ptr if Iterator_Started is False or if the Table is\n-      --  empty. Returns Iterator_Ptr if non null, or the next non null\n-      --  element in table if any.\n+      --  empty. Returns Iterator_Ptr if non null, or the next non null element\n+      --  in table if any.\n \n       ---------\n       -- Get --\n@@ -363,7 +362,834 @@ package body GNAT.Dynamic_HTables is\n       begin\n          E.Next := Next;\n       end Set_Next;\n-\n    end Simple_HTable;\n \n+   --------------------\n+   -- Dynamic_HTable --\n+   --------------------\n+\n+   package body Dynamic_HTable is\n+      Minimum_Size : constant Bucket_Range_Type := 32;\n+      --  Minimum size of the buckets\n+\n+      Safe_Compression_Size : constant Bucket_Range_Type :=\n+                                Minimum_Size * Compression_Factor;\n+      --  Maximum safe size for hash table compression. Beyond this size, a\n+      --  compression will violate the minimum size constraint on the buckets.\n+\n+      Safe_Expansion_Size : constant Bucket_Range_Type :=\n+                              Bucket_Range_Type'Last / Expansion_Factor;\n+      --  Maximum safe size for hash table expansion. Beyond this size, an\n+      --  expansion will overflow the buckets.\n+\n+      procedure Destroy_Buckets (Bkts : Bucket_Table_Ptr);\n+      pragma Inline (Destroy_Buckets);\n+      --  Destroy all nodes within buckets Bkts\n+\n+      procedure Detach (Nod : Node_Ptr);\n+      pragma Inline (Detach);\n+      --  Detach node Nod from the bucket it resides in\n+\n+      procedure Ensure_Circular (Head : Node_Ptr);\n+      pragma Inline (Ensure_Circular);\n+      --  Ensure that dummy head Head is circular with respect to itself\n+\n+      procedure Ensure_Created (T : Instance);\n+      pragma Inline (Ensure_Created);\n+      --  Verify that hash table T is created. Raise Not_Created if this is not\n+      --  the case.\n+\n+      procedure Ensure_Unlocked (T : Instance);\n+      pragma Inline (Ensure_Unlocked);\n+      --  Verify that hash table T is unlocked. Raise Table_Locked if this is\n+      --  not the case.\n+\n+      function Find_Bucket\n+        (Bkts : Bucket_Table_Ptr;\n+         Key  : Key_Type) return Node_Ptr;\n+      pragma Inline (Find_Bucket);\n+      --  Find the bucket among buckets Bkts which corresponds to key Key, and\n+      --  return its dummy head.\n+\n+      function Find_Node (Head : Node_Ptr; Key : Key_Type) return Node_Ptr;\n+      pragma Inline (Find_Node);\n+      --  Traverse a bucket indicated by dummy head Head to determine whether\n+      --  there exists a node with key Key. If such a node exists, return it,\n+      --  otherwise return null.\n+\n+      procedure First_Valid_Node\n+        (T        : Instance;\n+         Low_Bkt  : Bucket_Range_Type;\n+         High_Bkt : Bucket_Range_Type;\n+         Idx      : out Bucket_Range_Type;\n+         Nod      : out Node_Ptr);\n+      pragma Inline (First_Valid_Node);\n+      --  Find the first valid node in the buckets of hash table T constrained\n+      --  by the range Low_Bkt .. High_Bkt. If such a node exists, return its\n+      --  bucket index in Idx and reference in Nod. If no such node exists,\n+      --  Idx is set to 0 and Nod to null.\n+\n+      procedure Free is\n+        new Ada.Unchecked_Deallocation (Bucket_Table, Bucket_Table_Ptr);\n+\n+      procedure Free is\n+        new Ada.Unchecked_Deallocation (Hash_Table, Instance);\n+\n+      procedure Free is\n+        new Ada.Unchecked_Deallocation (Node, Node_Ptr);\n+\n+      function Is_Valid (Iter : Iterator) return Boolean;\n+      pragma Inline (Is_Valid);\n+      --  Determine whether iterator Iter refers to a valid key-value pair\n+\n+      function Is_Valid (Nod : Node_Ptr; Head : Node_Ptr) return Boolean;\n+      pragma Inline (Is_Valid);\n+      --  Determine whether node Nod is non-null and does not refer to dummy\n+      --  head Head, thus making it valid.\n+\n+      function Load_Factor (T : Instance) return Threshold_Type;\n+      pragma Inline (Load_Factor);\n+      --  Calculate the load factor of hash table T\n+\n+      procedure Lock (T : Instance);\n+      pragma Inline (Lock);\n+      --  Lock all mutation functionality of hash table T\n+\n+      procedure Mutate_And_Rehash (T : Instance; Size : Bucket_Range_Type);\n+      pragma Inline (Mutate_And_Rehash);\n+      --  Replace the buckets of hash table T with a new set of buckets of size\n+      --  Size. Rehash all key-value pairs from the old to the new buckets.\n+\n+      procedure Prepend (Nod : Node_Ptr; Head : Node_Ptr);\n+      pragma Inline (Prepend);\n+      --  Insert node Nod immediately after dummy head Head\n+\n+      procedure Unlock (T : Instance);\n+      pragma Inline (Unlock);\n+      --  Unlock all mutation functionality of hash table T\n+\n+      ------------\n+      -- Create --\n+      ------------\n+\n+      function Create (Initial_Size : Bucket_Range_Type) return Instance is\n+         Size : constant Bucket_Range_Type :=\n+                           Bucket_Range_Type'Max (Initial_Size, Minimum_Size);\n+         --  Ensure that the buckets meet a minimum size\n+\n+         T : constant Instance := new Hash_Table;\n+\n+      begin\n+         T.Buckets      := new Bucket_Table (0 .. Size - 1);\n+         T.Initial_Size := Size;\n+\n+         return T;\n+      end Create;\n+\n+      ------------\n+      -- Delete --\n+      ------------\n+\n+      procedure Delete (T : Instance; Key : Key_Type) is\n+         procedure Compress;\n+         pragma Inline (Compress);\n+         --  Determine whether hash table T requires compression, and if so,\n+         --  half its size.\n+\n+         --------------\n+         -- Compress --\n+         --------------\n+\n+         procedure Compress is\n+            pragma Assert (T /= null);\n+            pragma Assert (T.Buckets /= null);\n+\n+            Old_Size : constant Bucket_Range_Type := T.Buckets'Length;\n+\n+         begin\n+            --  The ratio of pairs to buckets is under the desited threshold.\n+            --  Compress the hash table only when there is still room to do so.\n+\n+            if Load_Factor (T) < Compression_Threshold\n+              and then Old_Size >= Safe_Compression_Size\n+            then\n+               Mutate_And_Rehash (T, Old_Size / Compression_Factor);\n+            end if;\n+         end Compress;\n+\n+         --  Local variables\n+\n+         Head : Node_Ptr;\n+         Nod  : Node_Ptr;\n+\n+      --  Start of processing for Delete\n+\n+      begin\n+         Ensure_Created  (T);\n+         Ensure_Unlocked (T);\n+\n+         --  Obtain the dummy head of the bucket which should house the\n+         --  key-value pair.\n+\n+         Head := Find_Bucket (T.Buckets, Key);\n+\n+         --  Try to find a node in the bucket which matches the key\n+\n+         Nod := Find_Node (Head, Key);\n+\n+         --  If such a node exists, remove it from the bucket and deallocate it\n+\n+         if Is_Valid (Nod, Head) then\n+            Detach (Nod);\n+            Free   (Nod);\n+\n+            T.Pairs := T.Pairs - 1;\n+\n+            --  Compress the hash table if the load factor drops below\n+            --  Compression_Threshold.\n+\n+            Compress;\n+         end if;\n+      end Delete;\n+\n+      -------------\n+      -- Destroy --\n+      -------------\n+\n+      procedure Destroy (T : in out Instance) is\n+      begin\n+         Ensure_Created  (T);\n+         Ensure_Unlocked (T);\n+\n+         --  Destroy all nodes in all buckets\n+\n+         Destroy_Buckets (T.Buckets);\n+         Free (T.Buckets);\n+         Free (T);\n+      end Destroy;\n+\n+      ---------------------\n+      -- Destroy_Buckets --\n+      ---------------------\n+\n+      procedure Destroy_Buckets (Bkts : Bucket_Table_Ptr) is\n+         procedure Destroy_Bucket (Head : Node_Ptr);\n+         pragma Inline (Destroy_Bucket);\n+         --  Destroy all nodes in a bucket with dummy head Head\n+\n+         --------------------\n+         -- Destroy_Bucket --\n+         --------------------\n+\n+         procedure Destroy_Bucket (Head : Node_Ptr) is\n+            Nod : Node_Ptr;\n+\n+         begin\n+            --  Destroy all valid nodes which follow the dummy head\n+\n+            while Is_Valid (Head.Next, Head) loop\n+               Nod := Head.Next;\n+\n+               Detach (Nod);\n+               Free   (Nod);\n+            end loop;\n+         end Destroy_Bucket;\n+\n+      --  Start of processing for Destroy_Buckets\n+\n+      begin\n+         pragma Assert (Bkts /= null);\n+\n+         for Scan_Idx in Bkts'Range loop\n+            Destroy_Bucket (Bkts (Scan_Idx)'Access);\n+         end loop;\n+      end Destroy_Buckets;\n+\n+      ------------\n+      -- Detach --\n+      ------------\n+\n+      procedure Detach (Nod : Node_Ptr) is\n+         pragma Assert (Nod /= null);\n+\n+         Next : constant Node_Ptr := Nod.Next;\n+         Prev : constant Node_Ptr := Nod.Prev;\n+\n+      begin\n+         pragma Assert (Next /= null);\n+         pragma Assert (Prev /= null);\n+\n+         Prev.Next := Next;\n+         Next.Prev := Prev;\n+\n+         Nod.Next := null;\n+         Nod.Prev := null;\n+      end Detach;\n+\n+      ---------------------\n+      -- Ensure_Circular --\n+      ---------------------\n+\n+      procedure Ensure_Circular (Head : Node_Ptr) is\n+         pragma Assert (Head /= null);\n+\n+      begin\n+         if Head.Next = null and then Head.Prev = null then\n+            Head.Next := Head;\n+            Head.Prev := Head;\n+         end if;\n+      end Ensure_Circular;\n+\n+      --------------------\n+      -- Ensure_Created --\n+      --------------------\n+\n+      procedure Ensure_Created (T : Instance) is\n+      begin\n+         if T = null then\n+            raise Not_Created;\n+         end if;\n+      end Ensure_Created;\n+\n+      ---------------------\n+      -- Ensure_Unlocked --\n+      ---------------------\n+\n+      procedure Ensure_Unlocked (T : Instance) is\n+      begin\n+         pragma Assert (T /= null);\n+\n+         --  The hash table has at least one outstanding iterator\n+\n+         if T.Locked > 0 then\n+            raise Table_Locked;\n+         end if;\n+      end Ensure_Unlocked;\n+\n+      -----------------\n+      -- Find_Bucket --\n+      -----------------\n+\n+      function Find_Bucket\n+        (Bkts : Bucket_Table_Ptr;\n+         Key  : Key_Type) return Node_Ptr\n+      is\n+         pragma Assert (Bkts /= null);\n+\n+         Idx : constant Bucket_Range_Type := Hash (Key) mod Bkts'Length;\n+\n+      begin\n+         return Bkts (Idx)'Access;\n+      end Find_Bucket;\n+\n+      ---------------\n+      -- Find_Node --\n+      ---------------\n+\n+      function Find_Node (Head : Node_Ptr; Key : Key_Type) return Node_Ptr is\n+         pragma Assert (Head /= null);\n+\n+         Nod : Node_Ptr;\n+\n+      begin\n+         --  Traverse the nodes of the bucket, looking for a key-value pair\n+         --  with the same key.\n+\n+         Nod := Head.Next;\n+         while Is_Valid (Nod, Head) loop\n+            if Equivalent_Keys (Nod.Key, Key) then\n+               return Nod;\n+            end if;\n+\n+            Nod := Nod.Next;\n+         end loop;\n+\n+         return null;\n+      end Find_Node;\n+\n+      ----------------------\n+      -- First_Valid_Node --\n+      ----------------------\n+\n+      procedure First_Valid_Node\n+        (T        : Instance;\n+         Low_Bkt  : Bucket_Range_Type;\n+         High_Bkt : Bucket_Range_Type;\n+         Idx      : out Bucket_Range_Type;\n+         Nod      : out Node_Ptr)\n+      is\n+         Head : Node_Ptr;\n+\n+      begin\n+         pragma Assert (T /= null);\n+         pragma Assert (T.Buckets /= null);\n+\n+         --  Assume that no valid node exists\n+\n+         Idx := 0;\n+         Nod := null;\n+\n+         --  Examine the buckets of the hash table within the requested range,\n+         --  looking for the first valid node.\n+\n+         for Scan_Idx in Low_Bkt .. High_Bkt loop\n+            Head := T.Buckets (Scan_Idx)'Access;\n+\n+            --  The bucket contains at least one valid node, return the first\n+            --  such node.\n+\n+            if Is_Valid (Head.Next, Head) then\n+               Idx := Scan_Idx;\n+               Nod := Head.Next;\n+               return;\n+            end if;\n+         end loop;\n+      end First_Valid_Node;\n+\n+      ---------\n+      -- Get --\n+      ---------\n+\n+      function Get (T : Instance; Key : Key_Type) return Value_Type is\n+         Head : Node_Ptr;\n+         Nod  : Node_Ptr;\n+\n+      begin\n+         Ensure_Created (T);\n+\n+         --  Obtain the dummy head of the bucket which should house the\n+         --  key-value pair.\n+\n+         Head := Find_Bucket (T.Buckets, Key);\n+\n+         --  Try to find a node in the bucket which matches the key\n+\n+         Nod := Find_Node (Head, Key);\n+\n+         --  If such a node exists, return the value of the key-value pair\n+\n+         if Is_Valid (Nod, Head) then\n+            return Nod.Value;\n+         end if;\n+\n+         return No_Value;\n+      end Get;\n+\n+      --------------\n+      -- Has_Next --\n+      --------------\n+\n+      function Has_Next (Iter : Iterator) return Boolean is\n+         Is_OK : constant Boolean  := Is_Valid (Iter);\n+         T     : constant Instance := Iter.Table;\n+\n+      begin\n+         pragma Assert (T /= null);\n+\n+         --  The iterator is no longer valid which indicates that it has been\n+         --  exhausted. Unlock all mutation functionality of the hash table\n+         --  because the iterator cannot be advanced any further.\n+\n+         if not Is_OK then\n+            Unlock (T);\n+         end if;\n+\n+         return Is_OK;\n+      end Has_Next;\n+\n+      --------------\n+      -- Is_Valid --\n+      --------------\n+\n+      function Is_Valid (Iter : Iterator) return Boolean is\n+      begin\n+         --  The invariant of Iterate and Next ensures that the iterator always\n+         --  refers to a valid node if there exists one.\n+\n+         return Iter.Nod /= null;\n+      end Is_Valid;\n+\n+      --------------\n+      -- Is_Valid --\n+      --------------\n+\n+      function Is_Valid (Nod : Node_Ptr; Head : Node_Ptr) return Boolean is\n+      begin\n+         --  A node is valid if it is non-null, and does not refer to the dummy\n+         --  head of some bucket.\n+\n+         return Nod /= null and then Nod /= Head;\n+      end Is_Valid;\n+\n+      -------------\n+      -- Iterate --\n+      -------------\n+\n+      function Iterate (T : Instance) return Iterator is\n+         Iter : Iterator;\n+\n+      begin\n+         Ensure_Created (T);\n+         pragma Assert (T.Buckets /= null);\n+\n+         --  Initialize the iterator to reference the first valid node in\n+         --  the full range of hash table buckets. If no such node exists,\n+         --  the iterator is left in a state which does not allow it to\n+         --  advance.\n+\n+         First_Valid_Node\n+           (T        => T,\n+            Low_Bkt  => T.Buckets'First,\n+            High_Bkt => T.Buckets'Last,\n+            Idx      => Iter.Idx,\n+            Nod      => Iter.Nod);\n+\n+         --  Associate the iterator with the hash table to allow for future\n+         --  mutation functionality unlocking.\n+\n+         Iter.Table := T;\n+\n+         --  Lock all mutation functionality of the hash table while it is\n+         --  being iterated on.\n+\n+         Lock (T);\n+\n+         return Iter;\n+      end Iterate;\n+\n+      -----------------\n+      -- Load_Factor --\n+      -----------------\n+\n+      function Load_Factor (T : Instance) return Threshold_Type is\n+         pragma Assert (T /= null);\n+         pragma Assert (T.Buckets /= null);\n+\n+      begin\n+         --  The load factor is the ratio of key-value pairs to buckets\n+\n+         return Threshold_Type (T.Pairs) / Threshold_Type (T.Buckets'Length);\n+      end Load_Factor;\n+\n+      ----------\n+      -- Lock --\n+      ----------\n+\n+      procedure Lock (T : Instance) is\n+      begin\n+         --  The hash table may be locked multiple times if multiple iterators\n+         --  are operating over it.\n+\n+         T.Locked := T.Locked + 1;\n+      end Lock;\n+\n+      -----------------------\n+      -- Mutate_And_Rehash --\n+      -----------------------\n+\n+      procedure Mutate_And_Rehash (T : Instance; Size : Bucket_Range_Type) is\n+         procedure Rehash (From : Bucket_Table_Ptr; To : Bucket_Table_Ptr);\n+         pragma Inline (Rehash);\n+         --  Remove all nodes from buckets From and rehash them into buckets To\n+\n+         procedure Rehash_Bucket (Head : Node_Ptr; To : Bucket_Table_Ptr);\n+         pragma Inline (Rehash_Bucket);\n+         --  Detach all nodes starting from dummy head Head and rehash them\n+         --  into To.\n+\n+         procedure Rehash_Node (Nod : Node_Ptr; To : Bucket_Table_Ptr);\n+         pragma Inline (Rehash_Node);\n+         --  Rehash node Nod into To\n+\n+         ------------\n+         -- Rehash --\n+         ------------\n+\n+         procedure Rehash (From : Bucket_Table_Ptr; To : Bucket_Table_Ptr) is\n+         begin\n+            pragma Assert (From /= null);\n+            pragma Assert (To /= null);\n+\n+            for Scan_Idx in From'Range loop\n+               Rehash_Bucket (From (Scan_Idx)'Access, To);\n+            end loop;\n+         end Rehash;\n+\n+         -------------------\n+         -- Rehash_Bucket --\n+         -------------------\n+\n+         procedure Rehash_Bucket (Head : Node_Ptr; To : Bucket_Table_Ptr) is\n+            pragma Assert (Head /= null);\n+\n+            Nod : Node_Ptr;\n+\n+         begin\n+            --  Detach all nodes which follow the dummy head\n+\n+            while Is_Valid (Head.Next, Head) loop\n+               Nod := Head.Next;\n+\n+               Detach (Nod);\n+               Rehash_Node (Nod, To);\n+            end loop;\n+         end Rehash_Bucket;\n+\n+         -----------------\n+         -- Rehash_Node --\n+         -----------------\n+\n+         procedure Rehash_Node (Nod : Node_Ptr; To : Bucket_Table_Ptr) is\n+            pragma Assert (Nod /= null);\n+\n+            Head : Node_Ptr;\n+\n+         begin\n+            --  Obtain the dummy head of the bucket which should house the\n+            --  key-value pair.\n+\n+            Head := Find_Bucket (To, Nod.Key);\n+\n+            --  Ensure that the dummy head of an empty bucket is circular with\n+            --  respect to itself.\n+\n+            Ensure_Circular (Head);\n+\n+            --  Prepend the node to the bucket\n+\n+            Prepend (Nod, Head);\n+         end Rehash_Node;\n+\n+         --  Local declarations\n+\n+         Old_Bkts : Bucket_Table_Ptr;\n+\n+      --  Start of processing for Mutate_And_Rehash\n+\n+      begin\n+         pragma Assert (T /= null);\n+\n+         Old_Bkts  := T.Buckets;\n+         T.Buckets := new Bucket_Table (0 .. Size - 1);\n+\n+         --  Transfer and rehash all key-value pairs from the old buckets to\n+         --  the new buckets.\n+\n+         Rehash (From => Old_Bkts, To => T.Buckets);\n+         Free (Old_Bkts);\n+      end Mutate_And_Rehash;\n+\n+      ----------\n+      -- Next --\n+      ----------\n+\n+      procedure Next (Iter : in out Iterator; Key : out Key_Type) is\n+         Is_OK : constant Boolean  := Is_Valid (Iter);\n+         Saved : constant Node_Ptr := Iter.Nod;\n+         T     : constant Instance := Iter.Table;\n+         Head  : Node_Ptr;\n+\n+      begin\n+         pragma Assert (T /= null);\n+         pragma Assert (T.Buckets /= null);\n+\n+         --  The iterator is no longer valid which indicates that it has been\n+         --  exhausted. Unlock all mutation functionality of the hash table as\n+         --  the iterator cannot be advanced any further.\n+\n+         if not Is_OK then\n+            Unlock (T);\n+            raise Iterator_Exhausted;\n+         end if;\n+\n+         --  Advance to the next node along the same bucket\n+\n+         Iter.Nod := Iter.Nod.Next;\n+         Head     := T.Buckets (Iter.Idx)'Access;\n+\n+         --  If the new node is no longer valid, then this indicates that the\n+         --  current bucket has been exhausted. Advance to the next valid node\n+         --  within the remaining range of buckets. If no such node exists, the\n+         --  iterator is left in a state which does not allow it to advance.\n+\n+         if not Is_Valid (Iter.Nod, Head) then\n+            First_Valid_Node\n+              (T      => T,\n+               Low_Bkt  => Iter.Idx + 1,\n+               High_Bkt => T.Buckets'Last,\n+               Idx      => Iter.Idx,\n+               Nod      => Iter.Nod);\n+         end if;\n+\n+         Key := Saved.Key;\n+      end Next;\n+\n+      -------------\n+      -- Prepend --\n+      -------------\n+\n+      procedure Prepend (Nod : Node_Ptr; Head : Node_Ptr) is\n+         pragma Assert (Nod /= null);\n+         pragma Assert (Head /= null);\n+\n+         Next : constant Node_Ptr := Head.Next;\n+\n+      begin\n+         Head.Next := Nod;\n+         Next.Prev := Nod;\n+\n+         Nod.Next := Next;\n+         Nod.Prev := Head;\n+      end Prepend;\n+\n+      ---------\n+      -- Put --\n+      ---------\n+\n+      procedure Put\n+        (T     : Instance;\n+         Key   : Key_Type;\n+         Value : Value_Type)\n+      is\n+         procedure Expand;\n+         pragma Inline (Expand);\n+         --  Determine whether hash table T requires expansion, and if so,\n+         --  double its size.\n+\n+         procedure Prepend_Or_Replace (Head : Node_Ptr);\n+         pragma Inline (Prepend_Or_Replace);\n+         --  Update the value of a node within a bucket with dummy head Head\n+         --  whose key is Key to Value. If there is no such node, prepend a new\n+         --  key-value pair to the bucket.\n+\n+         ------------\n+         -- Expand --\n+         ------------\n+\n+         procedure Expand is\n+            pragma Assert (T /= null);\n+            pragma Assert (T.Buckets /= null);\n+\n+            Old_Size : constant Bucket_Range_Type := T.Buckets'Length;\n+\n+         begin\n+            --  The ratio of pairs to buckets is over the desited threshold.\n+            --  Expand the hash table only when there is still room to do so.\n+\n+            if Load_Factor (T) > Expansion_Threshold\n+              and then Old_Size <= Safe_Expansion_Size\n+            then\n+               Mutate_And_Rehash (T, Old_Size * Expansion_Factor);\n+            end if;\n+         end Expand;\n+\n+         ------------------------\n+         -- Prepend_Or_Replace --\n+         ------------------------\n+\n+         procedure Prepend_Or_Replace (Head : Node_Ptr) is\n+            pragma Assert (Head /= null);\n+\n+            Nod : Node_Ptr;\n+\n+         begin\n+            --  If the bucket containst at least one valid node, then there is\n+            --  a chance that a node with the same key as Key exists. If this\n+            --  is the case, the value of that node must be updated.\n+\n+            Nod := Head.Next;\n+            while Is_Valid (Nod, Head) loop\n+               if Equivalent_Keys (Nod.Key, Key) then\n+                  Nod.Value := Value;\n+                  return;\n+               end if;\n+\n+               Nod := Nod.Next;\n+            end loop;\n+\n+            --  At this point the bucket is either empty, or none of the nodes\n+            --  match key Key. Prepend a new key-value pair.\n+\n+            Nod := new Node'(Key, Value, null, null);\n+\n+            Prepend (Nod, Head);\n+         end Prepend_Or_Replace;\n+\n+         --  Local variables\n+\n+         Head : Node_Ptr;\n+\n+      --  Start of processing for Put\n+\n+      begin\n+         Ensure_Created  (T);\n+         Ensure_Unlocked (T);\n+\n+         --  Obtain the dummy head of the bucket which should house the\n+         --  key-value pair.\n+\n+         Head := Find_Bucket (T.Buckets, Key);\n+\n+         --  Ensure that the dummy head of an empty bucket is circular with\n+         --  respect to itself.\n+\n+         Ensure_Circular (Head);\n+\n+         --  In case the bucket already contains a node with the same key,\n+         --  replace its value, otherwise prepend a new key-value pair.\n+\n+         Prepend_Or_Replace (Head);\n+\n+         T.Pairs := T.Pairs + 1;\n+\n+         --  Expand the hash table if the ratio of pairs to buckets goes over\n+         --  Expansion_Threshold.\n+\n+         Expand;\n+      end Put;\n+\n+      -----------\n+      -- Reset --\n+      -----------\n+\n+      procedure Reset (T : Instance) is\n+      begin\n+         Ensure_Created  (T);\n+         Ensure_Unlocked (T);\n+\n+         --  Destroy all nodes in all buckets\n+\n+         Destroy_Buckets (T.Buckets);\n+         Free (T.Buckets);\n+\n+         --  Recreate the buckets using the original size from creation time\n+\n+         T.Buckets := new Bucket_Table (0 .. T.Initial_Size - 1);\n+         T.Pairs   := 0;\n+      end Reset;\n+\n+      ----------\n+      -- Size --\n+      ----------\n+\n+      function Size (T : Instance) return Pair_Count_Type is\n+      begin\n+         Ensure_Created (T);\n+\n+         return T.Pairs;\n+      end Size;\n+\n+      ------------\n+      -- Unlock --\n+      ------------\n+\n+      procedure Unlock (T : Instance) is\n+      begin\n+         --  The hash table may be locked multiple times if multiple iterators\n+         --  are operating over it.\n+\n+         T.Locked := T.Locked - 1;\n+      end Unlock;\n+   end Dynamic_HTable;\n+\n end GNAT.Dynamic_HTables;"}, {"sha": "41574fd32d0be1009fff4f08cc251927e250da1f", "filename": "gcc/ada/libgnat/g-dynhta.ads", "status": "modified", "additions": 281, "deletions": 29, "changes": 310, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d8251d001b3507ffb80b26f4d17f1daa99a5dc4a/gcc%2Fada%2Flibgnat%2Fg-dynhta.ads", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d8251d001b3507ffb80b26f4d17f1daa99a5dc4a/gcc%2Fada%2Flibgnat%2Fg-dynhta.ads", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fada%2Flibgnat%2Fg-dynhta.ads?ref=d8251d001b3507ffb80b26f4d17f1daa99a5dc4a", "patch": "@@ -31,13 +31,11 @@\n \n --  Hash table searching routines\n \n---  This package contains three separate packages. The Simple_HTable package\n+--  This package contains two separate packages. The Simple_HTable package\n --  provides a very simple abstraction that associates one element to one key\n --  value and takes care of all allocations automatically using the heap. The\n --  Static_HTable package provides a more complex interface that allows full\n---  control over allocation. The Load_Factor_HTable package provides a more\n---  complex abstraction where collisions are resolved by chaining, and the\n---  table grows by a percentage after the load factor has been exceeded.\n+--  control over allocation.\n \n --  This package provides a facility similar to that of GNAT.HTable, except\n --  that this package declares types that can be used to define dynamic\n@@ -48,6 +46,8 @@\n --  GNAT.HTable to keep as much coherency as possible between these two\n --  related units.\n \n+pragma Compiler_Unit_Warning;\n+\n package GNAT.Dynamic_HTables is\n \n    -------------------\n@@ -85,52 +85,50 @@ package GNAT.Dynamic_HTables is\n       Null_Ptr : Elmt_Ptr;\n       --  The null value of the Elmt_Ptr type\n \n+      with function Next (E : Elmt_Ptr) return Elmt_Ptr;\n       with procedure Set_Next (E : Elmt_Ptr; Next : Elmt_Ptr);\n-      with function  Next     (E : Elmt_Ptr) return Elmt_Ptr;\n       --  The type must provide an internal link for the sake of the\n       --  staticness of the HTable.\n \n       type Key is limited private;\n       with function Get_Key (E : Elmt_Ptr) return Key;\n-      with function Hash    (F : Key)      return Header_Num;\n-      with function Equal   (F1, F2 : Key) return Boolean;\n+      with function Hash (F : Key) return Header_Num;\n+      with function Equal (F1 : Key; F2 : Key) return Boolean;\n \n    package Static_HTable is\n-\n       type Instance is private;\n       Nil : constant Instance;\n \n       procedure Reset (T : in out Instance);\n-      --  Resets the hash table by releasing all memory associated with\n-      --  it. The hash table can safely be reused after this call. For the\n-      --  most common case where Elmt_Ptr is an access type, and Null_Ptr is\n-      --  null, this is only needed if the same table is reused in a new\n-      --  context. If Elmt_Ptr is other than an access type, or Null_Ptr is\n-      --  other than null, then Reset must be called before the first use of\n-      --  the hash table.\n+      --  Resets the hash table by releasing all memory associated with it. The\n+      --  hash table can safely be reused after this call. For the most common\n+      --  case where Elmt_Ptr is an access type, and Null_Ptr is null, this is\n+      --  only needed if the same table is reused in a new context. If Elmt_Ptr\n+      --  is other than an access type, or Null_Ptr is other than null, then\n+      --  Reset must be called before the first use of the hash table.\n \n       procedure Set (T : in out Instance; E : Elmt_Ptr);\n       --  Insert the element pointer in the HTable\n \n       function Get (T : Instance; K : Key) return Elmt_Ptr;\n-      --  Returns the latest inserted element pointer with the given Key\n-      --  or null if none.\n+      --  Returns the latest inserted element pointer with the given Key or\n+      --  null if none.\n \n       procedure Remove (T : Instance; K : Key);\n-      --  Removes the latest inserted element pointer associated with the\n-      --  given key if any, does nothing if none.\n+      --  Removes the latest inserted element pointer associated with the given\n+      --  key if any, does nothing if none.\n \n       function Get_First (T : Instance) return Elmt_Ptr;\n       --  Returns Null_Ptr if the Htable is empty, otherwise returns one\n       --  unspecified element. There is no guarantee that 2 calls to this\n       --  function will return the same element.\n \n       function Get_Next (T : Instance) return Elmt_Ptr;\n-      --  Returns an unspecified element that has not been returned by the\n-      --  same function since the last call to Get_First or Null_Ptr if\n-      --  there is no such element or Get_First has never been called. If\n-      --  there is no call to 'Set' in between Get_Next calls, all the\n-      --  elements of the Htable will be traversed.\n+      --  Returns an unspecified element that has not been returned by the same\n+      --  function since the last call to Get_First or Null_Ptr if there is no\n+      --  such element or Get_First has never been called. If there is no call\n+      --  to 'Set' in between Get_Next calls, all the elements of the Htable\n+      --  will be traversed.\n \n    private\n       type Table_Type is array (Header_Num) of Elmt_Ptr;\n@@ -169,11 +167,10 @@ package GNAT.Dynamic_HTables is\n       --  a given key\n \n       type Key is private;\n-      with function Hash  (F : Key)      return Header_Num;\n-      with function Equal (F1, F2 : Key) return Boolean;\n+      with function Hash (F : Key) return Header_Num;\n+      with function Equal (F1 : Key; F2 : Key) return Boolean;\n \n    package Simple_HTable is\n-\n       type Instance is private;\n       Nil : constant Instance;\n \n@@ -233,7 +230,6 @@ package GNAT.Dynamic_HTables is\n       --  same restrictions apply as Get_Next.\n \n    private\n-\n       type Element_Wrapper;\n       type Elmt_Ptr is access all Element_Wrapper;\n       type Element_Wrapper is record\n@@ -260,7 +256,263 @@ package GNAT.Dynamic_HTables is\n \n       type Instance is new Tab.Instance;\n       Nil : constant Instance := Instance (Tab.Nil);\n-\n    end Simple_HTable;\n \n+   --------------------\n+   -- Dynamic_HTable --\n+   --------------------\n+\n+   --  The following package offers a hash table abstraction with the following\n+   --  characteristics:\n+   --\n+   --    * Dynamic resizing based on load factor.\n+   --    * Creation of multiple instances, of different sizes.\n+   --    * Iterable keys.\n+   --\n+   --  This type of hash table is best used in scenarios where the size of the\n+   --  key set is not known. The dynamic resizing aspect allows for performance\n+   --  to remain within reasonable bounds as the size of the key set grows.\n+   --\n+   --  The following use pattern must be employed when operating this table:\n+   --\n+   --    Table : Instance := Create (<some size>);\n+   --\n+   --    <various operations>\n+   --\n+   --    Destroy (Table);\n+   --\n+   --  The destruction of the table reclaims all storage occupied by it.\n+\n+   --  The following type denotes the underlying range of the hash table\n+   --  buckets.\n+\n+   type Bucket_Range_Type is mod 2 ** 32;\n+\n+   --  The following type denotes the multiplicative factor used in expansion\n+   --  and compression of the hash table.\n+\n+   subtype Factor_Type is Bucket_Range_Type range 2 .. 100;\n+\n+   --  The following type denotes the number of key-value pairs stored in the\n+   --  hash table.\n+\n+   type Pair_Count_Type is range 0 .. 2 ** 31 - 1;\n+\n+   --  The following type denotes the threshold range used in expansion and\n+   --  compression of the hash table.\n+\n+   subtype Threshold_Type is Long_Float range 0.0 .. Long_Float'Last;\n+\n+   generic\n+      type Key_Type is private;\n+      type Value_Type is private;\n+      --  The types of the key-value pairs stored in the hash table\n+\n+      No_Value : Value_Type;\n+      --  An indicator for a non-existent value\n+\n+      Expansion_Threshold : Threshold_Type;\n+      Expansion_Factor    : Factor_Type;\n+      --  Once the load factor goes over Expansion_Threshold, the size of the\n+      --  buckets is increased using the formula\n+      --\n+      --    New_Size = Old_Size * Expansion_Factor\n+      --\n+      --  An Expansion_Threshold of 1.5 and Expansion_Factor of 2 indicate that\n+      --  the size of the buckets will be doubled once the load factor exceeds\n+      --  1.5.\n+\n+      Compression_Threshold : Threshold_Type;\n+      Compression_Factor    : Factor_Type;\n+      --  Once the load factor drops below Compression_Threshold, the size of\n+      --  the buckets is decreased using the formula\n+      --\n+      --    New_Size = Old_Size / Compression_Factor\n+      --\n+      --  A Compression_Threshold of 0.5 and Compression_Factor of 2 indicate\n+      --  that the size of the buckets will be halved once the load factor\n+      --  drops below 0.5.\n+\n+      with function Equivalent_Keys\n+             (Left  : Key_Type;\n+              Right : Key_Type) return Boolean;\n+      --  Determine whether two keys are equivalent\n+\n+      with function Hash (Key : Key_Type) return Bucket_Range_Type;\n+      --  Map an arbitrary key into the range of buckets\n+\n+   package Dynamic_HTable is\n+\n+      ----------------------\n+      -- Table operations --\n+      ----------------------\n+\n+      --  The following type denotes a hash table handle. Each instance must be\n+      --  created using routine Create.\n+\n+      type Instance is private;\n+      Nil : constant Instance;\n+\n+      Not_Created : exception;\n+      --  This exception is raised when the hash table has not been created by\n+      --  routine Create, and an attempt is made to read or mutate its state.\n+\n+      Table_Locked : exception;\n+      --  This exception is raised when the hash table is being iterated on,\n+      --  and an attempt is made to mutate its state.\n+\n+      function Create (Initial_Size : Bucket_Range_Type) return Instance;\n+      --  Create a new table with bucket capacity Initial_Size. This routine\n+      --  must be called at the start of a hash table's lifetime.\n+\n+      procedure Delete (T : Instance; Key : Key_Type);\n+      --  Delete the value which corresponds to key Key from hash table T. The\n+      --  routine has no effect if the value is not present in the hash table.\n+      --  This action will raise Table_Locked if the hash table has outstanding\n+      --  iterators. If the load factor drops below Compression_Threshold, the\n+      --  size of the buckets is decreased by Copression_Factor.\n+\n+      procedure Destroy (T : in out Instance);\n+      --  Destroy the contents of hash table T, rendering it unusable. This\n+      --  routine must be called at the end of a hash table's lifetime. This\n+      --  action will raise Table_Locked if the hash table has outstanding\n+      --  iterators.\n+\n+      function Get (T : Instance; Key : Key_Type) return Value_Type;\n+      --  Obtain the value which corresponds to key Key from hash table T. If\n+      --  the value does not exist, return No_Value.\n+\n+      procedure Put\n+        (T     : Instance;\n+         Key   : Key_Type;\n+         Value : Value_Type);\n+      --  Associate value Value with key Key in hash table T. If the table\n+      --  already contains a mapping of the same key to a previous value, the\n+      --  previous value is overwritten. This action will raise Table_Locked\n+      --  if the hash table has outstanding iterators. If the load factor goes\n+      --  over Expansion_Threshold, the size of the buckets is increased by\n+      --  Expansion_Factor.\n+\n+      procedure Reset (T : Instance);\n+      --  Destroy the contents of hash table T, and reset it to its initial\n+      --  created state. This action will raise Table_Locked if the hash table\n+      --  has outstanding iterators.\n+\n+      function Size (T : Instance) return Pair_Count_Type;\n+      --  Obtain the number of key-value pairs in hash table T\n+\n+      -------------------------\n+      -- Iterator operations --\n+      -------------------------\n+\n+      --  The following type represents a key iterator. An iterator locks\n+      --  all mutation operations, and unlocks them once it is exhausted.\n+      --  The iterator must be used with the following pattern:\n+      --\n+      --    Iter := Iterate (My_Table);\n+      --    while Has_Next (Iter) loop\n+      --       Key := Next (Iter);\n+      --       . . .\n+      --    end loop;\n+      --\n+      --  It is possible to advance the iterator by using Next only, however\n+      --  this risks raising Iterator_Exhausted.\n+\n+      type Iterator is private;\n+\n+      Iterator_Exhausted : exception;\n+      --  This exception is raised when an iterator is exhausted and further\n+      --  attempts to advance it are made by calling routine Next.\n+\n+      function Iterate (T : Instance) return Iterator;\n+      --  Obtain an iterator over the keys of hash table T. This action locks\n+      --  all mutation functionality of the associated hash table.\n+\n+      function Has_Next (Iter : Iterator) return Boolean;\n+      --  Determine whether iterator Iter has more keys to examine. If the\n+      --  iterator has been exhausted, restore all mutation functionality of\n+      --  the associated hash table.\n+\n+      procedure Next\n+        (Iter : in out Iterator;\n+         Key  : out Key_Type);\n+      --  Return the current key referenced by iterator Iter and advance to\n+      --  the next available key. If the iterator has been exhausted and\n+      --  further attempts are made to advance it, this routine restores\n+      --  mutation functionality of the associated hash table, and then\n+      --  raises Iterator_Exhausted.\n+\n+   private\n+      --  The following type represents a doubly linked list node used to\n+      --  store a key-value pair. There are several reasons to use a doubly\n+      --  linked list:\n+      --\n+      --    * Most read and write operations utilize the same primitve\n+      --      routines to locate, create, and delete a node, allowing for\n+      --      greater degree of code sharing.\n+      --\n+      --    * Special cases are eliminated by maintaining a circular node\n+      --      list with a dummy head (see type Bucket_Table).\n+      --\n+      --  A node is said to be \"valid\" if it is non-null, and does not refer to\n+      --  the dummy head of some bucket.\n+\n+      type Node;\n+      type Node_Ptr is access all Node;\n+      type Node is record\n+         Key   : Key_Type;\n+         Value : Value_Type := No_Value;\n+         --  Key-value pair stored in a bucket\n+\n+         Prev : Node_Ptr := null;\n+         Next : Node_Ptr := null;\n+      end record;\n+\n+      --  The following type represents a bucket table. Each bucket contains a\n+      --  circular doubly linked list of nodes with a dummy head. Initially,\n+      --  the head does not refer to itself. This is intentional because it\n+      --  improves the performance of creation, compression, and expansion by\n+      --  avoiding a separate pass to link a head to itself. Several routines\n+      --  ensure that the head is properly formed.\n+\n+      type Bucket_Table is array (Bucket_Range_Type range <>) of aliased Node;\n+      type Bucket_Table_Ptr is access Bucket_Table;\n+\n+      --  The following type represents a hash table\n+\n+      type Hash_Table is record\n+         Buckets : Bucket_Table_Ptr := null;\n+         --  Reference to the compressing / expanding buckets\n+\n+         Initial_Size : Bucket_Range_Type := 0;\n+         --  The initial size of the buckets as specified at creation time\n+\n+         Locked : Natural := 0;\n+         --  Number of outstanding iterators\n+\n+         Pairs : Pair_Count_Type := 0;\n+         --  Number of key-value pairs in the buckets\n+      end record;\n+\n+      type Instance is access Hash_Table;\n+      Nil : constant Instance := null;\n+\n+      --  The following type represents a key iterator\n+\n+      type Iterator is record\n+         Idx : Bucket_Range_Type := 0;\n+         --  Index of the current bucket being examined. This index is always\n+         --  kept within the range of the buckets.\n+\n+         Nod : Node_Ptr := null;\n+         --  Reference to the current node being examined within the current\n+         --  bucket. The invariant of the iterator requires that this field\n+         --  always point to a valid node. A value of null indicates that the\n+         --  iterator is exhausted.\n+\n+         Table : Instance := null;\n+         --  Reference to the associated hash table\n+      end record;\n+   end Dynamic_HTable;\n+\n end GNAT.Dynamic_HTables;"}, {"sha": "2c02ca1549aca199ffab17ce71d9c4c6e0e7b21d", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d8251d001b3507ffb80b26f4d17f1daa99a5dc4a/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d8251d001b3507ffb80b26f4d17f1daa99a5dc4a/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=d8251d001b3507ffb80b26f4d17f1daa99a5dc4a", "patch": "@@ -1,3 +1,7 @@\n+2018-08-21  Hristian Kirtchev  <kirtchev@adacore.com>\n+\n+\t* gnat.dg/dynhash.adb: New testcase.\n+\n 2018-08-21  Javier Miranda  <miranda@adacore.com>\n \n \t* gnat.dg/enum4.adb: New testcase."}, {"sha": "79e1b984066f1e883714ad0ffd98c8eed10eff22", "filename": "gcc/testsuite/gnat.dg/dynhash.adb", "status": "added", "additions": 750, "deletions": 0, "changes": 750, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d8251d001b3507ffb80b26f4d17f1daa99a5dc4a/gcc%2Ftestsuite%2Fgnat.dg%2Fdynhash.adb", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d8251d001b3507ffb80b26f4d17f1daa99a5dc4a/gcc%2Ftestsuite%2Fgnat.dg%2Fdynhash.adb", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgnat.dg%2Fdynhash.adb?ref=d8251d001b3507ffb80b26f4d17f1daa99a5dc4a", "patch": "@@ -0,0 +1,750 @@\n+--  { dg-do run }\n+\n+with Ada.Text_IO;          use Ada.Text_IO;\n+with GNAT.Dynamic_HTables; use GNAT.Dynamic_HTables;\n+\n+procedure Dynhash is\n+   function Hash (Key : Integer) return Bucket_Range_Type;\n+\n+   package DHT is new Dynamic_HTable\n+     (Key_Type              => Integer,\n+      Value_Type            => Integer,\n+      No_Value              => 0,\n+      Expansion_Threshold   => 1.3,\n+      Expansion_Factor      => 2,\n+      Compression_Threshold => 0.3,\n+      Compression_Factor    => 2,\n+      Equivalent_Keys       => \"=\",\n+      Hash                  => Hash);\n+   use DHT;\n+\n+   function Create_And_Populate\n+     (Low_Key   : Integer;\n+      High_Key  : Integer;\n+      Init_Size : Bucket_Range_Type) return Instance;\n+   --  Create a hash table with initial size Init_Size and populate it with\n+   --  key-value pairs where both keys and values are in the range Low_Key\n+   --  .. High_Key.\n+\n+   procedure Check_Empty\n+     (Caller    : String;\n+      T         : Instance;\n+      Low_Key   : Integer;\n+      High_Key  : Integer);\n+   --  Ensure that\n+   --\n+   --    * The key-value pairs count of hash table T is 0.\n+   --    * All values for the keys in range Low_Key .. High_Key are 0.\n+\n+   procedure Check_Keys\n+     (Caller   : String;\n+      Iter     : in out Iterator;\n+      Low_Key  : Integer;\n+      High_Key : Integer);\n+   --  Ensure that iterator Iter visits every key in the range Low_Key ..\n+   --  High_Key exactly once.\n+\n+   procedure Check_Locked_Mutations (Caller : String; T : in out Instance);\n+   --  Ensure that all mutation operations of hash table T are locked\n+\n+   procedure Check_Size\n+     (Caller    : String;\n+      T         : Instance;\n+      Exp_Count : Pair_Count_Type);\n+   --  Ensure that the count of key-value pairs of hash table T matches\n+   --  expected count Exp_Count. Emit an error if this is not the case.\n+\n+   procedure Test_Create (Init_Size : Bucket_Range_Type);\n+   --  Verify that all dynamic hash table operations fail on a non-created\n+   --  table of size Init_Size.\n+\n+   procedure Test_Delete_Get_Put_Size\n+     (Low_Key   : Integer;\n+      High_Key  : Integer;\n+      Exp_Count : Pair_Count_Type;\n+      Init_Size : Bucket_Range_Type);\n+   --  Verify that\n+   --\n+   --    * Put properly inserts values in the hash table.\n+   --    * Get properly retrieves all values inserted in the table.\n+   --    * Delete properly deletes values.\n+   --    * The size of the hash table properly reflects the number of key-value\n+   --      pairs.\n+   --\n+   --  Low_Key and High_Key denote the range of keys to be inserted, retrieved,\n+   --  and deleted. Exp_Count is the expected count of key-value pairs n the\n+   --  hash table. Init_Size denotes the initial size of the table.\n+\n+   procedure Test_Iterate\n+     (Low_Key   : Integer;\n+      High_Key  : Integer;\n+      Init_Size : Bucket_Range_Type);\n+   --  Verify that iterators\n+   --\n+   --    * Properly visit each key exactly once.\n+   --    * Mutation operations are properly locked and unlocked during\n+   --      iteration.\n+   --\n+   --  Low_Key and High_Key denote the range of keys to be inserted, retrieved,\n+   --  and deleted. Init_Size denotes the initial size of the table.\n+\n+   procedure Test_Iterate_Empty (Init_Size : Bucket_Range_Type);\n+   --  Verify that an iterator over an empty hash table\n+   --\n+   --    * Does not visit any key\n+   --    * Mutation operations are properly locked and unlocked during\n+   --      iteration.\n+   --\n+   --  Init_Size denotes the initial size of the table.\n+\n+   procedure Test_Iterate_Forced\n+     (Low_Key   : Integer;\n+      High_Key  : Integer;\n+      Init_Size : Bucket_Range_Type);\n+   --  Verify that an iterator that is forcefully advanced by just Next\n+   --\n+   --    * Properly visit each key exactly once.\n+   --    * Mutation operations are properly locked and unlocked during\n+   --      iteration.\n+   --\n+   --  Low_Key and High_Key denote the range of keys to be inserted, retrieved,\n+   --  and deleted. Init_Size denotes the initial size of the table.\n+\n+   procedure Test_Replace\n+     (Low_Val   : Integer;\n+      High_Val  : Integer;\n+      Init_Size : Bucket_Range_Type);\n+   --  Verify that Put properly updates the value of a particular key. Low_Val\n+   --  and High_Val denote the range of values to be updated. Init_Size denotes\n+   --  the initial size of the table.\n+\n+   procedure Test_Reset\n+     (Low_Key   : Integer;\n+      High_Key  : Integer;\n+      Init_Size : Bucket_Range_Type);\n+   --  Verify that Reset properly destroy and recreats a hash table. Low_Key\n+   --  and High_Key denote the range of keys to be inserted in the hash table.\n+   --  Init_Size denotes the initial size of the table.\n+\n+   -------------------------\n+   -- Create_And_Populate --\n+   -------------------------\n+\n+   function Create_And_Populate\n+     (Low_Key   : Integer;\n+      High_Key  : Integer;\n+      Init_Size : Bucket_Range_Type) return Instance\n+   is\n+      T : Instance;\n+\n+   begin\n+      T := Create (Init_Size);\n+\n+      for Key in Low_Key .. High_Key loop\n+         Put (T, Key, Key);\n+      end loop;\n+\n+      return T;\n+   end Create_And_Populate;\n+\n+   -----------------\n+   -- Check_Empty --\n+   -----------------\n+\n+   procedure Check_Empty\n+     (Caller    : String;\n+      T         : Instance;\n+      Low_Key   : Integer;\n+      High_Key  : Integer)\n+   is\n+      Val : Integer;\n+\n+   begin\n+      Check_Size\n+        (Caller    => Caller,\n+         T         => T,\n+         Exp_Count => 0);\n+\n+      for Key in Low_Key .. High_Key loop\n+         Val := Get (T, Key);\n+\n+         if Val /= 0 then\n+            Put_Line (\"ERROR: \" & Caller & \": wrong value\");\n+            Put_Line (\"expected: 0\");\n+            Put_Line (\"got     :\" & Val'Img);\n+         end if;\n+      end loop;\n+   end Check_Empty;\n+\n+   ----------------\n+   -- Check_Keys --\n+   ----------------\n+\n+   procedure Check_Keys\n+     (Caller   : String;\n+      Iter     : in out Iterator;\n+      Low_Key  : Integer;\n+      High_Key : Integer)\n+   is\n+      type Bit_Vector is array (Low_Key .. High_Key) of Boolean;\n+      pragma Pack (Bit_Vector);\n+\n+      Count : Natural;\n+      Key   : Integer;\n+      Seen  : Bit_Vector := (others => False);\n+\n+   begin\n+      --  Compute the number of outstanding keys that have to be iterated on\n+\n+      Count := High_Key - Low_Key + 1;\n+\n+      while Has_Next (Iter) loop\n+         Next (Iter, Key);\n+\n+         if Seen (Key) then\n+            Put_Line\n+              (\"ERROR: \" & Caller & \": Check_Keys: duplicate key\" & Key'Img);\n+         else\n+            Seen (Key) := True;\n+            Count := Count - 1;\n+         end if;\n+      end loop;\n+\n+      --  In the end, all keys must have been iterated on\n+\n+      if Count /= 0 then\n+         for Key in Seen'Range loop\n+            if not Seen (Key) then\n+               Put_Line\n+                 (\"ERROR: \" & Caller & \": Check_Keys: missing key\" & Key'Img);\n+            end if;\n+         end loop;\n+      end if;\n+   end Check_Keys;\n+\n+   ----------------------------\n+   -- Check_Locked_Mutations --\n+   ----------------------------\n+\n+   procedure Check_Locked_Mutations (Caller : String; T : in out Instance) is\n+   begin\n+      begin\n+         Delete (T, 1);\n+         Put_Line (\"ERROR: \" & Caller & \": Delete: no exception raised\");\n+      exception\n+         when Table_Locked =>\n+            null;\n+         when others =>\n+           Put_Line (\"ERROR: \" & Caller & \": Delete: unexpected exception\");\n+      end;\n+\n+      begin\n+         Destroy (T);\n+         Put_Line (\"ERROR: \" & Caller & \": Destroy: no exception raised\");\n+      exception\n+         when Table_Locked =>\n+            null;\n+         when others =>\n+           Put_Line (\"ERROR: \" & Caller & \": Destroy: unexpected exception\");\n+      end;\n+\n+      begin\n+         Put (T, 1, 1);\n+         Put_Line (\"ERROR: \" & Caller & \": Put: no exception raised\");\n+      exception\n+         when Table_Locked =>\n+            null;\n+         when others =>\n+           Put_Line (\"ERROR: \" & Caller & \": Put: unexpected exception\");\n+      end;\n+\n+      begin\n+         Reset (T);\n+         Put_Line (\"ERROR: \" & Caller & \": Reset: no exception raised\");\n+      exception\n+         when Table_Locked =>\n+            null;\n+         when others =>\n+           Put_Line (\"ERROR: \" & Caller & \": Reset: unexpected exception\");\n+      end;\n+   end Check_Locked_Mutations;\n+\n+   ----------------\n+   -- Check_Size --\n+   ----------------\n+\n+   procedure Check_Size\n+     (Caller    : String;\n+      T         : Instance;\n+      Exp_Count : Pair_Count_Type)\n+   is\n+      Count : constant Pair_Count_Type := Size (T);\n+\n+   begin\n+      if Count /= Exp_Count then\n+         Put_Line (\"ERROR: \" & Caller & \": Size: wrong value\");\n+         Put_Line (\"expected:\" & Exp_Count'Img);\n+         Put_Line (\"got     :\" & Count'Img);\n+      end if;\n+   end Check_Size;\n+\n+   ----------\n+   -- Hash --\n+   ----------\n+\n+   function Hash (Key : Integer) return Bucket_Range_Type is\n+   begin\n+      return Bucket_Range_Type (Key);\n+   end Hash;\n+\n+   -----------------\n+   -- Test_Create --\n+   -----------------\n+\n+   procedure Test_Create (Init_Size : Bucket_Range_Type) is\n+      Count : Pair_Count_Type;\n+      Iter  : Iterator;\n+      T     : Instance;\n+      Val   : Integer;\n+\n+   begin\n+      --  Ensure that every routine defined in the API fails on a hash table\n+      --  which has not been created yet.\n+\n+      begin\n+         Delete (T, 1);\n+         Put_Line (\"ERROR: Test_Create: Delete: no exception raised\");\n+      exception\n+         when Not_Created =>\n+            null;\n+         when others =>\n+           Put_Line (\"ERROR: Test_Create: Delete: unexpected exception\");\n+      end;\n+\n+      begin\n+         Destroy (T);\n+         Put_Line (\"ERROR: Test_Create: Destroy: no exception raised\");\n+      exception\n+         when Not_Created =>\n+            null;\n+         when others =>\n+           Put_Line (\"ERROR: Test_Create: Destroy: unexpected exception\");\n+      end;\n+\n+      begin\n+         Val := Get (T, 1);\n+         Put_Line (\"ERROR: Test_Create: Get: no exception raised\");\n+      exception\n+         when Not_Created =>\n+            null;\n+         when others =>\n+           Put_Line (\"ERROR: Test_Create: Get: unexpected exception\");\n+      end;\n+\n+      begin\n+         Iter := Iterate (T);\n+         Put_Line (\"ERROR: Test_Create: Iterate: no exception raised\");\n+      exception\n+         when Not_Created =>\n+            null;\n+         when others =>\n+           Put_Line (\"ERROR: Test_Create: Iterate: unexpected exception\");\n+      end;\n+\n+      begin\n+         Put (T, 1, 1);\n+         Put_Line (\"ERROR: Test_Create: Put: no exception raised\");\n+      exception\n+         when Not_Created =>\n+            null;\n+         when others =>\n+           Put_Line (\"ERROR: Test_Create: Put: unexpected exception\");\n+      end;\n+\n+      begin\n+         Reset (T);\n+         Put_Line (\"ERROR: Test_Create: Reset: no exception raised\");\n+      exception\n+         when Not_Created =>\n+            null;\n+         when others =>\n+           Put_Line (\"ERROR: Test_Create: Reset: unexpected exception\");\n+      end;\n+\n+      begin\n+         Count := Size (T);\n+         Put_Line (\"ERROR: Test_Create: Size: no exception raised\");\n+      exception\n+         when Not_Created =>\n+            null;\n+         when others =>\n+           Put_Line (\"ERROR: Test_Create: Size: unexpected exception\");\n+      end;\n+\n+      --  Test create\n+\n+      T := Create (Init_Size);\n+\n+      --  Clean up the hash table to prevent memory leaks\n+\n+      Destroy (T);\n+   end Test_Create;\n+\n+   ------------------------------\n+   -- Test_Delete_Get_Put_Size --\n+   ------------------------------\n+\n+   procedure Test_Delete_Get_Put_Size\n+     (Low_Key   : Integer;\n+      High_Key  : Integer;\n+      Exp_Count : Pair_Count_Type;\n+      Init_Size : Bucket_Range_Type)\n+   is\n+      Exp_Val : Integer;\n+      T       : Instance;\n+      Val     : Integer;\n+\n+   begin\n+      T := Create_And_Populate (Low_Key, High_Key, Init_Size);\n+\n+      --  Ensure that its size matches an expected value\n+\n+      Check_Size\n+        (Caller    => \"Test_Delete_Get_Put_Size\",\n+         T         => T,\n+         Exp_Count => Exp_Count);\n+\n+      --  Ensure that every value for the range of keys exists\n+\n+      for Key in Low_Key .. High_Key loop\n+         Val := Get (T, Key);\n+\n+         if Val /= Key then\n+            Put_Line (\"ERROR: Test_Delete_Get_Put_Size: Get: wrong value\");\n+            Put_Line (\"expected:\" & Key'Img);\n+            Put_Line (\"got     :\" & Val'Img);\n+         end if;\n+      end loop;\n+\n+      --  Delete values whose keys are divisible by 10\n+\n+      for Key in Low_Key .. High_Key loop\n+         if Key mod 10 = 0 then\n+            Delete (T, Key);\n+         end if;\n+      end loop;\n+\n+      --  Ensure that all values whose keys were not deleted still exist\n+\n+      for Key in Low_Key .. High_Key loop\n+         if Key mod 10 = 0 then\n+            Exp_Val := 0;\n+         else\n+            Exp_Val := Key;\n+         end if;\n+\n+         Val := Get (T, Key);\n+\n+         if Val /= Exp_Val then\n+            Put_Line (\"ERROR: Test_Delete_Get_Put_Size: Get: wrong value\");\n+            Put_Line (\"expected:\" & Exp_Val'Img);\n+            Put_Line (\"got     :\" & Val'Img);\n+         end if;\n+      end loop;\n+\n+      --  Delete all values\n+\n+      for Key in Low_Key .. High_Key loop\n+         Delete (T, Key);\n+      end loop;\n+\n+      --  Ensure that the hash table is empty\n+\n+      Check_Empty\n+        (Caller   => \"Test_Delete_Get_Put_Size\",\n+         T        => T,\n+         Low_Key  => Low_Key,\n+         High_Key => High_Key);\n+\n+      --  Clean up the hash table to prevent memory leaks\n+\n+      Destroy (T);\n+   end Test_Delete_Get_Put_Size;\n+\n+   ------------------\n+   -- Test_Iterate --\n+   ------------------\n+\n+   procedure Test_Iterate\n+     (Low_Key   : Integer;\n+      High_Key  : Integer;\n+      Init_Size : Bucket_Range_Type)\n+   is\n+      Iter_1 : Iterator;\n+      Iter_2 : Iterator;\n+      T      : Instance;\n+\n+   begin\n+      T := Create_And_Populate (Low_Key, High_Key, Init_Size);\n+\n+      --  Obtain an iterator. This action must lock all mutation operations of\n+      --  the hash table.\n+\n+      Iter_1 := Iterate (T);\n+\n+      --  Ensure that every mutation routine defined in the API fails on a hash\n+      --  table with at least one outstanding iterator.\n+\n+      Check_Locked_Mutations\n+        (Caller => \"Test_Iterate\",\n+         T      => T);\n+\n+      --  Obtain another iterator\n+\n+      Iter_2 := Iterate (T);\n+\n+      --  Ensure that every mutation is still locked\n+\n+      Check_Locked_Mutations\n+        (Caller => \"Test_Iterate\",\n+         T      => T);\n+\n+      --  Ensure that all keys are iterable. Note that this does not unlock the\n+      --  mutation operations of the hash table because Iter_2 is not exhausted\n+      --  yet.\n+\n+      Check_Keys\n+        (Caller   => \"Test_Iterate\",\n+         Iter     => Iter_1,\n+         Low_Key  => Low_Key,\n+         High_Key => High_Key);\n+\n+      Check_Locked_Mutations\n+        (Caller => \"Test_Iterate\",\n+         T      => T);\n+\n+      --  Ensure that all keys are iterable. This action unlocks all mutation\n+      --  operations of the hash table because all outstanding iterators have\n+      --  been exhausted.\n+\n+      Check_Keys\n+        (Caller   => \"Test_Iterate\",\n+         Iter     => Iter_2,\n+         Low_Key  => Low_Key,\n+         High_Key => High_Key);\n+\n+      --  Ensure that all mutation operations are once again callable\n+\n+      Delete (T, Low_Key);\n+      Put (T, Low_Key, Low_Key);\n+      Reset (T);\n+\n+      --  Clean up the hash table to prevent memory leaks\n+\n+      Destroy (T);\n+   end Test_Iterate;\n+\n+   ------------------------\n+   -- Test_Iterate_Empty --\n+   ------------------------\n+\n+   procedure Test_Iterate_Empty (Init_Size : Bucket_Range_Type) is\n+      Iter : Iterator;\n+      Key  : Integer;\n+      T    : Instance;\n+\n+   begin\n+      T := Create_And_Populate (0, -1, Init_Size);\n+\n+      --  Obtain an iterator. This action must lock all mutation operations of\n+      --  the hash table.\n+\n+      Iter := Iterate (T);\n+\n+      --  Ensure that every mutation routine defined in the API fails on a hash\n+      --  table with at least one outstanding iterator.\n+\n+      Check_Locked_Mutations\n+        (Caller => \"Test_Iterate_Empty\",\n+         T      => T);\n+\n+      --  Attempt to iterate over the keys\n+\n+      while Has_Next (Iter) loop\n+         Next (Iter, Key);\n+\n+         Put_Line (\"ERROR: Test_Iterate_Empty: key\" & Key'Img & \" exists\");\n+      end loop;\n+\n+      --  Ensure that all mutation operations are once again callable\n+\n+      Delete (T, 1);\n+      Put (T, 1, 1);\n+      Reset (T);\n+\n+      --  Clean up the hash table to prevent memory leaks\n+\n+      Destroy (T);\n+   end Test_Iterate_Empty;\n+\n+   -------------------------\n+   -- Test_Iterate_Forced --\n+   -------------------------\n+\n+   procedure Test_Iterate_Forced\n+     (Low_Key   : Integer;\n+      High_Key  : Integer;\n+      Init_Size : Bucket_Range_Type)\n+   is\n+      Iter : Iterator;\n+      Key  : Integer;\n+      T    : Instance;\n+\n+   begin\n+      T := Create_And_Populate (Low_Key, High_Key, Init_Size);\n+\n+      --  Obtain an iterator. This action must lock all mutation operations of\n+      --  the hash table.\n+\n+      Iter := Iterate (T);\n+\n+      --  Ensure that every mutation routine defined in the API fails on a hash\n+      --  table with at least one outstanding iterator.\n+\n+      Check_Locked_Mutations\n+        (Caller => \"Test_Iterate_Forced\",\n+         T      => T);\n+\n+      --  Forcibly advance the iterator until it raises an exception\n+\n+      begin\n+         for Guard in Low_Key .. High_Key + 1 loop\n+            Next (Iter, Key);\n+         end loop;\n+\n+         Put_Line\n+           (\"ERROR: Test_Iterate_Forced: Iterator_Exhausted not raised\");\n+      exception\n+         when Iterator_Exhausted =>\n+            null;\n+         when others =>\n+            Put_Line (\"ERROR: Test_Iterate_Forced: unexpected exception\");\n+      end;\n+\n+      --  Ensure that all mutation operations are once again callable\n+\n+      Delete (T, Low_Key);\n+      Put (T, Low_Key, Low_Key);\n+      Reset (T);\n+\n+      --  Clean up the hash table to prevent memory leaks\n+\n+      Destroy (T);\n+   end Test_Iterate_Forced;\n+\n+   ------------------\n+   -- Test_Replace --\n+   ------------------\n+\n+   procedure Test_Replace\n+     (Low_Val   : Integer;\n+      High_Val  : Integer;\n+      Init_Size : Bucket_Range_Type)\n+   is\n+      Key : constant Integer := 1;\n+      T   : Instance;\n+      Val : Integer;\n+\n+   begin\n+      T := Create (Init_Size);\n+\n+      --  Ensure the Put properly updates values with the same key\n+\n+      for Exp_Val in Low_Val .. High_Val loop\n+         Put (T, Key, Exp_Val);\n+\n+         Val := Get (T, Key);\n+\n+         if Val /= Exp_Val then\n+            Put_Line (\"ERROR: Test_Replace: Get: wrong value\");\n+            Put_Line (\"expected:\" & Exp_Val'Img);\n+            Put_Line (\"got     :\" & Val'Img);\n+         end if;\n+      end loop;\n+\n+      --  Clean up the hash table to prevent memory leaks\n+\n+      Destroy (T);\n+   end Test_Replace;\n+\n+   ----------------\n+   -- Test_Reset --\n+   ----------------\n+\n+   procedure Test_Reset\n+     (Low_Key   : Integer;\n+      High_Key  : Integer;\n+      Init_Size : Bucket_Range_Type)\n+   is\n+      T : Instance;\n+\n+   begin\n+      T := Create_And_Populate (Low_Key, High_Key, Init_Size);\n+\n+      --  Reset the contents of the hash table\n+\n+      Reset (T);\n+\n+      --  Ensure that the hash table is empty\n+\n+      Check_Empty\n+        (Caller   => \"Test_Reset\",\n+         T        => T,\n+         Low_Key  => Low_Key,\n+         High_Key => High_Key);\n+\n+      --  Clean up the hash table to prevent memory leaks\n+\n+      Destroy (T);\n+   end Test_Reset;\n+\n+--  Start of processing for Operations\n+\n+begin\n+   Test_Create (Init_Size => 1);\n+   Test_Create (Init_Size => 100);\n+\n+   Test_Delete_Get_Put_Size\n+     (Low_Key   => 1,\n+      High_Key  => 1,\n+      Exp_Count => 1,\n+      Init_Size => 1);\n+\n+   Test_Delete_Get_Put_Size\n+     (Low_Key   => 1,\n+      High_Key  => 1000,\n+      Exp_Count => 1000,\n+      Init_Size => 32);\n+\n+   Test_Iterate\n+     (Low_Key   => 1,\n+      High_Key  => 32,\n+      Init_Size => 32);\n+\n+   Test_Iterate_Empty (Init_Size => 32);\n+\n+   Test_Iterate_Forced\n+     (Low_Key   => 1,\n+      High_Key  => 32,\n+      Init_Size => 32);\n+\n+   Test_Replace\n+     (Low_Val   => 1,\n+      High_Val  => 10,\n+      Init_Size => 32);\n+\n+   Test_Reset\n+     (Low_Key   => 1,\n+      High_Key  => 1000,\n+      Init_Size => 100);\n+end Dynhash;"}]}