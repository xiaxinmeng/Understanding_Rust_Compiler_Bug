{"sha": "3d6275e30a850b8e8051163bcd43ddbab2273046", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6M2Q2Mjc1ZTMwYTg1MGI4ZTgwNTExNjNiY2Q0M2RkYmFiMjI3MzA0Ng==", "commit": {"author": {"name": "Andrew Stubbs", "email": "ams@codesourcery.com", "date": "2019-01-17T12:31:28Z"}, "committer": {"name": "Andrew Stubbs", "email": "ams@gcc.gnu.org", "date": "2019-01-17T12:31:28Z"}, "message": "GCN machine description\n\nThis patch contains the machine description portion of the GCN back-end.  I've\nbroken it out mainly to avoid the mailing list size limit.\n\n2019-01-17  Andrew Stubbs  <ams@codesourcery.com>\n\t    Kwok Cheung Yeung  <kcy@codesourcery.com>\n\t    Julian Brown  <julian@codesourcery.com>\n\t    Tom de Vries  <tom@codesourcery.com>\n\t    Jan Hubicka  <hubicka@ucw.cz>\n\t    Martin Jambor  <mjambor@suse.cz>\n\n\tgcc/\n\t* config/gcn/constraints.md: New file.\n\t* config/gcn/gcn-valu.md: New file.\n\t* config/gcn/gcn.md: New file.\n\t* config/gcn/predicates.md: New file.\n\n\nCo-Authored-By: Jan Hubicka <hubicka@ucw.cz>\nCo-Authored-By: Julian Brown <julian@codesourcery.com>\nCo-Authored-By: Kwok Cheung Yeung <kcy@codesourcery.com>\nCo-Authored-By: Martin Jambor <mjambor@suse.cz>\nCo-Authored-By: Tom de Vries <tom@codesourcery.com>\n\nFrom-SVN: r268022", "tree": {"sha": "22a6f57ee442291acece2318ed96fdcce271e3cf", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/22a6f57ee442291acece2318ed96fdcce271e3cf"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/3d6275e30a850b8e8051163bcd43ddbab2273046", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3d6275e30a850b8e8051163bcd43ddbab2273046", "html_url": "https://github.com/Rust-GCC/gccrs/commit/3d6275e30a850b8e8051163bcd43ddbab2273046", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3d6275e30a850b8e8051163bcd43ddbab2273046/comments", "author": {"login": "ams-cs", "id": 2235130, "node_id": "MDQ6VXNlcjIyMzUxMzA=", "avatar_url": "https://avatars.githubusercontent.com/u/2235130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ams-cs", "html_url": "https://github.com/ams-cs", "followers_url": "https://api.github.com/users/ams-cs/followers", "following_url": "https://api.github.com/users/ams-cs/following{/other_user}", "gists_url": "https://api.github.com/users/ams-cs/gists{/gist_id}", "starred_url": "https://api.github.com/users/ams-cs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ams-cs/subscriptions", "organizations_url": "https://api.github.com/users/ams-cs/orgs", "repos_url": "https://api.github.com/users/ams-cs/repos", "events_url": "https://api.github.com/users/ams-cs/events{/privacy}", "received_events_url": "https://api.github.com/users/ams-cs/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "91d7b7fe84ad6bab8af76fc34e7abef483234ebd", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/91d7b7fe84ad6bab8af76fc34e7abef483234ebd", "html_url": "https://github.com/Rust-GCC/gccrs/commit/91d7b7fe84ad6bab8af76fc34e7abef483234ebd"}], "stats": {"total": 5256, "additions": 5256, "deletions": 0}, "files": [{"sha": "12489cdf8389dc4c3febf42936e42e5723bd7176", "filename": "gcc/ChangeLog", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3d6275e30a850b8e8051163bcd43ddbab2273046/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3d6275e30a850b8e8051163bcd43ddbab2273046/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=3d6275e30a850b8e8051163bcd43ddbab2273046", "patch": "@@ -1,3 +1,15 @@\n+2019-01-17  Andrew Stubbs  <ams@codesourcery.com>\n+\t    Kwok Cheung Yeung  <kcy@codesourcery.com>\n+\t    Julian Brown  <julian@codesourcery.com>\n+\t    Tom de Vries  <tom@codesourcery.com>\n+\t    Jan Hubicka  <hubicka@ucw.cz>\n+\t    Martin Jambor  <mjambor@suse.cz>\n+\n+\t* config/gcn/constraints.md: New file.\n+\t* config/gcn/gcn-valu.md: New file.\n+\t* config/gcn/gcn.md: New file.\n+\t* config/gcn/predicates.md: New file.\n+\n 2019-01-17  Eric Botcazou  <ebotcazou@adacore.com>\n \n \t* gimple-ssa-isolate-paths.c (stmt_uses_name_in_undefined_way): Replace"}, {"sha": "08ba76afc00bc6e2b240ee5ea013191821311f4c", "filename": "gcc/config/gcn/constraints.md", "status": "added", "additions": 139, "deletions": 0, "changes": 139, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3d6275e30a850b8e8051163bcd43ddbab2273046/gcc%2Fconfig%2Fgcn%2Fconstraints.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3d6275e30a850b8e8051163bcd43ddbab2273046/gcc%2Fconfig%2Fgcn%2Fconstraints.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fgcn%2Fconstraints.md?ref=3d6275e30a850b8e8051163bcd43ddbab2273046", "patch": "@@ -0,0 +1,139 @@\n+;; Constraint definitions for GCN.\n+;; Copyright (C) 2016-2019 Free Software Foundation, Inc.\n+;;\n+;; This file is part of GCC.\n+;;\n+;; GCC is free software; you can redistribute it and/or modify\n+;; it under the terms of the GNU General Public License as published by\n+;; the Free Software Foundation; either version 3, or (at your option)\n+;; any later version.\n+;;\n+;; GCC is distributed in the hope that it will be useful,\n+;; but WITHOUT ANY WARRANTY; without even the implied warranty of\n+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+;; GNU General Public License for more details.\n+;;\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+(define_constraint \"I\"\n+  \"Inline integer constant\"\n+  (and (match_code \"const_int\")\n+       (match_test \"ival >= -16 && ival <= 64\")))\n+\n+(define_constraint \"J\"\n+  \"Signed integer 16-bit inline constant\"\n+  (and (match_code \"const_int\")\n+       (match_test \"((unsigned HOST_WIDE_INT) ival + 0x8000) < 0x10000\")))\n+\n+(define_constraint \"Kf\"\n+  \"Immeditate constant -1\"\n+  (and (match_code \"const_int\")\n+       (match_test \"ival == -1\")))\n+\n+(define_constraint \"L\"\n+  \"Unsigned integer 15-bit constant\"\n+  (and (match_code \"const_int\")\n+       (match_test \"((unsigned HOST_WIDE_INT) ival) < 0x8000\")))\n+\n+(define_constraint \"A\"\n+  \"Inline immediate parameter\"\n+  (and (match_code \"const_int,const_double,const_vector\")\n+       (match_test \"gcn_inline_constant_p (op)\")))\n+\n+(define_constraint \"B\"\n+  \"Immediate 32-bit parameter\"\n+  (and (match_code \"const_int,const_double,const_vector\")\n+\t(match_test \"gcn_constant_p (op)\")))\n+\n+(define_constraint \"C\"\n+  \"Immediate 32-bit parameter zero-extended to 64-bits\"\n+  (and (match_code \"const_int,const_double,const_vector\")\n+\t(match_test \"gcn_constant64_p (op)\")))\n+\n+(define_constraint \"DA\"\n+  \"Splittable inline immediate 64-bit parameter\"\n+  (and (match_code \"const_int,const_double,const_vector\")\n+       (match_test \"gcn_inline_constant64_p (op)\")))\n+\n+(define_constraint \"DB\"\n+  \"Splittable immediate 64-bit parameter\"\n+  (match_code \"const_int,const_double,const_vector\"))\n+\n+(define_constraint \"U\"\n+  \"unspecified value\"\n+  (match_code \"unspec\"))\n+\n+(define_constraint \"Y\"\n+  \"Symbol or label for relative calls\"\n+  (match_code \"symbol_ref,label_ref\"))\n+\n+(define_register_constraint \"v\" \"VGPR_REGS\"\n+  \"VGPR registers\")\n+\n+(define_register_constraint \"Sg\" \"SGPR_REGS\"\n+  \"SGPR registers\")\n+\n+(define_register_constraint \"SD\" \"SGPR_DST_REGS\"\n+  \"registers useable as a destination of scalar operation\")\n+\n+(define_register_constraint \"SS\" \"SGPR_SRC_REGS\"\n+  \"registers useable as a source of scalar operation\")\n+\n+(define_register_constraint \"Sm\" \"SGPR_MEM_SRC_REGS\"\n+  \"registers useable as a source of scalar memory operation\")\n+\n+(define_register_constraint \"Sv\" \"SGPR_VOP_SRC_REGS\"\n+  \"registers useable as a source of VOP3A instruction\")\n+\n+(define_register_constraint \"ca\" \"ALL_CONDITIONAL_REGS\"\n+  \"SCC VCCZ or EXECZ\")\n+\n+(define_register_constraint \"cs\" \"SCC_CONDITIONAL_REG\"\n+  \"SCC\")\n+\n+(define_register_constraint \"cV\" \"VCC_CONDITIONAL_REG\"\n+  \"VCC\")\n+\n+(define_register_constraint \"e\" \"EXEC_MASK_REG\"\n+  \"EXEC\")\n+\n+(define_special_memory_constraint \"RB\"\n+  \"Buffer memory address to scratch memory.\"\n+  (and (match_code \"mem\")\n+       (match_test \"AS_SCRATCH_P (MEM_ADDR_SPACE (op))\")))\n+\n+(define_special_memory_constraint \"RF\"\n+  \"Buffer memory address to flat memory.\"\n+  (and (match_code \"mem\")\n+       (match_test \"AS_FLAT_P (MEM_ADDR_SPACE (op))\n+\t\t    && gcn_flat_address_p (XEXP (op, 0), mode)\")))\n+\n+(define_special_memory_constraint \"RS\"\n+  \"Buffer memory address to scalar flat memory.\"\n+  (and (match_code \"mem\")\n+       (match_test \"AS_SCALAR_FLAT_P (MEM_ADDR_SPACE (op))\n+\t\t    && gcn_scalar_flat_mem_p (op)\")))\n+\n+(define_special_memory_constraint \"RL\"\n+  \"Buffer memory address to LDS memory.\"\n+  (and (match_code \"mem\")\n+       (match_test \"AS_LDS_P (MEM_ADDR_SPACE (op))\")))\n+\n+(define_special_memory_constraint \"RG\"\n+  \"Buffer memory address to GDS memory.\"\n+  (and (match_code \"mem\")\n+       (match_test \"AS_GDS_P (MEM_ADDR_SPACE (op))\")))\n+\n+(define_special_memory_constraint \"RD\"\n+  \"Buffer memory address to GDS or LDS memory.\"\n+  (and (match_code \"mem\")\n+       (ior (match_test \"AS_GDS_P (MEM_ADDR_SPACE (op))\")\n+\t    (match_test \"AS_LDS_P (MEM_ADDR_SPACE (op))\"))))\n+\n+(define_special_memory_constraint \"RM\"\n+  \"Memory address to global (main) memory.\"\n+  (and (match_code \"mem\")\n+       (match_test \"AS_GLOBAL_P (MEM_ADDR_SPACE (op))\n+\t\t    && gcn_global_address_p (XEXP (op, 0))\")))"}, {"sha": "3cc59dd1cd6cb2de0ac710634bb51dd3a31172d9", "filename": "gcc/config/gcn/gcn-valu.md", "status": "added", "additions": 3049, "deletions": 0, "changes": 3049, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3d6275e30a850b8e8051163bcd43ddbab2273046/gcc%2Fconfig%2Fgcn%2Fgcn-valu.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3d6275e30a850b8e8051163bcd43ddbab2273046/gcc%2Fconfig%2Fgcn%2Fgcn-valu.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fgcn%2Fgcn-valu.md?ref=3d6275e30a850b8e8051163bcd43ddbab2273046"}, {"sha": "4573a4ce32f0b3982170349b7667c71c454df50a", "filename": "gcc/config/gcn/gcn.md", "status": "added", "additions": 1857, "deletions": 0, "changes": 1857, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3d6275e30a850b8e8051163bcd43ddbab2273046/gcc%2Fconfig%2Fgcn%2Fgcn.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3d6275e30a850b8e8051163bcd43ddbab2273046/gcc%2Fconfig%2Fgcn%2Fgcn.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fgcn%2Fgcn.md?ref=3d6275e30a850b8e8051163bcd43ddbab2273046", "patch": "@@ -0,0 +1,1857 @@\n+;; Copyright (C) 2016-2019 Free Software Foundation, Inc.\n+\n+;; This file is free software; you can redistribute it and/or modify it under\n+;; the terms of the GNU General Public License as published by the Free\n+;; Software Foundation; either version 3 of the License, or (at your option)\n+;; any later version.\n+\n+;; This file is distributed in the hope that it will be useful, but WITHOUT\n+;; ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+;; FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+;; for more details.\n+\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+;;- See file \"rtl.def\" for documentation on define_insn, match_*, et. al.\n+\n+(include \"predicates.md\")\n+(include \"constraints.md\")\n+\n+;; {{{ Constants and enums\n+\n+; Named registers\n+(define_constants\n+  [(FIRST_SGPR_REG\t\t 0)\n+   (LAST_SGPR_REG\t\t 101)\n+   (FLAT_SCRATCH_REG\t\t 102)\n+   (FLAT_SCRATCH_LO_REG\t\t 102)\n+   (FLAT_SCRATCH_HI_REG\t\t 103)\n+   (XNACK_MASK_REG\t\t 104)\n+   (XNACK_MASK_LO_REG\t\t 104)\n+   (XNACK_MASK_HI_REG\t\t 105)\n+   (VCC_REG\t\t\t 106)\n+   (VCC_LO_REG\t\t\t 106)\n+   (VCC_HI_REG\t\t\t 107)\n+   (VCCZ_REG\t\t\t 108)\n+   (TBA_REG\t\t\t 109)\n+   (TBA_LO_REG\t\t\t 109)\n+   (TBA_HI_REG\t\t\t 110)\n+   (TMA_REG\t\t\t 111)\n+   (TMA_LO_REG\t\t\t 111)\n+   (TMA_HI_REG\t\t\t 112)\n+   (TTMP0_REG\t\t\t 113)\n+   (TTMP11_REG\t\t\t 124)\n+   (M0_REG\t\t\t 125)\n+   (EXEC_REG\t\t\t 126)\n+   (EXEC_LO_REG\t\t\t 126)\n+   (EXEC_HI_REG\t\t\t 127)\n+   (EXECZ_REG\t\t\t 128)\n+   (SCC_REG\t\t\t 129)\n+   (FIRST_VGPR_REG\t\t 160)\n+   (LAST_VGPR_REG\t\t 415)])\n+\n+(define_constants\n+  [(SP_REGNUM 16)\n+   (LR_REGNUM 18)\n+   (AP_REGNUM 416)\n+   (FP_REGNUM 418)])\n+\n+(define_c_enum \"unspecv\" [\n+  UNSPECV_PROLOGUE_USE\n+  UNSPECV_KERNEL_RETURN\n+  UNSPECV_BARRIER\n+  UNSPECV_ATOMIC\n+  UNSPECV_ICACHE_INV])\n+\n+(define_c_enum \"unspec\" [\n+  UNSPEC_VECTOR\n+  UNSPEC_BPERMUTE\n+  UNSPEC_SGPRBASE\n+  UNSPEC_MEMORY_BARRIER\n+  UNSPEC_SMIN_DPP_SHR UNSPEC_SMAX_DPP_SHR\n+  UNSPEC_UMIN_DPP_SHR UNSPEC_UMAX_DPP_SHR\n+  UNSPEC_PLUS_DPP_SHR\n+  UNSPEC_PLUS_CARRY_DPP_SHR UNSPEC_PLUS_CARRY_IN_DPP_SHR\n+  UNSPEC_AND_DPP_SHR UNSPEC_IOR_DPP_SHR UNSPEC_XOR_DPP_SHR\n+  UNSPEC_MOV_FROM_LANE63\n+  UNSPEC_GATHER\n+  UNSPEC_SCATTER])\n+\n+;; }}}\n+;; {{{ Attributes\n+\n+; Instruction type (encoding) as described in the ISA specification.\n+; The following table summarizes possible operands of individual instruction\n+; types and corresponding constraints.\n+;\n+; sop2 - scalar, two inputs, one output\n+;\t ssrc0/ssrc1: sgpr 0-102; flat_scratch,xnack,vcc,tba,tma,ttmp0-11,exec\n+;\t\t      vccz,execz,scc,inline immedate,fp inline immediate\n+;\t sdst: sgpr 0-102; flat_scratch,xnack,vcc,tba,tma,ttmp0-11,exec\n+;\n+;\t Constraints \"=SD, SD\", \"SSA,SSB\",\"SSB,SSA\"\n+;\n+; sopk - scalar, inline constant input, one output\n+;\t simm16: 16bit inline constant\n+;\t sdst: same as sop2/ssrc0\n+;\n+;\t Constraints \"=SD\", \"J\"\n+;\n+; sop1 - scalar, one input, one output\n+;\t ssrc0: same as sop2/ssrc0.  FIXME: manual omit VCCZ\n+;\t sdst: same as sop2/sdst\n+;\n+;\t Constraints \"=SD\", \"SSA\"\n+;\n+; sopc - scalar, two inputs, one comparsion\n+;\t ssrc0: same as sop2/ssc0.\n+;\n+;\t Constraints \"SSI,SSA\",\"SSA,SSI\"\n+;\n+; sopp - scalar, one constant input, one special\n+;\t simm16\n+;\n+; smem - scalar memory\n+;\t sbase: aligned pair of sgprs.  Specify {size[15:0], base[47:0]} in\n+;               dwords\n+;\t sdata: sgpr0-102, flat_scratch, xnack, vcc, tba, tma\n+;\t offset: sgpr or 20bit unsigned byte offset\n+;\n+; vop2 - vector, two inputs, one output\n+;\t vsrc0: sgpr0-102,flat_scratch,xnack,vcc,tba,ttmp0-11,m0,exec,\n+;\t\tinline constant -16 to -64, fp inline immediate, vccz, execz,\n+;\t\tscc, lds, literal constant, vgpr0-255\n+;\t vsrc1: vgpr0-255\n+;\t vdst: vgpr0-255\n+;\t Limitations: At most one SGPR, at most one constant\n+;\t\t      if constant is used, SGPR must be M0\n+;\t\t      Only SRC0 can be LDS_DIRECT\n+;\n+;\t constraints: \"=v\", \"vBSv\", \"v\"\n+;\n+; vop1 - vector, one input, one output\n+;\t vsrc0: same as vop2/src0\n+;\t vdst: vgpr0-255\n+;\n+;\t constraints: \"=v\", \"vBSv\"\n+;\n+; vopc - vector, two inputs, one comparsion output;\n+;\t vsrc0: same as vop2/src0\n+;\t vsrc1: vgpr0-255\n+;\t vdst:\n+;\n+;\t constraints: \"vASv\", \"v\"\n+;\n+; vop3a - vector, three inputs, one output\n+;\t vdst: vgpr0-255, for v_cmp sgpr or vcc\n+;\t abs,clamp\n+;\t vsrc0: sgpr0-102,vcc,tba,ttmp0-11,m0,exec,\n+;\t\tinline constant -16 to -64, fp inline immediate, vccz, execz,\n+;\t\tscc, lds_direct\n+;\t\tFIXME: really missing 1/pi? really 104 SGPRs\n+;\n+; vop3b - vector, three inputs, one vector output, one scalar output\n+;\t vsrc0,vsrc1,vsrc2: same as vop3a vsrc0\n+;\t vdst: vgpr0-255\n+;\t sdst: sgpr0-103/vcc/tba/tma/ttmp0-11\n+;\n+; vop_sdwa - second dword for vop1/vop2/vopc for specifying sub-dword address\n+;\t src0: vgpr0-255\n+;\t dst_sel: BYTE_0-3, WORD_0-1, DWORD\n+;\t dst_unused: UNUSED_PAD, UNUSED_SEXT, UNUSED_PRESERVE\n+;\t clamp: true/false\n+;\t src0_sel: BYTE_0-3, WORD_0-1, DWORD\n+;\t flags: src0_sext, src0_neg, src0_abs, src1_sel, src1_sext, src1_neg,\n+  ;\t\tsrc1_abs\n+;\n+; vop_dpp - second dword for vop1/vop2/vopc for specifying data-parallel ops\n+;\t src0: vgpr0-255\n+;\t dpp_ctrl: quad_perm, row_sl0-15, row_sr0-15, row_rr0-15, wf_sl1,\n+;\t\t  wf_rl1, wf_sr1, wf_rr1, row_mirror, row_half_mirror,\n+;\t\t  bcast15, bcast31\n+;\t flags: src0_neg, src0_abs, src1_neg, src1_abs\n+;\t bank_mask: 4-bit mask\n+;\t row_mask: 4-bit mask\n+;\n+; ds - Local and global data share instructions.\n+;\t offset0: 8-bit constant\n+;\t offset1: 8-bit constant\n+;\t flag: gds\n+;\t addr: vgpr0-255\n+;\t data0: vgpr0-255\n+;\t data1: vgpr0-255\n+;\t vdst: vgpr0-255\n+;\n+; mubuf - Untyped memory buffer operation. First word with LDS, second word\n+;\t  non-LDS.\n+;\t offset: 12-bit constant\n+;\t vaddr: vgpr0-255\n+;\t vdata: vgpr0-255\n+;\t srsrc: sgpr0-102\n+;\t soffset: sgpr0-102\n+;\t flags: offen, idxen, glc, lds, slc, tfe\n+;\n+; mtbuf - Typed memory buffer operation. Two words\n+;\t offset: 12-bit constant\n+;\t dfmt: 4-bit constant\n+;\t nfmt: 3-bit constant\n+;\t vaddr: vgpr0-255\n+;\t vdata: vgpr0-255\n+;\t srsrc: sgpr0-102\n+;\t soffset: sgpr0-102\n+;\t flags: offen, idxen, glc, lds, slc, tfe\n+;\n+; flat - flat or global memory operations\n+;\t flags: glc, slc\n+;\t addr: vgpr0-255\n+;\t data: vgpr0-255\n+;\t vdst: vgpr0-255\n+;\n+; mult - expands to multiple instructions (pseudo encoding)\n+;\n+; vmult - as mult, when a vector instruction is used.\n+\n+(define_attr \"type\"\n+\t     \"unknown,sop1,sop2,sopk,sopc,sopp,smem,ds,vop2,vop1,vopc,\n+\t      vop3a,vop3b,vop_sdwa,vop_dpp,mubuf,mtbuf,flat,mult,vmult\"\n+\t     (const_string \"unknown\"))\n+\n+; Set if instruction is executed in scalar or vector unit\n+\n+(define_attr \"unit\" \"unknown,scalar,vector\"\n+  (cond [(eq_attr \"type\" \"sop1,sop2,sopk,sopc,sopp,smem,mult\")\n+\t    (const_string \"scalar\")\n+\t (eq_attr \"type\" \"vop2,vop1,vopc,vop3a,vop3b,ds,\n+\t\t\t  vop_sdwa,vop_dpp,flat,vmult\")\n+\t    (const_string \"vector\")]\n+\t (const_string \"unknown\")))\n+\n+; All vector instructions run as 64 threads as predicated by the EXEC\n+; register.  Scalar operations in vector register require a single lane\n+; enabled, vector moves require a full set of lanes enabled, and most vector\n+; operations handle the lane masking themselves.\n+; The md_reorg pass is responsible for ensuring that EXEC is set appropriately\n+; according to the following settings:\n+;   auto   - md_reorg will inspect def/use to determine what to do.\n+;   none   - exec is not needed.\n+;   single - disable all but lane zero.\n+;   full   - enable all lanes.\n+\n+(define_attr \"exec\" \"auto,none,single,full\"\n+   (const_string \"auto\"))\n+\n+; Infer the (worst-case) length from the instruction type by default.  Many\n+; types can have an optional immediate word following, which we include here.\n+; \"Multiple\" types are counted as two 64-bit instructions.  This is just a\n+; default fallback: it can be overridden per-alternative in insn patterns for\n+; greater accuracy.\n+\n+(define_attr \"length\" \"\"\n+  (cond [(eq_attr \"type\" \"sop1\") (const_int 8)\n+\t (eq_attr \"type\" \"sop2\") (const_int 8)\n+\t (eq_attr \"type\" \"sopk\") (const_int 8)\n+\t (eq_attr \"type\" \"sopc\") (const_int 8)\n+\t (eq_attr \"type\" \"sopp\") (const_int 4)\n+\t (eq_attr \"type\" \"smem\") (const_int 8)\n+\t (eq_attr \"type\" \"ds\")   (const_int 8)\n+\t (eq_attr \"type\" \"vop1\") (const_int 8)\n+\t (eq_attr \"type\" \"vop2\") (const_int 8)\n+\t (eq_attr \"type\" \"vopc\") (const_int 8)\n+\t (eq_attr \"type\" \"vop3a\") (const_int 8)\n+\t (eq_attr \"type\" \"vop3b\") (const_int 8)\n+\t (eq_attr \"type\" \"vop_sdwa\") (const_int 8)\n+\t (eq_attr \"type\" \"vop_dpp\") (const_int 8)\n+\t (eq_attr \"type\" \"flat\") (const_int 8)\n+\t (eq_attr \"type\" \"mult\") (const_int 16)\n+\t (eq_attr \"type\" \"vmult\") (const_int 16)]\n+\t(const_int 4)))\n+\n+; Disable alternatives that only apply to specific ISA variants.\n+\n+(define_attr \"gcn_version\" \"gcn3,gcn5\" (const_string \"gcn3\"))\n+\n+(define_attr \"enabled\" \"\"\n+  (cond [(eq_attr \"gcn_version\" \"gcn3\") (const_int 1)\n+\t (and (eq_attr \"gcn_version\" \"gcn5\")\n+\t      (ne (symbol_ref \"TARGET_GCN5_PLUS\") (const_int 0)))\n+\t   (const_int 1)]\n+\t(const_int 0)))\n+\n+; We need to be able to identify v_readlane and v_writelane with\n+; SGPR lane selection in order to handle \"Manually Inserted Wait States\".\n+\n+(define_attr \"laneselect\" \"yes,no\" (const_string \"no\"))\n+\n+;; }}}\n+;; {{{ Iterators useful across the wole machine description\n+\n+(define_mode_iterator SIDI [SI DI])\n+(define_mode_iterator SFDF [SF DF])\n+(define_mode_iterator SISF [SI SF])\n+(define_mode_iterator QIHI [QI HI])\n+(define_mode_iterator DIDF [DI DF])\n+\n+;; }}}\n+;; {{{ Attributes.\n+\n+; Translate RTX code into GCN instruction mnemonics with and without\n+; suffixes such as _b32, etc.\n+\n+(define_code_attr mnemonic\n+  [(minus \"sub%i\")\n+   (plus \"add%i\")\n+   (ashift \"lshl%b\")\n+   (lshiftrt \"lshr%b\")\n+   (ashiftrt \"ashr%i\")\n+   (and \"and%B\")\n+   (ior \"or%B\")\n+   (xor \"xor%B\")\n+   (mult \"mul%i\")\n+   (smin \"min%i\")\n+   (smax \"max%i\")\n+   (umin \"min%u\")\n+   (umax \"max%u\")\n+   (not \"not%b\")\n+   (popcount \"bcnt_u32%b\")])\n+\n+(define_code_attr bare_mnemonic\n+  [(plus \"add\")\n+   (minus \"sub\")\n+   (and \"and\")\n+   (ior \"or\")\n+   (xor \"xor\")])\n+\n+(define_code_attr s_mnemonic\n+  [(not \"not%b\")\n+   (popcount \"bcnt1_i32%b\")])\n+\n+(define_code_attr revmnemonic\n+  [(minus \"subrev%i\")\n+   (ashift \"lshlrev%b\")\n+   (lshiftrt \"lshrrev%b\")\n+   (ashiftrt \"ashrrev%i\")])\n+\n+; Translate RTX code into corresponding expander name.\n+\n+(define_code_attr expander\n+  [(and \"and\")\n+   (ior \"ior\")\n+   (xor \"xor\")\n+   (plus \"add\")\n+   (minus \"sub\")\n+   (ashift \"ashl\")\n+   (lshiftrt \"lshr\")\n+   (ashiftrt \"ashr\")\n+   (mult \"mul\")\n+   (smin \"smin\")\n+   (smax \"smax\")\n+   (umin \"umin\")\n+   (umax \"umax\")\n+   (not \"one_cmpl\")\n+   (popcount \"popcount\")])\n+\n+;; }}}\n+;; {{{ Miscellaneous instructions\n+\n+(define_insn \"nop\"\n+  [(const_int 0)]\n+  \"\"\n+  \"s_nop\\t0x0\"\n+  [(set_attr \"type\" \"sopp\")])\n+\n+; FIXME: What should the value of the immediate be? Zero is disallowed, so\n+; pick 1 for now.\n+(define_insn \"trap\"\n+  [(trap_if (const_int 1) (const_int 0))]\n+  \"\"\n+  \"s_trap\\t1\"\n+  [(set_attr \"type\" \"sopp\")])\n+\n+;; }}}\n+;; {{{ Moves\n+\n+;; All scalar modes we support moves in.\n+(define_mode_iterator MOV_MODE [BI QI HI SI DI TI SF DF])\n+\n+; This is the entry point for creating all kinds of scalar moves,\n+; including reloads and symbols.\n+\n+(define_expand \"mov<mode>\"\n+  [(set (match_operand:MOV_MODE 0 \"nonimmediate_operand\")\n+\t(match_operand:MOV_MODE 1 \"general_operand\"))]\n+  \"\"\n+  {\n+    if (MEM_P (operands[0]))\n+      operands[1] = force_reg (<MODE>mode, operands[1]);\n+\n+    if (!lra_in_progress && !reload_completed\n+\t&& !gcn_valid_move_p (<MODE>mode, operands[0], operands[1]))\n+      {\n+\t/* Something is probably trying to generate a move\n+\t   which can only work indirectly.\n+\t   E.g. Move from LDS memory to SGPR hardreg\n+\t     or MEM:QI to SGPR.  */\n+\trtx tmpreg = gen_reg_rtx (<MODE>mode);\n+\temit_insn (gen_mov<mode> (tmpreg, operands[1]));\n+\temit_insn (gen_mov<mode> (operands[0], tmpreg));\n+\tDONE;\n+      }\n+\n+    if (<MODE>mode == DImode\n+\t&& (GET_CODE (operands[1]) == SYMBOL_REF\n+\t    || GET_CODE (operands[1]) == LABEL_REF))\n+      {\n+\temit_insn (gen_movdi_symbol (operands[0], operands[1]));\n+\tDONE;\n+      }\n+  })\n+\n+; Split invalid moves into two valid moves\n+\n+(define_split\n+  [(set (match_operand:MOV_MODE 0 \"nonimmediate_operand\")\n+\t(match_operand:MOV_MODE 1 \"general_operand\"))]\n+  \"!reload_completed && !lra_in_progress\n+   && !gcn_valid_move_p (<MODE>mode, operands[0], operands[1])\"\n+  [(set (match_dup 2) (match_dup 1))\n+   (set (match_dup 0) (match_dup 2))]\n+  {\n+    operands[2] = gen_reg_rtx(<MODE>mode);\n+  })\n+\n+; We need BImode move so we can reload flags registers.\n+\n+(define_insn \"*movbi\"\n+  [(set (match_operand:BI 0 \"nonimmediate_operand\"\n+\t\t\t\t    \"=Sg,   v,Sg,cs,cV,cV,Sm,RS, v,RF, v,RM\")\n+\t(match_operand:BI 1 \"gcn_load_operand\"\n+\t\t\t\t    \"SSA,vSvA, v,SS, v,SS,RS,Sm,RF, v,RM, v\"))]\n+  \"\"\n+  {\n+    /* SCC as an operand is currently not accepted by the LLVM assembler, so\n+       we emit bytes directly as a workaround.  */\n+    switch (which_alternative) {\n+    case 0:\n+      if (REG_P (operands[1]) && REGNO (operands[1]) == SCC_REG)\n+\treturn \"; s_mov_b32\\t%0,%1 is not supported by the assembler.\\;\"\n+\t       \".byte\\t0xfd\\;\"\n+\t       \".byte\\t0x0\\;\"\n+\t       \".byte\\t0x80|%R0\\;\"\n+\t       \".byte\\t0xbe\";\n+      else\n+\treturn \"s_mov_b32\\t%0, %1\";\n+    case 1:\n+      if (REG_P (operands[1]) && REGNO (operands[1]) == SCC_REG)\n+\treturn \"; v_mov_b32\\t%0, %1\\;\"\n+\t       \".byte\\t0xfd\\;\"\n+\t       \".byte\\t0x2\\;\"\n+\t       \".byte\\t((%V0<<1)&0xff)\\;\"\n+\t       \".byte\\t0x7e|(%V0>>7)\";\n+      else\n+\treturn \"v_mov_b32\\t%0, %1\";\n+    case 2:\n+      return \"v_readlane_b32\\t%0, %1, 0\";\n+    case 3:\n+      return \"s_cmpk_lg_u32\\t%1, 0\";\n+    case 4:\n+      return \"v_cmp_ne_u32\\tvcc, 0, %1\";\n+    case 5:\n+      if (REGNO (operands[1]) == SCC_REG)\n+\treturn \"; s_mov_b32\\t%0, %1 is not supported by the assembler.\\;\"\n+\t       \".byte\\t0xfd\\;\"\n+\t       \".byte\\t0x0\\;\"\n+\t       \".byte\\t0xea\\;\"\n+\t       \".byte\\t0xbe\\;\"\n+\t       \"s_mov_b32\\tvcc_hi, 0\";\n+      else\n+\treturn \"s_mov_b32\\tvcc_lo, %1\\;\"\n+\t       \"s_mov_b32\\tvcc_hi, 0\";\n+    case 6:\n+      return \"s_load_dword\\t%0, %A1\\;s_waitcnt\\tlgkmcnt(0)\";\n+    case 7:\n+      return \"s_store_dword\\t%1, %A0\\;s_waitcnt\\texpcnt(0)\";\n+    case 8:\n+      return \"flat_load_dword\\t%0, %A1%O1%g1\\;s_waitcnt\\t0\";\n+    case 9:\n+      return \"flat_store_dword\\t%A0, %1%O0%g0\\;s_waitcnt\\texpcnt(0)\";\n+    case 10:\n+      return \"global_load_dword\\t%0, %A1%O1%g1\\;s_waitcnt\\tvmcnt(0)\";\n+    case 11:\n+      return \"global_store_dword\\t%A0, %1%O0%g0\\;s_waitcnt\\texpcnt(0)\";\n+    default:\n+      gcc_unreachable ();\n+    }\n+  }\n+  [(set_attr \"type\" \"sop1,vop1,vop3a,sopk,vopc,mult,smem,smem,flat,flat,\n+\t\t     flat,flat\")\n+   (set_attr \"exec\" \"*,*,none,*,*,*,*,*,*,*,*,*\")\n+   (set_attr \"length\" \"4,4,4,4,4,8,12,12,12,12,12,12\")])\n+\n+; 32bit move pattern\n+\n+(define_insn \"*mov<mode>_insn\"\n+  [(set (match_operand:SISF 0 \"nonimmediate_operand\"\n+\t\t  \"=SD,SD,SD,SD,RB,Sm,RS,v,Sg, v, v,RF,v,RLRG,   v,SD, v,RM\")\n+\t(match_operand:SISF 1 \"gcn_load_operand\"\n+\t\t  \"SSA, J, B,RB,Sm,RS,Sm,v, v,Sv,RF, v,B,   v,RLRG, Y,RM, v\"))]\n+  \"\"\n+  \"@\n+  s_mov_b32\\t%0, %1\n+  s_movk_i32\\t%0, %1\n+  s_mov_b32\\t%0, %1\n+  s_buffer_load%s0\\t%0, s[0:3], %1\\;s_waitcnt\\tlgkmcnt(0)\n+  s_buffer_store%s1\\t%1, s[0:3], %0\\;s_waitcnt\\texpcnt(0)\n+  s_load_dword\\t%0, %A1\\;s_waitcnt\\tlgkmcnt(0)\n+  s_store_dword\\t%1, %A0\\;s_waitcnt\\texpcnt(0)\n+  v_mov_b32\\t%0, %1\n+  v_readlane_b32\\t%0, %1, 0\n+  v_writelane_b32\\t%0, %1, 0\n+  flat_load_dword\\t%0, %A1%O1%g1\\;s_waitcnt\\t0\n+  flat_store_dword\\t%A0, %1%O0%g0\\;s_waitcnt\\texpcnt(0)\n+  v_mov_b32\\t%0, %1\n+  ds_write_b32\\t%A0, %1%O0\\;s_waitcnt\\texpcnt(0)\n+  ds_read_b32\\t%0, %A1%O1\\;s_waitcnt\\tlgkmcnt(0)\n+  s_mov_b32\\t%0, %1\n+  global_load_dword\\t%0, %A1%O1%g1\\;s_waitcnt\\tvmcnt(0)\n+  global_store_dword\\t%A0, %1%O0%g0\\;s_waitcnt\\texpcnt(0)\"\n+  [(set_attr \"type\" \"sop1,sopk,sop1,smem,smem,smem,smem,vop1,vop3a,vop3a,flat,\n+\t\t     flat,vop1,ds,ds,sop1,flat,flat\")\n+   (set_attr \"exec\" \"*,*,*,*,*,*,*,*,none,none,*,*,*,*,*,*,*,*\")\n+   (set_attr \"length\" \"4,4,8,12,12,12,12,4,8,8,12,12,8,12,12,8,12,12\")])\n+\n+; 8/16bit move pattern\n+\n+(define_insn \"*mov<mode>_insn\"\n+  [(set (match_operand:QIHI 0 \"nonimmediate_operand\"\n+\t\t\t\t \"=SD,SD,SD,v,Sg, v, v,RF,v,RLRG,   v, v,RM\")\n+\t(match_operand:QIHI 1 \"gcn_load_operand\"\n+\t\t\t\t \"SSA, J, B,v, v,Sv,RF, v,B,   v,RLRG,RM, v\"))]\n+  \"gcn_valid_move_p (<MODE>mode, operands[0], operands[1])\"\n+  \"@\n+  s_mov_b32\\t%0, %1\n+  s_movk_i32\\t%0, %1\n+  s_mov_b32\\t%0, %1\n+  v_mov_b32\\t%0, %1\n+  v_readlane_b32\\t%0, %1, 0\n+  v_writelane_b32\\t%0, %1, 0\n+  flat_load%o1\\t%0, %A1%O1%g1\\;s_waitcnt\\t0\n+  flat_store%s0\\t%A0, %1%O0%g0\\;s_waitcnt\\texpcnt(0)\n+  v_mov_b32\\t%0, %1\n+  ds_write%b0\\t%A0, %1%O0\\;s_waitcnt\\texpcnt(0)\n+  ds_read%u1\\t%0, %A1%O1\\;s_waitcnt\\tlgkmcnt(0)\n+  global_load%o1\\t%0, %A1%O1%g1\\;s_waitcnt\\tvmcnt(0)\n+  global_store%s0\\t%A0, %1%O0%g0\\;s_waitcnt\\texpcnt(0)\"\n+  [(set_attr \"type\"\n+\t     \"sop1,sopk,sop1,vop1,vop3a,vop3a,flat,flat,vop1,ds,ds,flat,flat\")\n+   (set_attr \"exec\" \"*,*,*,*,none,none,*,*,*,*,*,*,*\")\n+   (set_attr \"length\" \"4,4,8,4,4,4,12,12,8,12,12,12,12\")])\n+\n+; 64bit move pattern\n+\n+(define_insn_and_split \"*mov<mode>_insn\"\n+  [(set (match_operand:DIDF 0 \"nonimmediate_operand\"\n+\t\t\t  \"=SD,SD,SD,RS,Sm,v, v,Sg, v, v,RF,RLRG,   v, v,RM\")\n+\t(match_operand:DIDF 1 \"general_operand\"\n+\t\t\t  \"SSA, C,DB,Sm,RS,v,DB, v,Sv,RF, v,   v,RLRG,RM, v\"))]\n+  \"GET_CODE(operands[1]) != SYMBOL_REF\"\n+  \"@\n+  s_mov_b64\\t%0, %1\n+  s_mov_b64\\t%0, %1\n+  #\n+  s_store_dwordx2\\t%1, %A0\\;s_waitcnt\\texpcnt(0)\n+  s_load_dwordx2\\t%0, %A1\\;s_waitcnt\\tlgkmcnt(0)\n+  #\n+  #\n+  #\n+  #\n+  flat_load_dwordx2\\t%0, %A1%O1%g1\\;s_waitcnt\\t0\n+  flat_store_dwordx2\\t%A0, %1%O0%g0\\;s_waitcnt\\texpcnt(0)\n+  ds_write_b64\\t%A0, %1%O0\\;s_waitcnt\\texpcnt(0)\n+  ds_read_b64\\t%0, %A1%O1\\;s_waitcnt\\tlgkmcnt(0)\n+  global_load_dwordx2\\t%0, %A1%O1%g1\\;s_waitcnt\\tvmcnt(0)\n+  global_store_dwordx2\\t%A0, %1%O0%g0\\;s_waitcnt\\texpcnt(0)\"\n+  \"(reload_completed && !MEM_P (operands[0]) && !MEM_P (operands[1])\n+    && !gcn_sgpr_move_p (operands[0], operands[1]))\n+   || (GET_CODE (operands[1]) == CONST_INT && !gcn_constant64_p (operands[1]))\"\n+  [(set (match_dup 0) (match_dup 1))\n+   (set (match_dup 2) (match_dup 3))]\n+  {\n+    rtx inlo = gen_lowpart (SImode, operands[1]);\n+    rtx inhi = gen_highpart_mode (SImode, <MODE>mode, operands[1]);\n+    rtx outlo = gen_lowpart (SImode, operands[0]);\n+    rtx outhi = gen_highpart_mode (SImode, <MODE>mode, operands[0]);\n+\n+    /* Ensure that overlapping registers aren't corrupted.  */\n+    if (REGNO (outlo) == REGNO (inhi))\n+      {\n+\toperands[0] = outhi;\n+\toperands[1] = inhi;\n+\toperands[2] = outlo;\n+\toperands[3] = inlo;\n+      }\n+    else\n+      {\n+\toperands[0] = outlo;\n+\toperands[1] = inlo;\n+\toperands[2] = outhi;\n+\toperands[3] = inhi;\n+      }\n+  }\n+  [(set_attr \"type\" \"sop1,sop1,mult,smem,smem,vmult,vmult,vmult,vmult,flat,\n+\t\t     flat,ds,ds,flat,flat\")\n+   (set_attr \"length\" \"4,8,*,12,12,*,*,*,*,12,12,12,12,12,12\")])\n+\n+; 128-bit move.\n+\n+(define_insn_and_split \"*movti_insn\"\n+  [(set (match_operand:TI 0 \"nonimmediate_operand\"\n+\t\t\t\t      \"=SD,RS,Sm,RF, v,v, v,SD,RM, v,RL, v\")\n+\t(match_operand:TI 1 \"general_operand\"  \n+\t\t\t\t      \"SSB,Sm,RS, v,RF,v,Sv, v, v,RM, v,RL\"))]\n+  \"\"\n+  \"@\n+  #\n+  s_store_dwordx4\\t%1, %A0\\;s_waitcnt\\texpcnt(0)\n+  s_load_dwordx4\\t%0, %A1\\;s_waitcnt\\tlgkmcnt(0)\n+  flat_store_dwordx4\\t%A0, %1%O0%g0\\;s_waitcnt\\texpcnt(0)\n+  flat_load_dwordx4\\t%0, %A1%O1%g1\\;s_waitcnt\\t0\n+  #\n+  #\n+  #\n+  global_store_dwordx4\\t%A0, %1%O0%g0\\;s_waitcnt\\texpcnt(0)\n+  global_load_dwordx4\\t%0, %A1%O1%g1\\;s_waitcnt\\tvmcnt(0)\n+  ds_write_b128\\t%A0, %1%O0\\;s_waitcnt\\texpcnt(0)\n+  ds_read_b128\\t%0, %A1%O1\\;s_waitcnt\\tlgkmcnt(0)\"\n+  \"reload_completed\n+   && REG_P (operands[0])\n+   && (REG_P (operands[1]) || GET_CODE (operands[1]) == CONST_INT)\"\n+  [(set (match_dup 0) (match_dup 1))\n+   (set (match_dup 2) (match_dup 3))\n+   (set (match_dup 4) (match_dup 5))\n+   (set (match_dup 6) (match_dup 7))]\n+  {\n+    operands[6] = gcn_operand_part (TImode, operands[0], 3);\n+    operands[7] = gcn_operand_part (TImode, operands[1], 3);\n+    operands[4] = gcn_operand_part (TImode, operands[0], 2);\n+    operands[5] = gcn_operand_part (TImode, operands[1], 2);\n+    operands[2] = gcn_operand_part (TImode, operands[0], 1);\n+    operands[3] = gcn_operand_part (TImode, operands[1], 1);\n+    operands[0] = gcn_operand_part (TImode, operands[0], 0);\n+    operands[1] = gcn_operand_part (TImode, operands[1], 0);\n+  }\n+  [(set_attr \"type\" \"mult,smem,smem,flat,flat,vmult,vmult,vmult,flat,flat,\\\n+\t\t     ds,ds\")\n+   (set_attr \"length\" \"*,12,12,12,12,*,*,*,12,12,12,12\")])\n+\n+;; }}}\n+;; {{{ Prologue/Epilogue\n+\n+(define_insn \"prologue_use\"\n+  [(unspec_volatile [(match_operand 0)] UNSPECV_PROLOGUE_USE)]\n+  \"\"\n+  \"\"\n+  [(set_attr \"length\" \"0\")])\n+\n+(define_expand \"prologue\"\n+  [(const_int 0)]\n+  \"\"\n+  {\n+    gcn_expand_prologue ();\n+    DONE;\n+  })\n+\n+(define_expand \"epilogue\"\n+  [(const_int 0)]\n+  \"\"\n+  {\n+    gcn_expand_epilogue ();\n+    DONE;\n+  })\n+\n+;; }}}\n+;; {{{ Control flow\n+\n+; This pattern must satisfy simplejump_p, which means it cannot be a parallel\n+; that clobbers SCC.  Thus, we must preserve SCC if we're generating a long\n+; branch sequence.\n+\n+(define_insn \"jump\"\n+  [(set (pc)\n+\t(label_ref (match_operand 0)))]\n+  \"\"\n+  {\n+    if (get_attr_length (insn) == 4)\n+      return \"s_branch\\t%0\";\n+    else\n+      /* !!! This sequence clobbers EXEC_SAVE_REG and CC_SAVE_REG.  */\n+      return \"; s_mov_b32\\ts22, scc is not supported by the assembler.\\;\"\n+\t     \".long\\t0xbe9600fd\\;\"\n+\t     \"s_getpc_b64\\ts[20:21]\\;\"\n+\t     \"s_add_u32\\ts20, s20, %0@rel32@lo+4\\;\"\n+\t     \"s_addc_u32\\ts21, s21, %0@rel32@hi+4\\;\"\n+\t     \"s_cmpk_lg_u32\\ts22, 0\\;\"\n+\t     \"s_setpc_b64\\ts[20:21]\";\n+  }\n+  [(set_attr \"type\" \"sopp\")\n+   (set (attr \"length\")\n+\t(if_then_else (and (ge (minus (match_dup 0) (pc))\n+\t\t\t       (const_int -131072))\n+\t\t\t   (lt (minus (match_dup 0) (pc))\n+\t\t\t       (const_int 131072)))\n+\t\t      (const_int 4)\n+\t\t      (const_int 32)))])\n+\n+(define_insn \"indirect_jump\"\n+  [(set (pc)\n+\t(match_operand:DI 0 \"register_operand\" \"Sg\"))]\n+  \"\"\n+  \"s_setpc_b64\\t%0\"\n+  [(set_attr \"type\" \"sop1\")\n+   (set_attr \"length\" \"4\")])\n+\n+(define_insn \"cjump\"\n+  [(set (pc)\n+\t(if_then_else\n+\t  (match_operator:BI 1 \"gcn_conditional_operator\"\n+\t    [(match_operand:BI 2 \"gcn_conditional_register_operand\" \"ca,cV\")\n+\t     (const_int 0)])\n+\t  (label_ref (match_operand 0))\n+\t  (pc)))]\n+  \"\"\n+  {\n+    if (get_attr_length (insn) == 4)\n+      return \"s_cbranch%C1\\t%0\";\n+    else\n+      {\n+\t/* !!! This sequence clobbers EXEC_SAVE_REG and CC_SAVE_REG but\n+\t       restores SCC.  */\n+\tif (REGNO (operands[2]) == SCC_REG)\n+\t  {\n+\t    if (GET_CODE (operands[1]) == EQ)\n+\t      return \"s_cbranch%c1\\t.Lskip%=\\;\"\n+\t\t     \"s_getpc_b64\\ts[20:21]\\;\"\n+\t\t     \"s_add_u32\\ts20, s20, %0@rel32@lo+4\\;\"\n+\t\t     \"s_addc_u32\\ts21, s21, %0@rel32@hi+4\\;\"\n+\t\t     \"s_cmp_lg_u32\\t0, 0\\;\"\n+\t\t     \"s_setpc_b64\\ts[20:21]\\n\"\n+\t\t     \".Lskip%=:\";\n+\t    else\n+\t      return \"s_cbranch%c1\\t.Lskip%=\\;\"\n+\t\t     \"s_getpc_b64\\ts[20:21]\\;\"\n+\t\t     \"s_add_u32\\ts20, s20, %0@rel32@lo+4\\;\"\n+\t\t     \"s_addc_u32\\ts21, s21, %0@rel32@hi+4\\;\"\n+\t\t     \"s_cmp_eq_u32\\t0, 0\\;\"\n+\t\t     \"s_setpc_b64\\ts[20:21]\\n\"\n+\t\t     \".Lskip%=:\";\n+\t  }\n+\telse\n+\t  return \"s_cbranch%c1\\t.Lskip%=\\;\"\n+\t\t \"; s_mov_b32\\ts22, scc is not supported by the assembler.\\;\"\n+\t\t \".byte\\t0xfd\\;\"\n+\t\t \".byte\\t0x0\\;\"\n+\t\t \".byte\\t0x80|22\\;\"\n+\t\t \".byte\\t0xbe\\;\"\n+\t\t \"s_getpc_b64\\ts[20:21]\\;\"\n+\t\t \"s_add_u32\\ts20, s20, %0@rel32@lo+4\\;\"\n+\t\t \"s_addc_u32\\ts21, s21, %0@rel32@hi+4\\;\"\n+\t\t \"s_cmpk_lg_u32\\ts22, 0\\;\"\n+\t\t \"s_setpc_b64\\ts[20:21]\\n\"\n+\t\t \".Lskip%=:\";\n+      }\n+  }\n+  [(set_attr \"type\" \"sopp\")\n+   (set (attr \"length\")\n+\t(if_then_else (and (ge (minus (match_dup 0) (pc))\n+\t\t\t       (const_int -131072))\n+\t\t\t   (lt (minus (match_dup 0) (pc))\n+\t\t\t       (const_int 131072)))\n+\t\t      (const_int 4)\n+\t\t      (const_int 36)))])\n+\n+; Returning from a normal function is different to returning from a\n+; kernel function.\n+\n+(define_insn \"gcn_return\"\n+  [(return)]\n+  \"\"\n+  {\n+    if (cfun && cfun->machine && cfun->machine->normal_function)\n+      return \"s_setpc_b64\\ts[18:19]\";\n+    else\n+      return \"s_dcache_wb\\;s_endpgm\";\n+  }\n+  [(set_attr \"type\" \"sop1\")\n+   (set_attr \"length\" \"8\")])\n+\n+(define_expand \"call\"\n+  [(parallel [(call (match_operand 0 \"\")\n+\t\t    (match_operand 1 \"\"))\n+\t      (clobber (reg:DI LR_REGNUM))\n+\t      (clobber (match_scratch:DI 2))])]\n+  \"\"\n+  {})\n+\n+(define_insn \"gcn_simple_call\"\n+  [(call (mem (match_operand 0 \"immediate_operand\" \"Y,B\"))\n+\t (match_operand 1 \"const_int_operand\"))\n+   (clobber (reg:DI LR_REGNUM))\n+   (clobber (match_scratch:DI 2 \"=&Sg,X\"))]\n+  \"\"\n+  \"@\n+  s_getpc_b64\\t%2\\;s_add_u32\\t%L2, %L2, %0@rel32@lo+4\\;s_addc_u32\\t%H2, %H2, %0@rel32@hi+4\\;s_swappc_b64\\ts[18:19], %2\n+  s_swappc_b64\\ts[18:19], %0\"\n+  [(set_attr \"type\" \"mult,sop1\")\n+   (set_attr \"length\" \"24,4\")])\n+\n+(define_insn \"movdi_symbol\"\n+ [(set (match_operand:DI 0 \"nonimmediate_operand\" \"=Sg\")\n+       (match_operand:DI 1 \"general_operand\" \"Y\"))\n+  (clobber (reg:BI SCC_REG))]\n+ \"GET_CODE (operands[1]) == SYMBOL_REF || GET_CODE (operands[1]) == LABEL_REF\"\n+  {\n+    if (SYMBOL_REF_P (operands[1])\n+\t&& SYMBOL_REF_WEAK (operands[1]))\n+\treturn \"s_getpc_b64\\t%0\\;\"\n+\t       \"s_add_u32\\t%L0, %L0, %1@gotpcrel32@lo+4\\;\"\n+\t       \"s_addc_u32\\t%H0, %H0, %1@gotpcrel32@hi+4\\;\"\n+\t       \"s_load_dwordx2\\t%0, %0\\;\"\n+\t       \"s_waitcnt\\tlgkmcnt(0)\";\n+\n+    return \"s_getpc_b64\\t%0\\;\"\n+\t   \"s_add_u32\\t%L0, %L0, %1@rel32@lo+4\\;\"\n+\t   \"s_addc_u32\\t%H0, %H0, %1@rel32@hi+4\";\n+  }\n+ [(set_attr \"type\" \"mult\")\n+  (set_attr \"length\" \"32\")])\n+\n+(define_insn \"gcn_indirect_call\"\n+  [(call (mem (match_operand:DI 0 \"register_operand\" \"Sg\"))\n+\t (match_operand 1 \"\" \"\"))\n+   (clobber (reg:DI LR_REGNUM))\n+   (clobber (match_scratch:DI 2 \"=X\"))]\n+  \"\"\n+  \"s_swappc_b64\\ts[18:19], %0\"\n+  [(set_attr \"type\" \"sop1\")\n+   (set_attr \"length\" \"4\")])\n+\n+(define_expand \"call_value\"\n+  [(parallel [(set (match_operand 0 \"\")\n+\t\t   (call (match_operand 1 \"\")\n+\t\t\t (match_operand 2 \"\")))\n+\t      (clobber (reg:DI LR_REGNUM))\n+\t      (clobber (match_scratch:DI 3))])]\n+  \"\"\n+  {})\n+\n+(define_insn \"gcn_call_value\"\n+  [(set (match_operand 0 \"register_operand\" \"=Sg,Sg\")\n+\t(call (mem (match_operand 1 \"immediate_operand\" \"Y,B\"))\n+\t      (match_operand 2 \"const_int_operand\")))\n+   (clobber (reg:DI LR_REGNUM))\n+   (clobber (match_scratch:DI 3 \"=&Sg,X\"))]\n+  \"\"\n+  \"@\n+  s_getpc_b64\\t%3\\;s_add_u32\\t%L3, %L3, %1@rel32@lo+4\\;s_addc_u32\\t%H3, %H3, %1@rel32@hi+4\\;s_swappc_b64\\ts[18:19], %3\n+  s_swappc_b64\\ts[18:19], %1\"\n+  [(set_attr \"type\" \"sop1\")\n+   (set_attr \"length\" \"24\")])\n+\n+(define_insn \"gcn_call_value_indirect\"\n+  [(set (match_operand 0 \"register_operand\" \"=Sg\")\n+\t(call (mem (match_operand:DI 1 \"register_operand\" \"Sg\"))\n+\t      (match_operand 2 \"\" \"\")))\n+   (clobber (reg:DI LR_REGNUM))\n+   (clobber (match_scratch:DI 3 \"=X\"))]\n+  \"\"\n+  \"s_swappc_b64\\ts[18:19], %1\"\n+  [(set_attr \"type\" \"sop1\")\n+   (set_attr \"length\" \"4\")])\n+\n+; GCN does not have an instruction to clear only part of the instruction\n+; cache, so the operands are ignored.\n+\n+(define_insn \"clear_icache\"\n+  [(unspec_volatile\n+    [(match_operand 0 \"\") (match_operand 1 \"\")]\n+    UNSPECV_ICACHE_INV)]\n+  \"\"\n+  \"s_icache_inv\"\n+  [(set_attr \"type\" \"sopp\")\n+   (set_attr \"length\" \"4\")])\n+\n+;; }}}\n+;; {{{ Conditionals\n+\n+; 32-bit compare, scalar unit only\n+\n+(define_insn \"cstoresi4\"\n+  [(set (match_operand:BI 0 \"gcn_conditional_register_operand\"\n+\t\t\t\t\t\t\t \"=cs, cs, cs, cs\")\n+\t(match_operator:BI 1 \"gcn_compare_operator\"\n+\t  [(match_operand:SI 2 \"gcn_alu_operand\"\t \"SSA,SSA,SSB, SS\")\n+\t   (match_operand:SI 3 \"gcn_alu_operand\"\t \"SSA,SSL, SS,SSB\")]))]\n+  \"\"\n+  \"@\n+   s_cmp%D1\\t%2, %3\n+   s_cmpk%D1\\t%2, %3\n+   s_cmp%D1\\t%2, %3\n+   s_cmp%D1\\t%2, %3\"\n+  [(set_attr \"type\" \"sopc,sopk,sopk,sopk\")\n+   (set_attr \"length\" \"4,4,8,8\")])\n+\n+(define_expand \"cbranchsi4\"\n+  [(match_operator 0 \"gcn_compare_operator\"\n+     [(match_operand:SI 1 \"gcn_alu_operand\")\n+      (match_operand:SI 2 \"gcn_alu_operand\")])\n+   (match_operand 3)]\n+  \"\"\n+  {\n+    rtx cc = gen_reg_rtx (BImode);\n+    emit_insn (gen_cstoresi4 (cc, operands[0], operands[1], operands[2]));\n+    emit_jump_insn (gen_cjump (operands[3],\n+\t\t\t       gen_rtx_NE (BImode, cc, const0_rtx), cc));\n+    DONE;\n+  })\n+\n+; 64-bit compare; either unit, but scalar allows limited operators\n+\n+(define_expand \"cstoredi4\"\n+  [(set (match_operand:BI 0 \"gcn_conditional_register_operand\")\n+\t(match_operator:BI 1 \"gcn_compare_operator\"\n+\t\t\t   [(match_operand:DI 2 \"gcn_alu_operand\")\n+\t\t\t    (match_operand:DI 3 \"gcn_alu_operand\")]))]\n+  \"\"\n+  {})\n+\n+(define_insn \"cstoredi4_vec_and_scalar\"\n+  [(set (match_operand:BI 0 \"gcn_conditional_register_operand\" \"= cs,  cV\")\n+\t(match_operator:BI 1 \"gcn_compare_64bit_operator\"\n+\t  [(match_operand:DI 2 \"gcn_alu_operand\"\t       \"%SSA,vSvC\")\n+\t   (match_operand:DI 3 \"gcn_alu_operand\"\t       \" SSC,   v\")]))]\n+  \"\"\n+  \"@\n+   s_cmp%D1\\t%2, %3\n+   v_cmp%E1\\tvcc, %2, %3\"\n+  [(set_attr \"type\" \"sopc,vopc\")\n+   (set_attr \"length\" \"8\")])\n+\n+(define_insn \"cstoredi4_vector\"\n+  [(set (match_operand:BI 0 \"gcn_conditional_register_operand\" \"= cV\")\n+\t(match_operator:BI 1 \"gcn_compare_operator\"\n+          [(match_operand:DI 2 \"gcn_alu_operand\"\t       \"vSvB\")\n+\t   (match_operand:DI 3 \"gcn_alu_operand\"\t       \"   v\")]))]\n+  \"\"\n+  \"v_cmp%E1\\tvcc, %2, %3\"\n+  [(set_attr \"type\" \"vopc\")\n+   (set_attr \"length\" \"8\")])\n+\n+(define_expand \"cbranchdi4\"\n+  [(match_operator 0 \"gcn_compare_operator\"\n+     [(match_operand:DI 1 \"gcn_alu_operand\")\n+      (match_operand:DI 2 \"gcn_alu_operand\")])\n+   (match_operand 3)]\n+  \"\"\n+  {\n+    rtx cc = gen_reg_rtx (BImode);\n+    emit_insn (gen_cstoredi4 (cc, operands[0], operands[1], operands[2]));\n+    emit_jump_insn (gen_cjump (operands[3],\n+\t\t\t       gen_rtx_NE (BImode, cc, const0_rtx), cc));\n+    DONE;\n+  })\n+\n+; FP compare; vector unit only\n+\n+(define_insn \"cstore<mode>4\"\n+  [(set (match_operand:BI 0 \"gcn_conditional_register_operand\" \"=cV\")\n+\t(match_operator:BI 1 \"gcn_fp_compare_operator\"\n+\t  [(match_operand:SFDF 2 \"gcn_alu_operand\"\t\t\"vB\")\n+\t   (match_operand:SFDF 3 \"gcn_alu_operand\"\t\t \"v\")]))]\n+  \"\"\n+  \"v_cmp%E1\\tvcc, %2, %3\"\n+  [(set_attr \"type\" \"vopc\")\n+   (set_attr \"length\" \"8\")])\n+\n+(define_expand \"cbranch<mode>4\"\n+  [(match_operator 0 \"gcn_fp_compare_operator\"\n+     [(match_operand:SFDF 1 \"gcn_alu_operand\")\n+      (match_operand:SFDF 2 \"gcn_alu_operand\")])\n+   (match_operand 3)]\n+  \"\"\n+  {\n+    rtx cc = gen_reg_rtx (BImode);\n+    emit_insn (gen_cstore<mode>4 (cc, operands[0], operands[1], operands[2]));\n+    emit_jump_insn (gen_cjump (operands[3],\n+\t\t\t       gen_rtx_NE (BImode, cc, const0_rtx), cc));\n+    DONE;\n+  })\n+\n+;; }}}\n+;; {{{ ALU special cases: Plus\n+\n+(define_insn \"addsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\"         \"= Sg, Sg, Sg,   v\")\n+        (plus:SI (match_operand:SI 1 \"gcn_alu_operand\" \"%SgA,  0,SgA,   v\")\n+\t\t (match_operand:SI 2 \"gcn_alu_operand\" \" SgA,SgJ,  B,vBSv\")))\n+   (clobber (match_scratch:BI 3\t\t\t       \"= cs, cs, cs,   X\"))\n+   (clobber (match_scratch:DI 4\t\t\t       \"=  X,  X,  X,  cV\"))]\n+  \"\"\n+  \"@\n+   s_add_i32\\t%0, %1, %2\n+   s_addk_i32\\t%0, %2\n+   s_add_i32\\t%0, %1, %2\n+   v_add%^_u32\\t%0, vcc, %2, %1\"\n+  [(set_attr \"type\" \"sop2,sopk,sop2,vop2\")\n+   (set_attr \"length\" \"4,4,8,8\")])\n+\n+(define_expand \"addsi3_scc\"\n+  [(parallel [(set (match_operand:SI 0 \"register_operand\")\n+\t\t   (plus:SI (match_operand:SI 1 \"gcn_alu_operand\")\n+\t\t\t    (match_operand:SI 2 \"gcn_alu_operand\")))\n+\t      (clobber (reg:BI SCC_REG))\n+\t      (clobber (scratch:DI))])]\n+  \"\"\n+  {})\n+\n+; Having this as an insn_and_split allows us to keep together DImode adds\n+; through some RTL optimisation passes, and means the CC reg we set isn't\n+; dependent on the constraint alternative (which doesn't seem to work well).\n+\n+; There's an early clobber in the case where \"v[0:1]=v[1:2]+?\" but\n+; \"v[0:1]=v[0:1]+?\" is fine (as is \"v[1:2]=v[0:1]+?\", but that's trickier).\n+\n+; If v_addc_u32 is used to add with carry, a 32-bit literal constant cannot be\n+; used as an operand due to the read of VCC, so we restrict constants to the\n+; inlinable range for that alternative.\n+\n+(define_insn_and_split \"adddi3\"\n+  [(set (match_operand:DI 0 \"register_operand\"\t\t\n+\t\t\t\t\t      \"=&Sg,&Sg,&Sg,&Sg,&v,&v,&v,&v\")\n+\t(plus:DI (match_operand:DI 1 \"register_operand\" \n+\t\t\t\t\t      \"  Sg,  0,  0, Sg, v, 0, 0, v\")\n+\t\t (match_operand:DI 2 \"nonmemory_operand\"\n+\t\t\t\t\t      \"   0,SgB,  0,SgB, 0,vA, 0,vA\")))\n+   (clobber (match_scratch:BI 3\t\t      \"= cs, cs, cs, cs, X, X, X, X\"))\n+   (clobber (match_scratch:DI 4\t\t      \"=  X,  X,  X,  X,cV,cV,cV,cV\"))]\n+  \"\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(const_int 0)]\n+  {\n+    rtx cc = gen_rtx_REG (BImode, gcn_vgpr_register_operand (operands[1],\n+\t\t\t\t\t\t\t     DImode)\n+\t\t\t  ? VCC_REG : SCC_REG);\n+\n+    emit_insn (gen_addsi3_scalar_carry\n+\t       (gcn_operand_part (DImode, operands[0], 0),\n+\t\tgcn_operand_part (DImode, operands[1], 0),\n+\t\tgcn_operand_part (DImode, operands[2], 0),\n+\t\tcc));\n+    rtx val = gcn_operand_part (DImode, operands[2], 1);\n+    if (val != const0_rtx)\n+      emit_insn (gen_addcsi3_scalar\n+\t\t (gcn_operand_part (DImode, operands[0], 1),\n+\t\t  gcn_operand_part (DImode, operands[1], 1),\n+\t\t  gcn_operand_part (DImode, operands[2], 1),\n+\t\t  cc, cc));\n+    else\n+      emit_insn (gen_addcsi3_scalar_zero\n+\t\t (gcn_operand_part (DImode, operands[0], 1),\n+\t\t  gcn_operand_part (DImode, operands[1], 1),\n+\t\t  cc));\n+    DONE;\n+  }\n+  [(set_attr \"type\" \"mult,mult,mult,mult,vmult,vmult,vmult,vmult\")\n+   (set_attr \"length\" \"8\")])\n+\n+(define_expand \"adddi3_scc\"\n+  [(parallel [(set (match_operand:DI 0 \"register_operand\")\n+\t\t   (plus:DI (match_operand:DI 1 \"register_operand\")\n+\t\t\t    (match_operand:DI 2 \"nonmemory_operand\")))\n+\t      (clobber (reg:BI SCC_REG))\n+\t      (clobber (scratch:DI))])]\n+  \"\"\n+  {})\n+\n+;; Add with carry.\n+\n+(define_insn \"addsi3_scalar_carry\"\n+  [(set (match_operand:SI 0 \"register_operand\"\t       \"= Sg, v\")\n+\t(plus:SI (match_operand:SI 1 \"gcn_alu_operand\" \"%SgA, v\")\n+\t\t (match_operand:SI 2 \"gcn_alu_operand\" \" SgB,vB\")))\n+   (set (match_operand:BI 3 \"register_operand\"\t       \"= cs,cV\")\n+\t(ltu:BI (plus:SI (match_dup 1)\n+\t\t\t (match_dup 2))\n+\t\t(match_dup 1)))]\n+  \"\"\n+  \"@\n+   s_add_u32\\t%0, %1, %2\n+   v_add%^_u32\\t%0, vcc, %2, %1\"\n+  [(set_attr \"type\" \"sop2,vop2\")\n+   (set_attr \"length\" \"8,8\")])\n+\n+(define_insn \"addsi3_scalar_carry_cst\"\n+  [(set (match_operand:SI 0 \"register_operand\"           \"=Sg, v\")\n+        (plus:SI (match_operand:SI 1 \"gcn_alu_operand\"   \"SgA, v\")\n+\t\t (match_operand:SI 2 \"const_int_operand\" \"  n, n\")))\n+   (set (match_operand:BI 4 \"register_operand\"           \"=cs,cV\")\n+\t(geu:BI (plus:SI (match_dup 1)\n+\t\t\t (match_dup 2))\n+\t\t(match_operand:SI 3 \"const_int_operand\"  \"  n, n\")))]\n+  \"INTVAL (operands[2]) == -INTVAL (operands[3])\"\n+  \"@\n+   s_add_u32\\t%0, %1, %2\n+   v_add%^_u32\\t%0, vcc, %2, %1\"\n+  [(set_attr \"type\" \"sop2,vop2\")\n+   (set_attr \"length\" \"4\")])\n+\n+(define_insn \"addcsi3_scalar\"\n+  [(set (match_operand:SI 0 \"register_operand\"\t\t\t   \"= Sg, v\")\n+\t(plus:SI (plus:SI (zero_extend:SI\n+\t\t\t    (match_operand:BI 3 \"register_operand\" \"= cs,cV\"))\n+\t\t\t  (match_operand:SI 1 \"gcn_alu_operand\"    \"%SgA, v\"))\n+\t\t (match_operand:SI 2 \"gcn_alu_operand\"\t\t   \" SgB,vA\")))\n+   (set (match_operand:BI 4 \"register_operand\"\t\t\t   \"=  3, 3\")\n+\t(ior:BI (ltu:BI (plus:SI\n+\t\t\t  (plus:SI\n+\t\t\t    (zero_extend:SI (match_dup 3))\n+\t\t\t    (match_dup 1))\n+\t\t\t  (match_dup 2))\n+\t\t\t(match_dup 2))\n+\t\t(ltu:BI (plus:SI (zero_extend:SI (match_dup 3)) (match_dup 1))\n+\t\t\t(match_dup 1))))]\n+  \"\"\n+  \"@\n+   s_addc_u32\\t%0, %1, %2\n+   v_addc%^_u32\\t%0, vcc, %2, %1, vcc\"\n+  [(set_attr \"type\" \"sop2,vop2\")\n+   (set_attr \"length\" \"8,4\")])\n+\n+(define_insn \"addcsi3_scalar_zero\"\n+  [(set (match_operand:SI 0 \"register_operand\"\t\t  \"=Sg, v\")\n+        (plus:SI (zero_extend:SI\n+\t\t   (match_operand:BI 2 \"register_operand\" \"=cs,cV\"))\n+\t\t (match_operand:SI 1 \"gcn_alu_operand\"    \"SgA, v\")))\n+   (set (match_dup 2)\n+\t(ltu:BI (plus:SI (zero_extend:SI (match_dup 2))\n+\t\t\t (match_dup 1))\n+\t\t(match_dup 1)))]\n+  \"\"\n+  \"@\n+   s_addc_u32\\t%0, %1, 0\n+   v_addc%^_u32\\t%0, vcc, 0, %1, vcc\"\n+  [(set_attr \"type\" \"sop2,vop2\")\n+   (set_attr \"length\" \"4\")])\n+\n+; \"addptr\" is the same as \"add\" except that it must not write to VCC or SCC\n+; as a side-effect.  Unfortunately GCN does not have a suitable instruction\n+; for this, so we use a custom VOP3 add with CC_SAVE_REG as a temp.\n+; Note that it is not safe to save/clobber/restore SCC because doing so will\n+; break data-flow analysis, so this must use vector registers.\n+\n+(define_insn \"addptrdi3\"\n+  [(set (match_operand:DI 0 \"register_operand\"\t\t \"= &v\")\n+\t(plus:DI (match_operand:DI 1 \"register_operand\"\t \"  v0\")\n+\t\t (match_operand:DI 2 \"nonmemory_operand\" \"vDA0\")))]\n+  \"\"\n+  {\n+    rtx new_operands[4] = { operands[0], operands[1], operands[2],\n+\t\t\t    gen_rtx_REG (DImode, CC_SAVE_REG) };\n+\n+    output_asm_insn (\"v_add%^_u32 %L0, %3, %L2, %L1\", new_operands);\n+    output_asm_insn (\"v_addc%^_u32 %H0, %3, %H2, %H1, %3\", new_operands);\n+\n+    return \"\";\n+  }\n+  [(set_attr \"type\" \"vmult\")\n+   (set_attr \"length\" \"16\")])\n+\n+;; }}}\n+;; {{{ ALU special cases: Minus\n+\n+(define_insn \"subsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\"          \"=Sg, Sg,    v,   v\")\n+\t(minus:SI (match_operand:SI 1 \"gcn_alu_operand\" \"SgA,SgA,    v,vBSv\")\n+\t\t  (match_operand:SI 2 \"gcn_alu_operand\" \"SgA,  B, vBSv,   v\")))\n+   (clobber (match_scratch:BI 3\t\t\t\t\"=cs, cs,    X,   X\"))\n+   (clobber (match_scratch:DI 4\t\t\t\t\"= X,  X,   cV,  cV\"))]\n+  \"\"\n+  \"@\n+   s_sub_i32\\t%0, %1, %2\n+   s_sub_i32\\t%0, %1, %2\n+   v_subrev%^_u32\\t%0, vcc, %2, %1\n+   v_sub%^_u32\\t%0, vcc, %1, %2\"\n+  [(set_attr \"type\" \"sop2,sop2,vop2,vop2\")\n+   (set_attr \"length\" \"4,8,8,8\")])\n+\n+(define_insn_and_split \"subdi3\"\n+  [(set (match_operand:DI 0 \"register_operand\"        \"=Sg, Sg\")\n+\t(minus:DI\n+\t\t(match_operand:DI 1 \"gcn_alu_operand\" \"SgA,SgB\")\n+\t\t(match_operand:DI 2 \"gcn_alu_operand\" \"SgB,SgA\")))\n+   (clobber (reg:BI SCC_REG))]\n+  \"\"\n+  \"#\"\n+  \"reload_completed\"\n+  [(const_int 0)]\n+  {\n+    emit_insn (gen_subsi3_scalar_carry\n+\t       (gcn_operand_part (DImode, operands[0], 0),\n+\t\tgcn_operand_part (DImode, operands[1], 0),\n+\t\tgcn_operand_part (DImode, operands[2], 0)));\n+    rtx val = gcn_operand_part (DImode, operands[2], 1);\n+    if (val != const0_rtx)\n+      emit_insn (gen_subcsi3_scalar\n+\t\t (gcn_operand_part (DImode, operands[0], 1),\n+\t\t  gcn_operand_part (DImode, operands[1], 1),\n+\t\t  gcn_operand_part (DImode, operands[2], 1)));\n+    else\n+      emit_insn (gen_subcsi3_scalar_zero\n+\t\t (gcn_operand_part (DImode, operands[0], 1),\n+\t\t  gcn_operand_part (DImode, operands[1], 1)));\n+    DONE;\n+  }\n+  [(set_attr \"length\" \"8\")])\n+\n+(define_insn \"subsi3_scalar_carry\"\n+  [(set (match_operand:SI 0 \"register_operand\"          \"=Sg, Sg\")\n+        (minus:SI (match_operand:SI 1 \"gcn_alu_operand\" \"SgA,SgB\")\n+\t\t  (match_operand:SI 2 \"gcn_alu_operand\" \"SgB,SgA\")))\n+   (set (reg:BI SCC_REG)\n+\t(gtu:BI (minus:SI (match_dup 1)\n+\t\t\t  (match_dup 2))\n+\t\t(match_dup 1)))]\n+  \"\"\n+  \"s_sub_u32\\t%0, %1, %2\"\n+  [(set_attr \"type\" \"sop2\")\n+   (set_attr \"length\" \"8\")])\n+\n+(define_insn \"subsi3_scalar_carry_cst\"\n+  [(set (match_operand:SI 0 \"register_operand\"           \"=Sg\")\n+        (minus:SI (match_operand:SI 1 \"gcn_alu_operand\"  \"SgA\")\n+\t\t (match_operand:SI 2 \"const_int_operand\" \"  n\")))\n+   (set (reg:BI SCC_REG)\n+\t(leu:BI (minus:SI (match_dup 1)\n+\t\t\t (match_dup 2))\n+\t\t(match_operand:SI 3 \"const_int_operand\"  \"  n\")))]\n+  \"INTVAL (operands[2]) == -INTVAL (operands[3])\"\n+  \"s_sub_u32\\t%0, %1, %2\"\n+  [(set_attr \"type\" \"sop2\")\n+   (set_attr \"length\" \"4\")])\n+\n+(define_insn \"subcsi3_scalar\"\n+  [(set (match_operand:SI 0 \"register_operand\"                    \"=Sg, Sg\")\n+        (minus:SI (minus:SI (zero_extend:SI (reg:BI SCC_REG))\n+\t\t\t    (match_operand:SI 1 \"gcn_alu_operand\" \"SgA,SgB\"))\n+\t\t (match_operand:SI 2 \"gcn_alu_operand\"            \"SgB,SgA\")))\n+   (set (reg:BI SCC_REG)\n+\t(ior:BI (gtu:BI (minus:SI (minus:SI (zero_extend:SI (reg:BI SCC_REG))\n+\t\t\t\t\t    (match_dup 1))\n+\t\t\t\t (match_dup 2))\n+\t\t\t(match_dup 1))\n+\t\t(gtu:BI (minus:SI (zero_extend:SI (reg:BI SCC_REG))\n+\t\t\t\t  (match_dup 1))\n+\t\t\t(match_dup 1))))]\n+  \"\"\n+  \"s_subb_u32\\t%0, %1, %2\"\n+  [(set_attr \"type\" \"sop2\")\n+   (set_attr \"length\" \"8\")])\n+\n+(define_insn \"subcsi3_scalar_zero\"\n+  [(set (match_operand:SI 0 \"register_operand\"\t\t\"=Sg\")\n+        (minus:SI (zero_extend:SI (reg:BI SCC_REG))\n+\t\t  (match_operand:SI 1 \"gcn_alu_operand\" \"SgA\")))\n+   (set (reg:BI SCC_REG)\n+\t(gtu:BI (minus:SI (zero_extend:SI (reg:BI SCC_REG)) (match_dup 1))\n+\t\t(match_dup 1)))]\n+  \"\"\n+  \"s_subb_u32\\t%0, %1, 0\"\n+  [(set_attr \"type\" \"sop2\")\n+   (set_attr \"length\" \"4\")])\n+\n+;; }}}\n+;; {{{ ALU: mult\n+\n+; Vector multiply has vop3a encoding, but no corresponding vop2a, so no long\n+; immediate.\n+(define_insn \"mulsi3\"\n+  [(set (match_operand:SI 0 \"register_operand\"\t       \"= Sg,Sg, Sg,   v\")\n+        (mult:SI (match_operand:SI 1 \"gcn_alu_operand\" \"%SgA, 0,SgA,   v\")\n+\t\t (match_operand:SI 2 \"gcn_alu_operand\" \" SgA, J,  B,vASv\")))]\n+  \"\"\n+  \"@\n+   s_mul_i32\\t%0, %1, %2\n+   s_mulk_i32\\t%0, %2\n+   s_mul_i32\\t%0, %1, %2\n+   v_mul_lo_i32\\t%0, %1, %2\"\n+  [(set_attr \"type\" \"sop2,sopk,sop2,vop3a\")\n+   (set_attr \"length\" \"4,4,8,4\")])\n+\n+(define_code_iterator any_extend [sign_extend zero_extend])\n+(define_code_attr sgnsuffix [(sign_extend \"%i\") (zero_extend \"%u\")])\n+(define_code_attr su [(sign_extend \"s\") (zero_extend \"u\")])\n+(define_code_attr u [(sign_extend \"\") (zero_extend \"u\")])\n+(define_code_attr iu [(sign_extend \"i\") (zero_extend \"u\")])\n+(define_code_attr e [(sign_extend \"e\") (zero_extend \"\")])\n+\n+(define_insn \"<su>mulsi3_highpart\"\n+  [(set (match_operand:SI 0 \"register_operand\"\t       \"= v\")\n+\t(truncate:SI\n+\t  (lshiftrt:DI\n+\t    (mult:DI\n+\t      (any_extend:DI\n+\t\t(match_operand:SI 1 \"register_operand\" \"% v\"))\n+\t      (any_extend:DI\n+\t\t(match_operand:SI 2 \"register_operand\" \"vSv\")))\n+\t    (const_int 32))))]\n+  \"\"\n+  \"v_mul_hi<sgnsuffix>0\\t%0, %2, %1\"\n+  [(set_attr \"type\" \"vop3a\")\n+   (set_attr \"length\" \"8\")])\n+\n+(define_insn \"<u>mulhisi3\"\n+  [(set (match_operand:SI 0 \"register_operand\"\t\t\t\"=v\")\n+\t(mult:SI\n+\t  (any_extend:SI (match_operand:HI 1 \"register_operand\" \"%v\"))\n+\t  (any_extend:SI (match_operand:HI 2 \"register_operand\" \" v\"))))]\n+  \"\"\n+  \"v_mul_<iu>32_<iu>24_sdwa\\t%0, %<e>1, %<e>2 src0_sel:WORD_0 src1_sel:WORD_0\"\n+  [(set_attr \"type\" \"vop_sdwa\")\n+   (set_attr \"length\" \"8\")])\n+\n+(define_insn \"<u>mulqihi3_scalar\"\n+  [(set (match_operand:HI 0 \"register_operand\"\t\t\t\"=v\")\n+\t(mult:HI\n+\t  (any_extend:HI (match_operand:QI 1 \"register_operand\" \"%v\"))\n+\t  (any_extend:HI (match_operand:QI 2 \"register_operand\" \" v\"))))]\n+  \"\"\n+  \"v_mul_<iu>32_<iu>24_sdwa\\t%0, %<e>1, %<e>2 src0_sel:BYTE_0 src1_sel:BYTE_0\"\n+  [(set_attr \"type\" \"vop_sdwa\")\n+   (set_attr \"length\" \"8\")])\n+\n+;; }}}\n+;; {{{ ALU: generic 32-bit unop\n+\n+(define_code_iterator bitunop [not popcount])\n+(define_code_attr popcount_extra_op [(not \"\") (popcount \", 0\")])\n+\n+(define_insn \"<expander>si2\"\n+  [(set (match_operand:SI 0 \"register_operand\"  \"=Sg,   v\")\n+        (bitunop:SI\n+\t  (match_operand:SI 1 \"gcn_alu_operand\" \"SgB,vSvB\")))\n+   (clobber (match_scratch:BI 2\t\t\t\"=cs,   X\"))]\n+  \"\"\n+  \"@\n+   s_<s_mnemonic>0\\t%0, %1\n+   v_<mnemonic>0\\t%0, %1<popcount_extra_op>\"\n+  [(set_attr \"type\" \"sop1,vop1\")\n+   (set_attr \"length\" \"8\")])\n+\n+;; }}}\n+;; {{{ ALU: generic 32-bit binop\n+\n+; No plus and mult - they have variant with 16bit immediate\n+; and thus are defined later.\n+(define_code_iterator binop [and ior xor smin smax umin umax\n+\t\t\t\t ashift lshiftrt ashiftrt])\n+(define_code_iterator vec_and_scalar_com [and ior xor smin smax umin umax])\n+(define_code_iterator vec_and_scalar_nocom [ashift lshiftrt ashiftrt])\n+\n+(define_insn \"<expander>si3\"\n+  [(set (match_operand:SI 0 \"gcn_valu_dst_operand\"    \"= Sg,   v,RD\")\n+        (vec_and_scalar_com:SI\n+\t  (match_operand:SI 1 \"gcn_valu_src0_operand\" \"%SgA,vSvB, 0\")\n+\t  (match_operand:SI 2 \"gcn_alu_operand\"\t      \" SgB,   v, v\")))\n+   (clobber (match_scratch:BI 3\t\t\t      \"= cs,   X, X\"))]\n+  \"\"\n+  \"@\n+   s_<mnemonic>0\\t%0, %1, %2\n+   v_<mnemonic>0\\t%0, %1, %2\n+   ds_<mnemonic>0\\t%A0, %2%O0\"\n+  [(set_attr \"type\" \"sop2,vop2,ds\")\n+   (set_attr \"length\" \"8\")])\n+\n+(define_insn \"<expander>si3\"\n+  [(set (match_operand:SI 0 \"register_operand\"  \"=Sg, Sg,   v\")\n+        (vec_and_scalar_nocom:SI\n+\t  (match_operand:SI 1 \"gcn_alu_operand\" \"SgB,SgA,   v\")\n+\t  (match_operand:SI 2 \"gcn_alu_operand\" \"SgA,SgB,vSvB\")))\n+   (clobber (match_scratch:BI 3\t\t\t\"=cs, cs,   X\"))]\n+  \"\"\n+  \"@\n+   s_<mnemonic>0\\t%0, %1, %2\n+   s_<mnemonic>0\\t%0, %1, %2\n+   v_<revmnemonic>0\\t%0, %2, %1\"\n+  [(set_attr \"type\" \"sop2,sop2,vop2\")\n+   (set_attr \"length\" \"8\")])\n+\n+(define_expand \"<expander>si3_scc\"\n+  [(parallel [(set (match_operand:SI 0 \"gcn_valu_dst_operand\")\n+\t\t   (binop:SI\n+\t\t     (match_operand:SI 1 \"gcn_valu_src0_operand\")\n+\t\t     (match_operand:SI 2 \"gcn_alu_operand\")))\n+\t      (clobber (reg:BI SCC_REG))])]\n+  \"\"\n+  {})\n+\n+;; }}}\n+;; {{{ ALU: generic 64-bit\n+\n+(define_code_iterator vec_and_scalar64_com [and ior xor])\n+\n+(define_insn_and_split \"<expander>di3\"\n+   [(set (match_operand:DI 0 \"register_operand\"  \"= Sg,   &v,   &v\")\n+\t (vec_and_scalar64_com:DI\n+\t  (match_operand:DI 1 \"gcn_alu_operand\"  \"%SgA,vSvDB,vSvDB\")\n+\t   (match_operand:DI 2 \"gcn_alu_operand\" \" SgC,    v,    0\")))\n+   (clobber (match_scratch:BI 3\t\t\t \"= cs,    X,    X\"))]\n+  \"\"\n+  \"@\n+   s_<mnemonic>0\\t%0, %1, %2\n+   #\n+   #\"\n+  \"reload_completed && gcn_vgpr_register_operand (operands[0], DImode)\"\n+  [(parallel [(set (match_dup 4)\n+\t\t   (vec_and_scalar64_com:SI (match_dup 5) (match_dup 6)))\n+\t      (clobber (match_dup 3))])\n+   (parallel [(set (match_dup 7)\n+\t\t   (vec_and_scalar64_com:SI (match_dup 8) (match_dup 9)))\n+\t      (clobber (match_dup 3))])]\n+  {\n+    operands[4] = gcn_operand_part (DImode, operands[0], 0);\n+    operands[5] = gcn_operand_part (DImode, operands[1], 0);\n+    operands[6] = gcn_operand_part (DImode, operands[2], 0);\n+    operands[7] = gcn_operand_part (DImode, operands[0], 1);\n+    operands[8] = gcn_operand_part (DImode, operands[1], 1);\n+    operands[9] = gcn_operand_part (DImode, operands[2], 1);\n+  }\n+  [(set_attr \"type\" \"sop2,vop2,vop2\")\n+   (set_attr \"length\" \"8\")])\n+\n+(define_insn \"<expander>di3\"\n+  [(set (match_operand:DI 0 \"register_operand\"   \"=Sg, Sg,   v\")\n+\t(vec_and_scalar_nocom:DI\n+\t  (match_operand:DI 1 \"gcn_alu_operand\"  \"SgC,SgA,   v\")\n+\t  (match_operand:SI 2 \"gcn_alu_operand\"  \"SgA,SgC,vSvC\")))\n+   (clobber (match_scratch:BI 3\t\t\t \"=cs, cs,   X\"))]\n+  \"\"\n+  \"@\n+   s_<mnemonic>0\\t%0, %1, %2\n+   s_<mnemonic>0\\t%0, %1, %2\n+   v_<revmnemonic>0\\t%0, %2, %1\"\n+  [(set_attr \"type\" \"sop2,sop2,vop2\")\n+   (set_attr \"length\" \"8\")])\n+\n+;; }}}\n+;; {{{ Atomics\n+\n+; Each compute unit has it's own L1 cache. The L2 cache is shared between\n+; all the compute units.  Any load or store instruction can skip L1 and\n+; access L2 directly using the \"glc\" flag.  Atomic instructions also skip\n+; L1.  The L1 cache can be flushed and invalidated using instructions.\n+;\n+; Therefore, in order for \"acquire\" and \"release\" atomic modes to work\n+; correctly across compute units we must flush before each \"release\"\n+; and invalidate the cache after each \"acquire\".  It might seem like\n+; invalidation could be safely done before an \"acquire\", but since each\n+; compute unit can run up to 40 threads simultaneously, all reading values\n+; into the L1 cache, this is not actually safe.\n+;\n+; Additionally, scalar flat instructions access L2 via a different cache\n+; (the \"constant cache\"), so they have separate constrol instructions.  We\n+; do not attempt to invalidate both caches at once; instead, atomics\n+; operating on scalar flat pointers will flush the constant cache, and\n+; atomics operating on flat or global pointers will flush L1.  It is up to\n+; the programmer to get this right.\n+\n+(define_code_iterator atomicops [plus minus and ior xor])\n+(define_mode_attr X [(SI \"\") (DI \"_X2\")])\n+\n+;; TODO compare_and_swap test_and_set inc dec\n+;; Hardware also supports min and max, but GCC does not.\n+\n+(define_expand \"memory_barrier\"\n+  [(set (match_dup 0)\n+\t(unspec:BLK [(match_dup 0)] UNSPEC_MEMORY_BARRIER))]\n+  \"\"\n+  {\n+    operands[0] = gen_rtx_MEM (BLKmode, gen_rtx_SCRATCH (Pmode));\n+    MEM_VOLATILE_P (operands[0]) = 1;\n+  })\n+\n+(define_insn \"*memory_barrier\"\n+  [(set (match_operand:BLK 0)\n+\t(unspec:BLK [(match_dup 0)] UNSPEC_MEMORY_BARRIER))]\n+  \"\"\n+  \"buffer_wbinvl1_vol\"\n+  [(set_attr \"type\" \"mubuf\")\n+   (set_attr \"length\" \"4\")])\n+\n+; FIXME: These patterns have been disabled as they do not seem to work\n+; reliably - they can cause hangs or incorrect results.\n+; TODO: flush caches according to memory model\n+(define_insn \"atomic_fetch_<bare_mnemonic><mode>\"\n+  [(set (match_operand:SIDI 0 \"register_operand\"     \"=Sm, v, v\")\n+\t(match_operand:SIDI 1 \"memory_operand\"\t     \"+RS,RF,RM\"))\n+   (set (match_dup 1)\n+\t(unspec_volatile:SIDI\n+\t  [(atomicops:SIDI\n+\t    (match_dup 1)\n+\t    (match_operand:SIDI 2 \"register_operand\" \" Sm, v, v\"))]\n+\t   UNSPECV_ATOMIC))\n+   (use (match_operand 3 \"const_int_operand\"))]\n+  \"0 /* Disabled.  */\"\n+  \"@\n+   s_atomic_<bare_mnemonic><X>\\t%0, %1, %2 glc\\;s_waitcnt\\tlgkmcnt(0)\n+   flat_atomic_<bare_mnemonic><X>\\t%0, %1, %2 glc\\;s_waitcnt\\t0\n+   global_atomic_<bare_mnemonic><X>\\t%0, %A1, %2%O1 glc\\;s_waitcnt\\tvmcnt(0)\"\n+  [(set_attr \"type\" \"smem,flat,flat\")\n+   (set_attr \"length\" \"12\")\n+   (set_attr \"gcn_version\" \"gcn5,*,gcn5\")])\n+\n+; FIXME: These patterns are disabled because the instructions don't\n+; seem to work as advertised.  Specifically, OMP \"team distribute\"\n+; reductions apparently \"lose\" some of the writes, similar to what\n+; you might expect from a concurrent non-atomic read-modify-write.\n+; TODO: flush caches according to memory model\n+(define_insn \"atomic_<bare_mnemonic><mode>\"\n+  [(set (match_operand:SIDI 0 \"memory_operand\"       \"+RS,RF,RM\")\n+\t(unspec_volatile:SIDI\n+\t  [(atomicops:SIDI\n+\t    (match_dup 0)\n+\t    (match_operand:SIDI 1 \"register_operand\" \" Sm, v, v\"))]\n+\t  UNSPECV_ATOMIC))\n+   (use (match_operand 2 \"const_int_operand\"))]\n+  \"0 /* Disabled.  */\"\n+  \"@\n+   s_atomic_<bare_mnemonic><X>\\t%0, %1\\;s_waitcnt\\tlgkmcnt(0)\n+   flat_atomic_<bare_mnemonic><X>\\t%0, %1\\;s_waitcnt\\t0\n+   global_atomic_<bare_mnemonic><X>\\t%A0, %1%O0\\;s_waitcnt\\tvmcnt(0)\"\n+  [(set_attr \"type\" \"smem,flat,flat\")\n+   (set_attr \"length\" \"12\")\n+   (set_attr \"gcn_version\" \"gcn5,*,gcn5\")])\n+\n+(define_mode_attr x2 [(SI \"DI\") (DI \"TI\")])\n+(define_mode_attr size [(SI \"4\") (DI \"8\")])\n+(define_mode_attr bitsize [(SI \"32\") (DI \"64\")])\n+\n+(define_expand \"sync_compare_and_swap<mode>\"\n+  [(match_operand:SIDI 0 \"register_operand\")\n+   (match_operand:SIDI 1 \"memory_operand\")\n+   (match_operand:SIDI 2 \"register_operand\")\n+   (match_operand:SIDI 3 \"register_operand\")]\n+  \"\"\n+  {\n+    if (MEM_ADDR_SPACE (operands[1]) == ADDR_SPACE_LDS)\n+      {\n+\temit_insn (gen_sync_compare_and_swap<mode>_lds_insn (operands[0],\n+\t\t\t\t\t\t\t     operands[1],\n+\t\t\t\t\t\t\t     operands[2],\n+\t\t\t\t\t\t\t     operands[3]));\n+\tDONE;\n+      }\n+\n+    /* Operands 2 and 3 must be placed in consecutive registers, and passed\n+       as a combined value.  */\n+    rtx src_cmp = gen_reg_rtx (<x2>mode);\n+    emit_move_insn (gen_rtx_SUBREG (<MODE>mode, src_cmp, 0), operands[3]);\n+    emit_move_insn (gen_rtx_SUBREG (<MODE>mode, src_cmp, <size>), operands[2]);\n+    emit_insn (gen_sync_compare_and_swap<mode>_insn (operands[0],\n+\t\t\t\t\t\t     operands[1],\n+\t\t\t\t\t\t     src_cmp));\n+    DONE;\n+  })\n+\n+(define_insn \"sync_compare_and_swap<mode>_insn\"\n+  [(set (match_operand:SIDI 0 \"register_operand\"    \"=Sm, v, v\")\n+\t(match_operand:SIDI 1 \"memory_operand\"      \"+RS,RF,RM\"))\n+   (set (match_dup 1)\n+\t(unspec_volatile:SIDI\n+\t  [(match_operand:<x2> 2 \"register_operand\" \" Sm, v, v\")]\n+\t  UNSPECV_ATOMIC))]\n+  \"\"\n+  \"@\n+   s_atomic_cmpswap<X>\\t%0, %1, %2 glc\\;s_waitcnt\\tlgkmcnt(0)\n+   flat_atomic_cmpswap<X>\\t%0, %1, %2 glc\\;s_waitcnt\\t0\n+   global_atomic_cmpswap<X>\\t%0, %A1, %2%O1 glc\\;s_waitcnt\\tvmcnt(0)\"\n+  [(set_attr \"type\" \"smem,flat,flat\")\n+   (set_attr \"length\" \"12\")\n+   (set_attr \"gcn_version\" \"gcn5,*,gcn5\")])\n+\n+(define_insn \"sync_compare_and_swap<mode>_lds_insn\"\n+  [(set (match_operand:SIDI 0 \"register_operand\"    \"= v\")\n+\t(unspec_volatile:SIDI\n+\t  [(match_operand:SIDI 1 \"memory_operand\"   \"+RL\")]\n+\t  UNSPECV_ATOMIC))\n+   (set (match_dup 1)\n+\t(unspec_volatile:SIDI\n+\t  [(match_operand:SIDI 2 \"register_operand\" \"  v\")\n+\t   (match_operand:SIDI 3 \"register_operand\" \"  v\")]\n+\t  UNSPECV_ATOMIC))]\n+  \"\"\n+  \"ds_cmpst_rtn_b<bitsize> %0, %1, %2, %3\\;s_waitcnt\\tlgkmcnt(0)\"\n+  [(set_attr \"type\" \"ds\")\n+   (set_attr \"length\" \"12\")])\n+\n+(define_insn \"atomic_load<mode>\"\n+  [(set (match_operand:SIDI 0 \"register_operand\"  \"=Sm, v, v\")\n+\t(unspec_volatile:SIDI\n+\t  [(match_operand:SIDI 1 \"memory_operand\" \" RS,RF,RM\")]\n+\t  UNSPECV_ATOMIC))\n+   (use (match_operand:SIDI 2 \"immediate_operand\" \"  i, i, i\"))]\n+  \"\"\n+  {\n+    switch (INTVAL (operands[2]))\n+      {\n+      case MEMMODEL_RELAXED:\n+\tswitch (which_alternative)\n+\t  {\n+\t  case 0:\n+\t    return \"s_load%o0\\t%0, %A1 glc\\;s_waitcnt\\tlgkmcnt(0)\";\n+\t  case 1:\n+\t    return \"flat_load%o0\\t%0, %A1%O1 glc\\;s_waitcnt\\t0\";\n+\t  case 2:\n+\t    return \"global_load%o0\\t%0, %A1%O1 glc\\;s_waitcnt\\tvmcnt(0)\";\n+\t  }\n+\tbreak;\n+      case MEMMODEL_CONSUME:\n+      case MEMMODEL_ACQUIRE:\n+      case MEMMODEL_SYNC_ACQUIRE:\n+\tswitch (which_alternative)\n+\t  {\n+\t  case 0:\n+\t    return \"s_load%o0\\t%0, %A1 glc\\;s_waitcnt\\tlgkmcnt(0)\\;\"\n+\t\t   \"s_dcache_wb_vol\";\n+\t  case 1:\n+\t    return \"flat_load%o0\\t%0, %A1%O1 glc\\;s_waitcnt\\t0\\;\"\n+\t\t   \"buffer_wbinvl1_vol\";\n+\t  case 2:\n+\t    return \"global_load%o0\\t%0, %A1%O1 glc\\;s_waitcnt\\tvmcnt(0)\\;\"\n+\t\t   \"buffer_wbinvl1_vol\";\n+\t  }\n+\tbreak;\n+      case MEMMODEL_ACQ_REL:\n+      case MEMMODEL_SEQ_CST:\n+      case MEMMODEL_SYNC_SEQ_CST:\n+\tswitch (which_alternative)\n+\t  {\n+\t  case 0:\n+\t    return \"s_dcache_wb_vol\\;s_load%o0\\t%0, %A1 glc\\;\"\n+\t\t   \"s_waitcnt\\tlgkmcnt(0)\\;s_dcache_inv_vol\";\n+\t  case 1:\n+\t    return \"buffer_wbinvl1_vol\\;flat_load%o0\\t%0, %A1%O1 glc\\;\"\n+\t\t   \"s_waitcnt\\t0\\;buffer_wbinvl1_vol\";\n+\t  case 2:\n+\t    return \"buffer_wbinvl1_vol\\;global_load%o0\\t%0, %A1%O1 glc\\;\"\n+\t\t   \"s_waitcnt\\tvmcnt(0)\\;buffer_wbinvl1_vol\";\n+\t  }\n+\tbreak;\n+      }\n+    gcc_unreachable ();\n+  }\n+  [(set_attr \"type\" \"smem,flat,flat\")\n+   (set_attr \"length\" \"20\")\n+   (set_attr \"gcn_version\" \"gcn5,*,gcn5\")])\n+\n+(define_insn \"atomic_store<mode>\"\n+  [(set (match_operand:SIDI 0 \"memory_operand\"      \"=RS,RF,RM\")\n+\t(unspec_volatile:SIDI\n+\t  [(match_operand:SIDI 1 \"register_operand\" \" Sm, v, v\")]\n+\t  UNSPECV_ATOMIC))\n+  (use (match_operand:SIDI 2 \"immediate_operand\"    \"  i, i, i\"))]\n+  \"\"\n+  {\n+    switch (INTVAL (operands[2]))\n+      {\n+      case MEMMODEL_RELAXED:\n+\tswitch (which_alternative)\n+\t  {\n+\t  case 0:\n+\t    return \"s_store%o1\\t%1, %A0 glc\\;s_waitcnt\\tlgkmcnt(0)\";\n+\t  case 1:\n+\t    return \"flat_store%o1\\t%A0, %1%O0 glc\\;s_waitcnt\\t0\";\n+\t  case 2:\n+\t    return \"global_store%o1\\t%A0, %1%O0 glc\\;s_waitcnt\\tvmcnt(0)\";\n+\t  }\n+\tbreak;\n+      case MEMMODEL_RELEASE:\n+      case MEMMODEL_SYNC_RELEASE:\n+\tswitch (which_alternative)\n+\t  {\n+\t  case 0:\n+\t    return \"s_dcache_wb_vol\\;s_store%o1\\t%1, %A0 glc\\;\"\n+\t\t   \"s_waitcnt\\texpcnt(0)\";\n+\t  case 1:\n+\t    return \"buffer_wbinvl1_vol\\;flat_store%o1\\t%A0, %1%O0 glc\\;\"\n+\t\t   \"s_waitcnt\\texpcnt(0)\";\n+\t  case 2:\n+\t    return \"buffer_wbinvl1_vol\\;global_store%o1\\t%A0, %1%O0 glc\\;\"\n+\t           \"s_waitcnt\\texpcnt(0)\";\n+\t  }\n+\tbreak;\n+      case MEMMODEL_ACQ_REL:\n+      case MEMMODEL_SEQ_CST:\n+      case MEMMODEL_SYNC_SEQ_CST:\n+\tswitch (which_alternative)\n+\t  {\n+\t  case 0:\n+\t    return \"s_dcache_wb_vol\\;s_store%o1\\t%1, %A0 glc\\;\"\n+\t\t   \"s_waitcnt\\texpcnt(0)\\;s_dcache_inv_vol\";\n+\t  case 1:\n+\t    return \"buffer_wbinvl1_vol\\;flat_store%o1\\t%A0, %1%O0 glc\\;\"\n+\t\t   \"s_waitcnt\\texpcnt(0)\\;buffer_wbinvl1_vol\";\n+\t  case 2:\n+\t    return \"buffer_wbinvl1_vol\\;global_store%o1\\t%A0, %1%O0 glc\\;\"\n+\t\t   \"s_waitcnt\\texpcnt(0)\\;buffer_wbinvl1_vol\";\n+\t  }\n+\tbreak;\n+      }\n+    gcc_unreachable ();\n+  }\n+  [(set_attr \"type\" \"smem,flat,flat\")\n+   (set_attr \"length\" \"20\")\n+   (set_attr \"gcn_version\" \"gcn5,*,gcn5\")])\n+\n+(define_insn \"atomic_exchange<mode>\"\n+  [(set (match_operand:SIDI 0 \"register_operand\"    \"=Sm, v, v\")\n+        (match_operand:SIDI 1 \"memory_operand\"\t    \"+RS,RF,RM\"))\n+   (set (match_dup 1)\n+\t(unspec_volatile:SIDI\n+\t  [(match_operand:SIDI 2 \"register_operand\" \" Sm, v, v\")]\n+\t  UNSPECV_ATOMIC))\n+   (use (match_operand 3 \"immediate_operand\"))]\n+  \"\"\n+  {\n+    switch (INTVAL (operands[3]))\n+      {\n+      case MEMMODEL_RELAXED:\n+\tswitch (which_alternative)\n+\t  {\n+\t  case 0:\n+\t    return \"s_atomic_swap<X>\\t%0, %1, %2 glc\\;s_waitcnt\\tlgkmcnt(0)\";\n+\t  case 1:\n+\t    return \"flat_atomic_swap<X>\\t%0, %1, %2 glc\\;s_waitcnt\\t0\";\n+\t  case 2:\n+\t    return \"global_atomic_swap<X>\\t%0, %A1, %2%O1 glc\\;\"\n+\t\t   \"s_waitcnt\\tvmcnt(0)\";\n+\t  }\n+\tbreak;\n+      case MEMMODEL_CONSUME:\n+      case MEMMODEL_ACQUIRE:\n+      case MEMMODEL_SYNC_ACQUIRE:\n+\tswitch (which_alternative)\n+\t  {\n+\t  case 0:\n+\t    return \"s_atomic_swap<X>\\t%0, %1, %2 glc\\;s_waitcnt\\tlgkmcnt(0)\\;\"\n+\t\t   \"s_dcache_wb_vol\\;s_dcache_inv_vol\";\n+\t  case 1:\n+\t    return \"flat_atomic_swap<X>\\t%0, %1, %2 glc\\;s_waitcnt\\t0\\;\"\n+\t\t   \"buffer_wbinvl1_vol\";\n+\t  case 2:\n+\t    return \"global_atomic_swap<X>\\t%0, %A1, %2%O1 glc\\;\"\n+\t\t   \"s_waitcnt\\tvmcnt(0)\\;buffer_wbinvl1_vol\";\n+\t  }\n+\tbreak;\n+      case MEMMODEL_RELEASE:\n+      case MEMMODEL_SYNC_RELEASE:\n+\tswitch (which_alternative)\n+\t  {\n+\t  case 0:\n+\t    return \"s_dcache_wb_vol\\;s_atomic_swap<X>\\t%0, %1, %2 glc\\;\"\n+\t\t   \"s_waitcnt\\tlgkmcnt(0)\";\n+\t  case 1:\n+\t    return \"buffer_wbinvl1_vol\\;flat_atomic_swap<X>\\t%0, %1, %2 glc\\;\"\n+\t\t   \"s_waitcnt\\t0\";\n+\t  case 2:\n+\t    return \"buffer_wbinvl1_vol\\;\"\n+\t\t   \"global_atomic_swap<X>\\t%0, %A1, %2%O1 glc\\;\"\n+\t\t   \"s_waitcnt\\tvmcnt(0)\";\n+\t  }\n+\tbreak;\n+      case MEMMODEL_ACQ_REL:\n+      case MEMMODEL_SEQ_CST:\n+      case MEMMODEL_SYNC_SEQ_CST:\n+\tswitch (which_alternative)\n+\t  {\n+\t  case 0:\n+\t    return \"s_dcache_wb_vol\\;s_atomic_swap<X>\\t%0, %1, %2 glc\\;\"\n+\t\t   \"s_waitcnt\\tlgkmcnt(0)\\;s_dcache_inv_vol\";\n+\t  case 1:\n+\t    return \"buffer_wbinvl1_vol\\;flat_atomic_swap<X>\\t%0, %1, %2 glc\\;\"\n+\t\t   \"s_waitcnt\\t0\\;buffer_wbinvl1_vol\";\n+\t  case 2:\n+\t    return \"buffer_wbinvl1_vol\\;\"\n+\t\t   \"global_atomic_swap<X>\\t%0, %A1, %2%O1 glc\\;\"\n+\t\t   \"s_waitcnt\\tvmcnt(0)\\;buffer_wbinvl1_vol\";\n+\t  }\n+\tbreak;\n+      }\n+    gcc_unreachable ();\n+  }\n+  [(set_attr \"type\" \"smem,flat,flat\")\n+   (set_attr \"length\" \"20\")\n+   (set_attr \"gcn_version\" \"gcn5,*,gcn5\")])\n+\n+;; }}}\n+;; {{{ OpenACC / OpenMP\n+\n+(define_expand \"oacc_dim_size\"\n+  [(match_operand:SI 0 \"register_operand\")\n+   (match_operand:SI 1 \"const_int_operand\")]\n+  \"\"\n+  {\n+    rtx tmp = gcn_oacc_dim_size (INTVAL (operands[1]));\n+    emit_move_insn (operands[0], gen_lowpart (SImode, tmp));\n+    DONE;\n+  })\n+\n+(define_expand \"oacc_dim_pos\"\n+  [(match_operand:SI 0 \"register_operand\")\n+   (match_operand:SI 1 \"const_int_operand\")]\n+  \"\"\n+  {\n+    emit_move_insn (operands[0], gcn_oacc_dim_pos (INTVAL (operands[1])));\n+    DONE;\n+  })\n+\n+(define_expand \"gcn_wavefront_barrier\"\n+  [(set (match_dup 0)\n+\t(unspec_volatile:BLK [(match_dup 0)] UNSPECV_BARRIER))]\n+  \"\"\n+  {\n+    operands[0] = gen_rtx_MEM (BLKmode, gen_rtx_SCRATCH (Pmode));\n+    MEM_VOLATILE_P (operands[0]) = 1;\n+  })\n+\n+(define_insn \"*gcn_wavefront_barrier\"\n+  [(set (match_operand:BLK 0 \"\")\n+\t(unspec_volatile:BLK [(match_dup 0)] UNSPECV_BARRIER))]\n+  \"\"\n+  \"s_barrier\"\n+  [(set_attr \"type\" \"sopp\")])\n+\n+(define_expand \"oacc_fork\"\n+  [(set (match_operand:SI 0 \"\")\n+\t(match_operand:SI 1 \"\"))\n+   (use (match_operand:SI 2 \"\"))]\n+  \"\"\n+  {\n+    /* We need to have oacc_fork/oacc_join named patterns as a pair,\n+       but the fork isn't actually used.  */\n+    gcc_unreachable ();\n+  })\n+\n+(define_expand \"oacc_join\"\n+  [(set (match_operand:SI 0 \"\")\n+\t(match_operand:SI 1 \"\"))\n+   (use (match_operand:SI 2 \"\"))]\n+  \"\"\n+  {\n+    emit_insn (gen_gcn_wavefront_barrier ());\n+    DONE;\n+  })\n+\n+;; }}}\n+\n+(include \"gcn-valu.md\")"}, {"sha": "5b54f49f3cdee47c974aa8ba6799afbda6d8b1b5", "filename": "gcc/config/gcn/predicates.md", "status": "added", "additions": 199, "deletions": 0, "changes": 199, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3d6275e30a850b8e8051163bcd43ddbab2273046/gcc%2Fconfig%2Fgcn%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3d6275e30a850b8e8051163bcd43ddbab2273046/gcc%2Fconfig%2Fgcn%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fgcn%2Fpredicates.md?ref=3d6275e30a850b8e8051163bcd43ddbab2273046", "patch": "@@ -0,0 +1,199 @@\n+;; Predicate definitions for GCN.\n+;; Copyright (C) 2016-2019 Free Software Foundation, Inc.\n+;;\n+;; This file is part of GCC.\n+;;\n+;; GCC is free software; you can redistribute it and/or modify\n+;; it under the terms of the GNU General Public License as published by\n+;; the Free Software Foundation; either version 3, or (at your option)\n+;; any later version.\n+;;\n+;; GCC is distributed in the hope that it will be useful,\n+;; but WITHOUT ANY WARRANTY; without even the implied warranty of\n+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+;; GNU General Public License for more details.\n+;;\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+;; Return true if VALUE can be stored in a sign extended immediate field.\n+\n+(define_predicate \"gcn_conditional_register_operand\"\n+  (match_operand 0 \"register_operand\")\n+{\n+  if (GET_CODE (op) == SUBREG)\n+    op = SUBREG_REG (op);\n+\n+  if (!REG_P (op) || GET_MODE (op) != BImode)\n+    return 0;\n+\n+  return REGNO (op) == VCCZ_REG\n+\t || REGNO (op) == VCC_REG   /* Implied VCCZ.  */\n+\t || REGNO (op) == SCC_REG\n+\t || REGNO (op) == EXECZ_REG\n+\t || REGNO (op) >= FIRST_PSEUDO_REGISTER;\n+})\n+\n+(define_predicate \"gcn_ssrc_register_operand\"\n+  (match_operand 0 \"register_operand\")\n+{\n+  if (GET_CODE (op) == SUBREG)\n+    op = SUBREG_REG (op);\n+\n+  if (!REG_P (op))\n+    return false;\n+\n+  return SSRC_REGNO_P (REGNO (op)) || REGNO (op) >= FIRST_PSEUDO_REGISTER;\n+})\n+\n+(define_predicate \"gcn_sdst_register_operand\"\n+  (match_operand 0 \"register_operand\")\n+{\n+  if (GET_CODE (op) == SUBREG)\n+    op = SUBREG_REG (op);\n+\n+  if (!REG_P (op))\n+    return false;\n+\n+  return SDST_REGNO_P (REGNO (op)) || REGNO (op) >= FIRST_PSEUDO_REGISTER;\n+})\n+\n+(define_predicate \"gcn_vgpr_register_operand\"\n+  (match_operand 0 \"register_operand\")\n+{\n+  if (GET_CODE (op) == SUBREG)\n+    op = SUBREG_REG (op);\n+\n+  if (!REG_P (op))\n+    return false;\n+\n+  return VGPR_REGNO_P (REGNO (op)) || REGNO (op) >= FIRST_PSEUDO_REGISTER;\n+})\n+\n+(define_predicate \"gcn_inline_immediate_operand\"\n+  (match_code \"const_int,const_double,const_vector\")\n+{\n+  return gcn_inline_constant_p (op);\n+})\n+\n+(define_predicate \"gcn_vop3_operand\"\n+  (ior (match_operand 0 \"gcn_inline_immediate_operand\")\n+       (match_operand 0 \"register_operand\")))\n+\n+(define_predicate \"gcn_vec0_operand\"\n+  (match_code \"const_vector\")\n+{\n+  return CONST_VECTOR_ELT (op, 0) == const0_rtx && gcn_inline_constant_p (op);\n+})\n+\n+(define_predicate \"gcn_vec1_operand\"\n+  (match_code \"const_vector\")\n+{\n+  return CONST_VECTOR_ELT (op, 0) == const1_rtx && gcn_inline_constant_p (op);\n+})\n+\n+(define_predicate \"gcn_vec1d_operand\"\n+  (match_code \"const_vector\")\n+{\n+  if (!gcn_inline_constant_p (op))\n+    return false;\n+\n+  rtx elem = CONST_VECTOR_ELT (op, 0);\n+  if (!CONST_DOUBLE_P (elem))\n+    return false;\n+  return real_identical (CONST_DOUBLE_REAL_VALUE (elem), &dconst1);\n+})\n+\n+(define_predicate \"gcn_const1d_operand\"\n+  (match_code \"const_double\")\n+{\n+  return gcn_inline_constant_p (op)\n+      && real_identical (CONST_DOUBLE_REAL_VALUE (op), &dconst1);\n+})\n+\n+(define_predicate \"gcn_32bit_immediate_operand\"\n+  (match_code \"const_int,const_double,const_vector,symbol_ref,label_ref\")\n+{\n+  return gcn_constant_p (op);\n+})\n+\n+; LRA works smoother when exec values are immediate constants\n+; prior register allocation.\n+(define_predicate \"gcn_exec_operand\"\n+  (ior (match_operand 0 \"register_operand\")\n+       (match_code \"const_int\")))\n+\n+(define_predicate \"gcn_exec_reg_operand\"\n+  (match_operand 0 \"register_operand\"))\n+\n+(define_predicate \"gcn_load_operand\"\n+  (ior (match_operand 0 \"nonimmediate_operand\")\n+       (match_operand 0 \"gcn_32bit_immediate_operand\")))\n+\n+(define_predicate \"gcn_alu_operand\"\n+  (ior (match_operand 0 \"register_operand\")\n+       (match_operand 0 \"gcn_32bit_immediate_operand\")))\n+\n+(define_predicate \"gcn_ds_memory_operand\"\n+  (and (match_code \"mem\")\n+       (and (match_test \"AS_ANY_DS_P (MEM_ADDR_SPACE (op))\")\n+\t    (match_operand 0 \"memory_operand\"))))\n+\n+(define_predicate \"gcn_valu_dst_operand\"\n+  (ior (match_operand 0 \"register_operand\")\n+       (match_operand 0 \"gcn_ds_memory_operand\")))\n+\n+(define_predicate \"gcn_valu_src0_operand\"\n+  (ior (match_operand 0 \"register_operand\")\n+       (ior (match_operand 0 \"gcn_32bit_immediate_operand\")\n+\t    (match_operand 0 \"gcn_ds_memory_operand\"))))\n+\n+(define_predicate \"gcn_valu_src1_operand\"\n+  (match_operand 0 \"register_operand\"))\n+\n+(define_predicate \"gcn_valu_src1com_operand\"\n+  (ior (match_operand 0 \"register_operand\")\n+       (match_operand 0 \"gcn_32bit_immediate_operand\")))\n+\n+(define_predicate \"gcn_conditional_operator\"\n+  (match_code \"eq,ne\"))\n+\n+(define_predicate \"gcn_compare_64bit_operator\"\n+  (match_code \"eq,ne\"))\n+\n+(define_predicate \"gcn_compare_operator\"\n+  (match_code \"eq,ne,gt,ge,lt,le,gtu,geu,ltu,leu\"))\n+\n+(define_predicate \"gcn_fp_compare_operator\"\n+  (match_code \"eq,ne,gt,ge,lt,le,gtu,geu,ltu,leu,ordered,unordered\"))\n+\n+(define_predicate \"unary_operator\"\n+  (match_code \"not,popcount\"))\n+\n+(define_predicate \"binary_operator\"\n+  (match_code \"and,ior,xor,ashift,lshiftrt,ashiftrt,smin,smax,umin,umax\"))\n+\n+(define_predicate \"gcn_unspec_operand\"\n+  (and (match_code \"unspec\")\n+       (match_test \"XINT (op, 1) == UNSPEC_VECTOR\")))\n+\n+(define_predicate \"general_or_unspec_operand\"\n+  (ior (match_operand 0 \"general_operand\")\n+       (and (match_code \"unspec\")\n+            (match_test \"XINT (op, 1) == UNSPEC_VECTOR\"))))\n+\n+(define_predicate \"gcn_register_or_unspec_operand\"\n+  (ior (match_operand 0 \"register_operand\")\n+       (and (match_code \"unspec\")\n+            (match_test \"XINT (op, 1) == UNSPEC_VECTOR\"))))\n+\n+(define_predicate \"gcn_alu_or_unspec_operand\"\n+  (ior (match_operand 0 \"gcn_alu_operand\")\n+       (and (match_code \"unspec\")\n+            (match_test \"XINT (op, 1) == UNSPEC_VECTOR\"))))\n+\n+(define_predicate \"gcn_register_ds_or_unspec_operand\"\n+  (ior (match_operand 0 \"register_operand\")\n+       (ior (match_operand 0 \"gcn_ds_memory_operand\")\n+\t    (and (match_code \"unspec\")\n+              (match_test \"XINT (op, 1) == UNSPEC_VECTOR\")))))"}]}