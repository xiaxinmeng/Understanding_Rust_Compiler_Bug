{"sha": "0462169c731de56fdcbb99d96f31707daceee29c", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MDQ2MjE2OWM3MzFkZTU2ZmRjYmI5OWQ5NmYzMTcwN2RhY2VlZTI5Yw==", "commit": {"author": {"name": "Sofiane Naci", "email": "sofiane.naci@arm.com", "date": "2012-11-20T10:07:34Z"}, "committer": {"name": "James Greenhalgh", "email": "jgreenhalgh@gcc.gnu.org", "date": "2012-11-20T10:07:34Z"}, "message": "aarch64.md (define_attr \"sync_*\"): Remove.\n\ngcc/\n\t* config/aarch64/aarch64.md\n\t(define_attr \"sync_*\"): Remove.\n\t(define_attr \"length\"): Update.\n\tInclude atomics.md.\n\t* config/aarch64/aarch64-protos.h\n\t(aarch64_expand_compare_and_swap): Add function prototype.\n\t(aarch64_split_compare_and_swap): Likewise.\n\t(aarch64_split_atomic_op): Likewise.\n\t(aarch64_expand_sync): Remove function prototype.\n\t(aarch64_output_sync_insn): Likewise.\n\t(aarch64_output_sync_lock_release): Likewise.\n\t(aarch64_sync_loop_insns): Likewise.\n\t(struct aarch64_sync_generator): Remove.\n\t(enum aarch64_sync_generator_tag): Likewise.\n\t* config/aarch64/aarch64.c\n\t(aarch64_legitimize_sync_memory): Remove function.\n\t(aarch64_emit): Likewise.\n\t(aarch64_insn_count): Likewise.\n\t(aarch64_output_asm_insn): Likewise.\n\t(aarch64_load_store_suffix): Likewise.\n\t(aarch64_output_sync_load): Likewise.\n\t(aarch64_output_sync_store): Likewise.\n\t(aarch64_output_op2): Likewise.\n\t(aarch64_output_op3): Likewise.\n\t(aarch64_output_sync_loop): Likewise.\n\t(aarch64_get_sync_operand): Likewise.\n\t(aarch64_process_output_sync_insn): Likewise.\n\t(aarch64_output_sync_insn): Likewise.\n\t(aarch64_output_sync_lock_release): Likewise.\n\t(aarch64_sync_loop_insns): Likewise.\n\t(aarch64_call_generator): Likewise.\n\t(aarch64_expand_sync): Likewise.\n\t(* emit_f): Remove variable.\n\t(aarch64_insn_count): Likewise.\n\t(FETCH_SYNC_OPERAND): Likewise.\n\t(aarch64_emit_load_exclusive): New function.\n\t(aarch64_emit_store_exclusive): Likewise.\n\t(aarch64_emit_unlikely_jump): Likewise.\n\t(aarch64_expand_compare_and_swap): Likewise.\n\t(aarch64_split_compare_and_swap): Likewise.\n\t(aarch64_split_atomic_op): Likewise.\n\t* config/aarch64/iterators.md\n\t(atomic_sfx): New mode attribute.\n\t(atomic_optab): New code attribute.\n\t(atomic_op_operand): Likewise.\n\t(atomic_op_str): Likewise.\n\t(syncop): Rename to atomic_op.\n\t* config/aarch64/sync.md: Delete.\n\t* config/aarch64/atomics.md: New file.\n\ngcc/testsuite\n\t* gcc.target/aarch64/atomic-comp-swap-release-acquire.c: New testcase.\n\t* gcc.target/aarch64/atomic-op-acq_rel.c: Likewise.\n\t* gcc.target/aarch64/atomic-op-acquire.c: Likewise.\n\t* gcc.target/aarch64/atomic-op-char.c: Likewise.\n\t* gcc.target/aarch64/atomic-op-consume.c: Likewise.\n\t* gcc.target/aarch64/atomic-op-imm.c: Likewise.\n\t* gcc.target/aarch64/atomic-op-int.c: Likewise.\n\t* gcc.target/aarch64/atomic-op-long.c: Likewise.\n\t* gcc.target/aarch64/atomic-op-relaxed.c: Likewise.\n\t* gcc.target/aarch64/atomic-op-release.c: Likewise.\n\t* gcc.target/aarch64/atomic-op-seq_cst.c: Likewise.\n\t* gcc.target/aarch64/atomic-op-short.c: Likewise.\n\nFrom-SVN: r193651", "tree": {"sha": "104830aa9da4ca2de62e1c556c7877235a112f83", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/104830aa9da4ca2de62e1c556c7877235a112f83"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/0462169c731de56fdcbb99d96f31707daceee29c", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0462169c731de56fdcbb99d96f31707daceee29c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0462169c731de56fdcbb99d96f31707daceee29c", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0462169c731de56fdcbb99d96f31707daceee29c/comments", "author": null, "committer": null, "parents": [{"sha": "206604dccdcd6b054c1c81d4e058b9ca4db8f1f0", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/206604dccdcd6b054c1c81d4e058b9ca4db8f1f0", "html_url": "https://github.com/Rust-GCC/gccrs/commit/206604dccdcd6b054c1c81d4e058b9ca4db8f1f0"}], "stats": {"total": 1263, "additions": 326, "deletions": 937}, "files": [{"sha": "9e0b0d363fa3e401502fc48f736502b1363ba877", "filename": "gcc/ChangeLog", "status": "modified", "additions": 52, "deletions": 0, "changes": 52, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0462169c731de56fdcbb99d96f31707daceee29c/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0462169c731de56fdcbb99d96f31707daceee29c/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=0462169c731de56fdcbb99d96f31707daceee29c", "patch": "@@ -1,3 +1,55 @@\n+2012-11-20  Sofiane Naci  <sofiane.naci@arm.com>\n+\n+\t* config/aarch64/aarch64.md\n+\t(define_attr \"sync_*\"): Remove.\n+\t(define_attr \"length\"): Update.\n+\tInclude atomics.md.\n+\t* config/aarch64/aarch64-protos.h\n+\t(aarch64_expand_compare_and_swap): Add function prototype.\n+\t(aarch64_split_compare_and_swap): Likewise.\n+\t(aarch64_split_atomic_op): Likewise.\n+\t(aarch64_expand_sync): Remove function prototype.\n+\t(aarch64_output_sync_insn): Likewise.\n+\t(aarch64_output_sync_lock_release): Likewise.\n+\t(aarch64_sync_loop_insns): Likewise.\n+\t(struct aarch64_sync_generator): Remove.\n+\t(enum aarch64_sync_generator_tag): Likewise.\n+\t* config/aarch64/aarch64.c\n+\t(aarch64_legitimize_sync_memory): Remove function.\n+\t(aarch64_emit): Likewise.\n+\t(aarch64_insn_count): Likewise.\n+\t(aarch64_output_asm_insn): Likewise.\n+\t(aarch64_load_store_suffix): Likewise.\n+\t(aarch64_output_sync_load): Likewise.\n+\t(aarch64_output_sync_store): Likewise.\n+\t(aarch64_output_op2): Likewise.\n+\t(aarch64_output_op3): Likewise.\n+\t(aarch64_output_sync_loop): Likewise.\n+\t(aarch64_get_sync_operand): Likewise.\n+\t(aarch64_process_output_sync_insn): Likewise.\n+\t(aarch64_output_sync_insn): Likewise.\n+\t(aarch64_output_sync_lock_release): Likewise.\n+\t(aarch64_sync_loop_insns): Likewise.\n+\t(aarch64_call_generator): Likewise.\n+\t(aarch64_expand_sync): Likewise.\n+\t(* emit_f): Remove variable.\n+\t(aarch64_insn_count): Likewise.\n+\t(FETCH_SYNC_OPERAND): Likewise.\n+\t(aarch64_emit_load_exclusive): New function.\n+\t(aarch64_emit_store_exclusive): Likewise.\n+\t(aarch64_emit_unlikely_jump): Likewise.\n+\t(aarch64_expand_compare_and_swap): Likewise.\n+\t(aarch64_split_compare_and_swap): Likewise.\n+\t(aarch64_split_atomic_op): Likewise.\n+\t* config/aarch64/iterators.md\n+\t(atomic_sfx): New mode attribute.\n+\t(atomic_optab): New code attribute.\n+\t(atomic_op_operand): Likewise.\n+\t(atomic_op_str): Likewise.\n+\t(syncop): Rename to atomic_op.\n+\t* config/aarch64/sync.md: Delete.\n+\t* config/aarch64/atomics.md: New file.\n+\n 2012-11-20  Jakub Jelinek  <jakub@redhat.com>\n \n \tPR middle-end/55094"}, {"sha": "4414df4ba4652bb891fd427d0c27ba0d2bce0a13", "filename": "gcc/config/aarch64/aarch64-protos.h", "status": "modified", "additions": 4, "deletions": 34, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0462169c731de56fdcbb99d96f31707daceee29c/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0462169c731de56fdcbb99d96f31707daceee29c/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h?ref=0462169c731de56fdcbb99d96f31707daceee29c", "patch": "@@ -22,35 +22,6 @@\n #ifndef GCC_AARCH64_PROTOS_H\n #define GCC_AARCH64_PROTOS_H\n \n- /* This generator struct and enum is used to wrap a function pointer\n-    to a function that generates an RTX fragment but takes either 3 or\n-    4 operands.\n-\n-    The omn flavour, wraps a function that generates a synchronization\n-    instruction from 3 operands: old value, memory and new value.\n-\n-    The omrn flavour, wraps a function that generates a synchronization\n-    instruction from 4 operands: old value, memory, required value and\n-    new value.  */\n-\n-enum aarch64_sync_generator_tag\n-{\n-  aarch64_sync_generator_omn,\n-  aarch64_sync_generator_omrn\n-};\n-\n- /* Wrapper to pass around a polymorphic pointer to a sync instruction\n-    generator and.  */\n-struct aarch64_sync_generator\n-{\n-  enum aarch64_sync_generator_tag op;\n-  union\n-  {\n-    rtx (*omn) (rtx, rtx, rtx);\n-    rtx (*omrn) (rtx, rtx, rtx, rtx);\n-  } u;\n-};\n-\n /*\n   SYMBOL_CONTEXT_ADR\n   The symbol is used in a load-address operation.\n@@ -186,8 +157,6 @@ bool aarch64_symbolic_constant_p (rtx, enum aarch64_symbol_context,\n \t\t\t\t  enum aarch64_symbol_type *);\n bool aarch64_uimm12_shift (HOST_WIDE_INT);\n const char *aarch64_output_casesi (rtx *);\n-const char *aarch64_output_sync_insn (rtx, rtx *);\n-const char *aarch64_output_sync_lock_release (rtx, rtx);\n enum aarch64_symbol_type aarch64_classify_symbol (rtx,\n \t\t\t\t\t\t  enum aarch64_symbol_context);\n enum aarch64_symbol_type aarch64_classify_tls_symbol (rtx);\n@@ -210,14 +179,11 @@ rtx aarch64_simd_vect_par_cnst_half (enum machine_mode, bool);\n rtx aarch64_tls_get_addr (void);\n unsigned aarch64_dbx_register_number (unsigned);\n unsigned aarch64_trampoline_size (void);\n-unsigned aarch64_sync_loop_insns (rtx, rtx *);\n void aarch64_asm_output_labelref (FILE *, const char *);\n void aarch64_elf_asm_named_section (const char *, unsigned, tree);\n void aarch64_expand_epilogue (bool);\n void aarch64_expand_mov_immediate (rtx, rtx);\n void aarch64_expand_prologue (void);\n-void aarch64_expand_sync (enum machine_mode, struct aarch64_sync_generator *,\n-\t\t\t  rtx, rtx, rtx, rtx);\n void aarch64_function_profiler (FILE *, int);\n void aarch64_init_cumulative_args (CUMULATIVE_ARGS *, const_tree, rtx,\n \t\t\t\t   const_tree, unsigned);\n@@ -256,6 +222,10 @@ enum machine_mode aarch64_select_cc_mode (RTX_CODE, rtx, rtx);\n rtx aarch64_gen_compare_reg (RTX_CODE, rtx, rtx);\n rtx aarch64_load_tp (rtx);\n \n+void aarch64_expand_compare_and_swap (rtx op[]);\n+void aarch64_split_compare_and_swap (rtx op[]);\n+void aarch64_split_atomic_op (enum rtx_code, rtx, rtx, rtx, rtx, rtx, rtx);\n+\n #endif /* RTX_CODE */\n \n #endif /* GCC_AARCH64_PROTOS_H */"}, {"sha": "16837b770cbff364672d34f9fa5ae499e5aefa8e", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 237, "deletions": 376, "changes": 613, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0462169c731de56fdcbb99d96f31707daceee29c/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0462169c731de56fdcbb99d96f31707daceee29c/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=0462169c731de56fdcbb99d96f31707daceee29c", "patch": "@@ -5878,382 +5878,6 @@ aarch64_preferred_simd_mode (enum machine_mode mode)\n   return word_mode;\n }\n \n-/* Legitimize a memory reference for sync primitive implemented using\n-   LDXR/STXR instructions.  We currently force the form of the reference\n-   to be indirect without offset.  */\n-static rtx\n-aarch64_legitimize_sync_memory (rtx memory)\n-{\n-  rtx addr = force_reg (Pmode, XEXP (memory, 0));\n-  rtx legitimate_memory = gen_rtx_MEM (GET_MODE (memory), addr);\n-\n-  set_mem_alias_set (legitimate_memory, ALIAS_SET_MEMORY_BARRIER);\n-  MEM_VOLATILE_P (legitimate_memory) = MEM_VOLATILE_P (memory);\n-  return legitimate_memory;\n-}\n-\n-/* An instruction emitter.  */\n-typedef void (* emit_f) (int label, const char *, rtx *);\n-\n-/* An instruction emitter that emits via the conventional\n-   output_asm_insn.  */\n-static void\n-aarch64_emit (int label ATTRIBUTE_UNUSED, const char *pattern, rtx *operands)\n-{\n-  output_asm_insn (pattern, operands);\n-}\n-\n-/* Count the number of emitted synchronization instructions.  */\n-static unsigned aarch64_insn_count;\n-\n-/* An emitter that counts emitted instructions but does not actually\n-   emit instruction into the the instruction stream.  */\n-static void\n-aarch64_count (int label,\n-\t       const char *pattern ATTRIBUTE_UNUSED,\n-\t       rtx *operands ATTRIBUTE_UNUSED)\n-{\n-  if (! label)\n-    ++ aarch64_insn_count;\n-}\n-\n-static void\n-aarch64_output_asm_insn (emit_f, int, rtx *,\n-\t\t\t const char *, ...) ATTRIBUTE_PRINTF_4;\n-\n-/* Construct a pattern using conventional output formatting and feed\n-   it to output_asm_insn.  Provides a mechanism to construct the\n-   output pattern on the fly.  Note the hard limit on the pattern\n-   buffer size.  */\n-static void\n-aarch64_output_asm_insn (emit_f emit, int label, rtx *operands,\n-\t\t\t const char *pattern, ...)\n-{\n-  va_list ap;\n-  char buffer[256];\n-\n-  va_start (ap, pattern);\n-  vsnprintf (buffer, sizeof (buffer), pattern, ap);\n-  va_end (ap);\n-  emit (label, buffer, operands);\n-}\n-\n-/* Helper to figure out the instruction suffix required on LDXR/STXR\n-   instructions for operations on an object of the specified mode.  */\n-static const char *\n-aarch64_load_store_suffix (enum machine_mode mode)\n-{\n-  switch (mode)\n-    {\n-    case QImode: return \"b\";\n-    case HImode: return \"h\";\n-    case SImode: return \"\";\n-    case DImode: return \"\";\n-    default:\n-      gcc_unreachable ();\n-    }\n-  return \"\";\n-}\n-\n-/* Emit an excluive load instruction appropriate for the specified\n-   mode.  */\n-static void\n-aarch64_output_sync_load (emit_f emit,\n-\t\t\t  enum machine_mode mode,\n-\t\t\t  rtx target,\n-\t\t\t  rtx memory,\n-\t\t\t  bool with_barrier)\n-{\n-  const char *suffix = aarch64_load_store_suffix (mode);\n-  rtx operands[2];\n-\n-  operands[0] = target;\n-  operands[1] = memory;\n-  aarch64_output_asm_insn (emit, 0, operands, \"ld%sxr%s\\t%%%s0, %%1\",\n-\t\t\t   with_barrier ? \"a\" : \"\", suffix,\n-\t\t\t   mode == DImode ? \"x\" : \"w\");\n-}\n-\n-/* Emit an exclusive store instruction appropriate for the specified\n-   mode.  */\n-static void\n-aarch64_output_sync_store (emit_f emit,\n-\t\t\t   enum machine_mode mode,\n-\t\t\t   rtx result,\n-\t\t\t   rtx value,\n-\t\t\t   rtx memory,\n-\t\t\t   bool with_barrier)\n-{\n-  const char *suffix = aarch64_load_store_suffix (mode);\n-  rtx operands[3];\n-\n-  operands[0] = result;\n-  operands[1] = value;\n-  operands[2] = memory;\n-  aarch64_output_asm_insn (emit, 0, operands,\n-\t\t\t   \"st%sxr%s\\t%%w0, %%%s1, %%2\",\n-\t\t\t   with_barrier ? \"l\" : \"\",\n-\t\t\t   suffix,\n-\t\t\t   mode == DImode ? \"x\" : \"w\");\n-}\n-\n-/* Helper to emit a two operand instruction.  */\n-static void\n-aarch64_output_op2 (emit_f emit, const char *mnemonic, rtx d, rtx s)\n-{\n-  rtx operands[2];\n-  enum machine_mode mode;\n-  const char *constraint;\n-\n-  mode = GET_MODE (d);\n-  operands[0] = d;\n-  operands[1] = s;\n-  constraint = mode == DImode ? \"\" : \"w\";\n-  aarch64_output_asm_insn (emit, 0, operands, \"%s\\t%%%s0, %%%s1\", mnemonic,\n-\t\t\t   constraint, constraint);\n-}\n-\n-/* Helper to emit a three operand instruction.  */\n-static void\n-aarch64_output_op3 (emit_f emit, const char *mnemonic, rtx d, rtx a, rtx b)\n-{\n-  rtx operands[3];\n-  enum machine_mode mode;\n-  const char *constraint;\n-\n-  mode = GET_MODE (d);\n-  operands[0] = d;\n-  operands[1] = a;\n-  operands[2] = b;\n-\n-  constraint = mode == DImode ? \"\" : \"w\";\n-  aarch64_output_asm_insn (emit, 0, operands, \"%s\\t%%%s0, %%%s1, %%%s2\",\n-\t\t\t   mnemonic, constraint, constraint, constraint);\n-}\n-\n-/* Emit a load store exclusive synchronization loop.\n-\n-   do\n-     old_value = [mem]\n-     if old_value != required_value\n-       break;\n-     t1 = sync_op (old_value, new_value)\n-     [mem] = t1, t2 = [0|1]\n-   while ! t2\n-\n-   Note:\n-     t1 == t2 is not permitted\n-     t1 == old_value is permitted\n-\n-   required_value:\n-\n-   RTX register or const_int representing the required old_value for\n-   the modify to continue, if NULL no comparsion is performed.  */\n-static void\n-aarch64_output_sync_loop (emit_f emit,\n-\t\t\t  enum machine_mode mode,\n-\t\t\t  rtx old_value,\n-\t\t\t  rtx memory,\n-\t\t\t  rtx required_value,\n-\t\t\t  rtx new_value,\n-\t\t\t  rtx t1,\n-\t\t\t  rtx t2,\n-\t\t\t  enum attr_sync_op sync_op,\n-\t\t\t  int acquire_barrier,\n-\t\t\t  int release_barrier)\n-{\n-  rtx operands[1];\n-\n-  gcc_assert (t1 != t2);\n-\n-  aarch64_output_asm_insn (emit, 1, operands, \"%sLSYT%%=:\", LOCAL_LABEL_PREFIX);\n-\n-  aarch64_output_sync_load (emit, mode, old_value, memory, acquire_barrier);\n-\n-  if (required_value)\n-    {\n-      rtx operands[2];\n-\n-      operands[0] = old_value;\n-      operands[1] = required_value;\n-      aarch64_output_asm_insn (emit, 0, operands, \"cmp\\t%%0, %%1\");\n-      aarch64_output_asm_insn (emit, 0, operands, \"bne\\t%sLSYB%%=\",\n-\t\t\t       LOCAL_LABEL_PREFIX);\n-    }\n-\n-  switch (sync_op)\n-    {\n-    case SYNC_OP_ADD:\n-      aarch64_output_op3 (emit, \"add\", t1, old_value, new_value);\n-      break;\n-\n-    case SYNC_OP_SUB:\n-      aarch64_output_op3 (emit, \"sub\", t1, old_value, new_value);\n-      break;\n-\n-    case SYNC_OP_IOR:\n-      aarch64_output_op3 (emit, \"orr\", t1, old_value, new_value);\n-      break;\n-\n-    case SYNC_OP_XOR:\n-      aarch64_output_op3 (emit, \"eor\", t1, old_value, new_value);\n-      break;\n-\n-    case SYNC_OP_AND:\n-      aarch64_output_op3 (emit,\"and\", t1, old_value, new_value);\n-      break;\n-\n-    case SYNC_OP_NAND:\n-      aarch64_output_op3 (emit, \"and\", t1, old_value, new_value);\n-      aarch64_output_op2 (emit, \"mvn\", t1, t1);\n-      break;\n-\n-    case SYNC_OP_NONE:\n-      t1 = new_value;\n-      break;\n-    }\n-\n-  aarch64_output_sync_store (emit, mode, t2, t1, memory, release_barrier);\n-  operands[0] = t2;\n-  aarch64_output_asm_insn (emit, 0, operands, \"cbnz\\t%%w0, %sLSYT%%=\",\n-\t\t\t   LOCAL_LABEL_PREFIX);\n-\n-  aarch64_output_asm_insn (emit, 1, operands, \"%sLSYB%%=:\", LOCAL_LABEL_PREFIX);\n-}\n-\n-static rtx\n-aarch64_get_sync_operand (rtx *operands, int index, rtx default_value)\n-{\n-  if (index > 0)\n-    default_value = operands[index - 1];\n-\n-  return default_value;\n-}\n-\n-#define FETCH_SYNC_OPERAND(NAME, DEFAULT)                                \\\n-  aarch64_get_sync_operand (operands, (int) get_attr_sync_##NAME (insn), \\\n-\t\t\t    DEFAULT);\n-\n-/* Extract the operands for a synchroniztion instruction from the\n-   instructions attributes and emit the instruction.  */\n-static void\n-aarch64_process_output_sync_insn (emit_f emit, rtx insn, rtx *operands)\n-{\n-  rtx result, memory, required_value, new_value, t1, t2;\n-  int release_barrier;\n-  int acquire_barrier = 1;\n-  enum machine_mode mode;\n-  enum attr_sync_op sync_op;\n-\n-  result = FETCH_SYNC_OPERAND (result, 0);\n-  memory = FETCH_SYNC_OPERAND (memory, 0);\n-  required_value = FETCH_SYNC_OPERAND (required_value, 0);\n-  new_value = FETCH_SYNC_OPERAND (new_value, 0);\n-  t1 = FETCH_SYNC_OPERAND (t1, 0);\n-  t2 = FETCH_SYNC_OPERAND (t2, 0);\n-  release_barrier =\n-    get_attr_sync_release_barrier (insn) == SYNC_RELEASE_BARRIER_YES;\n-  sync_op = get_attr_sync_op (insn);\n-  mode = GET_MODE (memory);\n-\n-  aarch64_output_sync_loop (emit, mode, result, memory, required_value,\n-\t\t\t    new_value, t1, t2, sync_op, acquire_barrier,\n-\t\t\t    release_barrier);\n-}\n-\n-/* Emit a synchronization instruction loop.  */\n-const char *\n-aarch64_output_sync_insn (rtx insn, rtx *operands)\n-{\n-  aarch64_process_output_sync_insn (aarch64_emit, insn, operands);\n-  return \"\";\n-}\n-\n-/* Emit a store release instruction appropriate for the specified\n-   mode.  */\n-const char *\n-aarch64_output_sync_lock_release (rtx value, rtx memory)\n-{\n-  const char *suffix;\n-  enum machine_mode mode;\n-  rtx operands[2];\n-  operands[0] = value;\n-  operands[1] = memory;\n-  mode = GET_MODE (memory);\n-  suffix = aarch64_load_store_suffix (mode);\n-  aarch64_output_asm_insn (aarch64_emit, 0, operands,\n-\t\t\t   \"stlr%s\\t%%%s0, %%1\",\n-\t\t\t   suffix,\n-\t\t\t   mode == DImode ? \"x\" : \"w\");\n-  return \"\";\n-}\n-\n-/* Count the number of machine instruction that will be emitted for a\n-   synchronization instruction.  Note that the emitter used does not\n-   emit instructions, it just counts instructions being careful not\n-   to count labels.  */\n-unsigned int\n-aarch64_sync_loop_insns (rtx insn, rtx *operands)\n-{\n-  aarch64_insn_count = 0;\n-  aarch64_process_output_sync_insn (aarch64_count, insn, operands);\n-  return aarch64_insn_count;\n-}\n-\n-/* Helper to call a target sync instruction generator, dealing with\n-   the variation in operands required by the different generators.  */\n-static rtx\n-aarch64_call_generator (struct aarch64_sync_generator *generator, rtx old_value,\n-\t\t\trtx memory, rtx required_value, rtx new_value)\n-{\n-  switch (generator->op)\n-    {\n-    case aarch64_sync_generator_omn:\n-      gcc_assert (! required_value);\n-      return generator->u.omn (old_value, memory, new_value);\n-\n-    case aarch64_sync_generator_omrn:\n-      gcc_assert (required_value);\n-      return generator->u.omrn (old_value, memory, required_value, new_value);\n-    }\n-\n-  return NULL;\n-}\n-\n-/* Expand a synchronization loop.  The synchronization loop is\n-   expanded as an opaque block of instructions in order to ensure that\n-   we do not subsequently get extraneous memory accesses inserted\n-   within the critical region.  The exclusive access property of\n-   LDXR/STXR instructions is only guaranteed if there are no intervening\n-   memory accesses.  */\n-void\n-aarch64_expand_sync (enum machine_mode mode,\n-\t\t     struct aarch64_sync_generator *generator,\n-\t\t     rtx target, rtx memory, rtx required_value, rtx new_value)\n-{\n-  if (target == NULL)\n-    target = gen_reg_rtx (mode);\n-\n-  memory = aarch64_legitimize_sync_memory (memory);\n-  if (mode != SImode && mode != DImode)\n-    {\n-      rtx load_temp = gen_reg_rtx (SImode);\n-\n-      if (required_value)\n-\trequired_value = convert_modes (SImode, mode, required_value, true);\n-\n-      new_value = convert_modes (SImode, mode, new_value, true);\n-      emit_insn (aarch64_call_generator (generator, load_temp, memory,\n-\t\t\t\t\t required_value, new_value));\n-      emit_move_insn (target, gen_lowpart (mode, load_temp));\n-    }\n-  else\n-    {\n-      emit_insn (aarch64_call_generator (generator, target, memory,\n-\t\t\t\t\t required_value, new_value));\n-    }\n-}\n-\n /* Return the equivalent letter for size.  */\n static unsigned char\n sizetochar (int size)\n@@ -6814,6 +6438,243 @@ aarch64_asm_preferred_eh_data_format (int code ATTRIBUTE_UNUSED, int global)\n    return (global ? DW_EH_PE_indirect : 0) | DW_EH_PE_pcrel | type;\n }\n \n+/* Emit load exclusive.  */\n+\n+static void\n+aarch64_emit_load_exclusive (enum machine_mode mode, rtx rval,\n+\t\t\t     rtx mem, rtx model_rtx)\n+{\n+  rtx (*gen) (rtx, rtx, rtx);\n+\n+  switch (mode)\n+    {\n+    case QImode: gen = gen_aarch64_load_exclusiveqi; break;\n+    case HImode: gen = gen_aarch64_load_exclusivehi; break;\n+    case SImode: gen = gen_aarch64_load_exclusivesi; break;\n+    case DImode: gen = gen_aarch64_load_exclusivedi; break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  emit_insn (gen (rval, mem, model_rtx));\n+}\n+\n+/* Emit store exclusive.  */\n+\n+static void\n+aarch64_emit_store_exclusive (enum machine_mode mode, rtx bval,\n+\t\t\t      rtx rval, rtx mem, rtx model_rtx)\n+{\n+  rtx (*gen) (rtx, rtx, rtx, rtx);\n+\n+  switch (mode)\n+    {\n+    case QImode: gen = gen_aarch64_store_exclusiveqi; break;\n+    case HImode: gen = gen_aarch64_store_exclusivehi; break;\n+    case SImode: gen = gen_aarch64_store_exclusivesi; break;\n+    case DImode: gen = gen_aarch64_store_exclusivedi; break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  emit_insn (gen (bval, rval, mem, model_rtx));\n+}\n+\n+/* Mark the previous jump instruction as unlikely.  */\n+\n+static void\n+aarch64_emit_unlikely_jump (rtx insn)\n+{\n+  rtx very_unlikely = GEN_INT (REG_BR_PROB_BASE / 100 - 1);\n+\n+  insn = emit_jump_insn (insn);\n+  add_reg_note (insn, REG_BR_PROB, very_unlikely);\n+}\n+\n+/* Expand a compare and swap pattern.  */\n+\n+void\n+aarch64_expand_compare_and_swap (rtx operands[])\n+{\n+  rtx bval, rval, mem, oldval, newval, is_weak, mod_s, mod_f, x;\n+  enum machine_mode mode, cmp_mode;\n+  rtx (*gen) (rtx, rtx, rtx, rtx, rtx, rtx, rtx);\n+\n+  bval = operands[0];\n+  rval = operands[1];\n+  mem = operands[2];\n+  oldval = operands[3];\n+  newval = operands[4];\n+  is_weak = operands[5];\n+  mod_s = operands[6];\n+  mod_f = operands[7];\n+  mode = GET_MODE (mem);\n+  cmp_mode = mode;\n+\n+  /* Normally the succ memory model must be stronger than fail, but in the\n+     unlikely event of fail being ACQUIRE and succ being RELEASE we need to\n+     promote succ to ACQ_REL so that we don't lose the acquire semantics.  */\n+\n+  if (INTVAL (mod_f) == MEMMODEL_ACQUIRE\n+      && INTVAL (mod_s) == MEMMODEL_RELEASE)\n+    mod_s = GEN_INT (MEMMODEL_ACQ_REL);\n+\n+  switch (mode)\n+    {\n+    case QImode:\n+    case HImode:\n+      /* For short modes, we're going to perform the comparison in SImode,\n+\t so do the zero-extension now.  */\n+      cmp_mode = SImode;\n+      rval = gen_reg_rtx (SImode);\n+      oldval = convert_modes (SImode, mode, oldval, true);\n+      /* Fall through.  */\n+\n+    case SImode:\n+    case DImode:\n+      /* Force the value into a register if needed.  */\n+      if (!aarch64_plus_operand (oldval, mode))\n+\toldval = force_reg (cmp_mode, oldval);\n+      break;\n+\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  switch (mode)\n+    {\n+    case QImode: gen = gen_atomic_compare_and_swapqi_1; break;\n+    case HImode: gen = gen_atomic_compare_and_swaphi_1; break;\n+    case SImode: gen = gen_atomic_compare_and_swapsi_1; break;\n+    case DImode: gen = gen_atomic_compare_and_swapdi_1; break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  emit_insn (gen (rval, mem, oldval, newval, is_weak, mod_s, mod_f));\n+\n+  if (mode == QImode || mode == HImode)\n+    emit_move_insn (operands[1], gen_lowpart (mode, rval));\n+\n+  x = gen_rtx_REG (CCmode, CC_REGNUM);\n+  x = gen_rtx_EQ (SImode, x, const0_rtx);\n+  emit_insn (gen_rtx_SET (VOIDmode, bval, x));\n+}\n+\n+/* Split a compare and swap pattern.  */\n+\n+void\n+aarch64_split_compare_and_swap (rtx operands[])\n+{\n+  rtx rval, mem, oldval, newval, scratch;\n+  enum machine_mode mode;\n+  enum memmodel mod_s;\n+  bool is_weak;\n+  rtx label1, label2, x, cond;\n+\n+  rval = operands[0];\n+  mem = operands[1];\n+  oldval = operands[2];\n+  newval = operands[3];\n+  is_weak = (operands[4] != const0_rtx);\n+  mod_s = (enum memmodel) INTVAL (operands[5]);\n+  scratch = operands[7];\n+  mode = GET_MODE (mem);\n+\n+  label1 = NULL_RTX;\n+  if (!is_weak)\n+    {\n+      label1 = gen_label_rtx ();\n+      emit_label (label1);\n+    }\n+  label2 = gen_label_rtx ();\n+\n+  aarch64_emit_load_exclusive (mode, rval, mem, operands[5]);\n+\n+  cond = aarch64_gen_compare_reg (NE, rval, oldval);\n+  x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n+  x = gen_rtx_IF_THEN_ELSE (VOIDmode, x,\n+\t\t\t    gen_rtx_LABEL_REF (Pmode, label2), pc_rtx);\n+  aarch64_emit_unlikely_jump (gen_rtx_SET (VOIDmode, pc_rtx, x));\n+\n+  aarch64_emit_store_exclusive (mode, scratch, mem, newval, operands[5]);\n+\n+  if (!is_weak)\n+    {\n+      x = gen_rtx_NE (VOIDmode, scratch, const0_rtx);\n+      x = gen_rtx_IF_THEN_ELSE (VOIDmode, x,\n+\t\t\t\tgen_rtx_LABEL_REF (Pmode, label1), pc_rtx);\n+      aarch64_emit_unlikely_jump (gen_rtx_SET (VOIDmode, pc_rtx, x));\n+    }\n+  else\n+    {\n+      cond = gen_rtx_REG (CCmode, CC_REGNUM);\n+      x = gen_rtx_COMPARE (CCmode, scratch, const0_rtx);\n+      emit_insn (gen_rtx_SET (VOIDmode, cond, x));\n+    }\n+\n+  emit_label (label2);\n+}\n+\n+/* Split an atomic operation.  */\n+\n+void\n+aarch64_split_atomic_op (enum rtx_code code, rtx old_out, rtx new_out, rtx mem,\n+\t\t     rtx value, rtx model_rtx, rtx cond)\n+{\n+  enum machine_mode mode = GET_MODE (mem);\n+  enum machine_mode wmode = (mode == DImode ? DImode : SImode);\n+  rtx label, x;\n+\n+  label = gen_label_rtx ();\n+  emit_label (label);\n+\n+  if (new_out)\n+    new_out = gen_lowpart (wmode, new_out);\n+  if (old_out)\n+    old_out = gen_lowpart (wmode, old_out);\n+  else\n+    old_out = new_out;\n+  value = simplify_gen_subreg (wmode, value, mode, 0);\n+\n+  aarch64_emit_load_exclusive (mode, old_out, mem, model_rtx);\n+\n+  switch (code)\n+    {\n+    case SET:\n+      new_out = value;\n+      break;\n+\n+    case NOT:\n+      x = gen_rtx_AND (wmode, old_out, value);\n+      emit_insn (gen_rtx_SET (VOIDmode, new_out, x));\n+      x = gen_rtx_NOT (wmode, new_out);\n+      emit_insn (gen_rtx_SET (VOIDmode, new_out, x));\n+      break;\n+\n+    case MINUS:\n+      if (CONST_INT_P (value))\n+\t{\n+\t  value = GEN_INT (-INTVAL (value));\n+\t  code = PLUS;\n+\t}\n+      /* Fall through.  */\n+\n+    default:\n+      x = gen_rtx_fmt_ee (code, wmode, old_out, value);\n+      emit_insn (gen_rtx_SET (VOIDmode, new_out, x));\n+      break;\n+    }\n+\n+  aarch64_emit_store_exclusive (mode, cond, mem,\n+\t\t\t\tgen_lowpart (mode, new_out), model_rtx);\n+\n+  x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n+  x = gen_rtx_IF_THEN_ELSE (VOIDmode, x,\n+\t\t\t    gen_rtx_LABEL_REF (Pmode, label), pc_rtx);\n+  aarch64_emit_unlikely_jump (gen_rtx_SET (VOIDmode, pc_rtx, x));\n+}\n+\n static void\n aarch64_start_file (void)\n {"}, {"sha": "5c96c8925da36e335796376e128da4af887d09b3", "filename": "gcc/config/aarch64/aarch64.md", "status": "modified", "additions": 3, "deletions": 59, "changes": 62, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0462169c731de56fdcbb99d96f31707daceee29c/gcc%2Fconfig%2Faarch64%2Faarch64.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0462169c731de56fdcbb99d96f31707daceee29c/gcc%2Fconfig%2Faarch64%2Faarch64.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.md?ref=0462169c731de56fdcbb99d96f31707daceee29c", "patch": "@@ -103,60 +103,6 @@\n (include \"predicates.md\")\n (include \"iterators.md\")\n \n-;; -------------------------------------------------------------------\n-;; Synchronization Builtins\n-;; -------------------------------------------------------------------\n-\n-;; The following sync_* attributes are applied to sychronization\n-;; instruction patterns to control the way in which the\n-;; synchronization loop is expanded.\n-;; All instruction patterns that call aarch64_output_sync_insn ()\n-;; should define these attributes.  Refer to the comment above\n-;; aarch64.c:aarch64_output_sync_loop () for more detail on the use of\n-;; these attributes.\n-\n-;; Attribute specifies the operand number which contains the\n-;; result of a synchronization operation.  The result is the old value\n-;; loaded from SYNC_MEMORY.\n-(define_attr \"sync_result\"          \"none,0,1,2,3,4,5\" (const_string \"none\"))\n-\n-;; Attribute specifies the operand number which contains the memory\n-;; address to which the synchronization operation is being applied.\n-(define_attr \"sync_memory\"          \"none,0,1,2,3,4,5\" (const_string \"none\"))\n-\n-;; Attribute specifies the operand number which contains the required\n-;; old value expected in the memory location.  This attribute may be\n-;; none if no required value test should be performed in the expanded\n-;; code.\n-(define_attr \"sync_required_value\"  \"none,0,1,2,3,4,5\" (const_string \"none\"))\n-\n-;; Attribute specifies the operand number of the new value to be stored\n-;; into the memory location identitifed by the sync_memory attribute.\n-(define_attr \"sync_new_value\"       \"none,0,1,2,3,4,5\" (const_string \"none\"))\n-\n-;; Attribute specifies the operand number of a temporary register\n-;; which can be clobbered by the synchronization instruction sequence.\n-;; The register provided byn SYNC_T1 may be the same as SYNC_RESULT is\n-;; which case the result value will be clobbered and not available\n-;; after the synchronization loop exits.\n-(define_attr \"sync_t1\"              \"none,0,1,2,3,4,5\" (const_string \"none\"))\n-\n-;; Attribute specifies the operand number of a temporary register\n-;; which can be clobbered by the synchronization instruction sequence.\n-;; This register is used to collect the result of a store exclusive\n-;; instruction.\n-(define_attr \"sync_t2\"              \"none,0,1,2,3,4,5\" (const_string \"none\"))\n-\n-;; Attribute that specifies whether or not the emitted synchronization\n-;; loop must contain a release barrier.\n-(define_attr \"sync_release_barrier\" \"yes,no\"           (const_string \"yes\"))\n-\n-;; Attribute that specifies the operation that the synchronization\n-;; loop should apply to the old and new values to generate the value\n-;; written back to memory.\n-(define_attr \"sync_op\"              \"none,add,sub,ior,xor,and,nand\"\n-                                    (const_string \"none\"))\n-\n ;; -------------------------------------------------------------------\n ;; Instruction types and attributes\n ;; -------------------------------------------------------------------\n@@ -370,9 +316,7 @@\n (define_attr \"simd\" \"no,yes\" (const_string \"no\"))\n \n (define_attr \"length\" \"\"\n-  (cond [(not (eq_attr \"sync_memory\" \"none\"))\n-\t   (symbol_ref \"aarch64_sync_loop_insns (insn, operands) * 4\")\n-\t] (const_int 4)))\n+  (const_int 4))\n \n ;; Attribute that controls whether an alternative is enabled or not.\n ;; Currently it is only used to disable alternatives which touch fp or simd\n@@ -2952,5 +2896,5 @@\n ;; AdvSIMD Stuff\n (include \"aarch64-simd.md\")\n \n-;; Synchronization Builtins\n-(include \"sync.md\")\n+;; Atomic Operations\n+(include \"atomics.md\")"}, {"sha": "7a1cdc895351a71e3f0f4d4803b2879bcc8c16eb", "filename": "gcc/config/aarch64/iterators.md", "status": "modified", "additions": 15, "deletions": 1, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0462169c731de56fdcbb99d96f31707daceee29c/gcc%2Fconfig%2Faarch64%2Fiterators.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0462169c731de56fdcbb99d96f31707daceee29c/gcc%2Fconfig%2Faarch64%2Fiterators.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Fiterators.md?ref=0462169c731de56fdcbb99d96f31707daceee29c", "patch": "@@ -449,6 +449,10 @@\n \n (define_mode_attr VSTRUCT_DREG [(OI \"TI\") (CI \"EI\") (XI \"OI\")])\n \n+;; Mode for atomic operation suffixes\n+(define_mode_attr atomic_sfx\n+  [(QI \"b\") (HI \"h\") (SI \"\") (DI \"\")])\n+\n ;; -------------------------------------------------------------------\n ;; Code Iterators\n ;; -------------------------------------------------------------------\n@@ -480,7 +484,7 @@\n ;; Iterator for __sync_<op> operations that where the operation can be\n ;; represented directly RTL.  This is all of the sync operations bar\n ;; nand.\n-(define_code_iterator syncop [plus minus ior xor and])\n+(define_code_iterator atomic_op [plus minus ior xor and])\n \n ;; Iterator for integer conversions\n (define_code_iterator FIXUORS [fix unsigned_fix])\n@@ -575,6 +579,16 @@\n ;; MLA/MLS attributes.\n (define_code_attr as [(ss_plus \"a\") (ss_minus \"s\")])\n \n+;; Atomic operations\n+(define_code_attr atomic_optab\n+  [(ior \"or\") (xor \"xor\") (and \"and\") (plus \"add\") (minus \"sub\")])\n+\n+(define_code_attr atomic_op_operand\n+  [(ior \"aarch64_logical_operand\")\n+   (xor \"aarch64_logical_operand\")\n+   (and \"aarch64_logical_operand\")\n+   (plus \"aarch64_plus_operand\")\n+   (minus \"aarch64_plus_operand\")])\n \n ;; -------------------------------------------------------------------\n ;; Int Iterators."}, {"sha": "61f1f1b78b8e08065026386f222ff4710f634fbb", "filename": "gcc/config/aarch64/sync.md", "status": "removed", "additions": 0, "deletions": 467, "changes": 467, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/206604dccdcd6b054c1c81d4e058b9ca4db8f1f0/gcc%2Fconfig%2Faarch64%2Fsync.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/206604dccdcd6b054c1c81d4e058b9ca4db8f1f0/gcc%2Fconfig%2Faarch64%2Fsync.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Fsync.md?ref=206604dccdcd6b054c1c81d4e058b9ca4db8f1f0", "patch": "@@ -1,467 +0,0 @@\n-;; Machine description for AArch64 processor synchronization primitives.\n-;; Copyright (C) 2009, 2010, 2011, 2012 Free Software Foundation, Inc.\n-;; Contributed by ARM Ltd.\n-;;\n-;; This file is part of GCC.\n-;;\n-;; GCC is free software; you can redistribute it and/or modify it\n-;; under the terms of the GNU General Public License as published by\n-;; the Free Software Foundation; either version 3, or (at your option)\n-;; any later version.\n-;;\n-;; GCC is distributed in the hope that it will be useful, but\n-;; WITHOUT ANY WARRANTY; without even the implied warranty of\n-;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n-;; General Public License for more details.\n-;;\n-;; You should have received a copy of the GNU General Public License\n-;; along with GCC; see the file COPYING3.  If not see\n-;; <http://www.gnu.org/licenses/>.\n-\n-(define_c_enum \"unspecv\"\n- [\n-    UNSPECV_SYNC_COMPARE_AND_SWAP       ; Represent a sync_compare_and_swap.\n-    UNSPECV_SYNC_LOCK\t\t\t; Represent a sync_lock_test_and_set.\n-    UNSPECV_SYNC_LOCK_RELEASE\t\t; Represent a sync_lock_release.\n-    UNSPECV_SYNC_OP\t\t\t; Represent a sync_<op>\n-    UNSPECV_SYNC_NEW_OP\t\t\t; Represent a sync_new_<op>\n-    UNSPECV_SYNC_OLD_OP\t\t\t; Represent a sync_old_<op>\n-])\n-\n-(define_expand \"sync_compare_and_swap<mode>\"\n-  [(set (match_operand:ALLI 0 \"register_operand\")\n-        (unspec_volatile:ALLI [(match_operand:ALLI 1 \"memory_operand\")\n-\t\t\t       (match_operand:ALLI 2 \"register_operand\")\n-\t\t\t       (match_operand:ALLI 3 \"register_operand\")]\n-\t\t\t       UNSPECV_SYNC_COMPARE_AND_SWAP))]\n-  \"\"\n-  {\n-    struct aarch64_sync_generator generator;\n-    generator.op = aarch64_sync_generator_omrn;\n-    generator.u.omrn = gen_aarch64_sync_compare_and_swap<mode>;\n-    aarch64_expand_sync (<MODE>mode, &generator, operands[0], operands[1],\n-    \t\t\t operands[2], operands[3]);\n-    DONE;\n-  })\n-\n-(define_expand \"sync_lock_test_and_set<mode>\"\n-  [(match_operand:ALLI 0 \"register_operand\")\n-   (match_operand:ALLI 1 \"memory_operand\")\n-   (match_operand:ALLI 2 \"register_operand\")]\n-  \"\"\n-  {\n-    struct aarch64_sync_generator generator;\n-    generator.op = aarch64_sync_generator_omn;\n-    generator.u.omn = gen_aarch64_sync_lock_test_and_set<mode>;\n-    aarch64_expand_sync (<MODE>mode, &generator, operands[0], operands[1],\n-                         NULL, operands[2]);\n-    DONE;\n-  })\n-\n-(define_expand \"sync_<optab><mode>\"\n-  [(match_operand:ALLI 0 \"memory_operand\")\n-   (match_operand:ALLI 1 \"register_operand\")\n-   (syncop:ALLI (match_dup 0) (match_dup 1))]\n-  \"\"\n-  {\n-    struct aarch64_sync_generator generator;\n-    generator.op = aarch64_sync_generator_omn;\n-    generator.u.omn = gen_aarch64_sync_new_<optab><mode>;\n-    aarch64_expand_sync (<MODE>mode, &generator, NULL, operands[0], NULL,\n-                         operands[1]);\n-    DONE;\n-  })\n-\n-(define_expand \"sync_nand<mode>\"\n-  [(match_operand:ALLI 0 \"memory_operand\")\n-   (match_operand:ALLI 1 \"register_operand\")\n-   (not:ALLI (and:ALLI (match_dup 0) (match_dup 1)))]\n-  \"\"\n-  {\n-    struct aarch64_sync_generator generator;\n-    generator.op = aarch64_sync_generator_omn;\n-    generator.u.omn = gen_aarch64_sync_new_nand<mode>;\n-    aarch64_expand_sync (<MODE>mode, &generator, NULL, operands[0], NULL,\n-                         operands[1]);\n-    DONE;\n-  })\n-\n-(define_expand \"sync_new_<optab><mode>\"\n-  [(match_operand:ALLI 0 \"register_operand\")\n-   (match_operand:ALLI 1 \"memory_operand\")\n-   (match_operand:ALLI 2 \"register_operand\")\n-   (syncop:ALLI (match_dup 1) (match_dup 2))]\n-  \"\"\n-  {\n-    struct aarch64_sync_generator generator;\n-    generator.op = aarch64_sync_generator_omn;\n-    generator.u.omn = gen_aarch64_sync_new_<optab><mode>;\n-    aarch64_expand_sync (<MODE>mode, &generator, operands[0], operands[1],\n-    \t\t    \t NULL, operands[2]);\n-    DONE;\n-  })\n-\n-(define_expand \"sync_new_nand<mode>\"\n-  [(match_operand:ALLI 0 \"register_operand\")\n-   (match_operand:ALLI 1 \"memory_operand\")\n-   (match_operand:ALLI 2 \"register_operand\")\n-   (not:ALLI (and:ALLI (match_dup 1) (match_dup 2)))]\n-  \"\"\n-  {\n-    struct aarch64_sync_generator generator;\n-    generator.op = aarch64_sync_generator_omn;\n-    generator.u.omn = gen_aarch64_sync_new_nand<mode>;\n-    aarch64_expand_sync (<MODE>mode, &generator, operands[0], operands[1],\n-    \t\t\t NULL, operands[2]);\n-    DONE;\n-  });\n-\n-(define_expand \"sync_old_<optab><mode>\"\n-  [(match_operand:ALLI 0 \"register_operand\")\n-   (match_operand:ALLI 1 \"memory_operand\")\n-   (match_operand:ALLI 2 \"register_operand\")\n-   (syncop:ALLI (match_dup 1) (match_dup 2))]\n-  \"\"\n-  {\n-    struct aarch64_sync_generator generator;\n-    generator.op = aarch64_sync_generator_omn;\n-    generator.u.omn = gen_aarch64_sync_old_<optab><mode>;\n-    aarch64_expand_sync (<MODE>mode, &generator, operands[0], operands[1],\n-    \t\t         NULL, operands[2]);\n-    DONE;\n-  })\n-\n-(define_expand \"sync_old_nand<mode>\"\n-  [(match_operand:ALLI 0 \"register_operand\")\n-   (match_operand:ALLI 1 \"memory_operand\")\n-   (match_operand:ALLI 2 \"register_operand\")\n-   (not:ALLI (and:ALLI (match_dup 1) (match_dup 2)))]\n-  \"\"\n-  {\n-    struct aarch64_sync_generator generator;\n-    generator.op = aarch64_sync_generator_omn;\n-    generator.u.omn = gen_aarch64_sync_old_nand<mode>;\n-    aarch64_expand_sync (<MODE>mode, &generator, operands[0], operands[1],\n-                         NULL, operands[2]);\n-    DONE;\n-  })\n-\n-(define_expand \"memory_barrier\"\n-  [(set (match_dup 0) (unspec:BLK [(match_dup 0)] UNSPEC_MB))]\n-  \"\"\n-{\n-  operands[0] = gen_rtx_MEM (BLKmode, gen_rtx_SCRATCH (Pmode));\n-  MEM_VOLATILE_P (operands[0]) = 1;\n-})\n-\n-(define_insn \"aarch64_sync_compare_and_swap<mode>\"\n-  [(set (match_operand:GPI 0 \"register_operand\" \"=&r\")\n-        (unspec_volatile:GPI\n-\t  [(match_operand:GPI 1 \"aarch64_sync_memory_operand\" \"+Q\")\n-   \t   (match_operand:GPI 2 \"register_operand\" \"r\")\n-\t   (match_operand:GPI 3 \"register_operand\" \"r\")]\n-\t  UNSPECV_SYNC_COMPARE_AND_SWAP))\n-   (set (match_dup 1) (unspec_volatile:GPI [(match_dup 2)]\n-                                          UNSPECV_SYNC_COMPARE_AND_SWAP))\n-   (clobber:GPI (match_scratch:GPI 4 \"=&r\"))\n-   (set (reg:CC CC_REGNUM) (unspec_volatile:CC [(match_dup 1)]\n-                                                UNSPECV_SYNC_COMPARE_AND_SWAP))\n-   ]\n-  \"\"\n-  {\n-    return aarch64_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_required_value\"  \"2\")\n-   (set_attr \"sync_new_value\"       \"3\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"sync_t2\"              \"4\")\n-   ])\n-\n-(define_insn \"aarch64_sync_compare_and_swap<mode>\"\n-  [(set (match_operand:SI 0 \"register_operand\" \"=&r\")\n-        (zero_extend:SI\n-\t  (unspec_volatile:SHORT\n-\t    [(match_operand:SHORT 1 \"aarch64_sync_memory_operand\" \"+Q\")\n-   \t     (match_operand:SI 2 \"register_operand\" \"r\")\n-\t     (match_operand:SI 3 \"register_operand\" \"r\")]\n-\t    UNSPECV_SYNC_COMPARE_AND_SWAP)))\n-   (set (match_dup 1) (unspec_volatile:SHORT [(match_dup 2)]\n-                                             UNSPECV_SYNC_COMPARE_AND_SWAP))\n-   (clobber:SI (match_scratch:SI 4 \"=&r\"))\n-   (set (reg:CC CC_REGNUM) (unspec_volatile:CC [(match_dup 1)]\n-                                                UNSPECV_SYNC_COMPARE_AND_SWAP))\n-   ]\n-  \"\"\n-  {\n-    return aarch64_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_required_value\"  \"2\")\n-   (set_attr \"sync_new_value\"       \"3\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"sync_t2\"              \"4\")\n-   ])\n-\n-(define_insn \"aarch64_sync_lock_test_and_set<mode>\"\n-  [(set (match_operand:GPI 0 \"register_operand\" \"=&r\")\n-        (match_operand:GPI 1 \"aarch64_sync_memory_operand\" \"+Q\"))\n-   (set (match_dup 1)\n-        (unspec_volatile:GPI [(match_operand:GPI 2 \"register_operand\" \"r\")]\n-\t                     UNSPECV_SYNC_LOCK))\n-   (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:GPI 3 \"=&r\"))]\n-  \"\"\n-  {\n-    return aarch64_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_release_barrier\" \"no\")\n-   (set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"sync_t2\"              \"3\")\n-   ])\n-\n-(define_insn \"aarch64_sync_lock_test_and_set<mode>\"\n-  [(set (match_operand:SI 0 \"register_operand\" \"=&r\")\n-        (zero_extend:SI (match_operand:SHORT 1\n-\t                  \"aarch64_sync_memory_operand\" \"+Q\")))\n-   (set (match_dup 1)\n-        (unspec_volatile:SHORT [(match_operand:SI 2 \"register_operand\" \"r\")]\n-                               UNSPECV_SYNC_LOCK))\n-   (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:SI 3 \"=&r\"))]\n-  \"\"\n-  {\n-    return aarch64_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_release_barrier\" \"no\")\n-   (set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"sync_t2\"              \"3\")\n-   ])\n-\n-(define_insn \"aarch64_sync_new_<optab><mode>\"\n-  [(set (match_operand:GPI 0 \"register_operand\" \"=&r\")\n-        (unspec_volatile:GPI\n-\t  [(syncop:GPI\n-\t     (match_operand:GPI 1 \"aarch64_sync_memory_operand\" \"+Q\")\n-             (match_operand:GPI 2 \"register_operand\" \"r\"))]\n-           UNSPECV_SYNC_NEW_OP))\n-   (set (match_dup 1)\n-        (unspec_volatile:GPI [(match_dup 1) (match_dup 2)]\n-\t                    UNSPECV_SYNC_NEW_OP))\n-   (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:GPI 3 \"=&r\"))]\n-  \"\"\n-  {\n-    return aarch64_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"sync_t2\"              \"3\")\n-   (set_attr \"sync_op\"              \"<optab>\")\n-   ])\n-\n-(define_insn \"aarch64_sync_new_nand<mode>\"\n-  [(set (match_operand:GPI 0 \"register_operand\" \"=&r\")\n-        (unspec_volatile:GPI\n-\t  [(not:GPI (and:GPI\n-                     (match_operand:GPI 1 \"aarch64_sync_memory_operand\" \"+Q\")\n-                     (match_operand:GPI 2 \"register_operand\" \"r\")))]\n-          UNSPECV_SYNC_NEW_OP))\n-   (set (match_dup 1)\n-        (unspec_volatile:GPI [(match_dup 1) (match_dup 2)]\n-\t                    UNSPECV_SYNC_NEW_OP))\n-   (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:GPI 3 \"=&r\"))]\n-  \"\"\n-  {\n-    return aarch64_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"sync_t2\"              \"3\")\n-   (set_attr \"sync_op\"              \"nand\")\n-   ])\n-\n-(define_insn \"aarch64_sync_new_<optab><mode>\"\n-  [(set (match_operand:SI 0 \"register_operand\" \"=&r\")\n-        (unspec_volatile:SI\n-\t  [(syncop:SI\n-             (zero_extend:SI\n-\t       (match_operand:SHORT 1 \"aarch64_sync_memory_operand\" \"+Q\"))\n-               (match_operand:SI 2 \"register_operand\" \"r\"))]\n-          UNSPECV_SYNC_NEW_OP))\n-   (set (match_dup 1)\n-        (unspec_volatile:SHORT [(match_dup 1) (match_dup 2)]\n-\t                       UNSPECV_SYNC_NEW_OP))\n-   (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:SI 3 \"=&r\"))]\n-  \"\"\n-  {\n-    return aarch64_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"sync_t2\"              \"3\")\n-   (set_attr \"sync_op\"              \"<optab>\")\n-   ])\n-\n-(define_insn \"aarch64_sync_new_nand<mode>\"\n-  [(set (match_operand:SI 0 \"register_operand\" \"=&r\")\n-        (unspec_volatile:SI\n-\t  [(not:SI\n-\t     (and:SI\n-               (zero_extend:SI\n-\t         (match_operand:SHORT 1 \"aarch64_sync_memory_operand\" \"+Q\"))\n-               (match_operand:SI 2 \"register_operand\" \"r\")))\n-\t  ] UNSPECV_SYNC_NEW_OP))\n-   (set (match_dup 1)\n-        (unspec_volatile:SHORT [(match_dup 1) (match_dup 2)]\n-\t                       UNSPECV_SYNC_NEW_OP))\n-   (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:SI 3 \"=&r\"))]\n-  \"\"\n-  {\n-    return aarch64_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"sync_t2\"              \"3\")\n-   (set_attr \"sync_op\"              \"nand\")\n-   ])\n-\n-(define_insn \"aarch64_sync_old_<optab><mode>\"\n-  [(set (match_operand:GPI 0 \"register_operand\" \"=&r\")\n-        (unspec_volatile:GPI\n-          [(syncop:GPI\n-             (match_operand:GPI 1 \"aarch64_sync_memory_operand\" \"+Q\")\n-             (match_operand:GPI 2 \"register_operand\" \"r\"))]\n-          UNSPECV_SYNC_OLD_OP))\n-   (set (match_dup 1)\n-        (unspec_volatile:GPI [(match_dup 1) (match_dup 2)]\n-\t                     UNSPECV_SYNC_OLD_OP))\n-   (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:GPI 3 \"=&r\"))\n-   (clobber (match_scratch:GPI 4 \"=&r\"))]\n-  \"\"\n-  {\n-    return aarch64_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"3\")\n-   (set_attr \"sync_t2\"              \"4\")\n-   (set_attr \"sync_op\"              \"<optab>\")\n-   ])\n-\n-(define_insn \"aarch64_sync_old_nand<mode>\"\n-  [(set (match_operand:GPI 0 \"register_operand\" \"=&r\")\n-        (unspec_volatile:GPI\n-\t  [(not:GPI (and:GPI\n-                     (match_operand:GPI 1 \"aarch64_sync_memory_operand\" \"+Q\")\n-                     (match_operand:GPI 2 \"register_operand\" \"r\")))]\n-          UNSPECV_SYNC_OLD_OP))\n-   (set (match_dup 1)\n-        (unspec_volatile:GPI [(match_dup 1) (match_dup 2)]\n-\t                     UNSPECV_SYNC_OLD_OP))\n-   (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:GPI 3 \"=&r\"))\n-   (clobber (match_scratch:GPI 4 \"=&r\"))]\n-  \"\"\n-  {\n-    return aarch64_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"3\")\n-   (set_attr \"sync_t2\"              \"4\")\n-   (set_attr \"sync_op\"              \"nand\")\n-   ])\n-\n-(define_insn \"aarch64_sync_old_<optab><mode>\"\n-  [(set (match_operand:SI 0 \"register_operand\" \"=&r\")\n-        (unspec_volatile:SI\n-\t  [(syncop:SI\n-             (zero_extend:SI\n-\t       (match_operand:SHORT 1 \"aarch64_sync_memory_operand\" \"+Q\"))\n-               (match_operand:SI 2 \"register_operand\" \"r\"))]\n-           UNSPECV_SYNC_OLD_OP))\n-   (set (match_dup 1)\n-        (unspec_volatile:SHORT [(match_dup 1) (match_dup 2)]\n-\t                       UNSPECV_SYNC_OLD_OP))\n-   (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:SI 3 \"=&r\"))\n-   (clobber (match_scratch:SI 4 \"=&r\"))]\n-  \"\"\n-  {\n-    return aarch64_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"3\")\n-   (set_attr \"sync_t2\"              \"4\")\n-   (set_attr \"sync_op\"              \"<optab>\")\n-   ])\n-\n-(define_insn \"aarch64_sync_old_nand<mode>\"\n-  [(set (match_operand:SI 0 \"register_operand\" \"=&r\")\n-        (unspec_volatile:SI\n-\t  [(not:SI\n-\t     (and:SI\n-               (zero_extend:SI\n-\t\t (match_operand:SHORT 1 \"aarch64_sync_memory_operand\" \"+Q\"))\n-                 (match_operand:SI 2 \"register_operand\" \"r\")))]\n-          UNSPECV_SYNC_OLD_OP))\n-   (set (match_dup 1)\n-        (unspec_volatile:SHORT [(match_dup 1) (match_dup 2)]\n-\t                       UNSPECV_SYNC_OLD_OP))\n-   (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:SI 3 \"=&r\"))\n-   (clobber (match_scratch:SI 4 \"=&r\"))]\n-  \"\"\n-  {\n-    return aarch64_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"3\")\n-   (set_attr \"sync_t2\"              \"4\")\n-   (set_attr \"sync_op\"              \"nand\")\n-   ])\n-\n-(define_insn \"*memory_barrier\"\n-  [(set (match_operand:BLK 0 \"\" \"\")\n-\t(unspec:BLK [(match_dup 0)] UNSPEC_MB))]\n-  \"\"\n-  \"dmb\\\\tish\"\n-)\n-\n-(define_insn \"sync_lock_release<mode>\"\n-  [(set (match_operand:ALLI 0 \"memory_operand\" \"+Q\")\n-  \t(unspec_volatile:ALLI [(match_operand:ALLI 1 \"register_operand\" \"r\")]\n-\t                      UNSPECV_SYNC_LOCK_RELEASE))]\n-\n-  \"\"\n-  {\n-    return aarch64_output_sync_lock_release (operands[1], operands[0]);\n-  })\n-"}, {"sha": "1a9c0100385be955f3d21888b687fe139eaa9553", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0462169c731de56fdcbb99d96f31707daceee29c/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0462169c731de56fdcbb99d96f31707daceee29c/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=0462169c731de56fdcbb99d96f31707daceee29c", "patch": "@@ -1,3 +1,18 @@\n+2012-11-20  Sofiane Naci  <sofiane.naci@arm.com>\n+\n+\t* gcc.target/aarch64/atomic-comp-swap-release-acquire.c: New testcase.\n+\t* gcc.target/aarch64/atomic-op-acq_rel.c: Likewise.\n+\t* gcc.target/aarch64/atomic-op-acquire.c: Likewise.\n+\t* gcc.target/aarch64/atomic-op-char.c: Likewise.\n+\t* gcc.target/aarch64/atomic-op-consume.c: Likewise.\n+\t* gcc.target/aarch64/atomic-op-imm.c: Likewise.\n+\t* gcc.target/aarch64/atomic-op-int.c: Likewise.\n+\t* gcc.target/aarch64/atomic-op-long.c: Likewise.\n+\t* gcc.target/aarch64/atomic-op-relaxed.c: Likewise.\n+\t* gcc.target/aarch64/atomic-op-release.c: Likewise.\n+\t* gcc.target/aarch64/atomic-op-seq_cst.c: Likewise.\n+\t* gcc.target/aarch64/atomic-op-short.c: Likewise.\n+\n 2012-11-20  Jakub Jelinek  <jakub@redhat.com>\n \n \tPR middle-end/55094"}]}