{"sha": "b31186e589caee43ac5720a538d9a41ebf514e81", "node_id": "C_kwDOANBUbNoAKGIzMTE4NmU1ODljYWVlNDNhYzU3MjBhNTM4ZDlhNDFlYmY1MTRlODE", "commit": {"author": {"name": "Matthias Kretz", "email": "m.kretz@gsi.de", "date": "2023-02-21T07:48:18Z"}, "committer": {"name": "Matthias Kretz", "email": "m.kretz@gsi.de", "date": "2023-02-24T18:38:57Z"}, "message": "libstdc++: Fix formatting\n\nWhitespace changes only.\n\nSigned-off-by: Matthias Kretz <m.kretz@gsi.de>\n\nlibstdc++-v3/ChangeLog:\n\n\t* include/experimental/bits/simd.h: Line breaks and indenting\n\tfixed to follow the libstdc++ standard.\n\t* include/experimental/bits/simd_builtin.h: Likewise.\n\t* include/experimental/bits/simd_fixed_size.h: Likewise.\n\t* include/experimental/bits/simd_neon.h: Likewise.\n\t* include/experimental/bits/simd_ppc.h: Likewise.\n\t* include/experimental/bits/simd_scalar.h: Likewise.\n\t* include/experimental/bits/simd_x86.h: Likewise.", "tree": {"sha": "65cdf4fc84bb8a7eb90168d2c61fdd33a04df4bd", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/65cdf4fc84bb8a7eb90168d2c61fdd33a04df4bd"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/b31186e589caee43ac5720a538d9a41ebf514e81", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b31186e589caee43ac5720a538d9a41ebf514e81", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b31186e589caee43ac5720a538d9a41ebf514e81", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b31186e589caee43ac5720a538d9a41ebf514e81/comments", "author": {"login": "mattkretz", "id": 3306474, "node_id": "MDQ6VXNlcjMzMDY0NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/3306474?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mattkretz", "html_url": "https://github.com/mattkretz", "followers_url": "https://api.github.com/users/mattkretz/followers", "following_url": "https://api.github.com/users/mattkretz/following{/other_user}", "gists_url": "https://api.github.com/users/mattkretz/gists{/gist_id}", "starred_url": "https://api.github.com/users/mattkretz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mattkretz/subscriptions", "organizations_url": "https://api.github.com/users/mattkretz/orgs", "repos_url": "https://api.github.com/users/mattkretz/repos", "events_url": "https://api.github.com/users/mattkretz/events{/privacy}", "received_events_url": "https://api.github.com/users/mattkretz/received_events", "type": "User", "site_admin": false}, "committer": {"login": "mattkretz", "id": 3306474, "node_id": "MDQ6VXNlcjMzMDY0NzQ=", "avatar_url": "https://avatars.githubusercontent.com/u/3306474?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mattkretz", "html_url": "https://github.com/mattkretz", "followers_url": "https://api.github.com/users/mattkretz/followers", "following_url": "https://api.github.com/users/mattkretz/following{/other_user}", "gists_url": "https://api.github.com/users/mattkretz/gists{/gist_id}", "starred_url": "https://api.github.com/users/mattkretz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mattkretz/subscriptions", "organizations_url": "https://api.github.com/users/mattkretz/orgs", "repos_url": "https://api.github.com/users/mattkretz/repos", "events_url": "https://api.github.com/users/mattkretz/events{/privacy}", "received_events_url": "https://api.github.com/users/mattkretz/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e37b04328ae68f91efe1fb2c5de9122be34bc74a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e37b04328ae68f91efe1fb2c5de9122be34bc74a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e37b04328ae68f91efe1fb2c5de9122be34bc74a"}], "stats": {"total": 1872, "additions": 942, "deletions": 930}, "files": [{"sha": "4df446654acbee03b669fdb54d1fb608a0c4e9d6", "filename": "libstdc++-v3/include/experimental/bits/simd.h", "status": "modified", "additions": 235, "deletions": 238, "changes": 473, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b31186e589caee43ac5720a538d9a41ebf514e81/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b31186e589caee43ac5720a538d9a41ebf514e81/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd.h?ref=b31186e589caee43ac5720a538d9a41ebf514e81", "patch": "@@ -180,10 +180,7 @@ struct vector_aligned_tag\n   template <typename _Tp, typename _Up>\n     _GLIBCXX_SIMD_INTRINSIC static constexpr _Up*\n     _S_apply(_Up* __ptr)\n-    {\n-      return static_cast<_Up*>(\n-\t__builtin_assume_aligned(__ptr, _S_alignment<_Tp, _Up>));\n-    }\n+    { return static_cast<_Up*>(__builtin_assume_aligned(__ptr, _S_alignment<_Tp, _Up>)); }\n };\n \n template <size_t _Np> struct overaligned_tag\n@@ -288,13 +285,15 @@ namespace __detail\n   // expression. math_errhandling may expand to an extern symbol, in which case a constexpr value\n   // must be guessed.\n   template <int = math_errhandling>\n-    constexpr bool __handle_fpexcept_impl(int)\n+    constexpr bool\n+    __handle_fpexcept_impl(int)\n     { return math_errhandling & MATH_ERREXCEPT; }\n #endif\n \n   // Fallback if math_errhandling doesn't work: with fast-math assume floating-point exceptions are\n   // ignored, otherwise implement correct exception behavior.\n-  constexpr bool __handle_fpexcept_impl(float)\n+  constexpr bool\n+  __handle_fpexcept_impl(float)\n   {\n #if defined __FAST_MATH__\n     return false;\n@@ -749,8 +748,7 @@ template <typename _Tp, typename _Up>\n // __invoke_ub{{{\n template <typename... _Args>\n   [[noreturn]] _GLIBCXX_SIMD_ALWAYS_INLINE void\n-  __invoke_ub([[maybe_unused]] const char* __msg,\n-\t      [[maybe_unused]] const _Args&... __args)\n+  __invoke_ub([[maybe_unused]] const char* __msg, [[maybe_unused]] const _Args&... __args)\n   {\n #ifdef _GLIBCXX_DEBUG_UB\n     __builtin_fprintf(stderr, __msg, __args...);\n@@ -795,11 +793,14 @@ class _ExactBool\n   const bool _M_data;\n \n public:\n-  _GLIBCXX_SIMD_INTRINSIC constexpr _ExactBool(bool __b) : _M_data(__b) {}\n+  _GLIBCXX_SIMD_INTRINSIC constexpr\n+  _ExactBool(bool __b) : _M_data(__b) {}\n \n   _ExactBool(int) = delete;\n \n-  _GLIBCXX_SIMD_INTRINSIC constexpr operator bool() const { return _M_data; }\n+  _GLIBCXX_SIMD_INTRINSIC constexpr\n+  operator bool() const\n+  { return _M_data; }\n };\n \n // }}}\n@@ -1488,8 +1489,7 @@ template <typename _Tp>\n \n // else, use GNU-style builtin vector types\n template <typename _Tp, size_t _Np>\n-  struct __vector_type_n<_Tp, _Np,\n-\t\t\t enable_if_t<__is_vectorizable_v<_Tp> && _Np >= 2>>\n+  struct __vector_type_n<_Tp, _Np, enable_if_t<__is_vectorizable_v<_Tp> && _Np >= 2>>\n   {\n     static constexpr size_t _S_Np2 = std::__bit_ceil(_Np * sizeof(_Tp));\n \n@@ -1770,8 +1770,7 @@ template <typename _To, typename _From>\n // }}}\n // __to_intrin {{{\n template <typename _Tp, typename _TVT = _VectorTraits<_Tp>,\n-\t  typename _R\n-\t  = __intrinsic_type_t<typename _TVT::value_type, _TVT::_S_full_size>>\n+\t  typename _R = __intrinsic_type_t<typename _TVT::value_type, _TVT::_S_full_size>>\n   _GLIBCXX_SIMD_INTRINSIC constexpr _R\n   __to_intrin(_Tp __x)\n   {\n@@ -1792,9 +1791,7 @@ template <typename _Tp, typename _TVT = _VectorTraits<_Tp>,\n template <typename _Tp, typename... _Args>\n   _GLIBCXX_SIMD_INTRINSIC constexpr __vector_type_t<_Tp, sizeof...(_Args)>\n   __make_vector(const _Args&... __args)\n-  {\n-    return __vector_type_t<_Tp, sizeof...(_Args)>{static_cast<_Tp>(__args)...};\n-  }\n+  { return __vector_type_t<_Tp, sizeof...(_Args)>{static_cast<_Tp>(__args)...}; }\n \n // }}}\n // __vector_broadcast{{{\n@@ -1813,10 +1810,7 @@ template <size_t _Np, typename _Tp>\n   template <typename _Tp, size_t _Np, typename _Gp, size_t... _I>\n   _GLIBCXX_SIMD_INTRINSIC constexpr __vector_type_t<_Tp, _Np>\n   __generate_vector_impl(_Gp&& __gen, index_sequence<_I...>)\n-  {\n-    return __vector_type_t<_Tp, _Np>{\n-      static_cast<_Tp>(__gen(_SizeConstant<_I>()))...};\n-  }\n+  { return __vector_type_t<_Tp, _Np>{ static_cast<_Tp>(__gen(_SizeConstant<_I>()))...}; }\n \n template <typename _V, typename _VVT = _VectorTraits<_V>, typename _Gp>\n   _GLIBCXX_SIMD_INTRINSIC constexpr _V\n@@ -2029,8 +2023,7 @@ template <typename _Tp, typename _TVT = _VectorTraits<_Tp>>\n // }}}\n // __concat{{{\n template <typename _Tp, typename _TVT = _VectorTraits<_Tp>,\n-\t  typename _R = __vector_type_t<typename _TVT::value_type,\n-\t\t\t\t\t_TVT::_S_full_size * 2>>\n+\t  typename _R = __vector_type_t<typename _TVT::value_type, _TVT::_S_full_size * 2>>\n   constexpr _R\n   __concat(_Tp a_, _Tp b_)\n   {\n@@ -2174,8 +2167,7 @@ template <int _Offset,\n \t  int _SplitBy,\n \t  typename _Tp,\n \t  typename _TVT = _VectorTraits<_Tp>,\n-\t  typename _R = __vector_type_t<typename _TVT::value_type,\n-\t\t\t  _TVT::_S_full_size / _SplitBy>>\n+\t  typename _R = __vector_type_t<typename _TVT::value_type, _TVT::_S_full_size / _SplitBy>>\n   _GLIBCXX_SIMD_INTRINSIC constexpr _R\n   __extract(_Tp __in)\n   {\n@@ -2221,8 +2213,7 @@ template <int _Offset,\n // }}}\n // __lo/__hi64[z]{{{\n template <typename _Tp,\n-\t  typename _R\n-\t  = __vector_type8_t<typename _VectorTraits<_Tp>::value_type>>\n+\t  typename _R = __vector_type8_t<typename _VectorTraits<_Tp>::value_type>>\n   _GLIBCXX_SIMD_INTRINSIC constexpr _R\n   __lo64(_Tp __x)\n   {\n@@ -2232,8 +2223,7 @@ template <typename _Tp,\n   }\n \n template <typename _Tp,\n-\t  typename _R\n-\t  = __vector_type8_t<typename _VectorTraits<_Tp>::value_type>>\n+\t  typename _R = __vector_type8_t<typename _VectorTraits<_Tp>::value_type>>\n   _GLIBCXX_SIMD_INTRINSIC constexpr _R\n   __hi64(_Tp __x)\n   {\n@@ -2244,8 +2234,7 @@ template <typename _Tp,\n   }\n \n template <typename _Tp,\n-\t  typename _R\n-\t  = __vector_type8_t<typename _VectorTraits<_Tp>::value_type>>\n+\t  typename _R = __vector_type8_t<typename _VectorTraits<_Tp>::value_type>>\n   _GLIBCXX_SIMD_INTRINSIC constexpr _R\n   __hi64z([[maybe_unused]] _Tp __x)\n   {\n@@ -2356,18 +2345,15 @@ template <>\n // the following excludes bool via __is_vectorizable\n #if _GLIBCXX_SIMD_HAVE_SSE\n template <typename _Tp, size_t _Bytes>\n-  struct __intrinsic_type<_Tp, _Bytes,\n-\t\t\t  enable_if_t<__is_vectorizable_v<_Tp> && _Bytes <= 64>>\n+  struct __intrinsic_type<_Tp, _Bytes, enable_if_t<__is_vectorizable_v<_Tp> && _Bytes <= 64>>\n   {\n     static_assert(!is_same_v<_Tp, long double>,\n \t\t  \"no __intrinsic_type support for long double on x86\");\n \n-    static constexpr size_t _S_VBytes = _Bytes <= 16   ? 16\n-\t\t\t\t\t: _Bytes <= 32 ? 32\n-\t\t\t\t\t\t       : 64;\n+    static constexpr size_t _S_VBytes = _Bytes <= 16 ? 16 : _Bytes <= 32 ? 32 : 64;\n \n     using type [[__gnu__::__vector_size__(_S_VBytes)]]\n-    = conditional_t<is_integral_v<_Tp>, long long int, _Tp>;\n+      = conditional_t<is_integral_v<_Tp>, long long int, _Tp>;\n   };\n #endif // _GLIBCXX_SIMD_HAVE_SSE\n \n@@ -2413,16 +2399,19 @@ _GLIBCXX_SIMD_ARM_INTRIN(64, 2);\n #undef _GLIBCXX_SIMD_ARM_INTRIN\n \n template <typename _Tp, size_t _Bytes>\n-  struct __intrinsic_type<_Tp, _Bytes,\n-\t\t\t  enable_if_t<__is_vectorizable_v<_Tp> && _Bytes <= 16>>\n+  struct __intrinsic_type<_Tp, _Bytes, enable_if_t<__is_vectorizable_v<_Tp> && _Bytes <= 16>>\n   {\n     static constexpr int _SVecBytes = _Bytes <= 8 ? 8 : 16;\n+\n     using _Ip = __int_for_sizeof_t<_Tp>;\n+\n     using _Up = conditional_t<\n       is_floating_point_v<_Tp>, _Tp,\n       conditional_t<is_unsigned_v<_Tp>, make_unsigned_t<_Ip>, _Ip>>;\n+\n     static_assert(!is_same_v<_Tp, _Up> || _SVecBytes != _Bytes,\n \t\t  \"should use explicit specialization above\");\n+\n     using type = typename __intrinsic_type<_Up, _SVecBytes>::type;\n   };\n #endif // _GLIBCXX_SIMD_HAVE_NEON\n@@ -2457,18 +2446,20 @@ _GLIBCXX_SIMD_PPC_INTRIN(unsigned long long);\n #undef _GLIBCXX_SIMD_PPC_INTRIN\n \n template <typename _Tp, size_t _Bytes>\n-  struct __intrinsic_type<_Tp, _Bytes,\n-\t\t\t  enable_if_t<__is_vectorizable_v<_Tp> && _Bytes <= 16>>\n+  struct __intrinsic_type<_Tp, _Bytes, enable_if_t<__is_vectorizable_v<_Tp> && _Bytes <= 16>>\n   {\n     static constexpr bool _S_is_ldouble = is_same_v<_Tp, long double>;\n+\n     // allow _Tp == long double with -mlong-double-64\n     static_assert(!(_S_is_ldouble && sizeof(long double) > sizeof(double)),\n \t\t  \"no __intrinsic_type support for 128-bit floating point on PowerPC\");\n+\n #ifndef __VSX__\n     static_assert(!(is_same_v<_Tp, double>\n \t\t    || (_S_is_ldouble && sizeof(long double) == sizeof(double))),\n \t\t  \"no __intrinsic_type support for 64-bit floating point on PowerPC w/o VSX\");\n #endif\n+\n     using type =\n       typename __intrinsic_type_impl<\n \t\t conditional_t<is_floating_point_v<_Tp>,\n@@ -2489,42 +2480,51 @@ template <size_t _Width>\n     static constexpr size_t _S_full_size = sizeof(_BuiltinType) * __CHAR_BIT__;\n \n     _GLIBCXX_SIMD_INTRINSIC constexpr _SimdWrapper<bool, _S_full_size>\n-    __as_full_vector() const { return _M_data; }\n+    __as_full_vector() const\n+    { return _M_data; }\n+\n+    _GLIBCXX_SIMD_INTRINSIC constexpr\n+    _SimdWrapper() = default;\n \n-    _GLIBCXX_SIMD_INTRINSIC constexpr _SimdWrapper() = default;\n-    _GLIBCXX_SIMD_INTRINSIC constexpr _SimdWrapper(_BuiltinType __k)\n-      : _M_data(__k) {};\n+    _GLIBCXX_SIMD_INTRINSIC constexpr\n+    _SimdWrapper(_BuiltinType __k) : _M_data(__k) {};\n \n-    _GLIBCXX_SIMD_INTRINSIC operator const _BuiltinType&() const\n+    _GLIBCXX_SIMD_INTRINSIC\n+    operator const _BuiltinType&() const\n     { return _M_data; }\n \n-    _GLIBCXX_SIMD_INTRINSIC operator _BuiltinType&()\n+    _GLIBCXX_SIMD_INTRINSIC\n+    operator _BuiltinType&()\n     { return _M_data; }\n \n-    _GLIBCXX_SIMD_INTRINSIC _BuiltinType __intrin() const\n+    _GLIBCXX_SIMD_INTRINSIC _BuiltinType\n+    __intrin() const\n     { return _M_data; }\n \n-    _GLIBCXX_SIMD_INTRINSIC constexpr value_type operator[](size_t __i) const\n+    _GLIBCXX_SIMD_INTRINSIC constexpr value_type\n+    operator[](size_t __i) const\n     { return _M_data & (_BuiltinType(1) << __i); }\n \n     template <size_t __i>\n       _GLIBCXX_SIMD_INTRINSIC constexpr value_type\n       operator[](_SizeConstant<__i>) const\n       { return _M_data & (_BuiltinType(1) << __i); }\n \n-    _GLIBCXX_SIMD_INTRINSIC constexpr void _M_set(size_t __i, value_type __x)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr void\n+    _M_set(size_t __i, value_type __x)\n     {\n       if (__x)\n \t_M_data |= (_BuiltinType(1) << __i);\n       else\n \t_M_data &= ~(_BuiltinType(1) << __i);\n     }\n \n-    _GLIBCXX_SIMD_INTRINSIC\n-    constexpr bool _M_is_constprop() const\n+    _GLIBCXX_SIMD_INTRINSIC constexpr bool\n+    _M_is_constprop() const\n     { return __builtin_constant_p(_M_data); }\n \n-    _GLIBCXX_SIMD_INTRINSIC constexpr bool _M_is_constprop_none_of() const\n+    _GLIBCXX_SIMD_INTRINSIC constexpr bool\n+    _M_is_constprop_none_of() const\n     {\n       if (__builtin_constant_p(_M_data))\n \t{\n@@ -2536,7 +2536,8 @@ template <size_t _Width>\n       return false;\n     }\n \n-    _GLIBCXX_SIMD_INTRINSIC constexpr bool _M_is_constprop_all_of() const\n+    _GLIBCXX_SIMD_INTRINSIC constexpr bool\n+    _M_is_constprop_all_of() const\n     {\n       if (__builtin_constant_p(_M_data))\n \t{\n@@ -2558,10 +2559,11 @@ template <bool _MustZeroInitPadding, typename _BuiltinType>\n template <typename _BuiltinType>\n   struct _SimdWrapperBase<false, _BuiltinType> // no padding or no SNaNs\n   {\n-    _GLIBCXX_SIMD_INTRINSIC constexpr _SimdWrapperBase() = default;\n-    _GLIBCXX_SIMD_INTRINSIC constexpr _SimdWrapperBase(_BuiltinType __init)\n-      : _M_data(__init)\n-    {}\n+    _GLIBCXX_SIMD_INTRINSIC constexpr\n+    _SimdWrapperBase() = default;\n+\n+    _GLIBCXX_SIMD_INTRINSIC constexpr\n+    _SimdWrapperBase(_BuiltinType __init) : _M_data(__init) {}\n \n     _BuiltinType _M_data;\n   };\n@@ -2570,10 +2572,11 @@ template <typename _BuiltinType>\n   struct _SimdWrapperBase<true, _BuiltinType> // with padding that needs to\n \t\t\t\t\t      // never become SNaN\n   {\n-    _GLIBCXX_SIMD_INTRINSIC constexpr _SimdWrapperBase() : _M_data() {}\n-    _GLIBCXX_SIMD_INTRINSIC constexpr _SimdWrapperBase(_BuiltinType __init)\n-      : _M_data(__init)\n-    {}\n+    _GLIBCXX_SIMD_INTRINSIC constexpr\n+    _SimdWrapperBase() : _M_data() {}\n+\n+    _GLIBCXX_SIMD_INTRINSIC constexpr\n+    _SimdWrapperBase(_BuiltinType __init) : _M_data(__init) {}\n \n     _BuiltinType _M_data;\n   };\n@@ -2612,24 +2615,33 @@ template <typename _Tp, size_t _Width>\n     __as_full_vector() const\n     { return _M_data; }\n \n-    _GLIBCXX_SIMD_INTRINSIC constexpr _SimdWrapper(initializer_list<_Tp> __init)\n-      : _Base(__generate_from_n_evaluations<_Width, _BuiltinType>(\n-\t[&](auto __i) _GLIBCXX_SIMD_ALWAYS_INLINE_LAMBDA { return __init.begin()[__i.value]; })) {}\n+    _GLIBCXX_SIMD_INTRINSIC constexpr\n+    _SimdWrapper(initializer_list<_Tp> __init)\n+    : _Base(__generate_from_n_evaluations<_Width, _BuiltinType>(\n+\t      [&](auto __i) _GLIBCXX_SIMD_ALWAYS_INLINE_LAMBDA {\n+\t\treturn __init.begin()[__i.value];\n+\t      })) {}\n \n-    _GLIBCXX_SIMD_INTRINSIC constexpr _SimdWrapper() = default;\n-    _GLIBCXX_SIMD_INTRINSIC constexpr _SimdWrapper(const _SimdWrapper&)\n-      = default;\n-    _GLIBCXX_SIMD_INTRINSIC constexpr _SimdWrapper(_SimdWrapper&&) = default;\n+    _GLIBCXX_SIMD_INTRINSIC constexpr\n+    _SimdWrapper() = default;\n+\n+    _GLIBCXX_SIMD_INTRINSIC constexpr\n+    _SimdWrapper(const _SimdWrapper&) = default;\n+\n+    _GLIBCXX_SIMD_INTRINSIC constexpr\n+    _SimdWrapper(_SimdWrapper&&) = default;\n \n     _GLIBCXX_SIMD_INTRINSIC constexpr _SimdWrapper&\n     operator=(const _SimdWrapper&) = default;\n+\n     _GLIBCXX_SIMD_INTRINSIC constexpr _SimdWrapper&\n     operator=(_SimdWrapper&&) = default;\n \n     template <typename _V, typename = enable_if_t<disjunction_v<\n \t\t\t     is_same<_V, __vector_type_t<_Tp, _Width>>,\n \t\t\t     is_same<_V, __intrinsic_type_t<_Tp, _Width>>>>>\n-      _GLIBCXX_SIMD_INTRINSIC constexpr _SimdWrapper(_V __x)\n+      _GLIBCXX_SIMD_INTRINSIC constexpr\n+      _SimdWrapper(_V __x)\n       // __vector_bitcast can convert e.g. __m128 to __vector(2) float\n       : _Base(__vector_bitcast<_Tp, _Width>(__x)) {}\n \n@@ -2644,27 +2656,34 @@ template <typename _Tp, size_t _Width>\n \t\t { return _M_data[int(__i)]; });\n       }\n \n-    _GLIBCXX_SIMD_INTRINSIC constexpr operator const _BuiltinType&() const\n+    _GLIBCXX_SIMD_INTRINSIC constexpr\n+    operator const _BuiltinType&() const\n     { return _M_data; }\n \n-    _GLIBCXX_SIMD_INTRINSIC constexpr operator _BuiltinType&()\n+    _GLIBCXX_SIMD_INTRINSIC constexpr\n+    operator _BuiltinType&()\n     { return _M_data; }\n \n-    _GLIBCXX_SIMD_INTRINSIC constexpr _Tp operator[](size_t __i) const\n+    _GLIBCXX_SIMD_INTRINSIC constexpr _Tp\n+    operator[](size_t __i) const\n     { return _M_data[__i]; }\n \n     template <size_t __i>\n-      _GLIBCXX_SIMD_INTRINSIC constexpr _Tp operator[](_SizeConstant<__i>) const\n+      _GLIBCXX_SIMD_INTRINSIC constexpr _Tp\n+      operator[](_SizeConstant<__i>) const\n       { return _M_data[__i]; }\n \n-    _GLIBCXX_SIMD_INTRINSIC constexpr void _M_set(size_t __i, _Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr void\n+    _M_set(size_t __i, _Tp __x)\n     { _M_data[__i] = __x; }\n \n     _GLIBCXX_SIMD_INTRINSIC\n-    constexpr bool _M_is_constprop() const\n+    constexpr bool\n+    _M_is_constprop() const\n     { return __builtin_constant_p(_M_data); }\n \n-    _GLIBCXX_SIMD_INTRINSIC constexpr bool _M_is_constprop_none_of() const\n+    _GLIBCXX_SIMD_INTRINSIC constexpr bool\n+    _M_is_constprop_none_of() const\n     {\n       if (__builtin_constant_p(_M_data))\n \t{\n@@ -2685,7 +2704,8 @@ template <typename _Tp, size_t _Width>\n       return false;\n     }\n \n-    _GLIBCXX_SIMD_INTRINSIC constexpr bool _M_is_constprop_all_of() const\n+    _GLIBCXX_SIMD_INTRINSIC constexpr bool\n+    _M_is_constprop_all_of() const\n     {\n       if (__builtin_constant_p(_M_data))\n \t{\n@@ -2883,22 +2903,14 @@ template <typename _Tp, typename _V, typename = void>\n   struct rebind_simd;\n \n template <typename _Tp, typename _Up, typename _Abi>\n-  struct rebind_simd<\n-    _Tp, simd<_Up, _Abi>,\n-    void_t<simd_abi::deduce_t<_Tp, simd_size_v<_Up, _Abi>, _Abi>>>\n-  {\n-    using type\n-      = simd<_Tp, simd_abi::deduce_t<_Tp, simd_size_v<_Up, _Abi>, _Abi>>;\n-  };\n+  struct rebind_simd<_Tp, simd<_Up, _Abi>,\n+\t\t     void_t<simd_abi::deduce_t<_Tp, simd_size_v<_Up, _Abi>, _Abi>>>\n+  { using type = simd<_Tp, simd_abi::deduce_t<_Tp, simd_size_v<_Up, _Abi>, _Abi>>; };\n \n template <typename _Tp, typename _Up, typename _Abi>\n-  struct rebind_simd<\n-    _Tp, simd_mask<_Up, _Abi>,\n-    void_t<simd_abi::deduce_t<_Tp, simd_size_v<_Up, _Abi>, _Abi>>>\n-  {\n-    using type\n-      = simd_mask<_Tp, simd_abi::deduce_t<_Tp, simd_size_v<_Up, _Abi>, _Abi>>;\n-  };\n+  struct rebind_simd<_Tp, simd_mask<_Up, _Abi>,\n+\t\t     void_t<simd_abi::deduce_t<_Tp, simd_size_v<_Up, _Abi>, _Abi>>>\n+  { using type = simd_mask<_Tp, simd_abi::deduce_t<_Tp, simd_size_v<_Up, _Abi>, _Abi>>; };\n \n template <typename _Tp, typename _V>\n   using rebind_simd_t = typename rebind_simd<_Tp, _V>::type;\n@@ -2908,13 +2920,11 @@ template <int _Np, typename _V, typename = void>\n   struct resize_simd;\n \n template <int _Np, typename _Tp, typename _Abi>\n-  struct resize_simd<_Np, simd<_Tp, _Abi>,\n-\t\t     void_t<simd_abi::deduce_t<_Tp, _Np, _Abi>>>\n+  struct resize_simd<_Np, simd<_Tp, _Abi>, void_t<simd_abi::deduce_t<_Tp, _Np, _Abi>>>\n   { using type = simd<_Tp, simd_abi::deduce_t<_Tp, _Np, _Abi>>; };\n \n template <int _Np, typename _Tp, typename _Abi>\n-  struct resize_simd<_Np, simd_mask<_Tp, _Abi>,\n-\t\t     void_t<simd_abi::deduce_t<_Tp, _Np, _Abi>>>\n+  struct resize_simd<_Np, simd_mask<_Tp, _Abi>, void_t<simd_abi::deduce_t<_Tp, _Np, _Abi>>>\n   { using type = simd_mask<_Tp, simd_abi::deduce_t<_Tp, _Np, _Abi>>; };\n \n template <int _Np, typename _V>\n@@ -2963,13 +2973,11 @@ template <typename _Tp, size_t _Np>\n \n // casts [simd.casts] {{{1\n // static_simd_cast {{{2\n-template <typename _Tp, typename _Up, typename _Ap, bool = is_simd_v<_Tp>,\n-\t  typename = void>\n+template <typename _Tp, typename _Up, typename _Ap, bool = is_simd_v<_Tp>, typename = void>\n   struct __static_simd_cast_return_type;\n \n template <typename _Tp, typename _A0, typename _Up, typename _Ap>\n-  struct __static_simd_cast_return_type<simd_mask<_Tp, _A0>, _Up, _Ap, false,\n-\t\t\t\t\tvoid>\n+  struct __static_simd_cast_return_type<simd_mask<_Tp, _A0>, _Up, _Ap, false, void>\n   : __static_simd_cast_return_type<simd<_Tp, _A0>, _Up, _Ap> {};\n \n template <typename _Tp, typename _Up, typename _Ap>\n@@ -3284,6 +3292,7 @@ template <typename _M, typename _Tp>\n \n   public:\n     const_where_expression(const const_where_expression&) = delete;\n+\n     const_where_expression& operator=(const const_where_expression&) = delete;\n \n     _GLIBCXX_SIMD_INTRINSIC const_where_expression(const _M& __kk, const _Tp& dd)\n@@ -3328,8 +3337,8 @@ template <typename _Tp>\n     struct _Wrapper { using value_type = _V; };\n \n   protected:\n-    using value_type =\n-      typename conditional_t<is_arithmetic_v<_V>, _Wrapper, _V>::value_type;\n+    using value_type\n+      = typename conditional_t<is_arithmetic_v<_V>, _Wrapper, _V>::value_type;\n \n     _GLIBCXX_SIMD_INTRINSIC friend const _M&\n     __get_mask(const const_where_expression& __x)\n@@ -3426,48 +3435,48 @@ template <typename _M, typename _Tp>\n     _GLIBCXX_SIMD_OP_(>>, _S_shift_right);\n #undef _GLIBCXX_SIMD_OP_\n \n-    _GLIBCXX_SIMD_INTRINSIC void operator++() &&\n+    _GLIBCXX_SIMD_INTRINSIC void\n+    operator++() &&\n     {\n       __data(_M_value)\n-\t= _Impl::template _S_masked_unary<__increment>(__data(_M_k),\n-\t\t\t\t\t\t       __data(_M_value));\n+\t= _Impl::template _S_masked_unary<__increment>(__data(_M_k), __data(_M_value));\n     }\n \n-    _GLIBCXX_SIMD_INTRINSIC void operator++(int) &&\n+    _GLIBCXX_SIMD_INTRINSIC void\n+    operator++(int) &&\n     {\n       __data(_M_value)\n-\t= _Impl::template _S_masked_unary<__increment>(__data(_M_k),\n-\t\t\t\t\t\t       __data(_M_value));\n+\t= _Impl::template _S_masked_unary<__increment>(__data(_M_k), __data(_M_value));\n     }\n \n-    _GLIBCXX_SIMD_INTRINSIC void operator--() &&\n+    _GLIBCXX_SIMD_INTRINSIC void\n+    operator--() &&\n     {\n       __data(_M_value)\n-\t= _Impl::template _S_masked_unary<__decrement>(__data(_M_k),\n-\t\t\t\t\t\t       __data(_M_value));\n+\t= _Impl::template _S_masked_unary<__decrement>(__data(_M_k), __data(_M_value));\n     }\n \n-    _GLIBCXX_SIMD_INTRINSIC void operator--(int) &&\n+    _GLIBCXX_SIMD_INTRINSIC void\n+    operator--(int) &&\n     {\n       __data(_M_value)\n-\t= _Impl::template _S_masked_unary<__decrement>(__data(_M_k),\n-\t\t\t\t\t\t       __data(_M_value));\n+\t= _Impl::template _S_masked_unary<__decrement>(__data(_M_k), __data(_M_value));\n     }\n \n     // intentionally hides const_where_expression::copy_from\n     template <typename _Up, typename _Flags>\n       _GLIBCXX_SIMD_INTRINSIC void\n       copy_from(const _LoadStorePtr<_Up, value_type>* __mem, _Flags) &&\n       {\n-\t__data(_M_value)\n-\t  = _Impl::_S_masked_load(__data(_M_value), __data(_M_k),\n-\t\t\t\t  _Flags::template _S_apply<_Tp>(__mem));\n+\t__data(_M_value) = _Impl::_S_masked_load(__data(_M_value), __data(_M_k),\n+\t\t\t\t\t\t _Flags::template _S_apply<_Tp>(__mem));\n       }\n   };\n \n // where_expression<bool, T> {{{2\n template <typename _Tp>\n-  class where_expression<bool, _Tp> : public const_where_expression<bool, _Tp>\n+  class where_expression<bool, _Tp>\n+  : public const_where_expression<bool, _Tp>\n   {\n     using _M = bool;\n     using typename const_where_expression<_M, _Tp>::value_type;\n@@ -3478,12 +3487,14 @@ template <typename _Tp>\n     where_expression(const where_expression&) = delete;\n     where_expression& operator=(const where_expression&) = delete;\n \n-    _GLIBCXX_SIMD_INTRINSIC where_expression(const _M& __kk, _Tp& dd)\n-      : const_where_expression<_M, _Tp>(__kk, dd) {}\n+    _GLIBCXX_SIMD_INTRINSIC\n+    where_expression(const _M& __kk, _Tp& dd)\n+    : const_where_expression<_M, _Tp>(__kk, dd) {}\n \n #define _GLIBCXX_SIMD_OP_(__op)                                                \\\n     template <typename _Up>                                                    \\\n-      _GLIBCXX_SIMD_INTRINSIC void operator __op(_Up&& __x)&&                  \\\n+      _GLIBCXX_SIMD_INTRINSIC void                                             \\\n+      operator __op(_Up&& __x)&&                                               \\\n       { if (_M_k) _M_value __op static_cast<_Up&&>(__x); }\n \n     _GLIBCXX_SIMD_OP_(=)\n@@ -3499,16 +3510,20 @@ template <typename _Tp>\n     _GLIBCXX_SIMD_OP_(>>=)\n   #undef _GLIBCXX_SIMD_OP_\n \n-    _GLIBCXX_SIMD_INTRINSIC void operator++() &&\n+    _GLIBCXX_SIMD_INTRINSIC void\n+    operator++() &&\n     { if (_M_k) ++_M_value; }\n \n-    _GLIBCXX_SIMD_INTRINSIC void operator++(int) &&\n+    _GLIBCXX_SIMD_INTRINSIC void\n+    operator++(int) &&\n     { if (_M_k) ++_M_value; }\n \n-    _GLIBCXX_SIMD_INTRINSIC void operator--() &&\n+    _GLIBCXX_SIMD_INTRINSIC void\n+    operator--() &&\n     { if (_M_k) --_M_value; }\n \n-    _GLIBCXX_SIMD_INTRINSIC void operator--(int) &&\n+    _GLIBCXX_SIMD_INTRINSIC void\n+    operator--(int) &&\n     { if (_M_k) --_M_value; }\n \n     // intentionally hides const_where_expression::copy_from\n@@ -3526,23 +3541,20 @@ template <typename _Tp, typename _Ap>\n \n template <typename _Tp, typename _Ap>\n   _GLIBCXX_SIMD_INTRINSIC\n-    const_where_expression<simd_mask<_Tp, _Ap>, simd<_Tp, _Ap>>\n-    where(const typename simd<_Tp, _Ap>::mask_type& __k,\n-\t  const simd<_Tp, _Ap>& __value)\n+  const_where_expression<simd_mask<_Tp, _Ap>, simd<_Tp, _Ap>>\n+  where(const typename simd<_Tp, _Ap>::mask_type& __k, const simd<_Tp, _Ap>& __value)\n   { return {__k, __value}; }\n \n template <typename _Tp, typename _Ap>\n   _GLIBCXX_SIMD_INTRINSIC\n-    where_expression<simd_mask<_Tp, _Ap>, simd_mask<_Tp, _Ap>>\n-    where(const remove_const_t<simd_mask<_Tp, _Ap>>& __k,\n-\t  simd_mask<_Tp, _Ap>& __value)\n+  where_expression<simd_mask<_Tp, _Ap>, simd_mask<_Tp, _Ap>>\n+  where(const remove_const_t<simd_mask<_Tp, _Ap>>& __k, simd_mask<_Tp, _Ap>& __value)\n   { return {__k, __value}; }\n \n template <typename _Tp, typename _Ap>\n   _GLIBCXX_SIMD_INTRINSIC\n-    const_where_expression<simd_mask<_Tp, _Ap>, simd_mask<_Tp, _Ap>>\n-    where(const remove_const_t<simd_mask<_Tp, _Ap>>& __k,\n-\t  const simd_mask<_Tp, _Ap>& __value)\n+  const_where_expression<simd_mask<_Tp, _Ap>, simd_mask<_Tp, _Ap>>\n+  where(const remove_const_t<simd_mask<_Tp, _Ap>>& __k, const simd_mask<_Tp, _Ap>& __value)\n   { return {__k, __value}; }\n \n template <typename _Tp>\n@@ -3555,11 +3567,11 @@ template <typename _Tp>\n   where(_ExactBool __k, const _Tp& __value)\n   { return {__k, __value}; }\n \n-  template <typename _Tp, typename _Ap>\n-    void where(bool __k, simd<_Tp, _Ap>& __value) = delete;\n+template <typename _Tp, typename _Ap>\n+  void where(bool __k, simd<_Tp, _Ap>& __value) = delete;\n \n-  template <typename _Tp, typename _Ap>\n-    void where(bool __k, const simd<_Tp, _Ap>& __value) = delete;\n+template <typename _Tp, typename _Ap>\n+  void where(bool __k, const simd<_Tp, _Ap>& __value) = delete;\n \n // proposed mask iterations {{{1\n namespace __proposed {\n@@ -3576,10 +3588,12 @@ template <size_t _Np>\n       size_t __mask;\n       size_t __bit;\n \n-      _GLIBCXX_SIMD_INTRINSIC void __next_bit()\n+      _GLIBCXX_SIMD_INTRINSIC void\n+      __next_bit()\n       { __bit = __builtin_ctzl(__mask); }\n \n-      _GLIBCXX_SIMD_INTRINSIC void __reset_lsb()\n+      _GLIBCXX_SIMD_INTRINSIC void\n+      __reset_lsb()\n       {\n \t// 01100100 - 1 = 01100011\n \t__mask &= (__mask - 1);\n@@ -3591,38 +3605,46 @@ template <size_t _Np>\n       iterator(const iterator&) = default;\n       iterator(iterator&&) = default;\n \n-      _GLIBCXX_SIMD_ALWAYS_INLINE size_t operator->() const\n+      _GLIBCXX_SIMD_ALWAYS_INLINE size_t\n+      operator->() const\n       { return __bit; }\n \n-      _GLIBCXX_SIMD_ALWAYS_INLINE size_t operator*() const\n+      _GLIBCXX_SIMD_ALWAYS_INLINE size_t\n+      operator*() const\n       { return __bit; }\n \n-      _GLIBCXX_SIMD_ALWAYS_INLINE iterator& operator++()\n+      _GLIBCXX_SIMD_ALWAYS_INLINE iterator&\n+      operator++()\n       {\n \t__reset_lsb();\n \t__next_bit();\n \treturn *this;\n       }\n \n-      _GLIBCXX_SIMD_ALWAYS_INLINE iterator operator++(int)\n+      _GLIBCXX_SIMD_ALWAYS_INLINE iterator\n+      operator++(int)\n       {\n \titerator __tmp = *this;\n \t__reset_lsb();\n \t__next_bit();\n \treturn __tmp;\n       }\n \n-      _GLIBCXX_SIMD_ALWAYS_INLINE bool operator==(const iterator& __rhs) const\n+      _GLIBCXX_SIMD_ALWAYS_INLINE bool\n+      operator==(const iterator& __rhs) const\n       { return __mask == __rhs.__mask; }\n \n-      _GLIBCXX_SIMD_ALWAYS_INLINE bool operator!=(const iterator& __rhs) const\n+      _GLIBCXX_SIMD_ALWAYS_INLINE bool\n+      operator!=(const iterator& __rhs) const\n       { return __mask != __rhs.__mask; }\n     };\n \n-    iterator begin() const\n+    iterator\n+    begin() const\n     { return __bits.to_ullong(); }\n \n-    iterator end() const\n+    iterator\n+    end() const\n     { return 0; }\n   };\n \n@@ -3637,15 +3659,13 @@ template <typename _Tp, typename _Ap>\n // reductions [simd.reductions] {{{1\n template <typename _Tp, typename _Abi, typename _BinaryOperation = plus<>>\n   _GLIBCXX_SIMD_INTRINSIC _GLIBCXX_SIMD_CONSTEXPR _Tp\n-  reduce(const simd<_Tp, _Abi>& __v,\n-\t _BinaryOperation __binary_op = _BinaryOperation())\n+  reduce(const simd<_Tp, _Abi>& __v, _BinaryOperation __binary_op = _BinaryOperation())\n   { return _Abi::_SimdImpl::_S_reduce(__v, __binary_op); }\n \n template <typename _M, typename _V, typename _BinaryOperation = plus<>>\n   _GLIBCXX_SIMD_INTRINSIC typename _V::value_type\n   reduce(const const_where_expression<_M, _V>& __x,\n-\t typename _V::value_type __identity_element,\n-\t _BinaryOperation __binary_op)\n+\t typename _V::value_type __identity_element, _BinaryOperation __binary_op)\n   {\n     if (__builtin_expect(none_of(__get_mask(__x)), false))\n       return __identity_element;\n@@ -3684,16 +3704,12 @@ template <typename _M, typename _V>\n template <typename _Tp, typename _Abi>\n   _GLIBCXX_SIMD_INTRINSIC _GLIBCXX_SIMD_CONSTEXPR _Tp\n   hmin(const simd<_Tp, _Abi>& __v) noexcept\n-  {\n-    return _Abi::_SimdImpl::_S_reduce(__v, __detail::_Minimum());\n-  }\n+  { return _Abi::_SimdImpl::_S_reduce(__v, __detail::_Minimum()); }\n \n template <typename _Tp, typename _Abi>\n   _GLIBCXX_SIMD_INTRINSIC _GLIBCXX_SIMD_CONSTEXPR _Tp\n   hmax(const simd<_Tp, _Abi>& __v) noexcept\n-  {\n-    return _Abi::_SimdImpl::_S_reduce(__v, __detail::_Maximum());\n-  }\n+  { return _Abi::_SimdImpl::_S_reduce(__v, __detail::_Maximum()); }\n \n template <typename _M, typename _V>\n   _GLIBCXX_SIMD_INTRINSIC _GLIBCXX_SIMD_CONSTEXPR\n@@ -3761,8 +3777,7 @@ template <typename _Tp, typename _Ap>\n \n template <typename _Tp, typename _Ap>\n   _GLIBCXX_SIMD_INTRINSIC _GLIBCXX_SIMD_CONSTEXPR simd<_Tp, _Ap>\n-  clamp(const simd<_Tp, _Ap>& __v, const simd<_Tp, _Ap>& __lo,\n-\tconst simd<_Tp, _Ap>& __hi)\n+  clamp(const simd<_Tp, _Ap>& __v, const simd<_Tp, _Ap>& __lo, const simd<_Tp, _Ap>& __hi)\n   {\n     using _Impl = typename _Ap::_SimdImpl;\n     return {__private_init,\n@@ -3783,8 +3798,7 @@ template <int _Index, int _Total, int _Combine = 1, typename _Tp, size_t _Np>\n   _SimdWrapper<_Tp, _Np / _Total * _Combine>\n   __extract_part(const _SimdWrapper<_Tp, _Np> __x);\n \n-template <int _Index, int _Parts, int _Combine = 1, typename _Tp, typename _A0,\n-\t  typename... _As>\n+template <int _Index, int _Parts, int _Combine = 1, typename _Tp, typename _A0, typename... _As>\n   _GLIBCXX_SIMD_INTRINSIC auto\n   __extract_part(const _SimdTuple<_Tp, _A0, _As...>& __x);\n \n@@ -3794,7 +3808,8 @@ template <size_t _V0, size_t... _Values>\n   struct _SizeList\n   {\n     template <size_t _I>\n-      static constexpr size_t _S_at(_SizeConstant<_I> = {})\n+      static constexpr size_t\n+      _S_at(_SizeConstant<_I> = {})\n       {\n \tif constexpr (_I == 0)\n \t  return _V0;\n@@ -3803,7 +3818,8 @@ template <size_t _V0, size_t... _Values>\n       }\n \n     template <size_t _I>\n-      static constexpr auto _S_before(_SizeConstant<_I> = {})\n+      static constexpr auto\n+      _S_before(_SizeConstant<_I> = {})\n       {\n \tif constexpr (_I == 0)\n \t  return _SizeConstant<0>();\n@@ -3813,7 +3829,8 @@ template <size_t _V0, size_t... _Values>\n       }\n \n     template <size_t _Np>\n-      static constexpr auto _S_pop_front(_SizeConstant<_Np> = {})\n+      static constexpr auto\n+      _S_pop_front(_SizeConstant<_Np> = {})\n       {\n \tif constexpr (_Np == 0)\n \t  return _SizeList();\n@@ -3965,8 +3982,7 @@ template <typename _V, typename _Ap,\n // }}}\n // split<simd_mask>(simd_mask) {{{\n template <typename _V, typename _Ap,\n-\t  size_t _Parts\n-\t  = simd_size_v<typename _V::simd_type::value_type, _Ap> / _V::size()>\n+\t  size_t _Parts = simd_size_v<typename _V::simd_type::value_type, _Ap> / _V::size()>\n   enable_if_t<is_simd_mask_v<_V> && simd_size_v<typename\n     _V::simd_type::value_type, _Ap> == _Parts * _V::size(), array<_V, _Parts>>\n   split(const simd_mask<typename _V::simd_type::value_type, _Ap>& __x)\n@@ -4131,8 +4147,7 @@ template <size_t _I, typename _Tp, typename _Ap, typename... _As>\n // __store_pack_of_simd {{{\n template <typename _Tp, typename _A0, typename... _As>\n   _GLIBCXX_SIMD_INTRINSIC void\n-  __store_pack_of_simd(char* __mem, const simd<_Tp, _A0>& __x0,\n-\t\t       const simd<_Tp, _As>&... __xs)\n+  __store_pack_of_simd(char* __mem, const simd<_Tp, _A0>& __x0, const simd<_Tp, _As>&... __xs)\n   {\n     constexpr size_t __n_bytes = sizeof(_Tp) * simd_size_v<_Tp, _A0>;\n     __builtin_memcpy(__mem, &__data(__x0), __n_bytes);\n@@ -4188,7 +4203,8 @@ template <typename _Up, typename _Accessor = _Up,\n     int _M_index;\n     _Up& _M_obj;\n \n-    _GLIBCXX_SIMD_INTRINSIC constexpr _ValueType _M_read() const noexcept\n+    _GLIBCXX_SIMD_INTRINSIC constexpr _ValueType\n+    _M_read() const noexcept\n     {\n       if constexpr (is_arithmetic_v<_Up>)\n \treturn _M_obj;\n@@ -4197,7 +4213,8 @@ template <typename _Up, typename _Accessor = _Up,\n     }\n \n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC constexpr void _M_write(_Tp&& __x) const\n+      _GLIBCXX_SIMD_INTRINSIC constexpr void\n+      _M_write(_Tp&& __x) const\n       { _Accessor::_S_set(_M_obj, _M_index, static_cast<_Tp&&>(__x)); }\n \n   public:\n@@ -4207,52 +4224,52 @@ template <typename _Up, typename _Accessor = _Up,\n \n     using value_type = _ValueType;\n \n-    _GLIBCXX_SIMD_INTRINSIC _SmartReference(const _SmartReference&) = delete;\n+    _GLIBCXX_SIMD_INTRINSIC\n+    _SmartReference(const _SmartReference&) = delete;\n \n-    _GLIBCXX_SIMD_INTRINSIC constexpr operator value_type() const noexcept\n+    _GLIBCXX_SIMD_INTRINSIC constexpr\n+    operator value_type() const noexcept\n     { return _M_read(); }\n \n-    template <typename _Tp,\n-\t      typename\n-\t      = _ValuePreservingOrInt<__remove_cvref_t<_Tp>, value_type>>\n-      _GLIBCXX_SIMD_INTRINSIC constexpr _SmartReference operator=(_Tp&& __x) &&\n+    template <typename _Tp, typename = _ValuePreservingOrInt<__remove_cvref_t<_Tp>, value_type>>\n+      _GLIBCXX_SIMD_INTRINSIC constexpr _SmartReference\n+      operator=(_Tp&& __x) &&\n       {\n \t_M_write(static_cast<_Tp&&>(__x));\n \treturn {_M_obj, _M_index};\n       }\n \n-#define _GLIBCXX_SIMD_OP_(__op)                                                \\\n-    template <typename _Tp,                                                    \\\n-\t      typename _TT                                                     \\\n-\t      = decltype(declval<value_type>() __op declval<_Tp>()),           \\\n-\t      typename = _ValuePreservingOrInt<__remove_cvref_t<_Tp>, _TT>,    \\\n-\t      typename = _ValuePreservingOrInt<_TT, value_type>>               \\\n-      _GLIBCXX_SIMD_INTRINSIC constexpr _SmartReference                        \\\n-      operator __op##=(_Tp&& __x) &&                                           \\\n-      {                                                                        \\\n-\tconst value_type& __lhs = _M_read();                                   \\\n-\t_M_write(__lhs __op __x);                                              \\\n-\treturn {_M_obj, _M_index};                                             \\\n+#define _GLIBCXX_SIMD_OP_(__op)                                                   \\\n+    template <typename _Tp,                                                       \\\n+\t      typename _TT = decltype(declval<value_type>() __op declval<_Tp>()), \\\n+\t      typename = _ValuePreservingOrInt<__remove_cvref_t<_Tp>, _TT>,       \\\n+\t      typename = _ValuePreservingOrInt<_TT, value_type>>                  \\\n+      _GLIBCXX_SIMD_INTRINSIC constexpr _SmartReference                           \\\n+      operator __op##=(_Tp&& __x) &&                                              \\\n+      {                                                                           \\\n+\tconst value_type& __lhs = _M_read();                                      \\\n+\t_M_write(__lhs __op __x);                                                 \\\n+\treturn {_M_obj, _M_index};                                                \\\n       }\n     _GLIBCXX_SIMD_ALL_ARITHMETICS(_GLIBCXX_SIMD_OP_);\n     _GLIBCXX_SIMD_ALL_SHIFTS(_GLIBCXX_SIMD_OP_);\n     _GLIBCXX_SIMD_ALL_BINARY(_GLIBCXX_SIMD_OP_);\n #undef _GLIBCXX_SIMD_OP_\n \n     template <typename _Tp = void,\n-\t      typename\n-\t      = decltype(++declval<conditional_t<true, value_type, _Tp>&>())>\n-      _GLIBCXX_SIMD_INTRINSIC constexpr _SmartReference operator++() &&\n+\t      typename = decltype(++declval<conditional_t<true, value_type, _Tp>&>())>\n+      _GLIBCXX_SIMD_INTRINSIC constexpr _SmartReference\n+      operator++() &&\n       {\n \tvalue_type __x = _M_read();\n \t_M_write(++__x);\n \treturn {_M_obj, _M_index};\n       }\n \n     template <typename _Tp = void,\n-\t      typename\n-\t      = decltype(declval<conditional_t<true, value_type, _Tp>&>()++)>\n-      _GLIBCXX_SIMD_INTRINSIC constexpr value_type operator++(int) &&\n+\t      typename = decltype(declval<conditional_t<true, value_type, _Tp>&>()++)>\n+      _GLIBCXX_SIMD_INTRINSIC constexpr value_type\n+      operator++(int) &&\n       {\n \tconst value_type __r = _M_read();\n \tvalue_type __x = __r;\n@@ -4261,19 +4278,19 @@ template <typename _Up, typename _Accessor = _Up,\n       }\n \n     template <typename _Tp = void,\n-\t      typename\n-\t      = decltype(--declval<conditional_t<true, value_type, _Tp>&>())>\n-      _GLIBCXX_SIMD_INTRINSIC constexpr _SmartReference operator--() &&\n+\t      typename = decltype(--declval<conditional_t<true, value_type, _Tp>&>())>\n+      _GLIBCXX_SIMD_INTRINSIC constexpr _SmartReference\n+      operator--() &&\n       {\n \tvalue_type __x = _M_read();\n \t_M_write(--__x);\n \treturn {_M_obj, _M_index};\n       }\n \n     template <typename _Tp = void,\n-\t      typename\n-\t      = decltype(declval<conditional_t<true, value_type, _Tp>&>()--)>\n-      _GLIBCXX_SIMD_INTRINSIC constexpr value_type operator--(int) &&\n+\t      typename = decltype(declval<conditional_t<true, value_type, _Tp>&>()--)>\n+      _GLIBCXX_SIMD_INTRINSIC constexpr value_type\n+      operator--(int) &&\n       {\n \tconst value_type __r = _M_read();\n \tvalue_type __x = __r;\n@@ -4349,7 +4366,8 @@ template <int _Bytes>\n template <template <int> class _Abi, int _Bytes, typename _Tp>\n   struct __find_next_valid_abi\n   {\n-    static constexpr auto _S_choose()\n+    static constexpr auto\n+    _S_choose()\n     {\n       constexpr int _NextBytes = std::__bit_ceil(_Bytes) / 2;\n       using _NextAbi = _Abi<_NextBytes>;\n@@ -4393,7 +4411,8 @@ template <template <int> class _A0, template <int> class... _Rest>\n \ttypename _AbiList<_Rest...>::template _FirstValidAbi<_Tp, _Np>>;\n \n     template <typename _Tp, int _Np>\n-      static constexpr auto _S_determine_best_abi()\n+      static constexpr auto\n+      _S_determine_best_abi()\n       {\n \tstatic_assert(_Np >= 1);\n \tconstexpr int _Bytes = sizeof(_Tp) * _Np;\n@@ -4556,28 +4575,23 @@ template <typename _Tp, typename _Abi>\n     template <typename _Flags>\n       _GLIBCXX_SIMD_ALWAYS_INLINE\n       simd_mask(const value_type* __mem, _Flags)\n-      : _M_data(_Impl::template _S_load<_Ip>(\n-\t_Flags::template _S_apply<simd_mask>(__mem))) {}\n+      : _M_data(_Impl::template _S_load<_Ip>(_Flags::template _S_apply<simd_mask>(__mem))) {}\n \n     template <typename _Flags>\n       _GLIBCXX_SIMD_ALWAYS_INLINE\n       simd_mask(const value_type* __mem, simd_mask __k, _Flags)\n       : _M_data{}\n       {\n-\t_M_data\n-\t  = _Impl::_S_masked_load(_M_data, __k._M_data,\n-\t\t\t\t  _Flags::template _S_apply<simd_mask>(__mem));\n+\t_M_data = _Impl::_S_masked_load(_M_data, __k._M_data,\n+\t\t\t\t\t_Flags::template _S_apply<simd_mask>(__mem));\n       }\n \n     // }}}\n     // loads [simd_mask.load] {{{\n     template <typename _Flags>\n       _GLIBCXX_SIMD_ALWAYS_INLINE void\n       copy_from(const value_type* __mem, _Flags)\n-      {\n-\t_M_data = _Impl::template _S_load<_Ip>(\n-\t  _Flags::template _S_apply<simd_mask>(__mem));\n-      }\n+      { _M_data = _Impl::template _S_load<_Ip>(_Flags::template _S_apply<simd_mask>(__mem)); }\n \n     // }}}\n     // stores [simd_mask.store] {{{\n@@ -4618,8 +4632,7 @@ template <typename _Tp, typename _Abi>\n   #ifdef _GLIBCXX_SIMD_ENABLE_IMPLICIT_MASK_CAST\n     // simd_mask<int> && simd_mask<uint> needs disambiguation\n     template <typename _Up, typename _A2,\n-\t      typename\n-\t      = enable_if_t<is_convertible_v<simd_mask<_Up, _A2>, simd_mask>>>\n+\t      typename = enable_if_t<is_convertible_v<simd_mask<_Up, _A2>, simd_mask>>>\n       _GLIBCXX_SIMD_ALWAYS_INLINE friend simd_mask\n       operator&&(const simd_mask& __x, const simd_mask<_Up, _A2>& __y)\n       {\n@@ -4628,8 +4641,7 @@ template <typename _Tp, typename _Abi>\n       }\n \n     template <typename _Up, typename _A2,\n-\t      typename\n-\t      = enable_if_t<is_convertible_v<simd_mask<_Up, _A2>, simd_mask>>>\n+\t      typename = enable_if_t<is_convertible_v<simd_mask<_Up, _A2>, simd_mask>>>\n       _GLIBCXX_SIMD_ALWAYS_INLINE friend simd_mask\n       operator||(const simd_mask& __x, const simd_mask<_Up, _A2>& __y)\n       {\n@@ -4640,15 +4652,11 @@ template <typename _Tp, typename _Abi>\n \n     _GLIBCXX_SIMD_ALWAYS_INLINE friend simd_mask\n     operator&&(const simd_mask& __x, const simd_mask& __y)\n-    {\n-      return {__private_init, _Impl::_S_logical_and(__x._M_data, __y._M_data)};\n-    }\n+    { return {__private_init, _Impl::_S_logical_and(__x._M_data, __y._M_data)}; }\n \n     _GLIBCXX_SIMD_ALWAYS_INLINE friend simd_mask\n     operator||(const simd_mask& __x, const simd_mask& __y)\n-    {\n-      return {__private_init, _Impl::_S_logical_or(__x._M_data, __y._M_data)};\n-    }\n+    { return {__private_init, _Impl::_S_logical_or(__x._M_data, __y._M_data)}; }\n \n     _GLIBCXX_SIMD_ALWAYS_INLINE friend simd_mask\n     operator&(const simd_mask& __x, const simd_mask& __y)\n@@ -4714,8 +4722,7 @@ template <typename _Tp, typename _Abi>\n     // }}}\n     // bitset_init ctor {{{\n     _GLIBCXX_SIMD_INTRINSIC simd_mask(_BitsetInit, bitset<size()> __init)\n-    : _M_data(\n-\t_Impl::_S_from_bitmask(_SanitizedBitMask<size()>(__init), _S_type_tag))\n+    : _M_data(_Impl::_S_from_bitmask(_SanitizedBitMask<size()>(__init), _S_type_tag))\n     {}\n \n     // }}}\n@@ -4727,8 +4734,7 @@ template <typename _Tp, typename _Abi>\n     struct _CvtProxy\n     {\n       template <typename _Up, typename _A2,\n-\t\ttypename\n-\t\t= enable_if_t<simd_size_v<_Up, _A2> == simd_size_v<_Tp, _Abi>>>\n+\t\ttypename = enable_if_t<simd_size_v<_Up, _A2> == simd_size_v<_Tp, _Abi>>>\n \t_GLIBCXX_SIMD_ALWAYS_INLINE\n \toperator simd_mask<_Up, _A2>() &&\n \t{\n@@ -5419,26 +5425,17 @@ namespace __float_bitwise_operators { //{{{\n template <typename _Tp, typename _Ap>\n   _GLIBCXX_SIMD_INTRINSIC _GLIBCXX_SIMD_CONSTEXPR simd<_Tp, _Ap>\n   operator^(const simd<_Tp, _Ap>& __a, const simd<_Tp, _Ap>& __b)\n-  {\n-    return {__private_init,\n-\t    _Ap::_SimdImpl::_S_bit_xor(__data(__a), __data(__b))};\n-  }\n+  { return {__private_init, _Ap::_SimdImpl::_S_bit_xor(__data(__a), __data(__b))}; }\n \n template <typename _Tp, typename _Ap>\n   _GLIBCXX_SIMD_INTRINSIC _GLIBCXX_SIMD_CONSTEXPR simd<_Tp, _Ap>\n   operator|(const simd<_Tp, _Ap>& __a, const simd<_Tp, _Ap>& __b)\n-  {\n-    return {__private_init,\n-\t    _Ap::_SimdImpl::_S_bit_or(__data(__a), __data(__b))};\n-  }\n+  { return {__private_init, _Ap::_SimdImpl::_S_bit_or(__data(__a), __data(__b))}; }\n \n template <typename _Tp, typename _Ap>\n   _GLIBCXX_SIMD_INTRINSIC _GLIBCXX_SIMD_CONSTEXPR simd<_Tp, _Ap>\n   operator&(const simd<_Tp, _Ap>& __a, const simd<_Tp, _Ap>& __b)\n-  {\n-    return {__private_init,\n-\t    _Ap::_SimdImpl::_S_bit_and(__data(__a), __data(__b))};\n-  }\n+  { return {__private_init, _Ap::_SimdImpl::_S_bit_and(__data(__a), __data(__b))}; }\n \n template <typename _Tp, typename _Ap>\n   _GLIBCXX_SIMD_INTRINSIC _GLIBCXX_SIMD_CONSTEXPR"}, {"sha": "4c008da26e0bb32aeafe0303e69731de0fa53141", "filename": "libstdc++-v3/include/experimental/bits/simd_builtin.h", "status": "modified", "additions": 333, "deletions": 359, "changes": 692, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b31186e589caee43ac5720a538d9a41ebf514e81/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_builtin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b31186e589caee43ac5720a538d9a41ebf514e81/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_builtin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_builtin.h?ref=b31186e589caee43ac5720a538d9a41ebf514e81", "patch": "@@ -836,22 +836,19 @@ template <typename _Tp, typename _Mp, typename _Abi, size_t _Np>\n     // _SimdBase / base class for simd, providing extra conversions {{{\n     struct _SimdBase2\n     {\n-      _GLIBCXX_SIMD_ALWAYS_INLINE\n-      explicit operator __intrinsic_type_t<_Tp, _Np>() const\n-      {\n-\treturn __to_intrin(static_cast<const simd<_Tp, _Abi>*>(this)->_M_data);\n-      }\n-      _GLIBCXX_SIMD_ALWAYS_INLINE\n-      explicit operator __vector_type_t<_Tp, _Np>() const\n-      {\n-\treturn static_cast<const simd<_Tp, _Abi>*>(this)->_M_data.__builtin();\n-      }\n+      _GLIBCXX_SIMD_ALWAYS_INLINE explicit\n+      operator __intrinsic_type_t<_Tp, _Np>() const\n+      { return __to_intrin(static_cast<const simd<_Tp, _Abi>*>(this)->_M_data); }\n+\n+      _GLIBCXX_SIMD_ALWAYS_INLINE explicit\n+      operator __vector_type_t<_Tp, _Np>() const\n+      { return static_cast<const simd<_Tp, _Abi>*>(this)->_M_data.__builtin(); }\n     };\n \n     struct _SimdBase1\n     {\n-      _GLIBCXX_SIMD_ALWAYS_INLINE\n-      explicit operator __intrinsic_type_t<_Tp, _Np>() const\n+      _GLIBCXX_SIMD_ALWAYS_INLINE explicit\n+      operator __intrinsic_type_t<_Tp, _Np>() const\n       { return __data(*static_cast<const simd<_Tp, _Abi>*>(this)); }\n     };\n \n@@ -863,23 +860,19 @@ template <typename _Tp, typename _Mp, typename _Abi, size_t _Np>\n     // _MaskBase {{{\n     struct _MaskBase2\n     {\n-      _GLIBCXX_SIMD_ALWAYS_INLINE\n-      explicit operator __intrinsic_type_t<_Tp, _Np>() const\n-      {\n-\treturn static_cast<const simd_mask<_Tp, _Abi>*>(this)\n-\t  ->_M_data.__intrin();\n-      }\n-      _GLIBCXX_SIMD_ALWAYS_INLINE\n-      explicit operator __vector_type_t<_Tp, _Np>() const\n-      {\n-\treturn static_cast<const simd_mask<_Tp, _Abi>*>(this)->_M_data._M_data;\n-      }\n+      _GLIBCXX_SIMD_ALWAYS_INLINE explicit\n+      operator __intrinsic_type_t<_Tp, _Np>() const\n+      { return static_cast<const simd_mask<_Tp, _Abi>*>(this) ->_M_data.__intrin(); }\n+\n+      _GLIBCXX_SIMD_ALWAYS_INLINE explicit\n+      operator __vector_type_t<_Tp, _Np>() const\n+      { return static_cast<const simd_mask<_Tp, _Abi>*>(this)->_M_data._M_data; }\n     };\n \n     struct _MaskBase1\n     {\n-      _GLIBCXX_SIMD_ALWAYS_INLINE\n-      explicit operator __intrinsic_type_t<_Tp, _Np>() const\n+      _GLIBCXX_SIMD_ALWAYS_INLINE explicit\n+      operator __intrinsic_type_t<_Tp, _Np>() const\n       { return __data(*static_cast<const simd_mask<_Tp, _Abi>*>(this)); }\n     };\n \n@@ -898,6 +891,7 @@ template <typename _Tp, typename _Mp, typename _Abi, size_t _Np>\n     public:\n       _GLIBCXX_SIMD_ALWAYS_INLINE\n       _MaskCastType(_Up __x) : _M_data(__x) {}\n+\n       _GLIBCXX_SIMD_ALWAYS_INLINE\n       operator _MaskMember() const { return _M_data; }\n     };\n@@ -913,6 +907,7 @@ template <typename _Tp, typename _Mp, typename _Abi, size_t _Np>\n     public:\n       _GLIBCXX_SIMD_ALWAYS_INLINE\n       _SimdCastType1(_Ap __a) : _M_data(__vector_bitcast<_Tp>(__a)) {}\n+\n       _GLIBCXX_SIMD_ALWAYS_INLINE\n       operator _SimdMember() const { return _M_data; }\n     };\n@@ -926,8 +921,10 @@ template <typename _Tp, typename _Mp, typename _Abi, size_t _Np>\n     public:\n       _GLIBCXX_SIMD_ALWAYS_INLINE\n       _SimdCastType2(_Ap __a) : _M_data(__vector_bitcast<_Tp>(__a)) {}\n+\n       _GLIBCXX_SIMD_ALWAYS_INLINE\n       _SimdCastType2(_Bp __b) : _M_data(__b) {}\n+\n       _GLIBCXX_SIMD_ALWAYS_INLINE\n       operator _SimdMember() const { return _M_data; }\n     };\n@@ -1039,16 +1036,13 @@ template <int _UsedBytes>\n       }\n \n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static constexpr __intrinsic_type_t<_Tp,\n-\t\t\t\t\t\t\t\t  _S_size<_Tp>>\n+      _GLIBCXX_SIMD_INTRINSIC static constexpr __intrinsic_type_t<_Tp, _S_size<_Tp>>\n       _S_implicit_mask_intrin()\n-      {\n-\treturn __to_intrin(\n-\t  __vector_bitcast<_Tp>(_S_implicit_mask<_Tp>()._M_data));\n-      }\n+      { return __to_intrin(__vector_bitcast<_Tp>(_S_implicit_mask<_Tp>()._M_data)); }\n \n     template <typename _TW, typename _TVT = _VectorTraits<_TW>>\n-      _GLIBCXX_SIMD_INTRINSIC static constexpr _TW _S_masked(_TW __x)\n+      _GLIBCXX_SIMD_INTRINSIC static constexpr _TW\n+      _S_masked(_TW __x)\n       {\n \tusing _Tp = typename _TVT::value_type;\n \tif constexpr (!_MaskMember<_Tp>::_S_is_partial)\n@@ -1170,8 +1164,7 @@ template <int _UsedBytes>\n       { return __implicit_mask_n<_S_size<_Tp>>(); }\n \n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static constexpr __bool_storage_member_type_t<\n-\t_S_size<_Tp>>\n+      _GLIBCXX_SIMD_INTRINSIC static constexpr __bool_storage_member_type_t<_S_size<_Tp>>\n       _S_implicit_mask_intrin()\n       { return __implicit_mask_n<_S_size<_Tp>>(); }\n \n@@ -1303,7 +1296,8 @@ struct _CommonImplBuiltin\n   // }}}\n   // _S_store {{{\n   template <size_t _ReqBytes = 0, typename _TV>\n-    _GLIBCXX_SIMD_INTRINSIC static void _S_store(_TV __x, void* __addr)\n+    _GLIBCXX_SIMD_INTRINSIC static void\n+    _S_store(_TV __x, void* __addr)\n     {\n       constexpr size_t _Bytes = _ReqBytes == 0 ? sizeof(__x) : _ReqBytes;\n       static_assert(sizeof(__x) >= _Bytes);\n@@ -1339,8 +1333,8 @@ struct _CommonImplBuiltin\n     }\n \n   template <typename _Tp, size_t _Np>\n-    _GLIBCXX_SIMD_INTRINSIC static void _S_store(_SimdWrapper<_Tp, _Np> __x,\n-\t\t\t\t\t\t void* __addr)\n+    _GLIBCXX_SIMD_INTRINSIC static void\n+    _S_store(_SimdWrapper<_Tp, _Np> __x, void* __addr)\n     { _S_store<_Np * sizeof(_Tp)>(__x._M_data, __addr); }\n \n   // }}}\n@@ -1447,8 +1441,8 @@ template <typename _Abi, typename>\n \n     // _S_generator {{{2\n     template <typename _Fp, typename _Tp>\n-      inline static constexpr _SimdMember<_Tp> _S_generator(_Fp&& __gen,\n-\t\t\t\t\t\t\t    _TypeTag<_Tp>)\n+      inline static constexpr _SimdMember<_Tp>\n+      _S_generator(_Fp&& __gen, _TypeTag<_Tp>)\n       {\n \treturn __generate_vector<_Tp, _S_full_size<_Tp>>(\n \t\t [&](auto __i) constexpr _GLIBCXX_SIMD_ALWAYS_INLINE_LAMBDA {\n@@ -1569,8 +1563,7 @@ template <typename _Abi, typename>\n     // _S_masked_store_nocvt {{{2\n     template <typename _Tp, size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static void\n-      _S_masked_store_nocvt(_SimdWrapper<_Tp, _Np> __v, _Tp* __mem,\n-\t\t\t    _MaskMember<_Tp> __k)\n+      _S_masked_store_nocvt(_SimdWrapper<_Tp, _Np> __v, _Tp* __mem, _MaskMember<_Tp> __k)\n       {\n \t_BitOps::_S_bit_iteration(\n \t  _MaskImpl::_S_to_bits(__k),\n@@ -1583,8 +1576,7 @@ template <typename _Abi, typename>\n     template <typename _TW, typename _TVT = _VectorTraits<_TW>,\n \t      typename _Tp = typename _TVT::value_type, typename _Up>\n       static inline void\n-      _S_masked_store(const _TW __v, _Up* __mem, const _MaskMember<_Tp> __k)\n-\tnoexcept\n+      _S_masked_store(const _TW __v, _Up* __mem, const _MaskMember<_Tp> __k) noexcept\n       {\n \tconstexpr size_t _TV_size = _S_size<_Tp>;\n \t[[maybe_unused]] const auto __vi = __to_intrin(__v);\n@@ -1946,7 +1938,8 @@ template <typename _Abi, typename>\n     // frexp, modf and copysign implemented in simd_math.h\n #define _GLIBCXX_SIMD_MATH_FALLBACK(__name)                                    \\\n     template <typename _Tp, typename... _More>                                 \\\n-      static _Tp _S_##__name(const _Tp& __x, const _More&... __more)           \\\n+      static _Tp                                                               \\\n+      _S_##__name(const _Tp& __x, const _More&... __more)                      \\\n       {                                                                        \\\n \treturn __generate_vector<_Tp>(                                         \\\n \t\t [&](auto __i) _GLIBCXX_SIMD_ALWAYS_INLINE_LAMBDA {            \\\n@@ -1956,8 +1949,8 @@ template <typename _Abi, typename>\n \n #define _GLIBCXX_SIMD_MATH_FALLBACK_MASKRET(__name)                            \\\n     template <typename _Tp, typename... _More>                                 \\\n-      static typename _Tp::mask_type _S_##__name(const _Tp& __x,               \\\n-\t\t\t\t\t\t const _More&... __more)       \\\n+      static typename _Tp::mask_type                                           \\\n+      _S_##__name(const _Tp& __x, const _More&... __more)                      \\\n       {                                                                        \\\n \treturn __generate_vector<_Tp>(                                         \\\n \t\t [&](auto __i) _GLIBCXX_SIMD_ALWAYS_INLINE_LAMBDA {            \\\n@@ -1967,7 +1960,8 @@ template <typename _Abi, typename>\n \n #define _GLIBCXX_SIMD_MATH_FALLBACK_FIXEDRET(_RetTp, __name)                          \\\n     template <typename _Tp, typename... _More>                                        \\\n-      static auto _S_##__name(const _Tp& __x, const _More&... __more)                 \\\n+      static auto                                                                     \\\n+      _S_##__name(const _Tp& __x, const _More&... __more)                             \\\n       {                                                                               \\\n \treturn __fixed_size_storage_t<_RetTp,                                         \\\n \t\t\t\t      _VectorTraits<_Tp>::_S_partial_width>::         \\\n@@ -2115,341 +2109,339 @@ template <typename _Abi, typename>\n #undef _GLIBCXX_SIMD_MATH_FALLBACK_FIXEDRET\n     // _S_abs {{{3\n     template <typename _Tp, size_t _Np>\n-    _GLIBCXX_SIMD_INTRINSIC static _SimdWrapper<_Tp, _Np>\n-    _S_abs(_SimdWrapper<_Tp, _Np> __x) noexcept\n-    {\n-      // if (__builtin_is_constant_evaluated())\n-      //  {\n-      //    return __x._M_data < 0 ? -__x._M_data : __x._M_data;\n-      //  }\n-      if constexpr (is_floating_point_v<_Tp>)\n-\t// `v < 0 ? -v : v` cannot compile to the efficient implementation of\n-\t// masking the signbit off because it must consider v == -0\n-\n-\t// ~(-0.) & v would be easy, but breaks with fno-signed-zeros\n-\treturn __and(_S_absmask<__vector_type_t<_Tp, _Np>>, __x._M_data);\n-      else\n-\treturn __x._M_data < 0 ? -__x._M_data : __x._M_data;\n-    }\n+      _GLIBCXX_SIMD_INTRINSIC static _SimdWrapper<_Tp, _Np>\n+      _S_abs(_SimdWrapper<_Tp, _Np> __x) noexcept\n+      {\n+\t// if (__builtin_is_constant_evaluated())\n+\t//  {\n+\t//    return __x._M_data < 0 ? -__x._M_data : __x._M_data;\n+\t//  }\n+\tif constexpr (is_floating_point_v<_Tp>)\n+\t  // `v < 0 ? -v : v` cannot compile to the efficient implementation of\n+\t  // masking the signbit off because it must consider v == -0\n+\n+\t  // ~(-0.) & v would be easy, but breaks with fno-signed-zeros\n+\t  return __and(_S_absmask<__vector_type_t<_Tp, _Np>>, __x._M_data);\n+\telse\n+\t  return __x._M_data < 0 ? -__x._M_data : __x._M_data;\n+      }\n \n     // }}}3\n     // _S_plus_minus {{{\n     // Returns __x + __y - __y without -fassociative-math optimizing to __x.\n     // - _TV must be __vector_type_t<floating-point type, N>.\n     // - _UV must be _TV or floating-point type.\n     template <typename _TV, typename _UV>\n-    _GLIBCXX_SIMD_INTRINSIC static constexpr _TV _S_plus_minus(_TV __x,\n-\t\t\t\t\t\t\t       _UV __y) noexcept\n-    {\n-  #if defined __i386__ && !defined __SSE_MATH__\n-      if constexpr (sizeof(__x) == 8)\n-\t{ // operations on __x would use the FPU\n-\t  static_assert(is_same_v<_TV, __vector_type_t<float, 2>>);\n-\t  const auto __x4 = __vector_bitcast<float, 4>(__x);\n-\t  if constexpr (is_same_v<_TV, _UV>)\n-\t    return __vector_bitcast<float, 2>(\n-\t      _S_plus_minus(__x4, __vector_bitcast<float, 4>(__y)));\n-\t  else\n-\t    return __vector_bitcast<float, 2>(_S_plus_minus(__x4, __y));\n-\t}\n-  #endif\n-  #if !defined __clang__ && __GCC_IEC_559 == 0\n-      if (__builtin_is_constant_evaluated()\n-\t  || (__builtin_constant_p(__x) && __builtin_constant_p(__y)))\n+      _GLIBCXX_SIMD_INTRINSIC static constexpr _TV\n+      _S_plus_minus(_TV __x, _UV __y) noexcept\n+      {\n+#if defined __i386__ && !defined __SSE_MATH__\n+\tif constexpr (sizeof(__x) == 8)\n+\t  { // operations on __x would use the FPU\n+\t    static_assert(is_same_v<_TV, __vector_type_t<float, 2>>);\n+\t    const auto __x4 = __vector_bitcast<float, 4>(__x);\n+\t    if constexpr (is_same_v<_TV, _UV>)\n+\t      return __vector_bitcast<float, 2>(\n+\t\t       _S_plus_minus(__x4, __vector_bitcast<float, 4>(__y)));\n+\t    else\n+\t      return __vector_bitcast<float, 2>(_S_plus_minus(__x4, __y));\n+\t  }\n+#endif\n+#if !defined __clang__ && __GCC_IEC_559 == 0\n+\tif (__builtin_is_constant_evaluated()\n+\t      || (__builtin_constant_p(__x) && __builtin_constant_p(__y)))\n+\t  return (__x + __y) - __y;\n+\telse\n+\t  return [&] {\n+\t    __x += __y;\n+\t    if constexpr(__have_sse)\n+\t      {\n+\t\tif constexpr (sizeof(__x) >= 16)\n+\t\t  asm(\"\" : \"+x\"(__x));\n+\t\telse if constexpr (is_same_v<__vector_type_t<float, 2>, _TV>)\n+\t\t  asm(\"\" : \"+x\"(__x[0]), \"+x\"(__x[1]));\n+\t\telse\n+\t\t  __assert_unreachable<_TV>();\n+\t      }\n+\t    else if constexpr(__have_neon)\n+\t      asm(\"\" : \"+w\"(__x));\n+\t    else if constexpr (__have_power_vmx)\n+\t      {\n+\t\tif constexpr (is_same_v<__vector_type_t<float, 2>, _TV>)\n+\t\t  asm(\"\" : \"+fgr\"(__x[0]), \"+fgr\"(__x[1]));\n+\t\telse\n+\t\t  asm(\"\" : \"+v\"(__x));\n+\t      }\n+\t    else\n+\t      asm(\"\" : \"+g\"(__x));\n+\t    return __x - __y;\n+\t  }();\n+#else\n \treturn (__x + __y) - __y;\n-      else\n-\treturn [&] {\n-\t  __x += __y;\n-\t  if constexpr(__have_sse)\n-\t    {\n-\t      if constexpr (sizeof(__x) >= 16)\n-\t\tasm(\"\" : \"+x\"(__x));\n-\t      else if constexpr (is_same_v<__vector_type_t<float, 2>, _TV>)\n-\t\tasm(\"\" : \"+x\"(__x[0]), \"+x\"(__x[1]));\n-\t      else\n-\t\t__assert_unreachable<_TV>();\n-\t    }\n-\t  else if constexpr(__have_neon)\n-\t    asm(\"\" : \"+w\"(__x));\n-\t  else if constexpr (__have_power_vmx)\n-\t    {\n-\t      if constexpr (is_same_v<__vector_type_t<float, 2>, _TV>)\n-\t\tasm(\"\" : \"+fgr\"(__x[0]), \"+fgr\"(__x[1]));\n-\t      else\n-\t\tasm(\"\" : \"+v\"(__x));\n-\t    }\n-\t  else\n-\t    asm(\"\" : \"+g\"(__x));\n-\t  return __x - __y;\n-\t}();\n-  #else\n-      return (__x + __y) - __y;\n-  #endif\n-    }\n+#endif\n+      }\n \n     // }}}\n     // _S_nearbyint {{{3\n     template <typename _Tp, typename _TVT = _VectorTraits<_Tp>>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_nearbyint(_Tp __x_) noexcept\n-    {\n-      using value_type = typename _TVT::value_type;\n-      using _V = typename _TVT::type;\n-      const _V __x = __x_;\n-      const _V __absx = __and(__x, _S_absmask<_V>);\n-      static_assert(__CHAR_BIT__ * sizeof(1ull) >= __digits_v<value_type>);\n-      _GLIBCXX_SIMD_USE_CONSTEXPR _V __shifter_abs\n-\t= _V() + (1ull << (__digits_v<value_type> - 1));\n-      const _V __shifter = __or(__and(_S_signmask<_V>, __x), __shifter_abs);\n-      const _V __shifted = _S_plus_minus(__x, __shifter);\n-      return __absx < __shifter_abs ? __shifted : __x;\n-    }\n+      _GLIBCXX_SIMD_INTRINSIC static _Tp\n+      _S_nearbyint(_Tp __x_) noexcept\n+      {\n+\tusing value_type = typename _TVT::value_type;\n+\tusing _V = typename _TVT::type;\n+\tconst _V __x = __x_;\n+\tconst _V __absx = __and(__x, _S_absmask<_V>);\n+\tstatic_assert(__CHAR_BIT__ * sizeof(1ull) >= __digits_v<value_type>);\n+\t_GLIBCXX_SIMD_USE_CONSTEXPR _V __shifter_abs\n+\t  = _V() + (1ull << (__digits_v<value_type> - 1));\n+\tconst _V __shifter = __or(__and(_S_signmask<_V>, __x), __shifter_abs);\n+\tconst _V __shifted = _S_plus_minus(__x, __shifter);\n+\treturn __absx < __shifter_abs ? __shifted : __x;\n+      }\n \n     // _S_rint {{{3\n     template <typename _Tp, typename _TVT = _VectorTraits<_Tp>>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_rint(_Tp __x) noexcept\n-    {\n-      return _SuperImpl::_S_nearbyint(__x);\n-    }\n+      _GLIBCXX_SIMD_INTRINSIC static _Tp\n+      _S_rint(_Tp __x) noexcept\n+      { return _SuperImpl::_S_nearbyint(__x); }\n \n     // _S_trunc {{{3\n     template <typename _Tp, size_t _Np>\n-    _GLIBCXX_SIMD_INTRINSIC static _SimdWrapper<_Tp, _Np>\n-    _S_trunc(_SimdWrapper<_Tp, _Np> __x)\n-    {\n-      using _V = __vector_type_t<_Tp, _Np>;\n-      const _V __absx = __and(__x._M_data, _S_absmask<_V>);\n-      static_assert(__CHAR_BIT__ * sizeof(1ull) >= __digits_v<_Tp>);\n-      constexpr _Tp __shifter = 1ull << (__digits_v<_Tp> - 1);\n-      _V __truncated = _S_plus_minus(__absx, __shifter);\n-      __truncated -= __truncated > __absx ? _V() + 1 : _V();\n-      return __absx < __shifter ? __or(__xor(__absx, __x._M_data), __truncated)\n-\t\t\t\t: __x._M_data;\n-    }\n+      _GLIBCXX_SIMD_INTRINSIC static _SimdWrapper<_Tp, _Np>\n+      _S_trunc(_SimdWrapper<_Tp, _Np> __x)\n+      {\n+\tusing _V = __vector_type_t<_Tp, _Np>;\n+\tconst _V __absx = __and(__x._M_data, _S_absmask<_V>);\n+\tstatic_assert(__CHAR_BIT__ * sizeof(1ull) >= __digits_v<_Tp>);\n+\tconstexpr _Tp __shifter = 1ull << (__digits_v<_Tp> - 1);\n+\t_V __truncated = _S_plus_minus(__absx, __shifter);\n+\t__truncated -= __truncated > __absx ? _V() + 1 : _V();\n+\treturn __absx < __shifter ? __or(__xor(__absx, __x._M_data), __truncated)\n+\t\t\t\t  : __x._M_data;\n+      }\n \n     // _S_round {{{3\n     template <typename _Tp, size_t _Np>\n-    _GLIBCXX_SIMD_INTRINSIC static _SimdWrapper<_Tp, _Np>\n-    _S_round(_SimdWrapper<_Tp, _Np> __x)\n-    {\n-      const auto __abs_x = _SuperImpl::_S_abs(__x);\n-      const auto __t_abs = _SuperImpl::_S_trunc(__abs_x)._M_data;\n-      const auto __r_abs // round(abs(x)) =\n-\t= __t_abs + (__abs_x._M_data - __t_abs >= _Tp(.5) ? _Tp(1) : 0);\n-      return __or(__xor(__abs_x._M_data, __x._M_data), __r_abs);\n-    }\n+      _GLIBCXX_SIMD_INTRINSIC static _SimdWrapper<_Tp, _Np>\n+      _S_round(_SimdWrapper<_Tp, _Np> __x)\n+      {\n+\tconst auto __abs_x = _SuperImpl::_S_abs(__x);\n+\tconst auto __t_abs = _SuperImpl::_S_trunc(__abs_x)._M_data;\n+\tconst auto __r_abs // round(abs(x)) =\n+\t  = __t_abs + (__abs_x._M_data - __t_abs >= _Tp(.5) ? _Tp(1) : 0);\n+\treturn __or(__xor(__abs_x._M_data, __x._M_data), __r_abs);\n+      }\n \n     // _S_floor {{{3\n     template <typename _Tp, size_t _Np>\n-    _GLIBCXX_SIMD_INTRINSIC static _SimdWrapper<_Tp, _Np>\n-    _S_floor(_SimdWrapper<_Tp, _Np> __x)\n-    {\n-      const auto __y = _SuperImpl::_S_trunc(__x)._M_data;\n-      const auto __negative_input\n-\t= __vector_bitcast<_Tp>(__x._M_data < __vector_broadcast<_Np, _Tp>(0));\n-      const auto __mask\n-\t= __andnot(__vector_bitcast<_Tp>(__y == __x._M_data), __negative_input);\n-      return __or(__andnot(__mask, __y),\n-\t\t  __and(__mask, __y - __vector_broadcast<_Np, _Tp>(1)));\n-    }\n+      _GLIBCXX_SIMD_INTRINSIC static _SimdWrapper<_Tp, _Np>\n+      _S_floor(_SimdWrapper<_Tp, _Np> __x)\n+      {\n+\tconst auto __y = _SuperImpl::_S_trunc(__x)._M_data;\n+\tconst auto __negative_input\n+\t  = __vector_bitcast<_Tp>(__x._M_data < __vector_broadcast<_Np, _Tp>(0));\n+\tconst auto __mask\n+\t  = __andnot(__vector_bitcast<_Tp>(__y == __x._M_data), __negative_input);\n+\treturn __or(__andnot(__mask, __y),\n+\t\t    __and(__mask, __y - __vector_broadcast<_Np, _Tp>(1)));\n+      }\n \n     // _S_ceil {{{3\n     template <typename _Tp, size_t _Np>\n-    _GLIBCXX_SIMD_INTRINSIC static _SimdWrapper<_Tp, _Np>\n-    _S_ceil(_SimdWrapper<_Tp, _Np> __x)\n-    {\n-      const auto __y = _SuperImpl::_S_trunc(__x)._M_data;\n-      const auto __negative_input\n-\t= __vector_bitcast<_Tp>(__x._M_data < __vector_broadcast<_Np, _Tp>(0));\n-      const auto __inv_mask\n-\t= __or(__vector_bitcast<_Tp>(__y == __x._M_data), __negative_input);\n-      return __or(__and(__inv_mask, __y),\n-\t\t  __andnot(__inv_mask, __y + __vector_broadcast<_Np, _Tp>(1)));\n-    }\n+      _GLIBCXX_SIMD_INTRINSIC static _SimdWrapper<_Tp, _Np>\n+      _S_ceil(_SimdWrapper<_Tp, _Np> __x)\n+      {\n+\tconst auto __y = _SuperImpl::_S_trunc(__x)._M_data;\n+\tconst auto __negative_input\n+\t  = __vector_bitcast<_Tp>(__x._M_data < __vector_broadcast<_Np, _Tp>(0));\n+\tconst auto __inv_mask\n+\t  = __or(__vector_bitcast<_Tp>(__y == __x._M_data), __negative_input);\n+\treturn __or(__and(__inv_mask, __y),\n+\t\t    __andnot(__inv_mask, __y + __vector_broadcast<_Np, _Tp>(1)));\n+      }\n \n     // _S_isnan {{{3\n     template <typename _Tp, size_t _Np>\n-    _GLIBCXX_SIMD_INTRINSIC static _MaskMember<_Tp>\n-    _S_isnan([[maybe_unused]] _SimdWrapper<_Tp, _Np> __x)\n-    {\n-  #if __FINITE_MATH_ONLY__\n-      return {}; // false\n-  #elif !defined __SUPPORT_SNAN__\n-      return ~(__x._M_data == __x._M_data);\n-  #elif defined __STDC_IEC_559__\n-      using _Ip = __int_for_sizeof_t<_Tp>;\n-      const auto __absn = __vector_bitcast<_Ip>(_SuperImpl::_S_abs(__x));\n-      const auto __infn\n-\t= __vector_bitcast<_Ip>(__vector_broadcast<_Np>(__infinity_v<_Tp>));\n-      return __infn < __absn;\n-  #else\n-  #error \"Not implemented: how to support SNaN but non-IEC559 floating-point?\"\n-  #endif\n-    }\n+      _GLIBCXX_SIMD_INTRINSIC static _MaskMember<_Tp>\n+      _S_isnan([[maybe_unused]] _SimdWrapper<_Tp, _Np> __x)\n+      {\n+#if __FINITE_MATH_ONLY__\n+\treturn {}; // false\n+#elif !defined __SUPPORT_SNAN__\n+\treturn ~(__x._M_data == __x._M_data);\n+#elif defined __STDC_IEC_559__\n+\tusing _Ip = __int_for_sizeof_t<_Tp>;\n+\tconst auto __absn = __vector_bitcast<_Ip>(_SuperImpl::_S_abs(__x));\n+\tconst auto __infn\n+\t  = __vector_bitcast<_Ip>(__vector_broadcast<_Np>(__infinity_v<_Tp>));\n+\treturn __infn < __absn;\n+#else\n+#error \"Not implemented: how to support SNaN but non-IEC559 floating-point?\"\n+#endif\n+      }\n \n     // _S_isfinite {{{3\n     template <typename _Tp, size_t _Np>\n-    _GLIBCXX_SIMD_INTRINSIC static _MaskMember<_Tp>\n-    _S_isfinite([[maybe_unused]] _SimdWrapper<_Tp, _Np> __x)\n-    {\n-  #if __FINITE_MATH_ONLY__\n-      using _UV = typename _MaskMember<_Tp>::_BuiltinType;\n-      _GLIBCXX_SIMD_USE_CONSTEXPR _UV __alltrue = ~_UV();\n-      return __alltrue;\n-  #else\n-      // if all exponent bits are set, __x is either inf or NaN\n-      using _Ip = __int_for_sizeof_t<_Tp>;\n-      const auto __absn = __vector_bitcast<_Ip>(_SuperImpl::_S_abs(__x));\n-      const auto __maxn\n-\t= __vector_bitcast<_Ip>(__vector_broadcast<_Np>(__finite_max_v<_Tp>));\n-      return __absn <= __maxn;\n-  #endif\n-    }\n+      _GLIBCXX_SIMD_INTRINSIC static _MaskMember<_Tp>\n+      _S_isfinite([[maybe_unused]] _SimdWrapper<_Tp, _Np> __x)\n+      {\n+#if __FINITE_MATH_ONLY__\n+\tusing _UV = typename _MaskMember<_Tp>::_BuiltinType;\n+\t_GLIBCXX_SIMD_USE_CONSTEXPR _UV __alltrue = ~_UV();\n+\treturn __alltrue;\n+#else\n+\t// if all exponent bits are set, __x is either inf or NaN\n+\tusing _Ip = __int_for_sizeof_t<_Tp>;\n+\tconst auto __absn = __vector_bitcast<_Ip>(_SuperImpl::_S_abs(__x));\n+\tconst auto __maxn\n+\t  = __vector_bitcast<_Ip>(__vector_broadcast<_Np>(__finite_max_v<_Tp>));\n+\treturn __absn <= __maxn;\n+#endif\n+      }\n \n     // _S_isunordered {{{3\n     template <typename _Tp, size_t _Np>\n-    _GLIBCXX_SIMD_INTRINSIC static _MaskMember<_Tp>\n-    _S_isunordered(_SimdWrapper<_Tp, _Np> __x, _SimdWrapper<_Tp, _Np> __y)\n-    {\n-      return __or(_S_isnan(__x), _S_isnan(__y));\n-    }\n+      _GLIBCXX_SIMD_INTRINSIC static _MaskMember<_Tp>\n+      _S_isunordered(_SimdWrapper<_Tp, _Np> __x, _SimdWrapper<_Tp, _Np> __y)\n+      { return __or(_S_isnan(__x), _S_isnan(__y)); }\n \n     // _S_signbit {{{3\n     template <typename _Tp, size_t _Np>\n-    _GLIBCXX_SIMD_INTRINSIC static _MaskMember<_Tp>\n-    _S_signbit(_SimdWrapper<_Tp, _Np> __x)\n-    {\n-      using _Ip = __int_for_sizeof_t<_Tp>;\n-      return __vector_bitcast<_Ip>(__x) < 0;\n-      // Arithmetic right shift (SRA) would also work (instead of compare), but\n-      // 64-bit SRA isn't available on x86 before AVX512. And in general,\n-      // compares are more likely to be efficient than SRA.\n-    }\n+      _GLIBCXX_SIMD_INTRINSIC static _MaskMember<_Tp>\n+      _S_signbit(_SimdWrapper<_Tp, _Np> __x)\n+      {\n+\tusing _Ip = __int_for_sizeof_t<_Tp>;\n+\treturn __vector_bitcast<_Ip>(__x) < 0;\n+\t// Arithmetic right shift (SRA) would also work (instead of compare), but\n+\t// 64-bit SRA isn't available on x86 before AVX512. And in general,\n+\t// compares are more likely to be efficient than SRA.\n+      }\n \n     // _S_isinf {{{3\n     template <typename _Tp, size_t _Np>\n-    _GLIBCXX_SIMD_INTRINSIC static _MaskMember<_Tp>\n-    _S_isinf([[maybe_unused]] _SimdWrapper<_Tp, _Np> __x)\n-    {\n-  #if __FINITE_MATH_ONLY__\n-      return {}; // false\n-  #else\n-      return _SuperImpl::template _S_equal_to<_Tp, _Np>(_SuperImpl::_S_abs(__x),\n-\t\t\t\t\t\t\t__vector_broadcast<_Np>(\n-\t\t\t\t\t\t\t  __infinity_v<_Tp>));\n-      // alternative:\n-      // compare to inf using the corresponding integer type\n-      /*\n-\t return\n-\t __vector_bitcast<_Tp>(__vector_bitcast<__int_for_sizeof_t<_Tp>>(\n-\t\t\t       _S_abs(__x)._M_data)\n-\t ==\n-\t __vector_bitcast<__int_for_sizeof_t<_Tp>>(__vector_broadcast<_Np>(\n-\t __infinity_v<_Tp>)));\n-\t */\n-  #endif\n-    }\n+      _GLIBCXX_SIMD_INTRINSIC static _MaskMember<_Tp>\n+      _S_isinf([[maybe_unused]] _SimdWrapper<_Tp, _Np> __x)\n+      {\n+#if __FINITE_MATH_ONLY__\n+\treturn {}; // false\n+#else\n+\treturn _SuperImpl::template _S_equal_to<_Tp, _Np>(_SuperImpl::_S_abs(__x),\n+\t\t\t\t\t\t\t  __vector_broadcast<_Np>(\n+\t\t\t\t\t\t\t    __infinity_v<_Tp>));\n+\t// alternative:\n+\t// compare to inf using the corresponding integer type\n+\t/*\n+\t   return\n+\t   __vector_bitcast<_Tp>(__vector_bitcast<__int_for_sizeof_t<_Tp>>(\n+\t\t\t\t _S_abs(__x)._M_data)\n+\t   ==\n+\t   __vector_bitcast<__int_for_sizeof_t<_Tp>>(__vector_broadcast<_Np>(\n+\t   __infinity_v<_Tp>)));\n+\t   */\n+#endif\n+      }\n \n     // _S_isnormal {{{3\n     template <typename _Tp, size_t _Np>\n-    _GLIBCXX_SIMD_INTRINSIC static _MaskMember<_Tp>\n-    _S_isnormal(_SimdWrapper<_Tp, _Np> __x)\n-    {\n-      using _Ip = __int_for_sizeof_t<_Tp>;\n-      const auto __absn = __vector_bitcast<_Ip>(_SuperImpl::_S_abs(__x));\n-      const auto __minn\n-\t= __vector_bitcast<_Ip>(__vector_broadcast<_Np>(__norm_min_v<_Tp>));\n-  #if __FINITE_MATH_ONLY__\n-      return __absn >= __minn;\n-  #else\n-      const auto __maxn\n-\t= __vector_bitcast<_Ip>(__vector_broadcast<_Np>(__finite_max_v<_Tp>));\n-      return __minn <= __absn && __absn <= __maxn;\n-  #endif\n-    }\n+      _GLIBCXX_SIMD_INTRINSIC static _MaskMember<_Tp>\n+      _S_isnormal(_SimdWrapper<_Tp, _Np> __x)\n+      {\n+\tusing _Ip = __int_for_sizeof_t<_Tp>;\n+\tconst auto __absn = __vector_bitcast<_Ip>(_SuperImpl::_S_abs(__x));\n+\tconst auto __minn\n+\t  = __vector_bitcast<_Ip>(__vector_broadcast<_Np>(__norm_min_v<_Tp>));\n+#if __FINITE_MATH_ONLY__\n+\treturn __absn >= __minn;\n+#else\n+\tconst auto __maxn\n+\t  = __vector_bitcast<_Ip>(__vector_broadcast<_Np>(__finite_max_v<_Tp>));\n+\treturn __minn <= __absn && __absn <= __maxn;\n+#endif\n+      }\n \n     // _S_fpclassify {{{3\n     template <typename _Tp, size_t _Np>\n-    _GLIBCXX_SIMD_INTRINSIC static __fixed_size_storage_t<int, _Np>\n-    _S_fpclassify(_SimdWrapper<_Tp, _Np> __x)\n-    {\n-      using _I = __int_for_sizeof_t<_Tp>;\n-      const auto __xn\n-\t= __vector_bitcast<_I>(__to_intrin(_SuperImpl::_S_abs(__x)));\n-      constexpr size_t _NI = sizeof(__xn) / sizeof(_I);\n-      _GLIBCXX_SIMD_USE_CONSTEXPR auto __minn\n-\t= __vector_bitcast<_I>(__vector_broadcast<_NI>(__norm_min_v<_Tp>));\n-      _GLIBCXX_SIMD_USE_CONSTEXPR auto __infn\n-\t= __vector_bitcast<_I>(__vector_broadcast<_NI>(__infinity_v<_Tp>));\n-\n-      _GLIBCXX_SIMD_USE_CONSTEXPR auto __fp_normal\n-\t= __vector_broadcast<_NI, _I>(FP_NORMAL);\n-  #if !__FINITE_MATH_ONLY__\n-      _GLIBCXX_SIMD_USE_CONSTEXPR auto __fp_nan\n-\t= __vector_broadcast<_NI, _I>(FP_NAN);\n-      _GLIBCXX_SIMD_USE_CONSTEXPR auto __fp_infinite\n-\t= __vector_broadcast<_NI, _I>(FP_INFINITE);\n-  #endif\n-  #ifndef __FAST_MATH__\n-      _GLIBCXX_SIMD_USE_CONSTEXPR auto __fp_subnormal\n-\t= __vector_broadcast<_NI, _I>(FP_SUBNORMAL);\n-  #endif\n-      _GLIBCXX_SIMD_USE_CONSTEXPR auto __fp_zero\n-\t= __vector_broadcast<_NI, _I>(FP_ZERO);\n+      _GLIBCXX_SIMD_INTRINSIC static __fixed_size_storage_t<int, _Np>\n+      _S_fpclassify(_SimdWrapper<_Tp, _Np> __x)\n+      {\n+\tusing _I = __int_for_sizeof_t<_Tp>;\n+\tconst auto __xn\n+\t  = __vector_bitcast<_I>(__to_intrin(_SuperImpl::_S_abs(__x)));\n+\tconstexpr size_t _NI = sizeof(__xn) / sizeof(_I);\n+\t_GLIBCXX_SIMD_USE_CONSTEXPR auto __minn\n+\t  = __vector_bitcast<_I>(__vector_broadcast<_NI>(__norm_min_v<_Tp>));\n+\t_GLIBCXX_SIMD_USE_CONSTEXPR auto __infn\n+\t  = __vector_bitcast<_I>(__vector_broadcast<_NI>(__infinity_v<_Tp>));\n+\n+\t_GLIBCXX_SIMD_USE_CONSTEXPR auto __fp_normal\n+\t  = __vector_broadcast<_NI, _I>(FP_NORMAL);\n+#if !__FINITE_MATH_ONLY__\n+\t_GLIBCXX_SIMD_USE_CONSTEXPR auto __fp_nan\n+\t  = __vector_broadcast<_NI, _I>(FP_NAN);\n+\t_GLIBCXX_SIMD_USE_CONSTEXPR auto __fp_infinite\n+\t  = __vector_broadcast<_NI, _I>(FP_INFINITE);\n+#endif\n+#ifndef __FAST_MATH__\n+\t_GLIBCXX_SIMD_USE_CONSTEXPR auto __fp_subnormal\n+\t  = __vector_broadcast<_NI, _I>(FP_SUBNORMAL);\n+#endif\n+\t_GLIBCXX_SIMD_USE_CONSTEXPR auto __fp_zero\n+\t  = __vector_broadcast<_NI, _I>(FP_ZERO);\n \n-      __vector_type_t<_I, _NI>\n-\t__tmp = __xn < __minn\n+\t__vector_type_t<_I, _NI>\n+\t  __tmp = __xn < __minn\n   #ifdef __FAST_MATH__\n-\t\t  ? __fp_zero\n+\t\t    ? __fp_zero\n   #else\n-\t\t  ? (__xn == 0 ? __fp_zero : __fp_subnormal)\n+\t\t    ? (__xn == 0 ? __fp_zero : __fp_subnormal)\n   #endif\n   #if __FINITE_MATH_ONLY__\n-\t\t  : __fp_normal;\n+\t\t    : __fp_normal;\n   #else\n-\t\t  : (__xn < __infn ? __fp_normal\n-\t\t\t\t   : (__xn == __infn ? __fp_infinite : __fp_nan));\n+\t\t    : (__xn < __infn ? __fp_normal\n+\t\t\t\t     : (__xn == __infn ? __fp_infinite : __fp_nan));\n   #endif\n \n-      if constexpr (sizeof(_I) == sizeof(int))\n-\t{\n-\t  using _FixedInt = __fixed_size_storage_t<int, _Np>;\n-\t  const auto __as_int = __vector_bitcast<int, _Np>(__tmp);\n-\t  if constexpr (_FixedInt::_S_tuple_size == 1)\n-\t    return {__as_int};\n-\t  else if constexpr (_FixedInt::_S_tuple_size == 2\n-\t\t\t     && is_same_v<\n-\t\t\t       typename _FixedInt::_SecondType::_FirstAbi,\n-\t\t\t       simd_abi::scalar>)\n-\t    return {__extract<0, 2>(__as_int), __as_int[_Np - 1]};\n-\t  else if constexpr (_FixedInt::_S_tuple_size == 2)\n-\t    return {__extract<0, 2>(__as_int),\n-\t\t    __auto_bitcast(__extract<1, 2>(__as_int))};\n-\t  else\n-\t    __assert_unreachable<_Tp>();\n-\t}\n-      else if constexpr (_Np == 2 && sizeof(_I) == 8\n-\t\t\t && __fixed_size_storage_t<int, _Np>::_S_tuple_size == 2)\n-\t{\n-\t  const auto __aslong = __vector_bitcast<_LLong>(__tmp);\n-\t  return {int(__aslong[0]), {int(__aslong[1])}};\n-\t}\n-  #if _GLIBCXX_SIMD_X86INTRIN\n-      else if constexpr (sizeof(_Tp) == 8 && sizeof(__tmp) == 32\n-\t\t\t && __fixed_size_storage_t<int, _Np>::_S_tuple_size == 1)\n-\treturn {_mm_packs_epi32(__to_intrin(__lo128(__tmp)),\n-\t\t\t\t__to_intrin(__hi128(__tmp)))};\n-      else if constexpr (sizeof(_Tp) == 8 && sizeof(__tmp) == 64\n-\t\t\t && __fixed_size_storage_t<int, _Np>::_S_tuple_size == 1)\n-\treturn {_mm512_cvtepi64_epi32(__to_intrin(__tmp))};\n-  #endif // _GLIBCXX_SIMD_X86INTRIN\n-      else if constexpr (__fixed_size_storage_t<int, _Np>::_S_tuple_size == 1)\n-\treturn {__call_with_subscripts<_Np>(__vector_bitcast<_LLong>(__tmp),\n-\t\t\t\t\t    [](auto... __l) _GLIBCXX_SIMD_ALWAYS_INLINE_LAMBDA {\n-\t\t\t\t\t      return __make_wrapper<int>(__l...);\n-\t\t\t\t\t    })};\n-      else\n-\t__assert_unreachable<_Tp>();\n-    }\n+\tif constexpr (sizeof(_I) == sizeof(int))\n+\t  {\n+\t    using _FixedInt = __fixed_size_storage_t<int, _Np>;\n+\t    const auto __as_int = __vector_bitcast<int, _Np>(__tmp);\n+\t    if constexpr (_FixedInt::_S_tuple_size == 1)\n+\t      return {__as_int};\n+\t    else if constexpr (_FixedInt::_S_tuple_size == 2\n+\t\t\t\t && is_same_v<\n+\t\t\t\t      typename _FixedInt::_SecondType::_FirstAbi,\n+\t\t\t\t      simd_abi::scalar>)\n+\t      return {__extract<0, 2>(__as_int), __as_int[_Np - 1]};\n+\t    else if constexpr (_FixedInt::_S_tuple_size == 2)\n+\t      return {__extract<0, 2>(__as_int),\n+\t\t      __auto_bitcast(__extract<1, 2>(__as_int))};\n+\t    else\n+\t      __assert_unreachable<_Tp>();\n+\t  }\n+\telse if constexpr (_Np == 2 && sizeof(_I) == 8\n+\t\t\t     && __fixed_size_storage_t<int, _Np>::_S_tuple_size == 2)\n+\t  {\n+\t    const auto __aslong = __vector_bitcast<_LLong>(__tmp);\n+\t    return {int(__aslong[0]), {int(__aslong[1])}};\n+\t  }\n+#if _GLIBCXX_SIMD_X86INTRIN\n+\telse if constexpr (sizeof(_Tp) == 8 && sizeof(__tmp) == 32\n+\t\t\t     && __fixed_size_storage_t<int, _Np>::_S_tuple_size == 1)\n+\t  return {_mm_packs_epi32(__to_intrin(__lo128(__tmp)),\n+\t\t\t\t  __to_intrin(__hi128(__tmp)))};\n+\telse if constexpr (sizeof(_Tp) == 8 && sizeof(__tmp) == 64\n+\t\t\t     && __fixed_size_storage_t<int, _Np>::_S_tuple_size == 1)\n+\t  return {_mm512_cvtepi64_epi32(__to_intrin(__tmp))};\n+#endif // _GLIBCXX_SIMD_X86INTRIN\n+\telse if constexpr (__fixed_size_storage_t<int, _Np>::_S_tuple_size == 1)\n+\t  return {__call_with_subscripts<_Np>(__vector_bitcast<_LLong>(__tmp),\n+\t\t\t\t\t      [](auto... __l) _GLIBCXX_SIMD_ALWAYS_INLINE_LAMBDA {\n+\t\t\t\t\t\treturn __make_wrapper<int>(__l...);\n+\t\t\t\t\t      })};\n+\telse\n+\t  __assert_unreachable<_Tp>();\n+      }\n \n     // _S_increment & _S_decrement{{{2\n     template <typename _Tp, size_t _Np>\n@@ -2703,10 +2695,7 @@ template <typename _Abi, typename>\n     template <typename _Tp>\n       _GLIBCXX_SIMD_INTRINSIC static constexpr _MaskMember<_Tp>\n       _S_broadcast(bool __x)\n-      {\n-\treturn __x ? _Abi::template _S_implicit_mask<_Tp>()\n-\t\t   : _MaskMember<_Tp>();\n-      }\n+      { return __x ? _Abi::template _S_implicit_mask<_Tp>() : _MaskMember<_Tp>(); }\n \n     // }}}\n     // _S_load {{{\n@@ -2808,8 +2797,8 @@ template <typename _Abi, typename>\n \n     // _S_store {{{2\n     template <typename _Tp, size_t _Np>\n-      _GLIBCXX_SIMD_INTRINSIC static void _S_store(_SimdWrapper<_Tp, _Np> __v,\n-\t\t\t\t\t\t   bool* __mem) noexcept\n+      _GLIBCXX_SIMD_INTRINSIC static void\n+      _S_store(_SimdWrapper<_Tp, _Np> __v, bool* __mem) noexcept\n       {\n \t__execute_n_times<_Np>([&](auto __i) constexpr _GLIBCXX_SIMD_ALWAYS_INLINE_LAMBDA {\n \t  __mem[__i] = __v[__i];\n@@ -2832,21 +2821,17 @@ template <typename _Abi, typename>\n     template <size_t _Np, typename _Tp>\n       _GLIBCXX_SIMD_INTRINSIC static _MaskMember<_Tp>\n       _S_from_bitmask(_SanitizedBitMask<_Np> __bits, _TypeTag<_Tp>)\n-      {\n-\treturn _SuperImpl::template _S_to_maskvector<_Tp, _S_size<_Tp>>(__bits);\n-      }\n+      { return _SuperImpl::template _S_to_maskvector<_Tp, _S_size<_Tp>>(__bits); }\n \n     // logical and bitwise operators {{{2\n     template <typename _Tp, size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static constexpr _SimdWrapper<_Tp, _Np>\n-      _S_logical_and(const _SimdWrapper<_Tp, _Np>& __x,\n-\t\t     const _SimdWrapper<_Tp, _Np>& __y)\n+      _S_logical_and(const _SimdWrapper<_Tp, _Np>& __x, const _SimdWrapper<_Tp, _Np>& __y)\n       { return __and(__x._M_data, __y._M_data); }\n \n     template <typename _Tp, size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static constexpr _SimdWrapper<_Tp, _Np>\n-      _S_logical_or(const _SimdWrapper<_Tp, _Np>& __x,\n-\t\t    const _SimdWrapper<_Tp, _Np>& __y)\n+      _S_logical_or(const _SimdWrapper<_Tp, _Np>& __x, const _SimdWrapper<_Tp, _Np>& __y)\n       { return __or(__x._M_data, __y._M_data); }\n \n     template <typename _Tp, size_t _Np>\n@@ -2862,26 +2847,23 @@ template <typename _Abi, typename>\n \n     template <typename _Tp, size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static constexpr _SimdWrapper<_Tp, _Np>\n-      _S_bit_and(const _SimdWrapper<_Tp, _Np>& __x,\n-\t\t const _SimdWrapper<_Tp, _Np>& __y)\n+      _S_bit_and(const _SimdWrapper<_Tp, _Np>& __x, const _SimdWrapper<_Tp, _Np>& __y)\n       { return __and(__x._M_data, __y._M_data); }\n \n     template <typename _Tp, size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static constexpr _SimdWrapper<_Tp, _Np>\n-      _S_bit_or(const _SimdWrapper<_Tp, _Np>& __x,\n-\t\tconst _SimdWrapper<_Tp, _Np>& __y)\n+      _S_bit_or(const _SimdWrapper<_Tp, _Np>& __x, const _SimdWrapper<_Tp, _Np>& __y)\n       { return __or(__x._M_data, __y._M_data); }\n \n     template <typename _Tp, size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static constexpr _SimdWrapper<_Tp, _Np>\n-      _S_bit_xor(const _SimdWrapper<_Tp, _Np>& __x,\n-\t\t const _SimdWrapper<_Tp, _Np>& __y)\n+      _S_bit_xor(const _SimdWrapper<_Tp, _Np>& __x, const _SimdWrapper<_Tp, _Np>& __y)\n       { return __xor(__x._M_data, __y._M_data); }\n \n     // smart_reference access {{{2\n     template <typename _Tp, size_t _Np>\n-      static constexpr void _S_set(_SimdWrapper<_Tp, _Np>& __k, int __i,\n-\t\t\t\t   bool __x) noexcept\n+      static constexpr void\n+      _S_set(_SimdWrapper<_Tp, _Np>& __k, int __i, bool __x) noexcept\n       {\n \tif constexpr (is_same_v<_Tp, bool>)\n \t  __k._M_set(__i, __x);\n@@ -2907,15 +2889,13 @@ template <typename _Abi, typename>\n     // _S_masked_assign{{{2\n     template <typename _Tp, size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static void\n-      _S_masked_assign(_SimdWrapper<_Tp, _Np> __k,\n-\t\t       _SimdWrapper<_Tp, _Np>& __lhs,\n+      _S_masked_assign(_SimdWrapper<_Tp, _Np> __k, _SimdWrapper<_Tp, _Np>& __lhs,\n \t\t       __type_identity_t<_SimdWrapper<_Tp, _Np>> __rhs)\n       { __lhs = _CommonImpl::_S_blend(__k, __lhs, __rhs); }\n \n     template <typename _Tp, size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static void\n-      _S_masked_assign(_SimdWrapper<_Tp, _Np> __k,\n-\t\t       _SimdWrapper<_Tp, _Np>& __lhs, bool __rhs)\n+      _S_masked_assign(_SimdWrapper<_Tp, _Np> __k, _SimdWrapper<_Tp, _Np>& __lhs, bool __rhs)\n       {\n \tif (__builtin_constant_p(__rhs))\n \t  {\n@@ -2995,20 +2975,14 @@ template <typename _Abi, typename>\n     template <typename _Tp>\n       _GLIBCXX_SIMD_INTRINSIC static int\n       _S_find_first_set(simd_mask<_Tp, _Abi> __k)\n-      {\n-\treturn std::__countr_zero(\n-\t  _SuperImpl::_S_to_bits(__data(__k))._M_to_bits());\n-      }\n+      { return std::__countr_zero(_SuperImpl::_S_to_bits(__data(__k))._M_to_bits()); }\n \n     // }}}\n     // _S_find_last_set {{{\n     template <typename _Tp>\n       _GLIBCXX_SIMD_INTRINSIC static int\n       _S_find_last_set(simd_mask<_Tp, _Abi> __k)\n-      {\n-\treturn std::__bit_width(\n-\t  _SuperImpl::_S_to_bits(__data(__k))._M_to_bits()) - 1;\n-      }\n+      { return std::__bit_width(_SuperImpl::_S_to_bits(__data(__k))._M_to_bits()) - 1; }\n \n     // }}}\n   };"}, {"sha": "123e714b52800b69a398af43421bb45d339682c1", "filename": "libstdc++-v3/include/experimental/bits/simd_fixed_size.h", "status": "modified", "additions": 99, "deletions": 129, "changes": 228, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b31186e589caee43ac5720a538d9a41ebf514e81/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_fixed_size.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b31186e589caee43ac5720a538d9a41ebf514e81/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_fixed_size.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_fixed_size.h?ref=b31186e589caee43ac5720a538d9a41ebf514e81", "patch": "@@ -55,10 +55,7 @@ template <typename _Tp, typename _A0, typename... _As>\n \n template <size_t _I, typename _Tp, typename _A0, typename... _As>\n   struct __simd_tuple_element<_I, _SimdTuple<_Tp, _A0, _As...>>\n-  {\n-    using type =\n-      typename __simd_tuple_element<_I - 1, _SimdTuple<_Tp, _As...>>::type;\n-  };\n+  { using type = typename __simd_tuple_element<_I - 1, _SimdTuple<_Tp, _As...>>::type; };\n \n template <size_t _I, typename _Tp>\n   using __simd_tuple_element_t = typename __simd_tuple_element<_I, _Tp>::type;\n@@ -80,10 +77,8 @@ template <typename _Tp, typename... _A0s, typename... _A1s>\n   }\n \n template <typename _Tp, typename _A10, typename... _A1s>\n-  _GLIBCXX_SIMD_INTRINSIC constexpr _SimdTuple<_Tp, simd_abi::scalar, _A10,\n-\t\t\t\t\t       _A1s...>\n-  __simd_tuple_concat(const _Tp& __left,\n-\t\t      const _SimdTuple<_Tp, _A10, _A1s...>& __right)\n+  _GLIBCXX_SIMD_INTRINSIC constexpr _SimdTuple<_Tp, simd_abi::scalar, _A10, _A1s...>\n+  __simd_tuple_concat(const _Tp& __left, const _SimdTuple<_Tp, _A10, _A1s...>& __right)\n   { return {__left, __right}; }\n \n // }}}\n@@ -112,37 +107,29 @@ struct __as_simd_tuple {};\n \n template <typename _Tp, typename _A0, typename... _Abis>\n   _GLIBCXX_SIMD_INTRINSIC constexpr simd<_Tp, _A0>\n-  __simd_tuple_get_impl(__as_simd, const _SimdTuple<_Tp, _A0, _Abis...>& __t,\n-\t\t\t_SizeConstant<0>)\n+  __simd_tuple_get_impl(__as_simd, const _SimdTuple<_Tp, _A0, _Abis...>& __t, _SizeConstant<0>)\n   { return {__private_init, __t.first}; }\n \n template <typename _Tp, typename _A0, typename... _Abis>\n   _GLIBCXX_SIMD_INTRINSIC constexpr const auto&\n-  __simd_tuple_get_impl(__as_simd_tuple,\n-\t\t\tconst _SimdTuple<_Tp, _A0, _Abis...>& __t,\n+  __simd_tuple_get_impl(__as_simd_tuple, const _SimdTuple<_Tp, _A0, _Abis...>& __t,\n \t\t\t_SizeConstant<0>)\n   { return __t.first; }\n \n template <typename _Tp, typename _A0, typename... _Abis>\n   _GLIBCXX_SIMD_INTRINSIC constexpr auto&\n-  __simd_tuple_get_impl(__as_simd_tuple, _SimdTuple<_Tp, _A0, _Abis...>& __t,\n-\t\t\t_SizeConstant<0>)\n+  __simd_tuple_get_impl(__as_simd_tuple, _SimdTuple<_Tp, _A0, _Abis...>& __t, _SizeConstant<0>)\n   { return __t.first; }\n \n template <typename _R, size_t _Np, typename _Tp, typename... _Abis>\n   _GLIBCXX_SIMD_INTRINSIC constexpr auto\n-  __simd_tuple_get_impl(_R, const _SimdTuple<_Tp, _Abis...>& __t,\n-\t\t\t_SizeConstant<_Np>)\n+  __simd_tuple_get_impl(_R, const _SimdTuple<_Tp, _Abis...>& __t, _SizeConstant<_Np>)\n   { return __simd_tuple_get_impl(_R(), __t.second, _SizeConstant<_Np - 1>()); }\n \n template <size_t _Np, typename _Tp, typename... _Abis>\n   _GLIBCXX_SIMD_INTRINSIC constexpr auto&\n-  __simd_tuple_get_impl(__as_simd_tuple, _SimdTuple<_Tp, _Abis...>& __t,\n-\t\t\t_SizeConstant<_Np>)\n-  {\n-    return __simd_tuple_get_impl(__as_simd_tuple(), __t.second,\n-\t\t\t\t _SizeConstant<_Np - 1>());\n-  }\n+  __simd_tuple_get_impl(__as_simd_tuple, _SimdTuple<_Tp, _Abis...>& __t, _SizeConstant<_Np>)\n+  { return __simd_tuple_get_impl(__as_simd_tuple(), __t.second, _SizeConstant<_Np - 1>()); }\n \n template <size_t _Np, typename _Tp, typename... _Abis>\n   _GLIBCXX_SIMD_INTRINSIC constexpr auto\n@@ -154,16 +141,12 @@ template <size_t _Np, typename _Tp, typename... _Abis>\n template <size_t _Np, typename _Tp, typename... _Abis>\n   _GLIBCXX_SIMD_INTRINSIC constexpr auto\n   __get_tuple_at(const _SimdTuple<_Tp, _Abis...>& __t)\n-  {\n-    return __simd_tuple_get_impl(__as_simd_tuple(), __t, _SizeConstant<_Np>());\n-  }\n+  { return __simd_tuple_get_impl(__as_simd_tuple(), __t, _SizeConstant<_Np>()); }\n \n template <size_t _Np, typename _Tp, typename... _Abis>\n   _GLIBCXX_SIMD_INTRINSIC constexpr auto&\n   __get_tuple_at(_SimdTuple<_Tp, _Abis...>& __t)\n-  {\n-    return __simd_tuple_get_impl(__as_simd_tuple(), __t, _SizeConstant<_Np>());\n-  }\n+  { return __simd_tuple_get_impl(__as_simd_tuple(), __t, _SizeConstant<_Np>()); }\n \n // __tuple_element_meta {{{1\n template <typename _Tp, typename _Abi, size_t _Offset>\n@@ -213,17 +196,13 @@ template <size_t _Offset, typename _Base>\n   {\n     static inline constexpr size_t _S_offset = _Offset;\n \n-    _GLIBCXX_SIMD_INTRINSIC char* _M_as_charptr()\n-    {\n-      return reinterpret_cast<char*>(this)\n-\t     + _S_offset * sizeof(typename _Base::value_type);\n-    }\n+    _GLIBCXX_SIMD_INTRINSIC char*\n+    _M_as_charptr()\n+    { return reinterpret_cast<char*>(this) + _S_offset * sizeof(typename _Base::value_type); }\n \n-    _GLIBCXX_SIMD_INTRINSIC const char* _M_as_charptr() const\n-    {\n-      return reinterpret_cast<const char*>(this)\n-\t     + _S_offset * sizeof(typename _Base::value_type);\n-    }\n+    _GLIBCXX_SIMD_INTRINSIC const char*\n+    _M_as_charptr() const\n+    { return reinterpret_cast<const char*>(this) + _S_offset * sizeof(typename _Base::value_type); }\n   };\n \n // make _WithOffset<_WithOffset> ill-formed to use:\n@@ -240,19 +219,13 @@ template <size_t _Offset, typename _Tp>\n   _GLIBCXX_SIMD_INTRINSIC\n   decltype(auto)\n   __add_offset(const _Tp& __base)\n-  {\n-    return static_cast<const _WithOffset<_Offset, __remove_cvref_t<_Tp>>&>(\n-      __base);\n-  }\n+  { return static_cast<const _WithOffset<_Offset, __remove_cvref_t<_Tp>>&>(__base); }\n \n template <size_t _Offset, size_t _ExistingOffset, typename _Tp>\n   _GLIBCXX_SIMD_INTRINSIC\n   decltype(auto)\n   __add_offset(_WithOffset<_ExistingOffset, _Tp>& __base)\n-  {\n-    return static_cast<_WithOffset<_Offset + _ExistingOffset, _Tp>&>(\n-      static_cast<_Tp&>(__base));\n-  }\n+  { return static_cast<_WithOffset<_Offset + _ExistingOffset, _Tp>&>(static_cast<_Tp&>(__base)); }\n \n template <size_t _Offset, size_t _ExistingOffset, typename _Tp>\n   _GLIBCXX_SIMD_INTRINSIC\n@@ -298,7 +271,8 @@ template <typename _FirstType, typename _SecondType>\n     _SecondType second;\n \n     _GLIBCXX_SIMD_INTRINSIC\n-    constexpr bool _M_is_constprop() const\n+    constexpr bool\n+    _M_is_constprop() const\n     {\n       if constexpr (is_class_v<_FirstType>)\n \treturn first._M_is_constprop() && second._M_is_constprop();\n@@ -314,7 +288,8 @@ template <typename _FirstType, typename _Tp>\n     static constexpr _SimdTuple<_Tp> second = {};\n \n     _GLIBCXX_SIMD_INTRINSIC\n-    constexpr bool _M_is_constprop() const\n+    constexpr bool\n+    _M_is_constprop() const\n     {\n       if constexpr (is_class_v<_FirstType>)\n \treturn first._M_is_constprop();\n@@ -353,25 +328,31 @@ template <typename _Tp, typename _Abi0, typename... _Abis>\n       = default;\n \n     template <typename _Up>\n-      _GLIBCXX_SIMD_INTRINSIC constexpr _SimdTuple(_Up&& __x)\n+      _GLIBCXX_SIMD_INTRINSIC constexpr\n+      _SimdTuple(_Up&& __x)\n       : _Base{static_cast<_Up&&>(__x)} {}\n \n     template <typename _Up, typename _Up2>\n-      _GLIBCXX_SIMD_INTRINSIC constexpr _SimdTuple(_Up&& __x, _Up2&& __y)\n+      _GLIBCXX_SIMD_INTRINSIC constexpr\n+      _SimdTuple(_Up&& __x, _Up2&& __y)\n       : _Base{static_cast<_Up&&>(__x), static_cast<_Up2&&>(__y)} {}\n \n     template <typename _Up>\n-      _GLIBCXX_SIMD_INTRINSIC constexpr _SimdTuple(_Up&& __x, _SimdTuple<_Tp>)\n+      _GLIBCXX_SIMD_INTRINSIC constexpr\n+      _SimdTuple(_Up&& __x, _SimdTuple<_Tp>)\n       : _Base{static_cast<_Up&&>(__x)} {}\n \n-    _GLIBCXX_SIMD_INTRINSIC char* _M_as_charptr()\n+    _GLIBCXX_SIMD_INTRINSIC char*\n+    _M_as_charptr()\n     { return reinterpret_cast<char*>(this); }\n \n-    _GLIBCXX_SIMD_INTRINSIC const char* _M_as_charptr() const\n+    _GLIBCXX_SIMD_INTRINSIC const char*\n+    _M_as_charptr() const\n     { return reinterpret_cast<const char*>(this); }\n \n     template <size_t _Np>\n-      _GLIBCXX_SIMD_INTRINSIC constexpr auto& _M_at()\n+      _GLIBCXX_SIMD_INTRINSIC constexpr auto&\n+      _M_at()\n       {\n \tif constexpr (_Np == 0)\n \t  return first;\n@@ -380,7 +361,8 @@ template <typename _Tp, typename _Abi0, typename... _Abis>\n       }\n \n     template <size_t _Np>\n-      _GLIBCXX_SIMD_INTRINSIC constexpr const auto& _M_at() const\n+      _GLIBCXX_SIMD_INTRINSIC constexpr const auto&\n+      _M_at() const\n       {\n \tif constexpr (_Np == 0)\n \t  return first;\n@@ -389,7 +371,8 @@ template <typename _Tp, typename _Abi0, typename... _Abis>\n       }\n \n     template <size_t _Np>\n-      _GLIBCXX_SIMD_INTRINSIC constexpr auto _M_simd_at() const\n+      _GLIBCXX_SIMD_INTRINSIC constexpr auto\n+      _M_simd_at() const\n       {\n \tif constexpr (_Np == 0)\n \t  return simd<_Tp, _Abi0>(__private_init, first);\n@@ -552,8 +535,8 @@ template <typename _Tp, typename _Abi0, typename... _Abis>\n       }\n \n     template <typename _R = _Tp, typename _Fp, typename... _More>\n-      _GLIBCXX_SIMD_INTRINSIC auto _M_apply_r(_Fp&& __fun,\n-\t\t\t\t\t      const _More&... __more) const\n+      _GLIBCXX_SIMD_INTRINSIC auto\n+      _M_apply_r(_Fp&& __fun, const _More&... __more) const\n       {\n \tauto&& __first = __fun(__tuple_element_meta<_Tp, _Abi0, 0>(), first,\n \t\t\t       __more.first...);\n@@ -590,8 +573,8 @@ template <typename _Tp, typename _Abi0, typename... _Abis>\n \t  return second[integral_constant<_Up, _I - simd_size_v<_Tp, _Abi0>>()];\n       }\n \n-    _GLIBCXX_SIMD_INTRINSIC\n-    _Tp operator[](size_t __i) const noexcept\n+    _GLIBCXX_SIMD_INTRINSIC _Tp\n+    operator[](size_t __i) const noexcept\n     {\n       if constexpr (_S_tuple_size == 1)\n \treturn _M_subscript_read(__i);\n@@ -613,8 +596,8 @@ template <typename _Tp, typename _Abi0, typename... _Abis>\n \t}\n     }\n \n-    _GLIBCXX_SIMD_INTRINSIC\n-    void _M_set(size_t __i, _Tp __val) noexcept\n+    _GLIBCXX_SIMD_INTRINSIC void\n+    _M_set(size_t __i, _Tp __val) noexcept\n     {\n       if constexpr (_S_tuple_size == 1)\n \treturn _M_subscript_write(__i, __val);\n@@ -633,17 +616,17 @@ template <typename _Tp, typename _Abi0, typename... _Abis>\n \n   private:\n     // _M_subscript_read/_write {{{\n-    _GLIBCXX_SIMD_INTRINSIC\n-    _Tp _M_subscript_read([[maybe_unused]] size_t __i) const noexcept\n+    _GLIBCXX_SIMD_INTRINSIC _Tp\n+    _M_subscript_read([[maybe_unused]] size_t __i) const noexcept\n     {\n       if constexpr (__is_vectorizable_v<_FirstType>)\n \treturn first;\n       else\n \treturn first[__i];\n     }\n \n-    _GLIBCXX_SIMD_INTRINSIC\n-    void _M_subscript_write([[maybe_unused]] size_t __i, _Tp __y) noexcept\n+    _GLIBCXX_SIMD_INTRINSIC void\n+    _M_subscript_write([[maybe_unused]] size_t __i, _Tp __y) noexcept\n     {\n       if constexpr (__is_vectorizable_v<_FirstType>)\n \tfirst = __y;\n@@ -687,8 +670,7 @@ template <typename _Tp, size_t _Np,\n \t  size_t _Offset = 0, // skip this many elements in __from0\n \t  typename _R = __fixed_size_storage_t<_Tp, _Np>, typename _V0,\n \t  typename _V0VT = _VectorTraits<_V0>, typename... _VX>\n-  _GLIBCXX_SIMD_INTRINSIC _R constexpr __to_simd_tuple(const _V0 __from0,\n-\t\t\t\t\t\t       const _VX... __fromX)\n+  _GLIBCXX_SIMD_INTRINSIC _R constexpr __to_simd_tuple(const _V0 __from0, const _VX... __fromX)\n   {\n     static_assert(is_same_v<typename _V0VT::value_type, _Tp>);\n     static_assert(_Offset < _V0VT::_S_full_size);\n@@ -900,11 +882,8 @@ template <size_t _Offset = 0, typename _Tp, typename _A0, typename _A1,\n // __for_each(_SimdTuple &, const _SimdTuple &, Fun) {{{1\n template <size_t _Offset = 0, typename _Tp, typename _A0, typename _Fp>\n   _GLIBCXX_SIMD_INTRINSIC constexpr void\n-  __for_each(_SimdTuple<_Tp, _A0>& __a, const _SimdTuple<_Tp, _A0>& __b,\n-\t     _Fp&& __fun)\n-  {\n-    static_cast<_Fp&&>(__fun)(__make_meta<_Offset>(__a), __a.first, __b.first);\n-  }\n+  __for_each(_SimdTuple<_Tp, _A0>& __a, const _SimdTuple<_Tp, _A0>& __b, _Fp&& __fun)\n+  { static_cast<_Fp&&>(__fun)(__make_meta<_Offset>(__a), __a.first, __b.first); }\n \n template <size_t _Offset = 0, typename _Tp, typename _A0, typename _A1,\n \t  typename... _As, typename _Fp>\n@@ -920,11 +899,8 @@ template <size_t _Offset = 0, typename _Tp, typename _A0, typename _A1,\n // __for_each(const _SimdTuple &, const _SimdTuple &, Fun) {{{1\n template <size_t _Offset = 0, typename _Tp, typename _A0, typename _Fp>\n   _GLIBCXX_SIMD_INTRINSIC constexpr void\n-  __for_each(const _SimdTuple<_Tp, _A0>& __a, const _SimdTuple<_Tp, _A0>& __b,\n-\t     _Fp&& __fun)\n-  {\n-    static_cast<_Fp&&>(__fun)(__make_meta<_Offset>(__a), __a.first, __b.first);\n-  }\n+  __for_each(const _SimdTuple<_Tp, _A0>& __a, const _SimdTuple<_Tp, _A0>& __b, _Fp&& __fun)\n+  { static_cast<_Fp&&>(__fun)(__make_meta<_Offset>(__a), __a.first, __b.first); }\n \n template <size_t _Offset = 0, typename _Tp, typename _A0, typename _A1,\n \t  typename... _As, typename _Fp>\n@@ -939,8 +915,7 @@ template <size_t _Offset = 0, typename _Tp, typename _A0, typename _A1,\n \n // }}}1\n // __extract_part(_SimdTuple) {{{\n-template <int _Index, int _Total, int _Combine, typename _Tp, typename _A0,\n-\t  typename... _As>\n+template <int _Index, int _Total, int _Combine, typename _Tp, typename _A0, typename... _As>\n   _GLIBCXX_SIMD_INTRINSIC auto // __vector_type_t or _SimdTuple\n   __extract_part(const _SimdTuple<_Tp, _A0, _As...>& __x)\n   {\n@@ -1062,8 +1037,8 @@ template <typename _Tp, bool = is_arithmetic_v<__remove_cvref_t<_Tp>>>\n       return &_M_data;\n     }\n \n-    _GLIBCXX_SIMD_INTRINSIC\n-    constexpr __autocvt_to_simd(_Tp dd) : _M_data(dd) {}\n+    _GLIBCXX_SIMD_INTRINSIC constexpr\n+    __autocvt_to_simd(_Tp dd) : _M_data(dd) {}\n \n     template <typename _Abi>\n       _GLIBCXX_SIMD_INTRINSIC\n@@ -1073,18 +1048,12 @@ template <typename _Tp, bool = is_arithmetic_v<__remove_cvref_t<_Tp>>>\n     template <typename _Abi>\n       _GLIBCXX_SIMD_INTRINSIC\n       operator simd<typename _TT::value_type, _Abi>&()\n-      {\n-\treturn *reinterpret_cast<simd<typename _TT::value_type, _Abi>*>(\n-\t  &_M_data);\n-      }\n+      { return *reinterpret_cast<simd<typename _TT::value_type, _Abi>*>(&_M_data); }\n \n     template <typename _Abi>\n       _GLIBCXX_SIMD_INTRINSIC\n       operator simd<typename _TT::value_type, _Abi>*()\n-      {\n-\treturn reinterpret_cast<simd<typename _TT::value_type, _Abi>*>(\n-\t  &_M_data);\n-      }\n+      { return reinterpret_cast<simd<typename _TT::value_type, _Abi>*>(&_M_data); }\n   };\n \n template <typename _Tp>\n@@ -1197,12 +1166,12 @@ template <int _Np>\n \t  _SimdBase(const _SimdBase&) {}\n \t  _SimdBase() = default;\n \n-\t  _GLIBCXX_SIMD_ALWAYS_INLINE\n-\t  explicit operator const _SimdMember &() const\n+\t  _GLIBCXX_SIMD_ALWAYS_INLINE explicit\n+\t  operator const _SimdMember &() const\n \t  { return static_cast<const simd<_Tp, _Fixed>*>(this)->_M_data; }\n \n-\t  _GLIBCXX_SIMD_ALWAYS_INLINE\n-\t  explicit operator array<_Tp, _Np>() const\n+\t  _GLIBCXX_SIMD_ALWAYS_INLINE explicit\n+\t  operator array<_Tp, _Np>() const\n \t  {\n \t    array<_Tp, _Np> __r;\n \t    // _SimdMember can be larger because of higher alignment\n@@ -1224,10 +1193,12 @@ template <int _Np>\n \t{\n \t  _GLIBCXX_SIMD_ALWAYS_INLINE\n \t  _SimdCastType(const array<_Tp, _Np>&);\n+\n \t  _GLIBCXX_SIMD_ALWAYS_INLINE\n \t  _SimdCastType(const _SimdMember& dd) : _M_data(dd) {}\n-\t  _GLIBCXX_SIMD_ALWAYS_INLINE\n-\t  explicit operator const _SimdMember &() const { return _M_data; }\n+\n+\t  _GLIBCXX_SIMD_ALWAYS_INLINE explicit\n+\t  operator const _SimdMember &() const { return _M_data; }\n \n \tprivate:\n \t  const _SimdMember& _M_data;\n@@ -1466,8 +1437,7 @@ template <int _Np, typename>\n     // _S_min, _S_max {{{2\n     template <typename _Tp, typename... _As>\n       _GLIBCXX_SIMD_INTRINSIC static constexpr _SimdTuple<_Tp, _As...>\n-      _S_min(const _SimdTuple<_Tp, _As...>& __a,\n-\t     const _SimdTuple<_Tp, _As...>& __b)\n+      _S_min(const _SimdTuple<_Tp, _As...>& __a, const _SimdTuple<_Tp, _As...>& __b)\n       {\n \treturn __a._M_apply_per_chunk(\n \t  [](auto __impl, auto __aa, auto __bb) constexpr _GLIBCXX_SIMD_ALWAYS_INLINE_LAMBDA {\n@@ -1478,8 +1448,7 @@ template <int _Np, typename>\n \n     template <typename _Tp, typename... _As>\n       _GLIBCXX_SIMD_INTRINSIC static constexpr _SimdTuple<_Tp, _As...>\n-      _S_max(const _SimdTuple<_Tp, _As...>& __a,\n-\t     const _SimdTuple<_Tp, _As...>& __b)\n+      _S_max(const _SimdTuple<_Tp, _As...>& __a, const _SimdTuple<_Tp, _As...>& __b)\n       {\n \treturn __a._M_apply_per_chunk(\n \t  [](auto __impl, auto __aa, auto __bb) constexpr _GLIBCXX_SIMD_ALWAYS_INLINE_LAMBDA {\n@@ -1692,7 +1661,7 @@ template <int _Np, typename>\n #define _GLIBCXX_SIMD_TEST_ON_TUPLE_(name_)                                              \\\n     template <typename _Tp, typename... _As>                                             \\\n       static inline _MaskMember                                                          \\\n-\t_S_##name_(const _SimdTuple<_Tp, _As...>& __x) noexcept                          \\\n+      _S_##name_(const _SimdTuple<_Tp, _As...>& __x) noexcept                            \\\n       {                                                                                  \\\n \treturn _M_test([] (auto __impl, auto __xx) _GLIBCXX_SIMD_ALWAYS_INLINE_LAMBDA  { \\\n \t\t return __impl._S_##name_(__xx);                                         \\\n@@ -1754,8 +1723,8 @@ template <int _Np, typename>\n \n     // smart_reference access {{{2\n     template <typename _Tp, typename... _As, typename _Up>\n-      _GLIBCXX_SIMD_INTRINSIC static void _S_set(_SimdTuple<_Tp, _As...>& __v,\n-\t\t\t\t\t\t int __i, _Up&& __x) noexcept\n+      _GLIBCXX_SIMD_INTRINSIC static void\n+      _S_set(_SimdTuple<_Tp, _As...>& __v, int __i, _Up&& __x) noexcept\n       { __v._M_set(__i, static_cast<_Up&&>(__x)); }\n \n     // _S_masked_assign {{{2\n@@ -1789,10 +1758,9 @@ template <int _Np, typename>\n \n     // _S_masked_cassign {{{2\n     template <typename _Op, typename _Tp, typename... _As>\n-      static inline void _S_masked_cassign(const _MaskMember __bits,\n-\t\t\t\t\t   _SimdTuple<_Tp, _As...>& __lhs,\n-\t\t\t\t\t   const _SimdTuple<_Tp, _As...>& __rhs,\n-\t\t\t\t\t   _Op __op)\n+      static inline void\n+      _S_masked_cassign(const _MaskMember __bits, _SimdTuple<_Tp, _As...>& __lhs,\n+\t\t\tconst _SimdTuple<_Tp, _As...>& __rhs, _Op __op)\n       {\n \t__for_each(__lhs, __rhs,\n \t\t   [&](auto __meta, auto& __native_lhs, auto __native_rhs)\n@@ -1806,9 +1774,9 @@ template <int _Np, typename>\n     // Optimization for the case where the RHS is a scalar. No need to broadcast\n     // the scalar to a simd first.\n     template <typename _Op, typename _Tp, typename... _As>\n-      static inline void _S_masked_cassign(const _MaskMember __bits,\n-\t\t\t\t\t   _SimdTuple<_Tp, _As...>& __lhs,\n-\t\t\t\t\t   const _Tp& __rhs, _Op __op)\n+      static inline void\n+      _S_masked_cassign(const _MaskMember __bits, _SimdTuple<_Tp, _As...>& __lhs,\n+\t\t\tconst _Tp& __rhs, _Op __op)\n       {\n \t__for_each(\n \t  __lhs, [&](auto __meta, auto& __native_lhs) constexpr _GLIBCXX_SIMD_ALWAYS_INLINE_LAMBDA {\n@@ -1906,7 +1874,8 @@ template <int _Np, typename>\n       { return __bits; }\n \n     // _S_load {{{2\n-    static inline _MaskMember _S_load(const bool* __mem) noexcept\n+    static inline _MaskMember\n+    _S_load(const bool* __mem) noexcept\n     {\n       // TODO: _UChar is not necessarily the best type to use here. For smaller\n       // _Np _UShort, _UInt, _ULLong, float, and double can be more efficient.\n@@ -1921,9 +1890,8 @@ template <int _Np, typename>\n     }\n \n     // _S_masked_load {{{2\n-    static inline _MaskMember _S_masked_load(_MaskMember __merge,\n-\t\t\t\t\t     _MaskMember __mask,\n-\t\t\t\t\t     const bool* __mem) noexcept\n+    static inline _MaskMember\n+    _S_masked_load(_MaskMember __merge, _MaskMember __mask, const bool* __mem) noexcept\n     {\n       _BitOps::_S_bit_iteration(__mask.to_ullong(),\n \t\t\t\t[&](auto __i) _GLIBCXX_SIMD_ALWAYS_INLINE_LAMBDA {\n@@ -1933,8 +1901,8 @@ template <int _Np, typename>\n     }\n \n     // _S_store {{{2\n-    static inline void _S_store(const _MaskMember __bitmask,\n-\t\t\t\tbool* __mem) noexcept\n+    static inline void\n+    _S_store(const _MaskMember __bitmask, bool* __mem) noexcept\n     {\n       if constexpr (_Np == 1)\n \t__mem[0] = __bitmask[0];\n@@ -1943,8 +1911,8 @@ template <int _Np, typename>\n     }\n \n     // _S_masked_store {{{2\n-    static inline void _S_masked_store(const _MaskMember __v, bool* __mem,\n-\t\t\t\t       const _MaskMember __k) noexcept\n+    static inline void\n+    _S_masked_store(const _MaskMember __v, bool* __mem, const _MaskMember __k) noexcept\n     {\n       _BitOps::_S_bit_iteration(\n \t__k, [&](auto __i) _GLIBCXX_SIMD_ALWAYS_INLINE_LAMBDA { __mem[__i] = __v[__i]; });\n@@ -1976,20 +1944,18 @@ template <int _Np, typename>\n     { return __x ^ __y; }\n \n     // smart_reference access {{{2\n-    _GLIBCXX_SIMD_INTRINSIC static void _S_set(_MaskMember& __k, int __i,\n-\t\t\t\t\t       bool __x) noexcept\n+    _GLIBCXX_SIMD_INTRINSIC static void\n+    _S_set(_MaskMember& __k, int __i, bool __x) noexcept\n     { __k.set(__i, __x); }\n \n     // _S_masked_assign {{{2\n     _GLIBCXX_SIMD_INTRINSIC static void\n-    _S_masked_assign(const _MaskMember __k, _MaskMember& __lhs,\n-\t\t     const _MaskMember __rhs)\n+    _S_masked_assign(const _MaskMember __k, _MaskMember& __lhs, const _MaskMember __rhs)\n     { __lhs = (__lhs & ~__k) | (__rhs & __k); }\n \n     // Optimization for the case where the RHS is a scalar.\n-    _GLIBCXX_SIMD_INTRINSIC static void _S_masked_assign(const _MaskMember __k,\n-\t\t\t\t\t\t\t _MaskMember& __lhs,\n-\t\t\t\t\t\t\t const bool __rhs)\n+    _GLIBCXX_SIMD_INTRINSIC static void\n+    _S_masked_assign(const _MaskMember __k, _MaskMember& __lhs, const bool __rhs)\n     {\n       if (__rhs)\n \t__lhs |= __k;\n@@ -2000,19 +1966,22 @@ template <int _Np, typename>\n     // }}}2\n     // _S_all_of {{{\n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static bool _S_all_of(simd_mask<_Tp, _Abi> __k)\n+      _GLIBCXX_SIMD_INTRINSIC static bool\n+      _S_all_of(simd_mask<_Tp, _Abi> __k)\n       { return __data(__k).all(); }\n \n     // }}}\n     // _S_any_of {{{\n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static bool _S_any_of(simd_mask<_Tp, _Abi> __k)\n+      _GLIBCXX_SIMD_INTRINSIC static bool\n+      _S_any_of(simd_mask<_Tp, _Abi> __k)\n       { return __data(__k).any(); }\n \n     // }}}\n     // _S_none_of {{{\n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static bool _S_none_of(simd_mask<_Tp, _Abi> __k)\n+      _GLIBCXX_SIMD_INTRINSIC static bool\n+      _S_none_of(simd_mask<_Tp, _Abi> __k)\n       { return __data(__k).none(); }\n \n     // }}}\n@@ -2030,7 +1999,8 @@ template <int _Np, typename>\n     // }}}\n     // _S_popcount {{{\n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static int _S_popcount(simd_mask<_Tp, _Abi> __k)\n+      _GLIBCXX_SIMD_INTRINSIC static int\n+      _S_popcount(simd_mask<_Tp, _Abi> __k)\n       { return __data(__k).count(); }\n \n     // }}}"}, {"sha": "637b121b1307e58742eb10e7943cce2a63337fa9", "filename": "libstdc++-v3/include/experimental/bits/simd_neon.h", "status": "modified", "additions": 16, "deletions": 8, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b31186e589caee43ac5720a538d9a41ebf514e81/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b31186e589caee43ac5720a538d9a41ebf514e81/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_neon.h?ref=b31186e589caee43ac5720a538d9a41ebf514e81", "patch": "@@ -134,7 +134,8 @@ template <typename _Abi, typename>\n     // math {{{\n     // _S_sqrt {{{\n     template <typename _Tp, typename _TVT = _VectorTraits<_Tp>>\n-      _GLIBCXX_SIMD_INTRINSIC static _Tp _S_sqrt(_Tp __x)\n+      _GLIBCXX_SIMD_INTRINSIC static _Tp\n+      _S_sqrt(_Tp __x)\n       {\n \tif constexpr (__have_neon_a64)\n \t  {\n@@ -157,7 +158,8 @@ template <typename _Abi, typename>\n     // }}}\n     // _S_trunc {{{\n     template <typename _TW, typename _TVT = _VectorTraits<_TW>>\n-      _GLIBCXX_SIMD_INTRINSIC static _TW _S_trunc(_TW __x)\n+      _GLIBCXX_SIMD_INTRINSIC static _TW\n+      _S_trunc(_TW __x)\n       {\n \tusing _Tp = typename _TVT::value_type;\n \tif constexpr (__have_neon_a32)\n@@ -216,7 +218,8 @@ template <typename _Abi, typename>\n     // }}}\n     // _S_floor {{{\n     template <typename _Tp, typename _TVT = _VectorTraits<_Tp>>\n-      _GLIBCXX_SIMD_INTRINSIC static _Tp _S_floor(_Tp __x)\n+      _GLIBCXX_SIMD_INTRINSIC static _Tp\n+      _S_floor(_Tp __x)\n       {\n \tif constexpr (__have_neon_a32)\n \t  {\n@@ -239,7 +242,8 @@ template <typename _Abi, typename>\n     // }}}\n     // _S_ceil {{{\n     template <typename _Tp, typename _TVT = _VectorTraits<_Tp>>\n-      _GLIBCXX_SIMD_INTRINSIC static _Tp _S_ceil(_Tp __x)\n+      _GLIBCXX_SIMD_INTRINSIC static _Tp\n+      _S_ceil(_Tp __x)\n       {\n \tif constexpr (__have_neon_a32)\n \t  {\n@@ -400,7 +404,8 @@ template <typename _Abi, typename>\n \n     // _S_all_of {{{\n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static bool _S_all_of(simd_mask<_Tp, _Abi> __k)\n+      _GLIBCXX_SIMD_INTRINSIC static bool\n+      _S_all_of(simd_mask<_Tp, _Abi> __k)\n       {\n \tconst auto __kk\n \t  = __vector_bitcast<char>(__k._M_data)\n@@ -419,7 +424,8 @@ template <typename _Abi, typename>\n     // }}}\n     // _S_any_of {{{\n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static bool _S_any_of(simd_mask<_Tp, _Abi> __k)\n+      _GLIBCXX_SIMD_INTRINSIC static bool\n+      _S_any_of(simd_mask<_Tp, _Abi> __k)\n       {\n \tconst auto __kk\n \t  = __vector_bitcast<char>(__k._M_data)\n@@ -438,7 +444,8 @@ template <typename _Abi, typename>\n     // }}}\n     // _S_none_of {{{\n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static bool _S_none_of(simd_mask<_Tp, _Abi> __k)\n+      _GLIBCXX_SIMD_INTRINSIC static bool\n+      _S_none_of(simd_mask<_Tp, _Abi> __k)\n       {\n \tconst auto __kk = _Abi::_S_masked(__k._M_data);\n \tif constexpr (sizeof(__k) == 16)\n@@ -472,7 +479,8 @@ template <typename _Abi, typename>\n     // }}}\n     // _S_popcount {{{\n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static int _S_popcount(simd_mask<_Tp, _Abi> __k)\n+      _GLIBCXX_SIMD_INTRINSIC static int\n+      _S_popcount(simd_mask<_Tp, _Abi> __k)\n       {\n \tif constexpr (sizeof(_Tp) == 1)\n \t  {"}, {"sha": "eca1b34241bb4efdbbb6490550750d81aee248b3", "filename": "libstdc++-v3/include/experimental/bits/simd_ppc.h", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b31186e589caee43ac5720a538d9a41ebf514e81/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_ppc.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b31186e589caee43ac5720a538d9a41ebf514e81/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_ppc.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_ppc.h?ref=b31186e589caee43ac5720a538d9a41ebf514e81", "patch": "@@ -124,7 +124,8 @@ template <typename _Abi, typename>\n \n     // _S_popcount {{{\n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static int _S_popcount(simd_mask<_Tp, _Abi> __k)\n+      _GLIBCXX_SIMD_INTRINSIC static int\n+      _S_popcount(simd_mask<_Tp, _Abi> __k)\n       {\n \tconst auto __kv = __as_vector(__k);\n \tif constexpr (__have_power10vec)"}, {"sha": "1a1cc46fbe0385e05091f2e85a5483b53ff17c25", "filename": "libstdc++-v3/include/experimental/bits/simd_scalar.h", "status": "modified", "additions": 213, "deletions": 149, "changes": 362, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b31186e589caee43ac5720a538d9a41ebf514e81/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_scalar.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b31186e589caee43ac5720a538d9a41ebf514e81/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_scalar.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_scalar.h?ref=b31186e589caee43ac5720a538d9a41ebf514e81", "patch": "@@ -74,7 +74,8 @@ struct simd_abi::_Scalar\n   template <typename _Tp>\n     static constexpr bool _S_is_valid_v = _IsValid<_Tp>::value;\n \n-  _GLIBCXX_SIMD_INTRINSIC static constexpr bool _S_masked(bool __x)\n+  _GLIBCXX_SIMD_INTRINSIC static constexpr bool\n+  _S_masked(bool __x)\n   { return __x; }\n \n   using _CommonImpl = _CommonImplScalar;\n@@ -110,7 +111,8 @@ struct _CommonImplScalar\n {\n   // _S_store {{{\n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static void _S_store(_Tp __x, void* __addr)\n+    _GLIBCXX_SIMD_INTRINSIC static void\n+    _S_store(_Tp __x, void* __addr)\n     { __builtin_memcpy(__addr, &__x, sizeof(_Tp)); }\n \n   // }}}\n@@ -138,26 +140,26 @@ struct _SimdImplScalar\n \n   // _S_broadcast {{{2\n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp _S_broadcast(_Tp __x) noexcept\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_broadcast(_Tp __x) noexcept\n     { return __x; }\n \n   // _S_generator {{{2\n   template <typename _Fp, typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp _S_generator(_Fp&& __gen,\n-\t\t\t\t\t\t\t      _TypeTag<_Tp>)\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_generator(_Fp&& __gen, _TypeTag<_Tp>)\n     { return __gen(_SizeConstant<0>()); }\n \n   // _S_load {{{2\n   template <typename _Tp, typename _Up>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_load(const _Up* __mem,\n-\t\t\t\t\t       _TypeTag<_Tp>) noexcept\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_load(const _Up* __mem, _TypeTag<_Tp>) noexcept\n     { return static_cast<_Tp>(__mem[0]); }\n \n   // _S_masked_load {{{2\n   template <typename _Tp, typename _Up>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static _Tp _S_masked_load(_Tp __merge, bool __k,\n-\t\t\t\t     const _Up* __mem) noexcept\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_masked_load(_Tp __merge, bool __k, const _Up* __mem) noexcept\n     {\n       if (__k)\n \t__merge = static_cast<_Tp>(__mem[0]);\n@@ -166,97 +168,95 @@ struct _SimdImplScalar\n \n   // _S_store {{{2\n   template <typename _Tp, typename _Up>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static void _S_store(_Tp __v, _Up* __mem, _TypeTag<_Tp>) noexcept\n+    _GLIBCXX_SIMD_INTRINSIC static void\n+    _S_store(_Tp __v, _Up* __mem, _TypeTag<_Tp>) noexcept\n     { __mem[0] = static_cast<_Up>(__v); }\n \n   // _S_masked_store {{{2\n   template <typename _Tp, typename _Up>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static void _S_masked_store(const _Tp __v, _Up* __mem,\n-\t\t\t\t       const bool __k) noexcept\n+    _GLIBCXX_SIMD_INTRINSIC static void\n+    _S_masked_store(const _Tp __v, _Up* __mem, const bool __k) noexcept\n     { if (__k) __mem[0] = __v; }\n \n   // _S_negate {{{2\n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr bool _S_negate(_Tp __x) noexcept\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr bool\n+    _S_negate(_Tp __x) noexcept\n     { return !__x; }\n \n   // _S_reduce {{{2\n   template <typename _Tp, typename _BinaryOperation>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr _Tp\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n     _S_reduce(const simd<_Tp, simd_abi::scalar>& __x, const _BinaryOperation&)\n     { return __x._M_data; }\n \n   // _S_min, _S_max {{{2\n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr _Tp _S_min(const _Tp __a, const _Tp __b)\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_min(const _Tp __a, const _Tp __b)\n     { return std::min(__a, __b); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr _Tp _S_max(const _Tp __a, const _Tp __b)\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_max(const _Tp __a, const _Tp __b)\n     { return std::max(__a, __b); }\n \n   // _S_complement {{{2\n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr _Tp _S_complement(_Tp __x) noexcept\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_complement(_Tp __x) noexcept\n     { return static_cast<_Tp>(~__x); }\n \n   // _S_unary_minus {{{2\n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr _Tp _S_unary_minus(_Tp __x) noexcept\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_unary_minus(_Tp __x) noexcept\n     { return static_cast<_Tp>(-__x); }\n \n   // arithmetic operators {{{2\n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr _Tp _S_plus(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_plus(_Tp __x, _Tp __y)\n     {\n       return static_cast<_Tp>(__promote_preserving_unsigned(__x)\n \t\t\t      + __promote_preserving_unsigned(__y));\n     }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr _Tp _S_minus(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_minus(_Tp __x, _Tp __y)\n     {\n       return static_cast<_Tp>(__promote_preserving_unsigned(__x)\n \t\t\t      - __promote_preserving_unsigned(__y));\n     }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr _Tp _S_multiplies(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_multiplies(_Tp __x, _Tp __y)\n     {\n       return static_cast<_Tp>(__promote_preserving_unsigned(__x)\n \t\t\t      * __promote_preserving_unsigned(__y));\n     }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr _Tp _S_divides(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_divides(_Tp __x, _Tp __y)\n     {\n       return static_cast<_Tp>(__promote_preserving_unsigned(__x)\n \t\t\t      / __promote_preserving_unsigned(__y));\n     }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr _Tp _S_modulus(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_modulus(_Tp __x, _Tp __y)\n     {\n       return static_cast<_Tp>(__promote_preserving_unsigned(__x)\n \t\t\t      % __promote_preserving_unsigned(__y));\n     }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr _Tp _S_bit_and(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_bit_and(_Tp __x, _Tp __y)\n     {\n       if constexpr (is_floating_point_v<_Tp>)\n \t{\n@@ -269,8 +269,8 @@ struct _SimdImplScalar\n     }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr _Tp _S_bit_or(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_bit_or(_Tp __x, _Tp __y)\n     {\n       if constexpr (is_floating_point_v<_Tp>)\n \t{\n@@ -283,8 +283,8 @@ struct _SimdImplScalar\n     }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr _Tp _S_bit_xor(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_bit_xor(_Tp __x, _Tp __y)\n     {\n       if constexpr (is_floating_point_v<_Tp>)\n \t{\n@@ -297,13 +297,13 @@ struct _SimdImplScalar\n     }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr _Tp _S_bit_shift_left(_Tp __x, int __y)\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_bit_shift_left(_Tp __x, int __y)\n     { return static_cast<_Tp>(__promote_preserving_unsigned(__x) << __y); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    static constexpr _Tp _S_bit_shift_right(_Tp __x, int __y)\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr _Tp\n+    _S_bit_shift_right(_Tp __x, int __y)\n     { return static_cast<_Tp>(__promote_preserving_unsigned(__x) >> __y); }\n \n   // math {{{2\n@@ -312,300 +312,362 @@ struct _SimdImplScalar\n     using _ST = _SimdTuple<_Tp, simd_abi::scalar>;\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_acos(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_acos(_Tp __x)\n     { return std::acos(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_asin(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_asin(_Tp __x)\n     { return std::asin(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_atan(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_atan(_Tp __x)\n     { return std::atan(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_cos(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_cos(_Tp __x)\n     { return std::cos(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_sin(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_sin(_Tp __x)\n     { return std::sin(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_tan(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_tan(_Tp __x)\n     { return std::tan(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_acosh(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_acosh(_Tp __x)\n     { return std::acosh(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_asinh(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_asinh(_Tp __x)\n     { return std::asinh(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_atanh(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_atanh(_Tp __x)\n     { return std::atanh(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_cosh(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_cosh(_Tp __x)\n     { return std::cosh(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_sinh(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_sinh(_Tp __x)\n     { return std::sinh(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_tanh(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_tanh(_Tp __x)\n     { return std::tanh(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_atan2(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_atan2(_Tp __x, _Tp __y)\n     { return std::atan2(__x, __y); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_exp(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_exp(_Tp __x)\n     { return std::exp(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_exp2(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_exp2(_Tp __x)\n     { return std::exp2(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_expm1(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_expm1(_Tp __x)\n     { return std::expm1(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_log(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_log(_Tp __x)\n     { return std::log(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_log10(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_log10(_Tp __x)\n     { return std::log10(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_log1p(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_log1p(_Tp __x)\n     { return std::log1p(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_log2(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_log2(_Tp __x)\n     { return std::log2(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_logb(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_logb(_Tp __x)\n     { return std::logb(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _ST<int> _S_ilogb(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _ST<int>\n+    _S_ilogb(_Tp __x)\n     { return {std::ilogb(__x)}; }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_pow(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_pow(_Tp __x, _Tp __y)\n     { return std::pow(__x, __y); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_abs(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_abs(_Tp __x)\n     { return std::abs(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_fabs(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_fabs(_Tp __x)\n     { return std::fabs(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_sqrt(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_sqrt(_Tp __x)\n     { return std::sqrt(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_cbrt(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_cbrt(_Tp __x)\n     { return std::cbrt(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_erf(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_erf(_Tp __x)\n     { return std::erf(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_erfc(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_erfc(_Tp __x)\n     { return std::erfc(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_lgamma(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_lgamma(_Tp __x)\n     { return std::lgamma(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_tgamma(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_tgamma(_Tp __x)\n     { return std::tgamma(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_trunc(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_trunc(_Tp __x)\n     { return std::trunc(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_floor(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_floor(_Tp __x)\n     { return std::floor(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_ceil(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_ceil(_Tp __x)\n     { return std::ceil(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_nearbyint(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_nearbyint(_Tp __x)\n     { return std::nearbyint(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_rint(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_rint(_Tp __x)\n     { return std::rint(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _ST<long> _S_lrint(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _ST<long>\n+    _S_lrint(_Tp __x)\n     { return {std::lrint(__x)}; }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _ST<long long> _S_llrint(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _ST<long long>\n+    _S_llrint(_Tp __x)\n     { return {std::llrint(__x)}; }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_round(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_round(_Tp __x)\n     { return std::round(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _ST<long> _S_lround(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _ST<long>\n+    _S_lround(_Tp __x)\n     { return {std::lround(__x)}; }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _ST<long long> _S_llround(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC static _ST<long long>\n+    _S_llround(_Tp __x)\n     { return {std::llround(__x)}; }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_ldexp(_Tp __x, _ST<int> __y)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_ldexp(_Tp __x, _ST<int> __y)\n     { return std::ldexp(__x, __y.first); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_scalbn(_Tp __x, _ST<int> __y)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_scalbn(_Tp __x, _ST<int> __y)\n     { return std::scalbn(__x, __y.first); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_scalbln(_Tp __x, _ST<long> __y)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_scalbln(_Tp __x, _ST<long> __y)\n     { return std::scalbln(__x, __y.first); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_fmod(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_fmod(_Tp __x, _Tp __y)\n     { return std::fmod(__x, __y); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_remainder(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_remainder(_Tp __x, _Tp __y)\n     { return std::remainder(__x, __y); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_nextafter(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_nextafter(_Tp __x, _Tp __y)\n     { return std::nextafter(__x, __y); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_fdim(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_fdim(_Tp __x, _Tp __y)\n     { return std::fdim(__x, __y); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_fmax(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_fmax(_Tp __x, _Tp __y)\n     { return std::fmax(__x, __y); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_fmin(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_fmin(_Tp __x, _Tp __y)\n     { return std::fmin(__x, __y); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_fma(_Tp __x, _Tp __y, _Tp __z)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_fma(_Tp __x, _Tp __y, _Tp __z)\n     { return std::fma(__x, __y, __z); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_remquo(_Tp __x, _Tp __y, _ST<int>* __z)\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_remquo(_Tp __x, _Tp __y, _ST<int>* __z)\n     { return std::remquo(__x, __y, &__z->first); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static _ST<int> _S_fpclassify(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static _ST<int>\n+    _S_fpclassify(_Tp __x)\n     { return {std::fpclassify(__x)}; }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static bool _S_isfinite(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static bool\n+    _S_isfinite(_Tp __x)\n     { return std::isfinite(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static bool _S_isinf(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static bool\n+    _S_isinf(_Tp __x)\n     { return std::isinf(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static bool _S_isnan(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static bool\n+    _S_isnan(_Tp __x)\n     { return std::isnan(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static bool _S_isnormal(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static bool\n+    _S_isnormal(_Tp __x)\n     { return std::isnormal(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static bool _S_signbit(_Tp __x)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static bool\n+    _S_signbit(_Tp __x)\n     { return std::signbit(__x); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static bool _S_isgreater(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static bool\n+    _S_isgreater(_Tp __x, _Tp __y)\n     { return std::isgreater(__x, __y); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static bool _S_isgreaterequal(_Tp __x,\n-\t\t\t\t\t\t\t\t    _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static bool\n+    _S_isgreaterequal(_Tp __x, _Tp __y)\n     { return std::isgreaterequal(__x, __y); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static bool _S_isless(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static bool\n+    _S_isless(_Tp __x, _Tp __y)\n     { return std::isless(__x, __y); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static bool _S_islessequal(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static bool\n+    _S_islessequal(_Tp __x, _Tp __y)\n     { return std::islessequal(__x, __y); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static bool _S_islessgreater(_Tp __x,\n-\t\t\t\t\t\t\t\t   _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static bool\n+    _S_islessgreater(_Tp __x, _Tp __y)\n     { return std::islessgreater(__x, __y); }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static bool _S_isunordered(_Tp __x,\n-\t\t\t\t\t\t\t\t _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static bool\n+    _S_isunordered(_Tp __x, _Tp __y)\n     { return std::isunordered(__x, __y); }\n \n   // _S_increment & _S_decrement{{{2\n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    constexpr static void _S_increment(_Tp& __x)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static void\n+    _S_increment(_Tp& __x)\n     { ++__x; }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    constexpr static void _S_decrement(_Tp& __x)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static void\n+    _S_decrement(_Tp& __x)\n     { --__x; }\n \n \n   // compares {{{2\n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static bool _S_equal_to(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static bool\n+    _S_equal_to(_Tp __x, _Tp __y)\n     { return __x == __y; }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static bool _S_not_equal_to(_Tp __x,\n-\t\t\t\t\t\t\t\t  _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static bool\n+    _S_not_equal_to(_Tp __x, _Tp __y)\n     { return __x != __y; }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static bool _S_less(_Tp __x, _Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static bool\n+    _S_less(_Tp __x, _Tp __y)\n     { return __x < __y; }\n \n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static bool _S_less_equal(_Tp __x,\n-\t\t\t\t\t\t\t\t_Tp __y)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static bool\n+    _S_less_equal(_Tp __x, _Tp __y)\n     { return __x <= __y; }\n \n   // smart_reference access {{{2\n   template <typename _Tp, typename _Up>\n-    _GLIBCXX_SIMD_INTRINSIC\n-    constexpr static void _S_set(_Tp& __v, [[maybe_unused]] int __i,\n-\t\t\t\t _Up&& __x) noexcept\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static void\n+    _S_set(_Tp& __v, [[maybe_unused]] int __i, _Up&& __x) noexcept\n     {\n       _GLIBCXX_DEBUG_ASSERT(__i == 0);\n       __v = static_cast<_Up&&>(__x);\n@@ -625,8 +687,8 @@ struct _SimdImplScalar\n \n   // _S_masked_unary {{{2\n   template <template <typename> class _Op, typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC constexpr static _Tp _S_masked_unary(const bool __k,\n-\t\t\t\t\t\t\t\t const _Tp __v)\n+    _GLIBCXX_SIMD_INTRINSIC constexpr static _Tp\n+    _S_masked_unary(const bool __k, const _Tp __v)\n     { return static_cast<_Tp>(__k ? _Op<_Tp>{}(__v) : __v); }\n \n   // }}}2\n@@ -643,13 +705,15 @@ struct _MaskImplScalar\n   // }}}\n   // _S_broadcast {{{\n   template <typename>\n-    _GLIBCXX_SIMD_INTRINSIC static constexpr bool _S_broadcast(bool __x)\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr bool\n+    _S_broadcast(bool __x)\n     { return __x; }\n \n   // }}}\n   // _S_load {{{\n   template <typename>\n-    _GLIBCXX_SIMD_INTRINSIC static constexpr bool _S_load(const bool* __mem)\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr bool\n+    _S_load(const bool* __mem)\n     { return __mem[0]; }\n \n   // }}}\n@@ -687,7 +751,8 @@ struct _MaskImplScalar\n   }\n \n   // _S_store {{{2\n-  _GLIBCXX_SIMD_INTRINSIC static void _S_store(bool __v, bool* __mem) noexcept\n+  _GLIBCXX_SIMD_INTRINSIC static void\n+  _S_store(bool __v, bool* __mem) noexcept\n   { __mem[0] = __v; }\n \n   // _S_masked_store {{{2\n@@ -699,42 +764,41 @@ struct _MaskImplScalar\n   }\n \n   // logical and bitwise operators {{{2\n-  _GLIBCXX_SIMD_INTRINSIC\n-  static constexpr bool _S_logical_and(bool __x, bool __y)\n+  _GLIBCXX_SIMD_INTRINSIC static constexpr bool\n+  _S_logical_and(bool __x, bool __y)\n   { return __x && __y; }\n \n-  _GLIBCXX_SIMD_INTRINSIC\n-  static constexpr bool _S_logical_or(bool __x, bool __y)\n+  _GLIBCXX_SIMD_INTRINSIC static constexpr bool\n+  _S_logical_or(bool __x, bool __y)\n   { return __x || __y; }\n \n-  _GLIBCXX_SIMD_INTRINSIC\n-  static constexpr bool _S_bit_not(bool __x)\n+  _GLIBCXX_SIMD_INTRINSIC static constexpr bool\n+  _S_bit_not(bool __x)\n   { return !__x; }\n \n-  _GLIBCXX_SIMD_INTRINSIC\n-  static constexpr bool _S_bit_and(bool __x, bool __y)\n+  _GLIBCXX_SIMD_INTRINSIC static constexpr bool\n+  _S_bit_and(bool __x, bool __y)\n   { return __x && __y; }\n \n-  _GLIBCXX_SIMD_INTRINSIC\n-  static constexpr bool _S_bit_or(bool __x, bool __y)\n+  _GLIBCXX_SIMD_INTRINSIC static constexpr bool\n+  _S_bit_or(bool __x, bool __y)\n   { return __x || __y; }\n \n-  _GLIBCXX_SIMD_INTRINSIC\n-  static constexpr bool _S_bit_xor(bool __x, bool __y)\n+  _GLIBCXX_SIMD_INTRINSIC static constexpr bool\n+  _S_bit_xor(bool __x, bool __y)\n   { return __x != __y; }\n \n   // smart_reference access {{{2\n-  _GLIBCXX_SIMD_INTRINSIC\n-  constexpr static void _S_set(bool& __k, [[maybe_unused]] int __i,\n-\t\t\t       bool __x) noexcept\n+  _GLIBCXX_SIMD_INTRINSIC constexpr static void\n+  _S_set(bool& __k, [[maybe_unused]] int __i, bool __x) noexcept\n   {\n     _GLIBCXX_DEBUG_ASSERT(__i == 0);\n     __k = __x;\n   }\n \n   // _S_masked_assign {{{2\n-  _GLIBCXX_SIMD_INTRINSIC static void _S_masked_assign(bool __k, bool& __lhs,\n-\t\t\t\t\t\t       bool __rhs)\n+  _GLIBCXX_SIMD_INTRINSIC static void\n+  _S_masked_assign(bool __k, bool& __lhs, bool __rhs)\n   {\n     if (__k)\n       __lhs = __rhs;"}, {"sha": "608918542c6326d200941362a5ce96d31f41f8b9", "filename": "libstdc++-v3/include/experimental/bits/simd_x86.h", "status": "modified", "additions": 44, "deletions": 46, "changes": 90, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b31186e589caee43ac5720a538d9a41ebf514e81/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_x86.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b31186e589caee43ac5720a538d9a41ebf514e81/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_x86.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fexperimental%2Fbits%2Fsimd_x86.h?ref=b31186e589caee43ac5720a538d9a41ebf514e81", "patch": "@@ -40,10 +40,7 @@ _GLIBCXX_SIMD_BEGIN_NAMESPACE\n template <typename _Tp, size_t _Np>\n   _GLIBCXX_SIMD_INTRINSIC constexpr _SimdWrapper<__int_for_sizeof_t<_Tp>, _Np>\n   __to_masktype(_SimdWrapper<_Tp, _Np> __x)\n-  {\n-    return reinterpret_cast<__vector_type_t<__int_for_sizeof_t<_Tp>, _Np>>(\n-      __x._M_data);\n-  }\n+  { return reinterpret_cast<__vector_type_t<__int_for_sizeof_t<_Tp>, _Np>>(__x._M_data); }\n \n template <typename _TV,\n \t  typename _TVT\n@@ -434,7 +431,8 @@ struct _CommonImplX86 : _CommonImplBuiltin\n #ifdef _GLIBCXX_SIMD_WORKAROUND_PR85048\n   // _S_converts_via_decomposition {{{\n   template <typename _From, typename _To, size_t _ToSize>\n-    static constexpr bool _S_converts_via_decomposition()\n+    static constexpr bool\n+    _S_converts_via_decomposition()\n     {\n       if constexpr (is_integral_v<\n \t\t      _From> && is_integral_v<_To> && sizeof(_From) == 8\n@@ -465,8 +463,8 @@ struct _CommonImplX86 : _CommonImplBuiltin\n   using _CommonImplBuiltin::_S_store;\n \n   template <typename _Tp, size_t _Np>\n-    _GLIBCXX_SIMD_INTRINSIC static void _S_store(_SimdWrapper<_Tp, _Np> __x,\n-\t\t\t\t\t\t void* __addr)\n+    _GLIBCXX_SIMD_INTRINSIC static void\n+    _S_store(_SimdWrapper<_Tp, _Np> __x, void* __addr)\n     {\n       constexpr size_t _Bytes = _Np * sizeof(_Tp);\n \n@@ -702,8 +700,8 @@ struct _CommonImplX86 : _CommonImplBuiltin\n   // Requires: _Tp to be an intrinsic type (integers blend per byte) and 16/32\n   //           Bytes wide\n   template <typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static _Tp _S_blend_intrin(_Tp __k, _Tp __a,\n-\t\t\t\t\t\t       _Tp __b) noexcept\n+    _GLIBCXX_SIMD_INTRINSIC static _Tp\n+    _S_blend_intrin(_Tp __k, _Tp __a, _Tp __b) noexcept\n     {\n       static_assert(is_same_v<decltype(__to_intrin(__a)), _Tp>);\n       constexpr struct\n@@ -843,6 +841,7 @@ template <typename _Abi, typename>\n \t= (sizeof(_Tp) >= 4 && __have_avx512f) || __have_avx512bw  ? 64\n \t  : (is_floating_point_v<_Tp>&& __have_avx) || __have_avx2 ? 32\n \t\t\t\t\t\t\t\t   : 16;\n+\n     using _MaskImpl = typename _Abi::_MaskImpl;\n \n     // _S_masked_load {{{\n@@ -1033,8 +1032,7 @@ template <typename _Abi, typename>\n     // _S_masked_store_nocvt {{{\n     template <typename _Tp, size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static void\n-      _S_masked_store_nocvt(_SimdWrapper<_Tp, _Np> __v, _Tp* __mem,\n-\t\t\t    _SimdWrapper<bool, _Np> __k)\n+      _S_masked_store_nocvt(_SimdWrapper<_Tp, _Np> __v, _Tp* __mem, _SimdWrapper<bool, _Np> __k)\n       {\n \t[[maybe_unused]] const auto __vi = __to_intrin(__v);\n \tif constexpr (sizeof(__vi) == 64)\n@@ -1301,7 +1299,8 @@ template <typename _Abi, typename>\n     // }}}\n     // _S_multiplies {{{\n     template <typename _V, typename _VVT = _VectorTraits<_V>>\n-      _GLIBCXX_SIMD_INTRINSIC static constexpr _V _S_multiplies(_V __x, _V __y)\n+      _GLIBCXX_SIMD_INTRINSIC static constexpr _V\n+      _S_multiplies(_V __x, _V __y)\n       {\n \tusing _Tp = typename _VVT::value_type;\n \tif (__builtin_is_constant_evaluated() || __x._M_is_constprop()\n@@ -2739,7 +2738,8 @@ template <typename _Abi, typename>\n     // }}}\n     // _S_nearbyint {{{\n     template <typename _Tp, typename _TVT = _VectorTraits<_Tp>>\n-      _GLIBCXX_SIMD_INTRINSIC static _Tp _S_nearbyint(_Tp __x) noexcept\n+      _GLIBCXX_SIMD_INTRINSIC static _Tp\n+      _S_nearbyint(_Tp __x) noexcept\n       {\n \tif constexpr (_TVT::template _S_is<float, 16>)\n \t  return _mm512_roundscale_ps(__x, 0x0c);\n@@ -2764,7 +2764,8 @@ template <typename _Abi, typename>\n     // }}}\n     // _S_rint {{{\n     template <typename _Tp, typename _TVT = _VectorTraits<_Tp>>\n-      _GLIBCXX_SIMD_INTRINSIC static _Tp _S_rint(_Tp __x) noexcept\n+      _GLIBCXX_SIMD_INTRINSIC static _Tp\n+      _S_rint(_Tp __x) noexcept\n       {\n \tif constexpr (_TVT::template _S_is<float, 16>)\n \t  return _mm512_roundscale_ps(__x, 0x04);\n@@ -2912,7 +2913,8 @@ template <typename _Abi, typename>\n     // _S_isnonzerovalue_mask {{{\n     // (isnormal | is subnormal == !isinf & !isnan & !is zero)\n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static auto _S_isnonzerovalue_mask(_Tp __x)\n+      _GLIBCXX_SIMD_INTRINSIC static auto\n+      _S_isnonzerovalue_mask(_Tp __x)\n       {\n \tusing _Traits = _VectorTraits<_Tp>;\n \tif constexpr (__have_avx512dq_vl)\n@@ -3179,8 +3181,8 @@ template <typename _Abi, typename>\n     // }}}\n     // _S_isgreater {{{\n     template <typename _Tp, size_t _Np>\n-      static constexpr _MaskMember<_Tp> _S_isgreater(_SimdWrapper<_Tp, _Np> __x,\n-\t\t\t\t\t\t     _SimdWrapper<_Tp, _Np> __y)\n+      static constexpr _MaskMember<_Tp>\n+      _S_isgreater(_SimdWrapper<_Tp, _Np> __x, _SimdWrapper<_Tp, _Np> __y)\n       {\n \tconst auto __xi = __to_intrin(__x);\n \tconst auto __yi = __to_intrin(__y);\n@@ -3297,8 +3299,8 @@ template <typename _Abi, typename>\n     // }}}\n     // _S_isless {{{\n     template <typename _Tp, size_t _Np>\n-      static constexpr _MaskMember<_Tp> _S_isless(_SimdWrapper<_Tp, _Np> __x,\n-\t\t\t\t\t\t  _SimdWrapper<_Tp, _Np> __y)\n+      static constexpr _MaskMember<_Tp>\n+      _S_isless(_SimdWrapper<_Tp, _Np> __x, _SimdWrapper<_Tp, _Np> __y)\n       {\n \tconst auto __xi = __to_intrin(__x);\n \tconst auto __yi = __to_intrin(__y);\n@@ -3462,11 +3464,9 @@ template <typename _Abi, typename>\n       }\n \n     //}}} }}}\n-    template <template <typename> class _Op, typename _Tp, typename _K,\n-\t      size_t _Np>\n+    template <template <typename> class _Op, typename _Tp, typename _K, size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static _SimdWrapper<_Tp, _Np>\n-      _S_masked_unary(const _SimdWrapper<_K, _Np> __k,\n-\t\t      const _SimdWrapper<_Tp, _Np> __v)\n+      _S_masked_unary(const _SimdWrapper<_K, _Np> __k, const _SimdWrapper<_Tp, _Np> __v)\n       {\n \tif (__k._M_is_constprop_none_of())\n \t  return __v;\n@@ -3543,8 +3543,8 @@ struct _MaskImplX86Mixin\n \n   // _S_to_maskvector(bool) {{{\n   template <typename _Up, size_t _ToN = 1, typename _Tp>\n-    _GLIBCXX_SIMD_INTRINSIC static constexpr enable_if_t<\n-      is_same_v<_Tp, bool>, _SimdWrapper<_Up, _ToN>>\n+    _GLIBCXX_SIMD_INTRINSIC static constexpr\n+    enable_if_t<is_same_v<_Tp, bool>, _SimdWrapper<_Up, _ToN>>\n     _S_to_maskvector(_Tp __x)\n     {\n       static_assert(is_same_v<_Up, __int_for_sizeof_t<_Up>>);\n@@ -3554,8 +3554,7 @@ struct _MaskImplX86Mixin\n \n   // }}}\n   // _S_to_maskvector(_SanitizedBitMask) {{{\n-  template <typename _Up, size_t _UpN = 0, size_t _Np,\n-\t    size_t _ToN = _UpN == 0 ? _Np : _UpN>\n+  template <typename _Up, size_t _UpN = 0, size_t _Np, size_t _ToN = _UpN == 0 ? _Np : _UpN>\n     _GLIBCXX_SIMD_INTRINSIC static constexpr _SimdWrapper<_Up, _ToN>\n     _S_to_maskvector(_SanitizedBitMask<_Np> __x)\n     {\n@@ -4626,8 +4625,8 @@ template <typename _Abi, typename>\n \n     // _S_store {{{2\n     template <typename _Tp, size_t _Np>\n-      _GLIBCXX_SIMD_INTRINSIC static void _S_store(_SimdWrapper<_Tp, _Np> __v,\n-\t\t\t\t\t\t   bool* __mem) noexcept\n+      _GLIBCXX_SIMD_INTRINSIC static void\n+      _S_store(_SimdWrapper<_Tp, _Np> __v, bool* __mem) noexcept\n       {\n \tif constexpr (__is_avx512_abi<_Abi>())\n \t  {\n@@ -4791,8 +4790,7 @@ template <typename _Abi, typename>\n     // logical and bitwise operators {{{2\n     template <typename _Tp, size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static constexpr _SimdWrapper<_Tp, _Np>\n-      _S_logical_and(const _SimdWrapper<_Tp, _Np>& __x,\n-\t\t     const _SimdWrapper<_Tp, _Np>& __y)\n+      _S_logical_and(const _SimdWrapper<_Tp, _Np>& __x, const _SimdWrapper<_Tp, _Np>& __y)\n       {\n \tif constexpr (is_same_v<_Tp, bool>)\n \t  {\n@@ -4813,8 +4811,7 @@ template <typename _Abi, typename>\n \n     template <typename _Tp, size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static constexpr _SimdWrapper<_Tp, _Np>\n-      _S_logical_or(const _SimdWrapper<_Tp, _Np>& __x,\n-\t\t    const _SimdWrapper<_Tp, _Np>& __y)\n+      _S_logical_or(const _SimdWrapper<_Tp, _Np>& __x, const _SimdWrapper<_Tp, _Np>& __y)\n       {\n \tif constexpr (is_same_v<_Tp, bool>)\n \t  {\n@@ -4860,8 +4857,7 @@ template <typename _Abi, typename>\n \n     template <typename _Tp, size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static constexpr _SimdWrapper<_Tp, _Np>\n-      _S_bit_and(const _SimdWrapper<_Tp, _Np>& __x,\n-\t\t const _SimdWrapper<_Tp, _Np>& __y)\n+      _S_bit_and(const _SimdWrapper<_Tp, _Np>& __x, const _SimdWrapper<_Tp, _Np>& __y)\n       {\n \tif constexpr (is_same_v<_Tp, bool>)\n \t  {\n@@ -4882,8 +4878,7 @@ template <typename _Abi, typename>\n \n     template <typename _Tp, size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static constexpr _SimdWrapper<_Tp, _Np>\n-      _S_bit_or(const _SimdWrapper<_Tp, _Np>& __x,\n-\t\tconst _SimdWrapper<_Tp, _Np>& __y)\n+      _S_bit_or(const _SimdWrapper<_Tp, _Np>& __x, const _SimdWrapper<_Tp, _Np>& __y)\n       {\n \tif constexpr (is_same_v<_Tp, bool>)\n \t  {\n@@ -4904,8 +4899,7 @@ template <typename _Abi, typename>\n \n     template <typename _Tp, size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static constexpr _SimdWrapper<_Tp, _Np>\n-      _S_bit_xor(const _SimdWrapper<_Tp, _Np>& __x,\n-\t\t const _SimdWrapper<_Tp, _Np>& __y)\n+      _S_bit_xor(const _SimdWrapper<_Tp, _Np>& __x, const _SimdWrapper<_Tp, _Np>& __y)\n       {\n \tif constexpr (is_same_v<_Tp, bool>)\n \t  {\n@@ -4929,8 +4923,7 @@ template <typename _Abi, typename>\n     template <size_t _Np>\n       _GLIBCXX_SIMD_INTRINSIC static void\n       _S_masked_assign(_SimdWrapper<bool, _Np> __k,\n-\t\t       _SimdWrapper<bool, _Np>& __lhs,\n-\t\t       _SimdWrapper<bool, _Np> __rhs)\n+\t\t       _SimdWrapper<bool, _Np>& __lhs, _SimdWrapper<bool, _Np> __rhs)\n       {\n \t__lhs._M_data\n \t  = (~__k._M_data & __lhs._M_data) | (__k._M_data & __rhs._M_data);\n@@ -4952,7 +4945,8 @@ template <typename _Abi, typename>\n     //}}}\n     // _S_all_of {{{\n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static bool _S_all_of(simd_mask<_Tp, _Abi> __k)\n+      _GLIBCXX_SIMD_INTRINSIC static bool\n+      _S_all_of(simd_mask<_Tp, _Abi> __k)\n       {\n \tif constexpr (__is_sse_abi<_Abi>() || __is_avx_abi<_Abi>())\n \t  {\n@@ -5008,7 +5002,8 @@ template <typename _Abi, typename>\n     // }}}\n     // _S_any_of {{{\n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static bool _S_any_of(simd_mask<_Tp, _Abi> __k)\n+      _GLIBCXX_SIMD_INTRINSIC static bool\n+      _S_any_of(simd_mask<_Tp, _Abi> __k)\n       {\n \tif constexpr (__is_sse_abi<_Abi>() || __is_avx_abi<_Abi>())\n \t  {\n@@ -5043,7 +5038,8 @@ template <typename _Abi, typename>\n     // }}}\n     // _S_none_of {{{\n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static bool _S_none_of(simd_mask<_Tp, _Abi> __k)\n+      _GLIBCXX_SIMD_INTRINSIC static bool\n+      _S_none_of(simd_mask<_Tp, _Abi> __k)\n       {\n \tif constexpr (__is_sse_abi<_Abi>() || __is_avx_abi<_Abi>())\n \t  {\n@@ -5078,7 +5074,8 @@ template <typename _Abi, typename>\n     // }}}\n     // _S_some_of {{{\n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static bool _S_some_of(simd_mask<_Tp, _Abi> __k)\n+      _GLIBCXX_SIMD_INTRINSIC static bool\n+      _S_some_of(simd_mask<_Tp, _Abi> __k)\n       {\n \tif constexpr (__is_sse_abi<_Abi>() || __is_avx_abi<_Abi>())\n \t  {\n@@ -5119,7 +5116,8 @@ template <typename _Abi, typename>\n     // }}}\n     // _S_popcount {{{\n     template <typename _Tp>\n-      _GLIBCXX_SIMD_INTRINSIC static int _S_popcount(simd_mask<_Tp, _Abi> __k)\n+      _GLIBCXX_SIMD_INTRINSIC static int\n+      _S_popcount(simd_mask<_Tp, _Abi> __k)\n       {\n \tconstexpr size_t _Np = simd_size_v<_Tp, _Abi>;\n \tconst auto __kk = _Abi::_S_masked(__k._M_data)._M_data;"}]}