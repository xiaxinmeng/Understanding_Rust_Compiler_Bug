{"sha": "da29608a7a5df92fcd377086a5304889ae71413d", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZGEyOTYwOGE3YTVkZjkyZmNkMzc3MDg2YTUzMDQ4ODlhZTcxNDEzZA==", "commit": {"author": {"name": "Fran\u00e7ois Dumont", "email": "fdumont@gcc.gnu.org", "date": "2011-11-23T20:30:18Z"}, "committer": {"name": "Fran\u00e7ois Dumont", "email": "fdumont@gcc.gnu.org", "date": "2011-11-23T20:30:18Z"}, "message": "re PR libstdc++/41975 ([C++0x] [DR579] unordered_set::erase performs worse when nearly empty)\n\n2011-11-23  Fran\u00e7ois Dumont <fdumont@gcc.gnu.org>\n\n\tPR libstdc++/41975\n\t* include/bits/hashtable.h (_Hashtable<>): Major data model\n\tmodification to limit performance impact of empty buckets in\n\terase(iterator) implementation.\n\t* include/bits/hashtable_policy.h (_Hashtable_iterator,\n\t_Hashtable_const_iterator): Remove not used anymore.\n\t* include/bits/hashtable_policy.h (_Prime_rehash_policy): Remove\n\t_M_grow_factor, just use natural evolution of prime numbers. Add\n\t_M_prev_size to know when the number of buckets can be reduced.\n\t* include/bits/unordered_set.h (__unordered_set<>,\n\t__unordered_multiset<>), unordered_map.h (__unordered_map<>,\n\t__unordered_multimap<>): Change default value of cache hash code\n\ttemplate parameter, false for integral types with noexcept hash\n\tfunctor, true otherwise.\n\t* include/debug/unordered_map, unordered_set: Adapt transformation\n\tfrom iterator/const_iterator to respectively\n\tlocal_iterator/const_local_iterator.\n\t* testsuite/performance/23_containers/copy_construct/unordered_set.cc:\n\tNew.\n\t* testsuite/23_containers/unordered_set/instantiation_neg.cc: New.\n\t* testsuite/23_containers/unordered_set/hash_policy/rehash.cc: New.\n\t* testsuite/23_containers/unordered_multiset/cons/copy.cc: New.\n\t* testsuite/23_containers/unordered_multiset/erase/1.cc,\n\t24061-multiset.cc: Add checks on the number of bucket elements.\n\t* testsuite/23_containers/unordered_multiset/insert/multiset_range.cc,\n\tmultiset_single.cc, multiset_single_move.cc: Likewise.\n\nFrom-SVN: r181677", "tree": {"sha": "d6dfde4f6c17389a68c277fe5c1e37490b857508", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/d6dfde4f6c17389a68c277fe5c1e37490b857508"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/da29608a7a5df92fcd377086a5304889ae71413d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/da29608a7a5df92fcd377086a5304889ae71413d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/da29608a7a5df92fcd377086a5304889ae71413d", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/da29608a7a5df92fcd377086a5304889ae71413d/comments", "author": null, "committer": null, "parents": [{"sha": "2ff12653cd4bb6be8f92badf7fed6cae001ceb3b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2ff12653cd4bb6be8f92badf7fed6cae001ceb3b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2ff12653cd4bb6be8f92badf7fed6cae001ceb3b"}], "stats": {"total": 1381, "additions": 973, "deletions": 408}, "files": [{"sha": "aa324e0f3743dcf0523e748758ff54944e6e23b2", "filename": "libstdc++-v3/ChangeLog", "status": "modified", "additions": 29, "deletions": 0, "changes": 29, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2FChangeLog?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -1,3 +1,32 @@\n+2011-11-23  Fran\u00e7ois Dumont <fdumont@gcc.gnu.org>\n+\n+\tPR libstdc++/41975\n+\t* include/bits/hashtable.h (_Hashtable<>): Major data model\n+\tmodification to limit performance impact of empty buckets in\n+\terase(iterator) implementation.\n+\t* include/bits/hashtable_policy.h (_Hashtable_iterator,\n+\t_Hashtable_const_iterator): Remove not used anymore.\n+\t* include/bits/hashtable_policy.h (_Prime_rehash_policy): Remove\n+\t_M_grow_factor, just use natural evolution of prime numbers. Add\n+\t_M_prev_size to know when the number of buckets can be reduced.\n+\t* include/bits/unordered_set.h (__unordered_set<>,\n+\t__unordered_multiset<>), unordered_map.h (__unordered_map<>,\n+\t__unordered_multimap<>): Change default value of cache hash code\n+\ttemplate parameter, false for integral types with noexcept hash\n+\tfunctor, true otherwise.\n+\t* include/debug/unordered_map, unordered_set: Adapt transformation\n+\tfrom iterator/const_iterator to respectively\n+\tlocal_iterator/const_local_iterator.\n+\t* testsuite/performance/23_containers/copy_construct/unordered_set.cc:\n+\tNew.\n+\t* testsuite/23_containers/unordered_set/instantiation_neg.cc: New.\n+\t* testsuite/23_containers/unordered_set/hash_policy/rehash.cc: New.\n+\t* testsuite/23_containers/unordered_multiset/cons/copy.cc: New.\n+\t* testsuite/23_containers/unordered_multiset/erase/1.cc,\n+\t24061-multiset.cc: Add checks on the number of bucket elements.\n+\t* testsuite/23_containers/unordered_multiset/insert/multiset_range.cc,\n+\tmultiset_single.cc, multiset_single_move.cc: Likewise.\n+\n 2011-11-21  Jonathan Wakely  <jwakely.gcc@gmail.com>\n \n \t* include/std/functional (is_placeholder, is_bind_expression): Add"}, {"sha": "dfa91f7cc8cf5c2a6de7dda7bdf8a861a5a11067", "filename": "libstdc++-v3/include/bits/hashtable.h", "status": "modified", "additions": 586, "deletions": 217, "changes": 803, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fhashtable.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fhashtable.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fhashtable.h?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -48,7 +48,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n   // value type is Value.  As a conforming extension, we allow for\n   // value type != Value.\n \n-  // _ExtractKey: function object that takes a object of type Value\n+  // _ExtractKey: function object that takes an object of type Value\n   // and returns a value of type _Key.\n \n   // _Equal: function object that takes two objects of type k and returns\n@@ -78,9 +78,6 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n   // count.  If so, returns make_pair(true, n), where n is the new\n   // bucket count.  If not, returns make_pair(false, <anything>).\n \n-  // ??? Right now it is hard-wired that the number of buckets never\n-  // shrinks.  Should we allow _RehashPolicy to change that?\n-\n   // __cache_hash_code: bool.  true if we store the value of the hash\n   // function along with the value.  This is a time-space tradeoff.\n   // Storing it may improve lookup speed by reducing the number of times\n@@ -94,6 +91,53 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n   // is always at most one, false if it may be an arbitrary number.  This\n   // true for unordered_set and unordered_map, false for unordered_multiset\n   // and unordered_multimap.\n+  /**\n+   * Here's _Hashtable data structure, each _Hashtable has:\n+   * - _Bucket[]     _M_buckets\n+   * - size_type     _M_bucket_count\n+   * - size_type     _M_begin_bucket_index\n+   * - size_type     _M_element_count\n+   *\n+   * with _Bucket being _Node* and _Node:\n+   * - _Node*        _M_next\n+   * - Tp            _M_value\n+   * - size_t        _M_code if cache_hash_code is true\n+   *\n+   * In terms of Standard containers the hastable is like the aggregation of:\n+   * - std::forward_list<_Node> containing the elements\n+   * - std::vector<std::forward_list<_Node>::iterator> representing the buckets\n+   *\n+   * The first non-empty bucket with index _M_begin_bucket_index contains the\n+   * first container node which is also the first bucket node whereas other\n+   * non-empty buckets contain the node before the first bucket node. This is so\n+   * to implement something like a std::forward_list::erase_after on container\n+   * erase calls.\n+   * \n+   * Access to the bucket last element require a check on the hash code to see\n+   * if the node is still in the bucket. Such a design impose a quite efficient\n+   * hash functor and is one of the reasons it is highly advise to set\n+   * __cache_hash_code to true.\n+   *\n+   * The container iterators are simply built from nodes. This way incrementing\n+   * the iterator is perfectly efficient no matter how many empty buckets there\n+   * are in the container.\n+   *\n+   * On insert we compute element hash code and thanks to it find the bucket\n+   * index. If the element is the first one in the bucket we must find the\n+   * previous non-empty bucket where the previous node rely. To keep this loop\n+   * minimal it is important that the number of bucket is not too high compared\n+   * to the number of elements. So the hash policy must be carefully design so\n+   * that it computes a bucket count large enough to respect the user defined\n+   * load factor but also not too large to limit impact on the insert operation.\n+   *\n+   * On erase, the simple iterator design impose to use the hash functor to get\n+   * the index of the bucket to update. For this reason, when __cache_hash_code\n+   * is set to false, there is a static assertion that the hash functor cannot\n+   * throw.\n+   *\n+   * _M_begin_bucket_index is used to offer contant time access to the container\n+   * begin iterator.\n+   */\n \n   template<typename _Key, typename _Value, typename _Allocator,\n \t   typename _ExtractKey, typename _Equal,\n@@ -130,6 +174,9 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t\t\t\t\t\t __constant_iterators,\n \t\t\t\t\t\t __unique_keys> >\n     {\n+      static_assert(__or_<integral_constant<bool, __cache_hash_code>,\n+\t\t\t  __detail::__is_noexcept_hash<_Key, _H1>>::value,\n+      \t    \"Cache the hash code or qualify your hash functor with noexcept\");\n     public:\n       typedef _Allocator                                  allocator_type;\n       typedef _Value                                      value_type;\n@@ -152,30 +199,28 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t\t\t\t\t     __cache_hash_code>\n \t\t\t\t\t\t\t  const_local_iterator;\n \n-      typedef __detail::_Hashtable_iterator<value_type, __constant_iterators,\n-\t\t\t\t\t    __cache_hash_code>\n-\t\t\t\t\t\t\t  iterator;\n-      typedef __detail::_Hashtable_const_iterator<value_type,\n-\t\t\t\t\t\t  __constant_iterators,\n-\t\t\t\t\t\t  __cache_hash_code>\n-\t\t\t\t\t\t\t  const_iterator;\n+      typedef local_iterator iterator;\n+      typedef const_local_iterator const_iterator;\n \n       template<typename _Key2, typename _Value2, typename _Ex2, bool __unique2,\n \t       typename _Hashtable2>\n \tfriend struct __detail::_Map_base;\n \n     private:\n+      typedef typename _RehashPolicy::_State _RehashPolicyState;\n       typedef __detail::_Hash_node<_Value, __cache_hash_code> _Node;\n       typedef typename _Allocator::template rebind<_Node>::other\n \t\t\t\t\t\t\t_Node_allocator_type;\n-      typedef typename _Allocator::template rebind<_Node*>::other\n+      typedef _Node* _Bucket;\n+      //typedef __detail::_Bucket<_Value, __cache_hash_code> _Bucket;\n+      typedef typename _Allocator::template rebind<_Bucket>::other\n \t\t\t\t\t\t\t_Bucket_allocator_type;\n \n       typedef typename _Allocator::template rebind<_Value>::other\n \t\t\t\t\t\t\t_Value_allocator_type;\n \n       _Node_allocator_type   _M_node_allocator;\n-      _Node**                _M_buckets;\n+      _Bucket*               _M_buckets;\n       size_type              _M_bucket_count;\n       size_type              _M_begin_bucket_index; // First non-empty bucket.\n       size_type              _M_element_count;\n@@ -188,14 +233,38 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       void\n       _M_deallocate_node(_Node* __n);\n \n+      // Deallocate all nodes contained in the bucket array, buckets' nodes\n+      // are not linked to each other\n+      void\n+      _M_deallocate_nodes(_Bucket*, size_type);\n+\n+      // Deallocate the linked list of nodes pointed to by __n\n       void\n-      _M_deallocate_nodes(_Node**, size_type);\n+      _M_deallocate_nodes(_Node* __n);\n \n-      _Node**\n+      _Bucket*\n       _M_allocate_buckets(size_type __n);\n \n       void\n-      _M_deallocate_buckets(_Node**, size_type __n);\n+      _M_deallocate_buckets(_Bucket*, size_type __n);\n+\n+      // Gets bucket begin dealing with the difference between first non-empty\n+      // bucket containing the first container node and the other non-empty\n+      // buckets containing the node before the one belonging to the bucket.\n+      _Node*\n+      _M_bucket_begin(size_type __bkt) const;\n+\n+      // Gets the bucket last node if any\n+      _Node*\n+      _M_bucket_end(size_type __bkt) const;\n+\n+      // Gets the bucket node after the last if any\n+      _Node*\n+      _M_bucket_past_the_end(size_type __bkt) const\n+        {\n+\t  _Node* __end = _M_bucket_end(__bkt);\n+\t  return __end ? __end->_M_next : nullptr;\n+\t}\n \n     public:\n       // Constructor, destructor, assignment, swap\n@@ -240,27 +309,27 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       // Basic container operations\n       iterator\n       begin() noexcept\n-      { return iterator(_M_buckets + _M_begin_bucket_index); }\n+      { return iterator(_M_buckets[_M_begin_bucket_index]); }\n \n       const_iterator\n       begin() const noexcept\n-      { return const_iterator(_M_buckets + _M_begin_bucket_index); }\n+      { return const_iterator(_M_buckets[_M_begin_bucket_index]); }\n \n       iterator\n       end() noexcept\n-      { return iterator(_M_buckets + _M_bucket_count); }\n+      { return iterator(nullptr); }\n \n       const_iterator\n       end() const noexcept\n-      { return const_iterator(_M_buckets + _M_bucket_count); }\n+      { return const_iterator(nullptr); }\n \n       const_iterator\n       cbegin() const noexcept\n-      { return const_iterator(_M_buckets + _M_begin_bucket_index); }\n+      { return const_iterator(_M_buckets[_M_begin_bucket_index]); }\n \n       const_iterator\n       cend() const noexcept\n-      { return const_iterator(_M_buckets + _M_bucket_count); }\n+      { return const_iterator(nullptr); }\n \n       size_type\n       size() const noexcept\n@@ -307,28 +376,28 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \n       local_iterator\n       begin(size_type __n)\n-      { return local_iterator(_M_buckets[__n]); }\n+      { return local_iterator(_M_bucket_begin(__n)); }\n \n       local_iterator\n-      end(size_type)\n-      { return local_iterator(0); }\n+      end(size_type __n)\n+      { return local_iterator(_M_bucket_past_the_end(__n)); }\n \n       const_local_iterator\n       begin(size_type __n) const\n-      { return const_local_iterator(_M_buckets[__n]); }\n+      { return const_local_iterator(_M_bucket_begin(__n)); }\n \n       const_local_iterator\n-      end(size_type) const\n-      { return const_local_iterator(0); }\n+      end(size_type __n) const\n+      { return const_local_iterator(_M_bucket_past_the_end(__n)); }\n \n       // DR 691.\n       const_local_iterator\n       cbegin(size_type __n) const\n-      { return const_local_iterator(_M_buckets[__n]); }\n+      { return const_local_iterator(_M_bucket_begin(__n)); }\n \n       const_local_iterator\n-      cend(size_type) const\n-      { return const_local_iterator(0); }\n+      cend(size_type __n) const\n+      { return const_local_iterator(_M_bucket_past_the_end(__n)); }\n \n       float\n       load_factor() const noexcept\n@@ -366,9 +435,26 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     private:\n       // Find and insert helper functions and types\n       _Node*\n-      _M_find_node(_Node*, const key_type&,\n+      _M_find_node(size_type, const key_type&,\n \t\t   typename _Hashtable::_Hash_code_type) const;\n \n+      // Insert a node in an empty bucket\n+      void\n+      _M_insert_bucket_begin(size_type, _Node*);\n+\n+      // Insert a node after an other one in a non-empty bucket\n+      void\n+      _M_insert_after(size_type, _Node*, _Node*);\n+\n+      // Remove the bucket first node\n+      void\n+      _M_remove_bucket_begin(size_type __bkt, _Node* __next_n,\n+\t\t\t     size_type __next_bkt);\n+\n+      // Get the node before __n in the bucket __bkt\n+      _Node*\n+      _M_get_previous_node(size_type __bkt, _Node* __n);\n+\n       template<typename _Arg>\n \titerator\n \t_M_insert_bucket(_Arg&&, size_type,\n@@ -454,8 +540,8 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \n     private:\n       // Unconditionally change size of bucket array to n, restore hash policy\n-      // resize value to __next_resize on exception.\n-      void _M_rehash(size_type __n, size_type __next_resize);\n+      // state to __state on exception.\n+      void _M_rehash(size_type __n, const _RehashPolicyState& __state);\n     };\n \n \n@@ -476,7 +562,6 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t__try\n \t  {\n \t    _M_node_allocator.construct(__n, std::forward<_Args>(__args)...);\n-\t    __n->_M_next = 0;\n \t    return __n;\n \t  }\n \t__catch(...)\n@@ -506,18 +591,26 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     void\n     _Hashtable<_Key, _Value, _Allocator, _ExtractKey, _Equal,\n \t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n-    _M_deallocate_nodes(_Node** __array, size_type __n)\n+    _M_deallocate_nodes(_Bucket* __buckets, size_type __n)\n     {\n-      for (size_type __i = 0; __i < __n; ++__i)\n+      for (size_type __i = 0; __i != __n; ++__i)\n+\t_M_deallocate_nodes(__buckets[__i]);\n+    }\n+\n+  template<typename _Key, typename _Value,\n+\t   typename _Allocator, typename _ExtractKey, typename _Equal,\n+\t   typename _H1, typename _H2, typename _Hash, typename _RehashPolicy,\n+\t   bool __chc, bool __cit, bool __uk>\n+    void\n+    _Hashtable<_Key, _Value, _Allocator, _ExtractKey, _Equal,\n+\t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n+    _M_deallocate_nodes(_Node* __n)\n+    {\n+      while (__n)\n \t{\n-\t  _Node* __p = __array[__i];\n-\t  while (__p)\n-\t    {\n-\t      _Node* __tmp = __p;\n-\t      __p = __p->_M_next;\n-\t      _M_deallocate_node(__tmp);\n-\t    }\n-\t  __array[__i] = 0;\n+\t  _Node* __tmp = __n;\n+\t  __n = __n->_M_next;\n+\t  _M_deallocate_node(__tmp);\n \t}\n     }\n \n@@ -527,18 +620,17 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t   bool __chc, bool __cit, bool __uk>\n     typename _Hashtable<_Key, _Value, _Allocator, _ExtractKey, _Equal,\n \t\t\t_H1, _H2, _Hash, _RehashPolicy,\n-\t\t\t__chc, __cit, __uk>::_Node**\n+\t\t\t__chc, __cit, __uk>::_Bucket*\n     _Hashtable<_Key, _Value, _Allocator, _ExtractKey, _Equal,\n \t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n     _M_allocate_buckets(size_type __n)\n     {\n       _Bucket_allocator_type __alloc(_M_node_allocator);\n \n-      // We allocate one extra bucket to hold a sentinel, an arbitrary\n-      // non-null pointer.  Iterator increment relies on this.\n-      _Node** __p = __alloc.allocate(__n + 1);\n-      std::fill(__p, __p + __n, (_Node*) 0);\n-      __p[__n] = reinterpret_cast<_Node*>(0x1000);\n+      // We allocate one extra bucket to have _M_begin_bucket_index\n+      // point to it as long as container is empty\n+      _Bucket* __p = __alloc.allocate(__n + 1);\n+      __builtin_memset(__p, 0, (__n + 1) * sizeof(_Bucket));\n       return __p;\n     }\n \n@@ -549,12 +641,50 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     void\n     _Hashtable<_Key, _Value, _Allocator, _ExtractKey, _Equal,\n \t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n-    _M_deallocate_buckets(_Node** __p, size_type __n)\n+    _M_deallocate_buckets(_Bucket* __p, size_type __n)\n     {\n       _Bucket_allocator_type __alloc(_M_node_allocator);\n       __alloc.deallocate(__p, __n + 1);\n     }\n \n+  template<typename _Key, typename _Value,\n+\t   typename _Allocator, typename _ExtractKey, typename _Equal,\n+\t   typename _H1, typename _H2, typename _Hash, typename _RehashPolicy,\n+\t   bool __chc, bool __cit, bool __uk>\n+    typename _Hashtable<_Key, _Value, _Allocator, _ExtractKey,\n+\t\t\t_Equal, _H1, _H2, _Hash, _RehashPolicy,\n+\t\t\t__chc, __cit, __uk>::_Node*\n+    _Hashtable<_Key, _Value, _Allocator, _ExtractKey, _Equal,\n+\t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n+    _M_bucket_begin(size_type __bkt) const\n+    {\n+      if (__bkt == _M_begin_bucket_index)\n+\treturn _M_buckets[__bkt];\n+      _Node* __n = _M_buckets[__bkt];\n+      return __n ? __n->_M_next : nullptr;\n+    }\n+\n+  template<typename _Key, typename _Value,\n+\t   typename _Allocator, typename _ExtractKey, typename _Equal,\n+\t   typename _H1, typename _H2, typename _Hash, typename _RehashPolicy,\n+\t   bool __chc, bool __cit, bool __uk>\n+    typename _Hashtable<_Key, _Value, _Allocator, _ExtractKey,\n+\t\t\t_Equal, _H1, _H2, _Hash, _RehashPolicy,\n+\t\t\t__chc, __cit, __uk>::_Node*\n+    _Hashtable<_Key, _Value, _Allocator, _ExtractKey, _Equal,\n+\t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n+    _M_bucket_end(size_type __bkt) const\n+    {\n+      _Node* __n = _M_bucket_begin(__bkt);\n+      if (__n)\n+\tfor (;; __n = __n->_M_next)\n+\t  if (!__n->_M_next \n+\t      || this->_M_bucket_index(__n->_M_next, _M_bucket_count)\n+\t\t != __bkt)\n+\t    break;\n+      return __n;\n+    }\n+\n   template<typename _Key, typename _Value,\n \t   typename _Allocator, typename _ExtractKey, typename _Equal,\n \t   typename _H1, typename _H2, typename _Hash, typename _RehashPolicy,\n@@ -576,6 +706,9 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       _M_rehash_policy()\n     {\n       _M_bucket_count = _M_rehash_policy._M_next_bkt(__bucket_hint);\n+      // We don't want the rehash policy to ask for the hashtable to shrink\n+      // on the first insertion so we need to reset its previous resize level.\n+      _M_rehash_policy._M_prev_resize = 0;\n       _M_buckets = _M_allocate_buckets(_M_bucket_count);\n       _M_begin_bucket_index = _M_bucket_count;\n     }\n@@ -607,6 +740,10 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t\t\t\t   _M_bkt_for_elements(__detail::\n \t\t\t\t\t\t       __distance_fw(__f,\n \t\t\t\t\t\t\t\t     __l)));\n+        // We don't want the rehash policy to ask for the hashtable to shrink\n+        // on the first insertion so we need to reset its previous resize\n+\t// level.\n+\t_M_rehash_policy._M_prev_resize = 0;\n \t_M_buckets = _M_allocate_buckets(_M_bucket_count);\n \t_M_begin_bucket_index = _M_bucket_count;\n \t__try\n@@ -642,17 +779,41 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       _M_buckets = _M_allocate_buckets(_M_bucket_count);\n       __try\n \t{\n-\t  for (size_type __i = 0; __i < __ht._M_bucket_count; ++__i)\n+\t  const _Node* __ht_n = __ht._M_buckets[__ht._M_begin_bucket_index];\n+\t  if (!__ht_n)\n+\t    return;\n+\n+\t  // Note that the copy constructor do not rely on hash code usage.\n+\t  // First deal with the special first node that is directly store in\n+\t  // the first non-empty bucket\n+\t  _Node* __this_n = _M_allocate_node(__ht_n->_M_v);\n+\t  this->_M_copy_code(__this_n, __ht_n);\n+\t  _M_buckets[_M_begin_bucket_index] = __this_n;\n+\t  __ht_n = __ht_n->_M_next;\n+\t  // Second deal with following non-empty buckets containing previous\n+\t  // nodes node.\n+\t  for (size_type __i = __ht._M_begin_bucket_index + 1;\n+\t       __i != __ht._M_bucket_count; ++__i)\n \t    {\n-\t      _Node* __n = __ht._M_buckets[__i];\n-\t      _Node** __tail = _M_buckets + __i;\n-\t      while (__n)\n+\t      if (!__ht._M_buckets[__i])\n+\t\tcontinue;\n+\n+\t      for (; __ht_n != __ht._M_buckets[__i]->_M_next;\n+\t\t   __ht_n = __ht_n->_M_next)\n \t\t{\n-\t\t  *__tail = _M_allocate_node(__n->_M_v);\n-\t\t  this->_M_copy_code(*__tail, __n);\n-\t\t  __tail = &((*__tail)->_M_next);\n-\t\t  __n = __n->_M_next;\n+\t\t  __this_n->_M_next = _M_allocate_node(__ht_n->_M_v);\n+\t\t  this->_M_copy_code(__this_n->_M_next, __ht_n);\n+\t\t  __this_n = __this_n->_M_next;\n \t\t}\n+\n+\t      _M_buckets[__i] = __this_n;\n+\t    }\n+\t  // Last finalize copy of the nodes of the last non-empty bucket\n+\t  for (; __ht_n; __ht_n = __ht_n->_M_next)\n+\t    {\n+\t      __this_n->_M_next = _M_allocate_node(__ht_n->_M_v);\n+\t      this->_M_copy_code(__this_n->_M_next, __ht_n);\n+\t      __this_n = __this_n->_M_next;\n \t    }\n \t}\n       __catch(...)\n@@ -737,8 +898,8 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     __rehash_policy(const _RehashPolicy& __pol)\n     {\n       size_type __n_bkt = __pol._M_bkt_for_elements(_M_element_count);\n-      if (__n_bkt > _M_bucket_count)\n-\t_M_rehash(__n_bkt, _M_rehash_policy._M_next_resize);\n+      if (__n_bkt != _M_bucket_count)\n+\t_M_rehash(__n_bkt, _M_rehash_policy._M_state());\n       _M_rehash_policy = __pol;\n     }\n \n@@ -755,8 +916,8 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     {\n       typename _Hashtable::_Hash_code_type __code = this->_M_hash_code(__k);\n       std::size_t __n = this->_M_bucket_index(__k, __code, _M_bucket_count);\n-      _Node* __p = _M_find_node(_M_buckets[__n], __k, __code);\n-      return __p ? iterator(__p, _M_buckets + __n) : this->end();\n+      _Node* __p = _M_find_node(__n, __k, __code);\n+      return __p ? iterator(__p) : this->end();\n     }\n \n   template<typename _Key, typename _Value,\n@@ -772,8 +933,8 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     {\n       typename _Hashtable::_Hash_code_type __code = this->_M_hash_code(__k);\n       std::size_t __n = this->_M_bucket_index(__k, __code, _M_bucket_count);\n-      _Node* __p = _M_find_node(_M_buckets[__n], __k, __code);\n-      return __p ? const_iterator(__p, _M_buckets + __n) : this->end();\n+      _Node* __p = _M_find_node(__n, __k, __code);\n+      return __p ? const_iterator(__p) : this->end();\n     }\n \n   template<typename _Key, typename _Value,\n@@ -789,10 +950,25 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     {\n       typename _Hashtable::_Hash_code_type __code = this->_M_hash_code(__k);\n       std::size_t __n = this->_M_bucket_index(__k, __code, _M_bucket_count);\n+      _Node* __p = _M_bucket_begin(__n);\n+      if (!__p)\n+\treturn 0;\n+\n       std::size_t __result = 0;\n-      for (_Node* __p = _M_buckets[__n]; __p; __p = __p->_M_next)\n-\tif (this->_M_compare(__k, __code, __p))\n-\t  ++__result;\n+      for (;; __p = __p->_M_next)\n+\t{\n+\t  if (this->_M_compare(__k, __code, __p))\n+\t    ++__result;\n+\t  else if (__result)\n+\t    // All equivalent values are next to each other, if we found a not\n+\t    // equivalent value after an equivalent one it means that we won't\n+\t    // find anymore an equivalent value.\n+\t    break;\n+\t  if (!__p->_M_next\n+\t      || this->_M_bucket_index(__p->_M_next, _M_bucket_count)\n+\t\t != __n)\n+\t    break;\n+\t}\n       return __result;\n     }\n \n@@ -814,21 +990,17 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     {\n       typename _Hashtable::_Hash_code_type __code = this->_M_hash_code(__k);\n       std::size_t __n = this->_M_bucket_index(__k, __code, _M_bucket_count);\n-      _Node** __head = _M_buckets + __n;\n-      _Node* __p = _M_find_node(*__head, __k, __code);\n+      _Node* __p = _M_find_node(__n, __k, __code);\n \n       if (__p)\n \t{\n \t  _Node* __p1 = __p->_M_next;\n-\t  for (; __p1; __p1 = __p1->_M_next)\n-\t    if (!this->_M_compare(__k, __code, __p1))\n-\t      break;\n+\t  while (__p1\n+\t\t && this->_M_bucket_index(__p1, _M_bucket_count) == __n\n+\t\t && this->_M_compare(__k, __code, __p1))\n+\t    __p1 = __p1->_M_next;\n \n-\t  iterator __first(__p, __head);\n-\t  iterator __last(__p1, __head);\n-\t  if (!__p1)\n-\t    __last._M_incr_bucket();\n-\t  return std::make_pair(__first, __last);\n+\t  return std::make_pair(iterator(__p), iterator(__p1));\n \t}\n       else\n \treturn std::make_pair(this->end(), this->end());\n@@ -852,28 +1024,24 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     {\n       typename _Hashtable::_Hash_code_type __code = this->_M_hash_code(__k);\n       std::size_t __n = this->_M_bucket_index(__k, __code, _M_bucket_count);\n-      _Node** __head = _M_buckets + __n;\n-      _Node* __p = _M_find_node(*__head, __k, __code);\n+      _Node* __p = _M_find_node(__n, __k, __code);\n \n       if (__p)\n \t{\n \t  _Node* __p1 = __p->_M_next;\n-\t  for (; __p1; __p1 = __p1->_M_next)\n-\t    if (!this->_M_compare(__k, __code, __p1))\n-\t      break;\n+\t  while (__p1\n+\t\t && this->_M_bucket_index(__p1, _M_bucket_count) == __n\n+\t\t && this->_M_compare(__k, __code, __p1))\n+\t    __p1 = __p1->_M_next;\n \n-\t  const_iterator __first(__p, __head);\n-\t  const_iterator __last(__p1, __head);\n-\t  if (!__p1)\n-\t    __last._M_incr_bucket();\n-\t  return std::make_pair(__first, __last);\n+\t  return std::make_pair(const_iterator(__p), const_iterator(__p1));\n \t}\n       else\n \treturn std::make_pair(this->end(), this->end());\n     }\n \n-  // Find the node whose key compares equal to k, beginning the search\n-  // at p (usually the head of a bucket).  Return nullptr if no node is found.\n+  // Find the node whose key compares equal to k in the bucket n. Return nullptr\n+  // if no node is found.\n   template<typename _Key, typename _Value,\n \t   typename _Allocator, typename _ExtractKey, typename _Equal,\n \t   typename _H1, typename _H2, typename _Hash, typename _RehashPolicy,\n@@ -883,15 +1051,133 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t\t\t__chc, __cit, __uk>::_Node*\n     _Hashtable<_Key, _Value, _Allocator, _ExtractKey, _Equal,\n \t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n-    _M_find_node(_Node* __p, const key_type& __k,\n+    _M_find_node(size_type __n, const key_type& __k,\n \t\ttypename _Hashtable::_Hash_code_type __code) const\n     {\n-      for (; __p; __p = __p->_M_next)\n-\tif (this->_M_compare(__k, __code, __p))\n-\t  return __p;\n+      _Node* __p = _M_bucket_begin(__n);\n+      if (!__p)\n+\treturn nullptr;\n+      for (;; __p = __p->_M_next)\n+\t{\n+\t  if (this->_M_compare(__k, __code, __p))\n+\t    return __p;\n+\t  if (!(__p->_M_next)\n+\t      || this->_M_bucket_index(__p->_M_next, _M_bucket_count) != __n)\n+\t    break;\n+\t}\n       return nullptr;\n     }\n \n+  template<typename _Key, typename _Value,\n+\t   typename _Allocator, typename _ExtractKey, typename _Equal,\n+\t   typename _H1, typename _H2, typename _Hash, typename _RehashPolicy,\n+\t   bool __chc, bool __cit, bool __uk>\n+    void\n+    _Hashtable<_Key, _Value, _Allocator, _ExtractKey, _Equal,\n+\t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n+    _M_insert_bucket_begin(size_type __bkt, _Node* __new_node)\n+    {\n+      _Node* __prev_n;\n+      if (__bkt < _M_begin_bucket_index)\n+\t{\n+\t  if (_M_begin_bucket_index != _M_bucket_count)\n+\t    {\n+\t      __new_node->_M_next = _M_buckets[_M_begin_bucket_index];\n+\t      _M_buckets[_M_begin_bucket_index] = __new_node;\n+\t    }\n+\t  __prev_n = __new_node;\n+\t  _M_begin_bucket_index = __bkt;\n+\t}\n+      else\n+\t{\n+\t  // We need to find previous non-empty bucket to link the new node.\n+\t  // There are several ways to find this previous bucket:\n+\t  // 1. Move backward until we find it (the current method)\n+\t  // 2. Start from the begin bucket index and move forward until we\n+\t  // cross __n position.\n+\t  // 3. Move forward until we find a non-empty bucket that will\n+\t  // contain the previous node.\n+\t  size_type __prev_bkt;\n+\t  for (__prev_bkt = __bkt; __prev_bkt-- != 0;)\n+\t    if (_M_buckets[__prev_bkt])\n+\t      break;\n+\t  __prev_n = _M_bucket_end(__prev_bkt);\n+\t  _M_insert_after(__prev_bkt, __prev_n, __new_node);\n+\t}\n+      _M_buckets[__bkt] = __prev_n;\n+    }\n+\n+  template<typename _Key, typename _Value,\n+\t   typename _Allocator, typename _ExtractKey, typename _Equal,\n+\t   typename _H1, typename _H2, typename _Hash, typename _RehashPolicy,\n+\t   bool __chc, bool __cit, bool __uk>\n+    void\n+    _Hashtable<_Key, _Value, _Allocator, _ExtractKey, _Equal,\n+\t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n+    _M_insert_after(size_type __bkt, _Node* __prev_n, _Node* __new_n)\n+    {\n+      if (__prev_n->_M_next)\n+\t{\n+\t  size_type __next_bkt =\n+\t    this->_M_bucket_index(__prev_n->_M_next, _M_bucket_count);\n+\t  if (__next_bkt != __bkt)\n+\t    _M_buckets[__next_bkt] = __new_n;\n+\t}\n+      __new_n->_M_next = __prev_n->_M_next;\n+      __prev_n->_M_next = __new_n;\n+    }\n+\n+  template<typename _Key, typename _Value,\n+\t   typename _Allocator, typename _ExtractKey, typename _Equal,\n+\t   typename _H1, typename _H2, typename _Hash, typename _RehashPolicy,\n+\t   bool __chc, bool __cit, bool __uk>\n+    void\n+    _Hashtable<_Key, _Value, _Allocator, _ExtractKey, _Equal,\n+\t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n+    _M_remove_bucket_begin(size_type __bkt, _Node* __next, size_type __next_bkt)\n+    {\n+      if (!__next || __next_bkt != __bkt)\n+\t{\n+\t  // Bucket is now empty\n+\t  if (__next && __next_bkt != __bkt)\n+\t    // Update next non-empty bucket before begin node\n+\t    _M_buckets[__next_bkt] = _M_buckets[__bkt];\n+\t  _M_buckets[__bkt] = nullptr;\n+\t  if (__bkt == _M_begin_bucket_index)\n+\t    // We need to update begin bucket index\n+\t    if (__next)\n+\t      {\n+\t\t_M_begin_bucket_index = __next_bkt;\n+\t\t_M_buckets[_M_begin_bucket_index] = __next;\n+\t      }\n+\t    else\n+\t      _M_begin_bucket_index = _M_bucket_count;\n+\t}\n+      else if (__bkt == _M_begin_bucket_index)\n+\t_M_buckets[__bkt] = __next;\n+    }\n+\n+  template<typename _Key, typename _Value,\n+\t   typename _Allocator, typename _ExtractKey, typename _Equal,\n+\t   typename _H1, typename _H2, typename _Hash, typename _RehashPolicy,\n+\t   bool __chc, bool __cit, bool __uk>\n+    typename _Hashtable<_Key, _Value, _Allocator, _ExtractKey,\n+\t\t\t_Equal, _H1, _H2, _Hash, _RehashPolicy,\n+\t\t\t__chc, __cit, __uk>::_Node*\n+    _Hashtable<_Key, _Value, _Allocator, _ExtractKey, _Equal,\n+\t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n+    _M_get_previous_node(size_type __bkt, _Node* __n)\n+    {\n+      _Node* __prev_n = nullptr;\n+      if (__bkt != _M_begin_bucket_index || __n != _M_buckets[__bkt])\n+\t{\n+\t  __prev_n = _M_buckets[__bkt];\n+\t  while (__prev_n->_M_next != __n)\n+\t    __prev_n = __prev_n->_M_next;\n+\t}\n+      return __prev_n;\n+    }\n+\n   // Insert v in bucket n (assumes no element with its key already present).\n   template<typename _Key, typename _Value,\n \t   typename _Allocator, typename _ExtractKey, typename _Equal,\n@@ -906,7 +1192,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       _M_insert_bucket(_Arg&& __v, size_type __n,\n \t\t       typename _Hashtable::_Hash_code_type __code)\n       {\n-\tconst size_type __saved_next_resize = _M_rehash_policy._M_next_resize;\n+\tconst _RehashPolicyState& __saved_state = _M_rehash_policy._M_state();\n \tstd::pair<bool, std::size_t> __do_rehash\n \t  = _M_rehash_policy._M_need_rehash(_M_bucket_count,\n \t\t\t\t\t    _M_element_count, 1);\n@@ -917,27 +1203,27 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t    __n = this->_M_bucket_index(__k, __code, __do_rehash.second);\n \t  }\n \n-\t_Node* __new_node = 0;\n+\t_Node* __new_node = nullptr;\n \t__try\n \t  {\n \t    // Allocate the new node before doing the rehash so that we\n \t    // don't do a rehash if the allocation throws.\n \t    __new_node = _M_allocate_node(std::forward<_Arg>(__v));\n+\t    this->_M_store_code(__new_node, __code);\n \t    if (__do_rehash.first)\n-\t      _M_rehash(__do_rehash.second, __saved_next_resize);\n+\t      _M_rehash(__do_rehash.second, __saved_state);\n \n-\t    __new_node->_M_next = _M_buckets[__n];\n-\t    this->_M_store_code(__new_node, __code);\n-\t    _M_buckets[__n] = __new_node;\n+\t    if (_M_buckets[__n])\n+\t      _M_insert_after(__n, _M_buckets[__n], __new_node);\n+\t    else \n+\t      _M_insert_bucket_begin(__n, __new_node);\n \t    ++_M_element_count;\n-\t    if (__n < _M_begin_bucket_index)\n-\t      _M_begin_bucket_index = __n;\n-\t    return iterator(__new_node, _M_buckets + __n);\n+\t    return iterator(__new_node);\n \t  }\n \t__catch(...)\n \t  {\n \t    if (!__new_node)\n-\t      _M_rehash_policy._M_next_resize = __saved_next_resize;\n+\t      _M_rehash_policy._M_reset(__saved_state);\n \t    else\n \t      _M_deallocate_node(__new_node);\n \t    __throw_exception_again;\n@@ -962,8 +1248,8 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \ttypename _Hashtable::_Hash_code_type __code = this->_M_hash_code(__k);\n \tsize_type __n = this->_M_bucket_index(__k, __code, _M_bucket_count);\n \n-\tif (_Node* __p = _M_find_node(_M_buckets[__n], __k, __code))\n-\t  return std::make_pair(iterator(__p, _M_buckets + __n), false);\n+\tif (_Node* __p = _M_find_node(__n, __k, __code))\n+\t  return std::make_pair(iterator(__p), false);\n \treturn std::make_pair(_M_insert_bucket(std::forward<_Arg>(__v),\n \t\t\t      __n, __code), true);\n       }\n@@ -981,37 +1267,58 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t\t _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n       _M_insert(_Arg&& __v, std::false_type)\n       {\n-\tconst size_type __saved_next_resize = _M_rehash_policy._M_next_resize;\n+\tconst _RehashPolicyState& __saved_state = _M_rehash_policy._M_state();\n \tstd::pair<bool, std::size_t> __do_rehash\n \t  = _M_rehash_policy._M_need_rehash(_M_bucket_count,\n \t\t\t\t\t    _M_element_count, 1);\n-\tif (__do_rehash.first)\n-\t  _M_rehash(__do_rehash.second, __saved_next_resize);\n \n \tconst key_type& __k = this->_M_extract(__v);\n \ttypename _Hashtable::_Hash_code_type __code = this->_M_hash_code(__k);\n \tsize_type __n = this->_M_bucket_index(__k, __code, _M_bucket_count);\n \n \t// First find the node, avoid leaking new_node if compare throws.\n-\t_Node* __prev = _M_find_node(_M_buckets[__n], __k, __code);\n-\t_Node* __new_node = _M_allocate_node(std::forward<_Arg>(__v));\n-\n-\tif (__prev)\n+\t_Node* __prev = _M_find_node(__n, __k, __code);\n+\t_Node* __new_node = nullptr;\n+\t__try\n \t  {\n-\t    __new_node->_M_next = __prev->_M_next;\n-\t    __prev->_M_next = __new_node;\n+\t    // Second allocate new node so that we don't rehash if it throws\n+\t    __new_node = _M_allocate_node(std::forward<_Arg>(__v));\n+\t    this->_M_store_code(__new_node, __code);\n+\t    if (__do_rehash.first)\n+\t      {\n+\t\t_M_rehash(__do_rehash.second, __saved_state);\n+\t\t__n = this->_M_bucket_index(__k, __code, _M_bucket_count);\n+\t\t// __prev is still valid because rehash do not invalidate nodes\n+\t      }\n+\n+\t    if (__prev)\n+\t      // Insert after the previous equivalent node\n+\t      _M_insert_after(__n, __prev, __new_node);\n+\t    else if (_M_buckets[__n])\n+\t      // Bucket is not empty and the inserted node has no equivalent in\n+\t      // the hashtable. We must insert the new node at the beginning or\n+\t      // end of the bucket to preserve equivalent elements relative\n+\t      // positions.\n+\t      if (__n != _M_begin_bucket_index)\n+\t\t// We insert the new node at the beginning\n+\t\t_M_insert_after(__n, _M_buckets[__n], __new_node);\n+\t      else\n+\t\t// We insert the new node at the end\n+\t\t_M_insert_after(__n, _M_bucket_end(__n), __new_node);\n+\t    else\n+\t      _M_insert_bucket_begin(__n, __new_node);\n+\t    ++_M_element_count;\n+\t    return iterator(__new_node);\n \t  }\n-\telse\n+\t__catch(...)\n \t  {\n-\t    __new_node->_M_next = _M_buckets[__n];\n-\t    _M_buckets[__n] = __new_node;\n-\t    if (__n < _M_begin_bucket_index)\n-\t      _M_begin_bucket_index = __n;\n+\t    if (!__new_node)\n+\t      _M_rehash_policy._M_reset(__saved_state);\n+\t    else\n+\t      _M_deallocate_node(__new_node);\n+\t    __throw_exception_again;\n \t  }\n-\tthis->_M_store_code(__new_node, __code);\n \n-\t++_M_element_count;\n-\treturn iterator(__new_node, _M_buckets + __n);\n       }\n \n   template<typename _Key, typename _Value,\n@@ -1025,12 +1332,12 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       insert(_InputIterator __first, _InputIterator __last)\n       {\n \tsize_type __n_elt = __detail::__distance_fw(__first, __last);\n-\tconst size_type __saved_next_resize = _M_rehash_policy._M_next_resize;\n+\tconst _RehashPolicyState& __saved_state = _M_rehash_policy._M_state();\n \tstd::pair<bool, std::size_t> __do_rehash\n \t  = _M_rehash_policy._M_need_rehash(_M_bucket_count,\n \t\t\t\t\t    _M_element_count, __n_elt);\n \tif (__do_rehash.first)\n-\t  _M_rehash(__do_rehash.second, __saved_next_resize);\n+\t  _M_rehash(__do_rehash.second, __saved_state);\n \n \tfor (; __first != __last; ++__first)\n \t  this->insert(*__first);\n@@ -1047,31 +1354,29 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n     erase(const_iterator __it)\n     {\n-      iterator __result(__it._M_cur_node, __it._M_cur_bucket);\n-      ++__result;\n-\n-      _Node* __cur = *__it._M_cur_bucket;\n-      if (__cur == __it._M_cur_node)\n+      _Node* __n = __it._M_cur;\n+      std::size_t __bkt = this->_M_bucket_index(__n, _M_bucket_count);\n+\n+      // Look for previous node to unlink it from the erased one, this is why\n+      // we need buckets to contain the before begin node of the bucket to make\n+      // this research fast.\n+      _Node* __prev_n = _M_get_previous_node(__bkt, __n);\n+      if (__n == _M_bucket_begin(__bkt))\n+\t_M_remove_bucket_begin(__bkt, __n->_M_next,\n+\t   __n->_M_next ? this->_M_bucket_index(__n->_M_next, _M_bucket_count)\n+\t\t\t: 0);\n+      else if (__n->_M_next)\n \t{\n-\t  *__it._M_cur_bucket = __cur->_M_next;\n-\n-\t  // If _M_begin_bucket_index no longer indexes the first non-empty\n-\t  // bucket - its single node is being erased - update it.\n-\t  if (!_M_buckets[_M_begin_bucket_index])\n-\t    _M_begin_bucket_index = __result._M_cur_bucket - _M_buckets;\n-\t}\n-      else\n-\t{\n-\t  _Node* __next = __cur->_M_next;\n-\t  while (__next != __it._M_cur_node)\n-\t    {\n-\t      __cur = __next;\n-\t      __next = __cur->_M_next;\n-\t    }\n-\t  __cur->_M_next = __next->_M_next;\n+\t  size_type __next_bkt =\n+\t    this->_M_bucket_index(__n->_M_next, _M_bucket_count);\n+\t  if (__next_bkt != __bkt)\n+\t    _M_buckets[__next_bkt] = __prev_n;\n \t}\n \n-      _M_deallocate_node(__it._M_cur_node);\n+      if (__prev_n)\n+\t__prev_n->_M_next = __n->_M_next;\n+      iterator __result(__n->_M_next);\n+      _M_deallocate_node(__n);\n       --_M_element_count;\n \n       return __result;\n@@ -1089,64 +1394,65 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     erase(const key_type& __k)\n     {\n       typename _Hashtable::_Hash_code_type __code = this->_M_hash_code(__k);\n-      std::size_t __n = this->_M_bucket_index(__k, __code, _M_bucket_count);\n-      size_type __result = 0;\n-\n-      _Node** __slot = _M_buckets + __n;\n-      while (*__slot && !this->_M_compare(__k, __code, *__slot))\n-\t__slot = &((*__slot)->_M_next);\n+      std::size_t __bkt = this->_M_bucket_index(__k, __code, _M_bucket_count);\n+      // Look for the first matching node with its previous node at the same\n+      // time\n+      _Node* __n = _M_buckets[__bkt];\n+      if (!__n)\n+\treturn 0;\n+      _Node* __prev_n = nullptr;\n+      if (__bkt != _M_begin_bucket_index)\n+\t{\n+\t  __prev_n = __n;\n+\t  __n = __n->_M_next;\n+\t}\n+      bool __is_bucket_begin = true;\n+      for (;; __prev_n = __n, __n = __n->_M_next)\n+\t{\n+\t  if (this->_M_compare(__k, __code, __n))\n+\t    break;\n+\t  if (!(__n->_M_next)\n+\t      || this->_M_bucket_index(__n->_M_next, _M_bucket_count) != __bkt)\n+\t    return 0;\n+\t  __is_bucket_begin = false;\n+\t}\n \n-      _Node** __saved_slot = 0;\n-      while (*__slot && this->_M_compare(__k, __code, *__slot))\n+      // We found a matching node, start deallocation loop from it\n+      std::size_t __next_bkt = __bkt;\n+      _Node* __next_n = __n;\n+      size_type __result = 0;\n+      _Node* __saved_n = nullptr;\n+      do\n \t{\n+\t  _Node* __p = __next_n;\n+\t  __next_n = __p->_M_next;\n \t  // _GLIBCXX_RESOLVE_LIB_DEFECTS\n \t  // 526. Is it undefined if a function in the standard changes\n \t  // in parameters?\n-\t  if (std::__addressof(this->_M_extract((*__slot)->_M_v))\n+\t  if (std::__addressof(this->_M_extract(__p->_M_v))\n \t      != std::__addressof(__k))\n-\t    {\n-\t      _Node* __p = *__slot;\n-\t      *__slot = __p->_M_next;\n-\t      _M_deallocate_node(__p);\n-\t      --_M_element_count;\n-\t      ++__result;\n-\t    }\n+\t    _M_deallocate_node(__p);\n \t  else\n-\t    {\n-\t      __saved_slot = __slot;\n-\t      __slot = &((*__slot)->_M_next);\n-\t    }\n-\t}\n-\n-      if (__saved_slot)\n-\t{\n-\t  _Node* __p = *__saved_slot;\n-\t  *__saved_slot = __p->_M_next;\n-\t  _M_deallocate_node(__p);\n+\t    __saved_n = __p;\n \t  --_M_element_count;\n \t  ++__result;\n+\t  if (!__next_n)\n+\t    break;\n+\t  __next_bkt = this->_M_bucket_index(__next_n, _M_bucket_count);\n \t}\n-\n-      // If the entire bucket indexed by _M_begin_bucket_index has been\n-      // erased look forward for the first non-empty bucket.\n-      if (!_M_buckets[_M_begin_bucket_index])\n-\t{\n-\t  if (!_M_element_count)\n-\t    _M_begin_bucket_index = _M_bucket_count;\n-\t  else\n-\t    {\n-\t      ++_M_begin_bucket_index;\n-\t      while (!_M_buckets[_M_begin_bucket_index])\n-\t\t++_M_begin_bucket_index;\n-\t    }\n-\t}\n-\n+      while (__next_bkt == __bkt && this->_M_compare(__k, __code, __next_n));\n+\n+      if (__saved_n)\n+\t_M_deallocate_node(__saved_n);\n+      if (__is_bucket_begin)\n+\t_M_remove_bucket_begin(__bkt, __next_n, __next_bkt);\n+      else if (__next_n && __next_bkt != __bkt)\n+\t_M_buckets[__next_bkt] = __prev_n;\n+      if (__prev_n)\n+\t__prev_n->_M_next = __next_n;\n       return __result;\n     }\n \n-  // ??? This could be optimized by taking advantage of the bucket\n-  // structure, but it's not clear that it's worth doing.  It probably\n-  // wouldn't even be an optimization unless the load factor is large.\n   template<typename _Key, typename _Value,\n \t   typename _Allocator, typename _ExtractKey, typename _Equal,\n \t   typename _H1, typename _H2, typename _Hash, typename _RehashPolicy,\n@@ -1158,9 +1464,42 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n     erase(const_iterator __first, const_iterator __last)\n     {\n-       while (__first != __last)\n-\t __first = this->erase(__first);\n-      return iterator(__last._M_cur_node, __last._M_cur_bucket);\n+      _Node* __n = __first._M_cur;\n+      _Node* __last_n = __last._M_cur;\n+      if (__n == __last_n)\n+\treturn iterator(__n);\n+\n+      std::size_t __bkt = this->_M_bucket_index(__n, _M_bucket_count);\n+\n+      _Node* __prev_n = _M_get_previous_node(__bkt, __n);\n+      bool __is_bucket_begin = __n == _M_bucket_begin(__bkt);\n+      std::size_t __n_bkt = __bkt;\n+      for (;;)\n+\t{\n+\t  do\n+\t    {\n+\t      _Node* __tmp = __n;\n+\t      __n = __n->_M_next;\n+\t      _M_deallocate_node(__tmp);\n+\t      --_M_element_count;\n+\t      if (!__n)\n+\t\tbreak;\n+\t      __n_bkt = this->_M_bucket_index(__n, _M_bucket_count);\n+\t    }\n+\t  while (__n != __last_n && __n_bkt == __bkt);\n+\t  if (__is_bucket_begin)\n+\t    _M_remove_bucket_begin(__bkt, __n, __n_bkt);\n+\t  if (__n == __last_n)\n+\t    break;\n+\t  __is_bucket_begin = true;\n+\t  __bkt = __n_bkt;\n+\t}\n+\n+      if (__n && __n_bkt != __bkt)\n+\t_M_buckets[__n_bkt] = __prev_n;\n+      if (__prev_n)\n+\t__prev_n->_M_next = __n;\n+      return iterator(__n);\n     }\n \n   template<typename _Key, typename _Value,\n@@ -1172,7 +1511,8 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n     clear() noexcept\n     {\n-      _M_deallocate_nodes(_M_buckets, _M_bucket_count);\n+      _M_deallocate_nodes(_M_buckets[_M_begin_bucket_index]);\n+      __builtin_memset(_M_buckets, 0, _M_bucket_count * sizeof(_Bucket));\n       _M_element_count = 0;\n       _M_begin_bucket_index = _M_bucket_count;\n     }\n@@ -1186,11 +1526,11 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n \t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n     rehash(size_type __n)\n     {\n-      const size_type __saved_next_resize = _M_rehash_policy._M_next_resize;\n+      const _RehashPolicyState& __saved_state = _M_rehash_policy._M_state();\n       _M_rehash(std::max(_M_rehash_policy._M_next_bkt(__n),\n \t\t\t _M_rehash_policy._M_bkt_for_elements(_M_element_count\n \t\t\t\t\t\t\t      + 1)),\n-\t\t__saved_next_resize);\n+\t\t__saved_state);\n     }\n \n   template<typename _Key, typename _Value,\n@@ -1200,46 +1540,75 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     void\n     _Hashtable<_Key, _Value, _Allocator, _ExtractKey, _Equal,\n \t       _H1, _H2, _Hash, _RehashPolicy, __chc, __cit, __uk>::\n-    _M_rehash(size_type __n, size_type __next_resize)\n+    _M_rehash(size_type __n, const _RehashPolicyState& __state)\n     {\n-      _Node** __new_array = 0;\n+      _Bucket* __new_buckets = nullptr;\n+      _Node* __p = _M_buckets[_M_begin_bucket_index];\n       __try\n \t{\n-\t  __new_array = _M_allocate_buckets(__n);\n+\t  __new_buckets = _M_allocate_buckets(__n);\n+\t  // First loop to store each node in its new bucket\n+\t  while (__p)\n+\t    {\n+\t      _Node* __next = __p->_M_next;\n+\t      std::size_t __new_index = this->_M_bucket_index(__p, __n);\n+\t      if (!__new_buckets[__new_index])\n+\t\t// Store temporarily bucket end node in _M_buckets if possible.\n+\t\t// This will boost second loop where we need to access bucket\n+\t\t// end node quickly.\n+\t\tif (__new_index < _M_bucket_count)\n+\t\t  _M_buckets[__new_index] = __p;\n+\t      __p->_M_next = __new_buckets[__new_index];\n+\t      __new_buckets[__new_index] = __p;\n+\t      __p = __next;\n+\t    }\n \t  _M_begin_bucket_index = __n;\n-\t  for (size_type __i = 0; __i < _M_bucket_count; ++__i)\n-\t    while (_Node* __p = _M_buckets[__i])\n+\t  _Node* __prev_node = nullptr;\n+\t  // Second loop to link all nodes together and to fix bucket values so\n+\t  // that they contain the before begin node of the bucket.\n+\t  for (size_type __i = 0; __i != __n; ++__i)\n+\t    if (__new_buckets[__i])\n \t      {\n-\t\tstd::size_t __new_index = this->_M_bucket_index(__p, __n);\n-\t\t_M_buckets[__i] = __p->_M_next;\n-\t\t__p->_M_next = __new_array[__new_index];\n-\t\t__new_array[__new_index] = __p;\n-\t\tif (__new_index < _M_begin_bucket_index)\n-\t\t  _M_begin_bucket_index = __new_index;\n+\t\tif (__prev_node)\n+\t\t  {\n+\t\t    __prev_node->_M_next = __new_buckets[__i];\n+\t\t    __new_buckets[__i] = __prev_node;\n+\t\t  }\n+\t\telse\n+\t\t  _M_begin_bucket_index = __i;\n+\t\tif (__i < _M_bucket_count)\n+\t\t  __prev_node = _M_buckets[__i];\n+\t\telse\n+\t\t  {\n+\t\t    __prev_node = __new_buckets[__i];\n+\t\t    while (__prev_node->_M_next)\n+\t\t      __prev_node = __prev_node->_M_next;\n+\t\t  }\n \t      }\n \t  _M_deallocate_buckets(_M_buckets, _M_bucket_count);\n \t  _M_bucket_count = __n;\n-\t  _M_buckets = __new_array;\n+\t  _M_buckets = __new_buckets;\n \t}\n       __catch(...)\n \t{\n-\t  if (__new_array)\n+\t  if (__new_buckets)\n \t    {\n \t      // A failure here means that a hash function threw an exception.\n \t      // We can't restore the previous state without calling the hash\n \t      // function again, so the only sensible recovery is to delete\n \t      // everything.\n-\t      _M_deallocate_nodes(__new_array, __n);\n-\t      _M_deallocate_buckets(__new_array, __n);\n-\t      _M_deallocate_nodes(_M_buckets, _M_bucket_count);\n+\t      _M_deallocate_nodes(__new_buckets, __n);\n+\t      _M_deallocate_buckets(__new_buckets, __n);\n+\t      _M_deallocate_nodes(__p);\n+\t      __builtin_memset(_M_buckets, 0, sizeof(_Bucket) * _M_bucket_count);\n \t      _M_element_count = 0;\n \t      _M_begin_bucket_index = _M_bucket_count;\n-\t      _M_rehash_policy._M_next_resize = 0;\n+\t      _M_rehash_policy._M_reset(_RehashPolicyState());\n \t    }\n \t  else\n \t    // A failure here means that buckets allocation failed.  We only\n \t    // have to restore hash policy previous state.\n-\t    _M_rehash_policy._M_next_resize = __next_resize;\n+\t    _M_rehash_policy._M_reset(__state);\n \t  __throw_exception_again;\n \t}\n     }"}, {"sha": "44c749af515bd170a50d76d1b6353c99a5a1eef2", "filename": "libstdc++-v3/include/bits/hashtable_policy.h", "status": "modified", "additions": 55, "deletions": 176, "changes": 231, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fhashtable_policy.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fhashtable_policy.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fbits%2Fhashtable_policy.h?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -59,6 +59,13 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       return __distance_fw(__first, __last, _Tag());\n     }\n \n+  // Helper type used to detect when the hash functor is noexcept qualified or\n+  // not\n+  template <typename _Key, typename _Hash>\n+    struct __is_noexcept_hash : std::integral_constant<bool,\n+\tnoexcept(declval<const _Hash&>()(declval<const _Key&>()))>\n+    {};\n+\n   // Auxiliary types used for all instantiations of _Hashtable: nodes\n   // and iterators.\n \n@@ -211,155 +218,6 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       }\n     };\n \n-  template<typename _Value, bool __cache>\n-    struct _Hashtable_iterator_base\n-    {\n-      _Hashtable_iterator_base(_Hash_node<_Value, __cache>* __node,\n-\t\t\t       _Hash_node<_Value, __cache>** __bucket)\n-      : _M_cur_node(__node), _M_cur_bucket(__bucket) { }\n-\n-      void\n-      _M_incr()\n-      {\n-\t_M_cur_node = _M_cur_node->_M_next;\n-\tif (!_M_cur_node)\n-\t  _M_incr_bucket();\n-      }\n-\n-      void\n-      _M_incr_bucket();\n-\n-      _Hash_node<_Value, __cache>*   _M_cur_node;\n-      _Hash_node<_Value, __cache>**  _M_cur_bucket;\n-    };\n-\n-  // Global iterators, used for arbitrary iteration within a hash\n-  // table.  Larger and more expensive than local iterators.\n-  template<typename _Value, bool __cache>\n-    void\n-    _Hashtable_iterator_base<_Value, __cache>::\n-    _M_incr_bucket()\n-    {\n-      ++_M_cur_bucket;\n-\n-      // This loop requires the bucket array to have a non-null sentinel.\n-      while (!*_M_cur_bucket)\n-\t++_M_cur_bucket;\n-      _M_cur_node = *_M_cur_bucket;\n-    }\n-\n-  template<typename _Value, bool __cache>\n-    inline bool\n-    operator==(const _Hashtable_iterator_base<_Value, __cache>& __x,\n-\t       const _Hashtable_iterator_base<_Value, __cache>& __y)\n-    { return __x._M_cur_node == __y._M_cur_node; }\n-\n-  template<typename _Value, bool __cache>\n-    inline bool\n-    operator!=(const _Hashtable_iterator_base<_Value, __cache>& __x,\n-\t       const _Hashtable_iterator_base<_Value, __cache>& __y)\n-    { return __x._M_cur_node != __y._M_cur_node; }\n-\n-  template<typename _Value, bool __constant_iterators, bool __cache>\n-    struct _Hashtable_iterator\n-    : public _Hashtable_iterator_base<_Value, __cache>\n-    {\n-      typedef _Value                                   value_type;\n-      typedef typename std::conditional<__constant_iterators,\n-\t\t\t\t\tconst _Value*, _Value*>::type\n-\t\t\t\t\t\t       pointer;\n-      typedef typename std::conditional<__constant_iterators,\n-\t\t\t\t\tconst _Value&, _Value&>::type\n-\t\t\t\t\t\t       reference;\n-      typedef std::ptrdiff_t                           difference_type;\n-      typedef std::forward_iterator_tag                iterator_category;\n-\n-      _Hashtable_iterator()\n-      : _Hashtable_iterator_base<_Value, __cache>(0, 0) { }\n-\n-      _Hashtable_iterator(_Hash_node<_Value, __cache>* __p,\n-\t\t\t  _Hash_node<_Value, __cache>** __b)\n-      : _Hashtable_iterator_base<_Value, __cache>(__p, __b) { }\n-\n-      explicit\n-      _Hashtable_iterator(_Hash_node<_Value, __cache>** __b)\n-      : _Hashtable_iterator_base<_Value, __cache>(*__b, __b) { }\n-\n-      reference\n-      operator*() const\n-      { return this->_M_cur_node->_M_v; }\n-\n-      pointer\n-      operator->() const\n-      { return std::__addressof(this->_M_cur_node->_M_v); }\n-\n-      _Hashtable_iterator&\n-      operator++()\n-      {\n-\tthis->_M_incr();\n-\treturn *this;\n-      }\n-\n-      _Hashtable_iterator\n-      operator++(int)\n-      {\n-\t_Hashtable_iterator __tmp(*this);\n-\tthis->_M_incr();\n-\treturn __tmp;\n-      }\n-    };\n-\n-  template<typename _Value, bool __constant_iterators, bool __cache>\n-    struct _Hashtable_const_iterator\n-    : public _Hashtable_iterator_base<_Value, __cache>\n-    {\n-      typedef _Value                                   value_type;\n-      typedef const _Value*                            pointer;\n-      typedef const _Value&                            reference;\n-      typedef std::ptrdiff_t                           difference_type;\n-      typedef std::forward_iterator_tag                iterator_category;\n-\n-      _Hashtable_const_iterator()\n-      : _Hashtable_iterator_base<_Value, __cache>(0, 0) { }\n-\n-      _Hashtable_const_iterator(_Hash_node<_Value, __cache>* __p,\n-\t\t\t\t_Hash_node<_Value, __cache>** __b)\n-      : _Hashtable_iterator_base<_Value, __cache>(__p, __b) { }\n-\n-      explicit\n-      _Hashtable_const_iterator(_Hash_node<_Value, __cache>** __b)\n-      : _Hashtable_iterator_base<_Value, __cache>(*__b, __b) { }\n-\n-      _Hashtable_const_iterator(const _Hashtable_iterator<_Value,\n-\t\t\t\t__constant_iterators, __cache>& __x)\n-      : _Hashtable_iterator_base<_Value, __cache>(__x._M_cur_node,\n-\t\t\t\t\t\t  __x._M_cur_bucket) { }\n-\n-      reference\n-      operator*() const\n-      { return this->_M_cur_node->_M_v; }\n-\n-      pointer\n-      operator->() const\n-      { return std::__addressof(this->_M_cur_node->_M_v); }\n-\n-      _Hashtable_const_iterator&\n-      operator++()\n-      {\n-\tthis->_M_incr();\n-\treturn *this;\n-      }\n-\n-      _Hashtable_const_iterator\n-      operator++(int)\n-      {\n-\t_Hashtable_const_iterator __tmp(*this);\n-\tthis->_M_incr();\n-\treturn __tmp;\n-      }\n-    };\n-\n-\n   // Many of class template _Hashtable's template parameters are policy\n   // classes.  These are defaults for the policies.\n \n@@ -388,7 +246,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n   struct _Prime_rehash_policy\n   {\n     _Prime_rehash_policy(float __z = 1.0)\n-    : _M_max_load_factor(__z), _M_growth_factor(2.f), _M_next_resize(0) { }\n+    : _M_max_load_factor(__z), _M_prev_resize(0), _M_next_resize(0) { }\n \n     float\n     max_load_factor() const noexcept\n@@ -410,10 +268,23 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n     _M_need_rehash(std::size_t __n_bkt, std::size_t __n_elt,\n \t\t   std::size_t __n_ins) const;\n \n+    typedef std::pair<std::size_t, std::size_t> _State;\n+\n+    _State\n+    _M_state() const\n+    { return std::make_pair(_M_prev_resize, _M_next_resize); }\n+\n+    void\n+    _M_reset(const _State& __state)\n+    {\n+      _M_prev_resize = __state.first;\n+      _M_next_resize = __state.second;\n+    }\n+\n     enum { _S_n_primes = sizeof(unsigned long) != 8 ? 256 : 256 + 48 };\n \n     float                _M_max_load_factor;\n-    float                _M_growth_factor;\n+    mutable std::size_t  _M_prev_resize;\n     mutable std::size_t  _M_next_resize;\n   };\n \n@@ -429,15 +300,24 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n   {\n     // Optimize lookups involving the first elements of __prime_list.\n     // (useful to speed-up, eg, constructors)\n-    static const unsigned char __fast_bkt[12]\n+    static const unsigned long __fast_bkt[12]\n       = { 2, 2, 2, 3, 5, 5, 7, 7, 11, 11, 11, 11 };\n \n-    const unsigned long __p\n-      = __n <= 11 ? __fast_bkt[__n]\n-                  : *std::lower_bound(__prime_list + 5,\n-\t\t\t\t      __prime_list + _S_n_primes, __n);\n-    _M_next_resize = __builtin_floor(__p * (long double)_M_max_load_factor);\n-    return __p;\n+    const unsigned long* __p\n+      = __n <= 11 ? __fast_bkt + __n\n+\t\t  : std::lower_bound(__prime_list + 5,\n+\t\t\t\t     __prime_list + _S_n_primes, __n);\n+\n+    _M_prev_resize = __builtin_floor(*__p * (long double)_M_max_load_factor);\n+    if (__p != __fast_bkt)\n+      _M_prev_resize = std::min(_M_prev_resize,\n+\t\t\t\tstatic_cast<std::size_t>(*(__p - 1)));\n+    // Lets guaranty a minimal grow step of 11:\n+    if (*__p - __n < 11)\n+      __p = std::lower_bound(__prime_list + 5,\n+\t\t\t     __prime_list + _S_n_primes, __n + 11);\n+    _M_next_resize = __builtin_floor(*__p * (long double)_M_max_load_factor);\n+    return *__p;\n   }\n \n   // Return the smallest prime p such that alpha p >= n, where alpha\n@@ -461,24 +341,27 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n   _M_need_rehash(std::size_t __n_bkt, std::size_t __n_elt,\n \t\t std::size_t __n_ins) const\n   {\n-    if (__n_elt + __n_ins > _M_next_resize)\n+    if (__n_elt + __n_ins >= _M_next_resize)\n       {\n-\tlong double __min_bkts = ((__n_elt + __n_ins)\n-\t\t\t\t  / (long double)_M_max_load_factor);\n-\tif (__min_bkts > __n_bkt)\n-\t  {\n-\t    __min_bkts = std::max(__min_bkts, (long double)_M_growth_factor\n-\t\t\t\t  * __n_bkt);\n-\t    return std::make_pair(true,\n-\t\t\t\t  _M_next_bkt(__builtin_ceil(__min_bkts)));\n-\t  }\n+\tlong double __min_bkts = (__n_elt + __n_ins)\n+\t\t\t\t / (long double)_M_max_load_factor;\n+\tif (__min_bkts >= __n_bkt)\n+\t  return std::make_pair(true,\n+\t\t\t\t_M_next_bkt(__builtin_floor(__min_bkts) + 1));\n \telse\n \t  {\n \t    _M_next_resize\n \t      = __builtin_floor(__n_bkt * (long double)_M_max_load_factor);\n \t    return std::make_pair(false, 0);\n \t  }\n       }\n+    else if (__n_elt + __n_ins < _M_prev_resize)\n+      {\n+\tlong double __min_bkts = (__n_elt + __n_ins)\n+\t\t\t\t / (long double)_M_max_load_factor;\n+\treturn std::make_pair(true,\n+\t\t\t      _M_next_bkt(__builtin_floor(__min_bkts) + 1));\n+      }\n     else\n       return std::make_pair(false, 0);\n   }\n@@ -538,8 +421,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       std::size_t __n = __h->_M_bucket_index(__k, __code,\n \t\t\t\t\t     __h->_M_bucket_count);\n \n-      typename _Hashtable::_Node* __p =\n-\t__h->_M_find_node(__h->_M_buckets[__n], __k, __code);\n+      typename _Hashtable::_Node* __p = __h->_M_find_node(__n, __k, __code);\n       if (!__p)\n \treturn __h->_M_insert_bucket(std::make_pair(__k, mapped_type()),\n \t\t\t\t     __n, __code)->second;\n@@ -557,8 +439,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       std::size_t __n = __h->_M_bucket_index(__k, __code,\n \t\t\t\t\t     __h->_M_bucket_count);\n \n-      typename _Hashtable::_Node* __p =\n-\t__h->_M_find_node(__h->_M_buckets[__n], __k, __code);\n+      typename _Hashtable::_Node* __p = __h->_M_find_node(__n, __k, __code);\n       if (!__p)\n \treturn __h->_M_insert_bucket(std::make_pair(std::move(__k),\n \t\t\t\t\t\t    mapped_type()),\n@@ -577,8 +458,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       std::size_t __n = __h->_M_bucket_index(__k, __code,\n \t\t\t\t\t     __h->_M_bucket_count);\n \n-      typename _Hashtable::_Node* __p =\n-\t__h->_M_find_node(__h->_M_buckets[__n], __k, __code);\n+      typename _Hashtable::_Node* __p = __h->_M_find_node(__n, __k, __code);\n       if (!__p)\n \t__throw_out_of_range(__N(\"_Map_base::at\"));\n       return (__p->_M_v).second;\n@@ -595,8 +475,7 @@ _GLIBCXX_BEGIN_NAMESPACE_VERSION\n       std::size_t __n = __h->_M_bucket_index(__k, __code,\n \t\t\t\t\t     __h->_M_bucket_count);\n \n-      typename _Hashtable::_Node* __p =\n-\t__h->_M_find_node(__h->_M_buckets[__n], __k, __code);\n+      typename _Hashtable::_Node* __p = __h->_M_find_node(__n, __k, __code);\n       if (!__p)\n \t__throw_out_of_range(__N(\"_Map_base::at\"));\n       return (__p->_M_v).second;"}, {"sha": "7c810d3801f787ae43d4fc1c197f8e631dba637c", "filename": "libstdc++-v3/include/bits/unordered_map.h", "status": "modified", "additions": 6, "deletions": 2, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Finclude%2Fbits%2Funordered_map.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Finclude%2Fbits%2Funordered_map.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fbits%2Funordered_map.h?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -40,7 +40,9 @@ _GLIBCXX_BEGIN_NAMESPACE_CONTAINER\n \t   class _Hash = hash<_Key>,\n \t   class _Pred = std::equal_to<_Key>,\n \t   class _Alloc = std::allocator<std::pair<const _Key, _Tp> >,\n-\t   bool __cache_hash_code = false>\n+\t   bool __cache_hash_code =\n+\t     __not_<__and_<is_integral<_Key>,\n+\t\t\t   __detail::__is_noexcept_hash<_Key, _Hash>>>::value>\n     class __unordered_map\n     : public _Hashtable<_Key, std::pair<const _Key, _Tp>, _Alloc,\n \t\t\tstd::_Select1st<std::pair<const _Key, _Tp> >, _Pred, \n@@ -109,7 +111,9 @@ _GLIBCXX_BEGIN_NAMESPACE_CONTAINER\n \t   class _Hash = hash<_Key>,\n \t   class _Pred = std::equal_to<_Key>,\n \t   class _Alloc = std::allocator<std::pair<const _Key, _Tp> >,\n-\t   bool __cache_hash_code = false>\n+\t   bool __cache_hash_code =\n+\t     __not_<__and_<is_integral<_Key>,\n+\t\t\t   __detail::__is_noexcept_hash<_Key, _Hash>>>::value>\n     class __unordered_multimap\n     : public _Hashtable<_Key, std::pair<const _Key, _Tp>,\n \t\t\t_Alloc,"}, {"sha": "9aef08297498c1d6eede671b0d55a84e32659a84", "filename": "libstdc++-v3/include/bits/unordered_set.h", "status": "modified", "additions": 6, "deletions": 2, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Finclude%2Fbits%2Funordered_set.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Finclude%2Fbits%2Funordered_set.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fbits%2Funordered_set.h?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -40,7 +40,9 @@ _GLIBCXX_BEGIN_NAMESPACE_CONTAINER\n \t   class _Hash = hash<_Value>,\n \t   class _Pred = std::equal_to<_Value>,\n \t   class _Alloc = std::allocator<_Value>,\n-\t   bool __cache_hash_code = false>\n+\t   bool __cache_hash_code =\n+\t     __not_<__and_<is_integral<_Value>,\n+\t\t\t   __detail::__is_noexcept_hash<_Value, _Hash>>>::value>\n     class __unordered_set\n     : public _Hashtable<_Value, _Value, _Alloc,\n \t\t\tstd::_Identity<_Value>, _Pred,\n@@ -121,7 +123,9 @@ _GLIBCXX_BEGIN_NAMESPACE_CONTAINER\n \t   class _Hash = hash<_Value>,\n \t   class _Pred = std::equal_to<_Value>,\n \t   class _Alloc = std::allocator<_Value>,\n-\t   bool __cache_hash_code = false>\n+\t   bool __cache_hash_code =\n+\t     __not_<__and_<is_integral<_Value>,\n+\t\t\t   __detail::__is_noexcept_hash<_Value, _Hash>>>::value>\n     class __unordered_multiset\n     : public _Hashtable<_Value, _Value, _Alloc,\n \t\t\tstd::_Identity<_Value>, _Pred,"}, {"sha": "6ad46b627d39c83f097f3dd7e094d65fa40b16b7", "filename": "libstdc++-v3/include/debug/unordered_map", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Finclude%2Fdebug%2Funordered_map", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Finclude%2Fdebug%2Funordered_map", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fdebug%2Funordered_map?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -395,11 +395,11 @@ namespace __debug\n \n       static _Base_local_iterator\n       _S_to_local(_Base_iterator __it)\n-      { return _Base_local_iterator(__it._M_cur_node); }\n+      { return _Base_local_iterator(__it._M_cur); }\n \n       static _Base_const_local_iterator\n       _S_to_local(_Base_const_iterator __it)\n-      { return _Base_const_local_iterator(__it._M_cur_node); }\n+      { return _Base_const_local_iterator(__it._M_cur); }\n     };\n \n   template<typename _Key, typename _Tp, typename _Hash,\n@@ -774,11 +774,11 @@ namespace __debug\n \n       static _Base_local_iterator\n       _S_to_local(_Base_iterator __it)\n-      { return _Base_local_iterator(__it._M_cur_node); }\n+      { return _Base_local_iterator(__it._M_cur); }\n \n       static _Base_const_local_iterator\n       _S_to_local(_Base_const_iterator __it)\n-      { return _Base_const_local_iterator(__it._M_cur_node); }\n+      { return _Base_const_local_iterator(__it._M_cur); }\n     };\n \n   template<typename _Key, typename _Tp, typename _Hash,"}, {"sha": "2f41bc3a25d9e7becfedfdce09847fb490bd6efc", "filename": "libstdc++-v3/include/debug/unordered_set", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Finclude%2Fdebug%2Funordered_set", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Finclude%2Fdebug%2Funordered_set", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Finclude%2Fdebug%2Funordered_set?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -394,11 +394,11 @@ namespace __debug\n \n       static _Base_local_iterator\n       _S_to_local(_Base_iterator __it)\n-      { return _Base_local_iterator(__it._M_cur_node); }\n+      { return _Base_local_iterator(__it._M_cur); }\n \n       static _Base_const_local_iterator\n       _S_to_local(_Base_const_iterator __it)\n-      { return _Base_const_local_iterator(__it._M_cur_node); }\n+      { return _Base_const_local_iterator(__it._M_cur); }\n     };\n \n   template<typename _Value, typename _Hash, typename _Pred, typename _Alloc>\n@@ -759,11 +759,11 @@ namespace __debug\n \n       static _Base_local_iterator\n       _S_to_local(_Base_iterator __it)\n-      { return _Base_local_iterator(__it._M_cur_node); }\n+      { return _Base_local_iterator(__it._M_cur); }\n \n       static _Base_const_local_iterator\n       _S_to_local(_Base_const_iterator __it)\n-      { return _Base_const_local_iterator(__it._M_cur_node); }\n+      { return _Base_const_local_iterator(__it._M_cur); }\n     };\n \n   template<typename _Value, typename _Hash, typename _Pred, typename _Alloc>"}, {"sha": "7e50c302d11fb2cfa189f9fd0d7d5b46866b61a5", "filename": "libstdc++-v3/testsuite/23_containers/unordered_multiset/cons/copy.cc", "status": "added", "additions": 45, "deletions": 0, "changes": 45, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Fcons%2Fcopy.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Fcons%2Fcopy.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Fcons%2Fcopy.cc?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -0,0 +1,45 @@\n+// { dg-options \"-std=gnu++0x\" }\n+\n+// Copyright (C) 2011 Free Software Foundation, Inc.\n+//\n+// This file is part of the GNU ISO C++ Library.  This library is free\n+// software; you can redistribute it and/or modify it under the\n+// terms of the GNU General Public License as published by the\n+// Free Software Foundation; either version 3, or (at your option)\n+// any later version.\n+\n+// This library is distributed in the hope that it will be useful,\n+// but WITHOUT ANY WARRANTY; without even the implied warranty of\n+// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+// GNU General Public License for more details.\n+\n+// You should have received a copy of the GNU General Public License along\n+// with this library; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+\n+// NOTE: This makes use of the fact that we know how moveable\n+// is implemented on set (via swap). If the implementation changed\n+// this test may begin to fail.\n+\n+#include <unordered_set>\n+#include <utility>\n+#include <testsuite_hooks.h>\n+\n+int main()\n+{\n+  bool test __attribute__((unused)) = true;\n+\n+  const int nb = 10000;\n+  std::unordered_multiset<int> ref;\n+  for (int i = 0; i != nb; ++i)\n+    {\n+      ref.insert(i);\n+      ref.insert(i);\n+    }\n+\n+  std::unordered_multiset<int> copy(ref);\n+  VERIFY( copy.size() == ref.size() );\n+  VERIFY( std::equal(ref.begin(), ref.end(), copy.begin()) );\n+  return 0;\n+}"}, {"sha": "e48e31149e3ef3cc769ccb133c1f96fe6d071183", "filename": "libstdc++-v3/testsuite/23_containers/unordered_multiset/erase/1.cc", "status": "modified", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Ferase%2F1.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Ferase%2F1.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Ferase%2F1.cc?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -23,6 +23,18 @@\n #include <string>\n #include <testsuite_hooks.h>\n \n+namespace\n+{\n+  std::size_t\n+  get_nb_bucket_elems(const std::unordered_multiset<std::string>& us)\n+  {\n+    std::size_t nb = 0;\n+    for (std::size_t b = 0; b != us.bucket_count(); ++b)\n+      nb += us.bucket_size(b);\n+    return nb;\n+  }\n+}\n+\n void test01()\n {\n   bool test __attribute__((unused)) = true;\n@@ -45,14 +57,17 @@ void test01()\n   ms1.insert(\"one line behind\");\n   ms1.insert(\"because to why\");\n   VERIFY( ms1.size() == 11 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n \n   VERIFY( ms1.erase(\"eeilo\") == 1 );\n   VERIFY( ms1.size() == 10 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n   iterator it1 = ms1.find(\"eeilo\");\n   VERIFY( it1 == ms1.end() );\n \n   VERIFY( ms1.erase(\"tillsammans\") == 1 );\n   VERIFY( ms1.size() == 9 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n   iterator it2 = ms1.find(\"tillsammans\");\n   VERIFY( it2 == ms1.end() );\n \n@@ -61,17 +76,20 @@ void test01()\n   VERIFY( it3 != ms1.end() );\n   VERIFY( ms1.erase(*it3) == 1 );\n   VERIFY( ms1.size() == 8 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n   it3 = ms1.find(\"belonging (no longer mix)\");\n   VERIFY( it3 == ms1.end() );\n \n   VERIFY( !ms1.erase(\"abra\") );\n   VERIFY( ms1.size() == 8 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n \n   VERIFY( !ms1.erase(\"eeilo\") );\n   VERIFY( ms1.size() == 8 );\n \n   VERIFY( ms1.erase(\"because to why\") == 2 );\n   VERIFY( ms1.size() == 6 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n   iterator it4 = ms1.find(\"because to why\");\n   VERIFY( it4 == ms1.end() );\n \n@@ -87,11 +105,13 @@ void test01()\n \n   VERIFY( ms1.erase(*it5) == 1 );\n   VERIFY( ms1.size() == 5 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n   it5 = ms1.find(\"umbra/penumbra\");\n   VERIFY( it5 == ms1.end() );\n \n   VERIFY( ms1.erase(*it6) == 1 );\n   VERIFY( ms1.size() == 4 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n   it6 = ms1.find(\"one line behind\");\n   VERIFY( it6 == ms1.end() );\n \n@@ -103,22 +123,26 @@ void test01()\n \n   VERIFY( ms1.erase(*it8) == 1 );\n   VERIFY( ms1.size() == 3 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n   VERIFY( ++it7 == it9 );\n \n   iterator it10 = it9;\n   ++it10;\n   iterator it11 = it10;\n \n   VERIFY( ms1.erase(*it9) == 1 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n   VERIFY( ms1.size() == 2 );\n   VERIFY( ++it10 == ms1.end() );\n \n   VERIFY( ms1.erase(ms1.begin()) != ms1.end() );  \n   VERIFY( ms1.size() == 1 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n   VERIFY( ms1.begin() == it11 );\n \n   VERIFY( ms1.erase(*ms1.begin()) == 1 );  \n   VERIFY( ms1.size() == 0 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n   VERIFY( ms1.begin() == ms1.end() );\n }\n "}, {"sha": "ba1659aedfd6b9694753185a1d0c64db79c18300", "filename": "libstdc++-v3/testsuite/23_containers/unordered_multiset/erase/24061-multiset.cc", "status": "modified", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Ferase%2F24061-multiset.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Ferase%2F24061-multiset.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Ferase%2F24061-multiset.cc?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -23,6 +23,20 @@\n #include <string>\n #include <testsuite_hooks.h>\n \n+namespace\n+{\n+  std::size_t\n+  get_nb_bucket_elems(const std::unordered_multiset<std::string>& us)\n+  {\n+    std::size_t nb = 0;\n+    for (std::size_t b = 0; b != us.bucket_count(); ++b)\n+      {\n+\tnb += us.bucket_size(b);\n+      }\n+    return nb;\n+  }\n+}\n+\n // libstdc++/24061\n void test01()\n {\n@@ -49,13 +63,15 @@ void test01()\n   ms1.insert(\"love is not enough\");\n   ms1.insert(\"every day is exactly the same\");\n   VERIFY( ms1.size() == 13 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n \n   iterator it1 = ms1.begin();\n   ++it1;\n   iterator it2 = it1;\n   ++it2;\n   iterator it3 = ms1.erase(it1);\n   VERIFY( ms1.size() == 12 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n   VERIFY( it3 == it2 );\n   VERIFY( *it3 == *it2 );\n \n@@ -68,6 +84,7 @@ void test01()\n   ++it5;\n   iterator it6 = ms1.erase(it4, it5);\n   VERIFY( ms1.size() == 10 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n   VERIFY( it6 == it5 );\n   VERIFY( *it6 == *it5 );\n \n@@ -79,6 +96,7 @@ void test01()\n   ++it8;\n   const_iterator it9 = ms1.erase(it7);\n   VERIFY( ms1.size() == 9 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n   VERIFY( it9 == it8 );\n   VERIFY( *it9 == *it8 );\n \n@@ -91,11 +109,13 @@ void test01()\n   ++it11;\n   const_iterator it12 = ms1.erase(it10, it11);\n   VERIFY( ms1.size() == 5 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n   VERIFY( it12 == it11 );\n   VERIFY( *it12 == *it11 );\n \n   iterator it13 = ms1.erase(ms1.begin(), ms1.end());\n   VERIFY( ms1.size() == 0 );\n+  VERIFY( get_nb_bucket_elems(ms1) == ms1.size() );\n   VERIFY( it13 == ms1.end() );\n   VERIFY( it13 == ms1.begin() );\n }"}, {"sha": "59cd8c9857bc70a6e82e3102d32124f95285ebf9", "filename": "libstdc++-v3/testsuite/23_containers/unordered_multiset/insert/multiset_range.cc", "status": "modified", "additions": 17, "deletions": 2, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Finsert%2Fmultiset_range.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Finsert%2Fmultiset_range.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Finsert%2Fmultiset_range.cc?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -25,6 +25,19 @@\n #include <unordered_set>\n #include <testsuite_hooks.h>\n \n+namespace\n+{\n+  template <typename _Tp>\n+    std::size_t\n+    get_nb_bucket_elems(const std::unordered_multiset<_Tp>& us)\n+    {\n+      std::size_t nb = 0;\n+      for (std::size_t b = 0; b != us.bucket_count(); ++b)\n+\tnb += us.bucket_size(b);\n+      return nb;\n+    }\n+}\n+\n void test01()\n {\n   bool test __attribute__((unused)) = true;\n@@ -38,8 +51,9 @@ void test01()\n \t\t\t     \"magenta\", \"yellow\", \"orange\", \"pink\", \"gray\" };\n \n   s.insert(A+0, A+N);\n-  VERIFY(s.size() == static_cast<unsigned int>(N));\n-  VERIFY(std::distance(s.begin(), s.end()) == N);\n+  VERIFY( s.size() == static_cast<unsigned int>(N) );\n+  VERIFY( std::distance(s.begin(), s.end()) == N );\n+  VERIFY( get_nb_bucket_elems(s) == N );\n \n   for (int i = 0; i < N; ++i) {\n     std::string str = A[i];\n@@ -62,6 +76,7 @@ void test02()\n   s.insert(A+0, A+N);\n   VERIFY(s.size() == static_cast<unsigned int>(N));\n   VERIFY(std::distance(s.begin(), s.end()) == N);\n+  VERIFY( get_nb_bucket_elems(s) == N );\n \n   VERIFY(std::count(s.begin(), s.end(), 2) == 1);\n   VERIFY(std::count(s.begin(), s.end(), 3) == 1);"}, {"sha": "ebc38b2402a6bdd6131423ecdfc301b85e16eec5", "filename": "libstdc++-v3/testsuite/23_containers/unordered_multiset/insert/multiset_single.cc", "status": "modified", "additions": 16, "deletions": 1, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Finsert%2Fmultiset_single.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Finsert%2Fmultiset_single.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Finsert%2Fmultiset_single.cc?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -24,6 +24,19 @@\n #include <unordered_set>\n #include <testsuite_hooks.h>\n \n+namespace\n+{\n+  std::size_t\n+  get_nb_bucket_elems(const std::unordered_multiset<std::string>& us)\n+  {\n+    std::size_t nb = 0;\n+    for (std::size_t b = 0; b != us.bucket_count(); ++b)\n+      nb += us.bucket_size(b);\n+    return nb;\n+  }\n+}\n+\n+\n void test01()\n {\n   bool test __attribute__((unused)) = true;\n@@ -33,7 +46,8 @@ void test01()\n   VERIFY(s.empty());\n \n   Set::iterator i = s.insert(\"abcde\");\n-  VERIFY(s.size() == 1);\n+  VERIFY( s.size() == 1 );\n+  VERIFY( get_nb_bucket_elems(s) == 1 );\n   VERIFY(std::distance(s.begin(), s.end()) == 1);\n   VERIFY(i == s.begin());\n   VERIFY(*i == \"abcde\");\n@@ -50,6 +64,7 @@ void test02()\n   s.insert(\"abcde\");\n   Set::iterator i = s.insert(\"abcde\");\n   VERIFY(s.size() == 2);\n+  VERIFY( get_nb_bucket_elems(s) == 2 );\n   VERIFY(std::distance(s.begin(), s.end()) == 2);\n   VERIFY(*i == \"abcde\");\n   "}, {"sha": "4dc9fba5b68923ec895b574149672ea9bdc04fe2", "filename": "libstdc++-v3/testsuite/23_containers/unordered_multiset/insert/multiset_single_move.cc", "status": "modified", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Finsert%2Fmultiset_single_move.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Finsert%2Fmultiset_single_move.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_multiset%2Finsert%2Fmultiset_single_move.cc?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -26,6 +26,19 @@\n #include <testsuite_hooks.h>\n #include <testsuite_rvalref.h>\n \n+namespace\n+{\n+  template <typename _Tp>\n+    std::size_t\n+    get_nb_bucket_elems(const std::unordered_multiset<_Tp>& us)\n+    {\n+      std::size_t nb = 0;\n+      for (std::size_t b = 0; b != us.bucket_count(); ++b)\n+\tnb += us.bucket_size(b);\n+      return nb;\n+    }\n+}\n+\n void test01()\n {\n   bool test __attribute__((unused)) = true;\n@@ -37,6 +50,7 @@ void test01()\n \n   Set::iterator i = s.insert(rvalstruct(1));\n   VERIFY( s.size() == 1 );\n+  VERIFY( get_nb_bucket_elems(s) == 1 );\n   VERIFY( std::distance(s.begin(), s.end()) == 1 );\n   VERIFY( i == s.begin() );\n   VERIFY( (*i).val == 1 );\n@@ -54,6 +68,7 @@ void test02()\n   s.insert(rvalstruct(2));\n   Set::iterator i = s.insert(rvalstruct(2));\n   VERIFY( s.size() == 2 );\n+  VERIFY( get_nb_bucket_elems(s) == 2 );\n   VERIFY( std::distance(s.begin(), s.end()) == 2 );\n   VERIFY( (*i).val == 2 );\n   "}, {"sha": "91dc0fd402e7f2d970e778bc13ef0ffbed9b4aa8", "filename": "libstdc++-v3/testsuite/23_containers/unordered_set/hash_policy/rehash.cc", "status": "added", "additions": 62, "deletions": 0, "changes": 62, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_set%2Fhash_policy%2Frehash.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_set%2Fhash_policy%2Frehash.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_set%2Fhash_policy%2Frehash.cc?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -0,0 +1,62 @@\n+// Copyright (C) 2011 Free Software Foundation, Inc.\n+//\n+// This file is part of the GNU ISO C++ Library.  This library is free\n+// software; you can redistribute it and/or modify it under the\n+// terms of the GNU General Public License as published by the\n+// Free Software Foundation; either version 3, or (at your option)\n+// any later version.\n+//\n+// This library is distributed in the hope that it will be useful,\n+// but WITHOUT ANY WARRANTY; without even the implied warranty of\n+// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+// GNU General Public License for more details.\n+//\n+// You should have received a copy of the GNU General Public License along\n+// with this library; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+//\n+// { dg-options \"-std=gnu++0x\" }\n+\n+#include <unordered_set>\n+#include <testsuite_hooks.h>\n+\n+void test01()\n+{\n+  bool test __attribute__((unused)) = true;\n+  std::unordered_set<int> us;\n+  typedef typename std::unordered_set<int>::size_type size_type;\n+  bool rehashed = false;\n+  for (int i = 0; i != 100000; ++i)\n+  {\n+    size_type bkt_count = us.bucket_count();\n+    us.insert(i);\n+    if (bkt_count != us.bucket_count())\n+      {\n+\t// Container has been rehashed, lets check that it won't be rehash again\n+\t// if we remove and restore the last 2 inserted elements:\n+\trehashed = true;\n+\tbkt_count = us.bucket_count();\n+\tVERIFY( us.erase(i) == 1 );\n+\tVERIFY( bkt_count == us.bucket_count() );\n+\tif (i > 0)\n+\t  {\n+\t    VERIFY( us.erase(i - 1) == 1 );\n+\t    VERIFY( bkt_count == us.bucket_count() );\n+\n+\t    VERIFY( us.insert(i - 1).second );\n+\t    VERIFY( bkt_count == us.bucket_count() );\n+\t  }\n+\tVERIFY( us.insert(i).second );\n+\tVERIFY( bkt_count == us.bucket_count() );\n+      }\n+  }\n+\n+  // At lest we check a rehash once:\n+  VERIFY( rehashed );\n+}\n+\n+int main()\n+{\n+  test01();\n+  return 0;\n+}"}, {"sha": "aa52e6b07d4016e8d8e52547feabfa681d1ab545", "filename": "libstdc++-v3/testsuite/23_containers/unordered_set/instantiation_neg.cc", "status": "added", "additions": 41, "deletions": 0, "changes": 41, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_set%2Finstantiation_neg.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_set%2Finstantiation_neg.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2F23_containers%2Funordered_set%2Finstantiation_neg.cc?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -0,0 +1,41 @@\n+// { dg-do compile }\n+// { dg-options \"-std=gnu++0x\" }\n+// { dg-require-normal-mode \"\" }\n+\n+// Copyright (C) 2011 Free Software Foundation, Inc.\n+//\n+// This file is part of the GNU ISO C++ Library.  This library is free\n+// software; you can redistribute it and/or modify it under the\n+// terms of the GNU General Public License as published by the\n+// Free Software Foundation; either version 3, or (at your option)\n+// any later version.\n+\n+// This library is distributed in the hope that it will be useful,\n+// but WITHOUT ANY WARRANTY; without Pred the implied warranty of\n+// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+// GNU General Public License for more details.\n+\n+// You should have received a copy of the GNU General Public License along\n+// with this library; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+// { dg-error \"static assertion failed\" \"\" { target *-*-* } 177 }\n+\n+#include <unordered_set>\n+\n+namespace\n+{\n+  struct hash_without_noexcept\n+  {\n+    std::size_t operator() (int) const\n+    { return 0; }\n+  };\n+}\n+\n+void\n+test01()\n+{\n+  std::__unordered_set<int, hash_without_noexcept,\n+\t\t       std::equal_to<int>, std::allocator<int>,\n+\t\t       false> us;\n+}"}, {"sha": "f214d1dd666a27ccd521764ea2c00763a91c2f08", "filename": "libstdc++-v3/testsuite/performance/23_containers/copy_construct/unordered_set.cc", "status": "added", "additions": 43, "deletions": 0, "changes": 43, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2Fperformance%2F23_containers%2Fcopy_construct%2Funordered_set.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/da29608a7a5df92fcd377086a5304889ae71413d/libstdc%2B%2B-v3%2Ftestsuite%2Fperformance%2F23_containers%2Fcopy_construct%2Funordered_set.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libstdc%2B%2B-v3%2Ftestsuite%2Fperformance%2F23_containers%2Fcopy_construct%2Funordered_set.cc?ref=da29608a7a5df92fcd377086a5304889ae71413d", "patch": "@@ -0,0 +1,43 @@\n+// { dg-options \"-std=gnu++0x\" }\n+// Copyright (C) 2011 Free Software Foundation, Inc.\n+//\n+// This file is part of the GNU ISO C++ Library.  This library is free\n+// software; you can redistribute it and/or modify it under the\n+// terms of the GNU General Public License as published by the\n+// Free Software Foundation; either version 3, or (at your option)\n+// any later version.\n+\n+// This library is distributed in the hope that it will be useful,\n+// but WITHOUT ANY WARRANTY; without even the implied warranty of\n+// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+// GNU General Public License for more details.\n+\n+// You should have received a copy of the GNU General Public License along\n+// with this library; see the file COPYING3.  If not see\n+// <http://www.gnu.org/licenses/>.\n+\n+\n+#include <unordered_set>\n+#include <testsuite_performance.h>\n+\n+int main()\n+{\n+  using namespace __gnu_test;\n+\n+  time_counter time;\n+  resource_counter resource;\n+\n+  std::unordered_set<int> ref;\n+  for (int i = 0; i != 500000; ++i)\n+    ref.insert(i);\n+\n+  start_counters(time, resource);\n+\n+  for (unsigned i = 0; i < 500; ++i)\n+    std::unordered_set<int> v(ref);\n+\n+  stop_counters(time, resource);\n+  report_performance(__FILE__, \"unordered_set<int> copy\", time, resource);\n+\n+  return 0;\n+}"}]}