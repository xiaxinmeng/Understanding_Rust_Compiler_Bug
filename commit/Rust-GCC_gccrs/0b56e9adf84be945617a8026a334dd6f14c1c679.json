{"sha": "0b56e9adf84be945617a8026a334dd6f14c1c679", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MGI1NmU5YWRmODRiZTk0NTYxN2E4MDI2YTMzNGRkNmYxNGMxYzY3OQ==", "commit": {"author": {"name": "Bill Schmidt", "email": "wschmidt@linux.vnet.ibm.com", "date": "2016-10-31T03:04:59Z"}, "committer": {"name": "William Schmidt", "email": "wschmidt@gcc.gnu.org", "date": "2016-10-31T03:04:59Z"}, "message": "re PR tree-optimization/71915 (A missed opportunity for SLSR)\n\n[gcc]\n\n2016-10-30  Bill Schmidt  <wschmidt@linux.vnet.ibm.com>\n\n\tPR tree-optimization/71915\n\tPR tree-optimization/71490\n\t* gimple-ssa-strength-reduction.c (struct slsr_cand_d): Add\n\tstride_type field.\n\t(find_basis_for_base_expr): Require stride types to match when\n\tseeking a basis.\n\t(alloc_cand_and_find_basis): Record the stride type.\n\t(slsr_process_phi): Pass stride type to alloc_cand_and_find_basis.\n\t(backtrace_base_for_ref): Pass types to legal_cast_p_1 rather than\n\tthe expressions having those types.\n\t(slsr_process_ref): Pass stride type to alloc_cand_and_find_basis.\n\t(create_mul_ssa_cand): Likewise.\n\t(create_mul_imm_cand): Likewise.\n\t(create_add_ssa_cand): Likewise.\n\t(create_add_imm_cand): Likewise.\n\t(legal_cast_p_1): Change interface to accept types rather than the\n\texpressions having those types.\n\t(legal_cast_p): Pass types to legal_cast_p_1.\n\t(slsr_process_cast): Pass stride type to\n\talloc_cand_and_find_basis.\n\t(slsr_process_copy): Likewise.\n\t(dump_candidate): Display stride type when a cast exists.\n\t(create_add_on_incoming_edge): Introduce a cast when necessary for\n\tthe stride type.\n\t(analyze_increments): Change the code checking for invalid casts\n\tto rely on the stride type, and update the documentation and\n\texample.  Change the code checking for pointer multiplies to rely\n\ton the stride type.\n\t(insert_initializers): Introduce a cast when necessary for the\n\tstride type.  Use the stride type for the type of the initializer.\n\n[gcc/testsuite]\n\n2016-10-30  Bill Schmidt  <wschmidt@linux.vnet.ibm.com>\n\n\tPR tree-optimization/71915\n\tPR tree-optimization/71490\n\t* gcc.dg/tree-ssa/pr54245.c: Delete.\n\t* gcc.dg/tree-ssa/slsr-8.c: Adjust for new optimization and\n\tdocument why.\n\nFrom-SVN: r241695", "tree": {"sha": "9a26ae33b30338b694ff1694c28a109e28bbaa5f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/9a26ae33b30338b694ff1694c28a109e28bbaa5f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/0b56e9adf84be945617a8026a334dd6f14c1c679", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0b56e9adf84be945617a8026a334dd6f14c1c679", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0b56e9adf84be945617a8026a334dd6f14c1c679", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0b56e9adf84be945617a8026a334dd6f14c1c679/comments", "author": {"login": "wschmidt-ibm", "id": 5520937, "node_id": "MDQ6VXNlcjU1MjA5Mzc=", "avatar_url": "https://avatars.githubusercontent.com/u/5520937?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wschmidt-ibm", "html_url": "https://github.com/wschmidt-ibm", "followers_url": "https://api.github.com/users/wschmidt-ibm/followers", "following_url": "https://api.github.com/users/wschmidt-ibm/following{/other_user}", "gists_url": "https://api.github.com/users/wschmidt-ibm/gists{/gist_id}", "starred_url": "https://api.github.com/users/wschmidt-ibm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wschmidt-ibm/subscriptions", "organizations_url": "https://api.github.com/users/wschmidt-ibm/orgs", "repos_url": "https://api.github.com/users/wschmidt-ibm/repos", "events_url": "https://api.github.com/users/wschmidt-ibm/events{/privacy}", "received_events_url": "https://api.github.com/users/wschmidt-ibm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "8972aa3362ab322891f482725d3866ccf265bb3a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8972aa3362ab322891f482725d3866ccf265bb3a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8972aa3362ab322891f482725d3866ccf265bb3a"}], "stats": {"total": 337, "additions": 221, "deletions": 116}, "files": [{"sha": "f29b9b507fcf03de522685095e65e94ee1eed7c1", "filename": "gcc/ChangeLog", "status": "modified", "additions": 33, "deletions": 0, "changes": 33, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b56e9adf84be945617a8026a334dd6f14c1c679/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b56e9adf84be945617a8026a334dd6f14c1c679/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=0b56e9adf84be945617a8026a334dd6f14c1c679", "patch": "@@ -1,3 +1,36 @@\n+2016-10-30  Bill Schmidt  <wschmidt@linux.vnet.ibm.com>\n+\n+\tPR tree-optimization/71915\n+\tPR tree-optimization/71490\n+\t* gimple-ssa-strength-reduction.c (struct slsr_cand_d): Add\n+\tstride_type field.\n+\t(find_basis_for_base_expr): Require stride types to match when\n+\tseeking a basis.\n+\t(alloc_cand_and_find_basis): Record the stride type.\n+\t(slsr_process_phi): Pass stride type to alloc_cand_and_find_basis.\n+\t(backtrace_base_for_ref): Pass types to legal_cast_p_1 rather than\n+\tthe expressions having those types.\n+\t(slsr_process_ref): Pass stride type to alloc_cand_and_find_basis.\n+\t(create_mul_ssa_cand): Likewise.\n+\t(create_mul_imm_cand): Likewise.\n+\t(create_add_ssa_cand): Likewise.\n+\t(create_add_imm_cand): Likewise.\n+\t(legal_cast_p_1): Change interface to accept types rather than the\n+\texpressions having those types.\n+\t(legal_cast_p): Pass types to legal_cast_p_1.\n+\t(slsr_process_cast): Pass stride type to\n+\talloc_cand_and_find_basis.\n+\t(slsr_process_copy): Likewise.\n+\t(dump_candidate): Display stride type when a cast exists.\n+\t(create_add_on_incoming_edge): Introduce a cast when necessary for\n+\tthe stride type.\n+\t(analyze_increments): Change the code checking for invalid casts\n+\tto rely on the stride type, and update the documentation and\n+\texample.  Change the code checking for pointer multiplies to rely\n+\ton the stride type.\n+\t(insert_initializers): Introduce a cast when necessary for the\n+\tstride type.  Use the stride type for the type of the initializer.\n+\n 2016-10-30  Prathamesh Kulkarni  <prathamesh.kulkarni@linaro.org>\n \n \t* config/arm/arm.c (arm_const_not_ok_for_debug_p): Use VAR_P."}, {"sha": "bdfdb9a82b196a8c928e412dca3792ca45ce7a0d", "filename": "gcc/gimple-ssa-strength-reduction.c", "status": "modified", "additions": 170, "deletions": 63, "changes": 233, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b56e9adf84be945617a8026a334dd6f14c1c679/gcc%2Fgimple-ssa-strength-reduction.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b56e9adf84be945617a8026a334dd6f14c1c679/gcc%2Fgimple-ssa-strength-reduction.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-ssa-strength-reduction.c?ref=0b56e9adf84be945617a8026a334dd6f14c1c679", "patch": "@@ -246,6 +246,13 @@ struct slsr_cand_d\n      replacement MEM_REF.)  */\n   tree cand_type;\n \n+  /* The type to be used to interpret the stride field when the stride\n+     is not a constant.  Normally the same as the type of the recorded\n+     stride, but when the stride has been cast we need to maintain that\n+     knowledge in order to make legal substitutions without losing \n+     precision.  When the stride is a constant, this will be sizetype.  */\n+  tree stride_type;\n+\n   /* The kind of candidate (CAND_MULT, etc.).  */\n   enum cand_kind kind;\n \n@@ -502,6 +509,7 @@ find_basis_for_base_expr (slsr_cand_t c, tree base_expr)\n \t  || one_basis->cand_stmt == c->cand_stmt\n \t  || !operand_equal_p (one_basis->stride, c->stride, 0)\n \t  || !types_compatible_p (one_basis->cand_type, c->cand_type)\n+\t  || !types_compatible_p (one_basis->stride_type, c->stride_type)\n \t  || !dominated_by_p (CDI_DOMINATORS,\n \t\t\t      gimple_bb (c->cand_stmt),\n \t\t\t      gimple_bb (one_basis->cand_stmt)))\n@@ -615,7 +623,7 @@ record_potential_basis (slsr_cand_t c, tree base)\n static slsr_cand_t\n alloc_cand_and_find_basis (enum cand_kind kind, gimple *gs, tree base,\n \t\t\t   const widest_int &index, tree stride, tree ctype,\n-\t\t\t   unsigned savings)\n+\t\t\t   tree stype, unsigned savings)\n {\n   slsr_cand_t c = (slsr_cand_t) obstack_alloc (&cand_obstack,\n \t\t\t\t\t       sizeof (slsr_cand));\n@@ -624,6 +632,7 @@ alloc_cand_and_find_basis (enum cand_kind kind, gimple *gs, tree base,\n   c->stride = stride;\n   c->index = index;\n   c->cand_type = ctype;\n+  c->stride_type = stype;\n   c->kind = kind;\n   c->cand_num = cand_vec.length () + 1;\n   c->next_interp = 0;\n@@ -809,7 +818,8 @@ slsr_process_phi (gphi *phi, bool speed)\n   base_type = TREE_TYPE (arg0_base);\n \n   c = alloc_cand_and_find_basis (CAND_PHI, phi, arg0_base,\n-\t\t\t\t 0, integer_one_node, base_type, savings);\n+\t\t\t\t 0, integer_one_node, base_type,\n+\t\t\t\t sizetype, savings);\n \n   /* Add the candidate to the statement-candidate mapping.  */\n   add_cand_for_stmt (phi, c);\n@@ -838,7 +848,8 @@ backtrace_base_for_ref (tree *pbase)\n      e.g. 'B' is widened from an 'int' in order to calculate\n      a 64-bit address.  */\n   if (CONVERT_EXPR_P (base_in)\n-      && legal_cast_p_1 (base_in, TREE_OPERAND (base_in, 0)))\n+      && legal_cast_p_1 (TREE_TYPE (base_in),\n+\t\t\t TREE_TYPE (TREE_OPERAND (base_in, 0))))\n     base_in = get_unwidened (base_in, NULL_TREE);\n \n   if (TREE_CODE (base_in) != SSA_NAME)\n@@ -995,7 +1006,7 @@ slsr_process_ref (gimple *gs)\n     return;\n \n   c = alloc_cand_and_find_basis (CAND_REF, gs, base, index, offset,\n-\t\t\t\t type, 0);\n+\t\t\t\t type, sizetype, 0);\n \n   /* Add the candidate to the statement-candidate mapping.  */\n   add_cand_for_stmt (gs, c);\n@@ -1010,6 +1021,7 @@ static slsr_cand_t\n create_mul_ssa_cand (gimple *gs, tree base_in, tree stride_in, bool speed)\n {\n   tree base = NULL_TREE, stride = NULL_TREE, ctype = NULL_TREE;\n+  tree stype = NULL_TREE;\n   widest_int index;\n   unsigned savings = 0;\n   slsr_cand_t c;\n@@ -1030,6 +1042,7 @@ create_mul_ssa_cand (gimple *gs, tree base_in, tree stride_in, bool speed)\n \t  index = base_cand->index;\n \t  stride = stride_in;\n \t  ctype = base_cand->cand_type;\n+\t  stype = TREE_TYPE (stride_in);\n \t  if (has_single_use (base_in))\n \t    savings = (base_cand->dead_savings \n \t\t       + stmt_cost (base_cand->cand_stmt, speed));\n@@ -1045,6 +1058,7 @@ create_mul_ssa_cand (gimple *gs, tree base_in, tree stride_in, bool speed)\n \t  index = base_cand->index * wi::to_widest (base_cand->stride);\n \t  stride = stride_in;\n \t  ctype = base_cand->cand_type;\n+\t  stype = TREE_TYPE (stride_in);\n \t  if (has_single_use (base_in))\n \t    savings = (base_cand->dead_savings\n \t\t       + stmt_cost (base_cand->cand_stmt, speed));\n@@ -1064,10 +1078,11 @@ create_mul_ssa_cand (gimple *gs, tree base_in, tree stride_in, bool speed)\n       index = 0;\n       stride = stride_in;\n       ctype = TREE_TYPE (base_in);\n+      stype = TREE_TYPE (stride_in);\n     }\n \n   c = alloc_cand_and_find_basis (CAND_MULT, gs, base, index, stride,\n-\t\t\t\t ctype, savings);\n+\t\t\t\t ctype, stype, savings);\n   return c;\n }\n \n@@ -1156,7 +1171,7 @@ create_mul_imm_cand (gimple *gs, tree base_in, tree stride_in, bool speed)\n     }\n \n   c = alloc_cand_and_find_basis (CAND_MULT, gs, base, index, stride,\n-\t\t\t\t ctype, savings);\n+\t\t\t\t ctype, sizetype, savings);\n   return c;\n }\n \n@@ -1212,7 +1227,8 @@ static slsr_cand_t\n create_add_ssa_cand (gimple *gs, tree base_in, tree addend_in,\n \t\t     bool subtract_p, bool speed)\n {\n-  tree base = NULL_TREE, stride = NULL_TREE, ctype = NULL;\n+  tree base = NULL_TREE, stride = NULL_TREE, ctype = NULL_TREE;\n+  tree stype = NULL_TREE;\n   widest_int index;\n   unsigned savings = 0;\n   slsr_cand_t c;\n@@ -1237,6 +1253,7 @@ create_add_ssa_cand (gimple *gs, tree base_in, tree addend_in,\n \t    index = -index;\n \t  stride = addend_cand->base_expr;\n \t  ctype = TREE_TYPE (base_in);\n+\t  stype = addend_cand->cand_type;\n \t  if (has_single_use (addend_in))\n \t    savings = (addend_cand->dead_savings\n \t\t       + stmt_cost (addend_cand->cand_stmt, speed));\n@@ -1263,6 +1280,8 @@ create_add_ssa_cand (gimple *gs, tree base_in, tree addend_in,\n \t  index = subtract_p ? -1 : 1;\n \t  stride = addend_in;\n \t  ctype = base_cand->cand_type;\n+\t  stype = (TREE_CODE (addend_in) == INTEGER_CST ? sizetype\n+\t\t   : TREE_TYPE (addend_in));\n \t  if (has_single_use (base_in))\n \t    savings = (base_cand->dead_savings\n \t\t       + stmt_cost (base_cand->cand_stmt, speed));\n@@ -1286,6 +1305,7 @@ create_add_ssa_cand (gimple *gs, tree base_in, tree addend_in,\n \t\t  index = -index;\n \t\t  stride = subtrahend_cand->base_expr;\n \t\t  ctype = TREE_TYPE (base_in);\n+\t\t  stype = subtrahend_cand->cand_type;\n \t\t  if (has_single_use (addend_in))\n \t\t    savings = (subtrahend_cand->dead_savings \n \t\t\t       + stmt_cost (subtrahend_cand->cand_stmt, speed));\n@@ -1312,10 +1332,12 @@ create_add_ssa_cand (gimple *gs, tree base_in, tree addend_in,\n       index = subtract_p ? -1 : 1;\n       stride = addend_in;\n       ctype = TREE_TYPE (base_in);\n+      stype = (TREE_CODE (addend_in) == INTEGER_CST ? sizetype\n+\t       : TREE_TYPE (addend_in));\n     }\n \n   c = alloc_cand_and_find_basis (CAND_ADD, gs, base, index, stride,\n-\t\t\t\t ctype, savings);\n+\t\t\t\t ctype, stype, savings);\n   return c;\n }\n \n@@ -1329,6 +1351,7 @@ create_add_imm_cand (gimple *gs, tree base_in, const widest_int &index_in,\n {\n   enum cand_kind kind = CAND_ADD;\n   tree base = NULL_TREE, stride = NULL_TREE, ctype = NULL_TREE;\n+  tree stype = NULL_TREE;\n   widest_int index, multiple;\n   unsigned savings = 0;\n   slsr_cand_t c;\n@@ -1356,6 +1379,7 @@ create_add_imm_cand (gimple *gs, tree base_in, const widest_int &index_in,\n \t  index = base_cand->index + multiple;\n \t  stride = base_cand->stride;\n \t  ctype = base_cand->cand_type;\n+\t  stype = base_cand->stride_type;\n \t  if (has_single_use (base_in))\n \t    savings = (base_cand->dead_savings \n \t\t       + stmt_cost (base_cand->cand_stmt, speed));\n@@ -1376,10 +1400,11 @@ create_add_imm_cand (gimple *gs, tree base_in, const widest_int &index_in,\n       index = index_in;\n       stride = integer_one_node;\n       ctype = TREE_TYPE (base_in);\n+      stype = sizetype;\n     }\n \n   c = alloc_cand_and_find_basis (kind, gs, base, index, stride,\n-\t\t\t\t ctype, savings);\n+\t\t\t\t ctype, stype, savings);\n   return c;\n }\n \n@@ -1456,14 +1481,11 @@ slsr_process_neg (gimple *gs, tree rhs1, bool speed)\n    for more details.  */\n \n static bool\n-legal_cast_p_1 (tree lhs, tree rhs)\n+legal_cast_p_1 (tree lhs_type, tree rhs_type)\n {\n-  tree lhs_type, rhs_type;\n   unsigned lhs_size, rhs_size;\n   bool lhs_wraps, rhs_wraps;\n \n-  lhs_type = TREE_TYPE (lhs);\n-  rhs_type = TREE_TYPE (rhs);\n   lhs_size = TYPE_PRECISION (lhs_type);\n   rhs_size = TYPE_PRECISION (rhs_type);\n   lhs_wraps = ANY_INTEGRAL_TYPE_P (lhs_type) && TYPE_OVERFLOW_WRAPS (lhs_type);\n@@ -1521,7 +1543,7 @@ legal_cast_p (gimple *gs, tree rhs)\n       || !CONVERT_EXPR_CODE_P (gimple_assign_rhs_code (gs)))\n     return false;\n \n-  return legal_cast_p_1 (gimple_assign_lhs (gs), rhs);\n+  return legal_cast_p_1 (TREE_TYPE (gimple_assign_lhs (gs)), TREE_TYPE (rhs));\n }\n \n /* Given GS which is a cast to a scalar integer type, determine whether\n@@ -1556,7 +1578,8 @@ slsr_process_cast (gimple *gs, tree rhs1, bool speed)\n \t  c = alloc_cand_and_find_basis (base_cand->kind, gs,\n \t\t\t\t\t base_cand->base_expr,\n \t\t\t\t\t base_cand->index, base_cand->stride,\n-\t\t\t\t\t ctype, savings);\n+\t\t\t\t\t ctype, base_cand->stride_type,\n+\t\t\t\t\t savings);\n \t  if (base_cand->next_interp)\n \t    base_cand = lookup_cand (base_cand->next_interp);\n \t  else\n@@ -1574,10 +1597,10 @@ slsr_process_cast (gimple *gs, tree rhs1, bool speed)\n \t The first of these is somewhat arbitrary, but the choice of\n \t 1 for the stride simplifies the logic for propagating casts\n \t into their uses.  */\n-      c = alloc_cand_and_find_basis (CAND_ADD, gs, rhs1,\n-\t\t\t\t     0, integer_one_node, ctype, 0);\n-      c2 = alloc_cand_and_find_basis (CAND_MULT, gs, rhs1,\n-\t\t\t\t      0, integer_one_node, ctype, 0);\n+      c = alloc_cand_and_find_basis (CAND_ADD, gs, rhs1, 0,\n+\t\t\t\t     integer_one_node, ctype, sizetype, 0);\n+      c2 = alloc_cand_and_find_basis (CAND_MULT, gs, rhs1, 0,\n+\t\t\t\t      integer_one_node, ctype, sizetype, 0);\n       c->next_interp = c2->cand_num;\n     }\n \n@@ -1613,7 +1636,8 @@ slsr_process_copy (gimple *gs, tree rhs1, bool speed)\n \t  c = alloc_cand_and_find_basis (base_cand->kind, gs,\n \t\t\t\t\t base_cand->base_expr,\n \t\t\t\t\t base_cand->index, base_cand->stride,\n-\t\t\t\t\t base_cand->cand_type, savings);\n+\t\t\t\t\t base_cand->cand_type,\n+\t\t\t\t\t base_cand->stride_type, savings);\n \t  if (base_cand->next_interp)\n \t    base_cand = lookup_cand (base_cand->next_interp);\n \t  else\n@@ -1631,10 +1655,12 @@ slsr_process_copy (gimple *gs, tree rhs1, bool speed)\n \t The first of these is somewhat arbitrary, but the choice of\n \t 1 for the stride simplifies the logic for propagating casts\n \t into their uses.  */\n-      c = alloc_cand_and_find_basis (CAND_ADD, gs, rhs1,\n-\t\t\t\t     0, integer_one_node, TREE_TYPE (rhs1), 0);\n-      c2 = alloc_cand_and_find_basis (CAND_MULT, gs, rhs1,\n-\t\t\t\t      0, integer_one_node, TREE_TYPE (rhs1), 0);\n+      c = alloc_cand_and_find_basis (CAND_ADD, gs, rhs1, 0,\n+\t\t\t\t     integer_one_node, TREE_TYPE (rhs1),\n+\t\t\t\t     sizetype, 0);\n+      c2 = alloc_cand_and_find_basis (CAND_MULT, gs, rhs1, 0,\n+\t\t\t\t      integer_one_node, TREE_TYPE (rhs1),\n+\t\t\t\t      sizetype, 0);\n       c->next_interp = c2->cand_num;\n     }\n \n@@ -1755,6 +1781,13 @@ dump_candidate (slsr_cand_t c)\n       fputs (\" + \", dump_file);\n       print_decs (c->index, dump_file);\n       fputs (\") * \", dump_file);\n+      if (TREE_CODE (c->stride) != INTEGER_CST\n+\t  && c->stride_type != TREE_TYPE (c->stride))\n+\t{\n+\t  fputs (\"(\", dump_file);\n+\t  print_generic_expr (dump_file, c->stride_type, 0);\n+\t  fputs (\")\", dump_file);\n+\t}\n       print_generic_expr (dump_file, c->stride, 0);\n       fputs (\" : \", dump_file);\n       break;\n@@ -1764,6 +1797,13 @@ dump_candidate (slsr_cand_t c)\n       fputs (\" + (\", dump_file);\n       print_decs (c->index, dump_file);\n       fputs (\" * \", dump_file);\n+      if (TREE_CODE (c->stride) != INTEGER_CST\n+\t  && c->stride_type != TREE_TYPE (c->stride))\n+\t{\n+\t  fputs (\"(\", dump_file);\n+\t  print_generic_expr (dump_file, c->stride_type, 0);\n+\t  fputs (\")\", dump_file);\n+\t}\n       print_generic_expr (dump_file, c->stride, 0);\n       fputs (\") : \", dump_file);\n       break;\n@@ -2143,7 +2183,7 @@ create_add_on_incoming_edge (slsr_cand_t c, tree basis_name,\n   basic_block insert_bb;\n   gimple_stmt_iterator gsi;\n   tree lhs, basis_type;\n-  gassign *new_stmt;\n+  gassign *new_stmt, *cast_stmt = NULL;\n \n   /* If the add candidate along this incoming edge has the same\n      index as C's hidden basis, the hidden basis represents this\n@@ -2187,27 +2227,61 @@ create_add_on_incoming_edge (slsr_cand_t c, tree basis_name,\n \t  new_stmt = gimple_build_assign (lhs, code, basis_name,\n \t\t\t\t\t  incr_vec[i].initializer);\n \t}\n-      else if (increment == 1)\n-\tnew_stmt = gimple_build_assign (lhs, plus_code, basis_name, c->stride);\n-      else if (increment == -1)\n-\tnew_stmt = gimple_build_assign (lhs, MINUS_EXPR, basis_name,\n-\t\t\t\t\tc->stride);\n-      else\n-\tgcc_unreachable ();\n+      else {\n+\ttree stride;\n+\n+\tif (!types_compatible_p (TREE_TYPE (c->stride), c->stride_type))\n+\t  {\n+\t    tree cast_stride = make_temp_ssa_name (c->stride_type, NULL,\n+\t\t\t\t\t\t   \"slsr\");\n+\t    cast_stmt = gimple_build_assign (cast_stride, NOP_EXPR,\n+\t\t\t\t\t     c->stride);\n+\t    stride = cast_stride;\n+\t  }\n+\telse\n+\t  stride = c->stride;\n+\n+\tif (increment == 1)\n+\t  new_stmt = gimple_build_assign (lhs, plus_code, basis_name, stride);\n+\telse if (increment == -1)\n+\t  new_stmt = gimple_build_assign (lhs, MINUS_EXPR, basis_name, stride);\n+\telse\n+\t  gcc_unreachable ();\n+      }\n     }\n \n   insert_bb = single_succ_p (e->src) ? e->src : split_edge (e);\n   gsi = gsi_last_bb (insert_bb);\n \n   if (!gsi_end_p (gsi) && is_ctrl_stmt (gsi_stmt (gsi)))\n-    gsi_insert_before (&gsi, new_stmt, GSI_NEW_STMT);\n+    {\n+      gsi_insert_before (&gsi, new_stmt, GSI_SAME_STMT);\n+      if (cast_stmt)\n+\t{\n+\t  gsi_insert_before (&gsi, cast_stmt, GSI_SAME_STMT);\n+\t  gimple_set_location (cast_stmt, loc);\n+\t}\n+    }\n   else\n-    gsi_insert_after (&gsi, new_stmt, GSI_NEW_STMT);\n+    {\n+      if (cast_stmt)\n+\t{\n+\t  gsi_insert_after (&gsi, cast_stmt, GSI_NEW_STMT);\n+\t  gimple_set_location (cast_stmt, loc);\n+\t}\n+      gsi_insert_after (&gsi, new_stmt, GSI_NEW_STMT);\n+    }\n \n   gimple_set_location (new_stmt, loc);\n \n   if (dump_file && (dump_flags & TDF_DETAILS))\n     {\n+      if (cast_stmt)\n+\t{\n+\t  fprintf (dump_file, \"Inserting cast in block %d: \",\n+\t\t   insert_bb->index);\n+\t  print_gimple_stmt (dump_file, cast_stmt, 0, 0);\n+\t}\n       fprintf (dump_file, \"Inserting in block %d: \", insert_bb->index);\n       print_gimple_stmt (dump_file, new_stmt, 0, 0);\n     }\n@@ -2825,40 +2899,35 @@ analyze_increments (slsr_cand_t first_dep, machine_mode mode, bool speed)\n \t\t   && !POINTER_TYPE_P (first_dep->cand_type)))\n \tincr_vec[i].cost = COST_NEUTRAL;\n \n-      /* FORNOW: If we need to add an initializer, give up if a cast from\n-\t the candidate's type to its stride's type can lose precision.\n-\t This could eventually be handled better by expressly retaining the\n-\t result of a cast to a wider type in the stride.  Example:\n+      /* If we need to add an initializer, give up if a cast from the\n+\t candidate's type to its stride's type can lose precision.\n+\t Note that this already takes into account that the stride may\n+\t have been cast to a wider type, in which case this test won't\n+\t fire.  Example:\n \n            short int _1;\n \t   _2 = (int) _1;\n \t   _3 = _2 * 10;\n-\t   _4 = x + _3;    ADD: x + (10 * _1) : int\n+\t   _4 = x + _3;    ADD: x + (10 * (int)_1) : int\n \t   _5 = _2 * 15;\n-\t   _6 = x + _3;    ADD: x + (15 * _1) : int\n-\n-         Right now replacing _6 would cause insertion of an initializer\n-\t of the form \"short int T = _1 * 5;\" followed by a cast to \n-\t int, which could overflow incorrectly.  Had we recorded _2 or\n-\t (int)_1 as the stride, this wouldn't happen.  However, doing\n-         this breaks other opportunities, so this will require some\n-\t care.  */\n+\t   _6 = x + _5;    ADD: x + (15 * (int)_1) : int\n+\n+\t Although the stride was a short int initially, the stride\n+\t used in the analysis has been widened to an int, and such\n+\t widening will be done in the initializer as well.  */\n       else if (!incr_vec[i].initializer\n \t       && TREE_CODE (first_dep->stride) != INTEGER_CST\n-\t       && !legal_cast_p_1 (first_dep->stride,\n-\t\t\t\t   gimple_assign_lhs (first_dep->cand_stmt)))\n-\n+\t       && !legal_cast_p_1 (first_dep->stride_type,\n+\t\t\t\t   TREE_TYPE (gimple_assign_lhs\n+\t\t\t\t\t      (first_dep->cand_stmt))))\n \tincr_vec[i].cost = COST_INFINITE;\n \n       /* If we need to add an initializer, make sure we don't introduce\n \t a multiply by a pointer type, which can happen in certain cast\n-\t scenarios.  FIXME: When cleaning up these cast issues, we can\n-         afford to introduce the multiply provided we cast out to an\n-         unsigned int of appropriate size.  */\n+\t scenarios.  */\n       else if (!incr_vec[i].initializer\n \t       && TREE_CODE (first_dep->stride) != INTEGER_CST\n-\t       && POINTER_TYPE_P (TREE_TYPE (first_dep->stride)))\n-\n+\t       && POINTER_TYPE_P (first_dep->stride_type))\n \tincr_vec[i].cost = COST_INFINITE;\n \n       /* For any other increment, if this is a multiply candidate, we\n@@ -3105,7 +3174,8 @@ insert_initializers (slsr_cand_t c)\n       basic_block bb;\n       slsr_cand_t where = NULL;\n       gassign *init_stmt;\n-      tree stride_type, new_name, incr_tree;\n+      gassign *cast_stmt = NULL;\n+      tree new_name, incr_tree, init_stride;\n       widest_int incr = incr_vec[i].incr;\n \n       if (!profitable_increment_p (i)\n@@ -3134,37 +3204,74 @@ insert_initializers (slsr_cand_t c)\n \t that block, the earliest one will be returned in WHERE.  */\n       bb = nearest_common_dominator_for_cands (c, incr, &where);\n \n+      /* If the nominal stride has a different type than the recorded\n+\t stride type, build a cast from the nominal stride to that type.  */\n+      if (!types_compatible_p (TREE_TYPE (c->stride), c->stride_type))\n+\t{\n+\t  init_stride = make_temp_ssa_name (c->stride_type, NULL, \"slsr\");\n+\t  cast_stmt = gimple_build_assign (init_stride, NOP_EXPR, c->stride);\n+\t}\n+      else\n+\tinit_stride = c->stride;\n+\n       /* Create a new SSA name to hold the initializer's value.  */\n-      stride_type = TREE_TYPE (c->stride);\n-      new_name = make_temp_ssa_name (stride_type, NULL, \"slsr\");\n+      new_name = make_temp_ssa_name (c->stride_type, NULL, \"slsr\");\n       incr_vec[i].initializer = new_name;\n \n       /* Create the initializer and insert it in the latest possible\n \t dominating position.  */\n-      incr_tree = wide_int_to_tree (stride_type, incr);\n+      incr_tree = wide_int_to_tree (c->stride_type, incr);\n       init_stmt = gimple_build_assign (new_name, MULT_EXPR,\n-\t\t\t\t       c->stride, incr_tree);\n+\t\t\t\t       init_stride, incr_tree);\n       if (where)\n \t{\n \t  gimple_stmt_iterator gsi = gsi_for_stmt (where->cand_stmt);\n+\t  location_t loc = gimple_location (where->cand_stmt);\n+\n+\t  if (cast_stmt)\n+\t    {\n+\t      gsi_insert_before (&gsi, cast_stmt, GSI_SAME_STMT);\n+\t      gimple_set_location (cast_stmt, loc);\n+\t    }\n+\n \t  gsi_insert_before (&gsi, init_stmt, GSI_SAME_STMT);\n-\t  gimple_set_location (init_stmt, gimple_location (where->cand_stmt));\n+\t  gimple_set_location (init_stmt, loc);\n \t}\n       else\n \t{\n \t  gimple_stmt_iterator gsi = gsi_last_bb (bb);\n \t  gimple *basis_stmt = lookup_cand (c->basis)->cand_stmt;\n+\t  location_t loc = gimple_location (basis_stmt);\n \n \t  if (!gsi_end_p (gsi) && is_ctrl_stmt (gsi_stmt (gsi)))\n-\t    gsi_insert_before (&gsi, init_stmt, GSI_SAME_STMT);\n+\t    {\n+\t      if (cast_stmt)\n+\t\t{\n+\t\t  gsi_insert_before (&gsi, cast_stmt, GSI_SAME_STMT);\n+\t\t  gimple_set_location (cast_stmt, loc);\n+\t\t}\n+\t      gsi_insert_before (&gsi, init_stmt, GSI_SAME_STMT);\n+\t    }\n \t  else\n-\t    gsi_insert_after (&gsi, init_stmt, GSI_SAME_STMT);\n+\t    {\n+\t      if (cast_stmt)\n+\t\t{\n+\t\t  gsi_insert_after (&gsi, cast_stmt, GSI_NEW_STMT);\n+\t\t  gimple_set_location (cast_stmt, loc);\n+\t\t}\n+\t      gsi_insert_after (&gsi, init_stmt, GSI_SAME_STMT);\n+\t    }\n \n \t  gimple_set_location (init_stmt, gimple_location (basis_stmt));\n \t}\n \n       if (dump_file && (dump_flags & TDF_DETAILS))\n \t{\n+\t  if (cast_stmt)\n+\t    {\n+\t      fputs (\"Inserting stride cast: \", dump_file);\n+\t      print_gimple_stmt (dump_file, cast_stmt, 0, 0);\n+\t    }\n \t  fputs (\"Inserting initializer: \", dump_file);\n \t  print_gimple_stmt (dump_file, init_stmt, 0, 0);\n \t}"}, {"sha": "051ae8326968b175775c229a162c1fd80b76ef38", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b56e9adf84be945617a8026a334dd6f14c1c679/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b56e9adf84be945617a8026a334dd6f14c1c679/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=0b56e9adf84be945617a8026a334dd6f14c1c679", "patch": "@@ -1,3 +1,11 @@\n+2016-10-30  Bill Schmidt  <wschmidt@linux.vnet.ibm.com>\n+\n+\tPR tree-optimization/71915\n+\tPR tree-optimization/71490\n+\t* gcc.dg/tree-ssa/pr54245.c: Delete.\n+\t* gcc.dg/tree-ssa/slsr-8.c: Adjust for new optimization and\n+\tdocument why.\n+\n 2016-10-30  Jerry DeLisle  <jvdelisle@gcc.gnu.org>\n \n \tPR fortran/78123"}, {"sha": "b96e3e51f5bf910326e8b37ff83d3f399e7fdc66", "filename": "gcc/testsuite/gcc.dg/tree-ssa/pr54245.c", "status": "removed", "additions": 0, "deletions": 48, "changes": 48, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/8972aa3362ab322891f482725d3866ccf265bb3a/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr54245.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/8972aa3362ab322891f482725d3866ccf265bb3a/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr54245.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fpr54245.c?ref=8972aa3362ab322891f482725d3866ccf265bb3a", "patch": "@@ -1,48 +0,0 @@\n-/* { dg-do compile } */\n-/* { dg-options \"-O1 -fdump-tree-slsr-details\" } */\n-\n-#include <stdio.h>\n-\n-#define W1  22725\n-#define W2  21407\n-#define W3  19266\n-#define W6  8867\n-\n-void idct_row(short *row, int *dst)\n-{\n-    int a0, a1, b0, b1;\n-\n-    a0 = W1 * row[0];\n-    a1 = a0;\n-\n-    a0 += W2 * row[2];\n-    a1 += W6 * row[2];\n-\n-    b0 = W1 * row[1];\n-    b1 = W3 * row[1];\n-\n-    dst[0] = a0 + b0;\n-    dst[1] = a0 - b0;\n-    dst[2] = a1 + b1;\n-    dst[3] = a1 - b1;\n-}\n-\n-static short block[8] = { 1, 2, 3, 4 };\n-\n-int main(void)\n-{\n-    int out[4];\n-    int i;\n-\n-    idct_row(block, out);\n-\n-    for (i = 0; i < 4; i++)\n-        printf(\"%d\\n\", out[i]);\n-\n-    return !(out[2] == 87858 && out[3] == 10794);\n-}\n-\n-/* For now, disable inserting an initializer when the multiplication will\n-   take place in a smaller type than originally.  This test may be deleted\n-   in future when this case is handled more precisely.  */\n-/* { dg-final { scan-tree-dump-times \"Inserting initializer\" 0 \"slsr\" { target { ! int16 } } } } */"}, {"sha": "97b8eab8005a4453b9f6e69239d8e5c6db2f9f02", "filename": "gcc/testsuite/gcc.dg/tree-ssa/slsr-8.c", "status": "modified", "additions": 10, "deletions": 5, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b56e9adf84be945617a8026a334dd6f14c1c679/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fslsr-8.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b56e9adf84be945617a8026a334dd6f14c1c679/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fslsr-8.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftree-ssa%2Fslsr-8.c?ref=0b56e9adf84be945617a8026a334dd6f14c1c679", "patch": "@@ -4,7 +4,7 @@\n /* { dg-options \"-O3 -fdump-tree-optimized\" } */\n \n int*\n-f (int s, int *c)\n+f (int s, int *c, int *d)\n {\n   int a1, a2, a3, *x1, *x2, *x3;\n \n@@ -14,10 +14,15 @@ f (int s, int *c)\n   x2 = c - a2;\n   a3 = 6 * s;\n   x3 = c - a3;\n-  return x1 ? x2 : x3;\n+  return x1 == d ? x2 : x3;\n }\n \n+/* Note that since some branch prediction heuristics changed, the\n+   calculations of x2 and x3 are pushed downward into the legs\n+   of the conditional, changing the code presented to SLSR.\n+   However, this proves to be a useful test for introducing an\n+   initializer with a cast, so we'll keep it as is.  */\n+\n /* There are 4 ' * ' instances in the decls (since \"int * iftmp.0;\" is\n-   added), 1 parm, 2 in the code.  The second one in the code can be\n-   a widening mult.  */\n-/* { dg-final { scan-tree-dump-times \" w?\\\\* \" 7 \"optimized\" } } */\n+   added), 2 parms, 3 in the code.  */\n+/* { dg-final { scan-tree-dump-times \" \\\\* \" 9 \"optimized\" } } */"}]}