{"sha": "c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YzNmMTRkNTVlOGVhNjI5MDNhMzc2Y2ZlYjNmNWU5YjhmOTZkOWE1MA==", "commit": {"author": {"name": "David Malcolm", "email": "dmalcolm@redhat.com", "date": "2014-08-30T14:34:02Z"}, "committer": {"name": "David Malcolm", "email": "dmalcolm@gcc.gnu.org", "date": "2014-08-30T14:34:02Z"}, "message": "re PR bootstrap/62304 (ICE in follow_jumps, find_dead_or_set_registers)\n\n\tPR bootstrap/62304\n\n\t* gcc/reorg.c (skip_consecutive_labels): Convert return type and\n\tparam back from rtx_insn * to rtx.  Rename param from \"label\" to\n\t\"label_or_return\", reintroducing \"label\" as an rtx_insn * after\n\twe've ensured it's not a RETURN.\n\t(first_active_target_insn): Likewise for return type and param;\n\tadd a checked cast to rtx_insn * once we've ensured \"insn\" is not\n\ta RETURN.\n\t(steal_delay_list_from_target): Convert param \"pnew_thread\" back\n\tfrom rtx_insn ** to rtx *.  Replace use of JUMP_LABEL_AS_INSN\n\twith JUMP_LABEL.\n\t(own_thread_p): Convert param \"thread\" back from an rtx_insn * to\n\tan rtx.  Introduce local rtx_insn * \"thread_insn\" with a checked\n\tcast once we've established we're not dealing with a RETURN,\n\trenaming subsequent uses of \"thread\" to \"thread_insn\".\n\t(fill_simple_delay_slots): Convert uses of JUMP_LABEL_AS_INSN back\n\tto JUMP_LABEL.\n\t(follow_jumps): Convert return type and param \"label\" from\n\trtx_insn * back to rtx.  Move initialization of \"value\" to after\n\tthe handling for ANY_RETURN_P, adding a checked cast there to\n\trtx_insn *.  Convert local rtx_insn * \"this_label\" to an rtx and\n\trename to \"this_label_or_return\", reintroducing \"this_label\" as\n\tan rtx_insn * once we've handled the case where it could be an\n\tANY_RETURN_P.\n\t(fill_slots_from_thread): Rename param \"thread\" to\n\t\"thread_or_return\", converting from an rtx_insn * back to an rtx.\n\tReintroduce name \"thread\" as an rtx_insn * local with a checked\n\tcast once we've handled the case of it being an ANY_RETURN_P.\n\tConvert local \"new_thread\" from an rtx_insn * back to an rtx.\n\tAdd a checked cast when assigning to \"trial\" from \"new_thread\".\n\tConvert use of JUMP_LABEL_AS_INSN back to JUMP_LABEL.  Add a\n\tchecked cast to rtx_insn * from \"new_thread\" when invoking\n\tget_label_before.\n\t(fill_eager_delay_slots): Convert locals \"target_label\",\n\t\"insn_at_target\" from rtx_insn * back to rtx.\n\tConvert uses of JUMP_LABEL_AS_INSN back to JUMP_LABEL.\n\t(relax_delay_slots): Convert locals \"trial\", \"target_label\" from\n\trtx_insn * back to rtx.  Convert uses of JUMP_LABEL_AS_INSN back\n\tto JUMP_LABEL.  Add a checked cast to rtx_insn * on \"trial\" when\n\tinvoking update_block.\n\t(dbr_schedule): Convert use of JUMP_LABEL_AS_INSN back to\n\tJUMP_LABEL; this removes all JUMP_LABEL_AS_INSN from reorg.c.\n\n\t* resource.h (mark_target_live_regs): Undo erroneous conversion\n\tof second param of r214693, converting it back from rtx_insn * to\n\trtx, since it could be a RETURN.\n\n\t* resource.c (find_dead_or_set_registers): Similarly, convert\n\tparam \"jump_target\" back from an rtx_insn ** to an rtx *, as we\n\tcould be writing back a RETURN.  Rename local rtx_insn * \"next\" to\n\t\"next_insn\", and introduce \"lab_or_return\" as a local rtx,\n\thandling the case where JUMP_LABEL (this_jump_insn) is a RETURN.\n\t(mark_target_live_regs): Undo erroneous conversion\n\tof second param of r214693, converting it back from rtx_insn * to\n\trtx, since it could be a RETURN.  Rename it from \"target\" to\n\t\"target_maybe_return\", reintroducing the name \"target\" as a local\n\trtx_insn * with a checked cast, after we've handled the case of\n\tANY_RETURN_P.\n\nFrom-SVN: r214752", "tree": {"sha": "42c95125319434f4d1a7cb40503e4b5b63dc97dc", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/42c95125319434f4d1a7cb40503e4b5b63dc97dc"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50/comments", "author": {"login": "davidmalcolm", "id": 1553248, "node_id": "MDQ6VXNlcjE1NTMyNDg=", "avatar_url": "https://avatars.githubusercontent.com/u/1553248?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidmalcolm", "html_url": "https://github.com/davidmalcolm", "followers_url": "https://api.github.com/users/davidmalcolm/followers", "following_url": "https://api.github.com/users/davidmalcolm/following{/other_user}", "gists_url": "https://api.github.com/users/davidmalcolm/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidmalcolm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidmalcolm/subscriptions", "organizations_url": "https://api.github.com/users/davidmalcolm/orgs", "repos_url": "https://api.github.com/users/davidmalcolm/repos", "events_url": "https://api.github.com/users/davidmalcolm/events{/privacy}", "received_events_url": "https://api.github.com/users/davidmalcolm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "124aeea17940dba7fcfade6803b7aa59d7e7440d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/124aeea17940dba7fcfade6803b7aa59d7e7440d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/124aeea17940dba7fcfade6803b7aa59d7e7440d"}], "stats": {"total": 207, "additions": 147, "deletions": 60}, "files": [{"sha": "ff5128745cb3ef3f40ac3ea94cc2f6e9abcf0ea5", "filename": "gcc/ChangeLog", "status": "modified", "additions": 62, "deletions": 0, "changes": 62, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50", "patch": "@@ -1,3 +1,65 @@\n+2014-08-30  David Malcolm  <dmalcolm@redhat.com>\n+\n+\tPR bootstrap/62304\n+\n+\t* gcc/reorg.c (skip_consecutive_labels): Convert return type and\n+\tparam back from rtx_insn * to rtx.  Rename param from \"label\" to\n+\t\"label_or_return\", reintroducing \"label\" as an rtx_insn * after\n+\twe've ensured it's not a RETURN.\n+\t(first_active_target_insn): Likewise for return type and param;\n+\tadd a checked cast to rtx_insn * once we've ensured \"insn\" is not\n+\ta RETURN.\n+\t(steal_delay_list_from_target): Convert param \"pnew_thread\" back\n+\tfrom rtx_insn ** to rtx *.  Replace use of JUMP_LABEL_AS_INSN\n+\twith JUMP_LABEL.\n+\t(own_thread_p): Convert param \"thread\" back from an rtx_insn * to\n+\tan rtx.  Introduce local rtx_insn * \"thread_insn\" with a checked\n+\tcast once we've established we're not dealing with a RETURN,\n+\trenaming subsequent uses of \"thread\" to \"thread_insn\".\n+\t(fill_simple_delay_slots): Convert uses of JUMP_LABEL_AS_INSN back\n+\tto JUMP_LABEL.\n+\t(follow_jumps): Convert return type and param \"label\" from\n+\trtx_insn * back to rtx.  Move initialization of \"value\" to after\n+\tthe handling for ANY_RETURN_P, adding a checked cast there to\n+\trtx_insn *.  Convert local rtx_insn * \"this_label\" to an rtx and\n+\trename to \"this_label_or_return\", reintroducing \"this_label\" as\n+\tan rtx_insn * once we've handled the case where it could be an\n+\tANY_RETURN_P.\n+\t(fill_slots_from_thread): Rename param \"thread\" to\n+\t\"thread_or_return\", converting from an rtx_insn * back to an rtx.\n+\tReintroduce name \"thread\" as an rtx_insn * local with a checked\n+\tcast once we've handled the case of it being an ANY_RETURN_P.\n+\tConvert local \"new_thread\" from an rtx_insn * back to an rtx.\n+\tAdd a checked cast when assigning to \"trial\" from \"new_thread\".\n+\tConvert use of JUMP_LABEL_AS_INSN back to JUMP_LABEL.  Add a\n+\tchecked cast to rtx_insn * from \"new_thread\" when invoking\n+\tget_label_before.\n+\t(fill_eager_delay_slots): Convert locals \"target_label\",\n+\t\"insn_at_target\" from rtx_insn * back to rtx.\n+\tConvert uses of JUMP_LABEL_AS_INSN back to JUMP_LABEL.\n+\t(relax_delay_slots): Convert locals \"trial\", \"target_label\" from\n+\trtx_insn * back to rtx.  Convert uses of JUMP_LABEL_AS_INSN back\n+\tto JUMP_LABEL.  Add a checked cast to rtx_insn * on \"trial\" when\n+\tinvoking update_block.\n+\t(dbr_schedule): Convert use of JUMP_LABEL_AS_INSN back to\n+\tJUMP_LABEL; this removes all JUMP_LABEL_AS_INSN from reorg.c.\n+\n+\t* resource.h (mark_target_live_regs): Undo erroneous conversion\n+\tof second param of r214693, converting it back from rtx_insn * to\n+\trtx, since it could be a RETURN.\n+\n+\t* resource.c (find_dead_or_set_registers): Similarly, convert\n+\tparam \"jump_target\" back from an rtx_insn ** to an rtx *, as we\n+\tcould be writing back a RETURN.  Rename local rtx_insn * \"next\" to\n+\t\"next_insn\", and introduce \"lab_or_return\" as a local rtx,\n+\thandling the case where JUMP_LABEL (this_jump_insn) is a RETURN.\n+\t(mark_target_live_regs): Undo erroneous conversion\n+\tof second param of r214693, converting it back from rtx_insn * to\n+\trtx, since it could be a RETURN.  Rename it from \"target\" to\n+\t\"target_maybe_return\", reintroducing the name \"target\" as a local\n+\trtx_insn * with a checked cast, after we've handled the case of\n+\tANY_RETURN_P.\n+\n 2014-08-29  DJ Delorie  <dj@redhat.com>\n \n \t* cppbuiltin.c (define_builtin_macros_for_type_sizes): Round"}, {"sha": "3d438e551201bbb4deec9b2f70db1401dac9b6f7", "filename": "gcc/reorg.c", "status": "modified", "additions": 63, "deletions": 45, "changes": 108, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50/gcc%2Freorg.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50/gcc%2Freorg.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freorg.c?ref=c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50", "patch": "@@ -142,13 +142,15 @@ along with GCC; see the file COPYING3.  If not see\n /* Return the last label to mark the same position as LABEL.  Return LABEL\n    itself if it is null or any return rtx.  */\n \n-static rtx_insn *\n-skip_consecutive_labels (rtx_insn *label)\n+static rtx\n+skip_consecutive_labels (rtx label_or_return)\n {\n   rtx_insn *insn;\n \n-  if (label && ANY_RETURN_P (label))\n-    return label;\n+  if (label_or_return && ANY_RETURN_P (label_or_return))\n+    return label_or_return;\n+\n+  rtx_insn *label = as_a <rtx_insn *> (label_or_return);\n \n   for (insn = label; insn != 0 && !INSN_P (insn); insn = NEXT_INSN (insn))\n     if (LABEL_P (insn))\n@@ -229,7 +231,7 @@ static rtx_insn_list *steal_delay_list_from_target (rtx_insn *, rtx,\n \t\t\t\t\t\t    struct resources *,\n \t\t\t\t\t\t    struct resources *,\n \t\t\t\t\t\t    int, int *, int *,\n-\t\t\t\t\t\t    rtx_insn **);\n+\t\t\t\t\t\t    rtx *);\n static rtx_insn_list *steal_delay_list_from_fallthrough (rtx_insn *, rtx,\n \t\t\t\t\t\t\t rtx_sequence *,\n \t\t\t\t\t\t\t rtx_insn_list *,\n@@ -239,15 +241,14 @@ static rtx_insn_list *steal_delay_list_from_fallthrough (rtx_insn *, rtx,\n \t\t\t\t\t\t\t int, int *, int *);\n static void try_merge_delay_insns (rtx, rtx_insn *);\n static rtx redundant_insn (rtx, rtx_insn *, rtx);\n-static int own_thread_p (rtx_insn *, rtx, int);\n+static int own_thread_p (rtx, rtx, int);\n static void update_block (rtx_insn *, rtx);\n static int reorg_redirect_jump (rtx_insn *, rtx);\n static void update_reg_dead_notes (rtx, rtx);\n static void fix_reg_dead_note (rtx, rtx);\n static void update_reg_unused_notes (rtx, rtx);\n static void fill_simple_delay_slots (int);\n-static rtx_insn_list *fill_slots_from_thread (rtx_insn *, rtx,\n-\t\t\t\t\t      rtx_insn *, rtx_insn *,\n+static rtx_insn_list *fill_slots_from_thread (rtx_insn *, rtx, rtx, rtx,\n \t\t\t\t\t      int, int, int, int,\n \t\t\t\t\t      int *, rtx_insn_list *);\n static void fill_eager_delay_slots (void);\n@@ -257,12 +258,12 @@ static void make_return_insns (rtx_insn *);\n /* A wrapper around next_active_insn which takes care to return ret_rtx\n    unchanged.  */\n \n-static rtx_insn *\n-first_active_target_insn (rtx_insn *insn)\n+static rtx\n+first_active_target_insn (rtx insn)\n {\n   if (ANY_RETURN_P (insn))\n     return insn;\n-  return next_active_insn (insn);\n+  return next_active_insn (as_a <rtx_insn *> (insn));\n }\n \f\n /* Return true iff INSN is a simplejump, or any kind of return insn.  */\n@@ -1089,7 +1090,7 @@ steal_delay_list_from_target (rtx_insn *insn, rtx condition, rtx_sequence *seq,\n \t\t\t      struct resources *needed,\n \t\t\t      struct resources *other_needed,\n \t\t\t      int slots_to_fill, int *pslots_filled,\n-\t\t\t      int *pannul_p, rtx_insn **pnew_thread)\n+\t\t\t      int *pannul_p, rtx *pnew_thread)\n {\n   int slots_remaining = slots_to_fill - *pslots_filled;\n   int total_slots_filled = *pslots_filled;\n@@ -1202,7 +1203,7 @@ steal_delay_list_from_target (rtx_insn *insn, rtx condition, rtx_sequence *seq,\n       update_block (seq->insn (i), insn);\n \n   /* Show the place to which we will be branching.  */\n-  *pnew_thread = first_active_target_insn (JUMP_LABEL_AS_INSN (seq->insn (0)));\n+  *pnew_thread = first_active_target_insn (JUMP_LABEL (seq->insn (0)));\n \n   /* Add any new insns to the delay list and update the count of the\n      number of slots filled.  */\n@@ -1715,7 +1716,7 @@ redundant_insn (rtx insn, rtx_insn *target, rtx delay_list)\n    finding an active insn, we do not own this thread.  */\n \n static int\n-own_thread_p (rtx_insn *thread, rtx label, int allow_fallthrough)\n+own_thread_p (rtx thread, rtx label, int allow_fallthrough)\n {\n   rtx_insn *active_insn;\n   rtx_insn *insn;\n@@ -1724,10 +1725,13 @@ own_thread_p (rtx_insn *thread, rtx label, int allow_fallthrough)\n   if (thread == 0 || ANY_RETURN_P (thread))\n     return 0;\n \n-  /* Get the first active insn, or THREAD, if it is an active insn.  */\n-  active_insn = next_active_insn (PREV_INSN (thread));\n+  /* We have a non-NULL insn.  */\n+  rtx_insn *thread_insn = as_a <rtx_insn *> (thread);\n+\n+  /* Get the first active insn, or THREAD_INSN, if it is an active insn.  */\n+  active_insn = next_active_insn (PREV_INSN (thread_insn));\n \n-  for (insn = thread; insn != active_insn; insn = NEXT_INSN (insn))\n+  for (insn = thread_insn; insn != active_insn; insn = NEXT_INSN (insn))\n     if (LABEL_P (insn)\n \t&& (insn != label || LABEL_NUSES (insn) != 1))\n       return 0;\n@@ -1736,7 +1740,7 @@ own_thread_p (rtx_insn *thread, rtx label, int allow_fallthrough)\n     return 1;\n \n   /* Ensure that we reach a BARRIER before any insn or label.  */\n-  for (insn = prev_nonnote_insn (thread);\n+  for (insn = prev_nonnote_insn (thread_insn);\n        insn == 0 || !BARRIER_P (insn);\n        insn = prev_nonnote_insn (insn))\n     if (insn == 0\n@@ -2275,8 +2279,8 @@ fill_simple_delay_slots (int non_jumps_p)\n \t  = fill_slots_from_thread (insn, const_true_rtx,\n \t\t\t\t    next_active_insn (JUMP_LABEL (insn)),\n \t\t\t\t    NULL, 1, 1,\n-\t\t\t\t    own_thread_p (JUMP_LABEL_AS_INSN (insn),\n-\t\t\t\t\t\t  JUMP_LABEL_AS_INSN (insn), 0),\n+\t\t\t\t    own_thread_p (JUMP_LABEL (insn),\n+\t\t\t\t\t\t  JUMP_LABEL (insn), 0),\n \t\t\t\t    slots_to_fill, &slots_filled,\n \t\t\t\t    delay_list);\n \n@@ -2301,17 +2305,19 @@ fill_simple_delay_slots (int non_jumps_p)\n    If the returned label is obtained by following a crossing jump,\n    set *CROSSING to true, otherwise set it to false.  */\n \n-static rtx_insn *\n-follow_jumps (rtx_insn *label, rtx jump, bool *crossing)\n+static rtx\n+follow_jumps (rtx label, rtx jump, bool *crossing)\n {\n   rtx_insn *insn;\n   rtx_insn *next;\n-  rtx_insn *value = label;\n   int depth;\n \n   *crossing = false;\n   if (ANY_RETURN_P (label))\n     return label;\n+\n+  rtx_insn *value = as_a <rtx_insn *> (label);\n+\n   for (depth = 0;\n        (depth < 10\n \t&& (insn = next_active_insn (value)) != 0\n@@ -2323,15 +2329,17 @@ follow_jumps (rtx_insn *label, rtx jump, bool *crossing)\n \t&& BARRIER_P (next));\n        depth++)\n     {\n-      rtx_insn *this_label = JUMP_LABEL_AS_INSN (insn);\n+      rtx this_label_or_return = JUMP_LABEL (insn);\n \n       /* If we have found a cycle, make the insn jump to itself.  */\n-      if (this_label == label)\n+      if (this_label_or_return == label)\n \treturn label;\n \n       /* Cannot follow returns and cannot look through tablejumps.  */\n-      if (ANY_RETURN_P (this_label))\n-\treturn this_label;\n+      if (ANY_RETURN_P (this_label_or_return))\n+\treturn this_label_or_return;\n+\n+      rtx_insn *this_label = as_a <rtx_insn *> (this_label_or_return);\n       if (NEXT_INSN (this_label)\n \t  && JUMP_TABLE_DATA_P (NEXT_INSN (this_label)))\n \tbreak;\n@@ -2372,13 +2380,13 @@ follow_jumps (rtx_insn *label, rtx jump, bool *crossing)\n    slot.  We then adjust the jump to point after the insns we have taken.  */\n \n static rtx_insn_list *\n-fill_slots_from_thread (rtx_insn *insn, rtx condition, rtx_insn *thread,\n-\t\t\trtx_insn *opposite_thread, int likely,\n+fill_slots_from_thread (rtx_insn *insn, rtx condition, rtx thread_or_return,\n+\t\t\trtx opposite_thread, int likely,\n \t\t\tint thread_if_true,\n \t\t\tint own_thread, int slots_to_fill,\n \t\t\tint *pslots_filled, rtx_insn_list *delay_list)\n {\n-  rtx_insn *new_thread;\n+  rtx new_thread;\n   struct resources opposite_needed, set, needed;\n   rtx_insn *trial;\n   int lose = 0;\n@@ -2393,9 +2401,11 @@ fill_slots_from_thread (rtx_insn *insn, rtx condition, rtx_insn *thread,\n \n   /* If our thread is the end of subroutine, we can't get any delay\n      insns from that.  */\n-  if (thread == NULL_RTX || ANY_RETURN_P (thread))\n+  if (thread_or_return == NULL_RTX || ANY_RETURN_P (thread_or_return))\n     return delay_list;\n \n+  rtx_insn *thread = as_a <rtx_insn *> (thread_or_return);\n+\n   /* If this is an unconditional branch, nothing is needed at the\n      opposite thread.  Otherwise, compute what is needed there.  */\n   if (condition == const_true_rtx)\n@@ -2716,7 +2726,9 @@ fill_slots_from_thread (rtx_insn *insn, rtx condition, rtx_insn *thread,\n       rtx dest;\n       rtx src;\n \n-      trial = new_thread;\n+      /* We know \"new_thread\" is an insn due to NONJUMP_INSN_P (new_thread)\n+\t above.  */\n+      trial = as_a <rtx_insn *> (new_thread);\n       pat = PATTERN (trial);\n \n       if (!NONJUMP_INSN_P (trial)\n@@ -2797,15 +2809,16 @@ fill_slots_from_thread (rtx_insn *insn, rtx condition, rtx_insn *thread,\n \t  && redirect_with_delay_list_safe_p (insn,\n \t\t\t\t\t      JUMP_LABEL (new_thread),\n \t\t\t\t\t      delay_list))\n-\tnew_thread = follow_jumps (JUMP_LABEL_AS_INSN (new_thread), insn,\n+\tnew_thread = follow_jumps (JUMP_LABEL (new_thread), insn,\n \t\t\t\t   &crossing);\n \n       if (ANY_RETURN_P (new_thread))\n \tlabel = find_end_label (new_thread);\n       else if (LABEL_P (new_thread))\n \tlabel = new_thread;\n       else\n-\tlabel = get_label_before (new_thread, JUMP_LABEL (insn));\n+\tlabel = get_label_before (as_a <rtx_insn *> (new_thread),\n+\t\t\t\t  JUMP_LABEL (insn));\n \n       if (label)\n \t{\n@@ -2838,7 +2851,8 @@ fill_eager_delay_slots (void)\n   for (i = 0; i < num_unfilled_slots; i++)\n     {\n       rtx condition;\n-      rtx_insn *target_label, *insn_at_target, *fallthrough_insn;\n+      rtx target_label, insn_at_target;\n+      rtx_insn *fallthrough_insn;\n       rtx_insn_list *delay_list = 0;\n       int own_target;\n       int own_fallthrough;\n@@ -2867,7 +2881,7 @@ fill_eager_delay_slots (void)\n \tcontinue;\n \n       slots_filled = 0;\n-      target_label = JUMP_LABEL_AS_INSN (insn);\n+      target_label = JUMP_LABEL (insn);\n       condition = get_branch_condition (insn, target_label);\n \n       if (condition == 0)\n@@ -2911,7 +2925,7 @@ fill_eager_delay_slots (void)\n \t\t we might have found a redundant insn which we deleted\n \t\t from the thread that was filled.  So we have to recompute\n \t\t the next insn at the target.  */\n-\t      target_label = JUMP_LABEL_AS_INSN (insn);\n+\t      target_label = JUMP_LABEL (insn);\n \t      insn_at_target = first_active_target_insn (target_label);\n \n \t      delay_list\n@@ -3153,7 +3167,9 @@ relax_delay_slots (rtx_insn *first)\n {\n   rtx_insn *insn, *next;\n   rtx_sequence *pat;\n-  rtx_insn *trial, *delay_insn, *target_label;\n+  rtx trial;\n+  rtx_insn *delay_insn;\n+  rtx target_label;\n \n   /* Look at every JUMP_INSN and see if we can improve it.  */\n   for (insn = first; insn; insn = next)\n@@ -3168,7 +3184,7 @@ relax_delay_slots (rtx_insn *first)\n \t group of consecutive labels.  */\n       if (JUMP_P (insn)\n \t  && (condjump_p (insn) || condjump_in_parallel_p (insn))\n-\t  && !ANY_RETURN_P (target_label = JUMP_LABEL_AS_INSN (insn)))\n+\t  && !ANY_RETURN_P (target_label = JUMP_LABEL (insn)))\n \t{\n \t  target_label\n \t    = skip_consecutive_labels (follow_jumps (target_label, insn,\n@@ -3243,7 +3259,7 @@ relax_delay_slots (rtx_insn *first)\n \t  && 0 > mostly_true_jump (other))\n \t{\n \t  rtx other_target = JUMP_LABEL (other);\n-\t  target_label = JUMP_LABEL_AS_INSN (insn);\n+\t  target_label = JUMP_LABEL (insn);\n \n \t  if (invert_jump (other, target_label, 0))\n \t    reorg_redirect_jump (insn, other_target);\n@@ -3315,7 +3331,7 @@ relax_delay_slots (rtx_insn *first)\n \t  || !(condjump_p (delay_insn) || condjump_in_parallel_p (delay_insn)))\n \tcontinue;\n \n-      target_label = JUMP_LABEL_AS_INSN (delay_insn);\n+      target_label = JUMP_LABEL (delay_insn);\n       if (target_label && ANY_RETURN_P (target_label))\n \tcontinue;\n \n@@ -3353,8 +3369,10 @@ relax_delay_slots (rtx_insn *first)\n \n \t  if (tmp)\n \t    {\n-\t      /* Insert the special USE insn and update dataflow info.  */\n-\t      update_block (trial, tmp);\n+\t      /* Insert the special USE insn and update dataflow info.\n+\t\t We know \"trial\" is an insn here as it is the output of\n+\t\t next_real_insn () above.  */\n+\t      update_block (as_a <rtx_insn *> (trial), tmp);\n \t      \n \t      /* Now emit a label before the special USE insn, and\n \t\t redirect our jump to the new label.  */\n@@ -3374,7 +3392,7 @@ relax_delay_slots (rtx_insn *first)\n \t  && redundant_insn (XVECEXP (PATTERN (trial), 0, 1), insn, 0))\n \t{\n \t  rtx_sequence *trial_seq = as_a <rtx_sequence *> (PATTERN (trial));\n-\t  target_label = JUMP_LABEL_AS_INSN (trial_seq->insn (0));\n+\t  target_label = JUMP_LABEL (trial_seq->insn (0));\n \t  if (ANY_RETURN_P (target_label))\n \t    target_label = find_end_label (target_label);\n \t  \n@@ -3716,7 +3734,7 @@ dbr_schedule (rtx_insn *first)\n       if (JUMP_P (insn)\n \t  && (condjump_p (insn) || condjump_in_parallel_p (insn))\n \t  && !ANY_RETURN_P (JUMP_LABEL (insn))\n-\t  && ((target = skip_consecutive_labels (JUMP_LABEL_AS_INSN (insn)))\n+\t  && ((target = skip_consecutive_labels (JUMP_LABEL (insn)))\n \t      != JUMP_LABEL (insn)))\n \tredirect_jump (insn, target, 1);\n     }"}, {"sha": "95c5f283b9e3677122f4bb9ee3ce28bbe3079f79", "filename": "gcc/resource.c", "status": "modified", "additions": 21, "deletions": 14, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50/gcc%2Fresource.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50/gcc%2Fresource.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fresource.c?ref=c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50", "patch": "@@ -81,7 +81,7 @@ static void update_live_status (rtx, const_rtx, void *);\n static int find_basic_block (rtx, int);\n static rtx_insn *next_insn_no_annul (rtx_insn *);\n static rtx_insn *find_dead_or_set_registers (rtx_insn *, struct resources*,\n-\t\t\t\t\t     rtx_insn **, int, struct resources,\n+\t\t\t\t\t     rtx *, int, struct resources,\n \t\t\t\t\t     struct resources);\n \f\n /* Utility function called from mark_target_live_regs via note_stores.\n@@ -422,19 +422,20 @@ mark_referenced_resources (rtx x, struct resources *res,\n \n static rtx_insn *\n find_dead_or_set_registers (rtx_insn *target, struct resources *res,\n-\t\t\t    rtx_insn **jump_target, int jump_count,\n+\t\t\t    rtx *jump_target, int jump_count,\n \t\t\t    struct resources set, struct resources needed)\n {\n   HARD_REG_SET scratch;\n-  rtx_insn *insn, *next;\n+  rtx_insn *insn;\n+  rtx_insn *next_insn;\n   rtx_insn *jump_insn = 0;\n   int i;\n \n-  for (insn = target; insn; insn = next)\n+  for (insn = target; insn; insn = next_insn)\n     {\n       rtx_insn *this_jump_insn = insn;\n \n-      next = NEXT_INSN (insn);\n+      next_insn = NEXT_INSN (insn);\n \n       /* If this instruction can throw an exception, then we don't\n \t know where we might end up next.  That means that we have to\n@@ -497,14 +498,16 @@ find_dead_or_set_registers (rtx_insn *target, struct resources *res,\n \t      if (any_uncondjump_p (this_jump_insn)\n \t\t  || ANY_RETURN_P (PATTERN (this_jump_insn)))\n \t\t{\n-\t\t  next = JUMP_LABEL_AS_INSN (this_jump_insn);\n-\t\t  if (ANY_RETURN_P (next))\n-\t\t    next = NULL;\n+\t\t  rtx lab_or_return = JUMP_LABEL (this_jump_insn);\n+\t\t  if (ANY_RETURN_P (lab_or_return))\n+\t\t    next_insn = NULL;\n+\t\t  else\n+\t\t    next_insn = as_a <rtx_insn *> (lab_or_return);\n \t\t  if (jump_insn == 0)\n \t\t    {\n \t\t      jump_insn = insn;\n \t\t      if (jump_target)\n-\t\t\t*jump_target = JUMP_LABEL_AS_INSN (this_jump_insn);\n+\t\t\t*jump_target = JUMP_LABEL (this_jump_insn);\n \t\t    }\n \t\t}\n \t      else if (any_condjump_p (this_jump_insn))\n@@ -572,7 +575,7 @@ find_dead_or_set_registers (rtx_insn *target, struct resources *res,\n \t\t    find_dead_or_set_registers (JUMP_LABEL_AS_INSN (this_jump_insn),\n \t\t\t\t\t\t&target_res, 0, jump_count,\n \t\t\t\t\t\ttarget_set, needed);\n-\t\t  find_dead_or_set_registers (next,\n+\t\t  find_dead_or_set_registers (next_insn,\n \t\t\t\t\t      &fallthrough_res, 0, jump_count,\n \t\t\t\t\t      set, needed);\n \t\t  IOR_HARD_REG_SET (fallthrough_res.regs, target_res.regs);\n@@ -880,26 +883,30 @@ return_insn_p (const_rtx insn)\n    init_resource_info () was invoked before we are called.  */\n \n void\n-mark_target_live_regs (rtx_insn *insns, rtx_insn *target, struct resources *res)\n+mark_target_live_regs (rtx_insn *insns, rtx target_maybe_return, struct resources *res)\n {\n   int b = -1;\n   unsigned int i;\n   struct target_info *tinfo = NULL;\n   rtx_insn *insn;\n   rtx jump_insn = 0;\n-  rtx_insn *jump_target;\n+  rtx jump_target;\n   HARD_REG_SET scratch;\n   struct resources set, needed;\n \n   /* Handle end of function.  */\n-  if (target == 0 || ANY_RETURN_P (target))\n+  if (target_maybe_return == 0 || ANY_RETURN_P (target_maybe_return))\n     {\n       *res = end_of_function_needs;\n       return;\n     }\n \n+  /* We've handled the case of RETURN/SIMPLE_RETURN; we should now have an\n+     instruction.  */\n+  rtx_insn *target = as_a <rtx_insn *> (target_maybe_return);\n+\n   /* Handle return insn.  */\n-  else if (return_insn_p (target))\n+  if (return_insn_p (target))\n     {\n       *res = end_of_function_needs;\n       mark_referenced_resources (target, res, false);"}, {"sha": "2865283c66f93a0886af7c4450240429a8f85435", "filename": "gcc/resource.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50/gcc%2Fresource.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50/gcc%2Fresource.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fresource.h?ref=c3f14d55e8ea62903a376cfeb3f5e9b8f96d9a50", "patch": "@@ -44,7 +44,7 @@ enum mark_resource_type\n   MARK_SRC_DEST_CALL = 1\n };\n \n-extern void mark_target_live_regs (rtx_insn *, rtx_insn *, struct resources *);\n+extern void mark_target_live_regs (rtx_insn *, rtx, struct resources *);\n extern void mark_set_resources (rtx, struct resources *, int,\n \t\t\t\tenum mark_resource_type);\n extern void mark_referenced_resources (rtx, struct resources *, bool);"}]}