{"sha": "322e3e342039ed1f1aa8a53cd3948ed9313b87c5", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MzIyZTNlMzQyMDM5ZWQxZjFhYThhNTNjZDM5NDhlZDkzMTNiODdjNQ==", "commit": {"author": {"name": "Richard Kenner", "email": "kenner@gcc.gnu.org", "date": "1993-03-23T13:09:36Z"}, "committer": {"name": "Richard Kenner", "email": "kenner@gcc.gnu.org", "date": "1993-03-23T13:09:36Z"}, "message": "Include gvarargs.h.\n\nAdd prototypes to forward declarations and declare static functions.\n(prepare_call_address, emit_call_1): Now static.\n(emit_library_call, emit_library_call_value): Move to here.\n\nFrom-SVN: r3848", "tree": {"sha": "e36d8ead250107918465b066991ca83474571870", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/e36d8ead250107918465b066991ca83474571870"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/322e3e342039ed1f1aa8a53cd3948ed9313b87c5", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/322e3e342039ed1f1aa8a53cd3948ed9313b87c5", "html_url": "https://github.com/Rust-GCC/gccrs/commit/322e3e342039ed1f1aa8a53cd3948ed9313b87c5", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/322e3e342039ed1f1aa8a53cd3948ed9313b87c5/comments", "author": null, "committer": null, "parents": [{"sha": "b587ed666092094da78167f00e07d30ae791c739", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b587ed666092094da78167f00e07d30ae791c739", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b587ed666092094da78167f00e07d30ae791c739"}], "stats": {"total": 611, "additions": 607, "deletions": 4}, "files": [{"sha": "2b024d45eceeb29a635516f013bc99162d097db4", "filename": "gcc/calls.c", "status": "modified", "additions": 607, "deletions": 4, "changes": 611, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/322e3e342039ed1f1aa8a53cd3948ed9313b87c5/gcc%2Fcalls.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/322e3e342039ed1f1aa8a53cd3948ed9313b87c5/gcc%2Fcalls.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcalls.c?ref=322e3e342039ed1f1aa8a53cd3948ed9313b87c5", "patch": "@@ -22,6 +22,7 @@ the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.  */\n #include \"tree.h\"\n #include \"flags.h\"\n #include \"expr.h\"\n+#include \"gvarargs.h\"\n #include \"insn-flags.h\"\n \n /* Decide whether a function's arguments should be processed\n@@ -117,8 +118,12 @@ static int highest_outgoing_arg_in_use;\n int stack_arg_under_construction;\n #endif\n \n-static void store_one_arg ();\n-extern enum machine_mode mode_for_size ();\n+static int calls_function\tPROTO((tree, int));\n+static rtx prepare_call_address\tPROTO((rtx, tree, rtx *));\n+static void emit_call_1\t\tPROTO((rtx, tree, int, int, rtx, rtx, int,\n+\t\t\t\t       rtx, int));\n+static void store_one_arg\tPROTO ((struct arg_data *, rtx, int, int,\n+\t\t\t\t\ttree, int));\n \f\n /* If WHICH is 1, return 1 if EXP contains a call to the built-in function\n    `alloca'.\n@@ -213,7 +218,7 @@ calls_function (exp, which)\n    to which a USE of the static chain\n    register should be added, if required.  */\n \n-rtx\n+static rtx\n prepare_call_address (funexp, fndecl, use_insns)\n      rtx funexp;\n      tree fndecl;\n@@ -293,7 +298,7 @@ prepare_call_address (funexp, fndecl, use_insns)\n \n    IS_CONST is true if this is a `const' call.  */\n \n-void\n+static void\n emit_call_1 (funexp, funtype, stack_size, struct_value_size, next_arg_reg,\n \t     valreg, old_inhibit_defer_pop, use_insns, is_const)\n      rtx funexp;\n@@ -1931,6 +1936,604 @@ expand_call (exp, target, ignore)\n   return target;\n }\n \f\n+/* Output a library call to function FUN (a SYMBOL_REF rtx)\n+   (emitting the queue unless NO_QUEUE is nonzero),\n+   for a value of mode OUTMODE,\n+   with NARGS different arguments, passed as alternating rtx values\n+   and machine_modes to convert them to.\n+   The rtx values should have been passed through protect_from_queue already.\n+\n+   NO_QUEUE will be true if and only if the library call is a `const' call\n+   which will be enclosed in REG_LIBCALL/REG_RETVAL notes; it is equivalent\n+   to the variable is_const in expand_call.\n+\n+   NO_QUEUE must be true for const calls, because if it isn't, then\n+   any pending increment will be emitted between REG_LIBCALL/REG_RETVAL notes,\n+   and will be lost if the libcall sequence is optimized away.\n+\n+   NO_QUEUE must be false for non-const calls, because if it isn't, the\n+   call insn will have its CONST_CALL_P bit set, and it will be incorrectly\n+   optimized.  For instance, the instruction scheduler may incorrectly\n+   move memory references across the non-const call.  */\n+\n+void\n+emit_library_call (va_alist)\n+     va_dcl\n+{\n+  va_list p;\n+  /* Total size in bytes of all the stack-parms scanned so far.  */\n+  struct args_size args_size;\n+  /* Size of arguments before any adjustments (such as rounding).  */\n+  struct args_size original_args_size;\n+  register int argnum;\n+  enum machine_mode outmode;\n+  int nargs;\n+  rtx fun;\n+  rtx orgfun;\n+  int inc;\n+  int count;\n+  rtx argblock = 0;\n+  CUMULATIVE_ARGS args_so_far;\n+  struct arg { rtx value; enum machine_mode mode; rtx reg; int partial;\n+\t       struct args_size offset; struct args_size size; };\n+  struct arg *argvec;\n+  int old_inhibit_defer_pop = inhibit_defer_pop;\n+  int no_queue = 0;\n+  rtx use_insns;\n+\n+  va_start (p);\n+  orgfun = fun = va_arg (p, rtx);\n+  no_queue = va_arg (p, int);\n+  outmode = va_arg (p, enum machine_mode);\n+  nargs = va_arg (p, int);\n+\n+  /* Copy all the libcall-arguments out of the varargs data\n+     and into a vector ARGVEC.\n+\n+     Compute how to pass each argument.  We only support a very small subset\n+     of the full argument passing conventions to limit complexity here since\n+     library functions shouldn't have many args.  */\n+\n+  argvec = (struct arg *) alloca (nargs * sizeof (struct arg));\n+\n+  INIT_CUMULATIVE_ARGS (args_so_far, NULL_TREE, fun);\n+\n+  args_size.constant = 0;\n+  args_size.var = 0;\n+\n+  for (count = 0; count < nargs; count++)\n+    {\n+      rtx val = va_arg (p, rtx);\n+      enum machine_mode mode = va_arg (p, enum machine_mode);\n+\n+      /* We cannot convert the arg value to the mode the library wants here;\n+\t must do it earlier where we know the signedness of the arg.  */\n+      if (mode == BLKmode\n+\t  || (GET_MODE (val) != mode && GET_MODE (val) != VOIDmode))\n+\tabort ();\n+\n+      /* On some machines, there's no way to pass a float to a library fcn.\n+\t Pass it as a double instead.  */\n+#ifdef LIBGCC_NEEDS_DOUBLE\n+      if (LIBGCC_NEEDS_DOUBLE && mode == SFmode)\n+\tval = convert_to_mode (DFmode, val, 0), mode = DFmode;\n+#endif\n+\n+      /* There's no need to call protect_from_queue, because\n+\t either emit_move_insn or emit_push_insn will do that.  */\n+\n+      /* Make sure it is a reasonable operand for a move or push insn.  */\n+      if (GET_CODE (val) != REG && GET_CODE (val) != MEM\n+\t  && ! (CONSTANT_P (val) && LEGITIMATE_CONSTANT_P (val)))\n+\tval = force_operand (val, NULL_RTX);\n+\n+      argvec[count].value = val;\n+      argvec[count].mode = mode;\n+\n+#ifdef FUNCTION_ARG_PASS_BY_REFERENCE\n+      if (FUNCTION_ARG_PASS_BY_REFERENCE (args_so_far, mode, NULL_TREE, 1))\n+\tabort ();\n+#endif\n+\n+      argvec[count].reg = FUNCTION_ARG (args_so_far, mode, NULL_TREE, 1);\n+      if (argvec[count].reg && GET_CODE (argvec[count].reg) == EXPR_LIST)\n+\tabort ();\n+#ifdef FUNCTION_ARG_PARTIAL_NREGS\n+      argvec[count].partial\n+\t= FUNCTION_ARG_PARTIAL_NREGS (args_so_far, mode, NULL_TREE, 1);\n+#else\n+      argvec[count].partial = 0;\n+#endif\n+\n+      locate_and_pad_parm (mode, NULL_TREE,\n+\t\t\t   argvec[count].reg && argvec[count].partial == 0,\n+\t\t\t   NULL_TREE, &args_size, &argvec[count].offset,\n+\t\t\t   &argvec[count].size);\n+\n+      if (argvec[count].size.var)\n+\tabort ();\n+\n+#ifndef REG_PARM_STACK_SPACE\n+      if (argvec[count].partial)\n+\targvec[count].size.constant -= argvec[count].partial * UNITS_PER_WORD;\n+#endif\n+\n+      if (argvec[count].reg == 0 || argvec[count].partial != 0\n+#ifdef REG_PARM_STACK_SPACE\n+\t  || 1\n+#endif\n+\t  )\n+\targs_size.constant += argvec[count].size.constant;\n+\n+#ifdef ACCUMULATE_OUTGOING_ARGS\n+      /* If this arg is actually passed on the stack, it might be\n+\t clobbering something we already put there (this library call might\n+\t be inside the evaluation of an argument to a function whose call\n+\t requires the stack).  This will only occur when the library call\n+\t has sufficient args to run out of argument registers.  Abort in\n+\t this case; if this ever occurs, code must be added to save and\n+\t restore the arg slot.  */\n+\n+      if (argvec[count].reg == 0 || argvec[count].partial != 0)\n+\tabort ();\n+#endif\n+\n+      FUNCTION_ARG_ADVANCE (args_so_far, mode, (tree)0, 1);\n+    }\n+  va_end (p);\n+\n+  /* If this machine requires an external definition for library\n+     functions, write one out.  */\n+  assemble_external_libcall (fun);\n+\n+  original_args_size = args_size;\n+#ifdef STACK_BOUNDARY\n+  args_size.constant = (((args_size.constant + (STACK_BYTES - 1))\n+\t\t\t / STACK_BYTES) * STACK_BYTES);\n+#endif\n+\n+#ifdef REG_PARM_STACK_SPACE\n+  args_size.constant = MAX (args_size.constant,\n+\t\t\t    REG_PARM_STACK_SPACE (NULL_TREE));\n+#ifndef OUTGOING_REG_PARM_STACK_SPACE\n+  args_size.constant -= REG_PARM_STACK_SPACE (NULL_TREE);\n+#endif\n+#endif\n+\n+#ifdef ACCUMULATE_OUTGOING_ARGS\n+  if (args_size.constant > current_function_outgoing_args_size)\n+    current_function_outgoing_args_size = args_size.constant;\n+  args_size.constant = 0;\n+#endif\n+\n+#ifndef PUSH_ROUNDING\n+  argblock = push_block (GEN_INT (args_size.constant), 0, 0);\n+#endif\n+\n+#ifdef PUSH_ARGS_REVERSED\n+#ifdef STACK_BOUNDARY\n+  /* If we push args individually in reverse order, perform stack alignment\n+     before the first push (the last arg).  */\n+  if (argblock == 0)\n+    anti_adjust_stack (GEN_INT (args_size.constant\n+\t\t\t\t- original_args_size.constant));\n+#endif\n+#endif\n+\n+#ifdef PUSH_ARGS_REVERSED\n+  inc = -1;\n+  argnum = nargs - 1;\n+#else\n+  inc = 1;\n+  argnum = 0;\n+#endif\n+\n+  /* Push the args that need to be pushed.  */\n+\n+  for (count = 0; count < nargs; count++, argnum += inc)\n+    {\n+      register enum machine_mode mode = argvec[argnum].mode;\n+      register rtx val = argvec[argnum].value;\n+      rtx reg = argvec[argnum].reg;\n+      int partial = argvec[argnum].partial;\n+\n+      if (! (reg != 0 && partial == 0))\n+\temit_push_insn (val, mode, NULL_TREE, NULL_RTX, 0, partial, reg, 0,\n+\t\t\targblock, GEN_INT (argvec[count].offset.constant));\n+      NO_DEFER_POP;\n+    }\n+\n+#ifndef PUSH_ARGS_REVERSED\n+#ifdef STACK_BOUNDARY\n+  /* If we pushed args in forward order, perform stack alignment\n+     after pushing the last arg.  */\n+  if (argblock == 0)\n+    anti_adjust_stack (GEN_INT (args_size.constant\n+\t\t\t\t- original_args_size.constant));\n+#endif\n+#endif\n+\n+#ifdef PUSH_ARGS_REVERSED\n+  argnum = nargs - 1;\n+#else\n+  argnum = 0;\n+#endif\n+\n+  /* Now load any reg parms into their regs.  */\n+\n+  for (count = 0; count < nargs; count++, argnum += inc)\n+    {\n+      register enum machine_mode mode = argvec[argnum].mode;\n+      register rtx val = argvec[argnum].value;\n+      rtx reg = argvec[argnum].reg;\n+      int partial = argvec[argnum].partial;\n+\n+      if (reg != 0 && partial == 0)\n+\temit_move_insn (reg, val);\n+      NO_DEFER_POP;\n+    }\n+\n+  /* For version 1.37, try deleting this entirely.  */\n+  if (! no_queue)\n+    emit_queue ();\n+\n+  /* Any regs containing parms remain in use through the call.  */\n+  start_sequence ();\n+  for (count = 0; count < nargs; count++)\n+    if (argvec[count].reg != 0)\n+      emit_insn (gen_rtx (USE, VOIDmode, argvec[count].reg));\n+\n+  use_insns = get_insns ();\n+  end_sequence ();\n+\n+  fun = prepare_call_address (fun, NULL_TREE, &use_insns);\n+\n+  /* Don't allow popping to be deferred, since then\n+     cse'ing of library calls could delete a call and leave the pop.  */\n+  NO_DEFER_POP;\n+\n+  /* We pass the old value of inhibit_defer_pop + 1 to emit_call_1, which\n+     will set inhibit_defer_pop to that value.  */\n+\n+  emit_call_1 (fun, get_identifier (XSTR (orgfun, 0)), args_size.constant, 0,\n+\t       FUNCTION_ARG (args_so_far, VOIDmode, void_type_node, 1),\n+\t       outmode != VOIDmode ? hard_libcall_value (outmode) : NULL_RTX,\n+\t       old_inhibit_defer_pop + 1, use_insns, no_queue);\n+\n+  /* Now restore inhibit_defer_pop to its actual original value.  */\n+  OK_DEFER_POP;\n+}\n+\f\n+/* Like emit_library_call except that an extra argument, VALUE,\n+   comes second and says where to store the result.\n+   (If VALUE is zero, the result comes in the function value register.)  */\n+\n+void\n+emit_library_call_value (va_alist)\n+     va_dcl\n+{\n+  va_list p;\n+  /* Total size in bytes of all the stack-parms scanned so far.  */\n+  struct args_size args_size;\n+  /* Size of arguments before any adjustments (such as rounding).  */\n+  struct args_size original_args_size;\n+  register int argnum;\n+  enum machine_mode outmode;\n+  int nargs;\n+  rtx fun;\n+  rtx orgfun;\n+  int inc;\n+  int count;\n+  rtx argblock = 0;\n+  CUMULATIVE_ARGS args_so_far;\n+  struct arg { rtx value; enum machine_mode mode; rtx reg; int partial;\n+\t       struct args_size offset; struct args_size size; };\n+  struct arg *argvec;\n+  int old_inhibit_defer_pop = inhibit_defer_pop;\n+  int no_queue = 0;\n+  rtx use_insns;\n+  rtx value;\n+  rtx mem_value = 0;\n+\n+  va_start (p);\n+  orgfun = fun = va_arg (p, rtx);\n+  value = va_arg (p, rtx);\n+  no_queue = va_arg (p, int);\n+  outmode = va_arg (p, enum machine_mode);\n+  nargs = va_arg (p, int);\n+\n+  /* If this kind of value comes back in memory,\n+     decide where in memory it should come back.  */\n+  if (RETURN_IN_MEMORY (type_for_mode (outmode, 0)))\n+    {\n+      if (GET_CODE (value) == MEM)\n+\tmem_value = value;\n+      else\n+\tmem_value = assign_stack_temp (outmode, GET_MODE_SIZE (outmode), 0);\n+    }\n+\n+  /* ??? Unfinished: must pass the memory address as an argument.  */\n+\n+  /* Copy all the libcall-arguments out of the varargs data\n+     and into a vector ARGVEC.\n+\n+     Compute how to pass each argument.  We only support a very small subset\n+     of the full argument passing conventions to limit complexity here since\n+     library functions shouldn't have many args.  */\n+\n+  argvec = (struct arg *) alloca ((nargs + 1) * sizeof (struct arg));\n+\n+  INIT_CUMULATIVE_ARGS (args_so_far, NULL_TREE, fun);\n+\n+  args_size.constant = 0;\n+  args_size.var = 0;\n+\n+  count = 0;\n+\n+  /* If there's a structure value address to be passed,\n+     either pass it in the special place, or pass it as an extra argument.  */\n+  if (mem_value)\n+    {\n+      rtx addr = XEXP (mem_value, 0);\n+\n+      if (! struct_value_rtx)\n+\t{\n+\t  nargs++;\n+\n+\t  /* Make sure it is a reasonable operand for a move or push insn.  */\n+\t  if (GET_CODE (addr) != REG && GET_CODE (addr) != MEM\n+\t      && ! (CONSTANT_P (addr) && LEGITIMATE_CONSTANT_P (addr)))\n+\t    addr = force_operand (addr, NULL_RTX);\n+\n+\t  argvec[count].value = addr;\n+\t  argvec[count].mode = outmode;\n+\t  argvec[count].partial = 0;\n+\n+\t  argvec[count].reg = FUNCTION_ARG (args_so_far, outmode, NULL_TREE, 1);\n+#ifdef FUNCTION_ARG_PARTIAL_NREGS\n+\t  if (FUNCTION_ARG_PARTIAL_NREGS (args_so_far, outmode, NULL_TREE, 1))\n+\t    abort ();\n+#endif\n+\n+\t  locate_and_pad_parm (outmode, NULL_TREE,\n+\t\t\t       argvec[count].reg && argvec[count].partial == 0,\n+\t\t\t       NULL_TREE, &args_size, &argvec[count].offset,\n+\t\t\t       &argvec[count].size);\n+\n+\n+\t  if (argvec[count].reg == 0 || argvec[count].partial != 0\n+#ifdef REG_PARM_STACK_SPACE\n+\t      || 1\n+#endif\n+\t      )\n+\t    args_size.constant += argvec[count].size.constant;\n+\n+\t  FUNCTION_ARG_ADVANCE (args_so_far, outmode, (tree)0, 1);\n+\t}\n+    }\n+\n+  for (; count < nargs; count++)\n+    {\n+      rtx val = va_arg (p, rtx);\n+      enum machine_mode mode = va_arg (p, enum machine_mode);\n+\n+      /* We cannot convert the arg value to the mode the library wants here;\n+\t must do it earlier where we know the signedness of the arg.  */\n+      if (mode == BLKmode\n+\t  || (GET_MODE (val) != mode && GET_MODE (val) != VOIDmode))\n+\tabort ();\n+\n+      /* On some machines, there's no way to pass a float to a library fcn.\n+\t Pass it as a double instead.  */\n+#ifdef LIBGCC_NEEDS_DOUBLE\n+      if (LIBGCC_NEEDS_DOUBLE && mode == SFmode)\n+\tval = convert_to_mode (DFmode, val, 0), mode = DFmode;\n+#endif\n+\n+      /* There's no need to call protect_from_queue, because\n+\t either emit_move_insn or emit_push_insn will do that.  */\n+\n+      /* Make sure it is a reasonable operand for a move or push insn.  */\n+      if (GET_CODE (val) != REG && GET_CODE (val) != MEM\n+\t  && ! (CONSTANT_P (val) && LEGITIMATE_CONSTANT_P (val)))\n+\tval = force_operand (val, NULL_RTX);\n+\n+      argvec[count].value = val;\n+      argvec[count].mode = mode;\n+\n+#ifdef FUNCTION_ARG_PASS_BY_REFERENCE\n+      if (FUNCTION_ARG_PASS_BY_REFERENCE (args_so_far, mode, NULL_TREE, 1))\n+\tabort ();\n+#endif\n+\n+      argvec[count].reg = FUNCTION_ARG (args_so_far, mode, NULL_TREE, 1);\n+      if (argvec[count].reg && GET_CODE (argvec[count].reg) == EXPR_LIST)\n+\tabort ();\n+#ifdef FUNCTION_ARG_PARTIAL_NREGS\n+      argvec[count].partial\n+\t= FUNCTION_ARG_PARTIAL_NREGS (args_so_far, mode, NULL_TREE, 1);\n+#else\n+      argvec[count].partial = 0;\n+#endif\n+\n+      locate_and_pad_parm (mode, NULL_TREE,\n+\t\t\t   argvec[count].reg && argvec[count].partial == 0,\n+\t\t\t   NULL_TREE, &args_size, &argvec[count].offset,\n+\t\t\t   &argvec[count].size);\n+\n+      if (argvec[count].size.var)\n+\tabort ();\n+\n+#ifndef REG_PARM_STACK_SPACE\n+      if (argvec[count].partial)\n+\targvec[count].size.constant -= argvec[count].partial * UNITS_PER_WORD;\n+#endif\n+\n+      if (argvec[count].reg == 0 || argvec[count].partial != 0\n+#ifdef REG_PARM_STACK_SPACE\n+\t  || 1\n+#endif\n+\t  )\n+\targs_size.constant += argvec[count].size.constant;\n+\n+#ifdef ACCUMULATE_OUTGOING_ARGS\n+      /* If this arg is actually passed on the stack, it might be\n+\t clobbering something we already put there (this library call might\n+\t be inside the evaluation of an argument to a function whose call\n+\t requires the stack).  This will only occur when the library call\n+\t has sufficient args to run out of argument registers.  Abort in\n+\t this case; if this ever occurs, code must be added to save and\n+\t restore the arg slot.  */\n+\n+      if (argvec[count].reg == 0 || argvec[count].partial != 0)\n+\tabort ();\n+#endif\n+\n+      FUNCTION_ARG_ADVANCE (args_so_far, mode, (tree)0, 1);\n+    }\n+  va_end (p);\n+\n+  /* If this machine requires an external definition for library\n+     functions, write one out.  */\n+  assemble_external_libcall (fun);\n+\n+  original_args_size = args_size;\n+#ifdef STACK_BOUNDARY\n+  args_size.constant = (((args_size.constant + (STACK_BYTES - 1))\n+\t\t\t / STACK_BYTES) * STACK_BYTES);\n+#endif\n+\n+#ifdef REG_PARM_STACK_SPACE\n+  args_size.constant = MAX (args_size.constant,\n+\t\t\t    REG_PARM_STACK_SPACE (NULL_TREE));\n+#ifndef OUTGOING_REG_PARM_STACK_SPACE\n+  args_size.constant -= REG_PARM_STACK_SPACE (NULL_TREE);\n+#endif\n+#endif\n+\n+#ifdef ACCUMULATE_OUTGOING_ARGS\n+  if (args_size.constant > current_function_outgoing_args_size)\n+    current_function_outgoing_args_size = args_size.constant;\n+  args_size.constant = 0;\n+#endif\n+\n+#ifndef PUSH_ROUNDING\n+  argblock = push_block (GEN_INT (args_size.constant), 0, 0);\n+#endif\n+\n+#ifdef PUSH_ARGS_REVERSED\n+#ifdef STACK_BOUNDARY\n+  /* If we push args individually in reverse order, perform stack alignment\n+     before the first push (the last arg).  */\n+  if (argblock == 0)\n+    anti_adjust_stack (GEN_INT (args_size.constant\n+\t\t\t\t- original_args_size.constant));\n+#endif\n+#endif\n+\n+#ifdef PUSH_ARGS_REVERSED\n+  inc = -1;\n+  argnum = nargs - 1;\n+#else\n+  inc = 1;\n+  argnum = 0;\n+#endif\n+\n+  /* Push the args that need to be pushed.  */\n+\n+  for (count = 0; count < nargs; count++, argnum += inc)\n+    {\n+      register enum machine_mode mode = argvec[argnum].mode;\n+      register rtx val = argvec[argnum].value;\n+      rtx reg = argvec[argnum].reg;\n+      int partial = argvec[argnum].partial;\n+\n+      if (! (reg != 0 && partial == 0))\n+\temit_push_insn (val, mode, NULL_TREE, NULL_RTX, 0, partial, reg, 0,\n+\t\t\targblock, GEN_INT (argvec[count].offset.constant));\n+      NO_DEFER_POP;\n+    }\n+\n+#ifndef PUSH_ARGS_REVERSED\n+#ifdef STACK_BOUNDARY\n+  /* If we pushed args in forward order, perform stack alignment\n+     after pushing the last arg.  */\n+  if (argblock == 0)\n+    anti_adjust_stack (GEN_INT (args_size.constant\n+\t\t\t\t- original_args_size.constant));\n+#endif\n+#endif\n+\n+#ifdef PUSH_ARGS_REVERSED\n+  argnum = nargs - 1;\n+#else\n+  argnum = 0;\n+#endif\n+\n+  /* Now load any reg parms into their regs.  */\n+\n+  if (mem_value != 0 && struct_value_rtx != 0)\n+    emit_move_insn (struct_value_rtx, XEXP (mem_value, 0));\n+\n+  for (count = 0; count < nargs; count++, argnum += inc)\n+    {\n+      register enum machine_mode mode = argvec[argnum].mode;\n+      register rtx val = argvec[argnum].value;\n+      rtx reg = argvec[argnum].reg;\n+      int partial = argvec[argnum].partial;\n+\n+      if (reg != 0 && partial == 0)\n+\temit_move_insn (reg, val);\n+      NO_DEFER_POP;\n+    }\n+\n+#if 0\n+  /* For version 1.37, try deleting this entirely.  */\n+  if (! no_queue)\n+    emit_queue ();\n+#endif\n+\n+  /* Any regs containing parms remain in use through the call.  */\n+  start_sequence ();\n+  for (count = 0; count < nargs; count++)\n+    if (argvec[count].reg != 0)\n+      emit_insn (gen_rtx (USE, VOIDmode, argvec[count].reg));\n+\n+  use_insns = get_insns ();\n+  end_sequence ();\n+\n+  fun = prepare_call_address (fun, NULL_TREE, &use_insns);\n+\n+  /* Don't allow popping to be deferred, since then\n+     cse'ing of library calls could delete a call and leave the pop.  */\n+  NO_DEFER_POP;\n+\n+  /* We pass the old value of inhibit_defer_pop + 1 to emit_call_1, which\n+     will set inhibit_defer_pop to that value.  */\n+\n+  emit_call_1 (fun, get_identifier (XSTR (orgfun, 0)), args_size.constant, 0,\n+\t       FUNCTION_ARG (args_so_far, VOIDmode, void_type_node, 1),\n+\t       outmode != VOIDmode ? hard_libcall_value (outmode) : NULL_RTX,\n+\t       old_inhibit_defer_pop + 1, use_insns, no_queue);\n+\n+  /* Now restore inhibit_defer_pop to its actual original value.  */\n+  OK_DEFER_POP;\n+\n+  /* Copy the value to the right place.  */\n+  if (outmode != VOIDmode)\n+    {\n+      if (mem_value)\n+\t{\n+\t  if (value == 0)\n+\t    value = hard_libcall_value (outmode);\n+\t  if (value != mem_value)\n+\t    emit_move_insn (value, mem_value);\n+\t}\n+      else if (value != 0)\n+\temit_move_insn (value, hard_libcall_value (outmode));\n+    }\n+}\n+\f\n #if 0\n /* Return an rtx which represents a suitable home on the stack\n    given TYPE, the type of the argument looking for a home."}]}