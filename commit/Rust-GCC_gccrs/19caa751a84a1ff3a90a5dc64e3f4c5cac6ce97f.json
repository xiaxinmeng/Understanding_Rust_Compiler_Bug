{"sha": "19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MTljYWE3NTFhODRhMWZmM2E5MGE1ZGM2NGUzZjRjNWNhYzZjZTk3Zg==", "commit": {"author": {"name": "Richard Kenner", "email": "kenner@vlsi1.ultra.nyu.edu", "date": "2000-03-30T11:47:08Z"}, "committer": {"name": "Richard Kenner", "email": "kenner@gcc.gnu.org", "date": "2000-03-30T11:47:08Z"}, "message": "builtins.c (get_pointer_alignment): Use host_integerp & tree_low_cst.\n\n\t* builtins.c (get_pointer_alignment): Use host_integerp & tree_low_cst.\n\t(expand_builtin_apply): Pass alignment to emit_block_move in bits.\n\t(expand_builtin_memcpy, expand_builtin_va_copy): Likewise.\n\t(expand_builtin_memset): Likewise, but to clear_storage.\n\t* calls.c (save_fixed_argument_area): Likewise, to move_by_pieces.\n\t(restore_fixed_argument_area): Likewise.\n\t(store_unaligned_arguments_into_pseudos): Likewise, to store_bit_field.\n\t(load_register_parameters): Likewise, to emit_group_load.\n\t(expand_call): Likewise, to emit_group_store and emit_block_move.\n\t(emit_library_call_value_1): Likewise, to emit_block_move.\n\t(store_one_arg): Likewise, and to emit_push_insn.\n\t* expmed.c (extract_bit_field): Alignment is in bits, not bytes.\n\t(extract_fixed_bit_field, extract_split_bit_field): Likewise.\n\t* expr.c (move_by_pieces, move_by_pieces_ninsns): Likewise.\n\t(emit_block_move, emit_group_load, emit_group_store): Likewise.\n\t(clear_by_pieces, clear_storage, emit_push_insn): Likewise.\n\t(expand_assigment, store_expr, store_constructor_field): Likewise.\n\t(expand_expr_unaligned, do_jump, do_compare_and_jump): Likewise.\n\t(store_constructor, store_field, get_inner_reference): Likewise.\n\tUse host_integerp and tree_low_cst; sizes and positions HOST_WIDE_INT.\n\t(expand_expr, case COMPONENT_REF): Likewise.\n\t(copy_blkmode_from_regs): Use UNSIGNED_HOST_WIDE_INT for sizes\n\tand positions; reindent code.\n\t* expr.h (emit_cmp_insn, emit_cmp_and_jump_insns): Alignment unsigned.\n\t* function.c (purge_addressof_1): Pass bit align to store_bit_field.\n\t(assign_parms): Likewise to emit_group_store.\n\t* optbas.c (prepare_cmp_insn): Alignment is in bits.\n\t(emit_cmp_and_jump_insns, emit_cmp_insn): Likewise, and also unsigned.\n\t* stmt.c (expand_value_return): Pass align in bits to emit_group_load.\n\t(expand_return): Likewise to {extract,store}_bit_field.\n\t* stor-layout.c (get_mode_alignment): Minor cleanup.\n\t* config/rs6000/rs6000.h (SLOW_UNALIGNED_ACCESS): Align is in bits.\n\t* config/sh/sh.h (MOVE_BY_PIECES_P): Likewise.\n\t* ch/expr.c (chill_expand_expr): Pass bit alignment to emit_block_move.\n\nFrom-SVN: r32827", "tree": {"sha": "329b51ffb0413c60bc6cbeaca6487042e3b6592d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/329b51ffb0413c60bc6cbeaca6487042e3b6592d"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/comments", "author": null, "committer": null, "parents": [{"sha": "2dc4d9f050c5d46500c925725a5f18303dd882c1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2dc4d9f050c5d46500c925725a5f18303dd882c1", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2dc4d9f050c5d46500c925725a5f18303dd882c1"}], "stats": {"total": 576, "additions": 291, "deletions": 285}, "files": [{"sha": "5c67ec0e38cdf0ca0f02326a7c3c1550736f39d9", "filename": "gcc/ChangeLog", "status": "modified", "additions": 36, "deletions": 0, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "patch": "@@ -1,3 +1,39 @@\n+Thu Mar 30 06:32:51 2000  Richard Kenner  <kenner@vlsi1.ultra.nyu.edu>\n+\n+\t* builtins.c (get_pointer_alignment): Use host_integerp & tree_low_cst.\n+\t(expand_builtin_apply): Pass alignment to emit_block_move in bits.\n+\t(expand_builtin_memcpy, expand_builtin_va_copy): Likewise.\n+\t(expand_builtin_memset): Likewise, but to clear_storage.\n+\t* calls.c (save_fixed_argument_area): Likewise, to move_by_pieces.\n+\t(restore_fixed_argument_area): Likewise.\n+\t(store_unaligned_arguments_into_pseudos): Likewise, to store_bit_field.\n+\t(load_register_parameters): Likewise, to emit_group_load.\n+\t(expand_call): Likewise, to emit_group_store and emit_block_move.\n+\t(emit_library_call_value_1): Likewise, to emit_block_move.\n+\t(store_one_arg): Likewise, and to emit_push_insn.\n+\t* expmed.c (extract_bit_field): Alignment is in bits, not bytes.\n+\t(extract_fixed_bit_field, extract_split_bit_field): Likewise.\n+\t* expr.c (move_by_pieces, move_by_pieces_ninsns): Likewise.\n+\t(emit_block_move, emit_group_load, emit_group_store): Likewise.\n+\t(clear_by_pieces, clear_storage, emit_push_insn): Likewise.\n+\t(expand_assigment, store_expr, store_constructor_field): Likewise.\n+\t(expand_expr_unaligned, do_jump, do_compare_and_jump): Likewise.\n+\t(store_constructor, store_field, get_inner_reference): Likewise.\n+\tUse host_integerp and tree_low_cst; sizes and positions HOST_WIDE_INT.\n+\t(expand_expr, case COMPONENT_REF): Likewise.\n+\t(copy_blkmode_from_regs): Use UNSIGNED_HOST_WIDE_INT for sizes\n+\tand positions; reindent code.\n+\t* expr.h (emit_cmp_insn, emit_cmp_and_jump_insns): Alignment unsigned.\n+\t* function.c (purge_addressof_1): Pass bit align to store_bit_field.\n+\t(assign_parms): Likewise to emit_group_store.\n+\t* optbas.c (prepare_cmp_insn): Alignment is in bits.\n+\t(emit_cmp_and_jump_insns, emit_cmp_insn): Likewise, and also unsigned.\n+\t* stmt.c (expand_value_return): Pass align in bits to emit_group_load.\n+\t(expand_return): Likewise to {extract,store}_bit_field.\n+\t* stor-layout.c (get_mode_alignment): Minor cleanup.\n+\t* config/rs6000/rs6000.h (SLOW_UNALIGNED_ACCESS): Align is in bits.\n+\t* config/sh/sh.h (MOVE_BY_PIECES_P): Likewise.\n+\t\n 2000-03-29  Zack Weinberg  <zack@wolery.cumb.org>\n \n \t* cppinit.c (cpp_start_read): Call initialize_dependency_output"}, {"sha": "63b17f702563bd0f7a37d056166846aefe829264", "filename": "gcc/builtins.c", "status": "modified", "additions": 9, "deletions": 12, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fbuiltins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fbuiltins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.c?ref=19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "patch": "@@ -135,6 +135,7 @@ get_pointer_alignment (exp, max_align)\n \t  exp = TREE_OPERAND (exp, 0);\n \t  if (TREE_CODE (TREE_TYPE (exp)) != POINTER_TYPE)\n \t    return align;\n+\n \t  inner = TYPE_ALIGN (TREE_TYPE (TREE_TYPE (exp)));\n \t  align = MIN (inner, max_align);\n \t  break;\n@@ -143,10 +144,10 @@ get_pointer_alignment (exp, max_align)\n \t  /* If sum of pointer + int, restrict our maximum alignment to that\n \t     imposed by the integer.  If not, we can't do any better than\n \t     ALIGN.  */\n-\t  if (TREE_CODE (TREE_OPERAND (exp, 1)) != INTEGER_CST)\n+\t  if (! host_integerp (TREE_OPERAND (exp, 1), 1))\n \t    return align;\n \n-\t  while (((TREE_INT_CST_LOW (TREE_OPERAND (exp, 1)) * BITS_PER_UNIT)\n+\t  while (((tree_low_cst (TREE_OPERAND (exp, 1), 1) * BITS_PER_UNIT)\n \t\t  & (max_align - 1))\n \t\t != 0)\n \t    max_align >>= 1;\n@@ -903,8 +904,7 @@ expand_builtin_apply (function, arguments, argsize)\n   dest = allocate_dynamic_stack_space (argsize, 0, 0);\n   emit_block_move (gen_rtx_MEM (BLKmode, dest),\n \t\t   gen_rtx_MEM (BLKmode, incoming_args),\n-\t\t   argsize,\n-\t\t   PARM_BOUNDARY / BITS_PER_UNIT);\n+\t\t   argsize, PARM_BOUNDARY);\n \n   /* Refer to the argument block.  */\n   apply_args_size ();\n@@ -1435,10 +1435,8 @@ expand_builtin_memcpy (arglist)\n       tree src = TREE_VALUE (TREE_CHAIN (arglist));\n       tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));\n \n-      int src_align\n-\t= get_pointer_alignment (src, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;\n-      int dest_align\n-\t= get_pointer_alignment (dest, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;\n+      int src_align = get_pointer_alignment (src, BIGGEST_ALIGNMENT);\n+      int dest_align = get_pointer_alignment (dest, BIGGEST_ALIGNMENT);\n       rtx dest_mem, src_mem, dest_addr, len_rtx;\n \n       /* If either SRC or DEST is not a pointer type, don't do\n@@ -1531,8 +1529,7 @@ expand_builtin_memset (exp)\n       tree val = TREE_VALUE (TREE_CHAIN (arglist));\n       tree len = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));\n \n-      int dest_align\n-\t= get_pointer_alignment (dest, BIGGEST_ALIGNMENT) / BITS_PER_UNIT;\n+      int dest_align = get_pointer_alignment (dest, BIGGEST_ALIGNMENT);\n       rtx dest_mem, dest_addr, len_rtx;\n \n       /* If DEST is not a pointer type, don't do this \n@@ -1918,6 +1915,7 @@ stabilize_va_list (valist, needs_lvalue)\n \t{\n  \t  tree p1 = build_pointer_type (TREE_TYPE (va_list_type_node));\n  \t  tree p2 = build_pointer_type (va_list_type_node);\n+\n  \t  valist = build1 (ADDR_EXPR, p2, valist);\n \t  valist = fold (build1 (NOP_EXPR, p1, valist));\n \t}\n@@ -2190,8 +2188,7 @@ expand_builtin_va_copy (arglist)\n       MEM_ALIAS_SET (srcb) = get_alias_set (TREE_TYPE (TREE_TYPE (src)));\n \n       /* Copy.  */\n-      emit_block_move (dstb, srcb, size, \n-\t\t       TYPE_ALIGN (va_list_type_node) / BITS_PER_UNIT);\n+      emit_block_move (dstb, srcb, size, TYPE_ALIGN (va_list_type_node));\n     }\n \n   return const0_rtx;"}, {"sha": "646f4b947f09d62e8474821de4e48666a28e7e4b", "filename": "gcc/calls.c", "status": "modified", "additions": 20, "deletions": 25, "changes": 45, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fcalls.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fcalls.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcalls.c?ref=19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "patch": "@@ -856,11 +856,11 @@ save_fixed_argument_area (reg_parm_stack_space, argblock,\n       if (save_mode == BLKmode)\n \t{\n \t  save_area = assign_stack_temp (BLKmode, num_to_save, 0);\n-\t  /* Cannot use emit_block_move here because it can be done by a library\n-\t     call which in turn gets into this place again and deadly infinite\n-\t     recursion happens.  */\n+\t  /* Cannot use emit_block_move here because it can be done by a\n+\t     library call which in turn gets into this place again and deadly\n+\t     infinite recursion happens.  */\n \t  move_by_pieces (validize_mem (save_area), stack_area, num_to_save,\n-\t\t\t  PARM_BOUNDARY / BITS_PER_UNIT);\n+\t\t\t  PARM_BOUNDARY);\n \t}\n       else\n \t{\n@@ -900,8 +900,7 @@ restore_fixed_argument_area (save_area, argblock, high_to_save, low_to_save)\n        call which in turn gets into this place again and deadly infinite\n        recursion happens.  */\n     move_by_pieces (stack_area, validize_mem (save_area),\n-\t\t    high_to_save - low_to_save + 1,\n-\t\t    PARM_BOUNDARY / BITS_PER_UNIT);\n+\t\t    high_to_save - low_to_save + 1, PARM_BOUNDARY);\n }\n #endif\n \t  \n@@ -968,12 +967,10 @@ store_unaligned_arguments_into_pseudos (args, num_actuals)\n \n \t    bytes -= bitsize / BITS_PER_UNIT;\n \t    store_bit_field (reg, bitsize, big_endian_correction, word_mode,\n-\t\t\t     extract_bit_field (word, bitsize, 0, 1,\n-\t\t\t\t\t\tNULL_RTX, word_mode,\n-\t\t\t\t\t\tword_mode,\n-\t\t\t\t\t\tbitalign / BITS_PER_UNIT,\n+\t\t\t     extract_bit_field (word, bitsize, 0, 1, NULL_RTX,\n+\t\t\t\t\t\tword_mode, word_mode, bitalign,\n \t\t\t\t\t\tBITS_PER_WORD),\n-\t\t\t     bitalign / BITS_PER_UNIT, BITS_PER_WORD);\n+\t\t\t     bitalign, BITS_PER_WORD);\n \t  }\n       }\n }\n@@ -1656,12 +1653,9 @@ load_register_parameters (args, num_actuals, call_fusage)\n \t     locations.  The Irix 6 ABI has examples of this.  */\n \n \t  if (GET_CODE (reg) == PARALLEL)\n-\t    {\n-\t      emit_group_load (reg, args[i].value,\n-\t\t\t       int_size_in_bytes (TREE_TYPE (args[i].tree_value)),\n-\t\t\t       (TYPE_ALIGN (TREE_TYPE (args[i].tree_value))\n-\t\t\t\t/ BITS_PER_UNIT));\n-\t    }\n+\t    emit_group_load (reg, args[i].value,\n+\t\t\t     int_size_in_bytes (TREE_TYPE (args[i].tree_value)),\n+\t\t\t     TYPE_ALIGN (TREE_TYPE (args[i].tree_value)));\n \n \t  /* If simple case, just do move.  If normal partial, store_one_arg\n \t     has already loaded the register for us.  In all other cases,\n@@ -2911,7 +2905,8 @@ expand_call (exp, target, ignore)\n \n \t  if (! rtx_equal_p (target, valreg))\n \t    emit_group_store (target, valreg, bytes,\n-\t\t\t      TYPE_ALIGN (TREE_TYPE (exp)) / BITS_PER_UNIT);\n+\t\t\t      TYPE_ALIGN (TREE_TYPE (exp)));\n+\n \t  /* We can not support sibling calls for this case.  */\n \t  sibcall_failure = 1;\n \t}\n@@ -2992,7 +2987,7 @@ expand_call (exp, target, ignore)\n \t\t  emit_block_move (stack_area,\n \t\t\t\t   validize_mem (args[i].save_area),\n \t\t\t\t   GEN_INT (args[i].size.constant),\n-\t\t\t\t   PARM_BOUNDARY / BITS_PER_UNIT);\n+\t\t\t\t   PARM_BOUNDARY);\n \t\tsibcall_failure = 1;\n \t      }\n \n@@ -3474,8 +3469,7 @@ emit_library_call_value_1 (retval, orgfun, value, no_queue, outmode, nargs, p)\n \t    {\n \t      save_area = assign_stack_temp (BLKmode, num_to_save, 0);\n \t      emit_block_move (validize_mem (save_area), stack_area,\n-\t\t\t       GEN_INT (num_to_save),\n-\t\t\t       PARM_BOUNDARY / BITS_PER_UNIT);\n+\t\t\t       GEN_INT (num_to_save), PARM_BOUNDARY);\n \t    }\n \t  else\n \t    {\n@@ -3540,6 +3534,7 @@ emit_library_call_value_1 (retval, orgfun, value, no_queue, outmode, nargs, p)\n \t\t  emit_move_insn (argvec[argnum].save_area, stack_area);\n \t\t}\n \t    }\n+\n \t  emit_push_insn (val, mode, NULL_TREE, NULL_RTX, 0, partial, reg, 0,\n \t\t\t  argblock, GEN_INT (argvec[argnum].offset.constant),\n \t\t\t  reg_parm_stack_space, ARGS_SIZE_RTX (alignment_pad));\n@@ -3684,7 +3679,7 @@ emit_library_call_value_1 (retval, orgfun, value, no_queue, outmode, nargs, p)\n \t  else\n \t    emit_block_move (stack_area, validize_mem (save_area),\n \t\t\t     GEN_INT (high_to_save - low_to_save + 1),\n-\t\t\t\t PARM_BOUNDARY / BITS_PER_UNIT);\n+\t\t\t     PARM_BOUNDARY);\n \t}\n #endif\n \t      \n@@ -3922,7 +3917,7 @@ store_one_arg (arg, argblock, may_be_alloca, variable_size,\n \t\t  preserve_temp_slots (arg->save_area);\n \t\t  emit_block_move (validize_mem (arg->save_area), stack_area,\n \t\t\t\t   GEN_INT (arg->size.constant),\n-\t\t\t\t   PARM_BOUNDARY / BITS_PER_UNIT);\n+\t\t\t\t   PARM_BOUNDARY);\n \t\t}\n \t      else\n \t\t{\n@@ -4084,8 +4079,8 @@ store_one_arg (arg, argblock, may_be_alloca, variable_size,\n \t}\n \n       emit_push_insn (arg->value, arg->mode, TREE_TYPE (pval), size_rtx,\n-\t\t      TYPE_ALIGN (TREE_TYPE (pval)) / BITS_PER_UNIT, partial,\n-\t\t      reg, excess, argblock, ARGS_SIZE_RTX (arg->offset),\n+\t\t      TYPE_ALIGN (TREE_TYPE (pval)), partial, reg, excess,\n+\t\t      argblock, ARGS_SIZE_RTX (arg->offset),\n \t\t      reg_parm_stack_space,\n \t\t      ARGS_SIZE_RTX (arg->alignment_pad));\n     }"}, {"sha": "ac827171697cc7237d9213456011b2e661e339f0", "filename": "gcc/ch/ChangeLog", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fch%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fch%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fch%2FChangeLog?ref=19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "patch": "@@ -1,3 +1,7 @@\n+Thu Mar 30 06:32:51 2000  Richard Kenner  <kenner@vlsi1.ultra.nyu.edu>\n+\n+\t* expr.c (chill_expand_expr): Pass bit alignment to emit_block_move.\n+\n Sat Mar 25 09:12:10 2000  Richard Kenner  <kenner@vlsi1.ultra.nyu.edu>\n \n \t* actions.c (check_missing_cases): BYTES_NEEDED is HOST_WIDE_INT."}, {"sha": "40f74a42af0ceca19273f15690a67e2b458cdd82", "filename": "gcc/ch/expr.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fch%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fch%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fch%2Fexpr.c?ref=19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "patch": "@@ -362,7 +362,7 @@ chill_expand_expr (exp, target, tmode, modifier)\n \t\tif (temp == target || target == NULL_RTX)\n \t\t  return temp;\n \t\temit_block_move (target, temp, expr_size (exp0),\n-\t\t\t\t TYPE_ALIGN (TREE_TYPE(exp0)) / BITS_PER_UNIT);\n+\t\t\t\t TYPE_ALIGN (TREE_TYPE(exp0)));\n \t\treturn target;\n \t      }\n \t    else"}, {"sha": "11f96a381b65343cd3aa325ca26e942cb2112956", "filename": "gcc/config/rs6000/rs6000.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fconfig%2Frs6000%2Frs6000.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fconfig%2Frs6000%2Frs6000.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.h?ref=19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "patch": "@@ -618,7 +618,7 @@ extern int rs6000_debug_arg;\t\t/* debug argument handling */\n #define SLOW_UNALIGNED_ACCESS(MODE, ALIGN)\t\t\t\\\n    ((STRICT_ALIGNMENT\t\t\t\t\t\t\\\n      || (((MODE) == SFmode || (MODE) == DFmode || (MODE) == DImode) \\\n-         && (ALIGN) < 4)) ? 1 : 0)\n+         && (ALIGN) < 32)) ? 1 : 0)\n \f\n /* Standard register usage.  */\n "}, {"sha": "6ae0deb627727579ca03403e04636a89da9e9712", "filename": "gcc/config/sh/sh.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fconfig%2Fsh%2Fsh.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fconfig%2Fsh%2Fsh.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fsh.h?ref=19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "patch": "@@ -1183,7 +1183,7 @@ extern int current_function_anonymous_args;\n \n #define MOVE_BY_PIECES_P(SIZE, ALIGN)  (move_by_pieces_ninsns (SIZE, ALIGN) \\\n                                         < (TARGET_SMALLCODE ? 2 :           \\\n-                                           ((ALIGN >= 4) ? 16 : 2)))\n+                                           ((ALIGN >= 32) ? 16 : 2)))\n \n /* Macros to check register numbers against specific register classes.  */\n "}, {"sha": "07e9e827a8fc85a81faa334048c796e9438a8fdd", "filename": "gcc/expmed.c", "status": "modified", "additions": 14, "deletions": 17, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fexpmed.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fexpmed.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpmed.c?ref=19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "patch": "@@ -947,7 +947,7 @@ store_split_bit_field (op0, bitsize, bitpos, value, align)\n    TMODE is the mode the caller would like the value to have;\n    but the value may be returned with type MODE instead.\n \n-   ALIGN is the alignment that STR_RTX is known to have, measured in bytes.\n+   ALIGN is the alignment that STR_RTX is known to have.\n    TOTAL_SIZE is the size in bytes of the containing structure,\n    or -1 if varying.\n \n@@ -1068,7 +1068,7 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n        || (GET_CODE (op0) == MEM\n \t   && (! SLOW_UNALIGNED_ACCESS (mode, align)\n \t       || (offset * BITS_PER_UNIT % bitsize == 0\n-\t\t   && align * BITS_PER_UNIT % bitsize == 0))))\n+\t\t   && align % bitsize == 0))))\n       && ((bitsize >= BITS_PER_WORD && bitsize == GET_MODE_BITSIZE (mode)\n \t   && bitpos % BITS_PER_WORD == 0)\n \t  || (mode_for_size (bitsize, GET_MODE_CLASS (tmode), 0) != BLKmode\n@@ -1144,9 +1144,8 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \t  rtx result_part\n \t    = extract_bit_field (op0, MIN (BITS_PER_WORD,\n \t\t\t\t\t   bitsize - i * BITS_PER_WORD),\n-\t\t\t\t bitnum + bit_offset,\n-\t\t\t\t 1, target_part, mode, word_mode,\n-\t\t\t\t align, total_size);\n+\t\t\t\t bitnum + bit_offset, 1, target_part, mode,\n+\t\t\t\t word_mode, align, total_size);\n \n \t  if (target_part == 0)\n \t    abort ();\n@@ -1262,15 +1261,14 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \t\t  if (GET_MODE (xop0) == BLKmode\n \t\t      || (GET_MODE_SIZE (GET_MODE (op0))\n \t\t\t  > GET_MODE_SIZE (maxmode)))\n-\t\t    bestmode = get_best_mode (bitsize, bitnum,\n-\t\t\t\t\t      align * BITS_PER_UNIT, maxmode,\n+\t\t    bestmode = get_best_mode (bitsize, bitnum, align, maxmode,\n \t\t\t\t\t      MEM_VOLATILE_P (xop0));\n \t\t  else\n \t\t    bestmode = GET_MODE (xop0);\n \n \t\t  if (bestmode == VOIDmode\n \t\t      || (SLOW_UNALIGNED_ACCESS (bestmode, align)\n-\t\t\t  && GET_MODE_SIZE (bestmode) > align))\n+\t\t\t  && GET_MODE_BITSIZE (bestmode) > align))\n \t\t    goto extzv_loses;\n \n \t\t  /* Compute offset as multiple of this unit,\n@@ -1400,15 +1398,14 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n \t\t  if (GET_MODE (xop0) == BLKmode\n \t\t      || (GET_MODE_SIZE (GET_MODE (op0))\n \t\t\t  > GET_MODE_SIZE (maxmode)))\n-\t\t    bestmode = get_best_mode (bitsize, bitnum,\n-\t\t\t\t\t      align * BITS_PER_UNIT, maxmode,\n+\t\t    bestmode = get_best_mode (bitsize, bitnum, align, maxmode,\n \t\t\t\t\t      MEM_VOLATILE_P (xop0));\n \t\t  else\n \t\t    bestmode = GET_MODE (xop0);\n \n \t\t  if (bestmode == VOIDmode\n \t\t      || (SLOW_UNALIGNED_ACCESS (bestmode, align)\n-\t\t\t  && GET_MODE_SIZE (bestmode) > align))\n+\t\t\t  && GET_MODE_BITSIZE (bestmode) > align))\n \t\t    goto extv_loses;\n \n \t\t  /* Compute offset as multiple of this unit,\n@@ -1538,7 +1535,7 @@ extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n    and return TARGET, but this is not guaranteed.\n    If TARGET is not used, create a pseudo-reg of mode TMODE for the value.\n \n-   ALIGN is the alignment that STR_RTX is known to have, measured in bytes.  */\n+   ALIGN is the alignment that STR_RTX is known to have.  */\n \n static rtx\n extract_fixed_bit_field (tmode, op0, offset, bitsize, bitpos,\n@@ -1565,8 +1562,8 @@ extract_fixed_bit_field (tmode, op0, offset, bitsize, bitpos,\n \t includes the entire field.  If such a mode would be larger than\n \t a word, we won't be doing the extraction the normal way.  */\n \n-      mode = get_best_mode (bitsize, bitpos + offset * BITS_PER_UNIT,\n-\t\t\t    align * BITS_PER_UNIT, word_mode,\n+      mode = get_best_mode (bitsize, bitpos + offset * BITS_PER_UNIT, align,\n+\t\t\t    word_mode,\n \t\t\t    GET_CODE (op0) == MEM && MEM_VOLATILE_P (op0));\n \n       if (mode == VOIDmode)\n@@ -1759,8 +1756,8 @@ lshift_value (mode, value, bitpos, bitsize)\n    BITSIZE is the field width; BITPOS, position of its first bit, in the word.\n    UNSIGNEDP is 1 if should zero-extend the contents; else sign-extend.\n \n-   ALIGN is the known alignment of OP0, measured in bytes.\n-   This is also the size of the memory objects to be used.  */\n+   ALIGN is the known alignment of OP0.  This is also the size of the\n+   memory objects to be used.  */\n \n static rtx\n extract_split_bit_field (op0, bitsize, bitpos, unsignedp, align)\n@@ -1779,7 +1776,7 @@ extract_split_bit_field (op0, bitsize, bitpos, unsignedp, align)\n   if (GET_CODE (op0) == REG || GET_CODE (op0) == SUBREG)\n     unit = BITS_PER_WORD;\n   else\n-    unit = MIN (align * BITS_PER_UNIT, BITS_PER_WORD);\n+    unit = MIN (align, BITS_PER_WORD);\n \n   while (bitsdone < bitsize)\n     {"}, {"sha": "dd95760702306f80bbd7fed3778c33d68ca17ab1", "filename": "gcc/expr.c", "status": "modified", "additions": 182, "deletions": 205, "changes": 387, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "patch": "@@ -204,8 +204,8 @@ static char direct_store[NUM_MACHINE_MODES];\n /* This macro is used to determine whether move_by_pieces should be called\n    to perform a structure copy. */\n #ifndef MOVE_BY_PIECES_P\n-#define MOVE_BY_PIECES_P(SIZE, ALIGN) (move_by_pieces_ninsns        \\\n-                                       (SIZE, ALIGN) < MOVE_RATIO)\n+#define MOVE_BY_PIECES_P(SIZE, ALIGN) \\\n+  (move_by_pieces_ninsns (SIZE, ALIGN) < MOVE_RATIO)\n #endif\n \n /* This array records the insn_code of insns to perform block moves.  */\n@@ -1365,7 +1365,7 @@ convert_modes (mode, oldmode, x, unsignedp)\n \n /* MOVE_MAX_PIECES is the number of bytes at a time which we can\n    move efficiently, as opposed to  MOVE_MAX which is the maximum\n-   number of bhytes we can move with a single instruction. */\n+   number of bytes we can move with a single instruction. */\n \n #ifndef MOVE_MAX_PIECES\n #define MOVE_MAX_PIECES   MOVE_MAX\n@@ -1375,7 +1375,7 @@ convert_modes (mode, oldmode, x, unsignedp)\n    from block FROM to block TO.  (These are MEM rtx's with BLKmode).\n    The caller must pass FROM and TO\n     through protect_from_queue before calling.\n-   ALIGN (in bytes) is maximum alignment we can assume.  */\n+   ALIGN is maximum alignment we can assume.  */\n \n void\n move_by_pieces (to, from, len, align)\n@@ -1457,8 +1457,8 @@ move_by_pieces (to, from, len, align)\n     }\n \n   if (! SLOW_UNALIGNED_ACCESS (word_mode, align)\n-      || align > MOVE_MAX || align >= BIGGEST_ALIGNMENT / BITS_PER_UNIT)\n-    align = MOVE_MAX;\n+      || align > MOVE_MAX * BITS_PER_UNIT || align >= BIGGEST_ALIGNMENT)\n+    align = MOVE_MAX * BITS_PER_UNIT;\n \n   /* First move what we can in the largest integer mode, then go to\n      successively smaller modes.  */\n@@ -1474,9 +1474,7 @@ move_by_pieces (to, from, len, align)\n \tbreak;\n \n       icode = mov_optab->handlers[(int) mode].insn_code;\n-      if (icode != CODE_FOR_nothing\n-\t  && align >= MIN (BIGGEST_ALIGNMENT / BITS_PER_UNIT,\n-\t\t\t   (unsigned int) GET_MODE_SIZE (mode)))\n+      if (icode != CODE_FOR_nothing && align >= GET_MODE_ALIGNMENT (mode))\n \tmove_by_pieces_1 (GEN_FCN (icode), mode, &data);\n \n       max_size = GET_MODE_SIZE (mode);\n@@ -1499,7 +1497,7 @@ move_by_pieces_ninsns (l, align)\n   unsigned int max_size = MOVE_MAX + 1;\n \n   if (! SLOW_UNALIGNED_ACCESS (word_mode, align)\n-      || align > MOVE_MAX || align >= BIGGEST_ALIGNMENT / BITS_PER_UNIT)\n+      || align > MOVE_MAX * BITS_PER_UNIT || align >= BIGGEST_ALIGNMENT)\n     align = MOVE_MAX;\n \n   while (max_size > 1)\n@@ -1516,8 +1514,7 @@ move_by_pieces_ninsns (l, align)\n \tbreak;\n \n       icode = mov_optab->handlers[(int) mode].insn_code;\n-      if (icode != CODE_FOR_nothing\n-\t  && align >= GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT)\n+      if (icode != CODE_FOR_nothing && align >= GET_MODE_ALIGNMENT (mode))\n \tn_insns += l / GET_MODE_SIZE (mode), l %= GET_MODE_SIZE (mode);\n \n       max_size = GET_MODE_SIZE (mode);\n@@ -1584,8 +1581,7 @@ move_by_pieces_1 (genfun, mode, data)\n    Both X and Y must be MEM rtx's (perhaps inside VOLATILE)\n    with mode BLKmode.\n    SIZE is an rtx that says how long they are.\n-   ALIGN is the maximum alignment we can assume they have,\n-   measured in bytes. \n+   ALIGN is the maximum alignment we can assume they have.\n \n    Return the address of the new block, if memcpy is called and returns it,\n    0 otherwise.  */\n@@ -1627,7 +1623,7 @@ emit_block_move (x, y, size, align)\n \t including more than one in the machine description unless\n \t the more limited one has some advantage.  */\n \n-      rtx opalign = GEN_INT (align);\n+      rtx opalign = GEN_INT (align / BITS_PER_UNIT);\n       enum machine_mode mode;\n \n       for (mode = GET_CLASS_NARROWEST_MODE (MODE_INT); mode != VOIDmode;\n@@ -1952,7 +1948,7 @@ emit_group_load (dst, orig_src, ssize, align)\n \n       /* Optimize the access just a bit.  */\n       if (GET_CODE (src) == MEM\n-\t  && align * BITS_PER_UNIT >= GET_MODE_ALIGNMENT (mode)\n+\t  && align >= GET_MODE_ALIGNMENT (mode)\n \t  && bytepos * BITS_PER_UNIT % GET_MODE_ALIGNMENT (mode) == 0\n \t  && bytelen == GET_MODE_SIZE (mode))\n \t{\n@@ -1974,18 +1970,15 @@ emit_group_load (dst, orig_src, ssize, align)\n \t    abort ();\n \t}\n       else\n-\t{\n-\t  tmps[i] = extract_bit_field (src, bytelen*BITS_PER_UNIT,\n-\t\t\t\t       bytepos*BITS_PER_UNIT, 1, NULL_RTX,\n-\t\t\t\t       mode, mode, align, ssize);\n-\t}\n+\ttmps[i] = extract_bit_field (src, bytelen * BITS_PER_UNIT,\n+\t\t\t\t     bytepos * BITS_PER_UNIT, 1, NULL_RTX,\n+\t\t\t\t     mode, mode, align, ssize);\n \n       if (BYTES_BIG_ENDIAN && shift)\n-\t{\n-\t  expand_binop (mode, ashl_optab, tmps[i], GEN_INT (shift),\n-\t\t\ttmps[i], 0, OPTAB_WIDEN);\n-\t}\n+\texpand_binop (mode, ashl_optab, tmps[i], GEN_INT (shift),\n+\t\t      tmps[i], 0, OPTAB_WIDEN);\n     }\n+\n   emit_queue();\n \n   /* Copy the extracted pieces into the proper (probable) hard regs.  */\n@@ -2085,7 +2078,7 @@ emit_group_store (orig_dst, src, ssize, align)\n \n       /* Optimize the access just a bit.  */\n       if (GET_CODE (dst) == MEM\n-\t  && align * BITS_PER_UNIT >= GET_MODE_ALIGNMENT (mode)\n+\t  && align >= GET_MODE_ALIGNMENT (mode)\n \t  && bytepos * BITS_PER_UNIT % GET_MODE_ALIGNMENT (mode) == 0\n \t  && bytelen == GET_MODE_SIZE (mode))\n \temit_move_insn (change_address (dst, mode,\n@@ -2114,74 +2107,69 @@ emit_group_store (orig_dst, src, ssize, align)\n    in registers regardless of the structure's alignment. */\n \n rtx\n-copy_blkmode_from_reg (tgtblk,srcreg,type)\n+copy_blkmode_from_reg (tgtblk, srcreg, type)\n      rtx tgtblk;\n      rtx srcreg;\n      tree type;\n {\n-      int bytes = int_size_in_bytes (type);\n-      rtx src = NULL, dst = NULL;\n-      int bitsize = MIN (TYPE_ALIGN (type), BITS_PER_WORD);\n-      int bitpos, xbitpos, big_endian_correction = 0;\n-      \n-      if (tgtblk == 0)\n-\t{\n-\t  tgtblk = assign_stack_temp (BLKmode, bytes, 0);\n-\t  MEM_SET_IN_STRUCT_P (tgtblk, AGGREGATE_TYPE_P (type));\n-\t  preserve_temp_slots (tgtblk);\n-\t}\n+  unsigned HOST_WIDE_INT bytes = int_size_in_bytes (type);\n+  rtx src = NULL, dst = NULL;\n+  unsigned HOST_WIDE_INT bitsize = MIN (TYPE_ALIGN (type), BITS_PER_WORD);\n+  unsigned HOST_WIDE_INT bitpos, xbitpos, big_endian_correction = 0;\n+\n+  if (tgtblk == 0)\n+    {\n+      tgtblk = assign_stack_temp (BLKmode, bytes, 0);\n+      MEM_SET_IN_STRUCT_P (tgtblk, AGGREGATE_TYPE_P (type));\n+      preserve_temp_slots (tgtblk);\n+    }\n       \n-      /* This code assumes srcreg is at least a full word.  If it isn't,\n-\t copy it into a new pseudo which is a full word.  */\n-      if (GET_MODE (srcreg) != BLKmode\n-\t  && GET_MODE_SIZE (GET_MODE (srcreg)) < UNITS_PER_WORD)\n-\tsrcreg = convert_to_mode (word_mode, srcreg,\n-\t\t\t\t  TREE_UNSIGNED (type));\n-\n-      /* Structures whose size is not a multiple of a word are aligned\n-\t to the least significant byte (to the right).  On a BYTES_BIG_ENDIAN\n-\t machine, this means we must skip the empty high order bytes when\n-\t calculating the bit offset.  */\n-      if (BYTES_BIG_ENDIAN && bytes % UNITS_PER_WORD)\n-\tbig_endian_correction = (BITS_PER_WORD - ((bytes % UNITS_PER_WORD)\n-\t\t\t\t\t\t  * BITS_PER_UNIT));\n-\n-      /* Copy the structure BITSIZE bites at a time.\n-\n-\t We could probably emit more efficient code for machines\n-\t which do not use strict alignment, but it doesn't seem\n-\t worth the effort at the current time.  */\n-      for (bitpos = 0, xbitpos = big_endian_correction;\n-\t   bitpos < bytes * BITS_PER_UNIT;\n-\t   bitpos += bitsize, xbitpos += bitsize)\n-\t{\n-\n-\t  /* We need a new source operand each time xbitpos is on a \n-\t     word boundary and when xbitpos == big_endian_correction\n-\t     (the first time through).  */\n-\t  if (xbitpos % BITS_PER_WORD == 0\n-\t      || xbitpos == big_endian_correction)\n-\t    src = operand_subword_force (srcreg,\n-\t\t\t\t\t xbitpos / BITS_PER_WORD, \n-\t\t\t\t\t BLKmode);\n-\n-\t  /* We need a new destination operand each time bitpos is on\n-\t     a word boundary.  */\n-\t  if (bitpos % BITS_PER_WORD == 0)\n-\t    dst = operand_subword (tgtblk, bitpos / BITS_PER_WORD, 1, BLKmode);\n+  /* This code assumes srcreg is at least a full word.  If it isn't,\n+     copy it into a new pseudo which is a full word.  */\n+  if (GET_MODE (srcreg) != BLKmode\n+      && GET_MODE_SIZE (GET_MODE (srcreg)) < UNITS_PER_WORD)\n+    srcreg = convert_to_mode (word_mode, srcreg, TREE_UNSIGNED (type));\n+\n+  /* Structures whose size is not a multiple of a word are aligned\n+     to the least significant byte (to the right).  On a BYTES_BIG_ENDIAN\n+     machine, this means we must skip the empty high order bytes when\n+     calculating the bit offset.  */\n+  if (BYTES_BIG_ENDIAN && bytes % UNITS_PER_WORD)\n+    big_endian_correction\n+      = (BITS_PER_WORD - ((bytes % UNITS_PER_WORD) * BITS_PER_UNIT));\n+\n+  /* Copy the structure BITSIZE bites at a time.\n+     \n+     We could probably emit more efficient code for machines which do not use\n+     strict alignment, but it doesn't seem worth the effort at the current\n+     time.  */\n+  for (bitpos = 0, xbitpos = big_endian_correction;\n+       bitpos < bytes * BITS_PER_UNIT;\n+       bitpos += bitsize, xbitpos += bitsize)\n+    {\n+      /* We need a new source operand each time xbitpos is on a \n+\t word boundary and when xbitpos == big_endian_correction\n+\t (the first time through).  */\n+      if (xbitpos % BITS_PER_WORD == 0\n+\t  || xbitpos == big_endian_correction)\n+\tsrc = operand_subword_force (srcreg, xbitpos / BITS_PER_WORD, BLKmode);\n+\n+      /* We need a new destination operand each time bitpos is on\n+\t a word boundary.  */\n+      if (bitpos % BITS_PER_WORD == 0)\n+\tdst = operand_subword (tgtblk, bitpos / BITS_PER_WORD, 1, BLKmode);\n \t      \n-\t  /* Use xbitpos for the source extraction (right justified) and\n-\t     xbitpos for the destination store (left justified).  */\n-\t  store_bit_field (dst, bitsize, bitpos % BITS_PER_WORD, word_mode,\n-\t\t\t   extract_bit_field (src, bitsize,\n-\t\t\t\t\t      xbitpos % BITS_PER_WORD, 1,\n-\t\t\t\t\t      NULL_RTX, word_mode,\n-\t\t\t\t\t      word_mode,\n-\t\t\t\t\t      bitsize / BITS_PER_UNIT,\n-\t\t\t\t\t      BITS_PER_WORD),\n-\t\t\t   bitsize / BITS_PER_UNIT, BITS_PER_WORD);\n-\t}\n-      return tgtblk;\n+      /* Use xbitpos for the source extraction (right justified) and\n+\t xbitpos for the destination store (left justified).  */\n+      store_bit_field (dst, bitsize, bitpos % BITS_PER_WORD, word_mode,\n+\t\t       extract_bit_field (src, bitsize,\n+\t\t\t\t\t  xbitpos % BITS_PER_WORD, 1,\n+\t\t\t\t\t  NULL_RTX, word_mode, word_mode,\n+\t\t\t\t\t  bitsize, BITS_PER_WORD),\n+\t\t       bitsize, BITS_PER_WORD);\n+    }\n+\n+  return tgtblk;\n }\n \n \n@@ -2242,10 +2230,9 @@ use_group_regs (call_fusage, regs)\n     }\n }\n \f\n-/* Generate several move instructions to clear LEN bytes of block TO.\n-   (A MEM rtx with BLKmode).   The caller must pass TO through\n-   protect_from_queue before calling. ALIGN (in bytes) is maximum alignment\n-   we can assume.  */\n+/* Generate several move instructions to clear LEN bytes of block TO.  (A MEM\n+   rtx with BLKmode).  The caller must pass TO through protect_from_queue\n+   before calling. ALIGN is maximum alignment we can assume.  */\n \n static void\n clear_by_pieces (to, len, align)\n@@ -2303,7 +2290,7 @@ clear_by_pieces (to, len, align)\n     }\n \n   if (! SLOW_UNALIGNED_ACCESS (word_mode, align)\n-      || align > MOVE_MAX || align >= BIGGEST_ALIGNMENT / BITS_PER_UNIT)\n+      || align > MOVE_MAX * BITS_PER_UNIT || align >= BIGGEST_ALIGNMENT)\n     align = MOVE_MAX;\n \n   /* First move what we can in the largest integer mode, then go to\n@@ -2320,8 +2307,7 @@ clear_by_pieces (to, len, align)\n \tbreak;\n \n       icode = mov_optab->handlers[(int) mode].insn_code;\n-      if (icode != CODE_FOR_nothing\n-\t  && align >= GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT)\n+      if (icode != CODE_FOR_nothing && align >= GET_MODE_ALIGNMENT (mode))\n \tclear_by_pieces_1 (GEN_FCN (icode), mode, &data);\n \n       max_size = GET_MODE_SIZE (mode);\n@@ -2369,9 +2355,8 @@ clear_by_pieces_1 (genfun, mode, data)\n     }\n }\n \f\n-/* Write zeros through the storage of OBJECT.\n-   If OBJECT has BLKmode, SIZE is its length in bytes and ALIGN is\n-   the maximum alignment we can is has, measured in bytes.\n+/* Write zeros through the storage of OBJECT.  If OBJECT has BLKmode, SIZE is\n+   its length in bytes and ALIGN is the maximum alignment we can is has.\n \n    If we call a function that returns the length of the block, return it.  */\n \n@@ -2395,14 +2380,13 @@ clear_storage (object, size, align)\n       if (GET_CODE (size) == CONST_INT\n \t  && MOVE_BY_PIECES_P (INTVAL (size), align))\n \tclear_by_pieces (object, INTVAL (size), align);\n-\n       else\n \t{\n \t  /* Try the most limited insn first, because there's no point\n \t     including more than one in the machine description unless\n \t     the more limited one has some advantage.  */\n \n-\t  rtx opalign = GEN_INT (align);\n+\t  rtx opalign = GEN_INT (align / BITS_PER_UNIT);\n \t  enum machine_mode mode;\n \n \t  for (mode = GET_CLASS_NARROWEST_MODE (MODE_INT); mode != VOIDmode;\n@@ -2899,7 +2883,7 @@ get_push_address (size)\n    SIZE is an rtx for the size of data to be copied (in bytes),\n    needed only if X is BLKmode.\n \n-   ALIGN (in bytes) is maximum alignment we can assume.\n+   ALIGN is maximum alignment we can assume.\n \n    If PARTIAL and REG are both nonzero, then copy that many of the first\n    words of X into registers starting with REG, and push the rest of X.\n@@ -3001,7 +2985,7 @@ emit_push_insn (x, mode, type, size, align, partial, reg, extra,\n \t     forces many pushes of a small amount of data,\n \t     and such small pushes do rounding that causes trouble.  */\n \t  && ((! SLOW_UNALIGNED_ACCESS (word_mode, align))\n-\t      || align >= BIGGEST_ALIGNMENT / BITS_PER_UNIT\n+\t      || align >= BIGGEST_ALIGNMENT\n \t      || PUSH_ROUNDING (align) == align)\n \t  && PUSH_ROUNDING (INTVAL (size)) == INTVAL (size))\n \t{\n@@ -3102,7 +3086,7 @@ emit_push_insn (x, mode, type, size, align, partial, reg, extra,\n \t    }\n \t  else\n \t    {\n-\t      rtx opalign = GEN_INT (align);\n+\t      rtx opalign = GEN_INT (align / BITS_PER_UNIT);\n \t      enum machine_mode mode;\n \t      rtx target = gen_rtx_MEM (BLKmode, temp);\n \n@@ -3393,7 +3377,7 @@ expand_assignment (to, from, want_value, suggest_reg)\n \t      && bitsize\n \t      && (bitpos % bitsize) == 0 \n \t      && (bitsize % GET_MODE_ALIGNMENT (mode1)) == 0\n-\t      && (alignment * BITS_PER_UNIT) == GET_MODE_ALIGNMENT (mode1))\n+\t      && alignment == GET_MODE_ALIGNMENT (mode1))\n \t    {\n \t      rtx temp = change_address (to_rtx, mode1,\n \t\t\t\t         plus_constant (XEXP (to_rtx, 0),\n@@ -3483,7 +3467,7 @@ expand_assignment (to, from, want_value, suggest_reg)\n \t\t\t\t\t     bitpos / BITS_PER_UNIT));\n \n \t  emit_block_move (inner_to_rtx, from_rtx, expr_size (from),\n-\t\t\t   MIN (alignment, from_align / BITS_PER_UNIT));\n+\t\t\t   MIN (alignment, from_align));\n \t  free_temp_slots ();\n \t  pop_temp_slots ();\n \t  return to_rtx;\n@@ -3497,7 +3481,6 @@ expand_assignment (to, from, want_value, suggest_reg)\n \t\t\t\t    TYPE_MODE (TREE_TYPE (to)))\n \t\t\t\t : VOIDmode),\n \t\t\t\tunsignedp,\n-\t\t\t\t/* Required alignment of containing datum.  */\n \t\t\t\talignment,\n \t\t\t\tint_size_in_bytes (TREE_TYPE (tem)),\n \t\t\t\tget_alias_set (to));\n@@ -3542,10 +3525,10 @@ expand_assignment (to, from, want_value, suggest_reg)\n \t The Irix 6 ABI has examples of this.  */\n       if (GET_CODE (to_rtx) == PARALLEL)\n \temit_group_load (to_rtx, value, int_size_in_bytes (TREE_TYPE (from)),\n-\t\t\t TYPE_ALIGN (TREE_TYPE (from)) / BITS_PER_UNIT);\n+\t\t\t TYPE_ALIGN (TREE_TYPE (from)));\n       else if (GET_MODE (to_rtx) == BLKmode)\n \temit_block_move (to_rtx, value, expr_size (from),\n-\t\t\t TYPE_ALIGN (TREE_TYPE (from)) / BITS_PER_UNIT);\n+\t\t\t TYPE_ALIGN (TREE_TYPE (from)));\n       else\n \t{\n #ifdef POINTERS_EXTEND_UNSIGNED\n@@ -3582,7 +3565,7 @@ expand_assignment (to, from, want_value, suggest_reg)\n \n       if (GET_CODE (to_rtx) == PARALLEL)\n \temit_group_load (to_rtx, temp, int_size_in_bytes (TREE_TYPE (from)),\n-\t\t\t TYPE_ALIGN (TREE_TYPE (from)) / BITS_PER_UNIT);\n+\t\t\t TYPE_ALIGN (TREE_TYPE (from)));\n       else\n \temit_move_insn (to_rtx, temp);\n \n@@ -3908,8 +3891,7 @@ store_expr (exp, target, want_value)\n \t  size = expr_size (exp);\n \t  if (GET_CODE (size) == CONST_INT\n \t      && INTVAL (size) < TREE_STRING_LENGTH (exp))\n-\t    emit_block_move (target, temp, size,\n-\t\t\t     TYPE_ALIGN (TREE_TYPE (exp)) / BITS_PER_UNIT);\n+\t    emit_block_move (target, temp, size, TYPE_ALIGN (TREE_TYPE (exp)));\n \t  else\n \t    {\n \t      /* Compute the size of the data to copy from the string.  */\n@@ -3923,7 +3905,7 @@ store_expr (exp, target, want_value)\n \n \t      /* Copy that much.  */\n \t      emit_block_move (target, temp, copy_size_rtx,\n-\t\t\t       TYPE_ALIGN (TREE_TYPE (exp)) / BITS_PER_UNIT);\n+\t\t\t       TYPE_ALIGN (TREE_TYPE (exp)));\n \n \t      /* Figure out how much is left in TARGET that we have to clear.\n \t\t Do all calculations in ptr_mode.  */\n@@ -3987,10 +3969,10 @@ store_expr (exp, target, want_value)\n \t The Irix 6 ABI has examples of this.  */\n       else if (GET_CODE (target) == PARALLEL)\n \temit_group_load (target, temp, int_size_in_bytes (TREE_TYPE (exp)),\n-\t\t\t TYPE_ALIGN (TREE_TYPE (exp)) / BITS_PER_UNIT);\n+\t\t\t TYPE_ALIGN (TREE_TYPE (exp)));\n       else if (GET_MODE (temp) == BLKmode)\n \temit_block_move (target, temp, expr_size (exp),\n-\t\t\t TYPE_ALIGN (TREE_TYPE (exp)) / BITS_PER_UNIT);\n+\t\t\t TYPE_ALIGN (TREE_TYPE (exp)));\n       else\n \temit_move_insn (target, temp);\n     }\n@@ -4126,14 +4108,13 @@ store_constructor_field (target, bitsize, bitpos,\n       store_constructor (exp, target, align, cleared, bitsize / BITS_PER_UNIT);\n     }\n   else\n-    store_field (target, bitsize, bitpos, mode, exp, VOIDmode, 0, \n-\t\t (align + BITS_PER_UNIT - 1) / BITS_PER_UNIT,\n+    store_field (target, bitsize, bitpos, mode, exp, VOIDmode, 0, align,\n \t\t int_size_in_bytes (type), 0);\n }\n \n /* Store the value of constructor EXP into the rtx TARGET.\n    TARGET is either a REG or a MEM.\n-   ALIGN is the maximum known alignment for TARGET, in bits.\n+   ALIGN is the maximum known alignment for TARGET.\n    CLEARED is true if TARGET is known to have been zero'd.\n    SIZE is the number of bytes of TARGET we are allowed to modify: this\n    may not be the same as the size of EXP if we are assigning to a field\n@@ -4180,8 +4161,7 @@ store_constructor (exp, target, align, cleared, size)\n \n \t  /* If the constructor is empty, clear the union.  */\n \t  if (! CONSTRUCTOR_ELTS (exp)  && ! cleared)\n-\t    clear_storage (target, expr_size (exp),\n-\t\t\t   TYPE_ALIGN (type) / BITS_PER_UNIT);\n+\t    clear_storage (target, expr_size (exp), TYPE_ALIGN (type));\n \t}\n \n       /* If we are building a static constructor into a register,\n@@ -4206,8 +4186,7 @@ store_constructor (exp, target, align, cleared, size)\n \t\t   || mostly_zeros_p (exp)))\n \t{\n \t  if (! cleared)\n-\t    clear_storage (target, GEN_INT (size),\n-\t\t\t   (align + BITS_PER_UNIT - 1) / BITS_PER_UNIT);\n+\t    clear_storage (target, GEN_INT (size), align);\n \n \t  cleared = 1;\n \t}\n@@ -4361,19 +4340,21 @@ store_constructor (exp, target, align, cleared, size)\n \t    {\n \t      tree index = TREE_PURPOSE (elt);\n \t      HOST_WIDE_INT this_node_count;\n+\n \t      if (index != NULL_TREE && TREE_CODE (index) == RANGE_EXPR)\n \t\t{\n \t\t  tree lo_index = TREE_OPERAND (index, 0);\n \t\t  tree hi_index = TREE_OPERAND (index, 1);\n \n-\t\t  if (TREE_CODE (lo_index) != INTEGER_CST\n-\t\t      || TREE_CODE (hi_index) != INTEGER_CST)\n+\t\t  if (! host_integerp (lo_index, 1)\n+\t\t      || ! host_integerp (hi_index, 1))\n \t\t    {\n \t\t      need_to_clear = 1;\n \t\t      break;\n \t\t    }\n-\t\t  this_node_count = (TREE_INT_CST_LOW (hi_index)\n-\t\t\t\t     - TREE_INT_CST_LOW (lo_index) + 1);\n+\n+\t\t  this_node_count = (tree_low_cst (hi_index, 1)\n+\t\t\t\t     - tree_low_cst (lo_index, 1) + 1);\n \t\t}\n \t      else\n \t\tthis_node_count = 1;\n@@ -4390,8 +4371,7 @@ store_constructor (exp, target, align, cleared, size)\n       if (need_to_clear && size > 0)\n \t{\n \t  if (! cleared)\n-\t    clear_storage (target, GEN_INT (size),\n-\t\t\t   (align + BITS_PER_UNIT - 1) / BITS_PER_UNIT);\n+\t    clear_storage (target, GEN_INT (size), align);\n \t  cleared = 1;\n \t}\n       else\n@@ -4406,8 +4386,8 @@ store_constructor (exp, target, align, cleared, size)\n \t   elt = TREE_CHAIN (elt), i++)\n \t{\n \t  register enum machine_mode mode;\n-\t  int bitsize;\n-\t  int bitpos;\n+\t  HOST_WIDE_INT bitsize;\n+\t  HOST_WIDE_INT bitpos;\n \t  int unsignedp;\n \t  tree value = TREE_VALUE (elt);\n \t  unsigned int align = TYPE_ALIGN (TREE_TYPE (value));\n@@ -4420,13 +4400,9 @@ store_constructor (exp, target, align, cleared, size)\n \t  unsignedp = TREE_UNSIGNED (elttype);\n \t  mode = TYPE_MODE (elttype);\n \t  if (mode == BLKmode)\n-\t    {\n-\t      if (TREE_CODE (TYPE_SIZE (elttype)) == INTEGER_CST\n-\t\t  && TREE_INT_CST_HIGH (TYPE_SIZE (elttype)) == 0)\n-\t\tbitsize = TREE_INT_CST_LOW (TYPE_SIZE (elttype));\n-\t      else\n-\t\tbitsize = -1;\n-\t    }\n+\t    bitsize = (host_integerp (TYPE_SIZE (elttype), 1)\n+\t\t       ? tree_low_cst (TYPE_SIZE (elttype), 1)\n+\t\t       : -1);\n \t  else\n \t    bitsize = GET_MODE_BITSIZE (mode);\n \n@@ -4440,21 +4416,21 @@ store_constructor (exp, target, align, cleared, size)\n \t      tree position;\n \n \t      /* If the range is constant and \"small\", unroll the loop.  */\n-\t      if (TREE_CODE (lo_index) == INTEGER_CST\n-\t\t  && TREE_CODE (hi_index) == INTEGER_CST\n-\t\t  && (lo = TREE_INT_CST_LOW (lo_index),\n-\t\t      hi = TREE_INT_CST_LOW (hi_index),\n+\t      if (host_integerp (lo_index, 0)\n+\t\t  && host_integerp (hi_index, 0)\n+\t\t  && (lo = tree_low_cst (lo_index, 0),\n+\t\t      hi = tree_low_cst (hi_index, 0),\n \t\t      count = hi - lo + 1,\n \t\t      (GET_CODE (target) != MEM\n \t\t       || count <= 2\n-\t\t       || (TREE_CODE (TYPE_SIZE (elttype)) == INTEGER_CST\n-\t\t\t   && TREE_INT_CST_LOW (TYPE_SIZE (elttype)) * count\n-\t\t\t   <= 40 * 8))))\n+\t\t       || (host_integerp (TYPE_SIZE (elttype), 1)\n+\t\t\t   && (tree_low_cst (TYPE_SIZE (elttype), 1) * count\n+\t\t\t       <= 40 * 8)))))\n \t\t{\n \t\t  lo -= minelt;  hi -= minelt;\n \t\t  for (; lo <= hi; lo++)\n \t\t    {\n-\t\t      bitpos = lo * TREE_INT_CST_LOW (TYPE_SIZE (elttype));\n+\t\t      bitpos = lo * tree_low_cst (TYPE_SIZE (elttype), 0);\n \t\t      store_constructor_field (target, bitsize, bitpos, mode,\n \t\t\t\t\t       value, type, align, cleared);\n \t\t    }\n@@ -4513,8 +4489,8 @@ store_constructor (exp, target, align, cleared, size)\n \t\t  emit_label (loop_end);\n \t\t}\n \t    }\n-\t  else if ((index != 0 && TREE_CODE (index) != INTEGER_CST)\n-\t      || TREE_CODE (TYPE_SIZE (elttype)) != INTEGER_CST)\n+\t  else if ((index != 0 && ! host_integerp (index, 0))\n+\t\t   || ! host_integerp (TYPE_SIZE (elttype), 1))\n \t    {\n \t      rtx pos_rtx, addr;\n \t      tree position;\n@@ -4526,6 +4502,7 @@ store_constructor (exp, target, align, cleared, size)\n \t\tindex = convert (ssizetype,\n \t\t\t\t fold (build (MINUS_EXPR, index,\n \t\t\t\t\t      TYPE_MIN_VALUE (domain))));\n+\n \t      position = size_binop (MULT_EXPR, index,\n \t\t\t\t     convert (ssizetype,\n \t\t\t\t\t      TYPE_SIZE_UNIT (elttype)));\n@@ -4537,20 +4514,22 @@ store_constructor (exp, target, align, cleared, size)\n \t  else\n \t    {\n \t      if (index != 0)\n-\t\tbitpos = ((TREE_INT_CST_LOW (index) - minelt)\n-\t\t\t  * TREE_INT_CST_LOW (TYPE_SIZE (elttype)));\n+\t\tbitpos = ((tree_low_cst (index, 0) - minelt)\n+\t\t\t  * tree_low_cst (TYPE_SIZE (elttype), 1));\n \t      else\n-\t\tbitpos = (i * TREE_INT_CST_LOW (TYPE_SIZE (elttype)));\n+\t\tbitpos = (i * tree_low_cst (TYPE_SIZE (elttype), 1));\n+\n \t      store_constructor_field (target, bitsize, bitpos, mode, value,\n \t\t\t\t       type, align, cleared);\n \t    }\n \t}\n     }\n-  /* set constructor assignments */\n+\n+  /* Set constructor assignments */\n   else if (TREE_CODE (type) == SET_TYPE)\n     {\n       tree elt = CONSTRUCTOR_ELTS (exp);\n-      int nbytes = int_size_in_bytes (type), nbits;\n+      unsigned HOST_WIDE_INT nbytes = int_size_in_bytes (type), nbits;\n       tree domain = TYPE_DOMAIN (type);\n       tree domain_min, domain_max, bitlength;\n \n@@ -4568,8 +4547,7 @@ store_constructor (exp, target, align, cleared, size)\n       if (elt == NULL_TREE && size > 0)\n \t{\n \t  if (!cleared)\n-\t    clear_storage (target, GEN_INT (size),\n-\t\t\t   TYPE_ALIGN (type) / BITS_PER_UNIT);\n+\t    clear_storage (target, GEN_INT (size), TYPE_ALIGN (type));\n \t  return;\n \t}\n \n@@ -4579,23 +4557,22 @@ store_constructor (exp, target, align, cleared, size)\n \t\t\t      size_diffop (domain_max, domain_min),\n \t\t\t      ssize_int (1));\n \n-      if (nbytes < 0 || TREE_CODE (bitlength) != INTEGER_CST)\n-\tabort ();\n-      nbits = TREE_INT_CST_LOW (bitlength);\n+      nbits = tree_low_cst (bitlength, 1);\n \n       /* For \"small\" sets, or \"medium-sized\" (up to 32 bytes) sets that\n \t are \"complicated\" (more than one range), initialize (the\n \t constant parts) by copying from a constant.  */\t \n       if (GET_MODE (target) != BLKmode || nbits <= 2 * BITS_PER_WORD\n \t  || (nbytes <= 32 && TREE_CHAIN (elt) != NULL_TREE))\n \t{\n-\t  int set_word_size = TYPE_ALIGN (TREE_TYPE (exp));\n+\t  unsigned int set_word_size = TYPE_ALIGN (TREE_TYPE (exp));\n \t  enum machine_mode mode = mode_for_size (set_word_size, MODE_INT, 1);\n \t  char *bit_buffer = (char *) alloca (nbits);\n \t  HOST_WIDE_INT word = 0;\n-\t  int bit_pos = 0;\n-\t  int ibit = 0;\n-\t  int offset = 0;  /* In bytes from beginning of set.  */\n+\t  unsigned int bit_pos = 0;\n+\t  unsigned int ibit = 0;\n+\t  unsigned int offset = 0;  /* In bytes from beginning of set.  */\n+\n \t  elt = get_set_constructor_bits (exp, bit_buffer, nbits);\n \t  for (;;)\n \t    {\n@@ -4606,13 +4583,15 @@ store_constructor (exp, target, align, cleared, size)\n \t\t  else\n \t\t    word |= 1 << bit_pos;\n \t\t}\n+\n \t      bit_pos++;  ibit++;\n \t      if (bit_pos >= set_word_size || ibit == nbits)\n \t\t{\n \t\t  if (word != 0 || ! cleared)\n \t\t    {\n \t\t      rtx datum = GEN_INT (word);\n \t\t      rtx to_rtx;\n+\n \t\t      /* The assumption here is that it is safe to use\n \t\t\t XEXP if the set is multi-word, but not if\n \t\t\t it's single-word.  */\n@@ -4627,6 +4606,7 @@ store_constructor (exp, target, align, cleared, size)\n \t\t\tabort ();\n \t\t      emit_move_insn (to_rtx, datum);\n \t\t    }\n+\n \t\t  if (ibit == nbits)\n \t\t    break;\n \t\t  word = 0;\n@@ -4636,19 +4616,16 @@ store_constructor (exp, target, align, cleared, size)\n \t    }\n \t}\n       else if (!cleared)\n-\t{\n-\t  /* Don't bother clearing storage if the set is all ones.  */\n-\t  if (TREE_CHAIN (elt) != NULL_TREE\n-\t      || (TREE_PURPOSE (elt) == NULL_TREE\n-\t\t  ? nbits != 1\n-\t\t  : (TREE_CODE (TREE_VALUE (elt)) != INTEGER_CST\n-\t\t     || TREE_CODE (TREE_PURPOSE (elt)) != INTEGER_CST\n-\t\t     || ((HOST_WIDE_INT) TREE_INT_CST_LOW (TREE_VALUE (elt))\n-\t\t\t - (HOST_WIDE_INT) TREE_INT_CST_LOW (TREE_PURPOSE (elt)) + 1\n-\t\t\t != nbits))))\n-\t    clear_storage (target, expr_size (exp),\n-\t\t\t   TYPE_ALIGN (type) / BITS_PER_UNIT);\n-\t}\n+\t/* Don't bother clearing storage if the set is all ones.  */\n+\tif (TREE_CHAIN (elt) != NULL_TREE\n+\t    || (TREE_PURPOSE (elt) == NULL_TREE\n+\t\t? nbits != 1\n+\t\t: ( ! host_integerp (TREE_VALUE (elt), 0)\n+\t\t   || ! host_integerp (TREE_PURPOSE (elt), 0)\n+\t\t   || (tree_low_cst (TREE_VALUE (elt), 0)\n+\t\t       - tree_low_cst (TREE_PURPOSE (elt), 0) + 1\n+\t\t       != (HOST_WIDE_INT) nbits))))\n+\t  clear_storage (target, expr_size (exp), TYPE_ALIGN (type));\n \t  \n       for (; elt != NULL_TREE; elt = TREE_CHAIN (elt))\n \t{\n@@ -4659,17 +4636,18 @@ store_constructor (exp, target, align, cleared, size)\n #ifdef TARGET_MEM_FUNCTIONS\n \t  HOST_WIDE_INT startb, endb;\n #endif\n-\t  rtx  bitlength_rtx, startbit_rtx, endbit_rtx, targetx;\n+\t  rtx bitlength_rtx, startbit_rtx, endbit_rtx, targetx;\n \n \t  bitlength_rtx = expand_expr (bitlength,\n-\t\t\t    NULL_RTX, MEM, EXPAND_CONST_ADDRESS);\n+\t\t\t\t       NULL_RTX, MEM, EXPAND_CONST_ADDRESS);\n \n \t  /* handle non-range tuple element like [ expr ]  */\n \t  if (startbit == NULL_TREE)\n \t    {\n \t      startbit = save_expr (endbit);\n \t      endbit = startbit;\n \t    }\n+\n \t  startbit = convert (sizetype, startbit);\n \t  endbit = convert (sizetype, endbit);\n \t  if (! integer_zerop (domain_min))\n@@ -4689,6 +4667,7 @@ store_constructor (exp, target, align, cleared, size)\n \t\t\t\t\t   0);\n \t      emit_move_insn (targetx, target);\n \t    }\n+\n \t  else if (GET_CODE (target) == MEM)\n \t    targetx = target;\n \t  else\n@@ -4714,13 +4693,12 @@ store_constructor (exp, target, align, cleared, size)\n \t    }\n \t  else\n #endif\n-\t    {\n-\t      emit_library_call (gen_rtx_SYMBOL_REF (Pmode, \"__setbits\"),\n-\t\t\t\t 0, VOIDmode, 4, XEXP (targetx, 0), Pmode,\n-\t\t\t\t bitlength_rtx, TYPE_MODE (sizetype),\n-\t\t\t\t startbit_rtx, TYPE_MODE (sizetype),\n-\t\t\t\t endbit_rtx, TYPE_MODE (sizetype));\n-\t    }\n+\t    emit_library_call (gen_rtx_SYMBOL_REF (Pmode, \"__setbits\"),\n+\t\t\t       0, VOIDmode, 4, XEXP (targetx, 0), Pmode,\n+\t\t\t       bitlength_rtx, TYPE_MODE (sizetype),\n+\t\t\t       startbit_rtx, TYPE_MODE (sizetype),\n+\t\t\t       endbit_rtx, TYPE_MODE (sizetype));\n+\n \t  if (REG_P (target))\n \t    emit_move_insn (target, targetx);\n \t}\n@@ -4742,7 +4720,7 @@ store_constructor (exp, target, align, cleared, size)\n    has mode VALUE_MODE if that is convenient to do.\n    In this case, UNSIGNEDP must be nonzero if the value is an unsigned type.\n \n-   ALIGN is the alignment that TARGET is known to have, measured in bytes.\n+   ALIGN is the alignment that TARGET is known to have.\n    TOTAL_SIZE is the size in bytes of the structure, or -1 if varying.  \n \n    ALIAS_SET is the alias set for the destination.  This value will\n@@ -4828,10 +4806,10 @@ store_field (target, bitsize, bitpos, mode, exp, value_mode,\n       /* If the field isn't aligned enough to store as an ordinary memref,\n \t store it as a bit field.  */\n       || (mode != BLKmode && SLOW_UNALIGNED_ACCESS (mode, align)\n-\t  && (align * BITS_PER_UNIT < GET_MODE_ALIGNMENT (mode)\n+\t  && (align < GET_MODE_ALIGNMENT (mode)\n \t      || bitpos % GET_MODE_ALIGNMENT (mode)))\n       || (mode == BLKmode && SLOW_UNALIGNED_ACCESS (mode, align)\n-\t  && (TYPE_ALIGN (TREE_TYPE (exp)) > align * BITS_PER_UNIT\n+\t  && (TYPE_ALIGN (TREE_TYPE (exp)) > align\n \t      || bitpos % TYPE_ALIGN (TREE_TYPE (exp)) != 0))\n       /* If the RHS and field are a constant size and the size of the\n \t RHS isn't the same size as the bitfield, we must use bitfield\n@@ -4865,7 +4843,7 @@ store_field (target, bitsize, bitpos, mode, exp, value_mode,\n \t boundary.  If so, we simply do a block copy.  */\n       if (GET_MODE (target) == BLKmode && GET_MODE (temp) == BLKmode)\n \t{\n-\t  unsigned int exp_align = expr_align (exp) / BITS_PER_UNIT;\n+\t  unsigned int exp_align = expr_align (exp);\n \n \t  if (GET_CODE (target) != MEM || GET_CODE (temp) != MEM\n \t      || bitpos % BITS_PER_UNIT != 0)\n@@ -4879,7 +4857,7 @@ store_field (target, bitsize, bitpos, mode, exp, value_mode,\n \t  align = MIN (exp_align, align);\n \n \t  /* Find an alignment that is consistent with the bit position.  */\n-\t  while ((bitpos % (align * BITS_PER_UNIT)) != 0)\n+\t  while ((bitpos % align) != 0)\n \t    align >>= 1;\n \n \t  emit_block_move (target, temp,\n@@ -4957,7 +4935,7 @@ store_field (target, bitsize, bitpos, mode, exp, value_mode,\n    giving the variable offset (in units) in *POFFSET.\n    This offset is in addition to the bit position.\n    If the position is not variable, we store 0 in *POFFSET.\n-   We set *PALIGNMENT to the alignment in bytes of the address that will be\n+   We set *PALIGNMENT to the alignment of the address that will be\n    computed.  This is the alignment of the thing we return if *POFFSET\n    is zero, but can be more less strictly aligned if *POFFSET is nonzero.\n \n@@ -5111,7 +5089,7 @@ get_inner_reference (exp, pbitsize, pbitpos, poffset, pmode,\n     *pbitpos = tree_low_cst (bit_offset, 0), *poffset = offset;\n \n   *pmode = mode;\n-  *palignment = alignment / BITS_PER_UNIT;\n+  *palignment = alignment;\n   return exp;\n }\n \n@@ -6348,15 +6326,15 @@ expand_expr (exp, target, tmode, modifier)\n \t\t&& ((mode == BLKmode\n \t\t     && ! (target != 0 && safe_from_p (target, exp, 1)))\n \t\t    || TREE_ADDRESSABLE (exp)\n-\t\t    || (TREE_CODE (TYPE_SIZE_UNIT (type)) == INTEGER_CST\n-\t\t\t&& TREE_INT_CST_HIGH (TYPE_SIZE_UNIT (type)) == 0\n+\t\t    || (host_integerp (TYPE_SIZE_UNIT (type), 1)\n \t\t\t&& (! MOVE_BY_PIECES_P \n-\t\t\t    (TREE_INT_CST_LOW (TYPE_SIZE_UNIT (type)),\n-\t\t\t     TYPE_ALIGN (type) / BITS_PER_UNIT))\n+\t\t\t    (tree_low_cst (TYPE_SIZE_UNIT (type), 1),\n+\t\t\t     TYPE_ALIGN (type)))\n \t\t\t&& ! mostly_zeros_p (exp))))\n \t       || (modifier == EXPAND_INITIALIZER && TREE_CONSTANT (exp)))\n \t{\n \t  rtx constructor = output_constant_def (exp);\n+\n \t  if (modifier != EXPAND_CONST_ADDRESS\n \t      && modifier != EXPAND_INITIALIZER\n \t      && modifier != EXPAND_SUM\n@@ -6698,7 +6676,7 @@ expand_expr (exp, target, tmode, modifier)\n \t\t&& bitsize != 0\n \t\t&& (bitpos % bitsize) == 0 \n \t\t&& (bitsize % GET_MODE_ALIGNMENT (mode1)) == 0\n-\t\t&& (alignment * BITS_PER_UNIT) == GET_MODE_ALIGNMENT (mode1))\n+\t\t&& alignment == GET_MODE_ALIGNMENT (mode1))\n \t      {\n \t\trtx temp = change_address (op0, mode1,\n \t\t\t\t\t   plus_constant (XEXP (op0, 0),\n@@ -6772,7 +6750,7 @@ expand_expr (exp, target, tmode, modifier)\n \t\t    || (mode1 != BLKmode\n \t\t\t&& SLOW_UNALIGNED_ACCESS (mode1, alignment)\n \t\t\t&& ((TYPE_ALIGN (TREE_TYPE (tem))\n-\t\t\t     < (unsigned int) GET_MODE_ALIGNMENT (mode))\n+\t\t\t     < GET_MODE_ALIGNMENT (mode))\n \t\t\t    || (bitpos % GET_MODE_ALIGNMENT (mode) != 0)))\n \t\t    /* If the type and the field are a constant size and the\n \t\t       size of the type isn't the same size as the bitfield,\n@@ -6786,7 +6764,7 @@ expand_expr (exp, target, tmode, modifier)\n \t\t&& modifier != EXPAND_INITIALIZER\n \t\t&& mode == BLKmode\n \t\t&& SLOW_UNALIGNED_ACCESS (mode, alignment)\n-\t\t&& (TYPE_ALIGN (type) > alignment * BITS_PER_UNIT\n+\t\t&& (TYPE_ALIGN (type) > alignment\n \t\t    || bitpos % TYPE_ALIGN (type) != 0)))\n \t  {\n \t    enum machine_mode ext_mode = mode;\n@@ -6815,15 +6793,15 @@ expand_expr (exp, target, tmode, modifier)\n \t\temit_block_move (target, op0,\n \t\t\t\t GEN_INT ((bitsize + BITS_PER_UNIT - 1)\n \t\t\t\t\t  / BITS_PER_UNIT),\n-\t\t\t\t 1);\n+\t\t\t\t BITS_PER_UNIT);\n \t\t\n \t\treturn target;\n \t      }\n \n \t    op0 = validize_mem (op0);\n \n \t    if (GET_CODE (op0) == MEM && GET_CODE (XEXP (op0, 0)) == REG)\n-\t      mark_reg_pointer (XEXP (op0, 0), alignment);\n+\t      mark_reg_pointer (XEXP (op0, 0), alignment / BITS_PER_UNIT);\n \n \t    op0 = extract_bit_field (op0, bitsize, bitpos,\n \t\t\t\t     unsignedp, target, ext_mode, ext_mode,\n@@ -6874,7 +6852,7 @@ expand_expr (exp, target, tmode, modifier)\n \t  MEM_ALIAS_SET (op0) = get_alias_set (exp);\n  \n \tif (GET_CODE (XEXP (op0, 0)) == REG)\n-\t  mark_reg_pointer (XEXP (op0, 0), alignment);\n+\t  mark_reg_pointer (XEXP (op0, 0), alignment / BITS_PER_UNIT);\n \n \tMEM_SET_IN_STRUCT_P (op0, 1);\n \tMEM_VOLATILE_P (op0) |= volatilep;\n@@ -8722,7 +8700,7 @@ expand_expr_unaligned (exp, palign)\n \tif (mode1 == VOIDmode\n \t    || GET_CODE (op0) == REG || GET_CODE (op0) == SUBREG\n \t    || (SLOW_UNALIGNED_ACCESS (mode1, alignment)\n-\t\t&& (TYPE_ALIGN (type) > alignment * BITS_PER_UNIT\n+\t\t&& (TYPE_ALIGN (type) > alignment\n \t\t    || bitpos % TYPE_ALIGN (type) != 0)))\n \t  {\n \t    enum machine_mode ext_mode = mode_for_size (bitsize, MODE_INT, 1);\n@@ -8780,7 +8758,7 @@ expand_expr_unaligned (exp, palign)\n \t  alignment >>= 1;\n \n \tif (GET_CODE (XEXP (op0, 0)) == REG)\n-\t  mark_reg_pointer (XEXP (op0, 0), alignment);\n+\t  mark_reg_pointer (XEXP (op0, 0), alignment / BITS_PER_UNIT);\n \n \tMEM_IN_STRUCT_P (op0) = 1;\n \tMEM_VOLATILE_P (op0) |= volatilep;\n@@ -9363,9 +9341,8 @@ do_jump (exp, if_false_label, if_true_label)\n \n \t/* Get description of this reference.  We don't actually care\n \t   about the underlying object here.  */\n-\tget_inner_reference (exp, &bitsize, &bitpos, &offset,\n-\t\t\t     &mode, &unsignedp, &volatilep,\n-\t\t\t     &alignment);\n+\tget_inner_reference (exp, &bitsize, &bitpos, &offset, &mode,\n+\t\t\t     &unsignedp, &volatilep, &alignment);\n \n \ttype = type_for_size (bitsize, unsignedp);\n \tif (! SLOW_BYTE_ACCESS\n@@ -10050,7 +10027,7 @@ do_compare_and_jump (exp, signed_code, unsigned_code, if_false_label,\n   do_compare_rtx_and_jump (op0, op1, code, unsignedp, mode,\n \t\t\t   ((mode == BLKmode)\n \t\t\t    ? expr_size (TREE_OPERAND (exp, 0)) : NULL_RTX),\n-\t\t\t   MIN (align0, align1) / BITS_PER_UNIT,\n+\t\t\t   MIN (align0, align1),\n \t\t\t   if_false_label, if_true_label);\n }\n \f"}, {"sha": "a349d9a32c8e03f60baf6e748689a06b4f9dd149", "filename": "gcc/expr.h", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fexpr.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fexpr.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.h?ref=19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "patch": "@@ -793,12 +793,13 @@ extern void emit_0_to_1_insn PARAMS ((rtx));\n \n /* Emit one rtl insn to compare two rtx's.  */\n extern void emit_cmp_insn PARAMS ((rtx, rtx, enum rtx_code, rtx,\n-\t\t\t\t   enum machine_mode, int, int));\n+\t\t\t\t   enum machine_mode, int, unsigned int));\n \n /* Emit a pair of rtl insns to compare two rtx's and to jump \n    to a label if the comparison is true.  */\n extern void emit_cmp_and_jump_insns PARAMS ((rtx, rtx, enum rtx_code, rtx,\n-\t\t\t\t\t     enum machine_mode, int, int, rtx));\n+\t\t\t\t\t     enum machine_mode, int,\n+\t\t\t\t\t     unsigned int, rtx));\n \n /* The various uses that a comparison can have; used by can_compare_p:\n    jumps, conditional moves, store flag operations.  */"}, {"sha": "b384f6acd233ed595cc470675ccf492f22324387", "filename": "gcc/function.c", "status": "modified", "additions": 4, "deletions": 5, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Ffunction.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Ffunction.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffunction.c?ref=19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "patch": "@@ -3027,7 +3027,7 @@ purge_addressof_1 (loc, insn, force, store, ht)\n \t\t  start_sequence ();\n \t\t  store_bit_field (sub, size_x, 0, GET_MODE (x),\n \t\t\t\t   val, GET_MODE_SIZE (GET_MODE (sub)),\n-\t\t\t\t   GET_MODE_SIZE (GET_MODE (sub)));\n+\t\t\t\t   GET_MODE_ALIGNMENT (GET_MODE (sub)));\n \n \t\t  /* Make sure to unshare any shared rtl that store_bit_field\n \t\t     might have created.  */\n@@ -4339,8 +4339,8 @@ assign_parms (fndecl)\n \t      if (GET_CODE (entry_parm) == PARALLEL)\n \t\temit_group_store (validize_mem (stack_parm), entry_parm,\n \t\t\t\t  int_size_in_bytes (TREE_TYPE (parm)),\n-\t\t\t\t  (TYPE_ALIGN (TREE_TYPE (parm))\n-\t\t\t\t   / BITS_PER_UNIT));\n+\t\t\t\t  TYPE_ALIGN (TREE_TYPE (parm)));\n+\t\t\t\t  \n \t      else\n \t\tmove_block_from_reg (REGNO (entry_parm),\n \t\t\t\t     validize_mem (stack_parm), nregs,\n@@ -4498,8 +4498,7 @@ assign_parms (fndecl)\n \t      if (GET_CODE (entry_parm) == PARALLEL)\n \t\temit_group_store (validize_mem (stack_parm), entry_parm,\n \t\t\t\t  int_size_in_bytes (TREE_TYPE (parm)),\n-\t\t\t\t  (TYPE_ALIGN (TREE_TYPE (parm))\n-\t\t\t\t   / BITS_PER_UNIT));\n+\t\t\t\t  TYPE_ALIGN (TREE_TYPE (parm)));\n \t      else\n \t\tmove_block_from_reg (REGNO (entry_parm),\n \t\t\t\t     validize_mem (stack_parm),"}, {"sha": "61b1547bb27442d47a9db206f2234db3809466ff", "filename": "gcc/optabs.c", "status": "modified", "additions": 11, "deletions": 7, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Foptabs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Foptabs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Foptabs.c?ref=19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "patch": "@@ -2916,6 +2916,7 @@ prepare_cmp_insn (px, py, pcomparison, size, pmode, punsignedp, align,\n   rtx x = *px, y = *py;\n   int unsignedp = *punsignedp;\n   enum mode_class class;\n+  rtx opalign ATTRIBUTE_UNUSED = GEN_INT (align / BITS_PER_UNIT);;\n \n   class = GET_MODE_CLASS (mode);\n \n@@ -2932,10 +2933,12 @@ prepare_cmp_insn (px, py, pcomparison, size, pmode, punsignedp, align,\n \n   /* If we are inside an appropriately-short loop and one operand is an\n      expensive constant, force it into a register.  */\n-  if (CONSTANT_P (x) && preserve_subexpressions_p () && rtx_cost (x, COMPARE) > 2)\n+  if (CONSTANT_P (x) && preserve_subexpressions_p ()\n+      && rtx_cost (x, COMPARE) > 2)\n     x = force_reg (mode, x);\n \n-  if (CONSTANT_P (y) && preserve_subexpressions_p () && rtx_cost (y, COMPARE) > 2)\n+  if (CONSTANT_P (y) && preserve_subexpressions_p ()\n+      && rtx_cost (y, COMPARE) > 2)\n     y = force_reg (mode, y);\n \n #ifdef HAVE_cc0\n@@ -2970,7 +2973,7 @@ prepare_cmp_insn (px, py, pcomparison, size, pmode, punsignedp, align,\n \t{\n \t  result_mode = insn_data[(int) CODE_FOR_cmpstrqi].operand[0].mode;\n \t  result = gen_reg_rtx (result_mode);\n-\t  emit_insn (gen_cmpstrqi (result, x, y, size, GEN_INT (align)));\n+\t  emit_insn (gen_cmpstrqi (result, x, y, size, opalign));\n \t}\n       else\n #endif\n@@ -2981,7 +2984,7 @@ prepare_cmp_insn (px, py, pcomparison, size, pmode, punsignedp, align,\n \t{\n \t  result_mode = insn_data[(int) CODE_FOR_cmpstrhi].operand[0].mode;\n \t  result = gen_reg_rtx (result_mode);\n-\t  emit_insn (gen_cmpstrhi (result, x, y, size, GEN_INT (align)));\n+\t  emit_insn (gen_cmpstrhi (result, x, y, size, opalign));\n \t}\n       else\n #endif\n@@ -2993,7 +2996,7 @@ prepare_cmp_insn (px, py, pcomparison, size, pmode, punsignedp, align,\n \t  size = protect_from_queue (size, 0);\n \t  emit_insn (gen_cmpstrsi (result, x, y,\n \t\t\t\t   convert_to_mode (SImode, size, 1),\n-\t\t\t\t   GEN_INT (align)));\n+\t\t\t\t   opalign));\n \t}\n       else\n #endif\n@@ -3190,7 +3193,7 @@ emit_cmp_and_jump_insns (x, y, comparison, size, mode, unsignedp, align, label)\n      rtx size;\n      enum machine_mode mode;\n      int unsignedp;\n-     int align;\n+     unsigned int align;\n      rtx label;\n {\n   rtx op0;\n@@ -3227,14 +3230,15 @@ emit_cmp_and_jump_insns (x, y, comparison, size, mode, unsignedp, align, label)\n }\n \n /* Like emit_cmp_and_jump_insns, but generate only the comparison.  */\n+\n void\n emit_cmp_insn (x, y, comparison, size, mode, unsignedp, align)\n      rtx x, y;\n      enum rtx_code comparison;\n      rtx size;\n      enum machine_mode mode;\n      int unsignedp;\n-     int align;\n+     unsigned int align;\n {\n   emit_cmp_and_jump_insns (x, y, comparison, size, mode, unsignedp, align, 0);\n }"}, {"sha": "ad1b2c6cbab6eb5fbe9111be8b6ae3c8e1b30c48", "filename": "gcc/stmt.c", "status": "modified", "additions": 4, "deletions": 6, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fstmt.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fstmt.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstmt.c?ref=19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "patch": "@@ -2725,7 +2725,7 @@ expand_value_return (val)\n #endif\n       if (GET_CODE (return_reg) == PARALLEL)\n \temit_group_load (return_reg, val, int_size_in_bytes (type),\n-\t\t\t TYPE_ALIGN (type) / BITS_PER_UNIT);\n+\t\t\t TYPE_ALIGN (type));\n       else\n \temit_move_insn (return_reg, val);\n     }\n@@ -3014,11 +3014,9 @@ expand_return (retval)\n \t  store_bit_field (dst, bitsize, xbitpos % BITS_PER_WORD, word_mode,\n \t\t\t   extract_bit_field (src, bitsize,\n \t\t\t\t\t      bitpos % BITS_PER_WORD, 1,\n-\t\t\t\t\t      NULL_RTX, word_mode,\n-\t\t\t\t\t      word_mode,\n-\t\t\t\t\t      bitsize / BITS_PER_UNIT,\n-\t\t\t\t\t      BITS_PER_WORD),\n-\t\t\t   bitsize / BITS_PER_UNIT, BITS_PER_WORD);\n+\t\t\t\t\t      NULL_RTX, word_mode, word_mode,\n+\t\t\t\t\t      bitsize, BITS_PER_WORD),\n+\t\t\t   bitsize, BITS_PER_WORD);\n \t}\n \n       /* Find the smallest integer mode large enough to hold the"}, {"sha": "008c29cca416cdb0aca248b84ea9943d4025db98", "filename": "gcc/stor-layout.c", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fstor-layout.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f/gcc%2Fstor-layout.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstor-layout.c?ref=19caa751a84a1ff3a90a5dc64e3f4c5cac6ce97f", "patch": "@@ -1767,12 +1767,10 @@ unsigned int\n get_mode_alignment (mode)\n      enum machine_mode mode;\n {\n-  unsigned alignment = GET_MODE_UNIT_SIZE (mode);\n+  unsigned int alignment = GET_MODE_UNIT_SIZE (mode) * BITS_PER_UNIT;\n   \n   /* Extract the LSB of the size.  */\n   alignment = alignment & -alignment;\n-  \n-  alignment *= BITS_PER_UNIT;\n \n   alignment = MIN (BIGGEST_ALIGNMENT, MAX (1, alignment));\n   return alignment;"}]}