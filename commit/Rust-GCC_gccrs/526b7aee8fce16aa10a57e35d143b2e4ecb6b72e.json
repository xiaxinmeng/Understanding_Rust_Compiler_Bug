{"sha": "526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NTI2YjdhZWU4ZmNlMTZhYTEwYTU3ZTM1ZDE0M2IyZTRlY2I2YjcyZQ==", "commit": {"author": {"name": "Saurabh Verma", "email": "saurabh.verma@codito.com", "date": "2013-10-01T17:03:46Z"}, "committer": {"name": "Joern Rennecke", "email": "amylaar@gcc.gnu.org", "date": "2013-10-01T17:03:46Z"}, "message": "arc, arc: New directories.\n\n2013-10-01  Saurabh Verma  <saurabh.verma@codito.com>\n            Ramana Radhakrishnan  <ramana.radhakrishnan@codito.com>\n            Joern Rennecke  <joern.rennecke@embecosm.com>\n            Muhammad Khurram Riaz  <khurram.riaz@arc.com>\n            Brendan Kehoe  <brendan@zen.org>\n            Michael Eager  <eager@eagercon.com>\n            Simon Cook  <simon.cook@embecosm.com>\n            Jeremy Bennett  <jeremy.bennett@embecosm.com>\n\n        * config/arc, common/config/arc: New directories.\n\nCo-Authored-By: Brendan Kehoe <brendan@zen.org>\nCo-Authored-By: Jeremy Bennett <jeremy.bennett@embecosm.com>\nCo-Authored-By: Joern Rennecke <joern.rennecke@embecosm.com>\nCo-Authored-By: Michael Eager <eager@eagercon.com>\nCo-Authored-By: Muhammad Khurram Riaz <khurram.riaz@arc.com>\nCo-Authored-By: Ramana Radhakrishnan <ramana.radhakrishnan@codito.com>\nCo-Authored-By: Simon Cook <simon.cook@embecosm.com>\n\nFrom-SVN: r203072", "tree": {"sha": "75a517d751430164090a2f398e9524f7505b2d62", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/75a517d751430164090a2f398e9524f7505b2d62"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/comments", "author": null, "committer": null, "parents": [{"sha": "2a3e690ab3550c22c6e546ce354a8a91ce3eff14", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2a3e690ab3550c22c6e546ce354a8a91ce3eff14", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2a3e690ab3550c22c6e546ce354a8a91ce3eff14"}], "stats": {"total": 20445, "additions": 20445, "deletions": 0}, "files": [{"sha": "968b0d58506b2e9dc44dc34b825ac2aa95b22b48", "filename": "gcc/ChangeLog", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -1,3 +1,14 @@\n+2013-10-01  Saurabh Verma  <saurabh.verma@codito.com>\n+\t    Ramana Radhakrishnan  <ramana.radhakrishnan@codito.com>\n+\t    Joern Rennecke  <joern.rennecke@embecosm.com>\n+\t    Muhammad Khurram Riaz  <khurram.riaz@arc.com>\n+\t    Brendan Kehoe  <brendan@zen.org>\n+\t    Michael Eager  <eager@eagercon.com>\n+\t    Simon Cook  <simon.cook@embecosm.com>\n+\t    Jeremy Bennett  <jeremy.bennett@embecosm.com>\n+\n+\t* config/arc, common/config/arc: New directories.\n+\n 2013-10-01  Joern Rennecke  <joern.rennecke@embecosm.com>\n \t    Brendan Kehoe  <brendan@zen.org>\n \t    Simon Cook  <simon.cook@embecosm.com>"}, {"sha": "36e60ebc9d8c90c1354864bdac5ce0667f534bee", "filename": "gcc/common/config/arc/arc-common.c", "status": "added", "additions": 117, "deletions": 0, "changes": 117, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fcommon%2Fconfig%2Farc%2Farc-common.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fcommon%2Fconfig%2Farc%2Farc-common.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcommon%2Fconfig%2Farc%2Farc-common.c?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -0,0 +1,117 @@\n+/* Common hooks for Synopsys DesignWare ARC\n+   Copyright (C) 1994, 1995, 1997, 1998, 2007-2013\n+   Free Software Foundation, Inc.\n+   Contributor: Joern Rennecke <joern.rennecke@embecosm.com>\n+\t\ton behalf of Synopsys Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"diagnostic-core.h\"\n+#include \"tm.h\"\n+#include \"common/common-target.h\"\n+#include \"opts.h\"\n+#include \"flags.h\"\n+\n+static void\n+arc_option_init_struct (struct gcc_options *opts)\n+{\n+  opts->x_flag_no_common = 255; /* Mark as not user-initialized.  */\n+\n+  /* Which cpu we're compiling for (A5, ARC600, ARC601, ARC700).  */\n+  arc_cpu = PROCESSOR_NONE;\n+}\n+\n+/* Set default optimization options.  */\n+/* The conditions are incomplete, so we rely on the evaluation order here,\n+   which goes from first to last, i.e. the last match prevails.  */\n+/* ??? But this trick only works for reject_negative options.  Approximate\n+   missing option combination.  */\n+#define OPT_LEVELS_3_PLUS_SPEED_ONLY OPT_LEVELS_3_PLUS\n+static const struct default_options arc_option_optimization_table[] =\n+  {\n+    { OPT_LEVELS_1_PLUS, OPT_fomit_frame_pointer, NULL, 1 },\n+    { OPT_LEVELS_ALL, OPT_mRcq, NULL, 1 },\n+    { OPT_LEVELS_ALL, OPT_mRcw, NULL, 1 },\n+    { OPT_LEVELS_ALL, OPT_msize_level_, NULL, 1 },\n+    { OPT_LEVELS_3_PLUS_SPEED_ONLY, OPT_msize_level_, NULL, 0 },\n+    { OPT_LEVELS_SIZE, OPT_msize_level_, NULL, 3 },\n+    { OPT_LEVELS_3_PLUS_SPEED_ONLY, OPT_malign_call, NULL, 1 },\n+    { OPT_LEVELS_ALL, OPT_mearly_cbranchsi, NULL, 1 },\n+    { OPT_LEVELS_ALL, OPT_mbbit_peephole, NULL, 1 },\n+    { OPT_LEVELS_SIZE, OPT_mq_class, NULL, 1 },\n+    { OPT_LEVELS_SIZE, OPT_mcase_vector_pcrel, NULL, 1 },\n+    { OPT_LEVELS_SIZE, OPT_mcompact_casesi, NULL, 1 },\n+    { OPT_LEVELS_NONE, 0, NULL, 0 }\n+  };\n+\n+/*  Process options.  */\n+static bool\n+arc_handle_option (struct gcc_options *opts, struct gcc_options *opts_set,\n+\t\t   const struct cl_decoded_option *decoded,\n+\t\t   location_t loc)\n+{\n+  size_t code = decoded->opt_index;\n+  int value = decoded->value;\n+\n+  switch (code)\n+    {\n+      static int mcpu_seen = PROCESSOR_NONE;\n+    case OPT_mcpu_:\n+      /* N.B., at this point arc_cpu has already been set to its new value by\n+\t our caller, so comparing arc_cpu with PROCESSOR_NONE is pointless.  */\n+\n+      if (mcpu_seen != PROCESSOR_NONE && mcpu_seen != value)\n+\twarning_at (loc, 0, \"multiple -mcpu= options specified.\");\n+      mcpu_seen = value;\n+\n+      switch (value)\n+\t{\n+\tcase PROCESSOR_A5:\n+\tcase PROCESSOR_ARC600:\n+\tcase PROCESSOR_ARC700:\n+\t  if (! (opts_set->x_target_flags & MASK_BARREL_SHIFTER) )\n+\t    opts->x_target_flags |= MASK_BARREL_SHIFTER;\n+\t  break;\n+\tcase PROCESSOR_ARC601:\n+\t  if (! (opts_set->x_target_flags & MASK_BARREL_SHIFTER) )\n+\t    opts->x_target_flags &= ~MASK_BARREL_SHIFTER;\n+\t  break;\n+\tdefault:\n+\t  gcc_unreachable ();\n+\t}\n+    }\n+\n+  return true;\n+}\n+\n+#define TARGET_OPTION_INIT_STRUCT arc_option_init_struct\n+#define TARGET_OPTION_OPTIMIZATION_TABLE arc_option_optimization_table\n+#define TARGET_HANDLE_OPTION arc_handle_option\n+\n+#define DEFAULT_NO_SDATA (TARGET_SDATA_DEFAULT ? 0 : MASK_NO_SDATA_SET)\n+\n+/* We default to ARC700, which has the barrel shifter enabled.  */\n+#define TARGET_DEFAULT_TARGET_FLAGS \\\n+  (MASK_BARREL_SHIFTER|MASK_VOLATILE_CACHE_SET|DEFAULT_NO_SDATA)\n+\n+\n+#include \"common/common-target-def.h\"\n+\n+struct gcc_targetm_common targetm_common = TARGETM_COMMON_INITIALIZER;"}, {"sha": "e6ec727798e4baf6b0031f0675d12cd79805e97c", "filename": "gcc/config/arc/arc-modes.def", "status": "added", "additions": 37, "deletions": 0, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc-modes.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc-modes.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc-modes.def?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -0,0 +1,37 @@\n+/* Definitions of target machine for GNU compiler, Synopsys DesignWare ARC cpu.\n+   Copyright (C) 2002, 2007-2012 Free Software Foundation, Inc.\n+   Contributor: Joern Rennecke <joern.rennecke@embecosm.com>\n+\t\ton behalf of Synopsys Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+/* Some insns set all condition code flags, some only set the ZNC flags, and\n+   some only set the ZN flags.  */\n+\n+CC_MODE (CC_ZN);\n+CC_MODE (CC_Z);\n+CC_MODE (CC_C);\n+CC_MODE (CC_FP_GT);\n+CC_MODE (CC_FP_GE);\n+CC_MODE (CC_FP_ORD);\n+CC_MODE (CC_FP_UNEQ);\n+CC_MODE (CC_FPX);\n+\n+/* Vector modes.  */\n+VECTOR_MODES (INT, 4);        /*            V4QI V2HI */\n+VECTOR_MODES (INT, 8);        /*       V8QI V4HI V2SI */\n+VECTOR_MODES (INT, 16);       /* V16QI V8HI V4SI V2DI */"}, {"sha": "17ff2286e65921f9465f6b8b67acd156ef8dc6aa", "filename": "gcc/config/arc/arc-opts.h", "status": "added", "additions": 28, "deletions": 0, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc-opts.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc-opts.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc-opts.h?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -0,0 +1,28 @@\n+/* GCC option-handling definitions for the Synopsys DesignWare ARC architecture.\n+\n+   Copyright (C) 2007-2012 Free Software Foundation, Inc.\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify it\n+   under the terms of the GNU General Public License as published\n+   by the Free Software Foundation; either version 3, or (at your\n+   option) any later version.\n+\n+   GCC is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n+   or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public\n+   License for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with GCC; see the file COPYING3.  If not see\n+   <http://www.gnu.org/licenses/>.  */\n+\n+enum processor_type\n+{\n+  PROCESSOR_NONE,\n+  PROCESSOR_A5,\n+  PROCESSOR_ARC600,\n+  PROCESSOR_ARC601,\n+  PROCESSOR_ARC700\n+};"}, {"sha": "0939bc04bb40bfdfa70f7dd25374ba99b1d3455c", "filename": "gcc/config/arc/arc-protos.h", "status": "added", "additions": 118, "deletions": 0, "changes": 118, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc-protos.h?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -0,0 +1,118 @@\n+/* Definitions of target machine for GNU compiler, Synopsys DesignWare ARC cpu.\n+   Copyright (C) 2000, 2007-2013 Free Software Foundation, Inc.\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#ifdef RTX_CODE\n+\n+extern enum machine_mode arc_select_cc_mode (enum rtx_code, rtx, rtx);\n+\n+/* Define the function that build the compare insn for scc, bcc and mov*cc.  */\n+extern struct rtx_def *gen_compare_reg (rtx, enum machine_mode);\n+\n+/* Declarations for various fns used in the .md file.  */\n+extern void arc_output_function_epilogue (FILE *, HOST_WIDE_INT, int);\n+extern const char *output_shift (rtx *);\n+extern bool compact_sda_memory_operand (rtx op,enum machine_mode  mode);\n+extern bool arc_double_limm_p (rtx);\n+extern void arc_print_operand (FILE *, rtx, int);\n+extern void arc_print_operand_address (FILE *, rtx);\n+extern void arc_final_prescan_insn (rtx, rtx *, int);\n+extern void arc_set_default_type_attributes(tree type);\n+extern const char *arc_output_libcall (const char *);\n+extern bool prepare_extend_operands (rtx *operands, enum rtx_code code,\n+\t\t\t\t     enum machine_mode omode);\n+extern int arc_output_addsi (rtx *operands, bool, bool);\n+extern int arc_output_commutative_cond_exec (rtx *operands, bool);\n+extern bool arc_expand_movmem (rtx *operands);\n+extern bool prepare_move_operands (rtx *operands, enum machine_mode mode);\n+extern void emit_shift (enum rtx_code, rtx, rtx, rtx);\n+#endif /* RTX_CODE */\n+\n+#ifdef TREE_CODE\n+extern enum arc_function_type arc_compute_function_type (struct function *);\n+#endif /* TREE_CODE */\n+\n+\n+extern void arc_init (void);\n+extern unsigned int arc_compute_frame_size (int);\n+extern bool arc_ccfsm_branch_deleted_p (void);\n+extern void arc_ccfsm_record_branch_deleted (void);\n+\n+extern rtx arc_legitimize_pic_address (rtx, rtx);\n+void arc_asm_output_aligned_decl_local (FILE *, tree, const char *,\n+\t\t\t\t\tunsigned HOST_WIDE_INT,\n+\t\t\t\t\tunsigned HOST_WIDE_INT,\n+\t\t\t\t\tunsigned HOST_WIDE_INT);\n+extern rtx arc_return_addr_rtx (int , rtx);\n+extern bool check_if_valid_regno_const (rtx *, int);\n+extern bool check_if_valid_sleep_operand (rtx *, int);\n+extern bool arc_legitimate_constant_p (enum machine_mode, rtx);\n+extern bool arc_legitimate_pc_offset_p (rtx);\n+extern bool arc_legitimate_pic_addr_p (rtx);\n+extern void emit_pic_move (rtx *, enum machine_mode);\n+extern bool arc_raw_symbolic_reference_mentioned_p (rtx, bool);\n+extern bool arc_legitimate_pic_operand_p (rtx);\n+extern bool arc_is_longcall_p (rtx);\n+extern bool arc_is_shortcall_p (rtx);\n+extern bool arc_profile_call (rtx callee);\n+extern bool valid_brcc_with_delay_p (rtx *);\n+extern bool small_data_pattern (rtx , enum machine_mode);\n+extern rtx arc_rewrite_small_data (rtx);\n+extern bool arc_ccfsm_cond_exec_p (void);\n+struct secondary_reload_info;\n+extern int arc_register_move_cost (enum machine_mode, enum reg_class,\n+\t\t\t\t   enum reg_class);\n+extern rtx disi_highpart (rtx);\n+extern int arc_adjust_insn_length (rtx, int, bool);\n+extern int arc_corereg_hazard (rtx, rtx);\n+extern int arc_hazard (rtx, rtx);\n+extern int arc_write_ext_corereg (rtx);\n+extern rtx gen_acc1 (void);\n+extern rtx gen_acc2 (void);\n+extern rtx gen_mlo (void);\n+extern rtx gen_mhi (void);\n+extern bool arc_branch_size_unknown_p (void);\n+struct arc_ccfsm;\n+extern void arc_ccfsm_record_condition (rtx, bool, rtx, struct arc_ccfsm *);\n+extern void arc_expand_prologue (void);\n+extern void arc_expand_epilogue (int);\n+extern void arc_init_expanders (void);\n+extern int arc_check_millicode (rtx op, int offset, int load_p);\n+extern int arc_get_unalign (void);\n+extern void arc_clear_unalign (void);\n+extern void arc_toggle_unalign (void);\n+extern void split_addsi (rtx *);\n+extern void split_subsi (rtx *);\n+extern void arc_pad_return (void);\n+extern rtx arc_split_move (rtx *);\n+extern int arc_verify_short (rtx insn, int unalign, int);\n+extern const char *arc_short_long (rtx insn, const char *, const char *);\n+extern rtx arc_regno_use_in (unsigned int, rtx);\n+extern int arc_attr_type (rtx);\n+extern bool arc_scheduling_not_expected (void);\n+extern bool arc_sets_cc_p (rtx insn);\n+extern int arc_label_align (rtx label);\n+extern bool arc_need_delay (rtx insn);\n+extern bool arc_text_label (rtx);\n+extern int arc_decl_pretend_args (tree decl);\n+extern bool arc_short_comparison_p (rtx, int);\n+extern bool arc_epilogue_uses (int regno);\n+/* insn-attrtab.c doesn't include reload.h, which declares regno_clobbered_p. */\n+extern int regno_clobbered_p (unsigned int, rtx, enum machine_mode, int);\n+extern int arc_return_slot_offset (void);\n+extern bool arc_legitimize_reload_address (rtx *, enum machine_mode, int, int);"}, {"sha": "608bd41f80a2a9a11ab570db3da81394bf350565", "filename": "gcc/config/arc/arc-simd.h", "status": "added", "additions": 186, "deletions": 0, "changes": 186, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc-simd.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc-simd.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc-simd.h?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -0,0 +1,186 @@\n+/* Synopsys DesignWare ARC SIMD include file.\n+   Copyright (C) 2007-2012 Free Software Foundation, Inc.\n+   Written by Saurabh Verma (saurabh.verma@celunite.com) on behalf os Synopsys\n+   Inc.\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify it\n+   under the terms of the GNU General Public License as published\n+   by the Free Software Foundation; either version 3, or (at your\n+   option) any later version.\n+\n+   GCC is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n+   or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public\n+   License for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with GCC; see the file COPYING3.  If not see\n+   <http://www.gnu.org/licenses/>.  */\n+\n+/* As a special exception, if you include this header file into source\n+   files compiled by GCC, this header file does not by itself cause\n+   the resulting executable to be covered by the GNU General Public\n+   License.  This exception does not however invalidate any other\n+   reasons why the executable file might be covered by the GNU General\n+   Public License.  */\n+\n+#ifndef _ARC_SIMD_H\n+#define _ARC_SIMD_H 1\n+\n+#ifndef __ARC_SIMD__\n+#error Use the \"-msimd\" flag to enable ARC SIMD support\n+#endif\n+\n+/* I0-I7 registers.  */\n+#define _IREG_I0  0\n+#define _IREG_I1  1\n+#define _IREG_I2  2\n+#define _IREG_I3  3\n+#define _IREG_I4  4\n+#define _IREG_I5  5\n+#define _IREG_I6  6\n+#define _IREG_I7  7\n+\n+/* DMA configuration registers.  */\n+#define _DMA_REG_DR0\t\t0\n+#define _DMA_SDM_SRC_ADR_REG\t_DMA_REG_DR0\n+#define _DMA_SDM_DEST_ADR_REG\t_DMA_REG_DR0\n+\n+#define _DMA_REG_DR1\t\t1\n+#define _DMA_SDM_STRIDE_REG\t_DMA_REG_DR1\n+\n+#define _DMA_REG_DR2\t\t2\n+#define _DMA_BLK_REG\t\t_DMA_REG_DR2\n+\n+#define _DMA_REG_DR3\t\t3\n+#define _DMA_LOC_REG\t\t_DMA_REG_DR3\n+\n+#define _DMA_REG_DR4\t\t4\n+#define _DMA_SYS_SRC_ADR_REG\t_DMA_REG_DR4\n+#define _DMA_SYS_DEST_ADR_REG\t_DMA_REG_DR4\n+\n+#define _DMA_REG_DR5\t\t5\n+#define _DMA_SYS_STRIDE_REG\t_DMA_REG_DR5\n+\n+#define _DMA_REG_DR6\t\t6\n+#define _DMA_CFG_REG\t\t_DMA_REG_DR6\n+\n+#define _DMA_REG_DR7\t\t7\n+#define _DMA_FT_BASE_ADR_REG\t_DMA_REG_DR7\n+\n+/* Predefined types used in vector instructions.  */\n+typedef int   __v4si  __attribute__((vector_size(16)));\n+typedef short __v8hi  __attribute__((vector_size(16)));\n+\n+/* Synonyms */\n+#define _vaddaw    __builtin_arc_vaddaw\n+#define _vaddw     __builtin_arc_vaddw\n+#define _vavb      __builtin_arc_vavb\n+#define _vavrb     __builtin_arc_vavrb\n+#define _vdifaw    __builtin_arc_vdifaw\n+#define _vdifw     __builtin_arc_vdifw\n+#define _vmaxaw    __builtin_arc_vmaxaw\n+#define _vmaxw     __builtin_arc_vmaxw\n+#define _vminaw    __builtin_arc_vminaw\n+#define _vminw     __builtin_arc_vminw\n+#define _vmulaw    __builtin_arc_vmulaw\n+#define _vmulfaw   __builtin_arc_vmulfaw\n+#define _vmulfw    __builtin_arc_vmulfw\n+#define _vmulw     __builtin_arc_vmulw\n+#define _vsubaw    __builtin_arc_vsubaw\n+#define _vsubw     __builtin_arc_vsubw\n+#define _vsummw    __builtin_arc_vsummw\n+#define _vand      __builtin_arc_vand\n+#define _vandaw    __builtin_arc_vandaw\n+#define _vbic      __builtin_arc_vbic\n+#define _vbicaw    __builtin_arc_vbicaw\n+#define _vor       __builtin_arc_vor\n+#define _vxor      __builtin_arc_vxor\n+#define _vxoraw    __builtin_arc_vxoraw\n+#define _veqw      __builtin_arc_veqw\n+#define _vlew      __builtin_arc_vlew\n+#define _vltw      __builtin_arc_vltw\n+#define _vnew      __builtin_arc_vnew\n+#define _vmr1aw    __builtin_arc_vmr1aw\n+#define _vmr1w     __builtin_arc_vmr1w\n+#define _vmr2aw    __builtin_arc_vmr2aw\n+#define _vmr2w     __builtin_arc_vmr2w\n+#define _vmr3aw    __builtin_arc_vmr3aw\n+#define _vmr3w     __builtin_arc_vmr3w\n+#define _vmr4aw    __builtin_arc_vmr4aw\n+#define _vmr4w     __builtin_arc_vmr4w\n+#define _vmr5aw    __builtin_arc_vmr5aw\n+#define _vmr5w     __builtin_arc_vmr5w\n+#define _vmr6aw    __builtin_arc_vmr6aw\n+#define _vmr6w     __builtin_arc_vmr6w\n+#define _vmr7aw    __builtin_arc_vmr7aw\n+#define _vmr7w     __builtin_arc_vmr7w\n+#define _vmrb      __builtin_arc_vmrb\n+#define _vh264f    __builtin_arc_vh264f\n+#define _vh264ft   __builtin_arc_vh264ft\n+#define _vh264fw   __builtin_arc_vh264fw\n+#define _vvc1f     __builtin_arc_vvc1f\n+#define _vvc1ft    __builtin_arc_vvc1ft\n+#define _vbaddw    __builtin_arc_vbaddw\n+#define _vbmaxw    __builtin_arc_vbmaxw\n+#define _vbminw    __builtin_arc_vbminw\n+#define _vbmulaw   __builtin_arc_vbmulaw\n+#define _vbmulfw   __builtin_arc_vbmulfw\n+#define _vbmulw    __builtin_arc_vbmulw\n+#define _vbrsubw   __builtin_arc_vbrsubw\n+#define _vbsubw    __builtin_arc_vbsubw\n+#define _vasrw     __builtin_arc_vasrw\n+#define _vsr8      __builtin_arc_vsr8\n+#define _vsr8aw    __builtin_arc_vsr8aw\n+#define _vasrrwi   __builtin_arc_vasrrwi\n+#define _vasrsrwi  __builtin_arc_vasrsrwi\n+#define _vasrwi    __builtin_arc_vasrwi\n+#define _vasrpwbi  __builtin_arc_vasrpwbi\n+#define _vasrrpwbi __builtin_arc_vasrrpwbi\n+#define _vsr8awi   __builtin_arc_vsr8awi\n+#define _vsr8i     __builtin_arc_vsr8i\n+#define _vmvaw     __builtin_arc_vmvaw\n+#define _vmvw      __builtin_arc_vmvw\n+#define _vmvzw     __builtin_arc_vmvzw\n+#define _vd6tapf   __builtin_arc_vd6tapf\n+#define _vmovaw    __builtin_arc_vmovaw\n+#define _vmovw     __builtin_arc_vmovw\n+#define _vmovzw    __builtin_arc_vmovzw\n+#define _vabsaw    __builtin_arc_vabsaw\n+#define _vabsw     __builtin_arc_vabsw\n+#define _vaddsuw   __builtin_arc_vaddsuw\n+#define _vsignw    __builtin_arc_vsignw\n+#define _vexch1    __builtin_arc_vexch1\n+#define _vexch2    __builtin_arc_vexch2\n+#define _vexch4    __builtin_arc_vexch4\n+#define _vupbaw    __builtin_arc_vupbaw\n+#define _vupbw     __builtin_arc_vupbw\n+#define _vupsbaw   __builtin_arc_vupsbaw\n+#define _vupsbw    __builtin_arc_vupsbw\n+#define _vdirun    __builtin_arc_vdirun\n+#define _vdorun    __builtin_arc_vdorun\n+#define _vdiwr     __builtin_arc_vdiwr\n+#define _vdowr     __builtin_arc_vdowr\n+#define _vrec      __builtin_arc_vrec\n+#define _vrun      __builtin_arc_vrun\n+#define _vrecrun   __builtin_arc_vrecrun\n+#define _vendrec   __builtin_arc_vendrec\n+#define _vld32wh   __builtin_arc_vld32wh\n+#define _vld32wl   __builtin_arc_vld32wl\n+#define _vld64     __builtin_arc_vld64\n+#define _vld32     __builtin_arc_vld32\n+#define _vld64w    __builtin_arc_vld64w\n+#define _vld128    __builtin_arc_vld128\n+#define _vst128    __builtin_arc_vst128\n+#define _vst64     __builtin_arc_vst64\n+#define _vst16_n   __builtin_arc_vst16_n\n+#define _vst32_n   __builtin_arc_vst32_n\n+#define _vinti     __builtin_arc_vinti\n+\n+/* Additional synonyms to ease programming.  */\n+#define _setup_dma_in_channel_reg  _vdiwr\n+#define _setup_dma_out_channel_reg _vdowr\n+\n+#endif /* _ARC_SIMD_H */"}, {"sha": "51ad7d7e9dabf4c3733f18baafc1d6a5ed8308ca", "filename": "gcc/config/arc/arc.c", "status": "added", "additions": 9201, "deletions": 0, "changes": 9201, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc.c?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e"}, {"sha": "637f7b66acc463f7f20051ee04220ee70093ba63", "filename": "gcc/config/arc/arc.h", "status": "added", "additions": 1683, "deletions": 0, "changes": 1683, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc.h?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -0,0 +1,1683 @@\n+/* Definitions of target machine for GNU compiler, Synopsys DesignWare ARC cpu.\n+   Copyright (C) 1994, 1995, 1997, 1998, 2007-2013\n+   Free Software Foundation, Inc.\n+\n+   Sources derived from work done by Sankhya Technologies (www.sankhya.com) on\n+   behalf of Synopsys Inc.\n+\n+   Position Independent Code support added,Code cleaned up,\n+   Comments and Support For ARC700 instructions added by\n+   Saurabh Verma (saurabh.verma@codito.com)\n+   Ramana Radhakrishnan(ramana.radhakrishnan@codito.com)\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 3, or (at your option)\n+any later version.\n+\n+GCC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#ifndef GCC_ARC_H\n+#define GCC_ARC_H\n+\n+/* Things to do:\n+\n+   - incscc, decscc?\n+\n+*/\n+\n+#define SYMBOL_FLAG_SHORT_CALL\t(SYMBOL_FLAG_MACH_DEP << 0)\n+#define SYMBOL_FLAG_MEDIUM_CALL\t(SYMBOL_FLAG_MACH_DEP << 1)\n+#define SYMBOL_FLAG_LONG_CALL\t(SYMBOL_FLAG_MACH_DEP << 2)\n+\n+/* Check if this symbol has a long_call attribute in its declaration */\n+#define SYMBOL_REF_LONG_CALL_P(X)\t\\\n+\t((SYMBOL_REF_FLAGS (X) & SYMBOL_FLAG_LONG_CALL) != 0)\n+\n+/* Check if this symbol has a medium_call attribute in its declaration */\n+#define SYMBOL_REF_MEDIUM_CALL_P(X)\t\\\n+\t((SYMBOL_REF_FLAGS (X) & SYMBOL_FLAG_MEDIUM_CALL) != 0)\n+\n+/* Check if this symbol has a short_call attribute in its declaration */\n+#define SYMBOL_REF_SHORT_CALL_P(X)\t\\\n+\t((SYMBOL_REF_FLAGS (X) & SYMBOL_FLAG_SHORT_CALL) != 0)\n+\n+#undef ASM_SPEC\n+#undef LINK_SPEC\n+#undef STARTFILE_SPEC\n+#undef ENDFILE_SPEC\n+#undef SIZE_TYPE\n+#undef PTRDIFF_TYPE\n+#undef WCHAR_TYPE\n+#undef WCHAR_TYPE_SIZE\n+#undef ASM_APP_ON\n+#undef ASM_APP_OFF\n+#undef CC1_SPEC\n+\n+/* Names to predefine in the preprocessor for this target machine.  */\n+#define TARGET_CPU_CPP_BUILTINS()\t\\\n+ do {\t\t\t\t\t\\\n+    builtin_define (\"__arc__\");\t\t\\\n+    if (TARGET_A5)\t\t\t\\\n+      builtin_define (\"__A5__\");\t\\\n+    else if (TARGET_ARC600)\t\t\t\\\n+      {\t\t\t\t\t\\\n+\tbuiltin_define (\"__A6__\");\t\\\n+\tbuiltin_define (\"__ARC600__\");\t\\\n+      }\t\t\t\t\t\\\n+    else if (TARGET_ARC601)\t\t\t\\\n+      {\t\t\t\t\t\\\n+\tbuiltin_define (\"__ARC601__\");\t\\\n+      }\t\t\t\t\t\\\n+    else if (TARGET_ARC700)\t\t\t\\\n+      {\t\t\t\t\t\\\n+\tbuiltin_define (\"__A7__\");\t\\\n+\tbuiltin_define (\"__ARC700__\");\t\\\n+      }\t\t\t\t\t\\\n+    if (TARGET_NORM)\t\t\t\\\n+      {\t\t\t\t\t\\\n+\tbuiltin_define (\"__ARC_NORM__\");\\\n+\tbuiltin_define (\"__Xnorm\");\t\\\n+      }\t\t\t\t\t\\\n+    if (TARGET_MUL64_SET)\t\t\\\n+      builtin_define (\"__ARC_MUL64__\");\\\n+    if (TARGET_MULMAC_32BY16_SET)\t\\\n+      builtin_define (\"__ARC_MUL32BY16__\");\\\n+    if (TARGET_SIMD_SET)        \t\\\n+      builtin_define (\"__ARC_SIMD__\");\t\\\n+    if (TARGET_BARREL_SHIFTER)\t\t\\\n+      builtin_define (\"__Xbarrel_shifter\");\\\n+    builtin_assert (\"cpu=arc\");\t\t\\\n+    builtin_assert (\"machine=arc\");\t\\\n+    builtin_define (TARGET_BIG_ENDIAN\t\\\n+\t\t    ? \"__BIG_ENDIAN__\" : \"__LITTLE_ENDIAN__\"); \\\n+    if (TARGET_BIG_ENDIAN)\t\t\\\n+      builtin_define (\"__big_endian__\"); \\\n+} while(0)\n+\n+#if DEFAULT_LIBC == LIBC_UCLIBC\n+\n+#define TARGET_OS_CPP_BUILTINS() \\\n+  do \\\n+    { \\\n+      GNU_USER_TARGET_OS_CPP_BUILTINS (); \\\n+    } \\\n+  while (0)\n+#endif\n+\n+/* Match the macros used in the assembler.  */\n+#define CPP_SPEC \"\\\n+%{msimd:-D__Xsimd} %{mno-mpy:-D__Xno_mpy} %{mswap:-D__Xswap} \\\n+%{mmin-max:-D__Xmin_max} %{mEA:-D__Xea} \\\n+%{mspfp*:-D__Xspfp} %{mdpfp*:-D__Xdpfp} \\\n+%{mmac-d16:-D__Xxmac_d16} %{mmac-24:-D__Xxmac_24} \\\n+%{mdsp-packa:-D__Xdsp_packa} %{mcrc:-D__Xcrc} %{mdvbf:-D__Xdvbf} \\\n+%{mtelephony:-D__Xtelephony} %{mxy:-D__Xxy} %{mmul64: -D__Xmult32} \\\n+%{mlock:-D__Xlock} %{mswape:-D__Xswape} %{mrtsc:-D__Xrtsc} \\\n+\"\n+\n+#define CC1_SPEC \"\\\n+%{EB:%{EL:%emay not use both -EB and -EL}} \\\n+%{EB:-mbig-endian} %{EL:-mlittle-endian} \\\n+\"\n+\n+#define ASM_DEFAULT \"-mARC700 -mEA\"\n+\n+#define ASM_SPEC  \"\\\n+%{mbig-endian|EB:-EB} %{EL} \\\n+%{mcpu=A5|mcpu=a5|mA5:-mA5} \\\n+%{mcpu=ARC600:-mARC600} \\\n+%{mcpu=ARC601:-mARC601} \\\n+%{mcpu=ARC700:-mARC700} \\\n+%{mcpu=ARC700:-mEA} \\\n+%{!mcpu=*:\" ASM_DEFAULT \"} \\\n+%{mbarrel-shifter} %{mno-mpy} %{mmul64} %{mmul32x16:-mdsp-packa} %{mnorm} \\\n+%{mswap} %{mEA} %{mmin-max} %{mspfp*} %{mdpfp*} \\\n+%{msimd} \\\n+%{mmac-d16} %{mmac-24} %{mdsp-packa} %{mcrc} %{mdvbf} %{mtelephony} %{mxy} \\\n+%{mcpu=ARC700|!mcpu=*:%{mlock}} \\\n+%{mcpu=ARC700|!mcpu=*:%{mswape}} \\\n+%{mcpu=ARC700|!mcpu=*:%{mrtsc}} \\\n+\"\n+\n+#if DEFAULT_LIBC == LIBC_UCLIBC\n+/* Note that the default is to link against dynamic libraries, if they are\n+   available.  Override with -static.  */\n+#define LINK_SPEC \"%{h*} \\\n+\t\t   %{static:-Bstatic} \\\n+\t\t   %{symbolic:-Bsymbolic} \\\n+\t\t   %{rdynamic:-export-dynamic}\\\n+\t\t   -dynamic-linker /lib/ld-uClibc.so.0 \\\n+\t\t   -X %{mbig-endian:-EB} \\\n+\t\t   %{EB} %{EL} \\\n+\t\t   %{marclinux*} \\\n+\t\t   %{!marclinux*: %{pg|p|profile:-marclinux_prof;: -marclinux}} \\\n+\t\t   %{!z:-z max-page-size=0x2000 -z common-page-size=0x2000} \\\n+\t\t   %{shared:-shared}\"\n+/* Like the standard LINK_COMMAND_SPEC, but add %G when building\n+   a shared library with -nostdlib, so that the hidden functions of libgcc\n+   will be incorporated.\n+   N.B., we don't want a plain -lgcc, as this would lead to re-exporting\n+   non-hidden functions, so we have to consider libgcc_s.so.* first, which in\n+   turn should be wrapped with --as-needed.  */\n+#define LINK_COMMAND_SPEC \"\\\n+%{!fsyntax-only:%{!c:%{!M:%{!MM:%{!E:%{!S:\\\n+    %(linker) %l \" LINK_PIE_SPEC \"%X %{o*} %{A} %{d} %{e*} %{m} %{N} %{n} %{r}\\\n+    %{s} %{t} %{u*} %{x} %{z} %{Z} %{!A:%{!nostdlib:%{!nostartfiles:%S}}}\\\n+    %{static:} %{L*} %(mfwrap) %(link_libgcc) %o\\\n+    %{fopenmp:%:include(libgomp.spec)%(link_gomp)} %(mflib)\\\n+    %{fprofile-arcs|fprofile-generate|coverage:-lgcov}\\\n+    %{!nostdlib:%{!nodefaultlibs:%(link_ssp) %(link_gcc_c_sequence)}}\\\n+    %{!A:%{!nostdlib:%{!nostartfiles:%E}}} %{T*} }}}}}}\"\n+\n+#else\n+#define LINK_SPEC \"%{mbig-endian:-EB} %{EB} %{EL}\\\n+  %{pg|p:-marcelf_prof;mA7|mARC700|mcpu=arc700|mcpu=ARC700: -marcelf}\"\n+#endif\n+\n+#if DEFAULT_LIBC != LIBC_UCLIBC\n+#define STARTFILE_SPEC \"%{!shared:crt0.o%s} crti%O%s %{pg|p:crtg.o%s} crtbegin.o%s\"\n+#else\n+#define STARTFILE_SPEC   \"%{!shared:%{!mkernel:crt1.o%s}} crti.o%s \\\n+  %{!shared:%{pg|p|profile:crtg.o%s} crtbegin.o%s} %{shared:crtbeginS.o%s}\"\n+\n+#endif\n+\n+#if DEFAULT_LIBC != LIBC_UCLIBC\n+#define ENDFILE_SPEC \"%{pg|p:crtgend.o%s} crtend.o%s crtn%O%s\"\n+#else\n+#define ENDFILE_SPEC \"%{!shared:%{pg|p|profile:crtgend.o%s} crtend.o%s} \\\n+  %{shared:crtendS.o%s} crtn.o%s\"\n+\n+#endif\n+\n+#if DEFAULT_LIBC == LIBC_UCLIBC\n+#undef LIB_SPEC\n+#define LIB_SPEC  \\\n+  \"%{pthread:-lpthread} \\\n+   %{shared:-lc} \\\n+   %{!shared:%{pg|p|profile:-lgmon -u profil --defsym __profil=profil} -lc}\"\n+#define TARGET_ASM_FILE_END file_end_indicate_exec_stack\n+#else\n+#undef LIB_SPEC\n+/* -lc_p not present for arc-elf32-* : ashwin */\n+#define LIB_SPEC \"%{!shared:%{g*:-lg} %{pg|p:-lgmon} -lc}\"\n+#endif\n+\n+#ifndef DRIVER_ENDIAN_SELF_SPECS\n+#define DRIVER_ENDIAN_SELF_SPECS \"\"\n+#endif\n+#ifndef TARGET_SDATA_DEFAULT\n+#define TARGET_SDATA_DEFAULT 1\n+#endif\n+#ifndef TARGET_MMEDIUM_CALLS_DEFAULT\n+#define TARGET_MMEDIUM_CALLS_DEFAULT 0\n+#endif\n+\n+#define DRIVER_SELF_SPECS DRIVER_ENDIAN_SELF_SPECS \\\n+  \"%{mARC5|mA5: -mcpu=A5 %<mARC5 %<mA5}\" \\\n+  \"%{mARC600|mA6: -mcpu=ARC600 %<mARC600 %<mA6}\" \\\n+  \"%{mARC601: -mcpu=ARC601 %<mARC601}\" \\\n+  \"%{mARC700|mA7: -mcpu=ARC700 %<mARC700 %<mA7}\" \\\n+  \"%{mbarrel_shifte*: -mbarrel-shifte%* %<mbarrel_shifte*}\" \\\n+  \"%{mEA: -mea %<mEA}\" \\\n+  \"%{mspfp_*: -mspfp-%* %<mspfp_*}\" \\\n+  \"%{mdpfp_*: -mdpfp-%* %<mdpfp_*}\" \\\n+  \"%{mdsp_pack*: -mdsp-pack%* %<mdsp_pack*}\" \\\n+  \"%{mmac_*: -mmac-%* %<mmac_*}\" \\\n+  \"%{multcost=*: -mmultcost=%* %<multcost=*}\"\n+\n+/* Run-time compilation parameters selecting different hardware subsets.  */\n+\n+#define TARGET_MIXED_CODE (TARGET_MIXED_CODE_SET)\n+\n+#define TARGET_SPFP (TARGET_SPFP_FAST_SET || TARGET_SPFP_COMPACT_SET)\n+#define TARGET_DPFP (TARGET_DPFP_FAST_SET || TARGET_DPFP_COMPACT_SET)\n+\n+#define SUBTARGET_SWITCHES\n+\n+/* Instruction set characteristics.\n+   These are internal macros, set by the appropriate -m option.  */\n+\n+/* Non-zero means the cpu supports norm instruction.  This flag is set by\n+   default for A7, and only for pre A7 cores when -mnorm is given.  */\n+#define TARGET_NORM (TARGET_ARC700 || TARGET_NORM_SET)\n+/* Indicate if an optimized floating point emulation library is available.  */\n+#define TARGET_OPTFPE \\\n+ (TARGET_ARC700 \\\n+  /* We need a barrel shifter and NORM.  */ \\\n+  || (TARGET_ARC600 && TARGET_NORM_SET))\n+\n+/* Non-zero means the cpu supports swap instruction.  This flag is set by\n+   default for A7, and only for pre A7 cores when -mswap is given.  */\n+#define TARGET_SWAP (TARGET_ARC700 || TARGET_SWAP_SET)\n+\n+/* Provide some macros for size / scheduling features of the ARC700, so\n+   that we can pick & choose features if we get a new cpu family member.  */\n+\n+/* Should we try to unalign likely taken branches without a delay slot.  */\n+#define TARGET_UNALIGN_BRANCH (TARGET_ARC700 && !optimize_size)\n+\n+/* Should we upsize short delayed branches with a short delay insn?  */\n+#define TARGET_UPSIZE_DBR (TARGET_ARC700 && !optimize_size)\n+\n+/* Should we add padding before a return insn to avoid mispredict?  */\n+#define TARGET_PAD_RETURN (TARGET_ARC700 && !optimize_size)\n+\n+/* For an anulled-true delay slot insn for a delayed branch, should we only\n+   use conditional execution?  */\n+#define TARGET_AT_DBR_CONDEXEC  (!TARGET_ARC700)\n+\n+#define TARGET_A5 (arc_cpu == PROCESSOR_A5)\n+#define TARGET_ARC600 (arc_cpu == PROCESSOR_ARC600)\n+#define TARGET_ARC601 (arc_cpu == PROCESSOR_ARC601)\n+#define TARGET_ARC700 (arc_cpu == PROCESSOR_ARC700)\n+\n+/* Recast the cpu class to be the cpu attribute.  */\n+#define arc_cpu_attr ((enum attr_cpu)arc_cpu)\n+\n+#ifndef MULTILIB_DEFAULTS\n+#define MULTILIB_DEFAULTS { \"mARC700\" }\n+#endif\n+\n+/* Target machine storage layout.  */\n+\n+/* We want zero_extract to mean the same\n+   no matter what the byte endianness is.  */\n+#define BITS_BIG_ENDIAN 0\n+\n+/* Define this if most significant byte of a word is the lowest numbered.  */\n+#define BYTES_BIG_ENDIAN (TARGET_BIG_ENDIAN)\n+\n+/* Define this if most significant word of a multiword number is the lowest\n+   numbered.  */\n+#define WORDS_BIG_ENDIAN (TARGET_BIG_ENDIAN)\n+\n+/* Number of bits in an addressable storage unit.  */\n+#define BITS_PER_UNIT 8\n+\n+/* Width in bits of a \"word\", which is the contents of a machine register.\n+   Note that this is not necessarily the width of data type `int';\n+   if using 16-bit ints on a 68000, this would still be 32.\n+   But on a machine with 16-bit registers, this would be 16.  */\n+#define BITS_PER_WORD 32\n+\n+/* Width of a word, in units (bytes).  */\n+#define UNITS_PER_WORD 4\n+\n+/* Define this macro if it is advisable to hold scalars in registers\n+   in a wider mode than that declared by the program.  In such cases,\n+   the value is constrained to be within the bounds of the declared\n+   type, but kept valid in the wider mode.  The signedness of the\n+   extension may differ from that of the type.  */\n+#define PROMOTE_MODE(MODE,UNSIGNEDP,TYPE) \\\n+if (GET_MODE_CLASS (MODE) == MODE_INT\t\t\\\n+    && GET_MODE_SIZE (MODE) < UNITS_PER_WORD)\t\\\n+{\t\t\t\t\t\t\\\n+  (MODE) = SImode;\t\t\t\t\\\n+}\n+\n+/* Width in bits of a pointer.\n+   See also the macro `Pmode' defined below.  */\n+#define POINTER_SIZE 32\n+\n+/* Allocation boundary (in *bits*) for storing arguments in argument list.  */\n+#define PARM_BOUNDARY 32\n+\n+/* Boundary (in *bits*) on which stack pointer should be aligned.  */\n+/* TOCHECK: Changed from 64 to 32 */\n+#define STACK_BOUNDARY 32\n+\n+/* ALIGN FRAMES on word boundaries.  */\n+#define ARC_STACK_ALIGN(LOC) \\\n+  (((LOC) + STACK_BOUNDARY / BITS_PER_UNIT - 1) & -STACK_BOUNDARY/BITS_PER_UNIT)\n+\n+/* Allocation boundary (in *bits*) for the code of a function.  */\n+#define FUNCTION_BOUNDARY 32\n+\n+/* Alignment of field after `int : 0' in a structure.  */\n+#define EMPTY_FIELD_BOUNDARY 32\n+\n+/* Every structure's size must be a multiple of this.  */\n+#define STRUCTURE_SIZE_BOUNDARY 8\n+\n+/* A bitfield declared as `int' forces `int' alignment for the struct.  */\n+#define PCC_BITFIELD_TYPE_MATTERS 1\n+\n+/* An expression for the alignment of a structure field FIELD if the\n+   alignment computed in the usual way (including applying of\n+   `BIGGEST_ALIGNMENT' and `BIGGEST_FIELD_ALIGNMENT' to the\n+   alignment) is COMPUTED.  It overrides alignment only if the field\n+   alignment has not been set by the `__attribute__ ((aligned (N)))'\n+   construct.\n+*/\n+\n+#define ADJUST_FIELD_ALIGN(FIELD, COMPUTED) \\\n+(TYPE_MODE (strip_array_types (TREE_TYPE (FIELD))) == DFmode \\\n+ ? MIN ((COMPUTED), 32) : (COMPUTED))\n+\n+\n+\n+/* No data type wants to be aligned rounder than this.  */\n+/* This is bigger than currently necessary for the ARC.  If 8 byte floats are\n+   ever added it's not clear whether they'll need such alignment or not.  For\n+   now we assume they will.  We can always relax it if necessary but the\n+   reverse isn't true.  */\n+/* TOCHECK: Changed from 64 to 32 */\n+#define BIGGEST_ALIGNMENT 32\n+\n+/* The best alignment to use in cases where we have a choice.  */\n+#define FASTEST_ALIGNMENT 32\n+\n+/* Make strings word-aligned so strcpy from constants will be faster.  */\n+#define CONSTANT_ALIGNMENT(EXP, ALIGN)  \\\n+  ((TREE_CODE (EXP) == STRING_CST\t\\\n+    && (ALIGN) < FASTEST_ALIGNMENT)\t\\\n+   ? FASTEST_ALIGNMENT : (ALIGN))\n+\n+\n+/* Make arrays of chars word-aligned for the same reasons.  */\n+#define LOCAL_ALIGNMENT(TYPE, ALIGN)             \\\n+  (TREE_CODE (TYPE) == ARRAY_TYPE               \\\n+   && TYPE_MODE (TREE_TYPE (TYPE)) == QImode    \\\n+   && (ALIGN) < FASTEST_ALIGNMENT ? FASTEST_ALIGNMENT : (ALIGN))\n+\n+#define DATA_ALIGNMENT(TYPE, ALIGN)\t\t\\\n+  (TREE_CODE (TYPE) == ARRAY_TYPE\t\t\\\n+   && TYPE_MODE (TREE_TYPE (TYPE)) == QImode\t\\\n+   && arc_size_opt_level < 3\t\t\t\\\n+   && (ALIGN) < FASTEST_ALIGNMENT ? FASTEST_ALIGNMENT : (ALIGN))\n+\n+/* Set this nonzero if move instructions will actually fail to work\n+   when given unaligned data.  */\n+/* On the ARC the lower address bits are masked to 0 as necessary.  The chip\n+   won't croak when given an unaligned address, but the insn will still fail\n+   to produce the correct result.  */\n+#define STRICT_ALIGNMENT 1\n+\n+/* Layout of source language data types.  */\n+\n+#define SHORT_TYPE_SIZE\t\t16\n+#define INT_TYPE_SIZE\t\t32\n+#define LONG_TYPE_SIZE\t\t32\n+#define LONG_LONG_TYPE_SIZE\t64\n+#define FLOAT_TYPE_SIZE\t\t32\n+#define DOUBLE_TYPE_SIZE\t64\n+#define LONG_DOUBLE_TYPE_SIZE\t64\n+\n+/* Define this as 1 if `char' should by default be signed; else as 0.  */\n+#define DEFAULT_SIGNED_CHAR 0\n+\n+#define SIZE_TYPE \"long unsigned int\"\n+#define PTRDIFF_TYPE \"long int\"\n+#define WCHAR_TYPE \"int\"\n+#define WCHAR_TYPE_SIZE 32\n+\n+\n+/* ashwin : shifted from arc.c:102 */\n+#define PROGRAM_COUNTER_REGNO 63\n+\n+/* Standard register usage.  */\n+\n+/* Number of actual hardware registers.\n+   The hardware registers are assigned numbers for the compiler\n+   from 0 to just below FIRST_PSEUDO_REGISTER.\n+   All registers that the compiler knows about must be given numbers,\n+   even those that are not normally considered general registers.\n+\n+   Registers 61, 62, and 63 are not really registers and we needn't treat\n+   them as such.  We still need a register for the condition code and\n+   argument pointer.  */\n+\n+/* r63 is pc, r64-r127 = simd vregs, r128-r143 = simd dma config regs\n+   r144, r145 = lp_start, lp_end\n+   and therefore the pseudo registers start from r146. */\n+#define FIRST_PSEUDO_REGISTER 146\n+\n+/* 1 for registers that have pervasive standard uses\n+   and are not available for the register allocator.\n+\n+   0-28  - general purpose registers\n+   29    - ilink1 (interrupt link register)\n+   30    - ilink2 (interrupt link register)\n+   31    - blink (branch link register)\n+   32-59 - reserved for extensions\n+   60    - LP_COUNT\n+   61    - condition code\n+   62    - argument pointer\n+   63    - program counter\n+\n+   FWIW, this is how the 61-63 encodings are used by the hardware:\n+   61    - reserved\n+   62    - long immediate data indicator\n+   63    - PCL (program counter aligned to 32 bit, read-only)\n+\n+   The general purpose registers are further broken down into:\n+\n+   0-7   - arguments/results\n+   8-12  - call used (r11 - static chain pointer)\n+   13-25 - call saved\n+   26    - global pointer\n+   27    - frame pointer\n+   28    - stack pointer\n+   29    - ilink1\n+   30    - ilink2\n+   31    - return address register\n+\n+   By default, the extension registers are not available.  */\n+/* Present implementations only have VR0-VR23 only.  */\n+/* ??? FIXME: r27 and r31 should not be fixed registers.  */\n+#define FIXED_REGISTERS \\\n+{ 0, 0, 0, 0, 0, 0, 0, 0,\t\\\n+  0, 0, 0, 0, 0, 0, 0, 0,\t\\\n+  0, 0, 0, 0, 0, 0, 0, 0,\t\\\n+  0, 0, 1, 1, 1, 1, 1, 1,\t\\\n+\t\t\t\t\\\n+  1, 1, 1, 1, 1, 1, 1, 1,\t\\\n+  0, 0, 0, 0, 1, 1, 1, 1,\t\\\n+  1, 1, 1, 1, 1, 1, 1, 1,\t\\\n+  1, 1, 1, 1, 0, 1, 1, 1,       \\\n+\t\t\t\t\\\n+  0, 0, 0, 0, 0, 0, 0, 0,       \\\n+  0, 0, 0, 0, 0, 0, 0, 0,       \\\n+  0, 0, 0, 0, 0, 0, 0, 0,       \\\n+  1, 1, 1, 1, 1, 1, 1, 1,       \\\n+\t\t\t\t\\\n+  1, 1, 1, 1, 1, 1, 1, 1,       \\\n+  1, 1, 1, 1, 1, 1, 1, 1,       \\\n+  1, 1, 1, 1, 1, 1, 1, 1,       \\\n+  1, 1, 1, 1, 1, 1, 1, 1,       \\\n+\t\t\t\t\\\n+  0, 0, 0, 0, 0, 0, 0, 0,       \\\n+  0, 0, 0, 0, 0, 0, 0, 0,\t\\\n+  1, 1}\n+\n+/* 1 for registers not available across function calls.\n+   These must include the FIXED_REGISTERS and also any\n+   registers that can be used without being saved.\n+   The latter must include the registers where values are returned\n+   and the register where structure-value addresses are passed.\n+   Aside from that, you can include as many other registers as you like.  */\n+#define CALL_USED_REGISTERS     \\\n+{                               \\\n+  1, 1, 1, 1, 1, 1, 1, 1,\t\\\n+  1, 1, 1, 1, 1, 0, 0, 0,\t\\\n+  0, 0, 0, 0, 0, 0, 0, 0,\t\\\n+  0, 0, 1, 1, 1, 1, 1, 1,\t\\\n+\t\t\t\t\\\n+  1, 1, 1, 1, 1, 1, 1, 1,\t\\\n+  1, 1, 1, 1, 1, 1, 1, 1,\t\\\n+  1, 1, 1, 1, 1, 1, 1, 1,\t\\\n+  1, 1, 1, 1, 1, 1, 1, 1,       \\\n+\t\t\t\t\\\n+  0, 0, 0, 0, 0, 0, 0, 0,       \\\n+  0, 0, 0, 0, 0, 0, 0, 0,       \\\n+  0, 0, 0, 0, 0, 0, 0, 0,       \\\n+  1, 1, 1, 1, 1, 1, 1, 1,       \\\n+\t\t\t\t\\\n+  1, 1, 1, 1, 1, 1, 1, 1,       \\\n+  1, 1, 1, 1, 1, 1, 1, 1,       \\\n+  1, 1, 1, 1, 1, 1, 1, 1,       \\\n+  1, 1, 1, 1, 1, 1, 1, 1,       \\\n+\t\t\t\t\\\n+  0, 0, 0, 0, 0, 0, 0, 0,       \\\n+  0, 0, 0, 0, 0, 0, 0, 0,\t\\\n+  1, 1}\n+\n+/* If defined, an initializer for a vector of integers, containing the\n+   numbers of hard registers in the order in which GCC should\n+   prefer to use them (from most preferred to least).  */\n+#define REG_ALLOC_ORDER \\\n+{ 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 0, 1,\t\t\t\\\n+  16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, \t\t\t\t\\\n+  32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\t\\\n+  48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62,\t\t\\\n+  27, 28, 29, 30, 31, 63}\n+\n+/* Return number of consecutive hard regs needed starting at reg REGNO\n+   to hold something of mode MODE.\n+   This is ordinarily the length in words of a value of mode MODE\n+   but can be less for certain modes in special long registers.  */\n+#define HARD_REGNO_NREGS(REGNO, MODE) \\\n+((GET_MODE_SIZE (MODE) == 16 \\\n+  && REGNO >= ARC_FIRST_SIMD_VR_REG && REGNO <= ARC_LAST_SIMD_VR_REG) ? 1 \\\n+ : (GET_MODE_SIZE (MODE) + UNITS_PER_WORD - 1) / UNITS_PER_WORD)\n+\n+/* Value is 1 if hard register REGNO can hold a value of machine-mode MODE.  */\n+extern unsigned int arc_hard_regno_mode_ok[];\n+extern unsigned int arc_mode_class[];\n+#define HARD_REGNO_MODE_OK(REGNO, MODE) \\\n+((arc_hard_regno_mode_ok[REGNO] & arc_mode_class[MODE]) != 0)\n+\n+/* A C expression that is nonzero if it is desirable to choose\n+   register allocation so as to avoid move instructions between a\n+   value of mode MODE1 and a value of mode MODE2.\n+\n+   If `HARD_REGNO_MODE_OK (R, MODE1)' and `HARD_REGNO_MODE_OK (R,\n+   MODE2)' are ever different for any R, then `MODES_TIEABLE_P (MODE1,\n+   MODE2)' must be zero.  */\n+\n+/* Tie QI/HI/SI modes together.  */\n+#define MODES_TIEABLE_P(MODE1, MODE2) \\\n+(GET_MODE_CLASS (MODE1) == MODE_INT\t\t\\\n+ && GET_MODE_CLASS (MODE2) == MODE_INT\t\t\\\n+ && GET_MODE_SIZE (MODE1) <= UNITS_PER_WORD\t\\\n+ && GET_MODE_SIZE (MODE2) <= UNITS_PER_WORD)\n+\n+/* Internal macros to classify a register number as to whether it's a\n+   general purpose register for compact insns (r0-r3,r12-r15), or\n+   stack pointer (r28).  */\n+\n+#define COMPACT_GP_REG_P(REGNO) \\\n+   (((signed)(REGNO) >= 0 && (REGNO) <= 3) || ((REGNO) >= 12 && (REGNO) <= 15))\n+#define SP_REG_P(REGNO)  ((REGNO) == 28)\n+\n+\n+\n+/* Register classes and constants.  */\n+\n+/* Define the classes of registers for register constraints in the\n+   machine description.  Also define ranges of constants.\n+\n+   One of the classes must always be named ALL_REGS and include all hard regs.\n+   If there is more than one class, another class must be named NO_REGS\n+   and contain no registers.\n+\n+   The name GENERAL_REGS must be the name of a class (or an alias for\n+   another name such as ALL_REGS).  This is the class of registers\n+   that is allowed by \"g\" or \"r\" in a register constraint.\n+   Also, registers outside this class are allocated only when\n+   instructions express preferences for them.\n+\n+   The classes must be numbered in nondecreasing order; that is,\n+   a larger-numbered class must never be contained completely\n+   in a smaller-numbered class.\n+\n+   For any two classes, it is very desirable that there be another\n+   class that represents their union.\n+\n+   It is important that any condition codes have class NO_REGS.\n+   See `register_operand'.  */\n+\n+enum reg_class\n+{\n+   NO_REGS,\n+   R0_REGS,\t\t\t/* 'x' */\n+   GP_REG,\t\t\t/* 'Rgp' */\n+   FP_REG,\t\t\t/* 'f' */\n+   SP_REGS,\t\t\t/* 'b' */\n+   LPCOUNT_REG, \t\t/* 'l' */\n+   LINK_REGS,\t \t\t/* 'k' */\n+   DOUBLE_REGS,\t\t\t/* D0, D1 */\n+   SIMD_VR_REGS,\t\t/* VR00-VR63 */\n+   SIMD_DMA_CONFIG_REGS,\t/* DI0-DI7,DO0-DO7 */\n+   ARCOMPACT16_REGS,\t\t/* 'q' */\n+   AC16_BASE_REGS,  \t\t/* 'e' */\n+   SIBCALL_REGS,\t\t/* \"Rsc\" */\n+   GENERAL_REGS,\t\t/* 'r' */\n+   MPY_WRITABLE_CORE_REGS,\t/* 'W' */\n+   WRITABLE_CORE_REGS,\t\t/* 'w' */\n+   CHEAP_CORE_REGS,\t\t/* 'c' */\n+   ALL_CORE_REGS,\t\t/* 'Rac' */\n+   ALL_REGS,\n+   LIM_REG_CLASSES\n+};\n+\n+#define N_REG_CLASSES (int) LIM_REG_CLASSES\n+\n+/* Give names of register classes as strings for dump file.   */\n+#define REG_CLASS_NAMES\t  \\\n+{                         \\\n+  \"NO_REGS\",           \t  \\\n+  \"R0_REGS\",            \t  \\\n+  \"GP_REG\",            \t  \\\n+  \"FP_REG\",            \t  \\\n+  \"SP_REGS\",\t\t  \\\n+  \"LPCOUNT_REG\",\t  \\\n+  \"LINK_REGS\",         \t  \\\n+  \"DOUBLE_REGS\",          \\\n+  \"SIMD_VR_REGS\",         \\\n+  \"SIMD_DMA_CONFIG_REGS\", \\\n+  \"ARCOMPACT16_REGS\",  \t  \\\n+  \"AC16_BASE_REGS\",       \\\n+  \"SIBCALL_REGS\",\t  \\\n+  \"GENERAL_REGS\",      \t  \\\n+  \"MPY_WRITABLE_CORE_REGS\",   \\\n+  \"WRITABLE_CORE_REGS\",   \\\n+  \"CHEAP_CORE_REGS\",\t  \\\n+  \"ALL_CORE_REGS\",\t  \\\n+  \"ALL_REGS\"          \t  \\\n+}\n+\n+/* Define which registers fit in which classes.\n+   This is an initializer for a vector of HARD_REG_SET\n+   of length N_REG_CLASSES.  */\n+\n+#define REG_CLASS_CONTENTS \\\n+{\t\t\t\t\t\t\t\t\t\t\t\t\t\\\n+  {0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000},\t     /* No Registers */\t\t\t\\\n+  {0x00000001, 0x00000000, 0x00000000, 0x00000000, 0x00000000},      /* 'x', r0 register , r0 */\t\\\n+  {0x04000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000},      /* 'Rgp', Global Pointer, r26 */\t\\\n+  {0x08000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000},      /* 'f', Frame Pointer, r27 */\t\\\n+  {0x10000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000},      /* 'b', Stack Pointer, r28 */\t\\\n+  {0x00000000, 0x10000000, 0x00000000, 0x00000000, 0x00000000},      /* 'l', LPCOUNT Register, r60 */\t\\\n+  {0xe0000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000},      /* 'k', LINK Registers, r29-r31 */\t\\\n+  {0x00000000, 0x00000f00, 0x00000000, 0x00000000, 0x00000000},      /* 'D', D1, D2 Registers */\t\\\n+  {0x00000000, 0x00000000, 0xffffffff, 0xffffffff, 0x00000000},      /* 'V', VR00-VR63 Registers */\t\\\n+  {0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x0000ffff},      /* 'V', DI0-7,DO0-7 Registers */\t\\\n+  {0x0000f00f, 0x00000000, 0x00000000, 0x00000000, 0x00000000},\t     /* 'q', r0-r3, r12-r15 */\t\t\\\n+  {0x1000f00f, 0x00000000, 0x00000000, 0x00000000, 0x00000000},\t     /* 'e', r0-r3, r12-r15, sp */\t\\\n+  {0x1c001fff, 0x00000000, 0x00000000, 0x00000000, 0x00000000},    /* \"Rsc\", r0-r12 */ \\\n+  {0x9fffffff, 0xc0000000, 0x00000000, 0x00000000, 0x00000000},      /* 'r', r0-r28, blink, ap and pcl */\t\\\n+  {0xffffffff, 0x00000000, 0x00000000, 0x00000000, 0x00000000},      /* 'W',  r0-r31 */ \\\n+  /* Include ap / pcl in WRITABLE_CORE_REGS for sake of symmetry.  As these \\\n+     registers are fixed, it does not affect the literal meaning of the \\\n+     constraints, but it makes it a superset of GENERAL_REGS, thus \\\n+     enabling some operations that would otherwise not be possible.  */ \\\n+  {0xffffffff, 0xd0000000, 0x00000000, 0x00000000, 0x00000000},      /* 'w', r0-r31, r60 */ \\\n+  {0xffffffff, 0xdfffffff, 0x00000000, 0x00000000, 0x00000000},      /* 'c', r0-r60, ap, pcl */ \\\n+  {0xffffffff, 0xdfffffff, 0x00000000, 0x00000000, 0x00000000},      /* 'Rac', r0-r60, ap, pcl */ \\\n+  {0xffffffff, 0xffffffff, 0xffffffff, 0xffffffff, 0x0003ffff}       /* All Registers */\t\t\\\n+}\n+\n+/* Local macros to mark the first and last regs of different classes.  */\n+#define ARC_FIRST_SIMD_VR_REG              64\n+#define ARC_LAST_SIMD_VR_REG               127\n+\n+#define ARC_FIRST_SIMD_DMA_CONFIG_REG      128\n+#define ARC_FIRST_SIMD_DMA_CONFIG_IN_REG   128\n+#define ARC_FIRST_SIMD_DMA_CONFIG_OUT_REG  136\n+#define ARC_LAST_SIMD_DMA_CONFIG_REG       143\n+\n+/* The same information, inverted:\n+   Return the class number of the smallest class containing\n+   reg number REGNO.  This could be a conditional expression\n+   or could index an array.  */\n+\n+extern enum reg_class arc_regno_reg_class[];\n+\n+#define REGNO_REG_CLASS(REGNO) (arc_regno_reg_class[REGNO])\n+\n+/* The class value for valid index registers. An index register is\n+   one used in an address where its value is either multiplied by\n+   a scale factor or added to another register (as well as added to a\n+   displacement).  */\n+\n+#define INDEX_REG_CLASS (TARGET_MIXED_CODE ? ARCOMPACT16_REGS : GENERAL_REGS)\n+\n+/* The class value for valid base registers. A base register is one used in\n+   an address which is the register value plus a displacement.  */\n+\n+#define BASE_REG_CLASS (TARGET_MIXED_CODE ? AC16_BASE_REGS : GENERAL_REGS)\n+\n+/* These assume that REGNO is a hard or pseudo reg number.\n+   They give nonzero only if REGNO is a hard reg of the suitable class\n+   or a pseudo reg currently allocated to a suitable hard reg.\n+   Since they use reg_renumber, they are safe only once reg_renumber\n+   has been allocated, which happens in local-alloc.c.  */\n+#define REGNO_OK_FOR_BASE_P(REGNO) \\\n+((REGNO) < 29 || ((REGNO) == ARG_POINTER_REGNUM) || ((REGNO) == 63) ||\\\n+ (unsigned) reg_renumber[REGNO] < 29)\n+\n+#define REGNO_OK_FOR_INDEX_P(REGNO) REGNO_OK_FOR_BASE_P(REGNO)\n+\n+/* Given an rtx X being reloaded into a reg required to be\n+   in class CLASS, return the class of reg to actually use.\n+   In general this is just CLASS; but on some machines\n+   in some cases it is preferable to use a more restrictive class.  */\n+\n+#define PREFERRED_RELOAD_CLASS(X, CLASS) \\\n+  arc_preferred_reload_class((X), (CLASS))\n+\n+  extern enum reg_class arc_preferred_reload_class (rtx, enum reg_class);\n+\n+/* Return the maximum number of consecutive registers\n+   needed to represent mode MODE in a register of class CLASS.  */\n+\n+#define CLASS_MAX_NREGS(CLASS, MODE) \\\n+(( GET_MODE_SIZE (MODE) == 16 && CLASS == SIMD_VR_REGS) ? 1: \\\n+((GET_MODE_SIZE (MODE) + UNITS_PER_WORD - 1) / UNITS_PER_WORD))\n+\n+#define SMALL_INT(X) ((unsigned) ((X) + 0x100) < 0x200)\n+#define SMALL_INT_RANGE(X, OFFSET, SHIFT) \\\n+  ((unsigned) (((X) >> (SHIFT)) + 0x100) \\\n+   < 0x200 - ((unsigned) (OFFSET) >> (SHIFT)))\n+#define SIGNED_INT12(X) ((unsigned) ((X) + 0x800) < 0x1000)\n+#define LARGE_INT(X) \\\n+(((X) < 0) \\\n+ ? (X) >= (-(HOST_WIDE_INT) 0x7fffffff - 1) \\\n+ : (unsigned HOST_WIDE_INT) (X) <= (unsigned HOST_WIDE_INT) 0xffffffff)\n+#define UNSIGNED_INT3(X) ((unsigned) (X) < 0x8)\n+#define UNSIGNED_INT5(X) ((unsigned) (X) < 0x20)\n+#define UNSIGNED_INT6(X) ((unsigned) (X) < 0x40)\n+#define UNSIGNED_INT7(X) ((unsigned) (X) < 0x80)\n+#define UNSIGNED_INT8(X) ((unsigned) (X) < 0x100)\n+#define IS_ONE(X) ((X) == 1)\n+#define IS_ZERO(X) ((X) == 0)\n+\n+/* Stack layout and stack pointer usage.  */\n+\n+/* Define this macro if pushing a word onto the stack moves the stack\n+   pointer to a smaller address.  */\n+#define STACK_GROWS_DOWNWARD\n+\n+/* Define this if the nominal address of the stack frame\n+   is at the high-address end of the local variables;\n+   that is, each additional local variable allocated\n+   goes at a more negative offset in the frame.  */\n+#define FRAME_GROWS_DOWNWARD 1\n+\n+/* Offset within stack frame to start allocating local variables at.\n+   If FRAME_GROWS_DOWNWARD, this is the offset to the END of the\n+   first local allocated.  Otherwise, it is the offset to the BEGINNING\n+   of the first local allocated.  */\n+#define STARTING_FRAME_OFFSET 0\n+\n+/* Offset from the stack pointer register to the first location at which\n+   outgoing arguments are placed.  */\n+#define STACK_POINTER_OFFSET (0)\n+\n+/* Offset of first parameter from the argument pointer register value.  */\n+#define FIRST_PARM_OFFSET(FNDECL) (0)\n+\n+/* A C expression whose value is RTL representing the address in a\n+   stack frame where the pointer to the caller's frame is stored.\n+   Assume that FRAMEADDR is an RTL expression for the address of the\n+   stack frame itself.\n+\n+   If you don't define this macro, the default is to return the value\n+   of FRAMEADDR--that is, the stack frame address is also the address\n+   of the stack word that points to the previous frame.  */\n+/* ??? unfinished */\n+/*define DYNAMIC_CHAIN_ADDRESS (FRAMEADDR)*/\n+\n+/* A C expression whose value is RTL representing the value of the\n+   return address for the frame COUNT steps up from the current frame.\n+   FRAMEADDR is the frame pointer of the COUNT frame, or the frame\n+   pointer of the COUNT - 1 frame if `RETURN_ADDR_IN_PREVIOUS_FRAME'\n+   is defined.  */\n+/* The current return address is in r31.  The return address of anything\n+   farther back is at [%fp,4].  */\n+\n+#define RETURN_ADDR_RTX(COUNT, FRAME) \\\n+arc_return_addr_rtx(COUNT,FRAME)\n+\n+/* Register to use for pushing function arguments.  */\n+#define STACK_POINTER_REGNUM 28\n+\n+/* Base register for access to local variables of the function.  */\n+#define FRAME_POINTER_REGNUM 27\n+\n+/* Base register for access to arguments of the function. This register\n+   will be eliminated into either fp or sp.  */\n+#define ARG_POINTER_REGNUM 62\n+\n+#define RETURN_ADDR_REGNUM 31\n+\n+/* TODO - check usage of STATIC_CHAIN_REGNUM with a testcase */\n+/* Register in which static-chain is passed to a function.  This must\n+   not be a register used by the prologue.  */\n+#define STATIC_CHAIN_REGNUM  11\n+\n+/* Function argument passing.  */\n+\n+/* If defined, the maximum amount of space required for outgoing\n+   arguments will be computed and placed into the variable\n+   `crtl->outgoing_args_size'.  No space will be pushed\n+   onto the stack for each call; instead, the function prologue should\n+   increase the stack frame size by this amount.  */\n+#define ACCUMULATE_OUTGOING_ARGS 1\n+\n+/* Define a data type for recording info about an argument list\n+   during the scan of that argument list.  This data type should\n+   hold all necessary information about the function itself\n+   and about the args processed so far, enough to enable macros\n+   such as FUNCTION_ARG to determine where the next arg should go.  */\n+#define CUMULATIVE_ARGS int\n+\n+/* Initialize a variable CUM of type CUMULATIVE_ARGS\n+   for a call to a function whose data type is FNTYPE.\n+   For a library call, FNTYPE is 0.  */\n+#define INIT_CUMULATIVE_ARGS(CUM,FNTYPE,LIBNAME,INDIRECT,N_NAMED_ARGS) \\\n+((CUM) = 0)\n+\n+/* The number of registers used for parameter passing.  Local to this file.  */\n+#define MAX_ARC_PARM_REGS 8\n+\n+/* 1 if N is a possible register number for function argument passing.  */\n+#define FUNCTION_ARG_REGNO_P(N) \\\n+((unsigned) (N) < MAX_ARC_PARM_REGS)\n+\n+/* The ROUND_ADVANCE* macros are local to this file.  */\n+/* Round SIZE up to a word boundary.  */\n+#define ROUND_ADVANCE(SIZE) \\\n+(((SIZE) + UNITS_PER_WORD - 1) / UNITS_PER_WORD)\n+\n+/* Round arg MODE/TYPE up to the next word boundary.  */\n+#define ROUND_ADVANCE_ARG(MODE, TYPE) \\\n+((MODE) == BLKmode\t\t\t\t\\\n+ ? ROUND_ADVANCE (int_size_in_bytes (TYPE))\t\\\n+ : ROUND_ADVANCE (GET_MODE_SIZE (MODE)))\n+\n+#define ARC_FUNCTION_ARG_BOUNDARY(MODE,TYPE) PARM_BOUNDARY\n+/* Round CUM up to the necessary point for argument MODE/TYPE.  */\n+/* N.B. Vectors have alignment exceeding BIGGEST_ALIGNMENT.\n+   ARC_FUNCTION_ARG_BOUNDARY reduces this to no more than 32 bit.  */\n+#define ROUND_ADVANCE_CUM(CUM, MODE, TYPE) \\\n+  ((((CUM) - 1) | (ARC_FUNCTION_ARG_BOUNDARY ((MODE), (TYPE)) - 1)/BITS_PER_WORD)\\\n+   + 1)\n+\n+/* Return boolean indicating arg of type TYPE and mode MODE will be passed in\n+   a reg.  This includes arguments that have to be passed by reference as the\n+   pointer to them is passed in a reg if one is available (and that is what\n+   we're given).\n+   When passing arguments NAMED is always 1.  When receiving arguments NAMED\n+   is 1 for each argument except the last in a stdarg/varargs function.  In\n+   a stdarg function we want to treat the last named arg as named.  In a\n+   varargs function we want to treat the last named arg (which is\n+   `__builtin_va_alist') as unnamed.\n+   This macro is only used in this file.  */\n+#define PASS_IN_REG_P(CUM, MODE, TYPE) \\\n+((CUM) < MAX_ARC_PARM_REGS)\n+\n+\n+/* Function results.  */\n+\n+/* Define how to find the value returned by a library function\n+   assuming the value has mode MODE.  */\n+#define LIBCALL_VALUE(MODE) gen_rtx_REG (MODE, 0)\n+\n+/* 1 if N is a possible register number for a function value\n+   as seen by the caller.  */\n+/* ??? What about r1 in DI/DF values.  */\n+#define FUNCTION_VALUE_REGNO_P(N) ((N) == 0)\n+\n+/* Tell GCC to use RETURN_IN_MEMORY.  */\n+#define DEFAULT_PCC_STRUCT_RETURN 0\n+\n+/* Register in which address to store a structure value\n+   is passed to a function, or 0 to use `invisible' first argument.  */\n+#define STRUCT_VALUE 0\n+\n+/* EXIT_IGNORE_STACK should be nonzero if, when returning from a function,\n+   the stack pointer does not matter.  The value is tested only in\n+   functions that have frame pointers.\n+   No definition is equivalent to always zero.  */\n+#define EXIT_IGNORE_STACK 0\n+\n+#define EPILOGUE_USES(REGNO) arc_epilogue_uses ((REGNO))\n+\n+/* Definitions for register eliminations.\n+\n+   This is an array of structures.  Each structure initializes one pair\n+   of eliminable registers.  The \"from\" register number is given first,\n+   followed by \"to\".  Eliminations of the same \"from\" register are listed\n+   in order of preference.\n+\n+   We have two registers that can be eliminated on the ARC.  First, the\n+   argument pointer register can always be eliminated in favor of the stack\n+   pointer register or frame pointer register.  Secondly, the frame pointer\n+   register can often be eliminated in favor of the stack pointer register.\n+*/\n+\n+#define ELIMINABLE_REGS\t\t\t\t\t\\\n+{{ARG_POINTER_REGNUM, STACK_POINTER_REGNUM},\t\t\\\n+ {ARG_POINTER_REGNUM, FRAME_POINTER_REGNUM},\t\t\\\n+ {FRAME_POINTER_REGNUM, STACK_POINTER_REGNUM}}\n+\n+/* Define the offset between two registers, one to be eliminated, and the other\n+   its replacement, at the start of a routine.  */\n+extern int arc_initial_elimination_offset(int from, int to);\n+#define INITIAL_ELIMINATION_OFFSET(FROM, TO, OFFSET)                    \\\n+  (OFFSET) = arc_initial_elimination_offset ((FROM), (TO))\n+\n+/* Output assembler code to FILE to increment profiler label # LABELNO\n+   for profiling a function entry.\n+   We actually emit the profiler code at the call site, so leave this one\n+   empty.  */\n+#define FUNCTION_PROFILER(FILE, LABELNO) \\\n+  if (TARGET_UCB_MCOUNT) \\\n+    fprintf (FILE, \"\\t%s\\n\", arc_output_libcall (\"__mcount\"))\n+\n+#define NO_PROFILE_COUNTERS  1\n+\n+/* Trampolines.  */\n+\n+/* Length in units of the trampoline for entering a nested function.  */\n+#define TRAMPOLINE_SIZE 20\n+\n+/* Alignment required for a trampoline in bits .  */\n+/* For actual data alignment we just need 32, no more than the stack;\n+   however, to reduce cache coherency issues, we want to make sure that\n+   trampoline instructions always appear the same in any given cache line.  */\n+#define TRAMPOLINE_ALIGNMENT 256\n+\n+/* Library calls.  */\n+\n+/* Addressing modes, and classification of registers for them.  */\n+\n+/* Maximum number of registers that can appear in a valid memory address.  */\n+/* The `ld' insn allows 2, but the `st' insn only allows 1.  */\n+#define MAX_REGS_PER_ADDRESS 1\n+\n+/* We have pre inc/dec (load/store with update).  */\n+#define HAVE_PRE_INCREMENT 1\n+#define HAVE_PRE_DECREMENT 1\n+#define HAVE_POST_INCREMENT 1\n+#define HAVE_POST_DECREMENT 1\n+#define HAVE_PRE_MODIFY_DISP 1\n+#define HAVE_POST_MODIFY_DISP 1\n+#define HAVE_PRE_MODIFY_REG 1\n+#define HAVE_POST_MODIFY_REG 1\n+/* ??? should also do PRE_MODIFY_REG / POST_MODIFY_REG, but that requires\n+   a special predicate for the memory operand of stores, like for the SH.  */\n+\n+/* Recognize any constant value that is a valid address.  */\n+#define CONSTANT_ADDRESS_P(X) \\\n+(flag_pic?arc_legitimate_pic_addr_p (X): \\\n+(GET_CODE (X) == LABEL_REF || GET_CODE (X) == SYMBOL_REF\t\\\n+ || GET_CODE (X) == CONST_INT || GET_CODE (X) == CONST))\n+\n+/* Is the argument a const_int rtx, containing an exact power of 2 */\n+#define  IS_POWEROF2_P(X) (! ( (X) & ((X) - 1)) && (X))\n+\n+/* The macros REG_OK_FOR..._P assume that the arg is a REG rtx\n+   and check its validity for a certain class.\n+   We have two alternate definitions for each of them.\n+   The *_NONSTRICT definition accepts all pseudo regs; the other rejects\n+   them unless they have been allocated suitable hard regs.\n+\n+   Most source files want to accept pseudo regs in the hope that\n+   they will get allocated to the class that the insn wants them to be in.\n+   Source files for reload pass need to be strict.\n+   After reload, it makes no difference, since pseudo regs have\n+   been eliminated by then.  */\n+\n+/* Nonzero if X is a hard reg that can be used as an index\n+   or if it is a pseudo reg.  */\n+#define REG_OK_FOR_INDEX_P_NONSTRICT(X) \\\n+((unsigned) REGNO (X) >= FIRST_PSEUDO_REGISTER || \\\n+ (unsigned) REGNO (X) < 29 || \\\n+ (unsigned) REGNO (X) == 63 || \\\n+ (unsigned) REGNO (X) == ARG_POINTER_REGNUM)\n+/* Nonzero if X is a hard reg that can be used as a base reg\n+   or if it is a pseudo reg.  */\n+#define REG_OK_FOR_BASE_P_NONSTRICT(X) \\\n+((unsigned) REGNO (X) >= FIRST_PSEUDO_REGISTER || \\\n+ (unsigned) REGNO (X) < 29 || \\\n+ (unsigned) REGNO (X) == 63 || \\\n+ (unsigned) REGNO (X) == ARG_POINTER_REGNUM)\n+\n+/* Nonzero if X is a hard reg that can be used as an index.  */\n+#define REG_OK_FOR_INDEX_P_STRICT(X) REGNO_OK_FOR_INDEX_P (REGNO (X))\n+/* Nonzero if X is a hard reg that can be used as a base reg.  */\n+#define REG_OK_FOR_BASE_P_STRICT(X) REGNO_OK_FOR_BASE_P (REGNO (X))\n+\n+/* GO_IF_LEGITIMATE_ADDRESS recognizes an RTL expression\n+   that is a valid memory address for an instruction.\n+   The MODE argument is the machine mode for the MEM expression\n+   that wants to use this address.  */\n+/* The `ld' insn allows [reg],[reg+shimm],[reg+limm],[reg+reg],[limm]\n+   but the `st' insn only allows [reg],[reg+shimm],[limm].\n+   The only thing we can do is only allow the most strict case `st' and hope\n+   other parts optimize out the restrictions for `ld'.  */\n+\n+#define RTX_OK_FOR_BASE_P(X, STRICT) \\\n+(REG_P (X) \\\n+ && ((STRICT) ? REG_OK_FOR_BASE_P_STRICT (X) : REG_OK_FOR_BASE_P_NONSTRICT (X)))\n+\n+#define RTX_OK_FOR_INDEX_P(X, STRICT) \\\n+(REG_P (X) \\\n+ && ((STRICT) ? REG_OK_FOR_INDEX_P_STRICT (X) : REG_OK_FOR_INDEX_P_NONSTRICT (X)))\n+\n+/* A C compound statement that attempts to replace X, which is an address\n+   that needs reloading, with a valid memory address for an operand of\n+   mode MODE.  WIN is a C statement label elsewhere in the code.\n+\n+   We try to get a normal form\n+   of the address.  That will allow inheritance of the address reloads.  */\n+\n+#define LEGITIMIZE_RELOAD_ADDRESS(X,MODE,OPNUM,TYPE,IND_LEVELS,WIN)\t\\\n+  do {\t\t\t\t\t\t\t\t\t\\\n+    if (arc_legitimize_reload_address (&(X), (MODE), (OPNUM), (TYPE)))\t\\\n+      goto WIN;\t\t\t\t\t\t\t\t\\\n+  } while (0)\n+\n+/* Reading lp_count for anything but the lp instruction is very slow on the\n+   ARC700.  */\n+#define DONT_REALLOC(REGNO,MODE) \\\n+  (TARGET_ARC700 && (REGNO) == 60)\n+\n+\n+/* Given a comparison code (EQ, NE, etc.) and the first operand of a COMPARE,\n+   return the mode to be used for the comparison.  */\n+/*extern enum machine_mode arc_select_cc_mode ();*/\n+#define SELECT_CC_MODE(OP, X, Y) \\\n+arc_select_cc_mode (OP, X, Y)\n+\n+/* Return non-zero if SELECT_CC_MODE will never return MODE for a\n+   floating point inequality comparison.  */\n+#define REVERSIBLE_CC_MODE(MODE) 1 /*???*/\n+\n+/* Costs.  */\n+\n+/* Compute extra cost of moving data between one register class\n+   and another.  */\n+#define REGISTER_MOVE_COST(MODE, CLASS, TO_CLASS) \\\n+   arc_register_move_cost ((MODE), (CLASS), (TO_CLASS))\n+\n+/* Compute the cost of moving data between registers and memory.  */\n+/* Memory is 3 times as expensive as registers.\n+   ??? Is that the right way to look at it?  */\n+#define MEMORY_MOVE_COST(MODE,CLASS,IN) \\\n+(GET_MODE_SIZE (MODE) <= UNITS_PER_WORD ? 6 : 12)\n+\n+/* The cost of a branch insn.  */\n+/* ??? What's the right value here?  Branches are certainly more\n+   expensive than reg->reg moves.  */\n+#define BRANCH_COST(speed_p, predictable_p) 2\n+\n+/* Nonzero if access to memory by bytes is slow and undesirable.\n+   For RISC chips, it means that access to memory by bytes is no\n+   better than access by words when possible, so grab a whole word\n+   and maybe make use of that.  */\n+#define SLOW_BYTE_ACCESS  0\n+\n+/* Define this macro if it is as good or better to call a constant\n+   function address than to call an address kept in a register.  */\n+/* On the ARC, calling through registers is slow.  */\n+#define NO_FUNCTION_CSE\n+\n+/* Section selection.  */\n+/* WARNING: These section names also appear in dwarfout.c.  */\n+\n+#define TEXT_SECTION_ASM_OP\t\"\\t.section\\t.text\"\n+#define DATA_SECTION_ASM_OP\t\"\\t.section\\t.data\"\n+\n+#define BSS_SECTION_ASM_OP\t\"\\t.section\\t.bss\"\n+#define SDATA_SECTION_ASM_OP\t\"\\t.section\\t.sdata\"\n+#define SBSS_SECTION_ASM_OP\t\"\\t.section\\t.sbss\"\n+\n+/* Expression whose value is a string, including spacing, containing the\n+   assembler operation to identify the following data as initialization/termination\n+   code. If not defined, GCC will assume such a section does not exist. */\n+#define INIT_SECTION_ASM_OP \"\\t.section\\t.init\"\n+#define FINI_SECTION_ASM_OP \"\\t.section\\t.fini\"\n+\n+/* Define this macro if jump tables (for tablejump insns) should be\n+   output in the text section, along with the assembler instructions.\n+   Otherwise, the readonly data section is used.\n+   This macro is irrelevant if there is no separate readonly data section.  */\n+#define JUMP_TABLES_IN_TEXT_SECTION  (flag_pic || CASE_VECTOR_PC_RELATIVE)\n+\n+/* For DWARF.  Marginally different than default so output is \"prettier\"\n+   (and consistent with above).  */\n+#define PUSHSECTION_FORMAT \"\\t%s %s\\n\"\n+\n+/* Tell crtstuff.c we're using ELF.  */\n+#define OBJECT_FORMAT_ELF\n+\n+/* PIC */\n+\n+/* The register number of the register used to address a table of static\n+   data addresses in memory.  In some cases this register is defined by a\n+   processor's ``application binary interface'' (ABI).  When this macro\n+   is defined, RTL is generated for this register once, as with the stack\n+   pointer and frame pointer registers.  If this macro is not defined, it\n+   is up to the machine-dependent files to allocate such a register (if\n+   necessary).  */\n+#define PIC_OFFSET_TABLE_REGNUM 26\n+\n+/* Define this macro if the register defined by PIC_OFFSET_TABLE_REGNUM is\n+   clobbered by calls.  Do not define this macro if PIC_OFFSET_TABLE_REGNUM\n+   is not defined.  */\n+/* This register is call-saved on the ARC.  */\n+/*#define PIC_OFFSET_TABLE_REG_CALL_CLOBBERED*/\n+\n+/* A C expression that is nonzero if X is a legitimate immediate\n+   operand on the target machine when generating position independent code.\n+   You can assume that X satisfies CONSTANT_P, so you need not\n+   check this.  You can also assume `flag_pic' is true, so you need not\n+   check it either.  You need not define this macro if all constants\n+   (including SYMBOL_REF) can be immediate operands when generating\n+   position independent code.  */\n+#define LEGITIMATE_PIC_OPERAND_P(X)  (arc_legitimate_pic_operand_p(X))\n+\n+/* PIC and small data don't mix on ARC because they use the same register.  */\n+#define SDATA_BASE_REGNUM 26\n+\n+#define ASM_PREFERRED_EH_DATA_FORMAT(CODE, GLOBAL) \\\n+  (flag_pic \\\n+   ? (GLOBAL ? DW_EH_PE_indirect : 0) | DW_EH_PE_pcrel | DW_EH_PE_sdata4 \\\n+   : DW_EH_PE_absptr)\n+\n+/* Control the assembler format that we output.  */\n+\n+/* A C string constant describing how to begin a comment in the target\n+   assembler language.  The compiler assumes that the comment will\n+   end at the end of the line.  */\n+/* Gas needs this to be \"#\" in order to recognize line directives.  */\n+#define ASM_COMMENT_START \"#\"\n+\n+/* Output to assembler file text saying following lines\n+   may contain character constants, extra white space, comments, etc.  */\n+#define ASM_APP_ON \"\"\n+\n+/* Output to assembler file text saying following lines\n+   no longer contain unusual constructs.  */\n+#define ASM_APP_OFF \"\"\n+\n+/* Globalizing directive for a label.  */\n+#define GLOBAL_ASM_OP \"\\t.global\\t\"\n+\n+/* This is how to output an assembler line defining a `char' constant.  */\n+#define ASM_OUTPUT_CHAR(FILE, VALUE) \\\n+( fprintf (FILE, \"\\t.byte\\t\"),\t\t\t\\\n+  output_addr_const (FILE, (VALUE)),\t\t\\\n+  fprintf (FILE, \"\\n\"))\n+\n+/* This is how to output an assembler line defining a `short' constant.  */\n+#define ASM_OUTPUT_SHORT(FILE, VALUE) \\\n+( fprintf (FILE, \"\\t.hword\\t\"),\t\t\t\\\n+  output_addr_const (FILE, (VALUE)),\t\t\\\n+  fprintf (FILE, \"\\n\"))\n+\n+/* This is how to output an assembler line defining an `int' constant.\n+   We also handle symbol output here.  Code addresses must be right shifted\n+   by 2 because that's how the jump instruction wants them.  */\n+#define ASM_OUTPUT_INT(FILE, VALUE) \\\n+do {\t\t\t\t\t\t\t\t\t\\\n+  fprintf (FILE, \"\\t.word\\t\");\t\t\t\t\t\t\\\n+  if (GET_CODE (VALUE) == LABEL_REF)\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\t\t\\\n+      fprintf (FILE, \"%%st(@\");\t\t\t\t\t\t\\\n+      output_addr_const (FILE, (VALUE));\t\t\t\t\\\n+      fprintf (FILE, \")\");\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+  else\t\t\t\t\t\t\t\t\t\\\n+    output_addr_const (FILE, (VALUE));\t\t\t\t\t\\\n+  fprintf (FILE, \"\\n\");\t\t\t\t\t                \\\n+} while (0)\n+\n+/* This is how to output an assembler line defining a `float' constant.  */\n+#define ASM_OUTPUT_FLOAT(FILE, VALUE) \\\n+{\t\t\t\t\t\t\t\\\n+  long t;\t\t\t\t\t\t\\\n+  char str[30];\t\t\t\t\t\t\\\n+  REAL_VALUE_TO_TARGET_SINGLE ((VALUE), t);\t\t\\\n+  REAL_VALUE_TO_DECIMAL ((VALUE), \"%.20e\", str);\t\\\n+  fprintf (FILE, \"\\t.word\\t0x%lx %s %s\\n\",\t\t\\\n+\t   t, ASM_COMMENT_START, str);\t\t\t\\\n+}\n+\n+/* This is how to output an assembler line defining a `double' constant.  */\n+#define ASM_OUTPUT_DOUBLE(FILE, VALUE) \\\n+{\t\t\t\t\t\t\t\\\n+  long t[2];\t\t\t\t\t\t\\\n+  char str[30];\t\t\t\t\t\t\\\n+  REAL_VALUE_TO_TARGET_DOUBLE ((VALUE), t);\t\t\\\n+  REAL_VALUE_TO_DECIMAL ((VALUE), \"%.20e\", str);\t\\\n+  fprintf (FILE, \"\\t.word\\t0x%lx %s %s\\n\\t.word\\t0x%lx\\n\", \\\n+\t   t[0], ASM_COMMENT_START, str, t[1]);\t\t\\\n+}\n+\n+/* This is how to output the definition of a user-level label named NAME,\n+   such as the label on a static function or variable NAME.  */\n+#define ASM_OUTPUT_LABEL(FILE, NAME) \\\n+do { assemble_name (FILE, NAME); fputs (\":\\n\", FILE); } while (0)\n+\n+#define ASM_NAME_P(NAME) ( NAME[0]=='*')\n+\n+/* This is how to output a reference to a user-level label named NAME.\n+   `assemble_name' uses this.  */\n+/* We work around a dwarfout.c deficiency by watching for labels from it and\n+   not adding the '_' prefix.  There is a comment in\n+   dwarfout.c that says it should be using ASM_OUTPUT_INTERNAL_LABEL.  */\n+#define ASM_OUTPUT_LABELREF(FILE, NAME1) \\\n+do {\t\t\t\t\t\t\t\\\n+  const char *NAME;\t\t\t\t\t\\\n+  NAME = (*targetm.strip_name_encoding)(NAME1);\t\t\\\n+  if ((NAME)[0] == '.' && (NAME)[1] == 'L')\t\t\\\n+    fprintf (FILE, \"%s\", NAME);\t\t\t\t\\\n+  else\t\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\\\n+      if (!ASM_NAME_P (NAME1))\t\t\t\t\\\n+\tfprintf (FILE, \"%s\", user_label_prefix);\t\\\n+      fprintf (FILE, \"%s\", NAME);\t\t\t\\\n+    }\t\t\t\t\t\t\t\\\n+} while (0)\n+\n+/* This is how to output a reference to a symbol_ref / label_ref as\n+   (part of) an operand.  To disambiguate from register names like\n+   a1 / a2 / status etc, symbols are preceded by '@'.  */\n+#define ASM_OUTPUT_SYMBOL_REF(FILE,SYM) \\\n+  ASM_OUTPUT_LABEL_REF ((FILE), XSTR ((SYM), 0))\n+#define ASM_OUTPUT_LABEL_REF(FILE,STR)\t\t\t\\\n+  do\t\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\\\n+      fputc ('@', file);\t\t\t\t\\\n+      assemble_name ((FILE), (STR));\t\t\t\\\n+    }\t\t\t\t\t\t\t\\\n+  while (0)\n+\n+/* Store in OUTPUT a string (made with alloca) containing\n+   an assembler-name for a local static variable named NAME.\n+   LABELNO is an integer which is different for each call.  */\n+#define ASM_FORMAT_PRIVATE_NAME(OUTPUT, NAME, LABELNO) \\\n+( (OUTPUT) = (char *) alloca (strlen ((NAME)) + 10),\t\\\n+  sprintf ((OUTPUT), \"%s.%d\", (NAME), (LABELNO)))\n+\n+/* The following macro defines the format used to output the second\n+   operand of the .type assembler directive.  Different svr4 assemblers\n+   expect various different forms for this operand.  The one given here\n+   is just a default.  You may need to override it in your machine-\n+   specific tm.h file (depending upon the particulars of your assembler).  */\n+\n+#undef  TYPE_OPERAND_FMT\n+#define TYPE_OPERAND_FMT\t\"@%s\"\n+\n+/*  A C string containing the appropriate assembler directive to\n+    specify the size of a symbol, without any arguments.  On systems\n+    that use ELF, the default (in `config/elfos.h') is `\"\\t.size\\t\"';\n+    on other systems, the default is not to define this macro.  */\n+#undef SIZE_ASM_OP\n+#define SIZE_ASM_OP \"\\t.size\\t\"\n+\n+/* Assembler pseudo-op to equate one value with another.  */\n+/* ??? This is needed because dwarfout.c provides a default definition too\n+   late for defaults.h (which contains the default definition of ASM_OTPUT_DEF\n+   that we use).  */\n+#ifdef SET_ASM_OP\n+#undef SET_ASM_OP\n+#endif\n+#define SET_ASM_OP \"\\t.set\\t\"\n+\n+extern char rname56[], rname57[], rname58[], rname59[];\n+/* How to refer to registers in assembler output.\n+   This sequence is indexed by compiler's hard-register-number (see above).  */\n+#define REGISTER_NAMES\t\t\t\t\t\t\t\t\\\n+{  \"r0\",   \"r1\",   \"r2\",   \"r3\",       \"r4\",     \"r5\",     \"r6\",    \"r7\",\t\\\n+   \"r8\",   \"r9\",  \"r10\",  \"r11\",      \"r12\",    \"r13\",    \"r14\",   \"r15\",\t\\\n+  \"r16\",  \"r17\",  \"r18\",  \"r19\",      \"r20\",    \"r21\",    \"r22\",   \"r23\",\t\\\n+  \"r24\",  \"r25\",   \"gp\",   \"fp\",       \"sp\", \"ilink1\", \"ilink2\", \"blink\",\t\\\n+  \"r32\",  \"r33\",  \"r34\",  \"r35\",      \"r36\",    \"r37\",    \"r38\",   \"r39\",\t\\\n+   \"d1\",   \"d1\",   \"d2\",   \"d2\",      \"r44\",    \"r45\",    \"r46\",   \"r47\",\t\\\n+  \"r48\",  \"r49\",  \"r50\",  \"r51\",      \"r52\",    \"r53\",    \"r54\",   \"r55\",\t\\\n+  rname56,rname57,rname58,rname59,\"lp_count\",    \"cc\",     \"ap\",   \"pcl\",\t\\\n+  \"vr0\",  \"vr1\",  \"vr2\",  \"vr3\",      \"vr4\",    \"vr5\",    \"vr6\",   \"vr7\",       \\\n+  \"vr8\",  \"vr9\", \"vr10\", \"vr11\",     \"vr12\",   \"vr13\",   \"vr14\",  \"vr15\",\t\\\n+ \"vr16\", \"vr17\", \"vr18\", \"vr19\",     \"vr20\",   \"vr21\",   \"vr22\",  \"vr23\",\t\\\n+ \"vr24\", \"vr25\", \"vr26\", \"vr27\",     \"vr28\",   \"vr29\",   \"vr30\",  \"vr31\",\t\\\n+ \"vr32\", \"vr33\", \"vr34\", \"vr35\",     \"vr36\",   \"vr37\",   \"vr38\",  \"vr39\",\t\\\n+ \"vr40\", \"vr41\", \"vr42\", \"vr43\",     \"vr44\",   \"vr45\",   \"vr46\",  \"vr47\",\t\\\n+ \"vr48\", \"vr49\", \"vr50\", \"vr51\",     \"vr52\",   \"vr53\",   \"vr54\",  \"vr55\",\t\\\n+ \"vr56\", \"vr57\", \"vr58\", \"vr59\",     \"vr60\",   \"vr61\",   \"vr62\",  \"vr63\",\t\\\n+  \"dr0\",  \"dr1\",  \"dr2\",  \"dr3\",      \"dr4\",    \"dr5\",    \"dr6\",   \"dr7\",\t\\\n+  \"dr0\",  \"dr1\",  \"dr2\",  \"dr3\",      \"dr4\",    \"dr5\",    \"dr6\",   \"dr7\",\t\\\n+  \"lp_start\", \"lp_end\" \\\n+}\n+\n+/* Entry to the insn conditionalizer.  */\n+#define FINAL_PRESCAN_INSN(INSN, OPVEC, NOPERANDS) \\\n+  arc_final_prescan_insn (INSN, OPVEC, NOPERANDS)\n+\n+/* A C expression which evaluates to true if CODE is a valid\n+   punctuation character for use in the `PRINT_OPERAND' macro.  */\n+extern char arc_punct_chars[];\n+#define PRINT_OPERAND_PUNCT_VALID_P(CHAR) \\\n+arc_punct_chars[(unsigned char) (CHAR)]\n+\n+/* Print operand X (an rtx) in assembler syntax to file FILE.\n+   CODE is a letter or dot (`z' in `%z0') or 0 if no letter was specified.\n+   For `%' followed by punctuation, CODE is the punctuation and X is null.  */\n+#define PRINT_OPERAND(FILE, X, CODE) \\\n+arc_print_operand (FILE, X, CODE)\n+\n+/* A C compound statement to output to stdio stream STREAM the\n+   assembler syntax for an instruction operand that is a memory\n+   reference whose address is ADDR.  ADDR is an RTL expression.\n+\n+   On some machines, the syntax for a symbolic address depends on\n+   the section that the address refers to.  On these machines,\n+   define the macro `ENCODE_SECTION_INFO' to store the information\n+   into the `symbol_ref', and then check for it here.  */\n+#define PRINT_OPERAND_ADDRESS(FILE, ADDR) \\\n+arc_print_operand_address (FILE, ADDR)\n+\n+/* This is how to output an element of a case-vector that is absolute.  */\n+#define ASM_OUTPUT_ADDR_VEC_ELT(FILE, VALUE)  \\\n+do {\t\t\t\t\t\t\t\\\n+  char label[30];\t\t\t\t\t\\\n+  ASM_GENERATE_INTERNAL_LABEL (label, \"L\", VALUE);\t\\\n+  fprintf (FILE, \"\\t.word \");\t\t\t\t\\\n+  assemble_name (FILE, label);\t\t\t\t\\\n+  fprintf(FILE, \"\\n\");\t\t\t\t\t\\\n+} while (0)\n+\n+/* This is how to output an element of a case-vector that is relative.  */\n+#define ASM_OUTPUT_ADDR_DIFF_ELT(FILE, BODY, VALUE, REL) \\\n+do {\t\t\t\t\t\t\t\\\n+  char label[30];\t\t\t\t\t\\\n+  ASM_GENERATE_INTERNAL_LABEL (label, \"L\", VALUE);\t\\\n+  switch (GET_MODE (BODY))\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\\\n+    case QImode: fprintf (FILE, \"\\t.byte \"); break;\t\\\n+    case HImode: fprintf (FILE, \"\\t.hword \"); break;\t\\\n+    case SImode: fprintf (FILE, \"\\t.word \"); break;\t\\\n+    default: gcc_unreachable ();\t\t\t\\\n+    }\t\t\t\t\t\t\t\\\n+  assemble_name (FILE, label);\t\t\t\t\\\n+  fprintf (FILE, \"-\");\t\t\t\t\t\\\n+  ASM_GENERATE_INTERNAL_LABEL (label, \"L\", REL);\t\\\n+  assemble_name (FILE, label);\t\t\t\t\\\n+  if (TARGET_COMPACT_CASESI)\t\t\t\t\\\n+    fprintf (FILE, \" + %d\", 4 + arc_get_unalign ());\t\\\n+  fprintf(FILE, \"\\n\");                                  \\\n+} while (0)\n+\n+/* ADDR_DIFF_VECs are in the text section and thus can affect the\n+   current alignment.  */\n+#define ASM_OUTPUT_CASE_END(FILE, NUM, JUMPTABLE)       \\\n+  do                                                    \\\n+    {                                                   \\\n+      if (GET_CODE (PATTERN (JUMPTABLE)) == ADDR_DIFF_VEC \\\n+\t  && ((GET_MODE_SIZE (GET_MODE (PATTERN (JUMPTABLE))) \\\n+\t       * XVECLEN (PATTERN (JUMPTABLE), 1) + 1)\t\\\n+\t      & 2))\t\t\t\t\t\\\n+      arc_toggle_unalign ();\t\t\t\t\\\n+    }                                                   \\\n+  while (0)\n+\n+#define JUMP_ALIGN(LABEL) (arc_size_opt_level < 2 ? 2 : 0)\n+#define LABEL_ALIGN_AFTER_BARRIER(LABEL) \\\n+  (JUMP_ALIGN(LABEL) \\\n+   ? JUMP_ALIGN(LABEL) \\\n+   : GET_CODE (PATTERN (prev_active_insn (LABEL))) == ADDR_DIFF_VEC \\\n+   ? 1 : 0)\n+/* The desired alignment for the location counter at the beginning\n+   of a loop.  */\n+/* On the ARC, align loops to 4 byte boundaries unless doing all-out size\n+   optimization.  */\n+#define LOOP_ALIGN JUMP_ALIGN\n+\n+#define LABEL_ALIGN(LABEL) (arc_label_align (LABEL))\n+\n+/* This is how to output an assembler line\n+   that says to advance the location counter\n+   to a multiple of 2**LOG bytes.  */\n+#define ASM_OUTPUT_ALIGN(FILE,LOG) \\\n+do { \\\n+  if ((LOG) != 0) fprintf (FILE, \"\\t.align %d\\n\", 1 << (LOG)); \\\n+  if ((LOG)  > 1) \\\n+    arc_clear_unalign (); \\\n+} while (0)\n+\n+/*  ASM_OUTPUT_ALIGNED_DECL_LOCAL (STREAM, DECL, NAME, SIZE, ALIGNMENT)\n+    Define this macro when you need to see the variable's decl in order to\n+    chose what to output.  */\n+#define ASM_OUTPUT_ALIGNED_DECL_LOCAL(STREAM, DECL, NAME, SIZE, ALIGNMENT) \\\n+  arc_asm_output_aligned_decl_local (STREAM, DECL, NAME, SIZE, ALIGNMENT, 0)\n+\n+/* To translate the return value of arc_function_type into a register number\n+   to jump through for function return.  */\n+extern int arc_return_address_regs[4];\n+\n+/* Debugging information.  */\n+\n+/* Generate DBX and DWARF debugging information.  */\n+#ifdef DBX_DEBUGGING_INFO\n+#undef DBX_DEBUGGING_INFO\n+#endif\n+#define DBX_DEBUGGING_INFO\n+\n+#ifdef DWARF2_DEBUGGING_INFO\n+#undef DWARF2_DEBUGGING_INFO\n+#endif\n+#define DWARF2_DEBUGGING_INFO\n+\n+/* Prefer STABS (for now).  */\n+#undef PREFERRED_DEBUGGING_TYPE\n+#define PREFERRED_DEBUGGING_TYPE DWARF2_DEBUG\n+\n+/* How to renumber registers for dbx and gdb.  */\n+#define DBX_REGISTER_NUMBER(REGNO) \\\n+  ((TARGET_MULMAC_32BY16_SET && (REGNO) >= 56 && (REGNO) <= 57) \\\n+   ? ((REGNO) ^ !TARGET_BIG_ENDIAN) \\\n+   : (TARGET_MUL64_SET && (REGNO) >= 57 && (REGNO) <= 59) \\\n+   ? ((REGNO) == 57 \\\n+      ? 58 /* MMED */ \\\n+      : ((REGNO) & 1) ^ TARGET_BIG_ENDIAN \\\n+      ? 59 /* MHI */ \\\n+      : 57 + !!TARGET_MULMAC_32BY16_SET) /* MLO */ \\\n+   : (REGNO))\n+\n+#define DWARF_FRAME_REGNUM(REG) (REG)\n+\n+#define DWARF_FRAME_RETURN_COLUMN \tDWARF_FRAME_REGNUM (31)\n+\n+#define INCOMING_RETURN_ADDR_RTX  gen_rtx_REG (Pmode, 31)\n+\n+/* Frame info.  */\n+\n+/* Define this macro to 0 if your target supports DWARF 2 frame unwind\n+   information, but it does not yet work with exception handling.  */\n+/* N.B. the below test is valid in an #if, but not in a C expression.  */\n+#if DEFAULT_LIBC == LIBC_UCLIBC\n+#define DWARF2_UNWIND_INFO 1\n+#else\n+#define DWARF2_UNWIND_INFO 0\n+#endif\n+\n+#define EH_RETURN_DATA_REGNO(N)\t\\\n+  ((N) < 4 ? (N) : INVALID_REGNUM)\n+\n+/* Turn off splitting of long stabs.  */\n+#define DBX_CONTIN_LENGTH 0\n+\n+/* Miscellaneous.  */\n+\n+/* Specify the machine mode that this machine uses\n+   for the index in the tablejump instruction.\n+   If we have pc relative case vectors, we start the case vector shortening\n+   with QImode.  */\n+#define CASE_VECTOR_MODE \\\n+  ((optimize && (CASE_VECTOR_PC_RELATIVE || flag_pic)) ? QImode : Pmode)\n+\n+/* Define as C expression which evaluates to nonzero if the tablejump\n+   instruction expects the table to contain offsets from the address of the\n+   table.\n+   Do not define this if the table should contain absolute addresses.  */\n+#define CASE_VECTOR_PC_RELATIVE TARGET_CASE_VECTOR_PC_RELATIVE\n+\n+#define CASE_VECTOR_SHORTEN_MODE(MIN_OFFSET, MAX_OFFSET, BODY) \\\n+  CASE_VECTOR_SHORTEN_MODE_1 \\\n+    (MIN_OFFSET, TARGET_COMPACT_CASESI ? MAX_OFFSET + 6 : MAX_OFFSET, BODY)\n+\n+#define CASE_VECTOR_SHORTEN_MODE_1(MIN_OFFSET, MAX_OFFSET, BODY) \\\n+((MIN_OFFSET) >= 0 && (MAX_OFFSET) <= 255 \\\n+ ? (ADDR_DIFF_VEC_FLAGS (BODY).offset_unsigned = 1, QImode) \\\n+ : (MIN_OFFSET) >= -128 && (MAX_OFFSET) <= 127 \\\n+ ? (ADDR_DIFF_VEC_FLAGS (BODY).offset_unsigned = 0, QImode) \\\n+ : (MIN_OFFSET) >= 0 && (MAX_OFFSET) <= 65535 \\\n+ ? (ADDR_DIFF_VEC_FLAGS (BODY).offset_unsigned = 1, HImode) \\\n+ : (MIN_OFFSET) >= -32768 && (MAX_OFFSET) <= 32767 \\\n+ ? (ADDR_DIFF_VEC_FLAGS (BODY).offset_unsigned = 0, HImode) \\\n+ : SImode)\n+\n+#define ADDR_VEC_ALIGN(VEC_INSN) \\\n+  (exact_log2 (GET_MODE_SIZE (GET_MODE (PATTERN (VEC_INSN)))))\n+#undef ASM_OUTPUT_BEFORE_CASE_LABEL\n+#define ASM_OUTPUT_BEFORE_CASE_LABEL(FILE, PREFIX, NUM, TABLE) \\\n+  ASM_OUTPUT_ALIGN ((FILE), ADDR_VEC_ALIGN (TABLE));\n+\n+#define INSN_LENGTH_ALIGNMENT(INSN) \\\n+  ((JUMP_P (INSN) \\\n+    && GET_CODE (PATTERN (INSN)) == ADDR_DIFF_VEC \\\n+    && GET_MODE (PATTERN (INSN)) == QImode) \\\n+   ? 0 : length_unit_log)\n+\n+/* Define if operations between registers always perform the operation\n+   on the full register even if a narrower mode is specified.  */\n+#define WORD_REGISTER_OPERATIONS\n+\n+/* Define if loading in MODE, an integral mode narrower than BITS_PER_WORD\n+   will either zero-extend or sign-extend.  The value of this macro should\n+   be the code that says which one of the two operations is implicitly\n+   done, NIL if none.  */\n+#define LOAD_EXTEND_OP(MODE) ZERO_EXTEND\n+\n+\n+/* Max number of bytes we can move from memory to memory\n+   in one reasonably fast instruction.  */\n+#define MOVE_MAX 4\n+\n+/* Let the movmem expander handle small block moves.  */\n+#define MOVE_BY_PIECES_P(LEN, ALIGN)  0\n+#define CAN_MOVE_BY_PIECES(SIZE, ALIGN) \\\n+  (move_by_pieces_ninsns (SIZE, ALIGN, MOVE_MAX_PIECES + 1) \\\n+   < (unsigned int) MOVE_RATIO (!optimize_size))\n+\n+/* Undo the effects of the movmem pattern presence on STORE_BY_PIECES_P .  */\n+#define MOVE_RATIO(SPEED) ((SPEED) ? 15 : 3)\n+\n+/* Define this to be nonzero if shift instructions ignore all but the low-order\n+   few bits. Changed from 1 to 0 for rotate pattern testcases\n+   (e.g. 20020226-1.c). This change truncates the upper 27 bits of a word\n+   while rotating a word. Came to notice through a combine phase\n+   optimization viz. a << (32-b) is equivalent to a << (-b).\n+*/\n+#define SHIFT_COUNT_TRUNCATED 0\n+\n+/* Value is 1 if truncating an integer of INPREC bits to OUTPREC bits\n+   is done just by pretending it is already truncated.  */\n+#define TRULY_NOOP_TRUNCATION(OUTPREC, INPREC) 1\n+\n+/* We assume that the store-condition-codes instructions store 0 for false\n+   and some other value for true.  This is the value stored for true.  */\n+#define STORE_FLAG_VALUE 1\n+\n+/* Specify the machine mode that pointers have.\n+   After generation of rtl, the compiler makes no further distinction\n+   between pointers and any other objects of this machine mode.  */\n+/* ARCompact has full 32-bit pointers.  */\n+#define Pmode SImode\n+\n+/* A function address in a call instruction.  */\n+#define FUNCTION_MODE SImode\n+\n+/* Define the information needed to generate branch and scc insns.  This is\n+   stored from the compare operation.  Note that we can't use \"rtx\" here\n+   since it hasn't been defined!  */\n+extern struct rtx_def *arc_compare_op0, *arc_compare_op1;\n+\n+/* ARC function types.   */\n+enum arc_function_type {\n+  ARC_FUNCTION_UNKNOWN, ARC_FUNCTION_NORMAL,\n+  /* These are interrupt handlers.  The name corresponds to the register\n+     name that contains the return address.  */\n+  ARC_FUNCTION_ILINK1, ARC_FUNCTION_ILINK2\n+};\n+#define ARC_INTERRUPT_P(TYPE) \\\n+((TYPE) == ARC_FUNCTION_ILINK1 || (TYPE) == ARC_FUNCTION_ILINK2)\n+\n+/* Compute the type of a function from its DECL.  Needed for EPILOGUE_USES.  */\n+struct function;\n+extern enum arc_function_type arc_compute_function_type (struct function *);\n+\n+/* Called by crtstuff.c to make calls to function FUNCTION that are defined in\n+   SECTION_OP, and then to switch back to text section.  */\n+#undef CRT_CALL_STATIC_FUNCTION\n+#define CRT_CALL_STATIC_FUNCTION(SECTION_OP, FUNC) \\\n+    asm (SECTION_OP \"\\n\\t\"\t\t\t\t\\\n+\t\"bl @\" USER_LABEL_PREFIX #FUNC \"\\n\"\t\t\\\n+\tTEXT_SECTION_ASM_OP);\n+\n+/* This macro expands to the name of the scratch register r12, used for\n+   temporary calculations according to the ABI.  */\n+#define ARC_TEMP_SCRATCH_REG \"r12\"\n+\n+/* The C++ compiler must use one bit to indicate whether the function\n+   that will be called through a pointer-to-member-function is\n+   virtual.  Normally, we assume that the low-order bit of a function\n+   pointer must always be zero.  Then, by ensuring that the\n+   vtable_index is odd, we can distinguish which variant of the union\n+   is in use.  But, on some platforms function pointers can be odd,\n+   and so this doesn't work.  In that case, we use the low-order bit\n+   of the `delta' field, and shift the remainder of the `delta' field\n+   to the left. We needed to do this for A4 because the address was always\n+   shifted and thus could be odd.  */\n+#define TARGET_PTRMEMFUNC_VBIT_LOCATION \\\n+  (ptrmemfunc_vbit_in_pfn)\n+\n+#define INSN_SETS_ARE_DELAYED(X)\t\t\\\n+  (GET_CODE (X) == INSN\t\t\t\t\\\n+   && GET_CODE (PATTERN (X)) != SEQUENCE\t\\\n+   && GET_CODE (PATTERN (X)) != USE\t\t\\\n+   && GET_CODE (PATTERN (X)) != CLOBBER\t\t\\\n+   && (get_attr_type (X) == TYPE_CALL || get_attr_type (X) == TYPE_SFUNC))\n+\n+#define INSN_REFERENCES_ARE_DELAYED(insn) INSN_SETS_ARE_DELAYED (insn)\n+\n+#define CALL_ATTR(X, NAME) \\\n+  ((CALL_P (X) || NONJUMP_INSN_P (X)) \\\n+   && GET_CODE (PATTERN (X)) != USE \\\n+   && GET_CODE (PATTERN (X)) != CLOBBER \\\n+   && get_attr_is_##NAME (X) == IS_##NAME##_YES) \\\n+\n+#define REVERSE_CONDITION(CODE,MODE) \\\n+\t(((MODE) == CC_FP_GTmode || (MODE) == CC_FP_GEmode \\\n+\t  || (MODE) == CC_FP_UNEQmode || (MODE) == CC_FP_ORDmode \\\n+\t  || (MODE) == CC_FPXmode) \\\n+\t ? reverse_condition_maybe_unordered ((CODE)) \\\n+\t : reverse_condition ((CODE)))\n+\n+#define ADJUST_INSN_LENGTH(X, LENGTH) \\\n+  ((LENGTH) \\\n+   = (GET_CODE (PATTERN (X)) == SEQUENCE \\\n+      ? ((LENGTH) \\\n+\t + arc_adjust_insn_length (XVECEXP (PATTERN (X), 0, 0), \\\n+\t\t\t\t   get_attr_length (XVECEXP (PATTERN (X), \\\n+\t\t\t\t\t\t    0, 0)), \\\n+\t\t\t\t   true) \\\n+\t - get_attr_length (XVECEXP (PATTERN (X), 0, 0)) \\\n+\t + arc_adjust_insn_length (XVECEXP (PATTERN (X), 0, 1), \\\n+\t\t\t\t   get_attr_length (XVECEXP (PATTERN (X), \\\n+\t\t\t\t\t\t    0, 1)), \\\n+\t\t\t\t   true) \\\n+\t - get_attr_length (XVECEXP (PATTERN (X), 0, 1))) \\\n+      : arc_adjust_insn_length ((X), (LENGTH), false)))\n+\n+#define IS_ASM_LOGICAL_LINE_SEPARATOR(C,STR) ((C) == '`')\n+\n+#define INIT_EXPANDERS arc_init_expanders ()\n+\n+#define CFA_FRAME_BASE_OFFSET(FUNDECL) (-arc_decl_pretend_args ((FUNDECL)))\n+\n+#define ARG_POINTER_CFA_OFFSET(FNDECL) \\\n+  (FIRST_PARM_OFFSET (FNDECL) + arc_decl_pretend_args ((FNDECL)))\n+\n+enum\n+{\n+  ARC_LRA_PRIORITY_NONE, ARC_LRA_PRIORITY_NONCOMPACT, ARC_LRA_PRIORITY_COMPACT\n+};\n+\n+/* The define_cond_exec construct is rather crude, as we can't have\n+   different ones with different conditions apply to different sets\n+   of instructions.  We can't use an attribute test inside the condition,\n+   because that would lead to infinite recursion as the attribute test\n+   needs to recognize the insn.  So, instead we have a clause for\n+   the pattern condition of all sfunc patterns which is only relevant for\n+   the predicated varaint.  */\n+#define SFUNC_CHECK_PREDICABLE \\\n+  (GET_CODE (PATTERN (insn)) != COND_EXEC || !flag_pic || !TARGET_MEDIUM_CALLS)\n+\n+#endif /* GCC_ARC_H */"}, {"sha": "37103fe6ce0b9d2e4f0acccb6dfece772aba3aaf", "filename": "gcc/config/arc/arc.md", "status": "added", "additions": 5190, "deletions": 0, "changes": 5190, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc.md?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e"}, {"sha": "26e0de43fdab4978d1937c6e2b5a12853b7c9ee7", "filename": "gcc/config/arc/arc.opt", "status": "added", "additions": 390, "deletions": 0, "changes": 390, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc.opt?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -0,0 +1,390 @@\n+; Options for the Synopsys DesignWare ARC port of the compiler\n+;\n+; Copyright (C) 2005, 2007-2013 Free Software Foundation, Inc.\n+;\n+; This file is part of GCC.\n+;\n+; GCC is free software; you can redistribute it and/or modify it under\n+; the terms of the GNU General Public License as published by the Free\n+; Software Foundation; either version 3, or (at your option) any later\n+; version.\n+;\n+; GCC is distributed in the hope that it will be useful, but WITHOUT\n+; ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n+; or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public\n+; License for more details.\n+;\n+; You should have received a copy of the GNU General Public License\n+; along with GCC; see the file COPYING3.  If not see\n+; <http://www.gnu.org/licenses/>.\n+\n+HeaderInclude\n+config/arc/arc-opts.h\n+\n+mbig-endian\n+Target Report RejectNegative Mask(BIG_ENDIAN)\n+Compile code for big endian mode\n+\n+mlittle-endian\n+Target Report RejectNegative InverseMask(BIG_ENDIAN)\n+Compile code for little endian mode.  This is the default\n+\n+mno-cond-exec\n+Target Report RejectNegative Mask(NO_COND_EXEC)\n+Disable ARCompact specific pass to generate conditional execution instructions\n+\n+mA5\n+Target Report\n+Generate ARCompact 32-bit code for ARCtangent-A5 processor\n+\n+mA6\n+Target Report\n+Generate ARCompact 32-bit code for ARC600 processor\n+\n+mARC600\n+Target Report\n+Same as -mA6\n+\n+mARC601\n+Target Report\n+Generate ARCompact 32-bit code for ARC601 processor\n+\n+mA7\n+Target Report\n+Generate ARCompact 32-bit code for ARC700 processor\n+\n+mARC700\n+Target Report\n+Same as -mA7\n+\n+mmixed-code\n+Target Report Mask(MIXED_CODE_SET)\n+Tweak register allocation to help 16-bit instruction generation\n+; originally this was:\n+;Generate ARCompact 16-bit instructions intermixed with 32-bit instructions for ARCtangent-A5 and higher processors\n+; but we do that without -mmixed-code, too, it's just a different instruction\n+; count / size tradeoff.\n+\n+; We use an explict definition for the negative form because that is the\n+; actually interesting option, and we want that to have its own comment.\n+mvolatile-cache\n+Target Report RejectNegative Mask(VOLATILE_CACHE_SET)\n+Use ordinarily cached memory accesses for volatile references\n+\n+mno-volatile-cache\n+Target Report RejectNegative InverseMask(VOLATILE_CACHE_SET)\n+Enable cache bypass for volatile references\n+\n+mbarrel-shifter\n+Target Report Mask(BARREL_SHIFTER)\n+Generate instructions supported by barrel shifter\n+\n+mnorm\n+Target Report Mask(NORM_SET)\n+Generate norm instruction\n+\n+mswap\n+Target Report Mask(SWAP_SET)\n+Generate swap instruction\n+\n+mmul64\n+Target Report Mask(MUL64_SET)\n+Generate mul64 and mulu64 instructions\n+\n+mno-mpy\n+Target Report Mask(NOMPY_SET)\n+Do not generate mpy instructions for ARC700\n+\n+mea\n+Target Report Mask(EA_SET)\n+Generate Extended arithmetic instructions.  Currently only divaw, adds, subs and sat16 are supported\n+\n+msoft-float\n+Target Report Mask(0)\n+Dummy flag. This is the default unless FPX switches are provided explicitly\n+\n+mlong-calls\n+Target Report Mask(LONG_CALLS_SET)\n+Generate call insns as register indirect calls\n+\n+mno-brcc\n+Target Report Mask(NO_BRCC_SET)\n+Do no generate BRcc instructions in arc_reorg.\n+\n+msdata\n+Target Report InverseMask(NO_SDATA_SET)\n+Generate sdata references.  This is the default, unless you compile for PIC.\n+\n+mno-millicode\n+Target Report Mask(NO_MILLICODE_THUNK_SET)\n+Do not generate millicode thunks (needed only with -Os)\n+\n+mspfp\n+Target Report Mask(SPFP_COMPACT_SET)\n+FPX: Generate Single Precision FPX (compact) instructions.\n+\n+mspfp-compact\n+Target Report Mask(SPFP_COMPACT_SET) MaskExists\n+FPX: Generate Single Precision FPX (compact) instructions.\n+\n+mspfp-fast\n+Target Report Mask(SPFP_FAST_SET)\n+FPX: Generate Single Precision FPX (fast) instructions.\n+\n+margonaut\n+Target Report Mask(ARGONAUT_SET)\n+FPX: Enable Argonaut ARC CPU Double Precision Floating Point extensions.\n+\n+mdpfp\n+Target Report Mask(DPFP_COMPACT_SET)\n+FPX: Generate Double Precision FPX (compact) instructions.\n+\n+mdpfp-compact\n+Target Report Mask(DPFP_COMPACT_SET) MaskExists\n+FPX: Generate Double Precision FPX (compact) instructions.\n+\n+mdpfp-fast\n+Target Report Mask(DPFP_FAST_SET)\n+FPX: Generate Double Precision FPX (fast) instructions.\n+\n+mno-dpfp-lrsr\n+Target Report Mask(DPFP_DISABLE_LRSR)\n+Disable LR and SR instructions from using FPX extension aux registers.\n+\n+msimd\n+Target Report Mask(SIMD_SET)\n+Enable generation of ARC SIMD instructions via target-specific builtins.\n+\n+mcpu=\n+Target RejectNegative Joined Var(arc_cpu) Enum(processor_type) Init(PROCESSOR_NONE)\n+-mcpu=CPU\tCompile code for ARC variant CPU\n+\n+Enum\n+Name(processor_type) Type(enum processor_type)\n+\n+EnumValue\n+Enum(processor_type) String(A5) Value(PROCESSOR_A5)\n+\n+EnumValue\n+Enum(processor_type) String(ARC600) Value(PROCESSOR_ARC600)\n+\n+EnumValue\n+Enum(processor_type) String(ARC601) Value(PROCESSOR_ARC601)\n+\n+EnumValue\n+Enum(processor_type) String(ARC700) Value(PROCESSOR_ARC700)\n+\n+msize-level=\n+Target RejectNegative Joined UInteger Var(arc_size_opt_level) Init(-1)\n+size optimization level: 0:none 1:opportunistic 2: regalloc 3:drop align, -Os\n+\n+misize\n+Target Report Var(TARGET_DUMPISIZE)\n+Annotate assembler instructions with estimated addresses\n+\n+mmultcost=\n+Target RejectNegative Joined UInteger Var(arc_multcost) Init(-1)\n+Cost to assume for a multiply instruction, with 4 being equal to a normal insn.\n+\n+mtune=ARC600\n+Target RejectNegative Var(arc_tune, TUNE_ARC600)\n+Tune for ARC600 cpu.\n+\n+mtune=ARC601\n+Target RejectNegative Var(arc_tune, TUNE_ARC600)\n+Tune for ARC601 cpu.\n+\n+mtune=ARC700\n+Target RejectNegative Var(arc_tune, TUNE_ARC700_4_2_STD)\n+Tune for ARC700 R4.2 Cpu with standard multiplier block.\n+\n+mtune=ARC700-xmac\n+Target RejectNegative Var(arc_tune, TUNE_ARC700_4_2_XMAC)\n+Tune for ARC700 R4.2 Cpu with XMAC block.\n+\n+mtune=ARC725D\n+Target RejectNegative Var(arc_tune, TUNE_ARC700_4_2_XMAC)\n+Tune for ARC700 R4.2 Cpu with XMAC block.\n+\n+mtune=ARC750D\n+Target RejectNegative Var(arc_tune, TUNE_ARC700_4_2_XMAC)\n+Tune for ARC700 R4.2 Cpu with XMAC block.\n+\n+mindexed-loads\n+Target Var(TARGET_INDEXED_LOADS)\n+Enable the use of indexed loads\n+\n+mauto-modify-reg\n+Target Var(TARGET_AUTO_MODIFY_REG)\n+Enable the use of pre/post modify with register displacement.\n+\n+mmul32x16\n+Target Report Mask(MULMAC_32BY16_SET)\n+Generate 32x16 multiply and mac instructions\n+\n+; the initializer is supposed to be: Init(REG_BR_PROB_BASE/2) ,\n+; alas, basic-block.h is not included in options.c .\n+munalign-prob-threshold=\n+Target RejectNegative Joined UInteger Var(arc_unalign_prob_threshold) Init(10000/2)\n+Set probability threshold for unaligning branches\n+\n+mmedium-calls\n+Target Var(TARGET_MEDIUM_CALLS) Init(TARGET_MMEDIUM_CALLS_DEFAULT)\n+Don't use less than 25 bit addressing range for calls.\n+\n+mannotate-align\n+Target Var(TARGET_ANNOTATE_ALIGN)\n+Explain what alignment considerations lead to the decision to make an insn short or long.\n+\n+malign-call\n+Target Var(TARGET_ALIGN_CALL)\n+Do alignment optimizations for call instructions.\n+\n+mRcq\n+Target Var(TARGET_Rcq)\n+Enable Rcq constraint handling - most short code generation depends on this.\n+\n+mRcw\n+Target Var(TARGET_Rcw)\n+Enable Rcw constraint handling - ccfsm condexec mostly depends on this.\n+\n+mearly-cbranchsi\n+Target Var(TARGET_EARLY_CBRANCHSI)\n+Enable pre-reload use of cbranchsi pattern\n+\n+mbbit-peephole\n+Target Var(TARGET_BBIT_PEEPHOLE)\n+Enable bbit peephole2\n+\n+mcase-vector-pcrel\n+Target Var(TARGET_CASE_VECTOR_PC_RELATIVE)\n+Use pc-relative switch case tables - this enables case table shortening.\n+\n+mcompact-casesi\n+Target Var(TARGET_COMPACT_CASESI)\n+Enable compact casesi pattern\n+\n+mq-class\n+Target Var(TARGET_Q_CLASS)\n+Enable 'q' instruction alternatives.\n+\n+mexpand-adddi\n+Target Var(TARGET_EXPAND_ADDDI)\n+Expand adddi3 and subdi3 at rtl generation time into add.f / adc etc.\n+\n+\n+; Flags used by the assembler, but for which we define preprocessor\n+; macro symbols as well.\n+mcrc\n+Target Report\n+Enable variable polynomial CRC extension\n+\n+mdsp-packa\n+Target Report\n+Enable DSP 3.1 Pack A extensions\n+\n+mdvbf\n+Target Report\n+Enable dual viterbi butterfly extension\n+\n+mmac-d16\n+Target Report Undocumented\n+\n+mmac-24\n+Target Report Undocumented\n+\n+mtelephony\n+Target Report RejectNegative\n+Enable Dual and Single Operand Instructions for Telephony\n+\n+mxy\n+Target Report\n+Enable XY Memory extension (DSP version 3)\n+\n+; ARC700 4.10 extension instructions\n+mlock\n+Target Report\n+Enable Locked Load/Store Conditional extension\n+\n+mswape\n+Target Report\n+Enable swap byte ordering extension instruction\n+\n+mrtsc\n+Target Report\n+Enable 64-bit Time-Stamp Counter extension instruction\n+\n+mno-epilogue-cfi\n+Target Report RejectNegative InverseMask(EPILOGUE_CFI)\n+Disable generation of cfi for epilogues.\n+\n+mepilogue-cfi\n+Target RejectNegative Mask(EPILOGUE_CFI)\n+Enable generation of cfi for epilogues.\n+\n+EB\n+Target\n+Pass -EB option through to linker.\n+\n+EL\n+Target\n+Pass -EL option through to linker.\n+\n+marclinux\n+target\n+Pass -marclinux option through to linker.\n+\n+marclinux_prof\n+target\n+Pass -marclinux_prof option through to linker.\n+\n+;; lra is still unproven for ARC, so allow to fall back to reload with -mno-lra.\n+;Target InverseMask(NO_LRA)\n+mlra\n+; lra still won't allow to configure libgcc; see PR rtl-optimization/55464.\n+; so don't enable by default.\n+Target Mask(LRA)\n+Enable lra\n+\n+mlra-priority-none\n+Target RejectNegative Var(arc_lra_priority_tag, ARC_LRA_PRIORITY_NONE)\n+Don't indicate any priority with TARGET_REGISTER_PRIORITY\n+\n+mlra-priority-compact\n+Target RejectNegative Var(arc_lra_prioritytag, ARC_LRA_PRIORITY_COMPACT)\n+Indicate priority for r0..r3 / r12..r15 with TARGET_REGISTER_PRIORITY\n+\n+mlra-priority-noncompact\n+Target RejectNegative Var(arc_lra_prioritytag, ARC_LRA_PRIORITY_NONCOMPACT)\n+Reduce priority for r0..r3 / r12..r15 with TARGET_REGISTER_PRIORITY\n+\n+mucb-mcount\n+Target Report Var(TARGET_UCB_MCOUNT)\n+instrument with mcount calls as in the ucb code\n+\n+; backward-compatibility aliases, translated by DRIVER_SELF_SPECS\n+\n+mEA\n+Target\n+\n+multcost=\n+Target RejectNegative Joined\n+\n+; Unfortunately, listing the full option name gives us clashes\n+; with OPT_opt_name being claimed for both opt_name and opt-name,\n+; so we leave out the last character or more.\n+mbarrel_shifte\n+Target Joined\n+\n+mspfp_\n+Target Joined\n+\n+mdpfp_\n+Target Joined\n+\n+mdsp_pack\n+Target Joined\n+\n+mmac_\n+Target Joined\n+"}, {"sha": "f5665178322d17030ad314c82cd5ad59ecba46f3", "filename": "gcc/config/arc/arc600.md", "status": "added", "additions": 63, "deletions": 0, "changes": 63, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc600.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc600.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc600.md?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -0,0 +1,63 @@\n+;; DFA scheduling description of the Synopsys DesignWare ARC600 cpu\n+;; for GNU C compiler\n+;; Copyright (C) 2007-2013 Free Software Foundation, Inc.\n+;; Contributor: Joern Rennecke <joern.rennecke@embecosm.com>\n+;;              on behalf of Synopsys Inc.\n+\n+;; This file is part of GCC.\n+\n+;; GCC is free software; you can redistribute it and/or modify\n+;; it under the terms of the GNU General Public License as published by\n+;; the Free Software Foundation; either version 3, or (at your option)\n+;; any later version.\n+\n+;; GCC is distributed in the hope that it will be useful,\n+;; but WITHOUT ANY WARRANTY; without even the implied warranty of\n+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+;; GNU General Public License for more details.\n+\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+(define_automaton \"ARC600\")\n+\n+(define_cpu_unit \"issue_600\" \"ARC600\")\n+(define_cpu_unit \"mul64_600\" \"ARC600\")\n+\n+; latency from flag-setting insns to branches is 3.\n+(define_insn_reservation \"compare_600\" 3\n+  (and (eq_attr \"tune\" \"arc600\")\n+       (eq_attr \"type\" \"compare\"))\n+  \"issue_600\")\n+\n+(define_insn_reservation \"load_DI_600\" 4\n+  (and (eq_attr \"tune\" \"arc600\")\n+       (eq_attr \"type\" \"load\")\n+       (match_operand:DI 0 \"\" \"\"))\n+  \"issue_600\")\n+\n+(define_insn_reservation \"load_600\" 3\n+  (and (eq_attr \"tune\" \"arc600\")\n+       (eq_attr \"type\" \"load\")\n+       (not (match_operand:DI 0 \"\" \"\")))\n+  \"issue_600\")\n+\n+(define_insn_reservation \"mul_600_fast\" 3\n+  (and (eq_attr \"tune\" \"arc600\")\n+       (match_test \"arc_multcost < COSTS_N_INSNS (7)\")\n+       (eq_attr \"type\" \"multi,umulti\"))\n+  \"mul64_600*3\")\n+\n+(define_insn_reservation \"mul_600_slow\" 8\n+  (and (eq_attr \"tune\" \"arc600\")\n+       (match_test \"arc_multcost >= COSTS_N_INSNS (7)\")\n+       (eq_attr \"type\" \"multi,umulti\"))\n+  \"mul64_600*8\")\n+\n+(define_insn_reservation \"mul_mac_600\" 3\n+  (and (eq_attr \"tune\" \"arc600\")\n+       (eq_attr \"type\" \"mulmac_600\"))\n+  \"nothing*3\")\n+\n+(define_bypass 1 \"mul_mac_600\" \"mul_mac_600\")"}, {"sha": "59fc94176209de6ffab349369909e6b323001e39", "filename": "gcc/config/arc/arc700.md", "status": "added", "additions": 170, "deletions": 0, "changes": 170, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc700.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Farc700.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Farc700.md?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -0,0 +1,170 @@\n+;; DFA scheduling description of the Synopsys DesignWare ARC700 cpu\n+;; for GNU C compiler\n+;;    Comments and Support For ARC700 instructions added by\n+;;    Saurabh Verma (saurabh.verma@codito.com)\n+;;    Ramana Radhakrishnan(ramana.radhakrishnan@codito.com)\n+;;    Factoring out and improvement of ARC700 Scheduling by\n+;;    Joern Rennecke (joern.rennecke@embecosm.com)\n+;; Copyright (C) 2006-2012 Free Software Foundation, Inc.\n+\n+;; This file is part of GCC.\n+\n+;; GCC is free software; you can redistribute it and/or modify\n+;; it under the terms of the GNU General Public License as published by\n+;; the Free Software Foundation; either version 3, or (at your option)\n+;; any later version.\n+\n+;; GCC is distributed in the hope that it will be useful,\n+;; but WITHOUT ANY WARRANTY; without even the implied warranty of\n+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+;; GNU General Public License for more details.\n+\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+(define_automaton \"ARC700\")\n+\n+;; aux to be added here\n+(define_cpu_unit \"core, dmp,  write_port, dmp_write_port, multiplier, issue, blockage, simd_unit\" \"ARC700\")\n+\n+(define_insn_reservation \"core_insn_DI\" 2\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"unary, move, cmove, binary\")\n+       (match_operand:DI 0 \"\" \"\"))\n+  \"issue+core, issue+core+write_port, write_port\")\n+\n+(define_insn_reservation \"lr\" 2\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"lr\"))\n+  \"issue+blockage, blockage*2, write_port\")\n+\n+(define_insn_reservation \"sr\" 1\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"sr\"))\n+  \"issue+dmp_write_port+blockage, blockage*9\")\n+\n+(define_insn_reservation \"core_insn\" 1\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"unary, move, binary\"))\n+  \"issue+core, nothing, write_port\")\n+\n+(define_insn_reservation \"cmove\" 1\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"cmove\"))\n+  \"issue+core, nothing, write_port\")\n+\n+(define_insn_reservation \"cc_arith\" 1\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"cc_arith\"))\n+  \"issue+core, nothing, write_port\")\n+\n+(define_insn_reservation \"two_cycle_core_insn\" 2\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"two_cycle_core\"))\n+  \"issue+core, nothing, write_port\")\n+\n+(define_insn_reservation \"divaw_insn\" 2\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"divaw\"))\n+  \"issue+core, nothing, write_port\")\n+\n+(define_insn_reservation \"shift_insn\" 2\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"shift\"))\n+  \"issue+core, nothing, write_port\")\n+\n+; Latency from flag setters to arithmetic with carry is 3.\n+(define_insn_reservation \"compare_700\" 3\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"compare\"))\n+  \"issue+core, nothing, write_port\")\n+\n+; Assume here the branch is predicted correctly and has a delay slot insn\n+; or is properly unaligned.\n+(define_insn_reservation \"branch_700\" 1\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"compare\"))\n+  \"issue+core, nothing, write_port\")\n+\n+; TODOs: is this correct ??\n+(define_insn_reservation \"multi_DI\" 10\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"multi\")\n+       (match_operand:DI 0 \"\" \"\"))\n+  \"issue+multiplier, multiplier*2,issue+multiplier, multiplier*2,\n+   nothing,write_port,nothing*2, write_port\")\n+\n+(define_insn_reservation \"umulti_DI\" 9\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"umulti\")\n+       (match_operand:DI 0 \"\" \"\"))\n+  \"issue+multiplier, multiplier,issue+multiplier, multiplier*2,\n+   write_port,nothing*3, write_port\")\n+\n+(define_insn_reservation \"umulti_xmac\" 5\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"umulti\"))\n+  \"issue+multiplier, multiplier, nothing*3, write_port\")\n+\n+; latency of mpyu is lower than mpy / mpyh / mpyhu\n+(define_insn_reservation \"umulti_std\" 6\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"umulti\"))\n+  \"issue+multiplier, multiplier*3, nothing*2, write_port\")\n+\n+;; arc700 xmac multiplier\n+(define_insn_reservation \"multi_xmac\" 5\n+  (and (eq_attr \"tune\" \"arc700_4_2_xmac\")\n+       (eq_attr \"type\" \"multi\"))\n+  \"issue+multiplier,multiplier,nothing*3,write_port\")\n+\n+; arc700 standard multiplier\n+(define_insn_reservation \"multi_std\" 7\n+  (and (eq_attr \"tune\" \"arc700_4_2_std\")\n+       (eq_attr \"type\" \"multi\"))\n+  \"issue+multiplier,multiplier*4,nothing*2,write_port\")\n+\n+;(define_insn_reservation \"multi_SI\" 7\n+;       (eq_attr \"type\" \"multi\")\n+;  \"issue+multiplier, multiplier*2, nothing*4, write_port\")\n+\n+; There is no multiplier -> multiplier bypass except for the\n+; mac -> mac dependency on the accumulator.\n+\n+; divaw -> divaw latency is 1 cycle\n+(define_bypass 1 \"divaw_insn\" \"divaw_insn\")\n+\n+(define_bypass 1 \"compare_700\" \"branch_700,core_insn,data_store,data_load\")\n+\n+; we could shedule the cmove immediately after the compare, but then\n+; the cmove would have higher latency... so just keep the cmove apart\n+; from the compare.\n+(define_bypass 2 \"compare_700\" \"cmove\")\n+\n+; no functional unit runs when blockage is reserved\n+(exclusion_set \"blockage\" \"core, multiplier\")\n+\n+(define_insn_reservation \"data_load_DI\" 4\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"load\")\n+       (match_operand:DI 0 \"\" \"\"))\n+  \"issue+dmp, issue+dmp, dmp_write_port, dmp_write_port\")\n+\n+(define_insn_reservation \"data_load\" 3\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"load\")\n+       (not (match_operand:DI 0 \"\" \"\")))\n+  \"issue+dmp, nothing, dmp_write_port\")\n+\n+(define_insn_reservation \"data_store_DI\" 2\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"store\")\n+       (match_operand:DI 0 \"\" \"\"))\n+  \"issue+dmp_write_port, issue+dmp_write_port\")\n+\n+(define_insn_reservation \"data_store\" 1\n+  (and (eq_attr \"tune_arc700\" \"true\")\n+       (eq_attr \"type\" \"store\")\n+       (not (match_operand:DI 0 \"\" \"\")))\n+  \"issue+dmp_write_port\")"}, {"sha": "088013bbdb7ec91b295c975c2cda3002e7da03a6", "filename": "gcc/config/arc/constraints.md", "status": "added", "additions": 399, "deletions": 0, "changes": 399, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Fconstraints.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Fconstraints.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Fconstraints.md?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -0,0 +1,399 @@\n+;; Constraint definitions for Synopsys DesignWare ARC.\n+;; Copyright (C) 2007-2013 Free Software Foundation, Inc.\n+;;\n+;; This file is part of GCC.\n+;;\n+;; GCC is free software; you can redistribute it and/or modify\n+;; it under the terms of the GNU General Public License as published by\n+;; the Free Software Foundation; either version 3, or (at your option)\n+;; any later version.\n+;;\n+;; GCC is distributed in the hope that it will be useful,\n+;; but WITHOUT ANY WARRANTY; without even the implied warranty of\n+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+;; GNU General Public License for more details.\n+;;\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+;; Register constraints\n+\n+; Most instructions accept arbitrary core registers for their inputs, even\n+; if the core register in question cannot be written to, like the multiply\n+; result registers of the ARCtangent-A5 and ARC600 .\n+; First, define a class for core registers that can be read cheaply.  This\n+; is most or all core registers for ARC600, but only r0-r31 for ARC700\n+(define_register_constraint \"c\" \"CHEAP_CORE_REGS\"\n+  \"core register @code{r0}-@code{r31}, @code{ap},@code{pcl}\")\n+\n+; All core regs - e.g. for when we must have a way to reload a register.\n+(define_register_constraint \"Rac\" \"ALL_CORE_REGS\"\n+  \"core register @code{r0}-@code{r60}, @code{ap},@code{pcl}\")\n+\n+; Some core registers (.e.g lp_count) aren't general registers because they\n+; can't be used as the destination of a multi-cycle operation like\n+; load and/or multiply, yet they are still writable in the sense that\n+; register-register moves and single-cycle arithmetic (e.g \"add\", \"and\",\n+; but not \"mpy\") can write to them.\n+(define_register_constraint \"w\" \"WRITABLE_CORE_REGS\"\n+  \"writable core register: @code{r0}-@code{r31}, @code{r60}, nonfixed core register\")\n+\n+(define_register_constraint \"W\" \"MPY_WRITABLE_CORE_REGS\"\n+  \"writable core register except @code{LP_COUNT} (@code{r60}): @code{r0}-@code{r31}, nonfixed core register\")\n+\n+(define_register_constraint \"l\" \"LPCOUNT_REG\"\n+  \"@internal\n+   Loop count register @code{r60}\")\n+\n+(define_register_constraint \"x\" \"R0_REGS\"\n+  \"@code{R0} register.\")\n+\n+(define_register_constraint \"Rgp\" \"GP_REG\"\n+  \"@internal\n+   Global Pointer register @code{r26}\")\n+\n+(define_register_constraint \"f\" \"FP_REG\"\n+  \"@internal\n+   Frame Pointer register @code{r27}\")\n+\n+(define_register_constraint \"b\" \"SP_REGS\"\n+  \"@internal\n+   Stack Pointer register @code{r28}\")\n+\n+(define_register_constraint \"k\" \"LINK_REGS\"\n+  \"@internal\n+   Link Registers @code{ilink1}:@code{r29}, @code{ilink2}:@code{r30},\n+   @code{blink}:@code{r31},\")\n+\n+(define_register_constraint \"q\" \"ARCOMPACT16_REGS\"\n+  \"Registers usable in ARCompact 16-bit instructions: @code{r0}-@code{r3},\n+   @code{r12}-@code{r15}\")\n+\n+(define_register_constraint \"e\" \"AC16_BASE_REGS\"\n+  \"Registers usable as base-regs of memory addresses in ARCompact 16-bit memory\n+   instructions: @code{r0}-@code{r3}, @code{r12}-@code{r15}, @code{sp}\")\n+\n+(define_register_constraint \"D\" \"DOUBLE_REGS\"\n+  \"ARC FPX (dpfp) 64-bit registers. @code{D0}, @code{D1}\")\n+\n+(define_register_constraint \"d\" \"SIMD_DMA_CONFIG_REGS\"\n+  \"@internal\n+   ARC SIMD DMA configuration registers @code{di0}-@code{di7},\n+   @code{do0}-@code{do7}\")\n+\n+(define_register_constraint \"v\" \"SIMD_VR_REGS\"\n+  \"ARC SIMD 128-bit registers @code{VR0}-@code{VR23}\")\n+\n+; We could allow call-saved registers for sibling calls if we restored them\n+; in the delay slot of the call.  However, that would not allow to adjust the\n+; stack pointer afterwards, so the call-saved register would have to be\n+; restored from a call-used register that was just loaded with the value\n+; before.  So sticking to call-used registers for sibcalls will likely\n+; generate better code overall.\n+(define_register_constraint \"Rsc\" \"SIBCALL_REGS\"\n+  \"@internal\n+   Sibling call register\")\n+\n+;; Integer constraints\n+\n+(define_constraint \"I\"\n+  \"@internal\n+   A signed 12-bit integer constant.\"\n+  (and (match_code \"const_int\")\n+       (match_test \"SIGNED_INT12 (ival)\")))\n+\n+(define_constraint \"K\"\n+  \"@internal\n+   A 3-bit unsigned integer constant\"\n+  (and (match_code \"const_int\")\n+       (match_test \"UNSIGNED_INT3 (ival)\")))\n+\n+(define_constraint \"L\"\n+  \"@internal\n+   A 6-bit unsigned integer constant\"\n+  (and (match_code \"const_int\")\n+       (match_test \"UNSIGNED_INT6 (ival)\")))\n+\n+(define_constraint \"CnL\"\n+  \"@internal\n+   One's complement of a 6-bit unsigned integer constant\"\n+  (and (match_code \"const_int\")\n+       (match_test \"UNSIGNED_INT6 (~ival)\")))\n+\n+(define_constraint \"CmL\"\n+  \"@internal\n+   Two's complement of a 6-bit unsigned integer constant\"\n+  (and (match_code \"const_int\")\n+       (match_test \"UNSIGNED_INT6 (-ival)\")))\n+\n+(define_constraint \"M\"\n+  \"@internal\n+   A 5-bit unsigned integer constant\"\n+  (and (match_code \"const_int\")\n+       (match_test \"UNSIGNED_INT5 (ival)\")))\n+\n+(define_constraint \"N\"\n+  \"@internal\n+   Integer constant 1\"\n+  (and (match_code \"const_int\")\n+       (match_test \"IS_ONE (ival)\")))\n+\n+(define_constraint \"O\"\n+  \"@internal\n+   A 7-bit unsigned integer constant\"\n+  (and (match_code \"const_int\")\n+       (match_test \"UNSIGNED_INT7 (ival)\")))\n+\n+(define_constraint \"P\"\n+  \"@internal\n+   An 8-bit unsigned integer constant\"\n+  (and (match_code \"const_int\")\n+       (match_test \"UNSIGNED_INT8 (ival)\")))\n+\n+(define_constraint \"C_0\"\n+  \"@internal\n+   Zero\"\n+  (and (match_code \"const_int\")\n+       (match_test \"ival == 0\")))\n+\n+(define_constraint \"Cn0\"\n+  \"@internal\n+   Negative or zero\"\n+  (and (match_code \"const_int\")\n+       (match_test \"ival <= 0\")))\n+\n+(define_constraint \"Cca\"\n+  \"@internal\n+   Conditional or three-address add / sub constant\"\n+  (and (match_code \"const_int\")\n+       (match_test \"ival == -1 << 31\n+\t\t    || (ival >= -0x1f8 && ival <= 0x1f8\n+\t\t\t&& ((ival >= 0 ? ival : -ival)\n+\t\t\t    <= 0x3f * (ival & -ival)))\")))\n+\n+; intersection of \"O\" and \"Cca\".\n+(define_constraint \"CL2\"\n+  \"@internal\n+   A 6-bit unsigned integer constant times 2\"\n+  (and (match_code \"const_int\")\n+       (match_test \"!(ival & ~126)\")))\n+\n+(define_constraint \"CM4\"\n+  \"@internal\n+   A 5-bit unsigned integer constant times 4\"\n+  (and (match_code \"const_int\")\n+       (match_test \"!(ival & ~124)\")))\n+\n+(define_constraint \"Csp\"\n+  \"@internal\n+   A valid stack pointer offset for a short add\"\n+  (and (match_code \"const_int\")\n+       (match_test \"!(ival & ~124) || !(-ival & ~124)\")))\n+\n+(define_constraint \"C2a\"\n+  \"@internal\n+   Unconditional two-address add / sub constant\"\n+  (and (match_code \"const_int\")\n+       (match_test \"ival == -1 << 31\n+\t\t    || (ival >= -0x4000 && ival <= 0x4000\n+\t\t\t&& ((ival >= 0 ? ival : -ival)\n+\t\t\t    <= 0x7ff * (ival & -ival)))\")))\n+\n+(define_constraint \"C0p\"\n+ \"@internal\n+  power of two\"\n+  (and (match_code \"const_int\")\n+       (match_test \"IS_POWEROF2_P (ival)\")))\n+\n+(define_constraint \"C1p\"\n+ \"@internal\n+  constant such that x+1 is a power of two, and x != 0\"\n+  (and (match_code \"const_int\")\n+       (match_test \"ival && IS_POWEROF2_P (ival + 1)\")))\n+\n+(define_constraint \"Ccp\"\n+ \"@internal\n+  constant such that ~x (one's Complement) is a power of two\"\n+  (and (match_code \"const_int\")\n+       (match_test \"IS_POWEROF2_P (~ival)\")))\n+\n+(define_constraint \"Cux\"\n+ \"@internal\n+  constant such that AND gives an unsigned extension\"\n+  (and (match_code \"const_int\")\n+       (match_test \"ival == 0xff || ival == 0xffff\")))\n+\n+(define_constraint \"Crr\"\n+ \"@internal\n+  constant that can be loaded with ror b,u6\"\n+  (and (match_code \"const_int\")\n+       (match_test \"(ival & ~0x8000001f) == 0 && !arc_ccfsm_cond_exec_p ()\")))\n+\n+;; Floating-point constraints\n+\n+(define_constraint \"G\"\n+  \"@internal\n+   A 32-bit constant double value\"\n+  (and (match_code \"const_double\")\n+       (match_test \"arc_double_limm_p (op)\")))\n+\n+(define_constraint \"H\"\n+  \"@internal\n+   All const_double values (including 64-bit values)\"\n+  (and (match_code \"const_double\")\n+       (match_test \"1\")))\n+\n+;; Memory constraints\n+(define_memory_constraint \"T\"\n+  \"@internal\n+   A valid memory operand for ARCompact load instructions\"\n+  (and (match_code \"mem\")\n+       (match_test \"compact_load_memory_operand (op, VOIDmode)\")))\n+\n+(define_memory_constraint \"S\"\n+  \"@internal\n+   A valid memory operand for ARCompact store instructions\"\n+  (and (match_code \"mem\")\n+       (match_test \"compact_store_memory_operand (op, VOIDmode)\")))\n+\n+(define_memory_constraint \"Usd\"\n+  \"@internal\n+   A valid _small-data_ memory operand for ARCompact instructions\"\n+  (and (match_code \"mem\")\n+       (match_test \"compact_sda_memory_operand (op, VOIDmode)\")))\n+\n+(define_memory_constraint \"Usc\"\n+  \"@internal\n+   A valid memory operand for storing constants\"\n+  (and (match_code \"mem\")\n+       (match_test \"!CONSTANT_P (XEXP (op,0))\")\n+;; ??? the assembler rejects stores of immediates to small data.\n+       (match_test \"!compact_sda_memory_operand (op, VOIDmode)\")))\n+\n+(define_memory_constraint \"Us<\"\n+  \"@internal\n+   Stack pre-decrement\"\n+  (and (match_code \"mem\")\n+       (match_test \"GET_CODE (XEXP (op, 0)) == PRE_DEC\")\n+       (match_test \"REG_P (XEXP (XEXP (op, 0), 0))\")\n+       (match_test \"REGNO (XEXP (XEXP (op, 0), 0)) == SP_REG\")))\n+\n+(define_memory_constraint \"Us>\"\n+  \"@internal\n+   Stack post-increment\"\n+  (and (match_code \"mem\")\n+       (match_test \"GET_CODE (XEXP (op, 0)) == POST_INC\")\n+       (match_test \"REG_P (XEXP (XEXP (op, 0), 0))\")\n+       (match_test \"REGNO (XEXP (XEXP (op, 0), 0)) == SP_REG\")))\n+\n+;; General constraints\n+\n+(define_constraint \"Cbr\"\n+  \"Branch destination\"\n+  (ior (and (match_code \"symbol_ref\")\n+\t    (match_test \"!arc_is_longcall_p (op)\"))\n+       (match_code \"label_ref\")))\n+\n+(define_constraint \"Cbp\"\n+  \"predicable branch/call destination\"\n+  (ior (and (match_code \"symbol_ref\")\n+\t    (match_test \"arc_is_shortcall_p (op)\"))\n+       (match_code \"label_ref\")))\n+\n+(define_constraint \"Cpc\"\n+  \"pc-relative constant\"\n+  (match_test \"arc_legitimate_pc_offset_p (op)\"))\n+\n+(define_constraint \"Clb\"\n+  \"label\"\n+  (and (match_code \"label_ref\")\n+       (match_test \"arc_text_label (XEXP (op, 0))\")))\n+\n+(define_constraint \"Cal\"\n+  \"constant for arithmetic/logical operations\"\n+  (match_test \"immediate_operand (op, VOIDmode) && !arc_legitimate_pc_offset_p (op)\"))\n+\n+(define_constraint \"C32\"\n+  \"32 bit constant for arithmetic/logical operations\"\n+  (match_test \"immediate_operand (op, VOIDmode)\n+\t       && !arc_legitimate_pc_offset_p (op)\n+\t       && !satisfies_constraint_I (op)\"))\n+\n+; Note that the 'cryptic' register constraints will not make reload use the\n+; associated class to reload into, but this will not penalize reloading of any\n+; other operands, or using an alternate part of the same alternative.\n+\n+; Rcq is different in three important ways from a register class constraint:\n+; - It does not imply a register class, hence reload will not use it to drive\n+;   reloads.\n+; - It matches even when there is no register class to describe its accepted\n+;   set; not having such a set again lessens the impact on register allocation.\n+; - It won't match when the instruction is conditionalized by the ccfsm.\n+(define_constraint \"Rcq\"\n+  \"@internal\n+   Cryptic q - for short insn generation while not affecting register allocation\n+   Registers usable in ARCompact 16-bit instructions: @code{r0}-@code{r3},\n+   @code{r12}-@code{r15}\"\n+  (and (match_code \"REG\")\n+       (match_test \"TARGET_Rcq\n+\t\t    && !arc_ccfsm_cond_exec_p ()\n+\t\t    && ((((REGNO (op) & 7) ^ 4) - 4) & 15) == REGNO (op)\")))\n+\n+; If we need a reload, we generally want to steer reload to use three-address\n+; alternatives in preference of two-address alternatives, unless the\n+; three-address alternative introduces a LIMM that is unnecessary for the\n+; two-address alternative.\n+(define_constraint \"Rcw\"\n+  \"@internal\n+   Cryptic w - for use in early alternatives with matching constraint\"\n+  (and (match_code \"REG\")\n+       (match_test\n+\t\"TARGET_Rcw\n+\t && REGNO (op) < FIRST_PSEUDO_REGISTER\n+\t && TEST_HARD_REG_BIT (reg_class_contents[WRITABLE_CORE_REGS],\n+\t\t\t       REGNO (op))\")))\n+\n+(define_constraint \"Rcr\"\n+  \"@internal\n+   Cryptic r - for use in early alternatives with matching constraint\"\n+  (and (match_code \"REG\")\n+       (match_test\n+\t\"TARGET_Rcw\n+\t && REGNO (op) < FIRST_PSEUDO_REGISTER\n+\t && TEST_HARD_REG_BIT (reg_class_contents[GENERAL_REGS],\n+\t\t\t       REGNO (op))\")))\n+\n+(define_constraint \"Rcb\"\n+  \"@internal\n+   Stack Pointer register @code{r28} - do not reload into its class\"\n+  (and (match_code \"REG\")\n+       (match_test \"REGNO (op) == 28\")))\n+\n+(define_constraint \"Rck\"\n+  \"@internal\n+   blink (usful for push_s / pop_s)\"\n+  (and (match_code \"REG\")\n+       (match_test \"REGNO (op) == 31\")))\n+\n+(define_constraint \"Rs5\"\n+  \"@internal\n+   sibcall register - only allow one of the five available 16 bit isnsn.\n+   Registers usable in ARCompact 16-bit instructions: @code{r0}-@code{r3},\n+   @code{r12}\"\n+  (and (match_code \"REG\")\n+       (match_test \"!arc_ccfsm_cond_exec_p ()\")\n+       (ior (match_test \"(unsigned) REGNO (op) <= 3\")\n+\t    (match_test \"REGNO (op) == 12\"))))\n+\n+(define_constraint \"Rcc\"\n+  \"@internal\n+  Condition Codes\"\n+  (and (match_code \"REG\") (match_test \"cc_register (op, VOIDmode)\")))\n+\n+\n+(define_constraint \"Q\"\n+  \"@internal\n+   Integer constant zero\"\n+  (and (match_code \"const_int\")\n+       (match_test \"IS_ZERO (ival)\")))"}, {"sha": "10a5dcd3b66a447dc3c36e7c4f377fc75b56443d", "filename": "gcc/config/arc/fpx.md", "status": "added", "additions": 674, "deletions": 0, "changes": 674, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Ffpx.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Ffpx.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Ffpx.md?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -0,0 +1,674 @@\n+;; Machine description of the Synopsys DesignWare ARC cpu Floating Point\n+;; extensions for GNU C compiler\n+;; Copyright (C) 2007-2013 Free Software Foundation, Inc.\n+\n+;; This file is part of GCC.\n+\n+;; GCC is free software; you can redistribute it and/or modify\n+;; it under the terms of the GNU General Public License as published by\n+;; the Free Software Foundation; either version 3, or (at your option)\n+;; any later version.\n+\n+;; GCC is distributed in the hope that it will be useful,\n+;; but WITHOUT ANY WARRANTY; without even the implied warranty of\n+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+;; GNU General Public License for more details.\n+\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; TODOs:\n+;;        dpfp blocks?\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; Scheduler descriptions for the fpx instructions\n+(define_insn_reservation \"spfp_compact\" 3\n+  (and (match_test \"TARGET_SPFP_COMPACT_SET\")\n+       (eq_attr \"type\" \"spfp\"))\n+  \"issue+core, nothing*2, write_port\")\n+\n+(define_insn_reservation \"spfp_fast\" 6\n+  (and (match_test \"TARGET_SPFP_FAST_SET\")\n+       (eq_attr \"type\" \"spfp\"))\n+  \"issue+core, nothing*5, write_port\")\n+\n+(define_insn_reservation \"dpfp_compact_mult\" 7\n+  (and (match_test \"TARGET_DPFP_COMPACT_SET\")\n+       (eq_attr \"type\" \"dpfp_mult\"))\n+  \"issue+core, nothing*6, write_port\")\n+\n+(define_insn_reservation \"dpfp_compact_addsub\" 5\n+  (and (match_test \"TARGET_DPFP_COMPACT_SET\")\n+       (eq_attr \"type\" \"dpfp_addsub\"))\n+  \"issue+core, nothing*4, write_port\")\n+\n+(define_insn_reservation \"dpfp_fast\" 5\n+  (and (match_test \"TARGET_DPFP_FAST_SET\")\n+       (eq_attr \"type\" \"dpfp_mult,dpfp_addsub\"))\n+  \"issue+core, nothing*4, write_port\")\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+(define_insn \"addsf3\"\n+  [(set (match_operand:SF 0 \"register_operand\"          \"=r,r,r,r,r \")\n+\t(plus:SF (match_operand:SF 1 \"nonmemory_operand\" \"0,r,GCal,r,0\")\n+\t\t (match_operand:SF 2 \"nonmemory_operand\" \"I,rL,r,GCal,LrCal\")))]\n+;  \"(TARGET_ARC700 || TARGET_ARC600) && TARGET_SPFP_SET\";Add flag for float\n+  \"TARGET_SPFP\"\n+  \"@\n+   fadd %0,%1,%2\n+   fadd %0,%1,%2\n+   fadd   %0,%S1,%2\n+   fadd   %0,%1,%S2\n+   fadd%? %0,%1,%S2\"\n+  [(set_attr \"type\" \"spfp\")\n+  (set_attr \"length\" \"4,4,8,8,8\")])\n+\n+(define_insn \"subsf3\"\n+  [(set (match_operand:SF 0 \"register_operand\"          \"=r,r,r,r,r \")\n+\t(minus:SF (match_operand:SF 1 \"nonmemory_operand\" \"r,0,GCal,r,0\")\n+\t\t (match_operand:SF 2 \"nonmemory_operand\" \"rL,I,r,GCal,LrCal\")))]\n+  ;\"(TARGET_ARC700 || TARGET_ARC600) && TARGET_SPFP_SET\";Add flag for float\n+  \"TARGET_SPFP\"\n+  \"@\n+   fsub %0,%1,%2\n+   fsub %0,%1,%2\n+   fsub   %0,%S1,%2\n+   fsub   %0,%1,%S2\n+   fsub%? %0,%1,%S2\"\n+  [(set_attr \"type\" \"spfp\")\n+  (set_attr \"length\" \"4,4,8,8,8\")])\n+\n+(define_insn \"mulsf3\"\n+  [(set (match_operand:SF 0 \"register_operand\"          \"=r,r,r,r,r \")\n+\t(mult:SF (match_operand:SF 1 \"nonmemory_operand\" \"r,0,GCal,r,0\")\n+\t\t (match_operand:SF 2 \"nonmemory_operand\" \"rL,I,r,GCal,LrCal\")))]\n+;  \"(TARGET_ARC700 || TARGET_ARC600) && TARGET_SPFP_SET\"\t;Add flag for float\n+  \"TARGET_SPFP\"\n+  \"@\n+   fmul %0,%1,%2\n+   fmul %0,%1,%2\n+   fmul   %0,%S1,%2\n+   fmul   %0,%1,%S2\n+   fmul%? %0,%1,%S2\"\n+  [(set_attr \"type\" \"spfp\")\n+  (set_attr \"length\" \"4,4,8,8,8\")])\n+\n+\n+;; For comparisons, we can avoid storing the top half of the result into\n+;; a register since '.f' lets us set the Z bit for the conditional\n+;; branch insns.\n+\n+;; ??? FIXME (x-y)==0 is not a correct comparison for floats:\n+;;     http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm\n+(define_insn \"cmpsfpx_raw\"\n+  [(set (reg:CC_FPX 61)\n+\t(compare:CC_FPX (match_operand:SF 0 \"register_operand\" \"r\")\n+\t\t\t (match_operand:SF 1 \"register_operand\" \"r\")))]\n+  \"TARGET_ARGONAUT_SET && TARGET_SPFP\"\n+  \"fsub.f 0,%0,%1\"\n+  [(set_attr \"type\" \"spfp\")\n+   (set_attr \"length\" \"4\")])\n+\n+;; ??? FIXME (x-y)==0 is not a correct comparison for floats:\n+;;     http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm\n+;; ??? FIXME we claim to clobber operand 2, yet the two numbers appended\n+;; to the actual instructions are incorrect.  The result of the d*subh\n+;; insn is stored in the Dx register specified by that first number.\n+(define_insn \"cmpdfpx_raw\"\n+  [(set (reg:CC_FPX 61)\n+\t(compare:CC_FPX (match_operand:DF 0 \"nonmemory_operand\" \"D,r\")\n+\t\t\t (match_operand:DF 1 \"nonmemory_operand\" \"r,D\")))\n+   (clobber (match_scratch:DF 2 \"=D,D\"))]\n+  \"TARGET_ARGONAUT_SET && TARGET_DPFP\"\n+  \"@\n+   dsubh%F0%F1.f 0,%H2,%L2\n+   drsubh%F0%F2.f 0,%H1,%L1\"\n+  [(set_attr \"type\" \"dpfp_addsub\")\n+   (set_attr \"length\" \"4\")])\n+\n+;; ??? FIXME subtraction is not a correct comparison for floats:\n+;;     http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm\n+(define_insn \"*cmpfpx_gt\"\n+  [(set (reg:CC_FP_GT 61) (compare:CC_FP_GT (reg:CC_FPX 61) (const_int 0)))]\n+  \"TARGET_ARGONAUT_SET\"\n+  \"cmp.ls pcl,pcl\"\n+  [(set_attr \"type\" \"compare\")\n+   (set_attr \"length\" \"4\")])\n+\n+;; ??? FIXME subtraction is not a correct comparison for floats:\n+;;     http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm\n+(define_insn \"*cmpfpx_ge\"\n+  [(set (reg:CC_FP_GE 61) (compare:CC_FP_GE (reg:CC_FPX 61) (const_int 0)))]\n+  \"TARGET_ARGONAUT_SET\"\n+  \"rcmp.pnz pcl,0\"\n+  [(set_attr \"type\" \"compare\")\n+   (set_attr \"length\" \"4\")])\n+\n+;; DPFP instructions begin...\n+\n+;; op0_reg = D1_reg.low\n+(define_insn \"*lr_double_lower\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(unspec_volatile:SI [(match_operand:DF 1 \"arc_double_register_operand\" \"D\")] VUNSPEC_LR ))]\n+ \"TARGET_DPFP && !TARGET_DPFP_DISABLE_LRSR\"\n+\"lr %0, [%1l] ; *lr_double_lower\"\n+[(set_attr \"length\" \"8\")\n+(set_attr \"type\" \"lr\")]\n+)\n+\n+(define_insn \"*lr_double_higher\"\n+  [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t(unspec_volatile:SI [(match_operand:DF 1 \"arc_double_register_operand\" \"D\")] VUNSPEC_LR_HIGH ))]\n+ \"TARGET_DPFP && !TARGET_DPFP_DISABLE_LRSR\"\n+\"lr %0, [%1h] ; *lr_double_higher\"\n+[(set_attr \"length\" \"8\")\n+(set_attr \"type\" \"lr\")]\n+)\n+\n+\n+(define_insn \"*dexcl_3op_peep2_insn\"\n+  [(set (match_operand:SI 0 \"dest_reg_operand\" \"=r\") ; not register_operand, to accept SUBREG\n+\t\t   (unspec_volatile:SI [\n+\t\t   \t\t\t(match_operand:DF 1 \"arc_double_register_operand\" \"D\")\n+\t\t\t\t\t(match_operand:SI 2 \"shouldbe_register_operand\" \"r\")  ; r1\n+\t\t\t\t\t(match_operand:SI 3 \"shouldbe_register_operand\" \"r\") ; r0\n+\t\t\t\t\t] VUNSPEC_DEXCL ))\n+  ]\n+  \"TARGET_DPFP\"\n+  \"dexcl%F1 %0, %2, %3\"\n+  [(set_attr \"type\" \"move\")\n+   (set_attr \"length\" \"4\")]\n+)\n+\n+;; version which will not overwrite operand0\n+(define_insn \"*dexcl_3op_peep2_insn_nores\"\n+  [   (unspec_volatile:SI [\n+\t\t   \t\t\t(match_operand:DF 0 \"arc_double_register_operand\" \"D\")\n+\t\t\t\t\t(match_operand:SI 1 \"shouldbe_register_operand\" \"r\")  ; r1\n+\t\t\t\t\t(match_operand:SI 2 \"shouldbe_register_operand\" \"r\") ; r0\n+\t\t\t\t\t] VUNSPEC_DEXCL_NORES )\n+  ]\n+  \"TARGET_DPFP\"\n+  \"dexcl%F0 0, %1, %2\"\n+  [(set_attr \"type\" \"move\")\n+   (set_attr \"length\" \"4\")]\n+)\n+\n+;; dexcl a,b,c pattern generated by the peephole2 above\n+(define_insn \"*dexcl_3op_peep2_insn_lr\"\n+  [(parallel [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n+\t\t   (unspec_volatile:SI [(match_operand:DF 1 \"arc_double_register_operand\" \"=D\")] VUNSPEC_LR ))\n+\t     (set (match_dup 1) (match_operand:DF 2 \"register_operand\" \"r\"))]\n+\t    )\n+  ]\n+  \"TARGET_DPFP && !TARGET_DPFP_DISABLE_LRSR\"\n+  \"dexcl%F1 %0, %H2, %L2\"\n+  [(set_attr \"type\" \"move\")\n+   (set_attr \"length\" \"4\")]\n+)\n+\n+\n+;; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;;                             doubles support for ARC\n+;; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+;; D0 = D1+{reg_pair}2\n+;; (define_expand \"adddf3\"\n+;;   [(set (match_operand:DF 0 \"arc_double_register_operand\"          \"\")\n+;; \t(plus:DF (match_operand:DF 1 \"arc_double_register_operand\" \"\")\n+;; \t\t (match_operand:DF 2 \"nonmemory_operand\" \"\")))]\n+;;  \"TARGET_DPFP\"\n+;;  \" \"\n+;; )\n+;; daddh{0}{1} 0, {reg_pair}2.hi, {reg_pair}2.lo\n+;; OR\n+;; daddh{0}{1} 0, reg3, limm2.lo\n+(define_expand \"adddf3\"\n+  [(set (match_operand:DF 0 \"arc_double_register_operand\"          \"\")\n+\t(plus:DF (match_operand:DF 1 \"arc_double_register_operand\" \"\")\n+\t\t (match_operand:DF 2 \"nonmemory_operand\" \"\")))\n+     ]\n+ \"TARGET_DPFP\"\n+ \" if (GET_CODE (operands[2]) == CONST_DOUBLE)\n+     {\n+        rtx high, low, tmp;\n+        split_double (operands[2], &low, &high);\n+        tmp = force_reg (SImode, high);\n+        emit_insn(gen_adddf3_insn(operands[0], operands[1], operands[2],tmp,const0_rtx));\n+     }\n+   else\n+     emit_insn(gen_adddf3_insn(operands[0], operands[1], operands[2],const1_rtx,const1_rtx));\n+     DONE;\n+ \"\n+)\n+\n+;; daddh{0}{1} 0, {reg_pair}2.hi, {reg_pair}2.lo  /* operand 4 = 1*/\n+;; OR\n+;; daddh{0}{1} 0, reg3, limm2.lo /* operand 4 = 0 */\n+;;\n+(define_insn \"adddf3_insn\"\n+  [(set (match_operand:DF 0 \"arc_double_register_operand\"          \"=D,D\")\n+\t(plus:DF (match_operand:DF 1 \"arc_double_register_operand\" \"D,D\")\n+\t\t (match_operand:DF 2 \"nonmemory_operand\" \"!r,G\")))\n+  (use (match_operand:SI 3 \"\" \"N,r\"))\n+  (use (match_operand:SI 4 \"\" \"N,Q\"))\n+  ; Prevent can_combine_p from combining muldf3_insn patterns with\n+  ; different USE pairs.\n+  (use (match_dup 2))\n+  ]\n+  \"TARGET_DPFP &&\n+   !(GET_CODE(operands[2]) == CONST_DOUBLE && GET_CODE(operands[3]) == CONST_INT)\"\n+  \"@\n+     daddh%F0%F1 0,%H2,%L2\n+     daddh%F0%F1 0,%3,%L2\"\n+  [(set_attr \"type\" \"dpfp_addsub\")\n+  (set_attr \"length\" \"4,8\")])\n+\n+;; dmulh{0}{1} 0, {reg_pair}2.hi, {reg_pair}2.lo\n+;; OR\n+;; dmulh{0}{1} 0, reg3, limm2.lo\n+(define_expand \"muldf3\"\n+  [(set (match_operand:DF 0 \"arc_double_register_operand\"          \"\")\n+\t(mult:DF (match_operand:DF 1 \"arc_double_register_operand\" \"\")\n+\t\t (match_operand:DF 2 \"nonmemory_operand\" \"\")))]\n+\"TARGET_DPFP\"\n+\"  if (GET_CODE (operands[2]) == CONST_DOUBLE)\n+     {\n+        rtx high, low, tmp;\n+        split_double (operands[2], &low, &high);\n+        tmp = force_reg (SImode, high);\n+        emit_insn(gen_muldf3_insn(operands[0], operands[1], operands[2],tmp,const0_rtx));\n+     }\n+   else\n+     emit_insn(gen_muldf3_insn(operands[0], operands[1], operands[2],const1_rtx,const1_rtx));\n+\n+  DONE;\n+ \")\n+\n+\n+;; dmulh{0}{1} 0, {reg_pair}2.hi, {reg_pair}2.lo /* operand 4 = 1*/\n+;; OR\n+;; dmulh{0}{1} 0, reg3, limm2.lo /* operand 4 = 0*/\n+(define_insn \"muldf3_insn\"\n+  [(set (match_operand:DF 0 \"arc_double_register_operand\"          \"=D,D\")\n+\t(mult:DF (match_operand:DF 1 \"arc_double_register_operand\" \"D,D\")\n+\t\t (match_operand:DF 2 \"nonmemory_operand\" \"!r,G\")))\n+  (use (match_operand:SI 3 \"\" \"N,!r\"))\n+  (use (match_operand:SI 4 \"\" \"N,Q\"))\n+  ; Prevent can_combine_p from combining muldf3_insn patterns with\n+  ; different USE pairs.\n+  (use (match_dup 2))\n+  ]\n+  \"TARGET_DPFP &&\n+   !(GET_CODE(operands[2]) == CONST_DOUBLE && GET_CODE(operands[3]) == CONST_INT)\"\n+  \"@\n+    dmulh%F0%F1 0,%H2,%L2\n+    dmulh%F0%F1 0,%3, %L2\"\n+  [(set_attr \"type\" \"dpfp_mult\")\n+  (set_attr \"length\" \"4,8\")])\n+\n+;; dsubh{0}{1} 0, {reg_pair}2.hi, {reg_pair}2.lo\n+;; OR\n+;; dsubh{0}{1} 0, reg3, limm2.lo\n+;; OR\n+;; drsubh{0}{2} 0, {reg_pair}1.hi, {reg_pair}1.lo\n+;; OR\n+;; drsubh{0}{2} 0, reg3, limm1.lo\n+(define_expand \"subdf3\"\n+  [(set (match_operand:DF 0 \"arc_double_register_operand\"          \"\")\n+\t\t    (minus:DF (match_operand:DF 1 \"nonmemory_operand\" \"\")\n+\t\t\t\t  (match_operand:DF 2 \"nonmemory_operand\" \"\")))]\n+\"TARGET_DPFP\"\n+\"   if (GET_CODE (operands[1]) == CONST_DOUBLE || GET_CODE (operands[2]) == CONST_DOUBLE)\n+     {\n+        rtx high, low, tmp;\n+        int const_index = ((GET_CODE (operands[1]) == CONST_DOUBLE) ? 1: 2);\n+        split_double (operands[const_index], &low, &high);\n+        tmp = force_reg (SImode, high);\n+        emit_insn(gen_subdf3_insn(operands[0], operands[1], operands[2],tmp,const0_rtx));\n+     }\n+   else\n+     emit_insn(gen_subdf3_insn(operands[0], operands[1], operands[2],const1_rtx,const1_rtx));\n+\n+   DONE;\n+  \"\n+)\n+\n+;; dsubh{0}{1} 0, {reg_pair}2.hi, {reg_pair}2.lo /* operand 4 = 1 */\n+;; OR\n+;; dsubh{0}{1} 0, reg3, limm2.lo /* operand 4 = 0*/\n+;; OR\n+;; drsubh{0}{2} 0, {reg_pair}1.hi, {reg_pair}1.lo /* operand 4 = 1 */\n+;; OR\n+;; drsubh{0}{2} 0, reg3, limm1.lo /* operand 4 = 0*/\n+(define_insn \"subdf3_insn\"\n+  [(set (match_operand:DF 0 \"arc_double_register_operand\"          \"=D,D,D,D\")\n+\t\t   (minus:DF (match_operand:DF 1 \"nonmemory_operand\" \"D,D,!r,G\")\n+\t\t\t    (match_operand:DF 2 \"nonmemory_operand\" \"!r,G,D,D\")))\n+  (use (match_operand:SI 3 \"\" \"N,r,N,r\"))\n+  (use (match_operand:SI 4 \"\" \"N,Q,N,Q\"))\n+  ; Prevent can_combine_p from combining muldf3_insn patterns with\n+  ; different USE pairs.\n+  (use (match_dup 2))]\n+  \"TARGET_DPFP &&\n+   !(GET_CODE(operands[2]) == CONST_DOUBLE && GET_CODE(operands[3]) == CONST_INT) &&\n+   !(GET_CODE(operands[1]) == CONST_DOUBLE && GET_CODE(operands[3]) == CONST_INT)\"\n+  \"@\n+     dsubh%F0%F1 0,%H2,%L2\n+     dsubh%F0%F1 0,%3,%L2\n+     drsubh%F0%F2 0,%H1,%L1\n+     drsubh%F0%F2 0,%3,%L1\"\n+  [(set_attr \"type\" \"dpfp_addsub\")\n+  (set_attr \"length\" \"4,8,4,8\")])\n+\n+;; ;; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; ;; Peephole for following conversion\n+;; ;;                    D0 = D2<op>{reg_pair}3\n+;; ;;                    {reg_pair}5 = D0\n+;; ;;                    D0 = {reg_pair}6\n+;; ;;                            |\n+;; ;;                            V\n+;; ;;            _________________________________________________________\n+;; ;;           / D0             = D2 <op> {regpair3_or_limmreg34}\n+;; ;;    ---- +   {reg_pair}5.hi = ( D2<op>{regpair3_or_limmreg34} ).hi\n+;; ;;   |       \\_________________________________________________________\n+;; ;;   |\n+;; ;;   |         ________________________________________________________\n+;; ;;   |      / {reg_pair}5.lo  = ( D2<op>{regpair3_or_limmreg34} ).lo\n+;; ;;   +-----+  D0              = {reg_pair}6\n+;; ;;          \\ _________________________________________________________\n+;; ;;                            ||\n+;; ;;                            ||\n+;; ;;                            \\/\n+;; ;;  d<op>{0}{2}h {reg_pair}5.hi, {regpair3_or_limmreg34}.lo, {regpair3_or_limmreg34}.hi\n+;; ;;  dexcl{0}    {reg_pair}5.lo, {reg_pair}6.lo, {reg_pair}6.hi\n+;; ;; -----------------------------------------------------------------------------------------\n+;; ;;  where <op> is one of {+,*,-}\n+;; ;;        <opname> is {add,mult,sub}\n+;; ;;\n+;; ;; NOTE: For rsub insns D2 and {regpair3_or_limmreg34} get interchanged as\n+;; ;;       {regpair2_or_limmreg24} and D3\n+;; ;; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; (define_peephole2\n+;;   [(parallel [(set (match_operand:DF 0 \"register_operand\"          \"\")\n+;; \t(match_operator:DF 1 \"arc_dpfp_operator\" [(match_operand:DF 2 \"nonmemory_operand\" \"\")\n+;; \t\t\t   (match_operand:DF 3 \"nonmemory_operand\" \"\")]))\n+;; \t     (use (match_operand:SI 4 \"\" \"\"))])\n+;;   (set (match_operand:DF 5 \"register_operand\" \"\")\n+;;        (match_dup 0))\n+;;   (set (match_dup 0)\n+;;        (match_operand:DF 6 \"register_operand\" \"\"))\n+;;   ]\n+;;   \"TARGET_DPFP\"\n+;;   [\n+;;   (parallel [(set (match_dup 0)\n+;; \t\t  (match_op_dup:DF 1 [(match_dup 2)\n+;; \t\t\t\t   (match_dup 3)]))\n+;; \t    (use (match_dup 4))\n+;;             (set (match_dup 5)\n+;; \t\t (match_op_dup:DF  1 [(match_dup 2)\n+;; \t\t\t\t   (match_dup 3)]))])\n+;;   (parallel [\n+;; ;;\t    (set (subreg:SI (match_dup 5) 0)\n+;; \t    (set (match_dup 7)\n+;; \t\t (unspec_volatile [(match_dup 0)] VUNSPEC_LR ))\n+;; \t    (set (match_dup 0) (match_dup 6))]\n+;; \t    )\n+;;   ]\n+;;   \"operands[7] = simplify_gen_subreg(SImode,operands[5],DFmode,0);\"\n+;;   )\n+;; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; Peephole for following conversion\n+;;                    D0 = D2<op>{reg_pair}3\n+;;                    {reg_pair}6 = D0\n+;;                    D0 = {reg_pair}7\n+;;                            |\n+;;                            V\n+;;            _________________________________________________________\n+;;           / D0             = D2 <op> {regpair3_or_limmreg34}\n+;;    ---- +   {reg_pair}6.hi = ( D2<op>{regpair3_or_limmreg34} ).hi\n+;;   |       \\_________________________________________________________\n+;;   |\n+;;   |         ________________________________________________________\n+;;   |      / {reg_pair}6.lo  = ( D2<op>{regpair3_or_limmreg34} ).lo\n+;;   +-----+  D0              = {reg_pair}7\n+;;          \\ _________________________________________________________\n+;;                            ||\n+;;                            ||\n+;;                            \\/\n+;;  d<op>{0}{2}h {reg_pair}6.hi, {regpair3_or_limmreg34}.lo, {regpair3_or_limmreg34}.hi\n+;;  dexcl{0}    {reg_pair}6.lo, {reg_pair}7.lo, {reg_pair}7.hi\n+;; -----------------------------------------------------------------------------------------\n+;;  where <op> is one of {+,*,-}\n+;;        <opname> is {add,mult,sub}\n+;;\n+;; NOTE: For rsub insns D2 and {regpair3_or_limmreg34} get interchanged as\n+;;       {regpair2_or_limmreg24} and D3\n+;; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+(define_peephole2\n+  [(parallel [(set (match_operand:DF 0 \"register_operand\"          \"\")\n+\t(match_operator:DF 1 \"arc_dpfp_operator\" [(match_operand:DF 2 \"nonmemory_operand\" \"\")\n+\t\t\t   (match_operand:DF 3 \"nonmemory_operand\" \"\")]))\n+\t     (use (match_operand:SI 4 \"\" \"\"))\n+\t     (use (match_operand:SI 5 \"\" \"\"))\n+\t     (use (match_operand:SI 6 \"\" \"\"))])\n+  (set (match_operand:DF 7 \"register_operand\" \"\")\n+       (match_dup 0))\n+  (set (match_dup 0)\n+       (match_operand:DF 8 \"register_operand\" \"\"))\n+  ]\n+  \"TARGET_DPFP && !TARGET_DPFP_DISABLE_LRSR\"\n+  [\n+  (parallel [(set (match_dup 0)\n+\t\t  (match_op_dup:DF 1 [(match_dup 2)\n+\t\t\t\t   (match_dup 3)]))\n+\t    (use (match_dup 4))\n+\t    (use (match_dup 5))\n+            (set (match_dup 7)\n+\t\t (match_op_dup:DF  1 [(match_dup 2)\n+\t\t\t\t   (match_dup 3)]))])\n+  (parallel [\n+;;\t    (set (subreg:SI (match_dup 7) 0)\n+\t    (set (match_dup 9)\n+\t\t (unspec_volatile:SI [(match_dup 0)] VUNSPEC_LR ))\n+\t    (set (match_dup 0) (match_dup 8))]\n+\t    )\n+  ]\n+  \"operands[9] = simplify_gen_subreg(SImode,operands[7],DFmode,0);\"\n+  )\n+\n+;; ;; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; ;; Peephole to generate d<opname>{ij}h a,b,c instructions\n+;; ;;                    D0 = D2<op>{reg_pair}3\n+;; ;;                    {reg_pair}5 = D0\n+;; ;;                            |\n+;; ;;                            V\n+;; ;;            __________________________________________\n+;; ;;           / D0             = D2 <op> {regpair3_or_limmreg34}\n+;; ;;    ---- +   {reg_pair}5.hi = ( D2<op>{regpair3_or_limmreg34} ).hi\n+;; ;;   |       \\__________________________________________\n+;; ;;   |\n+;; ;;   + ---    {reg_pair}5.lo     = ( D2<op>{regpair3_or_limmreg34} ).lo\n+;; ;;                            ||\n+;; ;;                            ||\n+;; ;;                            \\/\n+;; ;;  d<op>{0}{2}h {reg_pair}4.hi, {regpair3_or_limmreg34}.lo, {regpair3_or_limmreg34}.hi\n+;; ;;  lr    {reg_pair}4.lo, {D2l}\n+;; ;; ----------------------------------------------------------------------------------------\n+;; ;;  where <op> is one of {+,*,-}\n+;; ;;        <opname> is {add,mult,sub}\n+;; ;;\n+;; ;; NOTE: For rsub insns D2 and {regpair3_or_limmreg34} get interchanged as\n+;; ;;       {regpair2_or_limmreg24} and D3\n+;; ;; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; (define_peephole2\n+;;   [(parallel [(set (match_operand:DF 0 \"register_operand\"          \"\")\n+;; \t\t   (match_operator:DF 1 \"arc_dpfp_operator\" [(match_operand:DF 2 \"nonmemory_operand\" \"\")\n+;; \t\t\t\t      (match_operand:DF 3 \"nonmemory_operand\" \"\")]))\n+;; \t     (use (match_operand:SI 4 \"\" \"\"))])\n+;;   (set (match_operand:DF 5 \"register_operand\" \"\")\n+;;        (match_dup 0))\n+;;   ]\n+;;   \"TARGET_DPFP\"\n+;;   [\n+;;   (parallel [(set (match_dup 0)\n+;; \t\t  (match_op_dup:DF 1 [(match_dup 2)\n+;; \t\t\t\t   (match_dup 3)]))\n+;; \t    (use (match_dup 4))\n+;;             (set (match_dup 5)\n+;; \t\t (match_op_dup:DF  1 [(match_dup 2)\n+;; \t\t\t\t   (match_dup 3)]))])\n+;; ;  (set (subreg:SI (match_dup 5) 0)\n+;;   (set (match_dup 6)\n+;;        (unspec_volatile [(match_dup 0)] VUNSPEC_LR ))\n+;;   ]\n+;;   \"operands[6] = simplify_gen_subreg(SImode,operands[5],DFmode,0);\"\n+;;   )\n+;; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; Peephole to generate d<opname>{ij}h a,b,c instructions\n+;;                    D0 = D2<op>{reg_pair}3\n+;;                    {reg_pair}6 = D0\n+;;                            |\n+;;                            V\n+;;            __________________________________________\n+;;           / D0             = D2 <op> {regpair3_or_limmreg34}\n+;;    ---- +   {reg_pair}6.hi = ( D2<op>{regpair3_or_limmreg34} ).hi\n+;;   |       \\__________________________________________\n+;;   |\n+;;   + ---    {reg_pair}6.lo     = ( D2<op>{regpair3_or_limmreg34} ).lo\n+;;                            ||\n+;;                            ||\n+;;                            \\/\n+;;  d<op>{0}{2}h {reg_pair}4.hi, {regpair3_or_limmreg34}.lo, {regpair3_or_limmreg34}.hi\n+;;  lr    {reg_pair}4.lo, {D2l}\n+;; ----------------------------------------------------------------------------------------\n+;;  where <op> is one of {+,*,-}\n+;;        <opname> is {add,mult,sub}\n+;;\n+;; NOTE: For rsub insns D2 and {regpair3_or_limmreg34} get interchanged as\n+;;       {regpair2_or_limmreg24} and D3\n+;; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+(define_peephole2\n+  [(parallel [(set (match_operand:DF 0 \"register_operand\"          \"\")\n+\t\t   (match_operator:DF 1 \"arc_dpfp_operator\" [(match_operand:DF 2 \"nonmemory_operand\" \"\")\n+\t\t\t\t      (match_operand:DF 3 \"nonmemory_operand\" \"\")]))\n+\t     (use (match_operand:SI 4 \"\" \"\"))\n+\t     (use (match_operand:SI 5 \"\" \"\"))\n+\t     (use (match_operand:SI 6 \"\" \"\"))])\n+  (set (match_operand:DF 7 \"register_operand\" \"\")\n+       (match_dup 0))\n+  ]\n+  \"TARGET_DPFP  && !TARGET_DPFP_DISABLE_LRSR\"\n+  [\n+  (parallel [(set (match_dup 0)\n+\t\t  (match_op_dup:DF 1 [(match_dup 2)\n+\t\t\t\t   (match_dup 3)]))\n+\t    (use (match_dup 4))\n+\t    (use (match_dup 5))\n+            (set (match_dup 7)\n+\t\t (match_op_dup:DF  1 [(match_dup 2)\n+\t\t\t\t   (match_dup 3)]))])\n+;  (set (subreg:SI (match_dup 7) 0)\n+  (set (match_dup 8)\n+       (unspec_volatile:SI [(match_dup 0)] VUNSPEC_LR ))\n+  ]\n+  \"operands[8] = simplify_gen_subreg(SImode,operands[7],DFmode,0);\"\n+  )\n+\n+;; ;;            _______________________________________________________\n+;; ;;           / D0             = D1 + {regpair2_or_limmreg23}\n+;; ;;         +   {reg_pair}4.hi = ( D1 + {regpair2_or_limmreg23} ).hi\n+;; ;;           \\_______________________________________________________\n+;; (define_insn \"*daddh_peep2_insn\"\n+;;   [(parallel [(set (match_operand:DF 0 \"arc_double_register_operand\" \"=D,D\")\n+;; \t\t   (plus:DF (match_operand:DF 1 \"arc_double_register_operand\" \"D,D\")\n+;; \t\t\t    (match_operand:DF 2 \"nonmemory_operand\" \"r,G\")))\n+;; \t     (use (match_operand:SI 3 \"\" \"N,r\"))\n+;; \t     (set (match_operand:DF 4 \"register_operand\" \"=r,r\")\n+;; \t\t  (plus:DF (match_dup 1)\n+;; \t\t\t   (match_dup 2)))])]\n+;;  \"TARGET_DPFP\"\n+;;  \"@\n+;;     daddh%F0%F1 %H4, %H2, %L2\n+;;     daddh%F0%F1 %H4, %3, %L2\"\n+;;  [(set_attr \"type\" \"dpfp_addsub\")\n+;;  (set_attr \"length\" \"4,8\")]\n+;; )\n+;;            _______________________________________________________\n+;;           / D0             = D1 + {regpair2_or_limmreg23}\n+;;         +   {reg_pair}5.hi = ( D1 + {regpair2_or_limmreg23} ).hi\n+;;           \\_______________________________________________________\n+(define_insn \"*daddh_peep2_insn\"\n+  [(parallel [(set (match_operand:DF 0 \"arc_double_register_operand\" \"=D,D\")\n+\t\t   (plus:DF (match_operand:DF 1 \"arc_double_register_operand\" \"D,D\")\n+\t\t\t    (match_operand:DF 2 \"nonmemory_operand\" \"r,G\")))\n+\t     (use (match_operand:SI 3 \"\" \"N,r\"))\n+\t     (use (match_operand:SI 4 \"\" \"N,Q\"))\n+\t     (use (match_operand:SI 5 \"\" \"\"))\n+\t     (set (match_operand:DF 6 \"register_operand\" \"=r,r\")\n+\t\t  (plus:DF (match_dup 1)\n+\t\t\t   (match_dup 2)))])]\n+ \"TARGET_DPFP &&\n+   !(GET_CODE(operands[2]) == CONST_DOUBLE && GET_CODE(operands[3]) == CONST_INT)\"\n+ \"@\n+    daddh%F0%F1 %H6, %H2, %L2\n+    daddh%F0%F1 %H6, %3, %L2\"\n+ [(set_attr \"type\" \"dpfp_addsub\")\n+ (set_attr \"length\" \"4,8\")]\n+)\n+\n+;;            _______________________________________________________\n+;;           / D0             = D1 * {regpair2_or_limmreg23}\n+;;         +   {reg_pair}5.hi = ( D1 * {regpair2_or_limmreg23} ).hi\n+;;           \\_______________________________________________________\n+(define_insn \"*dmulh_peep2_insn\"\n+  [(parallel [(set (match_operand:DF 0 \"arc_double_register_operand\" \"=D,D\")\n+\t\t   (mult:DF (match_operand:DF 1 \"arc_double_register_operand\" \"D,D\")\n+\t\t\t    (match_operand:DF 2 \"nonmemory_operand\" \"r,G\")))\n+\t     (use (match_operand:SI 3 \"\" \"N,r\"))\n+\t     (use (match_operand:SI 4 \"\" \"N,Q\"))\n+\t     (use (match_operand:SI 5 \"\" \"\"))\n+\t     (set (match_operand:DF 6 \"register_operand\" \"=r,r\")\n+\t\t  (mult:DF (match_dup 1)\n+\t\t\t\t      (match_dup 2)))])]\n+ \"TARGET_DPFP &&\n+   !(GET_CODE(operands[2]) == CONST_DOUBLE && GET_CODE(operands[3]) == CONST_INT)\"\n+ \"@\n+    dmulh%F0%F1 %H6, %H2, %L2\n+    dmulh%F0%F1 %H6, %3, %L2\"\n+ [(set_attr \"type\" \"dpfp_mult\")\n+ (set_attr \"length\" \"4,8\")]\n+)\n+\n+;;            _______________________________________________________\n+;;           / D0             = D1 - {regpair2_or_limmreg23}\n+;;         +   {reg_pair}5.hi = ( D1 - {regpair2_or_limmreg23} ).hi\n+;;           \\_______________________________________________________\n+;;  OR\n+;;            _______________________________________________________\n+;;           / D0             = {regpair1_or_limmreg13} - D2\n+;;         +   {reg_pair}5.hi = ( {regpair1_or_limmreg13} ).hi - D2\n+;;           \\_______________________________________________________\n+(define_insn \"*dsubh_peep2_insn\"\n+  [(parallel [(set (match_operand:DF 0 \"arc_double_register_operand\" \"=D,D,D,D\")\n+\t\t   (minus:DF (match_operand:DF 1 \"nonmemory_operand\" \"D,D,r,G\")\n+\t\t\t     (match_operand:DF 2 \"nonmemory_operand\" \"r,G,D,D\")))\n+\t     (use (match_operand:SI 3 \"\" \"N,r,N,r\"))\n+\t     (use (match_operand:SI 4 \"\" \"N,Q,N,Q\"))\n+\t     (use (match_operand:SI 5 \"\" \"\"))\n+\t     (set (match_operand:DF 6 \"register_operand\" \"=r,r,r,r\")\n+\t\t  (minus:DF (match_dup 1)\n+\t\t\t\t      (match_dup 2)))])]\n+ \"TARGET_DPFP &&\n+   !(GET_CODE(operands[2]) == CONST_DOUBLE && GET_CODE(operands[3]) == CONST_INT)  &&\n+   !(GET_CODE(operands[1]) == CONST_DOUBLE && GET_CODE(operands[3]) == CONST_INT)\"\n+ \"@\n+  dsubh%F0%F1 %H6, %H2, %L2\n+  dsubh%F0%F1 %H6, %3, %L2\n+  drsubh%F0%F2 %H6, %H1, %L1\n+  drsubh%F0%F2 %H6, %3, %L1\"\n+ [(set_attr \"type\" \"dpfp_addsub\")\n+  (set_attr \"length\" \"4,8,4,8\")]\n+)"}, {"sha": "241fb23ee3669b0968dad65abf09d05fd7c7fa31", "filename": "gcc/config/arc/predicates.md", "status": "added", "additions": 807, "deletions": 0, "changes": 807, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Fpredicates.md?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -0,0 +1,807 @@\n+;; Predicate definitions for Synopsys DesignWare ARC.\n+;; Copyright (C) 2007-2013 Free Software Foundation, Inc.\n+;;\n+;; This file is part of GCC.\n+;;\n+;; GCC is free software; you can redistribute it and/or modify\n+;; it under the terms of the GNU General Public License as published by\n+;; the Free Software Foundation; either version 3, or (at your option)\n+;; any later version.\n+;;\n+;; GCC is distributed in the hope that it will be useful,\n+;; but WITHOUT ANY WARRANTY; without even the implied warranty of\n+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+;; GNU General Public License for more details.\n+;;\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+(define_predicate \"dest_reg_operand\"\n+  (match_code \"reg,subreg\")\n+{\n+  rtx op0 = op;\n+\n+  if (GET_CODE (op0) == SUBREG)\n+    op0 = SUBREG_REG (op0);\n+  if (REG_P (op0) && REGNO (op0) < FIRST_PSEUDO_REGISTER\n+      && TEST_HARD_REG_BIT (reg_class_contents[ALL_CORE_REGS],\n+\t\t\t    REGNO (op0))\n+      && !TEST_HARD_REG_BIT (reg_class_contents[WRITABLE_CORE_REGS],\n+\t\t\t    REGNO (op0)))\n+    return 0;\n+  return register_operand (op, mode);\n+})\n+\n+(define_predicate \"mpy_dest_reg_operand\"\n+  (match_code \"reg,subreg\")\n+{\n+  rtx op0 = op;\n+\n+  if (GET_CODE (op0) == SUBREG)\n+    op0 = SUBREG_REG (op0);\n+  if (REG_P (op0) && REGNO (op0) < FIRST_PSEUDO_REGISTER\n+      && TEST_HARD_REG_BIT (reg_class_contents[ALL_CORE_REGS],\n+\t\t\t    REGNO (op0))\n+      /* Make sure the destination register is not LP_COUNT.  */\n+      && !TEST_HARD_REG_BIT (reg_class_contents[MPY_WRITABLE_CORE_REGS],\n+\t\t\t    REGNO (op0)))\n+    return 0;\n+  return register_operand (op, mode);\n+})\n+\n+\n+;; Returns 1 if OP is a symbol reference.\n+(define_predicate \"symbolic_operand\"\n+  (match_code \"symbol_ref, label_ref, const\")\n+)\n+\n+;; Acceptable arguments to the call insn.\n+(define_predicate \"call_address_operand\"\n+  (ior (match_code \"const_int, reg\")\n+       (match_operand 0 \"symbolic_operand\")\n+       (match_test \"CONSTANT_P (op)\n+\t\t    && arc_legitimate_constant_p (VOIDmode, op)\"))\n+)\n+\n+(define_predicate \"call_operand\"\n+  (and (match_code \"mem\")\n+       (match_test \"call_address_operand (XEXP (op, 0), mode)\"))\n+)\n+\n+;; Return true if OP is a unsigned 6-bit immediate (u6) value.\n+(define_predicate \"u6_immediate_operand\"\n+  (and (match_code \"const_int\")\n+       (match_test \"UNSIGNED_INT6 (INTVAL (op))\"))\n+)\n+\n+;; Return true if OP is a short immediate (shimm) value.\n+(define_predicate \"short_immediate_operand\"\n+  (and (match_code \"const_int\")\n+       (match_test \"SMALL_INT (INTVAL (op))\"))\n+)\n+\n+(define_predicate \"p2_immediate_operand\"\n+  (and (match_code \"const_int\")\n+       (match_test \"((INTVAL (op) - 1) & INTVAL (op)) == 0\")\n+       (match_test \"INTVAL (op)\"))\n+)\n+\n+;; Return true if OP will require a long immediate (limm) value.\n+;; This is currently only used when calculating length attributes.\n+(define_predicate \"long_immediate_operand\"\n+  (match_code \"symbol_ref, label_ref, const, const_double, const_int\")\n+{\n+  switch (GET_CODE (op))\n+    {\n+    case SYMBOL_REF :\n+    case LABEL_REF :\n+    case CONST :\n+      return 1;\n+    case CONST_INT :\n+      return !SIGNED_INT12 (INTVAL (op));\n+    case CONST_DOUBLE :\n+      /* These can happen because large unsigned 32 bit constants are\n+\t represented this way (the multiplication patterns can cause these\n+\t to be generated).  They also occur for SFmode values.  */\n+      return 1;\n+    default:\n+      break;\n+    }\n+  return 0;\n+}\n+)\n+\n+;; Return true if OP is a MEM that when used as a load or store address will\n+;; require an 8 byte insn.\n+;; Load and store instructions don't allow the same possibilities but they're\n+;; similar enough that this one function will do.\n+;; This is currently only used when calculating length attributes.  */\n+(define_predicate \"long_immediate_loadstore_operand\"\n+  (match_code \"mem\")\n+{\n+  int size = GET_MODE_SIZE (GET_MODE (op));\n+\n+  op = XEXP (op, 0);\n+  switch (GET_CODE (op))\n+    {\n+    case SYMBOL_REF :\n+    case LABEL_REF :\n+    case CONST :\n+      return 1;\n+    case CONST_INT :\n+      /* This must be handled as \"st c,[limm]\".  Ditto for load.\n+\t Technically, the assembler could translate some possibilities to\n+\t \"st c,[limm/2 + limm/2]\" if limm/2 will fit in a shimm, but we don't\n+\t assume that it does.  */\n+      return 1;\n+    case CONST_DOUBLE :\n+      /* These can happen because large unsigned 32 bit constants are\n+\t represented this way (the multiplication patterns can cause these\n+\t to be generated).  They also occur for SFmode values.  */\n+      return 1;\n+    case REG :\n+      return 0;\n+    case PLUS :\n+      {\n+\trtx x = XEXP (op, 1);\n+\n+\tif (GET_CODE (x) == CONST)\n+\t  {\n+\t    x = XEXP (x, 0);\n+\t    if (GET_CODE (x) == PLUS)\n+\t      x = XEXP (x, 0);\n+\t  }\n+\tif (CONST_INT_P (x))\n+\t  return (!SMALL_INT (INTVAL (x))\n+\t\t  && (size <= 1 || size > 4\n+\t\t      || (INTVAL (x) & (size - 1)) != 0\n+\t\t      || !SMALL_INT (INTVAL (x) / size)));\n+\telse if (GET_CODE (x) == SYMBOL_REF)\n+\t  return TARGET_NO_SDATA_SET || !SYMBOL_REF_SMALL_P (x);\n+\treturn 0;\n+      }\n+    default:\n+      break;\n+    }\n+  return 0;\n+}\n+)\n+\n+;; Return true if OP is any of R0-R3,R12-R15 for ARCompact 16-bit\n+;; instructions\n+(define_predicate \"compact_register_operand\"\n+  (match_code \"reg, subreg\")\n+  {\n+     if ((GET_MODE (op) != mode) && (mode != VOIDmode))\n+\t return 0;\n+\n+      return (GET_CODE (op) == REG)\n+      && (REGNO (op) >= FIRST_PSEUDO_REGISTER\n+\t\t|| COMPACT_GP_REG_P (REGNO (op))) ;\n+  }\n+)\n+\n+;; Return true if OP is an acceptable memory operand for ARCompact\n+;; 16-bit load instructions.\n+(define_predicate \"compact_load_memory_operand\"\n+  (match_code \"mem\")\n+{\n+  rtx addr, plus0, plus1;\n+  int size, off;\n+\n+  /* Eliminate non-memory operations.  */\n+  if (GET_CODE (op) != MEM)\n+    return 0;\n+\n+  /* .di instructions have no 16-bit form.  */\n+  if (MEM_VOLATILE_P (op) && !TARGET_VOLATILE_CACHE_SET)\n+     return 0;\n+\n+  if (mode == VOIDmode)\n+    mode = GET_MODE (op);\n+\n+  size = GET_MODE_SIZE (mode);\n+\n+  /* dword operations really put out 2 instructions, so eliminate them.  */\n+  if (size > UNITS_PER_WORD)\n+    return 0;\n+\n+  /* Decode the address now.  */\n+  addr = XEXP (op, 0);\n+  switch (GET_CODE (addr))\n+    {\n+    case REG:\n+      return (REGNO (addr) >= FIRST_PSEUDO_REGISTER\n+\t      || COMPACT_GP_REG_P (REGNO (addr))\n+\t      || (SP_REG_P (REGNO (addr)) && (size != 2)));\n+\t/* Reverting for the moment since ldw_s does not have sp as a valid\n+\t   parameter.  */\n+    case PLUS:\n+      plus0 = XEXP (addr, 0);\n+      plus1 = XEXP (addr, 1);\n+\n+      if ((GET_CODE (plus0) == REG)\n+\t  && ((REGNO (plus0) >= FIRST_PSEUDO_REGISTER)\n+\t      || COMPACT_GP_REG_P (REGNO (plus0)))\n+\t  && ((GET_CODE (plus1) == REG)\n+\t      && ((REGNO (plus1) >= FIRST_PSEUDO_REGISTER)\n+\t\t  || COMPACT_GP_REG_P (REGNO (plus1)))))\n+\t{\n+\t  return 1;\n+\t}\n+\n+      if ((GET_CODE (plus0) == REG)\n+\t  && ((REGNO (plus0) >= FIRST_PSEUDO_REGISTER)\n+\t      || COMPACT_GP_REG_P (REGNO (plus0)))\n+\t  && (GET_CODE (plus1) == CONST_INT))\n+\t{\n+\t  off = INTVAL (plus1);\n+\n+\t  /* Negative offset is not supported in 16-bit load/store insns.  */\n+\t  if (off < 0)\n+\t    return 0;\n+\n+\t  switch (size)\n+\t    {\n+\t    case 1:\n+\t      return (off < 32);\n+\t    case 2:\n+\t      return ((off < 64) && (off % 2 == 0));\n+\t    case 4:\n+\t      return ((off < 128) && (off % 4 == 0));\n+\t    }\n+\t}\n+\n+      if ((GET_CODE (plus0) == REG)\n+\t  && ((REGNO (plus0) >= FIRST_PSEUDO_REGISTER)\n+\t      || SP_REG_P (REGNO (plus0)))\n+\t  && (GET_CODE (plus1) == CONST_INT))\n+\t{\n+\t  off = INTVAL (plus1);\n+\t  return ((size != 2) && (off >= 0 && off < 128) && (off % 4 == 0));\n+\t}\n+    default:\n+      break ;\n+      /* TODO: 'gp' and 'pcl' are to supported as base address operand\n+\t       for 16-bit load instructions.  */\n+    }\n+  return 0;\n+\n+}\n+)\n+\n+;; Return true if OP is an acceptable memory operand for ARCompact\n+;; 16-bit store instructions\n+(define_predicate \"compact_store_memory_operand\"\n+  (match_code \"mem\")\n+{\n+  rtx addr, plus0, plus1;\n+  int size, off;\n+\n+  if (mode == VOIDmode)\n+    mode = GET_MODE (op);\n+\n+  /* .di instructions have no 16-bit form.  */\n+  if (MEM_VOLATILE_P (op) && !TARGET_VOLATILE_CACHE_SET)\n+     return 0;\n+\n+  size = GET_MODE_SIZE (mode);\n+\n+  /* dword operations really put out 2 instructions, so eliminate them.  */\n+  if (size > UNITS_PER_WORD)\n+    return 0;\n+\n+  /* Decode the address now.  */\n+  addr = XEXP (op, 0);\n+  switch (GET_CODE (addr))\n+    {\n+    case REG:\n+      return (REGNO (addr) >= FIRST_PSEUDO_REGISTER\n+\t\t|| COMPACT_GP_REG_P (REGNO (addr))\n+\t      || (SP_REG_P (REGNO (addr)) && (size != 2)));\n+\t/* stw_s does not support SP as a parameter.  */\n+    case PLUS:\n+      plus0 = XEXP (addr, 0);\n+      plus1 = XEXP (addr, 1);\n+\n+      if ((GET_CODE (plus0) == REG)\n+\t  && ((REGNO (plus0) >= FIRST_PSEUDO_REGISTER)\n+\t      || COMPACT_GP_REG_P (REGNO (plus0)))\n+\t  && (GET_CODE (plus1) == CONST_INT))\n+\t{\n+\t  off = INTVAL (plus1);\n+\n+\t  /* Negative offset is not supported in 16-bit load/store insns.  */\n+\t  if (off < 0)\n+\t    return 0;\n+\n+\t  switch (size)\n+\t    {\n+\t    case 1:\n+\t      return (off < 32);\n+\t    case 2:\n+\t      return ((off < 64) && (off % 2 == 0));\n+\t    case 4:\n+\t      return ((off < 128) && (off % 4 == 0));\n+\t    }\n+\t}\n+\n+      if ((GET_CODE (plus0) == REG)\n+\t  && ((REGNO (plus0) >= FIRST_PSEUDO_REGISTER)\n+\t      || SP_REG_P (REGNO (plus0)))\n+\t  && (GET_CODE (plus1) == CONST_INT))\n+\t{\n+\t  off = INTVAL (plus1);\n+\n+\t  return ((size != 2) && (off >= 0 && off < 128) && (off % 4 == 0));\n+\t}\n+    default:\n+      break;\n+    }\n+  return 0;\n+  }\n+)\n+\n+;; Return true if OP is an acceptable argument for a single word\n+;;   move source.\n+(define_predicate \"move_src_operand\"\n+  (match_code \"symbol_ref, label_ref, const, const_int, const_double, reg, subreg, mem\")\n+{\n+  switch (GET_CODE (op))\n+    {\n+    case SYMBOL_REF :\n+    case LABEL_REF :\n+    case CONST :\n+      return (!flag_pic || arc_legitimate_pic_operand_p(op));\n+    case CONST_INT :\n+      return (LARGE_INT (INTVAL (op)));\n+    case CONST_DOUBLE :\n+      /* We can handle DImode integer constants in SImode if the value\n+\t (signed or unsigned) will fit in 32 bits.  This is needed because\n+\t large unsigned 32 bit constants are represented as CONST_DOUBLEs.  */\n+      if (mode == SImode)\n+\treturn arc_double_limm_p (op);\n+      /* We can handle 32 bit floating point constants.  */\n+      if (mode == SFmode)\n+\treturn GET_MODE (op) == SFmode;\n+      return 0;\n+    case REG :\n+      return register_operand (op, mode);\n+    case SUBREG :\n+      /* (subreg (mem ...) ...) can occur here if the inner part was once a\n+\t pseudo-reg and is now a stack slot.  */\n+      if (GET_CODE (SUBREG_REG (op)) == MEM)\n+\treturn address_operand (XEXP (SUBREG_REG (op), 0), mode);\n+      else\n+\treturn register_operand (op, mode);\n+    case MEM :\n+      return address_operand (XEXP (op, 0), mode);\n+    default :\n+      return 0;\n+    }\n+}\n+)\n+\n+;; Return true if OP is an acceptable argument for a double word\n+;; move source.\n+(define_predicate \"move_double_src_operand\"\n+  (match_code \"reg, subreg, mem, const_int, const_double\")\n+{\n+  switch (GET_CODE (op))\n+    {\n+    case REG :\n+      return register_operand (op, mode);\n+    case SUBREG :\n+      /* (subreg (mem ...) ...) can occur here if the inner part was once a\n+\t pseudo-reg and is now a stack slot.  */\n+      if (GET_CODE (SUBREG_REG (op)) == MEM)\n+\treturn move_double_src_operand (SUBREG_REG (op), mode);\n+      else\n+\treturn register_operand (op, mode);\n+    case MEM :\n+      return address_operand (XEXP (op, 0), mode);\n+    case CONST_INT :\n+    case CONST_DOUBLE :\n+      return 1;\n+    default :\n+      return 0;\n+    }\n+}\n+)\n+\n+;; Return true if OP is an acceptable argument for a move destination.\n+(define_predicate \"move_dest_operand\"\n+  (match_code \"reg, subreg, mem\")\n+{\n+  switch (GET_CODE (op))\n+    {\n+    case REG :\n+     /* Program Counter register cannot be the target of a move.  It is\n+\t a readonly register.  */\n+      if (REGNO (op) == PROGRAM_COUNTER_REGNO)\n+\treturn 0;\n+      else if (TARGET_MULMAC_32BY16_SET\n+\t       && (REGNO (op) == 56 || REGNO(op) == 57))\n+\treturn 0;\n+      else if (TARGET_MUL64_SET\n+\t       && (REGNO (op) == 57 || REGNO(op) == 58 || REGNO(op) == 59 ))\n+\treturn 0;\n+      else\n+\treturn dest_reg_operand (op, mode);\n+    case SUBREG :\n+      /* (subreg (mem ...) ...) can occur here if the inner part was once a\n+\t pseudo-reg and is now a stack slot.  */\n+      if (GET_CODE (SUBREG_REG (op)) == MEM)\n+\treturn address_operand (XEXP (SUBREG_REG (op), 0), mode);\n+      else\n+\treturn dest_reg_operand (op, mode);\n+    case MEM :\n+      {\n+\trtx addr = XEXP (op, 0);\n+\n+\tif (GET_CODE (addr) == PLUS\n+\t    && (GET_CODE (XEXP (addr, 0)) == MULT\n+\t\t|| (!CONST_INT_P (XEXP (addr, 1))\n+\t\t    && (TARGET_NO_SDATA_SET\n+\t\t\t|| GET_CODE (XEXP (addr, 1)) != SYMBOL_REF\n+\t\t\t|| !SYMBOL_REF_SMALL_P (XEXP (addr, 1))))))\n+\t  return 0;\n+\tif ((GET_CODE (addr) == PRE_MODIFY || GET_CODE (addr) == POST_MODIFY)\n+\t    && (GET_CODE (XEXP (addr, 1)) != PLUS\n+\t\t|| !CONST_INT_P (XEXP (XEXP (addr, 1), 1))))\n+\t  return 0;\n+\treturn address_operand (addr, mode);\n+      }\n+    default :\n+      return 0;\n+    }\n+\n+}\n+)\n+\n+;; Return true if OP is valid load with update operand.\n+(define_predicate \"load_update_operand\"\n+  (match_code \"mem\")\n+{\n+  if (GET_CODE (op) != MEM\n+      || GET_MODE (op) != mode)\n+    return 0;\n+  op = XEXP (op, 0);\n+  if (GET_CODE (op) != PLUS\n+      || GET_MODE (op) != Pmode\n+      || !register_operand (XEXP (op, 0), Pmode)\n+      || !nonmemory_operand (XEXP (op, 1), Pmode))\n+    return 0;\n+  return 1;\n+\n+}\n+)\n+\n+;; Return true if OP is valid store with update operand.\n+(define_predicate \"store_update_operand\"\n+  (match_code \"mem\")\n+{\n+  if (GET_CODE (op) != MEM\n+      || GET_MODE (op) != mode)\n+    return 0;\n+  op = XEXP (op, 0);\n+  if (GET_CODE (op) != PLUS\n+      || GET_MODE (op) != Pmode\n+      || !register_operand (XEXP (op, 0), Pmode)\n+      || !(GET_CODE (XEXP (op, 1)) == CONST_INT\n+\t   && SMALL_INT (INTVAL (XEXP (op, 1)))))\n+    return 0;\n+  return 1;\n+}\n+)\n+\n+;; Return true if OP is a non-volatile non-immediate operand.\n+;; Volatile memory refs require a special \"cache-bypass\" instruction\n+;; and only the standard movXX patterns are set up to handle them.\n+(define_predicate \"nonvol_nonimm_operand\"\n+  (and (match_code \"subreg, reg, mem\")\n+       (match_test \"(GET_CODE (op) != MEM || !MEM_VOLATILE_P (op)) && nonimmediate_operand (op, mode)\"))\n+)\n+\n+;; Return 1 if OP is a comparison operator valid for the mode of CC.\n+;; This allows the use of MATCH_OPERATOR to recognize all the branch insns.\n+\n+(define_predicate \"proper_comparison_operator\"\n+  (match_code \"eq, ne, le, lt, ge, gt, leu, ltu, geu, gtu, unordered, ordered, uneq, unge, ungt, unle, unlt, ltgt\")\n+{\n+  enum rtx_code code = GET_CODE (op);\n+\n+  if (!COMPARISON_P (op))\n+    return 0;\n+\n+  /* After generic flag-setting insns, we can use eq / ne / pl / mi / pnz .\n+     There are some creative uses for hi / ls after shifts, but these are\n+     hard to understand for the compiler and could be at best the target of\n+     a peephole.  */\n+  switch (GET_MODE (XEXP (op, 0)))\n+    {\n+    case CC_ZNmode:\n+      return (code == EQ || code == NE || code == GE || code == LT\n+\t      || code == GT);\n+    case CC_Zmode:\n+      return code == EQ || code == NE;\n+    case CC_Cmode:\n+      return code == LTU || code == GEU;\n+    case CC_FP_GTmode:\n+      return code == GT || code == UNLE;\n+    case CC_FP_GEmode:\n+      return code == GE || code == UNLT;\n+    case CC_FP_ORDmode:\n+      return code == ORDERED || code == UNORDERED;\n+    case CC_FP_UNEQmode:\n+      return code == UNEQ || code == LTGT;\n+    case CC_FPXmode:\n+      return (code == EQ || code == NE || code == UNEQ || code == LTGT\n+\t      || code == ORDERED || code == UNORDERED);\n+\n+    case CCmode:\n+    case SImode: /* Used for BRcc.  */\n+      return 1;\n+    /* From combiner.  */\n+    case QImode: case HImode: case DImode: case SFmode: case DFmode:\n+      return 0;\n+    default:\n+      gcc_unreachable ();\n+  }\n+})\n+\n+(define_predicate \"equality_comparison_operator\"\n+  (match_code \"eq, ne\"))\n+\n+(define_predicate \"brcc_nolimm_operator\"\n+  (ior (match_test \"REG_P (XEXP (op, 1))\")\n+       (and (match_code \"eq, ne, lt, ge, ltu, geu\")\n+\t    (match_test \"u6_immediate_operand (XEXP (op, 1), SImode)\"))\n+       (and (match_code \"le, gt, leu, gtu\")\n+\t    (match_test \"UNSIGNED_INT6 (INTVAL (XEXP (op, 1)) + 1)\"))))\n+\n+;; Return TRUE if this is the condition code register, if we aren't given\n+;; a mode, accept any CCmode register\n+(define_special_predicate \"cc_register\"\n+  (match_code \"reg\")\n+{\n+  if (mode == VOIDmode)\n+    {\n+      mode = GET_MODE (op);\n+      if (GET_MODE_CLASS (mode) != MODE_CC)\n+\treturn FALSE;\n+    }\n+\n+  if (mode == GET_MODE (op) && GET_CODE (op) == REG && REGNO (op) == CC_REG)\n+    return TRUE;\n+\n+  return FALSE;\n+})\n+\n+;; Return TRUE if this is the condition code register; if we aren't given\n+;; a mode, accept any CCmode register.  If we are given a mode, accept\n+;; modes that set a subset of flags.\n+(define_special_predicate \"cc_set_register\"\n+  (match_code \"reg\")\n+{\n+  enum machine_mode rmode = GET_MODE (op);\n+\n+  if (mode == VOIDmode)\n+    {\n+      mode = rmode;\n+      if (GET_MODE_CLASS (mode) != MODE_CC)\n+\treturn FALSE;\n+    }\n+\n+  if (REGNO (op) != 61)\n+    return FALSE;\n+  if (mode == rmode\n+      || (mode == CC_ZNmode && rmode == CC_Zmode)\n+      || (mode == CCmode && rmode == CC_Zmode)\n+      || (mode == CCmode && rmode == CC_ZNmode)\n+      || (mode == CCmode && rmode == CC_Cmode))\n+    return TRUE;\n+\n+  return FALSE;\n+})\n+\n+; Accept CC_REG in modes which provide the flags needed for MODE.  */\n+(define_special_predicate \"cc_use_register\"\n+  (match_code \"reg\")\n+{\n+  if (REGNO (op) != CC_REG)\n+    return 0;\n+  if (GET_MODE (op) == mode)\n+    return 1;\n+  switch (mode)\n+    {\n+    case CC_Zmode:\n+      if (GET_MODE (op) == CC_ZNmode)\n+\treturn 1;\n+      /* Fall through.  */\n+    case CC_ZNmode: case CC_Cmode:\n+      return GET_MODE (op) == CCmode;\n+    default:\n+      gcc_unreachable ();\n+    }\n+})\n+\n+(define_special_predicate \"zn_compare_operator\"\n+  (match_code \"compare\")\n+{\n+  return GET_MODE (op) == CC_ZNmode || GET_MODE (op) == CC_Zmode;\n+})\n+\n+;; Return true if OP is a shift operator.\n+(define_predicate \"shift_operator\"\n+  (match_code \"ashiftrt, lshiftrt, ashift\")\n+)\n+\n+;; Return true if OP is a left shift operator that can be implemented in\n+;; four insn words or less without a barrel shifter or multiplier.\n+(define_predicate \"shiftl4_operator\"\n+  (and (match_code \"ashift\")\n+       (match_test \"const_int_operand (XEXP (op, 1), VOIDmode) \")\n+       (match_test \"UINTVAL (XEXP (op, 1)) <= 9U\n+\t\t    || INTVAL (XEXP (op, 1)) == 29\n+\t\t    || INTVAL (XEXP (op, 1)) == 30\n+\t\t    || INTVAL (XEXP (op, 1)) == 31\")))\n+\n+;; Return true if OP is a right shift operator that can be implemented in\n+;; four insn words or less without a barrel shifter or multiplier.\n+(define_predicate \"shiftr4_operator\"\n+  (and (match_code \"ashiftrt, lshiftrt\")\n+       (match_test \"const_int_operand (XEXP (op, 1), VOIDmode) \")\n+       (match_test \"UINTVAL (XEXP (op, 1)) <= 4U\n+\t\t    || INTVAL (XEXP (op, 1)) == 30\n+\t\t    || INTVAL (XEXP (op, 1)) == 31\")))\n+\n+;; Return true if OP is a shift operator that can be implemented in\n+;; four insn words or less without a barrel shifter or multiplier.\n+(define_predicate \"shift4_operator\"\n+  (ior (match_operand 0 \"shiftl4_operator\")\n+       (match_operand 0 \"shiftr4_operator\")))\n+\n+(define_predicate \"mult_operator\"\n+    (and (match_code \"mult\") (match_test \"TARGET_ARC700 && !TARGET_NOMPY_SET\"))\n+)\n+\n+(define_predicate \"commutative_operator\"\n+  (ior (match_code \"plus,ior,xor,and\")\n+       (match_operand 0 \"mult_operator\")\n+       (and (match_code \"ss_plus\")\n+\t    (match_test \"TARGET_ARC700 || TARGET_EA_SET\")))\n+)\n+\n+(define_predicate \"commutative_operator_sans_mult\"\n+  (ior (match_code \"plus,ior,xor,and\")\n+       (and (match_code \"ss_plus\")\n+\t    (match_test \"TARGET_ARC700 || TARGET_EA_SET\")))\n+)\n+\n+(define_predicate \"noncommutative_operator\"\n+  (ior (match_code \"minus,ashift,ashiftrt,lshiftrt,rotatert\")\n+       (and (match_code \"ss_minus\")\n+\t    (match_test \"TARGET_ARC700 || TARGET_EA_SET\")))\n+)\n+\n+(define_predicate \"unary_operator\"\n+  (ior (match_code \"abs,neg,not,sign_extend,zero_extend\")\n+       (and (ior (match_code \"ss_neg\")\n+\t\t (and (match_code \"ss_truncate\")\n+\t\t      (match_test \"GET_MODE (XEXP (op, 0)) == HImode\")))\n+\t    (match_test \"TARGET_ARC700 || TARGET_EA_SET\")))\n+)\n+\n+(define_predicate \"_2_4_8_operand\"\n+  (and (match_code \"const_int\")\n+       (match_test \"INTVAL (op) == 2 || INTVAL (op) == 4 || INTVAL (op) == 8\"))\n+)\n+\n+(define_predicate \"arc_double_register_operand\"\n+  (match_code \"reg\")\n+{\n+  if ((GET_MODE (op) != mode) && (mode != VOIDmode))\n+    return 0;\n+\n+  return (GET_CODE (op) == REG\n+\t\t   && (REGNO (op) >= FIRST_PSEUDO_REGISTER\n+\t\t\t     || REGNO_REG_CLASS (REGNO (op)) == DOUBLE_REGS));\n+})\n+\n+(define_predicate \"shouldbe_register_operand\"\n+  (match_code \"reg,subreg,mem\")\n+{\n+  return ((reload_in_progress || reload_completed)\n+\t  ? general_operand : register_operand) (op, mode);\n+})\n+\n+(define_predicate \"vector_register_operand\"\n+  (match_code \"reg\")\n+{\n+  if ((GET_MODE (op) != mode) && (mode != VOIDmode))\n+    return 0;\n+\n+  return (GET_CODE (op) == REG\n+\t  && (REGNO (op) >= FIRST_PSEUDO_REGISTER\n+\t      || REGNO_REG_CLASS (REGNO (op)) == SIMD_VR_REGS));\n+})\n+\n+(define_predicate \"vector_register_or_memory_operand\"\n+  ( ior (match_code \"reg\")\n+\t(match_code \"mem\"))\n+{\n+  if ((GET_MODE (op) != mode) && (mode != VOIDmode))\n+    return 0;\n+\n+  if ((GET_CODE (op) == MEM)\n+      && (mode == V8HImode)\n+      && GET_CODE (XEXP (op,0)) == REG)\n+    return 1;\n+\n+  return (GET_CODE (op) == REG\n+\t  && (REGNO (op) >= FIRST_PSEUDO_REGISTER\n+\t      || REGNO_REG_CLASS (REGNO (op)) == SIMD_VR_REGS));\n+})\n+\n+(define_predicate \"arc_dpfp_operator\"\n+  (match_code \"plus, mult,minus\")\n+)\n+\n+(define_predicate \"arc_simd_dma_register_operand\"\n+  (match_code \"reg\")\n+{\n+  if ((GET_MODE (op) != mode) && (mode != VOIDmode))\n+    return 0;\n+\n+  return (GET_CODE (op) == REG\n+\t  && (REGNO (op) >= FIRST_PSEUDO_REGISTER\n+\t      || REGNO_REG_CLASS (REGNO (op)) == SIMD_DMA_CONFIG_REGS));\n+})\n+\n+(define_predicate \"acc1_operand\"\n+  (and (match_code \"reg\")\n+       (match_test \"REGNO (op) == (TARGET_BIG_ENDIAN ? 56 : 57)\")))\n+\n+(define_predicate \"acc2_operand\"\n+  (and (match_code \"reg\")\n+       (match_test \"REGNO (op) == (TARGET_BIG_ENDIAN ? 57 : 56)\")))\n+\n+(define_predicate \"mlo_operand\"\n+  (and (match_code \"reg\")\n+       (match_test \"REGNO (op) == (TARGET_BIG_ENDIAN ? 59 : 58)\")))\n+\n+(define_predicate \"mhi_operand\"\n+  (and (match_code \"reg\")\n+       (match_test \"REGNO (op) == (TARGET_BIG_ENDIAN ? 58 : 59)\")))\n+\n+(define_predicate \"extend_operand\"\n+  (ior (match_test \"register_operand (op, mode)\")\n+       (and (match_test \"immediate_operand (op, mode)\")\n+\t    (not (match_test \"const_int_operand (op, mode)\")))))\n+\n+(define_predicate \"millicode_store_operation\"\n+  (match_code \"parallel\")\n+{\n+  return arc_check_millicode (op, 0, 0);\n+})\n+\n+(define_predicate \"millicode_load_operation\"\n+  (match_code \"parallel\")\n+{\n+  return arc_check_millicode (op, 2, 2);\n+})\n+\n+(define_predicate \"millicode_load_clob_operation\"\n+  (match_code \"parallel\")\n+{\n+  return arc_check_millicode (op, 0, 1);\n+})\n+\n+(define_special_predicate \"immediate_usidi_operand\"\n+  (if_then_else\n+    (match_code \"const_int\")\n+    (match_test \"INTVAL (op) >= 0\")\n+    (and (match_test \"const_double_operand (op, mode)\")\n+\t (match_test \"CONST_DOUBLE_HIGH (op) == 0\"))))"}, {"sha": "22daf51fa66f4c61a95064dcd77a4b2478c73a85", "filename": "gcc/config/arc/simdext.md", "status": "added", "additions": 1313, "deletions": 0, "changes": 1313, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Fsimdext.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Fsimdext.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Fsimdext.md?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -0,0 +1,1313 @@\n+;; Machine description of the Synopsys DesignWare ARC cpu for GNU C compiler\n+;; Copyright (C) 2007-2012 Free Software Foundation, Inc.\n+\n+;; This file is part of GCC.\n+\n+;; GCC is free software; you can redistribute it and/or modify\n+;; it under the terms of the GNU General Public License as published by\n+;; the Free Software Foundation; either version 3, or (at your option)\n+;; any later version.\n+\n+;; GCC is distributed in the hope that it will be useful,\n+;; but WITHOUT ANY WARRANTY; without even the implied warranty of\n+;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+;; GNU General Public License for more details.\n+\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+(define_constants\n+  [\n+  ;; Va, Vb, Vc builtins\n+  (UNSPEC_ARC_SIMD_VADDAW     1000)\n+  (UNSPEC_ARC_SIMD_VADDW      1001)\n+  (UNSPEC_ARC_SIMD_VAVB       1002)\n+  (UNSPEC_ARC_SIMD_VAVRB      1003)\n+  (UNSPEC_ARC_SIMD_VDIFAW     1004)\n+  (UNSPEC_ARC_SIMD_VDIFW      1005)\n+  (UNSPEC_ARC_SIMD_VMAXAW     1006)\n+  (UNSPEC_ARC_SIMD_VMAXW      1007)\n+  (UNSPEC_ARC_SIMD_VMINAW     1008)\n+  (UNSPEC_ARC_SIMD_VMINW      1009)\n+  (UNSPEC_ARC_SIMD_VMULAW     1010)\n+  (UNSPEC_ARC_SIMD_VMULFAW    1011)\n+  (UNSPEC_ARC_SIMD_VMULFW     1012)\n+  (UNSPEC_ARC_SIMD_VMULW      1013)\n+  (UNSPEC_ARC_SIMD_VSUBAW     1014)\n+  (UNSPEC_ARC_SIMD_VSUBW      1015)\n+  (UNSPEC_ARC_SIMD_VSUMMW     1016)\n+  (UNSPEC_ARC_SIMD_VAND       1017)\n+  (UNSPEC_ARC_SIMD_VANDAW     1018)\n+  (UNSPEC_ARC_SIMD_VBIC       1019)\n+  (UNSPEC_ARC_SIMD_VBICAW     1020)\n+  (UNSPEC_ARC_SIMD_VOR        1021)\n+  (UNSPEC_ARC_SIMD_VXOR       1022)\n+  (UNSPEC_ARC_SIMD_VXORAW     1023)\n+  (UNSPEC_ARC_SIMD_VEQW       1024)\n+  (UNSPEC_ARC_SIMD_VLEW       1025)\n+  (UNSPEC_ARC_SIMD_VLTW       1026)\n+  (UNSPEC_ARC_SIMD_VNEW       1027)\n+  (UNSPEC_ARC_SIMD_VMR1AW     1028)\n+  (UNSPEC_ARC_SIMD_VMR1W      1029)\n+  (UNSPEC_ARC_SIMD_VMR2AW     1030)\n+  (UNSPEC_ARC_SIMD_VMR2W      1031)\n+  (UNSPEC_ARC_SIMD_VMR3AW     1032)\n+  (UNSPEC_ARC_SIMD_VMR3W      1033)\n+  (UNSPEC_ARC_SIMD_VMR4AW     1034)\n+  (UNSPEC_ARC_SIMD_VMR4W      1035)\n+  (UNSPEC_ARC_SIMD_VMR5AW     1036)\n+  (UNSPEC_ARC_SIMD_VMR5W      1037)\n+  (UNSPEC_ARC_SIMD_VMR6AW     1038)\n+  (UNSPEC_ARC_SIMD_VMR6W      1039)\n+  (UNSPEC_ARC_SIMD_VMR7AW     1040)\n+  (UNSPEC_ARC_SIMD_VMR7W      1041)\n+  (UNSPEC_ARC_SIMD_VMRB       1042)\n+  (UNSPEC_ARC_SIMD_VH264F     1043)\n+  (UNSPEC_ARC_SIMD_VH264FT    1044)\n+  (UNSPEC_ARC_SIMD_VH264FW    1045)\n+  (UNSPEC_ARC_SIMD_VVC1F      1046)\n+  (UNSPEC_ARC_SIMD_VVC1FT     1047)\n+  ;; Va, Vb, rc/limm builtins\n+  (UNSPEC_ARC_SIMD_VBADDW     1050)\n+  (UNSPEC_ARC_SIMD_VBMAXW     1051)\n+  (UNSPEC_ARC_SIMD_VBMINW     1052)\n+  (UNSPEC_ARC_SIMD_VBMULAW    1053)\n+  (UNSPEC_ARC_SIMD_VBMULFW    1054)\n+  (UNSPEC_ARC_SIMD_VBMULW     1055)\n+  (UNSPEC_ARC_SIMD_VBRSUBW    1056)\n+  (UNSPEC_ARC_SIMD_VBSUBW     1057)\n+\n+  ;; Va, Vb, Ic builtins\n+  (UNSPEC_ARC_SIMD_VASRW      1060)\n+  (UNSPEC_ARC_SIMD_VSR8       1061)\n+  (UNSPEC_ARC_SIMD_VSR8AW     1062)\n+\n+  ;; Va, Vb, Ic builtins\n+  (UNSPEC_ARC_SIMD_VASRRWi    1065)\n+  (UNSPEC_ARC_SIMD_VASRSRWi   1066)\n+  (UNSPEC_ARC_SIMD_VASRWi     1067)\n+  (UNSPEC_ARC_SIMD_VASRPWBi   1068)\n+  (UNSPEC_ARC_SIMD_VASRRPWBi  1069)\n+  (UNSPEC_ARC_SIMD_VSR8AWi    1070)\n+  (UNSPEC_ARC_SIMD_VSR8i      1071)\n+\n+  ;; Va, Vb, u8 (simm) builtins\n+  (UNSPEC_ARC_SIMD_VMVAW      1075)\n+  (UNSPEC_ARC_SIMD_VMVW       1076)\n+  (UNSPEC_ARC_SIMD_VMVZW      1077)\n+  (UNSPEC_ARC_SIMD_VD6TAPF    1078)\n+\n+  ;; Va, rlimm, u8 (simm) builtins\n+  (UNSPEC_ARC_SIMD_VMOVAW     1080)\n+  (UNSPEC_ARC_SIMD_VMOVW      1081)\n+  (UNSPEC_ARC_SIMD_VMOVZW     1082)\n+\n+  ;; Va, Vb builtins\n+  (UNSPEC_ARC_SIMD_VABSAW     1085)\n+  (UNSPEC_ARC_SIMD_VABSW      1086)\n+  (UNSPEC_ARC_SIMD_VADDSUW    1087)\n+  (UNSPEC_ARC_SIMD_VSIGNW     1088)\n+  (UNSPEC_ARC_SIMD_VEXCH1     1089)\n+  (UNSPEC_ARC_SIMD_VEXCH2     1090)\n+  (UNSPEC_ARC_SIMD_VEXCH4     1091)\n+  (UNSPEC_ARC_SIMD_VUPBAW     1092)\n+  (UNSPEC_ARC_SIMD_VUPBW      1093)\n+  (UNSPEC_ARC_SIMD_VUPSBAW    1094)\n+  (UNSPEC_ARC_SIMD_VUPSBW     1095)\n+\n+  (UNSPEC_ARC_SIMD_VDIRUN     1100)\n+  (UNSPEC_ARC_SIMD_VDORUN     1101)\n+  (UNSPEC_ARC_SIMD_VDIWR      1102)\n+  (UNSPEC_ARC_SIMD_VDOWR      1103)\n+\n+  (UNSPEC_ARC_SIMD_VREC      1105)\n+  (UNSPEC_ARC_SIMD_VRUN      1106)\n+  (UNSPEC_ARC_SIMD_VRECRUN   1107)\n+  (UNSPEC_ARC_SIMD_VENDREC   1108)\n+\n+  (UNSPEC_ARC_SIMD_VLD32WH   1110)\n+  (UNSPEC_ARC_SIMD_VLD32WL   1111)\n+\n+  (UNSPEC_ARC_SIMD_VCAST     1200)\n+  (UNSPEC_ARC_SIMD_VINTI     1201)\n+   ]\n+)\n+\n+;; Scheduler descriptions for the simd instructions\n+(define_insn_reservation \"simd_lat_0_insn\" 1\n+  (eq_attr \"type\" \"simd_dma, simd_vstore, simd_vcontrol\")\n+  \"issue+simd_unit\")\n+\n+(define_insn_reservation \"simd_lat_1_insn\" 2\n+       (eq_attr \"type\" \"simd_vcompare, simd_vlogic,\n+                        simd_vmove_else_zero, simd_varith_1cycle\")\n+  \"issue+simd_unit, nothing\")\n+\n+(define_insn_reservation \"simd_lat_2_insn\" 3\n+       (eq_attr \"type\" \"simd_valign, simd_vpermute,\n+                        simd_vpack, simd_varith_2cycle\")\n+  \"issue+simd_unit, nothing*2\")\n+\n+(define_insn_reservation \"simd_lat_3_insn\" 4\n+       (eq_attr \"type\" \"simd_valign_with_acc, simd_vpack_with_acc,\n+                        simd_vlogic_with_acc, simd_vload128,\n+                        simd_vmove_with_acc, simd_vspecial_3cycle,\n+                        simd_varith_with_acc\")\n+  \"issue+simd_unit, nothing*3\")\n+\n+(define_insn_reservation \"simd_lat_4_insn\" 5\n+       (eq_attr \"type\" \"simd_vload, simd_vmove, simd_vspecial_4cycle\")\n+  \"issue+simd_unit, nothing*4\")\n+\n+(define_expand \"movv8hi\"\n+  [(set (match_operand:V8HI 0 \"general_operand\" \"\")\n+\t(match_operand:V8HI 1 \"general_operand\" \"\"))]\n+  \"\"\n+  \"\n+{\n+  /* Everything except mem = const or mem = mem can be done easily.  */\n+\n+  if (GET_CODE (operands[0]) == MEM && GET_CODE(operands[1]) == MEM)\n+    operands[1] = force_reg (V8HImode, operands[1]);\n+}\")\n+\n+;; This pattern should appear before the movv8hi_insn pattern\n+(define_insn \"vld128_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\" \"=v\")\n+\t(mem:V8HI (plus:SI (zero_extend:SI (vec_select:HI (match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t\t\t\t\t  (parallel [(match_operand:SI 2 \"immediate_operand\" \"L\")])))\n+\t\t\t   (match_operand:SI 3 \"immediate_operand\" \"P\"))))]\n+ \"TARGET_SIMD_SET\"\n+ \"vld128 %0, [i%2, %3]\"\n+ [(set_attr \"type\" \"simd_vload128\")\n+  (set_attr \"length\" \"4\")\n+  (set_attr \"cond\" \"nocond\")]\n+)\n+\n+(define_insn \"vst128_insn\"\n+  [(set\t(mem:V8HI (plus:SI (zero_extend:SI (vec_select:HI (match_operand:V8HI 0 \"vector_register_operand\"  \"v\")\n+\t\t\t\t\t\t\t  (parallel [(match_operand:SI 1 \"immediate_operand\" \"L\")])))\n+\t\t\t   (match_operand:SI 2 \"immediate_operand\" \"P\")))\n+\t(match_operand:V8HI 3 \"vector_register_operand\" \"=v\"))]\n+ \"TARGET_SIMD_SET\"\n+ \"vst128 %3, [i%1, %2]\"\n+ [(set_attr \"type\" \"simd_vstore\")\n+  (set_attr \"length\" \"4\")\n+  (set_attr \"cond\" \"nocond\")]\n+)\n+\n+(define_insn \"vst64_insn\"\n+  [(set\t(mem:V4HI (plus:SI (zero_extend:SI (vec_select:HI (match_operand:V8HI 0 \"vector_register_operand\"  \"v\")\n+\t\t\t\t\t\t\t  (parallel [(match_operand:SI 1 \"immediate_operand\" \"L\")])))\n+\t\t\t   (match_operand:SI 2 \"immediate_operand\" \"P\")))\n+\t(vec_select:V4HI (match_operand:V8HI 3 \"vector_register_operand\" \"=v\")\n+\t\t\t (parallel [(const_int 0)])))]\n+ \"TARGET_SIMD_SET\"\n+ \"vst64 %3, [i%1, %2]\"\n+ [(set_attr \"type\" \"simd_vstore\")\n+  (set_attr \"length\" \"4\")\n+  (set_attr \"cond\" \"nocond\")]\n+)\n+\n+(define_insn \"movv8hi_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_or_memory_operand\" \"=v,m,v\")\n+\t(match_operand:V8HI 1 \"vector_register_or_memory_operand\" \"m,v,v\"))]\n+  \"TARGET_SIMD_SET && !(GET_CODE (operands[0]) == MEM && GET_CODE(operands[1]) == MEM)\"\n+  \"@\n+    vld128r %0, %1\n+    vst128r %1, %0\n+    vmvzw %0,%1,0xffff\"\n+  [(set_attr \"type\" \"simd_vload128,simd_vstore,simd_vmove_else_zero\")\n+   (set_attr \"length\" \"8,8,4\")\n+   (set_attr \"cond\" \"nocond, nocond, nocond\")])\n+\n+(define_insn \"movti_insn\"\n+  [(set (match_operand:TI 0 \"vector_register_or_memory_operand\" \"=v,m,v\")\n+\t(match_operand:TI 1 \"vector_register_or_memory_operand\" \"m,v,v\"))]\n+  \"\"\n+  \"@\n+    vld128r %0, %1\n+    vst128r %1, %0\n+    vmvzw %0,%1,0xffff\"\n+  [(set_attr \"type\" \"simd_vload128,simd_vstore,simd_vmove_else_zero\")\n+   (set_attr \"length\" \"8,8,4\")\n+   (set_attr \"cond\" \"nocond, nocond, nocond\")])\n+\n+;; (define_insn \"*movv8hi_insn_rr\"\n+;;   [(set (match_operand:V8HI 0 \"vector_register_operand\" \"=v\")\n+;; \t(match_operand:V8HI 1 \"vector_register_operand\" \"v\"))]\n+;;   \"\"\n+;;   \"mov reg,reg\"\n+;;   [(set_attr \"length\" \"8\")\n+;;   (set_attr \"type\" \"move\")])\n+\n+;; (define_insn \"*movv8_out\"\n+;;   [(set (match_operand:V8HI 0 \"memory_operand\" \"=m\")\n+;; \t(match_operand:V8HI 1 \"vector_register_operand\" \"v\"))]\n+;;   \"\"\n+;;   \"mov out\"\n+;;   [(set_attr \"length\" \"8\")\n+;;   (set_attr \"type\" \"move\")])\n+\n+\n+;; (define_insn \"addv8hi3\"\n+;;   [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+;; \t(plus:V8HI (match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+;; \t\t   (match_operand:V8HI 2 \"vector_register_operand\" \"v\")))]\n+;;   \"TARGET_SIMD_SET\"\n+;;   \"vaddw %0, %1, %2\"\n+;;   [(set_attr \"length\" \"8\")\n+;;    (set_attr \"cond\" \"nocond\")])\n+\n+;; (define_insn \"vaddw_insn\"\n+;;   [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+;; \t(unspec [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+;; \t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VADDW))]\n+;;   \"TARGET_SIMD_SET\"\n+;;   \"vaddw %0, %1, %2\"\n+;;   [(set_attr \"length\" \"8\")\n+;;    (set_attr \"cond\" \"nocond\")])\n+\n+;; V V V Insns\n+(define_insn \"vaddaw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VADDAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vaddaw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vaddw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VADDW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vaddw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vavb_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VAVB))]\n+  \"TARGET_SIMD_SET\"\n+  \"vavb %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vavrb_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VAVRB))]\n+  \"TARGET_SIMD_SET\"\n+  \"vavrb %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vdifaw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VDIFAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vdifaw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vdifw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VDIFW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vdifw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmaxaw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMAXAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmaxaw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmaxw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMAXW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmaxw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vminaw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMINAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vminaw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vminw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMINW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vminw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmulaw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMULAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmulaw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmulfaw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMULFAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmulfaw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmulfw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMULFW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmulfw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_2cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmulw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMULW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmulw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_2cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vsubaw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VSUBAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vsubaw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vsubw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VSUBW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vsubw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vsummw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VSUMMW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vsummw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_2cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vand_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VAND))]\n+  \"TARGET_SIMD_SET\"\n+  \"vand %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vlogic\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vandaw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VANDAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vandaw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vlogic_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vbic_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VBIC))]\n+  \"TARGET_SIMD_SET\"\n+  \"vbic %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vlogic\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vbicaw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VBICAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vbicaw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vlogic_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vor_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VOR))]\n+  \"TARGET_SIMD_SET\"\n+  \"vor %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vlogic\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vxor_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VXOR))]\n+  \"TARGET_SIMD_SET\"\n+  \"vxor %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vlogic\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vxoraw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VXORAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vxoraw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vlogic_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"veqw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VEQW))]\n+  \"TARGET_SIMD_SET\"\n+  \"veqw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vcompare\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vlew_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VLEW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vlew %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vcompare\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vltw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VLTW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vltw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vcompare\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vnew_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VNEW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vnew %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vcompare\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmr1aw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMR1AW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmr1aw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmr1w_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMR1W))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmr1w %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmr2aw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMR2AW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmr2aw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmr2w_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMR2W))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmr2w %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmr3aw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMR3AW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmr3aw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmr3w_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMR3W))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmr3w %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmr4aw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMR4AW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmr4aw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmr4w_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMR4W))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmr4w %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmr5aw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMR5AW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmr5aw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmr5w_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMR5W))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmr5w %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmr6aw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMR6AW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmr6aw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmr6w_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMR6W))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmr6w %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmr7aw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMR7AW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmr7aw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmr7w_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMR7W))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmr7w %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmrb_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VMRB))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmrb %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vh264f_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VH264F))]\n+  \"TARGET_SIMD_SET\"\n+  \"vh264f %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vspecial_3cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vh264ft_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VH264FT))]\n+  \"TARGET_SIMD_SET\"\n+  \"vh264ft %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vspecial_3cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vh264fw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VH264FW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vh264fw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vspecial_3cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vvc1f_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VVC1F))]\n+  \"TARGET_SIMD_SET\"\n+  \"vvc1f %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vspecial_3cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vvc1ft_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t (match_operand:V8HI 2 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VVC1FT))]\n+  \"TARGET_SIMD_SET\"\n+  \"vvc1ft %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vspecial_3cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+\n+\n+;;---\n+;; V V r/limm Insns\n+\n+;; (define_insn \"vbaddw_insn\"\n+;;   [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+;; \t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+;; \t\t\t      (match_operand:SI 2 \"nonmemory_operand\" \"rCal\")] UNSPEC_ARC_SIMD_VBADDW))]\n+;;   \"TARGET_SIMD_SET\"\n+;;   \"vbaddw %0, %1, %2\"\n+;;   [(set_attr \"length\" \"4\")\n+;;    (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vbaddw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"nonmemory_operand\" \"r\")] UNSPEC_ARC_SIMD_VBADDW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vbaddw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vbmaxw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"nonmemory_operand\" \"r\")] UNSPEC_ARC_SIMD_VBMAXW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vbmaxw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vbminw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"nonmemory_operand\" \"r\")] UNSPEC_ARC_SIMD_VBMINW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vbminw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vbmulaw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"nonmemory_operand\" \"r\")] UNSPEC_ARC_SIMD_VBMULAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vbmulaw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vbmulfw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"nonmemory_operand\" \"r\")] UNSPEC_ARC_SIMD_VBMULFW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vbmulfw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_2cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vbmulw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"nonmemory_operand\" \"r\")] UNSPEC_ARC_SIMD_VBMULW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vbmulw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_2cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vbrsubw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t     (match_operand:SI 2 \"nonmemory_operand\" \"r\")] UNSPEC_ARC_SIMD_VBRSUBW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vbrsubw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vbsubw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"nonmemory_operand\" \"r\")] UNSPEC_ARC_SIMD_VBSUBW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vbsubw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+; Va, Vb, Ic instructions\n+\n+; Va, Vb, u6 instructions\n+(define_insn \"vasrrwi_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"L\")] UNSPEC_ARC_SIMD_VASRRWi))]\n+  \"TARGET_SIMD_SET\"\n+  \"vasrrwi %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_2cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vasrsrwi_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t     (match_operand:SI 2 \"immediate_operand\" \"L\")] UNSPEC_ARC_SIMD_VASRSRWi))]\n+  \"TARGET_SIMD_SET\"\n+  \"vasrsrwi %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_2cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vasrwi_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"L\")] UNSPEC_ARC_SIMD_VASRWi))]\n+  \"TARGET_SIMD_SET\"\n+  \"vasrwi %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vasrpwbi_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"L\")] UNSPEC_ARC_SIMD_VASRPWBi))]\n+  \"TARGET_SIMD_SET\"\n+  \"vasrpwbi %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vpack\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vasrrpwbi_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"L\")] UNSPEC_ARC_SIMD_VASRRPWBi))]\n+  \"TARGET_SIMD_SET\"\n+  \"vasrrpwbi %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vpack\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vsr8awi_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"L\")] UNSPEC_ARC_SIMD_VSR8AWi))]\n+  \"TARGET_SIMD_SET\"\n+  \"vsr8awi %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vsr8i_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"L\")] UNSPEC_ARC_SIMD_VSR8i))]\n+  \"TARGET_SIMD_SET\"\n+  \"vsr8i %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_valign\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+;; Va, Vb, u8 (simm) insns\n+\n+(define_insn \"vmvaw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+        (unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"P\")] UNSPEC_ARC_SIMD_VMVAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmvaw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vmove_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmvw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+        (unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"P\")] UNSPEC_ARC_SIMD_VMVW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmvw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vmove\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmvzw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+        (unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"P\")] UNSPEC_ARC_SIMD_VMVZW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmvzw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vmove_else_zero\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vd6tapf_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+        (unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"P\")] UNSPEC_ARC_SIMD_VD6TAPF))]\n+  \"TARGET_SIMD_SET\"\n+  \"vd6tapf %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vspecial_4cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+;; Va, rlimm, u8 (simm) insns\n+(define_insn \"vmovaw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+        (unspec:V8HI [(match_operand:SI 1 \"nonmemory_operand\"  \"r\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"P\")] UNSPEC_ARC_SIMD_VMOVAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmovaw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vmove_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmovw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+        (unspec:V8HI [(match_operand:SI 1 \"nonmemory_operand\"  \"r\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"P\")] UNSPEC_ARC_SIMD_VMOVW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmovw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vmove\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vmovzw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+        (unspec:V8HI [(match_operand:SI 1 \"nonmemory_operand\"  \"r\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"P\")] UNSPEC_ARC_SIMD_VMOVZW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vmovzw %0, %1, %2\"\n+  [(set_attr \"type\" \"simd_vmove_else_zero\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+;; Va, rlimm, Ic insns\n+(define_insn \"vsr8_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"K\")\n+\t\t      (match_operand:V8HI 3 \"vector_register_operand\"  \"v\")] UNSPEC_ARC_SIMD_VSR8))]\n+  \"TARGET_SIMD_SET\"\n+  \"vsr8 %0, %1, i%2\"\n+  [(set_attr \"type\" \"simd_valign\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vasrw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"K\")\n+\t\t      (match_operand:V8HI 3 \"vector_register_operand\"  \"v\")] UNSPEC_ARC_SIMD_VASRW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vasrw %0, %1, i%2\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vsr8aw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"K\")\n+\t\t      (match_operand:V8HI 3 \"vector_register_operand\"  \"v\")] UNSPEC_ARC_SIMD_VSR8AW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vsr8aw %0, %1, i%2\"\n+  [(set_attr \"type\" \"simd_valign_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+;; Va, Vb insns\n+(define_insn \"vabsaw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"  \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")] UNSPEC_ARC_SIMD_VABSAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vabsaw %0, %1\"\n+  [(set_attr \"type\" \"simd_varith_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vabsw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"  \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")] UNSPEC_ARC_SIMD_VABSW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vabsw %0, %1\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vaddsuw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"  \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")] UNSPEC_ARC_SIMD_VADDSUW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vaddsuw %0, %1\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vsignw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"  \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")] UNSPEC_ARC_SIMD_VSIGNW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vsignw %0, %1\"\n+  [(set_attr \"type\" \"simd_varith_1cycle\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vexch1_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"  \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")] UNSPEC_ARC_SIMD_VEXCH1))]\n+  \"TARGET_SIMD_SET\"\n+  \"vexch1 %0, %1\"\n+  [(set_attr \"type\" \"simd_vpermute\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vexch2_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"  \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")] UNSPEC_ARC_SIMD_VEXCH2))]\n+  \"TARGET_SIMD_SET\"\n+  \"vexch2 %0, %1\"\n+  [(set_attr \"type\" \"simd_vpermute\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vexch4_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"  \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")] UNSPEC_ARC_SIMD_VEXCH4))]\n+  \"TARGET_SIMD_SET\"\n+  \"vexch4 %0, %1\"\n+  [(set_attr \"type\" \"simd_vpermute\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vupbaw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"  \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")] UNSPEC_ARC_SIMD_VUPBAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vupbaw %0, %1\"\n+  [(set_attr \"type\" \"simd_vpack_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vupbw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"  \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")] UNSPEC_ARC_SIMD_VUPBW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vupbw %0, %1\"\n+  [(set_attr \"type\" \"simd_vpack\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vupsbaw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"  \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")] UNSPEC_ARC_SIMD_VUPSBAW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vupsbaw %0, %1\"\n+  [(set_attr \"type\" \"simd_vpack_with_acc\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vupsbw_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"  \"=v\")\n+\t(unspec:V8HI [(match_operand:V8HI 1 \"vector_register_operand\"  \"v\")] UNSPEC_ARC_SIMD_VUPSBW))]\n+  \"TARGET_SIMD_SET\"\n+  \"vupsbw %0, %1\"\n+  [(set_attr \"type\" \"simd_vpack\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+; DMA setup instructions\n+(define_insn \"vdirun_insn\"\n+  [(set (match_operand:SI 0 \"arc_simd_dma_register_operand\"           \"=d\")\n+        (unspec_volatile:SI [(match_operand:SI 1 \"nonmemory_operand\"  \"r\")\n+\t\t\t     (match_operand:SI 2 \"nonmemory_operand\" \"r\")] UNSPEC_ARC_SIMD_VDIRUN))]\n+  \"TARGET_SIMD_SET\"\n+  \"vdirun %1, %2\"\n+  [(set_attr \"type\" \"simd_dma\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vdorun_insn\"\n+  [(set (match_operand:SI 0 \"arc_simd_dma_register_operand\"              \"=d\")\n+        (unspec_volatile:SI [(match_operand:SI 1 \"nonmemory_operand\"     \"r\")\n+\t\t\t     (match_operand:SI 2 \"nonmemory_operand\"     \"r\")] UNSPEC_ARC_SIMD_VDORUN))]\n+  \"TARGET_SIMD_SET\"\n+  \"vdorun %1, %2\"\n+  [(set_attr \"type\" \"simd_dma\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vdiwr_insn\"\n+  [(set (match_operand:SI 0 \"arc_simd_dma_register_operand\"           \"=d,d\")\n+        (unspec_volatile:SI [(match_operand:SI 1 \"nonmemory_operand\"  \"r,Cal\")] UNSPEC_ARC_SIMD_VDIWR))]\n+  \"TARGET_SIMD_SET\"\n+  \"vdiwr %0, %1\"\n+  [(set_attr \"type\" \"simd_dma\")\n+   (set_attr \"length\" \"4,8\")\n+   (set_attr \"cond\" \"nocond,nocond\")])\n+\n+(define_insn \"vdowr_insn\"\n+  [(set (match_operand:SI 0 \"arc_simd_dma_register_operand\"           \"=d,d\")\n+        (unspec_volatile:SI [(match_operand:SI 1 \"nonmemory_operand\"  \"r,Cal\")] UNSPEC_ARC_SIMD_VDOWR))]\n+  \"TARGET_SIMD_SET\"\n+  \"vdowr %0, %1\"\n+  [(set_attr \"type\" \"simd_dma\")\n+   (set_attr \"length\" \"4,8\")\n+   (set_attr \"cond\" \"nocond,nocond\")])\n+\n+;; vector record and run instructions\n+(define_insn \"vrec_insn\"\n+  [(unspec_volatile [(match_operand:SI 0 \"nonmemory_operand\"  \"r\")] UNSPEC_ARC_SIMD_VREC)]\n+  \"TARGET_SIMD_SET\"\n+  \"vrec %0\"\n+  [(set_attr \"type\" \"simd_vcontrol\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vrun_insn\"\n+  [(unspec_volatile [(match_operand:SI 0 \"nonmemory_operand\"  \"r\")] UNSPEC_ARC_SIMD_VRUN)]\n+  \"TARGET_SIMD_SET\"\n+  \"vrun %0\"\n+  [(set_attr \"type\" \"simd_vcontrol\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vrecrun_insn\"\n+  [(unspec_volatile [(match_operand:SI 0 \"nonmemory_operand\"  \"r\")] UNSPEC_ARC_SIMD_VRECRUN)]\n+  \"TARGET_SIMD_SET\"\n+  \"vrecrun %0\"\n+  [(set_attr \"type\" \"simd_vcontrol\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vendrec_insn\"\n+  [(unspec_volatile [(match_operand:SI 0 \"nonmemory_operand\"  \"r\")] UNSPEC_ARC_SIMD_VENDREC)]\n+  \"TARGET_SIMD_SET\"\n+  \"vendrec %S0\"\n+  [(set_attr \"type\" \"simd_vcontrol\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+;; Va, [Ib,u8] instructions\n+;; (define_insn \"vld32wh_insn\"\n+;;   [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+;; \t(vec_concat:V8HI (unspec:V4HI [(match_operand:SI 1 \"immediate_operand\" \"P\")\n+;; \t\t\t\t      (vec_select:HI (match_operand:V8HI 2 \"vector_register_operand\"  \"v\")\n+;; \t\t\t\t\t\t      (parallel [(match_operand:SI 3 \"immediate_operand\" \"L\")]))] UNSPEC_ARC_SIMD_VLD32WH)\n+;; \t\t\t (vec_select:V4HI (match_dup 0)\n+;; \t\t\t\t\t  (parallel[(const_int 0)]))))]\n+;; (define_insn \"vld32wl_insn\"\n+;;   [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+;; \t(unspec:V8HI [(match_operand:SI 1 \"immediate_operand\" \"L\")\n+;; \t\t     (match_operand:SI 2 \"immediate_operand\" \"P\")\n+;; \t\t     (match_operand:V8HI 3 \"vector_register_operand\"  \"v\")\n+;; \t\t     (match_dup 0)] UNSPEC_ARC_SIMD_VLD32WL))]\n+;;   \"TARGET_SIMD_SET\"\n+;;   \"vld32wl %0, [I%1,%2]\"\n+;;   [(set_attr \"length\" \"4\")\n+;;   (set_attr \"cond\" \"nocond\")])\n+(define_insn \"vld32wh_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(vec_concat:V8HI (zero_extend:V4HI (mem:V4QI (plus:SI (match_operand:SI 1 \"immediate_operand\" \"P\")\n+\t\t\t\t\t\t\t      (zero_extend: SI (vec_select:HI (match_operand:V8HI 2 \"vector_register_operand\"  \"v\")\n+\t\t\t\t\t\t\t\t\t\t\t      (parallel [(match_operand:SI 3 \"immediate_operand\" \"L\")]))))))\n+\t\t\t (vec_select:V4HI (match_dup 0)\n+\t\t\t\t\t  (parallel [(const_int 0)]))))]\n+  \"TARGET_SIMD_SET\"\n+  \"vld32wh %0, [i%3,%1]\"\n+  [(set_attr \"type\" \"simd_vload\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vld32wl_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(vec_concat:V8HI (vec_select:V4HI (match_dup 0)\n+\t\t\t\t\t  (parallel [(const_int 1)]))\n+\t\t\t (zero_extend:V4HI (mem:V4QI (plus:SI (match_operand:SI 1 \"immediate_operand\" \"P\")\n+\t\t\t\t\t\t\t      (zero_extend: SI (vec_select:HI (match_operand:V8HI 2 \"vector_register_operand\"  \"v\")\n+\t\t\t\t\t\t\t\t\t\t\t      (parallel [(match_operand:SI 3 \"immediate_operand\" \"L\")])))))) ))]\n+  \"TARGET_SIMD_SET\"\n+  \"vld32wl %0, [i%3,%1]\"\n+  [(set_attr \"type\" \"simd_vload\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vld64w_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\" \"=v\")\n+\t(zero_extend:V8HI (mem:V4HI (plus:SI (zero_extend:SI (vec_select:HI (match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t\t\t\t\t\t\t    (parallel [(match_operand:SI 2 \"immediate_operand\" \"L\")])))\n+\t\t\t\t\t     (match_operand:SI 3 \"immediate_operand\" \"P\")))))]\n+ \"TARGET_SIMD_SET\"\n+ \"vld64w %0, [i%2, %3]\"\n+ [(set_attr \"type\" \"simd_vload\")\n+  (set_attr \"length\" \"4\")\n+  (set_attr \"cond\" \"nocond\")]\n+)\n+\n+(define_insn \"vld64_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(vec_concat:V8HI (vec_select:V4HI (match_dup 0)\n+\t\t\t\t\t  (parallel [(const_int 1)]))\n+\t\t\t (mem:V4HI (plus:SI (match_operand:SI 1 \"immediate_operand\" \"P\")\n+\t\t\t\t\t    (zero_extend: SI (vec_select:HI (match_operand:V8HI 2 \"vector_register_operand\"  \"v\")\n+\t\t\t\t\t\t\t\t\t    (parallel [(match_operand:SI 3 \"immediate_operand\" \"L\")]))))) ))]\n+  \"TARGET_SIMD_SET\"\n+  \"vld64 %0, [i%3,%1]\"\n+  [(set_attr \"type\" \"simd_vload\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vld32_insn\"\n+  [(set (match_operand:V8HI 0 \"vector_register_operand\"           \"=v\")\n+\t(vec_concat:V8HI (vec_select:V4HI (match_dup 0)\n+\t\t\t\t\t  (parallel [(const_int 1)]))\n+\t\t\t (vec_concat:V4HI  (vec_select:V2HI (match_dup 0)\n+\t\t\t\t\t\t\t    (parallel [(const_int 1)]))\n+\t\t\t\t\t   (mem:V2HI (plus:SI (match_operand:SI 1 \"immediate_operand\" \"P\")\n+\t\t\t\t\t\t\t      (zero_extend: SI (vec_select:HI (match_operand:V8HI 2 \"vector_register_operand\"  \"v\")\n+\t\t\t\t\t\t\t\t\t\t\t      (parallel [(match_operand:SI 3 \"immediate_operand\" \"L\")])))))) ))]\n+  \"TARGET_SIMD_SET\"\n+  \"vld32 %0, [i%3,%1]\"\n+  [(set_attr \"type\" \"simd_vload\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vst16_n_insn\"\n+  [(set  (mem:HI (plus:SI (match_operand:SI 0 \"immediate_operand\" \"P\")\n+\t\t\t  (zero_extend: SI (vec_select:HI (match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t\t\t\t\t  (parallel [(match_operand:SI 2 \"immediate_operand\" \"L\")])))))\n+\t (vec_select:HI (match_operand:V8HI 3 \"vector_register_operand\" \"v\")\n+\t\t\t(parallel [(match_operand:SI 4 \"immediate_operand\" \"L\")])))]\n+ \"TARGET_SIMD_SET\"\n+ \"vst16_%4 %3,[i%2, %0]\"\n+ [(set_attr \"type\" \"simd_vstore\")\n+  (set_attr \"length\" \"4\")\n+  (set_attr \"cond\" \"nocond\")])\n+\n+(define_insn \"vst32_n_insn\"\n+  [(set  (mem:SI (plus:SI (match_operand:SI 0 \"immediate_operand\" \"P\")\n+\t\t\t  (zero_extend: SI (vec_select:HI (match_operand:V8HI 1 \"vector_register_operand\"  \"v\")\n+\t\t\t\t\t\t\t  (parallel [(match_operand:SI 2 \"immediate_operand\" \"L\")])))))\n+\t (vec_select:SI (unspec:V4SI [(match_operand:V8HI 3 \"vector_register_operand\" \"v\")] UNSPEC_ARC_SIMD_VCAST)\n+\t\t\t(parallel [(match_operand:SI 4 \"immediate_operand\" \"L\")])))]\n+ \"TARGET_SIMD_SET\"\n+ \"vst32_%4 %3,[i%2, %0]\"\n+ [(set_attr \"type\" \"simd_vstore\")\n+  (set_attr \"length\" \"4\")\n+  (set_attr \"cond\" \"nocond\")])\n+\n+;; SIMD unit interrupt\n+(define_insn \"vinti_insn\"\n+  [(unspec_volatile [(match_operand:SI 0 \"nonmemory_operand\"  \"L\")] UNSPEC_ARC_SIMD_VINTI)]\n+  \"TARGET_SIMD_SET\"\n+  \"vinti %0\"\n+  [(set_attr \"type\" \"simd_vcontrol\")\n+   (set_attr \"length\" \"4\")\n+   (set_attr \"cond\" \"nocond\")])"}, {"sha": "5ce33b7a8ce3b1e8d7651fbbe64e457c773ac42f", "filename": "gcc/config/arc/t-arc-newlib", "status": "added", "additions": 38, "deletions": 0, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Ft-arc-newlib", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Ft-arc-newlib", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Ft-arc-newlib?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -0,0 +1,38 @@\n+# GCC Makefile fragment for Synopsys DesignWare ARC with newlib.\n+\n+# Copyright (C) 2007-2012 Free Software Foundation, Inc.\n+\n+# This file is part of GCC.\n+\n+# GCC is free software; you can redistribute it and/or modify it under the\n+# terms of the GNU General Public License as published by the Free Software\n+# Foundation; either version 3, or (at your option) any later version.\n+\n+# GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n+# details.\n+\n+# You should have received a copy of the GNU General Public License along\n+# with GCC; see the file COPYING3.  If not see\n+# <http://www.gnu.org/licenses/>.\n+\n+# Selecting -mA5 uses the same functional multilib files/libraries\n+# as get used for -mARC600 aka -mA6.\n+MULTILIB_OPTIONS=mcpu=ARC600/mcpu=ARC601 mmul64/mmul32x16 mnorm\n+MULTILIB_DIRNAMES=arc600 arc601 mul64 mul32x16 norm\n+#\n+# Aliases:\n+MULTILIB_MATCHES  = mcpu?ARC600=mcpu?arc600\n+MULTILIB_MATCHES += mcpu?ARC600=mARC600\n+MULTILIB_MATCHES += mcpu?ARC600=mA6\n+MULTILIB_MATCHES += mcpu?ARC600=mA5\n+MULTILIB_MATCHES += mcpu?ARC600=mno-mpy\n+MULTILIB_MATCHES += mcpu?ARC601=mcpu?arc601\n+MULTILIB_MATCHES += EL=mlittle-endian\n+MULTILIB_MATCHES += EB=mbig-endian\n+#\n+# These don't make sense for the ARC700 default target:\n+MULTILIB_EXCEPTIONS=mmul64* mmul32x16* mnorm*\n+# And neither of the -mmul* options make sense without -mnorm:\n+MULTILIB_EXCLUSIONS=mARC600/mmul64/!mnorm mcpu=ARC601/mmul64/!mnorm mARC600/mmul32x16/!mnorm"}, {"sha": "a08978d20ce6776fa9925ea43e397973f7c64b02", "filename": "gcc/config/arc/t-arc-uClibc", "status": "added", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Ft-arc-uClibc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/526b7aee8fce16aa10a57e35d143b2e4ecb6b72e/gcc%2Fconfig%2Farc%2Ft-arc-uClibc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farc%2Ft-arc-uClibc?ref=526b7aee8fce16aa10a57e35d143b2e4ecb6b72e", "patch": "@@ -0,0 +1,20 @@\n+# GCC Makefile fragment for Synopsys DesignWare ARC with uClibc\n+\n+# Copyright (C) 2007-2012 Free Software Foundation, Inc.\n+\n+# This file is part of GCC.\n+\n+# GCC is free software; you can redistribute it and/or modify it under the\n+# terms of the GNU General Public License as published by the Free Software\n+# Foundation; either version 3, or (at your option) any later version.\n+\n+# GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more\n+# details.\n+\n+# You should have received a copy of the GNU General Public License along\n+# with GCC; see the file COPYING3.  If not see\n+# <http://www.gnu.org/licenses/>.\n+\n+MULTILIB_EXTRA_OPTS = mno-sdata"}]}