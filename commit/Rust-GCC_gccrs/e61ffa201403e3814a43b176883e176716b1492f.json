{"sha": "e61ffa201403e3814a43b176883e176716b1492f", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTYxZmZhMjAxNDAzZTM4MTRhNDNiMTc2ODgzZTE3NjcxNmIxNDkyZg==", "commit": {"author": {"name": "David Malcolm", "email": "dmalcolm@redhat.com", "date": "2021-06-30T13:39:04Z"}, "committer": {"name": "David Malcolm", "email": "dmalcolm@redhat.com", "date": "2021-06-30T14:27:40Z"}, "message": "analyzer: eliminate enum binding_key [PR95006]\n\nI rewrote the way the analyzer's region_model tracks the state of memory\nin GCC 11 (in 808f4dfeb3a95f50f15e71148e5c1067f90a126d), which\nintroduced a store with a binding_map class, mapping binding keys to\nsymbolic values.\n\nThe GCC 11 implementation of binding keys has an enum binding_kind,\nwhich can be \"default\" vs \"direct\"; the idea being that direct\nbindings take priority over default bindings, where the latter could\nbe used to represent e.g. a zero-fill of a buffer, and the former\nexpresses those subregions that have since been touched.\n\nThis doesn't work well: it doesn't express the idea of filling\ndifferent subregions with different values, or a memset that only\ntouches part of a buffer, leading to numerous XFAILs in the memset\ntest cases (and elsewhere).\n\nAs preparatory work towards tracking uninitialized values, this patch\neliminates the enum binding_kind, so that all bindings have\nequal weight; the order in which they happen is all that matters.\nIf a write happens which partially overwrites an existing binding,\nthe new code can partially overwrite a binding, potentially punching a\nhole so that an existing binding is split into two parts.\n\nThe patch adds some new classes:\n- a new \"bits_within_svalue\" symbolic value to support extracting\n  parts of an existing value when its binding is partially clobbered\n- a new \"repeated_svalue\" symbolic value to better express filling\n  a region with repeated copies of a symbolic value (e.g. constant\n  zero)\n- a new \"sized_region\" region to express accessing a subregion\n  with a symbolic size in bytes\nand it rewrites e.g. how memset is implemented, so that we can precisely\ntrack which bits in a region have not been touched.\n\nThat said, the patch doesn't actually implement \"uninitialized\" values;\nI'm saving that for a followup.\n\ngcc/analyzer/ChangeLog:\n\tPR analyzer/95006\n\t* analyzer.h (class repeated_svalue): New forward decl.\n\t(class bits_within_svalue): New forward decl.\n\t(class sized_region): New forward decl.\n\t(get_field_at_bit_offset): New forward decl.\n\t* engine.cc (exploded_graph::get_or_create_node): Validate the\n\tmerged state.\n\t(exploded_graph::maybe_process_run_of_before_supernode_enodes):\n\tValidate the states at each stage.\n\t* program-state.cc (program_state::validate): Validate\n\tm_region_model.\n\t* region-model-impl-calls.cc (region_model::impl_call_memset):\n\tReplace special-case logic for handling constant sizes with\n\ta call to fill_region of a sized_region with the given fill value.\n\t* region-model-manager.cc (maybe_undo_optimize_bit_field_compare):\n\tDrop DK_direct.\n\t(region_model_manager::maybe_fold_sub_svalue):  Fold element-based\n\tsubregions of an initial value into initial values of an element.\n\tFold subvalues of repeated svalues.\n\t(region_model_manager::maybe_fold_repeated_svalue): New.\n\t(region_model_manager::get_or_create_repeated_svalue): New.\n\t(get_bit_range_for_field): New.\n\t(get_byte_range_for_field): New.\n\t(get_field_at_byte_range): New.\n\t(region_model_manager::maybe_fold_bits_within_svalue): New.\n\t(region_model_manager::get_or_create_bits_within): New.\n\t(region_model_manager::get_sized_region): New.\n\t(region_model_manager::log_stats): Update for addition of\n\tm_repeated_values_map, m_bits_within_values_map, and\n\tm_sized_regions.\n\t* region-model.cc (region_model::validate): New.\n\t(region_model::on_assignment): Drop enum binding_kind.\n\t(region_model::get_initial_value_for_global): Likewise.\n\t(region_model::get_rvalue_for_bits): Replace body with call to\n\tget_or_create_bits_within.\n\t(region_model::get_capacity): Handle RK_SIZED.\n\t(region_model::set_value): Drop enum binding_kind.\n\t(region_model::fill_region): New.\n\t(region_model::get_representative_path_var_1): Handle RK_SIZED.\n\t* region-model.h (visitor::visit_repeated_svalue): New.\n\t(visitor::visit_bits_within_svalue): New.\n\t(region_model_manager::get_or_create_repeated_svalue): New decl.\n\t(region_model_manager::get_or_create_bits_within): New decl.\n\t(region_model_manager::get_sized_region): New decl.\n\t(region_model_manager::maybe_fold_repeated_svalue): New decl.\n\t(region_model_manager::maybe_fold_bits_within_svalue): New decl.\n\t(region_model_manager::repeated_values_map_t): New typedef.\n\t(region_model_manager::m_repeated_values_map): New field.\n\t(region_model_manager::bits_within_values_map_t): New typedef.\n\t(region_model_manager::m_bits_within_values_map): New field.\n\t(region_model_manager::m_sized_regions): New field.\n\t(region_model::fill_region): New decl.\n\t* region.cc (region::get_base_region): Handle RK_SIZED.\n\t(region::base_region_p): Likewise.\n\t(region::get_byte_size_sval): New.\n\t(get_field_at_bit_offset): Make non-static.\n\t(region::calc_offset): Move implementation of cases to\n\tget_relative_concrete_offset vfunc implementations.  Handle\n\tRK_SIZED.\n\t(region::get_relative_concrete_offset): New.\n\t(decl_region::get_svalue_for_initializer): Drop enum binding_kind.\n\t(field_region::get_relative_concrete_offset): New, from\n\tregion::calc_offset.\n\t(element_region::get_relative_concrete_offset): Likewise.\n\t(offset_region::get_relative_concrete_offset): Likewise.\n\t(sized_region::accept): New.\n\t(sized_region::dump_to_pp): New.\n\t(sized_region::get_byte_size): New.\n\t(sized_region::get_bit_size): New.\n\t* region.h (enum region_kind): Add RK_SIZED.\n\t(region::dyn_cast_sized_region): New.\n\t(region::get_byte_size): Make virtual.\n\t(region::get_bit_size): Likewise.\n\t(region::get_byte_size_sval): New decl.\n\t(region::get_relative_concrete_offset): New decl.\n\t(field_region::get_relative_concrete_offset): New decl.\n\t(element_region::get_relative_concrete_offset): Likewise.\n\t(offset_region::get_relative_concrete_offset): Likewise.\n\t(class sized_region): New.\n\t* store.cc (binding_kind_to_string): Delete.\n\t(binding_key::make): Drop enum binding_kind.\n\t(binding_key::dump_to_pp): Delete.\n\t(binding_key::cmp_ptrs): Drop enum binding_kind.\n\t(bit_range::contains_p): New.\n\t(byte_range::dump): New.\n\t(byte_range::contains_p): New.\n\t(byte_range::cmp): New.\n\t(concrete_binding::dump_to_pp): Drop enum binding_kind.\n\t(concrete_binding::cmp_ptr_ptr): Likewise.\n\t(symbolic_binding::dump_to_pp): Likewise.\n\t(symbolic_binding::cmp_ptr_ptr): Likewise.\n\t(binding_map::apply_ctor_val_to_range): Likewise.\n\t(binding_map::apply_ctor_pair_to_child_region): Likewise.\n\t(binding_map::get_overlapping_bindings): New.\n\t(binding_map::remove_overlapping_bindings): New.\n\t(binding_cluster::validate): New.\n\t(binding_cluster::bind): Drop enum binding_kind.\n\t(binding_cluster::bind_compound_sval): Likewise.\n\t(binding_cluster::purge_region): Likewise.\n\t(binding_cluster::zero_fill_region): Reimplement in terms of...\n\t(binding_cluster::fill_region): New.\n\t(binding_cluster::mark_region_as_unknown): Drop enum binding_kind.\n\t(binding_cluster::get_binding): Likewise.\n\t(binding_cluster::get_binding_recursive): Likewise.\n\t(binding_cluster::get_any_binding): Likewise.\n\t(binding_cluster::maybe_get_compound_binding): Reimplement.\n\t(binding_cluster::get_overlapping_bindings): Delete.\n\t(binding_cluster::remove_overlapping_bindings): Reimplement in\n\tterms of binding_map::remove_overlapping_bindings.\n\t(binding_cluster::can_merge_p): Update for removal of\n\tenum binding_kind.\n\t(binding_cluster::on_unknown_fncall): Drop enum binding_kind.\n\t(binding_cluster::maybe_get_simple_value): Likewise.\n\t(store_manager::get_concrete_binding): Likewise.\n\t(store_manager::get_symbolic_binding): Likewise.\n\t(store::validate): New.\n\t(store::set_value): Drop enum binding_kind.\n\t(store::zero_fill_region): Reimplement in terms of...\n\t(store::fill_region): New.\n\t(selftest::test_binding_key_overlap): Drop enum binding_kind.\n\t* store.h (enum binding_kind): Delete.\n\t(binding_kind_to_string): Delete decl.\n\t(binding_key::make): Drop enum binding_kind.\n\t(binding_key::dump_to_pp): Make pure virtual.\n\t(binding_key::get_kind): Delete.\n\t(binding_key::mark_deleted): Delete.\n\t(binding_key::mark_empty): Delete.\n\t(binding_key::is_deleted): Delete.\n\t(binding_key::is_empty): Delete.\n\t(binding_key::binding_key): Delete.\n\t(binding_key::impl_hash): Delete.\n\t(binding_key::impl_eq): Delete.\n\t(binding_key::m_kind): Delete.\n\t(bit_range::get_last_bit_offset): New.\n\t(bit_range::contains_p): New.\n\t(byte_range::contains_p): New.\n\t(byte_range::operator==): New.\n\t(byte_range::get_start_byte_offset): New.\n\t(byte_range::get_next_byte_offset): New.\n\t(byte_range::get_last_byte_offset): New.\n\t(byte_range::as_bit_range): New.\n\t(byte_range::cmp): New.\n\t(concrete_binding::concrete_binding): Drop enum binding_kind.\n\t(concrete_binding::hash): Likewise.\n\t(concrete_binding::operator==): Likewise.\n\t(concrete_binding::mark_deleted): New.\n\t(concrete_binding::mark_empty): New.\n\t(concrete_binding::is_deleted): New.\n\t(concrete_binding::is_empty): New.\n\t(default_hash_traits<ana::concrete_binding>::empty_zero_p): Make false.\n\t(symbolic_binding::symbolic_binding): Drop enum binding_kind.\n\t(symbolic_binding::hash): Likewise.\n\t(symbolic_binding::operator==): Likewise.\n\t(symbolic_binding::mark_deleted): New.\n\t(symbolic_binding::mark_empty): New.\n\t(symbolic_binding::is_deleted): New.\n\t(symbolic_binding::is_empty): New.\n\t(binding_map::remove_overlapping_bindings): New decl.\n\t(binding_map::get_overlapping_bindings): New decl.\n\t(binding_cluster::validate): New decl.\n\t(binding_cluster::bind): Drop enum binding_kind.\n\t(binding_cluster::fill_region): New decl.\n\t(binding_cluster::get_binding): Drop enum binding_kind.\n\t(binding_cluster::get_binding_recursive): Likewise.\n\t(binding_cluster::get_overlapping_bindings): Delete.\n\t(store::validate): New decl.\n\t(store::set_value): Drop enum binding_kind.\n\t(store::fill_region): New decl.\n\t(store_manager::get_concrete_binding): Drop enum binding_kind.\n\t(store_manager::get_symbolic_binding): Likewise.\n\t* svalue.cc (svalue::cmp_ptr): Handle SK_REPEATED and\n\tSK_BITS_WITHIN.\n\t(svalue::extract_bit_range): New.\n\t(svalue::maybe_fold_bits_within): New.\n\t(constant_svalue::maybe_fold_bits_within): New.\n\t(unknown_svalue::maybe_fold_bits_within): New.\n\t(unaryop_svalue::maybe_fold_bits_within): New.\n\t(repeated_svalue::repeated_svalue): New.\n\t(repeated_svalue::dump_to_pp): New.\n\t(repeated_svalue::accept): New.\n\t(repeated_svalue::all_zeroes_p): New.\n\t(repeated_svalue::maybe_fold_bits_within): New.\n\t(bits_within_svalue::bits_within_svalue): New.\n\t(bits_within_svalue::dump_to_pp): New.\n\t(bits_within_svalue::maybe_fold_bits_within): New.\n\t(bits_within_svalue::accept): New.\n\t(bits_within_svalue::implicitly_live_p): New.\n\t(compound_svalue::maybe_fold_bits_within): New.\n\t* svalue.h (enum svalue_kind): Add SK_REPEATED and SK_BITS_WITHIN.\n\t(svalue::dyn_cast_repeated_svalue): New.\n\t(svalue::dyn_cast_bits_within_svalue): New.\n\t(svalue::extract_bit_range): New decl.\n\t(svalue::maybe_fold_bits_within): New vfunc decl.\n\t(region_svalue::key_t::mark_empty): Use 2 rather than NULL_TREE.\n\t(region_svalue::key_t::is_empty): Likewise.\n\t(default_hash_traits<region_svalue::key_t>::empty_zero_p): Make false.\n\t(constant_svalue::maybe_fold_bits_within): New.\n\t(unknown_svalue::maybe_fold_bits_within): New.\n\t(poisoned_svalue::key_t::mark_empty): Use 2 rather than NULL_TREE.\n\t(poisoned_svalue::key_t::is_empty): Likewise.\n\t(default_hash_traits<poisoned_svalue::key_t>::empty_zero_p): Make\n\tfalse.\n\t(setjmp_svalue::key_t::mark_empty): Use 2 rather than NULL_TREE.\n\t(setjmp_svalue::key_t::is_empty): Likewise.\n\t(default_hash_traits<setjmp_svalue::key_t>::empty_zero_p): Make\n\tfalse.\n\t(unaryop_svalue::key_t::mark_empty): Use 2 rather than NULL_TREE.\n\t(unaryop_svalue::key_t::is_empty): Likewise.\n\t(unaryop_svalue::maybe_fold_bits_within): New.\n\t(default_hash_traits<unaryop_svalue::key_t>::empty_zero_p): Make\n\tfalse.\n\t(binop_svalue::key_t::mark_empty): Use 2 rather than NULL_TREE.\n\t(binop_svalue::key_t::is_empty): Likewise.\n\t(default_hash_traits<binop_svalue::key_t>::empty_zero_p): Make\n\tfalse.\n\t(sub_svalue::key_t::mark_empty): Use 2 rather than NULL_TREE.\n\t(sub_svalue::key_t::is_empty): Likewise.\n\t(default_hash_traits<sub_svalue::key_t>::empty_zero_p): Make\n\tfalse.\n\t(class repeated_svalue): New.\n\t(is_a_helper <const repeated_svalue *>::test): New.\n\t(struct default_hash_traits<repeated_svalue::key_t>): New.\n\t(class bits_within_svalue): New.\n\t(is_a_helper <const bits_within_svalue *>::test): New.\n\t(struct default_hash_traits<bits_within_svalue::key_t>): New.\n\t(widening_svalue::key_t::mark_empty): Use 2 rather than NULL_TREE.\n\t(widening_svalue::key_t::is_empty): Likewise.\n\t(default_hash_traits<widening_svalue::key_t>::empty_zero_p): Make\n\tfalse.\n\t(compound_svalue::key_t::mark_empty): Use 2 rather than NULL_TREE.\n\t(compound_svalue::key_t::is_empty): Likewise.\n\t(compound_svalue::maybe_fold_bits_within): New.\n\t(default_hash_traits<compound_svalue::key_t>::empty_zero_p): Make\n\tfalse.\n\ngcc/testsuite/ChangeLog:\n\tPR analyzer/95006\n\t* gcc.dg/analyzer/clobbers-1.c: New test.\n\t* gcc.dg/analyzer/clobbers-2.c: New test.\n\t* gcc.dg/analyzer/data-model-1.c (test_26): Mark xfail as fixed.\n\t(test_28): Likewise.\n\t(test_52): Likewise.  Add coverage for end of buffer.\n\t* gcc.dg/analyzer/explode-1.c: Add leak warning.\n\t* gcc.dg/analyzer/memset-1.c (test_3): Mark xfail as fixed.\n\t(test_4): Use char.  Mark xfail as fixed.\n\t(test_6b): New.\n\t(test_7): Mark xfail as fixed.  Add coverage for start of buffer.\n\t(test_8): New.\n\t(test_9): New.\n\t* gcc.dg/analyzer/memset-CVE-2017-18549-1.c: New test.\n\t* gcc.dg/analyzer/symbolic-8.c: New test.\n\nSigned-off-by: David Malcolm <dmalcolm@redhat.com>", "tree": {"sha": "eed00732346b7f48728b1ec86617ce5cd24b741c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/eed00732346b7f48728b1ec86617ce5cd24b741c"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e61ffa201403e3814a43b176883e176716b1492f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e61ffa201403e3814a43b176883e176716b1492f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e61ffa201403e3814a43b176883e176716b1492f", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e61ffa201403e3814a43b176883e176716b1492f/comments", "author": {"login": "davidmalcolm", "id": 1553248, "node_id": "MDQ6VXNlcjE1NTMyNDg=", "avatar_url": "https://avatars.githubusercontent.com/u/1553248?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidmalcolm", "html_url": "https://github.com/davidmalcolm", "followers_url": "https://api.github.com/users/davidmalcolm/followers", "following_url": "https://api.github.com/users/davidmalcolm/following{/other_user}", "gists_url": "https://api.github.com/users/davidmalcolm/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidmalcolm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidmalcolm/subscriptions", "organizations_url": "https://api.github.com/users/davidmalcolm/orgs", "repos_url": "https://api.github.com/users/davidmalcolm/repos", "events_url": "https://api.github.com/users/davidmalcolm/events{/privacy}", "received_events_url": "https://api.github.com/users/davidmalcolm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "davidmalcolm", "id": 1553248, "node_id": "MDQ6VXNlcjE1NTMyNDg=", "avatar_url": "https://avatars.githubusercontent.com/u/1553248?v=4", "gravatar_id": "", "url": "https://api.github.com/users/davidmalcolm", "html_url": "https://github.com/davidmalcolm", "followers_url": "https://api.github.com/users/davidmalcolm/followers", "following_url": "https://api.github.com/users/davidmalcolm/following{/other_user}", "gists_url": "https://api.github.com/users/davidmalcolm/gists{/gist_id}", "starred_url": "https://api.github.com/users/davidmalcolm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/davidmalcolm/subscriptions", "organizations_url": "https://api.github.com/users/davidmalcolm/orgs", "repos_url": "https://api.github.com/users/davidmalcolm/repos", "events_url": "https://api.github.com/users/davidmalcolm/events{/privacy}", "received_events_url": "https://api.github.com/users/davidmalcolm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "63fe82d80dee997b25ca60fa7d1ed07e97930976", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/63fe82d80dee997b25ca60fa7d1ed07e97930976", "html_url": "https://github.com/Rust-GCC/gccrs/commit/63fe82d80dee997b25ca60fa7d1ed07e97930976"}], "stats": {"total": 2702, "additions": 2207, "deletions": 495}, "files": [{"sha": "02830e474bc6b5b524954d9f99f140e438a01288", "filename": "gcc/analyzer/analyzer.h", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fanalyzer.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fanalyzer.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fanalyzer%2Fanalyzer.h?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -46,6 +46,8 @@ class svalue;\n   class unaryop_svalue;\n   class binop_svalue;\n   class sub_svalue;\n+  class repeated_svalue;\n+  class bits_within_svalue;\n   class unmergeable_svalue;\n   class placeholder_svalue;\n   class widening_svalue;\n@@ -60,6 +62,7 @@ class region;\n   class symbolic_region;\n   class element_region;\n   class offset_region;\n+  class sized_region;\n   class cast_region;\n   class field_region;\n   class string_region;\n@@ -147,6 +150,8 @@ typedef offset_int byte_size_t;\n \n extern bool int_size_in_bits (const_tree type, bit_size_t *out);\n \n+extern tree get_field_at_bit_offset (tree record_type, bit_offset_t bit_offset);\n+\n /* The location of a region expressesd as an offset relative to a\n    base region.  */\n "}, {"sha": "4456d9b828bfa4d1a4e858f2fa889a5d063ed3f7", "filename": "gcc/analyzer/engine.cc", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fengine.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fengine.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fanalyzer%2Fengine.cc?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -2275,6 +2275,7 @@ exploded_graph::get_or_create_node (const program_point &point,\n \t  if (pruned_state.can_merge_with_p (existing_state, point,\n \t\t\t\t\t     &merged_state))\n \t    {\n+\t      merged_state.validate (m_ext_state);\n \t      if (logger)\n \t\tlogger->log (\"merging new state with that of EN: %i\",\n \t\t\t     existing_enode->m_index);\n@@ -2794,6 +2795,7 @@ maybe_process_run_of_before_supernode_enodes (exploded_node *enode)\n       items.quick_push (it);\n       const program_state &state = iter_enode->get_state ();\n       program_state *next_state = &it->m_processed_state;\n+      next_state->validate (m_ext_state);\n       const program_point &iter_point = iter_enode->get_point ();\n       if (const superedge *iter_sedge = iter_point.get_from_edge ())\n \t{\n@@ -2807,6 +2809,7 @@ maybe_process_run_of_before_supernode_enodes (exploded_node *enode)\n \t    next_state->m_region_model->update_for_phis\n \t      (snode, last_cfg_superedge, &ctxt);\n \t}\n+      next_state->validate (m_ext_state);\n     }\n \n   /* Attempt to partition the items into a set of merged states.\n@@ -2823,10 +2826,12 @@ maybe_process_run_of_before_supernode_enodes (exploded_node *enode)\n       unsigned iter_merger_idx;\n       FOR_EACH_VEC_ELT (merged_states, iter_merger_idx, merged_state)\n \t{\n+\t  merged_state->validate (m_ext_state);\n \t  program_state merge (m_ext_state);\n \t  if (it_state.can_merge_with_p (*merged_state, next_point, &merge))\n \t    {\n \t      *merged_state = merge;\n+\t      merged_state->validate (m_ext_state);\n \t      it->m_merger_idx = iter_merger_idx;\n \t      if (logger)\n \t\tlogger->log (\"reusing merger state %i for item %i (EN: %i)\","}, {"sha": "6d60c0449ce94e57116d309a56f1d10b2362590b", "filename": "gcc/analyzer/program-state.cc", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fprogram-state.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fprogram-state.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fanalyzer%2Fprogram-state.cc?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -1142,6 +1142,7 @@ program_state::validate (const extrinsic_state &ext_state) const\n #endif\n \n   gcc_assert (m_checker_states.length () == ext_state.get_num_checkers ());\n+  m_region_model->validate ();\n }\n \n static void"}, {"sha": "466d397ec494b0d432d21f5946cf6e977461350c", "filename": "gcc/analyzer/region-model-impl-calls.cc", "status": "modified", "additions": 9, "deletions": 30, "changes": 39, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fregion-model-impl-calls.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fregion-model-impl-calls.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fanalyzer%2Fregion-model-impl-calls.cc?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -389,36 +389,15 @@ region_model::impl_call_memset (const call_details &cd)\n   const region *dest_reg = deref_rvalue (dest_sval, cd.get_arg_tree (0),\n \t\t\t\t\t  cd.get_ctxt ());\n \n-  if (tree num_bytes = num_bytes_sval->maybe_get_constant ())\n-    {\n-      /* \"memset\" of zero size is a no-op.  */\n-      if (zerop (num_bytes))\n-\treturn true;\n-\n-      /* Set with known amount.  */\n-      byte_size_t reg_size;\n-      if (dest_reg->get_byte_size (&reg_size))\n-\t{\n-\t  /* Check for an exact size match.  */\n-\t  if (reg_size == wi::to_offset (num_bytes))\n-\t    {\n-\t      if (tree cst = fill_value_sval->maybe_get_constant ())\n-\t\t{\n-\t\t  if (zerop (cst))\n-\t\t    {\n-\t\t      zero_fill_region (dest_reg);\n-\t\t      return true;\n-\t\t    }\n-\t\t}\n-\t    }\n-\t}\n-    }\n-\n-  check_for_writable_region (dest_reg, cd.get_ctxt ());\n-\n-  /* Otherwise, mark region's contents as unknown.  */\n-  mark_region_as_unknown (dest_reg, cd.get_uncertainty ());\n-  return false;\n+  const svalue *fill_value_u8\n+    = m_mgr->get_or_create_cast (unsigned_char_type_node, fill_value_sval);\n+\n+  const region *sized_dest_reg = m_mgr->get_sized_region (dest_reg,\n+\t\t\t\t\t\t\t  NULL_TREE,\n+\t\t\t\t\t\t\t  num_bytes_sval);\n+  check_for_writable_region (sized_dest_reg, cd.get_ctxt ());\n+  fill_region (sized_dest_reg, fill_value_u8);\n+  return true;\n }\n \n /* Handle the on_call_pre part of \"operator new\".  */"}, {"sha": "55acb90da73e07c6b884a9fe6aac9ca3e0e350bd", "filename": "gcc/analyzer/region-model-manager.cc", "status": "modified", "additions": 307, "deletions": 6, "changes": 313, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fregion-model-manager.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fregion-model-manager.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fanalyzer%2Fregion-model-manager.cc?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -477,7 +477,7 @@ maybe_undo_optimize_bit_field_compare (tree type,\n     bound_bits = bit_range (BITS_PER_UNIT - bits.get_next_bit_offset (),\n \t\t\t    bits.m_size_in_bits);\n   const concrete_binding *conc\n-    = get_store_manager ()->get_concrete_binding (bound_bits, BK_direct);\n+    = get_store_manager ()->get_concrete_binding (bound_bits);\n   const svalue *sval = map.get (conc);\n   if (!sval)\n     return NULL;\n@@ -686,22 +686,38 @@ region_model_manager::maybe_fold_sub_svalue (tree type,\n \t      return get_or_create_cast (type, char_sval);\n \t}\n \n-  /* SUB(INIT(r)).FIELD -> INIT(r.FIELD)\n-     i.e.\n-     Subvalue(InitialValue(R1), FieldRegion(R2, F))\n-       -> InitialValue(FieldRegion(R1, F)).  */\n   if (const initial_svalue *init_sval\n-        = parent_svalue->dyn_cast_initial_svalue ())\n+\t= parent_svalue->dyn_cast_initial_svalue ())\n     {\n+      /* SUB(INIT(r)).FIELD -> INIT(r.FIELD)\n+\t i.e.\n+\t Subvalue(InitialValue(R1), FieldRegion(R2, F))\n+\t -> InitialValue(FieldRegion(R1, F)).  */\n       if (const field_region *field_reg = subregion->dyn_cast_field_region ())\n \t{\n \t  const region *field_reg_new\n \t    = get_field_region (init_sval->get_region (),\n \t\t\t\tfield_reg->get_field ());\n \t  return get_or_create_initial_value (field_reg_new);\n \t}\n+      /* SUB(INIT(r)[ELEMENT] -> INIT(e[ELEMENT])\n+\t i.e.\n+\t Subvalue(InitialValue(R1), ElementRegion(R2, IDX))\n+\t -> InitialValue(ElementRegion(R1, IDX)).  */\n+      if (const element_region *element_reg = subregion->dyn_cast_element_region ())\n+\t{\n+\t  const region *element_reg_new\n+\t    = get_element_region (init_sval->get_region (),\n+\t\t\t\t  element_reg->get_type (),\n+\t\t\t\t  element_reg->get_index ());\n+\t  return get_or_create_initial_value (element_reg_new);\n+\t}\n     }\n \n+  if (const repeated_svalue *repeated_sval\n+\t= parent_svalue->dyn_cast_repeated_svalue ())\n+    return get_or_create_cast (type, repeated_sval->get_inner_svalue ());\n+\n   return NULL;\n }\n \n@@ -727,6 +743,255 @@ region_model_manager::get_or_create_sub_svalue (tree type,\n   return sub_sval;\n }\n \n+/* Subroutine of region_model_manager::get_or_create_repeated_svalue.\n+   Return a folded svalue, or NULL.  */\n+\n+const svalue *\n+region_model_manager::maybe_fold_repeated_svalue (tree type,\n+\t\t\t\t\t\t  const svalue *outer_size,\n+\t\t\t\t\t\t  const svalue *inner_svalue)\n+{\n+  /* If INNER_SVALUE is the same size as OUTER_SIZE,\n+     turn into simply a cast.  */\n+  if (tree cst_outer_num_bytes = outer_size->maybe_get_constant ())\n+    {\n+      HOST_WIDE_INT num_bytes_inner_svalue\n+\t= int_size_in_bytes (inner_svalue->get_type ());\n+      if (num_bytes_inner_svalue != -1)\n+\tif (num_bytes_inner_svalue\n+\t    == (HOST_WIDE_INT)tree_to_uhwi (cst_outer_num_bytes))\n+\t  {\n+\t    if (type)\n+\t      return get_or_create_cast (type, inner_svalue);\n+\t    else\n+\t      return inner_svalue;\n+\t  }\n+    }\n+\n+  /* Handle zero-fill of a specific type.  */\n+  if (tree cst = inner_svalue->maybe_get_constant ())\n+    if (zerop (cst) && type)\n+      return get_or_create_cast (type, inner_svalue);\n+\n+  return NULL;\n+}\n+\n+/* Return the svalue * of type TYPE in which INNER_SVALUE is repeated\n+   enough times to be of size OUTER_SIZE, creating it if necessary.\n+   e.g. for filling buffers with a constant value.  */\n+\n+const svalue *\n+region_model_manager::get_or_create_repeated_svalue (tree type,\n+\t\t\t\t\t\t     const svalue *outer_size,\n+\t\t\t\t\t\t     const svalue *inner_svalue)\n+{\n+  if (const svalue *folded\n+\t= maybe_fold_repeated_svalue (type, outer_size, inner_svalue))\n+    return folded;\n+\n+  repeated_svalue::key_t key (type, outer_size, inner_svalue);\n+  if (repeated_svalue **slot = m_repeated_values_map.get (key))\n+    return *slot;\n+  repeated_svalue *repeated_sval\n+    = new repeated_svalue (type, outer_size, inner_svalue);\n+  RETURN_UNKNOWN_IF_TOO_COMPLEX (repeated_sval);\n+  m_repeated_values_map.put (key, repeated_sval);\n+  return repeated_sval;\n+}\n+\n+/* Attempt to get the bit_range for FIELD within a RECORD_TYPE.\n+   Return true and write the result to OUT if successful.\n+   Return false otherwise.  */\n+\n+static bool\n+get_bit_range_for_field (tree field, bit_range *out)\n+{\n+  bit_size_t bit_size;\n+  if (!int_size_in_bits (TREE_TYPE (field), &bit_size))\n+    return false;\n+  int field_bit_offset = int_bit_position (field);\n+  *out = bit_range (field_bit_offset, bit_size);\n+  return true;\n+}\n+\n+/* Attempt to get the byte_range for FIELD within a RECORD_TYPE.\n+   Return true and write the result to OUT if successful.\n+   Return false otherwise.  */\n+\n+static bool\n+get_byte_range_for_field (tree field, byte_range *out)\n+{\n+  bit_range field_bits (0, 0);\n+  if (!get_bit_range_for_field (field, &field_bits))\n+    return false;\n+  return field_bits.as_byte_range (out);\n+}\n+\n+/* Attempt to determine if there is a specific field within RECORD_TYPE\n+   at BYTES.  If so, return it, and write the location of BYTES relative\n+   to the field to *OUT_RANGE_WITHIN_FIELD.\n+   Otherwise, return NULL_TREE.\n+   For example, given:\n+     struct foo { uint32 a; uint32; b};\n+   and\n+     bytes = {bytes 6-7} (of foo)\n+   we have bytes 3-4 of field b.  */\n+\n+static tree\n+get_field_at_byte_range (tree record_type, const byte_range &bytes,\n+\t\t\t byte_range *out_range_within_field)\n+{\n+  bit_offset_t bit_offset = bytes.m_start_byte_offset * BITS_PER_UNIT;\n+\n+  tree field = get_field_at_bit_offset (record_type, bit_offset);\n+  if (!field)\n+    return NULL_TREE;\n+\n+  byte_range field_bytes (0,0);\n+  if (!get_byte_range_for_field (field, &field_bytes))\n+    return NULL_TREE;\n+\n+  /* Is BYTES fully within field_bytes?  */\n+  byte_range bytes_within_field (0,0);\n+  if (!field_bytes.contains_p (bytes, &bytes_within_field))\n+    return NULL_TREE;\n+\n+  *out_range_within_field = bytes_within_field;\n+  return field;\n+}\n+\n+/* Subroutine of region_model_manager::get_or_create_bits_within.\n+   Return a folded svalue, or NULL.  */\n+\n+const svalue *\n+region_model_manager::maybe_fold_bits_within_svalue (tree type,\n+\t\t\t\t\t\t     const bit_range &bits,\n+\t\t\t\t\t\t     const svalue *inner_svalue)\n+{\n+  tree inner_type = inner_svalue->get_type ();\n+  /* Fold:\n+       BITS_WITHIN ((0, sizeof (VAL), VAL))\n+     to:\n+       CAST(TYPE, VAL).  */\n+  if (bits.m_start_bit_offset == 0 && inner_type)\n+    {\n+      bit_size_t inner_type_size;\n+      if (int_size_in_bits (inner_type, &inner_type_size))\n+\tif (inner_type_size == bits.m_size_in_bits)\n+\t  {\n+\t    if (type)\n+\t      return get_or_create_cast (type, inner_svalue);\n+\t    else\n+\t      return inner_svalue;\n+\t  }\n+    }\n+\n+  /* Kind-specific folding.  */\n+  if (const svalue *sval\n+      = inner_svalue->maybe_fold_bits_within (type, bits, this))\n+    return sval;\n+\n+  byte_range bytes (0,0);\n+  if (bits.as_byte_range (&bytes) && inner_type)\n+    switch (TREE_CODE (inner_type))\n+      {\n+      default:\n+\tbreak;\n+      case ARRAY_TYPE:\n+\t{\n+\t  /* Fold:\n+\t       BITS_WITHIN (range, KIND(REG))\n+\t     to:\n+\t       BITS_WITHIN (range - offsetof(ELEMENT), KIND(REG.ELEMENT))\n+\t     if range1 is a byte-range fully within one ELEMENT.  */\n+\t  tree element_type = TREE_TYPE (inner_type);\n+\t  HOST_WIDE_INT element_byte_size\n+\t    = int_size_in_bytes (element_type);\n+\t  if (element_byte_size > 0)\n+\t    {\n+\t      HOST_WIDE_INT start_idx\n+\t\t= (bytes.get_start_byte_offset ().to_shwi ()\n+\t\t   / element_byte_size);\n+\t      HOST_WIDE_INT last_idx\n+\t\t= (bytes.get_last_byte_offset ().to_shwi ()\n+\t\t   / element_byte_size);\n+\t      if (start_idx == last_idx)\n+\t\t{\n+\t\t  if (const initial_svalue *initial_sval\n+\t\t      = inner_svalue->dyn_cast_initial_svalue ())\n+\t\t    {\n+\t\t      bit_offset_t start_of_element\n+\t\t\t= start_idx * element_byte_size * BITS_PER_UNIT;\n+\t\t      bit_range bits_within_element\n+\t\t\t(bits.m_start_bit_offset - start_of_element,\n+\t\t\t bits.m_size_in_bits);\n+\t\t      const svalue *idx_sval\n+\t\t\t= get_or_create_int_cst (integer_type_node, start_idx);\n+\t\t      const region *element_reg =\n+\t\t\tget_element_region (initial_sval->get_region (),\n+\t\t\t\t\t    element_type, idx_sval);\n+\t\t      const svalue *element_reg_sval\n+\t\t\t= get_or_create_initial_value (element_reg);\n+\t\t      return get_or_create_bits_within (type,\n+\t\t\t\t\t\t\tbits_within_element,\n+\t\t\t\t\t\t\telement_reg_sval);\n+\t\t    }\n+\t\t}\n+\t    }\n+\t}\n+\tbreak;\n+      case RECORD_TYPE:\n+\t{\n+\t  /* Fold:\n+\t       BYTES_WITHIN (range, KIND(REG))\n+\t     to:\n+\t       BYTES_WITHIN (range - offsetof(FIELD), KIND(REG.FIELD))\n+\t     if range1 is fully within FIELD.  */\n+\t  byte_range bytes_within_field (0, 0);\n+\t  if (tree field = get_field_at_byte_range (inner_type, bytes,\n+\t\t\t\t\t\t    &bytes_within_field))\n+\t    {\n+\t      if (const initial_svalue *initial_sval\n+\t\t  = inner_svalue->dyn_cast_initial_svalue ())\n+\t\t{\n+\t\t  const region *field_reg =\n+\t\t    get_field_region (initial_sval->get_region (), field);\n+\t\t  const svalue *initial_reg_sval\n+\t\t    = get_or_create_initial_value (field_reg);\n+\t\t  return get_or_create_bits_within\n+\t\t    (type,\n+\t\t     bytes_within_field.as_bit_range (),\n+\t\t     initial_reg_sval);\n+\t\t}\n+\t    }\n+\t}\n+\tbreak;\n+      }\n+  return NULL;\n+}\n+\n+/* Return the svalue * of type TYPE for extracting BITS from INNER_SVALUE,\n+   creating it if necessary.  */\n+\n+const svalue *\n+region_model_manager::get_or_create_bits_within (tree type,\n+\t\t\t\t\t\t const bit_range &bits,\n+\t\t\t\t\t\t const svalue *inner_svalue)\n+{\n+  if (const svalue *folded\n+\t= maybe_fold_bits_within_svalue (type, bits, inner_svalue))\n+    return folded;\n+\n+  bits_within_svalue::key_t key (type, bits, inner_svalue);\n+  if (bits_within_svalue **slot = m_bits_within_values_map.get (key))\n+    return *slot;\n+  bits_within_svalue *bits_within_sval\n+    = new bits_within_svalue (type, bits, inner_svalue);\n+  RETURN_UNKNOWN_IF_TOO_COMPLEX (bits_within_sval);\n+  m_bits_within_values_map.put (key, bits_within_sval);\n+  return bits_within_sval;\n+}\n+\n /* Return the svalue * that decorates ARG as being unmergeable,\n    creating it if necessary.  */\n \n@@ -966,6 +1231,38 @@ region_model_manager::get_offset_region (const region *parent,\n   return offset_reg;\n }\n \n+/* Return the region that describes accessing the subregion of type\n+   TYPE of size BYTE_SIZE_SVAL within PARENT, creating it if necessary.  */\n+\n+const region *\n+region_model_manager::get_sized_region (const region *parent,\n+\t\t\t\t\ttree type,\n+\t\t\t\t\tconst svalue *byte_size_sval)\n+{\n+  if (byte_size_sval->get_type () != size_type_node)\n+    byte_size_sval = get_or_create_cast (size_type_node, byte_size_sval);\n+\n+  /* If PARENT is already that size, return it.  */\n+  const svalue *parent_byte_size_sval = parent->get_byte_size_sval (this);\n+  if (tree parent_size_cst = parent_byte_size_sval->maybe_get_constant ())\n+    if (tree size_cst = byte_size_sval->maybe_get_constant ())\n+      {\n+\ttree comparison\n+\t  = fold_binary (EQ_EXPR, boolean_type_node, parent_size_cst, size_cst);\n+\tif (comparison == boolean_true_node)\n+\t  return parent;\n+      }\n+\n+  sized_region::key_t key (parent, type, byte_size_sval);\n+  if (sized_region *reg = m_sized_regions.get (key))\n+    return reg;\n+\n+  sized_region *sized_reg\n+    = new sized_region (alloc_region_id (), parent, type, byte_size_sval);\n+  m_sized_regions.put (key, sized_reg);\n+  return sized_reg;\n+}\n+\n /* Return the region that describes accessing PARENT_REGION as if\n    it were of type TYPE, creating it if necessary.  */\n \n@@ -1180,6 +1477,9 @@ region_model_manager::log_stats (logger *logger, bool show_objs) const\n   log_uniq_map (logger, show_objs, \"unaryop_svalue\", m_unaryop_values_map);\n   log_uniq_map (logger, show_objs, \"binop_svalue\", m_binop_values_map);\n   log_uniq_map (logger, show_objs, \"sub_svalue\", m_sub_values_map);\n+  log_uniq_map (logger, show_objs, \"repeated_svalue\", m_repeated_values_map);\n+  log_uniq_map (logger, show_objs, \"bits_within_svalue\",\n+\t\tm_bits_within_values_map);\n   log_uniq_map (logger, show_objs, \"unmergeable_svalue\",\n \t\tm_unmergeable_values_map);\n   log_uniq_map (logger, show_objs, \"widening_svalue\", m_widening_values_map);\n@@ -1198,6 +1498,7 @@ region_model_manager::log_stats (logger *logger, bool show_objs) const\n   log_uniq_map (logger, show_objs, \"field_region\", m_field_regions);\n   log_uniq_map (logger, show_objs, \"element_region\", m_element_regions);\n   log_uniq_map (logger, show_objs, \"offset_region\", m_offset_regions);\n+  log_uniq_map (logger, show_objs, \"sized_region\", m_sized_regions);\n   log_uniq_map (logger, show_objs, \"cast_region\", m_cast_regions);\n   log_uniq_map (logger, show_objs, \"frame_region\", m_frame_regions);\n   log_uniq_map (logger, show_objs, \"symbolic_region\", m_symbolic_regions);"}, {"sha": "4fb6bc9f747088ae65e484079334b9cdce0c92c3", "filename": "gcc/analyzer/region-model.cc", "status": "modified", "additions": 27, "deletions": 45, "changes": 72, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fregion-model.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fregion-model.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fanalyzer%2Fregion-model.cc?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -393,6 +393,14 @@ region_model::debug () const\n   dump (true);\n }\n \n+/* Assert that this object is valid.  */\n+\n+void\n+region_model::validate () const\n+{\n+  m_store.validate ();\n+}\n+\n /* Canonicalize the store and constraints, to maximize the chance of\n    equality between region_model instances.  */\n \n@@ -847,11 +855,9 @@ region_model::on_assignment (const gassign *assign, region_model_context *ctxt)\n     case STRING_CST:\n       {\n \t/* e.g. \"struct s2 x = {{'A', 'B', 'C', 'D'}};\".  */\n-\t/* Add a default binding, rather than a direct one, so that array\n-\t   access will \"inherit\" the individual chars.  */\n \tconst svalue *rhs_sval = get_rvalue (rhs1, ctxt);\n \tm_store.set_value (m_mgr->get_store_manager(), lhs_reg, rhs_sval,\n-\t\t\t   BK_default, ctxt ? ctxt->get_uncertainty () : NULL);\n+\t\t\t   ctxt ? ctxt->get_uncertainty () : NULL);\n       }\n       break;\n     }\n@@ -1662,8 +1668,7 @@ region_model::get_initial_value_for_global (const region *reg) const\n \t    {\n \t      /* Get the value for REG within base_reg_init.  */\n \t      binding_cluster c (base_reg);\n-\t      c.bind (m_mgr->get_store_manager (), base_reg, base_reg_init,\n-\t\t      BK_direct);\n+\t      c.bind (m_mgr->get_store_manager (), base_reg, base_reg_init);\n \t      const svalue *sval\n \t\t= c.get_any_binding (m_mgr->get_store_manager (), reg);\n \t      if (sval)\n@@ -1854,45 +1859,7 @@ region_model::get_rvalue_for_bits (tree type,\n \t\t\t\t   const bit_range &bits) const\n {\n   const svalue *sval = get_store_value (reg);\n-  if (const compound_svalue *compound_sval = sval->dyn_cast_compound_svalue ())\n-    {\n-      const binding_map &map = compound_sval->get_map ();\n-      binding_map result_map;\n-      for (auto iter : map)\n-\t{\n-\t  const binding_key *key = iter.first;\n-\t  if (const concrete_binding *conc_key\n-\t      = key->dyn_cast_concrete_binding ())\n-\t    {\n-\t      /* Ignore concrete bindings outside BITS.  */\n-\t      if (!conc_key->get_bit_range ().intersects_p (bits))\n-\t\tcontinue;\n-\t      if ((conc_key->get_start_bit_offset ()\n-\t\t   < bits.get_start_bit_offset ())\n-\t\t  || (conc_key->get_next_bit_offset ()\n-\t\t      > bits.get_next_bit_offset ()))\n-\t\t{\n-\t\t  /* If we have any concrete keys that aren't fully within BITS,\n-\t\t     then bail out.  */\n-\t\t  return m_mgr->get_or_create_unknown_svalue (type);\n-\t\t}\n-\t      const concrete_binding *offset_conc_key\n-\t\t    = m_mgr->get_store_manager ()->get_concrete_binding\n-\t\t\t(conc_key->get_start_bit_offset ()\n-\t\t\t   - bits.get_start_bit_offset (),\n-\t\t\t conc_key->get_size_in_bits (),\n-\t\t\t conc_key->get_kind ());\n-\t\t  const svalue *sval = iter.second;\n-\t\t  result_map.put (offset_conc_key, sval);\n-\t    }\n-\t  else\n-\t    /* If we have any symbolic keys we can't get it as bits.  */\n-\t    return m_mgr->get_or_create_unknown_svalue (type);\n-\t}\n-      return m_mgr->get_or_create_compound_svalue (type, result_map);\n-    }\n-\n-  return m_mgr->get_or_create_unknown_svalue (type);\n+  return m_mgr->get_or_create_bits_within (type, bits, sval);\n }\n \n /* A subclass of pending_diagnostic for complaining about writes to\n@@ -2035,6 +2002,10 @@ region_model::get_capacity (const region *reg) const\n \t  }\n       }\n       break;\n+    case RK_SIZED:\n+      /* Look through sized regions to get at the capacity\n+\t of the underlying regions.  */\n+      return get_capacity (reg->get_parent_region ());\n     }\n \n   if (const svalue *recorded = get_dynamic_extents (reg))\n@@ -2056,7 +2027,7 @@ region_model::set_value (const region *lhs_reg, const svalue *rhs_sval,\n   check_for_writable_region (lhs_reg, ctxt);\n \n   m_store.set_value (m_mgr->get_store_manager(), lhs_reg, rhs_sval,\n-\t\t     BK_direct, ctxt ? ctxt->get_uncertainty () : NULL);\n+\t\t     ctxt ? ctxt->get_uncertainty () : NULL);\n }\n \n /* Set the value of the region given by LHS to the value given by RHS.  */\n@@ -2087,6 +2058,14 @@ region_model::purge_region (const region *reg)\n   m_store.purge_region (m_mgr->get_store_manager(), reg);\n }\n \n+/* Fill REG with SVAL.  */\n+\n+void\n+region_model::fill_region (const region *reg, const svalue *sval)\n+{\n+  m_store.fill_region (m_mgr->get_store_manager(), reg, sval);\n+}\n+\n /* Zero-fill REG.  */\n \n void\n@@ -2711,6 +2690,9 @@ region_model::get_representative_path_var_1 (const region *reg,\n \t\t\t parent_pv.m_stack_depth);\n       }\n \n+    case RK_SIZED:\n+      return path_var (NULL_TREE, 0);\n+\n     case RK_CAST:\n       {\n \tpath_var parent_pv"}, {"sha": "b42852b3db9c9de6ec2fc208948e99428720f348", "filename": "gcc/analyzer/region-model.h", "status": "modified", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fregion-model.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fregion-model.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fanalyzer%2Fregion-model.h?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -212,6 +212,8 @@ class visitor\n   virtual void visit_unaryop_svalue (const unaryop_svalue *) {}\n   virtual void visit_binop_svalue (const binop_svalue *) {}\n   virtual void visit_sub_svalue (const sub_svalue *) {}\n+  virtual void visit_repeated_svalue (const repeated_svalue *) {}\n+  virtual void visit_bits_within_svalue (const bits_within_svalue *) {}\n   virtual void visit_unmergeable_svalue (const unmergeable_svalue *) {}\n   virtual void visit_placeholder_svalue (const placeholder_svalue *) {}\n   virtual void visit_widening_svalue (const widening_svalue *) {}\n@@ -255,6 +257,12 @@ class region_model_manager\n   const svalue *get_or_create_sub_svalue (tree type,\n \t\t\t\t\t  const svalue *parent_svalue,\n \t\t\t\t\t  const region *subregion);\n+  const svalue *get_or_create_repeated_svalue (tree type,\n+\t\t\t\t\t       const svalue *outer_size,\n+\t\t\t\t\t       const svalue *inner_svalue);\n+  const svalue *get_or_create_bits_within (tree type,\n+\t\t\t\t\t   const bit_range &bits,\n+\t\t\t\t\t   const svalue *inner_svalue);\n   const svalue *get_or_create_unmergeable (const svalue *arg);\n   const svalue *get_or_create_widening_svalue (tree type,\n \t\t\t\t\t       const program_point &point,\n@@ -286,6 +294,9 @@ class region_model_manager\n   const region *get_offset_region (const region *parent,\n \t\t\t\t   tree type,\n \t\t\t\t   const svalue *byte_offset);\n+  const region *get_sized_region (const region *parent,\n+\t\t\t\t  tree type,\n+\t\t\t\t  const svalue *byte_size_sval);\n   const region *get_cast_region (const region *original_region,\n \t\t\t\t tree type);\n   const frame_region *get_frame_region (const frame_region *calling_frame,\n@@ -321,6 +332,12 @@ class region_model_manager\n   const svalue *maybe_fold_sub_svalue (tree type,\n \t\t\t\t       const svalue *parent_svalue,\n \t\t\t\t       const region *subregion);\n+  const svalue *maybe_fold_repeated_svalue (tree type,\n+\t\t\t\t\t    const svalue *outer_size,\n+\t\t\t\t\t    const svalue *inner_svalue);\n+  const svalue *maybe_fold_bits_within_svalue (tree type,\n+\t\t\t\t\t       const bit_range &bits,\n+\t\t\t\t\t       const svalue *inner_svalue);\n   const svalue *maybe_undo_optimize_bit_field_compare (tree type,\n \t\t\t\t\t\t       const compound_svalue *compound_sval,\n \t\t\t\t\t\t       tree cst, const svalue *arg1);\n@@ -362,6 +379,14 @@ class region_model_manager\n   typedef hash_map<sub_svalue::key_t, sub_svalue *> sub_values_map_t;\n   sub_values_map_t m_sub_values_map;\n \n+  typedef hash_map<repeated_svalue::key_t,\n+\t\t   repeated_svalue *> repeated_values_map_t;\n+  repeated_values_map_t m_repeated_values_map;\n+\n+  typedef hash_map<bits_within_svalue::key_t,\n+\t\t   bits_within_svalue *> bits_within_values_map_t;\n+  bits_within_values_map_t m_bits_within_values_map;\n+\n   typedef hash_map<const svalue *,\n \t\t   unmergeable_svalue *> unmergeable_values_map_t;\n   unmergeable_values_map_t m_unmergeable_values_map;\n@@ -402,6 +427,7 @@ class region_model_manager\n   consolidation_map<field_region> m_field_regions;\n   consolidation_map<element_region> m_element_regions;\n   consolidation_map<offset_region> m_offset_regions;\n+  consolidation_map<sized_region> m_sized_regions;\n   consolidation_map<cast_region> m_cast_regions;\n   consolidation_map<frame_region> m_frame_regions;\n   consolidation_map<symbolic_region> m_symbolic_regions;\n@@ -575,6 +601,7 @@ class region_model\n   void set_value (tree lhs, tree rhs, region_model_context *ctxt);\n   void clobber_region (const region *reg);\n   void purge_region (const region *reg);\n+  void fill_region (const region *reg, const svalue *sval);\n   void zero_fill_region (const region *reg);\n   void mark_region_as_unknown (const region *reg, uncertainty_t *uncertainty);\n "}, {"sha": "46337179162e32268f80edfd3c381d6caba8cf5e", "filename": "gcc/analyzer/region.cc", "status": "modified", "additions": 180, "deletions": 50, "changes": 230, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fregion.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fregion.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fanalyzer%2Fregion.cc?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -98,6 +98,7 @@ region::get_base_region () const\n \tcase RK_FIELD:\n \tcase RK_ELEMENT:\n \tcase RK_OFFSET:\n+\tcase RK_SIZED:\n \t  iter = iter->get_parent_region ();\n \t  continue;\n \tcase RK_CAST:\n@@ -121,6 +122,7 @@ region::base_region_p () const\n     case RK_FIELD:\n     case RK_ELEMENT:\n     case RK_OFFSET:\n+    case RK_SIZED:\n     case RK_CAST:\n       return false;\n \n@@ -188,7 +190,8 @@ region::get_offset () const\n   return *m_cached_offset;\n }\n \n-/* If the size of this region (in bytes) is known statically, write it to *OUT\n+/* Base class implementation of region::get_byte_size vfunc.\n+   If the size of this region (in bytes) is known statically, write it to *OUT\n    and return true.\n    Otherwise return false.  */\n \n@@ -208,8 +211,29 @@ region::get_byte_size (byte_size_t *out) const\n   return true;\n }\n \n-/* If the size of TYPE (in bits) is constant, write it to *OUT\n-   and return true.\n+/* Base implementation of region::get_byte_size_sval vfunc.  */\n+\n+const svalue *\n+region::get_byte_size_sval (region_model_manager *mgr) const\n+{\n+  tree type = get_type ();\n+\n+  /* Bail out e.g. for heap-allocated regions.  */\n+  if (!type)\n+    return mgr->get_or_create_unknown_svalue (size_type_node);\n+\n+  HOST_WIDE_INT bytes = int_size_in_bytes (type);\n+  if (bytes == -1)\n+    return mgr->get_or_create_unknown_svalue (size_type_node);\n+\n+  tree byte_size = size_in_bytes (type);\n+  if (TREE_TYPE (byte_size) != size_type_node)\n+    byte_size = fold_build1 (NOP_EXPR, size_type_node, byte_size);\n+  return mgr->get_or_create_constant_svalue (byte_size);\n+}\n+\n+/* Attempt to get the size of TYPE in bits.\n+   If successful, return true and write the size to *OUT.\n    Otherwise return false.  */\n \n bool\n@@ -249,7 +273,7 @@ region::get_bit_size (bit_size_t *out) const\n \n /* Get the field within RECORD_TYPE at BIT_OFFSET.  */\n \n-static tree\n+tree\n get_field_at_bit_offset (tree record_type, bit_offset_t bit_offset)\n {\n   gcc_assert (TREE_CODE (record_type) == RECORD_TYPE);\n@@ -375,18 +399,10 @@ region::calc_offset () const\n \t      = (const field_region *)iter_region;\n \t    iter_region = iter_region->get_parent_region ();\n \n-\t    /* Compare with e.g. gimple-fold.c's\n-\t       fold_nonarray_ctor_reference.  */\n-\t    tree field = field_reg->get_field ();\n-\t    tree byte_offset = DECL_FIELD_OFFSET (field);\n-\t    if (TREE_CODE (byte_offset) != INTEGER_CST)\n+\t    bit_offset_t rel_bit_offset;\n+\t    if (!field_reg->get_relative_concrete_offset (&rel_bit_offset))\n \t      return region_offset::make_symbolic (iter_region);\n-\t    tree field_offset = DECL_FIELD_BIT_OFFSET (field);\n-\t    /* Compute bit offset of the field.  */\n-\t    offset_int bitoffset\n-\t      = (wi::to_offset (field_offset)\n-\t\t + (wi::to_offset (byte_offset) << LOG2_BITS_PER_UNIT));\n-\t    accum_bit_offset += bitoffset;\n+\t    accum_bit_offset += rel_bit_offset;\n \t  }\n \t  continue;\n \n@@ -396,28 +412,10 @@ region::calc_offset () const\n \t      = (const element_region *)iter_region;\n \t    iter_region = iter_region->get_parent_region ();\n \n-\t    if (tree idx_cst\n-\t\t  = element_reg->get_index ()->maybe_get_constant ())\n-\t      {\n-\t\tgcc_assert (TREE_CODE (idx_cst) == INTEGER_CST);\n-\n-\t\ttree elem_type = element_reg->get_type ();\n-\t\toffset_int element_idx = wi::to_offset (idx_cst);\n-\n-\t\t/* First, use int_size_in_bytes, to reject the case where we\n-\t\t   have an incomplete type, or a non-constant value.  */\n-\t\tHOST_WIDE_INT hwi_byte_size = int_size_in_bytes (elem_type);\n-\t\tif (hwi_byte_size > 0)\n-\t\t  {\n-\t\t    offset_int element_bit_size\n-\t\t      = hwi_byte_size << LOG2_BITS_PER_UNIT;\n-\t\t    offset_int element_bit_offset\n-\t\t      = element_idx * element_bit_size;\n-\t\t    accum_bit_offset += element_bit_offset;\n-\t\t    continue;\n-\t\t  }\n-\t      }\n-\t    return region_offset::make_symbolic (iter_region);\n+\t    bit_offset_t rel_bit_offset;\n+\t    if (!element_reg->get_relative_concrete_offset (&rel_bit_offset))\n+\t      return region_offset::make_symbolic (iter_region);\n+\t    accum_bit_offset += rel_bit_offset;\n \t  }\n \t  continue;\n \n@@ -427,22 +425,17 @@ region::calc_offset () const\n \t      = (const offset_region *)iter_region;\n \t    iter_region = iter_region->get_parent_region ();\n \n-\t    if (tree byte_offset_cst\n-\t\t  = offset_reg->get_byte_offset ()->maybe_get_constant ())\n-\t      {\n-\t\tgcc_assert (TREE_CODE (byte_offset_cst) == INTEGER_CST);\n-\t\t/* Use a signed value for the byte offset, to handle\n-\t\t   negative offsets.  */\n-\t\tHOST_WIDE_INT byte_offset\n-\t\t  = wi::to_offset (byte_offset_cst).to_shwi ();\n-\t\tHOST_WIDE_INT bit_offset = byte_offset * BITS_PER_UNIT;\n-\t\taccum_bit_offset += bit_offset;\n-\t      }\n-\t    else\n+\t    bit_offset_t rel_bit_offset;\n+\t    if (!offset_reg->get_relative_concrete_offset (&rel_bit_offset))\n \t      return region_offset::make_symbolic (iter_region);\n+\t    accum_bit_offset += rel_bit_offset;\n \t  }\n \t  continue;\n \n+\tcase RK_SIZED:\n+\t  iter_region = iter_region->get_parent_region ();\n+\t  continue;\n+\n \tcase RK_CAST:\n \t  {\n \t    const cast_region *cast_reg\n@@ -458,6 +451,14 @@ region::calc_offset () const\n   return region_offset::make_concrete (iter_region, accum_bit_offset);\n }\n \n+/* Base implementation of region::get_relative_concrete_offset vfunc.  */\n+\n+bool\n+region::get_relative_concrete_offset (bit_offset_t *) const\n+{\n+  return false;\n+}\n+\n /* Copy from SRC_REG to DST_REG, using CTXT for any issues that occur.  */\n \n void\n@@ -984,7 +985,7 @@ decl_region::get_svalue_for_initializer (region_model_manager *mgr) const\n \t which can fail if we have a region with unknown size\n \t (e.g. \"extern const char arr[];\").  */\n       const binding_key *binding\n-\t= binding_key::make (mgr->get_store_manager (), this, BK_direct);\n+\t= binding_key::make (mgr->get_store_manager (), this);\n       if (binding->symbolic_p ())\n \treturn NULL;\n \n@@ -1030,6 +1031,26 @@ field_region::dump_to_pp (pretty_printer *pp, bool simple) const\n     }\n }\n \n+/* Implementation of region::get_relative_concrete_offset vfunc\n+   for field_region.  */\n+\n+bool\n+field_region::get_relative_concrete_offset (bit_offset_t *out) const\n+{\n+  /* Compare with e.g. gimple-fold.c's\n+     fold_nonarray_ctor_reference.  */\n+  tree byte_offset = DECL_FIELD_OFFSET (m_field);\n+  if (TREE_CODE (byte_offset) != INTEGER_CST)\n+    return false;\n+  tree field_offset = DECL_FIELD_BIT_OFFSET (m_field);\n+  /* Compute bit offset of the field.  */\n+  offset_int bitoffset\n+    = (wi::to_offset (field_offset)\n+       + (wi::to_offset (byte_offset) << LOG2_BITS_PER_UNIT));\n+  *out = bitoffset;\n+  return true;\n+}\n+\n /* class element_region : public region.  */\n \n /* Implementation of region::accept vfunc for element_region.  */\n@@ -1067,6 +1088,35 @@ element_region::dump_to_pp (pretty_printer *pp, bool simple) const\n     }\n }\n \n+/* Implementation of region::get_relative_concrete_offset vfunc\n+   for element_region.  */\n+\n+bool\n+element_region::get_relative_concrete_offset (bit_offset_t *out) const\n+{\n+  if (tree idx_cst = m_index->maybe_get_constant ())\n+    {\n+      gcc_assert (TREE_CODE (idx_cst) == INTEGER_CST);\n+\n+      tree elem_type = get_type ();\n+      offset_int element_idx = wi::to_offset (idx_cst);\n+\n+      /* First, use int_size_in_bytes, to reject the case where we\n+\t have an incomplete type, or a non-constant value.  */\n+      HOST_WIDE_INT hwi_byte_size = int_size_in_bytes (elem_type);\n+      if (hwi_byte_size > 0)\n+\t{\n+\t  offset_int element_bit_size\n+\t    = hwi_byte_size << LOG2_BITS_PER_UNIT;\n+\t  offset_int element_bit_offset\n+\t    = element_idx * element_bit_size;\n+\t  *out = element_bit_offset;\n+\t  return true;\n+\t}\n+    }\n+  return false;\n+}\n+\n /* class offset_region : public region.  */\n \n /* Implementation of region::accept vfunc for offset_region.  */\n@@ -1103,6 +1153,86 @@ offset_region::dump_to_pp (pretty_printer *pp, bool simple) const\n     }\n }\n \n+/* Implementation of region::get_relative_concrete_offset vfunc\n+   for offset_region.  */\n+\n+bool\n+offset_region::get_relative_concrete_offset (bit_offset_t *out) const\n+{\n+  if (tree byte_offset_cst = m_byte_offset->maybe_get_constant ())\n+    {\n+      gcc_assert (TREE_CODE (byte_offset_cst) == INTEGER_CST);\n+      /* Use a signed value for the byte offset, to handle\n+\t negative offsets.  */\n+      HOST_WIDE_INT byte_offset\n+\t= wi::to_offset (byte_offset_cst).to_shwi ();\n+      HOST_WIDE_INT bit_offset = byte_offset * BITS_PER_UNIT;\n+      *out = bit_offset;\n+      return true;\n+    }\n+  return false;\n+}\n+\n+/* class sized_region : public region.  */\n+\n+/* Implementation of region::accept vfunc for sized_region.  */\n+\n+void\n+sized_region::accept (visitor *v) const\n+{\n+  region::accept (v);\n+  m_byte_size_sval->accept (v);\n+}\n+\n+/* Implementation of region::dump_to_pp vfunc for sized_region.  */\n+\n+void\n+sized_region::dump_to_pp (pretty_printer *pp, bool simple) const\n+{\n+  if (simple)\n+    {\n+      pp_string (pp, \"SIZED_REG(\");\n+      get_parent_region ()->dump_to_pp (pp, simple);\n+      pp_string (pp, \", \");\n+      m_byte_size_sval->dump_to_pp (pp, simple);\n+      pp_string (pp, \")\");\n+    }\n+  else\n+    {\n+      pp_string (pp, \"sized_region(\");\n+      get_parent_region ()->dump_to_pp (pp, simple);\n+      pp_string (pp, \", \");\n+      m_byte_size_sval->dump_to_pp (pp, simple);\n+      pp_printf (pp, \")\");\n+    }\n+}\n+\n+/* Implementation of region::get_byte_size vfunc for sized_region.  */\n+\n+bool\n+sized_region::get_byte_size (byte_size_t *out) const\n+{\n+  if (tree cst = m_byte_size_sval->maybe_get_constant ())\n+    {\n+      gcc_assert (TREE_CODE (cst) == INTEGER_CST);\n+      *out = tree_to_uhwi (cst);\n+      return true;\n+    }\n+  return false;\n+}\n+\n+/* Implementation of region::get_bit_size vfunc for sized_region.  */\n+\n+bool\n+sized_region::get_bit_size (bit_size_t *out) const\n+{\n+  byte_size_t byte_size;\n+  if (!get_byte_size (&byte_size))\n+    return false;\n+  *out = byte_size * BITS_PER_UNIT;\n+  return true;\n+}\n+\n /* class cast_region : public region.  */\n \n /* Implementation of region::accept vfunc for cast_region.  */"}, {"sha": "353d5c47b3c8f48e0e90819332f362600c74a77b", "filename": "gcc/analyzer/region.h", "status": "modified", "additions": 123, "deletions": 2, "changes": 125, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fregion.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fregion.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fanalyzer%2Fregion.h?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -43,6 +43,7 @@ enum region_kind\n   RK_FIELD,\n   RK_ELEMENT,\n   RK_OFFSET,\n+  RK_SIZED,\n   RK_CAST,\n   RK_HEAP_ALLOCATED,\n   RK_ALLOCA,\n@@ -70,6 +71,7 @@ enum region_kind\n      field_region (RK_FIELD)\n      element_region (RK_ELEMENT)\n      offset_region (RK_OFFSET)\n+     sized_region (RK_SIZED)\n      cast_region (RK_CAST)\n      heap_allocated_region (RK_HEAP_ALLOCATED)\n      alloca_region (RK_ALLOCA)\n@@ -107,6 +109,8 @@ class region\n   dyn_cast_element_region () const { return NULL; }\n   virtual const offset_region *\n   dyn_cast_offset_region () const { return NULL; }\n+  virtual const sized_region *\n+  dyn_cast_sized_region () const { return NULL; }\n   virtual const cast_region *\n   dyn_cast_cast_region () const { return NULL; }\n   virtual const string_region *\n@@ -138,8 +142,25 @@ class region\n   static int cmp_ptr_ptr (const void *, const void *);\n \n   region_offset get_offset () const;\n-  bool get_byte_size (byte_size_t *out) const;\n-  bool get_bit_size (bit_size_t *out) const;\n+\n+  /* Attempt to get the size of this region as a concrete number of bytes.\n+     If successful, return true and write the size to *OUT.\n+     Otherwise return false.  */\n+  virtual bool get_byte_size (byte_size_t *out) const;\n+\n+  /* Attempt to get the size of this region as a concrete number of bits.\n+     If successful, return true and write the size to *OUT.\n+     Otherwise return false.  */\n+  virtual bool get_bit_size (bit_size_t *out) const;\n+\n+  /* Get a symbolic value describing the size of this region in bytes\n+     (which could be \"unknown\").  */\n+  virtual const svalue *get_byte_size_sval (region_model_manager *mgr) const;\n+\n+  /* Attempt to get the offset in bits of this region relative to its parent.\n+     If successful, return true and write to *OUT.\n+     Otherwise return false.  */\n+  virtual bool get_relative_concrete_offset (bit_offset_t *out) const;\n \n   void\n   get_subregions_for_binding (region_model_manager *mgr,\n@@ -670,6 +691,8 @@ class field_region : public region\n \n   tree get_field () const { return m_field; }\n \n+  bool get_relative_concrete_offset (bit_offset_t *out) const FINAL OVERRIDE;\n+\n private:\n   tree m_field;\n };\n@@ -751,6 +774,9 @@ class element_region : public region\n \n   const svalue *get_index () const { return m_index; }\n \n+  virtual bool\n+  get_relative_concrete_offset (bit_offset_t *out) const FINAL OVERRIDE;\n+\n private:\n   const svalue *m_index;\n };\n@@ -833,6 +859,8 @@ class offset_region : public region\n \n   const svalue *get_byte_offset () const { return m_byte_offset; }\n \n+  bool get_relative_concrete_offset (bit_offset_t *out) const FINAL OVERRIDE;\n+\n private:\n   const svalue *m_byte_offset;\n };\n@@ -855,6 +883,99 @@ template <> struct default_hash_traits<offset_region::key_t>\n \n namespace ana {\n \n+/* A region that is size BYTES_SIZE_SVAL in size within its parent\n+   region (or possibly larger, which would lead to an overflow.  */\n+\n+class sized_region : public region\n+{\n+public:\n+  /* A support class for uniquifying instances of sized_region.  */\n+  struct key_t\n+  {\n+    key_t (const region *parent, tree element_type,\n+\t   const svalue *byte_size_sval)\n+      : m_parent (parent), m_element_type (element_type),\n+\tm_byte_size_sval (byte_size_sval)\n+    {\n+      gcc_assert (byte_size_sval);\n+    }\n+\n+    hashval_t hash () const\n+    {\n+      inchash::hash hstate;\n+      hstate.add_ptr (m_parent);\n+      hstate.add_ptr (m_element_type);\n+      hstate.add_ptr (m_byte_size_sval);\n+      return hstate.end ();\n+    }\n+\n+    bool operator== (const key_t &other) const\n+    {\n+      return (m_parent == other.m_parent\n+\t      && m_element_type == other.m_element_type\n+\t      && m_byte_size_sval == other.m_byte_size_sval);\n+    }\n+\n+    void mark_deleted () { m_byte_size_sval = reinterpret_cast<const svalue *> (1); }\n+    void mark_empty () { m_byte_size_sval = NULL; }\n+    bool is_deleted () const\n+    {\n+      return m_byte_size_sval == reinterpret_cast<const svalue *> (1);\n+    }\n+    bool is_empty () const { return m_byte_size_sval == NULL; }\n+\n+    const region *m_parent;\n+    tree m_element_type;\n+    const svalue *m_byte_size_sval;\n+    const svalue *m_end_offset;\n+  };\n+\n+  sized_region (unsigned id, const region *parent, tree type,\n+\t\tconst svalue *byte_size_sval)\n+  : region (complexity::from_pair (parent, byte_size_sval),\n+\t    id, parent, type),\n+    m_byte_size_sval (byte_size_sval)\n+  {}\n+\n+  enum region_kind get_kind () const FINAL OVERRIDE { return RK_SIZED; }\n+  const sized_region *\n+  dyn_cast_sized_region () const FINAL OVERRIDE { return this; }\n+\n+  void accept (visitor *v) const FINAL OVERRIDE;\n+\n+  void dump_to_pp (pretty_printer *pp, bool simple) const FINAL OVERRIDE;\n+\n+  bool get_byte_size (byte_size_t *out) const FINAL OVERRIDE;\n+  bool get_bit_size (bit_size_t *out) const FINAL OVERRIDE;\n+\n+  const svalue *\n+  get_byte_size_sval (region_model_manager *) const FINAL OVERRIDE\n+  {\n+    return m_byte_size_sval;\n+  }\n+\n+private:\n+  const svalue *m_byte_size_sval;\n+};\n+\n+} // namespace ana\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <const sized_region *>::test (const region *reg)\n+{\n+  return reg->get_kind () == RK_SIZED;\n+}\n+\n+template <> struct default_hash_traits<sized_region::key_t>\n+: public member_function_hash_traits<sized_region::key_t>\n+{\n+  static const bool empty_zero_p = true;\n+};\n+\n+namespace ana {\n+\n /* A region that views another region using a different type.  */\n \n class cast_region : public region"}, {"sha": "a65c7415b1bd2d7d4370243905336e108330b92c", "filename": "gcc/analyzer/store.cc", "status": "modified", "additions": 429, "deletions": 224, "changes": 653, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fstore.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fstore.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fanalyzer%2Fstore.cc?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -118,52 +118,25 @@ uncertainty_t::dump (bool simple) const\n   pp_flush (&pp);\n }\n \n-/* Get a human-readable string for KIND for dumps.  */\n-\n-const char *binding_kind_to_string (enum binding_kind kind)\n-{\n-  switch (kind)\n-    {\n-    default:\n-    case BK_empty:\n-    case BK_deleted:\n-      /* We shouldn't be attempting to print the hash kinds.  */\n-      gcc_unreachable ();\n-    case BK_direct:\n-      return \"direct\";\n-    case BK_default:\n-      return \"default\";\n-    }\n-}\n-\n /* class binding_key.  */\n \n const binding_key *\n-binding_key::make (store_manager *mgr, const region *r,\n-\t\t   enum binding_kind kind)\n+binding_key::make (store_manager *mgr, const region *r)\n {\n   region_offset offset = r->get_offset ();\n   if (offset.symbolic_p ())\n-    return mgr->get_symbolic_binding (r, kind);\n+    return mgr->get_symbolic_binding (r);\n   else\n     {\n       bit_size_t bit_size;\n       if (r->get_bit_size (&bit_size))\n \treturn mgr->get_concrete_binding (offset.get_bit_offset (),\n-\t\t\t\t\t  bit_size, kind);\n+\t\t\t\t\t  bit_size);\n       else\n-\treturn mgr->get_symbolic_binding (r, kind);\n+\treturn mgr->get_symbolic_binding (r);\n     }\n }\n \n-/* Base class implementation of binding_key::dump_to_pp vfunc.  */\n-\n-void\n-binding_key::dump_to_pp (pretty_printer *pp, bool /*simple*/) const\n-{\n-  pp_printf (pp, \"kind: %s\", binding_kind_to_string (m_kind));\n-}\n-\n /* Dump this binding_key to stderr.  */\n \n DEBUG_FUNCTION void\n@@ -204,11 +177,6 @@ binding_key::cmp_ptrs (const void *p1, const void *p2)\n int\n binding_key::cmp (const binding_key *k1, const binding_key *k2)\n {\n-  enum binding_kind kind1 = k1->get_kind ();\n-  enum binding_kind kind2 = k2->get_kind ();\n-  if (kind1 != kind2)\n-    return (int)kind1 - (int)kind2;\n-\n   int concrete1 = k1->concrete_p ();\n   int concrete2 = k2->concrete_p ();\n   if (int concrete_cmp = concrete1 - concrete2)\n@@ -236,7 +204,7 @@ binding_key::cmp (const binding_key *k1, const binding_key *k2)\n     }\n }\n \n-/* struct struct bit_range.  */\n+/* struct bit_range.  */\n \n void\n bit_range::dump_to_pp (pretty_printer *pp) const\n@@ -267,6 +235,24 @@ bit_range::dump () const\n   pp_flush (&pp);\n }\n \n+/* If OTHER is a subset of this, return true and write\n+   to *OUT the relative range of OTHER within this.\n+   Otherwise return false.  */\n+\n+bool\n+bit_range::contains_p (const bit_range &other, bit_range *out) const\n+{\n+  if (contains_p (other.get_start_bit_offset ())\n+      && contains_p (other.get_last_bit_offset ()))\n+    {\n+      out->m_start_bit_offset = other.m_start_bit_offset - m_start_bit_offset;\n+      out->m_size_in_bits = other.m_size_in_bits;\n+      return true;\n+    }\n+  else\n+    return false;\n+}\n+\n int\n bit_range::cmp (const bit_range &br1, const bit_range &br2)\n {\n@@ -371,15 +357,57 @@ byte_range::dump_to_pp (pretty_printer *pp) const\n     }\n }\n \n+/* Dump this object to stderr.  */\n+\n+DEBUG_FUNCTION void\n+byte_range::dump () const\n+{\n+  pretty_printer pp;\n+  pp.buffer->stream = stderr;\n+  dump_to_pp (&pp);\n+  pp_newline (&pp);\n+  pp_flush (&pp);\n+}\n+\n+/* If OTHER is a subset of this, return true and write\n+   to *OUT the relative range of OTHER within this.\n+   Otherwise return false.  */\n+\n+bool\n+byte_range::contains_p (const byte_range &other, byte_range *out) const\n+{\n+  if (contains_p (other.get_start_byte_offset ())\n+      && contains_p (other.get_last_byte_offset ()))\n+    {\n+      out->m_start_byte_offset = other.m_start_byte_offset - m_start_byte_offset;\n+      out->m_size_in_bytes = other.m_size_in_bytes;\n+      return true;\n+    }\n+  else\n+    return false;\n+}\n+\n+/* qsort comparator for byte ranges.  */\n+\n+int\n+byte_range::cmp (const byte_range &br1, const byte_range &br2)\n+{\n+  /* Order first by offset.  */\n+  if (int start_cmp = wi::cmps (br1.m_start_byte_offset,\n+\t\t\t\tbr2.m_start_byte_offset))\n+    return start_cmp;\n+\n+  /* ...then by size.  */\n+  return wi::cmpu (br1.m_size_in_bytes, br2.m_size_in_bytes);\n+}\n+\n /* class concrete_binding : public binding_key.  */\n \n /* Implementation of binding_key::dump_to_pp vfunc for concrete_binding.  */\n \n void\n-concrete_binding::dump_to_pp (pretty_printer *pp, bool simple) const\n+concrete_binding::dump_to_pp (pretty_printer *pp, bool) const\n {\n-  binding_key::dump_to_pp (pp, simple);\n-  pp_string (pp, \", \");\n   m_bit_range.dump_to_pp (pp);\n }\n \n@@ -402,9 +430,6 @@ concrete_binding::cmp_ptr_ptr (const void *p1, const void *p2)\n   const concrete_binding *b1 = *(const concrete_binding * const *)p1;\n   const concrete_binding *b2 = *(const concrete_binding * const *)p2;\n \n-  if (int kind_cmp = b1->get_kind () - b2->get_kind ())\n-    return kind_cmp;\n-\n   return bit_range::cmp (b1->m_bit_range, b2->m_bit_range);\n }\n \n@@ -413,8 +438,8 @@ concrete_binding::cmp_ptr_ptr (const void *p1, const void *p2)\n void\n symbolic_binding::dump_to_pp (pretty_printer *pp, bool simple) const\n {\n-  binding_key::dump_to_pp (pp, simple);\n-  pp_string (pp, \", region: \");\n+  //binding_key::dump_to_pp (pp, simple);\n+  pp_string (pp, \"region: \");\n   m_region->dump_to_pp (pp, simple);\n }\n \n@@ -426,9 +451,6 @@ symbolic_binding::cmp_ptr_ptr (const void *p1, const void *p2)\n   const symbolic_binding *b1 = *(const symbolic_binding * const *)p1;\n   const symbolic_binding *b2 = *(const symbolic_binding * const *)p2;\n \n-  if (int kind_cmp = b1->get_kind () - b2->get_kind ())\n-    return kind_cmp;\n-\n   return region::cmp_ids (b1->get_region (), b2->get_region ());\n }\n \n@@ -777,17 +799,15 @@ binding_map::apply_ctor_val_to_range (const region *parent_reg,\n     return false;\n   bit_offset_t start_bit_offset = min_offset.get_bit_offset ();\n   store_manager *smgr = mgr->get_store_manager ();\n-  const binding_key *max_element_key\n-    = binding_key::make (smgr, max_element, BK_direct);\n+  const binding_key *max_element_key = binding_key::make (smgr, max_element);\n   if (max_element_key->symbolic_p ())\n     return false;\n   const concrete_binding *max_element_ckey\n     = max_element_key->dyn_cast_concrete_binding ();\n   bit_size_t range_size_in_bits\n     = max_element_ckey->get_next_bit_offset () - start_bit_offset;\n   const concrete_binding *range_key\n-    = smgr->get_concrete_binding (start_bit_offset, range_size_in_bits,\n-\t\t\t\t  BK_direct);\n+    = smgr->get_concrete_binding (start_bit_offset, range_size_in_bits);\n   if (range_key->symbolic_p ())\n     return false;\n \n@@ -819,8 +839,7 @@ binding_map::apply_ctor_pair_to_child_region (const region *parent_reg,\n     {\n       const svalue *sval = get_svalue_for_ctor_val (val, mgr);\n       const binding_key *k\n-\t= binding_key::make (mgr->get_store_manager (), child_reg,\n-\t\t\t     BK_direct);\n+\t= binding_key::make (mgr->get_store_manager (), child_reg);\n       /* Handle the case where we have an unknown size for child_reg\n \t (e.g. due to it being a trailing field with incomplete array\n \t type.  */\n@@ -844,14 +863,174 @@ binding_map::apply_ctor_pair_to_child_region (const region *parent_reg,\n \t       - parent_base_offset.get_bit_offset ());\n \t  /* Create a concrete key for the child within the parent.  */\n \t  k = mgr->get_store_manager ()->get_concrete_binding\n-\t    (child_parent_offset, sval_bit_size, BK_direct);\n+\t    (child_parent_offset, sval_bit_size);\n \t}\n       gcc_assert (k->concrete_p ());\n       put (k, sval);\n       return true;\n     }\n }\n \n+/* Populate OUT with all bindings within this map that overlap KEY.  */\n+\n+void\n+binding_map::get_overlapping_bindings (const binding_key *key,\n+\t\t\t\t       auto_vec<const binding_key *> *out)\n+{\n+  for (auto iter : *this)\n+    {\n+      const binding_key *iter_key = iter.first;\n+      if (const concrete_binding *ckey\n+\t    = key->dyn_cast_concrete_binding ())\n+\t{\n+\t  if (const concrete_binding *iter_ckey\n+\t      = iter_key->dyn_cast_concrete_binding ())\n+\t    {\n+\t      if (ckey->overlaps_p (*iter_ckey))\n+\t\tout->safe_push (iter_key);\n+\t    }\n+\t  else\n+\t    {\n+\t      /* Assume overlap.  */\n+\t      out->safe_push (iter_key);\n+\t    }\n+\t}\n+      else\n+\t{\n+\t  /* Assume overlap.  */\n+\t  out->safe_push (iter_key);\n+\t}\n+    }\n+}\n+\n+/* Remove, truncate, and/or split any bindings within this map that\n+   overlap DROP_KEY.\n+\n+   For example, if we have:\n+\n+     +------------------------------------+\n+     |             old binding            |\n+     +------------------------------------+\n+\n+   which is to be overwritten with:\n+\n+     .......+----------------------+.......\n+     .......|      new binding     |.......\n+     .......+----------------------+.......\n+\n+   this function \"cuts a hole\" out of the old binding:\n+\n+     +------+......................+------+\n+     |prefix| hole for new binding |suffix|\n+     +------+......................+------+\n+\n+   into which the new binding can be added without\n+   overlapping the prefix or suffix.\n+\n+   The prefix and suffix (if added) will be bound to the pertinent\n+   parts of the value of the old binding.\n+\n+   For example, given:\n+     struct s5\n+     {\n+       char arr[8];\n+     };\n+     void test_5 (struct s5 *p)\n+     {\n+       struct s5 f = *p;\n+       f.arr[3] = 42;\n+     }\n+   then after the \"f = *p;\" we have:\n+     cluster for: f: INIT_VAL((*INIT_VAL(p_33(D))))\n+   and at the \"f.arr[3] = 42;\" we remove the bindings overlapping\n+   \"f.arr[3]\", replacing it with a prefix (bytes 0-2) and suffix (bytes 4-7)\n+   giving:\n+     cluster for: f\n+       key:   {bytes 0-2}\n+       value:  {BITS_WITHIN(bytes 0-2, inner_val: INIT_VAL((*INIT_VAL(p_33(D))).arr))}\n+       key:   {bytes 4-7}\n+       value:  {BITS_WITHIN(bytes 4-7, inner_val: INIT_VAL((*INIT_VAL(p_33(D))).arr))}\n+   punching a hole into which the new value can be written at byte 3:\n+     cluster for: f\n+       key:   {bytes 0-2}\n+       value:  {BITS_WITHIN(bytes 0-2, inner_val: INIT_VAL((*INIT_VAL(p_33(D))).arr))}\n+       key:   {byte 3}\n+       value: 'char' {(char)42}\n+       key:   {bytes 4-7}\n+       value:  {BITS_WITHIN(bytes 4-7, inner_val: INIT_VAL((*INIT_VAL(p_33(D))).arr))}\n+\n+   If UNCERTAINTY is non-NULL, use it to record any svalues that\n+   were removed, as being maybe-bound.  */\n+\n+void\n+binding_map::remove_overlapping_bindings (store_manager *mgr,\n+\t\t\t\t\t  const binding_key *drop_key,\n+\t\t\t\t\t  uncertainty_t *uncertainty)\n+{\n+  auto_vec<const binding_key *> bindings;\n+  get_overlapping_bindings (drop_key, &bindings);\n+\n+  unsigned i;\n+  const binding_key *iter_binding;\n+  FOR_EACH_VEC_ELT (bindings, i, iter_binding)\n+    {\n+      const svalue *old_sval = get (iter_binding);\n+      if (uncertainty)\n+\tuncertainty->on_maybe_bound_sval (old_sval);\n+\n+      /* Begin by removing the old binding. */\n+      m_map.remove (iter_binding);\n+\n+      /* Now potentially add the prefix and suffix.  */\n+      if (const concrete_binding *drop_ckey\n+\t  = drop_key->dyn_cast_concrete_binding ())\n+\tif (const concrete_binding *iter_ckey\n+\t      = iter_binding->dyn_cast_concrete_binding ())\n+\t  {\n+\t    gcc_assert (drop_ckey->overlaps_p (*iter_ckey));\n+\n+\t    const bit_range &drop_bits = drop_ckey->get_bit_range ();\n+\t    const bit_range &iter_bits = iter_ckey->get_bit_range ();\n+\n+\t    if (iter_bits.get_start_bit_offset ()\n+\t\t  < drop_bits.get_start_bit_offset ())\n+\t      {\n+\t\t/* We have a truncated prefix.  */\n+\t\tbit_range prefix_bits (iter_bits.get_start_bit_offset (),\n+\t\t\t\t       (drop_bits.get_start_bit_offset ()\n+\t\t\t\t\t- iter_bits.get_start_bit_offset ()));\n+\t\tconst concrete_binding *prefix_key\n+\t\t  = mgr->get_concrete_binding (prefix_bits);\n+\t\tbit_range rel_prefix (0, prefix_bits.m_size_in_bits);\n+\t\tconst svalue *prefix_sval\n+\t\t  = old_sval->extract_bit_range (NULL_TREE,\n+\t\t\t\t\t\t rel_prefix,\n+\t\t\t\t\t\t mgr->get_svalue_manager ());\n+\t\tm_map.put (prefix_key, prefix_sval);\n+\t      }\n+\n+\t    if (iter_bits.get_next_bit_offset ()\n+\t\t  > drop_bits.get_next_bit_offset ())\n+\t      {\n+\t\t/* We have a truncated suffix.  */\n+\t\tbit_range suffix_bits (drop_bits.get_next_bit_offset (),\n+\t\t\t\t       (iter_bits.get_next_bit_offset ()\n+\t\t\t\t\t- drop_bits.get_next_bit_offset ()));\n+\t\tconst concrete_binding *suffix_key\n+\t\t  = mgr->get_concrete_binding (suffix_bits);\n+\t\tbit_range rel_suffix (drop_bits.get_next_bit_offset ()\n+\t\t\t\t\t- iter_bits.get_start_bit_offset (),\n+\t\t\t\t      suffix_bits.m_size_in_bits);\n+\t\tconst svalue *suffix_sval\n+\t\t  = old_sval->extract_bit_range (NULL_TREE,\n+\t\t\t\t\t\t rel_suffix,\n+\t\t\t\t\t\t mgr->get_svalue_manager ());\n+\t\tm_map.put (suffix_key, suffix_sval);\n+\t      }\n+\t  }\n+    }\n+}\n+\n /* class binding_cluster.  */\n \n /* binding_cluster's copy ctor.  */\n@@ -964,6 +1143,27 @@ binding_cluster::dump (bool simple) const\n   pp_flush (&pp);\n }\n \n+/* Assert that this object is valid.  */\n+\n+void\n+binding_cluster::validate () const\n+{\n+  int num_symbolic = 0;\n+  int num_concrete = 0;\n+  for (auto iter : m_map)\n+    {\n+      if (iter.first->symbolic_p ())\n+\tnum_symbolic++;\n+      else\n+\tnum_concrete++;\n+    }\n+  /* We shouldn't have more than one symbolic key per cluster\n+     (or one would have clobbered the other).  */\n+  gcc_assert (num_symbolic < 2);\n+  /* We can't have both concrete and symbolic keys.  */\n+  gcc_assert (num_concrete == 0 || num_symbolic == 0);\n+}\n+\n /* Return a new json::object of the form\n    {\"escaped\": true/false,\n     \"touched\": true/false,\n@@ -986,8 +1186,7 @@ binding_cluster::to_json () const\n \n void\n binding_cluster::bind (store_manager *mgr,\n-\t\t       const region *reg, const svalue *sval,\n-\t\t       binding_kind kind)\n+\t\t       const region *reg, const svalue *sval)\n {\n   if (const compound_svalue *compound_sval\n \t= sval->dyn_cast_compound_svalue ())\n@@ -996,7 +1195,7 @@ binding_cluster::bind (store_manager *mgr,\n       return;\n     }\n \n-  const binding_key *binding = binding_key::make (mgr, reg, kind);\n+  const binding_key *binding = binding_key::make (mgr, reg);\n   bind_key (binding, sval);\n }\n \n@@ -1045,8 +1244,7 @@ binding_cluster::bind_compound_sval (store_manager *mgr,\n \t       + reg_offset.get_bit_offset ());\n \t  const concrete_binding *effective_concrete_key\n \t    = mgr->get_concrete_binding (effective_start,\n-\t\t\t\t\t concrete_key->get_size_in_bits (),\n-\t\t\t\t\t iter_key->get_kind ());\n+\t\t\t\t\t concrete_key->get_size_in_bits ());\n \t  bind_key (effective_concrete_key, iter_sval);\n \t}\n       else\n@@ -1069,31 +1267,35 @@ binding_cluster::purge_region (store_manager *mgr, const region *reg)\n {\n   gcc_assert (reg->get_kind () == RK_DECL);\n   const binding_key *binding\n-    = binding_key::make (mgr, const_cast<region *> (reg),\n-\t\t\t BK_direct);\n+    = binding_key::make (mgr, const_cast<region *> (reg));\n   m_map.remove (binding);\n }\n \n-/* Mark REG within this cluster as being filled with zeroes.\n-   Remove all bindings, add a default binding to zero, and clear the\n-   TOUCHED flag.  */\n+/* Clobber REG and fill it with repeated copies of SVAL.  */\n \n void\n-binding_cluster::zero_fill_region (store_manager *mgr, const region *reg)\n+binding_cluster::fill_region (store_manager *mgr,\n+\t\t\t      const region *reg,\n+\t\t\t      const svalue *sval)\n {\n   clobber_region (mgr, reg);\n \n-  /* Add a default binding to zero.  */\n   region_model_manager *sval_mgr = mgr->get_svalue_manager ();\n-  const svalue *cst_sval\n-    = sval_mgr->get_or_create_int_cst (integer_type_node, 0);\n-  const svalue *bound_sval = cst_sval;\n-  if (reg->get_type ())\n-    bound_sval = sval_mgr->get_or_create_unaryop (reg->get_type (), NOP_EXPR,\n-\t\t\t\t\t\t  cst_sval);\n-  bind (mgr, reg, bound_sval, BK_default);\n+  const svalue *byte_size_sval = reg->get_byte_size_sval (sval_mgr);\n+  const svalue *fill_sval\n+    = sval_mgr->get_or_create_repeated_svalue (reg->get_type (),\n+\t\t\t\t\t       byte_size_sval, sval);\n+  bind (mgr, reg, fill_sval);\n+}\n+\n+/* Clobber REG within this cluster and fill it with zeroes.  */\n \n-  m_touched = false;\n+void\n+binding_cluster::zero_fill_region (store_manager *mgr, const region *reg)\n+{\n+  region_model_manager *sval_mgr = mgr->get_svalue_manager ();\n+  const svalue *zero_sval = sval_mgr->get_or_create_int_cst (char_type_node, 0);\n+  fill_region (mgr, reg, zero_sval);\n }\n \n /* Mark REG within this cluster as being unknown.\n@@ -1111,18 +1313,17 @@ binding_cluster::mark_region_as_unknown (store_manager *mgr,\n   region_model_manager *sval_mgr = mgr->get_svalue_manager ();\n   const svalue *sval\n     = sval_mgr->get_or_create_unknown_svalue (reg->get_type ());\n-  bind (mgr, reg, sval, BK_default);\n+  bind (mgr, reg, sval);\n }\n \n /* Get any SVAL bound to REG within this cluster via kind KIND,\n    without checking parent regions of REG.  */\n \n const svalue *\n binding_cluster::get_binding (store_manager *mgr,\n-\t\t\t      const region *reg,\n-\t\t\t      binding_kind kind) const\n+\t\t\t      const region *reg) const\n {\n-  const binding_key *reg_binding = binding_key::make (mgr, reg, kind);\n+  const binding_key *reg_binding = binding_key::make (mgr, reg);\n   const svalue *sval = m_map.get (reg_binding);\n   if (sval)\n     {\n@@ -1140,7 +1341,7 @@ binding_cluster::get_binding (store_manager *mgr,\n       while (const region *parent_reg = reg->get_parent_region ())\n \t{\n \t  const binding_key *parent_reg_binding\n-\t    = binding_key::make (mgr, parent_reg, kind);\n+\t    = binding_key::make (mgr, parent_reg);\n \t  if (parent_reg_binding == reg_binding\n \t      && sval->get_type ()\n \t      && reg->get_type ()\n@@ -1161,29 +1362,28 @@ binding_cluster::get_binding (store_manager *mgr,\n \t  FOR_EACH_VEC_ELT_REVERSE (regions, i, iter_reg)\n \t    {\n \t      region_model_manager *rmm_mgr = mgr->get_svalue_manager ();\n-\t      sval = rmm_mgr->get_or_create_sub_svalue (reg->get_type (),\n+\t      sval = rmm_mgr->get_or_create_sub_svalue (iter_reg->get_type (),\n \t\t\t\t\t\t\tsval, iter_reg);\n \t    }\n \t}\n     }\n   return sval;\n }\n \n-/* Get any SVAL bound to REG within this cluster via kind KIND,\n+/* Get any SVAL bound to REG within this cluster,\n    either directly for REG, or recursively checking for bindings within\n    parent regions and extracting subvalues if need be.  */\n \n const svalue *\n binding_cluster::get_binding_recursive (store_manager *mgr,\n-\t\t\t\t\tconst region *reg,\n-\t\t\t\t\tenum binding_kind kind) const\n+\t\t\t\t\tconst region *reg) const\n {\n-  if (const svalue *sval = get_binding (mgr, reg, kind))\n+  if (const svalue *sval = get_binding (mgr, reg))\n     return sval;\n   if (reg != m_base_region)\n     if (const region *parent_reg = reg->get_parent_region ())\n       if (const svalue *parent_sval\n-\t  = get_binding_recursive (mgr, parent_reg, kind))\n+\t  = get_binding_recursive (mgr, parent_reg))\n \t{\n \t  /* Extract child svalue from parent svalue.  */\n \t  region_model_manager *rmm_mgr = mgr->get_svalue_manager ();\n@@ -1199,18 +1399,11 @@ const svalue *\n binding_cluster::get_any_binding (store_manager *mgr,\n \t\t\t\t  const region *reg) const\n {\n-  /* Look for a \"direct\" binding.  */\n+  /* Look for a direct binding.  */\n   if (const svalue *direct_sval\n-      = get_binding_recursive (mgr, reg, BK_direct))\n+      = get_binding_recursive (mgr, reg))\n     return direct_sval;\n \n-  /* Look for a \"default\" binding, but not if there's been a symbolic\n-     write.  */\n-  if (!m_touched)\n-    if (const svalue *default_sval\n-\t= get_binding_recursive (mgr, reg, BK_default))\n-      return default_sval;\n-\n   /* If this cluster has been touched by a symbolic write, then the content\n      of any subregion not currently specifically bound is \"UNKNOWN\".  */\n   if (m_touched)\n@@ -1251,15 +1444,43 @@ const svalue *\n binding_cluster::maybe_get_compound_binding (store_manager *mgr,\n \t\t\t\t\t     const region *reg) const\n {\n-  binding_map map;\n-\n   region_offset cluster_offset = m_base_region->get_offset ();\n   if (cluster_offset.symbolic_p ())\n     return NULL;\n   region_offset reg_offset = reg->get_offset ();\n   if (reg_offset.symbolic_p ())\n     return NULL;\n \n+  region_model_manager *sval_mgr = mgr->get_svalue_manager ();\n+\n+  /* We will a build the result map in two parts:\n+     (a) result_map, holding the concrete keys from this cluster,\n+\n+     (b) default_map, holding the initial values for the region\n+     (e.g. uninitialized, initializer values, or zero), unless this\n+     cluster has been touched.\n+\n+     We will populate (a), and as we do, clobber (b), trimming and\n+     splitting its bindings as necessary.\n+     Finally, we will merge (b) into (a), giving a concrete map\n+     that merges both the initial values and the bound values from\n+     the binding_cluster.\n+     Doing it this way reduces N for the O(N^2) intersection-finding,\n+     perhaps we should have a spatial-organized data structure for\n+     concrete keys, though.  */\n+\n+  binding_map result_map;\n+  binding_map default_map;\n+\n+  /* Set up default values in default_map.  */\n+  const svalue *default_sval;\n+  if (m_touched)\n+    default_sval = sval_mgr->get_or_create_unknown_svalue (reg->get_type ());\n+  else\n+    default_sval = sval_mgr->get_or_create_initial_value (reg);\n+  const binding_key *default_key = binding_key::make (mgr, reg);\n+  default_map.put (default_key, default_sval);\n+\n   for (map_t::iterator iter = m_map.begin (); iter != m_map.end (); ++iter)\n     {\n       const binding_key *key = (*iter).first;\n@@ -1268,78 +1489,77 @@ binding_cluster::maybe_get_compound_binding (store_manager *mgr,\n       if (const concrete_binding *concrete_key\n \t  = key->dyn_cast_concrete_binding ())\n \t{\n-\t  /* Skip bindings that are outside the bit range of REG.  */\n-\t  if (concrete_key->get_start_bit_offset ()\n-\t      < reg_offset.get_bit_offset ())\n-\t    continue;\n-\t  bit_size_t reg_bit_size;\n-\t  if (reg->get_bit_size (&reg_bit_size))\n-\t    if (concrete_key->get_start_bit_offset ()\n-\t      >= reg_offset.get_bit_offset () + reg_bit_size)\n-\t    continue;\n-\n-\t  /* Get offset of KEY relative to REG, rather than to\n-\t     the cluster.  */\n-\t  bit_offset_t relative_start\n-\t    = (concrete_key->get_start_bit_offset ()\n-\t       - reg_offset.get_bit_offset ());\n-\t  const concrete_binding *offset_concrete_key\n-\t    = mgr->get_concrete_binding (relative_start,\n-\t\t\t\t\t concrete_key->get_size_in_bits (),\n-\t\t\t\t\t key->get_kind ());\n-\t  map.put (offset_concrete_key, sval);\n-\t}\n-      else\n-\treturn NULL;\n-    }\n+\t  const bit_range &bound_range = concrete_key->get_bit_range ();\n \n-  if (map.elements () == 0)\n-    return NULL;\n+\t  bit_size_t reg_bit_size;\n+\t  if (!reg->get_bit_size (&reg_bit_size))\n+\t    return NULL;\n \n-  region_model_manager *sval_mgr = mgr->get_svalue_manager ();\n-  return sval_mgr->get_or_create_compound_svalue (reg->get_type (), map);\n-}\n+\t  bit_range reg_range (reg_offset.get_bit_offset (),\n+\t\t\t       reg_bit_size);\n \n+\t  /* Skip bindings that are outside the bit range of REG.  */\n+\t  if (!bound_range.intersects_p (reg_range))\n+\t    continue;\n \n-/* Populate OUT with all bindings within this cluster that overlap REG.  */\n+\t  /* We shouldn't have an exact match; that should have been\n+\t     handled already.  */\n+\t  gcc_assert (!(reg_range == bound_range));\n \n-void\n-binding_cluster::get_overlapping_bindings (store_manager *mgr,\n-\t\t\t\t\t   const region *reg,\n-\t\t\t\t\t   auto_vec<const binding_key *> *out)\n-{\n-  const binding_key *binding\n-    = binding_key::make (mgr, reg, BK_direct);\n-  for (map_t::iterator iter = m_map.begin ();\n-       iter != m_map.end (); ++iter)\n-    {\n-      const binding_key *iter_key = (*iter).first;\n-      if (const concrete_binding *ckey\n-\t    = binding->dyn_cast_concrete_binding ())\n-\t{\n-\t  if (const concrete_binding *iter_ckey\n-\t      = iter_key->dyn_cast_concrete_binding ())\n+\t  bit_range subrange (0, 0);\n+\t  if (reg_range.contains_p (bound_range, &subrange))\n \t    {\n-\t      if (ckey->overlaps_p (*iter_ckey))\n-\t\tout->safe_push (iter_key);\n+\t      /* We have a bound range fully within REG.\n+\t\t Add it to map, offsetting accordingly.  */\n+\n+\t      /* Get offset of KEY relative to REG, rather than to\n+\t\t the cluster.  */\n+\t      const concrete_binding *offset_concrete_key\n+\t\t= mgr->get_concrete_binding (subrange);\n+\t      result_map.put (offset_concrete_key, sval);\n+\n+\t      /* Clobber default_map, removing/trimming/spliting where\n+\t\t it overlaps with offset_concrete_key.  */\n+\t      default_map.remove_overlapping_bindings (mgr,\n+\t\t\t\t\t\t       offset_concrete_key,\n+\t\t\t\t\t\t       NULL);\n+\t    }\n+\t  else if (bound_range.contains_p (reg_range, &subrange))\n+\t    {\n+\t      /* REG is fully within the bound range, but\n+\t\t is not equal to it; we're extracting a subvalue.  */\n+\t      return sval->extract_bit_range (reg->get_type (),\n+\t\t\t\t\t      subrange,\n+\t\t\t\t\t      mgr->get_svalue_manager ());\n \t    }\n \t  else\n \t    {\n-\t      /* Assume overlap.  */\n-\t      out->safe_push (iter_key);\n+\t      /* REG and the bound range partially overlap.\n+\t\t We don't handle this case yet.  */\n+\t      return NULL;\n \t    }\n \t}\n       else\n-\t{\n-\t  /* Assume overlap.  */\n-\t  out->safe_push (iter_key);\n-\t}\n+\t/* Can't handle symbolic bindings.  */\n+\treturn NULL;\n+    }\n+\n+  if (result_map.elements () == 0)\n+    return NULL;\n+\n+  /* Merge any bindings from default_map into result_map.  */\n+  for (auto iter : default_map)\n+    {\n+      const binding_key *key = iter.first;\n+      const svalue *sval = iter.second;\n+      result_map.put (key, sval);\n     }\n+\n+  return sval_mgr->get_or_create_compound_svalue (reg->get_type (), result_map);\n }\n \n-/* Remove any bindings within this cluster that overlap REG,\n-   but retain default bindings that overlap but aren't fully covered\n-   by REG.\n+/* Remove, truncate, and/or split any bindings within this map that\n+   overlap REG.\n    If UNCERTAINTY is non-NULL, use it to record any svalues that\n    were removed, as being maybe-bound.  */\n \n@@ -1348,26 +1568,9 @@ binding_cluster::remove_overlapping_bindings (store_manager *mgr,\n \t\t\t\t\t      const region *reg,\n \t\t\t\t\t      uncertainty_t *uncertainty)\n {\n-  auto_vec<const binding_key *> bindings;\n-  get_overlapping_bindings (mgr, reg, &bindings);\n+  const binding_key *reg_binding = binding_key::make (mgr, reg);\n \n-  unsigned i;\n-  const binding_key *iter_binding;\n-  FOR_EACH_VEC_ELT (bindings, i, iter_binding)\n-    {\n-      /* Don't remove default bindings, unless the default binding\n-\t is fully covered by REG.  */\n-      if (iter_binding->get_kind () == BK_default)\n-\t{\n-\t  const binding_key *reg_binding\n-\t    = binding_key::make (mgr, reg, BK_default);\n-\t  if (reg_binding != iter_binding)\n-\t    continue;\n-\t}\n-      if (uncertainty)\n-\tuncertainty->on_maybe_bound_sval (m_map.get (iter_binding));\n-      m_map.remove (iter_binding);\n-    }\n+  m_map.remove_overlapping_bindings (mgr, reg_binding, uncertainty);\n }\n \n /* Attempt to merge CLUSTER_A and CLUSTER_B into OUT_CLUSTER, using\n@@ -1428,13 +1631,20 @@ binding_cluster::can_merge_p (const binding_cluster *cluster_a,\n       const binding_key *key_b = (*iter_b).first;\n       keys.add (key_b);\n     }\n+  int num_symbolic_keys = 0;\n+  int num_concrete_keys = 0;\n   for (hash_set<const binding_key *>::iterator iter = keys.begin ();\n        iter != keys.end (); ++iter)\n     {\n       const binding_key *key = *iter;\n       const svalue *sval_a = cluster_a->get_any_value (key);\n       const svalue *sval_b = cluster_b->get_any_value (key);\n \n+      if (key->symbolic_p ())\n+\tnum_symbolic_keys++;\n+      else\n+\tnum_concrete_keys++;\n+\n       if (sval_a == sval_b)\n \t{\n \t  gcc_assert (sval_a);\n@@ -1463,29 +1673,15 @@ binding_cluster::can_merge_p (const binding_cluster *cluster_a,\n       out_cluster->m_map.put (key, unknown_sval);\n     }\n \n-  /* Handle the case where we get a default binding from one and a direct\n-     binding from the other.  */\n-  auto_vec<const concrete_binding *> duplicate_keys;\n-  for (map_t::iterator iter = out_cluster->m_map.begin ();\n-       iter != out_cluster->m_map.end (); ++iter)\n-    {\n-      const concrete_binding *ckey\n-\t= (*iter).first->dyn_cast_concrete_binding ();\n-      if (!ckey)\n-\tcontinue;\n-      if (ckey->get_kind () != BK_direct)\n-\tcontinue;\n-      const concrete_binding *def_ckey\n-\t= mgr->get_concrete_binding (ckey->get_start_bit_offset (),\n-\t\t\t\t     ckey->get_size_in_bits (),\n-\t\t\t\t     BK_default);\n-      if (out_cluster->m_map.get (def_ckey))\n-\tduplicate_keys.safe_push (def_ckey);\n+  /* We can only have at most one symbolic key per cluster,\n+     and if we do, we can't have any concrete keys.\n+     If this happens, mark the cluster as touched, with no keys.  */\n+  if (num_symbolic_keys >= 2\n+      || (num_concrete_keys > 0 && num_symbolic_keys > 0))\n+    {\n+      out_cluster->m_touched = true;\n+      out_cluster->m_map.empty ();\n     }\n-  unsigned i;\n-  const concrete_binding *key;\n-  FOR_EACH_VEC_ELT (duplicate_keys, i, key)\n-    out_cluster->m_map.remove (key);\n \n   /* We don't handle other kinds of overlaps yet.  */\n \n@@ -1558,7 +1754,7 @@ binding_cluster::on_unknown_fncall (const gcall *call,\n       const svalue *sval\n \t= mgr->get_svalue_manager ()->get_or_create_conjured_svalue\n \t    (m_base_region->get_type (), call, m_base_region);\n-      bind (mgr, m_base_region, sval, BK_direct);\n+      bind (mgr, m_base_region, sval);\n \n       m_touched = true;\n     }\n@@ -1665,7 +1861,7 @@ binding_cluster::maybe_get_simple_value (store_manager *mgr) const\n   if (m_map.elements () != 1)\n     return NULL;\n \n-  const binding_key *key = binding_key::make (mgr, m_base_region, BK_direct);\n+  const binding_key *key = binding_key::make (mgr, m_base_region);\n   return get_any_value (key);\n }\n \n@@ -1675,10 +1871,9 @@ binding_cluster::maybe_get_simple_value (store_manager *mgr) const\n \n const concrete_binding *\n store_manager::get_concrete_binding (bit_offset_t start_bit_offset,\n-\t\t\t\t     bit_offset_t size_in_bits,\n-\t\t\t\t     enum binding_kind kind)\n+\t\t\t\t     bit_offset_t size_in_bits)\n {\n-  concrete_binding b (start_bit_offset, size_in_bits, kind);\n+  concrete_binding b (start_bit_offset, size_in_bits);\n   if (concrete_binding *existing = m_concrete_binding_key_mgr.get (b))\n     return existing;\n \n@@ -1688,10 +1883,9 @@ store_manager::get_concrete_binding (bit_offset_t start_bit_offset,\n }\n \n const symbolic_binding *\n-store_manager::get_symbolic_binding (const region *reg,\n-\t\t\t\t     enum binding_kind kind)\n+store_manager::get_symbolic_binding (const region *reg)\n {\n-  symbolic_binding b (reg, kind);\n+  symbolic_binding b (reg);\n   if (symbolic_binding *existing = m_symbolic_binding_key_mgr.get (b))\n     return existing;\n \n@@ -1952,6 +2146,15 @@ store::dump (bool simple) const\n   pp_flush (&pp);\n }\n \n+/* Assert that this object is valid.  */\n+\n+void\n+store::validate () const\n+{\n+  for (auto iter : m_cluster_map)\n+    iter.second->validate ();\n+}\n+\n /* Return a new json::object of the form\n    {PARENT_REGION_DESC: {BASE_REGION_DESC: object for binding_map,\n \t\t\t ... for each cluster within parent region},\n@@ -2027,7 +2230,7 @@ store::get_any_binding (store_manager *mgr, const region *reg) const\n \n void\n store::set_value (store_manager *mgr, const region *lhs_reg,\n-\t\t  const svalue *rhs_sval, enum binding_kind kind,\n+\t\t  const svalue *rhs_sval,\n \t\t  uncertainty_t *uncertainty)\n {\n   remove_overlapping_bindings (mgr, lhs_reg);\n@@ -2054,7 +2257,7 @@ store::set_value (store_manager *mgr, const region *lhs_reg,\n   else\n     {\n       lhs_cluster = get_or_create_cluster (lhs_base_reg);\n-      lhs_cluster->bind (mgr, lhs_reg, rhs_sval, kind);\n+      lhs_cluster->bind (mgr, lhs_reg, rhs_sval);\n     }\n \n   /* Bindings to a cluster can affect other clusters if a symbolic\n@@ -2209,16 +2412,26 @@ store::purge_region (store_manager *mgr, const region *reg)\n     }\n }\n \n-/* Zero-fill REG.  */\n+/* Fill REG with SVAL.  */\n \n void\n-store::zero_fill_region (store_manager *mgr, const region *reg)\n+store::fill_region (store_manager *mgr, const region *reg, const svalue *sval)\n {\n   const region *base_reg = reg->get_base_region ();\n   if (base_reg->symbolic_for_unknown_ptr_p ())\n     return;\n   binding_cluster *cluster = get_or_create_cluster (base_reg);\n-  cluster->zero_fill_region (mgr, reg);\n+  cluster->fill_region (mgr, reg, sval);\n+}\n+\n+/* Zero-fill REG.  */\n+\n+void\n+store::zero_fill_region (store_manager *mgr, const region *reg)\n+{\n+  region_model_manager *sval_mgr = mgr->get_svalue_manager ();\n+  const svalue *zero_sval = sval_mgr->get_or_create_int_cst (char_type_node, 0);\n+  fill_region (mgr, reg, zero_sval);\n }\n \n /* Mark REG as having unknown content.  */\n@@ -2740,26 +2953,18 @@ test_binding_key_overlap ()\n   store_manager mgr (NULL);\n \n   /* Various 8-bit bindings.  */\n-  const concrete_binding *cb_0_7\n-    = mgr.get_concrete_binding (0, 8, BK_direct);\n-  const concrete_binding *cb_8_15\n-    = mgr.get_concrete_binding (8, 8, BK_direct);\n-  const concrete_binding *cb_16_23\n-    = mgr.get_concrete_binding (16, 8, BK_direct);\n-  const concrete_binding *cb_24_31\n-    = mgr.get_concrete_binding (24, 8, BK_direct);\n+  const concrete_binding *cb_0_7 = mgr.get_concrete_binding (0, 8);\n+  const concrete_binding *cb_8_15 = mgr.get_concrete_binding (8, 8);\n+  const concrete_binding *cb_16_23 = mgr.get_concrete_binding (16, 8);\n+  const concrete_binding *cb_24_31 = mgr.get_concrete_binding (24, 8);\n \n   /* 16-bit bindings.  */\n-  const concrete_binding *cb_0_15\n-    = mgr.get_concrete_binding (0, 16, BK_direct);\n-  const concrete_binding *cb_8_23\n-    = mgr.get_concrete_binding (8, 16, BK_direct);\n-  const concrete_binding *cb_16_31\n-    = mgr.get_concrete_binding (16, 16, BK_direct);\n+  const concrete_binding *cb_0_15 = mgr.get_concrete_binding (0, 16);\n+  const concrete_binding *cb_8_23 = mgr.get_concrete_binding (8, 16);\n+  const concrete_binding *cb_16_31 = mgr.get_concrete_binding (16, 16);\n \n   /* 32-bit binding.  */\n-  const concrete_binding *cb_0_31\n-    = mgr.get_concrete_binding (0, 32, BK_direct);\n+  const concrete_binding *cb_0_31 = mgr.get_concrete_binding (0, 32);\n \n   /* Everything should self-overlap.  */\n   ASSERT_OVERLAP (cb_0_7, cb_0_7);"}, {"sha": "2ac2923723dced1d906dd8095b71b49a077a401e", "filename": "gcc/analyzer/store.h", "status": "modified", "additions": 76, "deletions": 81, "changes": 157, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fstore.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fstore.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fanalyzer%2Fstore.h?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -199,29 +199,6 @@ class uncertainty_t\n class byte_range;\n class concrete_binding;\n \n-/* An enum for discriminating between \"direct\" vs \"default\" levels of\n-   mapping.  */\n-\n-enum binding_kind\n-{\n-  /* Special-case value for hash support.\n-     This is the initial entry, so that hash traits can have\n-     empty_zero_p = true.  */\n-  BK_empty = 0,\n-\n-  /* Special-case value for hash support.  */\n-  BK_deleted,\n-\n-  /* The normal kind of mapping.  */\n-  BK_direct,\n-\n-  /* A lower-priority kind of mapping, for use when inheriting\n-     default values from a parent region.  */\n-  BK_default\n-};\n-\n-extern const char *binding_kind_to_string (enum binding_kind kind);\n-\n /* Abstract base class for describing ranges of bits within a binding_map\n    that can have svalues bound to them.  */\n \n@@ -232,10 +209,9 @@ class binding_key\n   virtual bool concrete_p () const = 0;\n   bool symbolic_p () const { return !concrete_p (); }\n \n-  static const binding_key *make (store_manager *mgr, const region *r,\n-\t\t\t\t   enum binding_kind kind);\n+  static const binding_key *make (store_manager *mgr, const region *r);\n \n-  virtual void dump_to_pp (pretty_printer *pp, bool simple) const;\n+  virtual void dump_to_pp (pretty_printer *pp, bool simple) const = 0;\n   void dump (bool simple) const;\n   label_text get_desc (bool simple=true) const;\n \n@@ -244,28 +220,6 @@ class binding_key\n \n   virtual const concrete_binding *dyn_cast_concrete_binding () const\n   { return NULL; }\n-\n-  enum binding_kind get_kind () const { return m_kind; }\n-\n-  void mark_deleted () { m_kind = BK_deleted; }\n-  void mark_empty () { m_kind = BK_empty; }\n-  bool is_deleted () const { return m_kind == BK_deleted; }\n-  bool is_empty () const { return m_kind == BK_empty; }\n-\n-protected:\n-  binding_key (enum binding_kind kind) : m_kind (kind) {}\n-\n-  hashval_t impl_hash () const\n-  {\n-    return m_kind;\n-  }\n-  bool impl_eq (const binding_key &other) const\n-  {\n-    return m_kind == other.m_kind;\n-  }\n-\n-private:\n-  enum binding_kind m_kind;\n };\n \n /* A concrete range of bits.  */\n@@ -288,13 +242,19 @@ struct bit_range\n   {\n     return m_start_bit_offset + m_size_in_bits;\n   }\n+  bit_offset_t get_last_bit_offset () const\n+  {\n+    return get_next_bit_offset () - 1;\n+  }\n \n   bool contains_p (bit_offset_t offset) const\n   {\n     return (offset >= get_start_bit_offset ()\n \t    && offset < get_next_bit_offset ());\n   }\n \n+  bool contains_p (const bit_range &other, bit_range *out) const;\n+\n   bool operator== (const bit_range &other) const\n   {\n     return (m_start_bit_offset == other.m_start_bit_offset\n@@ -327,12 +287,42 @@ struct byte_range\n   {}\n \n   void dump_to_pp (pretty_printer *pp) const;\n+  void dump () const;\n+\n+  bool contains_p (byte_offset_t offset) const\n+  {\n+    return (offset >= get_start_byte_offset ()\n+\t    && offset < get_next_byte_offset ());\n+  }\n+  bool contains_p (const byte_range &other, byte_range *out) const;\n+\n+  bool operator== (const byte_range &other) const\n+  {\n+    return (m_start_byte_offset == other.m_start_byte_offset\n+\t    && m_size_in_bytes == other.m_size_in_bytes);\n+  }\n \n+  byte_offset_t get_start_byte_offset () const\n+  {\n+    return m_start_byte_offset;\n+  }\n+  byte_offset_t get_next_byte_offset () const\n+  {\n+    return m_start_byte_offset + m_size_in_bytes;\n+  }\n   byte_offset_t get_last_byte_offset () const\n   {\n     return m_start_byte_offset + m_size_in_bytes - 1;\n   }\n \n+  bit_range as_bit_range () const\n+  {\n+    return bit_range (m_start_byte_offset * BITS_PER_UNIT,\n+\t\t      m_size_in_bytes * BITS_PER_UNIT);\n+  }\n+\n+  static int cmp (const byte_range &br1, const byte_range &br2);\n+\n   byte_offset_t m_start_byte_offset;\n   byte_size_t m_size_in_bytes;\n };\n@@ -346,10 +336,8 @@ class concrete_binding : public binding_key\n   /* This class is its own key for the purposes of consolidation.  */\n   typedef concrete_binding key_t;\n \n-  concrete_binding (bit_offset_t start_bit_offset, bit_size_t size_in_bits,\n-\t\t    enum binding_kind kind)\n-  : binding_key (kind),\n-    m_bit_range (start_bit_offset, size_in_bits)\n+  concrete_binding (bit_offset_t start_bit_offset, bit_size_t size_in_bits)\n+  : m_bit_range (start_bit_offset, size_in_bits)\n   {}\n   bool concrete_p () const FINAL OVERRIDE { return true; }\n \n@@ -358,12 +346,10 @@ class concrete_binding : public binding_key\n     inchash::hash hstate;\n     hstate.add_wide_int (m_bit_range.m_start_bit_offset);\n     hstate.add_wide_int (m_bit_range.m_size_in_bits);\n-    return hstate.end () ^ binding_key::impl_hash ();\n+    return hstate.end ();\n   }\n   bool operator== (const concrete_binding &other) const\n   {\n-    if (!binding_key::impl_eq (other))\n-      return false;\n     return m_bit_range == other.m_bit_range;\n   }\n \n@@ -392,6 +378,11 @@ class concrete_binding : public binding_key\n \n   static int cmp_ptr_ptr (const void *, const void *);\n \n+  void mark_deleted () { m_bit_range.m_start_bit_offset = -1; }\n+  void mark_empty () { m_bit_range.m_start_bit_offset = -2; }\n+  bool is_deleted () const { return m_bit_range.m_start_bit_offset == -1; }\n+  bool is_empty () const { return m_bit_range.m_start_bit_offset == -2; }\n+\n private:\n   bit_range m_bit_range;\n };\n@@ -401,7 +392,7 @@ class concrete_binding : public binding_key\n template <> struct default_hash_traits<ana::concrete_binding>\n : public member_function_hash_traits<ana::concrete_binding>\n {\n-  static const bool empty_zero_p = true;\n+  static const bool empty_zero_p = false;\n };\n \n namespace ana {\n@@ -415,21 +406,16 @@ class symbolic_binding : public binding_key\n   /* This class is its own key for the purposes of consolidation.  */\n   typedef symbolic_binding key_t;\n \n-  symbolic_binding (const region *region, enum binding_kind kind)\n-  : binding_key (kind),\n-    m_region (region)\n-  {}\n+  symbolic_binding (const region *region) : m_region (region) {}\n   bool concrete_p () const FINAL OVERRIDE { return false; }\n \n   hashval_t hash () const\n   {\n-    return (binding_key::impl_hash () ^ (intptr_t)m_region);\n+    return (intptr_t)m_region;\n   }\n   bool operator== (const symbolic_binding &other) const\n   {\n-    if (!binding_key::impl_eq (other))\n-      return false;\n-    return (m_region == other.m_region);\n+    return m_region == other.m_region;\n   }\n \n   void dump_to_pp (pretty_printer *pp, bool simple) const FINAL OVERRIDE;\n@@ -438,6 +424,12 @@ class symbolic_binding : public binding_key\n \n   static int cmp_ptr_ptr (const void *, const void *);\n \n+  void mark_deleted () { m_region = reinterpret_cast<const region *> (1); }\n+  void mark_empty () { m_region = NULL; }\n+  bool is_deleted () const\n+  { return m_region == reinterpret_cast<const region *> (1); }\n+  bool is_empty () const { return m_region == NULL; }\n+\n private:\n   const region *m_region;\n };\n@@ -504,7 +496,13 @@ class binding_map\n \n   static int cmp (const binding_map &map1, const binding_map &map2);\n \n+  void remove_overlapping_bindings (store_manager *mgr,\n+\t\t\t\t    const binding_key *drop_key,\n+\t\t\t\t    uncertainty_t *uncertainty);\n+\n private:\n+  void get_overlapping_bindings (const binding_key *key,\n+\t\t\t\t auto_vec<const binding_key *> *out);\n   bool apply_ctor_val_to_range (const region *parent_reg,\n \t\t\t\tregion_model_manager *mgr,\n \t\t\t\ttree min_index, tree max_index,\n@@ -553,22 +551,22 @@ class binding_cluster\n   void dump_to_pp (pretty_printer *pp, bool simple, bool multiline) const;\n   void dump (bool simple) const;\n \n+  void validate () const;\n+\n   json::object *to_json () const;\n \n-  void bind (store_manager *mgr, const region *, const svalue *,\n-\t     binding_kind kind);\n+  void bind (store_manager *mgr, const region *, const svalue *);\n \n   void clobber_region (store_manager *mgr, const region *reg);\n   void purge_region (store_manager *mgr, const region *reg);\n+  void fill_region (store_manager *mgr, const region *reg, const svalue *sval);\n   void zero_fill_region (store_manager *mgr, const region *reg);\n   void mark_region_as_unknown (store_manager *mgr, const region *reg,\n \t\t\t       uncertainty_t *uncertainty);\n \n-  const svalue *get_binding (store_manager *mgr, const region *reg,\n-\t\t\t      binding_kind kind) const;\n+  const svalue *get_binding (store_manager *mgr, const region *reg) const;\n   const svalue *get_binding_recursive (store_manager *mgr,\n-\t\t\t\t\tconst region *reg,\n-\t\t\t\t\tenum binding_kind kind) const;\n+\t\t\t\t\tconst region *reg) const;\n   const svalue *get_any_binding (store_manager *mgr,\n \t\t\t\t  const region *reg) const;\n   const svalue *maybe_get_compound_binding (store_manager *mgr,\n@@ -630,8 +628,6 @@ class binding_cluster\n \n private:\n   const svalue *get_any_value (const binding_key *key) const;\n-  void get_overlapping_bindings (store_manager *mgr, const region *reg,\n-\t\t\t\t auto_vec<const binding_key *> *out);\n   void bind_compound_sval (store_manager *mgr,\n \t\t\t   const region *reg,\n \t\t\t   const compound_svalue *compound_sval);\n@@ -684,17 +680,20 @@ class store\n   void dump (bool simple) const;\n   void summarize_to_pp (pretty_printer *pp, bool simple) const;\n \n+  void validate () const;\n+\n   json::object *to_json () const;\n \n   const svalue *get_any_binding (store_manager *mgr, const region *reg) const;\n \n   bool called_unknown_fn_p () const { return m_called_unknown_fn; }\n \n   void set_value (store_manager *mgr, const region *lhs_reg,\n-\t\t  const svalue *rhs_sval, enum binding_kind kind,\n+\t\t  const svalue *rhs_sval,\n \t\t  uncertainty_t *uncertainty);\n   void clobber_region (store_manager *mgr, const region *reg);\n   void purge_region (store_manager *mgr, const region *reg);\n+  void fill_region (store_manager *mgr, const region *reg, const svalue *sval);\n   void zero_fill_region (store_manager *mgr, const region *reg);\n   void mark_region_as_unknown (store_manager *mgr, const region *reg,\n \t\t\t       uncertainty_t *uncertainty);\n@@ -773,19 +772,15 @@ class store_manager\n   /* binding consolidation.  */\n   const concrete_binding *\n   get_concrete_binding (bit_offset_t start_bit_offset,\n-\t\t\tbit_offset_t size_in_bits,\n-\t\t\tenum binding_kind kind);\n+\t\t\tbit_offset_t size_in_bits);\n   const concrete_binding *\n-  get_concrete_binding (const bit_range &bits,\n-\t\t\tenum binding_kind kind)\n+  get_concrete_binding (const bit_range &bits)\n   {\n     return get_concrete_binding (bits.get_start_bit_offset (),\n-\t\t\t\t bits.m_size_in_bits,\n-\t\t\t\t kind);\n+\t\t\t\t bits.m_size_in_bits);\n   }\n   const symbolic_binding *\n-  get_symbolic_binding (const region *region,\n-\t\t\tenum binding_kind kind);\n+  get_symbolic_binding (const region *region);\n \n   region_model_manager *get_svalue_manager () const\n   {"}, {"sha": "6c8afef461ba52c8fbf6aea69efa5ea8b6273477", "filename": "gcc/analyzer/svalue.cc", "status": "modified", "additions": 381, "deletions": 0, "changes": 381, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fsvalue.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fsvalue.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fanalyzer%2Fsvalue.cc?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -415,6 +415,27 @@ svalue::cmp_ptr (const svalue *sval1, const svalue *sval2)\n \t\t\t\tsub_sval2->get_subregion ());\n       }\n       break;\n+    case SK_REPEATED:\n+      {\n+\tconst repeated_svalue *repeated_sval1 = (const repeated_svalue *)sval1;\n+\tconst repeated_svalue *repeated_sval2 = (const repeated_svalue *)sval2;\n+\treturn svalue::cmp_ptr (repeated_sval1->get_inner_svalue (),\n+\t\t\t\trepeated_sval2->get_inner_svalue ());\n+      }\n+      break;\n+    case SK_BITS_WITHIN:\n+      {\n+\tconst bits_within_svalue *bits_within_sval1\n+\t  = (const bits_within_svalue *)sval1;\n+\tconst bits_within_svalue *bits_within_sval2\n+\t  = (const bits_within_svalue *)sval2;\n+\tif (int cmp = bit_range::cmp (bits_within_sval1->get_bits (),\n+\t\t\t\t       bits_within_sval2->get_bits ()))\n+\t  return cmp;\n+\treturn svalue::cmp_ptr (bits_within_sval1->get_inner_svalue (),\n+\t\t\t\tbits_within_sval2->get_inner_svalue ());\n+      }\n+      break;\n     case SK_UNMERGEABLE:\n       {\n \tconst unmergeable_svalue *unmergeable_sval1\n@@ -515,6 +536,27 @@ svalue::involves_p (const svalue *other) const\n   return v.found_p ();\n }\n \n+/* Extract SUBRANGE from this value, of type TYPE.  */\n+\n+const svalue *\n+svalue::extract_bit_range (tree type,\n+\t\t\t   const bit_range &subrange,\n+\t\t\t   region_model_manager *mgr) const\n+{\n+  return mgr->get_or_create_bits_within (type, subrange, this);\n+}\n+\n+/* Base implementation of svalue::maybe_fold_bits_within vfunc.  */\n+\n+const svalue *\n+svalue::maybe_fold_bits_within (tree,\n+\t\t\t\tconst bit_range &,\n+\t\t\t\tregion_model_manager *) const\n+{\n+  /* By default, don't fold.  */\n+  return NULL;\n+}\n+\n /* class region_svalue : public svalue.  */\n \n /* Implementation of svalue::dump_to_pp vfunc for region_svalue.  */\n@@ -680,6 +722,26 @@ constant_svalue::eval_condition (const constant_svalue *lhs,\n   return tristate::TS_UNKNOWN;\n }\n \n+/* Implementation of svalue::maybe_fold_bits_within vfunc\n+   for constant_svalue.  */\n+\n+const svalue *\n+constant_svalue::maybe_fold_bits_within (tree type,\n+\t\t\t\t\t const bit_range &,\n+\t\t\t\t\t region_model_manager *mgr) const\n+{\n+  /* Bits within an all-zero value are also all zero.  */\n+  if (zerop (m_cst_expr))\n+    {\n+      if (type)\n+\treturn mgr->get_or_create_cast (type, this);\n+      else\n+\treturn this;\n+    }\n+  /* Otherwise, don't fold.  */\n+  return NULL;\n+}\n+\n /* class unknown_svalue : public svalue.  */\n \n /* Implementation of svalue::dump_to_pp vfunc for unknown_svalue.  */\n@@ -711,6 +773,18 @@ unknown_svalue::accept (visitor *v) const\n   v->visit_unknown_svalue (this);\n }\n \n+/* Implementation of svalue::maybe_fold_bits_within vfunc\n+   for unknown_svalue.  */\n+\n+const svalue *\n+unknown_svalue::maybe_fold_bits_within (tree type,\n+\t\t\t\t\tconst bit_range &,\n+\t\t\t\t\tregion_model_manager *mgr) const\n+{\n+  /* Bits within an unknown_svalue are themselves unknown.  */\n+  return mgr->get_or_create_unknown_svalue (type);\n+}\n+\n /* Get a string for KIND for use in debug dumps.  */\n \n const char *\n@@ -892,6 +966,34 @@ unaryop_svalue::implicitly_live_p (const svalue_set *live_svalues,\n   return get_arg ()->live_p (live_svalues, model);\n }\n \n+/* Implementation of svalue::maybe_fold_bits_within vfunc\n+   for unaryop_svalue.  */\n+\n+const svalue *\n+unaryop_svalue::maybe_fold_bits_within (tree type,\n+\t\t\t\t\tconst bit_range &,\n+\t\t\t\t\tregion_model_manager *mgr) const\n+{\n+  switch (m_op)\n+    {\n+    default:\n+      break;\n+    case NOP_EXPR:\n+      /* A cast of zero is zero.  */\n+      if (tree cst = m_arg->maybe_get_constant ())\n+\tif (zerop (cst))\n+\t  {\n+\t    if (type)\n+\t      return mgr->get_or_create_cast (type, this);\n+\t    else\n+\t      return this;\n+\t  }\n+      break;\n+    }\n+  /* Otherwise, don't fold.  */\n+  return NULL;\n+}\n+\n /* class binop_svalue : public svalue.  */\n \n /* Implementation of svalue::dump_to_pp vfunc for binop_svalue.  */\n@@ -995,6 +1097,216 @@ sub_svalue::implicitly_live_p (const svalue_set *live_svalues,\n   return get_parent ()->live_p (live_svalues, model);\n }\n \n+/* class repeated_svalue : public svalue.  */\n+\n+/* repeated_svalue'c ctor.  */\n+\n+repeated_svalue::repeated_svalue (tree type,\n+\t\t\t\t  const svalue *outer_size,\n+\t\t\t\t  const svalue *inner_svalue)\n+: svalue (complexity::from_pair (outer_size, inner_svalue), type),\n+  m_outer_size (outer_size),\n+  m_inner_svalue (inner_svalue)\n+{\n+}\n+\n+/* Implementation of svalue::dump_to_pp vfunc for repeated_svalue.  */\n+\n+void\n+repeated_svalue::dump_to_pp (pretty_printer *pp, bool simple) const\n+{\n+  if (simple)\n+    {\n+      pp_string (pp, \"REPEATED(\");\n+      if (get_type ())\n+\t{\n+\t  print_quoted_type (pp, get_type ());\n+\t  pp_string (pp, \", \");\n+\t}\n+      pp_string (pp, \"outer_size: \");\n+      m_outer_size->dump_to_pp (pp, simple);\n+      pp_string (pp, \", inner_val: \");\n+      m_inner_svalue->dump_to_pp (pp, simple);\n+      pp_character (pp, ')');\n+    }\n+  else\n+    {\n+      pp_string (pp, \"repeated_svalue (\");\n+      if (get_type ())\n+\t{\n+\t  print_quoted_type (pp, get_type ());\n+\t  pp_string (pp, \", \");\n+\t}\n+      pp_string (pp, \"outer_size: \");\n+      m_outer_size->dump_to_pp (pp, simple);\n+      pp_string (pp, \", inner_val: \");\n+      m_inner_svalue->dump_to_pp (pp, simple);\n+      pp_character (pp, ')');\n+    }\n+}\n+\n+/* Implementation of svalue::accept vfunc for repeated_svalue.  */\n+\n+void\n+repeated_svalue::accept (visitor *v) const\n+{\n+  v->visit_repeated_svalue (this);\n+  m_inner_svalue->accept (v);\n+}\n+\n+/* Return true if this value is known to be all zeroes.  */\n+\n+bool\n+repeated_svalue::all_zeroes_p () const\n+{\n+  if (tree cst = m_inner_svalue->maybe_get_constant ())\n+    if (zerop (cst))\n+      return true;\n+  return false;\n+}\n+\n+/* Implementation of svalue::maybe_fold_bits_within vfunc\n+   for repeated_svalue.  */\n+\n+const svalue *\n+repeated_svalue::maybe_fold_bits_within (tree type,\n+\t\t\t\t\t const bit_range &bits,\n+\t\t\t\t\t region_model_manager *mgr) const\n+{\n+  const svalue *innermost_sval = m_inner_svalue;\n+  /* Fold\n+       BITS_WITHIN (range, REPEATED_SVALUE (ZERO))\n+     to:\n+       REPEATED_SVALUE (ZERO).  */\n+  if (all_zeroes_p ())\n+    {\n+      byte_range bytes (0,0);\n+      if (bits.as_byte_range (&bytes))\n+\t{\n+\t  const svalue *byte_size\n+\t    = mgr->get_or_create_int_cst (size_type_node,\n+\t\t\t\t\t  bytes.m_size_in_bytes.to_uhwi ());\n+\t  return mgr->get_or_create_repeated_svalue (type, byte_size,\n+\t\t\t\t\t\t     innermost_sval);\n+\t}\n+    }\n+\n+  /* Fold:\n+       BITS_WITHIN (range, REPEATED_SVALUE (INNERMOST_SVALUE))\n+     to:\n+       BITS_WITHIN (range - offset, INNERMOST_SVALUE)\n+     if range is fully within one instance of INNERMOST_SVALUE.  */\n+  if (tree innermost_type = innermost_sval->get_type ())\n+    {\n+      bit_size_t element_bit_size;\n+      if (int_size_in_bits (innermost_type, &element_bit_size)\n+\t  && element_bit_size > 0)\n+\t{\n+\t  HOST_WIDE_INT start_idx\n+\t    = (bits.get_start_bit_offset ()\n+\t       / element_bit_size).to_shwi ();\n+\t  HOST_WIDE_INT last_idx\n+\t    = (bits.get_last_bit_offset ()\n+\t       / element_bit_size).to_shwi ();\n+\t  if (start_idx == last_idx)\n+\t    {\n+\t      bit_offset_t start_of_element\n+\t\t= start_idx * element_bit_size;\n+\t      bit_range range_within_element\n+\t\t(bits.m_start_bit_offset - start_of_element,\n+\t\t bits.m_size_in_bits);\n+\t      return mgr->get_or_create_bits_within (type,\n+\t\t\t\t\t\t     range_within_element,\n+\t\t\t\t\t\t     innermost_sval);\n+\t    }\n+\t}\n+    }\n+\n+  return NULL;\n+}\n+\n+/* class bits_within_svalue : public svalue.  */\n+\n+/* bits_within_svalue'c ctor.  */\n+\n+bits_within_svalue::bits_within_svalue (tree type,\n+\t\t\t\t\tconst bit_range &bits,\n+\t\t\t\t\tconst svalue *inner_svalue)\n+: svalue (complexity (inner_svalue), type),\n+  m_bits (bits),\n+  m_inner_svalue (inner_svalue)\n+{\n+}\n+\n+/* Implementation of svalue::dump_to_pp vfunc for bits_within_svalue.  */\n+\n+void\n+bits_within_svalue::dump_to_pp (pretty_printer *pp, bool simple) const\n+{\n+  if (simple)\n+    {\n+      pp_string (pp, \"BITS_WITHIN(\");\n+      if (get_type ())\n+\t{\n+\t  print_quoted_type (pp, get_type ());\n+\t  pp_string (pp, \", \");\n+\t}\n+      m_bits.dump_to_pp (pp);\n+      pp_string (pp, \", inner_val: \");\n+      m_inner_svalue->dump_to_pp (pp, simple);\n+      pp_character (pp, ')');\n+    }\n+  else\n+    {\n+      pp_string (pp, \"bits_within_svalue (\");\n+      if (get_type ())\n+\t{\n+\t  print_quoted_type (pp, get_type ());\n+\t  pp_string (pp, \", \");\n+\t}\n+      m_bits.dump_to_pp (pp);\n+      pp_string (pp, \", inner_val: \");\n+      m_inner_svalue->dump_to_pp (pp, simple);\n+      pp_character (pp, ')');\n+    }\n+}\n+\n+/* Implementation of svalue::maybe_fold_bits_within vfunc\n+   for bits_within_svalue.  */\n+\n+const svalue *\n+bits_within_svalue::maybe_fold_bits_within (tree type,\n+\t\t\t\t\t    const bit_range &bits,\n+\t\t\t\t\t    region_model_manager *mgr) const\n+{\n+  /* Fold:\n+       BITS_WITHIN (range1, BITS_WITHIN (range2, VAL))\n+     to:\n+       BITS_WITHIN (range1 in range 2, VAL).  */\n+  bit_range offset_bits (m_bits.get_start_bit_offset ()\n+\t\t\t + bits.m_start_bit_offset,\n+\t\t\t bits.m_size_in_bits);\n+  return mgr->get_or_create_bits_within (type, offset_bits, m_inner_svalue);\n+}\n+\n+/* Implementation of svalue::accept vfunc for bits_within_svalue.  */\n+\n+void\n+bits_within_svalue::accept (visitor *v) const\n+{\n+  v->visit_bits_within_svalue (this);\n+  m_inner_svalue->accept (v);\n+}\n+\n+/* Implementation of svalue::implicitly_live_p vfunc for bits_within_svalue.  */\n+\n+bool\n+bits_within_svalue::implicitly_live_p (const svalue_set *live_svalues,\n+\t\t\t\t       const region_model *model) const\n+{\n+  return m_inner_svalue->live_p (live_svalues, model);\n+}\n+\n /* class widening_svalue : public svalue.  */\n \n /* Implementation of svalue::dump_to_pp vfunc for widening_svalue.  */\n@@ -1291,6 +1603,75 @@ compound_svalue::calc_complexity (const binding_map &map)\n   return complexity (num_child_nodes + 1, max_child_depth + 1);\n }\n \n+/* Implementation of svalue::maybe_fold_bits_within vfunc\n+   for compound_svalue.  */\n+\n+const svalue *\n+compound_svalue::maybe_fold_bits_within (tree type,\n+\t\t\t\t\t const bit_range &bits,\n+\t\t\t\t\t region_model_manager *mgr) const\n+{\n+  binding_map result_map;\n+  for (auto iter : m_map)\n+    {\n+      const binding_key *key = iter.first;\n+      if (const concrete_binding *conc_key\n+\t  = key->dyn_cast_concrete_binding ())\n+\t{\n+\t  /* Ignore concrete bindings outside BITS.  */\n+\t  if (!conc_key->get_bit_range ().intersects_p (bits))\n+\t    continue;\n+\n+\t  const svalue *sval = iter.second;\n+\t  /* Get the position of conc_key relative to BITS.  */\n+\t  bit_range result_location (conc_key->get_start_bit_offset ()\n+\t\t\t\t     - bits.get_start_bit_offset (),\n+\t\t\t\t     conc_key->get_size_in_bits ());\n+\t  /* If conc_key starts after BITS, trim off leading bits\n+\t     from the svalue and adjust binding location.  */\n+\t  if (result_location.m_start_bit_offset < 0)\n+\t    {\n+\t      bit_size_t leading_bits_to_drop\n+\t\t= -result_location.m_start_bit_offset;\n+\t      result_location = bit_range\n+\t\t(0, result_location.m_size_in_bits - leading_bits_to_drop);\n+\t      bit_range bits_within_sval (leading_bits_to_drop,\n+\t\t\t\t\t  result_location.m_size_in_bits);\n+\t      /* Trim off leading bits from iter_sval.  */\n+\t      sval = mgr->get_or_create_bits_within (NULL_TREE,\n+\t\t\t\t\t\t     bits_within_sval,\n+\t\t\t\t\t\t     sval);\n+\t    }\n+\t  /* If conc_key finishes after BITS, trim off trailing bits\n+\t     from the svalue and adjust binding location.  */\n+\t  if (conc_key->get_next_bit_offset ()\n+\t      > bits.get_next_bit_offset ())\n+\t    {\n+\t      bit_size_t trailing_bits_to_drop\n+\t\t= (conc_key->get_next_bit_offset ()\n+\t\t   - bits.get_next_bit_offset ());\n+\t      result_location = bit_range\n+\t\t(result_location.m_start_bit_offset,\n+\t\t result_location.m_size_in_bits - trailing_bits_to_drop);\n+\t      bit_range bits_within_sval (0,\n+\t\t\t\t\t  result_location.m_size_in_bits);\n+\t      /* Trim off leading bits from iter_sval.  */\n+\t      sval = mgr->get_or_create_bits_within (NULL_TREE,\n+\t\t\t\t\t\t     bits_within_sval,\n+\t\t\t\t\t\t     sval);\n+\t    }\n+\t  const concrete_binding *offset_conc_key\n+\t    = mgr->get_store_manager ()->get_concrete_binding\n+\t\t(result_location);\n+\t  result_map.put (offset_conc_key, sval);\n+\t}\n+      else\n+\t/* If we have any symbolic keys we can't get it as bits.  */\n+\treturn NULL;\n+    }\n+  return mgr->get_or_create_compound_svalue (type, result_map);\n+}\n+\n /* class conjured_svalue : public svalue.  */\n \n /* Implementation of svalue::dump_to_pp vfunc for conjured_svalue.  */"}, {"sha": "3965a5f805db1eee71bf17036d9136186e473543", "filename": "gcc/analyzer/svalue.h", "status": "modified", "additions": 238, "deletions": 24, "changes": 262, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fsvalue.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Fanalyzer%2Fsvalue.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fanalyzer%2Fsvalue.h?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -41,6 +41,8 @@ enum svalue_kind\n   SK_UNARYOP,\n   SK_BINOP,\n   SK_SUB,\n+  SK_REPEATED,\n+  SK_BITS_WITHIN,\n   SK_UNMERGEABLE,\n   SK_PLACEHOLDER,\n   SK_WIDENING,\n@@ -63,6 +65,9 @@ enum svalue_kind\n      unaryop_svalue (SK_UNARYOP): unary operation on another svalue\n      binop_svalue (SK_BINOP): binary operation on two svalues\n      sub_svalue (SK_SUB): the result of accessing a subregion\n+     repeated_svalue (SK_REPEATED): repeating an svalue to fill a larger region\n+     bits_within_svalue (SK_BITS_WITHIN): a range of bits/bytes within a larger\n+       svalue\n      unmergeable_svalue (SK_UNMERGEABLE): a value that is so interesting\n        from a control-flow perspective that it can inhibit state-merging\n      placeholder_svalue (SK_PLACEHOLDER): for use in selftests.\n@@ -107,6 +112,10 @@ class svalue\n   dyn_cast_binop_svalue () const { return NULL; }\n   virtual const sub_svalue *\n   dyn_cast_sub_svalue () const { return NULL; }\n+  virtual const repeated_svalue *\n+  dyn_cast_repeated_svalue () const { return NULL; }\n+  virtual const bits_within_svalue *\n+  dyn_cast_bits_within_svalue () const { return NULL; }\n   virtual const unmergeable_svalue *\n   dyn_cast_unmergeable_svalue () const { return NULL; }\n   virtual const widening_svalue *\n@@ -138,6 +147,16 @@ class svalue\n \n   bool involves_p (const svalue *other) const;\n \n+  const svalue *\n+  extract_bit_range (tree type,\n+\t\t     const bit_range &subrange,\n+\t\t     region_model_manager *mgr) const;\n+\n+  virtual const svalue *\n+  maybe_fold_bits_within (tree type,\n+\t\t\t  const bit_range &subrange,\n+\t\t\t  region_model_manager *mgr) const;\n+\n  protected:\n   svalue (complexity c, tree type)\n   : m_complexity (c), m_type (type)\n@@ -175,9 +194,9 @@ class region_svalue : public svalue\n     }\n \n     void mark_deleted () { m_type = reinterpret_cast<tree> (1); }\n-    void mark_empty () { m_type = NULL_TREE; }\n+    void mark_empty () { m_type = reinterpret_cast<tree> (2); }\n     bool is_deleted () const { return m_type == reinterpret_cast<tree> (1); }\n-    bool is_empty () const { return m_type == NULL_TREE; }\n+    bool is_empty () const { return m_type == reinterpret_cast<tree> (2); }\n \n     tree m_type;\n     const region *m_reg;\n@@ -222,7 +241,7 @@ is_a_helper <const region_svalue *>::test (const svalue *sval)\n template <> struct default_hash_traits<region_svalue::key_t>\n : public member_function_hash_traits<region_svalue::key_t>\n {\n-  static const bool empty_zero_p = true;\n+  static const bool empty_zero_p = false;\n };\n \n namespace ana {\n@@ -253,6 +272,11 @@ class constant_svalue : public svalue\n \t\t\t\t  enum tree_code op,\n \t\t\t\t  const constant_svalue *rhs);\n \n+  const svalue *\n+  maybe_fold_bits_within (tree type,\n+\t\t\t  const bit_range &subrange,\n+\t\t\t  region_model_manager *mgr) const FINAL OVERRIDE;\n+\n  private:\n   tree m_cst_expr;\n };\n@@ -285,6 +309,11 @@ class unknown_svalue : public svalue\n \n   void dump_to_pp (pretty_printer *pp, bool simple) const FINAL OVERRIDE;\n   void accept (visitor *v) const FINAL OVERRIDE;\n+\n+  const svalue *\n+  maybe_fold_bits_within (tree type,\n+\t\t\t  const bit_range &subrange,\n+\t\t\t  region_model_manager *mgr) const FINAL OVERRIDE;\n };\n \n /* An enum describing a particular kind of \"poisoned\" value.  */\n@@ -327,9 +356,9 @@ class poisoned_svalue : public svalue\n     }\n \n     void mark_deleted () { m_type = reinterpret_cast<tree> (1); }\n-    void mark_empty () { m_type = NULL_TREE; }\n+    void mark_empty () { m_type = reinterpret_cast<tree> (2); }\n     bool is_deleted () const { return m_type == reinterpret_cast<tree> (1); }\n-    bool is_empty () const { return m_type == NULL_TREE; }\n+    bool is_empty () const { return m_type == reinterpret_cast<tree> (2); }\n \n     enum poison_kind m_kind;\n     tree m_type;\n@@ -364,7 +393,7 @@ is_a_helper <const poisoned_svalue *>::test (const svalue *sval)\n template <> struct default_hash_traits<poisoned_svalue::key_t>\n : public member_function_hash_traits<poisoned_svalue::key_t>\n {\n-  static const bool empty_zero_p = true;\n+  static const bool empty_zero_p = false;\n };\n \n namespace ana {\n@@ -426,9 +455,9 @@ class setjmp_svalue : public svalue\n     }\n \n     void mark_deleted () { m_type = reinterpret_cast<tree> (1); }\n-    void mark_empty () { m_type = NULL_TREE; }\n+    void mark_empty () { m_type = reinterpret_cast<tree> (2); }\n     bool is_deleted () const { return m_type == reinterpret_cast<tree> (1); }\n-    bool is_empty () const { return m_type == NULL_TREE; }\n+    bool is_empty () const { return m_type == reinterpret_cast<tree> (2); }\n \n     setjmp_record m_record;\n     tree m_type;\n@@ -467,7 +496,7 @@ is_a_helper <const setjmp_svalue *>::test (const svalue *sval)\n template <> struct default_hash_traits<setjmp_svalue::key_t>\n : public member_function_hash_traits<setjmp_svalue::key_t>\n {\n-  static const bool empty_zero_p = true;\n+  static const bool empty_zero_p = false;\n };\n \n namespace ana {\n@@ -548,9 +577,9 @@ class unaryop_svalue : public svalue\n     }\n \n     void mark_deleted () { m_type = reinterpret_cast<tree> (1); }\n-    void mark_empty () { m_type = NULL_TREE; }\n+    void mark_empty () { m_type = reinterpret_cast<tree> (2); }\n     bool is_deleted () const { return m_type == reinterpret_cast<tree> (1); }\n-    bool is_empty () const { return m_type == NULL_TREE; }\n+    bool is_empty () const { return m_type == reinterpret_cast<tree> (2); }\n \n     tree m_type;\n     enum tree_code m_op;\n@@ -574,6 +603,11 @@ class unaryop_svalue : public svalue\n   enum tree_code get_op () const { return m_op; }\n   const svalue *get_arg () const { return m_arg; }\n \n+  const svalue *\n+  maybe_fold_bits_within (tree type,\n+\t\t\t  const bit_range &subrange,\n+\t\t\t  region_model_manager *mgr) const FINAL OVERRIDE;\n+\n  private:\n   enum tree_code m_op;\n   const svalue *m_arg;\n@@ -592,7 +626,7 @@ is_a_helper <const unaryop_svalue *>::test (const svalue *sval)\n template <> struct default_hash_traits<unaryop_svalue::key_t>\n : public member_function_hash_traits<unaryop_svalue::key_t>\n {\n-  static const bool empty_zero_p = true;\n+  static const bool empty_zero_p = false;\n };\n \n namespace ana {\n@@ -630,9 +664,9 @@ class binop_svalue : public svalue\n     }\n \n     void mark_deleted () { m_type = reinterpret_cast<tree> (1); }\n-    void mark_empty () { m_type = NULL_TREE; }\n+    void mark_empty () { m_type = reinterpret_cast<tree> (2); }\n     bool is_deleted () const { return m_type == reinterpret_cast<tree> (1); }\n-    bool is_empty () const { return m_type == NULL_TREE; }\n+    bool is_empty () const { return m_type == reinterpret_cast<tree> (2); }\n \n     tree m_type;\n     enum tree_code m_op;\n@@ -683,7 +717,7 @@ is_a_helper <const binop_svalue *>::test (const svalue *sval)\n template <> struct default_hash_traits<binop_svalue::key_t>\n : public member_function_hash_traits<binop_svalue::key_t>\n {\n-  static const bool empty_zero_p = true;\n+  static const bool empty_zero_p = false;\n };\n \n namespace ana {\n@@ -719,9 +753,9 @@ class sub_svalue : public svalue\n     }\n \n     void mark_deleted () { m_type = reinterpret_cast<tree> (1); }\n-    void mark_empty () { m_type = NULL_TREE; }\n+    void mark_empty () { m_type = reinterpret_cast<tree> (2); }\n     bool is_deleted () const { return m_type == reinterpret_cast<tree> (1); }\n-    bool is_empty () const { return m_type == NULL_TREE; }\n+    bool is_empty () const { return m_type == reinterpret_cast<tree> (2); }\n \n     tree m_type;\n     const svalue *m_parent_svalue;\n@@ -762,7 +796,182 @@ is_a_helper <const sub_svalue *>::test (const svalue *sval)\n template <> struct default_hash_traits<sub_svalue::key_t>\n : public member_function_hash_traits<sub_svalue::key_t>\n {\n-  static const bool empty_zero_p = true;\n+  static const bool empty_zero_p = false;\n+};\n+\n+namespace ana {\n+\n+/* Concrete subclass of svalue representing repeating an inner svalue\n+   (possibly not a whole number of times) to fill a larger region of\n+   type TYPE of size OUTER_SIZE bytes.  */\n+\n+class repeated_svalue : public svalue\n+{\n+public:\n+  /* A support class for uniquifying instances of repeated_svalue.  */\n+  struct key_t\n+  {\n+    key_t (tree type,\n+\t   const svalue *outer_size,\n+\t   const svalue *inner_svalue)\n+    : m_type (type), m_outer_size (outer_size), m_inner_svalue (inner_svalue)\n+    {}\n+\n+    hashval_t hash () const\n+    {\n+      inchash::hash hstate;\n+      hstate.add_ptr (m_type);\n+      hstate.add_ptr (m_outer_size);\n+      hstate.add_ptr (m_inner_svalue);\n+      return hstate.end ();\n+    }\n+\n+    bool operator== (const key_t &other) const\n+    {\n+      return (m_type == other.m_type\n+\t      && m_outer_size == other.m_outer_size\n+\t      && m_inner_svalue == other.m_inner_svalue);\n+    }\n+\n+    void mark_deleted () { m_type = reinterpret_cast<tree> (1); }\n+    void mark_empty () { m_type = reinterpret_cast<tree> (2); }\n+    bool is_deleted () const { return m_type == reinterpret_cast<tree> (1); }\n+    bool is_empty () const { return m_type == reinterpret_cast<tree> (2); }\n+\n+    tree m_type;\n+    const svalue *m_outer_size;\n+    const svalue *m_inner_svalue;\n+  };\n+  repeated_svalue (tree type,\n+\t\t   const svalue *outer_size,\n+\t\t   const svalue *inner_svalue);\n+\n+  enum svalue_kind get_kind () const FINAL OVERRIDE { return SK_REPEATED; }\n+  const repeated_svalue *dyn_cast_repeated_svalue () const FINAL OVERRIDE\n+  {\n+    return this;\n+  }\n+\n+  void dump_to_pp (pretty_printer *pp, bool simple) const FINAL OVERRIDE;\n+  void accept (visitor *v) const FINAL OVERRIDE;\n+\n+  const svalue *get_outer_size () const { return m_outer_size; }\n+  const svalue *get_inner_svalue () const { return m_inner_svalue; }\n+\n+  bool all_zeroes_p () const;\n+\n+  const svalue *\n+  maybe_fold_bits_within (tree type,\n+\t\t\t  const bit_range &subrange,\n+\t\t\t  region_model_manager *mgr) const FINAL OVERRIDE;\n+\n+ private:\n+  const svalue *m_outer_size;\n+  const svalue *m_inner_svalue;\n+};\n+\n+} // namespace ana\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <const repeated_svalue *>::test (const svalue *sval)\n+{\n+  return sval->get_kind () == SK_REPEATED;\n+}\n+\n+template <> struct default_hash_traits<repeated_svalue::key_t>\n+: public member_function_hash_traits<repeated_svalue::key_t>\n+{\n+  static const bool empty_zero_p = false;\n+};\n+\n+namespace ana {\n+\n+/* A range of bits/bytes within another svalue\n+   e.g. bytes 5-39 of INITIAL_SVALUE(R).\n+   These can be generated for prefixes and suffixes when part of a binding\n+   is clobbered, so that we don't lose too much information.  */\n+\n+class bits_within_svalue : public svalue\n+{\n+public:\n+  /* A support class for uniquifying instances of bits_within_svalue.  */\n+  struct key_t\n+  {\n+    key_t (tree type,\n+\t   const bit_range &bits,\n+\t   const svalue *inner_svalue)\n+    : m_type (type), m_bits (bits), m_inner_svalue (inner_svalue)\n+    {}\n+\n+    hashval_t hash () const\n+    {\n+      inchash::hash hstate;\n+      hstate.add_ptr (m_type);\n+      hstate.add_ptr (m_inner_svalue);\n+      return hstate.end ();\n+    }\n+\n+    bool operator== (const key_t &other) const\n+    {\n+      return (m_type == other.m_type\n+\t      && m_bits == other.m_bits\n+\t      && m_inner_svalue == other.m_inner_svalue);\n+    }\n+\n+    void mark_deleted () { m_type = reinterpret_cast<tree> (1); }\n+    void mark_empty () { m_type = reinterpret_cast<tree> (2); }\n+    bool is_deleted () const { return m_type == reinterpret_cast<tree> (1); }\n+    bool is_empty () const { return m_type == reinterpret_cast<tree> (2); }\n+\n+    tree m_type;\n+    bit_range m_bits;\n+    const svalue *m_inner_svalue;\n+  };\n+  bits_within_svalue (tree type,\n+\t\t      const bit_range &bits,\n+\t\t      const svalue *inner_svalue);\n+\n+  enum svalue_kind get_kind () const FINAL OVERRIDE { return SK_BITS_WITHIN; }\n+  const bits_within_svalue *\n+  dyn_cast_bits_within_svalue () const FINAL OVERRIDE\n+  {\n+    return this;\n+  }\n+\n+  void dump_to_pp (pretty_printer *pp, bool simple) const FINAL OVERRIDE;\n+  void accept (visitor *v) const FINAL OVERRIDE;\n+  bool implicitly_live_p (const svalue_set *,\n+\t\t\t  const region_model *) const FINAL OVERRIDE;\n+\n+  const bit_range &get_bits () const { return m_bits; }\n+  const svalue *get_inner_svalue () const { return m_inner_svalue; }\n+\n+  const svalue *\n+  maybe_fold_bits_within (tree type,\n+\t\t\t  const bit_range &subrange,\n+\t\t\t  region_model_manager *mgr) const FINAL OVERRIDE;\n+\n+ private:\n+  const bit_range m_bits;\n+  const svalue *m_inner_svalue;\n+};\n+\n+} // namespace ana\n+\n+template <>\n+template <>\n+inline bool\n+is_a_helper <const bits_within_svalue *>::test (const svalue *sval)\n+{\n+  return sval->get_kind () == SK_BITS_WITHIN;\n+}\n+\n+template <> struct default_hash_traits<bits_within_svalue::key_t>\n+: public member_function_hash_traits<bits_within_svalue::key_t>\n+{\n+  static const bool empty_zero_p = false;\n };\n \n namespace ana {\n@@ -888,9 +1097,9 @@ class widening_svalue : public svalue\n     }\n \n     void mark_deleted () { m_type = reinterpret_cast<tree> (1); }\n-    void mark_empty () { m_type = NULL_TREE; }\n+    void mark_empty () { m_type = reinterpret_cast<tree> (2); }\n     bool is_deleted () const { return m_type == reinterpret_cast<tree> (1); }\n-    bool is_empty () const { return m_type == NULL_TREE; }\n+    bool is_empty () const { return m_type == reinterpret_cast<tree> (2); }\n \n     tree m_type;\n     function_point m_point;\n@@ -952,7 +1161,7 @@ is_a_helper <widening_svalue *>::test (svalue *sval)\n template <> struct default_hash_traits<widening_svalue::key_t>\n : public member_function_hash_traits<widening_svalue::key_t>\n {\n-  static const bool empty_zero_p = true;\n+  static const bool empty_zero_p = false;\n };\n \n namespace ana {\n@@ -1000,9 +1209,9 @@ class compound_svalue : public svalue\n     }\n \n     void mark_deleted () { m_type = reinterpret_cast<tree> (1); }\n-    void mark_empty () { m_type = NULL_TREE; }\n+    void mark_empty () { m_type = reinterpret_cast<tree> (2); }\n     bool is_deleted () const { return m_type == reinterpret_cast<tree> (1); }\n-    bool is_empty () const { return m_type == NULL_TREE; }\n+    bool is_empty () const { return m_type == reinterpret_cast<tree> (2); }\n \n     tree m_type;\n     const binding_map *m_map_ptr;\n@@ -1029,6 +1238,11 @@ class compound_svalue : public svalue\n     return key_t (get_type (), &m_map);\n   }\n \n+  const svalue *\n+  maybe_fold_bits_within (tree type,\n+\t\t\t  const bit_range &subrange,\n+\t\t\t  region_model_manager *mgr) const FINAL OVERRIDE;\n+\n  private:\n   static complexity calc_complexity (const binding_map &map);\n \n@@ -1048,7 +1262,7 @@ is_a_helper <compound_svalue *>::test (svalue *sval)\n template <> struct default_hash_traits<compound_svalue::key_t>\n : public member_function_hash_traits<compound_svalue::key_t>\n {\n-  static const bool empty_zero_p = true;\n+  static const bool empty_zero_p = false;\n };\n \n namespace ana {"}, {"sha": "824dbd42127714b57ca0b0e59a89c8e81018e252", "filename": "gcc/testsuite/gcc.dg/analyzer/clobbers-1.c", "status": "added", "additions": 98, "deletions": 0, "changes": 98, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fclobbers-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fclobbers-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fclobbers-1.c?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -0,0 +1,98 @@\n+#include \"analyzer-decls.h\"\n+\n+struct foo\n+{\n+  int i;\n+  int j;\n+};\n+\n+struct coord\n+{\n+  int x;\n+  int y;\n+  int z;\n+};\n+\n+struct foo g;\n+\n+void test_1 (void)\n+{\n+  g.i = 42;\n+  if (g.j)\n+    __analyzer_eval (g.j); /* { dg-warning \"TRUE\" } */\n+  else\n+    __analyzer_eval (g.j); /* { dg-warning \"FALSE\" } */\n+  __analyzer_dump_exploded_nodes (0); /* { dg-warning \"1 processed enode\" } */\n+}\n+\n+void test_2 (void)\n+{\n+  struct foo f;\n+  f.i = 42;\n+  if (f.j)\n+    __analyzer_eval (f.j); /* { dg-warning \"TRUE\" } */\n+  else\n+    __analyzer_eval (f.j); /* { dg-warning \"FALSE\" } */\n+  __analyzer_dump_exploded_nodes (0); /* { dg-warning \"1 processed enode\" } */\n+}\n+\n+void test_3 (struct foo *p)\n+{\n+  struct foo f = *p;\n+  f.i = 42;\n+  if (f.j)\n+    __analyzer_eval (f.j); /* { dg-warning \"TRUE\" } */\n+  else\n+    __analyzer_eval (f.j); /* { dg-warning \"FALSE\" } */\n+  __analyzer_dump_exploded_nodes (0); /* { dg-warning \"1 processed enode\" } */\n+}\n+\n+void test_4 (struct coord *p)\n+{\n+  struct coord f = *p;\n+  f.x = 42;\n+  __analyzer_eval (f.y == p->y); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.z == p->z); /* { dg-warning \"TRUE\" } */\n+}\n+\n+struct s5\n+{\n+  char arr[8];\n+};\n+\n+void test_5 (struct s5 *p)\n+{\n+  struct s5 f = *p;\n+  f.arr[3] = 42;\n+  __analyzer_eval (f.arr[0] == p->arr[0]); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.arr[1] == p->arr[1]); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.arr[2] == p->arr[2]); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.arr[3] == 42); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.arr[4] == p->arr[4]); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.arr[5] == p->arr[5]); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.arr[6] == p->arr[6]); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.arr[7] == p->arr[7]); /* { dg-warning \"TRUE\" } */\n+}\n+\n+struct s6\n+{\n+  int before; /* Give \"arr\" a nonzero offset.  */\n+  struct foo arr[4];\n+  int after;\n+};\n+\n+void test_6 (struct s6 *p, struct foo *q)\n+{\n+  struct s6 f = *p;\n+  f.arr[1] = *q;\n+  __analyzer_eval (f.before == p->before); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.arr[0].i == p->arr[0].i); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.arr[0].j == p->arr[0].j); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.arr[1].i == q->i); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.arr[1].j == q->j); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.arr[2].i == p->arr[2].i); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.arr[2].j == p->arr[2].j); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.arr[3].i == p->arr[3].i); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.arr[3].j == p->arr[3].j); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (f.after == p->after); /* { dg-warning \"TRUE\" } */\n+}"}, {"sha": "9a88349d641a1651a94c5adadc828c507c5398ac", "filename": "gcc/testsuite/gcc.dg/analyzer/clobbers-2.c", "status": "added", "additions": 72, "deletions": 0, "changes": 72, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fclobbers-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fclobbers-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fclobbers-2.c?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -0,0 +1,72 @@\n+#include \"analyzer-decls.h\"\n+\n+typedef __SIZE_TYPE__ size_t;\n+extern void bzero (void *s, size_t n);\n+extern void *memset(void *s, int c, size_t n);\n+\n+void test_1 (void)\n+{\n+  char arr[16];\n+  bzero (arr, sizeof (arr));\n+  __analyzer_eval (arr[0] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[7] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[8] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[9] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[15] == 0); /* { dg-warning \"TRUE\" } */\n+\n+  /* Clobber in the middle (with prefix and suffix).  */\n+  arr[8] = 42;\n+  __analyzer_eval (arr[0] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[7] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[8] == 0); /* { dg-warning \"FALSE\" } */\n+  __analyzer_eval (arr[8] == 42); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[9] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[15] == 0); /* { dg-warning \"TRUE\" } */\n+}\n+\n+void test_2 (void)\n+{\n+  char arr[16];\n+  bzero (arr, sizeof (arr));\n+  __analyzer_eval (arr[0] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[1] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[15] == 0); /* { dg-warning \"TRUE\" } */\n+\n+  /* Clobber at the front (suffix, but no prefix).  */\n+  arr[0] = 42;\n+  __analyzer_eval (arr[0] == 0); /* { dg-warning \"FALSE\" } */\n+  __analyzer_eval (arr[0] == 42); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[1] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[15] == 0); /* { dg-warning \"TRUE\" } */\n+}\n+\n+void test_3 (void)\n+{\n+  char arr[16];\n+  bzero (arr, sizeof (arr));\n+  __analyzer_eval (arr[0] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[14] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[15] == 0); /* { dg-warning \"TRUE\" } */\n+\n+  /* Clobber at the end (prefix, but no suffix).  */\n+  arr[15] = 42;\n+  __analyzer_eval (arr[0] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[14] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[15] == 0); /* { dg-warning \"FALSE\" } */\n+  __analyzer_eval (arr[15] == 42); /* { dg-warning \"TRUE\" } */\n+}\n+\n+void test_4 (void)\n+{\n+  char arr[16];\n+  bzero (arr, sizeof (arr));\n+  __analyzer_eval (arr[0] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[15] == 0); /* { dg-warning \"TRUE\" } */\n+\n+  /* Exact overlap, no prefix or suffix.  */\n+  memset (arr, 1, 16);\n+  __analyzer_eval (arr[0] == 0); /* { dg-warning \"FALSE\" } */\n+  __analyzer_eval (arr[15] == 0); /* { dg-warning \"FALSE\" } */\n+  __analyzer_eval (arr[0] == 1); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (arr[15] == 1); /* { dg-warning \"TRUE\" } */\n+}"}, {"sha": "34932da7bbc76a1997ca9801ab9d0e7a1d86bc66", "filename": "gcc/testsuite/gcc.dg/analyzer/data-model-1.c", "status": "modified", "additions": 7, "deletions": 17, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fdata-model-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fdata-model-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fdata-model-1.c?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -503,9 +503,7 @@ void test_26 (struct coord *p, struct coord *q)\n      the dest value.  */\n   *p = *q;\n   __analyzer_eval (p->x); /* { dg-warning \"UNKNOWN\" } */\n-  __analyzer_eval (p->y == 17); /* { dg-warning \"TRUE\" \"desired\" { xfail *-*-* } } */\n-  /* { dg-warning \"UNKNOWN\" \"status quo\" { target *-*-* } .-1 } */\n-  // TODO(xfail): should have been overwritten with q->y\n+  __analyzer_eval (p->y == 17); /* { dg-warning \"TRUE\" } */\n \n   __analyzer_eval (q->x); /* { dg-warning \"UNKNOWN\" } */\n   __analyzer_eval (q->y == 17); /* { dg-warning \"TRUE\" \"desired\" { xfail *-*-* } } */\n@@ -522,19 +520,11 @@ void test_27 (struct coord *p)\n void test_28 (struct coord *p)\n {\n   memset (p, 0, sizeof (struct coord) * 10);\n-  __analyzer_eval (p[0].x == 0); /* { dg-warning \"TRUE\" \"desired\" { xfail *-*-* } } */\n-  /* { dg-warning \"UNKNOWN\" \"status quo\" { target *-*-* } .-1 } */\n-  // TODO(xfail):\n-  __analyzer_eval (p[0].y == 0); /* { dg-warning \"TRUE\" \"desired\" { xfail *-*-* } } */\n-  /* { dg-warning \"UNKNOWN\" \"status quo\" { target *-*-* } .-1 } */\n-  // TODO(xfail):\n+  __analyzer_eval (p[0].x == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (p[0].y == 0); /* { dg-warning \"TRUE\" } */\n \n-  __analyzer_eval (p[9].x == 0); /* { dg-warning \"TRUE\" \"desired\" { xfail *-*-* } } */\n-  /* { dg-warning \"UNKNOWN\" \"status quo\" { target *-*-* } .-1 } */\n-  // TODO(xfail):\n-  __analyzer_eval (p[9].y == 0); /* { dg-warning \"TRUE\" \"desired\" { xfail *-*-* } } */\n-  /* { dg-warning \"UNKNOWN\" \"status quo\" { target *-*-* } .-1 } */\n-  // TODO(xfail):\n+  __analyzer_eval (p[9].x == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (p[9].y == 0); /* { dg-warning \"TRUE\" } */\n \n   __analyzer_eval (p[10].x == 0); /* { dg-warning \"UNKNOWN\" } */\n   __analyzer_eval (p[10].y == 0); /* { dg-warning \"UNKNOWN\" } */\n@@ -1035,8 +1025,8 @@ void test_52 (struct big b)\n {\n   struct big d;\n   memcpy (&d, &b, sizeof (struct big));\n-  __analyzer_eval (b.ia[0] == d.ia[0]); /* { dg-warning \"TRUE\" \"desired\" { xfail *-*-* } } */\n-  /* { dg-warning \"UNKNOWN\" \"status quo\" { target *-*-* } .-1 } */\n+  __analyzer_eval (b.ia[0] == d.ia[0]); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (b.ia[1023] == d.ia[1023]); /* { dg-warning \"TRUE\" } */\n }\n \n void test_53 (const char *msg)"}, {"sha": "f48408e8426ecd0893dbefd1d0a727ff140cd2db", "filename": "gcc/testsuite/gcc.dg/analyzer/explode-1.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fexplode-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fexplode-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fexplode-1.c?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -12,7 +12,7 @@ void test (void)\n {\n   void *p0, *p1, *p2, *p3, *p4, *p5, *p6, *p7, *p8;\n   void **pp;\n-  while (get ())\n+  while (get ()) /* { dg-warning \"leak\" } */\n     {\n       switch (get ())\n \t{"}, {"sha": "94c5a1b7c920811ef94ea0df61d53c5e0f6bf4da", "filename": "gcc/testsuite/gcc.dg/analyzer/memset-1.c", "status": "modified", "additions": 103, "deletions": 15, "changes": 118, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fmemset-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fmemset-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fmemset-1.c?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -36,22 +36,16 @@ void test_3 (int val)\n {\n   char buf[256];\n   memset (buf, 'A', 256);\n-  /* We currently merely mark such regions as \"unknown\", so querying\n-     values within them yields UNKNOWN when ideally it would be TRUE.  */\n-  __analyzer_eval (buf[42] == 'A'); /* { dg-warning \"TRUE\" \"known nonzero\" { xfail *-*-* } } */\n-  /* { dg-bogus \"UNKNOWN\" \"status quo\" { xfail *-*-* } .-1 } */\n+  __analyzer_eval (buf[42] == 'A'); /* { dg-warning \"TRUE\" } */\n }\n \n /* A \"memset\" with unknown value.  */\n \n-void test_4 (int val)\n+void test_4 (char val)\n {\n   char buf[256];\n   memset (buf, val, 256);\n-  /* We currently merely mark such regions as \"unknown\", so querying\n-     values within them yields UNKNOWN when ideally it would be TRUE.  */\n-  __analyzer_eval (buf[42] == (char)val); /* { dg-warning \"TRUE\" \"known nonzero\" { xfail *-*-* } } */\n-  /* { dg-bogus \"UNKNOWN\" \"status quo\" { xfail *-*-* } .-1 } */\n+  __analyzer_eval (buf[42] == (char)val); /* { dg-warning \"TRUE\" } */\n }\n \n /* A \"memset\" with unknown num bytes.  */\n@@ -98,17 +92,111 @@ void test_6 (int val)\n   __analyzer_eval (buf[42] == 'A'); /* { dg-warning \"TRUE\" } */  \n }\n \n+void test_6b (int val)\n+{\n+  char buf[256];\n+  memset (buf, 'A', sizeof (buf));\n+  memset (buf, 'B', get_zero ());\n+  __analyzer_eval (buf[42] == 'A'); /* { dg-warning \"TRUE\" } */  \n+}\n+\n /* A \"memset\" of known size that's not the full buffer.  */\n \n void test_7 (void)\n {\n   char buf[256];\n   buf[128] = 'A';\n   memset (buf, 0, 128);\n-  /* We currently merely mark the whole region as \"unknown\", so querying\n-     values within them yields UNKNOWN.  */\n-  __analyzer_eval (buf[127] == '\\0'); /* { dg-warning \"TRUE\" \"known nonzero\" { xfail *-*-* } } */\n-  /* { dg-bogus \"UNKNOWN\" \"status quo\" { xfail *-*-* } .-1 } */\n-  __analyzer_eval (buf[128] == 'A'); /* { dg-warning \"TRUE\" \"known nonzero\" { xfail *-*-* } } */\n-  /* { dg-bogus \"UNKNOWN\" \"status quo\" { xfail *-*-* } .-1 } */\n+  __analyzer_eval (buf[0] == '\\0'); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[127] == '\\0'); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[128] == 'A'); /* { dg-warning \"TRUE\" } */\n+}\n+\n+void test_8 (void)\n+{\n+  char buf[20];\n+  memset (buf + 0, 0, 1);\n+  memset (buf + 1, 1, 1);\n+  memset (buf + 2, 2, 1);\n+  memset (buf + 3, 3, 1);\n+  memset (buf + 4, 4, 2);\n+  memset (buf + 6, 6, 2);\n+  memset (buf + 8, 8, 4);\n+  memset (buf + 12, 12, 8);\n+  __analyzer_eval (buf[0] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[1] == 1); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[2] == 2); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[3] == 3); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[4] == 4); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[5] == 4); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[6] == 6); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[7] == 6); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[8] == 8); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[9] == 8); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[10] == 8); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[11] == 8); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[12] == 12); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[13] == 12); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[14] == 12); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[15] == 12); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[16] == 12); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[17] == 12); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[18] == 12); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[19] == 12); /* { dg-warning \"TRUE\" } */\n+}\n+\n+/* Various overlapping memset calls with different sizes and values.  */\n+\n+void test_9 (void)\n+{\n+  char buf[8];\n+  memset (buf, 0, 8);\n+  __analyzer_eval (buf[0] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[1] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[2] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[3] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[4] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[5] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[6] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[7] == 0); /* { dg-warning \"TRUE\" } */\n+\n+  memset (buf + 1, 1, 4);  \n+  __analyzer_eval (buf[0] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[1] == 1); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[2] == 1); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[3] == 1); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[4] == 1); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[5] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[6] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[7] == 0); /* { dg-warning \"TRUE\" } */\n+\n+  memset (buf + 2, 2, 4);  \n+  __analyzer_eval (buf[0] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[1] == 1); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[2] == 2); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[3] == 2); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[4] == 2); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[5] == 2); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[6] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[7] == 0); /* { dg-warning \"TRUE\" } */\n+\n+  memset (buf + 4, 3, 3);  \n+  __analyzer_eval (buf[0] == 0); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[1] == 1); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[2] == 2); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[3] == 2); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[4] == 3); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[5] == 3); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[6] == 3); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[7] == 0); /* { dg-warning \"TRUE\" } */\n+\n+  memset (buf + 0, 4, 3);  \n+  __analyzer_eval (buf[0] == 4); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[1] == 4); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[2] == 4); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[3] == 2); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[4] == 3); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[5] == 3); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[6] == 3); /* { dg-warning \"TRUE\" } */\n+  __analyzer_eval (buf[7] == 0); /* { dg-warning \"TRUE\" } */\n }"}, {"sha": "9dd11390c4d4c0fcabd79c17c2b089792abba068", "filename": "gcc/testsuite/gcc.dg/analyzer/memset-CVE-2017-18549-1.c", "status": "added", "additions": 107, "deletions": 0, "changes": 107, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fmemset-CVE-2017-18549-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fmemset-CVE-2017-18549-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fmemset-CVE-2017-18549-1.c?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -0,0 +1,107 @@\n+/* This is a very simplified version of CVE-2017-18549,\n+   a use of uninitialized padding values affecting the Linux kernel\n+   (and thus GPLv2).\n+\n+   It was fixed by e.g. 342ffc26693b528648bdc9377e51e4f2450b4860 on linux-4.13.y\n+   in linux-stable.  */\n+\n+#include \"analyzer-decls.h\"\n+#include <string.h>\n+\n+typedef unsigned int __u32;\n+typedef unsigned int u32;\n+typedef unsigned char u8;\n+\n+/* Adapted from include/uapi/linux/types.h  */\n+\n+#define __bitwise\n+typedef __u32 __bitwise __le32;\n+\n+/* Adapted from drivers/scsi/aacraid/aacraid.h  */\n+\n+#define\t\tAAC_SENSE_BUFFERSIZE\t 30\n+\n+struct aac_srb_reply\n+{\n+\t__le32\t\tstatus;\n+\t__le32\t\tsrb_status;\n+\t__le32\t\tscsi_status;\n+\t__le32\t\tdata_xfer_length;\n+\t__le32\t\tsense_data_size;\n+\tu8\t\tsense_data[AAC_SENSE_BUFFERSIZE];\n+\n+\t/* Manually added to help verify the fix.  */\n+\tu8 padding[2];\n+};\n+\n+#define\t\tST_OK\t\t0\n+#define SRB_STATUS_SUCCESS                  0x01\n+\n+/* Adapted from drivers/scsi/aacraid/commctrl.c  */\n+\n+static int aac_send_raw_srb(/* [...snip...] */)\n+{\n+\tu32 byte_count = 0;\n+\n+\t/* [...snip...] */\n+\n+\tstruct aac_srb_reply reply;\n+\n+\treply.status = ST_OK;\n+\n+\t/* [...snip...] */\n+\n+\treply.srb_status = SRB_STATUS_SUCCESS;\n+\treply.scsi_status = 0;\n+\treply.data_xfer_length = byte_count;\n+\treply.sense_data_size = 0;\n+\tmemset(reply.sense_data, 0, AAC_SENSE_BUFFERSIZE);\n+\n+\t/* [...snip...] */\n+\n+\t__analyzer_eval (reply.status == ST_OK); /* { dg-warning \"TRUE\" } */\n+\t__analyzer_eval (reply.srb_status == SRB_STATUS_SUCCESS); /* { dg-warning \"TRUE\" } */\n+\t__analyzer_eval (reply.scsi_status == 0); /* { dg-warning \"TRUE\" } */\n+\t__analyzer_eval (reply.data_xfer_length == byte_count); /* { dg-warning \"TRUE\" } */\n+\t__analyzer_eval (reply.sense_data_size == 0); /* { dg-warning \"TRUE\" } */\n+\t__analyzer_eval (reply.sense_data[0] == 0); /* { dg-warning \"TRUE\" } */\n+\t__analyzer_eval (reply.sense_data[AAC_SENSE_BUFFERSIZE - 1] == 0); /* { dg-warning \"TRUE\" } */\n+\t/* TODO: the following should be detected as uninitialized, when\n+\t   that diagnostic is reimplemented.  */\n+\t__analyzer_eval (reply.padding[0] == 0); /* { dg-warning \"UNKNOWN\" } */\n+\t__analyzer_eval (reply.padding[1] == 0); /* { dg-warning \"UNKNOWN\" } */\n+}\n+\n+static int aac_send_raw_srb_fixed(/* [...snip...] */)\n+{\n+\tu32 byte_count = 0;\n+\n+\t/* [...snip...] */\n+\n+\tstruct aac_srb_reply reply;\n+\n+\t/* This is the fix.  */\n+\tmemset(&reply, 0, sizeof(reply));\n+\n+\treply.status = ST_OK;\n+\n+\t/* [...snip...] */\n+\n+\treply.srb_status = SRB_STATUS_SUCCESS;\n+\treply.scsi_status = 0;\n+\treply.data_xfer_length = byte_count;\n+\treply.sense_data_size = 0;\n+\tmemset(reply.sense_data, 0, AAC_SENSE_BUFFERSIZE);\n+\n+\t/* [...snip...] */\n+\n+\t__analyzer_eval (reply.status == ST_OK); /* { dg-warning \"TRUE\" } */\n+\t__analyzer_eval (reply.srb_status == SRB_STATUS_SUCCESS); /* { dg-warning \"TRUE\" } */\n+\t__analyzer_eval (reply.scsi_status == 0); /* { dg-warning \"TRUE\" } */\n+\t__analyzer_eval (reply.data_xfer_length == byte_count); /* { dg-warning \"TRUE\" } */\n+\t__analyzer_eval (reply.sense_data_size == 0); /* { dg-warning \"TRUE\" } */\n+\t__analyzer_eval (reply.sense_data[0] == 0); /* { dg-warning \"TRUE\" } */\n+\t__analyzer_eval (reply.sense_data[AAC_SENSE_BUFFERSIZE - 1] == 0); /* { dg-warning \"TRUE\" } */\n+\t__analyzer_eval (reply.padding[0] == 0); /* { dg-warning \"TRUE\" } */\n+\t__analyzer_eval (reply.padding[1] == 0); /* { dg-warning \"TRUE\" } */\n+}"}, {"sha": "f9c3596cbbcc99a3fdaad016d676736c5ef82ef6", "filename": "gcc/testsuite/gcc.dg/analyzer/symbolic-8.c", "status": "added", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fsymbolic-8.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e61ffa201403e3814a43b176883e176716b1492f/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fsymbolic-8.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fanalyzer%2Fsymbolic-8.c?ref=e61ffa201403e3814a43b176883e176716b1492f", "patch": "@@ -0,0 +1,11 @@\n+/* Merger where \"arr\" has two different symbolic bindings.  */\n+\n+void test (int i, int j, int flag)\n+{\n+  int arr[16];\n+\n+  if (flag)\n+    arr[i] = 42;\n+  else\n+    arr[j] = 17;\n+}"}]}