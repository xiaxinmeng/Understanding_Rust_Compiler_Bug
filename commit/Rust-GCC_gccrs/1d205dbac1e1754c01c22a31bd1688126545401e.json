{"sha": "1d205dbac1e1754c01c22a31bd1688126545401e", "node_id": "C_kwDOANBUbNoAKDFkMjA1ZGJhYzFlMTc1NGMwMWMyMmEzMWJkMTY4ODEyNjU0NTQwMWU", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2022-06-13T14:24:34Z"}, "committer": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2022-06-13T14:24:34Z"}, "message": "Factor out common internal-fn idiom\n\ninternal-fn.c has quite a few functions that simply map the result\nof the call to an instruction's output operand (if any) and map\neach argument to an instruction's input operand, in order.\nThis patch adds a single function for doing that.  It's really\njust a generalisation of expand_direct_optab_fn, but with the\noutput operand being optional.\n\nUnfortunately, it isn't possible to do this for vcond_mask\nbecause the internal function has a different argument order\nfrom the optab.\n\ngcc/\n\t* internal-fn.cc (expand_fn_using_insn): New function,\n\tsplit out and adapted from...\n\t(expand_direct_optab_fn): ...here.\n\t(expand_GOMP_SIMT_ENTER_ALLOC): Use it.\n\t(expand_GOMP_SIMT_EXIT): Likewise.\n\t(expand_GOMP_SIMT_LANE): Likewise.\n\t(expand_GOMP_SIMT_LAST_LANE): Likewise.\n\t(expand_GOMP_SIMT_ORDERED_PRED): Likewise.\n\t(expand_GOMP_SIMT_VOTE_ANY): Likewise.\n\t(expand_GOMP_SIMT_XCHG_BFLY): Likewise.\n\t(expand_GOMP_SIMT_XCHG_IDX): Likewise.", "tree": {"sha": "94f2e793d54ffe545492387b20b4c5b59298ce6f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/94f2e793d54ffe545492387b20b4c5b59298ce6f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/1d205dbac1e1754c01c22a31bd1688126545401e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1d205dbac1e1754c01c22a31bd1688126545401e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1d205dbac1e1754c01c22a31bd1688126545401e", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1d205dbac1e1754c01c22a31bd1688126545401e/comments", "author": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "e55eda238545e93708c020fd21249459be64c463", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e55eda238545e93708c020fd21249459be64c463", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e55eda238545e93708c020fd21249459be64c463"}], "stats": {"total": 243, "additions": 89, "deletions": 154}, "files": [{"sha": "ab2b1baa893b5c50cc088e92d1869e037b737ac9", "filename": "gcc/internal-fn.cc", "status": "modified", "additions": 89, "deletions": 154, "changes": 243, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1d205dbac1e1754c01c22a31bd1688126545401e/gcc%2Finternal-fn.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1d205dbac1e1754c01c22a31bd1688126545401e/gcc%2Finternal-fn.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Finternal-fn.cc?ref=1d205dbac1e1754c01c22a31bd1688126545401e", "patch": "@@ -140,6 +140,86 @@ const direct_internal_fn_info direct_internal_fn_array[IFN_LAST + 1] = {\n   not_direct\n };\n \n+/* Expand STMT using instruction ICODE.  The instruction has NOUTPUTS\n+   output operands and NINPUTS input operands, where NOUTPUTS is either\n+   0 or 1.  The output operand (if any) comes first, followed by the\n+   NINPUTS input operands.  */\n+\n+static void\n+expand_fn_using_insn (gcall *stmt, insn_code icode, unsigned int noutputs,\n+\t\t      unsigned int ninputs)\n+{\n+  gcc_assert (icode != CODE_FOR_nothing);\n+\n+  expand_operand *ops = XALLOCAVEC (expand_operand, noutputs + ninputs);\n+  unsigned int opno = 0;\n+  rtx lhs_rtx = NULL_RTX;\n+  tree lhs = gimple_call_lhs (stmt);\n+\n+  if (noutputs)\n+    {\n+      gcc_assert (noutputs == 1);\n+      if (lhs)\n+\tlhs_rtx = expand_expr (lhs, NULL_RTX, VOIDmode, EXPAND_WRITE);\n+\n+      /* Do not assign directly to a promoted subreg, since there is no\n+\t guarantee that the instruction will leave the upper bits of the\n+\t register in the state required by SUBREG_PROMOTED_SIGN.  */\n+      rtx dest = lhs_rtx;\n+      if (dest && GET_CODE (dest) == SUBREG && SUBREG_PROMOTED_VAR_P (dest))\n+\tdest = NULL_RTX;\n+      create_output_operand (&ops[opno], dest,\n+\t\t\t     insn_data[icode].operand[opno].mode);\n+      opno += 1;\n+    }\n+  else\n+    gcc_assert (!lhs);\n+\n+  for (unsigned int i = 0; i < ninputs; ++i)\n+    {\n+      tree rhs = gimple_call_arg (stmt, i);\n+      tree rhs_type = TREE_TYPE (rhs);\n+      rtx rhs_rtx = expand_normal (rhs);\n+      if (INTEGRAL_TYPE_P (rhs_type))\n+\tcreate_convert_operand_from (&ops[opno], rhs_rtx,\n+\t\t\t\t     TYPE_MODE (rhs_type),\n+\t\t\t\t     TYPE_UNSIGNED (rhs_type));\n+      else\n+\tcreate_input_operand (&ops[opno], rhs_rtx, TYPE_MODE (rhs_type));\n+      opno += 1;\n+    }\n+\n+  gcc_assert (opno == noutputs + ninputs);\n+  expand_insn (icode, opno, ops);\n+  if (lhs_rtx && !rtx_equal_p (lhs_rtx, ops[0].value))\n+    {\n+      /* If the return value has an integral type, convert the instruction\n+\t result to that type.  This is useful for things that return an\n+\t int regardless of the size of the input.  If the instruction result\n+\t is smaller than required, assume that it is signed.\n+\n+\t If the return value has a nonintegral type, its mode must match\n+\t the instruction result.  */\n+      if (GET_CODE (lhs_rtx) == SUBREG && SUBREG_PROMOTED_VAR_P (lhs_rtx))\n+\t{\n+\t  /* If this is a scalar in a register that is stored in a wider\n+\t     mode than the declared mode, compute the result into its\n+\t     declared mode and then convert to the wider mode.  */\n+\t  gcc_checking_assert (INTEGRAL_TYPE_P (TREE_TYPE (lhs)));\n+\t  rtx tmp = convert_to_mode (GET_MODE (lhs_rtx), ops[0].value, 0);\n+\t  convert_move (SUBREG_REG (lhs_rtx), tmp,\n+\t\t\tSUBREG_PROMOTED_SIGN (lhs_rtx));\n+\t}\n+      else if (GET_MODE (lhs_rtx) == GET_MODE (ops[0].value))\n+\temit_move_insn (lhs_rtx, ops[0].value);\n+      else\n+\t{\n+\t  gcc_checking_assert (INTEGRAL_TYPE_P (TREE_TYPE (lhs)));\n+\t  convert_move (lhs_rtx, ops[0].value, 0);\n+\t}\n+    }\n+}\n+\n /* ARRAY_TYPE is an array of vector modes.  Return the associated insn\n    for load-lanes-style optab OPTAB, or CODE_FOR_nothing if none.  */\n \n@@ -233,35 +313,17 @@ expand_GOMP_SIMT_ENTER (internal_fn, gcall *)\n static void\n expand_GOMP_SIMT_ENTER_ALLOC (internal_fn, gcall *stmt)\n {\n-  rtx target;\n-  tree lhs = gimple_call_lhs (stmt);\n-  if (lhs)\n-    target = expand_expr (lhs, NULL_RTX, VOIDmode, EXPAND_WRITE);\n-  else\n-    target = gen_reg_rtx (Pmode);\n-  rtx size = expand_normal (gimple_call_arg (stmt, 0));\n-  rtx align = expand_normal (gimple_call_arg (stmt, 1));\n-  class expand_operand ops[3];\n-  create_output_operand (&ops[0], target, Pmode);\n-  create_input_operand (&ops[1], size, Pmode);\n-  create_input_operand (&ops[2], align, Pmode);\n   gcc_assert (targetm.have_omp_simt_enter ());\n-  expand_insn (targetm.code_for_omp_simt_enter, 3, ops);\n-  if (!rtx_equal_p (target, ops[0].value))\n-    emit_move_insn (target, ops[0].value);\n+  expand_fn_using_insn (stmt, targetm.code_for_omp_simt_enter, 1, 2);\n }\n \n /* Deallocate per-lane storage and leave non-uniform execution region.  */\n \n static void\n expand_GOMP_SIMT_EXIT (internal_fn, gcall *stmt)\n {\n-  gcc_checking_assert (!gimple_call_lhs (stmt));\n-  rtx arg = expand_normal (gimple_call_arg (stmt, 0));\n-  class expand_operand ops[1];\n-  create_input_operand (&ops[0], arg, Pmode);\n   gcc_assert (targetm.have_omp_simt_exit ());\n-  expand_insn (targetm.code_for_omp_simt_exit, 1, ops);\n+  expand_fn_using_insn (stmt, targetm.code_for_omp_simt_exit, 0, 1);\n }\n \n /* Lane index on SIMT targets: thread index in the warp on NVPTX.  On targets\n@@ -270,13 +332,8 @@ expand_GOMP_SIMT_EXIT (internal_fn, gcall *stmt)\n static void\n expand_GOMP_SIMT_LANE (internal_fn, gcall *stmt)\n {\n-  tree lhs = gimple_call_lhs (stmt);\n-  if (!lhs)\n-    return;\n-\n-  rtx target = expand_expr (lhs, NULL_RTX, VOIDmode, EXPAND_WRITE);\n   gcc_assert (targetm.have_omp_simt_lane ());\n-  emit_insn (targetm.gen_omp_simt_lane (target));\n+  expand_fn_using_insn (stmt, targetm.code_for_omp_simt_lane, 1, 0);\n }\n \n /* This should get expanded in omp_device_lower pass.  */\n@@ -294,41 +351,17 @@ expand_GOMP_SIMT_VF (internal_fn, gcall *)\n static void\n expand_GOMP_SIMT_LAST_LANE (internal_fn, gcall *stmt)\n {\n-  tree lhs = gimple_call_lhs (stmt);\n-  if (!lhs)\n-    return;\n-\n-  rtx target = expand_expr (lhs, NULL_RTX, VOIDmode, EXPAND_WRITE);\n-  rtx cond = expand_normal (gimple_call_arg (stmt, 0));\n-  machine_mode mode = TYPE_MODE (TREE_TYPE (lhs));\n-  class expand_operand ops[2];\n-  create_output_operand (&ops[0], target, mode);\n-  create_input_operand (&ops[1], cond, mode);\n   gcc_assert (targetm.have_omp_simt_last_lane ());\n-  expand_insn (targetm.code_for_omp_simt_last_lane, 2, ops);\n-  if (!rtx_equal_p (target, ops[0].value))\n-    emit_move_insn (target, ops[0].value);\n+  expand_fn_using_insn (stmt, targetm.code_for_omp_simt_last_lane, 1, 1);\n }\n \n /* Non-transparent predicate used in SIMT lowering of OpenMP \"ordered\".  */\n \n static void\n expand_GOMP_SIMT_ORDERED_PRED (internal_fn, gcall *stmt)\n {\n-  tree lhs = gimple_call_lhs (stmt);\n-  if (!lhs)\n-    return;\n-\n-  rtx target = expand_expr (lhs, NULL_RTX, VOIDmode, EXPAND_WRITE);\n-  rtx ctr = expand_normal (gimple_call_arg (stmt, 0));\n-  machine_mode mode = TYPE_MODE (TREE_TYPE (lhs));\n-  class expand_operand ops[2];\n-  create_output_operand (&ops[0], target, mode);\n-  create_input_operand (&ops[1], ctr, mode);\n   gcc_assert (targetm.have_omp_simt_ordered ());\n-  expand_insn (targetm.code_for_omp_simt_ordered, 2, ops);\n-  if (!rtx_equal_p (target, ops[0].value))\n-    emit_move_insn (target, ops[0].value);\n+  expand_fn_using_insn (stmt, targetm.code_for_omp_simt_ordered, 1, 1);\n }\n \n /* \"Or\" boolean reduction across SIMT lanes: return non-zero in all lanes if\n@@ -337,20 +370,8 @@ expand_GOMP_SIMT_ORDERED_PRED (internal_fn, gcall *stmt)\n static void\n expand_GOMP_SIMT_VOTE_ANY (internal_fn, gcall *stmt)\n {\n-  tree lhs = gimple_call_lhs (stmt);\n-  if (!lhs)\n-    return;\n-\n-  rtx target = expand_expr (lhs, NULL_RTX, VOIDmode, EXPAND_WRITE);\n-  rtx cond = expand_normal (gimple_call_arg (stmt, 0));\n-  machine_mode mode = TYPE_MODE (TREE_TYPE (lhs));\n-  class expand_operand ops[2];\n-  create_output_operand (&ops[0], target, mode);\n-  create_input_operand (&ops[1], cond, mode);\n   gcc_assert (targetm.have_omp_simt_vote_any ());\n-  expand_insn (targetm.code_for_omp_simt_vote_any, 2, ops);\n-  if (!rtx_equal_p (target, ops[0].value))\n-    emit_move_insn (target, ops[0].value);\n+  expand_fn_using_insn (stmt, targetm.code_for_omp_simt_vote_any, 1, 1);\n }\n \n /* Exchange between SIMT lanes with a \"butterfly\" pattern: source lane index\n@@ -359,45 +380,17 @@ expand_GOMP_SIMT_VOTE_ANY (internal_fn, gcall *stmt)\n static void\n expand_GOMP_SIMT_XCHG_BFLY (internal_fn, gcall *stmt)\n {\n-  tree lhs = gimple_call_lhs (stmt);\n-  if (!lhs)\n-    return;\n-\n-  rtx target = expand_expr (lhs, NULL_RTX, VOIDmode, EXPAND_WRITE);\n-  rtx src = expand_normal (gimple_call_arg (stmt, 0));\n-  rtx idx = expand_normal (gimple_call_arg (stmt, 1));\n-  machine_mode mode = TYPE_MODE (TREE_TYPE (lhs));\n-  class expand_operand ops[3];\n-  create_output_operand (&ops[0], target, mode);\n-  create_input_operand (&ops[1], src, mode);\n-  create_input_operand (&ops[2], idx, SImode);\n   gcc_assert (targetm.have_omp_simt_xchg_bfly ());\n-  expand_insn (targetm.code_for_omp_simt_xchg_bfly, 3, ops);\n-  if (!rtx_equal_p (target, ops[0].value))\n-    emit_move_insn (target, ops[0].value);\n+  expand_fn_using_insn (stmt, targetm.code_for_omp_simt_xchg_bfly, 1, 2);\n }\n \n /* Exchange between SIMT lanes according to given source lane index.  */\n \n static void\n expand_GOMP_SIMT_XCHG_IDX (internal_fn, gcall *stmt)\n {\n-  tree lhs = gimple_call_lhs (stmt);\n-  if (!lhs)\n-    return;\n-\n-  rtx target = expand_expr (lhs, NULL_RTX, VOIDmode, EXPAND_WRITE);\n-  rtx src = expand_normal (gimple_call_arg (stmt, 0));\n-  rtx idx = expand_normal (gimple_call_arg (stmt, 1));\n-  machine_mode mode = TYPE_MODE (TREE_TYPE (lhs));\n-  class expand_operand ops[3];\n-  create_output_operand (&ops[0], target, mode);\n-  create_input_operand (&ops[1], src, mode);\n-  create_input_operand (&ops[2], idx, SImode);\n   gcc_assert (targetm.have_omp_simt_xchg_idx ());\n-  expand_insn (targetm.code_for_omp_simt_xchg_idx, 3, ops);\n-  if (!rtx_equal_p (target, ops[0].value))\n-    emit_move_insn (target, ops[0].value);\n+  expand_fn_using_insn (stmt, targetm.code_for_omp_simt_xchg_idx, 1, 2);\n }\n \n /* This should get expanded in adjust_simduid_builtins.  */\n@@ -3565,67 +3558,9 @@ static void\n expand_direct_optab_fn (internal_fn fn, gcall *stmt, direct_optab optab,\n \t\t\tunsigned int nargs)\n {\n-  expand_operand *ops = XALLOCAVEC (expand_operand, nargs + 1);\n-\n   tree_pair types = direct_internal_fn_types (fn, stmt);\n   insn_code icode = direct_optab_handler (optab, TYPE_MODE (types.first));\n-  gcc_assert (icode != CODE_FOR_nothing);\n-\n-  tree lhs = gimple_call_lhs (stmt);\n-  rtx lhs_rtx = NULL_RTX;\n-  if (lhs)\n-    lhs_rtx = expand_expr (lhs, NULL_RTX, VOIDmode, EXPAND_WRITE);\n-\n-  /* Do not assign directly to a promoted subreg, since there is no\n-     guarantee that the instruction will leave the upper bits of the\n-     register in the state required by SUBREG_PROMOTED_SIGN.  */\n-  rtx dest = lhs_rtx;\n-  if (dest && GET_CODE (dest) == SUBREG && SUBREG_PROMOTED_VAR_P (dest))\n-    dest = NULL_RTX;\n-\n-  create_output_operand (&ops[0], dest, insn_data[icode].operand[0].mode);\n-\n-  for (unsigned int i = 0; i < nargs; ++i)\n-    {\n-      tree rhs = gimple_call_arg (stmt, i);\n-      tree rhs_type = TREE_TYPE (rhs);\n-      rtx rhs_rtx = expand_normal (rhs);\n-      if (INTEGRAL_TYPE_P (rhs_type))\n-\tcreate_convert_operand_from (&ops[i + 1], rhs_rtx,\n-\t\t\t\t     TYPE_MODE (rhs_type),\n-\t\t\t\t     TYPE_UNSIGNED (rhs_type));\n-      else\n-\tcreate_input_operand (&ops[i + 1], rhs_rtx, TYPE_MODE (rhs_type));\n-    }\n-\n-  expand_insn (icode, nargs + 1, ops);\n-  if (lhs_rtx && !rtx_equal_p (lhs_rtx, ops[0].value))\n-    {\n-      /* If the return value has an integral type, convert the instruction\n-\t result to that type.  This is useful for things that return an\n-\t int regardless of the size of the input.  If the instruction result\n-\t is smaller than required, assume that it is signed.\n-\n-\t If the return value has a nonintegral type, its mode must match\n-\t the instruction result.  */\n-      if (GET_CODE (lhs_rtx) == SUBREG && SUBREG_PROMOTED_VAR_P (lhs_rtx))\n-\t{\n-\t  /* If this is a scalar in a register that is stored in a wider\n-\t     mode than the declared mode, compute the result into its\n-\t     declared mode and then convert to the wider mode.  */\n-\t  gcc_checking_assert (INTEGRAL_TYPE_P (TREE_TYPE (lhs)));\n-\t  rtx tmp = convert_to_mode (GET_MODE (lhs_rtx), ops[0].value, 0);\n-\t  convert_move (SUBREG_REG (lhs_rtx), tmp,\n-\t\t\tSUBREG_PROMOTED_SIGN (lhs_rtx));\n-\t}\n-      else if (GET_MODE (lhs_rtx) == GET_MODE (ops[0].value))\n-\temit_move_insn (lhs_rtx, ops[0].value);\n-      else\n-\t{\n-\t  gcc_checking_assert (INTEGRAL_TYPE_P (TREE_TYPE (lhs)));\n-\t  convert_move (lhs_rtx, ops[0].value, 0);\n-\t}\n-    }\n+  expand_fn_using_insn (stmt, icode, 1, nargs);\n }\n \n /* Expand WHILE_ULT call STMT using optab OPTAB.  */"}]}