{"sha": "bd610db0d52cd1e4d972ff140c091d42ef486be4", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YmQ2MTBkYjBkNTJjZDFlNGQ5NzJmZjE0MGMwOTFkNDJlZjQ4NmJlNA==", "commit": {"author": {"name": "liuhongt", "email": "hongtao.liu@intel.com", "date": "2019-03-04T21:46:01Z"}, "committer": {"name": "liuhongt", "email": "hongtao.liu@intel.com", "date": "2021-09-16T05:09:30Z"}, "message": "AVX512FP16: Add vcvtph2dq/vcvtph2qq/vcvtph2w/vcvtph2uw/vcvtph2uqq/vcvtph2udq\n\ngcc/ChangeLog:\n\n\t* config/i386/avx512fp16intrin.h (_mm512_cvtph_epi32):\n\tNew intrinsic/\n\t(_mm512_mask_cvtph_epi32): Likewise.\n\t(_mm512_maskz_cvtph_epi32): Likewise.\n\t(_mm512_cvt_roundph_epi32): Likewise.\n\t(_mm512_mask_cvt_roundph_epi32): Likewise.\n\t(_mm512_maskz_cvt_roundph_epi32): Likewise.\n\t(_mm512_cvtph_epu32): Likewise.\n\t(_mm512_mask_cvtph_epu32): Likewise.\n\t(_mm512_maskz_cvtph_epu32): Likewise.\n\t(_mm512_cvt_roundph_epu32): Likewise.\n\t(_mm512_mask_cvt_roundph_epu32): Likewise.\n\t(_mm512_maskz_cvt_roundph_epu32): Likewise.\n\t(_mm512_cvtph_epi64): Likewise.\n\t(_mm512_mask_cvtph_epi64): Likewise.\n\t(_mm512_maskz_cvtph_epi64): Likewise.\n\t(_mm512_cvt_roundph_epi64): Likewise.\n\t(_mm512_mask_cvt_roundph_epi64): Likewise.\n\t(_mm512_maskz_cvt_roundph_epi64): Likewise.\n\t(_mm512_cvtph_epu64): Likewise.\n\t(_mm512_mask_cvtph_epu64): Likewise.\n\t(_mm512_maskz_cvtph_epu64): Likewise.\n\t(_mm512_cvt_roundph_epu64): Likewise.\n\t(_mm512_mask_cvt_roundph_epu64): Likewise.\n\t(_mm512_maskz_cvt_roundph_epu64): Likewise.\n\t(_mm512_cvtph_epi16): Likewise.\n\t(_mm512_mask_cvtph_epi16): Likewise.\n\t(_mm512_maskz_cvtph_epi16): Likewise.\n\t(_mm512_cvt_roundph_epi16): Likewise.\n\t(_mm512_mask_cvt_roundph_epi16): Likewise.\n\t(_mm512_maskz_cvt_roundph_epi16): Likewise.\n\t(_mm512_cvtph_epu16): Likewise.\n\t(_mm512_mask_cvtph_epu16): Likewise.\n\t(_mm512_maskz_cvtph_epu16): Likewise.\n\t(_mm512_cvt_roundph_epu16): Likewise.\n\t(_mm512_mask_cvt_roundph_epu16): Likewise.\n\t(_mm512_maskz_cvt_roundph_epu16): Likewise.\n\t* config/i386/avx512fp16vlintrin.h (_mm_cvtph_epi32):\n\tNew intrinsic.\n\t(_mm_mask_cvtph_epi32): Likewise.\n\t(_mm_maskz_cvtph_epi32): Likewise.\n\t(_mm256_cvtph_epi32): Likewise.\n\t(_mm256_mask_cvtph_epi32): Likewise.\n\t(_mm256_maskz_cvtph_epi32): Likewise.\n\t(_mm_cvtph_epu32): Likewise.\n\t(_mm_mask_cvtph_epu32): Likewise.\n\t(_mm_maskz_cvtph_epu32): Likewise.\n\t(_mm256_cvtph_epu32): Likewise.\n\t(_mm256_mask_cvtph_epu32): Likewise.\n\t(_mm256_maskz_cvtph_epu32): Likewise.\n\t(_mm_cvtph_epi64): Likewise.\n\t(_mm_mask_cvtph_epi64): Likewise.\n\t(_mm_maskz_cvtph_epi64): Likewise.\n\t(_mm256_cvtph_epi64): Likewise.\n\t(_mm256_mask_cvtph_epi64): Likewise.\n\t(_mm256_maskz_cvtph_epi64): Likewise.\n\t(_mm_cvtph_epu64): Likewise.\n\t(_mm_mask_cvtph_epu64): Likewise.\n\t(_mm_maskz_cvtph_epu64): Likewise.\n\t(_mm256_cvtph_epu64): Likewise.\n\t(_mm256_mask_cvtph_epu64): Likewise.\n\t(_mm256_maskz_cvtph_epu64): Likewise.\n\t(_mm_cvtph_epi16): Likewise.\n\t(_mm_mask_cvtph_epi16): Likewise.\n\t(_mm_maskz_cvtph_epi16): Likewise.\n\t(_mm256_cvtph_epi16): Likewise.\n\t(_mm256_mask_cvtph_epi16): Likewise.\n\t(_mm256_maskz_cvtph_epi16): Likewise.\n\t(_mm_cvtph_epu16): Likewise.\n\t(_mm_mask_cvtph_epu16): Likewise.\n\t(_mm_maskz_cvtph_epu16): Likewise.\n\t(_mm256_cvtph_epu16): Likewise.\n\t(_mm256_mask_cvtph_epu16): Likewise.\n\t(_mm256_maskz_cvtph_epu16): Likewise.\n\t* config/i386/i386-builtin-types.def: Add new builtin types.\n\t* config/i386/i386-builtin.def: Add new builtins.\n\t* config/i386/i386-expand.c\n\t(ix86_expand_args_builtin): Handle new builtin types.\n\t(ix86_expand_round_builtin): Ditto.\n\t* config/i386/sse.md (sseintconvert): New.\n\t(ssePHmode): Ditto.\n\t(UNSPEC_US_FIX_NOTRUNC): Ditto.\n\t(sseintconvertsignprefix): Ditto.\n\t(avx512fp16_vcvtph2<sseintconvertsignprefix><sseintconvert>_<mode><mask_name><round_name>):\n\tDitto.\n\ngcc/testsuite/ChangeLog:\n\n\t* gcc.target/i386/avx-1.c: Add test for new builtins.\n\t* gcc.target/i386/sse-13.c: Ditto.\n\t* gcc.target/i386/sse-23.c: Ditto.\n\t* gcc.target/i386/sse-14.c: Add test for new intrinsics.\n\t* gcc.target/i386/sse-22.c: Ditto.", "tree": {"sha": "2a201d09c21c5e3c658e37e9e70b508bab59f0a4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/2a201d09c21c5e3c658e37e9e70b508bab59f0a4"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/bd610db0d52cd1e4d972ff140c091d42ef486be4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bd610db0d52cd1e4d972ff140c091d42ef486be4", "html_url": "https://github.com/Rust-GCC/gccrs/commit/bd610db0d52cd1e4d972ff140c091d42ef486be4", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bd610db0d52cd1e4d972ff140c091d42ef486be4/comments", "author": {"login": "algebra84", "id": 22926165, "node_id": "MDQ6VXNlcjIyOTI2MTY1", "avatar_url": "https://avatars.githubusercontent.com/u/22926165?v=4", "gravatar_id": "", "url": "https://api.github.com/users/algebra84", "html_url": "https://github.com/algebra84", "followers_url": "https://api.github.com/users/algebra84/followers", "following_url": "https://api.github.com/users/algebra84/following{/other_user}", "gists_url": "https://api.github.com/users/algebra84/gists{/gist_id}", "starred_url": "https://api.github.com/users/algebra84/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/algebra84/subscriptions", "organizations_url": "https://api.github.com/users/algebra84/orgs", "repos_url": "https://api.github.com/users/algebra84/repos", "events_url": "https://api.github.com/users/algebra84/events{/privacy}", "received_events_url": "https://api.github.com/users/algebra84/received_events", "type": "User", "site_admin": false}, "committer": {"login": "algebra84", "id": 22926165, "node_id": "MDQ6VXNlcjIyOTI2MTY1", "avatar_url": "https://avatars.githubusercontent.com/u/22926165?v=4", "gravatar_id": "", "url": "https://api.github.com/users/algebra84", "html_url": "https://github.com/algebra84", "followers_url": "https://api.github.com/users/algebra84/followers", "following_url": "https://api.github.com/users/algebra84/following{/other_user}", "gists_url": "https://api.github.com/users/algebra84/gists{/gist_id}", "starred_url": "https://api.github.com/users/algebra84/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/algebra84/subscriptions", "organizations_url": "https://api.github.com/users/algebra84/orgs", "repos_url": "https://api.github.com/users/algebra84/repos", "events_url": "https://api.github.com/users/algebra84/events{/privacy}", "received_events_url": "https://api.github.com/users/algebra84/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "6d45f45975ba887dc14f4aa3c25c17f9d1bec5f9", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6d45f45975ba887dc14f4aa3c25c17f9d1bec5f9", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6d45f45975ba887dc14f4aa3c25c17f9d1bec5f9"}], "stats": {"total": 995, "additions": 995, "deletions": 0}, "files": [{"sha": "e57f6f45e24163b193e4c33dba7894252f5f451b", "filename": "gcc/config/i386/avx512fp16intrin.h", "status": "modified", "additions": 525, "deletions": 0, "changes": 525, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Fconfig%2Fi386%2Favx512fp16intrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Fconfig%2Fi386%2Favx512fp16intrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Favx512fp16intrin.h?ref=bd610db0d52cd1e4d972ff140c091d42ef486be4", "patch": "@@ -2512,6 +2512,531 @@ _mm_maskz_move_sh (__mmask8 __A, __m128h  __B, __m128h __C)\n   return __builtin_ia32_vmovsh_mask (__B, __C, _mm_setzero_ph (), __A);\n }\n \n+/* Intrinsics vcvtph2dq.  */\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtph_epi32 (__m256h __A)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2dq512_mask_round (__A,\n+\t\t\t\t\t    (__v16si)\n+\t\t\t\t\t    _mm512_setzero_si512 (),\n+\t\t\t\t\t    (__mmask16) -1,\n+\t\t\t\t\t    _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtph_epi32 (__m512i __A, __mmask16 __B, __m256h __C)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2dq512_mask_round (__C,\n+\t\t\t\t\t    (__v16si) __A,\n+\t\t\t\t\t    __B,\n+\t\t\t\t\t    _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtph_epi32 (__mmask16 __A, __m256h __B)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2dq512_mask_round (__B,\n+\t\t\t\t\t    (__v16si)\n+\t\t\t\t\t    _mm512_setzero_si512 (),\n+\t\t\t\t\t    __A,\n+\t\t\t\t\t    _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvt_roundph_epi32 (__m256h __A, int __B)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2dq512_mask_round (__A,\n+\t\t\t\t\t    (__v16si)\n+\t\t\t\t\t    _mm512_setzero_si512 (),\n+\t\t\t\t\t    (__mmask16) -1,\n+\t\t\t\t\t    __B);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvt_roundph_epi32 (__m512i __A, __mmask16 __B, __m256h __C, int __D)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2dq512_mask_round (__C,\n+\t\t\t\t\t    (__v16si) __A,\n+\t\t\t\t\t    __B,\n+\t\t\t\t\t    __D);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvt_roundph_epi32 (__mmask16 __A, __m256h __B, int __C)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2dq512_mask_round (__B,\n+\t\t\t\t\t    (__v16si)\n+\t\t\t\t\t    _mm512_setzero_si512 (),\n+\t\t\t\t\t    __A,\n+\t\t\t\t\t    __C);\n+}\n+\n+#else\n+#define _mm512_cvt_roundph_epi32(A, B)\t\t\t\t\t\\\n+  ((__m512i)\t\t\t\t\t\t\t\t\\\n+   __builtin_ia32_vcvtph2dq512_mask_round ((A),\t\t\t\t\\\n+\t\t\t\t\t   (__v16si)\t\t\t\\\n+\t\t\t\t\t   _mm512_setzero_si512 (),\t\\\n+\t\t\t\t\t   (__mmask16)-1,\t\t\\\n+\t\t\t\t\t   (B)))\n+\n+#define _mm512_mask_cvt_roundph_epi32(A, B, C, D)\t\t\t\\\n+  ((__m512i)\t\t\t\t\t\t\t\t\\\n+   __builtin_ia32_vcvtph2dq512_mask_round ((C), (__v16si)(A), (B), (D)))\n+\n+#define _mm512_maskz_cvt_roundph_epi32(A, B, C)\t\t\t\t\\\n+  ((__m512i)\t\t\t\t\t\t\t\t\\\n+   __builtin_ia32_vcvtph2dq512_mask_round ((B),\t\t\t\t\\\n+\t\t\t\t\t   (__v16si)\t\t\t\\\n+\t\t\t\t\t   _mm512_setzero_si512 (),\t\\\n+\t\t\t\t\t   (A),\t\t\t\t\\\n+\t\t\t\t\t   (C)))\n+\n+#endif /* __OPTIMIZE__ */\n+\n+/* Intrinsics vcvtph2udq.  */\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtph_epu32 (__m256h __A)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2udq512_mask_round (__A,\n+\t\t\t\t\t     (__v16si)\n+\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t     (__mmask16) -1,\n+\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtph_epu32 (__m512i __A, __mmask16 __B, __m256h __C)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2udq512_mask_round (__C,\n+\t\t\t\t\t     (__v16si) __A,\n+\t\t\t\t\t     __B,\n+\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtph_epu32 (__mmask16 __A, __m256h __B)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2udq512_mask_round (__B,\n+\t\t\t\t\t     (__v16si)\n+\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t     __A,\n+\t\t\t\t\t     _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvt_roundph_epu32 (__m256h __A, int __B)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2udq512_mask_round (__A,\n+\t\t\t\t\t     (__v16si)\n+\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t     (__mmask16) -1,\n+\t\t\t\t\t     __B);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvt_roundph_epu32 (__m512i __A, __mmask16 __B, __m256h __C, int __D)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2udq512_mask_round (__C,\n+\t\t\t\t\t     (__v16si) __A,\n+\t\t\t\t\t     __B,\n+\t\t\t\t\t     __D);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvt_roundph_epu32 (__mmask16 __A, __m256h __B, int __C)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2udq512_mask_round (__B,\n+\t\t\t\t\t     (__v16si)\n+\t\t\t\t\t     _mm512_setzero_si512 (),\n+\t\t\t\t\t     __A,\n+\t\t\t\t\t     __C);\n+}\n+\n+#else\n+#define _mm512_cvt_roundph_epu32(A, B)\t\t\t\t\t\\\n+  ((__m512i)\t\t\t\t\t\t\t\t\\\n+   __builtin_ia32_vcvtph2udq512_mask_round ((A),\t\t\t\\\n+\t\t\t\t\t    (__v16si)\t\t\t\\\n+\t\t\t\t\t    _mm512_setzero_si512 (),\t\\\n+\t\t\t\t\t    (__mmask16)-1,\t\t\\\n+\t\t\t\t\t    (B)))\n+\n+#define _mm512_mask_cvt_roundph_epu32(A, B, C, D)\t\t\t\\\n+  ((__m512i)\t\t\t\t\t\t\t\t\\\n+   __builtin_ia32_vcvtph2udq512_mask_round ((C), (__v16si)(A), (B), (D)))\n+\n+#define _mm512_maskz_cvt_roundph_epu32(A, B, C)\t\t\t\t\\\n+  ((__m512i)\t\t\t\t\t\t\t\t\\\n+   __builtin_ia32_vcvtph2udq512_mask_round ((B),\t\t\t\\\n+\t\t\t\t\t    (__v16si)\t\t\t\\\n+\t\t\t\t\t    _mm512_setzero_si512 (),\t\\\n+\t\t\t\t\t    (A),\t\t\t\\\n+\t\t\t\t\t    (C)))\n+\n+#endif /* __OPTIMIZE__ */\n+\n+/* Intrinsics vcvtph2qq.  */\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtph_epi64 (__m128h __A)\n+{\n+  return __builtin_ia32_vcvtph2qq512_mask_round (__A,\n+\t\t\t\t\t\t _mm512_setzero_si512 (),\n+\t\t\t\t\t\t (__mmask8) -1,\n+\t\t\t\t\t\t _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtph_epi64 (__m512i __A, __mmask8 __B, __m128h __C)\n+{\n+  return __builtin_ia32_vcvtph2qq512_mask_round (__C, __A, __B,\n+\t\t\t\t\t\t _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtph_epi64 (__mmask8 __A, __m128h __B)\n+{\n+  return __builtin_ia32_vcvtph2qq512_mask_round (__B,\n+\t\t\t\t\t\t _mm512_setzero_si512 (),\n+\t\t\t\t\t\t __A,\n+\t\t\t\t\t\t _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvt_roundph_epi64 (__m128h __A, int __B)\n+{\n+  return __builtin_ia32_vcvtph2qq512_mask_round (__A,\n+\t\t\t\t\t\t _mm512_setzero_si512 (),\n+\t\t\t\t\t\t (__mmask8) -1,\n+\t\t\t\t\t\t __B);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvt_roundph_epi64 (__m512i __A, __mmask8 __B, __m128h __C, int __D)\n+{\n+  return __builtin_ia32_vcvtph2qq512_mask_round (__C, __A, __B, __D);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvt_roundph_epi64 (__mmask8 __A, __m128h __B, int __C)\n+{\n+  return __builtin_ia32_vcvtph2qq512_mask_round (__B,\n+\t\t\t\t\t\t _mm512_setzero_si512 (),\n+\t\t\t\t\t\t __A,\n+\t\t\t\t\t\t __C);\n+}\n+\n+#else\n+#define _mm512_cvt_roundph_epi64(A, B)\t\t\t\t\t\\\n+  (__builtin_ia32_vcvtph2qq512_mask_round ((A),\t\t\t\t\\\n+\t\t\t\t\t   _mm512_setzero_si512 (),\t\\\n+\t\t\t\t\t   (__mmask8)-1,\t\t\\\n+\t\t\t\t\t   (B)))\n+\n+#define _mm512_mask_cvt_roundph_epi64(A, B, C, D)\t\t\\\n+  (__builtin_ia32_vcvtph2qq512_mask_round ((C), (A), (B), (D)))\n+\n+#define _mm512_maskz_cvt_roundph_epi64(A, B, C)\t\t\t\t\\\n+  (__builtin_ia32_vcvtph2qq512_mask_round ((B),\t\t\t\t\\\n+\t\t\t\t\t   _mm512_setzero_si512 (),\t\\\n+\t\t\t\t\t   (A),\t\t\t\t\\\n+\t\t\t\t\t   (C)))\n+\n+#endif /* __OPTIMIZE__ */\n+\n+/* Intrinsics vcvtph2uqq.  */\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtph_epu64 (__m128h __A)\n+{\n+  return __builtin_ia32_vcvtph2uqq512_mask_round (__A,\n+\t\t\t\t\t\t  _mm512_setzero_si512 (),\n+\t\t\t\t\t\t  (__mmask8) -1,\n+\t\t\t\t\t\t  _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtph_epu64 (__m512i __A, __mmask8 __B, __m128h __C)\n+{\n+  return __builtin_ia32_vcvtph2uqq512_mask_round (__C, __A, __B,\n+\t\t\t\t\t\t  _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtph_epu64 (__mmask8 __A, __m128h __B)\n+{\n+  return __builtin_ia32_vcvtph2uqq512_mask_round (__B,\n+\t\t\t\t\t\t  _mm512_setzero_si512 (),\n+\t\t\t\t\t\t  __A,\n+\t\t\t\t\t\t  _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+#ifdef __OPTIMIZE__\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvt_roundph_epu64 (__m128h __A, int __B)\n+{\n+  return __builtin_ia32_vcvtph2uqq512_mask_round (__A,\n+\t\t\t\t\t\t  _mm512_setzero_si512 (),\n+\t\t\t\t\t\t  (__mmask8) -1,\n+\t\t\t\t\t\t  __B);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvt_roundph_epu64 (__m512i __A, __mmask8 __B, __m128h __C, int __D)\n+{\n+  return __builtin_ia32_vcvtph2uqq512_mask_round (__C, __A, __B, __D);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvt_roundph_epu64 (__mmask8 __A, __m128h __B, int __C)\n+{\n+  return __builtin_ia32_vcvtph2uqq512_mask_round (__B,\n+\t\t\t\t\t\t  _mm512_setzero_si512 (),\n+\t\t\t\t\t\t  __A,\n+\t\t\t\t\t\t  __C);\n+}\n+\n+#else\n+#define _mm512_cvt_roundph_epu64(A, B)\t\t\t\t\t\\\n+  (__builtin_ia32_vcvtph2uqq512_mask_round ((A),\t\t\t\\\n+\t\t\t\t\t    _mm512_setzero_si512 (),\t\\\n+\t\t\t\t\t    (__mmask8)-1,\t\t\\\n+\t\t\t\t\t    (B)))\n+\n+#define _mm512_mask_cvt_roundph_epu64(A, B, C, D)\t\t\t\\\n+  (__builtin_ia32_vcvtph2uqq512_mask_round ((C), (A), (B), (D)))\n+\n+#define _mm512_maskz_cvt_roundph_epu64(A, B, C)\t\t\t\t\\\n+  (__builtin_ia32_vcvtph2uqq512_mask_round ((B),\t\t\t\\\n+\t\t\t\t\t    _mm512_setzero_si512 (),\t\\\n+\t\t\t\t\t    (A),\t\t\t\\\n+\t\t\t\t\t    (C)))\n+\n+#endif /* __OPTIMIZE__ */\n+\n+/* Intrinsics vcvtph2w.  */\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtph_epi16 (__m512h __A)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2w512_mask_round (__A,\n+\t\t\t\t\t      (__v32hi)\n+\t\t\t\t\t      _mm512_setzero_si512 (),\n+\t\t\t\t\t      (__mmask32) -1,\n+\t\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtph_epi16 (__m512i __A, __mmask32 __B, __m512h __C)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2w512_mask_round (__C,\n+\t\t\t\t\t      (__v32hi) __A,\n+\t\t\t\t\t      __B,\n+\t\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtph_epi16 (__mmask32 __A, __m512h __B)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2w512_mask_round (__B,\n+\t\t\t\t\t      (__v32hi)\n+\t\t\t\t\t      _mm512_setzero_si512 (),\n+\t\t\t\t\t      __A,\n+\t\t\t\t\t      _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvt_roundph_epi16 (__m512h __A, int __B)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2w512_mask_round (__A,\n+\t\t\t\t\t      (__v32hi)\n+\t\t\t\t\t      _mm512_setzero_si512 (),\n+\t\t\t\t\t      (__mmask32) -1,\n+\t\t\t\t\t      __B);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvt_roundph_epi16 (__m512i __A, __mmask32 __B, __m512h __C, int __D)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2w512_mask_round (__C,\n+\t\t\t\t\t      (__v32hi) __A,\n+\t\t\t\t\t      __B,\n+\t\t\t\t\t      __D);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvt_roundph_epi16 (__mmask32 __A, __m512h __B, int __C)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2w512_mask_round (__B,\n+\t\t\t\t\t      (__v32hi)\n+\t\t\t\t\t      _mm512_setzero_si512 (),\n+\t\t\t\t\t      __A,\n+\t\t\t\t\t      __C);\n+}\n+\n+#else\n+#define _mm512_cvt_roundph_epi16(A, B)\t\t\t\t\t\\\n+  ((__m512i)__builtin_ia32_vcvtph2w512_mask_round ((A),\t\t\\\n+\t\t\t\t\t\t      (__v32hi)\t\t\\\n+\t\t\t\t\t\t      _mm512_setzero_si512 (), \\\n+\t\t\t\t\t\t      (__mmask32)-1,\t\\\n+\t\t\t\t\t\t      (B)))\n+\n+#define _mm512_mask_cvt_roundph_epi16(A, B, C, D)\t\t\t\\\n+  ((__m512i)__builtin_ia32_vcvtph2w512_mask_round ((C),\t\t\\\n+\t\t\t\t\t\t      (__v32hi)(A),\t\\\n+\t\t\t\t\t\t      (B),\t\t\\\n+\t\t\t\t\t\t      (D)))\n+\n+#define _mm512_maskz_cvt_roundph_epi16(A, B, C)\t\t\t\t\\\n+  ((__m512i)__builtin_ia32_vcvtph2w512_mask_round ((B),\t\t\\\n+\t\t\t\t\t\t      (__v32hi)\t\t\\\n+\t\t\t\t\t\t      _mm512_setzero_si512 (), \\\n+\t\t\t\t\t\t      (A),\t\t\\\n+\t\t\t\t\t\t      (C)))\n+\n+#endif /* __OPTIMIZE__ */\n+\n+/* Intrinsics vcvtph2uw.  */\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvtph_epu16 (__m512h __A)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2uw512_mask_round (__A,\n+\t\t\t\t\t       (__v32hi)\n+\t\t\t\t\t       _mm512_setzero_si512 (),\n+\t\t\t\t\t       (__mmask32) -1,\n+\t\t\t\t\t       _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvtph_epu16 (__m512i __A, __mmask32 __B, __m512h __C)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2uw512_mask_round (__C, (__v32hi) __A, __B,\n+\t\t\t\t\t       _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvtph_epu16 (__mmask32 __A, __m512h __B)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2uw512_mask_round (__B,\n+\t\t\t\t\t       (__v32hi)\n+\t\t\t\t\t       _mm512_setzero_si512 (),\n+\t\t\t\t\t       __A,\n+\t\t\t\t\t       _MM_FROUND_CUR_DIRECTION);\n+}\n+\n+#ifdef __OPTIMIZE__\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_cvt_roundph_epu16 (__m512h __A, int __B)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2uw512_mask_round (__A,\n+\t\t\t\t\t       (__v32hi)\n+\t\t\t\t\t       _mm512_setzero_si512 (),\n+\t\t\t\t\t       (__mmask32) -1,\n+\t\t\t\t\t       __B);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_mask_cvt_roundph_epu16 (__m512i __A, __mmask32 __B, __m512h __C, int __D)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2uw512_mask_round (__C, (__v32hi) __A, __B, __D);\n+}\n+\n+extern __inline __m512i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm512_maskz_cvt_roundph_epu16 (__mmask32 __A, __m512h __B, int __C)\n+{\n+  return (__m512i)\n+    __builtin_ia32_vcvtph2uw512_mask_round (__B,\n+\t\t\t\t\t       (__v32hi)\n+\t\t\t\t\t       _mm512_setzero_si512 (),\n+\t\t\t\t\t       __A,\n+\t\t\t\t\t       __C);\n+}\n+\n+#else\n+#define _mm512_cvt_roundph_epu16(A, B)\t\t\t\t\t\\\n+  ((__m512i)\t\t\t\t\t\t\t\t\\\n+   __builtin_ia32_vcvtph2uw512_mask_round ((A),\t\t\t\\\n+\t\t\t\t\t      (__v32hi)\t\t\t\\\n+\t\t\t\t\t      _mm512_setzero_si512 (),\t\\\n+\t\t\t\t\t      (__mmask32)-1, (B)))\n+\n+#define _mm512_mask_cvt_roundph_epu16(A, B, C, D)\t\t\t\\\n+  ((__m512i)\t\t\t\t\t\t\t\t\\\n+   __builtin_ia32_vcvtph2uw512_mask_round ((C), (__v32hi)(A), (B), (D)))\n+\n+#define _mm512_maskz_cvt_roundph_epu16(A, B, C)\t\t\t\t\\\n+  ((__m512i)\t\t\t\t\t\t\t\t\\\n+   __builtin_ia32_vcvtph2uw512_mask_round ((B),\t\t\t\\\n+\t\t\t\t\t      (__v32hi)\t\t\t\\\n+\t\t\t\t\t      _mm512_setzero_si512 (),\t\\\n+\t\t\t\t\t      (A),\t\t\t\\\n+\t\t\t\t\t      (C)))\n+\n+#endif /* __OPTIMIZE__ */\n+\n #ifdef __DISABLE_AVX512FP16__\n #undef __DISABLE_AVX512FP16__\n #pragma GCC pop_options"}, {"sha": "92195f2cd8181d8c895e5006ae0bbda62bb48367", "filename": "gcc/config/i386/avx512fp16vlintrin.h", "status": "modified", "additions": 345, "deletions": 0, "changes": 345, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Fconfig%2Fi386%2Favx512fp16vlintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Fconfig%2Fi386%2Favx512fp16vlintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Favx512fp16vlintrin.h?ref=bd610db0d52cd1e4d972ff140c091d42ef486be4", "patch": "@@ -930,6 +930,351 @@ _mm_maskz_getmant_ph (__mmask8 __U, __m128h __A,\n \n #endif /* __OPTIMIZE__ */\n \n+/* Intrinsics vcvtph2dq.  */\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvtph_epi32 (__m128h __A)\n+{\n+  return (__m128i)\n+    __builtin_ia32_vcvtph2dq128_mask (__A,\n+\t\t\t\t      (__v4si)\n+\t\t\t\t      _mm_setzero_si128 (),\n+\t\t\t\t      (__mmask8) -1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvtph_epi32 (__m128i __A, __mmask8 __B, __m128h __C)\n+{\n+  return (__m128i)\n+    __builtin_ia32_vcvtph2dq128_mask (__C, ( __v4si) __A, __B);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvtph_epi32 (__mmask8 __A, __m128h __B)\n+{\n+  return (__m128i)\n+    __builtin_ia32_vcvtph2dq128_mask (__B,\n+\t\t\t\t      (__v4si) _mm_setzero_si128 (),\n+\t\t\t\t      __A);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtph_epi32 (__m128h __A)\n+{\n+  return (__m256i)\n+    __builtin_ia32_vcvtph2dq256_mask (__A,\n+\t\t\t\t      (__v8si)\n+\t\t\t\t      _mm256_setzero_si256 (),\n+\t\t\t\t      (__mmask8) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvtph_epi32 (__m256i __A, __mmask8 __B, __m128h __C)\n+{\n+  return (__m256i)\n+    __builtin_ia32_vcvtph2dq256_mask (__C, ( __v8si) __A, __B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvtph_epi32 (__mmask8 __A, __m128h __B)\n+{\n+  return (__m256i)\n+    __builtin_ia32_vcvtph2dq256_mask (__B,\n+\t\t\t\t      (__v8si)\n+\t\t\t\t      _mm256_setzero_si256 (),\n+\t\t\t\t      __A);\n+}\n+\n+/* Intrinsics vcvtph2udq.  */\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvtph_epu32 (__m128h __A)\n+{\n+  return (__m128i)\n+    __builtin_ia32_vcvtph2udq128_mask (__A,\n+\t\t\t\t       (__v4si)\n+\t\t\t\t       _mm_setzero_si128 (),\n+\t\t\t\t       (__mmask8) -1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvtph_epu32 (__m128i __A, __mmask8 __B, __m128h __C)\n+{\n+  return (__m128i)\n+    __builtin_ia32_vcvtph2udq128_mask (__C, ( __v4si) __A, __B);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvtph_epu32 (__mmask8 __A, __m128h __B)\n+{\n+  return (__m128i)\n+    __builtin_ia32_vcvtph2udq128_mask (__B,\n+\t\t\t\t       (__v4si)\n+\t\t\t\t       _mm_setzero_si128 (),\n+\t\t\t\t       __A);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtph_epu32 (__m128h __A)\n+{\n+  return (__m256i)\n+    __builtin_ia32_vcvtph2udq256_mask (__A,\n+\t\t\t\t       (__v8si)\n+\t\t\t\t       _mm256_setzero_si256 (),\n+\t\t\t\t       (__mmask8) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvtph_epu32 (__m256i __A, __mmask8 __B, __m128h __C)\n+{\n+  return (__m256i)\n+    __builtin_ia32_vcvtph2udq256_mask (__C, ( __v8si) __A, __B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvtph_epu32 (__mmask8 __A, __m128h __B)\n+{\n+  return (__m256i)\n+    __builtin_ia32_vcvtph2udq256_mask (__B,\n+\t\t\t\t       (__v8si) _mm256_setzero_si256 (),\n+\t\t\t\t       __A);\n+}\n+\n+/* Intrinsics vcvtph2qq.  */\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvtph_epi64 (__m128h __A)\n+{\n+  return\n+    __builtin_ia32_vcvtph2qq128_mask (__A,\n+\t\t\t\t      _mm_setzero_si128 (),\n+\t\t\t\t      (__mmask8) -1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvtph_epi64 (__m128i __A, __mmask8 __B, __m128h __C)\n+{\n+  return __builtin_ia32_vcvtph2qq128_mask (__C, __A, __B);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvtph_epi64 (__mmask8 __A, __m128h __B)\n+{\n+  return __builtin_ia32_vcvtph2qq128_mask (__B,\n+\t\t\t\t\t   _mm_setzero_si128 (),\n+\t\t\t\t\t   __A);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtph_epi64 (__m128h __A)\n+{\n+  return __builtin_ia32_vcvtph2qq256_mask (__A,\n+\t\t\t\t\t   _mm256_setzero_si256 (),\n+\t\t\t\t\t   (__mmask8) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvtph_epi64 (__m256i __A, __mmask8 __B, __m128h __C)\n+{\n+  return __builtin_ia32_vcvtph2qq256_mask (__C, __A, __B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvtph_epi64 (__mmask8 __A, __m128h __B)\n+{\n+  return __builtin_ia32_vcvtph2qq256_mask (__B,\n+\t\t\t\t\t   _mm256_setzero_si256 (),\n+\t\t\t\t\t   __A);\n+}\n+\n+/* Intrinsics vcvtph2uqq.  */\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvtph_epu64 (__m128h __A)\n+{\n+  return __builtin_ia32_vcvtph2uqq128_mask (__A,\n+\t\t\t\t\t    _mm_setzero_si128 (),\n+\t\t\t\t\t    (__mmask8) -1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvtph_epu64 (__m128i __A, __mmask8 __B, __m128h __C)\n+{\n+  return __builtin_ia32_vcvtph2uqq128_mask (__C, __A, __B);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvtph_epu64 (__mmask8 __A, __m128h __B)\n+{\n+  return __builtin_ia32_vcvtph2uqq128_mask (__B,\n+\t\t\t\t\t    _mm_setzero_si128 (),\n+\t\t\t\t\t    __A);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtph_epu64 (__m128h __A)\n+{\n+  return __builtin_ia32_vcvtph2uqq256_mask (__A,\n+\t\t\t\t\t    _mm256_setzero_si256 (),\n+\t\t\t\t\t    (__mmask8) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvtph_epu64 (__m256i __A, __mmask8 __B, __m128h __C)\n+{\n+  return __builtin_ia32_vcvtph2uqq256_mask (__C, __A, __B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvtph_epu64 (__mmask8 __A, __m128h __B)\n+{\n+  return __builtin_ia32_vcvtph2uqq256_mask (__B,\n+\t\t\t\t\t    _mm256_setzero_si256 (),\n+\t\t\t\t\t    __A);\n+}\n+\n+/* Intrinsics vcvtph2w.  */\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvtph_epi16 (__m128h __A)\n+{\n+  return (__m128i)\n+    __builtin_ia32_vcvtph2w128_mask (__A,\n+\t\t\t\t     (__v8hi)\n+\t\t\t\t     _mm_setzero_si128 (),\n+\t\t\t\t     (__mmask8) -1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvtph_epi16 (__m128i __A, __mmask8 __B, __m128h __C)\n+{\n+  return (__m128i)\n+    __builtin_ia32_vcvtph2w128_mask (__C, ( __v8hi) __A, __B);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvtph_epi16 (__mmask8 __A, __m128h __B)\n+{\n+  return (__m128i)\n+    __builtin_ia32_vcvtph2w128_mask (__B,\n+\t\t\t\t     (__v8hi)\n+\t\t\t\t     _mm_setzero_si128 (),\n+\t\t\t\t     __A);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtph_epi16 (__m256h __A)\n+{\n+  return (__m256i)\n+    __builtin_ia32_vcvtph2w256_mask (__A,\n+\t\t\t\t     (__v16hi)\n+\t\t\t\t     _mm256_setzero_si256 (),\n+\t\t\t\t     (__mmask16) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvtph_epi16 (__m256i __A, __mmask16 __B, __m256h __C)\n+{\n+  return (__m256i)\n+    __builtin_ia32_vcvtph2w256_mask (__C, ( __v16hi) __A, __B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvtph_epi16 (__mmask16 __A, __m256h __B)\n+{\n+  return (__m256i)\n+    __builtin_ia32_vcvtph2w256_mask (__B,\n+\t\t\t\t     (__v16hi)\n+\t\t\t\t     _mm256_setzero_si256 (),\n+\t\t\t\t     __A);\n+}\n+\n+/* Intrinsics vcvtph2uw.  */\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_cvtph_epu16 (__m128h __A)\n+{\n+  return (__m128i)\n+    __builtin_ia32_vcvtph2uw128_mask (__A,\n+\t\t\t\t      (__v8hi)\n+\t\t\t\t      _mm_setzero_si128 (),\n+\t\t\t\t      (__mmask8) -1);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_mask_cvtph_epu16 (__m128i __A, __mmask8 __B, __m128h __C)\n+{\n+  return (__m128i)\n+    __builtin_ia32_vcvtph2uw128_mask (__C, ( __v8hi) __A, __B);\n+}\n+\n+extern __inline __m128i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm_maskz_cvtph_epu16 (__mmask8 __A, __m128h __B)\n+{\n+  return (__m128i)\n+    __builtin_ia32_vcvtph2uw128_mask (__B,\n+\t\t\t\t      (__v8hi)\n+\t\t\t\t      _mm_setzero_si128 (),\n+\t\t\t\t      __A);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_cvtph_epu16 (__m256h __A)\n+{\n+  return (__m256i)\n+    __builtin_ia32_vcvtph2uw256_mask (__A,\n+\t\t\t\t      (__v16hi)\n+\t\t\t\t      _mm256_setzero_si256 (),\n+\t\t\t\t      (__mmask16) -1);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_mask_cvtph_epu16 (__m256i __A, __mmask16 __B, __m256h __C)\n+{\n+  return (__m256i)\n+    __builtin_ia32_vcvtph2uw256_mask (__C, ( __v16hi) __A, __B);\n+}\n+\n+extern __inline __m256i\n+__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))\n+_mm256_maskz_cvtph_epu16 (__mmask16 __A, __m256h __B)\n+{\n+  return (__m256i)\n+    __builtin_ia32_vcvtph2uw256_mask (__B,\n+\t\t\t\t      (__v16hi)\n+\t\t\t\t      _mm256_setzero_si256 (),\n+\t\t\t\t      __A);\n+}\n+\n #ifdef __DISABLE_AVX512FP16VL__\n #undef __DISABLE_AVX512FP16VL__\n #pragma GCC pop_options"}, {"sha": "87ea9dfa6a90528191f6a99d3c6697d9ded1c85c", "filename": "gcc/config/i386/i386-builtin-types.def", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Fconfig%2Fi386%2Fi386-builtin-types.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Fconfig%2Fi386%2Fi386-builtin-types.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-builtin-types.def?ref=bd610db0d52cd1e4d972ff140c091d42ef486be4", "patch": "@@ -1311,21 +1311,30 @@ DEF_FUNCTION_TYPE (SI, V32HF, INT, USI)\n DEF_FUNCTION_TYPE (V8HF, V8HF, V8HF)\n DEF_FUNCTION_TYPE (VOID, PCFLOAT16, V8HF, UQI)\n DEF_FUNCTION_TYPE (V8HF, PCFLOAT16, V8HF, UQI)\n+DEF_FUNCTION_TYPE (V2DI, V8HF, V2DI, UQI)\n+DEF_FUNCTION_TYPE (V4DI, V8HF, V4DI, UQI)\n+DEF_FUNCTION_TYPE (V4SI, V8HF, V4SI, UQI)\n+DEF_FUNCTION_TYPE (V8SI, V8HF, V8SI, UQI)\n+DEF_FUNCTION_TYPE (V8HI, V8HF, V8HI, UQI)\n DEF_FUNCTION_TYPE (V8HF, V8HF, V8HF, UQI)\n DEF_FUNCTION_TYPE (V8HF, V8HF, V8HF, INT)\n DEF_FUNCTION_TYPE (V8HF, V8HF, INT, V8HF, UQI)\n DEF_FUNCTION_TYPE (UQI, V8HF, V8HF, INT, UQI)\n DEF_FUNCTION_TYPE (V8HF, V8HF, V8HF, V8HF, UQI)\n DEF_FUNCTION_TYPE (UQI, V8HF, V8HF, INT, UQI, INT)\n+DEF_FUNCTION_TYPE (V8DI, V8HF, V8DI, UQI, INT)\n DEF_FUNCTION_TYPE (V8HF, V8HF, V8HF, V8HF, UQI, INT)\n DEF_FUNCTION_TYPE (V8HF, V8HF, V8HF, INT, V8HF, UQI, INT)\n DEF_FUNCTION_TYPE (V16HF, V16HF, V16HF)\n+DEF_FUNCTION_TYPE (V16HI, V16HF, V16HI, UHI)\n DEF_FUNCTION_TYPE (V16HF, V16HF, V16HF, UHI)\n+DEF_FUNCTION_TYPE (V16SI, V16HF, V16SI, UHI, INT)\n DEF_FUNCTION_TYPE (V16HF, V16HF, INT, V16HF, UHI)\n DEF_FUNCTION_TYPE (UHI, V16HF, V16HF, INT, UHI)\n DEF_FUNCTION_TYPE (V16HF, V16HF, V16HF, V16HF, UHI)\n DEF_FUNCTION_TYPE (V32HF, V32HF, V32HF, USI)\n DEF_FUNCTION_TYPE (V32HF, V32HF, V32HF, INT)\n+DEF_FUNCTION_TYPE (V32HI, V32HF, V32HI, USI, INT)\n DEF_FUNCTION_TYPE (USI, V32HF, V32HF, INT, USI)\n DEF_FUNCTION_TYPE (V32HF, V32HF, V32HF, USI, INT)\n DEF_FUNCTION_TYPE (V32HF, V32HF, V32HF, V32HF, USI)"}, {"sha": "6381653ecd2c5b6635e60187f7e55c850f799428", "filename": "gcc/config/i386/i386-builtin.def", "status": "modified", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Fconfig%2Fi386%2Fi386-builtin.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Fconfig%2Fi386%2Fi386-builtin.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-builtin.def?ref=bd610db0d52cd1e4d972ff140c091d42ef486be4", "patch": "@@ -2831,6 +2831,18 @@ BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp1\n BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512vl_getmantv16hf_mask, \"__builtin_ia32_getmantph256_mask\", IX86_BUILTIN_GETMANTPH256, UNKNOWN, (int) V16HF_FTYPE_V16HF_INT_V16HF_UHI)\n BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_getmantv8hf_mask, \"__builtin_ia32_getmantph128_mask\", IX86_BUILTIN_GETMANTPH128, UNKNOWN, (int) V8HF_FTYPE_V8HF_INT_V8HF_UQI)\n BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512f_movhf_mask, \"__builtin_ia32_vmovsh_mask\", IX86_BUILTIN_VMOVSH_MASK, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2dq_v4si_mask, \"__builtin_ia32_vcvtph2dq128_mask\", IX86_BUILTIN_VCVTPH2DQ128_MASK, UNKNOWN, (int) V4SI_FTYPE_V8HF_V4SI_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2dq_v8si_mask, \"__builtin_ia32_vcvtph2dq256_mask\", IX86_BUILTIN_VCVTPH2DQ256_MASK, UNKNOWN, (int) V8SI_FTYPE_V8HF_V8SI_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2udq_v4si_mask, \"__builtin_ia32_vcvtph2udq128_mask\", IX86_BUILTIN_VCVTPH2UDQ128_MASK, UNKNOWN, (int) V4SI_FTYPE_V8HF_V4SI_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2udq_v8si_mask, \"__builtin_ia32_vcvtph2udq256_mask\", IX86_BUILTIN_VCVTPH2UDQ256_MASK, UNKNOWN, (int) V8SI_FTYPE_V8HF_V8SI_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2qq_v2di_mask, \"__builtin_ia32_vcvtph2qq128_mask\", IX86_BUILTIN_VCVTPH2QQ128_MASK, UNKNOWN, (int) V2DI_FTYPE_V8HF_V2DI_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2qq_v4di_mask, \"__builtin_ia32_vcvtph2qq256_mask\", IX86_BUILTIN_VCVTPH2QQ256_MASK, UNKNOWN, (int) V4DI_FTYPE_V8HF_V4DI_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2uqq_v2di_mask, \"__builtin_ia32_vcvtph2uqq128_mask\", IX86_BUILTIN_VCVTPH2UQQ128_MASK, UNKNOWN, (int) V2DI_FTYPE_V8HF_V2DI_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2uqq_v4di_mask, \"__builtin_ia32_vcvtph2uqq256_mask\", IX86_BUILTIN_VCVTPH2UQQ256_MASK, UNKNOWN, (int) V4DI_FTYPE_V8HF_V4DI_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2w_v8hi_mask, \"__builtin_ia32_vcvtph2w128_mask\", IX86_BUILTIN_VCVTPH2W128_MASK, UNKNOWN, (int) V8HI_FTYPE_V8HF_V8HI_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2w_v16hi_mask, \"__builtin_ia32_vcvtph2w256_mask\", IX86_BUILTIN_VCVTPH2W256_MASK, UNKNOWN, (int) V16HI_FTYPE_V16HF_V16HI_UHI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2uw_v8hi_mask, \"__builtin_ia32_vcvtph2uw128_mask\", IX86_BUILTIN_VCVTPH2UW128_MASK, UNKNOWN, (int) V8HI_FTYPE_V8HF_V8HI_UQI)\n+BDESC (OPTION_MASK_ISA_AVX512VL, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2uw_v16hi_mask, \"__builtin_ia32_vcvtph2uw256_mask\", IX86_BUILTIN_VCVTPH2UW256_MASK, UNKNOWN, (int) V16HI_FTYPE_V16HF_V16HI_UHI)\n \n /* Builtins with rounding support.  */\n BDESC_END (ARGS, ROUND_ARGS)\n@@ -3058,6 +3070,12 @@ BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_getexpv32hf_mask_round,\n BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512f_sgetexpv8hf_mask_round, \"__builtin_ia32_getexpsh_mask_round\", IX86_BUILTIN_GETEXPSH_MASK_ROUND, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_V8HF_UQI_INT)\n BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512bw_getmantv32hf_mask_round, \"__builtin_ia32_getmantph512_mask\", IX86_BUILTIN_GETMANTPH512, UNKNOWN, (int) V32HF_FTYPE_V32HF_INT_V32HF_USI_INT)\n BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512f_vgetmantv8hf_mask_round, \"__builtin_ia32_getmantsh_mask_round\", IX86_BUILTIN_GETMANTSH_MASK_ROUND, UNKNOWN, (int) V8HF_FTYPE_V8HF_V8HF_INT_V8HF_UQI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2dq_v16si_mask_round, \"__builtin_ia32_vcvtph2dq512_mask_round\", IX86_BUILTIN_VCVTPH2DQ512_MASK_ROUND, UNKNOWN, (int) V16SI_FTYPE_V16HF_V16SI_UHI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2udq_v16si_mask_round, \"__builtin_ia32_vcvtph2udq512_mask_round\", IX86_BUILTIN_VCVTPH2UDQ512_MASK_ROUND, UNKNOWN, (int) V16SI_FTYPE_V16HF_V16SI_UHI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2qq_v8di_mask_round, \"__builtin_ia32_vcvtph2qq512_mask_round\", IX86_BUILTIN_VCVTPH2QQ512_MASK_ROUND, UNKNOWN, (int) V8DI_FTYPE_V8HF_V8DI_UQI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2uqq_v8di_mask_round, \"__builtin_ia32_vcvtph2uqq512_mask_round\", IX86_BUILTIN_VCVTPH2UQQ512_MASK_ROUND, UNKNOWN, (int) V8DI_FTYPE_V8HF_V8DI_UQI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2w_v32hi_mask_round, \"__builtin_ia32_vcvtph2w512_mask_round\", IX86_BUILTIN_VCVTPH2W512_MASK_ROUND, UNKNOWN, (int) V32HI_FTYPE_V32HF_V32HI_USI_INT)\n+BDESC (0, OPTION_MASK_ISA2_AVX512FP16, CODE_FOR_avx512fp16_vcvtph2uw_v32hi_mask_round, \"__builtin_ia32_vcvtph2uw512_mask_round\", IX86_BUILTIN_VCVTPH2UW512_MASK_ROUND, UNKNOWN, (int) V32HI_FTYPE_V32HF_V32HI_USI_INT)\n \n BDESC_END (ROUND_ARGS, MULTI_ARG)\n "}, {"sha": "990d013d73ca5c7bf6ac5b49f17d16b3aeafd5d0", "filename": "gcc/config/i386/i386-expand.c", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Fconfig%2Fi386%2Fi386-expand.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Fconfig%2Fi386%2Fi386-expand.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-expand.c?ref=bd610db0d52cd1e4d972ff140c091d42ef486be4", "patch": "@@ -9743,9 +9743,13 @@ ix86_expand_args_builtin (const struct builtin_description *d,\n     case V16HF_FTYPE_V16HF_V16HF_UHI:\n     case V8SF_FTYPE_V8HI_V8SF_UQI:\n     case V4SF_FTYPE_V8HI_V4SF_UQI:\n+    case V8SI_FTYPE_V8HF_V8SI_UQI:\n     case V8SI_FTYPE_V8SF_V8SI_UQI:\n     case V4SI_FTYPE_V4SF_V4SI_UQI:\n+    case V4SI_FTYPE_V8HF_V4SI_UQI:\n+    case V4DI_FTYPE_V8HF_V4DI_UQI:\n     case V4DI_FTYPE_V4SF_V4DI_UQI:\n+    case V2DI_FTYPE_V8HF_V2DI_UQI:\n     case V2DI_FTYPE_V4SF_V2DI_UQI:\n     case V8HF_FTYPE_V8HF_V8HF_UQI:\n     case V4SF_FTYPE_V4DI_V4SF_UQI:\n@@ -9756,6 +9760,7 @@ ix86_expand_args_builtin (const struct builtin_description *d,\n     case V16QI_FTYPE_V16HI_V16QI_UHI:\n     case V16QI_FTYPE_V4SI_V16QI_UQI:\n     case V16QI_FTYPE_V8SI_V16QI_UQI:\n+    case V8HI_FTYPE_V8HF_V8HI_UQI:\n     case V8HI_FTYPE_V4SI_V8HI_UQI:\n     case V8HI_FTYPE_V8SI_V8HI_UQI:\n     case V16QI_FTYPE_V2DI_V16QI_UQI:\n@@ -9813,6 +9818,7 @@ ix86_expand_args_builtin (const struct builtin_description *d,\n     case V8DI_FTYPE_DI_V8DI_UQI:\n     case V16SF_FTYPE_V8SF_V16SF_UHI:\n     case V16SI_FTYPE_V8SI_V16SI_UHI:\n+    case V16HI_FTYPE_V16HF_V16HI_UHI:\n     case V16HI_FTYPE_V16HI_V16HI_UHI:\n     case V8HI_FTYPE_V16QI_V8HI_UQI:\n     case V16HI_FTYPE_V16QI_V16HI_UHI:\n@@ -10679,7 +10685,9 @@ ix86_expand_round_builtin (const struct builtin_description *d,\n       break;\n     case V8SF_FTYPE_V8DF_V8SF_QI_INT:\n     case V8DF_FTYPE_V8DF_V8DF_QI_INT:\n+    case V32HI_FTYPE_V32HF_V32HI_USI_INT:\n     case V8SI_FTYPE_V8DF_V8SI_QI_INT:\n+    case V8DI_FTYPE_V8HF_V8DI_UQI_INT:\n     case V8DI_FTYPE_V8DF_V8DI_QI_INT:\n     case V8SF_FTYPE_V8DI_V8SF_QI_INT:\n     case V8DF_FTYPE_V8DI_V8DF_QI_INT:\n@@ -10688,6 +10696,7 @@ ix86_expand_round_builtin (const struct builtin_description *d,\n     case V8DI_FTYPE_V8SF_V8DI_QI_INT:\n     case V16SF_FTYPE_V16SI_V16SF_HI_INT:\n     case V16SI_FTYPE_V16SF_V16SI_HI_INT:\n+    case V16SI_FTYPE_V16HF_V16SI_UHI_INT:\n     case V8DF_FTYPE_V8SF_V8DF_QI_INT:\n     case V16SF_FTYPE_V16HI_V16SF_HI_INT:\n     case V2DF_FTYPE_V2DF_V2DF_V2DF_INT:"}, {"sha": "dec31f4bda382066bebc083834edfba723d45ff6", "filename": "gcc/config/i386/sse.md", "status": "modified", "additions": 35, "deletions": 0, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=bd610db0d52cd1e4d972ff140c091d42ef486be4", "patch": "@@ -738,6 +738,11 @@\n   [(V8DI \"V64QI\") (V4DI \"V32QI\") (V2DI \"V16QI\")\n    (V16SI \"V64QI\") (V8SI \"V32QI\") (V4SI \"V16QI\")])\n \n+(define_mode_attr sseintconvert\n+  [(V32HI \"w\") (V16HI \"w\") (V8HI \"w\")\n+   (V16SI \"dq\") (V8SI \"dq\") (V4SI \"dq\")\n+   (V8DI \"qq\") (V4DI \"qq\") (V2DI \"qq\")])\n+\n ;; All 128bit vector integer modes\n (define_mode_iterator VI_128 [V16QI V8HI V4SI V2DI])\n \n@@ -984,6 +989,12 @@\n    (V4SF  \"v2sf\")\n    (V32HF \"v16hf\") (V16HF \"v8hf\") (V8HF \"v4hf\")])\n \n+;; Mapping of vector modes to vector hf modes of conversion.\n+(define_mode_attr ssePHmode\n+  [(V32HI \"V32HF\") (V16HI \"V16HF\") (V8HI \"V8HF\")\n+   (V16SI \"V16HF\") (V8SI \"V8HF\") (V4SI \"V8HF\")\n+   (V8DI \"V8HF\") (V4DI \"V8HF\") (V2DI \"V8HF\")])\n+\n ;; Mapping of vector modes to packed single mode of the same size\n (define_mode_attr ssePSmode\n   [(V16SI \"V16SF\") (V8DF \"V16SF\")\n@@ -5713,6 +5724,30 @@\n   [(set_attr \"type\" \"ssemuladd\")\n    (set_attr \"mode\" \"<MODE>\")])\n \n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;;\n+;; Parallel half-precision floating point conversion operations\n+;;\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+(define_int_iterator UNSPEC_US_FIX_NOTRUNC\n+\t[UNSPEC_UNSIGNED_FIX_NOTRUNC UNSPEC_FIX_NOTRUNC])\n+\n+(define_int_attr sseintconvertsignprefix\n+\t[(UNSPEC_UNSIGNED_FIX_NOTRUNC \"u\")\n+\t (UNSPEC_FIX_NOTRUNC \"\")])\n+\n+(define_insn \"avx512fp16_vcvtph2<sseintconvertsignprefix><sseintconvert>_<mode><mask_name><round_name>\"\n+  [(set (match_operand:VI248_AVX512VL 0 \"register_operand\" \"=v\")\n+        (unspec:VI248_AVX512VL\n+\t   [(match_operand:<ssePHmode> 1 \"<round_nimm_predicate>\" \"<round_constraint>\")]\n+\t   UNSPEC_US_FIX_NOTRUNC))]\n+  \"TARGET_AVX512FP16\"\n+  \"vcvtph2<sseintconvertsignprefix><sseintconvert>\\t{<round_mask_op2>%1, %0<mask_operand2>|%0<mask_operand2>, %1<round_mask_op2>}\"\n+  [(set_attr \"type\" \"ssecvt\")\n+   (set_attr \"prefix\" \"evex\")\n+   (set_attr \"mode\" \"<sseinsnmode>\")])\n+\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n ;;\n ;; Parallel single-precision floating point conversion operations"}, {"sha": "1214a7d0b2f87356d43dff63c94efd3da0a2fd42", "filename": "gcc/testsuite/gcc.target/i386/avx-1.c", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Favx-1.c?ref=bd610db0d52cd1e4d972ff140c091d42ef486be4", "patch": "@@ -719,6 +719,12 @@\n #define __builtin_ia32_getexpsh_mask_round(A, B, C, D, E) __builtin_ia32_getexpsh_mask_round(A, B, C, D, 4)\n #define __builtin_ia32_getmantph512_mask(A, F, C, D, E) __builtin_ia32_getmantph512_mask(A, 1, C, D, 8)\n #define __builtin_ia32_getmantsh_mask_round(A, B, C, W, U, D) __builtin_ia32_getmantsh_mask_round(A, B, 1, W, U, 4)\n+#define __builtin_ia32_vcvtph2dq512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2dq512_mask_round(A, B, C, 8)\n+#define __builtin_ia32_vcvtph2udq512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2udq512_mask_round(A, B, C, 8)\n+#define __builtin_ia32_vcvtph2qq512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2qq512_mask_round(A, B, C, 8)\n+#define __builtin_ia32_vcvtph2uqq512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2uqq512_mask_round(A, B, C, 8)\n+#define __builtin_ia32_vcvtph2w512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2w512_mask_round(A, B, C, 8)\n+#define __builtin_ia32_vcvtph2uw512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2uw512_mask_round(A, B, C, 8)\n \n /* avx512fp16vlintrin.h */\n #define __builtin_ia32_cmpph128_mask(A, B, C, D) __builtin_ia32_cmpph128_mask(A, B, 1, D)"}, {"sha": "21fb919c919a96d76050f14fc58c2c2ef4d10810", "filename": "gcc/testsuite/gcc.target/i386/sse-13.c", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-13.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-13.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-13.c?ref=bd610db0d52cd1e4d972ff140c091d42ef486be4", "patch": "@@ -736,6 +736,12 @@\n #define __builtin_ia32_getexpsh_mask_round(A, B, C, D, E) __builtin_ia32_getexpsh_mask_round(A, B, C, D, 4)\n #define __builtin_ia32_getmantph512_mask(A, F, C, D, E) __builtin_ia32_getmantph512_mask(A, 1, C, D, 8)\n #define __builtin_ia32_getmantsh_mask_round(A, B, C, W, U, D) __builtin_ia32_getmantsh_mask_round(A, B, 1, W, U, 4)\n+#define __builtin_ia32_vcvtph2dq512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2dq512_mask_round(A, B, C, 8)\n+#define __builtin_ia32_vcvtph2udq512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2udq512_mask_round(A, B, C, 8)\n+#define __builtin_ia32_vcvtph2qq512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2qq512_mask_round(A, B, C, 8)\n+#define __builtin_ia32_vcvtph2uqq512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2uqq512_mask_round(A, B, C, 8)\n+#define __builtin_ia32_vcvtph2w512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2w512_mask_round(A, B, C, 8)\n+#define __builtin_ia32_vcvtph2uw512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2uw512_mask_round(A, B, C, 8)\n \n /* avx512fp16vlintrin.h */\n #define __builtin_ia32_cmpph128_mask(A, B, C, D) __builtin_ia32_cmpph128_mask(A, B, 1, D)"}, {"sha": "32aa4518703591dc5d4186eb1be8a4e3f41c73ea", "filename": "gcc/testsuite/gcc.target/i386/sse-14.c", "status": "modified", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-14.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-14.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-14.c?ref=bd610db0d52cd1e4d972ff140c091d42ef486be4", "patch": "@@ -678,6 +678,12 @@ test_1 (_mm_roundscale_ph, __m128h, __m128h, 123)\n test_1 (_mm256_roundscale_ph, __m256h, __m256h, 123)\n test_1 (_mm512_roundscale_ph, __m512h, __m512h, 123)\n test_1 (_mm512_getexp_round_ph, __m512h, __m512h, 8)\n+test_1 (_mm512_cvt_roundph_epi16, __m512i, __m512h, 8)\n+test_1 (_mm512_cvt_roundph_epu16, __m512i, __m512h, 8)\n+test_1 (_mm512_cvt_roundph_epi32, __m512i, __m256h, 8)\n+test_1 (_mm512_cvt_roundph_epu32, __m512i, __m256h, 8)\n+test_1 (_mm512_cvt_roundph_epi64, __m512i, __m128h, 8)\n+test_1 (_mm512_cvt_roundph_epu64, __m512i, __m128h, 8)\n test_1x (_mm512_reduce_round_ph, __m512h, __m512h, 123, 8)\n test_1x (_mm512_roundscale_round_ph, __m512h, __m512h, 123, 8)\n test_1x (_mm512_getmant_ph, __m512h, __m512h, 1, 1)\n@@ -710,6 +716,12 @@ test_2 (_mm512_maskz_roundscale_ph, __m512h, __mmask32, __m512h, 123)\n test_2 (_mm_roundscale_sh, __m128h, __m128h, __m128h, 123)\n test_2 (_mm512_maskz_getexp_round_ph, __m512h, __mmask32, __m512h, 8)\n test_2 (_mm_getexp_round_sh, __m128h, __m128h, __m128h, 8)\n+test_2 (_mm512_maskz_cvt_roundph_epi16, __m512i, __mmask32, __m512h, 8)\n+test_2 (_mm512_maskz_cvt_roundph_epu16, __m512i, __mmask32, __m512h, 8)\n+test_2 (_mm512_maskz_cvt_roundph_epi32, __m512i, __mmask16, __m256h, 8)\n+test_2 (_mm512_maskz_cvt_roundph_epu32, __m512i, __mmask16, __m256h, 8)\n+test_2 (_mm512_maskz_cvt_roundph_epi64, __m512i, __mmask8, __m128h, 8)\n+test_2 (_mm512_maskz_cvt_roundph_epu64, __m512i, __mmask8, __m128h, 8)\n test_2x (_mm512_cmp_round_ph_mask, __mmask32, __m512h, __m512h, 1, 8)\n test_2x (_mm_cmp_round_sh_mask, __mmask8, __m128h, __m128h, 1, 8)\n test_2x (_mm_comi_round_sh, int, __m128h, __m128h, 1, 8)\n@@ -748,6 +760,12 @@ test_3 (_mm512_mask_roundscale_ph, __m512h, __m512h, __mmask32, __m512h, 123)\n test_3 (_mm_maskz_roundscale_sh, __m128h, __mmask8, __m128h, __m128h, 123)\n test_3 (_mm_maskz_getexp_round_sh, __m128h, __mmask8, __m128h, __m128h, 8)\n test_3 (_mm512_mask_getexp_round_ph, __m512h, __m512h, __mmask32, __m512h, 8)\n+test_3 (_mm512_mask_cvt_roundph_epi16, __m512i, __m512i, __mmask32, __m512h, 8)\n+test_3 (_mm512_mask_cvt_roundph_epu16, __m512i, __m512i, __mmask32, __m512h, 8)\n+test_3 (_mm512_mask_cvt_roundph_epi32, __m512i, __m512i, __mmask16, __m256h, 8)\n+test_3 (_mm512_mask_cvt_roundph_epu32, __m512i, __m512i, __mmask16, __m256h, 8)\n+test_3 (_mm512_mask_cvt_roundph_epi64, __m512i, __m512i, __mmask8, __m128h, 8)\n+test_3 (_mm512_mask_cvt_roundph_epu64, __m512i, __m512i, __mmask8, __m128h, 8)\n test_3x (_mm512_mask_cmp_round_ph_mask, __mmask32, __mmask32, __m512h, __m512h, 1, 8)\n test_3x (_mm_mask_cmp_round_sh_mask, __mmask8, __mmask8, __m128h, __m128h, 1, 8)\n test_3x (_mm512_mask_reduce_round_ph, __m512h, __m512h, __mmask32, __m512h, 123, 8)"}, {"sha": "44ac10d602fa4ccd901cc826dd1523b27ad9e6ac", "filename": "gcc/testsuite/gcc.target/i386/sse-22.c", "status": "modified", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-22.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-22.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-22.c?ref=bd610db0d52cd1e4d972ff140c091d42ef486be4", "patch": "@@ -783,6 +783,12 @@ test_1 (_mm_roundscale_ph, __m128h, __m128h, 123)\n test_1 (_mm256_roundscale_ph, __m256h, __m256h, 123)\n test_1 (_mm512_roundscale_ph, __m512h, __m512h, 123)\n test_1 (_mm512_getexp_round_ph, __m512h, __m512h, 8)\n+test_1 (_mm512_cvt_roundph_epi16, __m512i, __m512h, 8)\n+test_1 (_mm512_cvt_roundph_epu16, __m512i, __m512h, 8)\n+test_1 (_mm512_cvt_roundph_epi32, __m512i, __m256h, 8)\n+test_1 (_mm512_cvt_roundph_epu32, __m512i, __m256h, 8)\n+test_1 (_mm512_cvt_roundph_epi64, __m512i, __m128h, 8)\n+test_1 (_mm512_cvt_roundph_epu64, __m512i, __m128h, 8)\n test_1x (_mm512_reduce_round_ph, __m512h, __m512h, 123, 8)\n test_1x (_mm512_roundscale_round_ph, __m512h, __m512h, 123, 8)\n test_1x (_mm512_getmant_ph, __m512h, __m512h, 1, 1)\n@@ -814,6 +820,12 @@ test_2 (_mm512_maskz_roundscale_ph, __m512h, __mmask32, __m512h, 123)\n test_2 (_mm_roundscale_sh, __m128h, __m128h, __m128h, 123)\n test_2 (_mm512_maskz_getexp_round_ph, __m512h, __mmask32, __m512h, 8)\n test_2 (_mm_getexp_round_sh, __m128h, __m128h, __m128h, 8)\n+test_2 (_mm512_maskz_cvt_roundph_epi16, __m512i, __mmask32, __m512h, 8)\n+test_2 (_mm512_maskz_cvt_roundph_epu16, __m512i, __mmask32, __m512h, 8)\n+test_2 (_mm512_maskz_cvt_roundph_epi32, __m512i, __mmask16, __m256h, 8)\n+test_2 (_mm512_maskz_cvt_roundph_epu32, __m512i, __mmask16, __m256h, 8)\n+test_2 (_mm512_maskz_cvt_roundph_epi64, __m512i, __mmask8, __m128h, 8)\n+test_2 (_mm512_maskz_cvt_roundph_epu64, __m512i, __mmask8, __m128h, 8)\n test_2x (_mm512_cmp_round_ph_mask, __mmask32, __m512h, __m512h, 1, 8)\n test_2x (_mm_cmp_round_sh_mask, __mmask8, __m128h, __m128h, 1, 8)\n test_2x (_mm_comi_round_sh, int, __m128h, __m128h, 1, 8)\n@@ -851,6 +863,12 @@ test_3 (_mm512_mask_roundscale_ph, __m512h, __m512h, __mmask32, __m512h, 123)\n test_3 (_mm_maskz_roundscale_sh, __m128h, __mmask8, __m128h, __m128h, 123)\n test_3 (_mm_maskz_getexp_round_sh, __m128h, __mmask8, __m128h, __m128h, 8)\n test_3 (_mm512_mask_getexp_round_ph, __m512h, __m512h, __mmask32, __m512h, 8)\n+test_3 (_mm512_mask_cvt_roundph_epi16, __m512i, __m512i, __mmask32, __m512h, 8)\n+test_3 (_mm512_mask_cvt_roundph_epu16, __m512i, __m512i, __mmask32, __m512h, 8)\n+test_3 (_mm512_mask_cvt_roundph_epi32, __m512i, __m512i, __mmask16, __m256h, 8)\n+test_3 (_mm512_mask_cvt_roundph_epu32, __m512i, __m512i, __mmask16, __m256h, 8)\n+test_3 (_mm512_mask_cvt_roundph_epi64, __m512i, __m512i, __mmask8, __m128h, 8)\n+test_3 (_mm512_mask_cvt_roundph_epu64, __m512i, __m512i, __mmask8, __m128h, 8)\n test_3x (_mm512_mask_cmp_round_ph_mask, __mmask32, __mmask32, __m512h, __m512h, 1, 8)\n test_3x (_mm_mask_cmp_round_sh_mask, __mmask8, __mmask8, __m128h, __m128h, 1, 8)\n test_3x (_mm512_mask_reduce_round_ph, __m512h, __m512h, __mmask32, __m512h, 123, 8)"}, {"sha": "f023d4fa2a4a4857cf1d6374bf051e151713112c", "filename": "gcc/testsuite/gcc.target/i386/sse-23.c", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-23.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd610db0d52cd1e4d972ff140c091d42ef486be4/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-23.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fsse-23.c?ref=bd610db0d52cd1e4d972ff140c091d42ef486be4", "patch": "@@ -737,6 +737,12 @@\n #define __builtin_ia32_getexpsh_mask_round(A, B, C, D, E) __builtin_ia32_getexpsh_mask_round(A, B, C, D, 4)\n #define __builtin_ia32_getmantph512_mask(A, F, C, D, E) __builtin_ia32_getmantph512_mask(A, 1, C, D, 8)\n #define __builtin_ia32_getmantsh_mask_round(A, B, C, W, U, D) __builtin_ia32_getmantsh_mask_round(A, B, 1, W, U, 4)\n+#define __builtin_ia32_vcvtph2dq512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2dq512_mask_round(A, B, C, 8)\n+#define __builtin_ia32_vcvtph2udq512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2udq512_mask_round(A, B, C, 8)\n+#define __builtin_ia32_vcvtph2qq512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2qq512_mask_round(A, B, C, 8)\n+#define __builtin_ia32_vcvtph2uqq512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2uqq512_mask_round(A, B, C, 8)\n+#define __builtin_ia32_vcvtph2w512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2w512_mask_round(A, B, C, 8)\n+#define __builtin_ia32_vcvtph2uw512_mask_round(A, B, C, D) __builtin_ia32_vcvtph2uw512_mask_round(A, B, C, 8)\n \n /* avx512fp16vlintrin.h */\n #define __builtin_ia32_cmpph128_mask(A, B, C, D) __builtin_ia32_cmpph128_mask(A, B, 1, D)"}]}