{"sha": "48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NDhhZTZjMTM4Y2EzMGM0YzVlODc2YTBiZTQ3YzlhMGI1YzhiZjVjMg==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2005-04-14T23:37:47Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2005-04-14T23:37:47Z"}, "message": "re PR middle-end/14311 (builtins for atomic operations needed)\n\n\tPR middle-end/14311\n\t* builtin-types.def (BT_BOOL, BT_VOLATILE_PTR, BT_I1, BT_I2,\n\tBT_I4, BT_I8, BT_FN_VOID_VPTR, BT_FN_I1_VPTR_I1, BT_FN_I2_VPTR_I2,\n\tBT_FN_I4_VPTR_I4, BT_FN_I8_VPTR_I8, BT_FN_BOOL_VPTR_I1_I1,\n\tBT_FN_BOOL_VPTR_I2_I2, BT_FN_BOOL_VPTR_I4_I4, BT_FN_BOOL_VPTR_I8_I8,\n\tBT_FN_I1_VPTR_I1_I1, BT_FN_I2_VPTR_I2_I2, BT_FN_I4_VPTR_I4_I4,\n\tBT_FN_I8_VPTR_I8_I8): New.\n\t* builtins.def (DEF_SYNC_BUILTIN): New.\n\t(BUILT_IN_FETCH_AND_ADD_N, BUILT_IN_FETCH_AND_ADD_1,\n\tBUILT_IN_FETCH_AND_ADD_2, BUILT_IN_FETCH_AND_ADD_4,\n\tBUILT_IN_FETCH_AND_ADD_8, BUILT_IN_FETCH_AND_SUB_N,\n\tBUILT_IN_FETCH_AND_SUB_1, BUILT_IN_FETCH_AND_SUB_2,\n\tBUILT_IN_FETCH_AND_SUB_4, BUILT_IN_FETCH_AND_SUB_8,\n\tBUILT_IN_FETCH_AND_OR_N, BUILT_IN_FETCH_AND_OR_1,\n\tBUILT_IN_FETCH_AND_OR_2, BUILT_IN_FETCH_AND_OR_4,\n\tBUILT_IN_FETCH_AND_OR_8, BUILT_IN_FETCH_AND_AND_N,\n\tBUILT_IN_FETCH_AND_AND_1, BUILT_IN_FETCH_AND_AND_2,\n\tBUILT_IN_FETCH_AND_AND_4, BUILT_IN_FETCH_AND_AND_8,\n\tBUILT_IN_FETCH_AND_XOR_N, BUILT_IN_FETCH_AND_XOR_1,\n\tBUILT_IN_FETCH_AND_XOR_2, BUILT_IN_FETCH_AND_XOR_4,\n\tBUILT_IN_FETCH_AND_XOR_8, BUILT_IN_FETCH_AND_NAND_N,\n\tBUILT_IN_FETCH_AND_NAND_1, BUILT_IN_FETCH_AND_NAND_2,\n\tBUILT_IN_FETCH_AND_NAND_4, BUILT_IN_FETCH_AND_NAND_8,\n\tBUILT_IN_ADD_AND_FETCH_N, BUILT_IN_ADD_AND_FETCH_1,\n\tBUILT_IN_ADD_AND_FETCH_2, BUILT_IN_ADD_AND_FETCH_4,\n\tBUILT_IN_ADD_AND_FETCH_8, BUILT_IN_SUB_AND_FETCH_N,\n\tBUILT_IN_SUB_AND_FETCH_1, BUILT_IN_SUB_AND_FETCH_2,\n\tBUILT_IN_SUB_AND_FETCH_4, BUILT_IN_SUB_AND_FETCH_8,\n\tBUILT_IN_OR_AND_FETCH_N, BUILT_IN_OR_AND_FETCH_1,\n\tBUILT_IN_OR_AND_FETCH_2, BUILT_IN_OR_AND_FETCH_4,\n\tBUILT_IN_OR_AND_FETCH_8, BUILT_IN_AND_AND_FETCH_N,\n\tBUILT_IN_AND_AND_FETCH_1, BUILT_IN_AND_AND_FETCH_2,\n\tBUILT_IN_AND_AND_FETCH_4, BUILT_IN_AND_AND_FETCH_8,\n\tBUILT_IN_XOR_AND_FETCH_N, BUILT_IN_XOR_AND_FETCH_1,\n\tBUILT_IN_XOR_AND_FETCH_2, BUILT_IN_XOR_AND_FETCH_4,\n\tBUILT_IN_XOR_AND_FETCH_8, BUILT_IN_NAND_AND_FETCH_N,\n\tBUILT_IN_NAND_AND_FETCH_1, BUILT_IN_NAND_AND_FETCH_2,\n\tBUILT_IN_NAND_AND_FETCH_4, BUILT_IN_NAND_AND_FETCH_8,\n\tBUILT_IN_BOOL_COMPARE_AND_SWAP_N, BUILT_IN_BOOL_COMPARE_AND_SWAP_1,\n\tBUILT_IN_BOOL_COMPARE_AND_SWAP_2, BUILT_IN_BOOL_COMPARE_AND_SWAP_4,\n\tBUILT_IN_BOOL_COMPARE_AND_SWAP_8, BUILT_IN_VAL_COMPARE_AND_SWAP_N,\n\tBUILT_IN_VAL_COMPARE_AND_SWAP_1, BUILT_IN_VAL_COMPARE_AND_SWAP_2,\n\tBUILT_IN_VAL_COMPARE_AND_SWAP_4, BUILT_IN_VAL_COMPARE_AND_SWAP_8,\n\tBUILT_IN_LOCK_TEST_AND_SET_N, BUILT_IN_LOCK_TEST_AND_SET_1,\n\tBUILT_IN_LOCK_TEST_AND_SET_2, BUILT_IN_LOCK_TEST_AND_SET_4,\n\tBUILT_IN_LOCK_TEST_AND_SET_8, BUILT_IN_LOCK_RELEASE_N,\n\tBUILT_IN_LOCK_RELEASE_1, BUILT_IN_LOCK_RELEASE_2,\n\tBUILT_IN_LOCK_RELEASE_4, BUILT_IN_LOCK_RELEASE_8,\n\tBUILT_IN_SYNCHRONIZE: New.\n\t* builtins.c (called_as_built_in): Rewrite from CALLED_AS_BUILT_IN\n\tas a function.  Accept __sync_ as a prefix as well.\n\t(expand_builtin_sync_operation, expand_builtin_compare_and_swap,\n\texpand_builtin_lock_test_and_set, expand_builtin_synchronize,\n\texpand_builtin_lock_release): New.\n\t(expand_builtin): Call them.\n\t* c-common.c (DEF_BUILTIN): Don't require __builtin_ prefix if\n\tneither BOTH_P nor FALLBACK_P are defined.\n\t(builtin_type_for_size): New.\n\t(sync_resolve_size, sync_resolve_params, sync_resolve_return): New.\n\t(resolve_overloaded_builtin): New.\n\t* c-common.h (resolve_overloaded_builtin): Declare.\n\t(builtin_type_for_size): Declare.\n\t* c-typeck.c (build_function_call): Invoke resolve_overloaded_builtin.\n\t* expr.c (sync_add_optab, sync_sub_optab, sync_ior_optab,\n\tsync_and_optab, sync_xor_optab, sync_nand_optab, sync_old_add_optab,\n\tsync_old_sub_optab, sync_old_ior_optab, sync_old_and_optab,\n\tsync_old_xor_optab, sync_old_nand_optab, sync_new_add_optab,\n\tsync_new_sub_optab, sync_new_ior_optab, sync_new_and_optab,\n\tsync_new_xor_optab, sync_new_nand_optab, sync_compare_and_swap,\n\tsync_compare_and_swap_cc, sync_lock_test_and_set,\n\tsync_lock_release): New.\n\t* optabs.h: Declare them.\n\t* expr.h (expand_val_compare_and_swap, expand_bool_compare_and_swap,\n\texpand_sync_operation, expand_sync_fetch_operation,\n\texpand_sync_lock_test_and_set): Declare.\n\t* genopinit.c (optabs): Add sync optabs.\n\t* optabs.c (init_optabs): Initialize sync optabs.\n\t(expand_val_compare_and_swap_1, expand_val_compare_and_swap,\n\texpand_bool_compare_and_swap, expand_compare_and_swap_loop,\n\texpand_sync_operation, expand_sync_fetch_operation,\n\texpand_sync_lock_test_and_set): New.\n\t* doc/extend.texi (Atomic Builtins): New section\n\t* doc/md.texi (Standard Names): Add sync patterns.\n\nFrom-SVN: r98154", "tree": {"sha": "1a1c7042dd3669b680fe5d1694acec62b0dfabc4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/1a1c7042dd3669b680fe5d1694acec62b0dfabc4"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/comments", "author": null, "committer": null, "parents": [{"sha": "871ae772871fdfbbb978c7e9f7ff68b03324644a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/871ae772871fdfbbb978c7e9f7ff68b03324644a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/871ae772871fdfbbb978c7e9f7ff68b03324644a"}], "stats": {"total": 2091, "additions": 2057, "deletions": 34}, "files": [{"sha": "88c3a037497296d2e8780192e0ffdd2133818ec5", "filename": "gcc/ChangeLog", "status": "modified", "additions": 113, "deletions": 27, "changes": 140, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -1,3 +1,89 @@\n+2004-04-14  Richard Henderson  <rth@redhat.com>\n+\n+\tPR middle-end/14311\n+\t* builtin-types.def (BT_BOOL, BT_VOLATILE_PTR, BT_I1, BT_I2,\n+\tBT_I4, BT_I8, BT_FN_VOID_VPTR, BT_FN_I1_VPTR_I1, BT_FN_I2_VPTR_I2,\n+\tBT_FN_I4_VPTR_I4, BT_FN_I8_VPTR_I8, BT_FN_BOOL_VPTR_I1_I1,\n+\tBT_FN_BOOL_VPTR_I2_I2, BT_FN_BOOL_VPTR_I4_I4, BT_FN_BOOL_VPTR_I8_I8,\n+\tBT_FN_I1_VPTR_I1_I1, BT_FN_I2_VPTR_I2_I2, BT_FN_I4_VPTR_I4_I4,\n+\tBT_FN_I8_VPTR_I8_I8): New.\n+\t* builtins.def (DEF_SYNC_BUILTIN): New.\n+\t(BUILT_IN_FETCH_AND_ADD_N, BUILT_IN_FETCH_AND_ADD_1,\n+\tBUILT_IN_FETCH_AND_ADD_2, BUILT_IN_FETCH_AND_ADD_4,\n+\tBUILT_IN_FETCH_AND_ADD_8, BUILT_IN_FETCH_AND_SUB_N,\n+\tBUILT_IN_FETCH_AND_SUB_1, BUILT_IN_FETCH_AND_SUB_2,\n+\tBUILT_IN_FETCH_AND_SUB_4, BUILT_IN_FETCH_AND_SUB_8,\n+\tBUILT_IN_FETCH_AND_OR_N, BUILT_IN_FETCH_AND_OR_1,\n+\tBUILT_IN_FETCH_AND_OR_2, BUILT_IN_FETCH_AND_OR_4,\n+\tBUILT_IN_FETCH_AND_OR_8, BUILT_IN_FETCH_AND_AND_N,\n+\tBUILT_IN_FETCH_AND_AND_1, BUILT_IN_FETCH_AND_AND_2,\n+\tBUILT_IN_FETCH_AND_AND_4, BUILT_IN_FETCH_AND_AND_8,\n+\tBUILT_IN_FETCH_AND_XOR_N, BUILT_IN_FETCH_AND_XOR_1,\n+\tBUILT_IN_FETCH_AND_XOR_2, BUILT_IN_FETCH_AND_XOR_4,\n+\tBUILT_IN_FETCH_AND_XOR_8, BUILT_IN_FETCH_AND_NAND_N,\n+\tBUILT_IN_FETCH_AND_NAND_1, BUILT_IN_FETCH_AND_NAND_2,\n+\tBUILT_IN_FETCH_AND_NAND_4, BUILT_IN_FETCH_AND_NAND_8,\n+\tBUILT_IN_ADD_AND_FETCH_N, BUILT_IN_ADD_AND_FETCH_1,\n+\tBUILT_IN_ADD_AND_FETCH_2, BUILT_IN_ADD_AND_FETCH_4,\n+\tBUILT_IN_ADD_AND_FETCH_8, BUILT_IN_SUB_AND_FETCH_N,\n+\tBUILT_IN_SUB_AND_FETCH_1, BUILT_IN_SUB_AND_FETCH_2,\n+\tBUILT_IN_SUB_AND_FETCH_4, BUILT_IN_SUB_AND_FETCH_8,\n+\tBUILT_IN_OR_AND_FETCH_N, BUILT_IN_OR_AND_FETCH_1,\n+\tBUILT_IN_OR_AND_FETCH_2, BUILT_IN_OR_AND_FETCH_4,\n+\tBUILT_IN_OR_AND_FETCH_8, BUILT_IN_AND_AND_FETCH_N,\n+\tBUILT_IN_AND_AND_FETCH_1, BUILT_IN_AND_AND_FETCH_2,\n+\tBUILT_IN_AND_AND_FETCH_4, BUILT_IN_AND_AND_FETCH_8,\n+\tBUILT_IN_XOR_AND_FETCH_N, BUILT_IN_XOR_AND_FETCH_1,\n+\tBUILT_IN_XOR_AND_FETCH_2, BUILT_IN_XOR_AND_FETCH_4,\n+\tBUILT_IN_XOR_AND_FETCH_8, BUILT_IN_NAND_AND_FETCH_N,\n+\tBUILT_IN_NAND_AND_FETCH_1, BUILT_IN_NAND_AND_FETCH_2,\n+\tBUILT_IN_NAND_AND_FETCH_4, BUILT_IN_NAND_AND_FETCH_8,\n+\tBUILT_IN_BOOL_COMPARE_AND_SWAP_N, BUILT_IN_BOOL_COMPARE_AND_SWAP_1,\n+\tBUILT_IN_BOOL_COMPARE_AND_SWAP_2, BUILT_IN_BOOL_COMPARE_AND_SWAP_4,\n+\tBUILT_IN_BOOL_COMPARE_AND_SWAP_8, BUILT_IN_VAL_COMPARE_AND_SWAP_N,\n+\tBUILT_IN_VAL_COMPARE_AND_SWAP_1, BUILT_IN_VAL_COMPARE_AND_SWAP_2,\n+\tBUILT_IN_VAL_COMPARE_AND_SWAP_4, BUILT_IN_VAL_COMPARE_AND_SWAP_8,\n+\tBUILT_IN_LOCK_TEST_AND_SET_N, BUILT_IN_LOCK_TEST_AND_SET_1,\n+\tBUILT_IN_LOCK_TEST_AND_SET_2, BUILT_IN_LOCK_TEST_AND_SET_4,\n+\tBUILT_IN_LOCK_TEST_AND_SET_8, BUILT_IN_LOCK_RELEASE_N,\n+\tBUILT_IN_LOCK_RELEASE_1, BUILT_IN_LOCK_RELEASE_2,\n+\tBUILT_IN_LOCK_RELEASE_4, BUILT_IN_LOCK_RELEASE_8,\n+\tBUILT_IN_SYNCHRONIZE: New.\n+\t* builtins.c (called_as_built_in): Rewrite from CALLED_AS_BUILT_IN\n+\tas a function.  Accept __sync_ as a prefix as well.\n+\t(expand_builtin_sync_operation, expand_builtin_compare_and_swap,\n+\texpand_builtin_lock_test_and_set, expand_builtin_synchronize,\n+\texpand_builtin_lock_release): New.\n+\t(expand_builtin): Call them.\n+\t* c-common.c (DEF_BUILTIN): Don't require __builtin_ prefix if\n+\tneither BOTH_P nor FALLBACK_P are defined.\n+\t(builtin_type_for_size): New.\n+\t(sync_resolve_size, sync_resolve_params, sync_resolve_return): New.\n+\t(resolve_overloaded_builtin): New.\n+\t* c-common.h (resolve_overloaded_builtin): Declare.\n+\t(builtin_type_for_size): Declare.\n+\t* c-typeck.c (build_function_call): Invoke resolve_overloaded_builtin.\n+\t* expr.c (sync_add_optab, sync_sub_optab, sync_ior_optab,\n+\tsync_and_optab, sync_xor_optab, sync_nand_optab, sync_old_add_optab,\n+\tsync_old_sub_optab, sync_old_ior_optab, sync_old_and_optab,\n+\tsync_old_xor_optab, sync_old_nand_optab, sync_new_add_optab,\n+\tsync_new_sub_optab, sync_new_ior_optab, sync_new_and_optab,\n+\tsync_new_xor_optab, sync_new_nand_optab, sync_compare_and_swap,\n+\tsync_compare_and_swap_cc, sync_lock_test_and_set,\n+\tsync_lock_release): New.\n+\t* optabs.h: Declare them.\n+\t* expr.h (expand_val_compare_and_swap, expand_bool_compare_and_swap,\n+\texpand_sync_operation, expand_sync_fetch_operation,\n+\texpand_sync_lock_test_and_set): Declare.\n+\t* genopinit.c (optabs): Add sync optabs.\n+\t* optabs.c (init_optabs): Initialize sync optabs.\n+\t(expand_val_compare_and_swap_1, expand_val_compare_and_swap,\n+\texpand_bool_compare_and_swap, expand_compare_and_swap_loop,\n+\texpand_sync_operation, expand_sync_fetch_operation,\n+\texpand_sync_lock_test_and_set): New.\n+\t* doc/extend.texi (Atomic Builtins): New section\n+\t* doc/md.texi (Standard Names): Add sync patterns.\n+\n 2005-04-14  Alexandre Oliva  <aoliva@redhat.com>\n \n \t* tree-eh.c (lower_try_finally_copy): Generate new code in\n@@ -91,13 +177,13 @@\n \n 2005-04-13  Dale Johannesen  <dalej@apple.com>\n \n-        * objc/Make-lang.in (objc-lang.o):  Depend on tree-gimple.h.\n-        (objc-act.o):  Ditto.\n-        * objc/objc-act.c (objc_gimplify_expr):  New.\n-        (objc_get_callee_fndecl):  New.\n-        * objc/objc-act.h:  Include tree-gimple.h.  Declare new functions.\n-        * objc/objc-lang.c (LANG_HOOKS_GIMPLIFY_EXPR):  Define.\n-        (LANG_HOOKS_GET_CALLEE_FNDECL):  Define.\n+\t* objc/Make-lang.in (objc-lang.o):  Depend on tree-gimple.h.\n+\t(objc-act.o):  Ditto.\n+\t* objc/objc-act.c (objc_gimplify_expr):  New.\n+\t(objc_get_callee_fndecl):  New.\n+\t* objc/objc-act.h:  Include tree-gimple.h.  Declare new functions.\n+\t* objc/objc-lang.c (LANG_HOOKS_GIMPLIFY_EXPR):  Define.\n+\t(LANG_HOOKS_GET_CALLEE_FNDECL):  Define.\n \n 2005-04-13  Devang Patel  <dpatel@apple.com>\n \n@@ -489,29 +575,29 @@\n \n 2005-04-11  Devang Patel  <dpatel@apple.com>\n \n-        * tree-data-ref.c (build_classic_dist_vector,\n-        compute_subscript_distance): Make externally visible.\n-        * tree-data-ref.h (build_classic_dist_vector,\n-        compute_subscript_distance): Same.\n-        * tree-vect-analyze.c (vect_analyze_data_ref_dependence):\n-        Check distance vector against vectorization factor.\n-        (vect_analyze_loop): Determine vectorizaion factor before\n-        analyzing data dependences.\n-        * tree-vectorizer.c (loops_num): Make it externally visible and\n-        rename ...\n-        * tree-vectorizer.c (vect_loops_num): ... new name.\n-        * tree-vectorizer.h  (vect_loops_num): New.\n+\t* tree-data-ref.c (build_classic_dist_vector,\n+\tcompute_subscript_distance): Make externally visible.\n+\t* tree-data-ref.h (build_classic_dist_vector,\n+\tcompute_subscript_distance): Same.\n+\t* tree-vect-analyze.c (vect_analyze_data_ref_dependence):\n+\tCheck distance vector against vectorization factor.\n+\t(vect_analyze_loop): Determine vectorizaion factor before\n+\tanalyzing data dependences.\n+\t* tree-vectorizer.c (loops_num): Make it externally visible and\n+\trename ...\n+\t* tree-vectorizer.c (vect_loops_num): ... new name.\n+\t* tree-vectorizer.h  (vect_loops_num): New.\n \n 2005-04-11  Devang Patel  <dpatel@apple.com>\n \n-        * tree-vect-analyze.c (vect_analyze_operations): Check\n-        vectorizable codition.\n-        * tree-vect-transform.c (vect_is_simple_cond): New function.\n-        (vectorizable_condition): New function.\n-        (vect_transform_stmt): Handle condition_vec_info_type.\n-        * tree-vectorizer.h (enum stmt_vec_info_type): Add\n-        condition_vec_info_type.\n-        (vectorizable_condition): New.\n+\t* tree-vect-analyze.c (vect_analyze_operations): Check\n+\tvectorizable codition.\n+\t* tree-vect-transform.c (vect_is_simple_cond): New function.\n+\t(vectorizable_condition): New function.\n+\t(vect_transform_stmt): Handle condition_vec_info_type.\n+\t* tree-vectorizer.h (enum stmt_vec_info_type): Add\n+\tcondition_vec_info_type.\n+\t(vectorizable_condition): New.\n \t\n 2005-04-11  Geoffrey Keating  <geoffk@apple.com>\n "}, {"sha": "4b5f35351e49f69315d446a1976fbb779678663f", "filename": "gcc/builtin-types.def", "status": "modified", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fbuiltin-types.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fbuiltin-types.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltin-types.def?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -60,6 +60,7 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n     the type pointed to.  */\n \n DEF_PRIMITIVE_TYPE (BT_VOID, void_type_node)\n+DEF_PRIMITIVE_TYPE (BT_BOOL, boolean_type_node)\n DEF_PRIMITIVE_TYPE (BT_INT, integer_type_node)\n DEF_PRIMITIVE_TYPE (BT_UINT, unsigned_type_node)\n DEF_PRIMITIVE_TYPE (BT_LONG, long_integer_type_node)\n@@ -79,6 +80,10 @@ DEF_PRIMITIVE_TYPE (BT_COMPLEX_LONGDOUBLE, complex_long_double_type_node)\n DEF_PRIMITIVE_TYPE (BT_PTR, ptr_type_node)\n DEF_PRIMITIVE_TYPE (BT_FILEPTR, fileptr_type_node)\n DEF_PRIMITIVE_TYPE (BT_CONST_PTR, const_ptr_type_node)\n+DEF_PRIMITIVE_TYPE (BT_VOLATILE_PTR,\n+\t\t    build_pointer_type\n+\t\t     (build_qualified_type (void_type_node,\n+\t\t\t\t\t    TYPE_QUAL_VOLATILE)))\n DEF_PRIMITIVE_TYPE (BT_PTRMODE, (*lang_hooks.types.type_for_mode)(ptr_mode, 0))\n DEF_PRIMITIVE_TYPE (BT_INT_PTR, integer_ptr_type_node)\n DEF_PRIMITIVE_TYPE (BT_FLOAT_PTR, float_ptr_type_node)\n@@ -94,6 +99,11 @@ DEF_PRIMITIVE_TYPE (BT_CONST_STRING, const_string_type_node)\n DEF_PRIMITIVE_TYPE (BT_VALIST_REF, va_list_ref_type_node)\n DEF_PRIMITIVE_TYPE (BT_VALIST_ARG, va_list_arg_type_node)\n \n+DEF_PRIMITIVE_TYPE (BT_I1, builtin_type_for_size (BITS_PER_UNIT*1, 1))\n+DEF_PRIMITIVE_TYPE (BT_I2, builtin_type_for_size (BITS_PER_UNIT*2, 1))\n+DEF_PRIMITIVE_TYPE (BT_I4, builtin_type_for_size (BITS_PER_UNIT*4, 1))\n+DEF_PRIMITIVE_TYPE (BT_I8, builtin_type_for_size (BITS_PER_UNIT*8, 1))\n+\n DEF_POINTER_TYPE (BT_PTR_CONST_STRING, BT_CONST_STRING)\n \n DEF_FUNCTION_TYPE_0 (BT_FN_VOID, BT_VOID)\n@@ -160,6 +170,7 @@ DEF_FUNCTION_TYPE_1 (BT_FN_STRING_CONST_STRING, BT_STRING, BT_CONST_STRING)\n DEF_FUNCTION_TYPE_1 (BT_FN_WORD_PTR, BT_WORD, BT_PTR)\n DEF_FUNCTION_TYPE_1 (BT_FN_INT_WINT, BT_INT, BT_WINT)\n DEF_FUNCTION_TYPE_1 (BT_FN_WINT_WINT, BT_WINT, BT_WINT)\n+DEF_FUNCTION_TYPE_1 (BT_FN_VOID_VPTR, BT_VOID, BT_VOLATILE_PTR)\n \n DEF_FUNCTION_TYPE_2 (BT_FN_VOID_PTR_INT, BT_VOID, BT_PTR, BT_INT)\n DEF_FUNCTION_TYPE_2 (BT_FN_STRING_STRING_CONST_STRING, \n@@ -241,6 +252,10 @@ DEF_FUNCTION_TYPE_2 (BT_FN_COMPLEX_LONGDOUBLE_COMPLEX_LONGDOUBLE_COMPLEX_LONGDOU\n DEF_FUNCTION_TYPE_2 (BT_FN_VOID_PTR_PTR, BT_VOID, BT_PTR, BT_PTR)\n DEF_FUNCTION_TYPE_2 (BT_FN_INT_CONST_STRING_PTR_CONST_STRING,\n \t\t     BT_INT, BT_CONST_STRING, BT_PTR_CONST_STRING)\n+DEF_FUNCTION_TYPE_2 (BT_FN_I1_VPTR_I1, BT_I1, BT_VOLATILE_PTR, BT_I1)\n+DEF_FUNCTION_TYPE_2 (BT_FN_I2_VPTR_I2, BT_I2, BT_VOLATILE_PTR, BT_I2)\n+DEF_FUNCTION_TYPE_2 (BT_FN_I4_VPTR_I4, BT_I4, BT_VOLATILE_PTR, BT_I4)\n+DEF_FUNCTION_TYPE_2 (BT_FN_I8_VPTR_I8, BT_I8, BT_VOLATILE_PTR, BT_I8)\n \n DEF_FUNCTION_TYPE_3 (BT_FN_STRING_STRING_CONST_STRING_SIZE,\n \t\t     BT_STRING, BT_STRING, BT_CONST_STRING, BT_SIZE)\n@@ -285,6 +300,18 @@ DEF_FUNCTION_TYPE_3 (BT_FN_VOID_LONGDOUBLE_LONGDOUBLEPTR_LONGDOUBLEPTR,\n DEF_FUNCTION_TYPE_3 (BT_FN_VOID_PTR_PTR_PTR, BT_VOID, BT_PTR, BT_PTR, BT_PTR)\n DEF_FUNCTION_TYPE_3 (BT_FN_INT_CONST_STRING_PTR_CONST_STRING_PTR_CONST_STRING,\n \t\t     BT_INT, BT_CONST_STRING, BT_PTR_CONST_STRING, BT_PTR_CONST_STRING)\n+DEF_FUNCTION_TYPE_3 (BT_FN_BOOL_VPTR_I1_I1, BT_BOOL, BT_VOLATILE_PTR,\n+\t\t     BT_I1, BT_I1)\n+DEF_FUNCTION_TYPE_3 (BT_FN_BOOL_VPTR_I2_I2, BT_BOOL, BT_VOLATILE_PTR,\n+\t\t     BT_I2, BT_I2)\n+DEF_FUNCTION_TYPE_3 (BT_FN_BOOL_VPTR_I4_I4, BT_BOOL, BT_VOLATILE_PTR,\n+\t\t     BT_I4, BT_I4)\n+DEF_FUNCTION_TYPE_3 (BT_FN_BOOL_VPTR_I8_I8, BT_BOOL, BT_VOLATILE_PTR,\n+\t\t     BT_I8, BT_I8)\n+DEF_FUNCTION_TYPE_3 (BT_FN_I1_VPTR_I1_I1, BT_I1, BT_VOLATILE_PTR, BT_I1, BT_I1)\n+DEF_FUNCTION_TYPE_3 (BT_FN_I2_VPTR_I2_I2, BT_I2, BT_VOLATILE_PTR, BT_I2, BT_I2)\n+DEF_FUNCTION_TYPE_3 (BT_FN_I4_VPTR_I4_I4, BT_I4, BT_VOLATILE_PTR, BT_I4, BT_I4)\n+DEF_FUNCTION_TYPE_3 (BT_FN_I8_VPTR_I8_I8, BT_I8, BT_VOLATILE_PTR, BT_I8, BT_I8)\n \n DEF_FUNCTION_TYPE_4 (BT_FN_SIZE_CONST_PTR_SIZE_SIZE_FILEPTR,\n \t\t     BT_SIZE, BT_CONST_PTR, BT_SIZE, BT_SIZE, BT_FILEPTR)"}, {"sha": "1a54a06854b275352796ea9d209ed48aac069bf3", "filename": "gcc/builtins.c", "status": "modified", "additions": 334, "deletions": 4, "changes": 338, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fbuiltins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fbuiltins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.c?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -48,9 +48,6 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n #include \"basic-block.h\"\n #include \"tree-mudflap.h\"\n \n-#define CALLED_AS_BUILT_IN(NODE) \\\n-   (!strncmp (IDENTIFIER_POINTER (DECL_NAME (NODE)), \"__builtin_\", 10))\n-\n #ifndef PAD_VARARGS_DOWN\n #define PAD_VARARGS_DOWN BYTES_BIG_ENDIAN\n #endif\n@@ -191,6 +188,19 @@ static tree fold_builtin_strspn (tree);\n static tree fold_builtin_strcspn (tree);\n static tree fold_builtin_sprintf (tree, int);\n \n+/* Return true if NODE should be considered for inline expansion regardless\n+   of the optimization level.  This means whenever a function is invoked with\n+   its \"internal\" name, which normally contains the prefix \"__builtin\".  */\n+\n+static bool called_as_built_in (tree node)\n+{\n+  const char *name = IDENTIFIER_POINTER (DECL_NAME (node));\n+  if (strncmp (name, \"__builtin_\", 10) == 0)\n+    return true;\n+  if (strncmp (name, \"__sync_\", 7) == 0)\n+    return true;\n+  return false;\n+}\n \n /* Return the alignment in bits of EXP, a pointer valued expression.\n    But don't return more than MAX_ALIGN no matter what.\n@@ -5225,6 +5235,166 @@ expand_builtin_fork_or_exec (tree fn, tree arglist, rtx target, int ignore)\n \n   return expand_call (call, target, ignore);\n }\n+\n+\f\n+/* Expand the __sync_xxx_and_fetch and __sync_fetch_and_xxx intrinsics.\n+   ARGLIST is the operands list to the function.  CODE is the rtx code \n+   that corresponds to the arithmetic or logical operation from the name;\n+   an exception here is that NOT actually means NAND.  TARGET is an optional\n+   place for us to store the results; AFTER is true if this is the\n+   fetch_and_xxx form.  IGNORE is true if we don't actually care about\n+   the result of the operation at all.  */\n+\n+static rtx\n+expand_builtin_sync_operation (tree arglist, enum rtx_code code, bool after,\n+\t\t\t       rtx target, bool ignore)\n+{\n+  enum machine_mode mode;\n+  rtx addr, val, mem;\n+\n+  /* Expand the operands.  */\n+  addr = expand_expr (TREE_VALUE (arglist), NULL, Pmode, EXPAND_SUM);\n+  mode = TYPE_MODE (TREE_TYPE (TREE_TYPE (TREE_VALUE (arglist))));\n+\n+  arglist = TREE_CHAIN (arglist);\n+  val = expand_expr (TREE_VALUE (arglist), NULL, mode, EXPAND_NORMAL);\n+\n+  /* Note that we explicitly do not want any alias information for this\n+     memory, so that we kill all other live memories.  Otherwise we don't\n+     satisfy the full barrier semantics of the intrinsic.  */\n+  mem = validize_mem (gen_rtx_MEM (mode, addr));\n+  MEM_VOLATILE_P (mem) = 1;\n+\n+  if (ignore)\n+    return expand_sync_operation (mem, val, code);\n+  else\n+    return expand_sync_fetch_operation (mem, val, code, after, target);\n+}\n+\n+/* Expand the __sync_val_compare_and_swap and __sync_bool_compare_and_swap\n+   intrinsics.  ARGLIST is the operands list to the function.  IS_BOOL is\n+   true if this is the boolean form.  TARGET is a place for us to store the\n+   results; this is NOT optional if IS_BOOL is true.  */\n+\n+static rtx\n+expand_builtin_compare_and_swap (tree arglist, bool is_bool, rtx target)\n+{\n+  enum machine_mode mode;\n+  rtx addr, old_val, new_val, mem;\n+\n+  /* Expand the operands.  */\n+  addr = expand_expr (TREE_VALUE (arglist), NULL, Pmode, EXPAND_SUM);\n+  mode = TYPE_MODE (TREE_TYPE (TREE_TYPE (TREE_VALUE (arglist))));\n+\n+  arglist = TREE_CHAIN (arglist);\n+  old_val = expand_expr (TREE_VALUE (arglist), NULL, mode, EXPAND_NORMAL);\n+\n+  arglist = TREE_CHAIN (arglist);\n+  new_val = expand_expr (TREE_VALUE (arglist), NULL, mode, EXPAND_NORMAL);\n+\n+  /* Note that we explicitly do not want any alias information for this\n+     memory, so that we kill all other live memories.  Otherwise we don't\n+     satisfy the full barrier semantics of the intrinsic.  */\n+  mem = validize_mem (gen_rtx_MEM (mode, addr));\n+  MEM_VOLATILE_P (mem) = 1;\n+\n+  if (is_bool)\n+    return expand_bool_compare_and_swap (mem, old_val, new_val, target);\n+  else\n+    return expand_val_compare_and_swap (mem, old_val, new_val, target);\n+}\n+\n+/* Expand the __sync_lock_test_and_set intrinsic.  Note that the most\n+   general form is actually an atomic exchange, and some targets only\n+   support a reduced form with the second argument being a constant 1.\n+   ARGLIST is the operands list to the function; TARGET is an optional\n+   place for us to store the results.  */\n+\n+static rtx\n+expand_builtin_lock_test_and_set (tree arglist, rtx target)\n+{\n+  enum machine_mode mode;\n+  rtx addr, val, mem;\n+\n+  /* Expand the operands.  */\n+  addr = expand_expr (TREE_VALUE (arglist), NULL, Pmode, EXPAND_NORMAL);\n+  mode = TYPE_MODE (TREE_TYPE (TREE_TYPE (TREE_VALUE (arglist))));\n+\n+  arglist = TREE_CHAIN (arglist);\n+  val = expand_expr (TREE_VALUE (arglist), NULL, mode, EXPAND_NORMAL);\n+\n+  /* Note that we explicitly do not want any alias information for this\n+     memory, so that we kill all other live memories.  Otherwise we don't\n+     satisfy the barrier semantics of the intrinsic.  */\n+  mem = validize_mem (gen_rtx_MEM (mode, addr));\n+  MEM_VOLATILE_P (mem) = 1;\n+\n+  return expand_sync_lock_test_and_set (mem, val, target);\n+}\n+\n+/* Expand the __sync_synchronize intrinsic.  */\n+\n+static void\n+expand_builtin_synchronize (void)\n+{\n+  rtx body;\n+\n+#ifdef HAVE_memory_barrier\n+  if (HAVE_memory_barrier)\n+    {\n+      emit_insn (gen_memory_barrier ());\n+      return;\n+    }\n+#endif\n+\n+  /* If no explicit memory barrier instruction is available, create an empty\n+     asm stmt that will prevent compiler movement across the barrier.  */\n+  body = gen_rtx_ASM_INPUT (VOIDmode, \"\");\n+  MEM_VOLATILE_P (body) = 1;\n+  emit_insn (body);\n+}\n+\n+/* Expand the __sync_lock_release intrinsic.  ARGLIST is the operands list\n+   to the function.  */\n+\n+static void\n+expand_builtin_lock_release (tree arglist)\n+{\n+  enum machine_mode mode;\n+  enum insn_code icode;\n+  rtx addr, val, mem, insn;\n+\n+  /* Expand the operands.  */\n+  addr = expand_expr (TREE_VALUE (arglist), NULL, Pmode, EXPAND_NORMAL);\n+  mode = TYPE_MODE (TREE_TYPE (TREE_TYPE (TREE_VALUE (arglist))));\n+  val = const0_rtx;\n+\n+  /* Note that we explicitly do not want any alias information for this\n+     memory, so that we kill all other live memories.  Otherwise we don't\n+     satisfy the barrier semantics of the intrinsic.  */\n+  mem = validize_mem (gen_rtx_MEM (mode, addr));\n+  MEM_VOLATILE_P (mem) = 1;\n+\n+  /* If there is an explicit operation in the md file, use it.  */\n+  icode = sync_lock_release[mode];\n+  if (icode != CODE_FOR_nothing)\n+    {\n+      if (!insn_data[icode].operand[1].predicate (val, mode))\n+\tval = force_reg (mode, val);\n+\n+      insn = GEN_FCN (icode) (mem, val);\n+      if (insn)\n+\t{\n+\t  emit_insn (insn);\n+\t  return;\n+\t}\n+    }\n+\n+  /* Otherwise we can implement this operation by emitting a barrier\n+     followed by a store of zero.  */\n+  expand_builtin_synchronize ();\n+  emit_move_insn (mem, val);\n+}\n \f\n /* Expand an expression EXP that calls a built-in function,\n    with result going to TARGET if that's convenient\n@@ -5247,7 +5417,7 @@ expand_builtin (tree exp, rtx target, rtx subtarget, enum machine_mode mode,\n   /* When not optimizing, generate calls to library functions for a certain\n      set of builtins.  */\n   if (!optimize\n-      && !CALLED_AS_BUILT_IN (fndecl)\n+      && !called_as_built_in (fndecl)\n       && DECL_ASSEMBLER_NAME_SET_P (fndecl)\n       && fcode != BUILT_IN_ALLOCA)\n     return expand_call (exp, target, ignore);\n@@ -5881,6 +6051,166 @@ expand_builtin (tree exp, rtx target, rtx subtarget, enum machine_mode mode,\n \treturn target;\n       break;\n \n+    case BUILT_IN_FETCH_AND_ADD_1:\n+    case BUILT_IN_FETCH_AND_ADD_2:\n+    case BUILT_IN_FETCH_AND_ADD_4:\n+    case BUILT_IN_FETCH_AND_ADD_8:\n+      target = expand_builtin_sync_operation (arglist, PLUS,\n+\t\t\t\t\t      false, target, ignore);\n+      if (target)\n+\treturn target;\n+      break;\n+\n+    case BUILT_IN_FETCH_AND_SUB_1:\n+    case BUILT_IN_FETCH_AND_SUB_2:\n+    case BUILT_IN_FETCH_AND_SUB_4:\n+    case BUILT_IN_FETCH_AND_SUB_8:\n+      target = expand_builtin_sync_operation (arglist, MINUS,\n+\t\t\t\t\t      false, target, ignore);\n+      if (target)\n+\treturn target;\n+      break;\n+\n+    case BUILT_IN_FETCH_AND_OR_1:\n+    case BUILT_IN_FETCH_AND_OR_2:\n+    case BUILT_IN_FETCH_AND_OR_4:\n+    case BUILT_IN_FETCH_AND_OR_8:\n+      target = expand_builtin_sync_operation (arglist, IOR,\n+\t\t\t\t\t      false, target, ignore);\n+      if (target)\n+\treturn target;\n+      break;\n+\n+    case BUILT_IN_FETCH_AND_AND_1:\n+    case BUILT_IN_FETCH_AND_AND_2:\n+    case BUILT_IN_FETCH_AND_AND_4:\n+    case BUILT_IN_FETCH_AND_AND_8:\n+      target = expand_builtin_sync_operation (arglist, AND,\n+\t\t\t\t\t      false, target, ignore);\n+      if (target)\n+\treturn target;\n+      break;\n+\n+    case BUILT_IN_FETCH_AND_XOR_1:\n+    case BUILT_IN_FETCH_AND_XOR_2:\n+    case BUILT_IN_FETCH_AND_XOR_4:\n+    case BUILT_IN_FETCH_AND_XOR_8:\n+      target = expand_builtin_sync_operation (arglist, XOR,\n+\t\t\t\t\t      false, target, ignore);\n+      if (target)\n+\treturn target;\n+      break;\n+\n+    case BUILT_IN_FETCH_AND_NAND_1:\n+    case BUILT_IN_FETCH_AND_NAND_2:\n+    case BUILT_IN_FETCH_AND_NAND_4:\n+    case BUILT_IN_FETCH_AND_NAND_8:\n+      target = expand_builtin_sync_operation (arglist, NOT,\n+\t\t\t\t\t      false, target, ignore);\n+      if (target)\n+\treturn target;\n+      break;\n+\n+    case BUILT_IN_ADD_AND_FETCH_1:\n+    case BUILT_IN_ADD_AND_FETCH_2:\n+    case BUILT_IN_ADD_AND_FETCH_4:\n+    case BUILT_IN_ADD_AND_FETCH_8:\n+      target = expand_builtin_sync_operation (arglist, PLUS,\n+\t\t\t\t\t      true, target, ignore);\n+      if (target)\n+\treturn target;\n+      break;\n+\n+    case BUILT_IN_SUB_AND_FETCH_1:\n+    case BUILT_IN_SUB_AND_FETCH_2:\n+    case BUILT_IN_SUB_AND_FETCH_4:\n+    case BUILT_IN_SUB_AND_FETCH_8:\n+      target = expand_builtin_sync_operation (arglist, MINUS,\n+\t\t\t\t\t      true, target, ignore);\n+      if (target)\n+\treturn target;\n+      break;\n+\n+    case BUILT_IN_OR_AND_FETCH_1:\n+    case BUILT_IN_OR_AND_FETCH_2:\n+    case BUILT_IN_OR_AND_FETCH_4:\n+    case BUILT_IN_OR_AND_FETCH_8:\n+      target = expand_builtin_sync_operation (arglist, IOR,\n+\t\t\t\t\t      true, target, ignore);\n+      if (target)\n+\treturn target;\n+      break;\n+\n+    case BUILT_IN_AND_AND_FETCH_1:\n+    case BUILT_IN_AND_AND_FETCH_2:\n+    case BUILT_IN_AND_AND_FETCH_4:\n+    case BUILT_IN_AND_AND_FETCH_8:\n+      target = expand_builtin_sync_operation (arglist, AND,\n+\t\t\t\t\t      true, target, ignore);\n+      if (target)\n+\treturn target;\n+      break;\n+\n+    case BUILT_IN_XOR_AND_FETCH_1:\n+    case BUILT_IN_XOR_AND_FETCH_2:\n+    case BUILT_IN_XOR_AND_FETCH_4:\n+    case BUILT_IN_XOR_AND_FETCH_8:\n+      target = expand_builtin_sync_operation (arglist, XOR,\n+\t\t\t\t\t      true, target, ignore);\n+      if (target)\n+\treturn target;\n+      break;\n+\n+    case BUILT_IN_NAND_AND_FETCH_1:\n+    case BUILT_IN_NAND_AND_FETCH_2:\n+    case BUILT_IN_NAND_AND_FETCH_4:\n+    case BUILT_IN_NAND_AND_FETCH_8:\n+      target = expand_builtin_sync_operation (arglist, NOT,\n+\t\t\t\t\t      true, target, ignore);\n+      if (target)\n+\treturn target;\n+      break;\n+\n+    case BUILT_IN_BOOL_COMPARE_AND_SWAP_1:\n+    case BUILT_IN_BOOL_COMPARE_AND_SWAP_2:\n+    case BUILT_IN_BOOL_COMPARE_AND_SWAP_4:\n+    case BUILT_IN_BOOL_COMPARE_AND_SWAP_8:\n+      if (!target || !register_operand (target, mode))\n+\ttarget = gen_reg_rtx (mode);\n+      target = expand_builtin_compare_and_swap (arglist, true, target);\n+      if (target)\n+\treturn target;\n+      break;\n+\n+    case BUILT_IN_VAL_COMPARE_AND_SWAP_1:\n+    case BUILT_IN_VAL_COMPARE_AND_SWAP_2:\n+    case BUILT_IN_VAL_COMPARE_AND_SWAP_4:\n+    case BUILT_IN_VAL_COMPARE_AND_SWAP_8:\n+      target = expand_builtin_compare_and_swap (arglist, false, target);\n+      if (target)\n+\treturn target;\n+      break;\n+\n+    case BUILT_IN_LOCK_TEST_AND_SET_1:\n+    case BUILT_IN_LOCK_TEST_AND_SET_2:\n+    case BUILT_IN_LOCK_TEST_AND_SET_4:\n+    case BUILT_IN_LOCK_TEST_AND_SET_8:\n+      target = expand_builtin_lock_test_and_set (arglist, target);\n+      if (target)\n+\treturn target;\n+      break;\n+\n+    case BUILT_IN_LOCK_RELEASE_1:\n+    case BUILT_IN_LOCK_RELEASE_2:\n+    case BUILT_IN_LOCK_RELEASE_4:\n+    case BUILT_IN_LOCK_RELEASE_8:\n+      expand_builtin_lock_release (arglist);\n+      return const0_rtx;\n+\n+    case BUILT_IN_SYNCHRONIZE:\n+      expand_builtin_synchronize ();\n+      return const0_rtx;\n+\n     default:\t/* just do library call, if unknown builtin */\n       break;\n     }"}, {"sha": "134bf98a12909e28997681a2d59e593faade0f75", "filename": "gcc/builtins.def", "status": "modified", "additions": 199, "deletions": 0, "changes": 199, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fbuiltins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fbuiltins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.def?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -71,6 +71,12 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n   DEF_BUILTIN (ENUM, \"__builtin_\" NAME, BUILT_IN_NORMAL, TYPE, BT_LAST,\t\\\n                false, false, false, ATTRS, true, true)\n \n+/* Like DEF_GCC_BUILTIN, except we don't prepend \"__builtin_\".  */\n+#undef DEF_SYNC_BUILTIN\n+#define DEF_SYNC_BUILTIN(ENUM, NAME, TYPE, ATTRS)\t\t\\\n+  DEF_BUILTIN (ENUM, NAME, BUILT_IN_NORMAL, TYPE, BT_LAST,\t\\\n+               false, false, false, ATTRS, true, true)\n+\n /* A library builtin (like __builtin_strchr) is a builtin equivalent\n    of an ANSI/ISO standard library function.  In addition to the\n    `__builtin' version, we will create an ordinary version (e.g,\n@@ -657,3 +663,196 @@ DEF_BUILTIN_STUB (BUILT_IN_STACK_RESTORE, \"__builtin_stack_restore\")\n /* Profiling hooks.  */\n DEF_BUILTIN_STUB (BUILT_IN_PROFILE_FUNC_ENTER, \"profile_func_enter\")\n DEF_BUILTIN_STUB (BUILT_IN_PROFILE_FUNC_EXIT, \"profile_func_exit\")\n+\n+/* Synchronization Primitives.  The \"_N\" version is the one that the user\n+   is supposed to be using.  It's overloaded, and is resolved to one of the\n+   \"_1\" through \"_8\" versions, plus some extra casts.  */\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_ADD_N, \"__sync_fetch_and_add\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_ADD_1, \"__sync_fetch_and_add_1\",\n+\t\t  BT_FN_I1_VPTR_I1, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_ADD_2, \"__sync_fetch_and_add_2\",\n+\t\t  BT_FN_I2_VPTR_I2, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_ADD_4, \"__sync_fetch_and_add_4\",\n+\t\t  BT_FN_I4_VPTR_I4, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_ADD_8, \"__sync_fetch_and_add_8\",\n+\t\t  BT_FN_I8_VPTR_I8, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_SUB_N, \"__sync_fetch_and_sub\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_SUB_1, \"__sync_fetch_and_sub_1\",\n+\t\t  BT_FN_I1_VPTR_I1, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_SUB_2, \"__sync_fetch_and_sub_2\",\n+\t\t  BT_FN_I2_VPTR_I2, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_SUB_4, \"__sync_fetch_and_sub_4\",\n+\t\t  BT_FN_I4_VPTR_I4, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_SUB_8, \"__sync_fetch_and_sub_8\",\n+\t\t  BT_FN_I8_VPTR_I8, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_OR_N, \"__sync_fetch_and_or\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_OR_1, \"__sync_fetch_and_or_1\",\n+\t\t  BT_FN_I1_VPTR_I1, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_OR_2, \"__sync_fetch_and_or_2\",\n+\t\t  BT_FN_I2_VPTR_I2, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_OR_4, \"__sync_fetch_and_or_4\",\n+\t\t  BT_FN_I4_VPTR_I4, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_OR_8, \"__sync_fetch_and_or_8\",\n+\t\t  BT_FN_I8_VPTR_I8, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_AND_N, \"__sync_fetch_and_and\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_AND_1, \"__sync_fetch_and_and_1\",\n+\t\t  BT_FN_I1_VPTR_I1, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_AND_2, \"__sync_fetch_and_and_2\",\n+\t\t  BT_FN_I2_VPTR_I2, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_AND_4, \"__sync_fetch_and_and_4\",\n+\t\t  BT_FN_I4_VPTR_I4, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_AND_8, \"__sync_fetch_and_and_8\",\n+\t\t  BT_FN_I8_VPTR_I8, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_XOR_N, \"__sync_fetch_and_xor\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_XOR_1, \"__sync_fetch_and_xor_1\",\n+\t\t  BT_FN_I1_VPTR_I1, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_XOR_2, \"__sync_fetch_and_xor_2\",\n+\t\t  BT_FN_I2_VPTR_I2, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_XOR_4, \"__sync_fetch_and_xor_4\",\n+\t\t  BT_FN_I4_VPTR_I4, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_XOR_8, \"__sync_fetch_and_xor_8\",\n+\t\t  BT_FN_I8_VPTR_I8, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_NAND_N, \"__sync_fetch_and_nand\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_NAND_1, \"__sync_fetch_and_nand_1\",\n+\t\t  BT_FN_I1_VPTR_I1, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_NAND_2, \"__sync_fetch_and_nand_2\",\n+\t\t  BT_FN_I2_VPTR_I2, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_NAND_4, \"__sync_fetch_and_nand_4\",\n+\t\t  BT_FN_I4_VPTR_I4, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_FETCH_AND_NAND_8, \"__sync_fetch_and_nand_8\",\n+\t\t  BT_FN_I8_VPTR_I8, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_ADD_AND_FETCH_N, \"__sync_add_and_fetch\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_ADD_AND_FETCH_1, \"__sync_add_and_fetch_1\",\n+\t\t  BT_FN_I1_VPTR_I1, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_ADD_AND_FETCH_2, \"__sync_add_and_fetch_2\",\n+\t\t  BT_FN_I2_VPTR_I2, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_ADD_AND_FETCH_4, \"__sync_add_and_fetch_4\",\n+\t\t  BT_FN_I4_VPTR_I4, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_ADD_AND_FETCH_8, \"__sync_add_and_fetch_8\",\n+\t\t  BT_FN_I8_VPTR_I8, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_SUB_AND_FETCH_N, \"__sync_sub_and_fetch\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_SUB_AND_FETCH_1, \"__sync_sub_and_fetch_1\",\n+\t\t  BT_FN_I1_VPTR_I1, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_SUB_AND_FETCH_2, \"__sync_sub_and_fetch_2\",\n+\t\t  BT_FN_I2_VPTR_I2, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_SUB_AND_FETCH_4, \"__sync_sub_and_fetch_4\",\n+\t\t  BT_FN_I4_VPTR_I4, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_SUB_AND_FETCH_8, \"__sync_sub_and_fetch_8\",\n+\t\t  BT_FN_I8_VPTR_I8, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_OR_AND_FETCH_N, \"__sync_or_and_fetch\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_OR_AND_FETCH_1, \"__sync_or_and_fetch_1\",\n+\t\t  BT_FN_I1_VPTR_I1, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_OR_AND_FETCH_2, \"__sync_or_and_fetch_2\",\n+\t\t  BT_FN_I2_VPTR_I2, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_OR_AND_FETCH_4, \"__sync_or_and_fetch_4\",\n+\t\t  BT_FN_I4_VPTR_I4, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_OR_AND_FETCH_8, \"__sync_or_and_fetch_8\",\n+\t\t  BT_FN_I8_VPTR_I8, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_AND_AND_FETCH_N, \"__sync_and_and_fetch\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_AND_AND_FETCH_1, \"__sync_and_and_fetch_1\",\n+\t\t  BT_FN_I1_VPTR_I1, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_AND_AND_FETCH_2, \"__sync_and_and_fetch_2\",\n+\t\t  BT_FN_I2_VPTR_I2, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_AND_AND_FETCH_4, \"__sync_and_and_fetch_4\",\n+\t\t  BT_FN_I4_VPTR_I4, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_AND_AND_FETCH_8, \"__sync_and_and_fetch_8\",\n+\t\t  BT_FN_I8_VPTR_I8, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_XOR_AND_FETCH_N, \"__sync_xor_and_fetch\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_XOR_AND_FETCH_1, \"__sync_xor_and_fetch_1\",\n+\t\t  BT_FN_I1_VPTR_I1, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_XOR_AND_FETCH_2, \"__sync_xor_and_fetch_2\",\n+\t\t  BT_FN_I2_VPTR_I2, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_XOR_AND_FETCH_4, \"__sync_xor_and_fetch_4\",\n+\t\t  BT_FN_I4_VPTR_I4, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_XOR_AND_FETCH_8, \"__sync_xor_and_fetch_8\",\n+\t\t  BT_FN_I8_VPTR_I8, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_NAND_AND_FETCH_N, \"__sync_nand_and_fetch\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_NAND_AND_FETCH_1, \"__sync_nand_and_fetch_1\",\n+\t\t  BT_FN_I1_VPTR_I1, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_NAND_AND_FETCH_2, \"__sync_nand_and_fetch_2\",\n+\t\t  BT_FN_I2_VPTR_I2, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_NAND_AND_FETCH_4, \"__sync_nand_and_fetch_4\",\n+\t\t  BT_FN_I4_VPTR_I4, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_NAND_AND_FETCH_8, \"__sync_nand_and_fetch_8\",\n+\t\t  BT_FN_I8_VPTR_I8, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_BOOL_COMPARE_AND_SWAP_N,\n+\t\t  \"__sync_bool_compare_and_swap\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_BOOL_COMPARE_AND_SWAP_1,\n+\t\t  \"__sync_bool_compare_and_swap_1\",\n+\t\t  BT_FN_BOOL_VPTR_I1_I1, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_BOOL_COMPARE_AND_SWAP_2,\n+\t\t  \"__sync_bool_compare_and_swap_2\",\n+\t\t  BT_FN_BOOL_VPTR_I2_I2, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_BOOL_COMPARE_AND_SWAP_4,\n+\t\t  \"__sync_bool_compare_and_swap_4\",\n+\t\t  BT_FN_BOOL_VPTR_I4_I4, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_BOOL_COMPARE_AND_SWAP_8,\n+\t\t  \"__sync_bool_compare_and_swap_8\",\n+\t\t  BT_FN_BOOL_VPTR_I8_I8, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_VAL_COMPARE_AND_SWAP_N,\n+\t\t  \"__sync_val_compare_and_swap\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_VAL_COMPARE_AND_SWAP_1,\n+\t\t  \"__sync_val_compare_and_swap_1\",\n+\t\t  BT_FN_I1_VPTR_I1_I1, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_VAL_COMPARE_AND_SWAP_2,\n+\t\t  \"__sync_val_compare_and_swap_2\",\n+\t\t  BT_FN_I2_VPTR_I2_I2, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_VAL_COMPARE_AND_SWAP_4,\n+\t\t  \"__sync_val_compare_and_swap_4\",\n+\t\t  BT_FN_I4_VPTR_I4_I4, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_VAL_COMPARE_AND_SWAP_8,\n+\t\t  \"__sync_val_compare_and_swap_8\",\n+\t\t  BT_FN_I8_VPTR_I8_I8, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_LOCK_TEST_AND_SET_N, \"__sync_lock_test_and_set\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_LOCK_TEST_AND_SET_1, \"__sync_lock_test_and_set_1\",\n+\t\t  BT_FN_I1_VPTR_I1, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_LOCK_TEST_AND_SET_2, \"__sync_lock_test_and_set_2\",\n+\t\t  BT_FN_I2_VPTR_I2, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_LOCK_TEST_AND_SET_4, \"__sync_lock_test_and_set_4\",\n+\t\t  BT_FN_I4_VPTR_I4, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_LOCK_TEST_AND_SET_8, \"__sync_lock_test_and_set_8\",\n+\t\t  BT_FN_I8_VPTR_I8, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_LOCK_RELEASE_N, \"__sync_lock_release\",\n+\t\t  BT_FN_VOID_VAR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_LOCK_RELEASE_1, \"__sync_lock_release_1\",\n+\t\t  BT_FN_VOID_VPTR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_LOCK_RELEASE_2, \"__sync_lock_release_2\",\n+\t\t  BT_FN_VOID_VPTR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_LOCK_RELEASE_4, \"__sync_lock_release_4\",\n+\t\t  BT_FN_VOID_VPTR, ATTR_NOTHROW_LIST)\n+DEF_SYNC_BUILTIN (BUILT_IN_LOCK_RELEASE_8, \"__sync_lock_release_8\",\n+\t\t  BT_FN_VOID_VPTR, ATTR_NOTHROW_LIST)\n+\n+DEF_SYNC_BUILTIN (BUILT_IN_SYNCHRONIZE, \"__sync_synchronize\",\n+\t\t  BT_FN_VOID, ATTR_NOTHROW_LIST)"}, {"sha": "da6be4e21a6a94e17a4a05201a05d57dea0c7af2", "filename": "gcc/c-common.c", "status": "modified", "additions": 169, "deletions": 2, "changes": 171, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fc-common.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fc-common.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-common.c?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -3242,8 +3242,9 @@ c_common_nodes_and_builtins (void)\n     {\t\t\t\t\t\t\t\t\t\\\n       tree decl;\t\t\t\t\t\t\t\\\n \t\t\t\t\t\t\t\t\t\\\n-      gcc_assert (!strncmp (NAME, \"__builtin_\",\t\t\t\t\\\n-\t\t\t    strlen (\"__builtin_\")));\t\t\t\\\n+      gcc_assert ((!BOTH_P && !FALLBACK_P)\t\t\t\t\\\n+\t\t  || !strncmp (NAME, \"__builtin_\",\t\t\t\\\n+\t\t\t       strlen (\"__builtin_\")));\t\t\t\\\n \t\t\t\t\t\t\t\t\t\\\n       if (!BOTH_P)\t\t\t\t\t\t\t\\\n \tdecl = lang_hooks.builtin_function (NAME, builtin_types[TYPE],\t\\\n@@ -5836,4 +5837,170 @@ complete_array_type (tree *ptype, tree initial_value, bool do_default)\n   return failure;\n }\n \n+\f\n+/* Used to help initialize the builtin-types.def table.  When a type of\n+   the correct size doesn't exist, use error_mark_node instead of NULL.\n+   The later results in segfaults even when a decl using the type doesn't\n+   get invoked.  */\n+\n+tree\n+builtin_type_for_size (int size, bool unsignedp)\n+{\n+  tree type = lang_hooks.types.type_for_size (size, unsignedp);\n+  return type ? type : error_mark_node;\n+}\n+\n+/* A helper function for resolve_overloaded_builtin in resolving the\n+   overloaded __sync_ builtins.  Returns a positive power of 2 if the\n+   first operand of PARAMS is a pointer to a supported data type.\n+   Returns 0 if an error is encountered.  */\n+\n+static int\n+sync_resolve_size (tree function, tree params)\n+{\n+  tree type;\n+  int size;\n+\n+  if (params == NULL)\n+    {\n+      error (\"too few arguments to function %qE\", function);\n+      return 0;\n+    }\n+\n+  type = TREE_TYPE (TREE_VALUE (params));\n+  if (TREE_CODE (type) != POINTER_TYPE)\n+    goto incompatible;\n+\n+  type = TREE_TYPE (type);\n+  if (!INTEGRAL_TYPE_P (type) && !POINTER_TYPE_P (type))\n+    goto incompatible;\n+\n+  size = tree_low_cst (TYPE_SIZE_UNIT (type), 1);\n+  if (size == 1 || size == 2 || size == 4 || size == 8)\n+    return size;\n+\n+ incompatible:\n+  error (\"incompatible type for argument %d of %qE\", 1, function);\n+  return 0;\n+}\n+\n+/* A helper function for resolve_overloaded_builtin.  Adds casts to \n+   PARAMS to make arguments match up with those of FUNCTION.  Drops\n+   the variadic arguments at the end.  Returns false if some error\n+   was encountered; true on success.  */\n+\n+static bool\n+sync_resolve_params (tree orig_function, tree function, tree params)\n+{\n+  tree arg_types = TYPE_ARG_TYPES (TREE_TYPE (function));\n+  tree ptype;\n+  int number;\n+\n+  /* We've declared the implementation functions to use \"volatile void *\"\n+     as the pointer parameter, so we shouldn't get any complaints from the\n+     call to check_function_arguments what ever type the user used.  */\n+  arg_types = TREE_CHAIN (arg_types);\n+  ptype = TREE_TYPE (TREE_TYPE (TREE_VALUE (params)));\n+  number = 2;\n+\n+  /* For the rest of the values, we need to cast these to FTYPE, so that we\n+     don't get warnings for passing pointer types, etc.  */\n+  while (arg_types != void_list_node)\n+    {\n+      tree val;\n+\n+      params = TREE_CHAIN (params);\n+      if (params == NULL)\n+\t{\n+\t  error (\"too few arguments to function %qE\", orig_function);\n+\t  return false;\n+\t}\n+\n+      /* ??? Ideally for the first conversion we'd use convert_for_assignment\n+\t so that we get warnings for anything that doesn't match the pointer\n+\t type.  This isn't portable across the C and C++ front ends atm.  */\n+      val = TREE_VALUE (params);\n+      val = convert (ptype, val);\n+      val = convert (TREE_VALUE (arg_types), val);\n+      TREE_VALUE (params) = val;\n+\n+      arg_types = TREE_CHAIN (arg_types);\n+      number++;\n+    }\n+\n+  /* The definition of these primitives is variadic, with the remaining\n+     being \"an optional list of variables protected by the memory barrier\".\n+     No clue what that's supposed to mean, precisely, but we consider all\n+     call-clobbered variables to be protected so we're safe.  */\n+  TREE_CHAIN (params) = NULL;\n+\n+  return true;\n+}\n+\n+/* A helper function for resolve_overloaded_builtin.  Adds a cast to \n+   RESULT to make it match the type of the first pointer argument in\n+   PARAMS.  */\n+\n+static tree\n+sync_resolve_return (tree params, tree result)\n+{\n+  tree ptype = TREE_TYPE (TREE_TYPE (TREE_VALUE (params)));\n+  return convert (ptype, result);\n+}\n+\n+/* Some builtin functions are placeholders for other expressions.  This\n+   function should be called immediately after parsing the call expression\n+   before surrounding code has committed to the type of the expression.\n+\n+   FUNCTION is the DECL that has been invoked; it is known to be a builtin.\n+   PARAMS is the argument list for the call.  The return value is non-null\n+   when expansion is complete, and null if normal processing should\n+   continue.  */\n+\n+tree\n+resolve_overloaded_builtin (tree function, tree params)\n+{\n+  enum built_in_function orig_code = DECL_FUNCTION_CODE (function);\n+  switch (orig_code)\n+    {\n+    case BUILT_IN_FETCH_AND_ADD_N:\n+    case BUILT_IN_FETCH_AND_SUB_N:\n+    case BUILT_IN_FETCH_AND_OR_N:\n+    case BUILT_IN_FETCH_AND_AND_N:\n+    case BUILT_IN_FETCH_AND_XOR_N:\n+    case BUILT_IN_FETCH_AND_NAND_N:\n+    case BUILT_IN_ADD_AND_FETCH_N:\n+    case BUILT_IN_SUB_AND_FETCH_N:\n+    case BUILT_IN_OR_AND_FETCH_N:\n+    case BUILT_IN_AND_AND_FETCH_N:\n+    case BUILT_IN_XOR_AND_FETCH_N:\n+    case BUILT_IN_NAND_AND_FETCH_N:\n+    case BUILT_IN_BOOL_COMPARE_AND_SWAP_N:\n+    case BUILT_IN_VAL_COMPARE_AND_SWAP_N:\n+    case BUILT_IN_LOCK_TEST_AND_SET_N:\n+    case BUILT_IN_LOCK_RELEASE_N:\n+      {\n+\tint n = sync_resolve_size (function, params);\n+\ttree new_function, result;\n+\n+\tif (n == 0)\n+\t  return error_mark_node;\n+\n+\tnew_function = built_in_decls[orig_code + exact_log2 (n) + 1];\n+\tif (!sync_resolve_params (function, new_function, params))\n+\t  return error_mark_node;\n+\n+\tresult = build_function_call (new_function, params);\n+\tif (orig_code != BUILT_IN_BOOL_COMPARE_AND_SWAP_N\n+\t    && orig_code != BUILT_IN_LOCK_RELEASE_N)\n+\t  result = sync_resolve_return (params, result);\n+\n+\treturn result;\n+      }\n+\n+    default:\n+      return NULL;\n+    }\n+}\n+\n #include \"gt-c-common.h\""}, {"sha": "cf6e88b9fa65318424bcd79e4252a2c560d3d518", "filename": "gcc/c-common.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fc-common.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fc-common.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-common.h?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -798,6 +798,8 @@ extern void c_do_switch_warnings (splay_tree, location_t, tree, tree);\n \n extern tree build_function_call (tree, tree);\n \n+extern tree resolve_overloaded_builtin (tree, tree);\n+\n extern tree finish_label_address_expr (tree);\n \n /* Same function prototype, but the C and C++ front ends have\n@@ -860,6 +862,8 @@ extern void lvalue_error (enum lvalue_use);\n \n extern int complete_array_type (tree *, tree, bool);\n \n+extern tree builtin_type_for_size (int, bool);\n+\n /* In c-gimplify.c  */\n extern void c_genericize (tree);\n extern int c_gimplify_expr (tree *, tree *, tree *);"}, {"sha": "9c82bbe601954f9360f63fed4ddad3c8e20869c8", "filename": "gcc/c-typeck.c", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fc-typeck.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fc-typeck.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-typeck.c?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -1978,6 +1978,13 @@ build_function_call (tree function, tree params)\n   /* Convert anything with function type to a pointer-to-function.  */\n   if (TREE_CODE (function) == FUNCTION_DECL)\n     {\n+      if (DECL_BUILT_IN_CLASS (function) == BUILT_IN_NORMAL)\n+\t{\n+\t  tem = resolve_overloaded_builtin (function, params);\n+\t  if (tem)\n+\t    return tem;\n+\t}\n+\n       name = DECL_NAME (function);\n \n       /* Differs from default_conversion by not setting TREE_ADDRESSABLE"}, {"sha": "5fc85a45abbb11a28ee51b34082ebabc428de1d3", "filename": "gcc/doc/extend.texi", "status": "modified", "additions": 128, "deletions": 0, "changes": 128, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fdoc%2Fextend.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fdoc%2Fextend.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fextend.texi?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -70,6 +70,7 @@ extensions, accepted by GCC in C89 mode and in C++.\n * Return Address::      Getting the return or frame address of a function.\n * Vector Extensions::   Using vector instructions through built-in functions.\n * Offsetof::            Special syntax for implementing @code{offsetof}.\n+* Atomic Builtins::\tBuilt-in functions for atomic memory access.\n * Other Builtins::      Other built-in functions.\n * Target Builtins::     Built-in functions specific to particular targets.\n * Target Format Checks:: Format checks specific to particular targets.\n@@ -4581,6 +4582,133 @@ is a suitable definition of the @code{offsetof} macro.  In C++, @var{type}\n may be dependent.  In either case, @var{member} may consist of a single\n identifier, or a sequence of member accesses and array references.\n \n+@node Atomic Builtins\n+@section Built-in functions for atomic memory access\n+\n+The following builtins are intended to be compatible with those described\n+in the @cite{Intel Itanium Processor-specific Application Binary Interface},\n+section 7.4.  As such, they depart from the normal GCC practice of using\n+the ``__builtin_'' prefix, and further that they are overloaded such that\n+they work on multiple types.\n+\n+The definition given in the Intel documentation allows only for the use of\n+the types @code{int}, @code{long}, @code{long long} as well as their unsigned\n+counterparts.  GCC will allow any integral scalar or pointer type that is\n+1, 2, 4 or 8 bytes in length.\n+\n+Not all operations are supported by all target processors.  If a particular\n+operation cannot be implemented on the target processor, a warning will be\n+generated and a call an external function will be generated.  The external\n+function will carry the same name as the builtin, with an additional suffix\n+@samp{_@var{n}} where @var{n} is the size of the data type.\n+\n+@c ??? Should we have a mechanism to suppress this warning?  This is almost\n+@c useful for implementing the operation under the control of an external\n+@c mutex.\n+\n+In most cases, these builtins are considered a @dfn{full barrier}.  That is,\n+no memory operand will be moved across the operation, either forward or\n+backward.  Further, instructions will be issued as necessary to prevent the\n+processor from speculating loads across the operation and from queuing stores\n+after the operation.\n+\n+All of the routines are are described in the Intel documentation to take\n+``an optional list of variables protected by the memory barrier''.  It's\n+not clear what is meant by that; it could mean that @emph{only} the\n+following variables are protected, or it could mean that these variables\n+should in addition be protected.  At present GCC ignores this list and\n+protects all variables which are globally accessible.  If in the future\n+we make some use of this list, an empty list will continue to mean all\n+globally accessible variables.\n+\n+@table @code\n+@item @var{type} __sync_fetch_and_add (@var{type} *ptr, @var{type} value, ...)\n+@itemx @var{type} __sync_fetch_and_sub (@var{type} *ptr, @var{type} value, ...)\n+@itemx @var{type} __sync_fetch_and_or (@var{type} *ptr, @var{type} value, ...)\n+@itemx @var{type} __sync_fetch_and_and (@var{type} *ptr, @var{type} value, ...)\n+@itemx @var{type} __sync_fetch_and_xor (@var{type} *ptr, @var{type} value, ...)\n+@itemx @var{type} __sync_fetch_and_nand (@var{type} *ptr, @var{type} value, ...)\n+@findex __sync_fetch_and_add\n+@findex __sync_fetch_and_sub\n+@findex __sync_fetch_and_or\n+@findex __sync_fetch_and_and\n+@findex __sync_fetch_and_xor\n+@findex __sync_fetch_and_nand\n+These builtins perform the operation suggested by the name, and\n+returns the value that had previously been in memory.  That is,\n+\n+@smallexample\n+@{ tmp = *ptr; *ptr @var{op}= value; return tmp; @}\n+@end smallexample\n+\n+The builtin @code{__sync_fetch_and_nand} could be implemented by\n+@code{__sync_fetch_and_and(ptr, ~value)}.\n+\n+@item @var{type} __sync_add_and_fetch (@var{type} *ptr, @var{type} value, ...)\n+@itemx @var{type} __sync_sub_and_fetch (@var{type} *ptr, @var{type} value, ...)\n+@itemx @var{type} __sync_or_and_fetch (@var{type} *ptr, @var{type} value, ...)\n+@itemx @var{type} __sync_and_and_fetch (@var{type} *ptr, @var{type} value, ...)\n+@itemx @var{type} __sync_xor_and_fetch (@var{type} *ptr, @var{type} value, ...)\n+@itemx @var{type} __sync_nand_and_fetch (@var{type} *ptr, @var{type} value, ...)\n+@findex __sync_add_and_fetch\n+@findex __sync_sub_and_fetch\n+@findex __sync_or_and_fetch\n+@findex __sync_and_and_fetch\n+@findex __sync_xor_and_fetch\n+@findex __sync_nand_and_fetch\n+These builtins perform the operation suggested by the name, and\n+return the new value.  That is,\n+\n+@smallexample\n+@{ *ptr @var{op}= value; return *ptr; @}\n+@end smallexample\n+\n+@item bool __sync_bool_compare_and_swap (@var{type} *ptr, @var{type} oldval @var{type} newval, ...)\n+@itemx @var{type} __sync_val_compare_and_swap (@var{type} *ptr, @var{type} oldval @var{type} newval, ...)\n+@findex __sync_bool_compare_and_swap\n+@findex __sync_val_compare_and_swap\n+These builtins perform an atomic compare and swap.  That is, if the current\n+value of @code{*@var{ptr}} is @var{oldval}, then write @var{newval} into\n+@code{*@var{ptr}}.\n+\n+The ``bool'' version returns true if the comparison is successful and \n+@var{newval} was written.  The ``val'' version returns the contents\n+of @code{*@var{ptr}} after the operation.\n+\n+@item __sync_synchronize (...)\n+@findex __sync_synchronize\n+This builtin issues a full memory barrier.\n+\n+@item @var{type} __sync_lock_test_and_set (@var{type} *ptr, @var{type} value, ...)\n+@findex __sync_lock_test_and_set\n+This builtin, as described by Intel, is not a traditional test-and-set\n+operation, but rather an atomic exchange operation.  It writes @var{value}\n+into @code{*@var{ptr}}, and returns the previous contents of\n+@code{*@var{ptr}}.\n+\n+Many targets have only minimal support for such locks, and do not support\n+a full exchange operation.  In this case, a target may support reduced\n+functionality here by which the @emph{only} valid value to store is the\n+immediate constant 1.  The exact value actually stored in @code{*@var{ptr}}\n+is implementation defined.\n+\n+This builtin is not a full barrier, but rather an @dfn{acquire barrier}.\n+This means that references after the builtin cannot move to (or be\n+speculated to) before the builtin, but previous memory stores may not\n+be globally visible yet, and previous memory loads may not yet be \n+satisfied.\n+\n+@item void __sync_lock_release (@var{type} *ptr, ...)\n+@findex __sync_lock_release\n+This builtin releases the lock acquired by @code{__sync_lock_test_and_set}.\n+Normally this means writing the constant 0 to @code{*@var{ptr}}.\n+\n+This builtin is not a full barrier, but rather a @dfn{release barrier}.\n+This means that all previous memory stores are globally visible, and all\n+previous memory loads have been satisfied, but following memory reads\n+are not prevented from being speculated to before the barrier.\n+@end table\n+\n @node Other Builtins\n @section Other built-in functions provided by GCC\n @cindex built-in functions"}, {"sha": "4deacfb67d7c5b3f978e55065f283cc2c8f700d8", "filename": "gcc/doc/md.texi", "status": "modified", "additions": 134, "deletions": 0, "changes": 134, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fdoc%2Fmd.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fdoc%2Fmd.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fmd.texi?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -3936,6 +3936,140 @@ respectively, a low or moderate degree of temporal locality.\n Targets that do not support write prefetches or locality hints can ignore\n the values of operands 1 and 2.\n \n+@cindex @code{memory_barrier} instruction pattern\n+@item @samp{memory_barrier}\n+\n+If the target memory model is not fully synchronous, then this pattern\n+should be defined to an instruction that orders both loads and stores\n+before the instruction with respect to loads and stores after the instruction.\n+This pattern has no operands.\n+\n+@cindex @code{sync_compare_and_swap@var{mode}} instruction pattern\n+@item @samp{sync_compare_and_swap@var{mode}}\n+\n+This pattern, if defined, emits code for an atomic compare-and-swap\n+operation.  Operand 1 is the memory on which the atomic operation is\n+performed.  Operand 2 is the ``old'' value to be compared against the\n+current contents of the memory location.  Operand 3 is the ``new'' value\n+to store in the memory if the compare succeeds.  Operand 0 is the result\n+of the operation; it should contain the current contents of the memory\n+after the operation.  If the compare succeeds, this should obviously be\n+a copy of operand 3.\n+\n+This pattern must show that both operand 0 and operand 1 are modified.\n+\n+This pattern must issue any memory barrier instructions such that the\n+pattern as a whole acts as a full barrier.\n+\n+@cindex @code{sync_compare_and_swap_cc@var{mode}} instruction pattern\n+@item @samp{sync_compare_and_swap_cc@var{mode}}\n+\n+This pattern is just like @code{sync_compare_and_swap@var{mode}}, except\n+it should act as if compare part of the compare-and-swap were issued via\n+@code{cmp@var{m}}.  This comparison will only be used with @code{EQ} and\n+@code{NE} branches and @code{setcc} operations.\n+\n+Some targets do expose the success or failure of the compare-and-swap\n+operation via the status flags.  Ideally we wouldn't need a separate\n+named pattern in order to take advantage of this, but the combine pass\n+does not handle patterns with multiple sets, which is required by\n+definition for @code{sync_compare_and_swap@var{mode}}.\n+\n+@cindex @code{sync_add@var{mode}} instruction pattern\n+@cindex @code{sync_sub@var{mode}} instruction pattern\n+@cindex @code{sync_ior@var{mode}} instruction pattern\n+@cindex @code{sync_and@var{mode}} instruction pattern\n+@cindex @code{sync_xor@var{mode}} instruction pattern\n+@cindex @code{sync_nand@var{mode}} instruction pattern\n+@item @samp{sync_add@var{mode}}, @samp{sync_sub@var{mode}}\n+@itemx @samp{sync_ior@var{mode}}, @samp{sync_and@var{mode}}\n+@itemx @samp{sync_xor@var{mode}}, @samp{sync_nand@var{mode}}\n+\n+These patterns emit code for an atomic operation on memory.\n+Operand 0 is the memory on which the atomic operation is performed.\n+Operand 1 is the second operand to the binary operator.\n+\n+The ``nand'' operation is @code{op0 & ~op1}.\n+\n+This pattern must issue any memory barrier instructions such that the\n+pattern as a whole acts as a full barrier.\n+\n+If these patterns are not defined, the operation will be constructed\n+from a compare-and-swap operation, if defined.\n+\n+@cindex @code{sync_old_add@var{mode}} instruction pattern\n+@cindex @code{sync_old_sub@var{mode}} instruction pattern\n+@cindex @code{sync_old_ior@var{mode}} instruction pattern\n+@cindex @code{sync_old_and@var{mode}} instruction pattern\n+@cindex @code{sync_old_xor@var{mode}} instruction pattern\n+@cindex @code{sync_old_nand@var{mode}} instruction pattern\n+@item @samp{sync_old_add@var{mode}}, @samp{sync_old_sub@var{mode}}\n+@itemx @samp{sync_old_ior@var{mode}}, @samp{sync_old_and@var{mode}}\n+@itemx @samp{sync_old_xor@var{mode}}, @samp{sync_old_nand@var{mode}}\n+\n+These patterns are emit code for an atomic operation on memory,\n+and return the value that the memory contained before the operation.\n+Operand 0 is the result value, operand 1 is the memory on which the\n+atomic operation is performed, and operand 2 is the second operand\n+to the binary operator.\n+\n+This pattern must issue any memory barrier instructions such that the\n+pattern as a whole acts as a full barrier.\n+\n+If these patterns are not defined, the operation will be constructed\n+from a compare-and-swap operation, if defined.\n+\n+@cindex @code{sync_new_add@var{mode}} instruction pattern\n+@cindex @code{sync_new_sub@var{mode}} instruction pattern\n+@cindex @code{sync_new_ior@var{mode}} instruction pattern\n+@cindex @code{sync_new_and@var{mode}} instruction pattern\n+@cindex @code{sync_new_xor@var{mode}} instruction pattern\n+@cindex @code{sync_new_nand@var{mode}} instruction pattern\n+@item @samp{sync_new_add@var{mode}}, @samp{sync_new_sub@var{mode}}\n+@itemx @samp{sync_new_ior@var{mode}}, @samp{sync_new_and@var{mode}}\n+@itemx @samp{sync_new_xor@var{mode}}, @samp{sync_new_nand@var{mode}}\n+\n+These patterns are like their @code{sync_old_@var{op}} counterparts,\n+except that they return the value that exists in the memory location\n+after the operation, rather than before the operation.\n+\n+@cindex @code{sync_lock_test_and_set@var{mode}} instruction pattern\n+@item @samp{sync_lock_test_and_set@var{mode}}\n+\n+This pattern takes two forms, based on the capabilities of the target.\n+In either case, operand 0 is the result of the operand, operand 1 is\n+the memory on which the atomic operation is performed, and operand 2\n+is the value to set in the lock.\n+\n+In the ideal case, this operation is an atomic exchange operation, in\n+which the previous value in memory operand is copied into the result\n+operand, and the value operand is stored in the memory operand.\n+\n+For less capable targets, any value operand that is not the constant 1\n+should be rejected with @code{FAIL}.  In this case the target may use\n+an atomic test-and-set bit operation.  The result operand should contain\n+1 if the bit was previously set and 0 if the bit was previously clear.\n+The true contents of the memory operand are implementation defined.\n+\n+This pattern must issue any memory barrier instructions such that the\n+pattern as a whole acts as an acquire barrier.\n+\n+If this pattern is not defined, the operation will be constructed from\n+a compare-and-swap operation, if defined.\n+\n+@cindex @code{sync_lock_release@var{mode}} instruction pattern\n+@item @samp{sync_lock_release@var{mode}}\n+\n+This pattern, if defined, releases a lock set by\n+@code{sync_lock_test_and_set@var{mode}}.  Operand 0 is the memory\n+that contains the lock.\n+\n+This pattern must issue any memory barrier instructions such that the\n+pattern as a whole acts as a release barrier.\n+\n+If this pattern is not defined, then a @code{memory_barrier} pattern\n+will be emitted, followed by a store of zero to the memory operand.\n+\n @end table\n \n @end ifset"}, {"sha": "b334453efd597677284aedc53389a2ace9483b88", "filename": "gcc/expr.c", "status": "modified", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -208,6 +208,30 @@ enum insn_code clrmem_optab[NUM_MACHINE_MODES];\n enum insn_code cmpstr_optab[NUM_MACHINE_MODES];\n enum insn_code cmpmem_optab[NUM_MACHINE_MODES];\n \n+/* Synchronization primitives.  */\n+enum insn_code sync_add_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_sub_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_ior_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_and_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_xor_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_nand_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_old_add_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_old_sub_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_old_ior_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_old_and_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_old_xor_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_old_nand_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_new_add_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_new_sub_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_new_ior_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_new_and_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_new_xor_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_new_nand_optab[NUM_MACHINE_MODES];\n+enum insn_code sync_compare_and_swap[NUM_MACHINE_MODES];\n+enum insn_code sync_compare_and_swap_cc[NUM_MACHINE_MODES];\n+enum insn_code sync_lock_test_and_set[NUM_MACHINE_MODES];\n+enum insn_code sync_lock_release[NUM_MACHINE_MODES];\n+\n /* SLOW_UNALIGNED_ACCESS is nonzero if unaligned accesses are very slow.  */\n \n #ifndef SLOW_UNALIGNED_ACCESS"}, {"sha": "f462dc84b47216c623d722f35a3b4e7e81dc188e", "filename": "gcc/expr.h", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fexpr.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fexpr.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.h?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -310,6 +310,11 @@ int can_conditionally_move_p (enum machine_mode mode);\n rtx emit_conditional_add (rtx, enum rtx_code, rtx, rtx, enum machine_mode,\n \t\t\t  rtx, rtx, enum machine_mode, int);\n \n+rtx expand_val_compare_and_swap (rtx, rtx, rtx, rtx);\n+rtx expand_bool_compare_and_swap (rtx, rtx, rtx, rtx);\n+rtx expand_sync_operation (rtx, rtx, enum rtx_code);\n+rtx expand_sync_fetch_operation (rtx, rtx, enum rtx_code, bool, rtx);\n+rtx expand_sync_lock_test_and_set (rtx, rtx, rtx);\n \f\n /* Functions from expmed.c:  */\n "}, {"sha": "d58f8811812365516750531ff33f42c8bbf85eed", "filename": "gcc/genopinit.c", "status": "modified", "additions": 24, "deletions": 1, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fgenopinit.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Fgenopinit.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgenopinit.c?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -171,12 +171,35 @@ static const char * const optabs[] =\n   \"clrmem_optab[$A] = CODE_FOR_$(clrmem$a$)\",\n   \"cmpstr_optab[$A] = CODE_FOR_$(cmpstr$a$)\",\n   \"cmpmem_optab[$A] = CODE_FOR_$(cmpmem$a$)\",\n+  \"sync_add_optab[$A] = CODE_FOR_$(sync_add$I$a$)\",\n+  \"sync_sub_optab[$A] = CODE_FOR_$(sync_sub$I$a$)\",\n+  \"sync_ior_optab[$A] = CODE_FOR_$(sync_ior$I$a$)\",\n+  \"sync_and_optab[$A] = CODE_FOR_$(sync_and$I$a$)\",\n+  \"sync_xor_optab[$A] = CODE_FOR_$(sync_xor$I$a$)\",\n+  \"sync_nand_optab[$A] = CODE_FOR_$(sync_nand$I$a$)\",\n+  \"sync_old_add_optab[$A] = CODE_FOR_$(sync_old_add$I$a$)\",\n+  \"sync_old_sub_optab[$A] = CODE_FOR_$(sync_old_sub$I$a$)\",\n+  \"sync_old_ior_optab[$A] = CODE_FOR_$(sync_old_ior$I$a$)\",\n+  \"sync_old_and_optab[$A] = CODE_FOR_$(sync_old_and$I$a$)\",\n+  \"sync_old_xor_optab[$A] = CODE_FOR_$(sync_old_xor$I$a$)\",\n+  \"sync_old_nand_optab[$A] = CODE_FOR_$(sync_old_nand$I$a$)\",\n+  \"sync_new_add_optab[$A] = CODE_FOR_$(sync_new_add$I$a$)\",\n+  \"sync_new_sub_optab[$A] = CODE_FOR_$(sync_new_sub$I$a$)\",\n+  \"sync_new_ior_optab[$A] = CODE_FOR_$(sync_new_ior$I$a$)\",\n+  \"sync_new_and_optab[$A] = CODE_FOR_$(sync_new_and$I$a$)\",\n+  \"sync_new_xor_optab[$A] = CODE_FOR_$(sync_new_xor$I$a$)\",\n+  \"sync_new_nand_optab[$A] = CODE_FOR_$(sync_new_nand$I$a$)\",\n+  \"sync_compare_and_swap[$A] = CODE_FOR_$(sync_compare_and_swap$I$a$)\",\n+  \"sync_compare_and_swap_cc[$A] = CODE_FOR_$(sync_compare_and_swap_cc$I$a$)\",\n+  \"sync_lock_test_and_set[$A] = CODE_FOR_$(sync_lock_test_and_set$I$a$)\",\n+  \"sync_lock_release[$A] = CODE_FOR_$(sync_lock_release$I$a$)\",\n   \"vec_set_optab->handlers[$A].insn_code = CODE_FOR_$(vec_set$a$)\",\n   \"vec_extract_optab->handlers[$A].insn_code = CODE_FOR_$(vec_extract$a$)\",\n   \"vec_init_optab->handlers[$A].insn_code = CODE_FOR_$(vec_init$a$)\",\n   \"vec_realign_load_optab->handlers[$A].insn_code = CODE_FOR_$(vec_realign_load_$a$)\",\n   \"vcond_gen_code[$A] = CODE_FOR_$(vcond$a$)\",\n-  \"vcondu_gen_code[$A] = CODE_FOR_$(vcondu$a$)\" };\n+  \"vcondu_gen_code[$A] = CODE_FOR_$(vcondu$a$)\"\n+};\n \n static void gen_insn (rtx);\n "}, {"sha": "47eec4bbcf3b9460b2d988aefe0d5b86990ac749", "filename": "gcc/optabs.c", "status": "modified", "additions": 536, "deletions": 0, "changes": 536, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Foptabs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Foptabs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Foptabs.c?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -5093,6 +5093,29 @@ init_optabs (void)\n       cmpstr_optab[i] = CODE_FOR_nothing;\n       cmpmem_optab[i] = CODE_FOR_nothing;\n \n+      sync_add_optab[i] = CODE_FOR_nothing;\n+      sync_sub_optab[i] = CODE_FOR_nothing;\n+      sync_ior_optab[i] = CODE_FOR_nothing;\n+      sync_and_optab[i] = CODE_FOR_nothing;\n+      sync_xor_optab[i] = CODE_FOR_nothing;\n+      sync_nand_optab[i] = CODE_FOR_nothing;\n+      sync_old_add_optab[i] = CODE_FOR_nothing;\n+      sync_old_sub_optab[i] = CODE_FOR_nothing;\n+      sync_old_ior_optab[i] = CODE_FOR_nothing;\n+      sync_old_and_optab[i] = CODE_FOR_nothing;\n+      sync_old_xor_optab[i] = CODE_FOR_nothing;\n+      sync_old_nand_optab[i] = CODE_FOR_nothing;\n+      sync_new_add_optab[i] = CODE_FOR_nothing;\n+      sync_new_sub_optab[i] = CODE_FOR_nothing;\n+      sync_new_ior_optab[i] = CODE_FOR_nothing;\n+      sync_new_and_optab[i] = CODE_FOR_nothing;\n+      sync_new_xor_optab[i] = CODE_FOR_nothing;\n+      sync_new_nand_optab[i] = CODE_FOR_nothing;\n+      sync_compare_and_swap[i] = CODE_FOR_nothing;\n+      sync_compare_and_swap_cc[i] = CODE_FOR_nothing;\n+      sync_lock_test_and_set[i] = CODE_FOR_nothing;\n+      sync_lock_release[i] = CODE_FOR_nothing;\n+\n #ifdef HAVE_SECONDARY_RELOADS\n       reload_in_optab[i] = reload_out_optab[i] = CODE_FOR_nothing;\n #endif\n@@ -5486,4 +5509,517 @@ expand_vec_cond_expr (tree vec_cond_expr, rtx target)\n \n   return target;\n }\n+\n+\f\n+/* This is an internal subroutine of the other compare_and_swap expanders.\n+   MEM, OLD_VAL and NEW_VAL are as you'd expect for a compare-and-swap\n+   operation.  TARGET is an optional place to store the value result of\n+   the operation.  ICODE is the particular instruction to expand.  Return\n+   the result of the operation.  */\n+\n+static rtx\n+expand_val_compare_and_swap_1 (rtx mem, rtx old_val, rtx new_val,\n+\t\t\t       rtx target, enum insn_code icode)\n+{\n+  enum machine_mode mode = GET_MODE (mem);\n+  rtx insn;\n+\n+  if (!target || !insn_data[icode].operand[0].predicate (target, mode))\n+    target = gen_reg_rtx (mode);\n+\n+  if (GET_MODE (old_val) != VOIDmode && GET_MODE (old_val) != mode)\n+    old_val = convert_modes (mode, GET_MODE (old_val), old_val, 1);\n+  if (!insn_data[icode].operand[2].predicate (old_val, mode))\n+    old_val = force_reg (mode, old_val);\n+\n+  if (GET_MODE (new_val) != VOIDmode && GET_MODE (new_val) != mode)\n+    new_val = convert_modes (mode, GET_MODE (new_val), new_val, 1);\n+  if (!insn_data[icode].operand[3].predicate (new_val, mode))\n+    new_val = force_reg (mode, new_val);\n+\n+  insn = GEN_FCN (icode) (target, mem, old_val, new_val);\n+  if (insn == NULL_RTX)\n+    return NULL_RTX;\n+  emit_insn (insn);\n+\n+  return target;\n+}\n+\n+/* Expand a compare-and-swap operation and return its value.  */\n+\n+rtx\n+expand_val_compare_and_swap (rtx mem, rtx old_val, rtx new_val, rtx target)\n+{\n+  enum machine_mode mode = GET_MODE (mem);\n+  enum insn_code icode = sync_compare_and_swap[mode];\n+\n+  if (icode == CODE_FOR_nothing)\n+    return NULL_RTX;\n+\n+  return expand_val_compare_and_swap_1 (mem, old_val, new_val, target, icode);\n+}\n+\n+/* Expand a compare-and-swap operation and store true into the result if\n+   the operation was successful and false otherwise.  Return the result.\n+   Unlike other routines, TARGET is not optional.  */\n+\n+rtx\n+expand_bool_compare_and_swap (rtx mem, rtx old_val, rtx new_val, rtx target)\n+{\n+  enum machine_mode mode = GET_MODE (mem);\n+  enum insn_code icode;\n+  rtx subtarget, label0, label1;\n+\n+  /* If the target supports a compare-and-swap pattern that simultaneously\n+     sets some flag for success, then use it.  Otherwise use the regular\n+     compare-and-swap and follow that immediately with a compare insn.  */\n+  icode = sync_compare_and_swap_cc[mode];\n+  switch (icode)\n+    {\n+    default:\n+      subtarget = expand_val_compare_and_swap_1 (mem, old_val, new_val,\n+\t\t\t\t\t\t NULL_RTX, icode);\n+      if (subtarget != NULL_RTX)\n+\tbreak;\n+\n+      /* FALLTHRU */\n+    case CODE_FOR_nothing:\n+      icode = sync_compare_and_swap[mode];\n+      if (icode == CODE_FOR_nothing)\n+\treturn NULL_RTX;\n+\n+      subtarget = expand_val_compare_and_swap_1 (mem, old_val, new_val,\n+\t\t\t\t\t\t NULL_RTX, icode);\n+      if (subtarget == NULL_RTX)\n+\treturn NULL_RTX;\n+\n+      emit_cmp_insn (subtarget, new_val, EQ, const0_rtx, mode, true);\n+    }\n+\n+  /* If the target has a sane STORE_FLAG_VALUE, then go ahead and use a\n+     setcc instruction from the beginning.  We don't work too hard here,\n+     but it's nice to not be stupid about initial code gen either.  */\n+  if (STORE_FLAG_VALUE == 1)\n+    {\n+      icode = setcc_gen_code[EQ];\n+      if (icode != CODE_FOR_nothing)\n+\t{\n+\t  enum machine_mode cmode = insn_data[icode].operand[0].mode;\n+\t  rtx insn;\n+\n+\t  subtarget = target;\n+\t  if (!insn_data[icode].operand[0].predicate (target, cmode))\n+\t    subtarget = gen_reg_rtx (cmode);\n+\n+\t  insn = GEN_FCN (icode) (subtarget);\n+\t  if (insn)\n+\t    {\n+\t      emit_insn (insn);\n+\t      if (GET_MODE (target) != GET_MODE (subtarget))\n+\t\t{\n+\t          convert_move (target, subtarget, 1);\n+\t\t  subtarget = target;\n+\t\t}\n+\t      return subtarget;\n+\t    }\n+\t}\n+    }\n+\n+  /* Without an appropriate setcc instruction, use a set of branches to \n+     get 1 and 0 stored into target.  Presumably if the target has a \n+     STORE_FLAG_VALUE that isn't 1, then this will get cleaned up by ifcvt.  */\n+\n+  label0 = gen_label_rtx ();\n+  label1 = gen_label_rtx ();\n+\n+  emit_jump_insn (bcc_gen_fctn[EQ] (label0));\n+  emit_move_insn (target, const0_rtx);\n+  emit_jump_insn (gen_jump (label1));\n+  emit_label (label0);\n+  emit_move_insn (target, const1_rtx);\n+  emit_label (label1);\n+\n+  return target;\n+}\n+\n+/* This is a helper function for the other atomic operations.  This function\n+   emits a loop that contains SEQ that iterates until a compare-and-swap\n+   operation at the end succeeds.  MEM is the memory to be modified.  SEQ is\n+   a set of instructions that takes a value from OLD_REG as an input and\n+   produces a value in NEW_REG as an output.  Before SEQ, OLD_REG will be\n+   set to the current contents of MEM.  After SEQ, a compare-and-swap will\n+   attempt to update MEM with NEW_REG.  The function returns true when the\n+   loop was generated successfully.  */\n+\n+static bool\n+expand_compare_and_swap_loop (rtx mem, rtx old_reg, rtx new_reg, rtx seq)\n+{\n+  enum machine_mode mode = GET_MODE (mem);\n+  enum insn_code icode;\n+  rtx label, subtarget;\n+\n+  /* The loop we want to generate looks like\n+\n+\told_reg = mem;\n+      label:\n+\tseq;\n+\told_reg = compare-and-swap(mem, old_reg, new_reg)\n+\tif (old_reg != new_reg)\n+\t  goto label;\n+\n+     Note that we only do the plain load from memory once.  Subsequent\n+     iterations use the value loaded by the compare-and-swap pattern.  */\n+\n+  label = gen_label_rtx ();\n+\n+  emit_move_insn (old_reg, mem);\n+  emit_label (label);\n+  if (seq)\n+    emit_insn (seq);\n+\n+  /* If the target supports a compare-and-swap pattern that simultaneously\n+     sets some flag for success, then use it.  Otherwise use the regular\n+     compare-and-swap and follow that immediately with a compare insn.  */\n+  icode = sync_compare_and_swap_cc[mode];\n+  switch (icode)\n+    {\n+    default:\n+      subtarget = expand_val_compare_and_swap_1 (mem, old_reg, new_reg,\n+\t\t\t\t\t\t old_reg, icode);\n+      if (subtarget != NULL_RTX)\n+\tbreak;\n+\n+      /* FALLTHRU */\n+    case CODE_FOR_nothing:\n+      icode = sync_compare_and_swap[mode];\n+      if (icode == CODE_FOR_nothing)\n+\treturn false;\n+\n+      subtarget = expand_val_compare_and_swap_1 (mem, old_reg, new_reg,\n+\t\t\t\t\t\t old_reg, icode);\n+      if (subtarget == NULL_RTX)\n+\treturn false;\n+\n+      emit_cmp_insn (subtarget, new_reg, EQ, const0_rtx, mode, true);\n+    }\n+\n+  /* ??? Mark this jump predicted not taken?  */\n+  emit_jump_insn (bcc_gen_fctn[NE] (label));\n+\n+  return true;\n+}\n+\n+/* This function generates the atomic operation MEM CODE= VAL.  In this\n+   case, we do not care about any resulting value.  Returns NULL if we \n+   cannot generate the operation.  */\n+\n+rtx\n+expand_sync_operation (rtx mem, rtx val, enum rtx_code code)\n+{\n+  enum machine_mode mode = GET_MODE (mem);\n+  enum insn_code icode;\n+  rtx insn;\n+\n+  /* Look to see if the target supports the operation directly.  */\n+  switch (code)\n+    {\n+    case PLUS:\n+      icode = sync_add_optab[mode];\n+      break;\n+    case IOR:\n+      icode = sync_ior_optab[mode];\n+      break;\n+    case XOR:\n+      icode = sync_xor_optab[mode];\n+      break;\n+    case AND:\n+      icode = sync_and_optab[mode];\n+      break;\n+\n+    case MINUS:\n+      icode = sync_sub_optab[mode];\n+      if (icode == CODE_FOR_nothing)\n+\t{\n+\t  icode = sync_add_optab[mode];\n+\t  if (icode != CODE_FOR_nothing)\n+\t    {\n+\t      val = expand_simple_unop (mode, NEG, val, NULL_RTX, 1);\n+\t      code = PLUS;\n+\t    }\n+\t}\n+      break;\n+\n+    case NOT:\n+      icode = sync_nand_optab[mode];\n+      if (icode != CODE_FOR_nothing)\n+\t{\n+\t  icode = sync_and_optab[mode];\n+\t  if (icode != CODE_FOR_nothing)\n+\t    {\n+\t      val = expand_simple_unop (mode, NOT, val, NULL_RTX, 1);\n+\t      code = AND;\n+\t    }\n+\t}\n+      break;\n+\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  /* Generate the direct operation, if present.  */\n+  if (icode != CODE_FOR_nothing)\n+    {\n+      if (GET_MODE (val) != VOIDmode && GET_MODE (val) != mode)\n+\tval = convert_modes (mode, GET_MODE (val), val, 1);\n+      if (!insn_data[icode].operand[1].predicate (val, mode))\n+\tval = force_reg (mode, val);\n+      \n+      insn = GEN_FCN (icode) (mem, val);\n+      if (insn)\n+\t{\n+\t  emit_insn (insn);\n+\t  return const0_rtx;\n+\t}\n+    }\n+\n+  /* Failing that, generate a compare-and-swap loop in which we perform the\n+     operation with normal arithmetic instructions.  */\n+  if (sync_compare_and_swap[mode] != CODE_FOR_nothing)\n+    {\n+      rtx t0 = gen_reg_rtx (mode), t1;\n+\n+      start_sequence ();\n+\n+      if (code == NOT)\n+\t{\n+\t  val = expand_simple_unop (mode, NOT, val, NULL_RTX, true);\n+\t  code = AND;\n+\t}\n+      t1 = expand_simple_binop (mode, code, t0, val, NULL_RTX,\n+\t\t\t\ttrue, OPTAB_LIB_WIDEN);\n+\n+      insn = get_insns ();\n+      end_sequence ();\n+\n+      if (t1 != NULL && expand_compare_and_swap_loop (mem, t0, t1, insn))\n+\treturn const0_rtx;\n+    }\n+\n+  return NULL_RTX;\n+}\n+\n+/* This function generates the atomic operation MEM CODE= VAL.  In this\n+   case, we do care about the resulting value: if AFTER is true then\n+   return the value MEM holds after the operation, if AFTER is false \n+   then return the value MEM holds before the operation.  TARGET is an\n+   optional place for the result value to be stored.  */\n+\n+rtx\n+expand_sync_fetch_operation (rtx mem, rtx val, enum rtx_code code,\n+\t\t\t     bool after, rtx target)\n+{\n+  enum machine_mode mode = GET_MODE (mem);\n+  enum insn_code old_code, new_code, icode;\n+  bool compensate;\n+  rtx insn;\n+\n+  /* Look to see if the target supports the operation directly.  */\n+  switch (code)\n+    {\n+    case PLUS:\n+      old_code = sync_old_add_optab[mode];\n+      new_code = sync_new_add_optab[mode];\n+      break;\n+    case IOR:\n+      old_code = sync_old_ior_optab[mode];\n+      new_code = sync_new_ior_optab[mode];\n+      break;\n+    case XOR:\n+      old_code = sync_old_xor_optab[mode];\n+      new_code = sync_new_xor_optab[mode];\n+      break;\n+    case AND:\n+      old_code = sync_old_and_optab[mode];\n+      new_code = sync_new_and_optab[mode];\n+      break;\n+\n+    case MINUS:\n+      old_code = sync_old_sub_optab[mode];\n+      new_code = sync_new_sub_optab[mode];\n+      if (old_code == CODE_FOR_nothing && new_code == CODE_FOR_nothing)\n+\t{\n+\t  old_code = sync_old_add_optab[mode];\n+\t  new_code = sync_new_add_optab[mode];\n+\t  if (old_code != CODE_FOR_nothing || new_code != CODE_FOR_nothing)\n+\t    {\n+\t      val = expand_simple_unop (mode, NEG, val, NULL_RTX, 1);\n+\t      code = PLUS;\n+\t    }\n+\t}\n+      break;\n+\n+    case NOT:\n+      old_code = sync_old_nand_optab[mode];\n+      new_code = sync_new_nand_optab[mode];\n+      if (old_code == CODE_FOR_nothing && new_code == CODE_FOR_nothing)\n+\t{\n+\t  old_code = sync_old_sub_optab[mode];\n+\t  new_code = sync_new_sub_optab[mode];\n+\t  if (old_code != CODE_FOR_nothing || new_code != CODE_FOR_nothing)\n+\t    {\n+\t      val = expand_simple_unop (mode, NOT, val, NULL_RTX, 1);\n+\t      code = AND;\n+\t    }\n+\t}\n+      break;\n+\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  /* If the target does supports the proper new/old operation, great.  But\n+     if we only support the opposite old/new operation, check to see if we\n+     can compensate.  In the case in which the old value is supported, then\n+     we can always perform the operation again with normal arithmetic.  In\n+     the case in which the new value is supported, then we can only handle\n+     this in the case the operation is reversible.  */\n+  compensate = false;\n+  if (after)\n+    {\n+      icode = new_code;\n+      if (icode == CODE_FOR_nothing)\n+\t{\n+\t  icode = old_code;\n+\t  if (icode != CODE_FOR_nothing)\n+\t    compensate = true;\n+\t}\n+    }\n+  else\n+    {\n+      icode = old_code;\n+      if (icode == CODE_FOR_nothing\n+\t  && (code == PLUS || code == MINUS || code == XOR))\n+\t{\n+\t  icode = new_code;\n+\t  if (icode != CODE_FOR_nothing)\n+\t    compensate = true;\n+\t}\n+    }\n+\n+  /* If we found something supported, great.  */\n+  if (icode != CODE_FOR_nothing)\n+    {\n+      if (!target || !insn_data[icode].operand[0].predicate (target, mode))\n+\ttarget = gen_reg_rtx (mode);\n+\n+      if (GET_MODE (val) != VOIDmode && GET_MODE (val) != mode)\n+\tval = convert_modes (mode, GET_MODE (val), val, 1);\n+      if (!insn_data[icode].operand[2].predicate (val, mode))\n+\tval = force_reg (mode, val);\n+      \n+      insn = GEN_FCN (icode) (target, mem, val);\n+      if (insn)\n+\t{\n+\t  emit_insn (insn);\n+\n+\t  /* If we need to compensate for using an operation with the\n+\t     wrong return value, do so now.  */\n+\t  if (compensate)\n+\t    {\n+\t      if (!after)\n+\t\t{\n+\t\t  if (code == PLUS)\n+\t\t    code = MINUS;\n+\t\t  else if (code == MINUS)\n+\t\t    code = PLUS;\n+\t\t}\n+\t      target = expand_simple_binop (mode, code, target, val, NULL_RTX,\n+\t\t\t\t\t    true, OPTAB_LIB_WIDEN);\n+\t    }\n+\n+\t  return target;\n+\t}\n+    }\n+\n+  /* Failing that, generate a compare-and-swap loop in which we perform the\n+     operation with normal arithmetic instructions.  */\n+  if (sync_compare_and_swap[mode] != CODE_FOR_nothing)\n+    {\n+      rtx t0 = gen_reg_rtx (mode), t1;\n+\n+      if (!target || !register_operand (target, mode))\n+\ttarget = gen_reg_rtx (mode);\n+\n+      start_sequence ();\n+\n+      if (code == NOT)\n+\t{\n+\t  val = expand_simple_unop (mode, NOT, val, NULL_RTX, true);\n+\t  code = AND;\n+\t}\n+      if (!after)\n+\temit_move_insn (target, t0);\n+      t1 = expand_simple_binop (mode, code, t0, val, NULL_RTX,\n+\t\t\t\ttrue, OPTAB_LIB_WIDEN);\n+      if (after)\n+\temit_move_insn (target, t1);\n+\n+      insn = get_insns ();\n+      end_sequence ();\n+\n+      if (t1 != NULL && expand_compare_and_swap_loop (mem, t0, t1, insn))\n+\treturn target;\n+    }\n+\n+  return NULL_RTX;\n+}\n+\n+/* This function expands a test-and-set operation.  Ideally we atomically\n+   store VAL in MEM and return the previous value in MEM.  Some targets\n+   may not support this operation and only support VAL with the constant 1;\n+   in this case while the return value will be 0/1, but the exact value \n+   stored in MEM is target defined.  TARGET is an option place to stick\n+   the return value.  */\n+\n+rtx\n+expand_sync_lock_test_and_set (rtx mem, rtx val, rtx target)\n+{\n+  enum machine_mode mode = GET_MODE (mem);\n+  enum insn_code icode;\n+  rtx insn;\n+\n+  /* If the target supports the test-and-set directly, great.  */\n+  icode = sync_lock_test_and_set[mode];\n+  if (icode != CODE_FOR_nothing)\n+    {\n+      if (!target || !insn_data[icode].operand[0].predicate (target, mode))\n+\ttarget = gen_reg_rtx (mode);\n+\n+      if (GET_MODE (val) != VOIDmode && GET_MODE (val) != mode)\n+\tval = convert_modes (mode, GET_MODE (val), val, 1);\n+      if (!insn_data[icode].operand[2].predicate (val, mode))\n+\tval = force_reg (mode, val);\n+\n+      insn = GEN_FCN (icode) (target, mem, val);\n+      if (insn)\n+\t{\n+\t  emit_insn (insn);\n+\t  return target;\n+\t}\n+    }\n+\n+  /* Otherwise, use a compare-and-swap loop for the exchange.  */\n+  if (sync_compare_and_swap[mode] != CODE_FOR_nothing)\n+    {\n+      if (!target || !register_operand (target, mode))\n+\ttarget = gen_reg_rtx (mode);\n+      if (GET_MODE (val) != VOIDmode && GET_MODE (val) != mode)\n+\tval = convert_modes (mode, GET_MODE (val), val, 1);\n+      if (expand_compare_and_swap_loop (mem, target, val, NULL_RTX))\n+\treturn target;\n+    }\n+\n+  return NULL_RTX;\n+}\n+\n #include \"gt-optabs.h\""}, {"sha": "1426e570fb9659c1e99839b33d630dd3601e07d2", "filename": "gcc/optabs.h", "status": "modified", "additions": 37, "deletions": 0, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Foptabs.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Foptabs.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Foptabs.h?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -432,6 +432,43 @@ extern enum insn_code clrmem_optab[NUM_MACHINE_MODES];\n extern enum insn_code cmpstr_optab[NUM_MACHINE_MODES];\n extern enum insn_code cmpmem_optab[NUM_MACHINE_MODES];\n \n+/* Synchronization primitives.  This first set is atomic operation for\n+   which we don't care about the resulting value.  */\n+extern enum insn_code sync_add_optab[NUM_MACHINE_MODES];\n+extern enum insn_code sync_sub_optab[NUM_MACHINE_MODES];\n+extern enum insn_code sync_ior_optab[NUM_MACHINE_MODES];\n+extern enum insn_code sync_and_optab[NUM_MACHINE_MODES];\n+extern enum insn_code sync_xor_optab[NUM_MACHINE_MODES];\n+extern enum insn_code sync_nand_optab[NUM_MACHINE_MODES];\n+\n+/* This second set is atomic operations in which we return the value\n+   that existed in memory before the operation.  */\n+extern enum insn_code sync_old_add_optab[NUM_MACHINE_MODES];\n+extern enum insn_code sync_old_sub_optab[NUM_MACHINE_MODES];\n+extern enum insn_code sync_old_ior_optab[NUM_MACHINE_MODES];\n+extern enum insn_code sync_old_and_optab[NUM_MACHINE_MODES];\n+extern enum insn_code sync_old_xor_optab[NUM_MACHINE_MODES];\n+extern enum insn_code sync_old_nand_optab[NUM_MACHINE_MODES];\n+\n+/* This third set is atomic operations in which we return the value\n+   that resulted after performing the operation.  */\n+extern enum insn_code sync_new_add_optab[NUM_MACHINE_MODES];\n+extern enum insn_code sync_new_sub_optab[NUM_MACHINE_MODES];\n+extern enum insn_code sync_new_ior_optab[NUM_MACHINE_MODES];\n+extern enum insn_code sync_new_and_optab[NUM_MACHINE_MODES];\n+extern enum insn_code sync_new_xor_optab[NUM_MACHINE_MODES];\n+extern enum insn_code sync_new_nand_optab[NUM_MACHINE_MODES];\n+\n+/* Atomic compare and swap.  */\n+extern enum insn_code sync_compare_and_swap[NUM_MACHINE_MODES];\n+extern enum insn_code sync_compare_and_swap_cc[NUM_MACHINE_MODES];\n+\n+/* Atomic exchange with acquire semantics.  */\n+extern enum insn_code sync_lock_test_and_set[NUM_MACHINE_MODES];\n+\n+/* Atomic clear with release semantics.  */\n+extern enum insn_code sync_lock_release[NUM_MACHINE_MODES];\n+\n /* Define functions given in optabs.c.  */\n \n extern rtx expand_ternary_op (enum machine_mode mode, optab ternary_optab, "}, {"sha": "1703aaf267f214814685f43922f0b57180e59f56", "filename": "gcc/testsuite/gcc.c-torture/compile/sync-1.c", "status": "added", "additions": 276, "deletions": 0, "changes": 276, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Ftestsuite%2Fgcc.c-torture%2Fcompile%2Fsync-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Ftestsuite%2Fgcc.c-torture%2Fcompile%2Fsync-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.c-torture%2Fcompile%2Fsync-1.c?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -0,0 +1,276 @@\n+/* Validate that each of the __sync builtins compiles.  This won't \n+   necessarily link, since the target might not support the builtin,\n+   so this may result in external library calls.  */\n+\n+signed char sc;\n+unsigned char uc;\n+signed short ss;\n+unsigned short us;\n+signed int si;\n+unsigned int ui;\n+signed long sl;\n+unsigned long ul;\n+signed long long sll;\n+unsigned long long ull;\n+void *vp;\n+int *ip;\n+struct S { struct S *next; int x; } *sp;\n+\n+void test_op_ignore (void)\n+{\n+  (void) __sync_fetch_and_add (&sc, 1);\n+  (void) __sync_fetch_and_add (&uc, 1);\n+  (void) __sync_fetch_and_add (&ss, 1);\n+  (void) __sync_fetch_and_add (&us, 1);\n+  (void) __sync_fetch_and_add (&si, 1);\n+  (void) __sync_fetch_and_add (&ui, 1);\n+  (void) __sync_fetch_and_add (&sl, 1);\n+  (void) __sync_fetch_and_add (&ul, 1);\n+  (void) __sync_fetch_and_add (&sll, 1);\n+  (void) __sync_fetch_and_add (&ull, 1);\n+\n+  (void) __sync_fetch_and_sub (&sc, 1);\n+  (void) __sync_fetch_and_sub (&uc, 1);\n+  (void) __sync_fetch_and_sub (&ss, 1);\n+  (void) __sync_fetch_and_sub (&us, 1);\n+  (void) __sync_fetch_and_sub (&si, 1);\n+  (void) __sync_fetch_and_sub (&ui, 1);\n+  (void) __sync_fetch_and_sub (&sl, 1);\n+  (void) __sync_fetch_and_sub (&ul, 1);\n+  (void) __sync_fetch_and_sub (&sll, 1);\n+  (void) __sync_fetch_and_sub (&ull, 1);\n+\n+  (void) __sync_fetch_and_or (&sc, 1);\n+  (void) __sync_fetch_and_or (&uc, 1);\n+  (void) __sync_fetch_and_or (&ss, 1);\n+  (void) __sync_fetch_and_or (&us, 1);\n+  (void) __sync_fetch_and_or (&si, 1);\n+  (void) __sync_fetch_and_or (&ui, 1);\n+  (void) __sync_fetch_and_or (&sl, 1);\n+  (void) __sync_fetch_and_or (&ul, 1);\n+  (void) __sync_fetch_and_or (&sll, 1);\n+  (void) __sync_fetch_and_or (&ull, 1);\n+\n+  (void) __sync_fetch_and_xor (&sc, 1);\n+  (void) __sync_fetch_and_xor (&uc, 1);\n+  (void) __sync_fetch_and_xor (&ss, 1);\n+  (void) __sync_fetch_and_xor (&us, 1);\n+  (void) __sync_fetch_and_xor (&si, 1);\n+  (void) __sync_fetch_and_xor (&ui, 1);\n+  (void) __sync_fetch_and_xor (&sl, 1);\n+  (void) __sync_fetch_and_xor (&ul, 1);\n+  (void) __sync_fetch_and_xor (&sll, 1);\n+  (void) __sync_fetch_and_xor (&ull, 1);\n+\n+  (void) __sync_fetch_and_and (&sc, 1);\n+  (void) __sync_fetch_and_and (&uc, 1);\n+  (void) __sync_fetch_and_and (&ss, 1);\n+  (void) __sync_fetch_and_and (&us, 1);\n+  (void) __sync_fetch_and_and (&si, 1);\n+  (void) __sync_fetch_and_and (&ui, 1);\n+  (void) __sync_fetch_and_and (&sl, 1);\n+  (void) __sync_fetch_and_and (&ul, 1);\n+  (void) __sync_fetch_and_and (&sll, 1);\n+  (void) __sync_fetch_and_and (&ull, 1);\n+\n+  (void) __sync_fetch_and_nand (&sc, 1);\n+  (void) __sync_fetch_and_nand (&uc, 1);\n+  (void) __sync_fetch_and_nand (&ss, 1);\n+  (void) __sync_fetch_and_nand (&us, 1);\n+  (void) __sync_fetch_and_nand (&si, 1);\n+  (void) __sync_fetch_and_nand (&ui, 1);\n+  (void) __sync_fetch_and_nand (&sl, 1);\n+  (void) __sync_fetch_and_nand (&ul, 1);\n+  (void) __sync_fetch_and_nand (&sll, 1);\n+  (void) __sync_fetch_and_nand (&ull, 1);\n+}\n+\n+void test_fetch_and_op (void)\n+{\n+  sc = __sync_fetch_and_add (&sc, 11);\n+  uc = __sync_fetch_and_add (&uc, 11);\n+  ss = __sync_fetch_and_add (&ss, 11);\n+  us = __sync_fetch_and_add (&us, 11);\n+  si = __sync_fetch_and_add (&si, 11);\n+  ui = __sync_fetch_and_add (&ui, 11);\n+  sl = __sync_fetch_and_add (&sl, 11);\n+  ul = __sync_fetch_and_add (&ul, 11);\n+  sll = __sync_fetch_and_add (&sll, 11);\n+  ull = __sync_fetch_and_add (&ull, 11);\n+\n+  sc = __sync_fetch_and_sub (&sc, 11);\n+  uc = __sync_fetch_and_sub (&uc, 11);\n+  ss = __sync_fetch_and_sub (&ss, 11);\n+  us = __sync_fetch_and_sub (&us, 11);\n+  si = __sync_fetch_and_sub (&si, 11);\n+  ui = __sync_fetch_and_sub (&ui, 11);\n+  sl = __sync_fetch_and_sub (&sl, 11);\n+  ul = __sync_fetch_and_sub (&ul, 11);\n+  sll = __sync_fetch_and_sub (&sll, 11);\n+  ull = __sync_fetch_and_sub (&ull, 11);\n+\n+  sc = __sync_fetch_and_or (&sc, 11);\n+  uc = __sync_fetch_and_or (&uc, 11);\n+  ss = __sync_fetch_and_or (&ss, 11);\n+  us = __sync_fetch_and_or (&us, 11);\n+  si = __sync_fetch_and_or (&si, 11);\n+  ui = __sync_fetch_and_or (&ui, 11);\n+  sl = __sync_fetch_and_or (&sl, 11);\n+  ul = __sync_fetch_and_or (&ul, 11);\n+  sll = __sync_fetch_and_or (&sll, 11);\n+  ull = __sync_fetch_and_or (&ull, 11);\n+\n+  sc = __sync_fetch_and_xor (&sc, 11);\n+  uc = __sync_fetch_and_xor (&uc, 11);\n+  ss = __sync_fetch_and_xor (&ss, 11);\n+  us = __sync_fetch_and_xor (&us, 11);\n+  si = __sync_fetch_and_xor (&si, 11);\n+  ui = __sync_fetch_and_xor (&ui, 11);\n+  sl = __sync_fetch_and_xor (&sl, 11);\n+  ul = __sync_fetch_and_xor (&ul, 11);\n+  sll = __sync_fetch_and_xor (&sll, 11);\n+  ull = __sync_fetch_and_xor (&ull, 11);\n+\n+  sc = __sync_fetch_and_and (&sc, 11);\n+  uc = __sync_fetch_and_and (&uc, 11);\n+  ss = __sync_fetch_and_and (&ss, 11);\n+  us = __sync_fetch_and_and (&us, 11);\n+  si = __sync_fetch_and_and (&si, 11);\n+  ui = __sync_fetch_and_and (&ui, 11);\n+  sl = __sync_fetch_and_and (&sl, 11);\n+  ul = __sync_fetch_and_and (&ul, 11);\n+  sll = __sync_fetch_and_and (&sll, 11);\n+  ull = __sync_fetch_and_and (&ull, 11);\n+\n+  sc = __sync_fetch_and_nand (&sc, 11);\n+  uc = __sync_fetch_and_nand (&uc, 11);\n+  ss = __sync_fetch_and_nand (&ss, 11);\n+  us = __sync_fetch_and_nand (&us, 11);\n+  si = __sync_fetch_and_nand (&si, 11);\n+  ui = __sync_fetch_and_nand (&ui, 11);\n+  sl = __sync_fetch_and_nand (&sl, 11);\n+  ul = __sync_fetch_and_nand (&ul, 11);\n+  sll = __sync_fetch_and_nand (&sll, 11);\n+  ull = __sync_fetch_and_nand (&ull, 11);\n+}\n+\n+void test_op_and_fetch (void)\n+{\n+  sc = __sync_add_and_fetch (&sc, uc);\n+  uc = __sync_add_and_fetch (&uc, uc);\n+  ss = __sync_add_and_fetch (&ss, uc);\n+  us = __sync_add_and_fetch (&us, uc);\n+  si = __sync_add_and_fetch (&si, uc);\n+  ui = __sync_add_and_fetch (&ui, uc);\n+  sl = __sync_add_and_fetch (&sl, uc);\n+  ul = __sync_add_and_fetch (&ul, uc);\n+  sll = __sync_add_and_fetch (&sll, uc);\n+  ull = __sync_add_and_fetch (&ull, uc);\n+\n+  sc = __sync_sub_and_fetch (&sc, uc);\n+  uc = __sync_sub_and_fetch (&uc, uc);\n+  ss = __sync_sub_and_fetch (&ss, uc);\n+  us = __sync_sub_and_fetch (&us, uc);\n+  si = __sync_sub_and_fetch (&si, uc);\n+  ui = __sync_sub_and_fetch (&ui, uc);\n+  sl = __sync_sub_and_fetch (&sl, uc);\n+  ul = __sync_sub_and_fetch (&ul, uc);\n+  sll = __sync_sub_and_fetch (&sll, uc);\n+  ull = __sync_sub_and_fetch (&ull, uc);\n+\n+  sc = __sync_or_and_fetch (&sc, uc);\n+  uc = __sync_or_and_fetch (&uc, uc);\n+  ss = __sync_or_and_fetch (&ss, uc);\n+  us = __sync_or_and_fetch (&us, uc);\n+  si = __sync_or_and_fetch (&si, uc);\n+  ui = __sync_or_and_fetch (&ui, uc);\n+  sl = __sync_or_and_fetch (&sl, uc);\n+  ul = __sync_or_and_fetch (&ul, uc);\n+  sll = __sync_or_and_fetch (&sll, uc);\n+  ull = __sync_or_and_fetch (&ull, uc);\n+\n+  sc = __sync_xor_and_fetch (&sc, uc);\n+  uc = __sync_xor_and_fetch (&uc, uc);\n+  ss = __sync_xor_and_fetch (&ss, uc);\n+  us = __sync_xor_and_fetch (&us, uc);\n+  si = __sync_xor_and_fetch (&si, uc);\n+  ui = __sync_xor_and_fetch (&ui, uc);\n+  sl = __sync_xor_and_fetch (&sl, uc);\n+  ul = __sync_xor_and_fetch (&ul, uc);\n+  sll = __sync_xor_and_fetch (&sll, uc);\n+  ull = __sync_xor_and_fetch (&ull, uc);\n+\n+  sc = __sync_and_and_fetch (&sc, uc);\n+  uc = __sync_and_and_fetch (&uc, uc);\n+  ss = __sync_and_and_fetch (&ss, uc);\n+  us = __sync_and_and_fetch (&us, uc);\n+  si = __sync_and_and_fetch (&si, uc);\n+  ui = __sync_and_and_fetch (&ui, uc);\n+  sl = __sync_and_and_fetch (&sl, uc);\n+  ul = __sync_and_and_fetch (&ul, uc);\n+  sll = __sync_and_and_fetch (&sll, uc);\n+  ull = __sync_and_and_fetch (&ull, uc);\n+\n+  sc = __sync_nand_and_fetch (&sc, uc);\n+  uc = __sync_nand_and_fetch (&uc, uc);\n+  ss = __sync_nand_and_fetch (&ss, uc);\n+  us = __sync_nand_and_fetch (&us, uc);\n+  si = __sync_nand_and_fetch (&si, uc);\n+  ui = __sync_nand_and_fetch (&ui, uc);\n+  sl = __sync_nand_and_fetch (&sl, uc);\n+  ul = __sync_nand_and_fetch (&ul, uc);\n+  sll = __sync_nand_and_fetch (&sll, uc);\n+  ull = __sync_nand_and_fetch (&ull, uc);\n+}\n+\n+void test_compare_and_swap (void)\n+{\n+  sc = __sync_val_compare_and_swap (&sc, uc, sc);\n+  uc = __sync_val_compare_and_swap (&uc, uc, sc);\n+  ss = __sync_val_compare_and_swap (&ss, uc, sc);\n+  us = __sync_val_compare_and_swap (&us, uc, sc);\n+  si = __sync_val_compare_and_swap (&si, uc, sc);\n+  ui = __sync_val_compare_and_swap (&ui, uc, sc);\n+  sl = __sync_val_compare_and_swap (&sl, uc, sc);\n+  ul = __sync_val_compare_and_swap (&ul, uc, sc);\n+  sll = __sync_val_compare_and_swap (&sll, uc, sc);\n+  ull = __sync_val_compare_and_swap (&ull, uc, sc);\n+\n+  ui = __sync_bool_compare_and_swap (&sc, uc, sc);\n+  ui = __sync_bool_compare_and_swap (&uc, uc, sc);\n+  ui = __sync_bool_compare_and_swap (&ss, uc, sc);\n+  ui = __sync_bool_compare_and_swap (&us, uc, sc);\n+  ui = __sync_bool_compare_and_swap (&si, uc, sc);\n+  ui = __sync_bool_compare_and_swap (&ui, uc, sc);\n+  ui = __sync_bool_compare_and_swap (&sl, uc, sc);\n+  ui = __sync_bool_compare_and_swap (&ul, uc, sc);\n+  ui = __sync_bool_compare_and_swap (&sll, uc, sc);\n+  ui = __sync_bool_compare_and_swap (&ull, uc, sc);\n+}\n+\n+void test_lock (void)\n+{\n+  sc = __sync_lock_test_and_set (&sc, 1);\n+  uc = __sync_lock_test_and_set (&uc, 1);\n+  ss = __sync_lock_test_and_set (&ss, 1);\n+  us = __sync_lock_test_and_set (&us, 1);\n+  si = __sync_lock_test_and_set (&si, 1);\n+  ui = __sync_lock_test_and_set (&ui, 1);\n+  sl = __sync_lock_test_and_set (&sl, 1);\n+  ul = __sync_lock_test_and_set (&ul, 1);\n+  sll = __sync_lock_test_and_set (&sll, 1);\n+  ull = __sync_lock_test_and_set (&ull, 1);\n+\n+  __sync_synchronize ();\n+\n+  __sync_lock_release (&sc);\n+  __sync_lock_release (&uc);\n+  __sync_lock_release (&ss);\n+  __sync_lock_release (&us);\n+  __sync_lock_release (&si);\n+  __sync_lock_release (&ui);\n+  __sync_lock_release (&sl);\n+  __sync_lock_release (&ul);\n+  __sync_lock_release (&sll);\n+  __sync_lock_release (&ull);\n+}"}, {"sha": "f8cabe47a9904b51a7fdebc646ddc70268bfbf63", "filename": "gcc/testsuite/gcc.dg/sync-1.c", "status": "added", "additions": 40, "deletions": 0, "changes": 40, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Ftestsuite%2Fgcc.dg%2Fsync-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2/gcc%2Ftestsuite%2Fgcc.dg%2Fsync-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fsync-1.c?ref=48ae6c138ca30c4c5e876a0be47c9a0b5c8bf5c2", "patch": "@@ -0,0 +1,40 @@\n+/* Validate that the __sync builtins are overloaded properly.  */\n+/* { dg-do compile } */\n+/* { dg-options \"-Werror\" } */\n+\n+#define TEST1(TYPE, BUILTIN)\t\t\\\n+void t_##TYPE##BUILTIN(TYPE *p)\t\t\\\n+{\t\t\t\t\t\\\n+  __typeof(BUILTIN(p, 1)) *pp;\t\t\\\n+  pp = p;\t\t\t\t\\\n+}\n+\n+#define TEST2(BUILTIN)\t\t\\\n+  TEST1(int, BUILTIN)\t\t\\\n+  TEST1(long, BUILTIN)\n+\n+TEST2(__sync_fetch_and_add)\n+TEST2(__sync_fetch_and_sub)\n+TEST2(__sync_fetch_and_or)\n+TEST2(__sync_fetch_and_and)\n+TEST2(__sync_fetch_and_xor)\n+TEST2(__sync_fetch_and_nand)\n+\n+TEST2(__sync_add_and_fetch)\n+TEST2(__sync_sub_and_fetch)\n+TEST2(__sync_or_and_fetch)\n+TEST2(__sync_and_and_fetch)\n+TEST2(__sync_xor_and_fetch)\n+TEST2(__sync_nand_and_fetch)\n+\n+TEST2(__sync_lock_test_and_set)\n+\n+#define TEST3(TYPE)\t\t\t\t\t\\\n+void t_##TYPE##__sync_val_compare_and_swap(TYPE *p)\t\\\n+{\t\t\t\t\t\t\t\\\n+  __typeof(__sync_val_compare_and_swap(p, 1, 2)) *pp;\t\\\n+  pp = p;\t\t\t\t\t\t\\\n+}\n+\n+TEST3(int)\n+TEST3(long)"}]}