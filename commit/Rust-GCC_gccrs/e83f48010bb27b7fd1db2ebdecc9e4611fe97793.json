{"sha": "e83f48010bb27b7fd1db2ebdecc9e4611fe97793", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTgzZjQ4MDEwYmIyN2I3ZmQxZGIyZWJkZWNjOWU0NjExZmU5Nzc5Mw==", "commit": {"author": {"name": "Steven Bosscher", "email": "stevenb@suse.de", "date": "2004-05-14T15:35:11Z"}, "committer": {"name": "Steven Bosscher", "email": "steven@gcc.gnu.org", "date": "2004-05-14T15:35:11Z"}, "message": "passes.c (rest_of_handle_null_pointer): Remove.\n\n\t* passes.c (rest_of_handle_null_pointer): Remove.\n\t(rest_of_handle_cse): Don't call rest_of_handle_null_pointer.\n\t(rest_of_compilation): Likewise.\n\t* rtl.h (delete_null_pointer_checks): Remove prototype.\n\t* gcse.c (rd_kill, rd_gen, reaching_defs, rd_out, ae_in, ae_out):\n\tRemove declarations.\n\t(get_bitmap_width, alloc_rd_mem, free_rd_mem, handle_rd_kill_set,\n\tcompute_kill_rd, compute_rd, alloc_avail_expr_mem,\n\tfree_avail_expr_mem, compute_ae_gen, expr_killed_p, compute_ae_kill,\n\texpr_reaches_here_p, computing_insn, def_reaches_here_p,\n\tcan_disregard_other_sets, handle_avail_expr, classic_gcse,\n\tone_classic_gcse_pass, invalidate_nonnull_info,\n\tdelete_null_pointer_checks_1, delete_null_pointer_checks,\n\texpr_reached_here_p_work): Remove.\n\t(gcse_main): Do not perform classic GCSE when optimizing for size.\n\t(alloc_pre_mem, free_pre_mem): Don't touch ae_in and ae_out, they\n\tare never used.\n\nFrom-SVN: r81849", "tree": {"sha": "c3536b32c0e0edb3d6b8105ee1e39af3cbde45ea", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/c3536b32c0e0edb3d6b8105ee1e39af3cbde45ea"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e83f48010bb27b7fd1db2ebdecc9e4611fe97793", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e83f48010bb27b7fd1db2ebdecc9e4611fe97793", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e83f48010bb27b7fd1db2ebdecc9e4611fe97793", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e83f48010bb27b7fd1db2ebdecc9e4611fe97793/comments", "author": null, "committer": null, "parents": [{"sha": "4f9c6b6e187417a15ac89f7e76019f27fd637076", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4f9c6b6e187417a15ac89f7e76019f27fd637076", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4f9c6b6e187417a15ac89f7e76019f27fd637076"}], "stats": {"total": 1483, "additions": 169, "deletions": 1314}, "files": [{"sha": "67de34125e3584e606a7ee00c47961f369185869", "filename": "gcc/ChangeLog", "status": "modified", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e83f48010bb27b7fd1db2ebdecc9e4611fe97793/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e83f48010bb27b7fd1db2ebdecc9e4611fe97793/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=e83f48010bb27b7fd1db2ebdecc9e4611fe97793", "patch": "@@ -1,3 +1,23 @@\n+2004-05-14  Steven Bosscher  <stevenb@suse.de>\n+\n+\t* passes.c (rest_of_handle_null_pointer): Remove.\n+\t(rest_of_handle_cse): Don't call rest_of_handle_null_pointer.\n+\t(rest_of_compilation): Likewise.\n+\t* rtl.h (delete_null_pointer_checks): Remove prototype.\n+\t* gcse.c (rd_kill, rd_gen, reaching_defs, rd_out, ae_in, ae_out):\n+\tRemove declarations.\n+\t(get_bitmap_width, alloc_rd_mem, free_rd_mem, handle_rd_kill_set,\n+\tcompute_kill_rd, compute_rd, alloc_avail_expr_mem,\n+\tfree_avail_expr_mem, compute_ae_gen, expr_killed_p, compute_ae_kill,\n+\texpr_reaches_here_p, computing_insn, def_reaches_here_p,\n+\tcan_disregard_other_sets, handle_avail_expr, classic_gcse,\n+\tone_classic_gcse_pass, invalidate_nonnull_info,\n+\tdelete_null_pointer_checks_1, delete_null_pointer_checks,\n+\texpr_reached_here_p_work): Remove.\n+\t(gcse_main): Do not perform classic GCSE when optimizing for size.\n+\t(alloc_pre_mem, free_pre_mem): Don't touch ae_in and ae_out, they\n+\tare never used.\n+\n 2004-05-14  Andrew Pinski  <pinskia@physics.uc.edu>\n \n \tPR optimization/14466"}, {"sha": "b6d0a6b4d4a3d018303860f51153df1c0a791a3d", "filename": "gcc/gcse.c", "status": "modified", "additions": 149, "deletions": 1282, "changes": 1431, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e83f48010bb27b7fd1db2ebdecc9e4611fe97793/gcc%2Fgcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e83f48010bb27b7fd1db2ebdecc9e4611fe97793/gcc%2Fgcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgcse.c?ref=e83f48010bb27b7fd1db2ebdecc9e4611fe97793", "patch": "@@ -192,7 +192,8 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA\n \n    3) Perform copy/constant propagation.\n \n-   4) Perform global cse.\n+   4) Perform global cse using lazy code motion if not optimizing\n+      for size, or code hoisting if we are.\n \n    5) Perform another pass of copy/constant propagation.\n \n@@ -485,7 +486,7 @@ static struct ls_expr * pre_ldst_mems = NULL;\n static regset reg_set_bitmap;\n \n /* For each block, a bitmap of registers set in the block.\n-   This is used by expr_killed_p and compute_transp.\n+   This is used by compute_transp.\n    It is computed during hash table computation and not by compute_sets\n    as it includes registers added since the last pass (or between cprop and\n    gcse) and it's currently not easy to realloc sbitmap vectors.  */\n@@ -515,25 +516,8 @@ static int const_prop_count;\n /* Number of copys propagated.  */\n static int copy_prop_count;\n \f\n-/* These variables are used by classic GCSE.\n-   Normally they'd be defined a bit later, but `rd_gen' needs to\n-   be declared sooner.  */\n-\n-/* Each block has a bitmap of each type.\n-   The length of each blocks bitmap is:\n-\n-       max_cuid  - for reaching definitions\n-       n_exprs - for available expressions\n-\n-   Thus we view the bitmaps as 2 dimensional arrays.  i.e.\n-   rd_kill[block_num][cuid_num]\n-   ae_kill[block_num][expr_num]\t\t\t */\n-\n-/* For reaching defs */\n-static sbitmap *rd_kill, *rd_gen, *reaching_defs, *rd_out;\n-\n-/* for available exprs */\n-static sbitmap *ae_kill, *ae_gen, *ae_in, *ae_out;\n+/* For available exprs */\n+static sbitmap *ae_kill, *ae_gen;\n \n /* Objects of this type are passed around by the null-pointer check\n    removal routines.  */\n@@ -558,7 +542,6 @@ static void alloc_gcse_mem (rtx);\n static void free_gcse_mem (void);\n static void alloc_reg_set_mem (int);\n static void free_reg_set_mem (void);\n-static int get_bitmap_width (int, int, int);\n static void record_one_set (int, rtx);\n static void replace_one_set (int, rtx, rtx);\n static void record_set_info (rtx, rtx, void *);\n@@ -640,31 +623,8 @@ static void compute_code_hoist_data (void);\n static int hoist_expr_reaches_here_p (basic_block, int, basic_block, char *);\n static void hoist_code (void);\n static int one_code_hoisting_pass (void);\n-static void alloc_rd_mem (int, int);\n-static void free_rd_mem (void);\n-static void handle_rd_kill_set (rtx, int, basic_block);\n-static void compute_kill_rd (void);\n-static void compute_rd (void);\n-static void alloc_avail_expr_mem (int, int);\n-static void free_avail_expr_mem (void);\n-static void compute_ae_gen (struct hash_table *);\n-static int expr_killed_p (rtx, basic_block);\n-static void compute_ae_kill (sbitmap *, sbitmap *, struct hash_table *);\n-static int expr_reaches_here_p (struct occr *, struct expr *, basic_block,\n-\t\t\t\tint);\n-static rtx computing_insn (struct expr *, rtx);\n-static int def_reaches_here_p (rtx, rtx);\n-static int can_disregard_other_sets (struct reg_set **, rtx, int);\n-static int handle_avail_expr (rtx, struct expr *);\n-static int classic_gcse (void);\n-static int one_classic_gcse_pass (int);\n-static void invalidate_nonnull_info (rtx, rtx, void *);\n-static int delete_null_pointer_checks_1 (unsigned int *, sbitmap *, sbitmap *,\n-\t\t\t\t\t struct null_pointer_info *);\n static rtx process_insert_insn (struct expr *);\n static int pre_edge_insert (struct edge_list *, struct expr **);\n-static int expr_reaches_here_p_work (struct occr *, struct expr *,\n-\t\t\t\t     basic_block, int, char *);\n static int pre_expr_reaches_here_p_work (basic_block, struct expr *,\n \t\t\t\t\t basic_block, char *);\n static struct ls_expr * ldst_entry (rtx);\n@@ -790,7 +750,7 @@ gcse_main (rtx f, FILE *file)\n       changed = one_cprop_pass (pass + 1, 0, 0);\n \n       if (optimize_size)\n-\tchanged |= one_classic_gcse_pass (pass + 1);\n+\t/* Do nothing.  */ ;\n       else\n \t{\n \t  changed |= one_pre_gcse_pass (pass + 1);\n@@ -821,8 +781,7 @@ gcse_main (rtx f, FILE *file)\n       /* It does not make sense to run code hoisting unless we are optimizing\n \t for code size -- it rarely makes programs faster, and can make\n \t them bigger if we did partial redundancy elimination (when optimizing\n-\t for space, we use a classic gcse algorithm instead of partial\n-\t redundancy algorithms).  */\n+\t for space, we don't run the partial redundancy algorithms).  */\n       if (optimize_size)\n \t{\n \t  max_gcse_regno = max_reg_num ();\n@@ -1025,46 +984,6 @@ free_gcse_mem (void)\n   BITMAP_XFREE (modify_mem_list_set);\n   BITMAP_XFREE (canon_modify_mem_list_set);\n }\n-\n-/* Many of the global optimization algorithms work by solving dataflow\n-   equations for various expressions.  Initially, some local value is\n-   computed for each expression in each block.  Then, the values across the\n-   various blocks are combined (by following flow graph edges) to arrive at\n-   global values.  Conceptually, each set of equations is independent.  We\n-   may therefore solve all the equations in parallel, solve them one at a\n-   time, or pick any intermediate approach.\n-\n-   When you're going to need N two-dimensional bitmaps, each X (say, the\n-   number of blocks) by Y (say, the number of expressions), call this\n-   function.  It's not important what X and Y represent; only that Y\n-   correspond to the things that can be done in parallel.  This function will\n-   return an appropriate chunking factor C; you should solve C sets of\n-   equations in parallel.  By going through this function, we can easily\n-   trade space against time; by solving fewer equations in parallel we use\n-   less space.  */\n-\n-static int\n-get_bitmap_width (int n, int x, int y)\n-{\n-  /* It's not really worth figuring out *exactly* how much memory will\n-     be used by a particular choice.  The important thing is to get\n-     something approximately right.  */\n-  size_t max_bitmap_memory = 10 * 1024 * 1024;\n-\n-  /* The number of bytes we'd use for a single column of minimum\n-     width.  */\n-  size_t column_size = n * x * sizeof (SBITMAP_ELT_TYPE);\n-\n-  /* Often, it's reasonable just to solve all the equations in\n-     parallel.  */\n-  if (column_size * SBITMAP_SET_SIZE (y) <= max_bitmap_memory)\n-    return y;\n-\n-  /* Otherwise, pick the largest width we can, without going over the\n-     limit.  */\n-  return SBITMAP_ELT_BITS * ((max_bitmap_memory + column_size - 1)\n-\t\t\t     / column_size);\n-}\n \f\n /* Compute the local properties of each recorded expression.\n \n@@ -2878,204 +2797,136 @@ mark_oprs_set (rtx insn)\n }\n \n \f\n-/* Classic GCSE reaching definition support.  */\n-\n-/* Allocate reaching def variables.  */\n-\n-static void\n-alloc_rd_mem (int n_blocks, int n_insns)\n-{\n-  rd_kill = sbitmap_vector_alloc (n_blocks, n_insns);\n-  sbitmap_vector_zero (rd_kill, n_blocks);\n-\n-  rd_gen = sbitmap_vector_alloc (n_blocks, n_insns);\n-  sbitmap_vector_zero (rd_gen, n_blocks);\n+/* Compute copy/constant propagation working variables.  */\n \n-  reaching_defs = sbitmap_vector_alloc (n_blocks, n_insns);\n-  sbitmap_vector_zero (reaching_defs, n_blocks);\n+/* Local properties of assignments.  */\n+static sbitmap *cprop_pavloc;\n+static sbitmap *cprop_absaltered;\n \n-  rd_out = sbitmap_vector_alloc (n_blocks, n_insns);\n-  sbitmap_vector_zero (rd_out, n_blocks);\n-}\n+/* Global properties of assignments (computed from the local properties).  */\n+static sbitmap *cprop_avin;\n+static sbitmap *cprop_avout;\n \n-/* Free reaching def variables.  */\n+/* Allocate vars used for copy/const propagation.  N_BLOCKS is the number of\n+   basic blocks.  N_SETS is the number of sets.  */\n \n static void\n-free_rd_mem (void)\n+alloc_cprop_mem (int n_blocks, int n_sets)\n {\n-  sbitmap_vector_free (rd_kill);\n-  sbitmap_vector_free (rd_gen);\n-  sbitmap_vector_free (reaching_defs);\n-  sbitmap_vector_free (rd_out);\n+  cprop_pavloc = sbitmap_vector_alloc (n_blocks, n_sets);\n+  cprop_absaltered = sbitmap_vector_alloc (n_blocks, n_sets);\n+\n+  cprop_avin = sbitmap_vector_alloc (n_blocks, n_sets);\n+  cprop_avout = sbitmap_vector_alloc (n_blocks, n_sets);\n }\n \n-/* Add INSN to the kills of BB.  REGNO, set in BB, is killed by INSN.  */\n+/* Free vars used by copy/const propagation.  */\n \n static void\n-handle_rd_kill_set (rtx insn, int regno, basic_block bb)\n+free_cprop_mem (void)\n {\n-  struct reg_set *this_reg;\n-\n-  for (this_reg = reg_set_table[regno]; this_reg; this_reg = this_reg ->next)\n-    if (BLOCK_NUM (this_reg->insn) != BLOCK_NUM (insn))\n-      SET_BIT (rd_kill[bb->index], INSN_CUID (this_reg->insn));\n+  sbitmap_vector_free (cprop_pavloc);\n+  sbitmap_vector_free (cprop_absaltered);\n+  sbitmap_vector_free (cprop_avin);\n+  sbitmap_vector_free (cprop_avout);\n }\n \n-/* Compute the set of kill's for reaching definitions.  */\n+/* For each block, compute whether X is transparent.  X is either an\n+   expression or an assignment [though we don't care which, for this context\n+   an assignment is treated as an expression].  For each block where an\n+   element of X is modified, set (SET_P == 1) or reset (SET_P == 0) the INDX\n+   bit in BMAP.  */\n \n static void\n-compute_kill_rd (void)\n+compute_transp (rtx x, int indx, sbitmap *bmap, int set_p)\n {\n-  int cuid;\n-  unsigned int regno;\n-  int i;\n+  int i, j;\n   basic_block bb;\n+  enum rtx_code code;\n+  reg_set *r;\n+  const char *fmt;\n \n-  /* For each block\n-       For each set bit in `gen' of the block (i.e each insn which\n-\t   generates a definition in the block)\n-\t Call the reg set by the insn corresponding to that bit regx\n-\t Look at the linked list starting at reg_set_table[regx]\n-\t For each setting of regx in the linked list, which is not in\n-\t     this block\n-\t   Set the bit in `kill' corresponding to that insn.  */\n-  FOR_EACH_BB (bb)\n-    for (cuid = 0; cuid < max_cuid; cuid++)\n-      if (TEST_BIT (rd_gen[bb->index], cuid))\n-\t{\n-\t  rtx insn = CUID_INSN (cuid);\n-\t  rtx pat = PATTERN (insn);\n+  /* repeat is used to turn tail-recursion into iteration since GCC\n+     can't do it when there's no return value.  */\n+ repeat:\n \n-\t  if (GET_CODE (insn) == CALL_INSN)\n+  if (x == 0)\n+    return;\n+\n+  code = GET_CODE (x);\n+  switch (code)\n+    {\n+    case REG:\n+      if (set_p)\n+\t{\n+\t  if (REGNO (x) < FIRST_PSEUDO_REGISTER)\n \t    {\n-\t      for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)\n-\t\tif (TEST_HARD_REG_BIT (regs_invalidated_by_call, regno))\n-\t\t  handle_rd_kill_set (insn, regno, bb);\n+\t      FOR_EACH_BB (bb)\n+\t\tif (TEST_BIT (reg_set_in_block[bb->index], REGNO (x)))\n+\t\t  SET_BIT (bmap[bb->index], indx);\n \t    }\n-\n-\t  if (GET_CODE (pat) == PARALLEL)\n+\t  else\n \t    {\n-\t      for (i = XVECLEN (pat, 0) - 1; i >= 0; i--)\n-\t\t{\n-\t\t  enum rtx_code code = GET_CODE (XVECEXP (pat, 0, i));\n-\n-\t\t  if ((code == SET || code == CLOBBER)\n-\t\t      && GET_CODE (XEXP (XVECEXP (pat, 0, i), 0)) == REG)\n-\t\t    handle_rd_kill_set (insn,\n-\t\t\t\t\tREGNO (XEXP (XVECEXP (pat, 0, i), 0)),\n-\t\t\t\t\tbb);\n-\t\t}\n+\t      for (r = reg_set_table[REGNO (x)]; r != NULL; r = r->next)\n+\t\tSET_BIT (bmap[BLOCK_NUM (r->insn)], indx);\n \t    }\n-\t  else if (GET_CODE (pat) == SET && GET_CODE (SET_DEST (pat)) == REG)\n-\t    /* Each setting of this register outside of this block\n-\t       must be marked in the set of kills in this block.  */\n-\t    handle_rd_kill_set (insn, REGNO (SET_DEST (pat)), bb);\n \t}\n-}\n-\n-/* Compute the reaching definitions as in\n-   Compilers Principles, Techniques, and Tools. Aho, Sethi, Ullman,\n-   Chapter 10.  It is the same algorithm as used for computing available\n-   expressions but applied to the gens and kills of reaching definitions.  */\n-\n-static void\n-compute_rd (void)\n-{\n-  int changed, passes;\n-  basic_block bb;\n-\n-  FOR_EACH_BB (bb)\n-    sbitmap_copy (rd_out[bb->index] /*dst*/, rd_gen[bb->index] /*src*/);\n-\n-  passes = 0;\n-  changed = 1;\n-  while (changed)\n-    {\n-      changed = 0;\n-      FOR_EACH_BB (bb)\n+      else\n \t{\n-\t  sbitmap_union_of_preds (reaching_defs[bb->index], rd_out, bb->index);\n-\t  changed |= sbitmap_union_of_diff_cg (rd_out[bb->index], rd_gen[bb->index],\n-\t\t\t\t\t       reaching_defs[bb->index], rd_kill[bb->index]);\n+\t  if (REGNO (x) < FIRST_PSEUDO_REGISTER)\n+\t    {\n+\t      FOR_EACH_BB (bb)\n+\t\tif (TEST_BIT (reg_set_in_block[bb->index], REGNO (x)))\n+\t\t  RESET_BIT (bmap[bb->index], indx);\n+\t    }\n+\t  else\n+\t    {\n+\t      for (r = reg_set_table[REGNO (x)]; r != NULL; r = r->next)\n+\t\tRESET_BIT (bmap[BLOCK_NUM (r->insn)], indx);\n+\t    }\n \t}\n-      passes++;\n-    }\n-\n-  if (gcse_file)\n-    fprintf (gcse_file, \"reaching def computation: %d passes\\n\", passes);\n-}\n-\f\n-/* Classic GCSE available expression support.  */\n-\n-/* Allocate memory for available expression computation.  */\n-\n-static void\n-alloc_avail_expr_mem (int n_blocks, int n_exprs)\n-{\n-  ae_kill = sbitmap_vector_alloc (n_blocks, n_exprs);\n-  sbitmap_vector_zero (ae_kill, n_blocks);\n-\n-  ae_gen = sbitmap_vector_alloc (n_blocks, n_exprs);\n-  sbitmap_vector_zero (ae_gen, n_blocks);\n-\n-  ae_in = sbitmap_vector_alloc (n_blocks, n_exprs);\n-  sbitmap_vector_zero (ae_in, n_blocks);\n-\n-  ae_out = sbitmap_vector_alloc (n_blocks, n_exprs);\n-  sbitmap_vector_zero (ae_out, n_blocks);\n-}\n-\n-static void\n-free_avail_expr_mem (void)\n-{\n-  sbitmap_vector_free (ae_kill);\n-  sbitmap_vector_free (ae_gen);\n-  sbitmap_vector_free (ae_in);\n-  sbitmap_vector_free (ae_out);\n-}\n-\n-/* Compute the set of available expressions generated in each basic block.  */\n \n-static void\n-compute_ae_gen (struct hash_table *expr_hash_table)\n-{\n-  unsigned int i;\n-  struct expr *expr;\n-  struct occr *occr;\n+      return;\n \n-  /* For each recorded occurrence of each expression, set ae_gen[bb][expr].\n-     This is all we have to do because an expression is not recorded if it\n-     is not available, and the only expressions we want to work with are the\n-     ones that are recorded.  */\n-  for (i = 0; i < expr_hash_table->size; i++)\n-    for (expr = expr_hash_table->table[i]; expr != 0; expr = expr->next_same_hash)\n-      for (occr = expr->avail_occr; occr != 0; occr = occr->next)\n-\tSET_BIT (ae_gen[BLOCK_NUM (occr->insn)], expr->bitmap_index);\n-}\n+    case MEM:\n+      FOR_EACH_BB (bb)\n+\t{\n+\t  rtx list_entry = canon_modify_mem_list[bb->index];\n \n-/* Return nonzero if expression X is killed in BB.  */\n+\t  while (list_entry)\n+\t    {\n+\t      rtx dest, dest_addr;\n \n-static int\n-expr_killed_p (rtx x, basic_block bb)\n-{\n-  int i, j;\n-  enum rtx_code code;\n-  const char *fmt;\n+\t      if (GET_CODE (XEXP (list_entry, 0)) == CALL_INSN)\n+\t\t{\n+\t\t  if (set_p)\n+\t\t    SET_BIT (bmap[bb->index], indx);\n+\t\t  else\n+\t\t    RESET_BIT (bmap[bb->index], indx);\n+\t\t  break;\n+\t\t}\n+\t      /* LIST_ENTRY must be an INSN of some kind that sets memory.\n+\t\t Examine each hunk of memory that is modified.  */\n \n-  if (x == 0)\n-    return 1;\n+\t      dest = XEXP (list_entry, 0);\n+\t      list_entry = XEXP (list_entry, 1);\n+\t      dest_addr = XEXP (list_entry, 0);\n \n-  code = GET_CODE (x);\n-  switch (code)\n-    {\n-    case REG:\n-      return TEST_BIT (reg_set_in_block[bb->index], REGNO (x));\n+\t      if (canon_true_dependence (dest, GET_MODE (dest), dest_addr,\n+\t\t\t\t\t x, rtx_addr_varies_p))\n+\t\t{\n+\t\t  if (set_p)\n+\t\t    SET_BIT (bmap[bb->index], indx);\n+\t\t  else\n+\t\t    RESET_BIT (bmap[bb->index], indx);\n+\t\t  break;\n+\t\t}\n+\t      list_entry = XEXP (list_entry, 1);\n+\t    }\n+\t}\n \n-    case MEM:\n-      if (load_killed_in_block_p (bb, get_max_uid () + 1, x, 0))\n-\treturn 1;\n-      else\n-\treturn expr_killed_p (XEXP (x, 0), bb);\n+      x = XEXP (x, 0);\n+      goto repeat;\n \n     case PC:\n     case CC0: /*FIXME*/\n@@ -3087,7 +2938,7 @@ expr_killed_p (rtx x, basic_block bb)\n     case LABEL_REF:\n     case ADDR_VEC:\n     case ADDR_DIFF_VEC:\n-      return 0;\n+      return;\n \n     default:\n       break;\n@@ -3101,755 +2952,68 @@ expr_killed_p (rtx x, basic_block bb)\n \t     needed at this level, change it into iteration.\n \t     This function is called enough to be worth it.  */\n \t  if (i == 0)\n-\t    return expr_killed_p (XEXP (x, i), bb);\n-\t  else if (expr_killed_p (XEXP (x, i), bb))\n-\t    return 1;\n+\t    {\n+\t      x = XEXP (x, i);\n+\t      goto repeat;\n+\t    }\n+\n+\t  compute_transp (XEXP (x, i), indx, bmap, set_p);\n \t}\n       else if (fmt[i] == 'E')\n \tfor (j = 0; j < XVECLEN (x, i); j++)\n-\t  if (expr_killed_p (XVECEXP (x, i, j), bb))\n-\t    return 1;\n+\t  compute_transp (XVECEXP (x, i, j), indx, bmap, set_p);\n     }\n-\n-  return 0;\n }\n \n-/* Compute the set of available expressions killed in each basic block.  */\n+/* Top level routine to do the dataflow analysis needed by copy/const\n+   propagation.  */\n \n static void\n-compute_ae_kill (sbitmap *ae_gen, sbitmap *ae_kill,\n-\t\t struct hash_table *expr_hash_table)\n+compute_cprop_data (void)\n {\n-  basic_block bb;\n-  unsigned int i;\n-  struct expr *expr;\n-\n-  FOR_EACH_BB (bb)\n-    for (i = 0; i < expr_hash_table->size; i++)\n-      for (expr = expr_hash_table->table[i]; expr; expr = expr->next_same_hash)\n-\t{\n-\t  /* Skip EXPR if generated in this block.  */\n-\t  if (TEST_BIT (ae_gen[bb->index], expr->bitmap_index))\n-\t    continue;\n-\n-\t  if (expr_killed_p (expr->expr, bb))\n-\t    SET_BIT (ae_kill[bb->index], expr->bitmap_index);\n-\t}\n+  compute_local_properties (cprop_absaltered, cprop_pavloc, NULL, &set_hash_table);\n+  compute_available (cprop_pavloc, cprop_absaltered,\n+\t\t     cprop_avout, cprop_avin);\n }\n \f\n-/* Actually perform the Classic GCSE optimizations.  */\n+/* Copy/constant propagation.  */\n \n-/* Return nonzero if occurrence OCCR of expression EXPR reaches block BB.\n+/* Maximum number of register uses in an insn that we handle.  */\n+#define MAX_USES 8\n \n-   CHECK_SELF_LOOP is nonzero if we should consider a block reaching itself\n-   as a positive reach.  We want to do this when there are two computations\n-   of the expression in the block.\n+/* Table of uses found in an insn.\n+   Allocated statically to avoid alloc/free complexity and overhead.  */\n+static struct reg_use reg_use_table[MAX_USES];\n \n-   VISITED is a pointer to a working buffer for tracking which BB's have\n-   been visited.  It is NULL for the top-level call.\n+/* Index into `reg_use_table' while building it.  */\n+static int reg_use_count;\n \n-   We treat reaching expressions that go through blocks containing the same\n-   reaching expression as \"not reaching\".  E.g. if EXPR is generated in blocks\n-   2 and 3, INSN is in block 4, and 2->3->4, we treat the expression in block\n-   2 as not reaching.  The intent is to improve the probability of finding\n-   only one reaching expression and to reduce register lifetimes by picking\n-   the closest such expression.  */\n+/* Set up a list of register numbers used in INSN.  The found uses are stored\n+   in `reg_use_table'.  `reg_use_count' is initialized to zero before entry,\n+   and contains the number of uses in the table upon exit.\n \n-static int\n-expr_reaches_here_p_work (struct occr *occr, struct expr *expr,\n-\t\t\t  basic_block bb, int check_self_loop, char *visited)\n+   ??? If a register appears multiple times we will record it multiple times.\n+   This doesn't hurt anything but it will slow things down.  */\n+\n+static void\n+find_used_regs (rtx *xptr, void *data ATTRIBUTE_UNUSED)\n {\n-  edge pred;\n+  int i, j;\n+  enum rtx_code code;\n+  const char *fmt;\n+  rtx x = *xptr;\n \n-  for (pred = bb->pred; pred != NULL; pred = pred->pred_next)\n+  /* repeat is used to turn tail-recursion into iteration since GCC\n+     can't do it when there's no return value.  */\n+ repeat:\n+  if (x == 0)\n+    return;\n+\n+  code = GET_CODE (x);\n+  if (REG_P (x))\n     {\n-      basic_block pred_bb = pred->src;\n-\n-      if (visited[pred_bb->index])\n-\t/* This predecessor has already been visited. Nothing to do.  */\n-\t  ;\n-      else if (pred_bb == bb)\n-\t{\n-\t  /* BB loops on itself.  */\n-\t  if (check_self_loop\n-\t      && TEST_BIT (ae_gen[pred_bb->index], expr->bitmap_index)\n-\t      && BLOCK_NUM (occr->insn) == pred_bb->index)\n-\t    return 1;\n-\n-\t  visited[pred_bb->index] = 1;\n-\t}\n-\n-      /* Ignore this predecessor if it kills the expression.  */\n-      else if (TEST_BIT (ae_kill[pred_bb->index], expr->bitmap_index))\n-\tvisited[pred_bb->index] = 1;\n-\n-      /* Does this predecessor generate this expression?  */\n-      else if (TEST_BIT (ae_gen[pred_bb->index], expr->bitmap_index))\n-\t{\n-\t  /* Is this the occurrence we're looking for?\n-\t     Note that there's only one generating occurrence per block\n-\t     so we just need to check the block number.  */\n-\t  if (BLOCK_NUM (occr->insn) == pred_bb->index)\n-\t    return 1;\n-\n-\t  visited[pred_bb->index] = 1;\n-\t}\n-\n-      /* Neither gen nor kill.  */\n-      else\n-\t{\n-\t  visited[pred_bb->index] = 1;\n-\t  if (expr_reaches_here_p_work (occr, expr, pred_bb, check_self_loop,\n-\t      visited))\n-\n-\t    return 1;\n-\t}\n-    }\n-\n-  /* All paths have been checked.  */\n-  return 0;\n-}\n-\n-/* This wrapper for expr_reaches_here_p_work() is to ensure that any\n-   memory allocated for that function is returned.  */\n-\n-static int\n-expr_reaches_here_p (struct occr *occr, struct expr *expr, basic_block bb,\n-\t\t     int check_self_loop)\n-{\n-  int rval;\n-  char *visited = xcalloc (last_basic_block, 1);\n-\n-  rval = expr_reaches_here_p_work (occr, expr, bb, check_self_loop, visited);\n-\n-  free (visited);\n-  return rval;\n-}\n-\n-/* Return the instruction that computes EXPR that reaches INSN's basic block.\n-   If there is more than one such instruction, return NULL.\n-\n-   Called only by handle_avail_expr.  */\n-\n-static rtx\n-computing_insn (struct expr *expr, rtx insn)\n-{\n-  basic_block bb = BLOCK_FOR_INSN (insn);\n-\n-  if (expr->avail_occr->next == NULL)\n-    {\n-      if (BLOCK_FOR_INSN (expr->avail_occr->insn) == bb)\n-\t/* The available expression is actually itself\n-\t   (i.e. a loop in the flow graph) so do nothing.  */\n-\treturn NULL;\n-\n-      /* (FIXME) Case that we found a pattern that was created by\n-\t a substitution that took place.  */\n-      return expr->avail_occr->insn;\n-    }\n-  else\n-    {\n-      /* Pattern is computed more than once.\n-\t Search backwards from this insn to see how many of these\n-\t computations actually reach this insn.  */\n-      struct occr *occr;\n-      rtx insn_computes_expr = NULL;\n-      int can_reach = 0;\n-\n-      for (occr = expr->avail_occr; occr != NULL; occr = occr->next)\n-\t{\n-\t  if (BLOCK_FOR_INSN (occr->insn) == bb)\n-\t    {\n-\t      /* The expression is generated in this block.\n-\t\t The only time we care about this is when the expression\n-\t\t is generated later in the block [and thus there's a loop].\n-\t\t We let the normal cse pass handle the other cases.  */\n-\t      if (INSN_CUID (insn) < INSN_CUID (occr->insn)\n-\t\t  && expr_reaches_here_p (occr, expr, bb, 1))\n-\t\t{\n-\t\t  can_reach++;\n-\t\t  if (can_reach > 1)\n-\t\t    return NULL;\n-\n-\t\t  insn_computes_expr = occr->insn;\n-\t\t}\n-\t    }\n-\t  else if (expr_reaches_here_p (occr, expr, bb, 0))\n-\t    {\n-\t      can_reach++;\n-\t      if (can_reach > 1)\n-\t\treturn NULL;\n-\n-\t      insn_computes_expr = occr->insn;\n-\t    }\n-\t}\n-\n-      if (insn_computes_expr == NULL)\n-\tabort ();\n-\n-      return insn_computes_expr;\n-    }\n-}\n-\n-/* Return nonzero if the definition in DEF_INSN can reach INSN.\n-   Only called by can_disregard_other_sets.  */\n-\n-static int\n-def_reaches_here_p (rtx insn, rtx def_insn)\n-{\n-  rtx reg;\n-\n-  if (TEST_BIT (reaching_defs[BLOCK_NUM (insn)], INSN_CUID (def_insn)))\n-    return 1;\n-\n-  if (BLOCK_NUM (insn) == BLOCK_NUM (def_insn))\n-    {\n-      if (INSN_CUID (def_insn) < INSN_CUID (insn))\n-\t{\n-\t  if (GET_CODE (PATTERN (def_insn)) == PARALLEL)\n-\t    return 1;\n-\t  else if (GET_CODE (PATTERN (def_insn)) == CLOBBER)\n-\t    reg = XEXP (PATTERN (def_insn), 0);\n-\t  else if (GET_CODE (PATTERN (def_insn)) == SET)\n-\t    reg = SET_DEST (PATTERN (def_insn));\n-\t  else\n-\t    abort ();\n-\n-\t  return ! reg_set_between_p (reg, NEXT_INSN (def_insn), insn);\n-\t}\n-      else\n-\treturn 0;\n-    }\n-\n-  return 0;\n-}\n-\n-/* Return nonzero if *ADDR_THIS_REG can only have one value at INSN.  The\n-   value returned is the number of definitions that reach INSN.  Returning a\n-   value of zero means that [maybe] more than one definition reaches INSN and\n-   the caller can't perform whatever optimization it is trying.  i.e. it is\n-   always safe to return zero.  */\n-\n-static int\n-can_disregard_other_sets (struct reg_set **addr_this_reg, rtx insn, int for_combine)\n-{\n-  int number_of_reaching_defs = 0;\n-  struct reg_set *this_reg;\n-\n-  for (this_reg = *addr_this_reg; this_reg != 0; this_reg = this_reg->next)\n-    if (def_reaches_here_p (insn, this_reg->insn))\n-      {\n-\tnumber_of_reaching_defs++;\n-\t/* Ignore parallels for now.  */\n-\tif (GET_CODE (PATTERN (this_reg->insn)) == PARALLEL)\n-\t  return 0;\n-\n-\tif (!for_combine\n-\t    && (GET_CODE (PATTERN (this_reg->insn)) == CLOBBER\n-\t\t|| ! rtx_equal_p (SET_SRC (PATTERN (this_reg->insn)),\n-\t\t\t\t  SET_SRC (PATTERN (insn)))))\n-\t  /* A setting of the reg to a different value reaches INSN.  */\n-\t  return 0;\n-\n-\tif (number_of_reaching_defs > 1)\n-\t  {\n-\t    /* If in this setting the value the register is being set to is\n-\t       equal to the previous value the register was set to and this\n-\t       setting reaches the insn we are trying to do the substitution\n-\t       on then we are ok.  */\n-\t    if (GET_CODE (PATTERN (this_reg->insn)) == CLOBBER)\n-\t      return 0;\n-\t    else if (! rtx_equal_p (SET_SRC (PATTERN (this_reg->insn)),\n-\t\t\t\t    SET_SRC (PATTERN (insn))))\n-\t      return 0;\n-\t  }\n-\n-\t*addr_this_reg = this_reg;\n-      }\n-\n-  return number_of_reaching_defs;\n-}\n-\n-/* Expression computed by insn is available and the substitution is legal,\n-   so try to perform the substitution.\n-\n-   The result is nonzero if any changes were made.  */\n-\n-static int\n-handle_avail_expr (rtx insn, struct expr *expr)\n-{\n-  rtx pat, insn_computes_expr, expr_set;\n-  rtx to;\n-  struct reg_set *this_reg;\n-  int found_setting, use_src;\n-  int changed = 0;\n-\n-  /* We only handle the case where one computation of the expression\n-     reaches this instruction.  */\n-  insn_computes_expr = computing_insn (expr, insn);\n-  if (insn_computes_expr == NULL)\n-    return 0;\n-  expr_set = single_set (insn_computes_expr);\n-  /* The set might be in a parallel with multiple sets; we could\n-     probably handle that, but there's currently no easy way to find\n-     the relevant sub-expression.  */\n-  if (!expr_set)\n-    return 0;\n-\n-  found_setting = 0;\n-  use_src = 0;\n-\n-  /* At this point we know only one computation of EXPR outside of this\n-     block reaches this insn.  Now try to find a register that the\n-     expression is computed into.  */\n-  if (GET_CODE (SET_SRC (expr_set)) == REG)\n-    {\n-      /* This is the case when the available expression that reaches\n-\t here has already been handled as an available expression.  */\n-      unsigned int regnum_for_replacing\n-\t= REGNO (SET_SRC (expr_set));\n-\n-      /* If the register was created by GCSE we can't use `reg_set_table',\n-\t however we know it's set only once.  */\n-      if (regnum_for_replacing >= max_gcse_regno\n-\t  /* If the register the expression is computed into is set only once,\n-\t     or only one set reaches this insn, we can use it.  */\n-\t  || (((this_reg = reg_set_table[regnum_for_replacing]),\n-\t       this_reg->next == NULL)\n-\t      || can_disregard_other_sets (&this_reg, insn, 0)))\n-\t{\n-\t  use_src = 1;\n-\t  found_setting = 1;\n-\t}\n-    }\n-\n-  if (!found_setting)\n-    {\n-      unsigned int regnum_for_replacing\n-\t= REGNO (SET_DEST (expr_set));\n-\n-      /* This shouldn't happen.  */\n-      if (regnum_for_replacing >= max_gcse_regno)\n-\tabort ();\n-\n-      this_reg = reg_set_table[regnum_for_replacing];\n-\n-      /* If the register the expression is computed into is set only once,\n-\t or only one set reaches this insn, use it.  */\n-      if (this_reg->next == NULL\n-\t  || can_disregard_other_sets (&this_reg, insn, 0))\n-\tfound_setting = 1;\n-    }\n-\n-  if (found_setting)\n-    {\n-      pat = PATTERN (insn);\n-      if (use_src)\n-\tto = SET_SRC (expr_set);\n-      else\n-\tto = SET_DEST (expr_set);\n-      changed = validate_change (insn, &SET_SRC (pat), to, 0);\n-\n-      /* We should be able to ignore the return code from validate_change but\n-\t to play it safe we check.  */\n-      if (changed)\n-\t{\n-\t  gcse_subst_count++;\n-\t  if (gcse_file != NULL)\n-\t    {\n-\t      fprintf (gcse_file, \"GCSE: Replacing the source in insn %d with\",\n-\t\t       INSN_UID (insn));\n-\t      fprintf (gcse_file, \" reg %d %s insn %d\\n\",\n-\t\t       REGNO (to), use_src ? \"from\" : \"set in\",\n-\t\t       INSN_UID (insn_computes_expr));\n-\t    }\n-\t}\n-    }\n-\n-  /* The register that the expr is computed into is set more than once.  */\n-  else if (1 /*expensive_op(this_pattrn->op) && do_expensive_gcse)*/)\n-    {\n-      /* Insert an insn after insnx that copies the reg set in insnx\n-\t into a new pseudo register call this new register REGN.\n-\t From insnb until end of basic block or until REGB is set\n-\t replace all uses of REGB with REGN.  */\n-      rtx new_insn;\n-\n-      to = gen_reg_rtx (GET_MODE (SET_DEST (expr_set)));\n-\n-      /* Generate the new insn.  */\n-      /* ??? If the change fails, we return 0, even though we created\n-\t an insn.  I think this is ok.  */\n-      new_insn\n-\t= emit_insn_after (gen_rtx_SET (VOIDmode, to,\n-\t\t\t\t\tSET_DEST (expr_set)),\n-\t\t\t   insn_computes_expr);\n-\n-      /* Keep register set table up to date.  */\n-      record_one_set (REGNO (to), new_insn);\n-\n-      gcse_create_count++;\n-      if (gcse_file != NULL)\n-\t{\n-\t  fprintf (gcse_file, \"GCSE: Creating insn %d to copy value of reg %d\",\n-\t\t   INSN_UID (NEXT_INSN (insn_computes_expr)),\n-\t\t   REGNO (SET_SRC (PATTERN (NEXT_INSN (insn_computes_expr)))));\n-\t  fprintf (gcse_file, \", computed in insn %d,\\n\",\n-\t\t   INSN_UID (insn_computes_expr));\n-\t  fprintf (gcse_file, \"      into newly allocated reg %d\\n\",\n-\t\t   REGNO (to));\n-\t}\n-\n-      pat = PATTERN (insn);\n-\n-      /* Do register replacement for INSN.  */\n-      changed = validate_change (insn, &SET_SRC (pat),\n-\t\t\t\t SET_DEST (PATTERN\n-\t\t\t\t\t   (NEXT_INSN (insn_computes_expr))),\n-\t\t\t\t 0);\n-\n-      /* We should be able to ignore the return code from validate_change but\n-\t to play it safe we check.  */\n-      if (changed)\n-\t{\n-\t  gcse_subst_count++;\n-\t  if (gcse_file != NULL)\n-\t    {\n-\t      fprintf (gcse_file,\n-\t\t       \"GCSE: Replacing the source in insn %d with reg %d \",\n-\t\t       INSN_UID (insn),\n-\t\t       REGNO (SET_DEST (PATTERN (NEXT_INSN\n-\t\t\t\t\t\t (insn_computes_expr)))));\n-\t      fprintf (gcse_file, \"set in insn %d\\n\",\n-\t\t       INSN_UID (insn_computes_expr));\n-\t    }\n-\t}\n-    }\n-\n-  return changed;\n-}\n-\n-/* Perform classic GCSE.  This is called by one_classic_gcse_pass after all\n-   the dataflow analysis has been done.\n-\n-   The result is nonzero if a change was made.  */\n-\n-static int\n-classic_gcse (void)\n-{\n-  int changed;\n-  rtx insn;\n-  basic_block bb;\n-\n-  /* Note we start at block 1.  */\n-\n-  if (ENTRY_BLOCK_PTR->next_bb == EXIT_BLOCK_PTR)\n-    return 0;\n-\n-  changed = 0;\n-  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR->next_bb->next_bb, EXIT_BLOCK_PTR, next_bb)\n-    {\n-      /* Reset tables used to keep track of what's still valid [since the\n-\t start of the block].  */\n-      reset_opr_set_tables ();\n-\n-      for (insn = BB_HEAD (bb);\n-\t   insn != NULL && insn != NEXT_INSN (BB_END (bb));\n-\t   insn = NEXT_INSN (insn))\n-\t{\n-\t  /* Is insn of form (set (pseudo-reg) ...)?  */\n-\t  if (GET_CODE (insn) == INSN\n-\t      && GET_CODE (PATTERN (insn)) == SET\n-\t      && GET_CODE (SET_DEST (PATTERN (insn))) == REG\n-\t      && REGNO (SET_DEST (PATTERN (insn))) >= FIRST_PSEUDO_REGISTER)\n-\t    {\n-\t      rtx pat = PATTERN (insn);\n-\t      rtx src = SET_SRC (pat);\n-\t      struct expr *expr;\n-\n-\t      if (want_to_gcse_p (src)\n-\t\t  /* Is the expression recorded?  */\n-\t\t  && ((expr = lookup_expr (src, &expr_hash_table)) != NULL)\n-\t\t  /* Is the expression available [at the start of the\n-\t\t     block]?  */\n-\t\t  && TEST_BIT (ae_in[bb->index], expr->bitmap_index)\n-\t\t  /* Are the operands unchanged since the start of the\n-\t\t     block?  */\n-\t\t  && oprs_not_set_p (src, insn))\n-\t\tchanged |= handle_avail_expr (insn, expr);\n-\t    }\n-\n-\t  /* Keep track of everything modified by this insn.  */\n-\t  /* ??? Need to be careful w.r.t. mods done to INSN.  */\n-\t  if (INSN_P (insn))\n-\t    mark_oprs_set (insn);\n-\t}\n-    }\n-\n-  return changed;\n-}\n-\n-/* Top level routine to perform one classic GCSE pass.\n-\n-   Return nonzero if a change was made.  */\n-\n-static int\n-one_classic_gcse_pass (int pass)\n-{\n-  int changed = 0;\n-\n-  gcse_subst_count = 0;\n-  gcse_create_count = 0;\n-\n-  alloc_hash_table (max_cuid, &expr_hash_table, 0);\n-  alloc_rd_mem (last_basic_block, max_cuid);\n-  compute_hash_table (&expr_hash_table);\n-  if (gcse_file)\n-    dump_hash_table (gcse_file, \"Expression\", &expr_hash_table);\n-\n-  if (expr_hash_table.n_elems > 0)\n-    {\n-      compute_kill_rd ();\n-      compute_rd ();\n-      alloc_avail_expr_mem (last_basic_block, expr_hash_table.n_elems);\n-      compute_ae_gen (&expr_hash_table);\n-      compute_ae_kill (ae_gen, ae_kill, &expr_hash_table);\n-      compute_available (ae_gen, ae_kill, ae_out, ae_in);\n-      changed = classic_gcse ();\n-      free_avail_expr_mem ();\n-    }\n-\n-  free_rd_mem ();\n-  free_hash_table (&expr_hash_table);\n-\n-  if (gcse_file)\n-    {\n-      fprintf (gcse_file, \"\\n\");\n-      fprintf (gcse_file, \"GCSE of %s, pass %d: %d bytes needed, %d substs,\",\n-\t       current_function_name (), pass, bytes_used, gcse_subst_count);\n-      fprintf (gcse_file, \"%d insns created\\n\", gcse_create_count);\n-    }\n-\n-  return changed;\n-}\n-\f\n-/* Compute copy/constant propagation working variables.  */\n-\n-/* Local properties of assignments.  */\n-static sbitmap *cprop_pavloc;\n-static sbitmap *cprop_absaltered;\n-\n-/* Global properties of assignments (computed from the local properties).  */\n-static sbitmap *cprop_avin;\n-static sbitmap *cprop_avout;\n-\n-/* Allocate vars used for copy/const propagation.  N_BLOCKS is the number of\n-   basic blocks.  N_SETS is the number of sets.  */\n-\n-static void\n-alloc_cprop_mem (int n_blocks, int n_sets)\n-{\n-  cprop_pavloc = sbitmap_vector_alloc (n_blocks, n_sets);\n-  cprop_absaltered = sbitmap_vector_alloc (n_blocks, n_sets);\n-\n-  cprop_avin = sbitmap_vector_alloc (n_blocks, n_sets);\n-  cprop_avout = sbitmap_vector_alloc (n_blocks, n_sets);\n-}\n-\n-/* Free vars used by copy/const propagation.  */\n-\n-static void\n-free_cprop_mem (void)\n-{\n-  sbitmap_vector_free (cprop_pavloc);\n-  sbitmap_vector_free (cprop_absaltered);\n-  sbitmap_vector_free (cprop_avin);\n-  sbitmap_vector_free (cprop_avout);\n-}\n-\n-/* For each block, compute whether X is transparent.  X is either an\n-   expression or an assignment [though we don't care which, for this context\n-   an assignment is treated as an expression].  For each block where an\n-   element of X is modified, set (SET_P == 1) or reset (SET_P == 0) the INDX\n-   bit in BMAP.  */\n-\n-static void\n-compute_transp (rtx x, int indx, sbitmap *bmap, int set_p)\n-{\n-  int i, j;\n-  basic_block bb;\n-  enum rtx_code code;\n-  reg_set *r;\n-  const char *fmt;\n-\n-  /* repeat is used to turn tail-recursion into iteration since GCC\n-     can't do it when there's no return value.  */\n- repeat:\n-\n-  if (x == 0)\n-    return;\n-\n-  code = GET_CODE (x);\n-  switch (code)\n-    {\n-    case REG:\n-      if (set_p)\n-\t{\n-\t  if (REGNO (x) < FIRST_PSEUDO_REGISTER)\n-\t    {\n-\t      FOR_EACH_BB (bb)\n-\t\tif (TEST_BIT (reg_set_in_block[bb->index], REGNO (x)))\n-\t\t  SET_BIT (bmap[bb->index], indx);\n-\t    }\n-\t  else\n-\t    {\n-\t      for (r = reg_set_table[REGNO (x)]; r != NULL; r = r->next)\n-\t\tSET_BIT (bmap[BLOCK_NUM (r->insn)], indx);\n-\t    }\n-\t}\n-      else\n-\t{\n-\t  if (REGNO (x) < FIRST_PSEUDO_REGISTER)\n-\t    {\n-\t      FOR_EACH_BB (bb)\n-\t\tif (TEST_BIT (reg_set_in_block[bb->index], REGNO (x)))\n-\t\t  RESET_BIT (bmap[bb->index], indx);\n-\t    }\n-\t  else\n-\t    {\n-\t      for (r = reg_set_table[REGNO (x)]; r != NULL; r = r->next)\n-\t\tRESET_BIT (bmap[BLOCK_NUM (r->insn)], indx);\n-\t    }\n-\t}\n-\n-      return;\n-\n-    case MEM:\n-      FOR_EACH_BB (bb)\n-\t{\n-\t  rtx list_entry = canon_modify_mem_list[bb->index];\n-\n-\t  while (list_entry)\n-\t    {\n-\t      rtx dest, dest_addr;\n-\n-\t      if (GET_CODE (XEXP (list_entry, 0)) == CALL_INSN)\n-\t\t{\n-\t\t  if (set_p)\n-\t\t    SET_BIT (bmap[bb->index], indx);\n-\t\t  else\n-\t\t    RESET_BIT (bmap[bb->index], indx);\n-\t\t  break;\n-\t\t}\n-\t      /* LIST_ENTRY must be an INSN of some kind that sets memory.\n-\t\t Examine each hunk of memory that is modified.  */\n-\n-\t      dest = XEXP (list_entry, 0);\n-\t      list_entry = XEXP (list_entry, 1);\n-\t      dest_addr = XEXP (list_entry, 0);\n-\n-\t      if (canon_true_dependence (dest, GET_MODE (dest), dest_addr,\n-\t\t\t\t\t x, rtx_addr_varies_p))\n-\t\t{\n-\t\t  if (set_p)\n-\t\t    SET_BIT (bmap[bb->index], indx);\n-\t\t  else\n-\t\t    RESET_BIT (bmap[bb->index], indx);\n-\t\t  break;\n-\t\t}\n-\t      list_entry = XEXP (list_entry, 1);\n-\t    }\n-\t}\n-\n-      x = XEXP (x, 0);\n-      goto repeat;\n-\n-    case PC:\n-    case CC0: /*FIXME*/\n-    case CONST:\n-    case CONST_INT:\n-    case CONST_DOUBLE:\n-    case CONST_VECTOR:\n-    case SYMBOL_REF:\n-    case LABEL_REF:\n-    case ADDR_VEC:\n-    case ADDR_DIFF_VEC:\n-      return;\n-\n-    default:\n-      break;\n-    }\n-\n-  for (i = GET_RTX_LENGTH (code) - 1, fmt = GET_RTX_FORMAT (code); i >= 0; i--)\n-    {\n-      if (fmt[i] == 'e')\n-\t{\n-\t  /* If we are about to do the last recursive call\n-\t     needed at this level, change it into iteration.\n-\t     This function is called enough to be worth it.  */\n-\t  if (i == 0)\n-\t    {\n-\t      x = XEXP (x, i);\n-\t      goto repeat;\n-\t    }\n-\n-\t  compute_transp (XEXP (x, i), indx, bmap, set_p);\n-\t}\n-      else if (fmt[i] == 'E')\n-\tfor (j = 0; j < XVECLEN (x, i); j++)\n-\t  compute_transp (XVECEXP (x, i, j), indx, bmap, set_p);\n-    }\n-}\n-\n-/* Top level routine to do the dataflow analysis needed by copy/const\n-   propagation.  */\n-\n-static void\n-compute_cprop_data (void)\n-{\n-  compute_local_properties (cprop_absaltered, cprop_pavloc, NULL, &set_hash_table);\n-  compute_available (cprop_pavloc, cprop_absaltered,\n-\t\t     cprop_avout, cprop_avin);\n-}\n-\f\n-/* Copy/constant propagation.  */\n-\n-/* Maximum number of register uses in an insn that we handle.  */\n-#define MAX_USES 8\n-\n-/* Table of uses found in an insn.\n-   Allocated statically to avoid alloc/free complexity and overhead.  */\n-static struct reg_use reg_use_table[MAX_USES];\n-\n-/* Index into `reg_use_table' while building it.  */\n-static int reg_use_count;\n-\n-/* Set up a list of register numbers used in INSN.  The found uses are stored\n-   in `reg_use_table'.  `reg_use_count' is initialized to zero before entry,\n-   and contains the number of uses in the table upon exit.\n-\n-   ??? If a register appears multiple times we will record it multiple times.\n-   This doesn't hurt anything but it will slow things down.  */\n-\n-static void\n-find_used_regs (rtx *xptr, void *data ATTRIBUTE_UNUSED)\n-{\n-  int i, j;\n-  enum rtx_code code;\n-  const char *fmt;\n-  rtx x = *xptr;\n-\n-  /* repeat is used to turn tail-recursion into iteration since GCC\n-     can't do it when there's no return value.  */\n- repeat:\n-  if (x == 0)\n-    return;\n-\n-  code = GET_CODE (x);\n-  if (REG_P (x))\n-    {\n-      if (reg_use_count == MAX_USES)\n-\treturn;\n+      if (reg_use_count == MAX_USES)\n+\treturn;\n \n       reg_use_table[reg_use_count].reg_rtx = x;\n       reg_use_count++;\n@@ -5046,8 +4210,6 @@ alloc_pre_mem (int n_blocks, int n_exprs)\n   pre_redundant = NULL;\n   pre_insert_map = NULL;\n   pre_delete_map = NULL;\n-  ae_in = NULL;\n-  ae_out = NULL;\n   ae_kill = sbitmap_vector_alloc (n_blocks, n_exprs);\n \n   /* pre_insert and pre_delete are allocated later.  */\n@@ -5071,14 +4233,9 @@ free_pre_mem (void)\n     sbitmap_vector_free (pre_insert_map);\n   if (pre_delete_map)\n     sbitmap_vector_free (pre_delete_map);\n-  if (ae_in)\n-    sbitmap_vector_free (ae_in);\n-  if (ae_out)\n-    sbitmap_vector_free (ae_out);\n \n   transp = comp = NULL;\n   pre_optimal = pre_redundant = pre_insert_map = pre_delete_map = NULL;\n-  ae_in = ae_out = NULL;\n }\n \n /* Top level routine to do the dataflow analysis needed by PRE.  */\n@@ -5107,8 +4264,7 @@ compute_pre_data (void)\n   /* Compute ae_kill for each basic block using:\n \n      ~(TRANSP | COMP)\n-\n-     This is significantly faster than compute_ae_kill.  */\n+  */\n \n   FOR_EACH_BB (bb)\n     {\n@@ -5913,295 +5069,6 @@ compute_transpout (void)\n     }\n }\n \n-/* Removal of useless null pointer checks */\n-\n-/* Called via note_stores.  X is set by SETTER.  If X is a register we must\n-   invalidate nonnull_local and set nonnull_killed.  DATA is really a\n-   `null_pointer_info *'.\n-\n-   We ignore hard registers.  */\n-\n-static void\n-invalidate_nonnull_info (rtx x, rtx setter ATTRIBUTE_UNUSED, void *data)\n-{\n-  unsigned int regno;\n-  struct null_pointer_info *npi = (struct null_pointer_info *) data;\n-\n-  while (GET_CODE (x) == SUBREG)\n-    x = SUBREG_REG (x);\n-\n-  /* Ignore anything that is not a register or is a hard register.  */\n-  if (GET_CODE (x) != REG\n-      || REGNO (x) < npi->min_reg\n-      || REGNO (x) >= npi->max_reg)\n-    return;\n-\n-  regno = REGNO (x) - npi->min_reg;\n-\n-  RESET_BIT (npi->nonnull_local[npi->current_block->index], regno);\n-  SET_BIT (npi->nonnull_killed[npi->current_block->index], regno);\n-}\n-\n-/* Do null-pointer check elimination for the registers indicated in\n-   NPI.  NONNULL_AVIN and NONNULL_AVOUT are pre-allocated sbitmaps;\n-   they are not our responsibility to free.  */\n-\n-static int\n-delete_null_pointer_checks_1 (unsigned int *block_reg, sbitmap *nonnull_avin,\n-\t\t\t      sbitmap *nonnull_avout,\n-\t\t\t      struct null_pointer_info *npi)\n-{\n-  basic_block bb, current_block;\n-  sbitmap *nonnull_local = npi->nonnull_local;\n-  sbitmap *nonnull_killed = npi->nonnull_killed;\n-  int something_changed = 0;\n-\n-  /* Compute local properties, nonnull and killed.  A register will have\n-     the nonnull property if at the end of the current block its value is\n-     known to be nonnull.  The killed property indicates that somewhere in\n-     the block any information we had about the register is killed.\n-\n-     Note that a register can have both properties in a single block.  That\n-     indicates that it's killed, then later in the block a new value is\n-     computed.  */\n-  sbitmap_vector_zero (nonnull_local, last_basic_block);\n-  sbitmap_vector_zero (nonnull_killed, last_basic_block);\n-\n-  FOR_EACH_BB (current_block)\n-    {\n-      rtx insn, stop_insn;\n-\n-      /* Set the current block for invalidate_nonnull_info.  */\n-      npi->current_block = current_block;\n-\n-      /* Scan each insn in the basic block looking for memory references and\n-\t register sets.  */\n-      stop_insn = NEXT_INSN (BB_END (current_block));\n-      for (insn = BB_HEAD (current_block);\n-\t   insn != stop_insn;\n-\t   insn = NEXT_INSN (insn))\n-\t{\n-\t  rtx set;\n-\t  rtx reg;\n-\n-\t  /* Ignore anything that is not a normal insn.  */\n-\t  if (! INSN_P (insn))\n-\t    continue;\n-\n-\t  /* Basically ignore anything that is not a simple SET.  We do have\n-\t     to make sure to invalidate nonnull_local and set nonnull_killed\n-\t     for such insns though.  */\n-\t  set = single_set (insn);\n-\t  if (!set)\n-\t    {\n-\t      note_stores (PATTERN (insn), invalidate_nonnull_info, npi);\n-\t      continue;\n-\t    }\n-\n-\t  /* See if we've got a usable memory load.  We handle it first\n-\t     in case it uses its address register as a dest (which kills\n-\t     the nonnull property).  */\n-\t  if (GET_CODE (SET_SRC (set)) == MEM\n-\t      && GET_CODE ((reg = XEXP (SET_SRC (set), 0))) == REG\n-\t      && REGNO (reg) >= npi->min_reg\n-\t      && REGNO (reg) < npi->max_reg)\n-\t    SET_BIT (nonnull_local[current_block->index],\n-\t\t     REGNO (reg) - npi->min_reg);\n-\n-\t  /* Now invalidate stuff clobbered by this insn.  */\n-\t  note_stores (PATTERN (insn), invalidate_nonnull_info, npi);\n-\n-\t  /* And handle stores, we do these last since any sets in INSN can\n-\t     not kill the nonnull property if it is derived from a MEM\n-\t     appearing in a SET_DEST.  */\n-\t  if (GET_CODE (SET_DEST (set)) == MEM\n-\t      && GET_CODE ((reg = XEXP (SET_DEST (set), 0))) == REG\n-\t      && REGNO (reg) >= npi->min_reg\n-\t      && REGNO (reg) < npi->max_reg)\n-\t    SET_BIT (nonnull_local[current_block->index],\n-\t\t     REGNO (reg) - npi->min_reg);\n-\t}\n-    }\n-\n-  /* Now compute global properties based on the local properties.   This\n-     is a classic global availability algorithm.  */\n-  compute_available (nonnull_local, nonnull_killed,\n-\t\t     nonnull_avout, nonnull_avin);\n-\n-  /* Now look at each bb and see if it ends with a compare of a value\n-     against zero.  */\n-  FOR_EACH_BB (bb)\n-    {\n-      rtx last_insn = BB_END (bb);\n-      rtx condition, earliest;\n-      int compare_and_branch;\n-\n-      /* Since MIN_REG is always at least FIRST_PSEUDO_REGISTER, and\n-\t since BLOCK_REG[BB] is zero if this block did not end with a\n-\t comparison against zero, this condition works.  */\n-      if (block_reg[bb->index] < npi->min_reg\n-\t  || block_reg[bb->index] >= npi->max_reg)\n-\tcontinue;\n-\n-      /* LAST_INSN is a conditional jump.  Get its condition.  */\n-      condition = get_condition (last_insn, &earliest, false);\n-\n-      /* If we can't determine the condition then skip.  */\n-      if (! condition)\n-\tcontinue;\n-\n-      /* Is the register known to have a nonzero value?  */\n-      if (!TEST_BIT (nonnull_avout[bb->index], block_reg[bb->index] - npi->min_reg))\n-\tcontinue;\n-\n-      /* Try to compute whether the compare/branch at the loop end is one or\n-\t two instructions.  */\n-      if (earliest == last_insn)\n-\tcompare_and_branch = 1;\n-      else if (earliest == prev_nonnote_insn (last_insn))\n-\tcompare_and_branch = 2;\n-      else\n-\tcontinue;\n-\n-      /* We know the register in this comparison is nonnull at exit from\n-\t this block.  We can optimize this comparison.  */\n-      if (GET_CODE (condition) == NE)\n-\t{\n-\t  rtx new_jump;\n-\n-\t  new_jump = emit_jump_insn_after (gen_jump (JUMP_LABEL (last_insn)),\n-\t\t\t\t\t   last_insn);\n-\t  JUMP_LABEL (new_jump) = JUMP_LABEL (last_insn);\n-\t  LABEL_NUSES (JUMP_LABEL (new_jump))++;\n-\t  emit_barrier_after (new_jump);\n-\t}\n-\n-      something_changed = 1;\n-      delete_insn (last_insn);\n-#ifdef HAVE_cc0\n-      if (compare_and_branch == 2)\n-\tdelete_insn (earliest);\n-#endif\n-      purge_dead_edges (bb);\n-\n-      /* Don't check this block again.  (Note that BB_END is\n-\t invalid here; we deleted the last instruction in the\n-\t block.)  */\n-      block_reg[bb->index] = 0;\n-    }\n-\n-  return something_changed;\n-}\n-\n-/* Find EQ/NE comparisons against zero which can be (indirectly) evaluated\n-   at compile time.\n-\n-   This is conceptually similar to global constant/copy propagation and\n-   classic global CSE (it even uses the same dataflow equations as cprop).\n-\n-   If a register is used as memory address with the form (mem (reg)), then we\n-   know that REG can not be zero at that point in the program.  Any instruction\n-   which sets REG \"kills\" this property.\n-\n-   So, if every path leading to a conditional branch has an available memory\n-   reference of that form, then we know the register can not have the value\n-   zero at the conditional branch.\n-\n-   So we merely need to compute the local properties and propagate that data\n-   around the cfg, then optimize where possible.\n-\n-   We run this pass two times.  Once before CSE, then again after CSE.  This\n-   has proven to be the most profitable approach.  It is rare for new\n-   optimization opportunities of this nature to appear after the first CSE\n-   pass.\n-\n-   This could probably be integrated with global cprop with a little work.  */\n-\n-int\n-delete_null_pointer_checks (rtx f ATTRIBUTE_UNUSED)\n-{\n-  sbitmap *nonnull_avin, *nonnull_avout;\n-  unsigned int *block_reg;\n-  basic_block bb;\n-  int reg;\n-  int regs_per_pass;\n-  int max_reg = max_reg_num ();\n-  struct null_pointer_info npi;\n-  int something_changed = 0;\n-\n-  /* If we have only a single block, or it is too expensive, give up.  */\n-  if (n_basic_blocks <= 1\n-      || is_too_expensive (_ (\"NULL pointer checks disabled\")))\n-    return 0;\n-\n-  /* We need four bitmaps, each with a bit for each register in each\n-     basic block.  */\n-  regs_per_pass = get_bitmap_width (4, last_basic_block, max_reg);\n-\n-  /* Allocate bitmaps to hold local and global properties.  */\n-  npi.nonnull_local = sbitmap_vector_alloc (last_basic_block, regs_per_pass);\n-  npi.nonnull_killed = sbitmap_vector_alloc (last_basic_block, regs_per_pass);\n-  nonnull_avin = sbitmap_vector_alloc (last_basic_block, regs_per_pass);\n-  nonnull_avout = sbitmap_vector_alloc (last_basic_block, regs_per_pass);\n-\n-  /* Go through the basic blocks, seeing whether or not each block\n-     ends with a conditional branch whose condition is a comparison\n-     against zero.  Record the register compared in BLOCK_REG.  */\n-  block_reg = xcalloc (last_basic_block, sizeof (int));\n-  FOR_EACH_BB (bb)\n-    {\n-      rtx last_insn = BB_END (bb);\n-      rtx condition, earliest, reg;\n-\n-      /* We only want conditional branches.  */\n-      if (GET_CODE (last_insn) != JUMP_INSN\n-\t  || !any_condjump_p (last_insn)\n-\t  || !onlyjump_p (last_insn))\n-\tcontinue;\n-\n-      /* LAST_INSN is a conditional jump.  Get its condition.  */\n-      condition = get_condition (last_insn, &earliest, false);\n-\n-      /* If we were unable to get the condition, or it is not an equality\n-\t comparison against zero then there's nothing we can do.  */\n-      if (!condition\n-\t  || (GET_CODE (condition) != NE && GET_CODE (condition) != EQ)\n-\t  || GET_CODE (XEXP (condition, 1)) != CONST_INT\n-\t  || (XEXP (condition, 1)\n-\t      != CONST0_RTX (GET_MODE (XEXP (condition, 0)))))\n-\tcontinue;\n-\n-      /* We must be checking a register against zero.  */\n-      reg = XEXP (condition, 0);\n-      if (GET_CODE (reg) != REG)\n-\tcontinue;\n-\n-      block_reg[bb->index] = REGNO (reg);\n-    }\n-\n-  /* Go through the algorithm for each block of registers.  */\n-  for (reg = FIRST_PSEUDO_REGISTER; reg < max_reg; reg += regs_per_pass)\n-    {\n-      npi.min_reg = reg;\n-      npi.max_reg = MIN (reg + regs_per_pass, max_reg);\n-      something_changed |= delete_null_pointer_checks_1 (block_reg,\n-\t\t\t\t\t\t\t nonnull_avin,\n-\t\t\t\t\t\t\t nonnull_avout,\n-\t\t\t\t\t\t\t &npi);\n-    }\n-\n-  /* Free the table of registers compared at the end of every block.  */\n-  free (block_reg);\n-\n-  /* Free bitmaps.  */\n-  sbitmap_vector_free (npi.nonnull_local);\n-  sbitmap_vector_free (npi.nonnull_killed);\n-  sbitmap_vector_free (nonnull_avin);\n-  sbitmap_vector_free (nonnull_avout);\n-\n-  return something_changed;\n-}\n-\n /* Code Hoisting variables and subroutines.  */\n \n /* Very busy expressions.  */"}, {"sha": "5c8e5a6fd0f13e773fdd9de70bc4e520a2519799", "filename": "gcc/passes.c", "status": "modified", "additions": 0, "deletions": 30, "changes": 30, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e83f48010bb27b7fd1db2ebdecc9e4611fe97793/gcc%2Fpasses.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e83f48010bb27b7fd1db2ebdecc9e4611fe97793/gcc%2Fpasses.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpasses.c?ref=e83f48010bb27b7fd1db2ebdecc9e4611fe97793", "patch": "@@ -1004,20 +1004,6 @@ rest_of_handle_jump_bypass (tree decl, rtx insns)\n #endif\n }\n \n-/* Try to identify useless null pointer tests and delete them.  */\n-static void\n-rest_of_handle_null_pointer (tree decl, rtx insns)\n-{\n-  open_dump_file (DFI_null, decl);\n-  if (dump_file)\n-    dump_flow_info (dump_file);\n-\n-  if (delete_null_pointer_checks (insns))\n-    cleanup_cfg (CLEANUP_EXPENSIVE | CLEANUP_PRE_LOOP);\n-\n-  close_dump_file (DFI_null, print_rtl_with_bb, insns);\n-}\n-\n /* Try combining insns through substitution.  */\n static void\n rest_of_handle_combine (tree decl, rtx insns)\n@@ -1120,19 +1106,6 @@ rest_of_handle_cse (tree decl, rtx insns)\n \n   if (tem || optimize > 1)\n     cleanup_cfg (CLEANUP_EXPENSIVE | CLEANUP_PRE_LOOP);\n-  /* Try to identify useless null pointer tests and delete them.  */\n-  if (flag_delete_null_pointer_checks)\n-    {\n-      timevar_push (TV_JUMP);\n-\n-      if (delete_null_pointer_checks (insns))\n-\tcleanup_cfg (CLEANUP_EXPENSIVE | CLEANUP_PRE_LOOP);\n-      timevar_pop (TV_JUMP);\n-    }\n-\n-  /* The second pass of jump optimization is likely to have\n-     removed a bunch more instructions.  */\n-  renumber_insns (dump_file);\n \n   timevar_pop (TV_CSE);\n   close_dump_file (DFI_cse, print_rtl_with_bb, insns);\n@@ -1547,9 +1520,6 @@ rest_of_compilation (tree decl)\n   if (optimize)\n     cleanup_cfg (CLEANUP_EXPENSIVE | CLEANUP_PRE_LOOP);\n \n-  if (flag_delete_null_pointer_checks)\n-    rest_of_handle_null_pointer (decl, insns);\n-\n   /* Jump optimization, and the removal of NULL pointer checks, may\n      have reduced the number of instructions substantially.  CSE, and\n      future passes, allocate arrays whose dimensions involve the"}, {"sha": "1041d020e1ab1d589a832546d3866ea231095d40", "filename": "gcc/rtl.h", "status": "modified", "additions": 0, "deletions": 2, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e83f48010bb27b7fd1db2ebdecc9e4611fe97793/gcc%2Frtl.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e83f48010bb27b7fd1db2ebdecc9e4611fe97793/gcc%2Frtl.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl.h?ref=e83f48010bb27b7fd1db2ebdecc9e4611fe97793", "patch": "@@ -2320,8 +2320,6 @@ extern void cannot_change_mode_set_regs (HARD_REG_SET *,\n extern bool invalid_mode_change_p (unsigned int, enum reg_class,\n \t\t\t\t   enum machine_mode);\n \n-extern int delete_null_pointer_checks (rtx);\n-\n /* In regmove.c */\n #ifdef BUFSIZ\n extern void regmove_optimize (rtx, int, FILE *);"}]}