{"sha": "bf592b2ff776aef71c91924cdb5e0d10488496cf", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YmY1OTJiMmZmNzc2YWVmNzFjOTE5MjRjZGI1ZTBkMTA0ODg0OTZjZg==", "commit": {"author": {"name": "xiezhiheng", "email": "xiezhiheng@huawei.com", "date": "2020-07-17T09:00:37Z"}, "committer": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2020-07-17T09:00:37Z"}, "message": "AArch64: Add flags in built-in functions [PR94442]\n\n2020-07-17  Zhiheng Xie  <xiezhiheng@huawei.com>\n\ngcc/ChangeLog:\n\n\t* config/aarch64/aarch64-builtins.c (enum aarch64_type_qualifiers):\n\tAdd new field flags.\n\t(VAR1): Add new field FLAG in macro.\n\t(VAR2): Likewise.\n\t(VAR3): Likewise.\n\t(VAR4): Likewise.\n\t(VAR5): Likewise.\n\t(VAR6): Likewise.\n\t(VAR7): Likewise.\n\t(VAR8): Likewise.\n\t(VAR9): Likewise.\n\t(VAR10): Likewise.\n\t(VAR11): Likewise.\n\t(VAR12): Likewise.\n\t(VAR13): Likewise.\n\t(VAR14): Likewise.\n\t(VAR15): Likewise.\n\t(VAR16): Likewise.\n\t(aarch64_general_fold_builtin): Likewise.\n\t(aarch64_general_gimple_fold_builtin): Likewise.\n\t* config/aarch64/aarch64-simd-builtins.def: Add default flag for\n\teach built-in function.\n\t* config/aarch64/geniterators.sh: Add new field in BUILTIN macro.", "tree": {"sha": "18270ac37a35ed0a84e2f03b6ee95ef94fe5122e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/18270ac37a35ed0a84e2f03b6ee95ef94fe5122e"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/bf592b2ff776aef71c91924cdb5e0d10488496cf", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bf592b2ff776aef71c91924cdb5e0d10488496cf", "html_url": "https://github.com/Rust-GCC/gccrs/commit/bf592b2ff776aef71c91924cdb5e0d10488496cf", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bf592b2ff776aef71c91924cdb5e0d10488496cf/comments", "author": null, "committer": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "0c1d1c01039a96c191a7aded40e5df40b14d387a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0c1d1c01039a96c191a7aded40e5df40b14d387a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0c1d1c01039a96c191a7aded40e5df40b14d387a"}], "stats": {"total": 1149, "additions": 581, "deletions": 568}, "files": [{"sha": "d5fb29048c4e03b6314e9857ab9341925ec04990", "filename": "gcc/config/aarch64/aarch64-builtins.c", "status": "modified", "additions": 72, "deletions": 59, "changes": 131, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bf592b2ff776aef71c91924cdb5e0d10488496cf/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bf592b2ff776aef71c91924cdb5e0d10488496cf/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c?ref=bf592b2ff776aef71c91924cdb5e0d10488496cf", "patch": "@@ -117,13 +117,26 @@ enum aarch64_type_qualifiers\n   qualifier_lane_quadtup_index = 0x1000,\n };\n \n+/* Flags that describe what a function might do.  */\n+const unsigned int FLAG_NONE = 0U;\n+const unsigned int FLAG_READ_FPCR = 1U << 0;\n+const unsigned int FLAG_RAISE_FP_EXCEPTIONS = 1U << 1;\n+const unsigned int FLAG_READ_MEMORY = 1U << 2;\n+const unsigned int FLAG_PREFETCH_MEMORY = 1U << 3;\n+const unsigned int FLAG_WRITE_MEMORY = 1U << 4;\n+\n+const unsigned int FLAG_FP = FLAG_READ_FPCR | FLAG_RAISE_FP_EXCEPTIONS;\n+const unsigned int FLAG_ALL = FLAG_READ_FPCR | FLAG_RAISE_FP_EXCEPTIONS\n+  | FLAG_READ_MEMORY | FLAG_PREFETCH_MEMORY | FLAG_WRITE_MEMORY;\n+\n typedef struct\n {\n   const char *name;\n   machine_mode mode;\n   const enum insn_code code;\n   unsigned int fcode;\n   enum aarch64_type_qualifiers *qualifiers;\n+  unsigned int flags;\n } aarch64_simd_builtin_datum;\n \n static enum aarch64_type_qualifiers\n@@ -336,53 +349,53 @@ aarch64_types_storestruct_lane_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n #define CF4(N, X) CODE_FOR_##N##X##4\n #define CF10(N, X) CODE_FOR_##N##X\n \n-#define VAR1(T, N, MAP, A) \\\n-  {#N #A, UP (A), CF##MAP (N, A), 0, TYPES_##T},\n-#define VAR2(T, N, MAP, A, B) \\\n-  VAR1 (T, N, MAP, A) \\\n-  VAR1 (T, N, MAP, B)\n-#define VAR3(T, N, MAP, A, B, C) \\\n-  VAR2 (T, N, MAP, A, B) \\\n-  VAR1 (T, N, MAP, C)\n-#define VAR4(T, N, MAP, A, B, C, D) \\\n-  VAR3 (T, N, MAP, A, B, C) \\\n-  VAR1 (T, N, MAP, D)\n-#define VAR5(T, N, MAP, A, B, C, D, E) \\\n-  VAR4 (T, N, MAP, A, B, C, D) \\\n-  VAR1 (T, N, MAP, E)\n-#define VAR6(T, N, MAP, A, B, C, D, E, F) \\\n-  VAR5 (T, N, MAP, A, B, C, D, E) \\\n-  VAR1 (T, N, MAP, F)\n-#define VAR7(T, N, MAP, A, B, C, D, E, F, G) \\\n-  VAR6 (T, N, MAP, A, B, C, D, E, F) \\\n-  VAR1 (T, N, MAP, G)\n-#define VAR8(T, N, MAP, A, B, C, D, E, F, G, H) \\\n-  VAR7 (T, N, MAP, A, B, C, D, E, F, G) \\\n-  VAR1 (T, N, MAP, H)\n-#define VAR9(T, N, MAP, A, B, C, D, E, F, G, H, I) \\\n-  VAR8 (T, N, MAP, A, B, C, D, E, F, G, H) \\\n-  VAR1 (T, N, MAP, I)\n-#define VAR10(T, N, MAP, A, B, C, D, E, F, G, H, I, J) \\\n-  VAR9 (T, N, MAP, A, B, C, D, E, F, G, H, I) \\\n-  VAR1 (T, N, MAP, J)\n-#define VAR11(T, N, MAP, A, B, C, D, E, F, G, H, I, J, K) \\\n-  VAR10 (T, N, MAP, A, B, C, D, E, F, G, H, I, J) \\\n-  VAR1 (T, N, MAP, K)\n-#define VAR12(T, N, MAP, A, B, C, D, E, F, G, H, I, J, K, L) \\\n-  VAR11 (T, N, MAP, A, B, C, D, E, F, G, H, I, J, K) \\\n-  VAR1 (T, N, MAP, L)\n-#define VAR13(T, N, MAP, A, B, C, D, E, F, G, H, I, J, K, L, M) \\\n-  VAR12 (T, N, MAP, A, B, C, D, E, F, G, H, I, J, K, L) \\\n-  VAR1 (T, N, MAP, M)\n-#define VAR14(T, X, MAP, A, B, C, D, E, F, G, H, I, J, K, L, M, N) \\\n-  VAR13 (T, X, MAP, A, B, C, D, E, F, G, H, I, J, K, L, M) \\\n-  VAR1 (T, X, MAP, N)\n-#define VAR15(T, X, MAP, A, B, C, D, E, F, G, H, I, J, K, L, M, N, O) \\\n-  VAR14 (T, X, MAP, A, B, C, D, E, F, G, H, I, J, K, L, M, N) \\\n-  VAR1 (T, X, MAP, O)\n-#define VAR16(T, X, MAP, A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P) \\\n-  VAR15 (T, X, MAP, A, B, C, D, E, F, G, H, I, J, K, L, M, N, O) \\\n-  VAR1 (T, X, MAP, P)\n+#define VAR1(T, N, MAP, FLAG, A) \\\n+  {#N #A, UP (A), CF##MAP (N, A), 0, TYPES_##T, FLAG_##FLAG},\n+#define VAR2(T, N, MAP, FLAG, A, B) \\\n+  VAR1 (T, N, MAP, FLAG, A) \\\n+  VAR1 (T, N, MAP, FLAG, B)\n+#define VAR3(T, N, MAP, FLAG, A, B, C) \\\n+  VAR2 (T, N, MAP, FLAG, A, B) \\\n+  VAR1 (T, N, MAP, FLAG, C)\n+#define VAR4(T, N, MAP, FLAG, A, B, C, D) \\\n+  VAR3 (T, N, MAP, FLAG, A, B, C) \\\n+  VAR1 (T, N, MAP, FLAG, D)\n+#define VAR5(T, N, MAP, FLAG, A, B, C, D, E) \\\n+  VAR4 (T, N, MAP, FLAG, A, B, C, D) \\\n+  VAR1 (T, N, MAP, FLAG, E)\n+#define VAR6(T, N, MAP, FLAG, A, B, C, D, E, F) \\\n+  VAR5 (T, N, MAP, FLAG, A, B, C, D, E) \\\n+  VAR1 (T, N, MAP, FLAG, F)\n+#define VAR7(T, N, MAP, FLAG, A, B, C, D, E, F, G) \\\n+  VAR6 (T, N, MAP, FLAG, A, B, C, D, E, F) \\\n+  VAR1 (T, N, MAP, FLAG, G)\n+#define VAR8(T, N, MAP, FLAG, A, B, C, D, E, F, G, H) \\\n+  VAR7 (T, N, MAP, FLAG, A, B, C, D, E, F, G) \\\n+  VAR1 (T, N, MAP, FLAG, H)\n+#define VAR9(T, N, MAP, FLAG, A, B, C, D, E, F, G, H, I) \\\n+  VAR8 (T, N, MAP, FLAG, A, B, C, D, E, F, G, H) \\\n+  VAR1 (T, N, MAP, FLAG, I)\n+#define VAR10(T, N, MAP, FLAG, A, B, C, D, E, F, G, H, I, J) \\\n+  VAR9 (T, N, MAP, FLAG, A, B, C, D, E, F, G, H, I) \\\n+  VAR1 (T, N, MAP, FLAG, J)\n+#define VAR11(T, N, MAP, FLAG, A, B, C, D, E, F, G, H, I, J, K) \\\n+  VAR10 (T, N, MAP, FLAG, A, B, C, D, E, F, G, H, I, J) \\\n+  VAR1 (T, N, MAP, FLAG, K)\n+#define VAR12(T, N, MAP, FLAG, A, B, C, D, E, F, G, H, I, J, K, L) \\\n+  VAR11 (T, N, MAP, FLAG, A, B, C, D, E, F, G, H, I, J, K) \\\n+  VAR1 (T, N, MAP, FLAG, L)\n+#define VAR13(T, N, MAP, FLAG, A, B, C, D, E, F, G, H, I, J, K, L, M) \\\n+  VAR12 (T, N, MAP, FLAG, A, B, C, D, E, F, G, H, I, J, K, L) \\\n+  VAR1 (T, N, MAP, FLAG, M)\n+#define VAR14(T, X, MAP, FLAG, A, B, C, D, E, F, G, H, I, J, K, L, M, N) \\\n+  VAR13 (T, X, MAP, FLAG, A, B, C, D, E, F, G, H, I, J, K, L, M) \\\n+  VAR1 (T, X, MAP, FLAG, N)\n+#define VAR15(T, X, MAP, FLAG, A, B, C, D, E, F, G, H, I, J, K, L, M, N, O) \\\n+  VAR14 (T, X, MAP, FLAG, A, B, C, D, E, F, G, H, I, J, K, L, M, N) \\\n+  VAR1 (T, X, MAP, FLAG, O)\n+#define VAR16(T, X, MAP, FLAG, A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P) \\\n+  VAR15 (T, X, MAP, FLAG, A, B, C, D, E, F, G, H, I, J, K, L, M, N, O) \\\n+  VAR1 (T, X, MAP, FLAG, P)\n \n #include \"aarch64-builtin-iterators.h\"\n \n@@ -438,7 +451,7 @@ typedef struct\n   AARCH64_SIMD_BUILTIN_FCMLA_LANEQ##I##_##M,\n \n #undef VAR1\n-#define VAR1(T, N, MAP, A) \\\n+#define VAR1(T, N, MAP, FLAG, A) \\\n   AARCH64_SIMD_BUILTIN_##T##_##N##A,\n \n enum aarch64_builtins\n@@ -2196,7 +2209,7 @@ aarch64_general_builtin_rsqrt (unsigned int fn)\n }\n \n #undef VAR1\n-#define VAR1(T, N, MAP, A) \\\n+#define VAR1(T, N, MAP, FLAG, A) \\\n   case AARCH64_SIMD_BUILTIN_##T##_##N##A:\n \n /* Try to fold a call to the built-in function with subcode FCODE.  The\n@@ -2209,11 +2222,11 @@ aarch64_general_fold_builtin (unsigned int fcode, tree type,\n {\n   switch (fcode)\n     {\n-      BUILTIN_VDQF (UNOP, abs, 2)\n+      BUILTIN_VDQF (UNOP, abs, 2, ALL)\n \treturn fold_build1 (ABS_EXPR, type, args[0]);\n-      VAR1 (UNOP, floatv2si, 2, v2sf)\n-      VAR1 (UNOP, floatv4si, 2, v4sf)\n-      VAR1 (UNOP, floatv2di, 2, v2df)\n+      VAR1 (UNOP, floatv2si, 2, ALL, v2sf)\n+      VAR1 (UNOP, floatv4si, 2, ALL, v4sf)\n+      VAR1 (UNOP, floatv2di, 2, ALL, v2df)\n \treturn fold_build1 (FLOAT_EXPR, type, args[0]);\n       default:\n \tbreak;\n@@ -2239,24 +2252,24 @@ aarch64_general_gimple_fold_builtin (unsigned int fcode, gcall *stmt)\n      the arguments to the __builtin.  */\n   switch (fcode)\n     {\n-      BUILTIN_VALL (UNOP, reduc_plus_scal_, 10)\n+      BUILTIN_VALL (UNOP, reduc_plus_scal_, 10, ALL)\n \tnew_stmt = gimple_build_call_internal (IFN_REDUC_PLUS,\n \t\t\t\t\t       1, args[0]);\n \tgimple_call_set_lhs (new_stmt, gimple_call_lhs (stmt));\n \tbreak;\n-      BUILTIN_VDQIF (UNOP, reduc_smax_scal_, 10)\n-      BUILTIN_VDQ_BHSI (UNOPU, reduc_umax_scal_, 10)\n+      BUILTIN_VDQIF (UNOP, reduc_smax_scal_, 10, ALL)\n+      BUILTIN_VDQ_BHSI (UNOPU, reduc_umax_scal_, 10, ALL)\n \tnew_stmt = gimple_build_call_internal (IFN_REDUC_MAX,\n \t\t\t\t\t       1, args[0]);\n \tgimple_call_set_lhs (new_stmt, gimple_call_lhs (stmt));\n \tbreak;\n-      BUILTIN_VDQIF (UNOP, reduc_smin_scal_, 10)\n-      BUILTIN_VDQ_BHSI (UNOPU, reduc_umin_scal_, 10)\n+      BUILTIN_VDQIF (UNOP, reduc_smin_scal_, 10, ALL)\n+      BUILTIN_VDQ_BHSI (UNOPU, reduc_umin_scal_, 10, ALL)\n \tnew_stmt = gimple_build_call_internal (IFN_REDUC_MIN,\n \t\t\t\t\t       1, args[0]);\n \tgimple_call_set_lhs (new_stmt, gimple_call_lhs (stmt));\n \tbreak;\n-      BUILTIN_GPF (BINOP, fmulx, 0)\n+      BUILTIN_GPF (BINOP, fmulx, 0, ALL)\n \t{\n \t  gcc_assert (nargs == 2);\n \t  bool a0_cst_p = TREE_CODE (args[0]) == REAL_CST;"}, {"sha": "e8650121cd68fc0a9320cad1b4ac2d9b983cc55a", "filename": "gcc/config/aarch64/aarch64-simd-builtins.def", "status": "modified", "additions": 507, "deletions": 507, "changes": 1014, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bf592b2ff776aef71c91924cdb5e0d10488496cf/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bf592b2ff776aef71c91924cdb5e0d10488496cf/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def?ref=bf592b2ff776aef71c91924cdb5e0d10488496cf", "patch": "@@ -39,693 +39,693 @@\n    1-9 - CODE_FOR_<name><mode><1-9>\n    10 - CODE_FOR_<name><mode>.  */\n \n-  BUILTIN_VDC (COMBINE, combine, 0)\n-  VAR1 (COMBINEP, combine, 0, di)\n-  BUILTIN_VB (BINOP, pmul, 0)\n-  BUILTIN_VHSDF_HSDF (BINOP, fmulx, 0)\n-  BUILTIN_VHSDF_DF (UNOP, sqrt, 2)\n-  BUILTIN_VD_BHSI (BINOP, addp, 0)\n-  VAR1 (UNOP, addp, 0, di)\n-  BUILTIN_VDQ_BHSI (UNOP, clrsb, 2)\n-  BUILTIN_VDQ_BHSI (UNOP, clz, 2)\n-  BUILTIN_VS (UNOP, ctz, 2)\n-  BUILTIN_VB (UNOP, popcount, 2)\n+  BUILTIN_VDC (COMBINE, combine, 0, ALL)\n+  VAR1 (COMBINEP, combine, 0, ALL, di)\n+  BUILTIN_VB (BINOP, pmul, 0, ALL)\n+  BUILTIN_VHSDF_HSDF (BINOP, fmulx, 0, ALL)\n+  BUILTIN_VHSDF_DF (UNOP, sqrt, 2, ALL)\n+  BUILTIN_VD_BHSI (BINOP, addp, 0, ALL)\n+  VAR1 (UNOP, addp, 0, ALL, di)\n+  BUILTIN_VDQ_BHSI (UNOP, clrsb, 2, ALL)\n+  BUILTIN_VDQ_BHSI (UNOP, clz, 2, ALL)\n+  BUILTIN_VS (UNOP, ctz, 2, ALL)\n+  BUILTIN_VB (UNOP, popcount, 2, ALL)\n \n   /* Implemented by aarch64_<sur>q<r>shl<mode>.  */\n-  BUILTIN_VSDQ_I (BINOP, sqshl, 0)\n-  BUILTIN_VSDQ_I (BINOP_UUS, uqshl, 0)\n-  BUILTIN_VSDQ_I (BINOP, sqrshl, 0)\n-  BUILTIN_VSDQ_I (BINOP_UUS, uqrshl, 0)\n+  BUILTIN_VSDQ_I (BINOP, sqshl, 0, ALL)\n+  BUILTIN_VSDQ_I (BINOP_UUS, uqshl, 0, ALL)\n+  BUILTIN_VSDQ_I (BINOP, sqrshl, 0, ALL)\n+  BUILTIN_VSDQ_I (BINOP_UUS, uqrshl, 0, ALL)\n   /* Implemented by aarch64_<su_optab><optab><mode>.  */\n-  BUILTIN_VSDQ_I (BINOP, sqadd, 0)\n-  BUILTIN_VSDQ_I (BINOPU, uqadd, 0)\n-  BUILTIN_VSDQ_I (BINOP, sqsub, 0)\n-  BUILTIN_VSDQ_I (BINOPU, uqsub, 0)\n+  BUILTIN_VSDQ_I (BINOP, sqadd, 0, ALL)\n+  BUILTIN_VSDQ_I (BINOPU, uqadd, 0, ALL)\n+  BUILTIN_VSDQ_I (BINOP, sqsub, 0, ALL)\n+  BUILTIN_VSDQ_I (BINOPU, uqsub, 0, ALL)\n   /* Implemented by aarch64_<sur>qadd<mode>.  */\n-  BUILTIN_VSDQ_I (BINOP_SSU, suqadd, 0)\n-  BUILTIN_VSDQ_I (BINOP_UUS, usqadd, 0)\n+  BUILTIN_VSDQ_I (BINOP_SSU, suqadd, 0, ALL)\n+  BUILTIN_VSDQ_I (BINOP_UUS, usqadd, 0, ALL)\n \n   /* Implemented by aarch64_get_dreg<VSTRUCT:mode><VDC:mode>.  */\n-  BUILTIN_VDC (GETREG, get_dregoi, 0)\n-  BUILTIN_VDC (GETREG, get_dregci, 0)\n-  BUILTIN_VDC (GETREG, get_dregxi, 0)\n-  VAR1 (GETREGP, get_dregoi, 0, di)\n-  VAR1 (GETREGP, get_dregci, 0, di)\n-  VAR1 (GETREGP, get_dregxi, 0, di)\n+  BUILTIN_VDC (GETREG, get_dregoi, 0, ALL)\n+  BUILTIN_VDC (GETREG, get_dregci, 0, ALL)\n+  BUILTIN_VDC (GETREG, get_dregxi, 0, ALL)\n+  VAR1 (GETREGP, get_dregoi, 0, ALL, di)\n+  VAR1 (GETREGP, get_dregci, 0, ALL, di)\n+  VAR1 (GETREGP, get_dregxi, 0, ALL, di)\n   /* Implemented by aarch64_get_qreg<VSTRUCT:mode><VQ:mode>.  */\n-  BUILTIN_VQ (GETREG, get_qregoi, 0)\n-  BUILTIN_VQ (GETREG, get_qregci, 0)\n-  BUILTIN_VQ (GETREG, get_qregxi, 0)\n-  VAR1 (GETREGP, get_qregoi, 0, v2di)\n-  VAR1 (GETREGP, get_qregci, 0, v2di)\n-  VAR1 (GETREGP, get_qregxi, 0, v2di)\n+  BUILTIN_VQ (GETREG, get_qregoi, 0, ALL)\n+  BUILTIN_VQ (GETREG, get_qregci, 0, ALL)\n+  BUILTIN_VQ (GETREG, get_qregxi, 0, ALL)\n+  VAR1 (GETREGP, get_qregoi, 0, ALL, v2di)\n+  VAR1 (GETREGP, get_qregci, 0, ALL, v2di)\n+  VAR1 (GETREGP, get_qregxi, 0, ALL, v2di)\n   /* Implemented by aarch64_set_qreg<VSTRUCT:mode><VQ:mode>.  */\n-  BUILTIN_VQ (SETREG, set_qregoi, 0)\n-  BUILTIN_VQ (SETREG, set_qregci, 0)\n-  BUILTIN_VQ (SETREG, set_qregxi, 0)\n-  VAR1 (SETREGP, set_qregoi, 0, v2di)\n-  VAR1 (SETREGP, set_qregci, 0, v2di)\n-  VAR1 (SETREGP, set_qregxi, 0, v2di)\n+  BUILTIN_VQ (SETREG, set_qregoi, 0, ALL)\n+  BUILTIN_VQ (SETREG, set_qregci, 0, ALL)\n+  BUILTIN_VQ (SETREG, set_qregxi, 0, ALL)\n+  VAR1 (SETREGP, set_qregoi, 0, ALL, v2di)\n+  VAR1 (SETREGP, set_qregci, 0, ALL, v2di)\n+  VAR1 (SETREGP, set_qregxi, 0, ALL, v2di)\n   /* Implemented by aarch64_ld1x2<VQ:mode>. */\n-  BUILTIN_VQ (LOADSTRUCT, ld1x2, 0)\n+  BUILTIN_VQ (LOADSTRUCT, ld1x2, 0, ALL)\n   /* Implemented by aarch64_ld1x2<VDC:mode>. */\n-  BUILTIN_VDC (LOADSTRUCT, ld1x2, 0)\n+  BUILTIN_VDC (LOADSTRUCT, ld1x2, 0, ALL)\n   /* Implemented by aarch64_ld<VSTRUCT:nregs><VDC:mode>.  */\n-  BUILTIN_VDC (LOADSTRUCT, ld2, 0)\n-  BUILTIN_VDC (LOADSTRUCT, ld3, 0)\n-  BUILTIN_VDC (LOADSTRUCT, ld4, 0)\n+  BUILTIN_VDC (LOADSTRUCT, ld2, 0, ALL)\n+  BUILTIN_VDC (LOADSTRUCT, ld3, 0, ALL)\n+  BUILTIN_VDC (LOADSTRUCT, ld4, 0, ALL)\n   /* Implemented by aarch64_ld<VSTRUCT:nregs><VQ:mode>.  */\n-  BUILTIN_VQ (LOADSTRUCT, ld2, 0)\n-  BUILTIN_VQ (LOADSTRUCT, ld3, 0)\n-  BUILTIN_VQ (LOADSTRUCT, ld4, 0)\n+  BUILTIN_VQ (LOADSTRUCT, ld2, 0, ALL)\n+  BUILTIN_VQ (LOADSTRUCT, ld3, 0, ALL)\n+  BUILTIN_VQ (LOADSTRUCT, ld4, 0, ALL)\n   /* Implemented by aarch64_ld<VSTRUCT:nregs>r<VALLDIF:mode>.  */\n-  BUILTIN_VALLDIF (LOADSTRUCT, ld2r, 0)\n-  BUILTIN_VALLDIF (LOADSTRUCT, ld3r, 0)\n-  BUILTIN_VALLDIF (LOADSTRUCT, ld4r, 0)\n+  BUILTIN_VALLDIF (LOADSTRUCT, ld2r, 0, ALL)\n+  BUILTIN_VALLDIF (LOADSTRUCT, ld3r, 0, ALL)\n+  BUILTIN_VALLDIF (LOADSTRUCT, ld4r, 0, ALL)\n   /* Implemented by aarch64_ld<VSTRUCT:nregs>_lane<VQ:mode>.  */\n-  BUILTIN_VALLDIF (LOADSTRUCT_LANE, ld2_lane, 0)\n-  BUILTIN_VALLDIF (LOADSTRUCT_LANE, ld3_lane, 0)\n-  BUILTIN_VALLDIF (LOADSTRUCT_LANE, ld4_lane, 0)\n+  BUILTIN_VALLDIF (LOADSTRUCT_LANE, ld2_lane, 0, ALL)\n+  BUILTIN_VALLDIF (LOADSTRUCT_LANE, ld3_lane, 0, ALL)\n+  BUILTIN_VALLDIF (LOADSTRUCT_LANE, ld4_lane, 0, ALL)\n   /* Implemented by aarch64_st<VSTRUCT:nregs><VDC:mode>.  */\n-  BUILTIN_VDC (STORESTRUCT, st2, 0)\n-  BUILTIN_VDC (STORESTRUCT, st3, 0)\n-  BUILTIN_VDC (STORESTRUCT, st4, 0)\n+  BUILTIN_VDC (STORESTRUCT, st2, 0, ALL)\n+  BUILTIN_VDC (STORESTRUCT, st3, 0, ALL)\n+  BUILTIN_VDC (STORESTRUCT, st4, 0, ALL)\n   /* Implemented by aarch64_st<VSTRUCT:nregs><VQ:mode>.  */\n-  BUILTIN_VQ (STORESTRUCT, st2, 0)\n-  BUILTIN_VQ (STORESTRUCT, st3, 0)\n-  BUILTIN_VQ (STORESTRUCT, st4, 0)\n-\n-  BUILTIN_VALLDIF (STORESTRUCT_LANE, st2_lane, 0)\n-  BUILTIN_VALLDIF (STORESTRUCT_LANE, st3_lane, 0)\n-  BUILTIN_VALLDIF (STORESTRUCT_LANE, st4_lane, 0)\n-\n-  BUILTIN_VQW (BINOP, saddl2, 0)\n-  BUILTIN_VQW (BINOP, uaddl2, 0)\n-  BUILTIN_VQW (BINOP, ssubl2, 0)\n-  BUILTIN_VQW (BINOP, usubl2, 0)\n-  BUILTIN_VQW (BINOP, saddw2, 0)\n-  BUILTIN_VQW (BINOP, uaddw2, 0)\n-  BUILTIN_VQW (BINOP, ssubw2, 0)\n-  BUILTIN_VQW (BINOP, usubw2, 0)\n+  BUILTIN_VQ (STORESTRUCT, st2, 0, ALL)\n+  BUILTIN_VQ (STORESTRUCT, st3, 0, ALL)\n+  BUILTIN_VQ (STORESTRUCT, st4, 0, ALL)\n+\n+  BUILTIN_VALLDIF (STORESTRUCT_LANE, st2_lane, 0, ALL)\n+  BUILTIN_VALLDIF (STORESTRUCT_LANE, st3_lane, 0, ALL)\n+  BUILTIN_VALLDIF (STORESTRUCT_LANE, st4_lane, 0, ALL)\n+\n+  BUILTIN_VQW (BINOP, saddl2, 0, ALL)\n+  BUILTIN_VQW (BINOP, uaddl2, 0, ALL)\n+  BUILTIN_VQW (BINOP, ssubl2, 0, ALL)\n+  BUILTIN_VQW (BINOP, usubl2, 0, ALL)\n+  BUILTIN_VQW (BINOP, saddw2, 0, ALL)\n+  BUILTIN_VQW (BINOP, uaddw2, 0, ALL)\n+  BUILTIN_VQW (BINOP, ssubw2, 0, ALL)\n+  BUILTIN_VQW (BINOP, usubw2, 0, ALL)\n   /* Implemented by aarch64_<ANY_EXTEND:su><ADDSUB:optab>l<mode>.  */\n-  BUILTIN_VD_BHSI (BINOP, saddl, 0)\n-  BUILTIN_VD_BHSI (BINOP, uaddl, 0)\n-  BUILTIN_VD_BHSI (BINOP, ssubl, 0)\n-  BUILTIN_VD_BHSI (BINOP, usubl, 0)\n+  BUILTIN_VD_BHSI (BINOP, saddl, 0, ALL)\n+  BUILTIN_VD_BHSI (BINOP, uaddl, 0, ALL)\n+  BUILTIN_VD_BHSI (BINOP, ssubl, 0, ALL)\n+  BUILTIN_VD_BHSI (BINOP, usubl, 0, ALL)\n   /* Implemented by aarch64_<ANY_EXTEND:su><ADDSUB:optab>w<mode>.  */\n-  BUILTIN_VD_BHSI (BINOP, saddw, 0)\n-  BUILTIN_VD_BHSI (BINOP, uaddw, 0)\n-  BUILTIN_VD_BHSI (BINOP, ssubw, 0)\n-  BUILTIN_VD_BHSI (BINOP, usubw, 0)\n+  BUILTIN_VD_BHSI (BINOP, saddw, 0, ALL)\n+  BUILTIN_VD_BHSI (BINOP, uaddw, 0, ALL)\n+  BUILTIN_VD_BHSI (BINOP, ssubw, 0, ALL)\n+  BUILTIN_VD_BHSI (BINOP, usubw, 0, ALL)\n   /* Implemented by aarch64_<sur>h<addsub><mode>.  */\n-  BUILTIN_VDQ_BHSI (BINOP, shadd, 0)\n-  BUILTIN_VDQ_BHSI (BINOP, shsub, 0)\n-  BUILTIN_VDQ_BHSI (BINOP, uhadd, 0)\n-  BUILTIN_VDQ_BHSI (BINOP, uhsub, 0)\n-  BUILTIN_VDQ_BHSI (BINOP, srhadd, 0)\n-  BUILTIN_VDQ_BHSI (BINOP, urhadd, 0)\n+  BUILTIN_VDQ_BHSI (BINOP, shadd, 0, ALL)\n+  BUILTIN_VDQ_BHSI (BINOP, shsub, 0, ALL)\n+  BUILTIN_VDQ_BHSI (BINOP, uhadd, 0, ALL)\n+  BUILTIN_VDQ_BHSI (BINOP, uhsub, 0, ALL)\n+  BUILTIN_VDQ_BHSI (BINOP, srhadd, 0, ALL)\n+  BUILTIN_VDQ_BHSI (BINOP, urhadd, 0, ALL)\n   /* Implemented by aarch64_<sur><addsub>hn<mode>.  */\n-  BUILTIN_VQN (BINOP, addhn, 0)\n-  BUILTIN_VQN (BINOP, subhn, 0)\n-  BUILTIN_VQN (BINOP, raddhn, 0)\n-  BUILTIN_VQN (BINOP, rsubhn, 0)\n+  BUILTIN_VQN (BINOP, addhn, 0, ALL)\n+  BUILTIN_VQN (BINOP, subhn, 0, ALL)\n+  BUILTIN_VQN (BINOP, raddhn, 0, ALL)\n+  BUILTIN_VQN (BINOP, rsubhn, 0, ALL)\n   /* Implemented by aarch64_<sur><addsub>hn2<mode>.  */\n-  BUILTIN_VQN (TERNOP, addhn2, 0)\n-  BUILTIN_VQN (TERNOP, subhn2, 0)\n-  BUILTIN_VQN (TERNOP, raddhn2, 0)\n-  BUILTIN_VQN (TERNOP, rsubhn2, 0)\n+  BUILTIN_VQN (TERNOP, addhn2, 0, ALL)\n+  BUILTIN_VQN (TERNOP, subhn2, 0, ALL)\n+  BUILTIN_VQN (TERNOP, raddhn2, 0, ALL)\n+  BUILTIN_VQN (TERNOP, rsubhn2, 0, ALL)\n \n-  BUILTIN_VSQN_HSDI (UNOP, sqmovun, 0)\n+  BUILTIN_VSQN_HSDI (UNOP, sqmovun, 0, ALL)\n   /* Implemented by aarch64_<sur>qmovn<mode>.  */\n-  BUILTIN_VSQN_HSDI (UNOP, sqmovn, 0)\n-  BUILTIN_VSQN_HSDI (UNOP, uqmovn, 0)\n+  BUILTIN_VSQN_HSDI (UNOP, sqmovn, 0, ALL)\n+  BUILTIN_VSQN_HSDI (UNOP, uqmovn, 0, ALL)\n   /* Implemented by aarch64_s<optab><mode>.  */\n-  BUILTIN_VSDQ_I (UNOP, sqabs, 0)\n-  BUILTIN_VSDQ_I (UNOP, sqneg, 0)\n+  BUILTIN_VSDQ_I (UNOP, sqabs, 0, ALL)\n+  BUILTIN_VSDQ_I (UNOP, sqneg, 0, ALL)\n \n   /* Implemented by aarch64_sqdml<SBINQOPS:as>l<mode>.  */\n-  BUILTIN_VSD_HSI (TERNOP, sqdmlal, 0)\n-  BUILTIN_VSD_HSI (TERNOP, sqdmlsl, 0)\n+  BUILTIN_VSD_HSI (TERNOP, sqdmlal, 0, ALL)\n+  BUILTIN_VSD_HSI (TERNOP, sqdmlsl, 0, ALL)\n   /* Implemented by aarch64_sqdml<SBINQOPS:as>l_lane<mode>.  */\n-  BUILTIN_VSD_HSI (QUADOP_LANE, sqdmlal_lane, 0)\n-  BUILTIN_VSD_HSI (QUADOP_LANE, sqdmlsl_lane, 0)\n+  BUILTIN_VSD_HSI (QUADOP_LANE, sqdmlal_lane, 0, ALL)\n+  BUILTIN_VSD_HSI (QUADOP_LANE, sqdmlsl_lane, 0, ALL)\n   /* Implemented by aarch64_sqdml<SBINQOPS:as>l_laneq<mode>.  */\n-  BUILTIN_VSD_HSI (QUADOP_LANE, sqdmlal_laneq, 0)\n-  BUILTIN_VSD_HSI (QUADOP_LANE, sqdmlsl_laneq, 0)\n+  BUILTIN_VSD_HSI (QUADOP_LANE, sqdmlal_laneq, 0, ALL)\n+  BUILTIN_VSD_HSI (QUADOP_LANE, sqdmlsl_laneq, 0, ALL)\n   /* Implemented by aarch64_sqdml<SBINQOPS:as>l_n<mode>.  */\n-  BUILTIN_VD_HSI (TERNOP, sqdmlal_n, 0)\n-  BUILTIN_VD_HSI (TERNOP, sqdmlsl_n, 0)\n-\n-  BUILTIN_VQ_HSI (TERNOP, sqdmlal2, 0)\n-  BUILTIN_VQ_HSI (TERNOP, sqdmlsl2, 0)\n-  BUILTIN_VQ_HSI (QUADOP_LANE, sqdmlal2_lane, 0)\n-  BUILTIN_VQ_HSI (QUADOP_LANE, sqdmlsl2_lane, 0)\n-  BUILTIN_VQ_HSI (QUADOP_LANE, sqdmlal2_laneq, 0)\n-  BUILTIN_VQ_HSI (QUADOP_LANE, sqdmlsl2_laneq, 0)\n-  BUILTIN_VQ_HSI (TERNOP, sqdmlal2_n, 0)\n-  BUILTIN_VQ_HSI (TERNOP, sqdmlsl2_n, 0)\n-\n-  BUILTIN_VD_BHSI (BINOP, intrinsic_vec_smult_lo_, 0)\n-  BUILTIN_VD_BHSI (BINOPU, intrinsic_vec_umult_lo_, 0)\n-\n-  BUILTIN_VQW (BINOP, vec_widen_smult_hi_, 10)\n-  BUILTIN_VQW (BINOPU, vec_widen_umult_hi_, 10)\n-\n-  BUILTIN_VD_HSI (TERNOP_LANE, vec_smult_lane_, 0)\n-  BUILTIN_VD_HSI (QUADOP_LANE, vec_smlal_lane_, 0)\n-  BUILTIN_VD_HSI (TERNOP_LANE, vec_smult_laneq_, 0)\n-  BUILTIN_VD_HSI (QUADOP_LANE, vec_smlal_laneq_, 0)\n-  BUILTIN_VD_HSI (TERNOPU_LANE, vec_umult_lane_, 0)\n-  BUILTIN_VD_HSI (QUADOPU_LANE, vec_umlal_lane_, 0)\n-  BUILTIN_VD_HSI (TERNOPU_LANE, vec_umult_laneq_, 0)\n-  BUILTIN_VD_HSI (QUADOPU_LANE, vec_umlal_laneq_, 0)\n-\n-  BUILTIN_VSD_HSI (BINOP, sqdmull, 0)\n-  BUILTIN_VSD_HSI (TERNOP_LANE, sqdmull_lane, 0)\n-  BUILTIN_VSD_HSI (TERNOP_LANE, sqdmull_laneq, 0)\n-  BUILTIN_VD_HSI (BINOP, sqdmull_n, 0)\n-  BUILTIN_VQ_HSI (BINOP, sqdmull2, 0)\n-  BUILTIN_VQ_HSI (TERNOP_LANE, sqdmull2_lane, 0)\n-  BUILTIN_VQ_HSI (TERNOP_LANE, sqdmull2_laneq, 0)\n-  BUILTIN_VQ_HSI (BINOP, sqdmull2_n, 0)\n+  BUILTIN_VD_HSI (TERNOP, sqdmlal_n, 0, ALL)\n+  BUILTIN_VD_HSI (TERNOP, sqdmlsl_n, 0, ALL)\n+\n+  BUILTIN_VQ_HSI (TERNOP, sqdmlal2, 0, ALL)\n+  BUILTIN_VQ_HSI (TERNOP, sqdmlsl2, 0, ALL)\n+  BUILTIN_VQ_HSI (QUADOP_LANE, sqdmlal2_lane, 0, ALL)\n+  BUILTIN_VQ_HSI (QUADOP_LANE, sqdmlsl2_lane, 0, ALL)\n+  BUILTIN_VQ_HSI (QUADOP_LANE, sqdmlal2_laneq, 0, ALL)\n+  BUILTIN_VQ_HSI (QUADOP_LANE, sqdmlsl2_laneq, 0, ALL)\n+  BUILTIN_VQ_HSI (TERNOP, sqdmlal2_n, 0, ALL)\n+  BUILTIN_VQ_HSI (TERNOP, sqdmlsl2_n, 0, ALL)\n+\n+  BUILTIN_VD_BHSI (BINOP, intrinsic_vec_smult_lo_, 0, ALL)\n+  BUILTIN_VD_BHSI (BINOPU, intrinsic_vec_umult_lo_, 0, ALL)\n+\n+  BUILTIN_VQW (BINOP, vec_widen_smult_hi_, 10, ALL)\n+  BUILTIN_VQW (BINOPU, vec_widen_umult_hi_, 10, ALL)\n+\n+  BUILTIN_VD_HSI (TERNOP_LANE, vec_smult_lane_, 0, ALL)\n+  BUILTIN_VD_HSI (QUADOP_LANE, vec_smlal_lane_, 0, ALL)\n+  BUILTIN_VD_HSI (TERNOP_LANE, vec_smult_laneq_, 0, ALL)\n+  BUILTIN_VD_HSI (QUADOP_LANE, vec_smlal_laneq_, 0, ALL)\n+  BUILTIN_VD_HSI (TERNOPU_LANE, vec_umult_lane_, 0, ALL)\n+  BUILTIN_VD_HSI (QUADOPU_LANE, vec_umlal_lane_, 0, ALL)\n+  BUILTIN_VD_HSI (TERNOPU_LANE, vec_umult_laneq_, 0, ALL)\n+  BUILTIN_VD_HSI (QUADOPU_LANE, vec_umlal_laneq_, 0, ALL)\n+\n+  BUILTIN_VSD_HSI (BINOP, sqdmull, 0, ALL)\n+  BUILTIN_VSD_HSI (TERNOP_LANE, sqdmull_lane, 0, ALL)\n+  BUILTIN_VSD_HSI (TERNOP_LANE, sqdmull_laneq, 0, ALL)\n+  BUILTIN_VD_HSI (BINOP, sqdmull_n, 0, ALL)\n+  BUILTIN_VQ_HSI (BINOP, sqdmull2, 0, ALL)\n+  BUILTIN_VQ_HSI (TERNOP_LANE, sqdmull2_lane, 0, ALL)\n+  BUILTIN_VQ_HSI (TERNOP_LANE, sqdmull2_laneq, 0, ALL)\n+  BUILTIN_VQ_HSI (BINOP, sqdmull2_n, 0, ALL)\n   /* Implemented by aarch64_sq<r>dmulh<mode>.  */\n-  BUILTIN_VSDQ_HSI (BINOP, sqdmulh, 0)\n-  BUILTIN_VSDQ_HSI (BINOP, sqrdmulh, 0)\n+  BUILTIN_VSDQ_HSI (BINOP, sqdmulh, 0, ALL)\n+  BUILTIN_VSDQ_HSI (BINOP, sqrdmulh, 0, ALL)\n   /* Implemented by aarch64_sq<r>dmulh_lane<q><mode>.  */\n-  BUILTIN_VSDQ_HSI (TERNOP_LANE, sqdmulh_lane, 0)\n-  BUILTIN_VSDQ_HSI (TERNOP_LANE, sqdmulh_laneq, 0)\n-  BUILTIN_VSDQ_HSI (TERNOP_LANE, sqrdmulh_lane, 0)\n-  BUILTIN_VSDQ_HSI (TERNOP_LANE, sqrdmulh_laneq, 0)\n+  BUILTIN_VSDQ_HSI (TERNOP_LANE, sqdmulh_lane, 0, ALL)\n+  BUILTIN_VSDQ_HSI (TERNOP_LANE, sqdmulh_laneq, 0, ALL)\n+  BUILTIN_VSDQ_HSI (TERNOP_LANE, sqrdmulh_lane, 0, ALL)\n+  BUILTIN_VSDQ_HSI (TERNOP_LANE, sqrdmulh_laneq, 0, ALL)\n \n-  BUILTIN_VSDQ_I_DI (BINOP, ashl, 3)\n+  BUILTIN_VSDQ_I_DI (BINOP, ashl, 3, ALL)\n   /* Implemented by aarch64_<sur>shl<mode>.  */\n-  BUILTIN_VSDQ_I_DI (BINOP, sshl, 0)\n-  BUILTIN_VSDQ_I_DI (BINOP_UUS, ushl, 0)\n-  BUILTIN_VSDQ_I_DI (BINOP, srshl, 0)\n-  BUILTIN_VSDQ_I_DI (BINOP_UUS, urshl, 0)\n+  BUILTIN_VSDQ_I_DI (BINOP, sshl, 0, ALL)\n+  BUILTIN_VSDQ_I_DI (BINOP_UUS, ushl, 0, ALL)\n+  BUILTIN_VSDQ_I_DI (BINOP, srshl, 0, ALL)\n+  BUILTIN_VSDQ_I_DI (BINOP_UUS, urshl, 0, ALL)\n \n   /* Implemented by aarch64_<sur><dotprod>{_lane}{q}<dot_mode>.  */\n-  BUILTIN_VB (TERNOP, sdot, 0)\n-  BUILTIN_VB (TERNOPU, udot, 0)\n-  BUILTIN_VB (TERNOP_SSUS, usdot, 0)\n-  BUILTIN_VB (QUADOP_LANE, sdot_lane, 0)\n-  BUILTIN_VB (QUADOPU_LANE, udot_lane, 0)\n-  BUILTIN_VB (QUADOP_LANE, sdot_laneq, 0)\n-  BUILTIN_VB (QUADOPU_LANE, udot_laneq, 0)\n-  BUILTIN_VB (QUADOPSSUS_LANE_QUADTUP, usdot_lane, 0)\n-  BUILTIN_VB (QUADOPSSUS_LANE_QUADTUP, usdot_laneq, 0)\n-  BUILTIN_VB (QUADOPSSSU_LANE_QUADTUP, sudot_lane, 0)\n-  BUILTIN_VB (QUADOPSSSU_LANE_QUADTUP, sudot_laneq, 0)\n+  BUILTIN_VB (TERNOP, sdot, 0, ALL)\n+  BUILTIN_VB (TERNOPU, udot, 0, ALL)\n+  BUILTIN_VB (TERNOP_SSUS, usdot, 0, ALL)\n+  BUILTIN_VB (QUADOP_LANE, sdot_lane, 0, ALL)\n+  BUILTIN_VB (QUADOPU_LANE, udot_lane, 0, ALL)\n+  BUILTIN_VB (QUADOP_LANE, sdot_laneq, 0, ALL)\n+  BUILTIN_VB (QUADOPU_LANE, udot_laneq, 0, ALL)\n+  BUILTIN_VB (QUADOPSSUS_LANE_QUADTUP, usdot_lane, 0, ALL)\n+  BUILTIN_VB (QUADOPSSUS_LANE_QUADTUP, usdot_laneq, 0, ALL)\n+  BUILTIN_VB (QUADOPSSSU_LANE_QUADTUP, sudot_lane, 0, ALL)\n+  BUILTIN_VB (QUADOPSSSU_LANE_QUADTUP, sudot_laneq, 0, ALL)\n \n   /* Implemented by aarch64_fcadd<rot><mode>.   */\n-  BUILTIN_VHSDF (BINOP, fcadd90, 0)\n-  BUILTIN_VHSDF (BINOP, fcadd270, 0)\n+  BUILTIN_VHSDF (BINOP, fcadd90, 0, ALL)\n+  BUILTIN_VHSDF (BINOP, fcadd270, 0, ALL)\n \n   /* Implemented by aarch64_fcmla{_lane}{q}<rot><mode>.   */\n-  BUILTIN_VHSDF (TERNOP, fcmla0, 0)\n-  BUILTIN_VHSDF (TERNOP, fcmla90, 0)\n-  BUILTIN_VHSDF (TERNOP, fcmla180, 0)\n-  BUILTIN_VHSDF (TERNOP, fcmla270, 0)\n-  BUILTIN_VHSDF (QUADOP_LANE_PAIR, fcmla_lane0, 0)\n-  BUILTIN_VHSDF (QUADOP_LANE_PAIR, fcmla_lane90, 0)\n-  BUILTIN_VHSDF (QUADOP_LANE_PAIR, fcmla_lane180, 0)\n-  BUILTIN_VHSDF (QUADOP_LANE_PAIR, fcmla_lane270, 0)\n-\n-  BUILTIN_VQ_HSF (QUADOP_LANE_PAIR, fcmlaq_lane0, 0)\n-  BUILTIN_VQ_HSF (QUADOP_LANE_PAIR, fcmlaq_lane90, 0)\n-  BUILTIN_VQ_HSF (QUADOP_LANE_PAIR, fcmlaq_lane180, 0)\n-  BUILTIN_VQ_HSF (QUADOP_LANE_PAIR, fcmlaq_lane270, 0)\n-\n-  BUILTIN_VDQ_I (SHIFTIMM, ashr, 3)\n-  VAR1 (SHIFTIMM, ashr_simd, 0, di)\n-  BUILTIN_VDQ_I (SHIFTIMM, lshr, 3)\n-  VAR1 (USHIFTIMM, lshr_simd, 0, di)\n+  BUILTIN_VHSDF (TERNOP, fcmla0, 0, ALL)\n+  BUILTIN_VHSDF (TERNOP, fcmla90, 0, ALL)\n+  BUILTIN_VHSDF (TERNOP, fcmla180, 0, ALL)\n+  BUILTIN_VHSDF (TERNOP, fcmla270, 0, ALL)\n+  BUILTIN_VHSDF (QUADOP_LANE_PAIR, fcmla_lane0, 0, ALL)\n+  BUILTIN_VHSDF (QUADOP_LANE_PAIR, fcmla_lane90, 0, ALL)\n+  BUILTIN_VHSDF (QUADOP_LANE_PAIR, fcmla_lane180, 0, ALL)\n+  BUILTIN_VHSDF (QUADOP_LANE_PAIR, fcmla_lane270, 0, ALL)\n+\n+  BUILTIN_VQ_HSF (QUADOP_LANE_PAIR, fcmlaq_lane0, 0, ALL)\n+  BUILTIN_VQ_HSF (QUADOP_LANE_PAIR, fcmlaq_lane90, 0, ALL)\n+  BUILTIN_VQ_HSF (QUADOP_LANE_PAIR, fcmlaq_lane180, 0, ALL)\n+  BUILTIN_VQ_HSF (QUADOP_LANE_PAIR, fcmlaq_lane270, 0, ALL)\n+\n+  BUILTIN_VDQ_I (SHIFTIMM, ashr, 3, ALL)\n+  VAR1 (SHIFTIMM, ashr_simd, 0, ALL, di)\n+  BUILTIN_VDQ_I (SHIFTIMM, lshr, 3, ALL)\n+  VAR1 (USHIFTIMM, lshr_simd, 0, ALL, di)\n   /* Implemented by aarch64_<sur>shr_n<mode>.  */\n-  BUILTIN_VSDQ_I_DI (SHIFTIMM, srshr_n, 0)\n-  BUILTIN_VSDQ_I_DI (USHIFTIMM, urshr_n, 0)\n+  BUILTIN_VSDQ_I_DI (SHIFTIMM, srshr_n, 0, ALL)\n+  BUILTIN_VSDQ_I_DI (USHIFTIMM, urshr_n, 0, ALL)\n   /* Implemented by aarch64_<sur>sra_n<mode>.  */\n-  BUILTIN_VSDQ_I_DI (SHIFTACC, ssra_n, 0)\n-  BUILTIN_VSDQ_I_DI (USHIFTACC, usra_n, 0)\n-  BUILTIN_VSDQ_I_DI (SHIFTACC, srsra_n, 0)\n-  BUILTIN_VSDQ_I_DI (USHIFTACC, ursra_n, 0)\n+  BUILTIN_VSDQ_I_DI (SHIFTACC, ssra_n, 0, ALL)\n+  BUILTIN_VSDQ_I_DI (USHIFTACC, usra_n, 0, ALL)\n+  BUILTIN_VSDQ_I_DI (SHIFTACC, srsra_n, 0, ALL)\n+  BUILTIN_VSDQ_I_DI (USHIFTACC, ursra_n, 0, ALL)\n   /* Implemented by aarch64_<sur>shll_n<mode>.  */\n-  BUILTIN_VD_BHSI (SHIFTIMM, sshll_n, 0)\n-  BUILTIN_VD_BHSI (USHIFTIMM, ushll_n, 0)\n+  BUILTIN_VD_BHSI (SHIFTIMM, sshll_n, 0, ALL)\n+  BUILTIN_VD_BHSI (USHIFTIMM, ushll_n, 0, ALL)\n   /* Implemented by aarch64_<sur>shll2_n<mode>.  */\n-  BUILTIN_VQW (SHIFTIMM, sshll2_n, 0)\n-  BUILTIN_VQW (SHIFTIMM, ushll2_n, 0)\n+  BUILTIN_VQW (SHIFTIMM, sshll2_n, 0, ALL)\n+  BUILTIN_VQW (SHIFTIMM, ushll2_n, 0, ALL)\n   /* Implemented by aarch64_<sur>q<r>shr<u>n_n<mode>.  */\n-  BUILTIN_VSQN_HSDI (SHIFTIMM, sqshrun_n, 0)\n-  BUILTIN_VSQN_HSDI (SHIFTIMM, sqrshrun_n, 0)\n-  BUILTIN_VSQN_HSDI (SHIFTIMM, sqshrn_n, 0)\n-  BUILTIN_VSQN_HSDI (USHIFTIMM, uqshrn_n, 0)\n-  BUILTIN_VSQN_HSDI (SHIFTIMM, sqrshrn_n, 0)\n-  BUILTIN_VSQN_HSDI (USHIFTIMM, uqrshrn_n, 0)\n+  BUILTIN_VSQN_HSDI (SHIFTIMM, sqshrun_n, 0, ALL)\n+  BUILTIN_VSQN_HSDI (SHIFTIMM, sqrshrun_n, 0, ALL)\n+  BUILTIN_VSQN_HSDI (SHIFTIMM, sqshrn_n, 0, ALL)\n+  BUILTIN_VSQN_HSDI (USHIFTIMM, uqshrn_n, 0, ALL)\n+  BUILTIN_VSQN_HSDI (SHIFTIMM, sqrshrn_n, 0, ALL)\n+  BUILTIN_VSQN_HSDI (USHIFTIMM, uqrshrn_n, 0, ALL)\n   /* Implemented by aarch64_<sur>s<lr>i_n<mode>.  */\n-  BUILTIN_VSDQ_I_DI (SHIFTINSERT, ssri_n, 0)\n-  BUILTIN_VSDQ_I_DI (USHIFTACC, usri_n, 0)\n-  BUILTIN_VSDQ_I_DI (SHIFTINSERT, ssli_n, 0)\n-  VAR2 (SHIFTINSERTP, ssli_n, 0, di, v2di)\n-  BUILTIN_VSDQ_I_DI (USHIFTACC, usli_n, 0)\n+  BUILTIN_VSDQ_I_DI (SHIFTINSERT, ssri_n, 0, ALL)\n+  BUILTIN_VSDQ_I_DI (USHIFTACC, usri_n, 0, ALL)\n+  BUILTIN_VSDQ_I_DI (SHIFTINSERT, ssli_n, 0, ALL)\n+  VAR2 (SHIFTINSERTP, ssli_n, 0, ALL, di, v2di)\n+  BUILTIN_VSDQ_I_DI (USHIFTACC, usli_n, 0, ALL)\n   /* Implemented by aarch64_<sur>qshl<u>_n<mode>.  */\n-  BUILTIN_VSDQ_I (SHIFTIMM_USS, sqshlu_n, 0)\n-  BUILTIN_VSDQ_I (SHIFTIMM, sqshl_n, 0)\n-  BUILTIN_VSDQ_I (USHIFTIMM, uqshl_n, 0)\n+  BUILTIN_VSDQ_I (SHIFTIMM_USS, sqshlu_n, 0, ALL)\n+  BUILTIN_VSDQ_I (SHIFTIMM, sqshl_n, 0, ALL)\n+  BUILTIN_VSDQ_I (USHIFTIMM, uqshl_n, 0, ALL)\n \n   /* Implemented by aarch64_reduc_plus_<mode>.  */\n-  BUILTIN_VALL (UNOP, reduc_plus_scal_, 10)\n+  BUILTIN_VALL (UNOP, reduc_plus_scal_, 10, ALL)\n \n   /* Implemented by reduc_<maxmin_uns>_scal_<mode> (producing scalar).  */\n-  BUILTIN_VDQIF_F16 (UNOP, reduc_smax_scal_, 10)\n-  BUILTIN_VDQIF_F16 (UNOP, reduc_smin_scal_, 10)\n-  BUILTIN_VDQ_BHSI (UNOPU, reduc_umax_scal_, 10)\n-  BUILTIN_VDQ_BHSI (UNOPU, reduc_umin_scal_, 10)\n-  BUILTIN_VHSDF (UNOP, reduc_smax_nan_scal_, 10)\n-  BUILTIN_VHSDF (UNOP, reduc_smin_nan_scal_, 10)\n+  BUILTIN_VDQIF_F16 (UNOP, reduc_smax_scal_, 10, ALL)\n+  BUILTIN_VDQIF_F16 (UNOP, reduc_smin_scal_, 10, ALL)\n+  BUILTIN_VDQ_BHSI (UNOPU, reduc_umax_scal_, 10, ALL)\n+  BUILTIN_VDQ_BHSI (UNOPU, reduc_umin_scal_, 10, ALL)\n+  BUILTIN_VHSDF (UNOP, reduc_smax_nan_scal_, 10, ALL)\n+  BUILTIN_VHSDF (UNOP, reduc_smin_nan_scal_, 10, ALL)\n \n   /* Implemented by <maxmin_uns><mode>3.\n      smax variants map to fmaxnm,\n      smax_nan variants map to fmax.  */\n-  BUILTIN_VDQ_BHSI (BINOP, smax, 3)\n-  BUILTIN_VDQ_BHSI (BINOP, smin, 3)\n-  BUILTIN_VDQ_BHSI (BINOP, umax, 3)\n-  BUILTIN_VDQ_BHSI (BINOP, umin, 3)\n-  BUILTIN_VHSDF_DF (BINOP, smax_nan, 3)\n-  BUILTIN_VHSDF_DF (BINOP, smin_nan, 3)\n+  BUILTIN_VDQ_BHSI (BINOP, smax, 3, ALL)\n+  BUILTIN_VDQ_BHSI (BINOP, smin, 3, ALL)\n+  BUILTIN_VDQ_BHSI (BINOP, umax, 3, ALL)\n+  BUILTIN_VDQ_BHSI (BINOP, umin, 3, ALL)\n+  BUILTIN_VHSDF_DF (BINOP, smax_nan, 3, ALL)\n+  BUILTIN_VHSDF_DF (BINOP, smin_nan, 3, ALL)\n \n   /* Implemented by <maxmin_uns><mode>3.  */\n-  BUILTIN_VHSDF_HSDF (BINOP, fmax, 3)\n-  BUILTIN_VHSDF_HSDF (BINOP, fmin, 3)\n+  BUILTIN_VHSDF_HSDF (BINOP, fmax, 3, ALL)\n+  BUILTIN_VHSDF_HSDF (BINOP, fmin, 3, ALL)\n \n   /* Implemented by aarch64_<maxmin_uns>p<mode>.  */\n-  BUILTIN_VDQ_BHSI (BINOP, smaxp, 0)\n-  BUILTIN_VDQ_BHSI (BINOP, sminp, 0)\n-  BUILTIN_VDQ_BHSI (BINOP, umaxp, 0)\n-  BUILTIN_VDQ_BHSI (BINOP, uminp, 0)\n-  BUILTIN_VHSDF (BINOP, smaxp, 0)\n-  BUILTIN_VHSDF (BINOP, sminp, 0)\n-  BUILTIN_VHSDF (BINOP, smax_nanp, 0)\n-  BUILTIN_VHSDF (BINOP, smin_nanp, 0)\n+  BUILTIN_VDQ_BHSI (BINOP, smaxp, 0, ALL)\n+  BUILTIN_VDQ_BHSI (BINOP, sminp, 0, ALL)\n+  BUILTIN_VDQ_BHSI (BINOP, umaxp, 0, ALL)\n+  BUILTIN_VDQ_BHSI (BINOP, uminp, 0, ALL)\n+  BUILTIN_VHSDF (BINOP, smaxp, 0, ALL)\n+  BUILTIN_VHSDF (BINOP, sminp, 0, ALL)\n+  BUILTIN_VHSDF (BINOP, smax_nanp, 0, ALL)\n+  BUILTIN_VHSDF (BINOP, smin_nanp, 0, ALL)\n \n   /* Implemented by <frint_pattern><mode>2.  */\n-  BUILTIN_VHSDF (UNOP, btrunc, 2)\n-  BUILTIN_VHSDF (UNOP, ceil, 2)\n-  BUILTIN_VHSDF (UNOP, floor, 2)\n-  BUILTIN_VHSDF (UNOP, nearbyint, 2)\n-  BUILTIN_VHSDF (UNOP, rint, 2)\n-  BUILTIN_VHSDF (UNOP, round, 2)\n-  BUILTIN_VHSDF_DF (UNOP, frintn, 2)\n-\n-  VAR1 (UNOP, btrunc, 2, hf)\n-  VAR1 (UNOP, ceil, 2, hf)\n-  VAR1 (UNOP, floor, 2, hf)\n-  VAR1 (UNOP, frintn, 2, hf)\n-  VAR1 (UNOP, nearbyint, 2, hf)\n-  VAR1 (UNOP, rint, 2, hf)\n-  VAR1 (UNOP, round, 2, hf)\n+  BUILTIN_VHSDF (UNOP, btrunc, 2, ALL)\n+  BUILTIN_VHSDF (UNOP, ceil, 2, ALL)\n+  BUILTIN_VHSDF (UNOP, floor, 2, ALL)\n+  BUILTIN_VHSDF (UNOP, nearbyint, 2, ALL)\n+  BUILTIN_VHSDF (UNOP, rint, 2, ALL)\n+  BUILTIN_VHSDF (UNOP, round, 2, ALL)\n+  BUILTIN_VHSDF_DF (UNOP, frintn, 2, ALL)\n+\n+  VAR1 (UNOP, btrunc, 2, ALL, hf)\n+  VAR1 (UNOP, ceil, 2, ALL, hf)\n+  VAR1 (UNOP, floor, 2, ALL, hf)\n+  VAR1 (UNOP, frintn, 2, ALL, hf)\n+  VAR1 (UNOP, nearbyint, 2, ALL, hf)\n+  VAR1 (UNOP, rint, 2, ALL, hf)\n+  VAR1 (UNOP, round, 2, ALL, hf)\n \n   /* Implemented by l<fcvt_pattern><su_optab><VQDF:mode><vcvt_target>2.  */\n-  VAR1 (UNOP, lbtruncv4hf, 2, v4hi)\n-  VAR1 (UNOP, lbtruncv8hf, 2, v8hi)\n-  VAR1 (UNOP, lbtruncv2sf, 2, v2si)\n-  VAR1 (UNOP, lbtruncv4sf, 2, v4si)\n-  VAR1 (UNOP, lbtruncv2df, 2, v2di)\n-\n-  VAR1 (UNOPUS, lbtruncuv4hf, 2, v4hi)\n-  VAR1 (UNOPUS, lbtruncuv8hf, 2, v8hi)\n-  VAR1 (UNOPUS, lbtruncuv2sf, 2, v2si)\n-  VAR1 (UNOPUS, lbtruncuv4sf, 2, v4si)\n-  VAR1 (UNOPUS, lbtruncuv2df, 2, v2di)\n-\n-  VAR1 (UNOP, lroundv4hf, 2, v4hi)\n-  VAR1 (UNOP, lroundv8hf, 2, v8hi)\n-  VAR1 (UNOP, lroundv2sf, 2, v2si)\n-  VAR1 (UNOP, lroundv4sf, 2, v4si)\n-  VAR1 (UNOP, lroundv2df, 2, v2di)\n+  VAR1 (UNOP, lbtruncv4hf, 2, ALL, v4hi)\n+  VAR1 (UNOP, lbtruncv8hf, 2, ALL, v8hi)\n+  VAR1 (UNOP, lbtruncv2sf, 2, ALL, v2si)\n+  VAR1 (UNOP, lbtruncv4sf, 2, ALL, v4si)\n+  VAR1 (UNOP, lbtruncv2df, 2, ALL, v2di)\n+\n+  VAR1 (UNOPUS, lbtruncuv4hf, 2, ALL, v4hi)\n+  VAR1 (UNOPUS, lbtruncuv8hf, 2, ALL, v8hi)\n+  VAR1 (UNOPUS, lbtruncuv2sf, 2, ALL, v2si)\n+  VAR1 (UNOPUS, lbtruncuv4sf, 2, ALL, v4si)\n+  VAR1 (UNOPUS, lbtruncuv2df, 2, ALL, v2di)\n+\n+  VAR1 (UNOP, lroundv4hf, 2, ALL, v4hi)\n+  VAR1 (UNOP, lroundv8hf, 2, ALL, v8hi)\n+  VAR1 (UNOP, lroundv2sf, 2, ALL, v2si)\n+  VAR1 (UNOP, lroundv4sf, 2, ALL, v4si)\n+  VAR1 (UNOP, lroundv2df, 2, ALL, v2di)\n   /* Implemented by l<fcvt_pattern><su_optab><GPF_F16:mode><GPI:mode>2.  */\n-  BUILTIN_GPI_I16 (UNOP, lroundhf, 2)\n-  VAR1 (UNOP, lroundsf, 2, si)\n-  VAR1 (UNOP, lrounddf, 2, di)\n-\n-  VAR1 (UNOPUS, lrounduv4hf, 2, v4hi)\n-  VAR1 (UNOPUS, lrounduv8hf, 2, v8hi)\n-  VAR1 (UNOPUS, lrounduv2sf, 2, v2si)\n-  VAR1 (UNOPUS, lrounduv4sf, 2, v4si)\n-  VAR1 (UNOPUS, lrounduv2df, 2, v2di)\n-  BUILTIN_GPI_I16 (UNOPUS, lrounduhf, 2)\n-  VAR1 (UNOPUS, lroundusf, 2, si)\n-  VAR1 (UNOPUS, lroundudf, 2, di)\n-\n-  VAR1 (UNOP, lceilv4hf, 2, v4hi)\n-  VAR1 (UNOP, lceilv8hf, 2, v8hi)\n-  VAR1 (UNOP, lceilv2sf, 2, v2si)\n-  VAR1 (UNOP, lceilv4sf, 2, v4si)\n-  VAR1 (UNOP, lceilv2df, 2, v2di)\n-  BUILTIN_GPI_I16 (UNOP, lceilhf, 2)\n-\n-  VAR1 (UNOPUS, lceiluv4hf, 2, v4hi)\n-  VAR1 (UNOPUS, lceiluv8hf, 2, v8hi)\n-  VAR1 (UNOPUS, lceiluv2sf, 2, v2si)\n-  VAR1 (UNOPUS, lceiluv4sf, 2, v4si)\n-  VAR1 (UNOPUS, lceiluv2df, 2, v2di)\n-  BUILTIN_GPI_I16 (UNOPUS, lceiluhf, 2)\n-  VAR1 (UNOPUS, lceilusf, 2, si)\n-  VAR1 (UNOPUS, lceiludf, 2, di)\n-\n-  VAR1 (UNOP, lfloorv4hf, 2, v4hi)\n-  VAR1 (UNOP, lfloorv8hf, 2, v8hi)\n-  VAR1 (UNOP, lfloorv2sf, 2, v2si)\n-  VAR1 (UNOP, lfloorv4sf, 2, v4si)\n-  VAR1 (UNOP, lfloorv2df, 2, v2di)\n-  BUILTIN_GPI_I16 (UNOP, lfloorhf, 2)\n-\n-  VAR1 (UNOPUS, lflooruv4hf, 2, v4hi)\n-  VAR1 (UNOPUS, lflooruv8hf, 2, v8hi)\n-  VAR1 (UNOPUS, lflooruv2sf, 2, v2si)\n-  VAR1 (UNOPUS, lflooruv4sf, 2, v4si)\n-  VAR1 (UNOPUS, lflooruv2df, 2, v2di)\n-  BUILTIN_GPI_I16 (UNOPUS, lflooruhf, 2)\n-  VAR1 (UNOPUS, lfloorusf, 2, si)\n-  VAR1 (UNOPUS, lfloorudf, 2, di)\n-\n-  VAR1 (UNOP, lfrintnv4hf, 2, v4hi)\n-  VAR1 (UNOP, lfrintnv8hf, 2, v8hi)\n-  VAR1 (UNOP, lfrintnv2sf, 2, v2si)\n-  VAR1 (UNOP, lfrintnv4sf, 2, v4si)\n-  VAR1 (UNOP, lfrintnv2df, 2, v2di)\n-  BUILTIN_GPI_I16 (UNOP, lfrintnhf, 2)\n-  VAR1 (UNOP, lfrintnsf, 2, si)\n-  VAR1 (UNOP, lfrintndf, 2, di)\n-\n-  VAR1 (UNOPUS, lfrintnuv4hf, 2, v4hi)\n-  VAR1 (UNOPUS, lfrintnuv8hf, 2, v8hi)\n-  VAR1 (UNOPUS, lfrintnuv2sf, 2, v2si)\n-  VAR1 (UNOPUS, lfrintnuv4sf, 2, v4si)\n-  VAR1 (UNOPUS, lfrintnuv2df, 2, v2di)\n-  BUILTIN_GPI_I16 (UNOPUS, lfrintnuhf, 2)\n-  VAR1 (UNOPUS, lfrintnusf, 2, si)\n-  VAR1 (UNOPUS, lfrintnudf, 2, di)\n+  BUILTIN_GPI_I16 (UNOP, lroundhf, 2, ALL)\n+  VAR1 (UNOP, lroundsf, 2, ALL, si)\n+  VAR1 (UNOP, lrounddf, 2, ALL, di)\n+\n+  VAR1 (UNOPUS, lrounduv4hf, 2, ALL, v4hi)\n+  VAR1 (UNOPUS, lrounduv8hf, 2, ALL, v8hi)\n+  VAR1 (UNOPUS, lrounduv2sf, 2, ALL, v2si)\n+  VAR1 (UNOPUS, lrounduv4sf, 2, ALL, v4si)\n+  VAR1 (UNOPUS, lrounduv2df, 2, ALL, v2di)\n+  BUILTIN_GPI_I16 (UNOPUS, lrounduhf, 2, ALL)\n+  VAR1 (UNOPUS, lroundusf, 2, ALL, si)\n+  VAR1 (UNOPUS, lroundudf, 2, ALL, di)\n+\n+  VAR1 (UNOP, lceilv4hf, 2, ALL, v4hi)\n+  VAR1 (UNOP, lceilv8hf, 2, ALL, v8hi)\n+  VAR1 (UNOP, lceilv2sf, 2, ALL, v2si)\n+  VAR1 (UNOP, lceilv4sf, 2, ALL, v4si)\n+  VAR1 (UNOP, lceilv2df, 2, ALL, v2di)\n+  BUILTIN_GPI_I16 (UNOP, lceilhf, 2, ALL)\n+\n+  VAR1 (UNOPUS, lceiluv4hf, 2, ALL, v4hi)\n+  VAR1 (UNOPUS, lceiluv8hf, 2, ALL, v8hi)\n+  VAR1 (UNOPUS, lceiluv2sf, 2, ALL, v2si)\n+  VAR1 (UNOPUS, lceiluv4sf, 2, ALL, v4si)\n+  VAR1 (UNOPUS, lceiluv2df, 2, ALL, v2di)\n+  BUILTIN_GPI_I16 (UNOPUS, lceiluhf, 2, ALL)\n+  VAR1 (UNOPUS, lceilusf, 2, ALL, si)\n+  VAR1 (UNOPUS, lceiludf, 2, ALL, di)\n+\n+  VAR1 (UNOP, lfloorv4hf, 2, ALL, v4hi)\n+  VAR1 (UNOP, lfloorv8hf, 2, ALL, v8hi)\n+  VAR1 (UNOP, lfloorv2sf, 2, ALL, v2si)\n+  VAR1 (UNOP, lfloorv4sf, 2, ALL, v4si)\n+  VAR1 (UNOP, lfloorv2df, 2, ALL, v2di)\n+  BUILTIN_GPI_I16 (UNOP, lfloorhf, 2, ALL)\n+\n+  VAR1 (UNOPUS, lflooruv4hf, 2, ALL, v4hi)\n+  VAR1 (UNOPUS, lflooruv8hf, 2, ALL, v8hi)\n+  VAR1 (UNOPUS, lflooruv2sf, 2, ALL, v2si)\n+  VAR1 (UNOPUS, lflooruv4sf, 2, ALL, v4si)\n+  VAR1 (UNOPUS, lflooruv2df, 2, ALL, v2di)\n+  BUILTIN_GPI_I16 (UNOPUS, lflooruhf, 2, ALL)\n+  VAR1 (UNOPUS, lfloorusf, 2, ALL, si)\n+  VAR1 (UNOPUS, lfloorudf, 2, ALL, di)\n+\n+  VAR1 (UNOP, lfrintnv4hf, 2, ALL, v4hi)\n+  VAR1 (UNOP, lfrintnv8hf, 2, ALL, v8hi)\n+  VAR1 (UNOP, lfrintnv2sf, 2, ALL, v2si)\n+  VAR1 (UNOP, lfrintnv4sf, 2, ALL, v4si)\n+  VAR1 (UNOP, lfrintnv2df, 2, ALL, v2di)\n+  BUILTIN_GPI_I16 (UNOP, lfrintnhf, 2, ALL)\n+  VAR1 (UNOP, lfrintnsf, 2, ALL, si)\n+  VAR1 (UNOP, lfrintndf, 2, ALL, di)\n+\n+  VAR1 (UNOPUS, lfrintnuv4hf, 2, ALL, v4hi)\n+  VAR1 (UNOPUS, lfrintnuv8hf, 2, ALL, v8hi)\n+  VAR1 (UNOPUS, lfrintnuv2sf, 2, ALL, v2si)\n+  VAR1 (UNOPUS, lfrintnuv4sf, 2, ALL, v4si)\n+  VAR1 (UNOPUS, lfrintnuv2df, 2, ALL, v2di)\n+  BUILTIN_GPI_I16 (UNOPUS, lfrintnuhf, 2, ALL)\n+  VAR1 (UNOPUS, lfrintnusf, 2, ALL, si)\n+  VAR1 (UNOPUS, lfrintnudf, 2, ALL, di)\n \n   /* Implemented by <optab><fcvt_target><VDQF:mode>2.  */\n-  VAR1 (UNOP, floatv4hi, 2, v4hf)\n-  VAR1 (UNOP, floatv8hi, 2, v8hf)\n-  VAR1 (UNOP, floatv2si, 2, v2sf)\n-  VAR1 (UNOP, floatv4si, 2, v4sf)\n-  VAR1 (UNOP, floatv2di, 2, v2df)\n+  VAR1 (UNOP, floatv4hi, 2, ALL, v4hf)\n+  VAR1 (UNOP, floatv8hi, 2, ALL, v8hf)\n+  VAR1 (UNOP, floatv2si, 2, ALL, v2sf)\n+  VAR1 (UNOP, floatv4si, 2, ALL, v4sf)\n+  VAR1 (UNOP, floatv2di, 2, ALL, v2df)\n \n-  VAR1 (UNOP, floatunsv4hi, 2, v4hf)\n-  VAR1 (UNOP, floatunsv8hi, 2, v8hf)\n-  VAR1 (UNOP, floatunsv2si, 2, v2sf)\n-  VAR1 (UNOP, floatunsv4si, 2, v4sf)\n-  VAR1 (UNOP, floatunsv2di, 2, v2df)\n+  VAR1 (UNOP, floatunsv4hi, 2, ALL, v4hf)\n+  VAR1 (UNOP, floatunsv8hi, 2, ALL, v8hf)\n+  VAR1 (UNOP, floatunsv2si, 2, ALL, v2sf)\n+  VAR1 (UNOP, floatunsv4si, 2, ALL, v4sf)\n+  VAR1 (UNOP, floatunsv2di, 2, ALL, v2df)\n \n-  VAR5 (UNOPU, bswap, 2, v4hi, v8hi, v2si, v4si, v2di)\n+  VAR5 (UNOPU, bswap, 2, ALL, v4hi, v8hi, v2si, v4si, v2di)\n \n-  BUILTIN_VB (UNOP, rbit, 0)\n+  BUILTIN_VB (UNOP, rbit, 0, ALL)\n \n   /* Implemented by\n      aarch64_<PERMUTE:perm_insn><mode>.  */\n-  BUILTIN_VALL (BINOP, zip1, 0)\n-  BUILTIN_VALL (BINOP, zip2, 0)\n-  BUILTIN_VALL (BINOP, uzp1, 0)\n-  BUILTIN_VALL (BINOP, uzp2, 0)\n-  BUILTIN_VALL (BINOP, trn1, 0)\n-  BUILTIN_VALL (BINOP, trn2, 0)\n+  BUILTIN_VALL (BINOP, zip1, 0, ALL)\n+  BUILTIN_VALL (BINOP, zip2, 0, ALL)\n+  BUILTIN_VALL (BINOP, uzp1, 0, ALL)\n+  BUILTIN_VALL (BINOP, uzp2, 0, ALL)\n+  BUILTIN_VALL (BINOP, trn1, 0, ALL)\n+  BUILTIN_VALL (BINOP, trn2, 0, ALL)\n \n-  BUILTIN_GPF_F16 (UNOP, frecpe, 0)\n-  BUILTIN_GPF_F16 (UNOP, frecpx, 0)\n+  BUILTIN_GPF_F16 (UNOP, frecpe, 0, ALL)\n+  BUILTIN_GPF_F16 (UNOP, frecpx, 0, ALL)\n \n-  BUILTIN_VDQ_SI (UNOP, urecpe, 0)\n+  BUILTIN_VDQ_SI (UNOP, urecpe, 0, ALL)\n \n-  BUILTIN_VHSDF (UNOP, frecpe, 0)\n-  BUILTIN_VHSDF_HSDF (BINOP, frecps, 0)\n+  BUILTIN_VHSDF (UNOP, frecpe, 0, ALL)\n+  BUILTIN_VHSDF_HSDF (BINOP, frecps, 0, ALL)\n \n   /* Implemented by a mixture of abs2 patterns.  Note the DImode builtin is\n      only ever used for the int64x1_t intrinsic, there is no scalar version.  */\n-  BUILTIN_VSDQ_I_DI (UNOP, abs, 0)\n-  BUILTIN_VHSDF (UNOP, abs, 2)\n-  VAR1 (UNOP, abs, 2, hf)\n+  BUILTIN_VSDQ_I_DI (UNOP, abs, 0, ALL)\n+  BUILTIN_VHSDF (UNOP, abs, 2, ALL)\n+  VAR1 (UNOP, abs, 2, ALL, hf)\n \n-  BUILTIN_VQ_HSF (UNOP, vec_unpacks_hi_, 10)\n-  VAR1 (BINOP, float_truncate_hi_, 0, v4sf)\n-  VAR1 (BINOP, float_truncate_hi_, 0, v8hf)\n+  BUILTIN_VQ_HSF (UNOP, vec_unpacks_hi_, 10, ALL)\n+  VAR1 (BINOP, float_truncate_hi_, 0, ALL, v4sf)\n+  VAR1 (BINOP, float_truncate_hi_, 0, ALL, v8hf)\n \n-  VAR1 (UNOP, float_extend_lo_, 0, v2df)\n-  VAR1 (UNOP, float_extend_lo_,  0, v4sf)\n-  BUILTIN_VDF (UNOP, float_truncate_lo_, 0)\n+  VAR1 (UNOP, float_extend_lo_, 0, ALL, v2df)\n+  VAR1 (UNOP, float_extend_lo_,  0, ALL, v4sf)\n+  BUILTIN_VDF (UNOP, float_truncate_lo_, 0, ALL)\n \n   /* Implemented by aarch64_ld1<VALL_F16:mode>.  */\n-  BUILTIN_VALL_F16 (LOAD1, ld1, 0)\n-  VAR1(STORE1P, ld1, 0, v2di)\n+  BUILTIN_VALL_F16 (LOAD1, ld1, 0, ALL)\n+  VAR1(STORE1P, ld1, 0, ALL, v2di)\n \n   /* Implemented by aarch64_st1<VALL_F16:mode>.  */\n-  BUILTIN_VALL_F16 (STORE1, st1, 0)\n-  VAR1(STORE1P, st1, 0, v2di)\n+  BUILTIN_VALL_F16 (STORE1, st1, 0, ALL)\n+  VAR1(STORE1P, st1, 0, ALL, v2di)\n \n   /* Implemented by aarch64_ld1x3<VALLDIF:mode>.  */\n-  BUILTIN_VALLDIF (LOADSTRUCT, ld1x3, 0)\n+  BUILTIN_VALLDIF (LOADSTRUCT, ld1x3, 0, ALL)\n \n   /* Implemented by aarch64_ld1x4<VALLDIF:mode>.  */\n-  BUILTIN_VALLDIF (LOADSTRUCT, ld1x4, 0)\n+  BUILTIN_VALLDIF (LOADSTRUCT, ld1x4, 0, ALL)\n \n   /* Implemented by aarch64_st1x2<VALLDIF:mode>.  */\n-  BUILTIN_VALLDIF (STORESTRUCT, st1x2, 0)\n+  BUILTIN_VALLDIF (STORESTRUCT, st1x2, 0, ALL)\n \n   /* Implemented by aarch64_st1x3<VALLDIF:mode>.  */\n-  BUILTIN_VALLDIF (STORESTRUCT, st1x3, 0)\n+  BUILTIN_VALLDIF (STORESTRUCT, st1x3, 0, ALL)\n \n   /* Implemented by aarch64_st1x4<VALLDIF:mode>.  */\n-  BUILTIN_VALLDIF (STORESTRUCT, st1x4, 0)\n+  BUILTIN_VALLDIF (STORESTRUCT, st1x4, 0, ALL)\n \n   /* Implemented by fma<mode>4.  */\n-  BUILTIN_VHSDF (TERNOP, fma, 4)\n-  VAR1 (TERNOP, fma, 4, hf)\n+  BUILTIN_VHSDF (TERNOP, fma, 4, ALL)\n+  VAR1 (TERNOP, fma, 4, ALL, hf)\n   /* Implemented by fnma<mode>4.  */\n-  BUILTIN_VHSDF (TERNOP, fnma, 4)\n-  VAR1 (TERNOP, fnma, 4, hf)\n+  BUILTIN_VHSDF (TERNOP, fnma, 4, ALL)\n+  VAR1 (TERNOP, fnma, 4, ALL, hf)\n \n   /* Implemented by aarch64_simd_bsl<mode>.  */\n-  BUILTIN_VDQQH (BSL_P, simd_bsl, 0)\n-  VAR2 (BSL_P, simd_bsl,0, di, v2di)\n-  BUILTIN_VSDQ_I_DI (BSL_U, simd_bsl, 0)\n-  BUILTIN_VALLDIF (BSL_S, simd_bsl, 0)\n+  BUILTIN_VDQQH (BSL_P, simd_bsl, 0, ALL)\n+  VAR2 (BSL_P, simd_bsl,0, ALL, di, v2di)\n+  BUILTIN_VSDQ_I_DI (BSL_U, simd_bsl, 0, ALL)\n+  BUILTIN_VALLDIF (BSL_S, simd_bsl, 0, ALL)\n \n   /* Implemented by aarch64_crypto_aes<op><mode>.  */\n-  VAR1 (BINOPU, crypto_aese, 0, v16qi)\n-  VAR1 (BINOPU, crypto_aesd, 0, v16qi)\n-  VAR1 (UNOPU, crypto_aesmc, 0, v16qi)\n-  VAR1 (UNOPU, crypto_aesimc, 0, v16qi)\n+  VAR1 (BINOPU, crypto_aese, 0, ALL, v16qi)\n+  VAR1 (BINOPU, crypto_aesd, 0, ALL, v16qi)\n+  VAR1 (UNOPU, crypto_aesmc, 0, ALL, v16qi)\n+  VAR1 (UNOPU, crypto_aesimc, 0, ALL, v16qi)\n \n   /* Implemented by aarch64_crypto_sha1<op><mode>.  */\n-  VAR1 (UNOPU, crypto_sha1h, 0, si)\n-  VAR1 (BINOPU, crypto_sha1su1, 0, v4si)\n-  VAR1 (TERNOPU, crypto_sha1c, 0, v4si)\n-  VAR1 (TERNOPU, crypto_sha1m, 0, v4si)\n-  VAR1 (TERNOPU, crypto_sha1p, 0, v4si)\n-  VAR1 (TERNOPU, crypto_sha1su0, 0, v4si)\n+  VAR1 (UNOPU, crypto_sha1h, 0, ALL, si)\n+  VAR1 (BINOPU, crypto_sha1su1, 0, ALL, v4si)\n+  VAR1 (TERNOPU, crypto_sha1c, 0, ALL, v4si)\n+  VAR1 (TERNOPU, crypto_sha1m, 0, ALL, v4si)\n+  VAR1 (TERNOPU, crypto_sha1p, 0, ALL, v4si)\n+  VAR1 (TERNOPU, crypto_sha1su0, 0, ALL, v4si)\n \n   /* Implemented by aarch64_crypto_sha256<op><mode>.  */\n-  VAR1 (TERNOPU, crypto_sha256h, 0, v4si)\n-  VAR1 (TERNOPU, crypto_sha256h2, 0, v4si)\n-  VAR1 (BINOPU, crypto_sha256su0, 0, v4si)\n-  VAR1 (TERNOPU, crypto_sha256su1, 0, v4si)\n+  VAR1 (TERNOPU, crypto_sha256h, 0, ALL, v4si)\n+  VAR1 (TERNOPU, crypto_sha256h2, 0, ALL, v4si)\n+  VAR1 (BINOPU, crypto_sha256su0, 0, ALL, v4si)\n+  VAR1 (TERNOPU, crypto_sha256su1, 0, ALL, v4si)\n \n   /* Implemented by aarch64_crypto_pmull<mode>.  */\n-  VAR1 (BINOPP, crypto_pmull, 0, di)\n-  VAR1 (BINOPP, crypto_pmull, 0, v2di)\n+  VAR1 (BINOPP, crypto_pmull, 0, ALL, di)\n+  VAR1 (BINOPP, crypto_pmull, 0, ALL, v2di)\n \n   /* Implemented by aarch64_tbl3<mode>.  */\n-  VAR1 (BINOP, tbl3, 0, v8qi)\n-  VAR1 (BINOP, tbl3, 0, v16qi)\n+  VAR1 (BINOP, tbl3, 0, ALL, v8qi)\n+  VAR1 (BINOP, tbl3, 0, ALL, v16qi)\n \n   /* Implemented by aarch64_qtbl3<mode>.  */\n-  VAR1 (BINOP, qtbl3, 0, v8qi)\n-  VAR1 (BINOP, qtbl3, 0, v16qi)\n+  VAR1 (BINOP, qtbl3, 0, ALL, v8qi)\n+  VAR1 (BINOP, qtbl3, 0, ALL, v16qi)\n \n   /* Implemented by aarch64_qtbl4<mode>.  */\n-  VAR1 (BINOP, qtbl4, 0, v8qi)\n-  VAR1 (BINOP, qtbl4, 0, v16qi)\n+  VAR1 (BINOP, qtbl4, 0, ALL, v8qi)\n+  VAR1 (BINOP, qtbl4, 0, ALL, v16qi)\n \n   /* Implemented by aarch64_tbx4<mode>.  */\n-  VAR1 (TERNOP, tbx4, 0, v8qi)\n-  VAR1 (TERNOP, tbx4, 0, v16qi)\n+  VAR1 (TERNOP, tbx4, 0, ALL, v8qi)\n+  VAR1 (TERNOP, tbx4, 0, ALL, v16qi)\n \n   /* Implemented by aarch64_qtbx3<mode>.  */\n-  VAR1 (TERNOP, qtbx3, 0, v8qi)\n-  VAR1 (TERNOP, qtbx3, 0, v16qi)\n+  VAR1 (TERNOP, qtbx3, 0, ALL, v8qi)\n+  VAR1 (TERNOP, qtbx3, 0, ALL, v16qi)\n \n   /* Implemented by aarch64_qtbx4<mode>.  */\n-  VAR1 (TERNOP, qtbx4, 0, v8qi)\n-  VAR1 (TERNOP, qtbx4, 0, v16qi)\n+  VAR1 (TERNOP, qtbx4, 0, ALL, v8qi)\n+  VAR1 (TERNOP, qtbx4, 0, ALL, v16qi)\n \n   /* Builtins for ARMv8.1-A Adv.SIMD instructions.  */\n \n   /* Implemented by aarch64_sqrdml<SQRDMLH_AS:rdma_as>h<mode>.  */\n-  BUILTIN_VSDQ_HSI (TERNOP, sqrdmlah, 0)\n-  BUILTIN_VSDQ_HSI (TERNOP, sqrdmlsh, 0)\n+  BUILTIN_VSDQ_HSI (TERNOP, sqrdmlah, 0, ALL)\n+  BUILTIN_VSDQ_HSI (TERNOP, sqrdmlsh, 0, ALL)\n \n   /* Implemented by aarch64_sqrdml<SQRDMLH_AS:rdma_as>h_lane<mode>.  */\n-  BUILTIN_VSDQ_HSI (QUADOP_LANE, sqrdmlah_lane, 0)\n-  BUILTIN_VSDQ_HSI (QUADOP_LANE, sqrdmlsh_lane, 0)\n+  BUILTIN_VSDQ_HSI (QUADOP_LANE, sqrdmlah_lane, 0, ALL)\n+  BUILTIN_VSDQ_HSI (QUADOP_LANE, sqrdmlsh_lane, 0, ALL)\n \n   /* Implemented by aarch64_sqrdml<SQRDMLH_AS:rdma_as>h_laneq<mode>.  */\n-  BUILTIN_VSDQ_HSI (QUADOP_LANE, sqrdmlah_laneq, 0)\n-  BUILTIN_VSDQ_HSI (QUADOP_LANE, sqrdmlsh_laneq, 0)\n+  BUILTIN_VSDQ_HSI (QUADOP_LANE, sqrdmlah_laneq, 0, ALL)\n+  BUILTIN_VSDQ_HSI (QUADOP_LANE, sqrdmlsh_laneq, 0, ALL)\n \n   /* Implemented by <FCVT_F2FIXED/FIXED2F:fcvt_fixed_insn><*><*>3.  */\n-  BUILTIN_VSDQ_HSDI (SHIFTIMM, scvtf, 3)\n-  BUILTIN_VSDQ_HSDI (FCVTIMM_SUS, ucvtf, 3)\n-  BUILTIN_VHSDF_HSDF (SHIFTIMM, fcvtzs, 3)\n-  BUILTIN_VHSDF_HSDF (SHIFTIMM_USS, fcvtzu, 3)\n-  VAR1 (SHIFTIMM, scvtfsi, 3, hf)\n-  VAR1 (SHIFTIMM, scvtfdi, 3, hf)\n-  VAR1 (FCVTIMM_SUS, ucvtfsi, 3, hf)\n-  VAR1 (FCVTIMM_SUS, ucvtfdi, 3, hf)\n-  BUILTIN_GPI (SHIFTIMM, fcvtzshf, 3)\n-  BUILTIN_GPI (SHIFTIMM_USS, fcvtzuhf, 3)\n+  BUILTIN_VSDQ_HSDI (SHIFTIMM, scvtf, 3, ALL)\n+  BUILTIN_VSDQ_HSDI (FCVTIMM_SUS, ucvtf, 3, ALL)\n+  BUILTIN_VHSDF_HSDF (SHIFTIMM, fcvtzs, 3, ALL)\n+  BUILTIN_VHSDF_HSDF (SHIFTIMM_USS, fcvtzu, 3, ALL)\n+  VAR1 (SHIFTIMM, scvtfsi, 3, ALL, hf)\n+  VAR1 (SHIFTIMM, scvtfdi, 3, ALL, hf)\n+  VAR1 (FCVTIMM_SUS, ucvtfsi, 3, ALL, hf)\n+  VAR1 (FCVTIMM_SUS, ucvtfdi, 3, ALL, hf)\n+  BUILTIN_GPI (SHIFTIMM, fcvtzshf, 3, ALL)\n+  BUILTIN_GPI (SHIFTIMM_USS, fcvtzuhf, 3, ALL)\n \n   /* Implemented by aarch64_rsqrte<mode>.  */\n-  BUILTIN_VHSDF_HSDF (UNOP, rsqrte, 0)\n+  BUILTIN_VHSDF_HSDF (UNOP, rsqrte, 0, ALL)\n \n   /* Implemented by aarch64_rsqrts<mode>.  */\n-  BUILTIN_VHSDF_HSDF (BINOP, rsqrts, 0)\n+  BUILTIN_VHSDF_HSDF (BINOP, rsqrts, 0, ALL)\n \n   /* Implemented by fabd<mode>3.  */\n-  BUILTIN_VHSDF_HSDF (BINOP, fabd, 3)\n+  BUILTIN_VHSDF_HSDF (BINOP, fabd, 3, ALL)\n \n   /* Implemented by aarch64_faddp<mode>.  */\n-  BUILTIN_VHSDF (BINOP, faddp, 0)\n+  BUILTIN_VHSDF (BINOP, faddp, 0, ALL)\n \n   /* Implemented by aarch64_cm<optab><mode>.  */\n-  BUILTIN_VHSDF_HSDF (BINOP_USS, cmeq, 0)\n-  BUILTIN_VHSDF_HSDF (BINOP_USS, cmge, 0)\n-  BUILTIN_VHSDF_HSDF (BINOP_USS, cmgt, 0)\n-  BUILTIN_VHSDF_HSDF (BINOP_USS, cmle, 0)\n-  BUILTIN_VHSDF_HSDF (BINOP_USS, cmlt, 0)\n+  BUILTIN_VHSDF_HSDF (BINOP_USS, cmeq, 0, ALL)\n+  BUILTIN_VHSDF_HSDF (BINOP_USS, cmge, 0, ALL)\n+  BUILTIN_VHSDF_HSDF (BINOP_USS, cmgt, 0, ALL)\n+  BUILTIN_VHSDF_HSDF (BINOP_USS, cmle, 0, ALL)\n+  BUILTIN_VHSDF_HSDF (BINOP_USS, cmlt, 0, ALL)\n \n   /* Implemented by neg<mode>2.  */\n-  BUILTIN_VHSDF_HSDF (UNOP, neg, 2)\n+  BUILTIN_VHSDF_HSDF (UNOP, neg, 2, ALL)\n \n   /* Implemented by aarch64_fac<optab><mode>.  */\n-  BUILTIN_VHSDF_HSDF (BINOP_USS, faclt, 0)\n-  BUILTIN_VHSDF_HSDF (BINOP_USS, facle, 0)\n-  BUILTIN_VHSDF_HSDF (BINOP_USS, facgt, 0)\n-  BUILTIN_VHSDF_HSDF (BINOP_USS, facge, 0)\n+  BUILTIN_VHSDF_HSDF (BINOP_USS, faclt, 0, ALL)\n+  BUILTIN_VHSDF_HSDF (BINOP_USS, facle, 0, ALL)\n+  BUILTIN_VHSDF_HSDF (BINOP_USS, facgt, 0, ALL)\n+  BUILTIN_VHSDF_HSDF (BINOP_USS, facge, 0, ALL)\n \n   /* Implemented by sqrt<mode>2.  */\n-  VAR1 (UNOP, sqrt, 2, hf)\n+  VAR1 (UNOP, sqrt, 2, ALL, hf)\n \n   /* Implemented by <optab><mode>hf2.  */\n-  VAR1 (UNOP, floatdi, 2, hf)\n-  VAR1 (UNOP, floatsi, 2, hf)\n-  VAR1 (UNOP, floathi, 2, hf)\n-  VAR1 (UNOPUS, floatunsdi, 2, hf)\n-  VAR1 (UNOPUS, floatunssi, 2, hf)\n-  VAR1 (UNOPUS, floatunshi, 2, hf)\n-  BUILTIN_GPI_I16 (UNOP, fix_trunchf, 2)\n-  BUILTIN_GPI (UNOP, fix_truncsf, 2)\n-  BUILTIN_GPI (UNOP, fix_truncdf, 2)\n-  BUILTIN_GPI_I16 (UNOPUS, fixuns_trunchf, 2)\n-  BUILTIN_GPI (UNOPUS, fixuns_truncsf, 2)\n-  BUILTIN_GPI (UNOPUS, fixuns_truncdf, 2)\n+  VAR1 (UNOP, floatdi, 2, ALL, hf)\n+  VAR1 (UNOP, floatsi, 2, ALL, hf)\n+  VAR1 (UNOP, floathi, 2, ALL, hf)\n+  VAR1 (UNOPUS, floatunsdi, 2, ALL, hf)\n+  VAR1 (UNOPUS, floatunssi, 2, ALL, hf)\n+  VAR1 (UNOPUS, floatunshi, 2, ALL, hf)\n+  BUILTIN_GPI_I16 (UNOP, fix_trunchf, 2, ALL)\n+  BUILTIN_GPI (UNOP, fix_truncsf, 2, ALL)\n+  BUILTIN_GPI (UNOP, fix_truncdf, 2, ALL)\n+  BUILTIN_GPI_I16 (UNOPUS, fixuns_trunchf, 2, ALL)\n+  BUILTIN_GPI (UNOPUS, fixuns_truncsf, 2, ALL)\n+  BUILTIN_GPI (UNOPUS, fixuns_truncdf, 2, ALL)\n \n   /* Implemented by aarch64_sm3ss1qv4si.  */\n-  VAR1 (TERNOPU, sm3ss1q, 0, v4si)\n+  VAR1 (TERNOPU, sm3ss1q, 0, ALL, v4si)\n   /* Implemented by aarch64_sm3tt<sm3tt_op>qv4si.  */\n-  VAR1 (QUADOPUI, sm3tt1aq, 0, v4si)\n-  VAR1 (QUADOPUI, sm3tt1bq, 0, v4si)\n-  VAR1 (QUADOPUI, sm3tt2aq, 0, v4si)\n-  VAR1 (QUADOPUI, sm3tt2bq, 0, v4si)\n+  VAR1 (QUADOPUI, sm3tt1aq, 0, ALL, v4si)\n+  VAR1 (QUADOPUI, sm3tt1bq, 0, ALL, v4si)\n+  VAR1 (QUADOPUI, sm3tt2aq, 0, ALL, v4si)\n+  VAR1 (QUADOPUI, sm3tt2bq, 0, ALL, v4si)\n   /* Implemented by aarch64_sm3partw<sm3part_op>qv4si.  */\n-  VAR1 (TERNOPU, sm3partw1q, 0, v4si)\n-  VAR1 (TERNOPU, sm3partw2q, 0, v4si)\n+  VAR1 (TERNOPU, sm3partw1q, 0, ALL, v4si)\n+  VAR1 (TERNOPU, sm3partw2q, 0, ALL, v4si)\n   /* Implemented by aarch64_sm4eqv4si.  */\n-  VAR1 (BINOPU, sm4eq, 0, v4si)\n+  VAR1 (BINOPU, sm4eq, 0, ALL, v4si)\n   /* Implemented by aarch64_sm4ekeyqv4si.  */\n-  VAR1 (BINOPU, sm4ekeyq, 0, v4si)\n+  VAR1 (BINOPU, sm4ekeyq, 0, ALL, v4si)\n   /* Implemented by aarch64_crypto_sha512hqv2di.  */\n-  VAR1 (TERNOPU, crypto_sha512hq, 0, v2di)\n+  VAR1 (TERNOPU, crypto_sha512hq, 0, ALL, v2di)\n   /* Implemented by aarch64_sha512h2qv2di.  */\n-  VAR1 (TERNOPU, crypto_sha512h2q, 0, v2di)\n+  VAR1 (TERNOPU, crypto_sha512h2q, 0, ALL, v2di)\n   /* Implemented by aarch64_crypto_sha512su0qv2di.  */\n-  VAR1 (BINOPU, crypto_sha512su0q, 0, v2di)\n+  VAR1 (BINOPU, crypto_sha512su0q, 0, ALL, v2di)\n   /* Implemented by aarch64_crypto_sha512su1qv2di.  */\n-  VAR1 (TERNOPU, crypto_sha512su1q, 0, v2di)\n+  VAR1 (TERNOPU, crypto_sha512su1q, 0, ALL, v2di)\n   /* Implemented by eor3q<mode>4.  */\n-  BUILTIN_VQ_I (TERNOPU, eor3q, 4)\n-  BUILTIN_VQ_I (TERNOP, eor3q, 4)\n+  BUILTIN_VQ_I (TERNOPU, eor3q, 4, ALL)\n+  BUILTIN_VQ_I (TERNOP, eor3q, 4, ALL)\n   /* Implemented by aarch64_rax1qv2di.  */\n-  VAR1 (BINOPU, rax1q, 0, v2di)\n+  VAR1 (BINOPU, rax1q, 0, ALL, v2di)\n   /* Implemented by aarch64_xarqv2di.  */\n-  VAR1 (TERNOPUI, xarq, 0, v2di)\n+  VAR1 (TERNOPUI, xarq, 0, ALL, v2di)\n   /* Implemented by bcaxq<mode>4.  */\n-  BUILTIN_VQ_I (TERNOPU, bcaxq, 4)\n-  BUILTIN_VQ_I (TERNOP, bcaxq, 4)\n+  BUILTIN_VQ_I (TERNOPU, bcaxq, 4, ALL)\n+  BUILTIN_VQ_I (TERNOP, bcaxq, 4, ALL)\n \n   /* Implemented by aarch64_fml<f16mac1>l<f16quad>_low<mode>.  */\n-  VAR1 (TERNOP, fmlal_low, 0, v2sf)\n-  VAR1 (TERNOP, fmlsl_low, 0, v2sf)\n-  VAR1 (TERNOP, fmlalq_low, 0, v4sf)\n-  VAR1 (TERNOP, fmlslq_low, 0, v4sf)\n+  VAR1 (TERNOP, fmlal_low, 0, ALL, v2sf)\n+  VAR1 (TERNOP, fmlsl_low, 0, ALL, v2sf)\n+  VAR1 (TERNOP, fmlalq_low, 0, ALL, v4sf)\n+  VAR1 (TERNOP, fmlslq_low, 0, ALL, v4sf)\n   /* Implemented by aarch64_fml<f16mac1>l<f16quad>_high<mode>.  */\n-  VAR1 (TERNOP, fmlal_high, 0, v2sf)\n-  VAR1 (TERNOP, fmlsl_high, 0, v2sf)\n-  VAR1 (TERNOP, fmlalq_high, 0, v4sf)\n-  VAR1 (TERNOP, fmlslq_high, 0, v4sf)\n+  VAR1 (TERNOP, fmlal_high, 0, ALL, v2sf)\n+  VAR1 (TERNOP, fmlsl_high, 0, ALL, v2sf)\n+  VAR1 (TERNOP, fmlalq_high, 0, ALL, v4sf)\n+  VAR1 (TERNOP, fmlslq_high, 0, ALL, v4sf)\n   /* Implemented by aarch64_fml<f16mac1>l_lane_lowv2sf.  */\n-  VAR1 (QUADOP_LANE, fmlal_lane_low, 0, v2sf)\n-  VAR1 (QUADOP_LANE, fmlsl_lane_low, 0, v2sf)\n+  VAR1 (QUADOP_LANE, fmlal_lane_low, 0, ALL, v2sf)\n+  VAR1 (QUADOP_LANE, fmlsl_lane_low, 0, ALL, v2sf)\n   /* Implemented by aarch64_fml<f16mac1>l_laneq_lowv2sf.  */\n-  VAR1 (QUADOP_LANE, fmlal_laneq_low, 0, v2sf)\n-  VAR1 (QUADOP_LANE, fmlsl_laneq_low, 0, v2sf)\n+  VAR1 (QUADOP_LANE, fmlal_laneq_low, 0, ALL, v2sf)\n+  VAR1 (QUADOP_LANE, fmlsl_laneq_low, 0, ALL, v2sf)\n   /* Implemented by aarch64_fml<f16mac1>lq_lane_lowv4sf.  */\n-  VAR1 (QUADOP_LANE, fmlalq_lane_low, 0, v4sf)\n-  VAR1 (QUADOP_LANE, fmlslq_lane_low, 0, v4sf)\n+  VAR1 (QUADOP_LANE, fmlalq_lane_low, 0, ALL, v4sf)\n+  VAR1 (QUADOP_LANE, fmlslq_lane_low, 0, ALL, v4sf)\n   /* Implemented by aarch64_fml<f16mac1>lq_laneq_lowv4sf.  */\n-  VAR1 (QUADOP_LANE, fmlalq_laneq_low, 0, v4sf)\n-  VAR1 (QUADOP_LANE, fmlslq_laneq_low, 0, v4sf)\n+  VAR1 (QUADOP_LANE, fmlalq_laneq_low, 0, ALL, v4sf)\n+  VAR1 (QUADOP_LANE, fmlslq_laneq_low, 0, ALL, v4sf)\n   /* Implemented by aarch64_fml<f16mac1>l_lane_highv2sf.  */\n-  VAR1 (QUADOP_LANE, fmlal_lane_high, 0, v2sf)\n-  VAR1 (QUADOP_LANE, fmlsl_lane_high, 0, v2sf)\n+  VAR1 (QUADOP_LANE, fmlal_lane_high, 0, ALL, v2sf)\n+  VAR1 (QUADOP_LANE, fmlsl_lane_high, 0, ALL, v2sf)\n   /* Implemented by aarch64_fml<f16mac1>l_laneq_highv2sf.  */\n-  VAR1 (QUADOP_LANE, fmlal_laneq_high, 0, v2sf)\n-  VAR1 (QUADOP_LANE, fmlsl_laneq_high, 0, v2sf)\n+  VAR1 (QUADOP_LANE, fmlal_laneq_high, 0, ALL, v2sf)\n+  VAR1 (QUADOP_LANE, fmlsl_laneq_high, 0, ALL, v2sf)\n   /* Implemented by aarch64_fml<f16mac1>lq_lane_highv4sf.  */\n-  VAR1 (QUADOP_LANE, fmlalq_lane_high, 0, v4sf)\n-  VAR1 (QUADOP_LANE, fmlslq_lane_high, 0, v4sf)\n+  VAR1 (QUADOP_LANE, fmlalq_lane_high, 0, ALL, v4sf)\n+  VAR1 (QUADOP_LANE, fmlslq_lane_high, 0, ALL, v4sf)\n   /* Implemented by aarch64_fml<f16mac1>lq_laneq_highv4sf.  */\n-  VAR1 (QUADOP_LANE, fmlalq_laneq_high, 0, v4sf)\n-  VAR1 (QUADOP_LANE, fmlslq_laneq_high, 0, v4sf)\n+  VAR1 (QUADOP_LANE, fmlalq_laneq_high, 0, ALL, v4sf)\n+  VAR1 (QUADOP_LANE, fmlslq_laneq_high, 0, ALL, v4sf)\n \n   /* Implemented by aarch64_<frintnzs_op><mode>.  */\n-  BUILTIN_VSFDF (UNOP, frint32z, 0)\n-  BUILTIN_VSFDF (UNOP, frint32x, 0)\n-  BUILTIN_VSFDF (UNOP, frint64z, 0)\n-  BUILTIN_VSFDF (UNOP, frint64x, 0)\n+  BUILTIN_VSFDF (UNOP, frint32z, 0, ALL)\n+  BUILTIN_VSFDF (UNOP, frint32x, 0, ALL)\n+  BUILTIN_VSFDF (UNOP, frint64z, 0, ALL)\n+  BUILTIN_VSFDF (UNOP, frint64x, 0, ALL)\n \n   /* Implemented by aarch64_bfdot{_lane}{q}<mode>.  */\n-  VAR2 (TERNOP, bfdot, 0, v2sf, v4sf)\n-  VAR2 (QUADOP_LANE_PAIR, bfdot_lane, 0, v2sf, v4sf)\n-  VAR2 (QUADOP_LANE_PAIR, bfdot_laneq, 0, v2sf, v4sf)\n+  VAR2 (TERNOP, bfdot, 0, ALL, v2sf, v4sf)\n+  VAR2 (QUADOP_LANE_PAIR, bfdot_lane, 0, ALL, v2sf, v4sf)\n+  VAR2 (QUADOP_LANE_PAIR, bfdot_laneq, 0, ALL, v2sf, v4sf)\n \n   /* Implemented by aarch64_bfmmlaqv4sf  */\n-  VAR1 (TERNOP, bfmmlaq, 0, v4sf)\n+  VAR1 (TERNOP, bfmmlaq, 0, ALL, v4sf)\n \n   /* Implemented by aarch64_bfmlal<bt>{_lane{q}}v4sf  */\n-  VAR1 (TERNOP, bfmlalb, 0, v4sf)\n-  VAR1 (TERNOP, bfmlalt, 0, v4sf)\n-  VAR1 (QUADOP_LANE, bfmlalb_lane, 0, v4sf)\n-  VAR1 (QUADOP_LANE, bfmlalt_lane, 0, v4sf)\n-  VAR1 (QUADOP_LANE, bfmlalb_lane_q, 0, v4sf)\n-  VAR1 (QUADOP_LANE, bfmlalt_lane_q, 0, v4sf)\n+  VAR1 (TERNOP, bfmlalb, 0, ALL, v4sf)\n+  VAR1 (TERNOP, bfmlalt, 0, ALL, v4sf)\n+  VAR1 (QUADOP_LANE, bfmlalb_lane, 0, ALL, v4sf)\n+  VAR1 (QUADOP_LANE, bfmlalt_lane, 0, ALL, v4sf)\n+  VAR1 (QUADOP_LANE, bfmlalb_lane_q, 0, ALL, v4sf)\n+  VAR1 (QUADOP_LANE, bfmlalt_lane_q, 0, ALL, v4sf)\n \n   /* Implemented by aarch64_simd_<sur>mmlav16qi.  */\n-  VAR1 (TERNOP, simd_smmla, 0, v16qi)\n-  VAR1 (TERNOPU, simd_ummla, 0, v16qi)\n-  VAR1 (TERNOP_SSUS, simd_usmmla, 0, v16qi)\n+  VAR1 (TERNOP, simd_smmla, 0, ALL, v16qi)\n+  VAR1 (TERNOPU, simd_ummla, 0, ALL, v16qi)\n+  VAR1 (TERNOP_SSUS, simd_usmmla, 0, ALL, v16qi)\n \n   /* Implemented by aarch64_bfcvtn{q}{2}<mode>  */\n-  VAR1 (UNOP, bfcvtn, 0, v4bf)\n-  VAR1 (UNOP, bfcvtn_q, 0, v8bf)\n-  VAR1 (BINOP, bfcvtn2, 0, v8bf)\n-  VAR1 (UNOP, bfcvt, 0, bf)\n+  VAR1 (UNOP, bfcvtn, 0, ALL, v4bf)\n+  VAR1 (UNOP, bfcvtn_q, 0, ALL, v8bf)\n+  VAR1 (BINOP, bfcvtn2, 0, ALL, v8bf)\n+  VAR1 (UNOP, bfcvt, 0, ALL, bf)"}, {"sha": "43feb482ce97ef537153ec184f81e8860ef69f8d", "filename": "gcc/config/aarch64/geniterators.sh", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bf592b2ff776aef71c91924cdb5e0d10488496cf/gcc%2Fconfig%2Faarch64%2Fgeniterators.sh", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bf592b2ff776aef71c91924cdb5e0d10488496cf/gcc%2Fconfig%2Faarch64%2Fgeniterators.sh", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Fgeniterators.sh?ref=bf592b2ff776aef71c91924cdb5e0d10488496cf", "patch": "@@ -70,8 +70,8 @@ iterdef {\n \tsub(/ *\\]/, \"\", s)\n \n \tn = split(s, a)\n-\tprintf \"#define BUILTIN_\" a[1] \"(T, N, MAP) \\\\\\n\"\n-\tprintf \"  VAR\" (n-1) \" (T, N, MAP\"\n+\tprintf \"#define BUILTIN_\" a[1] \"(T, N, MAP, FLAG) \\\\\\n\"\n+\tprintf \"  VAR\" (n-1) \" (T, N, MAP, FLAG\"\n \tfor (i = 2; i <= n; i++)\n \t\tprintf \", \"  tolower(a[i])\n \tprintf \")\\n\""}]}