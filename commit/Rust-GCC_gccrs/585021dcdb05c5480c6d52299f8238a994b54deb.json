{"sha": "585021dcdb05c5480c6d52299f8238a994b54deb", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NTg1MDIxZGNkYjA1YzU0ODBjNmQ1MjI5OWY4MjM4YTk5NGI1NGRlYg==", "commit": {"author": {"name": "Charles Hannum", "email": "mycroft@gnu.org", "date": "1991-08-29T23:24:57Z"}, "committer": {"name": "Charles Hannum", "email": "mycroft@gnu.org", "date": "1991-08-29T23:24:57Z"}, "message": "entered into RCS\n\nFrom-SVN: r36", "tree": {"sha": "fbe5ad10902e7b3a471d6af18950f565bb9303ab", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/fbe5ad10902e7b3a471d6af18950f565bb9303ab"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/585021dcdb05c5480c6d52299f8238a994b54deb", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/585021dcdb05c5480c6d52299f8238a994b54deb", "html_url": "https://github.com/Rust-GCC/gccrs/commit/585021dcdb05c5480c6d52299f8238a994b54deb", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/585021dcdb05c5480c6d52299f8238a994b54deb/comments", "author": null, "committer": null, "parents": [{"sha": "573ade84ccf53e4165b7e421b3516e08f1a5059e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/573ade84ccf53e4165b7e421b3516e08f1a5059e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/573ade84ccf53e4165b7e421b3516e08f1a5059e"}], "stats": {"total": 863, "additions": 863, "deletions": 0}, "files": [{"sha": "82ae9bd73496f4a83faca19a2522147823d813c0", "filename": "gcc/config/pyr/pyr.c", "status": "added", "additions": 863, "deletions": 0, "changes": 863, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/585021dcdb05c5480c6d52299f8238a994b54deb/gcc%2Fconfig%2Fpyr%2Fpyr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/585021dcdb05c5480c6d52299f8238a994b54deb/gcc%2Fconfig%2Fpyr%2Fpyr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fpyr%2Fpyr.c?ref=585021dcdb05c5480c6d52299f8238a994b54deb", "patch": "@@ -0,0 +1,863 @@\n+/* Subroutines for insn-output.c for Pyramid 90x, 9000, and MIServer Series.\n+   Copyright (C) 1989, 1991 Free Software Foundation, Inc.\n+\n+This file is part of GNU CC.\n+\n+GNU CC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 2, or (at your option)\n+any later version.\n+\n+GNU CC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GNU CC; see the file COPYING.  If not, write to\n+the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.  */\n+\n+/* Some output-actions in pyr.md need these.  */\n+#include <stdio.h>\n+#include \"config.h\"\n+#include \"rtl.h\"\n+#include \"regs.h\"\n+#include \"hard-reg-set.h\"\n+#include \"real.h\"\n+#include \"insn-config.h\"\n+#include \"conditions.h\"\n+#include \"insn-flags.h\"\n+#include \"output.h\"\n+#include \"insn-attr.h\"\n+#include \"tree.h\"\n+\n+/*\n+ * Do FUNCTION_ARG.\n+ * This cannot be defined as a macro on pyramids, because Pyramid Technology's\n+ * C compiler dies on (several equivalent definitions of) this macro.\n+ * The only way around this cc bug was to make this a function.\n+ * While it would be possible to use a macro version for gcc, it seems\n+ * more reliable to have a single version of the code.\n+ */\n+void *\n+pyr_function_arg(cum, mode, type, named)\n+  CUMULATIVE_ARGS cum;\n+  enum machine_mode mode;\n+  tree type;\n+{\n+  return (void *)(FUNCTION_ARG_HELPER (cum, mode,type,named));\n+}\n+\f\n+/* Do the hard part of PARAM_SAFE_FOR_REG_P.\n+ * This cannot be defined as a macro on pyramids, because Pyramid Technology's\n+ * C compiler dies on (several equivalent definitions of) this macro.\n+ * The only way around this cc bug was to make this a function.\n+ */\n+int\n+inner_param_safe_helper (type)\n+    tree type;\n+{\n+  return (INNER_PARAM_SAFE_HELPER(type));\n+}\n+\f\n+\n+/* Return 1 if OP is a non-indexed operand of mode MODE.\n+   This is either a register reference, a memory reference,\n+   or a constant.  In the case of a memory reference, the address\n+   is checked to make sure it isn't indexed.\n+\n+   Register and memory references must have mode MODE in order to be valid,\n+   but some constants have no machine mode and are valid for any mode.\n+\n+   If MODE is VOIDmode, OP is checked for validity for whatever mode\n+   it has.\n+\n+   The main use of this function is as a predicate in match_operand\n+   expressions in the machine description.\n+\n+   It is  useful to compare this with general_operand().  They should\n+   be identical except for one line.\n+\n+   This function seems necessary because of the non-orthogonality of\n+   Pyramid insns.\n+   For any 2-operand insn, and any combination of operand modes,\n+   if indexing is valid for the isn's second operand, it is invalid\n+   for the first operand to be indexed. */\n+\n+extern int volatile_ok;\n+\n+int\n+nonindexed_operand (op, mode)\n+    register rtx op;\n+    enum machine_mode mode;\n+{\n+  register RTX_CODE code = GET_CODE (op);\n+  int mode_altering_drug = 0;\n+\n+  if (mode == VOIDmode)\n+    mode = GET_MODE (op);\n+\n+  /* Don't accept CONST_INT or anything similar\n+     if the caller wants something floating.  */\n+  if (GET_MODE (op) == VOIDmode && mode != VOIDmode\n+      && GET_MODE_CLASS (mode) != MODE_INT)\n+    return 0;\n+\n+  if (CONSTANT_P (op))\n+    return ((GET_MODE (op) == VOIDmode || GET_MODE (op) == mode)\n+\t    && LEGITIMATE_CONSTANT_P (op));\n+\n+  /* Except for certain constants with VOIDmode, already checked for,\n+     OP's mode must match MODE if MODE specifies a mode.  */\n+\n+  if (GET_MODE (op) != mode)\n+    return 0;\n+\n+  while (code == SUBREG)\n+    {\n+      op = SUBREG_REG (op);\n+      code = GET_CODE (op);\n+#if 0\n+      /* No longer needed, since (SUBREG (MEM...))\n+\t will load the MEM into a reload reg in the MEM's own mode.  */\n+      mode_altering_drug = 1;\n+#endif\n+    }\n+  if (code == REG)\n+    return 1;\n+  if (code == CONST_DOUBLE)\n+    return LEGITIMATE_CONSTANT_P (op);\n+  if (code == MEM)\n+    {\n+      register rtx y = XEXP (op, 0);\n+      if (! volatile_ok && MEM_VOLATILE_P (op))\n+\treturn 0;\n+    GO_IF_NONINDEXED_ADDRESS (y, win);\n+    }\n+  return 0;\n+\n+ win:\n+  if (mode_altering_drug)\n+    return ! mode_dependent_address_p (XEXP (op, 0));\n+  return 1;\n+}\n+\n+/* Return non-zero if the rtx OP has an immediate component.  An\n+   immediate component or additive term equal to zero is rejected\n+   due to assembler problems.  */\n+\n+int\n+has_direct_base (op)\n+     rtx op;\n+{\n+  if ((CONSTANT_ADDRESS_P (op)\n+       && op != const0_rtx)\n+      || (GET_CODE (op) == PLUS\n+\t  && ((CONSTANT_ADDRESS_P (XEXP (op, 1))\n+\t       && XEXP (op, 1) != const0_rtx)\n+\t      || (CONSTANT_ADDRESS_P (XEXP (op, 0))\n+\t\t  && XEXP (op, 0) != const0_rtx))))\n+    return 1;\n+\n+  return 0;\n+}\n+\n+/* Return zero if the rtx OP has a (scaled) index.  */\n+\n+int\n+has_index (op)\n+     rtx op;\n+{\n+  if (GET_CODE (op) == PLUS\n+      && (GET_CODE (XEXP (op, 0)) == MULT\n+\t  || (GET_CODE (XEXP (op, 1)) == MULT)))\n+    return 1;\n+  else\n+    return 0;\n+}\n+\n+int swap_operands;\n+\n+/* weird_memory_memory -- return 1 if OP1 and OP2 can be compared (or\n+   exchanged with xchw) with one instruction.  If the operands need to\n+   be swapped, set the global variable SWAP_OPERANDS.  This function\n+   silently assumes that both OP0 and OP1 are valid memory references.\n+   */\n+\n+int\n+weird_memory_memory (op0, op1)\n+     rtx op0, op1;\n+{\n+  RTX_CODE code0, code1;\n+\n+  op0 = XEXP (op0, 0);\n+  op1 = XEXP (op1, 0);\n+  code0 = GET_CODE (op0);\n+  code1 = GET_CODE (op1);\n+\n+  swap_operands = 0;\n+\n+  if (code1 == REG || code1 == SUBREG)\n+    {\n+      return 1;\n+    }\n+  if (code0 == REG || code0 == SUBREG)\n+    {\n+      swap_operands = 1;\n+      return 1;\n+    }\n+  if (has_direct_base (op0) && has_direct_base (op1))\n+    {\n+      if (has_index (op1))\n+\t{\n+\t  if (has_index (op0))\n+\t    return 0;\n+\t  swap_operands = 1;\n+\t}\n+\n+      return 1;\n+    }\n+  return 0;\n+}\n+\n+int\n+signed_comparison (x, mode)\n+     rtx x;\n+     enum machine_mode mode;\n+{\n+  return ! TRULY_UNSIGNED_COMPARE_P (GET_CODE (x));\n+}\n+\n+extern rtx force_reg ();\n+rtx test_op0, test_op1;\n+enum machine_mode test_mode;\n+\n+/* Sign-extend or zero-extend constant X from FROM_MODE to TO_MODE.  */\n+\n+rtx\n+extend_const (x, extop, from_mode, to_mode)\n+    rtx x;\n+    RTX_CODE extop;\n+    enum machine_mode from_mode, to_mode;\n+{\n+  int val;\n+  int negative;\n+  if (from_mode == to_mode)\n+    return x;\n+  if (GET_CODE (x) != CONST_INT)\n+    abort ();\n+  val = INTVAL (x);\n+  negative = val & (1 << (GET_MODE_BITSIZE (from_mode) - 1));\n+  if (GET_MODE_BITSIZE (from_mode) == HOST_BITS_PER_INT)\n+    abort ();\n+  if (negative && extop == SIGN_EXTEND)\n+    val = val | ((-1) << (GET_MODE_BITSIZE (from_mode)));\n+  else\n+    val = val & ~((-1) << (GET_MODE_BITSIZE (from_mode)));\n+  if (GET_MODE_BITSIZE (to_mode) == HOST_BITS_PER_INT)\n+    return gen_rtx (CONST_INT, VOIDmode, val);\n+  return gen_rtx (CONST_INT, VOIDmode,\n+\t\t  val & ~((-1) << (GET_MODE_BITSIZE (to_mode))));\n+}\n+\n+rtx\n+ensure_extended (op, extop, from_mode)\n+     rtx op;\n+     RTX_CODE extop;\n+     enum machine_mode from_mode;\n+{\n+  if (GET_CODE (op) == CONST_INT)\n+    return extend_const (op, extop, from_mode, SImode);\n+  else\n+    return force_reg (SImode, gen_rtx (extop, SImode, op));\n+}\n+\n+/* Emit rtl for a branch, as well as any delayed (integer) compare insns.\n+   The compare insn to perform is determined by the global variables\n+   test_op0 and test_op1.  */\n+\n+void\n+extend_and_branch (extop)\n+     RTX_CODE extop;\n+{\n+  rtx op0, op1;\n+  RTX_CODE code0, code1;\n+\n+  op0 = test_op0, op1 = test_op1;\n+  if (op0 == 0)\n+    return;\n+\n+  code0 = GET_CODE (op0);\n+  if (op1 != 0)\n+    code1 = GET_CODE (op1);\n+  test_op0 = test_op1 = 0;\n+\n+  if (op1 == 0)\n+    {\n+      op0 = ensure_extended (op0, extop, test_mode);\n+      emit_insn (gen_rtx (SET, VOIDmode, cc0_rtx, op0));\n+    }\n+  else\n+    {\n+      if (CONSTANT_P (op0) && CONSTANT_P (op1))\n+\t{\n+\t  op0 = ensure_extended (op0, extop, test_mode);\n+\t  op1 = ensure_extended (op1, extop, test_mode);\n+\t}\n+      else if (extop == ZERO_EXTEND && test_mode == HImode)\n+\t{\n+\t  /* Pyramids have no unsigned \"cmphi\" instructions.  We need to\n+\t     zero extend unsigned halfwords into temporary registers. */\n+\t  op0 = ensure_extended (op0, extop, test_mode);\n+\t  op1 = ensure_extended (op1, extop, test_mode);\n+\t}\n+      else if (CONSTANT_P (op0))\n+\t{\n+\t  op0 = ensure_extended (op0, extop, test_mode);\n+\t  op1 = ensure_extended (op1, extop, test_mode);\n+\t}\n+      else if (CONSTANT_P (op1))\n+\t{\n+\t  op1 = ensure_extended (op1, extop, test_mode);\n+\t  op0 = ensure_extended (op0, extop, test_mode);\n+\t}\n+      else if ((code0 == REG || code0 == SUBREG)\n+\t       && (code1 == REG || code1 == SUBREG))\n+\t{\n+\t  /* I could do this case without extension, by using the virtual\n+\t     register address (but that would lose for global regs).  */\n+\t  op0 = ensure_extended (op0, extop, test_mode);\n+\t  op1 = ensure_extended (op1, extop, test_mode);\n+\t}\n+      else if (code0 == MEM && code1 == MEM)\n+\t{\n+\t  /* Load into a reg if the address combination can't be handled\n+\t     directly.  */\n+\t  if (! weird_memory_memory (op0, op1))\n+\t    op0 = force_reg (test_mode, op0);\n+\t}\n+\n+      emit_insn (gen_rtx (SET, VOIDmode, cc0_rtx,\n+\t\t\t  gen_rtx (COMPARE, VOIDmode, op0, op1)));\n+    }\n+}\n+\n+/* Return non-zero if the two single-word moves with operands[0]\n+   and operands[1] for the first single-word move, and operands[2]\n+   and operands[3] for the second single-word move, is possible to\n+   combine to a double word move.\n+\n+   The criterion is whether the operands are in consecutive memory cells,\n+   registers, etc.  */\n+\n+int\n+movdi_possible (operands)\n+     rtx operands[];\n+{\n+  int cnst_diff0, cnst_diff1;\n+  RTX_CODE code0 = GET_CODE (operands[0]);\n+  RTX_CODE code1 = GET_CODE (operands[1]);\n+\n+  /* Don't dare to combine (possibly overlapping) memory -> memory moves.  */\n+  /* It would be possible to detect the cases where we dare, by using\n+     constant_diff (operands[0], operands[1])!!!  */\n+  if (code0 == MEM && code1 == MEM)\n+    return 0;\n+\n+  cnst_diff0 = consecutive_operands (operands[0], operands[2]);\n+  if (cnst_diff0 == 0)\n+    return 0;\n+\n+  cnst_diff1 = consecutive_operands (operands[1], operands[3]);\n+  if (cnst_diff1 == 0)\n+    return 0;\n+\n+  if (cnst_diff0 & cnst_diff1)\n+    {\n+      /* The source and destination operands are consecutive.  */\n+\n+      /* If the first move writes into the source of the second move,\n+\t we cannot combine.  */\n+      if ((code0 == REG\n+\t   && reg_overlap_mentioned_p (operands[0], operands[3]))\n+\t  || (code0 == SUBREG\n+\t      && subreg_overlap_mentioned_p (operands[0], operands[3])))\n+\t  return 0;\n+\n+      if (cnst_diff0 & 1)\n+\t/* operands[0],[1] has higher addresses than operands[2],[3].  */\n+\tswap_operands = 0;\n+      else\n+\t/* operands[0],[1] has lower addresses than operands[2],[3].  */\n+\tswap_operands = 1;\n+      return 1;\n+    }\n+  return 0;\n+}\n+\n+/* Like reg_overlap_mentioned_p, but accepts a subreg rtx instead\n+   of a reg.  */\n+\n+int\n+subreg_overlap_mentioned_p (subreg, x)\n+     rtx subreg, x;\n+{\n+  rtx reg = SUBREG_REG (subreg);\n+  int regno = REGNO (reg) + SUBREG_WORD (subreg);\n+  int endregno = regno + HARD_REGNO_NREGS (regno, GET_MODE (subreg));\n+  return refers_to_regno_p (regno, endregno, x, 0);\n+}\n+\n+/* Return 1 if OP0 is a consecutive operand to OP1, 2 if OP1 is a\n+   consecutive operand to OP0.\n+\n+   This function is used to determine if addresses are consecutive,\n+   and therefore possible to combine to fewer instructions.  */\n+\n+int\n+consecutive_operands (op0, op1)\n+     rtx op0, op1;\n+{\n+  RTX_CODE code0, code1;\n+  int cnst_diff;\n+  int regno_off0, regno_off1;\n+\n+  code0 = GET_CODE (op0);\n+  code1 = GET_CODE (op1);\n+\n+  regno_off0 = 0;\n+  if (code0 == SUBREG)\n+    {\n+      if (GET_MODE_SIZE (GET_MODE (SUBREG_REG (op0))) <= UNITS_PER_WORD)\n+\treturn 0;\n+      regno_off0 = SUBREG_WORD (op0);\n+      op0 = SUBREG_REG (op0);\n+      code0 = REG;\n+    }\n+\n+  regno_off1 = 0;\n+  if (code1 == SUBREG)\n+    {\n+      if (GET_MODE_SIZE (GET_MODE (SUBREG_REG (op1))) <= UNITS_PER_WORD)\n+\treturn 0;\n+      regno_off1 = SUBREG_WORD (op1);\n+      op1 = SUBREG_REG (op1);\n+      code1 = REG;\n+    }\n+\n+  if (code0 != code1)\n+    return 0;\n+\n+  switch (code0)\n+    {\n+    case CONST_INT:\n+      /* Cannot permit any symbolic constants, even if the consecutive\n+\t operand is 0, since a movl really performs sign extension.  */\n+      if (code1 != CONST_INT)\n+\treturn 0;\n+      if ((INTVAL (op0) == 0 && INTVAL (op1) == 0)\n+\t  || (INTVAL (op0) == -1 && INTVAL (op1) == -1))\n+\treturn 3;\n+      if ((INTVAL (op0) == 0 && INTVAL (op1) > 0)\n+\t  || (INTVAL (op0) == -1 && INTVAL (op1) < 0))\n+\treturn 2;\n+      if ((INTVAL (op1) == 0 && INTVAL (op0) > 0)\n+\t  || (INTVAL (op1) == -1 && INTVAL (op0) < 0))\n+\treturn 1;\n+      break;\n+\n+    case REG:\n+      regno_off0 = REGNO (op0) + regno_off0;\n+      regno_off1 = REGNO (op1) + regno_off1;\n+\n+      cnst_diff = regno_off0 - regno_off1;\n+      if (cnst_diff == 1)\n+\t{\n+\t  /* movl with the highest numbered parameter (local) register as\n+\t     source or destination, doesn't wrap to the lowest numbered local\n+\t     (temporary) register.  */\n+\n+\t  if (regno_off0 % 16 != 0)\n+\t    return 1;\n+\t  else\n+\t    return 0;\n+\t}\n+      else if (cnst_diff == -1)\n+\t{\n+\t  if (regno_off1 % 16 != 0)\n+\t    return 2;\n+\t  else\n+\t    return 0;\n+\t}\n+      break;\n+\n+    case MEM:\n+      op0 = XEXP (op0, 0);\n+      op1 = XEXP (op1, 0);\n+      if (GET_CODE (op0) == CONST)\n+\top0 = XEXP (op0, 0);\n+      if (GET_CODE (op1) == CONST)\n+\top1 = XEXP (op1, 0);\n+\n+      cnst_diff = constant_diff (op0, op1);\n+      if (cnst_diff)\n+\t{\n+\t  if (cnst_diff == 4)\n+\t    return 1;\n+\t  else if (cnst_diff == -4)\n+\t    return 2;\n+\t}\n+      break;\n+    }\n+  return 0;\n+}\n+\n+/* Return the constant difference of the rtx expressions OP0 and OP1,\n+   or 0 if they don't have a constant difference.\n+\n+   This function is used to determine if addresses are consecutive,\n+   and therefore possible to combine to fewer instructions.  */\n+\n+int\n+constant_diff (op0, op1)\n+     rtx op0, op1;\n+{\n+  RTX_CODE code0, code1;\n+  int cnst_diff;\n+\n+  code0 = GET_CODE (op0);\n+  code1 = GET_CODE (op1);\n+\n+  if (code0 != code1)\n+    {\n+      if (code0 == PLUS)\n+\t{\n+\t  if (GET_CODE (XEXP (op0, 1)) == CONST_INT\n+\t      && rtx_equal_p (op1, XEXP (op0, 0)))\n+\t    return INTVAL (XEXP (op0, 1));\n+\t}\n+      else if (code1 == PLUS)\n+\t{\n+\t  if (GET_CODE (XEXP (op1, 1)) == CONST_INT\n+\t      && rtx_equal_p (op0, XEXP (op1, 0)))\n+\t    return -INTVAL (XEXP (op1, 1));\n+\t}\n+      return 0;\n+    }\n+\n+  if (code0 == CONST_INT)\n+    return INTVAL (op0) - INTVAL (op1);\n+\n+  if (code0 == PLUS)\n+    {\n+      cnst_diff = constant_diff (XEXP (op0, 0), XEXP (op1, 0));\n+      if (cnst_diff)\n+\treturn (rtx_equal_p (XEXP (op0, 1), XEXP (op1, 1)))\n+\t  ? cnst_diff : 0;\n+      cnst_diff = constant_diff (XEXP (op0, 1), XEXP (op1, 1));\n+      if (cnst_diff)\n+\treturn (rtx_equal_p (XEXP (op0, 0), XEXP (op1, 0)))\n+\t  ? cnst_diff : 0;\n+    }\n+\n+  return 0;\n+}\n+\n+int\n+already_sign_extended (insn, from_mode, op)\n+     rtx insn;\n+     enum machine_mode from_mode;\n+     rtx op;\n+{\n+  rtx xinsn, xdest, xsrc;\n+\n+  for (;;)\n+    {\n+      insn = PREV_INSN (insn);\n+      if (insn == 0)\n+\treturn 0;\n+      if (GET_CODE (insn) == NOTE || GET_CODE (insn) == JUMP_INSN)\n+\tcontinue;\n+      if (GET_CODE (insn) == CALL_INSN && ! call_used_regs[REGNO (op)])\n+\tcontinue;\n+      if (GET_CODE (insn) != INSN)\n+\treturn 0;\n+      xinsn = PATTERN (insn);\n+\n+      if (GET_CODE (xinsn) != SET)\n+\treturn 0;\n+\n+      xdest = SET_DEST (xinsn);\n+      xsrc = SET_SRC (xinsn);\n+\n+      if (GET_CODE (xdest) == SUBREG)\n+\tabort ();\n+\n+      if ( ! REG_P (xdest))\n+\tcontinue;\n+\n+      if (REGNO (op) == REGNO (xdest)\n+\t  && ((GET_CODE (xsrc) == SIGN_EXTEND\n+\t   && GET_MODE (XEXP (xsrc, 0)) == from_mode)\n+\t  || (GET_CODE (xsrc) == MEM\n+\t      && GET_MODE (xsrc) == from_mode)))\n+\treturn 1;\n+\n+      /* The register is modified by another operation.  */\n+      if (reg_overlap_mentioned_p (xdest, op))\n+\treturn 0;\n+    }\n+}\n+\n+char *\n+output_move_double (operands)\n+     rtx *operands;\n+{\n+  if (GET_CODE (operands[1]) == CONST_DOUBLE)\n+    {\n+      if (GET_MODE_CLASS (GET_MODE (operands[1])) == MODE_INT)\n+\t{\n+\t  /* In an integer, the low-order word is in CONST_DOUBLE_LOW.  */\n+\t  rtx const_op = operands[1];\n+\t  if ((CONST_DOUBLE_HIGH (const_op) == 0\n+\t       && CONST_DOUBLE_LOW (const_op) >= 0)\n+\t      || (CONST_DOUBLE_HIGH (const_op) == -1\n+\t\t  && CONST_DOUBLE_LOW (const_op) < 0))\n+\t    {\n+\t      operands[1] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t\t     CONST_DOUBLE_LOW (const_op));\n+\t      return \"movl %1,%0\";\n+\t    }\n+\t  operands[1] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t\t CONST_DOUBLE_HIGH (const_op));\n+\t  output_asm_insn (\"movw %1,%0\", operands);\n+\t  operands[0] = gen_rtx (REG, SImode, REGNO (operands[0]) + 1);\n+\t  operands[1] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t\t CONST_DOUBLE_LOW (const_op));\n+\t  return \"movw %1,%0\";\n+\t}\n+      else\n+\t{\n+\t  /* In a real, the low-address word is in CONST_DOUBLE_LOW.  */\n+\t  rtx const_op = operands[1];\n+\t  if ((CONST_DOUBLE_LOW (const_op) == 0\n+\t       && CONST_DOUBLE_HIGH (const_op) >= 0)\n+\t      || (CONST_DOUBLE_LOW (const_op) == -1\n+\t\t  && CONST_DOUBLE_HIGH (const_op) < 0))\n+\t    {\n+\t      operands[1] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t\t     CONST_DOUBLE_HIGH (const_op));\n+\t      return \"movl %1,%0\";\n+\t    }\n+\t  operands[1] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t\t CONST_DOUBLE_LOW (const_op));\n+\t  output_asm_insn (\"movw %1,%0\", operands);\n+\t  operands[0] = gen_rtx (REG, SImode, REGNO (operands[0]) + 1);\n+\t  operands[1] = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t\t CONST_DOUBLE_HIGH (const_op));\n+\t  return \"movw %1,%0\";\n+\t}\n+    }\n+\n+  return \"movl %1,%0\";\n+}\n+\n+/* Output a shift insns, after having reduced integer arguments to\n+   avoid as warnings.  */\n+\n+char *\n+output_shift (pattern, op2, mod)\n+     char *pattern;\n+     rtx op2;\n+     int mod;\n+{\n+  if (GET_CODE (op2) == CONST_INT)\n+    {\n+      int cnt = INTVAL (op2) % mod;\n+      if (cnt == 0)\n+\t{\n+\t  cc_status = cc_prev_status;\n+\t  return \"\";\n+\t}\n+      op2 = gen_rtx (CONST_INT, VOIDmode, cnt);\n+    }\n+  return pattern;\n+}\n+\n+/* Return non-zero if the code of this rtx pattern is a relop.  */\n+\n+int\n+relop (op, mode)\n+     rtx op;\n+     enum machine_mode mode;\n+{\n+  switch (GET_CODE (op))\n+    {\n+    case EQ:\n+    case NE:\n+    case LT:\n+    case LE:\n+    case GE:\n+    case GT:\n+    case LTU:\n+    case LEU:\n+    case GEU:\n+    case GTU:\n+      return 1;\n+    }\n+  return 0;\n+}\n+\n+void\n+notice_update_cc (EXP, INSN)\n+     rtx EXP, INSN;\n+{\n+  switch (GET_CODE (EXP))\n+    {\n+    case SET:\n+      switch (GET_CODE (SET_DEST (EXP)))\n+\t{\n+\tcase CC0:\n+\t  cc_status.mdep = 0;\n+\t  cc_status.flags = 0;\n+\t  cc_status.value1 = 0;\n+\t  cc_status.value2 = SET_SRC (EXP);\n+\t  break;\n+\n+\tcase PC:\n+\t  break;\n+\n+\tcase REG:\n+\t  switch (GET_CODE (SET_SRC (EXP)))\n+\t    {\n+\t    case CALL:\n+\t      goto call;\n+\t    case MEM:\n+\t      if (GET_MODE (SET_SRC (EXP)) == QImode\n+\t\t  || GET_MODE (SET_SRC (EXP)) == HImode)\n+\t\t{\n+\t\t  cc_status.mdep = 0;\n+\t\t  cc_status.flags = CC_NO_OVERFLOW;\n+\t\t  cc_status.value1 = SET_DEST (EXP);\n+\t\t  cc_status.value2 = SET_SRC (EXP);\n+\t\t  break;\n+\t\t}\n+\t      /* else: Fall through.  */\n+\t    case CONST_INT:\n+\t    case SYMBOL_REF:\n+\t    case LABEL_REF:\n+\t    case CONST:\n+\t    case CONST_DOUBLE:\n+\t    case REG:\n+\t      if (cc_status.value1\n+\t\t  && reg_overlap_mentioned_p (SET_DEST (EXP),\n+\t\t\t\t\t      cc_status.value1))\n+\t\tcc_status.value1 = 0;\n+\t      if (cc_status.value2\n+\t\t  && reg_overlap_mentioned_p (SET_DEST (EXP),\n+\t\t\t\t\t      cc_status.value2))\n+\t\tcc_status.value2 = 0;\n+\t      break;\n+\n+\t    case UDIV:\n+\t    case UMOD:\n+\t      cc_status.mdep = CC_VALID_FOR_UNSIGNED;\n+\t      cc_status.flags = CC_NO_OVERFLOW;\n+\t      cc_status.value1 = SET_DEST (EXP);\n+\t      cc_status.value2 = SET_SRC (EXP);\n+\t      break;\n+\t    default:\n+\t      cc_status.mdep = 0;\n+\t      cc_status.flags = CC_NO_OVERFLOW;\n+\t      cc_status.value1 = SET_DEST (EXP);\n+\t      cc_status.value2 = SET_SRC (EXP);\n+\t      break;\n+\t    }\n+\t  break;\n+\n+\tcase MEM:\n+\t  switch (GET_CODE (SET_SRC (EXP)))\n+\t    {\n+\t    case REG:\n+\t      if (GET_MODE (SET_SRC (EXP)) == QImode\n+\t\t  || GET_MODE (SET_SRC (EXP)) == HImode)\n+\t\t{\n+\t\t  cc_status.flags = CC_NO_OVERFLOW;\n+\t\t  cc_status.value1 = SET_DEST (EXP);\n+\t\t  cc_status.value2 = SET_SRC (EXP);\n+\t\t  cc_status.mdep = 0;\n+\t\t  break;\n+\t\t}\n+\t      /* else: Fall through.  */\n+\t    case CONST_INT:\n+\t    case SYMBOL_REF:\n+\t    case LABEL_REF:\n+\t    case CONST:\n+\t    case CONST_DOUBLE:\n+\t    case MEM:\n+\t      /* Need to forget cc_status about memory positions each\n+\t\t time a memory store is made, even if the memory store\n+\t\t insns in question doesn't modify the condition codes.  */\n+\t      if (cc_status.value1 &&\n+\t\t  GET_CODE (cc_status.value1) == MEM)\n+\t\tcc_status.value1 = 0;\n+\t      if (cc_status.value2 &&\n+\t\t  GET_CODE (cc_status.value2) == MEM)\n+\t\tcc_status.value2 = 0;\n+\t      break;\n+\t    case SIGN_EXTEND:\n+\t    case FLOAT_EXTEND:\n+\t    case FLOAT_TRUNCATE:\n+\t    case FLOAT:\n+\t    case FIX:\n+\t      cc_status.flags = CC_NO_OVERFLOW;\n+\t      cc_status.value1 = SET_DEST (EXP);\n+\t      cc_status.value2 = SET_SRC (EXP);\n+\t      cc_status.mdep = 0;\n+\t      break;\n+\n+\t    default:\n+\t      abort ();\n+\t    }\n+\t  break;\n+\n+\tdefault:\n+\t  abort ();\n+\t}\n+      break;\n+\n+    case CALL:\n+    call:\n+      CC_STATUS_INIT;\n+      break;\n+      /* Do calls preserve the condition codes?  (At least forget\n+\t cc_status expressions if they refer to registers\n+\t not preserved across calls.  Also forget expressions\n+\t about memory contents.)  */\n+      if (cc_status.value1\n+\t  && (refers_to_regno_p (PYR_TREG (0), PYR_TREG (15),\n+\t\t\t\t cc_status.value1, 0)\n+\t      || GET_CODE (cc_status.value1) == MEM))\n+\tcc_status.value1 = 0;\n+      if (cc_status.value2\n+\t  && (refers_to_regno_p (PYR_TREG (0), PYR_TREG (15),\n+\t\t\t\t cc_status.value2, 0)\n+\t      || GET_CODE (cc_status.value2) == MEM))\n+\tcc_status.value2 = 0;\n+      break;\n+\n+    default:\n+      CC_STATUS_INIT;\n+    }\n+}\n+\n+void\n+forget_cc_if_dependent (op)\n+     rtx op;\n+{\n+  cc_status = cc_prev_status;\n+  if (cc_status.value1 && reg_overlap_mentioned_p (op, cc_status.value1))\n+    cc_status.value1 = 0;\n+  if (cc_status.value2 && reg_overlap_mentioned_p (op, cc_status.value2))\n+    cc_status.value2 = 0;\n+}"}]}