{"sha": "1b28253347dedba72abaf81e86b1812863d07a11", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MWIyODI1MzM0N2RlZGJhNzJhYmFmODFlODZiMTgxMjg2M2QwN2ExMQ==", "commit": {"author": {"name": "Ian Lance Taylor", "email": "ian@gcc.gnu.org", "date": "2018-10-01T20:14:29Z"}, "committer": {"name": "Ian Lance Taylor", "email": "ian@gcc.gnu.org", "date": "2018-10-01T20:14:29Z"}, "message": "runtime: add arm64 version of AES hash code\n    \n    Rewrite the arm64 AES hashing code from gc assembler to C code using\n    intrinsics.  The resulting code generates the same hash code for the\n    same input as the gc code--that doesn't matter as such, but testing it\n    ensures that the C code does something useful.\n    \n    Reviewed-on: https://go-review.googlesource.com/138535\n\nFrom-SVN: r264771", "tree": {"sha": "992a035d1f5b4ec1e72fb1945fd096193f96d177", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/992a035d1f5b4ec1e72fb1945fd096193f96d177"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/1b28253347dedba72abaf81e86b1812863d07a11", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1b28253347dedba72abaf81e86b1812863d07a11", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1b28253347dedba72abaf81e86b1812863d07a11", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1b28253347dedba72abaf81e86b1812863d07a11/comments", "author": null, "committer": null, "parents": [{"sha": "df1346b423f1c8849b6090b47023ee29f6dddf7a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/df1346b423f1c8849b6090b47023ee29f6dddf7a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/df1346b423f1c8849b6090b47023ee29f6dddf7a"}], "stats": {"total": 405, "additions": 402, "deletions": 3}, "files": [{"sha": "69dd8b746b7805c2e08c8f6e40c5fbd21cd56376", "filename": "gcc/go/gofrontend/MERGE", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1b28253347dedba72abaf81e86b1812863d07a11/gcc%2Fgo%2Fgofrontend%2FMERGE", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1b28253347dedba72abaf81e86b1812863d07a11/gcc%2Fgo%2Fgofrontend%2FMERGE", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgo%2Fgofrontend%2FMERGE?ref=1b28253347dedba72abaf81e86b1812863d07a11", "patch": "@@ -1,4 +1,4 @@\n-f4a224ec481957ca4f14d0e8cc4fe59cc95b3a49\n+013a9e68c9a31f888733d46182d19f9e5d956f27\n \n The first line of this file holds the git revision number of the last\n merge done from the gofrontend repository."}, {"sha": "00658d7a8962550b5ab808c84e986e2f1f3288ed", "filename": "libgo/runtime/aeshash.c", "status": "modified", "additions": 401, "deletions": 2, "changes": 403, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1b28253347dedba72abaf81e86b1812863d07a11/libgo%2Fruntime%2Faeshash.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1b28253347dedba72abaf81e86b1812863d07a11/libgo%2Fruntime%2Faeshash.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Faeshash.c?ref=1b28253347dedba72abaf81e86b1812863d07a11", "patch": "@@ -573,13 +573,412 @@ uintptr aeshashbody(void* p, uintptr seed, uintptr size, Slice aeskeysched) {\n \n #endif // !defined(__x86_64__)\n \n-#else // !defined(__i386__) && !defined(__x86_64__) || !defined(HAVE_AS_X86_AES)\n+#elif defined(__aarch64__)\n+\n+// Undefine some identifiers that we pick up from the Go runtime package that\n+// are used in arm_neon.h.\n+\n+#undef t1\n+#undef tx\n+#undef t2\n+#undef t3\n+#undef t4\n+#undef t5\n+\n+#include <arm_neon.h>\n+\n+// Force appropriate CPU level.  We won't call here unless the CPU\n+// supports it.\n+\n+#pragma GCC target(\"+crypto\")\n+\n+// The arm64 version of aeshashbody.\n+\n+uintptr aeshashbody(void* p, uintptr seed, uintptr size, Slice aeskeysched) {\n+\tuint8x16_t *pseed;\n+\tuint32x4_t vinit32;\n+\tuint8x16_t vinit;\n+\tuint8x16_t vseed, vseed2, vseed3, vseed4;\n+\tuint8x16_t vseed5, vseed6, vseed7, vseed8;\n+\tuint8x16_t vval, vval2, vval3, vval4;\n+\tuint8x16_t vval5, vval6, vval7, vval8;\n+\tuint8x16_t vvalLoop, vvalLoop2, vvalLoop3, vvalLoop4;\n+\tuint8x16_t vvalLoop5, vvalLoop6, vvalLoop7, vvalLoop8;\n+\tuint8x16x2_t avval2;\n+\tuint8x16x3_t avseed3;\n+\n+\tpseed = (uint8x16_t*)(aeskeysched.__values);\n+\n+\t// Combined hash seed and length.\n+\tvinit32 = vdupq_n_u32(0);\n+\tvinit32[0] = (uint32)seed;\n+\tvinit32[1] = (uint32)size;\n+\tvinit = vreinterpretq_u8_u32(vinit32);\n+\n+\t// Mix in per-process seed.\n+\tvseed = vaeseq_u8(*pseed, vinit);\n+\t++pseed;\n+\t// Scramble seed.\n+\tvseed = vaesmcq_u8(vseed);\n+\n+\tif (size <= 16) {\n+\t\tif (size == 0) {\n+\t\t\t// Return 64 bits of scrambled input seed.\n+\t\t\treturn vreinterpretq_u64_u8(vseed)[0];\n+\t\t} else if (size < 16) {\n+\t\t\tvval = vreinterpretq_u8_u32(vdupq_n_u32(0));\n+\t\t\tif ((size & 8) != 0) {\n+\t\t\t\tvval = vreinterpretq_u8_u64(vld1q_lane_u64((uint64_t*)(p), vreinterpretq_u64_u8(vval), 0));\n+\t\t\t\tp = (void*)((uint64_t*)(p) + 1);\n+\t\t\t}\n+\t\t\tif ((size & 4) != 0) {\n+\t\t\t\tvval = vreinterpretq_u8_u32(vld1q_lane_u32((uint32_t*)(p), vreinterpretq_u32_u8(vval), 2));\n+\t\t\t\tp = (void*)((uint32_t*)(p) + 1);\n+\t\t\t}\n+\t\t\tif ((size & 2) != 0) {\n+\t\t\t\tvval = vreinterpretq_u8_u16(vld1q_lane_u16((uint16_t*)(p), vreinterpretq_u16_u8(vval), 6));\n+\t\t\t\tp = (void*)((uint16_t*)(p) + 1);\n+\t\t\t}\n+\t\t\tif ((size & 1) != 0) {\n+\t\t\t\tvval = vld1q_lane_u8((uint8*)(p), vval, 14);\n+\t\t\t}\n+\t\t} else {\n+\t\t\tvval = *(uint8x16_t*)(p);\n+\t\t}\n+\t\tvval = vaeseq_u8(vval, vseed);\n+\t\tvval = vaesmcq_u8(vval);\n+\t\tvval = vaeseq_u8(vval, vseed);\n+\t\tvval = vaesmcq_u8(vval);\n+\t\tvval = vaeseq_u8(vval, vseed);\n+\t\treturn vreinterpretq_u64_u8(vval)[0];\n+\t} else if (size <= 32) {\n+\t\t// Make a second seed.\n+\t\tvseed2 = vaeseq_u8(*pseed, vinit);\n+\t\tvseed2 = vaesmcq_u8(vseed2);\n+\t\tvval = *(uint8x16_t*)(p);\n+\t\tvval2 = *(uint8x16_t*)((char*)(p) + (size - 16));\n+\n+\t\tvval = vaeseq_u8(vval, vseed);\n+\t\tvval = vaesmcq_u8(vval);\n+\t\tvval2 = vaeseq_u8(vval2, vseed2);\n+\t\tvval2 = vaesmcq_u8(vval2);\n+\n+\t\tvval = vaeseq_u8(vval, vseed);\n+\t\tvval = vaesmcq_u8(vval);\n+\t\tvval2 = vaeseq_u8(vval2, vseed2);\n+\t\tvval2 = vaesmcq_u8(vval2);\n+\n+\t\tvval = vaeseq_u8(vval, vseed);\n+\t\tvval2 = vaeseq_u8(vval2, vseed2);\n+\n+\t\tvval ^= vval2;\n+\n+\t\treturn vreinterpretq_u64_u8(vval)[0];\n+\t} else if (size <= 64) {\n+\t\tavseed3 = vld1q_u8_x3((uint8*)(pseed));\n+\t\tvseed2 = avseed3.val[0];\n+\t\tvseed3 = avseed3.val[1];\n+\t\tvseed4 = avseed3.val[2];\n+\n+\t\tvseed2 = vaeseq_u8(vseed2, vinit);\n+\t\tvseed2 = vaesmcq_u8(vseed2);\n+\t\tvseed3 = vaeseq_u8(vseed3, vinit);\n+\t\tvseed3 = vaesmcq_u8(vseed3);\n+\t\tvseed4 = vaeseq_u8(vseed4, vinit);\n+\t\tvseed4 = vaesmcq_u8(vseed4);\n+\n+\t\tavval2 = vld1q_u8_x2((uint8*)(p));\n+\t\tvval = avval2.val[0];\n+\t\tvval2 = avval2.val[1];\n+\t\tavval2 = vld1q_u8_x2((uint8*)(p) + (size - 32));\n+\t\tvval3 = avval2.val[0];\n+\t\tvval4 = avval2.val[1];\n+\n+\t\tvval = vaeseq_u8(vval, vseed);\n+\t\tvval = vaesmcq_u8(vval);\n+\t\tvval2 = vaeseq_u8(vval2, vseed2);\n+\t\tvval2 = vaesmcq_u8(vval2);\n+\t\tvval3 = vaeseq_u8(vval3, vseed3);\n+\t\tvval3 = vaesmcq_u8(vval3);\n+\t\tvval4 = vaeseq_u8(vval4, vseed4);\n+\t\tvval4 = vaesmcq_u8(vval4);\n+\n+\t\tvval = vaeseq_u8(vval, vseed);\n+\t\tvval = vaesmcq_u8(vval);\n+\t\tvval2 = vaeseq_u8(vval2, vseed2);\n+\t\tvval2 = vaesmcq_u8(vval2);\n+\t\tvval3 = vaeseq_u8(vval3, vseed3);\n+\t\tvval3 = vaesmcq_u8(vval3);\n+\t\tvval4 = vaeseq_u8(vval4, vseed4);\n+\t\tvval4 = vaesmcq_u8(vval4);\n+\n+\t\tvval = vaeseq_u8(vval, vseed);\n+\t\tvval2 = vaeseq_u8(vval2, vseed2);\n+\t\tvval3 = vaeseq_u8(vval3, vseed3);\n+\t\tvval4 = vaeseq_u8(vval4, vseed4);\n+\n+\t\tvval ^= vval3;\n+\t\tvval2 ^= vval4;\n+\t\tvval ^= vval2;\n+\n+\t\treturn vreinterpretq_u64_u8(vval)[0];\n+\t} else if (size <= 128) {\n+\t\t// For some reason vld1q_u8_x4 is missing.\n+\t\tavseed3 = vld1q_u8_x3((uint8*)(pseed));\n+\t\tvseed2 = avseed3.val[0];\n+\t\tvseed3 = avseed3.val[1];\n+\t\tvseed4 = avseed3.val[2];\n+\t\tavseed3 = vld1q_u8_x3((uint8*)(pseed + 3));\n+\t\tvseed5 = avseed3.val[0];\n+\t\tvseed6 = avseed3.val[1];\n+\t\tvseed7 = avseed3.val[2];\n+\t\tvseed8 = *(pseed + 6);\n+\n+\t\tvseed2 = vaeseq_u8(vseed2, vinit);\n+\t\tvseed2 = vaesmcq_u8(vseed2);\n+\t\tvseed3 = vaeseq_u8(vseed3, vinit);\n+\t\tvseed3 = vaesmcq_u8(vseed3);\n+\t\tvseed4 = vaeseq_u8(vseed4, vinit);\n+\t\tvseed4 = vaesmcq_u8(vseed4);\n+\t\tvseed5 = vaeseq_u8(vseed5, vinit);\n+\t\tvseed5 = vaesmcq_u8(vseed5);\n+\t\tvseed6 = vaeseq_u8(vseed6, vinit);\n+\t\tvseed6 = vaesmcq_u8(vseed6);\n+\t\tvseed7 = vaeseq_u8(vseed7, vinit);\n+\t\tvseed7 = vaesmcq_u8(vseed7);\n+\t\tvseed8 = vaeseq_u8(vseed8, vinit);\n+\t\tvseed8 = vaesmcq_u8(vseed8);\n+\n+\t\tavval2 = vld1q_u8_x2((uint8*)(p));\n+\t\tvval = avval2.val[0];\n+\t\tvval2 = avval2.val[1];\n+\t\tavval2 = vld1q_u8_x2((uint8*)(p) + 32);\n+\t\tvval3 = avval2.val[0];\n+\t\tvval4 = avval2.val[1];\n+\t\tavval2 = vld1q_u8_x2((uint8*)(p) + (size - 64));\n+\t\tvval5 = avval2.val[0];\n+\t\tvval6 = avval2.val[1];\n+\t\tavval2 = vld1q_u8_x2((uint8*)(p) + (size - 32));\n+\t\tvval7 = avval2.val[0];\n+\t\tvval8 = avval2.val[1];\n+\n+\t\tvval = vaeseq_u8(vval, vseed);\n+\t\tvval = vaesmcq_u8(vval);\n+\t\tvval2 = vaeseq_u8(vval2, vseed2);\n+\t\tvval2 = vaesmcq_u8(vval2);\n+\t\tvval3 = vaeseq_u8(vval3, vseed3);\n+\t\tvval3 = vaesmcq_u8(vval3);\n+\t\tvval4 = vaeseq_u8(vval4, vseed4);\n+\t\tvval4 = vaesmcq_u8(vval4);\n+\t\tvval5 = vaeseq_u8(vval5, vseed5);\n+\t\tvval5 = vaesmcq_u8(vval5);\n+\t\tvval6 = vaeseq_u8(vval6, vseed6);\n+\t\tvval6 = vaesmcq_u8(vval6);\n+\t\tvval7 = vaeseq_u8(vval7, vseed7);\n+\t\tvval7 = vaesmcq_u8(vval7);\n+\t\tvval8 = vaeseq_u8(vval8, vseed8);\n+\t\tvval8 = vaesmcq_u8(vval8);\n+\n+\t\tvval = vaeseq_u8(vval, vseed);\n+\t\tvval = vaesmcq_u8(vval);\n+\t\tvval2 = vaeseq_u8(vval2, vseed2);\n+\t\tvval2 = vaesmcq_u8(vval2);\n+\t\tvval3 = vaeseq_u8(vval3, vseed3);\n+\t\tvval3 = vaesmcq_u8(vval3);\n+\t\tvval4 = vaeseq_u8(vval4, vseed4);\n+\t\tvval4 = vaesmcq_u8(vval4);\n+\t\tvval5 = vaeseq_u8(vval5, vseed5);\n+\t\tvval5 = vaesmcq_u8(vval5);\n+\t\tvval6 = vaeseq_u8(vval6, vseed6);\n+\t\tvval6 = vaesmcq_u8(vval6);\n+\t\tvval7 = vaeseq_u8(vval7, vseed7);\n+\t\tvval7 = vaesmcq_u8(vval7);\n+\t\tvval8 = vaeseq_u8(vval8, vseed8);\n+\t\tvval8 = vaesmcq_u8(vval8);\n+\n+\t\tvval = vaeseq_u8(vval, vseed);\n+\t\tvval2 = vaeseq_u8(vval2, vseed2);\n+\t\tvval3 = vaeseq_u8(vval3, vseed3);\n+\t\tvval4 = vaeseq_u8(vval4, vseed4);\n+\t\tvval5 = vaeseq_u8(vval5, vseed5);\n+\t\tvval6 = vaeseq_u8(vval6, vseed6);\n+\t\tvval7 = vaeseq_u8(vval7, vseed7);\n+\t\tvval8 = vaeseq_u8(vval8, vseed8);\n+\n+\t\tvval ^= vval5;\n+\t\tvval2 ^= vval6;\n+\t\tvval3 ^= vval7;\n+\t\tvval4 ^= vval8;\n+\t\tvval ^= vval3;\n+\t\tvval2 ^= vval4;\n+\t\tvval ^= vval2;\n+\n+\t\treturn vreinterpretq_u64_u8(vval)[0];\n+\t} else {\n+\t\t// For some reason vld1q_u8_x4 is missing.\n+\t\tavseed3 = vld1q_u8_x3((uint8*)(pseed));\n+\t\tvseed2 = avseed3.val[0];\n+\t\tvseed3 = avseed3.val[1];\n+\t\tvseed4 = avseed3.val[2];\n+\t\tavseed3 = vld1q_u8_x3((uint8*)(pseed + 3));\n+\t\tvseed5 = avseed3.val[0];\n+\t\tvseed6 = avseed3.val[1];\n+\t\tvseed7 = avseed3.val[2];\n+\t\tvseed8 = *(pseed + 6);\n+\n+\t\tvseed2 = vaeseq_u8(vseed2, vinit);\n+\t\tvseed2 = vaesmcq_u8(vseed2);\n+\t\tvseed3 = vaeseq_u8(vseed3, vinit);\n+\t\tvseed3 = vaesmcq_u8(vseed3);\n+\t\tvseed4 = vaeseq_u8(vseed4, vinit);\n+\t\tvseed4 = vaesmcq_u8(vseed4);\n+\t\tvseed5 = vaeseq_u8(vseed5, vinit);\n+\t\tvseed5 = vaesmcq_u8(vseed5);\n+\t\tvseed6 = vaeseq_u8(vseed6, vinit);\n+\t\tvseed6 = vaesmcq_u8(vseed6);\n+\t\tvseed7 = vaeseq_u8(vseed7, vinit);\n+\t\tvseed7 = vaesmcq_u8(vseed7);\n+\t\tvseed8 = vaeseq_u8(vseed8, vinit);\n+\t\tvseed8 = vaesmcq_u8(vseed8);\n+\n+\t\tavval2 = vld1q_u8_x2((uint8*)(p) + (size - 128));\n+\t\tvval = avval2.val[0];\n+\t\tvval2 = avval2.val[1];\n+\t\tavval2 = vld1q_u8_x2((uint8*)(p) + (size - 96));\n+\t\tvval3 = avval2.val[0];\n+\t\tvval4 = avval2.val[1];\n+\t\tavval2 = vld1q_u8_x2((uint8*)(p) + (size - 64));\n+\t\tvval5 = avval2.val[0];\n+\t\tvval6 = avval2.val[1];\n+\t\tavval2 = vld1q_u8_x2((uint8*)(p) + (size - 32));\n+\t\tvval7 = avval2.val[0];\n+\t\tvval8 = avval2.val[1];\n+\n+\t\tvvalLoop = vseed;\n+\t\tvvalLoop2 = vseed2;\n+\t\tvvalLoop3 = vseed3;\n+\t\tvvalLoop4 = vseed4;\n+\t\tvvalLoop5 = vseed5;\n+\t\tvvalLoop6 = vseed6;\n+\t\tvvalLoop7 = vseed7;\n+\t\tvvalLoop8 = vseed8;\n+\n+\t\tsize--;\n+\t\tsize >>= 7;\n+\t\tdo {\n+\t\t\tvval = vaeseq_u8(vval, vvalLoop);\n+\t\t\tvval = vaesmcq_u8(vval);\n+\t\t\tvval2 = vaeseq_u8(vval2, vvalLoop2);\n+\t\t\tvval2 = vaesmcq_u8(vval2);\n+\t\t\tvval3 = vaeseq_u8(vval3, vvalLoop3);\n+\t\t\tvval3 = vaesmcq_u8(vval3);\n+\t\t\tvval4 = vaeseq_u8(vval4, vvalLoop4);\n+\t\t\tvval4 = vaesmcq_u8(vval4);\n+\t\t\tvval5 = vaeseq_u8(vval5, vvalLoop5);\n+\t\t\tvval5 = vaesmcq_u8(vval5);\n+\t\t\tvval6 = vaeseq_u8(vval6, vvalLoop6);\n+\t\t\tvval6 = vaesmcq_u8(vval6);\n+\t\t\tvval7 = vaeseq_u8(vval7, vvalLoop7);\n+\t\t\tvval7 = vaesmcq_u8(vval7);\n+\t\t\tvval8 = vaeseq_u8(vval8, vvalLoop8);\n+\t\t\tvval8 = vaesmcq_u8(vval8);\n+\n+\t\t\tavval2 = vld1q_u8_x2((uint8*)(p));\n+\t\t\tvvalLoop = avval2.val[0];\n+\t\t\tvvalLoop2 = avval2.val[1];\n+\t\t\tavval2 = vld1q_u8_x2((uint8*)(p) + 32);\n+\t\t\tvvalLoop3 = avval2.val[0];\n+\t\t\tvvalLoop4 = avval2.val[1];\n+\t\t\tavval2 = vld1q_u8_x2((uint8*)(p) + 64);\n+\t\t\tvvalLoop5 = avval2.val[0];\n+\t\t\tvvalLoop6 = avval2.val[1];\n+\t\t\tavval2 = vld1q_u8_x2((uint8*)(p) + 96);\n+\t\t\tvvalLoop7 = avval2.val[0];\n+\t\t\tvvalLoop8 = avval2.val[1];\n+\n+\t\t\tp = (void *)((uint8*)(p) + 128);\n+\n+\t\t\tvval = vaeseq_u8(vval, vvalLoop);\n+\t\t\tvval = vaesmcq_u8(vval);\n+\t\t\tvval2 = vaeseq_u8(vval2, vvalLoop2);\n+\t\t\tvval2 = vaesmcq_u8(vval2);\n+\t\t\tvval3 = vaeseq_u8(vval3, vvalLoop3);\n+\t\t\tvval3 = vaesmcq_u8(vval3);\n+\t\t\tvval4 = vaeseq_u8(vval4, vvalLoop4);\n+\t\t\tvval4 = vaesmcq_u8(vval4);\n+\t\t\tvval5 = vaeseq_u8(vval5, vvalLoop5);\n+\t\t\tvval5 = vaesmcq_u8(vval5);\n+\t\t\tvval6 = vaeseq_u8(vval6, vvalLoop6);\n+\t\t\tvval6 = vaesmcq_u8(vval6);\n+\t\t\tvval7 = vaeseq_u8(vval7, vvalLoop7);\n+\t\t\tvval7 = vaesmcq_u8(vval7);\n+\t\t\tvval8 = vaeseq_u8(vval8, vvalLoop8);\n+\t\t\tvval8 = vaesmcq_u8(vval8);\n+\t\t} while (--size > 0);\n+\n+\t\tvval = vaeseq_u8(vval, vvalLoop);\n+\t\tvval = vaesmcq_u8(vval);\n+\t\tvval2 = vaeseq_u8(vval2, vvalLoop2);\n+\t\tvval2 = vaesmcq_u8(vval2);\n+\t\tvval3 = vaeseq_u8(vval3, vvalLoop3);\n+\t\tvval3 = vaesmcq_u8(vval3);\n+\t\tvval4 = vaeseq_u8(vval4, vvalLoop4);\n+\t\tvval4 = vaesmcq_u8(vval4);\n+\t\tvval5 = vaeseq_u8(vval5, vvalLoop5);\n+\t\tvval5 = vaesmcq_u8(vval5);\n+\t\tvval6 = vaeseq_u8(vval6, vvalLoop6);\n+\t\tvval6 = vaesmcq_u8(vval6);\n+\t\tvval7 = vaeseq_u8(vval7, vvalLoop7);\n+\t\tvval7 = vaesmcq_u8(vval7);\n+\t\tvval8 = vaeseq_u8(vval8, vvalLoop8);\n+\t\tvval8 = vaesmcq_u8(vval8);\n+\n+\n+\t\tvval = vaeseq_u8(vval, vvalLoop);\n+\t\tvval = vaesmcq_u8(vval);\n+\t\tvval2 = vaeseq_u8(vval2, vvalLoop2);\n+\t\tvval2 = vaesmcq_u8(vval2);\n+\t\tvval3 = vaeseq_u8(vval3, vvalLoop3);\n+\t\tvval3 = vaesmcq_u8(vval3);\n+\t\tvval4 = vaeseq_u8(vval4, vvalLoop4);\n+\t\tvval4 = vaesmcq_u8(vval4);\n+\t\tvval5 = vaeseq_u8(vval5, vvalLoop5);\n+\t\tvval5 = vaesmcq_u8(vval5);\n+\t\tvval6 = vaeseq_u8(vval6, vvalLoop6);\n+\t\tvval6 = vaesmcq_u8(vval6);\n+\t\tvval7 = vaeseq_u8(vval7, vvalLoop7);\n+\t\tvval7 = vaesmcq_u8(vval7);\n+\t\tvval8 = vaeseq_u8(vval8, vvalLoop8);\n+\t\tvval8 = vaesmcq_u8(vval8);\n+\n+\t\tvval = vaeseq_u8(vval, vvalLoop);\n+\t\tvval2 = vaeseq_u8(vval2, vvalLoop2);\n+\t\tvval3 = vaeseq_u8(vval3, vvalLoop3);\n+\t\tvval4 = vaeseq_u8(vval4, vvalLoop4);\n+\t\tvval5 = vaeseq_u8(vval5, vvalLoop5);\n+\t\tvval6 = vaeseq_u8(vval6, vvalLoop6);\n+\t\tvval7 = vaeseq_u8(vval7, vvalLoop7);\n+\t\tvval8 = vaeseq_u8(vval8, vvalLoop8);\n+\n+\t\tvval ^= vval5;\n+\t\tvval2 ^= vval6;\n+\t\tvval3 ^= vval7;\n+\t\tvval4 ^= vval8;\n+\t\tvval ^= vval3;\n+\t\tvval2 ^= vval4;\n+\t\tvval ^= vval2;\n+\n+\t\treturn vreinterpretq_u64_u8(vval)[0];\n+\t}\n+}\n+\n+#else // (!defined(__i386__) && !defined(__x86_64__) || !defined(HAVE_AS_X86_AES)) && !defined(__aarch64__)\n \n uintptr aeshashbody(void* p __attribute__((unused)),\n \t\t    uintptr seed __attribute__((unused)),\n \t\t    uintptr size __attribute__((unused)),\n \t\t    Slice aeskeysched __attribute__((unused))) {\n-\t// We should never get here on a non-x86 system.\n+\t// We should never get here on a non-x86, non-arm64 system.\n \truntime_throw(\"impossible call to aeshashbody\");\n }\n "}]}