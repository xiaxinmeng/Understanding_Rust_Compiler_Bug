{"sha": "44037a668cee3bcdf1121c517e3598e6a6ea3dd2", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NDQwMzdhNjY4Y2VlM2JjZGYxMTIxYzUxN2UzNTk4ZTZhNmVhM2RkMg==", "commit": {"author": {"name": "Torbjorn Granlund", "email": "tege@gnu.org", "date": "1992-03-06T19:37:23Z"}, "committer": {"name": "Torbjorn Granlund", "email": "tege@gnu.org", "date": "1992-03-06T19:37:23Z"}, "message": "Initial revision\n\nFrom-SVN: r401", "tree": {"sha": "049e08051cfaa88fb0945cb2bf94fc220b4401f7", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/049e08051cfaa88fb0945cb2bf94fc220b4401f7"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/44037a668cee3bcdf1121c517e3598e6a6ea3dd2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/44037a668cee3bcdf1121c517e3598e6a6ea3dd2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/44037a668cee3bcdf1121c517e3598e6a6ea3dd2", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/44037a668cee3bcdf1121c517e3598e6a6ea3dd2/comments", "author": null, "committer": null, "parents": [{"sha": "59be9a360f4c904a4f773d0ead641b5173e3d7ea", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/59be9a360f4c904a4f773d0ead641b5173e3d7ea", "html_url": "https://github.com/Rust-GCC/gccrs/commit/59be9a360f4c904a4f773d0ead641b5173e3d7ea"}], "stats": {"total": 2946, "additions": 2946, "deletions": 0}, "files": [{"sha": "f0b24a002286aee164b5b808f0dd2d0e2e812688", "filename": "gcc/expmed.c", "status": "added", "additions": 2946, "deletions": 0, "changes": 2946, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/44037a668cee3bcdf1121c517e3598e6a6ea3dd2/gcc%2Fexpmed.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/44037a668cee3bcdf1121c517e3598e6a6ea3dd2/gcc%2Fexpmed.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpmed.c?ref=44037a668cee3bcdf1121c517e3598e6a6ea3dd2", "patch": "@@ -0,0 +1,2946 @@\n+/* Medium-level subroutines: convert bit-field store and extract\n+   and shifts, multiplies and divides to rtl instructions.\n+   Copyright (C) 1987, 1988, 1989, 1992 Free Software Foundation, Inc.\n+\n+This file is part of GNU CC.\n+\n+GNU CC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 2, or (at your option)\n+any later version.\n+\n+GNU CC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GNU CC; see the file COPYING.  If not, write to\n+the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.  */\n+\n+\n+#include \"config.h\"\n+#include \"rtl.h\"\n+#include \"tree.h\"\n+#include \"flags.h\"\n+#include \"insn-flags.h\"\n+#include \"insn-codes.h\"\n+#include \"insn-config.h\"\n+#include \"expr.h\"\n+#include \"real.h\"\n+#include \"recog.h\"\n+\n+static rtx extract_split_bit_field ();\n+static rtx extract_fixed_bit_field ();\n+static void store_split_bit_field ();\n+static void store_fixed_bit_field ();\n+static rtx mask_rtx ();\n+static rtx lshift_value ();\n+\n+#define CEIL(x,y) (((x) + (y) - 1) / (y))\n+\n+/* Non-zero means multiply instructions are cheaper than shifts.  */\n+int mult_is_very_cheap;\n+\n+/* Non-zero means divides or modulus operations are relatively cheap for\n+   powers of two, so don't use branches; emit the operation instead. \n+   Usually, this will mean that the MD file will emit non-branch\n+   sequences.  */\n+\n+static int sdiv_pow2_cheap, smod_pow2_cheap;\n+\n+/* Cost of various pieces of RTL.  */\n+static int add_cost, shift_cost, mult_cost, negate_cost, lea_cost;\n+\n+/* Max scale factor for scaled address in lea instruction.  */\n+static int lea_max_mul;\n+\n+void\n+init_expmed ()\n+{\n+  char *free_point = (char *) oballoc (1);\n+  /* This is \"some random pseudo register\" for purposes of calling recog\n+     to see what insns exist.  */\n+  rtx reg = gen_rtx (REG, word_mode, FIRST_PSEUDO_REGISTER);\n+  rtx pow2 = gen_rtx (CONST_INT, VOIDmode, 32);\n+  rtx lea;\n+  int i, dummy;\n+\n+  add_cost = rtx_cost (gen_rtx (PLUS, word_mode, reg, reg));\n+  shift_cost = rtx_cost (gen_rtx (LSHIFT, word_mode, reg,\n+\t\t\t\t  /* Using a constant gives better\n+\t\t\t\t     estimate of typical costs.\n+\t\t\t\t     1 or 2 might have quirks.  */\n+\t\t\t\t  gen_rtx (CONST_INT, VOIDmode, 3)));\n+  mult_cost = rtx_cost (gen_rtx (MULT, word_mode, reg, reg));\n+  negate_cost = rtx_cost (gen_rtx (NEG, word_mode, reg));\n+\n+  mult_is_very_cheap\n+    = (rtx_cost (gen_rtx (MULT, word_mode, reg,\n+\t\t\t  gen_rtx (CONST_INT, VOIDmode, 128)))\n+       < rtx_cost (gen_rtx (LSHIFT, word_mode, reg,\n+\t\t\t    gen_rtx (CONST_INT, VOIDmode, 7))));\n+\n+  sdiv_pow2_cheap\n+    = rtx_cost (gen_rtx (DIV, word_mode, reg, pow2)) <= 2 * add_cost;\n+  smod_pow2_cheap\n+    = rtx_cost (gen_rtx (MOD, word_mode, reg, pow2)) <= 2 * add_cost;\n+\n+  init_recog ();\n+  for (i = 2;; i <<= 1)\n+    {\n+      lea = gen_rtx (SET, VOIDmode, reg,\n+\t\t     gen_rtx (PLUS, word_mode, reg,\n+\t\t\t      gen_rtx (MULT, word_mode, reg,\n+\t\t\t\t       gen_rtx (CONST_INT, VOIDmode, i))));\n+      /* Using 0 as second argument is not quite right,\n+\t but what else is there to do?  */\n+      if (recog (lea, 0, &dummy) < 0)\n+\tbreak;\n+      lea_max_mul = i;\n+      lea_cost = rtx_cost (SET_SRC (lea));\n+    }\n+\n+  /* Free the objects we just allocated.  */\n+  obfree (free_point);\n+}\n+\n+/* Return an rtx representing minus the value of X.\n+   MODE is the intended mode of the result,\n+   useful if X is a CONST_INT.  */\n+\n+rtx\n+negate_rtx (mode, x)\n+     enum machine_mode mode;\n+     rtx x;\n+{\n+  if (GET_CODE (x) == CONST_INT)\n+    {\n+      int val = - INTVAL (x);\n+      if (GET_MODE_BITSIZE (mode) < HOST_BITS_PER_INT)\n+\t{\n+\t  /* Sign extend the value from the bits that are significant.  */\n+\t  if (val & (1 << (GET_MODE_BITSIZE (mode) - 1)))\n+\t    val |= (-1) << GET_MODE_BITSIZE (mode);\n+\t  else\n+\t    val &= (1 << GET_MODE_BITSIZE (mode)) - 1;\n+\t}\n+      return gen_rtx (CONST_INT, VOIDmode, val);\n+    }\n+  else\n+    return expand_unop (GET_MODE (x), neg_optab, x, 0, 0);\n+}\n+\f\n+/* Generate code to store value from rtx VALUE\n+   into a bit-field within structure STR_RTX\n+   containing BITSIZE bits starting at bit BITNUM.\n+   FIELDMODE is the machine-mode of the FIELD_DECL node for this field.\n+   ALIGN is the alignment that STR_RTX is known to have, measured in bytes.\n+   TOTAL_SIZE is the size of the structure in bytes, or -1 if varying.  */\n+\n+/* ??? Note that there are two different ideas here for how\n+   to determine the size to count bits within, for a register.\n+   One is BITS_PER_WORD, and the other is the size of operand 3\n+   of the insv pattern.  (The latter assumes that an n-bit machine\n+   will be able to insert bit fields up to n bits wide.)\n+   It isn't certain that either of these is right.\n+   extract_bit_field has the same quandary.  */\n+\n+rtx\n+store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, align, total_size)\n+     rtx str_rtx;\n+     register int bitsize;\n+     int bitnum;\n+     enum machine_mode fieldmode;\n+     rtx value;\n+     int align;\n+     int total_size;\n+{\n+  int unit = (GET_CODE (str_rtx) == MEM) ? BITS_PER_UNIT : BITS_PER_WORD;\n+  register int offset = bitnum / unit;\n+  register int bitpos = bitnum % unit;\n+  register rtx op0 = str_rtx;\n+\n+  if (GET_CODE (str_rtx) == MEM && ! MEM_IN_STRUCT_P (str_rtx))\n+    abort ();\n+\n+  /* Discount the part of the structure before the desired byte.\n+     We need to know how many bytes are safe to reference after it.  */\n+  if (total_size >= 0)\n+    total_size -= (bitpos / BIGGEST_ALIGNMENT\n+\t\t   * (BIGGEST_ALIGNMENT / BITS_PER_UNIT));\n+\n+  while (GET_CODE (op0) == SUBREG)\n+    {\n+      /* The following line once was done only if WORDS_BIG_ENDIAN,\n+\t but I think that is a mistake.  WORDS_BIG_ENDIAN is\n+\t meaningful at a much higher level; when structures are copied\n+\t between memory and regs, the higher-numbered regs\n+\t always get higher addresses.  */\n+      offset += SUBREG_WORD (op0);\n+      /* We used to adjust BITPOS here, but now we do the whole adjustment\n+\t right after the loop.  */\n+      op0 = SUBREG_REG (op0);\n+    }\n+\n+#if BYTES_BIG_ENDIAN\n+  /* If OP0 is a register, BITPOS must count within a word.\n+     But as we have it, it counts within whatever size OP0 now has.\n+     On a bigendian machine, these are not the same, so convert.  */\n+  if (GET_CODE (op0) != MEM && unit > GET_MODE_BITSIZE (GET_MODE (op0)))\n+    bitpos += unit - GET_MODE_BITSIZE (GET_MODE (op0));\n+#endif\n+\n+  value = protect_from_queue (value, 0);\n+\n+  if (flag_force_mem)\n+    value = force_not_mem (value);\n+\n+  /* Note that the adjustment of BITPOS above has no effect on whether\n+     BITPOS is 0 in a REG bigger than a word.  */\n+  if (GET_MODE_SIZE (fieldmode) >= UNITS_PER_WORD && GET_CODE (op0) != MEM\n+      && bitpos == 0 && bitsize == GET_MODE_BITSIZE (fieldmode))\n+    {\n+      /* Storing in a full-word or multi-word field in a register\n+\t can be done with just SUBREG.  */\n+      if (GET_MODE (op0) != fieldmode)\n+\top0 = gen_rtx (SUBREG, fieldmode, op0, offset);\n+      emit_move_insn (op0, value);\n+      return value;\n+    }\n+\n+  /* Storing an lsb-aligned field in a register\n+     can be done with a movestrict instruction.  */\n+\n+  if (GET_CODE (op0) != MEM\n+#if BYTES_BIG_ENDIAN\n+      && bitpos + bitsize == unit\n+#else\n+      && bitpos == 0\n+#endif\n+      && bitsize == GET_MODE_BITSIZE (fieldmode)\n+      && (GET_MODE (op0) == fieldmode\n+\t  || (movstrict_optab->handlers[(int) fieldmode].insn_code\n+\t      != CODE_FOR_nothing)))\n+    {\n+      /* Get appropriate low part of the value being stored.  */\n+      if (GET_CODE (value) == CONST_INT || GET_CODE (value) == REG)\n+\tvalue = gen_lowpart (fieldmode, value);\n+      else if (!(GET_CODE (value) == SYMBOL_REF\n+\t\t || GET_CODE (value) == LABEL_REF\n+\t\t || GET_CODE (value) == CONST))\n+\tvalue = convert_to_mode (fieldmode, value, 0);\n+\n+      if (GET_MODE (op0) == fieldmode)\n+\temit_move_insn (op0, value);\n+      else\n+\t{\n+\t  int icode = movstrict_optab->handlers[(int) fieldmode].insn_code;\n+\t  if(! (*insn_operand_predicate[icode][1]) (value, fieldmode))\n+\t    value = copy_to_mode_reg (fieldmode, value);\n+\t  emit_insn (GEN_FCN (icode)\n+\t\t   (gen_rtx (SUBREG, fieldmode, op0, offset), value));\n+\t}\n+      return value;\n+    }\n+\n+  /* Handle fields bigger than a word.  */\n+\n+  if (bitsize > BITS_PER_WORD)\n+    {\n+      /* Here we transfer the words of the field\n+\t in the order least significant first.\n+\t This is because the most significant word is the one which may\n+\t be less than full.  */\n+\n+      int nwords = (bitsize + (BITS_PER_WORD - 1)) / BITS_PER_WORD;\n+      int i;\n+\n+      /* This is the mode we must force value to, so that there will be enough\n+\t subwords to extract.  Note that fieldmode will often (always?) be\n+\t VOIDmode, because that is what store_field uses to indicate that this\n+\t is a bit field, but passing VOIDmode to operand_subword_force will\n+\t result in an abort.  */\n+      fieldmode = mode_for_size (nwords * BITS_PER_WORD, MODE_INT, 0);\n+\n+      for (i = 0; i < nwords; i++)\n+\t{\n+\t  /* If I is 0, use the low-order word in both field and target;\n+\t     if I is 1, use the next to lowest word; and so on.  */\n+\t  int wordnum = (WORDS_BIG_ENDIAN ? nwords - i - 1 : i);\n+\t  int bit_offset = (WORDS_BIG_ENDIAN\n+\t\t\t    ? MAX (bitsize - (i + 1) * BITS_PER_WORD, 0)\n+\t\t\t    : i * BITS_PER_WORD);\n+\t  store_bit_field (op0, MIN (BITS_PER_WORD,\n+\t\t\t\t     bitsize - i * BITS_PER_WORD),\n+\t\t\t   bitnum + bit_offset, word_mode,\n+\t\t\t   operand_subword_force (value, wordnum, fieldmode),\n+\t\t\t   align, total_size);\n+\t}\n+      return value;\n+    }\n+\n+  /* From here on we can assume that the field to be stored in is\n+     a full-word (whatever type that is), since it is shorter than a word.  */\n+\n+  /* OFFSET is the number of words or bytes (UNIT says which)\n+     from STR_RTX to the first word or byte containing part of the field.  */\n+\n+  if (GET_CODE (op0) == REG)\n+    {\n+      if (offset != 0\n+\t  || GET_MODE_SIZE (GET_MODE (op0)) > UNITS_PER_WORD)\n+\top0 = gen_rtx (SUBREG, TYPE_MODE (type_for_size (BITS_PER_WORD, 0)),\n+\t\t       op0, offset);\n+      offset = 0;\n+    }\n+  else\n+    {\n+      op0 = protect_from_queue (op0, 1);\n+    }\n+\n+  /* Now OFFSET is nonzero only if OP0 is memory\n+     and is therefore always measured in bytes.  */\n+\n+#ifdef HAVE_insv\n+  if (HAVE_insv\n+      && !(bitsize == 1 && GET_CODE (value) == CONST_INT)\n+      /* Ensure insv's size is wide enough for this field.  */\n+      && (GET_MODE_BITSIZE (insn_operand_mode[(int) CODE_FOR_insv][3])\n+\t  >= bitsize))\n+    {\n+      int xbitpos = bitpos;\n+      rtx value1;\n+      rtx xop0 = op0;\n+      rtx last = get_last_insn ();\n+      rtx pat;\n+      enum machine_mode maxmode\n+\t= insn_operand_mode[(int) CODE_FOR_insv][3];\n+\n+      int save_volatile_ok = volatile_ok;\n+      volatile_ok = 1;\n+\n+      /* If this machine's insv can only insert into a register, or if we\n+\t are to force MEMs into a register, copy OP0 into a register and\n+\t save it back later.  */\n+      if (GET_CODE (op0) == MEM\n+\t  && (flag_force_mem\n+\t      || ! ((*insn_operand_predicate[(int) CODE_FOR_insv][0])\n+\t\t    (op0, VOIDmode))))\n+\t{\n+\t  rtx tempreg;\n+\t  enum machine_mode bestmode;\n+\n+\t  /* Get the mode to use for inserting into this field.  If OP0 is\n+\t     BLKmode, get the smallest mode consistent with the alignment. If\n+\t     OP0 is a non-BLKmode object that is no wider than MAXMODE, use its\n+\t     mode. Otherwise, use the smallest mode containing the field.  */\n+\n+\t  if (GET_MODE (op0) == BLKmode\n+\t      || GET_MODE_SIZE (GET_MODE (op0)) > GET_MODE_SIZE (maxmode))\n+\t    bestmode\n+\t      = get_best_mode (bitsize, bitnum,\n+\t\t\t       align * BITS_PER_UNIT, maxmode,\n+\t\t\t       GET_CODE (op0) == MEM && MEM_VOLATILE_P (op0));\n+\t  else\n+\t    bestmode = GET_MODE (op0);\n+\n+\t  if (bestmode == VOIDmode)\n+\t    goto insv_loses;\n+\n+\t  /* Adjust address to point to the containing unit of that mode.  */\n+\t  unit = GET_MODE_BITSIZE (bestmode);\n+\t  /* Compute offset as multiple of this unit, counting in bytes.  */\n+\t  offset = (bitnum / unit) * GET_MODE_SIZE (bestmode);\n+\t  bitpos = bitnum % unit;\n+\t  op0 = change_address (op0, bestmode, \n+\t\t\t\tplus_constant (XEXP (op0, 0), offset));\n+\n+\t  /* Fetch that unit, store the bitfield in it, then store the unit.  */\n+\t  tempreg = copy_to_reg (op0);\n+\t  store_bit_field (tempreg, bitsize, bitpos, fieldmode, value,\n+\t\t\t   align, total_size);\n+\t  emit_move_insn (op0, tempreg);\n+\t  return value;\n+\t}\n+      volatile_ok = save_volatile_ok;\n+\n+      /* Add OFFSET into OP0's address.  */\n+      if (GET_CODE (xop0) == MEM)\n+\txop0 = change_address (xop0, byte_mode,\n+\t\t\t       plus_constant (XEXP (xop0, 0), offset));\n+\n+      /* If xop0 is a register, we need it in MAXMODE\n+\t to make it acceptable to the format of insv.  */\n+      if (GET_CODE (xop0) == SUBREG)\n+\tPUT_MODE (xop0, maxmode);\n+      if (GET_CODE (xop0) == REG && GET_MODE (xop0) != maxmode)\n+\txop0 = gen_rtx (SUBREG, maxmode, xop0, 0);\n+\n+      /* On big-endian machines, we count bits from the most significant.\n+\t If the bit field insn does not, we must invert.  */\n+\n+#if BITS_BIG_ENDIAN != BYTES_BIG_ENDIAN\n+      xbitpos = unit - bitsize - xbitpos;\n+#endif\n+      /* We have been counting XBITPOS within UNIT.\n+\t Count instead within the size of the register.  */\n+#if BITS_BIG_ENDIAN\n+      if (GET_CODE (xop0) != MEM)\n+\txbitpos += GET_MODE_BITSIZE (maxmode) - unit;\n+#endif\n+      unit = GET_MODE_BITSIZE (maxmode);\n+\n+      /* Convert VALUE to maxmode (which insv insn wants) in VALUE1.  */\n+      value1 = value;\n+      if (GET_MODE (value) != maxmode)\n+\t{\n+\t  if (GET_MODE_BITSIZE (GET_MODE (value)) >= bitsize)\n+\t    {\n+\t      /* Optimization: Don't bother really extending VALUE\n+\t\t if it has all the bits we will actually use.  */\n+\n+\t      /* Avoid making subreg of a subreg, or of a mem.  */\n+\t      if (GET_CODE (value1) != REG)\n+\t\tvalue1 = copy_to_reg (value1);\n+\t      value1 = gen_rtx (SUBREG, maxmode, value1, 0);\n+\t    }\n+\t  else if (!CONSTANT_P (value))\n+\t    /* Parse phase is supposed to make VALUE's data type\n+\t       match that of the component reference, which is a type\n+\t       at least as wide as the field; so VALUE should have\n+\t       a mode that corresponds to that type.  */\n+\t    abort ();\n+\t}\n+\n+      /* If this machine's insv insists on a register,\n+\t get VALUE1 into a register.  */\n+      if (! ((*insn_operand_predicate[(int) CODE_FOR_insv][3])\n+\t     (value1, maxmode)))\n+\tvalue1 = force_reg (maxmode, value1);\n+\n+      pat = gen_insv (xop0,\n+\t\t      gen_rtx (CONST_INT, VOIDmode, bitsize),\n+\t\t      gen_rtx (CONST_INT, VOIDmode, xbitpos),\n+\t\t      value1);\n+      if (pat)\n+\temit_insn (pat);\n+      else\n+        {\n+\t  delete_insns_since (last);\n+\t  store_fixed_bit_field (op0, offset, bitsize, bitpos, value, align);\n+\t}\n+    }\n+  else\n+    insv_loses:\n+#endif\n+    /* Insv is not available; store using shifts and boolean ops.  */\n+    store_fixed_bit_field (op0, offset, bitsize, bitpos, value, align);\n+  return value;\n+}\n+\f\n+/* Use shifts and boolean operations to store VALUE\n+   into a bit field of width BITSIZE\n+   in a memory location specified by OP0 except offset by OFFSET bytes.\n+     (OFFSET must be 0 if OP0 is a register.)\n+   The field starts at position BITPOS within the byte.\n+    (If OP0 is a register, it may be a full word or a narrower mode,\n+     but BITPOS still counts within a full word,\n+     which is significant on bigendian machines.)\n+   STRUCT_ALIGN is the alignment the structure is known to have (in bytes).\n+\n+   Note that protect_from_queue has already been done on OP0 and VALUE.  */\n+\n+static void\n+store_fixed_bit_field (op0, offset, bitsize, bitpos, value, struct_align)\n+     register rtx op0;\n+     register int offset, bitsize, bitpos;\n+     register rtx value;\n+     int struct_align;\n+{\n+  register enum machine_mode mode;\n+  int total_bits = BITS_PER_WORD;\n+  rtx subtarget, temp;\n+  int all_zero = 0;\n+  int all_one = 0;\n+\n+  /* Add OFFSET to OP0's address (if it is in memory)\n+     and if a single byte contains the whole bit field\n+     change OP0 to a byte.  */\n+\n+  /* There is a case not handled here:\n+     a structure with a known alignment of just a halfword\n+     and a field split across two aligned halfwords within the structure.\n+     Or likewise a structure with a known alignment of just a byte\n+     and a field split across two bytes.\n+     Such cases are not supposed to be able to occur.  */\n+\n+  if (GET_CODE (op0) == REG || GET_CODE (op0) == SUBREG)\n+    {\n+      if (offset != 0)\n+\tabort ();\n+      /* Special treatment for a bit field split across two registers.  */\n+      if (bitsize + bitpos > BITS_PER_WORD)\n+\t{\n+\t  store_split_bit_field (op0, bitsize, bitpos, value, BITS_PER_WORD);\n+\t  return;\n+\t}\n+    }\n+  else\n+    {\n+      /* Get the proper mode to use for this field.  We want a mode that\n+\t includes the entire field.  If such a mode would be larger than\n+\t a word, we won't be doing the extraction the normal way.  */\n+\n+      mode = get_best_mode (bitsize, bitpos + offset * BITS_PER_UNIT,\n+\t\t\t    struct_align * BITS_PER_UNIT, word_mode,\n+\t\t\t    GET_CODE (op0) == MEM && MEM_VOLATILE_P (op0));\n+\n+      if (mode == VOIDmode)\n+\t{\n+\t  /* The only way this should occur is if the field spans word\n+\t     boundaries.  */\n+\t  store_split_bit_field (op0, bitsize, bitpos + offset * BITS_PER_UNIT,\n+\t\t\t\t value, struct_align);\n+\t  return;\n+\t}\n+\n+      total_bits = GET_MODE_BITSIZE (mode);\n+\n+      /* Get ref to an aligned byte, halfword, or word containing the field.\n+\t Adjust BITPOS to be position within a word,\n+\t and OFFSET to be the offset of that word.\n+\t Then alter OP0 to refer to that word.  */\n+      bitpos += (offset % (total_bits / BITS_PER_UNIT)) * BITS_PER_UNIT;\n+      offset -= (offset % (total_bits / BITS_PER_UNIT));\n+      op0 = change_address (op0, mode,\n+\t\t\t    plus_constant (XEXP (op0, 0), offset));\n+    }\n+\n+  mode = GET_MODE (op0);\n+\n+  /* Now MODE is either some integral mode for a MEM as OP0,\n+     or is a full-word for a REG as OP0.  TOTAL_BITS corresponds.\n+     The bit field is contained entirely within OP0.\n+     BITPOS is the starting bit number within OP0.\n+     (OP0's mode may actually be narrower than MODE.)  */\n+\n+#if BYTES_BIG_ENDIAN\n+  /* BITPOS is the distance between our msb\n+     and that of the containing datum.\n+     Convert it to the distance from the lsb.  */\n+\n+  bitpos = total_bits - bitsize - bitpos;\n+#endif\n+  /* Now BITPOS is always the distance between our lsb\n+     and that of OP0.  */\n+\n+  /* Shift VALUE left by BITPOS bits.  If VALUE is not constant,\n+     we must first convert its mode to MODE.  */\n+\n+  if (GET_CODE (value) == CONST_INT)\n+    {\n+      register int v = INTVAL (value);\n+\n+      if (bitsize < HOST_BITS_PER_INT)\n+\tv &= (1 << bitsize) - 1;\n+\n+      if (v == 0)\n+\tall_zero = 1;\n+      else if ((bitsize < HOST_BITS_PER_INT && v == (1 << bitsize) - 1)\n+\t       || (bitsize == HOST_BITS_PER_INT && v == -1))\n+\tall_one = 1;\n+\n+      value = lshift_value (mode, value, bitpos, bitsize);\n+    }\n+  else\n+    {\n+      int must_and = (GET_MODE_BITSIZE (GET_MODE (value)) != bitsize\n+\t\t      && bitpos + bitsize != GET_MODE_BITSIZE (mode));\n+\n+      if (GET_MODE (value) != mode)\n+\t{\n+\t  /* If VALUE is a floating-point mode, access it as an integer\n+\t     of the corresponding size, then convert it.  This can occur on\n+\t     a machine with 64 bit registers that uses SFmode for float.  */\n+\t  if (GET_MODE_CLASS (GET_MODE (value)) == MODE_FLOAT)\n+\t    {\n+\t      if (GET_CODE (value) != REG)\n+\t\tvalue = copy_to_reg (value);\n+\t      value\n+\t\t= gen_rtx (SUBREG, word_mode, value, 0);\n+\t    }\n+\n+\t  if ((GET_CODE (value) == REG || GET_CODE (value) == SUBREG)\n+\t      && GET_MODE_SIZE (mode) < GET_MODE_SIZE (GET_MODE (value)))\n+\t    value = gen_lowpart (mode, value);\n+\t  else\n+\t    value = convert_to_mode (mode, value, 1);\n+\t}\n+\n+      if (must_and)\n+\tvalue = expand_binop (mode, and_optab, value,\n+\t\t\t      mask_rtx (mode, 0, bitsize, 0),\n+\t\t\t      0, 1, OPTAB_LIB_WIDEN);\n+      if (bitpos > 0)\n+\tvalue = expand_shift (LSHIFT_EXPR, mode, value,\n+\t\t\t      build_int_2 (bitpos, 0), 0, 1);\n+    }\n+\n+  /* Now clear the chosen bits in OP0,\n+     except that if VALUE is -1 we need not bother.  */\n+\n+  subtarget = (GET_CODE (op0) == REG || ! flag_force_mem) ? op0 : 0;\n+\n+  if (! all_one)\n+    {\n+      temp = expand_binop (mode, and_optab, op0,\n+\t\t\t   mask_rtx (mode, bitpos, bitsize, 1),\n+\t\t\t   subtarget, 1, OPTAB_LIB_WIDEN);\n+      subtarget = temp;\n+    }\n+  else\n+    temp = op0;\n+\n+  /* Now logical-or VALUE into OP0, unless it is zero.  */\n+\n+  if (! all_zero)\n+    temp = expand_binop (mode, ior_optab, temp, value,\n+\t\t\t subtarget, 1, OPTAB_LIB_WIDEN);\n+  if (op0 != temp)\n+    emit_move_insn (op0, temp);\n+}\n+\f\n+/* Store a bit field that is split across two words.\n+\n+   OP0 is the REG, SUBREG or MEM rtx for the first of the two words.\n+   BITSIZE is the field width; BITPOS the position of its first bit\n+   (within the word).\n+   VALUE is the value to store.  */\n+\n+static void\n+store_split_bit_field (op0, bitsize, bitpos, value, align)\n+     rtx op0;\n+     int bitsize, bitpos;\n+     rtx value;\n+     int align;\n+{\n+  /* BITSIZE_1 is size of the part in the first word.  */\n+  int bitsize_1 = BITS_PER_WORD - bitpos % BITS_PER_WORD;\n+  /* BITSIZE_2 is size of the rest (in the following word).  */\n+  int bitsize_2 = bitsize - bitsize_1;\n+  rtx part1, part2;\n+  int unit = GET_CODE (op0) == MEM ? BITS_PER_UNIT : BITS_PER_WORD;\n+  int offset = bitpos / unit;\n+  rtx word;\n+\n+  /* The field must span exactly one word boundary.  */\n+  if (bitpos / BITS_PER_WORD != (bitpos + bitsize - 1) / BITS_PER_WORD - 1)\n+    abort ();\n+\n+  if (GET_MODE (value) != VOIDmode)\n+    value = convert_to_mode (word_mode, value, 1);\n+  if (CONSTANT_P (value) && GET_CODE (value) != CONST_INT)\n+    value = copy_to_reg (value);\n+\n+  /* Split the value into two parts:\n+     PART1 gets that which goes in the first word; PART2 the other.  */\n+#if BYTES_BIG_ENDIAN\n+  /* PART1 gets the more significant part.  */\n+  if (GET_CODE (value) == CONST_INT)\n+    {\n+      part1 = gen_rtx (CONST_INT, VOIDmode,\n+\t\t       (unsigned) (INTVAL (value)) >> bitsize_2);\n+      part2 = gen_rtx (CONST_INT, VOIDmode,\n+\t\t       (unsigned) (INTVAL (value)) & ((1 << bitsize_2) - 1));\n+    }\n+  else\n+    {\n+      part1 = extract_fixed_bit_field (word_mode, value, 0, bitsize_1,\n+\t\t\t\t       BITS_PER_WORD - bitsize, 0, 1,\n+\t\t\t\t       BITS_PER_WORD);\n+      part2 = extract_fixed_bit_field (word_mode, value, 0, bitsize_2,\n+\t\t\t\t       BITS_PER_WORD - bitsize_2, 0, 1,\n+\t\t\t\t       BITS_PER_WORD);\n+    }\n+#else\n+  /* PART1 gets the less significant part.  */\n+  if (GET_CODE (value) == CONST_INT)\n+    {\n+      part1 = gen_rtx (CONST_INT, VOIDmode,\n+\t\t       (unsigned) (INTVAL (value)) & ((1 << bitsize_1) - 1));\n+      part2 = gen_rtx (CONST_INT, VOIDmode,\n+\t\t       (unsigned) (INTVAL (value)) >> bitsize_1);\n+    }\n+  else\n+    {\n+      part1 = extract_fixed_bit_field (word_mode, value, 0, bitsize_1, 0,\n+\t\t\t\t       0, 1, BITS_PER_WORD);\n+      part2 = extract_fixed_bit_field (word_mode, value, 0, bitsize_2,\n+\t\t\t\t       bitsize_1, 0, 1, BITS_PER_WORD);\n+    }\n+#endif\n+\n+  /* Store PART1 into the first word.  If OP0 is a MEM, pass OP0 and the\n+     offset computed above.  Otherwise, get the proper word and pass an\n+     offset of zero.  */\n+  word = (GET_CODE (op0) == MEM ? op0\n+\t  : operand_subword (op0, offset, 1, GET_MODE (op0)));\n+  if (word == 0)\n+    abort ();\n+\n+  store_fixed_bit_field (word, GET_CODE (op0) == MEM ? offset : 0,\n+\t\t\t bitsize_1, bitpos % unit, part1, align);\n+\n+  /* Offset op0 by 1 word to get to the following one.  */\n+  if (GET_CODE (op0) == SUBREG)\n+    word = operand_subword (SUBREG_REG (op0), SUBREG_WORD (op0) + offset + 1,\n+\t\t\t    1, VOIDmode);\n+  else if (GET_CODE (op0) == MEM)\n+    word = op0;\n+  else\n+    word = operand_subword (op0, offset + 1, 1, GET_MODE (op0));\n+\n+  if (word == 0)\n+    abort ();\n+\n+  /* Store PART2 into the second word.  */\n+  store_fixed_bit_field (word,\n+\t\t\t (GET_CODE (op0) == MEM\n+\t\t\t  ? CEIL (offset + 1, UNITS_PER_WORD) * UNITS_PER_WORD\n+\t\t\t  : 0),\n+\t\t\t bitsize_2, 0, part2, align);\n+}\n+\f\n+/* Generate code to extract a byte-field from STR_RTX\n+   containing BITSIZE bits, starting at BITNUM,\n+   and put it in TARGET if possible (if TARGET is nonzero).\n+   Regardless of TARGET, we return the rtx for where the value is placed.\n+   It may be a QUEUED.\n+\n+   STR_RTX is the structure containing the byte (a REG or MEM).\n+   UNSIGNEDP is nonzero if this is an unsigned bit field.\n+   MODE is the natural mode of the field value once extracted.\n+   TMODE is the mode the caller would like the value to have;\n+   but the value may be returned with type MODE instead.\n+\n+   ALIGN is the alignment that STR_RTX is known to have, measured in bytes.\n+   TOTAL_SIZE is the size in bytes of the containing structure,\n+   or -1 if varying.\n+\n+   If a TARGET is specified and we can store in it at no extra cost,\n+   we do so, and return TARGET.\n+   Otherwise, we return a REG of mode TMODE or MODE, with TMODE preferred\n+   if they are equally easy.  */\n+\n+rtx\n+extract_bit_field (str_rtx, bitsize, bitnum, unsignedp,\n+\t\t   target, mode, tmode, align, total_size)\n+     rtx str_rtx;\n+     register int bitsize;\n+     int bitnum;\n+     int unsignedp;\n+     rtx target;\n+     enum machine_mode mode, tmode;\n+     int align;\n+     int total_size;\n+{\n+  int unit = (GET_CODE (str_rtx) == MEM) ? BITS_PER_UNIT : BITS_PER_WORD;\n+  register int offset = bitnum / unit;\n+  register int bitpos = bitnum % unit;\n+  register rtx op0 = str_rtx;\n+  rtx spec_target = target;\n+  rtx spec_target_subreg = 0;\n+\n+  if (GET_CODE (str_rtx) == MEM && ! MEM_IN_STRUCT_P (str_rtx))\n+    abort ();\n+\n+  /* Discount the part of the structure before the desired byte.\n+     We need to know how many bytes are safe to reference after it.  */\n+  if (total_size >= 0)\n+    total_size -= (bitpos / BIGGEST_ALIGNMENT\n+\t\t   * (BIGGEST_ALIGNMENT / BITS_PER_UNIT));\n+\n+  if (tmode == VOIDmode)\n+    tmode = mode;\n+\n+  while (GET_CODE (op0) == SUBREG)\n+    {\n+      offset += SUBREG_WORD (op0);\n+      op0 = SUBREG_REG (op0);\n+    }\n+  \n+#if BYTES_BIG_ENDIAN\n+  /* If OP0 is a register, BITPOS must count within a word.\n+     But as we have it, it counts within whatever size OP0 now has.\n+     On a bigendian machine, these are not the same, so convert.  */\n+  if (GET_CODE (op0) != MEM && unit > GET_MODE_BITSIZE (GET_MODE (op0)))\n+    bitpos += unit - GET_MODE_BITSIZE (GET_MODE (op0));\n+#endif\n+\n+  /* Extracting a full-word or multi-word value\n+     from a structure in a register.\n+     This can be done with just SUBREG.\n+     So too extracting a subword value in\n+     the least significant part of the register.  */\n+\n+  if (GET_CODE (op0) == REG\n+      && ((bitsize >= BITS_PER_WORD && bitsize == GET_MODE_BITSIZE (mode)\n+\t   && bitpos % BITS_PER_WORD == 0)\n+\t  || (mode_for_size (bitsize, GET_MODE_CLASS (tmode), 0) != BLKmode\n+#if BYTES_BIG_ENDIAN\n+\t      && bitpos + bitsize == BITS_PER_WORD\n+#else\n+\t      && bitpos == 0\n+#endif\n+\t      )))\n+    {\n+      enum machine_mode mode1\n+\t= mode_for_size (bitsize, GET_MODE_CLASS (tmode), 0);\n+\n+      if (mode1 != GET_MODE (op0))\n+\top0 = gen_rtx (SUBREG, mode1, op0, offset);\n+\n+      if (mode1 != mode)\n+\treturn convert_to_mode (tmode, op0, unsignedp);\n+      return op0;\n+    }\n+\n+  /* Handle fields bigger than a word.  */\n+  \n+  if (bitsize > BITS_PER_WORD)\n+    {\n+      /* Here we transfer the words of the field\n+\t in the order least significant first.\n+\t This is because the most significant word is the one which may\n+\t be less than full.  */\n+\n+      int nwords = (bitsize + (BITS_PER_WORD - 1)) / BITS_PER_WORD;\n+      int i;\n+\n+      if (target == 0 || GET_CODE (target) != REG)\n+\ttarget = gen_reg_rtx (mode);\n+\n+      for (i = 0; i < nwords; i++)\n+\t{\n+\t  /* If I is 0, use the low-order word in both field and target;\n+\t     if I is 1, use the next to lowest word; and so on.  */\n+\t  int wordnum = (WORDS_BIG_ENDIAN ? nwords - i - 1 : i);\n+\t  int bit_offset = (WORDS_BIG_ENDIAN\n+\t\t\t    ? MAX (0, bitsize - (i + 1) * BITS_PER_WORD)\n+\t\t\t    : i * BITS_PER_WORD);\n+\t  rtx target_part = operand_subword (target, wordnum, 1, VOIDmode);\n+\t  rtx result_part\n+\t    = extract_bit_field (op0, MIN (BITS_PER_WORD,\n+\t\t\t\t\t   bitsize - i * BITS_PER_WORD),\n+\t\t\t\t bitnum + bit_offset,\n+\t\t\t\t 1, target_part, mode, word_mode,\n+\t\t\t\t align, total_size);\n+\n+\t  if (target_part == 0)\n+\t    abort ();\n+\n+\t  if (result_part != target_part)\n+\t    emit_move_insn (target_part, result_part);\n+\t}\n+\n+      return target;\n+    }\n+  \n+  /* From here on we know the desired field is smaller than a word\n+     so we can assume it is an integer.  So we can safely extract it as one\n+     size of integer, if necessary, and then truncate or extend\n+     to the size that is wanted.  */\n+\n+  /* OFFSET is the number of words or bytes (UNIT says which)\n+     from STR_RTX to the first word or byte containing part of the field.  */\n+\n+  if (GET_CODE (op0) == REG)\n+    {\n+      if (offset != 0\n+\t  || GET_MODE_SIZE (GET_MODE (op0)) > UNITS_PER_WORD)\n+\top0 = gen_rtx (SUBREG, TYPE_MODE (type_for_size (BITS_PER_WORD, 0)),\n+\t\t       op0, offset);\n+      offset = 0;\n+    }\n+  else\n+    {\n+      op0 = protect_from_queue (str_rtx, 1);\n+    }\n+\n+  /* Now OFFSET is nonzero only for memory operands.  */\n+\n+  if (unsignedp)\n+    {\n+#ifdef HAVE_extzv\n+      if (HAVE_extzv\n+\t  && (GET_MODE_BITSIZE (insn_operand_mode[(int) CODE_FOR_extzv][0])\n+\t      >= bitsize))\n+\t{\n+\t  int xbitpos = bitpos, xoffset = offset;\n+\t  rtx bitsize_rtx, bitpos_rtx;\n+\t  rtx last = get_last_insn();\n+\t  rtx xop0 = op0;\n+\t  rtx xtarget = target;\n+\t  rtx xspec_target = spec_target;\n+\t  rtx xspec_target_subreg = spec_target_subreg;\n+\t  rtx pat;\n+\t  enum machine_mode maxmode\n+\t    = insn_operand_mode[(int) CODE_FOR_extzv][0];\n+\n+\t  if (GET_CODE (xop0) == MEM)\n+\t    {\n+\t      int save_volatile_ok = volatile_ok;\n+\t      volatile_ok = 1;\n+\n+\t      /* Is the memory operand acceptable?  */\n+\t      if (flag_force_mem\n+\t\t  || ! ((*insn_operand_predicate[(int) CODE_FOR_extzv][1])\n+\t\t\t(xop0, GET_MODE (xop0))))\n+\t\t{\n+\t\t  /* No, load into a reg and extract from there.  */\n+\t\t  enum machine_mode bestmode;\n+\n+\t\t  /* Get the mode to use for inserting into this field.  If\n+\t\t     OP0 is BLKmode, get the smallest mode consistent with the\n+\t\t     alignment. If OP0 is a non-BLKmode object that is no\n+\t\t     wider than MAXMODE, use its mode. Otherwise, use the\n+\t\t     smallest mode containing the field.  */\n+\n+\t\t  if (GET_MODE (xop0) == BLKmode\n+\t\t      || (GET_MODE_SIZE (GET_MODE (op0))\n+\t\t\t  > GET_MODE_SIZE (maxmode)))\n+\t\t    bestmode = get_best_mode (bitsize, bitnum,\n+\t\t\t\t\t      align * BITS_PER_UNIT, maxmode,\n+\t\t\t\t\t      (GET_CODE (xop0) == MEM\n+\t\t\t\t\t       && MEM_VOLATILE_P (xop0)));\n+\t\t  else\n+\t\t    bestmode = GET_MODE (xop0);\n+\n+\t\t  if (bestmode == VOIDmode)\n+\t\t    goto extzv_loses;\n+\n+\t\t  /* Compute offset as multiple of this unit,\n+\t\t     counting in bytes.  */\n+\t\t  unit = GET_MODE_BITSIZE (bestmode);\n+\t\t  xoffset = (bitnum / unit) * GET_MODE_SIZE (bestmode);\n+\t\t  xbitpos = bitnum % unit;\n+\t\t  xop0 = change_address (xop0, bestmode,\n+\t\t\t\t\t plus_constant (XEXP (xop0, 0),\n+\t\t\t\t\t\t\txoffset));\n+\t\t  /* Fetch it to a register in that size.  */\n+\t\t  xop0 = force_reg (bestmode, xop0);\n+\n+\t\t  /* XBITPOS counts within UNIT, which is what is expected.  */\n+\t\t}\n+\t      else\n+\t\t/* Get ref to first byte containing part of the field.  */\n+\t\txop0 = change_address (xop0, byte_mode,\n+\t\t\t\t       plus_constant (XEXP (xop0, 0), xoffset));\n+\n+\t      volatile_ok = save_volatile_ok;\n+\t    }\n+\n+\t  /* If op0 is a register, we need it in MAXMODE (which is usually\n+\t     SImode). to make it acceptable to the format of extzv.  */\n+\t  if (GET_CODE (xop0) == SUBREG && GET_MODE (xop0) != maxmode)\n+\t    abort ();\n+\t  if (GET_CODE (xop0) == REG && GET_MODE (xop0) != maxmode)\n+\t    xop0 = gen_rtx (SUBREG, maxmode, xop0, 0);\n+\n+\t  /* On big-endian machines, we count bits from the most significant.\n+\t     If the bit field insn does not, we must invert.  */\n+#if BITS_BIG_ENDIAN != BYTES_BIG_ENDIAN\n+\t  xbitpos = unit - bitsize - xbitpos;\n+#endif\n+\t  /* Now convert from counting within UNIT to counting in MAXMODE.  */\n+#if BITS_BIG_ENDIAN\n+\t  if (GET_CODE (xop0) != MEM)\n+\t    xbitpos += GET_MODE_BITSIZE (maxmode) - unit;\n+#endif\n+\t  unit = GET_MODE_BITSIZE (maxmode);\n+\n+\t  if (xtarget == 0\n+\t      || (flag_force_mem && GET_CODE (xtarget) == MEM))\n+\t    xtarget = xspec_target = gen_reg_rtx (tmode);\n+\n+\t  if (GET_MODE (xtarget) != maxmode)\n+\t    {\n+\t      if (GET_CODE (xtarget) == REG)\n+\t\txspec_target_subreg = xtarget = gen_lowpart (maxmode, xtarget);\n+\t      else\n+\t\txtarget = gen_reg_rtx (maxmode);\n+\t    }\n+\n+\t  /* If this machine's extzv insists on a register target,\n+\t     make sure we have one.  */\n+\t  if (! ((*insn_operand_predicate[(int) CODE_FOR_extzv][0])\n+\t\t (xtarget, maxmode)))\n+\t    xtarget = gen_reg_rtx (maxmode);\n+\n+\t  bitsize_rtx = gen_rtx (CONST_INT, VOIDmode, bitsize);\n+\t  bitpos_rtx = gen_rtx (CONST_INT, VOIDmode, xbitpos);\n+\n+\t  pat = gen_extzv (protect_from_queue (xtarget, 1),\n+\t\t\t   xop0, bitsize_rtx, bitpos_rtx);\n+\t  if (pat)\n+\t    {\n+\t      emit_insn (pat);\n+\t      target = xtarget;\n+\t      spec_target = xspec_target;\n+\t      spec_target_subreg = xspec_target_subreg;\n+\t    }\n+\t  else\n+\t    {\n+\t      delete_insns_since (last);\n+\t      target = extract_fixed_bit_field (tmode, op0, offset, bitsize,\n+\t\t\t\t\t\tbitpos, target, 1, align);\n+\t    }\n+\t}\n+      else\n+        extzv_loses:\n+#endif\n+\ttarget = extract_fixed_bit_field (tmode, op0, offset, bitsize, bitpos,\n+\t\t\t\t\t  target, 1, align);\n+    }\n+  else\n+    {\n+#ifdef HAVE_extv\n+      if (HAVE_extv\n+\t  && (GET_MODE_BITSIZE (insn_operand_mode[(int) CODE_FOR_extv][0])\n+\t      >= bitsize))\n+\t{\n+\t  int xbitpos = bitpos, xoffset = offset;\n+\t  rtx bitsize_rtx, bitpos_rtx;\n+\t  rtx last = get_last_insn();\n+\t  rtx xop0 = op0, xtarget = target;\n+\t  rtx xspec_target = spec_target;\n+\t  rtx xspec_target_subreg = spec_target_subreg;\n+\t  rtx pat;\n+\t  enum machine_mode maxmode\n+\t    = insn_operand_mode[(int) CODE_FOR_extv][0];\n+\n+\t  if (GET_CODE (xop0) == MEM)\n+\t    {\n+\t      /* Is the memory operand acceptable?  */\n+\t      if (! ((*insn_operand_predicate[(int) CODE_FOR_extv][1])\n+\t\t     (xop0, GET_MODE (xop0))))\n+\t\t{\n+\t\t  /* No, load into a reg and extract from there.  */\n+\t\t  enum machine_mode bestmode;\n+\n+\t\t  /* Get the mode to use for inserting into this field.  If\n+\t\t     OP0 is BLKmode, get the smallest mode consistent with the\n+\t\t     alignment. If OP0 is a non-BLKmode object that is no\n+\t\t     wider than MAXMODE, use its mode. Otherwise, use the\n+\t\t     smallest mode containing the field.  */\n+\n+\t\t  if (GET_MODE (xop0) == BLKmode\n+\t\t      || (GET_MODE_SIZE (GET_MODE (op0))\n+\t\t\t  > GET_MODE_SIZE (maxmode)))\n+\t\t    bestmode = get_best_mode (bitsize, bitnum,\n+\t\t\t\t\t      align * BITS_PER_UNIT, maxmode,\n+\t\t\t\t\t      (GET_CODE (xop0) == MEM\n+\t\t\t\t\t       && MEM_VOLATILE_P (xop0)));\n+\t\t  else\n+\t\t    bestmode = GET_MODE (xop0);\n+\n+\t\t  if (bestmode == VOIDmode)\n+\t\t    goto extv_loses;\n+\n+\t\t  /* Compute offset as multiple of this unit,\n+\t\t     counting in bytes.  */\n+\t\t  unit = GET_MODE_BITSIZE (bestmode);\n+\t\t  xoffset = (bitnum / unit) * GET_MODE_SIZE (bestmode);\n+\t\t  xbitpos = bitnum % unit;\n+\t\t  xop0 = change_address (xop0, bestmode,\n+\t\t\t\t\t plus_constant (XEXP (xop0, 0),\n+\t\t\t\t\t\t\txoffset));\n+\t\t  /* Fetch it to a register in that size.  */\n+\t\t  xop0 = force_reg (bestmode, xop0);\n+\n+\t\t  /* XBITPOS counts within UNIT, which is what is expected.  */\n+\t\t}\n+\t      else\n+\t\t/* Get ref to first byte containing part of the field.  */\n+\t\txop0 = change_address (xop0, byte_mode,\n+\t\t\t\t       plus_constant (XEXP (xop0, 0), xoffset));\n+\t    }\n+\n+\t  /* If op0 is a register, we need it in MAXMODE (which is usually\n+\t     SImode) to make it acceptable to the format of extv.  */\n+\t  if (GET_CODE (xop0) == SUBREG && GET_MODE (xop0) != maxmode)\n+\t    abort ();\n+\t  if (GET_CODE (xop0) == REG && GET_MODE (xop0) != maxmode)\n+\t    xop0 = gen_rtx (SUBREG, maxmode, xop0, 0);\n+\n+\t  /* On big-endian machines, we count bits from the most significant.\n+\t     If the bit field insn does not, we must invert.  */\n+#if BITS_BIG_ENDIAN != BYTES_BIG_ENDIAN\n+\t  xbitpos = unit - bitsize - xbitpos;\n+#endif\n+\t  /* XBITPOS counts within a size of UNIT.\n+\t     Adjust to count within a size of MAXMODE.  */\n+#if BITS_BIG_ENDIAN\n+\t  if (GET_CODE (xop0) != MEM)\n+\t    xbitpos += (GET_MODE_BITSIZE (maxmode) - unit);\n+#endif\n+\t  unit = GET_MODE_BITSIZE (maxmode);\n+\n+\t  if (xtarget == 0\n+\t      || (flag_force_mem && GET_CODE (xtarget) == MEM))\n+\t    xtarget = xspec_target = gen_reg_rtx (tmode);\n+\n+\t  if (GET_MODE (xtarget) != maxmode)\n+\t    {\n+\t      if (GET_CODE (xtarget) == REG)\n+\t\txspec_target_subreg = xtarget = gen_lowpart (maxmode, xtarget);\n+\t      else\n+\t\txtarget = gen_reg_rtx (maxmode);\n+\t    }\n+\n+\t  /* If this machine's extv insists on a register target,\n+\t     make sure we have one.  */\n+\t  if (! ((*insn_operand_predicate[(int) CODE_FOR_extv][0])\n+\t\t (xtarget, maxmode)))\n+\t    xtarget = gen_reg_rtx (maxmode);\n+\n+\t  bitsize_rtx = gen_rtx (CONST_INT, VOIDmode, bitsize);\n+\t  bitpos_rtx = gen_rtx (CONST_INT, VOIDmode, xbitpos);\n+\n+\t  pat = gen_extv (protect_from_queue (xtarget, 1),\n+\t\t\t  xop0, bitsize_rtx, bitpos_rtx);\n+\t  if (pat)\n+\t    {\n+\t      emit_insn (pat);\n+\t      target = xtarget;\n+\t      spec_target = xspec_target;\n+\t      spec_target_subreg = xspec_target_subreg;\n+\t    }\n+\t  else\n+\t    {\n+\t      delete_insns_since (last);\n+\t      target = extract_fixed_bit_field (tmode, op0, offset, bitsize,\n+\t\t\t\t\t\tbitpos, target, 0, align);\n+\t    }\n+\t} \n+      else\n+\textv_loses:\n+#endif\n+\ttarget = extract_fixed_bit_field (tmode, op0, offset, bitsize, bitpos,\n+\t\t\t\t\t  target, 0, align);\n+    }\n+  if (target == spec_target)\n+    return target;\n+  if (target == spec_target_subreg)\n+    return spec_target;\n+  if (GET_MODE (target) != tmode && GET_MODE (target) != mode)\n+    {\n+      /* If the target mode is floating-point, first convert to the\n+\t integer mode of that size and then access it as a floating-point\n+\t value via a SUBREG.  */\n+      if (GET_MODE_CLASS (tmode) == MODE_FLOAT)\n+\t{\n+\t  target = convert_to_mode (mode_for_size (GET_MODE_BITSIZE (tmode),\n+\t\t\t\t\t\t   MODE_INT, 0),\n+\t\t\t\t    target, unsignedp);\n+\t  if (GET_CODE (target) != REG)\n+\t    target = copy_to_reg (target);\n+\t  return gen_rtx (SUBREG, tmode, target, 0);\n+\t}\n+      else\n+\treturn convert_to_mode (tmode, target, unsignedp);\n+    }\n+  return target;\n+}\n+\f\n+/* Extract a bit field using shifts and boolean operations\n+   Returns an rtx to represent the value.\n+   OP0 addresses a register (word) or memory (byte).\n+   BITPOS says which bit within the word or byte the bit field starts in.\n+   OFFSET says how many bytes farther the bit field starts;\n+    it is 0 if OP0 is a register.\n+   BITSIZE says how many bits long the bit field is.\n+    (If OP0 is a register, it may be narrower than a full word,\n+     but BITPOS still counts within a full word,\n+     which is significant on bigendian machines.)\n+\n+   UNSIGNEDP is nonzero for an unsigned bit field (don't sign-extend value).\n+   If TARGET is nonzero, attempts to store the value there\n+   and return TARGET, but this is not guaranteed.\n+   If TARGET is not used, create a pseudo-reg of mode TMODE for the value.\n+\n+   ALIGN is the alignment that STR_RTX is known to have, measured in bytes.  */\n+\n+static rtx\n+extract_fixed_bit_field (tmode, op0, offset, bitsize, bitpos,\n+\t\t\t target, unsignedp, align)\n+     enum machine_mode tmode;\n+     register rtx op0, target;\n+     register int offset, bitsize, bitpos;\n+     int unsignedp;\n+     int align;\n+{\n+  int total_bits = BITS_PER_WORD;\n+  enum machine_mode mode;\n+\n+  if (GET_CODE (op0) == SUBREG || GET_CODE (op0) == REG)\n+    {\n+      /* Special treatment for a bit field split across two registers.  */\n+      if (bitsize + bitpos > BITS_PER_WORD)\n+\treturn extract_split_bit_field (op0, bitsize, bitpos,\n+\t\t\t\t\tunsignedp, align);\n+    }\n+  else\n+    {\n+      /* Get the proper mode to use for this field.  We want a mode that\n+\t includes the entire field.  If such a mode would be larger than\n+\t a word, we won't be doing the extraction the normal way.  */\n+\n+      mode = get_best_mode (bitsize, bitpos + offset * BITS_PER_UNIT,\n+\t\t\t    align * BITS_PER_UNIT, word_mode,\n+\t\t\t    GET_CODE (op0) == MEM && MEM_VOLATILE_P (op0));\n+\n+      if (mode == VOIDmode)\n+\t/* The only way this should occur is if the field spans word\n+\t   boundaries.  */\n+\treturn extract_split_bit_field (op0, bitsize,\n+\t\t\t\t\tbitpos + offset * BITS_PER_UNIT,\n+\t\t\t\t\tunsignedp, align);\n+\n+      total_bits = GET_MODE_BITSIZE (mode);\n+\n+      /* Get ref to an aligned byte, halfword, or word containing the field.\n+\t Adjust BITPOS to be position within a word,\n+\t and OFFSET to be the offset of that word.\n+\t Then alter OP0 to refer to that word.  */\n+      bitpos += (offset % (total_bits / BITS_PER_UNIT)) * BITS_PER_UNIT;\n+      offset -= (offset % (total_bits / BITS_PER_UNIT));\n+      op0 = change_address (op0, mode,\n+\t\t\t    plus_constant (XEXP (op0, 0), offset));\n+    }\n+\n+  mode = GET_MODE (op0);\n+\n+#if BYTES_BIG_ENDIAN\n+  /* BITPOS is the distance between our msb and that of OP0.\n+     Convert it to the distance from the lsb.  */\n+\n+  bitpos = total_bits - bitsize - bitpos;\n+#endif\n+  /* Now BITPOS is always the distance between the field's lsb and that of OP0.\n+     We have reduced the big-endian case to the little-endian case.  */\n+\n+  if (unsignedp)\n+    {\n+      if (bitpos)\n+\t{\n+\t  /* If the field does not already start at the lsb,\n+\t     shift it so it does.  */\n+\t  tree amount = build_int_2 (bitpos, 0);\n+\t  /* Maybe propagate the target for the shift.  */\n+\t  /* But not if we will return it--could confuse integrate.c.  */\n+\t  rtx subtarget = (target != 0 && GET_CODE (target) == REG\n+\t\t\t   && !REG_FUNCTION_VALUE_P (target)\n+\t\t\t   ? target : 0);\n+\t  if (tmode != mode) subtarget = 0;\n+\t  op0 = expand_shift (RSHIFT_EXPR, mode, op0, amount, subtarget, 1);\n+\t}\n+      /* Convert the value to the desired mode.  */\n+      if (mode != tmode)\n+\top0 = convert_to_mode (tmode, op0, 1);\n+\n+      /* Unless the msb of the field used to be the msb when we shifted,\n+\t mask out the upper bits.  */\n+\n+      if (GET_MODE_BITSIZE (mode) != bitpos + bitsize\n+#if 0\n+#ifdef SLOW_ZERO_EXTEND\n+\t  /* Always generate an `and' if\n+\t     we just zero-extended op0 and SLOW_ZERO_EXTEND, since it\n+\t     will combine fruitfully with the zero-extend. */\n+\t  || tmode != mode\n+#endif\n+#endif\n+\t  )\n+\treturn expand_binop (GET_MODE (op0), and_optab, op0,\n+\t\t\t     mask_rtx (GET_MODE (op0), 0, bitsize, 0),\n+\t\t\t     target, 1, OPTAB_LIB_WIDEN);\n+      return op0;\n+    }\n+\n+  /* To extract a signed bit-field, first shift its msb to the msb of the word,\n+     then arithmetic-shift its lsb to the lsb of the word.  */\n+  op0 = force_reg (mode, op0);\n+  if (mode != tmode)\n+    target = 0;\n+\n+  /* Find the narrowest integer mode that contains the field.  */\n+\n+  for (mode = GET_CLASS_NARROWEST_MODE (MODE_INT); mode != VOIDmode;\n+       mode = GET_MODE_WIDER_MODE (mode))\n+    if (GET_MODE_BITSIZE (mode) >= bitsize + bitpos)\n+      {\n+\top0 = convert_to_mode (mode, op0, 0);\n+\tbreak;\n+      }\n+\n+  if (GET_MODE_BITSIZE (mode) != (bitsize + bitpos))\n+    {\n+      tree amount = build_int_2 (GET_MODE_BITSIZE (mode) - (bitsize + bitpos), 0);\n+      /* Maybe propagate the target for the shift.  */\n+      /* But not if we will return the result--could confuse integrate.c.  */\n+      rtx subtarget = (target != 0 && GET_CODE (target) == REG\n+\t\t       && ! REG_FUNCTION_VALUE_P (target)\n+\t\t       ? target : 0);\n+      op0 = expand_shift (LSHIFT_EXPR, mode, op0, amount, subtarget, 1);\n+    }\n+\n+  return expand_shift (RSHIFT_EXPR, mode, op0,\n+\t\t       build_int_2 (GET_MODE_BITSIZE (mode) - bitsize, 0), \n+\t\t       target, 0);\n+}\n+\f\n+/* Return a constant integer (CONST_INT or CONST_DOUBLE) mask value\n+   of mode MODE with BITSIZE ones followed by BITPOS zeros, or the\n+   complement of that if COMPLEMENT.  The mask is truncated if\n+   necessary to the width of mode MODE.  */\n+\n+static rtx\n+mask_rtx (mode, bitpos, bitsize, complement)\n+     enum machine_mode mode;\n+     int bitpos, bitsize, complement;\n+{\n+  int masklow, maskhigh;\n+\n+  if (bitpos < HOST_BITS_PER_INT)\n+    masklow = -1 << bitpos;\n+  else\n+    masklow = 0;\n+\n+  if (bitpos + bitsize < HOST_BITS_PER_INT)\n+    masklow &= (unsigned) -1 >> (HOST_BITS_PER_INT - bitpos - bitsize);\n+  \n+  if (bitpos <= HOST_BITS_PER_INT)\n+    maskhigh = -1;\n+  else\n+    maskhigh = -1 << (bitpos - HOST_BITS_PER_INT);\n+\n+  if (bitpos + bitsize > HOST_BITS_PER_INT)\n+    maskhigh &= (unsigned) -1 >> (2 * HOST_BITS_PER_INT - bitpos - bitsize);\n+  else\n+    maskhigh = 0;\n+\n+  if (complement)\n+    {\n+      maskhigh = ~maskhigh;\n+      masklow = ~masklow;\n+    }\n+\n+  return immed_double_const (masklow, maskhigh, mode);\n+}\n+\n+/* Return a constant integer (CONST_INT or CONST_DOUBLE) rtx with the value\n+   VALUE truncated to BITSIZE bits and then shifted left BITPOS bits.  */\n+\n+static rtx\n+lshift_value (mode, value, bitpos, bitsize)\n+     enum machine_mode mode;\n+     rtx value;\n+     int bitpos, bitsize;\n+{\n+  unsigned v = INTVAL (value);\n+  int low, high;\n+\n+  if (bitsize < HOST_BITS_PER_INT)\n+    v &= ~(-1 << bitsize);\n+\n+  if (bitpos < HOST_BITS_PER_INT)\n+    {\n+      low = v << bitpos;\n+      high = (bitpos > 0 ? (v >> (HOST_BITS_PER_INT - bitpos)) : 0);\n+    }\n+  else\n+    {\n+      low = 0;\n+      high = v << (bitpos - HOST_BITS_PER_INT);\n+    }\n+\n+  return immed_double_const (low, high, mode);\n+}\n+\f\n+/* Extract a bit field that is split across two words\n+   and return an RTX for the result.\n+\n+   OP0 is the REG, SUBREG or MEM rtx for the first of the two words.\n+   BITSIZE is the field width; BITPOS, position of its first bit, in the word.\n+   UNSIGNEDP is 1 if should zero-extend the contents; else sign-extend.  */\n+\n+static rtx\n+extract_split_bit_field (op0, bitsize, bitpos, unsignedp, align)\n+     rtx op0;\n+     int bitsize, bitpos, unsignedp, align;\n+{\n+  /* BITSIZE_1 is size of the part in the first word.  */\n+  int bitsize_1 = BITS_PER_WORD - bitpos % BITS_PER_WORD;\n+  /* BITSIZE_2 is size of the rest (in the following word).  */\n+  int bitsize_2 = bitsize - bitsize_1;\n+  rtx part1, part2, result;\n+  int unit = GET_CODE (op0) == MEM ? BITS_PER_UNIT : BITS_PER_WORD;\n+  int offset = bitpos / unit;\n+  rtx word;\n+ \n+  /* The field must span exactly one word boundary.  */\n+  if (bitpos / BITS_PER_WORD != (bitpos + bitsize - 1) / BITS_PER_WORD - 1)\n+    abort ();\n+\n+  /* Get the part of the bit field from the first word.  If OP0 is a MEM,\n+     pass OP0 and the offset computed above.  Otherwise, get the proper\n+     word and pass an offset of zero.  */\n+  word = (GET_CODE (op0) == MEM ? op0\n+\t  : operand_subword_force (op0, offset, GET_MODE (op0)));\n+  part1 = extract_fixed_bit_field (word_mode, word,\n+\t\t\t\t   GET_CODE (op0) == MEM ? offset : 0,\n+\t\t\t\t   bitsize_1, bitpos % unit, 0, 1, align);\n+\n+  /* Offset op0 by 1 word to get to the following one.  */\n+  if (GET_CODE (op0) == SUBREG)\n+    word = operand_subword_force (SUBREG_REG (op0),\n+\t\t\t\t  SUBREG_WORD (op0) + offset + 1, VOIDmode);\n+  else if (GET_CODE (op0) == MEM)\n+    word = op0;\n+  else\n+    word = operand_subword_force (op0, offset + 1, GET_MODE (op0));\n+\n+  /* Get the part of the bit field from the second word.  */\n+  part2 = extract_fixed_bit_field (word_mode, word,\n+\t\t\t\t   (GET_CODE (op0) == MEM\n+\t\t\t\t    ? CEIL (offset + 1, UNITS_PER_WORD) * UNITS_PER_WORD\n+\t\t\t\t    : 0),\n+\t\t\t\t   bitsize_2, 0, 0, 1, align);\n+\n+  /* Shift the more significant part up to fit above the other part.  */\n+#if BYTES_BIG_ENDIAN\n+  part1 = expand_shift (LSHIFT_EXPR, word_mode, part1,\n+\t\t\tbuild_int_2 (bitsize_2, 0), 0, 1);\n+#else\n+  part2 = expand_shift (LSHIFT_EXPR, word_mode, part2,\n+\t\t\tbuild_int_2 (bitsize_1, 0), 0, 1);\n+#endif\n+\n+  /* Combine the two parts with bitwise or.  This works\n+     because we extracted both parts as unsigned bit fields.  */\n+  result = expand_binop (word_mode, ior_optab, part1, part2, 0, 1,\n+\t\t\t OPTAB_LIB_WIDEN);\n+\n+  /* Unsigned bit field: we are done.  */\n+  if (unsignedp)\n+    return result;\n+  /* Signed bit field: sign-extend with two arithmetic shifts.  */\n+  result = expand_shift (LSHIFT_EXPR, word_mode, result,\n+\t\t\t build_int_2 (BITS_PER_WORD - bitsize, 0), 0, 0);\n+  return expand_shift (RSHIFT_EXPR, word_mode, result,\n+\t\t       build_int_2 (BITS_PER_WORD - bitsize, 0), 0, 0);\n+}\n+\f\n+/* Add INC into TARGET.  */\n+\n+void\n+expand_inc (target, inc)\n+     rtx target, inc;\n+{\n+  rtx value = expand_binop (GET_MODE (target), add_optab,\n+\t\t\t    target, inc,\n+\t\t\t    target, 0, OPTAB_LIB_WIDEN);\n+  if (value != target)\n+    emit_move_insn (target, value);\n+}\n+\n+/* Subtract DEC from TARGET.  */\n+\n+void\n+expand_dec (target, dec)\n+     rtx target, dec;\n+{\n+  rtx value = expand_binop (GET_MODE (target), sub_optab,\n+\t\t\t    target, dec,\n+\t\t\t    target, 0, OPTAB_LIB_WIDEN);\n+  if (value != target)\n+    emit_move_insn (target, value);\n+}\n+\f\n+/* Output a shift instruction for expression code CODE,\n+   with SHIFTED being the rtx for the value to shift,\n+   and AMOUNT the tree for the amount to shift by.\n+   Store the result in the rtx TARGET, if that is convenient.\n+   If UNSIGNEDP is nonzero, do a logical shift; otherwise, arithmetic.\n+   Return the rtx for where the value is.  */\n+\n+rtx\n+expand_shift (code, mode, shifted, amount, target, unsignedp)\n+     enum tree_code code;\n+     register enum machine_mode mode;\n+     rtx shifted;\n+     tree amount;\n+     register rtx target;\n+     int unsignedp;\n+{\n+  register rtx op1, temp = 0;\n+  register int left = (code == LSHIFT_EXPR || code == LROTATE_EXPR);\n+  register int rotate = (code == LROTATE_EXPR || code == RROTATE_EXPR);\n+  int try;\n+\n+  /* Previously detected shift-counts computed by NEGATE_EXPR\n+     and shifted in the other direction; but that does not work\n+     on all machines.  */\n+\n+  op1 = expand_expr (amount, 0, VOIDmode, 0);\n+\n+  if (op1 == const0_rtx)\n+    return shifted;\n+\n+  for (try = 0; temp == 0 && try < 3; try++)\n+    {\n+      enum optab_methods methods;\n+\n+      if (try == 0)\n+\tmethods = OPTAB_DIRECT;\n+      else if (try == 1)\n+\tmethods = OPTAB_WIDEN;\n+      else\n+\tmethods = OPTAB_LIB_WIDEN;\n+\n+      if (rotate)\n+\t{\n+\t  /* Widening does not work for rotation.  */\n+\t  if (methods == OPTAB_WIDEN)\n+\t    continue;\n+\t  else if (methods == OPTAB_LIB_WIDEN)\n+\t    methods = OPTAB_LIB;\n+\n+\t  temp = expand_binop (mode,\n+\t\t\t       left ? rotl_optab : rotr_optab,\n+\t\t\t       shifted, op1, target, unsignedp, methods);\n+\t}\n+      else if (unsignedp)\n+\t{\n+\t  temp = expand_binop (mode,\n+\t\t\t       left ? lshl_optab : lshr_optab,\n+\t\t\t       shifted, op1, target, unsignedp, methods);\n+\t  if (temp == 0 && left)\n+\t    temp = expand_binop (mode, ashl_optab,\n+\t\t\t\t shifted, op1, target, unsignedp, methods);\n+\t}\n+\n+      /* Do arithmetic shifts.\n+\t Also, if we are going to widen the operand, we can just as well\n+\t use an arithmetic right-shift instead of a logical one.  */\n+      if (temp == 0 && ! rotate\n+\t  && (! unsignedp || (! left && methods == OPTAB_WIDEN)))\n+\t{\n+\t  enum optab_methods methods1 = methods;\n+\n+\t  /* If trying to widen a log shift to an arithmetic shift,\n+\t     don't accept an arithmetic shift of the same size.  */\n+\t  if (unsignedp)\n+\t    methods1 = OPTAB_MUST_WIDEN;\n+\n+\t  /* Arithmetic shift */\n+\n+\t  temp = expand_binop (mode,\n+\t\t\t       left ? ashl_optab : ashr_optab,\n+\t\t\t       shifted, op1, target, unsignedp, methods1);\n+\t}\n+\n+#ifdef HAVE_extzv\n+      /* We can do a logical (unsigned) right shift with a bit-field\n+\t extract insn.  But first check if one of the above methods worked.  */\n+      if (temp != 0)\n+\treturn temp;\n+\n+      if (unsignedp && code == RSHIFT_EXPR && ! BITS_BIG_ENDIAN && HAVE_extzv)\n+\t{\n+\t  enum machine_mode output_mode\n+\t    = insn_operand_mode[(int) CODE_FOR_extzv][0];\n+\n+\t  if ((methods == OPTAB_DIRECT && mode == output_mode)\n+\t      || (methods == OPTAB_WIDEN\n+\t\t  && GET_MODE_SIZE (mode) < GET_MODE_SIZE (output_mode)))\n+\t    {\n+\t      /* Note convert_to_mode does protect_from_queue.  */\n+\t      rtx shifted1 = convert_to_mode (output_mode, shifted, 1);\n+\t      enum machine_mode length_mode\n+\t\t= insn_operand_mode[(int) CODE_FOR_extzv][2];\n+\t      enum machine_mode pos_mode\n+\t\t= insn_operand_mode[(int) CODE_FOR_extzv][3];\n+\t      rtx target1 = 0;\n+\t      rtx last = get_last_insn ();\n+\t      rtx width;\n+\t      rtx xop1 = op1;\n+\t      rtx pat;\n+\n+\t      if (target != 0)\n+\t\ttarget1 = protect_from_queue (target, 1);\n+\n+\t      /* We define extract insns as having OUTPUT_MODE in a register\n+\t\t and the mode of operand 1 in memory.  Since we want\n+\t\t OUTPUT_MODE, we will always force the operand into a\n+\t\t register.  At some point we might want to support MEM\n+\t\t directly. */\n+\t      shifted1 = force_reg (output_mode, shifted1);\n+\n+\t      /* If we don't have or cannot use a suggested target,\n+\t\t make a place for the result, in the proper mode.  */\n+\t      if (methods == OPTAB_WIDEN || target1 == 0\n+\t\t  || ! ((*insn_operand_predicate[(int) CODE_FOR_extzv][0])\n+\t\t\t(target1, output_mode)))\n+\t\ttarget1 = gen_reg_rtx (output_mode);\n+\n+\t      xop1 = convert_to_mode (pos_mode, xop1,\n+\t\t\t\t      TREE_UNSIGNED (TREE_TYPE (amount)));\n+\n+\t      /* If this machine's extzv insists on a register for\n+\t\t operand 3 (position), arrange for that.  */\n+\t      if (! ((*insn_operand_predicate[(int) CODE_FOR_extzv][3])\n+\t\t     (xop1, pos_mode)))\n+\t\txop1 = force_reg (pos_mode, xop1);\n+\n+\t      /* WIDTH gets the width of the bit field to extract:\n+\t\t wordsize minus # bits to shift by.  */\n+\t      if (GET_CODE (xop1) == CONST_INT)\n+\t\twidth = gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t\t (GET_MODE_BITSIZE (mode) - INTVAL (op1)));\n+\t      else\n+\t\t{\n+\t\t  /* Now get the width in the proper mode.  */\n+\t\t  width = convert_to_mode (length_mode, op1,\n+\t\t\t\t\t   TREE_UNSIGNED (TREE_TYPE (amount)));\n+\n+\t\t  width = expand_binop (length_mode, sub_optab,\n+\t\t\t\t\tgen_rtx (CONST_INT, VOIDmode,\n+\t\t\t\t\t\t GET_MODE_BITSIZE (mode)),\n+\t\t\t\t\twidth, 0, 0, OPTAB_LIB_WIDEN);\n+\t\t}\n+\n+\t      /* If this machine's extzv insists on a register for\n+\t\t operand 2 (length), arrange for that.  */\n+\t      if (! ((*insn_operand_predicate[(int) CODE_FOR_extzv][2])\n+\t\t     (width, length_mode)))\n+\t\twidth = force_reg (length_mode, width);\n+\n+\t      /* Now extract with WIDTH, omitting OP1 least sig bits.  */\n+\t      pat = gen_extzv (target1, shifted1, width, xop1);\n+\t      if (pat)\n+\t\t{\n+\t\t  emit_insn (pat);\n+\t\t  temp = convert_to_mode (mode, target1, 1);\n+\t\t}\n+\t      else\n+\t\tdelete_insns_since (last);\n+\t    }\n+\n+\t  /* Can also do logical shift with signed bit-field extract\n+\t     followed by inserting the bit-field at a different position.\n+\t     That strategy is not yet implemented.  */\n+\t}\n+#endif /* HAVE_extzv */\n+    }\n+\n+  if (temp == 0)\n+    abort ();\n+  return temp;\n+}\n+\f\n+enum alg_code { alg_add, alg_subtract, alg_compound };\n+\n+/* This structure records a sequence of operations.\n+   `ops' is the number of operations recorded.\n+   `cost' is their total cost.\n+   The operations are stored in `op' and the corresponding\n+   integer coefficients in `coeff'.\n+   These are the operations:\n+   alg_add       Add to the total the multiplicand times the coefficient.\n+   alg_subtract  Subtract the multiplicand times the coefficient.\n+   alg_compound  This coefficient plus or minus the following one\n+                 is multiplied into the total.  The following operation\n+                 is alg_add or alg_subtract to indicate whether to add\n+\t\t or subtract the two coefficients.  */\n+\n+#ifndef MAX_BITS_PER_WORD\n+#define MAX_BITS_PER_WORD BITS_PER_WORD\n+#endif\n+\n+struct algorithm\n+{\n+  int cost;\n+  unsigned int ops;\n+  enum alg_code op[MAX_BITS_PER_WORD];\n+  unsigned int coeff[MAX_BITS_PER_WORD];\n+};\n+\n+/* Compute and return the best algorithm for multiplying by T.\n+   Assume that add insns cost ADD_COST and shifts cost SHIFT_COST.\n+   Return cost -1 if would cost more than MAX_COST.  */\n+\n+static struct algorithm\n+synth_mult (t, add_cost, shift_cost, max_cost)\n+     unsigned int t;\n+     int add_cost, shift_cost;\n+     int max_cost;\n+{\n+  int m, n;\n+  struct algorithm *best_alg = (struct algorithm *)alloca (sizeof (struct algorithm));\n+  struct algorithm *alg_in = (struct algorithm *)alloca (sizeof (struct algorithm));\n+  unsigned int cost;\n+\n+  /* No matter what happens, we want to return a valid algorithm.  */\n+  best_alg->cost = max_cost;\n+  best_alg->ops = 0;\n+\n+  /* Is t an exponent of 2, so we can just do a shift?  */\n+\n+  if ((t & -t) == t)\n+    {\n+      if (t > 1)\n+\t{\n+\t  if (max_cost >= shift_cost)\n+\t    {\n+\t      best_alg->cost = shift_cost;\n+\t      best_alg->ops = 1;\n+\t      best_alg->op[0] = alg_add;\n+\t      best_alg->coeff[0] = t;\n+\t    }\n+\t  else\n+\t    best_alg->cost = -1;\n+\t}\n+      else if (t == 1)\n+\t{\n+\t  if (max_cost >= 0)\n+\t    best_alg->cost = 0;\n+\t}\n+      else\n+\tbest_alg->cost = 0;\n+\n+      return *best_alg;\n+    }\n+\n+  /* If MAX_COST just permits as little as an addition (or less), we won't\n+     succeed in synthesizing an algorithm for t.  Return immediately with\n+     an indication of failure.  */\n+  if (max_cost <= add_cost)\n+    {\n+      best_alg->cost = -1;\n+      return *best_alg;\n+    }\n+\n+  /* Look for factors of t of the form\n+     t = q(2**m +- 1), 2 <= m <= floor(log2(t)) - 1.\n+     If we find such a factor, we can multiply by t using an algorithm that\n+     multiplies by q, shift the result by m and add/subtract it to itself.  */\n+\n+  for (m = floor_log2 (t) - 1; m >= 2; m--)\n+    {\n+      int m_exp_2 = 1 << m;\n+      int d;\n+\n+      d = m_exp_2 + 1;\n+      if (t % d == 0)\n+\t{\n+\t  int q = t / d;\n+\n+\t  cost = add_cost + shift_cost * 2;\n+\n+\t  *alg_in = synth_mult (q, add_cost, shift_cost,\n+\t\t\t\tMIN (max_cost, best_alg->cost) - cost);\n+\n+\t  if (alg_in->cost >= 0)\n+\t    {\n+\t      cost += alg_in->cost;\n+\n+\t      if (cost < best_alg->cost)\n+\t\t{\n+\t\t  struct algorithm *x;\n+\t\t  x = alg_in;\n+\t\t  alg_in = best_alg;\n+\t\t  best_alg = x;\n+\t\t  best_alg->coeff[best_alg->ops] = m_exp_2;\n+\t\t  best_alg->op[best_alg->ops++] = alg_compound;\n+\t\t  best_alg->coeff[best_alg->ops] = 1;\n+\t\t  best_alg->op[best_alg->ops++] = alg_add;\n+\t\t  best_alg->cost = cost;\n+\t\t}\n+\t    }\n+\t}\n+\n+      d = m_exp_2 - 1;\n+      if (t % d == 0)\n+\t{\n+\t  int q = t / d;\n+\n+\t  cost = add_cost + shift_cost * 2;\n+\n+\t  *alg_in = synth_mult (q, add_cost, shift_cost,\n+\t\t\t\tMIN (max_cost, best_alg->cost) - cost);\n+\n+\t  if (alg_in->cost >= 0)\n+\t    {\n+\t      cost += alg_in->cost;\n+\n+\t      if (cost < best_alg->cost)\n+\t\t{\n+\t\t  struct algorithm *x;\n+\t\t  x = alg_in;\n+\t\t  alg_in = best_alg;\n+\t\t  best_alg = x;\n+\t\t  best_alg->coeff[best_alg->ops] = m_exp_2;\n+\t\t  best_alg->op[best_alg->ops++] = alg_compound;\n+\t\t  best_alg->coeff[best_alg->ops] = 1;\n+\t\t  best_alg->op[best_alg->ops++] = alg_subtract;\n+\t\t  best_alg->cost = cost;\n+\t\t}\n+\t    }\n+\t}\n+    }\n+\n+  /* Try load effective address instructions, i.e. do a*3, a*5, a*9.  */\n+\n+  {\n+    int q;\n+    int w;\n+\n+    q = t & -t;\t\t\t/* get out lsb */\n+    w = (t - q) & -(t - q);\t/* get out next lsb */\n+\n+    if (w / q <= lea_max_mul)\n+      {\n+\tcost = lea_cost + (q != 1 ? shift_cost : 0);\n+\n+\t*alg_in = synth_mult (t - q - w, add_cost, shift_cost,\n+\t\t\t      MIN (max_cost, best_alg->cost) - cost);\n+\n+\tif (alg_in->cost >= 0)\n+\t  {\n+\t    cost += alg_in->cost;\n+\n+\t    /* Use <= to prefer this method to the factoring method\n+\t       when the cost appears the same, because this method\n+\t       uses fewer temporary registers.  */\n+\t    if (cost <= best_alg->cost)\n+\t      {\n+\t\tstruct algorithm *x;\n+\t\tx = alg_in;\n+\t\talg_in = best_alg;\n+\t\tbest_alg = x;\n+\t\tbest_alg->coeff[best_alg->ops] = w;\n+\t\tbest_alg->op[best_alg->ops++] = alg_add;\n+\t\tbest_alg->coeff[best_alg->ops] = q;\n+\t\tbest_alg->op[best_alg->ops++] = alg_add;\n+\t\tbest_alg->cost = cost;\n+\t      }\n+\t  }\n+      }\n+  }\n+\n+  /* Now, use the good old method to add or subtract at the leftmost\n+     1-bit.  */\n+\n+  {\n+    int q;\n+    int w;\n+\n+    q = t & -t;\t\t\t/* get out lsb */\n+    for (w = q; (w & t) != 0; w <<= 1)\n+      ;\n+    if ((w > q << 1)\n+\t/* Reject the case where t has only two bits.\n+\t   Thus we prefer addition in that case.  */\n+\t&& !(t < w && w == q << 2))\n+      {\n+\t/* There are many bits in a row.  Make 'em by subtraction.  */\n+\n+\tcost = add_cost;\n+\tif (q != 1)\n+\t  cost += shift_cost;\n+\n+\t*alg_in = synth_mult (t + q, add_cost, shift_cost,\n+\t\t\t      MIN (max_cost, best_alg->cost) - cost);\n+\n+\tif (alg_in->cost >= 0)\n+\t  {\n+\t    cost += alg_in->cost;\n+\n+\t    /* Use <= to prefer this method to the factoring method\n+\t       when the cost appears the same, because this method\n+\t       uses fewer temporary registers.  */\n+\t    if (cost <= best_alg->cost)\n+\t      {\n+\t\tstruct algorithm *x;\n+\t\tx = alg_in;\n+\t\talg_in = best_alg;\n+\t\tbest_alg = x;\n+\t\tbest_alg->coeff[best_alg->ops] = q;\n+\t\tbest_alg->op[best_alg->ops++] = alg_subtract;\n+\t\tbest_alg->cost = cost;\n+\t      }\n+\t  }\n+      }\n+    else\n+      {\n+\t/* There's only one bit at the left.  Make it by addition.  */\n+\n+\tcost = add_cost;\n+\tif (q != 1)\n+\t  cost += shift_cost;\n+\n+\t*alg_in = synth_mult (t - q, add_cost, shift_cost,\n+\t\t\t      MIN (max_cost, best_alg->cost) - cost);\n+\n+\tif (alg_in->cost >= 0)\n+\t  {\n+\t    cost += alg_in->cost;\n+\n+\t    if (cost <= best_alg->cost)\n+\t      {\n+\t\tstruct algorithm *x;\n+\t\tx = alg_in;\n+\t\talg_in = best_alg;\n+\t\tbest_alg = x;\n+\t\tbest_alg->coeff[best_alg->ops] = q;\n+\t\tbest_alg->op[best_alg->ops++] = alg_add;\n+\t\tbest_alg->cost = cost;\n+\t      }\n+\t  }\n+      }\n+  }\n+\n+  if (best_alg->cost >= max_cost)\n+    best_alg->cost = -1;\n+  return *best_alg;\n+}\n+\f\n+/* Perform a multiplication and return an rtx for the result.\n+   MODE is mode of value; OP0 and OP1 are what to multiply (rtx's);\n+   TARGET is a suggestion for where to store the result (an rtx).\n+\n+   We check specially for a constant integer as OP1.\n+   If you want this check for OP0 as well, then before calling\n+   you should swap the two operands if OP0 would be constant.  */\n+\n+rtx\n+expand_mult (mode, op0, op1, target, unsignedp)\n+     enum machine_mode mode;\n+     register rtx op0, op1, target;\n+     int unsignedp;\n+{\n+  rtx const_op1 = op1;\n+\n+  /* If we are multiplying in DImode, it may still be a win\n+     to try to work with shifts and adds.  */\n+  if (GET_CODE (op1) == CONST_DOUBLE\n+      && GET_MODE_CLASS (GET_MODE (op1)) == MODE_INT\n+      && HOST_BITS_PER_INT <= BITS_PER_WORD)\n+    {\n+      if ((CONST_DOUBLE_HIGH (op1) == 0 && CONST_DOUBLE_LOW (op1) >= 0)\n+\t  || (CONST_DOUBLE_HIGH (op1) == -1 && CONST_DOUBLE_LOW (op1) < 0))\n+\tconst_op1 = gen_rtx (CONST_INT, VOIDmode, CONST_DOUBLE_LOW (op1));\n+    }\n+\n+  if (GET_CODE (const_op1) == CONST_INT && ! mult_is_very_cheap && optimize)\n+    {\n+      struct algorithm alg;\n+      struct algorithm neg_alg;\n+      int negate = 0;\n+      int absval = INTVAL (op1);\n+      rtx last;\n+\n+      /* Try to do the computation two ways: multiply by the negative of OP1\n+\t and then negate, or do the multiplication directly.  The latter is\n+\t usually faster for positive numbers and the former for negative\n+\t numbers, but the opposite can be faster if the original value\n+\t has a factor of 2**m +/- 1, while the negated value does not or\n+\t vice versa.  */\n+\n+      alg = synth_mult (absval, add_cost, shift_cost, mult_cost);\n+      neg_alg = synth_mult (- absval, add_cost, shift_cost,\n+\t\t\t    mult_cost - negate_cost);\n+\n+      if (neg_alg.cost >= 0 && neg_alg.cost + negate_cost < alg.cost)\n+\talg = neg_alg, negate = 1, absval = - absval;\n+\n+      if (alg.cost >= 0)\n+\t{\n+\t  /* If we found something, it must be cheaper than multiply.\n+\t     So use it.  */\n+\t  int opno = 0;\n+\t  rtx accum, tem;\n+\t  int factors_seen = 0;\n+\n+\t  op0 = protect_from_queue (op0, 0);\n+\n+\t  /* Avoid referencing memory over and over.\n+\t     For speed, but also for correctness when mem is volatile.  */\n+\t  if (GET_CODE (op0) == MEM)\n+\t    op0 = force_reg (mode, op0);\n+\n+\t  if (alg.ops == 0)\n+\t    accum = copy_to_mode_reg (mode, op0);\n+\t  else\n+\t    {\n+\t      /* 1 if this is the last in a series of adds and subtracts.  */\n+\t      int last = (1 == alg.ops || alg.op[1] == alg_compound);\n+\t      int log = floor_log2 (alg.coeff[0]);\n+\t      if (! factors_seen && ! last)\n+\t\tlog -= floor_log2 (alg.coeff[1]);\n+\n+\t      if (alg.op[0] != alg_add)\n+\t\tabort ();\n+\t      accum = expand_shift (LSHIFT_EXPR, mode, op0,\n+\t\t\t\t    build_int_2 (log, 0),\n+\t\t\t\t    0, 0);\n+\t    }\n+   \n+\t  while (++opno < alg.ops)\n+\t    {\n+\t      int log = floor_log2 (alg.coeff[opno]);\n+\t      /* 1 if this is the last in a series of adds and subtracts.  */\n+\t      int last = (opno + 1 == alg.ops\n+\t\t\t  || alg.op[opno + 1] == alg_compound);\n+\n+\t      /* If we have not yet seen any separate factors (alg_compound)\n+\t\t then turn op0<<a1 + op0<<a2 + op0<<a3... into\n+\t\t (op0<<(a1-a2) + op0)<<(a2-a3) + op0...  */\n+\t      switch (alg.op[opno])\n+\t\t{\n+\t\tcase alg_add:\n+\t\t  if (factors_seen)\n+\t\t    {\n+\t\t      tem = expand_shift (LSHIFT_EXPR, mode, op0,\n+\t\t\t\t\t  build_int_2 (log, 0), 0, 0);\n+\t\t      accum = force_operand (gen_rtx (PLUS, mode, accum, tem),\n+\t\t\t\t\t     accum);\n+\t\t    }\n+\t\t  else\n+\t\t    {\n+\t\t      if (! last)\n+\t\t\tlog -= floor_log2 (alg.coeff[opno + 1]);\n+\t\t      accum = force_operand (gen_rtx (PLUS, mode, accum, op0),\n+\t\t\t\t\t     accum);\n+\t\t      accum = expand_shift (LSHIFT_EXPR, mode, accum,\n+\t\t\t\t\t    build_int_2 (log, 0), accum, 0);\n+\t\t    }\n+\t\t  break;\n+\n+\t\tcase alg_subtract:\n+\t\t  if (factors_seen)\n+\t\t    {\n+\t\t      tem = expand_shift (LSHIFT_EXPR, mode, op0,\n+\t\t\t\t\t  build_int_2 (log, 0), 0, 0);\n+\t\t      accum = force_operand (gen_rtx (MINUS, mode, accum, tem),\n+\t\t\t\t\t     accum);\n+\t\t    }\n+\t\t  else\n+\t\t    {\n+\t\t      if (! last)\n+\t\t\tlog -= floor_log2 (alg.coeff[opno + 1]);\n+\t\t      accum = force_operand (gen_rtx (MINUS, mode, accum, op0),\n+\t\t\t\t\t     accum);\n+\t\t      accum = expand_shift (LSHIFT_EXPR, mode, accum,\n+\t\t\t\t\t    build_int_2 (log, 0), accum, 0);\n+\t\t    }\n+\n+\t\t  break;\n+\n+\t\tcase alg_compound:\n+\t\t  factors_seen = 1;\n+\t\t  tem = expand_shift (LSHIFT_EXPR, mode, accum,\n+\t\t\t\t      build_int_2 (log, 0), 0, 0);\n+\n+\t\t  log = floor_log2 (alg.coeff[opno + 1]);\n+\t\t  accum = expand_shift (LSHIFT_EXPR, mode, accum,\n+\t\t\t\t\tbuild_int_2 (log, 0), 0, 0);\n+\t\t  opno++;\n+\t\t  if (alg.op[opno] == alg_add)\n+\t\t    accum = force_operand (gen_rtx (PLUS, mode, tem, accum),\n+\t\t\t\t\t   tem);\n+\t\t  else\n+\t\t    accum = force_operand (gen_rtx (MINUS, mode, tem, accum),\n+\t\t\t\t\t   tem);\n+\t\t}\n+\t    }\n+\n+\t  /* Write a REG_EQUAL note on the last insn so that we can cse \n+\t     multiplication sequences.  We need not do this if we were\n+\t     multiplying by a power of two, since only one insn would have\n+\t     been generated.\n+\n+\t     ??? We could also write REG_EQUAL notes on the last insn of\n+\t     each sequence that uses a single temporary, but it is not\n+\t     clear how to calculate the partial product so far.\n+\n+\t     Torbjorn: Can you do this?  */\n+\n+\t  if (exact_log2 (absval) < 0)\n+\t    {\n+\t      last = get_last_insn ();\n+\t      REG_NOTES (last)\n+\t\t= gen_rtx (EXPR_LIST, REG_EQUAL,\n+\t\t\t   gen_rtx (MULT, mode, op0, \n+\t\t\t\t    negate ? gen_rtx (CONST_INT,\n+\t\t\t\t\t\t      VOIDmode, absval)\n+\t\t\t\t    : op1),\n+\t\t\t   REG_NOTES (last));\n+\t    }\n+\n+\t  return (negate ? expand_unop (mode, neg_optab, accum, target, 0)\n+\t\t  : accum);\n+\t}\n+    }\n+\n+  /* This used to use umul_optab if unsigned,\n+     but I think that for non-widening multiply there is no difference\n+     between signed and unsigned.  */\n+  op0 = expand_binop (mode, smul_optab,\n+\t\t      op0, op1, target, unsignedp, OPTAB_LIB_WIDEN);\n+  if (op0 == 0)\n+    abort ();\n+  return op0;\n+}\n+\f\n+/* Emit the code to divide OP0 by OP1, putting the result in TARGET\n+   if that is convenient, and returning where the result is.\n+   You may request either the quotient or the remainder as the result;\n+   specify REM_FLAG nonzero to get the remainder.\n+\n+   CODE is the expression code for which kind of division this is;\n+   it controls how rounding is done.  MODE is the machine mode to use.\n+   UNSIGNEDP nonzero means do unsigned division.  */\n+\n+/* ??? For CEIL_MOD_EXPR, can compute incorrect remainder with ANDI\n+   and then correct it by or'ing in missing high bits\n+   if result of ANDI is nonzero.\n+   For ROUND_MOD_EXPR, can use ANDI and then sign-extend the result.\n+   This could optimize to a bfexts instruction.\n+   But C doesn't use these operations, so their optimizations are\n+   left for later.  */\n+\n+rtx\n+expand_divmod (rem_flag, code, mode, op0, op1, target, unsignedp)\n+     int rem_flag;\n+     enum tree_code code;\n+     enum machine_mode mode;\n+     register rtx op0, op1, target;\n+     int unsignedp;\n+{\n+  register rtx result = 0;\n+  enum machine_mode compute_mode;\n+  int log = -1;\n+  int can_clobber_op0;\n+  int mod_insn_no_good = 0;\n+  rtx adjusted_op0 = op0;\n+  optab optab1, optab2;\n+\n+  /* Don't use the function value register as a target\n+     since we have to read it as well as write it,\n+     and function-inlining gets confused by this.  */\n+  if (target && REG_P (target) && REG_FUNCTION_VALUE_P (target))\n+    target = 0;\n+\n+  /* Don't clobber an operand while doing a multi-step calculation.  */\n+  if (target)\n+    if ((rem_flag && (reg_mentioned_p (target, op0)\n+\t\t      || (GET_CODE (op0) == MEM && GET_CODE (target) == MEM)))\n+\t|| reg_mentioned_p (target, op1)\n+\t|| (GET_CODE (op1) == MEM && GET_CODE (target) == MEM))\n+      target = 0;\n+\n+  can_clobber_op0 = (GET_CODE (op0) == REG && op0 == target);\n+\n+  if (GET_CODE (op1) == CONST_INT)\n+    log = exact_log2 (INTVAL (op1));\n+\n+  /* If log is >= 0, we are dividing by 2**log, and will do it by shifting,\n+     which is really floor-division.  Otherwise we will really do a divide,\n+     and we assume that is trunc-division.\n+\n+     We must correct the dividend by adding or subtracting something\n+     based on the divisor, in order to do the kind of rounding specified\n+     by CODE.  The correction depends on what kind of rounding is actually\n+     available, and that depends on whether we will shift or divide.\n+\n+     In many of these cases it is possible to perform the operation by a\n+     clever series of logical operations (shifts and/or exclusive-ors).\n+     Although avoiding the jump has the advantage that it extends the basic\n+     block and allows further optimization, the branch-free code is normally\n+     at least one instruction longer in the (most common) case where the\n+     dividend is non-negative.  Performance measurements of the two\n+     alternatives show that the branch-free code is slightly faster on the\n+     IBM ROMP but slower on CISC processors (significantly slower on the\n+     VAX).  Accordingly, the jump code has been retained.\n+\n+     On machines where the jump code is slower, the cost of a DIV or MOD\n+     operation can be set small (less than twice that of an addition); in \n+     that case, we pretend that we don't have a power of two and perform\n+     a normal division or modulus operation.  */\n+\n+  if ((code == TRUNC_MOD_EXPR || code == TRUNC_DIV_EXPR)\n+      && ! unsignedp\n+      && (rem_flag ? smod_pow2_cheap : sdiv_pow2_cheap))\n+    log = -1;\n+\n+  /* Get the mode in which to perform this computation.  Normally it will\n+     be MODE, but sometimes we can't do the desired operation in MODE.\n+     If so, pick a wider mode in which we can do the operation.  Convert\n+     to that mode at the start to avoid repeated conversions.\n+\n+     First see what operations we need.  These depend on the expression\n+     we are evaluating.  (We assume that divxx3 insns exist under the\n+     same conditions that modxx3 insns and that these insns don't normally\n+     fail.  If these assumptions are not correct, we may generate less\n+     efficient code in some cases.)\n+\n+     Then see if we find a mode in which we can open-code that operation\n+     (either a division, modulus, or shift).  Finally, check for the smallest\n+     mode for which we can do the operation with a library call.  */\n+\n+  optab1 = (log >= 0 ? (unsignedp ? lshr_optab : ashr_optab)\n+\t    : (unsignedp ? udiv_optab : sdiv_optab));\n+  optab2 = (log >= 0 ? optab1 : (unsignedp ? udivmod_optab : sdivmod_optab));\n+\n+  for (compute_mode = mode; compute_mode != VOIDmode;\n+       compute_mode = GET_MODE_WIDER_MODE (compute_mode))\n+    if (optab1->handlers[(int) compute_mode].insn_code != CODE_FOR_nothing\n+\t|| optab2->handlers[(int) compute_mode].insn_code != CODE_FOR_nothing)\n+      break;\n+\n+  if (compute_mode == VOIDmode)\n+    for (compute_mode = mode; compute_mode != VOIDmode;\n+\t compute_mode = GET_MODE_WIDER_MODE (compute_mode))\n+      if (optab1->handlers[(int) compute_mode].libfunc\n+\t  || optab2->handlers[(int) compute_mode].libfunc)\n+\tbreak;\n+\n+  /* If we still couldn't find a mode, use MODE; we'll probably abort in\n+     expand_binop.  */\n+  if (compute_mode == VOIDmode)\n+    compute_mode = mode;\n+\n+  /* Now convert to the best mode to use.  Show we made a copy of OP0\n+     and hence we can clobber it (we cannot use a SUBREG to widen\n+     something.  */\n+  if (compute_mode != mode)\n+    {\n+      adjusted_op0 = op0 = convert_to_mode (compute_mode, op0, unsignedp);\n+      can_clobber_op0 = 1;\n+      op1 = convert_to_mode (compute_mode, op1, unsignedp);\n+    }\n+\n+  if (target == 0 || GET_MODE (target) != compute_mode)\n+    target = gen_reg_rtx (compute_mode);\n+\n+  switch (code)\n+    {\n+    case TRUNC_MOD_EXPR:\n+    case TRUNC_DIV_EXPR:\n+      if (log >= 0 && ! unsignedp)\n+\t{\n+\t  rtx label = gen_label_rtx ();\n+\t  if (! can_clobber_op0)\n+\t    {\n+\t      adjusted_op0 = copy_to_suggested_reg (adjusted_op0, target);\n+\t      /* Copy op0 to a reg, since emit_cmp_insn will call emit_queue\n+\t\t which will screw up mem refs for autoincrements.  */\n+\t      op0 = force_reg (compute_mode, op0);\n+\t    }\n+\t  emit_cmp_insn (adjusted_op0, const0_rtx, GE, 0, compute_mode, 0, 0);\n+\t  emit_jump_insn (gen_bge (label));\n+\t  expand_inc (adjusted_op0, plus_constant (op1, -1));\n+\t  emit_label (label);\n+\t  mod_insn_no_good = 1;\n+\t}\n+      break;\n+\n+    case FLOOR_DIV_EXPR:\n+    case FLOOR_MOD_EXPR:\n+      if (log < 0 && ! unsignedp)\n+\t{\n+\t  rtx label = gen_label_rtx ();\n+\t  if (! can_clobber_op0)\n+\t    {\n+\t      adjusted_op0 = copy_to_suggested_reg (adjusted_op0, target);\n+\t      /* Copy op0 to a reg, since emit_cmp_insn will call emit_queue\n+\t\t which will screw up mem refs for autoincrements.  */\n+\t      op0 = force_reg (compute_mode, op0);\n+\t    }\n+\t  emit_cmp_insn (adjusted_op0, const0_rtx, GE, 0, compute_mode, 0, 0);\n+\t  emit_jump_insn (gen_bge (label));\n+\t  expand_dec (adjusted_op0, op1);\n+\t  expand_inc (adjusted_op0, const1_rtx);\n+\t  emit_label (label);\n+\t  mod_insn_no_good = 1;\n+\t}\n+      break;\n+\n+    case CEIL_DIV_EXPR:\n+    case CEIL_MOD_EXPR:\n+      if (! can_clobber_op0)\n+\t{\n+\t  adjusted_op0 = copy_to_suggested_reg (adjusted_op0, target);\n+\t  /* Copy op0 to a reg, since emit_cmp_insn will call emit_queue\n+\t     which will screw up mem refs for autoincrements.  */\n+\t  op0 = force_reg (compute_mode, op0);\n+\t}\n+      if (log < 0)\n+\t{\n+\t  rtx label = 0;\n+\t  if (! unsignedp)\n+\t    {\n+\t      label = gen_label_rtx ();\n+\t      emit_cmp_insn (adjusted_op0, const0_rtx, LE, 0, compute_mode, 0, 0);\n+\t      emit_jump_insn (gen_ble (label));\n+\t    }\n+\t  expand_inc (adjusted_op0, op1);\n+\t  expand_dec (adjusted_op0, const1_rtx);\n+\t  if (! unsignedp)\n+\t    emit_label (label);\n+\t}\n+      else\n+\t{\n+\t  adjusted_op0 = expand_binop (compute_mode, add_optab,\n+\t\t\t\t       adjusted_op0, plus_constant (op1, -1),\n+\t\t\t\t       0, 0, OPTAB_LIB_WIDEN);\n+\t}\n+      mod_insn_no_good = 1;\n+      break;\n+\n+    case ROUND_DIV_EXPR:\n+    case ROUND_MOD_EXPR:\n+      if (! can_clobber_op0)\n+\t{\n+\t  adjusted_op0 = copy_to_suggested_reg (adjusted_op0, target);\n+\t  /* Copy op0 to a reg, since emit_cmp_insn will call emit_queue\n+\t     which will screw up mem refs for autoincrements.  */\n+\t  op0 = force_reg (compute_mode, op0);\n+\t}\n+      if (log < 0)\n+\t{\n+\t  op1 = expand_shift (RSHIFT_EXPR, compute_mode, op1,\n+\t\t\t      integer_one_node, 0, 0);\n+\t  if (! unsignedp)\n+\t    {\n+\t      rtx label = gen_label_rtx ();\n+\t      emit_cmp_insn (adjusted_op0, const0_rtx, GE, 0, compute_mode, 0, 0);\n+\t      emit_jump_insn (gen_bge (label));\n+\t      expand_unop (compute_mode, neg_optab, op1, op1, 0);\n+\t      emit_label (label);\n+\t    }\n+\t  expand_inc (adjusted_op0, op1);\n+\t}\n+      else\n+\t{\n+\t  op1 = gen_rtx (CONST_INT, VOIDmode, (1 << log) / 2);\n+\t  expand_inc (adjusted_op0, op1);\n+\t}\n+      mod_insn_no_good = 1;\n+      break;\n+    }\n+\n+  if (rem_flag && !mod_insn_no_good)\n+    {\n+      /* Try to produce the remainder directly */\n+      if (log >= 0)\n+\tresult = expand_binop (compute_mode, and_optab, adjusted_op0,\n+\t\t\t       gen_rtx (CONST_INT, VOIDmode,\n+\t\t\t\t\t(1 << log) - 1),\n+\t\t\t       target, 1, OPTAB_LIB_WIDEN);\n+      else\n+\t{\n+\t  /* See if we can do remainder without a library call.  */\n+\t  result = sign_expand_binop (mode, umod_optab, smod_optab,\n+\t\t\t\t      adjusted_op0, op1, target,\n+\t\t\t\t      unsignedp, OPTAB_WIDEN);\n+\t  if (result == 0)\n+\t    {\n+\t      /* No luck there.  Can we do remainder and divide at once\n+\t\t without a library call?  */\n+\t      result = gen_reg_rtx (compute_mode);\n+\t      if (! expand_twoval_binop (unsignedp\n+\t\t\t\t\t ? udivmod_optab : sdivmod_optab,\n+\t\t\t\t\t adjusted_op0, op1,\n+\t\t\t\t\t 0, result, unsignedp))\n+\t\tresult = 0;\n+\t    }\n+\t}\n+    }\n+\n+  if (result)\n+    return gen_lowpart (mode, result);\n+\n+  /* Produce the quotient.  */\n+  if (log >= 0)\n+    result = expand_shift (RSHIFT_EXPR, compute_mode, adjusted_op0,\n+\t\t\t   build_int_2 (log, 0), target, unsignedp);\n+  else if (rem_flag && !mod_insn_no_good)\n+    /* If producing quotient in order to subtract for remainder,\n+       and a remainder subroutine would be ok,\n+       don't use a divide subroutine.  */\n+    result = sign_expand_binop (compute_mode, udiv_optab, sdiv_optab,\n+\t\t\t\tadjusted_op0, op1, 0, unsignedp, OPTAB_WIDEN);\n+  else\n+    {\n+      /* Try a quotient insn, but not a library call.  */\n+      result = sign_expand_binop (compute_mode, udiv_optab, sdiv_optab,\n+\t\t\t\t  adjusted_op0, op1, rem_flag ? 0 : target,\n+\t\t\t\t  unsignedp, OPTAB_WIDEN);\n+      if (result == 0)\n+\t{\n+\t  /* No luck there.  Try a quotient-and-remainder insn,\n+\t     keeping the quotient alone.  */\n+\t  result = gen_reg_rtx (mode);\n+\t  if (! expand_twoval_binop (unsignedp ? udivmod_optab : sdivmod_optab,\n+\t\t\t\t     adjusted_op0, op1,\n+\t\t\t\t     result, 0, unsignedp))\n+\t    result = 0;\n+\t}\n+\n+      /* If still no luck, use a library call.  */\n+      if (result == 0)\n+\tresult = sign_expand_binop (compute_mode, udiv_optab, sdiv_optab,\n+\t\t\t\t    adjusted_op0, op1, rem_flag ? 0 : target,\n+\t\t\t\t    unsignedp, OPTAB_LIB_WIDEN);\n+    }\n+\n+  /* If we really want the remainder, get it by subtraction.  */\n+  if (rem_flag)\n+    {\n+      if (result == 0)\n+\t/* No divide instruction either.  Use library for remainder.  */\n+\tresult = sign_expand_binop (compute_mode, umod_optab, smod_optab,\n+\t\t\t\t    op0, op1, target,\n+\t\t\t\t    unsignedp, OPTAB_LIB_WIDEN);\n+      else\n+\t{\n+\t  /* We divided.  Now finish doing X - Y * (X / Y).  */\n+\t  result = expand_mult (compute_mode, result, op1, target, unsignedp);\n+\t  if (! result) abort ();\n+\t  result = expand_binop (compute_mode, sub_optab, op0,\n+\t\t\t\t result, target, unsignedp, OPTAB_LIB_WIDEN);\n+\t}\n+    }\n+\n+  if (result == 0)\n+    abort ();\n+\n+  return gen_lowpart (mode, result);\n+}\n+\f\n+/* Return a tree node with data type TYPE, describing the value of X.\n+   Usually this is an RTL_EXPR, if there is no obvious better choice.\n+   X may be an expression, however we only support those expressions\n+   generated by loop.c.   */\n+\n+tree\n+make_tree (type, x)\n+     tree type;\n+     rtx x;\n+{\n+  tree t;\n+\n+  switch (GET_CODE (x))\n+    {\n+    case CONST_INT:\n+      t = build_int_2 (INTVAL (x),\n+\t\t       ! TREE_UNSIGNED (type) && INTVAL (x) >= 0 ? 0 : -1);\n+      TREE_TYPE (t) = type;\n+      return t;\n+\n+    case CONST_DOUBLE:\n+      if (GET_MODE (x) == VOIDmode)\n+\t{\n+\t  t = build_int_2 (CONST_DOUBLE_LOW (x), CONST_DOUBLE_HIGH (x));\n+\t  TREE_TYPE (t) = type;\n+\t}\n+      else\n+\t{\n+\t  REAL_VALUE_TYPE d;\n+\n+\t  REAL_VALUE_FROM_CONST_DOUBLE (d, x);\n+\t  t = build_real (type, d);\n+\t}\n+\n+      return t;\n+\t  \n+    case PLUS:\n+      return fold (build (PLUS_EXPR, type, make_tree (type, XEXP (x, 0)),\n+\t\t\t  make_tree (type, XEXP (x, 1))));\n+\t\t\t\t\t\t       \n+    case MINUS:\n+      return fold (build (MINUS_EXPR, type, make_tree (type, XEXP (x, 0)),\n+\t\t\t  make_tree (type, XEXP (x, 1))));\n+\t\t\t\t\t\t       \n+    case NEG:\n+      return fold (build1 (NEGATE_EXPR, type, make_tree (type, XEXP (x, 0))));\n+\n+    case MULT:\n+      return fold (build (MULT_EXPR, type, make_tree (type, XEXP (x, 0)),\n+\t\t\t  make_tree (type, XEXP (x, 1))));\n+\t\t\t\t\t\t      \n+    case ASHIFT:\n+      return fold (build (LSHIFT_EXPR, type, make_tree (type, XEXP (x, 0)),\n+\t\t\t  make_tree (type, XEXP (x, 1))));\n+\t\t\t\t\t\t      \n+    case LSHIFTRT:\n+      return fold (convert (type,\n+\t\t\t    build (RSHIFT_EXPR, unsigned_type (type),\n+\t\t\t\t   make_tree (unsigned_type (type),\n+\t\t\t\t\t      XEXP (x, 0)),\n+\t\t\t\t   make_tree (type, XEXP (x, 1)))));\n+\t\t\t\t\t\t      \n+    case ASHIFTRT:\n+      return fold (convert (type,\n+\t\t\t    build (RSHIFT_EXPR, signed_type (type),\n+\t\t\t\t   make_tree (signed_type (type), XEXP (x, 0)),\n+\t\t\t\t   make_tree (type, XEXP (x, 1)))));\n+\t\t\t\t\t\t      \n+    case DIV:\n+      if (TREE_CODE (type) != REAL_TYPE)\n+\tt = signed_type (type);\n+      else\n+\tt = type;\n+\n+      return fold (convert (type,\n+\t\t\t    build (TRUNC_DIV_EXPR, t,\n+\t\t\t\t   make_tree (t, XEXP (x, 0)),\n+\t\t\t\t   make_tree (t, XEXP (x, 1)))));\n+    case UDIV:\n+      t = unsigned_type (type);\n+      return fold (convert (type,\n+\t\t\t    build (TRUNC_DIV_EXPR, t,\n+\t\t\t\t   make_tree (t, XEXP (x, 0)),\n+\t\t\t\t   make_tree (t, XEXP (x, 1)))));\n+   default:\n+      t = make_node (RTL_EXPR);\n+      TREE_TYPE (t) = type;\n+      RTL_EXPR_RTL (t) = x;\n+      /* There are no insns to be output\n+\t when this rtl_expr is used.  */\n+      RTL_EXPR_SEQUENCE (t) = 0;\n+      return t;\n+    }\n+}\n+\n+/* Return an rtx representing the value of X * MULT + ADD.\n+   TARGET is a suggestion for where to store the result (an rtx).\n+   MODE is the machine mode for the computation.\n+   X and MULT must have mode MODE.  ADD may have a different mode.\n+   So can X (defaults to same as MODE).\n+   UNSIGNEDP is non-zero to do unsigned multiplication.\n+   This may emit insns.  */\n+\n+rtx\n+expand_mult_add (x, target, mult, add, mode, unsignedp)\n+     rtx x, target, mult, add;\n+     enum machine_mode mode;\n+     int unsignedp;\n+{\n+  tree type = type_for_mode (mode, unsignedp);\n+  tree add_type = (GET_MODE (add) == VOIDmode\n+\t\t   ? type : type_for_mode (GET_MODE (add)));\n+  tree result =  fold (build (PLUS_EXPR, type,\n+\t\t\t      fold (build (MULT_EXPR, type,\n+\t\t\t\t\t   make_tree (type, x),\n+\t\t\t\t\t   make_tree (type, mult))),\n+\t\t\t      make_tree (add_type, add)));\n+\n+  return expand_expr (result, target, VOIDmode, 0);\n+}\n+\f\n+/* Compute the logical-and of OP0 and OP1, storing it in TARGET\n+   and returning TARGET.\n+\n+   If TARGET is 0, a pseudo-register or constant is returned.  */\n+\n+rtx\n+expand_and (op0, op1, target)\n+     rtx op0, op1, target;\n+{\n+  enum machine_mode mode = VOIDmode;\n+  rtx tem;\n+\n+  if (GET_MODE (op0) != VOIDmode)\n+    mode = GET_MODE (op0);\n+  else if (GET_MODE (op1) != VOIDmode)\n+    mode = GET_MODE (op1);\n+\n+  if (mode != VOIDmode)\n+    tem = expand_binop (mode, and_optab, op0, op1, target, 0, OPTAB_LIB_WIDEN);\n+  else if (GET_CODE (op0) == CONST_INT && GET_CODE (op1) == CONST_INT)\n+    tem = gen_rtx (CONST_INT, VOIDmode, INTVAL (op0) & INTVAL (op1));\n+  else\n+    abort ();\n+\n+  if (target == 0)\n+    target = tem;\n+  else if (tem != target)\n+    emit_move_insn (target, tem);\n+  return target;\n+}\n+\f\n+/* Emit a store-flags instruction for comparison CODE on OP0 and OP1\n+   and storing in TARGET.  Normally return TARGET.\n+   Return 0 if that cannot be done.\n+\n+   MODE is the mode to use for OP0 and OP1 should they be CONST_INTs.  If\n+   it is VOIDmode, they cannot both be CONST_INT.  \n+\n+   UNSIGNEDP is for the case where we have to widen the operands\n+   to perform the operation.  It says to use zero-extension.\n+\n+   NORMALIZEP is 1 if we should convert the result to be either zero\n+   or one one.  Normalize is -1 if we should convert the result to be\n+   either zero or -1.  If NORMALIZEP is zero, the result will be left\n+   \"raw\" out of the scc insn.  */\n+\n+rtx\n+emit_store_flag (target, code, op0, op1, mode, unsignedp, normalizep)\n+     rtx target;\n+     enum rtx_code code;\n+     rtx op0, op1;\n+     enum machine_mode mode;\n+     int unsignedp;\n+     int normalizep;\n+{\n+  rtx subtarget;\n+  enum insn_code icode;\n+  enum machine_mode compare_mode;\n+  enum machine_mode target_mode = GET_MODE (target);\n+  rtx tem;\n+  rtx last = 0;\n+  rtx pattern, comparison;\n+\n+  if (mode == VOIDmode)\n+    mode = GET_MODE (op0);\n+\n+  /* For some comparisons with 1 and -1, we can convert this to \n+     comparisons with zero.  This will often produce more opportunities for\n+     store-flag insns. */\n+\n+  switch (code)\n+    {\n+    case LT:\n+      if (op1 == const1_rtx)\n+\top1 = const0_rtx, code = LE;\n+      break;\n+    case LE:\n+      if (op1 == constm1_rtx)\n+\top1 = const0_rtx, code = LT;\n+      break;\n+    case GE:\n+      if (op1 == const1_rtx)\n+\top1 = const0_rtx, code = GT;\n+      break;\n+    case GT:\n+      if (op1 == constm1_rtx)\n+\top1 = const0_rtx, code = GE;\n+      break;\n+    case GEU:\n+      if (op1 == const1_rtx)\n+\top1 = const0_rtx, code = NE;\n+      break;\n+    case LTU:\n+      if (op1 == const1_rtx)\n+\top1 = const0_rtx, code = EQ;\n+      break;\n+    }\n+\n+  /* From now on, we won't change CODE, so set ICODE now.  */\n+  icode = setcc_gen_code[(int) code];\n+\n+  /* If this is A < 0 or A >= 0, we can do this by taking the ones\n+     complement of A (for GE) and shifting the sign bit to the low bit.  */\n+  if (op1 == const0_rtx && (code == LT || code == GE)\n+      && GET_MODE_CLASS (mode) == MODE_INT\n+      && (normalizep || STORE_FLAG_VALUE == 1\n+\t  || (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_INT\n+\t      && STORE_FLAG_VALUE == 1 << (GET_MODE_BITSIZE (mode) - 1))))\n+    {\n+      rtx subtarget = target;\n+\n+      /* If the result is to be wider than OP0, it is best to convert it\n+\t first.  If it is to be narrower, it is *incorrect* to convert it\n+\t first.  */\n+      if (GET_MODE_SIZE (target_mode) > GET_MODE_SIZE (mode))\n+\t{\n+\t  op0 = convert_to_mode (target_mode, op0, 0);\n+\t  mode = target_mode;\n+\t}\n+\n+      if (target_mode != mode)\n+\tsubtarget = 0;\n+\n+      if (code == GE)\n+\top0 = expand_unop (mode, one_cmpl_optab, op0, subtarget, 0);\n+\n+      if (normalizep || STORE_FLAG_VALUE == 1)\n+\t/* If we are supposed to produce a 0/1 value, we want to do\n+\t   a logical shift from the sign bit to the low-order bit; for\n+\t   a -1/0 value, we do an arithmetic shift.  */\n+\top0 = expand_shift (RSHIFT_EXPR, mode, op0,\n+\t\t\t    size_int (GET_MODE_BITSIZE (mode) - 1),\n+\t\t\t    subtarget, normalizep != -1);\n+\n+      if (mode != target_mode)\n+\top0 = convert_to_mode (target_mode, op0, 0);\n+\n+      return op0;\n+    }\n+\n+  if (icode != CODE_FOR_nothing)\n+    {\n+      /* We think we may be able to do this with a scc insn.  Emit the\n+\t comparison and then the scc insn.\n+\n+\t compare_from_rtx may call emit_queue, which would be deleted below\n+\t if the scc insn fails.  So call it ourselves before setting LAST.  */\n+\n+      emit_queue ();\n+      last = get_last_insn ();\n+\n+      comparison = compare_from_rtx (op0, op1, code, unsignedp, mode, 0, 0);\n+      if (GET_CODE (comparison) == CONST_INT)\n+\treturn (comparison == const0_rtx ? const0_rtx\n+\t\t: normalizep == 1 ? const1_rtx\n+\t\t: normalizep == -1 ? constm1_rtx\n+\t\t: const_true_rtx);\n+\n+      /* Get a reference to the target in the proper mode for this insn.  */\n+      compare_mode = insn_operand_mode[(int) icode][0];\n+      subtarget = target;\n+      if (preserve_subexpressions_p ()\n+\t  || ! (*insn_operand_predicate[(int) icode][0]) (subtarget, compare_mode))\n+\tsubtarget = gen_reg_rtx (compare_mode);\n+\n+      pattern = GEN_FCN (icode) (subtarget);\n+      if (pattern)\n+\t{\n+\t  emit_insn (pattern);\n+\n+\t  /* If we are converting to a wider mode, first convert to\n+\t     TARGET_MODE, then normalize.  This produces better combining\n+\t     opportunities on machines that have a SIGN_EXTRACT when we are\n+\t     testing a single bit.  This mostly benefits the 68k.\n+\n+\t     If STORE_FLAG_VALUE does not have the sign bit set when\n+\t     interpreted in COMPARE_MODE, we can do this conversion as\n+\t     unsigned, which is usually more efficient.  */\n+\t  if (GET_MODE_SIZE (target_mode) > GET_MODE_SIZE (compare_mode))\n+\t    {\n+\t      convert_move (target, subtarget,\n+\t\t\t    (GET_MODE_BITSIZE (compare_mode)\n+\t\t\t     <= HOST_BITS_PER_INT)\n+\t\t\t    && 0 == (STORE_FLAG_VALUE\n+\t\t\t\t     & (1 << (GET_MODE_BITSIZE (compare_mode) -1))));\n+\t      op0 = target;\n+\t      compare_mode = target_mode;\n+\t    }\n+\t  else\n+\t    op0 = subtarget;\n+\n+\t  /* Now normalize to the proper value in COMPARE_MODE.  Sometimes\n+\t     we don't have to do anything.  */\n+\t  if (normalizep == 0 || normalizep == STORE_FLAG_VALUE)\n+\t    ;\n+\t  else if (normalizep == - STORE_FLAG_VALUE)\n+\t    op0 = expand_unop (compare_mode, neg_optab, op0, subtarget, 0);\n+\n+\t  /* We don't want to use STORE_FLAG_VALUE < 0 below since this\n+\t     makes it hard to use a value of just the sign bit due to\n+\t     ANSI integer constant typing rules.  */\n+\t  else if (GET_MODE_BITSIZE (compare_mode) <= HOST_BITS_PER_INT\n+\t\t   && (STORE_FLAG_VALUE\n+\t\t       & (1 << (GET_MODE_BITSIZE (compare_mode) - 1))))\n+\t    op0 = expand_shift (RSHIFT_EXPR, compare_mode, op0,\n+\t\t\t\tsize_int (GET_MODE_BITSIZE (compare_mode) - 1),\n+\t\t\t\tsubtarget, normalizep == 1);\n+\t  else if (STORE_FLAG_VALUE & 1)\n+\t    {\n+\t      op0 = expand_and (op0, const1_rtx, subtarget);\n+\t      if (normalizep == -1)\n+\t\top0 = expand_unop (compare_mode, neg_optab, op0, op0, 0);\n+\t    }\n+\t  else\n+\t    abort ();\n+\n+\t  /* If we were converting to a smaller mode, do the \n+\t     conversion now.  */\n+\t  if (target_mode != compare_mode)\n+\t    {\n+\t      convert_move (target, op0);\n+\t      return target;\n+\t    }\n+\t  else\n+\t    return op0;\n+\t}\n+    }\n+\n+  if (last)\n+    delete_insns_since (last);\n+\n+  subtarget = target_mode == mode ? target : 0;\n+\n+  /* If we reached here, we can't do this with a scc insn.  However, there\n+     are some comparisons that can be done directly.  For example, if\n+     this is an equality comparison of integers, we can try to exclusive-or\n+     (or subtract) the two operands and use a recursive call to try the\n+     comparison with zero.  Don't do any of these cases if branches are\n+     very cheap.  */\n+\n+  if (BRANCH_COST >= 0\n+      && GET_MODE_CLASS (mode) == MODE_INT && (code == EQ || code == NE)\n+      && op1 != const0_rtx)\n+    {\n+      tem = expand_binop (mode, xor_optab, op0, op1, subtarget, 1,\n+\t\t\t  OPTAB_WIDEN);\n+\n+      if (tem == 0)\n+\ttem = expand_binop (mode, sub_optab, op0, op1, subtarget, 1,\n+\t\t\t    OPTAB_WIDEN);\n+      if (tem != 0)\n+\ttem = emit_store_flag (target, code, tem, const0_rtx,\n+\t\t\t       mode, unsignedp, normalizep);\n+      if (tem == 0)\n+\tdelete_insns_since (last);\n+      return tem;\n+    }\n+\n+  /* Some other cases we can do are EQ, NE, LE, and GT comparisons with \n+     the constant zero.  Reject all other comparisons at this point.  Only\n+     do LE and GT if branches are expensive since they are expensive on\n+     2-operand machines.  */\n+\n+  if (BRANCH_COST == 0\n+      || GET_MODE_CLASS (mode) != MODE_INT || op1 != const0_rtx\n+      || (code != EQ && code != NE\n+\t  && (BRANCH_COST <= 1 || (code != LE && code != GT))))\n+    return 0;\n+\n+  /* See what we need to return.  We can only return a 1, -1, or the\n+     sign bit.  */\n+\n+  if (normalizep == 0)\n+    {\n+      if (STORE_FLAG_VALUE == 1 || STORE_FLAG_VALUE == -1)\n+\tnormalizep = STORE_FLAG_VALUE;\n+\n+      else if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_INT\n+\t       && STORE_FLAG_VALUE == 1 << (GET_MODE_BITSIZE (mode) - 1))\n+\t;\n+      else\n+\treturn 0;\n+    }\n+\n+  /* Try to put the result of the comparison in the sign bit.  Assume we can't\n+     do the necessary operation below.  */\n+\n+  tem = 0;\n+\n+  /* To see if A <= 0, compute (A | (A - 1)).  A <= 0 iff that result has\n+     the sign bit set.  */\n+\n+  if (code == LE)\n+    {\n+      /* This is destructive, so SUBTARGET can't be OP0.  */\n+      if (rtx_equal_p (subtarget, op0))\n+\tsubtarget = 0;\n+\n+      tem = expand_binop (mode, sub_optab, op0, const1_rtx, subtarget, 0,\n+\t\t\t  OPTAB_WIDEN);\n+      if (tem)\n+\ttem = expand_binop (mode, ior_optab, op0, tem, subtarget, 0,\n+\t\t\t    OPTAB_WIDEN);\n+    }\n+\n+  /* To see if A > 0, compute (((signed) A) << BITS) - A, where BITS is the\n+     number of bits in the mode of OP0, minus one.  */\n+\n+  if (code == GT)\n+    {\n+      if (rtx_equal_p (subtarget, op0))\n+\tsubtarget = 0;\n+\n+      tem = expand_shift (RSHIFT_EXPR, mode, op0,\n+\t\t\t  size_int (GET_MODE_BITSIZE (mode) - 1),\n+\t\t\t  subtarget, 0);\n+      tem = expand_binop (mode, sub_optab, tem, op0, subtarget, 0,\n+\t\t\t  OPTAB_WIDEN);\n+    }\n+\t\t\t\t    \n+  if (code == EQ || code == NE)\n+    {\n+      /* For EQ or NE, one way to do the comparison is to apply an operation\n+\t that converts the operand into a positive number if it is non-zero\n+\t or zero if it was originally zero.  Then, for EQ, we subtract 1 and\n+\t for NE we negate.  This puts the result in the sign bit.  Then we\n+\t normalize with a shift, if needed. \n+\n+\t Two operations that can do the above actions are ABS and FFS, so try\n+\t them.  If that doesn't work, and MODE is smaller than a full word,\n+\t we can use zero-extention to the wider mode (an unsigned conversion)\n+\t as the operation.  */\n+\n+      if (abs_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)\n+\ttem = expand_unop (mode, abs_optab, op0, subtarget, 1);\n+      else if (ffs_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)\n+\ttem = expand_unop (mode, ffs_optab, op0, subtarget, 1);\n+      else if (GET_MODE_SIZE (mode) < UNITS_PER_WORD)\n+\t{\n+\t  mode = word_mode;\n+\t  tem = convert_to_mode (mode, op0, 1);\n+\t}\n+\n+      if (tem != 0)\n+\t{\n+\t  if (code == EQ)\n+\t    tem = expand_binop (mode, sub_optab, tem, const1_rtx, subtarget,\n+\t\t\t\t0, OPTAB_WIDEN);\n+\t  else\n+\t    tem = expand_unop (mode, neg_optab, tem, subtarget, 0);\n+\t}\n+\n+      /* If we couldn't do it that way, for NE we can \"or\" the two's complement\n+\t of the value with itself.  For EQ, we take the one's complement of\n+\t that \"or\", which is an extra insn, so we only handle EQ if branches\n+\t are expensive.  */\n+\n+      if (tem == 0 && (code == NE || BRANCH_COST > 1))\n+\t{\n+\t  tem = expand_unop (mode, neg_optab, op0, subtarget, 0);\n+\t  tem = expand_binop (mode, ior_optab, tem, op0, subtarget, 0,\n+\t\t\t      OPTAB_WIDEN);\n+\n+\t  if (tem && code == EQ)\n+\t    tem = expand_unop (mode, one_cmpl_optab, tem, subtarget, 0);\n+\t}\n+    }\n+\n+  if (tem && normalizep)\n+    tem = expand_shift (RSHIFT_EXPR, mode, tem,\n+\t\t\tsize_int (GET_MODE_BITSIZE (mode) - 1),\n+\t\t\ttem, normalizep == 1);\n+\n+  if (tem && GET_MODE (tem) != target_mode)\n+    {\n+      convert_move (target, tem, 0);\n+      tem = target;\n+    }\n+\n+  if (tem == 0)\n+    delete_insns_since (last);\n+\n+  return tem;\n+}\n+  emit_jump_insn ((*bcc_gen_fctn[(int) code]) (label));\n+  emit_move_insn (target, const1_rtx);\n+  emit_label (label);\n+\n+  return target;\n+}"}]}