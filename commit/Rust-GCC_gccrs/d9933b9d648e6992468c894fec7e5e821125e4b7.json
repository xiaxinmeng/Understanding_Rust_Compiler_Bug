{"sha": "d9933b9d648e6992468c894fec7e5e821125e4b7", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDk5MzNiOWQ2NDhlNjk5MjQ2OGM4OTRmZWM3ZTVlODIxMTI1ZTRiNw==", "commit": {"author": {"name": "Ulrich Weigand", "email": "uweigand@de.ibm.com", "date": "2007-09-14T04:24:25Z"}, "committer": {"name": "Ben Elliston", "email": "bje@gcc.gnu.org", "date": "2007-09-14T04:24:25Z"}, "message": "vmx2spu.h (vec_extract, [...]): New intrinsics.\n\n\t* config/spu/vmx2spu.h (vec_extract, vec_insert, vec_lvlx,\n\tvec_lvlxl, vec_lvrx, vec_lvrxl, vec_promote, vec_splats,\n\tvec_stvlx, vec_stvlxl, vec_stvrx, vec_stvrxl): New intrinsics.\n\nFrom-SVN: r128487", "tree": {"sha": "86d83a47bfd17a7cb808e59493df8dc509cb3932", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/86d83a47bfd17a7cb808e59493df8dc509cb3932"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d9933b9d648e6992468c894fec7e5e821125e4b7", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d9933b9d648e6992468c894fec7e5e821125e4b7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d9933b9d648e6992468c894fec7e5e821125e4b7", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d9933b9d648e6992468c894fec7e5e821125e4b7/comments", "author": null, "committer": null, "parents": [{"sha": "d4caa5795f4a49f562d0f0338c4bd44b5f615957", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d4caa5795f4a49f562d0f0338c4bd44b5f615957", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d4caa5795f4a49f562d0f0338c4bd44b5f615957"}], "stats": {"total": 550, "additions": 549, "deletions": 1}, "files": [{"sha": "cb845fc86ae0bb751a62d207eeb6f818dbcba1f9", "filename": "gcc/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d9933b9d648e6992468c894fec7e5e821125e4b7/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d9933b9d648e6992468c894fec7e5e821125e4b7/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=d9933b9d648e6992468c894fec7e5e821125e4b7", "patch": "@@ -1,3 +1,9 @@\n+2007-09-14  Ulrich Weigand  <Ulrich.Weigand@de.ibm.com>\n+\n+\t* config/spu/vmx2spu.h (vec_extract, vec_insert, vec_lvlx,\n+\tvec_lvlxl, vec_lvrx, vec_lvrxl, vec_promote, vec_splats,\n+\tvec_stvlx, vec_stvlxl, vec_stvrx, vec_stvrxl): New intrinsics.\n+\n 2007-09-13  Eric Christopher  <echristo@apple.com>\n \t    Kenneth Zadeck <zadeck@naturalbridge.com>\n "}, {"sha": "d135d4d97bff52e2a322f8662c008f3de43ca768", "filename": "gcc/config/spu/vmx2spu.h", "status": "modified", "additions": 543, "deletions": 1, "changes": 544, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d9933b9d648e6992468c894fec7e5e821125e4b7/gcc%2Fconfig%2Fspu%2Fvmx2spu.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d9933b9d648e6992468c894fec7e5e821125e4b7/gcc%2Fconfig%2Fspu%2Fvmx2spu.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fvmx2spu.h?ref=d9933b9d648e6992468c894fec7e5e821125e4b7", "patch": "@@ -1,4 +1,4 @@\n-/* Copyright (C) 2006 Free Software Foundation, Inc.\n+/* Copyright (C) 2006, 2007 Free Software Foundation, Inc.\n \n    This file is free software; you can redistribute it and/or modify it under\n    the terms of the GNU General Public License as published by the Free\n@@ -3440,6 +3440,548 @@ static inline int vec_any_out(vec_float4 a, vec_float4 b)\n   return (spu_extract(spu_gather(spu_nor(spu_cmpabsgt(a, b), (vec_uint4)(spu_rlmaska((vec_int4)(b), -31)))), 0) != 0xF);\n }\n \n+\n+/* CBE Language Extension Intrinsics\n+ */\n+\n+/* vec_extract (extract element from vector)\n+ * ===========\n+ */\n+#define vec_extract(_a, _element)\tspu_extract(_a, _element)\n+\n+\n+/* vec_insert (insert scalar into specified vector element)\n+ * ==========\n+ */\n+#define vec_insert(_a, _b, _element)\tspu_insert(_a, _b, _element)\n+\n+/* vec_lvlx (load vector left indexed)\n+ * ========\n+ */\n+static inline vec_uchar16 vec_lvlx(int a, unsigned char *b)\n+{\n+  vec_uchar16 *p = (vec_uchar16 *)((unsigned char *)(b) + a);\n+  return(spu_slqwbyte(*p, (unsigned int)p & 0xF));\n+}\n+\n+static inline vec_uchar16 vec_lvlx(int a, vec_uchar16 *b)\n+{\n+  vec_uchar16 *p = (vec_uchar16 *)((unsigned char *)(b) + a);\n+  return(spu_slqwbyte(*p, (unsigned int)p & 0xF));\n+}\n+\n+static inline vec_char16 vec_lvlx(int a, signed char *b)\n+{\n+  vec_char16 *p = (vec_char16 *)((unsigned char *)(b) + a);\n+  return(spu_slqwbyte(*p, (unsigned int)p & 0xF));\n+}\n+\n+static inline vec_char16 vec_lvlx(int a, vec_char16 *b)\n+{\n+  vec_char16 *p = (vec_char16 *)((unsigned char *)(b) + a);\n+  return(spu_slqwbyte(*p, (unsigned int)p & 0xF));\n+}\n+\n+static inline vec_ushort8 vec_lvlx(int a, unsigned short *b)\n+{\n+  vec_ushort8 *p = (vec_ushort8 *)((unsigned char *)(b) + a);\n+  return(spu_slqwbyte(*p, (unsigned int)p & 0xF));\n+}\n+\n+static inline vec_ushort8 vec_lvlx(int a, vec_ushort8 *b)\n+{\n+  vec_ushort8 *p = (vec_ushort8 *)((unsigned char *)(b) + a);\n+  return(spu_slqwbyte(*p, (unsigned int)p & 0xF));\n+}\n+\n+static inline vec_short8 vec_lvlx(int a, signed short *b)\n+{\n+  vec_short8 *p = (vec_short8 *)((unsigned char *)(b) + a);\n+  return(spu_slqwbyte(*p, (unsigned int)p & 0xF));\n+}\n+\n+static inline vec_short8 vec_lvlx(int a, vec_short8 *b)\n+{\n+  vec_short8 *p = (vec_short8 *)((unsigned char *)(b) + a);\n+  return(spu_slqwbyte(*p, (unsigned int)p & 0xF));\n+}\n+\n+static inline vec_uint4 vec_lvlx(int a, unsigned int *b)\n+{\n+  vec_uint4 *p = (vec_uint4 *)((unsigned char *)(b) + a);\n+  return(spu_slqwbyte(*p, (unsigned int)p & 0xF));\n+}\n+\n+static inline vec_uint4 vec_lvlx(int a, vec_uint4 *b)\n+{\n+  vec_uint4 *p = (vec_uint4 *)((unsigned char *)(b) + a);\n+  return(spu_slqwbyte(*p, (unsigned int)p & 0xF));\n+}\n+\n+static inline vec_int4 vec_lvlx(int a, signed int *b)\n+{\n+  vec_int4 *p = (vec_int4 *)((unsigned char *)(b) + a);\n+  return(spu_slqwbyte(*p, (unsigned int)p & 0xF));\n+}\n+\n+static inline vec_int4 vec_lvlx(int a, vec_int4 *b)\n+{\n+  vec_int4 *p = (vec_int4 *)((unsigned char *)(b) + a);\n+  return(spu_slqwbyte(*p, (unsigned int)p & 0xF));\n+}\n+\n+static inline vec_float4 vec_lvlx(int a, float *b)\n+{\n+  vec_float4 *p = (vec_float4 *)((unsigned char *)(b) + a);\n+  return(spu_slqwbyte(*p, (unsigned int)p & 0xF));\n+}\n+\n+static inline vec_float4 vec_lvlx(int a, vec_float4 *b)\n+{\n+  vec_float4 *p = (vec_float4 *)((unsigned char *)(b) + a);\n+  return(spu_slqwbyte(*p, (unsigned int)p & 0xF));\n+}\n+\n+\n+/* vec_lvlxl (load vector left indexed last)\n+ * =========\n+ */\n+#define vec_lvlxl(_a, _b)\tvec_lvlx(_a, _b)\n+\n+\n+/* vec_lvrx (load vector right indexed)\n+ * ========\n+ */\n+static inline vec_uchar16 vec_lvrx(int a, unsigned char *b)\n+{\n+  vec_uchar16 *p = (vec_uchar16 *)((unsigned char *)(b) + a);\n+  return(spu_rlmaskqwbyte(*p, ((int)p & 0xF)-16));\n+}\n+\n+static inline vec_uchar16 vec_lvrx(int a, vec_uchar16 *b)\n+{\n+  vec_uchar16 *p = (vec_uchar16 *)((unsigned char *)(b) + a);\n+  return(spu_rlmaskqwbyte(*p, ((int)p & 0xF)-16));\n+}\n+\n+static inline vec_char16 vec_lvrx(int a, signed char *b)\n+{\n+  vec_char16 *p = (vec_char16 *)((unsigned char *)(b) + a);\n+  return(spu_rlmaskqwbyte(*p, ((int)p & 0xF)-16));\n+}\n+\n+static inline vec_char16 vec_lvrx(int a, vec_char16 *b)\n+{\n+  vec_char16 *p = (vec_char16 *)((unsigned char *)(b) + a);\n+  return(spu_rlmaskqwbyte(*p, ((int)p & 0xF)-16));\n+}\n+\n+static inline vec_ushort8 vec_lvrx(int a, unsigned short *b)\n+{\n+  vec_ushort8 *p = (vec_ushort8 *)((unsigned char *)(b) + a);\n+  return(spu_rlmaskqwbyte(*p, ((int)p & 0xF)-16));\n+}\n+\n+static inline vec_ushort8 vec_lvrx(int a, vec_ushort8 *b)\n+{\n+  vec_ushort8 *p = (vec_ushort8 *)((unsigned char *)(b) + a);\n+  return(spu_rlmaskqwbyte(*p, ((int)p & 0xF)-16));\n+}\n+\n+static inline vec_short8 vec_lvrx(int a, signed short *b)\n+{\n+  vec_short8 *p = (vec_short8 *)((unsigned char *)(b) + a);\n+  return(spu_rlmaskqwbyte(*p, ((int)p & 0xF)-16));\n+}\n+\n+static inline vec_short8 vec_lvrx(int a, vec_short8 *b)\n+{\n+  vec_short8 *p = (vec_short8 *)((unsigned char *)(b) + a);\n+  return(spu_rlmaskqwbyte(*p, ((int)p & 0xF)-16));\n+}\n+\n+static inline vec_uint4 vec_lvrx(int a, unsigned int *b)\n+{\n+  vec_uint4 *p = (vec_uint4 *)((unsigned char *)(b) + a);\n+  return(spu_rlmaskqwbyte(*p, ((int)p & 0xF)-16));\n+}\n+\n+static inline vec_uint4 vec_lvrx(int a, vec_uint4 *b)\n+{\n+  vec_uint4 *p = (vec_uint4 *)((unsigned char *)(b) + a);\n+  return(spu_rlmaskqwbyte(*p, ((int)p & 0xF)-16));\n+}\n+\n+static inline vec_int4 vec_lvrx(int a, signed int *b)\n+{\n+  vec_int4 *p = (vec_int4 *)((unsigned char *)(b) + a);\n+  return(spu_rlmaskqwbyte(*p, ((int)p & 0xF)-16));\n+}\n+\n+static inline vec_int4 vec_lvrx(int a, vec_int4 *b)\n+{\n+  vec_int4 *p = (vec_int4 *)((unsigned char *)(b) + a);\n+  return(spu_rlmaskqwbyte(*p, ((int)p & 0xF)-16));\n+}\n+\n+static inline vec_float4 vec_lvrx(int a, float *b)\n+{\n+  vec_float4 *p = (vec_float4 *)((unsigned char *)(b) + a);\n+  return(spu_rlmaskqwbyte(*p, ((int)p & 0xF)-16));\n+}\n+\n+static inline vec_float4 vec_lvrx(int a, vec_float4 *b)\n+{\n+  vec_float4 *p = (vec_float4 *)((unsigned char *)(b) + a);\n+  return(spu_rlmaskqwbyte(*p, ((int)p & 0xF)-16));\n+}\n+\n+\n+\n+/* vec_lvrxl (load vector right indexed last)\n+ * =========\n+ */\n+#define vec_lvrxl(_a, _b)\tvec_lvrx(_a, _b)\n+\n+\n+/* vec_promote (promote scalar to a vector)\n+ * ===========\n+ */\n+#define vec_promote(_a, _element)\tspu_promote(_a, _element)\n+\n+\n+/* vec_splats (splat scalar to a vector)\n+ * ==========\n+ */\n+#define vec_splats(_a)\tspu_splats(_a)\n+\n+\n+/* vec_stvlx (store vector left indexed)\n+ * =========\n+ */\n+static inline void vec_stvlx(vec_uchar16 a, int b, unsigned char *c)\n+{\n+  int shift;\n+  vec_uchar16 *p = (vec_uchar16 *)((unsigned char *)(c) + b);\n+\n+  shift = -((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_rlmaskqwbyte(a, shift),\n+\t       spu_rlmaskqwbyte(spu_splats((unsigned char)0xFF), shift));\n+}\n+\n+static inline void vec_stvlx(vec_uchar16 a, int b, vec_uchar16 *c)\n+{\n+  int shift;\n+  vec_uchar16 *p = (vec_uchar16 *)((unsigned char *)(c) + b);\n+\n+  shift = -((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_rlmaskqwbyte(a, shift),\n+\t       spu_rlmaskqwbyte(spu_splats((unsigned char)0xFF), shift));\n+}\n+\n+static inline void vec_stvlx(vec_char16 a, int b, signed char *c)\n+{\n+  int shift;\n+  vec_char16 *p = (vec_char16 *)((unsigned char *)(c) + b);\n+\n+  shift = -((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_rlmaskqwbyte(a, shift),\n+\t       spu_rlmaskqwbyte(spu_splats((unsigned char)0xFF), shift));\n+}\n+\n+static inline void vec_stvlx(vec_char16 a, int b, vec_char16 *c)\n+{\n+  int shift;\n+  vec_char16 *p = (vec_char16 *)((unsigned char *)(c) + b);\n+\n+  shift = -((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_rlmaskqwbyte(a, shift),\n+\t       spu_rlmaskqwbyte(spu_splats((unsigned char)0xFF), shift));\n+}\n+\n+static inline void vec_stvlx(vec_ushort8 a, int b, unsigned short *c)\n+{\n+  int shift;\n+  vec_ushort8 *p = (vec_ushort8 *)((unsigned char *)(c) + b);\n+\n+  shift = -((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_rlmaskqwbyte(a, shift),\n+\t       spu_rlmaskqwbyte(spu_splats((unsigned short)0xFFFF), shift));\n+}\n+\n+static inline void vec_stvlx(vec_ushort8 a, int b, vec_ushort8 *c)\n+{\n+  int shift;\n+  vec_ushort8 *p = (vec_ushort8 *)((unsigned char *)(c) + b);\n+\n+  shift = -((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_rlmaskqwbyte(a, shift),\n+\t       spu_rlmaskqwbyte(spu_splats((unsigned short)0xFFFF), shift));\n+}\n+\n+static inline void vec_stvlx(vec_short8 a, int b, signed short *c)\n+{\n+  int shift;\n+  vec_short8 *p = (vec_short8 *)((unsigned char *)(c) + b);\n+\n+  shift = -((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_rlmaskqwbyte(a, shift),\n+\t       spu_rlmaskqwbyte(spu_splats((unsigned short)0xFFFF), shift));\n+}\n+\n+static inline void vec_stvlx(vec_short8 a, int b, vec_short8 *c)\n+{\n+  int shift;\n+  vec_short8 *p = (vec_short8 *)((unsigned char *)(c) + b);\n+\n+  shift = -((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_rlmaskqwbyte(a, shift),\n+\t       spu_rlmaskqwbyte(spu_splats((unsigned short)0xFFFF), shift));\n+}\n+\n+static inline void vec_stvlx(vec_uint4 a, int b, unsigned int *c)\n+{\n+  int shift;\n+  vec_uint4 *p = (vec_uint4 *)((unsigned char *)(c) + b);\n+\n+  shift = -((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_rlmaskqwbyte(a, shift),\n+\t       spu_rlmaskqwbyte(spu_splats((unsigned int)0xFFFFFFFF), shift));\n+}\n+\n+static inline void vec_stvlx(vec_uint4 a, int b, vec_uint4 *c)\n+{\n+  int shift;\n+  vec_uint4 *p = (vec_uint4 *)((unsigned char *)(c) + b);\n+\n+  shift = -((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_rlmaskqwbyte(a, shift),\n+\t       spu_rlmaskqwbyte(spu_splats((unsigned int)0xFFFFFFFF), shift));\n+}\n+\n+static inline void vec_stvlx(vec_int4 a, int b, signed int *c)\n+{\n+  int shift;\n+  vec_int4 *p = (vec_int4 *)((unsigned char *)(c) + b);\n+\n+  shift = -((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_rlmaskqwbyte(a, shift),\n+\t       spu_rlmaskqwbyte(spu_splats((unsigned int)0xFFFFFFFF), shift));\n+}\n+\n+static inline void vec_stvlx(vec_int4 a, int b, vec_int4 *c)\n+{\n+  int shift;\n+  vec_int4 *p = (vec_int4 *)((unsigned char *)(c) + b);\n+\n+  shift = -((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_rlmaskqwbyte(a, shift),\n+\t       spu_rlmaskqwbyte(spu_splats((unsigned int)0xFFFFFFFF), shift));\n+}\n+\n+static inline void vec_stvlx(vec_float4 a, int b, float *c)\n+{\n+  int shift;\n+  vec_float4 *p = (vec_float4 *)((unsigned char *)(c) + b);\n+\n+  shift = -((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_rlmaskqwbyte(a, shift),\n+\t       spu_rlmaskqwbyte(spu_splats((unsigned int)0xFFFFFFFF), shift));\n+}\n+\n+static inline void vec_stvlx(vec_float4 a, int b, vec_float4 *c)\n+{\n+  int shift;\n+  vec_float4 *p = (vec_float4 *)((unsigned char *)(c) + b);\n+\n+  shift = -((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_rlmaskqwbyte(a, shift),\n+\t       spu_rlmaskqwbyte(spu_splats((unsigned int)0xFFFFFFFF), shift));\n+}\n+\n+/* vec_stvlxl (store vector left indexed last)\n+ * ==========\n+ */\n+#define vec_stvlxl(_a, _b, _c)\tvec_stvlx(_a, _b, _c)\n+\n+\n+/* vec_stvrx (store vector right indexed)\n+ * =========\n+ */\n+static inline void vec_stvrx(vec_uchar16 a, int b, unsigned char *c)\n+{\n+  int shift;\n+  vec_uchar16 *p = (vec_uchar16 *)((unsigned char *)(c) + b);\n+\n+  shift = 16-((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_slqwbyte(a, shift),\n+\t       spu_slqwbyte(spu_splats((unsigned char)0xFF), shift));\n+}\n+\n+static inline void vec_stvrx(vec_uchar16 a, int b, vec_uchar16 *c)\n+{\n+  int shift;\n+  vec_uchar16 *p = (vec_uchar16 *)((unsigned char *)(c) + b);\n+\n+  shift = 16-((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_slqwbyte(a, shift),\n+\t       spu_slqwbyte(spu_splats((unsigned char)0xFF), shift));\n+}\n+\n+static inline void vec_stvrx(vec_char16 a, int b, signed char *c)\n+{\n+  int shift;\n+  vec_char16 *p = (vec_char16 *)((unsigned char *)(c) + b);\n+\n+  shift = 16-((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_slqwbyte(a, shift),\n+\t       spu_slqwbyte(spu_splats((unsigned char)0xFF), shift));\n+}\n+\n+static inline void vec_stvrx(vec_char16 a, int b, vec_char16 *c)\n+{\n+  int shift;\n+  vec_char16 *p = (vec_char16 *)((unsigned char *)(c) + b);\n+\n+  shift = 16-((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_slqwbyte(a, shift),\n+\t       spu_slqwbyte(spu_splats((unsigned char)0xFF), shift));\n+}\n+\n+static inline void vec_stvrx(vec_ushort8 a, int b, unsigned short *c)\n+{\n+  int shift;\n+  vec_ushort8 *p = (vec_ushort8 *)((unsigned char *)(c) + b);\n+\n+  shift = 16-((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_slqwbyte(a, shift),\n+\t       spu_slqwbyte(spu_splats((unsigned short)0xFFFF), shift));\n+}\n+\n+static inline void vec_stvrx(vec_ushort8 a, int b, vec_ushort8 *c)\n+{\n+  int shift;\n+  vec_ushort8 *p = (vec_ushort8 *)((unsigned char *)(c) + b);\n+\n+  shift = 16-((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_slqwbyte(a, shift),\n+\t       spu_slqwbyte(spu_splats((unsigned short)0xFFFF), shift));\n+}\n+\n+static inline void vec_stvrx(vec_short8 a, int b, signed short *c)\n+{\n+  int shift;\n+  vec_short8 *p = (vec_short8 *)((unsigned char *)(c) + b);\n+\n+  shift = 16-((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_slqwbyte(a, shift),\n+\t       spu_slqwbyte(spu_splats((unsigned short)0xFFFF), shift));\n+}\n+\n+static inline void vec_stvrx(vec_short8 a, int b, vec_short8 *c)\n+{\n+  int shift;\n+  vec_short8 *p = (vec_short8 *)((unsigned char *)(c) + b);\n+\n+  shift = 16-((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_slqwbyte(a, shift),\n+\t       spu_slqwbyte(spu_splats((unsigned short)0xFFFF), shift));\n+}\n+\n+static inline void vec_stvrx(vec_uint4 a, int b, unsigned int *c)\n+{\n+  int shift;\n+  vec_uint4 *p = (vec_uint4 *)((unsigned char *)(c) + b);\n+\n+  shift = 16-((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_slqwbyte(a, shift),\n+\t       spu_slqwbyte(spu_splats((unsigned int)0xFFFFFFFF), shift));\n+}\n+\n+static inline void vec_stvrx(vec_uint4 a, int b, vec_uint4 *c)\n+{\n+  int shift;\n+  vec_uint4 *p = (vec_uint4 *)((unsigned char *)(c) + b);\n+\n+  shift = 16-((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_slqwbyte(a, shift),\n+\t       spu_slqwbyte(spu_splats((unsigned int)0xFFFFFFFF), shift));\n+}\n+\n+static inline void vec_stvrx(vec_int4 a, int b, signed int *c)\n+{\n+  int shift;\n+  vec_int4 *p = (vec_int4 *)((unsigned char *)(c) + b);\n+\n+  shift = 16-((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_slqwbyte(a, shift),\n+\t       spu_slqwbyte(spu_splats((unsigned int)0xFFFFFFFF), shift));\n+}\n+\n+static inline void vec_stvrx(vec_int4 a, int b, vec_int4 *c)\n+{\n+  int shift;\n+  vec_int4 *p = (vec_int4 *)((unsigned char *)(c) + b);\n+\n+  shift = 16-((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_slqwbyte(a, shift),\n+\t       spu_slqwbyte(spu_splats((unsigned int)0xFFFFFFFF), shift));\n+}\n+\n+static inline void vec_stvrx(vec_float4 a, int b, float *c)\n+{\n+  int shift;\n+  vec_float4 *p = (vec_float4 *)((unsigned char *)(c) + b);\n+\n+  shift = 16-((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_slqwbyte(a, shift),\n+\t       spu_slqwbyte(spu_splats((unsigned int)0xFFFFFFFF), shift));\n+}\n+\n+static inline void vec_stvrx(vec_float4 a, int b, vec_float4 *c)\n+{\n+  int shift;\n+  vec_float4 *p = (vec_float4 *)((unsigned char *)(c) + b);\n+\n+  shift = 16-((int)p & 0xF);\n+  *p = spu_sel(*p,\n+\t       spu_slqwbyte(a, shift),\n+\t       spu_slqwbyte(spu_splats((unsigned int)0xFFFFFFFF), shift));\n+}\n+\n+/* vec_stvrxl (store vector right indexed last)\n+ * ==========\n+ */\n+#define vec_stvrxl(_a, _b, _c)\tvec_stvrx(_a, _b, _c)\n+\n+\n #endif /* __SPU__ */\n #endif /* __cplusplus */\n #endif /* !_VMX2SPU_H_ */"}]}