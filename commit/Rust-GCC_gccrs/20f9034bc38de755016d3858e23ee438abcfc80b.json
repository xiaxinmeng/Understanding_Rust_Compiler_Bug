{"sha": "20f9034bc38de755016d3858e23ee438abcfc80b", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MjBmOTAzNGJjMzhkZTc1NTAxNmQzODU4ZTIzZWU0MzhhYmNmYzgwYg==", "commit": {"author": {"name": "Uros Bizjak", "email": "uros@gcc.gnu.org", "date": "2012-05-09T18:06:47Z"}, "committer": {"name": "Uros Bizjak", "email": "uros@gcc.gnu.org", "date": "2012-05-09T18:06:47Z"}, "message": "re PR target/44141 (Redundant loads and stores generated for AMD bdver1 target)\n\n\tPR target/44141\n\t* config/i386/i386.c (ix86_expand_vector_move_misalign): Do not handle\n\t128 bit vectors specially for TARGET_AVX.  Emit sse2_movupd and\n\tsse_movupd RTXes for TARGET_AVX, TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL\n\tor when optimizing for size.\n\t* config/i386/sse.md (*mov<mode>_internal): Remove\n\tTARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL handling from asm output code.\n\tCalculate \"mode\" attribute according to optimize_function_for_size_p\n\tand TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL flag.\n\t(*<sse>_movu<ssemodesuffix><avxsizesuffix>): Choose asm template\n\tdepending on the mode of the instruction.  Calculate \"mode\" attribute\n\taccording to optimize_function_for_size_p, TARGET_SSE_TYPELESS_STORES\n\tand TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL flags.\n\t(*<sse2>_movdqu<avxsizesuffix>): Ditto.\n\nFrom-SVN: r187347", "tree": {"sha": "2fad70c416fc89d99cae46f4c14179415943c6c4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/2fad70c416fc89d99cae46f4c14179415943c6c4"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/20f9034bc38de755016d3858e23ee438abcfc80b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/20f9034bc38de755016d3858e23ee438abcfc80b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/20f9034bc38de755016d3858e23ee438abcfc80b", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/20f9034bc38de755016d3858e23ee438abcfc80b/comments", "author": null, "committer": null, "parents": [{"sha": "eac188c5bcb1ed4f3fd61de2de2590dece32be2b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/eac188c5bcb1ed4f3fd61de2de2590dece32be2b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/eac188c5bcb1ed4f3fd61de2de2590dece32be2b"}], "stats": {"total": 213, "additions": 110, "deletions": 103}, "files": [{"sha": "0d17b2a2e03e11b180e550d8e6cf26ec2f931ea8", "filename": "gcc/ChangeLog", "status": "modified", "additions": 21, "deletions": 5, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/20f9034bc38de755016d3858e23ee438abcfc80b/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/20f9034bc38de755016d3858e23ee438abcfc80b/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=20f9034bc38de755016d3858e23ee438abcfc80b", "patch": "@@ -1,3 +1,20 @@\n+2012-05-09  Uros Bizjak  <ubizjak@gmail.com>\n+\n+\tPR target/44141\n+\t* config/i386/i386.c (ix86_expand_vector_move_misalign): Do not handle\n+\t128 bit vectors specially for TARGET_AVX.  Emit sse2_movupd and\n+\tsse_movupd RTXes for TARGET_AVX, TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL\n+\tor when optimizing for size.\n+\t* config/i386/sse.md (*mov<mode>_internal): Remove\n+\tTARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL handling from asm output code.\n+\tCalculate \"mode\" attribute according to optimize_function_for_size_p\n+\tand TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL flag.\n+\t(*<sse>_movu<ssemodesuffix><avxsizesuffix>): Choose asm template\n+\tdepending on the mode of the instruction.  Calculate \"mode\" attribute\n+\taccording to optimize_function_for_size_p, TARGET_SSE_TYPELESS_STORES\n+\tand TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL flags.\n+\t(*<sse2>_movdqu<avxsizesuffix>): Ditto.\n+\n 2012-05-09  Georg-Johann Lay  <avr@gjlay.de>\n \n \tPR target/53256\n@@ -161,7 +178,7 @@\n \tPR target/51244\n \t* config/sh/sh.md (*branch_true, *branch_false): New insns.\n \n-2012-05-08   Teresa Johnson  <tejohnson@google.com>\n+2012-05-08  Teresa Johnson  <tejohnson@google.com>\n \n \t* gcov-io.h (__gcov_reset, __gcov_dump): Declare.\n \t* doc/gcov.texi: Add note on using __gcov_reset and __gcov_dump.\n@@ -180,8 +197,7 @@\n \t(clone_function_name): Likewise.\n \t(cgraph_create_virtual_clone): Likewise.\n \t(cgraph_remove_node_and_inline_clones): Likewise.\n-\t(cgraph_redirect_edge_call_stmt_to_callee): Move here from\n-\tcgraphunit.c\n+\t(cgraph_redirect_edge_call_stmt_to_callee): Move here from cgraphunit.c\n \t* cgraph.h: Reorder declarations so they match file of origin.\n \t(cgraph_create_empty_node): Declare.\n \t* cgraphunit.c (update_call_expr): Move to cgraphclones.c\n@@ -702,7 +718,7 @@\n \n \tEnable -Wunused-local-typedefs when -Wall or -Wunused is on\n \t* opts.c (finish_options): Activate -Wunused-local-typedefs if\n-    \t-Wunused is activated.\n+\t-Wunused is activated.\n \t* doc/invoke.texi: Update blurb of -Wunused-local-typedefs.\n \n 2012-05-04  Andreas Krebbel  <Andreas.Krebbel@de.ibm.com>\n@@ -1757,7 +1773,7 @@\n \t* config/pa/pa.c (pa_legitimate_constant_p): Don't put function labels\n \tin constant pool.\n \n-2012-04-27   Ollie Wild  <aaw@google.com>\n+2012-04-27  Ollie Wild  <aaw@google.com>\n \n \t* doc/invoke.texi (Wliteral-suffix): Document new option.\n "}, {"sha": "36370b2f6d1c94c7754f17536ae7f53f5a5b059a", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 31, "deletions": 82, "changes": 113, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/20f9034bc38de755016d3858e23ee438abcfc80b/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/20f9034bc38de755016d3858e23ee438abcfc80b/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=20f9034bc38de755016d3858e23ee438abcfc80b", "patch": "@@ -15907,60 +15907,19 @@ ix86_expand_vector_move_misalign (enum machine_mode mode, rtx operands[])\n   op0 = operands[0];\n   op1 = operands[1];\n \n-  if (TARGET_AVX)\n+  if (TARGET_AVX\n+      && GET_MODE_SIZE (mode) == 32)\n     {\n       switch (GET_MODE_CLASS (mode))\n \t{\n \tcase MODE_VECTOR_INT:\n \tcase MODE_INT:\n-\t  switch (GET_MODE_SIZE (mode))\n-\t    {\n-\t    case 16:\n-\t      if (TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL)\n-\t\t{\n-\t\t  op0 = gen_lowpart (V4SFmode, op0);\n-\t\t  op1 = gen_lowpart (V4SFmode, op1);\n-\t\t  emit_insn (gen_sse_movups (op0, op1));\n-\t\t}\n-\t      else\n-\t\t{\n-\t\t  op0 = gen_lowpart (V16QImode, op0);\n-\t\t  op1 = gen_lowpart (V16QImode, op1);\n-\t\t  emit_insn (gen_sse2_movdqu (op0, op1));\n-\t\t}\n-\t      break;\n-\t    case 32:\n-\t      op0 = gen_lowpart (V32QImode, op0);\n-\t      op1 = gen_lowpart (V32QImode, op1);\n-\t      ix86_avx256_split_vector_move_misalign (op0, op1);\n-\t      break;\n-\t    default:\n-\t      gcc_unreachable ();\n-\t    }\n-\t  break;\n+\t  op0 = gen_lowpart (V32QImode, op0);\n+\t  op1 = gen_lowpart (V32QImode, op1);\n+\t  /* FALLTHRU */\n+\n \tcase MODE_VECTOR_FLOAT:\n-\t  switch (mode)\n-\t    {\n-\t    case V4SFmode:\n-\t      emit_insn (gen_sse_movups (op0, op1));\n-\t      break;\n-\t    case V2DFmode:\n-\t      if (TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL)\n-\t\t{\n-\t\t  op0 = gen_lowpart (V4SFmode, op0);\n-\t\t  op1 = gen_lowpart (V4SFmode, op1);\n-\t\t  emit_insn (gen_sse_movups (op0, op1));\n-\t\t}\n-\t      else\n-\t\temit_insn (gen_sse2_movupd (op0, op1));\n-\t      break;\n-\t    case V8SFmode:\n-\t    case V4DFmode:\n-\t      ix86_avx256_split_vector_move_misalign (op0, op1);\n-\t      break;\n-\t    default:\n-\t      gcc_unreachable ();\n-\t    }\n+\t  ix86_avx256_split_vector_move_misalign (op0, op1);\n \t  break;\n \n \tdefault:\n@@ -15972,33 +15931,26 @@ ix86_expand_vector_move_misalign (enum machine_mode mode, rtx operands[])\n \n   if (MEM_P (op1))\n     {\n-      /* If we're optimizing for size, movups is the smallest.  */\n-      if (optimize_insn_for_size_p ()\n-\t  || TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL)\n-\t{\n-\t  op0 = gen_lowpart (V4SFmode, op0);\n-\t  op1 = gen_lowpart (V4SFmode, op1);\n-\t  emit_insn (gen_sse_movups (op0, op1));\n-\t  return;\n-\t}\n-\n       /* ??? If we have typed data, then it would appear that using\n \t movdqu is the only way to get unaligned data loaded with\n \t integer type.  */\n       if (TARGET_SSE2 && GET_MODE_CLASS (mode) == MODE_VECTOR_INT)\n \t{\n \t  op0 = gen_lowpart (V16QImode, op0);\n \t  op1 = gen_lowpart (V16QImode, op1);\n+\t  /* We will eventually emit movups based on insn attributes.  */\n \t  emit_insn (gen_sse2_movdqu (op0, op1));\n-\t  return;\n \t}\n-\n-      if (TARGET_SSE2 && mode == V2DFmode)\n+      else if (TARGET_SSE2 && mode == V2DFmode)\n         {\n           rtx zero;\n \n-\t  if (TARGET_SSE_UNALIGNED_LOAD_OPTIMAL)\n+\t  if (TARGET_AVX\n+\t      || TARGET_SSE_UNALIGNED_LOAD_OPTIMAL\n+\t      || TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL\n+\t      || optimize_function_for_size_p (cfun))\n \t    {\n+\t      /* We will eventually emit movups based on insn attributes.  */\n \t      emit_insn (gen_sse2_movupd (op0, op1));\n \t      return;\n \t    }\n@@ -16030,7 +15982,10 @@ ix86_expand_vector_move_misalign (enum machine_mode mode, rtx operands[])\n \t}\n       else\n         {\n-\t  if (TARGET_SSE_UNALIGNED_LOAD_OPTIMAL)\n+\t  if (TARGET_AVX\n+\t      || TARGET_SSE_UNALIGNED_LOAD_OPTIMAL\n+\t      || TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL\n+\t      || optimize_function_for_size_p (cfun))\n \t    {\n \t      op0 = gen_lowpart (V4SFmode, op0);\n \t      op1 = gen_lowpart (V4SFmode, op1);\n@@ -16045,6 +16000,7 @@ ix86_expand_vector_move_misalign (enum machine_mode mode, rtx operands[])\n \n \t  if (mode != V4SFmode)\n \t    op0 = gen_lowpart (V4SFmode, op0);\n+\n \t  m = adjust_address (op1, V2SFmode, 0);\n \t  emit_insn (gen_sse_loadlps (op0, op0, m));\n \t  m = adjust_address (op1, V2SFmode, 8);\n@@ -16053,30 +16009,20 @@ ix86_expand_vector_move_misalign (enum machine_mode mode, rtx operands[])\n     }\n   else if (MEM_P (op0))\n     {\n-      /* If we're optimizing for size, movups is the smallest.  */\n-      if (optimize_insn_for_size_p ()\n-\t  || TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL)\n-\t{\n-\t  op0 = gen_lowpart (V4SFmode, op0);\n-\t  op1 = gen_lowpart (V4SFmode, op1);\n-\t  emit_insn (gen_sse_movups (op0, op1));\n-\t  return;\n-\t}\n-\n-      /* ??? Similar to above, only less clear\n-\t because of typeless stores.  */\n-      if (TARGET_SSE2 && !TARGET_SSE_TYPELESS_STORES\n-\t  && GET_MODE_CLASS (mode) == MODE_VECTOR_INT)\n+      if (TARGET_SSE2 && GET_MODE_CLASS (mode) == MODE_VECTOR_INT)\n         {\n \t  op0 = gen_lowpart (V16QImode, op0);\n \t  op1 = gen_lowpart (V16QImode, op1);\n+\t  /* We will eventually emit movups based on insn attributes.  */\n \t  emit_insn (gen_sse2_movdqu (op0, op1));\n-\t  return;\n \t}\n-\n-      if (TARGET_SSE2 && mode == V2DFmode)\n+      else if (TARGET_SSE2 && mode == V2DFmode)\n \t{\n-\t  if (TARGET_SSE_UNALIGNED_STORE_OPTIMAL)\n+\t  if (TARGET_AVX\n+\t      || TARGET_SSE_UNALIGNED_STORE_OPTIMAL\n+\t      || TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL\n+\t      || optimize_function_for_size_p (cfun))\n+\t    /* We will eventually emit movups based on insn attributes.  */\n \t    emit_insn (gen_sse2_movupd (op0, op1));\n \t  else\n \t    {\n@@ -16091,7 +16037,10 @@ ix86_expand_vector_move_misalign (enum machine_mode mode, rtx operands[])\n \t  if (mode != V4SFmode)\n \t    op1 = gen_lowpart (V4SFmode, op1);\n \n-\t  if (TARGET_SSE_UNALIGNED_STORE_OPTIMAL)\n+\t  if (TARGET_AVX\n+\t      || TARGET_SSE_UNALIGNED_STORE_OPTIMAL\n+\t      || TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL\n+\t      || optimize_function_for_size_p (cfun))\n \t    {\n \t      op0 = gen_lowpart (V4SFmode, op0);\n \t      emit_insn (gen_sse_movups (op0, op1));"}, {"sha": "86b2ed39f0aa27c94abddde42cbfe41dac52ea71", "filename": "gcc/config/i386/sse.md", "status": "modified", "additions": 58, "deletions": 16, "changes": 74, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/20f9034bc38de755016d3858e23ee438abcfc80b/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/20f9034bc38de755016d3858e23ee438abcfc80b/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=20f9034bc38de755016d3858e23ee438abcfc80b", "patch": "@@ -449,8 +449,6 @@\n \t      && (misaligned_operand (operands[0], <MODE>mode)\n \t\t  || misaligned_operand (operands[1], <MODE>mode)))\n \t    return \"vmovupd\\t{%1, %0|%0, %1}\";\n-\t  else if (TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL)\n-\t    return \"%vmovaps\\t{%1, %0|%0, %1}\";\n \t  else\n \t    return \"%vmovapd\\t{%1, %0|%0, %1}\";\n \n@@ -460,8 +458,6 @@\n \t      && (misaligned_operand (operands[0], <MODE>mode)\n \t\t  || misaligned_operand (operands[1], <MODE>mode)))\n \t    return \"vmovdqu\\t{%1, %0|%0, %1}\";\n-\t  else if (TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL)\n-\t    return \"%vmovaps\\t{%1, %0|%0, %1}\";\n \t  else\n \t    return \"%vmovdqa\\t{%1, %0|%0, %1}\";\n \n@@ -475,19 +471,21 @@\n   [(set_attr \"type\" \"sselog1,ssemov,ssemov\")\n    (set_attr \"prefix\" \"maybe_vex\")\n    (set (attr \"mode\")\n-\t(cond [(match_test \"TARGET_AVX\")\n+\t(cond [(and (eq_attr \"alternative\" \"1,2\")\n+\t      \t    (match_test \"TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL\"))\n+\t\t (if_then_else\n+\t\t    (match_test \"GET_MODE_SIZE (<MODE>mode) > 16\")\n+\t\t    (const_string \"V8SF\")\n+\t\t    (const_string \"V4SF\"))\n+\t       (match_test \"TARGET_AVX\")\n \t\t (const_string \"<sseinsnmode>\")\n-\t       (ior (ior (match_test \"optimize_function_for_size_p (cfun)\")\n-\t\t\t (not (match_test \"TARGET_SSE2\")))\n+\t       (ior (and (eq_attr \"alternative\" \"1,2\")\n+\t\t\t (match_test \"optimize_function_for_size_p (cfun)\"))\n \t\t    (and (eq_attr \"alternative\" \"2\")\n \t\t\t (match_test \"TARGET_SSE_TYPELESS_STORES\")))\n \t\t (const_string \"V4SF\")\n-\t       (eq (const_string \"<MODE>mode\") (const_string \"V4SFmode\"))\n-\t\t (const_string \"V4SF\")\n-\t       (eq (const_string \"<MODE>mode\") (const_string \"V2DFmode\"))\n-\t\t (const_string \"V2DF\")\n \t      ]\n-\t  (const_string \"TI\")))])\n+\t  (const_string \"<sseinsnmode>\")))])\n \n (define_insn \"sse2_movq128\"\n   [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n@@ -597,11 +595,33 @@\n \t  [(match_operand:VF 1 \"nonimmediate_operand\" \"xm,x\")]\n \t  UNSPEC_MOVU))]\n   \"TARGET_SSE && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n-  \"%vmovu<ssemodesuffix>\\t{%1, %0|%0, %1}\"\n+{\n+  switch (get_attr_mode (insn))\n+    {\n+    case MODE_V8SF:\n+    case MODE_V4SF:\n+      return \"%vmovups\\t{%1, %0|%0, %1}\";\n+    default:\n+      return \"%vmovu<ssemodesuffix>\\t{%1, %0|%0, %1}\";\n+    }\n+}\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"movu\" \"1\")\n    (set_attr \"prefix\" \"maybe_vex\")\n-   (set_attr \"mode\" \"<MODE>\")])\n+   (set (attr \"mode\")\n+\t(cond [(match_test \"TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL\")\n+\t\t (if_then_else\n+\t\t    (match_test \"GET_MODE_SIZE (<MODE>mode) > 16\")\n+\t\t    (const_string \"V8SF\")\n+\t\t    (const_string \"V4SF\"))\n+\t       (match_test \"TARGET_AVX\")\n+\t\t (const_string \"<MODE>\")\n+\t       (ior (match_test \"optimize_function_for_size_p (cfun)\")\n+\t\t    (and (eq_attr \"alternative\" \"1\")\n+\t\t\t (match_test \"TARGET_SSE_TYPELESS_STORES\")))\n+\t         (const_string \"V4SF\")\n+\t      ]\n+\t(const_string \"<MODE>\")))])\n \n (define_expand \"<sse2>_movdqu<avxsizesuffix>\"\n   [(set (match_operand:VI1 0 \"nonimmediate_operand\")\n@@ -618,7 +638,16 @@\n \t(unspec:VI1 [(match_operand:VI1 1 \"nonimmediate_operand\" \"xm,x\")]\n \t\t    UNSPEC_MOVU))]\n   \"TARGET_SSE2 && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n-  \"%vmovdqu\\t{%1, %0|%0, %1}\"\n+{\n+  switch (get_attr_mode (insn))\n+    {\n+    case MODE_V8SF:\n+    case MODE_V4SF:\n+      return \"%vmovups\\t{%1, %0|%0, %1}\";\n+    default:\n+      return \"%vmovdqu\\t{%1, %0|%0, %1}\";\n+    }\n+}\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"movu\" \"1\")\n    (set (attr \"prefix_data16\")\n@@ -627,7 +656,20 @@\n      (const_string \"*\")\n      (const_string \"1\")))\n    (set_attr \"prefix\" \"maybe_vex\")\n-   (set_attr \"mode\" \"<sseinsnmode>\")])\n+   (set (attr \"mode\")\n+\t(cond [(match_test \"TARGET_SSE_PACKED_SINGLE_INSN_OPTIMAL\")\n+\t\t (if_then_else\n+\t\t    (match_test \"GET_MODE_SIZE (<MODE>mode) > 16\")\n+\t\t    (const_string \"V8SF\")\n+\t\t    (const_string \"V4SF\"))\n+\t       (match_test \"TARGET_AVX\")\n+\t\t (const_string \"<sseinsnmode>\")\n+\t       (ior (match_test \"optimize_function_for_size_p (cfun)\")\n+\t\t    (and (eq_attr \"alternative\" \"1\")\n+\t\t\t (match_test \"TARGET_SSE_TYPELESS_STORES\")))\n+\t         (const_string \"V4SF\")\n+\t      ]\n+\t(const_string \"<sseinsnmode>\")))])\n \n (define_insn \"<sse3>_lddqu<avxsizesuffix>\"\n   [(set (match_operand:VI1 0 \"register_operand\" \"=x\")"}]}