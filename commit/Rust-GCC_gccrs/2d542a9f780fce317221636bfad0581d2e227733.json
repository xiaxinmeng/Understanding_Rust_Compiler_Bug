{"sha": "2d542a9f780fce317221636bfad0581d2e227733", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MmQ1NDJhOWY3ODBmY2UzMTcyMjE2MzZiZmFkMDU4MWQyZTIyNzczMw==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@redhat.com", "date": "2012-06-23T16:42:19Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2012-06-23T16:42:19Z"}, "message": "re PR target/53749 (ice in expand_shift_1)\n\nPR target/53749\n        * config/i386/i386.c (ix86_rtx_costs): Add reasonable costs for\n        V*QImode shifts and multiply.\n        (ix86_expand_vecop_qihi): Support shifts.\n        * config/i386/i386.md (any_shift): New code iterator.\n        * config/i386/sse.md (ashlv16qi3): Merge ...\n        (<any_shiftrt>v16qi3): ... into ...\n        (<any_shift><VI1_AVX2>3): ... here.  Use ix86_expand_vecop_qihi\n        to support SSE and AVX.\n\nFrom-SVN: r188909", "tree": {"sha": "6e30fb45a07f23eaba80b3c9ca95f5e5f6048ada", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/6e30fb45a07f23eaba80b3c9ca95f5e5f6048ada"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/2d542a9f780fce317221636bfad0581d2e227733", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2d542a9f780fce317221636bfad0581d2e227733", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2d542a9f780fce317221636bfad0581d2e227733", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2d542a9f780fce317221636bfad0581d2e227733/comments", "author": null, "committer": null, "parents": [{"sha": "7b5321188b4011e2ce3b6d56cf26d6dde054419d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7b5321188b4011e2ce3b6d56cf26d6dde054419d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/7b5321188b4011e2ce3b6d56cf26d6dde054419d"}], "stats": {"total": 198, "additions": 123, "deletions": 75}, "files": [{"sha": "5c65a396259054ee09ab1c0f8a2745024724fca6", "filename": "gcc/ChangeLog", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2d542a9f780fce317221636bfad0581d2e227733/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2d542a9f780fce317221636bfad0581d2e227733/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=2d542a9f780fce317221636bfad0581d2e227733", "patch": "@@ -1,5 +1,15 @@\n 2012-06-23  Richard Henderson  <rth@redhat.com>\n \n+\tPR target/53749\n+\t* config/i386/i386.c (ix86_rtx_costs): Add reasonable costs for\n+\tV*QImode shifts and multiply.\n+\t(ix86_expand_vecop_qihi): Support shifts.\n+\t* config/i386/i386.md (any_shift): New code iterator.\n+\t* config/i386/sse.md (ashlv16qi3): Merge ...\n+\t(<any_shiftrt>v16qi3): ... into ...\n+\t(<any_shift><VI1_AVX2>3): ... here.  Use ix86_expand_vecop_qihi\n+\tto support SSE and AVX.\n+\n \t* config/i386/i386.c (ix86_expand_sse_unpack): Split operands[]\n \tparameter into src and dest.\n \t* config/i386/sse.md (vec_unpacku_hi_<V124_AVX2>): Update call."}, {"sha": "fc30632717e04d81f334479e4b7439f3e7ae4214", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 81, "deletions": 28, "changes": 109, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2d542a9f780fce317221636bfad0581d2e227733/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2d542a9f780fce317221636bfad0581d2e227733/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=2d542a9f780fce317221636bfad0581d2e227733", "patch": "@@ -31938,9 +31938,10 @@ ix86_set_reg_reg_cost (enum machine_mode mode)\n    scanned.  In either case, *TOTAL contains the cost result.  */\n \n static bool\n-ix86_rtx_costs (rtx x, int code, int outer_code_i, int opno, int *total,\n+ix86_rtx_costs (rtx x, int code_i, int outer_code_i, int opno, int *total,\n \t\tbool speed)\n {\n+  enum rtx_code code = (enum rtx_code) code_i;\n   enum rtx_code outer_code = (enum rtx_code) outer_code_i;\n   enum machine_mode mode = GET_MODE (x);\n   const struct processor_costs *cost = speed ? ix86_cost : &ix86_size_cost;\n@@ -32045,7 +32046,31 @@ ix86_rtx_costs (rtx x, int code, int outer_code_i, int opno, int *total,\n \t  /* ??? Should be SSE vector operation cost.  */\n \t  /* At least for published AMD latencies, this really is the same\n \t     as the latency for a simple fpu operation like fabs.  */\n-\t  *total = cost->fabs;\n+\t  /* V*QImode is emulated with 1-11 insns.  */\n+\t  if (mode == V16QImode || mode == V32QImode)\n+\t    {\n+\t      int count;\n+\t      if (TARGET_XOP && mode == V16QImode)\n+\t\t{\n+\t\t  /* For XOP we use vpshab, which requires a broadcast of the\n+\t\t     value to the variable shift insn.  For constants this\n+\t\t     means a V16Q const in mem; even when we can perform the\n+\t\t     shift with one insn set the cost to prefer paddb.  */\n+\t\t  if (CONSTANT_P (XEXP (x, 1)))\n+\t\t    {\n+\t\t      *total = (cost->fabs\n+\t\t\t\t+ rtx_cost (XEXP (x, 0), code, 0, speed)\n+\t\t\t\t+ (speed ? 2 : COSTS_N_BYTES (16)));\n+\t\t      return true;\n+\t\t    }\n+\t\t  count = 3;\n+\t\t}\n+\t      else\n+\t\tcount = TARGET_SSSE3 ? 7 : 11;\n+\t      *total = cost->fabs * count;\n+\t    }\n+\t  else\n+\t    *total = cost->fabs;\n \t  return false;\n \t}\n       if (GET_MODE_SIZE (mode) < UNITS_PER_WORD)\n@@ -32119,9 +32144,15 @@ ix86_rtx_costs (rtx x, int code, int outer_code_i, int opno, int *total,\n \t}\n       else if (GET_MODE_CLASS (mode) == MODE_VECTOR_INT)\n \t{\n+\t  /* V*QImode is emulated with 7-13 insns.  */\n+\t  if (mode == V16QImode || mode == V32QImode)\n+\t    {\n+\t      int extra = TARGET_XOP ? 5 : TARGET_SSSE3 ? 6 : 11;\n+\t      *total = cost->fmul * 2 + cost->fabs * extra;\n+\t    }\n \t  /* Without sse4.1, we don't have PMULLD; it's emulated with 7\n \t     insns, including two PMULUDQ.  */\n-\t  if (mode == V4SImode && !(TARGET_SSE4_1 || TARGET_AVX))\n+\t  else if (mode == V4SImode && !(TARGET_SSE4_1 || TARGET_AVX))\n \t    *total = cost->fmul * 2 + cost->fabs * 5;\n \t  else\n \t    *total = cost->fmul;\n@@ -38448,44 +38479,66 @@ ix86_expand_vecop_qihi (enum rtx_code code, rtx dest, rtx op1, rtx op2)\n   rtx (*gen_ih) (rtx, rtx, rtx);\n   rtx op1_l, op1_h, op2_l, op2_h, res_l, res_h;\n   struct expand_vec_perm_d d;\n-  bool ok;\n+  bool ok, full_interleave;\n+  bool uns_p = false;\n   int i;\n \n-  if (qimode == V16QImode)\n+  switch (qimode)\n     {\n+    case V16QImode:\n       himode = V8HImode;\n       gen_il = gen_vec_interleave_lowv16qi;\n       gen_ih = gen_vec_interleave_highv16qi;\n-    }\n-  else if (qimode == V32QImode)\n-    {\n+      break;\n+    case V32QImode:\n       himode = V16HImode;\n       gen_il = gen_avx2_interleave_lowv32qi;\n       gen_ih = gen_avx2_interleave_highv32qi;\n+      break;\n+    default:\n+      gcc_unreachable ();\n     }\n-  else\n-    gcc_unreachable ();\n \n-  /* Unpack data such that we've got a source byte in each low byte of\n-     each word.  We don't care what goes into the high byte of each word.\n-     Rather than trying to get zero in there, most convenient is to let\n-     it be a copy of the low byte.  */\n-  op1_l = gen_reg_rtx (qimode);\n-  op1_h = gen_reg_rtx (qimode);\n-  emit_insn (gen_il (op1_l, op1, op1));\n-  emit_insn (gen_ih (op1_h, op1, op1));\n+  op2_l = op2_h = op2;\n+  switch (code)\n+    {\n+    case MULT:\n+      /* Unpack data such that we've got a source byte in each low byte of\n+\t each word.  We don't care what goes into the high byte of each word.\n+\t Rather than trying to get zero in there, most convenient is to let\n+\t it be a copy of the low byte.  */\n+      op2_l = gen_reg_rtx (qimode);\n+      op2_h = gen_reg_rtx (qimode);\n+      emit_insn (gen_il (op2_l, op2, op2));\n+      emit_insn (gen_ih (op2_h, op2, op2));\n+      /* FALLTHRU */\n \n-  op2_l = gen_reg_rtx (qimode);\n-  op2_h = gen_reg_rtx (qimode);\n-  emit_insn (gen_il (op2_l, op2, op2));\n-  emit_insn (gen_ih (op2_h, op2, op2));\n+      op1_l = gen_reg_rtx (qimode);\n+      op1_h = gen_reg_rtx (qimode);\n+      emit_insn (gen_il (op1_l, op1, op1));\n+      emit_insn (gen_ih (op1_h, op1, op1));\n+      full_interleave = qimode == V16QImode;\n+      break;\n+\n+    case ASHIFT:\n+    case LSHIFTRT:\n+      uns_p = true;\n+      /* FALLTHRU */\n+    case ASHIFTRT:\n+      op1_l = gen_reg_rtx (himode);\n+      op1_h = gen_reg_rtx (himode);\n+      ix86_expand_sse_unpack (op1_l, op1, uns_p, false);\n+      ix86_expand_sse_unpack (op1_h, op1, uns_p, true);\n+      full_interleave = true;\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n \n   /* Perform the operation.  */\n-  res_l = expand_simple_binop (himode, code, gen_lowpart (himode, op1_l),\n-\t\t\t       gen_lowpart (himode, op2_l), NULL_RTX,\n+  res_l = expand_simple_binop (himode, code, op1_l, op2_l, NULL_RTX,\n \t\t\t       1, OPTAB_DIRECT);\n-  res_h = expand_simple_binop (himode, code, gen_lowpart (himode, op1_h),\n-\t\t\t       gen_lowpart (himode, op2_h), NULL_RTX,\n+  res_h = expand_simple_binop (himode, code, op1_h, op2_h, NULL_RTX,\n \t\t\t       1, OPTAB_DIRECT);\n   gcc_assert (res_l && res_h);\n \n@@ -38498,11 +38551,11 @@ ix86_expand_vecop_qihi (enum rtx_code code, rtx dest, rtx op1, rtx op2)\n   d.one_operand_p = false;\n   d.testing_p = false;\n \n-  if (qimode == V16QImode)\n+  if (full_interleave)\n     {\n       /* For SSE2, we used an full interleave, so the desired\n \t results are in the even elements.  */\n-      for (i = 0; i < 16; ++i)\n+      for (i = 0; i < 32; ++i)\n \td.perm[i] = i * 2;\n     }\n   else"}, {"sha": "da2f4b273483540c93b60d2beb1156cf5a732518", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2d542a9f780fce317221636bfad0581d2e227733/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2d542a9f780fce317221636bfad0581d2e227733/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=2d542a9f780fce317221636bfad0581d2e227733", "patch": "@@ -711,6 +711,9 @@\n ;; Mapping of shift-right operators\n (define_code_iterator any_shiftrt [lshiftrt ashiftrt])\n \n+;; Mapping of all shift operators\n+(define_code_iterator any_shift [ashift lshiftrt ashiftrt])\n+\n ;; Base name for define_insn\n (define_code_attr shift_insn\n   [(ashift \"ashl\") (lshiftrt \"lshr\") (ashiftrt \"ashr\")])"}, {"sha": "691256d5e21b5ed4a145f159947fb63eeea66df1", "filename": "gcc/config/i386/sse.md", "status": "modified", "additions": 29, "deletions": 47, "changes": 76, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2d542a9f780fce317221636bfad0581d2e227733/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2d542a9f780fce317221636bfad0581d2e227733/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=2d542a9f780fce317221636bfad0581d2e227733", "patch": "@@ -10550,60 +10550,42 @@\n    (set_attr \"prefix_extra\" \"2\")\n    (set_attr \"mode\" \"TI\")])\n \n-;; SSE2 doesn't have some shift variants, so define versions for XOP\n-(define_expand \"ashlv16qi3\"\n-  [(set (match_operand:V16QI 0 \"register_operand\")\n-\t(ashift:V16QI\n-\t  (match_operand:V16QI 1 \"register_operand\")\n-\t  (match_operand:SI 2 \"nonmemory_operand\")))]\n-  \"TARGET_XOP\"\n-{\n-  rtx reg = gen_reg_rtx (V16QImode);\n-  rtx par;\n-  int i;\n-\n-  par = gen_rtx_PARALLEL (V16QImode, rtvec_alloc (16));\n-  for (i = 0; i < 16; i++)\n-    XVECEXP (par, 0, i) = operands[2];\n-\n-  emit_insn (gen_vec_initv16qi (reg, par));\n-  emit_insn (gen_xop_shav16qi3 (operands[0], operands[1], reg));\n-  DONE;\n-})\n-\n-(define_expand \"<shift_insn>v16qi3\"\n-  [(set (match_operand:V16QI 0 \"register_operand\")\n-\t(any_shiftrt:V16QI\n-\t  (match_operand:V16QI 1 \"register_operand\")\n+(define_expand \"<shift_insn><mode>3\"\n+  [(set (match_operand:VI1_AVX2 0 \"register_operand\")\n+\t(any_shift:VI1_AVX2\n+\t  (match_operand:VI1_AVX2 1 \"register_operand\")\n \t  (match_operand:SI 2 \"nonmemory_operand\")))]\n-  \"TARGET_XOP\"\n+  \"TARGET_SSE2\"\n {\n-  rtx reg = gen_reg_rtx (V16QImode);\n-  rtx par;\n-  bool negate = false;\n-  rtx (*shift_insn)(rtx, rtx, rtx);\n-  int i;\n-\n-  if (CONST_INT_P (operands[2]))\n-    operands[2] = GEN_INT (-INTVAL (operands[2]));\n-  else\n-    negate = true;\n+  if (TARGET_XOP && <MODE>mode == V16QImode)\n+    {\n+      bool negate = false;\n+      rtx (*gen) (rtx, rtx, rtx);\n+      rtx tmp, par;\n+      int i;\n \n-  par = gen_rtx_PARALLEL (V16QImode, rtvec_alloc (16));\n-  for (i = 0; i < 16; i++)\n-    XVECEXP (par, 0, i) = operands[2];\n+      if (<CODE> != ASHIFT)\n+\t{\n+\t  if (CONST_INT_P (operands[2]))\n+\t    operands[2] = GEN_INT (-INTVAL (operands[2]));\n+\t  else\n+\t    negate = true;\n+\t}\n+      par = gen_rtx_PARALLEL (V16QImode, rtvec_alloc (16));\n+      for (i = 0; i < 16; i++)\n+        XVECEXP (par, 0, i) = operands[2];\n \n-  emit_insn (gen_vec_initv16qi (reg, par));\n+      tmp = gen_reg_rtx (V16QImode);\n+      emit_insn (gen_vec_initv16qi (tmp, par));\n \n-  if (negate)\n-    emit_insn (gen_negv16qi2 (reg, reg));\n+      if (negate)\n+\temit_insn (gen_negv16qi2 (tmp, tmp));\n \n-  if (<CODE> == LSHIFTRT)\n-    shift_insn = gen_xop_shlv16qi3;\n+      gen = (<CODE> == LSHIFTRT ? gen_xop_shlv16qi3 : gen_xop_shav16qi3);\n+      emit_insn (gen (operands[0], operands[1], tmp));\n+    }\n   else\n-    shift_insn = gen_xop_shav16qi3;\n-\n-  emit_insn (shift_insn (operands[0], operands[1], reg));\n+    ix86_expand_vecop_qihi (<CODE>, operands[0], operands[1], operands[2]);\n   DONE;\n })\n "}]}