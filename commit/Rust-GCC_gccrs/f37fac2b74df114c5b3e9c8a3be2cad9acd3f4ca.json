{"sha": "f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZjM3ZmFjMmI3NGRmMTE0YzViM2U5YzhhM2JlMmNhZDlhY2QzZjRjYQ==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@linaro.org", "date": "2017-12-21T06:57:41Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2017-12-21T06:57:41Z"}, "message": "poly_int: get_inner_reference & co.\n\nThis patch makes get_inner_reference and ptr_difference_const return the\nbit size and bit position as poly_int64s rather than HOST_WIDE_INTS.\nThe non-mechanical changes were handled by previous patches.\n\n2017-12-21  Richard Sandiford  <richard.sandiford@linaro.org>\n\t    Alan Hayward  <alan.hayward@arm.com>\n\t    David Sherwood  <david.sherwood@arm.com>\n\ngcc/\n\t* tree.h (get_inner_reference): Return the bitsize and bitpos\n\tas poly_int64_pods rather than HOST_WIDE_INT.\n\t* fold-const.h (ptr_difference_const): Return the pointer difference\n\tas a poly_int64_pod rather than a HOST_WIDE_INT.\n\t* expr.c (get_inner_reference): Return the bitsize and bitpos\n\tas poly_int64_pods rather than HOST_WIDE_INT.\n\t(expand_expr_addr_expr_1, expand_expr_real_1): Track polynomial\n\toffsets and sizes.\n\t* fold-const.c (make_bit_field_ref): Take the bitpos as a poly_int64\n\trather than a HOST_WIDE_INT.  Update call to get_inner_reference.\n\t(optimize_bit_field_compare): Update call to get_inner_reference.\n\t(decode_field_reference): Likewise.\n\t(fold_unary_loc): Track polynomial offsets and sizes.\n\t(split_address_to_core_and_offset): Return the bitpos as a\n\tpoly_int64_pod rather than a HOST_WIDE_INT.\n\t(ptr_difference_const): Likewise for the pointer difference.\n\t* asan.c (instrument_derefs): Track polynomial offsets and sizes.\n\t* config/mips/mips.c (r10k_safe_mem_expr_p): Likewise.\n\t* dbxout.c (dbxout_expand_expr): Likewise.\n\t* dwarf2out.c (loc_list_for_address_of_addr_expr_of_indirect_ref)\n\t(loc_list_from_tree_1, fortran_common): Likewise.\n\t* gimple-laddress.c (pass_laddress::execute): Likewise.\n\t* gimple-ssa-store-merging.c (find_bswap_or_nop_load): Likewise.\n\t* gimplify.c (gimplify_scan_omp_clauses): Likewise.\n\t* simplify-rtx.c (delegitimize_mem_from_attrs): Likewise.\n\t* tree-affine.c (tree_to_aff_combination): Likewise.\n\t(get_inner_reference_aff): Likewise.\n\t* tree-data-ref.c (split_constant_offset_1): Likewise.\n\t(dr_analyze_innermost): Likewise.\n\t* tree-scalar-evolution.c (interpret_rhs_expr): Likewise.\n\t* tree-sra.c (ipa_sra_check_caller): Likewise.\n\t* tree-vect-data-refs.c (vect_check_gather_scatter): Likewise.\n\t* ubsan.c (maybe_instrument_pointer_overflow): Likewise.\n\t(instrument_bool_enum_load, instrument_object_size): Likewise.\n\t* gimple-ssa-strength-reduction.c (slsr_process_ref): Update call\n\tto get_inner_reference.\n\t* hsa-gen.c (gen_hsa_addr): Likewise.\n\t* sanopt.c (maybe_optimize_ubsan_ptr_ifn): Likewise.\n\t* tsan.c (instrument_expr): Likewise.\n\t* match.pd: Update call to ptr_difference_const.\n\ngcc/ada/\n\t* gcc-interface/trans.c (Attribute_to_gnu): Track polynomial\n\toffsets and sizes.\n\t* gcc-interface/utils2.c (build_unary_op): Likewise.\n\ngcc/cp/\n\t* constexpr.c (check_automatic_or_tls): Track polynomial\n\toffsets and sizes.\n\nCo-Authored-By: Alan Hayward <alan.hayward@arm.com>\nCo-Authored-By: David Sherwood <david.sherwood@arm.com>\n\nFrom-SVN: r255914", "tree": {"sha": "ebd8f2d136ae51379031e2596095f05826868563", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/ebd8f2d136ae51379031e2596095f05826868563"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/comments", "author": null, "committer": null, "parents": [{"sha": "5b9bbb630de43db527acf5e5a80c0a3dd446e0d9", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5b9bbb630de43db527acf5e5a80c0a3dd446e0d9", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5b9bbb630de43db527acf5e5a80c0a3dd446e0d9"}], "stats": {"total": 581, "additions": 331, "deletions": 250}, "files": [{"sha": "fd061b9c2cafcedb11f9a1bbe420043dab2cb8ca", "filename": "gcc/ChangeLog", "status": "modified", "additions": 45, "deletions": 0, "changes": 45, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -1,3 +1,48 @@\n+2017-12-21  Richard Sandiford  <richard.sandiford@linaro.org>\n+\t    Alan Hayward  <alan.hayward@arm.com>\n+\t    David Sherwood  <david.sherwood@arm.com>\n+\n+\t* tree.h (get_inner_reference): Return the bitsize and bitpos\n+\tas poly_int64_pods rather than HOST_WIDE_INT.\n+\t* fold-const.h (ptr_difference_const): Return the pointer difference\n+\tas a poly_int64_pod rather than a HOST_WIDE_INT.\n+\t* expr.c (get_inner_reference): Return the bitsize and bitpos\n+\tas poly_int64_pods rather than HOST_WIDE_INT.\n+\t(expand_expr_addr_expr_1, expand_expr_real_1): Track polynomial\n+\toffsets and sizes.\n+\t* fold-const.c (make_bit_field_ref): Take the bitpos as a poly_int64\n+\trather than a HOST_WIDE_INT.  Update call to get_inner_reference.\n+\t(optimize_bit_field_compare): Update call to get_inner_reference.\n+\t(decode_field_reference): Likewise.\n+\t(fold_unary_loc): Track polynomial offsets and sizes.\n+\t(split_address_to_core_and_offset): Return the bitpos as a\n+\tpoly_int64_pod rather than a HOST_WIDE_INT.\n+\t(ptr_difference_const): Likewise for the pointer difference.\n+\t* asan.c (instrument_derefs): Track polynomial offsets and sizes.\n+\t* config/mips/mips.c (r10k_safe_mem_expr_p): Likewise.\n+\t* dbxout.c (dbxout_expand_expr): Likewise.\n+\t* dwarf2out.c (loc_list_for_address_of_addr_expr_of_indirect_ref)\n+\t(loc_list_from_tree_1, fortran_common): Likewise.\n+\t* gimple-laddress.c (pass_laddress::execute): Likewise.\n+\t* gimple-ssa-store-merging.c (find_bswap_or_nop_load): Likewise.\n+\t* gimplify.c (gimplify_scan_omp_clauses): Likewise.\n+\t* simplify-rtx.c (delegitimize_mem_from_attrs): Likewise.\n+\t* tree-affine.c (tree_to_aff_combination): Likewise.\n+\t(get_inner_reference_aff): Likewise.\n+\t* tree-data-ref.c (split_constant_offset_1): Likewise.\n+\t(dr_analyze_innermost): Likewise.\n+\t* tree-scalar-evolution.c (interpret_rhs_expr): Likewise.\n+\t* tree-sra.c (ipa_sra_check_caller): Likewise.\n+\t* tree-vect-data-refs.c (vect_check_gather_scatter): Likewise.\n+\t* ubsan.c (maybe_instrument_pointer_overflow): Likewise.\n+\t(instrument_bool_enum_load, instrument_object_size): Likewise.\n+\t* gimple-ssa-strength-reduction.c (slsr_process_ref): Update call\n+\tto get_inner_reference.\n+\t* hsa-gen.c (gen_hsa_addr): Likewise.\n+\t* sanopt.c (maybe_optimize_ubsan_ptr_ifn): Likewise.\n+\t* tsan.c (instrument_expr): Likewise.\n+\t* match.pd: Update call to ptr_difference_const.\n+\n 2017-12-21  Richard Sandiford  <richard.sandiford@linaro.org>\n \t    Alan Hayward  <alan.hayward@arm.com>\n \t    David Sherwood  <david.sherwood@arm.com>"}, {"sha": "13a0c80e43171238489f6c2aa02177cf2748021b", "filename": "gcc/ada/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fada%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fada%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fada%2FChangeLog?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -1,3 +1,11 @@\n+2017-12-21  Richard Sandiford  <richard.sandiford@linaro.org>\n+\t    Alan Hayward  <alan.hayward@arm.com>\n+\t    David Sherwood  <david.sherwood@arm.com>\n+\n+\t* gcc-interface/trans.c (Attribute_to_gnu): Track polynomial\n+\toffsets and sizes.\n+\t* gcc-interface/utils2.c (build_unary_op): Likewise.\n+\n 2017-12-20  Eric Botcazou  <ebotcazou@adacore.com>\n \n \t* gcc-interface/trans.c (Loop_Statement_to_gnu): Use IN_RANGE macro."}, {"sha": "587063b6e7735decb8008e9da115ebb22640a37f", "filename": "gcc/ada/gcc-interface/trans.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fada%2Fgcc-interface%2Ftrans.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fada%2Fgcc-interface%2Ftrans.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fada%2Fgcc-interface%2Ftrans.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -2187,8 +2187,8 @@ Attribute_to_gnu (Node_Id gnat_node, tree *gnu_result_type_p, int attribute)\n     case Attr_Last_Bit:\n     case Attr_Bit:\n       {\n-\tHOST_WIDE_INT bitsize;\n-\tHOST_WIDE_INT bitpos;\n+\tpoly_int64 bitsize;\n+\tpoly_int64 bitpos;\n \ttree gnu_offset;\n \ttree gnu_field_bitpos;\n \ttree gnu_field_offset;\n@@ -2255,11 +2255,11 @@ Attribute_to_gnu (Node_Id gnat_node, tree *gnu_result_type_p, int attribute)\n \n \t  case Attr_First_Bit:\n \t  case Attr_Bit:\n-\t    gnu_result = size_int (bitpos % BITS_PER_UNIT);\n+\t    gnu_result = size_int (num_trailing_bits (bitpos));\n \t    break;\n \n \t  case Attr_Last_Bit:\n-\t    gnu_result = bitsize_int (bitpos % BITS_PER_UNIT);\n+\t    gnu_result = bitsize_int (num_trailing_bits (bitpos));\n \t    gnu_result = size_binop (PLUS_EXPR, gnu_result,\n \t\t\t\t     TYPE_SIZE (TREE_TYPE (gnu_prefix)));\n \t    /* ??? Avoid a large unsigned result that will overflow when"}, {"sha": "7f3a3d3ff1acc816ac864eee94a3a0e2df2fd7dd", "filename": "gcc/ada/gcc-interface/utils2.c", "status": "modified", "additions": 5, "deletions": 4, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fada%2Fgcc-interface%2Futils2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fada%2Fgcc-interface%2Futils2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fada%2Fgcc-interface%2Futils2.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -1439,8 +1439,8 @@ build_unary_op (enum tree_code op_code, tree result_type, tree operand)\n \t       the offset to the field.  Otherwise, do this the normal way.  */\n \t  if (op_code == ATTR_ADDR_EXPR)\n \t    {\n-\t      HOST_WIDE_INT bitsize;\n-\t      HOST_WIDE_INT bitpos;\n+\t      poly_int64 bitsize;\n+\t      poly_int64 bitpos;\n \t      tree offset, inner;\n \t      machine_mode mode;\n \t      int unsignedp, reversep, volatilep;\n@@ -1460,8 +1460,9 @@ build_unary_op (enum tree_code op_code, tree result_type, tree operand)\n \t      if (!offset)\n \t\toffset = size_zero_node;\n \n-\t      offset = size_binop (PLUS_EXPR, offset,\n-\t\t\t\t   size_int (bitpos / BITS_PER_UNIT));\n+\t      offset\n+\t\t= size_binop (PLUS_EXPR, offset,\n+\t\t\t      size_int (bits_to_bytes_round_down (bitpos)));\n \n \t      /* Take the address of INNER, convert it to a pointer to our type\n \t\t and add the offset.  */"}, {"sha": "144bfb3585589cf89c54790252a20df7c1934a3a", "filename": "gcc/asan.c", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fasan.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fasan.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fasan.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -2076,7 +2076,7 @@ instrument_derefs (gimple_stmt_iterator *iter, tree t,\n   if (size_in_bytes <= 0)\n     return;\n \n-  HOST_WIDE_INT bitsize, bitpos;\n+  poly_int64 bitsize, bitpos;\n   tree offset;\n   machine_mode mode;\n   int unsignedp, reversep, volatilep = 0;\n@@ -2094,19 +2094,19 @@ instrument_derefs (gimple_stmt_iterator *iter, tree t,\n       return;\n     }\n \n-  if (bitpos % BITS_PER_UNIT\n-      || bitsize != size_in_bytes * BITS_PER_UNIT)\n+  if (!multiple_p (bitpos, BITS_PER_UNIT)\n+      || maybe_ne (bitsize, size_in_bytes * BITS_PER_UNIT))\n     return;\n \n   if (VAR_P (inner) && DECL_HARD_REGISTER (inner))\n     return;\n \n+  poly_int64 decl_size;\n   if (VAR_P (inner)\n       && offset == NULL_TREE\n-      && bitpos >= 0\n       && DECL_SIZE (inner)\n-      && tree_fits_shwi_p (DECL_SIZE (inner))\n-      && bitpos + bitsize <= tree_to_shwi (DECL_SIZE (inner)))\n+      && poly_int_tree_p (DECL_SIZE (inner), &decl_size)\n+      && known_subrange_p (bitpos, bitsize, 0, decl_size))\n     {\n       if (DECL_THREAD_LOCAL_P (inner))\n \treturn;"}, {"sha": "8f2f6e09824e0b6bd2dfaf82ef1f9e4806198370", "filename": "gcc/config/mips/mips.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fconfig%2Fmips%2Fmips.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fconfig%2Fmips%2Fmips.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fmips%2Fmips.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -17613,7 +17613,7 @@ r10k_safe_address_p (rtx x, rtx_insn *insn)\n static bool\n r10k_safe_mem_expr_p (tree expr, unsigned HOST_WIDE_INT offset)\n {\n-  HOST_WIDE_INT bitoffset, bitsize;\n+  poly_int64 bitoffset, bitsize;\n   tree inner, var_offset;\n   machine_mode mode;\n   int unsigned_p, reverse_p, volatile_p;"}, {"sha": "92a8ac6261355e2579206b3edb02d8b0df714768", "filename": "gcc/cp/ChangeLog", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fcp%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fcp%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2FChangeLog?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -1,3 +1,10 @@\n+2017-12-21  Richard Sandiford  <richard.sandiford@linaro.org>\n+\t    Alan Hayward  <alan.hayward@arm.com>\n+\t    David Sherwood  <david.sherwood@arm.com>\n+\n+\t* constexpr.c (check_automatic_or_tls): Track polynomial\n+\toffsets and sizes.\n+\n 2017-12-19  Paolo Carlini  <paolo.carlini@oracle.com>\n \n \tPR c++/82593"}, {"sha": "6845ca407c1a9e2fdeec98755534ba435f2029fe", "filename": "gcc/cp/constexpr.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fcp%2Fconstexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fcp%2Fconstexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fconstexpr.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -5110,7 +5110,7 @@ static int\n check_automatic_or_tls (tree ref)\n {\n   machine_mode mode;\n-  HOST_WIDE_INT bitsize, bitpos;\n+  poly_int64 bitsize, bitpos;\n   tree offset;\n   int volatilep = 0, unsignedp = 0;\n   tree decl = get_inner_reference (ref, &bitsize, &bitpos, &offset,"}, {"sha": "7c611ffc91abcb89426235b9bbd8efa88c3406d9", "filename": "gcc/dbxout.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fdbxout.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fdbxout.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdbxout.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -2531,7 +2531,7 @@ dbxout_expand_expr (tree expr)\n     case BIT_FIELD_REF:\n       {\n \tmachine_mode mode;\n-\tHOST_WIDE_INT bitsize, bitpos;\n+\tpoly_int64 bitsize, bitpos;\n \ttree offset, tem;\n \tint unsignedp, reversep, volatilep = 0;\n \trtx x;\n@@ -2548,8 +2548,8 @@ dbxout_expand_expr (tree expr)\n \t      return NULL;\n \t    x = adjust_address_nv (x, mode, tree_to_shwi (offset));\n \t  }\n-\tif (bitpos != 0)\n-\t  x = adjust_address_nv (x, mode, bitpos / BITS_PER_UNIT);\n+\tif (maybe_ne (bitpos, 0))\n+\t  x = adjust_address_nv (x, mode, bits_to_bytes_round_down (bitpos));\n \n \treturn x;\n       }"}, {"sha": "018f5123259119038de2d214a7b934f0fa4696da", "filename": "gcc/dwarf2out.c", "status": "modified", "additions": 25, "deletions": 19, "changes": 44, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fdwarf2out.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fdwarf2out.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdwarf2out.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -16700,7 +16700,7 @@ loc_list_for_address_of_addr_expr_of_indirect_ref (tree loc, bool toplev,\n \t\t\t\t\t\t   loc_descr_context *context)\n {\n   tree obj, offset;\n-  HOST_WIDE_INT bitsize, bitpos, bytepos;\n+  poly_int64 bitsize, bitpos, bytepos;\n   machine_mode mode;\n   int unsignedp, reversep, volatilep = 0;\n   dw_loc_list_ref list_ret = NULL, list_ret1 = NULL;\n@@ -16709,7 +16709,7 @@ loc_list_for_address_of_addr_expr_of_indirect_ref (tree loc, bool toplev,\n \t\t\t     &bitsize, &bitpos, &offset, &mode,\n \t\t\t     &unsignedp, &reversep, &volatilep);\n   STRIP_NOPS (obj);\n-  if (bitpos % BITS_PER_UNIT)\n+  if (!multiple_p (bitpos, BITS_PER_UNIT, &bytepos))\n     {\n       expansion_failed (loc, NULL_RTX, \"bitfield access\");\n       return 0;\n@@ -16720,7 +16720,7 @@ loc_list_for_address_of_addr_expr_of_indirect_ref (tree loc, bool toplev,\n \t\t\tNULL_RTX, \"no indirect ref in inner refrence\");\n       return 0;\n     }\n-  if (!offset && !bitpos)\n+  if (!offset && known_eq (bitpos, 0))\n     list_ret = loc_list_from_tree (TREE_OPERAND (obj, 0), toplev ? 2 : 1,\n \t\t\t\t   context);\n   else if (toplev\n@@ -16742,12 +16742,11 @@ loc_list_for_address_of_addr_expr_of_indirect_ref (tree loc, bool toplev,\n \t  add_loc_descr_to_each (list_ret,\n \t\t\t\t new_loc_descr (DW_OP_plus, 0, 0));\n \t}\n-      bytepos = bitpos / BITS_PER_UNIT;\n-      if (bytepos > 0)\n+      HOST_WIDE_INT value;\n+      if (bytepos.is_constant (&value) && value > 0)\n \tadd_loc_descr_to_each (list_ret,\n-\t\t\t       new_loc_descr (DW_OP_plus_uconst,\n-\t\t\t\t\t      bytepos, 0));\n-      else if (bytepos < 0)\n+\t\t\t       new_loc_descr (DW_OP_plus_uconst, value, 0));\n+      else if (maybe_ne (bytepos, 0))\n \tloc_list_plus_const (list_ret, bytepos);\n       add_loc_descr_to_each (list_ret,\n \t\t\t     new_loc_descr (DW_OP_stack_value, 0, 0));\n@@ -17717,7 +17716,7 @@ loc_list_from_tree_1 (tree loc, int want_address,\n     case IMAGPART_EXPR:\n       {\n \ttree obj, offset;\n-\tHOST_WIDE_INT bitsize, bitpos, bytepos;\n+\tpoly_int64 bitsize, bitpos, bytepos;\n \tmachine_mode mode;\n \tint unsignedp, reversep, volatilep = 0;\n \n@@ -17728,13 +17727,15 @@ loc_list_from_tree_1 (tree loc, int want_address,\n \n \tlist_ret = loc_list_from_tree_1 (obj,\n \t\t\t\t\t want_address == 2\n-\t\t\t\t\t && !bitpos && !offset ? 2 : 1,\n+\t\t\t\t\t && known_eq (bitpos, 0)\n+\t\t\t\t\t && !offset ? 2 : 1,\n \t\t\t\t\t context);\n \t/* TODO: We can extract value of the small expression via shifting even\n \t   for nonzero bitpos.  */\n \tif (list_ret == 0)\n \t  return 0;\n-\tif (bitpos % BITS_PER_UNIT != 0 || bitsize % BITS_PER_UNIT != 0)\n+\tif (!multiple_p (bitpos, BITS_PER_UNIT, &bytepos)\n+\t    || !multiple_p (bitsize, BITS_PER_UNIT))\n \t  {\n \t    expansion_failed (loc, NULL_RTX,\n \t\t\t      \"bitfield access\");\n@@ -17753,10 +17754,11 @@ loc_list_from_tree_1 (tree loc, int want_address,\n \t    add_loc_descr_to_each (list_ret, new_loc_descr (DW_OP_plus, 0, 0));\n \t  }\n \n-\tbytepos = bitpos / BITS_PER_UNIT;\n-\tif (bytepos > 0)\n-\t  add_loc_descr_to_each (list_ret, new_loc_descr (DW_OP_plus_uconst, bytepos, 0));\n-\telse if (bytepos < 0)\n+\tHOST_WIDE_INT value;\n+\tif (bytepos.is_constant (&value) && value > 0)\n+\t  add_loc_descr_to_each (list_ret, new_loc_descr (DW_OP_plus_uconst,\n+\t\t\t\t\t\t\t  value, 0));\n+\telse if (maybe_ne (bytepos, 0))\n \t  loc_list_plus_const (list_ret, bytepos);\n \n \thave_address = 1;\n@@ -19286,8 +19288,9 @@ fortran_common (tree decl, HOST_WIDE_INT *value)\n {\n   tree val_expr, cvar;\n   machine_mode mode;\n-  HOST_WIDE_INT bitsize, bitpos;\n+  poly_int64 bitsize, bitpos;\n   tree offset;\n+  HOST_WIDE_INT cbitpos;\n   int unsignedp, reversep, volatilep = 0;\n \n   /* If the decl isn't a VAR_DECL, or if it isn't static, or if\n@@ -19310,7 +19313,10 @@ fortran_common (tree decl, HOST_WIDE_INT *value)\n   if (cvar == NULL_TREE\n       || !VAR_P (cvar)\n       || DECL_ARTIFICIAL (cvar)\n-      || !TREE_PUBLIC (cvar))\n+      || !TREE_PUBLIC (cvar)\n+      /* We don't expect to have to cope with variable offsets,\n+\t since at present all static data must have a constant size.  */\n+      || !bitpos.is_constant (&cbitpos))\n     return NULL_TREE;\n \n   *value = 0;\n@@ -19320,8 +19326,8 @@ fortran_common (tree decl, HOST_WIDE_INT *value)\n \treturn NULL_TREE;\n       *value = tree_to_shwi (offset);\n     }\n-  if (bitpos != 0)\n-    *value += bitpos / BITS_PER_UNIT;\n+  if (cbitpos != 0)\n+    *value += cbitpos / BITS_PER_UNIT;\n \n   return cvar;\n }"}, {"sha": "4d146f9e2bad101ac5ad89059086b2f5a75874ed", "filename": "gcc/expr.c", "status": "modified", "additions": 75, "deletions": 76, "changes": 151, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -7038,16 +7038,16 @@ store_field (rtx target, poly_int64 bitsize, poly_int64 bitpos,\n    this case, but the address of the object can be found.  */\n \n tree\n-get_inner_reference (tree exp, HOST_WIDE_INT *pbitsize,\n-\t\t     HOST_WIDE_INT *pbitpos, tree *poffset,\n+get_inner_reference (tree exp, poly_int64_pod *pbitsize,\n+\t\t     poly_int64_pod *pbitpos, tree *poffset,\n \t\t     machine_mode *pmode, int *punsignedp,\n \t\t     int *preversep, int *pvolatilep)\n {\n   tree size_tree = 0;\n   machine_mode mode = VOIDmode;\n   bool blkmode_bitfield = false;\n   tree offset = size_zero_node;\n-  offset_int bit_offset = 0;\n+  poly_offset_int bit_offset = 0;\n \n   /* First get the mode, signedness, storage order and size.  We do this from\n      just the outermost expression.  */\n@@ -7121,7 +7121,7 @@ get_inner_reference (tree exp, HOST_WIDE_INT *pbitsize,\n       switch (TREE_CODE (exp))\n \t{\n \tcase BIT_FIELD_REF:\n-\t  bit_offset += wi::to_offset (TREE_OPERAND (exp, 2));\n+\t  bit_offset += wi::to_poly_offset (TREE_OPERAND (exp, 2));\n \t  break;\n \n \tcase COMPONENT_REF:\n@@ -7136,7 +7136,7 @@ get_inner_reference (tree exp, HOST_WIDE_INT *pbitsize,\n \t      break;\n \n \t    offset = size_binop (PLUS_EXPR, offset, this_offset);\n-\t    bit_offset += wi::to_offset (DECL_FIELD_BIT_OFFSET (field));\n+\t    bit_offset += wi::to_poly_offset (DECL_FIELD_BIT_OFFSET (field));\n \n \t    /* ??? Right now we don't do anything with DECL_OFFSET_ALIGN.  */\n \t  }\n@@ -7204,44 +7204,36 @@ get_inner_reference (tree exp, HOST_WIDE_INT *pbitsize,\n   /* If OFFSET is constant, see if we can return the whole thing as a\n      constant bit position.  Make sure to handle overflow during\n      this conversion.  */\n-  if (TREE_CODE (offset) == INTEGER_CST)\n+  if (poly_int_tree_p (offset))\n     {\n-      offset_int tem = wi::sext (wi::to_offset (offset),\n-\t\t\t\t TYPE_PRECISION (sizetype));\n+      poly_offset_int tem = wi::sext (wi::to_poly_offset (offset),\n+\t\t\t\t      TYPE_PRECISION (sizetype));\n       tem <<= LOG2_BITS_PER_UNIT;\n       tem += bit_offset;\n-      if (wi::fits_shwi_p (tem))\n-\t{\n-\t  *pbitpos = tem.to_shwi ();\n-\t  *poffset = offset = NULL_TREE;\n-\t}\n+      if (tem.to_shwi (pbitpos))\n+\t*poffset = offset = NULL_TREE;\n     }\n \n   /* Otherwise, split it up.  */\n   if (offset)\n     {\n       /* Avoid returning a negative bitpos as this may wreak havoc later.  */\n-      if (wi::neg_p (bit_offset) || !wi::fits_shwi_p (bit_offset))\n+      if (!bit_offset.to_shwi (pbitpos) || maybe_lt (*pbitpos, 0))\n         {\n-\t  offset_int mask = wi::mask <offset_int> (LOG2_BITS_PER_UNIT, false);\n-\t  offset_int tem = wi::bit_and_not (bit_offset, mask);\n-\t  /* TEM is the bitpos rounded to BITS_PER_UNIT towards -Inf.\n-\t     Subtract it to BIT_OFFSET and add it (scaled) to OFFSET.  */\n-\t  bit_offset -= tem;\n-\t  tem >>= LOG2_BITS_PER_UNIT;\n+\t  *pbitpos = num_trailing_bits (bit_offset.force_shwi ());\n+\t  poly_offset_int bytes = bits_to_bytes_round_down (bit_offset);\n \t  offset = size_binop (PLUS_EXPR, offset,\n-\t\t\t       wide_int_to_tree (sizetype, tem));\n+\t\t\t       build_int_cst (sizetype, bytes.force_shwi ()));\n \t}\n \n-      *pbitpos = bit_offset.to_shwi ();\n       *poffset = offset;\n     }\n \n   /* We can use BLKmode for a byte-aligned BLKmode bitfield.  */\n   if (mode == VOIDmode\n       && blkmode_bitfield\n-      && (*pbitpos % BITS_PER_UNIT) == 0\n-      && (*pbitsize % BITS_PER_UNIT) == 0)\n+      && multiple_p (*pbitpos, BITS_PER_UNIT)\n+      && multiple_p (*pbitsize, BITS_PER_UNIT))\n     *pmode = BLKmode;\n   else\n     *pmode = mode;\n@@ -7777,7 +7769,7 @@ expand_expr_addr_expr_1 (tree exp, rtx target, scalar_int_mode tmode,\n {\n   rtx result, subtarget;\n   tree inner, offset;\n-  HOST_WIDE_INT bitsize, bitpos;\n+  poly_int64 bitsize, bitpos;\n   int unsignedp, reversep, volatilep = 0;\n   machine_mode mode1;\n \n@@ -7893,7 +7885,7 @@ expand_expr_addr_expr_1 (tree exp, rtx target, scalar_int_mode tmode,\n   /* We must have made progress.  */\n   gcc_assert (inner != exp);\n \n-  subtarget = offset || bitpos ? NULL_RTX : target;\n+  subtarget = offset || maybe_ne (bitpos, 0) ? NULL_RTX : target;\n   /* For VIEW_CONVERT_EXPR, where the outer alignment is bigger than\n      inner alignment, force the inner to be sufficiently aligned.  */\n   if (CONSTANT_CLASS_P (inner)\n@@ -7928,20 +7920,19 @@ expand_expr_addr_expr_1 (tree exp, rtx target, scalar_int_mode tmode,\n \tresult = simplify_gen_binary (PLUS, tmode, result, tmp);\n       else\n \t{\n-\t  subtarget = bitpos ? NULL_RTX : target;\n+\t  subtarget = maybe_ne (bitpos, 0) ? NULL_RTX : target;\n \t  result = expand_simple_binop (tmode, PLUS, result, tmp, subtarget,\n \t\t\t\t\t1, OPTAB_LIB_WIDEN);\n \t}\n     }\n \n-  if (bitpos)\n+  if (maybe_ne (bitpos, 0))\n     {\n       /* Someone beforehand should have rejected taking the address\n-\t of such an object.  */\n-      gcc_assert ((bitpos % BITS_PER_UNIT) == 0);\n-\n+\t of an object that isn't byte-aligned.  */\n+      poly_int64 bytepos = exact_div (bitpos, BITS_PER_UNIT);\n       result = convert_memory_address_addr_space (tmode, result, as);\n-      result = plus_constant (tmode, result, bitpos / BITS_PER_UNIT);\n+      result = plus_constant (tmode, result, bytepos);\n       if (modifier < EXPAND_SUM)\n \tresult = force_operand (result, target);\n     }\n@@ -10496,7 +10487,7 @@ expand_expr_real_1 (tree exp, rtx target, machine_mode tmode,\n     normal_inner_ref:\n       {\n \tmachine_mode mode1, mode2;\n-\tHOST_WIDE_INT bitsize, bitpos;\n+\tpoly_int64 bitsize, bitpos, bytepos;\n \ttree offset;\n \tint reversep, volatilep = 0, must_force_mem;\n \ttree tem\n@@ -10549,13 +10540,14 @@ expand_expr_real_1 (tree exp, rtx target, machine_mode tmode,\n \t   to a larger size.  */\n \tmust_force_mem = (offset\n \t\t\t  || mode1 == BLKmode\n-\t\t\t  || bitpos + bitsize > GET_MODE_BITSIZE (mode2));\n+\t\t\t  || maybe_gt (bitpos + bitsize,\n+\t\t\t\t       GET_MODE_BITSIZE (mode2)));\n \n \t/* Handle CONCAT first.  */\n \tif (GET_CODE (op0) == CONCAT && !must_force_mem)\n \t  {\n-\t    if (bitpos == 0\n-\t\t&& bitsize == GET_MODE_BITSIZE (GET_MODE (op0))\n+\t    if (known_eq (bitpos, 0)\n+\t\t&& known_eq (bitsize, GET_MODE_BITSIZE (GET_MODE (op0)))\n \t\t&& COMPLEX_MODE_P (mode1)\n \t\t&& COMPLEX_MODE_P (GET_MODE (op0))\n \t\t&& (GET_MODE_PRECISION (GET_MODE_INNER (mode1))\n@@ -10587,17 +10579,20 @@ expand_expr_real_1 (tree exp, rtx target, machine_mode tmode,\n \t\t  }\n \t\treturn op0;\n \t      }\n-\t    if (bitpos == 0\n-\t\t&& bitsize == GET_MODE_BITSIZE (GET_MODE (XEXP (op0, 0)))\n-\t\t&& bitsize)\n+\t    if (known_eq (bitpos, 0)\n+\t\t&& known_eq (bitsize,\n+\t\t\t     GET_MODE_BITSIZE (GET_MODE (XEXP (op0, 0))))\n+\t\t&& maybe_ne (bitsize, 0))\n \t      {\n \t\top0 = XEXP (op0, 0);\n \t\tmode2 = GET_MODE (op0);\n \t      }\n-\t    else if (bitpos == GET_MODE_BITSIZE (GET_MODE (XEXP (op0, 0)))\n-\t\t     && bitsize == GET_MODE_BITSIZE (GET_MODE (XEXP (op0, 1)))\n-\t\t     && bitpos\n-\t\t     && bitsize)\n+\t    else if (known_eq (bitpos,\n+\t\t\t       GET_MODE_BITSIZE (GET_MODE (XEXP (op0, 0))))\n+\t\t     && known_eq (bitsize,\n+\t\t\t\t  GET_MODE_BITSIZE (GET_MODE (XEXP (op0, 1))))\n+\t\t     && maybe_ne (bitpos, 0)\n+\t\t     && maybe_ne (bitsize, 0))\n \t      {\n \t\top0 = XEXP (op0, 1);\n \t\tbitpos = 0;\n@@ -10652,13 +10647,14 @@ expand_expr_real_1 (tree exp, rtx target, machine_mode tmode,\n \n \t    /* See the comment in expand_assignment for the rationale.  */\n \t    if (mode1 != VOIDmode\n-\t\t&& bitpos != 0\n-\t\t&& bitsize > 0\n-\t\t&& (bitpos % bitsize) == 0\n-\t\t&& (bitsize % GET_MODE_ALIGNMENT (mode1)) == 0\n+\t\t&& maybe_ne (bitpos, 0)\n+\t\t&& maybe_gt (bitsize, 0)\n+\t\t&& multiple_p (bitpos, BITS_PER_UNIT, &bytepos)\n+\t\t&& multiple_p (bitpos, bitsize)\n+\t\t&& multiple_p (bitsize, GET_MODE_ALIGNMENT (mode1))\n \t\t&& MEM_ALIGN (op0) >= GET_MODE_ALIGNMENT (mode1))\n \t      {\n-\t\top0 = adjust_address (op0, mode1, bitpos / BITS_PER_UNIT);\n+\t\top0 = adjust_address (op0, mode1, bytepos);\n \t\tbitpos = 0;\n \t      }\n \n@@ -10668,7 +10664,9 @@ expand_expr_real_1 (tree exp, rtx target, machine_mode tmode,\n \n \t/* If OFFSET is making OP0 more aligned than BIGGEST_ALIGNMENT,\n \t   record its alignment as BIGGEST_ALIGNMENT.  */\n-\tif (MEM_P (op0) && bitpos == 0 && offset != 0\n+\tif (MEM_P (op0)\n+\t    && known_eq (bitpos, 0)\n+\t    && offset != 0\n \t    && is_aligning_offset (offset, tem))\n \t  set_mem_align (op0, BIGGEST_ALIGNMENT);\n \n@@ -10701,37 +10699,37 @@ expand_expr_real_1 (tree exp, rtx target, machine_mode tmode,\n \t    || (volatilep && TREE_CODE (exp) == COMPONENT_REF\n \t\t&& DECL_BIT_FIELD_TYPE (TREE_OPERAND (exp, 1))\n \t\t&& mode1 != BLKmode\n-\t\t&& bitsize < GET_MODE_SIZE (mode1) * BITS_PER_UNIT)\n+\t\t&& maybe_lt (bitsize, GET_MODE_SIZE (mode1) * BITS_PER_UNIT))\n \t    /* If the field isn't aligned enough to fetch as a memref,\n \t       fetch it as a bit field.  */\n \t    || (mode1 != BLKmode\n \t\t&& (((MEM_P (op0)\n \t\t      ? MEM_ALIGN (op0) < GET_MODE_ALIGNMENT (mode1)\n-\t\t        || (bitpos % GET_MODE_ALIGNMENT (mode1) != 0)\n+\t\t\t|| !multiple_p (bitpos, GET_MODE_ALIGNMENT (mode1))\n \t\t      : TYPE_ALIGN (TREE_TYPE (tem)) < GET_MODE_ALIGNMENT (mode)\n-\t\t        || (bitpos % GET_MODE_ALIGNMENT (mode) != 0))\n+\t\t\t|| !multiple_p (bitpos, GET_MODE_ALIGNMENT (mode)))\n \t\t     && modifier != EXPAND_MEMORY\n \t\t     && ((modifier == EXPAND_CONST_ADDRESS\n \t\t\t  || modifier == EXPAND_INITIALIZER)\n \t\t\t ? STRICT_ALIGNMENT\n \t\t\t : targetm.slow_unaligned_access (mode1,\n \t\t\t\t\t\t\t  MEM_ALIGN (op0))))\n-\t\t    || (bitpos % BITS_PER_UNIT != 0)))\n+\t\t    || !multiple_p (bitpos, BITS_PER_UNIT)))\n \t    /* If the type and the field are a constant size and the\n \t       size of the type isn't the same size as the bitfield,\n \t       we must use bitfield operations.  */\n-\t    || (bitsize >= 0\n+\t    || (known_size_p (bitsize)\n \t\t&& TYPE_SIZE (TREE_TYPE (exp))\n-\t\t&& TREE_CODE (TYPE_SIZE (TREE_TYPE (exp))) == INTEGER_CST\n-\t\t&& compare_tree_int (TYPE_SIZE (TREE_TYPE (exp)),\n-\t\t\t\t     bitsize) != 0))\n+\t\t&& poly_int_tree_p (TYPE_SIZE (TREE_TYPE (exp)))\n+\t\t&& maybe_ne (wi::to_poly_offset (TYPE_SIZE (TREE_TYPE (exp))),\n+\t\t\t     bitsize)))\n \t  {\n \t    machine_mode ext_mode = mode;\n \n \t    if (ext_mode == BLKmode\n \t\t&& ! (target != 0 && MEM_P (op0)\n \t\t      && MEM_P (target)\n-\t\t      && bitpos % BITS_PER_UNIT == 0))\n+\t\t      && multiple_p (bitpos, BITS_PER_UNIT)))\n \t      ext_mode = int_mode_for_size (bitsize, 1).else_blk ();\n \n \t    if (ext_mode == BLKmode)\n@@ -10741,20 +10739,19 @@ expand_expr_real_1 (tree exp, rtx target, machine_mode tmode,\n \n \t\t/* ??? Unlike the similar test a few lines below, this one is\n \t\t   very likely obsolete.  */\n-\t\tif (bitsize == 0)\n+\t\tif (known_eq (bitsize, 0))\n \t\t  return target;\n \n \t\t/* In this case, BITPOS must start at a byte boundary and\n \t\t   TARGET, if specified, must be a MEM.  */\n \t\tgcc_assert (MEM_P (op0)\n-\t\t\t    && (!target || MEM_P (target))\n-\t\t\t    && !(bitpos % BITS_PER_UNIT));\n+\t\t\t    && (!target || MEM_P (target)));\n \n+\t\tbytepos = exact_div (bitpos, BITS_PER_UNIT);\n+\t\tpoly_int64 bytesize = bits_to_bytes_round_up (bitsize);\n \t\temit_block_move (target,\n-\t\t\t\t adjust_address (op0, VOIDmode,\n-\t\t\t\t\t\t bitpos / BITS_PER_UNIT),\n-\t\t\t\t GEN_INT ((bitsize + BITS_PER_UNIT - 1)\n-\t\t\t\t\t  / BITS_PER_UNIT),\n+\t\t\t\t adjust_address (op0, VOIDmode, bytepos),\n+\t\t\t\t gen_int_mode (bytesize, Pmode),\n \t\t\t\t (modifier == EXPAND_STACK_PARM\n \t\t\t\t  ? BLOCK_OP_CALL_PARM : BLOCK_OP_NORMAL));\n \n@@ -10765,7 +10762,7 @@ expand_expr_real_1 (tree exp, rtx target, machine_mode tmode,\n \t       with SHIFT_COUNT_TRUNCATED == 0 and garbage otherwise.  Always\n \t       return 0 for the sake of consistency, as reading a zero-sized\n \t       bitfield is valid in Ada and the value is fully specified.  */\n-\t    if (bitsize == 0)\n+\t    if (known_eq (bitsize, 0))\n \t      return const0_rtx;\n \n \t    op0 = validize_mem (op0);\n@@ -10798,7 +10795,8 @@ expand_expr_real_1 (tree exp, rtx target, machine_mode tmode,\n \t      {\n \t\tHOST_WIDE_INT size = GET_MODE_BITSIZE (op0_mode);\n \n-\t\tif (bitsize < size\n+\t\tgcc_checking_assert (known_le (bitsize, size));\n+\t\tif (maybe_lt (bitsize, size)\n \t\t    && reversep ? !BYTES_BIG_ENDIAN : BYTES_BIG_ENDIAN)\n \t\t  op0 = expand_shift (LSHIFT_EXPR, op0_mode, op0,\n \t\t\t\t      size - bitsize, op0, 1);\n@@ -10830,11 +10828,12 @@ expand_expr_real_1 (tree exp, rtx target, machine_mode tmode,\n \t  mode1 = BLKmode;\n \n \t/* Get a reference to just this component.  */\n+\tbytepos = bits_to_bytes_round_down (bitpos);\n \tif (modifier == EXPAND_CONST_ADDRESS\n \t    || modifier == EXPAND_SUM || modifier == EXPAND_INITIALIZER)\n-\t  op0 = adjust_address_nv (op0, mode1, bitpos / BITS_PER_UNIT);\n+\t  op0 = adjust_address_nv (op0, mode1, bytepos);\n \telse\n-\t  op0 = adjust_address (op0, mode1, bitpos / BITS_PER_UNIT);\n+\t  op0 = adjust_address (op0, mode1, bytepos);\n \n \tif (op0 == orig_op0)\n \t  op0 = copy_rtx (op0);\n@@ -10917,12 +10916,12 @@ expand_expr_real_1 (tree exp, rtx target, machine_mode tmode,\n       /* If we are converting to BLKmode, try to avoid an intermediate\n \t temporary by fetching an inner memory reference.  */\n       if (mode == BLKmode\n-\t  && TREE_CODE (TYPE_SIZE (type)) == INTEGER_CST\n+\t  && poly_int_tree_p (TYPE_SIZE (type))\n \t  && TYPE_MODE (TREE_TYPE (treeop0)) != BLKmode\n \t  && handled_component_p (treeop0))\n       {\n \tmachine_mode mode1;\n-\tHOST_WIDE_INT bitsize, bitpos;\n+\tpoly_int64 bitsize, bitpos, bytepos;\n \ttree offset;\n \tint unsignedp, reversep, volatilep = 0;\n \ttree tem\n@@ -10932,10 +10931,10 @@ expand_expr_real_1 (tree exp, rtx target, machine_mode tmode,\n \n \t/* ??? We should work harder and deal with non-zero offsets.  */\n \tif (!offset\n-\t    && (bitpos % BITS_PER_UNIT) == 0\n+\t    && multiple_p (bitpos, BITS_PER_UNIT, &bytepos)\n \t    && !reversep\n-\t    && bitsize >= 0\n-\t    && compare_tree_int (TYPE_SIZE (type), bitsize) == 0)\n+\t    && known_size_p (bitsize)\n+\t    && known_eq (wi::to_poly_offset (TYPE_SIZE (type)), bitsize))\n \t  {\n \t    /* See the normal_inner_ref case for the rationale.  */\n \t    orig_op0\n@@ -10957,9 +10956,9 @@ expand_expr_real_1 (tree exp, rtx target, machine_mode tmode,\n \t\tif (modifier == EXPAND_CONST_ADDRESS\n \t\t    || modifier == EXPAND_SUM\n \t\t    || modifier == EXPAND_INITIALIZER)\n-\t\t  op0 = adjust_address_nv (op0, mode, bitpos / BITS_PER_UNIT);\n+\t\t  op0 = adjust_address_nv (op0, mode, bytepos);\n \t\telse\n-\t\t  op0 = adjust_address (op0, mode, bitpos / BITS_PER_UNIT);\n+\t\t  op0 = adjust_address (op0, mode, bytepos);\n \n \t\tif (op0 == orig_op0)\n \t\t  op0 = copy_rtx (op0);"}, {"sha": "2039d4dd2f9e3deab1a8cad4d6639cf36347d541", "filename": "gcc/fold-const.c", "status": "modified", "additions": 48, "deletions": 35, "changes": 83, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ffold-const.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ffold-const.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffold-const.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -3950,7 +3950,7 @@ invert_truthvalue_loc (location_t loc, tree arg)\n \n static tree\n make_bit_field_ref (location_t loc, tree inner, tree orig_inner, tree type,\n-\t\t    HOST_WIDE_INT bitsize, HOST_WIDE_INT bitpos,\n+\t\t    HOST_WIDE_INT bitsize, poly_int64 bitpos,\n \t\t    int unsignedp, int reversep)\n {\n   tree result, bftype;\n@@ -3960,17 +3960,15 @@ make_bit_field_ref (location_t loc, tree inner, tree orig_inner, tree type,\n     {\n       tree ninner = TREE_OPERAND (orig_inner, 0);\n       machine_mode nmode;\n-      HOST_WIDE_INT nbitsize, nbitpos;\n+      poly_int64 nbitsize, nbitpos;\n       tree noffset;\n       int nunsignedp, nreversep, nvolatilep = 0;\n       tree base = get_inner_reference (ninner, &nbitsize, &nbitpos,\n \t\t\t\t       &noffset, &nmode, &nunsignedp,\n \t\t\t\t       &nreversep, &nvolatilep);\n       if (base == inner\n \t  && noffset == NULL_TREE\n-\t  && nbitsize >= bitsize\n-\t  && nbitpos <= bitpos\n-\t  && bitpos + bitsize <= nbitpos + nbitsize\n+\t  && known_subrange_p (bitpos, bitsize, nbitpos, nbitsize)\n \t  && !reversep\n \t  && !nreversep\n \t  && !nvolatilep)\n@@ -3986,7 +3984,7 @@ make_bit_field_ref (location_t loc, tree inner, tree orig_inner, tree type,\n \t\t\t build_fold_addr_expr (inner),\n \t\t\t build_int_cst (ptr_type_node, 0));\n \n-  if (bitpos == 0 && !reversep)\n+  if (known_eq (bitpos, 0) && !reversep)\n     {\n       tree size = TYPE_SIZE (TREE_TYPE (inner));\n       if ((INTEGRAL_TYPE_P (TREE_TYPE (inner))\n@@ -4035,7 +4033,8 @@ static tree\n optimize_bit_field_compare (location_t loc, enum tree_code code,\n \t\t\t    tree compare_type, tree lhs, tree rhs)\n {\n-  HOST_WIDE_INT lbitpos, lbitsize, rbitpos, rbitsize, nbitpos, nbitsize;\n+  poly_int64 plbitpos, plbitsize, rbitpos, rbitsize;\n+  HOST_WIDE_INT lbitpos, lbitsize, nbitpos, nbitsize;\n   tree type = TREE_TYPE (lhs);\n   tree unsigned_type;\n   int const_p = TREE_CODE (rhs) == INTEGER_CST;\n@@ -4049,14 +4048,20 @@ optimize_bit_field_compare (location_t loc, enum tree_code code,\n   tree offset;\n \n   /* Get all the information about the extractions being done.  If the bit size\n-     if the same as the size of the underlying object, we aren't doing an\n+     is the same as the size of the underlying object, we aren't doing an\n      extraction at all and so can do nothing.  We also don't want to\n      do anything if the inner expression is a PLACEHOLDER_EXPR since we\n      then will no longer be able to replace it.  */\n-  linner = get_inner_reference (lhs, &lbitsize, &lbitpos, &offset, &lmode,\n+  linner = get_inner_reference (lhs, &plbitsize, &plbitpos, &offset, &lmode,\n \t\t\t\t&lunsignedp, &lreversep, &lvolatilep);\n-  if (linner == lhs || lbitsize == GET_MODE_BITSIZE (lmode) || lbitsize < 0\n-      || offset != 0 || TREE_CODE (linner) == PLACEHOLDER_EXPR || lvolatilep)\n+  if (linner == lhs\n+      || !known_size_p (plbitsize)\n+      || !plbitsize.is_constant (&lbitsize)\n+      || !plbitpos.is_constant (&lbitpos)\n+      || lbitsize == GET_MODE_BITSIZE (lmode)\n+      || offset != 0\n+      || TREE_CODE (linner) == PLACEHOLDER_EXPR\n+      || lvolatilep)\n     return 0;\n \n   if (const_p)\n@@ -4069,9 +4074,14 @@ optimize_bit_field_compare (location_t loc, enum tree_code code,\n        = get_inner_reference (rhs, &rbitsize, &rbitpos, &offset, &rmode,\n \t\t\t      &runsignedp, &rreversep, &rvolatilep);\n \n-     if (rinner == rhs || lbitpos != rbitpos || lbitsize != rbitsize\n-\t || lunsignedp != runsignedp || lreversep != rreversep || offset != 0\n-\t || TREE_CODE (rinner) == PLACEHOLDER_EXPR || rvolatilep)\n+     if (rinner == rhs\n+\t || maybe_ne (lbitpos, rbitpos)\n+\t || maybe_ne (lbitsize, rbitsize)\n+\t || lunsignedp != runsignedp\n+\t || lreversep != rreversep\n+\t || offset != 0\n+\t || TREE_CODE (rinner) == PLACEHOLDER_EXPR\n+\t || rvolatilep)\n        return 0;\n    }\n \n@@ -4080,7 +4090,6 @@ optimize_bit_field_compare (location_t loc, enum tree_code code,\n   poly_uint64 bitend = 0;\n   if (TREE_CODE (lhs) == COMPONENT_REF)\n     {\n-      poly_int64 plbitpos;\n       get_bit_range (&bitstart, &bitend, lhs, &plbitpos, &offset);\n       if (!plbitpos.is_constant (&lbitpos) || offset != NULL_TREE)\n \treturn 0;\n@@ -4250,10 +4259,14 @@ decode_field_reference (location_t loc, tree *exp_, HOST_WIDE_INT *pbitsize,\n \treturn 0;\n     }\n \n-  inner = get_inner_reference (exp, pbitsize, pbitpos, &offset, pmode,\n-\t\t\t       punsignedp, preversep, pvolatilep);\n+  poly_int64 poly_bitsize, poly_bitpos;\n+  inner = get_inner_reference (exp, &poly_bitsize, &poly_bitpos, &offset,\n+\t\t\t       pmode, punsignedp, preversep, pvolatilep);\n   if ((inner == exp && and_mask == 0)\n-      || *pbitsize < 0 || offset != 0\n+      || !poly_bitsize.is_constant (pbitsize)\n+      || !poly_bitpos.is_constant (pbitpos)\n+      || *pbitsize < 0\n+      || offset != 0\n       || TREE_CODE (inner) == PLACEHOLDER_EXPR\n       /* Reject out-of-bound accesses (PR79731).  */\n       || (! AGGREGATE_TYPE_P (TREE_TYPE (inner))\n@@ -7819,7 +7832,7 @@ fold_unary_loc (location_t loc, enum tree_code code, tree type, tree op0)\n \t  && POINTER_TYPE_P (type)\n \t  && handled_component_p (TREE_OPERAND (op0, 0)))\n         {\n-\t  HOST_WIDE_INT bitsize, bitpos;\n+\t  poly_int64 bitsize, bitpos;\n \t  tree offset;\n \t  machine_mode mode;\n \t  int unsignedp, reversep, volatilep;\n@@ -7830,7 +7843,8 @@ fold_unary_loc (location_t loc, enum tree_code code, tree type, tree op0)\n \t  /* If the reference was to a (constant) zero offset, we can use\n \t     the address of the base if it has the same base type\n \t     as the result type and the pointer type is unqualified.  */\n-\t  if (! offset && bitpos == 0\n+\t  if (!offset\n+\t      && known_eq (bitpos, 0)\n \t      && (TYPE_MAIN_VARIANT (TREE_TYPE (type))\n \t\t  == TYPE_MAIN_VARIANT (TREE_TYPE (base)))\n \t      && TYPE_QUALS (type) == TYPE_UNQUALIFIED)\n@@ -14351,12 +14365,12 @@ round_down_loc (location_t loc, tree value, int divisor)\n \n static tree\n split_address_to_core_and_offset (tree exp,\n-\t\t\t\t  HOST_WIDE_INT *pbitpos, tree *poffset)\n+\t\t\t\t  poly_int64_pod *pbitpos, tree *poffset)\n {\n   tree core;\n   machine_mode mode;\n   int unsignedp, reversep, volatilep;\n-  HOST_WIDE_INT bitsize;\n+  poly_int64 bitsize;\n   location_t loc = EXPR_LOCATION (exp);\n \n   if (TREE_CODE (exp) == ADDR_EXPR)\n@@ -14372,16 +14386,14 @@ split_address_to_core_and_offset (tree exp,\n       STRIP_NOPS (core);\n       *pbitpos = 0;\n       *poffset = TREE_OPERAND (exp, 1);\n-      if (TREE_CODE (*poffset) == INTEGER_CST)\n+      if (poly_int_tree_p (*poffset))\n \t{\n-\t  offset_int tem = wi::sext (wi::to_offset (*poffset),\n-\t\t\t\t     TYPE_PRECISION (TREE_TYPE (*poffset)));\n+\t  poly_offset_int tem\n+\t    = wi::sext (wi::to_poly_offset (*poffset),\n+\t\t\tTYPE_PRECISION (TREE_TYPE (*poffset)));\n \t  tem <<= LOG2_BITS_PER_UNIT;\n-\t  if (wi::fits_shwi_p (tem))\n-\t    {\n-\t      *pbitpos = tem.to_shwi ();\n-\t      *poffset = NULL_TREE;\n-\t    }\n+\t  if (tem.to_shwi (pbitpos))\n+\t    *poffset = NULL_TREE;\n \t}\n     }\n   else\n@@ -14398,17 +14410,18 @@ split_address_to_core_and_offset (tree exp,\n    otherwise.  If they do, E1 - E2 is stored in *DIFF.  */\n \n bool\n-ptr_difference_const (tree e1, tree e2, HOST_WIDE_INT *diff)\n+ptr_difference_const (tree e1, tree e2, poly_int64_pod *diff)\n {\n   tree core1, core2;\n-  HOST_WIDE_INT bitpos1, bitpos2;\n+  poly_int64 bitpos1, bitpos2;\n   tree toffset1, toffset2, tdiff, type;\n \n   core1 = split_address_to_core_and_offset (e1, &bitpos1, &toffset1);\n   core2 = split_address_to_core_and_offset (e2, &bitpos2, &toffset2);\n \n-  if (bitpos1 % BITS_PER_UNIT != 0\n-      || bitpos2 % BITS_PER_UNIT != 0\n+  poly_int64 bytepos1, bytepos2;\n+  if (!multiple_p (bitpos1, BITS_PER_UNIT, &bytepos1)\n+      || !multiple_p (bitpos2, BITS_PER_UNIT, &bytepos2)\n       || !operand_equal_p (core1, core2, 0))\n     return false;\n \n@@ -14433,7 +14446,7 @@ ptr_difference_const (tree e1, tree e2, HOST_WIDE_INT *diff)\n   else\n     *diff = 0;\n \n-  *diff += (bitpos1 - bitpos2) / BITS_PER_UNIT;\n+  *diff += bytepos1 - bytepos2;\n   return true;\n }\n "}, {"sha": "256dc6ffb350d5c89bae401431c41dac1d60da98", "filename": "gcc/fold-const.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ffold-const.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ffold-const.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffold-const.h?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -122,7 +122,7 @@ extern tree div_if_zero_remainder (const_tree, const_tree);\n extern bool tree_swap_operands_p (const_tree, const_tree);\n extern enum tree_code swap_tree_comparison (enum tree_code);\n \n-extern bool ptr_difference_const (tree, tree, HOST_WIDE_INT *);\n+extern bool ptr_difference_const (tree, tree, poly_int64_pod *);\n extern enum tree_code invert_tree_comparison (enum tree_code, bool);\n \n extern bool tree_unary_nonzero_warnv_p (enum tree_code, tree, tree, bool *);"}, {"sha": "690e1f587084b66657f4dcf94ed384570d8f32e5", "filename": "gcc/gimple-laddress.c", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fgimple-laddress.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fgimple-laddress.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-laddress.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -100,19 +100,19 @@ pass_laddress::execute (function *fun)\n \t  */\n \n \t  tree expr = gimple_assign_rhs1 (stmt);\n-\t  HOST_WIDE_INT bitsize, bitpos;\n+\t  poly_int64 bitsize, bitpos;\n \t  tree base, offset;\n \t  machine_mode mode;\n \t  int volatilep = 0, reversep, unsignedp = 0;\n \t  base = get_inner_reference (TREE_OPERAND (expr, 0), &bitsize,\n \t\t\t\t      &bitpos, &offset, &mode, &unsignedp,\n \t\t\t\t      &reversep, &volatilep);\n-\t  gcc_assert (base != NULL_TREE && (bitpos % BITS_PER_UNIT) == 0);\n+\t  gcc_assert (base != NULL_TREE);\n+\t  poly_int64 bytepos = exact_div (bitpos, BITS_PER_UNIT);\n \t  if (offset != NULL_TREE)\n \t    {\n-\t      if (bitpos != 0)\n-\t\toffset = size_binop (PLUS_EXPR, offset,\n-\t\t\t\t     size_int (bitpos / BITS_PER_UNIT));\n+\t      if (maybe_ne (bytepos, 0))\n+\t\toffset = size_binop (PLUS_EXPR, offset, size_int (bytepos));\n \t      offset = force_gimple_operand_gsi (&gsi, offset, true, NULL,\n \t\t\t\t\t\t true, GSI_SAME_STMT);\n \t      base = build_fold_addr_expr (base);"}, {"sha": "dddafb7bf2739bbfd53d5ea7f76ceb1e1d53fd33", "filename": "gcc/gimple-ssa-store-merging.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fgimple-ssa-store-merging.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fgimple-ssa-store-merging.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-ssa-store-merging.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -354,7 +354,7 @@ find_bswap_or_nop_load (gimple *stmt, tree ref, struct symbolic_number *n)\n {\n   /* Leaf node is an array or component ref. Memorize its base and\n      offset from base to compare to other such leaf node.  */\n-  HOST_WIDE_INT bitsize, bitpos;\n+  poly_int64 bitsize, bitpos, bytepos;\n   machine_mode mode;\n   int unsignedp, reversep, volatilep;\n   tree offset, base_addr;\n@@ -407,9 +407,9 @@ find_bswap_or_nop_load (gimple *stmt, tree ref, struct symbolic_number *n)\n   else\n     base_addr = build_fold_addr_expr (base_addr);\n \n-  if (bitpos % BITS_PER_UNIT)\n+  if (!multiple_p (bitpos, BITS_PER_UNIT, &bytepos))\n     return false;\n-  if (bitsize % BITS_PER_UNIT)\n+  if (!multiple_p (bitsize, BITS_PER_UNIT))\n     return false;\n   if (reversep)\n     return false;\n@@ -418,7 +418,7 @@ find_bswap_or_nop_load (gimple *stmt, tree ref, struct symbolic_number *n)\n     return false;\n   n->base_addr = base_addr;\n   n->offset = offset;\n-  n->bytepos = bitpos / BITS_PER_UNIT;\n+  n->bytepos = bytepos;\n   n->alias_set = reference_alias_ptr_type (ref);\n   n->vuse = gimple_vuse (stmt);\n   return true;"}, {"sha": "7d8543c28ca9ca13737137b409fc5781fb2165cf", "filename": "gcc/gimple-ssa-strength-reduction.c", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fgimple-ssa-strength-reduction.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fgimple-ssa-strength-reduction.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimple-ssa-strength-reduction.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -1031,7 +1031,7 @@ static void\n slsr_process_ref (gimple *gs)\n {\n   tree ref_expr, base, offset, type;\n-  HOST_WIDE_INT bitsize, bitpos;\n+  poly_int64 bitsize, bitpos;\n   machine_mode mode;\n   int unsignedp, reversep, volatilep;\n   slsr_cand_t c;\n@@ -1049,9 +1049,10 @@ slsr_process_ref (gimple *gs)\n \n   base = get_inner_reference (ref_expr, &bitsize, &bitpos, &offset, &mode,\n \t\t\t      &unsignedp, &reversep, &volatilep);\n-  if (reversep)\n+  HOST_WIDE_INT cbitpos;\n+  if (reversep || !bitpos.is_constant (&cbitpos))\n     return;\n-  widest_int index = bitpos;\n+  widest_int index = cbitpos;\n \n   if (!restructure_reference (&base, &offset, &index, &type))\n     return;"}, {"sha": "eb4ad967d0d7b6b362a5d74a2e556050e01d37ae", "filename": "gcc/gimplify.c", "status": "modified", "additions": 13, "deletions": 13, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fgimplify.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fgimplify.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimplify.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -7972,7 +7972,7 @@ gimplify_scan_omp_clauses (tree *list_p, gimple_seq *pre_p,\n \t\t    }\n \n \t\t  tree offset;\n-\t\t  HOST_WIDE_INT bitsize, bitpos;\n+\t\t  poly_int64 bitsize, bitpos;\n \t\t  machine_mode mode;\n \t\t  int unsignedp, reversep, volatilep = 0;\n \t\t  tree base = OMP_CLAUSE_DECL (c);\n@@ -7993,7 +7993,7 @@ gimplify_scan_omp_clauses (tree *list_p, gimple_seq *pre_p,\n \t\t    base = TREE_OPERAND (base, 0);\n \t\t  gcc_assert (base == decl\n \t\t\t      && (offset == NULL_TREE\n-\t\t\t\t  || TREE_CODE (offset) == INTEGER_CST));\n+\t\t\t\t  || poly_int_tree_p (offset)));\n \n \t\t  splay_tree_node n\n \t\t    = splay_tree_lookup (ctx->variables, (splay_tree_key)decl);\n@@ -8072,13 +8072,13 @@ gimplify_scan_omp_clauses (tree *list_p, gimple_seq *pre_p,\n \t\t      tree *sc = NULL, *scp = NULL;\n \t\t      if (GOMP_MAP_ALWAYS_P (OMP_CLAUSE_MAP_KIND (c)) || ptr)\n \t\t\tn->value |= GOVD_SEEN;\n-\t\t      offset_int o1, o2;\n+\t\t      poly_offset_int o1, o2;\n \t\t      if (offset)\n-\t\t\to1 = wi::to_offset (offset);\n+\t\t\to1 = wi::to_poly_offset (offset);\n \t\t      else\n \t\t\to1 = 0;\n-\t\t      if (bitpos)\n-\t\t\to1 = o1 + bitpos / BITS_PER_UNIT;\n+\t\t      if (maybe_ne (bitpos, 0))\n+\t\t\to1 += bits_to_bytes_round_down (bitpos);\n \t\t      sc = &OMP_CLAUSE_CHAIN (*osc);\n \t\t      if (*sc != c\n \t\t\t  && (OMP_CLAUSE_MAP_KIND (*sc)\n@@ -8097,7 +8097,7 @@ gimplify_scan_omp_clauses (tree *list_p, gimple_seq *pre_p,\n \t\t\telse\n \t\t\t  {\n \t\t\t    tree offset2;\n-\t\t\t    HOST_WIDE_INT bitsize2, bitpos2;\n+\t\t\t    poly_int64 bitsize2, bitpos2;\n \t\t\t    base = OMP_CLAUSE_DECL (*sc);\n \t\t\t    if (TREE_CODE (base) == ARRAY_REF)\n \t\t\t      {\n@@ -8133,7 +8133,7 @@ gimplify_scan_omp_clauses (tree *list_p, gimple_seq *pre_p,\n \t\t\t    if (scp)\n \t\t\t      continue;\n \t\t\t    gcc_assert (offset == NULL_TREE\n-\t\t\t\t\t|| TREE_CODE (offset) == INTEGER_CST);\n+\t\t\t\t\t|| poly_int_tree_p (offset));\n \t\t\t    tree d1 = OMP_CLAUSE_DECL (*sc);\n \t\t\t    tree d2 = OMP_CLAUSE_DECL (c);\n \t\t\t    while (TREE_CODE (d1) == ARRAY_REF)\n@@ -8163,13 +8163,13 @@ gimplify_scan_omp_clauses (tree *list_p, gimple_seq *pre_p,\n \t\t\t\tbreak;\n \t\t\t      }\n \t\t\t    if (offset2)\n-\t\t\t      o2 = wi::to_offset (offset2);\n+\t\t\t      o2 = wi::to_poly_offset (offset2);\n \t\t\t    else\n \t\t\t      o2 = 0;\n-\t\t\t    if (bitpos2)\n-\t\t\t      o2 = o2 + bitpos2 / BITS_PER_UNIT;\n-\t\t\t    if (wi::ltu_p (o1, o2)\n-\t\t\t\t|| (wi::eq_p (o1, o2) && bitpos < bitpos2))\n+\t\t\t    o2 += bits_to_bytes_round_down (bitpos2);\n+\t\t\t    if (maybe_lt (o1, o2)\n+\t\t\t\t|| (known_eq (o1, 2)\n+\t\t\t\t    && maybe_lt (bitpos, bitpos2)))\n \t\t\t      {\n \t\t\t\tif (ptr)\n \t\t\t\t  scp = sc;"}, {"sha": "9284a3cceba2c91cae8e831d346b305763948234", "filename": "gcc/hsa-gen.c", "status": "modified", "additions": 16, "deletions": 6, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fhsa-gen.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fhsa-gen.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhsa-gen.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -1972,12 +1972,22 @@ gen_hsa_addr (tree ref, hsa_bb *hbb, HOST_WIDE_INT *output_bitsize = NULL,\n     {\n       machine_mode mode;\n       int unsignedp, volatilep, preversep;\n-\n-      ref = get_inner_reference (ref, &bitsize, &bitpos, &varoffset, &mode,\n-\t\t\t\t &unsignedp, &preversep, &volatilep);\n-\n-      offset = bitpos;\n-      offset = wi::rshift (offset, LOG2_BITS_PER_UNIT, SIGNED);\n+      poly_int64 pbitsize, pbitpos;\n+      tree new_ref;\n+\n+      new_ref = get_inner_reference (ref, &pbitsize, &pbitpos, &varoffset,\n+\t\t\t\t     &mode, &unsignedp, &preversep,\n+\t\t\t\t     &volatilep);\n+      /* When this isn't true, the switch below will report an\n+\t appropriate error.  */\n+      if (pbitsize.is_constant () && pbitpos.is_constant ())\n+\t{\n+\t  bitsize = pbitsize.to_constant ();\n+\t  bitpos = pbitpos.to_constant ();\n+\t  ref = new_ref;\n+\t  offset = bitpos;\n+\t  offset = wi::rshift (offset, LOG2_BITS_PER_UNIT, SIGNED);\n+\t}\n     }\n \n   switch (TREE_CODE (ref))"}, {"sha": "ec99250f1c5ca403814006792c0754f378b534cb", "filename": "gcc/match.pd", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fmatch.pd", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fmatch.pd", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fmatch.pd?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -1561,27 +1561,27 @@ DEFINE_INT_AND_FLOAT_ROUND_FN (RINT)\n (simplify\n  (minus (convert ADDR_EXPR@0) (convert @1))\n  (if (tree_nop_conversion_p (type, TREE_TYPE (@0)))\n-  (with { HOST_WIDE_INT diff; }\n+  (with { poly_int64 diff; }\n    (if (ptr_difference_const (@0, @1, &diff))\n     { build_int_cst_type (type, diff); }))))\n (simplify\n  (minus (convert @0) (convert ADDR_EXPR@1))\n  (if (tree_nop_conversion_p (type, TREE_TYPE (@0)))\n-  (with { HOST_WIDE_INT diff; }\n+  (with { poly_int64 diff; }\n    (if (ptr_difference_const (@0, @1, &diff))\n     { build_int_cst_type (type, diff); }))))\n (simplify\n  (pointer_diff (convert?@2 ADDR_EXPR@0) (convert?@3 @1))\n  (if (tree_nop_conversion_p (TREE_TYPE(@2), TREE_TYPE (@0))\n       && tree_nop_conversion_p (TREE_TYPE(@3), TREE_TYPE (@1)))\n-  (with { HOST_WIDE_INT diff; }\n+  (with { poly_int64 diff; }\n    (if (ptr_difference_const (@0, @1, &diff))\n     { build_int_cst_type (type, diff); }))))\n (simplify\n  (pointer_diff (convert?@2 @0) (convert?@3 ADDR_EXPR@1))\n  (if (tree_nop_conversion_p (TREE_TYPE(@2), TREE_TYPE (@0))\n       && tree_nop_conversion_p (TREE_TYPE(@3), TREE_TYPE (@1)))\n-  (with { HOST_WIDE_INT diff; }\n+  (with { poly_int64 diff; }\n    (if (ptr_difference_const (@0, @1, &diff))\n     { build_int_cst_type (type, diff); }))))\n "}, {"sha": "d726c5e65e9efa24b54f214d03c533b1aac927dc", "filename": "gcc/sanopt.c", "status": "modified", "additions": 6, "deletions": 3, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fsanopt.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fsanopt.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsanopt.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -459,7 +459,7 @@ record_ubsan_ptr_check_stmt (sanopt_ctx *ctx, gimple *stmt, tree ptr,\n static bool\n maybe_optimize_ubsan_ptr_ifn (sanopt_ctx *ctx, gimple *stmt)\n {\n-  HOST_WIDE_INT bitsize, bitpos;\n+  poly_int64 bitsize, pbitpos;\n   machine_mode mode;\n   int volatilep = 0, reversep, unsignedp = 0;\n   tree offset;\n@@ -483,9 +483,12 @@ maybe_optimize_ubsan_ptr_ifn (sanopt_ctx *ctx, gimple *stmt)\n     {\n       base = TREE_OPERAND (base, 0);\n \n-      base = get_inner_reference (base, &bitsize, &bitpos, &offset, &mode,\n+      HOST_WIDE_INT bitpos;\n+      base = get_inner_reference (base, &bitsize, &pbitpos, &offset, &mode,\n \t\t\t\t  &unsignedp, &reversep, &volatilep);\n-      if (offset == NULL_TREE && DECL_P (base))\n+      if (offset == NULL_TREE\n+\t  && DECL_P (base)\n+\t  && pbitpos.is_constant (&bitpos))\n \t{\n \t  gcc_assert (!DECL_REGISTER (base));\n \t  offset_int expr_offset = bitpos / BITS_PER_UNIT;"}, {"sha": "35c98fb883f0b250c53e75d2e06038ac73d359c5", "filename": "gcc/simplify-rtx.c", "status": "modified", "additions": 5, "deletions": 9, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fsimplify-rtx.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fsimplify-rtx.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsimplify-rtx.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -308,23 +308,19 @@ delegitimize_mem_from_attrs (rtx x)\n \tcase IMAGPART_EXPR:\n \tcase VIEW_CONVERT_EXPR:\n \t  {\n-\t    HOST_WIDE_INT bitsize, bitpos;\n+\t    poly_int64 bitsize, bitpos, bytepos, toffset_val = 0;\n \t    tree toffset;\n \t    int unsignedp, reversep, volatilep = 0;\n \n \t    decl\n \t      = get_inner_reference (decl, &bitsize, &bitpos, &toffset, &mode,\n \t\t\t\t     &unsignedp, &reversep, &volatilep);\n-\t    if (bitsize != GET_MODE_BITSIZE (mode)\n-\t\t|| (bitpos % BITS_PER_UNIT)\n-\t\t|| (toffset && !tree_fits_shwi_p (toffset)))\n+\t    if (maybe_ne (bitsize, GET_MODE_BITSIZE (mode))\n+\t\t|| !multiple_p (bitpos, BITS_PER_UNIT, &bytepos)\n+\t\t|| (toffset && !poly_int_tree_p (toffset, &toffset_val)))\n \t      decl = NULL;\n \t    else\n-\t      {\n-\t\toffset += bitpos / BITS_PER_UNIT;\n-\t\tif (toffset)\n-\t\t  offset += tree_to_shwi (toffset);\n-\t      }\n+\t      offset += bytepos + toffset_val;\n \t    break;\n \t  }\n \t}"}, {"sha": "e3d461e69124cdfe26a4c843cbdd65da715d5007", "filename": "gcc/tree-affine.c", "status": "modified", "additions": 8, "deletions": 7, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ftree-affine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ftree-affine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-affine.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -267,7 +267,7 @@ tree_to_aff_combination (tree expr, tree type, aff_tree *comb)\n   aff_tree tmp;\n   enum tree_code code;\n   tree cst, core, toffset;\n-  HOST_WIDE_INT bitpos, bitsize;\n+  poly_int64 bitpos, bitsize, bytepos;\n   machine_mode mode;\n   int unsignedp, reversep, volatilep;\n \n@@ -324,12 +324,13 @@ tree_to_aff_combination (tree expr, tree type, aff_tree *comb)\n       core = get_inner_reference (TREE_OPERAND (expr, 0), &bitsize, &bitpos,\n \t\t\t\t  &toffset, &mode, &unsignedp, &reversep,\n \t\t\t\t  &volatilep);\n-      if (bitpos % BITS_PER_UNIT != 0)\n+      if (!multiple_p (bitpos, BITS_PER_UNIT, &bytepos))\n \tbreak;\n-      aff_combination_const (comb, type, bitpos / BITS_PER_UNIT);\n+      aff_combination_const (comb, type, bytepos);\n       if (TREE_CODE (core) == MEM_REF)\n \t{\n-\t  aff_combination_add_cst (comb, wi::to_widest (TREE_OPERAND (core, 1)));\n+\t  tree mem_offset = TREE_OPERAND (core, 1);\n+\t  aff_combination_add_cst (comb, wi::to_poly_widest (mem_offset));\n \t  core = TREE_OPERAND (core, 0);\n \t}\n       else\n@@ -929,7 +930,7 @@ debug_aff (aff_tree *val)\n tree\n get_inner_reference_aff (tree ref, aff_tree *addr, poly_widest_int *size)\n {\n-  HOST_WIDE_INT bitsize, bitpos;\n+  poly_int64 bitsize, bitpos;\n   tree toff;\n   machine_mode mode;\n   int uns, rev, vol;\n@@ -948,10 +949,10 @@ get_inner_reference_aff (tree ref, aff_tree *addr, poly_widest_int *size)\n       aff_combination_add (addr, &tmp);\n     }\n \n-  aff_combination_const (&tmp, sizetype, bitpos / BITS_PER_UNIT);\n+  aff_combination_const (&tmp, sizetype, bits_to_bytes_round_down (bitpos));\n   aff_combination_add (addr, &tmp);\n \n-  *size = (bitsize + BITS_PER_UNIT - 1) / BITS_PER_UNIT;\n+  *size = bits_to_bytes_round_up (bitsize);\n \n   return base;\n }"}, {"sha": "86a587d04c0559eced40438c1649fa52a7bcd20a", "filename": "gcc/tree-data-ref.c", "status": "modified", "additions": 7, "deletions": 6, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ftree-data-ref.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ftree-data-ref.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-data-ref.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -627,7 +627,7 @@ split_constant_offset_1 (tree type, tree op0, enum tree_code code, tree op1,\n     case ADDR_EXPR:\n       {\n \ttree base, poffset;\n-\tHOST_WIDE_INT pbitsize, pbitpos;\n+\tpoly_int64 pbitsize, pbitpos, pbytepos;\n \tmachine_mode pmode;\n \tint punsignedp, preversep, pvolatilep;\n \n@@ -636,10 +636,10 @@ split_constant_offset_1 (tree type, tree op0, enum tree_code code, tree op1,\n \t  = get_inner_reference (op0, &pbitsize, &pbitpos, &poffset, &pmode,\n \t\t\t\t &punsignedp, &preversep, &pvolatilep);\n \n-\tif (pbitpos % BITS_PER_UNIT != 0)\n+\tif (!multiple_p (pbitpos, BITS_PER_UNIT, &pbytepos))\n \t  return false;\n \tbase = build_fold_addr_expr (base);\n-\toff0 = ssize_int (pbitpos / BITS_PER_UNIT);\n+\toff0 = ssize_int (pbytepos);\n \n \tif (poffset)\n \t  {\n@@ -789,7 +789,7 @@ bool\n dr_analyze_innermost (innermost_loop_behavior *drb, tree ref,\n \t\t      struct loop *loop)\n {\n-  HOST_WIDE_INT pbitsize, pbitpos;\n+  poly_int64 pbitsize, pbitpos;\n   tree base, poffset;\n   machine_mode pmode;\n   int punsignedp, preversep, pvolatilep;\n@@ -804,7 +804,8 @@ dr_analyze_innermost (innermost_loop_behavior *drb, tree ref,\n \t\t\t      &punsignedp, &preversep, &pvolatilep);\n   gcc_assert (base != NULL_TREE);\n \n-  if (pbitpos % BITS_PER_UNIT != 0)\n+  poly_int64 pbytepos;\n+  if (!multiple_p (pbitpos, BITS_PER_UNIT, &pbytepos))\n     {\n       if (dump_file && (dump_flags & TDF_DETAILS))\n \tfprintf (dump_file, \"failed: bit offset alignment.\\n\");\n@@ -885,7 +886,7 @@ dr_analyze_innermost (innermost_loop_behavior *drb, tree ref,\n         }\n     }\n \n-  init = ssize_int (pbitpos / BITS_PER_UNIT);\n+  init = ssize_int (pbytepos);\n \n   /* Subtract any constant component from the base and add it to INIT instead.\n      Adjust the misalignment to reflect the amount we subtracted.  */"}, {"sha": "7ee70fa5dc5be11d6d911afdbed2b96b1c930e1d", "filename": "gcc/tree-scalar-evolution.c", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ftree-scalar-evolution.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ftree-scalar-evolution.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-scalar-evolution.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -1731,7 +1731,7 @@ interpret_rhs_expr (struct loop *loop, gimple *at_stmt,\n \t  || handled_component_p (TREE_OPERAND (rhs1, 0)))\n         {\n \t  machine_mode mode;\n-\t  HOST_WIDE_INT bitsize, bitpos;\n+\t  poly_int64 bitsize, bitpos;\n \t  int unsignedp, reversep;\n \t  int volatilep = 0;\n \t  tree base, offset;\n@@ -1770,11 +1770,9 @@ interpret_rhs_expr (struct loop *loop, gimple *at_stmt,\n \t      res = chrec_fold_plus (type, res, chrec2);\n \t    }\n \n-\t  if (bitpos != 0)\n+\t  if (maybe_ne (bitpos, 0))\n \t    {\n-\t      gcc_assert ((bitpos % BITS_PER_UNIT) == 0);\n-\n-\t      unitpos = size_int (bitpos / BITS_PER_UNIT);\n+\t      unitpos = size_int (exact_div (bitpos, BITS_PER_UNIT));\n \t      chrec3 = analyze_scalar_evolution (loop, unitpos);\n \t      chrec3 = chrec_convert (TREE_TYPE (unitpos), chrec3, at_stmt);\n \t      chrec3 = instantiate_parameters (loop, chrec3);"}, {"sha": "93de0442a807b51df289db2fcf9db5591da4240a", "filename": "gcc/tree-sra.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ftree-sra.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ftree-sra.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-sra.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -5399,12 +5399,12 @@ ipa_sra_check_caller (struct cgraph_node *node, void *data)\n \t      continue;\n \n \t  tree offset;\n-\t  HOST_WIDE_INT bitsize, bitpos;\n+\t  poly_int64 bitsize, bitpos;\n \t  machine_mode mode;\n \t  int unsignedp, reversep, volatilep = 0;\n \t  get_inner_reference (arg, &bitsize, &bitpos, &offset, &mode,\n \t\t\t       &unsignedp, &reversep, &volatilep);\n-\t  if (bitpos % BITS_PER_UNIT)\n+\t  if (!multiple_p (bitpos, BITS_PER_UNIT))\n \t    {\n \t      iscc->bad_arg_alignment = true;\n \t      return true;"}, {"sha": "9867077cd86a002c8eb262fe52073bda6b42eeda", "filename": "gcc/tree-vect-data-refs.c", "status": "modified", "additions": 6, "deletions": 4, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ftree-vect-data-refs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ftree-vect-data-refs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-data-refs.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -3226,7 +3226,8 @@ bool\n vect_check_gather_scatter (gimple *stmt, loop_vec_info loop_vinfo,\n \t\t\t   gather_scatter_info *info)\n {\n-  HOST_WIDE_INT scale = 1, pbitpos, pbitsize;\n+  HOST_WIDE_INT scale = 1;\n+  poly_int64 pbitpos, pbitsize;\n   struct loop *loop = LOOP_VINFO_LOOP (loop_vinfo);\n   stmt_vec_info stmt_info = vinfo_for_stmt (stmt);\n   struct data_reference *dr = STMT_VINFO_DATA_REF (stmt_info);\n@@ -3267,7 +3268,8 @@ vect_check_gather_scatter (gimple *stmt, loop_vec_info loop_vinfo,\n      that can be gimplified before the loop.  */\n   base = get_inner_reference (base, &pbitsize, &pbitpos, &off, &pmode,\n \t\t\t      &punsignedp, &reversep, &pvolatilep);\n-  gcc_assert (base && (pbitpos % BITS_PER_UNIT) == 0 && !reversep);\n+  gcc_assert (base && !reversep);\n+  poly_int64 pbytepos = exact_div (pbitpos, BITS_PER_UNIT);\n \n   if (TREE_CODE (base) == MEM_REF)\n     {\n@@ -3300,14 +3302,14 @@ vect_check_gather_scatter (gimple *stmt, loop_vec_info loop_vinfo,\n       if (!integer_zerop (off))\n \treturn false;\n       off = base;\n-      base = size_int (pbitpos / BITS_PER_UNIT);\n+      base = size_int (pbytepos);\n     }\n   /* Otherwise put base + constant offset into the loop invariant BASE\n      and continue with OFF.  */\n   else\n     {\n       base = fold_convert (sizetype, base);\n-      base = size_binop (PLUS_EXPR, base, size_int (pbitpos / BITS_PER_UNIT));\n+      base = size_binop (PLUS_EXPR, base, size_int (pbytepos));\n     }\n \n   /* OFF at this point may be either a SSA_NAME or some tree expression"}, {"sha": "5ac1f2594f072915942b39f670e96607c1df7a24", "filename": "gcc/tree.h", "status": "modified", "additions": 1, "deletions": 12, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ftree.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ftree.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.h?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -5636,19 +5636,8 @@ extern bool complete_ctor_at_level_p (const_tree, HOST_WIDE_INT, const_tree);\n /* Given an expression EXP that is a handled_component_p,\n    look for the ultimate containing object, which is returned and specify\n    the access position and size.  */\n-extern tree get_inner_reference (tree, HOST_WIDE_INT *, HOST_WIDE_INT *,\n+extern tree get_inner_reference (tree, poly_int64_pod *, poly_int64_pod *,\n \t\t\t\t tree *, machine_mode *, int *, int *, int *);\n-/* Temporary.  */\n-inline tree\n-get_inner_reference (tree exp, poly_int64_pod *pbitsize,\n-\t\t     poly_int64_pod *pbitpos, tree *poffset,\n-\t\t     machine_mode *pmode, int *punsignedp,\n-\t\t     int *preversep, int *pvolatilep)\n-{\n-  return get_inner_reference (exp, &pbitsize->coeffs[0], &pbitpos->coeffs[0],\n-\t\t\t      poffset, pmode, punsignedp, preversep,\n-\t\t\t      pvolatilep);\n-}\n \n extern tree build_personality_function (const char *);\n "}, {"sha": "538d315b11f62d2855cdfbb021d72b83b5ec85e8", "filename": "gcc/tsan.c", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ftsan.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Ftsan.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftsan.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -110,12 +110,12 @@ instrument_expr (gimple_stmt_iterator gsi, tree expr, bool is_write)\n   if (size <= 0)\n     return false;\n \n-  HOST_WIDE_INT bitsize, bitpos;\n+  poly_int64 unused_bitsize, unused_bitpos;\n   tree offset;\n   machine_mode mode;\n   int unsignedp, reversep, volatilep = 0;\n-  base = get_inner_reference (expr, &bitsize, &bitpos, &offset, &mode,\n-\t\t\t      &unsignedp, &reversep, &volatilep);\n+  base = get_inner_reference (expr, &unused_bitsize, &unused_bitpos, &offset,\n+\t\t\t      &mode, &unsignedp, &reversep, &volatilep);\n \n   /* No need to instrument accesses to decls that don't escape,\n      they can't escape to other threads then.  */\n@@ -142,6 +142,7 @@ instrument_expr (gimple_stmt_iterator gsi, tree expr, bool is_write)\n        && DECL_BIT_FIELD_TYPE (TREE_OPERAND (expr, 1)))\n       || TREE_CODE (expr) == BIT_FIELD_REF)\n     {\n+      HOST_WIDE_INT bitpos, bitsize;\n       base = TREE_OPERAND (expr, 0);\n       if (TREE_CODE (expr) == COMPONENT_REF)\n \t{"}, {"sha": "e89e87bcd2a01091eaebac0afae485f1e18cece9", "filename": "gcc/ubsan.c", "status": "modified", "additions": 14, "deletions": 14, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fubsan.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca/gcc%2Fubsan.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fubsan.c?ref=f37fac2b74df114c5b3e9c8a3be2cad9acd3f4ca", "patch": "@@ -1425,7 +1425,7 @@ maybe_instrument_pointer_overflow (gimple_stmt_iterator *gsi, tree t)\n   if (!handled_component_p (t) && TREE_CODE (t) != MEM_REF)\n     return;\n \n-  HOST_WIDE_INT bitsize, bitpos, bytepos;\n+  poly_int64 bitsize, bitpos, bytepos;\n   tree offset;\n   machine_mode mode;\n   int volatilep = 0, reversep, unsignedp = 0;\n@@ -1443,14 +1443,14 @@ maybe_instrument_pointer_overflow (gimple_stmt_iterator *gsi, tree t)\n       /* If BASE is a fixed size automatic variable or\n \t global variable defined in the current TU and bitpos\n \t fits, don't instrument anything.  */\n+      poly_int64 base_size;\n       if (offset == NULL_TREE\n-\t  && bitpos > 0\n+\t  && maybe_ne (bitpos, 0)\n \t  && (VAR_P (base)\n \t      || TREE_CODE (base) == PARM_DECL\n \t      || TREE_CODE (base) == RESULT_DECL)\n-\t  && DECL_SIZE (base)\n-\t  && TREE_CODE (DECL_SIZE (base)) == INTEGER_CST\n-\t  && compare_tree_int (DECL_SIZE (base), bitpos) >= 0\n+\t  && poly_int_tree_p (DECL_SIZE (base), &base_size)\n+\t  && known_ge (base_size, bitpos)\n \t  && (!is_global_var (base) || decl_binds_to_current_def_p (base)))\n \treturn;\n     }\n@@ -1471,16 +1471,16 @@ maybe_instrument_pointer_overflow (gimple_stmt_iterator *gsi, tree t)\n \n   if (!POINTER_TYPE_P (TREE_TYPE (base)) && !DECL_P (base))\n     return;\n-  bytepos = bitpos / BITS_PER_UNIT;\n-  if (offset == NULL_TREE && bytepos == 0 && moff == NULL_TREE)\n+  bytepos = bits_to_bytes_round_down (bitpos);\n+  if (offset == NULL_TREE && known_eq (bytepos, 0) && moff == NULL_TREE)\n     return;\n \n   tree base_addr = base;\n   if (decl_p)\n     base_addr = build1 (ADDR_EXPR,\n \t\t\tbuild_pointer_type (TREE_TYPE (base)), base);\n   t = offset;\n-  if (bytepos)\n+  if (maybe_ne (bytepos, 0))\n     {\n       if (t)\n \tt = fold_build2 (PLUS_EXPR, TREE_TYPE (t), t,\n@@ -1663,7 +1663,7 @@ instrument_bool_enum_load (gimple_stmt_iterator *gsi)\n     return;\n \n   int modebitsize = GET_MODE_BITSIZE (SCALAR_INT_TYPE_MODE (type));\n-  HOST_WIDE_INT bitsize, bitpos;\n+  poly_int64 bitsize, bitpos;\n   tree offset;\n   machine_mode mode;\n   int volatilep = 0, reversep, unsignedp = 0;\n@@ -1672,8 +1672,8 @@ instrument_bool_enum_load (gimple_stmt_iterator *gsi)\n   tree utype = build_nonstandard_integer_type (modebitsize, 1);\n \n   if ((VAR_P (base) && DECL_HARD_REGISTER (base))\n-      || (bitpos % modebitsize) != 0\n-      || bitsize != modebitsize\n+      || !multiple_p (bitpos, modebitsize)\n+      || maybe_ne (bitsize, modebitsize)\n       || GET_MODE_BITSIZE (SCALAR_INT_TYPE_MODE (utype)) != modebitsize\n       || TREE_CODE (gimple_assign_lhs (stmt)) != SSA_NAME)\n     return;\n@@ -2085,15 +2085,15 @@ instrument_object_size (gimple_stmt_iterator *gsi, tree t, bool is_lhs)\n   if (size_in_bytes <= 0)\n     return;\n \n-  HOST_WIDE_INT bitsize, bitpos;\n+  poly_int64 bitsize, bitpos;\n   tree offset;\n   machine_mode mode;\n   int volatilep = 0, reversep, unsignedp = 0;\n   tree inner = get_inner_reference (t, &bitsize, &bitpos, &offset, &mode,\n \t\t\t\t    &unsignedp, &reversep, &volatilep);\n \n-  if (bitpos % BITS_PER_UNIT != 0\n-      || bitsize != size_in_bytes * BITS_PER_UNIT)\n+  if (!multiple_p (bitpos, BITS_PER_UNIT)\n+      || maybe_ne (bitsize, size_in_bytes * BITS_PER_UNIT))\n     return;\n \n   bool decl_p = DECL_P (inner);"}]}