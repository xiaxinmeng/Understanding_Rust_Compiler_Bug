{"sha": "1a83e602a157b844ed98d0dab832c1240ed6bf4b", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MWE4M2U2MDJhMTU3Yjg0NGVkOThkMGRhYjgzMmMxMjQwZWQ2YmY0Yg==", "commit": {"author": {"name": "Bernd Schmidt", "email": "bernds@codesourcery.com", "date": "2012-09-19T19:37:31Z"}, "committer": {"name": "Bernd Schmidt", "email": "bernds@gcc.gnu.org", "date": "2012-09-19T19:37:31Z"}, "message": "dbgcnt.def (sched_breakdep): New counter.\n\n\t* dbgcnt.def (sched_breakdep): New counter.\n\t* haifa-sched.c (update_insn_after_change): New static function,\n\tbroken out of haifa_change_pattern.\n\t(haifa_change_pattern): Call it.\n\t(dep_t heap vecs): Declare.\n\t(INSN_COST): Define earlier.\n\t(next_cycle_replace_deps, next_cycle_apply): New static\n\tvariables.\n\t(apply_replacement): New static function.\n\t(recompute_todo_spec): New argument FOR_BACKTRACK.  All callers\n\tchanged.  Handle DEP_REPLACE deps.\n\t(contributes_to_priority_p): False for replaceable deps.\n\t(must_restore_pattern_p, restore_pattern): New static functions.\n\t(schedule_insn): Use them.  Apply replacements for broken deps.\n\t(struct haifa_saved_data): Add new fields to keep track of\n\treplacements.\n\t(save_backtrack_point): Initialize them.\n\t(undo_replacements_for_backtrack): New static function.\n\t(restore_last_backtrack_point, free_topmost_backtrack_point):\n\tUse it and keep track of replacements.\n\t(perform_replacements_new_cycle, undo_all_replacements): New static\n\tfunctions.\n\t(schedule_block): Call these two as necessary.  Call\n\tfind_modifiable_mems.\n\t(try_ready): Tweak the assert.  Check for DEP_POSTPONED.\n\t* sched-deps.c: Include \"emit-rtl.h\".\n\t(init_dep_1): Initialize DEP_NONREG, DEP_MULTIPLE and DEP_REPLACE.\n\t(dep_spec_p): True for DEP_REPLACE deps.\n\t(mark_as_hard): New static variable.\n\t(update_dep): Update DEP_NONREG and DEP_MULTIPLE.\n\t(add_dependence_list): New argument hard.  All callers changed.  Set\n\tand clear mark_as_hard around function body.\n\t(add_dependence_list_and_free): Likewise.\n\t(haifa_note_mem_dep): Set DEP_NONREG.\n\t(haifa_note_dep): Likewise if mark_as_hard is true.\n\t(sched_analyze_insn): Switch loop with if statement testing for\n\tsel_sched_p.\n\t(struct mem_inc_info): New.\n\t(attempt_change, parse_add_or_inc, find_inc, find_mem): New static\n\tfunctions.\n\t(find_modifiable_mems): New function.\n\t* sched-int.h (struct dep_replacement): New.\n\t(struct _dep): Add replace, nonreg and multiple fields.  Make type and\n\tcost bitfields.\n\t(UNKNOWN_DEP_COST): Change to match the bitfield.\n\t(DEP_NONREG, DEP_MULTIPLE, DEP_REPLACE): New macros.\n\t(DEP_POSTPONED): New macro.\n\t(DEP_CANCELLED): Renumber.\n\t(find_modifiable_mems): Declare.\n\t(enum SCHED_FLAGS): Add DONT_BREAK_DEPENDENCIES.\n\t* sched-rgn.c (init_ready_list): Set TODO_SPEC here.\n\t(new_ready): Don't set HARD_DEP, use DEP_POSTPONED.\n\t(debug_dependencies): Dump DEP_NONREG and DEP_MULTIPLE.\n\t* Makefile.in (sched-deps.o): Update dependencies.\n\t* config/c6x/c6x.c (in_hwloop): New static variable.\n\t(c6x_set_sched_flags): If it is true, add DONT_BREAK_DEPENDENCIES.\n\t(hwloop_optimize): Set and clear it around preliminary scheduling\n\tpass.\n\nFrom-SVN: r191493", "tree": {"sha": "379bbdd61db7200439ea249c13f2b0c2c5b8fefc", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/379bbdd61db7200439ea249c13f2b0c2c5b8fefc"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/1a83e602a157b844ed98d0dab832c1240ed6bf4b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1a83e602a157b844ed98d0dab832c1240ed6bf4b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1a83e602a157b844ed98d0dab832c1240ed6bf4b", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1a83e602a157b844ed98d0dab832c1240ed6bf4b/comments", "author": null, "committer": null, "parents": [{"sha": "7b49d6db24d87f69458eaa3712445741997e80c7", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7b49d6db24d87f69458eaa3712445741997e80c7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/7b49d6db24d87f69458eaa3712445741997e80c7"}], "stats": {"total": 1042, "additions": 902, "deletions": 140}, "files": [{"sha": "4e30ac41566629d8dc43e8aae28fe3a3640387fd", "filename": "gcc/ChangeLog", "status": "modified", "additions": 61, "deletions": 0, "changes": 61, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=1a83e602a157b844ed98d0dab832c1240ed6bf4b", "patch": "@@ -1,3 +1,64 @@\n+2012-09-19  Bernd Schmidt  <bernds@codesourcery.com>\n+\n+\t* dbgcnt.def (sched_breakdep): New counter.\n+\t* haifa-sched.c (update_insn_after_change): New static function,\n+\tbroken out of haifa_change_pattern.\n+\t(haifa_change_pattern): Call it.\n+\t(dep_t heap vecs): Declare.\n+\t(INSN_COST): Define earlier.\n+\t(next_cycle_replace_deps, next_cycle_apply): New static\n+\tvariables.\n+\t(apply_replacement): New static function.\n+\t(recompute_todo_spec): New argument FOR_BACKTRACK.  All callers\n+\tchanged.  Handle DEP_REPLACE deps.\n+\t(contributes_to_priority_p): False for replaceable deps.\n+\t(must_restore_pattern_p, restore_pattern): New static functions.\n+\t(schedule_insn): Use them.  Apply replacements for broken deps.\n+\t(struct haifa_saved_data): Add new fields to keep track of\n+\treplacements.\n+\t(save_backtrack_point): Initialize them.\n+\t(undo_replacements_for_backtrack): New static function.\n+\t(restore_last_backtrack_point, free_topmost_backtrack_point):\n+\tUse it and keep track of replacements.\n+\t(perform_replacements_new_cycle, undo_all_replacements): New static\n+\tfunctions.\n+\t(schedule_block): Call these two as necessary.  Call\n+\tfind_modifiable_mems.\n+\t(try_ready): Tweak the assert.  Check for DEP_POSTPONED.\n+\t* sched-deps.c: Include \"emit-rtl.h\".\n+\t(init_dep_1): Initialize DEP_NONREG, DEP_MULTIPLE and DEP_REPLACE.\n+\t(dep_spec_p): True for DEP_REPLACE deps.\n+\t(mark_as_hard): New static variable.\n+\t(update_dep): Update DEP_NONREG and DEP_MULTIPLE.\n+\t(add_dependence_list): New argument hard.  All callers changed.  Set\n+\tand clear mark_as_hard around function body.\n+\t(add_dependence_list_and_free): Likewise.\n+\t(haifa_note_mem_dep): Set DEP_NONREG.\n+\t(haifa_note_dep): Likewise if mark_as_hard is true.\n+\t(sched_analyze_insn): Switch loop with if statement testing for\n+\tsel_sched_p.\n+\t(struct mem_inc_info): New.\n+\t(attempt_change, parse_add_or_inc, find_inc, find_mem): New static\n+\tfunctions.\n+\t(find_modifiable_mems): New function.\n+\t* sched-int.h (struct dep_replacement): New.\n+\t(struct _dep): Add replace, nonreg and multiple fields.  Make type and\n+\tcost bitfields.\n+\t(UNKNOWN_DEP_COST): Change to match the bitfield.\n+\t(DEP_NONREG, DEP_MULTIPLE, DEP_REPLACE): New macros.\n+\t(DEP_POSTPONED): New macro.\n+\t(DEP_CANCELLED): Renumber.\n+\t(find_modifiable_mems): Declare.\n+\t(enum SCHED_FLAGS): Add DONT_BREAK_DEPENDENCIES.\n+\t* sched-rgn.c (init_ready_list): Set TODO_SPEC here.\n+\t(new_ready): Don't set HARD_DEP, use DEP_POSTPONED.\n+\t(debug_dependencies): Dump DEP_NONREG and DEP_MULTIPLE.\n+\t* Makefile.in (sched-deps.o): Update dependencies.\n+\t* config/c6x/c6x.c (in_hwloop): New static variable.\n+\t(c6x_set_sched_flags): If it is true, add DONT_BREAK_DEPENDENCIES.\n+\t(hwloop_optimize): Set and clear it around preliminary scheduling\n+\tpass.\n+\n 2012-09-19  Tulio Magno Quites Machado Filho  <tuliom@linux.vnet.ibm.com>\n \n \t* config/rs6000/rs6000-builtin.def: Add __builtin_ppc_get_timebase"}, {"sha": "90a1403bf7238fab15e11aa4c6fa3f216b6a2726", "filename": "gcc/Makefile.in", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FMakefile.in?ref=1a83e602a157b844ed98d0dab832c1240ed6bf4b", "patch": "@@ -3239,7 +3239,7 @@ haifa-sched.o : haifa-sched.c $(CONFIG_H) $(SYSTEM_H) coretypes.h dumpfile.h \\\n sched-deps.o : sched-deps.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \\\n    $(RTL_H) $(SCHED_INT_H) $(REGS_H) hard-reg-set.h $(FLAGS_H) insn-config.h \\\n    $(FUNCTION_H) $(INSN_ATTR_H) $(DIAGNOSTIC_CORE_H) $(RECOG_H) $(EXCEPT_H) cselib.h \\\n-   ira.h $(PARAMS_H) $(TM_P_H) ira.h $(TARGET_H) $(TREE_H)\n+   ira.h $(PARAMS_H) $(TM_P_H) ira.h $(TARGET_H) $(TREE_H) $(EMIT_RTL_H)\n sched-rgn.o : sched-rgn.c $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \\\n    $(RTL_H) $(SCHED_INT_H) $(REGS_H) hard-reg-set.h $(FLAGS_H) insn-config.h \\\n    $(FUNCTION_H) $(INSN_ATTR_H) $(DIAGNOSTIC_CORE_H) $(RECOG_H) $(EXCEPT_H) $(PARAMS_H) \\"}, {"sha": "e89488299a41de760cfb639d4e36622ea9b22280", "filename": "gcc/config/c6x/c6x.c", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2Fconfig%2Fc6x%2Fc6x.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2Fconfig%2Fc6x%2Fc6x.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fc6x%2Fc6x.c?ref=1a83e602a157b844ed98d0dab832c1240ed6bf4b", "patch": "@@ -3912,6 +3912,13 @@ c6x_free_sched_context (void *_sc)\n   free (_sc);\n }\n \n+/* True if we are currently performing a preliminary scheduling\n+   pass before modulo scheduling; we can't allow the scheduler to\n+   modify instruction patterns using packetization assumptions,\n+   since there will be another scheduling pass later if modulo\n+   scheduling fails.  */\n+static bool in_hwloop;\n+\n /* Provide information about speculation capabilities, and set the\n    DO_BACKTRACKING flag.  */\n static void\n@@ -3923,6 +3930,8 @@ c6x_set_sched_flags (spec_info_t spec_info)\n     {\n       *flags |= DO_BACKTRACKING | DO_PREDICATION;\n     }\n+  if (in_hwloop)\n+    *flags |= DONT_BREAK_DEPENDENCIES;\n \n   spec_info->mask = 0;\n }\n@@ -5536,9 +5545,11 @@ hwloop_optimize (hwloop_info loop)\n \n   reshuffle_units (loop->head);\n \n+  in_hwloop = true;\n   schedule_ebbs_init ();\n   schedule_ebb (BB_HEAD (loop->tail), loop->loop_end, true);\n   schedule_ebbs_finish ();\n+  in_hwloop = false;\n \n   bb = loop->head;\n   loop_earliest = bb_earliest_end_cycle (bb, loop->loop_end) + 1;"}, {"sha": "8f67cc3f3b8494dd6807a93c54bccc9045c0e967", "filename": "gcc/dbgcnt.def", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2Fdbgcnt.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2Fdbgcnt.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdbgcnt.def?ref=1a83e602a157b844ed98d0dab832c1240ed6bf4b", "patch": "@@ -176,6 +176,7 @@ DEBUG_COUNTER (sched2_func)\n DEBUG_COUNTER (sched_block)\n DEBUG_COUNTER (sched_func)\n DEBUG_COUNTER (sched_insn)\n+DEBUG_COUNTER (sched_breakdep)\n DEBUG_COUNTER (sched_region)\n DEBUG_COUNTER (sel_sched_cnt)\n DEBUG_COUNTER (sel_sched_region_cnt)"}, {"sha": "d63c4578893a5c6fbaebc9078e3d3a636c3616ae", "filename": "gcc/haifa-sched.c", "status": "modified", "additions": 347, "deletions": 53, "changes": 400, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2Fhaifa-sched.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2Fhaifa-sched.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhaifa-sched.c?ref=1a83e602a157b844ed98d0dab832c1240ed6bf4b", "patch": "@@ -214,6 +214,9 @@ struct common_sched_info_def *common_sched_info;\n #define FEEDS_BACKTRACK_INSN(INSN) (HID (INSN)->feeds_backtrack_insn)\n #define SHADOW_P(INSN) (HID (INSN)->shadow_p)\n #define MUST_RECOMPUTE_SPEC_P(INSN) (HID (INSN)->must_recompute_spec)\n+/* Cached cost of the instruction.  Use insn_cost to get cost of the\n+   insn.  -1 here means that the field is not initialized.  */\n+#define INSN_COST(INSN)\t(HID (INSN)->cost)\n \n /* If INSN_TICK of an instruction is equal to INVALID_TICK,\n    then it should be recalculated from scratch.  */\n@@ -1115,18 +1118,59 @@ cond_clobbered_p (rtx insn, HARD_REG_SET set_regs)\n   return false;\n }\n \n+/* This function should be called after modifying the pattern of INSN,\n+   to update scheduler data structures as needed.  */\n+static void\n+update_insn_after_change (rtx insn)\n+{\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n+\n+  dfa_clear_single_insn_cache (insn);\n+\n+  sd_it = sd_iterator_start (insn,\n+\t\t\t     SD_LIST_FORW | SD_LIST_BACK | SD_LIST_RES_BACK);\n+  while (sd_iterator_cond (&sd_it, &dep))\n+    {\n+      DEP_COST (dep) = UNKNOWN_DEP_COST;\n+      sd_iterator_next (&sd_it);\n+    }\n+\n+  /* Invalidate INSN_COST, so it'll be recalculated.  */\n+  INSN_COST (insn) = -1;\n+  /* Invalidate INSN_TICK, so it'll be recalculated.  */\n+  INSN_TICK (insn) = INVALID_TICK;\n+}\n+\n+DEF_VEC_P(dep_t);\n+DEF_VEC_ALLOC_P(dep_t, heap);\n+\n+/* Two VECs, one to hold dependencies for which pattern replacements\n+   need to be applied or restored at the start of the next cycle, and\n+   another to hold an integer that is either one, to apply the\n+   corresponding replacement, or zero to restore it.  */\n+static VEC(dep_t, heap) *next_cycle_replace_deps;\n+static VEC(int, heap) *next_cycle_apply;\n+\n+static void apply_replacement (dep_t, bool);\n+static void restore_pattern (dep_t, bool);\n+\n /* Look at the remaining dependencies for insn NEXT, and compute and return\n    the TODO_SPEC value we should use for it.  This is called after one of\n-   NEXT's dependencies has been resolved.  */\n+   NEXT's dependencies has been resolved.\n+   We also perform pattern replacements for predication, and for broken\n+   replacement dependencies.  The latter is only done if FOR_BACKTRACK is\n+   false.  */\n \n static ds_t\n-recompute_todo_spec (rtx next)\n+recompute_todo_spec (rtx next, bool for_backtrack)\n {\n   ds_t new_ds;\n   sd_iterator_def sd_it;\n-  dep_t dep, control_dep = NULL;\n+  dep_t dep, modify_dep = NULL;\n   int n_spec = 0;\n   int n_control = 0;\n+  int n_replace = 0;\n   bool first_p = true;\n \n   if (sd_lists_empty_p (next, SD_LIST_BACK))\n@@ -1143,9 +1187,10 @@ recompute_todo_spec (rtx next)\n \n   FOR_EACH_DEP (next, SD_LIST_BACK, sd_it, dep)\n     {\n+      rtx pro = DEP_PRO (dep);\n       ds_t ds = DEP_STATUS (dep) & SPECULATIVE;\n \n-      if (DEBUG_INSN_P (DEP_PRO (dep)) && !DEBUG_INSN_P (next))\n+      if (DEBUG_INSN_P (pro) && !DEBUG_INSN_P (next))\n \tcontinue;\n \n       if (ds)\n@@ -1160,15 +1205,47 @@ recompute_todo_spec (rtx next)\n \t  else\n \t    new_ds = ds_merge (new_ds, ds);\n \t}\n-      if (DEP_TYPE (dep) == REG_DEP_CONTROL)\n+      else if (DEP_TYPE (dep) == REG_DEP_CONTROL)\n \t{\n-\t  n_control++;\n-\t  control_dep = dep;\n+\t  if (QUEUE_INDEX (pro) != QUEUE_SCHEDULED)\n+\t    {\n+\t      n_control++;\n+\t      modify_dep = dep;\n+\t    }\n+\t  DEP_STATUS (dep) &= ~DEP_CANCELLED;\n+\t}\n+      else if (DEP_REPLACE (dep) != NULL)\n+\t{\n+\t  if (QUEUE_INDEX (pro) != QUEUE_SCHEDULED)\n+\t    {\n+\t      n_replace++;\n+\t      modify_dep = dep;\n+\t    }\n \t  DEP_STATUS (dep) &= ~DEP_CANCELLED;\n \t}\n     }\n \n-  if (n_control == 1 && n_spec == 0)\n+  if (n_replace > 0 && n_control == 0 && n_spec == 0)\n+    {\n+      if (!dbg_cnt (sched_breakdep))\n+\treturn HARD_DEP;\n+      FOR_EACH_DEP (next, SD_LIST_BACK, sd_it, dep)\n+\t{\n+\t  struct dep_replacement *desc = DEP_REPLACE (dep);\n+\t  if (desc != NULL)\n+\t    {\n+\t      if (desc->insn == next && !for_backtrack)\n+\t\t{\n+\t\t  gcc_assert (n_replace == 1);\n+\t\t  apply_replacement (dep, true);\n+\t\t}\n+\t      DEP_STATUS (dep) |= DEP_CANCELLED;\n+\t    }\n+\t}\n+      return 0;\n+    }\n+  \n+  else if (n_control == 1 && n_replace == 0 && n_spec == 0)\n     {\n       rtx pro, other, new_pat;\n       rtx cond = NULL_RTX;\n@@ -1182,7 +1259,7 @@ recompute_todo_spec (rtx next)\n \t      && PREDICATED_PAT (next) == NULL_RTX))\n \treturn HARD_DEP;\n \n-      pro = DEP_PRO (control_dep);\n+      pro = DEP_PRO (modify_dep);\n       other = real_insn_for_shadow (pro);\n       if (other != NULL_RTX)\n \tpro = other;\n@@ -1221,7 +1298,7 @@ recompute_todo_spec (rtx next)\n \t\t\t\t\t       PREDICATED_PAT (next));\n \t  gcc_assert (success);\n \t}\n-      DEP_STATUS (control_dep) |= DEP_CANCELLED;\n+      DEP_STATUS (modify_dep) |= DEP_CANCELLED;\n       return DEP_CONTROL;\n     }\n \n@@ -1238,11 +1315,12 @@ recompute_todo_spec (rtx next)\n      dependencies, so we return HARD_DEP in such a case.  Also fail if\n      we have speculative dependencies with not enough points, or more than\n      one control dependency.  */\n-  if ((n_spec > 0 && n_control > 0)\n+  if ((n_spec > 0 && (n_control > 0 || n_replace > 0))\n       || (n_spec > 0\n \t  /* Too few points?  */\n \t  && ds_weak (new_ds) < spec_info->data_weakness_cutoff)\n-      || (n_control > 1))\n+      || n_control > 0\n+      || n_replace > 0)\n     return HARD_DEP;\n \n   return new_ds;\n@@ -1262,10 +1340,6 @@ static rtx last_nondebug_scheduled_insn;\n    first unscheduled one.  */\n static rtx nonscheduled_insns_begin;\n \n-/* Cached cost of the instruction.  Use below function to get cost of the\n-   insn.  -1 here means that the field is not initialized.  */\n-#define INSN_COST(INSN)\t(HID (INSN)->cost)\n-\n /* Compute cost of executing INSN.\n    This is the number of cycles between instruction issue and\n    instruction results.  */\n@@ -1444,6 +1518,9 @@ contributes_to_priority_p (dep_t dep)\n \t\t\t\t\t\t    DEP_PRO (dep)))\n     return false;\n \n+  if (DEP_REPLACE (dep) != NULL)\n+    return false;\n+\n   /* If flag COUNT_SPEC_IN_CRITICAL_PATH is set,\n      then speculative instructions will less likely be\n      scheduled.  That is because the priority of\n@@ -2137,6 +2214,31 @@ model_recompute (rtx insn)\n   if (print_p)\n     fprintf (sched_dump, MODEL_BAR);\n }\n+\n+/* After DEP, which was cancelled, has been resolved for insn NEXT,\n+   check whether the insn's pattern needs restoring.  */\n+static bool\n+must_restore_pattern_p (rtx next, dep_t dep)\n+{\n+  if (QUEUE_INDEX (next) == QUEUE_SCHEDULED)\n+    return false;\n+\n+  if (DEP_TYPE (dep) == REG_DEP_CONTROL)\n+    {\n+      gcc_assert (ORIG_PAT (next) != NULL_RTX);\n+      gcc_assert (next == DEP_CON (dep));\n+    }\n+  else\n+    {\n+      struct dep_replacement *desc = DEP_REPLACE (dep);\n+      if (desc->insn != next)\n+\t{\n+\t  gcc_assert (*desc->loc == desc->orig);\n+\t  return false;\n+\t}\n+    }\n+  return true;\n+}\n \f\n /* model_spill_cost (CL, P, P') returns the cost of increasing the\n    pressure on CL from P to P'.  We use this to calculate a \"base ECC\",\n@@ -3736,7 +3838,20 @@ schedule_insn (rtx insn)\n \n   check_clobbered_conditions (insn);\n \n-  /* Update dependent instructions.  */\n+  /* Update dependent instructions.  First, see if by scheduling this insn\n+     now we broke a dependence in a way that requires us to change another\n+     insn.  */\n+  for (sd_it = sd_iterator_start (insn, SD_LIST_SPEC_BACK);\n+       sd_iterator_cond (&sd_it, &dep); sd_iterator_next (&sd_it))\n+    {\n+      struct dep_replacement *desc = DEP_REPLACE (dep);\n+      rtx pro = DEP_PRO (dep);\n+      if (QUEUE_INDEX (pro) != QUEUE_SCHEDULED\n+\t  && desc != NULL && desc->insn == pro)\n+\tapply_replacement (dep, false);\n+    }\n+\n+  /* Go through and resolve forward dependencies.  */\n   for (sd_it = sd_iterator_start (insn, SD_LIST_FORW);\n        sd_iterator_cond (&sd_it, &dep);)\n     {\n@@ -3750,17 +3865,8 @@ schedule_insn (rtx insn)\n \n       if (cancelled)\n \t{\n-\t  if (QUEUE_INDEX (next) != QUEUE_SCHEDULED)\n-\t    {\n-\t      int tick = INSN_TICK (next);\n-\t      gcc_assert (ORIG_PAT (next) != NULL_RTX);\n-\t      haifa_change_pattern (next, ORIG_PAT (next));\n-\t      INSN_TICK (next) = tick;\n-\t      if (sd_lists_empty_p (next, SD_LIST_BACK))\n-\t\tTODO_SPEC (next) = 0;\n-\t      else if (!sd_lists_empty_p (next, SD_LIST_HARD_BACK))\n-\t\tTODO_SPEC (next) = HARD_DEP;\n-\t    }\n+\t  if (must_restore_pattern_p (next, dep))\n+\t    restore_pattern (dep, false);\n \t  continue;\n \t}\n \n@@ -3918,6 +4024,16 @@ struct haifa_saved_data\n      to 0 when restoring.  */\n   int q_size;\n   rtx *insn_queue;\n+\n+  /* Describe pattern replacements that occurred since this backtrack point\n+     was queued.  */\n+  VEC (dep_t, heap) *replacement_deps;\n+  VEC (int, heap) *replace_apply;\n+\n+  /* A copy of the next-cycle replacement vectors at the time of the backtrack\n+     point.  */\n+  VEC (dep_t, heap) *next_cycle_deps;\n+  VEC (int, heap) *next_cycle_apply;\n };\n \n /* A record, in reverse order, of all scheduled insns which have delay slots\n@@ -3974,6 +4090,11 @@ save_backtrack_point (struct delay_pair *pair,\n \n   save->sched_block = sched_block;\n \n+  save->replacement_deps = NULL;\n+  save->replace_apply = NULL;\n+  save->next_cycle_deps = VEC_copy (dep_t, heap, next_cycle_replace_deps);\n+  save->next_cycle_apply = VEC_copy (int, heap, next_cycle_apply);\n+\n   if (current_sched_info->save_state)\n     save->fe_saved_data = (*current_sched_info->save_state) ();\n \n@@ -4043,6 +4164,25 @@ toggle_cancelled_flags (bool set)\n     }\n }\n \n+/* Undo the replacements that have occurred after backtrack point SAVE\n+   was placed.  */\n+static void\n+undo_replacements_for_backtrack (struct haifa_saved_data *save)\n+{\n+  while (!VEC_empty (dep_t, save->replacement_deps))\n+    {\n+      dep_t dep = VEC_pop (dep_t, save->replacement_deps);\n+      int apply_p = VEC_pop (int, save->replace_apply);\n+\n+      if (apply_p)\n+\trestore_pattern (dep, true);\n+      else\n+\tapply_replacement (dep, true);\n+    }\n+  VEC_free (dep_t, heap, save->replacement_deps);\n+  VEC_free (int, heap, save->replace_apply);\n+}\n+\n /* Pop entries from the SCHEDULED_INSNS vector up to and including INSN.\n    Restore their dependencies to an unresolved state, and mark them as\n    queued nowhere.  */\n@@ -4108,7 +4248,7 @@ unschedule_insns_until (rtx insn)\n \t    haifa_change_pattern (con, ORIG_PAT (con));\n \t}\n       else if (QUEUE_INDEX (con) != QUEUE_SCHEDULED)\n-\tTODO_SPEC (con) = recompute_todo_spec (con);\n+\tTODO_SPEC (con) = recompute_todo_spec (con, true);\n     }\n   VEC_free (rtx, heap, recompute_vec);\n }\n@@ -4136,6 +4276,10 @@ restore_last_backtrack_point (struct sched_block_state *psched_block)\n       targetm.sched.free_sched_context (save->be_saved_data);\n     }\n \n+  /* Do this first since it clobbers INSN_TICK of the involved\n+     instructions.  */\n+  undo_replacements_for_backtrack (save);\n+\n   /* Clear the QUEUE_INDEX of everything in the ready list or one\n      of the queues.  */\n   if (ready.n_ready > 0)\n@@ -4171,7 +4315,7 @@ restore_last_backtrack_point (struct sched_block_state *psched_block)\n \t{\n \t  rtx insn = first[i];\n \t  QUEUE_INDEX (insn) = QUEUE_READY;\n-\t  TODO_SPEC (insn) = recompute_todo_spec (insn);\n+\t  TODO_SPEC (insn) = recompute_todo_spec (insn, true);\n \t  INSN_TICK (insn) = save->clock_var;\n \t}\n     }\n@@ -4188,7 +4332,7 @@ restore_last_backtrack_point (struct sched_block_state *psched_block)\n \t{\n \t  rtx x = XEXP (link, 0);\n \t  QUEUE_INDEX (x) = i;\n-\t  TODO_SPEC (x) = recompute_todo_spec (x);\n+\t  TODO_SPEC (x) = recompute_todo_spec (x, true);\n \t  INSN_TICK (x) = save->clock_var + i;\n \t}\n     }\n@@ -4209,6 +4353,10 @@ restore_last_backtrack_point (struct sched_block_state *psched_block)\n \n   mark_backtrack_feeds (save->delay_pair->i2, 0);\n \n+  gcc_assert (VEC_empty (dep_t, next_cycle_replace_deps));\n+  next_cycle_replace_deps = VEC_copy (dep_t, heap, save->next_cycle_deps);\n+  next_cycle_apply = VEC_copy (int, heap, save->next_cycle_apply);\n+\n   free (save);\n \n   for (save = backtrack_queue; save; save = save->next)\n@@ -4238,7 +4386,14 @@ free_topmost_backtrack_point (bool reset_tick)\n \t  INSN_EXACT_TICK (pair->i2) = INVALID_TICK;\n \t  pair = pair->next_same_i1;\n \t}\n+      undo_replacements_for_backtrack (save);\n+    }\n+  else\n+    {\n+      VEC_free (dep_t, heap, save->replacement_deps);\n+      VEC_free (int, heap, save->replace_apply);\n     }\n+\n   if (targetm.sched.free_sched_context)\n     targetm.sched.free_sched_context (save->be_saved_data);\n   if (current_sched_info->restore_state)\n@@ -4259,6 +4414,124 @@ free_backtrack_queue (void)\n     free_topmost_backtrack_point (false);\n }\n \n+/* Apply a replacement described by DESC.  If IMMEDIATELY is false, we\n+   may have to postpone the replacement until the start of the next cycle,\n+   at which point we will be called again with IMMEDIATELY true.  This is\n+   only done for machines which have instruction packets with explicit\n+   parallelism however.  */\n+static void\n+apply_replacement (dep_t dep, bool immediately)\n+{\n+  struct dep_replacement *desc = DEP_REPLACE (dep);\n+  if (!immediately && targetm.sched.exposed_pipeline && reload_completed)\n+    {\n+      VEC_safe_push (dep_t, heap, next_cycle_replace_deps, dep);\n+      VEC_safe_push (int, heap, next_cycle_apply, 1);\n+    }\n+  else\n+    {\n+      bool success;\n+\n+      if (QUEUE_INDEX (desc->insn) == QUEUE_SCHEDULED)\n+\treturn;\n+\n+      if (sched_verbose >= 5)\n+\tfprintf (sched_dump, \"applying replacement for insn %d\\n\",\n+\t\t INSN_UID (desc->insn));\n+\n+      success = validate_change (desc->insn, desc->loc, desc->newval, 0);\n+      gcc_assert (success);\n+\n+      update_insn_after_change (desc->insn);\n+      if ((TODO_SPEC (desc->insn) & (HARD_DEP | DEP_POSTPONED)) == 0)\n+\tfix_tick_ready (desc->insn);\n+\n+      if (backtrack_queue != NULL)\n+\t{\n+\t  VEC_safe_push (dep_t, heap, backtrack_queue->replacement_deps, dep);\n+\t  VEC_safe_push (int, heap, backtrack_queue->replace_apply, 1);\n+\t}\n+    }\n+}\n+\n+/* We have determined that a pattern involved in DEP must be restored.\n+   If IMMEDIATELY is false, we may have to postpone the replacement\n+   until the start of the next cycle, at which point we will be called\n+   again with IMMEDIATELY true.  */\n+static void\n+restore_pattern (dep_t dep, bool immediately)\n+{\n+  rtx next = DEP_CON (dep);\n+  int tick = INSN_TICK (next);\n+\n+  /* If we already scheduled the insn, the modified version is\n+     correct.  */\n+  if (QUEUE_INDEX (next) == QUEUE_SCHEDULED)\n+    return;\n+\n+  if (!immediately && targetm.sched.exposed_pipeline && reload_completed)\n+    {\n+      VEC_safe_push (dep_t, heap, next_cycle_replace_deps, dep);\n+      VEC_safe_push (int, heap, next_cycle_apply, 0);\n+      return;\n+    }\n+\n+\n+  if (DEP_TYPE (dep) == REG_DEP_CONTROL)\n+    {\n+      if (sched_verbose >= 5)\n+\tfprintf (sched_dump, \"restoring pattern for insn %d\\n\",\n+\t\t INSN_UID (next));\n+      haifa_change_pattern (next, ORIG_PAT (next));\n+    }\n+  else\n+    {\n+      struct dep_replacement *desc = DEP_REPLACE (dep);\n+      bool success;\n+\n+      if (sched_verbose >= 5)\n+\tfprintf (sched_dump, \"restoring pattern for insn %d\\n\",\n+\t\t INSN_UID (desc->insn));\n+      tick = INSN_TICK (desc->insn);\n+\n+      success = validate_change (desc->insn, desc->loc, desc->orig, 0);\n+      gcc_assert (success);\n+      update_insn_after_change (desc->insn);\n+      if (backtrack_queue != NULL)\n+\t{\n+\t  VEC_safe_push (dep_t, heap, backtrack_queue->replacement_deps, dep);\n+\t  VEC_safe_push (int, heap, backtrack_queue->replace_apply, 0);\n+\t}\n+    }\n+  INSN_TICK (next) = tick;\n+  if (TODO_SPEC (next) == DEP_POSTPONED)\n+    return;\n+\n+  if (sd_lists_empty_p (next, SD_LIST_BACK))\n+    TODO_SPEC (next) = 0;\n+  else if (!sd_lists_empty_p (next, SD_LIST_HARD_BACK))\n+    TODO_SPEC (next) = HARD_DEP;\n+}\n+\n+/* Perform pattern replacements that were queued up until the next\n+   cycle.  */\n+static void\n+perform_replacements_new_cycle (void)\n+{\n+  int i;\n+  dep_t dep;\n+  FOR_EACH_VEC_ELT (dep_t, next_cycle_replace_deps, i, dep)\n+    {\n+      int apply_p = VEC_index (int, next_cycle_apply, i);\n+      if (apply_p)\n+\tapply_replacement (dep, true);\n+      else\n+\trestore_pattern (dep, true);\n+    }\n+  VEC_truncate (dep_t, next_cycle_replace_deps, 0);\n+  VEC_truncate (int, next_cycle_apply, 0);\n+}\n+\n /* Compute INSN_TICK_ESTIMATE for INSN.  PROCESSED is a bitmap of\n    instructions we've previously encountered, a set bit prevents\n    recursion.  BUDGET is a limit on how far ahead we look, it is\n@@ -4516,6 +4789,30 @@ restore_other_notes (rtx head, basic_block head_bb)\n   return head;\n }\n \n+/* When we know we are going to discard the schedule due to a failed attempt\n+   at modulo scheduling, undo all replacements.  */\n+static void\n+undo_all_replacements (void)\n+{\n+  rtx insn;\n+  int i;\n+\n+  FOR_EACH_VEC_ELT (rtx, scheduled_insns, i, insn)\n+    {\n+      sd_iterator_def sd_it;\n+      dep_t dep;\n+\n+      /* See if we must undo a replacement.  */\n+      for (sd_it = sd_iterator_start (insn, SD_LIST_RES_FORW);\n+\t   sd_iterator_cond (&sd_it, &dep); sd_iterator_next (&sd_it))\n+\t{\n+\t  struct dep_replacement *desc = DEP_REPLACE (dep);\n+\t  if (desc != NULL)\n+\t    validate_change (desc->insn, desc->loc, desc->orig, 0);\n+\t}\n+    }\n+}\n+\n /* Move insns that became ready to fire from queue to ready list.  */\n \n static void\n@@ -5557,6 +5854,9 @@ schedule_block (basic_block *target_bb)\n   rtx head = NEXT_INSN (prev_head);\n   rtx tail = PREV_INSN (next_tail);\n \n+  if ((current_sched_info->flags & DONT_BREAK_DEPENDENCIES) == 0)\n+    find_modifiable_mems (head, tail);\n+\n   /* We used to have code to avoid getting parameters moved from hard\n      argument registers into pseudos.\n \n@@ -5677,6 +5977,7 @@ schedule_block (basic_block *target_bb)\n   /* Loop until all the insns in BB are scheduled.  */\n   while ((*current_sched_info->schedule_more_p) ())\n     {\n+      perform_replacements_new_cycle ();\n       do\n \t{\n \t  start_clock_var = clock_var;\n@@ -5893,7 +6194,7 @@ schedule_block (basic_block *target_bb)\n \t    /* We normally get here only if we don't want to move\n \t       insn from the split block.  */\n \t    {\n-\t      TODO_SPEC (insn) = HARD_DEP;\n+\t      TODO_SPEC (insn) = DEP_POSTPONED;\n \t      goto restart_choose_ready;\n \t    }\n \n@@ -6004,6 +6305,8 @@ schedule_block (basic_block *target_bb)\n \t  gcc_assert (failed);\n \n \t  failed_insn = failed->delay_pair->i1;\n+\t  /* Clear these queues.  */\n+\t  perform_replacements_new_cycle ();\n \t  toggle_cancelled_flags (false);\n \t  unschedule_insns_until (failed_insn);\n \t  while (failed != backtrack_queue)\n@@ -6031,6 +6334,7 @@ schedule_block (basic_block *target_bb)\n   if (ls.modulo_epilogue)\n     success = true;\n  end_schedule:\n+  perform_replacements_new_cycle ();\n   if (modulo_ii > 0)\n     {\n       /* Once again, debug insn suckiness: they can be on the ready list\n@@ -6070,6 +6374,9 @@ schedule_block (basic_block *target_bb)\n \t}\n     }\n \n+  if (!success)\n+    undo_all_replacements ();\n+\n   /* Debug info.  */\n   if (sched_verbose)\n     {\n@@ -6553,14 +6860,15 @@ try_ready (rtx next)\n \n   old_ts = TODO_SPEC (next);\n \n-  gcc_assert (!(old_ts & ~(SPECULATIVE | HARD_DEP | DEP_CONTROL))\n-\t      && ((old_ts & HARD_DEP)\n+  gcc_assert (!(old_ts & ~(SPECULATIVE | HARD_DEP | DEP_CONTROL | DEP_POSTPONED))\n+\t      && (old_ts == HARD_DEP\n+\t\t  || old_ts == DEP_POSTPONED\n \t\t  || (old_ts & SPECULATIVE)\n-\t\t  || (old_ts & DEP_CONTROL)));\n+\t\t  || old_ts == DEP_CONTROL));\n \n-  new_ts = recompute_todo_spec (next);\n+  new_ts = recompute_todo_spec (next, false);\n \n-  if (new_ts & HARD_DEP)\n+  if (new_ts & (HARD_DEP | DEP_POSTPONED))\n     gcc_assert (new_ts == old_ts\n \t\t&& QUEUE_INDEX (next) == QUEUE_NOWHERE);\n   else if (current_sched_info->new_ready)\n@@ -6628,7 +6936,7 @@ try_ready (rtx next)\n \n   TODO_SPEC (next) = new_ts;\n \n-  if (new_ts & HARD_DEP)\n+  if (new_ts & (HARD_DEP | DEP_POSTPONED))\n     {\n       /* We can't assert (QUEUE_INDEX (next) == QUEUE_NOWHERE) here because\n \t control-speculative NEXT could have been discarded by sched-rgn.c\n@@ -7647,27 +7955,13 @@ fix_recovery_deps (basic_block rec)\n static bool\n haifa_change_pattern (rtx insn, rtx new_pat)\n {\n-  sd_iterator_def sd_it;\n-  dep_t dep;\n   int t;\n \n   t = validate_change (insn, &PATTERN (insn), new_pat, 0);\n   if (!t)\n     return false;\n-  dfa_clear_single_insn_cache (insn);\n-\n-  sd_it = sd_iterator_start (insn,\n-\t\t\t     SD_LIST_FORW | SD_LIST_BACK | SD_LIST_RES_BACK);\n-  while (sd_iterator_cond (&sd_it, &dep))\n-    {\n-      DEP_COST (dep) = UNKNOWN_DEP_COST;\n-      sd_iterator_next (&sd_it);\n-    }\n \n-  /* Invalidate INSN_COST, so it'll be recalculated.  */\n-  INSN_COST (insn) = -1;\n-  /* Invalidate INSN_TICK, so it'll be recalculated.  */\n-  INSN_TICK (insn) = INVALID_TICK;\n+  update_insn_after_change (insn);\n   return true;\n }\n "}, {"sha": "f53caddf73542ce527162c9a7397f53187e91090", "filename": "gcc/sched-deps.c", "status": "modified", "additions": 428, "deletions": 73, "changes": 501, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2Fsched-deps.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2Fsched-deps.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-deps.c?ref=1a83e602a157b844ed98d0dab832c1240ed6bf4b", "patch": "@@ -39,6 +39,7 @@ along with GCC; see the file COPYING3.  If not see\n #include \"insn-attr.h\"\n #include \"except.h\"\n #include \"recog.h\"\n+#include \"emit-rtl.h\"\n #include \"sched-int.h\"\n #include \"params.h\"\n #include \"cselib.h\"\n@@ -109,6 +110,9 @@ init_dep_1 (dep_t dep, rtx pro, rtx con, enum reg_note type, ds_t ds)\n   DEP_TYPE (dep) = type;\n   DEP_STATUS (dep) = ds;\n   DEP_COST (dep) = UNKNOWN_DEP_COST;\n+  DEP_NONREG (dep) = 0;\n+  DEP_MULTIPLE (dep) = 0;\n+  DEP_REPLACE (dep) = NULL;\n }\n \n /* Init DEP with the arguments.\n@@ -434,6 +438,8 @@ dep_spec_p (dep_t dep)\n       if (DEP_TYPE (dep) == REG_DEP_CONTROL)\n \treturn true;\n     }\n+  if (DEP_REPLACE (dep) != NULL)\n+    return true;\n   return false;\n }\n \n@@ -472,11 +478,14 @@ static bitmap_head *control_dependency_cache = NULL;\n static bitmap_head *spec_dependency_cache = NULL;\n static int cache_size;\n \n+/* True if we should mark added dependencies as a non-register deps.  */\n+static bool mark_as_hard;\n+\n static int deps_may_trap_p (const_rtx);\n static void add_dependence_1 (rtx, rtx, enum reg_note);\n-static void add_dependence_list (rtx, rtx, int, enum reg_note);\n+static void add_dependence_list (rtx, rtx, int, enum reg_note, bool);\n static void add_dependence_list_and_free (struct deps_desc *, rtx,\n-\t\t\t\t\t  rtx *, int, enum reg_note);\n+\t\t\t\t\t  rtx *, int, enum reg_note, bool);\n static void delete_all_dependences (rtx);\n static void chain_to_prev_insn (rtx);\n \n@@ -1136,6 +1145,9 @@ update_dep (dep_t dep, dep_t new_dep,\n   enum reg_note old_type = DEP_TYPE (dep);\n   bool was_spec = dep_spec_p (dep);\n \n+  DEP_NONREG (dep) |= DEP_NONREG (new_dep);\n+  DEP_MULTIPLE (dep) = 1;\n+\n   /* If this is a more restrictive type of dependence than the\n      existing one, then change the existing dependence to this\n      type.  */\n@@ -1538,33 +1550,38 @@ add_dependence (rtx con, rtx pro, enum reg_note dep_type)\n \t    fprintf (sched_dump, \"making DEP_CONTROL for %d\\n\",\n \t\t     INSN_UID (real_pro));\n \t  add_dependence_list (con, INSN_COND_DEPS (real_pro), 0,\n-\t\t\t       REG_DEP_TRUE);\n+\t\t\t       REG_DEP_TRUE, false);\n \t}\n     }\n \t  \n   add_dependence_1 (con, pro, dep_type);\n }\n \n-/* A convenience wrapper to operate on an entire list.  */\n+/* A convenience wrapper to operate on an entire list.  HARD should be\n+   true if DEP_NONREG should be set on newly created dependencies.  */\n \n static void\n-add_dependence_list (rtx insn, rtx list, int uncond, enum reg_note dep_type)\n+add_dependence_list (rtx insn, rtx list, int uncond, enum reg_note dep_type,\n+\t\t     bool hard)\n {\n+  mark_as_hard = hard;\n   for (; list; list = XEXP (list, 1))\n     {\n       if (uncond || ! sched_insns_conditions_mutex_p (insn, XEXP (list, 0)))\n \tadd_dependence (insn, XEXP (list, 0), dep_type);\n     }\n+  mark_as_hard = false;\n }\n \n /* Similar, but free *LISTP at the same time, when the context\n-   is not readonly.  */\n+   is not readonly.  HARD should be true if DEP_NONREG should be set on\n+   newly created dependencies.  */\n \n static void\n add_dependence_list_and_free (struct deps_desc *deps, rtx insn, rtx *listp,\n-                              int uncond, enum reg_note dep_type)\n+                              int uncond, enum reg_note dep_type, bool hard)\n {\n-  add_dependence_list (insn, *listp, uncond, dep_type);\n+  add_dependence_list (insn, *listp, uncond, dep_type, hard);\n \n   /* We don't want to short-circuit dependencies involving debug\n      insns, because they may cause actual dependencies to be\n@@ -1738,7 +1755,7 @@ flush_pending_lists (struct deps_desc *deps, rtx insn, int for_read,\n   if (for_write)\n     {\n       add_dependence_list_and_free (deps, insn, &deps->pending_read_insns,\n-                                    1, REG_DEP_ANTI);\n+                                    1, REG_DEP_ANTI, true);\n       if (!deps->readonly)\n         {\n           free_EXPR_LIST_list (&deps->pending_read_mems);\n@@ -1747,14 +1764,16 @@ flush_pending_lists (struct deps_desc *deps, rtx insn, int for_read,\n     }\n \n   add_dependence_list_and_free (deps, insn, &deps->pending_write_insns, 1,\n-\t\t\t\tfor_read ? REG_DEP_ANTI : REG_DEP_OUTPUT);\n+\t\t\t\tfor_read ? REG_DEP_ANTI : REG_DEP_OUTPUT,\n+\t\t\t\ttrue);\n \n   add_dependence_list_and_free (deps, insn,\n                                 &deps->last_pending_memory_flush, 1,\n-                                for_read ? REG_DEP_ANTI : REG_DEP_OUTPUT);\n+                                for_read ? REG_DEP_ANTI : REG_DEP_OUTPUT,\n+\t\t\t\ttrue);\n \n   add_dependence_list_and_free (deps, insn, &deps->pending_jump_insns, 1,\n-\t\t\t\tREG_DEP_ANTI);\n+\t\t\t\tREG_DEP_ANTI, true);\n \n   if (DEBUG_INSN_P (insn))\n     {\n@@ -1773,6 +1792,7 @@ flush_pending_lists (struct deps_desc *deps, rtx insn, int for_read,\n       deps->last_pending_memory_flush = alloc_INSN_LIST (insn, NULL_RTX);\n       deps->pending_flush_length = 1;\n     }\n+  mark_as_hard = false;\n }\n \f\n /* Instruction which dependencies we are analyzing.  */\n@@ -1828,6 +1848,7 @@ haifa_note_mem_dep (rtx mem, rtx pending_mem, rtx pending_insn, ds_t ds)\n \n     init_dep_1 (dep, pending_insn, cur_insn, ds_to_dt (ds),\n                 current_sched_info->flags & USE_DEPS_LIST ? ds : 0);\n+    DEP_NONREG (dep) = 1;\n     maybe_add_or_update_dep_1 (dep, false, pending_mem, mem);\n   }\n \n@@ -1840,6 +1861,8 @@ haifa_note_dep (rtx elem, ds_t ds)\n   dep_t dep = &_dep;\n \n   init_dep (dep, elem, cur_insn, ds_to_dt (ds));\n+  if (mark_as_hard)\n+    DEP_NONREG (dep) = 1;\n   maybe_add_or_update_dep_1 (dep, false, NULL_RTX, NULL_RTX);\n }\n \n@@ -2344,7 +2367,7 @@ sched_analyze_reg (struct deps_desc *deps, int regno, enum machine_mode mode,\n \t      = alloc_INSN_LIST (insn, deps->sched_before_next_call);\n \t  else\n \t    add_dependence_list (insn, deps->last_function_call, 1,\n-\t\t\t\t REG_DEP_ANTI);\n+\t\t\t\t REG_DEP_ANTI, false);\n \t}\n     }\n }\n@@ -2500,9 +2523,9 @@ sched_analyze_1 (struct deps_desc *deps, rtx x, rtx insn)\n \t    }\n \n \t  add_dependence_list (insn, deps->last_pending_memory_flush, 1,\n-\t\t\t       REG_DEP_ANTI);\n+\t\t\t       REG_DEP_ANTI, true);\n \t  add_dependence_list (insn, deps->pending_jump_insns, 1,\n-\t\t\t       REG_DEP_CONTROL);\n+\t\t\t       REG_DEP_CONTROL, true);\n \n           if (!deps->readonly)\n             add_insn_mem_dependence (deps, false, insn, dest);\n@@ -2799,7 +2822,7 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n     /* Avoid moving trapping instructions across function calls that might\n        not always return.  */\n     add_dependence_list (insn, deps->last_function_call_may_noreturn,\n-\t\t\t 1, REG_DEP_ANTI);\n+\t\t\t 1, REG_DEP_ANTI, true);\n \n   /* We must avoid creating a situation in which two successors of the\n      current block have different unwind info after scheduling.  If at any\n@@ -2816,7 +2839,8 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n \t= alloc_INSN_LIST (insn, deps->sched_before_next_jump);\n \n       /* Make sure epilogue insn is scheduled after preceding jumps.  */\n-      add_dependence_list (insn, deps->pending_jump_insns, 1, REG_DEP_ANTI);\n+      add_dependence_list (insn, deps->pending_jump_insns, 1, REG_DEP_ANTI,\n+\t\t\t   true);\n     }\n \n   if (code == COND_EXEC)\n@@ -2837,7 +2861,7 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n \t instruction so that reg-stack won't get confused.  */\n       if (code == CLOBBER)\n \tadd_dependence_list (insn, deps->last_function_call, 1,\n-\t\t\t     REG_DEP_OUTPUT);\n+\t\t\t     REG_DEP_OUTPUT, true);\n     }\n   else if (code == PARALLEL)\n     {\n@@ -2898,11 +2922,12 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n               EXECUTE_IF_SET_IN_REG_SET (reg_pending_control_uses, 0, i, rsi)\n                 {\n                   struct deps_reg *reg_last = &deps->reg_last[i];\n-                  add_dependence_list (insn, reg_last->sets, 0, REG_DEP_ANTI);\n+                  add_dependence_list (insn, reg_last->sets, 0, REG_DEP_ANTI,\n+\t\t\t\t       false);\n                   add_dependence_list (insn, reg_last->implicit_sets,\n-\t\t\t\t       0, REG_DEP_ANTI);\n+\t\t\t\t       0, REG_DEP_ANTI, false);\n                   add_dependence_list (insn, reg_last->clobbers, 0,\n-\t\t\t\t       REG_DEP_ANTI);\n+\t\t\t\t       REG_DEP_ANTI, false);\n                 }\n             }\n \n@@ -2932,9 +2957,9 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n \t    }\n \n \t  add_dependence_list (insn, deps->last_pending_memory_flush, 1,\n-\t\t\t       REG_DEP_ANTI);\n+\t\t\t       REG_DEP_ANTI, true);\n \t  add_dependence_list (insn, deps->pending_jump_insns, 1,\n-\t\t\t       REG_DEP_ANTI);\n+\t\t\t       REG_DEP_ANTI, true);\n \t}\n     }\n \n@@ -2967,19 +2992,20 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n \tadd_dependence (insn, prev, REG_DEP_ANTI);\n \n       add_dependence_list (insn, deps->last_function_call, 1,\n-\t\t\t   REG_DEP_ANTI);\n+\t\t\t   REG_DEP_ANTI, false);\n \n-      for (u = deps->last_pending_memory_flush; u; u = XEXP (u, 1))\n-\tif (!sel_sched_p ())\n+      if (!sel_sched_p ())\n+\tfor (u = deps->last_pending_memory_flush; u; u = XEXP (u, 1))\n \t  add_dependence (insn, XEXP (u, 0), REG_DEP_ANTI);\n \n       EXECUTE_IF_SET_IN_REG_SET (reg_pending_uses, 0, i, rsi)\n \t{\n \t  struct deps_reg *reg_last = &deps->reg_last[i];\n-\t  add_dependence_list (insn, reg_last->sets, 1, REG_DEP_ANTI);\n+\t  add_dependence_list (insn, reg_last->sets, 1, REG_DEP_ANTI, false);\n \t  /* There's no point in making REG_DEP_CONTROL dependencies for\n \t     debug insns.  */\n-\t  add_dependence_list (insn, reg_last->clobbers, 1, REG_DEP_ANTI);\n+\t  add_dependence_list (insn, reg_last->clobbers, 1, REG_DEP_ANTI,\n+\t\t\t       false);\n \n \t  if (!deps->readonly)\n \t    reg_last->uses = alloc_INSN_LIST (insn, reg_last->uses);\n@@ -3005,9 +3031,11 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n       EXECUTE_IF_SET_IN_REG_SET (reg_pending_uses, 0, i, rsi)\n \t{\n \t  struct deps_reg *reg_last = &deps->reg_last[i];\n-\t  add_dependence_list (insn, reg_last->sets, 0, REG_DEP_TRUE);\n-\t  add_dependence_list (insn, reg_last->implicit_sets, 0, REG_DEP_ANTI);\n-\t  add_dependence_list (insn, reg_last->clobbers, 0, REG_DEP_TRUE);\n+\t  add_dependence_list (insn, reg_last->sets, 0, REG_DEP_TRUE, false);\n+\t  add_dependence_list (insn, reg_last->implicit_sets, 0, REG_DEP_ANTI,\n+\t\t\t       false);\n+\t  add_dependence_list (insn, reg_last->clobbers, 0, REG_DEP_TRUE,\n+\t\t\t       false);\n \n \t  if (!deps->readonly)\n \t    {\n@@ -3020,10 +3048,11 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n \tif (TEST_HARD_REG_BIT (implicit_reg_pending_uses, i))\n \t  {\n \t    struct deps_reg *reg_last = &deps->reg_last[i];\n-\t    add_dependence_list (insn, reg_last->sets, 0, REG_DEP_TRUE);\n+\t    add_dependence_list (insn, reg_last->sets, 0, REG_DEP_TRUE, false);\n \t    add_dependence_list (insn, reg_last->implicit_sets, 0,\n-\t\t\t\t REG_DEP_ANTI);\n-\t    add_dependence_list (insn, reg_last->clobbers, 0, REG_DEP_TRUE);\n+\t\t\t\t REG_DEP_ANTI, false);\n+\t    add_dependence_list (insn, reg_last->clobbers, 0, REG_DEP_TRUE,\n+\t\t\t\t false);\n \n \t    if (!deps->readonly)\n \t      {\n@@ -3058,12 +3087,14 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n \t  EXECUTE_IF_SET_IN_REG_SET (reg_pending_clobbers, 0, i, rsi)\n \t    {\n \t      struct deps_reg *reg_last = &deps->reg_last[i];\n-\t      add_dependence_list (insn, reg_last->sets, 0, REG_DEP_OUTPUT);\n+\t      add_dependence_list (insn, reg_last->sets, 0, REG_DEP_OUTPUT,\n+\t\t\t\t   false);\n \t      add_dependence_list (insn, reg_last->implicit_sets, 0,\n-\t\t\t\t   REG_DEP_ANTI);\n-\t      add_dependence_list (insn, reg_last->uses, 0, REG_DEP_ANTI);\n+\t\t\t\t   REG_DEP_ANTI, false);\n+\t      add_dependence_list (insn, reg_last->uses, 0, REG_DEP_ANTI,\n+\t\t\t\t   false);\n \t      add_dependence_list (insn, reg_last->control_uses, 0,\n-\t\t\t\t   REG_DEP_CONTROL);\n+\t\t\t\t   REG_DEP_CONTROL, false);\n \n \t      if (!deps->readonly)\n \t\t{\n@@ -3075,13 +3106,16 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n \t  EXECUTE_IF_SET_IN_REG_SET (reg_pending_sets, 0, i, rsi)\n \t    {\n \t      struct deps_reg *reg_last = &deps->reg_last[i];\n-\t      add_dependence_list (insn, reg_last->sets, 0, REG_DEP_OUTPUT);\n+\t      add_dependence_list (insn, reg_last->sets, 0, REG_DEP_OUTPUT,\n+\t\t\t\t   false);\n \t      add_dependence_list (insn, reg_last->implicit_sets, 0,\n-\t\t\t\t   REG_DEP_ANTI);\n-\t      add_dependence_list (insn, reg_last->clobbers, 0, REG_DEP_OUTPUT);\n-\t      add_dependence_list (insn, reg_last->uses, 0, REG_DEP_ANTI);\n+\t\t\t\t   REG_DEP_ANTI, false);\n+\t      add_dependence_list (insn, reg_last->clobbers, 0, REG_DEP_OUTPUT,\n+\t\t\t\t   false);\n+\t      add_dependence_list (insn, reg_last->uses, 0, REG_DEP_ANTI,\n+\t\t\t\t   false);\n \t      add_dependence_list (insn, reg_last->control_uses, 0,\n-\t\t\t\t   REG_DEP_CONTROL);\n+\t\t\t\t   REG_DEP_CONTROL, false);\n \n \t      if (!deps->readonly)\n \t\treg_last->sets = alloc_INSN_LIST (insn, reg_last->sets);\n@@ -3096,17 +3130,18 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n \t\t  || reg_last->clobbers_length > MAX_PENDING_LIST_LENGTH)\n \t\t{\n \t\t  add_dependence_list_and_free (deps, insn, &reg_last->sets, 0,\n-\t\t\t\t\t\tREG_DEP_OUTPUT);\n+\t\t\t\t\t\tREG_DEP_OUTPUT, false);\n \t\t  add_dependence_list_and_free (deps, insn,\n \t\t\t\t\t\t&reg_last->implicit_sets, 0,\n-\t\t\t\t\t\tREG_DEP_ANTI);\n+\t\t\t\t\t\tREG_DEP_ANTI, false);\n \t\t  add_dependence_list_and_free (deps, insn, &reg_last->uses, 0,\n-\t\t\t\t\t\tREG_DEP_ANTI);\n+\t\t\t\t\t\tREG_DEP_ANTI, false);\n \t\t  add_dependence_list_and_free (deps, insn,\n \t\t\t\t\t\t&reg_last->control_uses, 0,\n-\t\t\t\t\t\tREG_DEP_ANTI);\n-\t\t  add_dependence_list_and_free\n-\t\t    (deps, insn, &reg_last->clobbers, 0, REG_DEP_OUTPUT);\n+\t\t\t\t\t\tREG_DEP_ANTI, false);\n+\t\t  add_dependence_list_and_free (deps, insn,\n+\t\t\t\t\t\t&reg_last->clobbers, 0,\n+\t\t\t\t\t\tREG_DEP_OUTPUT, false);\n \n \t\t  if (!deps->readonly)\n \t\t    {\n@@ -3117,12 +3152,14 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n \t\t}\n \t      else\n \t\t{\n-\t\t  add_dependence_list (insn, reg_last->sets, 0, REG_DEP_OUTPUT);\n+\t\t  add_dependence_list (insn, reg_last->sets, 0, REG_DEP_OUTPUT,\n+\t\t\t\t       false);\n \t\t  add_dependence_list (insn, reg_last->implicit_sets, 0,\n-\t\t\t\t       REG_DEP_ANTI);\n-\t\t  add_dependence_list (insn, reg_last->uses, 0, REG_DEP_ANTI);\n+\t\t\t\t       REG_DEP_ANTI, false);\n+\t\t  add_dependence_list (insn, reg_last->uses, 0, REG_DEP_ANTI,\n+\t\t\t\t       false);\n \t\t  add_dependence_list (insn, reg_last->control_uses, 0,\n-\t\t\t\t       REG_DEP_CONTROL);\n+\t\t\t\t       REG_DEP_CONTROL, false);\n \t\t}\n \n \t      if (!deps->readonly)\n@@ -3137,16 +3174,16 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n \t      struct deps_reg *reg_last = &deps->reg_last[i];\n \n \t      add_dependence_list_and_free (deps, insn, &reg_last->sets, 0,\n-\t\t\t\t\t    REG_DEP_OUTPUT);\n+\t\t\t\t\t    REG_DEP_OUTPUT, false);\n \t      add_dependence_list_and_free (deps, insn,\n \t\t\t\t\t    &reg_last->implicit_sets,\n-\t\t\t\t\t    0, REG_DEP_ANTI);\n+\t\t\t\t\t    0, REG_DEP_ANTI, false);\n \t      add_dependence_list_and_free (deps, insn, &reg_last->clobbers, 0,\n-\t\t\t\t\t    REG_DEP_OUTPUT);\n+\t\t\t\t\t    REG_DEP_OUTPUT, false);\n \t      add_dependence_list_and_free (deps, insn, &reg_last->uses, 0,\n-\t\t\t\t\t    REG_DEP_ANTI);\n+\t\t\t\t\t    REG_DEP_ANTI, false);\n \t      add_dependence_list (insn, reg_last->control_uses, 0,\n-\t\t\t\t   REG_DEP_CONTROL);\n+\t\t\t\t   REG_DEP_CONTROL, false);\n \n \t      if (!deps->readonly)\n \t\t{\n@@ -3171,10 +3208,11 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n     if (TEST_HARD_REG_BIT (implicit_reg_pending_clobbers, i))\n       {\n \tstruct deps_reg *reg_last = &deps->reg_last[i];\n-\tadd_dependence_list (insn, reg_last->sets, 0, REG_DEP_ANTI);\n-\tadd_dependence_list (insn, reg_last->clobbers, 0, REG_DEP_ANTI);\n-\tadd_dependence_list (insn, reg_last->uses, 0, REG_DEP_ANTI);\n-\tadd_dependence_list (insn, reg_last->control_uses, 0, REG_DEP_ANTI);\n+\tadd_dependence_list (insn, reg_last->sets, 0, REG_DEP_ANTI, false);\n+\tadd_dependence_list (insn, reg_last->clobbers, 0, REG_DEP_ANTI, false);\n+\tadd_dependence_list (insn, reg_last->uses, 0, REG_DEP_ANTI, false);\n+\tadd_dependence_list (insn, reg_last->control_uses, 0, REG_DEP_ANTI,\n+\t\t\t     false);\n \n \tif (!deps->readonly)\n \t  reg_last->implicit_sets\n@@ -3212,15 +3250,16 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n \t  EXECUTE_IF_SET_IN_REG_SET (&deps->reg_last_in_use, 0, i, rsi)\n \t    {\n \t      struct deps_reg *reg_last = &deps->reg_last[i];\n-\t      add_dependence_list (insn, reg_last->uses, 0, REG_DEP_ANTI);\n+\t      add_dependence_list (insn, reg_last->uses, 0, REG_DEP_ANTI,\n+\t\t\t\t   true);\n \t      add_dependence_list (insn, reg_last->sets, 0,\n \t\t\t\t   reg_pending_barrier == TRUE_BARRIER\n-\t\t\t\t   ? REG_DEP_TRUE : REG_DEP_ANTI);\n+\t\t\t\t   ? REG_DEP_TRUE : REG_DEP_ANTI, true);\n \t      add_dependence_list (insn, reg_last->implicit_sets, 0,\n-\t\t\t\t   REG_DEP_ANTI);\n+\t\t\t\t   REG_DEP_ANTI, true);\n \t      add_dependence_list (insn, reg_last->clobbers, 0,\n \t\t\t\t   reg_pending_barrier == TRUE_BARRIER\n-\t\t\t\t   ? REG_DEP_TRUE : REG_DEP_ANTI);\n+\t\t\t\t   ? REG_DEP_TRUE : REG_DEP_ANTI, true);\n \t    }\n \t}\n       else\n@@ -3229,19 +3268,21 @@ sched_analyze_insn (struct deps_desc *deps, rtx x, rtx insn)\n \t    {\n \t      struct deps_reg *reg_last = &deps->reg_last[i];\n \t      add_dependence_list_and_free (deps, insn, &reg_last->uses, 0,\n-\t\t\t\t\t    REG_DEP_ANTI);\n+\t\t\t\t\t    REG_DEP_ANTI, true);\n \t      add_dependence_list_and_free (deps, insn,\n \t\t\t\t\t    &reg_last->control_uses, 0,\n-\t\t\t\t\t    REG_DEP_CONTROL);\n+\t\t\t\t\t    REG_DEP_CONTROL, true);\n \t      add_dependence_list_and_free (deps, insn, &reg_last->sets, 0,\n \t\t\t\t\t    reg_pending_barrier == TRUE_BARRIER\n-\t\t\t\t\t    ? REG_DEP_TRUE : REG_DEP_ANTI);\n+\t\t\t\t\t    ? REG_DEP_TRUE : REG_DEP_ANTI,\n+\t\t\t\t\t    true);\n \t      add_dependence_list_and_free (deps, insn,\n \t\t\t\t\t    &reg_last->implicit_sets, 0,\n-\t\t\t\t\t    REG_DEP_ANTI);\n+\t\t\t\t\t    REG_DEP_ANTI, true);\n \t      add_dependence_list_and_free (deps, insn, &reg_last->clobbers, 0,\n \t\t\t\t\t    reg_pending_barrier == TRUE_BARRIER\n-\t\t\t\t\t    ? REG_DEP_TRUE : REG_DEP_ANTI);\n+\t\t\t\t\t    ? REG_DEP_TRUE : REG_DEP_ANTI,\n+\t\t\t\t\t    true);\n \n               if (!deps->readonly)\n                 {\n@@ -3526,7 +3567,7 @@ deps_analyze_insn (struct deps_desc *deps, rtx insn)\n       /* For each insn which shouldn't cross a jump, add a dependence.  */\n       add_dependence_list_and_free (deps, insn,\n \t\t\t\t    &deps->sched_before_next_jump, 1,\n-\t\t\t\t    REG_DEP_ANTI);\n+\t\t\t\t    REG_DEP_ANTI, true);\n \n       sched_analyze_insn (deps, PATTERN (insn), insn);\n     }\n@@ -3582,7 +3623,7 @@ deps_analyze_insn (struct deps_desc *deps, rtx insn)\n          between that insn and this call insn.  */\n       add_dependence_list_and_free (deps, insn,\n                                     &deps->sched_before_next_call, 1,\n-                                    REG_DEP_ANTI);\n+                                    REG_DEP_ANTI, true);\n \n       sched_analyze_insn (deps, PATTERN (insn), insn);\n \n@@ -4476,4 +4517,318 @@ check_dep (dep_t dep, bool relaxed_p)\n }\n #endif /* ENABLE_CHECKING */\n \n+/* The following code discovers opportunities to switch a memory reference\n+   and an increment by modifying the address.  We ensure that this is done\n+   only for dependencies that are only used to show a single register\n+   dependence (using DEP_NONREG and DEP_MULTIPLE), and so that every memory\n+   instruction involved is subject to only one dep that can cause a pattern\n+   change.\n+\n+   When we discover a suitable dependency, we fill in the dep_replacement\n+   structure to show how to modify the memory reference.  */\n+\n+/* Holds information about a pair of memory reference and register increment\n+   insns which depend on each other, but could possibly be interchanged.  */\n+struct mem_inc_info\n+{\n+  rtx inc_insn;\n+  rtx mem_insn;\n+\n+  rtx *mem_loc;\n+  /* A register occurring in the memory address for which we wish to break\n+     the dependence.  This must be identical to the destination register of\n+     the increment.  */\n+  rtx mem_reg0;\n+  /* Any kind of index that is added to that register.  */\n+  rtx mem_index;\n+  /* The constant offset used in the memory address.  */\n+  HOST_WIDE_INT mem_constant;\n+  /* The constant added in the increment insn.  Negated if the increment is\n+     after the memory address.  */\n+  HOST_WIDE_INT inc_constant;\n+  /* The source register used in the increment.  May be different from mem_reg0\n+     if the increment occurs before the memory address.  */\n+  rtx inc_input;\n+};\n+\n+/* Verify that the memory location described in MII can be replaced with\n+   one using NEW_ADDR.  Return the new memory reference or NULL_RTX.  The\n+   insn remains unchanged by this function.  */\n+\n+static rtx\n+attempt_change (struct mem_inc_info *mii, rtx new_addr)\n+{\n+  rtx mem = *mii->mem_loc;\n+  rtx new_mem;\n+\n+  /* Jump thru a lot of hoops to keep the attributes up to date.  We\n+     do not want to call one of the change address variants that take\n+     an offset even though we know the offset in many cases.  These\n+     assume you are changing where the address is pointing by the\n+     offset.  */\n+  new_mem = replace_equiv_address_nv (mem, new_addr);\n+  if (! validate_change (mii->mem_insn, mii->mem_loc, new_mem, 0))\n+    {\n+      if (sched_verbose >= 5)\n+\tfprintf (sched_dump, \"validation failure\\n\");\n+      return NULL_RTX;\n+    }\n+\n+  /* Put back the old one.  */\n+  validate_change (mii->mem_insn, mii->mem_loc, mem, 0);\n+\n+  return new_mem;\n+}\n+\n+/* Return true if INSN is of a form \"a = b op c\" where a and b are\n+   regs.  op is + if c is a reg and +|- if c is a const.  Fill in\n+   informantion in MII about what is found.\n+   BEFORE_MEM indicates whether the increment is found before or after\n+   a corresponding memory reference.  */\n+\n+static bool\n+parse_add_or_inc (struct mem_inc_info *mii, rtx insn, bool before_mem)\n+{\n+  rtx pat = single_set (insn);\n+  rtx src, cst;\n+  bool regs_equal;\n+\n+  if (RTX_FRAME_RELATED_P (insn) || !pat)\n+    return false;\n+\n+  /* Result must be single reg.  */\n+  if (!REG_P (SET_DEST (pat)))\n+    return false;\n+\n+  if (GET_CODE (SET_SRC (pat)) != PLUS\n+      && GET_CODE (SET_SRC (pat)) != MINUS)\n+    return false;\n+\n+  mii->inc_insn = insn;\n+  src = SET_SRC (pat);\n+  mii->inc_input = XEXP (src, 0);\n+\n+  if (!REG_P (XEXP (src, 0)))\n+    return false;\n+\n+  if (!rtx_equal_p (SET_DEST (pat), mii->mem_reg0))\n+    return false;\n+\n+  cst = XEXP (src, 1);\n+  if (!CONST_INT_P (cst))\n+    return false;\n+  mii->inc_constant = INTVAL (cst);\n+\n+  regs_equal = rtx_equal_p (mii->inc_input, mii->mem_reg0);\n+\n+  if (!before_mem)\n+    {\n+      mii->inc_constant = -mii->inc_constant;\n+      if (!regs_equal)\n+\treturn false;\n+    }\n+\n+  if (regs_equal && REGNO (SET_DEST (pat)) == STACK_POINTER_REGNUM)\n+    /* Note that the sign has already been reversed for !before_mem.  */\n+    return mii->inc_constant > 0;\n+\n+  return true;\n+}\n+\n+/* Once a suitable mem reference has been found and the corresponding data\n+   in MII has been filled in, this function is called to find a suitable\n+   add or inc insn involving the register we found in the memory\n+   reference.  */\n+\n+static bool\n+find_inc (struct mem_inc_info *mii, bool backwards)\n+{\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n+\n+  sd_it = sd_iterator_start (mii->mem_insn,\n+\t\t\t     backwards ? SD_LIST_HARD_BACK : SD_LIST_FORW);\n+  while (sd_iterator_cond (&sd_it, &dep))\n+    {\n+      dep_node_t node = DEP_LINK_NODE (*sd_it.linkp);\n+      rtx pro = DEP_PRO (dep);\n+      rtx con = DEP_CON (dep);\n+      rtx inc_cand = backwards ? pro : con;\n+      if (DEP_NONREG (dep) || DEP_MULTIPLE (dep))\n+\tgoto next;\n+      if (parse_add_or_inc (mii, inc_cand, backwards))\n+\t{\n+\t  struct dep_replacement *desc;\n+\t  df_ref *def_rec;\n+\t  rtx newaddr, newmem;\n+\n+\t  if (sched_verbose >= 5)\n+\t    fprintf (sched_dump, \"candidate mem/inc pair: %d %d\\n\",\n+\t\t     INSN_UID (mii->mem_insn), INSN_UID (inc_cand));\n+\n+\t  /* Need to assure that none of the operands of the inc\n+\t     instruction are assigned to by the mem insn.  */\n+\t  for (def_rec = DF_INSN_DEFS (mii->mem_insn); *def_rec; def_rec++)\n+\t    {\n+\t      df_ref def = *def_rec;\n+\t      if (reg_overlap_mentioned_p (DF_REF_REG (def), mii->inc_input)\n+\t\t  || reg_overlap_mentioned_p (DF_REF_REG (def), mii->mem_reg0))\n+\t\t{\n+\t\t  if (sched_verbose >= 5)\n+\t\t    fprintf (sched_dump,\n+\t\t\t     \"inc conflicts with store failure.\\n\");\n+\t\t  goto next;\n+\t\t}\n+\t    }\n+\t  newaddr = mii->inc_input;\n+\t  if (mii->mem_index != NULL_RTX)\n+\t    newaddr = gen_rtx_PLUS (GET_MODE (newaddr), newaddr,\n+\t\t\t\t    mii->mem_index);\n+\t  newaddr = plus_constant (GET_MODE (newaddr), newaddr,\n+\t\t\t\t   mii->mem_constant + mii->inc_constant);\n+\t  newmem = attempt_change (mii, newaddr);\n+\t  if (newmem == NULL_RTX)\n+\t    goto next;\n+\t  if (sched_verbose >= 5)\n+\t    fprintf (sched_dump, \"successful address replacement\\n\");\n+\t  desc = XCNEW (struct dep_replacement);\n+\t  DEP_REPLACE (dep) = desc;\n+\t  desc->loc = mii->mem_loc;\n+\t  desc->newval = newmem;\n+\t  desc->orig = *desc->loc;\n+\t  desc->insn = mii->mem_insn;\n+\t  move_dep_link (DEP_NODE_BACK (node), INSN_HARD_BACK_DEPS (con),\n+\t\t\t INSN_SPEC_BACK_DEPS (con));\n+\t  if (backwards)\n+\t    {\n+\t      FOR_EACH_DEP (mii->inc_insn, SD_LIST_BACK, sd_it, dep)\n+\t\tif (modified_in_p (mii->inc_input, DEP_PRO (dep)))\n+\t\t  add_dependence_1 (mii->mem_insn, DEP_PRO (dep),\n+\t\t\t\t    REG_DEP_TRUE);\n+\t    }\n+\t  else\n+\t    {\n+\t      FOR_EACH_DEP (mii->inc_insn, SD_LIST_FORW, sd_it, dep)\n+\t\tif (modified_in_p (mii->inc_input, DEP_CON (dep)))\n+\t\t  add_dependence_1 (DEP_CON (dep), mii->mem_insn,\n+\t\t\t\t    REG_DEP_ANTI);\n+\t    }\n+\t  return true;\n+\t}\n+    next:\n+      sd_iterator_next (&sd_it);\n+    }\n+  return false;\n+}\n+\n+/* A recursive function that walks ADDRESS_OF_X to find memory references\n+   which could be modified during scheduling.  We call find_inc for each\n+   one we find that has a recognizable form.  MII holds information about\n+   the pair of memory/increment instructions.\n+   We ensure that every instruction with a memory reference (which will be\n+   the location of the replacement) is assigned at most one breakable\n+   dependency.  */\n+\n+static bool\n+find_mem (struct mem_inc_info *mii, rtx *address_of_x)\n+{\n+  rtx x = *address_of_x;\n+  enum rtx_code code = GET_CODE (x);\n+  const char *const fmt = GET_RTX_FORMAT (code);\n+  int i;\n+\n+  if (code == MEM)\n+    {\n+      rtx reg0 = XEXP (x, 0);\n+\n+      mii->mem_loc = address_of_x;\n+      mii->mem_index = NULL_RTX;\n+      mii->mem_constant = 0;\n+      if (GET_CODE (reg0) == PLUS && CONST_INT_P (XEXP (reg0, 1)))\n+\t{\n+\t  mii->mem_constant = INTVAL (XEXP (reg0, 1));\n+\t  reg0 = XEXP (reg0, 0);\n+\t}\n+      if (GET_CODE (reg0) == PLUS)\n+\t{\n+\t  mii->mem_index = XEXP (reg0, 1);\n+\t  reg0 = XEXP (reg0, 0);\n+\t}\n+      if (REG_P (reg0))\n+\t{\n+\t  df_ref *def_rec;\n+\t  int occurrences = 0;\n+\n+\t  /* Make sure this reg appears only once in this insn.  Can't use\n+\t     count_occurrences since that only works for pseudos.  */\n+\t  for (def_rec = DF_INSN_USES (mii->mem_insn); *def_rec; def_rec++)\n+\t    {\n+\t      df_ref def = *def_rec;\n+\t      if (reg_overlap_mentioned_p (reg0, DF_REF_REG (def)))\n+\t\tif (++occurrences > 1)\n+\t\t  {\n+\t\t    if (sched_verbose >= 5)\n+\t\t      fprintf (sched_dump, \"mem count failure\\n\");\n+\t\t    return false;\n+\t\t  }\n+\t    }\n+\n+\t  mii->mem_reg0 = reg0;\n+\t  return find_inc (mii, true) || find_inc (mii, false);\n+\t}\n+      return false;\n+    }\n+\n+  if (code == SIGN_EXTRACT || code == ZERO_EXTRACT)\n+    {\n+      /* If REG occurs inside a MEM used in a bit-field reference,\n+\t that is unacceptable.  */\n+      return false;\n+    }\n+\n+  /* Time for some deep diving.  */\n+  for (i = GET_RTX_LENGTH (code) - 1; i >= 0; i--)\n+    {\n+      if (fmt[i] == 'e')\n+\t{\n+\t  if (find_mem (mii, &XEXP (x, i)))\n+\t    return true;\n+\t}\n+      else if (fmt[i] == 'E')\n+\t{\n+\t  int j;\n+\t  for (j = XVECLEN (x, i) - 1; j >= 0; j--)\n+\t    if (find_mem (mii, &XVECEXP (x, i, j)))\n+\t      return true;\n+\t}\n+    }\n+  return false;\n+}\n+\n+\n+/* Examine the instructions between HEAD and TAIL and try to find\n+   dependencies that can be broken by modifying one of the patterns.  */\n+\n+void\n+find_modifiable_mems (rtx head, rtx tail)\n+{\n+  rtx insn;\n+  int success_in_block = 0;\n+\n+  for (insn = head; insn != tail; insn = NEXT_INSN (insn))\n+    {\n+      struct mem_inc_info mii;\n+\n+      if (!NONDEBUG_INSN_P (insn) || RTX_FRAME_RELATED_P (insn))\n+\tcontinue;\n+\n+      mii.mem_insn = insn;\n+      if (find_mem (&mii, &PATTERN (insn)))\n+\tsuccess_in_block++;\n+    }\n+  if (success_in_block && sched_verbose >= 5)\n+    fprintf (sched_dump, \"%d candidates for address modification found.\\n\",\n+\t     success_in_block);\n+}\n+\n #endif /* INSN_SCHEDULING */"}, {"sha": "32bdeb42ab9ce70e1acb3dd59fb3f10303024676", "filename": "gcc/sched-int.h", "status": "modified", "additions": 41, "deletions": 9, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2Fsched-int.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2Fsched-int.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-int.h?ref=1a83e602a157b844ed98d0dab832c1240ed6bf4b", "patch": "@@ -206,6 +206,18 @@ typedef int dw_t;\n extern enum reg_note ds_to_dk (ds_t);\n extern ds_t dk_to_ds (enum reg_note);\n \n+/* Describe a dependency that can be broken by making a replacement\n+   in one of the patterns.  LOC is the location, ORIG and NEWVAL the\n+   two alternative contents, and INSN the instruction that must be\n+   changed.  */\n+struct dep_replacement\n+{\n+  rtx *loc;\n+  rtx orig;\n+  rtx newval;\n+  rtx insn;\n+};\n+\n /* Information about the dependency.  */\n struct _dep\n {\n@@ -215,18 +227,30 @@ struct _dep\n   /* Consumer.  */\n   rtx con;\n \n-  /* Dependency major type.  This field is superseded by STATUS below.\n-     Though, it is still in place because some targets use it.  */\n-  enum reg_note type;\n+  /* If nonnull, holds a pointer to information about how to break the\n+     dependency by making a replacement in one of the insns.  There is\n+     only one such dependency for each insn that must be modified in\n+     order to break such a dependency.  */\n+  struct dep_replacement *replace;\n \n   /* Dependency status.  This field holds all dependency types and additional\n      information for speculative dependencies.  */\n   ds_t status;\n \n-  /* Cached cost of the dependency.  */\n-  int cost;\n+  /* Dependency major type.  This field is superseded by STATUS above.\n+     Though, it is still in place because some targets use it.  */\n+  ENUM_BITFIELD(reg_note) type:6;\n+\n+  unsigned nonreg:1;\n+  unsigned multiple:1;\n+\n+  /* Cached cost of the dependency.  Make sure to update UNKNOWN_DEP_COST\n+     when changing the size of this field.  */\n+  int cost:20;\n };\n \n+#define UNKNOWN_DEP_COST (-1<<19)\n+\n typedef struct _dep dep_def;\n typedef dep_def *dep_t;\n \n@@ -235,8 +259,9 @@ typedef dep_def *dep_t;\n #define DEP_TYPE(D) ((D)->type)\n #define DEP_STATUS(D) ((D)->status)\n #define DEP_COST(D) ((D)->cost)\n-\n-#define UNKNOWN_DEP_COST INT_MIN\n+#define DEP_NONREG(D) ((D)->nonreg)\n+#define DEP_MULTIPLE(D) ((D)->multiple)\n+#define DEP_REPLACE(D) ((D)->replace)\n \n /* Functions to work with dep.  */\n \n@@ -1047,7 +1072,11 @@ enum SPEC_TYPES_OFFSETS {\n    Therefore, it can appear only in TODO_SPEC field of an instruction.  */\n #define HARD_DEP (DEP_CONTROL << 1)\n \n-#define DEP_CANCELLED (HARD_DEP << 1)\n+/* Set in the TODO_SPEC field of an instruction for which new_ready\n+   has decided not to schedule it speculatively.  */\n+#define DEP_POSTPONED (HARD_DEP << 1)\n+\n+#define DEP_CANCELLED (DEP_POSTPONED << 1)\n \n /* This represents the results of calling sched-deps.c functions,\n    which modify dependencies.  */\n@@ -1074,7 +1103,8 @@ enum SCHED_FLAGS {\n   DO_SPECULATION = USE_DEPS_LIST << 1,\n   DO_BACKTRACKING = DO_SPECULATION << 1,\n   DO_PREDICATION = DO_BACKTRACKING << 1,\n-  SCHED_RGN = DO_PREDICATION << 1,\n+  DONT_BREAK_DEPENDENCIES = DO_PREDICATION << 1,\n+  SCHED_RGN = DONT_BREAK_DEPENDENCIES << 1,\n   SCHED_EBB = SCHED_RGN << 1,\n   /* Scheduler can possibly create new basic blocks.  Used for assertions.  */\n   NEW_BBS = SCHED_EBB << 1,\n@@ -1406,6 +1436,8 @@ extern void dump_region_dot_file (const char *, int);\n extern void haifa_sched_init (void);\n extern void haifa_sched_finish (void);\n \n+extern void find_modifiable_mems (rtx, rtx);\n+\n /* sched-deps.c interface to walk, add, search, update, resolve, delete\n    and debug instruction dependencies.  */\n "}, {"sha": "5d39a36d7fac93cd150eb01963b42b1702b12f21", "filename": "gcc/sched-rgn.c", "status": "modified", "additions": 12, "deletions": 4, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2Fsched-rgn.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1a83e602a157b844ed98d0dab832c1240ed6bf4b/gcc%2Fsched-rgn.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-rgn.c?ref=1a83e602a157b844ed98d0dab832c1240ed6bf4b", "patch": "@@ -2103,6 +2103,8 @@ init_ready_list (void)\n      Count number of insns in the target block being scheduled.  */\n   for (insn = NEXT_INSN (prev_head); insn != next_tail; insn = NEXT_INSN (insn))\n     {\n+      gcc_assert (TODO_SPEC (insn) == HARD_DEP || TODO_SPEC (insn) == DEP_POSTPONED);\n+      TODO_SPEC (insn) = HARD_DEP;\n       try_ready (insn);\n       target_n_insns++;\n \n@@ -2126,7 +2128,11 @@ init_ready_list (void)\n \n \tfor (insn = src_head; insn != src_next_tail; insn = NEXT_INSN (insn))\n \t  if (INSN_P (insn))\n-\t    try_ready (insn);\n+\t    {\n+\t      gcc_assert (TODO_SPEC (insn) == HARD_DEP || TODO_SPEC (insn) == DEP_POSTPONED);\n+\t      TODO_SPEC (insn) = HARD_DEP;\n+\t      try_ready (insn);\n+\t    }\n       }\n }\n \n@@ -2218,11 +2224,11 @@ new_ready (rtx next, ds_t ts)\n \t\tts = new_ds;\n \t      else\n \t\t/* NEXT isn't ready yet.  */\n-\t\tts = (ts & ~SPECULATIVE) | HARD_DEP;\n+\t\tts = DEP_POSTPONED;\n \t    }\n \t  else\n \t    /* NEXT isn't ready yet.  */\n-            ts = (ts & ~SPECULATIVE) | HARD_DEP;\n+            ts = DEP_POSTPONED;\n \t}\n     }\n \n@@ -2826,7 +2832,9 @@ void debug_dependencies (rtx head, rtx tail)\n \tdep_t dep;\n \n \tFOR_EACH_DEP (insn, SD_LIST_FORW, sd_it, dep)\n-\t  fprintf (sched_dump, \"%d \", INSN_UID (DEP_CON (dep)));\n+\t  fprintf (sched_dump, \"%d%s%s \", INSN_UID (DEP_CON (dep)),\n+\t\t   DEP_NONREG (dep) ? \"n\" : \"\",\n+\t\t   DEP_MULTIPLE (dep) ? \"m\" : \"\");\n       }\n       fprintf (sched_dump, \"\\n\");\n     }"}]}