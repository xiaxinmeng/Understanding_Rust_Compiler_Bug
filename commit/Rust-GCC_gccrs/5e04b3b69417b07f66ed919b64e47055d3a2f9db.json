{"sha": "5e04b3b69417b07f66ed919b64e47055d3a2f9db", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NWUwNGIzYjY5NDE3YjA3ZjY2ZWQ5MTliNjRlNDcwNTVkM2EyZjlkYg==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@redhat.com", "date": "2009-11-30T18:26:55Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2009-11-30T18:26:55Z"}, "message": "Implement vec_perm broadcast, and tidy lots of patterns to help.\n\nFrom-SVN: r154836", "tree": {"sha": "b588611807250a4b1eed00a81e79ec2d2412b8d5", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/b588611807250a4b1eed00a81e79ec2d2412b8d5"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/5e04b3b69417b07f66ed919b64e47055d3a2f9db", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5e04b3b69417b07f66ed919b64e47055d3a2f9db", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5e04b3b69417b07f66ed919b64e47055d3a2f9db", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5e04b3b69417b07f66ed919b64e47055d3a2f9db/comments", "author": null, "committer": null, "parents": [{"sha": "9fda11a2ecf9047b64bbe2e92343f1e263ce1509", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9fda11a2ecf9047b64bbe2e92343f1e263ce1509", "html_url": "https://github.com/Rust-GCC/gccrs/commit/9fda11a2ecf9047b64bbe2e92343f1e263ce1509"}], "stats": {"total": 917, "additions": 623, "deletions": 294}, "files": [{"sha": "9c8294c8c6cc32bcc0c613f5706720f4fcd75f38", "filename": "gcc/ChangeLog", "status": "modified", "additions": 47, "deletions": 0, "changes": 47, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5e04b3b69417b07f66ed919b64e47055d3a2f9db/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5e04b3b69417b07f66ed919b64e47055d3a2f9db/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=5e04b3b69417b07f66ed919b64e47055d3a2f9db", "patch": "@@ -1,3 +1,50 @@\n+2009-11-30  Richard Henderson  <rth@redhat.com>\n+\n+\t* config/i386/i386.c (ix86_vec_interleave_v2df_operator_ok): New.\n+\t(bdesc_special_args): Update insn codes.\n+\t(avx_vpermilp_parallel): Correct range check.\n+\t(ix86_rtx_costs): Handle vector permutation rtx codes.\n+\t(struct expand_vec_perm_d): Move earlier.\n+\t(get_mode_wider_vector): New.\n+\t(expand_vec_perm_broadcast_1): New.\n+\t(ix86_expand_vector_init_duplicate): Use it.  Tidy AVX modes.\n+\t(expand_vec_perm_broadcast): New.\n+\t(ix86_expand_vec_perm_builtin_1): Use it.\n+\t* config/i386/i386-protos.h: Update.\n+\t* config/i386/predicates.md (avx_vbroadcast_operand): New.\n+\t* config/i386/sse.md (AVX256MODE24P): New.\n+\t(ssescalarmodesuffix2s): New.\n+\t(avxhalfvecmode, avxscalarmode): Fill out to all modes.\n+\t(avxmodesuffixf2c): Add V8SI, V4DI.\n+\t(vec_dupv4sf): New expander.\n+\t(*vec_dupv4sf_avx): Add vbroadcastss alternative.\n+\t(*vec_set<mode>_0_avx, **vec_set<mode>_0_sse4_1): Macro-ize for\n+\tV4SF and V4SI.  Move C alternatives to front.  Add insertps and\n+\tpinsrd alternatives.\n+\t(*vec_set<mode>_0_sse2): Split out from ...\n+\t(vec_set<mode>_0): Macro-ize for V4SF and V4SI.\n+\t(vec_interleave_highv2df, vec_interleave_lowv2df): Require register\n+\tdestination; use ix86_vec_interleave_v2df_operator_ok, instead of\n+\tix86_fixup_binary_operands.\n+\t(*avx_interleave_highv2df, avx_interleave_lowv2df): Add movddup.\n+\t(*sse3_interleave_highv2df, sse3_interleave_lowv2df): New.\n+\t(*avx_movddup, *sse3_movddup): Remove.  New splitter from\n+\tvec_select form to vec_duplicate form.\n+\t(*sse2_interleave_highv2df, sse2_interleave_lowv2df): Use\n+\tix86_vec_interleave_v2df_operator_ok.\n+\t(avx_movddup256, avx_unpcklpd256): Change to expanders, merge into ... \n+\t(*avx_unpcklpd256): ... here.\n+\t(*vec_dupv4si_avx): New.\n+\t(*vec_dupv2di_avx): Add movddup alternative.\n+\t(*vec_dupv2di_sse3): New.\n+\t(vec_dup<AVX256MODE24P>): Replace avx_vbroadcasts<AVXMODEF4P> and\n+\tavx_vbroadcastss256; represent with vec_duplicate instead of \n+\tnested vec_concat operations.\n+\t(avx_vbroadcastf128_<mode>): Rename from\n+\tavx_vbroadcastf128_p<avxmodesuffixf2c>256.\n+\t(*avx_vperm_broadcast_v4sf): New.\n+\t(*avx_vperm_broadcast_<AVX256MODEF2P>): New.\n+\n 2009-11-30  Martin Jambor  <mjambor@suse.cz>\n \n \tPR middle-end/42196"}, {"sha": "1451e799fa60c5853a2ba2dd51ed3b1fab271927", "filename": "gcc/config/i386/i386-protos.h", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5e04b3b69417b07f66ed919b64e47055d3a2f9db/gcc%2Fconfig%2Fi386%2Fi386-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5e04b3b69417b07f66ed919b64e47055d3a2f9db/gcc%2Fconfig%2Fi386%2Fi386-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-protos.h?ref=5e04b3b69417b07f66ed919b64e47055d3a2f9db", "patch": "@@ -86,6 +86,7 @@ extern void ix86_expand_binary_operator (enum rtx_code,\n \t\t\t\t\t enum machine_mode, rtx[]);\n extern int ix86_binary_operator_ok (enum rtx_code, enum machine_mode, rtx[]);\n extern bool ix86_lea_for_add_ok (enum rtx_code, rtx, rtx[]);\n+extern bool ix86_vec_interleave_v2df_operator_ok (rtx operands[3], bool high);\n extern bool ix86_dep_by_shift_count (const_rtx set_insn, const_rtx use_insn);\n extern bool ix86_agi_dependent (rtx set_insn, rtx use_insn);\n extern void ix86_expand_unary_operator (enum rtx_code, enum machine_mode,"}, {"sha": "21be89fed83e28cf3ecf1a9d65683e01b12a3364", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 218, "deletions": 128, "changes": 346, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5e04b3b69417b07f66ed919b64e47055d3a2f9db/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5e04b3b69417b07f66ed919b64e47055d3a2f9db/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=5e04b3b69417b07f66ed919b64e47055d3a2f9db", "patch": "@@ -13849,6 +13849,19 @@ ix86_unary_operator_ok (enum rtx_code code ATTRIBUTE_UNUSED,\n   return TRUE;\n }\n \n+/* Return TRUE if the operands to a vec_interleave_{high,low}v2df\n+   are ok, keeping in mind the possible movddup alternative.  */\n+\n+bool\n+ix86_vec_interleave_v2df_operator_ok (rtx operands[3], bool high)\n+{\n+  if (MEM_P (operands[0]))\n+    return rtx_equal_p (operands[0], operands[1 + high]);\n+  if (MEM_P (operands[1]) && MEM_P (operands[2]))\n+    return TARGET_SSE3 && rtx_equal_p (operands[1], operands[2]);\n+  return true;\n+}\n+\n /* Post-reload splitter for converting an SF or DFmode value in an\n    SSE register into an unsigned SImode.  */\n \n@@ -21480,11 +21493,11 @@ static const struct builtin_description bdesc_special_args[] =\n   { OPTION_MASK_ISA_AVX, CODE_FOR_avx_vzeroall, \"__builtin_ia32_vzeroall\", IX86_BUILTIN_VZEROALL, UNKNOWN, (int) VOID_FTYPE_VOID },\n   { OPTION_MASK_ISA_AVX, CODE_FOR_avx_vzeroupper, \"__builtin_ia32_vzeroupper\", IX86_BUILTIN_VZEROUPPER, UNKNOWN, (int) VOID_FTYPE_VOID },\n \n-  { OPTION_MASK_ISA_AVX, CODE_FOR_avx_vbroadcastss, \"__builtin_ia32_vbroadcastss\", IX86_BUILTIN_VBROADCASTSS, UNKNOWN, (int) V4SF_FTYPE_PCFLOAT },\n-  { OPTION_MASK_ISA_AVX, CODE_FOR_avx_vbroadcastsd256, \"__builtin_ia32_vbroadcastsd256\", IX86_BUILTIN_VBROADCASTSD256, UNKNOWN, (int) V4DF_FTYPE_PCDOUBLE },\n-  { OPTION_MASK_ISA_AVX, CODE_FOR_avx_vbroadcastss256, \"__builtin_ia32_vbroadcastss256\", IX86_BUILTIN_VBROADCASTSS256, UNKNOWN, (int) V8SF_FTYPE_PCFLOAT },\n-  { OPTION_MASK_ISA_AVX, CODE_FOR_avx_vbroadcastf128_pd256, \"__builtin_ia32_vbroadcastf128_pd256\", IX86_BUILTIN_VBROADCASTPD256, UNKNOWN, (int) V4DF_FTYPE_PCV2DF },\n-  { OPTION_MASK_ISA_AVX, CODE_FOR_avx_vbroadcastf128_ps256, \"__builtin_ia32_vbroadcastf128_ps256\", IX86_BUILTIN_VBROADCASTPS256, UNKNOWN, (int) V8SF_FTYPE_PCV4SF },\n+  { OPTION_MASK_ISA_AVX, CODE_FOR_vec_dupv4sf, \"__builtin_ia32_vbroadcastss\", IX86_BUILTIN_VBROADCASTSS, UNKNOWN, (int) V4SF_FTYPE_PCFLOAT },\n+  { OPTION_MASK_ISA_AVX, CODE_FOR_vec_dupv4df, \"__builtin_ia32_vbroadcastsd256\", IX86_BUILTIN_VBROADCASTSD256, UNKNOWN, (int) V4DF_FTYPE_PCDOUBLE },\n+  { OPTION_MASK_ISA_AVX, CODE_FOR_vec_dupv8sf, \"__builtin_ia32_vbroadcastss256\", IX86_BUILTIN_VBROADCASTSS256, UNKNOWN, (int) V8SF_FTYPE_PCFLOAT },\n+  { OPTION_MASK_ISA_AVX, CODE_FOR_avx_vbroadcastf128_v4df, \"__builtin_ia32_vbroadcastf128_pd256\", IX86_BUILTIN_VBROADCASTPD256, UNKNOWN, (int) V4DF_FTYPE_PCV2DF },\n+  { OPTION_MASK_ISA_AVX, CODE_FOR_avx_vbroadcastf128_v8sf, \"__builtin_ia32_vbroadcastf128_ps256\", IX86_BUILTIN_VBROADCASTPS256, UNKNOWN, (int) V8SF_FTYPE_PCV4SF },\n \n   { OPTION_MASK_ISA_AVX, CODE_FOR_avx_movupd256, \"__builtin_ia32_loadupd256\", IX86_BUILTIN_LOADUPD256, UNKNOWN, (int) V4DF_FTYPE_PCDOUBLE },\n   { OPTION_MASK_ISA_AVX, CODE_FOR_avx_movups256, \"__builtin_ia32_loadups256\", IX86_BUILTIN_LOADUPS256, UNKNOWN, (int) V8SF_FTYPE_PCFLOAT },\n@@ -24597,7 +24610,7 @@ avx_vpermilp_parallel (rtx par, enum machine_mode mode)\n       if (!CONST_INT_P (er))\n \treturn 0;\n       ei = INTVAL (er);\n-      if (ei >= nelt)\n+      if (ei >= 2 * nelt)\n \treturn 0;\n       ipar[i] = ei;\n     }\n@@ -25713,6 +25726,16 @@ ix86_rtx_costs (rtx x, int code, int outer_code_i, int *total, bool speed)\n \t*total = 0;\n       return false;\n \n+    case VEC_SELECT:\n+    case VEC_CONCAT:\n+    case VEC_MERGE:\n+    case VEC_DUPLICATE:\n+      /* ??? Assume all of these vector manipulation patterns are\n+\t recognizable.  In which case they all pretty much have the\n+\t same cost.  */\n+     *total = COSTS_N_INSNS (1);\n+     return true;\n+\n     default:\n       return false;\n     }\n@@ -26547,16 +26570,43 @@ x86_emit_floatuns (rtx operands[2])\n   emit_label (donelab);\n }\n \f\n+/* AVX does not support 32-byte integer vector operations,\n+   thus the longest vector we are faced with is V16QImode.  */\n+#define MAX_VECT_LEN\t16\n+\n+struct expand_vec_perm_d\n+{\n+  rtx target, op0, op1;\n+  unsigned char perm[MAX_VECT_LEN];\n+  enum machine_mode vmode;\n+  unsigned char nelt;\n+  bool testing_p;\n+};\n+\n+static bool expand_vec_perm_1 (struct expand_vec_perm_d *d);\n+static bool expand_vec_perm_broadcast_1 (struct expand_vec_perm_d *d);\n+\n+/* Get a vector mode of the same size as the original but with elements\n+   twice as wide.  This is only guaranteed to apply to integral vectors.  */\n+\n+static inline enum machine_mode\n+get_mode_wider_vector (enum machine_mode o)\n+{\n+  /* ??? Rely on the ordering that genmodes.c gives to vectors.  */\n+  enum machine_mode n = GET_MODE_WIDER_MODE (o);\n+  gcc_assert (GET_MODE_NUNITS (o) == GET_MODE_NUNITS (n) * 2);\n+  gcc_assert (GET_MODE_SIZE (o) == GET_MODE_SIZE (n));\n+  return n;\n+}\n+\n /* A subroutine of ix86_expand_vector_init.  Store into TARGET a vector\n    with all elements equal to VAR.  Return true if successful.  */\n-/* ??? Call into the vec_perm support to implement the broadcast.  */\n \n static bool\n ix86_expand_vector_init_duplicate (bool mmx_ok, enum machine_mode mode,\n \t\t\t\t   rtx target, rtx val)\n {\n-  enum machine_mode hmode, smode, wsmode, wvmode;\n-  rtx x;\n+  bool ok;\n \n   switch (mode)\n     {\n@@ -26566,144 +26616,116 @@ ix86_expand_vector_init_duplicate (bool mmx_ok, enum machine_mode mode,\n \treturn false;\n       /* FALLTHRU */\n \n+    case V4DFmode:\n+    case V4DImode:\n+    case V8SFmode:\n+    case V8SImode:\n     case V2DFmode:\n     case V2DImode:\n     case V4SFmode:\n     case V4SImode:\n-      val = force_reg (GET_MODE_INNER (mode), val);\n-      x = gen_rtx_VEC_DUPLICATE (mode, val);\n-      emit_insn (gen_rtx_SET (VOIDmode, target, x));\n+      {\n+\trtx insn, dup;\n+\n+\t/* First attempt to recognize VAL as-is.  */\n+\tdup = gen_rtx_VEC_DUPLICATE (mode, val);\n+\tinsn = emit_insn (gen_rtx_SET (VOIDmode, target, dup));\n+\tif (recog_memoized (insn) < 0)\n+\t  {\n+\t    /* If that fails, force VAL into a register.  */\n+\t    XEXP (dup, 0) = force_reg (GET_MODE_INNER (mode), val);\n+\t    ok = recog_memoized (insn) >= 0;\n+\t    gcc_assert (ok);\n+\t  }\n+      }\n       return true;\n \n     case V4HImode:\n       if (!mmx_ok)\n \treturn false;\n       if (TARGET_SSE || TARGET_3DNOW_A)\n \t{\n+\t  rtx x;\n+\n \t  val = gen_lowpart (SImode, val);\n \t  x = gen_rtx_TRUNCATE (HImode, val);\n \t  x = gen_rtx_VEC_DUPLICATE (mode, x);\n \t  emit_insn (gen_rtx_SET (VOIDmode, target, x));\n \t  return true;\n \t}\n-      else\n-\t{\n-\t  smode = HImode;\n-\t  wsmode = SImode;\n-\t  wvmode = V2SImode;\n-\t  goto widen;\n-\t}\n+      goto widen;\n \n     case V8QImode:\n       if (!mmx_ok)\n \treturn false;\n-      smode = QImode;\n-      wsmode = HImode;\n-      wvmode = V4HImode;\n       goto widen;\n+\n     case V8HImode:\n       if (TARGET_SSE2)\n \t{\n+\t  struct expand_vec_perm_d dperm;\n \t  rtx tmp1, tmp2;\n-\t  /* Extend HImode to SImode using a paradoxical SUBREG.  */\n+\n+\tpermute:\n+\t  memset (&dperm, 0, sizeof (dperm));\n+\t  dperm.target = target;\n+\t  dperm.vmode = mode;\n+\t  dperm.nelt = GET_MODE_NUNITS (mode);\n+\t  dperm.op0 = dperm.op1 = gen_reg_rtx (mode);\n+\n+\t  /* Extend to SImode using a paradoxical SUBREG.  */\n \t  tmp1 = gen_reg_rtx (SImode);\n \t  emit_move_insn (tmp1, gen_lowpart (SImode, val));\n-\t  /* Insert the SImode value as low element of V4SImode vector. */\n-\t  tmp2 = gen_reg_rtx (V4SImode);\n-\t  tmp1 = gen_rtx_VEC_MERGE (V4SImode,\n-\t\t\t\t    gen_rtx_VEC_DUPLICATE (V4SImode, tmp1),\n-\t\t\t\t    CONST0_RTX (V4SImode),\n-\t\t\t\t    const1_rtx);\n-\t  emit_insn (gen_rtx_SET (VOIDmode, tmp2, tmp1));\n-\t  /* Cast the V4SImode vector back to a V8HImode vector.  */\n-\t  tmp1 = gen_reg_rtx (V8HImode);\n-\t  emit_move_insn (tmp1, gen_lowpart (V8HImode, tmp2));\n-\t  /* Duplicate the low short through the whole low SImode word.  */\n-\t  emit_insn (gen_vec_interleave_lowv8hi (tmp1, tmp1, tmp1));\n-\t  /* Cast the V8HImode vector back to a V4SImode vector.  */\n-\t  tmp2 = gen_reg_rtx (V4SImode);\n-\t  emit_move_insn (tmp2, gen_lowpart (V4SImode, tmp1));\n-\t  /* Replicate the low element of the V4SImode vector.  */\n-\t  emit_insn (gen_sse2_pshufd (tmp2, tmp2, const0_rtx));\n-\t  /* Cast the V2SImode back to V8HImode, and store in target.  */\n-\t  emit_move_insn (target, gen_lowpart (V8HImode, tmp2));\n-\t  return true;\n+\n+\t  /* Insert the SImode value as low element of a V4SImode vector. */\n+\t  tmp2 = gen_lowpart (V4SImode, dperm.op0);\n+\t  emit_insn (gen_vec_setv4si_0 (tmp2, CONST0_RTX (V4SImode), tmp1));\n+\n+\t  ok = (expand_vec_perm_1 (&dperm)\n+\t\t|| expand_vec_perm_broadcast_1 (&dperm));\n+\t  gcc_assert (ok);\n+\t  return ok;\n \t}\n-      smode = HImode;\n-      wsmode = SImode;\n-      wvmode = V4SImode;\n       goto widen;\n+\n     case V16QImode:\n       if (TARGET_SSE2)\n-\t{\n-\t  rtx tmp1, tmp2;\n-\t  /* Extend QImode to SImode using a paradoxical SUBREG.  */\n-\t  tmp1 = gen_reg_rtx (SImode);\n-\t  emit_move_insn (tmp1, gen_lowpart (SImode, val));\n-\t  /* Insert the SImode value as low element of V4SImode vector. */\n-\t  tmp2 = gen_reg_rtx (V4SImode);\n-\t  tmp1 = gen_rtx_VEC_MERGE (V4SImode,\n-\t\t\t\t    gen_rtx_VEC_DUPLICATE (V4SImode, tmp1),\n-\t\t\t\t    CONST0_RTX (V4SImode),\n-\t\t\t\t    const1_rtx);\n-\t  emit_insn (gen_rtx_SET (VOIDmode, tmp2, tmp1));\n-\t  /* Cast the V4SImode vector back to a V16QImode vector.  */\n-\t  tmp1 = gen_reg_rtx (V16QImode);\n-\t  emit_move_insn (tmp1, gen_lowpart (V16QImode, tmp2));\n-\t  /* Duplicate the low byte through the whole low SImode word.  */\n-\t  emit_insn (gen_vec_interleave_lowv16qi (tmp1, tmp1, tmp1));\n-\t  emit_insn (gen_vec_interleave_lowv16qi (tmp1, tmp1, tmp1));\n-\t  /* Cast the V16QImode vector back to a V4SImode vector.  */\n-\t  tmp2 = gen_reg_rtx (V4SImode);\n-\t  emit_move_insn (tmp2, gen_lowpart (V4SImode, tmp1));\n-\t  /* Replicate the low element of the V4SImode vector.  */\n-\t  emit_insn (gen_sse2_pshufd (tmp2, tmp2, const0_rtx));\n-\t  /* Cast the V2SImode back to V16QImode, and store in target.  */\n-\t  emit_move_insn (target, gen_lowpart (V16QImode, tmp2));\n-\t  return true;\n-\t}\n-      smode = QImode;\n-      wsmode = HImode;\n-      wvmode = V8HImode;\n+\tgoto permute;\n       goto widen;\n+\n     widen:\n       /* Replicate the value once into the next wider mode and recurse.  */\n-      val = convert_modes (wsmode, smode, val, true);\n-      x = expand_simple_binop (wsmode, ASHIFT, val,\n-\t\t\t       GEN_INT (GET_MODE_BITSIZE (smode)),\n-\t\t\t       NULL_RTX, 1, OPTAB_LIB_WIDEN);\n-      val = expand_simple_binop (wsmode, IOR, val, x, x, 1, OPTAB_LIB_WIDEN);\n-\n-      x = gen_reg_rtx (wvmode);\n-      if (!ix86_expand_vector_init_duplicate (mmx_ok, wvmode, x, val))\n-\tgcc_unreachable ();\n-      emit_move_insn (target, gen_lowpart (mode, x));\n-      return true;\n+      {\n+\tenum machine_mode smode, wsmode, wvmode;\n+\trtx x;\n+\n+\tsmode = GET_MODE_INNER (mode);\n+\twvmode = get_mode_wider_vector (mode);\n+\twsmode = GET_MODE_INNER (wvmode);\n+\n+\tval = convert_modes (wsmode, smode, val, true);\n+\tx = expand_simple_binop (wsmode, ASHIFT, val,\n+\t\t\t\t GEN_INT (GET_MODE_BITSIZE (smode)),\n+\t\t\t\t NULL_RTX, 1, OPTAB_LIB_WIDEN);\n+\tval = expand_simple_binop (wsmode, IOR, val, x, x, 1, OPTAB_LIB_WIDEN);\n+\n+\tx = gen_lowpart (wvmode, target);\n+\tok = ix86_expand_vector_init_duplicate (mmx_ok, wvmode, x, val);\n+\tgcc_assert (ok);\n+\treturn ok;\n+      }\n \n-    case V4DFmode:\n-      hmode = V2DFmode;\n-      goto half;\n-    case V4DImode:\n-      hmode = V2DImode;\n-      goto half;\n-    case V8SFmode:\n-      hmode = V4SFmode;\n-      goto half;\n-    case V8SImode:\n-      hmode = V4SImode;\n-      goto half;\n     case V16HImode:\n-      hmode = V8HImode;\n-      goto half;\n     case V32QImode:\n-      hmode = V16QImode;\n-      goto half;\n-half:\n       {\n-\trtx tmp = gen_reg_rtx (hmode);\n-\tix86_expand_vector_init_duplicate (mmx_ok, hmode, tmp, val);\n-\temit_insn (gen_rtx_SET (VOIDmode, target,\n-\t\t\t\tgen_rtx_VEC_CONCAT (mode, tmp, tmp)));\n+\tenum machine_mode hvmode = (mode == V16HImode ? V8HImode : V16QImode);\n+\trtx x = gen_reg_rtx (hvmode);\n+\n+\tok = ix86_expand_vector_init_duplicate (false, hvmode, x, val);\n+\tgcc_assert (ok);\n+\n+\tx = gen_rtx_VEC_CONCAT (mode, x, x);\n+\temit_insn (gen_rtx_SET (VOIDmode, target, x));\n       }\n       return true;\n \n@@ -29085,19 +29107,6 @@ ix86_vectorize_builtin_vec_perm (tree vec_type, tree *mask_type)\n   return ix86_builtins[(int) fcode];\n }\n \n-/* AVX does not support 32-byte integer vector operations,\n-   thus the longest vector we are faced with is V16QImode.  */\n-#define MAX_VECT_LEN\t16\n-\n-struct expand_vec_perm_d\n-{\n-  rtx target, op0, op1;\n-  unsigned char perm[MAX_VECT_LEN];\n-  enum machine_mode vmode;\n-  unsigned char nelt;\n-  bool testing_p;\n-};\n-\n /* Return a vector mode with twice as many elements as VMODE.  */\n /* ??? Consider moving this to a table generated by genmodes.c.  */\n \n@@ -29739,8 +29748,8 @@ expand_vec_perm_pshufb2 (struct expand_vec_perm_d *d)\n   return true;\n }\n \n-/* A subroutine of ix86_expand_vec_perm_builtin_1.  Pattern match\n-   extract-even and extract-odd permutations.  */\n+/* A subroutine of ix86_expand_vec_perm_builtin_1.  Implement extract-even\n+   and extract-odd permutations.  */\n \n static bool\n expand_vec_perm_even_odd_1 (struct expand_vec_perm_d *d, unsigned odd)\n@@ -29855,6 +29864,9 @@ expand_vec_perm_even_odd_1 (struct expand_vec_perm_d *d, unsigned odd)\n   return true;\n }\n \n+/* A subroutine of ix86_expand_vec_perm_builtin_1.  Pattern match\n+   extract-even and extract-odd permutations.  */\n+\n static bool\n expand_vec_perm_even_odd (struct expand_vec_perm_d *d)\n {\n@@ -29871,15 +29883,92 @@ expand_vec_perm_even_odd (struct expand_vec_perm_d *d)\n   return expand_vec_perm_even_odd_1 (d, odd);\n }\n \n+/* A subroutine of ix86_expand_vec_perm_builtin_1.  Implement broadcast\n+   permutations.  We assume that expand_vec_perm_1 has already failed.  */\n+\n+static bool\n+expand_vec_perm_broadcast_1 (struct expand_vec_perm_d *d)\n+{\n+  unsigned elt = d->perm[0], nelt2 = d->nelt / 2;\n+  enum machine_mode vmode = d->vmode;\n+  unsigned char perm2[4];\n+  rtx op0 = d->op0;\n+  bool ok;\n+\n+  switch (vmode)\n+    {\n+    case V4DFmode:\n+    case V8SFmode:\n+      /* These are special-cased in sse.md so that we can optionally\n+\t use the vbroadcast instruction.  They expand to two insns\n+\t if the input happens to be in a register.  */\n+      gcc_unreachable ();\n+\n+    case V2DFmode:\n+    case V2DImode:\n+    case V4SFmode:\n+    case V4SImode:\n+      /* These are always implementable using standard shuffle patterns.  */\n+      gcc_unreachable ();\n+\n+    case V8HImode:\n+    case V16QImode:\n+      /* These can be implemented via interleave.  We save one insn by\n+\t stopping once we have promoted to V4SImode and then use pshufd.  */\n+      do\n+\t{\n+\t  optab otab = vec_interleave_low_optab;\n+\n+\t  if (elt >= nelt2)\n+\t    {\n+\t      otab = vec_interleave_high_optab;\n+\t      elt -= nelt2;\n+\t    }\n+\t  nelt2 /= 2;\n+\n+\t  op0 = expand_binop (vmode, otab, op0, op0, NULL, 0, OPTAB_DIRECT);\n+\t  vmode = get_mode_wider_vector (vmode);\n+\t  op0 = gen_lowpart (vmode, op0);\n+\t}\n+      while (vmode != V4SImode);\n+\n+      memset (perm2, elt, 4);\n+      ok = expand_vselect (gen_lowpart (V4SImode, d->target), op0, perm2, 4);\n+      gcc_assert (ok);\n+      return true;\n+\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+/* A subroutine of ix86_expand_vec_perm_builtin_1.  Pattern match\n+   broadcast permutations.  */\n+\n+static bool\n+expand_vec_perm_broadcast (struct expand_vec_perm_d *d)\n+{\n+  unsigned i, elt, nelt = d->nelt;\n+\n+  if (d->op0 != d->op1)\n+    return false;\n+\n+  elt = d->perm[0];\n+  for (i = 1; i < nelt; ++i)\n+    if (d->perm[i] != elt)\n+      return false;\n+\n+  return expand_vec_perm_broadcast_1 (d);\n+}\n+\n /* The guts of ix86_expand_vec_perm_builtin, also used by the ok hook.\n    With all of the interface bits taken care of, perform the expansion\n    in D and return true on success.  */\n \n static bool\n ix86_expand_vec_perm_builtin_1 (struct expand_vec_perm_d *d)\n {\n-  /* First things first -- check if the instruction is implementable\n-     with a single instruction.  */\n+  /* Try a single instruction expansion.  */\n   if (expand_vec_perm_1 (d))\n     return true;\n \n@@ -29894,13 +29983,16 @@ ix86_expand_vec_perm_builtin_1 (struct expand_vec_perm_d *d)\n   if (expand_vec_perm_interleave2 (d))\n     return true;\n \n+  if (expand_vec_perm_broadcast (d))\n+    return true;\n+\n   /* Try sequences of three instructions.  */\n \n   if (expand_vec_perm_pshufb2 (d))\n     return true;\n \n   /* ??? Look for narrow permutations whose element orderings would\n-     allow the promition to a wider mode.  */\n+     allow the promotion to a wider mode.  */\n \n   /* ??? Look for sequences of interleave or a wider permute that place\n      the data into the correct lanes for a half-vector shuffle like\n@@ -29912,8 +30004,6 @@ ix86_expand_vec_perm_builtin_1 (struct expand_vec_perm_d *d)\n   if (expand_vec_perm_even_odd (d))\n     return true;\n \n-  /* ??? Pattern match broadcast.  */\n-\n   return false;\n }\n "}, {"sha": "8f901cd87544241dfb3f7b8cbb5cd8e89fa3a833", "filename": "gcc/config/i386/predicates.md", "status": "modified", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5e04b3b69417b07f66ed919b64e47055d3a2f9db/gcc%2Fconfig%2Fi386%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5e04b3b69417b07f66ed919b64e47055d3a2f9db/gcc%2Fconfig%2Fi386%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fpredicates.md?ref=5e04b3b69417b07f66ed919b64e47055d3a2f9db", "patch": "@@ -1241,3 +1241,20 @@\n (define_predicate \"avx_vperm2f128_v4df_operand\"\n   (and (match_code \"parallel\")\n        (match_test \"avx_vperm2f128_parallel (op, V4DFmode)\")))\n+\n+;; Return 1 if OP is a parallel for a vbroadcast permute.\n+\n+(define_predicate \"avx_vbroadcast_operand\"\n+  (and (match_code \"parallel\")\n+       (match_code \"const_int\" \"a\"))\n+{\n+  rtx elt = XVECEXP (op, 0, 0);\n+  int i, nelt = XVECLEN (op, 0);\n+\n+  /* Don't bother checking there are the right number of operands,\n+     merely that they're all identical.  */\n+  for (i = 1; i < nelt; ++i)\n+    if (XVECEXP (op, 0, i) != elt)\n+      return false;\n+  return true;\n+})"}, {"sha": "08a3b5b5c89a4bee8704a1b211a9ab89fffbd404", "filename": "gcc/config/i386/sse.md", "status": "modified", "additions": 340, "deletions": 166, "changes": 506, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5e04b3b69417b07f66ed919b64e47055d3a2f9db/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5e04b3b69417b07f66ed919b64e47055d3a2f9db/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=5e04b3b69417b07f66ed919b64e47055d3a2f9db", "patch": "@@ -54,6 +54,7 @@\n \n (define_mode_iterator AVX256MODEF2P [V8SF V4DF])\n (define_mode_iterator AVX256MODE2P [V8SI V8SF V4DF])\n+(define_mode_iterator AVX256MODE24P [V8SI V8SF V4DI V4DF])\n (define_mode_iterator AVX256MODE4P [V4DI V4DF])\n (define_mode_iterator AVX256MODE8P [V8SI V8SF])\n (define_mode_iterator AVXMODEF2P [V4SF V2DF V8SF V4DF])\n@@ -96,6 +97,8 @@\n \n (define_mode_attr ssemodesuffixf2c [(V4SF \"s\") (V2DF \"d\")])\n \n+(define_mode_attr ssescalarmodesuffix2s [(V4SF \"ss\") (V4SI \"d\")])\n+\n ;; Mapping of the max integer size for xop rotate immediate constraint\n (define_mode_attr sserotatemax [(V16QI \"7\") (V8HI \"15\") (V4SI \"31\") (V2DI \"63\")])\n \n@@ -125,17 +128,18 @@\n   [(V16QI \"V4SF\") (V8HI \"V4SF\") (V4SI \"V4SF\") (V2DI \"V4SF\")\n    (V32QI \"V8SF\") (V16HI \"V8SF\") (V8SI \"V8SF\") (V4DI \"V8SF\")])\n (define_mode_attr avxhalfvecmode\n-  [(V4SF \"V2SF\") (V32QI \"V16QI\")  (V16HI \"V8HI\") (V8SI \"V4SI\")\n-   (V4DI \"V2DI\") (V8SF \"V4SF\") (V4DF \"V2DF\")])\n+  [(V32QI \"V16QI\") (V16HI \"V8HI\") (V8SI \"V4SI\") (V4DI \"V2DI\")\n+   (V8SF \"V4SF\") (V4DF \"V2DF\")\n+   (V16QI  \"V8QI\") (V8HI  \"V4HI\") (V4SI \"V2SI\") (V4SF \"V2SF\")])\n (define_mode_attr avxscalarmode\n-  [(V16QI \"QI\") (V8HI \"HI\") (V4SI \"SI\") (V4SF \"SF\") (V2DF \"DF\")\n-   (V8SF \"SF\") (V4DF \"DF\")])\n+  [(V16QI \"QI\") (V8HI  \"HI\") (V4SI \"SI\") (V2DI \"DI\") (V4SF \"SF\") (V2DF \"DF\")\n+   (V32QI \"QI\") (V16HI \"HI\") (V8SI \"SI\") (V4DI \"DI\") (V8SF \"SF\") (V4DF \"DF\")])\n (define_mode_attr avxcvtvecmode\n   [(V4SF \"V4SI\") (V8SF \"V8SI\") (V4SI \"V4SF\") (V8SI \"V8SF\")])\n (define_mode_attr avxpermvecmode\n   [(V2DF \"V2DI\") (V4SF \"V4SI\") (V4DF \"V4DI\") (V8SF \"V8SI\")])\n (define_mode_attr avxmodesuffixf2c\n-  [(V4SF \"s\") (V2DF \"d\") (V8SF \"s\") (V4DF \"d\")])\n+  [(V4SF \"s\") (V2DF \"d\") (V8SI \"s\") (V8SF \"s\") (V4DI \"d\") (V4DF \"d\")])\n (define_mode_attr avxmodesuffixp\n  [(V2DF \"pd\") (V4SI \"si\") (V4SF \"ps\") (V8SF \"ps\") (V8SI \"si\")\n   (V4DF \"pd\")])\n@@ -4012,14 +4016,27 @@\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"mode\" \"SF\")])\n \n+(define_expand \"vec_dupv4sf\"\n+  [(set (match_operand:V4SF 0 \"register_operand\" \"\")\n+\t(vec_duplicate:V4SF\n+\t  (match_operand:SF 1 \"nonimmediate_operand\" \"\")))]\n+  \"TARGET_SSE\"\n+{\n+  if (!TARGET_AVX)\n+    operands[1] = force_reg (V4SFmode, operands[1]);\n+})\n+\n (define_insn \"*vec_dupv4sf_avx\"\n-  [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n+  [(set (match_operand:V4SF 0 \"register_operand\" \"=x,x\")\n \t(vec_duplicate:V4SF\n-\t  (match_operand:SF 1 \"register_operand\" \"x\")))]\n+\t  (match_operand:SF 1 \"nonimmediate_operand\" \"x,m\")))]\n   \"TARGET_AVX\"\n-  \"vshufps\\t{$0, %1, %1, %0|%0, %1, %1, 0}\"\n-  [(set_attr \"type\" \"sselog1\")\n-   (set_attr \"length_immediate\" \"1\")\n+  \"@\n+   vshufps\\t{$0, %1, %1, %0|%0, %1, %1, 0}\n+   vbroadcastss\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sselog1,ssemov\")\n+   (set_attr \"length_immediate\" \"1,0\")\n+   (set_attr \"prefix_extra\" \"0,1\")\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"V4SF\")])\n \n@@ -4125,35 +4142,78 @@\n   DONE;\n })\n \n-(define_insn \"*vec_setv4sf_0_avx\"\n-  [(set (match_operand:V4SF 0 \"nonimmediate_operand\"  \"=x,x,x,m\")\n-\t(vec_merge:V4SF\n-\t  (vec_duplicate:V4SF\n-\t    (match_operand:SF 2 \"general_operand\"     \" x,m,*r,x*rfF\"))\n-\t  (match_operand:V4SF 1 \"vector_move_operand\" \" x,C,C ,0\")\n+(define_insn \"*vec_set<mode>_0_avx\"\n+  [(set (match_operand:SSEMODE4S 0 \"nonimmediate_operand\"  \"=x,x, x,x,  x,m\")\n+\t(vec_merge:SSEMODE4S\n+\t  (vec_duplicate:SSEMODE4S\n+\t    (match_operand:<ssescalarmode> 2\n+\t      \"general_operand\"                            \" x,m,*r,x,*rm,x*rfF\"))\n+\t  (match_operand:SSEMODE4S 1 \"vector_move_operand\" \" C,C, C,x,  x,0\")\n \t  (const_int 1)))]\n   \"TARGET_AVX\"\n   \"@\n-   vmovss\\t{%2, %1, %0|%0, %1, %2}\n-   vmovss\\t{%2, %0|%0, %2}\n+   vinsertps\\t{$0xe, %2, %2, %0|%0, %2, %2, 0xe}\n+   vmov<ssescalarmodesuffix2s>\\t{%2, %0|%0, %2}\n    vmovd\\t{%2, %0|%0, %2}\n+   vmovss\\t{%2, %1, %0|%0, %1, %2}\n+   vpinsrd\\t{$0, %2, %1, %0|%0, %1, %2, 0}\n+   #\"\n+  [(set_attr \"type\" \"sselog,ssemov,ssemov,ssemov,sselog,*\")\n+   (set_attr \"prefix_extra\" \"*,*,*,*,1,*\")\n+   (set_attr \"length_immediate\" \"*,*,*,*,1,*\")\n+   (set_attr \"prefix\" \"vex\")\n+   (set_attr \"mode\" \"SF,<ssescalarmode>,SI,SF,TI,*\")])\n+\n+(define_insn \"*vec_set<mode>_0_sse4_1\"\n+  [(set (match_operand:SSEMODE4S 0 \"nonimmediate_operand\"  \"=x,x, x,x,  x,m\")\n+\t(vec_merge:SSEMODE4S\n+\t  (vec_duplicate:SSEMODE4S\n+\t    (match_operand:<ssescalarmode> 2\n+\t      \"general_operand\"                            \" x,m,*r,x,*rm,*rfF\"))\n+\t  (match_operand:SSEMODE4S 1 \"vector_move_operand\" \" C,C, C,0,  0,0\")\n+\t  (const_int 1)))]\n+  \"TARGET_SSE4_1\"\n+  \"@\n+   insertps\\t{$0xe, %2, %0|%0, %2, 0xe}\n+   mov<ssescalarmodesuffix2s>\\t{%2, %0|%0, %2}\n+   movd\\t{%2, %0|%0, %2}\n+   movss\\t{%2, %0|%0, %2}\n+   pinsrd\\t{$0, %2, %0|%0, %2, 0}\n+   #\"\n+  [(set_attr \"type\" \"sselog,ssemov,ssemov,ssemov,sselog,*\")\n+   (set_attr \"prefix_extra\" \"*,*,*,*,1,*\")\n+   (set_attr \"length_immediate\" \"*,*,*,*,1,*\")\n+   (set_attr \"mode\" \"SF,<ssescalarmode>,SI,SF,TI,*\")])\n+\n+(define_insn \"*vec_set<mode>_0_sse2\"\n+  [(set (match_operand:SSEMODE4S 0 \"nonimmediate_operand\"  \"=x, x,x,m\")\n+\t(vec_merge:SSEMODE4S\n+\t  (vec_duplicate:SSEMODE4S\n+\t    (match_operand:<ssescalarmode> 2\n+\t      \"general_operand\"                            \" m,*r,x,x*rfF\"))\n+\t  (match_operand:SSEMODE4S 1 \"vector_move_operand\" \" C, C,0,0\")\n+\t  (const_int 1)))]\n+  \"TARGET_SSE2\"\n+  \"@\n+   mov<ssescalarmodesuffix2s>\\t{%2, %0|%0, %2}\n+   movd\\t{%2, %0|%0, %2}\n+   movss\\t{%2, %0|%0, %2}\n    #\"\n   [(set_attr \"type\" \"ssemov\")\n-   (set_attr \"prefix\" \"vex\")\n-   (set_attr \"mode\" \"SF\")])\n-\n-(define_insn \"vec_setv4sf_0\"\n-  [(set (match_operand:V4SF 0 \"nonimmediate_operand\"  \"=x,x,Y2,m\")\n-\t(vec_merge:V4SF\n-\t  (vec_duplicate:V4SF\n-\t    (match_operand:SF 2 \"general_operand\"     \" x,m,*r,x*rfF\"))\n-\t  (match_operand:V4SF 1 \"vector_move_operand\" \" 0,C,C ,0\")\n+   (set_attr \"mode\" \"<ssescalarmode>,SI,SF,*\")])\n+\n+(define_insn \"vec_set<mode>_0\"\n+  [(set (match_operand:SSEMODE4S 0 \"nonimmediate_operand\"  \"=x,x,m\")\n+\t(vec_merge:SSEMODE4S\n+\t  (vec_duplicate:SSEMODE4S\n+\t    (match_operand:<ssescalarmode> 2\n+\t      \"general_operand\"                            \" m,x,x*rfF\"))\n+\t  (match_operand:SSEMODE4S 1 \"vector_move_operand\" \" C,0,0\")\n \t  (const_int 1)))]\n   \"TARGET_SSE\"\n   \"@\n    movss\\t{%2, %0|%0, %2}\n    movss\\t{%2, %0|%0, %2}\n-   movd\\t{%2, %0|%0, %2}\n    #\"\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"mode\" \"SF\")])\n@@ -4484,32 +4544,54 @@\n    (set_attr \"mode\" \"V4DF\")])\n \n (define_expand \"vec_interleave_highv2df\"\n-  [(set (match_operand:V2DF 0 \"nonimmediate_operand\" \"\")\n+  [(set (match_operand:V2DF 0 \"register_operand\" \"\")\n \t(vec_select:V2DF\n \t  (vec_concat:V4DF\n \t    (match_operand:V2DF 1 \"nonimmediate_operand\" \"\")\n \t    (match_operand:V2DF 2 \"nonimmediate_operand\" \"\"))\n \t  (parallel [(const_int 1)\n \t\t     (const_int 3)])))]\n   \"TARGET_SSE2\"\n-  \"ix86_fixup_binary_operands (UNKNOWN, V2DFmode, operands);\")\n+{\n+  if (!ix86_vec_interleave_v2df_operator_ok (operands, 1))\n+    operands[2] = force_reg (V2DFmode, operands[2]);\n+})\n \n (define_insn \"*avx_interleave_highv2df\"\n-  [(set (match_operand:V2DF 0 \"nonimmediate_operand\"     \"=x,x,m\")\n+  [(set (match_operand:V2DF 0 \"nonimmediate_operand\"     \"=x,x,x,m\")\n \t(vec_select:V2DF\n \t  (vec_concat:V4DF\n-\t    (match_operand:V2DF 1 \"nonimmediate_operand\" \" x,o,x\")\n-\t    (match_operand:V2DF 2 \"nonimmediate_operand\" \" x,x,0\"))\n+\t    (match_operand:V2DF 1 \"nonimmediate_operand\" \" x,o,o,x\")\n+\t    (match_operand:V2DF 2 \"nonimmediate_operand\" \" x,1,x,0\"))\n \t  (parallel [(const_int 1)\n \t\t     (const_int 3)])))]\n-  \"TARGET_AVX && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n+  \"TARGET_AVX && ix86_vec_interleave_v2df_operator_ok (operands, 1)\"\n   \"@\n    vunpckhpd\\t{%2, %1, %0|%0, %1, %2}\n+   vmovddup\\t{%H1, %0|%0, %H1}\n    vmovlpd\\t{%H1, %2, %0|%0, %2, %H1}\n    vmovhpd\\t{%1, %0|%0, %1}\"\n-  [(set_attr \"type\" \"sselog,ssemov,ssemov\")\n+  [(set_attr \"type\" \"sselog,sselog,ssemov,ssemov\")\n    (set_attr \"prefix\" \"vex\")\n-   (set_attr \"mode\" \"V2DF,V1DF,V1DF\")])\n+   (set_attr \"mode\" \"V2DF,V2DF,V1DF,V1DF\")])\n+\n+(define_insn \"*sse3_interleave_highv2df\"\n+  [(set (match_operand:V2DF 0 \"nonimmediate_operand\"     \"=x,x,x,m\")\n+\t(vec_select:V2DF\n+\t  (vec_concat:V4DF\n+\t    (match_operand:V2DF 1 \"nonimmediate_operand\" \" 0,o,o,x\")\n+\t    (match_operand:V2DF 2 \"nonimmediate_operand\" \" x,1,0,0\"))\n+\t  (parallel [(const_int 1)\n+\t\t     (const_int 3)])))]\n+  \"TARGET_SSE3 && ix86_vec_interleave_v2df_operator_ok (operands, 1)\"\n+  \"@\n+   unpckhpd\\t{%2, %0|%0, %2}\n+   movddup\\t{%H1, %0|%0, %H1}\n+   movlpd\\t{%H1, %0|%0, %H1}\n+   movhpd\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sselog,sselog,ssemov,ssemov\")\n+   (set_attr \"prefix_data16\" \"*,*,1,1\")\n+   (set_attr \"mode\" \"V2DF,V2DF,V1DF,V1DF\")])\n \n (define_insn \"*sse2_interleave_highv2df\"\n   [(set (match_operand:V2DF 0 \"nonimmediate_operand\"     \"=x,x,m\")\n@@ -4519,7 +4601,7 @@\n \t    (match_operand:V2DF 2 \"nonimmediate_operand\" \" x,0,0\"))\n \t  (parallel [(const_int 1)\n \t\t     (const_int 3)])))]\n-  \"TARGET_SSE2 && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n+  \"TARGET_SSE2 && ix86_vec_interleave_v2df_operator_ok (operands, 1)\"\n   \"@\n    unpckhpd\\t{%2, %0|%0, %2}\n    movlpd\\t{%H1, %0|%0, %H1}\n@@ -4528,110 +4610,95 @@\n    (set_attr \"prefix_data16\" \"*,1,1\")\n    (set_attr \"mode\" \"V2DF,V1DF,V1DF\")])\n \n-(define_insn \"avx_movddup256\"\n-  [(set (match_operand:V4DF 0 \"register_operand\" \"=x\")\n+;; Recall that the 256-bit unpck insns only shuffle within their lanes.\n+(define_expand \"avx_movddup256\"\n+  [(set (match_operand:V4DF 0 \"register_operand\" \"\")\n \t(vec_select:V4DF\n \t  (vec_concat:V8DF\n-\t    (match_operand:V4DF 1 \"nonimmediate_operand\" \"xm\")\n+\t    (match_operand:V4DF 1 \"nonimmediate_operand\" \"\")\n \t    (match_dup 1))\n-\t  (parallel [(const_int 0) (const_int 2)\n-\t\t     (const_int 4) (const_int 6)])))]\n+\t  (parallel [(const_int 0) (const_int 4)\n+\t\t     (const_int 2) (const_int 6)])))]\n   \"TARGET_AVX\"\n-  \"vmovddup\\t{%1, %0|%0, %1}\"\n-  [(set_attr \"type\" \"sselog1\")\n-   (set_attr \"prefix\" \"vex\")\n-   (set_attr \"mode\" \"V4DF\")])\n-\n-(define_insn \"*avx_movddup\"\n-  [(set (match_operand:V2DF 0 \"nonimmediate_operand\"     \"=x,o\")\n-\t(vec_select:V2DF\n-\t  (vec_concat:V4DF\n-\t    (match_operand:V2DF 1 \"nonimmediate_operand\" \"xm,x\")\n-\t    (match_dup 1))\n-\t  (parallel [(const_int 0)\n-\t\t     (const_int 2)])))]\n-  \"TARGET_AVX && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n-  \"@\n-   vmovddup\\t{%1, %0|%0, %1}\n-   #\"\n-  [(set_attr \"type\" \"sselog1,ssemov\")\n-   (set_attr \"prefix\" \"vex\")\n-   (set_attr \"mode\" \"V2DF\")])\n-\n-(define_insn \"*sse3_movddup\"\n-  [(set (match_operand:V2DF 0 \"nonimmediate_operand\"     \"=x,o\")\n-\t(vec_select:V2DF\n-\t  (vec_concat:V4DF\n-\t    (match_operand:V2DF 1 \"nonimmediate_operand\" \"xm,x\")\n-\t    (match_dup 1))\n-\t  (parallel [(const_int 0)\n-\t\t     (const_int 2)])))]\n-  \"TARGET_SSE3 && !(MEM_P (operands[0]) && MEM_P (operands[1]))\"\n-  \"@\n-   movddup\\t{%1, %0|%0, %1}\n-   #\"\n-  [(set_attr \"type\" \"sselog1,ssemov\")\n-   (set_attr \"mode\" \"V2DF\")])\n-\n-(define_split\n-  [(set (match_operand:V2DF 0 \"memory_operand\" \"\")\n-\t(vec_select:V2DF\n-\t  (vec_concat:V4DF\n-\t    (match_operand:V2DF 1 \"register_operand\" \"\")\n-\t    (match_dup 1))\n-\t  (parallel [(const_int 0)\n-\t\t     (const_int 2)])))]\n-  \"TARGET_SSE3 && reload_completed\"\n-  [(const_int 0)]\n-{\n-  rtx low = gen_rtx_REG (DFmode, REGNO (operands[1]));\n-  emit_move_insn (adjust_address (operands[0], DFmode, 0), low);\n-  emit_move_insn (adjust_address (operands[0], DFmode, 8), low);\n-  DONE;\n-})\n+  \"\")\n \n-;; Recall that the 256-bit unpck insns only shuffle within their lanes.\n-(define_insn \"avx_unpcklpd256\"\n-  [(set (match_operand:V4DF 0 \"register_operand\" \"=x\")\n+(define_expand \"avx_unpcklpd256\"\n+  [(set (match_operand:V4DF 0 \"register_operand\" \"\")\n \t(vec_select:V4DF\n \t  (vec_concat:V8DF\n-\t    (match_operand:V4DF 1 \"register_operand\" \"x\")\n-\t    (match_operand:V4DF 2 \"nonimmediate_operand\" \"xm\"))\n+\t    (match_operand:V4DF 1 \"register_operand\" \"\")\n+\t    (match_operand:V4DF 2 \"nonimmediate_operand\" \"\"))\n \t  (parallel [(const_int 0) (const_int 4)\n \t\t     (const_int 2) (const_int 6)])))]\n   \"TARGET_AVX\"\n-  \"vunpcklpd\\t{%2, %1, %0|%0, %1, %2}\"\n+  \"\")\n+\n+(define_insn \"*avx_unpcklpd256\"\n+  [(set (match_operand:V4DF 0 \"register_operand\"         \"=x,x\")\n+\t(vec_select:V4DF\n+\t  (vec_concat:V8DF\n+\t    (match_operand:V4DF 1 \"nonimmediate_operand\" \"xm,x\")\n+\t    (match_operand:V4DF 2 \"nonimmediate_operand\" \" 1,xm\"))\n+\t  (parallel [(const_int 0) (const_int 4)\n+\t\t     (const_int 2) (const_int 6)])))]\n+  \"TARGET_AVX\n+   && (!MEM_P (operands[1]) || rtx_equal_p (operands[1], operands[2]))\"\n+  \"@\n+   vmovddup\\t{%1, %0|%0, %1}\n+   vunpcklpd\\t{%2, %1, %0|%0, %1, %2}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"V4DF\")])\n \n (define_expand \"vec_interleave_lowv2df\"\n-  [(set (match_operand:V2DF 0 \"nonimmediate_operand\" \"\")\n+  [(set (match_operand:V2DF 0 \"register_operand\" \"\")\n \t(vec_select:V2DF\n \t  (vec_concat:V4DF\n \t    (match_operand:V2DF 1 \"nonimmediate_operand\" \"\")\n \t    (match_operand:V2DF 2 \"nonimmediate_operand\" \"\"))\n \t  (parallel [(const_int 0)\n \t\t     (const_int 2)])))]\n   \"TARGET_SSE2\"\n-  \"ix86_fixup_binary_operands (UNKNOWN, V2DFmode, operands);\")\n+{\n+  if (!ix86_vec_interleave_v2df_operator_ok (operands, 0))\n+    operands[1] = force_reg (V2DFmode, operands[1]);\n+})\n \n (define_insn \"*avx_interleave_lowv2df\"\n-  [(set (match_operand:V2DF 0 \"nonimmediate_operand\"     \"=x,x,o\")\n+  [(set (match_operand:V2DF 0 \"nonimmediate_operand\"     \"=x,x,x,o\")\n \t(vec_select:V2DF\n \t  (vec_concat:V4DF\n-\t    (match_operand:V2DF 1 \"nonimmediate_operand\" \" x,x,0\")\n-\t    (match_operand:V2DF 2 \"nonimmediate_operand\" \" x,m,x\"))\n+\t    (match_operand:V2DF 1 \"nonimmediate_operand\" \" x,m,x,0\")\n+\t    (match_operand:V2DF 2 \"nonimmediate_operand\" \" x,1,m,x\"))\n \t  (parallel [(const_int 0)\n \t\t     (const_int 2)])))]\n-  \"TARGET_AVX && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n+  \"TARGET_AVX && ix86_vec_interleave_v2df_operator_ok (operands, 0)\"\n   \"@\n    vunpcklpd\\t{%2, %1, %0|%0, %1, %2}\n+   vmovddup\\t{%1, %0|%0, %1}\n    vmovhpd\\t{%2, %1, %0|%0, %1, %2}\n    vmovlpd\\t{%2, %H0|%H0, %2}\"\n-  [(set_attr \"type\" \"sselog,ssemov,ssemov\")\n+  [(set_attr \"type\" \"sselog,sselog,ssemov,ssemov\")\n    (set_attr \"prefix\" \"vex\")\n-   (set_attr \"mode\" \"V2DF,V1DF,V1DF\")])\n+   (set_attr \"mode\" \"V2DF,V2DF,V1DF,V1DF\")])\n+\n+(define_insn \"*sse3_interleave_lowv2df\"\n+  [(set (match_operand:V2DF 0 \"nonimmediate_operand\"     \"=x,x,x,o\")\n+\t(vec_select:V2DF\n+\t  (vec_concat:V4DF\n+\t    (match_operand:V2DF 1 \"nonimmediate_operand\" \" 0,m,0,0\")\n+\t    (match_operand:V2DF 2 \"nonimmediate_operand\" \" x,1,m,x\"))\n+\t  (parallel [(const_int 0)\n+\t\t     (const_int 2)])))]\n+  \"TARGET_SSE3 && ix86_vec_interleave_v2df_operator_ok (operands, 0)\"\n+  \"@\n+   unpcklpd\\t{%2, %0|%0, %2}\n+   movddup\\t{%1, %0|%0, %1}\n+   movhpd\\t{%2, %0|%0, %2}\n+   movlpd\\t{%2, %H0|%H0, %2}\"\n+  [(set_attr \"type\" \"sselog,sselog,ssemov,ssemov\")\n+   (set_attr \"prefix_data16\" \"*,*,1,1\")\n+   (set_attr \"mode\" \"V2DF,V2DF,V1DF,V1DF\")])\n \n (define_insn \"*sse2_interleave_lowv2df\"\n   [(set (match_operand:V2DF 0 \"nonimmediate_operand\"     \"=x,x,o\")\n@@ -4641,7 +4708,7 @@\n \t    (match_operand:V2DF 2 \"nonimmediate_operand\" \" x,m,x\"))\n \t  (parallel [(const_int 0)\n \t\t     (const_int 2)])))]\n-  \"TARGET_SSE2 && !(MEM_P (operands[1]) && MEM_P (operands[2]))\"\n+  \"TARGET_SSE2 && ix86_vec_interleave_v2df_operator_ok (operands, 0)\"\n   \"@\n    unpcklpd\\t{%2, %0|%0, %2}\n    movhpd\\t{%2, %0|%0, %2}\n@@ -4650,6 +4717,37 @@\n    (set_attr \"prefix_data16\" \"*,1,1\")\n    (set_attr \"mode\" \"V2DF,V1DF,V1DF\")])\n \n+(define_split\n+  [(set (match_operand:V2DF 0 \"memory_operand\" \"\")\n+\t(vec_select:V2DF\n+\t  (vec_concat:V4DF\n+\t    (match_operand:V2DF 1 \"register_operand\" \"\")\n+\t    (match_dup 1))\n+\t  (parallel [(const_int 0)\n+\t\t     (const_int 2)])))]\n+  \"TARGET_SSE3 && reload_completed\"\n+  [(const_int 0)]\n+{\n+  rtx low = gen_rtx_REG (DFmode, REGNO (operands[1]));\n+  emit_move_insn (adjust_address (operands[0], DFmode, 0), low);\n+  emit_move_insn (adjust_address (operands[0], DFmode, 8), low);\n+  DONE;\n+})\n+\n+(define_split\n+  [(set (match_operand:V2DF 0 \"register_operand\" \"\")\n+\t(vec_select:V2DF\n+\t  (vec_concat:V4DF\n+\t    (match_operand:V2DF 1 \"memory_operand\" \"\")\n+\t    (match_dup 1))\n+\t  (parallel [(match_operand:SI 2 \"const_0_to_1_operand\" \"\")\n+\t\t     (match_operand:SI 3 \"const_int_operand\" \"\")])))]\n+  \"TARGET_SSE3 && INTVAL (operands[2]) + 2 == INTVAL (operands[3])\"\n+  [(set (match_dup 0) (vec_duplicate:V2DF (match_dup 1)))]\n+{\n+  operands[1] = adjust_address (operands[1], DFmode, INTVAL (operands[2]) * 8);\n+})\n+\n (define_expand \"avx_shufpd256\"\n   [(match_operand:V4DF 0 \"register_operand\" \"\")\n    (match_operand:V4DF 1 \"register_operand\" \"\")\n@@ -7408,6 +7506,20 @@\n   [(set_attr \"type\" \"ssemov\")\n    (set_attr \"mode\" \"V2SF,V4SF,V2SF\")])\n \n+(define_insn \"*vec_dupv4si_avx\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x,x\")\n+\t(vec_duplicate:V4SI\n+\t  (match_operand:SI 1 \"register_operand\" \"x,m\")))]\n+  \"TARGET_AVX\"\n+  \"@\n+   vpshufd\\t{$0, %1, %0|%0, %1, 0}\n+   vbroadcastss\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sselog1,ssemov\")\n+   (set_attr \"length_immediate\" \"1,0\")\n+   (set_attr \"prefix_extra\" \"0,1\")\n+   (set_attr \"prefix\" \"vex\")\n+   (set_attr \"mode\" \"TI,V4SF\")])\n+\n (define_insn \"*vec_dupv4si\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=Y2,x\")\n \t(vec_duplicate:V4SI\n@@ -7417,19 +7529,31 @@\n    %vpshufd\\t{$0, %1, %0|%0, %1, 0}\n    shufps\\t{$0, %0, %0|%0, %0, 0}\"\n   [(set_attr \"type\" \"sselog1\")\n-   (set_attr \"prefix\" \"maybe_vex,orig\")\n    (set_attr \"length_immediate\" \"1\")\n    (set_attr \"mode\" \"TI,V4SF\")])\n \n (define_insn \"*vec_dupv2di_avx\"\n-  [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n+  [(set (match_operand:V2DI 0 \"register_operand\"     \"=x,x\")\n \t(vec_duplicate:V2DI\n-\t  (match_operand:DI 1 \"register_operand\" \"x\")))]\n+\t  (match_operand:DI 1 \"nonimmediate_operand\" \" x,m\")))]\n   \"TARGET_AVX\"\n-  \"vpunpcklqdq\\t{%1, %1, %0|%0, %1, %1}\"\n+  \"@\n+   vpunpcklqdq\\t{%1, %1, %0|%0, %1, %1}\n+   vmovddup\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"sselog1\")\n    (set_attr \"prefix\" \"vex\")\n-   (set_attr \"mode\" \"TI\")])\n+   (set_attr \"mode\" \"TI,DF\")])\n+\n+(define_insn \"*vec_dupv2di_sse3\"\n+  [(set (match_operand:V2DI 0 \"register_operand\"     \"=x,x\")\n+\t(vec_duplicate:V2DI\n+\t  (match_operand:DI 1 \"nonimmediate_operand\" \" 0,m\")))]\n+  \"TARGET_SSE3\"\n+  \"@\n+   punpcklqdq\\t%0, %0\n+   movddup\\t{%1, %0|%0, %1}\"\n+  [(set_attr \"type\" \"sselog1\")\n+   (set_attr \"mode\" \"TI,DF\")])\n \n (define_insn \"*vec_dupv2di\"\n   [(set (match_operand:V2DI 0 \"register_operand\" \"=Y2,x\")\n@@ -11838,6 +11962,108 @@\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"OI\")])\n \n+(define_insn_and_split \"vec_dup<mode>\"\n+  [(set (match_operand:AVX256MODE24P 0 \"register_operand\" \"=x,x\")\n+\t(vec_duplicate:AVX256MODE24P\n+\t  (match_operand:<avxscalarmode> 1 \"nonimmediate_operand\" \"m,?x\")))]\n+  \"TARGET_AVX\"\n+  \"@\n+   vbroadcasts<avxmodesuffixf2c>\\t{%1, %0|%0, %1}\n+   #\"\n+  \"&& reload_completed && REG_P (operands[1])\"\n+  [(set (match_dup 2) (vec_duplicate:<avxhalfvecmode> (match_dup 1)))\n+   (set (match_dup 0) (vec_concat:AVX256MODE24P (match_dup 2) (match_dup 2)))]\n+{\n+  operands[2] = gen_rtx_REG (<avxhalfvecmode>mode, REGNO (operands[0]));\n+}\n+  [(set_attr \"type\" \"ssemov\")\n+   (set_attr \"prefix_extra\" \"1\")\n+   (set_attr \"prefix\" \"vex\")\n+   (set_attr \"mode\" \"V8SF\")])\n+\n+(define_insn \"avx_vbroadcastf128_<mode>\"\n+  [(set (match_operand:AVX256MODE 0 \"register_operand\" \"=x,x,x\")\n+\t(vec_concat:AVX256MODE\n+\t  (match_operand:<avxhalfvecmode> 1 \"nonimmediate_operand\" \"m,0,?x\")\n+\t  (match_dup 1)))]\n+  \"TARGET_AVX\"\n+  \"@\n+   vbroadcastf128\\t{%1, %0|%0, %1}\n+   vinsertf128\\t{$1, %1, %0, %0|%0, %0, %1, 1}\n+   vperm2f128\\t{$0, %t1, %t1, %0|%0, %t1, %t1, 0}\"\n+  [(set_attr \"type\" \"ssemov,sselog1,sselog1\")\n+   (set_attr \"prefix_extra\" \"1\")\n+   (set_attr \"length_immediate\" \"0,1,1\")\n+   (set_attr \"prefix\" \"vex\")\n+   (set_attr \"mode\" \"V4SF,V8SF,V8SF\")])\n+\n+;; Recognize broadcast as a vec_select as produced by builtin_vec_perm.\n+;; If it so happens that the input is in memory, use vbroadcast.\n+;; Otherwise use vpermilp (and in the case of 256-bit modes, vperm2f128).\n+(define_insn \"*avx_vperm_broadcast_v4sf\"\n+  [(set (match_operand:V4SF 0 \"register_operand\" \"=x,x,x\")\n+\t(vec_select:V4SF\n+\t  (match_operand:V4SF 1 \"nonimmediate_operand\" \"m,o,x\")\n+\t  (match_parallel 2 \"avx_vbroadcast_operand\"\n+\t    [(match_operand 3 \"const_int_operand\" \"C,n,n\")])))]\n+  \"TARGET_AVX\"\n+{\n+  int elt = INTVAL (operands[3]);\n+  switch (which_alternative)\n+    {\n+    case 0:\n+    case 1:\n+      operands[1] = adjust_address_nv (operands[1], SFmode, elt * 4);\n+      return \"vbroadcastss\\t{%1, %0|%0, %1}\";\n+    case 2:\n+      operands[2] = GEN_INT (elt * 0x55);\n+      return \"vpermilps\\t{%2, %1, %0|%0, %1, %2}\";\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+  [(set_attr \"type\" \"ssemov,ssemov,sselog1\")\n+   (set_attr \"prefix_extra\" \"1\")\n+   (set_attr \"length_immediate\" \"0,0,1\")\n+   (set_attr \"prefix\" \"vex\")\n+   (set_attr \"mode\" \"SF,SF,V4SF\")])\n+\n+(define_insn_and_split \"*avx_vperm_broadcast_<mode>\"\n+  [(set (match_operand:AVX256MODEF2P 0 \"register_operand\" \"=x,x,x\")\n+\t(vec_select:AVX256MODEF2P\n+\t  (match_operand:AVX256MODEF2P 1 \"nonimmediate_operand\" \"m,o,?x\")\n+\t  (match_parallel 2 \"avx_vbroadcast_operand\"\n+\t    [(match_operand 3 \"const_int_operand\" \"C,n,n\")])))]\n+  \"TARGET_AVX\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(set (match_dup 0) (vec_duplicate:AVX256MODEF2P (match_dup 1)))]\n+{\n+  rtx op0 = operands[0], op1 = operands[1];\n+  int elt = INTVAL (operands[3]);\n+\n+  if (REG_P (op1))\n+    {\n+      int mask;\n+\n+      /* Shuffle element we care about into all elements of the 128-bit lane.\n+\t The other lane gets shuffled too, but we don't care.  */\n+      if (<MODE>mode == V4DFmode)\n+\tmask = (elt & 1 ? 15 : 0);\n+      else\n+\tmask = (elt & 3) * 0x55;\n+      emit_insn (gen_avx_vpermil<mode> (op0, op1, GEN_INT (mask)));\n+\n+      /* Shuffle the lane we care about into both lanes of the dest.  */\n+      mask = (elt / (<ssescalarnum> / 2)) * 0x11;\n+      emit_insn (gen_avx_vperm2f128<mode>3 (op0, op0, op0, GEN_INT (mask)));\n+      DONE;\n+    }\n+\n+  operands[1] = adjust_address_nv (op1, <avxscalarmode>mode,\n+  \t      \t\t\t   elt * GET_MODE_SIZE (<avxscalarmode>mode));\n+})\n+\n (define_expand \"avx_vpermil<mode>\"\n   [(set (match_operand:AVXMODEFDP 0 \"register_operand\" \"\")\n \t(vec_select:AVXMODEFDP\n@@ -11989,58 +12215,6 @@\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"V8SF\")])\n \n-(define_insn \"avx_vbroadcasts<avxmodesuffixf2c><avxmodesuffix>\"\n-  [(set (match_operand:AVXMODEF4P 0 \"register_operand\" \"=x\")\n-\t(vec_concat:AVXMODEF4P\n-\t  (vec_concat:<avxhalfvecmode>\n-\t    (match_operand:<avxscalarmode> 1 \"memory_operand\" \"m\")\n-\t    (match_dup 1))\n-\t  (vec_concat:<avxhalfvecmode>\n-\t    (match_dup 1)\n-\t    (match_dup 1))))]\n-  \"TARGET_AVX\"\n-  \"vbroadcasts<avxmodesuffixf2c>\\t{%1, %0|%0, %1}\"\n-  [(set_attr \"type\" \"ssemov\")\n-   (set_attr \"prefix_extra\" \"1\")\n-   (set_attr \"prefix\" \"vex\")\n-   (set_attr \"mode\" \"<avxscalarmode>\")])\n-\n-(define_insn \"avx_vbroadcastss256\"\n-  [(set (match_operand:V8SF 0 \"register_operand\" \"=x\")\n-\t(vec_concat:V8SF\n-\t  (vec_concat:V4SF\n-\t    (vec_concat:V2SF\n-\t      (match_operand:SF 1 \"memory_operand\" \"m\")\n-\t      (match_dup 1))\n-\t    (vec_concat:V2SF\n-\t      (match_dup 1)\n-\t      (match_dup 1)))\n-\t  (vec_concat:V4SF\n-\t    (vec_concat:V2SF\n-\t      (match_dup 1)\n-\t      (match_dup 1))\n-\t    (vec_concat:V2SF\n-\t      (match_dup 1)\n-\t      (match_dup 1)))))]\n-  \"TARGET_AVX\"\n-  \"vbroadcastss\\t{%1, %0|%0, %1}\"\n-  [(set_attr \"type\" \"ssemov\")\n-   (set_attr \"prefix_extra\" \"1\")\n-   (set_attr \"prefix\" \"vex\")\n-   (set_attr \"mode\" \"SF\")])\n-\n-(define_insn \"avx_vbroadcastf128_p<avxmodesuffixf2c>256\"\n-  [(set (match_operand:AVX256MODEF2P 0 \"register_operand\" \"=x\")\n-\t(vec_concat:AVX256MODEF2P\n-\t  (match_operand:<avxhalfvecmode> 1 \"memory_operand\" \"m\")\n-\t  (match_dup 1)))]\n-  \"TARGET_AVX\"\n-  \"vbroadcastf128\\t{%1, %0|%0, %1}\"\n-  [(set_attr \"type\" \"ssemov\")\n-   (set_attr \"prefix_extra\" \"1\")\n-   (set_attr \"prefix\" \"vex\")\n-   (set_attr \"mode\" \"V4SF\")])\n-\n (define_expand \"avx_vinsertf128<mode>\"\n   [(match_operand:AVX256MODE 0 \"register_operand\" \"\")\n    (match_operand:AVX256MODE 1 \"register_operand\" \"\")"}]}