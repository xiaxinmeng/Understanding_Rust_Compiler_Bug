{"sha": "6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NmM0Y2NmZDhhMThjMjk3ZmJkZDAxN2NkMDdkYzMwN2E3YTdjNmQ4OQ==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@redhat.com", "date": "2004-12-17T21:40:39Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2004-12-17T21:40:39Z"}, "message": "i386.c (x86_64_reg_class_name): Re-indent.\n\n        * config/i386/i386.c (x86_64_reg_class_name): Re-indent.\n        (classify_argument, examine_argument, construct_container,\n        merge_classes): Remove prototypes.\n        (type_natural_mode): Split out from ...\n        (function_arg): ... here.\n        (gen_reg_or_parallel): Remove alt_mode argument.  Update callers.\n        Use orig_mode unless it's BLKmode.\n        (construct_container): Add orig_mode argument.  Update callers.\n        Use gen_reg_or_parallel for SSE registers.\n        (ix86_function_value): Use type_natural_mode.\n        (ix86_gimplify_va_arg): Likewise.\n        (ix86_hard_regno_mode_ok): Always accept all SSE, MMX, 3DNOW modes in\n        SSE registers; always accept all MMX, 3DNOW modes in MMX registers.\n        * config/i386/i386.h (VALID_SSE2_REG_MODE): Don't include\n        VALID_MMX_REG_MODE.\n        * config/i386/i386.md (attribute mode): Add V1DF.\n        (movsi_1): Use 'x' instead of 'Y' constraints.\n        (movsi_1_nointernunit, movdi_2, movdi_1_rex64): Likewise.\n        (movdi_1_rex64_nointerunit): Likewise.\n        (movdf_nointeger, movdf_integer): Likewise.  Handle SSE1.\n        (movsf_1, movsf_1_nointerunit): Line up constraint alternatives.\n        (swapsf): Use fp_register_operand, don't disable for TARGET_SSE.\n        (swapdf): Likewise.\n        (swapxf): Enable only for TARGET_80387.\n        (movv2sf, movv2sf_internal, pushv2sf): Enable for MMX.\n        (movtf): Remove double-check for TARGET_64BIT.\n        (movv2df_internal): Enable for SSE1.\n        (movv8hi_internal, movv16qi_internal): Likewise.\n        (movv2df, movv8hi, movv16qi): Likewise.\n        (pushv2di, pushv8hi, pushv16qi, pushv4si): Likewise.\n        (pushdi2_rex64, movv4sf_internal, movv4si_internal, movv2di_internal,\n        movv8qi_internal, movv4hi_internal, movv2sf_internal,\n        movv2df_internal, movv8hi_internal, movv16qi_internal,\n        movti_internal): Add leading '*' to name.\n\nFrom-SVN: r92336", "tree": {"sha": "d0080e8895d8639f626812843872da4bc308e876", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/d0080e8895d8639f626812843872da4bc308e876"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89/comments", "author": null, "committer": null, "parents": [{"sha": "128691426dcb9e2a3cb57c89bc863d03c1009d82", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/128691426dcb9e2a3cb57c89bc863d03c1009d82", "html_url": "https://github.com/Rust-GCC/gccrs/commit/128691426dcb9e2a3cb57c89bc863d03c1009d82"}], "stats": {"total": 470, "additions": 287, "deletions": 183}, "files": [{"sha": "4e51583d5db1739c452c665b239c61a2a2d809e5", "filename": "gcc/ChangeLog", "status": "modified", "additions": 37, "deletions": 0, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89", "patch": "@@ -1,3 +1,40 @@\n+2004-12-17  Richard Henderson  <rth@redhat.com>\n+\n+\t* config/i386/i386.c (x86_64_reg_class_name): Re-indent.\n+\t(classify_argument, examine_argument, construct_container,\n+\tmerge_classes): Remove prototypes.\n+\t(type_natural_mode): Split out from ...\n+\t(function_arg): ... here.\n+\t(gen_reg_or_parallel): Remove alt_mode argument.  Update callers.\n+\tUse orig_mode unless it's BLKmode.\n+\t(construct_container): Add orig_mode argument.  Update callers.\n+\tUse gen_reg_or_parallel for SSE registers.\n+\t(ix86_function_value): Use type_natural_mode.\n+\t(ix86_gimplify_va_arg): Likewise.\n+\t(ix86_hard_regno_mode_ok): Always accept all SSE, MMX, 3DNOW modes in\n+\tSSE registers; always accept all MMX, 3DNOW modes in MMX registers.\n+\t* config/i386/i386.h (VALID_SSE2_REG_MODE): Don't include\n+\tVALID_MMX_REG_MODE.\n+\t* config/i386/i386.md (attribute mode): Add V1DF.\n+\t(movsi_1): Use 'x' instead of 'Y' constraints.\n+\t(movsi_1_nointernunit, movdi_2, movdi_1_rex64): Likewise.\n+\t(movdi_1_rex64_nointerunit): Likewise.\n+\t(movdf_nointeger, movdf_integer): Likewise.  Handle SSE1.\n+\t(movsf_1, movsf_1_nointerunit): Line up constraint alternatives.\n+\t(swapsf): Use fp_register_operand, don't disable for TARGET_SSE.\n+\t(swapdf): Likewise.\n+\t(swapxf): Enable only for TARGET_80387.\n+\t(movv2sf, movv2sf_internal, pushv2sf): Enable for MMX.\n+\t(movtf): Remove double-check for TARGET_64BIT.\n+\t(movv2df_internal): Enable for SSE1.\n+\t(movv8hi_internal, movv16qi_internal): Likewise.\n+\t(movv2df, movv8hi, movv16qi): Likewise.\n+\t(pushv2di, pushv8hi, pushv16qi, pushv4si): Likewise.\n+\t(pushdi2_rex64, movv4sf_internal, movv4si_internal, movv2di_internal,\n+\tmovv8qi_internal, movv4hi_internal, movv2sf_internal,\n+\tmovv2df_internal, movv8hi_internal, movv16qi_internal,\n+\tmovti_internal): Add leading '*' to name.\n+\n 2004-12-17  Dale Johannesen  <dalej@apple.com>\n \n \t* c-decl.c (diagnose_mismatched_decls):  Accept mismatched"}, {"sha": "bb54c22a6c5a03cb3d14e1b8f5227bde65a69f42", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 111, "deletions": 90, "changes": 201, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89", "patch": "@@ -951,17 +951,12 @@ enum x86_64_reg_class\n     X86_64_COMPLEX_X87_CLASS,\n     X86_64_MEMORY_CLASS\n   };\n-static const char * const x86_64_reg_class_name[] =\n-   {\"no\", \"integer\", \"integerSI\", \"sse\", \"sseSF\", \"sseDF\", \"sseup\", \"x87\", \"x87up\", \"cplx87\", \"no\"};\n+static const char * const x86_64_reg_class_name[] = {\n+  \"no\", \"integer\", \"integerSI\", \"sse\", \"sseSF\", \"sseDF\",\n+  \"sseup\", \"x87\", \"x87up\", \"cplx87\", \"no\"\n+};\n \n #define MAX_CLASSES 4\n-static int classify_argument (enum machine_mode, tree,\n-\t\t\t      enum x86_64_reg_class [MAX_CLASSES], int);\n-static int examine_argument (enum machine_mode, tree, int, int *, int *);\n-static rtx construct_container (enum machine_mode, tree, int, int, int,\n-\t\t\t\tconst int *, int);\n-static enum x86_64_reg_class merge_classes (enum x86_64_reg_class,\n-\t\t\t\t\t    enum x86_64_reg_class);\n \n /* Table of constants used by fldpi, fldln2, etc....  */\n static REAL_VALUE_TYPE ext_80387_constants_table [5];\n@@ -2040,6 +2035,71 @@ init_cumulative_args (CUMULATIVE_ARGS *cum,  /* Argument info to initialize */\n   return;\n }\n \n+/* Return the \"natural\" mode for TYPE.  In most cases, this is just TYPE_MODE.\n+   But in the case of vector types, it is some vector mode.\n+\n+   When we have only some of our vector isa extensions enabled, then there\n+   are some modes for which vector_mode_supported_p is false.  For these\n+   modes, the generic vector support in gcc will choose some non-vector mode\n+   in order to implement the type.  By computing the natural mode, we'll \n+   select the proper ABI location for the operand and not depend on whatever\n+   the middle-end decides to do with these vector types.  */\n+\n+static enum machine_mode\n+type_natural_mode (tree type)\n+{\n+  enum machine_mode mode = TYPE_MODE (type);\n+\n+  if (TREE_CODE (type) == VECTOR_TYPE && !VECTOR_MODE_P (mode))\n+    {\n+      HOST_WIDE_INT size = int_size_in_bytes (type);\n+      if ((size == 8 || size == 16)\n+\t  /* ??? Generic code allows us to create width 1 vectors.  Ignore.  */\n+\t  && TYPE_VECTOR_SUBPARTS (type) > 1)\n+\t{\n+\t  enum machine_mode innermode = TYPE_MODE (TREE_TYPE (type));\n+\n+\t  if (TREE_CODE (TREE_TYPE (type)) == REAL_TYPE)\n+\t    mode = MIN_MODE_VECTOR_FLOAT;\n+\t  else\n+\t    mode = MIN_MODE_VECTOR_INT;\n+\n+\t  /* Get the mode which has this inner mode and number of units.  */\n+\t  for (; mode != VOIDmode; mode = GET_MODE_WIDER_MODE (mode))\n+\t    if (GET_MODE_NUNITS (mode) == TYPE_VECTOR_SUBPARTS (type)\n+\t\t&& GET_MODE_INNER (mode) == innermode)\n+\t      return mode;\n+\n+\t  abort ();\n+\t}\n+    }\n+\n+  return mode;\n+}\n+\n+/* We want to pass a value in REGNO whose \"natural\" mode is MODE.  However,\n+   this may not agree with the mode that the type system has chosen for the\n+   register, which is ORIG_MODE.  If ORIG_MODE is not BLKmode, then we can\n+   go ahead and use it.  Otherwise we have to build a PARALLEL instead.  */\n+\n+static rtx\n+gen_reg_or_parallel (enum machine_mode mode, enum machine_mode orig_mode,\n+\t\t     unsigned int regno)\n+{\n+  rtx tmp;\n+\n+  if (orig_mode != BLKmode)\n+    tmp = gen_rtx_REG (orig_mode, regno);\n+  else\n+    {\n+      tmp = gen_rtx_REG (mode, regno);\n+      tmp = gen_rtx_EXPR_LIST (VOIDmode, tmp, const0_rtx);\n+      tmp = gen_rtx_PARALLEL (orig_mode, gen_rtvec (1, tmp));\n+    }\n+\n+  return tmp;\n+}\n+\n /* x86-64 register passing implementation.  See x86-64 ABI for details.  Goal\n    of this code is to classify each 8bytes of incoming argument by the register\n    class and assign registers accordingly.  */\n@@ -2442,12 +2502,14 @@ examine_argument (enum machine_mode mode, tree type, int in_return,\n       }\n   return 1;\n }\n+\n /* Construct container for the argument used by GCC interface.  See\n    FUNCTION_ARG for the detailed description.  */\n+\n static rtx\n-construct_container (enum machine_mode mode, tree type, int in_return,\n-\t\t     int nintregs, int nsseregs, const int * intreg,\n-\t\t     int sse_regno)\n+construct_container (enum machine_mode mode, enum machine_mode orig_mode,\n+\t\t     tree type, int in_return, int nintregs, int nsseregs,\n+\t\t     const int *intreg, int sse_regno)\n {\n   enum machine_mode tmpmode;\n   int bytes =\n@@ -2477,7 +2539,8 @@ construct_container (enum machine_mode mode, tree type, int in_return,\n     }\n   if (!n)\n     return NULL;\n-  if (!examine_argument (mode, type, in_return, &needed_intregs, &needed_sseregs))\n+  if (!examine_argument (mode, type, in_return, &needed_intregs,\n+\t\t\t &needed_sseregs))\n     return NULL;\n   if (needed_intregs > nintregs || needed_sseregs > nsseregs)\n     return NULL;\n@@ -2493,7 +2556,7 @@ construct_container (enum machine_mode mode, tree type, int in_return,\n       case X86_64_SSE_CLASS:\n       case X86_64_SSESF_CLASS:\n       case X86_64_SSEDF_CLASS:\n-\treturn gen_rtx_REG (mode, SSE_REGNO (sse_regno));\n+\treturn gen_reg_or_parallel (mode, orig_mode, SSE_REGNO (sse_regno));\n       case X86_64_X87_CLASS:\n       case X86_64_COMPLEX_X87_CLASS:\n \treturn gen_rtx_REG (mode, FIRST_STACK_REG);\n@@ -2581,19 +2644,18 @@ construct_container (enum machine_mode mode, tree type, int in_return,\n    (TYPE is null for libcalls where that information may not be available.)  */\n \n void\n-function_arg_advance (CUMULATIVE_ARGS *cum,\t/* current arg information */\n-\t\t      enum machine_mode mode,\t/* current arg mode */\n-\t\t      tree type,\t/* type of the argument or 0 if lib support */\n-\t\t      int named)\t/* whether or not the argument was named */\n+function_arg_advance (CUMULATIVE_ARGS *cum, enum machine_mode mode,\n+\t\t      tree type, int named)\n {\n   int bytes =\n     (mode == BLKmode) ? int_size_in_bytes (type) : (int) GET_MODE_SIZE (mode);\n   int words = (bytes + UNITS_PER_WORD - 1) / UNITS_PER_WORD;\n \n   if (TARGET_DEBUG_ARG)\n-    fprintf (stderr,\n-\t     \"function_adv (sz=%d, wds=%2d, nregs=%d, ssenregs=%d, mode=%s, named=%d)\\n\\n\",\n-\t     words, cum->words, cum->nregs, cum->sse_nregs, GET_MODE_NAME (mode), named);\n+    fprintf (stderr, \"function_adv (sz=%d, wds=%2d, nregs=%d, ssenregs=%d, \"\n+\t     \"mode=%s, named=%d)\\n\\n\",\n+\t     words, cum->words, cum->nregs, cum->sse_nregs,\n+\t     GET_MODE_NAME (mode), named);\n   if (TARGET_64BIT)\n     {\n       int int_nregs, sse_nregs;\n@@ -2651,34 +2713,6 @@ function_arg_advance (CUMULATIVE_ARGS *cum,\t/* current arg information */\n   return;\n }\n \n-/* A subroutine of function_arg.  We want to pass a parameter whose nominal\n-   type is MODE in REGNO.  We try to minimize ABI variation, so MODE may not\n-   actually be valid for REGNO with the current ISA.  In this case, ALT_MODE\n-   is used instead.  It must be the same size as MODE, and must be known to\n-   be valid for REGNO.  Finally, ORIG_MODE is the original mode of the \n-   parameter, as seen by the type system.  This may be different from MODE\n-   when we're mucking with things minimizing ABI variations.\n-\n-   Returns a REG or a PARALLEL as appropriate.  */\n-\n-static rtx\n-gen_reg_or_parallel (enum machine_mode mode, enum machine_mode alt_mode,\n-\t\t     enum machine_mode orig_mode, unsigned int regno)\n-{\n-  rtx tmp;\n-\n-  if (HARD_REGNO_MODE_OK (regno, mode))\n-    tmp = gen_rtx_REG (mode, regno);\n-  else\n-    {\n-      tmp = gen_rtx_REG (alt_mode, regno);\n-      tmp = gen_rtx_EXPR_LIST (VOIDmode, tmp, const0_rtx);\n-      tmp = gen_rtx_PARALLEL (orig_mode, gen_rtvec (1, tmp));\n-    }\n-\n-  return tmp;\n-}\n-\n /* Define where to put the arguments to a function.\n    Value is zero to push the argument on the stack,\n    or a hard register in which to store the argument.\n@@ -2705,26 +2739,8 @@ function_arg (CUMULATIVE_ARGS *cum, enum machine_mode orig_mode,\n \n   /* To simplify the code below, represent vector types with a vector mode\n      even if MMX/SSE are not active.  */\n-  if (type\n-      && TREE_CODE (type) == VECTOR_TYPE\n-      && (bytes == 8 || bytes == 16)\n-      && GET_MODE_CLASS (TYPE_MODE (type)) != MODE_VECTOR_INT\n-      && GET_MODE_CLASS (TYPE_MODE (type)) != MODE_VECTOR_FLOAT)\n-    {\n-      enum machine_mode innermode = TYPE_MODE (TREE_TYPE (type));\n-      enum machine_mode newmode\n-\t= TREE_CODE (TREE_TYPE (type)) == REAL_TYPE\n-\t  ? MIN_MODE_VECTOR_FLOAT : MIN_MODE_VECTOR_INT;\n-\n-      /* Get the mode which has this inner mode and number of units.  */\n-      for (; newmode != VOIDmode; newmode = GET_MODE_WIDER_MODE (newmode))\n-\tif (GET_MODE_NUNITS (newmode) == TYPE_VECTOR_SUBPARTS (type)\n-\t    && GET_MODE_INNER (newmode) == innermode)\n-\t  {\n-\t    mode = newmode;\n-\t    break;\n-\t  }\n-    }\n+  if (type && TREE_CODE (type) == VECTOR_TYPE)\n+    mode = type_natural_mode (type);\n \n   /* Handle a hidden AL argument containing number of registers for varargs\n      x86-64 functions.  For i386 ABI just return constm1_rtx to avoid\n@@ -2741,7 +2757,8 @@ function_arg (CUMULATIVE_ARGS *cum, enum machine_mode orig_mode,\n \treturn constm1_rtx;\n     }\n   if (TARGET_64BIT)\n-    ret = construct_container (mode, type, 0, cum->nregs, cum->sse_nregs,\n+    ret = construct_container (mode, orig_mode, type, 0, cum->nregs,\n+\t\t\t       cum->sse_nregs,\n \t\t\t       &x86_64_int_parameter_registers [cum->regno],\n \t\t\t       cum->sse_regno);\n   else\n@@ -2793,7 +2810,7 @@ function_arg (CUMULATIVE_ARGS *cum, enum machine_mode orig_mode,\n \t\t\t \"changes the ABI\");\n \t      }\n \t    if (cum->sse_nregs)\n-\t      ret = gen_reg_or_parallel (mode, TImode, orig_mode,\n+\t      ret = gen_reg_or_parallel (mode, orig_mode,\n \t\t\t\t\t cum->sse_regno + FIRST_SSE_REG);\n \t  }\n \tbreak;\n@@ -2810,7 +2827,7 @@ function_arg (CUMULATIVE_ARGS *cum, enum machine_mode orig_mode,\n \t\t\t \"changes the ABI\");\n \t      }\n \t    if (cum->mmx_nregs)\n-\t      ret = gen_reg_or_parallel (mode, DImode, orig_mode,\n+\t      ret = gen_reg_or_parallel (mode, orig_mode,\n \t\t\t\t\t cum->mmx_regno + FIRST_MMX_REG);\n \t  }\n \tbreak;\n@@ -2972,11 +2989,12 @@ ix86_function_value (tree valtype)\n {\n   if (TARGET_64BIT)\n     {\n-      rtx ret = construct_container (TYPE_MODE (valtype), valtype, 1,\n-\t\t\t\t     REGPARM_MAX, SSE_REGPARM_MAX,\n+      rtx ret = construct_container (type_natural_mode (valtype),\n+\t\t\t\t     TYPE_MODE (valtype), valtype,\n+\t\t\t\t     1, REGPARM_MAX, SSE_REGPARM_MAX,\n \t\t\t\t     x86_64_int_return_registers, 0);\n-      /* For zero sized structures, construct_container return NULL, but we need\n-         to keep rest of compiler happy by returning meaningful value.  */\n+      /* For zero sized structures, construct_container return NULL, but we\n+\t need to keep rest of compiler happy by returning meaningful value.  */\n       if (!ret)\n \tret = gen_rtx_REG (TYPE_MODE (valtype), 0);\n       return ret;\n@@ -3342,11 +3360,11 @@ ix86_gimplify_va_arg (tree valist, tree type, tree *pre_p, tree *post_p)\n   size = int_size_in_bytes (type);\n   rsize = (size + UNITS_PER_WORD - 1) / UNITS_PER_WORD;\n \n-  container = construct_container (TYPE_MODE (type), type, 0,\n-\t\t\t\t   REGPARM_MAX, SSE_REGPARM_MAX, intreg, 0);\n-  /*\n-   * Pull the value out of the saved registers ...\n-   */\n+  container = construct_container (type_natural_mode (type), TYPE_MODE (type),\n+\t\t\t\t   type, 0, REGPARM_MAX, SSE_REGPARM_MAX,\n+\t\t\t\t   intreg, 0);\n+\n+  /* Pull the value out of the saved registers.  */\n \n   addr = create_tmp_var (ptr_type_node, \"addr\");\n   DECL_POINTER_ALIAS_SET (addr) = get_varargs_alias_set ();\n@@ -14032,18 +14050,21 @@ ix86_hard_regno_mode_ok (int regno, enum machine_mode mode)\n     return VALID_FP_MODE_P (mode);\n   if (SSE_REGNO_P (regno))\n     {\n-      if (TARGET_SSE2 && VALID_SSE2_REG_MODE (mode))\n-\treturn 1;\n-      if (TARGET_SSE && VALID_SSE_REG_MODE (mode))\n-\treturn 1;\n-      return 0;\n+      /* We implement the move patterns for all vector modes into and\n+\t out of SSE registers, even when no operation instructions\n+\t are available.  */\n+      return (VALID_SSE_REG_MODE (mode)\n+\t      || VALID_SSE2_REG_MODE (mode)\n+\t      || VALID_MMX_REG_MODE (mode)\n+\t      || VALID_MMX_REG_MODE_3DNOW (mode));\n     }\n   if (MMX_REGNO_P (regno))\n     {\n-      if (TARGET_3DNOW && VALID_MMX_REG_MODE_3DNOW (mode))\n-\treturn 1;\n-      if (TARGET_MMX && VALID_MMX_REG_MODE (mode))\n-\treturn 1;\n+      /* We implement the move patterns for 3DNOW modes even in MMX mode,\n+\t so if the register is available at all, then we can move data of\n+\t the given mode into or out of it.  */\n+      return (VALID_MMX_REG_MODE (mode)\n+\t      || VALID_MMX_REG_MODE_3DNOW (mode));\n     }\n   /* We handle both integer and floats in the general purpose registers.\n      In future we should be able to handle vector modes as well.  */"}, {"sha": "5bcd6070af88d63d72d4123a8331477448e6a97f", "filename": "gcc/config/i386/i386.h", "status": "modified", "additions": 1, "deletions": 2, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89/gcc%2Fconfig%2Fi386%2Fi386.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89/gcc%2Fconfig%2Fi386%2Fi386.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.h?ref=6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89", "patch": "@@ -1075,8 +1075,7 @@ do {\t\t\t\t\t\t\t\t\t\\\n \n #define VALID_SSE2_REG_MODE(MODE) \\\n     ((MODE) == V16QImode || (MODE) == V8HImode || (MODE) == V2DFmode    \\\n-     || (MODE) == V2DImode || (MODE) == DFmode\t\t\t\t\\\n-     || VALID_MMX_REG_MODE (MODE))\n+     || (MODE) == V2DImode || (MODE) == DFmode)\n \n #define VALID_SSE_REG_MODE(MODE)\t\t\t\t\t\\\n     ((MODE) == TImode || (MODE) == V4SFmode || (MODE) == V4SImode\t\\"}, {"sha": "f270f742dc5376a8d68f5f38f7c875420a2f8332", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 138, "deletions": 91, "changes": 229, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=6c4ccfd8a18c297fbdd017cd07dc307a7a7c6d89", "patch": "@@ -199,7 +199,7 @@\n \n ;; Main data type used by the insn\n (define_attr \"mode\"\n-  \"unknown,none,QI,HI,SI,DI,SF,DF,XF,TI,V4SF,V2DF,V2SF\"\n+  \"unknown,none,QI,HI,SI,DI,SF,DF,XF,TI,V4SF,V2DF,V2SF,V1DF\"\n   (const_string \"unknown\"))\n \n ;; The CPU unit operations uses.\n@@ -1122,8 +1122,10 @@\n    (set_attr \"length_immediate\" \"1\")])\n \n (define_insn \"*movsi_1\"\n-  [(set (match_operand:SI 0 \"nonimmediate_operand\" \"=r,m,!*y,!rm,!*y,!*Y,!rm,!*Y\")\n-\t(match_operand:SI 1 \"general_operand\" \"rinm,rin,*y,*y,rm,*Y,*Y,rm\"))]\n+  [(set (match_operand:SI 0 \"nonimmediate_operand\"\n+\t\t\t\"=r  ,m  ,!*y,!rm,!*y,!*x,!rm,!*x\")\n+\t(match_operand:SI 1 \"general_operand\"\n+\t\t\t\"rinm,rin,*y ,*y ,rm ,*x ,*x ,rm\"))]\n   \"(TARGET_INTER_UNIT_MOVES || optimize_size)\n    && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n {\n@@ -1161,8 +1163,10 @@\n    (set_attr \"mode\" \"SI,SI,DI,SI,SI,TI,SI,SI\")])\n \n (define_insn \"*movsi_1_nointernunit\"\n-  [(set (match_operand:SI 0 \"nonimmediate_operand\" \"=r,m,!*y,!m,!*y,!*Y,!m,!*Y\")\n-\t(match_operand:SI 1 \"general_operand\" \"rinm,rin,*y,*y,m,*Y,*Y,m\"))]\n+  [(set (match_operand:SI 0 \"nonimmediate_operand\"\n+\t\t\t\"=r  ,m  ,!*y,!m,!*y,!*x,!m,!*x\")\n+\t(match_operand:SI 1 \"general_operand\"\n+\t\t\t\"rinm,rin,*y ,*y,m  ,*x ,*x,m\"))]\n   \"(!TARGET_INTER_UNIT_MOVES && !optimize_size)\n    && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n {\n@@ -1784,7 +1788,7 @@\n   \"!TARGET_64BIT\"\n   \"#\")\n \n-(define_insn \"pushdi2_rex64\"\n+(define_insn \"*pushdi2_rex64\"\n   [(set (match_operand:DI 0 \"push_operand\" \"=<,!<\")\n \t(match_operand:DI 1 \"general_no_elim_operand\" \"re*m,n\"))]\n   \"TARGET_64BIT\"\n@@ -1895,8 +1899,8 @@\n    (set_attr \"length_immediate\" \"1\")])\n \n (define_insn \"*movdi_2\"\n-  [(set (match_operand:DI 0 \"nonimmediate_operand\" \"=r,o,!m*y,!*y,!m,!*Y,!*Y\")\n-\t(match_operand:DI 1 \"general_operand\" \"riFo,riF,*y,m,*Y,*Y,m\"))]\n+  [(set (match_operand:DI 0 \"nonimmediate_operand\" \"=r,o,!m*y,!*y,!m,!*x,!*x\")\n+\t(match_operand:DI 1 \"general_operand\" \"riFo,riF,*y,m,*x,*x,m\"))]\n   \"!TARGET_64BIT\n    && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n   \"@\n@@ -1929,8 +1933,10 @@\n   \"ix86_split_long_move (operands); DONE;\")\n \n (define_insn \"*movdi_1_rex64\"\n-  [(set (match_operand:DI 0 \"nonimmediate_operand\" \"=r,r,r,mr,!mr,!*y,!rm,!*y,!*Y,!rm,!*Y,!*Y,!*y\")\n-\t(match_operand:DI 1 \"general_operand\" \"Z,rem,i,re,n,*y,*y,rm,*Y,*Y,rm,*y,*Y\"))]\n+  [(set (match_operand:DI 0 \"nonimmediate_operand\"\n+\t\t\"=r,r  ,r,mr,!mr,!*y,!rm,!*y,!*x,!rm,!*x,!*x,!*y\")\n+\t(match_operand:DI 1 \"general_operand\"\n+\t\t\"Z ,rem,i,re,n  ,*y ,*y ,rm ,*x ,*x ,rm ,*y ,*x\"))]\n   \"TARGET_64BIT\n    && (TARGET_INTER_UNIT_MOVES || optimize_size)\n    && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n@@ -1986,8 +1992,10 @@\n    (set_attr \"mode\" \"SI,DI,DI,DI,SI,DI,DI,DI,TI,DI,DI,DI,DI\")])\n \n (define_insn \"*movdi_1_rex64_nointerunit\"\n-  [(set (match_operand:DI 0 \"nonimmediate_operand\" \"=r,r,r,mr,!mr,!*y,!m,!*y,!*Y,!m,!*Y\")\n-\t(match_operand:DI 1 \"general_operand\" \"Z,rem,i,re,n,*y,*y,m,*Y,*Y,m\"))]\n+  [(set (match_operand:DI 0 \"nonimmediate_operand\"\n+\t\t\"=r,r ,r,mr,!mr,!*y,!m,!*y,!*Y,!m,!*Y\")\n+\t(match_operand:DI 1 \"general_operand\"\n+\t\t\"Z,rem,i,re,n  ,*y ,*y,m  ,*Y ,*Y,m\"))]\n   \"TARGET_64BIT\n    && (!TARGET_INTER_UNIT_MOVES && !optimize_size)\n    && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n@@ -2179,8 +2187,10 @@\n    (set (mem:SF (reg:DI SP_REG)) (match_dup 1))])\n \n (define_insn \"*movsf_1\"\n-  [(set (match_operand:SF 0 \"nonimmediate_operand\" \"=f#xr,m,f#xr,r#xf,m,x#rf,x#rf,x#rf,m,!*y,!rm,!*y\")\n-\t(match_operand:SF 1 \"general_operand\" \"fm#rx,f#rx,G,rmF#fx,Fr#fx,C,x,xm#rf,x#rf,rm,*y,*y\"))]\n+  [(set (match_operand:SF 0 \"nonimmediate_operand\"\n+\t  \"=f#xr,m   ,f#xr,r#xf  ,m    ,x#rf,x#rf,x#rf ,m   ,!*y,!rm,!*y\")\n+\t(match_operand:SF 1 \"general_operand\"\n+\t  \"fm#rx,f#rx,G   ,rmF#fx,Fr#fx,C   ,x   ,xm#rf,x#rf,rm ,*y ,*y\"))]\n   \"(TARGET_INTER_UNIT_MOVES || optimize_size)\n    && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\n    && (reload_in_progress || reload_completed\n@@ -2267,8 +2277,10 @@\n \t       (const_string \"SF\")))])\n \n (define_insn \"*movsf_1_nointerunit\"\n-  [(set (match_operand:SF 0 \"nonimmediate_operand\" \"=f#xr,m,f#xr,r#xf,m,x#rf,x#rf,x#rf,m,!*y,!m,!*y\")\n-\t(match_operand:SF 1 \"general_operand\" \"fm#rx,f#rx,G,rmF#fx,Fr#fx,C,x,xm#rf,x#rf,m,*y,*y\"))]\n+  [(set (match_operand:SF 0 \"nonimmediate_operand\"\n+\t  \"=f#xr,m   ,f#xr,r#xf  ,m    ,x#rf,x#rf,x#rf ,m   ,!*y,!m,!*y\")\n+\t(match_operand:SF 1 \"general_operand\"\n+\t  \"fm#rx,f#rx,G   ,rmF#fx,Fr#fx,C   ,x   ,xm#rf,x#rf,m  ,*y,*y\"))]\n   \"(!TARGET_INTER_UNIT_MOVES && !optimize_size)\n    && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\n    && (reload_in_progress || reload_completed\n@@ -2355,11 +2367,11 @@\n \t       (const_string \"SF\")))])\n \n (define_insn \"*swapsf\"\n-  [(set (match_operand:SF 0 \"register_operand\" \"+f\")\n-\t(match_operand:SF 1 \"register_operand\" \"+f\"))\n+  [(set (match_operand:SF 0 \"fp_register_operand\" \"+f\")\n+\t(match_operand:SF 1 \"fp_register_operand\" \"+f\"))\n    (set (match_dup 1)\n \t(match_dup 0))]\n-  \"reload_completed || !TARGET_SSE\"\n+  \"reload_completed || TARGET_80387\"\n {\n   if (STACK_TOP_P (operands[0]))\n     return \"fxch\\t%1\";\n@@ -2431,8 +2443,10 @@\n ;; when optimizing for size.\n \n (define_insn \"*movdf_nointeger\"\n-  [(set (match_operand:DF 0 \"nonimmediate_operand\" \"=f#Y,m,f#Y,*r,o,Y#f,Y#f,Y#f,m\")\n-\t(match_operand:DF 1 \"general_operand\" \"fm#Y,f#Y,G,*roF,F*r,C,Y#f,YHm#f,Y#f\"))]\n+  [(set (match_operand:DF 0 \"nonimmediate_operand\"\n+\t\t\t\t\"=f#x,m  ,f#x,*r  ,o  ,x#f,x#f,x#f  ,m\")\n+\t(match_operand:DF 1 \"general_operand\"\n+\t\t\t\t\"fm#x,f#x,G  ,*roF,F*r,C  ,x#f,xHm#f,x#f\"))]\n   \"(GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\n    && ((optimize_size || !TARGET_INTEGER_DFMODE_MOVES) && !TARGET_64BIT)\n    && (reload_in_progress || reload_completed\n@@ -2470,24 +2484,25 @@\n \t  abort ();\n \t}\n     case 6:\n+    case 7:\n+    case 8:\n       switch (get_attr_mode (insn))\n \t{\n \tcase MODE_V4SF:\n \t  return \"movaps\\t{%1, %0|%0, %1}\";\n \tcase MODE_V2DF:\n \t  return \"movapd\\t{%1, %0|%0, %1}\";\n+\tcase MODE_TI:\n+\t  return \"movdqa\\t{%1, %0|%0, %1}\";\n+\tcase MODE_DI:\n+\t  return \"movq\\t{%1, %0|%0, %1}\";\n \tcase MODE_DF:\n \t  return \"movsd\\t{%1, %0|%0, %1}\";\n+\tcase MODE_V1DF:\n+\t  return \"movlpd\\t{%1, %0|%0, %1}\";\n \tdefault:\n \t  abort ();\n \t}\n-    case 7:\n-      if (get_attr_mode (insn) == MODE_V2DF)\n-\treturn \"movlpd\\t{%1, %0|%0, %1}\";\n-      else\n-\treturn \"movsd\\t{%1, %0|%0, %1}\";\n-    case 8:\n-      return \"movsd\\t{%1, %0|%0, %1}\";\n \n     default:\n       abort();\n@@ -2497,28 +2512,42 @@\n    (set (attr \"mode\")\n         (cond [(eq_attr \"alternative\" \"3,4\")\n \t\t (const_string \"SI\")\n+\n+\t       /* For SSE1, we have many fewer alternatives.  */\n+\t       (eq (symbol_ref \"TARGET_SSE2\") (const_int 0))\n+\t\t (cond [(eq_attr \"alternative\" \"5,6\")\n+\t\t\t  (if_then_else\n+\t\t\t    (ne (symbol_ref \"optimize_size\") (const_int 0))\n+\t\t\t    (const_string \"V4SF\")\n+\t\t\t    (const_string \"TI\"))\n+\t\t       ]\n+\t\t   (const_string \"DI\"))\n+\n \t       /* xorps is one byte shorter.  */\n \t       (eq_attr \"alternative\" \"5\")\n \t\t (cond [(ne (symbol_ref \"optimize_size\")\n \t\t\t    (const_int 0))\n \t\t\t  (const_string \"V4SF\")\n \t\t\t(ne (symbol_ref \"TARGET_SSE_LOAD0_BY_PXOR\")\n \t\t\t    (const_int 0))\n-\t\t\t  (const_string \"TI\")]\n+\t\t\t  (const_string \"TI\")\n+\t\t       ]\n \t\t       (const_string \"V2DF\"))\n+\n \t       /* For architectures resolving dependencies on\n \t\t  whole SSE registers use APD move to break dependency\n \t\t  chains, otherwise use short move to avoid extra work.\n \n \t\t  movaps encodes one byte shorter.  */\n \t       (eq_attr \"alternative\" \"6\")\n \t\t (cond\n-\t\t  [(ne (symbol_ref \"optimize_size\")\n-\t\t       (const_int 0))\n-\t\t     (const_string \"V4SF\")\n-\t\t   (ne (symbol_ref \"TARGET_SSE_PARTIAL_REG_DEPENDENCY\")\n-\t\t       (const_int 0))\n-\t\t     (const_string \"V2DF\")]\n+\t\t   [(ne (symbol_ref \"optimize_size\")\n+\t\t        (const_int 0))\n+\t\t      (const_string \"V4SF\")\n+\t\t    (ne (symbol_ref \"TARGET_SSE_PARTIAL_REG_DEPENDENCY\")\n+\t\t        (const_int 0))\n+\t\t      (const_string \"V2DF\")\n+\t\t   ]\n \t\t   (const_string \"DF\"))\n \t       /* For architectures resolving dependencies on register\n \t\t  parts we may avoid extra work to zero out upper part\n@@ -2527,13 +2556,16 @@\n \t\t (if_then_else\n \t\t   (ne (symbol_ref \"TARGET_SSE_PARTIAL_REGS\")\n \t\t       (const_int 0))\n-\t\t   (const_string \"V2DF\")\n-\t\t   (const_string \"DF\"))]\n-\t       (const_string \"DF\")))])\n+\t\t   (const_string \"V1DF\")\n+\t\t   (const_string \"DF\"))\n+\t      ]\n+\t      (const_string \"DF\")))])\n \n (define_insn \"*movdf_integer\"\n-  [(set (match_operand:DF 0 \"nonimmediate_operand\" \"=f#Yr,m,f#Yr,r#Yf,o,Y#rf,Y#rf,Y#rf,m\")\n-\t(match_operand:DF 1 \"general_operand\" \"fm#Yr,f#Yr,G,roF#Yf,Fr#Yf,C,Y#rf,Ym#rf,Y#rf\"))]\n+  [(set (match_operand:DF 0 \"nonimmediate_operand\"\n+\t\t\t\"=f#Yr,m   ,f#Yr,r#Yf  ,o    ,Y#rf,Y#rf,Y#rf ,m\")\n+\t(match_operand:DF 1 \"general_operand\"\n+\t\t\t\"fm#Yr,f#Yr,G   ,roF#Yf,Fr#Yf,C   ,Y#rf,Ym#rf,Y#rf\"))]\n   \"(GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\n    && ((!optimize_size && TARGET_INTEGER_DFMODE_MOVES) || TARGET_64BIT)\n    && (reload_in_progress || reload_completed\n@@ -2572,24 +2604,25 @@\n \t  abort ();\n \t}\n     case 6:\n+    case 7:\n+    case 8:\n       switch (get_attr_mode (insn))\n \t{\n \tcase MODE_V4SF:\n \t  return \"movaps\\t{%1, %0|%0, %1}\";\n \tcase MODE_V2DF:\n \t  return \"movapd\\t{%1, %0|%0, %1}\";\n+\tcase MODE_TI:\n+\t  return \"movdqa\\t{%1, %0|%0, %1}\";\n+\tcase MODE_DI:\n+\t  return \"movq\\t{%1, %0|%0, %1}\";\n \tcase MODE_DF:\n \t  return \"movsd\\t{%1, %0|%0, %1}\";\n+\tcase MODE_V1DF:\n+\t  return \"movlpd\\t{%1, %0|%0, %1}\";\n \tdefault:\n \t  abort ();\n \t}\n-    case 7:\n-      if (get_attr_mode (insn) == MODE_V2DF)\n-\treturn \"movlpd\\t{%1, %0|%0, %1}\";\n-      else\n-\treturn \"movsd\\t{%1, %0|%0, %1}\";\n-    case 8:\n-      return \"movsd\\t{%1, %0|%0, %1}\";\n \n     default:\n       abort();\n@@ -2599,28 +2632,42 @@\n    (set (attr \"mode\")\n         (cond [(eq_attr \"alternative\" \"3,4\")\n \t\t (const_string \"SI\")\n+\n+\t       /* For SSE1, we have many fewer alternatives.  */\n+\t       (eq (symbol_ref \"TARGET_SSE2\") (const_int 0))\n+\t\t (cond [(eq_attr \"alternative\" \"5,6\")\n+\t\t\t  (if_then_else\n+\t\t\t    (ne (symbol_ref \"optimize_size\") (const_int 0))\n+\t\t\t    (const_string \"V4SF\")\n+\t\t\t    (const_string \"TI\"))\n+\t\t       ]\n+\t\t   (const_string \"DI\"))\n+\n \t       /* xorps is one byte shorter.  */\n \t       (eq_attr \"alternative\" \"5\")\n \t\t (cond [(ne (symbol_ref \"optimize_size\")\n \t\t\t    (const_int 0))\n \t\t\t  (const_string \"V4SF\")\n \t\t\t(ne (symbol_ref \"TARGET_SSE_LOAD0_BY_PXOR\")\n \t\t\t    (const_int 0))\n-\t\t\t  (const_string \"TI\")]\n+\t\t\t  (const_string \"TI\")\n+\t\t       ]\n \t\t       (const_string \"V2DF\"))\n+\n \t       /* For architectures resolving dependencies on\n \t\t  whole SSE registers use APD move to break dependency\n-\t\t  chains, otherwise use short move to avoid extra work.  \n+\t\t  chains, otherwise use short move to avoid extra work.\n \n \t\t  movaps encodes one byte shorter.  */\n \t       (eq_attr \"alternative\" \"6\")\n \t\t (cond\n-\t\t  [(ne (symbol_ref \"optimize_size\")\n-\t\t       (const_int 0))\n-\t\t     (const_string \"V4SF\")\n-\t\t   (ne (symbol_ref \"TARGET_SSE_PARTIAL_REG_DEPENDENCY\")\n-\t\t       (const_int 0))\n-\t\t     (const_string \"V2DF\")]\n+\t\t   [(ne (symbol_ref \"optimize_size\")\n+\t\t        (const_int 0))\n+\t\t      (const_string \"V4SF\")\n+\t\t    (ne (symbol_ref \"TARGET_SSE_PARTIAL_REG_DEPENDENCY\")\n+\t\t        (const_int 0))\n+\t\t      (const_string \"V2DF\")\n+\t\t   ]\n \t\t   (const_string \"DF\"))\n \t       /* For architectures resolving dependencies on register\n \t\t  parts we may avoid extra work to zero out upper part\n@@ -2629,9 +2676,10 @@\n \t\t (if_then_else\n \t\t   (ne (symbol_ref \"TARGET_SSE_PARTIAL_REGS\")\n \t\t       (const_int 0))\n-\t\t   (const_string \"V2DF\")\n-\t\t   (const_string \"DF\"))]\n-\t       (const_string \"DF\")))])\n+\t\t   (const_string \"V1DF\")\n+\t\t   (const_string \"DF\"))\n+\t      ]\n+\t      (const_string \"DF\")))])\n \n (define_split\n   [(set (match_operand:DF 0 \"nonimmediate_operand\" \"\")\n@@ -2648,11 +2696,11 @@\n   \"ix86_split_long_move (operands); DONE;\")\n \n (define_insn \"*swapdf\"\n-  [(set (match_operand:DF 0 \"register_operand\" \"+f\")\n-\t(match_operand:DF 1 \"register_operand\" \"+f\"))\n+  [(set (match_operand:DF 0 \"fp_register_operand\" \"+f\")\n+\t(match_operand:DF 1 \"fp_register_operand\" \"+f\"))\n    (set (match_dup 1)\n \t(match_dup 0))]\n-  \"reload_completed || !TARGET_SSE2\"\n+  \"reload_completed || TARGET_80387\"\n {\n   if (STACK_TOP_P (operands[0]))\n     return \"fxch\\t%1\";\n@@ -2843,7 +2891,7 @@\n \t(match_operand:XF 1 \"register_operand\" \"+f\"))\n    (set (match_dup 1)\n \t(match_dup 0))]\n-  \"\"\n+  \"TARGET_80387\"\n {\n   if (STACK_TOP_P (operands[0]))\n     return \"fxch\\t%1\";\n@@ -19759,7 +19807,7 @@\n \n ;; Moves for SSE/MMX regs.\n \n-(define_insn \"movv4sf_internal\"\n+(define_insn \"*movv4sf_internal\"\n   [(set (match_operand:V4SF 0 \"nonimmediate_operand\" \"=x,x,m\")\n \t(match_operand:V4SF 1 \"vector_move_operand\" \"C,xm,x\"))]\n   \"TARGET_SSE\"\n@@ -19784,7 +19832,7 @@\n   operands[2] = CONST0_RTX (V4SFmode);\n })\n \n-(define_insn \"movv4si_internal\"\n+(define_insn \"*movv4si_internal\"\n   [(set (match_operand:V4SI 0 \"nonimmediate_operand\" \"=x,x,m\")\n \t(match_operand:V4SI 1 \"vector_move_operand\" \"C,xm,x\"))]\n   \"TARGET_SSE\"\n@@ -19824,7 +19872,7 @@\n \t\t   (const_string \"TI\"))]\n \t       (const_string \"TI\")))])\n \n-(define_insn \"movv2di_internal\"\n+(define_insn \"*movv2di_internal\"\n   [(set (match_operand:V2DI 0 \"nonimmediate_operand\" \"=x,x,m\")\n \t(match_operand:V2DI 1 \"vector_move_operand\" \"C,xm,x\"))]\n   \"TARGET_SSE\"\n@@ -19878,7 +19926,7 @@\n   operands[2] = CONST0_RTX (V2DFmode);\n })\n \n-(define_insn \"movv8qi_internal\"\n+(define_insn \"*movv8qi_internal\"\n   [(set (match_operand:V8QI 0 \"nonimmediate_operand\" \"=y,y,m,!y,!*Y,?*Y,?m\")\n \t(match_operand:V8QI 1 \"vector_move_operand\" \"C,ym,y,*Y,y,*Ym,*Y\"))]\n   \"TARGET_MMX\n@@ -19894,7 +19942,7 @@\n   [(set_attr \"type\" \"mmxmov,mmxmov,mmxmov,ssecvt,ssecvt,ssemov,ssemov\")\n    (set_attr \"mode\" \"DI\")])\n \n-(define_insn \"movv4hi_internal\"\n+(define_insn \"*movv4hi_internal\"\n   [(set (match_operand:V4HI 0 \"nonimmediate_operand\" \"=y,y,m,!y,!*Y,?*Y,?m\")\n \t(match_operand:V4HI 1 \"vector_move_operand\" \"C,ym,y,*Y,y,*Ym,*Y\"))]\n   \"TARGET_MMX\n@@ -19926,10 +19974,10 @@\n   [(set_attr \"type\" \"mmxmov,mmxmov,mmxmov,ssecvt,ssecvt,ssemov,ssemov\")\n    (set_attr \"mode\" \"DI\")])\n \n-(define_insn \"movv2sf_internal\"\n+(define_insn \"*movv2sf_internal\"\n   [(set (match_operand:V2SF 0 \"nonimmediate_operand\" \"=y,y,m,!y,!*Y,?*x,?m\")\n         (match_operand:V2SF 1 \"vector_move_operand\" \"C,ym,y,*Y,y,*xm,*x\"))]\n-  \"TARGET_3DNOW\n+  \"TARGET_MMX\n    && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n   \"@\n     pxor\\t%0, %0\n@@ -19959,17 +20007,14 @@\n \t(match_operand:TF 1 \"nonimmediate_operand\" \"\"))]\n   \"TARGET_64BIT\"\n {\n-  if (TARGET_64BIT)\n-    ix86_expand_move (TFmode, operands);\n-  else\n-    ix86_expand_vector_move (TFmode, operands);\n+  ix86_expand_move (TFmode, operands);\n   DONE;\n })\n \n-(define_insn \"movv2df_internal\"\n+(define_insn \"*movv2df_internal\"\n   [(set (match_operand:V2DF 0 \"nonimmediate_operand\" \"=x,x,m\")\n \t(match_operand:V2DF 1 \"vector_move_operand\" \"C,xm,x\"))]\n-  \"TARGET_SSE2\n+  \"TARGET_SSE\n    && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n {\n   switch (which_alternative)\n@@ -19991,7 +20036,9 @@\n }\n   [(set_attr \"type\" \"ssemov\")\n    (set (attr \"mode\")\n-        (cond [(eq_attr \"alternative\" \"0,1\")\n+        (cond [(eq (symbol_ref \"TARGET_SSE2\") (const_int 0))\n+\t\t (const_string \"V4SF\")\n+\t       (eq_attr \"alternative\" \"0,1\")\n \t\t (if_then_else\n \t\t   (ne (symbol_ref \"optimize_size\")\n \t\t       (const_int 0))\n@@ -20007,10 +20054,10 @@\n \t\t   (const_string \"V2DF\"))]\n \t       (const_string \"V2DF\")))])\n \n-(define_insn \"movv8hi_internal\"\n+(define_insn \"*movv8hi_internal\"\n   [(set (match_operand:V8HI 0 \"nonimmediate_operand\" \"=x,x,m\")\n \t(match_operand:V8HI 1 \"vector_move_operand\" \"C,xm,x\"))]\n-  \"TARGET_SSE2\n+  \"TARGET_SSE\n    && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n {\n   switch (which_alternative)\n@@ -20048,10 +20095,10 @@\n \t\t   (const_string \"TI\"))]\n \t       (const_string \"TI\")))])\n \n-(define_insn \"movv16qi_internal\"\n+(define_insn \"*movv16qi_internal\"\n   [(set (match_operand:V16QI 0 \"nonimmediate_operand\" \"=x,x,m\")\n \t(match_operand:V16QI 1 \"vector_move_operand\" \"C,xm,x\"))]\n-  \"TARGET_SSE2\n+  \"TARGET_SSE\n    && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n {\n   switch (which_alternative)\n@@ -20092,7 +20139,7 @@\n (define_expand \"movv2df\"\n   [(set (match_operand:V2DF 0 \"nonimmediate_operand\" \"\")\n \t(match_operand:V2DF 1 \"nonimmediate_operand\" \"\"))]\n-  \"TARGET_SSE2\"\n+  \"TARGET_SSE\"\n {\n   ix86_expand_vector_move (V2DFmode, operands);\n   DONE;\n@@ -20101,7 +20148,7 @@\n (define_expand \"movv8hi\"\n   [(set (match_operand:V8HI 0 \"nonimmediate_operand\" \"\")\n \t(match_operand:V8HI 1 \"nonimmediate_operand\" \"\"))]\n-  \"TARGET_SSE2\"\n+  \"TARGET_SSE\"\n {\n   ix86_expand_vector_move (V8HImode, operands);\n   DONE;\n@@ -20110,7 +20157,7 @@\n (define_expand \"movv16qi\"\n   [(set (match_operand:V16QI 0 \"nonimmediate_operand\" \"\")\n \t(match_operand:V16QI 1 \"nonimmediate_operand\" \"\"))]\n-  \"TARGET_SSE2\"\n+  \"TARGET_SSE\"\n {\n   ix86_expand_vector_move (V16QImode, operands);\n   DONE;\n@@ -20173,7 +20220,7 @@\n (define_expand \"movv2sf\"\n   [(set (match_operand:V2SF 0 \"nonimmediate_operand\" \"\")\n \t(match_operand:V2SF 1 \"nonimmediate_operand\" \"\"))]\n-   \"TARGET_3DNOW\"\n+  \"TARGET_MMX\"\n {\n   ix86_expand_vector_move (V2SFmode, operands);\n   DONE;\n@@ -20194,19 +20241,19 @@\n (define_insn \"*pushv2di\"\n   [(set (match_operand:V2DI 0 \"push_operand\" \"=<\")\n \t(match_operand:V2DI 1 \"register_operand\" \"x\"))]\n-  \"TARGET_SSE2\"\n+  \"TARGET_SSE\"\n   \"#\")\n \n (define_insn \"*pushv8hi\"\n   [(set (match_operand:V8HI 0 \"push_operand\" \"=<\")\n \t(match_operand:V8HI 1 \"register_operand\" \"x\"))]\n-  \"TARGET_SSE2\"\n+  \"TARGET_SSE\"\n   \"#\")\n \n (define_insn \"*pushv16qi\"\n   [(set (match_operand:V16QI 0 \"push_operand\" \"=<\")\n \t(match_operand:V16QI 1 \"register_operand\" \"x\"))]\n-  \"TARGET_SSE2\"\n+  \"TARGET_SSE\"\n   \"#\")\n \n (define_insn \"*pushv4sf\"\n@@ -20218,7 +20265,7 @@\n (define_insn \"*pushv4si\"\n   [(set (match_operand:V4SI 0 \"push_operand\" \"=<\")\n \t(match_operand:V4SI 1 \"register_operand\" \"x\"))]\n-  \"TARGET_SSE2\"\n+  \"TARGET_SSE\"\n   \"#\")\n \n (define_insn \"*pushv2si\"\n@@ -20242,7 +20289,7 @@\n (define_insn \"*pushv2sf\"\n   [(set (match_operand:V2SF 0 \"push_operand\" \"=<\")\n \t(match_operand:V2SF 1 \"register_operand\" \"y\"))]\n-  \"TARGET_3DNOW\"\n+  \"TARGET_MMX\"\n   \"#\")\n \n (define_split\n@@ -20268,7 +20315,7 @@\n    operands[3] = GEN_INT (-GET_MODE_SIZE (GET_MODE (operands[0])));\")\n \n \n-(define_insn \"movti_internal\"\n+(define_insn \"*movti_internal\"\n   [(set (match_operand:TI 0 \"nonimmediate_operand\" \"=x,x,m\")\n \t(match_operand:TI 1 \"vector_move_operand\" \"C,xm,x\"))]\n   \"TARGET_SSE && !TARGET_64BIT\n@@ -22196,7 +22243,7 @@\n   [(set (match_operand:V2SI 0 \"register_operand\" \"=y\")\n \t(gt:V2SI (match_operand:V2SF 1 \"register_operand\" \"0\")\n \t\t (match_operand:V2SF 2 \"nonimmediate_operand\" \"ym\")))]\n- \"TARGET_3DNOW\"\n+  \"TARGET_3DNOW\"\n   \"pfcmpgt\\\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"mmxcmp\")\n    (set_attr \"mode\" \"V2SF\")])"}]}