{"sha": "50cb8300d3bf0b487063784fbbe394301b6c79b2", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NTBjYjgzMDBkM2JmMGI0ODcwNjM3ODRmYmJlMzk0MzAxYjZjNzliMg==", "commit": {"author": {"name": "Bill Schmidt", "email": "wschmidt@linux.ibm.com", "date": "2021-07-28T17:22:57Z"}, "committer": {"name": "Bill Schmidt", "email": "wschmidt@linux.ibm.com", "date": "2021-08-24T18:46:07Z"}, "message": "rs6000: Add Power10 builtins\n\n2021-07-28  Bill Schmidt  <wschmidt@linux.ibm.com>\n\ngcc/\n\t* config/rs6000/rs6000-builtin-new.def: Add power10 and power10-64\n\tstanzas.", "tree": {"sha": "ace126ba867710c69fd599207fac93bf8eecd5d4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/ace126ba867710c69fd599207fac93bf8eecd5d4"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/50cb8300d3bf0b487063784fbbe394301b6c79b2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/50cb8300d3bf0b487063784fbbe394301b6c79b2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/50cb8300d3bf0b487063784fbbe394301b6c79b2", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/50cb8300d3bf0b487063784fbbe394301b6c79b2/comments", "author": null, "committer": null, "parents": [{"sha": "19b7bf620cd4e610bb91b5d2ae5446a2b73b6308", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/19b7bf620cd4e610bb91b5d2ae5446a2b73b6308", "html_url": "https://github.com/Rust-GCC/gccrs/commit/19b7bf620cd4e610bb91b5d2ae5446a2b73b6308"}], "stats": {"total": 523, "additions": 523, "deletions": 0}, "files": [{"sha": "b6fc9946ac5a124fdcc527509793f7b0472a99cb", "filename": "gcc/config/rs6000/rs6000-builtin-new.def", "status": "modified", "additions": 523, "deletions": 0, "changes": 523, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/50cb8300d3bf0b487063784fbbe394301b6c79b2/gcc%2Fconfig%2Frs6000%2Frs6000-builtin-new.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/50cb8300d3bf0b487063784fbbe394301b6c79b2/gcc%2Fconfig%2Frs6000%2Frs6000-builtin-new.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000-builtin-new.def?ref=50cb8300d3bf0b487063784fbbe394301b6c79b2", "patch": "@@ -2806,3 +2806,526 @@\n \n   pure vsc __builtin_vsx_xl_len_r (void *, signed long);\n     XL_LEN_R xl_len_r {}\n+\n+\n+[power10]\n+  const vbq __builtin_altivec_cmpge_1ti (vsq, vsq);\n+    CMPGE_1TI vector_nltv1ti {}\n+\n+  const vbq __builtin_altivec_cmpge_u1ti (vuq, vuq);\n+    CMPGE_U1TI vector_nltuv1ti {}\n+\n+  const vbq __builtin_altivec_cmple_1ti (vsq, vsq);\n+    CMPLE_1TI vector_ngtv1ti {}\n+\n+  const vbq __builtin_altivec_cmple_u1ti (vuq, vuq);\n+    CMPLE_U1TI vector_ngtuv1ti {}\n+\n+  const unsigned long long __builtin_altivec_cntmbb (vuc, const int<1>);\n+    VCNTMBB vec_cntmb_v16qi {}\n+\n+  const unsigned long long __builtin_altivec_cntmbd (vull, const int<1>);\n+    VCNTMBD vec_cntmb_v2di {}\n+\n+  const unsigned long long __builtin_altivec_cntmbh (vus, const int<1>);\n+    VCNTMBH vec_cntmb_v8hi {}\n+\n+  const unsigned long long __builtin_altivec_cntmbw (vui, const int<1>);\n+    VCNTMBW vec_cntmb_v4si {}\n+\n+  const vsq __builtin_altivec_div_v1ti (vsq, vsq);\n+    DIV_V1TI vsx_div_v1ti {}\n+\n+  const vsq __builtin_altivec_dives (vsq, vsq);\n+    DIVES_V1TI vsx_dives_v1ti {}\n+\n+  const vuq __builtin_altivec_diveu (vuq, vuq);\n+    DIVEU_V1TI vsx_diveu_v1ti {}\n+\n+  const vsq __builtin_altivec_mods (vsq, vsq);\n+    MODS_V1TI vsx_mods_v1ti {}\n+\n+  const vuq __builtin_altivec_modu (vuq, vuq);\n+    MODU_V1TI vsx_modu_v1ti {}\n+\n+  const vuc __builtin_altivec_mtvsrbm (unsigned long long);\n+    MTVSRBM vec_mtvsr_v16qi {}\n+\n+  const vull __builtin_altivec_mtvsrdm (unsigned long long);\n+    MTVSRDM vec_mtvsr_v2di {}\n+\n+  const vus __builtin_altivec_mtvsrhm (unsigned long long);\n+    MTVSRHM vec_mtvsr_v8hi {}\n+\n+  const vuq __builtin_altivec_mtvsrqm (unsigned long long);\n+    MTVSRQM vec_mtvsr_v1ti {}\n+\n+  const vui __builtin_altivec_mtvsrwm (unsigned long long);\n+    MTVSRWM vec_mtvsr_v4si {}\n+\n+  pure signed __int128 __builtin_altivec_se_lxvrbx (signed long, const signed char *);\n+    SE_LXVRBX vsx_lxvrbx {lxvrse}\n+\n+  pure signed __int128 __builtin_altivec_se_lxvrhx (signed long, const signed short *);\n+    SE_LXVRHX vsx_lxvrhx {lxvrse}\n+\n+  pure signed __int128 __builtin_altivec_se_lxvrwx (signed long, const signed int *);\n+    SE_LXVRWX vsx_lxvrwx {lxvrse}\n+\n+  pure signed __int128 __builtin_altivec_se_lxvrdx (signed long, const signed long long *);\n+    SE_LXVRDX vsx_lxvrdx {lxvrse}\n+\n+  void __builtin_altivec_tr_stxvrbx (vsq, signed long, signed char *);\n+    TR_STXVRBX vsx_stxvrbx {stvec}\n+\n+  void __builtin_altivec_tr_stxvrhx (vsq, signed long, signed int *);\n+    TR_STXVRHX vsx_stxvrhx {stvec}\n+\n+  void __builtin_altivec_tr_stxvrwx (vsq, signed long, signed short *);\n+    TR_STXVRWX vsx_stxvrwx {stvec}\n+\n+  void __builtin_altivec_tr_stxvrdx (vsq, signed long, signed long long *);\n+    TR_STXVRDX vsx_stxvrdx {stvec}\n+\n+  const vuq __builtin_altivec_udiv_v1ti (vuq, vuq);\n+    UDIV_V1TI vsx_udiv_v1ti {}\n+\n+  const vull __builtin_altivec_vcfuged (vull, vull);\n+    VCFUGED vcfuged {}\n+\n+  const vsc __builtin_altivec_vclrlb (vsc, signed int);\n+    VCLRLB vclrlb {}\n+\n+  const vsc __builtin_altivec_vclrrb (vsc, signed int);\n+    VCLRRB vclrrb {}\n+\n+  const signed int __builtin_altivec_vcmpaet_p (vsq, vsq);\n+    VCMPAET_P vector_ae_v1ti_p {}\n+\n+  const vbq __builtin_altivec_vcmpequt (vsq, vsq);\n+    VCMPEQUT vector_eqv1ti {}\n+\n+  const signed int __builtin_altivec_vcmpequt_p (signed int, vsq, vsq);\n+    VCMPEQUT_P vector_eq_v1ti_p {pred}\n+\n+  const vbq __builtin_altivec_vcmpgtst (vsq, vsq);\n+    VCMPGTST vector_gtv1ti {}\n+\n+  const signed int __builtin_altivec_vcmpgtst_p (signed int, vsq, vsq);\n+    VCMPGTST_P vector_gt_v1ti_p {pred}\n+\n+  const vbq __builtin_altivec_vcmpgtut (vuq, vuq);\n+    VCMPGTUT vector_gtuv1ti {}\n+\n+  const signed int __builtin_altivec_vcmpgtut_p (signed int, vuq, vuq);\n+    VCMPGTUT_P vector_gtu_v1ti_p {pred}\n+\n+  const vbq __builtin_altivec_vcmpnet (vsq, vsq);\n+    VCMPNET vcmpnet {}\n+\n+  const signed int __builtin_altivec_vcmpnet_p (vsq, vsq);\n+    VCMPNET_P vector_ne_v1ti_p {}\n+\n+  const vull __builtin_altivec_vclzdm (vull, vull);\n+    VCLZDM vclzdm {}\n+\n+  const vull __builtin_altivec_vctzdm (vull, vull);\n+    VCTZDM vctzdm {}\n+\n+  const vsll __builtin_altivec_vdivesd (vsll, vsll);\n+    VDIVESD dives_v2di {}\n+\n+  const vsi __builtin_altivec_vdivesw (vsi, vsi);\n+    VDIVESW dives_v4si {}\n+\n+  const vull __builtin_altivec_vdiveud (vull, vull);\n+    VDIVEUD diveu_v2di {}\n+\n+  const vui __builtin_altivec_vdiveuw (vui, vui);\n+    VDIVEUW diveu_v4si {}\n+\n+  const vsll __builtin_altivec_vdivsd (vsll, vsll);\n+    VDIVSD divv2di3 {}\n+\n+  const vsi __builtin_altivec_vdivsw (vsi, vsi);\n+    VDIVSW divv4si3 {}\n+\n+  const vull __builtin_altivec_vdivud (vull, vull);\n+    VDIVUD udivv2di3 {}\n+\n+  const vui __builtin_altivec_vdivuw (vui, vui);\n+    VDIVUW udivv4si3 {}\n+\n+  const vuc __builtin_altivec_vexpandmb (vuc);\n+    VEXPANDMB vec_expand_v16qi {}\n+\n+  const vull __builtin_altivec_vexpandmd (vull);\n+    VEXPANDMD vec_expand_v2di {}\n+\n+  const vus __builtin_altivec_vexpandmh (vus);\n+    VEXPANDMH vec_expand_v8hi {}\n+\n+  const vuq __builtin_altivec_vexpandmq (vuq);\n+    VEXPANDMQ vec_expand_v1ti {}\n+\n+  const vui __builtin_altivec_vexpandmw (vui);\n+    VEXPANDMW vec_expand_v4si {}\n+\n+  const vull __builtin_altivec_vextddvhx (vull, vull, unsigned int);\n+    VEXTRACTDR vextractrv2di {}\n+\n+  const vull __builtin_altivec_vextddvlx (vull, vull, unsigned int);\n+    VEXTRACTDL vextractlv2di {}\n+\n+  const vull __builtin_altivec_vextdubvhx (vuc, vuc, unsigned int);\n+    VEXTRACTBR vextractrv16qi {}\n+\n+  const vull __builtin_altivec_vextdubvlx (vuc, vuc, unsigned int);\n+    VEXTRACTBL vextractlv16qi {}\n+\n+  const vull __builtin_altivec_vextduhvhx (vus, vus, unsigned int);\n+    VEXTRACTHR vextractrv8hi {}\n+\n+  const vull __builtin_altivec_vextduhvlx (vus, vus, unsigned int);\n+    VEXTRACTHL vextractlv8hi {}\n+\n+  const vull __builtin_altivec_vextduwvhx (vui, vui, unsigned int);\n+    VEXTRACTWR vextractrv4si {}\n+\n+  const vull __builtin_altivec_vextduwvlx (vui, vui, unsigned int);\n+    VEXTRACTWL vextractlv4si {}\n+\n+  const signed int __builtin_altivec_vextractmb (vsc);\n+    VEXTRACTMB vec_extract_v16qi {}\n+\n+  const signed int __builtin_altivec_vextractmd (vsll);\n+    VEXTRACTMD vec_extract_v2di {}\n+\n+  const signed int __builtin_altivec_vextractmh (vss);\n+    VEXTRACTMH vec_extract_v8hi {}\n+\n+  const signed int __builtin_altivec_vextractmq (vsq);\n+    VEXTRACTMQ vec_extract_v1ti {}\n+\n+  const signed int __builtin_altivec_vextractmw (vsi);\n+    VEXTRACTMW vec_extract_v4si {}\n+\n+  const unsigned long long __builtin_altivec_vgnb (vull, const int <2,7>);\n+    VGNB vgnb {}\n+\n+  const vuc __builtin_altivec_vinsgubvlx (unsigned int, vuc, unsigned int);\n+    VINSERTGPRBL vinsertgl_v16qi {}\n+\n+  const vsc __builtin_altivec_vinsgubvrx (signed int, vsc, signed int);\n+    VINSERTGPRBR vinsertgr_v16qi {}\n+\n+  const vull __builtin_altivec_vinsgudvlx (unsigned int, vull, unsigned int);\n+    VINSERTGPRDL vinsertgl_v2di {}\n+\n+  const vsll __builtin_altivec_vinsgudvrx (signed int, vsll, signed int);\n+    VINSERTGPRDR vinsertgr_v2di {}\n+\n+  const vus __builtin_altivec_vinsguhvlx (unsigned int, vus, unsigned int);\n+    VINSERTGPRHL vinsertgl_v8hi {}\n+\n+  const vss __builtin_altivec_vinsguhvrx (signed int, vss, signed int);\n+    VINSERTGPRHR vinsertgr_v8hi {}\n+\n+  const vui __builtin_altivec_vinsguwvlx (unsigned int, vui, unsigned int);\n+    VINSERTGPRWL vinsertgl_v4si {}\n+\n+  const vsi __builtin_altivec_vinsguwvrx (signed int, vsi, signed int);\n+    VINSERTGPRWR vinsertgr_v4si {}\n+\n+  const vuc __builtin_altivec_vinsvubvlx (vuc, vuc, unsigned int);\n+    VINSERTVPRBL vinsertvl_v16qi {}\n+\n+  const vsc __builtin_altivec_vinsvubvrx (vsc, vsc, signed int);\n+    VINSERTVPRBR vinsertvr_v16qi {}\n+\n+  const vus __builtin_altivec_vinsvuhvlx (vus, vus, unsigned int);\n+    VINSERTVPRHL vinsertvl_v8hi {}\n+\n+  const vss __builtin_altivec_vinsvuhvrx (vss, vss, signed int);\n+    VINSERTVPRHR vinsertvr_v8hi {}\n+\n+  const vui __builtin_altivec_vinsvuwvlx (vui, vui, unsigned int);\n+    VINSERTVPRWL vinsertvl_v4si {}\n+\n+  const vsi __builtin_altivec_vinsvuwvrx (vsi, vsi, signed int);\n+    VINSERTVPRWR vinsertvr_v4si {}\n+\n+  const vsll __builtin_altivec_vmodsd (vsll, vsll);\n+    VMODSD modv2di3 {}\n+\n+  const vsi __builtin_altivec_vmodsw (vsi, vsi);\n+    VMODSW modv4si3 {}\n+\n+  const vull __builtin_altivec_vmodud (vull, vull);\n+    VMODUD umodv2di3 {}\n+\n+  const vui __builtin_altivec_vmoduw (vui, vui);\n+    VMODUW umodv4si3 {}\n+\n+  const vsq __builtin_altivec_vmulesd (vsll, vsll);\n+    VMULESD vec_widen_smult_even_v2di {}\n+\n+  const vuq __builtin_altivec_vmuleud (vull, vull);\n+    VMULEUD vec_widen_umult_even_v2di {}\n+\n+  const vsll __builtin_altivec_vmulhsd (vsll, vsll);\n+    VMULHSD smulv2di3_highpart {}\n+\n+  const vsi __builtin_altivec_vmulhsw (vsi, vsi);\n+    VMULHSW smulv4si3_highpart {}\n+\n+  const vull __builtin_altivec_vmulhud (vull, vull);\n+    VMULHUD umulv2di3_highpart {}\n+\n+  const vui __builtin_altivec_vmulhuw (vui, vui);\n+    VMULHUW umulv4si3_highpart {}\n+\n+  const vsll __builtin_altivec_vmulld (vsll, vsll);\n+    VMULLD mulv2di3 {}\n+\n+  const vsq __builtin_altivec_vmulosd (vsll, vsll);\n+    VMULOSD vec_widen_smult_odd_v2di {}\n+\n+  const vuq __builtin_altivec_vmuloud (vull, vull);\n+    VMULOUD vec_widen_umult_odd_v2di {}\n+\n+  const vsq __builtin_altivec_vnor_v1ti (vsq, vsq);\n+    VNOR_V1TI norv1ti3 {}\n+\n+  const vuq __builtin_altivec_vnor_v1ti_uns (vuq, vuq);\n+    VNOR_V1TI_UNS norv1ti3 {}\n+\n+  const vull __builtin_altivec_vpdepd (vull, vull);\n+    VPDEPD vpdepd {}\n+\n+  const vull __builtin_altivec_vpextd (vull, vull);\n+    VPEXTD vpextd {}\n+\n+  const vull __builtin_altivec_vreplace_un_uv2di (vull, unsigned long long, const int<4>);\n+    VREPLACE_UN_UV2DI vreplace_un_v2di {}\n+\n+  const vui __builtin_altivec_vreplace_un_uv4si (vui, unsigned int, const int<4>);\n+    VREPLACE_UN_UV4SI vreplace_un_v4si {}\n+\n+  const vd __builtin_altivec_vreplace_un_v2df (vd, double, const int<4>);\n+    VREPLACE_UN_V2DF vreplace_un_v2df {}\n+\n+  const vsll __builtin_altivec_vreplace_un_v2di (vsll, signed long long, const int<4>);\n+    VREPLACE_UN_V2DI vreplace_un_v2di {}\n+\n+  const vf __builtin_altivec_vreplace_un_v4sf (vf, float, const int<4>);\n+    VREPLACE_UN_V4SF vreplace_un_v4sf {}\n+\n+  const vsi __builtin_altivec_vreplace_un_v4si (vsi, signed int, const int<4>);\n+    VREPLACE_UN_V4SI vreplace_un_v4si {}\n+\n+  const vull __builtin_altivec_vreplace_uv2di (vull, unsigned long long, const int<1>);\n+    VREPLACE_ELT_UV2DI vreplace_elt_v2di {}\n+\n+  const vui __builtin_altivec_vreplace_uv4si (vui, unsigned int, const int<2>);\n+    VREPLACE_ELT_UV4SI vreplace_elt_v4si {}\n+\n+  const vd __builtin_altivec_vreplace_v2df (vd, double, const int<1>);\n+    VREPLACE_ELT_V2DF vreplace_elt_v2df {}\n+\n+  const vsll __builtin_altivec_vreplace_v2di (vsll, signed long long, const int<1>);\n+    VREPLACE_ELT_V2DI vreplace_elt_v2di {}\n+\n+  const vf __builtin_altivec_vreplace_v4sf (vf, float, const int<2>);\n+    VREPLACE_ELT_V4SF vreplace_elt_v4sf {}\n+\n+  const vsi __builtin_altivec_vreplace_v4si (vsi, signed int, const int<2>);\n+    VREPLACE_ELT_V4SI vreplace_elt_v4si {}\n+\n+  const vsq __builtin_altivec_vrlq (vsq, vuq);\n+    VRLQ vrotlv1ti3 {}\n+\n+  const vsq __builtin_altivec_vrlqmi (vsq, vsq, vuq);\n+    VRLQMI altivec_vrlqmi {}\n+\n+  const vsq __builtin_altivec_vrlqnm (vsq, vuq);\n+    VRLQNM altivec_vrlqnm {}\n+\n+  const vsq __builtin_altivec_vsignext (vsll);\n+    VSIGNEXTSD2Q vsignextend_v2di_v1ti {}\n+\n+  const vsc __builtin_altivec_vsldb_v16qi (vsc, vsc, const int<3>);\n+    VSLDB_V16QI vsldb_v16qi {}\n+\n+  const vsll __builtin_altivec_vsldb_v2di (vsll, vsll, const int<3>);\n+    VSLDB_V2DI vsldb_v2di {}\n+\n+  const vsi __builtin_altivec_vsldb_v4si (vsi, vsi, const int<3>);\n+    VSLDB_V4SI vsldb_v4si {}\n+\n+  const vss __builtin_altivec_vsldb_v8hi (vss, vss, const int<3>);\n+    VSLDB_V8HI vsldb_v8hi {}\n+\n+  const vsq __builtin_altivec_vslq (vsq, vuq);\n+    VSLQ vashlv1ti3 {}\n+\n+  const vsq __builtin_altivec_vsraq (vsq, vuq);\n+    VSRAQ vashrv1ti3 {}\n+\n+  const vsc __builtin_altivec_vsrdb_v16qi (vsc, vsc, const int<3>);\n+    VSRDB_V16QI vsrdb_v16qi {}\n+\n+  const vsll __builtin_altivec_vsrdb_v2di (vsll, vsll, const int<3>);\n+    VSRDB_V2DI vsrdb_v2di {}\n+\n+  const vsi __builtin_altivec_vsrdb_v4si (vsi, vsi, const int<3>);\n+    VSRDB_V4SI vsrdb_v4si {}\n+\n+  const vss __builtin_altivec_vsrdb_v8hi (vss, vss, const int<3>);\n+    VSRDB_V8HI vsrdb_v8hi {}\n+\n+  const vsq __builtin_altivec_vsrq (vsq, vuq);\n+    VSRQ vlshrv1ti3 {}\n+\n+  const vsc __builtin_altivec_vstribl (vsc);\n+    VSTRIBL vstril_v16qi {}\n+\n+  const signed int __builtin_altivec_vstribl_p (vsc);\n+    VSTRIBL_P vstril_p_v16qi {}\n+\n+  const vsc __builtin_altivec_vstribr (vsc);\n+    VSTRIBR vstrir_v16qi {}\n+\n+  const signed int __builtin_altivec_vstribr_p (vsc);\n+    VSTRIBR_P vstrir_p_v16qi {}\n+\n+  const vss __builtin_altivec_vstrihl (vss);\n+    VSTRIHL vstril_v8hi {}\n+\n+  const signed int __builtin_altivec_vstrihl_p (vss);\n+    VSTRIHL_P vstril_p_v8hi {}\n+\n+  const vss __builtin_altivec_vstrihr (vss);\n+    VSTRIHR vstrir_v8hi {}\n+\n+  const signed int __builtin_altivec_vstrihr_p (vss);\n+    VSTRIHR_P vstrir_p_v8hi {}\n+\n+  const signed int __builtin_vsx_xvtlsbb_all_ones (vsc);\n+    XVTLSBB_ONES xvtlsbbo {}\n+\n+  const signed int __builtin_vsx_xvtlsbb_all_zeros (vsc);\n+    XVTLSBB_ZEROS xvtlsbbz {}\n+\n+  const vf __builtin_vsx_vxxsplti32dx_v4sf (vf, const int<1>, float);\n+    VXXSPLTI32DX_V4SF xxsplti32dx_v4sf {}\n+\n+  const vsi __builtin_vsx_vxxsplti32dx_v4si (vsi, const int<1>, signed int);\n+    VXXSPLTI32DX_V4SI xxsplti32dx_v4si {}\n+\n+  const vd __builtin_vsx_vxxspltidp (float);\n+    VXXSPLTIDP xxspltidp_v2df {}\n+\n+  const vf __builtin_vsx_vxxspltiw_v4sf (float);\n+    VXXSPLTIW_V4SF xxspltiw_v4sf {}\n+\n+  const vsi __builtin_vsx_vxxspltiw_v4si (signed int);\n+    VXXSPLTIW_V4SI xxspltiw_v4si {}\n+\n+  const vuc __builtin_vsx_xvcvbf16spn (vuc);\n+    XVCVBF16SPN vsx_xvcvbf16spn {}\n+\n+  const vuc __builtin_vsx_xvcvspbf16 (vuc);\n+    XVCVSPBF16 vsx_xvcvspbf16 {}\n+\n+  const vuc __builtin_vsx_xxblend_v16qi (vuc, vuc, vuc);\n+    VXXBLEND_V16QI xxblend_v16qi {}\n+\n+  const vd __builtin_vsx_xxblend_v2df (vd, vd, vd);\n+    VXXBLEND_V2DF xxblend_v2df {}\n+\n+  const vull __builtin_vsx_xxblend_v2di (vull, vull, vull);\n+    VXXBLEND_V2DI xxblend_v2di {}\n+\n+  const vf __builtin_vsx_xxblend_v4sf (vf, vf, vf);\n+    VXXBLEND_V4SF xxblend_v4sf {}\n+\n+  const vui __builtin_vsx_xxblend_v4si (vui, vui, vui);\n+    VXXBLEND_V4SI xxblend_v4si {}\n+\n+  const vus __builtin_vsx_xxblend_v8hi (vus, vus, vus);\n+    VXXBLEND_V8HI xxblend_v8hi {}\n+\n+  const vull __builtin_vsx_xxeval (vull, vull, vull, const int <8>);\n+    XXEVAL xxeval {}\n+\n+  const vuc __builtin_vsx_xxgenpcvm_v16qi (vuc, const int <2>);\n+    XXGENPCVM_V16QI xxgenpcvm_v16qi {}\n+\n+  const vull __builtin_vsx_xxgenpcvm_v2di (vull, const int <2>);\n+    XXGENPCVM_V2DI xxgenpcvm_v2di {}\n+\n+  const vui __builtin_vsx_xxgenpcvm_v4si (vui, const int <2>);\n+    XXGENPCVM_V4SI xxgenpcvm_v4si {}\n+\n+  const vus __builtin_vsx_xxgenpcvm_v8hi (vus, const int <2>);\n+    XXGENPCVM_V8HI xxgenpcvm_v8hi {}\n+\n+  const vuc __builtin_vsx_xxpermx_uv16qi (vuc, vuc, vuc, const int<3>);\n+    XXPERMX_UV16QI xxpermx {}\n+\n+  const vull __builtin_vsx_xxpermx_uv2di (vull, vull, vuc, const int<3>);\n+    XXPERMX_UV2DI xxpermx {}\n+\n+  const vui __builtin_vsx_xxpermx_uv4si (vui, vui, vuc, const int<3>);\n+    XXPERMX_UV4SI xxpermx {}\n+\n+  const vus __builtin_vsx_xxpermx_uv8hi (vus, vus, vuc, const int<3>);\n+    XXPERMX_UV8HI xxpermx {}\n+\n+  const vsc __builtin_vsx_xxpermx_v16qi (vsc, vsc, vuc, const int<3>);\n+    XXPERMX_V16QI xxpermx {}\n+\n+  const vd __builtin_vsx_xxpermx_v2df (vd, vd, vuc, const int<3>);\n+    XXPERMX_V2DF xxpermx {}\n+\n+  const vsll __builtin_vsx_xxpermx_v2di (vsll, vsll, vuc, const int<3>);\n+    XXPERMX_V2DI xxpermx {}\n+\n+  const vf __builtin_vsx_xxpermx_v4sf (vf, vf, vuc, const int<3>);\n+    XXPERMX_V4SF xxpermx {}\n+\n+  const vsi __builtin_vsx_xxpermx_v4si (vsi, vsi, vuc, const int<3>);\n+    XXPERMX_V4SI xxpermx {}\n+\n+  const vss __builtin_vsx_xxpermx_v8hi (vss, vss, vuc, const int<3>);\n+    XXPERMX_V8HI xxpermx {}\n+\n+  pure unsigned __int128 __builtin_altivec_ze_lxvrbx (signed long, const unsigned char *);\n+    ZE_LXVRBX vsx_lxvrbx {lxvrze}\n+\n+  pure unsigned __int128 __builtin_altivec_ze_lxvrhx (signed long, const unsigned short *);\n+    ZE_LXVRHX vsx_lxvrhx {lxvrze}\n+\n+  pure unsigned __int128 __builtin_altivec_ze_lxvrwx (signed long, const unsigned int *);\n+    ZE_LXVRWX vsx_lxvrwx {lxvrze}\n+\n+  pure unsigned __int128 __builtin_altivec_ze_lxvrdx (signed long, const unsigned long long *);\n+    ZE_LXVRDX vsx_lxvrdx {lxvrze}\n+\n+\n+[power10-64]\n+  const unsigned long long __builtin_cfuged (unsigned long long, unsigned long long);\n+    CFUGED cfuged {}\n+\n+  const unsigned long long __builtin_cntlzdm (unsigned long long, unsigned long long);\n+    CNTLZDM cntlzdm {}\n+\n+  const unsigned long long __builtin_cnttzdm (unsigned long long, unsigned long long);\n+    CNTTZDM cnttzdm {}\n+\n+  const unsigned long long __builtin_pdepd (unsigned long long, unsigned long long);\n+    PDEPD pdepd {}\n+\n+  const unsigned long long __builtin_pextd (unsigned long long, unsigned long long);\n+    PEXTD pextd {}"}]}