{"sha": "b67102aebdbf12edd5321b48c4ac5ca3303324c6", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YjY3MTAyYWViZGJmMTJlZGQ1MzIxYjQ4YzRhYzVjYTMzMDMzMjRjNg==", "commit": {"author": {"name": "Zdenek Dvorak", "email": "dvorakz@suse.cz", "date": "2006-09-24T19:03:57Z"}, "committer": {"name": "Adam Nemet", "email": "nemet@gcc.gnu.org", "date": "2006-09-24T19:03:57Z"}, "message": "tree-ssa-loop-ivopts.c (aff_combination_convert, [...]): New functions.\n\n\t* tree-ssa-loop-ivopts.c (aff_combination_convert,\n\tdetermine_common_wider_type): New functions.\n\t(get_computation_aff): Use them to simplify arithmetic between\n\tUBASE and CBASE if they are shortened from the same type.\n\nCo-Authored-By: Adam Nemet <anemet@caviumnetworks.com>\n\nFrom-SVN: r117182", "tree": {"sha": "5c3ed6cf825260942bd4420fe5ffa2a207ff9ea6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/5c3ed6cf825260942bd4420fe5ffa2a207ff9ea6"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/b67102aebdbf12edd5321b48c4ac5ca3303324c6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b67102aebdbf12edd5321b48c4ac5ca3303324c6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b67102aebdbf12edd5321b48c4ac5ca3303324c6", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b67102aebdbf12edd5321b48c4ac5ca3303324c6/comments", "author": null, "committer": null, "parents": [{"sha": "ab1e659cf766a49fe1923fefc9cbacbd4e320fc4", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ab1e659cf766a49fe1923fefc9cbacbd4e320fc4", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ab1e659cf766a49fe1923fefc9cbacbd4e320fc4"}], "stats": {"total": 113, "additions": 105, "deletions": 8}, "files": [{"sha": "245b081ee9f76f57c3b70b592a595172e38b6ffd", "filename": "gcc/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b67102aebdbf12edd5321b48c4ac5ca3303324c6/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b67102aebdbf12edd5321b48c4ac5ca3303324c6/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=b67102aebdbf12edd5321b48c4ac5ca3303324c6", "patch": "@@ -1,3 +1,11 @@\n+2006-09-24  Zdenek Dvorak <dvorakz@suse.cz>\n+\t    Adam Nemet  <anemet@caviumnetworks.com>\n+\n+\t* tree-ssa-loop-ivopts.c (aff_combination_convert,\n+\tdetermine_common_wider_type): New functions.\n+\t(get_computation_aff): Use them to simplify arithmetic between\n+\tUBASE and CBASE if they are shortened from the same type.\n+\n 2006-09-24  Kazu Hirata  <kazu@codesourcery.com>\n \n \tPR target/28911"}, {"sha": "6029923ae26a672f6bc5db0a1b0fa3a46bc21c93", "filename": "gcc/tree-ssa-loop-ivopts.c", "status": "modified", "additions": 97, "deletions": 8, "changes": 105, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b67102aebdbf12edd5321b48c4ac5ca3303324c6/gcc%2Ftree-ssa-loop-ivopts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b67102aebdbf12edd5321b48c4ac5ca3303324c6/gcc%2Ftree-ssa-loop-ivopts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-ivopts.c?ref=b67102aebdbf12edd5321b48c4ac5ca3303324c6", "patch": "@@ -2762,6 +2762,37 @@ aff_combination_add (struct affine_tree_combination *comb1,\n     aff_combination_add_elt (comb1, comb2->rest, 1);\n }\n \n+/* Convert COMB to TYPE.  */\n+\n+static void\n+aff_combination_convert (tree type, struct affine_tree_combination *comb)\n+{\n+  unsigned prec = TYPE_PRECISION (type);\n+  unsigned i;\n+\n+  /* If the precision of both types is the same, it suffices to change the type\n+     of the whole combination -- the elements are allowed to have another type\n+     equivalent wrto STRIP_NOPS.  */\n+  if (prec == TYPE_PRECISION (comb->type))\n+    {\n+      comb->type = type;\n+      return;\n+    }\n+\n+  comb->mask = (((unsigned HOST_WIDE_INT) 2 << (prec - 1)) - 1);\n+  comb->offset = comb->offset & comb->mask;\n+\n+  /* The type of the elements can be different from comb->type only as\n+     much as what STRIP_NOPS would remove.  We can just directly cast\n+     to TYPE.  */\n+  for (i = 0; i < comb->n; i++)\n+    comb->elts[i] = fold_convert (type, comb->elts[i]);\n+  if (comb->rest)\n+    comb->rest = fold_convert (type, comb->rest);\n+\n+  comb->type = type;\n+}\n+\n /* Splits EXPR into an affine combination of parts.  */\n \n static void\n@@ -2951,6 +2982,44 @@ fold_affine_expr (tree expr)\n   return aff_combination_to_tree (&comb);\n }\n \n+/* If A is (TYPE) BA and B is (TYPE) BB, and the types of BA and BB have the\n+   same precision that is at least as wide as the precision of TYPE, stores\n+   BA to A and BB to B, and returns the type of BA.  Otherwise, returns the\n+   type of A and B.  */\n+\n+static tree\n+determine_common_wider_type (tree *a, tree *b)\n+{\n+  tree wider_type = NULL;\n+  tree suba, subb;\n+  tree atype = TREE_TYPE (*a);\n+\n+  if ((TREE_CODE (*a) == NOP_EXPR\n+       || TREE_CODE (*a) == CONVERT_EXPR))\n+    {\n+      suba = TREE_OPERAND (*a, 0);\n+      wider_type = TREE_TYPE (suba);\n+      if (TYPE_PRECISION (wider_type) < TYPE_PRECISION (atype))\n+\treturn atype;\n+    }\n+  else\n+    return atype;\n+\n+  if ((TREE_CODE (*b) == NOP_EXPR\n+       || TREE_CODE (*b) == CONVERT_EXPR))\n+    {\n+      subb = TREE_OPERAND (*b, 0);\n+      if (TYPE_PRECISION (wider_type) != TYPE_PRECISION (TREE_TYPE (subb)))\n+\treturn atype;\n+    }\n+  else\n+    return atype;\n+\n+  *a = suba;\n+  *b = subb;\n+  return wider_type;\n+}\n+\n /* Determines the expression by that USE is expressed from induction variable\n    CAND at statement AT in LOOP.  The expression is stored in a decomposed\n    form into AFF.  Returns false if USE cannot be expressed using CAND.  */\n@@ -2965,6 +3034,7 @@ get_computation_aff (struct loop *loop,\n   tree cbase = cand->iv->base;\n   tree cstep = cand->iv->step;\n   tree utype = TREE_TYPE (ubase), ctype = TREE_TYPE (cbase);\n+  tree common_type;\n   tree uutype;\n   tree expr, delta;\n   tree ratio;\n@@ -3040,9 +3110,20 @@ get_computation_aff (struct loop *loop,\n \tratioi = 0;\n     }\n \n+  /* In case both UBASE and CBASE are shortened to UUTYPE from some common\n+     type, we achieve better folding by computing their difference in this\n+     wider type, and cast the result to UUTYPE.  We do not need to worry about\n+     overflows, as all the arithmetics will in the end be performed in UUTYPE\n+     anyway.  */\n+  common_type = determine_common_wider_type (&ubase, &cbase);\n+\n   /* We may need to shift the value if we are after the increment.  */\n   if (stmt_after_increment (loop, cand, at))\n-    cbase = fold_build2 (PLUS_EXPR, uutype, cbase, cstep);\n+    {\n+      if (uutype != common_type)\n+\tcstep = fold_convert (common_type, cstep);\n+      cbase = fold_build2 (PLUS_EXPR, common_type, cbase, cstep);\n+    }\n \n   /* use = ubase - ratio * cbase + ratio * var.\n \n@@ -3052,26 +3133,32 @@ get_computation_aff (struct loop *loop,\n      happen, fold is able to apply the distributive law to obtain this form\n      anyway.  */\n \n-  if (TYPE_PRECISION (uutype) > HOST_BITS_PER_WIDE_INT)\n+  if (TYPE_PRECISION (common_type) > HOST_BITS_PER_WIDE_INT)\n     {\n       /* Let's compute in trees and just return the result in AFF.  This case\n \t should not be very common, and fold itself is not that bad either,\n \t so making the aff. functions more complicated to handle this case\n \t is not that urgent.  */\n       if (ratioi == 1)\n \t{\n-\t  delta = fold_build2 (MINUS_EXPR, uutype, ubase, cbase);\n+\t  delta = fold_build2 (MINUS_EXPR, common_type, ubase, cbase);\n+\t  if (uutype != common_type)\n+\t    delta = fold_convert (uutype, delta);\n \t  expr = fold_build2 (PLUS_EXPR, uutype, expr, delta);\n \t}\n       else if (ratioi == -1)\n \t{\n-\t  delta = fold_build2 (PLUS_EXPR, uutype, ubase, cbase);\n+\t  delta = fold_build2 (PLUS_EXPR, common_type, ubase, cbase);\n+\t  if (uutype != common_type)\n+\t    delta = fold_convert (uutype, delta);\n \t  expr = fold_build2 (MINUS_EXPR, uutype, delta, expr);\n \t}\n       else\n \t{\n-\t  delta = fold_build2 (MULT_EXPR, uutype, cbase, ratio);\n-\t  delta = fold_build2 (MINUS_EXPR, uutype, ubase, delta);\n+\t  delta = fold_build2 (MULT_EXPR, common_type, cbase, ratio);\n+\t  delta = fold_build2 (MINUS_EXPR, common_type, ubase, delta);\n+\t  if (uutype != common_type)\n+\t    delta = fold_convert (uutype, delta);\n \t  expr = fold_build2 (MULT_EXPR, uutype, ratio, expr);\n \t  expr = fold_build2 (PLUS_EXPR, uutype, delta, expr);\n \t}\n@@ -3088,12 +3175,14 @@ get_computation_aff (struct loop *loop,\n      possible to compute ratioi.  */\n   gcc_assert (ratioi);\n \n-  tree_to_aff_combination (ubase, uutype, aff);\n-  tree_to_aff_combination (cbase, uutype, &cbase_aff);\n+  tree_to_aff_combination (ubase, common_type, aff);\n+  tree_to_aff_combination (cbase, common_type, &cbase_aff);\n   tree_to_aff_combination (expr, uutype, &expr_aff);\n   aff_combination_scale (&cbase_aff, -ratioi);\n   aff_combination_scale (&expr_aff, ratioi);\n   aff_combination_add (aff, &cbase_aff);\n+  if (common_type != uutype)\n+    aff_combination_convert (uutype, aff);\n   aff_combination_add (aff, &expr_aff);\n \n   return true;"}]}