{"sha": "543f217b7aea9a8cdc3b669c5ce7d56a1e944257", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NTQzZjIxN2I3YWVhOWE4Y2RjM2I2NjljNWNlN2Q1NmExZTk0NDI1Nw==", "commit": {"author": {"name": "Ian Lance Taylor", "email": "ian@gcc.gnu.org", "date": "2016-10-12T15:38:56Z"}, "committer": {"name": "Ian Lance Taylor", "email": "ian@gcc.gnu.org", "date": "2016-10-12T15:38:56Z"}, "message": "runtime: copy Go 1.7 runtime semaphore code\n    \n    This triggered a check in releaseSudog that g.param not nil, because\n    libgo uses the param field when starting a goroutine.  Fixed by clearing\n    g->param in kickoff in proc.c.\n    \n    Reviewed-on: https://go-review.googlesource.com/30951\n\nFrom-SVN: r241067", "tree": {"sha": "e893441fcdcea3e67f857c489e3e5cb2851da59e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/e893441fcdcea3e67f857c489e3e5cb2851da59e"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/543f217b7aea9a8cdc3b669c5ce7d56a1e944257", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/543f217b7aea9a8cdc3b669c5ce7d56a1e944257", "html_url": "https://github.com/Rust-GCC/gccrs/commit/543f217b7aea9a8cdc3b669c5ce7d56a1e944257", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/543f217b7aea9a8cdc3b669c5ce7d56a1e944257/comments", "author": null, "committer": null, "parents": [{"sha": "859e95abb84b67a2cb42d6e6013c16160d9c802d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/859e95abb84b67a2cb42d6e6013c16160d9c802d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/859e95abb84b67a2cb42d6e6013c16160d9c802d"}], "stats": {"total": 846, "additions": 368, "deletions": 478}, "files": [{"sha": "b5ba744b3b5cbf5bcc5532bc86e661057b4baa06", "filename": "gcc/go/gofrontend/MERGE", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/543f217b7aea9a8cdc3b669c5ce7d56a1e944257/gcc%2Fgo%2Fgofrontend%2FMERGE", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/543f217b7aea9a8cdc3b669c5ce7d56a1e944257/gcc%2Fgo%2Fgofrontend%2FMERGE", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgo%2Fgofrontend%2FMERGE?ref=543f217b7aea9a8cdc3b669c5ce7d56a1e944257", "patch": "@@ -1,4 +1,4 @@\n-d56717f8c434b3d6b753c027487681769e201e14\n+7e4543d050339e113e6278fd442d940c0f1a5670\n \n The first line of this file holds the git revision number of the last\n merge done from the gofrontend repository."}, {"sha": "d37bb68ba9c90f9338f87698f619de3ad81a7824", "filename": "libgo/Makefile.am", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/543f217b7aea9a8cdc3b669c5ce7d56a1e944257/libgo%2FMakefile.am", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/543f217b7aea9a8cdc3b669c5ce7d56a1e944257/libgo%2FMakefile.am", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2FMakefile.am?ref=543f217b7aea9a8cdc3b669c5ce7d56a1e944257", "patch": "@@ -528,7 +528,6 @@ runtime_files = \\\n \trdebug.c \\\n \treflect.c \\\n \truntime1.c \\\n-\tsema.c \\\n \tsigqueue.c \\\n \tstring.c \\\n \ttime.c \\"}, {"sha": "8493333290ca8ee3f52ddc021a37e43ba059f337", "filename": "libgo/Makefile.in", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/543f217b7aea9a8cdc3b669c5ce7d56a1e944257/libgo%2FMakefile.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/543f217b7aea9a8cdc3b669c5ce7d56a1e944257/libgo%2FMakefile.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2FMakefile.in?ref=543f217b7aea9a8cdc3b669c5ce7d56a1e944257", "patch": "@@ -265,7 +265,7 @@ am__objects_6 = go-append.lo go-assert.lo go-assert-interface.lo \\\n \t$(am__objects_2) panic.lo parfor.lo print.lo proc.lo \\\n \truntime.lo signal_unix.lo thread.lo $(am__objects_3) yield.lo \\\n \t$(am__objects_4) cpuprof.lo go-iface.lo lfstack.lo malloc.lo \\\n-\tmprof.lo netpoll.lo rdebug.lo reflect.lo runtime1.lo sema.lo \\\n+\tmprof.lo netpoll.lo rdebug.lo reflect.lo runtime1.lo \\\n \tsigqueue.lo string.lo time.lo $(am__objects_5)\n am_libgo_llgo_la_OBJECTS = $(am__objects_6)\n libgo_llgo_la_OBJECTS = $(am_libgo_llgo_la_OBJECTS)\n@@ -930,7 +930,6 @@ runtime_files = \\\n \trdebug.c \\\n \treflect.c \\\n \truntime1.c \\\n-\tsema.c \\\n \tsigqueue.c \\\n \tstring.c \\\n \ttime.c \\\n@@ -1656,7 +1655,6 @@ distclean-compile:\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/rtems-task-variable-add.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/runtime.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/runtime1.Plo@am__quote@\n-@AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/sema.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/signal_unix.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/sigqueue.Plo@am__quote@\n @AMDEP_TRUE@@am__include@ @am__quote@./$(DEPDIR)/string.Plo@am__quote@"}, {"sha": "855d73ef4f485eea68ac37e87f4c561aa4f6290d", "filename": "libgo/go/runtime/sema.go", "status": "added", "additions": 358, "deletions": 0, "changes": 358, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/543f217b7aea9a8cdc3b669c5ce7d56a1e944257/libgo%2Fgo%2Fruntime%2Fsema.go", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/543f217b7aea9a8cdc3b669c5ce7d56a1e944257/libgo%2Fgo%2Fruntime%2Fsema.go", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fgo%2Fruntime%2Fsema.go?ref=543f217b7aea9a8cdc3b669c5ce7d56a1e944257", "patch": "@@ -0,0 +1,358 @@\n+// Copyright 2009 The Go Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style\n+// license that can be found in the LICENSE file.\n+\n+// Semaphore implementation exposed to Go.\n+// Intended use is provide a sleep and wakeup\n+// primitive that can be used in the contended case\n+// of other synchronization primitives.\n+// Thus it targets the same goal as Linux's futex,\n+// but it has much simpler semantics.\n+//\n+// That is, don't think of these as semaphores.\n+// Think of them as a way to implement sleep and wakeup\n+// such that every sleep is paired with a single wakeup,\n+// even if, due to races, the wakeup happens before the sleep.\n+//\n+// See Mullender and Cox, ``Semaphores in Plan 9,''\n+// http://swtch.com/semaphore.pdf\n+\n+package runtime\n+\n+// Export temporarily for gccgo's C code to call:\n+//go:linkname semacquire runtime.semacquire\n+//go:linkname semrelease runtime.semrelease\n+\n+import (\n+\t\"runtime/internal/atomic\"\n+\t\"runtime/internal/sys\"\n+\t\"unsafe\"\n+)\n+\n+// Asynchronous semaphore for sync.Mutex.\n+\n+type semaRoot struct {\n+\tlock  mutex\n+\thead  *sudog\n+\ttail  *sudog\n+\tnwait uint32 // Number of waiters. Read w/o the lock.\n+}\n+\n+// Prime to not correlate with any user patterns.\n+const semTabSize = 251\n+\n+var semtable [semTabSize]struct {\n+\troot semaRoot\n+\tpad  [sys.CacheLineSize - unsafe.Sizeof(semaRoot{})]byte\n+}\n+\n+//go:linkname sync_runtime_Semacquire sync.runtime_Semacquire\n+func sync_runtime_Semacquire(addr *uint32) {\n+\tsemacquire(addr, true)\n+}\n+\n+//go:linkname net_runtime_Semacquire net.runtime_Semacquire\n+func net_runtime_Semacquire(addr *uint32) {\n+\tsemacquire(addr, true)\n+}\n+\n+//go:linkname sync_runtime_Semrelease sync.runtime_Semrelease\n+func sync_runtime_Semrelease(addr *uint32) {\n+\tsemrelease(addr)\n+}\n+\n+//go:linkname net_runtime_Semrelease net.runtime_Semrelease\n+func net_runtime_Semrelease(addr *uint32) {\n+\tsemrelease(addr)\n+}\n+\n+func readyWithTime(s *sudog, traceskip int) {\n+\tif s.releasetime != 0 {\n+\t\ts.releasetime = cputicks()\n+\t}\n+\tgoready(s.g, traceskip)\n+}\n+\n+// Called from runtime.\n+func semacquire(addr *uint32, profile bool) {\n+\tgp := getg()\n+\tif gp != gp.m.curg {\n+\t\tthrow(\"semacquire not on the G stack\")\n+\t}\n+\n+\t// Easy case.\n+\tif cansemacquire(addr) {\n+\t\treturn\n+\t}\n+\n+\t// Harder case:\n+\t//\tincrement waiter count\n+\t//\ttry cansemacquire one more time, return if succeeded\n+\t//\tenqueue itself as a waiter\n+\t//\tsleep\n+\t//\t(waiter descriptor is dequeued by signaler)\n+\ts := acquireSudog()\n+\troot := semroot(addr)\n+\tt0 := int64(0)\n+\ts.releasetime = 0\n+\tif profile && blockprofilerate > 0 {\n+\t\tt0 = cputicks()\n+\t\ts.releasetime = -1\n+\t}\n+\tfor {\n+\t\tlock(&root.lock)\n+\t\t// Add ourselves to nwait to disable \"easy case\" in semrelease.\n+\t\tatomic.Xadd(&root.nwait, 1)\n+\t\t// Check cansemacquire to avoid missed wakeup.\n+\t\tif cansemacquire(addr) {\n+\t\t\tatomic.Xadd(&root.nwait, -1)\n+\t\t\tunlock(&root.lock)\n+\t\t\tbreak\n+\t\t}\n+\t\t// Any semrelease after the cansemacquire knows we're waiting\n+\t\t// (we set nwait above), so go to sleep.\n+\t\troot.queue(addr, s)\n+\t\tgoparkunlock(&root.lock, \"semacquire\", traceEvGoBlockSync, 4)\n+\t\tif cansemacquire(addr) {\n+\t\t\tbreak\n+\t\t}\n+\t}\n+\tif s.releasetime > 0 {\n+\t\tblockevent(s.releasetime-t0, 3)\n+\t}\n+\treleaseSudog(s)\n+}\n+\n+func semrelease(addr *uint32) {\n+\troot := semroot(addr)\n+\tatomic.Xadd(addr, 1)\n+\n+\t// Easy case: no waiters?\n+\t// This check must happen after the xadd, to avoid a missed wakeup\n+\t// (see loop in semacquire).\n+\tif atomic.Load(&root.nwait) == 0 {\n+\t\treturn\n+\t}\n+\n+\t// Harder case: search for a waiter and wake it.\n+\tlock(&root.lock)\n+\tif atomic.Load(&root.nwait) == 0 {\n+\t\t// The count is already consumed by another goroutine,\n+\t\t// so no need to wake up another goroutine.\n+\t\tunlock(&root.lock)\n+\t\treturn\n+\t}\n+\ts := root.head\n+\tfor ; s != nil; s = s.next {\n+\t\tif s.elem == unsafe.Pointer(addr) {\n+\t\t\tatomic.Xadd(&root.nwait, -1)\n+\t\t\troot.dequeue(s)\n+\t\t\tbreak\n+\t\t}\n+\t}\n+\tunlock(&root.lock)\n+\tif s != nil {\n+\t\treadyWithTime(s, 5)\n+\t}\n+}\n+\n+func semroot(addr *uint32) *semaRoot {\n+\treturn &semtable[(uintptr(unsafe.Pointer(addr))>>3)%semTabSize].root\n+}\n+\n+func cansemacquire(addr *uint32) bool {\n+\tfor {\n+\t\tv := atomic.Load(addr)\n+\t\tif v == 0 {\n+\t\t\treturn false\n+\t\t}\n+\t\tif atomic.Cas(addr, v, v-1) {\n+\t\t\treturn true\n+\t\t}\n+\t}\n+}\n+\n+func (root *semaRoot) queue(addr *uint32, s *sudog) {\n+\ts.g = getg()\n+\ts.elem = unsafe.Pointer(addr)\n+\ts.next = nil\n+\ts.prev = root.tail\n+\tif root.tail != nil {\n+\t\troot.tail.next = s\n+\t} else {\n+\t\troot.head = s\n+\t}\n+\troot.tail = s\n+}\n+\n+func (root *semaRoot) dequeue(s *sudog) {\n+\tif s.next != nil {\n+\t\ts.next.prev = s.prev\n+\t} else {\n+\t\troot.tail = s.prev\n+\t}\n+\tif s.prev != nil {\n+\t\ts.prev.next = s.next\n+\t} else {\n+\t\troot.head = s.next\n+\t}\n+\ts.elem = nil\n+\ts.next = nil\n+\ts.prev = nil\n+}\n+\n+// notifyList is a ticket-based notification list used to implement sync.Cond.\n+//\n+// It must be kept in sync with the sync package.\n+type notifyList struct {\n+\t// wait is the ticket number of the next waiter. It is atomically\n+\t// incremented outside the lock.\n+\twait uint32\n+\n+\t// notify is the ticket number of the next waiter to be notified. It can\n+\t// be read outside the lock, but is only written to with lock held.\n+\t//\n+\t// Both wait & notify can wrap around, and such cases will be correctly\n+\t// handled as long as their \"unwrapped\" difference is bounded by 2^31.\n+\t// For this not to be the case, we'd need to have 2^31+ goroutines\n+\t// blocked on the same condvar, which is currently not possible.\n+\tnotify uint32\n+\n+\t// List of parked waiters.\n+\tlock mutex\n+\thead *sudog\n+\ttail *sudog\n+}\n+\n+// less checks if a < b, considering a & b running counts that may overflow the\n+// 32-bit range, and that their \"unwrapped\" difference is always less than 2^31.\n+func less(a, b uint32) bool {\n+\treturn int32(a-b) < 0\n+}\n+\n+// notifyListAdd adds the caller to a notify list such that it can receive\n+// notifications. The caller must eventually call notifyListWait to wait for\n+// such a notification, passing the returned ticket number.\n+//go:linkname notifyListAdd sync.runtime_notifyListAdd\n+func notifyListAdd(l *notifyList) uint32 {\n+\t// This may be called concurrently, for example, when called from\n+\t// sync.Cond.Wait while holding a RWMutex in read mode.\n+\treturn atomic.Xadd(&l.wait, 1) - 1\n+}\n+\n+// notifyListWait waits for a notification. If one has been sent since\n+// notifyListAdd was called, it returns immediately. Otherwise, it blocks.\n+//go:linkname notifyListWait sync.runtime_notifyListWait\n+func notifyListWait(l *notifyList, t uint32) {\n+\tlock(&l.lock)\n+\n+\t// Return right away if this ticket has already been notified.\n+\tif less(t, l.notify) {\n+\t\tunlock(&l.lock)\n+\t\treturn\n+\t}\n+\n+\t// Enqueue itself.\n+\ts := acquireSudog()\n+\ts.g = getg()\n+\ts.ticket = t\n+\ts.releasetime = 0\n+\tt0 := int64(0)\n+\tif blockprofilerate > 0 {\n+\t\tt0 = cputicks()\n+\t\ts.releasetime = -1\n+\t}\n+\tif l.tail == nil {\n+\t\tl.head = s\n+\t} else {\n+\t\tl.tail.next = s\n+\t}\n+\tl.tail = s\n+\tgoparkunlock(&l.lock, \"semacquire\", traceEvGoBlockCond, 3)\n+\tif t0 != 0 {\n+\t\tblockevent(s.releasetime-t0, 2)\n+\t}\n+\treleaseSudog(s)\n+}\n+\n+// notifyListNotifyAll notifies all entries in the list.\n+//go:linkname notifyListNotifyAll sync.runtime_notifyListNotifyAll\n+func notifyListNotifyAll(l *notifyList) {\n+\t// Fast-path: if there are no new waiters since the last notification\n+\t// we don't need to acquire the lock.\n+\tif atomic.Load(&l.wait) == atomic.Load(&l.notify) {\n+\t\treturn\n+\t}\n+\n+\t// Pull the list out into a local variable, waiters will be readied\n+\t// outside the lock.\n+\tlock(&l.lock)\n+\ts := l.head\n+\tl.head = nil\n+\tl.tail = nil\n+\n+\t// Update the next ticket to be notified. We can set it to the current\n+\t// value of wait because any previous waiters are already in the list\n+\t// or will notice that they have already been notified when trying to\n+\t// add themselves to the list.\n+\tatomic.Store(&l.notify, atomic.Load(&l.wait))\n+\tunlock(&l.lock)\n+\n+\t// Go through the local list and ready all waiters.\n+\tfor s != nil {\n+\t\tnext := s.next\n+\t\ts.next = nil\n+\t\treadyWithTime(s, 4)\n+\t\ts = next\n+\t}\n+}\n+\n+// notifyListNotifyOne notifies one entry in the list.\n+//go:linkname notifyListNotifyOne sync.runtime_notifyListNotifyOne\n+func notifyListNotifyOne(l *notifyList) {\n+\t// Fast-path: if there are no new waiters since the last notification\n+\t// we don't need to acquire the lock at all.\n+\tif atomic.Load(&l.wait) == atomic.Load(&l.notify) {\n+\t\treturn\n+\t}\n+\n+\tlock(&l.lock)\n+\n+\t// Re-check under the lock if we need to do anything.\n+\tt := l.notify\n+\tif t == atomic.Load(&l.wait) {\n+\t\tunlock(&l.lock)\n+\t\treturn\n+\t}\n+\n+\t// Update the next notify ticket number, and try to find the G that\n+\t// needs to be notified. If it hasn't made it to the list yet we won't\n+\t// find it, but it won't park itself once it sees the new notify number.\n+\tatomic.Store(&l.notify, t+1)\n+\tfor p, s := (*sudog)(nil), l.head; s != nil; p, s = s, s.next {\n+\t\tif s.ticket == t {\n+\t\t\tn := s.next\n+\t\t\tif p != nil {\n+\t\t\t\tp.next = n\n+\t\t\t} else {\n+\t\t\t\tl.head = n\n+\t\t\t}\n+\t\t\tif n == nil {\n+\t\t\t\tl.tail = p\n+\t\t\t}\n+\t\t\tunlock(&l.lock)\n+\t\t\ts.next = nil\n+\t\t\treadyWithTime(s, 4)\n+\t\t\treturn\n+\t\t}\n+\t}\n+\tunlock(&l.lock)\n+}\n+\n+//go:linkname notifyListCheck sync.runtime_notifyListCheck\n+func notifyListCheck(sz uintptr) {\n+\tif sz != unsafe.Sizeof(notifyList{}) {\n+\t\tprint(\"runtime: bad notifyList size - sync=\", sz, \" runtime=\", unsafe.Sizeof(notifyList{}), \"\\n\")\n+\t\tthrow(\"bad notifyList size\")\n+\t}\n+}"}, {"sha": "eb9e6c21e44bde809b6fcf39af3378a025837aa1", "filename": "libgo/runtime/proc.c", "status": "modified", "additions": 4, "deletions": 1, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/543f217b7aea9a8cdc3b669c5ce7d56a1e944257/libgo%2Fruntime%2Fproc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/543f217b7aea9a8cdc3b669c5ce7d56a1e944257/libgo%2Fruntime%2Fproc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fproc.c?ref=543f217b7aea9a8cdc3b669c5ce7d56a1e944257", "patch": "@@ -246,12 +246,15 @@ static void\n kickoff(void)\n {\n \tvoid (*fn)(void*);\n+\tvoid *param;\n \n \tif(g->traceback != nil)\n \t\tgtraceback(g);\n \n \tfn = (void (*)(void*))(g->entry);\n-\tfn(g->param);\n+\tparam = g->param;\n+\tg->param = nil;\n+\tfn(param);\n \truntime_goexit();\n }\n "}, {"sha": "69d2f5a7b2f6153021136371489bb808bc1fea64", "filename": "libgo/runtime/runtime.h", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/543f217b7aea9a8cdc3b669c5ce7d56a1e944257/libgo%2Fruntime%2Fruntime.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/543f217b7aea9a8cdc3b669c5ce7d56a1e944257/libgo%2Fruntime%2Fruntime.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fruntime.h?ref=543f217b7aea9a8cdc3b669c5ce7d56a1e944257", "patch": "@@ -552,8 +552,10 @@ void\truntime_newErrorCString(const char*, Eface*)\n /*\n  * wrapped for go users\n  */\n-void\truntime_semacquire(uint32 volatile *, bool);\n-void\truntime_semrelease(uint32 volatile *);\n+void\truntime_semacquire(uint32 volatile *, bool)\n+     __asm__ (GOSYM_PREFIX \"runtime.semacquire\");\n+void\truntime_semrelease(uint32 volatile *)\n+     __asm__ (GOSYM_PREFIX \"runtime.semrelease\");\n int32\truntime_gomaxprocsfunc(int32 n);\n void\truntime_procyield(uint32)\n   __asm__(GOSYM_PREFIX \"runtime.procyield\");"}, {"sha": "b0d198e6073446096592467ae7f3d4d287158a05", "filename": "libgo/runtime/sema.goc", "status": "removed", "additions": 0, "deletions": 470, "changes": 470, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/859e95abb84b67a2cb42d6e6013c16160d9c802d/libgo%2Fruntime%2Fsema.goc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/859e95abb84b67a2cb42d6e6013c16160d9c802d/libgo%2Fruntime%2Fsema.goc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fruntime%2Fsema.goc?ref=859e95abb84b67a2cb42d6e6013c16160d9c802d", "patch": "@@ -1,470 +0,0 @@\n-// Copyright 2009 The Go Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style\n-// license that can be found in the LICENSE file.\n-\n-// Semaphore implementation exposed to Go.\n-// Intended use is provide a sleep and wakeup\n-// primitive that can be used in the contended case\n-// of other synchronization primitives.\n-// Thus it targets the same goal as Linux's futex,\n-// but it has much simpler semantics.\n-//\n-// That is, don't think of these as semaphores.\n-// Think of them as a way to implement sleep and wakeup\n-// such that every sleep is paired with a single wakeup,\n-// even if, due to races, the wakeup happens before the sleep.\n-//\n-// See Mullender and Cox, ``Semaphores in Plan 9,''\n-// http://swtch.com/semaphore.pdf\n-\n-package sync\n-#include \"runtime.h\"\n-#include \"arch.h\"\n-\n-typedef struct SemaWaiter SemaWaiter;\n-struct SemaWaiter\n-{\n-\tuint32 volatile*\taddr;\n-\tG*\tg;\n-\tint64\treleasetime;\n-\tint32\tnrelease;\t// -1 for acquire\n-\tSemaWaiter*\tprev;\n-\tSemaWaiter*\tnext;\n-};\n-\n-typedef struct SemaRoot SemaRoot;\n-struct SemaRoot\n-{\n-\tLock;\n-\tSemaWaiter*\thead;\n-\tSemaWaiter*\ttail;\n-\t// Number of waiters. Read w/o the lock.\n-\tuint32 volatile\tnwait;\n-};\n-\n-// Prime to not correlate with any user patterns.\n-#define SEMTABLESZ 251\n-\n-struct semtable\n-{\n-\tSemaRoot;\n-\tuint8 pad[CacheLineSize-sizeof(SemaRoot)];\n-};\n-static struct semtable semtable[SEMTABLESZ];\n-\n-static SemaRoot*\n-semroot(uint32 volatile *addr)\n-{\n-\treturn &semtable[((uintptr)addr >> 3) % SEMTABLESZ];\n-}\n-\n-static void\n-semqueue(SemaRoot *root, uint32 volatile *addr, SemaWaiter *s)\n-{\n-\ts->g = runtime_g();\n-\ts->addr = addr;\n-\ts->next = nil;\n-\ts->prev = root->tail;\n-\tif(root->tail)\n-\t\troot->tail->next = s;\n-\telse\n-\t\troot->head = s;\n-\troot->tail = s;\n-}\n-\n-static void\n-semdequeue(SemaRoot *root, SemaWaiter *s)\n-{\n-\tif(s->next)\n-\t\ts->next->prev = s->prev;\n-\telse\n-\t\troot->tail = s->prev;\n-\tif(s->prev)\n-\t\ts->prev->next = s->next;\n-\telse\n-\t\troot->head = s->next;\n-\ts->prev = nil;\n-\ts->next = nil;\n-}\n-\n-static int32\n-cansemacquire(uint32 volatile *addr)\n-{\n-\tuint32 v;\n-\n-\twhile((v = runtime_atomicload(addr)) > 0)\n-\t\tif(runtime_cas(addr, v, v-1))\n-\t\t\treturn 1;\n-\treturn 0;\n-}\n-\n-static void readyWithTime(SudoG* s, int traceskip __attribute__ ((unused))) {\n-\tif (s->releasetime != 0) {\n-\t\ts->releasetime = runtime_cputicks();\n-\t}\n-\truntime_ready(s->g);\n-}\n-\n-void\n-runtime_semacquire(uint32 volatile *addr, bool profile)\n-{\n-\tSemaWaiter s;\t// Needs to be allocated on stack, otherwise garbage collector could deallocate it\n-\tSemaRoot *root;\n-\tint64 t0;\n-\t\n-\t// Easy case.\n-\tif(cansemacquire(addr))\n-\t\treturn;\n-\n-\t// Harder case:\n-\t//\tincrement waiter count\n-\t//\ttry cansemacquire one more time, return if succeeded\n-\t//\tenqueue itself as a waiter\n-\t//\tsleep\n-\t//\t(waiter descriptor is dequeued by signaler)\n-\troot = semroot(addr);\n-\tt0 = 0;\n-\ts.releasetime = 0;\n-\tif(profile && runtime_blockprofilerate > 0) {\n-\t\tt0 = runtime_cputicks();\n-\t\ts.releasetime = -1;\n-\t}\n-\tfor(;;) {\n-\n-\t\truntime_lock(root);\n-\t\t// Add ourselves to nwait to disable \"easy case\" in semrelease.\n-\t\truntime_xadd(&root->nwait, 1);\n-\t\t// Check cansemacquire to avoid missed wakeup.\n-\t\tif(cansemacquire(addr)) {\n-\t\t\truntime_xadd(&root->nwait, -1);\n-\t\t\truntime_unlock(root);\n-\t\t\treturn;\n-\t\t}\n-\t\t// Any semrelease after the cansemacquire knows we're waiting\n-\t\t// (we set nwait above), so go to sleep.\n-\t\tsemqueue(root, addr, &s);\n-\t\truntime_parkunlock(root, \"semacquire\");\n-\t\tif(cansemacquire(addr)) {\n-\t\t\tif(t0)\n-\t\t\t\truntime_blockevent(s.releasetime - t0, 3);\n-\t\t\treturn;\n-\t\t}\n-\t}\n-}\n-\n-void\n-runtime_semrelease(uint32 volatile *addr)\n-{\n-\tSemaWaiter *s;\n-\tSemaRoot *root;\n-\n-\troot = semroot(addr);\n-\truntime_xadd(addr, 1);\n-\n-\t// Easy case: no waiters?\n-\t// This check must happen after the xadd, to avoid a missed wakeup\n-\t// (see loop in semacquire).\n-\tif(runtime_atomicload(&root->nwait) == 0)\n-\t\treturn;\n-\n-\t// Harder case: search for a waiter and wake it.\n-\truntime_lock(root);\n-\tif(runtime_atomicload(&root->nwait) == 0) {\n-\t\t// The count is already consumed by another goroutine,\n-\t\t// so no need to wake up another goroutine.\n-\t\truntime_unlock(root);\n-\t\treturn;\n-\t}\n-\tfor(s = root->head; s; s = s->next) {\n-\t\tif(s->addr == addr) {\n-\t\t\truntime_xadd(&root->nwait, -1);\n-\t\t\tsemdequeue(root, s);\n-\t\t\tbreak;\n-\t\t}\n-\t}\n-\truntime_unlock(root);\n-\tif(s) {\n-\t\tif(s->releasetime)\n-\t\t\ts->releasetime = runtime_cputicks();\n-\t\truntime_ready(s->g);\n-\t}\n-}\n-\n-// TODO(dvyukov): move to netpoll.goc once it's used by all OSes.\n-void net_runtime_Semacquire(uint32 *addr)\n-  __asm__ (GOSYM_PREFIX \"net.runtime_Semacquire\");\n-\n-void net_runtime_Semacquire(uint32 *addr)\n-{\n-\truntime_semacquire(addr, true);\n-}\n-\n-void net_runtime_Semrelease(uint32 *addr)\n-  __asm__ (GOSYM_PREFIX \"net.runtime_Semrelease\");\n-\n-void net_runtime_Semrelease(uint32 *addr)\n-{\n-\truntime_semrelease(addr);\n-}\n-\n-func runtime_Semacquire(addr *uint32) {\n-\truntime_semacquire(addr, true);\n-}\n-\n-func runtime_Semrelease(addr *uint32) {\n-\truntime_semrelease(addr);\n-}\n-\n-typedef struct SyncSema SyncSema;\n-struct SyncSema\n-{\n-\tLock;\n-\tSemaWaiter*\thead;\n-\tSemaWaiter*\ttail;\n-};\n-\n-func runtime_Syncsemcheck(size uintptr) {\n-\tif(size != sizeof(SyncSema)) {\n-\t\truntime_printf(\"bad SyncSema size: sync:%D runtime:%D\\n\", (int64)size, (int64)sizeof(SyncSema));\n-\t\truntime_throw(\"bad SyncSema size\");\n-\t}\n-}\n-\n-// Syncsemacquire waits for a pairing Syncsemrelease on the same semaphore s.\n-func runtime_Syncsemacquire(s *SyncSema) {\n-\tSemaWaiter w, *wake;\n-\tint64 t0;\n-\n-\tw.g = runtime_g();\n-\tw.nrelease = -1;\n-\tw.next = nil;\n-\tw.releasetime = 0;\n-\tt0 = 0;\n-\tif(runtime_blockprofilerate > 0) {\n-\t\tt0 = runtime_cputicks();\n-\t\tw.releasetime = -1;\n-\t}\n-\n-\truntime_lock(s);\n-\tif(s->head && s->head->nrelease > 0) {\n-\t\t// have pending release, consume it\n-\t\twake = nil;\n-\t\ts->head->nrelease--;\n-\t\tif(s->head->nrelease == 0) {\n-\t\t\twake = s->head;\n-\t\t\ts->head = wake->next;\n-\t\t\tif(s->head == nil)\n-\t\t\t\ts->tail = nil;\n-\t\t}\n-\t\truntime_unlock(s);\n-\t\tif(wake)\n-\t\t\truntime_ready(wake->g);\n-\t} else {\n-\t\t// enqueue itself\n-\t\tif(s->tail == nil)\n-\t\t\ts->head = &w;\n-\t\telse\n-\t\t\ts->tail->next = &w;\n-\t\ts->tail = &w;\n-\t\truntime_parkunlock(s, \"semacquire\");\n-\t\tif(t0)\n-\t\t\truntime_blockevent(w.releasetime - t0, 2);\n-\t}\n-}\n-\n-// Syncsemrelease waits for n pairing Syncsemacquire on the same semaphore s.\n-func runtime_Syncsemrelease(s *SyncSema, n uint32) {\n-\tSemaWaiter w, *wake;\n-\n-\tw.g = runtime_g();\n-\tw.nrelease = (int32)n;\n-\tw.next = nil;\n-\tw.releasetime = 0;\n-\n-\truntime_lock(s);\n-\twhile(w.nrelease > 0 && s->head && s->head->nrelease < 0) {\n-\t\t// have pending acquire, satisfy it\n-\t\twake = s->head;\n-\t\ts->head = wake->next;\n-\t\tif(s->head == nil)\n-\t\t\ts->tail = nil;\n-\t\tif(wake->releasetime)\n-\t\t\twake->releasetime = runtime_cputicks();\n-\t\truntime_ready(wake->g);\n-\t\tw.nrelease--;\n-\t}\n-\tif(w.nrelease > 0) {\n-\t\t// enqueue itself\n-\t\tif(s->tail == nil)\n-\t\t\ts->head = &w;\n-\t\telse\n-\t\t\ts->tail->next = &w;\n-\t\ts->tail = &w;\n-\t\truntime_parkunlock(s, \"semarelease\");\n-\t} else\n-\t\truntime_unlock(s);\n-}\n-\n-// notifyList is a ticket-based notification list used to implement sync.Cond.\n-//\n-// It must be kept in sync with the sync package.\n-typedef struct {\n-\t// wait is the ticket number of the next waiter. It is atomically\n-\t// incremented outside the lock.\n-\tuint32 wait;\n-\n-\t// notify is the ticket number of the next waiter to be notified. It can\n-\t// be read outside the lock, but is only written to with lock held.\n-\t//\n-\t// Both wait & notify can wrap around, and such cases will be correctly\n-\t// handled as long as their \"unwrapped\" difference is bounded by 2^31.\n-\t// For this not to be the case, we'd need to have 2^31+ goroutines\n-\t// blocked on the same condvar, which is currently not possible.\n-\tuint32 notify;\n-\n-\t// List of parked waiters.\n-\tLock lock;\n-\tSudoG* head;\n-\tSudoG* tail;\n-} notifyList;\n-\n-// less checks if a < b, considering a & b running counts that may overflow the\n-// 32-bit range, and that their \"unwrapped\" difference is always less than 2^31.\n-static bool less(uint32 a, uint32 b) {\n-\treturn (int32)(a-b) < 0;\n-}\n-\n-// notifyListAdd adds the caller to a notify list such that it can receive\n-// notifications. The caller must eventually call notifyListWait to wait for\n-// such a notification, passing the returned ticket number.\n-//go:linkname notifyListAdd sync.runtime_notifyListAdd\n-func runtime_notifyListAdd(l *notifyList) (r uint32) {\n-\t// This may be called concurrently, for example, when called from\n-\t// sync.Cond.Wait while holding a RWMutex in read mode.\n-\tr = runtime_xadd(&l->wait, 1) - 1;\n-}\n-\n-// notifyListWait waits for a notification. If one has been sent since\n-// notifyListAdd was called, it returns immediately. Otherwise, it blocks.\n-//go:linkname notifyListWait sync.runtime_notifyListWait\n-func runtime_notifyListWait(l *notifyList, t uint32) {\n-\tSudoG s;\n-\tint64 t0;\n-\n-\truntime_lock(&l->lock);\n-\n-\t// Return right away if this ticket has already been notified.\n-\tif (less(t, l->notify)) {\n-\t\truntime_unlock(&l->lock);\n-\t\treturn;\n-\t}\n-\n-\t// Enqueue itself.\n-\truntime_memclr(&s, sizeof(s));\n-\ts.g = runtime_g();\n-\ts.ticket = t;\n-\ts.releasetime = 0;\n-\tt0 = 0;\n-\tif (runtime_blockprofilerate > 0) {\n-\t\tt0 = runtime_cputicks();\n-\t\ts.releasetime = -1;\n-\t}\n-\tif (l->tail == nil) {\n-\t\tl->head = &s;\n-\t} else {\n-\t\tl->tail->next = &s;\n-\t}\n-\tl->tail = &s;\n-\truntime_parkunlock(&l->lock, \"semacquire\");\n-\tif (t0 != 0) {\n-\t\truntime_blockevent(s.releasetime-t0, 2);\n-\t}\n-}\n-\n-// notifyListNotifyAll notifies all entries in the list.\n-//go:linkname notifyListNotifyAll sync.runtime_notifyListNotifyAll\n-func runtime_notifyListNotifyAll(l *notifyList) {\n-\tSudoG *s;\n-\n-\t// Fast-path: if there are no new waiters since the last notification\n-\t// we don't need to acquire the lock.\n-\tif (runtime_atomicload(&l->wait) == runtime_atomicload(&l->notify)) {\n-\t\treturn;\n-\t}\n-\n-\t// Pull the list out into a local variable, waiters will be readied\n-\t// outside the lock.\n-\truntime_lock(&l->lock);\n-\ts = l->head;\n-\tl->head = nil;\n-\tl->tail = nil;\n-\n-\t// Update the next ticket to be notified. We can set it to the current\n-\t// value of wait because any previous waiters are already in the list\n-\t// or will notice that they have already been notified when trying to\n-\t// add themselves to the list.\n-\truntime_atomicstore(&l->notify, runtime_atomicload(&l->wait));\n-\truntime_unlock(&l->lock);\n-\n-\t// Go through the local list and ready all waiters.\n-\twhile (s != nil) {\n-\t\tSudoG* next = s->next;\n-\t\ts->next = nil;\n-\t\treadyWithTime(s, 4);\n-\t\ts = next;\n-\t}\n-}\n-\n-// notifyListNotifyOne notifies one entry in the list.\n-//go:linkname notifyListNotifyOne sync.runtime_notifyListNotifyOne\n-func runtime_notifyListNotifyOne(l *notifyList) {\n-\tuint32 t;\n-\tSudoG *p;\n-\tSudoG *s;\n-\n-\t// Fast-path: if there are no new waiters since the last notification\n-\t// we don't need to acquire the lock at all.\n-\tif (runtime_atomicload(&l->wait) == runtime_atomicload(&l->notify)) {\n-\t\treturn;\n-\t}\n-\n-\truntime_lock(&l->lock);\n-\n-\t// Re-check under the lock if we need to do anything.\n-\tt = l->notify;\n-\tif (t == runtime_atomicload(&l->wait)) {\n-\t\truntime_unlock(&l->lock);\n-\t\treturn;\n-\t}\n-\n-\t// Update the next notify ticket number, and try to find the G that\n-\t// needs to be notified. If it hasn't made it to the list yet we won't\n-\t// find it, but it won't park itself once it sees the new notify number.\n-\truntime_atomicstore(&l->notify, t+1);\n-\tfor (p = nil, s = l->head; s != nil; p = s, s = s->next) {\n-\t\tif (s->ticket == t) {\n-\t\t\tSudoG *n = s->next;\n-\t\t\tif (p != nil) {\n-\t\t\t\tp->next = n;\n-\t\t\t} else {\n-\t\t\t\tl->head = n;\n-\t\t\t}\n-\t\t\tif (n == nil) {\n-\t\t\t\tl->tail = p;\n-\t\t\t}\n-\t\t\truntime_unlock(&l->lock);\n-\t\t\ts->next = nil;\n-\t\t\treadyWithTime(s, 4);\n-\t\t\treturn;\n-\t\t}\n-\t}\n-\truntime_unlock(&l->lock);\n-}\n-\n-//go:linkname notifyListCheck sync.runtime_notifyListCheck\n-func runtime_notifyListCheck(sz uintptr) {\n-\tif (sz != sizeof(notifyList)) {\n-\t\truntime_printf(\"runtime: bad notifyList size\\n\");\n-\t\truntime_throw(\"bad notifyList size\");\n-\t}\n-}"}]}