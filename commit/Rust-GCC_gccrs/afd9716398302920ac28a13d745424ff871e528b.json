{"sha": "afd9716398302920ac28a13d745424ff871e528b", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YWZkOTcxNjM5ODMwMjkyMGFjMjhhMTNkNzQ1NDI0ZmY4NzFlNTI4Yg==", "commit": {"author": {"name": "Aaron Sawdey", "email": "acsawdey@linux.ibm.com", "date": "2020-08-08T00:02:20Z"}, "committer": {"name": "Aaron Sawdey", "email": "acsawdey@linux.ibm.com", "date": "2020-08-18T19:16:45Z"}, "message": "rs6000: unaligned VSX in memcpy/memmove expansion\n\nThis patch adds a few new instructions to inline expansion of\nmemcpy/memmove. Generation of all these are controlled by\nthe option -mblock-ops-unaligned-vsx which is set on by default if the\ntarget has TARGET_EFFICIENT_UNALIGNED_VSX.\n * unaligned vsx load/store (V2DImode)\n * unaligned vsx pair load/store (POImode) which is also controlled\n   by -mblock-ops-vector-pair in case it is not wanted at some point.\n   The default for -mblock-ops-vector-pair is for it to be on if the\n   target has TARGET_MMA and TARGET_EFFICIENT_UNALIGNED_VSX. This is\n   redundant, but nice for the future to clearly specify what is\n   required.\n * unaligned vsx lxvl/stxvl but generally only to do the remainder\n   of a copy/move we stated with some vsx loads/stores, and also prefer\n   to use lb/lh/lw/ld if the remainder is 1/2/4/8 bytes.\n\nTesting of this is actually accomplished by gcc.dg/memcmp-1.c which does\ntwo memcpy() for each memcmp(). If the memcpy() calls don't do the right\nthing then the memcmp() will fail unexpectedly.\n\ngcc/ChangeLog:\n\n\t* config/rs6000/rs6000-string.c (gen_lxvl_stxvl_move):\n\tHelper function.\n\t(expand_block_move): Add lxvl/stxvl, vector pair, and\n\tunaligned VSX.\n\t* config/rs6000/rs6000.c (rs6000_option_override_internal):\n\tDefault value for -mblock-ops-vector-pair.\n\t* config/rs6000/rs6000.opt: Add -mblock-ops-vector-pair.", "tree": {"sha": "2987f4f7f621504b0748559bf4422caf3e4d230e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/2987f4f7f621504b0748559bf4422caf3e4d230e"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/afd9716398302920ac28a13d745424ff871e528b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/afd9716398302920ac28a13d745424ff871e528b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/afd9716398302920ac28a13d745424ff871e528b", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/afd9716398302920ac28a13d745424ff871e528b/comments", "author": {"login": "acsawdey", "id": 41373646, "node_id": "MDQ6VXNlcjQxMzczNjQ2", "avatar_url": "https://avatars.githubusercontent.com/u/41373646?v=4", "gravatar_id": "", "url": "https://api.github.com/users/acsawdey", "html_url": "https://github.com/acsawdey", "followers_url": "https://api.github.com/users/acsawdey/followers", "following_url": "https://api.github.com/users/acsawdey/following{/other_user}", "gists_url": "https://api.github.com/users/acsawdey/gists{/gist_id}", "starred_url": "https://api.github.com/users/acsawdey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/acsawdey/subscriptions", "organizations_url": "https://api.github.com/users/acsawdey/orgs", "repos_url": "https://api.github.com/users/acsawdey/repos", "events_url": "https://api.github.com/users/acsawdey/events{/privacy}", "received_events_url": "https://api.github.com/users/acsawdey/received_events", "type": "User", "site_admin": false}, "committer": {"login": "acsawdey", "id": 41373646, "node_id": "MDQ6VXNlcjQxMzczNjQ2", "avatar_url": "https://avatars.githubusercontent.com/u/41373646?v=4", "gravatar_id": "", "url": "https://api.github.com/users/acsawdey", "html_url": "https://github.com/acsawdey", "followers_url": "https://api.github.com/users/acsawdey/followers", "following_url": "https://api.github.com/users/acsawdey/following{/other_user}", "gists_url": "https://api.github.com/users/acsawdey/gists{/gist_id}", "starred_url": "https://api.github.com/users/acsawdey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/acsawdey/subscriptions", "organizations_url": "https://api.github.com/users/acsawdey/orgs", "repos_url": "https://api.github.com/users/acsawdey/repos", "events_url": "https://api.github.com/users/acsawdey/events{/privacy}", "received_events_url": "https://api.github.com/users/acsawdey/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "ea95ba8d582e967cdbfce95993e9bb6ad769c047", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ea95ba8d582e967cdbfce95993e9bb6ad769c047", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ea95ba8d582e967cdbfce95993e9bb6ad769c047"}], "stats": {"total": 121, "additions": 105, "deletions": 16}, "files": [{"sha": "82cc24ecdda38a19740c7ea7828ea4d9eea7cd2e", "filename": "gcc/config/rs6000/rs6000-string.c", "status": "modified", "additions": 89, "deletions": 14, "changes": 103, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/afd9716398302920ac28a13d745424ff871e528b/gcc%2Fconfig%2Frs6000%2Frs6000-string.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/afd9716398302920ac28a13d745424ff871e528b/gcc%2Fconfig%2Frs6000%2Frs6000-string.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000-string.c?ref=afd9716398302920ac28a13d745424ff871e528b", "patch": "@@ -2708,6 +2708,32 @@ gen_lvx_v4si_move (rtx dest, rtx src)\n     return gen_altivec_lvx_v4si_internal (dest, src);\n }\n \n+static rtx\n+gen_lxvl_stxvl_move (rtx dest, rtx src, int length)\n+{\n+  gcc_assert (MEM_P (dest) ^ MEM_P (src));\n+  gcc_assert (GET_MODE (dest) == V16QImode && GET_MODE (src) == V16QImode);\n+  gcc_assert (length <= 16);\n+\n+  bool is_store = MEM_P (dest);\n+  rtx addr;\n+\n+  /* If the address form is not a simple register, make it so.  */\n+  if (is_store)\n+    addr = XEXP (dest, 0);\n+  else\n+    addr = XEXP (src, 0);\n+\n+  if (!REG_P (addr))\n+    addr = force_reg (Pmode, addr);\n+\n+  rtx len = force_reg (DImode, gen_int_mode (length, DImode));\n+  if (is_store)\n+    return gen_stxvl (src, addr, len);\n+  else\n+    return gen_lxvl (dest, addr, len);\n+}\n+\n /* Expand a block move operation, and return 1 if successful.  Return 0\n    if we should let the compiler generate normal code.\n \n@@ -2750,18 +2776,56 @@ expand_block_move (rtx operands[], bool might_overlap)\n   if (bytes > rs6000_block_move_inline_limit)\n     return 0;\n \n+  int orig_bytes = bytes;\n   for (offset = 0; bytes > 0; offset += move_bytes, bytes -= move_bytes)\n     {\n       union {\n-\trtx (*movmemsi) (rtx, rtx, rtx, rtx);\n \trtx (*mov) (rtx, rtx);\n+\trtx (*movlen) (rtx, rtx, int);\n       } gen_func;\n       machine_mode mode = BLKmode;\n       rtx src, dest;\n-\n-      /* Altivec first, since it will be faster than a string move\n-\t when it applies, and usually not significantly larger.  */\n-      if (TARGET_ALTIVEC && bytes >= 16 && align >= 128)\n+      bool move_with_length = false;\n+\n+      /* Use POImode for paired vsx load/store.  Use V2DI for single\n+\t unaligned vsx load/store, for consistency with what other\n+\t expansions (compare) already do, and so we can use lxvd2x on\n+\t p8.  Order is VSX pair unaligned, VSX unaligned, Altivec, VSX\n+\t with length < 16 (if allowed), then gpr load/store.  */\n+\n+      if (TARGET_MMA && TARGET_BLOCK_OPS_UNALIGNED_VSX\n+\t  && TARGET_BLOCK_OPS_VECTOR_PAIR\n+\t  && bytes >= 32\n+\t  && (align >= 256 || !STRICT_ALIGNMENT))\n+\t{\n+\t  move_bytes = 32;\n+\t  mode = POImode;\n+\t  gen_func.mov = gen_movpoi;\n+\t}\n+      else if (TARGET_POWERPC64 && TARGET_BLOCK_OPS_UNALIGNED_VSX\n+\t       && VECTOR_MEM_VSX_P (V2DImode)\n+\t       && bytes >= 16 && (align >= 128 || !STRICT_ALIGNMENT))\n+\t{\n+\t  move_bytes = 16;\n+\t  mode = V2DImode;\n+\t  gen_func.mov = gen_vsx_movv2di_64bit;\n+\t}\n+      else if (TARGET_BLOCK_OPS_UNALIGNED_VSX\n+\t       && TARGET_POWER10 && bytes < 16\n+\t       && orig_bytes > 16\n+\t       && !(bytes == 1 || bytes == 2\n+\t\t    || bytes == 4 || bytes == 8)\n+\t       && (align >= 128 || !STRICT_ALIGNMENT))\n+\t{\n+\t  /* Only use lxvl/stxvl if it could replace multiple ordinary\n+\t     loads+stores.  Also don't use it unless we likely already\n+\t     did one vsx copy so we aren't mixing gpr and vsx.  */\n+\t  move_bytes = bytes;\n+\t  mode = V16QImode;\n+\t  gen_func.movlen = gen_lxvl_stxvl_move;\n+\t  move_with_length = true;\n+\t}\n+      else if (TARGET_ALTIVEC && bytes >= 16 && align >= 128)\n \t{\n \t  move_bytes = 16;\n \t  mode = V4SImode;\n@@ -2818,23 +2882,34 @@ expand_block_move (rtx operands[], bool might_overlap)\n \t  gen_func.mov = gen_movqi;\n \t}\n \n-      /* Mode is always set to something other than BLKmode by one of the \n+      /* If we can't succeed in doing the move in one pass, we can't\n+\t do it in the might_overlap case.  Bail out and return\n+\t failure.  We test num_reg + 1 >= MAX_MOVE_REG here to check\n+\t the same condition as the test of num_reg >= MAX_MOVE_REG\n+\t that is done below after the increment of num_reg.  */\n+      if (might_overlap && num_reg + 1 >= MAX_MOVE_REG\n+\t  && bytes > move_bytes)\n+\treturn 0;\n+\n+      /* Mode is always set to something other than BLKmode by one of the\n \t cases of the if statement above.  */\n       gcc_assert (mode != BLKmode);\n \n       src = adjust_address (orig_src, mode, offset);\n       dest = adjust_address (orig_dest, mode, offset);\n \n       rtx tmp_reg = gen_reg_rtx (mode);\n-      \n-      loads[num_reg]    = (*gen_func.mov) (tmp_reg, src);\n-      stores[num_reg++] = (*gen_func.mov) (dest, tmp_reg);\n \n-      /* If we didn't succeed in doing it in one pass, we can't do it in the \n-\t might_overlap case.  Bail out and return failure.  */\n-      if (might_overlap && num_reg >= MAX_MOVE_REG\n-\t  && bytes > move_bytes)\n-\treturn 0;\n+      if (move_with_length)\n+\t{\n+\t  loads[num_reg]    = (*gen_func.movlen) (tmp_reg, src, move_bytes);\n+\t  stores[num_reg++] = (*gen_func.movlen) (dest, tmp_reg, move_bytes);\n+\t}\n+      else\n+\t{\n+\t  loads[num_reg]    = (*gen_func.mov) (tmp_reg, src);\n+\t  stores[num_reg++] = (*gen_func.mov) (dest, tmp_reg);\n+\t}\n \n       /* Emit loads and stores saved up.  */\n       if (num_reg >= MAX_MOVE_REG || bytes == move_bytes)"}, {"sha": "1c1caa90edeb7326a53a47d2ee0fdd75ede2b4e0", "filename": "gcc/config/rs6000/rs6000.c", "status": "modified", "additions": 12, "deletions": 2, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/afd9716398302920ac28a13d745424ff871e528b/gcc%2Fconfig%2Frs6000%2Frs6000.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/afd9716398302920ac28a13d745424ff871e528b/gcc%2Fconfig%2Frs6000%2Frs6000.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.c?ref=afd9716398302920ac28a13d745424ff871e528b", "patch": "@@ -4018,6 +4018,14 @@ rs6000_option_override_internal (bool global_init_p)\n \trs6000_isa_flags &= ~OPTION_MASK_BLOCK_OPS_UNALIGNED_VSX;\n     }\n \n+  if (!(rs6000_isa_flags_explicit & OPTION_MASK_BLOCK_OPS_VECTOR_PAIR))\n+    {\n+      if (TARGET_MMA && TARGET_EFFICIENT_UNALIGNED_VSX)\n+\trs6000_isa_flags |= OPTION_MASK_BLOCK_OPS_VECTOR_PAIR;\n+      else\n+\trs6000_isa_flags &= ~OPTION_MASK_BLOCK_OPS_VECTOR_PAIR;\n+    }\n+\n   /* Use long double size to select the appropriate long double.  We use\n      TYPE_PRECISION to differentiate the 3 different long double types.  We map\n      128 into the precision used for TFmode.  */\n@@ -23222,8 +23230,10 @@ struct rs6000_opt_mask {\n static struct rs6000_opt_mask const rs6000_opt_masks[] =\n {\n   { \"altivec\",\t\t\tOPTION_MASK_ALTIVEC,\t\tfalse, true  },\n-  { \"block-ops-unaligned-vsx\",  OPTION_MASK_BLOCK_OPS_UNALIGNED_VSX,\n-                                                                false, true  },\n+  { \"block-ops-unaligned-vsx\",\tOPTION_MASK_BLOCK_OPS_UNALIGNED_VSX,\n+\t\t\t\t\t\t\t\tfalse, true  },\n+  { \"block-ops-vector-pair\",\tOPTION_MASK_BLOCK_OPS_VECTOR_PAIR,\n+\t\t\t\t\t\t\t\tfalse, true  },\n   { \"cmpb\",\t\t\tOPTION_MASK_CMPB,\t\tfalse, true  },\n   { \"crypto\",\t\t\tOPTION_MASK_CRYPTO,\t\tfalse, true  },\n   { \"direct-move\",\t\tOPTION_MASK_DIRECT_MOVE,\tfalse, true  },"}, {"sha": "b2a70e88ca8ff057bda03e79d219b0a4d7911edf", "filename": "gcc/config/rs6000/rs6000.opt", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/afd9716398302920ac28a13d745424ff871e528b/gcc%2Fconfig%2Frs6000%2Frs6000.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/afd9716398302920ac28a13d745424ff871e528b/gcc%2Fconfig%2Frs6000%2Frs6000.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.opt?ref=afd9716398302920ac28a13d745424ff871e528b", "patch": "@@ -328,6 +328,10 @@ mblock-ops-unaligned-vsx\n Target Report Mask(BLOCK_OPS_UNALIGNED_VSX) Var(rs6000_isa_flags)\n Generate unaligned VSX load/store for inline expansion of memcpy/memmove.\n \n+mblock-ops-vector-pair\n+Target Undocumented Mask(BLOCK_OPS_VECTOR_PAIR) Var(rs6000_isa_flags)\n+Generate unaligned VSX vector pair load/store for inline expansion of memcpy/memmove.\n+\n mblock-compare-inline-limit=\n Target Report Var(rs6000_block_compare_inline_limit) Init(63) RejectNegative Joined UInteger Save\n Max number of bytes to compare without loops."}]}