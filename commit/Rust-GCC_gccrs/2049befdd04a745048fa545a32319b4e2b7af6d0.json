{"sha": "2049befdd04a745048fa545a32319b4e2b7af6d0", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MjA0OWJlZmRkMDRhNzQ1MDQ4ZmE1NDVhMzIzMTliNGUyYjdhZjZkMA==", "commit": {"author": {"name": "Cesar Philippidis", "email": "cesar@codesourcery.com", "date": "2018-09-18T15:41:54Z"}, "committer": {"name": "Cesar Philippidis", "email": "cesar@gcc.gnu.org", "date": "2018-09-18T15:41:54Z"}, "message": "[nvptx] Remove use of CUDA unified memory in libgomp\n\n\tlibgomp/\n\t* plugin/plugin-nvptx.c (struct cuda_map): New.\n\t(struct ptx_stream): Replace d, h, h_begin, h_end, h_next, h_prev,\n\th_tail with (cuda_map *) map.\n\t(cuda_map_create): New function.\n\t(cuda_map_destroy): New function.\n\t(map_init): Update to use a linked list of cuda_map objects.\n\t(map_fini): Likewise.\n\t(map_pop): Likewise.\n\t(map_push): Likewise.  Return CUdeviceptr instead of void.\n\t(init_streams_for_device): Remove stales references to ptx_stream\n\tmembers.\n\t(select_stream_for_async): Likewise.\n\t(nvptx_exec): Update call to map_init.\n\nFrom-SVN: r264397", "tree": {"sha": "3350da1c21938ab90a1821d66840698bf9e0be1b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/3350da1c21938ab90a1821d66840698bf9e0be1b"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/2049befdd04a745048fa545a32319b4e2b7af6d0", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2049befdd04a745048fa545a32319b4e2b7af6d0", "html_url": "https://github.com/Rust-GCC/gccrs/commit/2049befdd04a745048fa545a32319b4e2b7af6d0", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/2049befdd04a745048fa545a32319b4e2b7af6d0/comments", "author": {"login": "cesarjp", "id": 4576177, "node_id": "MDQ6VXNlcjQ1NzYxNzc=", "avatar_url": "https://avatars.githubusercontent.com/u/4576177?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cesarjp", "html_url": "https://github.com/cesarjp", "followers_url": "https://api.github.com/users/cesarjp/followers", "following_url": "https://api.github.com/users/cesarjp/following{/other_user}", "gists_url": "https://api.github.com/users/cesarjp/gists{/gist_id}", "starred_url": "https://api.github.com/users/cesarjp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cesarjp/subscriptions", "organizations_url": "https://api.github.com/users/cesarjp/orgs", "repos_url": "https://api.github.com/users/cesarjp/repos", "events_url": "https://api.github.com/users/cesarjp/events{/privacy}", "received_events_url": "https://api.github.com/users/cesarjp/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "5e594075c8e0f05741b3c961959bf3a4c1f42e9b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5e594075c8e0f05741b3c961959bf3a4c1f42e9b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5e594075c8e0f05741b3c961959bf3a4c1f42e9b"}], "stats": {"total": 186, "additions": 107, "deletions": 79}, "files": [{"sha": "9c2ae06b4e1544e551bb24f8a913701da722f531", "filename": "libgomp/ChangeLog", "status": "modified", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2049befdd04a745048fa545a32319b4e2b7af6d0/libgomp%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2049befdd04a745048fa545a32319b4e2b7af6d0/libgomp%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2FChangeLog?ref=2049befdd04a745048fa545a32319b4e2b7af6d0", "patch": "@@ -1,3 +1,19 @@\n+2018-09-18  Cesar Philippidis  <cesar@codesourcery.com>\n+\n+\t* plugin/plugin-nvptx.c (struct cuda_map): New.\n+\t(struct ptx_stream): Replace d, h, h_begin, h_end, h_next, h_prev,\n+\th_tail with (cuda_map *) map.\n+\t(cuda_map_create): New function.\n+\t(cuda_map_destroy): New function.\n+\t(map_init): Update to use a linked list of cuda_map objects.\n+\t(map_fini): Likewise.\n+\t(map_pop): Likewise.\n+\t(map_push): Likewise.  Return CUdeviceptr instead of void.\n+\t(init_streams_for_device): Remove stales references to ptx_stream\n+\tmembers.\n+\t(select_stream_for_async): Likewise.\n+\t(nvptx_exec): Update call to map_init.\n+\n 2018-09-09  Cesar Philippidis  <cesar@codesourcery.com>\n             Julian Brown  <julian@codesourcery.com>\n "}, {"sha": "6492e5ffab77dc3479b0be22d146b5bebe50f00f", "filename": "libgomp/plugin/plugin-nvptx.c", "status": "modified", "additions": 91, "deletions": 79, "changes": 170, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/2049befdd04a745048fa545a32319b4e2b7af6d0/libgomp%2Fplugin%2Fplugin-nvptx.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/2049befdd04a745048fa545a32319b4e2b7af6d0/libgomp%2Fplugin%2Fplugin-nvptx.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Fplugin%2Fplugin-nvptx.c?ref=2049befdd04a745048fa545a32319b4e2b7af6d0", "patch": "@@ -192,20 +192,20 @@ cuda_error (CUresult r)\n static unsigned int instantiated_devices = 0;\n static pthread_mutex_t ptx_dev_lock = PTHREAD_MUTEX_INITIALIZER;\n \n+struct cuda_map\n+{\n+  CUdeviceptr d;\n+  size_t size;\n+  bool active;\n+  struct cuda_map *next;\n+};\n+\n struct ptx_stream\n {\n   CUstream stream;\n   pthread_t host_thread;\n   bool multithreaded;\n-\n-  CUdeviceptr d;\n-  void *h;\n-  void *h_begin;\n-  void *h_end;\n-  void *h_next;\n-  void *h_prev;\n-  void *h_tail;\n-\n+  struct cuda_map *map;\n   struct ptx_stream *next;\n };\n \n@@ -217,101 +217,114 @@ struct nvptx_thread\n   struct ptx_device *ptx_dev;\n };\n \n+static struct cuda_map *\n+cuda_map_create (size_t size)\n+{\n+  struct cuda_map *map = GOMP_PLUGIN_malloc (sizeof (struct cuda_map));\n+\n+  assert (map);\n+\n+  map->next = NULL;\n+  map->size = size;\n+  map->active = false;\n+\n+  CUDA_CALL_ERET (NULL, cuMemAlloc, &map->d, size);\n+  assert (map->d);\n+\n+  return map;\n+}\n+\n+static void\n+cuda_map_destroy (struct cuda_map *map)\n+{\n+  CUDA_CALL_ASSERT (cuMemFree, map->d);\n+  free (map);\n+}\n+\n+/* The following map_* routines manage the CUDA device memory that\n+   contains the data mapping arguments for cuLaunchKernel.  Each\n+   asynchronous PTX stream may have multiple pending kernel\n+   invocations, which are launched in a FIFO order.  As such, the map\n+   routines maintains a queue of cuLaunchKernel arguments.\n+\n+   Calls to map_push and map_pop must be guarded by ptx_event_lock.\n+   Likewise, calls to map_init and map_fini are guarded by\n+   ptx_dev_lock inside GOMP_OFFLOAD_init_device and\n+   GOMP_OFFLOAD_fini_device, respectively.  */\n+\n static bool\n map_init (struct ptx_stream *s)\n {\n   int size = getpagesize ();\n \n   assert (s);\n-  assert (!s->d);\n-  assert (!s->h);\n-\n-  CUDA_CALL (cuMemAllocHost, &s->h, size);\n-  CUDA_CALL (cuMemHostGetDevicePointer, &s->d, s->h, 0);\n \n-  assert (s->h);\n+  s->map = cuda_map_create (size);\n \n-  s->h_begin = s->h;\n-  s->h_end = s->h_begin + size;\n-  s->h_next = s->h_prev = s->h_tail = s->h_begin;\n-\n-  assert (s->h_next);\n-  assert (s->h_end);\n   return true;\n }\n \n static bool\n map_fini (struct ptx_stream *s)\n {\n-  CUDA_CALL (cuMemFreeHost, s->h);\n+  assert (s->map->next == NULL);\n+  assert (!s->map->active);\n+\n+  cuda_map_destroy (s->map);\n+\n   return true;\n }\n \n static void\n map_pop (struct ptx_stream *s)\n {\n-  assert (s != NULL);\n-  assert (s->h_next);\n-  assert (s->h_prev);\n-  assert (s->h_tail);\n-\n-  s->h_tail = s->h_next;\n-\n-  if (s->h_tail >= s->h_end)\n-    s->h_tail = s->h_begin + (int) (s->h_tail - s->h_end);\n+  struct cuda_map *next;\n \n-  if (s->h_next == s->h_tail)\n-    s->h_prev = s->h_next;\n+  assert (s != NULL);\n \n-  assert (s->h_next >= s->h_begin);\n-  assert (s->h_tail >= s->h_begin);\n-  assert (s->h_prev >= s->h_begin);\n+  if (s->map->next == NULL)\n+    {\n+      s->map->active = false;\n+      return;\n+    }\n \n-  assert (s->h_next <= s->h_end);\n-  assert (s->h_tail <= s->h_end);\n-  assert (s->h_prev <= s->h_end);\n+  next = s->map->next;\n+  cuda_map_destroy (s->map);\n+  s->map = next;\n }\n \n-static void\n-map_push (struct ptx_stream *s, size_t size, void **h, void **d)\n+static CUdeviceptr\n+map_push (struct ptx_stream *s, size_t size)\n {\n-  int left;\n-  int offset;\n+  struct cuda_map *map = NULL, *t = NULL;\n \n-  assert (s != NULL);\n+  assert (s);\n+  assert (s->map);\n \n-  left = s->h_end - s->h_next;\n+  /* Each PTX stream requires a separate data region to store the\n+     launch arguments for cuLaunchKernel.  Allocate a new\n+     cuda_map and push it to the end of the list.  */\n+  if (s->map->active)\n+    {\n+      map = cuda_map_create (size);\n \n-  assert (s->h_prev);\n-  assert (s->h_next);\n+      for (t = s->map; t->next != NULL; t = t->next)\n+\t;\n \n-  if (size >= left)\n+      t->next = map;\n+    }\n+  else if (s->map->size < size)\n     {\n-      assert (s->h_next == s->h_prev);\n-      s->h_next = s->h_prev = s->h_tail = s->h_begin;\n+      cuda_map_destroy (s->map);\n+      map = cuda_map_create (size);\n     }\n+  else\n+    map = s->map;\n \n-  assert (s->h_next);\n-\n-  offset = s->h_next - s->h;\n-\n-  *d = (void *)(s->d + offset);\n-  *h = (void *)(s->h + offset);\n-\n-  s->h_prev = s->h_next;\n-  s->h_next += size;\n-\n-  assert (s->h_prev);\n-  assert (s->h_next);\n-\n-  assert (s->h_next >= s->h_begin);\n-  assert (s->h_tail >= s->h_begin);\n-  assert (s->h_prev >= s->h_begin);\n-  assert (s->h_next <= s->h_end);\n-  assert (s->h_tail <= s->h_end);\n-  assert (s->h_prev <= s->h_end);\n+  s->map = map;\n+  s->map->active = true;\n \n-  return;\n+  return s->map->d;\n }\n \n /* Target data function launch information.  */\n@@ -442,8 +455,6 @@ init_streams_for_device (struct ptx_device *ptx_dev, int concurrency)\n   null_stream->stream = NULL;\n   null_stream->host_thread = pthread_self ();\n   null_stream->multithreaded = true;\n-  null_stream->d = (CUdeviceptr) NULL;\n-  null_stream->h = NULL;\n   if (!map_init (null_stream))\n     return false;\n \n@@ -578,8 +589,6 @@ select_stream_for_async (int async, pthread_t thread, bool create,\n \t  s->host_thread = thread;\n \t  s->multithreaded = false;\n \n-\t  s->d = (CUdeviceptr) NULL;\n-\t  s->h = NULL;\n \t  if (!map_init (s))\n \t    {\n \t      pthread_mutex_unlock (&ptx_dev->stream_lock);\n@@ -1120,7 +1129,8 @@ nvptx_exec (void (*fn), size_t mapnum, void **hostaddrs, void **devaddrs,\n   int i;\n   struct ptx_stream *dev_str;\n   void *kargs[1];\n-  void *hp, *dp;\n+  void *hp;\n+  CUdeviceptr dp;\n   struct nvptx_thread *nvthd = nvptx_thread ();\n   int warp_size = nvthd->ptx_dev->warp_size;\n   const char *maybe_abort_msg = \"(perhaps abort was called)\";\n@@ -1295,17 +1305,19 @@ nvptx_exec (void (*fn), size_t mapnum, void **hostaddrs, void **devaddrs,\n   /* This reserves a chunk of a pre-allocated page of memory mapped on both\n      the host and the device. HP is a host pointer to the new chunk, and DP is\n      the corresponding device pointer.  */\n-  map_push (dev_str, mapnum * sizeof (void *), &hp, &dp);\n+  pthread_mutex_lock (&ptx_event_lock);\n+  dp = map_push (dev_str, mapnum * sizeof (void *));\n+  pthread_mutex_unlock (&ptx_event_lock);\n \n   GOMP_PLUGIN_debug (0, \"  %s: prepare mappings\\n\", __FUNCTION__);\n \n   /* Copy the array of arguments to the mapped page.  */\n+  hp = alloca(sizeof(void *) * mapnum);\n   for (i = 0; i < mapnum; i++)\n     ((void **) hp)[i] = devaddrs[i];\n \n-  /* Copy the (device) pointers to arguments to the device (dp and hp might in\n-     fact have the same value on a unified-memory system).  */\n-  CUDA_CALL_ASSERT (cuMemcpy, (CUdeviceptr) dp, (CUdeviceptr) hp,\n+  /* Copy the (device) pointers to arguments to the device */\n+  CUDA_CALL_ASSERT (cuMemcpyHtoD, dp, hp,\n \t\t    mapnum * sizeof (void *));\n   GOMP_PLUGIN_debug (0, \"  %s: kernel %s: launch\"\n \t\t     \" gangs=%u, workers=%u, vectors=%u\\n\","}]}