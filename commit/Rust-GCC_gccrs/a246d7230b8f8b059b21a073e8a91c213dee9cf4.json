{"sha": "a246d7230b8f8b059b21a073e8a91c213dee9cf4", "node_id": "C_kwDOANBUbNoAKGEyNDZkNzIzMGI4ZjhiMDU5YjIxYTA3M2U4YTkxYzIxM2RlZTljZjQ", "commit": {"author": {"name": "Jan Hubicka", "email": "jh@suse.cz", "date": "2021-11-13T17:27:18Z"}, "committer": {"name": "Jan Hubicka", "email": "jh@suse.cz", "date": "2021-11-13T17:27:18Z"}, "message": "modref_access_node cleanup\n\nmove member functions of modref_access_node from ipa-modref-tree.h to\nipa-modref-tree.c since they become long and not fitting for inlines anyway.  I\nalso cleaned up the interface by making static insert method (which handles\ninserting accesses into a vector and optimizing them) which makes it possible\nto hide most of the interface handling interval merging private.\n\nHonza\n\ngcc/ChangeLog:\n\n\t* ipa-modref-tree.h\n\t(struct modref_access_node): Move longer member functions to\n\tipa-modref-tree.c\n\t(modref_ref_node::try_merge_with): Turn into modreef_acces_node member\n\tfunction.\n\t* ipa-modref-tree.c (modref_access_node::contains): Move here\n\tfrom ipa-modref-tree.h.\n\t(modref_access_node::update): Likewise.\n\t(modref_access_node::merge): Likewise.\n\t(modref_access_node::closer_pair_p): Likewise.\n\t(modref_access_node::forced_merge): Likewise.\n\t(modref_access_node::update2): Likewise.\n\t(modref_access_node::combined_offsets): Likewise.\n\t(modref_access_node::try_merge_with): Likewise.\n\t(modref_access_node::insert): Likewise.", "tree": {"sha": "9cfbc7b0f36a24e81c6b0bf2419bc82601a77416", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/9cfbc7b0f36a24e81c6b0bf2419bc82601a77416"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/a246d7230b8f8b059b21a073e8a91c213dee9cf4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a246d7230b8f8b059b21a073e8a91c213dee9cf4", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a246d7230b8f8b059b21a073e8a91c213dee9cf4", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a246d7230b8f8b059b21a073e8a91c213dee9cf4/comments", "author": null, "committer": null, "parents": [{"sha": "e0040bc3d97f11063fe0a5156a2d27d36069fb34", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e0040bc3d97f11063fe0a5156a2d27d36069fb34", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e0040bc3d97f11063fe0a5156a2d27d36069fb34"}], "stats": {"total": 1077, "additions": 563, "deletions": 514}, "files": [{"sha": "e363c506a099c6d6243a67dd691369ca12a03dfd", "filename": "gcc/ipa-modref-tree.c", "status": "modified", "additions": 535, "deletions": 0, "changes": 535, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a246d7230b8f8b059b21a073e8a91c213dee9cf4/gcc%2Fipa-modref-tree.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a246d7230b8f8b059b21a073e8a91c213dee9cf4/gcc%2Fipa-modref-tree.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-modref-tree.c?ref=a246d7230b8f8b059b21a073e8a91c213dee9cf4", "patch": "@@ -28,6 +28,541 @@ along with GCC; see the file COPYING3.  If not see\n \n #if CHECKING_P\n \n+/* Return true if both accesses are the same.  */\n+bool\n+modref_access_node::operator == (modref_access_node &a) const\n+{\n+  if (parm_index != a.parm_index)\n+    return false;\n+  if (parm_index != MODREF_UNKNOWN_PARM)\n+    {\n+      if (parm_offset_known != a.parm_offset_known)\n+\treturn false;\n+      if (parm_offset_known\n+\t  && !known_eq (parm_offset, a.parm_offset))\n+\treturn false;\n+    }\n+  if (range_info_useful_p () != a.range_info_useful_p ())\n+    return false;\n+  if (range_info_useful_p ()\n+      && (!known_eq (a.offset, offset)\n+\t  || !known_eq (a.size, size)\n+\t  || !known_eq (a.max_size, max_size)))\n+    return false;\n+  return true;\n+}\n+\n+/* Return true A is a subaccess.  */\n+bool\n+modref_access_node::contains (const modref_access_node &a) const\n+{\n+  poly_int64 aoffset_adj = 0;\n+  if (parm_index != MODREF_UNKNOWN_PARM)\n+    {\n+      if (parm_index != a.parm_index)\n+\treturn false;\n+      if (parm_offset_known)\n+\t{\n+\t   if (!a.parm_offset_known)\n+\t     return false;\n+\t   /* Accesses are never below parm_offset, so look\n+\t      for smaller offset.\n+\t      If access ranges are known still allow merging\n+\t      when bit offsets comparsion passes.  */\n+\t   if (!known_le (parm_offset, a.parm_offset)\n+\t       && !range_info_useful_p ())\n+\t     return false;\n+\t   /* We allow negative aoffset_adj here in case\n+\t      there is an useful range.  This is because adding\n+\t      a.offset may result in non-ngative offset again.\n+\t      Ubsan fails on val << LOG_BITS_PER_UNIT where val\n+\t      is negative.  */\n+\t   aoffset_adj = (a.parm_offset - parm_offset)\n+\t\t\t * BITS_PER_UNIT;\n+\t}\n+    }\n+  if (range_info_useful_p ())\n+    {\n+      if (!a.range_info_useful_p ())\n+\treturn false;\n+      /* Sizes of stores are used to check that object is big enough\n+\t to fit the store, so smaller or unknown sotre is more general\n+\t than large store.  */\n+      if (known_size_p (size)\n+\t  && (!known_size_p (a.size)\n+\t      || !known_le (size, a.size)))\n+\treturn false;\n+      if (known_size_p (max_size))\n+\treturn known_subrange_p (a.offset + aoffset_adj,\n+\t\t\t\t a.max_size, offset, max_size);\n+      else\n+\treturn known_le (offset, a.offset + aoffset_adj);\n+    }\n+  return true;\n+}\n+\n+/* Update access range to new parameters.\n+   If RECORD_ADJUSTMENTS is true, record number of changes in the access\n+   and if threshold is exceeded start dropping precision\n+   so only constantly many updates are possible.  This makes dataflow\n+   to converge.  */\n+void\n+modref_access_node::update (poly_int64 parm_offset1,\n+\t\t\t    poly_int64 offset1, poly_int64 size1,\n+\t\t\t    poly_int64 max_size1, bool record_adjustments)\n+{\n+  if (known_eq (parm_offset, parm_offset1)\n+      && known_eq (offset, offset1)\n+      && known_eq (size, size1)\n+      && known_eq (max_size, max_size1))\n+    return;\n+  if (!record_adjustments\n+      || (++adjustments) < param_modref_max_adjustments)\n+    {\n+      parm_offset = parm_offset1;\n+      offset = offset1;\n+      size = size1;\n+      max_size = max_size1;\n+    }\n+  else\n+    {\n+      if (dump_file)\n+\tfprintf (dump_file,\n+\t\t \"--param param=modref-max-adjustments limit reached:\");\n+      if (!known_eq (parm_offset, parm_offset1))\n+\t{\n+\t  if (dump_file)\n+\t    fprintf (dump_file, \" parm_offset cleared\");\n+\t  parm_offset_known = false;\n+\t}\n+      if (!known_eq (size, size1))\n+\t{\n+\t  size = -1;\n+\t  if (dump_file)\n+\t    fprintf (dump_file, \" size cleared\");\n+\t}\n+      if (!known_eq (max_size, max_size1))\n+\t{\n+\t  max_size = -1;\n+\t  if (dump_file)\n+\t    fprintf (dump_file, \" max_size cleared\");\n+\t}\n+      if (!known_eq (offset, offset1))\n+\t{\n+\t  offset = 0;\n+\t  if (dump_file)\n+\t    fprintf (dump_file, \" offset cleared\");\n+\t}\n+      if (dump_file)\n+\tfprintf (dump_file, \"\\n\");\n+    }\n+}\n+\n+/* Merge in access A if it is possible to do without losing\n+   precision.  Return true if successful.\n+   If RECORD_ADJUSTMENTs is true, remember how many interval\n+   was prolonged and punt when there are too many.  */\n+bool\n+modref_access_node::merge (const modref_access_node &a,\n+\t\t\t   bool record_adjustments)\n+{\n+  poly_int64 offset1 = 0;\n+  poly_int64 aoffset1 = 0;\n+  poly_int64 new_parm_offset = 0;\n+\n+  /* We assume that containment was tested earlier.  */\n+  gcc_checking_assert (!contains (a) && !a.contains (*this));\n+  if (parm_index != MODREF_UNKNOWN_PARM)\n+    {\n+      if (parm_index != a.parm_index)\n+\treturn false;\n+      if (parm_offset_known)\n+\t{\n+\t  if (!a.parm_offset_known)\n+\t    return false;\n+\t  if (!combined_offsets (a, &new_parm_offset, &offset1, &aoffset1))\n+\t    return false;\n+\t}\n+    }\n+  /* See if we can merge ranges.  */\n+  if (range_info_useful_p ())\n+    {\n+      /* In this case we have containment that should be\n+\t handled earlier.  */\n+      gcc_checking_assert (a.range_info_useful_p ());\n+\n+      /* If a.size is less specified than size, merge only\n+\t if intervals are otherwise equivalent.  */\n+      if (known_size_p (size)\n+\t  && (!known_size_p (a.size) || known_lt (a.size, size)))\n+\t{\n+\t  if (((known_size_p (max_size) || known_size_p (a.max_size))\n+\t       && !known_eq (max_size, a.max_size))\n+\t       || !known_eq (offset1, aoffset1))\n+\t    return false;\n+\t  update (new_parm_offset, offset1, a.size, max_size,\n+\t\t  record_adjustments);\n+\t  return true;\n+\t}\n+      /* If sizes are same, we can extend the interval.  */\n+      if ((known_size_p (size) || known_size_p (a.size))\n+\t  && !known_eq (size, a.size))\n+\treturn false;\n+      if (known_le (offset1, aoffset1))\n+\t{\n+\t  if (!known_size_p (max_size)\n+\t      || known_ge (offset1 + max_size, aoffset1))\n+\t    {\n+\t      update2 (new_parm_offset, offset1, size, max_size,\n+\t\t       aoffset1, a.size, a.max_size,\n+\t\t       record_adjustments);\n+\t      return true;\n+\t    }\n+\t}\n+      else if (known_le (aoffset1, offset1))\n+\t{\n+\t  if (!known_size_p (a.max_size)\n+\t      || known_ge (aoffset1 + a.max_size, offset1))\n+\t    {\n+\t      update2 (new_parm_offset, offset1, size, max_size,\n+\t\t       aoffset1, a.size, a.max_size,\n+\t\t       record_adjustments);\n+\t      return true;\n+\t    }\n+\t}\n+      return false;\n+    }\n+  update (new_parm_offset, offset1,\n+\t  size, max_size, record_adjustments);\n+  return true;\n+}\n+\n+/* Return true if A1 and B1 can be merged with lower information\n+   less than A2 and B2.\n+   Assume that no containment or lossless merging is possible.  */\n+bool\n+modref_access_node::closer_pair_p (const modref_access_node &a1,\n+\t\t\t\t   const modref_access_node &b1,\n+\t\t\t\t   const modref_access_node &a2,\n+\t\t\t\t   const modref_access_node &b2)\n+{\n+  /* Merging different parm indexes comes to complete loss\n+     of range info.  */\n+  if (a1.parm_index != b1.parm_index)\n+    return false;\n+  if (a2.parm_index != b2.parm_index)\n+    return true;\n+  /* If parm is known and parm indexes are the same we should\n+     already have containment.  */\n+  gcc_checking_assert (a1.parm_offset_known && b1.parm_offset_known);\n+  gcc_checking_assert (a2.parm_offset_known && b2.parm_offset_known);\n+\n+  /* First normalize offsets for parm offsets.  */\n+  poly_int64 new_parm_offset, offseta1, offsetb1, offseta2, offsetb2;\n+  if (!a1.combined_offsets (b1, &new_parm_offset, &offseta1, &offsetb1)\n+      || !a2.combined_offsets (b2, &new_parm_offset, &offseta2, &offsetb2))\n+    gcc_unreachable ();\n+\n+\n+  /* Now compute distnace of the intervals.  */\n+  poly_int64 dist1, dist2;\n+  if (known_le (offseta1, offsetb1))\n+    {\n+      if (!known_size_p (a1.max_size))\n+\tdist1 = 0;\n+      else\n+\tdist1 = offsetb1 - offseta1 - a1.max_size;\n+    }\n+  else\n+    {\n+      if (!known_size_p (b1.max_size))\n+\tdist1 = 0;\n+      else\n+\tdist1 = offseta1 - offsetb1 - b1.max_size;\n+    }\n+  if (known_le (offseta2, offsetb2))\n+    {\n+      if (!known_size_p (a2.max_size))\n+\tdist2 = 0;\n+      else\n+\tdist2 = offsetb2 - offseta2 - a2.max_size;\n+    }\n+  else\n+    {\n+      if (!known_size_p (b2.max_size))\n+\tdist2 = 0;\n+      else\n+\tdist2 = offseta2 - offsetb2 - b2.max_size;\n+    }\n+  /* It may happen that intervals overlap in case size\n+     is different.  Preffer the overlap to non-overlap.  */\n+  if (known_lt (dist1, 0) && known_ge (dist2, 0))\n+    return true;\n+  if (known_lt (dist2, 0) && known_ge (dist1, 0))\n+    return false;\n+  if (known_lt (dist1, 0))\n+    /* If both overlaps minimize overlap.  */\n+    return known_le (dist2, dist1);\n+  else\n+    /* If both are disjoint look for smaller distance.  */\n+    return known_le (dist1, dist2);\n+}\n+\n+/* Merge in access A while losing precision.  */\n+void\n+modref_access_node::forced_merge (const modref_access_node &a,\n+\t\t\t\t  bool record_adjustments)\n+{\n+  if (parm_index != a.parm_index)\n+    {\n+      gcc_checking_assert (parm_index != MODREF_UNKNOWN_PARM);\n+      parm_index = MODREF_UNKNOWN_PARM;\n+      return;\n+    }\n+\n+  /* We assume that containment and lossless merging\n+     was tested earlier.  */\n+  gcc_checking_assert (!contains (a) && !a.contains (*this)\n+\t\t       && !merge (a, record_adjustments));\n+  gcc_checking_assert (parm_offset_known && a.parm_offset_known);\n+\n+  poly_int64 new_parm_offset, offset1, aoffset1;\n+  if (!combined_offsets (a, &new_parm_offset, &offset1, &aoffset1))\n+    {\n+      parm_offset_known = false;\n+      return;\n+    }\n+  gcc_checking_assert (range_info_useful_p ()\n+\t\t       && a.range_info_useful_p ());\n+  if (record_adjustments)\n+    adjustments += a.adjustments;\n+  update2 (new_parm_offset,\n+\t   offset1, size, max_size,\n+\t   aoffset1, a.size, a.max_size,\n+\t   record_adjustments);\n+}\n+\n+/* Merge two ranges both starting at parm_offset1 and update THIS\n+   with result.  */\n+void\n+modref_access_node::update2 (poly_int64 parm_offset1,\n+\t\t\t     poly_int64 offset1, poly_int64 size1,\n+\t\t\t     poly_int64 max_size1,\n+\t\t\t     poly_int64 offset2, poly_int64 size2,\n+\t\t\t     poly_int64 max_size2,\n+\t\t\t     bool record_adjustments)\n+{\n+  poly_int64 new_size = size1;\n+\n+  if (!known_size_p (size2)\n+      || known_le (size2, size1))\n+    new_size = size2;\n+  else\n+    gcc_checking_assert (known_le (size1, size2));\n+\n+  if (known_le (offset1, offset2))\n+    ;\n+  else if (known_le (offset2, offset1))\n+    {\n+      std::swap (offset1, offset2);\n+      std::swap (max_size1, max_size2);\n+    }\n+  else\n+    gcc_unreachable ();\n+\n+  poly_int64 new_max_size;\n+\n+  if (!known_size_p (max_size1))\n+    new_max_size = max_size1;\n+  else if (!known_size_p (max_size2))\n+    new_max_size = max_size2;\n+  else\n+    {\n+      new_max_size = max_size2 + offset2 - offset1;\n+      if (known_le (new_max_size, max_size1))\n+\tnew_max_size = max_size1;\n+    }\n+\n+  update (parm_offset1, offset1,\n+\t  new_size, new_max_size, record_adjustments);\n+}\n+\n+/* Given access nodes THIS and A, return true if they\n+   can be done with common parm_offsets.  In this case\n+   return parm offset in new_parm_offset, new_offset\n+   which is start of range in THIS and new_aoffset that\n+   is start of range in A.  */\n+bool\n+modref_access_node::combined_offsets (const modref_access_node &a,\n+\t\t\t\t      poly_int64 *new_parm_offset,\n+\t\t\t\t      poly_int64 *new_offset,\n+\t\t\t\t      poly_int64 *new_aoffset) const\n+{\n+  gcc_checking_assert (parm_offset_known && a.parm_offset_known);\n+  if (known_le (a.parm_offset, parm_offset))\n+    {\n+      *new_offset = offset\n+\t\t    + ((parm_offset - a.parm_offset)\n+\t\t       << LOG2_BITS_PER_UNIT);\n+      *new_aoffset = a.offset;\n+      *new_parm_offset = a.parm_offset;\n+      return true;\n+    }\n+  else if (known_le (parm_offset, a.parm_offset))\n+    {\n+      *new_aoffset = a.offset\n+\t\t      + ((a.parm_offset - parm_offset)\n+\t\t\t << LOG2_BITS_PER_UNIT);\n+      *new_offset = offset;\n+      *new_parm_offset = parm_offset;\n+      return true;\n+    }\n+  else\n+    return false;\n+}\n+\n+/* Try to optimize the access ACCESSES list after entry INDEX was modified.  */\n+void\n+modref_access_node::try_merge_with (vec <modref_access_node, va_gc> *&accesses,\n+\t\t\t\t    size_t index)\n+{\n+  size_t i;\n+\n+  for (i = 0; i < accesses->length ();)\n+    if (i != index)\n+      {\n+\tbool found = false, restart = false;\n+\tmodref_access_node *a = &(*accesses)[i];\n+\tmodref_access_node *n = &(*accesses)[index];\n+\n+\tif (n->contains (*a))\n+\t  found = true;\n+\tif (!found && n->merge (*a, false))\n+\t  found = restart = true;\n+\tgcc_checking_assert (found || !a->merge (*n, false));\n+\tif (found)\n+\t  {\n+\t    accesses->unordered_remove (i);\n+\t    if (index == accesses->length ())\n+\t      {\n+\t\tindex = i;\n+\t\ti++;\n+\t      }\n+\t    if (restart)\n+\t      i = 0;\n+\t  }\n+\telse\n+\t  i++;\n+      }\n+    else\n+      i++;\n+}\n+\n+/* Insert access with OFFSET and SIZE.\n+   Collapse tree if it has more than MAX_ACCESSES entries.\n+   If RECORD_ADJUSTMENTs is true avoid too many interval extensions.\n+   Return true if record was changed.\n+\n+   Reutrn 0 if nothing changed, 1 if insert was successful and -1\n+   if entries should be collapsed.  */\n+int\n+modref_access_node::insert (vec <modref_access_node, va_gc> *&accesses,\n+\t\t\t    modref_access_node a, size_t max_accesses,\n+\t\t\t    bool record_adjustments)\n+{\n+  size_t i, j;\n+  modref_access_node *a2;\n+\n+  /* Verify that list does not contain redundant accesses.  */\n+  if (flag_checking)\n+    {\n+      size_t i, i2;\n+      modref_access_node *a, *a2;\n+\n+      FOR_EACH_VEC_SAFE_ELT (accesses, i, a)\n+\t{\n+\t  FOR_EACH_VEC_SAFE_ELT (accesses, i2, a2)\n+\t    if (i != i2)\n+\t      gcc_assert (!a->contains (*a2));\n+\t}\n+    }\n+\n+  FOR_EACH_VEC_SAFE_ELT (accesses, i, a2)\n+    {\n+      if (a2->contains (a))\n+\treturn 0;\n+      if (a.contains (*a2))\n+\t{\n+\t  a.adjustments = 0;\n+\t  a2->parm_index = a.parm_index;\n+\t  a2->parm_offset_known = a.parm_offset_known;\n+\t  a2->update (a.parm_offset, a.offset, a.size, a.max_size,\n+\t\t      record_adjustments);\n+\t  modref_access_node::try_merge_with (accesses, i);\n+\t  return 1;\n+\t}\n+      if (a2->merge (a, record_adjustments))\n+\t{\n+\t  modref_access_node::try_merge_with (accesses, i);\n+\t  return 1;\n+\t}\n+      gcc_checking_assert (!(a == *a2));\n+    }\n+\n+  /* If this base->ref pair has too many accesses stored, we will clear\n+     all accesses and bail out.  */\n+  if (accesses && accesses->length () >= max_accesses)\n+    {\n+      if (max_accesses < 2)\n+\treturn -1;\n+      /* Find least harmful merge and perform it.  */\n+      int best1 = -1, best2 = -1;\n+      FOR_EACH_VEC_SAFE_ELT (accesses, i, a2)\n+\t{\n+\t  for (j = i + 1; j < accesses->length (); j++)\n+\t    if (best1 < 0\n+\t\t|| modref_access_node::closer_pair_p\n+\t\t     (*a2, (*accesses)[j],\n+\t\t      (*accesses)[best1],\n+\t\t      best2 < 0 ? a : (*accesses)[best2]))\n+\t      {\n+\t\tbest1 = i;\n+\t\tbest2 = j;\n+\t      }\n+\t  if (modref_access_node::closer_pair_p\n+\t\t     (*a2, a,\n+\t\t      (*accesses)[best1],\n+\t\t      best2 < 0 ? a : (*accesses)[best2]))\n+\t    {\n+\t      best1 = i;\n+\t      best2 = -1;\n+\t    }\n+\t}\n+      (*accesses)[best1].forced_merge (best2 < 0 ? a : (*accesses)[best2],\n+\t\t\t\t       record_adjustments);\n+      /* Check that merging indeed merged ranges.  */\n+      gcc_checking_assert ((*accesses)[best1].contains\n+\t\t\t       (best2 < 0 ? a : (*accesses)[best2]));\n+      if (!(*accesses)[best1].useful_p ())\n+\treturn -1;\n+      if (dump_file && best2 >= 0)\n+\tfprintf (dump_file,\n+\t\t \"--param param=modref-max-accesses limit reached;\"\n+\t\t \" merging %i and %i\\n\", best1, best2);\n+      else if (dump_file)\n+\tfprintf (dump_file,\n+\t\t \"--param param=modref-max-accesses limit reached;\"\n+\t\t \" merging with %i\\n\", best1);\n+      modref_access_node::try_merge_with (accesses, best1);\n+      if (best2 >= 0)\n+\tinsert (accesses, a, max_accesses, record_adjustments);\n+      return 1;\n+    }\n+  a.adjustments = 0;\n+  vec_safe_push (accesses, a);\n+  return 1;\n+}\n+\n namespace selftest {\n \n static void"}, {"sha": "b35cf3a4aed93f3d71a4e5c124ea2e7d0c678954", "filename": "gcc/ipa-modref-tree.h", "status": "modified", "additions": 28, "deletions": 514, "changes": 542, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/a246d7230b8f8b059b21a073e8a91c213dee9cf4/gcc%2Fipa-modref-tree.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/a246d7230b8f8b059b21a073e8a91c213dee9cf4/gcc%2Fipa-modref-tree.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-modref-tree.h?ref=a246d7230b8f8b059b21a073e8a91c213dee9cf4", "patch": "@@ -57,7 +57,6 @@ enum modref_special_parms {\n /* Memory access.  */\n struct GTY(()) modref_access_node\n {\n-\n   /* Access range information (in bits).  */\n   poly_int64 offset;\n   poly_int64 size;\n@@ -88,380 +87,28 @@ struct GTY(()) modref_access_node\n \t\t || known_ge (offset, 0));\n     }\n   /* Return true if both accesses are the same.  */\n-  bool operator == (modref_access_node &a) const\n-    {\n-      if (parm_index != a.parm_index)\n-\treturn false;\n-      if (parm_index != MODREF_UNKNOWN_PARM)\n-\t{\n-\t  if (parm_offset_known != a.parm_offset_known)\n-\t    return false;\n-\t  if (parm_offset_known\n-\t      && !known_eq (parm_offset, a.parm_offset))\n-\t    return false;\n-\t}\n-      if (range_info_useful_p () != a.range_info_useful_p ())\n-\treturn false;\n-      if (range_info_useful_p ()\n-\t  && (!known_eq (a.offset, offset)\n-\t      || !known_eq (a.size, size)\n-\t      || !known_eq (a.max_size, max_size)))\n-\treturn false;\n-      return true;\n-    }\n-  /* Return true A is a subaccess.  */\n-  bool contains (const modref_access_node &a) const\n-    {\n-      poly_int64 aoffset_adj = 0;\n-      if (parm_index != MODREF_UNKNOWN_PARM)\n-\t{\n-\t  if (parm_index != a.parm_index)\n-\t    return false;\n-\t  if (parm_offset_known)\n-\t    {\n-\t       if (!a.parm_offset_known)\n-\t\t return false;\n-\t       /* Accesses are never below parm_offset, so look\n-\t\t  for smaller offset.\n-\t\t  If access ranges are known still allow merging\n-\t\t  when bit offsets comparsion passes.  */\n-\t       if (!known_le (parm_offset, a.parm_offset)\n-\t\t   && !range_info_useful_p ())\n-\t\t return false;\n-\t       /* We allow negative aoffset_adj here in case\n-\t\t  there is an useful range.  This is because adding\n-\t\t  a.offset may result in non-ngative offset again.\n-\t\t  Ubsan fails on val << LOG_BITS_PER_UNIT where val\n-\t\t  is negative.  */\n-\t       aoffset_adj = (a.parm_offset - parm_offset)\n-\t\t\t     * BITS_PER_UNIT;\n-\t    }\n-\t}\n-      if (range_info_useful_p ())\n-\t{\n-\t  if (!a.range_info_useful_p ())\n-\t    return false;\n-\t  /* Sizes of stores are used to check that object is big enough\n-\t     to fit the store, so smaller or unknown sotre is more general\n-\t     than large store.  */\n-\t  if (known_size_p (size)\n-\t      && (!known_size_p (a.size)\n-\t\t  || !known_le (size, a.size)))\n-\t    return false;\n-\t  if (known_size_p (max_size))\n-\t    return known_subrange_p (a.offset + aoffset_adj,\n-\t\t\t\t     a.max_size, offset, max_size);\n-\t  else\n-\t    return known_le (offset, a.offset + aoffset_adj);\n-\t}\n-      return true;\n-    }\n-  /* Update access range to new parameters.\n-     If RECORD_ADJUSTMENTS is true, record number of changes in the access\n-     and if threshold is exceeded start dropping precision\n-     so only constantly many updates are possible.  This makes dataflow\n-     to converge.  */\n-  void update (poly_int64 parm_offset1,\n-\t       poly_int64 offset1, poly_int64 size1, poly_int64 max_size1,\n-\t       bool record_adjustments)\n-    {\n-      if (known_eq (parm_offset, parm_offset1)\n-\t  && known_eq (offset, offset1)\n-\t  && known_eq (size, size1)\n-\t  && known_eq (max_size, max_size1))\n-\treturn;\n-      if (!record_adjustments\n-\t  || (++adjustments) < param_modref_max_adjustments)\n-\t{\n-\t  parm_offset = parm_offset1;\n-\t  offset = offset1;\n-\t  size = size1;\n-\t  max_size = max_size1;\n-\t}\n-      else\n-\t{\n-\t  if (dump_file)\n-\t    fprintf (dump_file,\n-\t\t     \"--param param=modref-max-adjustments limit reached:\");\n-\t  if (!known_eq (parm_offset, parm_offset1))\n-\t    {\n-\t      if (dump_file)\n-\t\tfprintf (dump_file, \" parm_offset cleared\");\n-\t      parm_offset_known = false;\n-\t    }\n-\t  if (!known_eq (size, size1))\n-\t    {\n-\t      size = -1;\n-\t      if (dump_file)\n-\t\tfprintf (dump_file, \" size cleared\");\n-\t    }\n-\t  if (!known_eq (max_size, max_size1))\n-\t    {\n-\t      max_size = -1;\n-\t      if (dump_file)\n-\t\tfprintf (dump_file, \" max_size cleared\");\n-\t    }\n-\t  if (!known_eq (offset, offset1))\n-\t    {\n-\t      offset = 0;\n-\t      if (dump_file)\n-\t\tfprintf (dump_file, \" offset cleared\");\n-\t    }\n-\t  if (dump_file)\n-\t    fprintf (dump_file, \"\\n\");\n-\t}\n-    }\n-  /* Merge in access A if it is possible to do without losing\n-     precision.  Return true if successful.\n-     If RECORD_ADJUSTMENTs is true, remember how many interval\n-     was prolonged and punt when there are too many.  */\n-  bool merge (const modref_access_node &a, bool record_adjustments)\n-    {\n-      poly_int64 offset1 = 0;\n-      poly_int64 aoffset1 = 0;\n-      poly_int64 new_parm_offset = 0;\n-\n-      /* We assume that containment was tested earlier.  */\n-      gcc_checking_assert (!contains (a) && !a.contains (*this));\n-      if (parm_index != MODREF_UNKNOWN_PARM)\n-\t{\n-\t  if (parm_index != a.parm_index)\n-\t    return false;\n-\t  if (parm_offset_known)\n-\t    {\n-\t      if (!a.parm_offset_known)\n-\t\treturn false;\n-\t      if (!combined_offsets (a, &new_parm_offset, &offset1, &aoffset1))\n-\t\treturn false;\n-\t    }\n-\t}\n-      /* See if we can merge ranges.  */\n-      if (range_info_useful_p ())\n-\t{\n-\t  /* In this case we have containment that should be\n-\t     handled earlier.  */\n-\t  gcc_checking_assert (a.range_info_useful_p ());\n-\n-\t  /* If a.size is less specified than size, merge only\n-\t     if intervals are otherwise equivalent.  */\n-\t  if (known_size_p (size)\n-\t      && (!known_size_p (a.size) || known_lt (a.size, size)))\n-\t    {\n-\t      if (((known_size_p (max_size) || known_size_p (a.max_size))\n-\t\t   && !known_eq (max_size, a.max_size))\n-\t\t   || !known_eq (offset1, aoffset1))\n-\t\treturn false;\n-\t      update (new_parm_offset, offset1, a.size, max_size,\n-\t\t      record_adjustments);\n-\t      return true;\n-\t    }\n-\t  /* If sizes are same, we can extend the interval.  */\n-\t  if ((known_size_p (size) || known_size_p (a.size))\n-\t      && !known_eq (size, a.size))\n-\t    return false;\n-\t  if (known_le (offset1, aoffset1))\n-\t    {\n-\t      if (!known_size_p (max_size)\n-\t\t  || known_ge (offset1 + max_size, aoffset1))\n-\t\t{\n-\t\t  update2 (new_parm_offset, offset1, size, max_size,\n-\t\t\t   aoffset1, a.size, a.max_size,\n-\t\t\t   record_adjustments);\n-\t\t  return true;\n-\t\t}\n-\t    }\n-\t  else if (known_le (aoffset1, offset1))\n-\t    {\n-\t      if (!known_size_p (a.max_size)\n-\t\t  || known_ge (aoffset1 + a.max_size, offset1))\n-\t\t{\n-\t\t  update2 (new_parm_offset, offset1, size, max_size,\n-\t\t\t   aoffset1, a.size, a.max_size,\n-\t\t\t   record_adjustments);\n-\t\t  return true;\n-\t\t}\n-\t    }\n-\t  return false;\n-\t}\n-      update (new_parm_offset, offset1,\n-\t      size, max_size, record_adjustments);\n-      return true;\n-    }\n-  /* Return true if A1 and B1 can be merged with lower informatoin\n-     less than A2 and B2.\n-     Assume that no containment or lossless merging is possible.  */\n-  static bool closer_pair_p (const modref_access_node &a1,\n-\t\t\t     const modref_access_node &b1,\n-\t\t\t     const modref_access_node &a2,\n-\t\t\t     const modref_access_node &b2)\n-    {\n-      /* Merging different parm indexes comes to complete loss\n-\t of range info.  */\n-      if (a1.parm_index != b1.parm_index)\n-\treturn false;\n-      if (a2.parm_index != b2.parm_index)\n-\treturn true;\n-      /* If parm is known and parm indexes are the same we should\n-\t already have containment.  */\n-      gcc_checking_assert (a1.parm_offset_known && b1.parm_offset_known);\n-      gcc_checking_assert (a2.parm_offset_known && b2.parm_offset_known);\n-\n-      /* First normalize offsets for parm offsets.  */\n-      poly_int64 new_parm_offset, offseta1, offsetb1, offseta2, offsetb2;\n-      if (!a1.combined_offsets (b1, &new_parm_offset, &offseta1, &offsetb1)\n-\t  || !a2.combined_offsets (b2, &new_parm_offset, &offseta2, &offsetb2))\n-\tgcc_unreachable ();\n-\n-\n-      /* Now compute distnace of the intervals.  */\n-      poly_int64 dist1, dist2;\n-      if (known_le (offseta1, offsetb1))\n-\t{\n-\t  if (!known_size_p (a1.max_size))\n-\t    dist1 = 0;\n-\t  else\n-\t    dist1 = offsetb1 - offseta1 - a1.max_size;\n-\t}\n-      else\n-\t{\n-\t  if (!known_size_p (b1.max_size))\n-\t    dist1 = 0;\n-\t  else\n-\t    dist1 = offseta1 - offsetb1 - b1.max_size;\n-\t}\n-      if (known_le (offseta2, offsetb2))\n-\t{\n-\t  if (!known_size_p (a2.max_size))\n-\t    dist2 = 0;\n-\t  else\n-\t    dist2 = offsetb2 - offseta2 - a2.max_size;\n-\t}\n-      else\n-\t{\n-\t  if (!known_size_p (b2.max_size))\n-\t    dist2 = 0;\n-\t  else\n-\t    dist2 = offseta2 - offsetb2 - b2.max_size;\n-\t}\n-      /* It may happen that intervals overlap in case size\n-\t is different.  Preffer the overlap to non-overlap.  */\n-      if (known_lt (dist1, 0) && known_ge (dist2, 0))\n-\treturn true;\n-      if (known_lt (dist2, 0) && known_ge (dist1, 0))\n-\treturn false;\n-      if (known_lt (dist1, 0))\n-\t/* If both overlaps minimize overlap.  */\n-\treturn known_le (dist2, dist1);\n-      else\n-\t/* If both are disjoint look for smaller distance.  */\n-\treturn known_le (dist1, dist2);\n-    }\n-\n-  /* Merge in access A while losing precision.  */\n-  void forced_merge (const modref_access_node &a, bool record_adjustments)\n-    {\n-      if (parm_index != a.parm_index)\n-\t{\n-\t  gcc_checking_assert (parm_index != MODREF_UNKNOWN_PARM);\n-\t  parm_index = MODREF_UNKNOWN_PARM;\n-\t  return;\n-\t}\n-\n-      /* We assume that containment and lossless merging\n-\t was tested earlier.  */\n-      gcc_checking_assert (!contains (a) && !a.contains (*this)\n-\t\t\t   && !merge (a, record_adjustments));\n-      gcc_checking_assert (parm_offset_known && a.parm_offset_known);\n-\n-      poly_int64 new_parm_offset, offset1, aoffset1;\n-      if (!combined_offsets (a, &new_parm_offset, &offset1, &aoffset1))\n-\t{\n-\t  parm_offset_known = false;\n-\t  return;\n-\t}\n-      gcc_checking_assert (range_info_useful_p ()\n-\t\t\t   && a.range_info_useful_p ());\n-      if (record_adjustments)\n-\tadjustments += a.adjustments;\n-      update2 (new_parm_offset,\n-\t       offset1, size, max_size,\n-\t       aoffset1, a.size, a.max_size,\n-\t       record_adjustments);\n-    }\n+  bool operator == (modref_access_node &a) const;\n+  /* Insert A into ACCESSES.  Limit size of vector to MAX_ACCESSES and if\n+     RECORD_ADJUSTMENT is true keep track of adjustment counts.\n+     Return 0 if nothing changed, 1 is insertion suceeded and -1 if\n+     failed.  */\n+  static int insert (vec <modref_access_node, va_gc> *&accesses,\n+\t\t     modref_access_node a, size_t max_accesses,\n+\t\t     bool record_adjustments);\n private:\n-  /* Merge two ranges both starting at parm_offset1 and update THIS\n-     with result.  */\n-  void update2 (poly_int64 parm_offset1,\n-\t\tpoly_int64 offset1, poly_int64 size1, poly_int64 max_size1,\n-\t\tpoly_int64 offset2, poly_int64 size2, poly_int64 max_size2,\n-\t\tbool record_adjustments)\n-    {\n-      poly_int64 new_size = size1;\n-\n-      if (!known_size_p (size2)\n-\t  || known_le (size2, size1))\n-\tnew_size = size2;\n-      else\n-\tgcc_checking_assert (known_le (size1, size2));\n-\n-      if (known_le (offset1, offset2))\n-\t;\n-      else if (known_le (offset2, offset1))\n-\t{\n-\t  std::swap (offset1, offset2);\n-\t  std::swap (max_size1, max_size2);\n-\t}\n-      else\n-\tgcc_unreachable ();\n-\n-      poly_int64 new_max_size;\n-\n-      if (!known_size_p (max_size1))\n-\tnew_max_size = max_size1;\n-      else if (!known_size_p (max_size2))\n-\tnew_max_size = max_size2;\n-      else\n-\t{\n-\t  new_max_size = max_size2 + offset2 - offset1;\n-\t  if (known_le (new_max_size, max_size1))\n-\t    new_max_size = max_size1;\n-\t}\n-\n-      update (parm_offset1, offset1,\n-\t      new_size, new_max_size, record_adjustments);\n-    }\n-  /* Given access nodes THIS and A, return true if they\n-     can be done with common parm_offsets.  In this case\n-     return parm offset in new_parm_offset, new_offset\n-     which is start of range in THIS and new_aoffset that\n-     is start of range in A.  */\n-  bool combined_offsets (const modref_access_node &a,\n-\t\t\t poly_int64 *new_parm_offset,\n-\t\t\t poly_int64 *new_offset,\n-\t\t\t poly_int64 *new_aoffset) const\n-    {\n-      gcc_checking_assert (parm_offset_known && a.parm_offset_known);\n-      if (known_le (a.parm_offset, parm_offset))\n-\t{\n-\t  *new_offset = offset\n-\t\t\t+ ((parm_offset - a.parm_offset)\n-\t\t\t   << LOG2_BITS_PER_UNIT);\n-\t  *new_aoffset = a.offset;\n-\t  *new_parm_offset = a.parm_offset;\n-\t  return true;\n-\t}\n-      else if (known_le (parm_offset, a.parm_offset))\n-\t{\n-\t  *new_aoffset = a.offset\n-\t  \t\t  + ((a.parm_offset - parm_offset)\n-\t\t\t     << LOG2_BITS_PER_UNIT);\n-\t  *new_offset = offset;\n-\t  *new_parm_offset = parm_offset;\n-\t  return true;\n-\t}\n-      else\n-\treturn false;\n-    }\n+  bool contains (const modref_access_node &) const;\n+  void update (poly_int64, poly_int64, poly_int64, poly_int64, bool);\n+  bool merge (const modref_access_node &, bool);\n+  static bool closer_pair_p (const modref_access_node &,\n+\t\t\t     const modref_access_node &,\n+\t\t\t     const modref_access_node &,\n+\t\t\t     const modref_access_node &);\n+  void forced_merge (const modref_access_node &, bool);\n+  void update2 (poly_int64, poly_int64, poly_int64, poly_int64,\n+\t\tpoly_int64, poly_int64, poly_int64, bool);\n+  bool combined_offsets (const modref_access_node &,\n+\t\t\t poly_int64 *, poly_int64 *, poly_int64 *) const;\n+  static void try_merge_with (vec <modref_access_node, va_gc> *&, size_t);\n };\n \n /* Access node specifying no useful info.  */\n@@ -489,20 +136,6 @@ struct GTY((user)) modref_ref_node\n     every_access = true;\n   }\n \n-  /* Verify that list does not contain redundant accesses.  */\n-  void verify ()\n-  {\n-    size_t i, i2;\n-    modref_access_node *a, *a2;\n-\n-    FOR_EACH_VEC_SAFE_ELT (accesses, i, a)\n-      {\n-\tFOR_EACH_VEC_SAFE_ELT (accesses, i2, a2)\n-\t  if (i != i2)\n-\t    gcc_assert (!a->contains (*a2));\n-      }\n-  }\n-\n   /* Insert access with OFFSET and SIZE.\n      Collapse tree if it has more than MAX_ACCESSES entries.\n      If RECORD_ADJUSTMENTs is true avoid too many interval extensions.\n@@ -514,18 +147,12 @@ struct GTY((user)) modref_ref_node\n     if (every_access)\n       return false;\n \n-    /* Otherwise, insert a node for the ref of the access under the base.  */\n-    size_t i, j;\n-    modref_access_node *a2;\n-\n     /* Only the following kind of paramters needs to be tracked.\n        We do not track return slots because they are seen as a direct store\n        in the caller.  */\n     gcc_checking_assert (a.parm_index >= 0\n \t\t\t || a.parm_index == MODREF_STATIC_CHAIN_PARM\n \t\t\t || a.parm_index == MODREF_UNKNOWN_PARM);\n-    if (flag_checking)\n-      verify ();\n \n     if (!a.useful_p ())\n       {\n@@ -537,130 +164,17 @@ struct GTY((user)) modref_ref_node\n \treturn false;\n       }\n \n-    FOR_EACH_VEC_SAFE_ELT (accesses, i, a2)\n-      {\n-\tif (a2->contains (a))\n-\t  return false;\n-\tif (a.contains (*a2))\n-\t  {\n-\t    a.adjustments = 0;\n-\t    a2->parm_index = a.parm_index;\n-\t    a2->parm_offset_known = a.parm_offset_known;\n-\t    a2->update (a.parm_offset, a.offset, a.size, a.max_size,\n-\t\t\trecord_adjustments);\n-\t    try_merge_with (i);\n-\t    return true;\n-\t  }\n-\tif (a2->merge (a, record_adjustments))\n-\t  {\n-\t    try_merge_with (i);\n-\t    return true;\n-\t  }\n-\tgcc_checking_assert (!(a == *a2));\n-      }\n-\n-    /* If this base->ref pair has too many accesses stored, we will clear\n-       all accesses and bail out.  */\n-    if (accesses && accesses->length () >= max_accesses)\n+    int ret = modref_access_node::insert (accesses, a, max_accesses,\n+\t\t\t\t\t  record_adjustments);\n+    if (ret == -1)\n       {\n-\tif (max_accesses < 2)\n-\t  {\n-\t    collapse ();\n-\t    if (dump_file)\n-\t      fprintf (dump_file,\n-\t\t       \"--param param=modref-max-accesses limit reached;\"\n-\t\t       \" collapsing\\n\");\n-\t    return true;\n-\t  }\n-\t/* Find least harmful merge and perform it.  */\n-\tint best1 = -1, best2 = -1;\n-\tFOR_EACH_VEC_SAFE_ELT (accesses, i, a2)\n-\t  {\n-\t    for (j = i + 1; j < accesses->length (); j++)\n-\t      if (best1 < 0\n-\t\t  || modref_access_node::closer_pair_p\n-\t\t       (*a2, (*accesses)[j],\n-\t\t\t(*accesses)[best1],\n-\t\t\tbest2 < 0 ? a : (*accesses)[best2]))\n-\t\t{\n-\t\t  best1 = i;\n-\t\t  best2 = j;\n-\t\t}\n-\t    if (modref_access_node::closer_pair_p\n-\t\t       (*a2, a,\n-\t\t\t(*accesses)[best1],\n-\t\t\tbest2 < 0 ? a : (*accesses)[best2]))\n-\t      {\n-\t\tbest1 = i;\n-\t\tbest2 = -1;\n-\t      }\n-\t  }\n-\t(*accesses)[best1].forced_merge (best2 < 0 ? a : (*accesses)[best2],\n-\t\t\t\t\t record_adjustments);\n-\t/* Check that merging indeed merged ranges.  */\n-\tgcc_checking_assert ((*accesses)[best1].contains\n-\t\t\t\t (best2 < 0 ? a : (*accesses)[best2]));\n-\tif (!(*accesses)[best1].useful_p ())\n-\t  {\n-\t    collapse ();\n-\t    if (dump_file)\n-\t      fprintf (dump_file,\n-\t\t       \"--param param=modref-max-accesses limit reached;\"\n-\t\t       \" collapsing\\n\");\n-\t    return true;\n-\t  }\n-\tif (dump_file && best2 >= 0)\n-\t  fprintf (dump_file,\n-\t\t   \"--param param=modref-max-accesses limit reached;\"\n-\t\t   \" merging %i and %i\\n\", best1, best2);\n-\telse if (dump_file)\n+\tif (dump_file)\n \t  fprintf (dump_file,\n \t\t   \"--param param=modref-max-accesses limit reached;\"\n-\t\t   \" merging with %i\\n\", best1);\n-\ttry_merge_with (best1);\n-\tif (best2 >= 0)\n-\t  insert_access (a, max_accesses, record_adjustments);\n-\treturn 1;\n+\t\t   \" collapsing\\n\");\n+\tcollapse ();\n       }\n-    a.adjustments = 0;\n-    vec_safe_push (accesses, a);\n-    return true;\n-  }\n-private:\n-  /* Try to optimize the access list after entry INDEX was modified.  */\n-  void\n-  try_merge_with (size_t index)\n-  {\n-    size_t i;\n-\n-    for (i = 0; i < accesses->length ();)\n-      if (i != index)\n-\t{\n-\t  bool found = false, restart = false;\n-\t  modref_access_node *a = &(*accesses)[i];\n-\t  modref_access_node *n = &(*accesses)[index];\n-\n-\t  if (n->contains (*a))\n-\t    found = true;\n-\t  if (!found && n->merge (*a, false))\n-\t    found = restart = true;\n-\t  gcc_checking_assert (found || !a->merge (*n, false));\n-\t  if (found)\n-\t    {\n-\t      accesses->unordered_remove (i);\n-\t      if (index == accesses->length ())\n-\t\t{\n-\t\t  index = i;\n-\t\t  i++;\n-\t\t}\n-\t      if (restart)\n-\t\ti = 0;\n-\t    }\n-\t  else\n-\t    i++;\n-\t}\n-      else\n-\ti++;\n+    return ret != 0;\n   }\n };\n "}]}