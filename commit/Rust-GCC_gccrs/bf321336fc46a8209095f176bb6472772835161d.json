{"sha": "bf321336fc46a8209095f176bb6472772835161d", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YmYzMjEzMzZmYzQ2YTgyMDkwOTVmMTc2YmI2NDcyNzcyODM1MTYxZA==", "commit": {"author": {"name": "Eric Botcazou", "email": "ebotcazou@adacore.com", "date": "2019-08-01T20:15:19Z"}, "committer": {"name": "Eric Botcazou", "email": "ebotcazou@gcc.gnu.org", "date": "2019-08-01T20:15:19Z"}, "message": "cgraph.h (cgraph_edge::maybe_hot_p): Tweak comment.\n\n\t* cgraph.h (cgraph_edge::maybe_hot_p): Tweak comment.\n\t* cgraph.c (cgraph_edge::maybe_hot_p): Likewise.  Remove useless test.\n\t* predict.c (maybe_hot_count_p): Likewise.\n\t(maybe_hot_bb_p): Tweak comment.\n\t(maybe_hot_edge_p): Likewise.\n\t(probably_never_executed): Likewise.  Minor tweak.\n\t(probably_never_executed_bb_p): Likewise.\n\t(unlikely_executed_edge_p): Likewise.\n\t(probably_never_executed_edge_p): Likewise.\n\t(optimize_function_for_size_p): Likewise.\n\t(optimize_function_for_speed_p): Likewise.\n\t(function_optimization_type): Likewise.\n\t(optimize_bb_for_size_p): Likewise.\n\t(optimize_bb_for_speed_p): Likewise.\n\t(bb_optimization_type): Likewise.\n\t(optimize_edge_for_size_p): Likewise.\n\t(optimize_edge_for_speed_p): Likewise.\n\t(optimize_insn_for_size_p): Likewise.\n\t(optimize_insn_for_speed_p): Likewise.\n\t(optimize_loop_for_size_p): Likewise.\n\t(optimize_loop_for_speed_p): Likewise.\n\t(optimize_loop_nest_for_speed_p): Likewise.\n\t(optimize_loop_nest_for_size_p): Likewise.\n\t(predictable_edge_p): Likewise.\n\t(handle_missing_profiles): Minor tweak.\n\nFrom-SVN: r273983", "tree": {"sha": "cba303a8b96c9b205090c3653e19eef9e2650b20", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/cba303a8b96c9b205090c3653e19eef9e2650b20"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/bf321336fc46a8209095f176bb6472772835161d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bf321336fc46a8209095f176bb6472772835161d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/bf321336fc46a8209095f176bb6472772835161d", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bf321336fc46a8209095f176bb6472772835161d/comments", "author": null, "committer": null, "parents": [{"sha": "f7eaa84e536803411cac5a1fdb69f9dea5ab65bc", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f7eaa84e536803411cac5a1fdb69f9dea5ab65bc", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f7eaa84e536803411cac5a1fdb69f9dea5ab65bc"}], "stats": {"total": 101, "additions": 61, "deletions": 40}, "files": [{"sha": "ab92da57ea6df97e278835de5207f3ab5fdc8b7f", "filename": "gcc/ChangeLog", "status": "modified", "additions": 28, "deletions": 0, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bf321336fc46a8209095f176bb6472772835161d/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bf321336fc46a8209095f176bb6472772835161d/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=bf321336fc46a8209095f176bb6472772835161d", "patch": "@@ -1,3 +1,31 @@\n+2019-08-01  Eric Botcazou  <ebotcazou@adacore.com>\n+\n+\t* cgraph.h (cgraph_edge::maybe_hot_p): Tweak comment.\n+\t* cgraph.c (cgraph_edge::maybe_hot_p): Likewise.  Remove useless test.\n+\t* predict.c (maybe_hot_count_p): Likewise.\n+\t(maybe_hot_bb_p): Tweak comment.\n+\t(maybe_hot_edge_p): Likewise.\n+\t(probably_never_executed): Likewise.  Minor tweak.\n+\t(probably_never_executed_bb_p): Likewise.\n+\t(unlikely_executed_edge_p): Likewise.\n+\t(probably_never_executed_edge_p): Likewise.\n+\t(optimize_function_for_size_p): Likewise.\n+\t(optimize_function_for_speed_p): Likewise.\n+\t(function_optimization_type): Likewise.\n+\t(optimize_bb_for_size_p): Likewise.\n+\t(optimize_bb_for_speed_p): Likewise.\n+\t(bb_optimization_type): Likewise.\n+\t(optimize_edge_for_size_p): Likewise.\n+\t(optimize_edge_for_speed_p): Likewise.\n+\t(optimize_insn_for_size_p): Likewise.\n+\t(optimize_insn_for_speed_p): Likewise.\n+\t(optimize_loop_for_size_p): Likewise.\n+\t(optimize_loop_for_speed_p): Likewise.\n+\t(optimize_loop_nest_for_speed_p): Likewise.\n+\t(optimize_loop_nest_for_size_p): Likewise.\n+\t(predictable_edge_p): Likewise.\n+\t(handle_missing_profiles): Minor tweak.\n+\n 2019-08-01  Michael Meissner  <meissner@linux.ibm.com>\n \n \t* config/rs6000/predicates.md (pcrel_external_address): Update"}, {"sha": "bed407e5766fef4c590a23f3142a62e8da851f89", "filename": "gcc/cgraph.c", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bf321336fc46a8209095f176bb6472772835161d/gcc%2Fcgraph.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bf321336fc46a8209095f176bb6472772835161d/gcc%2Fcgraph.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcgraph.c?ref=bf321336fc46a8209095f176bb6472772835161d", "patch": "@@ -2759,7 +2759,7 @@ cgraph_edge::cannot_lead_to_return_p (void)\n     return callee->cannot_return_p ();\n }\n \n-/* Return true if the call can be hot.  */\n+/* Return true if the edge may be considered hot.  */\n \n bool\n cgraph_edge::maybe_hot_p (void)\n@@ -2785,8 +2785,7 @@ cgraph_edge::maybe_hot_p (void)\n   if (caller->frequency == NODE_FREQUENCY_EXECUTED_ONCE\n       && sreal_frequency () * 2 < 3)\n     return false;\n-  if (PARAM_VALUE (HOT_BB_FREQUENCY_FRACTION) == 0\n-      || sreal_frequency () * PARAM_VALUE (HOT_BB_FREQUENCY_FRACTION) <= 1)\n+  if (sreal_frequency () * PARAM_VALUE (HOT_BB_FREQUENCY_FRACTION) <= 1)\n     return false;\n   return true;\n }"}, {"sha": "4c54210123a621231734299e33e17c971700b93c", "filename": "gcc/cgraph.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bf321336fc46a8209095f176bb6472772835161d/gcc%2Fcgraph.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bf321336fc46a8209095f176bb6472772835161d/gcc%2Fcgraph.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcgraph.h?ref=bf321336fc46a8209095f176bb6472772835161d", "patch": "@@ -1746,7 +1746,7 @@ class GTY((chain_next (\"%h.next_caller\"), chain_prev (\"%h.prev_caller\"),\n   /* Return true when the edge represents a direct recursion.  */\n   bool recursive_p (void);\n \n-  /* Return true if the call can be hot.  */\n+  /* Return true if the edge may be considered hot.  */\n   bool maybe_hot_p (void);\n \n   /* Get unique identifier of the edge.  */"}, {"sha": "f7bcbff1c35004bf6f849a6efba9f9d1403ce653", "filename": "gcc/predict.c", "status": "modified", "additions": 30, "deletions": 36, "changes": 66, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bf321336fc46a8209095f176bb6472772835161d/gcc%2Fpredict.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bf321336fc46a8209095f176bb6472772835161d/gcc%2Fpredict.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpredict.c?ref=bf321336fc46a8209095f176bb6472772835161d", "patch": "@@ -149,7 +149,7 @@ set_hot_bb_threshold (gcov_type min)\n   min_count = min;\n }\n \n-/* Return TRUE if frequency FREQ is considered to be hot.  */\n+/* Return TRUE if COUNT is considered to be hot in function FUN.  */\n \n bool\n maybe_hot_count_p (struct function *fun, profile_count count)\n@@ -173,8 +173,6 @@ maybe_hot_count_p (struct function *fun, profile_count count)\n       if (node->frequency == NODE_FREQUENCY_EXECUTED_ONCE\n \t  && count < (ENTRY_BLOCK_PTR_FOR_FN (fun)->count.apply_scale (2, 3)))\n \treturn false;\n-      if (PARAM_VALUE (HOT_BB_FREQUENCY_FRACTION) == 0)\n-\treturn false;\n       if (count.apply_scale (PARAM_VALUE (HOT_BB_FREQUENCY_FRACTION), 1)\n \t  < ENTRY_BLOCK_PTR_FOR_FN (fun)->count)\n \treturn false;\n@@ -186,8 +184,8 @@ maybe_hot_count_p (struct function *fun, profile_count count)\n   return (count.to_gcov_type () >= get_hot_bb_threshold ());\n }\n \n-/* Return true in case BB can be CPU intensive and should be optimized\n-   for maximal performance.  */\n+/* Return true if basic block BB of function FUN can be CPU intensive\n+   and should thus be optimized for maximum performance.  */\n \n bool\n maybe_hot_bb_p (struct function *fun, const_basic_block bb)\n@@ -196,21 +194,20 @@ maybe_hot_bb_p (struct function *fun, const_basic_block bb)\n   return maybe_hot_count_p (fun, bb->count);\n }\n \n-/* Return true in case BB can be CPU intensive and should be optimized\n-   for maximal performance.  */\n+/* Return true if edge E can be CPU intensive and should thus be optimized\n+   for maximum performance.  */\n \n bool\n maybe_hot_edge_p (edge e)\n {\n   return maybe_hot_count_p (cfun, e->count ());\n }\n \n-/* Return true if profile COUNT and FREQUENCY, or function FUN static\n-   node frequency reflects never being executed.  */\n+/* Return true if COUNT is considered to be never executed in function FUN\n+   or if function FUN is considered so in the static profile.  */\n    \n static bool\n-probably_never_executed (struct function *fun,\n-                         profile_count count)\n+probably_never_executed (struct function *fun, profile_count count)\n {\n   gcc_checking_assert (fun);\n   if (count.ipa () == profile_count::zero ())\n@@ -222,8 +219,8 @@ probably_never_executed (struct function *fun,\n      desirable.  */\n   if (count.precise_p () && profile_status_for_fn (fun) == PROFILE_READ)\n     {\n-      int unlikely_count_fraction = PARAM_VALUE (UNLIKELY_BB_COUNT_FRACTION);\n-      if (count.apply_scale (unlikely_count_fraction, 1) >= profile_info->runs)\n+      const int unlikely_frac = PARAM_VALUE (UNLIKELY_BB_COUNT_FRACTION);\n+      if (count.apply_scale (unlikely_frac, 1) >= profile_info->runs)\n \treturn false;\n       return true;\n     }\n@@ -234,17 +231,15 @@ probably_never_executed (struct function *fun,\n   return false;\n }\n \n-\n-/* Return true in case BB is probably never executed.  */\n+/* Return true if basic block BB of function FUN is probably never executed.  */\n \n bool\n probably_never_executed_bb_p (struct function *fun, const_basic_block bb)\n {\n   return probably_never_executed (fun, bb->count);\n }\n \n-\n-/* Return true if E is unlikely executed for obvious reasons.  */\n+/* Return true if edge E is unlikely executed for obvious reasons.  */\n \n static bool\n unlikely_executed_edge_p (edge e)\n@@ -254,7 +249,7 @@ unlikely_executed_edge_p (edge e)\n \t || (e->flags & (EDGE_EH | EDGE_FAKE));\n }\n \n-/* Return true in case edge E is probably never executed.  */\n+/* Return true if edge E of function FUN is probably never executed.  */\n \n bool\n probably_never_executed_edge_p (struct function *fun, edge e)\n@@ -264,7 +259,7 @@ probably_never_executed_edge_p (struct function *fun, edge e)\n   return probably_never_executed (fun, e->count ());\n }\n \n-/* Return true when current function should always be optimized for size.  */\n+/* Return true if function FUN should always be optimized for size.  */\n \n bool\n optimize_function_for_size_p (struct function *fun)\n@@ -275,15 +270,15 @@ optimize_function_for_size_p (struct function *fun)\n   return n && n->optimize_for_size_p ();\n }\n \n-/* Return true when current function should always be optimized for speed.  */\n+/* Return true if function FUN should always be optimized for speed.  */\n \n bool\n optimize_function_for_speed_p (struct function *fun)\n {\n   return !optimize_function_for_size_p (fun);\n }\n \n-/* Return the optimization type that should be used for the function FUN.  */\n+/* Return the optimization type that should be used for function FUN.  */\n \n optimization_type\n function_optimization_type (struct function *fun)\n@@ -293,7 +288,7 @@ function_optimization_type (struct function *fun)\n \t  : OPTIMIZE_FOR_SIZE);\n }\n \n-/* Return TRUE when BB should be optimized for size.  */\n+/* Return TRUE if basic block BB should be optimized for size.  */\n \n bool\n optimize_bb_for_size_p (const_basic_block bb)\n@@ -302,15 +297,15 @@ optimize_bb_for_size_p (const_basic_block bb)\n \t  || (bb && !maybe_hot_bb_p (cfun, bb)));\n }\n \n-/* Return TRUE when BB should be optimized for speed.  */\n+/* Return TRUE if basic block BB should be optimized for speed.  */\n \n bool\n optimize_bb_for_speed_p (const_basic_block bb)\n {\n   return !optimize_bb_for_size_p (bb);\n }\n \n-/* Return the optimization type that should be used for block BB.  */\n+/* Return the optimization type that should be used for basic block BB.  */\n \n optimization_type\n bb_optimization_type (const_basic_block bb)\n@@ -320,55 +315,55 @@ bb_optimization_type (const_basic_block bb)\n \t  : OPTIMIZE_FOR_SIZE);\n }\n \n-/* Return TRUE when BB should be optimized for size.  */\n+/* Return TRUE if edge E should be optimized for size.  */\n \n bool\n optimize_edge_for_size_p (edge e)\n {\n   return optimize_function_for_size_p (cfun) || !maybe_hot_edge_p (e);\n }\n \n-/* Return TRUE when BB should be optimized for speed.  */\n+/* Return TRUE if edge E should be optimized for speed.  */\n \n bool\n optimize_edge_for_speed_p (edge e)\n {\n   return !optimize_edge_for_size_p (e);\n }\n \n-/* Return TRUE when BB should be optimized for size.  */\n+/* Return TRUE if the current function is optimized for size.  */\n \n bool\n optimize_insn_for_size_p (void)\n {\n   return optimize_function_for_size_p (cfun) || !crtl->maybe_hot_insn_p;\n }\n \n-/* Return TRUE when BB should be optimized for speed.  */\n+/* Return TRUE if the current function is optimized for speed.  */\n \n bool\n optimize_insn_for_speed_p (void)\n {\n   return !optimize_insn_for_size_p ();\n }\n \n-/* Return TRUE when LOOP should be optimized for size.  */\n+/* Return TRUE if LOOP should be optimized for size.  */\n \n bool\n optimize_loop_for_size_p (class loop *loop)\n {\n   return optimize_bb_for_size_p (loop->header);\n }\n \n-/* Return TRUE when LOOP should be optimized for speed.  */\n+/* Return TRUE if LOOP should be optimized for speed.  */\n \n bool\n optimize_loop_for_speed_p (class loop *loop)\n {\n   return optimize_bb_for_speed_p (loop->header);\n }\n \n-/* Return TRUE when LOOP nest should be optimized for speed.  */\n+/* Return TRUE if nest rooted at LOOP should be optimized for speed.  */\n \n bool\n optimize_loop_nest_for_speed_p (class loop *loop)\n@@ -396,15 +391,15 @@ optimize_loop_nest_for_speed_p (class loop *loop)\n   return false;\n }\n \n-/* Return TRUE when LOOP nest should be optimized for size.  */\n+/* Return TRUE if nest rooted at LOOP should be optimized for size.  */\n \n bool\n optimize_loop_nest_for_size_p (class loop *loop)\n {\n   return !optimize_loop_nest_for_speed_p (loop);\n }\n \n-/* Return true when edge E is likely to be well predictable by branch\n+/* Return true if edge E is likely to be well predictable by branch\n    predictor.  */\n \n bool\n@@ -3532,8 +3527,8 @@ drop_profile (struct cgraph_node *node, profile_count call_count)\n void\n handle_missing_profiles (void)\n {\n+  const int unlikely_frac = PARAM_VALUE (UNLIKELY_BB_COUNT_FRACTION);\n   struct cgraph_node *node;\n-  int unlikely_count_fraction = PARAM_VALUE (UNLIKELY_BB_COUNT_FRACTION);\n   auto_vec<struct cgraph_node *, 64> worklist;\n \n   /* See if 0 count function has non-0 count callers.  In this case we\n@@ -3563,8 +3558,7 @@ handle_missing_profiles (void)\n \n       if (call_count > 0\n           && fn && fn->cfg\n-          && (call_count.apply_scale (unlikely_count_fraction, 1)\n-\t      >= profile_info->runs))\n+          && call_count.apply_scale (unlikely_frac, 1) >= profile_info->runs)\n         {\n           drop_profile (node, call_count);\n           worklist.safe_push (node);"}]}