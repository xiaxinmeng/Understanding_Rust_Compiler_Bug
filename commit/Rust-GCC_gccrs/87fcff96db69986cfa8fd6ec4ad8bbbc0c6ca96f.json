{"sha": "87fcff96db69986cfa8fd6ec4ad8bbbc0c6ca96f", "node_id": "C_kwDOANBUbNoAKDg3ZmNmZjk2ZGI2OTk4NmNmYThmZDZlYzRhZDhiYmJjMGM2Y2E5NmY", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2021-11-12T17:33:03Z"}, "committer": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2021-11-12T17:33:03Z"}, "message": "aarch64: Remove redundant costing code\n\nPrevious patches made some of the complex parts of the issue rate\ncode redundant.\n\ngcc/\n\t* config/aarch64/aarch64.c (aarch64_vector_op::n_advsimd_ops): Delete.\n\t(aarch64_vector_op::m_seen_loads): Likewise.\n\t(aarch64_vector_costs::aarch64_vector_costs): Don't push to\n\tm_advsimd_ops.\n\t(aarch64_vector_op::count_ops): Remove vectype and factor parameters.\n\tRemove code that tries to predict different vec_flags from the\n\tcurrent loop's.\n\t(aarch64_vector_costs::add_stmt_cost): Update accordingly.\n\tRemove m_advsimd_ops handling.", "tree": {"sha": "7fdd5cd646b348b2a8bf887c5db87e3186c13777", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/7fdd5cd646b348b2a8bf887c5db87e3186c13777"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/87fcff96db69986cfa8fd6ec4ad8bbbc0c6ca96f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/87fcff96db69986cfa8fd6ec4ad8bbbc0c6ca96f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/87fcff96db69986cfa8fd6ec4ad8bbbc0c6ca96f", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/87fcff96db69986cfa8fd6ec4ad8bbbc0c6ca96f/comments", "author": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "c6c5c5ebaee4e7aa99289ae63cabb2d05d9aee00", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c6c5c5ebaee4e7aa99289ae63cabb2d05d9aee00", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c6c5c5ebaee4e7aa99289ae63cabb2d05d9aee00"}], "stats": {"total": 142, "additions": 30, "deletions": 112}, "files": [{"sha": "d8410fc52f22dfb0e8c4d79bf8aa189d747d69ea", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 30, "deletions": 112, "changes": 142, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/87fcff96db69986cfa8fd6ec4ad8bbbc0c6ca96f/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/87fcff96db69986cfa8fd6ec4ad8bbbc0c6ca96f/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=87fcff96db69986cfa8fd6ec4ad8bbbc0c6ca96f", "patch": "@@ -14914,8 +14914,8 @@ class aarch64_vector_costs : public vector_costs\n private:\n   void record_potential_advsimd_unrolling (loop_vec_info);\n   void analyze_loop_vinfo (loop_vec_info);\n-  void count_ops (unsigned int, vect_cost_for_stmt, stmt_vec_info, tree,\n-\t\t  aarch64_vec_op_count *, unsigned int);\n+  void count_ops (unsigned int, vect_cost_for_stmt, stmt_vec_info,\n+\t\t  aarch64_vec_op_count *);\n   fractional_cost adjust_body_cost_sve (const aarch64_vec_op_count *,\n \t\t\t\t\tfractional_cost, unsigned int,\n \t\t\t\t\tunsigned int *, bool *);\n@@ -14959,16 +14959,6 @@ class aarch64_vector_costs : public vector_costs\n      or vector loop.  There is one entry for each tuning option of\n      interest.  */\n   auto_vec<aarch64_vec_op_count, 2> m_ops;\n-\n-  /* Used only when vectorizing loops for SVE.  For the first element of M_OPS,\n-     it estimates what the equivalent Advanced SIMD-only code would need\n-     in order to perform the same work as one iteration of the SVE loop.  */\n-  auto_vec<aarch64_vec_op_count, 1> m_advsimd_ops;\n-\n-  /* Used to detect cases in which we end up costing the same load twice,\n-     once to account for results that are actually used and once to account\n-     for unused results.  */\n-  hash_map<nofree_ptr_hash<_stmt_vec_info>, unsigned int> m_seen_loads;\n };\n \n aarch64_vector_costs::aarch64_vector_costs (vec_info *vinfo,\n@@ -14980,8 +14970,6 @@ aarch64_vector_costs::aarch64_vector_costs (vec_info *vinfo,\n   if (auto *issue_info = aarch64_tune_params.vec_costs->issue_info)\n     {\n       m_ops.quick_push ({ issue_info, m_vec_flags });\n-      if (m_vec_flags & VEC_ANY_SVE)\n-\tm_advsimd_ops.quick_push ({ issue_info, VEC_ADVSIMD });\n       if (aarch64_tune_params.vec_costs == &neoverse512tvb_vector_cost)\n \t{\n \t  unsigned int vf_factor = (m_vec_flags & VEC_ANY_SVE) ? 2 : 1;\n@@ -15620,73 +15608,37 @@ aarch64_adjust_stmt_cost (vect_cost_for_stmt kind, stmt_vec_info stmt_info,\n   return stmt_cost;\n }\n \n-/* COUNT, KIND, STMT_INFO and VECTYPE are the same as for\n-   vector_costs::add_stmt_cost and they describe an operation in the\n-   body of a vector loop.  Record issue information relating to the vector\n-   operation in OPS, where OPS is one of m_ops or m_advsimd_ops; see the\n-   comments above those variables for details.\n-\n-   FACTOR says how many iterations of the loop described by VEC_FLAGS would be\n-   needed to match one iteration of the vector loop in VINFO.  */\n+/* COUNT, KIND and STMT_INFO are the same as for vector_costs::add_stmt_cost\n+   and they describe an operation in the body of a vector loop.  Record issue\n+   information relating to the vector operation in OPS.  */\n void\n aarch64_vector_costs::count_ops (unsigned int count, vect_cost_for_stmt kind,\n-\t\t\t\t stmt_vec_info stmt_info, tree vectype,\n-\t\t\t\t aarch64_vec_op_count *ops,\n-\t\t\t\t unsigned int factor)\n+\t\t\t\t stmt_vec_info stmt_info,\n+\t\t\t\t aarch64_vec_op_count *ops)\n {\n   const aarch64_base_vec_issue_info *base_issue = ops->base_issue_info ();\n   if (!base_issue)\n     return;\n   const aarch64_simd_vec_issue_info *simd_issue = ops->simd_issue_info ();\n   const aarch64_sve_vec_issue_info *sve_issue = ops->sve_issue_info ();\n-  unsigned int vec_flags = ops->vec_flags ();\n \n   /* Calculate the minimum cycles per iteration imposed by a reduction\n      operation.  */\n   if ((kind == scalar_stmt || kind == vector_stmt || kind == vec_to_scalar)\n       && vect_is_reduction (stmt_info))\n     {\n       unsigned int base\n-\t= aarch64_in_loop_reduction_latency (m_vinfo, stmt_info, vec_flags);\n-      if (vect_reduc_type (m_vinfo, stmt_info) == FOLD_LEFT_REDUCTION)\n-\t{\n-\t  if (vectype && aarch64_sve_mode_p (TYPE_MODE (vectype)))\n-\t    {\n-\t      /* When costing an SVE FADDA, the vectorizer treats vec_to_scalar\n-\t\t as a single operation, whereas for Advanced SIMD it is a\n-\t\t per-element one.  Increase the factor accordingly, both for\n-\t\t the reduction_latency calculation and for the op couting.  */\n-\t      if (vec_flags & VEC_ADVSIMD)\n-\t\tfactor = vect_nunits_for_cost (vectype);\n-\t    }\n-\t  else\n-\t    /* An Advanced SIMD fold-left reduction is the same as a\n-\t       scalar one and the vectorizer therefore treats vec_to_scalar\n-\t       as a per-element cost.  There is no extra factor to apply for\n-\t       scalar code, either for reduction_latency or for the op\n-\t       counting below.  */\n-\t    factor = 1;\n-\t}\n+\t= aarch64_in_loop_reduction_latency (m_vinfo, stmt_info, m_vec_flags);\n \n-      /* ??? Ideally for vector code we'd do COUNT * FACTOR reductions in\n-\t parallel, but unfortunately that's not yet the case.  */\n-      ops->reduction_latency = MAX (ops->reduction_latency,\n-\t\t\t\t    base * count * factor);\n+      /* ??? Ideally we'd do COUNT reductions in parallel, but unfortunately\n+\t that's not yet the case.  */\n+      ops->reduction_latency = MAX (ops->reduction_latency, base * count);\n     }\n \n   /* Assume that multiply-adds will become a single operation.  */\n-  if (stmt_info && aarch64_multiply_add_p (m_vinfo, stmt_info, vec_flags))\n+  if (stmt_info && aarch64_multiply_add_p (m_vinfo, stmt_info, m_vec_flags))\n     return;\n \n-  /* When costing scalar statements in vector code, the count already\n-     includes the number of scalar elements in the vector, so we don't\n-     need to apply the factor as well.  */\n-  if (kind == scalar_load || kind == scalar_store || kind == scalar_stmt)\n-    factor = 1;\n-\n-  /* This can go negative with the load handling below.  */\n-  int num_copies = count * factor;\n-\n   /* Count the basic operation cost associated with KIND.  */\n   switch (kind)\n     {\n@@ -15702,65 +15654,38 @@ aarch64_vector_costs::count_ops (unsigned int count, vect_cost_for_stmt kind,\n     case vec_construct:\n     case vec_to_scalar:\n     case scalar_to_vec:\n-      /* Assume that these operations have no overhead in the original\n-\t scalar code.  */\n-      if (!vec_flags)\n-\tbreak;\n-      /* Fallthrough.  */\n     case vector_stmt:\n     case scalar_stmt:\n-      ops->general_ops += num_copies;\n+      ops->general_ops += count;\n       break;\n \n     case scalar_load:\n     case vector_load:\n     case unaligned_load:\n-      /* When costing scalars, detect cases in which we are called twice for\n-\t the same load.  This happens for LD[234] operations if only some of\n-\t the results are used.  The first time represents the cost of loading\n-\t the unused vectors, while the second time represents the cost of\n-\t loading the useful parts.  Only the latter should count towards the\n-\t scalar costs.  */\n-      if (stmt_info && !vec_flags)\n-\t{\n-\t  bool existed = false;\n-\t  unsigned int &prev_count\n-\t    = m_seen_loads.get_or_insert (stmt_info, &existed);\n-\t  if (existed)\n-\t    num_copies -= prev_count;\n-\t  else\n-\t    prev_count = num_copies;\n-\t}\n-      ops->loads += num_copies;\n-      if (vec_flags || FLOAT_TYPE_P (aarch64_dr_type (stmt_info)))\n-\tops->general_ops += base_issue->fp_simd_load_general_ops * num_copies;\n+      ops->loads += count;\n+      if (m_vec_flags || FLOAT_TYPE_P (aarch64_dr_type (stmt_info)))\n+\tops->general_ops += base_issue->fp_simd_load_general_ops * count;\n       break;\n \n     case vector_store:\n     case unaligned_store:\n     case scalar_store:\n-      ops->stores += num_copies;\n-      if (vec_flags || FLOAT_TYPE_P (aarch64_dr_type (stmt_info)))\n-\tops->general_ops += base_issue->fp_simd_store_general_ops * num_copies;\n+      ops->stores += count;\n+      if (m_vec_flags || FLOAT_TYPE_P (aarch64_dr_type (stmt_info)))\n+\tops->general_ops += base_issue->fp_simd_store_general_ops * count;\n       break;\n     }\n \n   /* Add any embedded comparison operations.  */\n   if ((kind == scalar_stmt || kind == vector_stmt || kind == vec_to_scalar)\n       && vect_embedded_comparison_type (stmt_info))\n-    ops->general_ops += num_copies;\n+    ops->general_ops += count;\n \n-  /* Detect COND_REDUCTIONs and things that would need to become\n-     COND_REDUCTIONs if they were implemented using Advanced SIMD.\n-     There are then two sets of VEC_COND_EXPRs, whereas so far we\n+  /* COND_REDUCTIONS need two sets of VEC_COND_EXPRs, whereas so far we\n      have only accounted for one.  */\n-  if (vec_flags && (kind == vector_stmt || kind == vec_to_scalar))\n-    {\n-      int reduc_type = vect_reduc_type (m_vinfo, stmt_info);\n-      if ((reduc_type == EXTRACT_LAST_REDUCTION && (vec_flags & VEC_ADVSIMD))\n-\t  || reduc_type == COND_REDUCTION)\n-\tops->general_ops += num_copies;\n-    }\n+  if ((kind == vector_stmt || kind == vec_to_scalar)\n+      && vect_reduc_type (m_vinfo, stmt_info) == COND_REDUCTION)\n+    ops->general_ops += count;\n \n   /* Count the predicate operations needed by an SVE comparison.  */\n   if (sve_issue && (kind == vector_stmt || kind == vec_to_scalar))\n@@ -15769,23 +15694,23 @@ aarch64_vector_costs::count_ops (unsigned int count, vect_cost_for_stmt kind,\n \tunsigned int base = (FLOAT_TYPE_P (type)\n \t\t\t     ? sve_issue->fp_cmp_pred_ops\n \t\t\t     : sve_issue->int_cmp_pred_ops);\n-\tops->pred_ops += base * num_copies;\n+\tops->pred_ops += base * count;\n       }\n \n   /* Add any extra overhead associated with LD[234] and ST[234] operations.  */\n   if (simd_issue)\n     switch (aarch64_ld234_st234_vectors (kind, stmt_info))\n       {\n       case 2:\n-\tops->general_ops += simd_issue->ld2_st2_general_ops * num_copies;\n+\tops->general_ops += simd_issue->ld2_st2_general_ops * count;\n \tbreak;\n \n       case 3:\n-\tops->general_ops += simd_issue->ld3_st3_general_ops * num_copies;\n+\tops->general_ops += simd_issue->ld3_st3_general_ops * count;\n \tbreak;\n \n       case 4:\n-\tops->general_ops += simd_issue->ld4_st4_general_ops * num_copies;\n+\tops->general_ops += simd_issue->ld4_st4_general_ops * count;\n \tbreak;\n       }\n \n@@ -15861,15 +15786,8 @@ aarch64_vector_costs::add_stmt_cost (int count, vect_cost_for_stmt kind,\n \t  && (m_costing_for_scalar || where == vect_body)\n \t  && (!LOOP_VINFO_LOOP (loop_vinfo)->inner || in_inner_loop_p)\n \t  && stmt_cost != 0)\n-\t{\n-\t  for (auto &ops : m_ops)\n-\t    count_ops (count, kind, stmt_info, vectype, &ops, 1);\n-\t  for (auto &ops : m_advsimd_ops)\n-\t    /* Record estimates for a possible Advanced SIMD version\n-\t       of the SVE code.  */\n-\t    count_ops (count, kind, stmt_info, vectype, &ops,\n-\t\t       aarch64_estimated_sve_vq ());\n-\t}\n+\tfor (auto &ops : m_ops)\n+\t  count_ops (count, kind, stmt_info, &ops);\n \n       /* If we're applying the SVE vs. Advanced SIMD unrolling heuristic,\n \t estimate the number of statements in the unrolled Advanced SIMD"}]}