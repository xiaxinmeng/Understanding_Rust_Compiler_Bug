{"sha": "9cf32741aabefe8fa90bad887b694dbf7ad29726", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OWNmMzI3NDFhYWJlZmU4ZmE5MGJhZDg4N2I2OTRkYmY3YWQyOTcyNg==", "commit": {"author": {"name": "Jakub Jelinek", "email": "jakub@redhat.com", "date": "2014-06-12T21:10:11Z"}, "committer": {"name": "Jakub Jelinek", "email": "jakub@gcc.gnu.org", "date": "2014-06-12T21:10:11Z"}, "message": "re PR middle-end/61486 (ICE with #pragma omp teams)\n\n\tPR middle-end/61486\n\t* gimplify.c (struct gimplify_omp_ctx): Add distribute field.\n\t(gimplify_adjust_omp_clauses): Don't or in GOVD_LASTPRIVATE\n\tif outer combined construct is distribute.\n\t(gimplify_omp_for): For OMP_DISTRIBUTE set\n\tgimplify_omp_ctxp->distribute.\n\t* omp-low.c (scan_sharing_clauses) <case OMP_CLAUSE_SHARED>: For\n\tGIMPLE_OMP_TEAMS, if decl isn't global in outer context, record\n\tmapping into decl map.\nc-family/\n\t* c-omp.c (c_omp_split_clauses): Don't crash on firstprivate in\n\t#pragma omp target teams or\n\t#pragma omp {,target }teams distribute simd.\ntestsuite/\n\t* c-c++-common/gomp/pr61486-1.c: New test.\n\t* c-c++-common/gomp/pr61486-2.c: New test.\n\nFrom-SVN: r211596", "tree": {"sha": "c4172ecef31a5a6826c56350eb72c44c9d78516b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/c4172ecef31a5a6826c56350eb72c44c9d78516b"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/9cf32741aabefe8fa90bad887b694dbf7ad29726", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9cf32741aabefe8fa90bad887b694dbf7ad29726", "html_url": "https://github.com/Rust-GCC/gccrs/commit/9cf32741aabefe8fa90bad887b694dbf7ad29726", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9cf32741aabefe8fa90bad887b694dbf7ad29726/comments", "author": {"login": "jakubjelinek", "id": 9370665, "node_id": "MDQ6VXNlcjkzNzA2NjU=", "avatar_url": "https://avatars.githubusercontent.com/u/9370665?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jakubjelinek", "html_url": "https://github.com/jakubjelinek", "followers_url": "https://api.github.com/users/jakubjelinek/followers", "following_url": "https://api.github.com/users/jakubjelinek/following{/other_user}", "gists_url": "https://api.github.com/users/jakubjelinek/gists{/gist_id}", "starred_url": "https://api.github.com/users/jakubjelinek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jakubjelinek/subscriptions", "organizations_url": "https://api.github.com/users/jakubjelinek/orgs", "repos_url": "https://api.github.com/users/jakubjelinek/repos", "events_url": "https://api.github.com/users/jakubjelinek/events{/privacy}", "received_events_url": "https://api.github.com/users/jakubjelinek/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "62984918665f0c82b187293ba762bc2edb32ab92", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/62984918665f0c82b187293ba762bc2edb32ab92", "html_url": "https://github.com/Rust-GCC/gccrs/commit/62984918665f0c82b187293ba762bc2edb32ab92"}], "stats": {"total": 526, "additions": 521, "deletions": 5}, "files": [{"sha": "6e8da453ff5e40dd83375eee277c1c1055033a3a", "filename": "gcc/ChangeLog", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=9cf32741aabefe8fa90bad887b694dbf7ad29726", "patch": "@@ -1,3 +1,15 @@\n+2014-06-12  Jakub Jelinek  <jakub@redhat.com>\n+\n+\tPR middle-end/61486\n+\t* gimplify.c (struct gimplify_omp_ctx): Add distribute field.\n+\t(gimplify_adjust_omp_clauses): Don't or in GOVD_LASTPRIVATE\n+\tif outer combined construct is distribute.\n+\t(gimplify_omp_for): For OMP_DISTRIBUTE set\n+\tgimplify_omp_ctxp->distribute.\n+\t* omp-low.c (scan_sharing_clauses) <case OMP_CLAUSE_SHARED>: For\n+\tGIMPLE_OMP_TEAMS, if decl isn't global in outer context, record\n+\tmapping into decl map.\n+\n 2014-06-12  Jason Merrill  <jason@redhat.com>\n \n \t* common.opt (fabi-version): Change default to 0."}, {"sha": "0348310f0947bdfcb6d64a1902b3e77ac8f99ab9", "filename": "gcc/c-family/ChangeLog", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2Fc-family%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2Fc-family%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-family%2FChangeLog?ref=9cf32741aabefe8fa90bad887b694dbf7ad29726", "patch": "@@ -1,3 +1,10 @@\n+2014-06-12  Jakub Jelinek  <jakub@redhat.com>\n+\n+\tPR middle-end/61486\n+\t* c-omp.c (c_omp_split_clauses): Don't crash on firstprivate in\n+\t#pragma omp target teams or\n+\t#pragma omp {,target }teams distribute simd.\n+\n 2014-06-12  Jason Merrill  <jason@redhat.com>\n \n \t* c.opt (Wabi=, fabi-compat-version): New."}, {"sha": "6a0e41988a714a7680fe00304cf5469b70d2ad8d", "filename": "gcc/c-family/c-omp.c", "status": "modified", "additions": 7, "deletions": 2, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2Fc-family%2Fc-omp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2Fc-family%2Fc-omp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-family%2Fc-omp.c?ref=9cf32741aabefe8fa90bad887b694dbf7ad29726", "patch": "@@ -789,8 +789,13 @@ c_omp_split_clauses (location_t loc, enum tree_code code,\n \t  else if ((mask & (OMP_CLAUSE_MASK_1 << PRAGMA_OMP_CLAUSE_NUM_TEAMS))\n \t\t   != 0)\n \t    {\n-\t      /* This must be #pragma omp {,target }teams distribute.  */\n-\t      gcc_assert (code == OMP_DISTRIBUTE);\n+\t      /* This must be one of\n+\t\t #pragma omp {,target }teams distribute\n+\t\t #pragma omp target teams\n+\t\t #pragma omp {,target }teams distribute simd.  */\n+\t      gcc_assert (code == OMP_DISTRIBUTE\n+\t\t\t  || code == OMP_TEAMS\n+\t\t\t  || code == OMP_SIMD);\n \t      s = C_OMP_CLAUSE_SPLIT_TEAMS;\n \t    }\n \t  else if ((mask & (OMP_CLAUSE_MASK_1"}, {"sha": "10f8ac6d0e0b7afa756c2d517a48e6f3f88cc0bc", "filename": "gcc/gimplify.c", "status": "modified", "additions": 8, "deletions": 1, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2Fgimplify.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2Fgimplify.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgimplify.c?ref=9cf32741aabefe8fa90bad887b694dbf7ad29726", "patch": "@@ -139,6 +139,7 @@ struct gimplify_omp_ctx\n   enum omp_clause_default_kind default_kind;\n   enum omp_region_type region_type;\n   bool combined_loop;\n+  bool distribute;\n };\n \n static struct gimplify_ctx *gimplify_ctxp;\n@@ -6359,7 +6360,11 @@ gimplify_adjust_omp_clauses (tree *list_p)\n \t\t      if (n == NULL\n \t\t\t  || (n->value & GOVD_DATA_SHARE_CLASS) == 0)\n \t\t\t{\n-\t\t\t  int flags = GOVD_FIRSTPRIVATE | GOVD_LASTPRIVATE;\n+\t\t\t  int flags = GOVD_FIRSTPRIVATE;\n+\t\t\t  /* #pragma omp distribute does not allow\n+\t\t\t     lastprivate clause.  */\n+\t\t\t  if (!ctx->outer_context->distribute)\n+\t\t\t    flags |= GOVD_LASTPRIVATE;\n \t\t\t  if (n == NULL)\n \t\t\t    omp_add_variable (ctx->outer_context, decl,\n \t\t\t\t\t      flags | GOVD_SEEN);\n@@ -6640,6 +6645,8 @@ gimplify_omp_for (tree *expr_p, gimple_seq *pre_p)\n \t  || TREE_CODE (for_stmt) == CILK_SIMD);\n   gimplify_scan_omp_clauses (&OMP_FOR_CLAUSES (for_stmt), pre_p,\n \t\t\t     simd ? ORT_SIMD : ORT_WORKSHARE);\n+  if (TREE_CODE (for_stmt) == OMP_DISTRIBUTE)\n+    gimplify_omp_ctxp->distribute = true;\n \n   /* Handle OMP_FOR_INIT.  */\n   for_pre_body = NULL;"}, {"sha": "67254cc5bdf4c9cb9c18597118b0463b23951829", "filename": "gcc/omp-low.c", "status": "modified", "additions": 10, "deletions": 2, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2Fomp-low.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2Fomp-low.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fomp-low.c?ref=9cf32741aabefe8fa90bad887b694dbf7ad29726", "patch": "@@ -1509,11 +1509,19 @@ scan_sharing_clauses (tree clauses, omp_context *ctx)\n \t  break;\n \n \tcase OMP_CLAUSE_SHARED:\n+\t  decl = OMP_CLAUSE_DECL (c);\n \t  /* Ignore shared directives in teams construct.  */\n \t  if (gimple_code (ctx->stmt) == GIMPLE_OMP_TEAMS)\n-\t    break;\n+\t    {\n+\t      /* Global variables don't need to be copied,\n+\t\t the receiver side will use them directly.  */\n+\t      tree odecl = maybe_lookup_decl_in_outer_ctx (decl, ctx);\n+\t      if (is_global_var (odecl))\n+\t\tbreak;\n+\t      insert_decl_map (&ctx->cb, decl, odecl);\n+\t      break;\n+\t    }\n \t  gcc_assert (is_taskreg_ctx (ctx));\n-\t  decl = OMP_CLAUSE_DECL (c);\n \t  gcc_assert (!COMPLETE_TYPE_P (TREE_TYPE (decl))\n \t\t      || !is_variable_sized (decl));\n \t  /* Global variables don't need to be copied,"}, {"sha": "497b979b1f5504dbb6397178eb7e4fe6e8cd8d8e", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=9cf32741aabefe8fa90bad887b694dbf7ad29726", "patch": "@@ -1,3 +1,9 @@\n+2014-06-12  Jakub Jelinek  <jakub@redhat.com>\n+\n+\tPR middle-end/61486\n+\t* c-c++-common/gomp/pr61486-1.c: New test.\n+\t* c-c++-common/gomp/pr61486-2.c: New test.\n+\n 2014-06-10  Alan Lawrence  <alan.lawrence@arm.com>\n \n \tPR target/59843"}, {"sha": "9ada58c8ccfd157a10438dd740b215ba4179cd1e", "filename": "gcc/testsuite/c-c++-common/gomp/pr61486-1.c", "status": "added", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Fpr61486-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Fpr61486-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Fpr61486-1.c?ref=9cf32741aabefe8fa90bad887b694dbf7ad29726", "patch": "@@ -0,0 +1,13 @@\n+/* PR middle-end/61486 */\n+/* { dg-do compile } */\n+/* { dg-options \"-fopenmp\" } */\n+\n+int\n+foo (int *a)\n+{\n+  int i, j = 0;\n+  #pragma omp target teams distribute simd linear(i, j) map(a[:10])\n+  for (i = 0; i < 10; i++)\n+    a[i] = j++;\n+  return i + j;\n+}"}, {"sha": "729438101e2f00481330c21950c890bb7dcb55e0", "filename": "gcc/testsuite/c-c++-common/gomp/pr61486-2.c", "status": "added", "additions": 458, "deletions": 0, "changes": 458, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Fpr61486-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/9cf32741aabefe8fa90bad887b694dbf7ad29726/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Fpr61486-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fc-c%2B%2B-common%2Fgomp%2Fpr61486-2.c?ref=9cf32741aabefe8fa90bad887b694dbf7ad29726", "patch": "@@ -0,0 +1,458 @@\n+/* PR middle-end/61486 */\n+/* { dg-do compile } */\n+/* { dg-options \"-fopenmp\" } */\n+\n+#pragma omp declare target\n+void dosomething (int *a, int n, int m);\n+#pragma omp end declare target\n+\n+void\n+test (int n, int o, int p, int q, int r, int s, int *pp)\n+{\n+  int a[o], i, j;\n+  #pragma omp target data device (n + 1) if (n != 6) map (tofrom: n, r)\n+  {\n+    #pragma omp target device (n + 1) if (n != 6) map (from: n) map (alloc: a[2:o-2])\n+      dosomething (a, n, 0);\n+    #pragma omp target teams device (n + 1) num_teams (n + 4) thread_limit (n * 2) \\\n+    \tif (n != 6)map (from: n) map (alloc: a[2:o-2]) default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r)\n+    {\n+      r = r + 1;\n+      p = q;\n+      dosomething (a, n, p + q);\n+    }\n+    #pragma omp target teams distribute device (n + 1) num_teams (n + 4) collapse (2) \\\n+    \tif (n != 6)map (from: n) map (alloc: a[2:o-2]) default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    dosomething (a, n, p + q);\n+\t  }\n+    #pragma omp target teams distribute device (n + 1) num_teams (n + 4) \\\n+    \tif (n != 6)map (from: n) map (alloc: a[2:o-2]) default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    dosomething (a, n, p + q);\n+\t  }\n+    #pragma omp target teams distribute parallel for device (n + 1) num_teams (n + 4) \\\n+    \tif (n != 6)map (from: n) map (alloc: a[2:o-2]) default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4) collapse (2) \\\n+    \tnum_threads (n + 4) proc_bind (spread) lastprivate (s) \\\n+    \tordered schedule (static, 8)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    dosomething (a, n, p + q);\n+\t    #pragma omp ordered\n+\t      p = q;\n+\t    s = i * 10 + j;\n+\t  }\n+    #pragma omp target teams distribute parallel for device (n + 1) num_teams (n + 4) \\\n+    \tif (n != 6)map (from: n) map (alloc: a[2:o-2]) default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4) num_threads (n + 4) \\\n+    \tproc_bind (master) lastprivate (s) ordered schedule (static, 8)\n+      for (i = 0; i < 10; i++)\n+\t{\n+\t  for (j = 0; j < 10; j++)\n+\t    {\n+\t      r = r + 1;\n+\t      p = q;\n+\t      dosomething (a, n, p + q);\n+\t    }\n+\t  #pragma omp ordered\n+\t    p = q;\n+\t  s = i * 10;\n+\t}\n+    #pragma omp target teams distribute parallel for simd device (n + 1) \\\n+    \tif (n != 6)map (from: n) map (alloc: a[2:o-2]) default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4) collapse (2) \\\n+    \tnum_threads (n + 4) proc_bind (spread) lastprivate (s) \\\n+    \tschedule (static, 8) num_teams (n + 4) safelen(8)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    a[2+i*10+j] = p + q;\n+\t    s = i * 10 + j;\n+\t  }\n+    #pragma omp target teams distribute parallel for simd device (n + 1) \\\n+    \tif (n != 6)map (from: n) map (alloc: a[2:o-2]) default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4) num_threads (n + 4) \\\n+    \tproc_bind (master) lastprivate (s) schedule (static, 8) \\\n+    \tnum_teams (n + 4) safelen(16) linear(i:1) aligned (pp:4)\n+      for (i = 0; i < 10; i++)\n+\t{\n+\t  r = r + 1;\n+\t  p = q;\n+\t  a[2+i] = p + q;\n+\t  s = i * 10;\n+\t}\n+    #pragma omp target teams distribute simd device (n + 1) \\\n+    \tif (n != 6)map (from: n) map (alloc: a[2:o-2]) default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4) collapse (2) \\\n+    \tlastprivate (s) num_teams (n + 4) safelen(8)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    a[2+i*10+j] = p + q;\n+\t    s = i * 10 + j;\n+\t  }\n+    #pragma omp target teams distribute simd device (n + 1) \\\n+    \tif (n != 6)map (from: n) map (alloc: a[2:o-2]) default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4) lastprivate (s) \\\n+    \tnum_teams (n + 4) safelen(16) linear(i:1) aligned (pp:4)\n+      for (i = 0; i < 10; i++)\n+\t{\n+\t  r = r + 1;\n+\t  p = q;\n+\t  a[2+i] = p + q;\n+\t  s = i * 10;\n+\t}\n+    #pragma omp target device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2])\n+    #pragma omp teams num_teams (n + 4) thread_limit (n * 2) default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r)\n+    {\n+      r = r + 1;\n+      p = q;\n+      dosomething (a, n, p + q);\n+    }\n+    #pragma omp target device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2])\n+    #pragma omp teams distribute num_teams (n + 4) collapse (2) default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    dosomething (a, n, p + q);\n+\t  }\n+    #pragma omp target device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2])\n+    #pragma omp teams distribute num_teams (n + 4) default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    dosomething (a, n, p + q);\n+\t  }\n+    #pragma omp target device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2])\n+    #pragma omp teams distribute parallel for num_teams (n + 4) if (n != 6) \\\n+\tdefault(shared) private (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4) collapse (2) \\\n+    \tnum_threads (n + 4) proc_bind (spread) lastprivate (s) \\\n+    \tordered schedule (static, 8)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    dosomething (a, n, p + q);\n+\t    #pragma omp ordered\n+\t      p = q;\n+\t    s = i * 10 + j;\n+\t  }\n+    #pragma omp target device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2])\n+    #pragma omp teams distribute parallel for num_teams (n + 4) if (n != 6) \\\n+\tdefault(shared) private (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4) num_threads (n + 4) \\\n+    \tproc_bind (master) lastprivate (s) ordered schedule (static, 8)\n+      for (i = 0; i < 10; i++)\n+\t{\n+\t  for (j = 0; j < 10; j++)\n+\t    {\n+\t      r = r + 1;\n+\t      p = q;\n+\t      dosomething (a, n, p + q);\n+\t    }\n+\t  #pragma omp ordered\n+\t    p = q;\n+\t  s = i * 10;\n+\t}\n+    #pragma omp target device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2])\n+    #pragma omp teams distribute parallel for simd if (n != 6)default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4) collapse (2) \\\n+    \tnum_threads (n + 4) proc_bind (spread) lastprivate (s) \\\n+    \tschedule (static, 8) num_teams (n + 4) safelen(8)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    a[2+i*10+j] = p + q;\n+\t    s = i * 10 + j;\n+\t  }\n+    #pragma omp target device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2])\n+    #pragma omp teams distribute parallel for simd if (n != 6)default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4) num_threads (n + 4) \\\n+    \tproc_bind (master) lastprivate (s) schedule (static, 8) \\\n+    \tnum_teams (n + 4) safelen(16) linear(i:1) aligned (pp:4)\n+      for (i = 0; i < 10; i++)\n+\t{\n+\t  r = r + 1;\n+\t  p = q;\n+\t  a[2+i] = p + q;\n+\t  s = i * 10;\n+\t}\n+    #pragma omp target device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2])\n+    #pragma omp teams distribute simd default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4) collapse (2) \\\n+    \tlastprivate (s) num_teams (n + 4) safelen(8)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    a[2+i*10+j] = p + q;\n+\t    s = i * 10 + j;\n+\t  }\n+    #pragma omp target device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2])\n+    #pragma omp teams distribute simd default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tthread_limit (n * 2) dist_schedule (static, 4) lastprivate (s) \\\n+    \tnum_teams (n + 4) safelen(16) linear(i:1) aligned (pp:4)\n+      for (i = 0; i < 10; i++)\n+\t{\n+\t  r = r + 1;\n+\t  p = q;\n+\t  a[2+i] = p + q;\n+\t  s = i * 10;\n+\t}\n+    #pragma omp target teams device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2]) \\\n+\tnum_teams (n + 4) thread_limit (n * 2)default(shared) shared(n) \\\n+\tprivate (p) reduction (+: r)\n+    #pragma omp distribute collapse (2) dist_schedule (static, 4) firstprivate (q)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    dosomething (a, n, p + q);\n+\t  }\n+    #pragma omp target teams device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2]) \\\n+\tnum_teams (n + 4) thread_limit (n * 2) shared(n) private(p) reduction (+ : r) \\\n+\tdefault(shared)\n+    #pragma omp distribute dist_schedule (static, 4) firstprivate (q)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    dosomething (a, n, p + q);\n+\t  }\n+    #pragma omp target teams device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2]) \\\n+\tnum_teams (n + 4) thread_limit (n * 2)\n+    #pragma omp distribute parallel for if (n != 6) \\\n+\tdefault(shared) private (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tcollapse (2) dist_schedule (static, 4) \\\n+    \tnum_threads (n + 4) proc_bind (spread) lastprivate (s) \\\n+    \tordered schedule (static, 8)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    dosomething (a, n, p + q);\n+\t    #pragma omp ordered\n+\t      p = q;\n+\t    s = i * 10 + j;\n+\t  }\n+    #pragma omp target teams device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2]) \\\n+\tnum_teams (n + 4) thread_limit (n * 2)\n+    #pragma omp distribute parallel for if (n != 6) \\\n+\tdefault(shared) private (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tnum_threads (n + 4) dist_schedule (static, 4) \\\n+    \tproc_bind (master) lastprivate (s) ordered schedule (static, 8)\n+      for (i = 0; i < 10; i++)\n+\t{\n+\t  for (j = 0; j < 10; j++)\n+\t    {\n+\t      r = r + 1;\n+\t      p = q;\n+\t      dosomething (a, n, p + q);\n+\t    }\n+\t  #pragma omp ordered\n+\t    p = q;\n+\t  s = i * 10;\n+\t}\n+    #pragma omp target teams device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2]) \\\n+\tnum_teams (n + 4) thread_limit (n * 2)\n+    #pragma omp distribute parallel for simd if (n != 6)default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tcollapse (2) dist_schedule (static, 4) \\\n+    \tnum_threads (n + 4) proc_bind (spread) lastprivate (s) \\\n+    \tschedule (static, 8) safelen(8)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    a[2+i*10+j] = p + q;\n+\t    s = i * 10 + j;\n+\t  }\n+    #pragma omp target teams device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2]) \\\n+\tnum_teams (n + 4) thread_limit (n * 2)\n+    #pragma omp distribute parallel for simd if (n != 6)default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tnum_threads (n + 4) dist_schedule (static, 4) \\\n+    \tproc_bind (master) lastprivate (s) schedule (static, 8) \\\n+    \tsafelen(16) linear(i:1) aligned (pp:4)\n+      for (i = 0; i < 10; i++)\n+\t{\n+\t  r = r + 1;\n+\t  p = q;\n+\t  a[2+i] = p + q;\n+\t  s = i * 10;\n+\t}\n+    #pragma omp target teams device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2]) \\\n+\tnum_teams (n + 4) thread_limit (n * 2) default(shared) shared(n) private(p) \\\n+\treduction(+:r)\n+    #pragma omp distribute simd private (p) firstprivate (q) reduction (+: r) \\\n+    \tcollapse (2) dist_schedule (static, 4) lastprivate (s) safelen(8)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    a[2+i*10+j] = p + q;\n+\t    s = i * 10 + j;\n+\t  }\n+    #pragma omp target teams device (n + 1) if (n != 6)map(from:n) map(alloc:a[2:o-2]) \\\n+\tnum_teams (n + 4) thread_limit (n * 2) default(shared) shared(n) private(p) \\\n+\treduction(+:r)\n+    #pragma omp distribute simd private (p) firstprivate (q) reduction (+: r) \\\n+    \tlastprivate (s) dist_schedule (static, 4) safelen(16) linear(i:1) aligned (pp:4)\n+      for (i = 0; i < 10; i++)\n+\t{\n+\t  r = r + 1;\n+\t  p = q;\n+\t  a[2+i] = p + q;\n+\t  s = i * 10;\n+\t}\n+  }\n+}\n+\n+int q, i, j;\n+\n+void\n+test2 (int n, int o, int p, int r, int s, int *pp)\n+{\n+  int a[o];\n+    #pragma omp distribute collapse (2) dist_schedule (static, 4) firstprivate (q)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    dosomething (a, n, p + q);\n+\t  }\n+    #pragma omp distribute dist_schedule (static, 4) firstprivate (q)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    dosomething (a, n, p + q);\n+\t  }\n+    #pragma omp distribute parallel for if (n != 6) \\\n+\tdefault(shared) private (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tcollapse (2) dist_schedule (static, 4) \\\n+    \tnum_threads (n + 4) proc_bind (spread) lastprivate (s) \\\n+    \tordered schedule (static, 8)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    dosomething (a, n, p + q);\n+\t    #pragma omp ordered\n+\t      p = q;\n+\t    s = i * 10 + j;\n+\t  }\n+    #pragma omp distribute parallel for if (n != 6) \\\n+\tdefault(shared) private (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tnum_threads (n + 4) dist_schedule (static, 4) \\\n+    \tproc_bind (master) lastprivate (s) ordered schedule (static, 8)\n+      for (i = 0; i < 10; i++)\n+\t{\n+\t  for (j = 0; j < 10; j++)\n+\t    {\n+\t      r = r + 1;\n+\t      p = q;\n+\t      dosomething (a, n, p + q);\n+\t    }\n+\t  #pragma omp ordered\n+\t    p = q;\n+\t  s = i * 10;\n+\t}\n+    #pragma omp distribute parallel for simd if (n != 6)default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tcollapse (2) dist_schedule (static, 4) \\\n+    \tnum_threads (n + 4) proc_bind (spread) lastprivate (s) \\\n+    \tschedule (static, 8) safelen(8)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    a[2+i*10+j] = p + q;\n+\t    s = i * 10 + j;\n+\t  }\n+    #pragma omp distribute parallel for simd if (n != 6)default(shared) \\\n+    \tprivate (p) firstprivate (q) shared (n) reduction (+: r) \\\n+    \tnum_threads (n + 4) dist_schedule (static, 4) \\\n+    \tproc_bind (master) lastprivate (s) schedule (static, 8) \\\n+    \tsafelen(16) linear(i:1) aligned (pp:4)\n+      for (i = 0; i < 10; i++)\n+\t{\n+\t  r = r + 1;\n+\t  p = q;\n+\t  a[2+i] = p + q;\n+\t  s = i * 10;\n+\t}\n+    #pragma omp distribute simd private (p) firstprivate (q) reduction (+: r) \\\n+    \tcollapse (2) dist_schedule (static, 4) lastprivate (s) safelen(8)\n+      for (i = 0; i < 10; i++)\n+\tfor (j = 0; j < 10; j++)\n+\t  {\n+\t    r = r + 1;\n+\t    p = q;\n+\t    a[2+i*10+j] = p + q;\n+\t    s = i * 10 + j;\n+\t  }\n+    #pragma omp distribute simd private (p) firstprivate (q) reduction (+: r) \\\n+    \tlastprivate (s) dist_schedule (static, 4) safelen(16) linear(i:1) aligned (pp:4)\n+      for (i = 0; i < 10; i++)\n+\t{\n+\t  r = r + 1;\n+\t  p = q;\n+\t  a[2+i] = p + q;\n+\t  s = i * 10;\n+\t}\n+}"}]}