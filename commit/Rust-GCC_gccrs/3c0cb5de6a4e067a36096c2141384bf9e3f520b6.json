{"sha": "3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6M2MwY2I1ZGU2YTRlMDY3YTM2MDk2YzIxNDEzODRiZjllM2Y1MjBiNg==", "commit": {"author": {"name": "Jerry Quinn", "email": "jlquinn@optonline.net", "date": "2004-07-01T12:52:53Z"}, "committer": {"name": "Jerry Quinn", "email": "jlquinn@gcc.gnu.org", "date": "2004-07-01T12:52:53Z"}, "message": "alias.c (get_alias_set, [...]): Use MEM_P.\n\n2004-07-01  Jerry Quinn  <jlquinn@optonline.net>\n\n\t* alias.c (get_alias_set, canon_rtx, get_addr,\n\tnonoverlapping_memrefs_p, nonlocal_referenced_p_1, memory_modified_1):\n\tUse MEM_P.\n\t* builtins.c (expand_builtin_prefetch, expand_builtin_profile_func,\n\texpand_builtin): Likewise.\n\t* calls.c (expand_call, emit_library_call_value_1, store_one_arg):\n\tLikewise.\n\t* combine.c (can_combine_p, combinable_i3pat, try_combine,\n\tfind_split_point, combine_simplify_rtx, simplify_set, make_extraction,\n\trtx_equal_for_field_assignment_p, gen_lowpart_for_combine,\n\trecord_dead_and_set_regs_1, get_last_value_validate,\n\tmark_used_regs_combine, move_deaths, unmentioned_reg_p_1): Likewise.\n\t* cse.c (check_dependence, canon_hash, equiv_constant,\n\tgen_lowpart_if_possible, cse_insn, invalidate_from_clobbers,\n\tcse_around_loop, cse_check_loop_start, cse_set_around_loop,\n\tcount_reg_usage): Likewise.\n\t* cselib.c (rtx_equal_for_cselib_p, add_mem_for_addr, cselib_lookup,\n\tcselib_invalidate_mem, cselib_invalidate_rtx, cselib_record_set,\n\tcselib_record_sets): Likewise.\n\t* dbxout.c (PARM_PASSED_IN_MEMORY, dbxout_symbol,\n\tdbxout_symbol_location, dbxout_parms, dbxout_reg_parms): Likewise.\n\t* ddg.c (mark_mem_use, mark_mem_store, rtx_mem_access_p): Likewise.\n\t* df.c (df_uses_record): Likewise.\n\t* dojump (do_jump): Likewise.\n\t* dwarf2out.c (stack_adjust_offset, mem_loc_descriptor,\n\tloc_descriptor_from_tree, rtl_for_decl_location, add_bound_info,\n\tdecl_start_label): Likewise.\n\t* emit-rtl.c (gen_complex_constant_part, gen_highpart,\n\toperand_subword, change_address_1, make_safe_from): Likewise.\n\t* explow.c (break_out_memory_refs, copy_all_regs, validize_mem,\n\tstabilize, force_not_mem): Likewise.\n\t* expmed.c (store_bit_field, store_split_bit_field, extract_bit_field,\n\texpand_mult_const, expand_divmod, emit_store_flag): Likewise.\n\t* expr.c (convert_move, convert_modes, emit_block_move,\n\temit_group_load, emit_group_store, clear_storage, emit_move_insn,\n\temit_move_insn_1, expand_assignment, store_expr,\n\tstore_constructor_field, store_constructor, store_field,\n\tforce_operand, safe_from_p, expand_expr_real_1, expand_increment):\n\tLikewise.\n\t* final.c (cleanup_subreg_operands, alter_subreg,\n\tget_mem_expr_from_op): Likewise.\n\t* flow.c (notice_stack_pointer_modification_1,\n\tinit_propagate_block_info, insn_dead_p, mark_set_1, mark_used_regs):\n\tLikewise.\n\t* function.c (mark_temp_addr_taken, preserve_temp_slots,\n\tpreserve_rtl_expr_result, put_var_into_stack, fixup_var_refs_1,\n\toptimize_bit_field, flush_addressof, purge_addressof_1,\n\tinstantiate_decl, instantiate_virtual_regs_1, assign_parms,\n\tsetjmp_protect, setjmp_protect_args, fix_lexical_addr,\n\tkeep_stack_depressed): Likewise.\n\t* ifcvt.c (noce_try_cmove_arith, noce_try_abs, noce_operand_ok,\n\tnoce_process_if_block, find_memory): Likewise.\n\t* integrate.c (subst_constants, allocate_initial_values): Likewise.\n\t* local-alloc.c (validate_equiv_mem_from_store, memref_referenced_p,\n\tupdate_equiv_regs): Likewise.\n\t* loop.c (scan_loop, prescan_loop, note_addr_stored, check_store,\n\tmaybe_eliminate_biv_1, find_mem_in_note_1): Likewise.\n\t* optabs.c (expand_abs, emit_unop_insn): Likewise.\n\t* passes.c (rest_of_handle_final): Likewise.\n\t* postreload.c (reload_cse_simplify_set, reload_cse_simplify_operands,\n\tmove2add_note_store): Likewise.\n\t* ra-build.c (detect_remat_webs): Likewise.\n\t* ra-debug.c (dump_static_insn_cost): Likewise.\n\t* ra-rewrite.c (slots_overlap_p, insert_stores): Likewise.\n\t* recog.c (validate_change, apply_change_group, cancel_changes,\n\tvalidate_replace_rtx_1, general_operand, register_operand,\n\tnonmemory_operand, push_operand, pop_operand, memory_operand,\n\tindirect_operand, asm_operand_ok, offsettable_memref_p,\n\toffsettable_nonstrict_memref_p, constrain_operands,\n\tstore_data_bypass_p): Likewise.\n\t* reg-stack.c (subst_stack_regs_pat): Likewise.\n\t* regclass.c (record_operand_costs, scan_one_insn, record_reg_classes,\n\tcopy_cost, reg_scan_mark_refs): Likewise.\n\t* regmove.c (optimize_reg_copy_3, stack_memref_p,\n\tcombine_stack_adjustments_for_block): Likewise.\n\t* regrename.c (copyprop_hardreg_forward_1): Likewise.\n\t* reload.c (can_reload_into, push_reload, decompose, immune_p,\n\tfind_reloads, find_reloads_address, find_reloads_address_1,\n\treg_overlap_mentioned_for_reload_p, refers_to_mem_for_reload_p,\n\tfind_equiv_reg): Likewise.\n\t* reload1.c (reload, eliminate_regs, eliminate_regs_in_insn,\n\treload_as_needed, choose_reload_regs, emit_input_reload_insns,\n\tdo_input_reload, emit_reload_insns, gen_reload, delete_output_reload,\n\tdelete_address_reloads): Likewise.\n\t* resource.c (mark_referenced_resources): Likewise.\n\t* rtlanal.c (get_jump_table_offset, count_occurrences,\n\treg_referenced_p, reg_set_p, set_of_1, set_noop_p,\n\treg_overlap_mentioned_p, note_uses, replace_regs, nonzero_bits1,\n\tnum_sign_bit_copies1): Likewise.\n\t* rtlhooks.c (gen_lowpart_general): Likewise.\n\t* sched-deps.c (sched_analyze_1, sched_analyze_2): Likewise.\n\t* sdbout.c (PARM_PASSED_IN_MEMORY, sdbout_symbol,\n\tsdbout_toplevel_data, sdbout_parms, sdbout_reg_parms,\n\tsdbout_global_decl): Likewise.\n\t* simplify-rtx.c (simplify_subreg): Likewise.\n\t* stmt.c (expand_asm_operands, expand_expr_stmt_value, expand_decl,\n\texpand_anon_union_decl, expand_end_case_type): Likewise.\n\t* unroll.c (calculate_giv_inc): Likewise.\n\t* var-tracking.c (stack_adjust_offset_pre_post,\n\tbb_stack_adjust_offset, track_expr_p, count_uses, add_uses,\n\tadd_stores, compute_bb_dataflow, vt_get_decl_and_offset,\n\tvt_add_function_parameters): Likewise.\n\t* varasm.c (make_var_volatile, notice_global_symbol,\n\tassemble_external, decode_addr_const, mark_weak,\n\tdefault_encode_section_info): Likewise.\n\nFrom-SVN: r83980", "tree": {"sha": "f48d60264473680791f8223b21f0c82f2666fcba", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/f48d60264473680791f8223b21f0c82f2666fcba"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/comments", "author": {"login": "jlquinn", "id": 826841, "node_id": "MDQ6VXNlcjgyNjg0MQ==", "avatar_url": "https://avatars.githubusercontent.com/u/826841?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jlquinn", "html_url": "https://github.com/jlquinn", "followers_url": "https://api.github.com/users/jlquinn/followers", "following_url": "https://api.github.com/users/jlquinn/following{/other_user}", "gists_url": "https://api.github.com/users/jlquinn/gists{/gist_id}", "starred_url": "https://api.github.com/users/jlquinn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jlquinn/subscriptions", "organizations_url": "https://api.github.com/users/jlquinn/orgs", "repos_url": "https://api.github.com/users/jlquinn/repos", "events_url": "https://api.github.com/users/jlquinn/events{/privacy}", "received_events_url": "https://api.github.com/users/jlquinn/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "8436e65ac6e638dd045098516f37d4f2c685a3e1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8436e65ac6e638dd045098516f37d4f2c685a3e1", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8436e65ac6e638dd045098516f37d4f2c685a3e1"}], "stats": {"total": 1026, "additions": 567, "deletions": 459}, "files": [{"sha": "6e00281a510ae5e2e63cc4dd898d6d01ad9bc5a8", "filename": "gcc/ChangeLog", "status": "modified", "additions": 108, "deletions": 0, "changes": 108, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -1,3 +1,111 @@\n+2004-07-01  Jerry Quinn  <jlquinn@optonline.net>\n+\n+\t* alias.c (get_alias_set, canon_rtx, get_addr,\n+\tnonoverlapping_memrefs_p, nonlocal_referenced_p_1, memory_modified_1):\n+\tUse MEM_P.\n+\t* builtins.c (expand_builtin_prefetch, expand_builtin_profile_func,\n+\texpand_builtin): Likewise.\n+\t* calls.c (expand_call, emit_library_call_value_1, store_one_arg):\n+\tLikewise. \n+\t* combine.c (can_combine_p, combinable_i3pat, try_combine,\n+\tfind_split_point, combine_simplify_rtx, simplify_set, make_extraction,\n+\trtx_equal_for_field_assignment_p, gen_lowpart_for_combine,\n+\trecord_dead_and_set_regs_1, get_last_value_validate,\n+\tmark_used_regs_combine, move_deaths, unmentioned_reg_p_1): Likewise.\n+\t* cse.c (check_dependence, canon_hash, equiv_constant,\n+\tgen_lowpart_if_possible, cse_insn, invalidate_from_clobbers,\n+\tcse_around_loop, cse_check_loop_start, cse_set_around_loop,\n+\tcount_reg_usage): Likewise.\n+\t* cselib.c (rtx_equal_for_cselib_p, add_mem_for_addr, cselib_lookup,\n+\tcselib_invalidate_mem, cselib_invalidate_rtx, cselib_record_set,\n+\tcselib_record_sets): Likewise.\n+\t* dbxout.c (PARM_PASSED_IN_MEMORY, dbxout_symbol,\n+\tdbxout_symbol_location, dbxout_parms, dbxout_reg_parms): Likewise.\n+\t* ddg.c (mark_mem_use, mark_mem_store, rtx_mem_access_p): Likewise.\n+\t* df.c (df_uses_record): Likewise.\n+\t* dojump (do_jump): Likewise.\n+\t* dwarf2out.c (stack_adjust_offset, mem_loc_descriptor,\n+\tloc_descriptor_from_tree, rtl_for_decl_location, add_bound_info,\n+\tdecl_start_label): Likewise.\n+\t* emit-rtl.c (gen_complex_constant_part, gen_highpart,\n+\toperand_subword, change_address_1, make_safe_from): Likewise.\n+\t* explow.c (break_out_memory_refs, copy_all_regs, validize_mem,\n+\tstabilize, force_not_mem): Likewise.\n+\t* expmed.c (store_bit_field, store_split_bit_field, extract_bit_field,\n+\texpand_mult_const, expand_divmod, emit_store_flag): Likewise.\n+\t* expr.c (convert_move, convert_modes, emit_block_move,\n+\temit_group_load, emit_group_store, clear_storage, emit_move_insn,\n+\temit_move_insn_1, expand_assignment, store_expr,\n+\tstore_constructor_field, store_constructor, store_field,\n+\tforce_operand, safe_from_p, expand_expr_real_1, expand_increment):\n+\tLikewise. \n+\t* final.c (cleanup_subreg_operands, alter_subreg,\n+\tget_mem_expr_from_op): Likewise.\n+\t* flow.c (notice_stack_pointer_modification_1,\n+\tinit_propagate_block_info, insn_dead_p, mark_set_1, mark_used_regs):\n+\tLikewise. \n+\t* function.c (mark_temp_addr_taken, preserve_temp_slots,\n+\tpreserve_rtl_expr_result, put_var_into_stack, fixup_var_refs_1,\n+\toptimize_bit_field, flush_addressof, purge_addressof_1,\n+\tinstantiate_decl, instantiate_virtual_regs_1, assign_parms,\n+\tsetjmp_protect, setjmp_protect_args, fix_lexical_addr,\n+\tkeep_stack_depressed): Likewise.\n+\t* ifcvt.c (noce_try_cmove_arith, noce_try_abs, noce_operand_ok,\n+\tnoce_process_if_block, find_memory): Likewise.\n+\t* integrate.c (subst_constants, allocate_initial_values): Likewise.\n+\t* local-alloc.c (validate_equiv_mem_from_store, memref_referenced_p,\n+\tupdate_equiv_regs): Likewise.\n+\t* loop.c (scan_loop, prescan_loop, note_addr_stored, check_store,\n+\tmaybe_eliminate_biv_1, find_mem_in_note_1): Likewise.\n+\t* optabs.c (expand_abs, emit_unop_insn): Likewise.\n+\t* passes.c (rest_of_handle_final): Likewise.\n+\t* postreload.c (reload_cse_simplify_set, reload_cse_simplify_operands,\n+\tmove2add_note_store): Likewise.\n+\t* ra-build.c (detect_remat_webs): Likewise.\n+\t* ra-debug.c (dump_static_insn_cost): Likewise.\n+\t* ra-rewrite.c (slots_overlap_p, insert_stores): Likewise.\n+\t* recog.c (validate_change, apply_change_group, cancel_changes,\n+\tvalidate_replace_rtx_1, general_operand, register_operand,\n+\tnonmemory_operand, push_operand, pop_operand, memory_operand,\n+\tindirect_operand, asm_operand_ok, offsettable_memref_p,\n+\toffsettable_nonstrict_memref_p, constrain_operands,\n+\tstore_data_bypass_p): Likewise.\n+\t* reg-stack.c (subst_stack_regs_pat): Likewise.\n+\t* regclass.c (record_operand_costs, scan_one_insn, record_reg_classes,\n+\tcopy_cost, reg_scan_mark_refs): Likewise.\n+\t* regmove.c (optimize_reg_copy_3, stack_memref_p,\n+\tcombine_stack_adjustments_for_block): Likewise.\n+\t* regrename.c (copyprop_hardreg_forward_1): Likewise.\n+\t* reload.c (can_reload_into, push_reload, decompose, immune_p,\n+\tfind_reloads, find_reloads_address, find_reloads_address_1,\n+\treg_overlap_mentioned_for_reload_p, refers_to_mem_for_reload_p,\n+\tfind_equiv_reg): Likewise.\n+\t* reload1.c (reload, eliminate_regs, eliminate_regs_in_insn,\n+\treload_as_needed, choose_reload_regs, emit_input_reload_insns,\n+\tdo_input_reload, emit_reload_insns, gen_reload, delete_output_reload,\n+\tdelete_address_reloads): Likewise.\n+\t* resource.c (mark_referenced_resources): Likewise.\n+\t* rtlanal.c (get_jump_table_offset, count_occurrences,\n+\treg_referenced_p, reg_set_p, set_of_1, set_noop_p,\n+\treg_overlap_mentioned_p, note_uses, replace_regs, nonzero_bits1,\n+\tnum_sign_bit_copies1): Likewise.\n+\t* rtlhooks.c (gen_lowpart_general): Likewise.\n+\t* sched-deps.c (sched_analyze_1, sched_analyze_2): Likewise.\n+\t* sdbout.c (PARM_PASSED_IN_MEMORY, sdbout_symbol,\n+\tsdbout_toplevel_data, sdbout_parms, sdbout_reg_parms,\n+\tsdbout_global_decl): Likewise.\n+\t* simplify-rtx.c (simplify_subreg): Likewise.\n+\t* stmt.c (expand_asm_operands, expand_expr_stmt_value, expand_decl,\n+\texpand_anon_union_decl, expand_end_case_type): Likewise.\n+\t* unroll.c (calculate_giv_inc): Likewise.\n+\t* var-tracking.c (stack_adjust_offset_pre_post,\n+\tbb_stack_adjust_offset, track_expr_p, count_uses, add_uses,\n+\tadd_stores, compute_bb_dataflow, vt_get_decl_and_offset,\n+\tvt_add_function_parameters): Likewise.\n+\t* varasm.c (make_var_volatile, notice_global_symbol,\n+\tassemble_external, decode_addr_const, mark_weak,\n+\tdefault_encode_section_info): Likewise.\n+\n 2004-07-01  Steven Bosscher  <stevenb@suse.de>\n \n \t* stmt.c (check_seenlabel): Remove."}, {"sha": "b8443e8c02deaffbf74193b83c9a58aedf29ba75", "filename": "gcc/alias.c", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Falias.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Falias.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Falias.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -566,7 +566,7 @@ get_alias_set (tree t)\n \t it.  This is necessary for C++ anonymous unions, whose component\n \t variables don't look like union members (boo!).  */\n       if (TREE_CODE (t) == VAR_DECL\n-\t  && DECL_RTL_SET_P (t) && GET_CODE (DECL_RTL (t)) == MEM)\n+\t  && DECL_RTL_SET_P (t) && MEM_P (DECL_RTL (t)))\n \treturn MEM_ALIAS_SET (DECL_RTL (t));\n \n       /* Now all we care about is the type.  */\n@@ -1197,7 +1197,7 @@ canon_rtx (rtx x)\n      the loop optimizer.   Note we want to leave the original\n      MEM alone, but need to return the canonicalized MEM with\n      all the flags with their original values.  */\n-  else if (GET_CODE (x) == MEM)\n+  else if (MEM_P (x))\n     x = replace_equiv_address_nv (x, canon_rtx (XEXP (x, 0)));\n \n   return x;\n@@ -1608,7 +1608,7 @@ get_addr (rtx x)\n \tif (CONSTANT_P (l->loc))\n \t  return l->loc;\n       for (l = v->locs; l; l = l->next)\n-\tif (!REG_P (l->loc) && GET_CODE (l->loc) != MEM)\n+\tif (!REG_P (l->loc) && !MEM_P (l->loc))\n \t  return l->loc;\n       if (v->locs)\n \treturn v->locs->loc;\n@@ -2110,19 +2110,19 @@ nonoverlapping_memrefs_p (rtx x, rtx y)\n   /* If either RTL is not a MEM, it must be a REG or CONCAT, meaning they\n      can't overlap unless they are the same because we never reuse that part\n      of the stack frame used for locals for spilled pseudos.  */\n-  if ((GET_CODE (rtlx) != MEM || GET_CODE (rtly) != MEM)\n+  if ((!MEM_P (rtlx) || !MEM_P (rtly))\n       && ! rtx_equal_p (rtlx, rtly))\n     return 1;\n \n   /* Get the base and offsets of both decls.  If either is a register, we\n      know both are and are the same, so use that as the base.  The only\n      we can avoid overlap is if we can deduce that they are nonoverlapping\n      pieces of that decl, which is very rare.  */\n-  basex = GET_CODE (rtlx) == MEM ? XEXP (rtlx, 0) : rtlx;\n+  basex = MEM_P (rtlx) ? XEXP (rtlx, 0) : rtlx;\n   if (GET_CODE (basex) == PLUS && GET_CODE (XEXP (basex, 1)) == CONST_INT)\n     offsetx = INTVAL (XEXP (basex, 1)), basex = XEXP (basex, 0);\n \n-  basey = GET_CODE (rtly) == MEM ? XEXP (rtly, 0) : rtly;\n+  basey = MEM_P (rtly) ? XEXP (rtly, 0) : rtly;\n   if (GET_CODE (basey) == PLUS && GET_CODE (XEXP (basey, 1)) == CONST_INT)\n     offsety = INTVAL (XEXP (basey, 1)), basey = XEXP (basey, 0);\n \n@@ -2137,10 +2137,10 @@ nonoverlapping_memrefs_p (rtx x, rtx y)\n \t    || (CONSTANT_P (basey) && REG_P (basex)\n \t\t&& REGNO_PTR_FRAME_P (REGNO (basex))));\n \n-  sizex = (GET_CODE (rtlx) != MEM ? (int) GET_MODE_SIZE (GET_MODE (rtlx))\n+  sizex = (!MEM_P (rtlx) ? (int) GET_MODE_SIZE (GET_MODE (rtlx))\n \t   : MEM_SIZE (rtlx) ? INTVAL (MEM_SIZE (rtlx))\n \t   : -1);\n-  sizey = (GET_CODE (rtly) != MEM ? (int) GET_MODE_SIZE (GET_MODE (rtly))\n+  sizey = (!MEM_P (rtly) ? (int) GET_MODE_SIZE (GET_MODE (rtly))\n \t   : MEM_SIZE (rtly) ? INTVAL (MEM_SIZE (rtly)) :\n \t   -1);\n \n@@ -2557,7 +2557,7 @@ nonlocal_referenced_p_1 (rtx *loc, void *data ATTRIBUTE_UNUSED)\n       if (nonlocal_mentioned_p (SET_SRC (x)))\n \treturn 1;\n \n-      if (GET_CODE (SET_DEST (x)) == MEM)\n+      if (MEM_P (SET_DEST (x)))\n \treturn nonlocal_mentioned_p (XEXP (SET_DEST (x), 0));\n \n       /* If the destination is anything other than a CC0, PC,\n@@ -2577,7 +2577,7 @@ nonlocal_referenced_p_1 (rtx *loc, void *data ATTRIBUTE_UNUSED)\n       return 0;\n \n     case CLOBBER:\n-      if (GET_CODE (XEXP (x, 0)) == MEM)\n+      if (MEM_P (XEXP (x, 0)))\n \treturn nonlocal_mentioned_p (XEXP (XEXP (x, 0), 0));\n       return 0;\n \n@@ -2789,7 +2789,7 @@ static bool memory_modified;\n static void\n memory_modified_1 (rtx x, rtx pat ATTRIBUTE_UNUSED, void *data)\n {\n-  if (GET_CODE (x) == MEM)\n+  if (MEM_P (x))\n     {\n       if (anti_dependence (x, (rtx)data) || output_dependence (x, (rtx)data))\n \tmemory_modified = true;"}, {"sha": "eb33f0ba9f5fdb76d4bebce2eab887de98bfe317", "filename": "gcc/builtins.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fbuiltins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fbuiltins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -965,7 +965,7 @@ expand_builtin_prefetch (tree arglist)\n     op0 = protect_from_queue (op0, 0);\n   /* Don't do anything with direct references to volatile memory, but\n      generate code to handle other side effects.  */\n-  if (GET_CODE (op0) != MEM && side_effects_p (op0))\n+  if (!MEM_P (op0) && side_effects_p (op0))\n     emit_insn (op0);\n }\n \n@@ -5329,7 +5329,7 @@ expand_builtin_profile_func (bool exitp)\n   rtx this, which;\n \n   this = DECL_RTL (current_function_decl);\n-  if (GET_CODE (this) == MEM)\n+  if (MEM_P (this))\n     this = XEXP (this, 0);\n   else\n     abort ();\n@@ -5836,7 +5836,7 @@ expand_builtin (tree exp, rtx target, rtx subtarget, enum machine_mode mode,\n     case BUILT_IN_AGGREGATE_INCOMING_ADDRESS:\n       if (arglist != 0\n \t  || ! AGGREGATE_TYPE_P (TREE_TYPE (TREE_TYPE (current_function_decl)))\n-\t  || GET_CODE (DECL_RTL (DECL_RESULT (current_function_decl))) != MEM)\n+\t  || !MEM_P (DECL_RTL (DECL_RESULT (current_function_decl))))\n \treturn const0_rtx;\n       else\n \treturn XEXP (DECL_RTL (DECL_RESULT (current_function_decl)), 0);"}, {"sha": "11d8b26e848278e6de3ffab97e12e0ec146c2cb4", "filename": "gcc/calls.c", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fcalls.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fcalls.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcalls.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -2208,7 +2208,7 @@ expand_call (tree exp, rtx target, int ignore)\n \t    structure_value_addr = expand_expr (return_arg, NULL_RTX,\n \t\t\t\t\t\tVOIDmode, EXPAND_NORMAL);\n \t  }\n-\telse if (target && GET_CODE (target) == MEM)\n+\telse if (target && MEM_P (target))\n \t  structure_value_addr = XEXP (target, 0);\n \telse\n \t  {\n@@ -3101,7 +3101,7 @@ expand_call (tree exp, rtx target, int ignore)\n \ttarget = const0_rtx;\n       else if (structure_value_addr)\n \t{\n-\t  if (target == 0 || GET_CODE (target) != MEM)\n+\t  if (target == 0 || !MEM_P (target))\n \t    {\n \t      target\n \t\t= gen_rtx_MEM (TYPE_MODE (TREE_TYPE (exp)),\n@@ -3156,7 +3156,7 @@ expand_call (tree exp, rtx target, int ignore)\n \t  /* If we are setting a MEM, this code must be executed.  Since it is\n \t     emitted after the call insn, sibcall optimization cannot be\n \t     performed in that case.  */\n-\t  if (GET_CODE (target) == MEM)\n+\t  if (MEM_P (target))\n \t    sibcall_failure = 1;\n \t}\n       else if (TYPE_MODE (TREE_TYPE (exp)) == BLKmode)\n@@ -3281,7 +3281,7 @@ expand_call (tree exp, rtx target, int ignore)\n \t adding to call_fusage before the call to emit_call_1 because TARGET\n \t may be modified in the meantime.  */\n       if (structure_value_addr != 0 && target != 0\n-\t  && GET_CODE (target) == MEM && RTX_UNCHANGING_P (target))\n+\t  && MEM_P (target) && RTX_UNCHANGING_P (target))\n \tadd_function_usage_to\n \t  (last_call_insn (),\n \t   gen_rtx_EXPR_LIST (VOIDmode, gen_rtx_CLOBBER (VOIDmode, target),\n@@ -3609,7 +3609,7 @@ emit_library_call_value_1 (int retval, rtx orgfun, rtx value,\n \t    value = gen_reg_rtx (outmode);\n #else /* not PCC_STATIC_STRUCT_RETURN */\n \t  struct_value_size = GET_MODE_SIZE (outmode);\n-\t  if (value != 0 && GET_CODE (value) == MEM)\n+\t  if (value != 0 && MEM_P (value))\n \t    mem_value = value;\n \t  else\n \t    mem_value = assign_temp (tfom, 0, 1, 1);\n@@ -3659,7 +3659,7 @@ emit_library_call_value_1 (int retval, rtx orgfun, rtx value,\n       nargs++;\n \n       /* Make sure it is a reasonable operand for a move or push insn.  */\n-      if (!REG_P (addr) && GET_CODE (addr) != MEM\n+      if (!REG_P (addr) && !MEM_P (addr)\n \t  && ! (CONSTANT_P (addr) && LEGITIMATE_CONSTANT_P (addr)))\n \taddr = force_operand (addr, NULL_RTX);\n \n@@ -3705,7 +3705,7 @@ emit_library_call_value_1 (int retval, rtx orgfun, rtx value,\n \t either emit_move_insn or emit_push_insn will do that.  */\n \n       /* Make sure it is a reasonable operand for a move or push insn.  */\n-      if (!REG_P (val) && GET_CODE (val) != MEM\n+      if (!REG_P (val) && !MEM_P (val)\n \t  && ! (CONSTANT_P (val) && LEGITIMATE_CONSTANT_P (val)))\n \tval = force_operand (val, NULL_RTX);\n \n@@ -4530,7 +4530,7 @@ store_one_arg (struct arg_data *arg, rtx argblock, int flags,\n \t    }\n \t}\n \n-      if ((flags & ECF_SIBCALL) && GET_CODE (arg->value) == MEM)\n+      if ((flags & ECF_SIBCALL) && MEM_P (arg->value))\n \t{\n \t  /* emit_push_insn might not work properly if arg->value and\n \t     argblock + arg->locate.offset areas overlap.  */"}, {"sha": "533e4a806a2c35ab0af65aca638882203dfceef1", "filename": "gcc/combine.c", "status": "modified", "additions": 30, "deletions": 30, "changes": 60, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fcombine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fcombine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcombine.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -1234,7 +1234,7 @@ can_combine_p (rtx insn, rtx i3, rtx pred ATTRIBUTE_UNUSED, rtx succ,\n \t are intervening stores.  Also, don't move a volatile asm or\n \t UNSPEC_VOLATILE across any other insns.  */\n       || (! all_adjacent\n-\t  && (((GET_CODE (src) != MEM\n+\t  && (((!MEM_P (src)\n \t\t|| ! find_reg_note (insn, REG_EQUIV, src))\n \t       && use_crosses_set_p (src, INSN_CUID (insn)))\n \t      || (GET_CODE (src) == ASM_OPERANDS && MEM_VOLATILE_P (src))\n@@ -1433,7 +1433,7 @@ combinable_i3pat (rtx i3, rtx *loc, rtx i2dest, rtx i1dest,\n \t into the address of a MEM, so only prevent the combination if\n \t i1 or i2 set the same MEM.  */\n       if ((inner_dest != dest &&\n-\t   (GET_CODE (inner_dest) != MEM\n+\t   (!MEM_P (inner_dest)\n \t    || rtx_equal_p (i2dest, inner_dest)\n \t    || (i1dest && rtx_equal_p (i1dest, inner_dest)))\n \t   && (reg_overlap_mentioned_p (i2dest, inner_dest)\n@@ -1914,7 +1914,7 @@ try_combine (rtx i3, rtx i2, rtx i1, int *new_direct_jump_p)\n #if 0\n   if (!(GET_CODE (PATTERN (i3)) == SET\n \t&& REG_P (SET_SRC (PATTERN (i3)))\n-\t&& GET_CODE (SET_DEST (PATTERN (i3))) == MEM\n+\t&& MEM_P (SET_DEST (PATTERN (i3)))\n \t&& (GET_CODE (XEXP (SET_DEST (PATTERN (i3)), 0)) == POST_INC\n \t    || GET_CODE (XEXP (SET_DEST (PATTERN (i3)), 0)) == POST_DEC)))\n     /* It's not the exception.  */\n@@ -2414,7 +2414,7 @@ try_combine (rtx i3, rtx i2, rtx i1, int *new_direct_jump_p)\n #ifdef INSN_SCHEDULING\n \t  /* If *SPLIT is a paradoxical SUBREG, when we split it, it should\n \t     be written as a ZERO_EXTEND.  */\n-\t  if (split_code == SUBREG && GET_CODE (SUBREG_REG (*split)) == MEM)\n+\t  if (split_code == SUBREG && MEM_P (SUBREG_REG (*split)))\n \t    {\n #ifdef LOAD_EXTEND_OP\n \t      /* Or as a SIGN_EXTEND if LOAD_EXTEND_OP says that that's\n@@ -3046,7 +3046,7 @@ find_split_point (rtx *loc, rtx insn)\n #ifdef INSN_SCHEDULING\n       /* If we are making a paradoxical SUBREG invalid, it becomes a split\n \t point.  */\n-      if (GET_CODE (SUBREG_REG (x)) == MEM)\n+      if (MEM_P (SUBREG_REG (x)))\n \treturn loc;\n #endif\n       return find_split_point (&SUBREG_REG (x), insn);\n@@ -3995,7 +3995,7 @@ combine_simplify_rtx (rtx x, enum machine_mode op0_mode, int in_dest)\n \n       /* Don't change the mode of the MEM if that would change the meaning\n \t of the address.  */\n-      if (GET_CODE (SUBREG_REG (x)) == MEM\n+      if (MEM_P (SUBREG_REG (x))\n \t  && (MEM_VOLATILE_P (SUBREG_REG (x))\n \t      || mode_dependent_address_p (XEXP (SUBREG_REG (x), 0))))\n \treturn gen_rtx_CLOBBER (mode, const0_rtx);\n@@ -5358,7 +5358,7 @@ simplify_set (rtx x)\n       && SUBREG_BYTE (src) == 0\n       && (GET_MODE_SIZE (GET_MODE (src))\n \t  > GET_MODE_SIZE (GET_MODE (SUBREG_REG (src))))\n-      && GET_CODE (SUBREG_REG (src)) == MEM)\n+      && MEM_P (SUBREG_REG (src)))\n     {\n       SUBST (SET_SRC (x),\n \t     gen_rtx_fmt_e (LOAD_EXTEND_OP (GET_MODE (SUBREG_REG (src))),\n@@ -6139,7 +6139,7 @@ make_extraction (enum machine_mode mode, rtx inner, HOST_WIDE_INT pos,\n \t The subreg adds or removes high bits; its mode is\n \t irrelevant to the meaning of this extraction,\n \t since POS and LEN count from the lsb.  */\n-      if (GET_CODE (SUBREG_REG (inner)) == MEM)\n+      if (MEM_P (SUBREG_REG (inner)))\n \tis_mode = GET_MODE (SUBREG_REG (inner));\n       inner = SUBREG_REG (inner);\n     }\n@@ -6180,11 +6180,11 @@ make_extraction (enum machine_mode mode, rtx inner, HOST_WIDE_INT pos,\n   if (tmode != BLKmode\n       && ! (spans_byte && inner_mode != tmode)\n       && ((pos_rtx == 0 && (pos % BITS_PER_WORD) == 0\n-\t   && GET_CODE (inner) != MEM\n+\t   && !MEM_P (inner)\n \t   && (! in_dest\n \t       || (REG_P (inner)\n \t\t   && have_insn_for (STRICT_LOW_PART, tmode))))\n-\t  || (GET_CODE (inner) == MEM && pos_rtx == 0\n+\t  || (MEM_P (inner) && pos_rtx == 0\n \t      && (pos\n \t\t  % (STRICT_ALIGNMENT ? GET_MODE_ALIGNMENT (tmode)\n \t\t     : BITS_PER_UNIT)) == 0\n@@ -6202,7 +6202,7 @@ make_extraction (enum machine_mode mode, rtx inner, HOST_WIDE_INT pos,\n \t If INNER is not a MEM, get a piece consisting of just the field\n \t of interest (in this case POS % BITS_PER_WORD must be 0).  */\n \n-      if (GET_CODE (inner) == MEM)\n+      if (MEM_P (inner))\n \t{\n \t  HOST_WIDE_INT offset;\n \n@@ -6261,7 +6261,7 @@ make_extraction (enum machine_mode mode, rtx inner, HOST_WIDE_INT pos,\n \t make a STRICT_LOW_PART unless we made a MEM.  */\n \n       if (in_dest)\n-\treturn (GET_CODE (new) == MEM ? new\n+\treturn (MEM_P (new) ? new\n \t\t: (GET_CODE (new) != SUBREG\n \t\t   ? gen_rtx_CLOBBER (tmode, const0_rtx)\n \t\t   : gen_rtx_STRICT_LOW_PART (VOIDmode, new)));\n@@ -6312,7 +6312,7 @@ make_extraction (enum machine_mode mode, rtx inner, HOST_WIDE_INT pos,\n      length is not 1.  In all other cases, we would only be going outside\n      our object in cases when an original shift would have been\n      undefined.  */\n-  if (! spans_byte && GET_CODE (inner) == MEM\n+  if (! spans_byte && MEM_P (inner)\n       && ((pos_rtx == 0 && pos + len > GET_MODE_BITSIZE (is_mode))\n \t  || (pos_rtx != 0 && len != 1)))\n     return 0;\n@@ -6355,7 +6355,7 @@ make_extraction (enum machine_mode mode, rtx inner, HOST_WIDE_INT pos,\n   /* If this is not from memory, the desired mode is wanted_inner_reg_mode;\n      if we have to change the mode of memory and cannot, the desired mode is\n      EXTRACTION_MODE.  */\n-  if (GET_CODE (inner) != MEM)\n+  if (!MEM_P (inner))\n     wanted_inner_mode = wanted_inner_reg_mode;\n   else if (inner_mode != wanted_inner_mode\n \t   && (mode_dependent_address_p (XEXP (inner, 0))\n@@ -6373,7 +6373,7 @@ make_extraction (enum machine_mode mode, rtx inner, HOST_WIDE_INT pos,\n \t If it's a MEM we need to recompute POS relative to that.\n \t However, if we're extracting from (or inserting into) a register,\n \t we want to recompute POS relative to wanted_inner_mode.  */\n-      int width = (GET_CODE (inner) == MEM\n+      int width = (MEM_P (inner)\n \t\t   ? GET_MODE_BITSIZE (is_mode)\n \t\t   : GET_MODE_BITSIZE (wanted_inner_mode));\n \n@@ -6383,15 +6383,15 @@ make_extraction (enum machine_mode mode, rtx inner, HOST_WIDE_INT pos,\n \tpos_rtx\n \t  = gen_rtx_MINUS (GET_MODE (pos_rtx), GEN_INT (width - len), pos_rtx);\n       /* POS may be less than 0 now, but we check for that below.\n-\t Note that it can only be less than 0 if GET_CODE (inner) != MEM.  */\n+\t Note that it can only be less than 0 if !MEM_P (inner).  */\n     }\n \n   /* If INNER has a wider mode, make it smaller.  If this is a constant\n      extract, try to adjust the byte to point to the byte containing\n      the value.  */\n   if (wanted_inner_mode != VOIDmode\n       && GET_MODE_SIZE (wanted_inner_mode) < GET_MODE_SIZE (is_mode)\n-      && ((GET_CODE (inner) == MEM\n+      && ((MEM_P (inner)\n \t   && (inner_mode == wanted_inner_mode\n \t       || (! mode_dependent_address_p (XEXP (inner, 0))\n \t\t   && ! MEM_VOLATILE_P (inner))))))\n@@ -6429,7 +6429,7 @@ make_extraction (enum machine_mode mode, rtx inner, HOST_WIDE_INT pos,\n   /* If INNER is not memory, we can always get it into the proper mode.  If we\n      are changing its mode, POS must be a constant and smaller than the size\n      of the new mode.  */\n-  else if (GET_CODE (inner) != MEM)\n+  else if (!MEM_P (inner))\n     {\n       if (GET_MODE (inner) != wanted_inner_mode\n \t  && (pos_rtx != 0\n@@ -7771,14 +7771,14 @@ rtx_equal_for_field_assignment_p (rtx x, rtx y)\n   /* Check for a paradoxical SUBREG of a MEM compared with the MEM.\n      Note that all SUBREGs of MEM are paradoxical; otherwise they\n      would have been rewritten.  */\n-  if (GET_CODE (x) == MEM && GET_CODE (y) == SUBREG\n-      && GET_CODE (SUBREG_REG (y)) == MEM\n+  if (MEM_P (x) && GET_CODE (y) == SUBREG\n+      && MEM_P (SUBREG_REG (y))\n       && rtx_equal_p (SUBREG_REG (y),\n \t\t      gen_lowpart (GET_MODE (SUBREG_REG (y)), x)))\n     return 1;\n \n-  if (GET_CODE (y) == MEM && GET_CODE (x) == SUBREG\n-      && GET_CODE (SUBREG_REG (x)) == MEM\n+  if (MEM_P (y) && GET_CODE (x) == SUBREG\n+      && MEM_P (SUBREG_REG (x))\n       && rtx_equal_p (SUBREG_REG (x),\n \t\t      gen_lowpart (GET_MODE (SUBREG_REG (x)), y)))\n     return 1;\n@@ -9348,7 +9348,7 @@ gen_lowpart_for_combine (enum machine_mode mode, rtx x)\n   /* X might be a paradoxical (subreg (mem)).  In that case, gen_lowpart\n      won't know what to do.  So we will strip off the SUBREG here and\n      process normally.  */\n-  if (GET_CODE (x) == SUBREG && GET_CODE (SUBREG_REG (x)) == MEM)\n+  if (GET_CODE (x) == SUBREG && MEM_P (SUBREG_REG (x)))\n     {\n       x = SUBREG_REG (x);\n       if (GET_MODE (x) == mode)\n@@ -9369,7 +9369,7 @@ gen_lowpart_for_combine (enum machine_mode mode, rtx x)\n   if (result)\n     return result;\n \n-  if (GET_CODE (x) == MEM)\n+  if (MEM_P (x))\n     {\n       int offset = 0;\n \n@@ -10899,7 +10899,7 @@ record_dead_and_set_regs_1 (rtx dest, rtx setter, void *data)\n       else\n \trecord_value_for_reg (dest, record_dead_insn, NULL_RTX);\n     }\n-  else if (GET_CODE (dest) == MEM\n+  else if (MEM_P (dest)\n \t   /* Ignore pushes, they clobber nothing.  */\n \t   && ! push_operand (dest, GET_MODE (dest)))\n     mem_last_set = INSN_CUID (record_dead_insn);\n@@ -11088,7 +11088,7 @@ get_last_value_validate (rtx *loc, rtx insn, int tick, int replace)\n   /* If this is a memory reference, make sure that there were\n      no stores after it that might have clobbered the value.  We don't\n      have alias info, so we assume any store invalidates it.  */\n-  else if (GET_CODE (x) == MEM && ! RTX_UNCHANGING_P (x)\n+  else if (MEM_P (x) && ! RTX_UNCHANGING_P (x)\n \t   && INSN_CUID (insn) <= mem_last_set)\n     {\n       if (replace)\n@@ -11384,7 +11384,7 @@ mark_used_regs_combine (rtx x)\n     case CLOBBER:\n       /* If we are clobbering a MEM, mark any hard registers inside the\n \t address as used.  */\n-      if (GET_CODE (XEXP (x, 0)) == MEM)\n+      if (MEM_P (XEXP (x, 0)))\n \tmark_used_regs_combine (XEXP (XEXP (x, 0), 0));\n       return;\n \n@@ -11425,7 +11425,7 @@ mark_used_regs_combine (rtx x)\n \t       || GET_CODE (testreg) == STRICT_LOW_PART)\n \t  testreg = XEXP (testreg, 0);\n \n-\tif (GET_CODE (testreg) == MEM)\n+\tif (MEM_P (testreg))\n \t  mark_used_regs_combine (XEXP (testreg, 0));\n \n \tmark_used_regs_combine (SET_SRC (x));\n@@ -11624,7 +11624,7 @@ move_deaths (rtx x, rtx maybe_kill_insn, int from_cuid, rtx to_insn,\n \t For a REG (the only other possibility), the entire value is\n \t being replaced so the old value is not used in this insn.  */\n \n-      if (GET_CODE (dest) == MEM)\n+      if (MEM_P (dest))\n \tmove_deaths (XEXP (dest, 0), maybe_kill_insn, from_cuid,\n \t\t     to_insn, pnotes);\n       return;\n@@ -12356,7 +12356,7 @@ unmentioned_reg_p_1 (rtx *loc, void *expr)\n   rtx x = *loc;\n \n   if (x != NULL_RTX\n-      && (REG_P (x) || GET_CODE (x) == MEM)\n+      && (REG_P (x) || MEM_P (x))\n       && ! reg_mentioned_p (x, (rtx) expr))\n     return 1;\n   return 0;"}, {"sha": "c50b28aaba76d0d1c00db4fb3fcb24c8c153ae8c", "filename": "gcc/cse.c", "status": "modified", "additions": 22, "deletions": 22, "changes": 44, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcse.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -1689,7 +1689,7 @@ static int\n check_dependence (rtx *x, void *data)\n {\n   struct check_dependence_data *d = (struct check_dependence_data *) data;\n-  if (*x && GET_CODE (*x) == MEM)\n+  if (*x && MEM_P (*x))\n     return canon_true_dependence (d->exp, d->mode, d->addr, *x,\n \t\t    \t\t  cse_rtx_varies_p);\n   else\n@@ -2246,7 +2246,7 @@ canon_hash (rtx x, enum machine_mode mode)\n \t handling since the MEM may be BLKmode which normally\n \t prevents an entry from being made.  Pure calls are\n \t marked by a USE which mentions BLKmode memory.  */\n-      if (GET_CODE (XEXP (x, 0)) == MEM\n+      if (MEM_P (XEXP (x, 0))\n \t  && ! MEM_VOLATILE_P (XEXP (x, 0)))\n \t{\n \t  hash += (unsigned) USE;\n@@ -4195,7 +4195,7 @@ equiv_constant (rtx x)\n      is a constant-pool reference.  Then try to look it up in the hash table\n      in case it is something whose value we have seen before.  */\n \n-  if (GET_CODE (x) == MEM)\n+  if (MEM_P (x))\n     {\n       struct table_elt *elt;\n \n@@ -4231,7 +4231,7 @@ gen_lowpart_if_possible (enum machine_mode mode, rtx x)\n \n   if (result)\n     return result;\n-  else if (GET_CODE (x) == MEM)\n+  else if (MEM_P (x))\n     {\n       /* This is the only other case we handle.  */\n       int offset = 0;\n@@ -4700,7 +4700,7 @@ cse_insn (rtx insn, rtx libcall_insn)\n \t      /* If we clobber memory, canon the address.\n \t\t This does nothing when a register is clobbered\n \t\t because we have already invalidated the reg.  */\n-\t      if (GET_CODE (XEXP (y, 0)) == MEM)\n+\t      if (MEM_P (XEXP (y, 0)))\n \t\tcanon_reg (XEXP (y, 0), NULL_RTX);\n \t    }\n \t  else if (GET_CODE (y) == USE\n@@ -4719,7 +4719,7 @@ cse_insn (rtx insn, rtx libcall_insn)\n     }\n   else if (GET_CODE (x) == CLOBBER)\n     {\n-      if (GET_CODE (XEXP (x, 0)) == MEM)\n+      if (MEM_P (XEXP (x, 0)))\n \tcanon_reg (XEXP (x, 0), NULL_RTX);\n     }\n \n@@ -4789,7 +4789,7 @@ cse_insn (rtx insn, rtx libcall_insn)\n \t     || GET_CODE (dest) == SIGN_EXTRACT)\n \tdest = XEXP (dest, 0);\n \n-      if (GET_CODE (dest) == MEM)\n+      if (MEM_P (dest))\n \tcanon_reg (dest, insn);\n     }\n \n@@ -4916,7 +4916,7 @@ cse_insn (rtx insn, rtx libcall_insn)\n \t RTL would be referring to SRC, so we don't lose any optimization\n \t opportunities by not having SRC in the hash table.  */\n \n-      if (GET_CODE (src) == MEM\n+      if (MEM_P (src)\n \t  && find_reg_note (insn, REG_EQUIV, NULL_RTX) != 0\n \t  && REG_P (dest)\n \t  && REGNO (dest) >= FIRST_PSEUDO_REGISTER)\n@@ -5130,7 +5130,7 @@ cse_insn (rtx insn, rtx libcall_insn)\n       if (flag_expensive_optimizations && src_related == 0\n \t  && (GET_MODE_SIZE (mode) < UNITS_PER_WORD)\n \t  && GET_MODE_CLASS (mode) == MODE_INT\n-\t  && GET_CODE (src) == MEM && ! do_not_record\n+\t  && MEM_P (src) && ! do_not_record\n \t  && LOAD_EXTEND_OP (mode) != NIL)\n \t{\n \t  enum machine_mode tmode;\n@@ -5391,7 +5391,7 @@ cse_insn (rtx insn, rtx libcall_insn)\n \t      if (libcall_insn\n \t\t  && (REG_P (sets[i].orig_src)\n \t\t      || GET_CODE (sets[i].orig_src) == SUBREG\n-\t\t      || GET_CODE (sets[i].orig_src) == MEM))\n+\t\t      || MEM_P (sets[i].orig_src)))\n \t\t{\n \t          rtx note = find_reg_equal_equiv_note (libcall_insn);\n \t\t  if (note != 0)\n@@ -5426,7 +5426,7 @@ cse_insn (rtx insn, rtx libcall_insn)\n \t\t\t && GET_CODE (XEXP (XEXP (trial, 0), 0)) == LABEL_REF\n \t\t\t && GET_CODE (XEXP (XEXP (trial, 0), 1)) == LABEL_REF)\n \t\t   && (src_folded == 0\n-\t\t       || (GET_CODE (src_folded) != MEM\n+\t\t       || (!MEM_P (src_folded)\n \t\t\t   && ! src_folded_force_flag))\n \t\t   && GET_MODE_CLASS (mode) != MODE_CC\n \t\t   && mode != VOIDmode)\n@@ -5542,7 +5542,7 @@ cse_insn (rtx insn, rtx libcall_insn)\n \n       sets[i].inner_dest = dest;\n \n-      if (GET_CODE (dest) == MEM)\n+      if (MEM_P (dest))\n \t{\n #ifdef PUSH_ROUNDING\n \t  /* Stack pushes invalidate the stack pointer.  */\n@@ -5658,7 +5658,7 @@ cse_insn (rtx insn, rtx libcall_insn)\n \t{\n \t  if (REG_P (dest) || GET_CODE (dest) == SUBREG)\n \t    invalidate (dest, VOIDmode);\n-\t  else if (GET_CODE (dest) == MEM)\n+\t  else if (MEM_P (dest))\n \t    {\n \t      /* Outgoing arguments for a libcall don't\n \t\t affect any recorded expressions.  */\n@@ -5831,7 +5831,7 @@ cse_insn (rtx insn, rtx libcall_insn)\n \t   we have just done an invalidate_memory that covers even those.  */\n \tif (REG_P (dest) || GET_CODE (dest) == SUBREG)\n \t  invalidate (dest, VOIDmode);\n-\telse if (GET_CODE (dest) == MEM)\n+\telse if (MEM_P (dest))\n \t  {\n \t    /* Outgoing arguments for a libcall don't\n \t       affect any recorded expressions.  */\n@@ -5931,7 +5931,7 @@ cse_insn (rtx insn, rtx libcall_insn)\n \t   floating-point values in registers that might be wider than\n \t   memory.  */\n \tif ((flag_float_store\n-\t     && GET_CODE (dest) == MEM\n+\t     && MEM_P (dest)\n \t     && FLOAT_MODE_P (GET_MODE (dest)))\n \t    /* Don't record BLKmode values, because we don't know the\n \t       size of it, and can't be sure that other BLKmode values\n@@ -5973,7 +5973,7 @@ cse_insn (rtx insn, rtx libcall_insn)\n \t      sets[i].dest_hash = HASH (dest, GET_MODE (dest));\n \t    }\n \n-\tif (GET_CODE (inner_dest) == MEM\n+\tif (MEM_P (inner_dest)\n \t    && GET_CODE (XEXP (inner_dest, 0)) == ADDRESSOF)\n \t  /* Given (SET (MEM (ADDRESSOF (X))) Y) we don't want to say\n \t     that (MEM (ADDRESSOF (X))) is equivalent to Y.\n@@ -5985,7 +5985,7 @@ cse_insn (rtx insn, rtx libcall_insn)\n \t  elt = insert (dest, sets[i].src_elt,\n \t\t\tsets[i].dest_hash, GET_MODE (dest));\n \n-\telt->in_memory = (GET_CODE (sets[i].inner_dest) == MEM\n+\telt->in_memory = (MEM_P (sets[i].inner_dest)\n \t\t\t  && (! RTX_UNCHANGING_P (sets[i].inner_dest)\n \t\t\t      || fixed_base_plus_p (XEXP (sets[i].inner_dest,\n \t\t\t\t\t\t\t  0))));\n@@ -6248,7 +6248,7 @@ invalidate_from_clobbers (rtx x)\n       if (ref)\n \t{\n \t  if (REG_P (ref) || GET_CODE (ref) == SUBREG\n-\t      || GET_CODE (ref) == MEM)\n+\t      || MEM_P (ref))\n \t    invalidate (ref, VOIDmode);\n \t  else if (GET_CODE (ref) == STRICT_LOW_PART\n \t\t   || GET_CODE (ref) == ZERO_EXTRACT)\n@@ -6265,7 +6265,7 @@ invalidate_from_clobbers (rtx x)\n \t    {\n \t      rtx ref = XEXP (y, 0);\n \t      if (REG_P (ref) || GET_CODE (ref) == SUBREG\n-\t\t  || GET_CODE (ref) == MEM)\n+\t\t  || MEM_P (ref))\n \t\tinvalidate (ref, VOIDmode);\n \t      else if (GET_CODE (ref) == STRICT_LOW_PART\n \t\t       || GET_CODE (ref) == ZERO_EXTRACT)\n@@ -6517,7 +6517,7 @@ cse_check_loop_start (rtx x, rtx set ATTRIBUTE_UNUSED, void *data)\n       || GET_CODE (x) == CC0 || GET_CODE (x) == PC)\n     return;\n \n-  if ((GET_CODE (x) == MEM && GET_CODE (*cse_check_loop_start_value) == MEM)\n+  if ((MEM_P (x) && MEM_P (*cse_check_loop_start_value))\n       || reg_overlap_mentioned_p (x, *cse_check_loop_start_value))\n     *cse_check_loop_start_value = NULL_RTX;\n }\n@@ -6637,7 +6637,7 @@ cse_set_around_loop (rtx x, rtx insn, rtx loop_start)\n   /* See comment on similar code in cse_insn for explanation of these\n      tests.  */\n   if (REG_P (SET_DEST (x)) || GET_CODE (SET_DEST (x)) == SUBREG\n-      || GET_CODE (SET_DEST (x)) == MEM)\n+      || MEM_P (SET_DEST (x)))\n     invalidate (SET_DEST (x), VOIDmode);\n   else if (GET_CODE (SET_DEST (x)) == STRICT_LOW_PART\n \t   || GET_CODE (SET_DEST (x)) == ZERO_EXTRACT)\n@@ -7303,7 +7303,7 @@ count_reg_usage (rtx x, int *counts, int incr)\n     case CLOBBER:\n       /* If we are clobbering a MEM, mark any registers inside the address\n          as being used.  */\n-      if (GET_CODE (XEXP (x, 0)) == MEM)\n+      if (MEM_P (XEXP (x, 0)))\n \tcount_reg_usage (XEXP (XEXP (x, 0), 0), counts, incr);\n       return;\n "}, {"sha": "c5b29deb1d6c6edab007ca9fe8a3cdbdc8fba567", "filename": "gcc/cselib.c", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fcselib.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fcselib.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcselib.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -434,7 +434,7 @@ rtx_equal_for_cselib_p (rtx x, rtx y)\n \t  rtx t = l->loc;\n \n \t  /* Avoid infinite recursion.  */\n-\t  if (REG_P (t) || GET_CODE (t) == MEM)\n+\t  if (REG_P (t) || MEM_P (t))\n \t    continue;\n \t  else if (rtx_equal_for_cselib_p (t, y))\n \t    return 1;\n@@ -452,7 +452,7 @@ rtx_equal_for_cselib_p (rtx x, rtx y)\n \t{\n \t  rtx t = l->loc;\n \n-\t  if (REG_P (t) || GET_CODE (t) == MEM)\n+\t  if (REG_P (t) || MEM_P (t))\n \t    continue;\n \t  else if (rtx_equal_for_cselib_p (x, t))\n \t    return 1;\n@@ -720,7 +720,7 @@ add_mem_for_addr (cselib_val *addr_elt, cselib_val *mem_elt, rtx x)\n \n   /* Avoid duplicates.  */\n   for (l = mem_elt->locs; l; l = l->next)\n-    if (GET_CODE (l->loc) == MEM\n+    if (MEM_P (l->loc)\n \t&& CSELIB_VAL_PTR (XEXP (l->loc, 0)) == addr_elt)\n       return;\n \n@@ -923,7 +923,7 @@ cselib_lookup (rtx x, enum machine_mode mode, int create)\n       return e;\n     }\n \n-  if (GET_CODE (x) == MEM)\n+  if (MEM_P (x))\n     return cselib_lookup_mem (x, create);\n \n   hashval = hash_rtx (x, mode, create);\n@@ -1085,7 +1085,7 @@ cselib_invalidate_mem (rtx mem_rtx)\n \n \t  /* MEMs may occur in locations only at the top level; below\n \t     that every MEM or REG is substituted by its VALUE.  */\n-\t  if (GET_CODE (x) != MEM)\n+\t  if (!MEM_P (x))\n \t    {\n \t      p = &(*p)->next;\n \t      continue;\n@@ -1148,7 +1148,7 @@ cselib_invalidate_rtx (rtx dest, rtx ignore ATTRIBUTE_UNUSED,\n \n   if (REG_P (dest))\n     cselib_invalidate_regno (REGNO (dest), GET_MODE (dest));\n-  else if (GET_CODE (dest) == MEM)\n+  else if (MEM_P (dest))\n     cselib_invalidate_mem (dest);\n \n   /* Some machines don't define AUTO_INC_DEC, but they still use push\n@@ -1199,7 +1199,7 @@ cselib_record_set (rtx dest, cselib_val *src_elt, cselib_val *dest_addr_elt)\n \tn_useless_values--;\n       src_elt->locs = new_elt_loc_list (src_elt->locs, dest);\n     }\n-  else if (GET_CODE (dest) == MEM && dest_addr_elt != 0\n+  else if (MEM_P (dest) && dest_addr_elt != 0\n \t   && cselib_record_memory)\n     {\n       if (src_elt->locs == 0)\n@@ -1275,13 +1275,13 @@ cselib_record_sets (rtx insn)\n \n       /* We don't know how to record anything but REG or MEM.  */\n       if (REG_P (dest)\n-\t  || (GET_CODE (dest) == MEM && cselib_record_memory))\n+\t  || (MEM_P (dest) && cselib_record_memory))\n         {\n \t  rtx src = sets[i].src;\n \t  if (cond)\n \t    src = gen_rtx_IF_THEN_ELSE (GET_MODE (src), cond, src, dest);\n \t  sets[i].src_elt = cselib_lookup (src, GET_MODE (dest), 1);\n-\t  if (GET_CODE (dest) == MEM)\n+\t  if (MEM_P (dest))\n \t    sets[i].dest_addr_elt = cselib_lookup (XEXP (dest, 0), Pmode, 1);\n \t  else\n \t    sets[i].dest_addr_elt = 0;\n@@ -1303,7 +1303,7 @@ cselib_record_sets (rtx insn)\n       for (i = 0; i < n_sets; i++)\n \t{\n \t  rtx dest = sets[i].dest;\n-\t  if (REG_P (dest) || GET_CODE (dest) == MEM)\n+\t  if (REG_P (dest) || MEM_P (dest))\n \t    {\n \t      int j;\n \t      for (j = i + 1; j < n_sets; j++)\n@@ -1321,7 +1321,7 @@ cselib_record_sets (rtx insn)\n     {\n       rtx dest = sets[i].dest;\n       if (REG_P (dest)\n-\t  || (GET_CODE (dest) == MEM && cselib_record_memory))\n+\t  || (MEM_P (dest) && cselib_record_memory))\n \tcselib_record_set (dest, sets[i].src_elt, sets[i].dest_addr_elt);\n     }\n }"}, {"sha": "d0d9dda44a70528010a6b33accc889fcdb22fd54", "filename": "gcc/dbxout.c", "status": "modified", "additions": 13, "deletions": 13, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fdbxout.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fdbxout.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdbxout.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -276,7 +276,7 @@ static const char *cwd;\n /* 1 if PARM is passed to this function in memory.  */\n \n #define PARM_PASSED_IN_MEMORY(PARM) \\\n- (GET_CODE (DECL_INCOMING_RTL (PARM)) == MEM)\n+ (MEM_P (DECL_INCOMING_RTL (PARM)))\n \n /* A C expression for the integer offset value of an automatic variable\n    (N_LSYM) having address X (an RTX).  */\n@@ -2169,7 +2169,7 @@ dbxout_symbol (tree decl, int local ATTRIBUTE_UNUSED)\n       context = decl_function_context (decl);\n       if (context == current_function_decl)\n \tbreak;\n-      if (GET_CODE (DECL_RTL (decl)) != MEM\n+      if (!MEM_P (DECL_RTL (decl))\n \t  || GET_CODE (XEXP (DECL_RTL (decl), 0)) != SYMBOL_REF)\n \tbreak;\n       FORCE_TEXT;\n@@ -2473,7 +2473,7 @@ dbxout_symbol_location (tree decl, tree type, const char *suffix, rtx home)\n      no letter at all, and N_LSYM, for auto variable,\n      r and N_RSYM for register variable.  */\n \n-  if (GET_CODE (home) == MEM\n+  if (MEM_P (home)\n       && GET_CODE (XEXP (home, 0)) == SYMBOL_REF)\n     {\n       if (TREE_PUBLIC (decl))\n@@ -2546,8 +2546,8 @@ dbxout_symbol_location (tree decl, tree type, const char *suffix, rtx home)\n       current_sym_code = N_RSYM;\n       current_sym_value = DBX_REGISTER_NUMBER (regno);\n     }\n-  else if (GET_CODE (home) == MEM\n-\t   && (GET_CODE (XEXP (home, 0)) == MEM\n+  else if (MEM_P (home)\n+\t   && (MEM_P (XEXP (home, 0))\n \t       || (REG_P (XEXP (home, 0))\n \t\t   && REGNO (XEXP (home, 0)) != HARD_FRAME_POINTER_REGNUM\n \t\t   && REGNO (XEXP (home, 0)) != STACK_POINTER_REGNUM\n@@ -2586,13 +2586,13 @@ dbxout_symbol_location (tree decl, tree type, const char *suffix, rtx home)\n       type = make_node (POINTER_TYPE);\n       TREE_TYPE (type) = TREE_TYPE (decl);\n     }\n-  else if (GET_CODE (home) == MEM\n+  else if (MEM_P (home)\n \t   && REG_P (XEXP (home, 0)))\n     {\n       current_sym_code = N_LSYM;\n       current_sym_value = DEBUGGER_AUTO_OFFSET (XEXP (home, 0));\n     }\n-  else if (GET_CODE (home) == MEM\n+  else if (MEM_P (home)\n \t   && GET_CODE (XEXP (home, 0)) == PLUS\n \t   && GET_CODE (XEXP (XEXP (home, 0), 1)) == CONST_INT)\n     {\n@@ -2601,7 +2601,7 @@ dbxout_symbol_location (tree decl, tree type, const char *suffix, rtx home)\n \t We want the value of that CONST_INT.  */\n       current_sym_value = DEBUGGER_AUTO_OFFSET (XEXP (home, 0));\n     }\n-  else if (GET_CODE (home) == MEM\n+  else if (MEM_P (home)\n \t   && GET_CODE (XEXP (home, 0)) == CONST)\n     {\n       /* Handle an obscure case which can arise when optimizing and\n@@ -2892,7 +2892,7 @@ dbxout_parms (tree parms)\n \t    dbxout_type (parm_type, 0);\n \t    dbxout_finish_symbol (parms);\n \t  }\n-\telse if (GET_CODE (DECL_RTL (parms)) == MEM\n+\telse if (MEM_P (DECL_RTL (parms))\n \t\t && REG_P (XEXP (DECL_RTL (parms), 0))\n \t\t && REGNO (XEXP (DECL_RTL (parms), 0)) != HARD_FRAME_POINTER_REGNUM\n \t\t && REGNO (XEXP (DECL_RTL (parms), 0)) != STACK_POINTER_REGNUM\n@@ -2946,8 +2946,8 @@ dbxout_parms (tree parms)\n \t    dbxout_type (TREE_TYPE (parms), 0);\n \t    dbxout_finish_symbol (parms);\n \t  }\n-\telse if (GET_CODE (DECL_RTL (parms)) == MEM\n-\t\t && GET_CODE (XEXP (DECL_RTL (parms), 0)) == MEM)\n+\telse if (MEM_P (DECL_RTL (parms))\n+\t\t && MEM_P (XEXP (DECL_RTL (parms), 0)))\n \t  {\n \t    /* Parm was passed via invisible reference, with the reference\n \t       living on the stack.  DECL_RTL looks like\n@@ -2973,7 +2973,7 @@ dbxout_parms (tree parms)\n \t    dbxout_type (TREE_TYPE (parms), 0);\n \t    dbxout_finish_symbol (parms);\n \t  }\n-\telse if (GET_CODE (DECL_RTL (parms)) == MEM\n+\telse if (MEM_P (DECL_RTL (parms))\n \t\t && XEXP (DECL_RTL (parms), 0) != const0_rtx\n \t\t /* ??? A constant address for a parm can happen\n \t\t    when the reg it lives in is equiv to a constant in memory.\n@@ -3064,7 +3064,7 @@ dbxout_reg_parms (tree parms)\n \t  dbxout_symbol_location (parms, TREE_TYPE (parms),\n \t\t\t\t  0, DECL_RTL (parms));\n \t/* Report parms that live in memory but not where they were passed.  */\n-\telse if (GET_CODE (DECL_RTL (parms)) == MEM\n+\telse if (MEM_P (DECL_RTL (parms))\n \t\t && ! rtx_equal_p (DECL_RTL (parms), DECL_INCOMING_RTL (parms)))\n \t  dbxout_symbol_location (parms, TREE_TYPE (parms),\n \t\t\t\t  0, DECL_RTL (parms));"}, {"sha": "76825d98b54b063f5beef784932bcd8c4d7ab872", "filename": "gcc/df.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fdf.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fdf.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdf.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -985,7 +985,7 @@ df_uses_record (struct df *df, rtx *loc, enum df_ref_type ref_type,\n     case CLOBBER:\n       /* If we are clobbering a MEM, mark any registers inside the address\n \t as being used.  */\n-      if (GET_CODE (XEXP (x, 0)) == MEM)\n+      if (MEM_P (XEXP (x, 0)))\n \tdf_uses_record (df, &XEXP (XEXP (x, 0), 0),\n \t\t\tDF_REF_REG_MEM_STORE, bb, insn, flags);\n "}, {"sha": "5ef98a1fc20ec67bb989f21ed90184a22b86b4b6", "filename": "gcc/dojump.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fdojump.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fdojump.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdojump.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -622,7 +622,7 @@ do_jump (tree exp, rtx if_false_label, rtx if_true_label)\n          sequences.  */\n       /* Copy to register to avoid generating bad insns by cse\n          from (set (mem ...) (arithop))  (set (cc0) (mem ...)).  */\n-      if (!cse_not_expected && GET_CODE (temp) == MEM)\n+      if (!cse_not_expected && MEM_P (temp))\n         temp = copy_to_reg (temp);\n #endif\n       do_pending_stack_adjust ();"}, {"sha": "34c507a090579f86be2e2bbf6b9970b849f9f71e", "filename": "gcc/dwarf2out.c", "status": "modified", "additions": 13, "deletions": 13, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fdwarf2out.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fdwarf2out.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdwarf2out.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -1000,7 +1000,7 @@ stack_adjust_offset (rtx pattern)\n       if (code == PLUS)\n \toffset = -offset;\n     }\n-  else if (GET_CODE (dest) == MEM)\n+  else if (MEM_P (dest))\n     {\n       /* (set (mem (pre_dec (reg sp))) (foo)) */\n       src = XEXP (dest, 0);\n@@ -8735,7 +8735,7 @@ mem_loc_descriptor (rtx rtl, enum machine_mode mode, bool can_use_fbreg)\n     case ADDRESSOF:\n       /* If this is a MEM, return its address.  Otherwise, we can't\n \t represent this.  */\n-      if (GET_CODE (XEXP (rtl, 0)) == MEM)\n+      if (MEM_P (XEXP (rtl, 0)))\n \treturn mem_loc_descriptor (XEXP (XEXP (rtl, 0), 0), mode,\n \t\t\t\t   can_use_fbreg);\n       else\n@@ -8927,7 +8927,7 @@ loc_descriptor_from_tree (tree loc, int addressp)\n \t  if (rtl == NULL_RTX)\n \t    return 0;\n \n-\t  if (GET_CODE (rtl) != MEM)\n+\t  if (!MEM_P (rtl))\n \t    return 0;\n \t  rtl = XEXP (rtl, 0);\n \t  if (! CONSTANT_P (rtl))\n@@ -8963,7 +8963,7 @@ loc_descriptor_from_tree (tree loc, int addressp)\n \t  {\n \t    enum machine_mode mode = GET_MODE (rtl);\n \n-\t    if (GET_CODE (rtl) == MEM)\n+\t    if (MEM_P (rtl))\n \t      {\n \t\tindirect_p = 1;\n \t\trtl = XEXP (rtl, 0);\n@@ -9045,7 +9045,7 @@ loc_descriptor_from_tree (tree loc, int addressp)\n \trtx rtl = lookup_constant_def (loc);\n \tenum machine_mode mode;\n \n-\tif (GET_CODE (rtl) != MEM)\n+\tif (!MEM_P (rtl))\n \t  return 0;\n \tmode = GET_MODE (rtl);\n \trtl = XEXP (rtl, 0);\n@@ -9823,7 +9823,7 @@ rtl_for_decl_location (tree decl)\n     {\n       if (rtl\n \t  && (CONSTANT_P (rtl)\n-\t      || (GET_CODE (rtl) == MEM\n+\t      || (MEM_P (rtl)\n \t          && CONSTANT_P (XEXP (rtl, 0)))\n \t      || (REG_P (rtl)\n \t          && TREE_CODE (decl) == VAR_DECL\n@@ -9860,11 +9860,11 @@ rtl_for_decl_location (tree decl)\n \t we reach the big endian correction code there.  It isn't clear if all\n \t of these checks are necessary here, but keeping them all is the safe\n \t thing to do.  */\n-      else if (GET_CODE (rtl) == MEM\n+      else if (MEM_P (rtl)\n \t       && XEXP (rtl, 0) != const0_rtx\n \t       && ! CONSTANT_P (XEXP (rtl, 0))\n \t       /* Not passed in memory.  */\n-\t       && GET_CODE (DECL_INCOMING_RTL (decl)) != MEM\n+\t       && !MEM_P (DECL_INCOMING_RTL (decl))\n \t       /* Not passed by invisible reference.  */\n \t       && (!REG_P (XEXP (rtl, 0))\n \t\t   || REGNO (XEXP (rtl, 0)) == HARD_FRAME_POINTER_REGNUM\n@@ -9888,7 +9888,7 @@ rtl_for_decl_location (tree decl)\n     }\n   else if (TREE_CODE (decl) == VAR_DECL\n \t   && rtl\n-\t   && GET_CODE (rtl) == MEM\n+\t   && MEM_P (rtl)\n \t   && GET_MODE (rtl) != TYPE_MODE (TREE_TYPE (decl))\n \t   && BYTES_BIG_ENDIAN)\n     {\n@@ -9949,7 +9949,7 @@ rtl_for_decl_location (tree decl)\n \t  rtl = expand_expr (DECL_INITIAL (decl), NULL_RTX, VOIDmode,\n \t\t\t     EXPAND_INITIALIZER);\n \t  /* If expand_expr returns a MEM, it wasn't immediate.  */\n-\t  if (rtl && GET_CODE (rtl) == MEM)\n+\t  if (rtl && MEM_P (rtl))\n \t    abort ();\n \t}\n     }\n@@ -10268,15 +10268,15 @@ add_bound_info (dw_die_ref subrange_die, enum dwarf_attribute bound_attr, tree b\n \t value there unless it was going to be used repeatedly in the\n \t function, i.e. for cleanups.  */\n       if (SAVE_EXPR_RTL (bound)\n-\t  && (! optimize || GET_CODE (SAVE_EXPR_RTL (bound)) == MEM))\n+\t  && (! optimize || MEM_P (SAVE_EXPR_RTL (bound))))\n \t{\n \t  dw_die_ref ctx = lookup_decl_die (current_function_decl);\n \t  dw_die_ref decl_die = new_die (DW_TAG_variable, ctx, bound);\n \t  rtx loc = SAVE_EXPR_RTL (bound);\n \n \t  /* If the RTL for the SAVE_EXPR is memory, handle the case where\n \t     it references an outer function's frame.  */\n-\t  if (GET_CODE (loc) == MEM)\n+\t  if (MEM_P (loc))\n \t    {\n \t      rtx new_addr = fix_lexical_addr (XEXP (loc, 0), bound);\n \n@@ -10848,7 +10848,7 @@ decl_start_label (tree decl)\n   const char *fnname;\n \n   x = DECL_RTL (decl);\n-  if (GET_CODE (x) != MEM)\n+  if (!MEM_P (x))\n     abort ();\n \n   x = XEXP (x, 0);"}, {"sha": "b88144b9dc8667c74929b62f496061e9f4aadf8d", "filename": "gcc/emit-rtl.c", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Femit-rtl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Femit-rtl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Femit-rtl.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -1140,7 +1140,7 @@ gen_complex_constant_part (enum machine_mode mode, rtx x, int imagpart_p)\n {\n   tree decl, part;\n \n-  if (GET_CODE (x) == MEM\n+  if (MEM_P (x)\n       && GET_CODE (XEXP (x, 0)) == SYMBOL_REF)\n     {\n       decl = SYMBOL_REF_DECL (XEXP (x, 0));\n@@ -1223,7 +1223,7 @@ gen_highpart (enum machine_mode mode, rtx x)\n   /* simplify_gen_subreg is not guaranteed to return a valid operand for\n      the target if we have a MEM.  gen_highpart must return a valid operand,\n      emitting code if necessary to do so.  */\n-  if (result != NULL_RTX && GET_CODE (result) == MEM)\n+  if (result != NULL_RTX && MEM_P (result))\n     result = validize_mem (result);\n \n   if (!result)\n@@ -1349,7 +1349,7 @@ operand_subword (rtx op, unsigned int offset, int validate_address, enum machine\n     return const0_rtx;\n \n   /* Form a new MEM at the requested address.  */\n-  if (GET_CODE (op) == MEM)\n+  if (MEM_P (op))\n     {\n       rtx new = adjust_address_nv (op, word_mode, offset * UNITS_PER_WORD);\n \n@@ -1802,7 +1802,7 @@ change_address_1 (rtx memref, enum machine_mode mode, rtx addr, int validate)\n {\n   rtx new;\n \n-  if (GET_CODE (memref) != MEM)\n+  if (!MEM_P (memref))\n     abort ();\n   if (mode == VOIDmode)\n     mode = GET_MODE (memref);\n@@ -2785,7 +2785,7 @@ make_safe_from (rtx x, rtx other)\n \tgoto done;\n       }\n  done:\n-  if ((GET_CODE (other) == MEM\n+  if ((MEM_P (other)\n        && ! CONSTANT_P (x)\n        && !REG_P (x)\n        && GET_CODE (x) != SUBREG)"}, {"sha": "99d39362bb3f971478fce48d29ae4eca98c46372", "filename": "gcc/explow.c", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fexplow.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fexplow.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexplow.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -283,7 +283,7 @@ int_expr_size (tree exp)\n static rtx\n break_out_memory_refs (rtx x)\n {\n-  if (GET_CODE (x) == MEM\n+  if (MEM_P (x)\n       || (CONSTANT_P (x) && CONSTANT_ADDRESS_P (x)\n \t  && GET_MODE (x) != VOIDmode))\n     x = force_reg (GET_MODE (x), x);\n@@ -414,7 +414,7 @@ copy_all_regs (rtx x)\n \t  )\n \tx = copy_to_reg (x);\n     }\n-  else if (GET_CODE (x) == MEM)\n+  else if (MEM_P (x))\n     x = copy_to_reg (x);\n   else if (GET_CODE (x) == PLUS || GET_CODE (x) == MINUS\n \t   || GET_CODE (x) == MULT)\n@@ -574,7 +574,7 @@ memory_address_noforce (enum machine_mode mode, rtx x)\n rtx\n validize_mem (rtx ref)\n {\n-  if (GET_CODE (ref) != MEM)\n+  if (!MEM_P (ref))\n     return ref;\n   if (! (flag_force_addr && CONSTANT_ADDRESS_P (XEXP (ref, 0)))\n       && memory_address_p (GET_MODE (ref), XEXP (ref, 0)))\n@@ -620,7 +620,7 @@ maybe_set_unchanging (rtx ref, tree t)\n rtx\n stabilize (rtx x)\n {\n-  if (GET_CODE (x) != MEM\n+  if (!MEM_P (x)\n       || ! rtx_unstable_p (XEXP (x, 0)))\n     return x;\n \n@@ -763,7 +763,7 @@ force_not_mem (rtx x)\n {\n   rtx temp;\n \n-  if (GET_CODE (x) != MEM || GET_MODE (x) == BLKmode)\n+  if (!MEM_P (x) || GET_MODE (x) == BLKmode)\n     return x;\n \n   temp = gen_reg_rtx (GET_MODE (x));"}, {"sha": "40213da57d08d6e6a2f0304a6971a87dc68177c7", "filename": "gcc/expmed.c", "status": "modified", "additions": 32, "deletions": 32, "changes": 64, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fexpmed.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fexpmed.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpmed.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -300,7 +300,7 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \t\t rtx value, HOST_WIDE_INT total_size)\n {\n   unsigned int unit\n-    = (GET_CODE (str_rtx) == MEM) ? BITS_PER_UNIT : BITS_PER_WORD;\n+    = (MEM_P (str_rtx)) ? BITS_PER_UNIT : BITS_PER_WORD;\n   unsigned HOST_WIDE_INT offset = bitnum / unit;\n   unsigned HOST_WIDE_INT bitpos = bitnum % unit;\n   rtx op0 = str_rtx;\n@@ -332,7 +332,7 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n   /* Use vec_extract patterns for extracting parts of vectors whenever\n      available.  */\n   if (VECTOR_MODE_P (GET_MODE (op0))\n-      && GET_CODE (op0) != MEM\n+      && !MEM_P (op0)\n       && (vec_set_optab->handlers[GET_MODE (op0)].insn_code\n \t  != CODE_FOR_nothing)\n       && fieldmode == GET_MODE_INNER (GET_MODE (op0))\n@@ -396,7 +396,7 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \n   if (bitpos == 0\n       && bitsize == GET_MODE_BITSIZE (fieldmode)\n-      && (GET_CODE (op0) != MEM\n+      && (!MEM_P (op0)\n \t  ? ((GET_MODE_SIZE (fieldmode) >= UNITS_PER_WORD\n \t     || GET_MODE_SIZE (GET_MODE (op0)) == GET_MODE_SIZE (fieldmode))\n \t     && byte_offset % GET_MODE_SIZE (fieldmode) == 0)\n@@ -435,7 +435,7 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n     enum machine_mode imode = int_mode_for_mode (GET_MODE (op0));\n     if (imode != GET_MODE (op0))\n       {\n-\tif (GET_CODE (op0) == MEM)\n+\tif (MEM_P (op0))\n \t  op0 = adjust_address (op0, imode, 0);\n \telse if (imode != BLKmode)\n \t  op0 = gen_lowpart (imode, op0);\n@@ -446,7 +446,7 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \n   /* We may be accessing data outside the field, which means\n      we can alias adjacent data.  */\n-  if (GET_CODE (op0) == MEM)\n+  if (MEM_P (op0))\n     {\n       op0 = shallow_copy_rtx (op0);\n       set_mem_alias_set (op0, 0);\n@@ -457,14 +457,14 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n      But as we have it, it counts within whatever size OP0 now has.\n      On a bigendian machine, these are not the same, so convert.  */\n   if (BYTES_BIG_ENDIAN\n-      && GET_CODE (op0) != MEM\n+      && !MEM_P (op0)\n       && unit > GET_MODE_BITSIZE (GET_MODE (op0)))\n     bitpos += unit - GET_MODE_BITSIZE (GET_MODE (op0));\n \n   /* Storing an lsb-aligned field in a register\n      can be done with a movestrict instruction.  */\n \n-  if (GET_CODE (op0) != MEM\n+  if (!MEM_P (op0)\n       && (BYTES_BIG_ENDIAN ? bitpos + bitsize == unit : bitpos == 0)\n       && bitsize == GET_MODE_BITSIZE (fieldmode)\n       && (movstrict_optab->handlers[fieldmode].insn_code\n@@ -554,7 +554,7 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n   /* OFFSET is the number of words or bytes (UNIT says which)\n      from STR_RTX to the first word or byte containing part of the field.  */\n \n-  if (GET_CODE (op0) != MEM)\n+  if (!MEM_P (op0))\n     {\n       if (offset != 0\n \t  || GET_MODE_SIZE (GET_MODE (op0)) > UNITS_PER_WORD)\n@@ -615,7 +615,7 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \t into a register and save it back later.  */\n       /* This used to check flag_force_mem, but that was a serious\n \t de-optimization now that flag_force_mem is enabled by -O2.  */\n-      if (GET_CODE (op0) == MEM\n+      if (MEM_P (op0)\n \t  && ! ((*insn_data[(int) CODE_FOR_insv].operand[0].predicate)\n \t\t(op0, VOIDmode)))\n \t{\n@@ -658,7 +658,7 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n       volatile_ok = save_volatile_ok;\n \n       /* Add OFFSET into OP0's address.  */\n-      if (GET_CODE (xop0) == MEM)\n+      if (MEM_P (xop0))\n \txop0 = adjust_address (xop0, byte_mode, offset);\n \n       /* If xop0 is a register, we need it in MAXMODE\n@@ -678,7 +678,7 @@ store_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \n       /* We have been counting XBITPOS within UNIT.\n \t Count instead within the size of the register.  */\n-      if (BITS_BIG_ENDIAN && GET_CODE (xop0) != MEM)\n+      if (BITS_BIG_ENDIAN && !MEM_P (xop0))\n \txbitpos += GET_MODE_BITSIZE (maxmode) - unit;\n \n       unit = GET_MODE_BITSIZE (maxmode);\n@@ -971,7 +971,7 @@ store_split_bit_field (rtx op0, unsigned HOST_WIDE_INT bitsize,\n \t  /* We must do an endian conversion exactly the same way as it is\n \t     done in extract_bit_field, so that the two calls to\n \t     extract_fixed_bit_field will have comparable arguments.  */\n-\t  if (GET_CODE (value) != MEM || GET_MODE (value) == BLKmode)\n+\t  if (!MEM_P (value) || GET_MODE (value) == BLKmode)\n \t    total_bits = BITS_PER_WORD;\n \t  else\n \t    total_bits = GET_MODE_BITSIZE (GET_MODE (value));\n@@ -1057,7 +1057,7 @@ extract_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \t\t   HOST_WIDE_INT total_size)\n {\n   unsigned int unit\n-    = (GET_CODE (str_rtx) == MEM) ? BITS_PER_UNIT : BITS_PER_WORD;\n+    = (MEM_P (str_rtx)) ? BITS_PER_UNIT : BITS_PER_WORD;\n   unsigned HOST_WIDE_INT offset = bitnum / unit;\n   unsigned HOST_WIDE_INT bitpos = bitnum % unit;\n   rtx op0 = str_rtx;\n@@ -1101,7 +1101,7 @@ extract_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n   /* Use vec_extract patterns for extracting parts of vectors whenever\n      available.  */\n   if (VECTOR_MODE_P (GET_MODE (op0))\n-      && GET_CODE (op0) != MEM\n+      && !MEM_P (op0)\n       && (vec_extract_optab->handlers[GET_MODE (op0)].insn_code\n \t  != CODE_FOR_nothing)\n       && ((bitsize + bitnum) / GET_MODE_BITSIZE (GET_MODE_INNER (GET_MODE (op0)))\n@@ -1159,7 +1159,7 @@ extract_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n     enum machine_mode imode = int_mode_for_mode (GET_MODE (op0));\n     if (imode != GET_MODE (op0))\n       {\n-\tif (GET_CODE (op0) == MEM)\n+\tif (MEM_P (op0))\n \t  op0 = adjust_address (op0, imode, 0);\n \telse if (imode != BLKmode)\n \t  op0 = gen_lowpart (imode, op0);\n@@ -1170,7 +1170,7 @@ extract_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \n   /* We may be accessing data outside the field, which means\n      we can alias adjacent data.  */\n-  if (GET_CODE (op0) == MEM)\n+  if (MEM_P (op0))\n     {\n       op0 = shallow_copy_rtx (op0);\n       set_mem_alias_set (op0, 0);\n@@ -1189,7 +1189,7 @@ extract_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n      But as we have it, it counts within whatever size OP0 now has.\n      On a bigendian machine, these are not the same, so convert.  */\n   if (BYTES_BIG_ENDIAN\n-      && GET_CODE (op0) != MEM\n+      && !MEM_P (op0)\n       && unit > GET_MODE_BITSIZE (GET_MODE (op0)))\n     bitpos += unit - GET_MODE_BITSIZE (GET_MODE (op0));\n \n@@ -1216,12 +1216,12 @@ extract_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \t   && (BYTES_BIG_ENDIAN\n \t       ? bitpos + bitsize == BITS_PER_WORD\n \t       : bitpos == 0)))\n-      && ((GET_CODE (op0) != MEM\n+      && ((!MEM_P (op0)\n \t   && TRULY_NOOP_TRUNCATION (GET_MODE_BITSIZE (mode),\n \t\t\t\t     GET_MODE_BITSIZE (GET_MODE (op0)))\n \t   && GET_MODE_SIZE (mode1) != 0\n \t   && byte_offset % GET_MODE_SIZE (mode1) == 0)\n-\t  || (GET_CODE (op0) == MEM\n+\t  || (MEM_P (op0)\n \t      && (! SLOW_UNALIGNED_ACCESS (mode, MEM_ALIGN (op0))\n \t\t  || (offset * BITS_PER_UNIT % bitsize == 0\n \t\t      && MEM_ALIGN (op0) % bitsize == 0)))))\n@@ -1342,7 +1342,7 @@ extract_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n   /* OFFSET is the number of words or bytes (UNIT says which)\n      from STR_RTX to the first word or byte containing part of the field.  */\n \n-  if (GET_CODE (op0) != MEM)\n+  if (!MEM_P (op0))\n     {\n       if (offset != 0\n \t  || GET_MODE_SIZE (GET_MODE (op0)) > UNITS_PER_WORD)\n@@ -1376,7 +1376,7 @@ extract_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \t  rtx pat;\n \t  enum machine_mode maxmode = mode_for_extraction (EP_extzv, 0);\n \n-\t  if (GET_CODE (xop0) == MEM)\n+\t  if (MEM_P (xop0))\n \t    {\n \t      int save_volatile_ok = volatile_ok;\n \t      volatile_ok = 1;\n@@ -1440,13 +1440,13 @@ extract_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \t    xbitpos = unit - bitsize - xbitpos;\n \n \t  /* Now convert from counting within UNIT to counting in MAXMODE.  */\n-\t  if (BITS_BIG_ENDIAN && GET_CODE (xop0) != MEM)\n+\t  if (BITS_BIG_ENDIAN && !MEM_P (xop0))\n \t    xbitpos += GET_MODE_BITSIZE (maxmode) - unit;\n \n \t  unit = GET_MODE_BITSIZE (maxmode);\n \n \t  if (xtarget == 0\n-\t      || (flag_force_mem && GET_CODE (xtarget) == MEM))\n+\t      || (flag_force_mem && MEM_P (xtarget)))\n \t    xtarget = xspec_target = gen_reg_rtx (tmode);\n \n \t  if (GET_MODE (xtarget) != maxmode)\n@@ -1509,7 +1509,7 @@ extract_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \t  rtx pat;\n \t  enum machine_mode maxmode = mode_for_extraction (EP_extv, 0);\n \n-\t  if (GET_CODE (xop0) == MEM)\n+\t  if (MEM_P (xop0))\n \t    {\n \t      /* Is the memory operand acceptable?  */\n \t      if (! ((*insn_data[(int) CODE_FOR_extv].operand[1].predicate)\n@@ -1569,13 +1569,13 @@ extract_bit_field (rtx str_rtx, unsigned HOST_WIDE_INT bitsize,\n \n \t  /* XBITPOS counts within a size of UNIT.\n \t     Adjust to count within a size of MAXMODE.  */\n-\t  if (BITS_BIG_ENDIAN && GET_CODE (xop0) != MEM)\n+\t  if (BITS_BIG_ENDIAN && !MEM_P (xop0))\n \t    xbitpos += (GET_MODE_BITSIZE (maxmode) - unit);\n \n \t  unit = GET_MODE_BITSIZE (maxmode);\n \n \t  if (xtarget == 0\n-\t      || (flag_force_mem && GET_CODE (xtarget) == MEM))\n+\t      || (flag_force_mem && MEM_P (xtarget)))\n \t    xtarget = xspec_target = gen_reg_rtx (tmode);\n \n \t  if (GET_MODE (xtarget) != maxmode)\n@@ -2514,7 +2514,7 @@ expand_mult_const (enum machine_mode mode, rtx op0, HOST_WIDE_INT val,\n \n   /* Avoid referencing memory over and over.\n      For speed, but also for correctness when mem is volatile.  */\n-  if (GET_CODE (op0) == MEM)\n+  if (MEM_P (op0))\n     op0 = force_reg (mode, op0);\n \n   /* ACCUM starts out either as OP0 or as a zero, depending on\n@@ -3290,9 +3290,9 @@ expand_divmod (int rem_flag, enum tree_code code, enum machine_mode mode,\n \t  /* Don't clobber an operand while doing a multi-step calculation.  */\n \t  || ((rem_flag || op1_is_constant)\n \t      && (reg_mentioned_p (target, op0)\n-\t\t  || (GET_CODE (op0) == MEM && GET_CODE (target) == MEM)))\n+\t\t  || (MEM_P (op0) && MEM_P (target))))\n \t  || reg_mentioned_p (target, op1)\n-\t  || (GET_CODE (op1) == MEM && GET_CODE (target) == MEM)))\n+\t  || (MEM_P (op1) && MEM_P (target))))\n     target = 0;\n \n   /* Get the mode in which to perform this computation.  Normally it will\n@@ -3381,9 +3381,9 @@ expand_divmod (int rem_flag, enum tree_code code, enum machine_mode mode,\n \n   /* If one of the operands is a volatile MEM, copy it into a register.  */\n \n-  if (GET_CODE (op0) == MEM && MEM_VOLATILE_P (op0))\n+  if (MEM_P (op0) && MEM_VOLATILE_P (op0))\n     op0 = force_reg (compute_mode, op0);\n-  if (GET_CODE (op1) == MEM && MEM_VOLATILE_P (op1))\n+  if (MEM_P (op1) && MEM_VOLATILE_P (op1))\n     op1 = force_reg (compute_mode, op1);\n \n   /* If we need the remainder or if OP1 is constant, we need to\n@@ -4610,7 +4610,7 @@ emit_store_flag (rtx target, enum rtx_code code, rtx op0, rtx op1,\n   if (GET_MODE_BITSIZE (mode) == BITS_PER_WORD * 2\n       && GET_MODE_CLASS (mode) == MODE_INT\n       && op1 == const0_rtx\n-      && (GET_CODE (op0) != MEM || ! MEM_VOLATILE_P (op0)))\n+      && (!MEM_P (op0) || ! MEM_VOLATILE_P (op0)))\n     {\n       if (code == EQ || code == NE)\n \t{"}, {"sha": "9bc77212a5c356a4c61e76a29d64bf73a2ef193c", "filename": "gcc/expr.c", "status": "modified", "additions": 72, "deletions": 72, "changes": 144, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -792,7 +792,7 @@ convert_move (rtx to, rtx from, int unsignedp)\n   if (GET_MODE_BITSIZE (from_mode) > BITS_PER_WORD\n       && GET_MODE_BITSIZE (to_mode) <= BITS_PER_WORD)\n     {\n-      if (!((GET_CODE (from) == MEM\n+      if (!((MEM_P (from)\n \t     && ! MEM_VOLATILE_P (from)\n \t     && direct_load[(int) to_mode]\n \t     && ! mode_dependent_address_p (XEXP (from, 0)))\n@@ -811,7 +811,7 @@ convert_move (rtx to, rtx from, int unsignedp)\n       && TRULY_NOOP_TRUNCATION (GET_MODE_BITSIZE (to_mode),\n \t\t\t\tGET_MODE_BITSIZE (from_mode)))\n     {\n-      if (!((GET_CODE (from) == MEM\n+      if (!((MEM_P (from)\n \t     && ! MEM_VOLATILE_P (from)\n \t     && direct_load[(int) to_mode]\n \t     && ! mode_dependent_address_p (XEXP (from, 0)))\n@@ -984,7 +984,7 @@ convert_modes (enum machine_mode mode, enum machine_mode oldmode, rtx x, int uns\n \t  && GET_MODE_CLASS (oldmode) == MODE_INT\n \t  && (GET_CODE (x) == CONST_DOUBLE\n \t      || (GET_MODE_SIZE (mode) <= GET_MODE_SIZE (oldmode)\n-\t\t  && ((GET_CODE (x) == MEM && ! MEM_VOLATILE_P (x)\n+\t\t  && ((MEM_P (x) && ! MEM_VOLATILE_P (x)\n \t\t       && direct_load[(int) mode])\n \t\t      || (REG_P (x)\n \t\t\t  && (! HARD_REGISTER_P (x)\n@@ -1358,9 +1358,9 @@ emit_block_move (rtx x, rtx y, rtx size, enum block_op_methods method)\n   y = protect_from_queue (y, 0);\n   size = protect_from_queue (size, 0);\n \n-  if (GET_CODE (x) != MEM)\n+  if (!MEM_P (x))\n     abort ();\n-  if (GET_CODE (y) != MEM)\n+  if (!MEM_P (y))\n     abort ();\n   if (size == 0)\n     abort ();\n@@ -1883,7 +1883,7 @@ emit_group_load (rtx dst, rtx orig_src, tree type ATTRIBUTE_UNUSED, int ssize)\n \t from strange tricks we might play; but make sure that the source can\n \t be loaded directly into the destination.  */\n       src = orig_src;\n-      if (GET_CODE (orig_src) != MEM\n+      if (!MEM_P (orig_src)\n \t  && (!CONSTANT_P (orig_src)\n \t      || (GET_MODE (orig_src) != mode\n \t\t  && GET_MODE (orig_src) != VOIDmode)))\n@@ -1897,7 +1897,7 @@ emit_group_load (rtx dst, rtx orig_src, tree type ATTRIBUTE_UNUSED, int ssize)\n \t}\n \n       /* Optimize the access just a bit.  */\n-      if (GET_CODE (src) == MEM\n+      if (MEM_P (src)\n \t  && (! SLOW_UNALIGNED_ACCESS (mode, MEM_ALIGN (src))\n \t      || MEM_ALIGN (src) >= GET_MODE_ALIGNMENT (mode))\n \t  && bytepos * BITS_PER_UNIT % GET_MODE_ALIGNMENT (mode) == 0\n@@ -2043,7 +2043,7 @@ emit_group_store (rtx orig_dst, rtx src, tree type ATTRIBUTE_UNUSED, int ssize)\n       emit_group_load (dst, temp, type, ssize);\n       return;\n     }\n-  else if (GET_CODE (dst) != MEM && GET_CODE (dst) != CONCAT)\n+  else if (!MEM_P (dst) && GET_CODE (dst) != CONCAT)\n     {\n       dst = gen_reg_rtx (GET_MODE (orig_dst));\n       /* Make life a bit easier for combine.  */\n@@ -2102,7 +2102,7 @@ emit_group_store (rtx orig_dst, rtx src, tree type ATTRIBUTE_UNUSED, int ssize)\n \t}\n \n       /* Optimize the access just a bit.  */\n-      if (GET_CODE (dest) == MEM\n+      if (MEM_P (dest)\n \t  && (! SLOW_UNALIGNED_ACCESS (mode, MEM_ALIGN (dest))\n \t      || MEM_ALIGN (dest) >= GET_MODE_ALIGNMENT (mode))\n \t  && bytepos * BITS_PER_UNIT % GET_MODE_ALIGNMENT (mode) == 0\n@@ -2560,7 +2560,7 @@ rtx\n clear_storage (rtx object, rtx size)\n {\n   rtx retval = 0;\n-  unsigned int align = (GET_CODE (object) == MEM ? MEM_ALIGN (object)\n+  unsigned int align = (MEM_P (object) ? MEM_ALIGN (object)\n \t\t\t: GET_MODE_ALIGNMENT (GET_MODE (object)));\n \n   /* If OBJECT is not BLKmode and SIZE is the same size as its mode,\n@@ -2824,14 +2824,14 @@ emit_move_insn (rtx x, rtx y)\n \n   /* If X or Y are memory references, verify that their addresses are valid\n      for the machine.  */\n-  if (GET_CODE (x) == MEM\n+  if (MEM_P (x)\n       && ((! memory_address_p (GET_MODE (x), XEXP (x, 0))\n \t   && ! push_operand (x, GET_MODE (x)))\n \t  || (flag_force_addr\n \t      && CONSTANT_ADDRESS_P (XEXP (x, 0)))))\n     x = validize_mem (x);\n \n-  if (GET_CODE (y) == MEM\n+  if (MEM_P (y)\n       && (! memory_address_p (GET_MODE (y), XEXP (y, 0))\n \t  || (flag_force_addr\n \t      && CONSTANT_ADDRESS_P (XEXP (y, 0)))))\n@@ -3056,14 +3056,14 @@ emit_move_insn_1 (rtx x, rtx y)\n       if (reload_in_progress)\n \t{\n \t  x = gen_lowpart_common (tmode, x1);\n-\t  if (x == 0 && GET_CODE (x1) == MEM)\n+\t  if (x == 0 && MEM_P (x1))\n \t    {\n \t      x = adjust_address_nv (x1, tmode, 0);\n \t      copy_replacements (x1, x);\n \t    }\n \n \t  y = gen_lowpart_common (tmode, y1);\n-\t  if (y == 0 && GET_CODE (y1) == MEM)\n+\t  if (y == 0 && MEM_P (y1))\n \t    {\n \t      y = adjust_address_nv (y1, tmode, 0);\n \t      copy_replacements (y1, y);\n@@ -3145,10 +3145,10 @@ emit_move_insn_1 (rtx x, rtx y)\n \n       /* If we are in reload, see if either operand is a MEM whose address\n \t is scheduled for replacement.  */\n-      if (reload_in_progress && GET_CODE (x) == MEM\n+      if (reload_in_progress && MEM_P (x)\n \t  && (inner = find_replacement (&XEXP (x, 0))) != XEXP (x, 0))\n \tx = replace_equiv_address_nv (x, inner);\n-      if (reload_in_progress && GET_CODE (y) == MEM\n+      if (reload_in_progress && MEM_P (y)\n \t  && (inner = find_replacement (&XEXP (y, 0))) != XEXP (y, 0))\n \ty = replace_equiv_address_nv (y, inner);\n \n@@ -3791,7 +3791,7 @@ expand_assignment (tree to, tree from, int want_value)\n \t{\n \t  rtx offset_rtx = expand_expr (offset, NULL_RTX, VOIDmode, EXPAND_SUM);\n \n-\t  if (GET_CODE (to_rtx) != MEM)\n+\t  if (!MEM_P (to_rtx))\n \t    abort ();\n \n #ifdef POINTERS_EXTEND_UNSIGNED\n@@ -3804,7 +3804,7 @@ expand_assignment (tree to, tree from, int want_value)\n \n \t  /* A constant address in TO_RTX can have VOIDmode, we must not try\n \t     to call force_reg for that case.  Avoid that case.  */\n-\t  if (GET_CODE (to_rtx) == MEM\n+\t  if (MEM_P (to_rtx)\n \t      && GET_MODE (to_rtx) == BLKmode\n \t      && GET_MODE (XEXP (to_rtx, 0)) != VOIDmode\n \t      && bitsize > 0\n@@ -3821,7 +3821,7 @@ expand_assignment (tree to, tree from, int want_value)\n \t\t\t\t   \t\t\t\t   offset));\n \t}\n \n-      if (GET_CODE (to_rtx) == MEM)\n+      if (MEM_P (to_rtx))\n \t{\n \t  /* If the field is at offset zero, we could have been given the\n \t     DECL_RTX of the parent struct.  Don't munge it.  */\n@@ -3832,7 +3832,7 @@ expand_assignment (tree to, tree from, int want_value)\n \n       /* Deal with volatile and readonly fields.  The former is only done\n \t for MEM.  Also set MEM_KEEP_ALIAS_SET_P if needed.  */\n-      if (volatilep && GET_CODE (to_rtx) == MEM)\n+      if (volatilep && MEM_P (to_rtx))\n \t{\n \t  if (to_rtx == orig_to_rtx)\n \t    to_rtx = copy_rtx (to_rtx);\n@@ -3844,14 +3844,14 @@ expand_assignment (tree to, tree from, int want_value)\n \t  /* We can't assert that a MEM won't be set more than once\n \t     if the component is not addressable because another\n \t     non-addressable component may be referenced by the same MEM.  */\n-\t  && ! (GET_CODE (to_rtx) == MEM && ! can_address_p (to)))\n+\t  && ! (MEM_P (to_rtx) && ! can_address_p (to)))\n \t{\n \t  if (to_rtx == orig_to_rtx)\n \t    to_rtx = copy_rtx (to_rtx);\n \t  RTX_UNCHANGING_P (to_rtx) = 1;\n \t}\n \n-      if (GET_CODE (to_rtx) == MEM && ! can_address_p (to))\n+      if (MEM_P (to_rtx) && ! can_address_p (to))\n \t{\n \t  if (to_rtx == orig_to_rtx)\n \t    to_rtx = copy_rtx (to_rtx);\n@@ -4152,7 +4152,7 @@ store_expr (tree exp, rtx target, int want_value)\n \tdont_return_target = 1;\n     }\n   else if ((want_value & 1) != 0\n-\t   && GET_CODE (target) == MEM\n+\t   && MEM_P (target)\n \t   && ! MEM_VOLATILE_P (target)\n \t   && GET_MODE (target) != BLKmode)\n     /* If target is in memory and caller wants value in a register instead,\n@@ -4216,7 +4216,7 @@ store_expr (tree exp, rtx target, int want_value)\n \t only necessary if the MEM is volatile, or if the address\n \t overlaps TARGET.  But not performing the load twice also\n \t reduces the amount of rtl we generate and then have to CSE.  */\n-      if (GET_CODE (temp) == MEM && (want_value & 1) != 0)\n+      if (MEM_P (temp) && (want_value & 1) != 0)\n \ttemp = copy_to_reg (temp);\n \n       /* If TEMP is a VOIDmode constant, use convert_modes to make\n@@ -4269,7 +4269,7 @@ store_expr (tree exp, rtx target, int want_value)\n \t or if we really want the correct value.  */\n       if (!(target && REG_P (target)\n \t    && REGNO (target) < FIRST_PSEUDO_REGISTER)\n-\t  && !(GET_CODE (target) == MEM && MEM_VOLATILE_P (target))\n+\t  && !(MEM_P (target) && MEM_VOLATILE_P (target))\n \t  && ! rtx_equal_p (temp, target)\n \t  && (CONSTANT_P (temp) || (want_value & 1) != 0))\n \tdont_return_target = 1;\n@@ -4427,7 +4427,7 @@ store_expr (tree exp, rtx target, int want_value)\n \n   /* If we are supposed to return TEMP, do so as long as it isn't a MEM.\n      ??? The latter test doesn't seem to make sense.  */\n-  else if (dont_return_target && GET_CODE (temp) != MEM)\n+  else if (dont_return_target && !MEM_P (temp))\n     return temp;\n \n   /* Return TARGET itself if it is a hard register.  */\n@@ -4651,9 +4651,9 @@ store_constructor_field (rtx target, unsigned HOST_WIDE_INT bitsize,\n       /* If we have a nonzero bitpos for a register target, then we just\n \t let store_field do the bitfield handling.  This is unlikely to\n \t generate unnecessary clear instructions anyways.  */\n-      && (bitpos == 0 || GET_CODE (target) == MEM))\n+      && (bitpos == 0 || MEM_P (target)))\n     {\n-      if (GET_CODE (target) == MEM)\n+      if (MEM_P (target))\n \ttarget\n \t  = adjust_address (target,\n \t\t\t    GET_MODE (target) == BLKmode\n@@ -4663,7 +4663,7 @@ store_constructor_field (rtx target, unsigned HOST_WIDE_INT bitsize,\n \n \n       /* Update the alias set, if required.  */\n-      if (GET_CODE (target) == MEM && ! MEM_KEEP_ALIAS_SET_P (target)\n+      if (MEM_P (target) && ! MEM_KEEP_ALIAS_SET_P (target)\n \t  && MEM_ALIAS_SET (target) != 0)\n \t{\n \t  target = copy_rtx (target);\n@@ -4800,7 +4800,7 @@ store_constructor (tree exp, rtx target, int cleared, HOST_WIDE_INT size)\n \t\t\t\t\t\t\t     target));\n \n \t      offset_rtx = expand_expr (offset, NULL_RTX, VOIDmode, 0);\n-\t      if (GET_CODE (to_rtx) != MEM)\n+\t      if (!MEM_P (to_rtx))\n \t\tabort ();\n \n #ifdef POINTERS_EXTEND_UNSIGNED\n@@ -4817,7 +4817,7 @@ store_constructor (tree exp, rtx target, int cleared, HOST_WIDE_INT size)\n \n \t  if (TREE_READONLY (field))\n \t    {\n-\t      if (GET_CODE (to_rtx) == MEM)\n+\t      if (MEM_P (to_rtx))\n \t\tto_rtx = copy_rtx (to_rtx);\n \n \t      RTX_UNCHANGING_P (to_rtx) = 1;\n@@ -4854,7 +4854,7 @@ store_constructor (tree exp, rtx target, int cleared, HOST_WIDE_INT size)\n \t    }\n #endif\n \n-\t  if (GET_CODE (to_rtx) == MEM && !MEM_KEEP_ALIAS_SET_P (to_rtx)\n+\t  if (MEM_P (to_rtx) && !MEM_KEEP_ALIAS_SET_P (to_rtx)\n \t      && DECL_NONADDRESSABLE_P (field))\n \t    {\n \t      to_rtx = copy_rtx (to_rtx);\n@@ -5032,7 +5032,7 @@ store_constructor (tree exp, rtx target, int cleared, HOST_WIDE_INT size)\n \t\t  && (lo = tree_low_cst (lo_index, 0),\n \t\t      hi = tree_low_cst (hi_index, 0),\n \t\t      count = hi - lo + 1,\n-\t\t      (GET_CODE (target) != MEM\n+\t\t      (!MEM_P (target)\n \t\t       || count <= 2\n \t\t       || (host_integerp (TYPE_SIZE (elttype), 1)\n \t\t\t   && (tree_low_cst (TYPE_SIZE (elttype), 1) * count\n@@ -5043,7 +5043,7 @@ store_constructor (tree exp, rtx target, int cleared, HOST_WIDE_INT size)\n \t\t    {\n \t\t      bitpos = lo * tree_low_cst (TYPE_SIZE (elttype), 0);\n \n-\t\t      if (GET_CODE (target) == MEM\n+\t\t      if (MEM_P (target)\n \t\t\t  && !MEM_KEEP_ALIAS_SET_P (target)\n \t\t\t  && TREE_CODE (type) == ARRAY_TYPE\n \t\t\t  && TYPE_NONALIASED_COMPONENT (type))\n@@ -5165,7 +5165,7 @@ store_constructor (tree exp, rtx target, int cleared, HOST_WIDE_INT size)\n \t      else\n \t\tbitpos = (i * tree_low_cst (TYPE_SIZE (elttype), 1));\n \n-\t      if (GET_CODE (target) == MEM && !MEM_KEEP_ALIAS_SET_P (target)\n+\t      if (MEM_P (target) && !MEM_KEEP_ALIAS_SET_P (target)\n \t\t  && TREE_CODE (type) == ARRAY_TYPE\n \t\t  && TYPE_NONALIASED_COMPONENT (type))\n \t\t{\n@@ -5254,7 +5254,7 @@ store_constructor (tree exp, rtx target, int cleared, HOST_WIDE_INT size)\n \t\t      /* The assumption here is that it is safe to use\n \t\t\t XEXP if the set is multi-word, but not if\n \t\t\t it's single-word.  */\n-\t\t      if (GET_CODE (target) == MEM)\n+\t\t      if (MEM_P (target))\n \t\t\tto_rtx = adjust_address (target, mode, offset);\n \t\t      else if (offset == 0)\n \t\t\tto_rtx = target;\n@@ -5325,7 +5325,7 @@ store_constructor (tree exp, rtx target, int cleared, HOST_WIDE_INT size)\n \t      emit_move_insn (targetx, target);\n \t    }\n \n-\t  else if (GET_CODE (target) == MEM)\n+\t  else if (MEM_P (target))\n \t    targetx = target;\n \t  else\n \t    abort ();\n@@ -5486,7 +5486,7 @@ store_field (rtx target, HOST_WIDE_INT bitsize, HOST_WIDE_INT bitpos,\n \t boundary.  If so, we simply do a block copy.  */\n       if (GET_MODE (target) == BLKmode && GET_MODE (temp) == BLKmode)\n \t{\n-\t  if (GET_CODE (target) != MEM || GET_CODE (temp) != MEM\n+\t  if (!MEM_P (target) || !MEM_P (temp)\n \t      || bitpos % BITS_PER_UNIT != 0)\n \t    abort ();\n \n@@ -5508,7 +5508,7 @@ store_field (rtx target, HOST_WIDE_INT bitsize, HOST_WIDE_INT bitpos,\n \t  /* The caller wants an rtx for the value.\n \t     If possible, avoid refetching from the bitfield itself.  */\n \t  if (width_mask != 0\n-\t      && ! (GET_CODE (target) == MEM && MEM_VOLATILE_P (target)))\n+\t      && ! (MEM_P (target) && MEM_VOLATILE_P (target)))\n \t    {\n \t      tree count;\n \t      enum machine_mode tmode;\n@@ -5829,7 +5829,7 @@ force_operand (rtx value, rtx target)\n   /* Check for subreg applied to an expression produced by loop optimizer.  */\n   if (code == SUBREG\n       && !REG_P (SUBREG_REG (value))\n-      && GET_CODE (SUBREG_REG (value)) != MEM)\n+      && !MEM_P (SUBREG_REG (value)))\n     {\n       value = simplify_gen_subreg (GET_MODE (value),\n \t\t\t\t   force_reg (GET_MODE (SUBREG_REG (value)),\n@@ -5940,7 +5940,7 @@ force_operand (rtx value, rtx target)\n #ifdef INSN_SCHEDULING\n   /* On machines that have insn scheduling, we want all memory reference to be\n      explicit, so we need to deal with such paradoxical SUBREGs.  */\n-  if (GET_CODE (value) == SUBREG && GET_CODE (SUBREG_REG (value)) == MEM\n+  if (GET_CODE (value) == SUBREG && MEM_P (SUBREG_REG (value))\n       && (GET_MODE_SIZE (GET_MODE (value))\n \t  > GET_MODE_SIZE (GET_MODE (SUBREG_REG (value)))))\n     value\n@@ -5985,7 +5985,7 @@ safe_from_p (rtx x, tree exp, int top_p)\n \t      != INTEGER_CST)\n \t  && GET_MODE (x) == BLKmode)\n       /* If X is in the outgoing argument area, it is always safe.  */\n-      || (GET_CODE (x) == MEM\n+      || (MEM_P (x)\n \t  && (XEXP (x, 0) == virtual_outgoing_args_rtx\n \t      || (GET_CODE (XEXP (x, 0)) == PLUS\n \t\t  && XEXP (XEXP (x, 0), 0) == virtual_outgoing_args_rtx))))\n@@ -6094,15 +6094,15 @@ safe_from_p (rtx x, tree exp, int top_p)\n \t  if (DECL_P (exp))\n \t    {\n \t      if (!DECL_RTL_SET_P (exp)\n-\t\t  || GET_CODE (DECL_RTL (exp)) != MEM)\n+\t\t  || !MEM_P (DECL_RTL (exp)))\n \t\treturn 0;\n \t      else\n \t\texp_rtl = XEXP (DECL_RTL (exp), 0);\n \t    }\n \t  break;\n \n \tcase INDIRECT_REF:\n-\t  if (GET_CODE (x) == MEM\n+\t  if (MEM_P (x)\n \t      && alias_sets_conflict_p (MEM_ALIAS_SET (x),\n \t\t\t\t\tget_alias_set (exp)))\n \t    return 0;\n@@ -6112,7 +6112,7 @@ safe_from_p (rtx x, tree exp, int top_p)\n \t  /* Assume that the call will clobber all hard registers and\n \t     all of memory.  */\n \t  if ((REG_P (x) && REGNO (x) < FIRST_PSEUDO_REGISTER)\n-\t      || GET_CODE (x) == MEM)\n+\t      || MEM_P (x))\n \t    return 0;\n \t  break;\n \n@@ -6196,7 +6196,7 @@ safe_from_p (rtx x, tree exp, int top_p)\n       /* If the rtl is X, then it is not safe.  Otherwise, it is unless both\n \t are memory and they conflict.  */\n       return ! (rtx_equal_p (x, exp_rtl)\n-\t\t|| (GET_CODE (x) == MEM && GET_CODE (exp_rtl) == MEM\n+\t\t|| (MEM_P (x) && MEM_P (exp_rtl)\n \t\t    && true_dependence (exp_rtl, VOIDmode, x,\n \t\t\t\t\trtx_addr_varies_p)));\n     }\n@@ -6571,7 +6571,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t  && modifier != EXPAND_CONST_ADDRESS)\n \t{\n \t  temp = expand_expr (exp, NULL_RTX, VOIDmode, modifier);\n-\t  if (GET_CODE (temp) == MEM)\n+\t  if (MEM_P (temp))\n \t    temp = copy_to_reg (temp);\n \t  return const0_rtx;\n \t}\n@@ -6676,7 +6676,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \n       if (context != 0 && context != current_function_decl\n \t  /* If var is static, we don't need a static chain to access it.  */\n-\t  && ! (GET_CODE (DECL_RTL (exp)) == MEM\n+\t  && ! (MEM_P (DECL_RTL (exp))\n \t\t&& CONSTANT_P (XEXP (DECL_RTL (exp), 0))))\n \t{\n \t  rtx addr;\n@@ -6686,10 +6686,10 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t  if (DECL_NO_STATIC_CHAIN (current_function_decl))\n \t    abort ();\n \t  lang_hooks.mark_addressable (exp);\n-\t  if (GET_CODE (DECL_RTL (exp)) != MEM)\n+\t  if (!MEM_P (DECL_RTL (exp)))\n \t    abort ();\n \t  addr = XEXP (DECL_RTL (exp), 0);\n-\t  if (GET_CODE (addr) == MEM)\n+\t  if (MEM_P (addr))\n \t    addr\n \t      = replace_equiv_address (addr,\n \t\t\t\t       fix_lexical_addr (XEXP (addr, 0), exp));\n@@ -6703,15 +6703,15 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t from its initializer, while the initializer is still being parsed.\n \t See expand_decl.  */\n \n-      else if (GET_CODE (DECL_RTL (exp)) == MEM\n+      else if (MEM_P (DECL_RTL (exp))\n \t       && REG_P (XEXP (DECL_RTL (exp), 0)))\n \ttemp = validize_mem (DECL_RTL (exp));\n \n       /* If DECL_RTL is memory, we are in the normal case and either\n \t the address is not valid or it is not a register and -fforce-addr\n \t is specified, get the address into a register.  */\n \n-      else if (GET_CODE (DECL_RTL (exp)) == MEM\n+      else if (MEM_P (DECL_RTL (exp))\n \t       && modifier != EXPAND_CONST_ADDRESS\n \t       && modifier != EXPAND_SUM\n \t       && modifier != EXPAND_INITIALIZER\n@@ -6730,7 +6730,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t if the address is a register.  */\n       if (temp != 0)\n \t{\n-\t  if (GET_CODE (temp) == MEM && REG_P (XEXP (temp, 0)))\n+\t  if (MEM_P (temp) && REG_P (XEXP (temp, 0)))\n \t    mark_reg_pointer (XEXP (temp, 0), DECL_ALIGN (exp));\n \n \t  return temp;\n@@ -6856,7 +6856,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t      put_var_into_stack (exp, /*rescan=*/true);\n \t      temp = SAVE_EXPR_RTL (exp);\n \t    }\n-\t  if (temp == 0 || GET_CODE (temp) != MEM)\n+\t  if (temp == 0 || !MEM_P (temp))\n \t    abort ();\n \t  return\n \t    replace_equiv_address (temp,\n@@ -7325,7 +7325,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n  \t   C, but can in Ada if we have unchecked conversion of an expression\n  \t   from a scalar type to an array or record type or for an\n  \t   ARRAY_RANGE_REF whose type is BLKmode.  */\n-\telse if (GET_CODE (op0) != MEM\n+\telse if (!MEM_P (op0)\n \t\t && (offset != 0\n \t\t     || (code == ARRAY_RANGE_REF && mode == BLKmode)))\n \t  {\n@@ -7355,7 +7355,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t    rtx offset_rtx = expand_expr (offset, NULL_RTX, VOIDmode,\n \t\t\t\t\t  EXPAND_SUM);\n \n-\t    if (GET_CODE (op0) != MEM)\n+\t    if (!MEM_P (op0))\n \t      abort ();\n \n #ifdef POINTERS_EXTEND_UNSIGNED\n@@ -7385,12 +7385,12 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \n \t/* If OFFSET is making OP0 more aligned than BIGGEST_ALIGNMENT,\n \t   record its alignment as BIGGEST_ALIGNMENT.  */\n-\tif (GET_CODE (op0) == MEM && bitpos == 0 && offset != 0\n+\tif (MEM_P (op0) && bitpos == 0 && offset != 0\n \t    && is_aligning_offset (offset, tem))\n \t  set_mem_align (op0, BIGGEST_ALIGNMENT);\n \n \t/* Don't forget about volatility even if this is a bitfield.  */\n-\tif (GET_CODE (op0) == MEM && volatilep && ! MEM_VOLATILE_P (op0))\n+\tif (MEM_P (op0) && volatilep && ! MEM_VOLATILE_P (op0))\n \t  {\n \t    if (op0 == orig_op0)\n \t      op0 = copy_rtx (op0);\n@@ -7426,7 +7426,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t    || (mode1 != BLKmode\n \t\t&& (((TYPE_ALIGN (TREE_TYPE (tem)) < GET_MODE_ALIGNMENT (mode)\n \t\t      || (bitpos % GET_MODE_ALIGNMENT (mode) != 0)\n-\t\t      || (GET_CODE (op0) == MEM\n+\t\t      || (MEM_P (op0)\n \t\t\t  && (MEM_ALIGN (op0) < GET_MODE_ALIGNMENT (mode1)\n \t\t\t      || (bitpos % GET_MODE_ALIGNMENT (mode1) != 0))))\n \t\t     && ((modifier == EXPAND_CONST_ADDRESS\n@@ -7446,8 +7446,8 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t    enum machine_mode ext_mode = mode;\n \n \t    if (ext_mode == BLKmode\n-\t\t&& ! (target != 0 && GET_CODE (op0) == MEM\n-\t\t      && GET_CODE (target) == MEM\n+\t\t&& ! (target != 0 && MEM_P (op0)\n+\t\t      && MEM_P (target)\n \t\t      && bitpos % BITS_PER_UNIT == 0))\n \t      ext_mode = mode_for_size (bitsize, MODE_INT, 1);\n \n@@ -7461,8 +7461,8 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \n \t\t/* In this case, BITPOS must start at a byte boundary and\n \t\t   TARGET, if specified, must be a MEM.  */\n-\t\tif (GET_CODE (op0) != MEM\n-\t\t    || (target != 0 && GET_CODE (target) != MEM)\n+\t\tif (!MEM_P (op0)\n+\t\t    || (target != 0 && !MEM_P (target))\n \t\t    || bitpos % BITS_PER_UNIT != 0)\n \t\t  abort ();\n \n@@ -7479,7 +7479,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \n \t    op0 = validize_mem (op0);\n \n-\t    if (GET_CODE (op0) == MEM && REG_P (XEXP (op0, 0)))\n+\t    if (MEM_P (op0) && REG_P (XEXP (op0, 0)))\n \t      mark_reg_pointer (XEXP (op0, 0), MEM_ALIGN (op0));\n \n \t    op0 = extract_bit_field (op0, bitsize, bitpos, unsignedp,\n@@ -7742,7 +7742,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t\ttarget = assign_temp (type, 0, 1, 1);\n \t    }\n \n-\t  if (GET_CODE (target) == MEM)\n+\t  if (MEM_P (target))\n \t    /* Store data into beginning of memory target.  */\n \t    store_expr (TREE_OPERAND (exp, 0),\n \t\t\tadjust_address (target, TYPE_MODE (valtype), 0),\n@@ -7825,7 +7825,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t       && GET_MODE_SIZE (TYPE_MODE (type)) <= UNITS_PER_WORD\n \t       && GET_MODE_SIZE (GET_MODE (op0)) <= UNITS_PER_WORD)\n \top0 = gen_lowpart (TYPE_MODE (type), op0);\n-      else if (GET_CODE (op0) != MEM)\n+      else if (!MEM_P (op0))\n \t{\n \t  /* If the operand is not a MEM, force it into memory.  Since we\n \t     are going to be be changing the mode of the MEM, don't call\n@@ -7850,7 +7850,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t that the operand is known to be aligned, indicate that it is.\n \t Otherwise, we need only be concerned about alignment for non-BLKmode\n \t results.  */\n-      if (GET_CODE (op0) == MEM)\n+      if (MEM_P (op0))\n \t{\n \t  op0 = copy_rtx (op0);\n \n@@ -8263,7 +8263,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n       target = original_target;\n       if (target == 0\n \t  || modifier == EXPAND_STACK_PARM\n-\t  || (GET_CODE (target) == MEM && MEM_VOLATILE_P (target))\n+\t  || (MEM_P (target) && MEM_VOLATILE_P (target))\n \t  || GET_MODE (target) != mode\n \t  || (REG_P (target)\n \t      && REGNO (target) < FIRST_PSEUDO_REGISTER))\n@@ -8286,7 +8286,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n       /* At this point, a MEM target is no longer useful; we will get better\n \t code without it.  */\n \n-      if (GET_CODE (target) == MEM)\n+      if (MEM_P (target))\n \ttarget = gen_reg_rtx (mode);\n \n       /* If op1 was placed in target, swap op0 and op1.  */\n@@ -8654,7 +8654,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t\t     || REG_P (original_target)\n \t\t     || TREE_ADDRESSABLE (type))\n #endif\n-\t\t && (GET_CODE (original_target) != MEM\n+\t\t && (!MEM_P (original_target)\n \t\t     || TREE_ADDRESSABLE (type)))\n \t  temp = original_target;\n \telse if (TREE_ADDRESSABLE (type))\n@@ -9100,7 +9100,7 @@ expand_expr_real_1 (tree exp, rtx target, enum machine_mode tmode,\n \t\t}\n \t    }\n \n-\t  if (GET_CODE (op0) != MEM)\n+\t  if (!MEM_P (op0))\n \t    abort ();\n \n \t  mark_temp_addr_taken (op0);\n@@ -9725,7 +9725,7 @@ expand_increment (tree exp, int post, int ignore)\n \n \t  return enqueue_insn (op0, GEN_FCN (icode) (op0, op0, op1));\n \t}\n-      if (icode != (int) CODE_FOR_nothing && GET_CODE (op0) == MEM)\n+      if (icode != (int) CODE_FOR_nothing && MEM_P (op0))\n \t{\n \t  rtx addr = (general_operand (XEXP (op0, 0), mode)\n \t\t      ? force_reg (Pmode, XEXP (op0, 0))"}, {"sha": "9b72363159cbc5fd4cd8bb35978904a8fd7d36bd", "filename": "gcc/final.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Ffinal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Ffinal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffinal.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -2602,7 +2602,7 @@ cleanup_subreg_operands (rtx insn)\n \trecog_data.operand[i] = alter_subreg (recog_data.operand_loc[i]);\n       else if (GET_CODE (recog_data.operand[i]) == PLUS\n \t       || GET_CODE (recog_data.operand[i]) == MULT\n-\t       || GET_CODE (recog_data.operand[i]) == MEM)\n+\t       || MEM_P (recog_data.operand[i]))\n \trecog_data.operand[i] = walk_alter_subreg (recog_data.operand_loc[i]);\n     }\n \n@@ -2612,7 +2612,7 @@ cleanup_subreg_operands (rtx insn)\n \t*recog_data.dup_loc[i] = alter_subreg (recog_data.dup_loc[i]);\n       else if (GET_CODE (*recog_data.dup_loc[i]) == PLUS\n \t       || GET_CODE (*recog_data.dup_loc[i]) == MULT\n-\t       || GET_CODE (*recog_data.dup_loc[i]) == MEM)\n+\t       || MEM_P (*recog_data.dup_loc[i]))\n \t*recog_data.dup_loc[i] = walk_alter_subreg (recog_data.dup_loc[i]);\n     }\n }\n@@ -2628,7 +2628,7 @@ alter_subreg (rtx *xp)\n \n   /* simplify_subreg does not remove subreg from volatile references.\n      We are required to.  */\n-  if (GET_CODE (y) == MEM)\n+  if (MEM_P (y))\n     *xp = adjust_address (y, GET_MODE (x), SUBREG_BYTE (x));\n   else\n     {\n@@ -2906,7 +2906,7 @@ get_mem_expr_from_op (rtx op, int *paddressp)\n \n   if (REG_P (op))\n     return REG_EXPR (op);\n-  else if (GET_CODE (op) != MEM)\n+  else if (!MEM_P (op))\n     return 0;\n \n   if (MEM_EXPR (op) != 0)"}, {"sha": "0cc108870ef25c9b3b508bd00bce0e306ebaa687", "filename": "gcc/flow.c", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fflow.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fflow.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fflow.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -858,7 +858,7 @@ notice_stack_pointer_modification_1 (rtx x, rtx pat ATTRIBUTE_UNUSED,\n       /* The stack pointer is only modified indirectly as the result\n \t of a push until later in flow.  See the comments in rtl.texi\n \t regarding Embedded Side-Effects on Addresses.  */\n-      || (GET_CODE (x) == MEM\n+      || (MEM_P (x)\n \t  && GET_RTX_CLASS (GET_CODE (XEXP (x, 0))) == RTX_AUTOINC\n \t  && XEXP (XEXP (x, 0), 0) == stack_pointer_rtx))\n     current_function_sp_is_unchanging = 0;\n@@ -1934,7 +1934,7 @@ init_propagate_block_info (basic_block bb, regset live, regset local_set,\n       for (insn = BB_END (bb); insn != BB_HEAD (bb); insn = PREV_INSN (insn))\n \tif (GET_CODE (insn) == INSN\n \t    && (set = single_set (insn))\n-\t    && GET_CODE (SET_DEST (set)) == MEM)\n+\t    && MEM_P (SET_DEST (set)))\n \t  {\n \t    rtx mem = SET_DEST (set);\n \t    rtx canon_mem = canon_rtx (mem);\n@@ -2104,7 +2104,7 @@ insn_dead_p (struct propagate_block_info *pbi, rtx x, int call_ok,\n       else if (volatile_refs_p (SET_SRC (x)))\n \treturn 0;\n \n-      if (GET_CODE (r) == MEM)\n+      if (MEM_P (r))\n \t{\n \t  rtx temp, canon_r;\n \n@@ -2540,7 +2540,7 @@ mark_set_1 (struct propagate_block_info *pbi, enum rtx_code code, rtx reg, rtx c\n \t     || GET_CODE (reg) == ZERO_EXTRACT\n \t     || GET_CODE (reg) == SIGN_EXTRACT\n \t     || GET_CODE (reg) == STRICT_LOW_PART);\n-      if (GET_CODE (reg) == MEM)\n+      if (MEM_P (reg))\n \tbreak;\n       not_dead = (unsigned long) REGNO_REG_SET_P (pbi->reg_live, REGNO (reg));\n       /* Fall through.  */\n@@ -2611,10 +2611,10 @@ mark_set_1 (struct propagate_block_info *pbi, enum rtx_code code, rtx reg, rtx c\n       /* If the memory reference had embedded side effects (autoincrement\n \t address modes.  Then we may need to kill some entries on the\n \t memory set list.  */\n-      if (insn && GET_CODE (reg) == MEM)\n+      if (insn && MEM_P (reg))\n \tfor_each_rtx (&PATTERN (insn), invalidate_mems_from_autoinc, pbi);\n \n-      if (GET_CODE (reg) == MEM && ! side_effects_p (reg)\n+      if (MEM_P (reg) && ! side_effects_p (reg)\n \t  /* ??? With more effort we could track conditional memory life.  */\n \t  && ! cond)\n \tadd_to_mem_set_list (pbi, canon_rtx (reg));\n@@ -3730,7 +3730,7 @@ mark_used_regs (struct propagate_block_info *pbi, rtx x, rtx cond, rtx insn)\n     case CLOBBER:\n       /* If we are clobbering a MEM, mark any registers inside the address\n \t as being used.  */\n-      if (GET_CODE (XEXP (x, 0)) == MEM)\n+      if (MEM_P (XEXP (x, 0)))\n \tmark_used_regs (pbi, XEXP (XEXP (x, 0), 0), cond, insn);\n       return;\n \n@@ -3811,7 +3811,7 @@ mark_used_regs (struct propagate_block_info *pbi, rtx x, rtx cond, rtx insn)\n \n \t/* If storing into MEM, don't show it as being used.  But do\n \t   show the address as being used.  */\n-\tif (GET_CODE (testreg) == MEM)\n+\tif (MEM_P (testreg))\n \t  {\n #ifdef AUTO_INC_DEC\n \t    if (flags & PROP_AUTOINC)"}, {"sha": "008669fa8d79dd7a8181c07220c9886549ec636a", "filename": "gcc/function.c", "status": "modified", "additions": 22, "deletions": 22, "changes": 44, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Ffunction.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Ffunction.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffunction.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -1134,7 +1134,7 @@ mark_temp_addr_taken (rtx x)\n \n   /* If X is not in memory or is at a constant address, it cannot be in\n      a temporary slot.  */\n-  if (GET_CODE (x) != MEM || CONSTANT_P (XEXP (x, 0)))\n+  if (!MEM_P (x) || CONSTANT_P (XEXP (x, 0)))\n     return;\n \n   p = find_temp_slot_from_address (XEXP (x, 0));\n@@ -1181,7 +1181,7 @@ preserve_temp_slots (rtx x)\n   /* If X is not in memory or is at a constant address, it cannot be in\n      a temporary slot, but it can contain something whose address was\n      taken.  */\n-  if (p == 0 && (GET_CODE (x) != MEM || CONSTANT_P (XEXP (x, 0))))\n+  if (p == 0 && (!MEM_P (x) || CONSTANT_P (XEXP (x, 0))))\n     {\n       for (p = *temp_slots_at_level (temp_slot_level); p; p = next)\n \t{\n@@ -1242,7 +1242,7 @@ preserve_rtl_expr_result (rtx x)\n \n   /* If X is not in memory or is at a constant address, it cannot be in\n      a temporary slot.  */\n-  if (x == 0 || GET_CODE (x) != MEM || CONSTANT_P (XEXP (x, 0)))\n+  if (x == 0 || !MEM_P (x) || CONSTANT_P (XEXP (x, 0)))\n     return;\n \n   /* If we can find a match, move it to our level unless it is already at\n@@ -1400,7 +1400,7 @@ put_var_into_stack (tree decl, int rescan)\n      reference, with a pseudo to address it, put that pseudo into the stack\n      if the var is non-local.  */\n   if (TREE_CODE (decl) != SAVE_EXPR && DECL_NONLOCAL (decl)\n-      && GET_CODE (reg) == MEM\n+      && MEM_P (reg)\n       && REG_P (XEXP (reg, 0))\n       && REGNO (XEXP (reg, 0)) > LAST_VIRTUAL_REGISTER)\n     {\n@@ -1425,7 +1425,7 @@ put_var_into_stack (tree decl, int rescan)\n   /* If we can't use ADDRESSOF, make sure we see through one we already\n      generated.  */\n   if (! can_use_addressof_p\n-      && GET_CODE (reg) == MEM\n+      && MEM_P (reg)\n       && GET_CODE (XEXP (reg, 0)) == ADDRESSOF)\n     reg = XEXP (XEXP (reg, 0), 0);\n \n@@ -1442,7 +1442,7 @@ put_var_into_stack (tree decl, int rescan)\n \t  /* If this was previously a MEM but we've removed the ADDRESSOF,\n \t     set this address into that MEM so we always use the same\n \t     rtx for this variable.  */\n-\t  if (orig_reg != reg && GET_CODE (orig_reg) == MEM)\n+\t  if (orig_reg != reg && MEM_P (orig_reg))\n \t    XEXP (orig_reg, 0) = XEXP (reg, 0);\n     }\n   else if (GET_CODE (reg) == CONCAT)\n@@ -2157,7 +2157,7 @@ fixup_var_refs_1 (rtx var, enum machine_mode promoted_mode, rtx *loc, rtx insn,\n \t\t means that the insn may have become invalid again.  We can't\n \t\t in this case make a new replacement since we already have one\n \t\t and we must deal with MATCH_DUPs.  */\n-\t      if (GET_CODE (replacement->new) == MEM)\n+\t      if (MEM_P (replacement->new))\n \t\t{\n \t\t  INSN_CODE (insn) = -1;\n \t\t  if (recog_memoized (insn) >= 0)\n@@ -2702,13 +2702,13 @@ optimize_bit_field (rtx body, rtx insn, rtx *equiv_mem)\n       /* Now check that the containing word is memory, not a register,\n \t and that it is safe to change the machine mode.  */\n \n-      if (GET_CODE (XEXP (bitfield, 0)) == MEM)\n+      if (MEM_P (XEXP (bitfield, 0)))\n \tmemref = XEXP (bitfield, 0);\n       else if (REG_P (XEXP (bitfield, 0))\n \t       && equiv_mem != 0)\n \tmemref = equiv_mem[REGNO (XEXP (bitfield, 0))];\n       else if (GET_CODE (XEXP (bitfield, 0)) == SUBREG\n-\t       && GET_CODE (SUBREG_REG (XEXP (bitfield, 0))) == MEM)\n+\t       && MEM_P (SUBREG_REG (XEXP (bitfield, 0))))\n \tmemref = SUBREG_REG (XEXP (bitfield, 0));\n       else if (GET_CODE (XEXP (bitfield, 0)) == SUBREG\n \t       && equiv_mem != 0\n@@ -2947,7 +2947,7 @@ flush_addressof (tree decl)\n {\n   if ((TREE_CODE (decl) == PARM_DECL || TREE_CODE (decl) == VAR_DECL)\n       && DECL_RTL (decl) != 0\n-      && GET_CODE (DECL_RTL (decl)) == MEM\n+      && MEM_P (DECL_RTL (decl))\n       && GET_CODE (XEXP (DECL_RTL (decl), 0)) == ADDRESSOF\n       && REG_P (XEXP (XEXP (DECL_RTL (decl), 0), 0)))\n     put_addressof_into_stack (XEXP (DECL_RTL (decl), 0), 0);\n@@ -3043,7 +3043,7 @@ purge_addressof_1 (rtx *loc, rtx insn, int force, int store, int may_postpone,\n     {\n       rtx sub, insns;\n \n-      if (GET_CODE (XEXP (x, 0)) != MEM)\n+      if (!MEM_P (XEXP (x, 0)))\n \tput_addressof_into_stack (x, ht);\n \n       /* We must create a copy of the rtx because it was created by\n@@ -3077,7 +3077,7 @@ purge_addressof_1 (rtx *loc, rtx insn, int force, int store, int may_postpone,\n     {\n       rtx sub = XEXP (XEXP (x, 0), 0);\n \n-      if (GET_CODE (sub) == MEM)\n+      if (MEM_P (sub))\n \tsub = adjust_address_nv (sub, GET_MODE (x), 0);\n       else if (REG_P (sub)\n \t       && (MEM_VOLATILE_P (x) || GET_MODE (x) == BLKmode))\n@@ -3706,7 +3706,7 @@ instantiate_decl (rtx x, HOST_WIDE_INT size, int valid_only)\n   /* If this is not a MEM, no need to do anything.  Similarly if the\n      address is a constant or a register that is not a virtual register.  */\n \n-  if (x == 0 || GET_CODE (x) != MEM)\n+  if (x == 0 || !MEM_P (x))\n     return;\n \n   addr = XEXP (x, 0);\n@@ -4129,7 +4129,7 @@ instantiate_virtual_regs_1 (rtx *loc, rtx object, int extra_insns)\n \t go ahead and make the invalid one, but do it to a copy.  For a REG,\n \t just make the recursive call, since there's no chance of a problem.  */\n \n-      if ((GET_CODE (XEXP (x, 0)) == MEM\n+      if ((MEM_P (XEXP (x, 0))\n \t   && instantiate_virtual_regs_1 (&XEXP (XEXP (x, 0), 0), XEXP (x, 0),\n \t\t\t\t\t  0))\n \t  || (REG_P (XEXP (x, 0))\n@@ -4169,7 +4169,7 @@ instantiate_virtual_regs_1 (rtx *loc, rtx object, int extra_insns)\n       if (REG_P (XEXP (x, 0)))\n \treturn 1;\n \n-      else if (GET_CODE (XEXP (x, 0)) == MEM)\n+      else if (MEM_P (XEXP (x, 0)))\n \t{\n \t  /* If we have a (addressof (mem ..)), do any instantiation inside\n \t     since we know we'll be making the inside valid when we finally\n@@ -5106,7 +5106,7 @@ assign_parms (tree fndecl)\n \t  if (nominal_mode == passed_mode\n \t      && ! did_conversion\n \t      && stack_parm != 0\n-\t      && GET_CODE (stack_parm) == MEM\n+\t      && MEM_P (stack_parm)\n \t      && locate.offset.var == 0\n \t      && reg_mentioned_p (virtual_incoming_args_rtx,\n \t\t\t\t  XEXP (stack_parm, 0)))\n@@ -5254,7 +5254,7 @@ assign_parms (tree fndecl)\n \t      /* Set MEM_EXPR to the original decl, i.e. to PARM,\n \t\t instead of the copy of decl, i.e. FNARGS.  */\n \t      if (DECL_INCOMING_RTL (parm)\n-\t\t  && GET_CODE (DECL_INCOMING_RTL (parm)) == MEM)\n+\t\t  && MEM_P (DECL_INCOMING_RTL (parm)))\n \t\tset_mem_expr (DECL_INCOMING_RTL (parm), parm);\n \t    }\n \t  fnargs = TREE_CHAIN (fnargs);\n@@ -5737,7 +5737,7 @@ setjmp_protect (tree block)\n \t || TREE_CODE (decl) == PARM_DECL)\n \t&& DECL_RTL (decl) != 0\n \t&& (REG_P (DECL_RTL (decl))\n-\t    || (GET_CODE (DECL_RTL (decl)) == MEM\n+\t    || (MEM_P (DECL_RTL (decl))\n \t\t&& GET_CODE (XEXP (DECL_RTL (decl), 0)) == ADDRESSOF))\n \t/* If this variable came from an inline function, it must be\n \t   that its life doesn't overlap the setjmp.  If there was a\n@@ -5770,7 +5770,7 @@ setjmp_protect_args (void)\n \t || TREE_CODE (decl) == PARM_DECL)\n \t&& DECL_RTL (decl) != 0\n \t&& (REG_P (DECL_RTL (decl))\n-\t    || (GET_CODE (DECL_RTL (decl)) == MEM\n+\t    || (MEM_P (DECL_RTL (decl))\n \t\t&& GET_CODE (XEXP (DECL_RTL (decl), 0)) == ADDRESSOF))\n \t&& (\n \t    /* If longjmp doesn't restore the registers,\n@@ -5802,7 +5802,7 @@ fix_lexical_addr (rtx addr, tree var)\n \n   fp = find_function_data (context);\n \n-  if (GET_CODE (addr) == ADDRESSOF && GET_CODE (XEXP (addr, 0)) == MEM)\n+  if (GET_CODE (addr) == ADDRESSOF && MEM_P (XEXP (addr, 0)))\n     addr = XEXP (XEXP (addr, 0), 0);\n \n   /* Decode given address as base reg plus displacement.  */\n@@ -7050,10 +7050,10 @@ keep_stack_depressed (rtx insns)\n \t      insn = next;\n \t      continue;\n \t    }\n-\t  else if (GET_CODE (retaddr) == MEM\n+\t  else if (MEM_P (retaddr)\n \t\t   && REG_P (XEXP (retaddr, 0)))\n \t    base = gen_rtx_REG (Pmode, REGNO (XEXP (retaddr, 0))), offset = 0;\n-\t  else if (GET_CODE (retaddr) == MEM\n+\t  else if (MEM_P (retaddr)\n \t\t   && GET_CODE (XEXP (retaddr, 0)) == PLUS\n \t\t   && REG_P (XEXP (XEXP (retaddr, 0), 0))\n \t\t   && GET_CODE (XEXP (XEXP (retaddr, 0), 1)) == CONST_INT)"}, {"sha": "a903237a7af207c94375d89498a2ac56b51e006f", "filename": "gcc/ifcvt.c", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fifcvt.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fifcvt.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fifcvt.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -1188,7 +1188,7 @@ noce_try_cmove_arith (struct noce_if_info *if_info)\n      early because it'll screw alias analysis.  Note that we've\n      already checked for no side effects.  */\n   if (! no_new_pseudos && cse_not_expected\n-      && GET_CODE (a) == MEM && GET_CODE (b) == MEM\n+      && MEM_P (a) && MEM_P (b)\n       && BRANCH_COST >= 5)\n     {\n       a = XEXP (a, 0);\n@@ -1629,7 +1629,7 @@ noce_try_abs (struct noce_if_info *if_info)\n \treturn FALSE;\n       c = XEXP (note, 0);\n     }\n-  if (GET_CODE (c) == MEM\n+  if (MEM_P (c)\n       && GET_CODE (XEXP (c, 0)) == SYMBOL_REF\n       && CONSTANT_POOL_ADDRESS_P (XEXP (c, 0)))\n     c = get_pool_constant (XEXP (c, 0));\n@@ -1833,7 +1833,7 @@ noce_operand_ok (rtx op)\n {\n   /* We special-case memories, so handle any of them with\n      no address side effects.  */\n-  if (GET_CODE (op) == MEM)\n+  if (MEM_P (op))\n     return ! side_effects_p (XEXP (op, 0));\n \n   if (side_effects_p (op))\n@@ -2022,7 +2022,7 @@ noce_process_if_block (struct ce_if_block * ce_info)\n      for most optimizations if writing to x may trap, i.e. it's a memory\n      other than a static var or a stack slot.  */\n   if (! set_b\n-      && GET_CODE (orig_x) == MEM\n+      && MEM_P (orig_x)\n       && ! MEM_NOTRAP_P (orig_x)\n       && rtx_addr_can_trap_p (XEXP (orig_x, 0)))\n     {\n@@ -2997,7 +2997,7 @@ find_if_case_2 (basic_block test_bb, edge then_edge, edge else_edge)\n static int\n find_memory (rtx *px, void *data ATTRIBUTE_UNUSED)\n {\n-  return GET_CODE (*px) == MEM;\n+  return MEM_P (*px);\n }\n \n /* Used by the code above to perform the actual rtl transformations."}, {"sha": "3b587ab8d2b05893e6ce37f7069ca4d753b4155f", "filename": "gcc/integrate.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fintegrate.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fintegrate.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fintegrate.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -763,7 +763,7 @@ subst_constants (rtx *loc, rtx insn, struct inline_remap *map, int memonly)\n     case CLOBBER:\n       /* The only thing we can do with a USE or CLOBBER is possibly do\n \t some substitutions in a MEM within it.  */\n-      if (GET_CODE (XEXP (x, 0)) == MEM)\n+      if (MEM_P (XEXP (x, 0)))\n \tsubst_constants (&XEXP (XEXP (x, 0), 0), insn, map, 0);\n       return;\n \n@@ -864,7 +864,7 @@ subst_constants (rtx *loc, rtx insn, struct inline_remap *map, int memonly)\n \t  }\n \n \t/* Do substitute in the address of a destination in memory.  */\n-\tif (GET_CODE (*dest_loc) == MEM)\n+\tif (MEM_P (*dest_loc))\n \t  subst_constants (&XEXP (*dest_loc, 0), insn, map, 0);\n \n \t/* Check for the case of DEST a SUBREG, both it and the underlying\n@@ -1320,7 +1320,7 @@ allocate_initial_values (rtx *reg_equiv_memory_loc ATTRIBUTE_UNUSED)\n \n       if (x == NULL_RTX || REG_N_SETS (REGNO (ivs->entries[i].pseudo)) > 1)\n \t; /* Do nothing.  */\n-      else if (GET_CODE (x) == MEM)\n+      else if (MEM_P (x))\n \treg_equiv_memory_loc[regno] = x;\n       else if (REG_P (x))\n \t{"}, {"sha": "d99a42babd306893dc461b1be55d58d16f7e8bd9", "filename": "gcc/local-alloc.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Flocal-alloc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Flocal-alloc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flocal-alloc.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -450,7 +450,7 @@ validate_equiv_mem_from_store (rtx dest, rtx set ATTRIBUTE_UNUSED,\n {\n   if ((REG_P (dest)\n        && reg_overlap_mentioned_p (dest, equiv_mem))\n-      || (GET_CODE (dest) == MEM\n+      || (MEM_P (dest)\n \t  && true_dependence (dest, VOIDmode, equiv_mem, rtx_varies_p)))\n     equiv_mem_modified = 1;\n }\n@@ -711,7 +711,7 @@ memref_referenced_p (rtx memref, rtx x)\n     case SET:\n       /* If we are setting a MEM, it doesn't count (its address does), but any\n \t other SET_DEST that has a MEM in it is referencing the MEM.  */\n-      if (GET_CODE (SET_DEST (x)) == MEM)\n+      if (MEM_P (SET_DEST (x)))\n \t{\n \t  if (memref_referenced_p (memref, XEXP (SET_DEST (x), 0)))\n \t    return 1;\n@@ -882,7 +882,7 @@ update_equiv_regs (void)\n \t      || (regno = REGNO (dest)) < FIRST_PSEUDO_REGISTER\n \t      || reg_equiv[regno].init_insns == const0_rtx\n \t      || (CLASS_LIKELY_SPILLED_P (reg_preferred_class (regno))\n-\t\t  && GET_CODE (src) == MEM))\n+\t\t  && MEM_P (src)))\n \t    {\n \t      /* This might be setting a SUBREG of a pseudo, a pseudo that is\n \t\t also set somewhere else to a constant.  */\n@@ -940,7 +940,7 @@ update_equiv_regs (void)\n \t  note = find_reg_note (insn, REG_EQUIV, NULL_RTX);\n \n \t  if (note == 0 && REG_BASIC_BLOCK (regno) >= 0\n-\t      && GET_CODE (SET_SRC (set)) == MEM\n+\t      && MEM_P (SET_SRC (set))\n \t      && validate_equiv_mem (insn, dest, SET_SRC (set)))\n \t    REG_NOTES (insn) = note = gen_rtx_EXPR_LIST (REG_EQUIV, SET_SRC (set),\n \t\t\t\t\t\t\t REG_NOTES (insn));"}, {"sha": "17955b49dea987ca4887a697a9e4f521b9eff6ad", "filename": "gcc/loop.c", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Floop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Floop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -825,7 +825,7 @@ scan_loop (struct loop *loop, int flags)\n \t\t\t  = gen_rtx_EXPR_LIST (VOIDmode, XEXP (x, 0),\n \t\t\t\t\t       dependencies);\n \t\t      else if (GET_CODE (x) == CLOBBER \n-\t\t\t       && GET_CODE (XEXP (x, 0)) == MEM)\n+\t\t\t       && MEM_P (XEXP (x, 0)))\n \t\t\tdependencies = find_regs_nested (dependencies, \n \t\t\t\t\t\t  XEXP (XEXP (x, 0), 0));\n \t\t    }\n@@ -2593,7 +2593,7 @@ prescan_loop (struct loop *loop)\n \t\trtx fusage = XEXP (fusage_entry, 0);\n \n \t\tif (GET_CODE (fusage) == CLOBBER\n-\t\t    && GET_CODE (XEXP (fusage, 0)) == MEM\n+\t\t    && MEM_P (XEXP (fusage, 0))\n \t\t    && RTX_UNCHANGING_P (XEXP (fusage, 0)))\n \t\t  {\n \t\t    note_stores (fusage, note_addr_stored, loop_info);\n@@ -3233,7 +3233,7 @@ note_addr_stored (rtx x, rtx y ATTRIBUTE_UNUSED,\n {\n   struct loop_info *loop_info = data;\n \n-  if (x == 0 || GET_CODE (x) != MEM)\n+  if (x == 0 || !MEM_P (x))\n     return;\n \n   /* Count number of memory writes.\n@@ -3657,7 +3657,7 @@ check_store (rtx x, rtx pat ATTRIBUTE_UNUSED, void *data)\n {\n   struct check_store_data *d = (struct check_store_data *) data;\n \n-  if ((GET_CODE (x) == MEM) && rtx_equal_p (d->mem_address, XEXP (x, 0)))\n+  if ((MEM_P (x)) && rtx_equal_p (d->mem_address, XEXP (x, 0)))\n     d->mem_write = 1;\n }\n \f\n@@ -8960,7 +8960,7 @@ maybe_eliminate_biv_1 (const struct loop *loop, rtx x, rtx insn,\n \t\t  return 1;\n \t      }\n \t}\n-      else if (REG_P (arg) || GET_CODE (arg) == MEM)\n+      else if (REG_P (arg) || MEM_P (arg))\n \t{\n \t  if (loop_invariant_p (loop, arg) == 1)\n \t    {\n@@ -10288,7 +10288,7 @@ try_swap_copy_prop (const struct loop *loop, rtx replacement,\n static int\n find_mem_in_note_1 (rtx *x, void *data)\n {\n-  if (*x != NULL_RTX && GET_CODE (*x) == MEM)\n+  if (*x != NULL_RTX && MEM_P (*x))\n     {\n       rtx *res = (rtx *) data;\n       *res = *x;"}, {"sha": "1ef656d0eb1faecedf691f6d45f42d5942c27b54", "filename": "gcc/optabs.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Foptabs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Foptabs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Foptabs.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -2985,7 +2985,7 @@ expand_abs (enum machine_mode mode, rtx op0, rtx target,\n   op1 = gen_label_rtx ();\n   if (target == 0 || ! safe\n       || GET_MODE (target) != mode\n-      || (GET_CODE (target) == MEM && MEM_VOLATILE_P (target))\n+      || (MEM_P (target) && MEM_VOLATILE_P (target))\n       || (REG_P (target)\n \t  && REGNO (target) < FIRST_PSEUDO_REGISTER))\n     target = gen_reg_rtx (mode);\n@@ -3241,7 +3241,7 @@ emit_unop_insn (int icode, rtx target, rtx op0, enum rtx_code code)\n     op0 = copy_to_mode_reg (mode0, op0);\n \n   if (! (*insn_data[icode].operand[0].predicate) (temp, GET_MODE (temp))\n-      || (flag_force_mem && GET_CODE (temp) == MEM))\n+      || (flag_force_mem && MEM_P (temp)))\n     temp = gen_reg_rtx (GET_MODE (temp));\n \n   pat = GEN_FCN (icode) (temp, op0);"}, {"sha": "c564f687adfea54dd6a1e30d198f5ae2c2ab7b2f", "filename": "gcc/passes.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fpasses.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fpasses.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpasses.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -440,7 +440,7 @@ rest_of_handle_final (void)\n        different from the DECL_NAME name used in the source file.  */\n \n     x = DECL_RTL (current_function_decl);\n-    if (GET_CODE (x) != MEM)\n+    if (!MEM_P (x))\n       abort ();\n     x = XEXP (x, 0);\n     if (GET_CODE (x) != SYMBOL_REF)"}, {"sha": "121350901b8c617c7fe9275088c76bada50c4b45", "filename": "gcc/postreload.c", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fpostreload.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fpostreload.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpostreload.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -232,7 +232,7 @@ reload_cse_simplify_set (rtx set, rtx insn)\n      that combine made wrt the contents of sign bits.  We'll do this by\n      generating an extend instruction instead of a reg->reg copy.  Thus\n      the destination must be a register that we can widen.  */\n-  if (GET_CODE (src) == MEM\n+  if (MEM_P (src)\n       && GET_MODE_BITSIZE (GET_MODE (src)) < BITS_PER_WORD\n       && (extend_op = LOAD_EXTEND_OP (GET_MODE (src))) != NIL\n       && !REG_P (SET_DEST (set)))\n@@ -244,7 +244,7 @@ reload_cse_simplify_set (rtx set, rtx insn)\n     return 0;\n \n   /* If memory loads are cheaper than register copies, don't change them.  */\n-  if (GET_CODE (src) == MEM)\n+  if (MEM_P (src))\n     old_cost = MEMORY_MOVE_COST (GET_MODE (src), dclass, 1);\n   else if (REG_P (src))\n     old_cost = REGISTER_MOVE_COST (GET_MODE (src),\n@@ -404,7 +404,7 @@ reload_cse_simplify_operands (rtx insn, rtx testreg)\n       op = recog_data.operand[i];\n       mode = GET_MODE (op);\n #ifdef LOAD_EXTEND_OP\n-      if (GET_CODE (op) == MEM\n+      if (MEM_P (op)\n \t  && GET_MODE_BITSIZE (mode) < BITS_PER_WORD\n \t  && LOAD_EXTEND_OP (mode) != NIL)\n \t{\n@@ -418,7 +418,7 @@ reload_cse_simplify_operands (rtx insn, rtx testreg)\n \t     extension applies.\n \t     Also, if there is an explicit extension, we don't have to\n \t     worry about an implicit one.  */\n-\t  else if (GET_CODE (SET_DEST (set)) == MEM\n+\t  else if (MEM_P (SET_DEST (set))\n \t\t   || GET_CODE (SET_DEST (set)) == STRICT_LOW_PART\n \t\t   || GET_CODE (SET_SRC (set)) == ZERO_EXTEND\n \t\t   || GET_CODE (SET_SRC (set)) == SIGN_EXTEND)\n@@ -1432,7 +1432,7 @@ move2add_note_store (rtx dst, rtx set, void *data ATTRIBUTE_UNUSED)\n \n   /* Some targets do argument pushes without adding REG_INC notes.  */\n \n-  if (GET_CODE (dst) == MEM)\n+  if (MEM_P (dst))\n     {\n       dst = XEXP (dst, 0);\n       if (GET_CODE (dst) == PRE_INC || GET_CODE (dst) == POST_INC"}, {"sha": "ba354905bc68c9f390478b02a5c6ff27fb1e1ec6", "filename": "gcc/ra-build.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fra-build.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fra-build.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fra-build.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -2597,7 +2597,7 @@ detect_remat_webs (void)\n \t\t  we created them ourself.  They might not have set their\n \t\t  unchanging flag set, but nevertheless they are stable across\n \t\t  the livetime in question.  */\n-\t       || (GET_CODE (src) == MEM\n+\t       || (MEM_P (src)\n \t\t   && INSN_UID (insn) >= orig_max_uid\n \t\t   && memref_is_stack_slot (src)))\n \t      /* And we must be able to construct an insn without"}, {"sha": "3aa73289b98fb13598ca25dc911dbb66d8031fe5", "filename": "gcc/ra-debug.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fra-debug.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fra-debug.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fra-debug.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -955,10 +955,10 @@ dump_static_insn_cost (FILE *file, const char *message, const char *prefix)\n \t\t    src = SUBREG_REG (src);\n \t\t  if (GET_CODE (dest) == SUBREG)\n \t\t    dest = SUBREG_REG (dest);\n-\t\t  if (GET_CODE (src) == MEM && GET_CODE (dest) != MEM\n+\t\t  if (MEM_P (src) && !MEM_P (dest)\n \t\t      && memref_is_stack_slot (src))\n \t\t    pcost = &load;\n-\t\t  else if (GET_CODE (src) != MEM && GET_CODE (dest) == MEM\n+\t\t  else if (!MEM_P (src) && MEM_P (dest)\n \t\t\t   && memref_is_stack_slot (dest))\n \t\t    pcost = &store;\n \t\t}"}, {"sha": "c7d39fbcbdcf6bbb183c540919c07468d8020e62", "filename": "gcc/ra-rewrite.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fra-rewrite.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fra-rewrite.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fra-rewrite.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -570,7 +570,7 @@ slots_overlap_p (rtx s1, rtx s2)\n \treturn 0;\n       return 1;\n     }\n-  if (GET_CODE (s1) != MEM || GET_CODE (s2) != MEM)\n+  if (!MEM_P (s1) || GET_CODE (s2) != MEM)\n     abort ();\n   s1 = XEXP (s1, 0);\n   s2 = XEXP (s2, 0);\n@@ -722,7 +722,7 @@ insert_stores (bitmap new_deaths)\n \t    slots = NULL;\n \t  else\n \t    {\n-\t      if (1 || GET_CODE (SET_SRC (set)) == MEM)\n+\t      if (1 || MEM_P (SET_SRC (set)))\n \t        delete_overlapping_slots (&slots, SET_SRC (set));\n \t    }\n \t}"}, {"sha": "2d9e472d6cf2ff053c061d551281d85e3fbdc6fa", "filename": "gcc/recog.c", "status": "modified", "additions": 27, "deletions": 27, "changes": 54, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Frecog.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Frecog.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frecog.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -233,7 +233,7 @@ validate_change (rtx object, rtx *loc, rtx new, int in_group)\n   changes[num_changes].loc = loc;\n   changes[num_changes].old = old;\n \n-  if (object && GET_CODE (object) != MEM)\n+  if (object && !MEM_P (object))\n     {\n       /* Set INSN_CODE to force rerecognition of insn.  Save old code in\n \t case invalid.  */\n@@ -338,7 +338,7 @@ apply_change_group (void)\n       if (object == 0 || object == last_validated)\n \tcontinue;\n \n-      if (GET_CODE (object) == MEM)\n+      if (MEM_P (object))\n \t{\n \t  if (! memory_address_p (GET_MODE (object), XEXP (object, 0)))\n \t    break;\n@@ -433,7 +433,7 @@ cancel_changes (int num)\n   for (i = num_changes - 1; i >= num; i--)\n     {\n       *changes[i].loc = changes[i].old;\n-      if (changes[i].object && GET_CODE (changes[i].object) != MEM)\n+      if (changes[i].object && !MEM_P (changes[i].object))\n \tINSN_CODE (changes[i].object) = changes[i].old_code;\n     }\n   num_changes = num;\n@@ -586,7 +586,7 @@ validate_replace_rtx_1 (rtx *loc, rtx from, rtx to, rtx object)\n          likely to be an insertion operation; if it was, nothing bad will\n          happen, we might just fail in some cases).  */\n \n-      if (GET_CODE (XEXP (x, 0)) == MEM\n+      if (MEM_P (XEXP (x, 0))\n \t  && GET_CODE (XEXP (x, 1)) == CONST_INT\n \t  && GET_CODE (XEXP (x, 2)) == CONST_INT\n \t  && !mode_dependent_address_p (XEXP (XEXP (x, 0), 0))\n@@ -942,7 +942,7 @@ general_operand (rtx op, enum machine_mode mode)\n #ifdef INSN_SCHEDULING\n       /* On machines that have insn scheduling, we want all memory\n \t reference to be explicit, so outlaw paradoxical SUBREGs.  */\n-      if (GET_CODE (sub) == MEM\n+      if (MEM_P (sub)\n \t  && GET_MODE_SIZE (mode) > GET_MODE_SIZE (GET_MODE (sub)))\n \treturn 0;\n #endif\n@@ -953,7 +953,7 @@ general_operand (rtx op, enum machine_mode mode)\n \n \t ??? This is a kludge.  */\n       if (!reload_completed && SUBREG_BYTE (op) != 0\n-\t  && GET_CODE (sub) == MEM)\n+\t  && MEM_P (sub))\n \treturn 0;\n \n       /* FLOAT_MODE subregs can't be paradoxical.  Combine will occasionally\n@@ -1039,7 +1039,7 @@ register_operand (rtx op, enum machine_mode mode)\n \t (Ideally, (SUBREG (MEM)...) should not exist after reload,\n \t but currently it does result from (SUBREG (REG)...) where the\n \t reg went on the stack.)  */\n-      if (! reload_completed && GET_CODE (sub) == MEM)\n+      if (! reload_completed && MEM_P (sub))\n \treturn general_operand (op, mode);\n \n #ifdef CANNOT_CHANGE_MODE_CLASS\n@@ -1202,7 +1202,7 @@ nonmemory_operand (rtx op, enum machine_mode mode)\n \t (Ideally, (SUBREG (MEM)...) should not exist after reload,\n \t but currently it does result from (SUBREG (REG)...) where the\n \t reg went on the stack.)  */\n-      if (! reload_completed && GET_CODE (SUBREG_REG (op)) == MEM)\n+      if (! reload_completed && MEM_P (SUBREG_REG (op)))\n \treturn general_operand (op, mode);\n       op = SUBREG_REG (op);\n     }\n@@ -1229,7 +1229,7 @@ push_operand (rtx op, enum machine_mode mode)\n   rounded_size = PUSH_ROUNDING (rounded_size);\n #endif\n \n-  if (GET_CODE (op) != MEM)\n+  if (!MEM_P (op))\n     return 0;\n \n   if (mode != VOIDmode && GET_MODE (op) != mode)\n@@ -1269,7 +1269,7 @@ push_operand (rtx op, enum machine_mode mode)\n int\n pop_operand (rtx op, enum machine_mode mode)\n {\n-  if (GET_CODE (op) != MEM)\n+  if (!MEM_P (op))\n     return 0;\n \n   if (mode != VOIDmode && GET_MODE (op) != mode)\n@@ -1312,7 +1312,7 @@ memory_operand (rtx op, enum machine_mode mode)\n   if (! reload_completed)\n     /* Note that no SUBREG is a memory operand before end of reload pass,\n        because (SUBREG (MEM...)) forces reloading into a register.  */\n-    return GET_CODE (op) == MEM && general_operand (op, mode);\n+    return MEM_P (op) && general_operand (op, mode);\n \n   if (mode != VOIDmode && GET_MODE (op) != mode)\n     return 0;\n@@ -1321,7 +1321,7 @@ memory_operand (rtx op, enum machine_mode mode)\n   if (GET_CODE (inner) == SUBREG)\n     inner = SUBREG_REG (inner);\n \n-  return (GET_CODE (inner) == MEM && general_operand (op, mode));\n+  return (MEM_P (inner) && general_operand (op, mode));\n }\n \n /* Return 1 if OP is a valid indirect memory reference with mode MODE;\n@@ -1332,7 +1332,7 @@ indirect_operand (rtx op, enum machine_mode mode)\n {\n   /* Before reload, a SUBREG isn't in memory (see memory_operand, above).  */\n   if (! reload_completed\n-      && GET_CODE (op) == SUBREG && GET_CODE (SUBREG_REG (op)) == MEM)\n+      && GET_CODE (op) == SUBREG && MEM_P (SUBREG_REG (op)))\n     {\n       int offset = SUBREG_BYTE (op);\n       rtx inner = SUBREG_REG (op);\n@@ -1352,7 +1352,7 @@ indirect_operand (rtx op, enum machine_mode mode)\n \t\t  && general_operand (XEXP (XEXP (inner, 0), 0), Pmode)));\n     }\n \n-  return (GET_CODE (op) == MEM\n+  return (MEM_P (op)\n \t  && memory_operand (op, mode)\n \t  && general_operand (XEXP (op, 0), Pmode));\n }\n@@ -1653,15 +1653,15 @@ asm_operand_ok (rtx op, const char *constraint)\n \n \t     Match any memory and hope things are resolved after reload.  */\n \n-\t  if (GET_CODE (op) == MEM\n+\t  if (MEM_P (op)\n \t      && (1\n \t\t  || GET_CODE (XEXP (op, 0)) == PRE_DEC\n \t\t  || GET_CODE (XEXP (op, 0)) == POST_DEC))\n \t    result = 1;\n \t  break;\n \n \tcase '>':\n-\t  if (GET_CODE (op) == MEM\n+\t  if (MEM_P (op)\n \t      && (1\n \t\t  || GET_CODE (XEXP (op, 0)) == PRE_INC\n \t\t  || GET_CODE (XEXP (op, 0)) == POST_INC))\n@@ -1856,7 +1856,7 @@ find_constant_term_loc (rtx *p)\n int\n offsettable_memref_p (rtx op)\n {\n-  return ((GET_CODE (op) == MEM)\n+  return ((MEM_P (op))\n \t  && offsettable_address_p (1, GET_MODE (op), XEXP (op, 0)));\n }\n \n@@ -1866,7 +1866,7 @@ offsettable_memref_p (rtx op)\n int\n offsettable_nonstrict_memref_p (rtx op)\n {\n-  return ((GET_CODE (op) == MEM)\n+  return ((MEM_P (op))\n \t  && offsettable_address_p (0, GET_MODE (op), XEXP (op, 0)));\n }\n \n@@ -2432,7 +2432,7 @@ constrain_operands (int strict)\n \t      case 'm':\n \t\t/* Memory operands must be valid, to the extent\n \t\t   required by STRICT.  */\n-\t\tif (GET_CODE (op) == MEM)\n+\t\tif (MEM_P (op))\n \t\t  {\n \t\t    if (strict > 0\n \t\t\t&& !strict_memory_address_p (GET_MODE (op),\n@@ -2453,14 +2453,14 @@ constrain_operands (int strict)\n \t\tbreak;\n \n \t      case '<':\n-\t\tif (GET_CODE (op) == MEM\n+\t\tif (MEM_P (op)\n \t\t    && (GET_CODE (XEXP (op, 0)) == PRE_DEC\n \t\t\t|| GET_CODE (XEXP (op, 0)) == POST_DEC))\n \t\t  win = 1;\n \t\tbreak;\n \n \t      case '>':\n-\t\tif (GET_CODE (op) == MEM\n+\t\tif (MEM_P (op)\n \t\t    && (GET_CODE (XEXP (op, 0)) == PRE_INC\n \t\t\t|| GET_CODE (XEXP (op, 0)) == POST_INC))\n \t\t  win = 1;\n@@ -2512,10 +2512,10 @@ constrain_operands (int strict)\n \t\tbreak;\n \n \t      case 'V':\n-\t\tif (GET_CODE (op) == MEM\n+\t\tif (MEM_P (op)\n \t\t    && ((strict > 0 && ! offsettable_memref_p (op))\n \t\t\t|| (strict < 0\n-\t\t\t    && !(CONSTANT_P (op) || GET_CODE (op) == MEM))\n+\t\t\t    && !(CONSTANT_P (op) || MEM_P (op)))\n \t\t\t|| (reload_in_progress\n \t\t\t    && !(REG_P (op)\n \t\t\t\t && REGNO (op) >= FIRST_PSEUDO_REGISTER))))\n@@ -2527,7 +2527,7 @@ constrain_operands (int strict)\n \t\t    || (strict == 0 && offsettable_nonstrict_memref_p (op))\n \t\t    /* Before reload, accept what reload can handle.  */\n \t\t    || (strict < 0\n-\t\t\t&& (CONSTANT_P (op) || GET_CODE (op) == MEM))\n+\t\t\t&& (CONSTANT_P (op) || MEM_P (op)))\n \t\t    /* During reload, accept a pseudo  */\n \t\t    || (reload_in_progress && REG_P (op)\n \t\t\t&& REGNO (op) >= FIRST_PSEUDO_REGISTER))\n@@ -2557,7 +2557,7 @@ constrain_operands (int strict)\n \n \t\t  else if (EXTRA_MEMORY_CONSTRAINT (c, p)\n \t\t\t   /* Every memory operand can be reloaded to fit.  */\n-\t\t\t   && ((strict < 0 && GET_CODE (op) == MEM)\n+\t\t\t   && ((strict < 0 && MEM_P (op))\n \t\t\t       /* Before reload, accept what reload can turn\n \t\t\t\t  into mem.  */\n \t\t\t       || (strict < 0 && CONSTANT_P (op))\n@@ -2598,7 +2598,7 @@ constrain_operands (int strict)\n \t      if (earlyclobber[eopno]\n \t\t  && REG_P (recog_data.operand[eopno]))\n \t\tfor (opno = 0; opno < recog_data.n_operands; opno++)\n-\t\t  if ((GET_CODE (recog_data.operand[opno]) == MEM\n+\t\t  if ((MEM_P (recog_data.operand[opno])\n \t\t       || recog_data.operand_type[opno] != OP_OUT)\n \t\t      && opno != eopno\n \t\t      /* Ignore things like match_operator operands.  */\n@@ -3309,7 +3309,7 @@ store_data_bypass_p (rtx out_insn, rtx in_insn)\n   if (! in_set)\n     abort ();\n \n-  if (GET_CODE (SET_DEST (in_set)) != MEM)\n+  if (!MEM_P (SET_DEST (in_set)))\n     return false;\n \n   out_set = single_set (out_insn);"}, {"sha": "501756cd43efb44002e53ab8f86a71863ff0f71b", "filename": "gcc/reg-stack.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Freg-stack.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Freg-stack.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freg-stack.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -1530,7 +1530,7 @@ subst_stack_regs_pat (rtx insn, stack regstack, rtx pat)\n \t/* See if this is a `movM' pattern, and handle elsewhere if so.  */\n \tif (STACK_REG_P (*src)\n \t    || (STACK_REG_P (*dest)\n-\t\t&& (REG_P (*src) || GET_CODE (*src) == MEM\n+\t\t&& (REG_P (*src) || MEM_P (*src)\n \t\t    || GET_CODE (*src) == CONST_DOUBLE)))\n \t  {\n \t    control_flow_insn_deleted |= move_for_stack_reg (insn, regstack, pat);"}, {"sha": "510e0db1a396dbc846806b9fa176784526c9c1d9", "filename": "gcc/regclass.c", "status": "modified", "additions": 11, "deletions": 11, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fregclass.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fregclass.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fregclass.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -967,7 +967,7 @@ record_operand_costs (rtx insn, struct costs *op_costs,\n       if (GET_CODE (recog_data.operand[i]) == SUBREG)\n \trecog_data.operand[i] = SUBREG_REG (recog_data.operand[i]);\n \n-      if (GET_CODE (recog_data.operand[i]) == MEM)\n+      if (MEM_P (recog_data.operand[i]))\n \trecord_address_regs (XEXP (recog_data.operand[i], 0),\n \t\t\t     MODE_BASE_REG_CLASS (modes[i]), frequency * 2);\n       else if (constraints[i][0] == 'p'\n@@ -1038,10 +1038,10 @@ scan_one_insn (rtx insn, int pass)\n      parameter is stored in memory.  Record this fact.  */\n \n   if (set != 0 && REG_P (SET_DEST (set))\n-      && GET_CODE (SET_SRC (set)) == MEM\n+      && MEM_P (SET_SRC (set))\n       && (note = find_reg_note (insn, REG_EQUIV,\n \t\t\t\tNULL_RTX)) != 0\n-      && GET_CODE (XEXP (note, 0)) == MEM)\n+      && MEM_P (XEXP (note, 0)))\n     {\n       costs[REGNO (SET_DEST (set))].mem_cost\n \t-= (MEMORY_MOVE_COST (GET_MODE (SET_DEST (set)),\n@@ -1570,19 +1570,19 @@ record_reg_classes (int n_alts, int n_ops, rtx *ops,\n \t\t  /* It doesn't seem worth distinguishing between offsettable\n \t\t     and non-offsettable addresses here.  */\n \t\t  allows_mem[i] = 1;\n-\t\t  if (GET_CODE (op) == MEM)\n+\t\t  if (MEM_P (op))\n \t\t    win = 1;\n \t\t  break;\n \n \t\tcase '<':\n-\t\t  if (GET_CODE (op) == MEM\n+\t\t  if (MEM_P (op)\n \t\t      && (GET_CODE (XEXP (op, 0)) == PRE_DEC\n \t\t\t  || GET_CODE (XEXP (op, 0)) == POST_DEC))\n \t\t    win = 1;\n \t\t  break;\n \n \t\tcase '>':\n-\t\t  if (GET_CODE (op) == MEM\n+\t\t  if (MEM_P (op)\n \t\t      && (GET_CODE (XEXP (op, 0)) == PRE_INC\n \t\t\t  || GET_CODE (XEXP (op, 0)) == POST_INC))\n \t\t    win = 1;\n@@ -1643,7 +1643,7 @@ record_reg_classes (int n_alts, int n_ops, rtx *ops,\n \t\t  break;\n \n \t\tcase 'g':\n-\t\t  if (GET_CODE (op) == MEM\n+\t\t  if (MEM_P (op)\n \t\t      || (CONSTANT_P (op)\n #ifdef LEGITIMATE_PIC_OPERAND_P\n \t\t\t  && (! flag_pic || LEGITIMATE_PIC_OPERAND_P (op))\n@@ -1669,7 +1669,7 @@ record_reg_classes (int n_alts, int n_ops, rtx *ops,\n \t\t    {\n \t\t      /* Every MEM can be reloaded to fit.  */\n \t\t      allows_mem[i] = 1;\n-\t\t      if (GET_CODE (op) == MEM)\n+\t\t      if (MEM_P (op))\n \t\t\twin = 1;\n \t\t    }\n \t\t  if (EXTRA_ADDRESS_CONSTRAINT (c, p))\n@@ -1909,7 +1909,7 @@ copy_cost (rtx x, enum machine_mode mode ATTRIBUTE_UNUSED,\n      cost to move between the register classes, and use 2 for everything\n      else (constants).  */\n \n-  if (GET_CODE (x) == MEM || class == NO_REGS)\n+  if (MEM_P (x) || class == NO_REGS)\n     return MEMORY_MOVE_COST (mode, class, to_p);\n \n   else if (REG_P (x))\n@@ -2418,7 +2418,7 @@ reg_scan_mark_refs (rtx x, rtx insn, int note_flag, unsigned int min_regno)\n \t    REG_N_SETS (REGNO (reg))++;\n \t    REG_N_REFS (REGNO (reg))++;\n \t  }\n-\telse if (GET_CODE (reg) == MEM)\n+\telse if (MEM_P (reg))\n \t  reg_scan_mark_refs (XEXP (reg, 0), insn, note_flag, min_regno);\n       }\n       break;\n@@ -2505,7 +2505,7 @@ reg_scan_mark_refs (rtx x, rtx insn, int note_flag, unsigned int min_regno)\n \n \t  if (!REG_ATTRS (dest) && REG_P (src))\n \t    REG_ATTRS (dest) = REG_ATTRS (src);\n-\t  if (!REG_ATTRS (dest) && GET_CODE (src) == MEM)\n+\t  if (!REG_ATTRS (dest) && MEM_P (src))\n \t    set_reg_attrs_from_mem (dest, src);\n \t}\n "}, {"sha": "c6dd485f5ebb0075749685114b00026daaa578d6", "filename": "gcc/regmove.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fregmove.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fregmove.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fregmove.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -671,7 +671,7 @@ optimize_reg_copy_3 (rtx insn, rtx dest, rtx src)\n     return;\n \n   if (! (set = single_set (p))\n-      || GET_CODE (SET_SRC (set)) != MEM\n+      || !MEM_P (SET_SRC (set))\n       /* If there's a REG_EQUIV note, this must be an insn that loads an\n \t argument.  Prefer keeping the note over doing this optimization.  */\n       || find_reg_note (p, REG_EQUIV, NULL_RTX)\n@@ -2134,7 +2134,7 @@ combine_stack_adjustments (void)\n static int\n stack_memref_p (rtx x)\n {\n-  if (GET_CODE (x) != MEM)\n+  if (!MEM_P (x))\n     return 0;\n   x = XEXP (x, 0);\n \n@@ -2411,7 +2411,7 @@ combine_stack_adjustments_for_block (basic_block bb)\n \t     turn it into a direct store.  Obviously we can't do this if\n \t     there were any intervening uses of the stack pointer.  */\n \t  if (memlist == NULL\n-\t      && GET_CODE (dest) == MEM\n+\t      && MEM_P (dest)\n \t      && ((GET_CODE (XEXP (dest, 0)) == PRE_DEC\n \t\t   && (last_sp_adjust\n \t\t       == (HOST_WIDE_INT) GET_MODE_SIZE (GET_MODE (dest))))"}, {"sha": "0b7e785f9855c99cc13e1bcc129cc24720dfcf99", "filename": "gcc/regrename.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fregrename.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fregrename.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fregrename.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -1676,11 +1676,11 @@ copyprop_hardreg_forward_1 (basic_block bb, struct value_data *vd)\n \t\t  = replace_oldest_value_reg (recog_data.operand_loc[i],\n \t\t\t\t\t      recog_op_alt[i][alt].class,\n \t\t\t\t\t      insn, vd);\n-\t      else if (GET_CODE (recog_data.operand[i]) == MEM)\n+\t      else if (MEM_P (recog_data.operand[i]))\n \t\treplaced = replace_oldest_value_mem (recog_data.operand[i],\n \t\t\t\t\t\t     insn, vd);\n \t    }\n-\t  else if (GET_CODE (recog_data.operand[i]) == MEM)\n+\t  else if (MEM_P (recog_data.operand[i]))\n \t    replaced = replace_oldest_value_mem (recog_data.operand[i],\n \t\t\t\t\t\t insn, vd);\n "}, {"sha": "c95959691d2c0b00a1c4da77603a7cf6b74ac582", "filename": "gcc/reload.c", "status": "modified", "additions": 41, "deletions": 41, "changes": 82, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Freload.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Freload.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freload.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -862,7 +862,7 @@ can_reload_into (rtx in, int regno, enum machine_mode mode)\n      that are already scheduled, which can become quite complicated.\n      And since we've already handled address reloads for this MEM, it\n      should always succeed anyway.  */\n-  if (GET_CODE (in) == MEM)\n+  if (MEM_P (in))\n     return 1;\n \n   /* If we can make a simple SET insn that does the job, everything should\n@@ -961,7 +961,7 @@ push_reload (rtx in, rtx out, rtx *inloc, rtx *outloc,\n \n   /* If we have a read-write operand with an address side-effect,\n      change either IN or OUT so the side-effect happens only once.  */\n-  if (in != 0 && out != 0 && GET_CODE (in) == MEM && rtx_equal_p (in, out))\n+  if (in != 0 && out != 0 && MEM_P (in) && rtx_equal_p (in, out))\n     switch (GET_CODE (XEXP (in, 0)))\n       {\n       case POST_INC: case POST_DEC:   case POST_MODIFY:\n@@ -1016,7 +1016,7 @@ push_reload (rtx in, rtx out, rtx *inloc, rtx *outloc,\n \t  || strict_low\n \t  || (((REG_P (SUBREG_REG (in))\n \t\t&& REGNO (SUBREG_REG (in)) >= FIRST_PSEUDO_REGISTER)\n-\t       || GET_CODE (SUBREG_REG (in)) == MEM)\n+\t       || MEM_P (SUBREG_REG (in)))\n \t      && ((GET_MODE_SIZE (inmode)\n \t\t   > GET_MODE_SIZE (GET_MODE (SUBREG_REG (in))))\n #ifdef LOAD_EXTEND_OP\n@@ -1068,7 +1068,7 @@ push_reload (rtx in, rtx out, rtx *inloc, rtx *outloc,\n       inloc = &SUBREG_REG (in);\n       in = *inloc;\n #if ! defined (LOAD_EXTEND_OP) && ! defined (WORD_REGISTER_OPERATIONS)\n-      if (GET_CODE (in) == MEM)\n+      if (MEM_P (in))\n \t/* This is supposed to happen only for paradoxical subregs made by\n \t   combine.c.  (SUBREG (MEM)) isn't supposed to occur other ways.  */\n \tif (GET_MODE_SIZE (GET_MODE (in)) > GET_MODE_SIZE (inmode))\n@@ -1125,7 +1125,7 @@ push_reload (rtx in, rtx out, rtx *inloc, rtx *outloc,\n \t  || strict_low\n \t  || (((REG_P (SUBREG_REG (out))\n \t\t&& REGNO (SUBREG_REG (out)) >= FIRST_PSEUDO_REGISTER)\n-\t       || GET_CODE (SUBREG_REG (out)) == MEM)\n+\t       || MEM_P (SUBREG_REG (out)))\n \t      && ((GET_MODE_SIZE (outmode)\n \t\t   > GET_MODE_SIZE (GET_MODE (SUBREG_REG (out))))\n #ifdef WORD_REGISTER_OPERATIONS\n@@ -1166,7 +1166,7 @@ push_reload (rtx in, rtx out, rtx *inloc, rtx *outloc,\n       outloc = &SUBREG_REG (out);\n       out = *outloc;\n #if ! defined (LOAD_EXTEND_OP) && ! defined (WORD_REGISTER_OPERATIONS)\n-      if (GET_CODE (out) == MEM\n+      if (MEM_P (out)\n \t  && GET_MODE_SIZE (GET_MODE (out)) > GET_MODE_SIZE (outmode))\n \tabort ();\n #endif\n@@ -1201,8 +1201,8 @@ push_reload (rtx in, rtx out, rtx *inloc, rtx *outloc,\n     }\n \n   /* If IN appears in OUT, we can't share any input-only reload for IN.  */\n-  if (in != 0 && out != 0 && GET_CODE (out) == MEM\n-      && (REG_P (in) || GET_CODE (in) == MEM)\n+  if (in != 0 && out != 0 && MEM_P (out)\n+      && (REG_P (in) || MEM_P (in))\n       && reg_overlap_mentioned_for_reload_p (in, XEXP (out, 0)))\n     dont_share = 1;\n \n@@ -2268,7 +2268,7 @@ decompose (rtx x)\n \n   memset (&val, 0, sizeof (val));\n \n-  if (GET_CODE (x) == MEM)\n+  if (MEM_P (x))\n     {\n       rtx base = NULL_RTX, offset = 0;\n       rtx addr = XEXP (x, 0);\n@@ -2407,10 +2407,10 @@ immune_p (rtx x, rtx y, struct decomposition ydata)\n   if (ydata.safe)\n     return 1;\n \n-  if (GET_CODE (y) != MEM)\n+  if (!MEM_P (y))\n     abort ();\n   /* If Y is memory and X is not, Y can't affect X.  */\n-  if (GET_CODE (x) != MEM)\n+  if (!MEM_P (x))\n     return 1;\n \n   xdata = decompose (x);\n@@ -2761,7 +2761,7 @@ find_reloads (rtx insn, int replace, int ind_levels, int live_known,\n \t     wider reload.  */\n \n \t  if (replace\n-\t      && GET_CODE (op) == MEM\n+\t      && MEM_P (op)\n \t      && REG_P (reg)\n \t      && (GET_MODE_SIZE (GET_MODE (reg))\n \t\t  >= GET_MODE_SIZE (GET_MODE (op))))\n@@ -2955,7 +2955,7 @@ find_reloads (rtx insn, int replace, int ind_levels, int live_known,\n \t\t     ??? When is it right at this stage to have a subreg\n \t\t     of a mem that is _not_ to be handled specially?  IMO\n \t\t     those should have been reduced to just a mem.  */\n-\t\t  || ((GET_CODE (operand) == MEM\n+\t\t  || ((MEM_P (operand)\n \t\t       || (REG_P (operand)\n \t\t\t   && REGNO (operand) >= FIRST_PSEUDO_REGISTER))\n #ifndef WORD_REGISTER_OPERATIONS\n@@ -3066,7 +3066,7 @@ find_reloads (rtx insn, int replace, int ind_levels, int live_known,\n \t\t       offsettable address was expected, then we must reject\n \t\t       this combination, because we can't reload it.  */\n \t\t    if (this_alternative_offmemok[m]\n-\t\t\t&& GET_CODE (recog_data.operand[m]) == MEM\n+\t\t\t&& MEM_P (recog_data.operand[m])\n \t\t\t&& this_alternative[m] == (int) NO_REGS\n \t\t\t&& ! this_alternative_win[m])\n \t\t      bad = 1;\n@@ -3125,7 +3125,7 @@ find_reloads (rtx insn, int replace, int ind_levels, int live_known,\n \t      case 'm':\n \t\tif (force_reload)\n \t\t  break;\n-\t\tif (GET_CODE (operand) == MEM\n+\t\tif (MEM_P (operand)\n \t\t    || (REG_P (operand)\n \t\t\t&& REGNO (operand) >= FIRST_PSEUDO_REGISTER\n \t\t\t&& reg_renumber[REGNO (operand)] < 0))\n@@ -3136,15 +3136,15 @@ find_reloads (rtx insn, int replace, int ind_levels, int live_known,\n \t\tbreak;\n \n \t      case '<':\n-\t\tif (GET_CODE (operand) == MEM\n+\t\tif (MEM_P (operand)\n \t\t    && ! address_reloaded[i]\n \t\t    && (GET_CODE (XEXP (operand, 0)) == PRE_DEC\n \t\t\t|| GET_CODE (XEXP (operand, 0)) == POST_DEC))\n \t\t  win = 1;\n \t\tbreak;\n \n \t      case '>':\n-\t\tif (GET_CODE (operand) == MEM\n+\t\tif (MEM_P (operand)\n \t\t    && ! address_reloaded[i]\n \t\t    && (GET_CODE (XEXP (operand, 0)) == PRE_INC\n \t\t\t|| GET_CODE (XEXP (operand, 0)) == POST_INC))\n@@ -3155,7 +3155,7 @@ find_reloads (rtx insn, int replace, int ind_levels, int live_known,\n \t      case 'V':\n \t\tif (force_reload)\n \t\t  break;\n-\t\tif (GET_CODE (operand) == MEM\n+\t\tif (MEM_P (operand)\n \t\t    && ! (ind_levels ? offsettable_memref_p (operand)\n \t\t\t  : offsettable_nonstrict_memref_p (operand))\n \t\t    /* Certain mem addresses will become offsettable\n@@ -3172,7 +3172,7 @@ find_reloads (rtx insn, int replace, int ind_levels, int live_known,\n \t      case 'o':\n \t\tif (force_reload)\n \t\t  break;\n-\t\tif ((GET_CODE (operand) == MEM\n+\t\tif ((MEM_P (operand)\n \t\t     /* If IND_LEVELS, find_reloads_address won't reload a\n \t\t\tpseudo that didn't get a hard reg, so we have to\n \t\t\treject that case.  */\n@@ -3193,7 +3193,7 @@ find_reloads (rtx insn, int replace, int ind_levels, int live_known,\n \t\t\t    || (reg_equiv_address[REGNO (operand)] != 0))))\n \t\t  win = 1;\n \t\tif (CONST_POOL_OK_P (operand)\n-\t\t    || GET_CODE (operand) == MEM)\n+\t\t    || MEM_P (operand))\n \t\t  badop = 0;\n \t\tconstmemok = 1;\n \t\toffmemok = 1;\n@@ -3295,7 +3295,7 @@ find_reloads (rtx insn, int replace, int ind_levels, int live_known,\n \t\t          win = 1;\n \t\t\t/* If the address was already reloaded,\n \t\t\t   we win as well.  */\n-\t\t\telse if (GET_CODE (operand) == MEM\n+\t\t\telse if (MEM_P (operand)\n \t\t\t\t && address_reloaded[i])\n \t\t\t  win = 1;\n \t\t\t/* Likewise if the address will be reloaded because\n@@ -3313,7 +3313,7 @@ find_reloads (rtx insn, int replace, int ind_levels, int live_known,\n \t\t\t   constants via force_const_mem, and other\n \t\t\t   MEMs by reloading the address like for 'o'.  */\n \t\t\tif (CONST_POOL_OK_P (operand)\n-\t\t\t    || GET_CODE (operand) == MEM)\n+\t\t\t    || MEM_P (operand))\n \t\t\t  badop = 0;\n \t\t\tconstmemok = 1;\n \t\t\toffmemok = 1;\n@@ -3513,7 +3513,7 @@ find_reloads (rtx insn, int replace, int ind_levels, int live_known,\n \n \t    for (j = 0; j < noperands; j++)\n \t      /* Is this an input operand or a memory ref?  */\n-\t      if ((GET_CODE (recog_data.operand[j]) == MEM\n+\t      if ((MEM_P (recog_data.operand[j])\n \t\t   || modified[j] != RELOAD_WRITE)\n \t\t  && j != i\n \t\t  /* Ignore things like match_operator operands.  */\n@@ -3801,7 +3801,7 @@ find_reloads (rtx insn, int replace, int ind_levels, int live_known,\n \t   so we don't bother with it.  It may not be worth doing.  */\n \telse if (goal_alternative_matched[i] == -1\n \t\t && goal_alternative_offmemok[i]\n-\t\t && GET_CODE (recog_data.operand[i]) == MEM)\n+\t\t && MEM_P (recog_data.operand[i]))\n \t  {\n \t    operand_reloadnum[i]\n \t      = push_reload (XEXP (recog_data.operand[i], 0), NULL_RTX,\n@@ -3907,7 +3907,7 @@ find_reloads (rtx insn, int replace, int ind_levels, int live_known,\n \n \twhile (GET_CODE (operand) == SUBREG)\n \t  operand = SUBREG_REG (operand);\n-\tif ((GET_CODE (operand) == MEM\n+\tif ((MEM_P (operand)\n \t     || (REG_P (operand)\n \t\t && REGNO (operand) >= FIRST_PSEUDO_REGISTER))\n \t    /* If this is only for an output, the optional reload would not\n@@ -3948,7 +3948,7 @@ find_reloads (rtx insn, int replace, int ind_levels, int live_known,\n \t   we then need to emit a USE and/or a CLOBBER so that reload\n \t   inheritance will do the right thing.  */\n \telse if (replace\n-\t\t && (GET_CODE (operand) == MEM\n+\t\t && (MEM_P (operand)\n \t\t     || (REG_P (operand)\n \t\t\t && REGNO (operand) >= FIRST_PSEUDO_REGISTER\n \t\t\t && reg_renumber [REGNO (operand)] < 0)))\n@@ -3984,7 +3984,7 @@ find_reloads (rtx insn, int replace, int ind_levels, int live_known,\n \n \twhile (GET_CODE (operand) == SUBREG)\n \t  operand = SUBREG_REG (operand);\n-\tif ((GET_CODE (operand) == MEM\n+\tif ((MEM_P (operand)\n \t     || (REG_P (operand)\n \t\t && REGNO (operand) >= FIRST_PSEUDO_REGISTER))\n \t    && ((enum reg_class) goal_alternative[goal_alternative_matches[i]]\n@@ -4796,7 +4796,7 @@ find_reloads_address (enum machine_mode mode, rtx *memrefloc, rtx ad,\n      frame and stack pointers is not its initial value.  In that case the\n      pseudo will have been replaced by a MEM referring to the\n      stack pointer.  */\n-  if (GET_CODE (ad) == MEM)\n+  if (MEM_P (ad))\n     {\n       /* First ensure that the address in this MEM is valid.  Then, unless\n \t indirect addresses are valid, reload the MEM into a register.  */\n@@ -4822,7 +4822,7 @@ find_reloads_address (enum machine_mode mode, rtx *memrefloc, rtx ad,\n \n       if (ind_levels == 0\n \t  || (GET_CODE (XEXP (tem, 0)) == SYMBOL_REF && ! indirect_symref_ok)\n-\t  || GET_CODE (XEXP (tem, 0)) == MEM\n+\t  || MEM_P (XEXP (tem, 0))\n \t  || ! (REG_P (XEXP (tem, 0))\n \t\t|| (GET_CODE (XEXP (tem, 0)) == PLUS\n \t\t    && REG_P (XEXP (XEXP (tem, 0), 0))\n@@ -5524,7 +5524,7 @@ find_reloads_address_1 (enum machine_mode mode, rtx x, int context,\n \t\t memory location, since this will make it harder to\n \t\t reuse address reloads, and increases register pressure.\n \t\t Also don't do this if we can probably update x directly.  */\n-\t      rtx equiv = (GET_CODE (XEXP (x, 0)) == MEM\n+\t      rtx equiv = (MEM_P (XEXP (x, 0))\n \t\t\t   ? XEXP (x, 0)\n \t\t\t   : reg_equiv_mem[regno]);\n \t      int icode = (int) add_optab->handlers[(int) Pmode].insn_code;\n@@ -5573,7 +5573,7 @@ find_reloads_address_1 (enum machine_mode mode, rtx x, int context,\n \t  return value;\n \t}\n \n-      else if (GET_CODE (XEXP (x, 0)) == MEM)\n+      else if (MEM_P (XEXP (x, 0)))\n \t{\n \t  /* This is probably the result of a substitution, by eliminate_regs,\n \t     of an equivalent address for a pseudo that was not allocated to a\n@@ -6311,7 +6311,7 @@ reg_overlap_mentioned_for_reload_p (rtx x, rtx in)\n \t  abort ();\n \t}\n     }\n-  else if (GET_CODE (x) == MEM)\n+  else if (MEM_P (x))\n     return refers_to_mem_for_reload_p (in);\n   else if (GET_CODE (x) == SCRATCH || GET_CODE (x) == PC\n \t   || GET_CODE (x) == CC0)\n@@ -6323,7 +6323,7 @@ reg_overlap_mentioned_for_reload_p (rtx x, rtx in)\n \t (plus (sp) (const_int 64)), since that can lead to incorrect reload\n \t allocation when spuriously changing a RELOAD_FOR_OUTPUT_ADDRESS\n \t into a RELOAD_OTHER on behalf of another RELOAD_OTHER.  */\n-      while (GET_CODE (in) == MEM)\n+      while (MEM_P (in))\n \tin = XEXP (in, 0);\n       if (REG_P (in))\n \treturn 0;\n@@ -6351,7 +6351,7 @@ refers_to_mem_for_reload_p (rtx x)\n   const char *fmt;\n   int i;\n \n-  if (GET_CODE (x) == MEM)\n+  if (MEM_P (x))\n     return 1;\n \n   if (REG_P (x))\n@@ -6361,7 +6361,7 @@ refers_to_mem_for_reload_p (rtx x)\n   fmt = GET_RTX_FORMAT (GET_CODE (x));\n   for (i = GET_RTX_LENGTH (GET_CODE (x)) - 1; i >= 0; i--)\n     if (fmt[i] == 'e'\n-\t&& (GET_CODE (XEXP (x, i)) == MEM\n+\t&& (MEM_P (XEXP (x, i))\n \t    || refers_to_mem_for_reload_p (XEXP (x, i))))\n       return 1;\n \n@@ -6416,7 +6416,7 @@ find_equiv_reg (rtx goal, rtx insn, enum reg_class class, int other,\n     regno = goalreg;\n   else if (REG_P (goal))\n     regno = REGNO (goal);\n-  else if (GET_CODE (goal) == MEM)\n+  else if (MEM_P (goal))\n     {\n       enum rtx_code code = GET_CODE (XEXP (goal, 0));\n       if (MEM_VOLATILE_P (goal))\n@@ -6719,10 +6719,10 @@ find_equiv_reg (rtx goal, rtx insn, enum reg_class class, int other,\n \t\t  if (xregno == STACK_POINTER_REGNUM && need_stable_sp)\n \t\t    return 0;\n \t\t}\n-\t      else if (goal_mem && GET_CODE (dest) == MEM\n+\t      else if (goal_mem && MEM_P (dest)\n \t\t       && ! push_operand (dest, GET_MODE (dest)))\n \t\treturn 0;\n-\t      else if (GET_CODE (dest) == MEM && regno >= FIRST_PSEUDO_REGISTER\n+\t      else if (MEM_P (dest) && regno >= FIRST_PSEUDO_REGISTER\n \t\t       && reg_equiv_memory_loc[regno] != 0)\n \t\treturn 0;\n \t      else if (need_stable_sp && push_operand (dest, GET_MODE (dest)))\n@@ -6765,10 +6765,10 @@ find_equiv_reg (rtx goal, rtx insn, enum reg_class class, int other,\n \t\t\t  if (xregno == STACK_POINTER_REGNUM && need_stable_sp)\n \t\t\t    return 0;\n \t\t\t}\n-\t\t      else if (goal_mem && GET_CODE (dest) == MEM\n+\t\t      else if (goal_mem && MEM_P (dest)\n \t\t\t       && ! push_operand (dest, GET_MODE (dest)))\n \t\t\treturn 0;\n-\t\t      else if (GET_CODE (dest) == MEM && regno >= FIRST_PSEUDO_REGISTER\n+\t\t      else if (MEM_P (dest) && regno >= FIRST_PSEUDO_REGISTER\n \t\t\t       && reg_equiv_memory_loc[regno] != 0)\n \t\t\treturn 0;\n \t\t      else if (need_stable_sp\n@@ -6808,7 +6808,7 @@ find_equiv_reg (rtx goal, rtx insn, enum reg_class class, int other,\n \t\t\t    return 0;\n \t\t\t}\n \n-\t\t      else if (goal_mem && GET_CODE (dest) == MEM\n+\t\t      else if (goal_mem && MEM_P (dest)\n \t\t\t       && ! push_operand (dest, GET_MODE (dest)))\n \t\t\treturn 0;\n \t\t      else if (need_stable_sp"}, {"sha": "a7eafa3382a97cf4390777651bfa716a52e26ecd", "filename": "gcc/reload1.c", "status": "modified", "additions": 21, "deletions": 21, "changes": 42, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Freload1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Freload1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freload1.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -793,7 +793,7 @@ reload (rtx first, int global)\n \t\t     and the MEM is not SET_SRC, the equivalencing insn\n \t\t     is one with the MEM as a SET_DEST and it occurs later.\n \t\t     So don't mark this insn now.  */\n-\t\t  if (GET_CODE (x) != MEM\n+\t\t  if (!MEM_P (x)\n \t\t      || rtx_equal_p (SET_SRC (set), x))\n \t\t    reg_equiv_init[i]\n \t\t      = gen_rtx_INSN_LIST (VOIDmode, insn, reg_equiv_init[i]);\n@@ -803,7 +803,7 @@ reload (rtx first, int global)\n \n       /* If this insn is setting a MEM from a register equivalent to it,\n \t this is the equivalencing insn.  */\n-      else if (set && GET_CODE (SET_DEST (set)) == MEM\n+      else if (set && MEM_P (SET_DEST (set))\n \t       && REG_P (SET_SRC (set))\n \t       && reg_equiv_memory_loc[REGNO (SET_SRC (set))]\n \t       && rtx_equal_p (SET_DEST (set),\n@@ -1171,7 +1171,7 @@ reload (rtx first, int global)\n \t     && (GET_MODE (insn) == QImode\n \t\t || find_reg_note (insn, REG_EQUAL, NULL_RTX)))\n \t    || (GET_CODE (PATTERN (insn)) == CLOBBER\n-\t\t&& (GET_CODE (XEXP (PATTERN (insn), 0)) != MEM\n+\t\t&& (!MEM_P (XEXP (PATTERN (insn), 0))\n \t\t    || GET_MODE (XEXP (PATTERN (insn), 0)) != BLKmode\n \t\t    || (GET_CODE (XEXP (XEXP (PATTERN (insn), 0), 0)) != SCRATCH\n \t\t\t&& XEXP (XEXP (PATTERN (insn), 0), 0)\n@@ -2287,7 +2287,7 @@ eliminate_regs (rtx x, enum machine_mode mem_mode, rtx insn)\n \t eliminate_regs on DECL_RTL; any ADDRESSOFs in the actual insns are\n \t removed after CSE.  */\n       new = eliminate_regs (XEXP (x, 0), 0, insn);\n-      if (GET_CODE (new) == MEM)\n+      if (MEM_P (new))\n \treturn XEXP (new, 0);\n       return x;\n \n@@ -2529,7 +2529,7 @@ eliminate_regs (rtx x, enum machine_mode mem_mode, rtx insn)\n \t  int x_size = GET_MODE_SIZE (GET_MODE (x));\n \t  int new_size = GET_MODE_SIZE (GET_MODE (new));\n \n-\t  if (GET_CODE (new) == MEM\n+\t  if (MEM_P (new)\n \t      && ((x_size < new_size\n #ifdef WORD_REGISTER_OPERATIONS\n \t\t   /* On these machines, combine can create rtl of the form\n@@ -3128,7 +3128,7 @@ eliminate_regs_in_insn (rtx insn, int replace)\n \t   insn, write a CLOBBER insn.  */\n \t  if (recog_data.operand_type[i] != OP_IN\n \t      && REG_P (orig_operand[i])\n-\t      && GET_CODE (substed_operand[i]) == MEM\n+\t      && MEM_P (substed_operand[i])\n \t      && replace)\n \t    emit_insn_after (gen_rtx_CLOBBER (VOIDmode, orig_operand[i]),\n \t\t\t     insn);\n@@ -3189,9 +3189,9 @@ eliminate_regs_in_insn (rtx insn, int replace)\n \t\t the MEM in recog_data.operand to the one in the insn.\n \t\t If they are not equal, then rerecognize the insn.  */\n \t      || (old_set != 0\n-\t\t  && ((GET_CODE (SET_SRC (old_set)) == MEM\n+\t\t  && ((MEM_P (SET_SRC (old_set))\n \t\t       && SET_SRC (old_set) != recog_data.operand[1])\n-\t\t      || (GET_CODE (SET_DEST (old_set)) == MEM\n+\t\t      || (MEM_P (SET_DEST (old_set))\n \t\t\t  && SET_DEST (old_set) != recog_data.operand[0])))\n \t      /* If this was an add insn before, rerecognize.  */\n \t      || GET_CODE (SET_SRC (old_set)) == PLUS))\n@@ -3821,7 +3821,7 @@ reload_as_needed (int live_known)\n \n \t  if ((GET_CODE (PATTERN (insn)) == USE\n \t       || GET_CODE (PATTERN (insn)) == CLOBBER)\n-\t      && GET_CODE (XEXP (PATTERN (insn), 0)) == MEM)\n+\t      && MEM_P (XEXP (PATTERN (insn), 0)))\n \t    XEXP (XEXP (PATTERN (insn), 0), 0)\n \t      = eliminate_regs (XEXP (XEXP (PATTERN (insn), 0), 0),\n \t\t\t\tGET_MODE (XEXP (PATTERN (insn), 0)),\n@@ -5354,7 +5354,7 @@ choose_reload_regs (struct insn_chain *chain)\n \t  if (rld[r].in != 0 && rld[r].reg_rtx != 0\n \t      && (rtx_equal_p (rld[r].in, rld[r].reg_rtx)\n \t\t  || (rtx_equal_p (rld[r].out, rld[r].reg_rtx)\n-\t\t      && GET_CODE (rld[r].in) != MEM\n+\t\t      && !MEM_P (rld[r].in)\n \t\t      && true_regnum (rld[r].in) < FIRST_PSEUDO_REGISTER)))\n \t    continue;\n \n@@ -5592,7 +5592,7 @@ choose_reload_regs (struct insn_chain *chain)\n \t      && (CONSTANT_P (rld[r].in)\n \t\t  || GET_CODE (rld[r].in) == PLUS\n \t\t  || REG_P (rld[r].in)\n-\t\t  || GET_CODE (rld[r].in) == MEM)\n+\t\t  || MEM_P (rld[r].in))\n \t      && (rld[r].nregs == max_group_size\n \t\t  || ! reg_classes_intersect_p (rld[r].class, group_class)))\n \t    search_equiv = rld[r].in;\n@@ -6205,7 +6205,7 @@ emit_input_reload_insns (struct insn_chain *chain, struct reload *rl,\n      because we will use this equiv reg right away.  */\n \n   if (oldequiv == 0 && optimize\n-      && (GET_CODE (old) == MEM\n+      && (MEM_P (old)\n \t  || (REG_P (old)\n \t      && REGNO (old) >= FIRST_PSEUDO_REGISTER\n \t      && reg_renumber[REGNO (old)] < 0)))\n@@ -6837,7 +6837,7 @@ static void\n do_input_reload (struct insn_chain *chain, struct reload *rl, int j)\n {\n   rtx insn = chain->insn;\n-  rtx old = (rl->in && GET_CODE (rl->in) == MEM\n+  rtx old = (rl->in && MEM_P (rl->in)\n \t     ? rl->in_reg : rl->in);\n \n   if (old != 0\n@@ -6852,8 +6852,8 @@ do_input_reload (struct insn_chain *chain, struct reload *rl, int j)\n      e.g. inheriting a SImode output reload for\n      (mem:HI (plus:SI (reg:SI 14 fp) (const_int 10)))  */\n   if (optimize && reload_inherited[j] && rl->in\n-      && GET_CODE (rl->in) == MEM\n-      && GET_CODE (rl->in_reg) == MEM\n+      && MEM_P (rl->in)\n+      && MEM_P (rl->in_reg)\n       && reload_spill_index[j] >= 0\n       && TEST_HARD_REG_BIT (reg_reloaded_valid, reload_spill_index[j]))\n     rl->in = regno_reg_rtx[reg_reloaded_contents[reload_spill_index[j]]];\n@@ -7283,7 +7283,7 @@ emit_reload_insns (struct insn_chain *chain)\n \t it thinks only about the original insn.  So invalidate it here.  */\n       if (i < 0 && rld[r].out != 0\n \t  && (REG_P (rld[r].out)\n-\t      || (GET_CODE (rld[r].out) == MEM\n+\t      || (MEM_P (rld[r].out)\n \t\t  && REG_P (rld[r].out_reg))))\n \t{\n \t  rtx out = (REG_P (rld[r].out)\n@@ -7426,11 +7426,11 @@ gen_reload (rtx out, rtx in, int opnum, enum reload_type type)\n   if (GET_CODE (in) == PLUS\n       && (REG_P (XEXP (in, 0))\n \t  || GET_CODE (XEXP (in, 0)) == SUBREG\n-\t  || GET_CODE (XEXP (in, 0)) == MEM)\n+\t  || MEM_P (XEXP (in, 0)))\n       && (REG_P (XEXP (in, 1))\n \t  || GET_CODE (XEXP (in, 1)) == SUBREG\n \t  || CONSTANT_P (XEXP (in, 1))\n-\t  || GET_CODE (XEXP (in, 1)) == MEM))\n+\t  || MEM_P (XEXP (in, 1))))\n     {\n       /* We need to compute the sum of a register or a MEM and another\n \t register, constant, or MEM, and put it into the reload\n@@ -7497,7 +7497,7 @@ gen_reload (rtx out, rtx in, int opnum, enum reload_type type)\n \n       code = (int) add_optab->handlers[(int) GET_MODE (out)].insn_code;\n \n-      if (CONSTANT_P (op1) || GET_CODE (op1) == MEM || GET_CODE (op1) == SUBREG\n+      if (CONSTANT_P (op1) || MEM_P (op1) || GET_CODE (op1) == SUBREG\n \t  || (REG_P (op1)\n \t      && REGNO (op1) >= FIRST_PSEUDO_REGISTER)\n \t  || (code != CODE_FOR_nothing\n@@ -7627,7 +7627,7 @@ delete_output_reload (rtx insn, int j, int last_reload_reg)\n       rtx reg2 = rld[k].in;\n       if (! reg2)\n \tcontinue;\n-      if (GET_CODE (reg2) == MEM || reload_override_in[k])\n+      if (MEM_P (reg2) || reload_override_in[k])\n \treg2 = rld[k].in_reg;\n #ifdef AUTO_INC_DEC\n       if (rld[k].out && ! rld[k].out_reg)\n@@ -7773,7 +7773,7 @@ delete_address_reloads (rtx dead_insn, rtx current_insn)\n   if (set)\n     {\n       rtx dst = SET_DEST (set);\n-      if (GET_CODE (dst) == MEM)\n+      if (MEM_P (dst))\n \tdelete_address_reloads_1 (dead_insn, XEXP (dst, 0), current_insn);\n     }\n   /* If we deleted the store from a reloaded post_{in,de}c expression,"}, {"sha": "08a1635807327fe1af0caf9ad57f639d9120f3a6", "filename": "gcc/resource.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fresource.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fresource.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fresource.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -315,7 +315,7 @@ mark_referenced_resources (rtx x, struct resources *res,\n \tmark_referenced_resources (x, res, 0);\n       else if (GET_CODE (x) == SUBREG)\n \tx = SUBREG_REG (x);\n-      if (GET_CODE (x) == MEM)\n+      if (MEM_P (x))\n \tmark_referenced_resources (XEXP (x, 0), res, 0);\n       return;\n "}, {"sha": "3329d8bf07c63b4fe9ab9e81ab9b2cdd3630fd5e", "filename": "gcc/rtlanal.c", "status": "modified", "additions": 13, "deletions": 13, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Frtlanal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Frtlanal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtlanal.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -534,7 +534,7 @@ get_jump_table_offset (rtx insn, rtx *earliest)\n     }\n \n   /* If X isn't a MEM then this isn't a tablejump we understand.  */\n-  if (GET_CODE (x) != MEM)\n+  if (!MEM_P (x))\n     return NULL_RTX;\n \n   /* Strip off the MEM.  */\n@@ -688,7 +688,7 @@ count_occurrences (rtx x, rtx find, int count_dest)\n       return 0;\n \n     case MEM:\n-      if (GET_CODE (find) == MEM && rtx_equal_p (x, find))\n+      if (MEM_P (find) && rtx_equal_p (x, find))\n \treturn 1;\n       break;\n \n@@ -898,7 +898,7 @@ reg_referenced_p (rtx x, rtx body)\n       return 0;\n \n     case CLOBBER:\n-      if (GET_CODE (XEXP (body, 0)) == MEM)\n+      if (MEM_P (XEXP (body, 0)))\n \tif (reg_overlap_mentioned_p (x, XEXP (XEXP (body, 0), 0)))\n \t  return 1;\n       return 0;\n@@ -968,7 +968,7 @@ reg_set_p (rtx reg, rtx insn)\n \t\t information holds all clobbered registers.  */\n \t      && ((REG_P (reg)\n \t\t   && REGNO (reg) < FIRST_PSEUDO_REGISTER)\n-\t\t  || GET_CODE (reg) == MEM\n+\t\t  || MEM_P (reg)\n \t\t  || find_reg_fusage (insn, CLOBBER, reg)))))\n     return 1;\n \n@@ -1186,7 +1186,7 @@ set_of_1 (rtx x, rtx pat, void *data1)\n {\n    struct set_of_data *data = (struct set_of_data *) (data1);\n    if (rtx_equal_p (x, data->pat)\n-       || (GET_CODE (x) != MEM && reg_overlap_mentioned_p (data->pat, x)))\n+       || (!MEM_P (x) && reg_overlap_mentioned_p (data->pat, x)))\n      data->found = pat;\n }\n \n@@ -1299,7 +1299,7 @@ set_noop_p (rtx set)\n   if (dst == pc_rtx && src == pc_rtx)\n     return 1;\n \n-  if (GET_CODE (dst) == MEM && GET_CODE (src) == MEM)\n+  if (MEM_P (dst) && MEM_P (src))\n     return rtx_equal_p (dst, src) && !side_effects_p (dst);\n \n   if (GET_CODE (dst) == SIGN_EXTRACT\n@@ -1573,7 +1573,7 @@ reg_overlap_mentioned_p (rtx x, rtx in)\n \tconst char *fmt;\n \tint i;\n \n-\tif (GET_CODE (in) == MEM)\n+\tif (MEM_P (in))\n \t  return 1;\n \n \tfmt = GET_RTX_FORMAT (GET_CODE (in));\n@@ -1708,7 +1708,7 @@ note_uses (rtx *pbody, void (*fun) (rtx *, void *), void *data)\n       return;\n \n     case CLOBBER:\n-      if (GET_CODE (XEXP (body, 0)) == MEM)\n+      if (MEM_P (XEXP (body, 0)))\n \t(*fun) (&XEXP (XEXP (body, 0), 0), data);\n       return;\n \n@@ -1729,7 +1729,7 @@ note_uses (rtx *pbody, void (*fun) (rtx *, void *), void *data)\n \twhile (GET_CODE (dest) == SUBREG || GET_CODE (dest) == STRICT_LOW_PART)\n \t  dest = XEXP (dest, 0);\n \n-\tif (GET_CODE (dest) == MEM)\n+\tif (MEM_P (dest))\n \t  (*fun) (&XEXP (dest, 0), data);\n       }\n       return;\n@@ -2033,7 +2033,7 @@ pure_call_p (rtx insn)\n       rtx u, m;\n \n       if (GET_CODE (u = XEXP (link, 0)) == USE\n-\t  && GET_CODE (m = XEXP (u, 0)) == MEM && GET_MODE (m) == BLKmode\n+\t  && MEM_P (m = XEXP (u, 0)) && GET_MODE (m) == BLKmode\n \t  && GET_CODE (XEXP (m, 0)) == SCRATCH)\n \treturn 1;\n     }\n@@ -2648,7 +2648,7 @@ replace_regs (rtx x, rtx *reg_map, unsigned int nregs, int replace_dest)\n       if (replace_dest)\n \tSET_DEST (x) = replace_regs (SET_DEST (x), reg_map, nregs, 0);\n \n-      else if (GET_CODE (SET_DEST (x)) == MEM\n+      else if (MEM_P (SET_DEST (x))\n \t       || GET_CODE (SET_DEST (x)) == STRICT_LOW_PART)\n \t/* Even if we are not to replace destinations, replace register if it\n \t   is CONTAINED in destination (destination is memory or\n@@ -4266,7 +4266,7 @@ nonzero_bits1 (rtx x, enum machine_mode mode, rtx known_x,\n \t\t\t<< (GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (x))) - 1))))\n \t\t   != 0))\n \t       : LOAD_EXTEND_OP (GET_MODE (SUBREG_REG (x))) != ZERO_EXTEND)\n-\t      || GET_CODE (SUBREG_REG (x)) != MEM)\n+\t      || !MEM_P (SUBREG_REG (x)))\n #endif\n \t    {\n \t      /* On many CISC machines, accessing an object in a wider mode\n@@ -4575,7 +4575,7 @@ num_sign_bit_copies1 (rtx x, enum machine_mode mode, rtx known_x,\n       if ((GET_MODE_SIZE (GET_MODE (x))\n \t   > GET_MODE_SIZE (GET_MODE (SUBREG_REG (x))))\n \t  && LOAD_EXTEND_OP (GET_MODE (SUBREG_REG (x))) == SIGN_EXTEND\n-\t  && GET_CODE (SUBREG_REG (x)) == MEM)\n+\t  && MEM_P (SUBREG_REG (x)))\n \treturn cached_num_sign_bit_copies (SUBREG_REG (x), mode,\n \t\t\t\t\t   known_x, known_mode, known_ret);\n #endif"}, {"sha": "cabb1b7ead321e238bcd47a379c6ebd013692d2e", "filename": "gcc/rtlhooks.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Frtlhooks.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Frtlhooks.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtlhooks.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -51,7 +51,7 @@ gen_lowpart_general (enum machine_mode mode, rtx x)\n \tabort ();\n       return result;\n     }\n-  else if (GET_CODE (x) == MEM)\n+  else if (MEM_P (x))\n     {\n       /* The only additional case we can do is MEM.  */\n       int offset = 0;"}, {"sha": "44322156134e1cbc4f57eb81f8c9771a41c155a2", "filename": "gcc/sched-deps.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fsched-deps.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fsched-deps.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-deps.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -526,7 +526,7 @@ sched_analyze_1 (struct deps *deps, rtx x, rtx insn)\n \t  if (!reload_completed && get_reg_known_equiv_p (regno))\n \t    {\n \t      rtx t = get_reg_known_value (regno);\n-\t      if (GET_CODE (t) == MEM)\n+\t      if (MEM_P (t))\n \t        sched_analyze_2 (deps, XEXP (t, 0), insn);\n \t    }\n \n@@ -536,7 +536,7 @@ sched_analyze_1 (struct deps *deps, rtx x, rtx insn)\n \t    add_dependence_list (insn, deps->last_function_call, REG_DEP_ANTI);\n \t}\n     }\n-  else if (GET_CODE (dest) == MEM)\n+  else if (MEM_P (dest))\n     {\n       /* Writing memory.  */\n       rtx t = dest;\n@@ -664,7 +664,7 @@ sched_analyze_2 (struct deps *deps, rtx x, rtx insn)\n \t    if (!reload_completed && get_reg_known_equiv_p (regno))\n \t      {\n \t\trtx t = get_reg_known_value (regno);\n-\t\tif (GET_CODE (t) == MEM)\n+\t\tif (MEM_P (t))\n \t\t  sched_analyze_2 (deps, XEXP (t, 0), insn);\n \t      }\n "}, {"sha": "2e40f8ad3839bfb8b3175569427ed7fbbdf1c0a3", "filename": "gcc/sdbout.c", "status": "modified", "additions": 14, "deletions": 14, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fsdbout.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fsdbout.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsdbout.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -88,7 +88,7 @@ static GTY(()) bool sdbout_initialized;\n /* 1 if PARM is passed to this function in memory.  */\n \n #define PARM_PASSED_IN_MEMORY(PARM) \\\n- (GET_CODE (DECL_INCOMING_RTL (PARM)) == MEM)\n+ (MEM_P (DECL_INCOMING_RTL (PARM)))\n \n /* A C expression for the integer offset value of an automatic variable\n    (C_AUTO) having address X (an RTX).  */\n@@ -732,7 +732,7 @@ sdbout_symbol (tree decl, int local)\n \t a DECL_INITIAL value of 0.  */\n       if (! DECL_INITIAL (decl))\n \treturn;\n-      if (GET_CODE (DECL_RTL (decl)) != MEM\n+      if (!MEM_P (DECL_RTL (decl))\n \t  || GET_CODE (XEXP (DECL_RTL (decl), 0)) != SYMBOL_REF)\n \treturn;\n       PUT_SDB_DEF (IDENTIFIER_POINTER (DECL_ASSEMBLER_NAME (decl)));\n@@ -811,7 +811,7 @@ sdbout_symbol (tree decl, int local)\n       /* Don't output anything if an auto variable\n \t gets RTL that is static.\n \t GAS version 2.2 can't handle such output.  */\n-      else if (GET_CODE (value) == MEM && CONSTANT_P (XEXP (value, 0))\n+      else if (MEM_P (value) && CONSTANT_P (XEXP (value, 0))\n \t       && ! TREE_STATIC (decl))\n \treturn;\n \n@@ -830,7 +830,7 @@ sdbout_symbol (tree decl, int local)\n \n       /* Defer SDB information for top-level initialized variables! */\n       if (! local\n-\t  && GET_CODE (value) == MEM\n+\t  && MEM_P (value)\n \t  && DECL_INITIAL (decl))\n \treturn;\n \n@@ -845,7 +845,7 @@ sdbout_symbol (tree decl, int local)\n       else\n \tname = IDENTIFIER_POINTER (DECL_ASSEMBLER_NAME (decl));\n \n-      if (GET_CODE (value) == MEM\n+      if (MEM_P (value)\n \t  && GET_CODE (XEXP (value, 0)) == SYMBOL_REF)\n \t{\n \t  PUT_SDB_DEF (name);\n@@ -866,8 +866,8 @@ sdbout_symbol (tree decl, int local)\n \t  PUT_SDB_INT_VAL (DBX_REGISTER_NUMBER (regno));\n \t  PUT_SDB_SCL (C_REG);\n \t}\n-      else if (GET_CODE (value) == MEM\n-\t       && (GET_CODE (XEXP (value, 0)) == MEM\n+      else if (MEM_P (value)\n+\t       && (MEM_P (XEXP (value, 0))\n \t\t   || (REG_P (XEXP (value, 0))\n \t\t       && REGNO (XEXP (value, 0)) != HARD_FRAME_POINTER_REGNUM\n \t\t       && REGNO (XEXP (value, 0)) != STACK_POINTER_REGNUM)))\n@@ -901,7 +901,7 @@ sdbout_symbol (tree decl, int local)\n \t  type = make_node (POINTER_TYPE);\n \t  TREE_TYPE (type) = TREE_TYPE (decl);\n \t}\n-      else if (GET_CODE (value) == MEM\n+      else if (MEM_P (value)\n \t       && ((GET_CODE (XEXP (value, 0)) == PLUS\n \t\t    && REG_P (XEXP (XEXP (value, 0), 0))\n \t\t    && GET_CODE (XEXP (XEXP (value, 0), 1)) == CONST_INT)\n@@ -943,7 +943,7 @@ sdbout_toplevel_data (tree decl)\n     return;\n \n   if (! (TREE_CODE (decl) == VAR_DECL\n-\t && GET_CODE (DECL_RTL (decl)) == MEM\n+\t && MEM_P (DECL_RTL (decl))\n \t && DECL_INITIAL (decl)))\n     abort ();\n \n@@ -1310,7 +1310,7 @@ sdbout_parms (tree parms)\n \t\t    (GET_MODE_SIZE (TYPE_MODE (DECL_ARG_TYPE (parms)))\n \t\t     - GET_MODE_SIZE (GET_MODE (DECL_RTL (parms))));\n \n-\t\tif (GET_CODE (DECL_RTL (parms)) == MEM\n+\t\tif (MEM_P (DECL_RTL (parms))\n \t\t    && GET_CODE (XEXP (DECL_RTL (parms), 0)) == PLUS\n \t\t    && (GET_CODE (XEXP (XEXP (DECL_RTL (parms), 0), 1))\n \t\t\t== CONST_INT)\n@@ -1352,7 +1352,7 @@ sdbout_parms (tree parms)\n \t    PUT_SDB_TYPE (plain_type (TREE_TYPE (parms)));\n \t    PUT_SDB_ENDEF;\n \t  }\n-\telse if (GET_CODE (DECL_RTL (parms)) == MEM\n+\telse if (MEM_P (DECL_RTL (parms))\n \t\t && XEXP (DECL_RTL (parms), 0) != const0_rtx)\n \t  {\n \t    /* Parm was passed in registers but lives on the stack.  */\n@@ -1362,7 +1362,7 @@ sdbout_parms (tree parms)\n \t       or (MEM (REG ...)) or (MEM (MEM ...)),\n \t       in which case we use a value of zero.  */\n \t    if (REG_P (XEXP (DECL_RTL (parms), 0))\n-\t\t|| GET_CODE (XEXP (DECL_RTL (parms), 0)) == MEM)\n+\t\t|| MEM_P (XEXP (DECL_RTL (parms), 0)))\n \t      current_sym_value = 0;\n \t    else\n \t      current_sym_value = INTVAL (XEXP (XEXP (DECL_RTL (parms), 0), 1));\n@@ -1412,7 +1412,7 @@ sdbout_reg_parms (tree parms)\n \t    PUT_SDB_ENDEF;\n \t  }\n \t/* Report parms that live in memory but not where they were passed.  */\n-\telse if (GET_CODE (DECL_RTL (parms)) == MEM\n+\telse if (MEM_P (DECL_RTL (parms))\n \t\t && GET_CODE (XEXP (DECL_RTL (parms), 0)) == PLUS\n \t\t && GET_CODE (XEXP (XEXP (DECL_RTL (parms), 0), 1)) == CONST_INT\n \t\t && PARM_PASSED_IN_MEMORY (parms)\n@@ -1464,7 +1464,7 @@ sdbout_global_decl (tree decl)\n \n       /* Output COFF information for non-global file-scope initialized\n \t variables.  */\n-      if (DECL_INITIAL (decl) && GET_CODE (DECL_RTL (decl)) == MEM)\n+      if (DECL_INITIAL (decl) && MEM_P (DECL_RTL (decl)))\n \tsdbout_toplevel_data (decl);\n     }\n }"}, {"sha": "0d24be864709963b3ba9821ca718fcbd7771e335", "filename": "gcc/simplify-rtx.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fsimplify-rtx.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fsimplify-rtx.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsimplify-rtx.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -3719,7 +3719,7 @@ simplify_subreg (enum machine_mode outermode, rtx op,\n      SUBREG with it.  Don't do this if the MEM has a mode-dependent address\n      or if we would be widening it.  */\n \n-  if (GET_CODE (op) == MEM\n+  if (MEM_P (op)\n       && ! mode_dependent_address_p (XEXP (op, 0))\n       /* Allow splitting of volatile memory references in case we don't\n          have instruction to move the whole thing.  */"}, {"sha": "9f7ca381bbb8bd7f044fb3454a81d94981163f25", "filename": "gcc/stmt.c", "status": "modified", "additions": 9, "deletions": 9, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fstmt.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fstmt.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstmt.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -1513,12 +1513,12 @@ expand_asm_operands (tree string, tree outputs, tree inputs,\n \t  || is_inout)\n \t{\n \t  op = expand_expr (val, NULL_RTX, VOIDmode, EXPAND_WRITE);\n-\t  if (GET_CODE (op) == MEM)\n+\t  if (MEM_P (op))\n \t    op = validize_mem (op);\n \n-\t  if (! allows_reg && GET_CODE (op) != MEM)\n+\t  if (! allows_reg && !MEM_P (op))\n \t    error (\"output number %d not directly addressable\", i);\n-\t  if ((! allows_mem && GET_CODE (op) == MEM)\n+\t  if ((! allows_mem && MEM_P (op))\n \t      || GET_CODE (op) == CONCAT)\n \t    {\n \t      real_output_rtx[i] = protect_from_queue (op, 1);\n@@ -1587,7 +1587,7 @@ expand_asm_operands (tree string, tree outputs, tree inputs,\n       /* Never pass a CONCAT to an ASM.  */\n       if (GET_CODE (op) == CONCAT)\n \top = force_reg (GET_MODE (op), op);\n-      else if (GET_CODE (op) == MEM)\n+      else if (MEM_P (op))\n \top = validize_mem (op);\n \n       if (asm_operand_ok (op, constraint) <= 0)\n@@ -1597,7 +1597,7 @@ expand_asm_operands (tree string, tree outputs, tree inputs,\n \t  else if (!allows_mem)\n \t    warning (\"asm operand %d probably doesn't match constraints\",\n \t\t     i + noutputs);\n-\t  else if (GET_CODE (op) == MEM)\n+\t  else if (MEM_P (op))\n \t    {\n \t      /* We won't recognize either volatile memory or memory\n \t\t with a queued address as available a memory_operand\n@@ -2108,7 +2108,7 @@ expand_expr_stmt_value (tree exp, int want_value, int maybe_last)\n \n   /* If all we do is reference a volatile value in memory,\n      copy it to a register to be sure it is actually touched.  */\n-  if (value && GET_CODE (value) == MEM && TREE_THIS_VOLATILE (exp))\n+  if (value && MEM_P (value) && TREE_THIS_VOLATILE (exp))\n     {\n       if (TYPE_MODE (type) == VOIDmode)\n \t;\n@@ -3297,7 +3297,7 @@ expand_decl (tree decl)\n \t to the proper address.  */\n       if (DECL_RTL_SET_P (decl))\n \t{\n-\t  if (GET_CODE (DECL_RTL (decl)) != MEM\n+\t  if (!MEM_P (DECL_RTL (decl))\n \t      || !REG_P (XEXP (DECL_RTL (decl), 0)))\n \t    abort ();\n \t  oldaddr = XEXP (DECL_RTL (decl), 0);\n@@ -3621,7 +3621,7 @@ expand_anon_union_decl (tree decl, tree cleanup, tree decl_elts)\n \n       /* (SUBREG (MEM ...)) at RTL generation time is invalid, so we\n          instead create a new MEM rtx with the proper mode.  */\n-      if (GET_CODE (x) == MEM)\n+      if (MEM_P (x))\n \t{\n \t  if (mode == GET_MODE (x))\n \t    SET_DECL_RTL (decl_elt, x);\n@@ -4530,7 +4530,7 @@ expand_end_case_type (tree orig_index, tree orig_type)\n \t  do_pending_stack_adjust ();\n \n \t  index = protect_from_queue (index, 0);\n-\t  if (GET_CODE (index) == MEM)\n+\t  if (MEM_P (index))\n \t    index = copy_to_reg (index);\n \t  if (GET_CODE (index) == CONST_INT\n \t      || TREE_CODE (index_expr) == INTEGER_CST)"}, {"sha": "ac7622d9bff7e5f2bd1c278845f74f0d025456fc", "filename": "gcc/unroll.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Funroll.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Funroll.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Funroll.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -1599,7 +1599,7 @@ calculate_giv_inc (rtx pattern, rtx src_insn, unsigned int regno)\n \n       /* Some ports store large constants in memory and add a REG_EQUAL\n \t note to the store insn.  */\n-      else if (GET_CODE (increment) == MEM)\n+      else if (MEM_P (increment))\n \t{\n \t  rtx note = find_reg_note (src_insn, REG_EQUAL, 0);\n \t  if (note)"}, {"sha": "1ec25833c4283ad6c18d685cdc2e590a0fbd6fa7", "filename": "gcc/var-tracking.c", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fvar-tracking.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fvar-tracking.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fvar-tracking.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -370,7 +370,7 @@ stack_adjust_offset_pre_post (rtx pattern, HOST_WIDE_INT *pre,\n       else\n \t*post -= INTVAL (XEXP (src, 1));\n     }\n-  else if (GET_CODE (dest) == MEM)\n+  else if (MEM_P (dest))\n     {\n       /* (set (mem (pre_dec (reg sp))) (foo)) */\n       src = XEXP (dest, 0);\n@@ -474,7 +474,7 @@ bb_stack_adjust_offset (basic_block bb)\n \toffset += VTI (bb)->mos[i].u.adjust;\n       else if (VTI (bb)->mos[i].type != MO_CALL)\n \t{\n-\t  if (GET_CODE (VTI (bb)->mos[i].u.loc) == MEM)\n+\t  if (MEM_P (VTI (bb)->mos[i].u.loc))\n \t    {\n \t      VTI (bb)->mos[i].u.loc\n \t\t= adjust_stack_reference (VTI (bb)->mos[i].u.loc, -offset);\n@@ -1466,13 +1466,13 @@ track_expr_p (tree expr)\n      extern char **_dl_argv_internal __attribute__ ((alias (\"_dl_argv\")));\n      char **_dl_argv;\n   */\n-  if (GET_CODE (decl_rtl) == MEM\n+  if (MEM_P (decl_rtl)\n       && contains_symbol_ref (XEXP (decl_rtl, 0)))\n     return 0;\n \n   /* If RTX is a memory it should not be very large (because it would be\n      an array or struct).  */\n-  if (GET_CODE (decl_rtl) == MEM)\n+  if (MEM_P (decl_rtl))\n     {\n       /* Do not track structures and arrays.  */\n       if (GET_MODE (decl_rtl) == BLKmode)\n@@ -1501,7 +1501,7 @@ count_uses (rtx *loc, void *insn)\n #endif\n \tVTI (bb)->n_mos++;\n     }\n-  else if (GET_CODE (*loc) == MEM\n+  else if (MEM_P (*loc)\n \t   && MEM_EXPR (*loc)\n \t   && track_expr_p (MEM_EXPR (*loc)))\n     {\n@@ -1544,7 +1544,7 @@ add_uses (rtx *loc, void *insn)\n       mo->u.loc = *loc;\n       mo->insn = (rtx) insn;\n     }\n-  else if (GET_CODE (*loc) == MEM\n+  else if (MEM_P (*loc)\n \t   && MEM_EXPR (*loc)\n \t   && track_expr_p (MEM_EXPR (*loc)))\n     {\n@@ -1585,7 +1585,7 @@ add_stores (rtx loc, rtx expr, void *insn)\n       mo->u.loc = loc;\n       mo->insn = (rtx) insn;\n     }\n-  else if (GET_CODE (loc) == MEM\n+  else if (MEM_P (loc)\n \t   && MEM_EXPR (loc)\n \t   && track_expr_p (MEM_EXPR (loc)))\n     {\n@@ -1631,7 +1631,7 @@ compute_bb_dataflow (basic_block bb)\n \n \t      if (REG_P (loc))\n \t\tvar_reg_delete_and_set (out, loc);\n-\t      else if (GET_CODE (loc) == MEM)\n+\t      else if (MEM_P (loc))\n \t\tvar_mem_delete_and_set (out, loc);\n \t    }\n \t    break;\n@@ -1643,7 +1643,7 @@ compute_bb_dataflow (basic_block bb)\n \n \t      if (REG_P (loc))\n \t\tvar_reg_delete (out, loc);\n-\t      else if (GET_CODE (loc) == MEM)\n+\t      else if (MEM_P (loc))\n \t\tvar_mem_delete (out, loc);\n \t    }\n \t    break;\n@@ -2472,7 +2472,7 @@ vt_get_decl_and_offset (rtx rtl, tree *declp, HOST_WIDE_INT *offsetp)\n \t  return true;\n \t}\n     }\n-  else if (GET_CODE (rtl) == MEM)\n+  else if (MEM_P (rtl))\n     {\n       if (MEM_ATTRS (rtl))\n \t{\n@@ -2529,7 +2529,7 @@ vt_add_function_parameters (void)\n #endif\n \n       incoming = eliminate_regs (incoming, 0, NULL_RTX);\n-      if (!frame_pointer_needed && GET_CODE (incoming) == MEM)\n+      if (!frame_pointer_needed && MEM_P (incoming))\n \tincoming = adjust_stack_reference (incoming, -stack_adjust);\n       out = &VTI (ENTRY_BLOCK_PTR)->out;\n \n@@ -2543,7 +2543,7 @@ vt_add_function_parameters (void)\n \t\t\t     parm, offset, incoming);\n \t  set_variable_part (out, incoming, parm, offset);\n \t}\n-      else if (GET_CODE (incoming) == MEM)\n+      else if (MEM_P (incoming))\n \t{\n \t  set_variable_part (out, incoming, parm, offset);\n \t}"}, {"sha": "95434b55ae8bbafc036c580b608f29d441f1b701", "filename": "gcc/varasm.c", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fvarasm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3c0cb5de6a4e067a36096c2141384bf9e3f520b6/gcc%2Fvarasm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fvarasm.c?ref=3c0cb5de6a4e067a36096c2141384bf9e3f520b6", "patch": "@@ -896,7 +896,7 @@ make_decl_rtl (tree decl, const char *asmspec)\n void\n make_var_volatile (tree var)\n {\n-  if (GET_CODE (DECL_RTL (var)) != MEM)\n+  if (!MEM_P (DECL_RTL (var)))\n     abort ();\n \n   MEM_VOLATILE_P (DECL_RTL (var)) = 1;\n@@ -1059,7 +1059,7 @@ notice_global_symbol (tree decl)\n \t      || (DECL_COMMON (decl)\n \t\t  && (DECL_INITIAL (decl) == 0\n \t\t      || DECL_INITIAL (decl) == error_mark_node))))\n-      || GET_CODE (DECL_RTL (decl)) != MEM)\n+      || !MEM_P (DECL_RTL (decl)))\n     return;\n \n   /* We win when global object is found, but it is useful to know about weak\n@@ -1652,7 +1652,7 @@ assemble_external (tree decl ATTRIBUTE_UNUSED)\n     {\n       rtx rtl = DECL_RTL (decl);\n \n-      if (GET_CODE (rtl) == MEM && GET_CODE (XEXP (rtl, 0)) == SYMBOL_REF\n+      if (MEM_P (rtl) && GET_CODE (XEXP (rtl, 0)) == SYMBOL_REF\n \t  && !SYMBOL_REF_USED (XEXP (rtl, 0))\n \t  && !incorporeal_function_p (decl))\n \t{\n@@ -2039,7 +2039,7 @@ decode_addr_const (tree exp, struct addr_const *value)\n       abort ();\n     }\n \n-  if (GET_CODE (x) != MEM)\n+  if (!MEM_P (x))\n     abort ();\n   x = XEXP (x, 0);\n \n@@ -4029,7 +4029,7 @@ mark_weak (tree decl)\n   DECL_WEAK (decl) = 1;\n \n   if (DECL_RTL_SET_P (decl)\n-      && GET_CODE (DECL_RTL (decl)) == MEM\n+      && MEM_P (DECL_RTL (decl))\n       && XEXP (DECL_RTL (decl), 0)\n       && GET_CODE (XEXP (DECL_RTL (decl), 0)) == SYMBOL_REF)\n     SYMBOL_REF_WEAK (XEXP (DECL_RTL (decl), 0)) = 1;\n@@ -4893,7 +4893,7 @@ default_encode_section_info (tree decl, rtx rtl, int first ATTRIBUTE_UNUSED)\n   int flags;\n \n   /* Careful not to prod global register variables.  */\n-  if (GET_CODE (rtl) != MEM)\n+  if (!MEM_P (rtl))\n     return;\n   symbol = XEXP (rtl, 0);\n   if (GET_CODE (symbol) != SYMBOL_REF)"}]}