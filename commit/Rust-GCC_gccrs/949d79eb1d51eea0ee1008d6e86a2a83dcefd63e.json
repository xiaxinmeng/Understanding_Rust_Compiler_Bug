{"sha": "949d79eb1d51eea0ee1008d6e86a2a83dcefd63e", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OTQ5ZDc5ZWIxZDUxZWVhMGVlMTAwOGQ2ZTg2YTJhODNkY2VmZDYzZQ==", "commit": {"author": {"name": "Richard Earnshaw", "email": "rearnsha@arm.com", "date": "1999-08-04T13:40:10Z"}, "committer": {"name": "Richard Earnshaw", "email": "rearnsha@gcc.gnu.org", "date": "1999-08-04T13:40:10Z"}, "message": "arm.c (typedef minipool_node): Renamed from pool_node.\n\n* arm.c (typedef minipool_node): Renamed from pool_node.\n(minipool_vector, minipool_size, minipool_vector_label): Similarly.\n(add_minipool_constant): New function.\n(dump_minipool): New function.\n(find_barrier): Remove special case for getting the insn size of\nan insn that references the constant pool.\n(minipool_fixup): New structure.\n(push_minipool_barrier): New function.\n(push_minipool_fix): New function.\n(note_invalid_constants): New function.\n(add_pool_constant, dump_table, fixit, broken_move): Delete.\n(arm_reorg): Rewrite code to fix up the constant pool into a\nseries of mini-pools embedded in the insn stream.\n(arm_output_epilogue): New function, made mainly from the body\nof output_func_epilogue.\n(output_func_epilogue): Move insn generation part of epilogue code\nto arm_output_epilogue.\n* arm.h (ASM_OUTPUT_SPECIAL_POOL_ENTRY): Delete.\n* arm.md (pool_range): New attribute.\n(zero_extendqidi2): Add attribute pool_range.\n(zero_extend_hisi_insn, load_extendqisi, extendhisi_insn,\nextendqihi_insn, extendqisi_insn, movdi, movsi_insn, pic_load_addr,\npic_load_addr_based_insn, movhi_insn_arch4, movhi_insn_littleend,\nmovhi_insn_bigend, loadhi_si_bigend, movsf_hard_insn, movsf_soft_insn,\nmovdf_hard_insn, movdf_soft_insn, movxf_hard_insn): Likewise.\n(epilogue): New expand.\n(epilogue_insn): New insn.  Call arm_output_epilogue.\n\n* arm.c (arm_poke_function_name): Undo change of July 17.  Tidy up.\n* arm.h (TARGET_SWITCHES): Add missing doc string for TARGET_DEFAULT.\n\nFrom-SVN: r28499", "tree": {"sha": "a6be283c1c76509e6e6c7dd42ecc51c3a0f660d3", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/a6be283c1c76509e6e6c7dd42ecc51c3a0f660d3"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/949d79eb1d51eea0ee1008d6e86a2a83dcefd63e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/949d79eb1d51eea0ee1008d6e86a2a83dcefd63e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/949d79eb1d51eea0ee1008d6e86a2a83dcefd63e", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/949d79eb1d51eea0ee1008d6e86a2a83dcefd63e/comments", "author": null, "committer": null, "parents": [{"sha": "49f48c719e00f7aa5ff80a07ee4a4c8740cb662e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/49f48c719e00f7aa5ff80a07ee4a4c8740cb662e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/49f48c719e00f7aa5ff80a07ee4a4c8740cb662e"}], "stats": {"total": 829, "additions": 477, "deletions": 352}, "files": [{"sha": "ad20fac6a864a1b3678229e06520707cfe6523c8", "filename": "gcc/ChangeLog", "status": "modified", "additions": 31, "deletions": 0, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/949d79eb1d51eea0ee1008d6e86a2a83dcefd63e/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/949d79eb1d51eea0ee1008d6e86a2a83dcefd63e/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=949d79eb1d51eea0ee1008d6e86a2a83dcefd63e", "patch": "@@ -3,6 +3,37 @@ Wed Aug  4 09:06:14 1999  Richard Earnshaw (rearnsha@arm.com)\n \t* recog.c (preproces_constraints): Zero recog_op_alt before \n \tprocessing the constraints.\n \n+\t* arm.c (typedef minipool_node): Renamed from pool_node.\n+\t(minipool_vector, minipool_size, minipool_vector_label): Similarly.\n+\t(add_minipool_constant): New function.\n+\t(dump_minipool): New function.\n+\t(find_barrier): Remove special case for getting the insn size of\n+\tan insn that references the constant pool.\n+\t(minipool_fixup): New structure.\n+\t(push_minipool_barrier): New function.\n+\t(push_minipool_fix): New function.\n+\t(note_invalid_constants): New function.\n+\t(add_pool_constant, dump_table, fixit, broken_move): Delete.\n+\t(arm_reorg): Rewrite code to fix up the constant pool into a\n+\tseries of mini-pools embedded in the insn stream.\n+\t(arm_output_epilogue): New function, made mainly from the body\n+\tof output_func_epilogue.\n+\t(output_func_epilogue): Move insn generation part of epilogue code\n+\tto arm_output_epilogue.\n+\t* arm.h (ASM_OUTPUT_SPECIAL_POOL_ENTRY): Delete.\n+\t* arm.md (pool_range): New attribute.\n+\t(zero_extendqidi2): Add attribute pool_range.\n+\t(zero_extend_hisi_insn, load_extendqisi, extendhisi_insn,\n+\textendqihi_insn, extendqisi_insn, movdi, movsi_insn, pic_load_addr,\n+\tpic_load_addr_based_insn, movhi_insn_arch4, movhi_insn_littleend,\n+\tmovhi_insn_bigend, loadhi_si_bigend, movsf_hard_insn, movsf_soft_insn,\n+\tmovdf_hard_insn, movdf_soft_insn, movxf_hard_insn): Likewise.\n+\t(epilogue): New expand.\n+\t(epilogue_insn): New insn.  Call arm_output_epilogue.\n+\n+\t* arm.c (arm_poke_function_name): Undo change of July 17.  Tidy up.\n+\t* arm.h (TARGET_SWITCHES): Add missing doc string for TARGET_DEFAULT.\n+\n Mon Aug  2 19:18:44 1999  Jason Merrill  <jason@yorick.cygnus.com>\n \n \t* linux.h (HANDLE_PRAGMA_PACK_PUSH_POP): Define."}, {"sha": "38c7c58ca0d76168205928584f97171684c1f3af", "filename": "gcc/config/arm/arm.c", "status": "modified", "additions": 377, "deletions": 326, "changes": 703, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/949d79eb1d51eea0ee1008d6e86a2a83dcefd63e/gcc%2Fconfig%2Farm%2Farm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/949d79eb1d51eea0ee1008d6e86a2a83dcefd63e/gcc%2Fconfig%2Farm%2Farm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.c?ref=949d79eb1d51eea0ee1008d6e86a2a83dcefd63e", "patch": "@@ -1,5 +1,5 @@\n /* Output routines for GCC for ARM.\n-   Copyright (C) 1991, 93, 94, 95, 96, 97, 98, 1999 Free Software Foundation, Inc.\n+   Copyright (C) 1991, 93-98, 1999 Free Software Foundation, Inc.\n    Contributed by Pieter `Tiggr' Schoenmakers (rcpieter@win.tue.nl)\n    and Martin Simmons (@harleqn.co.uk).\n    More major hacks by Richard Earnshaw (rearnsha@arm.com).\n@@ -55,11 +55,13 @@ static int arm_naked_function_p PROTO ((tree));\n static void init_fpa_table PROTO ((void));\n static enum machine_mode select_dominance_cc_mode PROTO ((rtx, rtx,\n \t\t\t\t\t\t\t  HOST_WIDE_INT));\n-static HOST_WIDE_INT add_constant PROTO ((rtx, enum machine_mode, int *));\n-static void dump_table PROTO ((rtx));\n-static int fixit PROTO ((rtx, enum machine_mode, int));\n+static HOST_WIDE_INT add_minipool_constant PROTO ((rtx, enum machine_mode));\n+static void dump_minipool PROTO ((rtx));\n static rtx find_barrier PROTO ((rtx, int));\n-static int broken_move PROTO ((rtx));\n+static void push_minipool_fix PROTO ((rtx, int, rtx *, enum machine_mode,\n+\t\t\t\t      rtx));\n+static void push_minipool_barrier PROTO ((rtx, int));\n+static void note_invalid_constants PROTO ((rtx, int));\n static char * fp_const_from_val PROTO ((REAL_VALUE_TYPE *));\n static int eliminate_lr2ip PROTO ((rtx *));\n static char * shift_op PROTO ((rtx, HOST_WIDE_INT *));\n@@ -104,7 +106,8 @@ int    arm_structure_size_boundary = 32; /* Used to be 8 */\n #define FL_LDSCHED    (1 << 7)\t      /* Load scheduling necessary */\n #define FL_STRONG     (1 << 8)\t      /* StrongARM */\n \n-/* The bits in this mask specify which instructions we are allowed to generate.  */\n+/* The bits in this mask specify which instructions we are allowed to\n+   generate.  */\n static int insn_flags = 0;\n /* The bits in this mask specify which instruction scheduling options should\n    be used.  Note - there is an overlap with the FL_FAST_MULT.  For some\n@@ -199,11 +202,13 @@ static struct processors all_cores[] =\n   {\"arm600\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 },\n   {\"arm610\",\t             FL_MODE26 | FL_MODE32 },\n   {\"arm620\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 },\n-  {\"arm7\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 }, \n-  {\"arm7m\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 | FL_FAST_MULT }, /* arm7m doesn't exist on its own, */\n-  {\"arm7d\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 }, \t\t     /* but only with D, (and I),       */\n-  {\"arm7dm\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 | FL_FAST_MULT }, /* but those don't alter the code, */\n-  {\"arm7di\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 },\t\t     /* so arm7m is sometimes used.     */\n+  {\"arm7\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 },\n+  /* arm7m doesn't exist on its own, but only with D, (and I), but\n+   those don't alter the code, so arm7m is sometimes used.  */\n+  {\"arm7m\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 | FL_FAST_MULT },\n+  {\"arm7d\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 },\n+  {\"arm7dm\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 | FL_FAST_MULT },\n+  {\"arm7di\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 },\n   {\"arm7dmi\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 | FL_FAST_MULT },\n   {\"arm70\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 },\n   {\"arm700\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 },\n@@ -212,7 +217,8 @@ static struct processors all_cores[] =\n   {\"arm710c\",\t             FL_MODE26 | FL_MODE32 },\n   {\"arm7100\",\t             FL_MODE26 | FL_MODE32 },\n   {\"arm7500\",\t             FL_MODE26 | FL_MODE32 },\n-  {\"arm7500fe\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 }, /* Doesn't really have an external co-proc, but does have embedded fpu.  */\n+  /* Doesn't have an external co-proc, but does have embedded fpu.  */\n+  {\"arm7500fe\",\tFL_CO_PROC | FL_MODE26 | FL_MODE32 },\n   {\"arm7tdmi\",\tFL_CO_PROC |             FL_MODE32 | FL_FAST_MULT | FL_ARCH4 | FL_THUMB },\n   {\"arm8\",\t             FL_MODE26 | FL_MODE32 | FL_FAST_MULT | FL_ARCH4 |            FL_LDSCHED },\n   {\"arm810\",\t             FL_MODE26 | FL_MODE32 | FL_FAST_MULT | FL_ARCH4 |            FL_LDSCHED },\n@@ -235,7 +241,7 @@ static struct processors all_architectures[] =\n   { \"armv2a\",    FL_CO_PROC | FL_MODE26 },\n   { \"armv3\",     FL_CO_PROC | FL_MODE26 | FL_MODE32 },\n   { \"armv3m\",    FL_CO_PROC | FL_MODE26 | FL_MODE32 | FL_FAST_MULT },\n-  { \"armv4\",     FL_CO_PROC | FL_MODE26 | FL_MODE32 | FL_FAST_MULT | FL_ARCH4  },\n+  { \"armv4\",     FL_CO_PROC | FL_MODE26 | FL_MODE32 | FL_FAST_MULT | FL_ARCH4 },\n   /* Strictly, FL_MODE26 is a permitted option for v4t, but there are no\n      implementations that support it, so we will leave it out for now.  */\n   { \"armv4t\",    FL_CO_PROC |             FL_MODE32 | FL_FAST_MULT | FL_ARCH4 | FL_THUMB },\n@@ -1877,20 +1883,12 @@ arm_adjust_cost (insn, link, dep, cost)\n \t constant pool are cached, and that others will miss.  This is a \n \t hack. */\n       \n-/*       debug_rtx (insn);\n-      debug_rtx (dep);\n-      debug_rtx (link);\n-      fprintf (stderr, \"costs %d\\n\", cost); */\n-\n       if (CONSTANT_POOL_ADDRESS_P (XEXP (SET_SRC (i_pat), 0))\n \t  || reg_mentioned_p (stack_pointer_rtx, XEXP (SET_SRC (i_pat), 0))\n \t  || reg_mentioned_p (frame_pointer_rtx, XEXP (SET_SRC (i_pat), 0))\n \t  || reg_mentioned_p (hard_frame_pointer_rtx, \n \t\t\t      XEXP (SET_SRC (i_pat), 0)))\n-\t{\n-/* \t  fprintf (stderr, \"***** Now 1\\n\"); */\n-\t  return 1;\n-\t}\n+\treturn 1;\n     }\n \n   return cost;\n@@ -2807,15 +2805,16 @@ load_multiple_sequence (operands, nops, regs, base, load_offset)\n   if (unsorted_offsets[order[nops - 1]] == -4)\n     return 4; /* ldmdb */\n \n-  /* For ARM8,9 & StrongARM, 2 ldr instructions are faster than an ldm if\n-     the offset isn't small enough.  The reason 2 ldrs are faster is because\n-     these ARMs are able to do more than one cache access in a single cycle.\n-     The ARM9 and StrongARM have Harvard caches, whilst the ARM8 has a double \n-     bandwidth cache.  This means that these cores can do both an instruction \n-     fetch and a data fetch in a single cycle, so the trick of calculating the \n-     address into a scratch register (one of the result regs) and then doing a \n-     load multiple actually becomes slower (and no smaller in code size).  That \n-     is the transformation\n+  /* For ARM8,9 & StrongARM, 2 ldr instructions are faster than an ldm\n+     if the offset isn't small enough.  The reason 2 ldrs are faster\n+     is because these ARMs are able to do more than one cache access\n+     in a single cycle.  The ARM9 and StrongARM have Harvard caches,\n+     whilst the ARM8 has a double bandwidth cache.  This means that\n+     these cores can do both an instruction fetch and a data fetch in\n+     a single cycle, so the trick of calculating the address into a\n+     scratch register (one of the result regs) and then doing a load\n+     multiple actually becomes slower (and no smaller in code size).\n+     That is the transformation\n  \n  \tldr\trd1, [rbase + offset]\n  \tldr\trd2, [rbase + offset + 4]\n@@ -2825,15 +2824,16 @@ load_multiple_sequence (operands, nops, regs, base, load_offset)\n  \tadd\trd1, rbase, offset\n  \tldmia\trd1, {rd1, rd2}\n  \n-     produces worse code -- '3 cycles + any stalls on rd2' instead of '2 cycles \n-     + any stalls on rd2'.  On ARMs with only one cache access per cycle, the \n-     first sequence could never complete in less than 6 cycles, whereas the ldm \n-     sequence would only take 5 and would make better use of sequential accesses\n-     if not hitting the cache.\n-\n-     We cheat here and test 'arm_ld_sched' which we currently know to only be\n-     true for the ARM8, ARM9 and StrongARM.  If this ever changes, then the test\n-     below needs to be reworked.  */\n+     produces worse code -- '3 cycles + any stalls on rd2' instead of\n+     '2 cycles + any stalls on rd2'.  On ARMs with only one cache\n+     access per cycle, the first sequence could never complete in less\n+     than 6 cycles, whereas the ldm sequence would only take 5 and\n+     would make better use of sequential accesses if not hitting the\n+     cache.\n+\n+     We cheat here and test 'arm_ld_sched' which we currently know to\n+     only be true for the ARM8, ARM9 and StrongARM.  If this ever\n+     changes, then the test below needs to be reworked.  */\n   if (nops == 2 && arm_ld_sched)\n     return 0;\n \n@@ -3919,60 +3919,68 @@ arm_reload_out_hi (operands)\n }\n \f\n /* Routines for manipulation of the constant pool.  */\n-/* This is unashamedly hacked from the version in sh.c, since the problem is\n-   extremely similar.  */\n \n-/* Arm instructions cannot load a large constant into a register,\n-   constants have to come from a pc relative load.  The reference of a pc\n-   relative load instruction must be less than 1k infront of the instruction.\n-   This means that we often have to dump a constant inside a function, and\n+/* Arm instructions cannot load a large constant directly into a\n+   register; they have to come from a pc relative load.  The constant\n+   must therefore be placed in the addressable range of the pc\n+   relative load.  Depending on the precise pc relative load\n+   instruction the range is somewhere between 256 bytes and 4k.  This\n+   means that we often have to dump a constant inside a function, and\n    generate code to branch around it.\n \n-   It is important to minimize this, since the branches will slow things\n-   down and make things bigger.\n+   It is important to minimize this, since the branches will slow\n+   things down and make the code larger.\n \n-   Worst case code looks like:\n+   Normally we can hide the table after an existing unconditional\n+   branch so that there is no interruption of the flow, but in the\n+   worst case the code looks like this:\n \n \tldr\trn, L1\n+\t...\n \tb\tL2\n \talign\n \tL1:\t.long value\n \tL2:\n-\t..\n-\n-\tldr\trn, L3\n-\tb\tL4\n-\talign\n-\tL3:\t.long value\n-\tL4:\n-\t..\n-\n-   We fix this by performing a scan before scheduling, which notices which\n-   instructions need to have their operands fetched from the constant table\n-   and builds the table.\n-\n-\n-   The algorithm is:\n+\t...\n \n-   scan, find an instruction which needs a pcrel move.  Look forward, find th\n-   last barrier which is within MAX_COUNT bytes of the requirement.\n-   If there isn't one, make one.  Process all the instructions between\n-   the find and the barrier.\n-\n-   In the above example, we can tell that L3 is within 1k of L1, so\n-   the first move can be shrunk from the 2 insn+constant sequence into\n-   just 1 insn, and the constant moved to L3 to make:\n-\n-\tldr\trn, L1\n-\t..\n \tldr\trn, L3\n+\t...\n \tb\tL4\n \talign\n-\tL1:\t.long value\n \tL3:\t.long value\n \tL4:\n-\n-   Then the second move becomes the target for the shortening process.\n+\t...\n+\n+   We fix this by performing a scan after scheduling, which notices\n+   which instructions need to have their operands fetched from the\n+   constant table and builds the table.\n+\n+   The algorithm starts by building a table of all the constants that\n+   need fixing up and all the natural barriers in the function (places\n+   where a constant table can be dropped without breaking the flow).\n+   For each fixup we note how far the pc-relative replacement will be\n+   able to reach and the offset of the instruction into the function.\n+\n+   Having built the table we then group the fixes together to form\n+   tables that are as large as possible (subject to addressing\n+   constraints) and emit each table of constants after the last\n+   barrier that is within range of all the instructions in the group.\n+   If a group does not contain a barrier, then we forcibly create one\n+   by inserting a jump instruction into the flow.  Once the table has\n+   been inserted, the insns are then modified to reference the\n+   relevant entry in the pool.\n+\n+   Possible enhancements to the alogorithm (not implemented) are:\n+\n+   1) ARM instructions (but not thumb) can use negative offsets, so we\n+   could reference back to a previous pool rather than forwards to a\n+   new one.  For large functions this may reduce the number of pools\n+   required.\n+\n+   2) For some processors and object formats, there may be benefit in\n+   aligning the pools to the start of cache lines; this alignment\n+   would need to be taken into account when calculating addressability\n+   of a pool.\n \n  */\n \n@@ -3981,16 +3989,16 @@ typedef struct\n   rtx value;                    /* Value in table */\n   HOST_WIDE_INT next_offset;\n   enum machine_mode mode;       /* Mode of value */\n-} pool_node;\n+} minipool_node;\n \n /* The maximum number of constants that can fit into one pool, since\n-   the pc relative range is 0...1020 bytes and constants are at least 4\n-   bytes long */\n+   the pc relative range is 0...4092 bytes and constants are at least 4\n+   bytes long.  */\n \n-#define MAX_POOL_SIZE (1020/4)\n-static pool_node pool_vector[MAX_POOL_SIZE];\n-static int pool_size;\n-static rtx pool_vector_label;\n+#define MAX_MINIPOOL_SIZE (4092/4)\n+static minipool_node minipool_vector[MAX_MINIPOOL_SIZE];\n+static int minipool_size;\n+static rtx minipool_vector_label;\n \n /* Add a constant to the pool and return its offset within the current\n    pool.\n@@ -3999,82 +4007,58 @@ static rtx pool_vector_label;\n    ADDRESS_ONLY will be non-zero if we really want the address of such\n    a constant, not the constant itself.  */\n static HOST_WIDE_INT\n-add_constant (x, mode, address_only)\n+add_minipool_constant (x, mode)\n      rtx x;\n      enum machine_mode mode;\n-     int * address_only;\n {\n   int i;\n   HOST_WIDE_INT offset;\n-\n-  * address_only = 0;\n   \n-  if (mode == SImode && GET_CODE (x) == MEM && CONSTANT_P (XEXP (x, 0))\n-      && CONSTANT_POOL_ADDRESS_P (XEXP (x, 0)))\n-    x = get_pool_constant (XEXP (x, 0));\n-  else if (GET_CODE (x) == SYMBOL_REF && CONSTANT_POOL_ADDRESS_P(x))\n-    {\n-      *address_only = 1;\n-      mode = get_pool_mode (x);\n-      x = get_pool_constant (x);\n-    }\n-#ifndef AOF_ASSEMBLER\n-  else if (GET_CODE (x) == UNSPEC && XINT (x, 1) == 3)\n-    x = XVECEXP (x, 0, 0);\n-#endif\n-\n-#ifdef AOF_ASSEMBLER\n-  /* PIC Symbol references need to be converted into offsets into the \n-     based area.  */\n-  if (flag_pic && GET_CODE (x) == SYMBOL_REF)\n-    x = aof_pic_entry (x);\n-#endif /* AOF_ASSEMBLER */\n-\n-  /* First see if we've already got it */\n-  for (i = 0; i < pool_size; i++)\n+  /* First, see if we've already got it.  */\n+  for (i = 0; i < minipool_size; i++)\n     {\n-      if (GET_CODE (x) == pool_vector[i].value->code\n-\t  && mode == pool_vector[i].mode)\n+      if (GET_CODE (x) == minipool_vector[i].value->code\n+\t  && mode == minipool_vector[i].mode)\n \t{\n \t  if (GET_CODE (x) == CODE_LABEL)\n \t    {\n-\t      if (XINT (x, 3) != XINT (pool_vector[i].value, 3))\n+\t      if (XINT (x, 3) != XINT (minipool_vector[i].value, 3))\n \t\tcontinue;\n \t    }\n-\t  if (rtx_equal_p (x, pool_vector[i].value))\n-\t    return pool_vector[i].next_offset - GET_MODE_SIZE (mode);\n+\t  if (rtx_equal_p (x, minipool_vector[i].value))\n+\t    return minipool_vector[i].next_offset - GET_MODE_SIZE (mode);\n \t}\n     }\n \n   /* Need a new one */\n-  pool_vector[pool_size].next_offset = GET_MODE_SIZE (mode);\n+  minipool_vector[minipool_size].next_offset = GET_MODE_SIZE (mode);\n   offset = 0;\n-  if (pool_size == 0)\n-    pool_vector_label = gen_label_rtx ();\n+  if (minipool_size == 0)\n+    minipool_vector_label = gen_label_rtx ();\n   else\n-    pool_vector[pool_size].next_offset\n-      += (offset = pool_vector[pool_size - 1].next_offset);\n+    minipool_vector[minipool_size].next_offset\n+      += (offset = minipool_vector[minipool_size - 1].next_offset);\n \n-  pool_vector[pool_size].value = x;\n-  pool_vector[pool_size].mode = mode;\n-  pool_size++;\n+  minipool_vector[minipool_size].value = x;\n+  minipool_vector[minipool_size].mode = mode;\n+  minipool_size++;\n   return offset;\n }\n \n /* Output the literal table */\n static void\n-dump_table (scan)\n+dump_minipool (scan)\n      rtx scan;\n {\n   int i;\n \n   scan = emit_label_after (gen_label_rtx (), scan);\n   scan = emit_insn_after (gen_align_4 (), scan);\n-  scan = emit_label_after (pool_vector_label, scan);\n+  scan = emit_label_after (minipool_vector_label, scan);\n \n-  for (i = 0; i < pool_size; i++)\n+  for (i = 0; i < minipool_size; i++)\n     {\n-      pool_node * p = pool_vector + i;\n+      minipool_node *p = minipool_vector + i;\n \n       switch (GET_MODE_SIZE (p->mode))\n \t{\n@@ -4094,39 +4078,11 @@ dump_table (scan)\n \n   scan = emit_insn_after (gen_consttable_end (), scan);\n   scan = emit_barrier_after (scan);\n-  pool_size = 0;\n+  minipool_size = 0;\n }\n \n-/* Non zero if the src operand needs to be fixed up */\n-static int\n-fixit (src, mode, destreg)\n-     rtx src;\n-     enum machine_mode mode;\n-     int destreg;\n-{\n-  if (CONSTANT_P (src))\n-    {\n-      if (GET_CODE (src) == CONST_INT)\n-\treturn (! const_ok_for_arm (INTVAL (src))\n-\t\t&& ! const_ok_for_arm (~INTVAL (src)));\n-      if (GET_CODE (src) == CONST_DOUBLE)\n-\treturn (GET_MODE (src) == VOIDmode\n-\t\t|| destreg < 16\n-\t\t|| (! const_double_rtx_ok_for_fpu (src)\n-\t\t    && ! neg_const_double_rtx_ok_for_fpu (src)));\n-      return symbol_mentioned_p (src);\n-    }\n-#ifndef AOF_ASSEMBLER\n-  else if (GET_CODE (src) == UNSPEC && XINT (src, 1) == 3)\n-    return 1;\n-#endif\n-  else\n-    return (mode == SImode && GET_CODE (src) == MEM\n-\t    && GET_CODE (XEXP (src, 0)) == SYMBOL_REF\n-\t    && CONSTANT_POOL_ADDRESS_P (XEXP (src, 0)));\n-}\n-\n-/* Find the last barrier less than MAX_COUNT bytes from FROM, or create one. */\n+/* Find the last barrier less than MAX_COUNT bytes from FROM, or\n+   create one.  */\n static rtx\n find_barrier (from, max_count)\n      rtx from;\n@@ -4144,20 +4100,14 @@ find_barrier (from, max_count)\n \tfound_barrier = from;\n \n       /* Count the length of this insn */\n-      if (GET_CODE (from) == INSN\n-\t  && GET_CODE (PATTERN (from)) == SET\n-\t  && CONSTANT_P (SET_SRC (PATTERN (from)))\n-\t  && CONSTANT_POOL_ADDRESS_P (SET_SRC (PATTERN (from))))\n-\tcount += 8;\n-      /* Handle table jumps as a single entity.  */\n-      else if (GET_CODE (from) == JUMP_INSN\n-\t       && JUMP_LABEL (from) != 0\n-\t       && ((tmp = next_real_insn (JUMP_LABEL (from)))\n-\t\t   == next_real_insn (from))\n-\t       && tmp != NULL\n-\t       && GET_CODE (tmp) == JUMP_INSN\n-\t       && (GET_CODE (PATTERN (tmp)) == ADDR_VEC\n-\t\t   || GET_CODE (PATTERN (tmp)) == ADDR_DIFF_VEC))\n+      if (GET_CODE (from) == JUMP_INSN\n+\t  && JUMP_LABEL (from) != 0\n+\t  && ((tmp = next_real_insn (JUMP_LABEL (from)))\n+\t      == next_real_insn (from))\n+\t  && tmp != NULL\n+\t  && GET_CODE (tmp) == JUMP_INSN\n+\t  && (GET_CODE (PATTERN (tmp)) == ADDR_VEC\n+\t      || GET_CODE (PATTERN (tmp)) == ADDR_DIFF_VEC))\n \t{\n \t  int elt = GET_CODE (PATTERN (tmp)) == ADDR_DIFF_VEC ? 1 : 0;\n \t  count += (get_attr_length (from)\n@@ -4200,165 +4150,258 @@ find_barrier (from, max_count)\n   return found_barrier;\n }\n \n-/* Non zero if the insn is a move instruction which needs to be fixed. */\n-static int\n-broken_move (insn)\n+struct minipool_fixup\n+{\n+  struct minipool_fixup *next;\n+  rtx insn;\n+  int address;\n+  rtx *loc;\n+  enum machine_mode mode;\n+  rtx value;\n+  int range;\n+};\n+  \n+struct minipool_fixup *minipool_fix_head;\n+struct minipool_fixup *minipool_fix_tail;\n+\n+static void\n+push_minipool_barrier (insn, address)\n      rtx insn;\n+     int address;\n {\n-  if (!INSN_DELETED_P (insn)\n-      && GET_CODE (insn) == INSN\n-      && GET_CODE (PATTERN (insn)) == SET)\n-    {\n-      rtx pat = PATTERN (insn);\n-      rtx src = SET_SRC (pat);\n-      rtx dst = SET_DEST (pat);\n-      int destreg;\n-      enum machine_mode mode = GET_MODE (dst);\n+  struct minipool_fixup *fix\n+    = (struct minipool_fixup *) oballoc (sizeof (struct minipool_fixup));\n \n-      if (dst == pc_rtx)\n-\treturn 0;\n+  fix->insn = insn;\n+  fix->address = address;\n \n-      if (GET_CODE (dst) == REG)\n-\tdestreg = REGNO (dst);\n-      else if (GET_CODE (dst) == SUBREG && GET_CODE (SUBREG_REG (dst)) == REG)\n-\tdestreg = REGNO (SUBREG_REG (dst));\n-      else\n-\treturn 0;\n+  fix->next = NULL;\n+  if (minipool_fix_head != NULL)\n+    minipool_fix_tail->next = fix;\n+  else\n+    minipool_fix_head = fix;\n+\n+  minipool_fix_tail = fix;\n+}\n+\n+static void\n+push_minipool_fix (insn, address, loc, mode, value)\n+     rtx insn;\n+     int address;\n+     rtx *loc;\n+     enum machine_mode mode;\n+     rtx value;\n+{\n+  struct minipool_fixup *fix\n+    = (struct minipool_fixup *) oballoc (sizeof (struct minipool_fixup));\n+\n+#ifdef AOF_ASSEMBLER\n+  /* PIC symbol refereneces need to be converted into offsets into the\n+     based area.  */\n+  if (flag_pic && GET_MODE == SYMBOL_REF)\n+    value = aof_pic_entry (value);\n+#endif /* AOF_ASSEMBLER */\n+\n+  fix->insn = insn;\n+  fix->address = address;\n+  fix->loc = loc;\n+  fix->mode = mode;\n+  fix->value = value;\n+  fix->range = get_attr_pool_range (insn);\n+\n+  /* If an insn doesn't have a range defined for it, then it isn't\n+     expecting to be reworked by this code.  Better to abort now than\n+     to generate duff assembly code.  */\n+  if (fix->range == 0)\n+    abort ();\n+\n+  /* Add it to the chain of fixes */\n+  fix->next = NULL;\n+  if (minipool_fix_head != NULL)\n+    minipool_fix_tail->next = fix;\n+  else\n+    minipool_fix_head = fix;\n+\n+  minipool_fix_tail = fix;\n+}\n+\n+static void\n+note_invalid_constants (insn, address)\n+     rtx insn;\n+     int address;\n+{\n+  int opno;\n+\n+  /* Extract the operands of the insn */\n+  extract_insn(insn);\n+\n+  /* If this is an asm, we can't do anything about it (or can we?) */\n+  if (INSN_CODE (insn) < 0)\n+    return;\n+\n+  /* Find the alternative selected */\n+  if (! constrain_operands (1))\n+    fatal_insn_not_found (insn);\n+\n+  /* Preprocess the constraints, to extract some useful information.  */\n+  preprocess_constraints ();\n+\n+  for (opno = 0; opno < recog_n_operands; opno++)\n+    {\n+      /* Things we need to fix can only occur in inputs */\n+      if (recog_op_type[opno] != OP_IN)\n+\tcontinue;\n \n-      return fixit (src, mode, destreg);\n+      /* If this alternative is a memory reference, then any mention\n+\t of constants in this alternative is really to fool reload\n+\t into allowing us to accept one there.  We need to fix them up\n+\t now so that we output the right code.  */\n+      if (recog_op_alt[opno][which_alternative].memory_ok)\n+\t{\n+\t  rtx op = recog_operand[opno];\n+\n+\t  if (CONSTANT_P (op))\n+\t    push_minipool_fix (insn, address, recog_operand_loc[opno],\n+\t\t\t       recog_operand_mode[opno], op);\n+#ifndef AOF_ASSEMBLER\n+\t  else if (GET_CODE (op) == UNSPEC && XINT (op, 1) == 3)\n+\t    push_minipool_fix (insn, address, recog_operand_loc[opno],\n+\t\t\t       recog_operand_mode[opno], XVECEXP (op, 0, 0));\n+#endif\n+\t  else if (recog_operand_mode[opno] == SImode\n+\t\t   && GET_CODE (op) == MEM\n+\t\t   && GET_CODE (XEXP (op, 0)) == SYMBOL_REF\n+\t\t   && CONSTANT_POOL_ADDRESS_P (XEXP (op, 0)))\n+\t    push_minipool_fix (insn, address, recog_operand_loc[opno],\n+\t\t\t       recog_operand_mode[opno],\n+\t\t\t       get_pool_constant (XEXP (op, 0)));\n+\t}\n     }\n-  return 0;\n }\n \n void\n arm_reorg (first)\n      rtx first;\n {\n   rtx insn;\n-  int count_size;\n-\n-#if 0\n-  /* The ldr instruction can work with up to a 4k offset, and most constants\n-     will be loaded with one of these instructions; however, the adr \n-     instruction and the ldf instructions only work with a 1k offset.  This\n-     code needs to be rewritten to use the 4k offset when possible, and to\n-     adjust when a 1k offset is needed.  For now we just use a 1k offset\n-     from the start.  */\n-  count_size = 4000;\n-\n-  /* Floating point operands can't work further than 1024 bytes from the\n-     PC, so to make things simple we restrict all loads for such functions.\n-     */\n-  if (TARGET_HARD_FLOAT)\n-    {\n-      int regno;\n-\n-      for (regno = 16; regno < 24; regno++)\n-\tif (regs_ever_live[regno])\n-\t  {\n-\t    count_size = 1000;\n-\t    break;\n-\t  }\n-    }\n-#else\n-  count_size = 1000;\n-#endif /* 0 */\n+  int address = 0;\n+  struct minipool_fixup *fix;\n+\n+  minipool_fix_head = minipool_fix_tail = NULL;\n+\n+  /* The first insn must always be a note, or the code below won't\n+     scan it properly.  */\n+  if (GET_CODE (first) != NOTE)\n+    abort ();\n \n-  for (insn = first; insn; insn = NEXT_INSN (insn))\n+  /* Scan all the insns and record the operands that will need fixing.  */\n+  for (insn = next_nonnote_insn (first); insn; insn = next_nonnote_insn (insn))\n     {\n-      if (broken_move (insn))\n-\t{\n-\t  /* This is a broken move instruction, scan ahead looking for\n-\t     a barrier to stick the constant table behind */\n-\t  rtx scan;\n-\t  rtx barrier = find_barrier (insn, count_size);\n \n-\t  /* Now find all the moves between the points and modify them */\n-\t  for (scan = insn; scan != barrier; scan = NEXT_INSN (scan))\n+      if (GET_CODE (insn) == BARRIER)\n+\tpush_minipool_barrier(insn, address);\n+      else if (GET_CODE (insn) == INSN || GET_CODE (insn) == CALL_INSN\n+\t       || GET_CODE (insn) == JUMP_INSN)\n+\t{\n+\t  rtx table;\n+\n+\t  note_invalid_constants (insn, address);\n+\t  address += get_attr_length (insn);\n+\t  /* If the insn is a vector jump, add the size of the table\n+\t     and skip the table.  */\n+\t  if (GET_CODE (insn) == JUMP_INSN\n+\t      && JUMP_LABEL (insn) != NULL\n+\t      && ((table = next_real_insn (JUMP_LABEL (insn)))\n+\t\t  == next_real_insn (insn))\n+\t      && table != NULL\n+\t      && GET_CODE (table) == JUMP_INSN\n+\t      && (GET_CODE (PATTERN (table)) == ADDR_VEC\n+\t\t  || GET_CODE (PATTERN (table)) == ADDR_DIFF_VEC))\n \t    {\n-\t      if (broken_move (scan))\n-\t\t{\n-\t\t  /* This is a broken move instruction, add it to the pool */\n-\t\t  rtx pat = PATTERN (scan);\n-\t\t  rtx src = SET_SRC (pat);\n-\t\t  rtx dst = SET_DEST (pat);\n-\t\t  enum machine_mode mode = GET_MODE (dst);\n-\t\t  HOST_WIDE_INT offset;\n-\t\t  rtx newinsn = scan;\n-\t\t  rtx newsrc;\n-\t\t  rtx addr;\n-\t\t  int scratch;\n-\t\t  int address_only;\n-\n-\t\t  /* If this is an HImode constant load, convert it into\n-\t\t     an SImode constant load.  Since the register is always\n-\t\t     32 bits this is safe.  We have to do this, since the\n-\t\t     load pc-relative instruction only does a 32-bit load. */\n-\t\t  if (mode == HImode)\n-\t\t    {\n-\t\t      mode = SImode;\n-\t\t      if (GET_CODE (dst) != REG)\n-\t\t\tabort ();\n-\t\t      PUT_MODE (dst, SImode);\n-\t\t    }\n+\t      int elt = GET_CODE (PATTERN (table)) == ADDR_DIFF_VEC ? 1 : 0;\n \n-\t\t  offset = add_constant (src, mode, &address_only);\n-\t\t  addr = plus_constant (gen_rtx_LABEL_REF (VOIDmode,\n-\t\t\t\t\t\t\t   pool_vector_label),\n-\t\t\t\t\toffset);\n-\n-\t\t  /* If we only want the address of the pool entry, or\n-\t\t     for wide moves to integer regs we need to split\n-\t\t     the address calculation off into a separate insn.\n-\t\t     If necessary, the load can then be done with a\n-\t\t     load-multiple.  This is safe, since we have\n-\t\t     already noted the length of such insns to be 8,\n-\t\t     and we are immediately over-writing the scratch\n-\t\t     we have grabbed with the final result.  */\n-\t\t  if ((address_only || GET_MODE_SIZE (mode) > 4)\n-\t\t      && (scratch = REGNO (dst)) < 16)\n-\t\t    {\n-\t\t      rtx reg;\n+\t      address += GET_MODE_SIZE (SImode) * XVECLEN (PATTERN (table), \n+\t\t\t\t\t\t\t   elt);\n+\t      insn = table;\n+\t    }\n+\t}\n+    }\n \n-\t\t      if (mode == SImode)\n-\t\t\treg = dst;\n-\t\t      else \n-\t\t\treg = gen_rtx_REG (SImode, scratch);\n+  /* Now scan the fixups and perform the required changes.  */\n+  for (fix = minipool_fix_head; fix; fix = fix->next)\n+    {\n+      struct minipool_fixup *ftmp;\n+      struct minipool_fixup *last_barrier = NULL;\n+      int max_range;\n+      rtx barrier;\n+      struct minipool_fixup *this_fix;\n+      int new_minipool_size = 0;\n \n-\t\t      newinsn = emit_insn_after (gen_movaddr (reg, addr),\n-\t\t\t\t\t\t newinsn);\n-\t\t      addr = reg;\n-\t\t    }\n+      /* Skip any further barriers before the next fix.  */\n+      while (fix && GET_CODE (fix->insn) == BARRIER)\n+\tfix = fix->next;\n \n-\t\t  if (! address_only)\n-\t\t    {\n-\t\t      newsrc = gen_rtx_MEM (mode, addr);\n-\n-\t\t      /* XXX Fixme -- I think the following is bogus.  */\n-\t\t      /* Build a jump insn wrapper around the move instead\n-\t\t\t of an ordinary insn, because we want to have room for\n-\t\t\t the target label rtx in fld[7], which an ordinary\n-\t\t\t insn doesn't have. */\n-\t\t      newinsn\n-\t\t\t= emit_jump_insn_after (gen_rtx_SET (VOIDmode, dst,\n-\t\t\t\t\t\t\t     newsrc),\n-\t\t\t\t\t\tnewinsn);\n-\t\t      JUMP_LABEL (newinsn) = pool_vector_label;\n-\n-\t\t      /* But it's still an ordinary insn */\n-\t\t      PUT_CODE (newinsn, INSN);\n-\t\t    }\n+      if (fix == NULL)\n+\tbreak;\n \n-\t\t  /* Kill old insn */\n-\t\t  delete_insn (scan);\n-\t\t  scan = newinsn;\n-\t\t}\n+      ftmp = fix;\n+      max_range = fix->address + fix->range;\n+\n+      /* Find all the other fixes that can live in the same pool.  */\n+      while (ftmp->next && ftmp->next->address < max_range\n+\t     && (GET_CODE (ftmp->next->insn) == BARRIER\n+\t\t /* Ensure we can reach the constant inside the pool.  */\n+\t\t || ftmp->next->range > new_minipool_size))\n+\t{\n+\t  ftmp = ftmp->next;\n+\t  if (GET_CODE (ftmp->insn) == BARRIER)\n+\t    last_barrier = ftmp;\n+\t  else\n+\t    {\n+\t      /* Does this fix constrain the range we can search?  */\n+\t      if (ftmp->address + ftmp->range - new_minipool_size < max_range)\n+\t\tmax_range = ftmp->address + ftmp->range - new_minipool_size;\n+\n+\t      new_minipool_size += GET_MODE_SIZE (ftmp->mode);\n \t    }\n-\t  dump_table (barrier);\n-\t  insn = scan;\n \t}\n+\n+      /* If we found a barrier, drop back to that; any fixes that we could\n+\t have reached but come after the barrier will now go in the next\n+\t mini-pool.  */\n+      if (last_barrier != NULL)\n+\t{\n+\t  barrier = last_barrier->insn;\n+\t  ftmp = last_barrier;\n+\t}\n+      else\n+\t/* ftmp is last fix that we can fit into this pool and we\n+\t   failed to find a barrier that we could use.  Insert a new\n+\t   barrier in the code and arrange to jump around it.  */\n+\tbarrier = find_barrier (ftmp->insn, max_range - ftmp->address);\n+\n+      /* Scan over the fixes we have identified for this pool, fixing them\n+\t up and adding the constants to the pool itself.  */\n+      for (this_fix = fix; this_fix && ftmp->next != this_fix;\n+\t   this_fix = this_fix->next)\n+\tif (GET_CODE (this_fix->insn) != BARRIER)\n+\t  {\n+\t    int offset = add_minipool_constant (this_fix->value,\n+\t\t\t\t\t\tthis_fix->mode);\n+\t    rtx addr\n+\t      = plus_constant (gen_rtx_LABEL_REF (VOIDmode, \n+\t\t\t\t\t\t  minipool_vector_label),\n+\t\t\t       offset);\n+\t    *this_fix->loc = gen_rtx_MEM (this_fix->mode, addr);\n+\t  }\n+\n+      dump_minipool (barrier);\n+      fix = ftmp;\n     }\n \n+  /* From now on we must synthesize any constants that we can't handle\n+     directly.  This can happen if the RTL gets split during final\n+     instruction generation.  */\n   after_arm_reorg = 1;\n }\n \n@@ -5519,10 +5562,10 @@ arm_poke_function_name (stream, name)\n   unsigned long length;\n   rtx           x;\n \n-  length = strlen (name);\n-  alignlength = NUM_INTS (length + 1);\n+  length = strlen (name) + 1;\n+  alignlength = (length + 3) & ~3;\n   \n-  ASM_OUTPUT_ASCII (stream, name, length + 1);\n+  ASM_OUTPUT_ASCII (stream, name, length);\n   ASM_OUTPUT_ALIGN (stream, 2);\n   x = GEN_INT (0xff000000UL + alignlength);\n   ASM_OUTPUT_INT (stream, x);\n@@ -5612,30 +5655,25 @@ output_func_prologue (f, frame_size)\n #endif\n }\n \n-\n-void\n-output_func_epilogue (f, frame_size)\n-     FILE * f;\n-     int frame_size;\n+char *\n+arm_output_epilogue ()\n {\n-  int reg, live_regs_mask = 0;\n-  /* If we need this then it will always be at least this much */\n+  int reg;\n+  int live_regs_mask = 0;\n+  /* If we need this, then it will always be at least this much */\n   int floats_offset = 12;\n   rtx operands[3];\n+  int frame_size = get_frame_size ();\n+  FILE *f = asm_out_file;\n   int volatile_func = (optimize > 0\n \t\t       && TREE_THIS_VOLATILE (current_function_decl));\n \n   if (use_return_insn (FALSE) && return_used_this_function)\n-    {\n-      if ((frame_size + current_function_outgoing_args_size) != 0\n-\t  && !(frame_pointer_needed && TARGET_APCS))\n-\tabort ();\n-      goto epilogue_done;\n-    }\n+    return \"\";\n \n   /* Naked functions don't have epilogues.  */\n   if (arm_naked_function_p (current_function_decl))\n-    goto epilogue_done;\n+    return \"\";\n \n   /* A volatile function should never return.  Call abort.  */\n   if (TARGET_ABORT_NORETURN && volatile_func)\n@@ -5644,7 +5682,7 @@ output_func_epilogue (f, frame_size)\n       op = gen_rtx_SYMBOL_REF (Pmode, NEED_PLT_RELOC ? \"abort(PLT)\" : \"abort\");\n       assemble_external_libcall (op);\n       output_asm_insn (\"bl\\t%a0\", &op);\n-      goto epilogue_done;\n+      return \"\";\n     }\n \n   for (reg = 0; reg <= 10; reg++)\n@@ -5822,7 +5860,18 @@ output_func_epilogue (f, frame_size)\n \t}\n     }\n \n-epilogue_done:\n+  return \"\";\n+}\n+\n+void\n+output_func_epilogue (f, frame_size)\n+     FILE *f ATTRIBUTE_UNUSED;\n+     int frame_size;\n+{\n+  if (use_return_insn (FALSE) && return_used_this_function\n+      && (frame_size + current_function_outgoing_args_size) != 0\n+      && ! (frame_pointer_needed && TARGET_APCS))\n+\tabort ();\n \n   /* Reset the ARM-specific per-function variables.  */\n   current_function_anonymous_args = 0;\n@@ -5909,6 +5958,8 @@ arm_expand_prologue ()\n \t\t\t  + current_function_outgoing_args_size));\n   int live_regs_mask = 0;\n   int store_arg_regs = 0;\n+  /* If this function doesn't return, then there is no need to push\n+     the call-saved regs.  */\n   int volatile_func = (optimize > 0\n \t\t       && TREE_THIS_VOLATILE (current_function_decl));\n "}, {"sha": "127dc75cc2a463f5562209d1a9913e8b865ef5e7", "filename": "gcc/config/arm/arm.h", "status": "modified", "additions": 4, "deletions": 7, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/949d79eb1d51eea0ee1008d6e86a2a83dcefd63e/gcc%2Fconfig%2Farm%2Farm.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/949d79eb1d51eea0ee1008d6e86a2a83dcefd63e/gcc%2Fconfig%2Farm%2Farm.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.h?ref=949d79eb1d51eea0ee1008d6e86a2a83dcefd63e", "patch": "@@ -1,8 +1,8 @@\n /* Definitions of target machine for GNU compiler, for ARM.\n-   Copyright (C) 1991, 93, 94, 95, 96, 97, 98, 1999 Free Software Foundation, Inc.\n+   Copyright (C) 1991, 93-98, 1999 Free Software Foundation, Inc.\n    Contributed by Pieter `Tiggr' Schoenmakers (rcpieter@win.tue.nl)\n    and Martin Simmons (@harleqn.co.uk).\n-   More major hacks by Richard Earnshaw (rwe11@cl.cam.ac.uk)\n+   More major hacks by Richard Earnshaw (rearnsha@arm.com)\n    Minor hacks by Nick Clifton (nickc@cygnus.com)\n \n This file is part of GNU CC.\n@@ -394,7 +394,7 @@ Unrecognized value in TARGET_CPU_DEFAULT.\n      \"Do not load the PIC register in function prologues\" },\t\\\n   {\"no-single-pic-base\",       -ARM_FLAG_SINGLE_PIC_BASE, \"\" },\t\\\n   SUBTARGET_SWITCHES\t\t\t\t\t\t\\\n-  {\"\",\t\t\t\tTARGET_DEFAULT }\t\t\\\n+  {\"\",\t\t\t\tTARGET_DEFAULT, \"\" }\t\t\\\n }\n \n #define TARGET_OPTIONS\t\t\t\t\t\t\\\n@@ -1961,10 +1961,6 @@ extern struct rtx_def * arm_compare_op1;\n    point in the code.  */\n #define MACHINE_DEPENDENT_REORG(INSN)\tarm_reorg ((INSN))\n \n-/* The pool is empty, since we have moved everything into the code.  */\n-#define ASM_OUTPUT_SPECIAL_POOL_ENTRY(FILE,X,MODE,ALIGN,LABELNO,JUMPTO)\t\\\n-  goto JUMPTO\n-\n /* Output an internal label definition.  */\n #ifndef ASM_OUTPUT_INTERNAL_LABEL\n #define ASM_OUTPUT_INTERNAL_LABEL(STREAM, PREFIX, NUM)\t\t\\\n@@ -2304,6 +2300,7 @@ void   arm_poke_function_name STDIO_PROTO ((FILE *, char *));\n void   output_func_prologue STDIO_PROTO ((FILE *, int));\n void   output_func_epilogue STDIO_PROTO ((FILE *, int));\n void   arm_expand_prologue PROTO ((void));\n+char * arm_output_epilogue PROTO ((void));\n void   arm_print_operand STDIO_PROTO ((FILE *, Rtx, int));\n void   arm_final_prescan_insn PROTO ((Rtx));\n int    short_branch PROTO ((int, int));"}, {"sha": "953eec7935bca5f3acd403b7f13ab12f9124a47f", "filename": "gcc/config/arm/arm.md", "status": "modified", "additions": 65, "deletions": 19, "changes": 84, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/949d79eb1d51eea0ee1008d6e86a2a83dcefd63e/gcc%2Fconfig%2Farm%2Farm.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/949d79eb1d51eea0ee1008d6e86a2a83dcefd63e/gcc%2Fconfig%2Farm%2Farm.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.md?ref=949d79eb1d51eea0ee1008d6e86a2a83dcefd63e", "patch": "@@ -56,6 +56,11 @@\n ; LENGTH of an instruction (in bytes)\n (define_attr \"length\" \"\" (const_int 4))\n \n+; POOL_RANGE is how far away from a constant pool entry that this insn\n+; can be placed.  If the distance is zero, then this insn will never\n+; reference the pool.\n+(define_attr \"pool_range\" \"\" (const_int 0))\n+\n ; An assembler sequence may clobber the condition codes without us knowing\n (define_asm_attributes\n  [(set_attr \"conds\" \"clob\")\n@@ -2146,7 +2151,8 @@\n    and%?\\\\t%Q0, %1, #255\\;mov%?\\\\t%R0, #0\n    ldr%?b\\\\t%Q0, %1\\;mov%?\\\\t%R0, #0\"\n [(set_attr \"length\" \"8\")\n- (set_attr \"type\" \"*,load\")])\n+ (set_attr \"type\" \"*,load\")\n+ (set_attr \"pool_range\" \"*,4096\")])\n \n (define_insn \"extendsidi2\"\n   [(set (match_operand:DI 0 \"s_register_operand\" \"=r\")\n@@ -2193,7 +2199,8 @@\n \t(zero_extend:SI (match_operand:HI 1 \"memory_operand\" \"m\")))]\n   \"arm_arch4\"\n   \"ldr%?h\\\\t%0, %1\"\n-[(set_attr \"type\" \"load\")])\n+[(set_attr \"type\" \"load\")\n+ (set_attr \"pool_range\" \"256\")])\n \n (define_split\n   [(set (match_operand:SI 0 \"s_register_operand\" \"\")\n@@ -2244,7 +2251,8 @@\n \t(zero_extend:SI (match_operand:QI 1 \"memory_operand\" \"m\")))]\n   \"\"\n   \"ldr%?b\\\\t%0, %1\\\\t%@ zero_extendqisi2\"\n-[(set_attr \"type\" \"load\")])\n+[(set_attr \"type\" \"load\")\n+ (set_attr \"pool_range\" \"4096\")])\n \n (define_split\n   [(set (match_operand:SI 0 \"s_register_operand\" \"\")\n@@ -2339,7 +2347,8 @@\n \t(sign_extend:SI (match_operand:HI 1 \"memory_operand\" \"m\")))]\n   \"arm_arch4\"\n   \"ldr%?sh\\\\t%0, %1\"\n-[(set_attr \"type\" \"load\")])\n+[(set_attr \"type\" \"load\")\n+ (set_attr \"pool_range\" \"256\")])\n \n (define_split\n   [(set (match_operand:SI 0 \"s_register_operand\" \"\")\n@@ -2408,7 +2417,8 @@\n   return \\\"ldr%?sb\\\\t%0, %1\\\";\n \"\n [(set_attr \"type\" \"load\")\n- (set_attr \"length\" \"8\")])\n+ (set_attr \"length\" \"8\")\n+ (set_attr \"pool_range\" \"256\")])\n \n (define_split\n   [(set (match_operand:HI 0 \"s_register_operand\" \"\")\n@@ -2481,7 +2491,8 @@\n   return \\\"ldr%?sb\\\\t%0, %1\\\";\n \"\n [(set_attr \"type\" \"load\")\n- (set_attr \"length\" \"8\")])\n+ (set_attr \"length\" \"8\")\n+ (set_attr \"pool_range\" \"256\")])\n \n (define_split\n   [(set (match_operand:SI 0 \"s_register_operand\" \"\")\n@@ -2609,7 +2620,8 @@\n   return (output_move_double (operands));\n \"\n [(set_attr \"length\" \"8,8,8\")\n- (set_attr \"type\" \"*,load,store2\")])\n+ (set_attr \"type\" \"*,load,store2\")\n+ (set_attr \"pool_range\" \"0,1020,0\")])\n \n (define_expand \"movsi\"\n   [(set (match_operand:SI 0 \"general_operand\" \"\")\n@@ -2646,7 +2658,8 @@\n    mvn%?\\\\t%0, #%B1\n    ldr%?\\\\t%0, %1\n    str%?\\\\t%1, %0\"\n-[(set_attr \"type\" \"*,*,load,store1\")])\n+[(set_attr \"type\" \"*,*,load,store1\")\n+ (set_attr \"pool_range\" \"*,*,4096,*\")])\n \n (define_split\n   [(set (match_operand:SI 0 \"s_register_operand\" \"\")\n@@ -2687,7 +2700,8 @@\n \t(unspec:SI [(match_operand 1 \"\" \"\")] 3))]\n   \"flag_pic\"\n   \"ldr%?\\\\t%0, %a1\"\n- [(set_attr \"type\" \"load\")])\n+ [(set_attr \"type\" \"load\")\n+  (set_attr \"pool_range\" \"4096\")])\n \n ;; This variant is used for AOF assembly, since it needs to mention the\n ;; pic register in the rtl.\n@@ -2708,7 +2722,9 @@\n #endif\n   output_asm_insn (\\\"ldr%?\\\\t%0, %a1\\\", operands);\n   return \\\"\\\";\n-\" [(set_attr \"type\" \"load\")])\n+\"\n+[(set_attr \"type\" \"load\")\n+ (set_attr \"pool_range\" \"4096\")])\n \n (define_insn \"pic_add_dot_plus_eight\"\n   [(set (match_operand 0 \"register_operand\" \"+r\")\n@@ -3079,7 +3095,8 @@\n    mvn%?\\\\t%0, #%B1\\\\t%@ movhi\n    ldr%?h\\\\t%0, %1\\\\t%@ movhi\n    str%?h\\\\t%1, %0\\\\t%@ movhi\"\n-[(set_attr \"type\" \"*,*,load,store1\")])\n+[(set_attr \"type\" \"*,*,load,store1\")\n+ (set_attr \"pool_range\" \"*,*,256,*\")])\n \n (define_insn \"*movhi_insn_littleend\"\n   [(set (match_operand:HI 0 \"s_register_operand\" \"=r,r,r\")\n@@ -3094,7 +3111,8 @@\n    mov%?\\\\t%0, %1\\\\t%@ movhi\n    mvn%?\\\\t%0, #%B1\\\\t%@ movhi\n    ldr%?\\\\t%0, %1\\\\t%@ movhi\"\n-[(set_attr \"type\" \"*,*,load\")])\n+[(set_attr \"type\" \"*,*,load\")\n+ (set_attr \"pool_range\" \"4096\")])\n \n (define_insn \"*movhi_insn_bigend\"\n   [(set (match_operand:HI 0 \"s_register_operand\" \"=r,r,r\")\n@@ -3110,7 +3128,8 @@\n    mvn%?\\\\t%0, #%B1\\\\t%@ movhi\n    ldr%?\\\\t%0, %1\\\\t%@ movhi_bigend\\;mov%?\\\\t%0, %0, asr #16\"\n [(set_attr \"type\" \"*,*,load\")\n- (set_attr \"length\" \"4,4,8\")])\n+ (set_attr \"length\" \"4,4,8\")\n+ (set_attr \"pool_range\" \"*,*,4092\")])\n \n (define_insn \"*loadhi_si_bigend\"\n   [(set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n@@ -3119,7 +3138,8 @@\n   \"BYTES_BIG_ENDIAN\n    && ! TARGET_SHORT_BY_BYTES\"\n   \"ldr%?\\\\t%0, %1\\\\t%@ movhi_bigend\"\n-[(set_attr \"type\" \"load\")])\n+[(set_attr \"type\" \"load\")\n+ (set_attr \"pool_range\" \"4096\")])\n \n (define_insn \"*movhi_bytes\"\n   [(set (match_operand:HI 0 \"s_register_operand\" \"=r,r\")\n@@ -3212,7 +3232,8 @@\n    str%?\\\\t%1, %0\\\\t%@ float\"\n [(set_attr \"length\" \"4,4,4,4,8,8,4,4,4\")\n  (set_attr \"type\"\n-\t \"ffarith,ffarith,f_load,f_store,r_mem_f,f_mem_r,*,load,store1\")])\n+\t \"ffarith,ffarith,f_load,f_store,r_mem_f,f_mem_r,*,load,store1\")\n+ (set_attr \"pool_range\" \"*,*,1024,*,*,*,*,4096,*\")])\n \n ;; Exactly the same as above, except that all `f' cases are deleted.\n ;; This is necessary to prevent reload from ever trying to use a `f' reg\n@@ -3228,7 +3249,8 @@\n    ldr%?\\\\t%0, %1\\\\t%@ float\n    str%?\\\\t%1, %0\\\\t%@ float\"\n [(set_attr \"length\" \"4,4,4\")\n- (set_attr \"type\" \"*,load,store1\")])\n+ (set_attr \"type\" \"*,load,store1\")\n+ (set_attr \"pool_range\" \"*,4096,*\")])\n \n (define_expand \"movdf\"\n   [(set (match_operand:DF 0 \"general_operand\" \"\")\n@@ -3306,7 +3328,8 @@\n \"\n [(set_attr \"length\" \"4,4,8,8,8,4,4,4,4,8,8\")\n  (set_attr \"type\"\n-\"load,store2,*,store2,load,ffarith,ffarith,f_load,f_store,r_mem_f,f_mem_r\")])\n+\"load,store2,*,store2,load,ffarith,ffarith,f_load,f_store,r_mem_f,f_mem_r\")\n+ (set_attr \"pool_range\" \"*,*,*,*,252,*,*,1024,*,*,*\")])\n \n ;; Software floating point version.  This is essentially the same as movdi.\n ;; Do not use `f' as a constraint to prevent reload from ever trying to use\n@@ -3318,7 +3341,8 @@\n   \"TARGET_SOFT_FLOAT\"\n   \"* return output_move_double (operands);\"\n [(set_attr \"length\" \"8,8,8\")\n- (set_attr \"type\" \"*,load,store2\")])\n+ (set_attr \"type\" \"*,load,store2\")\n+ (set_attr \"pool_range\" \"252\")])\n \n (define_expand \"movxf\"\n   [(set (match_operand:XF 0 \"general_operand\" \"\")\n@@ -3347,7 +3371,8 @@\n     }\n \"\n [(set_attr \"length\" \"4,4,4,4,8,8,12\")\n- (set_attr \"type\" \"ffarith,ffarith,f_load,f_store,r_mem_f,f_mem_r,*\")])\n+ (set_attr \"type\" \"ffarith,ffarith,f_load,f_store,r_mem_f,f_mem_r,*\")\n+ (set_attr \"pool_range\" \"*,*,1024,*,*,*,*\")])\n \f\n \n ;; load- and store-multiple insns\n@@ -6097,6 +6122,27 @@\n   DONE;\n \")\n \n+(define_expand \"epilogue\"\n+  [(unspec_volatile [(return)] 6)]\n+  \"\"\n+  \"\n+  if (USE_RETURN_INSN (FALSE))\n+    {\n+      emit_jump_insn (gen_return ());\n+      DONE;\n+    }\n+\")\n+\n+(define_insn \"*epilogue_insn\"\n+  [(unspec_volatile [(return)] 6)]\n+  \"\"\n+  \"*\n+  return arm_output_epilogue ();\n+\"\n+;; Length is absolute worst case\n+[(set_attr \"length\" \"44\")\n+ (set_attr \"type\" \"block\")])\n+\n ;; This split is only used during output to reduce the number of patterns\n ;; that need assembler instructions adding to them.  We allowed the setting\n ;; of the conditions to be implicit during rtl generation so that"}]}