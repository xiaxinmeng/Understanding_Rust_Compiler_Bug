{"sha": "18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MThmMGZlNmI5OGVjODJkYTEwZTNkM2M2N2Y4MDJmMWNmNmMyYTc3Zg==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2012-01-10T04:14:09Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2012-01-10T04:14:09Z"}, "message": "arm: Convert to atomic optabs.\n\n\t* config/arm/arm.c (arm_gen_compare_reg): Add scratch argument;\n\tuse it if reload_completed.\n\t(arm_legitimize_sync_memory, arm_emit, arm_insn_count, arm_count,\n\tarm_output_asm_insn, arm_process_output_memory_barrier,\n\tarm_output_memory_barrier, arm_ldrex_suffix, arm_output_ldrex,\n\tarm_output_strex, arm_output_it, arm_output_op2, arm_output_op3,\n\tarm_output_sync_loop, arm_get_sync_operand, FETCH_SYNC_OPERAND,\n\tarm_process_output_sync_insn, arm_output_sync_insn,\n\tarm_sync_loop_insns, arm_call_generator, arm_expand_sync): Remove.\n\t(arm_pre_atomic_barrier, arm_post_atomic_barrier): New.\n\t(arm_emit_load_exclusive, arm_emit_store_exclusive): New.\n\t(emit_unlikely_jump): New.\n\t(arm_expand_compare_and_swap, arm_split_compare_and_swap): New.\n\t(arm_split_atomic_op): New.\n\t* config/arm/arm-protos.h: Update.\n\t* config/arm/arm.h (enum arm_sync_generator_tag): Remove.\n\t(struct arm_sync_generator): Remove.\n\t* config/arm/arm.md (VUNSPEC_SYNC_COMPARE_AND_SWAP, VUNSPEC_SYNC_LOCK,\n\tVUNSPEC_SYNC_OP, VUNSPEC_SYNC_NEW_OP, VUNSPEC_SYNC_OLD_OP): Remove.\n\t(VUNSPEC_ATOMIC_CAS, VUNSPEC_ATOMIC_XCHG, VUNSPEC_ATOMIC_OP): New.\n\t(VUNSPEC_LL, VUNSPEC_SC): New.\n\t(sync_result, sync_memory, sync_required_value, sync_new_value,\n\tsync_t1, sync_t2, sync_release_barrier, sync_op): Remove.\n\t(attr length): Don't use arm_sync_loop_insns.\n\t(cbranch_cc, cstore_cc): Update call to arm_gen_compare_reg.\n\t(movsfcc, movdfcc): Likewise.\n\t* config/arm/constraints.md (Ua): New.\n\t* config/arm/prediates.md (mem_noofs_operand): New.\n\t(sync_compare_and_swap<QHSD>, sync_lock_test_and_set<QHSD>): Remove.\n\t(sync_clobber, sync_t2_reqd): Remove.\n\t(sync_<syncop><QHSD>, sync_nand<QHSD>): Remove.\n\t(sync_new_<syncop><QHSD>, sync_new_nand<QHSD>): Remove.\n\t(sync_old_<syncop><QHSD>, sync_old_nand<QHSD>): Remove.\n\t(arm_sync_compare_and_swap<SIDI>): Remove.\n\t(arm_sync_compare_and_swap<NARROW>): Remove.\n\t(arm_sync_lock_test_and_set<SIDI>): Remove.\n\t(arm_sync_lock_test_and_set<NARROW>): Remove.\n\t(arm_sync_new_<syncop><SIDI>): Remove.\n\t(arm_sync_new_<syncop><NARROW>): Remove.\n\t(arm_sync_new_nand<SIDI>): Remove.\n\t(arm_sync_new_nand<NARROW>): Remove.\n\t(arm_sync_old_<syncop><SIDI>): Remove.\n\t(arm_sync_old_<syncop><NARROW>): Remove.\n\t(arm_sync_old_nand<SIDI>): Remove.\n\t(arm_sync_old_nand<NARROW>): Remove.\n\t(*memory_barrier): Merge arm_output_memory_barrier.\n\t(atomic_compare_and_swap<QHSD>): New.\n\t(atomic_compare_and_swap<NARROW>_1): New.\n\t(atomic_compare_and_swap<SIDI>_1): New.\n\t(atomic_exchange<QHSD>): New.\n\t(cas_cmp_operand, cas_cmp_str): New.\n\t(atomic_op_operand, atomic_op_str): New.\n\t(atomic_<syncop><QHSD>, atomic_nand<QHSD>): New.\n\t(atomic_fetch_<syncop><QHSD>, atomic_fetch_nand<QHSD>): New.\n\t(atomic_<syncop>_fetch<QHSD>, atomic_nand_fetch<QHSD>): New.\n\t(arm_load_exclusive<NARROW>): New.\n\t(arm_load_exclusivesi, arm_load_exclusivedi): New.\n\t(arm_store_exclusive<QHSD>): New.\n\nFrom-SVN: r183050", "tree": {"sha": "4beb1f30ce9aaa086052f1a9b009b27fe336a1e0", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/4beb1f30ce9aaa086052f1a9b009b27fe336a1e0"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/comments", "author": null, "committer": null, "parents": [{"sha": "8377e5e5461f7370489eb849e8af4cde4a75831f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8377e5e5461f7370489eb849e8af4cde4a75831f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8377e5e5461f7370489eb849e8af4cde4a75831f"}], "stats": {"total": 1636, "additions": 665, "deletions": 971}, "files": [{"sha": "d2d5209d0d0d3af537e2c33e4b659ca8772ec2b5", "filename": "gcc/ChangeLog", "status": "modified", "additions": 62, "deletions": 0, "changes": 62, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f", "patch": "@@ -1,3 +1,65 @@\n+2012-01-10  Richard Henderson  <rth@redhat.com>\n+\n+\t* config/arm/arm.c (arm_gen_compare_reg): Add scratch argument;\n+\tuse it if reload_completed.\n+\t(arm_legitimize_sync_memory, arm_emit, arm_insn_count, arm_count,\n+\tarm_output_asm_insn, arm_process_output_memory_barrier,\n+\tarm_output_memory_barrier, arm_ldrex_suffix, arm_output_ldrex,\n+\tarm_output_strex, arm_output_it, arm_output_op2, arm_output_op3,\n+\tarm_output_sync_loop, arm_get_sync_operand, FETCH_SYNC_OPERAND,\n+\tarm_process_output_sync_insn, arm_output_sync_insn,\n+\tarm_sync_loop_insns, arm_call_generator, arm_expand_sync): Remove.\n+\t(arm_pre_atomic_barrier, arm_post_atomic_barrier): New.\n+\t(arm_emit_load_exclusive, arm_emit_store_exclusive): New.\n+\t(emit_unlikely_jump): New.\n+\t(arm_expand_compare_and_swap, arm_split_compare_and_swap): New.\n+\t(arm_split_atomic_op): New.\n+\t* config/arm/arm-protos.h: Update.\n+\t* config/arm/arm.h (enum arm_sync_generator_tag): Remove.\n+\t(struct arm_sync_generator): Remove.\n+\t* config/arm/arm.md (VUNSPEC_SYNC_COMPARE_AND_SWAP, VUNSPEC_SYNC_LOCK,\n+\tVUNSPEC_SYNC_OP, VUNSPEC_SYNC_NEW_OP, VUNSPEC_SYNC_OLD_OP): Remove.\n+\t(VUNSPEC_ATOMIC_CAS, VUNSPEC_ATOMIC_XCHG, VUNSPEC_ATOMIC_OP): New.\n+\t(VUNSPEC_LL, VUNSPEC_SC): New.\n+\t(sync_result, sync_memory, sync_required_value, sync_new_value,\n+\tsync_t1, sync_t2, sync_release_barrier, sync_op): Remove.\n+\t(attr length): Don't use arm_sync_loop_insns.\n+\t(cbranch_cc, cstore_cc): Update call to arm_gen_compare_reg.\n+\t(movsfcc, movdfcc): Likewise.\n+\t* config/arm/constraints.md (Ua): New.\n+\t* config/arm/prediates.md (mem_noofs_operand): New.\n+\t(sync_compare_and_swap<QHSD>, sync_lock_test_and_set<QHSD>): Remove.\n+\t(sync_clobber, sync_t2_reqd): Remove.\n+\t(sync_<syncop><QHSD>, sync_nand<QHSD>): Remove.\n+\t(sync_new_<syncop><QHSD>, sync_new_nand<QHSD>): Remove.\n+\t(sync_old_<syncop><QHSD>, sync_old_nand<QHSD>): Remove.\n+\t(arm_sync_compare_and_swap<SIDI>): Remove.\n+\t(arm_sync_compare_and_swap<NARROW>): Remove.\n+\t(arm_sync_lock_test_and_set<SIDI>): Remove.\n+\t(arm_sync_lock_test_and_set<NARROW>): Remove.\n+\t(arm_sync_new_<syncop><SIDI>): Remove.\n+\t(arm_sync_new_<syncop><NARROW>): Remove.\n+\t(arm_sync_new_nand<SIDI>): Remove.\n+\t(arm_sync_new_nand<NARROW>): Remove.\n+\t(arm_sync_old_<syncop><SIDI>): Remove.\n+\t(arm_sync_old_<syncop><NARROW>): Remove.\n+\t(arm_sync_old_nand<SIDI>): Remove.\n+\t(arm_sync_old_nand<NARROW>): Remove.\n+\t(*memory_barrier): Merge arm_output_memory_barrier.\n+\t(atomic_compare_and_swap<QHSD>): New.\n+\t(atomic_compare_and_swap<NARROW>_1): New.\n+\t(atomic_compare_and_swap<SIDI>_1): New.\n+\t(atomic_exchange<QHSD>): New.\n+\t(cas_cmp_operand, cas_cmp_str): New.\n+\t(atomic_op_operand, atomic_op_str): New.\n+\t(atomic_<syncop><QHSD>, atomic_nand<QHSD>): New.\n+\t(atomic_fetch_<syncop><QHSD>, atomic_fetch_nand<QHSD>): New.\n+\t(atomic_<syncop>_fetch<QHSD>, atomic_nand_fetch<QHSD>): New.\n+\t(arm_load_exclusive<NARROW>): New.\n+\t(arm_load_exclusivesi, arm_load_exclusivedi): New.\n+\t(arm_store_exclusive<QHSD>): New.\n+\n+2012-01-09  Michael Meissner  <meissner@linux.vnet.ibm.com>\n \n \t* config/rs6000/rs6000.c (rs6000_init_hard_regno_mode_ok): Add DF\n \treload patterns if -mvsx-scalar-memory."}, {"sha": "28e3b9463b98e5fb11501ac2bc4e17726fd59a14", "filename": "gcc/config/arm/arm-protos.h", "status": "modified", "additions": 5, "deletions": 6, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2Fconfig%2Farm%2Farm-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2Fconfig%2Farm%2Farm-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm-protos.h?ref=18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f", "patch": "@@ -1,6 +1,6 @@\n /* Prototypes for exported functions defined in arm.c and pe.c\n    Copyright (C) 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008,\n-   2009, 2010 Free Software Foundation, Inc.\n+   2009, 2010, 2012  Free Software Foundation, Inc.\n    Contributed by Richard Earnshaw (rearnsha@arm.com)\n    Minor hacks by Nick Clifton (nickc@cygnus.com)\n \n@@ -116,7 +116,7 @@ extern int arm_gen_movmemqi (rtx *);\n extern enum machine_mode arm_select_cc_mode (RTX_CODE, rtx, rtx);\n extern enum machine_mode arm_select_dominance_cc_mode (rtx, rtx,\n \t\t\t\t\t\t       HOST_WIDE_INT);\n-extern rtx arm_gen_compare_reg (RTX_CODE, rtx, rtx);\n+extern rtx arm_gen_compare_reg (RTX_CODE, rtx, rtx, rtx);\n extern rtx arm_gen_return_addr_mask (void);\n extern void arm_reload_in_hi (rtx *);\n extern void arm_reload_out_hi (rtx *);\n@@ -155,12 +155,11 @@ extern const char *vfp_output_fstmd (rtx *);\n extern void arm_set_return_address (rtx, rtx);\n extern int arm_eliminable_register (rtx);\n extern const char *arm_output_shift(rtx *, int);\n-extern void arm_expand_sync (enum machine_mode, struct arm_sync_generator *,\n- \t\t\t     rtx, rtx, rtx, rtx);\n-extern const char *arm_output_memory_barrier (rtx *);\n-extern const char *arm_output_sync_insn (rtx, rtx *);\n extern unsigned int arm_sync_loop_insns (rtx , rtx *);\n extern int arm_attr_length_push_multi(rtx, rtx);\n+extern void arm_expand_compare_and_swap (rtx op[]);\n+extern void arm_split_compare_and_swap (rtx op[]);\n+extern void arm_split_atomic_op (enum rtx_code, rtx, rtx, rtx, rtx, rtx, rtx);\n \n #if defined TREE_CODE\n extern void arm_init_cumulative_args (CUMULATIVE_ARGS *, tree, rtx, tree);"}, {"sha": "951d65ced629a7962697077c5ac55336e2afeccc", "filename": "gcc/config/arm/arm.c", "status": "modified", "additions": 313, "deletions": 517, "changes": 830, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2Fconfig%2Farm%2Farm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2Fconfig%2Farm%2Farm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.c?ref=18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f", "patch": "@@ -1,6 +1,6 @@\n /* Output routines for GCC for ARM.\n    Copyright (C) 1991, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001,\n-   2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011\n+   2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012\n    Free Software Foundation, Inc.\n    Contributed by Pieter `Tiggr' Schoenmakers (rcpieter@win.tue.nl)\n    and Martin Simmons (@harleqn.co.uk).\n@@ -11730,7 +11730,7 @@ arm_select_cc_mode (enum rtx_code op, rtx x, rtx y)\n    return the rtx for register 0 in the proper mode.  FP means this is a\n    floating point compare: I don't think that it is needed on the arm.  */\n rtx\n-arm_gen_compare_reg (enum rtx_code code, rtx x, rtx y)\n+arm_gen_compare_reg (enum rtx_code code, rtx x, rtx y, rtx scratch)\n {\n   enum machine_mode mode;\n   rtx cc_reg;\n@@ -11755,11 +11755,18 @@ arm_gen_compare_reg (enum rtx_code code, rtx x, rtx y)\n \t CC_CZmode is cheaper.  */\n       if (mode == CC_Zmode && y != const0_rtx)\n \t{\n+\t  gcc_assert (!reload_completed);\n \t  x = expand_binop (DImode, xor_optab, x, y, NULL_RTX, 0, OPTAB_WIDEN);\n \t  y = const0_rtx;\n \t}\n+\n       /* A scratch register is required.  */\n-      clobber = gen_rtx_CLOBBER (VOIDmode, gen_rtx_SCRATCH (SImode));\n+      if (reload_completed)\n+\tgcc_assert (scratch != NULL && GET_MODE (scratch) == SImode);\n+      else\n+\tscratch = gen_rtx_SCRATCH (SImode);\n+\n+      clobber = gen_rtx_CLOBBER (VOIDmode, scratch);\n       set = gen_rtx_SET (VOIDmode, cc_reg, gen_rtx_COMPARE (mode, x, y));\n       emit_insn (gen_rtx_PARALLEL (VOIDmode, gen_rtvec (2, set, clobber)));\n     }\n@@ -24417,520 +24424,6 @@ arm_have_conditional_execution (void)\n   return !TARGET_THUMB1;\n }\n \n-/* Legitimize a memory reference for sync primitive implemented using\n-   ldrex / strex.  We currently force the form of the reference to be\n-   indirect without offset.  We do not yet support the indirect offset\n-   addressing supported by some ARM targets for these\n-   instructions.  */\n-static rtx\n-arm_legitimize_sync_memory (rtx memory)\n-{\n-  rtx addr = force_reg (Pmode, XEXP (memory, 0));\n-  rtx legitimate_memory = gen_rtx_MEM (GET_MODE (memory), addr);\n-\n-  set_mem_alias_set (legitimate_memory, ALIAS_SET_MEMORY_BARRIER);\n-  MEM_VOLATILE_P (legitimate_memory) = MEM_VOLATILE_P (memory);\n-  return legitimate_memory;\n-}\n-\n-/* An instruction emitter. */\n-typedef void (* emit_f) (int label, const char *, rtx *);\n-\n-/* An instruction emitter that emits via the conventional\n-   output_asm_insn.  */\n-static void\n-arm_emit (int label ATTRIBUTE_UNUSED, const char *pattern, rtx *operands)\n-{\n-  output_asm_insn (pattern, operands);\n-}\n-\n-/* Count the number of emitted synchronization instructions.  */\n-static unsigned arm_insn_count;\n-\n-/* An emitter that counts emitted instructions but does not actually\n-   emit instruction into the instruction stream.  */\n-static void\n-arm_count (int label,\n-\t   const char *pattern ATTRIBUTE_UNUSED,\n-\t   rtx *operands ATTRIBUTE_UNUSED)\n-{\n-  if (! label)\n-    ++ arm_insn_count;\n-}\n-\n-/* Construct a pattern using conventional output formatting and feed\n-   it to output_asm_insn.  Provides a mechanism to construct the\n-   output pattern on the fly.  Note the hard limit on the pattern\n-   buffer size.  */\n-static void ATTRIBUTE_PRINTF_4\n-arm_output_asm_insn (emit_f emit, int label, rtx *operands,\n-\t\t     const char *pattern, ...)\n-{\n-  va_list ap;\n-  char buffer[256];\n-\n-  va_start (ap, pattern);\n-  vsprintf (buffer, pattern, ap);\n-  va_end (ap);\n-  emit (label, buffer, operands);\n-}\n-\n-/* Emit the memory barrier instruction, if any, provided by this\n-   target to a specified emitter.  */\n-static void\n-arm_process_output_memory_barrier (emit_f emit, rtx *operands)\n-{\n-  if (TARGET_HAVE_DMB)\n-    {\n-      /* Note we issue a system level barrier. We should consider\n-         issuing a inner shareabilty zone barrier here instead, ie.\n-         \"DMB ISH\".  */\n-      emit (0, \"dmb\\tsy\", operands);\n-      return;\n-    }\n-\n-  if (TARGET_HAVE_DMB_MCR)\n-    {\n-      emit (0, \"mcr\\tp15, 0, r0, c7, c10, 5\", operands);\n-      return;\n-    }\n-\n-  gcc_unreachable ();\n-}\n-\n-/* Emit the memory barrier instruction, if any, provided by this\n-   target.  */\n-const char *\n-arm_output_memory_barrier (rtx *operands)\n-{\n-  arm_process_output_memory_barrier (arm_emit, operands);\n-  return \"\";\n-}\n-\n-/* Helper to figure out the instruction suffix required on ldrex/strex\n-   for operations on an object of the specified mode.  */\n-static const char *\n-arm_ldrex_suffix (enum machine_mode mode)\n-{\n-  switch (mode)\n-    {\n-    case QImode: return \"b\";\n-    case HImode: return \"h\";\n-    case SImode: return \"\";\n-    case DImode: return \"d\";\n-    default:\n-      gcc_unreachable ();\n-    }\n-  return \"\";\n-}\n-\n-/* Emit an ldrex{b,h,d, } instruction appropriate for the specified\n-   mode.  */\n-static void\n-arm_output_ldrex (emit_f emit,\n-\t\t  enum machine_mode mode,\n-\t\t  rtx target,\n-\t\t  rtx memory)\n-{\n-  rtx operands[3];\n-\n-  operands[0] = target;\n-  if (mode != DImode)\n-    {\n-      const char *suffix = arm_ldrex_suffix (mode);\n-      operands[1] = memory;\n-      arm_output_asm_insn (emit, 0, operands, \"ldrex%s\\t%%0, %%C1\", suffix);\n-    }\n-  else\n-    {\n-      /* The restrictions on target registers in ARM mode are that the two\n-\t registers are consecutive and the first one is even; Thumb is\n-\t actually more flexible, but DI should give us this anyway.\n-\t Note that the 1st register always gets the lowest word in memory.  */\n-      gcc_assert ((REGNO (target) & 1) == 0);\n-      operands[1] = gen_rtx_REG (SImode, REGNO (target) + 1);\n-      operands[2] = memory;\n-      arm_output_asm_insn (emit, 0, operands, \"ldrexd\\t%%0, %%1, %%C2\");\n-    }\n-}\n-\n-/* Emit a strex{b,h,d, } instruction appropriate for the specified\n-   mode.  */\n-static void\n-arm_output_strex (emit_f emit,\n-\t\t  enum machine_mode mode,\n-\t\t  const char *cc,\n-\t\t  rtx result,\n-\t\t  rtx value,\n-\t\t  rtx memory)\n-{\n-  rtx operands[4];\n-\n-  operands[0] = result;\n-  operands[1] = value;\n-  if (mode != DImode)\n-    {\n-      const char *suffix = arm_ldrex_suffix (mode);\n-      operands[2] = memory;\n-      arm_output_asm_insn (emit, 0, operands, \"strex%s%s\\t%%0, %%1, %%C2\",\n-\t\t\t  suffix, cc);\n-    }\n-  else\n-    {\n-      /* The restrictions on target registers in ARM mode are that the two\n-\t registers are consecutive and the first one is even; Thumb is\n-\t actually more flexible, but DI should give us this anyway.\n-\t Note that the 1st register always gets the lowest word in memory.  */\n-      gcc_assert ((REGNO (value) & 1) == 0 || TARGET_THUMB2);\n-      operands[2] = gen_rtx_REG (SImode, REGNO (value) + 1);\n-      operands[3] = memory;\n-      arm_output_asm_insn (emit, 0, operands, \"strexd%s\\t%%0, %%1, %%2, %%C3\",\n-\t\t\t   cc);\n-    }\n-}\n-\n-/* Helper to emit an it instruction in Thumb2 mode only; although the assembler\n-   will ignore it in ARM mode, emitting it will mess up instruction counts we\n-   sometimes keep 'flags' are the extra t's and e's if it's more than one\n-   instruction that is conditional.  */\n-static void\n-arm_output_it (emit_f emit, const char *flags, const char *cond)\n-{\n-  rtx operands[1]; /* Don't actually use the operand.  */\n-  if (TARGET_THUMB2)\n-    arm_output_asm_insn (emit, 0, operands, \"it%s\\t%s\", flags, cond);\n-}\n-\n-/* Helper to emit a two operand instruction.  */\n-static void\n-arm_output_op2 (emit_f emit, const char *mnemonic, rtx d, rtx s)\n-{\n-  rtx operands[2];\n-\n-  operands[0] = d;\n-  operands[1] = s;\n-  arm_output_asm_insn (emit, 0, operands, \"%s\\t%%0, %%1\", mnemonic);\n-}\n-\n-/* Helper to emit a three operand instruction.  */\n-static void\n-arm_output_op3 (emit_f emit, const char *mnemonic, rtx d, rtx a, rtx b)\n-{\n-  rtx operands[3];\n-\n-  operands[0] = d;\n-  operands[1] = a;\n-  operands[2] = b;\n-  arm_output_asm_insn (emit, 0, operands, \"%s\\t%%0, %%1, %%2\", mnemonic);\n-}\n-\n-/* Emit a load store exclusive synchronization loop.\n-\n-   do\n-     old_value = [mem]\n-     if old_value != required_value\n-       break;\n-     t1 = sync_op (old_value, new_value)\n-     [mem] = t1, t2 = [0|1]\n-   while ! t2\n-\n-   Note:\n-     t1 == t2 is not permitted\n-     t1 == old_value is permitted\n-\n-   required_value:\n-\n-   RTX register representing the required old_value for\n-   the modify to continue, if NULL no comparsion is performed.  */\n-static void\n-arm_output_sync_loop (emit_f emit,\n-\t\t      enum machine_mode mode,\n-\t\t      rtx old_value,\n-\t\t      rtx memory,\n-\t\t      rtx required_value,\n-\t\t      rtx new_value,\n-\t\t      rtx t1,\n-\t\t      rtx t2,\n-\t\t      enum attr_sync_op sync_op,\n-\t\t      int early_barrier_required)\n-{\n-  rtx operands[2];\n-  /* We'll use the lo for the normal rtx in the none-DI case\n-     as well as the least-sig word in the DI case.  */\n-  rtx old_value_lo, required_value_lo, new_value_lo, t1_lo;\n-  rtx old_value_hi, required_value_hi, new_value_hi, t1_hi;\n-\n-  bool is_di = mode == DImode;\n-\n-  gcc_assert (t1 != t2);\n-\n-  if (early_barrier_required)\n-    arm_process_output_memory_barrier (emit, NULL);\n-\n-  arm_output_asm_insn (emit, 1, operands, \"%sLSYT%%=:\", LOCAL_LABEL_PREFIX);\n-\n-  arm_output_ldrex (emit, mode, old_value, memory);\n-\n-  if (is_di)\n-    {\n-      old_value_lo = gen_lowpart (SImode, old_value);\n-      old_value_hi = gen_highpart (SImode, old_value);\n-      if (required_value)\n-\t{\n-\t  required_value_lo = gen_lowpart (SImode, required_value);\n-\t  required_value_hi = gen_highpart (SImode, required_value);\n-\t}\n-      else\n-\t{\n-\t  /* Silence false potentially unused warning.  */\n-\t  required_value_lo = NULL_RTX;\n-\t  required_value_hi = NULL_RTX;\n-\t}\n-      new_value_lo = gen_lowpart (SImode, new_value);\n-      new_value_hi = gen_highpart (SImode, new_value);\n-      t1_lo = gen_lowpart (SImode, t1);\n-      t1_hi = gen_highpart (SImode, t1);\n-    }\n-  else\n-    {\n-      old_value_lo = old_value;\n-      new_value_lo = new_value;\n-      required_value_lo = required_value;\n-      t1_lo = t1;\n-\n-      /* Silence false potentially unused warning.  */\n-      t1_hi = NULL_RTX;\n-      new_value_hi = NULL_RTX;\n-      required_value_hi = NULL_RTX;\n-      old_value_hi = NULL_RTX;\n-    }\n-\n-  if (required_value)\n-    {\n-      operands[0] = old_value_lo;\n-      operands[1] = required_value_lo;\n-\n-      arm_output_asm_insn (emit, 0, operands, \"cmp\\t%%0, %%1\");\n-      if (is_di)\n-        {\n-          arm_output_it (emit, \"\", \"eq\");\n-          arm_output_op2 (emit, \"cmpeq\", old_value_hi, required_value_hi);\n-        }\n-      arm_output_asm_insn (emit, 0, operands, \"bne\\t%sLSYB%%=\", LOCAL_LABEL_PREFIX);\n-    }\n-\n-  switch (sync_op)\n-    {\n-    case SYNC_OP_ADD:\n-      arm_output_op3 (emit, is_di ? \"adds\" : \"add\",\n-\t\t      t1_lo, old_value_lo, new_value_lo);\n-      if (is_di)\n-\tarm_output_op3 (emit, \"adc\", t1_hi, old_value_hi, new_value_hi);\n-      break;\n-\n-    case SYNC_OP_SUB:\n-      arm_output_op3 (emit, is_di ? \"subs\" : \"sub\",\n-\t\t      t1_lo, old_value_lo, new_value_lo);\n-      if (is_di)\n-\tarm_output_op3 (emit, \"sbc\", t1_hi, old_value_hi, new_value_hi);\n-      break;\n-\n-    case SYNC_OP_IOR:\n-      arm_output_op3 (emit, \"orr\", t1_lo, old_value_lo, new_value_lo);\n-      if (is_di)\n-\tarm_output_op3 (emit, \"orr\", t1_hi, old_value_hi, new_value_hi);\n-      break;\n-\n-    case SYNC_OP_XOR:\n-      arm_output_op3 (emit, \"eor\", t1_lo, old_value_lo, new_value_lo);\n-      if (is_di)\n-\tarm_output_op3 (emit, \"eor\", t1_hi, old_value_hi, new_value_hi);\n-      break;\n-\n-    case SYNC_OP_AND:\n-      arm_output_op3 (emit,\"and\", t1_lo, old_value_lo, new_value_lo);\n-      if (is_di)\n-\tarm_output_op3 (emit, \"and\", t1_hi, old_value_hi, new_value_hi);\n-      break;\n-\n-    case SYNC_OP_NAND:\n-      arm_output_op3 (emit, \"and\", t1_lo, old_value_lo, new_value_lo);\n-      if (is_di)\n-\tarm_output_op3 (emit, \"and\", t1_hi, old_value_hi, new_value_hi);\n-      arm_output_op2 (emit, \"mvn\", t1_lo, t1_lo);\n-      if (is_di)\n-\tarm_output_op2 (emit, \"mvn\", t1_hi, t1_hi);\n-      break;\n-\n-    case SYNC_OP_NONE:\n-      t1 = new_value;\n-      t1_lo = new_value_lo;\n-      if (is_di)\n-\tt1_hi = new_value_hi;\n-      break;\n-    }\n-\n-  /* Note that the result of strex is a 0/1 flag that's always 1 register.  */\n-  if (t2)\n-    {\n-      arm_output_strex (emit, mode, \"\", t2, t1, memory);\n-      operands[0] = t2;\n-      arm_output_asm_insn (emit, 0, operands, \"teq\\t%%0, #0\");\n-      arm_output_asm_insn (emit, 0, operands, \"bne\\t%sLSYT%%=\",\n-\t\t\t   LOCAL_LABEL_PREFIX);\n-    }\n-  else\n-    {\n-      /* Use old_value for the return value because for some operations\n-\t the old_value can easily be restored.  This saves one register.  */\n-      arm_output_strex (emit, mode, \"\", old_value_lo, t1, memory);\n-      operands[0] = old_value_lo;\n-      arm_output_asm_insn (emit, 0, operands, \"teq\\t%%0, #0\");\n-      arm_output_asm_insn (emit, 0, operands, \"bne\\t%sLSYT%%=\",\n-\t\t\t   LOCAL_LABEL_PREFIX);\n-\n-      /* Note that we only used the _lo half of old_value as a temporary\n-\t so in DI we don't have to restore the _hi part.  */\n-      switch (sync_op)\n-\t{\n-\tcase SYNC_OP_ADD:\n-\t  arm_output_op3 (emit, \"sub\", old_value_lo, t1_lo, new_value_lo);\n-\t  break;\n-\n-\tcase SYNC_OP_SUB:\n-\t  arm_output_op3 (emit, \"add\", old_value_lo, t1_lo, new_value_lo);\n-\t  break;\n-\n-\tcase SYNC_OP_XOR:\n-\t  arm_output_op3 (emit, \"eor\", old_value_lo, t1_lo, new_value_lo);\n-\t  break;\n-\n-\tcase SYNC_OP_NONE:\n-\t  arm_output_op2 (emit, \"mov\", old_value_lo, required_value_lo);\n-\t  break;\n-\n-\tdefault:\n-\t  gcc_unreachable ();\n-\t}\n-    }\n-\n-  /* Note: label is before barrier so that in cmp failure case we still get\n-     a barrier to stop subsequent loads floating upwards past the ldrex\n-     PR target/48126.  */\n-  arm_output_asm_insn (emit, 1, operands, \"%sLSYB%%=:\", LOCAL_LABEL_PREFIX);\n-  arm_process_output_memory_barrier (emit, NULL);\n-}\n-\n-static rtx\n-arm_get_sync_operand (rtx *operands, int index, rtx default_value)\n-{\n-  if (index > 0)\n-    default_value = operands[index - 1];\n-\n-  return default_value;\n-}\n-\n-#define FETCH_SYNC_OPERAND(NAME, DEFAULT) \\\n-  arm_get_sync_operand (operands, (int) get_attr_sync_##NAME (insn), DEFAULT);\n-\n-/* Extract the operands for a synchroniztion instruction from the\n-   instructions attributes and emit the instruction.  */\n-static void\n-arm_process_output_sync_insn (emit_f emit, rtx insn, rtx *operands)\n-{\n-  rtx result, memory, required_value, new_value, t1, t2;\n-  int early_barrier;\n-  enum machine_mode mode;\n-  enum attr_sync_op sync_op;\n-\n-  result = FETCH_SYNC_OPERAND(result, 0);\n-  memory = FETCH_SYNC_OPERAND(memory, 0);\n-  required_value = FETCH_SYNC_OPERAND(required_value, 0);\n-  new_value = FETCH_SYNC_OPERAND(new_value, 0);\n-  t1 = FETCH_SYNC_OPERAND(t1, 0);\n-  t2 = FETCH_SYNC_OPERAND(t2, 0);\n-  early_barrier =\n-    get_attr_sync_release_barrier (insn) == SYNC_RELEASE_BARRIER_YES;\n-  sync_op = get_attr_sync_op (insn);\n-  mode = GET_MODE (memory);\n-\n-  arm_output_sync_loop (emit, mode, result, memory, required_value,\n-\t\t\tnew_value, t1, t2, sync_op, early_barrier);\n-}\n-\n-/* Emit a synchronization instruction loop.  */\n-const char *\n-arm_output_sync_insn (rtx insn, rtx *operands)\n-{\n-  arm_process_output_sync_insn (arm_emit, insn, operands);\n-  return \"\";\n-}\n-\n-/* Count the number of machine instruction that will be emitted for a\n-   synchronization instruction.  Note that the emitter used does not\n-   emit instructions, it just counts instructions being carefull not\n-   to count labels.  */\n-unsigned int\n-arm_sync_loop_insns (rtx insn, rtx *operands)\n-{\n-  arm_insn_count = 0;\n-  arm_process_output_sync_insn (arm_count, insn, operands);\n-  return arm_insn_count;\n-}\n-\n-/* Helper to call a target sync instruction generator, dealing with\n-   the variation in operands required by the different generators.  */\n-static rtx\n-arm_call_generator (struct arm_sync_generator *generator, rtx old_value,\n-  \t\t    rtx memory, rtx required_value, rtx new_value)\n-{\n-  switch (generator->op)\n-    {\n-    case arm_sync_generator_omn:\n-      gcc_assert (! required_value);\n-      return generator->u.omn (old_value, memory, new_value);\n-\n-    case arm_sync_generator_omrn:\n-      gcc_assert (required_value);\n-      return generator->u.omrn (old_value, memory, required_value, new_value);\n-    }\n-\n-  return NULL;\n-}\n-\n-/* Expand a synchronization loop. The synchronization loop is expanded\n-   as an opaque block of instructions in order to ensure that we do\n-   not subsequently get extraneous memory accesses inserted within the\n-   critical region. The exclusive access property of ldrex/strex is\n-   only guaranteed in there are no intervening memory accesses. */\n-void\n-arm_expand_sync (enum machine_mode mode,\n-\t\t struct arm_sync_generator *generator,\n-\t\t rtx target, rtx memory, rtx required_value, rtx new_value)\n-{\n-  if (target == NULL)\n-    target = gen_reg_rtx (mode);\n-\n-  memory = arm_legitimize_sync_memory (memory);\n-  if (mode != SImode && mode != DImode)\n-    {\n-      rtx load_temp = gen_reg_rtx (SImode);\n-\n-      if (required_value)\n-\trequired_value = convert_modes (SImode, mode, required_value, true);\n-\n-      new_value = convert_modes (SImode, mode, new_value, true);\n-      emit_insn (arm_call_generator (generator, load_temp, memory,\n-\t\t\t\t     required_value, new_value));\n-      emit_move_insn (target, gen_lowpart (mode, load_temp));\n-    }\n-  else\n-    {\n-      emit_insn (arm_call_generator (generator, target, memory, required_value,\n-\t\t\t\t     new_value));\n-    }\n-}\n-\n static unsigned int\n arm_autovectorize_vector_sizes (void)\n {\n@@ -25150,5 +24643,308 @@ vfp3_const_double_for_fract_bits (rtx operand)\n   return 0;\n }\n \n+/* Emit a memory barrier around an atomic sequence according to MODEL.  */\n+\n+static void\n+arm_pre_atomic_barrier (enum memmodel model)\n+{\n+  switch (model)\n+    {\n+    case MEMMODEL_RELAXED:\n+    case MEMMODEL_CONSUME:\n+    case MEMMODEL_ACQUIRE:\n+      break;\n+    case MEMMODEL_RELEASE:\n+    case MEMMODEL_ACQ_REL:\n+    case MEMMODEL_SEQ_CST:\n+      emit_insn (gen_memory_barrier ());\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+static void\n+arm_post_atomic_barrier (enum memmodel model)\n+{\n+  switch (model)\n+    {\n+    case MEMMODEL_RELAXED:\n+    case MEMMODEL_CONSUME:\n+    case MEMMODEL_RELEASE:\n+      break;\n+    case MEMMODEL_ACQUIRE:\n+    case MEMMODEL_ACQ_REL:\n+    case MEMMODEL_SEQ_CST:\n+      emit_insn (gen_memory_barrier ());\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+/* Emit the load-exclusive and store-exclusive instructions.  */\n+\n+static void\n+arm_emit_load_exclusive (enum machine_mode mode, rtx rval, rtx mem)\n+{\n+  rtx (*gen) (rtx, rtx);\n+\n+  switch (mode)\n+    {\n+    case QImode: gen = gen_arm_load_exclusiveqi; break;\n+    case HImode: gen = gen_arm_load_exclusivehi; break;\n+    case SImode: gen = gen_arm_load_exclusivesi; break;\n+    case DImode: gen = gen_arm_load_exclusivedi; break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  emit_insn (gen (rval, mem));\n+}\n+\n+static void\n+arm_emit_store_exclusive (enum machine_mode mode, rtx bval, rtx rval, rtx mem)\n+{\n+  rtx (*gen) (rtx, rtx, rtx);\n+\n+  switch (mode)\n+    {\n+    case QImode: gen = gen_arm_store_exclusiveqi; break;\n+    case HImode: gen = gen_arm_store_exclusivehi; break;\n+    case SImode: gen = gen_arm_store_exclusivesi; break;\n+    case DImode: gen = gen_arm_store_exclusivedi; break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  emit_insn (gen (bval, rval, mem));\n+}\n+\n+/* Mark the previous jump instruction as unlikely.  */\n+\n+static void\n+emit_unlikely_jump (rtx insn)\n+{\n+  rtx very_unlikely = GEN_INT (REG_BR_PROB_BASE / 100 - 1);\n+\n+  insn = emit_jump_insn (insn);\n+  add_reg_note (insn, REG_BR_PROB, very_unlikely);\n+}\n+\n+/* Expand a compare and swap pattern.  */\n+\n+void\n+arm_expand_compare_and_swap (rtx operands[])\n+{\n+  rtx bval, rval, mem, oldval, newval, is_weak, mod_s, mod_f, x;\n+  enum machine_mode mode;\n+  rtx (*gen) (rtx, rtx, rtx, rtx, rtx, rtx, rtx);\n+\n+  bval = operands[0];\n+  rval = operands[1];\n+  mem = operands[2];\n+  oldval = operands[3];\n+  newval = operands[4];\n+  is_weak = operands[5];\n+  mod_s = operands[6];\n+  mod_f = operands[7];\n+  mode = GET_MODE (mem);\n+\n+  switch (mode)\n+    {\n+    case QImode:\n+    case HImode:\n+      /* For narrow modes, we're going to perform the comparison in SImode,\n+\t so do the zero-extension now.  */\n+      rval = gen_reg_rtx (SImode);\n+      oldval = convert_modes (SImode, mode, oldval, true);\n+      /* FALLTHRU */\n+\n+    case SImode:\n+      /* Force the value into a register if needed.  We waited until after\n+\t the zero-extension above to do this properly.  */\n+      if (!arm_add_operand (oldval, mode))\n+\toldval = force_reg (mode, oldval);\n+      break;\n+\n+    case DImode:\n+      if (!cmpdi_operand (oldval, mode))\n+\toldval = force_reg (mode, oldval);\n+      break;\n+\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  switch (mode)\n+    {\n+    case QImode: gen = gen_atomic_compare_and_swapqi_1; break;\n+    case HImode: gen = gen_atomic_compare_and_swaphi_1; break;\n+    case SImode: gen = gen_atomic_compare_and_swapsi_1; break;\n+    case DImode: gen = gen_atomic_compare_and_swapdi_1; break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  emit_insn (gen (rval, mem, oldval, newval, is_weak, mod_s, mod_f));\n+\n+  if (mode == QImode || mode == HImode)\n+    emit_move_insn (operands[1], gen_lowpart (mode, rval));\n+\n+  /* In all cases, we arrange for success to be signaled by Z set.\n+     This arrangement allows for the boolean result to be used directly\n+     in a subsequent branch, post optimization.  */\n+  x = gen_rtx_REG (CCmode, CC_REGNUM);\n+  x = gen_rtx_EQ (SImode, x, const0_rtx);\n+  emit_insn (gen_rtx_SET (VOIDmode, bval, x));\n+}\n+\n+/* Split a compare and swap pattern.  It is IMPLEMENTATION DEFINED whether\n+   another memory store between the load-exclusive and store-exclusive can\n+   reset the monitor from Exclusive to Open state.  This means we must wait\n+   until after reload to split the pattern, lest we get a register spill in\n+   the middle of the atomic sequence.  */\n+\n+void\n+arm_split_compare_and_swap (rtx operands[])\n+{\n+  rtx rval, mem, oldval, newval, scratch;\n+  enum machine_mode mode;\n+  enum memmodel mod_s, mod_f;\n+  bool is_weak;\n+  rtx label1, label2, x, cond;\n+\n+  rval = operands[0];\n+  mem = operands[1];\n+  oldval = operands[2];\n+  newval = operands[3];\n+  is_weak = (operands[4] != const0_rtx);\n+  mod_s = (enum memmodel) INTVAL (operands[5]);\n+  mod_f = (enum memmodel) INTVAL (operands[6]);\n+  scratch = operands[7];\n+  mode = GET_MODE (mem);\n+\n+  arm_pre_atomic_barrier (mod_s);\n+\n+  label1 = NULL_RTX;\n+  if (!is_weak)\n+    {\n+      label1 = gen_label_rtx ();\n+      emit_label (label1);\n+    }\n+  label2 = gen_label_rtx ();\n+\n+  arm_emit_load_exclusive (mode, rval, mem);\n+\n+  cond = arm_gen_compare_reg (NE, rval, oldval, scratch);\n+  x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n+  x = gen_rtx_IF_THEN_ELSE (VOIDmode, x,\n+\t\t\t    gen_rtx_LABEL_REF (Pmode, label2), pc_rtx);\n+  emit_unlikely_jump (gen_rtx_SET (VOIDmode, pc_rtx, x));\n+\n+  arm_emit_store_exclusive (mode, scratch, mem, newval);\n+\n+  /* Weak or strong, we want EQ to be true for success, so that we\n+     match the flags that we got from the compare above.  */\n+  cond = gen_rtx_REG (CCmode, CC_REGNUM);\n+  x = gen_rtx_COMPARE (CCmode, scratch, const0_rtx);\n+  emit_insn (gen_rtx_SET (VOIDmode, cond, x));\n+\n+  if (!is_weak)\n+    {\n+      x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n+      x = gen_rtx_IF_THEN_ELSE (VOIDmode, x,\n+\t\t\t\tgen_rtx_LABEL_REF (Pmode, label1), pc_rtx);\n+      emit_unlikely_jump (gen_rtx_SET (VOIDmode, pc_rtx, x));\n+    }\n+\n+  if (mod_f != MEMMODEL_RELAXED)\n+    emit_label (label2);\n+\n+  arm_post_atomic_barrier (mod_s);\n+\n+  if (mod_f == MEMMODEL_RELAXED)\n+    emit_label (label2);\n+}\n+\n+void\n+arm_split_atomic_op (enum rtx_code code, rtx old_out, rtx new_out, rtx mem,\n+\t\t     rtx value, rtx model_rtx, rtx cond)\n+{\n+  enum memmodel model = (enum memmodel) INTVAL (model_rtx);\n+  enum machine_mode mode = GET_MODE (mem);\n+  enum machine_mode wmode = (mode == DImode ? DImode : SImode);\n+  rtx label, x;\n+\n+  arm_pre_atomic_barrier (model);\n+\n+  label = gen_label_rtx ();\n+  emit_label (label);\n+\n+  if (new_out)\n+    new_out = gen_lowpart (wmode, new_out);\n+  if (old_out)\n+    old_out = gen_lowpart (wmode, old_out);\n+  else\n+    old_out = new_out;\n+  value = simplify_gen_subreg (wmode, value, mode, 0);\n+\n+  arm_emit_load_exclusive (mode, old_out, mem);\n+\n+  switch (code)\n+    {\n+    case SET:\n+      new_out = value;\n+      break;\n+\n+    case NOT:\n+      x = gen_rtx_AND (wmode, old_out, value);\n+      emit_insn (gen_rtx_SET (VOIDmode, new_out, x));\n+      x = gen_rtx_NOT (wmode, new_out);\n+      emit_insn (gen_rtx_SET (VOIDmode, new_out, x));\n+      break;\n+\n+    case MINUS:\n+      if (CONST_INT_P (value))\n+\t{\n+\t  value = GEN_INT (-INTVAL (value));\n+\t  code = PLUS;\n+\t}\n+      /* FALLTHRU */\n+\n+    case PLUS:\n+      if (mode == DImode)\n+\t{\n+\t  /* DImode plus/minus need to clobber flags.  */\n+\t  /* The adddi3 and subdi3 patterns are incorrectly written so that\n+\t     they require matching operands, even when we could easily support\n+\t     three operands.  Thankfully, this can be fixed up post-splitting,\n+\t     as the individual add+adc patterns do accept three operands and\n+\t     post-reload cprop can make these moves go away.  */\n+\t  emit_move_insn (new_out, old_out);\n+\t  if (code == PLUS)\n+\t    x = gen_adddi3 (new_out, new_out, value);\n+\t  else\n+\t    x = gen_subdi3 (new_out, new_out, value);\n+\t  emit_insn (x);\n+\t  break;\n+\t}\n+      /* FALLTHRU */\n+\n+    default:\n+      x = gen_rtx_fmt_ee (code, wmode, old_out, value);\n+      emit_insn (gen_rtx_SET (VOIDmode, new_out, x));\n+      break;\n+    }\n+\n+  arm_emit_store_exclusive (mode, cond, mem, gen_lowpart (mode, new_out));\n+\n+  x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n+  emit_unlikely_jump (gen_cbranchsi4 (x, cond, const0_rtx, label));\n+\n+  arm_post_atomic_barrier (model);\n+}\n+\n #include \"gt-arm.h\"\n "}, {"sha": "443d2ed168dc4e9bf19a977acbfe4b4d614a4fc3", "filename": "gcc/config/arm/arm.h", "status": "modified", "additions": 1, "deletions": 19, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2Fconfig%2Farm%2Farm.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2Fconfig%2Farm%2Farm.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.h?ref=18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f", "patch": "@@ -1,6 +1,6 @@\n /* Definitions of target machine for GNU compiler, for ARM.\n    Copyright (C) 1991, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,\n-   2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011\n+   2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012\n    Free Software Foundation, Inc.\n    Contributed by Pieter `Tiggr' Schoenmakers (rcpieter@win.tue.nl)\n    and Martin Simmons (@harleqn.co.uk).\n@@ -123,24 +123,6 @@ enum target_cpus\n /* The processor for which instructions should be scheduled.  */\n extern enum processor_type arm_tune;\n \n-enum arm_sync_generator_tag\n-  {\n-    arm_sync_generator_omn,\n-    arm_sync_generator_omrn\n-  };\n-\n-/* Wrapper to pass around a polymorphic pointer to a sync instruction\n-   generator and.  */\n-struct arm_sync_generator\n-{\n-  enum arm_sync_generator_tag op;\n-  union\n-  {\n-    rtx (* omn) (rtx, rtx, rtx);\n-    rtx (* omrn) (rtx, rtx, rtx, rtx);\n-  } u;\n-};\n-\n typedef enum arm_cond_code\n {\n   ARM_EQ = 0, ARM_NE, ARM_CS, ARM_CC, ARM_MI, ARM_PL, ARM_VS, ARM_VC,"}, {"sha": "0e4bc3e50a1733ae27947c32809f2ebf770cb353", "filename": "gcc/config/arm/arm.md", "status": "modified", "additions": 11, "deletions": 23, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2Fconfig%2Farm%2Farm.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2Fconfig%2Farm%2Farm.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.md?ref=18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f", "patch": "@@ -151,11 +151,11 @@\n   VUNSPEC_WCMP_GT       ; Used by the iwMMXT WCMPGT instructions\n   VUNSPEC_EH_RETURN     ; Use to override the return address for exception\n                         ; handling.\n-  VUNSPEC_SYNC_COMPARE_AND_SWAP    ; Represent an atomic compare swap.\n-  VUNSPEC_SYNC_LOCK                ; Represent a sync_lock_test_and_set.\n-  VUNSPEC_SYNC_OP                  ; Represent a sync_<op>\n-  VUNSPEC_SYNC_NEW_OP              ; Represent a sync_new_<op>\n-  VUNSPEC_SYNC_OLD_OP              ; Represent a sync_old_<op>\n+  VUNSPEC_ATOMIC_CAS\t; Represent an atomic compare swap.\n+  VUNSPEC_ATOMIC_XCHG\t; Represent an atomic exchange.\n+  VUNSPEC_ATOMIC_OP\t; Represent an atomic operation.\n+  VUNSPEC_LL\t\t; Represent a load-register-exclusive.\n+  VUNSPEC_SC\t\t; Represent a store-register-exclusive.\n ])\n \f\n ;;---------------------------------------------------------------------------\n@@ -185,21 +185,9 @@\n (define_attr \"fpu\" \"none,fpa,fpe2,fpe3,maverick,vfp\"\n   (const (symbol_ref \"arm_fpu_attr\")))\n \n-(define_attr \"sync_result\"          \"none,0,1,2,3,4,5\" (const_string \"none\"))\n-(define_attr \"sync_memory\"          \"none,0,1,2,3,4,5\" (const_string \"none\"))\n-(define_attr \"sync_required_value\"  \"none,0,1,2,3,4,5\" (const_string \"none\"))\n-(define_attr \"sync_new_value\"       \"none,0,1,2,3,4,5\" (const_string \"none\"))\n-(define_attr \"sync_t1\"              \"none,0,1,2,3,4,5\" (const_string \"none\"))\n-(define_attr \"sync_t2\"              \"none,0,1,2,3,4,5\" (const_string \"none\"))\n-(define_attr \"sync_release_barrier\" \"yes,no\"           (const_string \"yes\"))\n-(define_attr \"sync_op\"              \"none,add,sub,ior,xor,and,nand\"\n-                                    (const_string \"none\"))\n-\n ; LENGTH of an instruction (in bytes)\n (define_attr \"length\" \"\"\n-  (cond [(not (eq_attr \"sync_memory\" \"none\"))\n- \t   (symbol_ref \"arm_sync_loop_insns (insn, operands) * 4\")\n-\t] (const_int 4)))\n+  (const_int 4))\n \n ; The architecture which supports the instruction (or alternative).\n ; This can be \"a\" for ARM, \"t\" for either of the Thumbs, \"32\" for\n@@ -7637,7 +7625,7 @@\n \t\t      (pc)))]\n   \"TARGET_32BIT\"\n   \"operands[1] = arm_gen_compare_reg (GET_CODE (operands[0]),\n-\t\t\t\t      operands[1], operands[2]);\n+\t\t\t\t      operands[1], operands[2], NULL_RTX);\n    operands[2] = const0_rtx;\"\n )\n \n@@ -7707,7 +7695,7 @@\n \t\t\t\t (match_operand 3 \"\" \"\")]))]\n   \"TARGET_32BIT\"\n   \"operands[2] = arm_gen_compare_reg (GET_CODE (operands[1]),\n-\t\t\t\t      operands[2], operands[3]);\n+\t\t\t\t      operands[2], operands[3], NULL_RTX);\n    operands[3] = const0_rtx;\"\n )\n \n@@ -8035,7 +8023,7 @@\n       FAIL;\n \n     ccreg = arm_gen_compare_reg (code, XEXP (operands[1], 0),\n-\t\t\t\t XEXP (operands[1], 1));\n+\t\t\t\t XEXP (operands[1], 1), NULL_RTX);\n     operands[1] = gen_rtx_fmt_ee (code, VOIDmode, ccreg, const0_rtx);\n   }\"\n )\n@@ -8061,7 +8049,7 @@\n       operands[3] = force_reg (SFmode, operands[3]);\n \n     ccreg = arm_gen_compare_reg (code, XEXP (operands[1], 0),\n-\t\t\t\t XEXP (operands[1], 1));\n+\t\t\t\t XEXP (operands[1], 1), NULL_RTX);\n     operands[1] = gen_rtx_fmt_ee (code, VOIDmode, ccreg, const0_rtx);\n   }\"\n )\n@@ -8081,7 +8069,7 @@\n       FAIL;\n \n     ccreg = arm_gen_compare_reg (code, XEXP (operands[1], 0),\n-\t\t\t\t XEXP (operands[1], 1));\n+\t\t\t\t XEXP (operands[1], 1), NULL_RTX);\n     operands[1] = gen_rtx_fmt_ee (code, VOIDmode, ccreg, const0_rtx);\n   }\"\n )"}, {"sha": "3ff968b98eadb56c4222227e8b05e945aaea8916", "filename": "gcc/config/arm/constraints.md", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2Fconfig%2Farm%2Fconstraints.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2Fconfig%2Farm%2Fconstraints.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fconstraints.md?ref=18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f", "patch": "@@ -297,6 +297,11 @@\n   (and (match_code \"const_double\")\n        (match_test \"TARGET_32BIT && TARGET_VFP && vfp3_const_double_for_fract_bits (op)\")))\n \n+(define_memory_constraint \"Ua\"\n+ \"@internal\n+  An address valid for loading/storing register exclusive\"\n+ (match_operand 0 \"mem_noofs_operand\"))\n+\n (define_memory_constraint \"Ut\"\n  \"@internal\n   In ARM/Thumb-2 state an address valid for loading/storing opaque structure"}, {"sha": "fa2f695356be3fbb889608501173e76363afa4ff", "filename": "gcc/config/arm/predicates.md", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2Fconfig%2Farm%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2Fconfig%2Farm%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fpredicates.md?ref=18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f", "patch": "@@ -769,3 +769,7 @@\n \n (define_special_predicate \"add_operator\"\n   (match_code \"plus\"))\n+\n+(define_predicate \"mem_noofs_operand\"\n+  (and (match_code \"mem\")\n+       (match_code \"reg\" \"0\")))"}, {"sha": "96de0f37d8d68a6841dce92f7f8db09e901e04c5", "filename": "gcc/config/arm/sync.md", "status": "modified", "additions": 264, "deletions": 406, "changes": 670, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2Fconfig%2Farm%2Fsync.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f/gcc%2Fconfig%2Farm%2Fsync.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fsync.md?ref=18f0fe6b98ec82da10e3d3c67f802f1cf6c2a77f", "patch": "@@ -1,5 +1,5 @@\n ;; Machine description for ARM processor synchronization primitives.\n-;; Copyright (C) 2010 Free Software Foundation, Inc.\n+;; Copyright (C) 2010, 2012 Free Software Foundation, Inc.\n ;; Written by Marcus Shawcroft (marcus.shawcroft@arm.com)\n ;; 64bit Atomics by Dave Gilbert (david.gilbert@linaro.org)\n ;;\n@@ -19,11 +19,20 @@\n ;; along with GCC; see the file COPYING3.  If not see\n ;; <http://www.gnu.org/licenses/>.  */\n \n-;; ARMV6 introduced ldrex and strex instruction. These instruction\n-;; access SI width data. In order to implement synchronization\n-;; primitives for the narrower QI and HI modes we insert appropriate\n-;; AND/OR sequences into the synchronization loop to mask out the\n-;; relevant component of an SI access.\n+(define_mode_attr sync_predtab\n+  [(QI \"TARGET_HAVE_LDREXBH && TARGET_HAVE_MEMORY_BARRIER\")\n+   (HI \"TARGET_HAVE_LDREXBH && TARGET_HAVE_MEMORY_BARRIER\")\n+   (SI \"TARGET_HAVE_LDREX && TARGET_HAVE_MEMORY_BARRIER\")\n+   (DI \"TARGET_HAVE_LDREXD && ARM_DOUBLEWORD_ALIGN\n+\t&& TARGET_HAVE_MEMORY_BARRIER\")])\n+\n+(define_code_iterator syncop [plus minus ior xor and])\n+\n+(define_code_attr sync_optab\n+  [(ior \"ior\") (xor \"xor\") (and \"and\") (plus \"add\") (minus \"sub\")])\n+\n+(define_mode_attr sync_sfx\n+  [(QI \"b\") (HI \"h\") (SI \"\") (DI \"d\")])\n \n (define_expand \"memory_barrier\"\n   [(set (match_dup 0)\n@@ -34,463 +43,312 @@\n   MEM_VOLATILE_P (operands[0]) = 1;\n })\n \n-\n-(define_mode_attr sync_predtab [(SI \"TARGET_HAVE_LDREX &&\n-\t\t\t\t\tTARGET_HAVE_MEMORY_BARRIER\")\n-\t\t\t\t(QI \"TARGET_HAVE_LDREXBH &&\n-\t\t\t\t\tTARGET_HAVE_MEMORY_BARRIER\")\n-\t\t\t\t(HI \"TARGET_HAVE_LDREXBH &&\n-\t\t\t\t\tTARGET_HAVE_MEMORY_BARRIER\")\n-\t\t\t\t(DI \"TARGET_HAVE_LDREXD &&\n-\t\t\t\t\tARM_DOUBLEWORD_ALIGN &&\n-\t\t\t\t\tTARGET_HAVE_MEMORY_BARRIER\")])\n-\n-(define_expand \"sync_compare_and_swap<mode>\"\n-  [(set (match_operand:QHSD 0 \"s_register_operand\")\n-        (unspec_volatile:QHSD [(match_operand:QHSD 1 \"memory_operand\")\n-\t\t\t     (match_operand:QHSD 2 \"s_register_operand\")\n-\t\t\t     (match_operand:QHSD 3 \"s_register_operand\")]\n-\t\t\t     VUNSPEC_SYNC_COMPARE_AND_SWAP))]\n-  \"<sync_predtab>\"\n-  {\n-    struct arm_sync_generator generator;\n-    generator.op = arm_sync_generator_omrn;\n-    generator.u.omrn = gen_arm_sync_compare_and_swap<mode>;\n-    arm_expand_sync (<MODE>mode, &generator, operands[0], operands[1],\n-                     operands[2], operands[3]);\n-    DONE;\n-  })\n-\n-(define_expand \"sync_lock_test_and_set<mode>\"\n-  [(match_operand:QHSD 0 \"s_register_operand\")\n-   (match_operand:QHSD 1 \"memory_operand\")\n-   (match_operand:QHSD 2 \"s_register_operand\")]\n-  \"<sync_predtab>\"\n+(define_insn \"*memory_barrier\"\n+  [(set (match_operand:BLK 0 \"\" \"\")\n+\t(unspec:BLK [(match_dup 0)] UNSPEC_MEMORY_BARRIER))]\n+  \"TARGET_HAVE_MEMORY_BARRIER\"\n   {\n-    struct arm_sync_generator generator;\n-    generator.op = arm_sync_generator_omn;\n-    generator.u.omn = gen_arm_sync_lock_test_and_set<mode>;\n-    arm_expand_sync (<MODE>mode, &generator, operands[0], operands[1], NULL,\n-                     operands[2]);\n-    DONE;\n-  })\n-\n-(define_code_iterator syncop [plus minus ior xor and])\n-\n-(define_code_attr sync_optab [(ior \"ior\")\n-\t\t\t      (xor \"xor\")\n-\t\t\t      (and \"and\")\n-\t\t\t      (plus \"add\")\n-\t\t\t      (minus \"sub\")])\n+    if (TARGET_HAVE_DMB)\n+      {\n+\t/* Note we issue a system level barrier. We should consider issuing\n+\t   a inner shareabilty zone barrier here instead, ie. \"DMB ISH\".  */\n+\t/* ??? Differentiate based on SEQ_CST vs less strict?  */\n+\treturn \"dmb\\tsy\";\n+      }\n \n-(define_code_attr sync_clobber [(ior \"=&r\")\n-\t\t\t\t(and \"=&r\")\n-\t\t\t\t(xor \"X\")\n-\t\t\t\t(plus \"X\")\n-\t\t\t\t(minus \"X\")])\n+    if (TARGET_HAVE_DMB_MCR)\n+      return \"mcr\\tp15, 0, r0, c7, c10, 5\";\n \n-(define_code_attr sync_t2_reqd [(ior \"4\")\n-\t\t\t\t(and \"4\")\n-\t\t\t\t(xor \"*\")\n-\t\t\t\t(plus \"*\")\n-\t\t\t\t(minus \"*\")])\n-\n-(define_expand \"sync_<sync_optab><mode>\"\n-  [(match_operand:QHSD 0 \"memory_operand\")\n-   (match_operand:QHSD 1 \"s_register_operand\")\n-   (syncop:QHSD (match_dup 0) (match_dup 1))]\n-  \"<sync_predtab>\"\n-  {\n-    struct arm_sync_generator generator;\n-    generator.op = arm_sync_generator_omn;\n-    generator.u.omn = gen_arm_sync_new_<sync_optab><mode>;\n-    arm_expand_sync (<MODE>mode, &generator, NULL, operands[0], NULL,\n-\t\t     operands[1]);\n-    DONE;\n-  })\n+    gcc_unreachable ();\n+  }\n+  [(set_attr \"length\" \"4\")\n+   (set_attr \"conds\" \"unconditional\")\n+   (set_attr \"predicable\" \"no\")])\n \n-(define_expand \"sync_nand<mode>\"\n-  [(match_operand:QHSD 0 \"memory_operand\")\n-   (match_operand:QHSD 1 \"s_register_operand\")\n-   (not:QHSD (and:QHSD (match_dup 0) (match_dup 1)))]\n+(define_expand \"atomic_compare_and_swap<mode>\"\n+  [(match_operand:SI 0 \"s_register_operand\" \"\")\t\t;; bool out\n+   (match_operand:QHSD 1 \"s_register_operand\" \"\")\t;; val out\n+   (match_operand:QHSD 2 \"mem_noofs_operand\" \"\")\t;; memory\n+   (match_operand:QHSD 3 \"general_operand\" \"\")\t\t;; expected\n+   (match_operand:QHSD 4 \"s_register_operand\" \"\")\t;; desired\n+   (match_operand:SI 5 \"const_int_operand\")\t\t;; is_weak\n+   (match_operand:SI 6 \"const_int_operand\")\t\t;; mod_s\n+   (match_operand:SI 7 \"const_int_operand\")]\t\t;; mod_f\n   \"<sync_predtab>\"\n-  {\n-    struct arm_sync_generator generator;\n-    generator.op = arm_sync_generator_omn;\n-    generator.u.omn = gen_arm_sync_new_nand<mode>;\n-    arm_expand_sync (<MODE>mode, &generator, NULL, operands[0], NULL,\n-                     operands[1]);\n-    DONE;\n-  })\n+{\n+  arm_expand_compare_and_swap (operands);\n+  DONE;\n+})\n \n-(define_expand \"sync_new_<sync_optab><mode>\"\n-  [(match_operand:QHSD 0 \"s_register_operand\")\n-   (match_operand:QHSD 1 \"memory_operand\")\n-   (match_operand:QHSD 2 \"s_register_operand\")\n-   (syncop:QHSD (match_dup 1) (match_dup 2))]\n+(define_insn_and_split \"atomic_compare_and_swap<mode>_1\"\n+  [(set (reg:CC_Z CC_REGNUM)\t\t\t\t\t;; bool out\n+\t(unspec_volatile:CC_Z [(const_int 0)] VUNSPEC_ATOMIC_CAS))\n+   (set (match_operand:SI 0 \"s_register_operand\" \"=&r\")\t\t;; val out\n+\t(zero_extend:SI\n+\t  (match_operand:NARROW 1 \"mem_noofs_operand\" \"+Ua\")))\t;; memory\n+   (set (match_dup 1)\n+\t(unspec_volatile:NARROW\n+\t  [(match_operand:SI 2 \"arm_add_operand\" \"rIL\")\t\t;; expected\n+\t   (match_operand:NARROW 3 \"s_register_operand\" \"r\")\t;; desired\n+\t   (match_operand:SI 4 \"const_int_operand\")\t\t;; is_weak\n+\t   (match_operand:SI 5 \"const_int_operand\")\t\t;; mod_s\n+\t   (match_operand:SI 6 \"const_int_operand\")]\t\t;; mod_f\n+\t  VUNSPEC_ATOMIC_CAS))\n+   (clobber (match_scratch:SI 7 \"=&r\"))]\n   \"<sync_predtab>\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(const_int 0)]\n   {\n-    struct arm_sync_generator generator;\n-    generator.op = arm_sync_generator_omn;\n-    generator.u.omn = gen_arm_sync_new_<sync_optab><mode>;\n-    arm_expand_sync (<MODE>mode, &generator, operands[0], operands[1],\n-\t\t     NULL, operands[2]);\n+    arm_split_compare_and_swap (operands);\n     DONE;\n   })\n \n-(define_expand \"sync_new_nand<mode>\"\n-  [(match_operand:QHSD 0 \"s_register_operand\")\n-   (match_operand:QHSD 1 \"memory_operand\")\n-   (match_operand:QHSD 2 \"s_register_operand\")\n-   (not:QHSD (and:QHSD (match_dup 1) (match_dup 2)))]\n-  \"<sync_predtab>\"\n-  {\n-    struct arm_sync_generator generator;\n-    generator.op = arm_sync_generator_omn;\n-    generator.u.omn = gen_arm_sync_new_nand<mode>;\n-    arm_expand_sync (<MODE>mode, &generator, operands[0], operands[1],\n-    \t\t     NULL, operands[2]);\n-    DONE;\n-  });\n+(define_mode_attr cas_cmp_operand\n+  [(SI \"arm_add_operand\") (DI \"cmpdi_operand\")])\n+(define_mode_attr cas_cmp_str\n+  [(SI \"rIL\") (DI \"rDi\")])\n \n-(define_expand \"sync_old_<sync_optab><mode>\"\n-  [(match_operand:QHSD 0 \"s_register_operand\")\n-   (match_operand:QHSD 1 \"memory_operand\")\n-   (match_operand:QHSD 2 \"s_register_operand\")\n-   (syncop:QHSD (match_dup 1) (match_dup 2))]\n+(define_insn_and_split \"atomic_compare_and_swap<mode>_1\"\n+  [(set (reg:CC_Z CC_REGNUM)\t\t\t\t\t;; bool out\n+\t(unspec_volatile:CC_Z [(const_int 0)] VUNSPEC_ATOMIC_CAS))\n+   (set (match_operand:SIDI 0 \"s_register_operand\" \"=&r\")\t;; val out\n+\t(match_operand:SIDI 1 \"mem_noofs_operand\" \"+Ua\"))\t;; memory\n+   (set (match_dup 1)\n+\t(unspec_volatile:SIDI\n+\t  [(match_operand:SIDI 2 \"<cas_cmp_operand>\" \"<cas_cmp_str>\") ;; expect\n+\t   (match_operand:SIDI 3 \"s_register_operand\" \"r\")\t;; desired\n+\t   (match_operand:SI 4 \"const_int_operand\")\t\t;; is_weak\n+\t   (match_operand:SI 5 \"const_int_operand\")\t\t;; mod_s\n+\t   (match_operand:SI 6 \"const_int_operand\")]\t\t;; mod_f\n+\t  VUNSPEC_ATOMIC_CAS))\n+   (clobber (match_scratch:SI 7 \"=&r\"))]\n   \"<sync_predtab>\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(const_int 0)]\n   {\n-    struct arm_sync_generator generator;\n-    generator.op = arm_sync_generator_omn;\n-    generator.u.omn = gen_arm_sync_old_<sync_optab><mode>;\n-    arm_expand_sync (<MODE>mode, &generator, operands[0], operands[1],\n-\t\t     NULL, operands[2]);\n+    arm_split_compare_and_swap (operands);\n     DONE;\n   })\n \n-(define_expand \"sync_old_nand<mode>\"\n-  [(match_operand:QHSD 0 \"s_register_operand\")\n-   (match_operand:QHSD 1 \"memory_operand\")\n-   (match_operand:QHSD 2 \"s_register_operand\")\n-   (not:QHSD (and:QHSD (match_dup 1) (match_dup 2)))]\n+(define_insn_and_split \"atomic_exchange<mode>\"\n+  [(set (match_operand:QHSD 0 \"s_register_operand\" \"=&r\")\t;; output\n+\t(match_operand:QHSD 1 \"mem_noofs_operand\" \"+Ua\"))\t;; memory\n+   (set (match_dup 1)\n+\t(unspec_volatile:QHSD\n+\t  [(match_operand:QHSD 2 \"s_register_operand\" \"r\")\t;; input\n+\t   (match_operand:SI 3 \"const_int_operand\" \"\")]\t\t;; model\n+\t  VUNSPEC_ATOMIC_XCHG))\n+   (clobber (reg:CC CC_REGNUM))\n+   (clobber (match_scratch:SI 4 \"=&r\"))]\n   \"<sync_predtab>\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(const_int 0)]\n   {\n-    struct arm_sync_generator generator;\n-    generator.op = arm_sync_generator_omn;\n-    generator.u.omn = gen_arm_sync_old_nand<mode>;\n-    arm_expand_sync (<MODE>mode, &generator, operands[0], operands[1],\n-                     NULL, operands[2]);\n+    arm_split_atomic_op (SET, operands[0], NULL, operands[1],\n+\t\t\t operands[2], operands[3], operands[4]);\n     DONE;\n   })\n \n-(define_insn \"arm_sync_compare_and_swap<mode>\"\n-  [(set (match_operand:SIDI 0 \"s_register_operand\" \"=&r\")\n-        (unspec_volatile:SIDI\n-\t [(match_operand:SIDI 1 \"arm_sync_memory_operand\" \"+Q\")\n-\t  (match_operand:SIDI 2 \"s_register_operand\" \"r\")\n-\t  (match_operand:SIDI 3 \"s_register_operand\" \"r\")]\n-\t VUNSPEC_SYNC_COMPARE_AND_SWAP))\n-   (set (match_dup 1) (unspec_volatile:SIDI [(match_dup 2)]\n-                                          VUNSPEC_SYNC_COMPARE_AND_SWAP))\n-   (set (reg:CC CC_REGNUM) (unspec_volatile:CC [(match_dup 1)]\n-                                                VUNSPEC_SYNC_COMPARE_AND_SWAP))\n-   ]\n-  \"<sync_predtab>\"\n-  {\n-    return arm_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_required_value\"  \"2\")\n-   (set_attr \"sync_new_value\"       \"3\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"conds\" \"clob\")\n-   (set_attr \"predicable\" \"no\")])\n+(define_mode_attr atomic_op_operand\n+  [(QI \"reg_or_int_operand\")\n+   (HI \"reg_or_int_operand\")\n+   (SI \"reg_or_int_operand\")\n+   (DI \"s_register_operand\")])\n \n-(define_insn \"arm_sync_compare_and_swap<mode>\"\n-  [(set (match_operand:SI 0 \"s_register_operand\" \"=&r\")\n-        (zero_extend:SI\n-\t  (unspec_volatile:NARROW\n-\t    [(match_operand:NARROW 1 \"arm_sync_memory_operand\" \"+Q\")\n-\t     (match_operand:SI 2 \"s_register_operand\" \"r\")\n-\t     (match_operand:SI 3 \"s_register_operand\" \"r\")]\n-\t    VUNSPEC_SYNC_COMPARE_AND_SWAP)))\n-   (set (match_dup 1) (unspec_volatile:NARROW [(match_dup 2)]\n-                                          VUNSPEC_SYNC_COMPARE_AND_SWAP))\n-   (set (reg:CC CC_REGNUM) (unspec_volatile:CC [(match_dup 1)]\n-                                                VUNSPEC_SYNC_COMPARE_AND_SWAP))\n-   ]\n-  \"<sync_predtab>\"\n-  {\n-    return arm_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_required_value\"  \"2\")\n-   (set_attr \"sync_new_value\"       \"3\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"conds\" \"clob\")\n-   (set_attr \"predicable\" \"no\")])\n+(define_mode_attr atomic_op_str\n+  [(QI \"rn\") (HI \"rn\") (SI \"rn\") (DI \"r\")])\n \n-(define_insn \"arm_sync_lock_test_and_set<mode>\"\n-  [(set (match_operand:SIDI 0 \"s_register_operand\" \"=&r\")\n-\t(match_operand:SIDI 1 \"arm_sync_memory_operand\" \"+Q\"))\n-   (set (match_dup 1)\n-\t(unspec_volatile:SIDI [(match_operand:SIDI 2 \"s_register_operand\" \"r\")]\n-\tVUNSPEC_SYNC_LOCK))\n+(define_insn_and_split \"atomic_<sync_optab><mode>\"\n+  [(set (match_operand:QHSD 0 \"mem_noofs_operand\" \"+Ua\")\n+\t(unspec_volatile:QHSD\n+\t  [(syncop:QHSD (match_dup 0)\n+\t     (match_operand:QHSD 1 \"<atomic_op_operand>\" \"<atomic_op_str>\"))\n+\t   (match_operand:SI 2 \"const_int_operand\")]\t\t;; model\n+\t  VUNSPEC_ATOMIC_OP))\n    (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:SI 3 \"=&r\"))]\n+   (clobber (match_scratch:QHSD 3 \"=&r\"))\n+   (clobber (match_scratch:SI 4 \"=&r\"))]\n   \"<sync_predtab>\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(const_int 0)]\n   {\n-    return arm_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_release_barrier\" \"no\")\n-   (set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"sync_t2\"              \"3\")\n-   (set_attr \"conds\" \"clob\")\n-   (set_attr \"predicable\" \"no\")])\n+    arm_split_atomic_op (<CODE>, NULL, operands[3], operands[0],\n+\t\t\t operands[1], operands[2], operands[4]);\n+    DONE;\n+  })\n \n-(define_insn \"arm_sync_lock_test_and_set<mode>\"\n-  [(set (match_operand:SI 0 \"s_register_operand\" \"=&r\")\n-        (zero_extend:SI (match_operand:NARROW 1 \"arm_sync_memory_operand\" \"+Q\")))\n-   (set (match_dup 1)\n-        (unspec_volatile:NARROW [(match_operand:SI 2 \"s_register_operand\" \"r\")]\n-\t\t\t\tVUNSPEC_SYNC_LOCK))\n+(define_insn_and_split \"atomic_nand<mode>\"\n+  [(set (match_operand:QHSD 0 \"mem_noofs_operand\" \"+Ua\")\n+\t(unspec_volatile:QHSD\n+\t  [(not:QHSD\n+\t     (and:QHSD (match_dup 0)\n+\t       (match_operand:QHSD 1 \"<atomic_op_operand>\" \"<atomic_op_str>\")))\n+\t   (match_operand:SI 2 \"const_int_operand\")]\t\t;; model\n+\t  VUNSPEC_ATOMIC_OP))\n    (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:SI 3 \"=&r\"))]\n+   (clobber (match_scratch:QHSD 3 \"=&r\"))\n+   (clobber (match_scratch:SI 4 \"=&r\"))]\n   \"<sync_predtab>\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(const_int 0)]\n   {\n-    return arm_output_sync_insn (insn, operands);\n-  } \n-  [(set_attr \"sync_release_barrier\" \"no\")\n-   (set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"sync_t2\"              \"3\")\n-   (set_attr \"conds\" \"clob\")\n-   (set_attr \"predicable\" \"no\")])\n+    arm_split_atomic_op (NOT, NULL, operands[3], operands[0],\n+\t\t\t operands[1], operands[2], operands[4]);\n+    DONE;\n+  })\n \n-(define_insn \"arm_sync_new_<sync_optab><mode>\"\n-  [(set (match_operand:SIDI 0 \"s_register_operand\" \"=&r\")\n-        (unspec_volatile:SIDI [(syncop:SIDI\n-\t\t\t       (match_operand:SIDI 1 \"arm_sync_memory_operand\" \"+Q\")\n-\t\t\t       (match_operand:SIDI 2 \"s_register_operand\" \"r\"))\n-\t\t\t    ]\n-\t\t\t    VUNSPEC_SYNC_NEW_OP))\n+(define_insn_and_split \"atomic_fetch_<sync_optab><mode>\"\n+  [(set (match_operand:QHSD 0 \"s_register_operand\" \"=&r\")\n+\t(match_operand:QHSD 1 \"mem_noofs_operand\" \"+Ua\"))\n    (set (match_dup 1)\n-\t(unspec_volatile:SIDI [(match_dup 1) (match_dup 2)]\n-\t\t\t    VUNSPEC_SYNC_NEW_OP))\n+\t(unspec_volatile:QHSD\n+\t  [(syncop:QHSD (match_dup 1)\n+\t     (match_operand:QHSD 2 \"<atomic_op_operand>\" \"<atomic_op_str>\"))\n+\t   (match_operand:SI 3 \"const_int_operand\")]\t\t;; model\n+\t  VUNSPEC_ATOMIC_OP))\n    (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:SI 3 \"=&r\"))]\n+   (clobber (match_scratch:QHSD 4 \"=&r\"))\n+   (clobber (match_scratch:SI 5 \"=&r\"))]\n   \"<sync_predtab>\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(const_int 0)]\n   {\n-    return arm_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"sync_t2\"              \"3\")\n-   (set_attr \"sync_op\"              \"<sync_optab>\")\n-   (set_attr \"conds\" \"clob\")\n-   (set_attr \"predicable\" \"no\")])\n+    arm_split_atomic_op (<CODE>, operands[0], operands[4], operands[1],\n+\t\t\t operands[2], operands[3], operands[5]);\n+    DONE;\n+  })\n \n-(define_insn \"arm_sync_new_<sync_optab><mode>\"\n-  [(set (match_operand:SI 0 \"s_register_operand\" \"=&r\")\n-        (unspec_volatile:SI [(syncop:SI\n-\t\t\t       (zero_extend:SI\n-\t\t\t\t (match_operand:NARROW 1 \"arm_sync_memory_operand\" \"+Q\"))\n-\t\t\t       (match_operand:SI 2 \"s_register_operand\" \"r\"))\n-\t\t\t    ]\n-\t\t\t    VUNSPEC_SYNC_NEW_OP))\n+(define_insn_and_split \"atomic_fetch_nand<mode>\"\n+  [(set (match_operand:QHSD 0 \"s_register_operand\" \"=&r\")\n+\t(match_operand:QHSD 1 \"mem_noofs_operand\" \"+Ua\"))\n    (set (match_dup 1)\n-\t(unspec_volatile:NARROW [(match_dup 1) (match_dup 2)]\n-\t\t\t\tVUNSPEC_SYNC_NEW_OP))\n+\t(unspec_volatile:QHSD\n+\t  [(not:QHSD\n+\t     (and:QHSD (match_dup 1)\n+\t       (match_operand:QHSD 2 \"<atomic_op_operand>\" \"<atomic_op_str>\")))\n+\t   (match_operand:SI 3 \"const_int_operand\")]\t\t;; model\n+\t  VUNSPEC_ATOMIC_OP))\n    (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:SI 3 \"=&r\"))]\n+   (clobber (match_scratch:QHSD 4 \"=&r\"))\n+   (clobber (match_scratch:SI 5 \"=&r\"))]\n   \"<sync_predtab>\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(const_int 0)]\n   {\n-    return arm_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"sync_t2\"              \"3\")\n-   (set_attr \"sync_op\"              \"<sync_optab>\")\n-   (set_attr \"conds\" \"clob\")\n-   (set_attr \"predicable\" \"no\")])\n+    arm_split_atomic_op (NOT, operands[0], operands[4], operands[1],\n+\t\t\t operands[2], operands[3], operands[5]);\n+    DONE;\n+  })\n \n-(define_insn \"arm_sync_new_nand<mode>\"\n-  [(set (match_operand:SIDI 0 \"s_register_operand\" \"=&r\")\n-        (unspec_volatile:SIDI [(not:SIDI (and:SIDI\n-\t\t\t       (match_operand:SIDI 1 \"arm_sync_memory_operand\" \"+Q\")\n-\t\t\t       (match_operand:SIDI 2 \"s_register_operand\" \"r\")))\n-\t\t\t    ]\n-\t\t\t    VUNSPEC_SYNC_NEW_OP))\n+(define_insn_and_split \"atomic_<sync_optab>_fetch<mode>\"\n+  [(set (match_operand:QHSD 0 \"s_register_operand\" \"=&r\")\n+\t(syncop:QHSD\n+\t  (match_operand:QHSD 1 \"mem_noofs_operand\" \"+Ua\")\n+\t  (match_operand:QHSD 2 \"<atomic_op_operand>\" \"<atomic_op_str>\")))\n    (set (match_dup 1)\n-\t(unspec_volatile:SIDI [(match_dup 1) (match_dup 2)]\n-\t\t\t    VUNSPEC_SYNC_NEW_OP))\n+\t(unspec_volatile:QHSD\n+\t  [(match_dup 1) (match_dup 2)\n+\t   (match_operand:SI 3 \"const_int_operand\")]\t\t;; model\n+\t  VUNSPEC_ATOMIC_OP))\n    (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:SI 3 \"=&r\"))]\n+   (clobber (match_scratch:SI 4 \"=&r\"))]\n   \"<sync_predtab>\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(const_int 0)]\n   {\n-    return arm_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"sync_t2\"              \"3\")\n-   (set_attr \"sync_op\"              \"nand\")\n-   (set_attr \"conds\" \"clob\")\n-   (set_attr \"predicable\" \"no\")])\n+    arm_split_atomic_op (<CODE>, NULL, operands[0], operands[1],\n+\t\t\t operands[2], operands[3], operands[4]);\n+    DONE;\n+  })\n \n-(define_insn \"arm_sync_new_nand<mode>\"\n-  [(set (match_operand:SI 0 \"s_register_operand\" \"=&r\")\n-        (unspec_volatile:SI\n-\t  [(not:SI\n-\t     (and:SI\n-\t       (zero_extend:SI\n-\t\t (match_operand:NARROW 1 \"arm_sync_memory_operand\" \"+Q\"))\n-\t       (match_operand:SI 2 \"s_register_operand\" \"r\")))\n-\t  ] VUNSPEC_SYNC_NEW_OP))\n+(define_insn_and_split \"atomic_nand_fetch<mode>\"\n+  [(set (match_operand:QHSD 0 \"s_register_operand\" \"=&r\")\n+\t(not:QHSD\n+\t  (and:QHSD\n+\t    (match_operand:QHSD 1 \"mem_noofs_operand\" \"+Ua\")\n+\t    (match_operand:QHSD 2 \"<atomic_op_operand>\" \"<atomic_op_str>\"))))\n    (set (match_dup 1)\n-        (unspec_volatile:NARROW [(match_dup 1) (match_dup 2)]\n-\t\t\t\tVUNSPEC_SYNC_NEW_OP))\n+\t(unspec_volatile:QHSD\n+\t  [(match_dup 1) (match_dup 2)\n+\t   (match_operand:SI 3 \"const_int_operand\")]\t\t;; model\n+\t  VUNSPEC_ATOMIC_OP))\n    (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:SI 3 \"=&r\"))]\n+   (clobber (match_scratch:SI 4 \"=&r\"))]\n   \"<sync_predtab>\"\n+  \"#\"\n+  \"&& reload_completed\"\n+  [(const_int 0)]\n   {\n-    return arm_output_sync_insn (insn, operands);\n-  }\n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"0\")\n-   (set_attr \"sync_t2\"              \"3\")\n-   (set_attr \"sync_op\"              \"nand\")\n-   (set_attr \"conds\" \"clob\")\n-   (set_attr \"predicable\" \"no\")])\n+    arm_split_atomic_op (NOT, NULL, operands[0], operands[1],\n+\t\t\t operands[2], operands[3], operands[4]);\n+    DONE;\n+  })\n \n-(define_insn \"arm_sync_old_<sync_optab><mode>\"\n-  [(set (match_operand:SIDI 0 \"s_register_operand\" \"=&r\")\n-\t(unspec_volatile:SIDI [(syncop:SIDI\n-\t\t\t       (match_operand:SIDI 1 \"arm_sync_memory_operand\" \"+Q\")\n-\t\t\t       (match_operand:SIDI 2 \"s_register_operand\" \"r\"))\n-\t\t\t    ]\n-\t\t\t    VUNSPEC_SYNC_OLD_OP))\n-   (set (match_dup 1)\n-        (unspec_volatile:SIDI [(match_dup 1) (match_dup 2)]\n-\t\t\t      VUNSPEC_SYNC_OLD_OP))\n-   (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:SIDI 3 \"=&r\"))\n-   (clobber (match_scratch:SI 4 \"<sync_clobber>\"))]\n-  \"<sync_predtab>\"\n-  {\n-    return arm_output_sync_insn (insn, operands);\n-  } \n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"3\")\n-   (set_attr \"sync_t2\"              \"<sync_t2_reqd>\")\n-   (set_attr \"sync_op\"              \"<sync_optab>\")\n-   (set_attr \"conds\" \"clob\")\n-   (set_attr \"predicable\" \"no\")])\n+(define_insn \"arm_load_exclusive<mode>\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n+        (zero_extend:SI\n+\t  (unspec_volatile:NARROW\n+\t    [(match_operand:NARROW 1 \"mem_noofs_operand\" \"Ua\")]\n+\t    VUNSPEC_LL)))]\n+  \"TARGET_HAVE_LDREXBH\"\n+  \"ldrex<sync_sfx>%?\\t%0, %C1\"\n+  [(set_attr \"predicable\" \"yes\")])\n \n-(define_insn \"arm_sync_old_<sync_optab><mode>\"\n-  [(set (match_operand:SI 0 \"s_register_operand\" \"=&r\")\n-        (unspec_volatile:SI [(syncop:SI\n-\t\t\t       (zero_extend:SI\n-\t\t\t\t (match_operand:NARROW 1 \"arm_sync_memory_operand\" \"+Q\"))\n-\t\t\t       (match_operand:SI 2 \"s_register_operand\" \"r\"))\n-\t\t\t    ]\n-\t\t\t    VUNSPEC_SYNC_OLD_OP))\n-   (set (match_dup 1)\n-\t(unspec_volatile:NARROW [(match_dup 1) (match_dup 2)]\n-\t\t\t    VUNSPEC_SYNC_OLD_OP))\n-   (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:SI 3 \"=&r\"))\n-   (clobber (match_scratch:SI 4 \"<sync_clobber>\"))]\n-  \"<sync_predtab>\"\n-  {\n-    return arm_output_sync_insn (insn, operands);\n-  } \n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"3\")\n-   (set_attr \"sync_t2\"              \"<sync_t2_reqd>\")\n-   (set_attr \"sync_op\"              \"<sync_optab>\")\n-   (set_attr \"conds\" \t\t    \"clob\")\n-   (set_attr \"predicable\" \"no\")])\n+(define_insn \"arm_load_exclusivesi\"\n+  [(set (match_operand:SI 0 \"s_register_operand\" \"=r\")\n+\t(unspec_volatile:SI\n+\t  [(match_operand:SI 1 \"mem_noofs_operand\" \"Ua\")]\n+\t  VUNSPEC_LL))]\n+  \"TARGET_HAVE_LDREX\"\n+  \"ldrex%?\\t%0, %C1\"\n+  [(set_attr \"predicable\" \"yes\")])\n \n-(define_insn \"arm_sync_old_nand<mode>\"\n-  [(set (match_operand:SIDI 0 \"s_register_operand\" \"=&r\")\n-\t(unspec_volatile:SIDI [(not:SIDI (and:SIDI\n-\t\t\t       (match_operand:SIDI 1 \"arm_sync_memory_operand\" \"+Q\")\n-\t\t\t       (match_operand:SIDI 2 \"s_register_operand\" \"r\")))\n-\t\t\t    ]\n-\t\t\t    VUNSPEC_SYNC_OLD_OP))\n-   (set (match_dup 1)\n-        (unspec_volatile:SIDI [(match_dup 1) (match_dup 2)]\n-\t                    VUNSPEC_SYNC_OLD_OP))\n-   (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:SIDI 3 \"=&r\"))\n-   (clobber (match_scratch:SI 4 \"=&r\"))]\n-  \"<sync_predtab>\"\n+(define_insn \"arm_load_exclusivedi\"\n+  [(set (match_operand:DI 0 \"s_register_operand\" \"=r\")\n+\t(unspec_volatile:DI\n+\t  [(match_operand:DI 1 \"mem_noofs_operand\" \"Ua\")]\n+\t  VUNSPEC_LL))]\n+  \"TARGET_HAVE_LDREXD\"\n   {\n-    return arm_output_sync_insn (insn, operands);\n-  } \n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"3\")\n-   (set_attr \"sync_t2\"              \"4\")\n-   (set_attr \"sync_op\"              \"nand\")\n-   (set_attr \"conds\" \t\t    \"clob\")\n-   (set_attr \"predicable\" \"no\")])\n+    rtx target = operands[0];\n+    /* The restrictions on target registers in ARM mode are that the two\n+       registers are consecutive and the first one is even; Thumb is\n+       actually more flexible, but DI should give us this anyway.\n+       Note that the 1st register always gets the lowest word in memory.  */\n+    gcc_assert ((REGNO (target) & 1) == 0);\n+    operands[2] = gen_rtx_REG (SImode, REGNO (target) + 1);\n+    return \"ldrexd%?\\t%0, %2, %C1\";\n+  }\n+  [(set_attr \"predicable\" \"yes\")])\n \n-(define_insn \"arm_sync_old_nand<mode>\"\n+(define_insn \"arm_store_exclusive<mode>\"\n   [(set (match_operand:SI 0 \"s_register_operand\" \"=&r\")\n-\t(unspec_volatile:SI [(not:SI (and:SI\n-\t\t\t       (zero_extend:SI\n-\t\t\t\t (match_operand:NARROW 1 \"arm_sync_memory_operand\" \"+Q\"))\n-\t\t\t       (match_operand:SI 2 \"s_register_operand\" \"r\")))\n-\t\t\t    ]\n-\t\t\t    VUNSPEC_SYNC_OLD_OP))\n-   (set (match_dup 1)\n-\t(unspec_volatile:NARROW [(match_dup 1) (match_dup 2)]\n-\t\t\t    VUNSPEC_SYNC_OLD_OP))\n-   (clobber (reg:CC CC_REGNUM))\n-   (clobber (match_scratch:SI 3 \"=&r\"))\n-   (clobber (match_scratch:SI 4 \"=&r\"))]\n+\t(unspec_volatile:SI [(const_int 0)] VUNSPEC_SC))\n+   (set (match_operand:QHSD 1 \"mem_noofs_operand\" \"=Ua\")\n+\t(unspec_volatile:QHSD\n+\t  [(match_operand:QHSD 2 \"s_register_operand\" \"r\")]\n+\t  VUNSPEC_SC))]\n   \"<sync_predtab>\"\n   {\n-    return arm_output_sync_insn (insn, operands);\n-  } \n-  [(set_attr \"sync_result\"          \"0\")\n-   (set_attr \"sync_memory\"          \"1\")\n-   (set_attr \"sync_new_value\"       \"2\")\n-   (set_attr \"sync_t1\"              \"3\")\n-   (set_attr \"sync_t2\"              \"4\")\n-   (set_attr \"sync_op\"              \"nand\")\n-   (set_attr \"conds\"                \"clob\")\n-   (set_attr \"predicable\" \"no\")])\n-\n-(define_insn \"*memory_barrier\"\n-  [(set (match_operand:BLK 0 \"\" \"\")\n-\t(unspec:BLK [(match_dup 0)] UNSPEC_MEMORY_BARRIER))]\n-  \"TARGET_HAVE_MEMORY_BARRIER\"\n-  {\n-    return arm_output_memory_barrier (operands);\n+    if (<MODE>mode == DImode)\n+      {\n+\trtx value = operands[2];\n+\t/* The restrictions on target registers in ARM mode are that the two\n+\t   registers are consecutive and the first one is even; Thumb is\n+\t   actually more flexible, but DI should give us this anyway.\n+\t   Note that the 1st register always gets the lowest word in memory.  */\n+\tgcc_assert ((REGNO (value) & 1) == 0 || TARGET_THUMB2);\n+\toperands[3] = gen_rtx_REG (SImode, REGNO (value) + 1);\n+\treturn \"strexd%?\\t%0, %2, %3, %C1\";\n+      }\n+    return \"strex<sync_sfx>%?\\t%0, %2, %C1\";\n   }\n-  [(set_attr \"length\" \"4\")\n-   (set_attr \"conds\" \"unconditional\")\n-   (set_attr \"predicable\" \"no\")])\n-\n+  [(set_attr \"predicable\" \"yes\")])"}]}