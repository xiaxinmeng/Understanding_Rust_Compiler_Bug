{"sha": "3af82a61fa223fad00f5396b8f0ebb93cde646d1", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6M2FmODJhNjFmYTIyM2ZhZDAwZjUzOTZiOGYwZWJiOTNjZGU2NDZkMQ==", "commit": {"author": {"name": "Andreas Krebbel", "email": "krebbel@gcc.gnu.org", "date": "2015-05-19T17:32:07Z"}, "committer": {"name": "Andreas Krebbel", "email": "krebbel@gcc.gnu.org", "date": "2015-05-19T17:32:07Z"}, "message": "S/390 zvector builtin support.\n\nWith this patch GCC implements an Altivec style set of builtins to\nmake use of vector instructions in C/C++ code.  This is provided for\ncompatibility with the IBM XL compiler.\n\ngcc/\n\t* config.gcc: Add vecintrin.h to extra_headers.  Add s390-c.o to\n\tc_target_objs and cxx_target_objs.  Add t-s390 to tmake_file.\n\t* config/s390/s390-builtin-types.def: New file.\n\t* config/s390/s390-builtins.def: New file.\n\t* config/s390/s390-builtins.h: New file.\n\t* config/s390/s390-c.c: New file.\n\t* config/s390/s390-modes.def: Add modes CCVEQANY, CCVH,\n\tCCVHANY, CCVHU, CCVHUANY, CCVFHANY, CCVFHEANY.\n\t* config/s390/s390-protos.h (s390_expand_vec_compare_cc)\n\t(s390_cpu_cpp_builtins, s390_register_target_pragmas): Add\n\tprototypes.\n\t* config/s390/s390.c (s390-builtins.h, s390-builtins.def):\n\tInclude.\n\t(flags_builtin, flags_overloaded_builtin_var, s390_builtin_types)\n\t(s390_builtin_fn_types, s390_builtin_decls, code_for_builtin): New\n\tvariable definitions.\n\t(s390_const_operand_ok): New function.\n\t(s390_expand_builtin): Rewrite.\n\t(s390_init_builtins): New function.\n\t(s390_handle_vectorbool_attribute): New function.\n\t(s390_attribute_table): Add s390_vector_bool attribute.\n\t(s390_match_ccmode_set): Handle new cc modes CCVH, CCVHU.\n\t(s390_branch_condition_mask): Generate masks for new modes.\n\t(s390_expand_vec_compare_cc): New function.\n\t(s390_mangle_type): Add mangling for vector bool types.\n\t(enum s390_builtin): Remove.\n\t(s390_atomic_assign_expand_fenv): Rename constants for sfpc and\n\tefpc builtins.\n\t* config/s390/s390.h (TARGET_CPU_CPP_BUILTINS): Call\n\ts390_cpu_cpp_builtins.\n\t(REGISTER_TARGET_PRAGMAS): New macro.\n\t* config/s390/s390.md: Define more UNSPEC_VEC_* constants.\n\t(insn_cmp mode attribute): Add new CC modes.\n\t(s390_sfpc, s390_efpc): Rename patterns to sfpc and efpc.\n\t(lcbb): New pattern definition.\n\t* config/s390/s390intrin.h: Include vecintrin.h.\n\t* config/s390/t-s390: New file.\n\t* config/s390/vecintrin.h: New file.\n\t* config/s390/vector.md: Include vx-builtins.md.\n\t* config/s390/vx-builtins.md: New file.S/390 zvector builtin support.\n\nFrom-SVN: r223398", "tree": {"sha": "7d357e75cc6b0f15e4628fcdd9db4c4262d0f65f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/7d357e75cc6b0f15e4628fcdd9db4c4262d0f65f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/3af82a61fa223fad00f5396b8f0ebb93cde646d1", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3af82a61fa223fad00f5396b8f0ebb93cde646d1", "html_url": "https://github.com/Rust-GCC/gccrs/commit/3af82a61fa223fad00f5396b8f0ebb93cde646d1", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3af82a61fa223fad00f5396b8f0ebb93cde646d1/comments", "author": null, "committer": null, "parents": [{"sha": "6e5b5de88b7764a779cee87591186a01cab96f50", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6e5b5de88b7764a779cee87591186a01cab96f50", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6e5b5de88b7764a779cee87591186a01cab96f50"}], "stats": {"total": 7766, "additions": 7493, "deletions": 273}, "files": [{"sha": "aa0c389cd4f706655260ad82c21d8ed8e013221b", "filename": "gcc/config.gcc", "status": "modified", "additions": 16, "deletions": 8, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig.gcc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig.gcc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig.gcc?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1", "patch": "@@ -457,7 +457,7 @@ spu*-*-*)\n s390*-*-*)\n \tcpu_type=s390\n \textra_options=\"${extra_options} fused-madd.opt\"\n-\textra_headers=\"s390intrin.h htmintrin.h htmxlintrin.h\"\n+\textra_headers=\"s390intrin.h htmintrin.h htmxlintrin.h vecintrin.h\"\n \t;;\n # Note the 'l'; we need to be able to match e.g. \"shle\" or \"shl\".\n sh[123456789lbe]*-*-* | sh-*-*)\n@@ -2538,27 +2538,35 @@ rx-*-elf*)\n s390-*-linux*)\n \tdefault_gnu_indirect_function=yes\n \ttm_file=\"s390/s390.h dbxelf.h elfos.h gnu-user.h linux.h glibc-stdint.h s390/linux.h\"\n+\tc_target_objs=\"${c_target_objs} s390-c.o\"\n+\tcxx_target_objs=\"${cxx_target_objs} s390-c.o\"\n \tif test x$enable_targets = xall; then\n \t\ttmake_file=\"${tmake_file} s390/t-linux64\"\n \tfi\n+\ttmake_file=\"${tmake_file} s390/t-s390\"\n \t;;\n s390x-*-linux*)\n \tdefault_gnu_indirect_function=yes\n \ttm_file=\"s390/s390x.h s390/s390.h dbxelf.h elfos.h gnu-user.h linux.h glibc-stdint.h s390/linux.h\"\n \ttm_p_file=\"linux-protos.h s390/s390-protos.h\"\n+\tc_target_objs=\"${c_target_objs} s390-c.o\"\n+\tcxx_target_objs=\"${cxx_target_objs} s390-c.o\"\n \tmd_file=s390/s390.md\n \textra_modes=s390/s390-modes.def\n \tout_file=s390/s390.c\n-\ttmake_file=\"${tmake_file} s390/t-linux64\"\n+\ttmake_file=\"${tmake_file} s390/t-linux64 s390/t-s390\"\n \t;;\n s390x-ibm-tpf*)\n-        tm_file=\"s390/s390x.h s390/s390.h dbxelf.h elfos.h s390/tpf.h\"\n-        tm_p_file=s390/s390-protos.h\n-        md_file=s390/s390.md\n-        extra_modes=s390/s390-modes.def\n-        out_file=s390/s390.c\n-        thread_file='tpf'\n+\ttm_file=\"s390/s390x.h s390/s390.h dbxelf.h elfos.h s390/tpf.h\"\n+\ttm_p_file=s390/s390-protos.h\n+\tc_target_objs=\"${c_target_objs} s390-c.o\"\n+\tcxx_target_objs=\"${cxx_target_objs} s390-c.o\"\n+\tmd_file=s390/s390.md\n+\textra_modes=s390/s390-modes.def\n+\tout_file=s390/s390.c\n+\tthread_file='tpf'\n \textra_options=\"${extra_options} s390/tpf.opt\"\n+\ttmake_file=\"${tmake_file} s390/t-s390\"\n \t;;\n sh-*-elf* | sh[12346l]*-*-elf* | \\\n   sh-*-linux* | sh[2346lbe]*-*-linux* | \\"}, {"sha": "8c65ae6f8113594019e9789a3de9804da2859452", "filename": "gcc/config/s390/s390-builtin-types.def", "status": "added", "additions": 747, "deletions": 0, "changes": 747, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390-builtin-types.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390-builtin-types.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Fs390-builtin-types.def?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1", "patch": "@@ -0,0 +1,747 @@\n+/* Builtin type definitions for IBM S/390 and zSeries\n+   Copyright (C) 2015 Free Software Foundation, Inc.\n+\n+   Contributed by Andreas Krebbel (Andreas.Krebbel@de.ibm.com).\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify it\n+   under the terms of the GNU General Public License as published by\n+   the Free Software Foundation; either version 3, or (at your option)\n+   any later version.\n+\n+   GCC is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n+   or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public\n+   License for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with GCC; see the file COPYING3.  If not see\n+   <http://www.gnu.org/licenses/>.  */\n+\n+#define DEF_FN_TYPE_1(FN_TYPE, T1)\t\t\\\n+  DEF_FN_TYPE (FN_TYPE,\t\t\t\t\\\n+\t       s390_builtin_types[T1])\n+#define DEF_FN_TYPE_2(FN_TYPE, T1, T2)\t\t\\\n+  DEF_FN_TYPE (FN_TYPE,\t\t\t\t\\\n+\t       s390_builtin_types[T1],\t\t\\\n+\t       s390_builtin_types[T2])\n+#define DEF_FN_TYPE_3(FN_TYPE, T1, T2, T3)\t\\\n+  DEF_FN_TYPE (FN_TYPE,\t\t\t\t\\\n+\t       s390_builtin_types[T1],\t\t\\\n+\t       s390_builtin_types[T2],\t\t\\\n+\t       s390_builtin_types[T3])\n+#define DEF_FN_TYPE_4(FN_TYPE, T1, T2, T3, T4)\t\\\n+  DEF_FN_TYPE (FN_TYPE,\t\t\t\t\\\n+\t       s390_builtin_types[T1],\t\t\\\n+\t       s390_builtin_types[T2],\t\t\\\n+\t       s390_builtin_types[T3],\t\t\\\n+\t       s390_builtin_types[T4])\n+#define DEF_FN_TYPE_5(FN_TYPE, T1, T2, T3, T4, T5)\t\\\n+  DEF_FN_TYPE (FN_TYPE,\t\t\t\t\t\\\n+\t       s390_builtin_types[T1],\t\t\t\\\n+\t       s390_builtin_types[T2],\t\t\t\\\n+\t       s390_builtin_types[T3],\t\t\t\\\n+\t       s390_builtin_types[T4],\t\t\t\\\n+\t       s390_builtin_types[T5])\n+#define DEF_FN_TYPE_6(FN_TYPE, T1, T2, T3, T4, T5, T6)\t\\\n+  DEF_FN_TYPE (FN_TYPE,\t\t\t\t\t\\\n+\t       s390_builtin_types[T1],\t\t\t\\\n+\t       s390_builtin_types[T2],\t\t\t\\\n+\t       s390_builtin_types[T3],\t\t\t\\\n+\t       s390_builtin_types[T4],\t\t\t\\\n+\t       s390_builtin_types[T5],\t\t\t\\\n+\t       s390_builtin_types[T6])\n+\n+DEF_TYPE (BT_DBL, double_type_node, 0)\n+DEF_TYPE (BT_DBLCONST, double_type_node, 1)\n+DEF_TYPE (BT_FLTCONST, float_type_node, 1)\n+DEF_TYPE (BT_FLT, float_type_node, 0)\n+DEF_TYPE (BT_INTCONST, integer_type_node, 1)\n+DEF_TYPE (BT_INT, integer_type_node, 0)\n+DEF_TYPE (BT_LONG, long_integer_type_node, 0)\n+DEF_TYPE (BT_LONGLONGCONST, long_long_integer_type_node, 1)\n+DEF_TYPE (BT_LONGLONG, long_long_integer_type_node, 0)\n+DEF_TYPE (BT_UCHAR, unsigned_char_type_node, 0)\n+DEF_TYPE (BT_SCHAR, signed_char_type_node, 0)\n+DEF_TYPE (BT_SCHARCONST, signed_char_type_node, 1)\n+DEF_TYPE (BT_SHORTCONST, short_integer_type_node, 1)\n+DEF_TYPE (BT_SHORT, short_integer_type_node, 0)\n+DEF_TYPE (BT_UINT64, c_uint64_type_node, 0)\n+DEF_TYPE (BT_UINT, unsigned_type_node, 0)\n+DEF_TYPE (BT_UCHARCONST, unsigned_char_type_node, 1)\n+DEF_TYPE (BT_UINTCONST, unsigned_type_node, 1)\n+DEF_TYPE (BT_ULONGLONGCONST, long_long_unsigned_type_node, 1)\n+DEF_TYPE (BT_USHORTCONST, short_unsigned_type_node, 1)\n+DEF_TYPE (BT_VOIDCONST, void_type_node, 1)\n+DEF_TYPE (BT_VOID, void_type_node, 0)\n+DEF_TYPE (BT_ULONG, long_unsigned_type_node, 0)\n+DEF_TYPE (BT_ULONGLONG, long_long_unsigned_type_node, 0)\n+DEF_TYPE (BT_USHORT, short_unsigned_type_node, 0)\n+DEF_DISTINCT_TYPE (BT_BCHAR, BT_UCHAR)\n+DEF_DISTINCT_TYPE (BT_BINT, BT_UINT)\n+DEF_DISTINCT_TYPE (BT_BLONGLONG, BT_ULONGLONG)\n+DEF_DISTINCT_TYPE (BT_BSHORT, BT_USHORT)\n+DEF_POINTER_TYPE (BT_DBLPTR, BT_DBL)\n+DEF_POINTER_TYPE (BT_DBLCONSTPTR, BT_DBLCONST)\n+DEF_POINTER_TYPE (BT_FLTPTR, BT_FLT)\n+DEF_POINTER_TYPE (BT_FLTCONSTPTR, BT_FLTCONST)\n+DEF_POINTER_TYPE (BT_INTCONSTPTR, BT_INTCONST)\n+DEF_POINTER_TYPE (BT_INTPTR, BT_INT)\n+DEF_POINTER_TYPE (BT_LONGLONGCONSTPTR, BT_LONGLONGCONST)\n+DEF_POINTER_TYPE (BT_LONGLONGPTR, BT_LONGLONG)\n+DEF_POINTER_TYPE (BT_SCHARCONSTPTR, BT_SCHARCONST)\n+DEF_POINTER_TYPE (BT_SCHARPTR, BT_SCHAR)\n+DEF_POINTER_TYPE (BT_SHORTPTR, BT_SHORT)\n+DEF_POINTER_TYPE (BT_SHORTCONSTPTR, BT_SHORTCONST)\n+DEF_POINTER_TYPE (BT_UCHARPTR, BT_UCHAR)\n+DEF_POINTER_TYPE (BT_UCHARCONSTPTR, BT_UCHARCONST)\n+DEF_POINTER_TYPE (BT_UINTPTR, BT_UINT)\n+DEF_POINTER_TYPE (BT_UINTCONSTPTR, BT_UINTCONST)\n+DEF_POINTER_TYPE (BT_UINT64PTR, BT_UINT64)\n+DEF_POINTER_TYPE (BT_ULONGLONGPTR, BT_ULONGLONG)\n+DEF_POINTER_TYPE (BT_ULONGLONGCONSTPTR, BT_ULONGLONGCONST)\n+DEF_POINTER_TYPE (BT_USHORTCONSTPTR, BT_USHORTCONST)\n+DEF_POINTER_TYPE (BT_USHORTPTR, BT_USHORT)\n+DEF_POINTER_TYPE (BT_VOIDPTR, BT_VOID)\n+DEF_POINTER_TYPE (BT_VOIDCONSTPTR, BT_VOIDCONST)\n+DEF_VECTOR_TYPE (BT_V16QI, BT_SCHAR, 16)\n+DEF_VECTOR_TYPE (BT_V2DF, BT_DBL, 2)\n+DEF_VECTOR_TYPE (BT_V2DI, BT_LONGLONG, 2)\n+DEF_VECTOR_TYPE (BT_V4SI, BT_INT, 4)\n+DEF_VECTOR_TYPE (BT_V8HI, BT_SHORT, 8)\n+DEF_VECTOR_TYPE (BT_UV16QI, BT_UCHAR, 16)\n+DEF_VECTOR_TYPE (BT_UV2DI, BT_ULONGLONG, 2)\n+DEF_VECTOR_TYPE (BT_UV4SI, BT_UINT, 4)\n+DEF_VECTOR_TYPE (BT_UV8HI, BT_USHORT, 8)\n+DEF_OPAQUE_VECTOR_TYPE (BT_OV2DI, BT_LONGLONG, 2)\n+DEF_OPAQUE_VECTOR_TYPE (BT_OV4SI, BT_INT, 4)\n+DEF_OPAQUE_VECTOR_TYPE (BT_OUV4SI, BT_UINT, 4)\n+DEF_OPAQUE_VECTOR_TYPE (BT_BV16QI, BT_BCHAR, 16)\n+DEF_OPAQUE_VECTOR_TYPE (BT_BV2DI, BT_BLONGLONG, 2)\n+DEF_OPAQUE_VECTOR_TYPE (BT_BV4SI, BT_BINT, 4)\n+DEF_OPAQUE_VECTOR_TYPE (BT_BV8HI, BT_BSHORT, 8)\n+DEF_FN_TYPE_1 (BT_FN_UINT, BT_UINT)\n+DEF_FN_TYPE_1 (BT_FN_INT, BT_INT)\n+DEF_FN_TYPE_2 (BT_FN_VOID_UINT, BT_VOID, BT_UINT)\n+DEF_FN_TYPE_2 (BT_FN_VOID_INT, BT_VOID, BT_INT)\n+DEF_FN_TYPE_2 (BT_FN_INT_INT, BT_INT, BT_INT)\n+DEF_FN_TYPE_2 (BT_FN_INT_VOIDPTR, BT_INT, BT_VOIDPTR)\n+DEF_FN_TYPE_2 (BT_FN_UV16QI_UCHARCONSTPTR, BT_UV16QI, BT_UCHARCONSTPTR)\n+DEF_FN_TYPE_2 (BT_FN_UV16QI_USHORT, BT_UV16QI, BT_USHORT)\n+DEF_FN_TYPE_2 (BT_FN_UV16QI_UCHAR, BT_UV16QI, BT_UCHAR)\n+DEF_FN_TYPE_2 (BT_FN_UV16QI_UV16QI, BT_UV16QI, BT_UV16QI)\n+DEF_FN_TYPE_2 (BT_FN_UV2DI_ULONGLONG, BT_UV2DI, BT_ULONGLONG)\n+DEF_FN_TYPE_2 (BT_FN_UV2DI_ULONGLONGCONSTPTR, BT_UV2DI, BT_ULONGLONGCONSTPTR)\n+DEF_FN_TYPE_2 (BT_FN_UV2DI_UV2DI, BT_UV2DI, BT_UV2DI)\n+DEF_FN_TYPE_2 (BT_FN_UV2DI_UV4SI, BT_UV2DI, BT_UV4SI)\n+DEF_FN_TYPE_2 (BT_FN_OV4SI_INTCONSTPTR, BT_OV4SI, BT_INTCONSTPTR)\n+DEF_FN_TYPE_2 (BT_FN_UV4SI_UV4SI, BT_UV4SI, BT_UV4SI)\n+DEF_FN_TYPE_2 (BT_FN_OV4SI_INT, BT_OV4SI, BT_INT)\n+DEF_FN_TYPE_2 (BT_FN_OV4SI_OV4SI, BT_OV4SI, BT_OV4SI)\n+DEF_FN_TYPE_2 (BT_FN_UV4SI_UINTCONSTPTR, BT_UV4SI, BT_UINTCONSTPTR)\n+DEF_FN_TYPE_2 (BT_FN_UV4SI_UV8HI, BT_UV4SI, BT_UV8HI)\n+DEF_FN_TYPE_2 (BT_FN_UV4SI_UINT, BT_UV4SI, BT_UINT)\n+DEF_FN_TYPE_2 (BT_FN_UV8HI_USHORT, BT_UV8HI, BT_USHORT)\n+DEF_FN_TYPE_2 (BT_FN_UV8HI_UV16QI, BT_UV8HI, BT_UV16QI)\n+DEF_FN_TYPE_2 (BT_FN_UV8HI_UV8HI, BT_UV8HI, BT_UV8HI)\n+DEF_FN_TYPE_2 (BT_FN_UV8HI_USHORTCONSTPTR, BT_UV8HI, BT_USHORTCONSTPTR)\n+DEF_FN_TYPE_2 (BT_FN_V16QI_UCHAR, BT_V16QI, BT_UCHAR)\n+DEF_FN_TYPE_2 (BT_FN_V16QI_V16QI, BT_V16QI, BT_V16QI)\n+DEF_FN_TYPE_2 (BT_FN_V2DI_V16QI, BT_V2DI, BT_V16QI)\n+DEF_FN_TYPE_2 (BT_FN_V2DI_V2DI, BT_V2DI, BT_V2DI)\n+DEF_FN_TYPE_2 (BT_FN_V2DI_SHORT, BT_V2DI, BT_SHORT)\n+DEF_FN_TYPE_2 (BT_FN_V2DF_V2DF, BT_V2DF, BT_V2DF)\n+DEF_FN_TYPE_2 (BT_FN_V2DI_V8HI, BT_V2DI, BT_V8HI)\n+DEF_FN_TYPE_2 (BT_FN_V2DF_FLTCONSTPTR, BT_V2DF, BT_FLTCONSTPTR)\n+DEF_FN_TYPE_2 (BT_FN_V2DI_V4SI, BT_V2DI, BT_V4SI)\n+DEF_FN_TYPE_2 (BT_FN_V2DF_DBL, BT_V2DF, BT_DBL)\n+DEF_FN_TYPE_2 (BT_FN_V4SI_V8HI, BT_V4SI, BT_V8HI)\n+DEF_FN_TYPE_2 (BT_FN_V4SI_V4SI, BT_V4SI, BT_V4SI)\n+DEF_FN_TYPE_2 (BT_FN_V4SI_SHORT, BT_V4SI, BT_SHORT)\n+DEF_FN_TYPE_2 (BT_FN_V8HI_V16QI, BT_V8HI, BT_V16QI)\n+DEF_FN_TYPE_2 (BT_FN_V8HI_V8HI, BT_V8HI, BT_V8HI)\n+DEF_FN_TYPE_2 (BT_FN_V8HI_SHORT, BT_V8HI, BT_SHORT)\n+DEF_FN_TYPE_3 (BT_FN_INT_V2DI_V2DI, BT_INT, BT_V2DI, BT_V2DI)\n+DEF_FN_TYPE_3 (BT_FN_INT_OV4SI_OV4SI, BT_INT, BT_OV4SI, BT_OV4SI)\n+DEF_FN_TYPE_3 (BT_FN_INT_V2DF_V2DF, BT_INT, BT_V2DF, BT_V2DF)\n+DEF_FN_TYPE_3 (BT_FN_USHORT_UV8HI_INT, BT_USHORT, BT_UV8HI, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_INT_UV2DI_UV2DI, BT_INT, BT_UV2DI, BT_UV2DI)\n+DEF_FN_TYPE_3 (BT_FN_ULONGLONG_UV2DI_INT, BT_ULONGLONG, BT_UV2DI, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_INT_UV4SI_UV4SI, BT_INT, BT_UV4SI, BT_UV4SI)\n+DEF_FN_TYPE_3 (BT_FN_UCHAR_UV16QI_INT, BT_UCHAR, BT_UV16QI, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_INT_UV8HI_UV8HI, BT_INT, BT_UV8HI, BT_UV8HI)\n+DEF_FN_TYPE_3 (BT_FN_INT_V4SI_V4SI, BT_INT, BT_V4SI, BT_V4SI)\n+DEF_FN_TYPE_3 (BT_FN_INT_UV16QI_UV16QI, BT_INT, BT_UV16QI, BT_UV16QI)\n+DEF_FN_TYPE_3 (BT_FN_INT_V16QI_V16QI, BT_INT, BT_V16QI, BT_V16QI)\n+DEF_FN_TYPE_3 (BT_FN_INT_VOIDPTR_INT, BT_INT, BT_VOIDPTR, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_DBL_V2DF_INT, BT_DBL, BT_V2DF, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_VOID_UINT64PTR_UINT64, BT_VOID, BT_UINT64PTR, BT_UINT64)\n+DEF_FN_TYPE_3 (BT_FN_INT_V8HI_V8HI, BT_INT, BT_V8HI, BT_V8HI)\n+DEF_FN_TYPE_3 (BT_FN_UINT_VOIDCONSTPTR_INT, BT_UINT, BT_VOIDCONSTPTR, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_INT_OV4SI_INT, BT_INT, BT_OV4SI, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_VOID_V2DF_FLTPTR, BT_VOID, BT_V2DF, BT_FLTPTR)\n+DEF_FN_TYPE_3 (BT_FN_UINT_UV4SI_INT, BT_UINT, BT_UV4SI, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_UV16QI_UV8HI_UV8HI, BT_UV16QI, BT_UV8HI, BT_UV8HI)\n+DEF_FN_TYPE_3 (BT_FN_UV16QI_UCHARCONSTPTR_USHORT, BT_UV16QI, BT_UCHARCONSTPTR, BT_USHORT)\n+DEF_FN_TYPE_3 (BT_FN_UV16QI_UV16QI_UV16QI, BT_UV16QI, BT_UV16QI, BT_UV16QI)\n+DEF_FN_TYPE_3 (BT_FN_UV16QI_UV16QI_UCHAR, BT_UV16QI, BT_UV16QI, BT_UCHAR)\n+DEF_FN_TYPE_3 (BT_FN_UV16QI_UV4SI_UV4SI, BT_UV16QI, BT_UV4SI, BT_UV4SI)\n+DEF_FN_TYPE_3 (BT_FN_UV16QI_UCHAR_UCHAR, BT_UV16QI, BT_UCHAR, BT_UCHAR)\n+DEF_FN_TYPE_3 (BT_FN_UV16QI_UCHAR_INT, BT_UV16QI, BT_UCHAR, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_UV16QI_UV2DI_UV2DI, BT_UV16QI, BT_UV2DI, BT_UV2DI)\n+DEF_FN_TYPE_3 (BT_FN_UV16QI_UV16QI_UINT, BT_UV16QI, BT_UV16QI, BT_UINT)\n+DEF_FN_TYPE_3 (BT_FN_UV16QI_UV16QI_INTPTR, BT_UV16QI, BT_UV16QI, BT_INTPTR)\n+DEF_FN_TYPE_3 (BT_FN_UV2DI_V2DF_INT, BT_UV2DI, BT_V2DF, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_UV2DI_UV2DI_UINT, BT_UV2DI, BT_UV2DI, BT_UINT)\n+DEF_FN_TYPE_3 (BT_FN_OV2DI_LONGLONG_LONGLONG, BT_OV2DI, BT_LONGLONG, BT_LONGLONG)\n+DEF_FN_TYPE_3 (BT_FN_UV2DI_UV2DI_UV2DI, BT_UV2DI, BT_UV2DI, BT_UV2DI)\n+DEF_FN_TYPE_3 (BT_FN_UV2DI_UV2DI_UCHAR, BT_UV2DI, BT_UV2DI, BT_UCHAR)\n+DEF_FN_TYPE_3 (BT_FN_UV2DI_ULONGLONG_INT, BT_UV2DI, BT_ULONGLONG, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_UV2DI_UV8HI_UV8HI, BT_UV2DI, BT_UV8HI, BT_UV8HI)\n+DEF_FN_TYPE_3 (BT_FN_UV2DI_UCHAR_UCHAR, BT_UV2DI, BT_UCHAR, BT_UCHAR)\n+DEF_FN_TYPE_3 (BT_FN_UV2DI_UV4SI_UV4SI, BT_UV2DI, BT_UV4SI, BT_UV4SI)\n+DEF_FN_TYPE_3 (BT_FN_OV4SI_INT_INT, BT_OV4SI, BT_INT, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_UV4SI_UINT_INT, BT_UV4SI, BT_UINT, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_UV4SI_UV4SI_UV4SI, BT_UV4SI, BT_UV4SI, BT_UV4SI)\n+DEF_FN_TYPE_3 (BT_FN_UV4SI_UV4SI_UCHAR, BT_UV4SI, BT_UV4SI, BT_UCHAR)\n+DEF_FN_TYPE_3 (BT_FN_UV4SI_UV8HI_UV8HI, BT_UV4SI, BT_UV8HI, BT_UV8HI)\n+DEF_FN_TYPE_3 (BT_FN_OV4SI_OV4SI_UCHAR, BT_OV4SI, BT_OV4SI, BT_UCHAR)\n+DEF_FN_TYPE_3 (BT_FN_UV4SI_UV4SI_UINT, BT_UV4SI, BT_UV4SI, BT_UINT)\n+DEF_FN_TYPE_3 (BT_FN_UV4SI_UV16QI_UV16QI, BT_UV4SI, BT_UV16QI, BT_UV16QI)\n+DEF_FN_TYPE_3 (BT_FN_OV4SI_INTCONSTPTR_INT, BT_OV4SI, BT_INTCONSTPTR, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_OV4SI_OV4SI_INTPTR, BT_OV4SI, BT_OV4SI, BT_INTPTR)\n+DEF_FN_TYPE_3 (BT_FN_UV4SI_UV2DI_UV2DI, BT_UV4SI, BT_UV2DI, BT_UV2DI)\n+DEF_FN_TYPE_3 (BT_FN_OV4SI_INTCONSTPTR_UINT, BT_OV4SI, BT_INTCONSTPTR, BT_UINT)\n+DEF_FN_TYPE_3 (BT_FN_OV4SI_OV4SI_ULONG, BT_OV4SI, BT_OV4SI, BT_ULONG)\n+DEF_FN_TYPE_3 (BT_FN_OV4SI_OV4SI_OV4SI, BT_OV4SI, BT_OV4SI, BT_OV4SI)\n+DEF_FN_TYPE_3 (BT_FN_UV4SI_UCHAR_UCHAR, BT_UV4SI, BT_UCHAR, BT_UCHAR)\n+DEF_FN_TYPE_3 (BT_FN_UV4SI_UV4SI_INTPTR, BT_UV4SI, BT_UV4SI, BT_INTPTR)\n+DEF_FN_TYPE_3 (BT_FN_UV8HI_UV4SI_UV4SI, BT_UV8HI, BT_UV4SI, BT_UV4SI)\n+DEF_FN_TYPE_3 (BT_FN_UV8HI_UV16QI_UV16QI, BT_UV8HI, BT_UV16QI, BT_UV16QI)\n+DEF_FN_TYPE_3 (BT_FN_UV8HI_UCHAR_UCHAR, BT_UV8HI, BT_UCHAR, BT_UCHAR)\n+DEF_FN_TYPE_3 (BT_FN_UV8HI_UV8HI_UV8HI, BT_UV8HI, BT_UV8HI, BT_UV8HI)\n+DEF_FN_TYPE_3 (BT_FN_UV8HI_UV8HI_UCHAR, BT_UV8HI, BT_UV8HI, BT_UCHAR)\n+DEF_FN_TYPE_3 (BT_FN_UV8HI_UV8HI_INTPTR, BT_UV8HI, BT_UV8HI, BT_INTPTR)\n+DEF_FN_TYPE_3 (BT_FN_UV8HI_UV8HI_UINT, BT_UV8HI, BT_UV8HI, BT_UINT)\n+DEF_FN_TYPE_3 (BT_FN_UV8HI_USHORT_INT, BT_UV8HI, BT_USHORT, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_V16QI_UV16QI_UV16QI, BT_V16QI, BT_UV16QI, BT_UV16QI)\n+DEF_FN_TYPE_3 (BT_FN_V16QI_UINT_VOIDCONSTPTR, BT_V16QI, BT_UINT, BT_VOIDCONSTPTR)\n+DEF_FN_TYPE_3 (BT_FN_V16QI_V8HI_V8HI, BT_V16QI, BT_V8HI, BT_V8HI)\n+DEF_FN_TYPE_3 (BT_FN_V16QI_BV16QI_V16QI, BT_V16QI, BT_BV16QI, BT_V16QI)\n+DEF_FN_TYPE_3 (BT_FN_V16QI_V16QI_V16QI, BT_V16QI, BT_V16QI, BT_V16QI)\n+DEF_FN_TYPE_3 (BT_FN_V2DI_V2DF_INT, BT_V2DI, BT_V2DF, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_V2DI_V2DF_V2DF, BT_V2DI, BT_V2DF, BT_V2DF)\n+DEF_FN_TYPE_3 (BT_FN_V2DI_V4SI_V4SI, BT_V2DI, BT_V4SI, BT_V4SI)\n+DEF_FN_TYPE_3 (BT_FN_V2DI_UV2DI_UV2DI, BT_V2DI, BT_UV2DI, BT_UV2DI)\n+DEF_FN_TYPE_3 (BT_FN_V2DI_V2DI_V2DI, BT_V2DI, BT_V2DI, BT_V2DI)\n+DEF_FN_TYPE_3 (BT_FN_V2DF_V2DI_INT, BT_V2DF, BT_V2DI, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_V2DF_UV2DI_INT, BT_V2DF, BT_UV2DI, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_V2DF_V2DF_V2DF, BT_V2DF, BT_V2DF, BT_V2DF)\n+DEF_FN_TYPE_3 (BT_FN_V2DF_DBL_INT, BT_V2DF, BT_DBL, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_V2DI_BV2DI_V2DI, BT_V2DI, BT_BV2DI, BT_V2DI)\n+DEF_FN_TYPE_3 (BT_FN_V2DF_UV4SI_INT, BT_V2DF, BT_UV4SI, BT_INT)\n+DEF_FN_TYPE_3 (BT_FN_V4SI_V4SI_V4SI, BT_V4SI, BT_V4SI, BT_V4SI)\n+DEF_FN_TYPE_3 (BT_FN_V4SI_V8HI_V8HI, BT_V4SI, BT_V8HI, BT_V8HI)\n+DEF_FN_TYPE_3 (BT_FN_V4SI_INT_VOIDPTR, BT_V4SI, BT_INT, BT_VOIDPTR)\n+DEF_FN_TYPE_3 (BT_FN_V4SI_V2DI_V2DI, BT_V4SI, BT_V2DI, BT_V2DI)\n+DEF_FN_TYPE_3 (BT_FN_V4SI_UV4SI_UV4SI, BT_V4SI, BT_UV4SI, BT_UV4SI)\n+DEF_FN_TYPE_3 (BT_FN_V4SI_BV4SI_V4SI, BT_V4SI, BT_BV4SI, BT_V4SI)\n+DEF_FN_TYPE_3 (BT_FN_V8HI_BV8HI_V8HI, BT_V8HI, BT_BV8HI, BT_V8HI)\n+DEF_FN_TYPE_3 (BT_FN_V8HI_V16QI_V16QI, BT_V8HI, BT_V16QI, BT_V16QI)\n+DEF_FN_TYPE_3 (BT_FN_V8HI_V4SI_V4SI, BT_V8HI, BT_V4SI, BT_V4SI)\n+DEF_FN_TYPE_3 (BT_FN_V8HI_UV8HI_UV8HI, BT_V8HI, BT_UV8HI, BT_UV8HI)\n+DEF_FN_TYPE_3 (BT_FN_V8HI_V8HI_V8HI, BT_V8HI, BT_V8HI, BT_V8HI)\n+DEF_FN_TYPE_4 (BT_FN_VOID_OV4SI_VOIDPTR_UINT, BT_VOID, BT_OV4SI, BT_VOIDPTR, BT_UINT)\n+DEF_FN_TYPE_4 (BT_FN_INT_OV4SI_OV4SI_INTPTR, BT_INT, BT_OV4SI, BT_OV4SI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_VOID_V16QI_UINT_VOIDPTR, BT_VOID, BT_V16QI, BT_UINT, BT_VOIDPTR)\n+DEF_FN_TYPE_4 (BT_FN_VOID_OV4SI_INT_VOIDPTR, BT_VOID, BT_OV4SI, BT_INT, BT_VOIDPTR)\n+DEF_FN_TYPE_4 (BT_FN_UV16QI_UV16QI_UV16QI_INTPTR, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_UV16QI_UV16QI_UV16QI_INT, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_INT)\n+DEF_FN_TYPE_4 (BT_FN_UV16QI_UV16QI_UCHAR_INT, BT_UV16QI, BT_UV16QI, BT_UCHAR, BT_INT)\n+DEF_FN_TYPE_4 (BT_FN_UV16QI_UV16QI_UV16QI_UV16QI, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_UV16QI)\n+DEF_FN_TYPE_4 (BT_FN_UV16QI_UV8HI_UV8HI_INTPTR, BT_UV16QI, BT_UV8HI, BT_UV8HI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_UV16QI_UV2DI_UV2DI_UV16QI, BT_UV16QI, BT_UV2DI, BT_UV2DI, BT_UV16QI)\n+DEF_FN_TYPE_4 (BT_FN_UV2DI_UV2DI_UV2DI_INT, BT_UV2DI, BT_UV2DI, BT_UV2DI, BT_INT)\n+DEF_FN_TYPE_4 (BT_FN_UV2DI_UV4SI_UV4SI_UV2DI, BT_UV2DI, BT_UV4SI, BT_UV4SI, BT_UV2DI)\n+DEF_FN_TYPE_4 (BT_FN_UV2DI_UV2DI_ULONGLONG_INT, BT_UV2DI, BT_UV2DI, BT_ULONGLONG, BT_INT)\n+DEF_FN_TYPE_4 (BT_FN_UV4SI_UV2DI_UV2DI_INTPTR, BT_UV4SI, BT_UV2DI, BT_UV2DI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_UV4SI_UV4SI_UV4SI_UV4SI, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_UV4SI)\n+DEF_FN_TYPE_4 (BT_FN_OV4SI_OV4SI_OV4SI_INTPTR, BT_OV4SI, BT_OV4SI, BT_OV4SI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_OV4SI_OV4SI_OV4SI_INT, BT_OV4SI, BT_OV4SI, BT_OV4SI, BT_INT)\n+DEF_FN_TYPE_4 (BT_FN_UV4SI_UV4SI_UV4SI_INTPTR, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_OV4SI_INT_OV4SI_INT, BT_OV4SI, BT_INT, BT_OV4SI, BT_INT)\n+DEF_FN_TYPE_4 (BT_FN_UV4SI_UV4SI_UV4SI_INT, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_INT)\n+DEF_FN_TYPE_4 (BT_FN_OV4SI_OV4SI_OV4SI_ULONGLONG, BT_OV4SI, BT_OV4SI, BT_OV4SI, BT_ULONGLONG)\n+DEF_FN_TYPE_4 (BT_FN_OV4SI_OV4SI_OV4SI_OV4SI, BT_OV4SI, BT_OV4SI, BT_OV4SI, BT_OV4SI)\n+DEF_FN_TYPE_4 (BT_FN_UV4SI_UV8HI_UV8HI_UV4SI, BT_UV4SI, BT_UV8HI, BT_UV8HI, BT_UV4SI)\n+DEF_FN_TYPE_4 (BT_FN_UV4SI_UV4SI_UINT_INT, BT_UV4SI, BT_UV4SI, BT_UINT, BT_INT)\n+DEF_FN_TYPE_4 (BT_FN_OV4SI_OV4SI_OV4SI_UCHAR, BT_OV4SI, BT_OV4SI, BT_OV4SI, BT_UCHAR)\n+DEF_FN_TYPE_4 (BT_FN_UV8HI_UV4SI_UV4SI_INTPTR, BT_UV8HI, BT_UV4SI, BT_UV4SI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_UV8HI_UV8HI_UV8HI_INT, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_INT)\n+DEF_FN_TYPE_4 (BT_FN_UV8HI_UV8HI_UV8HI_UV8HI, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_UV8HI)\n+DEF_FN_TYPE_4 (BT_FN_UV8HI_UV16QI_UV16QI_UV8HI, BT_UV8HI, BT_UV16QI, BT_UV16QI, BT_UV8HI)\n+DEF_FN_TYPE_4 (BT_FN_UV8HI_UV8HI_UV8HI_INTPTR, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_UV8HI_UV8HI_USHORT_INT, BT_UV8HI, BT_UV8HI, BT_USHORT, BT_INT)\n+DEF_FN_TYPE_4 (BT_FN_V16QI_V8HI_V8HI_INTPTR, BT_V16QI, BT_V8HI, BT_V8HI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_V16QI_V16QI_V16QI_INTPTR, BT_V16QI, BT_V16QI, BT_V16QI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_V16QI_UV16QI_UV16QI_INTPTR, BT_V16QI, BT_UV16QI, BT_UV16QI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_V16QI_V16QI_V16QI_V16QI, BT_V16QI, BT_V16QI, BT_V16QI, BT_V16QI)\n+DEF_FN_TYPE_4 (BT_FN_V2DI_V2DF_INT_INTPTR, BT_V2DI, BT_V2DF, BT_INT, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_V2DI_V2DI_V2DI_INTPTR, BT_V2DI, BT_V2DI, BT_V2DI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_V2DF_V2DF_DBL_INT, BT_V2DF, BT_V2DF, BT_DBL, BT_INT)\n+DEF_FN_TYPE_4 (BT_FN_V2DF_V2DF_UCHAR_UCHAR, BT_V2DF, BT_V2DF, BT_UCHAR, BT_UCHAR)\n+DEF_FN_TYPE_4 (BT_FN_V2DI_V2DF_V2DF_INTPTR, BT_V2DI, BT_V2DF, BT_V2DF, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_V2DI_V4SI_V4SI_V2DI, BT_V2DI, BT_V4SI, BT_V4SI, BT_V2DI)\n+DEF_FN_TYPE_4 (BT_FN_V2DF_V2DF_V2DF_V2DF, BT_V2DF, BT_V2DF, BT_V2DF, BT_V2DF)\n+DEF_FN_TYPE_4 (BT_FN_V2DI_UV2DI_UV2DI_INTPTR, BT_V2DI, BT_UV2DI, BT_UV2DI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_V4SI_V8HI_V8HI_V4SI, BT_V4SI, BT_V8HI, BT_V8HI, BT_V4SI)\n+DEF_FN_TYPE_4 (BT_FN_V4SI_UV4SI_UV4SI_INTPTR, BT_V4SI, BT_UV4SI, BT_UV4SI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_V4SI_V2DI_V2DI_INTPTR, BT_V4SI, BT_V2DI, BT_V2DI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_V4SI_V4SI_V4SI_INTPTR, BT_V4SI, BT_V4SI, BT_V4SI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_V4SI_V4SI_V4SI_V4SI, BT_V4SI, BT_V4SI, BT_V4SI, BT_V4SI)\n+DEF_FN_TYPE_4 (BT_FN_V8HI_V8HI_V8HI_V8HI, BT_V8HI, BT_V8HI, BT_V8HI, BT_V8HI)\n+DEF_FN_TYPE_4 (BT_FN_V8HI_UV8HI_UV8HI_INTPTR, BT_V8HI, BT_UV8HI, BT_UV8HI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_V8HI_V16QI_V16QI_V8HI, BT_V8HI, BT_V16QI, BT_V16QI, BT_V8HI)\n+DEF_FN_TYPE_4 (BT_FN_V8HI_V8HI_V8HI_INTPTR, BT_V8HI, BT_V8HI, BT_V8HI, BT_INTPTR)\n+DEF_FN_TYPE_4 (BT_FN_V8HI_V4SI_V4SI_INTPTR, BT_V8HI, BT_V4SI, BT_V4SI, BT_INTPTR)\n+DEF_FN_TYPE_5 (BT_FN_VOID_UV4SI_UV4SI_UINTPTR_ULONGLONG, BT_VOID, BT_UV4SI, BT_UV4SI, BT_UINTPTR, BT_ULONGLONG)\n+DEF_FN_TYPE_5 (BT_FN_VOID_UV2DI_UV2DI_ULONGLONGPTR_ULONGLONG, BT_VOID, BT_UV2DI, BT_UV2DI, BT_ULONGLONGPTR, BT_ULONGLONG)\n+DEF_FN_TYPE_5 (BT_FN_VOID_V4SI_V4SI_INTPTR_ULONGLONG, BT_VOID, BT_V4SI, BT_V4SI, BT_INTPTR, BT_ULONGLONG)\n+DEF_FN_TYPE_5 (BT_FN_UV16QI_UV16QI_UV16QI_INT_INTPTR, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_INT, BT_INTPTR)\n+DEF_FN_TYPE_5 (BT_FN_UV16QI_UV16QI_UV16QI_UV16QI_INT, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_INT)\n+DEF_FN_TYPE_5 (BT_FN_UV2DI_UV2DI_UV2DI_UV2DI_INT, BT_UV2DI, BT_UV2DI, BT_UV2DI, BT_UV2DI, BT_INT)\n+DEF_FN_TYPE_5 (BT_FN_UV2DI_UV2DI_UV2DI_ULONGLONGCONSTPTR_UCHAR, BT_UV2DI, BT_UV2DI, BT_UV2DI, BT_ULONGLONGCONSTPTR, BT_UCHAR)\n+DEF_FN_TYPE_5 (BT_FN_UV4SI_UV4SI_UV4SI_UV4SI_INT, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_INT)\n+DEF_FN_TYPE_5 (BT_FN_UV4SI_UV4SI_UV4SI_INT_INTPTR, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_INT, BT_INTPTR)\n+DEF_FN_TYPE_5 (BT_FN_OV4SI_OV4SI_OV4SI_OV4SI_INTPTR, BT_OV4SI, BT_OV4SI, BT_OV4SI, BT_OV4SI, BT_INTPTR)\n+DEF_FN_TYPE_5 (BT_FN_OV4SI_OV4SI_OUV4SI_INTCONSTPTR_UCHAR, BT_OV4SI, BT_OV4SI, BT_OUV4SI, BT_INTCONSTPTR, BT_UCHAR)\n+DEF_FN_TYPE_5 (BT_FN_UV4SI_UV4SI_UV4SI_UINTCONSTPTR_UCHAR, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_UINTCONSTPTR, BT_UCHAR)\n+DEF_FN_TYPE_5 (BT_FN_UV8HI_UV8HI_UV8HI_UV8HI_INT, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_INT)\n+DEF_FN_TYPE_5 (BT_FN_UV8HI_UV8HI_UV8HI_INT_INTPTR, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_INT, BT_INTPTR)\n+DEF_FN_TYPE_6 (BT_FN_UV16QI_UV16QI_UV16QI_UV16QI_INT_INTPTR, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_INT, BT_INTPTR)\n+DEF_FN_TYPE_6 (BT_FN_UV4SI_UV4SI_UV4SI_UV4SI_INT_INTPTR, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_INT, BT_INTPTR)\n+DEF_FN_TYPE_6 (BT_FN_UV8HI_UV8HI_UV8HI_UV8HI_INT_INTPTR, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_INT, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_BV16QI_BV16QI, BT_BV16QI, BT_BV16QI)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI, BT_UV16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_UV16QI_UCHAR, BT_UV16QI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_UV16QI_V16QI, BT_UV16QI, BT_V16QI)\n+DEF_OV_TYPE (BT_OV_UV16QI_UCHARCONSTPTR, BT_UV16QI, BT_UCHARCONSTPTR)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI, BT_UV2DI, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_BV2DI_BV4SI, BT_BV2DI, BT_BV4SI)\n+DEF_OV_TYPE (BT_OV_UV2DI_V2DI, BT_UV2DI, BT_V2DI)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV4SI, BT_UV2DI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_UV2DI_ULONGLONG, BT_UV2DI, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_UV2DI_ULONGLONGCONSTPTR, BT_UV2DI, BT_ULONGLONGCONSTPTR)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI, BT_UV4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_UV4SI_V4SI, BT_UV4SI, BT_V4SI)\n+DEF_OV_TYPE (BT_OV_BV4SI_BV8HI, BT_BV4SI, BT_BV8HI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UINTCONSTPTR, BT_UV4SI, BT_UINTCONSTPTR)\n+DEF_OV_TYPE (BT_OV_UV4SI_UINT, BT_UV4SI, BT_UINT)\n+DEF_OV_TYPE (BT_OV_BV4SI_BV4SI, BT_BV4SI, BT_BV4SI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV8HI, BT_UV4SI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI, BT_UV8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UV8HI_USHORTCONSTPTR, BT_UV8HI, BT_USHORTCONSTPTR)\n+DEF_OV_TYPE (BT_OV_BV8HI_BV16QI, BT_BV8HI, BT_BV16QI)\n+DEF_OV_TYPE (BT_OV_UV8HI_USHORT, BT_UV8HI, BT_USHORT)\n+DEF_OV_TYPE (BT_OV_UV8HI_V8HI, BT_UV8HI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_BV8HI_BV8HI, BT_BV8HI, BT_BV8HI)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV16QI, BT_UV8HI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_V16QI_SCHAR, BT_V16QI, BT_SCHAR)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI, BT_V16QI, BT_V16QI)\n+DEF_OV_TYPE (BT_OV_V16QI_SCHARCONSTPTR, BT_V16QI, BT_SCHARCONSTPTR)\n+DEF_OV_TYPE (BT_OV_V2DI_LONGLONG, BT_V2DI, BT_LONGLONG)\n+DEF_OV_TYPE (BT_OV_V2DI_V8HI, BT_V2DI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_V2DI_V16QI, BT_V2DI, BT_V16QI)\n+DEF_OV_TYPE (BT_OV_V2DI_LONGLONGCONSTPTR, BT_V2DI, BT_LONGLONGCONSTPTR)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI, BT_V2DI, BT_V2DI)\n+DEF_OV_TYPE (BT_OV_V2DI_V4SI, BT_V2DI, BT_V4SI)\n+DEF_OV_TYPE (BT_OV_V2DF_DBL, BT_V2DF, BT_DBL)\n+DEF_OV_TYPE (BT_OV_V2DF_V2DF, BT_V2DF, BT_V2DF)\n+DEF_OV_TYPE (BT_OV_V2DF_DBLCONSTPTR, BT_V2DF, BT_DBLCONSTPTR)\n+DEF_OV_TYPE (BT_OV_V4SI_INTCONSTPTR, BT_V4SI, BT_INTCONSTPTR)\n+DEF_OV_TYPE (BT_OV_V4SI_INT, BT_V4SI, BT_INT)\n+DEF_OV_TYPE (BT_OV_V4SI_V8HI, BT_V4SI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI, BT_V4SI, BT_V4SI)\n+DEF_OV_TYPE (BT_OV_V8HI_V16QI, BT_V8HI, BT_V16QI)\n+DEF_OV_TYPE (BT_OV_V8HI_SHORTCONSTPTR, BT_V8HI, BT_SHORTCONSTPTR)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI, BT_V8HI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_V8HI_SHORT, BT_V8HI, BT_SHORT)\n+DEF_OV_TYPE (BT_OV_INT_UV2DI_BV2DI, BT_INT, BT_UV2DI, BT_BV2DI)\n+DEF_OV_TYPE (BT_OV_DBL_V2DF_INT, BT_DBL, BT_V2DF, BT_INT)\n+DEF_OV_TYPE (BT_OV_INT_V8HI_UV8HI, BT_INT, BT_V8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_INT_BV8HI_BV8HI, BT_INT, BT_BV8HI, BT_BV8HI)\n+DEF_OV_TYPE (BT_OV_INT_V4SI_UV4SI, BT_INT, BT_V4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_UCHAR_UV16QI_INT, BT_UCHAR, BT_UV16QI, BT_INT)\n+DEF_OV_TYPE (BT_OV_INT_V2DI_UV2DI, BT_INT, BT_V2DI, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_SHORT_V8HI_INT, BT_SHORT, BT_V8HI, BT_INT)\n+DEF_OV_TYPE (BT_OV_INT_BV8HI_V8HI, BT_INT, BT_BV8HI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_USHORT_BV8HI_INT, BT_USHORT, BT_BV8HI, BT_INT)\n+DEF_OV_TYPE (BT_OV_INT_BV8HI_UV8HI, BT_INT, BT_BV8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UINT_UV4SI_INT, BT_UINT, BT_UV4SI, BT_INT)\n+DEF_OV_TYPE (BT_OV_INT_UV8HI_UV8HI, BT_INT, BT_UV8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_LONGLONG_V2DI_INT, BT_LONGLONG, BT_V2DI, BT_INT)\n+DEF_OV_TYPE (BT_OV_INT_UV8HI_BV8HI, BT_INT, BT_UV8HI, BT_BV8HI)\n+DEF_OV_TYPE (BT_OV_ULONGLONG_BV2DI_INT, BT_ULONGLONG, BT_BV2DI, BT_INT)\n+DEF_OV_TYPE (BT_OV_INT_V4SI_V4SI, BT_INT, BT_V4SI, BT_V4SI)\n+DEF_OV_TYPE (BT_OV_INT_V8HI_BV8HI, BT_INT, BT_V8HI, BT_BV8HI)\n+DEF_OV_TYPE (BT_OV_INT_V4SI_BV4SI, BT_INT, BT_V4SI, BT_BV4SI)\n+DEF_OV_TYPE (BT_OV_INT_UV16QI_BV16QI, BT_INT, BT_UV16QI, BT_BV16QI)\n+DEF_OV_TYPE (BT_OV_INT_V2DF_UV2DI, BT_INT, BT_V2DF, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_INT_BV16QI_UV16QI, BT_INT, BT_BV16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_INT_BV4SI_BV4SI, BT_INT, BT_BV4SI, BT_BV4SI)\n+DEF_OV_TYPE (BT_OV_INT_BV16QI_BV16QI, BT_INT, BT_BV16QI, BT_BV16QI)\n+DEF_OV_TYPE (BT_OV_INT_BV4SI_V4SI, BT_INT, BT_BV4SI, BT_V4SI)\n+DEF_OV_TYPE (BT_OV_INT_V16QI_UV16QI, BT_INT, BT_V16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_INT_V16QI_V16QI, BT_INT, BT_V16QI, BT_V16QI)\n+DEF_OV_TYPE (BT_OV_UCHAR_BV16QI_INT, BT_UCHAR, BT_BV16QI, BT_INT)\n+DEF_OV_TYPE (BT_OV_INT_BV4SI_UV4SI, BT_INT, BT_BV4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_INT_V4SI_INT, BT_INT, BT_V4SI, BT_INT)\n+DEF_OV_TYPE (BT_OV_INT_UV4SI_UV4SI, BT_INT, BT_UV4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_ULONGLONG_UV2DI_INT, BT_ULONGLONG, BT_UV2DI, BT_INT)\n+DEF_OV_TYPE (BT_OV_INT_UV4SI_BV4SI, BT_INT, BT_UV4SI, BT_BV4SI)\n+DEF_OV_TYPE (BT_OV_INT_V8HI_V8HI, BT_INT, BT_V8HI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_INT_V2DI_V2DI, BT_INT, BT_V2DI, BT_V2DI)\n+DEF_OV_TYPE (BT_OV_INT_BV16QI_V16QI, BT_INT, BT_BV16QI, BT_V16QI)\n+DEF_OV_TYPE (BT_OV_INT_V2DI_BV2DI, BT_INT, BT_V2DI, BT_BV2DI)\n+DEF_OV_TYPE (BT_OV_SCHAR_V16QI_INT, BT_SCHAR, BT_V16QI, BT_INT)\n+DEF_OV_TYPE (BT_OV_INT_BV2DI_BV2DI, BT_INT, BT_BV2DI, BT_BV2DI)\n+DEF_OV_TYPE (BT_OV_UINT_BV4SI_INT, BT_UINT, BT_BV4SI, BT_INT)\n+DEF_OV_TYPE (BT_OV_INT_BV2DI_V2DI, BT_INT, BT_BV2DI, BT_V2DI)\n+DEF_OV_TYPE (BT_OV_INT_UV16QI_UV16QI, BT_INT, BT_UV16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_INT_BV2DI_UV2DI, BT_INT, BT_BV2DI, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_USHORT_UV8HI_INT, BT_USHORT, BT_UV8HI, BT_INT)\n+DEF_OV_TYPE (BT_OV_INT_V2DF_V2DF, BT_INT, BT_V2DF, BT_V2DF)\n+DEF_OV_TYPE (BT_OV_INT_V16QI_BV16QI, BT_INT, BT_V16QI, BT_BV16QI)\n+DEF_OV_TYPE (BT_OV_INT_UV2DI_UV2DI, BT_INT, BT_UV2DI, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI_ULONG, BT_UV16QI, BT_UV16QI, BT_ULONG)\n+DEF_OV_TYPE (BT_OV_BV16QI_BV8HI_BV8HI, BT_BV16QI, BT_BV8HI, BT_BV8HI)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV2DI_UV2DI, BT_UV16QI, BT_UV2DI, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_BV16QI_BV16QI_BV16QI, BT_BV16QI, BT_BV16QI, BT_BV16QI)\n+DEF_OV_TYPE (BT_OV_UV16QI_BV16QI_BV16QI, BT_UV16QI, BT_BV16QI, BT_BV16QI)\n+DEF_OV_TYPE (BT_OV_BV16QI_V16QI_V16QI, BT_BV16QI, BT_V16QI, BT_V16QI)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI_BV16QI, BT_UV16QI, BT_UV16QI, BT_BV16QI)\n+DEF_OV_TYPE (BT_OV_UV16QI_UCHARCONSTPTR_UINT, BT_UV16QI, BT_UCHARCONSTPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_UV16QI_BV16QI_UV16QI, BT_UV16QI, BT_BV16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_UV16QI_UCHARCONSTPTR_USHORT, BT_UV16QI, BT_UCHARCONSTPTR, BT_USHORT)\n+DEF_OV_TYPE (BT_OV_UV16QI_LONG_UCHARPTR, BT_UV16QI, BT_LONG, BT_UCHARPTR)\n+DEF_OV_TYPE (BT_OV_UV16QI_UCHAR_INT, BT_UV16QI, BT_UCHAR, BT_INT)\n+DEF_OV_TYPE (BT_OV_BV16QI_BV16QI_UV4SI, BT_BV16QI, BT_BV16QI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV8HI_UV8HI, BT_UV16QI, BT_UV8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_BV16QI_BV16QI_UV8HI, BT_BV16QI, BT_BV16QI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_BV16QI_BV16QI_UCHAR, BT_BV16QI, BT_BV16QI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_BV16QI_BV16QI_UV16QI, BT_BV16QI, BT_BV16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_BV16QI_UV16QI_UV16QI, BT_BV16QI, BT_UV16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_BV16QI_BV16QI_INTPTR, BT_BV16QI, BT_BV16QI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI_V16QI, BT_UV16QI, BT_UV16QI, BT_V16QI)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI_INTPTR, BT_UV16QI, BT_UV16QI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI_UCHAR, BT_UV16QI, BT_UV16QI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI_UV4SI, BT_UV16QI, BT_UV16QI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI_UV8HI, BT_UV16QI, BT_UV16QI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UV16QI_V8HI_V8HI, BT_UV16QI, BT_V8HI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI_UV16QI, BT_UV16QI, BT_UV16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV4SI_UV4SI, BT_UV16QI, BT_UV4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI_UV16QI, BT_UV2DI, BT_UV2DI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_BV2DI_BV2DI_BV2DI, BT_BV2DI, BT_BV2DI, BT_BV2DI)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV4SI_UV4SI, BT_UV2DI, BT_UV4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_UV2DI_ULONGLONGCONSTPTR_USHORT, BT_UV2DI, BT_ULONGLONGCONSTPTR, BT_USHORT)\n+DEF_OV_TYPE (BT_OV_UV2DI_LONG_ULONGLONGPTR, BT_UV2DI, BT_LONG, BT_ULONGLONGPTR)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI_UV8HI, BT_UV2DI, BT_UV2DI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI_BV2DI, BT_UV2DI, BT_UV2DI, BT_BV2DI)\n+DEF_OV_TYPE (BT_OV_UV2DI_ULONGLONG_ULONGLONG, BT_UV2DI, BT_ULONGLONG, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI_V2DI, BT_UV2DI, BT_UV2DI, BT_V2DI)\n+DEF_OV_TYPE (BT_OV_UV2DI_ULONGLONGCONSTPTR_UINT, BT_UV2DI, BT_ULONGLONGCONSTPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_BV2DI_BV2DI_UV4SI, BT_BV2DI, BT_BV2DI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_BV2DI_V2DI_V2DI, BT_BV2DI, BT_V2DI, BT_V2DI)\n+DEF_OV_TYPE (BT_OV_BV2DI_BV2DI_UV16QI, BT_BV2DI, BT_BV2DI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_BV2DI_UV2DI_UV2DI, BT_BV2DI, BT_UV2DI, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI_ULONG, BT_UV2DI, BT_UV2DI, BT_ULONG)\n+DEF_OV_TYPE (BT_OV_BV2DI_V2DF_V2DF, BT_BV2DI, BT_V2DF, BT_V2DF)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV8HI_UV8HI, BT_UV2DI, BT_UV8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI_UV2DI, BT_UV2DI, BT_UV2DI, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_BV2DI_BV2DI_UV8HI, BT_BV2DI, BT_BV2DI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI_UCHAR, BT_UV2DI, BT_UV2DI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_UV2DI_BV2DI_UV2DI, BT_UV2DI, BT_BV2DI, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_BV2DI_BV2DI_UCHAR, BT_BV2DI, BT_BV2DI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI_UV4SI, BT_UV2DI, BT_UV2DI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_UV2DI_ULONGLONG_INT, BT_UV2DI, BT_ULONGLONG, BT_INT)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_UV8HI, BT_UV4SI, BT_UV4SI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UV4SI_V2DI_V2DI, BT_UV4SI, BT_V2DI, BT_V2DI)\n+DEF_OV_TYPE (BT_OV_BV4SI_BV4SI_UV8HI, BT_BV4SI, BT_BV4SI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_V4SI, BT_UV4SI, BT_UV4SI, BT_V4SI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_UCHAR, BT_UV4SI, BT_UV4SI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_UV4SI_UINT_INT, BT_UV4SI, BT_UINT, BT_INT)\n+DEF_OV_TYPE (BT_OV_BV4SI_BV4SI_INTPTR, BT_BV4SI, BT_BV4SI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_UV4SI, BT_UV4SI, BT_UV4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_ULONG, BT_UV4SI, BT_UV4SI, BT_ULONG)\n+DEF_OV_TYPE (BT_OV_BV4SI_BV2DI_BV2DI, BT_BV4SI, BT_BV2DI, BT_BV2DI)\n+DEF_OV_TYPE (BT_OV_BV4SI_BV4SI_BV4SI, BT_BV4SI, BT_BV4SI, BT_BV4SI)\n+DEF_OV_TYPE (BT_OV_BV4SI_BV4SI_UV4SI, BT_BV4SI, BT_BV4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_BV4SI, BT_UV4SI, BT_UV4SI, BT_BV4SI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV2DI_UV2DI, BT_UV4SI, BT_UV2DI, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_BV4SI_UV4SI_UV4SI, BT_BV4SI, BT_UV4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_UV16QI, BT_UV4SI, BT_UV4SI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_INTPTR, BT_UV4SI, BT_UV4SI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV4SI_UINTCONSTPTR_USHORT, BT_UV4SI, BT_UINTCONSTPTR, BT_USHORT)\n+DEF_OV_TYPE (BT_OV_UV4SI_BV4SI_BV4SI, BT_UV4SI, BT_BV4SI, BT_BV4SI)\n+DEF_OV_TYPE (BT_OV_BV4SI_BV4SI_UCHAR, BT_BV4SI, BT_BV4SI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV16QI_UV16QI, BT_UV4SI, BT_UV16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV8HI_UV8HI, BT_UV4SI, BT_UV8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UV4SI_LONG_UINTPTR, BT_UV4SI, BT_LONG, BT_UINTPTR)\n+DEF_OV_TYPE (BT_OV_BV4SI_BV4SI_UV16QI, BT_BV4SI, BT_BV4SI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_BV4SI_V4SI_V4SI, BT_BV4SI, BT_V4SI, BT_V4SI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UINTCONSTPTR_UINT, BT_UV4SI, BT_UINTCONSTPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_UV4SI_BV4SI_UV4SI, BT_UV4SI, BT_BV4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_BV8HI_BV8HI_BV8HI, BT_BV8HI, BT_BV8HI, BT_BV8HI)\n+DEF_OV_TYPE (BT_OV_UV8HI_V4SI_V4SI, BT_UV8HI, BT_V4SI, BT_V4SI)\n+DEF_OV_TYPE (BT_OV_UV8HI_USHORTCONSTPTR_UINT, BT_UV8HI, BT_USHORTCONSTPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_UV4SI, BT_UV8HI, BT_UV8HI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_BV8HI_V8HI_V8HI, BT_BV8HI, BT_V8HI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_BV8HI_BV4SI_BV4SI, BT_BV8HI, BT_BV4SI, BT_BV4SI)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_V8HI, BT_UV8HI, BT_UV8HI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV4SI_UV4SI, BT_UV8HI, BT_UV4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_UV8HI_USHORT_INT, BT_UV8HI, BT_USHORT, BT_INT)\n+DEF_OV_TYPE (BT_OV_BV8HI_BV8HI_UV16QI, BT_BV8HI, BT_BV8HI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_BV8HI_UV8HI_UV8HI, BT_BV8HI, BT_UV8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UV8HI_USHORTCONSTPTR_USHORT, BT_UV8HI, BT_USHORTCONSTPTR, BT_USHORT)\n+DEF_OV_TYPE (BT_OV_UV8HI_LONG_USHORTPTR, BT_UV8HI, BT_LONG, BT_USHORTPTR)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_UCHAR, BT_UV8HI, BT_UV8HI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_BV8HI_BV8HI_UCHAR, BT_BV8HI, BT_BV8HI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_BV8HI_BV8HI_INTPTR, BT_BV8HI, BT_BV8HI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_BV8HI_BV8HI_UV8HI, BT_BV8HI, BT_BV8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_UV16QI, BT_UV8HI, BT_UV8HI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_BV8HI, BT_UV8HI, BT_UV8HI, BT_BV8HI)\n+DEF_OV_TYPE (BT_OV_BV8HI_BV8HI_UV4SI, BT_BV8HI, BT_BV8HI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_UV8HI_BV8HI_BV8HI, BT_UV8HI, BT_BV8HI, BT_BV8HI)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV16QI_UV16QI, BT_UV8HI, BT_UV16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_UV8HI_BV8HI_UV8HI, BT_UV8HI, BT_BV8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_INTPTR, BT_UV8HI, BT_UV8HI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_ULONG, BT_UV8HI, BT_UV8HI, BT_ULONG)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_UV8HI, BT_UV8HI, BT_UV8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_V16QI_BV16QI_V16QI, BT_V16QI, BT_BV16QI, BT_V16QI)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_UCHAR, BT_V16QI, BT_V16QI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_INTPTR, BT_V16QI, BT_V16QI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_BV16QI, BT_V16QI, BT_V16QI, BT_BV16QI)\n+DEF_OV_TYPE (BT_OV_V16QI_LONG_SCHARPTR, BT_V16QI, BT_LONG, BT_SCHARPTR)\n+DEF_OV_TYPE (BT_OV_V16QI_SCHARCONSTPTR_UINT, BT_V16QI, BT_SCHARCONSTPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_UV8HI, BT_V16QI, BT_V16QI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_UV16QI, BT_V16QI, BT_V16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_UV4SI, BT_V16QI, BT_V16QI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_ULONG, BT_V16QI, BT_V16QI, BT_ULONG)\n+DEF_OV_TYPE (BT_OV_V16QI_SCHARCONSTPTR_USHORT, BT_V16QI, BT_SCHARCONSTPTR, BT_USHORT)\n+DEF_OV_TYPE (BT_OV_V16QI_SCHAR_INT, BT_V16QI, BT_SCHAR, BT_INT)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_V16QI, BT_V16QI, BT_V16QI, BT_V16QI)\n+DEF_OV_TYPE (BT_OV_V16QI_V8HI_V8HI, BT_V16QI, BT_V8HI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_V2DF_UV2DI_INT, BT_V2DF, BT_UV2DI, BT_INT)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI_UCHAR, BT_V2DI, BT_V2DI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI_UV16QI, BT_V2DI, BT_V2DI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_V2DF_DBLCONSTPTR_USHORT, BT_V2DF, BT_DBLCONSTPTR, BT_USHORT)\n+DEF_OV_TYPE (BT_OV_V2DF_BV2DI_V2DF, BT_V2DF, BT_BV2DI, BT_V2DF)\n+DEF_OV_TYPE (BT_OV_V2DF_V2DF_UCHAR, BT_V2DF, BT_V2DF, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_V2DF_V2DF_BV2DI, BT_V2DF, BT_V2DF, BT_BV2DI)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI_UV8HI, BT_V2DI, BT_V2DI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_V2DF_DBLCONSTPTR_UINT, BT_V2DF, BT_DBLCONSTPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_V2DF_DBL_INT, BT_V2DF, BT_DBL, BT_INT)\n+DEF_OV_TYPE (BT_OV_V2DF_V2DF_UV2DI, BT_V2DF, BT_V2DF, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI_UV4SI, BT_V2DI, BT_V2DI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_V2DF_V2DF_V2DI, BT_V2DF, BT_V2DF, BT_V2DI)\n+DEF_OV_TYPE (BT_OV_V2DI_BV2DI_V2DI, BT_V2DI, BT_BV2DI, BT_V2DI)\n+DEF_OV_TYPE (BT_OV_V2DI_LONG_LONGLONGPTR, BT_V2DI, BT_LONG, BT_LONGLONGPTR)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI_V2DI, BT_V2DI, BT_V2DI, BT_V2DI)\n+DEF_OV_TYPE (BT_OV_V2DI_V4SI_V4SI, BT_V2DI, BT_V4SI, BT_V4SI)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI_UV2DI, BT_V2DI, BT_V2DI, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_V2DF_V2DI_INT, BT_V2DF, BT_V2DI, BT_INT)\n+DEF_OV_TYPE (BT_OV_V2DI_LONGLONG_INT, BT_V2DI, BT_LONGLONG, BT_INT)\n+DEF_OV_TYPE (BT_OV_V2DI_LONGLONGCONSTPTR_UINT, BT_V2DI, BT_LONGLONGCONSTPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI_BV2DI, BT_V2DI, BT_V2DI, BT_BV2DI)\n+DEF_OV_TYPE (BT_OV_V2DF_LONG_DBLPTR, BT_V2DF, BT_LONG, BT_DBLPTR)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI_ULONG, BT_V2DI, BT_V2DI, BT_ULONG)\n+DEF_OV_TYPE (BT_OV_V2DI_LONGLONG_LONGLONG, BT_V2DI, BT_LONGLONG, BT_LONGLONG)\n+DEF_OV_TYPE (BT_OV_V2DI_LONGLONGCONSTPTR_USHORT, BT_V2DI, BT_LONGLONGCONSTPTR, BT_USHORT)\n+DEF_OV_TYPE (BT_OV_V2DF_V2DF_V2DF, BT_V2DF, BT_V2DF, BT_V2DF)\n+DEF_OV_TYPE (BT_OV_V4SI_INTCONSTPTR_USHORT, BT_V4SI, BT_INTCONSTPTR, BT_USHORT)\n+DEF_OV_TYPE (BT_OV_V4SI_V8HI_V8HI, BT_V4SI, BT_V8HI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_BV4SI, BT_V4SI, BT_V4SI, BT_BV4SI)\n+DEF_OV_TYPE (BT_OV_V4SI_INTCONSTPTR_UINT, BT_V4SI, BT_INTCONSTPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_V4SI_BV4SI_V4SI, BT_V4SI, BT_BV4SI, BT_V4SI)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_UV8HI, BT_V4SI, BT_V4SI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_INTPTR, BT_V4SI, BT_V4SI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_V4SI, BT_V4SI, BT_V4SI, BT_V4SI)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_ULONG, BT_V4SI, BT_V4SI, BT_ULONG)\n+DEF_OV_TYPE (BT_OV_V4SI_INT_INT, BT_V4SI, BT_INT, BT_INT)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_UV4SI, BT_V4SI, BT_V4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_UV16QI, BT_V4SI, BT_V4SI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_V4SI_LONG_INTPTR, BT_V4SI, BT_LONG, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_UCHAR, BT_V4SI, BT_V4SI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_V4SI_V2DI_V2DI, BT_V4SI, BT_V2DI, BT_V2DI)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_UV8HI, BT_V8HI, BT_V8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_V8HI, BT_V8HI, BT_V8HI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_ULONG, BT_V8HI, BT_V8HI, BT_ULONG)\n+DEF_OV_TYPE (BT_OV_V8HI_LONG_SHORTPTR, BT_V8HI, BT_LONG, BT_SHORTPTR)\n+DEF_OV_TYPE (BT_OV_V8HI_V4SI_V4SI, BT_V8HI, BT_V4SI, BT_V4SI)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_INTPTR, BT_V8HI, BT_V8HI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_UV16QI, BT_V8HI, BT_V8HI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_V8HI_BV8HI_V8HI, BT_V8HI, BT_BV8HI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_UV4SI, BT_V8HI, BT_V8HI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_BV8HI, BT_V8HI, BT_V8HI, BT_BV8HI)\n+DEF_OV_TYPE (BT_OV_V8HI_SHORTCONSTPTR_UINT, BT_V8HI, BT_SHORTCONSTPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_V8HI_SHORT_INT, BT_V8HI, BT_SHORT, BT_INT)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_UCHAR, BT_V8HI, BT_V8HI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_V8HI_SHORTCONSTPTR_USHORT, BT_V8HI, BT_SHORTCONSTPTR, BT_USHORT)\n+DEF_OV_TYPE (BT_OV_V8HI_V16QI_V16QI, BT_V8HI, BT_V16QI, BT_V16QI)\n+DEF_OV_TYPE (BT_OV_VOID_V2DF_DBLPTR_UINT, BT_VOID, BT_V2DF, BT_DBLPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_VOID_UV16QI_UCHARPTR_UINT, BT_VOID, BT_UV16QI, BT_UCHARPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_VOID_V4SI_INTPTR_UINT, BT_VOID, BT_V4SI, BT_INTPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_VOID_UV4SI_LONG_UINTPTR, BT_VOID, BT_UV4SI, BT_LONG, BT_UINTPTR)\n+DEF_OV_TYPE (BT_OV_VOID_V4SI_LONG_INTPTR, BT_VOID, BT_V4SI, BT_LONG, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_VOID_V2DI_LONG_LONGLONGPTR, BT_VOID, BT_V2DI, BT_LONG, BT_LONGLONGPTR)\n+DEF_OV_TYPE (BT_OV_VOID_V8HI_SHORTPTR_UINT, BT_VOID, BT_V8HI, BT_SHORTPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_VOID_V2DF_LONG_DBLPTR, BT_VOID, BT_V2DF, BT_LONG, BT_DBLPTR)\n+DEF_OV_TYPE (BT_OV_VOID_UV8HI_USHORTPTR_UINT, BT_VOID, BT_UV8HI, BT_USHORTPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_VOID_UV2DI_ULONGLONGPTR_UINT, BT_VOID, BT_UV2DI, BT_ULONGLONGPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_VOID_UV16QI_LONG_UCHARPTR, BT_VOID, BT_UV16QI, BT_LONG, BT_UCHARPTR)\n+DEF_OV_TYPE (BT_OV_VOID_UV8HI_LONG_USHORTPTR, BT_VOID, BT_UV8HI, BT_LONG, BT_USHORTPTR)\n+DEF_OV_TYPE (BT_OV_VOID_UV4SI_UINTPTR_UINT, BT_VOID, BT_UV4SI, BT_UINTPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_VOID_V16QI_SCHARPTR_UINT, BT_VOID, BT_V16QI, BT_SCHARPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_VOID_V16QI_LONG_SCHARPTR, BT_VOID, BT_V16QI, BT_LONG, BT_SCHARPTR)\n+DEF_OV_TYPE (BT_OV_VOID_V8HI_LONG_SHORTPTR, BT_VOID, BT_V8HI, BT_LONG, BT_SHORTPTR)\n+DEF_OV_TYPE (BT_OV_VOID_UV2DI_LONG_ULONGLONGPTR, BT_VOID, BT_UV2DI, BT_LONG, BT_ULONGLONGPTR)\n+DEF_OV_TYPE (BT_OV_VOID_V2DI_LONGLONGPTR_UINT, BT_VOID, BT_V2DI, BT_LONGLONGPTR, BT_UINT)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV8HI_UV8HI_INTPTR, BT_UV16QI, BT_UV8HI, BT_UV8HI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI_UV16QI_UCHAR, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI_UV16QI_ULONGLONG, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI_UV16QI_INT, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_INT)\n+DEF_OV_TYPE (BT_OV_BV16QI_BV16QI_BV16QI_BV16QI, BT_BV16QI, BT_BV16QI, BT_BV16QI, BT_BV16QI)\n+DEF_OV_TYPE (BT_OV_BV16QI_BV16QI_BV16QI_UV16QI, BT_BV16QI, BT_BV16QI, BT_BV16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_UV16QI_UCHAR_UV16QI_INT, BT_UV16QI, BT_UCHAR, BT_UV16QI, BT_INT)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI_UV16QI_UV16QI, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_BV16QI_UV16QI_UV16QI_UV16QI, BT_BV16QI, BT_UV16QI, BT_UV16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_UV16QI_BV16QI_BV16QI_INTPTR, BT_UV16QI, BT_BV16QI, BT_BV16QI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI_UV16QI_BV16QI, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_BV16QI)\n+DEF_OV_TYPE (BT_OV_BV16QI_BV16QI_BV16QI_INTPTR, BT_BV16QI, BT_BV16QI, BT_BV16QI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_BV16QI_UV16QI_UV16QI_INTPTR, BT_BV16QI, BT_UV16QI, BT_UV16QI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_BV16QI_V16QI_V16QI_INTPTR, BT_BV16QI, BT_V16QI, BT_V16QI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV16QI_UCHAR_BV16QI_INT, BT_UV16QI, BT_UCHAR, BT_BV16QI, BT_INT)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI_UV16QI_INTPTR, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI_UV2DI_ULONGLONG, BT_UV2DI, BT_UV2DI, BT_UV2DI, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_UV2DI_ULONGLONG_UV2DI_INT, BT_UV2DI, BT_ULONGLONG, BT_UV2DI, BT_INT)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI_UV2DI_INT, BT_UV2DI, BT_UV2DI, BT_UV2DI, BT_INT)\n+DEF_OV_TYPE (BT_OV_BV2DI_BV2DI_BV2DI_INT, BT_BV2DI, BT_BV2DI, BT_BV2DI, BT_INT)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI_UV2DI_UV2DI, BT_UV2DI, BT_UV2DI, BT_UV2DI, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI_UV2DI_UCHAR, BT_UV2DI, BT_UV2DI, BT_UV2DI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_BV2DI_BV2DI_BV2DI_BV2DI, BT_BV2DI, BT_BV2DI, BT_BV2DI, BT_BV2DI)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV4SI_UV4SI_UV2DI, BT_UV2DI, BT_UV4SI, BT_UV4SI, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI_UV2DI_BV2DI, BT_UV2DI, BT_UV2DI, BT_UV2DI, BT_BV2DI)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI_UV2DI_UV16QI, BT_UV2DI, BT_UV2DI, BT_UV2DI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_BV2DI_BV2DI_BV2DI_UV2DI, BT_BV2DI, BT_BV2DI, BT_BV2DI, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_BV2DI_BV2DI_BV2DI_UV16QI, BT_BV2DI, BT_BV2DI, BT_BV2DI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_UV2DI_ULONGLONG_BV2DI_INT, BT_UV2DI, BT_ULONGLONG, BT_BV2DI, BT_INT)\n+DEF_OV_TYPE (BT_OV_BV4SI_BV4SI_BV4SI_BV4SI, BT_BV4SI, BT_BV4SI, BT_BV4SI, BT_BV4SI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV8HI_UV8HI_UV4SI, BT_UV4SI, BT_UV8HI, BT_UV8HI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_BV4SI_V4SI_V4SI_INTPTR, BT_BV4SI, BT_V4SI, BT_V4SI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_UV4SI_UCHAR, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_BV4SI_BV4SI_BV4SI_INTPTR, BT_BV4SI, BT_BV4SI, BT_BV4SI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV4SI_UINT_UV4SI_INT, BT_UV4SI, BT_UINT, BT_UV4SI, BT_INT)\n+DEF_OV_TYPE (BT_OV_BV4SI_UV4SI_UV4SI_INTPTR, BT_BV4SI, BT_UV4SI, BT_UV4SI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV2DI_UV2DI_INTPTR, BT_UV4SI, BT_UV2DI, BT_UV2DI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV4SI_BV4SI_BV4SI_INTPTR, BT_UV4SI, BT_BV4SI, BT_BV4SI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_UV4SI_UV16QI, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_BV4SI_BV4SI_BV4SI_UV4SI, BT_BV4SI, BT_BV4SI, BT_BV4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_BV4SI_UV4SI_UV4SI_UV4SI, BT_BV4SI, BT_UV4SI, BT_UV4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UINT_BV4SI_INT, BT_UV4SI, BT_UINT, BT_BV4SI, BT_INT)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_UV4SI_UV4SI, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_UV4SI_INT, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_INT)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_UV4SI_BV4SI, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_BV4SI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_UV4SI_INTPTR, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_BV4SI_BV4SI_BV4SI_UV16QI, BT_BV4SI, BT_BV4SI, BT_BV4SI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_UV4SI_ULONGLONG, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_BV8HI_UV8HI_UV8HI_UV8HI, BT_BV8HI, BT_UV8HI, BT_UV8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_BV8HI_BV8HI_BV8HI_INTPTR, BT_BV8HI, BT_BV8HI, BT_BV8HI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV4SI_UV4SI_INTPTR, BT_UV8HI, BT_UV4SI, BT_UV4SI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_BV8HI_BV8HI_BV8HI_UV8HI, BT_BV8HI, BT_BV8HI, BT_BV8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_UV8HI_INTPTR, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_BV8HI_BV8HI_BV8HI_BV8HI, BT_BV8HI, BT_BV8HI, BT_BV8HI, BT_BV8HI)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV16QI_UV16QI_UV8HI, BT_UV8HI, BT_UV16QI, BT_UV16QI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_UV8HI_UV8HI, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_UV8HI_UV16QI, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_UV8HI_BV8HI, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_BV8HI)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_UV8HI_ULONGLONG, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_UV8HI_USHORT_BV8HI_INT, BT_UV8HI, BT_USHORT, BT_BV8HI, BT_INT)\n+DEF_OV_TYPE (BT_OV_BV8HI_V8HI_V8HI_INTPTR, BT_BV8HI, BT_V8HI, BT_V8HI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_UV8HI_INT, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_INT)\n+DEF_OV_TYPE (BT_OV_BV8HI_BV8HI_BV8HI_UV16QI, BT_BV8HI, BT_BV8HI, BT_BV8HI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_UV8HI_UCHAR, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_BV8HI_UV8HI_UV8HI_INTPTR, BT_BV8HI, BT_UV8HI, BT_UV8HI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV8HI_BV8HI_BV8HI_INTPTR, BT_UV8HI, BT_BV8HI, BT_BV8HI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV8HI_USHORT_UV8HI_INT, BT_UV8HI, BT_USHORT, BT_UV8HI, BT_INT)\n+DEF_OV_TYPE (BT_OV_V16QI_SCHAR_V16QI_INT, BT_V16QI, BT_SCHAR, BT_V16QI, BT_INT)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_V16QI_BV16QI, BT_V16QI, BT_V16QI, BT_V16QI, BT_BV16QI)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_V16QI_V16QI, BT_V16QI, BT_V16QI, BT_V16QI, BT_V16QI)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_V16QI_INTPTR, BT_V16QI, BT_V16QI, BT_V16QI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_V16QI_UV16QI_V16QI_V16QI, BT_V16QI, BT_UV16QI, BT_V16QI, BT_V16QI)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_V16QI_ULONGLONG, BT_V16QI, BT_V16QI, BT_V16QI, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_V16QI_V8HI_V8HI_INTPTR, BT_V16QI, BT_V8HI, BT_V8HI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_UV16QI_UCHAR, BT_V16QI, BT_V16QI, BT_UV16QI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_UV16QI_UV16QI, BT_V16QI, BT_V16QI, BT_UV16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_V16QI_INT, BT_V16QI, BT_V16QI, BT_V16QI, BT_INT)\n+DEF_OV_TYPE (BT_OV_V16QI_V16QI_V16QI_UV16QI, BT_V16QI, BT_V16QI, BT_V16QI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI_UV2DI_UCHAR, BT_V2DI, BT_V2DI, BT_UV2DI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI_V2DI_INT, BT_V2DI, BT_V2DI, BT_V2DI, BT_INT)\n+DEF_OV_TYPE (BT_OV_V2DF_V2DF_V2DF_ULONGLONG, BT_V2DF, BT_V2DF, BT_V2DF, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI_V2DI_UV16QI, BT_V2DI, BT_V2DI, BT_V2DI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_V2DF_V2DF_V2DF_INT, BT_V2DF, BT_V2DF, BT_V2DF, BT_INT)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI_V2DI_UV2DI, BT_V2DI, BT_V2DI, BT_V2DI, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_V2DF_V2DF_V2DF_UV16QI, BT_V2DF, BT_V2DF, BT_V2DF, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI_V2DI_ULONGLONG, BT_V2DI, BT_V2DI, BT_V2DI, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_V2DF_DBL_V2DF_INT, BT_V2DF, BT_DBL, BT_V2DF, BT_INT)\n+DEF_OV_TYPE (BT_OV_V2DI_V4SI_V4SI_V2DI, BT_V2DI, BT_V4SI, BT_V4SI, BT_V2DI)\n+DEF_OV_TYPE (BT_OV_V2DI_LONGLONG_V2DI_INT, BT_V2DI, BT_LONGLONG, BT_V2DI, BT_INT)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI_V2DI_BV2DI, BT_V2DI, BT_V2DI, BT_V2DI, BT_BV2DI)\n+DEF_OV_TYPE (BT_OV_V2DF_V2DF_V2DF_UV2DI, BT_V2DF, BT_V2DF, BT_V2DF, BT_UV2DI)\n+DEF_OV_TYPE (BT_OV_V2DF_V2DF_V2DF_BV2DI, BT_V2DF, BT_V2DF, BT_V2DF, BT_BV2DI)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_V4SI_BV4SI, BT_V4SI, BT_V4SI, BT_V4SI, BT_BV4SI)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_V4SI_UV16QI, BT_V4SI, BT_V4SI, BT_V4SI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_V4SI_INT, BT_V4SI, BT_V4SI, BT_V4SI, BT_INT)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_UV4SI_UV4SI, BT_V4SI, BT_V4SI, BT_UV4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_V4SI_ULONGLONG, BT_V4SI, BT_V4SI, BT_V4SI, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_UV4SI_UCHAR, BT_V4SI, BT_V4SI, BT_UV4SI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_V4SI_V8HI_V8HI_V4SI, BT_V4SI, BT_V8HI, BT_V8HI, BT_V4SI)\n+DEF_OV_TYPE (BT_OV_V4SI_UV4SI_V4SI_V4SI, BT_V4SI, BT_UV4SI, BT_V4SI, BT_V4SI)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_V4SI_V4SI, BT_V4SI, BT_V4SI, BT_V4SI, BT_V4SI)\n+DEF_OV_TYPE (BT_OV_V4SI_V2DI_V2DI_INTPTR, BT_V4SI, BT_V2DI, BT_V2DI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_V4SI_UV4SI, BT_V4SI, BT_V4SI, BT_V4SI, BT_UV4SI)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_V4SI_INTPTR, BT_V4SI, BT_V4SI, BT_V4SI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_V4SI_INT_V4SI_INT, BT_V4SI, BT_INT, BT_V4SI, BT_INT)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_V8HI_INT, BT_V8HI, BT_V8HI, BT_V8HI, BT_INT)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_UV8HI_UCHAR, BT_V8HI, BT_V8HI, BT_UV8HI, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_UV8HI_UV8HI, BT_V8HI, BT_V8HI, BT_UV8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_V8HI_UV8HI, BT_V8HI, BT_V8HI, BT_V8HI, BT_UV8HI)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_V8HI_INTPTR, BT_V8HI, BT_V8HI, BT_V8HI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_V8HI_UV8HI_V8HI_V8HI, BT_V8HI, BT_UV8HI, BT_V8HI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_V8HI_V16QI_V16QI_V8HI, BT_V8HI, BT_V16QI, BT_V16QI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_V8HI_BV8HI, BT_V8HI, BT_V8HI, BT_V8HI, BT_BV8HI)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_V8HI_ULONGLONG, BT_V8HI, BT_V8HI, BT_V8HI, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_V8HI_SHORT_V8HI_INT, BT_V8HI, BT_SHORT, BT_V8HI, BT_INT)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_V8HI_V8HI, BT_V8HI, BT_V8HI, BT_V8HI, BT_V8HI)\n+DEF_OV_TYPE (BT_OV_V8HI_V4SI_V4SI_INTPTR, BT_V8HI, BT_V4SI, BT_V4SI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_V8HI_V8HI_V8HI_UV16QI, BT_V8HI, BT_V8HI, BT_V8HI, BT_UV16QI)\n+DEF_OV_TYPE (BT_OV_VOID_V2DF_UV2DI_DBLPTR_ULONGLONG, BT_VOID, BT_V2DF, BT_UV2DI, BT_DBLPTR, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_VOID_V4SI_UV4SI_INTPTR_ULONGLONG, BT_VOID, BT_V4SI, BT_UV4SI, BT_INTPTR, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_VOID_UV2DI_UV2DI_ULONGLONGPTR_ULONGLONG, BT_VOID, BT_UV2DI, BT_UV2DI, BT_ULONGLONGPTR, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_VOID_UV4SI_UV4SI_UINTPTR_ULONGLONG, BT_VOID, BT_UV4SI, BT_UV4SI, BT_UINTPTR, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_VOID_BV2DI_UV2DI_ULONGLONGPTR_ULONGLONG, BT_VOID, BT_BV2DI, BT_UV2DI, BT_ULONGLONGPTR, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_VOID_V2DI_UV2DI_LONGLONGPTR_ULONGLONG, BT_VOID, BT_V2DI, BT_UV2DI, BT_LONGLONGPTR, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_VOID_BV4SI_UV4SI_UINTPTR_ULONGLONG, BT_VOID, BT_BV4SI, BT_UV4SI, BT_UINTPTR, BT_ULONGLONG)\n+DEF_OV_TYPE (BT_OV_UV16QI_UV16QI_UV16QI_UV16QI_INTPTR, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_BV16QI_UV16QI_UV16QI_UV16QI_INTPTR, BT_BV16QI, BT_UV16QI, BT_UV16QI, BT_UV16QI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_BV2DI_BV2DI_UV2DI_ULONGLONGCONSTPTR_UCHAR, BT_BV2DI, BT_BV2DI, BT_UV2DI, BT_ULONGLONGCONSTPTR, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_UV2DI_UV2DI_UV2DI_ULONGLONGCONSTPTR_UCHAR, BT_UV2DI, BT_UV2DI, BT_UV2DI, BT_ULONGLONGCONSTPTR, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_BV4SI_BV4SI_UV4SI_UINTCONSTPTR_UCHAR, BT_BV4SI, BT_BV4SI, BT_UV4SI, BT_UINTCONSTPTR, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_BV4SI_UV4SI_UV4SI_UV4SI_INTPTR, BT_BV4SI, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_UV4SI_UV4SI_INTPTR, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV4SI_UV4SI_UV4SI_UINTCONSTPTR_UCHAR, BT_UV4SI, BT_UV4SI, BT_UV4SI, BT_UINTCONSTPTR, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_BV8HI_UV8HI_UV8HI_UV8HI_INTPTR, BT_BV8HI, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_UV8HI_UV8HI_UV8HI_UV8HI_INTPTR, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_UV8HI, BT_INTPTR)\n+DEF_OV_TYPE (BT_OV_V2DI_V2DI_UV2DI_LONGLONGCONSTPTR_UCHAR, BT_V2DI, BT_V2DI, BT_UV2DI, BT_LONGLONGCONSTPTR, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_V2DF_V2DF_UV2DI_DBLCONSTPTR_UCHAR, BT_V2DF, BT_V2DF, BT_UV2DI, BT_DBLCONSTPTR, BT_UCHAR)\n+DEF_OV_TYPE (BT_OV_V4SI_V4SI_UV4SI_INTCONSTPTR_UCHAR, BT_V4SI, BT_V4SI, BT_UV4SI, BT_INTCONSTPTR, BT_UCHAR)"}, {"sha": "357be2aa9e20a666235f7ea0f234bf69fc69ae77", "filename": "gcc/config/s390/s390-builtins.def", "status": "added", "additions": 2486, "deletions": 0, "changes": 2486, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Fs390-builtins.def?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1"}, {"sha": "043c098efa157782beff985b43423084277f9775", "filename": "gcc/config/s390/s390-builtins.h", "status": "added", "additions": 160, "deletions": 0, "changes": 160, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390-builtins.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390-builtins.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Fs390-builtins.h?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1", "patch": "@@ -0,0 +1,160 @@\n+/* Common data structures used for builtin handling on S/390.\n+   Copyright (C) 2015 Free Software Foundation, Inc.\n+\n+   Contributed by Andreas Krebbel (Andreas.Krebbel@de.ibm.com).\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify it\n+   under the terms of the GNU General Public License as published by\n+   the Free Software Foundation; either version 3, or (at your option)\n+   any later version.\n+\n+   GCC is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n+   or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public\n+   License for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with GCC; see the file COPYING3.  If not see\n+   <http://www.gnu.org/licenses/>.  */\n+\n+/* This files contains data structure definitions which can be used by\n+   s390-builtins.c as well as s390-c.c.  Since the latter is\n+   considered to be part of the front-end we have to be careful not\n+   to use any of tree and rtx like data structures.  */\n+\n+/* Builtin types, data and prototypes. */\n+\n+enum s390_builtin_type_index\n+{\n+#undef DEF_TYPE\n+#undef DEF_POINTER_TYPE\n+#undef DEF_DISTINCT_TYPE\n+#undef DEF_VECTOR_TYPE\n+#undef DEF_OPAQUE_VECTOR_TYPE\n+#undef DEF_FN_TYPE\n+#undef DEF_OV_TYPE\n+#define DEF_TYPE(INDEX, NODE, CONST_P) INDEX,\n+#define DEF_POINTER_TYPE(INDEX, INDEX2) INDEX,\n+#define DEF_DISTINCT_TYPE(INDEX, INDEX2) INDEX,\n+#define DEF_VECTOR_TYPE(INDEX, INDEX2, ELEMENTS) INDEX,\n+#define DEF_OPAQUE_VECTOR_TYPE(INDEX, INDEX2, ELEMENTS) INDEX,\n+#define DEF_FN_TYPE(...)\n+#define DEF_OV_TYPE(...)\n+#include \"s390-builtin-types.def\"\n+  BT_MAX\n+};\n+\n+enum s390_builtin_fn_type_index\n+{\n+#undef DEF_TYPE\n+#undef DEF_POINTER_TYPE\n+#undef DEF_DISTINCT_TYPE\n+#undef DEF_VECTOR_TYPE\n+#undef DEF_OPAQUE_VECTOR_TYPE\n+#undef DEF_FN_TYPE\n+#undef DEF_OV_TYPE\n+#define DEF_TYPE(...)\n+#define DEF_POINTER_TYPE(...)\n+#define DEF_DISTINCT_TYPE(...)\n+#define DEF_VECTOR_TYPE(...)\n+#define DEF_OPAQUE_VECTOR_TYPE(...)\n+#define DEF_FN_TYPE(INDEX, ...) INDEX,\n+#define DEF_OV_TYPE(...)\n+#include \"s390-builtin-types.def\"\n+  BT_FN_MAX\n+};\n+\n+enum s390_builtin_ov_type_index\n+{\n+#undef DEF_TYPE\n+#undef DEF_POINTER_TYPE\n+#undef DEF_DISTINCT_TYPE\n+#undef DEF_VECTOR_TYPE\n+#undef DEF_OPAQUE_VECTOR_TYPE\n+#undef DEF_FN_TYPE\n+#undef DEF_OV_TYPE\n+#define DEF_TYPE(...)\n+#define DEF_POINTER_TYPE(...)\n+#define DEF_DISTINCT_TYPE(...)\n+#define DEF_VECTOR_TYPE(...)\n+#define DEF_OPAQUE_VECTOR_TYPE(...)\n+#define DEF_FN_TYPE(...)\n+#define DEF_OV_TYPE(INDEX, ...) INDEX,\n+#include \"s390-builtin-types.def\"\n+  BT_OV_MAX\n+};\n+\n+#define MAX_OV_OPERANDS 6\n+\n+extern tree s390_builtin_types[BT_MAX];\n+extern tree s390_builtin_fn_types[BT_FN_MAX];\n+\n+  /* Builtins.  */\n+\n+enum s390_builtins {\n+#undef B_DEF\n+#undef OB_DEF\n+#undef OB_DEF_VAR\n+#define B_DEF(NAME, ...) S390_BUILTIN_##NAME,\n+#define OB_DEF(...)\n+#define OB_DEF_VAR(...)\n+\n+#include \"s390-builtins.def\"\n+  S390_BUILTIN_MAX\n+};\n+\n+\n+/* Generate an enumeration of all overloaded builtins defined with\n+   OB_DEF in s390-builtins.def.  */\n+enum s390_overloaded_builtins {\n+#undef B_DEF\n+#undef OB_DEF\n+#undef OB_DEF_VAR\n+#define B_DEF(...)\n+#define OB_DEF(NAME, ...) S390_OVERLOADED_BUILTIN_##NAME,\n+#define OB_DEF_VAR(...)\n+#include \"s390-builtins.def\"\n+S390_OVERLOADED_BUILTIN_MAX\n+};\n+\n+/* Generate an enumeration of all variants of overloaded builtins\n+   defined with OB_DEF_VAR in s390-builtins.def.  */\n+enum s390_overloaded_builtin_vars {\n+#undef B_DEF\n+#undef OB_DEF\n+#undef OB_DEF_VAR\n+#define B_DEF(...)\n+#define OB_DEF(...)\n+#define OB_DEF_VAR(NAME, ...) S390_OVERLOADED_BUILTIN_VAR_##NAME,\n+#include \"s390-builtins.def\"\n+S390_OVERLOADED_BUILTIN_VAR_MAX\n+};\n+\n+#define S390_OVERLOADED_BUILTIN_OFFSET S390_BUILTIN_MAX\n+#define S390_OVERLOADED_BUILTIN_VAR_OFFSET \\\n+  (S390_BUILTIN_MAX + S390_OVERLOADED_BUILTIN_MAX)\n+#define S390_ALL_BUILTIN_MAX\t\t\t\t\\\n+  (S390_BUILTIN_MAX + S390_OVERLOADED_BUILTIN_MAX +\t\\\n+   S390_OVERLOADED_BUILTIN_VAR_MAX)\n+\n+extern const unsigned int flags_builtin[S390_BUILTIN_MAX + 1];\n+extern const unsigned int\n+  flags_overloaded_builtin_var[S390_OVERLOADED_BUILTIN_VAR_MAX + 1];\n+\n+static inline unsigned int\n+flags_for_builtin (int fcode)\n+{\n+  if (fcode >= S390_OVERLOADED_BUILTIN_VAR_OFFSET)\n+    return flags_overloaded_builtin_var[fcode -\n+\t\t\t\t\tS390_OVERLOADED_BUILTIN_VAR_OFFSET];\n+  else if (fcode >= S390_OVERLOADED_BUILTIN_OFFSET)\n+    gcc_unreachable ();\n+  else\n+    return flags_builtin[fcode];\n+}\n+\n+extern tree s390_builtin_decls[S390_BUILTIN_MAX +\n+\t\t\t       S390_OVERLOADED_BUILTIN_MAX +\n+\t\t\t       S390_OVERLOADED_BUILTIN_VAR_MAX];"}, {"sha": "ed81b0f86b4f0f334e19a5fc84fe4db5f692fdfd", "filename": "gcc/config/s390/s390-c.c", "status": "added", "additions": 907, "deletions": 0, "changes": 907, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390-c.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390-c.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Fs390-c.c?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1", "patch": "@@ -0,0 +1,907 @@\n+/* Language specific subroutines used for code generation on IBM S/390\n+   and zSeries\n+   Copyright (C) 2015 Free Software Foundation, Inc.\n+\n+   Contributed by Andreas Krebbel (Andreas.Krebbel@de.ibm.com).\n+\n+   This file is part of GCC.\n+\n+   GCC is free software; you can redistribute it and/or modify it\n+   under the terms of the GNU General Public License as published by\n+   the Free Software Foundation; either version 3, or (at your option)\n+   any later version.\n+\n+   GCC is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n+   or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public\n+   License for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with GCC; see the file COPYING3.  If not see\n+   <http://www.gnu.org/licenses/>.\n+\n+   Based on gcc/config/rs6000/rs6000-c.c.\n+\n+   In GCC terms this file belongs to the frontend.  It will be\n+   compiled with -DIN_GCC_FRONTEND.  With that rtl.h cannot be\n+   included anymore - a mechanism supposed to avoid adding frontend -\n+   backend dependencies.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"cpplib.h\"\n+#include \"hash-set.h\"\n+#include \"machmode.h\"\n+#include \"vec.h\"\n+#include \"double-int.h\"\n+#include \"input.h\"\n+#include \"alias.h\"\n+#include \"symtab.h\"\n+#include \"wide-int.h\"\n+#include \"inchash.h\"\n+#include \"tree.h\"\n+#include \"fold-const.h\"\n+#include \"stringpool.h\"\n+#include \"c-family/c-common.h\"\n+#include \"c-family/c-pragma.h\"\n+#include \"diagnostic-core.h\"\n+#include \"tm_p.h\"\n+#include \"target.h\"\n+#include \"langhooks.h\"\n+#include \"tree-pretty-print.h\"\n+#include \"c/c-tree.h\"\n+\n+#include \"s390-builtins.h\"\n+\n+static GTY(()) tree __vector_keyword;\n+static GTY(()) tree vector_keyword;\n+static GTY(()) tree __bool_keyword;\n+static GTY(()) tree bool_keyword;\n+static GTY(()) tree _Bool_keyword;\n+\n+\n+/* Generate an array holding all the descriptions of variants of\n+   overloaded builtins defined with OB_DEF_VAR in\n+   s390-builtins.def.  */\n+static enum s390_builtin_ov_type_index\n+type_for_overloaded_builtin_var[S390_OVERLOADED_BUILTIN_VAR_MAX + 1] =\n+  {\n+#undef B_DEF\n+#undef OB_DEF\n+#undef OB_DEF_VAR\n+#define B_DEF(...)\n+#define OB_DEF(...)\n+#define OB_DEF_VAR(NAME, PATTERN, FLAGS, FNTYPE) FNTYPE,\n+#include \"s390-builtins.def\"\n+    BT_OV_MAX\n+  };\n+\n+\n+/* Generate an array indexed by an overloaded builtin index returning\n+   the first index in desc_for_overloaded_builtin_var where the\n+   variants for the builtin can be found.  */\n+static enum s390_overloaded_builtin_vars\n+desc_start_for_overloaded_builtin[S390_OVERLOADED_BUILTIN_MAX + 1] =\n+  {\n+#undef B_DEF\n+#undef OB_DEF\n+#undef OB_DEF_VAR\n+#define B_DEF(...)\n+#define OB_DEF(NAME, FIRST_VAR_NAME, LAST_VAR_NAME, FNTYPE)\t\\\n+    S390_OVERLOADED_BUILTIN_VAR_##FIRST_VAR_NAME,\n+#define OB_DEF_VAR(...)\n+    #include \"s390-builtins.def\"\n+    S390_OVERLOADED_BUILTIN_VAR_MAX\n+  };\n+\n+/* Generate an array indexed by an overloaded builtin index returning\n+   the last index in desc_for_overloaded_builtin_var where the\n+   variants for the builtin can be found.  */\n+static enum s390_overloaded_builtin_vars\n+desc_end_for_overloaded_builtin[S390_OVERLOADED_BUILTIN_MAX + 1] =\n+  {\n+#undef B_DEF\n+#undef OB_DEF\n+#undef OB_DEF_VAR\n+#define B_DEF(...)\n+#define OB_DEF(NAME, FIRST_VAR_NAME, LAST_VAR_NAME, FNTYPE)\t\\\n+    S390_OVERLOADED_BUILTIN_VAR_##LAST_VAR_NAME,\n+#define OB_DEF_VAR(...)\n+    #include \"s390-builtins.def\"\n+    S390_OVERLOADED_BUILTIN_VAR_MAX\n+  };\n+\n+static enum s390_builtin_type_index\n+s390_builtin_ov_types[BT_OV_MAX][MAX_OV_OPERANDS] =\n+  {\n+#undef DEF_TYPE\n+#undef DEF_POINTER_TYPE\n+#undef DEF_DISTINCT_TYPE\n+#undef DEF_VECTOR_TYPE\n+#undef DEF_OPAQUE_VECTOR_TYPE\n+#undef DEF_FN_TYPE\n+#undef DEF_OV_TYPE\n+#define DEF_TYPE(...)\n+#define DEF_POINTER_TYPE(...)\n+#define DEF_DISTINCT_TYPE(...)\n+#define DEF_VECTOR_TYPE(...)\n+#define DEF_OPAQUE_VECTOR_TYPE(...)\n+#define DEF_FN_TYPE(...)\n+#define DEF_OV_TYPE(INDEX, args...) { args },\n+#include \"s390-builtin-types.def\"\n+  };\n+\n+static const enum s390_builtins bt_for_overloaded_builtin_var[S390_OVERLOADED_BUILTIN_VAR_MAX] = {\n+#undef B_DEF\n+#undef OB_DEF\n+#undef OB_DEF_VAR\n+#define B_DEF(...)\n+#define OB_DEF(...)\n+#define OB_DEF_VAR(NAME, BT, ...) S390_BUILTIN_##BT,\n+\n+#include \"s390-builtins.def\"\n+  };\n+\n+/* In addition to calling fold_convert for EXPR of type TYPE, also\n+   call c_fully_fold to remove any C_MAYBE_CONST_EXPRs that could be\n+   hiding there (PR47197).  */\n+tree\n+fully_fold_convert (tree type, tree expr)\n+{\n+  tree result = fold_convert (type, expr);\n+  bool maybe_const = true;\n+\n+  if (!c_dialect_cxx ())\n+    result = c_fully_fold (result, false, &maybe_const);\n+\n+  return result;\n+}\n+\n+/* Unify the different variants to the same nodes in order to keep the\n+   code working with it simple.  */\n+static cpp_hashnode *\n+s390_categorize_keyword (const cpp_token *tok)\n+{\n+  if (tok->type == CPP_NAME)\n+    {\n+      cpp_hashnode *ident = tok->val.node.node;\n+\n+      if (ident == C_CPP_HASHNODE (vector_keyword))\n+\treturn C_CPP_HASHNODE (__vector_keyword);\n+\n+      if (ident == C_CPP_HASHNODE (bool_keyword))\n+\treturn C_CPP_HASHNODE (__bool_keyword);\n+\n+      if (ident == C_CPP_HASHNODE (_Bool_keyword))\n+\treturn C_CPP_HASHNODE (__bool_keyword);\n+      return ident;\n+    }\n+\n+  return 0;\n+}\n+\n+\n+/* Called to decide whether a conditional macro should be expanded.\n+   Since we have exactly one such macro (i.e, 'vector'), we do not\n+   need to examine the 'tok' parameter.  */\n+\n+static cpp_hashnode *\n+s390_macro_to_expand (cpp_reader *pfile, const cpp_token *tok)\n+{\n+  cpp_hashnode *expand_this = tok->val.node.node;\n+  cpp_hashnode *ident;\n+  static bool expand_bool_p = false;\n+  int idx = 0;\n+  enum rid rid_code;\n+\n+  /* The vector keyword is only expanded if the machine actually\n+     provides hardware support.  */\n+  if (!TARGET_ZVECTOR)\n+    return NULL;\n+\n+  ident = s390_categorize_keyword (tok);\n+\n+  /* Triggered when we picked a different variant in\n+     s390_categorize_keyword.  */\n+  if (ident != expand_this)\n+    expand_this = NULL;\n+\n+  /* The vector keyword has been found already and we remembered to\n+     expand the next bool.  */\n+  if (expand_bool_p && ident == C_CPP_HASHNODE (__bool_keyword))\n+    {\n+      expand_bool_p = false;\n+      return ident;\n+    }\n+\n+  if (ident != C_CPP_HASHNODE (__vector_keyword))\n+    return expand_this;\n+\n+  do\n+    tok = cpp_peek_token (pfile, idx++);\n+  while (tok->type == CPP_PADDING);\n+  ident = s390_categorize_keyword (tok);\n+\n+  if (!ident)\n+    return expand_this;\n+\n+  /* vector bool - remember to expand the next bool. */\n+  if (ident == C_CPP_HASHNODE (__bool_keyword))\n+    {\n+      expand_bool_p = true;\n+      return C_CPP_HASHNODE (__vector_keyword);\n+    }\n+\n+  /* The boost libraries have code with Iterator::vector vector in it.\n+     If we allow the normal handling, this module will be called\n+     recursively, and the vector will be skipped.; */\n+  if (ident == C_CPP_HASHNODE (__vector_keyword))\n+    return expand_this;\n+\n+  rid_code = (enum rid)(ident->rid_code);\n+\n+  if (ident->type == NT_MACRO)\n+    {\n+      /* Now actually fetch the tokens we \"peeked\" before and do a\n+\t lookahead for the next.  */\n+      do\n+\t(void) cpp_get_token (pfile);\n+      while (--idx > 0);\n+      do\n+\ttok = cpp_peek_token (pfile, idx++);\n+      while (tok->type == CPP_PADDING);\n+      ident = s390_categorize_keyword (tok);\n+\n+      if (ident == C_CPP_HASHNODE (__bool_keyword))\n+\t{\n+\t  expand_bool_p = true;\n+\t  return C_CPP_HASHNODE (__vector_keyword);\n+\t}\n+      else if (ident)\n+\trid_code = (enum rid)(ident->rid_code);\n+    }\n+\n+  /* vector keyword followed by type identifier: vector unsigned,\n+     vector long, ...\n+     Types consisting of more than one identifier are not supported by\n+     zvector e.g. long long, long double, unsigned long int.  */\n+  if (rid_code == RID_UNSIGNED || rid_code == RID_LONG\n+      || rid_code == RID_SHORT || rid_code == RID_SIGNED\n+      || rid_code == RID_INT || rid_code == RID_CHAR\n+      || rid_code == RID_DOUBLE)\n+    {\n+      expand_this = C_CPP_HASHNODE (__vector_keyword);\n+      /* If the next keyword is bool, it will need to be expanded as\n+\t well.  */\n+      do\n+\ttok = cpp_peek_token (pfile, idx++);\n+      while (tok->type == CPP_PADDING);\n+      ident = s390_categorize_keyword (tok);\n+\n+      /* __vector long __bool a; */\n+      if (ident == C_CPP_HASHNODE (__bool_keyword))\n+\texpand_bool_p = true;\n+      else\n+\t{\n+\t  /* Triggered with: __vector long long __bool a; */\n+\t  do\n+\t    tok = cpp_peek_token (pfile, idx++);\n+\t  while (tok->type == CPP_PADDING);\n+\t  ident = s390_categorize_keyword (tok);\n+\n+\t  if (ident == C_CPP_HASHNODE (__bool_keyword))\n+\t    expand_bool_p = true;\n+\t}\n+    }\n+\n+  return expand_this;\n+}\n+\n+/* Define platform dependent macros.  */\n+void\n+s390_cpu_cpp_builtins (cpp_reader *pfile)\n+{\n+  cpp_assert (pfile, \"cpu=s390\");\n+  cpp_assert (pfile, \"machine=s390\");\n+  cpp_define (pfile, \"__s390__\");\n+  if (TARGET_ZARCH)\n+    cpp_define (pfile, \"__zarch__\");\n+  if (TARGET_64BIT)\n+    cpp_define (pfile, \"__s390x__\");\n+  if (TARGET_LONG_DOUBLE_128)\n+    cpp_define (pfile, \"__LONG_DOUBLE_128__\");\n+  if (TARGET_HTM)\n+    cpp_define (pfile, \"__HTM__\");\n+  if (TARGET_ZVECTOR)\n+    {\n+      cpp_define (pfile, \"__VEC__=10301\");\n+      cpp_define (pfile, \"__vector=__attribute__((vector_size(16)))\");\n+      cpp_define (pfile, \"__bool=__attribute__((s390_vector_bool)) unsigned\");\n+\n+      if (!flag_iso)\n+\t{\n+\t  cpp_define (pfile, \"__VECTOR_KEYWORD_SUPPORTED__\");\n+\t  cpp_define (pfile, \"vector=vector\");\n+\t  cpp_define (pfile, \"bool=bool\");\n+\n+\t  __vector_keyword = get_identifier (\"__vector\");\n+\t  C_CPP_HASHNODE (__vector_keyword)->flags |= NODE_CONDITIONAL;\n+\n+\t  vector_keyword = get_identifier (\"vector\");\n+\t  C_CPP_HASHNODE (vector_keyword)->flags |= NODE_CONDITIONAL;\n+\n+\t  __bool_keyword = get_identifier (\"__bool\");\n+\t  C_CPP_HASHNODE (__bool_keyword)->flags |= NODE_CONDITIONAL;\n+\n+\t  bool_keyword = get_identifier (\"bool\");\n+\t  C_CPP_HASHNODE (bool_keyword)->flags |= NODE_CONDITIONAL;\n+\n+\t  _Bool_keyword = get_identifier (\"_Bool\");\n+\t  C_CPP_HASHNODE (_Bool_keyword)->flags |= NODE_CONDITIONAL;\n+\n+\t  /* Enable context-sensitive macros.  */\n+\t  cpp_get_callbacks (pfile)->macro_to_expand = s390_macro_to_expand;\n+\t}\n+    }\n+}\n+\n+/* Expand builtins which can directly be mapped to tree expressions.\n+   LOC - location information\n+   FCODE - function code of the builtin\n+   ARGLIST - value supposed to be passed as arguments\n+   RETURN-TYPE - expected return type of the builtin */\n+static tree\n+s390_expand_overloaded_builtin (location_t loc,\n+\t\t\t\tunsigned fcode,\n+\t\t\t\tvec<tree, va_gc> *arglist,\n+\t\t\t\ttree return_type)\n+{\n+  switch (fcode)\n+    {\n+    case S390_OVERLOADED_BUILTIN_s390_vec_step:\n+      if (TREE_CODE (TREE_TYPE ((*arglist)[0])) != VECTOR_TYPE)\n+\t{\n+\t  error_at (loc, \"Builtin vec_step can only be used on vector types.\");\n+\t  return error_mark_node;\n+\t}\n+      return build_int_cst (NULL_TREE,\n+\t\t\t    TYPE_VECTOR_SUBPARTS (TREE_TYPE ((*arglist)[0])));\n+    case S390_OVERLOADED_BUILTIN_s390_vec_xld2:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_xlw4:\n+      return build2 (MEM_REF, return_type,\n+\t\t     fold_build_pointer_plus ((*arglist)[1], (*arglist)[0]),\n+\t\t     build_int_cst (TREE_TYPE ((*arglist)[1]), 0));\n+    case S390_OVERLOADED_BUILTIN_s390_vec_xstd2:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_xstw4:\n+      return build2 (MODIFY_EXPR, TREE_TYPE((*arglist)[0]),\n+\t\t     build1 (INDIRECT_REF, TREE_TYPE((*arglist)[0]),\n+\t\t\t     fold_build_pointer_plus ((*arglist)[2], (*arglist)[1])),\n+\t\t     (*arglist)[0]);\n+    case S390_OVERLOADED_BUILTIN_s390_vec_load_pair:\n+      return build_constructor_va (return_type, 2,\n+\t\t\t\t   NULL_TREE, (*arglist)[0],\n+\t\t\t\t   NULL_TREE, (*arglist)[1]);\n+    default:\n+      gcc_unreachable ();\n+    }\n+}\n+\n+/* invert result */\n+#define __VSTRING_FLAG_IN         8\n+/* result type */\n+#define __VSTRING_FLAG_RT         4\n+/* zero search */\n+#define __VSTRING_FLAG_ZS         2\n+/* set condition code */\n+#define __VSTRING_FLAG_CS         1\n+\n+/* Return the flags value to be used for string low-level builtins\n+   when expanded from overloaded builtin OB_FCODE.  */\n+static unsigned int\n+s390_get_vstring_flags (int ob_fcode)\n+{\n+  unsigned int flags = 0;\n+\n+  switch (ob_fcode)\n+    {\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_or_0_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_or_0_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_or_0_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_or_0_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_cc:\n+      flags |= __VSTRING_FLAG_IN;\n+      break;\n+    default:\n+      break;\n+    }\n+  switch (ob_fcode)\n+    {\n+\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_eq_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_eq_or_0_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_or_0_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_eq_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_eq_or_0_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_or_0_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmprg_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmprg_or_0_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_or_0_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmprg_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmprg_or_0_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_or_0_idx_cc:\n+      flags |= __VSTRING_FLAG_RT;\n+      break;\n+    default:\n+      break;\n+    }\n+  switch (ob_fcode)\n+    {\n+\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_eq_or_0_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_or_0_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_eq_or_0_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_or_0_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmprg_or_0_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_or_0_idx:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmprg_or_0_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_or_0_idx_cc:\n+      flags |= __VSTRING_FLAG_ZS;\n+      break;\n+    default:\n+      break;\n+    }\n+  switch (ob_fcode)\n+    {\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_eq_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_eq_or_0_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_or_0_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_eq_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmprg_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmprg_or_0_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_or_0_idx_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmprg_cc:\n+    case S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_cc:\n+      flags |= __VSTRING_FLAG_CS;\n+      break;\n+    default:\n+      break;\n+    }\n+  return flags;\n+}\n+#undef __VSTRING_FLAG_IN\n+#undef __VSTRING_FLAG_RT\n+#undef __VSTRING_FLAG_ZS\n+#undef __VSTRING_FLAG_CS\n+\n+/* For several overloaded builtins the argument lists do not match\n+   exactly the signature of a low-level builtin.  This function\n+   adjusts the argument list ARGLIST for the overloaded builtin\n+   OB_FCODE to the signature of the low-level builtin given by\n+   DECL.  */\n+static void\n+s390_adjust_builtin_arglist (unsigned int ob_fcode, tree decl,\n+\t\t\t     vec<tree, va_gc> **arglist)\n+{\n+  tree arg_chain;\n+  int src_arg_index, dest_arg_index;\n+  vec<tree, va_gc> *folded_args = NULL;\n+\n+  /* We at most add one more operand to the list.  */\n+  vec_alloc (folded_args, (*arglist)->allocated () + 1);\n+  for (arg_chain = TYPE_ARG_TYPES (TREE_TYPE (decl)),\n+\t src_arg_index = 0, dest_arg_index = 0;\n+       !VOID_TYPE_P (TREE_VALUE (arg_chain));\n+       arg_chain = TREE_CHAIN (arg_chain), dest_arg_index++)\n+    {\n+      bool arg_assigned_p = false;\n+      switch (ob_fcode)\n+\t{\n+\t  /* For all these the low level builtin needs an additional flags parameter.  */\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_find_any_eq_idx:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_idx:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_find_any_eq_or_0_idx:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_or_0_idx:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_find_any_eq:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_find_any_eq_idx_cc:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_idx_cc:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_find_any_eq_or_0_idx_cc:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_or_0_idx_cc:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_find_any_eq_cc:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_find_any_ne_cc:\n+\t  if (dest_arg_index == 2)\n+\t    {\n+\t      folded_args->quick_push (build_int_cst (integer_type_node,\n+\t\t\t\t       s390_get_vstring_flags (ob_fcode)));\n+\t      arg_assigned_p = true;\n+\t    }\n+\t  break;\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_cmprg_idx:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_idx:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_cmprg_or_0_idx:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_or_0_idx:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_cmprg:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_cmprg_idx_cc:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_idx_cc:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_cmprg_or_0_idx_cc:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_or_0_idx_cc:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_cmprg_cc:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_cmpnrg_cc:\n+\t  if (dest_arg_index == 3)\n+\t    {\n+\t      folded_args->quick_push (build_int_cst (integer_type_node,\n+\t\t\t\t       s390_get_vstring_flags (ob_fcode)));\n+\t      arg_assigned_p = true;\n+\t    }\n+\t  break;\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_sel:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_insert:\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_load_len:\n+\t  /* Swap the first to arguments. It is better to do it here\n+\t     instead of the header file to avoid operand checking\n+\t     throwing error messages for a weird operand index.  */\n+\t  if (dest_arg_index < 2)\n+\t    {\n+\t      folded_args->quick_push (fully_fold_convert (TREE_VALUE (arg_chain),\n+\t\t\t\t\t (**arglist)[1 - dest_arg_index]));\n+\t      src_arg_index++;\n+\t      arg_assigned_p = true;\n+\t    }\n+\t  break;\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_store_len:\n+\t  if (dest_arg_index == 1 || dest_arg_index == 2)\n+\t    {\n+\t      folded_args->quick_push (fully_fold_convert (TREE_VALUE (arg_chain),\n+\t\t\t\t\t (**arglist)[3 - dest_arg_index]));\n+\t      src_arg_index++;\n+\t      arg_assigned_p = true;\n+\t    }\n+\t  break;\n+\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_load_bndry:\n+\t  {\n+\t    int code;\n+\n+\t    if (dest_arg_index == 1)\n+\t      {\n+\t\tswitch (tree_to_uhwi ((**arglist)[src_arg_index]))\n+\t\t  {\n+\t\t  case 64: code = 0; break;\n+\t\t  case 128: code = 1; break;\n+\t\t  case 256: code = 2; break;\n+\t\t  case 512: code = 3; break;\n+\t\t  case 1024: code = 4; break;\n+\t\t  case 2048: code = 5; break;\n+\t\t  case 4096: code = 6; break;\n+\t\t  default:\n+\t\t    error (\"valid values for builtin %qF argument %d are 64, \"\n+\t\t\t   \"128, 256, 512, 1024, 2048, and 4096\", decl,\n+\t\t\t   src_arg_index + 1);\n+\t\t    return;\n+\t\t  }\n+\t\tfolded_args->quick_push (build_int_cst (integer_type_node,\n+\t\t\t\t\t\t\tcode));\n+\t\tsrc_arg_index++;\n+\t\targ_assigned_p = true;\n+\t      }\n+\t  }\n+\t  break;\n+\tcase S390_OVERLOADED_BUILTIN_s390_vec_rl_mask:\n+\t  /* Duplicate the first src arg.  */\n+\t  if (dest_arg_index == 0)\n+\t    {\n+\t      folded_args->quick_push (fully_fold_convert (TREE_VALUE (arg_chain),\n+\t\t\t\t\t   (**arglist)[src_arg_index]));\n+\t      arg_assigned_p = true;\n+\t    }\n+\t  break;\n+\tdefault:\n+\t  break;\n+\t}\n+      if (!arg_assigned_p)\n+\t{\n+\t  folded_args->quick_push (fully_fold_convert (TREE_VALUE (arg_chain),\n+\t\t\t\t\t\t (**arglist)[src_arg_index]));\n+\t  src_arg_index++;\n+\t}\n+    }\n+  *arglist = folded_args;\n+}\n+\n+/* Check whether the arguments in ARGLIST match the function type\n+   DEF_TYPE. Return the number of argument types which required\n+   conversion/promotion in order to make it match.\n+   0 stands for a perfect match - all operand types match without changes\n+   INT_MAX stands for a mismatch.  */\n+static int\n+s390_fn_types_compatible (enum s390_builtin_ov_type_index typeindex,\n+\t\t\t  vec<tree, va_gc> *arglist)\n+{\n+  unsigned int i;\n+  int match_type = 0;\n+\n+  for (i = 0; i < vec_safe_length (arglist); i++)\n+    {\n+      tree b_arg_type = s390_builtin_types[s390_builtin_ov_types[typeindex][i + 1]];\n+      tree in_arg = (*arglist)[i];\n+      tree in_type = TREE_TYPE (in_arg);\n+\n+      if (TREE_CODE (b_arg_type) == VECTOR_TYPE)\n+\t{\n+\t  /* Vector types have to match precisely.  */\n+\t  if (b_arg_type != in_type\n+\t      && TYPE_MAIN_VARIANT (b_arg_type) != TYPE_MAIN_VARIANT (in_type))\n+\t    goto mismatch;\n+\t}\n+\n+      if (lang_hooks.types_compatible_p (in_type, b_arg_type))\n+\tcontinue;\n+\n+      if (lang_hooks.types_compatible_p (\n+\t    lang_hooks.types.type_promotes_to (in_type),\n+\t    lang_hooks.types.type_promotes_to (b_arg_type)))\n+\t{\n+\t  match_type++;\n+\t  continue;\n+\t}\n+\n+      /* In this stage the C++ frontend would go ahead trying to find\n+\t implicit conversion chains for the argument to match the\n+\t target type.  We will mimic this here only for our limited\n+\t subset of argument types.  */\n+      if (TREE_CODE (b_arg_type) == INTEGER_TYPE\n+\t  && TREE_CODE (in_type) == INTEGER_TYPE)\n+\t{\n+\t  match_type++;\n+\t  continue;\n+\t}\n+\n+      /* If the incoming pointer argument has more qualifiers than the\n+\t argument type it can still be an imperfect match.  */\n+      if (POINTER_TYPE_P (b_arg_type) && POINTER_TYPE_P (in_type)\n+\t  && !(TYPE_QUALS (TREE_TYPE (in_type))\n+\t       & ~TYPE_QUALS (TREE_TYPE (b_arg_type)))\n+\t  && (TYPE_QUALS (TREE_TYPE (b_arg_type))\n+\t      & ~TYPE_QUALS (TREE_TYPE (in_type))))\n+\t{\n+\t  tree qual_in_type =\n+\t    build_qualified_type (TREE_TYPE (in_type),\n+\t\t\t\t  TYPE_QUALS (TREE_TYPE (b_arg_type)));\n+\n+\t  if (lang_hooks.types_compatible_p (qual_in_type,\n+\t\t\t\t\t     TREE_TYPE (b_arg_type)))\n+\t    {\n+\t      match_type++;\n+\t      continue;\n+\t    }\n+\t}\n+\n+    mismatch:\n+      if (TARGET_DEBUG_ARG)\n+\tfprintf (stderr, \" mismatch in operand: %d\\n\", i + 1);\n+      return INT_MAX;\n+    }\n+\n+  return match_type;\n+}\n+\n+/* Return the number of elements in the vector arguments of FNDECL in\n+   case all it matches for all vector arguments, -1 otherwise.  */\n+static int\n+s390_vec_n_elem (tree fndecl)\n+{\n+  tree b_arg_chain;\n+  int n_elem = -1;\n+\n+  if (TREE_CODE (TREE_TYPE (TREE_TYPE (fndecl))) == VECTOR_TYPE)\n+    n_elem = TYPE_VECTOR_SUBPARTS (TREE_TYPE (TREE_TYPE ((fndecl))));\n+\n+  for (b_arg_chain = TYPE_ARG_TYPES (TREE_TYPE (fndecl));\n+       !VOID_TYPE_P (TREE_VALUE (b_arg_chain));\n+       b_arg_chain = TREE_CHAIN (b_arg_chain))\n+    {\n+      int tmp_n_elem;\n+      if (TREE_CODE (TREE_VALUE (b_arg_chain)) != VECTOR_TYPE)\n+\tcontinue;\n+      tmp_n_elem = TYPE_VECTOR_SUBPARTS (TREE_VALUE (b_arg_chain));\n+      if (n_elem != -1 && n_elem != tmp_n_elem)\n+\treturn -1;\n+      n_elem = tmp_n_elem;\n+    }\n+  return n_elem;\n+}\n+\n+\n+/* Return a tree expression for a call to the overloaded builtin\n+   function OB_FNDECL at LOC with arguments PASSED_ARGLIST.  */\n+tree\n+s390_resolve_overloaded_builtin (location_t loc,\n+\t\t\t\t tree ob_fndecl,\n+\t\t\t\t void *passed_arglist)\n+{\n+  vec<tree, va_gc> *arglist = static_cast<vec<tree, va_gc> *> (passed_arglist);\n+  unsigned int in_args_num = vec_safe_length (arglist);\n+  unsigned int ob_args_num = 0;\n+  unsigned int ob_fcode = DECL_FUNCTION_CODE (ob_fndecl);\n+  enum s390_overloaded_builtin_vars bindex;\n+  unsigned int i;\n+  int last_match_type = INT_MAX;\n+  int last_match_index = -1;\n+  unsigned int all_op_flags;\n+  int num_matches = 0;\n+  tree target_builtin_decl, b_arg_chain, return_type;\n+  enum s390_builtin_ov_type_index last_match_fntype_index;\n+\n+  if (TARGET_DEBUG_ARG)\n+    fprintf (stderr,\n+      \"s390_resolve_overloaded_builtin, code = %4d, %s - %s overloaded\\n\",\n+      (int)ob_fcode, IDENTIFIER_POINTER (DECL_NAME (ob_fndecl)),\n+     ob_fcode < S390_BUILTIN_MAX ? \"not\" : \"\");\n+\n+  /* 0...S390_BUILTIN_MAX-1 is for non-overloaded builtins.  */\n+  if (ob_fcode < S390_BUILTIN_MAX)\n+    {\n+      if (flags_for_builtin(ob_fcode) & B_INT)\n+\t{\n+\t  error_at (loc,\n+\t\t    \"Builtin %qF is for GCC internal use only.\",\n+\t\t    ob_fndecl);\n+\t  return error_mark_node;\n+\t}\n+      return NULL_TREE;\n+    }\n+\n+  ob_fcode -= S390_BUILTIN_MAX;\n+\n+  for (b_arg_chain = TYPE_ARG_TYPES (TREE_TYPE (ob_fndecl));\n+       !VOID_TYPE_P (TREE_VALUE (b_arg_chain));\n+       b_arg_chain = TREE_CHAIN (b_arg_chain))\n+    ob_args_num++;\n+\n+  if (ob_args_num != in_args_num)\n+    {\n+      error_at (loc,\n+\t\t\"Mismatch in number of arguments for builtin %qF. \"\n+\t\t\"Expected: %d got %d\", ob_fndecl,\n+\t\tob_args_num, in_args_num);\n+      return error_mark_node;\n+    }\n+\n+  for (i = 0; i < in_args_num; i++)\n+    if ((*arglist)[i] == error_mark_node)\n+      return error_mark_node;\n+\n+  /* Overloaded builtins without any variants are directly expanded here.  */\n+  if (desc_start_for_overloaded_builtin[ob_fcode] ==\n+      S390_OVERLOADED_BUILTIN_VAR_MAX)\n+    return s390_expand_overloaded_builtin (loc, ob_fcode, arglist, NULL_TREE);\n+\n+  for (bindex = desc_start_for_overloaded_builtin[ob_fcode];\n+       bindex <= desc_end_for_overloaded_builtin[ob_fcode];\n+       bindex = (enum s390_overloaded_builtin_vars)((int)bindex + 1))\n+  {\n+    int match_type;\n+    enum s390_builtin_ov_type_index type_index =\n+      type_for_overloaded_builtin_var[bindex];\n+\n+    if (TARGET_DEBUG_ARG)\n+      fprintf (stderr, \"checking variant number: %d\", (int)bindex);\n+\n+    match_type = s390_fn_types_compatible (type_index, arglist);\n+\n+    if (match_type == INT_MAX)\n+      continue;\n+\n+    if (TARGET_DEBUG_ARG)\n+      fprintf (stderr,\n+\t       \" %s match score: %d\\n\", match_type == 0 ? \"perfect\" : \"imperfect\",\n+\t       match_type);\n+\n+    if (match_type < last_match_type)\n+      {\n+\tnum_matches = 1;\n+\tlast_match_type = match_type;\n+\tlast_match_fntype_index = type_index;\n+\tlast_match_index = bindex;\n+      }\n+    else if (match_type == last_match_type)\n+      num_matches++;\n+  }\n+\n+  if (last_match_type == INT_MAX)\n+    {\n+      error_at (loc, \"invalid parameter combination for intrinsic\");\n+      return error_mark_node;\n+    }\n+  else if (num_matches > 1)\n+    {\n+      error_at (loc, \"ambiguous overload for intrinsic: %s\\n\",\n+\t     IDENTIFIER_POINTER (DECL_NAME (ob_fndecl)));\n+      return error_mark_node;\n+    }\n+\n+  if (bt_for_overloaded_builtin_var[last_match_index] == S390_BUILTIN_MAX)\n+    target_builtin_decl = ob_fndecl;\n+  else\n+    target_builtin_decl = s390_builtin_decls[bt_for_overloaded_builtin_var[last_match_index]];\n+\n+  all_op_flags = flags_overloaded_builtin_var[last_match_index];\n+  return_type = s390_builtin_types[s390_builtin_ov_types[last_match_fntype_index][0]];\n+\n+  /* Check for the operand flags in the overloaded builtin variant.  */\n+  for (i = 0; i < ob_args_num; i++)\n+    {\n+      unsigned int op_flags = all_op_flags & ((1 << O_SHIFT) - 1);\n+      tree arg = (*arglist)[i];\n+      tree type = s390_builtin_types[s390_builtin_ov_types[last_match_fntype_index][i + 1]];\n+\n+      all_op_flags = all_op_flags >> O_SHIFT;\n+\n+      if (op_flags == O_ELEM)\n+\t{\n+\t  int n_elem = s390_vec_n_elem (target_builtin_decl);\n+\t  gcc_assert (n_elem > 0);\n+\t  gcc_assert (type == integer_type_node);\n+\t  (*arglist)[i] = build2 (BIT_AND_EXPR, integer_type_node,\n+\t\t\t\t  fold_convert (integer_type_node, arg),\n+\t\t\t\t  build_int_cst (NULL_TREE, n_elem - 1));\n+\t}\n+\n+      if (TREE_CODE (arg) != INTEGER_CST || !O_IMM_P (op_flags))\n+\tcontinue;\n+\n+      if ((TYPE_UNSIGNED (type)\n+\t   && !int_fits_type_p (arg, c_common_unsigned_type (type)))\n+\t  || (!TYPE_UNSIGNED (type)\n+\t      && !int_fits_type_p (arg, c_common_signed_type (type))))\n+\t{\n+\t  error(\"constant argument %d for builtin %qF is out \"\n+\t\t\"of range for target type\",\n+\t\ti + 1, target_builtin_decl);\n+\t  return error_mark_node;\n+\t}\n+\n+      if (TREE_CODE (arg) == INTEGER_CST\n+\t  && !s390_const_operand_ok (arg, i + 1, op_flags, target_builtin_decl))\n+\treturn error_mark_node;\n+    }\n+\n+  /* Handle builtins we expand directly - without mapping it to a low\n+     level builtin.  */\n+  if (bt_for_overloaded_builtin_var[last_match_index] == S390_BUILTIN_MAX)\n+    return s390_expand_overloaded_builtin (loc, ob_fcode, arglist, return_type);\n+\n+  s390_adjust_builtin_arglist (ob_fcode, target_builtin_decl, &arglist);\n+\n+  if (VOID_TYPE_P (return_type))\n+    return build_function_call_vec (loc, vNULL, target_builtin_decl,\n+\t\t\t\t    arglist, NULL);\n+  else\n+    return fully_fold_convert (return_type,\n+\t\t\t       build_function_call_vec (loc, vNULL, target_builtin_decl,\n+\t\t\t\t\t\t\targlist, NULL));\n+}\n+\n+/* This is used to define the REGISTER_TARGET_PRAGMAS macro in s390.h.  */\n+void\n+s390_register_target_pragmas (void)\n+{\n+  targetm.resolve_overloaded_builtin = s390_resolve_overloaded_builtin;\n+}"}, {"sha": "f4c53f82552865b7dfde053671c2baaaa2c24d6b", "filename": "gcc/config/s390/s390-modes.def", "status": "modified", "additions": 30, "deletions": 0, "changes": 30, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390-modes.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390-modes.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Fs390-modes.def?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1", "patch": "@@ -87,9 +87,21 @@ CCA                       -> CCAP, CCAN\n Vector comparison modes\n \n CCVEQ  \t  EQ\t  - \t       - \t   NE\t      (VCEQ)\n+CCVEQANY  EQ\t  EQ\t       - \t   NE\t      (VCEQ)\n+\n+CCVH\t  GT\t  - \t       - \t   LE\t      (VCH)\n+CCVHANY\t  GT\t  GT\t       - \t   LE\t      (VCH)\n+CCVHU\t  GTU\t  -  \t       -  \t   LEU\t      (VCHL)\n+CCVHUANY  GTU\t  GTU\t       -  \t   LEU\t      (VCHL)\n \n CCVFH\t  GT\t  -   \t       -   \t   UNLE\t      (VFCH)\n+CCVFHANY  GT\t  GT\t       -   \t   UNLE\t      (VFCH)\n CCVFHE\t  GE\t  -   \t       -   \t   UNLT\t      (VFCHE)\n+CCVFHEANY GE\t  GE\t       -   \t   UNLT\t      (VFCHE)\n+\n+\n+\n+\n *** Comments ***\n \n CCAP, CCAN\n@@ -157,6 +169,15 @@ The compare and swap instructions sets the condition code to 0/1 if the\n operands were equal/unequal. The CCZ1 mode ensures the result can be\n effectively placed into a register.\n \n+\n+CCV*\n+\n+The variants with and without ANY are generated by the same\n+instructions and therefore are holding the same information.  However,\n+when generating a condition code mask they require checking different\n+bits of CC.  In that case the variants without ANY represent the\n+results for *all* elements.\n+\n CCRAW\n \n The cc mode generated by a non-compare instruction.  The condition\n@@ -188,8 +209,17 @@ CC_MODE (CCT3);\n CC_MODE (CCRAW);\n \n CC_MODE (CCVEQ);\n+CC_MODE (CCVEQANY);\n+\n+CC_MODE (CCVH);\n+CC_MODE (CCVHANY);\n+CC_MODE (CCVHU);\n+CC_MODE (CCVHUANY);\n+\n CC_MODE (CCVFH);\n+CC_MODE (CCVFHANY);\n CC_MODE (CCVFHE);\n+CC_MODE (CCVFHEANY);\n \n \n /* Vector modes.  */"}, {"sha": "a8b885476ddf21ed27b20b673a93f305899cead9", "filename": "gcc/config/s390/s390-protos.h", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Fs390-protos.h?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1", "patch": "@@ -97,6 +97,7 @@ extern void s390_expand_atomic (machine_mode, enum rtx_code,\n \t\t\t\trtx, rtx, rtx, bool);\n extern void s390_expand_tbegin (rtx, rtx, rtx, bool);\n extern void s390_expand_vec_compare (rtx, enum rtx_code, rtx, rtx);\n+extern void s390_expand_vec_compare_cc (rtx, enum rtx_code, rtx, rtx, bool);\n extern void s390_expand_vcond (rtx, rtx, rtx, enum rtx_code, rtx, rtx);\n extern void s390_expand_vec_init (rtx, rtx);\n extern rtx s390_return_addr_rtx (int, rtx);\n@@ -124,3 +125,10 @@ extern bool s390_extzv_shift_ok (int, int, unsigned HOST_WIDE_INT);\n extern void s390_asm_output_function_label (FILE *, const char *, tree);\n \n #endif /* RTX_CODE */\n+\n+/* s390-c.c routines */\n+extern void s390_cpu_cpp_builtins (struct cpp_reader *);\n+extern void s390_register_target_pragmas (void);\n+\n+/* Routines for s390-c.c */\n+extern bool s390_const_operand_ok (tree, int, int, tree);"}, {"sha": "7fd5969941043a628a5a7bc9f016a2d5c489886e", "filename": "gcc/config/s390/s390.c", "status": "modified", "additions": 592, "deletions": 239, "changes": 831, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Fs390.c?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1", "patch": "@@ -465,6 +465,398 @@ struct GTY(()) machine_function\n    bytes on a z10 (or higher) CPU.  */\n #define PREDICT_DISTANCE (TARGET_Z10 ? 384 : 2048)\n \n+\n+/* System z builtins.  */\n+\n+#include \"s390-builtins.h\"\n+\n+const unsigned int flags_builtin[S390_BUILTIN_MAX + 1] =\n+  {\n+#undef B_DEF\n+#undef OB_DEF\n+#undef OB_DEF_VAR\n+#define B_DEF(NAME, PATTERN, ATTRS, FLAGS, FNTYPE) FLAGS,\n+#define OB_DEF(...)\n+#define OB_DEF_VAR(...)\n+#include \"s390-builtins.def\"\n+    0\n+  };\n+\n+const unsigned int flags_overloaded_builtin_var[S390_OVERLOADED_BUILTIN_VAR_MAX + 1] =\n+  {\n+#undef B_DEF\n+#undef OB_DEF\n+#undef OB_DEF_VAR\n+#define B_DEF(...)\n+#define OB_DEF(...)\n+#define OB_DEF_VAR(NAME, PATTERN, FLAGS, FNTYPE) FLAGS,\n+#include \"s390-builtins.def\"\n+    0\n+  };\n+\n+tree s390_builtin_types[BT_MAX];\n+tree s390_builtin_fn_types[BT_FN_MAX];\n+tree s390_builtin_decls[S390_BUILTIN_MAX +\n+\t\t\tS390_OVERLOADED_BUILTIN_MAX +\n+\t\t\tS390_OVERLOADED_BUILTIN_VAR_MAX];\n+\n+static enum insn_code const code_for_builtin[S390_BUILTIN_MAX + 1] = {\n+#undef B_DEF\n+#undef OB_DEF\n+#undef OB_DEF_VAR\n+#define B_DEF(NAME, PATTERN, ...) CODE_FOR_##PATTERN,\n+#define OB_DEF(...)\n+#define OB_DEF_VAR(...)\n+\n+#include \"s390-builtins.def\"\n+  CODE_FOR_nothing\n+};\n+\n+static void\n+s390_init_builtins (void)\n+{\n+  /* These definitions are being used in s390-builtins.def.  */\n+  tree returns_twice_attr = tree_cons (get_identifier (\"returns_twice\"),\n+\t\t\t\t       NULL, NULL);\n+  tree noreturn_attr = tree_cons (get_identifier (\"noreturn\"), NULL, NULL);\n+  tree c_uint64_type_node;\n+\n+  /* The uint64_type_node from tree.c is not compatible to the C99\n+     uint64_t data type.  What we want is c_uint64_type_node from\n+     c-common.c.  But since backend code is not supposed to interface\n+     with the frontend we recreate it here.  */\n+  if (TARGET_64BIT)\n+    c_uint64_type_node = long_unsigned_type_node;\n+  else\n+    c_uint64_type_node = long_long_unsigned_type_node;\n+\n+#undef DEF_TYPE\n+#define DEF_TYPE(INDEX, NODE, CONST_P)\t\t\t\\\n+  s390_builtin_types[INDEX] = (!CONST_P) ?\t\t\\\n+    (NODE) : build_type_variant ((NODE), 1, 0);\n+\n+#undef DEF_POINTER_TYPE\n+#define DEF_POINTER_TYPE(INDEX, INDEX_BASE)\t\t\t\t\\\n+  s390_builtin_types[INDEX] =\t\t\t\t\t\t\\\n+    build_pointer_type (s390_builtin_types[INDEX_BASE]);\n+\n+#undef DEF_DISTINCT_TYPE\n+#define DEF_DISTINCT_TYPE(INDEX, INDEX_BASE)\t\t\t\t\\\n+  s390_builtin_types[INDEX] =\t\t\t\t\t\t\\\n+    build_distinct_type_copy (s390_builtin_types[INDEX_BASE]);\n+\n+#undef DEF_VECTOR_TYPE\n+#define DEF_VECTOR_TYPE(INDEX, INDEX_BASE, ELEMENTS)\t\t\t\\\n+  s390_builtin_types[INDEX] =\t\t\t\t\t\t\\\n+    build_vector_type (s390_builtin_types[INDEX_BASE], ELEMENTS);\n+\n+#undef DEF_OPAQUE_VECTOR_TYPE\n+#define DEF_OPAQUE_VECTOR_TYPE(INDEX, INDEX_BASE, ELEMENTS)\t\t\\\n+  s390_builtin_types[INDEX] =\t\t\t\t\t\t\\\n+    build_opaque_vector_type (s390_builtin_types[INDEX_BASE], ELEMENTS);\n+\n+#undef DEF_FN_TYPE\n+#define DEF_FN_TYPE(INDEX, args...)\t\t\t\t\\\n+  s390_builtin_fn_types[INDEX] =\t\t\t\t\\\n+    build_function_type_list (args, NULL_TREE);\n+#undef DEF_OV_TYPE\n+#define DEF_OV_TYPE(...)\n+#include \"s390-builtin-types.def\"\n+\n+#undef B_DEF\n+#define B_DEF(NAME, PATTERN, ATTRS, FLAGS, FNTYPE)\t\t\t\\\n+  s390_builtin_decls[S390_BUILTIN_##NAME] =\t\t\t\t\\\n+  add_builtin_function (\"__builtin_\" #NAME,\t\t\t\t\\\n+\t\t\ts390_builtin_fn_types[FNTYPE],\t\t\t\\\n+\t\t\tS390_BUILTIN_##NAME,\t\t\t\t\\\n+\t\t\tBUILT_IN_MD,\t\t\t\t\t\\\n+\t\t\tNULL,\t\t\t\t\t\t\\\n+\t\t\tATTRS);\n+#undef OB_DEF\n+#define OB_DEF(NAME, FIRST_VAR_NAME, LAST_VAR_NAME, FNTYPE)\t\t\\\n+  s390_builtin_decls[S390_OVERLOADED_BUILTIN_##NAME + S390_BUILTIN_MAX] = \\\n+  add_builtin_function (\"__builtin_\" #NAME,\t\t\t\t\\\n+\t\t\ts390_builtin_fn_types[FNTYPE],\t\t\t\\\n+\t\t\tS390_OVERLOADED_BUILTIN_##NAME + S390_BUILTIN_MAX, \\\n+\t\t\tBUILT_IN_MD,\t\t\t\t\t\\\n+\t\t\tNULL,\t\t\t\t\t\t\\\n+\t\t\t0);\n+#undef OB_DEF_VAR\n+#define OB_DEF_VAR(...)\n+#include \"s390-builtins.def\"\n+\n+}\n+\n+/* Return true if ARG is appropriate as argument number ARGNUM of\n+   builtin DECL.  The operand flags from s390-builtins.def have to\n+   passed as OP_FLAGS.  */\n+bool\n+s390_const_operand_ok (tree arg, int argnum, int op_flags, tree decl)\n+{\n+  if (O_UIMM_P (op_flags))\n+    {\n+      int bitwidths[] = { 1, 2, 3, 4, 5, 8, 12, 16, 32 };\n+      int bitwidth = bitwidths[op_flags - O_U1];\n+\n+      if (!tree_fits_uhwi_p (arg)\n+\t  || tree_to_uhwi (arg) > ((unsigned HOST_WIDE_INT)1 << bitwidth) - 1)\n+\t{\n+\t  error(\"constant argument %d for builtin %qF is out of range (0..\"\n+\t\tHOST_WIDE_INT_PRINT_UNSIGNED \")\",\n+\t\targnum, decl,\n+\t\t((unsigned HOST_WIDE_INT)1 << bitwidth) - 1);\n+\t  return false;\n+\t}\n+    }\n+\n+  if (O_SIMM_P (op_flags))\n+    {\n+      int bitwidths[] = { 2, 3, 4, 5, 8, 12, 16, 32 };\n+      int bitwidth = bitwidths[op_flags - O_S2];\n+\n+      if (!tree_fits_shwi_p (arg)\n+\t  || tree_to_shwi (arg) < -((HOST_WIDE_INT)1 << (bitwidth - 1))\n+\t  || tree_to_shwi (arg) > (((HOST_WIDE_INT)1 << (bitwidth - 1)) - 1))\n+\t{\n+\t  error(\"constant argument %d for builtin %qF is out of range (\"\n+\t\tHOST_WIDE_INT_PRINT_DEC \"..\"\n+\t\tHOST_WIDE_INT_PRINT_DEC \")\",\n+\t\targnum, decl,\n+\t\t-(HOST_WIDE_INT)1 << (bitwidth - 1),\n+\t\t((HOST_WIDE_INT)1 << (bitwidth - 1)) - 1);\n+\t  return false;\n+\t}\n+    }\n+  return true;\n+}\n+\n+/* Expand an expression EXP that calls a built-in function,\n+   with result going to TARGET if that's convenient\n+   (and in mode MODE if that's convenient).\n+   SUBTARGET may be used as the target for computing one of EXP's operands.\n+   IGNORE is nonzero if the value is to be ignored.  */\n+\n+static rtx\n+s390_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n+\t\t     machine_mode mode ATTRIBUTE_UNUSED,\n+\t\t     int ignore ATTRIBUTE_UNUSED)\n+{\n+#define MAX_ARGS 5\n+\n+  tree fndecl = TREE_OPERAND (CALL_EXPR_FN (exp), 0);\n+  unsigned int fcode = DECL_FUNCTION_CODE (fndecl);\n+  enum insn_code icode;\n+  rtx op[MAX_ARGS], pat;\n+  int arity;\n+  bool nonvoid;\n+  tree arg;\n+  call_expr_arg_iterator iter;\n+  unsigned int all_op_flags = flags_for_builtin (fcode);\n+  machine_mode last_vec_mode = VOIDmode;\n+\n+  if (TARGET_DEBUG_ARG)\n+    {\n+      fprintf (stderr,\n+\t       \"s390_expand_builtin, code = %4d, %s\\n\",\n+\t       (int)fcode, IDENTIFIER_POINTER (DECL_NAME (fndecl)));\n+    }\n+\n+\n+  if (fcode >= S390_OVERLOADED_BUILTIN_VAR_OFFSET\n+      && fcode < S390_ALL_BUILTIN_MAX)\n+    {\n+      gcc_unreachable ();\n+    }\n+  else if (fcode < S390_OVERLOADED_BUILTIN_OFFSET)\n+    {\n+      icode = code_for_builtin[fcode];\n+      /* Set a flag in the machine specific cfun part in order to support\n+\t saving/restoring of FPRs.  */\n+      if (fcode == S390_BUILTIN_tbegin || fcode == S390_BUILTIN_tbegin_retry)\n+\tcfun->machine->tbegin_p = true;\n+    }\n+  else if (fcode < S390_OVERLOADED_BUILTIN_VAR_OFFSET)\n+    {\n+      error (\"Unresolved overloaded builtin\");\n+      return const0_rtx;\n+    }\n+  else\n+    internal_error (\"bad builtin fcode\");\n+\n+  if (icode == 0)\n+    internal_error (\"bad builtin icode\");\n+\n+  nonvoid = TREE_TYPE (TREE_TYPE (fndecl)) != void_type_node;\n+\n+  if (nonvoid)\n+    {\n+      machine_mode tmode = insn_data[icode].operand[0].mode;\n+      if (!target\n+\t  || GET_MODE (target) != tmode\n+\t  || !(*insn_data[icode].operand[0].predicate) (target, tmode))\n+\ttarget = gen_reg_rtx (tmode);\n+\n+      /* There are builtins (e.g. vec_promote) with no vector\n+\t arguments but an element selector.  So we have to also look\n+\t at the vector return type when emitting the modulo\n+\t operation.  */\n+      if (VECTOR_MODE_P (insn_data[icode].operand[0].mode))\n+\tlast_vec_mode = insn_data[icode].operand[0].mode;\n+    }\n+\n+  arity = 0;\n+  FOR_EACH_CALL_EXPR_ARG (arg, iter, exp)\n+    {\n+      const struct insn_operand_data *insn_op;\n+      unsigned int op_flags = all_op_flags & ((1 << O_SHIFT) - 1);\n+\n+      all_op_flags = all_op_flags >> O_SHIFT;\n+\n+      if (arg == error_mark_node)\n+\treturn NULL_RTX;\n+      if (arity >= MAX_ARGS)\n+\treturn NULL_RTX;\n+\n+      if (O_IMM_P (op_flags)\n+\t  && TREE_CODE (arg) != INTEGER_CST)\n+\t{\n+\t  error (\"constant value required for builtin %qF argument %d\",\n+\t\t fndecl, arity + 1);\n+\t  return const0_rtx;\n+\t}\n+\n+      if (!s390_const_operand_ok (arg, arity + 1, op_flags, fndecl))\n+\treturn const0_rtx;\n+\n+      insn_op = &insn_data[icode].operand[arity + nonvoid];\n+      op[arity] = expand_expr (arg, NULL_RTX, insn_op->mode, EXPAND_NORMAL);\n+\n+      /* Wrap the expanded RTX for pointer types into a MEM expr with\n+\t the proper mode.  This allows us to use e.g. (match_operand\n+\t \"memory_operand\"..) in the insn patterns instead of (mem\n+\t (match_operand \"address_operand)).  This is helpful for\n+\t patterns not just accepting MEMs.  */\n+      if (POINTER_TYPE_P (TREE_TYPE (arg))\n+\t  && insn_op->predicate != address_operand)\n+\top[arity] = gen_rtx_MEM (insn_op->mode, op[arity]);\n+\n+      /* Expand the module operation required on element selectors.  */\n+      if (op_flags == O_ELEM)\n+\t{\n+\t  gcc_assert (last_vec_mode != VOIDmode);\n+\t  op[arity] = simplify_expand_binop (SImode, code_to_optab (AND),\n+\t\t\t\t\t     op[arity],\n+\t\t\t\t\t     GEN_INT (GET_MODE_NUNITS (last_vec_mode) - 1),\n+\t\t\t\t\t     NULL_RTX, 1, OPTAB_DIRECT);\n+\t}\n+\n+      /* Record the vector mode used for an element selector.  This assumes:\n+\t 1. There is no builtin with two different vector modes and an element selector\n+         2. The element selector comes after the vector type it is referring to.\n+\t This currently the true for all the builtins but FIXME we\n+\t should better check for that.  */\n+      if (VECTOR_MODE_P (insn_op->mode))\n+\tlast_vec_mode = insn_op->mode;\n+\n+      if (insn_op->predicate (op[arity], insn_op->mode))\n+\t{\n+\t  arity++;\n+\t  continue;\n+\t}\n+\n+      if (MEM_P (op[arity])\n+\t  && insn_op->predicate == memory_operand\n+\t  && (GET_MODE (XEXP (op[arity], 0)) == Pmode\n+\t      || GET_MODE (XEXP (op[arity], 0)) == VOIDmode))\n+\t{\n+\t  op[arity] = replace_equiv_address (op[arity],\n+\t\t\t\t\t     copy_to_mode_reg (Pmode,\n+\t\t\t\t\t       XEXP (op[arity], 0)));\n+\t}\n+      else if (GET_MODE (op[arity]) == insn_op->mode\n+\t       || GET_MODE (op[arity]) == VOIDmode\n+\t       || (insn_op->predicate == address_operand\n+\t\t   && GET_MODE (op[arity]) == Pmode))\n+\t{\n+\t  /* An address_operand usually has VOIDmode in the expander\n+\t     so we cannot use this.  */\n+\t  machine_mode target_mode =\n+\t    (insn_op->predicate == address_operand\n+\t     ? Pmode : insn_op->mode);\n+\t  op[arity] = copy_to_mode_reg (target_mode, op[arity]);\n+\t}\n+\n+      if (!insn_op->predicate (op[arity], insn_op->mode))\n+\t{\n+\t  error (\"Invalid argument %d for builtin %qF\", arity + 1, fndecl);\n+\t  return const0_rtx;\n+\t}\n+      arity++;\n+    }\n+\n+  if (last_vec_mode != VOIDmode && !TARGET_VX)\n+    {\n+      error (\"Vector type builtin %qF is not supported without -mvx \"\n+\t     \"(default with -march=z13).\",\n+\t     fndecl);\n+      return const0_rtx;\n+    }\n+\n+  switch (arity)\n+    {\n+    case 0:\n+      pat = GEN_FCN (icode) (target);\n+      break;\n+    case 1:\n+      if (nonvoid)\n+        pat = GEN_FCN (icode) (target, op[0]);\n+      else\n+\tpat = GEN_FCN (icode) (op[0]);\n+      break;\n+    case 2:\n+      if (nonvoid)\n+\tpat = GEN_FCN (icode) (target, op[0], op[1]);\n+      else\n+\tpat = GEN_FCN (icode) (op[0], op[1]);\n+      break;\n+    case 3:\n+      if (nonvoid)\n+\tpat = GEN_FCN (icode) (target, op[0], op[1], op[2]);\n+      else\n+\tpat = GEN_FCN (icode) (op[0], op[1], op[2]);\n+      break;\n+    case 4:\n+      if (nonvoid)\n+\tpat = GEN_FCN (icode) (target, op[0], op[1], op[2], op[3]);\n+      else\n+\tpat = GEN_FCN (icode) (op[0], op[1], op[2], op[3]);\n+      break;\n+    case 5:\n+      if (nonvoid)\n+\tpat = GEN_FCN (icode) (target, op[0], op[1], op[2], op[3], op[4]);\n+      else\n+\tpat = GEN_FCN (icode) (op[0], op[1], op[2], op[3], op[4]);\n+      break;\n+    case 6:\n+      if (nonvoid)\n+\tpat = GEN_FCN (icode) (target, op[0], op[1], op[2], op[3], op[4], op[5]);\n+      else\n+\tpat = GEN_FCN (icode) (op[0], op[1], op[2], op[3], op[4], op[5]);\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+  if (!pat)\n+    return NULL_RTX;\n+  emit_insn (pat);\n+\n+  if (nonvoid)\n+    return target;\n+  else\n+    return const0_rtx;\n+}\n+\n+\n static const int s390_hotpatch_hw_max = 1000000;\n static int s390_hotpatch_hw_before_label = 0;\n static int s390_hotpatch_hw_after_label = 0;\n@@ -514,9 +906,43 @@ s390_handle_hotpatch_attribute (tree *node, tree name, tree args,\n   return NULL_TREE;\n }\n \n+/* Expand the s390_vector_bool type attribute.  */\n+\n+static tree\n+s390_handle_vectorbool_attribute (tree *node, tree name ATTRIBUTE_UNUSED,\n+\t\t\t\t  tree args ATTRIBUTE_UNUSED,\n+\t\t\t\t  int flags ATTRIBUTE_UNUSED, bool *no_add_attrs)\n+{\n+  tree type = *node, result = NULL_TREE;\n+  machine_mode mode;\n+\n+  while (POINTER_TYPE_P (type)\n+\t || TREE_CODE (type) == FUNCTION_TYPE\n+\t || TREE_CODE (type) == METHOD_TYPE\n+\t || TREE_CODE (type) == ARRAY_TYPE)\n+    type = TREE_TYPE (type);\n+\n+  mode = TYPE_MODE (type);\n+  switch (mode)\n+    {\n+    case DImode: case V2DImode: result = s390_builtin_types[BT_BV2DI]; break;\n+    case SImode: case V4SImode: result = s390_builtin_types[BT_BV4SI]; break;\n+    case HImode: case V8HImode: result = s390_builtin_types[BT_BV8HI]; break;\n+    case QImode: case V16QImode: result = s390_builtin_types[BT_BV16QI];\n+    default: break;\n+    }\n+\n+  *no_add_attrs = true;  /* No need to hang on to the attribute.  */\n+\n+  if (result)\n+    *node = lang_hooks.types.reconstruct_complex_type (*node, result);\n+\n+  return NULL_TREE;\n+}\n+\n static const struct attribute_spec s390_attribute_table[] = {\n-  { \"hotpatch\", 2, 2, true, false, false, s390_handle_hotpatch_attribute, false\n-  },\n+  { \"hotpatch\", 2, 2, true, false, false, s390_handle_hotpatch_attribute, false },\n+  { \"s390_vector_bool\", 0, 0, false, true, false, s390_handle_vectorbool_attribute, true },\n   /* End element.  */\n   { NULL,        0, 0, false, false, false, NULL, false }\n };\n@@ -682,6 +1108,8 @@ s390_match_ccmode_set (rtx set, machine_mode req_mode)\n     case CCT2mode:\n     case CCT3mode:\n     case CCVEQmode:\n+    case CCVHmode:\n+    case CCVHUmode:\n     case CCVFHmode:\n     case CCVFHEmode:\n       if (req_mode != set_mode)\n@@ -1416,6 +1844,49 @@ s390_branch_condition_mask (rtx code)\n \tcase NE:        return CC3;\n \tdefault:        return -1;\n \t}\n+\n+    case CCVEQANYmode:\n+      switch (GET_CODE (code))\n+\t{\n+\tcase EQ:        return CC0 | CC1;\n+\tcase NE:        return CC3 | CC1;\n+\tdefault:        return -1;\n+\t}\n+\n+      /* Integer vector compare modes.  */\n+\n+    case CCVHmode:\n+      switch (GET_CODE (code))\n+\t{\n+\tcase GT:        return CC0;\n+\tcase LE:        return CC3;\n+\tdefault:        return -1;\n+\t}\n+\n+    case CCVHANYmode:\n+      switch (GET_CODE (code))\n+\t{\n+\tcase GT:        return CC0 | CC1;\n+\tcase LE:        return CC3 | CC1;\n+\tdefault:        return -1;\n+\t}\n+\n+    case CCVHUmode:\n+      switch (GET_CODE (code))\n+\t{\n+\tcase GTU:       return CC0;\n+\tcase LEU:       return CC3;\n+\tdefault:        return -1;\n+\t}\n+\n+    case CCVHUANYmode:\n+      switch (GET_CODE (code))\n+\t{\n+\tcase GTU:       return CC0 | CC1;\n+\tcase LEU:       return CC3 | CC1;\n+\tdefault:        return -1;\n+\t}\n+\n       /* FP vector compare modes.  */\n \n     case CCVFHmode:\n@@ -1425,13 +1896,32 @@ s390_branch_condition_mask (rtx code)\n \tcase UNLE:      return CC3;\n \tdefault:        return -1;\n \t}\n+\n+    case CCVFHANYmode:\n+      switch (GET_CODE (code))\n+\t{\n+\tcase GT:        return CC0 | CC1;\n+\tcase UNLE:      return CC3 | CC1;\n+\tdefault:        return -1;\n+\t}\n+\n     case CCVFHEmode:\n       switch (GET_CODE (code))\n \t{\n \tcase GE:        return CC0;\n \tcase UNLT:      return CC3;\n \tdefault:        return -1;\n \t}\n+\n+    case CCVFHEANYmode:\n+      switch (GET_CODE (code))\n+\t{\n+\tcase GE:        return CC0 | CC1;\n+\tcase UNLT:      return CC3 | CC1;\n+\tdefault:        return -1;\n+\t}\n+\n+\n     case CCRAWmode:\n       switch (GET_CODE (code))\n \t{\n@@ -5359,6 +5849,93 @@ s390_expand_vec_compare (rtx target, enum rtx_code cond,\n     emit_insn (gen_rtx_SET (target, gen_rtx_NOT (mode, target)));\n }\n \n+/* Expand the comparison CODE of CMP1 and CMP2 and copy 1 or 0 into\n+   TARGET if either all (ALL_P is true) or any (ALL_P is false) of the\n+   elements in CMP1 and CMP2 fulfill the comparison.  */\n+void\n+s390_expand_vec_compare_cc (rtx target, enum rtx_code code,\n+\t\t\t    rtx cmp1, rtx cmp2, bool all_p)\n+{\n+  enum rtx_code new_code = code;\n+  machine_mode cmp_mode, full_cmp_mode, scratch_mode;\n+  rtx tmp_reg = gen_reg_rtx (SImode);\n+  bool swap_p = false;\n+\n+  if (GET_MODE_CLASS (GET_MODE (cmp1)) == MODE_VECTOR_INT)\n+    {\n+      switch (code)\n+\t{\n+\tcase EQ:  cmp_mode = CCVEQmode; break;\n+\tcase NE:  cmp_mode = CCVEQmode; break;\n+\tcase GT:  cmp_mode = CCVHmode;  break;\n+\tcase GE:  cmp_mode = CCVHmode;  new_code = LE; swap_p = true; break;\n+\tcase LT:  cmp_mode = CCVHmode;  new_code = GT; swap_p = true; break;\n+\tcase LE:  cmp_mode = CCVHmode;  new_code = LE; break;\n+\tcase GTU: cmp_mode = CCVHUmode; break;\n+\tcase GEU: cmp_mode = CCVHUmode; new_code = LEU; swap_p = true; break;\n+\tcase LTU: cmp_mode = CCVHUmode; new_code = GTU; swap_p = true; break;\n+\tcase LEU: cmp_mode = CCVHUmode; new_code = LEU; break;\n+\tdefault: gcc_unreachable ();\n+\t}\n+      scratch_mode = GET_MODE (cmp1);\n+    }\n+  else if (GET_MODE (cmp1) == V2DFmode)\n+    {\n+      switch (code)\n+\t{\n+\tcase EQ:   cmp_mode = CCVEQmode;  break;\n+\tcase NE:   cmp_mode = CCVEQmode;  break;\n+\tcase GT:   cmp_mode = CCVFHmode;  break;\n+\tcase GE:   cmp_mode = CCVFHEmode; break;\n+\tcase UNLE: cmp_mode = CCVFHmode;  break;\n+\tcase UNLT: cmp_mode = CCVFHEmode; break;\n+\tcase LT:   cmp_mode = CCVFHmode;  new_code = GT; swap_p = true; break;\n+\tcase LE:   cmp_mode = CCVFHEmode; new_code = GE; swap_p = true; break;\n+\tdefault: gcc_unreachable ();\n+\t}\n+      scratch_mode = V2DImode;\n+    }\n+  else\n+    gcc_unreachable ();\n+\n+  if (!all_p)\n+    switch (cmp_mode)\n+      {\n+      case CCVEQmode:  full_cmp_mode = CCVEQANYmode;  break;\n+      case CCVHmode:   full_cmp_mode = CCVHANYmode;   break;\n+      case CCVHUmode:  full_cmp_mode = CCVHUANYmode;  break;\n+      case CCVFHmode:  full_cmp_mode = CCVFHANYmode;  break;\n+      case CCVFHEmode: full_cmp_mode = CCVFHEANYmode; break;\n+      default: gcc_unreachable ();\n+      }\n+  else\n+    /* The modes without ANY match the ALL modes.  */\n+    full_cmp_mode = cmp_mode;\n+\n+  if (swap_p)\n+    {\n+      rtx tmp = cmp2;\n+      cmp2 = cmp1;\n+      cmp1 = tmp;\n+    }\n+\n+  emit_insn (gen_rtx_PARALLEL (VOIDmode,\n+\t       gen_rtvec (2, gen_rtx_SET (\n+\t\t\t       gen_rtx_REG (cmp_mode, CC_REGNUM),\n+\t\t\t       gen_rtx_COMPARE (cmp_mode, cmp1, cmp2)),\n+\t\t\t  gen_rtx_CLOBBER (VOIDmode,\n+\t\t\t\t\t   gen_rtx_SCRATCH (scratch_mode)))));\n+  emit_move_insn (target, const0_rtx);\n+  emit_move_insn (tmp_reg, const1_rtx);\n+\n+  emit_move_insn (target,\n+\t\t  gen_rtx_IF_THEN_ELSE (SImode,\n+\t\t    gen_rtx_fmt_ee (new_code, VOIDmode,\n+\t\t\t\t    gen_rtx_REG (full_cmp_mode, CC_REGNUM),\n+\t\t\t\t    const0_rtx),\n+\t\t      target, tmp_reg));\n+}\n+\n /* Generate a vector comparison expression loading either elements of\n    THEN or ELS into TARGET depending on the comparison COND of CMP_OP1\n    and CMP_OP2.  */\n@@ -5805,6 +6382,17 @@ s390_dwarf_frame_reg_mode (int regno)\n static const char *\n s390_mangle_type (const_tree type)\n {\n+  type = TYPE_MAIN_VARIANT (type);\n+\n+  if (TREE_CODE (type) != VOID_TYPE && TREE_CODE (type) != BOOLEAN_TYPE\n+      && TREE_CODE (type) != INTEGER_TYPE && TREE_CODE (type) != REAL_TYPE)\n+    return NULL;\n+\n+  if (type == s390_builtin_types[BT_BV16QI]) return \"U6__boolc\";\n+  if (type == s390_builtin_types[BT_BV8HI]) return \"U6__bools\";\n+  if (type == s390_builtin_types[BT_BV4SI]) return \"U6__booli\";\n+  if (type == s390_builtin_types[BT_BV2DI]) return \"U6__booll\";\n+\n   if (TYPE_MAIN_VARIANT (type) == long_double_type_node\n       && TARGET_LONG_DOUBLE_128)\n     return \"g\";\n@@ -10934,241 +11522,6 @@ s390_expand_tbegin (rtx dest, rtx tdb, rtx retry, bool clobber_fprs_p)\n     }\n }\n \n-/* Builtins.  */\n-\n-enum s390_builtin\n-{\n-  S390_BUILTIN_TBEGIN,\n-  S390_BUILTIN_TBEGIN_NOFLOAT,\n-  S390_BUILTIN_TBEGIN_RETRY,\n-  S390_BUILTIN_TBEGIN_RETRY_NOFLOAT,\n-  S390_BUILTIN_TBEGINC,\n-  S390_BUILTIN_TEND,\n-  S390_BUILTIN_TABORT,\n-  S390_BUILTIN_NON_TX_STORE,\n-  S390_BUILTIN_TX_NESTING_DEPTH,\n-  S390_BUILTIN_TX_ASSIST,\n-\n-  S390_BUILTIN_S390_SFPC,\n-  S390_BUILTIN_S390_EFPC,\n-\n-  S390_BUILTIN_MAX\n-};\n-\n-tree s390_builtin_decls[S390_BUILTIN_MAX];\n-\n-static enum insn_code const code_for_builtin[S390_BUILTIN_MAX] = {\n-  CODE_FOR_tbegin,\n-  CODE_FOR_tbegin_nofloat,\n-  CODE_FOR_tbegin_retry,\n-  CODE_FOR_tbegin_retry_nofloat,\n-  CODE_FOR_tbeginc,\n-  CODE_FOR_tend,\n-  CODE_FOR_tabort,\n-  CODE_FOR_ntstg,\n-  CODE_FOR_etnd,\n-  CODE_FOR_tx_assist,\n-\n-  CODE_FOR_s390_sfpc,\n-  CODE_FOR_s390_efpc\n-};\n-\n-static void\n-s390_init_builtins (void)\n-{\n-  tree ftype, uint64_type;\n-  tree returns_twice_attr = tree_cons (get_identifier (\"returns_twice\"),\n-\t\t\t\t       NULL, NULL);\n-  tree noreturn_attr = tree_cons (get_identifier (\"noreturn\"), NULL, NULL);\n-\n-  /* void foo (void) */\n-  ftype = build_function_type_list (void_type_node, NULL_TREE);\n-  s390_builtin_decls[S390_BUILTIN_TBEGINC] =\n-    add_builtin_function (\"__builtin_tbeginc\", ftype, S390_BUILTIN_TBEGINC,\n-\t\t\t  BUILT_IN_MD, NULL, NULL_TREE);\n-\n-  /* void foo (int) */\n-  ftype = build_function_type_list (void_type_node, integer_type_node,\n-\t\t\t\t    NULL_TREE);\n-  s390_builtin_decls[S390_BUILTIN_TABORT] =\n-    add_builtin_function (\"__builtin_tabort\", ftype,\n-\t\t\t  S390_BUILTIN_TABORT, BUILT_IN_MD, NULL,\n-\t\t\t  noreturn_attr);\n-  s390_builtin_decls[S390_BUILTIN_TX_ASSIST] =\n-    add_builtin_function (\"__builtin_tx_assist\", ftype,\n-\t\t\t  S390_BUILTIN_TX_ASSIST, BUILT_IN_MD, NULL, NULL_TREE);\n-\n-  /* void foo (unsigned) */\n-  ftype = build_function_type_list (void_type_node, unsigned_type_node,\n-\t\t\t\t    NULL_TREE);\n-  s390_builtin_decls[S390_BUILTIN_S390_SFPC] =\n-    add_builtin_function (\"__builtin_s390_sfpc\", ftype,\n-\t\t\t  S390_BUILTIN_S390_SFPC, BUILT_IN_MD, NULL, NULL_TREE);\n-\n-  /* int foo (void *) */\n-  ftype = build_function_type_list (integer_type_node, ptr_type_node,\n-\t\t\t\t    NULL_TREE);\n-  s390_builtin_decls[S390_BUILTIN_TBEGIN] =\n-    add_builtin_function (\"__builtin_tbegin\", ftype, S390_BUILTIN_TBEGIN,\n-\t\t\t  BUILT_IN_MD, NULL, returns_twice_attr);\n-  s390_builtin_decls[S390_BUILTIN_TBEGIN_NOFLOAT] =\n-    add_builtin_function (\"__builtin_tbegin_nofloat\", ftype,\n-\t\t\t  S390_BUILTIN_TBEGIN_NOFLOAT,\n-\t\t\t  BUILT_IN_MD, NULL, returns_twice_attr);\n-\n-  /* int foo (void *, int) */\n-  ftype = build_function_type_list (integer_type_node, ptr_type_node,\n-\t\t\t\t    integer_type_node, NULL_TREE);\n-  s390_builtin_decls[S390_BUILTIN_TBEGIN_RETRY] =\n-    add_builtin_function (\"__builtin_tbegin_retry\", ftype,\n-\t\t\t  S390_BUILTIN_TBEGIN_RETRY,\n-\t\t\t  BUILT_IN_MD,\n-\t\t\t  NULL, returns_twice_attr);\n-  s390_builtin_decls[S390_BUILTIN_TBEGIN_RETRY_NOFLOAT] =\n-    add_builtin_function (\"__builtin_tbegin_retry_nofloat\", ftype,\n-\t\t\t  S390_BUILTIN_TBEGIN_RETRY_NOFLOAT,\n-\t\t\t  BUILT_IN_MD,\n-\t\t\t  NULL, returns_twice_attr);\n-\n-  /* int foo (void) */\n-  ftype = build_function_type_list (integer_type_node, NULL_TREE);\n-  s390_builtin_decls[S390_BUILTIN_TX_NESTING_DEPTH] =\n-    add_builtin_function (\"__builtin_tx_nesting_depth\", ftype,\n-\t\t\t  S390_BUILTIN_TX_NESTING_DEPTH,\n-\t\t\t  BUILT_IN_MD, NULL, NULL_TREE);\n-  s390_builtin_decls[S390_BUILTIN_TEND] =\n-    add_builtin_function (\"__builtin_tend\", ftype,\n-\t\t\t  S390_BUILTIN_TEND, BUILT_IN_MD, NULL, NULL_TREE);\n-\n-  /* unsigned foo (void) */\n-  ftype = build_function_type_list (unsigned_type_node, NULL_TREE);\n-  s390_builtin_decls[S390_BUILTIN_S390_EFPC] =\n-    add_builtin_function (\"__builtin_s390_efpc\", ftype,\n-\t\t\t  S390_BUILTIN_S390_EFPC, BUILT_IN_MD, NULL, NULL_TREE);\n-\n-  /* void foo (uint64_t *, uint64_t) */\n-  if (TARGET_64BIT)\n-    uint64_type = long_unsigned_type_node;\n-  else\n-    uint64_type = long_long_unsigned_type_node;\n-\n-  ftype = build_function_type_list (void_type_node,\n- \t\t\t\t    build_pointer_type (uint64_type),\n-\t\t\t\t    uint64_type, NULL_TREE);\n-  s390_builtin_decls[S390_BUILTIN_NON_TX_STORE] =\n-    add_builtin_function (\"__builtin_non_tx_store\", ftype,\n-\t\t\t  S390_BUILTIN_NON_TX_STORE,\n-\t\t\t  BUILT_IN_MD, NULL, NULL_TREE);\n-}\n-\n-/* Expand an expression EXP that calls a built-in function,\n-   with result going to TARGET if that's convenient\n-   (and in mode MODE if that's convenient).\n-   SUBTARGET may be used as the target for computing one of EXP's operands.\n-   IGNORE is nonzero if the value is to be ignored.  */\n-\n-static rtx\n-s390_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n-\t\t     machine_mode mode ATTRIBUTE_UNUSED,\n-\t\t     int ignore ATTRIBUTE_UNUSED)\n-{\n-#define MAX_ARGS 2\n-\n-  tree fndecl = TREE_OPERAND (CALL_EXPR_FN (exp), 0);\n-  unsigned int fcode = DECL_FUNCTION_CODE (fndecl);\n-  enum insn_code icode;\n-  rtx op[MAX_ARGS], pat;\n-  int arity;\n-  bool nonvoid;\n-  tree arg;\n-  call_expr_arg_iterator iter;\n-\n-  if (fcode >= S390_BUILTIN_MAX)\n-    internal_error (\"bad builtin fcode\");\n-  icode = code_for_builtin[fcode];\n-  if (icode == 0)\n-    internal_error (\"bad builtin fcode\");\n-\n-  if (!TARGET_HTM && fcode <= S390_BUILTIN_TX_ASSIST)\n-    error (\"Transactional execution builtins not enabled (-mhtm)\\n\");\n-\n-  /* Set a flag in the machine specific cfun part in order to support\n-     saving/restoring of FPRs.  */\n-  if (fcode == S390_BUILTIN_TBEGIN || fcode == S390_BUILTIN_TBEGIN_RETRY)\n-    cfun->machine->tbegin_p = true;\n-\n-  nonvoid = TREE_TYPE (TREE_TYPE (fndecl)) != void_type_node;\n-\n-  arity = 0;\n-  FOR_EACH_CALL_EXPR_ARG (arg, iter, exp)\n-    {\n-      const struct insn_operand_data *insn_op;\n-\n-      if (arg == error_mark_node)\n-\treturn NULL_RTX;\n-      if (arity >= MAX_ARGS)\n-\treturn NULL_RTX;\n-\n-      insn_op = &insn_data[icode].operand[arity + nonvoid];\n-\n-      op[arity] = expand_expr (arg, NULL_RTX, insn_op->mode, EXPAND_NORMAL);\n-\n-      if (!(*insn_op->predicate) (op[arity], insn_op->mode))\n-\t{\n-\t  if (insn_op->predicate == memory_operand)\n-\t    {\n-\t      /* Don't move a NULL pointer into a register. Otherwise\n-\t\t we have to rely on combine being able to move it back\n-\t\t in order to get an immediate 0 in the instruction.  */\n-\t      if (op[arity] != const0_rtx)\n-\t\top[arity] = copy_to_mode_reg (Pmode, op[arity]);\n-\t      op[arity] = gen_rtx_MEM (insn_op->mode, op[arity]);\n-\t    }\n-\t  else\n-\t    op[arity] = copy_to_mode_reg (insn_op->mode, op[arity]);\n-\t}\n-\n-      arity++;\n-    }\n-\n-  if (nonvoid)\n-    {\n-      machine_mode tmode = insn_data[icode].operand[0].mode;\n-      if (!target\n-\t  || GET_MODE (target) != tmode\n-\t  || !(*insn_data[icode].operand[0].predicate) (target, tmode))\n-\ttarget = gen_reg_rtx (tmode);\n-    }\n-\n-  switch (arity)\n-    {\n-    case 0:\n-      pat = GEN_FCN (icode) (target);\n-      break;\n-    case 1:\n-      if (nonvoid)\n-        pat = GEN_FCN (icode) (target, op[0]);\n-      else\n-\tpat = GEN_FCN (icode) (op[0]);\n-      break;\n-    case 2:\n-      if (nonvoid)\n-\tpat = GEN_FCN (icode) (target, op[0], op[1]);\n-      else\n-\tpat = GEN_FCN (icode) (op[0], op[1]);\n-      break;\n-    default:\n-      gcc_unreachable ();\n-    }\n-  if (!pat)\n-    return NULL_RTX;\n-  emit_insn (pat);\n-\n-  if (nonvoid)\n-    return target;\n-  else\n-    return const0_rtx;\n-}\n \n /* Return the decl for the target specific builtin with the function\n    code FCODE.  */\n@@ -13178,8 +13531,8 @@ s390_use_by_pieces_infrastructure_p (unsigned HOST_WIDE_INT size,\n static void\n s390_atomic_assign_expand_fenv (tree *hold, tree *clear, tree *update)\n {\n-  tree sfpc = s390_builtin_decls[S390_BUILTIN_S390_SFPC];\n-  tree efpc = s390_builtin_decls[S390_BUILTIN_S390_EFPC];\n+  tree sfpc = s390_builtin_decls[S390_BUILTIN_s390_sfpc];\n+  tree efpc = s390_builtin_decls[S390_BUILTIN_s390_efpc];\n   tree call_efpc = build_call_expr (efpc, 0);\n   tree fenv_var = create_tmp_var (unsigned_type_node);\n "}, {"sha": "6ddd8aa2052e86cd78bbcabc9676eab297033195", "filename": "gcc/config/s390/s390.h", "status": "modified", "additions": 11, "deletions": 16, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Fs390.h?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1", "patch": "@@ -111,22 +111,7 @@ enum processor_flags\n #define TARGET_TPF 0\n \n /* Target CPU builtins.  */\n-#define TARGET_CPU_CPP_BUILTINS()\t\t\t\t\t\\\n-  do\t\t\t\t\t\t\t\t\t\\\n-    {\t\t\t\t\t\t\t\t\t\\\n-      builtin_assert (\"cpu=s390\");\t\t\t\t\t\\\n-      builtin_assert (\"machine=s390\");\t\t\t\t\t\\\n-      builtin_define (\"__s390__\");\t\t\t\t\t\\\n-      if (TARGET_ZARCH)\t\t\t\t\t\t\t\\\n-\tbuiltin_define (\"__zarch__\");\t\t\t\t\t\\\n-      if (TARGET_64BIT)\t\t\t\t\t\t\t\\\n-        builtin_define (\"__s390x__\");\t\t\t\t\t\\\n-      if (TARGET_LONG_DOUBLE_128)\t\t\t\t\t\\\n-        builtin_define (\"__LONG_DOUBLE_128__\");\t\t\t\t\\\n-      if (TARGET_HTM)\t\t\t\t\t\t\t\\\n-\tbuiltin_define (\"__HTM__\");\t\t\t\t\t\\\n-    }\t\t\t\t\t\t\t\t\t\\\n-  while (0)\n+#define TARGET_CPU_CPP_BUILTINS() s390_cpu_cpp_builtins (pfile)\n \n #ifdef DEFAULT_TARGET_64BIT\n #define TARGET_DEFAULT     (MASK_64BIT | MASK_ZARCH | MASK_HARD_DFP\t\\\n@@ -989,4 +974,14 @@ extern const int processor_flags_table[];\n    always generate -1 in that case.  */\n #define VECTOR_STORE_FLAG_VALUE(MODE) CONSTM1_RTX (GET_MODE_INNER (MODE))\n \n+/* Target pragma.  */\n+\n+/* resolve_overloaded_builtin can not be defined the normal way since\n+   it is defined in code which technically belongs to the\n+   front-end.  */\n+#define REGISTER_TARGET_PRAGMAS()\t\t\\\n+  do {\t\t\t\t\t\t\\\n+    s390_register_target_pragmas ();\t\t\\\n+  } while (0)\n+\n #endif /* S390_H */"}, {"sha": "8c07d1bea57eda547135fc2d1f5319f43870a399", "filename": "gcc/config/s390/s390.md", "status": "modified", "additions": 108, "deletions": 10, "changes": 118, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Fs390.md?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1", "patch": "@@ -126,21 +126,107 @@\n    UNSPEC_FPINT_NEARBYINT\n    UNSPEC_FPINT_RINT\n \n+   UNSPEC_LCBB\n+\n    ; Vector\n-   UNSPEC_VEC_EXTRACT\n-   UNSPEC_VEC_SET\n-   UNSPEC_VEC_PERM\n-   UNSPEC_VEC_SRLB\n-   UNSPEC_VEC_GENBYTEMASK\n-   UNSPEC_VEC_VSUM\n-   UNSPEC_VEC_VSUMG\n+   UNSPEC_VEC_SMULT_HI\n+   UNSPEC_VEC_UMULT_HI\n+   UNSPEC_VEC_SMULT_LO\n    UNSPEC_VEC_SMULT_EVEN\n    UNSPEC_VEC_UMULT_EVEN\n    UNSPEC_VEC_SMULT_ODD\n    UNSPEC_VEC_UMULT_ODD\n+\n+   UNSPEC_VEC_VMAL\n+   UNSPEC_VEC_VMAH\n+   UNSPEC_VEC_VMALH\n+   UNSPEC_VEC_VMAE\n+   UNSPEC_VEC_VMALE\n+   UNSPEC_VEC_VMAO\n+   UNSPEC_VEC_VMALO\n+\n+   UNSPEC_VEC_GATHER\n+   UNSPEC_VEC_EXTRACT\n+   UNSPEC_VEC_INSERT_AND_ZERO\n+   UNSPEC_VEC_LOAD_BNDRY\n    UNSPEC_VEC_LOAD_LEN\n+   UNSPEC_VEC_MERGEH\n+   UNSPEC_VEC_MERGEL\n+   UNSPEC_VEC_PACK\n+   UNSPEC_VEC_PACK_SATURATE\n+   UNSPEC_VEC_PACK_SATURATE_CC\n+   UNSPEC_VEC_PACK_SATURATE_GENCC\n+   UNSPEC_VEC_PACK_UNSIGNED_SATURATE\n+   UNSPEC_VEC_PACK_UNSIGNED_SATURATE_CC\n+   UNSPEC_VEC_PACK_UNSIGNED_SATURATE_GENCC\n+   UNSPEC_VEC_PERM\n+   UNSPEC_VEC_PERMI\n+   UNSPEC_VEC_EXTEND\n+   UNSPEC_VEC_STORE_LEN\n+   UNSPEC_VEC_UNPACKH\n+   UNSPEC_VEC_UNPACKH_L\n+   UNSPEC_VEC_UNPACKL\n+   UNSPEC_VEC_UNPACKL_L\n+   UNSPEC_VEC_ADDC\n+   UNSPEC_VEC_ADDC_U128\n+   UNSPEC_VEC_ADDE_U128\n+   UNSPEC_VEC_ADDEC_U128\n+   UNSPEC_VEC_AVG\n+   UNSPEC_VEC_AVGU\n+   UNSPEC_VEC_CHECKSUM\n+   UNSPEC_VEC_GFMSUM\n+   UNSPEC_VEC_GFMSUM_128\n+   UNSPEC_VEC_GFMSUM_ACCUM\n+   UNSPEC_VEC_GFMSUM_ACCUM_128\n+   UNSPEC_VEC_SET\n+\n+   UNSPEC_VEC_VSUMG\n+   UNSPEC_VEC_VSUMQ\n+   UNSPEC_VEC_VSUM\n+   UNSPEC_VEC_RL_MASK\n+   UNSPEC_VEC_SLL\n+   UNSPEC_VEC_SLB\n+   UNSPEC_VEC_SLDB\n+   UNSPEC_VEC_SRAL\n+   UNSPEC_VEC_SRAB\n+   UNSPEC_VEC_SRL\n+   UNSPEC_VEC_SRLB\n+\n+   UNSPEC_VEC_SUB_U128\n+   UNSPEC_VEC_SUBC\n+   UNSPEC_VEC_SUBC_U128\n+   UNSPEC_VEC_SUBE_U128\n+   UNSPEC_VEC_SUBEC_U128\n+\n+   UNSPEC_VEC_TEST_MASK\n+\n+   UNSPEC_VEC_VFAE\n+   UNSPEC_VEC_VFAECC\n+\n+   UNSPEC_VEC_VFEE\n+   UNSPEC_VEC_VFEECC\n    UNSPEC_VEC_VFENE\n    UNSPEC_VEC_VFENECC\n+\n+   UNSPEC_VEC_VISTR\n+   UNSPEC_VEC_VISTRCC\n+\n+   UNSPEC_VEC_VSTRC\n+   UNSPEC_VEC_VSTRCCC\n+\n+   UNSPEC_VEC_VCDGB\n+   UNSPEC_VEC_VCDLGB\n+\n+   UNSPEC_VEC_VCGDB\n+   UNSPEC_VEC_VCLGDB\n+\n+   UNSPEC_VEC_VFIDB\n+\n+   UNSPEC_VEC_VLDEB\n+   UNSPEC_VEC_VLEDB\n+\n+   UNSPEC_VEC_VFTCIDB\n+   UNSPEC_VEC_VFTCIDBCC\n ])\n \n ;;\n@@ -651,7 +737,7 @@\n ; Used with VFCMP to expand part of the mnemonic\n ; For fp we have a mismatch: eq in the insn name - e in asm\n (define_mode_attr asm_fcmp [(CCVEQ \"e\") (CCVFH \"h\") (CCVFHE \"he\")])\n-(define_mode_attr insn_cmp [(CCVEQ \"eq\") (CCVFH \"h\") (CCVFHE \"he\")])\n+(define_mode_attr insn_cmp [(CCVEQ \"eq\") (CCVH \"h\") (CCVHU \"hl\") (CCVFH \"h\") (CCVFHE \"he\")])\n \n \n (include \"vector.md\")\n@@ -10614,14 +10700,26 @@\n \n ; Set and get floating point control register\n \n-(define_insn \"s390_sfpc\"\n+(define_insn \"sfpc\"\n   [(unspec_volatile [(match_operand:SI 0 \"register_operand\" \"d\")]\n \t\t    UNSPECV_SFPC)]\n   \"TARGET_HARD_FLOAT\"\n   \"sfpc\\t%0\")\n \n-(define_insn \"s390_efpc\"\n+(define_insn \"efpc\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=d\")\n \t(unspec_volatile:SI [(const_int 0)] UNSPECV_EFPC))]\n   \"TARGET_HARD_FLOAT\"\n   \"efpc\\t%0\")\n+\n+\n+; Load count to block boundary\n+\n+(define_insn \"lcbb\"\n+  [(set (match_operand:SI             0 \"register_operand\"  \"=d\")\n+\t(unspec:SI [(match_operand:SI 1 \"address_operand\" \"ZQZR\")\n+\t\t    (match_operand:SI 2 \"immediate_operand\"  \"C\")] UNSPEC_LCBB))\n+   (clobber (reg:CC CC_REGNUM))]\n+  \"TARGET_Z13\"\n+  \"lcbb\\t%0,%1,%b2\"\n+  [(set_attr \"op_type\" \"VRX\")])"}, {"sha": "b841c4dac4d287a6d2104299f7ffc3508b929809", "filename": "gcc/config/s390/s390.opt", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Fs390.opt?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1", "patch": "@@ -153,6 +153,10 @@ mmvcle\n Target Report Mask(MVCLE)\n mvcle use\n \n+mzvector\n+Target Report Mask(ZVECTOR)\n+Enable the z vector language extension providing the context-sensitive vector macro.\n+\n mwarn-dynamicstack\n Target RejectNegative Var(s390_warn_dynamicstack_p)\n Warn if a function uses alloca or creates an array with dynamic size"}, {"sha": "c25f69ef71a0fd57375be2966a80c77ebccc6c91", "filename": "gcc/config/s390/s390intrin.h", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390intrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fs390intrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Fs390intrin.h?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1", "patch": "@@ -29,5 +29,8 @@ along with GCC; see the file COPYING3.  If not see\n #include <htmintrin.h>\n #endif\n \n+#ifdef __VEC__\n+#include <vecintrin.h>\n+#endif\n \n #endif /* _S390INTRIN_H*/"}, {"sha": "800412c9dd2637f1a990752e23fde80c4796a144", "filename": "gcc/config/s390/t-s390", "status": "added", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Ft-s390", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Ft-s390", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Ft-s390?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1", "patch": "@@ -0,0 +1,27 @@\n+# Copyright (C) 2015 Free Software Foundation, Inc.\n+#\n+# This file is part of GCC.\n+#\n+# GCC is free software; you can redistribute it and/or modify\n+# it under the terms of the GNU General Public License as published by\n+# the Free Software Foundation; either version 3, or (at your option)\n+# any later version.\n+#\n+# GCC is distributed in the hope that it will be useful,\n+# but WITHOUT ANY WARRANTY; without even the implied warranty of\n+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+# GNU General Public License for more details.\n+#\n+# You should have received a copy of the GNU General Public License\n+# along with GCC; see the file COPYING3.  If not see\n+# <http://www.gnu.org/licenses/>.\n+\n+TM_H += $(srcdir)/config/s390/s390-builtins.def\n+TM_H += $(srcdir)/config/s390/s390-builtin-types.def\n+\n+s390-c.o: $(srcdir)/config/s390/s390-c.c \\\n+  $(srcdir)/config/s390/s390-protos.h $(CONFIG_H) $(SYSTEM_H) coretypes.h \\\n+  $(TM_H) $(TREE_H) $(TM_P_H) $(FLAGS_H) $(C_COMMON_H) $(GGC_H) \\\n+  $(TARGET_H) $(TARGET_DEF_H) $(CPPLIB_H) $(C_PRAGMA_H)\n+\t$(COMPILER) -c $(ALL_COMPILERFLAGS) $(ALL_CPPFLAGS) $(INCLUDES) \\\n+\t\t$(srcdir)/config/s390/s390-c.c"}, {"sha": "95851f45ff7f2cd471ea4551b46bc34525c9d1c8", "filename": "gcc/config/s390/vecintrin.h", "status": "added", "additions": 311, "deletions": 0, "changes": 311, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fvecintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fvecintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Fvecintrin.h?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1", "patch": "@@ -0,0 +1,311 @@\n+/* GNU compiler hardware transactional execution intrinsics\n+   Copyright (C) 2015 Free Software Foundation, Inc.\n+   Contributed by Andreas Krebbel (Andreas.Krebbel@de.ibm.com)\n+\n+This file is part of GCC.\n+\n+GCC is free software; you can redistribute it and/or modify it under\n+the terms of the GNU General Public License as published by the Free\n+Software Foundation; either version 3, or (at your option) any later\n+version.\n+\n+GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GCC; see the file COPYING3.  If not see\n+<http://www.gnu.org/licenses/>.  */\n+\n+#ifndef _VECINTRIN_H\n+#define _VECINTRIN_H\n+\n+#ifdef __VEC__\n+\n+#define __VFTCI_ZERO           1<<11\n+#define __VFTCI_ZERO_N         1<<10\n+#define __VFTCI_NORMAL          1<<9\n+#define __VFTCI_NORMAL_N        1<<8\n+#define __VFTCI_SUBNORMAL       1<<7\n+#define __VFTCI_SUBNORMAL_N     1<<6\n+#define __VFTCI_INF             1<<5\n+#define __VFTCI_INF_N           1<<4\n+#define __VFTCI_QNAN            1<<3\n+#define __VFTCI_QNAN_N          1<<2\n+#define __VFTCI_SNAN            1<<1\n+#define __VFTCI_SNAN_N          1<<0\n+\n+/* This also accepts a type for its parameter, so it is not enough\n+   to #define vec_step to __builtin_vec_step.  */\n+#define vec_step(x) __builtin_vec_step (* (__typeof__ (x) *) 0)\n+\n+static inline int\n+__lcbb(const void *ptr, int bndry)\n+{\n+  int code;\n+  switch (bndry)\n+    {\n+    case 64: code = 0; break;\n+    case 128: code = 1; break;\n+    case 256: code = 2; break;\n+    case 512: code = 3; break;\n+    case 1024: code = 4; break;\n+    case 2048: code = 5; break;\n+    case 4096: code = 6; break;\n+    default: return 0;\n+    }\n+  return __builtin_s390_lcbb (ptr, code);\n+}\n+\n+#define vec_all_nle(X, Y) vec_all_nge ((Y), (X))\n+#define vec_all_nlt(X, Y) vec_all_ngt ((Y), (X))\n+#define vec_any_nle(X, Y) vec_any_nge ((Y), (X))\n+#define vec_any_nlt(X, Y) vec_any_ngt ((Y), (X))\n+#define vec_genmask __builtin_s390_vgbm\n+#define vec_genmasks_8 __builtin_s390_vgmb\n+#define vec_genmasks_16 __builtin_s390_vgmh\n+#define vec_genmasks_32 __builtin_s390_vgmf\n+#define vec_genmasks_64 __builtin_s390_vgmg\n+#define vec_splat_u8 __builtin_s390_vlrepb\n+#define vec_splat_s8 __builtin_s390_vlrepb\n+#define vec_splat_u16 __builtin_s390_vlreph\n+#define vec_splat_s16 __builtin_s390_vlreph\n+#define vec_splat_u32 __builtin_s390_vlrepf\n+#define vec_splat_s32 __builtin_s390_vlrepf\n+#define vec_splat_u64 __builtin_s390_vlrepg\n+#define vec_splat_s64 __builtin_s390_vlrepg\n+#define vec_add_u128 __builtin_s390_vaq\n+#define vec_addc_u128 __builtin_s390_vaccq\n+#define vec_adde_u128 __builtin_s390_vacq\n+#define vec_addec_u128 __builtin_s390_vacccq\n+#define vec_checksum __builtin_s390_vcksm\n+#define vec_gfmsum_128 __builtin_s390_vgfmg\n+#define vec_gfmsum_accum_128 __builtin_s390_vgfmag\n+#define vec_subc_u128 __builtin_s390_vscbiq\n+#define vec_sube_u128 __builtin_s390_vsbiq\n+#define vec_subec_u128 __builtin_s390_vsbcbiq\n+#define vec_ceil(X) __builtin_s390_vfidb((X), 4, 6)\n+#define vec_roundp(X) __builtin_s390_vfidb((X), 4, 6)\n+#define vec_floor(X) __builtin_s390_vfidb((X), 4, 7)\n+#define vec_roundm(X) __builtin_s390_vfidb((X), 4, 7)\n+#define vec_trunc(X) __builtin_s390_vfidb((X), 4, 5)\n+#define vec_roundz(X) __builtin_s390_vfidb((X), 4, 5)\n+#define vec_roundc(X) __builtin_s390_vfidb((X), 4, 0)\n+#define vec_round(X) __builtin_s390_vfidb((X), 4, 4)\n+#define vec_madd __builtin_s390_vfmadb\n+#define vec_msub __builtin_s390_vfmsdb\n+\n+static inline int\n+vec_all_nan (__vector double a)\n+{\n+  int cc;\n+  __builtin_s390_vftcidb (a,\n+\t\t\t  __VFTCI_QNAN\n+\t\t\t  | __VFTCI_QNAN_N\n+\t\t\t  | __VFTCI_SNAN\n+\t\t\t  | __VFTCI_SNAN_N, &cc);\n+  return cc == 0 ? 1 : 0;\n+}\n+\n+static inline int\n+vec_all_numeric (__vector double a)\n+{\n+  int cc;\n+  __builtin_s390_vftcidb (a,\n+\t\t\t  __VFTCI_NORMAL\n+\t\t\t  | __VFTCI_NORMAL_N\n+\t\t\t  | __VFTCI_SUBNORMAL\n+\t\t\t  | __VFTCI_SUBNORMAL_N, &cc);\n+  return cc == 0 ? 1 : 0;\n+}\n+\n+static inline int\n+vec_any_nan (__vector double a)\n+{\n+  int cc;\n+  __builtin_s390_vftcidb (a,\n+\t\t\t  __VFTCI_QNAN\n+\t\t\t  | __VFTCI_QNAN_N\n+\t\t\t  | __VFTCI_SNAN\n+\t\t\t  | __VFTCI_SNAN_N, &cc);\n+  return cc != 3 ? 1 : 0;\n+}\n+\n+static inline int\n+vec_any_numeric (__vector double a)\n+{\n+  int cc;\n+  __builtin_s390_vftcidb (a,\n+\t\t\t  __VFTCI_NORMAL\n+\t\t\t  | __VFTCI_NORMAL_N\n+\t\t\t  | __VFTCI_SUBNORMAL\n+\t\t\t  | __VFTCI_SUBNORMAL_N, &cc);\n+  return cc != 3 ? 1 : 0;\n+}\n+#define vec_gather_element __builtin_s390_vec_gather_element\n+#define vec_xld2 __builtin_s390_vec_xld2\n+#define vec_xlw4 __builtin_s390_vec_xlw4\n+#define vec_splats __builtin_s390_vec_splats\n+#define vec_insert __builtin_s390_vec_insert\n+#define vec_promote __builtin_s390_vec_promote\n+#define vec_extract __builtin_s390_vec_extract\n+#define vec_insert_and_zero __builtin_s390_vec_insert_and_zero\n+#define vec_load_bndry __builtin_s390_vec_load_bndry\n+#define vec_load_pair __builtin_s390_vec_load_pair\n+#define vec_load_len __builtin_s390_vec_load_len\n+#define vec_mergeh __builtin_s390_vec_mergeh\n+#define vec_mergel __builtin_s390_vec_mergel\n+#define vec_pack __builtin_s390_vec_pack\n+#define vec_packs __builtin_s390_vec_packs\n+#define vec_packs_cc __builtin_s390_vec_packs_cc\n+#define vec_packsu __builtin_s390_vec_packsu\n+#define vec_packsu_u16 __builtin_s390_vec_packsu_u16\n+#define vec_packsu_u32 __builtin_s390_vec_packsu_u32\n+#define vec_packsu_u64 __builtin_s390_vec_packsu_u64\n+#define vec_packsu_cc __builtin_s390_vec_packsu_cc\n+#define vec_perm __builtin_s390_vec_perm\n+#define vec_permi __builtin_s390_vec_permi\n+#define vec_splat __builtin_s390_vec_splat\n+#define vec_scatter_element __builtin_s390_vec_scatter_element\n+#define vec_sel __builtin_s390_vec_sel\n+#define vec_extend_s64 __builtin_s390_vec_extend_s64\n+#define vec_xstd2 __builtin_s390_vec_xstd2\n+#define vec_xstw4 __builtin_s390_vec_xstw4\n+#define vec_store_len __builtin_s390_vec_store_len\n+#define vec_unpackh __builtin_s390_vec_unpackh\n+#define vec_unpackl __builtin_s390_vec_unpackl\n+#define vec_addc __builtin_s390_vec_addc\n+#define vec_and __builtin_s390_vec_and\n+#define vec_andc __builtin_s390_vec_andc\n+#define vec_avg __builtin_s390_vec_avg\n+#define vec_all_eqv16qi __builtin_vec_all_eqv16qi\n+#define vec_all_eqv8hi __builtin_vec_all_eqv8hi\n+#define vec_all_eqv4si __builtin_vec_all_eqv4si\n+#define vec_all_eqv2di __builtin_vec_all_eqv2di\n+#define vec_all_eqv2df __builtin_vec_all_eqv2df\n+#define vec_all_gev16qi __builtin_vec_all_gev16qi\n+#define vec_all_geuv16qi __builtin_vec_all_geuv16qi\n+#define vec_all_gev8hi __builtin_vec_all_gev8hi\n+#define vec_all_geuv8hi __builtin_vec_all_geuv8hi\n+#define vec_all_gev4si __builtin_vec_all_gev4si\n+#define vec_all_geuv4si __builtin_vec_all_geuv4si\n+#define vec_all_gev2di __builtin_vec_all_gev2di\n+#define vec_all_geuv2di __builtin_vec_all_geuv2di\n+#define vec_all_gev2df __builtin_vec_all_gev2df\n+#define vec_all_gtv2df __builtin_vec_all_gtv2df\n+#define vec_all_eq __builtin_s390_vec_all_eq\n+#define vec_all_ne __builtin_s390_vec_all_ne\n+#define vec_all_ge __builtin_s390_vec_all_ge\n+#define vec_all_gt __builtin_s390_vec_all_gt\n+#define vec_all_le __builtin_s390_vec_all_le\n+#define vec_all_lt __builtin_s390_vec_all_lt\n+#define vec_any_eqv16qi __builtin_vec_any_eqv16qi\n+#define vec_any_eqv8hi __builtin_vec_any_eqv8hi\n+#define vec_any_eqv4si __builtin_vec_any_eqv4si\n+#define vec_any_eqv2di __builtin_vec_any_eqv2di\n+#define vec_any_eqv2df __builtin_vec_any_eqv2df\n+#define vec_any_gev16qi __builtin_vec_any_gev16qi\n+#define vec_any_geuv16qi __builtin_vec_any_geuv16qi\n+#define vec_any_gev8hi __builtin_vec_any_gev8hi\n+#define vec_any_geuv8hi __builtin_vec_any_geuv8hi\n+#define vec_any_gev4si __builtin_vec_any_gev4si\n+#define vec_any_geuv4si __builtin_vec_any_geuv4si\n+#define vec_any_gev2di __builtin_vec_any_gev2di\n+#define vec_any_geuv2di __builtin_vec_any_geuv2di\n+#define vec_any_gev2df __builtin_vec_any_gev2df\n+#define vec_any_gtv2df __builtin_vec_any_gtv2df\n+#define vec_any_eq __builtin_s390_vec_any_eq\n+#define vec_any_ne __builtin_s390_vec_any_ne\n+#define vec_any_ge __builtin_s390_vec_any_ge\n+#define vec_any_gt __builtin_s390_vec_any_gt\n+#define vec_any_le __builtin_s390_vec_any_le\n+#define vec_any_lt __builtin_s390_vec_any_lt\n+#define vec_cmpeq __builtin_s390_vec_cmpeq\n+#define vec_cmpge __builtin_s390_vec_cmpge\n+#define vec_cmpgt __builtin_s390_vec_cmpgt\n+#define vec_cmple __builtin_s390_vec_cmple\n+#define vec_cmplt __builtin_s390_vec_cmplt\n+#define vec_cntlz __builtin_s390_vec_cntlz\n+#define vec_cnttz __builtin_s390_vec_cnttz\n+#define vec_xor __builtin_s390_vec_xor\n+#define vec_gfmsum __builtin_s390_vec_gfmsum\n+#define vec_gfmsum_accum __builtin_s390_vec_gfmsum_accum\n+#define vec_abs __builtin_s390_vec_abs\n+#define vec_max __builtin_s390_vec_max\n+#define vec_max_dbl __builtin_s390_vec_max_dbl\n+#define vec_min __builtin_s390_vec_min\n+#define vec_min_dbl __builtin_s390_vec_min_dbl\n+#define vec_mladd __builtin_s390_vec_mladd\n+#define vec_mhadd __builtin_s390_vec_mhadd\n+#define vec_meadd __builtin_s390_vec_meadd\n+#define vec_moadd __builtin_s390_vec_moadd\n+#define vec_mulh __builtin_s390_vec_mulh\n+#define vec_mule __builtin_s390_vec_mule\n+#define vec_mulo __builtin_s390_vec_mulo\n+#define vec_nor __builtin_s390_vec_nor\n+#define vec_or __builtin_s390_vec_or\n+#define vec_popcnt __builtin_s390_vec_popcnt\n+#define vec_rl __builtin_s390_vec_rl\n+#define vec_rli __builtin_s390_vec_rli\n+#define vec_rl_mask __builtin_s390_vec_rl_mask\n+#define vec_sll __builtin_s390_vec_sll\n+#define vec_slb __builtin_s390_vec_slb\n+#define vec_sld __builtin_s390_vec_sld\n+#define vec_sldw __builtin_s390_vec_sldw\n+#define vec_sral __builtin_s390_vec_sral\n+#define vec_srab __builtin_s390_vec_srab\n+#define vec_srl __builtin_s390_vec_srl\n+#define vec_srb __builtin_s390_vec_srb\n+#define vec_subc __builtin_s390_vec_subc\n+#define vec_sum2 __builtin_s390_vec_sum2\n+#define vec_sum_u128 __builtin_s390_vec_sum_u128\n+#define vec_sum4 __builtin_s390_vec_sum4\n+#define vec_test_mask __builtin_s390_vec_test_mask\n+#define vec_find_any_eq_idx __builtin_s390_vec_find_any_eq_idx\n+#define vec_find_any_ne_idx __builtin_s390_vec_find_any_ne_idx\n+#define vec_find_any_eq_or_0_idx __builtin_s390_vec_find_any_eq_or_0_idx\n+#define vec_find_any_ne_or_0_idx __builtin_s390_vec_find_any_ne_or_0_idx\n+#define vec_find_any_eq __builtin_s390_vec_find_any_eq\n+#define vec_find_any_ne __builtin_s390_vec_find_any_ne\n+#define vec_find_any_eq_idx_cc __builtin_s390_vec_find_any_eq_idx_cc\n+#define vec_find_any_ne_idx_cc __builtin_s390_vec_find_any_ne_idx_cc\n+#define vec_find_any_eq_or_0_idx_cc __builtin_s390_vec_find_any_eq_or_0_idx_cc\n+#define vec_find_any_ne_or_0_idx_cc __builtin_s390_vec_find_any_ne_or_0_idx_cc\n+#define vec_find_any_eq_cc __builtin_s390_vec_find_any_eq_cc\n+#define vec_find_any_ne_cc __builtin_s390_vec_find_any_ne_cc\n+#define vec_cmpeq_idx __builtin_s390_vec_cmpeq_idx\n+#define vec_cmpeq_or_0_idx __builtin_s390_vec_cmpeq_or_0_idx\n+#define vec_cmpeq_idx_cc __builtin_s390_vec_cmpeq_idx_cc\n+#define vec_cmpeq_or_0_idx_cc __builtin_s390_vec_cmpeq_or_0_idx_cc\n+#define vec_cmpne_idx __builtin_s390_vec_cmpne_idx\n+#define vec_cmpne_or_0_idx __builtin_s390_vec_cmpne_or_0_idx\n+#define vec_cmpne_idx_cc __builtin_s390_vec_cmpne_idx_cc\n+#define vec_cmpne_or_0_idx_cc __builtin_s390_vec_cmpne_or_0_idx_cc\n+#define vec_cp_until_zero __builtin_s390_vec_cp_until_zero\n+#define vec_cp_until_zero_cc __builtin_s390_vec_cp_until_zero_cc\n+#define vec_cmprg_idx __builtin_s390_vec_cmprg_idx\n+#define vec_cmpnrg_idx __builtin_s390_vec_cmpnrg_idx\n+#define vec_cmprg_or_0_idx __builtin_s390_vec_cmprg_or_0_idx\n+#define vec_cmpnrg_or_0_idx __builtin_s390_vec_cmpnrg_or_0_idx\n+#define vec_cmprg __builtin_s390_vec_cmprg\n+#define vec_cmpnrg __builtin_s390_vec_cmpnrg\n+#define vec_cmprg_idx_cc __builtin_s390_vec_cmprg_idx_cc\n+#define vec_cmpnrg_idx_cc __builtin_s390_vec_cmpnrg_idx_cc\n+#define vec_cmprg_or_0_idx_cc __builtin_s390_vec_cmprg_or_0_idx_cc\n+#define vec_cmpnrg_or_0_idx_cc __builtin_s390_vec_cmpnrg_or_0_idx_cc\n+#define vec_cmprg_cc __builtin_s390_vec_cmprg_cc\n+#define vec_cmpnrg_cc __builtin_s390_vec_cmpnrg_cc\n+#define vec_all_nge __builtin_s390_vec_all_nge\n+#define vec_all_ngt __builtin_s390_vec_all_ngt\n+#define vec_any_nge __builtin_s390_vec_any_nge\n+#define vec_any_ngt __builtin_s390_vec_any_ngt\n+#define vec_ctd __builtin_s390_vec_ctd\n+#define vec_ctd_s64 __builtin_s390_vec_ctd_s64\n+#define vec_ctd_u64 __builtin_s390_vec_ctd_u64\n+#define vec_ctsl __builtin_s390_vec_ctsl\n+#define vec_ctul __builtin_s390_vec_ctul\n+#define vec_ld2f __builtin_s390_vec_ld2f\n+#define vec_st2f __builtin_s390_vec_st2f\n+#endif /* __VEC__ */\n+#endif /* _VECINTRIN_H */"}, {"sha": "16276e0de36769daf15d5d7e9110365fea2469e2", "filename": "gcc/config/s390/vector.md", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fvector.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fvector.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Fvector.md?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1", "patch": "@@ -133,6 +133,8 @@\n    (VSTRING_FLAG_ZS         2)   ; zero search\n    (VSTRING_FLAG_CS         1)]) ; condition code set\n \n+(include \"vx-builtins.md\")\n+\n ; Full HW vector size moves\n (define_insn \"mov<mode>\"\n   [(set (match_operand:V_128 0 \"nonimmediate_operand\" \"=v, v,QR,  v,  v,  v,  v,v,d\")"}, {"sha": "e306ee8bd0534e6de1caacb65a9ed1e464f51f72", "filename": "gcc/config/s390/vx-builtins.md", "status": "added", "additions": 2081, "deletions": 0, "changes": 2081, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fvx-builtins.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3af82a61fa223fad00f5396b8f0ebb93cde646d1/gcc%2Fconfig%2Fs390%2Fvx-builtins.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fs390%2Fvx-builtins.md?ref=3af82a61fa223fad00f5396b8f0ebb93cde646d1", "patch": "@@ -0,0 +1,2081 @@\n+;;- Instruction patterns for the System z vector facility builtins.\n+;;  Copyright (C) 2015 Free Software Foundation, Inc.\n+;;  Contributed by Andreas Krebbel (Andreas.Krebbel@de.ibm.com)\n+\n+;; This file is part of GCC.\n+\n+;; GCC is free software; you can redistribute it and/or modify it under\n+;; the terms of the GNU General Public License as published by the Free\n+;; Software Foundation; either version 3, or (at your option) any later\n+;; version.\n+\n+;; GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+;; WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+;; FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+;; for more details.\n+\n+;; You should have received a copy of the GNU General Public License\n+;; along with GCC; see the file COPYING3.  If not see\n+;; <http://www.gnu.org/licenses/>.\n+\n+; The patterns in this file are enabled with -mzvector\n+\n+(define_mode_iterator V_HW_64 [V2DI V2DF])\n+(define_mode_iterator V_HW_32_64 [V4SI V2DI V2DF])\n+(define_mode_iterator VI_HW_SD [V4SI V2DI])\n+(define_mode_iterator V_HW_HSD [V8HI V4SI V2DI V2DF])\n+(define_mode_iterator VI_HW_HSD [V8HI V4SI V2DI])\n+\n+; The element type of the vector with floating point modes translated\n+; to int modes of the same size.\n+(define_mode_attr non_vec_int[(V2QI \"QI\") (V4QI \"QI\") (V8QI \"QI\") (V16QI \"QI\")\n+\t\t\t      (V2HI \"HI\") (V4HI \"HI\") (V8HI \"HI\")\n+\t\t\t      (V2SI \"SI\") (V4SI \"SI\")\n+\t\t\t      (V2DI \"DI\")\n+\t\t\t      (V2SF \"SI\") (V4SF \"SI\")\n+\t\t\t      (V2DF \"DI\")])\n+\n+; Condition code modes generated by int comparisons\n+(define_mode_iterator VICMP [CCVEQ CCVH CCVHU])\n+\n+; Comparisons supported by the vec_cmp* builtins\n+(define_code_iterator intcmp [eq gt gtu ge geu lt ltu le leu])\n+(define_code_iterator fpcmp  [eq gt ge lt le])\n+\n+; Comparisons supported by the vec_all/any* builtins\n+(define_code_iterator intcmpcc [eq ne gt ge lt le gtu geu ltu leu])\n+(define_code_iterator fpcmpcc  [eq ne gt ge unle unlt lt le])\n+\n+; Flags for vector string instructions (vfae all 4, vfee only ZS and CS, vstrc all 4)\n+(define_constants\n+  [(VSTRING_FLAG_IN         8)   ; invert result\n+   (VSTRING_FLAG_RT         4)   ; result type\n+   (VSTRING_FLAG_ZS         2)   ; zero search\n+   (VSTRING_FLAG_CS         1)]) ; condition code set\n+\n+; Rounding modes as being used for e.g. VFI\n+(define_constants\n+  [(VEC_RND_CURRENT                0)\n+   (VEC_RND_NEAREST_AWAY_FROM_ZERO 1)\n+   (VEC_RND_SHORT_PREC             3)\n+   (VEC_RND_NEAREST_TO_EVEN        4)\n+   (VEC_RND_TO_ZERO                5)\n+   (VEC_RND_TO_INF                 6)\n+   (VEC_RND_TO_MINF                7)])\n+\n+\n+; Vector gather element\n+\n+(define_insn \"vec_gather_element<mode>\"\n+  [(set (match_operand:V_HW_32_64                     0 \"register_operand\" \"=v\")\n+\t(unspec:V_HW_32_64 [(match_operand:V_HW_32_64 1 \"register_operand\"  \"0\")\n+\t\t\t    (match_operand:<tointvec> 2 \"register_operand\"  \"v\")\n+\t\t\t    (match_operand:BLK        3 \"memory_operand\"   \"QR\")\n+\t\t\t    (match_operand:QI         4 \"immediate_operand\" \"C\")]\n+\t\t\t   UNSPEC_VEC_GATHER))]\n+  \"TARGET_VX\"\n+  \"vge<bhfgq>\\t%0,%O3(%v2,%R3),%b4\"\n+  [(set_attr \"op_type\" \"VRV\")])\n+\n+(define_expand \"vec_genmask<mode>\"\n+  [(match_operand:VI_HW 0 \"register_operand\" \"=v\")\n+   (match_operand:QI    1 \"immediate_operand\" \"C\")\n+   (match_operand:QI    2 \"immediate_operand\" \"C\")]\n+  \"TARGET_VX\"\n+{\n+  int nunits = GET_MODE_NUNITS (<VI_HW:MODE>mode);\n+  int bitlen = GET_MODE_UNIT_BITSIZE (<VI_HW:MODE>mode);\n+  /* To bit little endian style.  */\n+  int end = bitlen - 1 - INTVAL (operands[1]);\n+  int start = bitlen - 1 - INTVAL (operands[2]);\n+  rtx const_vec[16];\n+  int i;\n+  unsigned HOST_WIDE_INT mask;\n+  bool swapped_p = false;\n+\n+  if (start > end)\n+    {\n+      i = start - 1; start = end + 1; end = i;\n+      swapped_p = true;\n+    }\n+  if (end == 63)\n+    mask = HOST_WIDE_INT_M1U;\n+  else\n+    mask = (HOST_WIDE_INT_1U << (end + 1)) - 1;\n+\n+  mask &= ~((HOST_WIDE_INT_1U << start) - 1);\n+\n+  if (swapped_p)\n+    mask = ~mask;\n+\n+  for (i = 0; i < nunits; i++)\n+    const_vec[i] = GEN_INT (trunc_int_for_mode (mask,\n+\t\t\t      GET_MODE_INNER (<VI_HW:MODE>mode)));\n+\n+  emit_insn (gen_rtx_SET (operands[0],\n+\t\t\t  gen_rtx_CONST_VECTOR (<VI_HW:MODE>mode,\n+\t\t\t\t\t\tgen_rtvec_v (nunits, const_vec))));\n+  DONE;\n+})\n+\n+(define_expand \"vec_genbytemaskv16qi\"\n+  [(match_operand:V16QI 0 \"register_operand\"  \"\")\n+   (match_operand       1 \"immediate_operand\" \"\")]\n+  \"TARGET_VX && CONST_OK_FOR_CONSTRAINT_P (INTVAL (operands[1]), 'K', \\\"K\\\")\"\n+{\n+  int i;\n+  unsigned mask = 0x8000;\n+  rtx const_vec[16];\n+  unsigned HOST_WIDE_INT byte_mask = INTVAL (operands[1]);\n+\n+  for (i = 0; i < 16; i++)\n+    {\n+      if (mask & byte_mask)\n+\tconst_vec[i] = constm1_rtx;\n+      else\n+\tconst_vec[i] = const0_rtx;\n+      mask = mask >> 1;\n+    }\n+  emit_insn (gen_rtx_SET (operands[0],\n+\t\t\t  gen_rtx_CONST_VECTOR (V16QImode,\n+\t\t\t\t\t\tgen_rtvec_v (16, const_vec))));\n+  DONE;\n+})\n+\n+(define_expand \"vec_splats<mode>\"\n+  [(set (match_operand:V_HW                          0 \"register_operand\" \"\")\n+\t(vec_duplicate:V_HW (match_operand:<non_vec> 1 \"general_operand\"  \"\")))]\n+  \"TARGET_VX\")\n+\n+(define_expand \"vec_insert<mode>\"\n+  [(set (match_operand:V_HW                    0 \"register_operand\" \"\")\n+\t(unspec:V_HW [(match_operand:<non_vec> 2 \"register_operand\" \"\")\n+\t\t      (match_operand:SI        3 \"shift_count_or_setmem_operand\" \"\")\n+\t\t      (match_operand:V_HW      1 \"register_operand\" \"\")]\n+\t\t     UNSPEC_VEC_SET))]\n+  \"TARGET_VX\"\n+  \"\")\n+\n+; This is vec_set + modulo arithmetic on the element selector (op 2)\n+(define_expand \"vec_promote<mode>\"\n+  [(set (match_operand:V_HW                    0 \"register_operand\" \"\")\n+\t(unspec:V_HW [(match_operand:<non_vec> 1 \"register_operand\" \"\")\n+\t\t      (match_operand:SI        2 \"shift_count_or_setmem_operand\" \"\")\n+\t\t      (match_dup 0)]\n+\t\t     UNSPEC_VEC_SET))]\n+  \"TARGET_VX\"\n+  \"\")\n+\n+; vec_extract is also an RTL standard name -> vector.md\n+\n+(define_insn \"vec_insert_and_zero<mode>\"\n+  [(set (match_operand:V_HW                    0 \"register_operand\" \"=v\")\n+\t(unspec:V_HW [(match_operand:<non_vec> 1 \"memory_operand\"   \"QR\")]\n+\t\t     UNSPEC_VEC_INSERT_AND_ZERO))]\n+  \"TARGET_VX\"\n+  \"vllez<bhfgq>\\t%v0,%1\"\n+  [(set_attr \"op_type\" \"VRX\")])\n+\n+(define_insn \"vlbb\"\n+  [(set (match_operand:V16QI              0 \"register_operand\"  \"=v\")\n+\t(unspec:V16QI [(match_operand:BLK 1 \"memory_operand\"    \"QR\")\n+\t\t       (match_operand:HI  2 \"immediate_operand\" \" K\")]\n+\t\t      UNSPEC_VEC_LOAD_BNDRY))]\n+  \"TARGET_VX\"\n+  \"vlbb\\t%v0,%1,%2\"\n+  [(set_attr \"op_type\" \"VRX\")])\n+\n+; FIXME: The following two patterns might using vec_merge. But what is\n+; the canonical form: (vec_select (vec_merge op0 op1)) or (vec_merge\n+; (vec_select op0) (vec_select op1)\n+(define_insn \"vec_mergeh<mode>\"\n+  [(set (match_operand:V_HW               0 \"register_operand\" \"=v\")\n+\t(unspec:V_HW [(match_operand:V_HW 1 \"register_operand\"  \"v\")\n+\t\t      (match_operand:V_HW 2 \"register_operand\"  \"v\")]\n+\t\t     UNSPEC_VEC_MERGEH))]\n+  \"TARGET_VX\"\n+  \"vmrh<bhfgq>\\t%v0,%1,%2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"vec_mergel<mode>\"\n+  [(set (match_operand:V_HW               0 \"register_operand\" \"=v\")\n+\t(unspec:V_HW [(match_operand:V_HW 1 \"register_operand\"  \"v\")\n+\t\t      (match_operand:V_HW 2 \"register_operand\"  \"v\")]\n+\t\t     UNSPEC_VEC_MERGEL))]\n+  \"TARGET_VX\"\n+  \"vmrl<bhfgq>\\t%v0,%1,%2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector pack\n+\n+(define_insn \"vec_pack<mode>\"\n+  [(set (match_operand:<vec_half>                    0 \"register_operand\" \"=v\")\n+\t(unspec:<vec_half> [(match_operand:VI_HW_HSD 1 \"register_operand\"  \"v\")\n+\t\t\t    (match_operand:VI_HW_HSD 2 \"register_operand\"  \"v\")]\n+\t\t\t   UNSPEC_VEC_PACK))]\n+  \"TARGET_VX\"\n+  \"vpk<bhfgq>\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector pack saturate\n+\n+(define_insn \"vec_packs<mode>\"\n+  [(set (match_operand:<vec_half>                    0 \"register_operand\" \"=v\")\n+\t(unspec:<vec_half> [(match_operand:VI_HW_HSD 1 \"register_operand\"  \"v\")\n+\t\t\t    (match_operand:VI_HW_HSD 2 \"register_operand\"  \"v\")]\n+\t\t\t   UNSPEC_VEC_PACK_SATURATE))]\n+  \"TARGET_VX\"\n+  \"vpks<bhfgq>\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; This is vec_packs_cc + loading cc into a caller specified memory location.\n+(define_expand \"vec_packs_cc<mode>\"\n+  [(parallel\n+    [(set (reg:CCRAW CC_REGNUM)\n+\t  (unspec:CCRAW [(match_operand:VI_HW_HSD 1 \"register_operand\" \"\")\n+\t\t\t (match_operand:VI_HW_HSD 2 \"register_operand\" \"\")]\n+\t\t\tUNSPEC_VEC_PACK_SATURATE_GENCC))\n+     (set (match_operand:<vec_half> 0 \"register_operand\" \"\")\n+\t  (unspec:<vec_half> [(match_dup 1) (match_dup 2)]\n+\t\t\t     UNSPEC_VEC_PACK_SATURATE_CC))])\n+   (set (match_dup 4)\n+\t(unspec:SI [(reg:CCRAW CC_REGNUM)] UNSPEC_CC_TO_INT))\n+   (set (match_operand:SI 3 \"memory_operand\" \"\")\n+\t(match_dup 4))]\n+  \"TARGET_VX\"\n+{\n+  operands[4] = gen_reg_rtx (SImode);\n+})\n+\n+(define_insn \"*vec_packs_cc<mode>\"\n+  [(set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_operand:VI_HW_HSD 1 \"register_operand\" \"v\")\n+\t\t       (match_operand:VI_HW_HSD 2 \"register_operand\" \"v\")]\n+\t\t      UNSPEC_VEC_PACK_SATURATE_GENCC))\n+   (set (match_operand:<vec_half> 0 \"register_operand\" \"=v\")\n+\t(unspec:<vec_half> [(match_dup 1) (match_dup 2)]\n+\t\t\t   UNSPEC_VEC_PACK_SATURATE_CC))]\n+  \"TARGET_VX\"\n+  \"vpks<bhfgq>s\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector pack logical saturate\n+\n+(define_insn \"vec_packsu<mode>\"\n+  [(set (match_operand:<vec_half>                    0 \"register_operand\" \"=v\")\n+\t(unspec:<vec_half> [(match_operand:VI_HW_HSD 1 \"register_operand\"  \"v\")\n+\t\t\t    (match_operand:VI_HW_HSD 2 \"register_operand\"  \"v\")]\n+\t\t\t   UNSPEC_VEC_PACK_UNSIGNED_SATURATE))]\n+  \"TARGET_VX\"\n+  \"vpkls<bhfgq>\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; Emulate saturate unsigned pack on signed operands.\n+; Zero out negative elements and continue with the unsigned saturating pack.\n+(define_expand \"vec_packsu_u<mode>\"\n+  [(set (match_operand:<vec_half>                    0 \"register_operand\" \"=v\")\n+\t(unspec:<vec_half> [(match_operand:VI_HW_HSD 1 \"register_operand\"  \"v\")\n+\t\t\t    (match_operand:VI_HW_HSD 2 \"register_operand\"  \"v\")]\n+\t\t\t   UNSPEC_VEC_PACK_UNSIGNED_SATURATE))]\n+  \"TARGET_VX\"\n+{\n+   rtx null_vec = CONST0_RTX(<MODE>mode);\n+   machine_mode half_mode;\n+   switch (<MODE>mode)\n+   {\n+     case V8HImode: half_mode = V16QImode; break;\n+     case V4SImode: half_mode = V8HImode; break;\n+     case V2DImode: half_mode = V4SImode; break;\n+     default: gcc_unreachable ();\n+   }\n+   s390_expand_vcond (operands[1], operands[1], null_vec,\n+\t\t      GE, operands[1], null_vec);\n+   s390_expand_vcond (operands[2], operands[2], null_vec,\n+\t\t      GE, operands[2], null_vec);\n+   emit_insn (gen_rtx_SET (operands[0],\n+\t\t\t   gen_rtx_UNSPEC (half_mode,\n+\t\t\t\t\t   gen_rtvec (2, operands[1], operands[2]),\n+\t\t\t\t\t   UNSPEC_VEC_PACK_UNSIGNED_SATURATE)));\n+   DONE;\n+})\n+\n+; This is vec_packsu_cc + loading cc into a caller specified memory location.\n+; FIXME: The reg to target mem copy should be issued by reload?!\n+(define_expand \"vec_packsu_cc<mode>\"\n+  [(parallel\n+    [(set (reg:CCRAW CC_REGNUM)\n+\t  (unspec:CCRAW [(match_operand:VI_HW_HSD 1 \"register_operand\" \"\")\n+\t\t\t (match_operand:VI_HW_HSD 2 \"register_operand\" \"\")]\n+\t\t\tUNSPEC_VEC_PACK_UNSIGNED_SATURATE_GENCC))\n+     (set (match_operand:<vec_half> 0 \"register_operand\" \"\")\n+\t  (unspec:<vec_half> [(match_dup 1) (match_dup 2)]\n+\t\t\t     UNSPEC_VEC_PACK_UNSIGNED_SATURATE_CC))])\n+   (set (match_dup 4)\n+\t(unspec:SI [(reg:CCRAW CC_REGNUM)] UNSPEC_CC_TO_INT))\n+   (set (match_operand:SI 3 \"memory_operand\" \"\")\n+\t(match_dup 4))]\n+  \"TARGET_VX\"\n+{\n+  operands[4] = gen_reg_rtx (SImode);\n+})\n+\n+(define_insn \"*vec_packsu_cc<mode>\"\n+  [(set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_operand:VI_HW_HSD 1 \"register_operand\" \"v\")\n+\t\t       (match_operand:VI_HW_HSD 2 \"register_operand\" \"v\")]\n+\t\t      UNSPEC_VEC_PACK_UNSIGNED_SATURATE_GENCC))\n+   (set (match_operand:<vec_half> 0 \"register_operand\" \"=v\")\n+\t(unspec:<vec_half> [(match_dup 1) (match_dup 2)]\n+\t\t\t   UNSPEC_VEC_PACK_UNSIGNED_SATURATE_CC))]\n+  \"TARGET_VX\"\n+  \"vpkls<bhfgq>s\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector permute\n+\n+; vec_perm is also RTL standard name, but we can only use it for V16QI\n+\n+(define_insn \"vec_zperm<mode>\"\n+  [(set (match_operand:V_HW_HSD                   0 \"register_operand\" \"=v\")\n+\t(unspec:V_HW_HSD [(match_operand:V_HW_HSD 1 \"register_operand\"  \"v\")\n+\t\t\t  (match_operand:V_HW_HSD 2 \"register_operand\"  \"v\")\n+\t\t\t  (match_operand:V16QI    3 \"register_operand\"  \"v\")]\n+\t\t\t UNSPEC_VEC_PERM))]\n+  \"TARGET_VX\"\n+  \"vperm\\t%v0,%v1,%v2,%v3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_expand \"vec_permi<mode>\"\n+  [(set (match_operand:V_HW_64                  0 \"register_operand\"  \"\")\n+\t(unspec:V_HW_64 [(match_operand:V_HW_64 1 \"register_operand\"  \"\")\n+\t\t\t (match_operand:V_HW_64 2 \"register_operand\"  \"\")\n+\t\t\t (match_operand:QI      3 \"immediate_operand\" \"\")]\n+\t\t\tUNSPEC_VEC_PERMI))]\n+  \"TARGET_VX\"\n+{\n+  HOST_WIDE_INT val = INTVAL (operands[3]);\n+  operands[3] = GEN_INT ((val & 1) | (val & 2) << 1);\n+})\n+\n+(define_insn \"*vec_permi<mode>\"\n+  [(set (match_operand:V_HW_64                  0 \"register_operand\" \"=v\")\n+\t(unspec:V_HW_64 [(match_operand:V_HW_64 1 \"register_operand\"  \"v\")\n+\t\t\t (match_operand:V_HW_64 2 \"register_operand\"  \"v\")\n+\t\t\t (match_operand:QI      3 \"immediate_operand\" \"C\")]\n+\t\t\tUNSPEC_VEC_PERMI))]\n+  \"TARGET_VX\"\n+  \"vpdi\\t%v0,%v1,%v2,%b3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector replicate\n+\n+\n+; Replicate from vector element\n+(define_expand \"vec_splat<mode>\"\n+  [(set (match_operand:V_HW                      0 \"register_operand\"  \"\")\n+\t(vec_duplicate:V_HW (vec_select:<non_vec>\n+\t\t\t     (match_operand:V_HW 1 \"register_operand\"  \"\")\n+\t\t\t     (parallel\n+\t\t\t      [(match_operand:QI 2 \"immediate_operand\" \"\")]))))]\n+  \"TARGET_VX\")\n+\n+; Vector scatter element\n+\n+; vscef, vsceg\n+\n+; A 64 bit target adress generated from 32 bit elements\n+(define_insn \"vec_scatter_elementv4si_DI\"\n+  [(set (mem:SI\n+\t (plus:DI (zero_extend:DI\n+\t\t   (unspec:SI [(match_operand:V4SI 1 \"register_operand\"  \"v\")\n+\t\t\t       (match_operand:DI   3 \"immediate_operand\" \"I\")]\n+\t\t\t      UNSPEC_VEC_EXTRACT))\n+\t\t  (match_operand:SI                2 \"address_operand\"  \"ZQ\")))\n+\t(unspec:SI [(match_operand:V4SI            0 \"register_operand\"  \"v\")\n+\t\t    (match_dup 3)] UNSPEC_VEC_EXTRACT))]\n+  \"TARGET_VX && TARGET_64BIT\"\n+  \"vscef\\t%v0,%O2(%v1,%R2),%3\"\n+  [(set_attr \"op_type\" \"VRV\")])\n+\n+; A 31 bit target address is generated from 64 bit elements\n+(define_insn \"vec_scatter_element<V_HW_64:mode>_SI\"\n+  [(set (mem:<non_vec>\n+\t (plus:SI (subreg:SI\n+\t\t   (unspec:<non_vec_int> [(match_operand:V_HW_64 1 \"register_operand\"  \"v\")\n+\t\t\t\t\t  (match_operand:DI      3 \"immediate_operand\" \"I\")]\n+\t\t\t\t\t UNSPEC_VEC_EXTRACT) 4)\n+\t\t  (match_operand:SI                              2 \"address_operand\"  \"ZQ\")))\n+\t(unspec:<non_vec> [(match_operand:V_HW_64                0 \"register_operand\"  \"v\")\n+\t\t\t   (match_dup 3)] UNSPEC_VEC_EXTRACT))]\n+  \"TARGET_VX && !TARGET_64BIT\"\n+  \"vsce<V_HW_64:gf>\\t%v0,%O2(%v1,%R2),%3\"\n+  [(set_attr \"op_type\" \"VRV\")])\n+\n+; Element size and target adress size is the same\n+(define_insn \"vec_scatter_element<mode>_<non_vec_int>\"\n+  [(set (mem:<non_vec>\n+\t (plus:<non_vec_int> (unspec:<non_vec_int>\n+\t\t\t      [(match_operand:<tointvec> 1 \"register_operand\"  \"v\")\n+\t\t\t       (match_operand:DI         3 \"immediate_operand\" \"I\")]\n+\t\t\t      UNSPEC_VEC_EXTRACT)\n+\t\t\t     (match_operand:DI           2 \"address_operand\"  \"ZQ\")))\n+\t(unspec:<non_vec> [(match_operand:V_HW_32_64     0 \"register_operand\"  \"v\")\n+\t\t\t   (match_dup 3)] UNSPEC_VEC_EXTRACT))]\n+  \"TARGET_VX\"\n+  \"vsce<gf>\\t%v0,%O2(%v1,%R2),%3\"\n+  [(set_attr \"op_type\" \"VRV\")])\n+\n+; Depending on the address size we have to expand a different pattern.\n+; This however cannot be represented in s390-builtins.def so we do the\n+; multiplexing here in the expander.\n+(define_expand \"vec_scatter_element<V_HW_32_64:mode>\"\n+  [(match_operand:V_HW_32_64 0 \"register_operand\" \"\")\n+   (match_operand:<tointvec> 1 \"register_operand\" \"\")\n+   (match_operand 2 \"address_operand\" \"\")\n+   (match_operand:DI 3 \"immediate_operand\" \"\")]\n+  \"TARGET_VX\"\n+{\n+  if (TARGET_64BIT)\n+    {\n+      PUT_MODE (operands[2], DImode);\n+      emit_insn (\n+\tgen_vec_scatter_element<V_HW_32_64:mode>_DI (operands[0], operands[1],\n+\t\t\t\t\t\t     operands[2], operands[3]));\n+    }\n+  else\n+    {\n+      PUT_MODE (operands[2], SImode);\n+      emit_insn (\n+\tgen_vec_scatter_element<V_HW_32_64:mode>_SI (operands[0], operands[1],\n+\t\t\t\t\t\t     operands[2], operands[3]));\n+    }\n+  DONE;\n+})\n+\n+\n+; Vector select\n+\n+; Operand 3 selects bits from either OP1 (0) or OP2 (1)\n+\n+; Comparison operator should not matter as long as we always use the same ?!\n+\n+; Operands 1 and 2 are swapped in order to match the altivec builtin.\n+; If operand 3 is a const_int bitmask this would be vec_merge\n+(define_expand \"vec_sel<mode>\"\n+  [(set (match_operand:V_HW 0 \"register_operand\" \"\")\n+\t(if_then_else:V_HW\n+\t (eq (match_operand:<tointvec> 3 \"register_operand\"  \"\")\n+\t     (match_dup 4))\n+\t (match_operand:V_HW 2 \"register_operand\"  \"\")\n+\t (match_operand:V_HW 1 \"register_operand\"  \"\")))]\n+  \"TARGET_VX\"\n+{\n+  operands[4] = CONST0_RTX (<tointvec>mode);\n+})\n+\n+\n+; Vector sign extend to doubleword\n+\n+; Sign extend of right most vector element to respective double-word\n+(define_insn \"vec_extend<mode>\"\n+  [(set (match_operand:VI_HW_QHS                    0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\"  \"v\")]\n+\t\t\t  UNSPEC_VEC_EXTEND))]\n+  \"TARGET_VX\"\n+  \"vseg<bhfgq>\\t%v0,%1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector store with length\n+\n+; Store bytes in OP1 from OP0 with the highest indexed byte to be\n+; stored from OP0 given by OP2\n+(define_insn \"vstl<mode>\"\n+  [(set (match_operand:BLK             2 \"memory_operand\"   \"=Q\")\n+\t(unspec:BLK [(match_operand:V  0 \"register_operand\"  \"v\")\n+\t\t     (match_operand:SI 1 \"register_operand\"  \"d\")]\n+\t\t    UNSPEC_VEC_STORE_LEN))]\n+  \"TARGET_VX\"\n+  \"vstl\\t%v0,%1,%2\"\n+  [(set_attr \"op_type\" \"VRS\")])\n+\n+\n+; Vector unpack high\n+\n+; vuphb, vuphh, vuphf\n+(define_insn \"vec_unpackh<mode>\"\n+  [(set (match_operand:<vec_double>                    0 \"register_operand\" \"=v\")\n+\t(unspec:<vec_double> [(match_operand:VI_HW_QHS 1 \"register_operand\"  \"v\")]\n+\t\t\t     UNSPEC_VEC_UNPACKH))]\n+  \"TARGET_VX\"\n+  \"vuph<bhfgq>\\t%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; vuplhb, vuplhh, vuplhf\n+(define_insn \"vec_unpackh_l<mode>\"\n+  [(set (match_operand:<vec_double>                    0 \"register_operand\" \"=v\")\n+\t(unspec:<vec_double> [(match_operand:VI_HW_QHS 1 \"register_operand\"  \"v\")]\n+\t\t\t     UNSPEC_VEC_UNPACKH_L))]\n+  \"TARGET_VX\"\n+  \"vuplh<bhfgq>\\t%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector unpack low\n+\n+; vuplb, vuplhw, vuplf\n+(define_insn \"vec_unpackl<mode>\"\n+  [(set (match_operand:<vec_double>                    0 \"register_operand\" \"=v\")\n+\t(unspec:<vec_double> [(match_operand:VI_HW_QHS 1 \"register_operand\"  \"v\")]\n+\t\t\t     UNSPEC_VEC_UNPACKL))]\n+  \"TARGET_VX\"\n+  \"vupl<bhfgq><w>\\t%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; vupllb, vupllh, vupllf\n+(define_insn \"vec_unpackl_l<mode>\"\n+  [(set (match_operand:<vec_double>                    0 \"register_operand\" \"=v\")\n+\t(unspec:<vec_double> [(match_operand:VI_HW_QHS 1 \"register_operand\"  \"v\")]\n+\t\t\t     UNSPEC_VEC_UNPACKL_L))]\n+  \"TARGET_VX\"\n+  \"vupll<bhfgq>\\t%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector add\n+\n+; vaq\n+\n+; zvector builtins uses V16QI operands.  So replace the modes in order\n+; to map this to a TImode add.  We have to keep the V16QI mode\n+; operands in the expander in order to allow some operand type\n+; checking when expanding the builtin.\n+(define_expand \"vec_add_u128\"\n+  [(match_operand:V16QI 0 \"register_operand\" \"\")\n+   (match_operand:V16QI 1 \"register_operand\" \"\")\n+   (match_operand:V16QI 2 \"register_operand\" \"\")]\n+  \"TARGET_VX\"\n+{\n+  rtx op0 = gen_rtx_SUBREG (TImode, operands[0], 0);\n+  rtx op1 = gen_rtx_SUBREG (TImode, operands[1], 0);\n+  rtx op2 = gen_rtx_SUBREG (TImode, operands[2], 0);\n+\n+  emit_insn (gen_rtx_SET (op0,\n+\t\t\t  gen_rtx_PLUS (TImode, op1, op2)));\n+  DONE;\n+})\n+\n+; Vector add compute carry\n+\n+(define_insn \"vec_addc<mode>\"\n+  [(set (match_operand:VI_HW                0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW [(match_operand:VI_HW 1 \"register_operand\"  \"v\")\n+\t\t       (match_operand:VI_HW 2 \"register_operand\"  \"v\")]\n+\t\t      UNSPEC_VEC_ADDC))]\n+  \"TARGET_VX\"\n+  \"vacc<bhfgq>\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"vec_addc_u128\"\n+  [(set (match_operand:V16QI                0 \"register_operand\" \"=v\")\n+\t(unspec:V16QI [(match_operand:V16QI 1 \"register_operand\"  \"v\")\n+\t\t       (match_operand:V16QI 2 \"register_operand\"  \"v\")]\n+\t\t      UNSPEC_VEC_ADDC_U128))]\n+  \"TARGET_VX\"\n+  \"vaccq\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector add with carry\n+\n+(define_insn \"vec_adde_u128\"\n+  [(set (match_operand:V16QI                0 \"register_operand\" \"=v\")\n+\t(unspec:V16QI [(match_operand:V16QI 1 \"register_operand\"  \"v\")\n+\t\t       (match_operand:V16QI 2 \"register_operand\"  \"v\")\n+\t\t       (match_operand:V16QI 3 \"register_operand\"  \"v\")]\n+\t\t      UNSPEC_VEC_ADDE_U128))]\n+  \"TARGET_VX\"\n+  \"vacq\\t%v0,%v1,%v2,%v3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector add with carry compute carry\n+\n+(define_insn \"vec_addec_u128\"\n+  [(set (match_operand:V16QI                0 \"register_operand\" \"=v\")\n+\t(unspec:V16QI [(match_operand:V16QI 1 \"register_operand\"  \"v\")\n+\t\t       (match_operand:V16QI 2 \"register_operand\"  \"v\")\n+\t\t       (match_operand:V16QI 3 \"register_operand\"  \"v\")]\n+\t\t      UNSPEC_VEC_ADDEC_U128))]\n+  \"TARGET_VX\"\n+  \"vacccq\\t%v0,%v1,%v2,%v3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector and\n+\n+; The following two patterns allow mixed mode and's as required for the intrinsics.\n+(define_insn \"and_av2df3\"\n+  [(set (match_operand:V2DF                        0 \"register_operand\" \"=v\")\n+\t(and:V2DF (subreg:V2DF (match_operand:V2DI 1 \"register_operand\"  \"v\") 0)\n+\t\t  (match_operand:V2DF              2 \"register_operand\"  \"v\")))]\n+  \"TARGET_VX\"\n+  \"vn\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"and_cv2df3\"\n+  [(set (match_operand:V2DF                        0 \"register_operand\" \"=v\")\n+\t(and:V2DF (match_operand:V2DF              1 \"register_operand\"  \"v\")\n+\t\t  (subreg:V2DF (match_operand:V2DI 2 \"register_operand\"  \"v\") 0)))]\n+  \"TARGET_VX\"\n+  \"vn\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector and with complement\n+\n+; vnc\n+(define_insn \"vec_andc<mode>3\"\n+  [(set (match_operand:VT_HW                       0 \"register_operand\" \"=v\")\n+\t(and:VT_HW (not:VT_HW (match_operand:VT_HW 2 \"register_operand\"  \"v\"))\n+\t\t  (match_operand:VT_HW             1 \"register_operand\"  \"v\")))]\n+  \"TARGET_VX\"\n+  \"vnc\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; The following two patterns allow mixed mode and's as required for the intrinsics.\n+(define_insn \"vec_andc_av2df3\"\n+  [(set (match_operand:V2DF                        0 \"register_operand\" \"=v\")\n+\t(and:V2DF (not:V2DF (match_operand:V2DF    2 \"register_operand\"  \"v\"))\n+\t\t  (subreg:V2DF (match_operand:V2DI 1 \"register_operand\"  \"v\") 0)))]\n+\n+  \"TARGET_VX\"\n+  \"vnc\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"vec_andc_cv2df3\"\n+  [(set (match_operand:V2DF 0 \"register_operand\" \"=v\")\n+\t(and:V2DF (not:V2DF (subreg:V2DF (match_operand:V2DI 2 \"register_operand\" \"v\") 0))\n+\t\t  (match_operand:V2DF 1 \"register_operand\" \"v\")))]\n+  \"TARGET_VX\"\n+  \"vnc\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector average\n+\n+(define_insn \"vec_avg<mode>\"\n+  [(set (match_operand:VI_HW                0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW [(match_operand:VI_HW 1 \"register_operand\"  \"v\")\n+\t\t       (match_operand:VI_HW 2 \"register_operand\"  \"v\")]\n+\t\t      UNSPEC_VEC_AVG))]\n+  \"TARGET_VX\"\n+  \"vavg<bhfgq>\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; Vector average logical\n+\n+(define_insn \"vec_avgu<mode>\"\n+  [(set (match_operand:VI_HW                0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW [(match_operand:VI_HW 1 \"register_operand\"  \"v\")\n+\t\t       (match_operand:VI_HW 2 \"register_operand\"  \"v\")]\n+\t\t      UNSPEC_VEC_AVGU))]\n+  \"TARGET_VX\"\n+  \"vavgl<bhfgq>\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector checksum\n+\n+(define_insn \"vec_checksum\"\n+  [(set (match_operand:V4SI               0 \"register_operand\" \"=v\")\n+\t(unspec:V4SI [(match_operand:V4SI 1 \"register_operand\"  \"v\")\n+\t\t      (match_operand:V4SI 2 \"register_operand\"  \"v\")]\n+\t\t     UNSPEC_VEC_CHECKSUM))]\n+  \"TARGET_VX\"\n+  \"vcksm\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+;;\n+;; Vector compare\n+;;\n+\n+; vec_all/any int compares\n+\n+(define_expand \"vec_all_<intcmpcc:code><VI_HW:mode>\"\n+  [(match_operand:SI                0 \"register_operand\" \"\")\n+   (intcmpcc (match_operand:VI_HW 1 \"register_operand\" \"\")\n+\t     (match_operand:VI_HW 2 \"register_operand\" \"\"))]\n+  \"TARGET_VX\"\n+{\n+  s390_expand_vec_compare_cc (operands[0],\n+\t\t\t      <intcmpcc:CODE>,\n+\t\t\t      operands[1],\n+\t\t\t      operands[2],\n+\t\t\t      true);\n+  DONE;\n+})\n+\n+(define_expand \"vec_any_<intcmpcc:code><VI_HW:mode>\"\n+  [(match_operand:SI                0 \"register_operand\" \"\")\n+   (intcmpcc (match_operand:VI_HW 1 \"register_operand\" \"\")\n+\t     (match_operand:VI_HW 2 \"register_operand\" \"\"))]\n+  \"TARGET_VX\"\n+{\n+  s390_expand_vec_compare_cc (operands[0],\n+\t\t\t      <intcmpcc:CODE>,\n+\t\t\t      operands[1],\n+\t\t\t      operands[2],\n+\t\t\t      false);\n+  DONE;\n+})\n+\n+; vec_all/any fp compares\n+\n+(define_expand \"vec_all_<fpcmpcc:code>v2df\"\n+  [(match_operand:SI            0 \"register_operand\" \"\")\n+   (fpcmpcc (match_operand:V2DF 1 \"register_operand\" \"\")\n+\t    (match_operand:V2DF 2 \"register_operand\" \"\"))]\n+  \"TARGET_VX\"\n+{\n+  s390_expand_vec_compare_cc (operands[0],\n+\t\t\t      <fpcmpcc:CODE>,\n+\t\t\t      operands[1],\n+\t\t\t      operands[2],\n+\t\t\t      true);\n+  DONE;\n+})\n+\n+(define_expand \"vec_any_<fpcmpcc:code>v2df\"\n+  [(match_operand:SI            0 \"register_operand\" \"\")\n+   (fpcmpcc (match_operand:V2DF 1 \"register_operand\" \"\")\n+\t    (match_operand:V2DF 2 \"register_operand\" \"\"))]\n+  \"TARGET_VX\"\n+{\n+  s390_expand_vec_compare_cc (operands[0],\n+\t\t\t      <fpcmpcc:CODE>,\n+\t\t\t      operands[1],\n+\t\t\t      operands[2],\n+\t\t\t      false);\n+  DONE;\n+})\n+\n+\n+; Compare without generating CC\n+\n+(define_expand \"vec_cmp<intcmp:code><VI_HW:mode>\"\n+  [(set (match_operand:VI_HW               0 \"register_operand\" \"=v\")\n+\t(intcmp:VI_HW (match_operand:VI_HW 1 \"register_operand\"  \"v\")\n+\t\t      (match_operand:VI_HW 2 \"register_operand\"  \"v\")))]\n+  \"TARGET_VX\"\n+{\n+  s390_expand_vec_compare (operands[0], <intcmp:CODE>, operands[1], operands[2]);\n+  DONE;\n+})\n+\n+(define_expand \"vec_cmp<fpcmp:code>v2df\"\n+  [(set (match_operand:V2DI             0 \"register_operand\" \"=v\")\n+\t(fpcmp:V2DI (match_operand:V2DF 1 \"register_operand\"  \"v\")\n+\t\t    (match_operand:V2DF 2 \"register_operand\"  \"v\")))]\n+  \"TARGET_VX\"\n+{\n+  s390_expand_vec_compare (operands[0], <fpcmp:CODE>, operands[1], operands[2]);\n+  DONE;\n+})\n+\n+\n+; Vector count leading zeros\n+\n+; vec_cntlz -> clz\n+; vec_cnttz -> ctz\n+\n+; Vector xor\n+\n+; vec_xor -> xor\n+\n+; The following two patterns allow mixed mode xor's as required for the intrinsics.\n+(define_insn \"xor_av2df3\"\n+  [(set (match_operand:V2DF 0 \"register_operand\" \"=v\")\n+\t(xor:V2DF (subreg:V2DF (match_operand:V2DI 1 \"register_operand\" \"v\") 0)\n+\t\t  (match_operand:V2DF 2 \"register_operand\" \"v\")))]\n+  \"TARGET_VX\"\n+  \"vx\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"xor_cv2df3\"\n+  [(set (match_operand:V2DF 0 \"register_operand\" \"=v\")\n+\t(xor:V2DF (match_operand:V2DF 1 \"register_operand\" \"v\")\n+\t\t  (subreg:V2DF (match_operand:V2DI 2 \"register_operand\" \"v\") 0)))]\n+  \"TARGET_VX\"\n+  \"vx\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector Galois field multiply sum\n+\n+(define_insn \"vec_gfmsum<mode>\"\n+  [(set (match_operand:VI_HW_QHS 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\" \"v\")]\n+\t\t\t  UNSPEC_VEC_GFMSUM))]\n+  \"TARGET_VX\"\n+  \"vgfm<bhfgq>\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"vec_gfmsum_128\"\n+  [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n+\t(unspec:V16QI [(match_operand:V2DI 1 \"register_operand\" \"v\")\n+\t\t       (match_operand:V2DI 2 \"register_operand\" \"v\")]\n+\t\t      UNSPEC_VEC_GFMSUM_128))]\n+  \"TARGET_VX\"\n+  \"vgfmg\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"vec_gfmsum_accum<mode>\"\n+  [(set (match_operand:<vec_double> 0 \"register_operand\" \"=v\")\n+\t(unspec:<vec_double> [(match_operand:VI_HW_QHS 1 \"register_operand\" \"v\")\n+\t\t\t      (match_operand:VI_HW_QHS 2 \"register_operand\" \"v\")\n+\t\t\t      (match_operand:<vec_double> 3 \"register_operand\" \"v\")]\n+\t\t\t     UNSPEC_VEC_GFMSUM_ACCUM))]\n+  \"TARGET_VX\"\n+  \"vgfma<bhfgq>\\t%v0,%v1,%v2,%v3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"vec_gfmsum_accum_128\"\n+  [(set (match_operand:V16QI 0 \"register_operand\" \"=v\")\n+\t(unspec:V16QI [(match_operand:V2DI 1 \"register_operand\" \"v\")\n+\t\t       (match_operand:V2DI 2 \"register_operand\" \"v\")\n+\t\t       (match_operand:V16QI 3 \"register_operand\" \"v\")]\n+\t\t      UNSPEC_VEC_GFMSUM_ACCUM_128))]\n+  \"TARGET_VX\"\n+  \"vgfmag\\t%v0,%v1,%v2,%v3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; FIXME: vec_neg ?\n+\n+; Vector load positive: vec_abs -> abs\n+; Vector maximum vec_max -> smax, logical vec_max -> umax\n+; Vector maximum vec_min -> smin, logical vec_min -> umin\n+\n+\n+; Vector multiply and add high\n+\n+; vec_mladd -> vec_vmal\n+; vmalb, vmalh, vmalf, vmalg\n+(define_insn \"vec_vmal<mode>\"\n+  [(set (match_operand:VI_HW 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW [(match_operand:VI_HW 1 \"register_operand\" \"v\")\n+\t\t       (match_operand:VI_HW 2 \"register_operand\" \"v\")\n+\t\t       (match_operand:VI_HW 3 \"register_operand\" \"v\")]\n+\t\t      UNSPEC_VEC_VMAL))]\n+  \"TARGET_VX\"\n+  \"vmal<bhfgq><w>\\t%v0,%v1,%v2,%v3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; vec_mhadd -> vec_vmah/vec_vmalh\n+\n+; vmahb; vmahh, vmahf, vmahg\n+(define_insn \"vec_vmah<mode>\"\n+  [(set (match_operand:VI_HW 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW [(match_operand:VI_HW 1 \"register_operand\" \"v\")\n+\t\t       (match_operand:VI_HW 2 \"register_operand\" \"v\")\n+\t\t       (match_operand:VI_HW 3 \"register_operand\" \"v\")]\n+\t\t      UNSPEC_VEC_VMAH))]\n+  \"TARGET_VX\"\n+  \"vmah<bhfgq>\\t%v0,%v1,%v2,%v3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; vmalhb; vmalhh, vmalhf, vmalhg\n+(define_insn \"vec_vmalh<mode>\"\n+  [(set (match_operand:VI_HW 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW [(match_operand:VI_HW 1 \"register_operand\" \"v\")\n+\t\t       (match_operand:VI_HW 2 \"register_operand\" \"v\")\n+\t\t       (match_operand:VI_HW 3 \"register_operand\" \"v\")]\n+\t\t      UNSPEC_VEC_VMALH))]\n+  \"TARGET_VX\"\n+  \"vmalh<bhfgq>\\t%v0,%v1,%v2,%v3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; vec_meadd -> vec_vmae/vec_vmale\n+\n+; vmaeb; vmaeh, vmaef, vmaeg\n+(define_insn \"vec_vmae<mode>\"\n+  [(set (match_operand:<vec_double> 0 \"register_operand\" \"=v\")\n+\t(unspec:<vec_double> [(match_operand:VI_HW_QHS 1 \"register_operand\" \"v\")\n+\t\t\t      (match_operand:VI_HW_QHS 2 \"register_operand\" \"v\")\n+\t\t\t      (match_operand:<vec_double> 3 \"register_operand\" \"v\")]\n+\t\t\t     UNSPEC_VEC_VMAE))]\n+  \"TARGET_VX\"\n+  \"vmae<bhfgq>\\t%v0,%v1,%v2,%v3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; vmaleb; vmaleh, vmalef, vmaleg\n+(define_insn \"vec_vmale<mode>\"\n+  [(set (match_operand:<vec_double> 0 \"register_operand\" \"=v\")\n+\t(unspec:<vec_double> [(match_operand:VI_HW_QHS 1 \"register_operand\" \"v\")\n+\t\t\t      (match_operand:VI_HW_QHS 2 \"register_operand\" \"v\")\n+\t\t\t      (match_operand:<vec_double> 3 \"register_operand\" \"v\")]\n+\t\t\t     UNSPEC_VEC_VMALE))]\n+  \"TARGET_VX\"\n+  \"vmale<bhfgq>\\t%v0,%v1,%v2,%v3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; vec_moadd -> vec_vmao/vec_vmalo\n+\n+; vmaob; vmaoh, vmaof, vmaog\n+(define_insn \"vec_vmao<mode>\"\n+  [(set (match_operand:<vec_double> 0 \"register_operand\" \"=v\")\n+\t(unspec:<vec_double> [(match_operand:VI_HW_QHS 1 \"register_operand\" \"v\")\n+\t\t\t      (match_operand:VI_HW_QHS 2 \"register_operand\" \"v\")\n+\t\t\t      (match_operand:<vec_double> 3 \"register_operand\" \"v\")]\n+\t\t\t     UNSPEC_VEC_VMAO))]\n+  \"TARGET_VX\"\n+  \"vmao<bhfgq>\\t%v0,%v1,%v2,%v3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; vmalob; vmaloh, vmalof, vmalog\n+(define_insn \"vec_vmalo<mode>\"\n+  [(set (match_operand:<vec_double> 0 \"register_operand\" \"=v\")\n+\t(unspec:<vec_double> [(match_operand:VI_HW_QHS 1 \"register_operand\" \"v\")\n+\t\t\t      (match_operand:VI_HW_QHS 2 \"register_operand\" \"v\")\n+\t\t\t      (match_operand:<vec_double> 3 \"register_operand\" \"v\")]\n+\t\t\t     UNSPEC_VEC_VMALO))]\n+  \"TARGET_VX\"\n+  \"vmalo<bhfgq>\\t%v0,%v1,%v2,%v3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector multiply high\n+\n+; vec_mulh -> vec_smulh/vec_umulh\n+\n+; vmhb, vmhh, vmhf\n+(define_insn \"vec_smulh<mode>\"\n+  [(set (match_operand:VI_HW_QHS 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\" \"v\")]\n+\t\t\t  UNSPEC_VEC_SMULT_HI))]\n+  \"TARGET_VX\"\n+  \"vmh<bhfgq>\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; vmlhb, vmlhh, vmlhf\n+(define_insn \"vec_umulh<mode>\"\n+  [(set (match_operand:VI_HW_QHS 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\" \"v\")]\n+\t\t\t  UNSPEC_VEC_UMULT_HI))]\n+  \"TARGET_VX\"\n+  \"vmlh<bhfgq>\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector multiply low\n+\n+; vec_mule -> vec_widen_umult_even/vec_widen_smult_even\n+; vec_mulo -> vec_widen_umult_odd/vec_widen_smult_odd\n+\n+\n+; Vector nor\n+\n+(define_insn \"vec_nor<mode>3\"\n+  [(set (match_operand:VT_HW 0 \"register_operand\" \"=v\")\n+\t(not:VT_HW (ior:VT_HW (match_operand:VT_HW 1 \"register_operand\" \"v\")\n+\t\t\t      (match_operand:VT_HW 2 \"register_operand\" \"v\"))))]\n+  \"TARGET_VX\"\n+  \"vno\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; The following two patterns allow mixed mode and's as required for the intrinsics.\n+(define_insn \"vec_nor_av2df3\"\n+  [(set (match_operand:V2DF 0 \"register_operand\" \"=v\")\n+\t(not:V2DF (ior:V2DF (subreg:V2DF (match_operand:V2DI 1 \"register_operand\" \"v\") 0)\n+\t\t\t    (match_operand:V2DF 2 \"register_operand\" \"v\"))))]\n+  \"TARGET_VX\"\n+  \"vno\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"vec_nor_cv2df3\"\n+  [(set (match_operand:V2DF 0 \"register_operand\" \"=v\")\n+\t(not:V2DF (ior:V2DF (match_operand:V2DF 1 \"register_operand\" \"v\")\n+\t\t\t    (subreg:V2DF (match_operand:V2DI 2 \"register_operand\" \"v\") 0))))]\n+  \"TARGET_VX\"\n+  \"vno\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector or\n+\n+; The following two patterns allow mixed mode or's as required for the intrinsics.\n+(define_insn \"ior_av2df3\"\n+  [(set (match_operand:V2DF 0 \"register_operand\" \"=v\")\n+\t(ior:V2DF (subreg:V2DF (match_operand:V2DI 1 \"register_operand\" \"v\") 0)\n+\t\t  (match_operand:V2DF 2 \"register_operand\" \"v\")))]\n+  \"TARGET_VX\"\n+  \"vo\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"ior_cv2df3\"\n+  [(set (match_operand:V2DF 0 \"register_operand\" \"=v\")\n+\t(ior:V2DF (match_operand:V2DF 1 \"register_operand\" \"v\")\n+\t\t  (subreg:V2DF (match_operand:V2DI 2 \"register_operand\" \"v\") 0)))]\n+  \"TARGET_VX\"\n+  \"vo\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector population count vec_popcnt -> popcount\n+; Vector element rotate left logical vec_rl -> vrotl, vec_rli -> rot\n+\n+; Vector element rotate and insert under mask\n+\n+; verimb, verimh, verimf, verimg\n+(define_insn \"verim<mode>\"\n+  [(set (match_operand:VI_HW                0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW [(match_operand:VI_HW 1 \"register_operand\"  \"0\")\n+\t\t       (match_operand:VI_HW 2 \"register_operand\"  \"v\")\n+\t\t       (match_operand:VI_HW 3 \"register_operand\"  \"v\")\n+\t\t       (match_operand:SI    4 \"immediate_operand\" \"I\")]\n+\t\t      UNSPEC_VEC_RL_MASK))]\n+  \"TARGET_VX\"\n+  \"verim<bhfgq>\\t%v0,%v2,%v3,%b4\"\n+  [(set_attr \"op_type\" \"VRI\")])\n+\n+\n+; Vector shift left\n+\n+(define_insn \"vec_sll<VI_HW:mode><VI_HW_QHS:mode>\"\n+  [(set (match_operand:VI_HW                    0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW [(match_operand:VI_HW     1 \"register_operand\"  \"v\")\n+\t\t       (match_operand:VI_HW_QHS 2 \"register_operand\"  \"v\")]\n+\t\t      UNSPEC_VEC_SLL))]\n+  \"TARGET_VX\"\n+  \"vsl\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector shift left by byte\n+\n+(define_insn \"vec_slb<mode>\"\n+  [(set (match_operand:V_HW 0 \"register_operand\"                    \"=v\")\n+\t(unspec:V_HW [(match_operand:V_HW 1 \"register_operand\"       \"v\")\n+\t\t      (match_operand:<tointvec> 2 \"register_operand\" \"v\")]\n+\t\t     UNSPEC_VEC_SLB))]\n+  \"TARGET_VX\"\n+  \"vslb\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector shift left double by byte\n+\n+(define_insn \"vec_sld<mode>\"\n+  [(set (match_operand:V_HW 0 \"register_operand\"              \"=v\")\n+\t(unspec:V_HW [(match_operand:V_HW 1 \"register_operand\" \"v\")\n+\t\t      (match_operand:V_HW 2 \"register_operand\" \"v\")\n+\t\t      (match_operand:DI 3 \"immediate_operand\" \"C\")]\n+\t\t     UNSPEC_VEC_SLDB))]\n+  \"TARGET_VX\"\n+  \"vsldb\\t%v0,%v1,%v2,%b3\"\n+  [(set_attr \"op_type\" \"VRI\")])\n+\n+(define_expand \"vec_sldw<mode>\"\n+  [(set (match_operand:V_HW 0 \"register_operand\"               \"\")\n+\t(unspec:V_HW [(match_operand:V_HW 1 \"register_operand\" \"\")\n+\t\t      (match_operand:V_HW 2 \"register_operand\" \"\")\n+\t\t      (match_operand:DI 3 \"immediate_operand\"  \"\")]\n+\t\t     UNSPEC_VEC_SLDB))]\n+  \"TARGET_VX\"\n+{\n+  operands[3] = GEN_INT (INTVAL (operands[3]) << 2);\n+})\n+\n+; Vector shift right arithmetic\n+\n+(define_insn \"vec_sral<VI_HW:mode><VI_HW_QHS:mode>\"\n+  [(set (match_operand:VI_HW                    0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW [(match_operand:VI_HW     1 \"register_operand\"  \"v\")\n+\t\t       (match_operand:VI_HW_QHS 2 \"register_operand\"  \"v\")]\n+\t\t      UNSPEC_VEC_SRAL))]\n+  \"TARGET_VX\"\n+  \"vsra\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector shift right arithmetic by byte\n+\n+(define_insn \"vec_srab<mode>\"\n+  [(set (match_operand:V_HW 0 \"register_operand\"                    \"=v\")\n+\t(unspec:V_HW [(match_operand:V_HW 1 \"register_operand\"       \"v\")\n+\t\t      (match_operand:<tointvec> 2 \"register_operand\" \"v\")]\n+\t\t     UNSPEC_VEC_SRAB))]\n+  \"TARGET_VX\"\n+  \"vsrab\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector shift right logical\n+\n+(define_insn \"vec_srl<VI_HW:mode><VI_HW_QHS:mode>\"\n+  [(set (match_operand:VI_HW                    0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW [(match_operand:VI_HW     1 \"register_operand\"  \"v\")\n+\t\t       (match_operand:VI_HW_QHS 2 \"register_operand\"  \"v\")]\n+\t\t      UNSPEC_VEC_SRL))]\n+  \"TARGET_VX\"\n+  \"vsrl\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector shift right logical by byte\n+\n+; Pattern definition in vector.md\n+(define_expand \"vec_srb<mode>\"\n+  [(set (match_operand:V_HW 0 \"register_operand\"                     \"\")\n+\t(unspec:V_HW [(match_operand:V_HW 1 \"register_operand\"       \"\")\n+\t\t      (match_operand:<tointvec> 2 \"register_operand\" \"\")]\n+\t\t     UNSPEC_VEC_SRLB))]\n+  \"TARGET_VX\")\n+\n+\n+; Vector subtract\n+\n+(define_insn \"vec_sub_u128\"\n+  [(set (match_operand:V16QI 0 \"register_operand\"               \"=v\")\n+\t(unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n+\t\t       (match_operand:V16QI 2 \"register_operand\" \"v\")]\n+\t\t     UNSPEC_VEC_SUB_U128))]\n+  \"TARGET_VX\"\n+  \"vsq\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector subtract compute borrow indication\n+\n+(define_insn \"vec_subc<mode>\"\n+  [(set (match_operand:VI_HW 0 \"register_operand\"               \"=v\")\n+\t(unspec:VI_HW [(match_operand:VI_HW 1 \"register_operand\" \"v\")\n+\t\t       (match_operand:VI_HW 2 \"register_operand\" \"v\")]\n+\t\t      UNSPEC_VEC_SUBC))]\n+  \"TARGET_VX\"\n+  \"vscbi<bhfgq>\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"vec_subc_u128\"\n+  [(set (match_operand:V16QI 0 \"register_operand\"               \"=v\")\n+\t(unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n+\t\t       (match_operand:V16QI 2 \"register_operand\" \"v\")]\n+\t\t     UNSPEC_VEC_SUBC_U128))]\n+  \"TARGET_VX\"\n+  \"vscbiq\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector subtract with borrow indication\n+\n+(define_insn \"vec_sube_u128\"\n+  [(set (match_operand:V16QI 0 \"register_operand\"               \"=v\")\n+\t(unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n+\t\t       (match_operand:V16QI 2 \"register_operand\" \"v\")\n+\t\t       (match_operand:V16QI 3 \"register_operand\" \"v\")]\n+\t\t      UNSPEC_VEC_SUBE_U128))]\n+  \"TARGET_VX\"\n+  \"vsbiq\\t%v0,%v1,%v2,%v3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector subtract with borrow compute and borrow indication\n+\n+(define_insn \"vec_subec_u128\"\n+  [(set (match_operand:V16QI 0 \"register_operand\"               \"=v\")\n+\t(unspec:V16QI [(match_operand:V16QI 1 \"register_operand\" \"v\")\n+\t\t       (match_operand:V16QI 2 \"register_operand\" \"v\")\n+\t\t       (match_operand:V16QI 3 \"register_operand\" \"v\")]\n+\t\t      UNSPEC_VEC_SUBEC_U128))]\n+  \"TARGET_VX\"\n+  \"vsbcbiq\\t%v0,%v1,%v2,%v3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector sum across\n+\n+; Sum across DImode parts of the 1st operand and add the rightmost\n+; element of 2nd operand\n+; vsumgh, vsumgf\n+(define_expand \"vec_sum2<mode>\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"\")\n+\t(unspec:V2DI [(match_operand:VI_HW_HS 1 \"register_operand\" \"\")\n+\t\t      (match_operand:VI_HW_HS 2 \"register_operand\" \"\")]\n+\t\t     UNSPEC_VEC_VSUMG))]\n+  \"TARGET_VX\")\n+\n+; vsumqh, vsumqf\n+(define_insn \"vec_sum_u128<mode>\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=v\")\n+\t(unspec:V2DI [(match_operand:VI_HW_SD 1 \"register_operand\" \"v\")\n+\t\t      (match_operand:VI_HW_SD 2 \"register_operand\" \"v\")]\n+\t\t     UNSPEC_VEC_VSUMQ))]\n+  \"TARGET_VX\"\n+  \"vsumq<bhfgq>\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; vsumb, vsumh\n+(define_expand \"vec_sum4<mode>\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"\")\n+\t(unspec:V4SI [(match_operand:VI_HW_QH 1 \"register_operand\" \"\")\n+\t\t      (match_operand:VI_HW_QH 2 \"register_operand\" \"\")]\n+\t\t     UNSPEC_VEC_VSUM))]\n+  \"TARGET_VX\")\n+\n+\n+; Vector test under mask\n+\n+(define_expand \"vec_test_mask_int<mode>\"\n+  [(set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_operand:V_HW 1 \"register_operand\" \"\")\n+\t\t       (match_operand:<tointvec> 2 \"register_operand\" \"\")]\n+\t\t      UNSPEC_VEC_TEST_MASK))\n+   (set (match_operand:SI 0 \"register_operand\" \"\")\n+\t(unspec:SI [(reg:CCRAW CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\")\n+\n+(define_insn \"*vec_test_mask<mode>\"\n+  [(set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_operand:V_HW 0 \"register_operand\" \"v\")\n+\t\t       (match_operand:<tointvec> 1 \"register_operand\" \"v\")]\n+\t\t      UNSPEC_VEC_TEST_MASK))]\n+  \"TARGET_VX\"\n+  \"vtm\\t%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+\n+; Vector find any element equal\n+\n+; vfaeb, vfaeh, vfaef\n+; vfaezb, vfaezh, vfaezf\n+(define_insn \"vfae<mode>\"\n+  [(set (match_operand:VI_HW_QHS 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:SI        3 \"immediate_operand\" \"C\")]\n+\t\t\t  UNSPEC_VEC_VFAE))]\n+  \"TARGET_VX\"\n+{\n+  unsigned HOST_WIDE_INT flags = INTVAL (operands[3]);\n+\n+  if (flags & VSTRING_FLAG_ZS)\n+    {\n+      flags &= ~VSTRING_FLAG_ZS;\n+      operands[3] = GEN_INT (flags);\n+      return \"vfaez<bhfgq>\\t%v0,%v1,%v2,%b3\";\n+    }\n+  return \"vfae<bhfgq>\\t%v0,%v1,%v2,%b3\";\n+}\n+[(set_attr \"op_type\" \"VRR\")])\n+\n+; vfaebs, vfaehs, vfaefs\n+; vfaezbs, vfaezhs, vfaezfs\n+(define_insn \"*vfaes<mode>\"\n+  [(set (match_operand:VI_HW_QHS 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:SI        3 \"immediate_operand\" \"C\")]\n+\t\t\t  UNSPEC_VEC_VFAE))\n+   (set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_dup 1)\n+\t\t       (match_dup 2)\n+\t\t       (match_dup 3)]\n+\t\t      UNSPEC_VEC_VFAECC))]\n+  \"TARGET_VX\"\n+{\n+  unsigned HOST_WIDE_INT flags = INTVAL (operands[3]);\n+\n+  if (flags & VSTRING_FLAG_ZS)\n+    {\n+      flags &= ~VSTRING_FLAG_ZS;\n+      operands[3] = GEN_INT (flags);\n+      return \"vfaez<bhfgq>s\\t%v0,%v1,%v2,%b3\";\n+    }\n+  return \"vfae<bhfgq>s\\t%v0,%v1,%v2,%b3\";\n+}\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_expand \"vfaez<mode>\"\n+  [(set (match_operand:VI_HW_QHS 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:SI        3 \"immediate_operand\" \"C\")]\n+\t\t\t  UNSPEC_VEC_VFAE))]\n+  \"TARGET_VX\"\n+{\n+  operands[3] = GEN_INT (INTVAL (operands[3]) | VSTRING_FLAG_ZS);\n+})\n+\n+(define_expand \"vfaes<mode>\"\n+  [(parallel\n+    [(set (match_operand:VI_HW_QHS 0 \"register_operand\" \"\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\" \"\")\n+\t\t\t   (match_operand:SI        3 \"immediate_operand\" \"C\")]\n+\t\t\t  UNSPEC_VEC_VFAE))\n+   (set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_dup 1)\n+\t\t       (match_dup 2)\n+\t\t       (match_dup 3)]\n+\t\t      UNSPEC_VEC_VFAECC))])\n+   (set (match_operand:SI 4 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCRAW CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\"\n+{\n+  operands[3] = GEN_INT (INTVAL (operands[3]) | VSTRING_FLAG_CS);\n+})\n+\n+(define_expand \"vfaezs<mode>\"\n+  [(parallel\n+    [(set (match_operand:VI_HW_QHS 0 \"register_operand\" \"\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\" \"\")\n+\t\t\t   (match_operand:SI        3 \"immediate_operand\" \"C\")]\n+\t\t\t  UNSPEC_VEC_VFAE))\n+   (set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_dup 1)\n+\t\t       (match_dup 2)\n+\t\t       (match_dup 3)]\n+\t\t      UNSPEC_VEC_VFAECC))])\n+   (set (match_operand:SI 4 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCRAW CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\"\n+{\n+  operands[3] = GEN_INT (INTVAL (operands[3]) | VSTRING_FLAG_CS | VSTRING_FLAG_ZS);\n+})\n+\n+\n+; Vector find element equal\n+\n+; vfeebs, vfeehs, vfeefs\n+; vfeezbs, vfeezhs, vfeezfs\n+(define_insn \"*vfees<mode>\"\n+  [(set (match_operand:VI_HW_QHS 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:QI 3 \"immediate_operand\" \"C\")]\n+\t\t\t  UNSPEC_VEC_VFEE))\n+   (set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_dup 1)\n+\t\t       (match_dup 2)\n+\t\t       (match_dup 3)]\n+\t\t      UNSPEC_VEC_VFEECC))]\n+  \"TARGET_VX\"\n+{\n+  unsigned HOST_WIDE_INT flags = INTVAL (operands[3]);\n+\n+  gcc_assert (!(flags & ~(VSTRING_FLAG_ZS | VSTRING_FLAG_CS)));\n+  flags &= ~VSTRING_FLAG_CS;\n+\n+  if (flags == VSTRING_FLAG_ZS)\n+    return \"vfeez<bhfgq>s\\t%v0,%v1,%v2\";\n+  return \"vfee<bhfgq>s\\t%v0,%v1,%v2,%b3\";\n+}\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; vfeeb, vfeeh, vfeef\n+(define_insn \"vfee<mode>\"\n+  [(set (match_operand:VI_HW_QHS                    0 \"register_operand\" \"\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\" \"\")\n+\t\t\t   (const_int 0)]\n+\t\t\t  UNSPEC_VEC_VFEE))]\n+  \"TARGET_VX\"\n+  \"vfee<bhfgq>\\t%v0,%v1,%v2,0\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; vfeezb, vfeezh, vfeezf\n+(define_insn \"vfeez<mode>\"\n+  [(set (match_operand:VI_HW_QHS                    0 \"register_operand\" \"\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\" \"\")\n+\t\t\t   (const_int VSTRING_FLAG_ZS)]\n+\t\t\t  UNSPEC_VEC_VFEE))]\n+  \"TARGET_VX\"\n+  \"vfeez<bhfgq>s\\t%v0,%v1,%v2,2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_expand \"vfees<mode>\"\n+  [(parallel\n+    [(set (match_operand:VI_HW_QHS                    0 \"register_operand\" \"\")\n+\t  (unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"\")\n+\t\t\t     (match_operand:VI_HW_QHS 2 \"register_operand\" \"\")\n+\t\t\t     (const_int VSTRING_FLAG_CS)]\n+\t\t\t    UNSPEC_VEC_VFEE))\n+   (set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_dup 1)\n+\t\t       (match_dup 2)\n+\t\t       (const_int VSTRING_FLAG_CS)]\n+\t\t      UNSPEC_VEC_VFEECC))])\n+   (set (match_operand:SI 3 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCRAW CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\")\n+\n+(define_expand \"vfeezs<mode>\"\n+  [(parallel\n+    [(set (match_operand:VI_HW_QHS                    0 \"register_operand\" \"\")\n+\t  (unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"\")\n+\t\t\t     (match_operand:VI_HW_QHS 2 \"register_operand\" \"\")\n+\t\t\t     (match_dup 4)]\n+\t\t\t    UNSPEC_VEC_VFEE))\n+   (set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_dup 1)\n+\t\t       (match_dup 2)\n+\t\t       (match_dup 4)]\n+\t\t      UNSPEC_VEC_VFEECC))])\n+   (set (match_operand:SI 3 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCRAW CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\"\n+{\n+  operands[4] = GEN_INT (VSTRING_FLAG_ZS | VSTRING_FLAG_CS);\n+})\n+\n+; Vector find element not equal\n+\n+; vfeneb, vfeneh, vfenef\n+(define_insn \"vfene<mode>\"\n+  [(set (match_operand:VI_HW_QHS                    0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\"  \"v\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\"  \"v\")\n+\t\t\t   (const_int 0)]\n+\t\t\t  UNSPEC_VEC_VFENE))]\n+  \"TARGET_VX\"\n+  \"vfene<bhfgq>\\t%v0,%v1,%v2,0\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; vec_vfenes can be found in vector.md since it is used for strlen\n+\n+; vfenezb, vfenezh, vfenezf\n+(define_insn \"vfenez<mode>\"\n+  [(set (match_operand:VI_HW_QHS                    0 \"register_operand\" \"\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\" \"\")\n+\t\t\t   (const_int VSTRING_FLAG_ZS)]\n+\t\t\t  UNSPEC_VEC_VFENE))]\n+  \"TARGET_VX\"\n+  \"vfenez<bhfgq>\\t%v0,%v1,%v2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_expand \"vfenes<mode>\"\n+  [(parallel\n+    [(set (match_operand:VI_HW_QHS                    0 \"register_operand\" \"\")\n+\t  (unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"\")\n+\t\t\t     (match_operand:VI_HW_QHS 2 \"register_operand\" \"\")\n+\t\t\t     (const_int VSTRING_FLAG_CS)]\n+\t\t\t    UNSPEC_VEC_VFENE))\n+   (set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_dup 1)\n+\t\t       (match_dup 2)\n+\t\t       (const_int VSTRING_FLAG_CS)]\n+\t\t      UNSPEC_VEC_VFENECC))])\n+   (set (match_operand:SI 3 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCRAW CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\")\n+\n+(define_expand \"vfenezs<mode>\"\n+  [(parallel\n+    [(set (match_operand:VI_HW_QHS                    0 \"register_operand\" \"\")\n+\t  (unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"\")\n+\t\t\t     (match_operand:VI_HW_QHS 2 \"register_operand\" \"\")\n+\t\t\t     (match_dup 4)]\n+\t\t\t    UNSPEC_VEC_VFENE))\n+     (set (reg:CCRAW CC_REGNUM)\n+\t  (unspec:CCRAW [(match_dup 1)\n+\t\t\t (match_dup 2)\n+\t\t\t (match_dup 4)]\n+\t\t\tUNSPEC_VEC_VFENECC))])\n+   (set (match_operand:SI 3 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCRAW CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\"\n+{\n+  operands[4] = GEN_INT (VSTRING_FLAG_ZS | VSTRING_FLAG_CS);\n+})\n+\n+; Vector isolate string\n+\n+; vistrb, vistrh, vistrf\n+(define_insn \"vistr<mode>\"\n+  [(set (match_operand:VI_HW_QHS 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"v\")]\n+\t\t\t  UNSPEC_VEC_VISTR))]\n+  \"TARGET_VX\"\n+  \"vistr<bhfgq>\\t%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; vistrbs, vistrhs, vistrfs\n+(define_insn \"*vistrs<mode>\"\n+  [(set (match_operand:VI_HW_QHS 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"v\")]\n+\t\t\t  UNSPEC_VEC_VISTR))\n+   (set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_dup 1)] UNSPEC_VEC_VISTRCC))]\n+  \"TARGET_VX\"\n+  \"vistr<bhfgq>s\\t%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_expand \"vistrs<mode>\"\n+  [(parallel\n+    [(set (match_operand:VI_HW_QHS                    0 \"register_operand\" \"\")\n+\t  (unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"\")]\n+\t\t\t    UNSPEC_VEC_VISTR))\n+     (set (reg:CCRAW CC_REGNUM)\n+\t  (unspec:CCRAW [(match_dup 1)]\n+\t\t\tUNSPEC_VEC_VISTRCC))])\n+   (set (match_operand:SI 2 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCRAW CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\")\n+\n+\n+; Vector compare range\n+\n+; vstrcb, vstrch, vstrcf\n+; vstrczb, vstrczh, vstrczf\n+(define_insn \"vstrc<mode>\"\n+  [(set (match_operand:VI_HW_QHS                    0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\"  \"v\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\"  \"v\")\n+\t\t\t   (match_operand:VI_HW_QHS 3 \"register_operand\"  \"v\")\n+\t\t\t   (match_operand:SI        4 \"immediate_operand\" \"C\")]\n+\t\t\t  UNSPEC_VEC_VSTRC))]\n+  \"TARGET_VX\"\n+{\n+  unsigned HOST_WIDE_INT flags = INTVAL (operands[4]);\n+\n+  if (flags & VSTRING_FLAG_ZS)\n+    {\n+      flags &= ~VSTRING_FLAG_ZS;\n+      operands[4] = GEN_INT (flags);\n+      return \"vstrcz<bhfgq>\\t%v0,%v1,%v2,%v3,%b4\";\n+    }\n+  return \"vstrc<bhfgq>\\t%v0,%v1,%v2,%v3,%b4\";\n+}\n+[(set_attr \"op_type\" \"VRR\")])\n+\n+; vstrcbs, vstrchs, vstrcfs\n+; vstrczbs, vstrczhs, vstrczfs\n+(define_insn \"*vstrcs<mode>\"\n+  [(set (match_operand:VI_HW_QHS                    0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\"  \"v\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\"  \"v\")\n+\t\t\t   (match_operand:VI_HW_QHS 3 \"register_operand\"  \"v\")\n+\t\t\t   (match_operand:SI        4 \"immediate_operand\" \"C\")]\n+\t\t\t  UNSPEC_VEC_VSTRC))\n+   (set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_dup 1)\n+\t\t       (match_dup 2)\n+\t\t       (match_dup 3)\n+\t\t       (match_dup 4)]\n+\t\t      UNSPEC_VEC_VSTRCCC))]\n+  \"TARGET_VX\"\n+{\n+  unsigned HOST_WIDE_INT flags = INTVAL (operands[4]);\n+\n+  if (flags & VSTRING_FLAG_ZS)\n+    {\n+      flags &= ~VSTRING_FLAG_ZS;\n+      operands[4] = GEN_INT (flags);\n+      return \"vstrcz<bhfgq>s\\t%v0,%v1,%v2,%v3,%b4\";\n+    }\n+  return \"vstrc<bhfgq>s\\t%v0,%v1,%v2,%v3,%b4\";\n+}\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_expand \"vstrcz<mode>\"\n+  [(set (match_operand:VI_HW_QHS 0 \"register_operand\" \"=v\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:VI_HW_QHS 3 \"register_operand\" \"v\")\n+\t\t\t   (match_operand:SI        4 \"immediate_operand\" \"C\")]\n+\t\t\t  UNSPEC_VEC_VSTRC))]\n+  \"TARGET_VX\"\n+{\n+  operands[4] = GEN_INT (INTVAL (operands[4]) | VSTRING_FLAG_ZS);\n+})\n+\n+(define_expand \"vstrcs<mode>\"\n+  [(parallel\n+    [(set (match_operand:VI_HW_QHS 0 \"register_operand\" \"\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\" \"\")\n+\t\t\t   (match_operand:VI_HW_QHS 3 \"register_operand\" \"\")\n+\t\t\t   (match_operand:SI        4 \"immediate_operand\" \"C\")]\n+\t\t\t  UNSPEC_VEC_VSTRC))\n+   (set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_dup 1)\n+\t\t       (match_dup 2)\n+\t\t       (match_dup 3)\n+\t\t       (match_dup 4)]\n+\t\t      UNSPEC_VEC_VSTRCCC))])\n+   (set (match_operand:SI 5 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCRAW CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\"\n+{\n+  operands[4] = GEN_INT (INTVAL (operands[4]) | VSTRING_FLAG_CS);\n+})\n+\n+(define_expand \"vstrczs<mode>\"\n+  [(parallel\n+    [(set (match_operand:VI_HW_QHS 0 \"register_operand\" \"\")\n+\t(unspec:VI_HW_QHS [(match_operand:VI_HW_QHS 1 \"register_operand\" \"\")\n+\t\t\t   (match_operand:VI_HW_QHS 2 \"register_operand\" \"\")\n+\t\t\t   (match_operand:VI_HW_QHS 3 \"register_operand\" \"\")\n+\t\t\t   (match_operand:SI        4 \"immediate_operand\" \"C\")]\n+\t\t\t  UNSPEC_VEC_VSTRC))\n+   (set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_dup 1)\n+\t\t       (match_dup 2)\n+\t\t       (match_dup 3)\n+\t\t       (match_dup 4)]\n+\t\t      UNSPEC_VEC_VSTRCCC))])\n+   (set (match_operand:SI 5 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCRAW CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\"\n+{\n+  operands[4] = GEN_INT (INTVAL (operands[4]) | VSTRING_FLAG_CS | VSTRING_FLAG_ZS);\n+})\n+\n+\n+; Signed V2DI -> V2DF conversion - inexact exception disabled\n+(define_insn \"vec_di_to_df_s64\"\n+  [(set (match_operand:V2DF 0 \"register_operand\"               \"=v\")\n+\t(unspec:V2DF [(match_operand:V2DI 1 \"register_operand\"  \"v\")\n+\t\t      (match_operand:QI   2 \"immediate_operand\" \"C\")]\n+\t\t     UNSPEC_VEC_VCDGB))]\n+  \"TARGET_VX\"\n+  \"vcdgb\\t%v0,%v1,4,%b2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; The result needs to be multiplied with 2**-op2\n+(define_expand \"vec_ctd_s64\"\n+  [(set (match_operand:V2DF               0 \"register_operand\" \"\")\n+\t(unspec:V2DF [(match_operand:V2DI 1 \"register_operand\" \"\")\n+\t\t      (const_int 0)] ; According to current BFP rounding mode\n+\t\t     UNSPEC_VEC_VCDGB))\n+   (use (match_operand:QI 2 \"immediate_operand\" \"\"))\n+   (set (match_dup 0) (mult:V2DF (match_dup 0) (match_dup 3)))]\n+  \"TARGET_VX\"\n+{\n+  REAL_VALUE_TYPE f;\n+  rtx c;\n+\n+  real_2expN (&f, -INTVAL (operands[2]), DFmode);\n+  c = CONST_DOUBLE_FROM_REAL_VALUE (f, DFmode);\n+\n+  operands[3] = gen_rtx_CONST_VECTOR (V2DFmode, gen_rtvec (2, c, c));\n+  operands[3] = force_reg (V2DFmode, operands[3]);\n+})\n+\n+; Unsigned V2DI -> V2DF conversion - inexact exception disabled\n+(define_insn \"vec_di_to_df_u64\"\n+  [(set (match_operand:V2DF 0 \"register_operand\"               \"=v\")\n+\t(unspec:V2DF [(match_operand:V2DI 1 \"register_operand\"  \"v\")\n+\t\t      (match_operand:QI   2 \"immediate_operand\" \"C\")]\n+\t\t     UNSPEC_VEC_VCDLGB))]\n+  \"TARGET_VX\"\n+  \"vcdlgb\\t%v0,%v1,4,%b2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; The result needs to be multiplied with 2**-op2\n+(define_expand \"vec_ctd_u64\"\n+  [(set (match_operand:V2DF               0 \"register_operand\" \"\")\n+\t(unspec:V2DF [(match_operand:V2DI 1 \"register_operand\" \"\")\n+\t\t      (const_int 0)] ; According to current BFP rounding mode\n+\t\t     UNSPEC_VEC_VCDLGB))\n+   (use (match_operand:QI 2 \"immediate_operand\" \"\"))\n+   (set (match_dup 0) (mult:V2DF (match_dup 0) (match_dup 3)))]\n+  \"TARGET_VX\"\n+{\n+  REAL_VALUE_TYPE f;\n+  rtx c;\n+\n+  real_2expN (&f, -INTVAL (operands[2]), DFmode);\n+  c = CONST_DOUBLE_FROM_REAL_VALUE (f, DFmode);\n+\n+  operands[3] = gen_rtx_CONST_VECTOR (V2DFmode, gen_rtvec (2, c, c));\n+  operands[3] = force_reg (V2DFmode, operands[3]);\n+})\n+\n+\n+; Signed V2DF -> V2DI conversion - inexact exception disabled\n+(define_insn \"vec_df_to_di_s64\"\n+  [(set (match_operand:V2DI 0 \"register_operand\"               \"=v\")\n+\t(unspec:V2DI [(match_operand:V2DF 1 \"register_operand\"  \"v\")\n+\t\t      (match_operand:QI   2 \"immediate_operand\" \"C\")]\n+\t\t     UNSPEC_VEC_VCGDB))]\n+  \"TARGET_VX\"\n+  \"vcgdb\\t%v0,%v1,4,%b2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; The input needs to be multiplied with 2**op2\n+(define_expand \"vec_ctsl\"\n+  [(use (match_operand:QI 2 \"immediate_operand\" \"\"))\n+   (set (match_dup 4) (mult:V2DF (match_operand:V2DF 1 \"register_operand\" \"\")\n+\t\t\t\t (match_dup 3)))\n+   (set (match_operand:V2DI 0 \"register_operand\" \"\")\n+\t(unspec:V2DI [(match_dup 4) (const_int 0)] ; According to current BFP rounding mode\n+\t\t     UNSPEC_VEC_VCGDB))]\n+  \"TARGET_VX\"\n+{\n+  REAL_VALUE_TYPE f;\n+  rtx c;\n+\n+  real_2expN (&f, INTVAL (operands[2]), DFmode);\n+  c = CONST_DOUBLE_FROM_REAL_VALUE (f, DFmode);\n+\n+  operands[3] = gen_rtx_CONST_VECTOR (V2DFmode, gen_rtvec (2, c, c));\n+  operands[3] = force_reg (V2DFmode, operands[3]);\n+  operands[4] = gen_reg_rtx (V2DFmode);\n+})\n+\n+; Unsigned V2DF -> V2DI conversion - inexact exception disabled\n+(define_insn \"vec_df_to_di_u64\"\n+  [(set (match_operand:V2DI 0 \"register_operand\"               \"=v\")\n+\t(unspec:V2DI [(match_operand:V2DF 1 \"register_operand\"  \"v\")\n+\t\t      (match_operand:QI   2 \"immediate_operand\" \"C\")]\n+\t\t     UNSPEC_VEC_VCLGDB))]\n+  \"TARGET_VX\"\n+  \"vclgdb\\t%v0,%v1,4,%b2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; The input needs to be multiplied with 2**op2\n+(define_expand \"vec_ctul\"\n+  [(use (match_operand:QI 2 \"immediate_operand\" \"\"))\n+   (set (match_dup 4) (mult:V2DF (match_operand:V2DF 1 \"register_operand\" \"\")\n+\t\t\t\t (match_dup 3)))\n+   (set (match_operand:V2DI 0 \"register_operand\" \"\")\n+\t(unspec:V2DI [(match_dup 4) (const_int 0)] ; According to current BFP rounding mode\n+\t\t     UNSPEC_VEC_VCLGDB))]\n+  \"TARGET_VX\"\n+{\n+  REAL_VALUE_TYPE f;\n+  rtx c;\n+\n+  real_2expN (&f, INTVAL (operands[2]), DFmode);\n+  c = CONST_DOUBLE_FROM_REAL_VALUE (f, DFmode);\n+\n+  operands[3] = gen_rtx_CONST_VECTOR (V2DFmode, gen_rtvec (2, c, c));\n+  operands[3] = force_reg (V2DFmode, operands[3]);\n+  operands[4] = gen_reg_rtx (V2DFmode);\n+})\n+\n+; Vector load fp integer - IEEE inexact exception is suppressed\n+(define_insn \"vfidb\"\n+  [(set (match_operand:V2DI               0 \"register_operand\" \"=v\")\n+\t(unspec:V2DI [(match_operand:V2DF 1 \"register_operand\"  \"v\")\n+\t\t      (match_operand:QI   2 \"immediate_operand\" \"C\")\n+\t\t      (match_operand:QI   3 \"immediate_operand\" \"C\")]\n+\t\t     UNSPEC_VEC_VFIDB))]\n+  \"TARGET_VX\"\n+  \"vfidb\\t%v0,%v1,%b2,%b3\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_expand \"vec_ceil\"\n+  [(set (match_operand:V2DI               0 \"register_operand\" \"\")\n+\t(unspec:V2DI [(match_operand:V2DF 1 \"register_operand\" \"\")\n+\t\t      (const_int VEC_RND_TO_INF)]\n+\t\t     UNSPEC_VEC_VFIDB))]\n+  \"TARGET_VX\")\n+\n+(define_expand \"vec_floor\"\n+  [(set (match_operand:V2DI               0 \"register_operand\" \"\")\n+\t(unspec:V2DI [(match_operand:V2DF 1 \"register_operand\" \"\")\n+\t\t      (const_int VEC_RND_TO_MINF)]\n+\t\t     UNSPEC_VEC_VFIDB))]\n+  \"TARGET_VX\")\n+\n+(define_expand \"vec_trunc\"\n+  [(set (match_operand:V2DI               0 \"register_operand\" \"\")\n+\t(unspec:V2DI [(match_operand:V2DF 1 \"register_operand\" \"\")\n+\t\t      (const_int VEC_RND_TO_ZERO)]\n+\t\t     UNSPEC_VEC_VFIDB))]\n+  \"TARGET_VX\")\n+\n+(define_expand \"vec_roundc\"\n+  [(set (match_operand:V2DI               0 \"register_operand\" \"\")\n+\t(unspec:V2DI [(match_operand:V2DF 1 \"register_operand\" \"\")\n+\t\t      (const_int VEC_RND_CURRENT)]\n+\t\t     UNSPEC_VEC_VFIDB))]\n+  \"TARGET_VX\")\n+\n+(define_expand \"vec_round\"\n+  [(set (match_operand:V2DI               0 \"register_operand\" \"\")\n+\t(unspec:V2DI [(match_operand:V2DF 1 \"register_operand\" \"\")\n+\t\t      (const_int VEC_RND_NEAREST_TO_EVEN)]\n+\t\t     UNSPEC_VEC_VFIDB))]\n+  \"TARGET_VX\")\n+\n+\n+; Vector load lengthened - V4SF -> V2DF\n+\n+(define_insn \"*vldeb\"\n+  [(set (match_operand:V2DF 0 \"register_operand\"               \"=v\")\n+\t(unspec:V2DF [(match_operand:V4SF 1 \"register_operand\"  \"v\")]\n+\t\t     UNSPEC_VEC_VLDEB))]\n+  \"TARGET_VX\"\n+  \"vldeb\\t%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_expand \"vec_ld2f\"\n+  [; Initialize a vector to all zeroes.  FIXME: This should not be\n+   ; necessary since all elements of the vector will be set anyway.\n+   ; This is just to make it explicit to the data flow framework.\n+   (set (match_dup 2) (match_dup 3))\n+   (set (match_dup 2) (unspec:V4SF [(match_operand:SF 1 \"memory_operand\" \"\")\n+\t\t\t\t    (const_int 0)\n+\t\t\t\t    (match_dup 2)]\n+\t\t\t\t    UNSPEC_VEC_SET))\n+   (set (match_dup 2) (unspec:V4SF [(match_dup 4)\n+\t\t\t\t    (const_int 2)\n+\t\t\t\t    (match_dup 2)]\n+\t\t\t\t    UNSPEC_VEC_SET))\n+   (set (match_operand:V2DF 0 \"register_operand\" \"\")\n+\t(unspec:V2DF [(match_dup 2)] UNSPEC_VEC_VLDEB))]\n+  \"TARGET_VX\"\n+{\n+  operands[2] = gen_reg_rtx (V4SFmode);\n+  operands[3] = CONST0_RTX (V4SFmode);\n+  operands[4] = adjust_address (operands[1], SFmode, 4);\n+})\n+\n+\n+; Vector load rounded - V2DF -> V4SF\n+\n+(define_insn \"*vledb\"\n+  [(set (match_operand:V4SF 0 \"register_operand\"               \"=v\")\n+\t(unspec:V4SF [(match_operand:V2DF 1 \"register_operand\"  \"v\")]\n+\t\t     UNSPEC_VEC_VLEDB))]\n+  \"TARGET_VX\"\n+  \"vledb\\t%v0,%v1,0,0\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_expand \"vec_st2f\"\n+  [(set (match_dup 2)\n+\t(unspec:V4SF [(match_operand:V2DF 0 \"register_operand\" \"\")]\n+\t\t     UNSPEC_VEC_VLEDB))\n+   (set (match_operand:SF 1 \"memory_operand\" \"\")\n+\t(unspec:SF [(match_dup 2) (const_int 0)] UNSPEC_VEC_EXTRACT))\n+   (set (match_dup 3)\n+\t(unspec:SF [(match_dup 2) (const_int 2)] UNSPEC_VEC_EXTRACT))]\n+  \"TARGET_VX\"\n+{\n+  operands[2] = gen_reg_rtx (V4SFmode);\n+  operands[3] = adjust_address (operands[1], SFmode, 4);\n+})\n+\n+\n+; Vector load negated fp\n+\n+(define_expand \"vec_nabs\"\n+  [(set (match_operand:V2DF 0 \"register_operand\" \"\")\n+\t(neg:V2DF (abs:V2DF (match_operand:V2DF 1 \"register_operand\" \"\"))))]\n+  \"TARGET_VX\")\n+\n+; Vector square root fp vec_sqrt -> sqrt rtx standard name\n+\n+; Vector FP test data class immediate\n+\n+(define_insn \"*vftcidb\"\n+  [(set (match_operand:V2DF 0 \"register_operand\"  \"=v\")\n+\t(unspec:V2DF [(match_operand:V2DF 1 \"register_operand\"  \"v\")\n+\t\t      (match_operand:SI   2 \"immediate_operand\" \"J\")]\n+\t\t     UNSPEC_VEC_VFTCIDB))\n+   (set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_dup 1) (match_dup 2)] UNSPEC_VEC_VFTCIDBCC))]\n+  \"TARGET_VX\"\n+  \"vftcidb\\t%v0,%v1,%x2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"*vftcidb_cconly\"\n+  [(set (reg:CCRAW CC_REGNUM)\n+\t(unspec:CCRAW [(match_operand:V2DF 1 \"register_operand\"  \"v\")\n+\t\t       (match_operand:SI   2 \"immediate_operand\" \"J\")]\n+\t\t      UNSPEC_VEC_VFTCIDBCC))\n+   (clobber (match_scratch:V2DI 0 \"=v\"))]\n+  \"TARGET_VX\"\n+  \"vftcidb\\t%v0,%v1,%x2\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_expand \"vftcidb\"\n+  [(parallel\n+    [(set (match_operand:V2DF               0 \"register_operand\"  \"\")\n+\t  (unspec:V2DF [(match_operand:V2DF 1 \"register_operand\"  \"\")\n+\t\t\t(match_operand:SI   2 \"immediate_operand\" \"\")]\n+\t\t       UNSPEC_VEC_VFTCIDB))\n+     (set (reg:CCRAW CC_REGNUM)\n+\t  (unspec:CCRAW [(match_dup 1) (match_dup 2)] UNSPEC_VEC_VFTCIDBCC))])\n+   (set (match_operand:SI 3 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCRAW CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\")\n+\n+;;\n+;; Integer compares\n+;;\n+\n+; All comparisons which produce a CC need fully populated (VI_HW)\n+; vector arguments.  Otherwise the any/all CCs would be just bogus.\n+\n+(define_insn \"*vec_cmp<VICMP:insn_cmp><VI_HW:mode>_cconly\"\n+  [(set (reg:VICMP CC_REGNUM)\n+\t(compare:VICMP (match_operand:VI_HW 0 \"register_operand\" \"v\")\n+\t\t       (match_operand:VI_HW 1 \"register_operand\" \"v\")))\n+   (clobber (match_scratch:VI_HW 2 \"=v\"))]\n+  \"TARGET_VX\"\n+  \"vc<VICMP:insn_cmp><VI_HW:bhfgq>s\\t%v2,%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; FIXME: The following 2x3 definitions should be merged into 2 with\n+; VICMP like above but I could not find a way to set the comparison\n+; operator (eq) depending on the mode CCVEQ (mode_iterator). Or the\n+; other way around - setting the mode depending on the code\n+; (code_iterator).\n+(define_expand \"vec_cmpeq<VI_HW:mode>_cc\"\n+  [(parallel\n+    [(set (reg:CCVEQ CC_REGNUM)\n+\t(compare:CCVEQ (match_operand:VI_HW 1 \"register_operand\" \"v\")\n+\t\t       (match_operand:VI_HW 2 \"register_operand\" \"v\")))\n+     (set (match_operand:VI_HW 0 \"register_operand\" \"=v\")\n+\t  (eq:VI_HW (match_dup 1) (match_dup 2)))])\n+   (set (match_operand:SI 3 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCVEQ CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\")\n+\n+(define_expand \"vec_cmph<VI_HW:mode>_cc\"\n+  [(parallel\n+    [(set (reg:CCVH CC_REGNUM)\n+\t  (compare:CCVH (match_operand:VI_HW 1 \"register_operand\" \"v\")\n+\t\t\t(match_operand:VI_HW 2 \"register_operand\" \"v\")))\n+     (set (match_operand:VI_HW 0 \"register_operand\" \"=v\")\n+\t  (gt:VI_HW (match_dup 1) (match_dup 2)))])\n+   (set (match_operand:SI 3 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCVH CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\")\n+\n+(define_expand \"vec_cmphl<VI_HW:mode>_cc\"\n+  [(parallel\n+    [(set (reg:CCVHU CC_REGNUM)\n+\t  (compare:CCVHU (match_operand:VI_HW 1 \"register_operand\" \"v\")\n+\t\t\t (match_operand:VI_HW 2 \"register_operand\" \"v\")))\n+     (set (match_operand:VI_HW 0 \"register_operand\" \"=v\")\n+\t  (gtu:VI_HW (match_dup 1) (match_dup 2)))])\n+   (set (match_operand:SI 3 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCVHU CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\")\n+\n+\n+(define_insn \"*vec_cmpeq<VI_HW:mode>_cc\"\n+  [(set (reg:CCVEQ CC_REGNUM)\n+\t(compare:CCVEQ (match_operand:VI_HW 0 \"register_operand\"  \"v\")\n+\t\t       (match_operand:VI_HW 1 \"register_operand\"  \"v\")))\n+   (set (match_operand:VI_HW                2 \"register_operand\" \"=v\")\n+\t(eq:VI_HW (match_dup 0) (match_dup 1)))]\n+  \"TARGET_VX\"\n+  \"vceq<VI_HW:bhfgq>s\\t%v2,%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"*vec_cmph<VI_HW:mode>_cc\"\n+  [(set (reg:CCVH CC_REGNUM)\n+\t(compare:CCVH (match_operand:VI_HW 0 \"register_operand\"  \"v\")\n+\t\t      (match_operand:VI_HW 1 \"register_operand\"  \"v\")))\n+   (set (match_operand:VI_HW               2 \"register_operand\" \"=v\")\n+\t(gt:VI_HW (match_dup 0) (match_dup 1)))]\n+  \"TARGET_VX\"\n+  \"vch<VI_HW:bhfgq>s\\t%v2,%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"*vec_cmphl<VI_HW:mode>_cc\"\n+  [(set (reg:CCVHU CC_REGNUM)\n+\t(compare:CCVHU (match_operand:VI_HW 0 \"register_operand\"  \"v\")\n+\t\t       (match_operand:VI_HW 1 \"register_operand\"  \"v\")))\n+   (set (match_operand:VI_HW                2 \"register_operand\" \"=v\")\n+\t(gtu:VI_HW (match_dup 0) (match_dup 1)))]\n+  \"TARGET_VX\"\n+  \"vchl<VI_HW:bhfgq>s\\t%v2,%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+;;\n+;; Floating point comparesg\n+;;\n+\n+(define_insn \"*vec_cmp<insn_cmp>v2df_cconly\"\n+  [(set (reg:VFCMP CC_REGNUM)\n+\t(compare:VFCMP (match_operand:V2DF 0 \"register_operand\" \"v\")\n+\t\t       (match_operand:V2DF 1 \"register_operand\" \"v\")))\n+   (clobber (match_scratch:V2DI 2 \"=v\"))]\n+  \"TARGET_VX\"\n+  \"vfc<asm_fcmp>dbs\\t%v2,%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+; FIXME: Merge the following 2x3 patterns with VFCMP\n+(define_expand \"vec_cmpeqv2df_cc\"\n+  [(parallel\n+    [(set (reg:CCVEQ CC_REGNUM)\n+\t  (compare:CCVEQ (match_operand:V2DF 1 \"register_operand\"  \"v\")\n+\t\t\t (match_operand:V2DF 2 \"register_operand\"  \"v\")))\n+     (set (match_operand:V2DI 0 \"register_operand\" \"=v\")\n+\t  (eq:V2DI (match_dup 1) (match_dup 2)))])\n+   (set (match_operand:SI 3 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCVEQ CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\")\n+\n+(define_expand \"vec_cmphv2df_cc\"\n+  [(parallel\n+    [(set (reg:CCVH CC_REGNUM)\n+\t  (compare:CCVH (match_operand:V2DF 1 \"register_operand\"  \"v\")\n+\t\t\t(match_operand:V2DF 2 \"register_operand\"  \"v\")))\n+     (set (match_operand:V2DI 0 \"register_operand\" \"=v\")\n+\t  (gt:V2DI (match_dup 1) (match_dup 2)))])\n+   (set (match_operand:SI 3 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCVH CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\")\n+\n+(define_expand \"vec_cmphev2df_cc\"\n+  [(parallel\n+    [(set (reg:CCVFHE CC_REGNUM)\n+\t  (compare:CCVFHE (match_operand:V2DF 1 \"register_operand\"  \"v\")\n+\t\t\t  (match_operand:V2DF 2 \"register_operand\"  \"v\")))\n+     (set (match_operand:V2DI 0 \"register_operand\" \"=v\")\n+\t  (ge:V2DI (match_dup 1) (match_dup 2)))])\n+   (set (match_operand:SI 3 \"memory_operand\" \"\")\n+\t(unspec:SI [(reg:CCVFHE CC_REGNUM)] UNSPEC_CC_TO_INT))]\n+  \"TARGET_VX\")\n+\n+\n+(define_insn \"*vec_cmpeqv2df_cc\"\n+  [(set (reg:CCVEQ CC_REGNUM)\n+\t(compare:CCVEQ (match_operand:V2DF 0 \"register_operand\"  \"v\")\n+\t\t       (match_operand:V2DF 1 \"register_operand\"  \"v\")))\n+   (set (match_operand:V2DI                2 \"register_operand\" \"=v\")\n+\t(eq:V2DI (match_dup 0) (match_dup 1)))]\n+  \"TARGET_VX\"\n+  \"vfcedbs\\t%v2,%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"*vec_cmphv2df_cc\"\n+  [(set (reg:CCVH CC_REGNUM)\n+\t(compare:CCVH (match_operand:V2DF 0 \"register_operand\"  \"v\")\n+\t\t      (match_operand:V2DF 1 \"register_operand\"  \"v\")))\n+   (set (match_operand:V2DI               2 \"register_operand\" \"=v\")\n+\t(gt:V2DI (match_dup 0) (match_dup 1)))]\n+  \"TARGET_VX\"\n+  \"vfchdbs\\t%v2,%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])\n+\n+(define_insn \"*vec_cmphev2df_cc\"\n+  [(set (reg:CCVFHE CC_REGNUM)\n+\t(compare:CCVFHE (match_operand:V2DF 0 \"register_operand\"  \"v\")\n+\t\t\t(match_operand:V2DF 1 \"register_operand\"  \"v\")))\n+   (set (match_operand:V2DI                 2 \"register_operand\" \"=v\")\n+\t(ge:V2DI (match_dup 0) (match_dup 1)))]\n+  \"TARGET_VX\"\n+  \"vfchedbs\\t%v2,%v0,%v1\"\n+  [(set_attr \"op_type\" \"VRR\")])"}]}