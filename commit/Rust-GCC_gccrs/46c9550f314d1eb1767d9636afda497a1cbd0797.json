{"sha": "46c9550f314d1eb1767d9636afda497a1cbd0797", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NDZjOTU1MGYzMTRkMWViMTc2N2Q5NjM2YWZkYTQ5N2ExY2JkMDc5Nw==", "commit": {"author": {"name": "Bernd Schmidt", "email": "bernds@codesourcery.com", "date": "2011-07-06T23:12:45Z"}, "committer": {"name": "Bernd Schmidt", "email": "bernds@gcc.gnu.org", "date": "2011-07-06T23:12:45Z"}, "message": "machmode.h (HWI_COMPUTABLE_MODE_P): New macro.\n\n\t* machmode.h (HWI_COMPUTABLE_MODE_P): New macro.\n\t* combine.c (set_nonzero_bits_and_sign_copies): Use it.\n\t(find_split-point, combine_simplify_rtx, simplify_if_then_else,\n\tsimplify_set, simplify_logical, expand_compound_operation,\n\tmake_extraction, force_to_mode, if_then_else_cond, extended_count,\n\ttry_widen_shift_mode, simplify_shift_const_1, simplify_comparison,\n\trecord_value_for_reg): Likewise.\n\t* expmed.c (expand_widening_mult, expand_mult_highpart): Likewise.\n\t* simplify-rtx. c (simplify_unary_operation_1,\n\tsimplify_binary_operation_1, simplify_const_relational_operation):\n\tLikewise.\n\nFrom-SVN: r175945", "tree": {"sha": "404fbb53e667f21f4be95e942ca6c31b0c8268e5", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/404fbb53e667f21f4be95e942ca6c31b0c8268e5"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/46c9550f314d1eb1767d9636afda497a1cbd0797", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/46c9550f314d1eb1767d9636afda497a1cbd0797", "html_url": "https://github.com/Rust-GCC/gccrs/commit/46c9550f314d1eb1767d9636afda497a1cbd0797", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/46c9550f314d1eb1767d9636afda497a1cbd0797/comments", "author": null, "committer": null, "parents": [{"sha": "6a4bdc797621dbf63470b88dcd50095571b0fe1d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6a4bdc797621dbf63470b88dcd50095571b0fe1d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6a4bdc797621dbf63470b88dcd50095571b0fe1d"}], "stats": {"total": 120, "additions": 64, "deletions": 56}, "files": [{"sha": "97ee184e414cd190a677e7f6c039181a0c6fe05b", "filename": "gcc/ChangeLog", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46c9550f314d1eb1767d9636afda497a1cbd0797/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46c9550f314d1eb1767d9636afda497a1cbd0797/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=46c9550f314d1eb1767d9636afda497a1cbd0797", "patch": "@@ -12,6 +12,18 @@\n \t(push_reload): Use precision to check for paradoxical subregs.\n \t* expmed.c (extract_bit_field_1): Likewise.\n \n+\t* machmode.h (HWI_COMPUTABLE_MODE_P): New macro.\n+\t* combine.c (set_nonzero_bits_and_sign_copies): Use it.\n+\t(find_split-point, combine_simplify_rtx, simplify_if_then_else,\n+\tsimplify_set, simplify_logical, expand_compound_operation,\n+\tmake_extraction, force_to_mode, if_then_else_cond, extended_count,\n+\ttry_widen_shift_mode, simplify_shift_const_1, simplify_comparison,\n+\trecord_value_for_reg): Likewise.\n+\t* expmed.c (expand_widening_mult, expand_mult_highpart): Likewise.\n+\t* simplify-rtx. c (simplify_unary_operation_1,\n+\tsimplify_binary_operation_1, simplify_const_relational_operation):\n+\tLikewise.\n+\n 2011-07-06  Michael Meissner  <meissner@linux.vnet.ibm.com>\n \n \t* config/rs6000/rs6000-protos.h (rs6000_call_indirect_aix): New"}, {"sha": "9ae5e9939ce3ee138ef7ae0abeea4519ab62eac7", "filename": "gcc/combine.c", "status": "modified", "additions": 38, "deletions": 45, "changes": 83, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46c9550f314d1eb1767d9636afda497a1cbd0797/gcc%2Fcombine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46c9550f314d1eb1767d9636afda497a1cbd0797/gcc%2Fcombine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcombine.c?ref=46c9550f314d1eb1767d9636afda497a1cbd0797", "patch": "@@ -1560,7 +1560,7 @@ set_nonzero_bits_and_sign_copies (rtx x, const_rtx set, void *data)\n \t say what its contents were.  */\n       && ! REGNO_REG_SET_P\n            (DF_LR_IN (ENTRY_BLOCK_PTR->next_bb), REGNO (x))\n-      && GET_MODE_BITSIZE (GET_MODE (x)) <= HOST_BITS_PER_WIDE_INT)\n+      && HWI_COMPUTABLE_MODE_P (GET_MODE (x)))\n     {\n       reg_stat_type *rsp = VEC_index (reg_stat_type, reg_stat, REGNO (x));\n \n@@ -4679,8 +4679,7 @@ find_split_point (rtx *loc, rtx insn, bool set_src)\n       /* See if this is a bitfield assignment with everything constant.  If\n \t so, this is an IOR of an AND, so split it into that.  */\n       if (GET_CODE (SET_DEST (x)) == ZERO_EXTRACT\n-\t  && (GET_MODE_BITSIZE (GET_MODE (XEXP (SET_DEST (x), 0)))\n-\t      <= HOST_BITS_PER_WIDE_INT)\n+\t  && HWI_COMPUTABLE_MODE_P (GET_MODE (XEXP (SET_DEST (x), 0)))\n \t  && CONST_INT_P (XEXP (SET_DEST (x), 1))\n \t  && CONST_INT_P (XEXP (SET_DEST (x), 2))\n \t  && CONST_INT_P (SET_SRC (x))\n@@ -5584,7 +5583,7 @@ combine_simplify_rtx (rtx x, enum machine_mode op0_mode, int in_dest,\n       if (GET_MODE_CLASS (mode) == MODE_PARTIAL_INT)\n \tbreak;\n \n-      if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT)\n+      if (HWI_COMPUTABLE_MODE_P (mode))\n \tSUBST (XEXP (x, 0),\n \t       force_to_mode (XEXP (x, 0), GET_MODE (XEXP (x, 0)),\n \t\t\t      GET_MODE_MASK (mode), 0));\n@@ -5596,7 +5595,7 @@ combine_simplify_rtx (rtx x, enum machine_mode op0_mode, int in_dest,\n       /* Similarly to what we do in simplify-rtx.c, a truncate of a register\n \t whose value is a comparison can be replaced with a subreg if\n \t STORE_FLAG_VALUE permits.  */\n-      if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+      if (HWI_COMPUTABLE_MODE_P (mode)\n \t  && (STORE_FLAG_VALUE & ~GET_MODE_MASK (mode)) == 0\n \t  && (temp = get_last_value (XEXP (x, 0)))\n \t  && COMPARISON_P (temp))\n@@ -5634,7 +5633,7 @@ combine_simplify_rtx (rtx x, enum machine_mode op0_mode, int in_dest,\n \t  && INTVAL (XEXP (x, 1)) == -INTVAL (XEXP (XEXP (x, 0), 1))\n \t  && ((i = exact_log2 (UINTVAL (XEXP (XEXP (x, 0), 1)))) >= 0\n \t      || (i = exact_log2 (UINTVAL (XEXP (x, 1)))) >= 0)\n-\t  && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t  && HWI_COMPUTABLE_MODE_P (mode)\n \t  && ((GET_CODE (XEXP (XEXP (x, 0), 0)) == AND\n \t       && CONST_INT_P (XEXP (XEXP (XEXP (x, 0), 0), 1))\n \t       && (UINTVAL (XEXP (XEXP (XEXP (x, 0), 0), 1))\n@@ -5669,7 +5668,7 @@ combine_simplify_rtx (rtx x, enum machine_mode op0_mode, int in_dest,\n \t for example in cases like ((a & 1) + (a & 2)), which can\n \t become a & 3.  */\n \n-      if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+      if (HWI_COMPUTABLE_MODE_P (mode)\n \t  && (nonzero_bits (XEXP (x, 0), mode)\n \t      & nonzero_bits (XEXP (x, 1), mode)) == 0)\n \t{\n@@ -5880,7 +5879,7 @@ combine_simplify_rtx (rtx x, enum machine_mode op0_mode, int in_dest,\n \t     AND with STORE_FLAG_VALUE when we are done, since we are only\n \t     going to test the sign bit.  */\n \t  if (new_code == NE && GET_MODE_CLASS (mode) == MODE_INT\n-\t      && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t      && HWI_COMPUTABLE_MODE_P (mode)\n \t      && val_signbit_p (mode, STORE_FLAG_VALUE)\n \t      && op1 == const0_rtx\n \t      && mode == GET_MODE (op0)\n@@ -6214,7 +6213,7 @@ simplify_if_then_else (rtx x)\n \t\t   || GET_CODE (XEXP (t, 0)) == LSHIFTRT\n \t\t   || GET_CODE (XEXP (t, 0)) == ASHIFTRT)\n \t       && GET_CODE (XEXP (XEXP (t, 0), 0)) == SUBREG\n-\t       && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t       && HWI_COMPUTABLE_MODE_P (mode)\n \t       && subreg_lowpart_p (XEXP (XEXP (t, 0), 0))\n \t       && rtx_equal_p (SUBREG_REG (XEXP (XEXP (t, 0), 0)), f)\n \t       && ((nonzero_bits (f, GET_MODE (f))\n@@ -6230,7 +6229,7 @@ simplify_if_then_else (rtx x)\n \t\t   || GET_CODE (XEXP (t, 0)) == IOR\n \t\t   || GET_CODE (XEXP (t, 0)) == XOR)\n \t       && GET_CODE (XEXP (XEXP (t, 0), 1)) == SUBREG\n-\t       && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t       && HWI_COMPUTABLE_MODE_P (mode)\n \t       && subreg_lowpart_p (XEXP (XEXP (t, 0), 1))\n \t       && rtx_equal_p (SUBREG_REG (XEXP (XEXP (t, 0), 1)), f)\n \t       && ((nonzero_bits (f, GET_MODE (f))\n@@ -6308,8 +6307,7 @@ simplify_set (rtx x)\n      simplify the expression for the object knowing that we only need the\n      low-order bits.  */\n \n-  if (GET_MODE_CLASS (mode) == MODE_INT\n-      && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT)\n+  if (GET_MODE_CLASS (mode) == MODE_INT && HWI_COMPUTABLE_MODE_P (mode))\n     {\n       src = force_to_mode (src, mode, ~(unsigned HOST_WIDE_INT) 0, 0);\n       SUBST (SET_SRC (x), src);\n@@ -6444,7 +6442,7 @@ simplify_set (rtx x)\n \t  if (((old_code == NE && new_code == EQ)\n \t       || (old_code == EQ && new_code == NE))\n \t      && ! other_changed_previously && op1 == const0_rtx\n-\t      && GET_MODE_BITSIZE (GET_MODE (op0)) <= HOST_BITS_PER_WIDE_INT\n+\t      && HWI_COMPUTABLE_MODE_P (GET_MODE (op0))\n \t      && exact_log2 (mask = nonzero_bits (op0, GET_MODE (op0))) >= 0)\n \t    {\n \t      rtx pat = PATTERN (other_insn), note = 0;\n@@ -6657,7 +6655,7 @@ simplify_logical (rtx x)\n \t any (sign) bits when converting INTVAL (op1) to\n \t \"unsigned HOST_WIDE_INT\".  */\n       if (CONST_INT_P (op1)\n-\t  && (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t  && (HWI_COMPUTABLE_MODE_P (mode)\n \t      || INTVAL (op1) > 0))\n \t{\n \t  x = simplify_and_const_int (x, mode, op0, INTVAL (op1));\n@@ -6815,7 +6813,7 @@ expand_compound_operation (rtx x)\n      bit is not set, as this is easier to optimize.  It will be converted\n      back to cheaper alternative in make_extraction.  */\n   if (GET_CODE (x) == SIGN_EXTEND\n-      && (GET_MODE_BITSIZE (GET_MODE (x)) <= HOST_BITS_PER_WIDE_INT\n+      && (HWI_COMPUTABLE_MODE_P (GET_MODE (x))\n \t  && ((nonzero_bits (XEXP (x, 0), GET_MODE (XEXP (x, 0)))\n \t\t& ~(((unsigned HOST_WIDE_INT)\n \t\t      GET_MODE_MASK (GET_MODE (XEXP (x, 0))))\n@@ -6844,7 +6842,7 @@ expand_compound_operation (rtx x)\n \t set.  */\n       if (GET_CODE (XEXP (x, 0)) == TRUNCATE\n \t  && GET_MODE (XEXP (XEXP (x, 0), 0)) == GET_MODE (x)\n-\t  && GET_MODE_BITSIZE (GET_MODE (x)) <= HOST_BITS_PER_WIDE_INT\n+\t  && HWI_COMPUTABLE_MODE_P (GET_MODE (x))\n \t  && (nonzero_bits (XEXP (XEXP (x, 0), 0), GET_MODE (x))\n \t      & ~GET_MODE_MASK (GET_MODE (XEXP (x, 0)))) == 0)\n \treturn XEXP (XEXP (x, 0), 0);\n@@ -6853,7 +6851,7 @@ expand_compound_operation (rtx x)\n       if (GET_CODE (XEXP (x, 0)) == SUBREG\n \t  && GET_MODE (SUBREG_REG (XEXP (x, 0))) == GET_MODE (x)\n \t  && subreg_lowpart_p (XEXP (x, 0))\n-\t  && GET_MODE_BITSIZE (GET_MODE (x)) <= HOST_BITS_PER_WIDE_INT\n+\t  && HWI_COMPUTABLE_MODE_P (GET_MODE (x))\n \t  && (nonzero_bits (SUBREG_REG (XEXP (x, 0)), GET_MODE (x))\n \t      & ~GET_MODE_MASK (GET_MODE (XEXP (x, 0)))) == 0)\n \treturn SUBREG_REG (XEXP (x, 0));\n@@ -7242,11 +7240,9 @@ make_extraction (enum machine_mode mode, rtx inner, HOST_WIDE_INT pos,\n \t bit is not set, convert the extraction to the cheaper of\n \t sign and zero extension, that are equivalent in these cases.  */\n       if (flag_expensive_optimizations\n-\t  && (GET_MODE_BITSIZE (tmode) <= HOST_BITS_PER_WIDE_INT\n+\t  && (HWI_COMPUTABLE_MODE_P (tmode)\n \t      && ((nonzero_bits (new_rtx, tmode)\n-\t\t   & ~(((unsigned HOST_WIDE_INT)\n-\t\t\tGET_MODE_MASK (tmode))\n-\t\t       >> 1))\n+\t\t   & ~(((unsigned HOST_WIDE_INT)GET_MODE_MASK (tmode)) >> 1))\n \t\t  == 0)))\n \t{\n \t  rtx temp = gen_rtx_ZERO_EXTEND (mode, new_rtx);\n@@ -7445,7 +7441,7 @@ make_extraction (enum machine_mode mode, rtx inner, HOST_WIDE_INT pos,\n \t SIGN_EXTENSION or ZERO_EXTENSION, that are equivalent in these\n \t cases.  */\n       if (flag_expensive_optimizations\n-\t  && (GET_MODE_BITSIZE (GET_MODE (pos_rtx)) <= HOST_BITS_PER_WIDE_INT\n+\t  && (HWI_COMPUTABLE_MODE_P (GET_MODE (pos_rtx))\n \t      && ((nonzero_bits (pos_rtx, GET_MODE (pos_rtx))\n \t\t   & ~(((unsigned HOST_WIDE_INT)\n \t\t\tGET_MODE_MASK (GET_MODE (pos_rtx)))\n@@ -8207,7 +8203,7 @@ force_to_mode (rtx x, enum machine_mode mode, unsigned HOST_WIDE_INT mask,\n \n \t  if (GET_CODE (x) == AND && CONST_INT_P (XEXP (x, 1))\n \t      && GET_MODE_MASK (GET_MODE (x)) != mask\n-\t      && GET_MODE_BITSIZE (GET_MODE (x)) <= HOST_BITS_PER_WIDE_INT)\n+\t      && HWI_COMPUTABLE_MODE_P (GET_MODE (x)))\n \t    {\n \t      unsigned HOST_WIDE_INT cval\n \t\t= UINTVAL (XEXP (x, 1))\n@@ -8365,7 +8361,7 @@ force_to_mode (rtx x, enum machine_mode mode, unsigned HOST_WIDE_INT mask,\n       if (CONST_INT_P (XEXP (x, 1))\n \t  && INTVAL (XEXP (x, 1)) >= 0\n \t  && INTVAL (XEXP (x, 1)) < GET_MODE_BITSIZE (op_mode)\n-\t  && GET_MODE_BITSIZE (op_mode) <= HOST_BITS_PER_WIDE_INT)\n+\t  && HWI_COMPUTABLE_MODE_P (op_mode))\n \tmask >>= INTVAL (XEXP (x, 1));\n       else\n \tmask = fuller_mask;\n@@ -8385,7 +8381,7 @@ force_to_mode (rtx x, enum machine_mode mode, unsigned HOST_WIDE_INT mask,\n \n       if (CONST_INT_P (XEXP (x, 1))\n \t  && INTVAL (XEXP (x, 1)) < HOST_BITS_PER_WIDE_INT\n-\t  && GET_MODE_BITSIZE (op_mode) <= HOST_BITS_PER_WIDE_INT)\n+\t  && HWI_COMPUTABLE_MODE_P (op_mode))\n \t{\n \t  rtx inner = XEXP (x, 0);\n \t  unsigned HOST_WIDE_INT inner_mask;\n@@ -8815,8 +8811,7 @@ if_then_else_cond (rtx x, rtx *ptrue, rtx *pfalse)\n     }\n \n   /* Likewise for 0 or a single bit.  */\n-  else if (SCALAR_INT_MODE_P (mode)\n-\t   && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+  else if (HWI_COMPUTABLE_MODE_P (mode)\n \t   && exact_log2 (nz = nonzero_bits (x, mode)) >= 0)\n     {\n       *ptrue = gen_int_mode (nz, mode), *pfalse = const0_rtx;\n@@ -9655,7 +9650,7 @@ extended_count (const_rtx x, enum machine_mode mode, int unsignedp)\n     return 0;\n \n   return (unsignedp\n-\t  ? (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t  ? (HWI_COMPUTABLE_MODE_P (mode)\n \t     ? (unsigned int) (GET_MODE_BITSIZE (mode) - 1\n \t\t\t       - floor_log2 (nonzero_bits (x, mode)))\n \t     : 0)\n@@ -9823,7 +9818,7 @@ try_widen_shift_mode (enum rtx_code code, rtx op, int count,\n \n     case LSHIFTRT:\n       /* Similarly here but with zero bits.  */\n-      if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+      if (HWI_COMPUTABLE_MODE_P (mode)\n \t  && (nonzero_bits (op, mode) & ~GET_MODE_MASK (orig_mode)) == 0)\n \treturn mode;\n \n@@ -9973,10 +9968,10 @@ simplify_shift_const_1 (enum rtx_code code, enum machine_mode result_mode,\n \tcode = LSHIFTRT;\n \n       if (((code == LSHIFTRT\n-\t    && GET_MODE_BITSIZE (shift_mode) <= HOST_BITS_PER_WIDE_INT\n+\t    && HWI_COMPUTABLE_MODE_P (shift_mode)\n \t    && !(nonzero_bits (varop, shift_mode) >> count))\n \t   || (code == ASHIFT\n-\t       && GET_MODE_BITSIZE (shift_mode) <= HOST_BITS_PER_WIDE_INT\n+\t       && HWI_COMPUTABLE_MODE_P (shift_mode)\n \t       && !((nonzero_bits (varop, shift_mode) << count)\n \t\t    & GET_MODE_MASK (shift_mode))))\n \t  && !side_effects_p (varop))\n@@ -10092,8 +10087,8 @@ simplify_shift_const_1 (enum rtx_code code, enum machine_mode result_mode,\n \t  if (CONST_INT_P (XEXP (varop, 1))\n \t      && INTVAL (XEXP (varop, 1)) >= 0\n \t      && INTVAL (XEXP (varop, 1)) < GET_MODE_BITSIZE (GET_MODE (varop))\n-\t      && GET_MODE_BITSIZE (result_mode) <= HOST_BITS_PER_WIDE_INT\n-\t      && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t      && HWI_COMPUTABLE_MODE_P (result_mode)\n+\t      && HWI_COMPUTABLE_MODE_P (mode)\n \t      && !VECTOR_MODE_P (result_mode))\n \t    {\n \t      enum rtx_code first_code = GET_CODE (varop);\n@@ -10334,7 +10329,7 @@ simplify_shift_const_1 (enum rtx_code code, enum machine_mode result_mode,\n \t      && XEXP (varop, 1) == const0_rtx\n \t      && GET_MODE (XEXP (varop, 0)) == result_mode\n \t      && count == (GET_MODE_BITSIZE (result_mode) - 1)\n-\t      && GET_MODE_BITSIZE (result_mode) <= HOST_BITS_PER_WIDE_INT\n+\t      && HWI_COMPUTABLE_MODE_P (result_mode)\n \t      && STORE_FLAG_VALUE == -1\n \t      && nonzero_bits (XEXP (varop, 0), result_mode) == 1\n \t      && merge_outer_ops (&outer_op, &outer_const, XOR, 1, result_mode,\n@@ -10402,7 +10397,7 @@ simplify_shift_const_1 (enum rtx_code code, enum machine_mode result_mode,\n \t    }\n \t  else if ((code == ASHIFTRT || code == LSHIFTRT)\n \t\t   && count < HOST_BITS_PER_WIDE_INT\n-\t\t   && GET_MODE_BITSIZE (result_mode) <= HOST_BITS_PER_WIDE_INT\n+\t\t   && HWI_COMPUTABLE_MODE_P (result_mode)\n \t\t   && 0 == (nonzero_bits (XEXP (varop, 0), result_mode)\n \t\t\t    >> count)\n \t\t   && 0 == (nonzero_bits (XEXP (varop, 0), result_mode)\n@@ -11084,7 +11079,7 @@ simplify_comparison (enum rtx_code code, rtx *pop0, rtx *pop1)\n \t this shift are known to be zero for both inputs and if the type of\n \t comparison is compatible with the shift.  */\n       if (GET_CODE (op0) == GET_CODE (op1)\n-\t  && GET_MODE_BITSIZE (GET_MODE (op0)) <= HOST_BITS_PER_WIDE_INT\n+\t  && HWI_COMPUTABLE_MODE_P (GET_MODE(op0))\n \t  && ((GET_CODE (op0) == ROTATE && (code == NE || code == EQ))\n \t      || ((GET_CODE (op0) == LSHIFTRT || GET_CODE (op0) == ASHIFT)\n \t\t  && (code != GT && code != LT && code != GE && code != LE))\n@@ -11233,8 +11228,7 @@ simplify_comparison (enum rtx_code code, rtx *pop0, rtx *pop1)\n \n       /* If this is a sign bit comparison and we can do arithmetic in\n \t MODE, say that we will only be needing the sign bit of OP0.  */\n-      if (sign_bit_comparison_p\n-\t  && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT)\n+      if (sign_bit_comparison_p && HWI_COMPUTABLE_MODE_P (mode))\n \top0 = force_to_mode (op0, mode,\n \t\t\t     (unsigned HOST_WIDE_INT) 1\n \t\t\t     << (GET_MODE_BITSIZE (mode) - 1),\n@@ -11481,7 +11475,7 @@ simplify_comparison (enum rtx_code code, rtx *pop0, rtx *pop1)\n \t  mode = GET_MODE (XEXP (op0, 0));\n \t  if (mode != VOIDmode && GET_MODE_CLASS (mode) == MODE_INT\n \t      && (unsigned_comparison_p || equality_comparison_p)\n-\t      && (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT)\n+\t      && HWI_COMPUTABLE_MODE_P (mode)\n \t      && ((unsigned HOST_WIDE_INT) const_op < GET_MODE_MASK (mode))\n \t      && have_insn_for (COMPARE, mode))\n \t    {\n@@ -11726,7 +11720,7 @@ simplify_comparison (enum rtx_code code, rtx *pop0, rtx *pop1)\n \t\t\t  && subreg_lowpart_p (XEXP (op0, 0))))\n \t\t  && CONST_INT_P (XEXP (op0, 1))\n \t\t  && mode_width <= HOST_BITS_PER_WIDE_INT\n-\t\t  && GET_MODE_BITSIZE (tmode) <= HOST_BITS_PER_WIDE_INT\n+\t\t  && HWI_COMPUTABLE_MODE_P (tmode)\n \t\t  && ((c1 = INTVAL (XEXP (op0, 1))) & ~mask) == 0\n \t\t  && (c1 & ~GET_MODE_MASK (tmode)) == 0\n \t\t  && c1 != mask\n@@ -11765,7 +11759,7 @@ simplify_comparison (enum rtx_code code, rtx *pop0, rtx *pop1)\n \t\t  || (GET_CODE (shift_op) == XOR\n \t\t      && CONST_INT_P (XEXP (shift_op, 1))\n \t\t      && CONST_INT_P (shift_count)\n-\t\t      && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t\t      && HWI_COMPUTABLE_MODE_P (mode)\n \t\t      && (UINTVAL (XEXP (shift_op, 1))\n \t\t\t  == (unsigned HOST_WIDE_INT) 1\n \t\t\t       << INTVAL (shift_count))))\n@@ -12014,8 +12008,7 @@ simplify_comparison (enum rtx_code code, rtx *pop0, rtx *pop1)\n       && GET_MODE_SIZE (mode) < UNITS_PER_WORD\n       && ! have_insn_for (COMPARE, mode))\n     for (tmode = GET_MODE_WIDER_MODE (mode);\n-\t (tmode != VOIDmode\n-\t  && GET_MODE_BITSIZE (tmode) <= HOST_BITS_PER_WIDE_INT);\n+\t (tmode != VOIDmode && HWI_COMPUTABLE_MODE_P (tmode));\n \t tmode = GET_MODE_WIDER_MODE (tmode))\n       if (have_insn_for (COMPARE, tmode))\n \t{\n@@ -12026,7 +12019,7 @@ simplify_comparison (enum rtx_code code, rtx *pop0, rtx *pop1)\n \t     a paradoxical subreg to extend OP0.  */\n \n \t  if (op1 == const0_rtx && (code == LT || code == GE)\n-\t      && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT)\n+\t      && HWI_COMPUTABLE_MODE_P (mode))\n \t    {\n \t      op0 = simplify_gen_binary (AND, tmode,\n \t\t\t\t\t gen_lowpart (tmode, op0),\n@@ -12318,7 +12311,7 @@ record_value_for_reg (rtx reg, rtx insn, rtx value)\n       subst_low_luid = DF_INSN_LUID (insn);\n       rsp->last_set_mode = mode;\n       if (GET_MODE_CLASS (mode) == MODE_INT\n-\t  && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT)\n+\t  && HWI_COMPUTABLE_MODE_P (mode))\n \tmode = nonzero_bits_mode;\n       rsp->last_set_nonzero_bits = nonzero_bits (value, mode);\n       rsp->last_set_sign_bit_copies"}, {"sha": "662add5b2ed3df1bf989a5d0be58f745a0944491", "filename": "gcc/expmed.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46c9550f314d1eb1767d9636afda497a1cbd0797/gcc%2Fexpmed.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46c9550f314d1eb1767d9636afda497a1cbd0797/gcc%2Fexpmed.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpmed.c?ref=46c9550f314d1eb1767d9636afda497a1cbd0797", "patch": "@@ -3112,7 +3112,7 @@ expand_widening_mult (enum machine_mode mode, rtx op0, rtx op1, rtx target,\n \t\t\t\tthis_optab == umul_widen_optab))\n       && CONST_INT_P (cop1)\n       && (INTVAL (cop1) >= 0\n-\t  || GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT))\n+\t  || HWI_COMPUTABLE_MODE_P (mode)))\n     {\n       HOST_WIDE_INT coeff = INTVAL (cop1);\n       int max_cost;\n@@ -3459,7 +3459,7 @@ expand_mult_highpart (enum machine_mode mode, rtx op0, rtx op1,\n \n   gcc_assert (!SCALAR_FLOAT_MODE_P (mode));\n   /* We can't support modes wider than HOST_BITS_PER_INT.  */\n-  gcc_assert (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT);\n+  gcc_assert (HWI_COMPUTABLE_MODE_P (mode));\n \n   cnst1 = INTVAL (op1) & GET_MODE_MASK (mode);\n "}, {"sha": "f979b95ea0b7ea13222698f7732efefd03fb4acd", "filename": "gcc/machmode.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46c9550f314d1eb1767d9636afda497a1cbd0797/gcc%2Fmachmode.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46c9550f314d1eb1767d9636afda497a1cbd0797/gcc%2Fmachmode.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fmachmode.h?ref=46c9550f314d1eb1767d9636afda497a1cbd0797", "patch": "@@ -279,4 +279,8 @@ extern void init_adjust_machine_modes (void);\n   TRULY_NOOP_TRUNCATION (GET_MODE_PRECISION (MODE1), \\\n \t\t\t GET_MODE_PRECISION (MODE2))\n \n+#define HWI_COMPUTABLE_MODE_P(MODE) \\\n+  (SCALAR_INT_MODE_P (MODE) \\\n+   && GET_MODE_PRECISION (MODE) <= HOST_BITS_PER_WIDE_INT)\n+\n #endif /* not HAVE_MACHINE_MODES */"}, {"sha": "d5a9cbcbdede69bca0acacb6f0244f7c0ce94771", "filename": "gcc/simplify-rtx.c", "status": "modified", "additions": 8, "deletions": 9, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46c9550f314d1eb1767d9636afda497a1cbd0797/gcc%2Fsimplify-rtx.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46c9550f314d1eb1767d9636afda497a1cbd0797/gcc%2Fsimplify-rtx.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsimplify-rtx.c?ref=46c9550f314d1eb1767d9636afda497a1cbd0797", "patch": "@@ -865,7 +865,7 @@ simplify_unary_operation_1 (enum rtx_code code, enum machine_mode mode, rtx op)\n          STORE_FLAG_VALUE permits.  This is like the previous test,\n          but it works even if the comparison is done in a mode larger\n          than HOST_BITS_PER_WIDE_INT.  */\n-      if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+      if (HWI_COMPUTABLE_MODE_P (mode)\n \t  && COMPARISON_P (op)\n \t  && (STORE_FLAG_VALUE & ~GET_MODE_MASK (mode)) == 0)\n \treturn rtl_hooks.gen_lowpart_no_emit (mode, op);\n@@ -2446,7 +2446,7 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n \n       /* (ior A C) is C if all bits of A that might be nonzero are on in C.  */\n       if (CONST_INT_P (op1)\n-\t  && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t  && HWI_COMPUTABLE_MODE_P (mode)\n \t  && (nonzero_bits (op0, mode) & ~UINTVAL (op1)) == 0)\n \treturn op1;\n \n@@ -2531,7 +2531,7 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n       /* If we have (ior (and (X C1) C2)), simplify this by making\n \t C1 as small as possible if C1 actually changes.  */\n       if (CONST_INT_P (op1)\n-\t  && (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t  && (HWI_COMPUTABLE_MODE_P (mode)\n \t      || INTVAL (op1) > 0)\n \t  && GET_CODE (op0) == AND\n \t  && CONST_INT_P (XEXP (op0, 1))\n@@ -2602,7 +2602,7 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n \t convert them into an IOR.  This helps to detect rotation encoded\n \t using those methods and possibly other simplifications.  */\n \n-      if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+      if (HWI_COMPUTABLE_MODE_P (mode)\n \t  && (nonzero_bits (op0, mode)\n \t      & nonzero_bits (op1, mode)) == 0)\n \treturn (simplify_gen_binary (IOR, mode, op0, op1));\n@@ -2721,7 +2721,7 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n     case AND:\n       if (trueop1 == CONST0_RTX (mode) && ! side_effects_p (op0))\n \treturn trueop1;\n-      if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT)\n+      if (HWI_COMPUTABLE_MODE_P (mode))\n \t{\n \t  HOST_WIDE_INT nzop0 = nonzero_bits (trueop0, mode);\n \t  HOST_WIDE_INT nzop1;\n@@ -2754,7 +2754,7 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n       if ((GET_CODE (op0) == SIGN_EXTEND\n \t   || GET_CODE (op0) == ZERO_EXTEND)\n \t  && CONST_INT_P (trueop1)\n-\t  && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t  && HWI_COMPUTABLE_MODE_P (mode)\n \t  && (~GET_MODE_MASK (GET_MODE (XEXP (op0, 0)))\n \t      & UINTVAL (trueop1)) == 0)\n \t{\n@@ -2836,7 +2836,7 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n          Also, if (N & M) == 0, then\n \t (A +- N) & M -> A & M.  */\n       if (CONST_INT_P (trueop1)\n-\t  && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t  && HWI_COMPUTABLE_MODE_P (mode)\n \t  && ~UINTVAL (trueop1)\n \t  && (UINTVAL (trueop1) & (UINTVAL (trueop1) + 1)) == 0\n \t  && (GET_CODE (op0) == PLUS || GET_CODE (op0) == MINUS))\n@@ -4681,8 +4681,7 @@ simplify_const_relational_operation (enum rtx_code code,\n     }\n \n   /* Optimize comparisons with upper and lower bounds.  */\n-  if (SCALAR_INT_MODE_P (mode)\n-      && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+  if (HWI_COMPUTABLE_MODE_P (mode)\n       && CONST_INT_P (trueop1))\n     {\n       int sign;"}]}