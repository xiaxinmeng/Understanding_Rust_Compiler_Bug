{"sha": "e37af218eed960ea5d499158db780aa4821e02cc", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTM3YWYyMThlZWQ5NjBlYTVkNDk5MTU4ZGI3ODBhYTQ4MjFlMDJjYw==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@redhat.com", "date": "2002-01-12T10:05:28Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2002-01-12T10:05:28Z"}, "message": "i386.c (override_options): If SSE, enable sse prefetch.\n\n        * config/i386/i386.c (override_options): If SSE, enable sse prefetch.\n        (ix86_expand_vector_move): New.\n        (bdesc_2arg): Remove andps, andnps, orps, xorps.\n        (ix86_init_mmx_sse_builtins): Make static.  Remove composite builtins.\n        Remove old prefetch builtins.  Special case the logicals removed above.\n        (ix86_expand_builtin): Likewise.\n        (safe_vector_operand): Use V4SFmode, not TImode.\n        (ix86_expand_store_builtin): Remove shuffle arg.  Update callers.\n        (ix86_expand_timode_binop_builtin): New.\n        * config/i386/i386-protos.h: Update.\n        * config/i386/i386.h (enum ix86_builtins): Update.\n        * config/i386/i386.md: Correct predicates on MMX/SSE patterns.\n        Use ix86_expand_vector_move in vector move expanders.\n        (movti_internal, movti_rex64): Add xorps alternative.\n        (sse_clrv4sf): Rename and adjust from sse_clrti.\n        (prefetch): Don't work so hard.\n        (prefetch_sse, prefetch_3dnow): Use PREFETCH rtx, not UNSPEC.\n        * config/i386/xmmintrin.h (__m128): Use V4SFmode.\n        (_mm_getcsr, _mm_setcsr): Fix typo in builtin name.\n\nFrom-SVN: r48796", "tree": {"sha": "9015cbde63a553c647631990a8859f8b29b4af0f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/9015cbde63a553c647631990a8859f8b29b4af0f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e37af218eed960ea5d499158db780aa4821e02cc", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e37af218eed960ea5d499158db780aa4821e02cc", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e37af218eed960ea5d499158db780aa4821e02cc", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e37af218eed960ea5d499158db780aa4821e02cc/comments", "author": null, "committer": null, "parents": [{"sha": "b0d723da3660fdff9096353054bfcf6c39f3769c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b0d723da3660fdff9096353054bfcf6c39f3769c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b0d723da3660fdff9096353054bfcf6c39f3769c"}], "stats": {"total": 893, "additions": 335, "deletions": 558}, "files": [{"sha": "93ceae32832b73832987300ab1722383f4f559ab", "filename": "gcc/ChangeLog", "status": "modified", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e37af218eed960ea5d499158db780aa4821e02cc/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e37af218eed960ea5d499158db780aa4821e02cc/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=e37af218eed960ea5d499158db780aa4821e02cc", "patch": "@@ -1,3 +1,25 @@\n+2002-01-12  Richard Henderson  <rth@redhat.com>\n+\n+\t* config/i386/i386.c (override_options): If SSE, enable sse prefetch.\n+\t(ix86_expand_vector_move): New.\n+\t(bdesc_2arg): Remove andps, andnps, orps, xorps.\n+\t(ix86_init_mmx_sse_builtins): Make static.  Remove composite builtins.\n+\tRemove old prefetch builtins.  Special case the logicals removed above.\n+\t(ix86_expand_builtin): Likewise.\n+\t(safe_vector_operand): Use V4SFmode, not TImode.\n+\t(ix86_expand_store_builtin): Remove shuffle arg.  Update callers.\n+\t(ix86_expand_timode_binop_builtin): New.\n+\t* config/i386/i386-protos.h: Update.\n+\t* config/i386/i386.h (enum ix86_builtins): Update.\n+\t* config/i386/i386.md: Correct predicates on MMX/SSE patterns.\n+\tUse ix86_expand_vector_move in vector move expanders.\n+\t(movti_internal, movti_rex64): Add xorps alternative.\n+\t(sse_clrv4sf): Rename and adjust from sse_clrti.\n+\t(prefetch): Don't work so hard.\n+\t(prefetch_sse, prefetch_3dnow): Use PREFETCH rtx, not UNSPEC.\n+\t* config/i386/xmmintrin.h (__m128): Use V4SFmode.\n+\t(_mm_getcsr, _mm_setcsr): Fix typo in builtin name.\n+\n 2002-01-11  Richard Henderson  <rth@redhat.com>\n \n \t* config/i386/mmintrin.h: New file."}, {"sha": "01c4d447054a93d886ac6c40d944ba8a2813171b", "filename": "gcc/config/i386/i386-protos.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e37af218eed960ea5d499158db780aa4821e02cc/gcc%2Fconfig%2Fi386%2Fi386-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e37af218eed960ea5d499158db780aa4821e02cc/gcc%2Fconfig%2Fi386%2Fi386-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-protos.h?ref=e37af218eed960ea5d499158db780aa4821e02cc", "patch": "@@ -108,6 +108,7 @@ extern rtx i386_simplify_dwarf_addr PARAMS ((rtx));\n \n extern void ix86_expand_clear PARAMS ((rtx));\n extern void ix86_expand_move PARAMS ((enum machine_mode, rtx[]));\n+extern void ix86_expand_vector_move PARAMS ((enum machine_mode, rtx[]));\n extern void ix86_expand_binary_operator PARAMS ((enum rtx_code,\n \t\t\t\t\t       enum machine_mode, rtx[]));\n extern int ix86_binary_operator_ok PARAMS ((enum rtx_code, enum machine_mode,\n@@ -177,7 +178,6 @@ extern void function_arg_advance PARAMS ((CUMULATIVE_ARGS *, enum machine_mode,\n \t\t\t\t\ttree, int));\n extern rtx ix86_function_value PARAMS ((tree));\n extern void ix86_init_builtins PARAMS ((void));\n-extern void ix86_init_mmx_sse_builtins PARAMS ((void));\n extern rtx ix86_expand_builtin PARAMS ((tree, rtx, rtx, enum machine_mode, int));\n #endif\n "}, {"sha": "08c9ca6920238802b7008b62e0c45ab9f918fa31", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 107, "deletions": 174, "changes": 281, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e37af218eed960ea5d499158db780aa4821e02cc/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e37af218eed960ea5d499158db780aa4821e02cc/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=e37af218eed960ea5d499158db780aa4821e02cc", "patch": "@@ -684,6 +684,7 @@ static int ix86_adjust_cost PARAMS ((rtx, rtx, rtx, int));\n static void ix86_sched_init PARAMS ((FILE *, int, int));\n static int ix86_sched_reorder PARAMS ((FILE *, int, rtx *, int *, int));\n static int ix86_variable_issue PARAMS ((FILE *, int, rtx, int));\n+static void ix86_init_mmx_sse_builtins PARAMS ((void));\n \n struct ix86_address\n {\n@@ -701,7 +702,9 @@ static rtx ix86_expand_sse_compare PARAMS ((const struct builtin_description *,\n static rtx ix86_expand_unop1_builtin PARAMS ((enum insn_code, tree, rtx));\n static rtx ix86_expand_unop_builtin PARAMS ((enum insn_code, tree, rtx, int));\n static rtx ix86_expand_binop_builtin PARAMS ((enum insn_code, tree, rtx));\n-static rtx ix86_expand_store_builtin PARAMS ((enum insn_code, tree, int));\n+static rtx ix86_expand_timode_binop_builtin PARAMS ((enum insn_code,\n+\t\t\t\t\t\t     tree, rtx));\n+static rtx ix86_expand_store_builtin PARAMS ((enum insn_code, tree));\n static rtx safe_vector_operand PARAMS ((rtx, enum machine_mode));\n static enum rtx_code ix86_fp_compare_code_to_integer PARAMS ((enum rtx_code));\n static void ix86_fp_comparison_codes PARAMS ((enum rtx_code code,\n@@ -1164,7 +1167,10 @@ override_options ()\n   /* It makes no sense to ask for just SSE builtins, so MMX is also turned\n      on by -msse.  */\n   if (TARGET_SSE)\n-    target_flags |= MASK_MMX;\n+    {\n+      target_flags |= MASK_MMX;\n+      x86_prefetch_sse = true;\n+    }\n \n   /* If it has 3DNow! it also has MMX so MMX is also turned on by -m3dnow */\n   if (TARGET_3DNOW)\n@@ -6661,6 +6667,38 @@ ix86_expand_move (mode, operands)\n   emit_insn (insn);\n }\n \n+void\n+ix86_expand_vector_move (mode, operands)\n+     enum machine_mode mode;\n+     rtx operands[];\n+{\n+  /* Force constants other than zero into memory.  We do not know how\n+     the instructions used to build constants modify the upper 64 bits\n+     of the register, once we have that information we may be able\n+     to handle some of them more efficiently.  */\n+  if ((reload_in_progress | reload_completed) == 0\n+      && register_operand (operands[0], mode)\n+      && CONSTANT_P (operands[1]))\n+    {\n+      rtx addr = gen_reg_rtx (Pmode);\n+      emit_move_insn (addr, XEXP (force_const_mem (mode, operands[1]), 0));\n+      operands[1] = gen_rtx_MEM (mode, addr);\n+    }\n+\n+  /* Make operand1 a register if it isn't already.  */\n+  if ((reload_in_progress | reload_completed) == 0\n+      && !register_operand (operands[0], mode)\n+      && !register_operand (operands[1], mode)\n+      && operands[1] != CONST0_RTX (mode))\n+    {\n+      rtx temp = force_reg (TImode, operands[1]);\n+      emit_move_insn (operands[0], temp);\n+      return;\n+    }\n+\n+  emit_insn (gen_rtx_SET (VOIDmode, operands[0], operands[1]));\n+}  \n+\n /* Attempt to expand a binary operator.  Make the expansion closer to the\n    actual machine, then just general_operand, which will allow 3 separate\n    memory references (one output, two input) in a single insn.  */\n@@ -10748,11 +10786,6 @@ static const struct builtin_description bdesc_2arg[] =\n   { MASK_SSE, CODE_FOR_vmsminv4sf3, \"__builtin_ia32_minss\", IX86_BUILTIN_MINSS, 0, 0 },\n   { MASK_SSE, CODE_FOR_vmsmaxv4sf3, \"__builtin_ia32_maxss\", IX86_BUILTIN_MAXSS, 0, 0 },\n \n-  { MASK_SSE, CODE_FOR_sse_andti3, \"__builtin_ia32_andps\", IX86_BUILTIN_ANDPS, 0, 0 },\n-  { MASK_SSE, CODE_FOR_sse_nandti3,  \"__builtin_ia32_andnps\", IX86_BUILTIN_ANDNPS, 0, 0 },\n-  { MASK_SSE, CODE_FOR_sse_iorti3, \"__builtin_ia32_orps\", IX86_BUILTIN_ORPS, 0, 0 },\n-  { MASK_SSE, CODE_FOR_sse_xorti3,  \"__builtin_ia32_xorps\", IX86_BUILTIN_XORPS, 0, 0 },\n-\n   { MASK_SSE, CODE_FOR_sse_movss,  \"__builtin_ia32_movss\", IX86_BUILTIN_MOVSS, 0, 0 },\n   { MASK_SSE, CODE_FOR_sse_movhlps,  \"__builtin_ia32_movhlps\", IX86_BUILTIN_MOVHLPS, 0, 0 },\n   { MASK_SSE, CODE_FOR_sse_movlhps,  \"__builtin_ia32_movlhps\", IX86_BUILTIN_MOVLHPS, 0, 0 },\n@@ -10865,7 +10898,7 @@ ix86_init_builtins ()\n /* Set up all the MMX/SSE builtins.  This is not called if TARGET_MMX\n    is zero.  Otherwise, if TARGET_SSE is not set, only expand the MMX\n    builtins.  */\n-void\n+static void\n ix86_init_mmx_sse_builtins ()\n {\n   const struct builtin_description * d;\n@@ -10899,14 +10932,6 @@ ix86_init_mmx_sse_builtins ()\n     = build_function_type (integer_type_node,\n \t\t\t   tree_cons (NULL_TREE, V8QI_type_node,\n \t\t\t\t      endlink));\n-  tree int_ftype_v2si\n-    = build_function_type (integer_type_node,\n-\t\t\t   tree_cons (NULL_TREE, V2SI_type_node,\n-\t\t\t\t      endlink));\n-  tree v2si_ftype_int\n-    = build_function_type (V2SI_type_node,\n-\t\t\t   tree_cons (NULL_TREE, integer_type_node,\n-\t\t\t\t      endlink));\n   tree v4sf_ftype_v4sf_int\n     = build_function_type (V4SF_type_node,\n \t\t\t   tree_cons (NULL_TREE, V4SF_type_node,\n@@ -10976,11 +11001,6 @@ ix86_init_mmx_sse_builtins ()\n \t\t\t\t\t\t endlink)));\n   tree void_ftype_void\n     = build_function_type (void_type_node, endlink);\n-  tree void_ftype_pchar_int\n-    = build_function_type (void_type_node,\n-\t\t\t   tree_cons (NULL_TREE, pchar_type_node,\n-\t\t\t\t      tree_cons (NULL_TREE, integer_type_node,\n-\t\t\t\t\t\t endlink)));\n   tree void_ftype_unsigned\n     = build_function_type (void_type_node,\n \t\t\t   tree_cons (NULL_TREE, unsigned_type_node,\n@@ -10989,8 +11009,8 @@ ix86_init_mmx_sse_builtins ()\n     = build_function_type (unsigned_type_node, endlink);\n   tree di_ftype_void\n     = build_function_type (long_long_unsigned_type_node, endlink);\n-  tree ti_ftype_void\n-    = build_function_type (intTI_type_node, endlink);\n+  tree v4sf_ftype_void\n+    = build_function_type (V4SF_type_node, endlink);\n   tree v2si_ftype_v4sf\n     = build_function_type (V2SI_type_node,\n \t\t\t   tree_cons (NULL_TREE, V4SF_type_node,\n@@ -11007,19 +11027,6 @@ ix86_init_mmx_sse_builtins ()\n     = build_function_type (V4SF_type_node,\n \t\t\t   tree_cons (NULL_TREE, pfloat_type_node,\n \t\t\t\t      endlink));\n-  tree v4sf_ftype_float\n-    = build_function_type (V4SF_type_node,\n-\t\t\t   tree_cons (NULL_TREE, float_type_node,\n-\t\t\t\t      endlink));\n-  tree v4sf_ftype_float_float_float_float\n-    = build_function_type (V4SF_type_node,\n-\t\t\t   tree_cons (NULL_TREE, float_type_node,\n-\t\t\t\t      tree_cons (NULL_TREE, float_type_node,\n-\t\t\t\t\t\t tree_cons (NULL_TREE,\n-\t\t\t\t\t\t\t    float_type_node,\n-\t\t\t\t\t\t\t    tree_cons (NULL_TREE,\n-\t\t\t\t\t\t\t\t       float_type_node,\n-\t\t\t\t\t\t\t\t       endlink)))));\n   /* @@@ the type is bogus */\n   tree v4sf_ftype_v4sf_pv2si\n     = build_function_type (V4SF_type_node,\n@@ -11069,11 +11076,6 @@ ix86_init_mmx_sse_builtins ()\n \t\t\t   tree_cons (NULL_TREE, V2SI_type_node,\n \t\t\t\t      tree_cons (NULL_TREE, V2SI_type_node,\n \t\t\t\t\t\t endlink)));\n-  tree ti_ftype_ti_ti\n-    = build_function_type (intTI_type_node,\n-\t\t\t   tree_cons (NULL_TREE, intTI_type_node,\n-\t\t\t\t      tree_cons (NULL_TREE, intTI_type_node,\n-\t\t\t\t\t\t endlink)));\n   tree di_ftype_di_di\n     = build_function_type (long_long_unsigned_type_node,\n \t\t\t   tree_cons (NULL_TREE, long_long_unsigned_type_node,\n@@ -11110,11 +11112,6 @@ ix86_init_mmx_sse_builtins ()\n                                                  V2SF_type_node,\n                                                  endlink)));\n \n-  tree void_ftype_pchar\n-    = build_function_type (void_type_node,\n-                           tree_cons (NULL_TREE, pchar_type_node,\n-                                      endlink));\n-\n   /* Add all builtins that are more or less simple operations on two\n      operands.  */\n   for (i = 0, d = bdesc_2arg; i < sizeof (bdesc_2arg) / sizeof *d; i++, d++)\n@@ -11142,9 +11139,6 @@ ix86_init_mmx_sse_builtins ()\n \tcase V2SImode:\n \t  type = v2si_ftype_v2si_v2si;\n \t  break;\n-\tcase TImode:\n-\t  type = ti_ftype_ti_ti;\n-\t  break;\n \tcase DImode:\n \t  type = di_ftype_di_di;\n \t  break;\n@@ -11164,8 +11158,6 @@ ix86_init_mmx_sse_builtins ()\n     }\n \n   /* Add the remaining MMX insns with somewhat more complicated types.  */\n-  def_builtin (MASK_MMX, \"__builtin_ia32_m_from_int\", v2si_ftype_int, IX86_BUILTIN_M_FROM_INT);\n-  def_builtin (MASK_MMX, \"__builtin_ia32_m_to_int\", int_ftype_v2si, IX86_BUILTIN_M_TO_INT);\n   def_builtin (MASK_MMX, \"__builtin_ia32_mmx_zero\", di_ftype_void, IX86_BUILTIN_MMX_ZERO);\n   def_builtin (MASK_MMX, \"__builtin_ia32_emms\", void_ftype_void, IX86_BUILTIN_EMMS);\n   def_builtin (MASK_MMX, \"__builtin_ia32_ldmxcsr\", void_ftype_unsigned, IX86_BUILTIN_LDMXCSR);\n@@ -11199,6 +11191,11 @@ ix86_init_mmx_sse_builtins ()\n   def_builtin (MASK_SSE, \"__builtin_ia32_cvttps2pi\", v2si_ftype_v4sf, IX86_BUILTIN_CVTTPS2PI);\n   def_builtin (MASK_SSE, \"__builtin_ia32_cvttss2si\", int_ftype_v4sf, IX86_BUILTIN_CVTTSS2SI);\n \n+  def_builtin (MASK_SSE, \"__builtin_ia32_andps\", v4sf_ftype_v4sf_v4sf, IX86_BUILTIN_ANDPS);\n+  def_builtin (MASK_SSE, \"__builtin_ia32_andnps\", v4sf_ftype_v4sf_v4sf, IX86_BUILTIN_ANDNPS);\n+  def_builtin (MASK_SSE, \"__builtin_ia32_orps\", v4sf_ftype_v4sf_v4sf, IX86_BUILTIN_ORPS);\n+  def_builtin (MASK_SSE, \"__builtin_ia32_xorps\", v4sf_ftype_v4sf_v4sf, IX86_BUILTIN_XORPS);\n+\n   def_builtin (MASK_SSE | MASK_3DNOW_A, \"__builtin_ia32_pextrw\", int_ftype_v4hi_int, IX86_BUILTIN_PEXTRW);\n   def_builtin (MASK_SSE | MASK_3DNOW_A, \"__builtin_ia32_pinsrw\", v4hi_ftype_v4hi_int_int, IX86_BUILTIN_PINSRW);\n \n@@ -11222,7 +11219,6 @@ ix86_init_mmx_sse_builtins ()\n   def_builtin (MASK_SSE | MASK_3DNOW_A, \"__builtin_ia32_movntq\", void_ftype_pdi_di, IX86_BUILTIN_MOVNTQ);\n \n   def_builtin (MASK_SSE | MASK_3DNOW_A, \"__builtin_ia32_sfence\", void_ftype_void, IX86_BUILTIN_SFENCE);\n-  def_builtin (MASK_SSE | MASK_3DNOW_A, \"__builtin_ia32_prefetch\", void_ftype_pchar_int, IX86_BUILTIN_PREFETCH);\n \n   def_builtin (MASK_SSE | MASK_3DNOW_A, \"__builtin_ia32_psadbw\", v4hi_ftype_v8qi_v8qi, IX86_BUILTIN_PSADBW);\n \n@@ -11256,8 +11252,6 @@ ix86_init_mmx_sse_builtins ()\n   def_builtin (MASK_3DNOW, \"__builtin_ia32_pfsubr\", v2sf_ftype_v2sf_v2sf, IX86_BUILTIN_PFSUBR);\n   def_builtin (MASK_3DNOW, \"__builtin_ia32_pi2fd\", v2sf_ftype_v2si, IX86_BUILTIN_PI2FD);\n   def_builtin (MASK_3DNOW, \"__builtin_ia32_pmulhrw\", v4hi_ftype_v4hi_v4hi, IX86_BUILTIN_PMULHRW);\n-  def_builtin (MASK_3DNOW, \"__builtin_ia32_prefetch_3dnow\", void_ftype_pchar, IX86_BUILTIN_PREFETCH_3DNOW);\n-  def_builtin (MASK_3DNOW, \"__builtin_ia32_prefetchw\", void_ftype_pchar, IX86_BUILTIN_PREFETCHW);\n \n   /* 3DNow! extension as used in the Athlon CPU.  */\n   def_builtin (MASK_3DNOW_A, \"__builtin_ia32_pf2iw\", v2si_ftype_v2sf, IX86_BUILTIN_PF2IW);\n@@ -11267,14 +11261,7 @@ ix86_init_mmx_sse_builtins ()\n   def_builtin (MASK_3DNOW_A, \"__builtin_ia32_pswapdsf\", v2sf_ftype_v2sf, IX86_BUILTIN_PSWAPDSF);\n   def_builtin (MASK_3DNOW_A, \"__builtin_ia32_pswapdsi\", v2si_ftype_v2si, IX86_BUILTIN_PSWAPDSI);\n \n-  /* Composite intrinsics.  */\n-  def_builtin (MASK_SSE, \"__builtin_ia32_setps1\", v4sf_ftype_float, IX86_BUILTIN_SETPS1);\n-  def_builtin (MASK_SSE, \"__builtin_ia32_setps\", v4sf_ftype_float_float_float_float, IX86_BUILTIN_SETPS);\n-  def_builtin (MASK_SSE, \"__builtin_ia32_setzerops\", ti_ftype_void, IX86_BUILTIN_CLRPS);\n-  def_builtin (MASK_SSE, \"__builtin_ia32_loadps1\", v4sf_ftype_pfloat, IX86_BUILTIN_LOADPS1);\n-  def_builtin (MASK_SSE, \"__builtin_ia32_loadrps\", v4sf_ftype_pfloat, IX86_BUILTIN_LOADRPS);\n-  def_builtin (MASK_SSE, \"__builtin_ia32_storeps1\", void_ftype_pfloat_v4sf, IX86_BUILTIN_STOREPS1);\n-  def_builtin (MASK_SSE, \"__builtin_ia32_storerps\", void_ftype_pfloat_v4sf, IX86_BUILTIN_STORERPS);\n+  def_builtin (MASK_SSE, \"__builtin_ia32_setzerops\", v4sf_ftype_void, IX86_BUILTIN_SSE_ZERO);\n }\n \n /* Errors in the source file can cause expand_expr to return const0_rtx\n@@ -11293,8 +11280,8 @@ safe_vector_operand (x, mode)\n     emit_insn (gen_mmx_clrdi (mode == DImode ? x\n \t\t\t      : gen_rtx_SUBREG (DImode, x, 0)));\n   else\n-    emit_insn (gen_sse_clrti (mode == TImode ? x\n-\t\t\t      : gen_rtx_SUBREG (TImode, x, 0)));\n+    emit_insn (gen_sse_clrv4sf (mode == V4SFmode ? x\n+\t\t\t\t: gen_rtx_SUBREG (V4SFmode, x, 0)));\n   return x;\n }\n \n@@ -11342,13 +11329,45 @@ ix86_expand_binop_builtin (icode, arglist, target)\n   return target;\n }\n \n+/* In type_for_mode we restrict the ability to create TImode types \n+   to hosts with 64-bit H_W_I.  So we've defined the SSE logicals\n+   to have a V4SFmode signature.  Convert them in-place to TImode.  */\n+\n+static rtx\n+ix86_expand_timode_binop_builtin (icode, arglist, target)\n+     enum insn_code icode;\n+     tree arglist;\n+     rtx target;\n+{\n+  rtx pat;\n+  tree arg0 = TREE_VALUE (arglist);\n+  tree arg1 = TREE_VALUE (TREE_CHAIN (arglist));\n+  rtx op0 = expand_expr (arg0, NULL_RTX, VOIDmode, 0);\n+  rtx op1 = expand_expr (arg1, NULL_RTX, VOIDmode, 0);\n+\n+  op0 = gen_lowpart (TImode, op0);\n+  op1 = gen_lowpart (TImode, op1);\n+  target = gen_reg_rtx (TImode);\n+\n+  if (! (*insn_data[icode].operand[1].predicate) (op0, TImode))\n+    op0 = copy_to_mode_reg (TImode, op0);\n+  if (! (*insn_data[icode].operand[2].predicate) (op1, TImode))\n+    op1 = copy_to_mode_reg (TImode, op1);\n+\n+  pat = GEN_FCN (icode) (target, op0, op1);\n+  if (! pat)\n+    return 0;\n+  emit_insn (pat);\n+\n+  return gen_lowpart (V4SFmode, target);\n+}\n+\n /* Subroutine of ix86_expand_builtin to take care of stores.  */\n \n static rtx\n-ix86_expand_store_builtin (icode, arglist, shuffle)\n+ix86_expand_store_builtin (icode, arglist)\n      enum insn_code icode;\n      tree arglist;\n-     int shuffle;\n {\n   rtx pat;\n   tree arg0 = TREE_VALUE (arglist);\n@@ -11362,10 +11381,6 @@ ix86_expand_store_builtin (icode, arglist, shuffle)\n     op1 = safe_vector_operand (op1, mode1);\n \n   op0 = gen_rtx_MEM (mode0, copy_to_mode_reg (Pmode, op0));\n-  if (shuffle >= 0 || ! (*insn_data[icode].operand[1].predicate) (op1, mode1))\n-    op1 = copy_to_mode_reg (mode1, op1);\n-  if (shuffle >= 0)\n-    emit_insn (gen_sse_shufps (op1, op1, op1, GEN_INT (shuffle)));\n   pat = GEN_FCN (icode) (op0, op1);\n   if (pat)\n     emit_insn (pat);\n@@ -11568,7 +11583,7 @@ ix86_expand_builtin (exp, target, subtarget, mode, ignore)\n   enum insn_code icode;\n   tree fndecl = TREE_OPERAND (TREE_OPERAND (exp, 0), 0);\n   tree arglist = TREE_OPERAND (exp, 1);\n-  tree arg0, arg1, arg2, arg3;\n+  tree arg0, arg1, arg2;\n   rtx op0, op1, op2, pat;\n   enum machine_mode tmode, mode0, mode1, mode2;\n   unsigned int fcode = DECL_FUNCTION_CODE (fndecl);\n@@ -11583,19 +11598,6 @@ ix86_expand_builtin (exp, target, subtarget, mode, ignore)\n       emit_insn (gen_sfence ());\n       return 0;\n \n-    case IX86_BUILTIN_M_FROM_INT:\n-      target = gen_reg_rtx (DImode);\n-      op0 = expand_expr (TREE_VALUE (arglist), NULL_RTX, VOIDmode, 0);\n-      emit_move_insn (gen_rtx_SUBREG (SImode, target, 0), op0);\n-      return target;\n-\n-    case IX86_BUILTIN_M_TO_INT:\n-      op0 = expand_expr (TREE_VALUE (arglist), NULL_RTX, VOIDmode, 0);\n-      op0 = copy_to_mode_reg (DImode, op0);\n-      target = gen_reg_rtx (SImode);\n-      emit_move_insn (target, gen_rtx_SUBREG (SImode, op0, 0));\n-      return target;\n-\n     case IX86_BUILTIN_PEXTRW:\n       icode = CODE_FOR_mmx_pextrw;\n       arg0 = TREE_VALUE (arglist);\n@@ -11689,22 +11691,35 @@ ix86_expand_builtin (exp, target, subtarget, mode, ignore)\n     case IX86_BUILTIN_RCPSS:\n       return ix86_expand_unop1_builtin (CODE_FOR_vmrcpv4sf2, arglist, target);\n \n+    case IX86_BUILTIN_ANDPS:\n+      return ix86_expand_timode_binop_builtin (CODE_FOR_sse_andti3,\n+\t\t\t\t\t       arglist, target);\n+    case IX86_BUILTIN_ANDNPS:\n+      return ix86_expand_timode_binop_builtin (CODE_FOR_sse_nandti3,\n+\t\t\t\t\t       arglist, target);\n+    case IX86_BUILTIN_ORPS:\n+      return ix86_expand_timode_binop_builtin (CODE_FOR_sse_iorti3,\n+\t\t\t\t\t       arglist, target);\n+    case IX86_BUILTIN_XORPS:\n+      return ix86_expand_timode_binop_builtin (CODE_FOR_sse_xorti3,\n+\t\t\t\t\t       arglist, target);\n+\n     case IX86_BUILTIN_LOADAPS:\n       return ix86_expand_unop_builtin (CODE_FOR_sse_movaps, arglist, target, 1);\n \n     case IX86_BUILTIN_LOADUPS:\n       return ix86_expand_unop_builtin (CODE_FOR_sse_movups, arglist, target, 1);\n \n     case IX86_BUILTIN_STOREAPS:\n-      return ix86_expand_store_builtin (CODE_FOR_sse_movaps, arglist, -1);\n+      return ix86_expand_store_builtin (CODE_FOR_sse_movaps, arglist);\n     case IX86_BUILTIN_STOREUPS:\n-      return ix86_expand_store_builtin (CODE_FOR_sse_movups, arglist, -1);\n+      return ix86_expand_store_builtin (CODE_FOR_sse_movups, arglist);\n \n     case IX86_BUILTIN_LOADSS:\n       return ix86_expand_unop_builtin (CODE_FOR_sse_loadss, arglist, target, 1);\n \n     case IX86_BUILTIN_STORESS:\n-      return ix86_expand_store_builtin (CODE_FOR_sse_storess, arglist, -1);\n+      return ix86_expand_store_builtin (CODE_FOR_sse_storess, arglist);\n \n     case IX86_BUILTIN_LOADHPS:\n     case IX86_BUILTIN_LOADLPS:\n@@ -11753,9 +11768,9 @@ ix86_expand_builtin (exp, target, subtarget, mode, ignore)\n       return 0;\n \n     case IX86_BUILTIN_MOVNTPS:\n-      return ix86_expand_store_builtin (CODE_FOR_sse_movntv4sf, arglist, -1);\n+      return ix86_expand_store_builtin (CODE_FOR_sse_movntv4sf, arglist);\n     case IX86_BUILTIN_MOVNTQ:\n-      return ix86_expand_store_builtin (CODE_FOR_sse_movntdi, arglist, -1);\n+      return ix86_expand_store_builtin (CODE_FOR_sse_movntdi, arglist);\n \n     case IX86_BUILTIN_LDMXCSR:\n       op0 = expand_expr (TREE_VALUE (arglist), NULL_RTX, VOIDmode, 0);\n@@ -11769,29 +11784,6 @@ ix86_expand_builtin (exp, target, subtarget, mode, ignore)\n       emit_insn (gen_stmxcsr (target));\n       return copy_to_mode_reg (SImode, target);\n \n-    case IX86_BUILTIN_PREFETCH:\n-      icode = CODE_FOR_prefetch_sse;\n-      arg0 = TREE_VALUE (arglist);\n-      arg1 = TREE_VALUE (TREE_CHAIN (arglist));\n-      op0 = expand_expr (arg0, NULL_RTX, VOIDmode, 0);\n-      op1 = expand_expr (arg1, NULL_RTX, VOIDmode, 0);\n-      mode0 = insn_data[icode].operand[0].mode;\n-      mode1 = insn_data[icode].operand[1].mode;\n-\n-      if (! (*insn_data[icode].operand[1].predicate) (op1, mode1))\n-\t{\n-\t  /* @@@ better error message */\n-\t  error (\"selector must be an immediate\");\n-\t  return const0_rtx;\n-\t}\n-\n-      op0 = copy_to_mode_reg (Pmode, op0);\n-      pat = GEN_FCN (icode) (op0, op1);\n-      if (! pat)\n-\treturn 0;\n-      emit_insn (pat);\n-      return target;\n-\n     case IX86_BUILTIN_SHUFPS:\n       icode = CODE_FOR_sse_shufps;\n       arg0 = TREE_VALUE (arglist);\n@@ -11914,19 +11906,6 @@ ix86_expand_builtin (exp, target, subtarget, mode, ignore)\n     case IX86_BUILTIN_PMULHRW:\n       return ix86_expand_binop_builtin (CODE_FOR_pmulhrwv4hi3, arglist, target);\n \n-    case IX86_BUILTIN_PREFETCH_3DNOW:\n-    case IX86_BUILTIN_PREFETCHW:\n-      icode = CODE_FOR_prefetch_3dnow;\n-      arg0 = TREE_VALUE (arglist);\n-      op0 = expand_expr (arg0, NULL_RTX, VOIDmode, 0);\n-      op1 = (fcode == IX86_BUILTIN_PREFETCH_3DNOW ? const0_rtx : const1_rtx);\n-      mode0 = insn_data[icode].operand[0].mode;\n-      pat = GEN_FCN (icode) (copy_to_mode_reg (Pmode, op0), op1);\n-      if (! pat)\n-        return NULL_RTX;\n-      emit_insn (pat);\n-      return NULL_RTX;\n-\n     case IX86_BUILTIN_PF2IW:\n       return ix86_expand_unop_builtin (CODE_FOR_pf2iw, arglist, target, 0);\n \n@@ -11945,57 +11924,11 @@ ix86_expand_builtin (exp, target, subtarget, mode, ignore)\n     case IX86_BUILTIN_PSWAPDSF:\n       return ix86_expand_unop_builtin (CODE_FOR_pswapdv2sf2, arglist, target, 0);\n \n-      /* Composite intrinsics.  */\n-    case IX86_BUILTIN_SETPS1:\n-      target = assign_386_stack_local (SFmode, 0);\n-      arg0 = TREE_VALUE (arglist);\n-      emit_move_insn (adjust_address (target, SFmode, 0),\n-\t\t      expand_expr (arg0, NULL_RTX, VOIDmode, 0));\n-      op0 = gen_reg_rtx (V4SFmode);\n-      emit_insn (gen_sse_loadss (op0, adjust_address (target, V4SFmode, 0)));\n-      emit_insn (gen_sse_shufps (op0, op0, op0, GEN_INT (0)));\n-      return op0;\n-\n-    case IX86_BUILTIN_SETPS:\n-      target = assign_386_stack_local (V4SFmode, 0);\n-      arg0 = TREE_VALUE (arglist);\n-      arg1 = TREE_VALUE (TREE_CHAIN (arglist));\n-      arg2 = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (arglist)));\n-      arg3 = TREE_VALUE (TREE_CHAIN (TREE_CHAIN (TREE_CHAIN (arglist))));\n-      emit_move_insn (adjust_address (target, SFmode, 0),\n-\t\t      expand_expr (arg0, NULL_RTX, VOIDmode, 0));\n-      emit_move_insn (adjust_address (target, SFmode, 4),\n-\t\t      expand_expr (arg1, NULL_RTX, VOIDmode, 0));\n-      emit_move_insn (adjust_address (target, SFmode, 8),\n-\t\t      expand_expr (arg2, NULL_RTX, VOIDmode, 0));\n-      emit_move_insn (adjust_address (target, SFmode, 12),\n-\t\t      expand_expr (arg3, NULL_RTX, VOIDmode, 0));\n-      op0 = gen_reg_rtx (V4SFmode);\n-      emit_insn (gen_sse_movaps (op0, target));\n-      return op0;\n-\n-    case IX86_BUILTIN_CLRPS:\n-      target = gen_reg_rtx (TImode);\n-      emit_insn (gen_sse_clrti (target));\n-      return target;\n-\n-    case IX86_BUILTIN_LOADRPS:\n-      target = ix86_expand_unop_builtin (CODE_FOR_sse_movaps, arglist,\n-\t\t\t\t\t gen_reg_rtx (V4SFmode), 1);\n-      emit_insn (gen_sse_shufps (target, target, target, GEN_INT (0x1b)));\n+    case IX86_BUILTIN_SSE_ZERO:\n+      target = gen_reg_rtx (V4SFmode);\n+      emit_insn (gen_sse_clrv4sf (target));\n       return target;\n \n-    case IX86_BUILTIN_LOADPS1:\n-      target = ix86_expand_unop_builtin (CODE_FOR_sse_loadss, arglist,\n-\t\t\t\t\t gen_reg_rtx (V4SFmode), 1);\n-      emit_insn (gen_sse_shufps (target, target, target, const0_rtx));\n-      return target;\n-\n-    case IX86_BUILTIN_STOREPS1:\n-      return ix86_expand_store_builtin (CODE_FOR_sse_movaps, arglist, 0);\n-    case IX86_BUILTIN_STORERPS:\n-      return ix86_expand_store_builtin (CODE_FOR_sse_movaps, arglist, 0x1B);\n-\n     case IX86_BUILTIN_MMX_ZERO:\n       target = gen_reg_rtx (DImode);\n       emit_insn (gen_mmx_clrdi (target));"}, {"sha": "8f8e208d1a4aafe2b800a50d6972c5a37331c4e0", "filename": "gcc/config/i386/i386.h", "status": "modified", "additions": 1, "deletions": 15, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e37af218eed960ea5d499158db780aa4821e02cc/gcc%2Fconfig%2Fi386%2Fi386.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e37af218eed960ea5d499158db780aa4821e02cc/gcc%2Fconfig%2Fi386%2Fi386.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.h?ref=e37af218eed960ea5d499158db780aa4821e02cc", "patch": "@@ -2089,8 +2089,6 @@ enum ix86_builtins\n   IX86_BUILTIN_CVTSS2SI,\n   IX86_BUILTIN_CVTTPS2PI,\n   IX86_BUILTIN_CVTTSS2SI,\n-  IX86_BUILTIN_M_FROM_INT,\n-  IX86_BUILTIN_M_TO_INT,\n \n   IX86_BUILTIN_MAXPS,\n   IX86_BUILTIN_MAXSS,\n@@ -2215,7 +2213,6 @@ enum ix86_builtins\n   IX86_BUILTIN_LDMXCSR,\n   IX86_BUILTIN_STMXCSR,\n   IX86_BUILTIN_SFENCE,\n-  IX86_BUILTIN_PREFETCH,\n \n   /* 3DNow! Original */\n   IX86_BUILTIN_FEMMS,\n@@ -2238,8 +2235,6 @@ enum ix86_builtins\n   IX86_BUILTIN_PFSUBR,\n   IX86_BUILTIN_PI2FD,\n   IX86_BUILTIN_PMULHRW,\n-  IX86_BUILTIN_PREFETCH_3DNOW, /* PREFETCH already used */\n-  IX86_BUILTIN_PREFETCHW,\n \n   /* 3DNow! Athlon Extensions */\n   IX86_BUILTIN_PF2IW,\n@@ -2249,16 +2244,7 @@ enum ix86_builtins\n   IX86_BUILTIN_PSWAPDSI,\n   IX86_BUILTIN_PSWAPDSF,\n \n-  /* Composite builtins, expand to more than one insn.  */\n-  IX86_BUILTIN_SETPS1,\n-  IX86_BUILTIN_SETPS,\n-  IX86_BUILTIN_CLRPS,\n-  IX86_BUILTIN_SETRPS,\n-  IX86_BUILTIN_LOADPS1,\n-  IX86_BUILTIN_LOADRPS,\n-  IX86_BUILTIN_STOREPS1,\n-  IX86_BUILTIN_STORERPS,\n-\n+  IX86_BUILTIN_SSE_ZERO,\n   IX86_BUILTIN_MMX_ZERO,\n \n   IX86_BUILTIN_MAX"}, {"sha": "c892fc183ce19517d542a8a6cfc1eadd002b65aa", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 199, "deletions": 363, "changes": 562, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e37af218eed960ea5d499158db780aa4821e02cc/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e37af218eed960ea5d499158db780aa4821e02cc/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=e37af218eed960ea5d499158db780aa4821e02cc", "patch": "@@ -81,7 +81,6 @@\n ;; 32 This is a `maskmov' operation.\n ;; 33 This is a `movmsk' operation.\n ;; 34 This is a `non-temporal' move.\n-;; 35 This is a `prefetch' (SSE) operation.\n ;; 36 This is used to distinguish COMISS from UCOMISS.\n ;; 37 This is a `ldmxcsr' operation.\n ;; 38 This is a forced `movaps' instruction (rather than whatever movti does)\n@@ -17686,44 +17685,44 @@\n \n (define_insn \"movv4sf_internal\"\n   [(set (match_operand:V4SF 0 \"nonimmediate_operand\" \"=x,m\")\n-\t(match_operand:V4SF 1 \"general_operand\" \"xm,x\"))]\n+\t(match_operand:V4SF 1 \"nonimmediate_operand\" \"xm,x\"))]\n   \"TARGET_SSE\"\n   ;; @@@ let's try to use movaps here.\n   \"movaps\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"movv4si_internal\"\n   [(set (match_operand:V4SI 0 \"nonimmediate_operand\" \"=x,m\")\n-\t(match_operand:V4SI 1 \"general_operand\" \"xm,x\"))]\n+\t(match_operand:V4SI 1 \"nonimmediate_operand\" \"xm,x\"))]\n   \"TARGET_SSE\"\n   ;; @@@ let's try to use movaps here.\n   \"movaps\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"movv8qi_internal\"\n   [(set (match_operand:V8QI 0 \"nonimmediate_operand\" \"=y,m\")\n-\t(match_operand:V8QI 1 \"general_operand\" \"ym,y\"))]\n+\t(match_operand:V8QI 1 \"nonimmediate_operand\" \"ym,y\"))]\n   \"TARGET_MMX\"\n   \"movq\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"mmx\")])\n \n (define_insn \"movv4hi_internal\"\n   [(set (match_operand:V4HI 0 \"nonimmediate_operand\" \"=y,m\")\n-\t(match_operand:V4HI 1 \"general_operand\" \"ym,y\"))]\n+\t(match_operand:V4HI 1 \"nonimmediate_operand\" \"ym,y\"))]\n   \"TARGET_MMX\"\n   \"movq\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"mmx\")])\n \n (define_insn \"movv2si_internal\"\n   [(set (match_operand:V2SI 0 \"nonimmediate_operand\" \"=y,m\")\n-\t(match_operand:V2SI 1 \"general_operand\" \"ym,y\"))]\n+\t(match_operand:V2SI 1 \"nonimmediate_operand\" \"ym,y\"))]\n   \"TARGET_MMX\"\n   \"movq\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"mmx\")])\n \n (define_insn \"movv2sf_internal\"\n   [(set (match_operand:V2SF 0 \"nonimmediate_operand\" \"=y,m\")\n-        (match_operand:V2SF 1 \"general_operand\" \"ym,y\"))]\n+        (match_operand:V2SF 1 \"nonimmediate_operand\" \"ym,y\"))]\n   \"TARGET_3DNOW\"\n   \"movq\\\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"mmx\")])\n@@ -17734,224 +17733,65 @@\n   \"TARGET_SSE || TARGET_64BIT\"\n {\n   if (TARGET_64BIT)\n-    {\n-      ix86_expand_move (TImode, operands);\n-      DONE;\n-    }\n-  /* For constants other than zero into memory.  We do not know how the\n-     instructions used to build constants modify the upper 64 bits\n-     of the register, once we have that information we may be able\n-     to handle some of them more efficiently.  */\n-  if ((reload_in_progress | reload_completed) == 0\n-      && register_operand (operands[0], TImode)\n-      && CONSTANT_P (operands[1]))\n-    {\n-      rtx addr = gen_reg_rtx (Pmode);\n-\n-      emit_move_insn (addr, XEXP (force_const_mem (TImode, operands[1]), 0));\n-      operands[1] = gen_rtx_MEM (TImode, addr);\n-    }\n-\n-  /* Make operand1 a register if it isn't already.  */\n-  if ((reload_in_progress | reload_completed) == 0\n-      && !register_operand (operands[0], TImode)\n-      && !register_operand (operands[1], TImode)\n-      && operands[1] != CONST0_RTX (TImode))\n-    {\n-      rtx temp = force_reg (TImode, operands[1]);\n-      emit_move_insn (operands[0], temp);\n-      DONE;\n-    }\n+    ix86_expand_move (TImode, operands);\n+  else\n+    ix86_expand_vector_move (TImode, operands);\n+  DONE;\n })\n \n (define_expand \"movv4sf\"\n   [(set (match_operand:V4SF 0 \"general_operand\" \"\")\n \t(match_operand:V4SF 1 \"general_operand\" \"\"))]\n   \"TARGET_SSE\"\n {\n-  /* For constants other than zero into memory.  We do not know how the\n-     instructions used to build constants modify the upper 64 bits\n-     of the register, once we have that information we may be able\n-     to handle some of them more efficiently.  */\n-  if ((reload_in_progress | reload_completed) == 0\n-      && register_operand (operands[0], V4SFmode)\n-      && CONSTANT_P (operands[1]))\n-    {\n-      rtx addr = gen_reg_rtx (Pmode);\n-\n-      emit_move_insn (addr, XEXP (force_const_mem (V4SFmode, operands[1]), 0));\n-      operands[1] = gen_rtx_MEM (V4SFmode, addr);\n-    }\n-\n-  /* Make operand1 a register if it isn't already.  */\n-  if ((reload_in_progress | reload_completed) == 0\n-      && !register_operand (operands[0], V4SFmode)\n-      && !register_operand (operands[1], V4SFmode)\n-      && operands[1] != CONST0_RTX (V4SFmode))\n-    {\n-      rtx temp = force_reg (V4SFmode, operands[1]);\n-      emit_move_insn (operands[0], temp);\n-      DONE;\n-    }\n+  ix86_expand_vector_move (V4SFmode, operands);\n+  DONE;\n })\n \n (define_expand \"movv4si\"\n   [(set (match_operand:V4SI 0 \"general_operand\" \"\")\n \t(match_operand:V4SI 1 \"general_operand\" \"\"))]\n   \"TARGET_MMX\"\n {\n-  /* For constants other than zero into memory.  We do not know how the\n-     instructions used to build constants modify the upper 64 bits\n-     of the register, once we have that information we may be able\n-     to handle some of them more efficiently.  */\n-  if ((reload_in_progress | reload_completed) == 0\n-      && register_operand (operands[0], V4SImode)\n-      && CONSTANT_P (operands[1]))\n-    {\n-      rtx addr = gen_reg_rtx (Pmode);\n-\n-      emit_move_insn (addr, XEXP (force_const_mem (V4SImode, operands[1]), 0));\n-      operands[1] = gen_rtx_MEM (V4SImode, addr);\n-    }\n-\n-  /* Make operand1 a register if it isn't already.  */\n-  if ((reload_in_progress | reload_completed) == 0\n-      && !register_operand (operands[0], V4SImode)\n-      && !register_operand (operands[1], V4SImode)\n-      && operands[1] != CONST0_RTX (V4SImode))\n-    {\n-      rtx temp = force_reg (V4SImode, operands[1]);\n-      emit_move_insn (operands[0], temp);\n-      DONE;\n-    }\n+  ix86_expand_vector_move (V4SImode, operands);\n+  DONE;\n })\n \n (define_expand \"movv2si\"\n   [(set (match_operand:V2SI 0 \"general_operand\" \"\")\n \t(match_operand:V2SI 1 \"general_operand\" \"\"))]\n   \"TARGET_MMX\"\n {\n-  /* For constants other than zero into memory.  We do not know how the\n-     instructions used to build constants modify the upper 64 bits\n-     of the register, once we have that information we may be able\n-     to handle some of them more efficiently.  */\n-  if ((reload_in_progress | reload_completed) == 0\n-      && register_operand (operands[0], V2SImode)\n-      && CONSTANT_P (operands[1]))\n-    {\n-      rtx addr = gen_reg_rtx (Pmode);\n-\n-      emit_move_insn (addr, XEXP (force_const_mem (V2SImode, operands[1]), 0));\n-      operands[1] = gen_rtx_MEM (V2SImode, addr);\n-    }\n-\n-  /* Make operand1 a register if it isn't already.  */\n-  if ((reload_in_progress | reload_completed) == 0\n-      && !register_operand (operands[0], V2SImode)\n-      && !register_operand (operands[1], V2SImode)\n-      && operands[1] != CONST0_RTX (V2SImode))\n-    {\n-      rtx temp = force_reg (V2SImode, operands[1]);\n-      emit_move_insn (operands[0], temp);\n-      DONE;\n-    }\n+  ix86_expand_vector_move (V2SImode, operands);\n+  DONE;\n })\n \n (define_expand \"movv4hi\"\n   [(set (match_operand:V4HI 0 \"general_operand\" \"\")\n \t(match_operand:V4HI 1 \"general_operand\" \"\"))]\n   \"TARGET_MMX\"\n {\n-  /* For constants other than zero into memory.  We do not know how the\n-     instructions used to build constants modify the upper 64 bits\n-     of the register, once we have that information we may be able\n-     to handle some of them more efficiently.  */\n-  if ((reload_in_progress | reload_completed) == 0\n-      && register_operand (operands[0], V4HImode)\n-      && CONSTANT_P (operands[1]))\n-    {\n-      rtx addr = gen_reg_rtx (Pmode);\n-\n-      emit_move_insn (addr, XEXP (force_const_mem (V4HImode, operands[1]), 0));\n-      operands[1] = gen_rtx_MEM (V4HImode, addr);\n-    }\n-\n-  /* Make operand1 a register if it isn't already.  */\n-  if ((reload_in_progress | reload_completed) == 0\n-      && !register_operand (operands[0], V4HImode)\n-      && !register_operand (operands[1], V4HImode)\n-      && operands[1] != CONST0_RTX (V4HImode))\n-    {\n-      rtx temp = force_reg (V4HImode, operands[1]);\n-      emit_move_insn (operands[0], temp);\n-      DONE;\n-    }\n+  ix86_expand_vector_move (V4HImode, operands);\n+  DONE;\n })\n \n (define_expand \"movv8qi\"\n   [(set (match_operand:V8QI 0 \"general_operand\" \"\")\n \t(match_operand:V8QI 1 \"general_operand\" \"\"))]\n   \"TARGET_MMX\"\n {\n-  /* For constants other than zero into memory.  We do not know how the\n-     instructions used to build constants modify the upper 64 bits\n-     of the register, once we have that information we may be able\n-     to handle some of them more efficiently.  */\n-  if ((reload_in_progress | reload_completed) == 0\n-      && register_operand (operands[0], V8QImode)\n-      && CONSTANT_P (operands[1]))\n-    {\n-      rtx addr = gen_reg_rtx (Pmode);\n-\n-      emit_move_insn (addr, XEXP (force_const_mem (V8QImode, operands[1]), 0));\n-      operands[1] = gen_rtx_MEM (V8QImode, addr);\n-    }\n-\n-  /* Make operand1 a register if it isn't already.  */\n-  if ((reload_in_progress | reload_completed) == 0\n-      && !register_operand (operands[0], V8QImode)\n-      && !register_operand (operands[1], V8QImode)\n-      && operands[1] != CONST0_RTX (V8QImode))\n-    {\n-      rtx temp = force_reg (V8QImode, operands[1]);\n-      emit_move_insn (operands[0], temp);\n-      DONE;\n-    }\n+  ix86_expand_vector_move (V8QImode, operands);\n+  DONE;\n })\n \n (define_expand \"movv2sf\"\n   [(set (match_operand:V2SF 0 \"general_operand\" \"\")\n \t(match_operand:V2SF 1 \"general_operand\" \"\"))]\n    \"TARGET_3DNOW\"\n-   \"\n {\n-  /* For constants other than zero into memory.  We do not know how the\n-     instructions used to build constants modify the upper 64 bits\n-     of the register, once we have that information we may be able\n-     to handle some of them more efficiently.  */\n-  if ((reload_in_progress | reload_completed) == 0\n-      && register_operand (operands[0], V2SFmode)\n-      && CONSTANT_P (operands[1]))\n-    {\n-      rtx addr = gen_reg_rtx (Pmode);\n-\n-      emit_move_insn (addr,\n-\t\t      XEXP (force_const_mem (V2SFmode, operands[1]), 0));\n-      operands[1] = gen_rtx_MEM (V2SFmode, addr);\n-   }\n-\n-  /* Make operand1 a register is it isn't already.  */\n-  if ((reload_in_progress | reload_completed) == 0\n-      && !register_operand (operands[0], V2SFmode)\n-      && !register_operand (operands[1], V2SFmode)\n-      && (GET_CODE (operands[1]) != CONST_INT || INTVAL (operands[1]) != 0)\n-      && operands[1] != CONST0_RTX (V2SFmode))\n-   {\n-      rtx temp = force_reg (V2SFmode, operands[1]);\n-      emit_move_insn (operands[0], temp);\n-      DONE;\n-    }\n-}\")\n+  ix86_expand_vector_move (V2SFmode, operands);\n+  DONE;\n+})\n \n (define_insn_and_split \"*pushti\"\n   [(set (match_operand:TI 0 \"push_operand\" \"=<\")\n@@ -18031,25 +17871,27 @@\n   [(set_attr \"type\" \"mmx\")])\n \n (define_insn \"movti_internal\"\n-  [(set (match_operand:TI 0 \"nonimmediate_operand\" \"=x,m\")\n-\t(match_operand:TI 1 \"general_operand\" \"xm,x\"))]\n+  [(set (match_operand:TI 0 \"nonimmediate_operand\" \"=x,x,m\")\n+\t(match_operand:TI 1 \"general_operand\" \"O,xm,x\"))]\n   \"TARGET_SSE && !TARGET_64BIT\"\n   \"@\n+   xorps\\t%0, %0\n    movaps\\t{%1, %0|%0, %1}\n    movaps\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"*movti_rex64\"\n-  [(set (match_operand:TI 0 \"nonimmediate_operand\" \"=r,o,mx,x\")\n-\t(match_operand:TI 1 \"general_operand\" \"riFo,riF,x,m\"))]\n+  [(set (match_operand:TI 0 \"nonimmediate_operand\" \"=r,o,x,mx,x\")\n+\t(match_operand:TI 1 \"general_operand\" \"riFo,riF,O,x,m\"))]\n   \"TARGET_64BIT\n    && (GET_CODE (operands[0]) != MEM || GET_CODE (operands[1]) != MEM)\"\n   \"@\n    #\n    #\n+   xorps\\t%0, %0\n    movaps\\\\t{%1, %0|%0, %1}\n    movaps\\\\t{%1, %0|%0, %1}\"\n-  [(set_attr \"type\" \"*,*,sse,sse\")\n+  [(set_attr \"type\" \"*,*,sse,sse,sse\")\n    (set_attr \"mode\" \"TI\")])\n \n (define_split\n@@ -18064,7 +17906,8 @@\n ;; movaps or movups\n (define_insn \"sse_movaps\"\n   [(set (match_operand:V4SF 0 \"nonimmediate_operand\" \"=x,m\")\n-\t(unspec:V4SF [(match_operand:V4SF 1 \"general_operand\" \"xm,x\")] 38))]\n+\t(unspec:V4SF\n+\t [(match_operand:V4SF 1 \"nonimmediate_operand\" \"xm,x\")] 38))]\n   \"TARGET_SSE\"\n   \"@\n    movaps\\t{%1, %0|%0, %1}\n@@ -18073,7 +17916,8 @@\n \n (define_insn \"sse_movups\"\n   [(set (match_operand:V4SF 0 \"nonimmediate_operand\" \"=x,m\")\n-\t(unspec:V4SF [(match_operand:V4SF 1 \"general_operand\" \"xm,x\")] 39))]\n+\t(unspec:V4SF\n+\t [(match_operand:V4SF 1 \"nonimmediate_operand\" \"xm,x\")] 39))]\n   \"TARGET_SSE\"\n   \"@\n    movups\\t{%1, %0|%0, %1}\n@@ -18154,7 +17998,8 @@\n \t (match_operand:V4SF 1 \"nonimmediate_operand\" \"0,0\")\n \t (match_operand:V4SF 2 \"nonimmediate_operand\" \"m,x\")\n \t (const_int 12)))]\n-  \"TARGET_SSE && (GET_CODE (operands[1]) == MEM || GET_CODE (operands[2]) == MEM)\"\n+  \"TARGET_SSE\n+   && (GET_CODE (operands[1]) == MEM || GET_CODE (operands[2]) == MEM)\"\n   \"movhps\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sse\")])\n \n@@ -18164,7 +18009,8 @@\n \t (match_operand:V4SF 1 \"nonimmediate_operand\" \"0,0\")\n \t (match_operand:V4SF 2 \"nonimmediate_operand\" \"m,x\")\n \t (const_int 3)))]\n-  \"TARGET_SSE && (GET_CODE (operands[1]) == MEM || GET_CODE (operands[2]) == MEM)\"\n+  \"TARGET_SSE\n+   && (GET_CODE (operands[1]) == MEM || GET_CODE (operands[2]) == MEM)\"\n   \"movlps\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sse\")])\n \n@@ -18220,28 +18066,30 @@\n \n (define_insn \"vmaddv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n-\t(vec_merge:V4SF (plus:V4SF (match_operand:V4SF 1 \"register_operand\" \"0\")\n-\t                           (match_operand:V4SF 2 \"nonimmediate_operand\" \"xm\"))\n-                        (match_dup 1)\n-\t\t\t(const_int 1)))]\n+\t(vec_merge:V4SF\n+\t (plus:V4SF (match_operand:V4SF 1 \"register_operand\" \"0\")\n+\t\t    (match_operand:V4SF 2 \"nonimmediate_operand\" \"xm\"))\n+\t (match_dup 1)\n+\t (const_int 1)))]\n   \"TARGET_SSE\"\n   \"addss\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"subv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n         (minus:V4SF (match_operand:V4SF 1 \"register_operand\" \"0\")\n-\t           (match_operand:V4SF 2 \"nonimmediate_operand\" \"xm\")))]\n+\t\t    (match_operand:V4SF 2 \"nonimmediate_operand\" \"xm\")))]\n   \"TARGET_SSE\"\n   \"subps\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"vmsubv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n-\t(vec_merge:V4SF (minus:V4SF (match_operand:V4SF 1 \"register_operand\" \"0\")\n-\t                           (match_operand:V4SF 2 \"nonimmediate_operand\" \"xm\"))\n-                        (match_dup 1)\n-\t\t\t(const_int 1)))]\n+\t(vec_merge:V4SF\n+\t (minus:V4SF (match_operand:V4SF 1 \"register_operand\" \"0\")\n+\t\t     (match_operand:V4SF 2 \"nonimmediate_operand\" \"xm\"))\n+\t (match_dup 1)\n+\t (const_int 1)))]\n   \"TARGET_SSE\"\n   \"subss\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sse\")])\n@@ -18256,10 +18104,11 @@\n \n (define_insn \"vmmulv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n-\t(vec_merge:V4SF (mult:V4SF (match_operand:V4SF 1 \"register_operand\" \"0\")\n-\t                           (match_operand:V4SF 2 \"nonimmediate_operand\" \"xm\"))\n-                        (match_dup 1)\n-\t\t\t(const_int 1)))]\n+\t(vec_merge:V4SF\n+\t (mult:V4SF (match_operand:V4SF 1 \"register_operand\" \"0\")\n+\t\t    (match_operand:V4SF 2 \"nonimmediate_operand\" \"xm\"))\n+\t (match_dup 1)\n+\t (const_int 1)))]\n   \"TARGET_SSE\"\n   \"mulss\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sse\")])\n@@ -18274,10 +18123,11 @@\n \n (define_insn \"vmdivv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n-\t(vec_merge:V4SF (div:V4SF (match_operand:V4SF 1 \"register_operand\" \"0\")\n-\t\t\t\t  (match_operand:V4SF 2 \"nonimmediate_operand\" \"xm\"))\n-                        (match_dup 1)\n-\t\t\t(const_int 1)))]\n+\t(vec_merge:V4SF\n+\t (div:V4SF (match_operand:V4SF 1 \"register_operand\" \"0\")\n+\t\t   (match_operand:V4SF 2 \"nonimmediate_operand\" \"xm\"))\n+\t (match_dup 1)\n+\t (const_int 1)))]\n   \"TARGET_SSE\"\n   \"divss\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sse\")])\n@@ -18287,53 +18137,57 @@\n \n (define_insn \"rcpv4sf2\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n-        (unspec:V4SF [(match_operand:V4SF 1 \"register_operand\" \"xm\")] 42))]\n+        (unspec:V4SF\n+\t [(match_operand:V4SF 1 \"nonimmediate_operand\" \"xm\")] 42))]\n   \"TARGET_SSE\"\n   \"rcpps\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"vmrcpv4sf2\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n-\t(vec_merge:V4SF (unspec:V4SF [(match_operand:V4SF 1 \"register_operand\" \"xm\")] 42)\n-                        (match_operand:V4SF 2 \"register_operand\" \"0\")\n-\t\t\t(const_int 1)))]\n+\t(vec_merge:V4SF\n+\t (unspec:V4SF [(match_operand:V4SF 1 \"nonimmediate_operand\" \"xm\")] 42)\n+\t (match_operand:V4SF 2 \"register_operand\" \"0\")\n+\t (const_int 1)))]\n   \"TARGET_SSE\"\n   \"rcpss\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"rsqrtv4sf2\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n-        (unspec:V4SF [(match_operand:V4SF 1 \"register_operand\" \"xm\")] 43))]\n+        (unspec:V4SF\n+\t [(match_operand:V4SF 1 \"nonimmediate_operand\" \"xm\")] 43))]\n   \"TARGET_SSE\"\n   \"rsqrtps\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"vmrsqrtv4sf2\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n-\t(vec_merge:V4SF (unspec:V4SF [(match_operand:V4SF 1 \"register_operand\" \"xm\")] 43)\n-                        (match_operand:V4SF 2 \"register_operand\" \"0\")\n-\t\t\t(const_int 1)))]\n+\t(vec_merge:V4SF\n+\t (unspec:V4SF [(match_operand:V4SF 1 \"nonimmediate_operand\" \"xm\")] 43)\n+\t (match_operand:V4SF 2 \"register_operand\" \"0\")\n+\t (const_int 1)))]\n   \"TARGET_SSE\"\n   \"rsqrtss\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"sqrtv4sf2\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n-        (sqrt:V4SF (match_operand:V4SF 1 \"register_operand\" \"xm\")))]\n+        (sqrt:V4SF (match_operand:V4SF 1 \"nonimmediate_operand\" \"xm\")))]\n   \"TARGET_SSE\"\n   \"sqrtps\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"vmsqrtv4sf2\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n-\t(vec_merge:V4SF (sqrt:V4SF (match_operand:V4SF 1 \"register_operand\" \"xm\"))\n-                        (match_operand:V4SF 2 \"register_operand\" \"0\")\n-\t\t\t(const_int 1)))]\n+\t(vec_merge:V4SF\n+\t (sqrt:V4SF (match_operand:V4SF 1 \"nonimmediate_operand\" \"xm\"))\n+\t (match_operand:V4SF 2 \"register_operand\" \"0\")\n+\t (const_int 1)))]\n   \"TARGET_SSE\"\n   \"sqrtss\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"sse\")])\n \n-\n ;; SSE logical operations.\n \n ;; These are not called andti3 etc. because we really really don't want\n@@ -18519,9 +18373,9 @@\n \n ;; Use xor, but don't show input operands so they aren't live before\n ;; this insn.\n-(define_insn \"sse_clrti\"\n-  [(set (match_operand:TI 0 \"register_operand\" \"=x\")\n-        (unspec:TI [(const_int 0)] 45))]\n+(define_insn \"sse_clrv4sf\"\n+  [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n+        (unspec:V4SF [(const_int 0)] 45))]\n   \"TARGET_SSE\"\n   \"xorps\\t{%0, %0|%0, %0}\"\n   [(set_attr \"type\" \"sse\")\n@@ -18532,8 +18386,8 @@\n (define_insn \"maskcmpv4sf3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=x\")\n         (match_operator:V4SI 3 \"sse_comparison_operator\"\n-\t\t\t     [(match_operand:V4SF 1 \"register_operand\" \"0\")\n-\t\t\t      (match_operand:V4SF 2 \"nonimmediate_operand\" \"x\")]))]\n+\t\t[(match_operand:V4SF 1 \"register_operand\" \"0\")\n+\t\t (match_operand:V4SF 2 \"register_operand\" \"x\")]))]\n   \"TARGET_SSE\"\n   \"cmp%D3ps\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sse\")])\n@@ -18542,24 +18396,23 @@\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=x\")\n         (not:V4SI\n \t (match_operator:V4SI 3 \"sse_comparison_operator\"\n-\t\t\t      [(match_operand:V4SF 1 \"register_operand\" \"0\")\n-\t\t\t       (match_operand:V4SF 2 \"nonimmediate_operand\" \"x\")])))]\n+\t\t[(match_operand:V4SF 1 \"register_operand\" \"0\")\n+\t\t (match_operand:V4SF 2 \"register_operand\" \"x\")])))]\n   \"TARGET_SSE\"\n-  \"*\n {\n   if (GET_CODE (operands[3]) == UNORDERED)\n-    return \\\"cmpordps\\t{%2, %0|%0, %2}\\\";\n-\n-  return \\\"cmpn%D3ps\\t{%2, %0|%0, %2}\\\";\n-}\"\n+    return \"cmpordps\\t{%2, %0|%0, %2}\";\n+  else\n+    return \"cmpn%D3ps\\t{%2, %0|%0, %2}\";\n+}\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"vmmaskcmpv4sf3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=x\")\n \t(vec_merge:V4SI\n \t (match_operator:V4SI 3 \"sse_comparison_operator\"\n-\t\t\t      [(match_operand:V4SF 1 \"register_operand\" \"0\")\n-\t\t\t       (match_operand:V4SF 2 \"nonimmediate_operand\" \"x\")])\n+\t\t[(match_operand:V4SF 1 \"register_operand\" \"0\")\n+\t\t (match_operand:V4SF 2 \"register_operand\" \"x\")])\n \t (match_dup 1)\n \t (const_int 1)))]\n   \"TARGET_SSE\"\n@@ -18571,18 +18424,17 @@\n \t(vec_merge:V4SI\n \t (not:V4SI\n \t  (match_operator:V4SI 3 \"sse_comparison_operator\"\n-\t\t\t       [(match_operand:V4SF 1 \"register_operand\" \"0\")\n-\t\t\t\t(match_operand:V4SF 2 \"nonimmediate_operand\" \"x\")]))\n+\t\t[(match_operand:V4SF 1 \"register_operand\" \"0\")\n+\t\t (match_operand:V4SF 2 \"register_operand\" \"x\")]))\n \t (subreg:V4SI (match_dup 1) 0)\n \t (const_int 1)))]\n   \"TARGET_SSE\"\n-  \"*\n {\n   if (GET_CODE (operands[3]) == UNORDERED)\n-    return \\\"cmpordss\\t{%2, %0|%0, %2}\\\";\n-\n-  return \\\"cmpn%D3ss\\t{%2, %0|%0, %2}\\\";\n-}\"\n+    return \"cmpordss\\t{%2, %0|%0, %2}\";\n+  else\n+    return \"cmpn%D3ss\\t{%2, %0|%0, %2}\";\n+}\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"sse_comi\"\n@@ -18663,10 +18515,11 @@\n \n (define_insn \"vmsmaxv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n-\t(vec_merge:V4SF (smax:V4SF (match_operand:V4SF 1 \"register_operand\" \"0\")\n-\t                           (match_operand:V4SF 2 \"nonimmediate_operand\" \"xm\"))\n-                        (match_dup 1)\n-\t\t\t(const_int 1)))]\n+\t(vec_merge:V4SF\n+\t (smax:V4SF (match_operand:V4SF 1 \"register_operand\" \"0\")\n+\t\t    (match_operand:V4SF 2 \"nonimmediate_operand\" \"xm\"))\n+\t (match_dup 1)\n+\t (const_int 1)))]\n   \"TARGET_SSE\"\n   \"maxss\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sse\")])\n@@ -18681,10 +18534,11 @@\n \n (define_insn \"vmsminv4sf3\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n-\t(vec_merge:V4SF (smin:V4SF (match_operand:V4SF 1 \"register_operand\" \"0\")\n-\t                           (match_operand:V4SF 2 \"nonimmediate_operand\" \"xm\"))\n-                        (match_dup 1)\n-\t\t\t(const_int 1)))]\n+\t(vec_merge:V4SF\n+\t (smin:V4SF (match_operand:V4SF 1 \"register_operand\" \"0\")\n+\t\t    (match_operand:V4SF 2 \"nonimmediate_operand\" \"xm\"))\n+\t (match_dup 1)\n+\t (const_int 1)))]\n   \"TARGET_SSE\"\n   \"minss\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sse\")])\n@@ -18694,56 +18548,58 @@\n \n (define_insn \"cvtpi2ps\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n-\t(vec_merge:V4SF (match_operand:V4SF 1 \"register_operand\" \"0\")\n-\t\t\t(vec_duplicate:V4SF\n-\t\t\t (float:V2SF (match_operand:V2SI 2 \"register_operand\" \"ym\")))\n-\t\t\t(const_int 12)))]\n+\t(vec_merge:V4SF\n+\t (match_operand:V4SF 1 \"register_operand\" \"0\")\n+\t (vec_duplicate:V4SF\n+\t  (float:V2SF (match_operand:V2SI 2 \"nonimmediate_operand\" \"ym\")))\n+\t (const_int 12)))]\n   \"TARGET_SSE\"\n   \"cvtpi2ps\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"cvtps2pi\"\n   [(set (match_operand:V2SI 0 \"register_operand\" \"=y\")\n-\t(vec_select:V2SI (fix:V4SI (match_operand:V4SF 1 \"register_operand\" \"xm\"))\n-\t\t\t (parallel\n-\t\t\t  [(const_int 0)\n-\t\t\t   (const_int 1)])))]\n+\t(vec_select:V2SI\n+\t (fix:V4SI (match_operand:V4SF 1 \"nonimmediate_operand\" \"xm\"))\n+\t (parallel [(const_int 0) (const_int 1)])))]\n   \"TARGET_SSE\"\n   \"cvtps2pi\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"cvttps2pi\"\n   [(set (match_operand:V2SI 0 \"register_operand\" \"=y\")\n-\t(vec_select:V2SI (unspec:V4SI [(match_operand:V4SF 1 \"register_operand\" \"xm\")] 30)\n-\t\t\t (parallel\n-\t\t\t  [(const_int 0)\n-\t\t\t   (const_int 1)])))]\n+\t(vec_select:V2SI\n+\t (unspec:V4SI [(match_operand:V4SF 1 \"nonimmediate_operand\" \"xm\")] 30)\n+\t (parallel [(const_int 0) (const_int 1)])))]\n   \"TARGET_SSE\"\n   \"cvttps2pi\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"cvtsi2ss\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n-\t(vec_merge:V4SF (match_operand:V4SF 1 \"register_operand\" \"0\")\n-\t \t\t(vec_duplicate:V4SF\n-\t\t\t (float:SF (match_operand:SI 2 \"register_operand\" \"rm\")))\n-\t\t\t(const_int 14)))]\n+\t(vec_merge:V4SF\n+\t (match_operand:V4SF 1 \"register_operand\" \"0\")\n+\t (vec_duplicate:V4SF\n+\t  (float:SF (match_operand:SI 2 \"nonimmediate_operand\" \"rm\")))\n+\t (const_int 14)))]\n   \"TARGET_SSE\"\n   \"cvtsi2ss\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"cvtss2si\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n-\t(vec_select:SI (fix:V4SI (match_operand:V4SF 1 \"register_operand\" \"xm\"))\n-\t\t       (parallel [(const_int 0)])))]\n+\t(vec_select:SI\n+\t (fix:V4SI (match_operand:V4SF 1 \"nonimmediate_operand\" \"xm\"))\n+\t (parallel [(const_int 0)])))]\n   \"TARGET_SSE\"\n   \"cvtss2si\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"sse\")])\n \n (define_insn \"cvttss2si\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n-\t(vec_select:SI (unspec:V4SI [(match_operand:V4SF 1 \"register_operand\" \"xm\")] 30)\n-\t\t       (parallel [(const_int 0)])))]\n+\t(vec_select:SI\n+\t (unspec:V4SI [(match_operand:V4SF 1 \"nonimmediate_operand\" \"xm\")] 30)\n+\t (parallel [(const_int 0)])))]\n   \"TARGET_SSE\"\n   \"cvttss2si\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"sse\")])\n@@ -18877,8 +18733,10 @@\n   [(set (match_operand:V4HI 0 \"register_operand\" \"=y\")\n \t(truncate:V4HI\n \t (lshiftrt:V4SI\n-\t  (mult:V4SI (sign_extend:V4SI (match_operand:V4HI 1 \"register_operand\" \"0\"))\n-\t\t     (sign_extend:V4SI (match_operand:V4HI 2 \"nonimmediate_operand\" \"ym\")))\n+\t  (mult:V4SI (sign_extend:V4SI\n+\t\t      (match_operand:V4HI 1 \"register_operand\" \"0\"))\n+\t\t     (sign_extend:V4SI\n+\t\t      (match_operand:V4HI 2 \"nonimmediate_operand\" \"ym\")))\n \t  (const_int 16))))]\n   \"TARGET_MMX\"\n   \"pmulhw\\t{%2, %0|%0, %2}\"\n@@ -18888,8 +18746,10 @@\n   [(set (match_operand:V4HI 0 \"register_operand\" \"=y\")\n \t(truncate:V4HI\n \t (lshiftrt:V4SI\n-\t  (mult:V4SI (zero_extend:V4SI (match_operand:V4HI 1 \"register_operand\" \"0\"))\n-\t\t     (zero_extend:V4SI (match_operand:V4HI 2 \"nonimmediate_operand\" \"ym\")))\n+\t  (mult:V4SI (zero_extend:V4SI\n+\t\t      (match_operand:V4HI 1 \"register_operand\" \"0\"))\n+\t\t     (zero_extend:V4SI\n+\t\t      (match_operand:V4HI 2 \"nonimmediate_operand\" \"ym\")))\n \t  (const_int 16))))]\n   \"TARGET_SSE || TARGET_3DNOW_A\"\n   \"pmulhuw\\t{%2, %0|%0, %2}\"\n@@ -18899,12 +18759,12 @@\n   [(set (match_operand:V2SI 0 \"register_operand\" \"=y\")\n         (plus:V2SI\n \t (mult:V2SI\n-\t  (sign_extend:V2SI (vec_select:V2HI (match_operand:V4HI 1 \"register_operand\" \"0\")\n-\t\t\t\t\t     (parallel [(const_int 0)\n-\t\t\t\t\t\t\t(const_int 2)])))\n-\t  (sign_extend:V2SI (vec_select:V2HI (match_operand:V4HI 2 \"nonimmediate_operand\" \"ym\")\n-\t\t\t\t\t     (parallel [(const_int 0)\n-\t\t\t\t\t\t\t(const_int 2)]))))\n+\t  (sign_extend:V2SI\n+\t   (vec_select:V2HI (match_operand:V4HI 1 \"register_operand\" \"0\")\n+\t\t\t    (parallel [(const_int 0) (const_int 2)])))\n+\t  (sign_extend:V2SI\n+\t   (vec_select:V2HI (match_operand:V4HI 2 \"nonimmediate_operand\" \"ym\")\n+\t\t\t    (parallel [(const_int 0) (const_int 2)]))))\n \t (mult:V2SI\n \t  (sign_extend:V2SI (vec_select:V2HI (match_dup 1)\n \t\t\t\t\t     (parallel [(const_int 1)\n@@ -19404,75 +19264,6 @@\n   [(set_attr \"type\" \"sse\")\n    (set_attr \"memory\" \"unknown\")])\n \n-(define_expand \"prefetch\"\n-  [(prefetch (match_operand:SI 0 \"address_operand\" \"p\")\n-\t     (match_operand:SI 1 \"const_int_operand\" \"n\")\n-\t     (match_operand:SI 2 \"const_int_operand\" \"n\"))]\n-  \"TARGET_PREFETCH_SSE || TARGET_3DNOW\"\n-  \"\n-{\n-  int rw = INTVAL (operands[1]);\n-  int locality = INTVAL (operands[2]);\n-  if (rw != 0 && rw != 1)\n-    abort ();\n-  if (locality < 0 || locality > 3)\n-    abort ();\n-  /* Use 3dNOW prefetch in case we are asking for write prefetch not\n-     suported by SSE counterpart or the SSE prefetch is not available\n-     (K6 machines).  Otherwise use SSE prefetch as it allows specifying\n-     of locality.  */\n-  if (TARGET_3DNOW\n-       && (!TARGET_PREFETCH_SSE || rw))\n-    {\n-      emit_insn (gen_prefetch_3dnow (operands[0], operands[1]));\n-    }\n-  else\n-    {\n-      int i;\n-      switch (locality)\n-\t{\n-\t  case 0:\t/* No temporal locality.  */\n-\t    i = 0;\n-\t    break;\n-\t  case 1:\t/* Lowest level of temporal locality.  */\n-\t    i = 3;\n-\t    break;\n-\t  case 2:\t/* Moderate level of temporal locality.  */\n-\t    i = 2;\n-\t    break;\n-\t  case 3:\t/* Highest level of temporal locality.  */\n-\t    i = 1;\n-\t    break;\n-\t  default:\n-\t    abort ();\t/* We already checked for valid values above.  */\n-\t    break;\n-\t}\n-      emit_insn (gen_prefetch_sse (operands[0], GEN_INT (i)));\n-    }\n-  DONE;\n-}\")\n-\n-(define_insn \"prefetch_sse\"\n-  [(unspec [(match_operand:SI 0 \"address_operand\" \"p\")\n-\t    (match_operand:SI 1 \"immediate_operand\" \"n\")] 35)]\n-  \"TARGET_PREFETCH_SSE\"\n-{\n-  switch (INTVAL (operands[1]))\n-    {\n-    case 0:\n-      return \"prefetchnta\\t%a0\";\n-    case 1:\n-      return \"prefetcht0\\t%a0\";\n-    case 2:\n-      return \"prefetcht1\\t%a0\";\n-    case 3:\n-      return \"prefetcht2\\t%a0\";\n-    default:\n-      abort ();\n-    }\n-}\n-  [(set_attr \"type\" \"sse\")])\n-\n (define_expand \"sse_prologue_save\"\n   [(parallel [(set (match_operand:BLK 0 \"\" \"\")\n \t\t   (unspec:BLK [(reg:DI 21)\n@@ -19630,19 +19421,6 @@\n   \"femms\"\n   [(set_attr \"type\" \"mmx\")])\n \n-(define_insn \"prefetch_3dnow\"\n-  [(prefetch (match_operand:SI 0 \"address_operand\" \"p\")\n-\t     (match_operand:SI 1 \"const_int_operand\" \"n\")\n-\t     (const_int 0))]\n-  \"TARGET_3DNOW\"\n-{\n-  if (INTVAL (operands[1]) == 0)\n-    return \"prefetch\\t%a0\";\n-  else\n-    return \"prefetchw\\t%a0\";\n-}\n-  [(set_attr \"type\" \"mmx\")])\n-\n (define_insn \"pf2id\"\n   [(set (match_operand:V2SI 0 \"register_operand\" \"=y\")\n \t(fix:V2SI (match_operand:V2SF 1 \"nonimmediate_operand\" \"ym\")))]\n@@ -19820,3 +19598,61 @@\n   \"TARGET_3DNOW_A\"\n   \"pswapd\\\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"mmx\")])\n+\n+(define_expand \"prefetch\"\n+  [(prefetch (match_operand:SI 0 \"address_operand\" \"\")\n+\t     (match_operand:SI 1 \"const_int_operand\" \"\")\n+\t     (match_operand:SI 2 \"const_int_operand\" \"\"))]\n+  \"TARGET_PREFETCH_SSE || TARGET_3DNOW\"\n+{\n+  int rw = INTVAL (operands[1]);\n+  int locality = INTVAL (operands[2]);\n+  if (rw != 0 && rw != 1)\n+    abort ();\n+  if (locality < 0 || locality > 3)\n+    abort ();\n+\n+  /* Use 3dNOW prefetch in case we are asking for write prefetch not\n+     suported by SSE counterpart or the SSE prefetch is not available\n+     (K6 machines).  Otherwise use SSE prefetch as it allows specifying\n+     of locality.  */\n+  if (TARGET_3DNOW && (!TARGET_PREFETCH_SSE || rw))\n+    {\n+      operands[2] = GEN_INT (3);\n+    }\n+  else\n+    {\n+      operands[1] = const0_rtx;\n+    }\n+})\n+\n+(define_insn \"*prefetch_sse\"\n+  [(prefetch (match_operand:SI 0 \"address_operand\" \"\")\n+\t     (const_int 0)\n+\t     (match_operand:SI 1 \"const_int_operand\" \"\"))]\n+  \"TARGET_PREFETCH_SSE\"\n+{\n+  static const char * const patterns[4] = {\n+   \"prefetchnta\\t%a0\", \"prefetcht2\\t%a0\", \"prefetcht1\\t%a0\", \"prefetcht0\\t%a0\"\n+  };\n+\n+  int locality = INTVAL (operands[1]);\n+  if (locality < 0 || locality > 3)\n+    abort ();\n+\n+  return patterns[locality];  \n+}\n+  [(set_attr \"type\" \"sse\")])\n+\n+(define_insn \"*prefetch_3dnow\"\n+  [(prefetch (match_operand:SI 0 \"address_operand\" \"p\")\n+\t     (match_operand:SI 1 \"const_int_operand\" \"n\")\n+\t     (const_int 0))]\n+  \"TARGET_3DNOW\"\n+{\n+  if (INTVAL (operands[1]) == 0)\n+    return \"prefetch\\t%a0\";\n+  else\n+    return \"prefetchw\\t%a0\";\n+}\n+  [(set_attr \"type\" \"mmx\")])"}, {"sha": "9f9f2f993933fc52bf23c9a32c6519a11b0c2858", "filename": "gcc/config/i386/xmmintrin.h", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e37af218eed960ea5d499158db780aa4821e02cc/gcc%2Fconfig%2Fi386%2Fxmmintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e37af218eed960ea5d499158db780aa4821e02cc/gcc%2Fconfig%2Fi386%2Fxmmintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fxmmintrin.h?ref=e37af218eed960ea5d499158db780aa4821e02cc", "patch": "@@ -34,11 +34,11 @@\n #include <mmintrin.h>\n \n /* The data type indended for user use.  */\n-typedef int __m128 __attribute__ ((mode (TI)));\n+typedef int __m128 __attribute__ ((__mode__(__V4SF__)));\n \n /* Internal data types for implementing the instrinsics.  */\n-typedef int __v4sf __attribute__ ((mode (V4SF)));\n-typedef int __v4si __attribute__ ((mode (V4SI)));\n+typedef int __v4sf __attribute__ ((__mode__(__V4SF__)));\n+typedef int __v4si __attribute__ ((__mode__(__V4SI__)));\n \n /* Create a selector for use with the SHUFPS instruction.  */\n #define _MM_SHUFFLE(fp3,fp2,fp1,fp0) \\\n@@ -680,7 +680,7 @@ _mm_movemask_ps (__m128 __A)\n static __inline unsigned int\n _mm_getcsr (void)\n {\n-  return __builtin_ia32_getmxcsr ();\n+  return __builtin_ia32_stmxcsr ();\n }\n \n /* Read exception bits from the control register.  */\n@@ -712,7 +712,7 @@ _MM_GET_FLUSH_ZERO_MODE (void)\n static __inline void\n _mm_setcsr (unsigned int __I)\n {\n-  __builtin_ia32_setmxcsr (__I);\n+  __builtin_ia32_ldmxcsr (__I);\n }\n \n /* Set exception bits in the control register.  */"}]}