{"sha": "add0c11114af3e58c2a64b9d34b69f38a79ef608", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YWRkMGMxMTExNGFmM2U1OGMyYTY0YjlkMzRiNjlmMzhhNzllZjYwOA==", "commit": {"author": {"name": "Ramana Radhakrishnan", "email": "ramana.radhakrishnan@arm.com", "date": "2014-05-08T14:30:10Z"}, "committer": {"name": "Ramana Radhakrishnan", "email": "ramana@gcc.gnu.org", "date": "2014-05-08T14:30:10Z"}, "message": "Neon intrinsics TLC - Replace intrinsics with GNU C implementations.\n\n2014-05-08  Ramana Radhakrishnan  <ramana.radhakrishnan@arm.com>\n\n\t* config/arm/arm_neon.h (vadd_s8): GNU C implementation\n\t(vadd_s16): Likewise.\n\t(vadd_s32): Likewise.\n\t(vadd_f32): Likewise.\n\t(vadd_u8): Likewise.\n\t(vadd_u16): Likewise.\n\t(vadd_u32): Likewise.\n\t(vadd_s64): Likewise.\n\t(vadd_u64): Likewise.\n\t(vaddq_s8): Likewise.\n\t(vaddq_s16): Likewise.\n\t(vaddq_s32): Likewise.\n\t(vaddq_s64): Likewise.\n\t(vaddq_f32): Likewise.\n\t(vaddq_u8): Likewise.\n\t(vaddq_u16): Likewise.\n\t(vaddq_u32): Likewise.\n\t(vaddq_u64): Likewise.\n\t(vmul_s8): Likewise.\n\t(vmul_s16): Likewise.\n\t(vmul_s32): Likewise.\n\t(vmul_f32): Likewise.\n\t(vmul_u8): Likewise.\n\t(vmul_u16): Likewise.\n\t(vmul_u32): Likewise.\n\t(vmul_p8): Likewise.\n\t(vmulq_s8): Likewise.\n\t(vmulq_s16): Likewise.\n\t(vmulq_s32): Likewise.\n\t(vmulq_f32): Likewise.\n\t(vmulq_u8): Likewise.\n\t(vmulq_u16): Likewise.\n\t(vmulq_u32): Likewise.\n\t(vsub_s8): Likewise.\n\t(vsub_s16): Likewise.\n\t(vsub_s32): Likewise.\n\t(vsub_f32): Likewise.\n\t(vsub_u8): Likewise.\n\t(vsub_u16): Likewise.\n\t(vsub_u32): Likewise.\n\t(vsub_s64): Likewise.\n\t(vsub_u64): Likewise.\n\t(vsubq_s8): Likewise.\n\t(vsubq_s16): Likewise.\n\t(vsubq_s32): Likewise.\n\t(vsubq_s64): Likewise.\n\t(vsubq_f32): Likewise.\n\t(vsubq_u8): Likewise.\n\t(vsubq_u16): Likewise.\n\t(vsubq_u32): Likewise.\n\t(vsubq_u64): Likewise.\n\t(vand_s8): Likewise.\n\t(vand_s16): Likewise.\n\t(vand_s32): Likewise.\n\t(vand_u8): Likewise.\n\t(vand_u16): Likewise.\n\t(vand_u32): Likewise.\n\t(vand_s64): Likewise.\n\t(vand_u64): Likewise.\n\t(vandq_s8): Likewise.\n\t(vandq_s16): Likewise.\n\t(vandq_s32): Likewise.\n\t(vandq_s64): Likewise.\n\t(vandq_u8): Likewise.\n\t(vandq_u16): Likewise.\n\t(vandq_u32): Likewise.\n\t(vandq_u64): Likewise.\n\t(vorr_s8): Likewise.\n\t(vorr_s16): Likewise.\n\t(vorr_s32): Likewise.\n\t(vorr_u8): Likewise.\n\t(vorr_u16): Likewise.\n\t(vorr_u32): Likewise.\n\t(vorr_s64): Likewise.\n\t(vorr_u64): Likewise.\n\t(vorrq_s8): Likewise.\n\t(vorrq_s16): Likewise.\n\t(vorrq_s32): Likewise.\n\t(vorrq_s64): Likewise.\n\t(vorrq_u8): Likewise.\n\t(vorrq_u16): Likewise.\n\t(vorrq_u32): Likewise.\n\t(vorrq_u64): Likewise.\n\t(veor_s8): Likewise.\n\t(veor_s16): Likewise.\n\t(veor_s32): Likewise.\n\t(veor_u8): Likewise.\n\t(veor_u16): Likewise.\n\t(veor_u32): Likewise.\n\t(veor_s64): Likewise.\n\t(veor_u64): Likewise.\n\t(veorq_s8): Likewise.\n\t(veorq_s16): Likewise.\n\t(veorq_s32): Likewise.\n\t(veorq_s64): Likewise.\n\t(veorq_u8): Likewise.\n\t(veorq_u16): Likewise.\n\t(veorq_u32): Likewise.\n\t(veorq_u64): Likewise.\n\t(vbic_s8): Likewise.\n\t(vbic_s16): Likewise.\n\t(vbic_s32): Likewise.\n\t(vbic_u8): Likewise.\n\t(vbic_u16): Likewise.\n\t(vbic_u32): Likewise.\n\t(vbic_s64): Likewise.\n\t(vbic_u64): Likewise.\n\t(vbicq_s8): Likewise.\n\t(vbicq_s16): Likewise.\n\t(vbicq_s32): Likewise.\n\t(vbicq_s64): Likewise.\n\t(vbicq_u8): Likewise.\n\t(vbicq_u16): Likewise.\n\t(vbicq_u32): Likewise.\n\t(vbicq_u64): Likewise.\n\t(vorn_s8): Likewise.\n\t(vorn_s16): Likewise.\n\t(vorn_s32): Likewise.\n\t(vorn_u8): Likewise.\n\t(vorn_u16): Likewise.\n\t(vorn_u32): Likewise.\n\t(vorn_s64): Likewise.\n\t(vorn_u64): Likewise.\n\t(vornq_s8): Likewise.\n\t(vornq_s16): Likewise.\n\t(vornq_s32): Likewise.\n\t(vornq_s64): Likewise.\n\t(vornq_u8): Likewise.\n\t(vornq_u16): Likewise.\n\t(vornq_u32): Likewise.\n\t(vornq_u64): Likewise.\n\nFrom-SVN: r210216", "tree": {"sha": "4510994b4797b091faaeb33698d702a5a70e7970", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/4510994b4797b091faaeb33698d702a5a70e7970"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/add0c11114af3e58c2a64b9d34b69f38a79ef608", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/add0c11114af3e58c2a64b9d34b69f38a79ef608", "html_url": "https://github.com/Rust-GCC/gccrs/commit/add0c11114af3e58c2a64b9d34b69f38a79ef608", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/add0c11114af3e58c2a64b9d34b69f38a79ef608/comments", "author": null, "committer": null, "parents": [{"sha": "ca40fb286efdbbeaf778ee3a9f58bc40b046b863", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ca40fb286efdbbeaf778ee3a9f58bc40b046b863", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ca40fb286efdbbeaf778ee3a9f58bc40b046b863"}], "stats": {"total": 436, "additions": 297, "deletions": 139}, "files": [{"sha": "ad1eb8156d4517b50943980fd016b3a6a2aa9344", "filename": "gcc/ChangeLog", "status": "modified", "additions": 134, "deletions": 0, "changes": 134, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/add0c11114af3e58c2a64b9d34b69f38a79ef608/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/add0c11114af3e58c2a64b9d34b69f38a79ef608/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=add0c11114af3e58c2a64b9d34b69f38a79ef608", "patch": "@@ -1,3 +1,137 @@\n+2014-05-08  Ramana Radhakrishnan  <ramana.radhakrishnan@arm.com>\n+\n+\t* config/arm/arm_neon.h (vadd_s8): GNU C implementation\n+\t(vadd_s16): Likewise.\n+\t(vadd_s32): Likewise.\n+\t(vadd_f32): Likewise.\n+\t(vadd_u8): Likewise.\n+\t(vadd_u16): Likewise.\n+\t(vadd_u32): Likewise.\n+\t(vadd_s64): Likewise.\n+\t(vadd_u64): Likewise.\n+\t(vaddq_s8): Likewise.\n+\t(vaddq_s16): Likewise.\n+\t(vaddq_s32): Likewise.\n+\t(vaddq_s64): Likewise.\n+\t(vaddq_f32): Likewise.\n+\t(vaddq_u8): Likewise.\n+\t(vaddq_u16): Likewise.\n+\t(vaddq_u32): Likewise.\n+\t(vaddq_u64): Likewise.\n+\t(vmul_s8): Likewise.\n+\t(vmul_s16): Likewise.\n+\t(vmul_s32): Likewise.\n+\t(vmul_f32): Likewise.\n+\t(vmul_u8): Likewise.\n+\t(vmul_u16): Likewise.\n+\t(vmul_u32): Likewise.\n+\t(vmul_p8): Likewise.\n+\t(vmulq_s8): Likewise.\n+\t(vmulq_s16): Likewise.\n+\t(vmulq_s32): Likewise.\n+\t(vmulq_f32): Likewise.\n+\t(vmulq_u8): Likewise.\n+\t(vmulq_u16): Likewise.\n+\t(vmulq_u32): Likewise.\n+\t(vsub_s8): Likewise.\n+\t(vsub_s16): Likewise.\n+\t(vsub_s32): Likewise.\n+\t(vsub_f32): Likewise.\n+\t(vsub_u8): Likewise.\n+\t(vsub_u16): Likewise.\n+\t(vsub_u32): Likewise.\n+\t(vsub_s64): Likewise.\n+\t(vsub_u64): Likewise.\n+\t(vsubq_s8): Likewise.\n+\t(vsubq_s16): Likewise.\n+\t(vsubq_s32): Likewise.\n+\t(vsubq_s64): Likewise.\n+\t(vsubq_f32): Likewise.\n+\t(vsubq_u8): Likewise.\n+\t(vsubq_u16): Likewise.\n+\t(vsubq_u32): Likewise.\n+\t(vsubq_u64): Likewise.\n+\t(vand_s8): Likewise.\n+\t(vand_s16): Likewise.\n+\t(vand_s32): Likewise.\n+\t(vand_u8): Likewise.\n+\t(vand_u16): Likewise.\n+\t(vand_u32): Likewise.\n+\t(vand_s64): Likewise.\n+\t(vand_u64): Likewise.\n+\t(vandq_s8): Likewise.\n+\t(vandq_s16): Likewise.\n+\t(vandq_s32): Likewise.\n+\t(vandq_s64): Likewise.\n+\t(vandq_u8): Likewise.\n+\t(vandq_u16): Likewise.\n+\t(vandq_u32): Likewise.\n+\t(vandq_u64): Likewise.\n+\t(vorr_s8): Likewise.\n+\t(vorr_s16): Likewise.\n+\t(vorr_s32): Likewise.\n+\t(vorr_u8): Likewise.\n+\t(vorr_u16): Likewise.\n+\t(vorr_u32): Likewise.\n+\t(vorr_s64): Likewise.\n+\t(vorr_u64): Likewise.\n+\t(vorrq_s8): Likewise.\n+\t(vorrq_s16): Likewise.\n+\t(vorrq_s32): Likewise.\n+\t(vorrq_s64): Likewise.\n+\t(vorrq_u8): Likewise.\n+\t(vorrq_u16): Likewise.\n+\t(vorrq_u32): Likewise.\n+\t(vorrq_u64): Likewise.\n+\t(veor_s8): Likewise.\n+\t(veor_s16): Likewise.\n+\t(veor_s32): Likewise.\n+\t(veor_u8): Likewise.\n+\t(veor_u16): Likewise.\n+\t(veor_u32): Likewise.\n+\t(veor_s64): Likewise.\n+\t(veor_u64): Likewise.\n+\t(veorq_s8): Likewise.\n+\t(veorq_s16): Likewise.\n+\t(veorq_s32): Likewise.\n+\t(veorq_s64): Likewise.\n+\t(veorq_u8): Likewise.\n+\t(veorq_u16): Likewise.\n+\t(veorq_u32): Likewise.\n+\t(veorq_u64): Likewise.\n+\t(vbic_s8): Likewise.\n+\t(vbic_s16): Likewise.\n+\t(vbic_s32): Likewise.\n+\t(vbic_u8): Likewise.\n+\t(vbic_u16): Likewise.\n+\t(vbic_u32): Likewise.\n+\t(vbic_s64): Likewise.\n+\t(vbic_u64): Likewise.\n+\t(vbicq_s8): Likewise.\n+\t(vbicq_s16): Likewise.\n+\t(vbicq_s32): Likewise.\n+\t(vbicq_s64): Likewise.\n+\t(vbicq_u8): Likewise.\n+\t(vbicq_u16): Likewise.\n+\t(vbicq_u32): Likewise.\n+\t(vbicq_u64): Likewise.\n+\t(vorn_s8): Likewise.\n+\t(vorn_s16): Likewise.\n+\t(vorn_s32): Likewise.\n+\t(vorn_u8): Likewise.\n+\t(vorn_u16): Likewise.\n+\t(vorn_u32): Likewise.\n+\t(vorn_s64): Likewise.\n+\t(vorn_u64): Likewise.\n+\t(vornq_s8): Likewise.\n+\t(vornq_s16): Likewise.\n+\t(vornq_s32): Likewise.\n+\t(vornq_s64): Likewise.\n+\t(vornq_u8): Likewise.\n+\t(vornq_u16): Likewise.\n+\t(vornq_u32): Likewise.\n+\t(vornq_u64): Likewise.\n+\n 2014-05-08  Ramana Radhakrishnan  <ramana.radhakrishnan@arm.com>\n \n \t* wide-int.cc (UTItype): Define."}, {"sha": "479ec2cfa364ffbf08895111ff996a1134030af6", "filename": "gcc/config/arm/arm_neon.h", "status": "modified", "additions": 163, "deletions": 139, "changes": 302, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/add0c11114af3e58c2a64b9d34b69f38a79ef608/gcc%2Fconfig%2Farm%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/add0c11114af3e58c2a64b9d34b69f38a79ef608/gcc%2Fconfig%2Farm%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm_neon.h?ref=add0c11114af3e58c2a64b9d34b69f38a79ef608", "patch": "@@ -453,114 +453,121 @@ typedef struct poly64x2x4_t\n } poly64x2x4_t;\n #endif\n \n-\n-\n+/* vadd  */\n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n vadd_s8 (int8x8_t __a, int8x8_t __b)\n {\n-  return (int8x8_t)__builtin_neon_vaddv8qi (__a, __b, 1);\n+  return __a + __b;\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vadd_s16 (int16x4_t __a, int16x4_t __b)\n {\n-  return (int16x4_t)__builtin_neon_vaddv4hi (__a, __b, 1);\n+  return __a + __b;\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vadd_s32 (int32x2_t __a, int32x2_t __b)\n {\n-  return (int32x2_t)__builtin_neon_vaddv2si (__a, __b, 1);\n+  return __a + __b;\n }\n \n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vadd_f32 (float32x2_t __a, float32x2_t __b)\n {\n-  return (float32x2_t)__builtin_neon_vaddv2sf (__a, __b, 3);\n+#ifdef __FAST_MATH__\n+  return __a + __b;\n+#else\n+  return (float32x2_t) __builtin_neon_vaddv2sf (__a, __b, 3);\n+#endif\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vadd_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t)__builtin_neon_vaddv8qi ((int8x8_t) __a, (int8x8_t) __b, 0);\n+  return __a + __b;\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vadd_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t)__builtin_neon_vaddv4hi ((int16x4_t) __a, (int16x4_t) __b, 0);\n+  return __a + __b;\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vadd_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t)__builtin_neon_vaddv2si ((int32x2_t) __a, (int32x2_t) __b, 0);\n+  return __a + __b;\n }\n \n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n vadd_s64 (int64x1_t __a, int64x1_t __b)\n {\n-  return (int64x1_t)__builtin_neon_vadddi (__a, __b, 1);\n+  return __a + __b;\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vadd_u64 (uint64x1_t __a, uint64x1_t __b)\n {\n-  return (uint64x1_t)__builtin_neon_vadddi ((int64x1_t) __a, (int64x1_t) __b, 0);\n+  return __a + __b;\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n vaddq_s8 (int8x16_t __a, int8x16_t __b)\n {\n-  return (int8x16_t)__builtin_neon_vaddv16qi (__a, __b, 1);\n+  return __a + __b;\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vaddq_s16 (int16x8_t __a, int16x8_t __b)\n {\n-  return (int16x8_t)__builtin_neon_vaddv8hi (__a, __b, 1);\n+  return __a + __b;\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n vaddq_s32 (int32x4_t __a, int32x4_t __b)\n {\n-  return (int32x4_t)__builtin_neon_vaddv4si (__a, __b, 1);\n+  return __a + __b;\n }\n \n __extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n vaddq_s64 (int64x2_t __a, int64x2_t __b)\n {\n-  return (int64x2_t)__builtin_neon_vaddv2di (__a, __b, 1);\n+  return __a + __b;\n }\n \n __extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n vaddq_f32 (float32x4_t __a, float32x4_t __b)\n {\n-  return (float32x4_t)__builtin_neon_vaddv4sf (__a, __b, 3);\n+#ifdef __FAST_MATH\n+  return __a + __b;\n+#else\n+  return (float32x4_t) __builtin_neon_vaddv4sf (__a, __b, 3);\n+#endif\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vaddq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t)__builtin_neon_vaddv16qi ((int8x16_t) __a, (int8x16_t) __b, 0);\n+  return __a + __b;\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vaddq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t)__builtin_neon_vaddv8hi ((int16x8_t) __a, (int16x8_t) __b, 0);\n+  return __a + __b;\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vaddq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t)__builtin_neon_vaddv4si ((int32x4_t) __a, (int32x4_t) __b, 0);\n+  return __a + __b;\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vaddq_u64 (uint64x2_t __a, uint64x2_t __b)\n {\n-  return (uint64x2_t)__builtin_neon_vaddv2di ((int64x2_t) __a, (int64x2_t) __b, 0);\n+  return __a + __b;\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n@@ -950,91 +957,100 @@ vraddhn_u64 (uint64x2_t __a, uint64x2_t __b)\n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n vmul_s8 (int8x8_t __a, int8x8_t __b)\n {\n-  return (int8x8_t)__builtin_neon_vmulv8qi (__a, __b, 1);\n+  return __a * __b;\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vmul_s16 (int16x4_t __a, int16x4_t __b)\n {\n-  return (int16x4_t)__builtin_neon_vmulv4hi (__a, __b, 1);\n+  return __a * __b;\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vmul_s32 (int32x2_t __a, int32x2_t __b)\n {\n-  return (int32x2_t)__builtin_neon_vmulv2si (__a, __b, 1);\n+  return __a * __b;\n }\n \n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vmul_f32 (float32x2_t __a, float32x2_t __b)\n {\n-  return (float32x2_t)__builtin_neon_vmulv2sf (__a, __b, 3);\n+#ifdef __FAST_MATH\n+  return __a * __b;\n+#else\n+  return (float32x2_t) __builtin_neon_vmulv2sf (__a, __b, 3);\n+#endif\n+\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vmul_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t)__builtin_neon_vmulv8qi ((int8x8_t) __a, (int8x8_t) __b, 0);\n+  return __a * __b;\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vmul_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t)__builtin_neon_vmulv4hi ((int16x4_t) __a, (int16x4_t) __b, 0);\n+  return __a * __b;\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vmul_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t)__builtin_neon_vmulv2si ((int32x2_t) __a, (int32x2_t) __b, 0);\n-}\n-\n-__extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n-vmul_p8 (poly8x8_t __a, poly8x8_t __b)\n-{\n-  return (poly8x8_t)__builtin_neon_vmulv8qi ((int8x8_t) __a, (int8x8_t) __b, 2);\n+  return __a * __b;\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n vmulq_s8 (int8x16_t __a, int8x16_t __b)\n {\n-  return (int8x16_t)__builtin_neon_vmulv16qi (__a, __b, 1);\n+  return __a * __b;\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vmulq_s16 (int16x8_t __a, int16x8_t __b)\n {\n-  return (int16x8_t)__builtin_neon_vmulv8hi (__a, __b, 1);\n+  return __a * __b;\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n vmulq_s32 (int32x4_t __a, int32x4_t __b)\n {\n-  return (int32x4_t)__builtin_neon_vmulv4si (__a, __b, 1);\n+  return __a * __b;\n }\n \n __extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n vmulq_f32 (float32x4_t __a, float32x4_t __b)\n {\n-  return (float32x4_t)__builtin_neon_vmulv4sf (__a, __b, 3);\n+#ifdef __FAST_MATH\n+  return __a * __b;\n+#else\n+  return (float32x4_t) __builtin_neon_vmulv4sf (__a, __b, 3);\n+#endif\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vmulq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t)__builtin_neon_vmulv16qi ((int8x16_t) __a, (int8x16_t) __b, 0);\n+  return __a * __b;\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vmulq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t)__builtin_neon_vmulv8hi ((int16x8_t) __a, (int16x8_t) __b, 0);\n+  return __a * __b;\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vmulq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t)__builtin_neon_vmulv4si ((int32x4_t) __a, (int32x4_t) __b, 0);\n+  return __a * __b;\n+}\n+\n+__extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n+vmul_p8 (poly8x8_t __a, poly8x8_t __b)\n+{\n+  return (poly8x8_t)__builtin_neon_vmulv8qi ((int8x8_t) __a, (int8x8_t) __b, 2);\n }\n \n __extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n@@ -1521,112 +1537,121 @@ vrndq_f32 (float32x4_t __a)\n }\n \n #endif\n+\n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n vsub_s8 (int8x8_t __a, int8x8_t __b)\n {\n-  return (int8x8_t)__builtin_neon_vsubv8qi (__a, __b, 1);\n+  return __a - __b;\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vsub_s16 (int16x4_t __a, int16x4_t __b)\n {\n-  return (int16x4_t)__builtin_neon_vsubv4hi (__a, __b, 1);\n+  return __a - __b;\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vsub_s32 (int32x2_t __a, int32x2_t __b)\n {\n-  return (int32x2_t)__builtin_neon_vsubv2si (__a, __b, 1);\n+  return __a - __b;\n }\n \n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vsub_f32 (float32x2_t __a, float32x2_t __b)\n {\n-  return (float32x2_t)__builtin_neon_vsubv2sf (__a, __b, 3);\n+#ifdef __FAST_MATH\n+  return __a - __b;\n+#else\n+  return (float32x2_t) __builtin_neon_vsubv2sf (__a, __b, 3);\n+#endif\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vsub_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t)__builtin_neon_vsubv8qi ((int8x8_t) __a, (int8x8_t) __b, 0);\n+  return __a - __b;\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vsub_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t)__builtin_neon_vsubv4hi ((int16x4_t) __a, (int16x4_t) __b, 0);\n+  return __a - __b;\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vsub_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t)__builtin_neon_vsubv2si ((int32x2_t) __a, (int32x2_t) __b, 0);\n+  return __a - __b;\n }\n \n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n vsub_s64 (int64x1_t __a, int64x1_t __b)\n {\n-  return (int64x1_t)__builtin_neon_vsubdi (__a, __b, 1);\n+  return __a - __b;\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vsub_u64 (uint64x1_t __a, uint64x1_t __b)\n {\n-  return (uint64x1_t)__builtin_neon_vsubdi ((int64x1_t) __a, (int64x1_t) __b, 0);\n+  return __a - __b;\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n vsubq_s8 (int8x16_t __a, int8x16_t __b)\n {\n-  return (int8x16_t)__builtin_neon_vsubv16qi (__a, __b, 1);\n+  return __a - __b;\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vsubq_s16 (int16x8_t __a, int16x8_t __b)\n {\n-  return (int16x8_t)__builtin_neon_vsubv8hi (__a, __b, 1);\n+  return __a - __b;\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n vsubq_s32 (int32x4_t __a, int32x4_t __b)\n {\n-  return (int32x4_t)__builtin_neon_vsubv4si (__a, __b, 1);\n+  return __a - __b;\n }\n \n __extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n vsubq_s64 (int64x2_t __a, int64x2_t __b)\n {\n-  return (int64x2_t)__builtin_neon_vsubv2di (__a, __b, 1);\n+  return __a - __b;\n }\n \n __extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n vsubq_f32 (float32x4_t __a, float32x4_t __b)\n {\n-  return (float32x4_t)__builtin_neon_vsubv4sf (__a, __b, 3);\n+#ifdef __FAST_MATH\n+  return __a - __b;\n+#else\n+  return (float32x4_t) __builtin_neon_vsubv4sf (__a, __b, 3);\n+#endif\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vsubq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t)__builtin_neon_vsubv16qi ((int8x16_t) __a, (int8x16_t) __b, 0);\n+  return __a - __b;\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vsubq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t)__builtin_neon_vsubv8hi ((int16x8_t) __a, (int16x8_t) __b, 0);\n+  return __a - __b;\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vsubq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t)__builtin_neon_vsubv4si ((int32x4_t) __a, (int32x4_t) __b, 0);\n+  return __a - __b;\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vsubq_u64 (uint64x2_t __a, uint64x2_t __b)\n {\n-  return (uint64x2_t)__builtin_neon_vsubv2di ((int64x2_t) __a, (int64x2_t) __b, 0);\n+  return __a - __b;\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n@@ -10907,484 +10932,483 @@ vst4q_lane_p16 (poly16_t * __a, poly16x8x4_t __b, const int __c)\n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n vand_s8 (int8x8_t __a, int8x8_t __b)\n {\n-  return (int8x8_t)__builtin_neon_vandv8qi (__a, __b, 1);\n+  return __a & __b;\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vand_s16 (int16x4_t __a, int16x4_t __b)\n {\n-  return (int16x4_t)__builtin_neon_vandv4hi (__a, __b, 1);\n+  return __a & __b;\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vand_s32 (int32x2_t __a, int32x2_t __b)\n {\n-  return (int32x2_t)__builtin_neon_vandv2si (__a, __b, 1);\n+  return __a & __b;\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vand_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t)__builtin_neon_vandv8qi ((int8x8_t) __a, (int8x8_t) __b, 0);\n+  return __a & __b;\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vand_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t)__builtin_neon_vandv4hi ((int16x4_t) __a, (int16x4_t) __b, 0);\n+  return __a & __b;\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vand_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t)__builtin_neon_vandv2si ((int32x2_t) __a, (int32x2_t) __b, 0);\n+  return __a & __b;\n }\n \n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n vand_s64 (int64x1_t __a, int64x1_t __b)\n {\n-  return (int64x1_t)__builtin_neon_vanddi (__a, __b, 1);\n+  return __a & __b;\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vand_u64 (uint64x1_t __a, uint64x1_t __b)\n {\n-  return (uint64x1_t)__builtin_neon_vanddi ((int64x1_t) __a, (int64x1_t) __b, 0);\n+  return __a & __b;\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n vandq_s8 (int8x16_t __a, int8x16_t __b)\n {\n-  return (int8x16_t)__builtin_neon_vandv16qi (__a, __b, 1);\n+  return __a & __b;\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vandq_s16 (int16x8_t __a, int16x8_t __b)\n {\n-  return (int16x8_t)__builtin_neon_vandv8hi (__a, __b, 1);\n+  return __a & __b;\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n vandq_s32 (int32x4_t __a, int32x4_t __b)\n {\n-  return (int32x4_t)__builtin_neon_vandv4si (__a, __b, 1);\n+  return __a & __b;\n }\n \n __extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n vandq_s64 (int64x2_t __a, int64x2_t __b)\n {\n-  return (int64x2_t)__builtin_neon_vandv2di (__a, __b, 1);\n+  return __a & __b;\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vandq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t)__builtin_neon_vandv16qi ((int8x16_t) __a, (int8x16_t) __b, 0);\n+  return __a & __b;\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vandq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t)__builtin_neon_vandv8hi ((int16x8_t) __a, (int16x8_t) __b, 0);\n+  return __a & __b;\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vandq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t)__builtin_neon_vandv4si ((int32x4_t) __a, (int32x4_t) __b, 0);\n+  return __a & __b;\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vandq_u64 (uint64x2_t __a, uint64x2_t __b)\n {\n-  return (uint64x2_t)__builtin_neon_vandv2di ((int64x2_t) __a, (int64x2_t) __b, 0);\n+  return __a & __b;\n }\n \n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n vorr_s8 (int8x8_t __a, int8x8_t __b)\n {\n-  return (int8x8_t)__builtin_neon_vorrv8qi (__a, __b, 1);\n+  return __a | __b;\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vorr_s16 (int16x4_t __a, int16x4_t __b)\n {\n-  return (int16x4_t)__builtin_neon_vorrv4hi (__a, __b, 1);\n+  return __a | __b;\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vorr_s32 (int32x2_t __a, int32x2_t __b)\n {\n-  return (int32x2_t)__builtin_neon_vorrv2si (__a, __b, 1);\n+  return __a | __b;\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vorr_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t)__builtin_neon_vorrv8qi ((int8x8_t) __a, (int8x8_t) __b, 0);\n+  return __a | __b;\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vorr_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t)__builtin_neon_vorrv4hi ((int16x4_t) __a, (int16x4_t) __b, 0);\n+  return __a | __b;\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vorr_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t)__builtin_neon_vorrv2si ((int32x2_t) __a, (int32x2_t) __b, 0);\n+  return __a | __b;\n }\n \n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n vorr_s64 (int64x1_t __a, int64x1_t __b)\n {\n-  return (int64x1_t)__builtin_neon_vorrdi (__a, __b, 1);\n+  return __a | __b;\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vorr_u64 (uint64x1_t __a, uint64x1_t __b)\n {\n-  return (uint64x1_t)__builtin_neon_vorrdi ((int64x1_t) __a, (int64x1_t) __b, 0);\n+  return __a | __b;\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n vorrq_s8 (int8x16_t __a, int8x16_t __b)\n {\n-  return (int8x16_t)__builtin_neon_vorrv16qi (__a, __b, 1);\n+  return __a | __b;\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vorrq_s16 (int16x8_t __a, int16x8_t __b)\n {\n-  return (int16x8_t)__builtin_neon_vorrv8hi (__a, __b, 1);\n+  return __a | __b;\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n vorrq_s32 (int32x4_t __a, int32x4_t __b)\n {\n-  return (int32x4_t)__builtin_neon_vorrv4si (__a, __b, 1);\n+  return __a | __b;\n }\n \n __extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n vorrq_s64 (int64x2_t __a, int64x2_t __b)\n {\n-  return (int64x2_t)__builtin_neon_vorrv2di (__a, __b, 1);\n+  return __a | __b;\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vorrq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t)__builtin_neon_vorrv16qi ((int8x16_t) __a, (int8x16_t) __b, 0);\n+  return __a | __b;\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vorrq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t)__builtin_neon_vorrv8hi ((int16x8_t) __a, (int16x8_t) __b, 0);\n+  return __a | __b;\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vorrq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t)__builtin_neon_vorrv4si ((int32x4_t) __a, (int32x4_t) __b, 0);\n+  return __a | __b;\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vorrq_u64 (uint64x2_t __a, uint64x2_t __b)\n {\n-  return (uint64x2_t)__builtin_neon_vorrv2di ((int64x2_t) __a, (int64x2_t) __b, 0);\n+  return __a | __b;\n }\n \n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n veor_s8 (int8x8_t __a, int8x8_t __b)\n {\n-  return (int8x8_t)__builtin_neon_veorv8qi (__a, __b, 1);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n veor_s16 (int16x4_t __a, int16x4_t __b)\n {\n-  return (int16x4_t)__builtin_neon_veorv4hi (__a, __b, 1);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n veor_s32 (int32x2_t __a, int32x2_t __b)\n {\n-  return (int32x2_t)__builtin_neon_veorv2si (__a, __b, 1);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n veor_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t)__builtin_neon_veorv8qi ((int8x8_t) __a, (int8x8_t) __b, 0);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n veor_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t)__builtin_neon_veorv4hi ((int16x4_t) __a, (int16x4_t) __b, 0);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n veor_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t)__builtin_neon_veorv2si ((int32x2_t) __a, (int32x2_t) __b, 0);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n veor_s64 (int64x1_t __a, int64x1_t __b)\n {\n-  return (int64x1_t)__builtin_neon_veordi (__a, __b, 1);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n veor_u64 (uint64x1_t __a, uint64x1_t __b)\n {\n-  return (uint64x1_t)__builtin_neon_veordi ((int64x1_t) __a, (int64x1_t) __b, 0);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n veorq_s8 (int8x16_t __a, int8x16_t __b)\n {\n-  return (int8x16_t)__builtin_neon_veorv16qi (__a, __b, 1);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n veorq_s16 (int16x8_t __a, int16x8_t __b)\n {\n-  return (int16x8_t)__builtin_neon_veorv8hi (__a, __b, 1);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n veorq_s32 (int32x4_t __a, int32x4_t __b)\n {\n-  return (int32x4_t)__builtin_neon_veorv4si (__a, __b, 1);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n veorq_s64 (int64x2_t __a, int64x2_t __b)\n {\n-  return (int64x2_t)__builtin_neon_veorv2di (__a, __b, 1);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n veorq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t)__builtin_neon_veorv16qi ((int8x16_t) __a, (int8x16_t) __b, 0);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n veorq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t)__builtin_neon_veorv8hi ((int16x8_t) __a, (int16x8_t) __b, 0);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n veorq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t)__builtin_neon_veorv4si ((int32x4_t) __a, (int32x4_t) __b, 0);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n veorq_u64 (uint64x2_t __a, uint64x2_t __b)\n {\n-  return (uint64x2_t)__builtin_neon_veorv2di ((int64x2_t) __a, (int64x2_t) __b, 0);\n+  return __a ^ __b;\n }\n \n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n vbic_s8 (int8x8_t __a, int8x8_t __b)\n {\n-  return (int8x8_t)__builtin_neon_vbicv8qi (__a, __b, 1);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vbic_s16 (int16x4_t __a, int16x4_t __b)\n {\n-  return (int16x4_t)__builtin_neon_vbicv4hi (__a, __b, 1);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vbic_s32 (int32x2_t __a, int32x2_t __b)\n {\n-  return (int32x2_t)__builtin_neon_vbicv2si (__a, __b, 1);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vbic_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t)__builtin_neon_vbicv8qi ((int8x8_t) __a, (int8x8_t) __b, 0);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vbic_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t)__builtin_neon_vbicv4hi ((int16x4_t) __a, (int16x4_t) __b, 0);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vbic_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t)__builtin_neon_vbicv2si ((int32x2_t) __a, (int32x2_t) __b, 0);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n vbic_s64 (int64x1_t __a, int64x1_t __b)\n {\n-  return (int64x1_t)__builtin_neon_vbicdi (__a, __b, 1);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vbic_u64 (uint64x1_t __a, uint64x1_t __b)\n {\n-  return (uint64x1_t)__builtin_neon_vbicdi ((int64x1_t) __a, (int64x1_t) __b, 0);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n vbicq_s8 (int8x16_t __a, int8x16_t __b)\n {\n-  return (int8x16_t)__builtin_neon_vbicv16qi (__a, __b, 1);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vbicq_s16 (int16x8_t __a, int16x8_t __b)\n {\n-  return (int16x8_t)__builtin_neon_vbicv8hi (__a, __b, 1);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n vbicq_s32 (int32x4_t __a, int32x4_t __b)\n {\n-  return (int32x4_t)__builtin_neon_vbicv4si (__a, __b, 1);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n vbicq_s64 (int64x2_t __a, int64x2_t __b)\n {\n-  return (int64x2_t)__builtin_neon_vbicv2di (__a, __b, 1);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vbicq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t)__builtin_neon_vbicv16qi ((int8x16_t) __a, (int8x16_t) __b, 0);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vbicq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t)__builtin_neon_vbicv8hi ((int16x8_t) __a, (int16x8_t) __b, 0);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vbicq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t)__builtin_neon_vbicv4si ((int32x4_t) __a, (int32x4_t) __b, 0);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vbicq_u64 (uint64x2_t __a, uint64x2_t __b)\n {\n-  return (uint64x2_t)__builtin_neon_vbicv2di ((int64x2_t) __a, (int64x2_t) __b, 0);\n+  return __a & ~__b;\n }\n \n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n vorn_s8 (int8x8_t __a, int8x8_t __b)\n {\n-  return (int8x8_t)__builtin_neon_vornv8qi (__a, __b, 1);\n+  return __a | ~__b;\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vorn_s16 (int16x4_t __a, int16x4_t __b)\n {\n-  return (int16x4_t)__builtin_neon_vornv4hi (__a, __b, 1);\n+  return __a | ~__b;\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vorn_s32 (int32x2_t __a, int32x2_t __b)\n {\n-  return (int32x2_t)__builtin_neon_vornv2si (__a, __b, 1);\n+  return __a | ~__b;\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vorn_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t)__builtin_neon_vornv8qi ((int8x8_t) __a, (int8x8_t) __b, 0);\n+  return __a | ~__b;\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vorn_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t)__builtin_neon_vornv4hi ((int16x4_t) __a, (int16x4_t) __b, 0);\n+  return __a | ~__b;\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vorn_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t)__builtin_neon_vornv2si ((int32x2_t) __a, (int32x2_t) __b, 0);\n+  return __a | ~__b;\n }\n \n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n vorn_s64 (int64x1_t __a, int64x1_t __b)\n {\n-  return (int64x1_t)__builtin_neon_vorndi (__a, __b, 1);\n+  return __a | ~__b;\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vorn_u64 (uint64x1_t __a, uint64x1_t __b)\n {\n-  return (uint64x1_t)__builtin_neon_vorndi ((int64x1_t) __a, (int64x1_t) __b, 0);\n+  return __a | ~__b;\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n vornq_s8 (int8x16_t __a, int8x16_t __b)\n {\n-  return (int8x16_t)__builtin_neon_vornv16qi (__a, __b, 1);\n+  return __a | ~__b;\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vornq_s16 (int16x8_t __a, int16x8_t __b)\n {\n-  return (int16x8_t)__builtin_neon_vornv8hi (__a, __b, 1);\n+  return __a | ~__b;\n }\n \n __extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n vornq_s32 (int32x4_t __a, int32x4_t __b)\n {\n-  return (int32x4_t)__builtin_neon_vornv4si (__a, __b, 1);\n+  return __a | ~__b;\n }\n \n __extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n vornq_s64 (int64x2_t __a, int64x2_t __b)\n {\n-  return (int64x2_t)__builtin_neon_vornv2di (__a, __b, 1);\n+  return __a | ~__b;\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vornq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t)__builtin_neon_vornv16qi ((int8x16_t) __a, (int8x16_t) __b, 0);\n+  return __a | ~__b;\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vornq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t)__builtin_neon_vornv8hi ((int16x8_t) __a, (int16x8_t) __b, 0);\n+  return __a | ~__b;\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vornq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t)__builtin_neon_vornv4si ((int32x4_t) __a, (int32x4_t) __b, 0);\n+  return __a | ~__b;\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vornq_u64 (uint64x2_t __a, uint64x2_t __b)\n {\n-  return (uint64x2_t)__builtin_neon_vornv2di ((int64x2_t) __a, (int64x2_t) __b, 0);\n+  return __a | ~__b;\n }\n \n-\n __extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n vreinterpret_p8_p16 (poly16x4_t __a)\n {"}]}