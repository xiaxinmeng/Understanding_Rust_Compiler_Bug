{"sha": "3dfa80718b8ed4d46aaf89b1e8a410130945a793", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6M2RmYTgwNzE4YjhlZDRkNDZhYWY4OWIxZThhNDEwMTMwOTQ1YTc5Mw==", "commit": {"author": {"name": "Kyrylo Tkachov", "email": "kyrylo.tkachov@arm.com", "date": "2016-06-30T15:19:45Z"}, "committer": {"name": "Kyrylo Tkachov", "email": "ktkachov@gcc.gnu.org", "date": "2016-06-30T15:19:45Z"}, "message": "[AArch64][2/2] (Re)Implement vcopy<q>_lane<q> intrinsics\n\n2016-06-30  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>\n            James Greenhalgh  <james.greenhalgh@arm.com>\n\n\t* config/aarch64/arm_neon.h (vcopyq_lane_f32, vcopyq_lane_f64,\n\tvcopyq_lane_p8, vcopyq_lane_p16, vcopyq_lane_s8, vcopyq_lane_s16,\n\tvcopyq_lane_s32, vcopyq_lane_s64, vcopyq_lane_u8, vcopyq_lane_u16,\n\tvcopyq_lane_u32, vcopyq_lane_u64): Reimplement in C.\n\t(vcopy_lane_f32, vcopy_lane_f64, vcopy_lane_p8, vcopy_lane_p16,\n\tvcopy_lane_s8, vcopy_lane_s16, vcopy_lane_s32, vcopy_lane_s64,\n\tvcopy_lane_u8, vcopy_lane_u16, vcopy_lane_u32, vcopy_lane_u64,\n\tvcopy_laneq_f32, vcopy_laneq_f64, vcopy_laneq_p8, vcopy_laneq_p16,\n\tvcopy_laneq_s8, vcopy_laneq_s16, vcopy_laneq_s32, vcopy_laneq_s64,\n\tvcopy_laneq_u8, vcopy_laneq_u16, vcopy_laneq_u32, vcopy_laneq_u64,\n\tvcopyq_laneq_f32, vcopyq_laneq_f64, vcopyq_laneq_p8, vcopyq_laneq_p16,\n\tvcopyq_laneq_s8, vcopyq_laneq_s16, vcopyq_laneq_s32, vcopyq_laneq_s64,\n\tvcopyq_laneq_u8, vcopyq_laneq_u16, vcopyq_laneq_u32, vcopyq_laneq_u64):\n\tNew intrinsics.\n\n\t* gcc.target/aarch64/vect_copy_lane_1.c: New test.\n\n\nCo-Authored-By: James Greenhalgh <james.greenhalgh@arm.com>\n\nFrom-SVN: r237883", "tree": {"sha": "7aca1ace387a0f7a911df83b632b5d7d68b8100d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/7aca1ace387a0f7a911df83b632b5d7d68b8100d"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/3dfa80718b8ed4d46aaf89b1e8a410130945a793", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3dfa80718b8ed4d46aaf89b1e8a410130945a793", "html_url": "https://github.com/Rust-GCC/gccrs/commit/3dfa80718b8ed4d46aaf89b1e8a410130945a793", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3dfa80718b8ed4d46aaf89b1e8a410130945a793/comments", "author": {"login": "ktkachov-arm", "id": 74917949, "node_id": "MDQ6VXNlcjc0OTE3OTQ5", "avatar_url": "https://avatars.githubusercontent.com/u/74917949?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ktkachov-arm", "html_url": "https://github.com/ktkachov-arm", "followers_url": "https://api.github.com/users/ktkachov-arm/followers", "following_url": "https://api.github.com/users/ktkachov-arm/following{/other_user}", "gists_url": "https://api.github.com/users/ktkachov-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/ktkachov-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ktkachov-arm/subscriptions", "organizations_url": "https://api.github.com/users/ktkachov-arm/orgs", "repos_url": "https://api.github.com/users/ktkachov-arm/repos", "events_url": "https://api.github.com/users/ktkachov-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/ktkachov-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "9bd622427288a8aac7e095842021b175087356d6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/9bd622427288a8aac7e095842021b175087356d6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/9bd622427288a8aac7e095842021b175087356d6"}], "stats": {"total": 657, "additions": 501, "deletions": 156}, "files": [{"sha": "da6956aafc9abcfae9f14fe815ac896a37a97dbc", "filename": "gcc/ChangeLog", "status": "modified", "additions": 18, "deletions": 0, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3dfa80718b8ed4d46aaf89b1e8a410130945a793/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3dfa80718b8ed4d46aaf89b1e8a410130945a793/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=3dfa80718b8ed4d46aaf89b1e8a410130945a793", "patch": "@@ -1,3 +1,21 @@\n+2016-06-30  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>\n+            James Greenhalgh  <james.greenhalgh@arm.com>\n+\n+\t* config/aarch64/arm_neon.h (vcopyq_lane_f32, vcopyq_lane_f64,\n+\tvcopyq_lane_p8, vcopyq_lane_p16, vcopyq_lane_s8, vcopyq_lane_s16,\n+\tvcopyq_lane_s32, vcopyq_lane_s64, vcopyq_lane_u8, vcopyq_lane_u16,\n+\tvcopyq_lane_u32, vcopyq_lane_u64): Reimplement in C.\n+\t(vcopy_lane_f32, vcopy_lane_f64, vcopy_lane_p8, vcopy_lane_p16,\n+\tvcopy_lane_s8, vcopy_lane_s16, vcopy_lane_s32, vcopy_lane_s64,\n+\tvcopy_lane_u8, vcopy_lane_u16, vcopy_lane_u32, vcopy_lane_u64,\n+\tvcopy_laneq_f32, vcopy_laneq_f64, vcopy_laneq_p8, vcopy_laneq_p16,\n+\tvcopy_laneq_s8, vcopy_laneq_s16, vcopy_laneq_s32, vcopy_laneq_s64,\n+\tvcopy_laneq_u8, vcopy_laneq_u16, vcopy_laneq_u32, vcopy_laneq_u64,\n+\tvcopyq_laneq_f32, vcopyq_laneq_f64, vcopyq_laneq_p8, vcopyq_laneq_p16,\n+\tvcopyq_laneq_s8, vcopyq_laneq_s16, vcopyq_laneq_s32, vcopyq_laneq_s64,\n+\tvcopyq_laneq_u8, vcopyq_laneq_u16, vcopyq_laneq_u32, vcopyq_laneq_u64):\n+\tNew intrinsics.\n+\n 2016-06-30  James Greenhalgh  <james.greenhalgh@arm.com>\n             Kyrylo Tkachov  <kyrylo.tkachov@arm.com>\n "}, {"sha": "4d5292eaed5558dfc21e8fb44b1ebe57c392aeee", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 392, "deletions": 156, "changes": 548, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3dfa80718b8ed4d46aaf89b1e8a410130945a793/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3dfa80718b8ed4d46aaf89b1e8a410130945a793/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=3dfa80718b8ed4d46aaf89b1e8a410130945a793", "patch": "@@ -5814,162 +5814,6 @@ vaddlvq_u32 (uint32x4_t a)\n   return result;\n }\n \n-#define vcopyq_lane_f32(a, b, c, d)                                     \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       float32x4_t c_ = (c);                                            \\\n-       float32x4_t a_ = (a);                                            \\\n-       float32x4_t result;                                              \\\n-       __asm__ (\"ins %0.s[%2], %3.s[%4]\"                                \\\n-                : \"=w\"(result)                                          \\\n-                : \"0\"(a_), \"i\"(b), \"w\"(c_), \"i\"(d)                      \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vcopyq_lane_f64(a, b, c, d)                                     \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       float64x2_t c_ = (c);                                            \\\n-       float64x2_t a_ = (a);                                            \\\n-       float64x2_t result;                                              \\\n-       __asm__ (\"ins %0.d[%2], %3.d[%4]\"                                \\\n-                : \"=w\"(result)                                          \\\n-                : \"0\"(a_), \"i\"(b), \"w\"(c_), \"i\"(d)                      \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vcopyq_lane_p8(a, b, c, d)                                      \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       poly8x16_t c_ = (c);                                             \\\n-       poly8x16_t a_ = (a);                                             \\\n-       poly8x16_t result;                                               \\\n-       __asm__ (\"ins %0.b[%2], %3.b[%4]\"                                \\\n-                : \"=w\"(result)                                          \\\n-                : \"0\"(a_), \"i\"(b), \"w\"(c_), \"i\"(d)                      \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vcopyq_lane_p16(a, b, c, d)                                     \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       poly16x8_t c_ = (c);                                             \\\n-       poly16x8_t a_ = (a);                                             \\\n-       poly16x8_t result;                                               \\\n-       __asm__ (\"ins %0.h[%2], %3.h[%4]\"                                \\\n-                : \"=w\"(result)                                          \\\n-                : \"0\"(a_), \"i\"(b), \"w\"(c_), \"i\"(d)                      \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vcopyq_lane_s8(a, b, c, d)                                      \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int8x16_t c_ = (c);                                              \\\n-       int8x16_t a_ = (a);                                              \\\n-       int8x16_t result;                                                \\\n-       __asm__ (\"ins %0.b[%2], %3.b[%4]\"                                \\\n-                : \"=w\"(result)                                          \\\n-                : \"0\"(a_), \"i\"(b), \"w\"(c_), \"i\"(d)                      \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vcopyq_lane_s16(a, b, c, d)                                     \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int16x8_t c_ = (c);                                              \\\n-       int16x8_t a_ = (a);                                              \\\n-       int16x8_t result;                                                \\\n-       __asm__ (\"ins %0.h[%2], %3.h[%4]\"                                \\\n-                : \"=w\"(result)                                          \\\n-                : \"0\"(a_), \"i\"(b), \"w\"(c_), \"i\"(d)                      \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vcopyq_lane_s32(a, b, c, d)                                     \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int32x4_t c_ = (c);                                              \\\n-       int32x4_t a_ = (a);                                              \\\n-       int32x4_t result;                                                \\\n-       __asm__ (\"ins %0.s[%2], %3.s[%4]\"                                \\\n-                : \"=w\"(result)                                          \\\n-                : \"0\"(a_), \"i\"(b), \"w\"(c_), \"i\"(d)                      \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vcopyq_lane_s64(a, b, c, d)                                     \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       int64x2_t c_ = (c);                                              \\\n-       int64x2_t a_ = (a);                                              \\\n-       int64x2_t result;                                                \\\n-       __asm__ (\"ins %0.d[%2], %3.d[%4]\"                                \\\n-                : \"=w\"(result)                                          \\\n-                : \"0\"(a_), \"i\"(b), \"w\"(c_), \"i\"(d)                      \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vcopyq_lane_u8(a, b, c, d)                                      \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint8x16_t c_ = (c);                                             \\\n-       uint8x16_t a_ = (a);                                             \\\n-       uint8x16_t result;                                               \\\n-       __asm__ (\"ins %0.b[%2], %3.b[%4]\"                                \\\n-                : \"=w\"(result)                                          \\\n-                : \"0\"(a_), \"i\"(b), \"w\"(c_), \"i\"(d)                      \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vcopyq_lane_u16(a, b, c, d)                                     \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint16x8_t c_ = (c);                                             \\\n-       uint16x8_t a_ = (a);                                             \\\n-       uint16x8_t result;                                               \\\n-       __asm__ (\"ins %0.h[%2], %3.h[%4]\"                                \\\n-                : \"=w\"(result)                                          \\\n-                : \"0\"(a_), \"i\"(b), \"w\"(c_), \"i\"(d)                      \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vcopyq_lane_u32(a, b, c, d)                                     \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint32x4_t c_ = (c);                                             \\\n-       uint32x4_t a_ = (a);                                             \\\n-       uint32x4_t result;                                               \\\n-       __asm__ (\"ins %0.s[%2], %3.s[%4]\"                                \\\n-                : \"=w\"(result)                                          \\\n-                : \"0\"(a_), \"i\"(b), \"w\"(c_), \"i\"(d)                      \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n-#define vcopyq_lane_u64(a, b, c, d)                                     \\\n-  __extension__                                                         \\\n-    ({                                                                  \\\n-       uint64x2_t c_ = (c);                                             \\\n-       uint64x2_t a_ = (a);                                             \\\n-       uint64x2_t result;                                               \\\n-       __asm__ (\"ins %0.d[%2], %3.d[%4]\"                                \\\n-                : \"=w\"(result)                                          \\\n-                : \"0\"(a_), \"i\"(b), \"w\"(c_), \"i\"(d)                      \\\n-                : /* No clobbers */);                                   \\\n-       result;                                                          \\\n-     })\n-\n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vcvtx_f32_f64 (float64x2_t a)\n {\n@@ -12356,6 +12200,398 @@ vcntq_u8 (uint8x16_t __a)\n   return (uint8x16_t) __builtin_aarch64_popcountv16qi ((int8x16_t) __a);\n }\n \n+/* vcopy_lane.  */\n+\n+__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n+vcopy_lane_f32 (float32x2_t __a, const int __lane1,\n+\t\tfloat32x2_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n+vcopy_lane_f64 (float64x1_t __a, const int __lane1,\n+\t\tfloat64x1_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n+vcopy_lane_p8 (poly8x8_t __a, const int __lane1,\n+\t       poly8x8_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t __a, __lane1);\n+}\n+\n+__extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n+vcopy_lane_p16 (poly16x4_t __a, const int __lane1,\n+\t\tpoly16x4_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n+vcopy_lane_s8 (int8x8_t __a, const int __lane1,\n+\t       int8x8_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t __a, __lane1);\n+}\n+\n+__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n+vcopy_lane_s16 (int16x4_t __a, const int __lane1,\n+\t\tint16x4_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n+vcopy_lane_s32 (int32x2_t __a, const int __lane1,\n+\t\tint32x2_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n+vcopy_lane_s64 (int64x1_t __a, const int __lane1,\n+\t\tint64x1_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n+vcopy_lane_u8 (uint8x8_t __a, const int __lane1,\n+\t       uint8x8_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t __a, __lane1);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vcopy_lane_u16 (uint16x4_t __a, const int __lane1,\n+\t\tuint16x4_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n+vcopy_lane_u32 (uint32x2_t __a, const int __lane1,\n+\t\tuint32x2_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n+vcopy_lane_u64 (uint64x1_t __a, const int __lane1,\n+\t\tuint64x1_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+/* vcopy_laneq.  */\n+\n+__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n+vcopy_laneq_f32 (float32x2_t __a, const int __lane1,\n+\t\t float32x4_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n+vcopy_laneq_f64 (float64x1_t __a, const int __lane1,\n+\t\t float64x2_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n+vcopy_laneq_p8 (poly8x8_t __a, const int __lane1,\n+\t\tpoly8x16_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t __a, __lane1);\n+}\n+\n+__extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n+vcopy_laneq_p16 (poly16x4_t __a, const int __lane1,\n+\t\t poly16x8_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n+vcopy_laneq_s8 (int8x8_t __a, const int __lane1,\n+\t\tint8x16_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t __a, __lane1);\n+}\n+\n+__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n+vcopy_laneq_s16 (int16x4_t __a, const int __lane1,\n+\t\t int16x8_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n+vcopy_laneq_s32 (int32x2_t __a, const int __lane1,\n+\t\t int32x4_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n+vcopy_laneq_s64 (int64x1_t __a, const int __lane1,\n+\t\t int64x2_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n+vcopy_laneq_u8 (uint8x8_t __a, const int __lane1,\n+\t\tuint8x16_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t __a, __lane1);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vcopy_laneq_u16 (uint16x4_t __a, const int __lane1,\n+\t\t uint16x8_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n+vcopy_laneq_u32 (uint32x2_t __a, const int __lane1,\n+\t\t uint32x4_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n+vcopy_laneq_u64 (uint64x1_t __a, const int __lane1,\n+\t\t uint64x2_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+/* vcopyq_lane.  */\n+\n+__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n+vcopyq_lane_f32 (float32x4_t __a, const int __lane1,\n+\t\t float32x2_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n+vcopyq_lane_f64 (float64x2_t __a, const int __lane1,\n+\t\t float64x1_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n+vcopyq_lane_p8 (poly8x16_t __a, const int __lane1,\n+\t\tpoly8x8_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline poly16x8_t __attribute__ ((__always_inline__))\n+vcopyq_lane_p16 (poly16x8_t __a, const int __lane1,\n+\t\t poly16x4_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n+vcopyq_lane_s8 (int8x16_t __a, const int __lane1,\n+\t\tint8x8_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n+vcopyq_lane_s16 (int16x8_t __a, const int __lane1,\n+\t\t int16x4_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n+vcopyq_lane_s32 (int32x4_t __a, const int __lane1,\n+\t\t int32x2_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n+vcopyq_lane_s64 (int64x2_t __a, const int __lane1,\n+\t\t int64x1_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n+vcopyq_lane_u8 (uint8x16_t __a, const int __lane1,\n+\t\tuint8x8_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vcopyq_lane_u16 (uint16x8_t __a, const int __lane1,\n+\t\t uint16x4_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n+vcopyq_lane_u32 (uint32x4_t __a, const int __lane1,\n+\t\t uint32x2_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n+vcopyq_lane_u64 (uint64x2_t __a, const int __lane1,\n+\t\t uint64x1_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+/* vcopyq_laneq.  */\n+\n+__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n+vcopyq_laneq_f32 (float32x4_t __a, const int __lane1,\n+\t\t  float32x4_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n+vcopyq_laneq_f64 (float64x2_t __a, const int __lane1,\n+\t\t  float64x2_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n+vcopyq_laneq_p8 (poly8x16_t __a, const int __lane1,\n+\t\t poly8x16_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline poly16x8_t __attribute__ ((__always_inline__))\n+vcopyq_laneq_p16 (poly16x8_t __a, const int __lane1,\n+\t\t  poly16x8_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n+vcopyq_laneq_s8 (int8x16_t __a, const int __lane1,\n+\t\t int8x16_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n+vcopyq_laneq_s16 (int16x8_t __a, const int __lane1,\n+\t\t  int16x8_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n+vcopyq_laneq_s32 (int32x4_t __a, const int __lane1,\n+\t\t  int32x4_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n+vcopyq_laneq_s64 (int64x2_t __a, const int __lane1,\n+\t\t  int64x2_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n+vcopyq_laneq_u8 (uint8x16_t __a, const int __lane1,\n+\t\t uint8x16_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t  __a, __lane1);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vcopyq_laneq_u16 (uint16x8_t __a, const int __lane1,\n+\t\t  uint16x8_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n+vcopyq_laneq_u32 (uint32x4_t __a, const int __lane1,\n+\t\t  uint32x4_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n+__extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n+vcopyq_laneq_u64 (uint64x2_t __a, const int __lane1,\n+\t\t  uint64x2_t __b, const int __lane2)\n+{\n+  return __aarch64_vset_lane_any (__aarch64_vget_lane_any (__b, __lane2),\n+\t\t\t\t   __a, __lane1);\n+}\n+\n /* vcvt (double -> float).  */\n \n __extension__ static __inline float16x4_t __attribute__ ((__always_inline__))"}, {"sha": "216f61fd8210cfed6af91c900bde9a6035b38368", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3dfa80718b8ed4d46aaf89b1e8a410130945a793/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3dfa80718b8ed4d46aaf89b1e8a410130945a793/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=3dfa80718b8ed4d46aaf89b1e8a410130945a793", "patch": "@@ -1,3 +1,8 @@\n+2016-06-30  Kyrylo Tkachov  <kyrylo.tkachov@arm.com>\n+            James Greenhalgh  <james.greenhalgh@arm.com>\n+\n+\t* gcc.target/aarch64/vect_copy_lane_1.c: New test.\n+\n 2016-06-30  James Greenhalgh  <james.greenhalgh@arm.com>\n             Kyrylo Tkachov  <kyrylo.tkachov@arm.com>\n "}, {"sha": "e144def83862fb9b895533bd48a80be4bc643bf8", "filename": "gcc/testsuite/gcc.target/aarch64/vect_copy_lane_1.c", "status": "added", "additions": 86, "deletions": 0, "changes": 86, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3dfa80718b8ed4d46aaf89b1e8a410130945a793/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvect_copy_lane_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3dfa80718b8ed4d46aaf89b1e8a410130945a793/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvect_copy_lane_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvect_copy_lane_1.c?ref=3dfa80718b8ed4d46aaf89b1e8a410130945a793", "patch": "@@ -0,0 +1,86 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O3\" } */\n+\n+#include \"arm_neon.h\"\n+\n+#define BUILD_TEST(TYPE1, TYPE2, Q1, Q2, SUFFIX, INDEX1, INDEX2)\t\\\n+TYPE1 __attribute__((noinline,noclone))\t\t\t\t\t\\\n+test_copy##Q1##_lane##Q2##_##SUFFIX (TYPE1 a, TYPE2 b)\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+  return vcopy##Q1##_lane##Q2##_##SUFFIX (a, INDEX1, b, INDEX2);\t\\\n+}\n+\n+/* vcopy_lane.  */\n+BUILD_TEST (poly8x8_t, poly8x8_t, , , p8, 7, 6)\n+BUILD_TEST (int8x8_t,  int8x8_t,  , , s8, 7, 6)\n+BUILD_TEST (uint8x8_t, uint8x8_t, , , u8, 7, 6)\n+/* { dg-final { scan-assembler-times \"ins\\\\tv0.b\\\\\\[7\\\\\\], v1.b\\\\\\[6\\\\\\]\" 3 } } */\n+BUILD_TEST (poly16x4_t, poly16x4_t, , , p16, 3, 2)\n+BUILD_TEST (int16x4_t,  int16x4_t,  , , s16, 3, 2)\n+BUILD_TEST (uint16x4_t, uint16x4_t, , , u16, 3, 2)\n+/* { dg-final { scan-assembler-times \"ins\\\\tv0.h\\\\\\[3\\\\\\], v1.h\\\\\\[2\\\\\\]\" 3 } } */\n+BUILD_TEST (float32x2_t, float32x2_t, , , f32, 1, 0)\n+BUILD_TEST (int32x2_t,   int32x2_t,   , , s32, 1, 0)\n+BUILD_TEST (uint32x2_t,  uint32x2_t,  , , u32, 1, 0)\n+/* { dg-final { scan-assembler-times \"ins\\\\tv0.s\\\\\\[1\\\\\\], v1.s\\\\\\[0\\\\\\]\" 3 } } */\n+BUILD_TEST (int64x1_t,   int64x1_t,   , , s64, 0, 0)\n+BUILD_TEST (uint64x1_t,  uint64x1_t,  , , u64, 0, 0)\n+BUILD_TEST (float64x1_t, float64x1_t, , , f64, 0, 0)\n+/* { dg-final { scan-assembler-times \"fmov\\\\td0, d1\" 3 } } */\n+\n+/* vcopy_laneq.  */\n+\n+BUILD_TEST (poly8x8_t, poly8x16_t, , q, p8, 7, 15)\n+BUILD_TEST (int8x8_t,  int8x16_t,  , q, s8, 7, 15)\n+BUILD_TEST (uint8x8_t, uint8x16_t, , q, u8, 7, 15)\n+/* { dg-final { scan-assembler-times \"ins\\\\tv0.b\\\\\\[7\\\\\\], v1.b\\\\\\[15\\\\\\]\" 3 } } */\n+BUILD_TEST (poly16x4_t, poly16x8_t, , q, p16, 3, 7)\n+BUILD_TEST (int16x4_t,  int16x8_t,  , q, s16, 3, 7)\n+BUILD_TEST (uint16x4_t, uint16x8_t, , q, u16, 3, 7)\n+/* { dg-final { scan-assembler-times \"ins\\\\tv0.h\\\\\\[3\\\\\\], v1.h\\\\\\[7\\\\\\]\" 3 } } */\n+BUILD_TEST (float32x2_t, float32x4_t, , q, f32, 1, 3)\n+BUILD_TEST (int32x2_t,   int32x4_t,   , q, s32, 1, 3)\n+BUILD_TEST (uint32x2_t,  uint32x4_t,  , q, u32, 1, 3)\n+/* { dg-final { scan-assembler-times \"ins\\\\tv0.s\\\\\\[1\\\\\\], v1.s\\\\\\[3\\\\\\]\" 3 } } */\n+BUILD_TEST (float64x1_t, float64x2_t, , q, f64, 0, 1)\n+BUILD_TEST (int64x1_t,  int64x2_t,    , q, s64, 0, 1)\n+BUILD_TEST (uint64x1_t, uint64x2_t,   , q, u64, 0, 1)\n+/* XFAIL due to PR 71307.  */\n+/* { dg-final { scan-assembler-times \"dup\\\\td0, v1.d\\\\\\[1\\\\\\]\" 3 { xfail *-*-* } } } */\n+\n+/* vcopyq_lane.  */\n+BUILD_TEST (poly8x16_t, poly8x8_t, q, , p8, 15, 7)\n+BUILD_TEST (int8x16_t,  int8x8_t,  q, , s8, 15, 7)\n+BUILD_TEST (uint8x16_t, uint8x8_t, q, , u8, 15, 7)\n+/* { dg-final { scan-assembler-times \"ins\\\\tv0.b\\\\\\[15\\\\\\], v1.b\\\\\\[7\\\\\\]\" 3 } } */\n+BUILD_TEST (poly16x8_t, poly16x4_t, q, , p16, 7, 3)\n+BUILD_TEST (int16x8_t,  int16x4_t,  q, , s16, 7, 3)\n+BUILD_TEST (uint16x8_t, uint16x4_t, q, , u16, 7, 3)\n+/* { dg-final { scan-assembler-times \"ins\\\\tv0.h\\\\\\[7\\\\\\], v1.h\\\\\\[3\\\\\\]\" 3 } } */\n+BUILD_TEST (float32x4_t, float32x2_t, q, , f32, 3, 1)\n+BUILD_TEST (int32x4_t,   int32x2_t,   q, , s32, 3, 1)\n+BUILD_TEST (uint32x4_t,  uint32x2_t,  q, , u32, 3, 1)\n+/* { dg-final { scan-assembler-times \"ins\\\\tv0.s\\\\\\[3\\\\\\], v1.s\\\\\\[1\\\\\\]\" 3 } } */\n+BUILD_TEST (float64x2_t, float64x1_t, q, , f64, 1, 0)\n+BUILD_TEST (int64x2_t,   int64x1_t,   q, , s64, 1, 0)\n+BUILD_TEST (uint64x2_t,  uint64x1_t,  q, , u64, 1, 0)\n+/* { dg-final { scan-assembler-times \"ins\\\\tv0.d\\\\\\[1\\\\\\], v1.d\\\\\\[0\\\\\\]\" 3 } } */\n+\n+/* vcopyq_laneq.  */\n+\n+BUILD_TEST (poly8x16_t, poly8x16_t, q, q, p8, 14, 15)\n+BUILD_TEST (int8x16_t,  int8x16_t,  q, q, s8, 14, 15)\n+BUILD_TEST (uint8x16_t, uint8x16_t, q, q, u8, 14, 15)\n+/* { dg-final { scan-assembler-times \"ins\\\\tv0.b\\\\\\[14\\\\\\], v1.b\\\\\\[15\\\\\\]\" 3 } } */\n+BUILD_TEST (poly16x8_t, poly16x8_t, q, q, p16, 6, 7)\n+BUILD_TEST (int16x8_t,  int16x8_t,  q, q, s16, 6, 7)\n+BUILD_TEST (uint16x8_t, uint16x8_t, q, q, u16, 6, 7)\n+/* { dg-final { scan-assembler-times \"ins\\\\tv0.h\\\\\\[6\\\\\\], v1.h\\\\\\[7\\\\\\]\" 3 } } */\n+BUILD_TEST (float32x4_t, float32x4_t, q, q, f32, 2, 3)\n+BUILD_TEST (int32x4_t,   int32x4_t,   q, q, s32, 2, 3)\n+BUILD_TEST (uint32x4_t,  uint32x4_t,  q, q, u32, 2, 3)\n+/* { dg-final { scan-assembler-times \"ins\\\\tv0.s\\\\\\[2\\\\\\], v1.s\\\\\\[3\\\\\\]\" 3 } } */\n+BUILD_TEST (float64x2_t, float64x2_t, q, q, f64, 1, 1)\n+BUILD_TEST (int64x2_t,   int64x2_t,   q,  q, s64, 1, 1)\n+BUILD_TEST (uint64x2_t,  uint64x2_t,  q, q, u64, 1, 1)\n+/* { dg-final { scan-assembler-times \"ins\\\\tv0.d\\\\\\[1\\\\\\], v1.d\\\\\\[1\\\\\\]\" 3 } } */"}]}