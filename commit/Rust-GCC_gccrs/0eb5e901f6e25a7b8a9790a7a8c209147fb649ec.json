{"sha": "0eb5e901f6e25a7b8a9790a7a8c209147fb649ec", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MGViNWU5MDFmNmUyNWE3YjhhOTc5MGE3YThjMjA5MTQ3ZmI2NDllYw==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2020-10-02T10:53:06Z"}, "committer": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2020-10-02T10:53:06Z"}, "message": "aarch64: Remove aarch64_sve_pred_dominates_p\n\nIn r11-2922, Przemek fixed a post-RA instruction match failure\ncaused by the SVE FP subtraction patterns..  This patch applies\nthe same fix to the other patterns.\n\nTo recap, the issue is around the handling of predication.\nWe want to do two things:\n\n- Optimise cases in which a predicate is known to be all-true.\n\n- Differentiate cases in which the predicate on an _x ACLE function has\n  to be kept as-is from cases in which we can make more lanes active.\n  The former is true by default, the latter is true for certain\n  combinations of flags in the -ffast-math group.\n\nThis is handled by a boolean flag in the unspecs to say whether the\npredicate is \u201cstrict\u201d or \u201crelaxed\u201d.  When combining multiple strict\noperations, the predicates used in the operations generally need to\nmatch.  When combining multiple relaxed operations, we can ignore the\npredicates on nested operations and just use the predicate on the\n\u201coutermost\u201d operation.\n\nOriginally I'd tried to reduce combinatorial explosion by using\naarch64_sve_pred_dominates_p.  This required matching predicates\nfor strict operations but allowed more combinations for relaxed\noperations.\n\nThe problem (as I should have remembered) is that C conditions on\ninsn patterns can't reliably enforce matching operands.  If the\nsame register is used in two different input operands, the RA is\nallowed to use different hard registers for those input operands\n(and sometimes it has to).  So operands that match before RA\nmight not match afterwards.  The only sure way to force a match\nis via match_dup.\n\nThis patch splits the cases into two.  I cry bitter tears at having\nto do this, but I think it's the only backportable fix.  There might\nbe some way of using define_subst to generate the cond_* patterns from\nthe pred_* patterns, with some alternatives strategically disabled in\neach case, but that's future work and might not be an improvement.\n\nSince so many patterns now do this, I moved the comments from the\nsubtraction pattern to a new banner comment at the head of the file.\n\ngcc/\n\t* config/aarch64/aarch64-protos.h (aarch64_sve_pred_dominates_p):\n\tDelete.\n\t* config/aarch64/aarch64.c (aarch64_sve_pred_dominates_p): Likewise.\n\t* config/aarch64/aarch64-sve.md: Add banner comment describing\n\thow merging predicated FP operations are represented.\n\t(*cond_<SVE_COND_FP_UNARY:optab><mode>_2): Split into...\n\t(*cond_<SVE_COND_FP_UNARY:optab><mode>_2_relaxed): ...this and...\n\t(*cond_<SVE_COND_FP_UNARY:optab><mode>_2_strict): ...this.\n\t(*cond_<SVE_COND_FP_UNARY:optab><mode>_any): Split into...\n\t(*cond_<SVE_COND_FP_UNARY:optab><mode>_any_relaxed): ...this and...\n\t(*cond_<SVE_COND_FP_UNARY:optab><mode>_any_strict): ...this.\n\t(*cond_<SVE_COND_FP_BINARY_INT:optab><mode>_2): Split into...\n\t(*cond_<SVE_COND_FP_BINARY_INT:optab><mode>_2_relaxed): ...this and...\n\t(*cond_<SVE_COND_FP_BINARY_INT:optab><mode>_2_strict): ...this.\n\t(*cond_<SVE_COND_FP_BINARY_INT:optab><mode>_any): Split into...\n\t(*cond_<SVE_COND_FP_BINARY_INT:optab><mode>_any_relaxed): ...this\n\tand...\n\t(*cond_<SVE_COND_FP_BINARY_INT:optab><mode>_any_strict): ...this.\n\t(*cond_<SVE_COND_FP_BINARY:optab><mode>_2): Split into...\n\t(*cond_<SVE_COND_FP_BINARY:optab><mode>_2_relaxed): ...this and...\n\t(*cond_<SVE_COND_FP_BINARY:optab><mode>_2_strict): ...this.\n\t(*cond_<SVE_COND_FP_BINARY_I1:optab><mode>_2_const): Split into...\n\t(*cond_<SVE_COND_FP_BINARY_I1:optab><mode>_2_const_relaxed): ...this\n\tand...\n\t(*cond_<SVE_COND_FP_BINARY_I1:optab><mode>_2_const_strict): ...this.\n\t(*cond_<SVE_COND_FP_BINARY:optab><mode>_3): Split into...\n\t(*cond_<SVE_COND_FP_BINARY:optab><mode>_3_relaxed): ...this and...\n\t(*cond_<SVE_COND_FP_BINARY:optab><mode>_3_strict): ...this.\n\t(*cond_<SVE_COND_FP_BINARY:optab><mode>_any): Split into...\n\t(*cond_<SVE_COND_FP_BINARY:optab><mode>_any_relaxed): ...this and...\n\t(*cond_<SVE_COND_FP_BINARY:optab><mode>_any_strict): ...this.\n\t(*cond_<SVE_COND_FP_BINARY_I1:optab><mode>_any_const): Split into...\n\t(*cond_<SVE_COND_FP_BINARY_I1:optab><mode>_any_const_relaxed): ...this\n\tand...\n\t(*cond_<SVE_COND_FP_BINARY_I1:optab><mode>_any_const_strict): ...this.\n\t(*cond_add<mode>_2_const): Split into...\n\t(*cond_add<mode>_2_const_relaxed): ...this and...\n\t(*cond_add<mode>_2_const_strict): ...this.\n\t(*cond_add<mode>_any_const): Split into...\n\t(*cond_add<mode>_any_const_relaxed): ...this and...\n\t(*cond_add<mode>_any_const_strict): ...this.\n\t(*cond_<SVE_COND_FCADD:optab><mode>_2): Split into...\n\t(*cond_<SVE_COND_FCADD:optab><mode>_2_relaxed): ...this and...\n\t(*cond_<SVE_COND_FCADD:optab><mode>_2_strict): ...this.\n\t(*cond_<SVE_COND_FCADD:optab><mode>_any): Split into...\n\t(*cond_<SVE_COND_FCADD:optab><mode>_any_relaxed): ...this and...\n\t(*cond_<SVE_COND_FCADD:optab><mode>_any_strict): ...this.\n\t(*cond_sub<mode>_3_const): Split into...\n\t(*cond_sub<mode>_3_const_relaxed): ...this and...\n\t(*cond_sub<mode>_3_const_strict): ...this.\n\t(*aarch64_pred_abd<mode>): Split into...\n\t(*aarch64_pred_abd<mode>_relaxed): ...this and...\n\t(*aarch64_pred_abd<mode>_strict): ...this.\n\t(*aarch64_cond_abd<mode>_2): Split into...\n\t(*aarch64_cond_abd<mode>_2_relaxed): ...this and...\n\t(*aarch64_cond_abd<mode>_2_strict): ...this.\n\t(*aarch64_cond_abd<mode>_3): Split into...\n\t(*aarch64_cond_abd<mode>_3_relaxed): ...this and...\n\t(*aarch64_cond_abd<mode>_3_strict): ...this.\n\t(*aarch64_cond_abd<mode>_any): Split into...\n\t(*aarch64_cond_abd<mode>_any_relaxed): ...this and...\n\t(*aarch64_cond_abd<mode>_any_strict): ...this.\n\t(*cond_<SVE_COND_FP_TERNARY:optab><mode>_2): Split into...\n\t(*cond_<SVE_COND_FP_TERNARY:optab><mode>_2_relaxed): ...this and...\n\t(*cond_<SVE_COND_FP_TERNARY:optab><mode>_2_strict): ...this.\n\t(*cond_<SVE_COND_FP_TERNARY:optab><mode>_4): Split into...\n\t(*cond_<SVE_COND_FP_TERNARY:optab><mode>_4_relaxed): ...this and...\n\t(*cond_<SVE_COND_FP_TERNARY:optab><mode>_4_strict): ...this.\n\t(*cond_<SVE_COND_FP_TERNARY:optab><mode>_any): Split into...\n\t(*cond_<SVE_COND_FP_TERNARY:optab><mode>_any_relaxed): ...this and...\n\t(*cond_<SVE_COND_FP_TERNARY:optab><mode>_any_strict): ...this.\n\t(*cond_<SVE_COND_FCMLA:optab><mode>_4): Split into...\n\t(*cond_<SVE_COND_FCMLA:optab><mode>_4_relaxed): ...this and...\n\t(*cond_<SVE_COND_FCMLA:optab><mode>_4_strict): ...this.\n\t(*cond_<SVE_COND_FCMLA:optab><mode>_any): Split into...\n\t(*cond_<SVE_COND_FCMLA:optab><mode>_any_relaxed): ...this and...\n\t(*cond_<SVE_COND_FCMLA:optab><mode>_any_strict): ...this.\n\t(*aarch64_pred_fac<cmp_op><mode>): Split into...\n\t(*aarch64_pred_fac<cmp_op><mode>_relaxed): ...this and...\n\t(*aarch64_pred_fac<cmp_op><mode>_strict): ...this.\n\t(*cond_<optab>_nontrunc<SVE_FULL_F:mode><SVE_FULL_HSDI:mode>): Split\n\tinto...\n\t(*cond_<optab>_nontrunc<SVE_FULL_F:mode><SVE_FULL_HSDI:mode>_relaxed):\n\t...this and...\n\t(*cond_<optab>_nontrunc<SVE_FULL_F:mode><SVE_FULL_HSDI:mode>_strict):\n\t...this.\n\t(*cond_<optab>_nonextend<SVE_FULL_HSDI:mode><SVE_FULL_F:mode>): Split\n\tinto...\n\t(*cond_<optab>_nonextend<SVE_FULL_HSDI:mode><SVE_FULL_F:mode>_relaxed):\n\t...this and...\n\t(*cond_<optab>_nonextend<SVE_FULL_HSDI:mode><SVE_FULL_F:mode>_strict):\n\t...this.\n\t* config/aarch64/aarch64-sve2.md\n\t(*cond_<SVE2_COND_FP_UNARY_LONG:optab><mode>): Split into...\n\t(*cond_<SVE2_COND_FP_UNARY_LONG:optab><mode>_relaxed): ...this and...\n\t(*cond_<SVE2_COND_FP_UNARY_LONG:optab><mode>_strict): ...this.\n\t(*cond_<SVE2_COND_FP_UNARY_NARROWB:optab><mode>_any): Split into...\n\t(*cond_<SVE2_COND_FP_UNARY_NARROWB:optab><mode>_any_relaxed): ...this\n\tand...\n\t(*cond_<SVE2_COND_FP_UNARY_NARROWB:optab><mode>_any_strict): ...this.\n\t(*cond_<SVE2_COND_INT_UNARY_FP:optab><mode>): Split into...\n\t(*cond_<SVE2_COND_INT_UNARY_FP:optab><mode>_relaxed): ...this and...\n\t(*cond_<SVE2_COND_INT_UNARY_FP:optab><mode>_strict): ...this.", "tree": {"sha": "91a66cd4e3e1e35222ab0ee100a5c124b5100a6f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/91a66cd4e3e1e35222ab0ee100a5c124b5100a6f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/0eb5e901f6e25a7b8a9790a7a8c209147fb649ec", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0eb5e901f6e25a7b8a9790a7a8c209147fb649ec", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0eb5e901f6e25a7b8a9790a7a8c209147fb649ec", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0eb5e901f6e25a7b8a9790a7a8c209147fb649ec/comments", "author": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "bb78e5876aa6a6b4a8158cdc0f6c8511eb2be75f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bb78e5876aa6a6b4a8158cdc0f6c8511eb2be75f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/bb78e5876aa6a6b4a8158cdc0f6c8511eb2be75f"}], "stats": {"total": 1015, "additions": 853, "deletions": 162}, "files": [{"sha": "7a34c841355bad88365381912b163c61c5a35811", "filename": "gcc/config/aarch64/aarch64-protos.h", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0eb5e901f6e25a7b8a9790a7a8c209147fb649ec/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0eb5e901f6e25a7b8a9790a7a8c209147fb649ec/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h?ref=0eb5e901f6e25a7b8a9790a7a8c209147fb649ec", "patch": "@@ -630,7 +630,6 @@ void aarch64_expand_mov_immediate (rtx, rtx);\n rtx aarch64_stack_protect_canary_mem (machine_mode, rtx, aarch64_salt_type);\n rtx aarch64_ptrue_reg (machine_mode);\n rtx aarch64_pfalse_reg (machine_mode);\n-bool aarch64_sve_pred_dominates_p (rtx *, rtx);\n bool aarch64_sve_same_pred_for_ptest_p (rtx *, rtx *);\n void aarch64_emit_sve_pred_move (rtx, rtx, rtx);\n void aarch64_expand_sve_mem_move (rtx, rtx, machine_mode);"}, {"sha": "31a8c5a5aefc24b36c5115157cde0482b7a7927b", "filename": "gcc/config/aarch64/aarch64-sve.md", "status": "modified", "additions": 792, "deletions": 131, "changes": 923, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0eb5e901f6e25a7b8a9790a7a8c209147fb649ec/gcc%2Fconfig%2Faarch64%2Faarch64-sve.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0eb5e901f6e25a7b8a9790a7a8c209147fb649ec/gcc%2Fconfig%2Faarch64%2Faarch64-sve.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-sve.md?ref=0eb5e901f6e25a7b8a9790a7a8c209147fb649ec", "patch": "@@ -464,6 +464,95 @@\n ;;\n ;; - MNEMONIC is the mnemonic of the associated SVE instruction.\n ;;\n+;; For (3) and (4), we combine these operations with an UNSPEC_SEL\n+;; that selects between the result of the FP operation and the \"else\"\n+;; value.  (This else value is a merge input for _m ACLE functions\n+;; and zero for _z ACLE functions.)  The outer pattern then has the form:\n+;;\n+;;   (unspec [pred fp_operation else_value] UNSPEC_SEL)\n+;;\n+;; This means that the patterns for (3) and (4) have two predicates:\n+;; one for the FP operation itself and one for the UNSPEC_SEL.\n+;; This pattern is equivalent to the result of combining an instance\n+;; of (1) or (2) with a separate vcond instruction, so these patterns\n+;; are useful as combine targets too.\n+;;\n+;; However, in the combine case, the instructions that we want to\n+;; combine might use different predicates.  Then:\n+;;\n+;; - Some of the active lanes of the FP operation might be discarded\n+;;   by the UNSPEC_SEL.  It's OK to drop the FP operation on those lanes,\n+;;   even for SVE_STRICT_GP, since the operations on those lanes are\n+;;   effectively dead code.\n+;;\n+;; - Some of the inactive lanes of the FP operation might be selected\n+;;   by the UNSPEC_SEL, giving unspecified values for those lanes.\n+;;   SVE_RELAXED_GP lets us extend the FP operation to cover these\n+;;   extra lanes, but SVE_STRICT_GP does not.\n+;;\n+;; Thus SVE_RELAXED_GP allows us to ignore the predicate on the FP operation\n+;; and operate on exactly the lanes selected by the UNSPEC_SEL predicate.\n+;; This typically leads to patterns like:\n+;;\n+;;    (unspec [(match_operand 1 \"register_operand\" \"Upl\")\n+;;             (unspec [(match_operand N)\n+;;                      (const_int SVE_RELAXED_GP)\n+;;                      ...]\n+;;                     UNSPEC_COND_<MNEMONIC>)\n+;;             ...])\n+;;\n+;; where operand N is allowed to be anything.  These instructions then\n+;; have rewrite rules to replace operand N with operand 1, which gives the\n+;; instructions a canonical form and means that the original operand N is\n+;; not kept live unnecessarily.\n+;;\n+;; In contrast, SVE_STRICT_GP only allows the UNSPEC_SEL predicate to be\n+;; a subset of the FP operation predicate.  This case isn't interesting\n+;; for FP operations that have an all-true predicate, since such operations\n+;; use SVE_RELAXED_GP instead.  And it is not possible for instruction\n+;; conditions to track the subset relationship for arbitrary registers.\n+;; So in practice, the only useful case for SVE_STRICT_GP is the one\n+;; in which the predicates match:\n+;;\n+;;    (unspec [(match_operand 1 \"register_operand\" \"Upl\")\n+;;             (unspec [(match_dup 1)\n+;;                      (const_int SVE_STRICT_GP)\n+;;                      ...]\n+;;                     UNSPEC_COND_<MNEMONIC>)\n+;;             ...])\n+;;\n+;; This pattern would also be correct for SVE_RELAXED_GP, but it would\n+;; be redundant with the one above.  However, if the combine pattern\n+;; has multiple FP operations, using a match_operand allows combinations\n+;; of SVE_STRICT_GP and SVE_RELAXED_GP in the same operation, provided\n+;; that the predicates are the same:\n+;;\n+;;    (unspec [(match_operand 1 \"register_operand\" \"Upl\")\n+;;             (...\n+;;                (unspec [(match_dup 1)\n+;;                         (match_operand:SI N \"aarch64_sve_gp_strictness\")\n+;;                         ...]\n+;;                        UNSPEC_COND_<MNEMONIC1>)\n+;;                (unspec [(match_dup 1)\n+;;                         (match_operand:SI M \"aarch64_sve_gp_strictness\")\n+;;                         ...]\n+;;                        UNSPEC_COND_<MNEMONIC2>) ...)\n+;;             ...])\n+;;\n+;; The fully-relaxed version of this pattern is:\n+;;\n+;;    (unspec [(match_operand 1 \"register_operand\" \"Upl\")\n+;;             (...\n+;;                (unspec [(match_operand:SI N)\n+;;                         (const_int SVE_RELAXED_GP)\n+;;                         ...]\n+;;                        UNSPEC_COND_<MNEMONIC1>)\n+;;                (unspec [(match_operand:SI M)\n+;;                         (const_int SVE_RELAXED_GP)\n+;;                         ...]\n+;;                        UNSPEC_COND_<MNEMONIC2>) ...)\n+;;             ...])\n+;;\n ;; -------------------------------------------------------------------------\n ;; ---- Note on FFR handling\n ;; -------------------------------------------------------------------------\n@@ -3304,18 +3393,18 @@\n )\n \n ;; Predicated floating-point unary arithmetic, merging with the first input.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_2\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_2_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 3)\n-\t      (match_operand:SI 4 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w\")]\n \t     SVE_COND_FP_UNARY)\n \t   (match_dup 2)]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE && aarch64_sve_pred_dominates_p (&operands[3], operands[1])\"\n+  \"TARGET_SVE\"\n   \"@\n    <sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>\n    movprfx\\t%0, %2\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>\"\n@@ -3326,6 +3415,24 @@\n   [(set_attr \"movprfx\" \"*,yes\")]\n )\n \n+(define_insn \"*cond_<optab><mode>_2_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w\")]\n+\t     SVE_COND_FP_UNARY)\n+\t   (match_dup 2)]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\"\n+  \"@\n+   <sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>\n+   movprfx\\t%0, %2\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>\"\n+  [(set_attr \"movprfx\" \"*,yes\")]\n+)\n+\n ;; Predicated floating-point unary arithmetic, merging with an independent\n ;; value.\n ;;\n@@ -3334,20 +3441,18 @@\n ;; which is handled above rather than here.  Marking all the alternatives\n ;; as earlyclobber helps to make the instruction more regular to the\n ;; register allocator.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_any\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_any_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, ?&w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 4)\n-\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w, w\")]\n \t     SVE_COND_FP_UNARY)\n \t   (match_operand:SVE_FULL_F 3 \"aarch64_simd_reg_or_zero\" \"0, Dz, w\")]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE\n-   && !rtx_equal_p (operands[2], operands[3])\n-   && aarch64_sve_pred_dominates_p (&operands[4], operands[1])\"\n+  \"TARGET_SVE && !rtx_equal_p (operands[2], operands[3])\"\n   \"@\n    <sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>\n    movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>\n@@ -3359,6 +3464,25 @@\n   [(set_attr \"movprfx\" \"*,yes,yes\")]\n )\n \n+(define_insn \"*cond_<optab><mode>_any_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, ?&w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w, w\")]\n+\t     SVE_COND_FP_UNARY)\n+\t   (match_operand:SVE_FULL_F 3 \"aarch64_simd_reg_or_zero\" \"0, Dz, w\")]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE && !rtx_equal_p (operands[2], operands[3])\"\n+  \"@\n+   <sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>\n+   movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>\n+   movprfx\\t%0, %3\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>\"\n+  [(set_attr \"movprfx\" \"*,yes,yes\")]\n+)\n+\n ;; -------------------------------------------------------------------------\n ;; ---- [FP] Square root\n ;; -------------------------------------------------------------------------\n@@ -4649,19 +4773,19 @@\n \n ;; Predicated floating-point binary operations that take an integer as their\n ;; second operand, with inactive lanes coming from the first operand.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_2\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_2_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 4)\n-\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w\")\n \t      (match_operand:<V_INT_EQUIV> 3 \"register_operand\" \"w, w\")]\n \t     SVE_COND_FP_BINARY_INT)\n \t   (match_dup 2)]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE && aarch64_sve_pred_dominates_p (&operands[4], operands[1])\"\n+  \"TARGET_SVE\"\n   \"@\n    <sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n    movprfx\\t%0, %2\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\"\n@@ -4672,24 +4796,41 @@\n   [(set_attr \"movprfx\" \"*,yes\")]\n )\n \n+(define_insn \"*cond_<optab><mode>_2_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w\")\n+\t      (match_operand:<V_INT_EQUIV> 3 \"register_operand\" \"w, w\")]\n+\t     SVE_COND_FP_BINARY_INT)\n+\t   (match_dup 2)]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\"\n+  \"@\n+   <sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n+   movprfx\\t%0, %2\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\"\n+  [(set_attr \"movprfx\" \"*,yes\")]\n+)\n+\n ;; Predicated floating-point binary operations that take an integer as\n ;; their second operand, with the values of inactive lanes being distinct\n ;; from the other inputs.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_any\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_any_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, &w, &w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 5)\n-\t      (match_operand:SI 6 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w, w, w\")\n \t      (match_operand:<V_INT_EQUIV> 3 \"register_operand\" \"w, w, w, w\")]\n \t     SVE_COND_FP_BINARY_INT)\n \t   (match_operand:SVE_FULL_F 4 \"aarch64_simd_reg_or_zero\" \"Dz, Dz, 0, w\")]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE\n-   && !rtx_equal_p (operands[2], operands[4])\n-   && aarch64_sve_pred_dominates_p (&operands[5], operands[1])\"\n+  \"TARGET_SVE && !rtx_equal_p (operands[2], operands[4])\"\n   \"@\n    movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n    movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n@@ -4713,6 +4854,35 @@\n   [(set_attr \"movprfx\" \"yes\")]\n )\n \n+(define_insn_and_rewrite \"*cond_<optab><mode>_any_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, &w, &w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w, w, w\")\n+\t      (match_operand:<V_INT_EQUIV> 3 \"register_operand\" \"w, w, w, w\")]\n+\t     SVE_COND_FP_BINARY_INT)\n+\t   (match_operand:SVE_FULL_F 4 \"aarch64_simd_reg_or_zero\" \"Dz, Dz, 0, w\")]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE && !rtx_equal_p (operands[2], operands[4])\"\n+  \"@\n+   movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n+   movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n+   movprfx\\t%0.<Vetype>, %1/m, %2.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n+   #\"\n+  \"&& reload_completed\n+   && register_operand (operands[4], <MODE>mode)\n+   && !rtx_equal_p (operands[0], operands[4])\"\n+  {\n+    emit_insn (gen_vcond_mask_<mode><vpred> (operands[0], operands[2],\n+\t\t\t\t\t     operands[4], operands[1]));\n+    operands[4] = operands[2] = operands[0];\n+  }\n+  [(set_attr \"movprfx\" \"yes\")]\n+)\n+\n ;; -------------------------------------------------------------------------\n ;; ---- [FP] General binary arithmetic corresponding to rtx codes\n ;; -------------------------------------------------------------------------\n@@ -4813,19 +4983,19 @@\n )\n \n ;; Predicated floating-point operations, merging with the first input.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_2\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_2_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 4)\n-\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w\")\n \t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w\")]\n \t     SVE_COND_FP_BINARY)\n \t   (match_dup 2)]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE && aarch64_sve_pred_dominates_p (&operands[4], operands[1])\"\n+  \"TARGET_SVE\"\n   \"@\n    <sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n    movprfx\\t%0, %2\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\"\n@@ -4836,20 +5006,39 @@\n   [(set_attr \"movprfx\" \"*,yes\")]\n )\n \n+(define_insn \"*cond_<optab><mode>_2_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w\")\n+\t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w\")]\n+\t     SVE_COND_FP_BINARY)\n+\t   (match_dup 2)]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\"\n+  \"@\n+   <sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n+   movprfx\\t%0, %2\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\"\n+  [(set_attr \"movprfx\" \"*,yes\")]\n+)\n+\n ;; Same for operations that take a 1-bit constant.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_2_const\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_2_const_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 4)\n-\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w\")\n \t      (match_operand:SVE_FULL_F 3 \"<sve_pred_fp_rhs2_immediate>\")]\n \t     SVE_COND_FP_BINARY_I1)\n \t   (match_dup 2)]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE && aarch64_sve_pred_dominates_p (&operands[4], operands[1])\"\n+  \"TARGET_SVE\"\n   \"@\n    <sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%3\n    movprfx\\t%0, %2\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%3\"\n@@ -4860,20 +5049,39 @@\n   [(set_attr \"movprfx\" \"*,yes\")]\n )\n \n+(define_insn \"*cond_<optab><mode>_2_const_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w\")\n+\t      (match_operand:SVE_FULL_F 3 \"<sve_pred_fp_rhs2_immediate>\")]\n+\t     SVE_COND_FP_BINARY_I1)\n+\t   (match_dup 2)]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\"\n+  \"@\n+   <sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%3\n+   movprfx\\t%0, %2\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%3\"\n+  [(set_attr \"movprfx\" \"*,yes\")]\n+)\n+\n ;; Predicated floating-point operations, merging with the second input.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_3\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_3_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 4)\n-\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w\")\n \t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"0, w\")]\n \t     SVE_COND_FP_BINARY)\n \t   (match_dup 3)]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE && aarch64_sve_pred_dominates_p (&operands[4], operands[1])\"\n+  \"TARGET_SVE\"\n   \"@\n    <sve_fp_op_rev>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %2.<Vetype>\n    movprfx\\t%0, %3\\;<sve_fp_op_rev>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %2.<Vetype>\"\n@@ -4884,23 +5092,41 @@\n   [(set_attr \"movprfx\" \"*,yes\")]\n )\n \n+(define_insn \"*cond_<optab><mode>_3_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w\")\n+\t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"0, w\")]\n+\t     SVE_COND_FP_BINARY)\n+\t   (match_dup 3)]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\"\n+  \"@\n+   <sve_fp_op_rev>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %2.<Vetype>\n+   movprfx\\t%0, %3\\;<sve_fp_op_rev>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %2.<Vetype>\"\n+  [(set_attr \"movprfx\" \"*,yes\")]\n+)\n+\n ;; Predicated floating-point operations, merging with an independent value.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_any\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_any_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, &w, &w, &w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 5)\n-\t      (match_operand:SI 6 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w, w, w, w\")\n \t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, 0, w, w, w\")]\n \t     SVE_COND_FP_BINARY)\n \t   (match_operand:SVE_FULL_F 4 \"aarch64_simd_reg_or_zero\" \"Dz, Dz, Dz, 0, w\")]\n \t  UNSPEC_SEL))]\n   \"TARGET_SVE\n    && !rtx_equal_p (operands[2], operands[4])\n-   && !rtx_equal_p (operands[3], operands[4])\n-   && aarch64_sve_pred_dominates_p (&operands[5], operands[1])\"\n+   && !rtx_equal_p (operands[3], operands[4])\"\n   \"@\n    movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n    movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;<sve_fp_op_rev>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %2.<Vetype>\n@@ -4925,22 +5151,52 @@\n   [(set_attr \"movprfx\" \"yes\")]\n )\n \n+(define_insn_and_rewrite \"*cond_<optab><mode>_any_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, &w, &w, &w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w, w, w, w\")\n+\t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, 0, w, w, w\")]\n+\t     SVE_COND_FP_BINARY)\n+\t   (match_operand:SVE_FULL_F 4 \"aarch64_simd_reg_or_zero\" \"Dz, Dz, Dz, 0, w\")]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\n+   && !rtx_equal_p (operands[2], operands[4])\n+   && !rtx_equal_p (operands[3], operands[4])\"\n+  \"@\n+   movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n+   movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;<sve_fp_op_rev>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %2.<Vetype>\n+   movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n+   movprfx\\t%0.<Vetype>, %1/m, %2.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n+   #\"\n+  \"&& reload_completed\n+   && register_operand (operands[4], <MODE>mode)\n+   && !rtx_equal_p (operands[0], operands[4])\"\n+  {\n+    emit_insn (gen_vcond_mask_<mode><vpred> (operands[0], operands[2],\n+\t\t\t\t\t     operands[4], operands[1]));\n+    operands[4] = operands[2] = operands[0];\n+  }\n+  [(set_attr \"movprfx\" \"yes\")]\n+)\n+\n ;; Same for operations that take a 1-bit constant.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_any_const\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_any_const_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, w, ?w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 5)\n-\t      (match_operand:SI 6 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w, w\")\n \t      (match_operand:SVE_FULL_F 3 \"<sve_pred_fp_rhs2_immediate>\")]\n \t     SVE_COND_FP_BINARY_I1)\n \t   (match_operand:SVE_FULL_F 4 \"aarch64_simd_reg_or_zero\" \"Dz, 0, w\")]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE\n-   && !rtx_equal_p (operands[2], operands[4])\n-   && aarch64_sve_pred_dominates_p (&operands[5], operands[1])\"\n+  \"TARGET_SVE && !rtx_equal_p (operands[2], operands[4])\"\n   \"@\n    movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%3\n    movprfx\\t%0.<Vetype>, %1/m, %2.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%3\n@@ -4963,6 +5219,34 @@\n   [(set_attr \"movprfx\" \"yes\")]\n )\n \n+(define_insn_and_rewrite \"*cond_<optab><mode>_any_const_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, w, ?w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w, w\")\n+\t      (match_operand:SVE_FULL_F 3 \"<sve_pred_fp_rhs2_immediate>\")]\n+\t     SVE_COND_FP_BINARY_I1)\n+\t   (match_operand:SVE_FULL_F 4 \"aarch64_simd_reg_or_zero\" \"Dz, 0, w\")]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE && !rtx_equal_p (operands[2], operands[4])\"\n+  \"@\n+   movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%3\n+   movprfx\\t%0.<Vetype>, %1/m, %2.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%3\n+   #\"\n+  \"&& reload_completed\n+   && register_operand (operands[4], <MODE>mode)\n+   && !rtx_equal_p (operands[0], operands[4])\"\n+  {\n+    emit_insn (gen_vcond_mask_<mode><vpred> (operands[0], operands[2],\n+\t\t\t\t\t     operands[4], operands[1]));\n+    operands[4] = operands[2] = operands[0];\n+  }\n+  [(set_attr \"movprfx\" \"yes\")]\n+)\n+\n ;; -------------------------------------------------------------------------\n ;; ---- [FP] Addition\n ;; -------------------------------------------------------------------------\n@@ -5001,19 +5285,19 @@\n \n ;; Predicated floating-point addition of a constant, merging with the\n ;; first input.\n-(define_insn_and_rewrite \"*cond_add<mode>_2_const\"\n+(define_insn_and_rewrite \"*cond_add<mode>_2_const_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, w, ?w, ?w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 4)\n-\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, 0, w, w\")\n \t      (match_operand:SVE_FULL_F 3 \"aarch64_sve_float_arith_with_sub_immediate\" \"vsA, vsN, vsA, vsN\")]\n \t     UNSPEC_COND_FADD)\n \t   (match_dup 2)]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE && aarch64_sve_pred_dominates_p (&operands[4], operands[1])\"\n+  \"TARGET_SVE\"\n   \"@\n    fadd\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%3\n    fsub\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%N3\n@@ -5026,23 +5310,42 @@\n   [(set_attr \"movprfx\" \"*,*,yes,yes\")]\n )\n \n+(define_insn \"*cond_add<mode>_2_const_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, w, ?w, ?w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, 0, w, w\")\n+\t      (match_operand:SVE_FULL_F 3 \"aarch64_sve_float_arith_with_sub_immediate\" \"vsA, vsN, vsA, vsN\")]\n+\t     UNSPEC_COND_FADD)\n+\t   (match_dup 2)]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\"\n+  \"@\n+   fadd\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%3\n+   fsub\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%N3\n+   movprfx\\t%0, %2\\;fadd\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%3\n+   movprfx\\t%0, %2\\;fsub\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%N3\"\n+  [(set_attr \"movprfx\" \"*,*,yes,yes\")]\n+)\n+\n ;; Predicated floating-point addition of a constant, merging with an\n ;; independent value.\n-(define_insn_and_rewrite \"*cond_add<mode>_any_const\"\n+(define_insn_and_rewrite \"*cond_add<mode>_any_const_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, w, w, w, ?w, ?w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl, Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 5)\n-\t      (match_operand:SI 6 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w, w, w, w, w\")\n \t      (match_operand:SVE_FULL_F 3 \"aarch64_sve_float_arith_with_sub_immediate\" \"vsA, vsN, vsA, vsN, vsA, vsN\")]\n \t     UNSPEC_COND_FADD)\n \t   (match_operand:SVE_FULL_F 4 \"aarch64_simd_reg_or_zero\" \"Dz, Dz, 0, 0, w, w\")]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE\n-   && !rtx_equal_p (operands[2], operands[4])\n-   && aarch64_sve_pred_dominates_p (&operands[5], operands[1])\"\n+  \"TARGET_SVE && !rtx_equal_p (operands[2], operands[4])\"\n   \"@\n    movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;fadd\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%3\n    movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;fsub\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%N3\n@@ -5068,6 +5371,37 @@\n   [(set_attr \"movprfx\" \"yes\")]\n )\n \n+(define_insn_and_rewrite \"*cond_add<mode>_any_const_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, w, w, w, ?w, ?w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl, Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w, w, w, w, w\")\n+\t      (match_operand:SVE_FULL_F 3 \"aarch64_sve_float_arith_with_sub_immediate\" \"vsA, vsN, vsA, vsN, vsA, vsN\")]\n+\t     UNSPEC_COND_FADD)\n+\t   (match_operand:SVE_FULL_F 4 \"aarch64_simd_reg_or_zero\" \"Dz, Dz, 0, 0, w, w\")]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE && !rtx_equal_p (operands[2], operands[4])\"\n+  \"@\n+   movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;fadd\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%3\n+   movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;fsub\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%N3\n+   movprfx\\t%0.<Vetype>, %1/m, %2.<Vetype>\\;fadd\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%3\n+   movprfx\\t%0.<Vetype>, %1/m, %2.<Vetype>\\;fsub\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%N3\n+   #\n+   #\"\n+  \"&& reload_completed\n+   && register_operand (operands[4], <MODE>mode)\n+   && !rtx_equal_p (operands[0], operands[4])\"\n+  {\n+    emit_insn (gen_vcond_mask_<mode><vpred> (operands[0], operands[2],\n+\t\t\t\t\t     operands[4], operands[1]));\n+    operands[4] = operands[2] = operands[0];\n+  }\n+  [(set_attr \"movprfx\" \"yes\")]\n+)\n+\n ;; Register merging forms are handled through SVE_COND_FP_BINARY.\n \n ;; -------------------------------------------------------------------------\n@@ -5110,19 +5444,19 @@\n )\n \n ;; Predicated FCADD, merging with the first input.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_2\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_2_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 4)\n-\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w\")\n \t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w\")]\n \t     SVE_COND_FCADD)\n \t   (match_dup 2)]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE && aarch64_sve_pred_dominates_p (&operands[4], operands[1])\"\n+  \"TARGET_SVE\"\n   \"@\n    fcadd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>, #<rot>\n    movprfx\\t%0, %2\\;fcadd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>, #<rot>\"\n@@ -5133,22 +5467,39 @@\n   [(set_attr \"movprfx\" \"*,yes\")]\n )\n \n+(define_insn \"*cond_<optab><mode>_2_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w\")\n+\t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w\")]\n+\t     SVE_COND_FCADD)\n+\t   (match_dup 2)]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\"\n+  \"@\n+   fcadd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>, #<rot>\n+   movprfx\\t%0, %2\\;fcadd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>, #<rot>\"\n+  [(set_attr \"movprfx\" \"*,yes\")]\n+)\n+\n ;; Predicated FCADD, merging with an independent value.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_any\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_any_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, &w, &w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 5)\n-\t      (match_operand:SI 6 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, 0, w, w\")\n \t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w, w, w\")]\n \t     SVE_COND_FCADD)\n \t   (match_operand:SVE_FULL_F 4 \"aarch64_simd_reg_or_zero\" \"Dz, Dz, 0, w\")]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE\n-   && !rtx_equal_p (operands[2], operands[4])\n-   && aarch64_sve_pred_dominates_p (&operands[5], operands[1])\"\n+  \"TARGET_SVE && !rtx_equal_p (operands[2], operands[4])\"\n   \"@\n    movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;fcadd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>, #<rot>\n    movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;fcadd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>, #<rot>\n@@ -5172,6 +5523,35 @@\n   [(set_attr \"movprfx\" \"yes\")]\n )\n \n+(define_insn_and_rewrite \"*cond_<optab><mode>_any_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, &w, &w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, 0, w, w\")\n+\t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w, w, w\")]\n+\t     SVE_COND_FCADD)\n+\t   (match_operand:SVE_FULL_F 4 \"aarch64_simd_reg_or_zero\" \"Dz, Dz, 0, w\")]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE && !rtx_equal_p (operands[2], operands[4])\"\n+  \"@\n+   movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;fcadd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>, #<rot>\n+   movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;fcadd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>, #<rot>\n+   movprfx\\t%0.<Vetype>, %1/m, %2.<Vetype>\\;fcadd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>, #<rot>\n+   #\"\n+  \"&& reload_completed\n+   && register_operand (operands[4], <MODE>mode)\n+   && !rtx_equal_p (operands[0], operands[4])\"\n+  {\n+    emit_insn (gen_vcond_mask_<mode><vpred> (operands[0], operands[2],\n+\t\t\t\t\t     operands[4], operands[1]));\n+    operands[4] = operands[2] = operands[0];\n+  }\n+  [(set_attr \"movprfx\" \"yes\")]\n+)\n+\n ;; -------------------------------------------------------------------------\n ;; ---- [FP] Subtraction\n ;; -------------------------------------------------------------------------\n@@ -5209,19 +5589,19 @@\n \n ;; Predicated floating-point subtraction from a constant, merging with the\n ;; second input.\n-(define_insn_and_rewrite \"*cond_sub<mode>_3_const\"\n+(define_insn_and_rewrite \"*cond_sub<mode>_3_const_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 4)\n-\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"aarch64_sve_float_arith_immediate\")\n \t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"0, w\")]\n \t     UNSPEC_COND_FSUB)\n \t   (match_dup 3)]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE && aarch64_sve_pred_dominates_p (&operands[4], operands[1])\"\n+  \"TARGET_SVE\"\n   \"@\n    fsubr\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%2\n    movprfx\\t%0, %3\\;fsubr\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%2\"\n@@ -5232,12 +5612,28 @@\n   [(set_attr \"movprfx\" \"*,yes\")]\n )\n \n+(define_insn \"*cond_sub<mode>_3_const_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"aarch64_sve_float_arith_immediate\")\n+\t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"0, w\")]\n+\t     UNSPEC_COND_FSUB)\n+\t   (match_dup 3)]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\"\n+  \"@\n+   fsubr\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%2\n+   movprfx\\t%0, %3\\;fsubr\\t%0.<Vetype>, %1/m, %0.<Vetype>, #%2\"\n+  [(set_attr \"movprfx\" \"*,yes\")]\n+)\n+\n ;; Predicated floating-point subtraction from a constant, merging with an\n ;; independent value.\n-;;\n-;; The subtraction predicate and the merge predicate are allowed to be\n-;; different.\n-(define_insn_and_rewrite \"*cond_sub<mode>_relaxed_const\"\n+(define_insn_and_rewrite \"*cond_sub<mode>_const_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, w, ?w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl\")\n@@ -5272,11 +5668,7 @@\n   [(set_attr \"movprfx\" \"yes\")]\n )\n \n-;; Predicated floating-point subtraction from a constant, merging with an\n-;; independent value.\n-;;\n-;; The subtraction predicate and the merge predicate must be the same.\n-(define_insn_and_rewrite \"*cond_sub<mode>_strict_const\"\n+(define_insn_and_rewrite \"*cond_sub<mode>_const_strict\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, w, ?w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl\")\n@@ -5329,19 +5721,19 @@\n )\n \n ;; Predicated floating-point absolute difference.\n-(define_insn_and_rewrite \"*aarch64_pred_abd<mode>\"\n+(define_insn_and_rewrite \"*aarch64_pred_abd<mode>_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n \t   (match_operand:SI 4 \"aarch64_sve_gp_strictness\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 5)\n-\t      (match_operand:SI 6 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"%0, w\")\n \t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w\")]\n \t     UNSPEC_COND_FSUB)]\n \t  UNSPEC_COND_FABS))]\n-  \"TARGET_SVE && aarch64_sve_pred_dominates_p (&operands[5], operands[1])\"\n+  \"TARGET_SVE\"\n   \"@\n    fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n    movprfx\\t%0, %2\\;fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\"\n@@ -5352,6 +5744,25 @@\n   [(set_attr \"movprfx\" \"*,yes\")]\n )\n \n+(define_insn \"*aarch64_pred_abd<mode>_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n+\t   (match_operand:SI 4 \"aarch64_sve_gp_strictness\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"%0, w\")\n+\t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w\")]\n+\t     UNSPEC_COND_FSUB)]\n+\t  UNSPEC_COND_FABS))]\n+  \"TARGET_SVE\"\n+  \"@\n+   fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n+   movprfx\\t%0, %2\\;fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\"\n+  [(set_attr \"movprfx\" \"*,yes\")]\n+)\n+\n (define_expand \"@aarch64_cond_abd<mode>\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\")\n \t(unspec:SVE_FULL_F\n@@ -5376,82 +5787,124 @@\n \n ;; Predicated floating-point absolute difference, merging with the first\n ;; input.\n-(define_insn_and_rewrite \"*aarch64_cond_abd<mode>_2\"\n+(define_insn_and_rewrite \"*aarch64_cond_abd<mode>_2_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 4)\n-\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (unspec:SVE_FULL_F\n-\t\t[(match_operand 6)\n-\t\t (match_operand:SI 7 \"aarch64_sve_gp_strictness\")\n+\t\t[(match_operand 5)\n+\t\t (const_int SVE_RELAXED_GP)\n \t\t (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w\")\n \t\t (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w\")]\n \t\tUNSPEC_COND_FSUB)]\n \t     UNSPEC_COND_FABS)\n \t   (match_dup 2)]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE\n-   && aarch64_sve_pred_dominates_p (&operands[4], operands[1])\n-   && aarch64_sve_pred_dominates_p (&operands[6], operands[1])\"\n+  \"TARGET_SVE\"\n   \"@\n    fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n    movprfx\\t%0, %2\\;fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\"\n   \"&& (!rtx_equal_p (operands[1], operands[4])\n-       || !rtx_equal_p (operands[1], operands[6]))\"\n+       || !rtx_equal_p (operands[1], operands[5]))\"\n   {\n     operands[4] = copy_rtx (operands[1]);\n-    operands[6] = copy_rtx (operands[1]);\n+    operands[5] = copy_rtx (operands[1]);\n   }\n   [(set_attr \"movprfx\" \"*,yes\")]\n )\n \n+(define_insn \"*aarch64_cond_abd<mode>_2_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (match_operand:SI 4 \"aarch64_sve_gp_strictness\")\n+\t      (unspec:SVE_FULL_F\n+\t\t[(match_dup 1)\n+\t\t (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t\t (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w\")\n+\t\t (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w\")]\n+\t\tUNSPEC_COND_FSUB)]\n+\t     UNSPEC_COND_FABS)\n+\t   (match_dup 2)]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\"\n+  \"@\n+   fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n+   movprfx\\t%0, %2\\;fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\"\n+  [(set_attr \"movprfx\" \"*,yes\")]\n+)\n+\n ;; Predicated floating-point absolute difference, merging with the second\n ;; input.\n-(define_insn_and_rewrite \"*aarch64_cond_abd<mode>_3\"\n+(define_insn_and_rewrite \"*aarch64_cond_abd<mode>_3_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 4)\n-\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (unspec:SVE_FULL_F\n-\t\t[(match_operand 6)\n-\t\t (match_operand:SI 7 \"aarch64_sve_gp_strictness\")\n+\t\t[(match_operand 5)\n+\t\t (const_int SVE_RELAXED_GP)\n \t\t (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w\")\n \t\t (match_operand:SVE_FULL_F 3 \"register_operand\" \"0, w\")]\n \t\tUNSPEC_COND_FSUB)]\n \t     UNSPEC_COND_FABS)\n \t   (match_dup 3)]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE\n-   && aarch64_sve_pred_dominates_p (&operands[4], operands[1])\n-   && aarch64_sve_pred_dominates_p (&operands[6], operands[1])\"\n+  \"TARGET_SVE\"\n   \"@\n    fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %2.<Vetype>\n    movprfx\\t%0, %3\\;fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %2.<Vetype>\"\n   \"&& (!rtx_equal_p (operands[1], operands[4])\n-       || !rtx_equal_p (operands[1], operands[6]))\"\n+       || !rtx_equal_p (operands[1], operands[5]))\"\n   {\n     operands[4] = copy_rtx (operands[1]);\n-    operands[6] = copy_rtx (operands[1]);\n+    operands[5] = copy_rtx (operands[1]);\n   }\n   [(set_attr \"movprfx\" \"*,yes\")]\n )\n \n+(define_insn \"*aarch64_cond_abd<mode>_3_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (match_operand:SI 4 \"aarch64_sve_gp_strictness\")\n+\t      (unspec:SVE_FULL_F\n+\t\t[(match_dup 1)\n+\t\t (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t\t (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w\")\n+\t\t (match_operand:SVE_FULL_F 3 \"register_operand\" \"0, w\")]\n+\t\tUNSPEC_COND_FSUB)]\n+\t     UNSPEC_COND_FABS)\n+\t   (match_dup 3)]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\"\n+  \"@\n+   fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %2.<Vetype>\n+   movprfx\\t%0, %3\\;fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %2.<Vetype>\"\n+  [(set_attr \"movprfx\" \"*,yes\")]\n+)\n+\n ;; Predicated floating-point absolute difference, merging with an\n ;; independent value.\n-(define_insn_and_rewrite \"*aarch64_cond_abd<mode>_any\"\n+(define_insn_and_rewrite \"*aarch64_cond_abd<mode>_any_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, &w, &w, &w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 5)\n-\t      (match_operand:SI 6 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (unspec:SVE_FULL_F\n-\t\t[(match_operand 7)\n-\t\t (match_operand:SI 8 \"aarch64_sve_gp_strictness\")\n+\t\t[(match_operand 6)\n+\t\t (const_int SVE_RELAXED_GP)\n \t\t (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w, w, w, w\")\n \t\t (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, 0, w, w, w\")]\n \t\tUNSPEC_COND_FSUB)]\n@@ -5460,9 +5913,7 @@\n \t  UNSPEC_SEL))]\n   \"TARGET_SVE\n    && !rtx_equal_p (operands[2], operands[4])\n-   && !rtx_equal_p (operands[3], operands[4])\n-   && aarch64_sve_pred_dominates_p (&operands[5], operands[1])\n-   && aarch64_sve_pred_dominates_p (&operands[7], operands[1])\"\n+   && !rtx_equal_p (operands[3], operands[4])\"\n   \"@\n    movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n    movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %2.<Vetype>\n@@ -5472,25 +5923,61 @@\n   \"&& 1\"\n   {\n     if (reload_completed\n-        && register_operand (operands[4], <MODE>mode)\n-        && !rtx_equal_p (operands[0], operands[4]))\n+\t&& register_operand (operands[4], <MODE>mode)\n+\t&& !rtx_equal_p (operands[0], operands[4]))\n       {\n \temit_insn (gen_vcond_mask_<mode><vpred> (operands[0], operands[3],\n \t\t\t\t\t\t operands[4], operands[1]));\n \toperands[4] = operands[3] = operands[0];\n       }\n     else if (!rtx_equal_p (operands[1], operands[5])\n-\t     || !rtx_equal_p (operands[1], operands[7]))\n+\t     || !rtx_equal_p (operands[1], operands[6]))\n       {\n \toperands[5] = copy_rtx (operands[1]);\n-\toperands[7] = copy_rtx (operands[1]);\n+\toperands[6] = copy_rtx (operands[1]);\n       }\n     else\n       FAIL;\n   }\n   [(set_attr \"movprfx\" \"yes\")]\n )\n \n+(define_insn_and_rewrite \"*aarch64_cond_abd<mode>_any_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, &w, &w, &w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (unspec:SVE_FULL_F\n+\t\t[(match_dup 1)\n+\t\t (match_operand:SI 6 \"aarch64_sve_gp_strictness\")\n+\t\t (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w, w, w, w\")\n+\t\t (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, 0, w, w, w\")]\n+\t\tUNSPEC_COND_FSUB)]\n+\t     UNSPEC_COND_FABS)\n+\t   (match_operand:SVE_FULL_F 4 \"aarch64_simd_reg_or_zero\" \"Dz, Dz, Dz, 0, w\")]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\n+   && !rtx_equal_p (operands[2], operands[4])\n+   && !rtx_equal_p (operands[3], operands[4])\"\n+  \"@\n+   movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n+   movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %2.<Vetype>\n+   movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n+   movprfx\\t%0.<Vetype>, %1/m, %2.<Vetype>\\;fabd\\t%0.<Vetype>, %1/m, %0.<Vetype>, %3.<Vetype>\n+   #\"\n+  \"&& reload_completed\n+   && register_operand (operands[4], <MODE>mode)\n+   && !rtx_equal_p (operands[0], operands[4])\"\n+  {\n+    emit_insn (gen_vcond_mask_<mode><vpred> (operands[0], operands[3],\n+\t\t\t\t\t     operands[4], operands[1]));\n+    operands[4] = operands[3] = operands[0];\n+  }\n+  [(set_attr \"movprfx\" \"yes\")]\n+)\n+\n ;; -------------------------------------------------------------------------\n ;; ---- [FP] Multiplication\n ;; -------------------------------------------------------------------------\n@@ -6416,20 +6903,20 @@\n \n ;; Predicated floating-point ternary operations, merging with the\n ;; first input.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_2\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_2_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 5)\n-\t      (match_operand:SI 6 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w\")\n \t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w\")\n \t      (match_operand:SVE_FULL_F 4 \"register_operand\" \"w, w\")]\n \t     SVE_COND_FP_TERNARY)\n \t   (match_dup 2)]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE && aarch64_sve_pred_dominates_p (&operands[5], operands[1])\"\n+  \"TARGET_SVE\"\n   \"@\n    <sve_fmad_op>\\t%0.<Vetype>, %1/m, %3.<Vetype>, %4.<Vetype>\n    movprfx\\t%0, %2\\;<sve_fmad_op>\\t%0.<Vetype>, %1/m, %3.<Vetype>, %4.<Vetype>\"\n@@ -6440,22 +6927,42 @@\n   [(set_attr \"movprfx\" \"*,yes\")]\n )\n \n+(define_insn \"*cond_<optab><mode>_2_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"0, w\")\n+\t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w\")\n+\t      (match_operand:SVE_FULL_F 4 \"register_operand\" \"w, w\")]\n+\t     SVE_COND_FP_TERNARY)\n+\t   (match_dup 2)]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\"\n+  \"@\n+   <sve_fmad_op>\\t%0.<Vetype>, %1/m, %3.<Vetype>, %4.<Vetype>\n+   movprfx\\t%0, %2\\;<sve_fmad_op>\\t%0.<Vetype>, %1/m, %3.<Vetype>, %4.<Vetype>\"\n+  [(set_attr \"movprfx\" \"*,yes\")]\n+)\n+\n ;; Predicated floating-point ternary operations, merging with the\n ;; third input.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_4\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_4_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 5)\n-\t      (match_operand:SI 6 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w\")\n \t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w\")\n \t      (match_operand:SVE_FULL_F 4 \"register_operand\" \"0, w\")]\n \t     SVE_COND_FP_TERNARY)\n \t   (match_dup 4)]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE && aarch64_sve_pred_dominates_p (&operands[5], operands[1])\"\n+  \"TARGET_SVE\"\n   \"@\n    <sve_fmla_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>\n    movprfx\\t%0, %4\\;<sve_fmla_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>\"\n@@ -6466,15 +6973,35 @@\n   [(set_attr \"movprfx\" \"*,yes\")]\n )\n \n+(define_insn \"*cond_<optab><mode>_4_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w\")\n+\t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w\")\n+\t      (match_operand:SVE_FULL_F 4 \"register_operand\" \"0, w\")]\n+\t     SVE_COND_FP_TERNARY)\n+\t   (match_dup 4)]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\"\n+  \"@\n+   <sve_fmla_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>\n+   movprfx\\t%0, %4\\;<sve_fmla_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>\"\n+  [(set_attr \"movprfx\" \"*,yes\")]\n+)\n+\n ;; Predicated floating-point ternary operations, merging with an\n ;; independent value.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_any\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_any_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, &w, &w, &w, &w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl, Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 6)\n-\t      (match_operand:SI 7 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w, 0, w, w, w\")\n \t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w, w, 0, w, w\")\n \t      (match_operand:SVE_FULL_F 4 \"register_operand\" \"w, 0, w, w, w, w\")]\n@@ -6484,8 +7011,7 @@\n   \"TARGET_SVE\n    && !rtx_equal_p (operands[2], operands[5])\n    && !rtx_equal_p (operands[3], operands[5])\n-   && !rtx_equal_p (operands[4], operands[5])\n-   && aarch64_sve_pred_dominates_p (&operands[6], operands[1])\"\n+   && !rtx_equal_p (operands[4], operands[5])\"\n   \"@\n    movprfx\\t%0.<Vetype>, %1/z, %4.<Vetype>\\;<sve_fmla_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>\n    movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;<sve_fmla_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>\n@@ -6511,6 +7037,41 @@\n   [(set_attr \"movprfx\" \"yes\")]\n )\n \n+(define_insn_and_rewrite \"*cond_<optab><mode>_any_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, &w, &w, &w, &w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl, Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w, 0, w, w, w\")\n+\t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w, w, 0, w, w\")\n+\t      (match_operand:SVE_FULL_F 4 \"register_operand\" \"w, 0, w, w, w, w\")]\n+\t     SVE_COND_FP_TERNARY)\n+\t   (match_operand:SVE_FULL_F 5 \"aarch64_simd_reg_or_zero\" \"Dz, Dz, Dz, Dz, 0, w\")]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\n+   && !rtx_equal_p (operands[2], operands[5])\n+   && !rtx_equal_p (operands[3], operands[5])\n+   && !rtx_equal_p (operands[4], operands[5])\"\n+  \"@\n+   movprfx\\t%0.<Vetype>, %1/z, %4.<Vetype>\\;<sve_fmla_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>\n+   movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;<sve_fmla_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>\n+   movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;<sve_fmad_op>\\t%0.<Vetype>, %1/m, %3.<Vetype>, %4.<Vetype>\n+   movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;<sve_fmad_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>, %4.<Vetype>\n+   movprfx\\t%0.<Vetype>, %1/m, %4.<Vetype>\\;<sve_fmla_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>\n+   #\"\n+  \"&& reload_completed\n+   && register_operand (operands[5], <MODE>mode)\n+   && !rtx_equal_p (operands[0], operands[5])\"\n+  {\n+    emit_insn (gen_vcond_mask_<mode><vpred> (operands[0], operands[4],\n+\t\t\t\t\t     operands[5], operands[1]));\n+    operands[5] = operands[4] = operands[0];\n+  }\n+  [(set_attr \"movprfx\" \"yes\")]\n+)\n+\n ;; Unpredicated FMLA and FMLS by selected lanes.  It doesn't seem worth using\n ;; (fma ...) since target-independent code won't understand the indexing.\n (define_insn \"@aarch64_<optab>_lane_<mode>\"\n@@ -6572,20 +7133,20 @@\n )\n \n ;; Predicated FCMLA, merging with the third input.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_4\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_4_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 5)\n-\t      (match_operand:SI 6 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w\")\n \t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w\")\n \t      (match_operand:SVE_FULL_F 4 \"register_operand\" \"0, w\")]\n \t     SVE_COND_FCMLA)\n \t   (match_dup 4)]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE && aarch64_sve_pred_dominates_p (&operands[5], operands[1])\"\n+  \"TARGET_SVE\"\n   \"@\n    fcmla\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>, #<rot>\n    movprfx\\t%0, %4\\;fcmla\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>, #<rot>\"\n@@ -6596,23 +7157,41 @@\n   [(set_attr \"movprfx\" \"*,yes\")]\n )\n \n+(define_insn \"*cond_<optab><mode>_4_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w\")\n+\t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w\")\n+\t      (match_operand:SVE_FULL_F 4 \"register_operand\" \"0, w\")]\n+\t     SVE_COND_FCMLA)\n+\t   (match_dup 4)]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE\"\n+  \"@\n+   fcmla\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>, #<rot>\n+   movprfx\\t%0, %4\\;fcmla\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>, #<rot>\"\n+  [(set_attr \"movprfx\" \"*,yes\")]\n+)\n+\n ;; Predicated FCMLA, merging with an independent value.\n-(define_insn_and_rewrite \"*cond_<optab><mode>_any\"\n+(define_insn_and_rewrite \"*cond_<optab><mode>_any_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, &w, &w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 6)\n-\t      (match_operand:SI 7 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w, w, w\")\n \t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w, w, w\")\n \t      (match_operand:SVE_FULL_F 4 \"register_operand\" \"w, 0, w, w\")]\n \t     SVE_COND_FCMLA)\n \t   (match_operand:SVE_FULL_F 5 \"aarch64_simd_reg_or_zero\" \"Dz, Dz, 0, w\")]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE\n-   && !rtx_equal_p (operands[4], operands[5])\n-   && aarch64_sve_pred_dominates_p (&operands[6], operands[1])\"\n+  \"TARGET_SVE && !rtx_equal_p (operands[4], operands[5])\"\n   \"@\n    movprfx\\t%0.<Vetype>, %1/z, %4.<Vetype>\\;fcmla\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>, #<rot>\n    movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;fcmla\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>, #<rot>\n@@ -6636,6 +7215,36 @@\n   [(set_attr \"movprfx\" \"yes\")]\n )\n \n+(define_insn_and_rewrite \"*cond_<optab><mode>_any_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, &w, &w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w, w, w\")\n+\t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w, w, w, w\")\n+\t      (match_operand:SVE_FULL_F 4 \"register_operand\" \"w, 0, w, w\")]\n+\t     SVE_COND_FCMLA)\n+\t   (match_operand:SVE_FULL_F 5 \"aarch64_simd_reg_or_zero\" \"Dz, Dz, 0, w\")]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE && !rtx_equal_p (operands[4], operands[5])\"\n+  \"@\n+   movprfx\\t%0.<Vetype>, %1/z, %4.<Vetype>\\;fcmla\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>, #<rot>\n+   movprfx\\t%0.<Vetype>, %1/z, %0.<Vetype>\\;fcmla\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>, #<rot>\n+   movprfx\\t%0.<Vetype>, %1/m, %4.<Vetype>\\;fcmla\\t%0.<Vetype>, %1/m, %2.<Vetype>, %3.<Vetype>, #<rot>\n+   #\"\n+  \"&& reload_completed\n+   && register_operand (operands[5], <MODE>mode)\n+   && !rtx_equal_p (operands[0], operands[5])\"\n+  {\n+    emit_insn (gen_vcond_mask_<mode><vpred> (operands[0], operands[4],\n+\t\t\t\t\t     operands[5], operands[1]));\n+    operands[5] = operands[4] = operands[0];\n+  }\n+  [(set_attr \"movprfx\" \"yes\")]\n+)\n+\n ;; Unpredicated FCMLA with indexing.\n (define_insn \"@aarch64_<optab>_lane_<mode>\"\n   [(set (match_operand:SVE_FULL_HSF 0 \"register_operand\" \"=w, ?&w\")\n@@ -7328,34 +7937,52 @@\n   \"TARGET_SVE\"\n )\n \n-(define_insn_and_rewrite \"*aarch64_pred_fac<cmp_op><mode>\"\n+(define_insn_and_rewrite \"*aarch64_pred_fac<cmp_op><mode>_relaxed\"\n   [(set (match_operand:<VPRED> 0 \"register_operand\" \"=Upa\")\n \t(unspec:<VPRED>\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl\")\n \t   (match_operand:SI 4 \"aarch64_sve_ptrue_flag\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 5)\n-\t      (match_operand:SI 6 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w\")]\n \t     UNSPEC_COND_FABS)\n \t   (unspec:SVE_FULL_F\n-\t     [(match_operand 7)\n-\t      (match_operand:SI 8 \"aarch64_sve_gp_strictness\")\n+\t     [(match_operand 6)\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w\")]\n \t     UNSPEC_COND_FABS)]\n \t  SVE_COND_FP_ABS_CMP))]\n-  \"TARGET_SVE\n-   && aarch64_sve_pred_dominates_p (&operands[5], operands[1])\n-   && aarch64_sve_pred_dominates_p (&operands[7], operands[1])\"\n+  \"TARGET_SVE\"\n   \"fac<cmp_op>\\t%0.<Vetype>, %1/z, %2.<Vetype>, %3.<Vetype>\"\n   \"&& (!rtx_equal_p (operands[1], operands[5])\n-       || !rtx_equal_p (operands[1], operands[7]))\"\n+       || !rtx_equal_p (operands[1], operands[6]))\"\n   {\n     operands[5] = copy_rtx (operands[1]);\n-    operands[7] = copy_rtx (operands[1]);\n+    operands[6] = copy_rtx (operands[1]);\n   }\n )\n \n+(define_insn \"*aarch64_pred_fac<cmp_op><mode>_strict\"\n+  [(set (match_operand:<VPRED> 0 \"register_operand\" \"=Upa\")\n+\t(unspec:<VPRED>\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl\")\n+\t   (match_operand:SI 4 \"aarch64_sve_ptrue_flag\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w\")]\n+\t     UNSPEC_COND_FABS)\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (match_operand:SI 6 \"aarch64_sve_gp_strictness\")\n+\t      (match_operand:SVE_FULL_F 3 \"register_operand\" \"w\")]\n+\t     UNSPEC_COND_FABS)]\n+\t  SVE_COND_FP_ABS_CMP))]\n+  \"TARGET_SVE\"\n+  \"fac<cmp_op>\\t%0.<Vetype>, %1/z, %2.<Vetype>, %3.<Vetype>\"\n+)\n+\n ;; -------------------------------------------------------------------------\n ;; ---- [PRED] Select\n ;; -------------------------------------------------------------------------\n@@ -7937,20 +8564,18 @@\n ;; the same register (despite having different modes).  Making all the\n ;; alternatives earlyclobber makes things more consistent for the\n ;; register allocator.\n-(define_insn_and_rewrite \"*cond_<optab>_nontrunc<SVE_FULL_F:mode><SVE_FULL_HSDI:mode>\"\n+(define_insn_and_rewrite \"*cond_<optab>_nontrunc<SVE_FULL_F:mode><SVE_FULL_HSDI:mode>_relaxed\"\n   [(set (match_operand:SVE_FULL_HSDI 0 \"register_operand\" \"=&w, &w, ?&w\")\n \t(unspec:SVE_FULL_HSDI\n \t  [(match_operand:<SVE_FULL_HSDI:VPRED> 1 \"register_operand\" \"Upl, Upl, Upl\")\n \t   (unspec:SVE_FULL_HSDI\n \t     [(match_operand 4)\n-\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w, w\")]\n \t     SVE_COND_FCVTI)\n \t   (match_operand:SVE_FULL_HSDI 3 \"aarch64_simd_reg_or_zero\" \"0, Dz, w\")]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE\n-   && <SVE_FULL_HSDI:elem_bits> >= <SVE_FULL_F:elem_bits>\n-   && aarch64_sve_pred_dominates_p (&operands[4], operands[1])\"\n+  \"TARGET_SVE && <SVE_FULL_HSDI:elem_bits> >= <SVE_FULL_F:elem_bits>\"\n   \"@\n    fcvtz<su>\\t%0.<SVE_FULL_HSDI:Vetype>, %1/m, %2.<SVE_FULL_F:Vetype>\n    movprfx\\t%0.<SVE_FULL_HSDI:Vetype>, %1/z, %2.<SVE_FULL_HSDI:Vetype>\\;fcvtz<su>\\t%0.<SVE_FULL_HSDI:Vetype>, %1/m, %2.<SVE_FULL_F:Vetype>\n@@ -7962,6 +8587,25 @@\n   [(set_attr \"movprfx\" \"*,yes,yes\")]\n )\n \n+(define_insn \"*cond_<optab>_nontrunc<SVE_FULL_F:mode><SVE_FULL_HSDI:mode>_strict\"\n+  [(set (match_operand:SVE_FULL_HSDI 0 \"register_operand\" \"=&w, &w, ?&w\")\n+\t(unspec:SVE_FULL_HSDI\n+\t  [(match_operand:<SVE_FULL_HSDI:VPRED> 1 \"register_operand\" \"Upl, Upl, Upl\")\n+\t   (unspec:SVE_FULL_HSDI\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w, w\")]\n+\t     SVE_COND_FCVTI)\n+\t   (match_operand:SVE_FULL_HSDI 3 \"aarch64_simd_reg_or_zero\" \"0, Dz, w\")]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE && <SVE_FULL_HSDI:elem_bits> >= <SVE_FULL_F:elem_bits>\"\n+  \"@\n+   fcvtz<su>\\t%0.<SVE_FULL_HSDI:Vetype>, %1/m, %2.<SVE_FULL_F:Vetype>\n+   movprfx\\t%0.<SVE_FULL_HSDI:Vetype>, %1/z, %2.<SVE_FULL_HSDI:Vetype>\\;fcvtz<su>\\t%0.<SVE_FULL_HSDI:Vetype>, %1/m, %2.<SVE_FULL_F:Vetype>\n+   movprfx\\t%0, %3\\;fcvtz<su>\\t%0.<SVE_FULL_HSDI:Vetype>, %1/m, %2.<SVE_FULL_F:Vetype>\"\n+  [(set_attr \"movprfx\" \"*,yes,yes\")]\n+)\n+\n ;; Predicated narrowing float-to-integer conversion with merging.\n (define_expand \"@cond_<optab>_trunc<VNx2DF_ONLY:mode><VNx4SI_ONLY:mode>\"\n   [(set (match_operand:VNx4SI_ONLY 0 \"register_operand\")\n@@ -8101,20 +8745,18 @@\n ;; the same register (despite having different modes).  Making all the\n ;; alternatives earlyclobber makes things more consistent for the\n ;; register allocator.\n-(define_insn_and_rewrite \"*cond_<optab>_nonextend<SVE_FULL_HSDI:mode><SVE_FULL_F:mode>\"\n+(define_insn_and_rewrite \"*cond_<optab>_nonextend<SVE_FULL_HSDI:mode><SVE_FULL_F:mode>_relaxed\"\n   [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, &w, ?&w\")\n \t(unspec:SVE_FULL_F\n \t  [(match_operand:<SVE_FULL_HSDI:VPRED> 1 \"register_operand\" \"Upl, Upl, Upl\")\n \t   (unspec:SVE_FULL_F\n \t     [(match_operand 4)\n-\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_HSDI 2 \"register_operand\" \"w, w, w\")]\n \t     SVE_COND_ICVTF)\n \t   (match_operand:SVE_FULL_F 3 \"aarch64_simd_reg_or_zero\" \"0, Dz, w\")]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE\n-   && <SVE_FULL_HSDI:elem_bits> >= <SVE_FULL_F:elem_bits>\n-   && aarch64_sve_pred_dominates_p (&operands[4], operands[1])\"\n+  \"TARGET_SVE && <SVE_FULL_HSDI:elem_bits> >= <SVE_FULL_F:elem_bits>\"\n   \"@\n    <su>cvtf\\t%0.<SVE_FULL_F:Vetype>, %1/m, %2.<SVE_FULL_HSDI:Vetype>\n    movprfx\\t%0.<SVE_FULL_HSDI:Vetype>, %1/z, %2.<SVE_FULL_HSDI:Vetype>\\;<su>cvtf\\t%0.<SVE_FULL_F:Vetype>, %1/m, %2.<SVE_FULL_HSDI:Vetype>\n@@ -8126,6 +8768,25 @@\n   [(set_attr \"movprfx\" \"*,yes,yes\")]\n )\n \n+(define_insn \"*cond_<optab>_nonextend<SVE_FULL_HSDI:mode><SVE_FULL_F:mode>_strict\"\n+  [(set (match_operand:SVE_FULL_F 0 \"register_operand\" \"=&w, &w, ?&w\")\n+\t(unspec:SVE_FULL_F\n+\t  [(match_operand:<SVE_FULL_HSDI:VPRED> 1 \"register_operand\" \"Upl, Upl, Upl\")\n+\t   (unspec:SVE_FULL_F\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_HSDI 2 \"register_operand\" \"w, w, w\")]\n+\t     SVE_COND_ICVTF)\n+\t   (match_operand:SVE_FULL_F 3 \"aarch64_simd_reg_or_zero\" \"0, Dz, w\")]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE && <SVE_FULL_HSDI:elem_bits> >= <SVE_FULL_F:elem_bits>\"\n+  \"@\n+   <su>cvtf\\t%0.<SVE_FULL_F:Vetype>, %1/m, %2.<SVE_FULL_HSDI:Vetype>\n+   movprfx\\t%0.<SVE_FULL_HSDI:Vetype>, %1/z, %2.<SVE_FULL_HSDI:Vetype>\\;<su>cvtf\\t%0.<SVE_FULL_F:Vetype>, %1/m, %2.<SVE_FULL_HSDI:Vetype>\n+   movprfx\\t%0, %3\\;<su>cvtf\\t%0.<SVE_FULL_F:Vetype>, %1/m, %2.<SVE_FULL_HSDI:Vetype>\"\n+  [(set_attr \"movprfx\" \"*,yes,yes\")]\n+)\n+\n ;; Predicated widening integer-to-float conversion with merging.\n (define_expand \"@cond_<optab>_extend<VNx4SI_ONLY:mode><VNx2DF_ONLY:mode>\"\n   [(set (match_operand:VNx2DF_ONLY 0 \"register_operand\")"}, {"sha": "0cafd0b690dc3d8270dab6bebdc0c5f9262bcf01", "filename": "gcc/config/aarch64/aarch64-sve2.md", "status": "modified", "additions": 61, "deletions": 12, "changes": 73, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0eb5e901f6e25a7b8a9790a7a8c209147fb649ec/gcc%2Fconfig%2Faarch64%2Faarch64-sve2.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0eb5e901f6e25a7b8a9790a7a8c209147fb649ec/gcc%2Fconfig%2Faarch64%2Faarch64-sve2.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-sve2.md?ref=0eb5e901f6e25a7b8a9790a7a8c209147fb649ec", "patch": "@@ -1890,25 +1890,40 @@\n )\n \n ;; These instructions do not take MOVPRFX.\n-(define_insn_and_rewrite \"*cond_<sve_fp_op><mode>\"\n+(define_insn_and_rewrite \"*cond_<sve_fp_op><mode>_relaxed\"\n   [(set (match_operand:SVE_FULL_SDF 0 \"register_operand\" \"=w\")\n \t(unspec:SVE_FULL_SDF\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl\")\n \t   (unspec:SVE_FULL_SDF\n \t     [(match_operand 4)\n-\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:<VNARROW> 2 \"register_operand\" \"w\")]\n \t     SVE2_COND_FP_UNARY_LONG)\n \t   (match_operand:SVE_FULL_SDF 3 \"register_operand\" \"0\")]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE2 && aarch64_sve_pred_dominates_p (&operands[4], operands[1])\"\n+  \"TARGET_SVE2\"\n   \"<sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Ventype>\"\n   \"&& !rtx_equal_p (operands[1], operands[4])\"\n   {\n     operands[4] = copy_rtx (operands[1]);\n   }\n )\n \n+(define_insn \"*cond_<sve_fp_op><mode>_strict\"\n+  [(set (match_operand:SVE_FULL_SDF 0 \"register_operand\" \"=w\")\n+\t(unspec:SVE_FULL_SDF\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl\")\n+\t   (unspec:SVE_FULL_SDF\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:<VNARROW> 2 \"register_operand\" \"w\")]\n+\t     SVE2_COND_FP_UNARY_LONG)\n+\t   (match_operand:SVE_FULL_SDF 3 \"register_operand\" \"0\")]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE2\"\n+  \"<sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Ventype>\"\n+)\n+\n ;; -------------------------------------------------------------------------\n ;; ---- [FP<-FP] Narrowing conversions\n ;; -------------------------------------------------------------------------\n@@ -1963,20 +1978,18 @@\n   \"TARGET_SVE2\"\n )\n \n-(define_insn_and_rewrite \"*cond_<sve_fp_op><mode>_any\"\n+(define_insn_and_rewrite \"*cond_<sve_fp_op><mode>_any_relaxed\"\n   [(set (match_operand:VNx4SF_ONLY 0 \"register_operand\" \"=&w, &w, &w\")\n \t(unspec:VNx4SF_ONLY\n \t  [(match_operand:<VWIDE_PRED> 1 \"register_operand\" \"Upl, Upl, Upl\")\n \t   (unspec:VNx4SF_ONLY\n \t     [(match_operand 4)\n-\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:<VWIDE> 2 \"register_operand\" \"w, w, w\")]\n \t     SVE2_COND_FP_UNARY_NARROWB)\n \t   (match_operand:VNx4SF_ONLY 3 \"aarch64_simd_reg_or_zero\" \"0, Dz, w\")]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE2\n-   && !rtx_equal_p (operands[2], operands[3])\n-   && aarch64_sve_pred_dominates_p (&operands[4], operands[1])\"\n+  \"TARGET_SVE2 && !rtx_equal_p (operands[2], operands[3])\"\n   \"@\n    <sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vewtype>\n    movprfx\\t%0.<Vewtype>, %1/z, %2.<Vewtype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vewtype>\n@@ -1988,6 +2001,25 @@\n   [(set_attr \"movprfx\" \"*,yes,yes\")]\n )\n \n+(define_insn \"*cond_<sve_fp_op><mode>_any_strict\"\n+  [(set (match_operand:VNx4SF_ONLY 0 \"register_operand\" \"=&w, &w, &w\")\n+\t(unspec:VNx4SF_ONLY\n+\t  [(match_operand:<VWIDE_PRED> 1 \"register_operand\" \"Upl, Upl, Upl\")\n+\t   (unspec:VNx4SF_ONLY\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:<VWIDE> 2 \"register_operand\" \"w, w, w\")]\n+\t     SVE2_COND_FP_UNARY_NARROWB)\n+\t   (match_operand:VNx4SF_ONLY 3 \"aarch64_simd_reg_or_zero\" \"0, Dz, w\")]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE2 && !rtx_equal_p (operands[2], operands[3])\"\n+  \"@\n+   <sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vewtype>\n+   movprfx\\t%0.<Vewtype>, %1/z, %2.<Vewtype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vewtype>\n+   movprfx\\t%0, %3\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vewtype>\"\n+  [(set_attr \"movprfx\" \"*,yes,yes\")]\n+)\n+\n ;; Predicated FCVTXNT.  This doesn't give a natural aarch64_pred_*/cond_*\n ;; pair because the even elements always have to be supplied for active\n ;; elements, even if the inactive elements don't matter.\n@@ -2113,14 +2145,12 @@\n \t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl\")\n \t   (unspec:<V_INT_EQUIV>\n \t     [(match_operand 4)\n-\t      (match_operand:SI 5 \"aarch64_sve_gp_strictness\")\n+\t      (const_int SVE_RELAXED_GP)\n \t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w, w\")]\n \t     SVE2_COND_INT_UNARY_FP)\n \t   (match_operand:<V_INT_EQUIV> 3 \"aarch64_simd_reg_or_zero\" \"0, Dz, w\")]\n \t  UNSPEC_SEL))]\n-  \"TARGET_SVE2\n-   && !rtx_equal_p (operands[2], operands[3])\n-   && aarch64_sve_pred_dominates_p (&operands[4], operands[1])\"\n+  \"TARGET_SVE2 && !rtx_equal_p (operands[2], operands[3])\"\n   \"@\n    <sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>\n    movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>\n@@ -2132,6 +2162,25 @@\n   [(set_attr \"movprfx\" \"*,yes,yes\")]\n )\n \n+(define_insn \"*cond_<sve_fp_op><mode>_strict\"\n+  [(set (match_operand:<V_INT_EQUIV> 0 \"register_operand\" \"=&w, ?&w, ?&w\")\n+\t(unspec:<V_INT_EQUIV>\n+\t  [(match_operand:<VPRED> 1 \"register_operand\" \"Upl, Upl, Upl\")\n+\t   (unspec:<V_INT_EQUIV>\n+\t     [(match_dup 1)\n+\t      (const_int SVE_STRICT_GP)\n+\t      (match_operand:SVE_FULL_F 2 \"register_operand\" \"w, w, w\")]\n+\t     SVE2_COND_INT_UNARY_FP)\n+\t   (match_operand:<V_INT_EQUIV> 3 \"aarch64_simd_reg_or_zero\" \"0, Dz, w\")]\n+\t  UNSPEC_SEL))]\n+  \"TARGET_SVE2 && !rtx_equal_p (operands[2], operands[3])\"\n+  \"@\n+   <sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>\n+   movprfx\\t%0.<Vetype>, %1/z, %2.<Vetype>\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>\n+   movprfx\\t%0, %3\\;<sve_fp_op>\\t%0.<Vetype>, %1/m, %2.<Vetype>\"\n+  [(set_attr \"movprfx\" \"*,yes,yes\")]\n+)\n+\n ;; -------------------------------------------------------------------------\n ;; ---- [INT] Polynomial multiplication\n ;; -------------------------------------------------------------------------"}, {"sha": "a3408f48c823f7775c31f44f9ed7a0bfcc05fe28", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 0, "deletions": 18, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0eb5e901f6e25a7b8a9790a7a8c209147fb649ec/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0eb5e901f6e25a7b8a9790a7a8c209147fb649ec/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=0eb5e901f6e25a7b8a9790a7a8c209147fb649ec", "patch": "@@ -3717,24 +3717,6 @@ aarch64_pfalse_reg (machine_mode mode)\n   return gen_lowpart (mode, reg);\n }\n \n-/* Return true if predicate PRED1[0] is true whenever predicate PRED2 is\n-   true, or alternatively if we know that the operation predicated by\n-   PRED1[0] is safe to perform whenever PRED2 is true.  PRED1[1] is a\n-   aarch64_sve_gp_strictness operand that describes the operation\n-   predicated by PRED1[0].  */\n-\n-bool\n-aarch64_sve_pred_dominates_p (rtx *pred1, rtx pred2)\n-{\n-  machine_mode mode = GET_MODE (pred2);\n-  gcc_assert (GET_MODE_CLASS (mode) == MODE_VECTOR_BOOL\n-\t      && mode == GET_MODE (pred1[0])\n-\t      && aarch64_sve_gp_strictness (pred1[1], SImode));\n-  return (pred1[0] == CONSTM1_RTX (mode)\n-\t  || INTVAL (pred1[1]) == SVE_RELAXED_GP\n-\t  || rtx_equal_p (pred1[0], pred2));\n-}\n-\n /* PRED1[0] is a PTEST predicate and PRED1[1] is an aarch64_sve_ptrue_flag\n    for it.  PRED2[0] is the predicate for the instruction whose result\n    is tested by the PTEST and PRED2[1] is again an aarch64_sve_ptrue_flag"}]}