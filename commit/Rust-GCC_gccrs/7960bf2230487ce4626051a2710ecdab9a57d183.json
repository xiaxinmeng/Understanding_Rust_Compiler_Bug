{"sha": "7960bf2230487ce4626051a2710ecdab9a57d183", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Nzk2MGJmMjIzMDQ4N2NlNDYyNjA1MWEyNzEwZWNkYWI5YTU3ZDE4Mw==", "commit": {"author": {"name": "Jeff Law", "email": "law@redhat.com", "date": "2003-07-03T05:42:57Z"}, "committer": {"name": "Jeff Law", "email": "law@gcc.gnu.org", "date": "2003-07-03T05:42:57Z"}, "message": "expr.c (do_store_flag): Remove special case folding for single bit tests.\n\n\t* expr.c (do_store_flag): Remove special case folding for\n\tsingle bit tests.  Instead call back into the commonized folder\n\troutine.\n\t* fold-const.c (fold_single_bit_test): New function, mostly\n\textracted from do_store_flag, with an additional case extracted\n\tfrom fold.\n\t(fold): Call fold_single_bit_test appropriately.\n\t* tree.h (fold_single_bit_test): Prototype.\n\nFrom-SVN: r68867", "tree": {"sha": "6d15d4ff3d46299130068684fb935f49bb691251", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/6d15d4ff3d46299130068684fb935f49bb691251"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/7960bf2230487ce4626051a2710ecdab9a57d183", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7960bf2230487ce4626051a2710ecdab9a57d183", "html_url": "https://github.com/Rust-GCC/gccrs/commit/7960bf2230487ce4626051a2710ecdab9a57d183", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7960bf2230487ce4626051a2710ecdab9a57d183/comments", "author": null, "committer": null, "parents": [{"sha": "b9add4494a906f9c57c4b9ea1dd17f520eca7178", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b9add4494a906f9c57c4b9ea1dd17f520eca7178", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b9add4494a906f9c57c4b9ea1dd17f520eca7178"}], "stats": {"total": 208, "additions": 136, "deletions": 72}, "files": [{"sha": "7a29f36a60e391fe449cd14375904d68b04a21d2", "filename": "gcc/ChangeLog", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7960bf2230487ce4626051a2710ecdab9a57d183/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7960bf2230487ce4626051a2710ecdab9a57d183/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=7960bf2230487ce4626051a2710ecdab9a57d183", "patch": "@@ -1,3 +1,14 @@\n+2003-07-02  Jeff Law  <law@redhat.com>\n+\n+\t* expr.c (do_store_flag): Remove special case folding for\n+\tsingle bit tests.  Instead call back into the commonized folder\n+\troutine.\n+\t* fold-const.c (fold_single_bit_test): New function, mostly\n+\textracted from do_store_flag, with an additional case extracted\n+\tfrom fold.\n+\t(fold): Call fold_single_bit_test appropriately.\n+\t* tree.h (fold_single_bit_test): Prototype.\n+\n 2003-07-02  Zack Weinberg  <zack@codesourcery.com>\n \n \t* system.h: Include filenames.h."}, {"sha": "f735f95515c50cc29c5c46b1613908d0dcc32655", "filename": "gcc/expr.c", "status": "modified", "additions": 7, "deletions": 55, "changes": 62, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7960bf2230487ce4626051a2710ecdab9a57d183/gcc%2Fexpr.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7960bf2230487ce4626051a2710ecdab9a57d183/gcc%2Fexpr.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexpr.c?ref=7960bf2230487ce4626051a2710ecdab9a57d183", "patch": "@@ -9990,65 +9990,17 @@ do_store_flag (tree exp, rtx target, enum machine_mode mode, int only_cheap)\n      do this by shifting the bit being tested to the low-order bit and\n      masking the result with the constant 1.  If the condition was EQ,\n      we xor it with 1.  This does not require an scc insn and is faster\n-     than an scc insn even if we have it.  */\n+     than an scc insn even if we have it.\n+\n+     The code to make this transformation was moved into fold_single_bit_test,\n+     so we just call into the folder and expand its result.  */\n \n   if ((code == NE || code == EQ)\n       && TREE_CODE (arg0) == BIT_AND_EXPR && integer_zerop (arg1)\n       && integer_pow2p (TREE_OPERAND (arg0, 1)))\n-    {\n-      tree inner = TREE_OPERAND (arg0, 0);\n-      int bitnum = tree_log2 (TREE_OPERAND (arg0, 1));\n-      int ops_unsignedp;\n-\n-      /* If INNER is a right shift of a constant and it plus BITNUM does\n-\t not overflow, adjust BITNUM and INNER.  */\n-\n-      if (TREE_CODE (inner) == RSHIFT_EXPR\n-\t  && TREE_CODE (TREE_OPERAND (inner, 1)) == INTEGER_CST\n-\t  && TREE_INT_CST_HIGH (TREE_OPERAND (inner, 1)) == 0\n-\t  && bitnum < TYPE_PRECISION (type)\n-\t  && 0 > compare_tree_int (TREE_OPERAND (inner, 1),\n-\t\t\t\t   bitnum - TYPE_PRECISION (type)))\n-\t{\n-\t  bitnum += TREE_INT_CST_LOW (TREE_OPERAND (inner, 1));\n-\t  inner = TREE_OPERAND (inner, 0);\n-\t}\n-\n-      /* If we are going to be able to omit the AND below, we must do our\n-\t operations as unsigned.  If we must use the AND, we have a choice.\n-\t Normally unsigned is faster, but for some machines signed is.  */\n-      ops_unsignedp = (bitnum == TYPE_PRECISION (type) - 1 ? 1\n-#ifdef LOAD_EXTEND_OP\n-\t\t       : (LOAD_EXTEND_OP (operand_mode) == SIGN_EXTEND ? 0 : 1)\n-#else\n-\t\t       : 1\n-#endif\n-\t\t       );\n-\n-      if (! get_subtarget (subtarget)\n-\t  || GET_MODE (subtarget) != operand_mode\n-\t  || ! safe_from_p (subtarget, inner, 1))\n-\tsubtarget = 0;\n-\n-      op0 = expand_expr (inner, subtarget, VOIDmode, 0);\n-\n-      if (bitnum != 0)\n-\top0 = expand_shift (RSHIFT_EXPR, operand_mode, op0,\n-\t\t\t    size_int (bitnum), subtarget, ops_unsignedp);\n-\n-      if (GET_MODE (op0) != mode)\n-\top0 = convert_to_mode (mode, op0, ops_unsignedp);\n-\n-      if ((code == EQ && ! invert) || (code == NE && invert))\n-\top0 = expand_binop (mode, xor_optab, op0, const1_rtx, subtarget,\n-\t\t\t    ops_unsignedp, OPTAB_LIB_WIDEN);\n-\n-      /* Put the AND last so it can combine with more things.  */\n-      if (bitnum != TYPE_PRECISION (type) - 1)\n-\top0 = expand_and (mode, op0, const1_rtx, subtarget);\n-\n-      return op0;\n-    }\n+    return expand_expr (fold_single_bit_test (code == NE ? NE_EXPR : EQ_EXPR,\n+\t\t\t\t\t      arg0, arg1, type), \n+\t\t\ttarget, VOIDmode, EXPAND_NORMAL);\n \n   /* Now see if we are likely to be able to do this.  Return if not.  */\n   if (! can_compare_p (code, operand_mode, ccp_store_flag))"}, {"sha": "7751cb95a372e42362c64b50795712c2c67ad6c6", "filename": "gcc/fold-const.c", "status": "modified", "additions": 116, "deletions": 17, "changes": 133, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7960bf2230487ce4626051a2710ecdab9a57d183/gcc%2Ffold-const.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7960bf2230487ce4626051a2710ecdab9a57d183/gcc%2Ffold-const.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffold-const.c?ref=7960bf2230487ce4626051a2710ecdab9a57d183", "patch": "@@ -4797,6 +4797,111 @@ fold_inf_compare (enum tree_code code, tree type, tree arg0, tree arg1)\n   return NULL_TREE;\n }\n \n+/* If CODE with arguments ARG0 and ARG1 represents a single bit\n+   equality/inequality test, then return a simplified form of\n+   the test using shifts and logical operations.  Otherwise return\n+   NULL.  TYPE is the desired result type.  */\n+ \n+tree\n+fold_single_bit_test (code, arg0, arg1, result_type)\n+    enum tree_code code;\n+    tree arg0;\n+    tree arg1;\n+    tree result_type;\n+{\n+  /* If this is a TRUTH_NOT_EXPR, it may have a single bit test inside\n+     operand 0.  */\n+  if (code == TRUTH_NOT_EXPR)\n+    {\n+      code = TREE_CODE (arg0);\n+      if (code != NE_EXPR && code != EQ_EXPR)\n+\treturn NULL_TREE;\n+\n+      /* Extract the arguments of the EQ/NE.  */\n+      arg1 = TREE_OPERAND (arg0, 1);\n+      arg0 = TREE_OPERAND (arg0, 0);\n+\n+      /* This requires us to invert the code.  */ \n+      code = (code == EQ_EXPR ? NE_EXPR : EQ_EXPR);\n+    }\n+\n+  /* If this is testing a single bit, we can optimize the test.  */\n+  if ((code == NE_EXPR || code == EQ_EXPR)\n+      && TREE_CODE (arg0) == BIT_AND_EXPR && integer_zerop (arg1)\n+      && integer_pow2p (TREE_OPERAND (arg0, 1)))\n+    {\n+      tree inner = TREE_OPERAND (arg0, 0);\n+      tree type = TREE_TYPE (arg0);\n+      int bitnum = tree_log2 (TREE_OPERAND (arg0, 1));\n+      enum machine_mode operand_mode = TYPE_MODE (type);\n+      int ops_unsigned;\n+      tree signed_type, unsigned_type;\n+      tree arg00;\n+  \n+      /* If we have (A & C) != 0 where C is the sign bit of A, convert\n+\t this into A < 0.  Similarly for (A & C) == 0 into A >= 0.  */\n+      arg00 = sign_bit_p (TREE_OPERAND (arg0, 0), TREE_OPERAND (arg0, 1));\n+      if (arg00 != NULL_TREE)\n+\t{\n+\t  tree stype = (*lang_hooks.types.signed_type) (TREE_TYPE (arg00));\n+\t  return fold (build (code == EQ_EXPR ? GE_EXPR : LT_EXPR, type,\n+\t\t\t      convert (stype, arg00),\n+\t\t\t      convert (stype, integer_zero_node)));\n+\t}\n+      \n+      /* Otherwise we have (A & C) != 0 where C is a single bit, \n+\t convert that into ((A >> C2) & 1).  Where C2 = log2(C).\n+\t Similarly for (A & C) == 0.  */\n+\n+      /* If INNER is a right shift of a constant and it plus BITNUM does\n+\t not overflow, adjust BITNUM and INNER.  */\n+      if (TREE_CODE (inner) == RSHIFT_EXPR\n+\t  && TREE_CODE (TREE_OPERAND (inner, 1)) == INTEGER_CST\n+\t  && TREE_INT_CST_HIGH (TREE_OPERAND (inner, 1)) == 0\n+\t  && bitnum < TYPE_PRECISION (type)\n+\t  && 0 > compare_tree_int (TREE_OPERAND (inner, 1),\n+\t\t\t\t   bitnum - TYPE_PRECISION (type)))\n+\t{\n+\t  bitnum += TREE_INT_CST_LOW (TREE_OPERAND (inner, 1));\n+\t  inner = TREE_OPERAND (inner, 0);\n+\t}\n+\n+      /* If we are going to be able to omit the AND below, we must do our\n+\t operations as unsigned.  If we must use the AND, we have a choice.\n+\t Normally unsigned is faster, but for some machines signed is.  */\n+      ops_unsigned = (bitnum == TYPE_PRECISION (type) - 1 ? 1\n+#ifdef LOAD_EXTEND_OP\n+\t\t      : (LOAD_EXTEND_OP (operand_mode) == SIGN_EXTEND ? 0 : 1)\n+#else\n+\t\t      : 1\n+#endif\n+\t\t      );\n+\n+      signed_type = (*lang_hooks.types.type_for_mode) (operand_mode, 0);\n+      unsigned_type = (*lang_hooks.types.type_for_mode) (operand_mode, 1);\n+\n+      if (bitnum != 0)\n+\tinner = build (RSHIFT_EXPR, ops_unsigned ? unsigned_type : signed_type,\n+\t\t       inner, size_int (bitnum));\n+\n+      if (code == EQ_EXPR)\n+\tinner = build (BIT_XOR_EXPR, ops_unsigned ? unsigned_type : signed_type,\n+\t\t       inner, integer_one_node);\n+\n+      /* Put the AND last so it can combine with more things.  */\n+      if (bitnum != TYPE_PRECISION (type) - 1)\n+\tinner = build (BIT_AND_EXPR, ops_unsigned ? unsigned_type : signed_type,\n+\t\t       inner, integer_one_node);\n+\n+      /* Make sure to return the proper type.  */\n+      if (TREE_TYPE (inner) != result_type)\n+\tinner = convert (result_type, inner);\n+\n+      return inner;\n+    }\n+  return NULL_TREE;\n+}\n+ \n /* Perform constant folding and related simplification of EXPR.\n    The related simplifications include x*1 => x, x*0 => 0, etc.,\n    and application of the associative law.\n@@ -6320,7 +6425,12 @@ fold (tree expr)\n       tem = invert_truthvalue (arg0);\n       /* Avoid infinite recursion.  */\n       if (TREE_CODE (tem) == TRUTH_NOT_EXPR)\n-\treturn t;\n+\t{\n+\t  tem = fold_single_bit_test (code, arg0, arg1, type);\n+\t  if (tem)\n+\t    return tem;\n+\t  return t;\n+\t}\n       return convert (type, tem);\n \n     case TRUTH_ANDIF_EXPR:\n@@ -7012,22 +7122,11 @@ fold (tree expr)\n \treturn fold (build (code == EQ_EXPR ? NE_EXPR : EQ_EXPR, type,\n \t\t\t    arg0, integer_zero_node));\n \n-      /* If we have (A & C) != 0 where C is the sign bit of A, convert\n-\t this into A < 0.  Similarly for (A & C) == 0 into A >= 0.  */\n-      if ((code == EQ_EXPR || code == NE_EXPR)\n-\t  && TREE_CODE (arg0) == BIT_AND_EXPR\n-\t  && integer_zerop (arg1))\n-\t{\n-\t  tree arg00 = sign_bit_p (TREE_OPERAND (arg0, 0),\n-\t\t\t\t   TREE_OPERAND (arg0, 1));\n-\t  if (arg00 != NULL_TREE)\n-\t  {\n-\t    tree stype = (*lang_hooks.types.signed_type) (TREE_TYPE (arg00));\n-\t    return fold (build (code == EQ_EXPR ? GE_EXPR : LT_EXPR, type,\n-\t\t\t        convert (stype, arg00),\n-\t\t\t\tconvert (stype, integer_zero_node)));\n-\t  }\n-\t}\n+      /* If we have (A & C) != 0 or (A & C) == 0 and C is a power of\n+\t 2, then fold the expression into shifts and logical operations.  */\n+      tem = fold_single_bit_test (code, arg0, arg1, type);\n+      if (tem)\n+\treturn tem;\n \n       /* If X is unsigned, convert X < (1 << Y) into X >> Y == 0\n \t and similarly for >= into !=.  */"}, {"sha": "ac9c44c7c2da5195615a8aa52c54adee3274cec7", "filename": "gcc/tree.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7960bf2230487ce4626051a2710ecdab9a57d183/gcc%2Ftree.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7960bf2230487ce4626051a2710ecdab9a57d183/gcc%2Ftree.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.h?ref=7960bf2230487ce4626051a2710ecdab9a57d183", "patch": "@@ -2727,6 +2727,8 @@ extern void using_eh_for_cleanups\t\tPARAMS ((void));\n    subexpressions are not changed.  */\n \n extern tree fold\t\tPARAMS ((tree));\n+extern tree fold_single_bit_test\n+  PARAMS ((enum tree_code, tree, tree, tree));\n \n extern int force_fit_type\tPARAMS ((tree, int));\n extern int add_double\t\tPARAMS ((unsigned HOST_WIDE_INT, HOST_WIDE_INT,"}]}