{"sha": "4f05ff34d63b582557918189528531f35041ef0e", "node_id": "C_kwDOANBUbNoAKDRmMDVmZjM0ZDYzYjU4MjU1NzkxODE4OTUyODUzMWYzNTA0MWVmMGU", "commit": {"author": {"name": "Tobias Burnus", "email": "tobias@codesourcery.com", "date": "2022-09-08T18:56:49Z"}, "committer": {"name": "Tobias Burnus", "email": "tobias@codesourcery.com", "date": "2022-09-08T18:56:49Z"}, "message": "libgomp.texi: Document libmemkind + nvptx/gcn specifics\n\nlibgomp/ChangeLog:\n\n\t* libgomp.texi (OpenMP-Implementation Specifics): New; add libmemkind\n\tsection; move OpenMP Context Selectors from ...\n\t(Offload-Target Specifics): ... here; add 'AMD Radeo (GCN)' and\n\t'nvptx' sections.", "tree": {"sha": "cba9501e707fd4fc49c0301031f11b4945698cf1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/cba9501e707fd4fc49c0301031f11b4945698cf1"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/4f05ff34d63b582557918189528531f35041ef0e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4f05ff34d63b582557918189528531f35041ef0e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4f05ff34d63b582557918189528531f35041ef0e", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4f05ff34d63b582557918189528531f35041ef0e/comments", "author": {"login": "tob2", "id": 264461, "node_id": "MDQ6VXNlcjI2NDQ2MQ==", "avatar_url": "https://avatars.githubusercontent.com/u/264461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tob2", "html_url": "https://github.com/tob2", "followers_url": "https://api.github.com/users/tob2/followers", "following_url": "https://api.github.com/users/tob2/following{/other_user}", "gists_url": "https://api.github.com/users/tob2/gists{/gist_id}", "starred_url": "https://api.github.com/users/tob2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tob2/subscriptions", "organizations_url": "https://api.github.com/users/tob2/orgs", "repos_url": "https://api.github.com/users/tob2/repos", "events_url": "https://api.github.com/users/tob2/events{/privacy}", "received_events_url": "https://api.github.com/users/tob2/received_events", "type": "User", "site_admin": false}, "committer": {"login": "tob2", "id": 264461, "node_id": "MDQ6VXNlcjI2NDQ2MQ==", "avatar_url": "https://avatars.githubusercontent.com/u/264461?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tob2", "html_url": "https://github.com/tob2", "followers_url": "https://api.github.com/users/tob2/followers", "following_url": "https://api.github.com/users/tob2/following{/other_user}", "gists_url": "https://api.github.com/users/tob2/gists{/gist_id}", "starred_url": "https://api.github.com/users/tob2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tob2/subscriptions", "organizations_url": "https://api.github.com/users/tob2/orgs", "repos_url": "https://api.github.com/users/tob2/repos", "events_url": "https://api.github.com/users/tob2/events{/privacy}", "received_events_url": "https://api.github.com/users/tob2/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "30c811f2bac73e63e0b461ba7ed3805b77898798", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/30c811f2bac73e63e0b461ba7ed3805b77898798", "html_url": "https://github.com/Rust-GCC/gccrs/commit/30c811f2bac73e63e0b461ba7ed3805b77898798"}], "stats": {"total": 131, "additions": 125, "deletions": 6}, "files": [{"sha": "8847f3ee59f8ff560ae1e4bf70cb2a17e8148a67", "filename": "libgomp/libgomp.texi", "status": "modified", "additions": 125, "deletions": 6, "changes": 131, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4f05ff34d63b582557918189528531f35041ef0e/libgomp%2Flibgomp.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4f05ff34d63b582557918189528531f35041ef0e/libgomp%2Flibgomp.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgomp%2Flibgomp.texi?ref=4f05ff34d63b582557918189528531f35041ef0e", "patch": "@@ -113,6 +113,8 @@ changed to GNU Offloading and Multi Processing Runtime Library.\n * OpenACC Library Interoperability:: OpenACC library interoperability with the\n                                NVIDIA CUBLAS library.\n * OpenACC Profiling Interface::\n+* OpenMP-Implementation Specifics:: Notes specifics of this OpenMP\n+                               implementation\n * Offload-Target Specifics::   Notes on offload-target specific internals\n * The libgomp ABI::            Notes on the external ABI presented by libgomp.\n * Reporting Bugs::             How to report bugs in the GNU Offloading and\n@@ -4274,16 +4276,15 @@ offloading devices (it's not clear if they should be):\n @end itemize\n \n @c ---------------------------------------------------------------------\n-@c Offload-Target Specifics\n+@c OpenMP-Implementation Specifics\n @c ---------------------------------------------------------------------\n \n-@node Offload-Target Specifics\n-@chapter Offload-Target Specifics\n-\n-The following sections present notes on the offload-target specifics.\n+@node OpenMP-Implementation Specifics\n+@chapter OpenMP-Implementation Specifics\n \n @menu\n * OpenMP Context Selectors::\n+* Memory allocation with libmemkind::\n @end menu\n \n @node OpenMP Context Selectors\n@@ -4302,9 +4303,127 @@ The following sections present notes on the offload-target specifics.\n       @tab See @code{-march=} in ``AMD GCN Options''\n @item @code{nvptx}\n       @tab @code{gpu}\n-      @tab See @code{-misa=} in ``Nvidia PTX Options''\n+      @tab See @code{-march=} in ``Nvidia PTX Options''\n @end multitable\n \n+@node Memory allocation with libmemkind\n+@section Memory allocation with libmemkind\n+\n+On Linux systems, where the @uref{https://github.com/memkind/memkind, memkind\n+library} (@code{libmemkind.so.0}) is available at runtime, it is used when\n+creating memory allocators requesting\n+\n+@itemize\n+@item the memory space @code{omp_high_bw_mem_space}\n+@item the memory space @code{omp_large_cap_mem_space}\n+@item the partition trait @code{omp_atv_interleaved}\n+@end itemize\n+\n+\n+@c ---------------------------------------------------------------------\n+@c Offload-Target Specifics\n+@c ---------------------------------------------------------------------\n+\n+@node Offload-Target Specifics\n+@chapter Offload-Target Specifics\n+\n+The following sections present notes on the offload-target specifics\n+\n+@menu\n+* AMD Radeon::\n+* nvptx::\n+@end menu\n+\n+@node AMD Radeon\n+@section AMD Radeon (GCN)\n+\n+On the hardware side, there is the hierarchy (fine to coarse):\n+@itemize\n+@item work item (thread)\n+@item wavefront\n+@item work group\n+@item compute unite (CU)\n+@end itemize\n+\n+All OpenMP and OpenACC levels are used, i.e.\n+@itemize\n+@item OpenMP's simd and OpenACC's vector map to work items (thread)\n+@item OpenMP's threads (``parallel'') and OpenACC's workers map\n+      to wavefronts\n+@item OpenMP's teams and OpenACC's gang use a threadpool with the\n+      size of the number of teams or gangs, respectively.\n+@end itemize\n+\n+The used sizes are\n+@itemize\n+@item Number of teams is the specified @code{num_teams} (OpenMP) or\n+      @code{num_gangs} (OpenACC) or otherwise the number of CU\n+@item Number of wavefronts is 4 for gfx900 and 16 otherwise;\n+      @code{num_threads} (OpenMP) and @code{num_workers} (OpenACC)\n+      overrides this if smaller.\n+@item The wavefront has 102 scalars and 64 vectors\n+@item Number of workitems is always 64\n+@item The hardware permits maximally 40 workgroups/CU and\n+      16 wavefronts/workgroup up to a limit of 40 wavefronts in total per CU.\n+@item 80 scalars registers and 24 vector registers in non-kernel functions\n+      (the chosen procedure-calling API).\n+@item For the kernel itself: as many as register pressure demands (number of\n+      teams and number of threads, scaled down if registers are exhausted)\n+@end itemize\n+\n+The implementation remark:\n+@itemize\n+@item I/O within OpenMP target regions and OpenACC parallel/kernels is supported\n+      using the C library @code{printf} functions and the Fortran\n+      @code{print}/@code{write} statements.\n+@end itemize\n+\n+\n+\n+@node nvptx\n+@section nvptx\n+\n+On the hardware side, there is the hierarchy (fine to coarse):\n+@itemize\n+@item thread\n+@item warp\n+@item thread block\n+@item streaming multiprocessor\n+@end itemize\n+\n+All OpenMP and OpenACC levels are used, i.e.\n+@itemize\n+@item OpenMP's simd and OpenACC's vector map to threads\n+@item OpenMP's threads (``parallel'') and OpenACC's workers map to warps\n+@item OpenMP's teams and OpenACC's gang use a threadpool with the\n+      size of the number of teams or gangs, respectively.\n+@end itemize\n+\n+The used sizes are\n+@itemize\n+@item The @code{warp_size} is always 32\n+@item CUDA kernel launched: @code{dim=@{#teams,1,1@}, blocks=@{#threads,warp_size,1@}}.\n+@end itemize\n+\n+Additional information can be obtained by setting the environment variable to\n+@code{GOMP_DEBUG=1} (very verbose; grep for @code{kernel.*launch} for launch\n+parameters).\n+\n+GCC generates generic PTX ISA code, which is just-in-time compiled by CUDA,\n+which caches the JIT in the user's directory (see CUDA documentation; can be\n+tuned by the environment variables @code{CUDA_CACHE_@{DISABLE,MAXSIZE,PATH@}}.\n+\n+Note: While PTX ISA is generic, the @code{-mptx=} and @code{-march=} commandline\n+options still affect the used PTX ISA code and, thus, the requirments on\n+CUDA version and hardware.\n+\n+The implementation remark:\n+@itemize\n+@item I/O within OpenMP target regions and OpenACC parallel/kernels is supported\n+      using the C library @code{printf} functions. Note that the Fortran\n+      @code{print}/@code{write} statements are not supported, yet.\n+@end itemize\n+\n \n @c ---------------------------------------------------------------------\n @c The libgomp ABI"}]}