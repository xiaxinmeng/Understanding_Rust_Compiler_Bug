{"sha": "fc7b4248172561a9ee310e2d43d8a485a5c9e108", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZmM3YjQyNDgxNzI1NjFhOWVlMzEwZTJkNDNkOGE0ODVhNWM5ZTEwOA==", "commit": {"author": {"name": "Richard Biener", "email": "rguenther@suse.de", "date": "2020-12-11T09:52:58Z"}, "committer": {"name": "Richard Biener", "email": "rguenther@suse.de", "date": "2020-12-11T10:55:29Z"}, "message": "tree-optimization/98235 - limit SLP discovery\n\nWith following backedges and the SLP discovery cache not being\npermute aware we have to put some discovery limits in place again.\nThat's also the opportunity to ditch the separate limit on the\nnumber of permutes we try, so the patch limits the overall work\ndone (as in vect_build_slp_tree cache misses) to what we compute\nas max_tree_size which is based on the number of scalar stmts in\nthe vectorized region.\n\nNote the limit is global and there's no attempt to divide the\nallowed work evenly amongst opportunities, so one degenerate\ncan eat it all up.  That's probably only relevant for BB\nvectorization where the limit is based on up to the size of the\nwhole function.\n\n2020-12-11  Richard Biener  <rguenther@suse.de>\n\n\tPR tree-optimization/98235\n\t* tree-vect-slp.c (vect_build_slp_tree): Exchange npermutes\n\tfor limit.  Decrement that for each cache miss and fail\n\tdiscovery when it reaches zero.\n\t(vect_build_slp_tree_2): Remove npermutes handling and\n\tsimply pass down limit.\n\t(vect_build_slp_instance): Use pass down limit.\n\t(vect_analyze_slp_instance): Likewise.\n\t(vect_analyze_slp): Base the SLP discovery limit on\n\tmax_tree_size and pass it down.\n\n\t* gcc.dg/torture/pr98235.c: New testcase.", "tree": {"sha": "238944498d6085e49a2ce94139ec5b519a33d1db", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/238944498d6085e49a2ce94139ec5b519a33d1db"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/fc7b4248172561a9ee310e2d43d8a485a5c9e108", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/fc7b4248172561a9ee310e2d43d8a485a5c9e108", "html_url": "https://github.com/Rust-GCC/gccrs/commit/fc7b4248172561a9ee310e2d43d8a485a5c9e108", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/fc7b4248172561a9ee310e2d43d8a485a5c9e108/comments", "author": {"login": "rguenth", "id": 2046526, "node_id": "MDQ6VXNlcjIwNDY1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/2046526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rguenth", "html_url": "https://github.com/rguenth", "followers_url": "https://api.github.com/users/rguenth/followers", "following_url": "https://api.github.com/users/rguenth/following{/other_user}", "gists_url": "https://api.github.com/users/rguenth/gists{/gist_id}", "starred_url": "https://api.github.com/users/rguenth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rguenth/subscriptions", "organizations_url": "https://api.github.com/users/rguenth/orgs", "repos_url": "https://api.github.com/users/rguenth/repos", "events_url": "https://api.github.com/users/rguenth/events{/privacy}", "received_events_url": "https://api.github.com/users/rguenth/received_events", "type": "User", "site_admin": false}, "committer": {"login": "rguenth", "id": 2046526, "node_id": "MDQ6VXNlcjIwNDY1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/2046526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rguenth", "html_url": "https://github.com/rguenth", "followers_url": "https://api.github.com/users/rguenth/followers", "following_url": "https://api.github.com/users/rguenth/following{/other_user}", "gists_url": "https://api.github.com/users/rguenth/gists{/gist_id}", "starred_url": "https://api.github.com/users/rguenth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rguenth/subscriptions", "organizations_url": "https://api.github.com/users/rguenth/orgs", "repos_url": "https://api.github.com/users/rguenth/repos", "events_url": "https://api.github.com/users/rguenth/events{/privacy}", "received_events_url": "https://api.github.com/users/rguenth/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "3e60ddeb8220ed388819bb3f14e8caa9309fd3c2", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3e60ddeb8220ed388819bb3f14e8caa9309fd3c2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/3e60ddeb8220ed388819bb3f14e8caa9309fd3c2"}], "stats": {"total": 108, "additions": 77, "deletions": 31}, "files": [{"sha": "5f59013e9a2449f7ad7f45f3efd6a87e7bb4b1da", "filename": "gcc/testsuite/gcc.dg/torture/pr98235.c", "status": "added", "additions": 34, "deletions": 0, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/fc7b4248172561a9ee310e2d43d8a485a5c9e108/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr98235.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/fc7b4248172561a9ee310e2d43d8a485a5c9e108/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr98235.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Ftorture%2Fpr98235.c?ref=fc7b4248172561a9ee310e2d43d8a485a5c9e108", "patch": "@@ -0,0 +1,34 @@\n+/* { dg-do compile } */\n+/* { dg-additional-options \"-fallow-store-data-races\" } */\n+\n+char tcube[3][9];\n+int cur_move;\n+void perm_cube(void) {\n+  int i, j, k, tmp;\n+  for (; i < cur_move; i++)\n+    while (k-- >= 0)\n+      switch (j) {\n+      case 0:\n+        tmp = tcube[0][6];\n+        tcube[2][8] = tcube[0][8];\n+        tcube[0][8] = tmp;\n+        tmp = tcube[0][5];\n+        tcube[0][5] = tcube[1][8];\n+        tcube[1][8] = tcube[2][5];\n+        tcube[2][5] = tcube[1][2];\n+        tcube[1][2] = tcube[2][1];\n+        tcube[2][1] = tcube[1][0];\n+        tcube[0][6] = tmp;\n+        tmp = tcube[0][3];\n+        tcube[0][3] = tcube[1][0];\n+        tcube[1][0] = tcube[2][3];\n+        tcube[2][3] = tcube[1][6];\n+        tcube[1][6] = tmp;\n+        break;\n+      case 5:\n+        tmp = tcube[2][0];\n+        tcube[2][0] = tcube[2][2];\n+        tcube[2][2] = tcube[2][8];\n+        tcube[2][3] = tmp;\n+      }\n+}"}, {"sha": "2d55885a553bc729f2e180d88e913b9cafbff5de", "filename": "gcc/tree-vect-slp.c", "status": "modified", "additions": 43, "deletions": 31, "changes": 74, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/fc7b4248172561a9ee310e2d43d8a485a5c9e108/gcc%2Ftree-vect-slp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/fc7b4248172561a9ee310e2d43d8a485a5c9e108/gcc%2Ftree-vect-slp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-slp.c?ref=fc7b4248172561a9ee310e2d43d8a485a5c9e108", "patch": "@@ -1375,14 +1375,14 @@ static slp_tree\n vect_build_slp_tree_2 (vec_info *vinfo, slp_tree node,\n \t\t       vec<stmt_vec_info> stmts, unsigned int group_size,\n \t\t       poly_uint64 *max_nunits,\n-\t\t       bool *matches, unsigned *npermutes, unsigned *tree_size,\n+\t\t       bool *matches, unsigned *limit, unsigned *tree_size,\n \t\t       scalar_stmts_to_slp_tree_map_t *bst_map);\n \n static slp_tree\n vect_build_slp_tree (vec_info *vinfo,\n \t\t     vec<stmt_vec_info> stmts, unsigned int group_size,\n \t\t     poly_uint64 *max_nunits,\n-\t\t     bool *matches, unsigned *npermutes, unsigned *tree_size,\n+\t\t     bool *matches, unsigned *limit, unsigned *tree_size,\n \t\t     scalar_stmts_to_slp_tree_map_t *bst_map)\n {\n   if (slp_tree *leader = bst_map->get (stmts))\n@@ -1405,10 +1405,26 @@ vect_build_slp_tree (vec_info *vinfo,\n   SLP_TREE_SCALAR_STMTS (res) = stmts;\n   bst_map->put (stmts.copy (), res);\n \n+  if (*limit == 0)\n+    {\n+      if (dump_enabled_p ())\n+\tdump_printf_loc (MSG_NOTE, vect_location,\n+\t\t\t \"SLP discovery limit exceeded\\n\");\n+      bool existed_p = bst_map->put (stmts, NULL);\n+      gcc_assert (existed_p);\n+      /* Mark the node invalid so we can detect those when still in use\n+\t as backedge destinations.  */\n+      SLP_TREE_SCALAR_STMTS (res) = vNULL;\n+      SLP_TREE_DEF_TYPE (res) = vect_uninitialized_def;\n+      vect_free_slp_tree (res);\n+      return NULL;\n+    }\n+  --*limit;\n+\n   poly_uint64 this_max_nunits = 1;\n   slp_tree res_ = vect_build_slp_tree_2 (vinfo, res, stmts, group_size,\n \t\t\t\t\t&this_max_nunits,\n-\t\t\t\t\tmatches, npermutes, tree_size, bst_map);\n+\t\t\t\t\tmatches, limit, tree_size, bst_map);\n   if (!res_)\n     {\n       bool existed_p = bst_map->put (stmts, NULL);\n@@ -1441,7 +1457,7 @@ static slp_tree\n vect_build_slp_tree_2 (vec_info *vinfo, slp_tree node,\n \t\t       vec<stmt_vec_info> stmts, unsigned int group_size,\n \t\t       poly_uint64 *max_nunits,\n-\t\t       bool *matches, unsigned *npermutes, unsigned *tree_size,\n+\t\t       bool *matches, unsigned *limit, unsigned *tree_size,\n \t\t       scalar_stmts_to_slp_tree_map_t *bst_map)\n {\n   unsigned nops, i, this_tree_size = 0;\n@@ -1687,7 +1703,7 @@ vect_build_slp_tree_2 (vec_info *vinfo, slp_tree node,\n \n       if ((child = vect_build_slp_tree (vinfo, oprnd_info->def_stmts,\n \t\t\t\t\tgroup_size, &this_max_nunits,\n-\t\t\t\t\tmatches, npermutes,\n+\t\t\t\t\tmatches, limit,\n \t\t\t\t\t&this_tree_size, bst_map)) != NULL)\n \t{\n \t  oprnd_info->def_stmts = vNULL;\n@@ -1708,12 +1724,7 @@ vect_build_slp_tree_2 (vec_info *vinfo, slp_tree node,\n \t  && is_gimple_assign (stmt_info->stmt)\n \t  /* Swapping operands for reductions breaks assumptions later on.  */\n \t  && STMT_VINFO_DEF_TYPE (stmt_info) != vect_reduction_def\n-\t  && STMT_VINFO_DEF_TYPE (stmt_info) != vect_double_reduction_def\n-\t  /* Do so only if the number of not successful permutes was nor more\n-\t     than a cut-ff as re-trying the recursive match on\n-\t     possibly each level of the tree would expose exponential\n-\t     behavior.  */\n-\t  && *npermutes < 4)\n+\t  && STMT_VINFO_DEF_TYPE (stmt_info) != vect_double_reduction_def)\n \t{\n \t  /* See whether we can swap the matching or the non-matching\n \t     stmt operands.  */\n@@ -1759,17 +1770,13 @@ vect_build_slp_tree_2 (vec_info *vinfo, slp_tree node,\n \t  bool *tem = XALLOCAVEC (bool, group_size);\n \t  if ((child = vect_build_slp_tree (vinfo, oprnd_info->def_stmts,\n \t\t\t\t\t    group_size, &this_max_nunits,\n-\t\t\t\t\t    tem, npermutes,\n+\t\t\t\t\t    tem, limit,\n \t\t\t\t\t    &this_tree_size, bst_map)) != NULL)\n \t    {\n \t      oprnd_info->def_stmts = vNULL;\n \t      children.safe_push (child);\n \t      continue;\n \t    }\n-\t  /* We do not undo the swapping here since it might still be\n-\t     the better order for the second operand in case we build\n-\t     the first one from scalars below.  */\n-\t  ++*npermutes;\n \t}\n fail:\n \n@@ -2213,7 +2220,7 @@ static bool\n vect_analyze_slp_instance (vec_info *vinfo,\n \t\t\t   scalar_stmts_to_slp_tree_map_t *bst_map,\n \t\t\t   stmt_vec_info stmt_info, slp_instance_kind kind,\n-\t\t\t   unsigned max_tree_size);\n+\t\t\t   unsigned max_tree_size, unsigned *limit);\n \n /* Analyze an SLP instance starting from SCALAR_STMTS which are a group\n    of KIND.  Return true if successful.  */\n@@ -2223,7 +2230,7 @@ vect_build_slp_instance (vec_info *vinfo,\n \t\t\t slp_instance_kind kind,\n \t\t\t vec<stmt_vec_info> &scalar_stmts,\n \t\t\t stmt_vec_info root_stmt_info,\n-\t\t\t unsigned max_tree_size,\n+\t\t\t unsigned max_tree_size, unsigned *limit,\n \t\t\t scalar_stmts_to_slp_tree_map_t *bst_map,\n \t\t\t /* ???  We need stmt_info for group splitting.  */\n \t\t\t stmt_vec_info stmt_info_)\n@@ -2240,12 +2247,11 @@ vect_build_slp_instance (vec_info *vinfo,\n   /* Build the tree for the SLP instance.  */\n   unsigned int group_size = scalar_stmts.length ();\n   bool *matches = XALLOCAVEC (bool, group_size);\n-  unsigned npermutes = 0;\n   poly_uint64 max_nunits = 1;\n   unsigned tree_size = 0;\n   unsigned i;\n   slp_tree node = vect_build_slp_tree (vinfo, scalar_stmts, group_size,\n-\t\t\t\t       &max_nunits, matches, &npermutes,\n+\t\t\t\t       &max_nunits, matches, limit,\n \t\t\t\t       &tree_size, bst_map);\n   if (node != NULL)\n     {\n@@ -2413,7 +2419,8 @@ vect_build_slp_instance (vec_info *vinfo,\n \t      stmt_vec_info rest = vect_split_slp_store_group (stmt_info,\n \t\t\t\t\t\t\t       group1_size);\n \t      bool res = vect_analyze_slp_instance (vinfo, bst_map, stmt_info,\n-\t\t\t\t\t\t    kind, max_tree_size);\n+\t\t\t\t\t\t    kind, max_tree_size,\n+\t\t\t\t\t\t    limit);\n \t      /* Split the rest at the failure point and possibly\n \t\t re-analyze the remaining matching part if it has\n \t\t at least two lanes.  */\n@@ -2425,13 +2432,15 @@ vect_build_slp_instance (vec_info *vinfo,\n \t\t  rest = vect_split_slp_store_group (rest, i - group1_size);\n \t\t  if (i - group1_size > 1)\n \t\t    res |= vect_analyze_slp_instance (vinfo, bst_map, rest2,\n-\t\t\t\t\t\t      kind, max_tree_size);\n+\t\t\t\t\t\t      kind, max_tree_size,\n+\t\t\t\t\t\t      limit);\n \t\t}\n \t      /* Re-analyze the non-matching tail if it has at least\n \t\t two lanes.  */\n \t      if (i + 1 < group_size)\n \t\tres |= vect_analyze_slp_instance (vinfo, bst_map,\n-\t\t\t\t\t\t  rest, kind, max_tree_size);\n+\t\t\t\t\t\t  rest, kind, max_tree_size,\n+\t\t\t\t\t\t  limit);\n \t      return res;\n \t    }\n \t}\n@@ -2456,10 +2465,10 @@ vect_build_slp_instance (vec_info *vinfo,\n \t  DR_GROUP_GAP (stmt_info) = 0;\n \n \t  bool res = vect_analyze_slp_instance (vinfo, bst_map, stmt_info,\n-\t\t\t\t\t\tkind, max_tree_size);\n+\t\t\t\t\t\tkind, max_tree_size, limit);\n \t  if (i + 1 < group_size)\n \t    res |= vect_analyze_slp_instance (vinfo, bst_map,\n-\t\t\t\t\t      rest, kind, max_tree_size);\n+\t\t\t\t\t      rest, kind, max_tree_size, limit);\n \n \t  return res;\n \t}\n@@ -2484,7 +2493,7 @@ vect_analyze_slp_instance (vec_info *vinfo,\n \t\t\t   scalar_stmts_to_slp_tree_map_t *bst_map,\n \t\t\t   stmt_vec_info stmt_info,\n \t\t\t   slp_instance_kind kind,\n-\t\t\t   unsigned max_tree_size)\n+\t\t\t   unsigned max_tree_size, unsigned *limit)\n {\n   unsigned int i;\n   vec<stmt_vec_info> scalar_stmts;\n@@ -2556,7 +2565,7 @@ vect_analyze_slp_instance (vec_info *vinfo,\n   bool res = vect_build_slp_instance (vinfo, kind, scalar_stmts,\n \t\t\t\t      kind == slp_inst_kind_ctor\n \t\t\t\t      ? stmt_info : NULL,\n-\t\t\t\t      max_tree_size, bst_map,\n+\t\t\t\t      max_tree_size, limit, bst_map,\n \t\t\t\t      kind == slp_inst_kind_store\n \t\t\t\t      ? stmt_info : NULL);\n \n@@ -2577,6 +2586,8 @@ vect_analyze_slp (vec_info *vinfo, unsigned max_tree_size)\n \n   DUMP_VECT_SCOPE (\"vect_analyze_slp\");\n \n+  unsigned limit = max_tree_size;\n+\n   scalar_stmts_to_slp_tree_map_t *bst_map\n     = new scalar_stmts_to_slp_tree_map_t ();\n \n@@ -2585,7 +2596,7 @@ vect_analyze_slp (vec_info *vinfo, unsigned max_tree_size)\n     vect_analyze_slp_instance (vinfo, bst_map, first_element,\n \t\t\t       STMT_VINFO_GROUPED_ACCESS (first_element)\n \t\t\t       ? slp_inst_kind_store : slp_inst_kind_ctor,\n-\t\t\t       max_tree_size);\n+\t\t\t       max_tree_size, &limit);\n \n   if (bb_vec_info bb_vinfo = dyn_cast <bb_vec_info> (vinfo))\n     {\n@@ -2595,7 +2606,7 @@ vect_analyze_slp (vec_info *vinfo, unsigned max_tree_size)\n \t  if (vect_build_slp_instance (bb_vinfo, bb_vinfo->roots[i].kind,\n \t\t\t\t       bb_vinfo->roots[i].stmts,\n \t\t\t\t       bb_vinfo->roots[i].root,\n-\t\t\t\t       max_tree_size, bst_map, NULL))\n+\t\t\t\t       max_tree_size, &limit, bst_map, NULL))\n \t    bb_vinfo->roots[i].stmts = vNULL;\n \t}\n     }\n@@ -2609,7 +2620,7 @@ vect_analyze_slp (vec_info *vinfo, unsigned max_tree_size)\n \t  ;\n \telse if (! vect_analyze_slp_instance (vinfo, bst_map, first_element,\n \t\t\t\t\t      slp_inst_kind_reduc_chain,\n-\t\t\t\t\t      max_tree_size))\n+\t\t\t\t\t      max_tree_size, &limit))\n \t  {\n \t    /* Dissolve reduction chain group.  */\n \t    stmt_vec_info vinfo = first_element;\n@@ -2630,7 +2641,8 @@ vect_analyze_slp (vec_info *vinfo, unsigned max_tree_size)\n       /* Find SLP sequences starting from groups of reductions.  */\n       if (loop_vinfo->reductions.length () > 1)\n \tvect_analyze_slp_instance (vinfo, bst_map, loop_vinfo->reductions[0],\n-\t\t\t\t   slp_inst_kind_reduc_group, max_tree_size);\n+\t\t\t\t   slp_inst_kind_reduc_group, max_tree_size,\n+\t\t\t\t   &limit);\n     }\n \n   /* The map keeps a reference on SLP nodes built, release that.  */"}]}