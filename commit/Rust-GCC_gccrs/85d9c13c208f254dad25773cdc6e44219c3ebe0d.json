{"sha": "85d9c13c208f254dad25773cdc6e44219c3ebe0d", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ODVkOWMxM2MyMDhmMjU0ZGFkMjU3NzNjZGM2ZTQ0MjE5YzNlYmUwZA==", "commit": {"author": {"name": "Trevor Smigiel", "email": "tsmigiel@gcc.gnu.org", "date": "2006-11-21T01:35:42Z"}, "committer": {"name": "Trevor Smigiel", "email": "tsmigiel@gcc.gnu.org", "date": "2006-11-21T01:35:42Z"}, "message": "configure.in (skipdirs): Don't build target-libiberty for SPU.\n\nChangeLog\n\n\t* configure.in (skipdirs) : Don't build target-libiberty for SPU.\n\t* configure : Rebuilt.\n\ngcc/ChangeLog\n\n\t* config.gcc : Add target for SPU.\n\t* config/spu/constraints.md : New file.\n\t* config/spu/crt0.c : New file.\n\t* config/spu/crtend.c : New file.\n\t* config/spu/crti.asm : New file.\n\t* config/spu/crtn.asm : New file.\n\t* config/spu/float_unsdidf.c : New file.\n\t* config/spu/float_unssidf.c : New file.\n\t* config/spu/predicates.md : New file.\n\t* config/spu/spu-builtins.def : New file.\n\t* config/spu/spu-builtins.h : New file.\n\t* config/spu/spu-builtins.md : New file.\n\t* config/spu/spu-c.c : New file.\n\t* config/spu/spu-elf.h : New file.\n\t* config/spu/spu-modes.def : New file.\n\t* config/spu/spu-protos.h : New file.\n\t* config/spu/spu.c : New file.\n\t* config/spu/spu.h : New file.\n\t* config/spu/spu.md : New file.\n\t* config/spu/spu.opt : New file.\n\t* config/spu/spu_internals.h : New file.\n\t* config/spu/spu_intrinsics.h : New file.\n\t* config/spu/spu_mfcio.h : New file.\n\t* config/spu/t-spu-elf : New file.\n\t* config/spu/vec_types.h : New file.\n\t* config/spu/vmx2spu.h : New file.\n\t* doc/contrib.texi : Document SPU contributor.\n\t* doc/extend.texi : Document SPU extensions.\n\t* doc/invoke.texi : Document SPU options.\n\t* doc/md.texi : Document SPU constraints.\n\nlibcpp/ChangeLog\n\n\t* configure.ac (need_64bit_hwint): Need 64bit hwint for SPU.\n\t* configure : Rebuilt.\n\nFrom-SVN: r119041", "tree": {"sha": "660a6a760b01414d76e3d26c200e8946444802a6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/660a6a760b01414d76e3d26c200e8946444802a6"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/85d9c13c208f254dad25773cdc6e44219c3ebe0d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/85d9c13c208f254dad25773cdc6e44219c3ebe0d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/85d9c13c208f254dad25773cdc6e44219c3ebe0d", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/85d9c13c208f254dad25773cdc6e44219c3ebe0d/comments", "author": null, "committer": null, "parents": [{"sha": "99f8a411dc763471dcd73cef8b42663e3c64c3f8", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/99f8a411dc763471dcd73cef8b42663e3c64c3f8", "html_url": "https://github.com/Rust-GCC/gccrs/commit/99f8a411dc763471dcd73cef8b42663e3c64c3f8"}], "stats": {"total": 18242, "additions": 18240, "deletions": 2}, "files": [{"sha": "3e01240ccf013c1beb28cf230a68b92785822fb5", "filename": "ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/ChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/ChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/ChangeLog?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -1,3 +1,8 @@\n+2006-11-20  Trevor Smigiel <trevor_smigiel@playstation.sony.com>\n+\n+\t* configure.in (skipdirs) : Don't build target-libiberty for SPU.\n+\t* configure : Rebuilt.\n+\n 2006-11-20  Trevor Smigiel <trevor_smigiel@playstation.sony.com>\n \n \t* MAINTAINERS (Write After Approval): Add myself."}, {"sha": "175c2805733630f802c7df21ad2039696d8dadb9", "filename": "configure", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/configure", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/configure", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/configure?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -1598,6 +1598,9 @@ case \"${target}\" in\n     ;;\n   sparc-*-solaris* | sparc64-*-solaris* | sparcv9-*-solaris*)\n     ;;\n+  spu-*-*)\n+    skipdirs=\"target-libiberty\"\n+    ;;\n   v810-*-*)\n     noconfigdirs=\"$noconfigdirs bfd binutils gas gcc gdb ld target-libstdc++-v3 opcodes target-libgloss ${libgcj}\"\n     ;;"}, {"sha": "3ae50e02c09508871a4ade1e93fbf1ebf5cbd753", "filename": "configure.in", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/configure.in", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/configure.in", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/configure.in?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -774,6 +774,9 @@ case \"${target}\" in\n     ;;\n   sparc-*-solaris* | sparc64-*-solaris* | sparcv9-*-solaris*)\n     ;;\n+  spu-*-*)\n+    skipdirs=\"target-libiberty\"\n+    ;;\n   v810-*-*)\n     noconfigdirs=\"$noconfigdirs bfd binutils gas gcc gdb ld target-libstdc++-v3 opcodes target-libgloss ${libgcj}\"\n     ;;"}, {"sha": "fbeb695d90a314036d122db6f2577d721cdb5404", "filename": "gcc/ChangeLog", "status": "modified", "additions": 39, "deletions": 0, "changes": 39, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -1,3 +1,42 @@\n+2006-11-20  Trevor Smigiel <Trevor_Smigiel@playstation.sony.com>\n+\tRussell Olsen <Russell_Olsen@playstation.sony.com>\n+\tDmitri Makarov <Dmitri_Makarov@playstation.sony.com>\n+\tYukishige Shibata <shibata@rd.scei.sony.co.jp>\n+\tNobuhisa Fujinami <fnami@rd.scei.sony.co.jp>\n+\tTakeaki Fukuoka <fukuoka@rd.scei.sony.co.jp>\n+\tAndrew Pinski <Andrew_Pinski@playstation.sony.com>\n+\n+\t* config.gcc : Add target for SPU.\n+\t* config/spu/constraints.md : New file.\n+\t* config/spu/crt0.c : New file.\n+\t* config/spu/crtend.c : New file.\n+\t* config/spu/crti.asm : New file.\n+\t* config/spu/crtn.asm : New file.\n+\t* config/spu/float_unsdidf.c : New file.\n+\t* config/spu/float_unssidf.c : New file.\n+\t* config/spu/predicates.md : New file.\n+\t* config/spu/spu-builtins.def : New file.\n+\t* config/spu/spu-builtins.h : New file.\n+\t* config/spu/spu-builtins.md : New file.\n+\t* config/spu/spu-c.c : New file.\n+\t* config/spu/spu-elf.h : New file.\n+\t* config/spu/spu-modes.def : New file.\n+\t* config/spu/spu-protos.h : New file.\n+\t* config/spu/spu.c : New file.\n+\t* config/spu/spu.h : New file.\n+\t* config/spu/spu.md : New file.\n+\t* config/spu/spu.opt : New file.\n+\t* config/spu/spu_internals.h : New file.\n+\t* config/spu/spu_intrinsics.h : New file.\n+\t* config/spu/spu_mfcio.h : New file.\n+\t* config/spu/t-spu-elf : New file.\n+\t* config/spu/vec_types.h : New file.\n+\t* config/spu/vmx2spu.h : New file.\n+\t* doc/contrib.texi : Document SPU contributor.\n+\t* doc/extend.texi : Document SPU extensions.\n+\t* doc/invoke.texi : Document SPU options.\n+\t* doc/md.texi : Document SPU constraints.\n+\n 2006-11-21  Zdenek Dvorak <dvorakz@suse.cz>\n \n \t* cfgloopmanip.c (add_loop, duplicate_loop): Do not set level"}, {"sha": "ebabf9e392fedf8448de52aec097434e8fd34865", "filename": "gcc/config.gcc", "status": "modified", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig.gcc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig.gcc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig.gcc?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -321,6 +321,10 @@ sparc64*-*-*)\n sparc*-*-*)\n \tcpu_type=sparc\n \t;;\n+spu*-*-*)\n+\tcpu_type=spu\n+\tneed_64bit_hwint=yes\n+\t;;\n s390*-*-*)\n \tcpu_type=s390\n \tneed_64bit_hwint=yes\n@@ -2326,6 +2330,14 @@ sparc64-*-netbsd*)\n \textra_options=\"${extra_options} sparc/long-double-switch.opt\"\n \ttmake_file=\"${tmake_file} sparc/t-netbsd64\"\n \t;;\n+spu-*-elf*)\n+\ttm_file=\"dbxelf.h elfos.h spu/spu-elf.h spu/spu.h\"\n+\ttmake_file=\"spu/t-spu-elf\"\n+\textra_headers=\"spu_intrinsics.h spu_internals.h vmx2spu.h spu_mfcio.h vec_types.h\"\n+\textra_modes=spu/spu-modes.def\n+\tc_target_objs=\"${c_target_objs} spu-c.o\"\n+\tcxx_target_objs=\"${cxx_target_objs} spu-c.o\"\n+\t;;\n strongarm-*-elf*)\n \ttm_file=\"arm/strongarm-elf.h dbxelf.h elfos.h arm/unknown-elf.h arm/elf.h arm/aout.h arm/arm.h\"\n \ttmake_file=\"arm/t-arm arm/t-strongarm-elf\""}, {"sha": "6c4fb0819230fdee6a5547abee003c59007c1860", "filename": "gcc/config/spu/constraints.md", "status": "added", "additions": 150, "deletions": 0, "changes": 150, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fconstraints.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fconstraints.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fconstraints.md?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,150 @@\n+;; Constraint definitions for SPU\n+;; Copyright (C) 2006 Free Software Foundation, Inc.\n+;;\n+;; This file is free software; you can redistribute it and/or modify it under\n+;; the terms of the GNU General Public License as published by the Free\n+;; Software Foundation; either version 2 of the License, or (at your option) \n+;; any later version.\n+\n+;; This file is distributed in the hope that it will be useful, but WITHOUT\n+;; ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+;; FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+;; for more details.\n+\n+;; You should have received a copy of the GNU General Public License\n+;; along with this file; see the file COPYING.  If not, write to the Free\n+;; Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+;; 02110-1301, USA.\n+\n+\f\n+;; GCC standard constraints:  g, i, m, n, o, p, r, s, E-H, I-P, V, X\n+;; unused for SPU:  E-H, L, Q, d, e, h, j-l, q, t-z\n+\n+;; For most immediate constraints we have 3 variations to deal with the\n+;; fact const_int has no mode.  One variation treats const_int as 32 bit,\n+;; another treats it as 64 bit, and the third sign extends it to 128 bit.\n+\n+(define_constraint \"A\"\n+  \"An immediate which can be loaded with the il/ila/ilh/ilhu instructions.  const_int is treated as a 32 bit value.\"\n+  (ior (and (match_code \"const_int,const_double,const_vector\")\n+\t    (match_test \"immediate_load_p (op, SImode)\"))\n+       (and (match_test \"!TARGET_LARGE_MEM && !flag_pic\")\n+\t    (ior (match_code \"symbol_ref,label_ref\")\n+\t\t (and (match_code \"const\")\n+\t\t      (match_test \"legitimate_const (op, 0)\"))))))\n+\n+(define_constraint \"B\"\n+  \"An immediate for arithmetic instructions (e.g., ai, ceqi).  const_int is treated as a 32 bit value.\"\n+  (and (match_code \"const_int,const_double,const_vector\")\n+       (match_test \"arith_immediate_p (op, SImode, -0x200, 0x1ff)\")))\n+\n+(define_constraint \"C\"\n+  \"An immediate for and/xor/or instructions.  const_int is treated as a 32 bit value.\"\n+  (and (match_code \"const_int,const_double,const_vector\")\n+       (match_test \"logical_immediate_p (op, SImode)\")))\n+\n+(define_constraint \"D\"\n+  \"An immediate for iohl instruction.  const_int is treated as a 32 bit value.\"\n+  (and (match_code \"const_int,const_double,const_vector\")\n+       (match_test \"iohl_immediate_p (op, SImode)\")))\n+\n+(define_constraint \"U\"\n+  \"An immediate which can be loaded with the il/ila/ilh/ilhu instructions.  const_int is sign extended to 128 bit.\"\n+  (and (match_code \"const_int,const_double,const_vector\")\n+       (match_test \"immediate_load_p (op, TImode)\")))\n+\n+(define_constraint \"W\"\n+  \"An immediate for shift and rotate instructions.  const_int is treated as a 32 bit value.\"\n+  (and (match_code \"const_int,const_double,const_vector\")\n+       (match_test \"arith_immediate_p (op, SImode, -0x40, 0x3f)\")))\n+\n+(define_constraint \"Y\"\n+  \"An immediate for and/xor/or instructions.  const_int is sign extended as a 128 bit.\"\n+  (and (match_code \"const_int,const_double,const_vector\")\n+       (match_test \"logical_immediate_p (op, TImode)\")))\n+\n+(define_constraint \"Z\"\n+  \"An immediate for iohl instruction.  const_int is sign extended to 128 bit.\"\n+  (and (match_code \"const_int,const_double,const_vector\")\n+       (match_test \"iohl_immediate_p (op, TImode)\")))\n+\n+(define_constraint \"a\"\n+  \"An immediate which can be loaded with the il/ila/ilh/ilhu instructions.  const_int is treated as a 64 bit value.\"\n+  (and (match_code \"const_int\")\n+       (match_test \"immediate_load_p (op, DImode)\")))\n+\n+(define_constraint \"c\"\n+  \"An immediate for and/xor/or instructions.  const_int is treated as a 64 bit value.\"\n+  (and (match_code \"const_int\")\n+       (match_test \"logical_immediate_p (op, DImode)\")))\n+\n+(define_constraint \"d\"\n+  \"An immediate for iohl instruction.  const_int is treated as a 64 bit value.\"\n+  (and (match_code \"const_int\")\n+       (match_test \"iohl_immediate_p (op, DImode)\")))\n+\n+(define_constraint \"f\"\n+  \"An immediate which can be loaded with fsmbi.\"\n+  (and (match_code \"const_int,const_double,const_vector\")\n+       (match_test \"fsmbi_const_p (op)\")))\n+\f\n+;; Integer constraints\n+\n+(define_constraint \"I\"\n+  \"A constant in the range [-64, 63] for shift/rotate instructions.\"\n+  (and (match_code \"const_int\")\n+       (match_test \"ival >= -0x40 && ival <= 0x3f\")))\n+\n+(define_constraint \"J\"\n+  \"An unsigned 7-bit constant for conversion/nop/channel instructions.\"\n+  (and (match_code \"const_int\")\n+       (match_test \"ival >= 0 && ival <= 0x7f\")))\n+\n+(define_constraint \"K\"\n+  \"A signed 10-bit constant for most arithmetic instructions.\"\n+  (and (match_code \"const_int\")\n+       (match_test \"ival >= -0x200 && ival <= 0x1ff\")))\n+ \n+(define_constraint \"M\"\n+  \"A signed 16 bit immediate for @code{stop}.\"\n+  (and (match_code \"const_int\")\n+       (match_test \"ival >= -0x8000ll && ival <= 0x7fffll\")))\n+\n+(define_constraint \"N\"\n+  \"An unsigned 16-bit constant for @code{iohl} and @code{fsmbi}.\"\n+  (and (match_code \"const_int\")\n+       (match_test \"ival >= 0 && ival <= 0xffff\")))\n+\n+(define_constraint \"O\"\n+  \"An unsigned 7-bit constant whose 3 least significant bits are 0.\"\n+  (and (match_code \"const_int\")\n+       (match_test \"ival >= 0 && ival <= 0x7f && (ival & 7) == 0\")))\n+\n+(define_constraint \"P\"\n+  \"An unsigned 3-bit constant for 16-byte rotates and shifts\"\n+  (and (match_code \"const_int\")\n+       (match_test \"ival >= 0 && ival <= 7\")))\n+\n+\f\n+;; Memory constraints\n+\n+(define_memory_constraint \"R\"\n+  \"Call operand, reg, for indirect calls\"\n+  (and (match_code \"mem\")\n+       (match_test \"GET_CODE(XEXP(op, 0)) == REG\")))\n+\n+(define_memory_constraint \"S\"\n+  \"Call operand, symbol, for relative calls.\"\n+  (and (match_code \"mem\")\n+       (match_test \"!TARGET_LARGE_MEM\n+\t\t    && ((GET_CODE (XEXP (op, 0)) == SYMBOL_REF\n+\t\t\t || GET_CODE (XEXP (op, 0)) == LABEL_REF))\")))\n+\n+(define_memory_constraint \"T\"\n+  \"Call operand, const_int, for absolute calls.\"\n+  (and (match_code \"mem\")\n+       (match_test \"GET_CODE (XEXP (op, 0)) == CONST_INT\n+\t\t    && INTVAL (XEXP (op, 0)) >= 0\n+\t\t    && INTVAL (XEXP (op, 0)) <= 0x3ffff\")))\n+\n+"}, {"sha": "8c03abe12b6cbc42d6ae6309e20a204de96657ca", "filename": "gcc/config/spu/crt0.c", "status": "added", "additions": 130, "deletions": 0, "changes": 130, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fcrt0.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fcrt0.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fcrt0.c?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,130 @@\n+/* Copyright (C) 2006 Free Software Foundation, Inc.\n+  \n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option)\n+   any later version.\n+  \n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+  \n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+/* As a special exception, if you link this library with files compiled with\n+   GCC to produce an executable, this does not cause the resulting executable\n+   to be covered by the GNU General Public License.  The exception does not\n+   however invalidate any other reasons why the executable file might be covered\n+   by the GNU General Public License. */\n+\n+extern int main(int, unsigned long long, unsigned long long);\n+void _start(int, unsigned long long, unsigned long long) __attribute__((__naked__));\n+\n+extern void exit(int);\n+\n+void _exit(int) __attribute__((__naked__));\n+\n+typedef void (*func_ptr) (void);\n+typedef __attribute__ ((__vector_size__(16))) unsigned int vec_uint4;\n+\n+extern vec_uint4 __stack[];\n+register vec_uint4 si_sp __asm__(\"$sp\");\n+register unsigned int si_r2 __asm__(\"$2\");\n+\n+extern char _end[];\n+\n+/* If we want these aligned we need to do it in the linker script. */\n+func_ptr __CTOR_LIST__[1]\n+  __attribute__ ((__section__(\".ctors\"), __aligned__(4)))\n+  = { (func_ptr) (-1) };\n+\n+static func_ptr __DTOR_LIST__[1]\n+  __attribute__((__section__(\".dtors\"), __aligned__(4)))\n+  = { (func_ptr) (-1) };\n+\n+\n+/* According to the BE Linux ABI an SPU module is called with these\n+ * parameters.  Also, $2 is set to the Available Stack Size.  */\n+void\n+_start(int spu_id,\n+       unsigned long long param,\n+       unsigned long long env)\n+{\n+  unsigned int stack_size;\n+  unsigned int sp = (unsigned int)(__stack - 2);\n+\n+  /* Initialize the stack.  __stack has been set to point to the top\n+     quadword of the stack.  The ABI requires at least a NULL terminated\n+     back chain and lr save area.  For example:\n+         +----------------+\n+\t | 0              |\n+         +----------------+  <-  __stack (e.g., 0x3fff0)\n+\t | space for $lr  |\n+         +----------------+\n+\t | back chain     |\n+         +----------------+  <-  $sp  (e.g., __stack - 32, 0x3ffd0)\n+  */\n+  __stack[0] = (vec_uint4){0, 0, 0, 0};\n+  __stack[-1] = (vec_uint4){0, 0, 0, 0};\n+\n+  /* Initialize the Available Stack Size word of the Stack Pointer\n+   * information register.  The BE Linux ABI passes the stack size in\n+   * $2, or use everything up to _end if $2 == 0. */\n+  stack_size = si_r2 == 0 ? sp - (unsigned int)_end : si_r2;\n+\n+  __stack[-2] = (vec_uint4){(unsigned int)__stack, stack_size, 0, 0};\n+\n+  si_sp = (vec_uint4){sp, stack_size, 0, 0};\n+\n+\n+  {\n+    extern func_ptr __CTOR_END__[];\n+    func_ptr *p;\n+\n+    /* The compiler assumes all symbols are 16 byte aligned, which is\n+     * not the case for __CTOR_END__.  This inline assembly makes sure\n+     * the address is loaded into a register for which the compiler does\n+     * not assume anything about alignment. */\n+    __asm__ (\"\\n\" : \"=r\" (p) : \"0\" (__CTOR_END__ - 1));\n+\n+    for (; *p != (func_ptr) -1; p--)\n+      (*p) ();\n+  }\n+\n+  exit(main(spu_id, param, env));\n+  __asm__ volatile ( \"\tstop\t0x20ff\");\n+}\n+\n+/* C99 requires _Exit */\n+void _Exit(int) __attribute__((__weak__, __alias__(\"_exit\")));\n+\n+void\n+_exit(int rc)\n+{\n+  {\n+    static func_ptr *p = 0;\n+    if (!p)\n+      {\n+\t/* See comment for __CTOR_END__ above. */\n+\t__asm__ (\"\" : \"=r\" (p) : \"0\" (__DTOR_LIST__ + 1));\n+\tfor (; *p; p++)\n+\t  (*p) ();\n+      }\n+  }\n+  /* Some self modifying code to return 'rc' in the 'stop' insn. */\n+  __asm__ volatile (\n+    \"\tori\t$3, %0,0\\n\"\n+    \"\tlqr\t$4, 1f\\n\"\n+    \"\tcbd\t$5, 1f+3($sp)\\n\"\n+    \"\tshufb\t$0, %0, $4, $5\\n\"\n+    \"\tstqr\t$0, 1f\\n\"\n+    \"\tsync\\n\"\n+    \"1:\\n\"\n+    \"\tstop\t0x2000\\n\"\n+    : : \"r\" (rc) );\n+}\n+"}, {"sha": "694a7eef2447f5f4d76ad45b034701741df1d778", "filename": "gcc/config/spu/crtend.c", "status": "added", "additions": 32, "deletions": 0, "changes": 32, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fcrtend.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fcrtend.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fcrtend.c?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,32 @@\n+/* Copyright (C) 2006 Free Software Foundation, Inc.\n+\n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option) \n+   any later version.\n+\n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+/* As a special exception, if you link this library with files compiled with \n+   GCC to produce an executable, this does not cause the resulting executable \n+   to be covered by the GNU General Public License.  The exception does not \n+   however invalidate any other reasons why the executable file might be covered \n+   by the GNU General Public License. */\n+\n+typedef void (*func_ptr) (void);\n+\n+func_ptr __CTOR_END__[1]\n+  __attribute__ ((section(\".ctors\"), aligned(sizeof(func_ptr))))\n+  = { (func_ptr) (0) };\n+\n+func_ptr __DTOR_END__[1]\n+  __attribute__((section(\".dtors\"), aligned(sizeof(func_ptr))))\n+  = { (func_ptr) (0) };"}, {"sha": "dd0aa3da8adb2df16e45360a16eeaf140faee6ce", "filename": "gcc/config/spu/crti.asm", "status": "added", "additions": 53, "deletions": 0, "changes": 53, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fcrti.asm", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fcrti.asm", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fcrti.asm?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,53 @@\n+#  Copyright (C) 2006 Free Software Foundation, Inc.\n+#\n+#  This file is free software; you can redistribute it and/or modify it under\n+#  the terms of the GNU General Public License as published by the Free\n+#  Software Foundation; either version 2 of the License, or (at your option) \n+#  any later version.\n+#\n+#  This file is distributed in the hope that it will be useful, but WITHOUT\n+#  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+#  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+#  for more details.\n+#\n+#  You should have received a copy of the GNU General Public License\n+#  along with this file; see the file COPYING.  If not, write to the Free\n+#  Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+#  02110-1301, USA.  */\n+# \n+#    As a special exception, if you link this library with files\n+#    compiled with GCC to produce an executable, this does not cause\n+#    the resulting executable to be covered by the GNU General Public License.\n+#    This exception does not however invalidate any other reasons why\n+#    the executable file might be covered by the GNU General Public License.\n+# \n+\n+# This file just make a stack frame for the contents of the .fini and\n+# .init sections.  Users may put any desired instructions in those\n+# sections.\n+\n+\t# Note - this macro is complimented by the FUNC_END macro\n+\t# in crtn.asm.  If you change this macro you must also change\n+\t# that macro match.\n+.macro FUNC_START\n+\t#  Create a stack frame and save any call-preserved registers\n+\tai\t$sp, $sp, -16\n+\tstqd\t$lr, 0($sp)\n+.endm\n+\t\t\n+\t.file\t\t\"crti.asm\"\n+\n+\t.section\t\".init\"\n+\t.align 2\n+\t.global\t_init\n+_init:\n+\tFUNC_START\n+\t\n+\t\t\n+\t.section\t\".fini\"\n+\t.align\t2\n+\t.global\t_fini\n+_fini:\n+\tFUNC_START\n+\t\n+# end of crti.asm"}, {"sha": "27b5276198a0ea05455eeff661b99916c63ea82a", "filename": "gcc/config/spu/crtn.asm", "status": "added", "additions": 54, "deletions": 0, "changes": 54, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fcrtn.asm", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fcrtn.asm", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fcrtn.asm?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,54 @@\n+#  Copyright (C) 2006 Free Software Foundation, Inc.\n+#\n+#  This file is free software; you can redistribute it and/or modify it under\n+#  the terms of the GNU General Public License as published by the Free\n+#  Software Foundation; either version 2 of the License, or (at your option) \n+#  any later version.\n+#\n+#  This file is distributed in the hope that it will be useful, but WITHOUT\n+#  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+#  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+#  for more details.\n+#\n+#  You should have received a copy of the GNU General Public License\n+#  along with this file; see the file COPYING.  If not, write to the Free\n+#  Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+#  02110-1301, USA.  */\n+# \n+#    As a special exception, if you link this library with files\n+#    compiled with GCC to produce an executable, this does not cause\n+#    the resulting executable to be covered by the GNU General Public License.\n+#    This exception does not however invalidate any other reasons why\n+#    the executable file might be covered by the GNU General Public License.\n+# \n+\n+# This file just makes sure that the .fini and .init sections do in\n+# fact return.  Users may put any desired instructions in those sections.\n+# This file is the last thing linked into any executable.\n+\n+\t# Note - this macro is complimented by the FUNC_START macro\n+\t# in crti.asm.  If you change this macro you must also change\n+\t# that macro match.\n+\t#\n+\t# Note - we do not try any fancy optimisations of the return\n+\t# sequences here, it is just not worth it.  Instead keep things\n+\t# simple.  Restore all the save resgisters, including the link\n+\t# register and then perform the correct function return instruction.\n+.macro FUNC_END\n+\tlqd\t$lr, 0($sp)\n+\tai\t$sp, $sp, 16\n+\tbi\t$lr\n+.endm\n+\t\t\n+\t\n+\t.file\t\t\"crtn.asm\"\n+\n+\t.section\t\".init\"\n+\t;;\n+\tFUNC_END\n+\t\n+\t.section\t\".fini\"\n+\t;;\n+\tFUNC_END\n+\t\n+# end of crtn.asm"}, {"sha": "9b3094915eeacaf60ae9b5002c0d1985cfdbbb68", "filename": "gcc/config/spu/float_unsdidf.c", "status": "added", "additions": 56, "deletions": 0, "changes": 56, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Ffloat_unsdidf.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Ffloat_unsdidf.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Ffloat_unsdidf.c?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,56 @@\n+/* Copyright (C) 2006 Free Software Foundation, Inc.\n+  \n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option)\n+   any later version.\n+  \n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+  \n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+/* As a special exception, if you link this library with files compiled with\n+   GCC to produce an executable, this does not cause the resulting executable\n+   to be covered by the GNU General Public License.  The exception does not\n+   however invalidate any other reasons why the executable file might be covered\n+   by the GNU General Public License. */\n+\n+#include <spu_intrinsics.h>\n+const unsigned char __didf_scale[16] __attribute__ ((__aligned__ (16))) = {\n+  0x00, 0x00, 0x04, 0x3e,\n+  0x00, 0x00, 0x04, 0x1e,\n+  0x00, 0x00, 0x00, 0x00,\n+  0x00, 0x00, 0x00, 0x00\n+};\n+const unsigned char __didf_pat[16] __attribute__ ((__aligned__ (16))) = {\n+  0x02, 0x03, 0x10, 0x11,\n+  0x12, 0x13, 0x80, 0x80,\n+  0x06, 0x07, 0x14, 0x15,\n+  0x16, 0x17, 0x80, 0x80\n+};\n+\n+/* double __float_unsdidf (unsigned long long int) \n+   Construct two exact doubles representing the high and low parts (in\n+   parallel), then add them. */\n+qword __float_unsdidf (qword DI);\n+qword\n+__float_unsdidf (qword DI)\n+{\n+  qword t0, t1, t2, t3, t4, t5, t6, t7, t8;\n+  t0 = si_clz (DI);\n+  t1 = si_shl (DI, t0);\n+  t2 = si_ceqi (t0, 32);\n+  t3 = si_sf (t0, *(qword *) __didf_scale);\n+  t4 = si_a (t1, t1);\n+  t5 = si_andc (t3, t2);\n+  t6 = si_shufb (t5, t4, *(qword *) __didf_pat);\n+  t7 = si_shlqbii (t6, 4);\n+  t8 = si_shlqbyi (t7, 8);\n+  return si_dfa (t7, t8);\n+}"}, {"sha": "63d475b7c9d1e35662c38d7e8462437066752892", "filename": "gcc/config/spu/float_unssidf.c", "status": "added", "additions": 47, "deletions": 0, "changes": 47, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Ffloat_unssidf.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Ffloat_unssidf.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Ffloat_unssidf.c?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,47 @@\n+/* Copyright (C) 2006 Free Software Foundation, Inc.\n+  \n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option)\n+   any later version.\n+  \n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+  \n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+/* As a special exception, if you link this library with files compiled with\n+   GCC to produce an executable, this does not cause the resulting executable\n+   to be covered by the GNU General Public License.  The exception does not\n+   however invalidate any other reasons why the executable file might be covered\n+   by the GNU General Public License. */\n+\n+#include <spu_intrinsics.h>\n+const unsigned char __sidf_pat[16] __attribute__ ((__aligned__ (16))) = {\n+  0x02, 0x03, 0x10, 0x11,\n+  0x12, 0x13, 0x80, 0x80,\n+  0x06, 0x07, 0x14, 0x15,\n+  0x16, 0x17, 0x80, 0x80\n+};\n+\n+/* double __float_unssidf (unsigned int SI) */\n+qword __float_unssidf (qword SI);\n+qword\n+__float_unssidf (qword SI)\n+{\n+  qword t0, t1, t2, t3, t4, t5, t6, t7;\n+  t0 = si_clz (SI);\n+  t1 = si_il (1054);\n+  t2 = si_shl (SI, t0);\n+  t3 = si_ceqi (t0, 32);\n+  t4 = si_sf (t0, t1);\n+  t5 = si_a (t2, t2);\n+  t6 = si_andc (t4, t3);\n+  t7 = si_shufb (t6, t5, *(qword *)__sidf_pat);\n+  return si_shlqbii (t7, 4);\n+}"}, {"sha": "0474d840c1c496296de9782a6c6b979216d2573a", "filename": "gcc/config/spu/predicates.md", "status": "added", "additions": 100, "deletions": 0, "changes": 100, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fpredicates.md?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,100 @@\n+;; Predicate definitions for CELL SPU\n+;; Copyright (C) 2006 Free Software Foundation, Inc.\n+;;\n+;; This file is free software; you can redistribute it and/or modify it under\n+;; the terms of the GNU General Public License as published by the Free\n+;; Software Foundation; either version 2 of the License, or (at your option) \n+;; any later version.\n+\n+;; This file is distributed in the hope that it will be useful, but WITHOUT\n+;; ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+;; FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+;; for more details.\n+\n+;; You should have received a copy of the GNU General Public License\n+;; along with this file; see the file COPYING.  If not, write to the Free\n+;; Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+;; 02110-1301, USA.\n+\n+(define_predicate \"spu_reg_operand\"\n+  (and (match_operand 0 \"register_operand\")\n+       (ior (not (match_code \"subreg\"))\n+            (match_test \"valid_subreg (op)\"))))\n+\n+(define_predicate \"spu_nonimm_operand\"\n+  (and (match_operand 0 \"nonimmediate_operand\")\n+       (ior (not (match_code \"subreg\"))\n+            (match_test \"valid_subreg (op)\"))))\n+\n+(define_predicate \"spu_nonmem_operand\"\n+  (and (match_operand 0 \"nonmemory_operand\")\n+       (ior (not (match_code \"subreg\"))\n+            (match_test \"valid_subreg (op)\"))))\n+\n+(define_predicate \"spu_mem_operand\"\n+  (and (match_operand 0 \"memory_operand\")\n+       (match_test \"reload_in_progress || reload_completed || aligned_mem_p (op)\")))\n+\n+(define_predicate \"call_operand\"\n+  (and (match_code \"mem\")\n+       (match_test \"(!TARGET_LARGE_MEM && satisfies_constraint_S (op))\n+\t\t    || (satisfies_constraint_R (op)\n+\t\t\t&& REGNO (XEXP (op, 0)) != FRAME_POINTER_REGNUM\n+\t\t\t&& REGNO (XEXP (op, 0)) != ARG_POINTER_REGNUM\n+\t\t\t&& (REGNO (XEXP (op, 0)) < FIRST_PSEUDO_REGISTER\n+\t\t\t    || REGNO (XEXP (op, 0)) > LAST_VIRTUAL_REGISTER))\")))\n+\n+(define_predicate \"vec_imm_operand\"\n+  (and (match_code \"const_int,const_double,const_vector\")\n+       (match_test \"spu_legitimate_constant_p (op)\")))\n+\n+(define_predicate \"spu_arith_operand\"\n+  (match_code \"reg,subreg,const_int,const_vector\")\n+  {\n+    if (spu_reg_operand (op, mode))\n+      return 1;\n+    if (GET_CODE (op) == CONST_INT || GET_CODE (op) == CONST_VECTOR)\n+      return arith_immediate_p (op, mode, -0x200, 0x1ff);\n+    return 0;\n+  })\n+\n+(define_predicate \"spu_logical_operand\"\n+  (match_code \"reg,subreg,const_int,const_double,const_vector\")\n+  {\n+    if (spu_reg_operand (op, mode))\n+      return 1;\n+    if (GET_CODE (op) == CONST_INT || GET_CODE (op) == CONST_DOUBLE\n+\t|| GET_CODE (op) == CONST_VECTOR)\n+      return logical_immediate_p (op, mode);\n+    return 0;\n+  })\n+\n+(define_predicate \"spu_ior_operand\"\n+  (match_code \"reg,subreg,const_int,const_double,const_vector\")\n+  {\n+    if (spu_reg_operand (op, mode))\n+      return 1;\n+    if (GET_CODE (op) == CONST_INT || GET_CODE (op) == CONST_DOUBLE\n+\t|| GET_CODE (op) == CONST_VECTOR)\n+      return logical_immediate_p (op, mode)\n+\t     || iohl_immediate_p (op, mode);\n+    return 0;\n+  })\n+\n+(define_predicate \"spu_shift_operand\"\n+  (match_code \"reg,subreg,const_int,const_vector\")\n+  {\n+    if (spu_reg_operand (op, mode))\n+      return 1;\n+    if (GET_CODE (op) == CONST_INT || GET_CODE (op) == CONST_VECTOR)\n+      return arith_immediate_p (op, mode, -0x40, 0x3f);\n+    return 0;\n+  })\n+\n+;; Return 1 if OP is a comparison operation that is valid for a branch insn.\n+;; We only check the opcode against the mode of the register value here. \n+(define_predicate \"branch_comparison_operator\"\n+  (and (match_code \"eq,ne\")\n+       (ior (match_test \"GET_MODE (XEXP (op, 0)) == HImode\")\n+\t    (match_test \"GET_MODE (XEXP (op, 0)) == SImode\"))))\n+"}, {"sha": "af8a8885a830935f3757d7782f71f9738f9473c6", "filename": "gcc/config/spu/spu-builtins.def", "status": "added", "additions": 715, "deletions": 0, "changes": 715, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu-builtins.def?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,715 @@\n+/* Definitions of builtin fuctions for the Synergistic Processing Unit (SPU). */\n+/* Copyright (C) 2006 Free Software Foundation, Inc.\n+\n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option) \n+   any later version.\n+\n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+\n+/* The first argument to these macros is the return type of the builtin,\n+ * the rest are arguments of the builtin. */\n+#define _A1(a)       {a, SPU_BTI_END_OF_PARAMS}\n+#define _A2(a,b)     {a, b, SPU_BTI_END_OF_PARAMS}\n+#define _A3(a,b,c)   {a, b, c, SPU_BTI_END_OF_PARAMS}\n+#define _A4(a,b,c,d) {a, b, c, d, SPU_BTI_END_OF_PARAMS}\n+\n+/* definitions to support si intrinisic functions: (These and other builtin \n+ * definitions must preceed definitions of the overloaded generic intrinsics */\n+\n+DEF_BUILTIN (SI_LQD,         CODE_FOR_spu_lqd,       \"si_lqd\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10_4))\n+DEF_BUILTIN (SI_LQX,         CODE_FOR_spu_lqx,       \"si_lqx\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_LQA,         CODE_FOR_spu_lqa,       \"si_lqa\",         B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_U16_2))\n+DEF_BUILTIN (SI_LQR,         CODE_FOR_spu_lqr,       \"si_lqr\",         B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_S16_2))\n+DEF_BUILTIN (SI_STQD,        CODE_FOR_spu_stqd,      \"si_stqd\",        B_INSN,   _A4(SPU_BTI_VOID,     SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10_4))\n+DEF_BUILTIN (SI_STQX,        CODE_FOR_spu_stqx,      \"si_stqx\",        B_INSN,   _A4(SPU_BTI_VOID,     SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_STQA,        CODE_FOR_spu_stqa,      \"si_stqa\",        B_INSN,   _A3(SPU_BTI_VOID,     SPU_BTI_QUADWORD, SPU_BTI_U16_2))\n+DEF_BUILTIN (SI_STQR,        CODE_FOR_spu_stqr,      \"si_stqr\",        B_INSN,   _A3(SPU_BTI_VOID,     SPU_BTI_QUADWORD, SPU_BTI_S16_2))\n+DEF_BUILTIN (SI_CBD,         CODE_FOR_spu_cbx,       \"si_cbd\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S7))\n+DEF_BUILTIN (SI_CBX,         CODE_FOR_spu_cbx,       \"si_cbx\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CHD,         CODE_FOR_spu_chx,       \"si_chd\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S7))\n+DEF_BUILTIN (SI_CHX,         CODE_FOR_spu_chx,       \"si_chx\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CWD,         CODE_FOR_spu_cwx,       \"si_cwd\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S7))\n+DEF_BUILTIN (SI_CWX,         CODE_FOR_spu_cwx,       \"si_cwx\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CDD,         CODE_FOR_spu_cdx,       \"si_cdd\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S7))\n+DEF_BUILTIN (SI_CDX,         CODE_FOR_spu_cdx,       \"si_cdx\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ILH,         CODE_FOR_movv8hi,       \"si_ilh\",         B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_16))\n+DEF_BUILTIN (SI_ILHU,        CODE_FOR_spu_ilhu,      \"si_ilhu\",        B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_16))\n+DEF_BUILTIN (SI_IL,          CODE_FOR_movv4si,       \"si_il\",          B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_S16))\n+DEF_BUILTIN (SI_ILA,         CODE_FOR_movv4si,       \"si_ila\",         B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_U18))\n+DEF_BUILTIN (SI_IOHL,        CODE_FOR_iorv4si3,      \"si_iohl\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_U16))\n+DEF_BUILTIN (SI_FSMBI,       CODE_FOR_spu_fsmb,      \"si_fsmbi\",       B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_16))\n+DEF_BUILTIN (SI_AH,          CODE_FOR_addv8hi3,      \"si_ah\",          B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_AHI,         CODE_FOR_addv8hi3,      \"si_ahi\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_A,           CODE_FOR_addv4si3,      \"si_a\",           B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_AI,          CODE_FOR_addv4si3,      \"si_ai\",          B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_ADDX,        CODE_FOR_addx_v4si,     \"si_addx\",        B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CG,          CODE_FOR_cg_v4si,       \"si_cg\",          B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CGX,         CODE_FOR_cgx_v4si,      \"si_cgx\",         B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_SFH,         CODE_FOR_spu_sfh,       \"si_sfh\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_SFHI,        CODE_FOR_spu_sfh,       \"si_sfhi\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_SF,          CODE_FOR_spu_sf,        \"si_sf\",          B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_SFI,         CODE_FOR_spu_sf,        \"si_sfi\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_SFX,         CODE_FOR_spu_sfx,       \"si_sfx\",         B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_BG,          CODE_FOR_spu_bg,        \"si_bg\",          B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_BGX,         CODE_FOR_spu_bgx,       \"si_bgx\",         B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_MPY,         CODE_FOR_spu_mpy,       \"si_mpy\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_MPYU,        CODE_FOR_spu_mpyu,      \"si_mpyu\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_MPYI,        CODE_FOR_spu_mpy,       \"si_mpyi\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_MPYUI,       CODE_FOR_spu_mpyu,      \"si_mpyui\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_MPYA,        CODE_FOR_spu_mpya,      \"si_mpya\",        B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_MPYH,        CODE_FOR_spu_mpyh,      \"si_mpyh\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_MPYS,        CODE_FOR_spu_mpys,      \"si_mpys\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_MPYHH,       CODE_FOR_spu_mpyhh,     \"si_mpyhh\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_MPYHHU,      CODE_FOR_spu_mpyhhu,    \"si_mpyhhu\",      B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_MPYHHA,      CODE_FOR_spu_mpyhha,    \"si_mpyhha\",      B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_MPYHHAU,     CODE_FOR_spu_mpyhhau,   \"si_mpyhhau\",     B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CLZ,         CODE_FOR_clzv4si2,      \"si_clz\",         B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CNTB,        CODE_FOR_cntb_v16qi,    \"si_cntb\",        B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FSMB,        CODE_FOR_spu_fsmb,      \"si_fsmb\",        B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FSMH,        CODE_FOR_spu_fsmh,      \"si_fsmh\",        B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FSM,         CODE_FOR_spu_fsm,       \"si_fsm\",         B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_GBB,         CODE_FOR_spu_gbb,       \"si_gbb\",         B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_GBH,         CODE_FOR_spu_gbh,       \"si_gbh\",         B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_GB,          CODE_FOR_spu_gb,        \"si_gb\",          B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_AVGB,        CODE_FOR_spu_avgb,      \"si_avgb\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ABSDB,       CODE_FOR_spu_absdb,     \"si_absdb\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_SUMB,        CODE_FOR_spu_sumb,      \"si_sumb\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_XSBH,        CODE_FOR_spu_xsbh,      \"si_xsbh\",        B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_XSHW,        CODE_FOR_spu_xshw,      \"si_xshw\",        B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_XSWD,        CODE_FOR_spu_xswd,      \"si_xswd\",        B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_AND,         CODE_FOR_andv16qi3,     \"si_and\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ANDC,        CODE_FOR_andc_v16qi,    \"si_andc\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ANDBI,       CODE_FOR_andv16qi3,     \"si_andbi\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_ANDHI,       CODE_FOR_andv8hi3,      \"si_andhi\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_ANDI,        CODE_FOR_andv4si3,      \"si_andi\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_OR,          CODE_FOR_iorv16qi3,     \"si_or\",          B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ORC,         CODE_FOR_orc_v16qi,     \"si_orc\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ORBI,        CODE_FOR_iorv16qi3,     \"si_orbi\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_ORHI,        CODE_FOR_iorv8hi3,      \"si_orhi\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_ORI,         CODE_FOR_iorv4si3,      \"si_ori\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_ORX,         CODE_FOR_spu_orx,       \"si_orx\",         B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_XOR,         CODE_FOR_xorv16qi3,     \"si_xor\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_XORBI,       CODE_FOR_xorv16qi3,     \"si_xorbi\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_XORHI,       CODE_FOR_xorv8hi3,      \"si_xorhi\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_XORI,        CODE_FOR_xorv4si3,      \"si_xori\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_NAND,        CODE_FOR_nand_v16qi,    \"si_nand\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_NOR,         CODE_FOR_nor_v16qi,     \"si_nor\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_EQV,         CODE_FOR_eqv_v16qi,     \"si_eqv\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_SELB,        CODE_FOR_selb,          \"si_selb\",        B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_SHUFB,       CODE_FOR_shufb,         \"si_shufb\",       B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_SHLH,        CODE_FOR_ashlv8hi3,     \"si_shlh\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_SHLHI,       CODE_FOR_ashlv8hi3,     \"si_shlhi\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_SHL,         CODE_FOR_ashlv4si3,     \"si_shl\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_SHLI,        CODE_FOR_ashlv4si3,     \"si_shli\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_SHLQBI,      CODE_FOR_shlqbi_ti,     \"si_shlqbi\",      B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_SHLQBII,     CODE_FOR_shlqbi_ti,     \"si_shlqbii\",     B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_SHLQBY,      CODE_FOR_shlqby_ti,     \"si_shlqby\",      B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_SHLQBYI,     CODE_FOR_shlqby_ti,     \"si_shlqbyi\",     B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_SHLQBYBI,    CODE_FOR_shlqbybi_ti,   \"si_shlqbybi\",    B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ROTH,        CODE_FOR_rotlv8hi3,     \"si_roth\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ROTHI,       CODE_FOR_rotlv8hi3,     \"si_rothi\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_ROT,         CODE_FOR_rotlv4si3,     \"si_rot\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ROTI,        CODE_FOR_rotlv4si3,     \"si_roti\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_ROTQBY,      CODE_FOR_rotqby_ti,     \"si_rotqby\",      B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ROTQBYI,     CODE_FOR_rotqby_ti,     \"si_rotqbyi\",     B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_ROTQBYBI,    CODE_FOR_rotqbybi_ti,   \"si_rotqbybi\",    B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ROTQBI,      CODE_FOR_rotqbi_ti,     \"si_rotqbi\",      B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ROTQBII,     CODE_FOR_rotqbi_ti,     \"si_rotqbii\",     B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_ROTHM,       CODE_FOR_rotm_v8hi,     \"si_rothm\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ROTHMI,      CODE_FOR_rotm_v8hi,     \"si_rothmi\",      B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_ROTM,        CODE_FOR_rotm_v4si,     \"si_rotm\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ROTMI,       CODE_FOR_rotm_v4si,     \"si_rotmi\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_ROTQMBY,     CODE_FOR_rotqmby_ti,    \"si_rotqmby\",     B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ROTQMBYI,    CODE_FOR_rotqmby_ti,    \"si_rotqmbyi\",    B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_ROTQMBI,     CODE_FOR_rotqmbi_ti,    \"si_rotqmbi\",     B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ROTQMBII,    CODE_FOR_rotqmbi_ti,    \"si_rotqmbii\",    B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_ROTQMBYBI,   CODE_FOR_rotqmbybi_ti,  \"si_rotqmbybi\",   B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ROTMAH,      CODE_FOR_rotma_v8hi,    \"si_rotmah\",      B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ROTMAHI,     CODE_FOR_rotma_v8hi,    \"si_rotmahi\",     B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_ROTMA,       CODE_FOR_rotma_v4si,    \"si_rotma\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_ROTMAI,      CODE_FOR_rotma_v4si,    \"si_rotmai\",      B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_7))\n+DEF_BUILTIN (SI_HEQ,         CODE_FOR_spu_heq,       \"si_heq\",         B_INSN,   _A3(SPU_BTI_VOID,     SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_HEQI,        CODE_FOR_spu_heq,       \"si_heqi\",        B_INSN,   _A3(SPU_BTI_VOID,     SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_HGT,         CODE_FOR_spu_hgt,       \"si_hgt\",         B_INSN,   _A3(SPU_BTI_VOID,     SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_HGTI,        CODE_FOR_spu_hgt,       \"si_hgti\",        B_INSN,   _A3(SPU_BTI_VOID,     SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_HLGT,        CODE_FOR_spu_hlgt,      \"si_hlgt\",        B_INSN,   _A3(SPU_BTI_VOID,     SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_HLGTI,       CODE_FOR_spu_hlgt,      \"si_hlgti\",       B_INSN,   _A3(SPU_BTI_VOID,     SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_CEQB,        CODE_FOR_ceq_v16qi,     \"si_ceqb\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CEQBI,       CODE_FOR_ceq_v16qi,     \"si_ceqbi\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_CEQH,        CODE_FOR_ceq_v8hi,      \"si_ceqh\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CEQHI,       CODE_FOR_ceq_v8hi,      \"si_ceqhi\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_CEQ,         CODE_FOR_ceq_v4si,      \"si_ceq\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CEQI,        CODE_FOR_ceq_v4si,      \"si_ceqi\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_CGTB,        CODE_FOR_cgt_v16qi,     \"si_cgtb\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CGTBI,       CODE_FOR_cgt_v16qi,     \"si_cgtbi\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_CGTH,        CODE_FOR_cgt_v8hi,      \"si_cgth\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CGTHI,       CODE_FOR_cgt_v8hi,      \"si_cgthi\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_CGT,         CODE_FOR_cgt_v4si,      \"si_cgt\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CGTI,        CODE_FOR_cgt_v4si,      \"si_cgti\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_CLGTB,       CODE_FOR_clgt_v16qi,    \"si_clgtb\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CLGTBI,      CODE_FOR_clgt_v16qi,    \"si_clgtbi\",      B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_CLGTH,       CODE_FOR_clgt_v8hi,     \"si_clgth\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CLGTHI,      CODE_FOR_clgt_v8hi,     \"si_clgthi\",      B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_CLGT,        CODE_FOR_clgt_v4si,     \"si_clgt\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CLGTI,       CODE_FOR_clgt_v4si,     \"si_clgti\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_S10))\n+DEF_BUILTIN (SI_FA,          CODE_FOR_addv4sf3,      \"si_fa\",          B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_DFA,         CODE_FOR_addv2df3,      \"si_dfa\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FS,          CODE_FOR_subv4sf3,      \"si_fs\",          B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_DFS,         CODE_FOR_subv2df3,      \"si_dfs\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FM,          CODE_FOR_mulv4sf3,      \"si_fm\",          B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_DFM,         CODE_FOR_mulv2df3,      \"si_dfm\",         B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FMA,         CODE_FOR_fma_v4sf,      \"si_fma\",         B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_DFMA,        CODE_FOR_fma_v2df,      \"si_dfma\",        B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_DFNMA,       CODE_FOR_fnma_v2df,     \"si_dfnma\",       B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FNMS,        CODE_FOR_fnms_v4sf,     \"si_fnms\",        B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_DFNMS,       CODE_FOR_fnms_v2df,     \"si_dfnms\",       B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FMS,         CODE_FOR_fms_v4sf,      \"si_fms\",         B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_DFMS,        CODE_FOR_fms_v2df,      \"si_dfms\",        B_INSN,   _A4(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FREST,       CODE_FOR_frest_v4sf,    \"si_frest\",       B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FRSQEST,     CODE_FOR_frsqest_v4sf,  \"si_frsqest\",     B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FI,          CODE_FOR_fi_v4sf,       \"si_fi\",          B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_CSFLT,       CODE_FOR_spu_csflt,     \"si_csflt\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_U7))\n+DEF_BUILTIN (SI_CFLTS,       CODE_FOR_spu_cflts,     \"si_cflts\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_U7))\n+DEF_BUILTIN (SI_CUFLT,       CODE_FOR_spu_cuflt,     \"si_cuflt\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_U7))\n+DEF_BUILTIN (SI_CFLTU,       CODE_FOR_spu_cfltu,     \"si_cfltu\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_U7))\n+DEF_BUILTIN (SI_FRDS,        CODE_FOR_spu_frds,      \"si_frds\",        B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FESD,        CODE_FOR_spu_fesd,      \"si_fesd\",        B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FCEQ,        CODE_FOR_ceq_v4sf,      \"si_fceq\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FCMEQ,       CODE_FOR_cmeq_v4sf,     \"si_fcmeq\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FCGT,        CODE_FOR_cgt_v4sf,      \"si_fcgt\",        B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FCMGT,       CODE_FOR_cmgt_v4sf,     \"si_fcmgt\",       B_INSN,   _A3(SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_STOP,        CODE_FOR_spu_stop,      \"si_stop\",        B_INSN,   _A2(SPU_BTI_VOID,     SPU_BTI_U14))\n+DEF_BUILTIN (SI_STOPD,       CODE_FOR_spu_stopd,     \"si_stopd\",       B_INSN,   _A4(SPU_BTI_VOID,     SPU_BTI_QUADWORD, SPU_BTI_QUADWORD, SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_LNOP,        CODE_FOR_lnop,          \"si_lnop\",        B_INSN,   _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SI_NOP,         CODE_FOR_nop,           \"si_nop\",         B_INSN,   _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SI_SYNC,        CODE_FOR_sync,          \"si_sync\",        B_INSN,   _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SI_SYNCC,       CODE_FOR_syncc,         \"si_syncc\",       B_INSN,   _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SI_DSYNC,       CODE_FOR_dsync,         \"si_dsync\",       B_INSN,   _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SI_MFSPR,       CODE_FOR_spu_mfspr,     \"si_mfspr\",       B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_U7))\n+DEF_BUILTIN (SI_MTSPR,       CODE_FOR_spu_mtspr,     \"si_mtspr\",       B_INSN,   _A3(SPU_BTI_VOID,     SPU_BTI_U7,       SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FSCRRD,      CODE_FOR_spu_fscrrd,    \"si_fscrrd\",      B_INSN,   _A1(SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FSCRWR,      CODE_FOR_spu_fscrwr,    \"si_fscrwr\",      B_INSN,   _A2(SPU_BTI_VOID,     SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_RDCH,        CODE_FOR_spu_rdch,      \"si_rdch\",        B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_U7))\n+DEF_BUILTIN (SI_RCHCNT,      CODE_FOR_spu_rchcnt,    \"si_rchcnt\",      B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_U7))\n+DEF_BUILTIN (SI_WRCH,        CODE_FOR_spu_wrch,      \"si_wrch\",        B_INSN,   _A3(SPU_BTI_VOID,     SPU_BTI_U7,       SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_TO_CHAR,     CODE_FOR_spu_convert,   \"si_to_char\",     B_INSN,   _A2(SPU_BTI_INTQI,    SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_TO_UCHAR,    CODE_FOR_spu_convert,   \"si_to_uchar\",    B_INSN,   _A2(SPU_BTI_UINTQI,   SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_TO_SHORT,    CODE_FOR_spu_convert,   \"si_to_short\",    B_INSN,   _A2(SPU_BTI_INTHI,    SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_TO_USHORT,   CODE_FOR_spu_convert,   \"si_to_ushort\",   B_INSN,   _A2(SPU_BTI_UINTHI,   SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_TO_INT,      CODE_FOR_spu_convert,   \"si_to_int\",      B_INSN,   _A2(SPU_BTI_INTSI,    SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_TO_UINT,     CODE_FOR_spu_convert,   \"si_to_uint\",     B_INSN,   _A2(SPU_BTI_UINTSI,   SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_TO_LONG,     CODE_FOR_spu_convert,   \"si_to_long\",     B_INSN,   _A2(SPU_BTI_INTDI,    SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_TO_ULONG,    CODE_FOR_spu_convert,   \"si_to_ulong\",    B_INSN,   _A2(SPU_BTI_UINTDI,   SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_TO_FLOAT,    CODE_FOR_spu_convert,   \"si_to_float\",    B_INSN,   _A2(SPU_BTI_FLOAT,    SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_TO_DOUBLE,   CODE_FOR_spu_convert,   \"si_to_double\",   B_INSN,   _A2(SPU_BTI_DOUBLE,   SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_TO_PTR,      CODE_FOR_spu_convert,   \"si_to_ptr\",      B_INSN,   _A2(SPU_BTI_PTR,      SPU_BTI_QUADWORD))\n+DEF_BUILTIN (SI_FROM_CHAR,   CODE_FOR_spu_convert,   \"si_from_char\",   B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_INTQI))\n+DEF_BUILTIN (SI_FROM_UCHAR,  CODE_FOR_spu_convert,   \"si_from_uchar\",  B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_UINTQI))\n+DEF_BUILTIN (SI_FROM_SHORT,  CODE_FOR_spu_convert,   \"si_from_short\",  B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_INTHI))\n+DEF_BUILTIN (SI_FROM_USHORT, CODE_FOR_spu_convert,   \"si_from_ushort\", B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_UINTHI))\n+DEF_BUILTIN (SI_FROM_INT,    CODE_FOR_spu_convert,   \"si_from_int\",    B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_INTSI))\n+DEF_BUILTIN (SI_FROM_UINT,   CODE_FOR_spu_convert,   \"si_from_uint\",   B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_UINTSI))\n+DEF_BUILTIN (SI_FROM_LONG,   CODE_FOR_spu_convert,   \"si_from_long\",   B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_INTDI))\n+DEF_BUILTIN (SI_FROM_ULONG,  CODE_FOR_spu_convert,   \"si_from_ulong\",  B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_UINTDI))\n+DEF_BUILTIN (SI_FROM_FLOAT,  CODE_FOR_spu_convert,   \"si_from_float\",  B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_FLOAT))\n+DEF_BUILTIN (SI_FROM_DOUBLE, CODE_FOR_spu_convert,   \"si_from_double\", B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_DOUBLE))\n+DEF_BUILTIN (SI_FROM_PTR,    CODE_FOR_spu_convert,   \"si_from_ptr\",    B_INSN,   _A2(SPU_BTI_QUADWORD, SPU_BTI_PTR))\n+\n+/* definitions to support generic builtin functions: */\n+\n+DEF_BUILTIN (SPU_CONVTS,     CODE_FOR_spu_cflts,      \"spu_convts\",     B_INSN,     _A3(SPU_BTI_V4SI,     SPU_BTI_V4SF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_CONVTU,     CODE_FOR_spu_cfltu,      \"spu_convtu\",     B_INSN,     _A3(SPU_BTI_UV4SI,    SPU_BTI_V4SF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_ROUNDTF,    CODE_FOR_spu_frds,       \"spu_roundtf\",    B_INSN,     _A2(SPU_BTI_V4SF,     SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_MULH,       CODE_FOR_spu_mpyh,       \"spu_mulh\",       B_INSN,     _A3(SPU_BTI_V4SI,     SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_MULSR,      CODE_FOR_spu_mpys,       \"spu_mulsr\",      B_INSN,     _A3(SPU_BTI_V4SI,     SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_FREST,      CODE_FOR_frest_v4sf,     \"spu_frest\",      B_INSN,     _A2(SPU_BTI_V4SF,     SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_FRSQEST,    CODE_FOR_frsqest_v4sf,   \"spu_frsqest\",    B_INSN,     _A2(SPU_BTI_V4SF,     SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_NMADD,      CODE_FOR_fnma_v2df,      \"spu_nmadd\",      B_INSN,     _A4(SPU_BTI_V2DF,     SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_ABSD,       CODE_FOR_spu_absdb,      \"spu_absd\",       B_INSN,     _A3(SPU_BTI_UV16QI,   SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_AVG,        CODE_FOR_spu_avgb,       \"spu_avg\",        B_INSN,     _A3(SPU_BTI_UV16QI,   SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_SUMB,       CODE_FOR_spu_sumb,       \"spu_sumb\",       B_INSN,     _A3(SPU_BTI_UV8HI,    SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_BISLED,     CODE_FOR_spu_bisled,     \"spu_bisled\",     B_BISLED,   _A3(SPU_BTI_VOID,    SPU_BTI_PTR,   SPU_BTI_PTR))\n+DEF_BUILTIN (SPU_BISLED_D,   CODE_FOR_spu_bisledd,    \"spu_bisled_d\",   B_BISLED,   _A3(SPU_BTI_VOID,    SPU_BTI_PTR,   SPU_BTI_PTR))\n+DEF_BUILTIN (SPU_BISLED_E,   CODE_FOR_spu_bislede,    \"spu_bisled_e\",   B_BISLED,   _A3(SPU_BTI_VOID,    SPU_BTI_PTR,   SPU_BTI_PTR))\n+DEF_BUILTIN (SPU_CMPABSEQ,   CODE_FOR_cmeq_v4sf,      \"spu_cmpabseq\",   B_INSN,     _A3(SPU_BTI_UV4SI,    SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_CMPABSGT,   CODE_FOR_cmgt_v4sf,      \"spu_cmpabsgt\",   B_INSN,     _A3(SPU_BTI_UV4SI,    SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_IDISABLE,   CODE_FOR_spu_idisable,   \"spu_idisable\",   B_INSN,     _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_IENABLE,    CODE_FOR_spu_ienable,    \"spu_ienable\",    B_INSN,     _A1(SPU_BTI_VOID))\n+\n+/* definitions to support overloaded generic builtin functions:  */\n+\n+DEF_BUILTIN (SPU_CONVTF,           CODE_FOR_nothing,       \"spu_convtf\",           B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_CONVTF_0,         CODE_FOR_spu_cuflt,     \"spu_convtf_0\",         B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_CONVTF_1,         CODE_FOR_spu_csflt,     \"spu_convtf_1\",         B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SI,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_EXTEND,           CODE_FOR_nothing,       \"spu_extend\",           B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_EXTEND_0,         CODE_FOR_spu_xsbh,      \"spu_extend_0\",         B_INTERNAL, _A2(SPU_BTI_V8HI,   SPU_BTI_V16QI))\n+DEF_BUILTIN (SPU_EXTEND_1,         CODE_FOR_spu_xshw,      \"spu_extend_1\",         B_INTERNAL, _A2(SPU_BTI_V4SI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_EXTEND_2,         CODE_FOR_spu_xswd,      \"spu_extend_2\",         B_INTERNAL, _A2(SPU_BTI_V2DI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_EXTEND_3,         CODE_FOR_spu_fesd,      \"spu_extend_3\",         B_INTERNAL, _A2(SPU_BTI_V2DF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_ADD,              CODE_FOR_nothing,       \"spu_add\",              B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_ADD_0,            CODE_FOR_addv4si3,      \"spu_add_0\",            B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_ADD_1,            CODE_FOR_addv4si3,      \"spu_add_1\",            B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_ADD_2,            CODE_FOR_addv8hi3,      \"spu_add_2\",            B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_ADD_3,            CODE_FOR_addv8hi3,      \"spu_add_3\",            B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_ADD_4,            CODE_FOR_addv4sf3,      \"spu_add_4\",            B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_ADD_5,            CODE_FOR_addv2df3,      \"spu_add_5\",            B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_ADD_6,            CODE_FOR_addv8hi3,      \"spu_add_6\",            B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UINTHI))\n+DEF_BUILTIN (SPU_ADD_7,            CODE_FOR_addv8hi3,      \"spu_add_7\",            B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_INTHI))\n+DEF_BUILTIN (SPU_ADD_8,            CODE_FOR_addv4si3,      \"spu_add_8\",            B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_ADD_9,            CODE_FOR_addv4si3,      \"spu_add_9\",            B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_ADDX,             CODE_FOR_nothing,       \"spu_addx\",             B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_ADDX_0,           CODE_FOR_addx_v4si,     \"spu_addx_0\",           B_INTERNAL, _A4(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_ADDX_1,           CODE_FOR_addx_v4si,     \"spu_addx_1\",           B_INTERNAL, _A4(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_GENC,             CODE_FOR_nothing,       \"spu_genc\",             B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_GENC_0,           CODE_FOR_cg_v4si,       \"spu_genc_0\",           B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_GENC_1,           CODE_FOR_cg_v4si,       \"spu_genc_1\",           B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_GENCX,            CODE_FOR_nothing,       \"spu_gencx\",            B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_GENCX_0,          CODE_FOR_cgx_v4si,      \"spu_gencx_0\",          B_INTERNAL, _A4(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_GENCX_1,          CODE_FOR_cgx_v4si,      \"spu_gencx_1\",          B_INTERNAL, _A4(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_MADD,             CODE_FOR_nothing,       \"spu_madd\",             B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_MADD_0,           CODE_FOR_spu_mpya,      \"spu_madd_0\",           B_INTERNAL, _A4(SPU_BTI_V4SI,   SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_MADD_1,           CODE_FOR_fma_v4sf,      \"spu_madd_1\",           B_INTERNAL, _A4(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_MADD_2,           CODE_FOR_fma_v2df,      \"spu_madd_2\",           B_INTERNAL, _A4(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_MSUB,             CODE_FOR_nothing,       \"spu_msub\",             B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_MSUB_0,           CODE_FOR_fms_v4sf,      \"spu_msub_0\",           B_INTERNAL, _A4(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_MSUB_1,           CODE_FOR_fms_v2df,      \"spu_msub_1\",           B_INTERNAL, _A4(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_MHHADD,           CODE_FOR_nothing,       \"spu_mhhadd\",           B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_MHHADD_0,         CODE_FOR_spu_mpyhhau,   \"spu_mhhadd_0\",         B_INTERNAL, _A4(SPU_BTI_UV4SI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_MHHADD_1,         CODE_FOR_spu_mpyhha,    \"spu_mhhadd_1\",         B_INTERNAL, _A4(SPU_BTI_V4SI,   SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_MULE,             CODE_FOR_nothing,       \"spu_mule\",             B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_MULE_0,           CODE_FOR_spu_mpyhhu,    \"spu_mule_0\",           B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_MULE_1,           CODE_FOR_spu_mpyhh,     \"spu_mule_1\",           B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_MUL,              CODE_FOR_nothing,       \"spu_mul\",              B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_MUL_0,            CODE_FOR_mulv4sf3,      \"spu_mul_0\",            B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_MUL_1,            CODE_FOR_mulv2df3,      \"spu_mul_1\",            B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_MULO,             CODE_FOR_nothing,       \"spu_mulo\",             B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_MULO_0,           CODE_FOR_spu_mpy,       \"spu_mulo_0\",           B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_MULO_1,           CODE_FOR_spu_mpyu,      \"spu_mulo_1\",           B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_MULO_2,           CODE_FOR_spu_mpy,       \"spu_mulo_2\",           B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V8HI,   SPU_BTI_INTHI))\n+DEF_BUILTIN (SPU_MULO_3,           CODE_FOR_spu_mpyu,      \"spu_mulo_3\",           B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV8HI,  SPU_BTI_UINTHI))\n+DEF_BUILTIN (SPU_NMSUB,            CODE_FOR_nothing,       \"spu_nmsub\",            B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_NMSUB_0,          CODE_FOR_fnms_v4sf,     \"spu_nmsub_0\",          B_INTERNAL, _A4(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_NMSUB_1,          CODE_FOR_fnms_v2df,     \"spu_nmsub_1\",          B_INTERNAL, _A4(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_SUB,              CODE_FOR_nothing,       \"spu_sub\",              B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_SUB_0,            CODE_FOR_subv8hi3,      \"spu_sub_0\",            B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_SUB_1,            CODE_FOR_subv8hi3,      \"spu_sub_1\",            B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_SUB_2,            CODE_FOR_subv4si3,      \"spu_sub_2\",            B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_SUB_3,            CODE_FOR_subv4si3,      \"spu_sub_3\",            B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_SUB_4,            CODE_FOR_subv4sf3,      \"spu_sub_4\",            B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_SUB_5,            CODE_FOR_subv2df3,      \"spu_sub_5\",            B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_SUB_6,            CODE_FOR_subv8hi3,      \"spu_sub_6\",            B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UINTHI, SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_SUB_7,            CODE_FOR_subv8hi3,      \"spu_sub_7\",            B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_INTHI,  SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_SUB_8,            CODE_FOR_subv4si3,      \"spu_sub_8\",            B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UINTSI, SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_SUB_9,            CODE_FOR_subv4si3,      \"spu_sub_9\",            B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_INTSI,  SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_SUBX,             CODE_FOR_nothing,       \"spu_subx\",             B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_SUBX_0,           CODE_FOR_sfx_v4si,      \"spu_subx_0\",           B_INTERNAL, _A4(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_SUBX_1,           CODE_FOR_sfx_v4si,      \"spu_subx_1\",           B_INTERNAL, _A4(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_GENB,             CODE_FOR_nothing,       \"spu_genb\",             B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_GENB_0,           CODE_FOR_bg_v4si,       \"spu_genb_0\",           B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_GENB_1,           CODE_FOR_bg_v4si,       \"spu_genb_1\",           B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_GENBX,            CODE_FOR_nothing,       \"spu_genbx\",            B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_GENBX_0,          CODE_FOR_bgx_v4si,      \"spu_genbx_0\",          B_INTERNAL, _A4(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_GENBX_1,          CODE_FOR_bgx_v4si,      \"spu_genbx_1\",          B_INTERNAL, _A4(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_CMPEQ,            CODE_FOR_nothing,       \"spu_cmpeq\",            B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_CMPEQ_0,          CODE_FOR_ceq_v16qi,     \"spu_cmpeq_0\",          B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_CMPEQ_1,          CODE_FOR_ceq_v16qi,     \"spu_cmpeq_1\",          B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_V16QI,  SPU_BTI_V16QI))\n+DEF_BUILTIN (SPU_CMPEQ_2,          CODE_FOR_ceq_v8hi,      \"spu_cmpeq_2\",          B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_CMPEQ_3,          CODE_FOR_ceq_v8hi,      \"spu_cmpeq_3\",          B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_CMPEQ_4,          CODE_FOR_ceq_v4si,      \"spu_cmpeq_4\",          B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_CMPEQ_5,          CODE_FOR_ceq_v4si,      \"spu_cmpeq_5\",          B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_CMPEQ_6,          CODE_FOR_ceq_v4sf,      \"spu_cmpeq_6\",          B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_CMPEQ_7,          CODE_FOR_ceq_v16qi,     \"spu_cmpeq_7\",          B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UINTQI))\n+DEF_BUILTIN (SPU_CMPEQ_8,          CODE_FOR_ceq_v16qi,     \"spu_cmpeq_8\",          B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_V16QI,  SPU_BTI_INTQI))\n+DEF_BUILTIN (SPU_CMPEQ_9,          CODE_FOR_ceq_v8hi,      \"spu_cmpeq_9\",          B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UINTHI))\n+DEF_BUILTIN (SPU_CMPEQ_10,         CODE_FOR_ceq_v8hi,      \"spu_cmpeq_10\",         B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_V8HI,   SPU_BTI_INTHI))\n+DEF_BUILTIN (SPU_CMPEQ_11,         CODE_FOR_ceq_v4si,      \"spu_cmpeq_11\",         B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_CMPEQ_12,         CODE_FOR_ceq_v4si,      \"spu_cmpeq_12\",         B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_CMPGT,            CODE_FOR_nothing,       \"spu_cmpgt\",            B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_CMPGT_0,          CODE_FOR_clgt_v16qi,    \"spu_cmpgt_0\",          B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_CMPGT_1,          CODE_FOR_cgt_v16qi,     \"spu_cmpgt_1\",          B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_V16QI,  SPU_BTI_V16QI))\n+DEF_BUILTIN (SPU_CMPGT_2,          CODE_FOR_clgt_v8hi,     \"spu_cmpgt_2\",          B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_CMPGT_3,          CODE_FOR_cgt_v8hi,      \"spu_cmpgt_3\",          B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_CMPGT_4,          CODE_FOR_clgt_v4si,     \"spu_cmpgt_4\",          B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_CMPGT_5,          CODE_FOR_cgt_v4si,      \"spu_cmpgt_5\",          B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_CMPGT_6,          CODE_FOR_cgt_v4sf,      \"spu_cmpgt_6\",          B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_CMPGT_7,          CODE_FOR_clgt_v16qi,    \"spu_cmpgt_7\",          B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UINTQI))\n+DEF_BUILTIN (SPU_CMPGT_8,          CODE_FOR_cgt_v16qi,     \"spu_cmpgt_8\",          B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_V16QI,  SPU_BTI_INTQI))\n+DEF_BUILTIN (SPU_CMPGT_9,          CODE_FOR_clgt_v8hi,     \"spu_cmpgt_9\",          B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UINTHI))\n+DEF_BUILTIN (SPU_CMPGT_10,         CODE_FOR_cgt_v8hi,      \"spu_cmpgt_10\",         B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_V8HI,   SPU_BTI_INTHI))\n+DEF_BUILTIN (SPU_CMPGT_11,         CODE_FOR_cgt_v4si,      \"spu_cmpgt_11\",         B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_CMPGT_12,         CODE_FOR_clgt_v4si,     \"spu_cmpgt_12\",         B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_HCMPEQ,           CODE_FOR_nothing,       \"spu_hcmpeq\",           B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_HCMPEQ_0,         CODE_FOR_spu_heq,       \"spu_hcmpeq_0\",         B_INTERNAL, _A3(SPU_BTI_VOID,  SPU_BTI_INTSI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_HCMPEQ_1,         CODE_FOR_spu_heq,       \"spu_hcmpeq_1\",         B_INTERNAL, _A3(SPU_BTI_VOID,  SPU_BTI_UINTSI, SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_HCMPGT,           CODE_FOR_nothing,       \"spu_hcmpgt\",           B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_HCMPGT_0,         CODE_FOR_spu_hgt,       \"spu_hcmpgt_0\",         B_INTERNAL, _A3(SPU_BTI_VOID,  SPU_BTI_INTSI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_HCMPGT_1,         CODE_FOR_spu_hlgt,      \"spu_hcmpgt_1\",         B_INTERNAL, _A3(SPU_BTI_VOID,  SPU_BTI_UINTSI, SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_CNTB,             CODE_FOR_nothing,       \"spu_cntb\",             B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_CNTB_0,           CODE_FOR_cntb_v16qi,    \"spu_cntb_0\",           B_INTERNAL, _A2(SPU_BTI_UV16QI, SPU_BTI_V16QI))\n+DEF_BUILTIN (SPU_CNTB_1,           CODE_FOR_cntb_v16qi,    \"spu_cntb_1\",           B_INTERNAL, _A2(SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_CNTLZ,            CODE_FOR_nothing,       \"spu_cntlz\",            B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_CNTLZ_0,          CODE_FOR_clzv4si2,      \"spu_cntlz_0\",          B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_CNTLZ_1,          CODE_FOR_clzv4si2,      \"spu_cntlz_1\",          B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_CNTLZ_2,          CODE_FOR_clzv4si2,      \"spu_cntlz_2\",          B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_GATHER,           CODE_FOR_nothing,       \"spu_gather\",           B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_GATHER_0,         CODE_FOR_spu_gb,        \"spu_gather_0\",         B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_GATHER_1,         CODE_FOR_spu_gb,        \"spu_gather_1\",         B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_GATHER_2,         CODE_FOR_spu_gbh,       \"spu_gather_2\",         B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_GATHER_3,         CODE_FOR_spu_gbh,       \"spu_gather_3\",         B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_GATHER_4,         CODE_FOR_spu_gbb,       \"spu_gather_4\",         B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_V16QI))\n+DEF_BUILTIN (SPU_GATHER_5,         CODE_FOR_spu_gbb,       \"spu_gather_5\",         B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_GATHER_6,         CODE_FOR_spu_gb,        \"spu_gather_6\",         B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_MASKB,            CODE_FOR_nothing,       \"spu_maskb\",            B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_MASKB_0,          CODE_FOR_spu_fsmb,      \"spu_maskb_0\",          B_INTERNAL, _A2(SPU_BTI_UV16QI, SPU_BTI_UINTHI))\n+DEF_BUILTIN (SPU_MASKB_1,          CODE_FOR_spu_fsmb,      \"spu_maskb_1\",          B_INTERNAL, _A2(SPU_BTI_UV16QI, SPU_BTI_INTHI))\n+DEF_BUILTIN (SPU_MASKB_2,          CODE_FOR_spu_fsmb,      \"spu_maskb_2\",          B_INTERNAL, _A2(SPU_BTI_UV16QI, SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_MASKB_3,          CODE_FOR_spu_fsmb,      \"spu_maskb_3\",          B_INTERNAL, _A2(SPU_BTI_UV16QI, SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_MASKH,            CODE_FOR_nothing,       \"spu_maskh\",            B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_MASKH_0,          CODE_FOR_spu_fsmh,      \"spu_maskh_0\",          B_INTERNAL, _A2(SPU_BTI_UV8HI,  SPU_BTI_UINTQI))\n+DEF_BUILTIN (SPU_MASKH_1,          CODE_FOR_spu_fsmh,      \"spu_maskh_1\",          B_INTERNAL, _A2(SPU_BTI_UV8HI,  SPU_BTI_INTQI))\n+DEF_BUILTIN (SPU_MASKH_2,          CODE_FOR_spu_fsmh,      \"spu_maskh_2\",          B_INTERNAL, _A2(SPU_BTI_UV8HI,  SPU_BTI_UINTHI))\n+DEF_BUILTIN (SPU_MASKH_3,          CODE_FOR_spu_fsmh,      \"spu_maskh_3\",          B_INTERNAL, _A2(SPU_BTI_UV8HI,  SPU_BTI_INTHI))\n+DEF_BUILTIN (SPU_MASKH_4,          CODE_FOR_spu_fsmh,      \"spu_maskh_4\",          B_INTERNAL, _A2(SPU_BTI_UV8HI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_MASKH_5,          CODE_FOR_spu_fsmh,      \"spu_maskh_5\",          B_INTERNAL, _A2(SPU_BTI_UV8HI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_MASKW,            CODE_FOR_nothing,       \"spu_maskw\",            B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_MASKW_0,          CODE_FOR_spu_fsm,       \"spu_maskw_0\",          B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_UINTQI))\n+DEF_BUILTIN (SPU_MASKW_1,          CODE_FOR_spu_fsm,       \"spu_maskw_1\",          B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_INTQI))\n+DEF_BUILTIN (SPU_MASKW_2,          CODE_FOR_spu_fsm,       \"spu_maskw_2\",          B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_UINTHI))\n+DEF_BUILTIN (SPU_MASKW_3,          CODE_FOR_spu_fsm,       \"spu_maskw_3\",          B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_INTHI))\n+DEF_BUILTIN (SPU_MASKW_4,          CODE_FOR_spu_fsm,       \"spu_maskw_4\",          B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_MASKW_5,          CODE_FOR_spu_fsm,       \"spu_maskw_5\",          B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_SEL,              CODE_FOR_nothing,       \"spu_sel\",              B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_SEL_0,            CODE_FOR_selb,          \"spu_sel_0\",            B_INTERNAL, _A4(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_UV2DI))\n+DEF_BUILTIN (SPU_SEL_1,            CODE_FOR_selb,          \"spu_sel_1\",            B_INTERNAL, _A4(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UV2DI))\n+DEF_BUILTIN (SPU_SEL_2,            CODE_FOR_selb,          \"spu_sel_2\",            B_INTERNAL, _A4(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_SEL_3,            CODE_FOR_selb,          \"spu_sel_3\",            B_INTERNAL, _A4(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_SEL_4,            CODE_FOR_selb,          \"spu_sel_4\",            B_INTERNAL, _A4(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_SEL_5,            CODE_FOR_selb,          \"spu_sel_5\",            B_INTERNAL, _A4(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_SEL_6,            CODE_FOR_selb,          \"spu_sel_6\",            B_INTERNAL, _A4(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_SEL_7,            CODE_FOR_selb,          \"spu_sel_7\",            B_INTERNAL, _A4(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_SEL_8,            CODE_FOR_selb,          \"spu_sel_8\",            B_INTERNAL, _A4(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_SEL_9,            CODE_FOR_selb,          \"spu_sel_9\",            B_INTERNAL, _A4(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_UV2DI))\n+DEF_BUILTIN (SPU_SHUFFLE,          CODE_FOR_nothing,       \"spu_shuffle\",          B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_SHUFFLE_0,        CODE_FOR_shufb,         \"spu_shuffle_0\",        B_INTERNAL, _A4(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_SHUFFLE_1,        CODE_FOR_shufb,         \"spu_shuffle_1\",        B_INTERNAL, _A4(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_SHUFFLE_2,        CODE_FOR_shufb,         \"spu_shuffle_2\",        B_INTERNAL, _A4(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_SHUFFLE_3,        CODE_FOR_shufb,         \"spu_shuffle_3\",        B_INTERNAL, _A4(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_SHUFFLE_4,        CODE_FOR_shufb,         \"spu_shuffle_4\",        B_INTERNAL, _A4(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_SHUFFLE_5,        CODE_FOR_shufb,         \"spu_shuffle_5\",        B_INTERNAL, _A4(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_SHUFFLE_6,        CODE_FOR_shufb,         \"spu_shuffle_6\",        B_INTERNAL, _A4(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_SHUFFLE_7,        CODE_FOR_shufb,         \"spu_shuffle_7\",        B_INTERNAL, _A4(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_SHUFFLE_8,        CODE_FOR_shufb,         \"spu_shuffle_8\",        B_INTERNAL, _A4(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_SHUFFLE_9,        CODE_FOR_shufb,         \"spu_shuffle_9\",        B_INTERNAL, _A4(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_AND,              CODE_FOR_nothing,       \"spu_and\",              B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_AND_0,            CODE_FOR_andv16qi3,     \"spu_and_0\",            B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_AND_1,            CODE_FOR_andv16qi3,     \"spu_and_1\",            B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_V16QI))\n+DEF_BUILTIN (SPU_AND_2,            CODE_FOR_andv8hi3,      \"spu_and_2\",            B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_AND_3,            CODE_FOR_andv8hi3,      \"spu_and_3\",            B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_AND_4,            CODE_FOR_andv4si3,      \"spu_and_4\",            B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_AND_5,            CODE_FOR_andv4si3,      \"spu_and_5\",            B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_AND_6,            CODE_FOR_andv2di3,      \"spu_and_6\",            B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UV2DI))\n+DEF_BUILTIN (SPU_AND_7,            CODE_FOR_andv2di3,      \"spu_and_7\",            B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_V2DI))\n+DEF_BUILTIN (SPU_AND_8,            CODE_FOR_andv4si3,      \"spu_and_8\",            B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_AND_9,            CODE_FOR_andv2di3,      \"spu_and_9\",            B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_AND_10,           CODE_FOR_andv16qi3,     \"spu_and_10\",           B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UINTQI))\n+DEF_BUILTIN (SPU_AND_11,           CODE_FOR_andv16qi3,     \"spu_and_11\",           B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_INTQI))\n+DEF_BUILTIN (SPU_AND_12,           CODE_FOR_andv8hi3,      \"spu_and_12\",           B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UINTHI))\n+DEF_BUILTIN (SPU_AND_13,           CODE_FOR_andv8hi3,      \"spu_and_13\",           B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_INTHI))\n+DEF_BUILTIN (SPU_AND_14,           CODE_FOR_andv4si3,      \"spu_and_14\",           B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_AND_15,           CODE_FOR_andv4si3,      \"spu_and_15\",           B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_ANDC,             CODE_FOR_nothing,       \"spu_andc\",             B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_ANDC_0,           CODE_FOR_andc_v2di,     \"spu_andc_0\",           B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_V2DI))\n+DEF_BUILTIN (SPU_ANDC_1,           CODE_FOR_andc_v2di,     \"spu_andc_1\",           B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UV2DI))\n+DEF_BUILTIN (SPU_ANDC_2,           CODE_FOR_andc_v4si,     \"spu_andc_2\",           B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_ANDC_3,           CODE_FOR_andc_v4si,     \"spu_andc_3\",           B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_ANDC_4,           CODE_FOR_andc_v8hi,     \"spu_andc_4\",           B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_ANDC_5,           CODE_FOR_andc_v8hi,     \"spu_andc_5\",           B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_ANDC_6,           CODE_FOR_andc_v16qi,    \"spu_andc_6\",           B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_V16QI))\n+DEF_BUILTIN (SPU_ANDC_7,           CODE_FOR_andc_v16qi,    \"spu_andc_7\",           B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_ANDC_8,           CODE_FOR_andc_v4si,     \"spu_andc_8\",           B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_ANDC_9,           CODE_FOR_andc_v2di,     \"spu_andc_9\",           B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_EQV,              CODE_FOR_nothing,       \"spu_eqv\",              B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_EQV_0,            CODE_FOR_eqv_v2di,      \"spu_eqv_0\",            B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_V2DI))\n+DEF_BUILTIN (SPU_EQV_1,            CODE_FOR_eqv_v2di,      \"spu_eqv_1\",            B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UV2DI))\n+DEF_BUILTIN (SPU_EQV_2,            CODE_FOR_eqv_v4si,      \"spu_eqv_2\",            B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_EQV_3,            CODE_FOR_eqv_v4si,      \"spu_eqv_3\",            B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_EQV_4,            CODE_FOR_eqv_v8hi,      \"spu_eqv_4\",            B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_EQV_5,            CODE_FOR_eqv_v8hi,      \"spu_eqv_5\",            B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_EQV_6,            CODE_FOR_eqv_v16qi,     \"spu_eqv_6\",            B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_V16QI))\n+DEF_BUILTIN (SPU_EQV_7,            CODE_FOR_eqv_v16qi,     \"spu_eqv_7\",            B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_EQV_8,            CODE_FOR_eqv_v4si,      \"spu_eqv_8\",            B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_EQV_9,            CODE_FOR_eqv_v2di,      \"spu_eqv_9\",            B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_NAND,             CODE_FOR_nothing,       \"spu_nand\",             B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_NAND_0,           CODE_FOR_nand_v2di,     \"spu_nand_0\",           B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_V2DI))\n+DEF_BUILTIN (SPU_NAND_1,           CODE_FOR_nand_v2di,     \"spu_nand_1\",           B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UV2DI))\n+DEF_BUILTIN (SPU_NAND_2,           CODE_FOR_nand_v4si,     \"spu_nand_2\",           B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_NAND_3,           CODE_FOR_nand_v4si,     \"spu_nand_3\",           B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_NAND_4,           CODE_FOR_nand_v8hi,     \"spu_nand_4\",           B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_NAND_5,           CODE_FOR_nand_v8hi,     \"spu_nand_5\",           B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_NAND_6,           CODE_FOR_nand_v16qi,    \"spu_nand_6\",           B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_V16QI))\n+DEF_BUILTIN (SPU_NAND_7,           CODE_FOR_nand_v16qi,    \"spu_nand_7\",           B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_NAND_8,           CODE_FOR_nand_v4si,     \"spu_nand_8\",           B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_NAND_9,           CODE_FOR_nand_v2di,     \"spu_nand_9\",           B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_NOR,              CODE_FOR_nothing,       \"spu_nor\",              B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_NOR_0,            CODE_FOR_nor_v2di,      \"spu_nor_0\",            B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_V2DI))\n+DEF_BUILTIN (SPU_NOR_1,            CODE_FOR_nor_v2di,      \"spu_nor_1\",            B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UV2DI))\n+DEF_BUILTIN (SPU_NOR_2,            CODE_FOR_nor_v4si,      \"spu_nor_2\",            B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_NOR_3,            CODE_FOR_nor_v4si,      \"spu_nor_3\",            B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_NOR_4,            CODE_FOR_nor_v8hi,      \"spu_nor_4\",            B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_NOR_5,            CODE_FOR_nor_v8hi,      \"spu_nor_5\",            B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_NOR_6,            CODE_FOR_nor_v16qi,     \"spu_nor_6\",            B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_V16QI))\n+DEF_BUILTIN (SPU_NOR_7,            CODE_FOR_nor_v16qi,     \"spu_nor_7\",            B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_NOR_8,            CODE_FOR_nor_v4si,      \"spu_nor_8\",            B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_NOR_9,            CODE_FOR_nor_v2di,      \"spu_nor_9\",            B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_OR,               CODE_FOR_nothing,       \"spu_or\",               B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_OR_0,             CODE_FOR_iorv16qi3,     \"spu_or_0\",             B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_OR_1,             CODE_FOR_iorv16qi3,     \"spu_or_1\",             B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_V16QI))\n+DEF_BUILTIN (SPU_OR_2,             CODE_FOR_iorv8hi3,      \"spu_or_2\",             B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_OR_3,             CODE_FOR_iorv8hi3,      \"spu_or_3\",             B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_OR_4,             CODE_FOR_iorv4si3,      \"spu_or_4\",             B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_OR_5,             CODE_FOR_iorv4si3,      \"spu_or_5\",             B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_OR_6,             CODE_FOR_iorv2di3,      \"spu_or_6\",             B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UV2DI))\n+DEF_BUILTIN (SPU_OR_7,             CODE_FOR_iorv2di3,      \"spu_or_7\",             B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_V2DI))\n+DEF_BUILTIN (SPU_OR_8,             CODE_FOR_iorv4si3,      \"spu_or_8\",             B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_OR_9,             CODE_FOR_iorv2di3,      \"spu_or_9\",             B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_OR_10,            CODE_FOR_iorv16qi3,     \"spu_or_10\",            B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UINTQI))\n+DEF_BUILTIN (SPU_OR_11,            CODE_FOR_iorv16qi3,     \"spu_or_11\",            B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_INTQI))\n+DEF_BUILTIN (SPU_OR_12,            CODE_FOR_iorv8hi3,      \"spu_or_12\",            B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UINTHI))\n+DEF_BUILTIN (SPU_OR_13,            CODE_FOR_iorv8hi3,      \"spu_or_13\",            B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_INTHI))\n+DEF_BUILTIN (SPU_OR_14,            CODE_FOR_iorv4si3,      \"spu_or_14\",            B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_OR_15,            CODE_FOR_iorv4si3,      \"spu_or_15\",            B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_ORC,              CODE_FOR_nothing,       \"spu_orc\",              B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_ORC_0,            CODE_FOR_orc_v2di,      \"spu_orc_0\",            B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_V2DI))\n+DEF_BUILTIN (SPU_ORC_1,            CODE_FOR_orc_v2di,      \"spu_orc_1\",            B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UV2DI))\n+DEF_BUILTIN (SPU_ORC_2,            CODE_FOR_orc_v4si,      \"spu_orc_2\",            B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_ORC_3,            CODE_FOR_orc_v4si,      \"spu_orc_3\",            B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_ORC_4,            CODE_FOR_orc_v8hi,      \"spu_orc_4\",            B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_ORC_5,            CODE_FOR_orc_v8hi,      \"spu_orc_5\",            B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_ORC_6,            CODE_FOR_orc_v16qi,     \"spu_orc_6\",            B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_V16QI))\n+DEF_BUILTIN (SPU_ORC_7,            CODE_FOR_orc_v16qi,     \"spu_orc_7\",            B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_ORC_8,            CODE_FOR_orc_v4si,      \"spu_orc_8\",            B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_ORC_9,            CODE_FOR_orc_v2di,      \"spu_orc_9\",            B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_ORX,              CODE_FOR_nothing,       \"spu_orx\",              B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_ORX_0,            CODE_FOR_spu_orx,       \"spu_orx_0\",            B_INTERNAL, _A2(SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_ORX_1,            CODE_FOR_spu_orx,       \"spu_orx_1\",            B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_XOR,              CODE_FOR_nothing,       \"spu_xor\",              B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_XOR_0,            CODE_FOR_xorv16qi3,     \"spu_xor_0\",            B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UV16QI))\n+DEF_BUILTIN (SPU_XOR_1,            CODE_FOR_xorv16qi3,     \"spu_xor_1\",            B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_V16QI))\n+DEF_BUILTIN (SPU_XOR_2,            CODE_FOR_xorv8hi3,      \"spu_xor_2\",            B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_XOR_3,            CODE_FOR_xorv8hi3,      \"spu_xor_3\",            B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_XOR_4,            CODE_FOR_xorv4si3,      \"spu_xor_4\",            B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_XOR_5,            CODE_FOR_xorv4si3,      \"spu_xor_5\",            B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_XOR_6,            CODE_FOR_xorv2di3,      \"spu_xor_6\",            B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UV2DI))\n+DEF_BUILTIN (SPU_XOR_7,            CODE_FOR_xorv2di3,      \"spu_xor_7\",            B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_V2DI))\n+DEF_BUILTIN (SPU_XOR_8,            CODE_FOR_xorv4si3,      \"spu_xor_8\",            B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_V4SF))\n+DEF_BUILTIN (SPU_XOR_9,            CODE_FOR_xorv2di3,      \"spu_xor_9\",            B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_V2DF))\n+DEF_BUILTIN (SPU_XOR_10,           CODE_FOR_xorv16qi3,     \"spu_xor_10\",           B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UINTQI))\n+DEF_BUILTIN (SPU_XOR_11,           CODE_FOR_xorv16qi3,     \"spu_xor_11\",           B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_INTQI))\n+DEF_BUILTIN (SPU_XOR_12,           CODE_FOR_xorv8hi3,      \"spu_xor_12\",           B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UINTHI))\n+DEF_BUILTIN (SPU_XOR_13,           CODE_FOR_xorv8hi3,      \"spu_xor_13\",           B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_INTHI))\n+DEF_BUILTIN (SPU_XOR_14,           CODE_FOR_xorv4si3,      \"spu_xor_14\",           B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_XOR_15,           CODE_FOR_xorv4si3,      \"spu_xor_15\",           B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RL,               CODE_FOR_nothing,       \"spu_rl\",               B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_RL_0,             CODE_FOR_rotlv8hi3,     \"spu_rl_0\",             B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_RL_1,             CODE_FOR_rotlv8hi3,     \"spu_rl_1\",             B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_RL_2,             CODE_FOR_rotlv4si3,     \"spu_rl_2\",             B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_RL_3,             CODE_FOR_rotlv4si3,     \"spu_rl_3\",             B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_RL_4,             CODE_FOR_rotlv8hi3,     \"spu_rl_4\",             B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_INTHI))\n+DEF_BUILTIN (SPU_RL_5,             CODE_FOR_rotlv8hi3,     \"spu_rl_5\",             B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_INTHI))\n+DEF_BUILTIN (SPU_RL_6,             CODE_FOR_rotlv4si3,     \"spu_rl_6\",             B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RL_7,             CODE_FOR_rotlv4si3,     \"spu_rl_7\",             B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQW,             CODE_FOR_nothing,       \"spu_rlqw\",             B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_RLQW_0,           CODE_FOR_rotqbi_ti,     \"spu_rlqw_0\",           B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQW_1,           CODE_FOR_rotqbi_ti,     \"spu_rlqw_1\",           B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQW_2,           CODE_FOR_rotqbi_ti,     \"spu_rlqw_2\",           B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQW_3,           CODE_FOR_rotqbi_ti,     \"spu_rlqw_3\",           B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQW_4,           CODE_FOR_rotqbi_ti,     \"spu_rlqw_4\",           B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQW_5,           CODE_FOR_rotqbi_ti,     \"spu_rlqw_5\",           B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQW_6,           CODE_FOR_rotqbi_ti,     \"spu_rlqw_6\",           B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQW_7,           CODE_FOR_rotqbi_ti,     \"spu_rlqw_7\",           B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQW_8,           CODE_FOR_rotqbi_ti,     \"spu_rlqw_8\",           B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQW_9,           CODE_FOR_rotqbi_ti,     \"spu_rlqw_9\",           B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTE,         CODE_FOR_nothing,       \"spu_rlqwbyte\",         B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_RLQWBYTE_0,       CODE_FOR_rotqby_ti,     \"spu_rlqwbyte_0\",       B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTE_1,       CODE_FOR_rotqby_ti,     \"spu_rlqwbyte_1\",       B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTE_2,       CODE_FOR_rotqby_ti,     \"spu_rlqwbyte_2\",       B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTE_3,       CODE_FOR_rotqby_ti,     \"spu_rlqwbyte_3\",       B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTE_4,       CODE_FOR_rotqby_ti,     \"spu_rlqwbyte_4\",       B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTE_5,       CODE_FOR_rotqby_ti,     \"spu_rlqwbyte_5\",       B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTE_6,       CODE_FOR_rotqby_ti,     \"spu_rlqwbyte_6\",       B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTE_7,       CODE_FOR_rotqby_ti,     \"spu_rlqwbyte_7\",       B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTE_8,       CODE_FOR_rotqby_ti,     \"spu_rlqwbyte_8\",       B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTE_9,       CODE_FOR_rotqby_ti,     \"spu_rlqwbyte_9\",       B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTEBC,       CODE_FOR_nothing,       \"spu_rlqwbytebc\",       B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_RLQWBYTEBC_0,     CODE_FOR_rotqbybi_ti,   \"spu_rlqwbytebc_0\",     B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTEBC_1,     CODE_FOR_rotqbybi_ti,   \"spu_rlqwbytebc_1\",     B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTEBC_2,     CODE_FOR_rotqbybi_ti,   \"spu_rlqwbytebc_2\",     B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTEBC_3,     CODE_FOR_rotqbybi_ti,   \"spu_rlqwbytebc_3\",     B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTEBC_4,     CODE_FOR_rotqbybi_ti,   \"spu_rlqwbytebc_4\",     B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTEBC_5,     CODE_FOR_rotqbybi_ti,   \"spu_rlqwbytebc_5\",     B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTEBC_6,     CODE_FOR_rotqbybi_ti,   \"spu_rlqwbytebc_6\",     B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTEBC_7,     CODE_FOR_rotqbybi_ti,   \"spu_rlqwbytebc_7\",     B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTEBC_8,     CODE_FOR_rotqbybi_ti,   \"spu_rlqwbytebc_8\",     B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLQWBYTEBC_9,     CODE_FOR_rotqbybi_ti,   \"spu_rlqwbytebc_9\",     B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASK,           CODE_FOR_nothing,       \"spu_rlmask\",           B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_RLMASK_0,         CODE_FOR_rotm_v8hi,     \"spu_rlmask_0\",         B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_RLMASK_1,         CODE_FOR_rotm_v8hi,     \"spu_rlmask_1\",         B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_RLMASK_2,         CODE_FOR_rotm_v4si,     \"spu_rlmask_2\",         B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_RLMASK_3,         CODE_FOR_rotm_v4si,     \"spu_rlmask_3\",         B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_RLMASK_4,         CODE_FOR_rotm_v8hi,     \"spu_rlmask_4\",         B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASK_5,         CODE_FOR_rotm_v8hi,     \"spu_rlmask_5\",         B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASK_6,         CODE_FOR_rotm_v4si,     \"spu_rlmask_6\",         B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASK_7,         CODE_FOR_rotm_v4si,     \"spu_rlmask_7\",         B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKA,          CODE_FOR_nothing,       \"spu_rlmaska\",          B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_RLMASKA_0,        CODE_FOR_rotma_v8hi,    \"spu_rlmaska_0\",        B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_RLMASKA_1,        CODE_FOR_rotma_v8hi,    \"spu_rlmaska_1\",        B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_V8HI))\n+DEF_BUILTIN (SPU_RLMASKA_2,        CODE_FOR_rotma_v4si,    \"spu_rlmaska_2\",        B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_RLMASKA_3,        CODE_FOR_rotma_v4si,    \"spu_rlmaska_3\",        B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_V4SI))\n+DEF_BUILTIN (SPU_RLMASKA_4,        CODE_FOR_rotma_v8hi,    \"spu_rlmaska_4\",        B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKA_5,        CODE_FOR_rotma_v8hi,    \"spu_rlmaska_5\",        B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKA_6,        CODE_FOR_rotma_v4si,    \"spu_rlmaska_6\",        B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKA_7,        CODE_FOR_rotma_v4si,    \"spu_rlmaska_7\",        B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQW,         CODE_FOR_nothing,       \"spu_rlmaskqw\",         B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_RLMASKQW_0,       CODE_FOR_rotqmbi_ti,    \"spu_rlmaskqw_0\",       B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQW_1,       CODE_FOR_rotqmbi_ti,    \"spu_rlmaskqw_1\",       B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQW_2,       CODE_FOR_rotqmbi_ti,    \"spu_rlmaskqw_2\",       B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQW_3,       CODE_FOR_rotqmbi_ti,    \"spu_rlmaskqw_3\",       B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQW_4,       CODE_FOR_rotqmbi_ti,    \"spu_rlmaskqw_4\",       B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQW_5,       CODE_FOR_rotqmbi_ti,    \"spu_rlmaskqw_5\",       B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQW_6,       CODE_FOR_rotqmbi_ti,    \"spu_rlmaskqw_6\",       B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQW_7,       CODE_FOR_rotqmbi_ti,    \"spu_rlmaskqw_7\",       B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQW_8,       CODE_FOR_rotqmbi_ti,    \"spu_rlmaskqw_8\",       B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQW_9,       CODE_FOR_rotqmbi_ti,    \"spu_rlmaskqw_9\",       B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTE,     CODE_FOR_nothing,       \"spu_rlmaskqwbyte\",     B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_RLMASKQWBYTE_0,   CODE_FOR_rotqmby_ti,    \"spu_rlmaskqwbyte_0\",   B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTE_1,   CODE_FOR_rotqmby_ti,    \"spu_rlmaskqwbyte_1\",   B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTE_2,   CODE_FOR_rotqmby_ti,    \"spu_rlmaskqwbyte_2\",   B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTE_3,   CODE_FOR_rotqmby_ti,    \"spu_rlmaskqwbyte_3\",   B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTE_4,   CODE_FOR_rotqmby_ti,    \"spu_rlmaskqwbyte_4\",   B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTE_5,   CODE_FOR_rotqmby_ti,    \"spu_rlmaskqwbyte_5\",   B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTE_6,   CODE_FOR_rotqmby_ti,    \"spu_rlmaskqwbyte_6\",   B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTE_7,   CODE_FOR_rotqmby_ti,    \"spu_rlmaskqwbyte_7\",   B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTE_8,   CODE_FOR_rotqmby_ti,    \"spu_rlmaskqwbyte_8\",   B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTE_9,   CODE_FOR_rotqmby_ti,    \"spu_rlmaskqwbyte_9\",   B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTEBC,   CODE_FOR_nothing,       \"spu_rlmaskqwbytebc\",   B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_RLMASKQWBYTEBC_0, CODE_FOR_rotqmbybi_ti,  \"spu_rlmaskqwbytebc_0\", B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTEBC_1, CODE_FOR_rotqmbybi_ti,  \"spu_rlmaskqwbytebc_1\", B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTEBC_2, CODE_FOR_rotqmbybi_ti,  \"spu_rlmaskqwbytebc_2\", B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTEBC_3, CODE_FOR_rotqmbybi_ti,  \"spu_rlmaskqwbytebc_3\", B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTEBC_4, CODE_FOR_rotqmbybi_ti,  \"spu_rlmaskqwbytebc_4\", B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTEBC_5, CODE_FOR_rotqmbybi_ti,  \"spu_rlmaskqwbytebc_5\", B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTEBC_6, CODE_FOR_rotqmbybi_ti,  \"spu_rlmaskqwbytebc_6\", B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTEBC_7, CODE_FOR_rotqmbybi_ti,  \"spu_rlmaskqwbytebc_7\", B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTEBC_8, CODE_FOR_rotqmbybi_ti,  \"spu_rlmaskqwbytebc_8\", B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_RLMASKQWBYTEBC_9, CODE_FOR_rotqmbybi_ti,  \"spu_rlmaskqwbytebc_9\", B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_SL,               CODE_FOR_nothing,       \"spu_sl\",               B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_SL_0,             CODE_FOR_ashlv8hi3,     \"spu_sl_0\",             B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_SL_1,             CODE_FOR_ashlv8hi3,     \"spu_sl_1\",             B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_UV8HI))\n+DEF_BUILTIN (SPU_SL_2,             CODE_FOR_ashlv4si3,     \"spu_sl_2\",             B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_SL_3,             CODE_FOR_ashlv4si3,     \"spu_sl_3\",             B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_UV4SI))\n+DEF_BUILTIN (SPU_SL_4,             CODE_FOR_ashlv8hi3,     \"spu_sl_4\",             B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SL_5,             CODE_FOR_ashlv8hi3,     \"spu_sl_5\",             B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SL_6,             CODE_FOR_ashlv4si3,     \"spu_sl_6\",             B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SL_7,             CODE_FOR_ashlv4si3,     \"spu_sl_7\",             B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQW,             CODE_FOR_nothing,       \"spu_slqw\",             B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_SLQW_0,           CODE_FOR_shlqbi_ti,     \"spu_slqw_0\",           B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQW_1,           CODE_FOR_shlqbi_ti,     \"spu_slqw_1\",           B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQW_2,           CODE_FOR_shlqbi_ti,     \"spu_slqw_2\",           B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQW_3,           CODE_FOR_shlqbi_ti,     \"spu_slqw_3\",           B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQW_4,           CODE_FOR_shlqbi_ti,     \"spu_slqw_4\",           B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQW_5,           CODE_FOR_shlqbi_ti,     \"spu_slqw_5\",           B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQW_6,           CODE_FOR_shlqbi_ti,     \"spu_slqw_6\",           B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQW_7,           CODE_FOR_shlqbi_ti,     \"spu_slqw_7\",           B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQW_8,           CODE_FOR_shlqbi_ti,     \"spu_slqw_8\",           B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQW_9,           CODE_FOR_shlqbi_ti,     \"spu_slqw_9\",           B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTE,         CODE_FOR_nothing,       \"spu_slqwbyte\",         B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_SLQWBYTE_0,       CODE_FOR_shlqby_ti,     \"spu_slqwbyte_0\",       B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTE_1,       CODE_FOR_shlqby_ti,     \"spu_slqwbyte_1\",       B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTE_2,       CODE_FOR_shlqby_ti,     \"spu_slqwbyte_2\",       B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTE_3,       CODE_FOR_shlqby_ti,     \"spu_slqwbyte_3\",       B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTE_4,       CODE_FOR_shlqby_ti,     \"spu_slqwbyte_4\",       B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTE_5,       CODE_FOR_shlqby_ti,     \"spu_slqwbyte_5\",       B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTE_6,       CODE_FOR_shlqby_ti,     \"spu_slqwbyte_6\",       B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTE_7,       CODE_FOR_shlqby_ti,     \"spu_slqwbyte_7\",       B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTE_8,       CODE_FOR_shlqby_ti,     \"spu_slqwbyte_8\",       B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTE_9,       CODE_FOR_shlqby_ti,     \"spu_slqwbyte_9\",       B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTEBC,       CODE_FOR_nothing,       \"spu_slqwbytebc\",       B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_SLQWBYTEBC_0,     CODE_FOR_shlqbybi_ti,   \"spu_slqwbytebc_0\",     B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_V2DI,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTEBC_1,     CODE_FOR_shlqbybi_ti,   \"spu_slqwbytebc_1\",     B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UV2DI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTEBC_2,     CODE_FOR_shlqbybi_ti,   \"spu_slqwbytebc_2\",     B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_V4SI,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTEBC_3,     CODE_FOR_shlqbybi_ti,   \"spu_slqwbytebc_3\",     B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTEBC_4,     CODE_FOR_shlqbybi_ti,   \"spu_slqwbytebc_4\",     B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_V8HI,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTEBC_5,     CODE_FOR_shlqbybi_ti,   \"spu_slqwbytebc_5\",     B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UV8HI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTEBC_6,     CODE_FOR_shlqbybi_ti,   \"spu_slqwbytebc_6\",     B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_V16QI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTEBC_7,     CODE_FOR_shlqbybi_ti,   \"spu_slqwbytebc_7\",     B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UV16QI, SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTEBC_8,     CODE_FOR_shlqbybi_ti,   \"spu_slqwbytebc_8\",     B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_V4SF,   SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SLQWBYTEBC_9,     CODE_FOR_shlqbybi_ti,   \"spu_slqwbytebc_9\",     B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_V2DF,   SPU_BTI_UINTSI))\n+\n+DEF_BUILTIN (SPU_SPLATS,           CODE_FOR_nothing,       \"spu_splats\",           B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_SPLATS_0,         CODE_FOR_spu_splats,    \"spu_splats_0\",         B_INTERNAL, _A2(SPU_BTI_UV16QI, SPU_BTI_UINTQI))\n+DEF_BUILTIN (SPU_SPLATS_1,         CODE_FOR_spu_splats,    \"spu_splats_1\",         B_INTERNAL, _A2(SPU_BTI_V16QI,  SPU_BTI_INTQI))\n+DEF_BUILTIN (SPU_SPLATS_2,         CODE_FOR_spu_splats,    \"spu_splats_2\",         B_INTERNAL, _A2(SPU_BTI_UV8HI,  SPU_BTI_UINTHI))\n+DEF_BUILTIN (SPU_SPLATS_3,         CODE_FOR_spu_splats,    \"spu_splats_3\",         B_INTERNAL, _A2(SPU_BTI_V8HI,   SPU_BTI_INTHI))\n+DEF_BUILTIN (SPU_SPLATS_4,         CODE_FOR_spu_splats,    \"spu_splats_4\",         B_INTERNAL, _A2(SPU_BTI_UV4SI,  SPU_BTI_UINTSI))\n+DEF_BUILTIN (SPU_SPLATS_5,         CODE_FOR_spu_splats,    \"spu_splats_5\",         B_INTERNAL, _A2(SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_SPLATS_6,         CODE_FOR_spu_splats,    \"spu_splats_6\",         B_INTERNAL, _A2(SPU_BTI_UV2DI,  SPU_BTI_UINTDI))\n+DEF_BUILTIN (SPU_SPLATS_7,         CODE_FOR_spu_splats,    \"spu_splats_7\",         B_INTERNAL, _A2(SPU_BTI_V2DI,   SPU_BTI_INTDI))\n+DEF_BUILTIN (SPU_SPLATS_8,         CODE_FOR_spu_splats,    \"spu_splats_8\",         B_INTERNAL, _A2(SPU_BTI_V4SF,   SPU_BTI_FLOAT))\n+DEF_BUILTIN (SPU_SPLATS_9,         CODE_FOR_spu_splats,    \"spu_splats_9\",         B_INTERNAL, _A2(SPU_BTI_V2DF,   SPU_BTI_DOUBLE))\n+DEF_BUILTIN (SPU_EXTRACT,          CODE_FOR_nothing,       \"spu_extract\",          B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_EXTRACT_0,        CODE_FOR_spu_extract,   \"spu_extract_0\",        B_INTERNAL, _A3(SPU_BTI_UINTQI, SPU_BTI_UV16QI, SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_EXTRACT_1,        CODE_FOR_spu_extract,   \"spu_extract_1\",        B_INTERNAL, _A3(SPU_BTI_INTQI,  SPU_BTI_V16QI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_EXTRACT_2,        CODE_FOR_spu_extract,   \"spu_extract_2\",        B_INTERNAL, _A3(SPU_BTI_UINTHI, SPU_BTI_UV8HI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_EXTRACT_3,        CODE_FOR_spu_extract,   \"spu_extract_3\",        B_INTERNAL, _A3(SPU_BTI_INTHI,  SPU_BTI_V8HI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_EXTRACT_4,        CODE_FOR_spu_extract,   \"spu_extract_4\",        B_INTERNAL, _A3(SPU_BTI_UINTSI, SPU_BTI_UV4SI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_EXTRACT_5,        CODE_FOR_spu_extract,   \"spu_extract_5\",        B_INTERNAL, _A3(SPU_BTI_INTSI,  SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_EXTRACT_6,        CODE_FOR_spu_extract,   \"spu_extract_6\",        B_INTERNAL, _A3(SPU_BTI_UINTDI, SPU_BTI_UV2DI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_EXTRACT_7,        CODE_FOR_spu_extract,   \"spu_extract_7\",        B_INTERNAL, _A3(SPU_BTI_INTDI,  SPU_BTI_V2DI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_EXTRACT_8,        CODE_FOR_spu_extract,   \"spu_extract_8\",        B_INTERNAL, _A3(SPU_BTI_FLOAT,  SPU_BTI_V4SF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_EXTRACT_9,        CODE_FOR_spu_extract,   \"spu_extract_9\",        B_INTERNAL, _A3(SPU_BTI_DOUBLE, SPU_BTI_V2DF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_INSERT,           CODE_FOR_nothing,       \"spu_insert\",           B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_INSERT_0,         CODE_FOR_spu_insert,    \"spu_insert_0\",         B_INTERNAL, _A4(SPU_BTI_UV16QI, SPU_BTI_UINTQI, SPU_BTI_UV16QI, SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_INSERT_1,         CODE_FOR_spu_insert,    \"spu_insert_1\",         B_INTERNAL, _A4(SPU_BTI_V16QI,  SPU_BTI_INTQI,  SPU_BTI_V16QI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_INSERT_2,         CODE_FOR_spu_insert,    \"spu_insert_2\",         B_INTERNAL, _A4(SPU_BTI_UV8HI,  SPU_BTI_UINTHI, SPU_BTI_UV8HI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_INSERT_3,         CODE_FOR_spu_insert,    \"spu_insert_3\",         B_INTERNAL, _A4(SPU_BTI_V8HI,   SPU_BTI_INTHI,  SPU_BTI_V8HI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_INSERT_4,         CODE_FOR_spu_insert,    \"spu_insert_4\",         B_INTERNAL, _A4(SPU_BTI_UV4SI,  SPU_BTI_UINTSI, SPU_BTI_UV4SI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_INSERT_5,         CODE_FOR_spu_insert,    \"spu_insert_5\",         B_INTERNAL, _A4(SPU_BTI_V4SI,   SPU_BTI_INTSI,  SPU_BTI_V4SI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_INSERT_6,         CODE_FOR_spu_insert,    \"spu_insert_6\",         B_INTERNAL, _A4(SPU_BTI_UV2DI,  SPU_BTI_UINTDI, SPU_BTI_UV2DI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_INSERT_7,         CODE_FOR_spu_insert,    \"spu_insert_7\",         B_INTERNAL, _A4(SPU_BTI_V2DI,   SPU_BTI_INTDI,  SPU_BTI_V2DI,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_INSERT_8,         CODE_FOR_spu_insert,    \"spu_insert_8\",         B_INTERNAL, _A4(SPU_BTI_V4SF,   SPU_BTI_FLOAT,  SPU_BTI_V4SF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_INSERT_9,         CODE_FOR_spu_insert,    \"spu_insert_9\",         B_INTERNAL, _A4(SPU_BTI_V2DF,   SPU_BTI_DOUBLE, SPU_BTI_V2DF,   SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_PROMOTE,          CODE_FOR_nothing,       \"spu_promote\",          B_OVERLOAD, _A1(SPU_BTI_VOID))\n+DEF_BUILTIN (SPU_PROMOTE_0,        CODE_FOR_spu_promote,   \"spu_promote_0\",        B_INTERNAL, _A3(SPU_BTI_UV16QI, SPU_BTI_UINTQI, SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_PROMOTE_1,        CODE_FOR_spu_promote,   \"spu_promote_1\",        B_INTERNAL, _A3(SPU_BTI_V16QI,  SPU_BTI_INTQI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_PROMOTE_2,        CODE_FOR_spu_promote,   \"spu_promote_2\",        B_INTERNAL, _A3(SPU_BTI_UV8HI,  SPU_BTI_UINTHI, SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_PROMOTE_3,        CODE_FOR_spu_promote,   \"spu_promote_3\",        B_INTERNAL, _A3(SPU_BTI_V8HI,   SPU_BTI_INTHI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_PROMOTE_4,        CODE_FOR_spu_promote,   \"spu_promote_4\",        B_INTERNAL, _A3(SPU_BTI_UV4SI,  SPU_BTI_UINTSI, SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_PROMOTE_5,        CODE_FOR_spu_promote,   \"spu_promote_5\",        B_INTERNAL, _A3(SPU_BTI_V4SI,   SPU_BTI_INTSI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_PROMOTE_6,        CODE_FOR_spu_promote,   \"spu_promote_6\",        B_INTERNAL, _A3(SPU_BTI_UV2DI,  SPU_BTI_UINTDI, SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_PROMOTE_7,        CODE_FOR_spu_promote,   \"spu_promote_7\",        B_INTERNAL, _A3(SPU_BTI_V2DI,   SPU_BTI_INTDI,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_PROMOTE_8,        CODE_FOR_spu_promote,   \"spu_promote_8\",        B_INTERNAL, _A3(SPU_BTI_V4SF,   SPU_BTI_FLOAT,  SPU_BTI_INTSI))\n+DEF_BUILTIN (SPU_PROMOTE_9,        CODE_FOR_spu_promote,   \"spu_promote_9\",        B_INTERNAL, _A3(SPU_BTI_V2DF,   SPU_BTI_DOUBLE, SPU_BTI_INTSI))\n+\n+/* We need something that is not B_INTERNAL as a sentinal. */\n+\n+/* These are for the convenience of imlpemnting fma() in the standard\n+   libraries. */\n+DEF_BUILTIN (SCALAR_FMA,           CODE_FOR_fma_sf,        \"fmas\",                 B_INSN,     _A4(SPU_BTI_FLOAT,  SPU_BTI_FLOAT, SPU_BTI_FLOAT, SPU_BTI_FLOAT))\n+DEF_BUILTIN (SCALAR_DFMA,          CODE_FOR_fma_df,        \"dfmas\",                B_INSN,     _A4(SPU_BTI_DOUBLE, SPU_BTI_DOUBLE, SPU_BTI_DOUBLE, SPU_BTI_DOUBLE))\n+\n+DEF_BUILTIN (SPU_ALIGN_HINT,       CODE_FOR_spu_align_hint,\"spu_align_hint\",       B_INSN,     _A4(SPU_BTI_VOID,   SPU_BTI_PTR,    SPU_BTI_7,      SPU_BTI_7))\n+#undef _A1\n+#undef _A2\n+#undef _A3\n+#undef _A4"}, {"sha": "4eb2d58819a5f08bf7bd23d15377af4f634f9267", "filename": "gcc/config/spu/spu-builtins.h", "status": "added", "additions": 120, "deletions": 0, "changes": 120, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu-builtins.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu-builtins.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu-builtins.h?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,120 @@\n+/* Copyright (C) 2006 Free Software Foundation, Inc.\n+\n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option) \n+   any later version.\n+\n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\f\n+/* built-ins */\n+\n+enum spu_builtin_type_index\n+{\n+  SPU_BTI_END_OF_PARAMS,\n+\n+  /* We create new type nodes for these. */\n+  SPU_BTI_V16QI,\n+  SPU_BTI_V8HI,\n+  SPU_BTI_V4SI,\n+  SPU_BTI_V2DI,\n+  SPU_BTI_V4SF,\n+  SPU_BTI_V2DF,\n+  SPU_BTI_UV16QI,\n+  SPU_BTI_UV8HI,\n+  SPU_BTI_UV4SI,\n+  SPU_BTI_UV2DI,\n+\n+  /* A 16-byte type. (Implemented with V16QI_type_node) */\n+  SPU_BTI_QUADWORD,\n+\n+  /* These all correspond to intSI_type_node */\n+  SPU_BTI_7,\n+  SPU_BTI_S7,\n+  SPU_BTI_U7,\n+  SPU_BTI_S10,\n+  SPU_BTI_S10_4,\n+  SPU_BTI_U14,\n+  SPU_BTI_16,\n+  SPU_BTI_S16,\n+  SPU_BTI_S16_2,\n+  SPU_BTI_U16,\n+  SPU_BTI_U16_2,\n+  SPU_BTI_U18,\n+\n+  /* These correspond to the standard types */\n+  SPU_BTI_INTQI, \n+  SPU_BTI_INTHI, \n+  SPU_BTI_INTSI, \n+  SPU_BTI_INTDI, \n+\n+  SPU_BTI_UINTQI,\n+  SPU_BTI_UINTHI,\n+  SPU_BTI_UINTSI,\n+  SPU_BTI_UINTDI,\n+\n+  SPU_BTI_FLOAT, \n+  SPU_BTI_DOUBLE,\n+\n+  SPU_BTI_VOID,   \n+  SPU_BTI_PTR,   \n+\n+  SPU_BTI_MAX\n+};\n+\n+#define V16QI_type_node               (spu_builtin_types[SPU_BTI_V16QI])\n+#define V8HI_type_node                (spu_builtin_types[SPU_BTI_V8HI])\n+#define V4SI_type_node                (spu_builtin_types[SPU_BTI_V4SI])\n+#define V2DI_type_node                (spu_builtin_types[SPU_BTI_V2DI])\n+#define V4SF_type_node                (spu_builtin_types[SPU_BTI_V4SF])\n+#define V2DF_type_node                (spu_builtin_types[SPU_BTI_V2DF])\n+#define unsigned_V16QI_type_node      (spu_builtin_types[SPU_BTI_UV16QI])\n+#define unsigned_V8HI_type_node       (spu_builtin_types[SPU_BTI_UV8HI])\n+#define unsigned_V4SI_type_node       (spu_builtin_types[SPU_BTI_UV4SI])\n+#define unsigned_V2DI_type_node       (spu_builtin_types[SPU_BTI_UV2DI])\n+\n+extern GTY(()) tree spu_builtin_types[SPU_BTI_MAX];\n+\n+/* Some builtins require special handling.  This enum differentiates. */\n+enum spu_builtin_type {\n+    B_INSN,\n+    B_JUMP,\n+    B_BISLED,\n+    B_CALL,\n+    B_HINT,\n+    B_OVERLOAD, \n+    B_INTERNAL\n+};\n+\n+typedef enum {\n+#define DEF_BUILTIN(fcode, icode, name, type, params) fcode,\n+#include \"spu-builtins.def\"\n+#undef DEF_BUILTIN\n+   NUM_SPU_BUILTINS\n+} spu_function_code;\n+\n+struct spu_builtin_description {\n+    spu_function_code fcode;\n+    enum insn_code icode;\n+    const char *name;\n+    enum spu_builtin_type type;\n+\n+    /* The first element of parm is always the return type.  The rest\n+     * are a zero terminated list of parameters. */\n+    int parm[5];\n+\n+    tree fndecl;\n+};\n+\n+extern GTY(()) struct spu_builtin_description spu_builtins[];\n+\n+\n+"}, {"sha": "9b9a21b61d7744c820297a4b0e3e278a6940578b", "filename": "gcc/config/spu/spu-builtins.md", "status": "added", "additions": 872, "deletions": 0, "changes": 872, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu-builtins.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu-builtins.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu-builtins.md?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,872 @@\n+;; Copyright (C) 2006 Free Software Foundation, Inc.\n+\n+;; This file is free software; you can redistribute it and/or modify it under\n+;; the terms of the GNU General Public License as published by the Free\n+;; Software Foundation; either version 2 of the License, or (at your option) \n+;; any later version.\n+\n+;; This file is distributed in the hope that it will be useful, but WITHOUT\n+;; ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+;; FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+;; for more details.\n+\n+;; You should have received a copy of the GNU General Public License\n+;; along with this file; see the file COPYING.  If not, write to the Free\n+;; Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+;; 02110-1301, USA.\n+\n+\n+;; This includes expands for all the intrinsics.\n+;; spu_expand_builtin looks at the mode of match_operand.\n+\n+\f\n+;; load/store\n+\n+(define_expand \"spu_lqd\"\n+  [(set (match_operand:TI 0 \"spu_reg_operand\" \"\")\n+        (mem:TI (and:SI (plus:SI (match_operand:SI 1 \"spu_reg_operand\" \"\")\n+\t\t\t\t (match_operand:SI 2 \"spu_nonmem_operand\" \"\"))\n+\t\t        (const_int -16))))]\n+  \"\"\n+  {\n+    if (GET_CODE (operands[2]) == CONST_INT\n+\t&& (INTVAL (operands[2]) & 15) != 0)\n+      operands[2] = GEN_INT (INTVAL (operands[2]) & -16);\n+    if (GET_CODE (operands[2]) != CONST_INT)\n+      {\n+\trtx op2 = operands[2];\n+\toperands[2] = force_reg (Pmode, operands[2]);\n+\tif (!ALIGNED_SYMBOL_REF_P (op2))\n+\t  emit_insn (gen_andsi3 (operands[2], operands[2], GEN_INT (-16)));\n+      }\n+  })\n+\n+(define_expand \"spu_lqx\"\n+  [(set (match_operand:TI 0 \"spu_reg_operand\" \"\")\n+        (mem:TI (and:SI (plus:SI (match_operand:SI 1 \"spu_reg_operand\" \"\")\n+                                 (match_operand:SI 2 \"spu_reg_operand\" \"\"))\n+                        (const_int -16))))]\n+  \"\"\n+  \"\")\n+\n+(define_expand \"spu_lqa\"\n+  [(set (match_operand:TI 0 \"spu_reg_operand\" \"\")\n+        (mem:TI (and:SI (match_operand:SI 1 \"immediate_operand\" \"\")\n+                        (const_int -16))))]\n+  \"\"\n+  {\n+    if (GET_CODE (operands[1]) == CONST_INT\n+\t&& (INTVAL (operands[1]) & 15) != 0)\n+      operands[1] = GEN_INT (INTVAL (operands[1]) & -16);\n+  })\n+\n+(define_expand \"spu_lqr\"\n+  [(set (match_operand:TI 0 \"spu_reg_operand\" \"\")\n+\t(mem:TI (and:SI (match_operand:SI 1 \"address_operand\" \"\")\n+\t\t\t(const_int -16))))]\n+  \"\"\n+  \"\")\n+\n+(define_expand \"spu_stqd\"\n+  [(set (mem:TI (and:SI (plus:SI (match_operand:SI 1 \"spu_reg_operand\" \"\")\n+\t\t\t\t (match_operand:SI 2 \"spu_nonmem_operand\" \"\"))\n+\t\t        (const_int -16)))\n+        (match_operand:TI 0 \"spu_reg_operand\" \"r,r\"))]\n+  \"\"\n+  {\n+    if (GET_CODE (operands[2]) == CONST_INT\n+\t&& (INTVAL (operands[2]) & 15) != 0)\n+      operands[2] = GEN_INT (INTVAL (operands[2]) & -16);\n+    if (GET_CODE (operands[2]) != CONST_INT)\n+      {\n+\trtx op2 = operands[2];\n+\toperands[2] = force_reg (Pmode, operands[2]);\n+\tif (!ALIGNED_SYMBOL_REF_P (op2))\n+\t  emit_insn (gen_andsi3 (operands[2], operands[2], GEN_INT (-16)));\n+      }\n+  })\n+\n+(define_expand \"spu_stqx\"\n+  [(set (mem:TI (and:SI (plus:SI (match_operand:SI 1 \"spu_reg_operand\" \"\")\n+\t\t\t\t (match_operand:SI 2 \"spu_reg_operand\" \"\"))\n+\t\t        (const_int -16)))\n+        (match_operand:TI 0 \"spu_reg_operand\" \"r\"))]\n+  \"\"\n+  \"\")\n+\n+(define_expand \"spu_stqa\"\n+  [(set (mem:TI (and:SI (match_operand:SI 1 \"immediate_operand\" \"\")\n+\t\t\t(const_int -16)))\n+        (match_operand:TI 0 \"spu_reg_operand\" \"r\"))]\n+  \"\"\n+  {\n+    if (GET_CODE (operands[1]) == CONST_INT\n+\t&& (INTVAL (operands[1]) & 15) != 0)\n+      operands[1] = GEN_INT (INTVAL (operands[1]) & -16);\n+  })\n+\n+(define_expand \"spu_stqr\"\n+    [(set (mem:TI (and:SI (match_operand:SI 1 \"address_operand\" \"\")\n+\t\t\t  (const_int -16)))\n+\t  (match_operand:TI 0 \"spu_reg_operand\" \"\"))]\n+  \"\"\n+  \"\")\n+\n+\f\n+;; generate control word\n+\n+(define_expand \"spu_cbx\"\n+  [(set (match_operand:TI 0 \"spu_reg_operand\" \"\")\n+        (unspec:TI [(match_operand:SI 1 \"spu_reg_operand\" \"\")\n+                    (match_operand:SI 2 \"spu_nonmem_operand\" \"\")\n+                    (const_int 1)] UNSPEC_CPAT))]\n+  \"\"\n+  \"\")\n+\n+(define_expand \"spu_chx\"\n+  [(set (match_operand:TI 0 \"spu_reg_operand\" \"\")\n+        (unspec:TI [(match_operand:SI 1 \"spu_reg_operand\" \"\")\n+                    (match_operand:SI 2 \"spu_nonmem_operand\" \"\")\n+                    (const_int 2)] UNSPEC_CPAT))]\n+  \"\"\n+  \"\")\n+\n+(define_expand \"spu_cwx\"\n+  [(set (match_operand:TI 0 \"spu_reg_operand\" \"\")\n+        (unspec:TI [(match_operand:SI 1 \"spu_reg_operand\" \"\")\n+                    (match_operand:SI 2 \"spu_nonmem_operand\" \"\")\n+                    (const_int 4)] UNSPEC_CPAT))]\n+  \"\"\n+  \"\")\n+\n+(define_expand \"spu_cdx\"\n+  [(set (match_operand:TI 0 \"spu_reg_operand\" \"\")\n+        (unspec:TI [(match_operand:SI 1 \"spu_reg_operand\" \"\")\n+                    (match_operand:SI 2 \"spu_nonmem_operand\" \"\")\n+                    (const_int 8)] UNSPEC_CPAT))]\n+  \"\"\n+  \"\")\n+\n+\n+\f\n+;; Constant formation\n+\n+(define_expand \"spu_ilhu\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"\")\n+        (const_vector:V4SI [(match_operand:SI 1 \"immediate_operand\" \"\")]))]\n+  \"\"\n+  \"{ emit_insn(gen_movv4si(operands[0], spu_const(V4SImode, (INTVAL(operands[1]) << 16))));\n+     DONE;\n+   }\")\n+\n+\f\n+;; integer subtract\n+(define_expand \"spu_sfh\"\n+  [(set (match_operand:V8HI 0 \"spu_reg_operand\" \"\")\n+        (minus:V8HI (match_operand:V8HI 2 \"spu_nonmem_operand\" \"\")\n+                    (match_operand:V8HI 1 \"spu_reg_operand\" \"\")))]\n+  \"\"\n+  \"\")\n+\n+(define_expand \"spu_sf\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"\")\n+        (minus:V4SI (match_operand:V4SI 2 \"spu_nonmem_operand\" \"\")\n+                    (match_operand:V4SI 1 \"spu_reg_operand\" \"\")))]\n+  \"\"\n+  \"\")\n+\n+(define_expand \"spu_sfx\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"\")\n+        (unspec:V4SI [(match_operand:V4SI 2 \"spu_reg_operand\" \"\")\n+\t\t      (match_operand:V4SI 1 \"spu_reg_operand\" \"\")\n+\t\t      (match_operand:V4SI 3 \"spu_reg_operand\" \"\")] UNSPEC_SFX))]\n+  \"\"\n+  \"\")\n+\n+(define_expand \"spu_bg\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"\")\n+        (unspec:V4SI [(match_operand:V4SI 2 \"spu_reg_operand\" \"\")\n+\t\t      (match_operand:V4SI 1 \"spu_reg_operand\" \"\")] UNSPEC_BG))]\n+  \"\"\n+  \"\")\n+\n+(define_expand \"spu_bgx\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"\")\n+        (unspec:V4SI [(match_operand:V4SI 2 \"spu_reg_operand\" \"\")\n+\t\t      (match_operand:V4SI 1 \"spu_reg_operand\" \"\")\n+\t\t      (match_operand:V4SI 3 \"spu_reg_operand\" \"\")] UNSPEC_BGX))]\n+  \"\"\n+  \"\")\n+\n+;; integer multiply\n+(define_insn \"spu_mpy\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r,r\")\n+        (mult:V4SI\n+\t  (sign_extend:V4SI\n+\t    (vec_select:V4HI\n+\t      (match_operand:V8HI 1 \"spu_reg_operand\" \"r,r\")\n+\t      (parallel [(const_int 1)(const_int 3)(const_int 5)(const_int 7)])))\n+          (sign_extend:V4SI\n+\t    (vec_select:V4HI\n+\t      (match_operand:V8HI 2 \"spu_arith_operand\" \"r,B\")\n+\t      (parallel [(const_int 1)(const_int 3)(const_int 5)(const_int 7)])))))]\n+  \"\"\n+  \"@\n+   mpy\\t%0,%1,%2\n+   mpyi\\t%0,%1,%H2\"\n+  [(set_attr \"type\" \"fp7\")])\n+\n+(define_insn \"spu_mpyu\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r,r\")\n+        (mult:V4SI\n+\t  (zero_extend:V4SI\n+\t    (vec_select:V4HI\n+\t      (match_operand:V8HI 1 \"spu_reg_operand\" \"r,r\")\n+\t      (parallel [(const_int 1)(const_int 3)(const_int 5)(const_int 7)])))\n+          (zero_extend:V4SI\n+\t    (vec_select:V4HI\n+\t      (match_operand:V8HI 2 \"spu_arith_operand\" \"r,B\")\n+\t      (parallel [(const_int 1)(const_int 3)(const_int 5)(const_int 7)])))))]\n+  \"\"\n+  \"@\n+   mpyu\\t%0,%1,%2\n+   mpyui\\t%0,%1,%H2\"\n+  [(set_attr \"type\" \"fp7\")])\n+\n+(define_insn \"spu_mpya\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+        (plus:V4SI\n+\t  (mult:V4SI\n+\t    (sign_extend:V4SI\n+\t      (vec_select:V4HI\n+\t\t(match_operand:V8HI 1 \"spu_reg_operand\" \"r\")\n+\t\t(parallel [(const_int 1)(const_int 3)(const_int 5)(const_int 7)])))\n+\t    (sign_extend:V4SI\n+\t      (vec_select:V4HI\n+\t\t(match_operand:V8HI 2 \"spu_reg_operand\" \"r\")\n+\t\t(parallel [(const_int 1)(const_int 3)(const_int 5)(const_int 7)]))))\n+\t(match_operand:V4SI 3 \"spu_reg_operand\" \"r\")))]\n+  \"\"\n+  \"mpya\\t%0,%1,%2,%3\"\n+  [(set_attr \"type\" \"fp7\")])\n+\n+(define_insn \"spu_mpyh\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+        (ashift:V4SI\n+\t  (mult:V4SI\n+\t    (sign_extend:V4SI\n+\t      (vec_select:V4HI\n+\t\t(match_operand:V8HI 1 \"spu_reg_operand\" \"r\")\n+\t\t(parallel [(const_int 0)(const_int 2)(const_int 4)(const_int 6)])))\n+\t    (sign_extend:V4SI\n+\t      (vec_select:V4HI\n+\t\t(match_operand:V8HI 2 \"spu_reg_operand\" \"r\")\n+\t\t(parallel [(const_int 1)(const_int 3)(const_int 5)(const_int 7)]))))\n+\t  (const_vector:V4SI [(const_int 16)(const_int 16)(const_int 16)(const_int 16)])))]\n+  \"\"\n+  \"mpyh\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fp7\")])\n+\n+(define_insn \"spu_mpys\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+        (ashiftrt:V4SI\n+\t  (mult:V4SI\n+\t    (sign_extend:V4SI\n+\t      (vec_select:V4HI\n+\t\t(match_operand:V8HI 1 \"spu_reg_operand\" \"r\")\n+\t\t(parallel [(const_int 1)(const_int 3)(const_int 5)(const_int 7)])))\n+\t    (sign_extend:V4SI\n+\t      (vec_select:V4HI\n+\t\t(match_operand:V8HI 2 \"spu_reg_operand\" \"r\")\n+\t\t(parallel [(const_int 1)(const_int 3)(const_int 5)(const_int 7)]))))\n+\t  (const_vector:V4SI [(const_int 16)(const_int 16)(const_int 16)(const_int 16)])))]\n+  \"\"\n+  \"mpys\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fp7\")])\n+\n+(define_insn \"spu_mpyhhu\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+\t(mult:V4SI\n+\t  (zero_extend:V4SI\n+\t    (vec_select:V4HI\n+\t      (match_operand:V8HI 1 \"spu_reg_operand\" \"r\")\n+\t      (parallel [(const_int 0)(const_int 2)(const_int 4)(const_int 6)])))\n+\t  (zero_extend:V4SI\n+\t    (vec_select:V4HI\n+\t      (match_operand:V8HI 2 \"spu_reg_operand\" \"r\")\n+\t      (parallel [(const_int 0)(const_int 2)(const_int 4)(const_int 6)])))))]\n+  \"\"\n+  \"mpyhhu\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fp7\")])\n+\n+(define_insn \"spu_mpyhh\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+\t(mult:V4SI\n+\t  (sign_extend:V4SI\n+\t    (vec_select:V4HI\n+\t      (match_operand:V8HI 1 \"spu_reg_operand\" \"r\")\n+\t      (parallel [(const_int 0)(const_int 2)(const_int 4)(const_int 6)])))\n+\t  (sign_extend:V4SI\n+\t    (vec_select:V4HI\n+\t      (match_operand:V8HI 2 \"spu_reg_operand\" \"r\")\n+\t      (parallel [(const_int 0)(const_int 2)(const_int 4)(const_int 6)])))))]\n+  \"\"\n+  \"mpyhh\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fp7\")])\n+\n+(define_insn \"spu_mpyhhau\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+        (plus:V4SI\n+\t  (mult:V4SI\n+\t    (zero_extend:V4SI\n+\t      (vec_select:V4HI\n+\t\t(match_operand:V8HI 1 \"spu_reg_operand\" \"r\")\n+\t\t(parallel [(const_int 0)(const_int 2)(const_int 4)(const_int 6)])))\n+\t    (zero_extend:V4SI\n+\t      (vec_select:V4HI\n+\t\t(match_operand:V8HI 2 \"spu_reg_operand\" \"r\")\n+\t\t(parallel [(const_int 0)(const_int 2)(const_int 4)(const_int 6)]))))\n+\t  (match_operand:V4SI 3 \"spu_reg_operand\" \"0\")))]\n+  \"\"\n+  \"mpyhhau\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fp7\")])\n+\n+(define_insn \"spu_mpyhha\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+        (plus:V4SI\n+\t  (mult:V4SI\n+\t    (sign_extend:V4SI\n+\t      (vec_select:V4HI\n+\t\t(match_operand:V8HI 1 \"spu_reg_operand\" \"r\")\n+\t\t(parallel [(const_int 0)(const_int 2)(const_int 4)(const_int 6)])))\n+\t    (sign_extend:V4SI\n+\t      (vec_select:V4HI\n+\t\t(match_operand:V8HI 2 \"spu_reg_operand\" \"r\")\n+\t\t(parallel [(const_int 0)(const_int 2)(const_int 4)(const_int 6)]))))\n+\t  (match_operand:V4SI 3 \"spu_reg_operand\" \"0\")))]\n+  \"\"\n+  \"mpyhha\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fp7\")])\n+\n+;; form select mask\n+(define_insn \"spu_fsmb\"\n+  [(set (match_operand:V16QI 0 \"spu_reg_operand\" \"=r,r\")\n+        (unspec:V16QI [(match_operand:SI 1 \"spu_nonmem_operand\" \"r,MN\")] UNSPEC_FSMB))]\n+  \"\"\n+  \"@\n+  fsmb\\t%0,%1\n+  fsmbi\\t%0,%1\"\n+  [(set_attr \"type\" \"shuf\")])\n+\n+(define_insn \"spu_fsmh\"\n+  [(set (match_operand:V8HI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec:V8HI [(match_operand:SI 1 \"spu_reg_operand\" \"r\")] UNSPEC_FSMH))]\n+  \"\"\n+  \"fsmh\\t%0,%1\"\n+  [(set_attr \"type\" \"shuf\")])\n+\n+(define_insn \"spu_fsm\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec:V4SI [(match_operand:SI 1 \"spu_reg_operand\" \"r\")] UNSPEC_FSM))]\n+  \"\"\n+  \"fsm\\t%0,%1\"\n+  [(set_attr \"type\" \"shuf\")])\n+\n+\n+;; gather bits\n+(define_insn \"spu_gbb\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec:V4SI [(match_operand:V16QI 1 \"spu_reg_operand\" \"r\")] UNSPEC_GBB))]\n+  \"\"\n+  \"gbb\\t%0,%1\"\n+  [(set_attr \"type\" \"shuf\")])\n+\n+(define_insn \"spu_gbh\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec:V4SI [(match_operand:V8HI 1 \"spu_reg_operand\" \"r\")] UNSPEC_GBH))]\n+  \"\"\n+  \"gbh\\t%0,%1\"\n+  [(set_attr \"type\" \"shuf\")])\n+\n+(define_insn \"spu_gb\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec:V4SI [(match_operand:V4SI 1 \"spu_reg_operand\" \"r\")] UNSPEC_GB))]\n+  \"\"\n+  \"gb\\t%0,%1\"\n+  [(set_attr \"type\" \"shuf\")])\n+\n+;; misc byte operations\n+(define_insn \"spu_avgb\"\n+  [(set (match_operand:V16QI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec:V16QI [(match_operand:V16QI 1 \"spu_reg_operand\" \"r\")\n+\t\t       (match_operand:V16QI 2 \"spu_reg_operand\" \"r\")] UNSPEC_AVGB))]\n+  \"\"\n+  \"avgb\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fxb\")])\n+\n+(define_insn \"spu_absdb\"\n+  [(set (match_operand:V16QI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec:V16QI [(match_operand:V16QI 1 \"spu_reg_operand\" \"r\")\n+\t\t       (match_operand:V16QI 2 \"spu_reg_operand\" \"r\")] UNSPEC_ABSDB))]\n+  \"\"\n+  \"absdb\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fxb\")])\n+\n+(define_insn \"spu_sumb\"\n+  [(set (match_operand:V8HI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec:V8HI [(match_operand:V16QI 1 \"spu_reg_operand\" \"r\")\n+\t\t      (match_operand:V16QI 2 \"spu_reg_operand\" \"r\")] UNSPEC_SUMB))]\n+  \"\"\n+  \"sumb\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fxb\")])\n+\n+;; sign extend\n+(define_insn \"spu_xsbh\"\n+  [(set (match_operand:V8HI 0 \"spu_reg_operand\" \"=r\")\n+        (sign_extend:V8HI\n+\t  (vec_select:V8QI\n+\t    (match_operand:V16QI 1 \"spu_reg_operand\" \"r\")\n+\t    (parallel [(const_int 1)(const_int 3)(const_int 5)(const_int 7)\n+\t               (const_int 9)(const_int 11)(const_int 13)(const_int 15)]))))]\n+  \"\"\n+  \"xsbh\\t%0,%1\")\n+\n+(define_insn \"spu_xshw\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+        (sign_extend:V4SI\n+\t  (vec_select:V4HI\n+\t    (match_operand:V8HI 1 \"spu_reg_operand\" \"r\")\n+\t    (parallel [(const_int 1)(const_int 3)(const_int 5)(const_int 7)]))))]\n+  \"\"\n+  \"xshw\\t%0,%1\")\n+\n+(define_insn \"spu_xswd\"\n+  [(set (match_operand:V2DI 0 \"spu_reg_operand\" \"=r\")\n+        (sign_extend:V2DI\n+\t  (vec_select:V2SI\n+\t    (match_operand:V4SI 1 \"spu_reg_operand\" \"r\")\n+\t    (parallel [(const_int 1)(const_int 3)]))))]\n+  \"\"\n+  \"xswd\\t%0,%1\")\n+\n+;; or across\n+\n+(define_insn \"spu_orx\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+\t(unspec:V4SI [(match_operand:V4SI 1 \"spu_reg_operand\" \"r\")] UNSPEC_ORX))]\n+  \"\"\n+  \"orx\\t%0,%1\")\n+\n+\n+;; compare & halt\n+(define_insn \"spu_heq\"\n+  [(unspec_volatile [(match_operand:SI 0 \"spu_reg_operand\" \"r,r\")\n+\t             (match_operand:SI 1 \"spu_nonmem_operand\" \"r,K\")] UNSPEC_HEQ)]\n+  \"\"\n+  \"@\n+  heq\\t%0,%1\n+  heqi\\t%0,%1\")\n+\n+(define_insn \"spu_hgt\"\n+  [(unspec_volatile [(match_operand:SI 0 \"spu_reg_operand\" \"r,r\")\n+\t             (match_operand:SI 1 \"spu_nonmem_operand\" \"r,K\")] UNSPEC_HGT)]\n+  \"\"\n+  \"@\n+  hgt\\t%0,%1\n+  hgti\\t%0,%1\")\n+\n+(define_insn \"spu_hlgt\"\n+  [(unspec_volatile [(match_operand:SI 0 \"spu_reg_operand\" \"r,r\")\n+\t             (match_operand:SI 1 \"spu_nonmem_operand\" \"r,K\")] UNSPEC_HLGT)]\n+  \"\"\n+  \"@\n+  hlgt\\t%0,%1\n+  hlgti\\t%0,%1\")\n+\n+;; branches\n+\n+;; The description below hides the fact that bisled conditionally\n+;; executes the call depending on the value in channel 0.  This was \n+;; done so that the description would conform to the format of a call \n+;; insn.  Otherwise (if this were not part of call insn), the link \n+;; register, $lr, would not be saved/restored in the prologue/epilogue.\n+\n+(define_insn \"spu_bisled\"\n+  [(parallel\n+    [(call (mem:QI (match_operand:SI 0 \"spu_reg_operand\" \"r\"))\n+            (const_int 0))\n+     (clobber (reg:SI 0))\n+     (clobber (reg:SI 130))\n+     (use (match_operand:SI 1 \"address_operand\" \"\"))\n+     (use (const_int 0))])]\n+  \"\"\n+  \"bisled\\t$lr,%0\"\n+  [(set_attr \"type\" \"br\")])\n+\n+(define_insn \"spu_bisledd\"\n+  [(parallel\n+    [(call (mem:QI (match_operand:SI 0 \"spu_reg_operand\" \"r\"))\n+            (const_int 0))\n+     (clobber (reg:SI 0))\n+     (clobber (reg:SI 130))\n+     (use (match_operand:SI 1 \"address_operand\" \"\"))\n+     (use (const_int 1))])]\n+  \"\"\n+  \"bisledd\\t$lr,%0\"\n+  [(set_attr \"type\" \"br\")])\n+\n+(define_insn \"spu_bislede\"\n+  [(parallel\n+    [(call (mem:QI (match_operand:SI 0 \"spu_reg_operand\" \"r\"))\n+            (const_int 0))\n+     (clobber (reg:SI 0))\n+     (clobber (reg:SI 130))\n+     (use (match_operand:SI 1 \"address_operand\" \"\"))\n+     (use (const_int 2))])]\n+  \"\"\n+  \"bislede\\t$lr,%0\"\n+  [(set_attr \"type\" \"br\")])\n+\n+;; float convert\n+(define_insn \"spu_csflt\"\n+  [(set (match_operand:V4SF 0 \"spu_reg_operand\" \"=r\")\n+\t(unspec:V4SF [(match_operand:V4SI 1 \"spu_reg_operand\" \"r\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"K\")] UNSPEC_CSFLT ))]\n+  \"\"\n+  \"csflt\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fp7\")])\n+\n+(define_insn \"spu_cflts\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+\t(unspec:V4SI [(match_operand:V4SF 1 \"spu_reg_operand\" \"r\")\n+                      (match_operand:SI 2 \"immediate_operand\" \"J\")] UNSPEC_CFLTS ))]\n+  \"\"\n+  \"cflts\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fp7\")])\n+\n+(define_insn \"spu_cuflt\"\n+  [(set (match_operand:V4SF 0 \"spu_reg_operand\" \"=r\")\n+\t(unspec:V4SF [(match_operand:V4SI 1 \"spu_reg_operand\" \"r\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"K\")] UNSPEC_CUFLT ))]\n+  \"\"\n+  \"cuflt\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fp7\")])\n+\n+(define_insn \"spu_cfltu\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+\t(unspec:V4SI [(match_operand:V4SF 1 \"spu_reg_operand\" \"r\")\n+\t\t      (match_operand:SI 2 \"immediate_operand\" \"J\")] UNSPEC_CFLTU ))]\n+  \"\"\n+  \"cfltu\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"fp7\")])\n+\n+(define_expand \"spu_frds\"\n+   [(set (match_operand:V4SF 0 \"spu_reg_operand\" \"\")\n+         (vec_select:V4SF\n+\t   (vec_concat:V4SF\n+\t     (float_truncate:V2SF (match_operand:V2DF 1 \"spu_reg_operand\" \"\"))\n+\t     (match_dup:V2SF 2))\n+\t   (parallel [(const_int 0)(const_int 2)(const_int 1)(const_int 3)])))]\n+  \"\"\n+  \"operands[2] = spu_const(V2SFmode, 0);\")\n+\n+(define_insn \"_frds\"\n+   [(set (match_operand:V4SF 0 \"spu_reg_operand\" \"=r\")\n+        (vec_select:V4SF\n+\t  (vec_concat:V4SF\n+\t    (float_truncate:V2SF (match_operand:V2DF 1 \"spu_reg_operand\" \"r\"))\n+\t    (match_operand:V2SF 2 \"vec_imm_operand\" \"i\"))\n+\t  (parallel [(const_int 0)(const_int 2)(const_int 1)(const_int 3)])))]\n+  \"\"\n+  \"frds\\t%0,%1\"\n+  [(set_attr \"type\" \"fpd\")])\n+\n+(define_insn \"spu_fesd\"\n+  [(set (match_operand:V2DF 0 \"spu_reg_operand\" \"=r\")\n+        (float_extend:V2DF\n+\t  (vec_select:V2SF\n+\t    (match_operand:V4SF 1 \"spu_reg_operand\" \"r\")\n+\t      (parallel [(const_int 0)(const_int 2)]))))]\n+  \"\"\n+  \"fesd\\t%0,%1\"\n+  [(set_attr \"type\" \"fpd\")])\n+\n+;; control\n+(define_insn \"spu_stop\"\n+  [(unspec_volatile [(match_operand:SI 0 \"immediate_operand\" \"M\")] UNSPEC_STOP)]\n+  \"\"\n+  \"stop\\t%0\"\n+  [(set_attr \"type\" \"br\")])\n+\n+(define_insn \"spu_stopd\"\n+  [(unspec_volatile [(match_operand:SI 0 \"spu_reg_operand\" \"r\")\n+\t\t     (match_operand:SI 1 \"spu_reg_operand\" \"r\")\n+\t\t     (match_operand:SI 2 \"spu_reg_operand\" \"r\")] UNSPEC_STOPD)]\n+  \"\"\n+  \"stopd\\t%0,%1,%2\"\n+  [(set_attr \"type\" \"br\")])\n+\n+;; interrupt disable/enable\n+;; Register 131 is used exclusively for enabling/disabling interrupts.\n+;; It is marked as a global reg and the instructions clobber mem, so it will\n+;; not be incorrectly optimized.\n+(define_expand \"spu_idisable\"\n+  [(parallel\n+    [(set (reg:INTR 131) (const_int 0))\n+     (clobber (match_dup:SI 0))\n+     (clobber (mem:BLK (scratch)))])]\n+  \"\"\n+  \"operands[0] = gen_reg_rtx (SImode);\")\n+\n+(define_expand \"spu_ienable\"\n+  [(parallel\n+    [(set (reg:INTR 131) (const_int 1))\n+     (clobber (match_dup:SI 0))\n+     (clobber (mem:BLK (scratch)))])]\n+  \"\"\n+  \"operands[0] = gen_reg_rtx (SImode);\")\n+\n+(define_insn \"set_intr\"\n+  [(set (reg:INTR 131) (match_operand 1 \"const_int_operand\" \"i\"))\n+   (clobber (match_operand:SI 0 \"spu_reg_operand\" \"=&r\"))\n+   (clobber (mem:BLK (scratch)))]\n+  \"! flag_pic\"\n+  \"ila\\t%0,.+8\\;bi%I1\\t%0\"\n+  [(set_attr \"length\" \"8\")\n+   (set_attr \"type\" \"multi0\")])\n+\n+(define_insn \"set_intr_pic\"\n+  [(set (reg:INTR 131) (match_operand 1 \"const_int_operand\" \"i\"))\n+   (clobber (match_operand:SI 0 \"spu_reg_operand\" \"=&r\"))\n+   (clobber (mem:BLK (scratch)))]\n+  \"flag_pic\"\n+  \"brsl\\t%0,.+4\\;ai\\t%0,%0,8\\;bi%I1\\t%0\"\n+  [(set_attr \"length\" \"12\")\n+   (set_attr \"type\" \"multi1\")])\n+\n+(define_expand \"movintrcc\"\n+  [(parallel\n+    [(set (match_operand:INTR 0 \"spu_reg_operand\" \"\")\n+\t  (if_then_else:INTR (match_operand 1 \"branch_comparison_operator\" \"\")\n+\t\t\t(match_operand 3 \"const_int_operand\" \"\")\n+\t\t\t(match_operand:INTR 2 \"spu_reg_operand\" \"\")))\n+     (clobber (match_dup:SI 4))\n+     (clobber (mem:BLK (scratch)))])]\n+  \"\"\n+  { /* We've swapped operands 2 and 3 in the pattern, reverse the\n+       condition code too. */\n+    PUT_CODE (operands[1], reverse_condition (GET_CODE (operands[1])));\n+    operands[4] = gen_reg_rtx (SImode);\n+  })\n+\n+(define_insn \"set_intr_cc\"\n+  [(set (reg:INTR 131)\n+\t(if_then_else:INTR\n+\t  (match_operator 1 \"branch_comparison_operator\"\n+\t    [(match_operand 2 \"spu_reg_operand\" \"r\")\n+\t     (const_int 0)])\n+\t  (match_operand:SI 3 \"const_int_operand\" \"i\")\n+\t  (reg:INTR 131)))\n+   (clobber (match_operand:SI 0 \"spu_reg_operand\" \"=&r\"))\n+   (clobber (mem:BLK (scratch)))]\n+  \"! flag_pic\"\n+  \"ila\\t%0,.+8\\;bi%b2%b1z%I3\\t%2,%0\"\n+  [(set_attr \"length\" \"8\")\n+   (set_attr \"type\" \"multi0\")])\n+\n+(define_insn \"set_intr_cc_pic\"\n+  [(set (reg:INTR 131)\n+\t(if_then_else:INTR\n+\t  (match_operator 1 \"branch_comparison_operator\"\n+\t    [(match_operand 2 \"spu_reg_operand\" \"r\")\n+\t     (const_int 0)])\n+\t  (match_operand:SI 3 \"const_int_operand\" \"i\")\n+\t  (reg:INTR 131)))\n+   (clobber (match_operand:SI 0 \"spu_reg_operand\" \"=&r\"))\n+   (clobber (mem:BLK (scratch)))]\n+  \"flag_pic\"\n+  \"brsl\\t%0,.+4\\;ai\\t%0,%0,8\\;%b2%b1z%I3\\t%2,%0\"\n+  [(set_attr \"length\" \"12\")\n+   (set_attr \"type\" \"multi1\")])\n+\n+(define_insn \"set_intr_return\"\n+  [(set (reg:INTR 131) (match_operand 0 \"const_int_operand\" \"i\"))\n+   (return)]\n+  \"\"\n+  \"bi%I0\\t$lr\"\n+  [(set_attr \"type\" \"br\")])\n+\n+(define_peephole2\n+  [(parallel\n+    [(set (reg:INTR 131) (match_operand 0 \"const_int_operand\"))\n+     (clobber (match_operand:SI 1 \"spu_reg_operand\"))\n+     (clobber (mem:BLK (scratch)))])\n+   (use (reg:SI 0))\n+   (return)]\n+  \"\"\n+  [(use (reg:SI 0))\n+   (parallel\n+    [(set (reg:INTR 131) (match_dup 0))\n+     (return)])]\n+  \"\")\n+\n+;; special purpose registers\n+(define_insn \"spu_fscrrd\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec_volatile:V4SI [(const_int 6)] UNSPEC_FSCRRD))]\n+  \"\"\n+  \"fscrrd\\t%0\"\n+  [(set_attr \"type\" \"spr\")])\n+\n+(define_insn \"spu_fscrwr\"\n+  [(unspec_volatile [(match_operand:V4SI 0 \"spu_reg_operand\" \"r\")] UNSPEC_FSCRWR)]\n+  \"\"\n+  \"fscrwr\\t$0,%0\"\n+  [(set_attr \"type\" \"spr\")])\n+\n+(define_insn \"spu_mfspr\"\n+  [(set (match_operand:SI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec_volatile:SI [(match_operand:SI 1 \"immediate_operand\" \"J\")] UNSPEC_MFSPR))]\n+  \"\"\n+  \"mfspr\\t%0,$sp%1\"\n+  [(set_attr \"type\" \"spr\")])\n+\n+(define_insn \"spu_mtspr\"\n+  [(unspec_volatile [(match_operand:SI 0 \"immediate_operand\" \"J\")\n+\t             (match_operand:SI 1 \"spu_reg_operand\" \"r\")] UNSPEC_MTSPR)]\n+  \"\"\n+  \"mtspr\\t$sp%0,%1\"\n+  [(set_attr \"type\" \"spr\")])\n+\n+;; channels\n+(define_expand \"spu_rdch\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"\")\n+        (unspec_volatile:V4SI [(match_operand:SI 1 \"immediate_operand\" \"\")] UNSPEC_RDCH))]\n+  \"\"\n+  \"{\n+    if (spu_safe_dma (INTVAL (operands[1])))\n+      {\n+        emit_insn (gen_spu_rdch_clobber (operands[0], operands[1]));\n+        DONE;\n+      }\n+   }\")\n+\n+(define_expand \"spu_rchcnt\"\n+  [(set (match_operand:SI 0 \"spu_reg_operand\" \"\")\n+        (unspec_volatile:SI [(match_operand:SI 1 \"immediate_operand\" \"\")] UNSPEC_RCHCNT))]\n+  \"\"\n+  \"{\n+    if (spu_safe_dma (INTVAL (operands[1])))\n+      {\n+        emit_insn (gen_spu_rchcnt_clobber (operands[0], operands[1]));\n+        DONE;\n+      }\n+   }\")\n+\n+(define_expand \"spu_wrch\"\n+   [(unspec_volatile [(match_operand:SI 0 \"immediate_operand\" \"\")\n+ \t              (match_operand:V4SI 1 \"spu_reg_operand\" \"\")] UNSPEC_WRCH)]\n+   \"\"\n+  \"{\n+    if (spu_safe_dma (INTVAL (operands[0])))\n+      {\n+        emit_insn (gen_spu_wrch_clobber (operands[0], operands[1]));\n+        DONE;\n+      }\n+   }\")\n+\n+(define_insn \"spu_rdch_noclobber\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec_volatile:V4SI [(match_operand:SI 1 \"immediate_operand\" \"J\")] UNSPEC_RDCH))]\n+  \"\"\n+  \"rdch\\t%0,$ch%1\"\n+  [(set_attr \"type\" \"spr\")])\n+\n+(define_insn \"spu_rchcnt_noclobber\"\n+  [(set (match_operand:SI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec_volatile:SI [(match_operand:SI 1 \"immediate_operand\" \"J\")] UNSPEC_RCHCNT))]\n+  \"\"\n+  \"rchcnt\\t%0,$ch%1\"\n+  [(set_attr \"type\" \"spr\")])\n+\n+(define_insn \"spu_wrch_noclobber\"\n+   [(unspec_volatile [(match_operand:SI 0 \"immediate_operand\" \"J\")\n+ \t              (match_operand:V4SI 1 \"spu_reg_operand\" \"r\")] UNSPEC_WRCH)]\n+   \"\"\n+   \"wrch\\t$ch%0,%1\"\n+   [(set_attr \"type\" \"spr\")])\n+\n+(define_insn \"spu_rdch_clobber\"\n+  [(set (match_operand:V4SI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec_volatile:V4SI [(match_operand:SI 1 \"immediate_operand\" \"J\")] UNSPEC_RDCH))\n+    (clobber (mem:BLK (scratch)))]\n+  \"\"\n+  \"rdch\\t%0,$ch%1\"\n+  [(set_attr \"type\" \"spr\")])\n+\n+(define_insn \"spu_rchcnt_clobber\"\n+  [(set (match_operand:SI 0 \"spu_reg_operand\" \"=r\")\n+        (unspec_volatile:SI [(match_operand:SI 1 \"immediate_operand\" \"J\")] UNSPEC_RCHCNT))\n+    (clobber (mem:BLK (scratch)))]\n+  \"\"\n+  \"rchcnt\\t%0,$ch%1\"\n+  [(set_attr \"type\" \"spr\")])\n+\n+(define_insn \"spu_wrch_clobber\"\n+   [(unspec_volatile [(match_operand:SI 0 \"immediate_operand\" \"J\")\n+ \t              (match_operand:V4SI 1 \"spu_reg_operand\" \"r\")] UNSPEC_WRCH)\n+    (clobber (mem:BLK (scratch)))]\n+   \"\"\n+   \"wrch\\t$ch%0,%1\"\n+   [(set_attr \"type\" \"spr\")])\n+\n+(define_expand \"spu_splats\" \n+  [(set (match_operand 0 \"spu_reg_operand\" \"\")\n+        (vec_duplicate (match_operand 1 \"spu_nonmem_operand\" \"\")))]\n+  \"\"\n+  {\n+    spu_builtin_splats(operands);\n+    DONE;\n+  })\n+\n+(define_expand \"spu_extract\"\n+  [(set (match_operand 0 \"spu_reg_operand\" \"\")\n+\t(unspec [(match_operand 1 \"spu_reg_operand\" \"\")\n+\t\t (match_operand 2 \"spu_nonmem_operand\" \"\")] 0))]\n+  \"\"\n+  {\n+    spu_builtin_extract (operands);\n+    DONE;\n+  })\n+\n+(define_expand \"spu_insert\"\n+  [(set (match_operand 0 \"spu_reg_operand\" \"\")\n+        (unspec [(match_operand 1 \"spu_reg_operand\" \"\")\n+                 (match_operand 2 \"spu_reg_operand\" \"\")\n+                 (match_operand:SI 3 \"spu_nonmem_operand\" \"\")] 0))] \n+  \"\"\n+  {\n+    spu_builtin_insert(operands);\n+    DONE;\n+  })\n+\n+(define_expand \"spu_promote\"\n+  [(set (match_operand 0 \"spu_reg_operand\" \"\")\n+        (unspec [(match_operand 1 \"spu_reg_operand\" \"\")\n+                 (match_operand:SI 2 \"immediate_operand\" \"\")] 0))] \n+  \"\"\n+  {\n+    spu_builtin_promote(operands);\n+    DONE;\n+  })\n+\n+;; Currently doing nothing with this but expanding its args.\n+(define_expand \"spu_align_hint\"\n+  [(unspec [(match_operand:SI 0 \"address_operand\" \"\")\n+            (match_operand:SI 1 \"immediate_operand\" \"\")\n+            (match_operand:SI 2 \"immediate_operand\" \"\")] 0)]\n+  \"\"\n+  {\n+     DONE;\n+  })\n+"}, {"sha": "80a570195efe14b2edbdabdaaa59fed941dcd534", "filename": "gcc/config/spu/spu-c.c", "status": "added", "additions": 443, "deletions": 0, "changes": 443, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu-c.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu-c.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu-c.c?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,443 @@\n+/* Copyright (C) 2006 Free Software Foundation, Inc.\n+\n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option) \n+   any later version.\n+\n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+#include \"config.h\"\n+#include \"system.h\"\n+#include \"coretypes.h\"\n+#include \"tm.h\"\n+#include \"cpplib.h\"\n+#include \"tree.h\"\n+#include \"c-tree.h\"\n+#include \"c-pragma.h\"\n+#include \"function.h\"\n+#include \"rtl.h\"\n+#include \"expr.h\"\n+#include \"errors.h\"\n+#include \"tm_p.h\"\n+#include \"langhooks.h\"\n+#include \"insn-config.h\"\n+#include \"insn-codes.h\"\n+#include \"recog.h\"\n+#include \"optabs.h\"\n+#include \"spu-builtins.h\"\n+\n+static rtx spu_expand_builtin_1 (struct spu_builtin_description *d,\n+\t\t\t\t tree arglist, rtx target);\n+static void spu_check_builtin_parm (struct spu_builtin_description *, rtx,\n+\t\t\t\t    int);\n+static void expand_builtin_args (struct spu_builtin_description *, tree, rtx,\n+\t\t\t\t rtx[]);\n+static rtx spu_force_reg (enum machine_mode mode, rtx op);\n+\n+/* Builtin types, data and prototypes. */\n+struct spu_builtin_range\n+{\n+  int low, high;\n+};\n+\n+static struct spu_builtin_range spu_builtin_range[] = {\n+  {-0x40ll, 0x7fll},\t\t/* SPU_BTI_7     */\n+  {-0x40ll, 0x3fll},\t\t/* SPU_BTI_S7    */\n+  {0ll, 0x7fll},\t\t/* SPU_BTI_U7    */\n+  {-0x200ll, 0x1ffll},\t\t/* SPU_BTI_S10   */\n+  {-0x2000ll, 0x1fffll},\t/* SPU_BTI_S10_4 */\n+  {0ll, 0x3fffll},\t\t/* SPU_BTI_U14   */\n+  {-0x8000ll, 0xffffll},\t/* SPU_BTI_16    */\n+  {-0x8000ll, 0x7fffll},\t/* SPU_BTI_S16   */\n+  {-0x20000ll, 0x1ffffll},\t/* SPU_BTI_S16_2 */\n+  {0ll, 0xffffll},\t\t/* SPU_BTI_U16   */\n+  {0ll, 0x3ffffll},\t\t/* SPU_BTI_U16_2 */\n+  {0ll, 0x3ffffll},\t\t/* SPU_BTI_U18   */\n+};\n+\f\n+\n+/* Helper for spu_resolve_overloaded_builtin.  */\n+static tree\n+spu_build_overload_builtin (tree fndecl, tree fnargs)\n+{\n+  tree param, param_type;\n+  tree ret_type = TREE_TYPE (TREE_TYPE (fndecl));\n+  tree arg, arglist = NULL_TREE;\n+  tree val;\n+\n+  for (param = TYPE_ARG_TYPES (TREE_TYPE (fndecl)), arg = fnargs;\n+       param != void_list_node;\n+       param = TREE_CHAIN (param), arg = TREE_CHAIN (arg))\n+    {\n+      gcc_assert (arg != NULL_TREE);\n+      param_type = TREE_VALUE (param);\n+      val = default_conversion (TREE_VALUE (arg));\n+      val = fold_convert (param_type, val);\n+\n+      arglist = tree_cons (NULL_TREE, val, arglist);\n+    }\n+  gcc_assert (arg == NULL_TREE);\n+  arglist = nreverse (arglist);\n+\n+  return fold_convert (ret_type, build_function_call_expr (fndecl, arglist));\n+}\n+\n+/* target hook for resolve_overloaded_builtin(). Returns a function call\n+   RTX if we can resolve the overloaded builtin */\n+tree\n+spu_resolve_overloaded_builtin (tree fndecl, tree fnargs)\n+{\n+  spu_function_code new_fcode, fcode =\n+    DECL_FUNCTION_CODE (fndecl) - END_BUILTINS;\n+  struct spu_builtin_description *desc;\n+  tree match = NULL_TREE;\n+\n+  /* The vector types are not available if the backend is not initalized */\n+  gcc_assert (!flag_preprocess_only);\n+\n+  desc = &spu_builtins[fcode];\n+  if (desc->type != B_OVERLOAD)\n+    return NULL_TREE;\n+\n+  /* Compare the signature of each internal builtin function with the\n+     function arguments until a match is found. */\n+\n+  for (new_fcode = fcode + 1; spu_builtins[new_fcode].type == B_INTERNAL;\n+       new_fcode++)\n+    {\n+      tree decl = spu_builtins[new_fcode].fndecl;\n+      tree params = TYPE_ARG_TYPES (TREE_TYPE (decl));\n+      tree arg, param;\n+      int p;\n+\n+      for (param = params, arg = fnargs, p = 0;\n+\t   param != void_list_node;\n+\t   param = TREE_CHAIN (param), arg = TREE_CHAIN (arg), p++)\n+\t{\n+\t  tree var, arg_type, param_type = TREE_VALUE (param);\n+\n+\t  if (!arg)\n+\t    {\n+\t      error (\"insufficient arguments to overloaded function %s\",\n+\t\t     desc->name);\n+\t      return error_mark_node;\n+\t    }\n+\n+\t  var = TREE_VALUE (arg);\n+\n+\t  if (TREE_CODE (var) == NON_LVALUE_EXPR)\n+\t    var = TREE_OPERAND (var, 0);\n+\n+\t  if (TREE_CODE (var) == ERROR_MARK)\n+\t    return NULL_TREE;\t/* Let somebody else deal with the problem. */\n+\n+\t  arg_type = TREE_TYPE (var);\n+\n+\t  /* The intrinsics spec does not specify precisely how to\n+\t     resolve generic intrinsics.  We require an exact match\n+\t     for vector types and let C do it's usual parameter type\n+\t     checking/promotions for scalar arguments, except for the\n+\t     first argument of intrinsics which don't have a vector\n+\t     parameter. */\n+\t  if ((TREE_CODE (param_type) == VECTOR_TYPE\n+\t       || ((fcode == SPU_SPLATS || fcode == SPU_PROMOTE\n+\t\t    || fcode == SPU_HCMPEQ || fcode == SPU_HCMPGT\n+\t\t    || fcode == SPU_MASKB || fcode == SPU_MASKH\n+\t\t    || fcode == SPU_MASKW) && p == 0))\n+\t      && !comptypes (TYPE_MAIN_VARIANT (param_type),\n+\t\t\t     TYPE_MAIN_VARIANT (arg_type)))\n+\t    break;\n+\t}\n+      if (param == void_list_node)\n+\t{\n+\t  if (arg)\n+\t    {\n+\t      error (\"too many arguments to overloaded function %s\",\n+\t\t     desc->name);\n+\t      return error_mark_node;\n+\t    }\n+\n+\t  match = decl;\n+\t  break;\n+\t}\n+    }\n+\n+  if (match == NULL_TREE)\n+    {\n+      error (\"parameter list does not match a valid signature for %s()\",\n+\t     desc->name);\n+      return error_mark_node;\n+    }\n+\n+  return spu_build_overload_builtin (match, fnargs);\n+}\n+\n+static void\n+spu_check_builtin_parm (struct spu_builtin_description *d, rtx op, int p)\n+{\n+  HOST_WIDE_INT v = 0;\n+  int lsbits;\n+  /* Check the range of immediate operands. */\n+  if (p >= SPU_BTI_7 && p <= SPU_BTI_U18)\n+    {\n+      int range = p - SPU_BTI_7;\n+      if (!CONSTANT_P (op)\n+\t  || (GET_CODE (op) == CONST_INT\n+\t      && (INTVAL (op) < spu_builtin_range[range].low\n+\t\t  || INTVAL (op) > spu_builtin_range[range].high)))\n+\terror (\"%s expects an integer literal in the range [%d, %d].\",\n+\t       d->name,\n+\t       spu_builtin_range[range].low, spu_builtin_range[range].high);\n+\n+      if (GET_CODE (op) == CONST\n+\t  && (GET_CODE (XEXP (op, 0)) == PLUS\n+\t      || GET_CODE (XEXP (op, 0)) == MINUS))\n+\t{\n+\t  v = INTVAL (XEXP (XEXP (op, 0), 1));\n+\t  op = XEXP (XEXP (op, 0), 0);\n+\t}\n+      else if (GET_CODE (op) == CONST_INT)\n+\tv = INTVAL (op);\n+\n+      switch (p)\n+\t{\n+\tcase SPU_BTI_S10_4:\n+\t  lsbits = 4;\n+\t  break;\n+\tcase SPU_BTI_U16_2:\n+\t  /* This is only used in lqa, and stqa.  Even though the insns\n+\t     encode 16 bits of the address (all but the 2 least\n+\t     significant), only 14 bits are used because it is masked to\n+\t     be 16 byte aligned. */\n+\t  lsbits = 4;\n+\t  break;\n+\tcase SPU_BTI_S16_2:\n+\t  /* This is used for lqr and stqr. */\n+\t  lsbits = 2;\n+\t  break;\n+\tdefault:\n+\t  lsbits = 0;\n+\t}\n+\n+      if (GET_CODE (op) == LABEL_REF\n+\t  || (GET_CODE (op) == SYMBOL_REF\n+\t      && SYMBOL_REF_FUNCTION_P (op))\n+\t  || (INTVAL (op) & ((1 << lsbits) - 1)) != 0)\n+\twarning (0, \"%d least significant bits of %s are ignored.\", lsbits,\n+\t\t d->name);\n+    }\n+}\n+\n+static void\n+expand_builtin_args (struct spu_builtin_description *d, tree arglist,\n+\t\t     rtx target, rtx ops[])\n+{\n+  enum insn_code icode = d->icode;\n+  int i = 0;\n+\n+  /* Expand the arguments into rtl. */\n+\n+  if (d->parm[0] != SPU_BTI_VOID)\n+    ops[i++] = target;\n+\n+  for (; i < insn_data[icode].n_operands; i++)\n+    {\n+      tree arg = TREE_VALUE (arglist);\n+      if (arg == 0)\n+\tabort ();\n+      ops[i] = expand_expr (arg, NULL_RTX, VOIDmode, 0);\n+      arglist = TREE_CHAIN (arglist);\n+    }\n+}\n+\n+static rtx\n+spu_expand_builtin_1 (struct spu_builtin_description *d,\n+\t\t      tree arglist, rtx target)\n+{\n+  rtx pat;\n+  rtx ops[8];\n+  enum insn_code icode = d->icode;\n+  enum machine_mode mode, tmode;\n+  int i, p;\n+  tree return_type;\n+\n+  /* Set up ops[] with values from arglist. */\n+  expand_builtin_args (d, arglist, target, ops);\n+\n+  /* Handle the target operand which must be operand 0. */\n+  i = 0;\n+  if (d->parm[0] != SPU_BTI_VOID)\n+    {\n+\n+      /* We prefer the mode specified for the match_operand otherwise\n+         use the mode from the builtin function prototype. */\n+      tmode = insn_data[d->icode].operand[0].mode;\n+      if (tmode == VOIDmode)\n+\ttmode = TYPE_MODE (spu_builtin_types[d->parm[0]]);\n+\n+      /* Try to use target because not using it can lead to extra copies\n+         and when we are using all of the registers extra copies leads\n+         to extra spills.  */\n+      if (target && GET_CODE (target) == REG && GET_MODE (target) == tmode)\n+\tops[0] = target;\n+      else\n+\ttarget = ops[0] = gen_reg_rtx (tmode);\n+\n+      if (!(*insn_data[icode].operand[0].predicate) (ops[0], tmode))\n+\tabort ();\n+\n+      i++;\n+    }\n+\n+  /* Ignore align_hint, but still expand it's args in case they have\n+     side effects. */\n+  if (icode == CODE_FOR_spu_align_hint)\n+    return 0;\n+\n+  /* Handle the rest of the operands. */\n+  for (p = 1; i < insn_data[icode].n_operands; i++, p++)\n+    {\n+      if (insn_data[d->icode].operand[i].mode != VOIDmode)\n+\tmode = insn_data[d->icode].operand[i].mode;\n+      else\n+\tmode = TYPE_MODE (spu_builtin_types[d->parm[i]]);\n+\n+      /* mode can be VOIDmode here for labels */\n+\n+      /* For specific intrinsics with an immediate operand, e.g.,\n+         si_ai(), we sometimes need to convert the scalar argument to a\n+         vector argument by splatting the scalar. */\n+      if (VECTOR_MODE_P (mode)\n+\t  && (GET_CODE (ops[i]) == CONST_INT\n+\t      || GET_MODE_CLASS (GET_MODE (ops[i])) == MODE_INT\n+\t      || GET_MODE_CLASS (GET_MODE (ops[i])) == MODE_FLOAT))\n+\t{\n+\t  if (GET_CODE (ops[i]) == CONST_INT)\n+\t    ops[i] = spu_const (mode, INTVAL (ops[i]));\n+\t  else\n+\t    {\n+\t      rtx reg = gen_reg_rtx (mode);\n+\t      enum machine_mode imode = GET_MODE_INNER (mode);\n+\t      if (!spu_nonmem_operand (ops[i], GET_MODE (ops[i])))\n+\t\tops[i] = force_reg (GET_MODE (ops[i]), ops[i]);\n+\t      if (imode != GET_MODE (ops[i]))\n+\t\tops[i] = convert_to_mode (imode, ops[i],\n+\t\t\t\t\t  TYPE_UNSIGNED (spu_builtin_types\n+\t\t\t\t\t\t\t [d->parm[i]]));\n+\t      emit_insn (gen_spu_splats (reg, ops[i]));\n+\t      ops[i] = reg;\n+\t    }\n+\t}\n+\n+      if (!(*insn_data[icode].operand[i].predicate) (ops[i], mode))\n+\tops[i] = spu_force_reg (mode, ops[i]);\n+\n+      spu_check_builtin_parm (d, ops[i], d->parm[p]);\n+    }\n+\n+  switch (insn_data[icode].n_operands)\n+    {\n+    case 0:\n+      pat = GEN_FCN (icode) (0);\n+      break;\n+    case 1:\n+      pat = GEN_FCN (icode) (ops[0]);\n+      break;\n+    case 2:\n+      pat = GEN_FCN (icode) (ops[0], ops[1]);\n+      break;\n+    case 3:\n+      pat = GEN_FCN (icode) (ops[0], ops[1], ops[2]);\n+      break;\n+    case 4:\n+      pat = GEN_FCN (icode) (ops[0], ops[1], ops[2], ops[3]);\n+      break;\n+    case 5:\n+      pat = GEN_FCN (icode) (ops[0], ops[1], ops[2], ops[3], ops[4]);\n+      break;\n+    case 6:\n+      pat = GEN_FCN (icode) (ops[0], ops[1], ops[2], ops[3], ops[4], ops[5]);\n+      break;\n+    default:\n+      abort ();\n+    }\n+\n+  if (!pat)\n+    abort ();\n+\n+  if (d->type == B_CALL || d->type == B_BISLED)\n+    emit_call_insn (pat);\n+  else if (d->type == B_JUMP)\n+    {\n+      emit_jump_insn (pat);\n+      emit_barrier ();\n+    }\n+  else\n+    emit_insn (pat);\n+\n+  return_type = spu_builtin_types[d->parm[0]];\n+  if (d->parm[0] != SPU_BTI_VOID\n+      && GET_MODE (target) != TYPE_MODE (return_type))\n+    {\n+      /* target is the return value.  It should always be the mode of\n+         the builtin function prototype. */\n+      target = spu_force_reg (TYPE_MODE (return_type), target);\n+    }\n+\n+  return target;\n+}\n+\n+rtx\n+spu_expand_builtin (tree exp,\n+\t\t    rtx target,\n+\t\t    rtx subtarget ATTRIBUTE_UNUSED,\n+\t\t    enum machine_mode mode ATTRIBUTE_UNUSED,\n+\t\t    int ignore ATTRIBUTE_UNUSED)\n+{\n+  tree fndecl = TREE_OPERAND (TREE_OPERAND (exp, 0), 0);\n+  unsigned int fcode = DECL_FUNCTION_CODE (fndecl) - END_BUILTINS;\n+  tree arglist = TREE_OPERAND (exp, 1);\n+  struct spu_builtin_description *d;\n+\n+  if (fcode < NUM_SPU_BUILTINS)\n+    {\n+      d = &spu_builtins[fcode];\n+\n+      return spu_expand_builtin_1 (d, arglist, target);\n+    }\n+  abort ();\n+}\n+\n+static rtx\n+spu_force_reg (enum machine_mode mode, rtx op)\n+{\n+  rtx x, r;\n+  if (GET_MODE (op) == VOIDmode || GET_MODE (op) == BLKmode)\n+    {\n+      if ((SCALAR_INT_MODE_P (mode) && GET_CODE (op) == CONST_INT)\n+\t  || GET_MODE (op) == BLKmode)\n+\treturn force_reg (mode, convert_to_mode (mode, op, 0));\n+      abort ();\n+    }\n+\n+  r = force_reg (GET_MODE (op), op);\n+  if (GET_MODE_SIZE (GET_MODE (op)) == GET_MODE_SIZE (mode))\n+    {\n+      x = simplify_gen_subreg (mode, r, GET_MODE (op), 0);\n+      if (x)\n+\treturn x;\n+    }\n+\n+  x = gen_reg_rtx (mode);\n+  emit_insn (gen_spu_convert (x, r));\n+  return x;\n+}"}, {"sha": "f20a701e5d51609645b018a4e7b8d3d240d70f81", "filename": "gcc/config/spu/spu-elf.h", "status": "added", "additions": 54, "deletions": 0, "changes": 54, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu-elf.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu-elf.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu-elf.h?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,54 @@\n+/* Copyright (C) 2006 Free Software Foundation, Inc.\n+\n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option) \n+   any later version.\n+\n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+#ifndef OBJECT_FORMAT_ELF\n+ #error elf.h included before elfos.h\n+#endif\n+\n+#define BSS_SECTION_ASM_OP \"\\t.section .bss\"\n+\n+#define ASM_OUTPUT_ALIGNED_BSS(FILE, DECL, NAME, SIZE, ALIGN) \\\n+            asm_output_aligned_bss (FILE, DECL, NAME, SIZE, ALIGN)\n+\n+\n+#undef  STARTFILE_SPEC\n+#define STARTFILE_SPEC\t\"crt1%O%s\"\n+\n+#undef  ENDFILE_SPEC\n+#define ENDFILE_SPEC\t\"crtend1%O%s\"\n+\n+#define PREFERRED_DEBUGGING_TYPE DWARF2_DEBUG\n+\n+#define DWARF2_DEBUGGING_INFO 1\n+#define DWARF2_ASM_LINE_DEBUG_INFO 1\n+\n+#define SET_ASM_OP\t\t\"\\t.set\\t\"\n+\n+#undef TARGET_ASM_NAMED_SECTION\n+#define TARGET_ASM_NAMED_SECTION  default_elf_asm_named_section\n+\n+#define EH_FRAME_IN_DATA_SECTION 1\n+\n+#define LINK_SPEC \"%{mlarge-mem: --defsym __stack=0xfffffff0 }\"\n+\n+#define LIB_SPEC \\\n+\t\"-( %{!shared:%{g*:-lg} %{!p:%{!pg:-lc}}%{p:-lc_p}%{pg:-lc_p}} -lgloss -)\"\n+\n+/* Turn off warnings in the assembler too. */\n+#undef ASM_SPEC\n+#define ASM_SPEC  \"%{w:-W}\"\n+"}, {"sha": "a3397c5a18ff71a7e0c32554cd4034c2857f5d23", "filename": "gcc/config/spu/spu-modes.def", "status": "added", "additions": 34, "deletions": 0, "changes": 34, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu-modes.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu-modes.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu-modes.def?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,34 @@\n+/* Copyright (C) 2006 Free Software Foundation, Inc.\n+\n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option) \n+   any later version.\n+\n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+/* Vector modes.  */\n+VECTOR_MODES (INT, 2);        /*                 V2QI */ \n+VECTOR_MODES (INT, 4);        /*            V4QI V2HI */\n+VECTOR_MODES (INT, 8);        /*       V8QI V4HI V2SI */\n+VECTOR_MODES (INT, 16);       /* V16QI V8HI V4SI V2DI */\n+        \n+        \n+VECTOR_MODES (FLOAT, 8);      /*            V4HF V2SF */ \n+VECTOR_MODES (FLOAT, 16);     /*       V8HF V4SF V2DF */ \n+        \n+/* A special mode for the intr regsister so we can treat it differently\n+   for conditional moves. */\n+RANDOM_MODE (INTR);\n+\n+/* cse_insn needs an INT_MODE larger than WORD_MODE, otherwise some\n+   parts of it will go into an infinite loop. */\n+INT_MODE (OI, 32);"}, {"sha": "a42210dbc3ca69cc49ffa1348b3d792cd183d758", "filename": "gcc/config/spu/spu-protos.h", "status": "added", "additions": 93, "deletions": 0, "changes": 93, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu-protos.h?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,93 @@\n+/* Copyright (C) 2006 Free Software Foundation, Inc.\n+\n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option) \n+   any later version.\n+\n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+#ifndef _SPU_PROTOS_\n+#define _SPU_PROTOS_\n+\n+#include \"rtl.h\"\n+\n+extern enum machine_mode spu_eh_return_filter_mode (void);\n+extern void spu_cpu_cpp_builtins (struct cpp_reader * pfile);\n+extern void builtin_define_std (const char *);\n+extern void spu_override_options (void);\n+extern int valid_subreg (rtx op);\n+extern void spu_expand_extv (rtx * ops, int unsignedp);\n+extern void spu_expand_insv (rtx * ops);\n+extern int spu_expand_block_move (rtx * ops);\n+extern void spu_emit_branch_or_set (int is_set, enum rtx_code code,\n+\t\t\t\t    rtx * operands);\n+extern HOST_WIDE_INT const_double_to_hwint (rtx x);\n+extern rtx hwint_to_const_double (enum machine_mode mode, HOST_WIDE_INT v);\n+extern void print_operand_address (FILE * file, register rtx addr);\n+extern void print_operand (FILE * file, rtx x, int code);\n+extern int spu_saved_regs_size (void);\n+extern int direct_return (void);\n+extern void spu_expand_prologue (void);\n+extern void spu_expand_epilogue (unsigned char sibcall_p);\n+extern rtx spu_return_addr (int count, rtx frame);\n+extern rtx spu_const (enum machine_mode mode, HOST_WIDE_INT val);\n+extern struct rtx_def *spu_float_const (const char *string,\n+\t\t\t\t\tenum machine_mode mode);\n+extern int immediate_load_p (rtx op, enum machine_mode mode);\n+extern int logical_immediate_p (rtx op, enum machine_mode mode);\n+extern int iohl_immediate_p (rtx op, enum machine_mode mode);\n+extern int arith_immediate_p (rtx op, enum machine_mode mode,\n+\t\t\t      HOST_WIDE_INT low, HOST_WIDE_INT high);\n+extern int legitimate_const (rtx x, int aligned);\n+extern int spu_constant_address_p (rtx x);\n+extern int spu_legitimate_constant_p (rtx x);\n+extern int spu_legitimate_address (enum machine_mode mode, rtx x,\n+\t\t\t\t   int reg_ok_strict);\n+extern rtx spu_legitimize_address (rtx x, rtx oldx, enum machine_mode mode);\n+extern int spu_initial_elimination_offset (int from, int to);\n+extern rtx spu_function_value (tree type, tree func);\n+extern rtx spu_function_arg (int cum, enum machine_mode mode, tree type,\n+\t\t\t     int named);\n+extern void spu_va_start (tree valist, rtx nextarg);\n+extern void spu_setup_incoming_varargs (int *cum, enum machine_mode mode,\n+\t\t\t\t\ttree type, int *pretend_size,\n+\t\t\t\t\tint no_rtl);\n+extern void spu_conditional_register_usage (void);\n+extern int aligned_mem_p (rtx mem);\n+extern int spu_expand_mov (rtx * ops, enum machine_mode mode);\n+extern void spu_split_load (rtx * ops);\n+extern void spu_split_store (rtx * ops);\n+extern int spu_valid_move (rtx * ops);\n+extern int fsmbi_const_p (rtx x);\n+extern void constant_to_array (enum machine_mode mode, rtx x,\n+\t\t\t       unsigned char *arr);\n+extern rtx array_to_constant (enum machine_mode mode, unsigned char *arr);\n+extern enum machine_mode spu_eh_return_filter_mode (void);\n+extern void spu_allocate_stack (rtx op0, rtx op1);\n+extern void spu_restore_stack_nonlocal (rtx op0, rtx op1);\n+extern rtx spu_gen_subreg (enum machine_mode mode, rtx x);\n+extern int spu_safe_dma(HOST_WIDE_INT channel);\n+extern void spu_builtin_splats (rtx ops[]);\n+extern void spu_builtin_extract (rtx ops[]);\n+extern void spu_builtin_insert (rtx ops[]);\n+extern void spu_builtin_promote (rtx ops[]);\n+extern void spu_initialize_trampoline (rtx tramp, rtx fnaddr, rtx cxt);\n+extern void spu_expand_sign_extend (rtx ops[]);\n+extern void spu_expand_vector_init (rtx target, rtx vals);\n+\n+/* spu-c.c */\n+extern tree spu_resolve_overloaded_builtin (tree fndecl, tree fnargs);\n+extern rtx spu_expand_builtin (tree exp, rtx target, rtx subtarget,\n+\t\t\t       enum machine_mode mode, int ignore);\n+extern rtx spu_expand_builtin (tree, rtx, rtx, enum machine_mode, int);\n+\n+#endif"}, {"sha": "99a0ac86e58f73b659b8bd9d6b35c74057886bd4", "filename": "gcc/config/spu/spu.c", "status": "added", "additions": 4469, "deletions": 0, "changes": 4469, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu.c?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d"}, {"sha": "a9714cba8c1e1467d21ffb4320382cb06cd715a6", "filename": "gcc/config/spu/spu.h", "status": "added", "additions": 550, "deletions": 0, "changes": 550, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu.h?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,550 @@\n+/* Copyright (C) 2006 Free Software Foundation, Inc.\n+\n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option) \n+   any later version.\n+\n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+\f\n+/* Run-time Target */\n+#define TARGET_CPU_CPP_BUILTINS()\tspu_cpu_cpp_builtins(pfile)\n+\n+#define TARGET_VERSION fprintf (stderr, \" (spu %s)\", __DATE__);\n+\n+#define OVERRIDE_OPTIONS spu_override_options()\n+\n+extern int target_flags;\n+\n+/* Default target_flags if no switches specified.  */\n+#ifndef TARGET_DEFAULT\n+#define TARGET_DEFAULT (MASK_ERROR_RELOC | MASK_SAFE_DMA | MASK_BRANCH_HINTS)\n+#endif\n+\n+\f\n+/* Storage Layout */\n+\n+#define BITS_BIG_ENDIAN 1\n+\n+#define BYTES_BIG_ENDIAN 1\n+\n+#define WORDS_BIG_ENDIAN 1\n+\n+#define BITS_PER_UNIT 8\n+\n+/* GCC uses word_mode in many places, assuming that it is the fastest\n+   integer mode.  That is not the case for SPU though.  We can't use\n+   32 here because (of some reason I can't remember.) */\n+#define BITS_PER_WORD 128\n+\n+#define UNITS_PER_WORD (BITS_PER_WORD/BITS_PER_UNIT)\n+\n+/* We never actually change UNITS_PER_WORD, but defining this causes\n+   libgcc to use some different sizes of types when compiling. */\n+#define MIN_UNITS_PER_WORD 4\n+\n+#define POINTER_SIZE 32\n+\n+#define PARM_BOUNDARY 128\n+\n+#define STACK_BOUNDARY 128\n+\n+/* We want it 8-byte aligned so we can properly use dual-issue\n+   instructions, which can only happen on an 8-byte aligned address. */\n+#define FUNCTION_BOUNDARY 64\n+\n+/* We would like to allow a larger alignment for data objects (for DMA)\n+   but the aligned attribute is limited by BIGGEST_ALIGNMENT.  We don't\n+   define BIGGEST_ALIGNMENT as larger because it is used in other places\n+   and would end up wasting space.  (Is this still true?)  */\n+#define BIGGEST_ALIGNMENT 128\n+\n+#define MINIMUM_ATOMIC_ALIGNMENT 128\n+\n+/* Make all static objects 16-byte aligned.  This allows us to assume\n+   they are also padded to 16-bytes, which means we can use a single\n+   load or store instruction to access them.  Do the same for objects\n+   on the stack.  (Except a bug (?) allows some stack objects to be\n+   unaligned.)  */\n+#define DATA_ALIGNMENT(TYPE,ALIGN) ((ALIGN) > 128 ? (ALIGN) : 128)\n+#define CONSTANT_ALIGNMENT(TYPE,ALIGN) ((ALIGN) > 128 ? (ALIGN) : 128)\n+#define LOCAL_ALIGNMENT(TYPE,ALIGN) ((ALIGN) > 128 ? (ALIGN) : 128)\n+\n+#define EMPTY_FIELD_BOUNDARY 32\n+\n+#define STRICT_ALIGNMENT 1\n+\n+/* symbol_ref's of functions are not aligned to 16 byte boundary. */\n+#define ALIGNED_SYMBOL_REF_P(X) \\\n+\t(GET_CODE (X) == SYMBOL_REF \\\n+\t  && (! SYMBOL_REF_FUNCTION_P (X) \\\n+\t      || align_functions >= 16))\n+\n+#define PCC_BITFIELD_TYPE_MATTERS 1\n+\n+#define MAX_FIXED_MODE_SIZE 128\n+\n+#define STACK_SAVEAREA_MODE(save_level) SImode\n+\n+#define STACK_SIZE_MODE SImode\n+\n+/* #define TARGET_FLOAT_FORMAT     \tSPU_FLOAT_FORMAT */\n+\n+#ifndef MODE_HAS_NANS\n+#define MODE_HAS_NANS(MODE)                                     \\\n+  (FLOAT_MODE_P (MODE) \t\t\t\t\t\t\\\n+   && MODE != SFmode\t\t\t\t\t\t\\\n+   && !LARGEST_EXPONENT_IS_NORMAL (GET_MODE_BITSIZE (MODE)))\n+#endif\n+                                                                              \n+#ifndef MODE_HAS_INFINITIES\n+#define MODE_HAS_INFINITIES(MODE)                               \\\n+  (FLOAT_MODE_P (MODE) \t\t\t\t\t\t\\\n+   && MODE != SFmode                                            \\\n+   && !LARGEST_EXPONENT_IS_NORMAL (GET_MODE_BITSIZE (MODE)))\n+#endif\n+                                                                              \n+#ifndef MODE_HAS_SIGN_DEPENDENT_ROUNDING\n+#define MODE_HAS_SIGN_DEPENDENT_ROUNDING(MODE)                  \\\n+  (FLOAT_MODE_P (MODE)                                          \\\n+    && MODE != SFmode                                           \\\n+   && !ROUND_TOWARDS_ZERO)\n+#endif\n+\n+#define ROUND_TOWARDS_ZERO 1\n+\n+/* This is certainly true.  Should it be defined?  (It wasn't before.) */\n+/* #define LARGEST_EXPONENT_IS_NORMAL(size) (size != 32) */\n+\n+\f\n+/* Type Layout */\n+\n+#define INT_TYPE_SIZE 32\n+\n+#define LONG_TYPE_SIZE 32\n+\n+#define LONG_LONG_TYPE_SIZE 64\n+\n+#define FLOAT_TYPE_SIZE 32\n+\n+#define DOUBLE_TYPE_SIZE 64\n+\n+#define LONG_DOUBLE_TYPE_SIZE 64\n+\n+#define DEFAULT_SIGNED_CHAR 0\n+\n+\f\n+/* Register Basics */\n+\n+/* 128-130 are special registers that never appear in assembly code. */\n+#define FIRST_PSEUDO_REGISTER 132\n+\n+#define FIXED_REGISTERS {\t\t\t    \\\n+    1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n+    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n+    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n+    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n+    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n+    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n+    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n+    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n+    1, 1, 1, 1 \\\n+}\n+\n+#define CALL_USED_REGISTERS {\t\t\t    \\\n+    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \\\n+    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \\\n+    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \\\n+    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \\\n+    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \\\n+    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n+    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n+    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n+    1, 1, 1, 1 \\\n+}\n+\n+#define CONDITIONAL_REGISTER_USAGE \\\n+\tspu_conditional_register_usage()\n+\n+\f\n+/* Values in Registers */\n+\n+#define HARD_REGNO_NREGS(REGNO, MODE)   \\\n+    ((GET_MODE_BITSIZE(MODE)+MAX_FIXED_MODE_SIZE-1)/MAX_FIXED_MODE_SIZE)\n+\n+#define HARD_REGNO_MODE_OK(REGNO, MODE) 1\n+\n+#define MODES_TIEABLE_P(MODE1, MODE2) \\\n+  (GET_MODE_BITSIZE (MODE1) <= MAX_FIXED_MODE_SIZE \\\n+   && GET_MODE_BITSIZE (MODE2) <= MAX_FIXED_MODE_SIZE)\n+\n+\f\n+/* Register Classes */\n+\n+enum reg_class { \n+   NO_REGS, \n+   GENERAL_REGS,\n+   ALL_REGS,\n+   LIM_REG_CLASSES \n+};\n+\n+#define N_REG_CLASSES (int) LIM_REG_CLASSES\n+\n+#define REG_CLASS_NAMES \\\n+{  \"NO_REGS\", \\\n+   \"GENERAL_REGS\", \\\n+   \"ALL_REGS\" \\\n+}\n+\n+#define REG_CLASS_CONTENTS { \\\n+    {0, 0, 0, 0, 0}, /* no regs */ \\\n+    {0xffffffff, 0xffffffff, 0xffffffff, 0xffffffff, 0x3}, /* general regs */ \\\n+    {0xffffffff, 0xffffffff, 0xffffffff, 0xffffffff, 0x3}} /* all regs */\n+\n+#define REGNO_REG_CLASS(REGNO) (GENERAL_REGS)\n+\n+#define BASE_REG_CLASS GENERAL_REGS\n+\n+#define INDEX_REG_CLASS GENERAL_REGS\n+\n+#define REGNO_OK_FOR_BASE_P(regno) \\\n+   ((regno) < FIRST_PSEUDO_REGISTER || (regno > LAST_VIRTUAL_REGISTER && reg_renumber[regno] >= 0))\n+\n+#define REGNO_OK_FOR_INDEX_P(regno)  \\\n+   ((regno) < FIRST_PSEUDO_REGISTER || (regno > LAST_VIRTUAL_REGISTER && reg_renumber[regno] >= 0))\n+\n+#define INT_REG_OK_FOR_INDEX_P(X,STRICT) \\\n+\t((!(STRICT) || REGNO_OK_FOR_INDEX_P (REGNO (X))))\n+#define INT_REG_OK_FOR_BASE_P(X,STRICT) \\\n+\t((!(STRICT) || REGNO_OK_FOR_BASE_P (REGNO (X))))\n+\n+#define PREFERRED_RELOAD_CLASS(X,CLASS)  (CLASS)\n+\n+#define CLASS_MAX_NREGS(CLASS, MODE)\t\\\n+\t((GET_MODE_SIZE (MODE) + UNITS_PER_WORD - 1) / UNITS_PER_WORD)\n+\n+/* GCC assumes that modes are in the lowpart of a register, which is\n+   only true for SPU. */\n+#define CANNOT_CHANGE_MODE_CLASS(FROM, TO, CLASS) \\\n+        ((GET_MODE_SIZE (FROM) > 4 || GET_MODE_SIZE (TO) > 4) \\\n+\t && GET_MODE_SIZE (FROM) != GET_MODE_SIZE (TO))\n+\n+\f\n+/* Frame Layout */\n+\n+#define STACK_GROWS_DOWNWARD\n+\n+#define STARTING_FRAME_OFFSET (0)\n+\n+#define STACK_POINTER_OFFSET 32\n+\n+#define FIRST_PARM_OFFSET(FNDECL) (0)\n+\n+#define DYNAMIC_CHAIN_ADDRESS(FP) plus_constant ((FP), -16)\n+\n+#define RETURN_ADDR_RTX(COUNT,FP) (spu_return_addr (COUNT, FP))\n+\n+/* Should this be defined?  Would it simplify our implementation. */\n+/* #define RETURN_ADDR_IN_PREVIOUS_FRAME */\n+\n+#define INCOMING_RETURN_ADDR_RTX gen_rtx_REG(Pmode, LINK_REGISTER_REGNUM)\n+\n+\f\n+/* Stack Checking */\n+\n+/* We store the Available Stack Size in the second slot of the stack\n+   register.   We emit stack checking code during the prologue.  */\n+#define STACK_CHECK_BUILTIN 1\n+\n+\f\n+/* Frame Registers, and other registers */\n+\n+#define STACK_POINTER_REGNUM 1\n+\n+/* Will be eliminated. */\n+#define FRAME_POINTER_REGNUM 128\n+\n+/* This is not specified in any ABI, so could be set to anything. */\n+#define HARD_FRAME_POINTER_REGNUM 127\n+\n+/* Will be eliminated. */\n+#define ARG_POINTER_REGNUM 129\n+\n+#define STATIC_CHAIN_REGNUM 2\n+\n+#define LINK_REGISTER_REGNUM 0\n+\n+/* Used to keep track of instructions that have clobbered the hint\n+ * buffer.  Users can also specify it in inline asm. */\n+#define HBR_REGNUM 130\n+\n+/* Used to keep track of enabling and disabling interrupts. */\n+#define INTR_REGNUM 131\n+\n+#define MAX_REGISTER_ARGS    72\n+#define FIRST_ARG_REGNUM     3\n+#define LAST_ARG_REGNUM      (FIRST_ARG_REGNUM + MAX_REGISTER_ARGS - 1)\n+\n+#define MAX_REGISTER_RETURN  72\n+#define FIRST_RETURN_REGNUM  3\n+#define LAST_RETURN_REGNUM   (FIRST_RETURN_REGNUM + MAX_REGISTER_RETURN - 1)\n+\n+\f\n+/* Elimination */\n+\n+#define FRAME_POINTER_REQUIRED 0\n+\n+#define INITIAL_FRAME_POINTER_OFFSET(DEPTH) ((DEPTH) = 0)\n+\n+#define ELIMINABLE_REGS  \\\n+  {{ARG_POINTER_REGNUM,\t STACK_POINTER_REGNUM},\t\t\t\t\\\n+  {ARG_POINTER_REGNUM,\t HARD_FRAME_POINTER_REGNUM},\t\t\t\\\n+  {FRAME_POINTER_REGNUM, STACK_POINTER_REGNUM},\t\t\t\t\\\n+  {FRAME_POINTER_REGNUM, HARD_FRAME_POINTER_REGNUM}}\n+\n+#define CAN_ELIMINATE(FROM,TO) 1 \n+\n+#define INITIAL_ELIMINATION_OFFSET(FROM, TO, OFFSET) \\\n+  ((OFFSET) = spu_initial_elimination_offset((FROM),(TO)))\n+\n+\f\n+/* Stack Arguments */\n+\n+#define ACCUMULATE_OUTGOING_ARGS 1\n+\n+#define REG_PARM_STACK_SPACE(FNDECL) 0\n+\n+#define OUTGOING_REG_PARM_STACK_SPACE \n+\n+#define RETURN_POPS_ARGS(FUNDECL,FUNTYPE,SIZE) (0)\n+\n+\f\n+/* Register Arguments */\n+\n+#define FUNCTION_ARG(CUM, MODE, TYPE, NAMED) \\\n+        (spu_function_arg((CUM),(MODE),(TYPE),(NAMED)))\n+\n+#define CUMULATIVE_ARGS int\n+\n+#define INIT_CUMULATIVE_ARGS(CUM,FNTYPE,LIBNAME,FNDECL,N_NAMED_ARGS) \\\n+\t\t((CUM) = 0)\n+\n+#define FUNCTION_ARG_ADVANCE(CUM, MODE, TYPE, NAMED)\t\\\n+        ((CUM) += \\\n+\t (TYPE) && TREE_CODE (TYPE_SIZE (TYPE)) != INTEGER_CST ? 1 \\\n+\t : (MODE) == BLKmode ? ((int_size_in_bytes(TYPE)+15) / 16) \\\n+         : (MODE) == VOIDmode ? 1 \\\n+\t : HARD_REGNO_NREGS(CUM,MODE))\n+\n+#define FUNCTION_ARG_PADDING(MODE,TYPE) upward\n+\n+#define PAD_VARARGS_DOWN 0\n+\n+#define FUNCTION_ARG_REGNO_P(N) ((N) >= (FIRST_ARG_REGNUM) && (N) <= (LAST_ARG_REGNUM))\n+\n+/* Undocumented */\n+#define EXPAND_BUILTIN_VA_START(valist, nextarg) \\\n+  spu_va_start (valist, nextarg)\n+\n+\f\n+/* Scalar Return */\n+\n+#define FUNCTION_VALUE(VALTYPE, FUNC) \\\n+        (spu_function_value((VALTYPE),(FUNC)))\n+\n+#define LIBCALL_VALUE(MODE) gen_rtx_REG (MODE, FIRST_RETURN_REGNUM)\n+\n+#define FUNCTION_VALUE_REGNO_P(N) ((N) >= (FIRST_RETURN_REGNUM) && (N) <= (LAST_RETURN_REGNUM))\n+\n+\f\n+/* Aggregate Return */\n+\n+#define DEFAULT_PCC_STRUCT_RETURN 0\n+\n+\f\n+/* Function Entry */\n+\n+#define EXIT_IGNORE_STACK 0\n+\n+#define EPILOGUE_USES(REGNO) ((REGNO)==1 ? 1 : 0)\n+\n+\f\n+/* Profiling */\n+\n+/* Nothing, for now. */\n+#define FUNCTION_PROFILER(FILE, LABELNO)  \\\n+   fprintf (FILE, \"\\t\\n\")\n+\n+\f\n+/* Trampolines */\n+\n+#define TRAMPOLINE_SIZE (TARGET_LARGE_MEM ? 20 : 16)\n+\n+#define TRAMPOLINE_ALIGNMENT 128\n+\n+#define INITIALIZE_TRAMPOLINE(TRAMP,FNADDR,CXT) \\\n+\t  spu_initialize_trampoline(TRAMP,FNADDR,CXT)\n+\n+\f\n+/* Addressing Modes */\n+\n+#define CONSTANT_ADDRESS_P(X)   spu_constant_address_p(X)\n+\n+#define MAX_REGS_PER_ADDRESS 2\n+\n+#ifdef REG_OK_STRICT\n+# define REG_OK_STRICT_FLAG 1\n+#else\n+# define REG_OK_STRICT_FLAG 0\n+#endif\n+\n+#define GO_IF_LEGITIMATE_ADDRESS(MODE, X, ADDR)\t\t\t\\\n+    { if (spu_legitimate_address (MODE, X, REG_OK_STRICT_FLAG))\t\\\n+\tgoto ADDR;\t\t\t\t\t\t\\\n+    }\n+\n+#define LEGITIMIZE_ADDRESS(X,OLDX,MODE,WIN) \\\n+  {  rtx result = spu_legitimize_address (X, OLDX, MODE);\t\\\n+     if (result != NULL_RTX)\t\t\t\t\t\\\n+       {\t\t\t\t\t\t\t\\\n+\t (X) = result;\t\t\t\t\t\t\\\n+\t goto WIN;\t\t\t\t\t\t\\\n+       }\t\t\t\t\t\t\t\\\n+  }\n+\n+#define GO_IF_MODE_DEPENDENT_ADDRESS(ADDR,LABEL)\n+\n+#define LEGITIMATE_CONSTANT_P(X) spu_legitimate_constant_p(X)\n+\n+\f\n+/* Costs */\n+\n+#define BRANCH_COST spu_branch_cost\n+\n+#define SLOW_BYTE_ACCESS 0\n+\n+#define MOVE_RATIO 32\n+\n+#define NO_FUNCTION_CSE\n+\n+\f\n+/* Sections */\n+\n+#define TEXT_SECTION_ASM_OP \".text\"\n+\n+#define DATA_SECTION_ASM_OP \".data\"\n+\n+#define JUMP_TABLES_IN_TEXT_SECTION 1\n+\n+\f\n+/* PIC */\n+#define PIC_OFFSET_TABLE_REGNUM 126\n+\n+\f\n+/* File Framework */\n+\n+#define ASM_APP_ON \"\"\n+\n+#define ASM_APP_OFF \"\"\n+\n+#define ASM_OUTPUT_SOURCE_FILENAME(STREAM, NAME) \\\n+  do {\tfprintf (STREAM, \"\\t.file\\t\");\t\t\t\\\n+\toutput_quoted_string (STREAM, NAME);\t\t\\\n+\tfprintf (STREAM, \"\\n\");\t\t\t\t\\\n+  } while (0)\n+\n+\f\n+/* Uninitialized Data */\n+#define ASM_OUTPUT_COMMON(FILE, NAME, SIZE, ROUNDED)  \\\n+( fputs (\".comm \", (FILE)),\t\t\t\\\n+  assemble_name ((FILE), (NAME)),\t\t\\\n+  fprintf ((FILE), \",%d\\n\", (ROUNDED)))\n+\n+#define ASM_OUTPUT_LOCAL(FILE, NAME, SIZE, ROUNDED)  \\\n+( fputs (\".lcomm \", (FILE)),\t\t\t\\\n+  assemble_name ((FILE), (NAME)),\t\t\\\n+  fprintf ((FILE), \",%d\\n\", (ROUNDED)))\n+\n+\f\n+/* Label Output */\n+#define ASM_OUTPUT_LABEL(FILE,NAME)\t\\\n+  do { assemble_name (FILE, NAME); fputs (\":\\n\", FILE); } while (0)\n+\n+#define ASM_OUTPUT_LABELREF(FILE, NAME) \\\n+  asm_fprintf (FILE, \"%U%s\", default_strip_name_encoding (NAME))\n+\n+#define ASM_FORMAT_PRIVATE_NAME(OUTPUT, NAME, LABELNO)\t\\\n+( (OUTPUT) = (char *) alloca (strlen ((NAME)) + 10),\t\\\n+  sprintf ((OUTPUT), \"%s.%d\", (NAME), (LABELNO)))\n+\n+\f\n+/* Instruction Output */\n+#define REGISTER_NAMES \\\n+{\"$lr\", \"$sp\", \"$2\", \"$3\", \"$4\", \"$5\", \"$6\", \"$7\", \"$8\", \"$9\", \"$10\", \"$11\", \"$12\", \"$13\", \"$14\", \"$15\", \\\n+ \"$16\", \"$17\", \"$18\", \"$19\", \"$20\", \"$21\", \"$22\", \"$23\", \"$24\", \"$25\", \"$26\", \"$27\", \"$28\", \"$29\", \"$30\", \"$31\", \\\n+ \"$32\", \"$33\", \"$34\", \"$35\", \"$36\", \"$37\", \"$38\", \"$39\", \"$40\", \"$41\", \"$42\", \"$43\", \"$44\", \"$45\", \"$46\", \"$47\", \\\n+ \"$48\", \"$49\", \"$50\", \"$51\", \"$52\", \"$53\", \"$54\", \"$55\", \"$56\", \"$57\", \"$58\", \"$59\", \"$60\", \"$61\", \"$62\", \"$63\", \\\n+ \"$64\", \"$65\", \"$66\", \"$67\", \"$68\", \"$69\", \"$70\", \"$71\", \"$72\", \"$73\", \"$74\", \"$75\", \"$76\", \"$77\", \"$78\", \"$79\", \\\n+ \"$80\", \"$81\", \"$82\", \"$83\", \"$84\", \"$85\", \"$86\", \"$87\", \"$88\", \"$89\", \"$90\", \"$91\", \"$92\", \"$93\", \"$94\", \"$95\", \\\n+ \"$96\", \"$97\", \"$98\", \"$99\", \"$100\", \"$101\", \"$102\", \"$103\", \"$104\", \"$105\", \"$106\", \"$107\", \"$108\", \"$109\", \"$110\", \"$111\", \\\n+ \"$112\", \"$113\", \"$114\", \"$115\", \"$116\", \"$117\", \"$118\", \"$119\", \"$120\", \"$121\", \"$122\", \"$123\", \"$124\", \"$125\", \"$126\", \"$127\", \\\n+ \"$vfp\", \"$vap\", \"hbr\", \"intr\" \\\n+}\n+\n+#define PRINT_OPERAND(FILE, X, CODE)  print_operand(FILE, X, CODE)\n+\n+#define PRINT_OPERAND_ADDRESS(FILE, ADDR)  \\\n+ print_operand_address (FILE, ADDR)\n+\n+#define LOCAL_LABEL_PREFIX \".\"\n+\n+#define USER_LABEL_PREFIX \"\"\n+\n+\f\n+/* Dispatch Tables */\n+\n+#define ASM_OUTPUT_ADDR_DIFF_ELT(FILE, BODY, VALUE, REL)  \\\n+  fprintf (FILE, \"\\t.word .L%d-.L%d\\n\", VALUE, REL)\n+\n+#define ASM_OUTPUT_ADDR_VEC_ELT(FILE, VALUE)  \\\n+  fprintf (FILE, \"\\t.word .L%d\\n\", VALUE)\n+\n+\f\n+/* Alignment Output */\n+\n+#define ASM_OUTPUT_ALIGN(FILE,LOG)  \\\n+  do { if (LOG!=0) fprintf (FILE, \"\\t.align\\t%d\\n\", (LOG)); } while (0)\n+\n+\f\n+/* Misc */\n+\n+#define CASE_VECTOR_MODE SImode\n+\n+#define MOVE_MAX 16 \n+\n+#define TRULY_NOOP_TRUNCATION(OUTPREC, INPREC) ((INPREC) <= 32 && (OUTPREC) <= (INPREC))\n+\n+#define STORE_FLAG_VALUE -1\n+\n+#define Pmode SImode\n+\n+#define FUNCTION_MODE QImode\n+\n+#define NO_IMPLICIT_EXTERN_C 1\n+\n+\f\n+\n+/* These are set by the cmp patterns and used while expanding\n+   conditional branches. */\n+extern GTY(()) rtx spu_compare_op0;\n+extern GTY(()) rtx spu_compare_op1;\n+"}, {"sha": "6ed9e7b530274c82fa870f9c06854373a6f9150d", "filename": "gcc/config/spu/spu.md", "status": "added", "additions": 3171, "deletions": 0, "changes": 3171, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu.md?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d"}, {"sha": "d234dcd3e2946bd469ce81066dbbc1f5438afc6c", "filename": "gcc/config/spu/spu.opt", "status": "added", "additions": 50, "deletions": 0, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu.opt?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,50 @@\n+; Options for the SPU port of the compiler\n+; Copyright (C) 2006 Free Software Foundation, Inc.\n+\n+; This file is free software; you can redistribute it and/or modify it under\n+; the terms of the GNU General Public License as published by the Free\n+; Software Foundation; either version 2 of the License, or (at your option)\n+; any later version.\n+\n+; This file is distributed in the hope that it will be useful, but WITHOUT\n+; ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+; FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+; for more details.\n+;\n+; You should have received a copy of the GNU General Public License\n+; along with this file; see the file COPYING.  If not, write to the Free\n+; Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+; 02110-1301, USA.\n+\n+mwarn-reloc\n+Target Report Mask(WARN_RELOC)\n+Emit warnings when run-time relocations are generated\n+\n+merror-reloc\n+Target Report Mask(ERROR_RELOC)\n+Emit errors when run-time relocations are generated\n+\n+mbranch-cost=\n+Target RejectNegative Joined UInteger Var(spu_branch_cost) Init(20)\n+Specify cost of branches (Default 20)\n+\n+msafe-dma\n+Target Report RejectNegative Mask(SAFE_DMA)\n+Make sure loads and stores are not moved past DMA instructions\n+\n+munsafe-dma\n+Target Report RejectNegative InverseMask(SAFE_DMA)\n+volatile must be specified on any memory that is effected by DMA\n+\n+mbranch-hints\n+Target Report Mask(BRANCH_HINTS)\n+Generate branch hints for branches\n+\n+msmall-mem\n+Target Report RejectNegative InverseMask(LARGE_MEM)\n+Generate code for 18 bit addressing\n+\n+mlarge-mem\n+Target Report RejectNegative Mask(LARGE_MEM)\n+Generate code for 32 bit addressing\n+"}, {"sha": "752ddb6f04f15d2a6deeb5d331bf9d44c538652c", "filename": "gcc/config/spu/spu_internals.h", "status": "added", "additions": 2846, "deletions": 0, "changes": 2846, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu_internals.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu_internals.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu_internals.h?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d"}, {"sha": "a0832163b9f0b85a3b85149b315be526fbf54661", "filename": "gcc/config/spu/spu_intrinsics.h", "status": "added", "additions": 75, "deletions": 0, "changes": 75, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu_intrinsics.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu_intrinsics.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu_intrinsics.h?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,75 @@\n+/* Definitions of Synergistic Processing Unit (SPU). */\n+/* Copyright (C) 2006 Free Software Foundation, Inc.\n+\n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option) \n+   any later version.\n+\n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+/* As a special exception, if you include this header file into source files \n+   compiled by GCC, this header file does not by itself cause  the resulting \n+   executable to be covered by the GNU General Public License.  This exception \n+   does not however invalidate any other reasons why the executable file might be \n+   covered by the GNU General Public License.  */ \n+\n+#ifndef  _SPU_INTRINSICS_H\n+#define _SPU_INTRINSICS_H \n+ \n+#define vec_uchar16             __vector unsigned char\n+#define vec_char16              __vector   signed char\n+#define vec_ushort8             __vector unsigned short\n+#define vec_short8              __vector   signed short\n+#define vec_uint4               __vector unsigned int\n+#define vec_int4                __vector   signed int\n+#define vec_ullong2             __vector unsigned long long\n+#define vec_llong2              __vector   signed long long\n+#define vec_float4              __vector          float\n+#define vec_double2             __vector          double\n+\n+/* SPU Channel Defines \n+ */\n+#define SPU_RdEventStat\t\t 0\n+#define SPU_WrEventMask\t\t 1\n+#define SPU_WrEventAck\t\t 2\n+#define SPU_RdSigNotify1\t 3\n+#define SPU_RdSigNotify2\t 4\n+#define SPU_WrDec\t\t 7\n+#define SPU_RdDec\t\t 8\n+#define SPU_RdEventStatMask\t11\n+#define SPU_RdMachStat\t\t13\n+#define SPU_WrSRR0\t\t14\n+#define SPU_RdSRR0\t\t15\n+#define SPU_WrOutMbox\t\t28 \n+#define SPU_RdInMbox\t\t29 \n+#define SPU_WrOutIntrMbox\t30 \n+\n+/* MFC Channel Defines. \n+ */\n+#define MFC_WrMSSyncReq\t\t 9\n+#define MFC_RdTagMask\t\t12\n+#define MFC_LSA\t\t\t16 \n+#define MFC_EAH\t\t\t17 \n+#define MFC_EAL\t\t\t18 \n+#define MFC_Size\t\t19 \n+#define MFC_TagID\t\t20 \n+#define MFC_Cmd\t\t\t21 \n+#define MFC_WrTagMask\t\t22 \n+#define MFC_WrTagUpdate\t\t23 \n+#define MFC_RdTagStat\t\t24 \n+#define MFC_RdListStallStat\t25 \n+#define MFC_WrListStallAck\t26 \n+#define MFC_RdAtomicStat\t27 \n+\n+#include <spu_internals.h>\n+\n+#endif /* _SPU_INTRINSICS_H */"}, {"sha": "b0436bc600f69fbc640279e1697441b6752c54d7", "filename": "gcc/config/spu/spu_mfcio.h", "status": "added", "additions": 270, "deletions": 0, "changes": 270, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu_mfcio.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fspu_mfcio.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fspu_mfcio.h?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,270 @@\n+/* Copyright (C) 2006 Free Software Foundation, Inc.\n+\n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option) \n+   any later version.\n+\n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+/* As a special exception, if you include this header file into source files \n+   compiled by GCC, this header file does not by itself cause  the resulting \n+   executable to be covered by the GNU General Public License.  This exception \n+   does not however invalidate any other reasons why the executable file might be \n+   covered by the GNU General Public License.  */ \n+\n+#ifndef __SPU_MFCIO_H__\n+#define __SPU_MFCIO_H__ 1\n+\n+#include <spu_intrinsics.h>\n+#include <stdint.h>\n+\n+\n+/****************************************************************/\n+/* DMA list element structure*/\n+/****************************************************************/\n+ \n+#ifdef __GNUC__\n+__extension__\n+#endif\n+typedef struct mfc_list_element {\n+  uint64_t notify       :  1;   /** Stall-and-notify bit  */\n+  uint64_t reserved     : 15;\n+  uint64_t size         : 16;   /** Transfer size */\n+  uint64_t eal          : 32;   /** Lower word of effective address */\n+} mfc_list_element_t;\n+ \n+/****************************************************************/\n+/* DMA max/min size definitions.                        */\n+/****************************************************************/\n+\n+#define MFC_MIN_DMA_SIZE_SHIFT  4      /* 16 bytes */\n+#define MFC_MAX_DMA_SIZE_SHIFT 14      /* 16384 bytes */\n+\n+#define MFC_MIN_DMA_SIZE (1 << MFC_MIN_DMA_SIZE_SHIFT)\n+#define MFC_MAX_DMA_SIZE (1 << MFC_MAX_DMA_SIZE_SHIFT)\n+\n+#define MFC_MIN_DMA_SIZE_MASK (MFC_MIN_DMA_SIZE - 1)\n+#define MFC_MAX_DMA_SIZE_MASK (MFC_MAX_DMA_SIZE - 1)\n+\n+#define MFC_MIN_DMA_LIST_SIZE 0x0008   /*   8 bytes */\n+#define MFC_MAX_DMA_LIST_SIZE 0x4000   /* 16K bytes */\n+\n+/****************************************************************/\n+/* MFC DMA Command flags which identify classes of operations.   */\n+/****************************************************************/\n+/* Note: These flags may be used in conjunction with the base command types\n+  (i.e. MFC_PUT_CMD, MFC_PUTR_CMD, MFC_GET_CMD, and MFC_SNDSIG_CMD)\n+  to construct the various command permutations.\n+ */\n+\n+#define MFC_BARRIER_ENABLE    0x0001\n+#define MFC_FENCE_ENABLE      0x0002\n+#define MFC_LIST_ENABLE       0x0004   /* SPU Only */\n+#define MFC_START_ENABLE      0x0008   /*  PU Only */\n+#define MFC_RESULT_ENABLE     0x0010\n+\n+/****************************************************************/\n+/* MFC DMA Put Commands                                 */\n+/****************************************************************/\n+\n+#define MFC_PUT_CMD          0x0020\n+#define MFC_PUTS_CMD         0x0028   /*  PU Only */\n+#define MFC_PUTR_CMD         0x0030\n+#define MFC_PUTF_CMD         0x0022\n+#define MFC_PUTB_CMD         0x0021\n+#define MFC_PUTFS_CMD        0x002A   /*  PU Only */\n+#define MFC_PUTBS_CMD        0x0029   /*  PU Only */\n+#define MFC_PUTRF_CMD        0x0032\n+#define MFC_PUTRB_CMD        0x0031\n+#define MFC_PUTL_CMD         0x0024   /* SPU Only */\n+#define MFC_PUTRL_CMD        0x0034   /* SPU Only */\n+#define MFC_PUTLF_CMD        0x0026   /* SPU Only */\n+#define MFC_PUTLB_CMD        0x0025   /* SPU Only */\n+#define MFC_PUTRLF_CMD       0x0036   /* SPU Only */\n+#define MFC_PUTRLB_CMD       0x0035   /* SPU Only */\n+\n+/****************************************************************/\n+/* MFC DMA Get Commands                                 */\n+/****************************************************************/\n+\n+#define MFC_GET_CMD          0x0040\n+#define MFC_GETS_CMD         0x0048   /*  PU Only */\n+#define MFC_GETF_CMD         0x0042\n+#define MFC_GETB_CMD         0x0041\n+#define MFC_GETFS_CMD        0x004A   /*  PU Only */\n+#define MFC_GETBS_CMD        0x0049   /*  PU Only */\n+#define MFC_GETL_CMD         0x0044   /* SPU Only */\n+#define MFC_GETLF_CMD        0x0046   /* SPU Only */\n+#define MFC_GETLB_CMD        0x0045   /* SPU Only */\n+\n+/****************************************************************/\n+/* MFC Synchronization Commands                           */\n+/****************************************************************/\n+\n+#define MFC_SNDSIG_CMD       0x00A0\n+#define MFC_SNDSIGB_CMD      0x00A1\n+#define MFC_SNDSIGF_CMD      0x00A2\n+#define MFC_BARRIER_CMD      0x00C0\n+#define MFC_EIEIO_CMD        0x00C8\n+#define MFC_SYNC_CMD         0x00CC\n+\n+/****************************************************************/\n+/* MFC Atomic Commands                                 */\n+/****************************************************************/\n+\n+#define MFC_GETLLAR_CMD      0x00D0   /* SPU Only */\n+#define MFC_PUTLLC_CMD       0x00B4   /* SPU Only */\n+#define MFC_PUTLLUC_CMD      0x00B0   /* SPU Only */\n+#define MFC_PUTQLLUC_CMD     0x00B8   /* SPU Only */\n+\n+/****************************************************************/\n+/* Channel Defines                                    */\n+/****************************************************************/\n+\n+/* Events Defines for channels\n+ *    0 (SPU_RdEventStat),\n+ *    1 (SPU_WrEventMask), and\n+ *    2 (SPU_WrEventAck).\n+ */\n+#define MFC_TAG_STATUS_UPDATE_EVENT         0x00000001\n+#define MFC_LIST_STALL_NOTIFY_EVENT         0x00000002\n+#define MFC_COMMAND_QUEUE_AVAILABLE_EVENT   0x00000008\n+#define MFC_IN_MBOX_AVAILABLE_EVENT         0x00000010\n+#define MFC_DECREMENTER_EVENT               0x00000020\n+#define MFC_OUT_INTR_MBOX_AVAILABLE_EVENT   0x00000040\n+#define MFC_OUT_MBOX_AVAILABLE_EVENT        0x00000080\n+#define MFC_SIGNAL_NOTIFY_2_EVENT           0x00000100\n+#define MFC_SIGNAL_NOTIFY_1_EVENT           0x00000200\n+#define MFC_LLR_LOST_EVENT                  0x00000400\n+#define MFC_PRIV_ATTN_EVENT                 0x00000800\n+#define MFC_MULTI_SRC_SYNC_EVENT            0x00001000\n+\n+/* Tag Status Update defines for channel 23 (MFC_WrTagUpdate) */\n+#define MFC_TAG_UPDATE_IMMEDIATE   0x0\n+#define MFC_TAG_UPDATE_ANY         0x1\n+#define MFC_TAG_UPDATE_ALL         0x2\n+\n+/* Atomic Command Status defines for channel 27 (MFC_RdAtomicStat) */\n+#define MFC_PUTLLC_STATUS    0x00000001\n+#define MFC_PUTLLUC_STATUS   0x00000002\n+#define MFC_GETLLAR_STATUS   0x00000004\n+\n+\n+/****************************************************************/\n+/* Definitions for constructing a 32-bit command word         */\n+/* including the transfer and replacement class id and the      */\n+/* command opcode.                                    */\n+/****************************************************************/\n+#define MFC_CMD_WORD(_tid, _rid, _cmd) (((_tid)<<24)|((_rid)<<16)|(_cmd))\n+\n+\n+/* Addressing Utilities */\n+#define mfc_ea2h(ea)   (unsigned int)((unsigned long long)(ea)>>32)\n+#define mfc_ea2l(ea)   (unsigned int)(ea)\n+#define mfc_hl2ea(h,l)   si_to_ullong(si_selb(si_from_uint(h),\\\n+                                  si_rotqbyi(si_from_uint(l), -4),\\\n+                                  si_fsmbi(0x0f0f)))\n+#define mfc_ceil128(v)   (((v) + 127) & ~127)\n+\n+/* MFC DMA */\n+#define mfc_put(  ls,ea,size,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),mfc_ea2l(ea),size,tag,MFC_CMD_WORD(tid,rid,MFC_PUT_CMD))\n+#define mfc_putf( ls,ea,size,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),mfc_ea2l(ea),size,tag,MFC_CMD_WORD(tid,rid,MFC_PUTF_CMD))\n+#define mfc_putb( ls,ea,size,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),mfc_ea2l(ea),size,tag,MFC_CMD_WORD(tid,rid,MFC_PUTB_CMD))\n+#define mfc_get(  ls,ea,size,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),mfc_ea2l(ea),size,tag,MFC_CMD_WORD(tid,rid,MFC_GET_CMD))\n+#define mfc_getf( ls,ea,size,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),mfc_ea2l(ea),size,tag,MFC_CMD_WORD(tid,rid,MFC_GETF_CMD))\n+#define mfc_getb( ls,ea,size,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),mfc_ea2l(ea),size,tag,MFC_CMD_WORD(tid,rid,MFC_GETB_CMD))\n+\n+/* MFC list DMA */\n+#define mfc_putl(  ls,ea,lsa,size,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),(unsigned int)(lsa),size,tag,MFC_CMD_WORD(tid,rid,MFC_PUTL_CMD))\n+#define mfc_putlf( ls,ea,lsa,size,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),(unsigned int)(lsa),size,tag,MFC_CMD_WORD(tid,rid,MFC_PUTLF_CMD))\n+#define mfc_putlb( ls,ea,lsa,size,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),(unsigned int)(lsa),size,tag,MFC_CMD_WORD(tid,rid,MFC_PUTLB_CMD))\n+#define mfc_getl(  ls,ea,lsa,size,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),(unsigned int)(lsa),size,tag,MFC_CMD_WORD(tid,rid,MFC_GETL_CMD))\n+#define mfc_getlf( ls,ea,lsa,size,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),(unsigned int)(lsa),size,tag,MFC_CMD_WORD(tid,rid,MFC_GETLF_CMD))\n+#define mfc_getlb( ls,ea,lsa,size,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),(unsigned int)(lsa),size,tag,MFC_CMD_WORD(tid,rid,MFC_GETLB_CMD))\n+\n+/* MFC Atomic Update DMA */\n+#define mfc_getllar( ls,ea,tid,rid)     spu_mfcdma64(ls,mfc_ea2h(ea),mfc_ea2l(ea),128,  0,MFC_CMD_WORD(tid,rid,MFC_GETLLAR_CMD))\n+#define mfc_putllc(  ls,ea,tid,rid)     spu_mfcdma64(ls,mfc_ea2h(ea),mfc_ea2l(ea),128,  0,MFC_CMD_WORD(tid,rid,MFC_PUTLLC_CMD))\n+#define mfc_putlluc( ls,ea,tid,rid)     spu_mfcdma64(ls,mfc_ea2h(ea),mfc_ea2l(ea),128,  0,MFC_CMD_WORD(tid,rid,MFC_PUTLLUC_CMD))\n+#define mfc_putqlluc(ls,ea,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),mfc_ea2l(ea),128,tag,MFC_CMD_WORD(tid,rid,MFC_PUTQLLUC_CMD))\n+\n+/* MFC Synchronization Commands */\n+#define mfc_sndsig( ls,ea,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),mfc_ea2l(ea),4,tag,MFC_CMD_WORD(tid,rid,MFC_SNDSIG_CMD))\n+#define mfc_sndsigb(ls,ea,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),mfc_ea2l(ea),4,tag,MFC_CMD_WORD(tid,rid,MFC_SNDSIGB_CMD))\n+#define mfc_sndsigf(ls,ea,tag,tid,rid) spu_mfcdma64(ls,mfc_ea2h(ea),mfc_ea2l(ea),4,tag,MFC_CMD_WORD(tid,rid,MFC_SNDSIGF_CMD))\n+#define mfc_barrier(tag)       spu_mfcdma32(0,0,0,tag,MFC_BARRIER_CMD)\n+#define mfc_eieio(tag,tid,rid) spu_mfcdma32(0,0,0,tag,MFC_CMD_WORD(tid,rid,MFC_EIEIO_CMD))\n+#define mfc_sync(tag)          spu_mfcdma32(0,0,0,tag,MFC_SYNC_CMD)\n+\n+/* DMA Queue */\n+#define mfc_stat_cmd_queue()          spu_readchcnt(MFC_Cmd)\n+\n+/* MFC Tag-Status */\n+#define mfc_write_tag_mask(mask)      spu_writech(MFC_WrTagMask,mask)\n+#define mfc_read_tag_mask()           spu_readch(MFC_RdTagMask)\n+\n+#define mfc_write_tag_update(ts)         spu_writech(MFC_WrTagUpdate,ts)\n+#define mfc_write_tag_update_immediate() mfc_write_tag_update(MFC_TAG_UPDATE_IMMEDIATE)\n+#define mfc_write_tag_update_any()       mfc_write_tag_update(MFC_TAG_UPDATE_ANY)\n+#define mfc_write_tag_update_all()       mfc_write_tag_update(MFC_TAG_UPDATE_ALL)\n+#define mfc_stat_tag_update()            spu_readchcnt(MFC_WrTagUpdate)\n+\n+#define mfc_read_tag_status()            spu_readch(MFC_RdTagStat)\n+#define mfc_read_tag_status_immediate()  (mfc_write_tag_update_immediate(), mfc_read_tag_status())\n+#define mfc_read_tag_status_any()        (mfc_write_tag_update_any(), mfc_read_tag_status())\n+#define mfc_read_tag_status_all()        (mfc_write_tag_update_all(), mfc_read_tag_status())\n+#define mfc_stat_tag_status()            spu_readchcnt(MFC_RdTagStat)\n+\n+/* MFC List Stall-and-Notify Tag */\n+#define mfc_read_list_stall_status()     spu_readch(MFC_RdListStallStat)\n+#define mfc_stat_list_stall_status()     spu_readchcnt(MFC_RdListStallStat)\n+#define mfc_write_list_stall_ack(tag)    spu_writech(MFC_WrListStallAck,tag)\n+\n+/* Atomic DMA */\n+#define mfc_read_atomic_status()      spu_readch(MFC_RdAtomicStat)\n+#define mfc_stat_atomic_status()      spu_readchcnt(MFC_RdAtomicStat)\n+\n+/* MFC Multi-source Synchronization */\n+#define mfc_write_multi_src_sync_request()   spu_writech(MFC_WrMSSyncReq,0)\n+#define mfc_stat_multi_src_sync_request()    spu_readchcnt(MFC_WrMSSyncReq)\n+\n+/* SPU Signal */\n+#define spu_read_signal1()            spu_readch(SPU_RdSigNotify1)\n+#define spu_stat_signal1()            spu_readchcnt(SPU_RdSigNotify1)\n+#define spu_read_signal2()            spu_readch(SPU_RdSigNotify2)\n+#define spu_stat_signal2()            spu_readchcnt(SPU_RdSigNotify2)\n+\n+/* SPU/PPE Mailbox */\n+#define spu_read_in_mbox()            spu_readch(SPU_RdInMbox)\n+#define spu_stat_in_mbox()            spu_readchcnt(SPU_RdInMbox)\n+#define spu_write_out_mbox(a)         spu_writech(SPU_WrOutMbox,a)\n+#define spu_stat_out_mbox()           spu_readchcnt(SPU_WrOutMbox)\n+#define spu_write_out_intr_mbox(a)    spu_writech(SPU_WrOutIntrMbox,a)\n+#define spu_stat_out_intr_mbox()      spu_readchcnt(SPU_WrOutIntrMbox)\n+\n+/* SPU Decrementer */\n+#define spu_read_decrementer()        spu_readch(SPU_RdDec)\n+#define spu_write_decrementer(cnt)    spu_writech(SPU_WrDec,(cnt))\n+\n+/* SPU Event */\n+#define spu_read_event_status()       spu_readch(SPU_RdEventStat)\n+#define spu_stat_event_status()       spu_readchcnt(SPU_RdEventStat)\n+#define spu_write_event_mask(mask)    spu_writech(SPU_WrEventMask,(mask))\n+#define spu_write_event_ack(ack)      spu_writech(SPU_WrEventAck,(ack))\n+#define spu_read_event_mask()         spu_readch(SPU_RdEventStatMask)\n+\n+/* SPU State Management */\n+#define spu_read_machine_status()     spu_readch(SPU_MachStat)\n+#define spu_write_srr0(srr0)          spu_writech(SPU_WrSRR0,srr0)\n+#define spu_read_srr0()               spu_readch(SPU_RdSRR0)\n+\n+#endif /* __SPU_MFCIO_H__ */"}, {"sha": "c05b2452346cb28c3f64390035e6412a29c6a1c7", "filename": "gcc/config/spu/t-spu-elf", "status": "added", "additions": 99, "deletions": 0, "changes": 99, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Ft-spu-elf", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Ft-spu-elf", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Ft-spu-elf?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,99 @@\n+#  Copyright (C) 2006 Free Software Foundation, Inc.\n+#\n+#  This file is free software; you can redistribute it and/or modify it under\n+#  the terms of the GNU General Public License as published by the Free\n+#  Software Foundation; either version 2 of the License, or (at your option) \n+#  any later version.\n+#\n+#  This file is distributed in the hope that it will be useful, but WITHOUT\n+#  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+#  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+#  for more details.\n+#\n+#  You should have received a copy of the GNU General Public License\n+#  along with this file; see the file COPYING.  If not, write to the Free\n+#  Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+#  02110-1301, USA.\n+\n+\n+# Suppress building libgcc1.a\n+LIBGCC1 =\n+CROSS_LIBGCC1 =\n+\n+# On SPU __word__ is TImode which is too inefficient and incomplete for\n+# implementing libgcc routines.\n+TARGET_LIBGCC2_CFLAGS = -fPIC -D__word__=SI -mwarn-reloc\n+\n+LIB2FUNCS_STATIC_EXTRA = $(srcdir)/config/spu/float_unssidf.c \\\n+\t\t\t $(srcdir)/config/spu/float_unsdidf.c\n+\n+LIB2ADDEH = $(srcdir)/unwind-dw2.c $(srcdir)/unwind-dw2-fde.c \\\n+   $(srcdir)/unwind-sjlj.c $(srcdir)/unwind-c.c\n+\n+# We want fine grained libraries, so use the new code to build the\n+# floating point emulation libraries.\n+FPBIT = fp-bit.c\n+DPBIT = dp-bit.c\n+\n+dp-bit.c: $(srcdir)/config/fp-bit.c $(srcdir)/config/spu/t-spu-elf\n+\techo '#undef US_SOFTWARE_GOFAST' > dp-bit.c\n+\tcat $(srcdir)/config/fp-bit.c >> dp-bit.c\n+\n+fp-bit.c: $(srcdir)/config/fp-bit.c $(srcdir)/config/spu/t-spu-elf\n+\techo '#define FLOAT' > fp-bit.c\n+\techo '#undef US_SOFTWARE_GOFAST' >> fp-bit.c\n+\tcat $(srcdir)/config/fp-bit.c >> fp-bit.c\n+\n+# Don't let CTOR_LIST end up in sdata section.\n+CRTSTUFF_T_CFLAGS =\n+\n+#MULTILIB_OPTIONS=mlarge-mem/mtest-abi\n+#MULTILIB_DIRNAMES=large-mem test-abi\n+#MULTILIB_MATCHES=\n+\n+# Neither gcc or newlib seem to have a standard way to generate multiple\n+# crt*.o files.  So we don't use the standard crt0.o name anymore.\n+\n+EXTRA_MULTILIB_PARTS = crtbegin.o crtend.o crti.o crtn.o crt1.o crtend1.o\n+\n+LIBGCC = stmp-multilib\n+INSTALL_LIBGCC = install-multilib\n+\n+# Assemble startup files.\n+$(T)crti.o: $(srcdir)/config/spu/crti.asm $(GCC_PASSES)\n+\t$(GCC_FOR_TARGET) $(GCC_CFLAGS) $(MULTILIB_CFLAGS) $(INCLUDES) \\\n+\t-c -o $(T)crti.o -x assembler-with-cpp $(srcdir)/config/spu/crti.asm\n+\n+$(T)crtn.o: $(srcdir)/config/spu/crtn.asm $(GCC_PASSES)\n+\t$(GCC_FOR_TARGET) $(GCC_CFLAGS) $(MULTILIB_CFLAGS) $(INCLUDES) \\\n+\t-c -o $(T)crtn.o -x assembler-with-cpp $(srcdir)/config/spu/crtn.asm\n+\n+$(T)crt1.o: $(srcdir)/config/spu/crt0.c $(GCC_PASSES)\n+\t$(GCC_FOR_TARGET) $(GCC_CFLAGS) $(MULTILIB_CFLAGS) $(INCLUDES) \\\n+\t-O2 \\\n+\t-c -o $(T)crt1.o $(srcdir)/config/spu/crt0.c\n+\n+$(T)crtend1.o: $(srcdir)/config/spu/crtend.c $(GCC_PASSES)\n+\t$(GCC_FOR_TARGET) $(GCC_CFLAGS) $(MULTILIB_CFLAGS) $(INCLUDES) \\\n+\t-O2 \\\n+\t-c -o $(T)crtend1.o $(srcdir)/config/spu/crtend.c\n+\n+\n+spu.o: $(CONFIG_H) $(SYSTEM_H) coretypes.h $(TM_H) \\\n+  $(RTL_H) $(REGS_H) hard-reg-set.h \\\n+  real.h insn-config.h conditions.h insn-attr.h flags.h $(RECOG_H) \\\n+  $(OBSTACK_H) $(TREE_H) $(EXPR_H) $(OPTABS_H) except.h function.h \\\n+  output.h $(BASIC_BLOCK_H) $(INTEGRATE_H) toplev.h $(GGC_H) $(HASHTAB_H) \\\n+  $(TM_P_H) $(TARGET_H) $(TARGET_DEF_H) langhooks.h reload.h cfglayout.h \\\n+  $(srcdir)/config/spu/spu-protos.h \\\n+  $(srcdir)/config/spu/spu-builtins.h \\\n+  $(srcdir)/config/spu/spu-builtins.def \n+\n+spu-c.o: $(srcdir)/config/spu/spu-c.c \\\n+    $(srcdir)/config/spu/spu-protos.h \\\n+    $(srcdir)/config/spu/spu-builtins.h \\\n+    $(srcdir)/config/spu/spu-builtins.def \\\n+    $(CONFIG_H) $(SYSTEM_H) $(TREE_H) $(CPPLIB_H) \\\n+    $(TM_P_H) c-pragma.h errors.h coretypes.h $(TM_H) insn-codes.h\n+\t$(CC) -c $(ALL_CFLAGS) $(ALL_CPPFLAGS) $(INCLUDES) $(srcdir)/config/spu/spu-c.c\n+"}, {"sha": "4d5a2e2241d02d57ef9762ea7d3aab3365fa4705", "filename": "gcc/config/spu/vec_types.h", "status": "added", "additions": 38, "deletions": 0, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fvec_types.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fvec_types.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fvec_types.h?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -0,0 +1,38 @@\n+/* Copyright (C) 2006 Free Software Foundation, Inc.\n+\n+   This file is free software; you can redistribute it and/or modify it under\n+   the terms of the GNU General Public License as published by the Free\n+   Software Foundation; either version 2 of the License, or (at your option) \n+   any later version.\n+\n+   This file is distributed in the hope that it will be useful, but WITHOUT\n+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+   FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+   for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this file; see the file COPYING.  If not, write to the Free\n+   Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA\n+   02110-1301, USA.  */\n+\n+/* As a special exception, if you include this header file into source files \n+   compiled by GCC, this header file does not by itself cause  the resulting \n+   executable to be covered by the GNU General Public License.  This exception \n+   does not however invalidate any other reasons why the executable file might be \n+   covered by the GNU General Public License.  */ \n+\n+#ifndef _VEC_TYPES_H_\n+#define _VEC_TYPES_H_\t1\n+\n+#include <spu_intrinsics.h>\n+\n+/* Define additional PowerPC SIMD/Vector Multi-media eXtension\n+ * single keyword vector data types for use in mapping VMX code\n+ * to the SPU.\n+ */\n+#define vec_bchar16\t__vector unsigned char\n+#define vec_bshort8\t__vector unsigned short\n+#define vec_pixel8\t__vector unsigned short\n+#define vec_bint4\t__vector unsigned int\n+\n+#endif /* _VEC_TYPES_H_ */"}, {"sha": "7328da4a9d485df70bb6e2333c613def1f2c80e6", "filename": "gcc/config/spu/vmx2spu.h", "status": "added", "additions": 3445, "deletions": 0, "changes": 3445, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fvmx2spu.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fconfig%2Fspu%2Fvmx2spu.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fspu%2Fvmx2spu.h?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d"}, {"sha": "46e8612bc5626a6f812690acafdb3fa428768c3d", "filename": "gcc/doc/contrib.texi", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fdoc%2Fcontrib.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fdoc%2Fcontrib.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fcontrib.texi?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -821,6 +821,9 @@ for GNU/Linux.\n @item\n Andrey Slepuhin for assorted AIX hacking.\n \n+@item\n+Trevor Smigiel for contributing the SPU port.\n+\n @item\n Christopher Smith did the port for Convex machines.\n "}, {"sha": "fa7f31e9ba0eeabd55d6503252e38b9f80bda6e2", "filename": "gcc/doc/extend.texi", "status": "modified", "additions": 74, "deletions": 2, "changes": 76, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fdoc%2Fextend.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fdoc%2Fextend.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fextend.texi?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -2054,8 +2054,8 @@ defined by shared libraries.\n \n @item naked\n @cindex function without a prologue/epilogue code\n-Use this attribute on the ARM, AVR, C4x and IP2K ports to indicate that the\n-specified function does not need prologue/epilogue sequences generated by\n+Use this attribute on the ARM, AVR, C4x, IP2K and SPU ports to indicate that\n+the specified function does not need prologue/epilogue sequences generated by\n the compiler.  It is up to the programmer to provide these sequences.\n \n @item near\n@@ -3416,6 +3416,12 @@ documentation in the @xref{i386 Variable Attributes}, section.\n For documentation of @code{altivec} attribute please see the\n documentation in the @xref{PowerPC Type Attributes}, section.\n \n+@subsection SPU Variable Attributes\n+\n+The SPU supports the @code{spu_vector} attribute for variables.  For\n+documentation of this attribute please see the documentation in the\n+@xref{SPU Type Attributes}, section.\n+\n @subsection Xstormy16 Variable Attributes\n \n One attribute is currently defined for xstormy16 configurations:\n@@ -3795,6 +3801,15 @@ __attribute__((altivec(bool__))) unsigned\n These attributes mainly are intended to support the @code{__vector},\n @code{__pixel}, and @code{__bool} AltiVec keywords.\n \n+@anchor{SPU Type Attributes}\n+@subsection SPU Type Attributes\n+\n+The SPU supports the @code{spu_vector} attribute for types.  This attribute\n+allows one to declare vector data types supported by the Sony/Toshiba/IBM SPU\n+Language Extensions Specification.  It is intended to support the\n+@code{__vector} keyword.\n+\n+\n @node Inline\n @section An Inline Function is As Fast As a Macro\n @cindex inline functions\n@@ -6157,6 +6172,7 @@ instructions, but allow the compiler to schedule those calls.\n * MIPS Paired-Single Support::\n * PowerPC AltiVec Built-in Functions::\n * SPARC VIS Built-in Functions::\n+* SPU Built-in Functions::\n @end menu\n \n @node Alpha Built-in Functions\n@@ -9736,6 +9752,62 @@ v8qi __builtin_vis_fpmerge (v4qi, v4qi);\n int64_t __builtin_vis_pdist (v8qi, v8qi, int64_t);\n @end smallexample\n \n+@node SPU Built-in Functions\n+@subsection SPU Built-in Functions\n+\n+GCC provides extensions for the SPU processor as described in the\n+Sony/Toshiba/IBM SPU Language Extensions Specification, which can be\n+found at @uref{http://cell.scei.co.jp/} or\n+@uref{http://www.ibm.com/developerworks/power/cell/}.  GCC's\n+implementation differs in several ways.\n+\n+@itemize @bullet\n+\n+@item\n+The optional extension of specifying vector constants in parentheses is\n+not supported.\n+\n+@item\n+A vector initializer requires no cast if the vector constant is of the\n+same type as the variable it is initializing.\n+\n+@item\n+If @code{signed} or @code{unsigned} is omitted, the signedness of the\n+vector type is the default signedness of the base type.  The default\n+varies depending on the operating system, so a portable program should\n+always specify the signedness.\n+\n+@item\n+By default, the keyword @code{__vector} is added. The macro\n+@code{vector} is defined in @code{<spu_intrinsics.h>} and can be\n+undefined.\n+\n+@item\n+GCC allows using a @code{typedef} name as the type specifier for a\n+vector type.\n+\n+@item\n+For C, overloaded functions are implemented with macros so the following\n+does not work:\n+\n+@smallexample\n+  spu_add ((vector signed int)@{1, 2, 3, 4@}, foo);\n+@end smallexample\n+\n+Since @code{spu_add} is a macro, the vector constant in the example\n+is treated as four separate arguments.  Wrap the entire argument in\n+parentheses for this to work.\n+\n+@item\n+The extended version of @code{__builtin_expect} is not supported.\n+\n+@end itemize\n+\n+@emph{Note:} Only the interface descibed in the aforementioned\n+specification is supported. Internally, GCC uses built-in functions to\n+implement the required functionality, but these are not supported and\n+are subject to change without notice.\n+\n @node Target Format Checks\n @section Format Checks Specific to Particular Target Machines\n "}, {"sha": "3cd8219549c96ec0a8e40c949a08b1bcf3a03910", "filename": "gcc/doc/invoke.texi", "status": "modified", "additions": 58, "deletions": 0, "changes": 58, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fdoc%2Finvoke.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fdoc%2Finvoke.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finvoke.texi?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -728,6 +728,12 @@ See RS/6000 and PowerPC Options.\n -mv8plus  -mno-v8plus  -mvis  -mno-vis\n -threads -pthreads -pthread}\n \n+@emph{SPU Options}\n+@gccoptlist{-mwarn-reloc -merror-reloc @gol\n+-msafe-dma -munsafe-dma @gol\n+-mbranch-hints @gol\n+-msmall-mem -mlarge-mem}\n+\n @emph{System V Options}\n @gccoptlist{-Qy  -Qn  -YP,@var{paths}  -Ym,@var{dir}}\n \n@@ -7358,6 +7364,7 @@ platform.\n * Score Options::\n * SH Options::\n * SPARC Options::\n+* SPU Options::\n * System V Options::\n * TMS320C3x/C4x Options::\n * V850 Options::\n@@ -12781,6 +12788,57 @@ that of libraries supplied with it.\n This is a synonym for @option{-pthreads}.\n @end table\n \n+@node SPU Options\n+@subsection SPU Options\n+@cindex SPU options\n+\n+These @samp{-m} options are supported on the SPU:\n+\n+@table @gcctabopt\n+@item -mwarn-reloc\n+@itemx -merror-reloc\n+@opindex mwarn-reloc\n+@opindex merror-reloc\n+\n+The loader for SPU does not handle dynamic relocations.  By default, GCC\n+will give an error when it generates code that requires a dynamic\n+relocation.  @option{-mno-error-reloc} disables the error,\n+@option{-mwarn-reloc} will generate a warning instead.\n+\n+@item -msafe-dma\n+@itemx -munsafe-dma\n+@opindex msafe-dma\n+@opindex munsafe-dma\n+\n+Instructions which initiate or test completion of DMA must not be\n+reordered with respect to loads and stores of the memory which is being\n+accessed.  Users typically address this problem using the volatile\n+keyword, but that can lead to inefficient code in places where the\n+memory is known to not change.  Rather than mark the memory as volatile\n+we treat the DMA instructions as potentially effecting all memory.  With\n+@option{-munsafe-dma} users must use the volatile keyword to protect\n+memory accesses.\n+\n+@item -mbranch-hints\n+@opindex mbranch-hints\n+\n+By default, GCC will generate a branch hint instruction to avoid\n+pipeline stalls for always taken or probably taken branches.  A hint\n+will not be generated closer than 8 instructions away from its branch.\n+There is little reason to disable them, except for debugging purposes,\n+or to make an object a little bit smaller.\n+\n+@item -msmall-mem\n+@itemx -mlarge-mem\n+@opindex msmall-mem\n+@opindex mlarge-mem\n+\n+By default, GCC generates code assuming that addresses are never larger\n+than 18 bits.  With @option{-mlarge-mem} code is generated that assumes\n+a full 32 bit address.\n+\n+@end table\n+\n @node System V Options\n @subsection Options for System V\n "}, {"sha": "2696eca7ebfd4c6aba8117415033e47e0bb729ef", "filename": "gcc/doc/md.texi", "status": "modified", "additions": 70, "deletions": 0, "changes": 70, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fdoc%2Fmd.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/gcc%2Fdoc%2Fmd.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Fmd.texi?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -2630,6 +2630,76 @@ Vector zero\n \n @end table\n \n+@item SPU---@file{config/spu/spu.h}\n+@table @code\n+@item a\n+An immediate which can be loaded with the il/ila/ilh/ilhu instructions.  const_int is treated as a 64 bit value.  \n+\n+@item c\n+An immediate for and/xor/or instructions.  const_int is treated as a 64 bit value.  \n+\n+@item d\n+An immediate for the @code{iohl} instruction.  const_int is treated as a 64 bit value.  \n+\n+@item f\n+An immediate which can be loaded with @code{fsmbi}.  \n+\n+@item A\n+An immediate which can be loaded with the il/ila/ilh/ilhu instructions.  const_int is treated as a 32 bit value.  \n+\n+@item B\n+An immediate for most arithmetic instructions.  const_int is treated as a 32 bit value.  \n+\n+@item C\n+An immediate for and/xor/or instructions.  const_int is treated as a 32 bit value.  \n+\n+@item D\n+An immediate for the @code{iohl} instruction.  const_int is treated as a 32 bit value.  \n+\n+@item I\n+A constant in the range [-64, 63] for shift/rotate instructions.  \n+\n+@item J\n+An unsigned 7-bit constant for conversion/nop/channel instructions.  \n+\n+@item K\n+A signed 10-bit constant for most arithmetic instructions.  \n+\n+@item M\n+A signed 16 bit immediate for @code{stop}.  \n+\n+@item N\n+An unsigned 16-bit constant for @code{iohl} and @code{fsmbi}.  \n+\n+@item O\n+An unsigned 7-bit constant whose 3 least significant bits are 0.  \n+\n+@item P\n+An unsigned 3-bit constant for 16-byte rotates and shifts \n+\n+@item R\n+Call operand, reg, for indirect calls \n+\n+@item S\n+Call operand, symbol, for relative calls.  \n+\n+@item T\n+Call operand, const_int, for absolute calls.  \n+\n+@item U\n+An immediate which can be loaded with the il/ila/ilh/ilhu instructions.  const_int is sign extended to 128 bit.  \n+\n+@item W\n+An immediate for shift and rotate instructions.  const_int is treated as a 32 bit value.  \n+\n+@item Y\n+An immediate for and/xor/or instructions.  const_int is sign extended as a 128 bit.  \n+\n+@item Z\n+An immediate for the @code{iohl} instruction.  const_int is sign extended to 128 bit.  \n+\n+@end table\n+\n @item TMS320C3x/C4x---@file{config/c4x/c4x.h}\n @table @code\n @item a"}, {"sha": "59838ec281f991adf9b086cdb52807486ba30a67", "filename": "libcpp/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/libcpp%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/libcpp%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libcpp%2FChangeLog?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -1,3 +1,8 @@\n+2006-11-20  Trevor Smigiel <Trevor_Smigiel@playstation.sony.com>\n+\n+\t* configure.ac (need_64bit_hwint): Need 64bit hwint for SPU.\n+\t* configure : Rebuilt.\n+\n 2006-11-01\tDouglas Gregor <doug.gregor@gmail.com>\n \n \t* include/cpplib.h (enum c_lang): Add CLK_GNUCXX0X and CLK_CXX0X"}, {"sha": "783cb7cccfb67fda953082136e64400e487505da", "filename": "libcpp/configure", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/libcpp%2Fconfigure", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/libcpp%2Fconfigure", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libcpp%2Fconfigure?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -8244,6 +8244,7 @@ case $target in\n \tsparc64*-*-* | ultrasparc-*-freebsd* | \\\n \tsparcv9-*-solaris2* | \\\n \tsparc-*-solaris2.[789] | sparc-*-solaris2.1[0-9]* | \\\n+\tspu-*-* | \\\n \tsh[123456789l]*-*-*)\n \t\tneed_64bit_hwint=yes ;;\n \ti[34567]86-*-linux*)"}, {"sha": "8a23633f4dedde7c2f89999d1e3676f335c4ea0d", "filename": "libcpp/configure.ac", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/85d9c13c208f254dad25773cdc6e44219c3ebe0d/libcpp%2Fconfigure.ac", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/85d9c13c208f254dad25773cdc6e44219c3ebe0d/libcpp%2Fconfigure.ac", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libcpp%2Fconfigure.ac?ref=85d9c13c208f254dad25773cdc6e44219c3ebe0d", "patch": "@@ -128,6 +128,7 @@ case $target in\n \tsparc64*-*-* | ultrasparc-*-freebsd* | \\\n \tsparcv9-*-solaris2* | \\\n \tsparc-*-solaris2.[789] | sparc-*-solaris2.1[0-9]* | \\\n+\tspu-*-* | \\\n \tsh[123456789l]*-*-*)\n \t\tneed_64bit_hwint=yes ;;\n \ti[34567]86-*-linux*)"}]}