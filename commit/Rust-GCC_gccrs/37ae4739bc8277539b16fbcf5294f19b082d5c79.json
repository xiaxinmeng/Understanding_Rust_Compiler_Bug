{"sha": "37ae4739bc8277539b16fbcf5294f19b082d5c79", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MzdhZTQ3MzliYzgyNzc1MzliMTZmYmNmNTI5NGYxOWIwODJkNWM3OQ==", "commit": {"author": {"name": "Aaron Sawdey", "email": "acsawdey@linux.ibm.com", "date": "2018-11-26T20:59:06Z"}, "committer": {"name": "Aaron Sawdey", "email": "acsawdey@gcc.gnu.org", "date": "2018-11-26T20:59:06Z"}, "message": "rs6000-string.c (expand_cmp_vec_sequence): Rename and modify expand_strncmp_vec_sequence.\n\n2018-11-26  Aaron Sawdey  <acsawdey@linux.ibm.com>\n\n\t* config/rs6000/rs6000-string.c (expand_cmp_vec_sequence): Rename\n\tand modify expand_strncmp_vec_sequence.\n\t(emit_final_compare_vec): Rename and modify emit_final_str_compare_vec.\n\t(generate_6432_conversion): New function.\n\t(expand_block_compare): Add support for vsx.\n\t(expand_block_compare_gpr): New function.\n\t* config/rs6000/rs6000.opt (rs6000_block_compare_inline_limit): Increase\n\tdefault limit to 63 because of more compact vsx code.\n\nFrom-SVN: r266481", "tree": {"sha": "2d94558038c47e2c6a126a2ff8597feeb330cae3", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/2d94558038c47e2c6a126a2ff8597feeb330cae3"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/37ae4739bc8277539b16fbcf5294f19b082d5c79", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/37ae4739bc8277539b16fbcf5294f19b082d5c79", "html_url": "https://github.com/Rust-GCC/gccrs/commit/37ae4739bc8277539b16fbcf5294f19b082d5c79", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/37ae4739bc8277539b16fbcf5294f19b082d5c79/comments", "author": {"login": "acsawdey", "id": 41373646, "node_id": "MDQ6VXNlcjQxMzczNjQ2", "avatar_url": "https://avatars.githubusercontent.com/u/41373646?v=4", "gravatar_id": "", "url": "https://api.github.com/users/acsawdey", "html_url": "https://github.com/acsawdey", "followers_url": "https://api.github.com/users/acsawdey/followers", "following_url": "https://api.github.com/users/acsawdey/following{/other_user}", "gists_url": "https://api.github.com/users/acsawdey/gists{/gist_id}", "starred_url": "https://api.github.com/users/acsawdey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/acsawdey/subscriptions", "organizations_url": "https://api.github.com/users/acsawdey/orgs", "repos_url": "https://api.github.com/users/acsawdey/repos", "events_url": "https://api.github.com/users/acsawdey/events{/privacy}", "received_events_url": "https://api.github.com/users/acsawdey/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "02ef9b0c2d73bac1e3bc3f8cc8c1e1f43826a04b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/02ef9b0c2d73bac1e3bc3f8cc8c1e1f43826a04b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/02ef9b0c2d73bac1e3bc3f8cc8c1e1f43826a04b"}], "stats": {"total": 973, "additions": 547, "deletions": 426}, "files": [{"sha": "a6406ec3b84beeef6ea6e0200a77ebf6ff3b61b1", "filename": "gcc/ChangeLog", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/37ae4739bc8277539b16fbcf5294f19b082d5c79/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/37ae4739bc8277539b16fbcf5294f19b082d5c79/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=37ae4739bc8277539b16fbcf5294f19b082d5c79", "patch": "@@ -1,3 +1,14 @@\n+2018-11-26  Aaron Sawdey  <acsawdey@linux.ibm.com>\n+\n+\t* config/rs6000/rs6000-string.c (expand_cmp_vec_sequence): Rename\n+\tand modify expand_strncmp_vec_sequence.\n+\t(emit_final_compare_vec): Rename and modify emit_final_str_compare_vec.\n+\t(generate_6432_conversion): New function.\n+\t(expand_block_compare): Add support for vsx.\n+\t(expand_block_compare_gpr): New function.\n+\t* config/rs6000/rs6000.opt (rs6000_block_compare_inline_limit): Increase\n+\tdefault limit to 63 because of more compact vsx code.\n+\n 2018-11-26  Uros Bizjak  <ubizjak@gmail.com>\n \n \tPR target/88178"}, {"sha": "620be2b7325e9dfc507b47d1aca900a6287877e9", "filename": "gcc/config/rs6000/rs6000-string.c", "status": "modified", "additions": 535, "deletions": 425, "changes": 960, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/37ae4739bc8277539b16fbcf5294f19b082d5c79/gcc%2Fconfig%2Frs6000%2Frs6000-string.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/37ae4739bc8277539b16fbcf5294f19b082d5c79/gcc%2Fconfig%2Frs6000%2Frs6000-string.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000-string.c?ref=37ae4739bc8277539b16fbcf5294f19b082d5c79", "patch": "@@ -615,6 +615,274 @@ do_overlap_load_compare (machine_mode load_mode, bool isConst,\n     }\n }\n \n+/* Generate the sequence of compares for strcmp/strncmp using vec/vsx\n+   instructions.\n+\n+   BYTES_TO_COMPARE is the number of bytes to be compared.\n+   ORIG_SRC1 is the unmodified rtx for the first string.\n+   ORIG_SRC2 is the unmodified rtx for the second string.\n+   S1ADDR is the register to use for the base address of the first string.\n+   S2ADDR is the register to use for the base address of the second string.\n+   OFF_REG is the register to use for the string offset for loads.\n+   S1DATA is the register for loading the first string.\n+   S2DATA is the register for loading the second string.\n+   VEC_RESULT is the rtx for the vector result indicating the byte difference.\n+   EQUALITY_COMPARE_REST is a flag to indicate we need to make a cleanup call\n+   to strcmp/strncmp if we have equality at the end of the inline comparison.\n+   P_CLEANUP_LABEL is a pointer to rtx for a label we generate if we need code\n+   to clean up and generate the final comparison result.\n+   FINAL_MOVE_LABEL is rtx for a label we can branch to when we can just\n+   set the final result.\n+   CHECKZERO indicates whether the sequence should check for zero bytes\n+   for use doing strncmp, or not (for use doing memcmp).  */\n+static void\n+expand_cmp_vec_sequence (unsigned HOST_WIDE_INT bytes_to_compare,\n+\t\t\t rtx orig_src1, rtx orig_src2,\n+\t\t\t rtx s1addr, rtx s2addr, rtx off_reg,\n+\t\t\t rtx s1data, rtx s2data, rtx vec_result,\n+\t\t\t bool equality_compare_rest, rtx *p_cleanup_label,\n+\t\t\t rtx final_move_label, bool checkzero)\n+{\n+  machine_mode load_mode;\n+  unsigned int load_mode_size;\n+  unsigned HOST_WIDE_INT cmp_bytes = 0;\n+  unsigned HOST_WIDE_INT offset = 0;\n+  rtx zero_reg = NULL;\n+\n+  gcc_assert (p_cleanup_label != NULL);\n+  rtx cleanup_label = *p_cleanup_label;\n+\n+  emit_move_insn (s1addr, force_reg (Pmode, XEXP (orig_src1, 0)));\n+  emit_move_insn (s2addr, force_reg (Pmode, XEXP (orig_src2, 0)));\n+\n+  if (checkzero && !TARGET_P9_VECTOR)\n+    {\n+      zero_reg = gen_reg_rtx (V16QImode);\n+      emit_move_insn (zero_reg, CONST0_RTX (V16QImode));\n+    }\n+\n+  while (bytes_to_compare > 0)\n+    {\n+      /* VEC/VSX compare sequence for P8:\n+\t check each 16B with:\n+\t lxvd2x 32,28,8\n+\t lxvd2x 33,29,8\n+\t vcmpequb 2,0,1  # compare strings\n+\t vcmpequb 4,0,3  # compare w/ 0\n+\t xxlorc 37,36,34       # first FF byte is either mismatch or end of string\n+\t vcmpequb. 7,5,3  # reg 7 contains 0\n+\t bnl 6,.Lmismatch\n+\n+\t For the P8 LE case, we use lxvd2x and compare full 16 bytes\n+\t but then use use vgbbd and a shift to get two bytes with the\n+\t information we need in the correct order.\n+\n+\t VEC/VSX compare sequence if TARGET_P9_VECTOR:\n+\t lxvb16x/lxvb16x     # load 16B of each string\n+\t vcmpnezb.           # produces difference location or zero byte location\n+\t bne 6,.Lmismatch\n+\n+\t Use the overlapping compare trick for the last block if it is\n+\t less than 16 bytes.\n+      */\n+\n+      load_mode = V16QImode;\n+      load_mode_size = GET_MODE_SIZE (load_mode);\n+\n+      if (bytes_to_compare >= load_mode_size)\n+\tcmp_bytes = load_mode_size;\n+      else\n+\t{\n+\t  /* Move this load back so it doesn't go past the end.  P8/P9\n+\t     can do this efficiently.  This is never called with less\n+\t     than 16 bytes so we should always be able to do this.  */\n+\t  unsigned int extra_bytes = load_mode_size - bytes_to_compare;\n+\t  cmp_bytes = bytes_to_compare;\n+\t  gcc_assert (offset > extra_bytes);\n+\t  offset -= extra_bytes;\n+\t  cmp_bytes = load_mode_size;\n+\t  bytes_to_compare = cmp_bytes;\n+\t}\n+\n+      /* The offset currently used is always kept in off_reg so that the\n+\t cleanup code on P8 can use it to extract the differing byte.  */\n+      emit_move_insn (off_reg, GEN_INT (offset));\n+\n+      rtx addr1 = gen_rtx_PLUS (Pmode, s1addr, off_reg);\n+      do_load_for_compare_from_addr (load_mode, s1data, addr1, orig_src1);\n+      rtx addr2 = gen_rtx_PLUS (Pmode, s2addr, off_reg);\n+      do_load_for_compare_from_addr (load_mode, s2data, addr2, orig_src2);\n+\n+      /* Cases to handle.  A and B are chunks of the two strings.\n+\t 1: Not end of comparison:\n+\t A != B: branch to cleanup code to compute result.\n+\t A == B: next block\n+\t 2: End of the inline comparison:\n+\t A != B: branch to cleanup code to compute result.\n+\t A == B: call strcmp/strncmp\n+\t 3: compared requested N bytes:\n+\t A == B: branch to result 0.\n+\t A != B: cleanup code to compute result.  */\n+\n+      unsigned HOST_WIDE_INT remain = bytes_to_compare - cmp_bytes;\n+\n+      if (checkzero)\n+\t{\n+\t  if (TARGET_P9_VECTOR)\n+\t    emit_insn (gen_vcmpnezb_p (vec_result, s1data, s2data));\n+\t  else\n+\t    {\n+\t      /* Emit instructions to do comparison and zero check.  */\n+\t      rtx cmp_res = gen_reg_rtx (load_mode);\n+\t      rtx cmp_zero = gen_reg_rtx (load_mode);\n+\t      rtx cmp_combined = gen_reg_rtx (load_mode);\n+\t      emit_insn (gen_altivec_eqv16qi (cmp_res, s1data, s2data));\n+\t      emit_insn (gen_altivec_eqv16qi (cmp_zero, s1data, zero_reg));\n+\t      emit_insn (gen_orcv16qi3 (vec_result, cmp_zero, cmp_res));\n+\t      emit_insn (gen_altivec_vcmpequb_p (cmp_combined, vec_result, zero_reg));\n+\t    }\n+\t}\n+      else\n+\temit_insn (gen_altivec_vcmpequb_p (vec_result, s1data, s2data));\n+\n+      bool branch_to_cleanup = (remain > 0 || equality_compare_rest);\n+      rtx cr6 = gen_rtx_REG (CCmode, CR6_REGNO);\n+      rtx dst_label;\n+      rtx cmp_rtx;\n+      if (branch_to_cleanup)\n+\t{\n+\t  /* Branch to cleanup code, otherwise fall through to do more\n+\t     compares.  P8 and P9 use different CR bits because on P8\n+\t     we are looking at the result of a comparsion vs a\n+\t     register of zeroes so the all-true condition means no\n+\t     difference or zero was found.  On P9, vcmpnezb sets a byte\n+\t     to 0xff if there is a mismatch or zero, so the all-false\n+\t     condition indicates we found no difference or zero.  */\n+\t  if (!cleanup_label)\n+\t    cleanup_label = gen_label_rtx ();\n+\t  dst_label = cleanup_label;\n+\t  if (TARGET_P9_VECTOR && checkzero)\n+\t    cmp_rtx = gen_rtx_NE (VOIDmode, cr6, const0_rtx);\n+\t  else\n+\t    cmp_rtx = gen_rtx_GE (VOIDmode, cr6, const0_rtx);\n+\t}\n+      else\n+\t{\n+\t  /* Branch to final return or fall through to cleanup,\n+\t     result is already set to 0.  */\n+\t  dst_label = final_move_label;\n+\t  if (TARGET_P9_VECTOR && checkzero)\n+\t    cmp_rtx = gen_rtx_EQ (VOIDmode, cr6, const0_rtx);\n+\t  else\n+\t    cmp_rtx = gen_rtx_LT (VOIDmode, cr6, const0_rtx);\n+\t}\n+\n+      rtx lab_ref = gen_rtx_LABEL_REF (VOIDmode, dst_label);\n+      rtx ifelse = gen_rtx_IF_THEN_ELSE (VOIDmode, cmp_rtx,\n+\t\t\t\t\t lab_ref, pc_rtx);\n+      rtx j2 = emit_jump_insn (gen_rtx_SET (pc_rtx, ifelse));\n+      JUMP_LABEL (j2) = dst_label;\n+      LABEL_NUSES (dst_label) += 1;\n+\n+      offset += cmp_bytes;\n+      bytes_to_compare -= cmp_bytes;\n+    }\n+  *p_cleanup_label = cleanup_label;\n+  return;\n+}\n+\n+/* Generate the final sequence that identifies the differing\n+   byte and generates the final result, taking into account\n+   zero bytes:\n+\n+   P8:\n+        vgbbd 0,0\n+        vsldoi 0,0,0,9\n+        mfvsrd 9,32\n+        addi 10,9,-1    # count trailing zero bits\n+        andc 9,10,9\n+        popcntd 9,9\n+        lbzx 10,28,9    # use that offset to load differing byte\n+        lbzx 3,29,9\n+        subf 3,3,10     # subtract for final result\n+\n+   P9:\n+\t vclzlsbb            # counts trailing bytes with lsb=0\n+\t vextublx            # extract differing byte\n+\n+   STR1 is the reg rtx for data from string 1.\n+   STR2 is the reg rtx for data from string 2.\n+   RESULT is the reg rtx for the comparison result.\n+   S1ADDR is the register to use for the base address of the first string.\n+   S2ADDR is the register to use for the base address of the second string.\n+   ORIG_SRC1 is the unmodified rtx for the first string.\n+   ORIG_SRC2 is the unmodified rtx for the second string.\n+   OFF_REG is the register to use for the string offset for loads.\n+   VEC_RESULT is the rtx for the vector result indicating the byte difference.  */\n+\n+static void\n+emit_final_compare_vec (rtx str1, rtx str2, rtx result,\n+\t\t\trtx s1addr, rtx s2addr,\n+\t\t\trtx orig_src1, rtx orig_src2,\n+\t\t\trtx off_reg, rtx vec_result)\n+{\n+\n+  if (TARGET_P9_VECTOR)\n+    {\n+      rtx diffix = gen_reg_rtx (SImode);\n+      rtx chr1 = gen_reg_rtx (SImode);\n+      rtx chr2 = gen_reg_rtx (SImode);\n+      rtx chr1_di = simplify_gen_subreg (DImode, chr1, SImode, 0);\n+      rtx chr2_di = simplify_gen_subreg (DImode, chr2, SImode, 0);\n+      emit_insn (gen_vclzlsbb_v16qi (diffix, vec_result));\n+      emit_insn (gen_vextublx (chr1, diffix, str1));\n+      emit_insn (gen_vextublx (chr2, diffix, str2));\n+      do_sub3 (result, chr1_di, chr2_di);\n+    }\n+  else\n+    {\n+      gcc_assert (TARGET_P8_VECTOR);\n+      rtx diffix = gen_reg_rtx (DImode);\n+      rtx result_gbbd = gen_reg_rtx (V16QImode);\n+      /* Since each byte of the input is either 00 or FF, the bytes in\n+\t dw0 and dw1 after vgbbd are all identical to each other.  */\n+      emit_insn (gen_p8v_vgbbd (result_gbbd, vec_result));\n+      /* For LE, we shift by 9 and get BA in the low two bytes then CTZ.\n+\t For BE, we shift by 7 and get AB in the high two bytes then CLZ.  */\n+      rtx result_shifted = gen_reg_rtx (V16QImode);\n+      int shift_amt = (BYTES_BIG_ENDIAN) ? 7 : 9;\n+      emit_insn (gen_altivec_vsldoi_v16qi (result_shifted, result_gbbd,\n+\t\t\t\t\t   result_gbbd, GEN_INT (shift_amt)));\n+\n+      rtx diffix_df = simplify_gen_subreg (DFmode, diffix, DImode, 0);\n+      emit_insn (gen_p8_mfvsrd_3_v16qi (diffix_df, result_shifted));\n+      rtx count = gen_reg_rtx (DImode);\n+\n+      if (BYTES_BIG_ENDIAN)\n+\temit_insn (gen_clzdi2 (count, diffix));\n+      else\n+\temit_insn (gen_ctzdi2 (count, diffix));\n+\n+      /* P8 doesn't have a good solution for extracting one byte from\n+\t a vsx reg like vextublx on P9 so we just compute the offset\n+\t of the differing byte and load it from each string.  */\n+      do_add3 (off_reg, off_reg, count);\n+\n+      rtx chr1 = gen_reg_rtx (QImode);\n+      rtx chr2 = gen_reg_rtx (QImode);\n+      rtx addr1 = gen_rtx_PLUS (Pmode, s1addr, off_reg);\n+      do_load_for_compare_from_addr (QImode, chr1, addr1, orig_src1);\n+      rtx addr2 = gen_rtx_PLUS (Pmode, s2addr, off_reg);\n+      do_load_for_compare_from_addr (QImode, chr2, addr2, orig_src2);\n+      machine_mode rmode = GET_MODE (result);\n+      rtx chr1_rm = simplify_gen_subreg (rmode, chr1, QImode, 0);\n+      rtx chr2_rm = simplify_gen_subreg (rmode, chr2, QImode, 0);\n+      do_sub3 (result, chr1_rm, chr2_rm);\n+    }\n+\n+  return;\n+}\n+\n /* Expand a block compare operation using loop code, and return true\n    if successful.  Return false if we should let the compiler generate\n    normal code, probably a memcmp call.\n@@ -1343,106 +1611,80 @@ expand_compare_loop (rtx operands[])\n   return true;\n }\n \n-/* Expand a block compare operation, and return true if successful.\n-   Return false if we should let the compiler generate normal code,\n-   probably a memcmp call.\n+/* Generate code to convert a DImode-plus-carry subtract result into\n+   a SImode result that has the same <0 / ==0 / >0 properties to\n+   produce the final result from memcmp.\n \n-   OPERANDS[0] is the target (result).\n-   OPERANDS[1] is the first source.\n-   OPERANDS[2] is the second source.\n-   OPERANDS[3] is the length.\n-   OPERANDS[4] is the alignment.  */\n-bool\n-expand_block_compare (rtx operands[])\n-{\n-  rtx target = operands[0];\n-  rtx orig_src1 = operands[1];\n-  rtx orig_src2 = operands[2];\n-  rtx bytes_rtx = operands[3];\n-  rtx align_rtx = operands[4];\n-  HOST_WIDE_INT cmp_bytes = 0;\n-  rtx src1 = orig_src1;\n-  rtx src2 = orig_src2;\n+   TARGET is the rtx for the register to receive the memcmp result.\n+   SUB_RESULT is the rtx for the register contining the subtract result.  */\n \n-  /* This case is complicated to handle because the subtract\n-     with carry instructions do not generate the 64-bit\n-     carry and so we must emit code to calculate it ourselves.\n-     We choose not to implement this yet.  */\n-  if (TARGET_32BIT && TARGET_POWERPC64)\n-    return false;\n-\n-  bool isP7 = (rs6000_tune == PROCESSOR_POWER7);\n-\n-  /* Allow this param to shut off all expansion.  */\n-  if (rs6000_block_compare_inline_limit == 0)\n-    return false;\n-\n-  /* targetm.slow_unaligned_access -- don't do unaligned stuff.\n-     However slow_unaligned_access returns true on P7 even though the\n-     performance of this code is good there.  */\n-  if (!isP7\n-      && (targetm.slow_unaligned_access (word_mode, MEM_ALIGN (orig_src1))\n-\t  || targetm.slow_unaligned_access (word_mode, MEM_ALIGN (orig_src2))))\n-    return false;\n-\n-  /* Unaligned l*brx traps on P7 so don't do this.  However this should\n-     not affect much because LE isn't really supported on P7 anyway.  */\n-  if (isP7 && !BYTES_BIG_ENDIAN)\n-    return false;\n-\n-  /* If this is not a fixed size compare, try generating loop code and\n-     if that fails just call memcmp.  */\n-  if (!CONST_INT_P (bytes_rtx))\n-    return expand_compare_loop (operands);\n-\n-  /* This must be a fixed size alignment.  */\n-  if (!CONST_INT_P (align_rtx))\n-    return false;\n-\n-  unsigned int base_align = UINTVAL (align_rtx) / BITS_PER_UNIT;\n+void\n+generate_6432_conversion(rtx target, rtx sub_result)\n+{\n+  /* We need to produce DI result from sub, then convert to target SI\n+     while maintaining <0 / ==0 / >0 properties.  This sequence works:\n+     subfc L,A,B\n+     subfe H,H,H\n+     popcntd L,L\n+     rldimi L,H,6,0\n \n-  gcc_assert (GET_MODE (target) == SImode);\n+     This is an alternate one Segher cooked up if somebody\n+     wants to expand this for something that doesn't have popcntd:\n+     subfc L,a,b\n+     subfe H,x,x\n+     addic t,L,-1\n+     subfe v,t,L\n+     or z,v,H\n \n-  /* Anything to move?  */\n-  unsigned HOST_WIDE_INT bytes = UINTVAL (bytes_rtx);\n-  if (bytes == 0)\n-    return true;\n+     And finally, p9 can just do this:\n+     cmpld A,B\n+     setb r */\n \n-  rtx tmp_reg_src1 = gen_reg_rtx (word_mode);\n-  rtx tmp_reg_src2 = gen_reg_rtx (word_mode);\n-  /* P7/P8 code uses cond for subfc. but P9 uses\n-     it for cmpld which needs CCUNSmode.  */\n-  rtx cond;\n-  if (TARGET_P9_MISC)\n-    cond = gen_reg_rtx (CCUNSmode);\n+  if (TARGET_64BIT)\n+    {\n+      rtx tmp_reg_ca = gen_reg_rtx (DImode);\n+      emit_insn (gen_subfdi3_carry_in_xx (tmp_reg_ca));\n+      rtx popcnt = gen_reg_rtx (DImode);\n+      emit_insn (gen_popcntddi2 (popcnt, sub_result));\n+      rtx tmp2 = gen_reg_rtx (DImode);\n+      emit_insn (gen_iordi3 (tmp2, popcnt, tmp_reg_ca));\n+      emit_insn (gen_movsi (target, gen_lowpart (SImode, tmp2)));\n+    }\n   else\n-    cond = gen_reg_rtx (CCmode);\n-\n-  /* Strategy phase.  How many ops will this take and should we expand it?  */\n-\n-  unsigned HOST_WIDE_INT offset = 0;\n-  machine_mode load_mode =\n-    select_block_compare_mode (offset, bytes, base_align);\n-  unsigned int load_mode_size = GET_MODE_SIZE (load_mode);\n-\n-  /* We don't want to generate too much code.  The loop code can take\n-     over for lengths greater than 31 bytes.  */\n-  unsigned HOST_WIDE_INT max_bytes = rs6000_block_compare_inline_limit;\n-  if (!IN_RANGE (bytes, 1, max_bytes))\n-    return expand_compare_loop (operands);\n-\n-  /* The code generated for p7 and older is not faster than glibc\n-     memcmp if alignment is small and length is not short, so bail\n-     out to avoid those conditions.  */\n-  if (!TARGET_EFFICIENT_OVERLAPPING_UNALIGNED\n-      && ((base_align == 1 && bytes > 16)\n-\t  || (base_align == 2 && bytes > 32)))\n-    return false;\n+    {\n+      rtx tmp_reg_ca = gen_reg_rtx (SImode);\n+      emit_insn (gen_subfsi3_carry_in_xx (tmp_reg_ca));\n+      rtx popcnt = gen_reg_rtx (SImode);\n+      emit_insn (gen_popcntdsi2 (popcnt, sub_result));\n+      emit_insn (gen_iorsi3 (target, popcnt, tmp_reg_ca));\n+    }\n+}\n \n-  bool generate_6432_conversion = false;\n-  rtx convert_label = NULL;\n-  rtx final_label = NULL;\n+/* Generate memcmp expansion using in-line non-loop GPR instructions.\n+   The bool return indicates whether code for a 64->32 conversion\n+   should be generated.\n+\n+   BYTES is the number of bytes to be compared.\n+   BASE_ALIGN is the minimum alignment for both blocks to compare.\n+   ORIG_SRC1 is the original pointer to the first block to compare.\n+   ORIG_SRC2 is the original pointer to the second block to compare.\n+   SUB_RESULT is the reg rtx for the result from the final subtract.\n+   COND is rtx for a condition register that will be used for the final\n+   compare on power9 or better.\n+   FINAL_RESULT is the reg rtx for the final memcmp result.\n+   P_CONVERT_LABEL is a pointer to rtx that will be used to store the\n+   label generated for a branch to the 64->32 code, if such a branch\n+   is needed.\n+   P_FINAL_LABEL is a pointer to rtx that will be used to store the label\n+   for the end of the memcmp if a branch there is needed.\n+*/\n \n+bool\n+expand_block_compare_gpr(unsigned HOST_WIDE_INT bytes, unsigned int base_align,\n+\t\t\t rtx orig_src1, rtx orig_src2,\n+\t\t\t rtx sub_result, rtx cond, rtx final_result,\n+\t\t\t rtx *p_convert_label, rtx *p_final_label)\n+{\n   /* Example of generated code for 18 bytes aligned 1 byte.\n      Compiled with -fno-reorder-blocks for clarity.\n              ldbrx 10,31,8\n@@ -1473,6 +1715,18 @@ expand_block_compare (rtx operands[])\n      if the difference is found there, then a final block of HImode that skips\n      the DI->SI conversion.  */\n \n+  unsigned HOST_WIDE_INT offset = 0;\n+  unsigned int load_mode_size;\n+  HOST_WIDE_INT cmp_bytes = 0;\n+  rtx src1 = orig_src1;\n+  rtx src2 = orig_src2;\n+  rtx tmp_reg_src1 = gen_reg_rtx (word_mode);\n+  rtx tmp_reg_src2 = gen_reg_rtx (word_mode);\n+  bool need_6432_conv = false;\n+  rtx convert_label = NULL;\n+  rtx final_label = NULL;\n+  machine_mode load_mode;\n+\n   while (bytes > 0)\n     {\n       unsigned int align = compute_current_alignment (base_align, offset);\n@@ -1536,15 +1790,15 @@ expand_block_compare (rtx operands[])\n \t}\n \n       int remain = bytes - cmp_bytes;\n-      if (GET_MODE_SIZE (GET_MODE (target)) > GET_MODE_SIZE (load_mode))\n+      if (GET_MODE_SIZE (GET_MODE (final_result)) > GET_MODE_SIZE (load_mode))\n \t{\n-\t  /* Target is larger than load size so we don't need to\n+\t  /* Final_result is larger than load size so we don't need to\n \t     reduce result size.  */\n \n \t  /* We previously did a block that need 64->32 conversion but\n \t     the current block does not, so a label is needed to jump\n \t     to the end.  */\n-\t  if (generate_6432_conversion && !final_label)\n+\t  if (need_6432_conv && !final_label)\n \t    final_label = gen_label_rtx ();\n \n \t  if (remain > 0)\n@@ -1557,7 +1811,7 @@ expand_block_compare (rtx operands[])\n \t      rtx tmp = gen_rtx_MINUS (word_mode, tmp_reg_src1, tmp_reg_src2);\n \t      rtx cr = gen_reg_rtx (CCmode);\n \t      rs6000_emit_dot_insn (tmp_reg_src2, tmp, 2, cr);\n-\t      emit_insn (gen_movsi (target,\n+\t      emit_insn (gen_movsi (final_result,\n \t\t\t\t    gen_lowpart (SImode, tmp_reg_src2)));\n \t      rtx ne_rtx = gen_rtx_NE (VOIDmode, cr, const0_rtx);\n \t      rtx ifelse = gen_rtx_IF_THEN_ELSE (VOIDmode, ne_rtx,\n@@ -1572,11 +1826,11 @@ expand_block_compare (rtx operands[])\n \t\t{\n \t\t  emit_insn (gen_subdi3 (tmp_reg_src2, tmp_reg_src1,\n \t\t\t\t\t tmp_reg_src2));\n-\t\t  emit_insn (gen_movsi (target,\n+\t\t  emit_insn (gen_movsi (final_result,\n \t\t\t\t\tgen_lowpart (SImode, tmp_reg_src2)));\n \t\t}\n \t      else\n-\t\temit_insn (gen_subsi3 (target, tmp_reg_src1, tmp_reg_src2));\n+\t\temit_insn (gen_subsi3 (final_result, tmp_reg_src1, tmp_reg_src2));\n \n \t      if (final_label)\n \t\t{\n@@ -1591,9 +1845,9 @@ expand_block_compare (rtx operands[])\n       else\n \t{\n \t  /* Do we need a 64->32 conversion block? We need the 64->32\n-\t     conversion even if target size == load_mode size because\n+\t     conversion even if final_result size == load_mode size because\n \t     the subtract generates one extra bit.  */\n-\t  generate_6432_conversion = true;\n+\t  need_6432_conv = true;\n \n \t  if (remain > 0)\n \t    {\n@@ -1604,20 +1858,27 @@ expand_block_compare (rtx operands[])\n \t      rtx cvt_ref = gen_rtx_LABEL_REF (VOIDmode, convert_label);\n \t      if (TARGET_P9_MISC)\n \t\t{\n-\t\t/* Generate a compare, and convert with a setb later.  */\n+\t\t/* Generate a compare, and convert with a setb later.\n+\t\t   Use cond that is passed in because the caller needs\n+\t\t   to use it for the 64->32 conversion later.  */\n \t\t  rtx cmp = gen_rtx_COMPARE (CCUNSmode, tmp_reg_src1,\n \t\t\t\t\t     tmp_reg_src2);\n \t\t  emit_insn (gen_rtx_SET (cond, cmp));\n \t\t}\n \t      else\n-\t\t/* Generate a subfc. and use the longer\n-\t\t   sequence for conversion.  */\n-\t\tif (TARGET_64BIT)\n-\t\t  emit_insn (gen_subfdi3_carry_dot2 (tmp_reg_src2, tmp_reg_src2,\n-\t\t\t\t\t\t     tmp_reg_src1, cond));\n-\t\telse\n-\t\t  emit_insn (gen_subfsi3_carry_dot2 (tmp_reg_src2, tmp_reg_src2,\n-\t\t\t\t\t\t     tmp_reg_src1, cond));\n+\t\t{\n+\t\t  /* Generate a subfc. and use the longer sequence for\n+\t\t     conversion.  Cond is not used outside this\n+\t\t     function in this case.  */\n+\t\t  cond = gen_reg_rtx (CCmode);\n+\t\t  if (TARGET_64BIT)\n+\t\t    emit_insn (gen_subfdi3_carry_dot2 (sub_result, tmp_reg_src2,\n+\t\t\t\t\t\t       tmp_reg_src1, cond));\n+\t\t  else\n+\t\t    emit_insn (gen_subfsi3_carry_dot2 (sub_result, tmp_reg_src2,\n+\t\t\t\t\t\t       tmp_reg_src1, cond));\n+\t\t}\n+\n \t      rtx ne_rtx = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n \t      rtx ifelse = gen_rtx_IF_THEN_ELSE (VOIDmode, ne_rtx,\n \t\t\t\t\t\t cvt_ref, pc_rtx);\n@@ -1637,10 +1898,10 @@ expand_block_compare (rtx operands[])\n \t\t}\n \t      else\n \t\tif (TARGET_64BIT)\n-\t\t  emit_insn (gen_subfdi3_carry (tmp_reg_src2, tmp_reg_src2,\n+\t\t  emit_insn (gen_subfdi3_carry (sub_result, tmp_reg_src2,\n \t\t\t\t\t\ttmp_reg_src1));\n \t\telse\n-\t\t  emit_insn (gen_subfsi3_carry (tmp_reg_src2, tmp_reg_src2,\n+\t\t  emit_insn (gen_subfsi3_carry (sub_result, tmp_reg_src2,\n \t\t\t\t\t\ttmp_reg_src1));\n \t    }\n \t}\n@@ -1649,58 +1910,168 @@ expand_block_compare (rtx operands[])\n       bytes -= cmp_bytes;\n     }\n \n-  if (generate_6432_conversion)\n+  if (convert_label)\n+    *p_convert_label = convert_label;\n+  if (final_label)\n+    *p_final_label = final_label;\n+  return need_6432_conv;\n+}\n+\n+/* Expand a block compare operation, and return true if successful.\n+   Return false if we should let the compiler generate normal code,\n+   probably a memcmp call.\n+\n+   OPERANDS[0] is the target (result).\n+   OPERANDS[1] is the first source.\n+   OPERANDS[2] is the second source.\n+   OPERANDS[3] is the length.\n+   OPERANDS[4] is the alignment.  */\n+bool\n+expand_block_compare (rtx operands[])\n+{\n+  rtx target = operands[0];\n+  rtx orig_src1 = operands[1];\n+  rtx orig_src2 = operands[2];\n+  rtx bytes_rtx = operands[3];\n+  rtx align_rtx = operands[4];\n+\n+  /* This case is complicated to handle because the subtract\n+     with carry instructions do not generate the 64-bit\n+     carry and so we must emit code to calculate it ourselves.\n+     We choose not to implement this yet.  */\n+  if (TARGET_32BIT && TARGET_POWERPC64)\n+    return false;\n+\n+  bool isP7 = (rs6000_tune == PROCESSOR_POWER7);\n+\n+  /* Allow this param to shut off all expansion.  */\n+  if (rs6000_block_compare_inline_limit == 0)\n+    return false;\n+\n+  /* targetm.slow_unaligned_access -- don't do unaligned stuff.\n+     However slow_unaligned_access returns true on P7 even though the\n+     performance of this code is good there.  */\n+  if (!isP7\n+      && (targetm.slow_unaligned_access (word_mode, MEM_ALIGN (orig_src1))\n+\t  || targetm.slow_unaligned_access (word_mode, MEM_ALIGN (orig_src2))))\n+    return false;\n+\n+  /* Unaligned l*brx traps on P7 so don't do this.  However this should\n+     not affect much because LE isn't really supported on P7 anyway.  */\n+  if (isP7 && !BYTES_BIG_ENDIAN)\n+    return false;\n+\n+  /* If this is not a fixed size compare, try generating loop code and\n+     if that fails just call memcmp.  */\n+  if (!CONST_INT_P (bytes_rtx))\n+    return expand_compare_loop (operands);\n+\n+  /* This must be a fixed size alignment.  */\n+  if (!CONST_INT_P (align_rtx))\n+    return false;\n+\n+  unsigned int base_align = UINTVAL (align_rtx) / BITS_PER_UNIT;\n+\n+  gcc_assert (GET_MODE (target) == SImode);\n+\n+  /* Anything to move?  */\n+  unsigned HOST_WIDE_INT bytes = UINTVAL (bytes_rtx);\n+  if (bytes == 0)\n+    return true;\n+\n+  /* P7/P8 code uses cond for subfc. but P9 uses\n+     it for cmpld which needs CCUNSmode.  */\n+  rtx cond = NULL;\n+  if (TARGET_P9_MISC)\n+    cond = gen_reg_rtx (CCUNSmode);\n+\n+  /* Is it OK to use vec/vsx for this.  TARGET_VSX means we have at\n+     least POWER7 but we use TARGET_EFFICIENT_UNALIGNED_VSX which is\n+     at least POWER8.  That way we can rely on overlapping compares to\n+     do the final comparison of less than 16 bytes.  Also I do not\n+     want to deal with making this work for 32 bits.  In addition, we\n+     have to make sure that we have at least P8_VECTOR (we don't allow\n+     P9_VECTOR without P8_VECTOR).  */\n+  int use_vec = (bytes >= 33 && !TARGET_32BIT\n+\t\t && TARGET_EFFICIENT_UNALIGNED_VSX && TARGET_P8_VECTOR);\n+\n+  /* We don't want to generate too much code.  The loop code can take\n+     over for lengths greater than 31 bytes.  */\n+  unsigned HOST_WIDE_INT max_bytes = rs6000_block_compare_inline_limit;\n+\n+  /* Don't generate too much code if vsx was disabled.  */\n+  if (!use_vec && max_bytes > 1)\n+    max_bytes = ((max_bytes + 1) / 2) - 1;\n+\n+  if (!IN_RANGE (bytes, 1, max_bytes))\n+    return expand_compare_loop (operands);\n+\n+  /* The code generated for p7 and older is not faster than glibc\n+     memcmp if alignment is small and length is not short, so bail\n+     out to avoid those conditions.  */\n+  if (!TARGET_EFFICIENT_OVERLAPPING_UNALIGNED\n+      && ((base_align == 1 && bytes > 16)\n+\t  || (base_align == 2 && bytes > 32)))\n+    return false;\n+\n+  rtx final_label = NULL;\n+\n+  if (use_vec)\n     {\n-      if (convert_label)\n-\temit_label (convert_label);\n-\n-      /* We need to produce DI result from sub, then convert to target SI\n-\t while maintaining <0 / ==0 / >0 properties.  This sequence works:\n-\t subfc L,A,B\n-\t subfe H,H,H\n-\t popcntd L,L\n-\t rldimi L,H,6,0\n-\n-\t This is an alternate one Segher cooked up if somebody\n-\t wants to expand this for something that doesn't have popcntd:\n-\t subfc L,a,b\n-\t subfe H,x,x\n-\t addic t,L,-1\n-\t subfe v,t,L\n-\t or z,v,H\n-\n-\t And finally, p9 can just do this:\n-\t cmpld A,B\n-\t setb r */\n+      rtx final_move_label = gen_label_rtx ();\n+      rtx s1addr = gen_reg_rtx (Pmode);\n+      rtx s2addr = gen_reg_rtx (Pmode);\n+      rtx off_reg = gen_reg_rtx (Pmode);\n+      rtx cleanup_label = NULL;\n+      rtx vec_result = gen_reg_rtx (V16QImode);\n+      rtx s1data = gen_reg_rtx (V16QImode);\n+      rtx s2data = gen_reg_rtx (V16QImode);\n+      rtx result_reg = gen_reg_rtx (word_mode);\n+      emit_move_insn (result_reg, GEN_INT (0));\n \n-      if (TARGET_P9_MISC)\n-\t{\n-\t  emit_insn (gen_setb_unsigned (target, cond));\n-\t}\n-      else\n+      expand_cmp_vec_sequence (bytes, orig_src1, orig_src2,\n+\t\t\t       s1addr, s2addr, off_reg, s1data, s2data,\n+\t\t\t       vec_result, false,\n+\t\t\t       &cleanup_label, final_move_label, false);\n+\n+      if (cleanup_label)\n+\temit_label (cleanup_label);\n+\n+      emit_insn (gen_one_cmplv16qi2 (vec_result, vec_result));\n+\n+      emit_final_compare_vec (s1data, s2data, result_reg,\n+\t\t\t      s1addr, s2addr, orig_src1, orig_src2,\n+\t\t\t      off_reg, vec_result);\n+\n+      emit_label (final_move_label);\n+      emit_insn (gen_movsi (target,\n+\t\t\t    gen_lowpart (SImode, result_reg)));\n+    }\n+  else\n+    { /* generate GPR code */\n+\n+      rtx convert_label = NULL;\n+      rtx sub_result = gen_reg_rtx (word_mode);\n+      bool need_6432_conversion =\n+\texpand_block_compare_gpr(bytes, base_align,\n+\t\t\t\t orig_src1, orig_src2,\n+\t\t\t\t sub_result, cond, target,\n+\t\t\t\t &convert_label, &final_label);\n+\n+      if (need_6432_conversion)\n \t{\n-\t  if (TARGET_64BIT)\n-\t    {\n-\t      rtx tmp_reg_ca = gen_reg_rtx (DImode);\n-\t      emit_insn (gen_subfdi3_carry_in_xx (tmp_reg_ca));\n-\t      emit_insn (gen_popcntddi2 (tmp_reg_src2, tmp_reg_src2));\n-\t      emit_insn (gen_iordi3 (tmp_reg_src2, tmp_reg_src2, tmp_reg_ca));\n-\t      emit_insn (gen_movsi (target, gen_lowpart (SImode, tmp_reg_src2)));\n-\t    }\n+\t  if (convert_label)\n+\t    emit_label (convert_label);\n+\t  if (TARGET_P9_MISC)\n+\t    emit_insn (gen_setb_unsigned (target, cond));\n \t  else\n-\t    {\n-\t      rtx tmp_reg_ca = gen_reg_rtx (SImode);\n-\t      emit_insn (gen_subfsi3_carry_in_xx (tmp_reg_ca));\n-\t      emit_insn (gen_popcntdsi2 (tmp_reg_src2, tmp_reg_src2));\n-\t      emit_insn (gen_iorsi3 (target, tmp_reg_src2, tmp_reg_ca));\n-\t    }\n+\t    generate_6432_conversion(target, sub_result);\n \t}\n     }\n \n   if (final_label)\n     emit_label (final_label);\n \n-  gcc_assert (bytes == 0);\n   return true;\n }\n \n@@ -1808,7 +2179,7 @@ expand_strncmp_gpr_sequence (unsigned HOST_WIDE_INT bytes_to_compare,\n \t}\n       rtx addr1 = gen_rtx_PLUS (Pmode, src1_addr, offset_rtx);\n       rtx addr2 = gen_rtx_PLUS (Pmode, src2_addr, offset_rtx);\n-\t  \n+\n       do_load_for_compare_from_addr (load_mode, tmp_reg_src1, addr1, orig_src1);\n       do_load_for_compare_from_addr (load_mode, tmp_reg_src2, addr2, orig_src2);\n \n@@ -1966,176 +2337,6 @@ expand_strncmp_gpr_sequence (unsigned HOST_WIDE_INT bytes_to_compare,\n   return;\n }\n \n-/* Generate the sequence of compares for strcmp/strncmp using vec/vsx\n-   instructions.\n-\n-   BYTES_TO_COMPARE is the number of bytes to be compared.\n-   ORIG_SRC1 is the unmodified rtx for the first string.\n-   ORIG_SRC2 is the unmodified rtx for the second string.\n-   S1ADDR is the register to use for the base address of the first string.\n-   S2ADDR is the register to use for the base address of the second string.\n-   OFF_REG is the register to use for the string offset for loads.\n-   S1DATA is the register for loading the first string.\n-   S2DATA is the register for loading the second string.\n-   VEC_RESULT is the rtx for the vector result indicating the byte difference.\n-   EQUALITY_COMPARE_REST is a flag to indicate we need to make a cleanup call\n-   to strcmp/strncmp if we have equality at the end of the inline comparison.\n-   P_CLEANUP_LABEL is a pointer to rtx for a label we generate if we need code to clean up\n-   and generate the final comparison result.\n-   FINAL_MOVE_LABEL is rtx for a label we can branch to when we can just\n-   set the final result.  */\n-static void\n-expand_strncmp_vec_sequence (unsigned HOST_WIDE_INT bytes_to_compare,\n-\t\t\t     rtx orig_src1, rtx orig_src2,\n-\t\t\t     rtx s1addr, rtx s2addr, rtx off_reg,\n-\t\t\t     rtx s1data, rtx s2data,\n-\t\t\t     rtx vec_result, bool equality_compare_rest,\n-\t\t\t     rtx *p_cleanup_label, rtx final_move_label)\n-{\n-  machine_mode load_mode;\n-  unsigned int load_mode_size;\n-  unsigned HOST_WIDE_INT cmp_bytes = 0;\n-  unsigned HOST_WIDE_INT offset = 0;\n-\n-  gcc_assert (p_cleanup_label != NULL);\n-  rtx cleanup_label = *p_cleanup_label;\n-\n-  emit_move_insn (s1addr, force_reg (Pmode, XEXP (orig_src1, 0)));\n-  emit_move_insn (s2addr, force_reg (Pmode, XEXP (orig_src2, 0)));\n-\n-  unsigned int i;\n-  rtx zr[16];\n-  for (i = 0; i < 16; i++)\n-    zr[i] = GEN_INT (0);\n-  rtvec zv = gen_rtvec_v (16, zr);\n-  rtx zero_reg = gen_reg_rtx (V16QImode);\n-  rs6000_expand_vector_init (zero_reg, gen_rtx_PARALLEL (V16QImode, zv));\n-\n-  while (bytes_to_compare > 0)\n-    {\n-      /* VEC/VSX compare sequence for P8:\n-\t check each 16B with:\n-\t lxvd2x 32,28,8\n-\t lxvd2x 33,29,8\n-\t vcmpequb 2,0,1  # compare strings\n-\t vcmpequb 4,0,3  # compare w/ 0\n-\t xxlorc 37,36,34       # first FF byte is either mismatch or end of string\n-\t vcmpequb. 7,5,3  # reg 7 contains 0\n-\t bnl 6,.Lmismatch\n-\n-\t For the P8 LE case, we use lxvd2x and compare full 16 bytes\n-\t but then use use vgbbd and a shift to get two bytes with the\n-\t information we need in the correct order.\n-\n-\t VEC/VSX compare sequence if TARGET_P9_VECTOR:\n-\t lxvb16x/lxvb16x     # load 16B of each string\n-\t vcmpnezb.           # produces difference location or zero byte location\n-\t bne 6,.Lmismatch\n-\n-\t Use the overlapping compare trick for the last block if it is\n-\t less than 16 bytes.\n-      */\n-\n-      load_mode = V16QImode;\n-      load_mode_size = GET_MODE_SIZE (load_mode);\n-\n-      if (bytes_to_compare >= load_mode_size)\n-\tcmp_bytes = load_mode_size;\n-      else\n-\t{\n-\t  /* Move this load back so it doesn't go past the end.  P8/P9\n-\t     can do this efficiently.  This is never called with less\n-\t     than 16 bytes so we should always be able to do this.  */\n-\t  unsigned int extra_bytes = load_mode_size - bytes_to_compare;\n-\t  cmp_bytes = bytes_to_compare;\n-\t  gcc_assert (offset > extra_bytes);\n-\t  offset -= extra_bytes;\n-\t  cmp_bytes = load_mode_size;\n-\t  bytes_to_compare = cmp_bytes;\n-\t}\n-\n-      /* The offset currently used is always kept in off_reg so that the\n-\t cleanup code on P8 can use it to extract the differing byte.  */\n-      emit_move_insn (off_reg, GEN_INT (offset));\n-\n-      rtx addr1 = gen_rtx_PLUS (Pmode, s1addr, off_reg);\n-      do_load_for_compare_from_addr (load_mode, s1data, addr1, orig_src1);\n-      rtx addr2 = gen_rtx_PLUS (Pmode, s2addr, off_reg);\n-      do_load_for_compare_from_addr (load_mode, s2data, addr2, orig_src2);\n-\n-      /* Cases to handle.  A and B are chunks of the two strings.\n-\t 1: Not end of comparison:\n-\t A != B: branch to cleanup code to compute result.\n-\t A == B: next block\n-\t 2: End of the inline comparison:\n-\t A != B: branch to cleanup code to compute result.\n-\t A == B: call strcmp/strncmp\n-\t 3: compared requested N bytes:\n-\t A == B: branch to result 0.\n-\t A != B: cleanup code to compute result.  */\n-\n-      unsigned HOST_WIDE_INT remain = bytes_to_compare - cmp_bytes;\n-\n-      if (TARGET_P9_VECTOR)\n-\temit_insn (gen_vcmpnezb_p (vec_result, s1data, s2data));\n-      else\n-\t{\n-\t  /* Emit instructions to do comparison and zero check.  */\n-\t  rtx cmp_res = gen_reg_rtx (load_mode);\n-\t  rtx cmp_zero = gen_reg_rtx (load_mode);\n-\t  rtx cmp_combined = gen_reg_rtx (load_mode);\n-\t  emit_insn (gen_altivec_eqv16qi (cmp_res, s1data, s2data));\n-\t  emit_insn (gen_altivec_eqv16qi (cmp_zero, s1data, zero_reg));\n-\t  emit_insn (gen_orcv16qi3 (vec_result, cmp_zero, cmp_res));\n-\t  emit_insn (gen_altivec_vcmpequb_p (cmp_combined, vec_result, zero_reg));\n-\t}\n-\n-      bool branch_to_cleanup = (remain > 0 || equality_compare_rest);\n-      rtx cr6 = gen_rtx_REG (CCmode, CR6_REGNO);\n-      rtx dst_label;\n-      rtx cmp_rtx;\n-      if (branch_to_cleanup)\n-\t{\n-\t  /* Branch to cleanup code, otherwise fall through to do more\n-\t     compares.  P8 and P9 use different CR bits because on P8\n-\t     we are looking at the result of a comparsion vs a\n-\t     register of zeroes so the all-true condition means no\n-\t     difference or zero was found.  On P9, vcmpnezb sets a byte\n-\t     to 0xff if there is a mismatch or zero, so the all-false\n-\t     condition indicates we found no difference or zero.  */\n-\t  if (!cleanup_label)\n-\t    cleanup_label = gen_label_rtx ();\n-\t  dst_label = cleanup_label;\n-\t  if (TARGET_P9_VECTOR)\n-\t    cmp_rtx = gen_rtx_NE (VOIDmode, cr6, const0_rtx);\n-\t  else\n-\t    cmp_rtx = gen_rtx_GE (VOIDmode, cr6, const0_rtx);\n-\t}\n-      else\n-\t{\n-\t  /* Branch to final return or fall through to cleanup,\n-\t     result is already set to 0.  */\n-\t  dst_label = final_move_label;\n-\t  if (TARGET_P9_VECTOR)\n-\t    cmp_rtx = gen_rtx_EQ (VOIDmode, cr6, const0_rtx);\n-\t  else\n-\t    cmp_rtx = gen_rtx_LT (VOIDmode, cr6, const0_rtx);\n-\t}\n-\n-      rtx lab_ref = gen_rtx_LABEL_REF (VOIDmode, dst_label);\n-      rtx ifelse = gen_rtx_IF_THEN_ELSE (VOIDmode, cmp_rtx,\n-\t\t\t\t\t lab_ref, pc_rtx);\n-      rtx j2 = emit_jump_insn (gen_rtx_SET (pc_rtx, ifelse));\n-      JUMP_LABEL (j2) = dst_label;\n-      LABEL_NUSES (dst_label) += 1;\n-\n-      offset += cmp_bytes;\n-      bytes_to_compare -= cmp_bytes;\n-    }\n-  *p_cleanup_label = cleanup_label;\n-  return;\n-}\n-\n /* Generate the final sequence that identifies the differing\n    byte and generates the final result, taking into account\n    zero bytes:\n@@ -2190,97 +2391,6 @@ emit_final_str_compare_gpr (rtx str1, rtx str2, rtx result)\n   return;\n }\n \n-/* Generate the final sequence that identifies the differing\n-   byte and generates the final result, taking into account\n-   zero bytes:\n-\n-   P8:\n-        vgbbd 0,0\n-        vsldoi 0,0,0,9\n-        mfvsrd 9,32\n-        addi 10,9,-1    # count trailing zero bits\n-        andc 9,10,9\n-        popcntd 9,9\n-        lbzx 10,28,9    # use that offset to load differing byte\n-        lbzx 3,29,9\n-        subf 3,3,10     # subtract for final result\n-\n-   P9:\n-\t vclzlsbb            # counts trailing bytes with lsb=0\n-\t vextublx            # extract differing byte\n-\n-   STR1 is the reg rtx for data from string 1.\n-   STR2 is the reg rtx for data from string 2.\n-   RESULT is the reg rtx for the comparison result.\n-   S1ADDR is the register to use for the base address of the first string.\n-   S2ADDR is the register to use for the base address of the second string.\n-   ORIG_SRC1 is the unmodified rtx for the first string.\n-   ORIG_SRC2 is the unmodified rtx for the second string.\n-   OFF_REG is the register to use for the string offset for loads.\n-   VEC_RESULT is the rtx for the vector result indicating the byte difference.\n-  */\n-\n-static void\n-emit_final_str_compare_vec (rtx str1, rtx str2, rtx result,\n-\t\t\t    rtx s1addr, rtx s2addr,\n-\t\t\t    rtx orig_src1, rtx orig_src2,\n-\t\t\t    rtx off_reg, rtx vec_result)\n-{\n-  if (TARGET_P9_VECTOR)\n-    {\n-      rtx diffix = gen_reg_rtx (SImode);\n-      rtx chr1 = gen_reg_rtx (SImode);\n-      rtx chr2 = gen_reg_rtx (SImode);\n-      rtx chr1_di = simplify_gen_subreg (DImode, chr1, SImode, 0);\n-      rtx chr2_di = simplify_gen_subreg (DImode, chr2, SImode, 0);\n-      emit_insn (gen_vclzlsbb_v16qi (diffix, vec_result));\n-      emit_insn (gen_vextublx (chr1, diffix, str1));\n-      emit_insn (gen_vextublx (chr2, diffix, str2));\n-      do_sub3 (result, chr1_di, chr2_di);\n-    }\n-  else\n-    {\n-      gcc_assert (TARGET_P8_VECTOR);\n-      rtx diffix = gen_reg_rtx (DImode);\n-      rtx result_gbbd = gen_reg_rtx (V16QImode);\n-      /* Since each byte of the input is either 00 or FF, the bytes in\n-\t dw0 and dw1 after vgbbd are all identical to each other.  */\n-      emit_insn (gen_p8v_vgbbd (result_gbbd, vec_result));\n-      /* For LE, we shift by 9 and get BA in the low two bytes then CTZ.\n-\t For BE, we shift by 7 and get AB in the high two bytes then CLZ.  */\n-      rtx result_shifted = gen_reg_rtx (V16QImode);\n-      int shift_amt = (BYTES_BIG_ENDIAN) ? 7 : 9;\n-      emit_insn (gen_altivec_vsldoi_v16qi (result_shifted,result_gbbd,result_gbbd, GEN_INT (shift_amt)));\n-\n-      rtx diffix_df = simplify_gen_subreg (DFmode, diffix, DImode, 0);\n-      emit_insn (gen_p8_mfvsrd_3_v16qi (diffix_df, result_shifted));\n-      rtx count = gen_reg_rtx (DImode);\n-\n-      if (BYTES_BIG_ENDIAN)\n-\temit_insn (gen_clzdi2 (count, diffix));\n-      else\n-\temit_insn (gen_ctzdi2 (count, diffix));\n-\n-      /* P8 doesn't have a good solution for extracting one byte from\n-\t a vsx reg like vextublx on P9 so we just compute the offset\n-\t of the differing byte and load it from each string.  */\n-      do_add3 (off_reg, off_reg, count);\n-\n-      rtx chr1 = gen_reg_rtx (QImode);\n-      rtx chr2 = gen_reg_rtx (QImode);\n-      rtx addr1 = gen_rtx_PLUS (Pmode, s1addr, off_reg);\n-      do_load_for_compare_from_addr (QImode, chr1, addr1, orig_src1);\n-      rtx addr2 = gen_rtx_PLUS (Pmode, s2addr, off_reg);\n-      do_load_for_compare_from_addr (QImode, chr2, addr2, orig_src2);\n-      machine_mode rmode = GET_MODE (result);\n-      rtx chr1_rm = simplify_gen_subreg (rmode, chr1, QImode, 0);\n-      rtx chr2_rm = simplify_gen_subreg (rmode, chr2, QImode, 0);\n-      do_sub3 (result, chr1_rm, chr2_rm);\n-    }\n-\n-  return;\n-}\n-\n /* Expand a string compare operation with length, and return\n    true if successful.  Return false if we should let the\n    compiler generate normal code, probably a strncmp call.\n@@ -2490,13 +2600,13 @@ expand_strn_compare (rtx operands[], int no_length)\n       off_reg = gen_reg_rtx (Pmode);\n       vec_result = gen_reg_rtx (load_mode);\n       emit_move_insn (result_reg, GEN_INT (0));\n-      expand_strncmp_vec_sequence (compare_length,\n-\t\t\t\t   orig_src1, orig_src2,\n-\t\t\t\t   s1addr, s2addr, off_reg,\n-\t\t\t\t   tmp_reg_src1, tmp_reg_src2,\n-\t\t\t\t   vec_result,\n-\t\t\t\t   equality_compare_rest,\n-\t\t\t\t   &cleanup_label, final_move_label);\n+      expand_cmp_vec_sequence (compare_length,\n+\t\t\t       orig_src1, orig_src2,\n+\t\t\t       s1addr, s2addr, off_reg,\n+\t\t\t       tmp_reg_src1, tmp_reg_src2,\n+\t\t\t       vec_result,\n+\t\t\t       equality_compare_rest,\n+\t\t\t       &cleanup_label, final_move_label, true);\n     }\n   else\n     expand_strncmp_gpr_sequence (compare_length, base_align,\n@@ -2545,9 +2655,9 @@ expand_strn_compare (rtx operands[], int no_length)\n     emit_label (cleanup_label);\n \n   if (use_vec)\n-    emit_final_str_compare_vec (tmp_reg_src1, tmp_reg_src2, result_reg,\n-\t\t\t\ts1addr, s2addr, orig_src1, orig_src2,\n-\t\t\t\toff_reg, vec_result);\n+    emit_final_compare_vec (tmp_reg_src1, tmp_reg_src2, result_reg,\n+\t\t\t    s1addr, s2addr, orig_src1, orig_src2,\n+\t\t\t    off_reg, vec_result);\n   else\n     emit_final_str_compare_gpr (tmp_reg_src1, tmp_reg_src2, result_reg);\n "}, {"sha": "794f887bbea3d7fd3a3065e1b2f5cb8d69e5e668", "filename": "gcc/config/rs6000/rs6000.opt", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/37ae4739bc8277539b16fbcf5294f19b082d5c79/gcc%2Fconfig%2Frs6000%2Frs6000.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/37ae4739bc8277539b16fbcf5294f19b082d5c79/gcc%2Fconfig%2Frs6000%2Frs6000.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.opt?ref=37ae4739bc8277539b16fbcf5294f19b082d5c79", "patch": "@@ -326,7 +326,7 @@ Target Report Var(rs6000_block_move_inline_limit) Init(0) RejectNegative Joined\n Max number of bytes to move inline.\n \n mblock-compare-inline-limit=\n-Target Report Var(rs6000_block_compare_inline_limit) Init(31) RejectNegative Joined UInteger Save\n+Target Report Var(rs6000_block_compare_inline_limit) Init(63) RejectNegative Joined UInteger Save\n Max number of bytes to compare without loops.\n \n mblock-compare-inline-loop-limit="}]}