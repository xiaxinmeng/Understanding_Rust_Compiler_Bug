{"sha": "30fb3231107d372c2e9df88e18714baae783870e", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MzBmYjMyMzExMDdkMzcyYzJlOWRmODhlMTg3MTRiYWFlNzgzODcwZQ==", "commit": {"author": {"name": "H.J. Lu", "email": "hongjiu.lu@intel.com", "date": "2003-06-06T13:52:17Z"}, "committer": {"name": "H.J. Lu", "email": "hjl@gcc.gnu.org", "date": "2003-06-06T13:52:17Z"}, "message": "config.gcc (extra_headers): Add emmintrin.h for i[34567]86-*-* and x86_64-*-*.\n\n2003-06-06  H.J. Lu <hongjiu.lu@intel.com>\n\n\t* config.gcc (extra_headers): Add emmintrin.h for i[34567]86-*-*\n\tand x86_64-*-*.\n\n\t* config/i386/mmintrin.h: Update version and add alternate\n\tintrinsic names.\n\t* config/i386/xmmintrin.h: Likewise.\n\n\t* config/i386/xmmintrin.h: Include <emmintrin.h>. Move SSE2\n\tintrinsics to ...\n\t* config/i386/emmintrin.h: Here. New file.\n\nFrom-SVN: r67543", "tree": {"sha": "c73c60b1e5e30e770cc5ee2f5e27968a785c19ca", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/c73c60b1e5e30e770cc5ee2f5e27968a785c19ca"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/30fb3231107d372c2e9df88e18714baae783870e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/30fb3231107d372c2e9df88e18714baae783870e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/30fb3231107d372c2e9df88e18714baae783870e", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/30fb3231107d372c2e9df88e18714baae783870e/comments", "author": {"login": "hjl-tools", "id": 1072356, "node_id": "MDQ6VXNlcjEwNzIzNTY=", "avatar_url": "https://avatars.githubusercontent.com/u/1072356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hjl-tools", "html_url": "https://github.com/hjl-tools", "followers_url": "https://api.github.com/users/hjl-tools/followers", "following_url": "https://api.github.com/users/hjl-tools/following{/other_user}", "gists_url": "https://api.github.com/users/hjl-tools/gists{/gist_id}", "starred_url": "https://api.github.com/users/hjl-tools/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hjl-tools/subscriptions", "organizations_url": "https://api.github.com/users/hjl-tools/orgs", "repos_url": "https://api.github.com/users/hjl-tools/repos", "events_url": "https://api.github.com/users/hjl-tools/events{/privacy}", "received_events_url": "https://api.github.com/users/hjl-tools/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "6d8176f05987fac7e6f58e5bea2ab739a14eea84", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6d8176f05987fac7e6f58e5bea2ab739a14eea84", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6d8176f05987fac7e6f58e5bea2ab739a14eea84"}], "stats": {"total": 3070, "additions": 1601, "deletions": 1469}, "files": [{"sha": "faaa9bc03ccdc4e07b59cd4a8e52725de0fc1975", "filename": "gcc/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30fb3231107d372c2e9df88e18714baae783870e/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30fb3231107d372c2e9df88e18714baae783870e/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=30fb3231107d372c2e9df88e18714baae783870e", "patch": "@@ -1,3 +1,16 @@\n+2003-06-06  H.J. Lu <hongjiu.lu@intel.com>\n+\n+\t* config.gcc (extra_headers): Add emmintrin.h for i[34567]86-*-*\n+\tand x86_64-*-*.\n+\n+\t* config/i386/mmintrin.h: Update version and add alternate\n+\tintrinsic names.\n+\t* config/i386/xmmintrin.h: Likewise.\n+\n+\t* config/i386/xmmintrin.h: Include <emmintrin.h>. Move SSE2\n+\tintrinsics to ...\n+\t* config/i386/emmintrin.h: Here. New file.\n+\n 2003-06-06  Roger Sayle  <roger@eyesopen.com>\n \n \t* fold-const.c (fold <ABS_EXPR>):  Re-fold the result of folding"}, {"sha": "68ba927636921f9bf2a7ada2fab92a0d43e34859", "filename": "gcc/config.gcc", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30fb3231107d372c2e9df88e18714baae783870e/gcc%2Fconfig.gcc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30fb3231107d372c2e9df88e18714baae783870e/gcc%2Fconfig.gcc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig.gcc?ref=30fb3231107d372c2e9df88e18714baae783870e", "patch": "@@ -300,11 +300,11 @@ xscale-*-*)\n \t;;\n i[34567]86-*-*)\n \tcpu_type=i386\n-\textra_headers=\"mmintrin.h xmmintrin.h\"\n+\textra_headers=\"mmintrin.h xmmintrin.h emmintrin.h\"\n \t;;\n x86_64-*-*)\n \tcpu_type=i386\n-\textra_headers=\"mmintrin.h xmmintrin.h\"\n+\textra_headers=\"mmintrin.h xmmintrin.h emmintrin.h\"\n \tneed_64bit_hwint=yes\n \t;;\n ia64-*-*)"}, {"sha": "7007fc5864a21a66c1085cef977431ec1ac5de1b", "filename": "gcc/config/i386/emmintrin.h", "status": "added", "additions": 1499, "deletions": 0, "changes": 1499, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30fb3231107d372c2e9df88e18714baae783870e/gcc%2Fconfig%2Fi386%2Femmintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30fb3231107d372c2e9df88e18714baae783870e/gcc%2Fconfig%2Fi386%2Femmintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Femmintrin.h?ref=30fb3231107d372c2e9df88e18714baae783870e", "patch": "@@ -0,0 +1,1499 @@\n+/* Copyright (C) 2003 Free Software Foundation, Inc.\n+\n+   This file is part of GNU CC.\n+\n+   GNU CC is free software; you can redistribute it and/or modify\n+   it under the terms of the GNU General Public License as published by\n+   the Free Software Foundation; either version 2, or (at your option)\n+   any later version.\n+\n+   GNU CC is distributed in the hope that it will be useful,\n+   but WITHOUT ANY WARRANTY; without even the implied warranty of\n+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+   GNU General Public License for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with GNU CC; see the file COPYING.  If not, write to\n+   the Free Software Foundation, 59 Temple Place - Suite 330,\n+   Boston, MA 02111-1307, USA.  */\n+\n+/* As a special exception, if you include this header file into source\n+   files compiled by GCC, this header file does not by itself cause\n+   the resulting executable to be covered by the GNU General Public\n+   License.  This exception does not however invalidate any other\n+   reasons why the executable file might be covered by the GNU General\n+   Public License.  */\n+\n+/* Implemented from the specification included in the Intel C++ Compiler\n+   User Guide and Reference, version 8.0.  */\n+\n+#ifndef _EMMINTRIN_H_INCLUDED\n+#define _EMMINTRIN_H_INCLUDED\n+\n+#ifdef __SSE2__\n+#include <xmmintrin.h>\n+\n+/* SSE2 */\n+typedef int __v2df __attribute__ ((mode (V2DF)));\n+typedef int __v2di __attribute__ ((mode (V2DI)));\n+typedef int __v4si __attribute__ ((mode (V4SI)));\n+typedef int __v8hi __attribute__ ((mode (V8HI)));\n+typedef int __v16qi __attribute__ ((mode (V16QI)));\n+\n+/* Create a selector for use with the SHUFPD instruction.  */\n+#define _MM_SHUFFLE2(fp1,fp0) \\\n+ (((fp1) << 1) | (fp0))\n+\n+#define __m128i __v2di\n+#define __m128d __v2df\n+\n+/* Create a vector with element 0 as *P and the rest zero.  */\n+static __inline __m128d\n+_mm_load_sd (double const *__P)\n+{\n+  return (__m128d) __builtin_ia32_loadsd (__P);\n+}\n+\n+/* Create a vector with all two elements equal to *P.  */\n+static __inline __m128d\n+_mm_load1_pd (double const *__P)\n+{\n+  __v2df __tmp = __builtin_ia32_loadsd (__P);\n+  return (__m128d) __builtin_ia32_shufpd (__tmp, __tmp, _MM_SHUFFLE2 (0,0));\n+}\n+\n+static __inline __m128d\n+_mm_load_pd1 (double const *__P)\n+{\n+  return _mm_load1_pd (__P);\n+}\n+\n+/* Load two DPFP values from P.  The address must be 16-byte aligned.  */\n+static __inline __m128d\n+_mm_load_pd (double const *__P)\n+{\n+  return (__m128d) __builtin_ia32_loadapd (__P);\n+}\n+\n+/* Load two DPFP values from P.  The address need not be 16-byte aligned.  */\n+static __inline __m128d\n+_mm_loadu_pd (double const *__P)\n+{\n+  return (__m128d) __builtin_ia32_loadupd (__P);\n+}\n+\n+/* Load two DPFP values in reverse order.  The address must be aligned.  */\n+static __inline __m128d\n+_mm_loadr_pd (double const *__P)\n+{\n+  __v2df __tmp = __builtin_ia32_loadapd (__P);\n+  return (__m128d) __builtin_ia32_shufpd (__tmp, __tmp, _MM_SHUFFLE2 (0,1));\n+}\n+\n+/* Create a vector with element 0 as F and the rest zero.  */\n+static __inline __m128d\n+_mm_set_sd (double __F)\n+{\n+  return (__m128d) __builtin_ia32_loadsd (&__F);\n+}\n+\n+/* Create a vector with all two elements equal to F.  */\n+static __inline __m128d\n+_mm_set1_pd (double __F)\n+{\n+  __v2df __tmp = __builtin_ia32_loadsd (&__F);\n+  return (__m128d) __builtin_ia32_shufpd (__tmp, __tmp, _MM_SHUFFLE2 (0,0));\n+}\n+\n+static __inline __m128d\n+_mm_set_pd1 (double __F)\n+{\n+  return _mm_set1_pd (__F);\n+}\n+\n+/* Create the vector [Z Y].  */\n+static __inline __m128d\n+_mm_set_pd (double __Z, double __Y)\n+{\n+  union {\n+    double __a[2];\n+    __m128d __v;\n+  } __u;\n+\n+  __u.__a[0] = __Y;\n+  __u.__a[1] = __Z;\n+\n+  return __u.__v;\n+}\n+\n+/* Create the vector [Y Z].  */\n+static __inline __m128d\n+_mm_setr_pd (double __Z, double __Y)\n+{\n+  return _mm_set_pd (__Y, __Z);\n+}\n+\n+/* Create a vector of zeros.  */\n+static __inline __m128d\n+_mm_setzero_pd (void)\n+{\n+  return (__m128d) __builtin_ia32_setzeropd ();\n+}\n+\n+/* Stores the lower DPFP value.  */\n+static __inline void\n+_mm_store_sd (double *__P, __m128d __A)\n+{\n+  __builtin_ia32_storesd (__P, (__v2df)__A);\n+}\n+\n+/* Store the lower DPFP value acrosd two words.  */\n+static __inline void\n+_mm_store1_pd (double *__P, __m128d __A)\n+{\n+  __v2df __va = (__v2df)__A;\n+  __v2df __tmp = __builtin_ia32_shufpd (__va, __va, _MM_SHUFFLE2 (0,0));\n+  __builtin_ia32_storeapd (__P, __tmp);\n+}\n+\n+static __inline void\n+_mm_store_pd1 (double *__P, __m128d __A)\n+{\n+  _mm_store1_pd (__P, __A);\n+}\n+\n+/* Store two DPFP values.  The address must be 16-byte aligned.  */\n+static __inline void\n+_mm_store_pd (double *__P, __m128d __A)\n+{\n+  __builtin_ia32_storeapd (__P, (__v2df)__A);\n+}\n+\n+/* Store two DPFP values.  The address need not be 16-byte aligned.  */\n+static __inline void\n+_mm_storeu_pd (double *__P, __m128d __A)\n+{\n+  __builtin_ia32_storeupd (__P, (__v2df)__A);\n+}\n+\n+/* Store two DPFP values in reverse order.  The address must be aligned.  */\n+static __inline void\n+_mm_storer_pd (double *__P, __m128d __A)\n+{\n+  __v2df __va = (__v2df)__A;\n+  __v2df __tmp = __builtin_ia32_shufpd (__va, __va, _MM_SHUFFLE2 (0,1));\n+  __builtin_ia32_storeapd (__P, __tmp);\n+}\n+\n+/* Sets the low DPFP value of A from the low value of B.  */\n+static __inline __m128d\n+_mm_move_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_movsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+\n+static __inline __m128d\n+_mm_add_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_addpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_add_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_addsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_sub_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_subpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_sub_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_subsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_mul_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_mulpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_mul_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_mulsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_div_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_divpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_div_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_divsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_sqrt_pd (__m128d __A)\n+{\n+  return (__m128d)__builtin_ia32_sqrtpd ((__v2df)__A);\n+}\n+\n+/* Return pair {sqrt (A[0), B[1]}.  */\n+static __inline __m128d\n+_mm_sqrt_sd (__m128d __A, __m128d __B)\n+{\n+  __v2df __tmp = __builtin_ia32_movsd ((__v2df)__A, (__v2df)__B);\n+  return (__m128d)__builtin_ia32_sqrtsd ((__v2df)__tmp);\n+}\n+\n+static __inline __m128d\n+_mm_min_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_minpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_min_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_minsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_max_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_maxpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_max_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_maxsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_and_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_andpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_andnot_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_andnpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_or_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_orpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_xor_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_xorpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpeq_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpeqpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmplt_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpltpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmple_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmplepd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpgt_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpgtpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpge_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpgepd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpneq_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpneqpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpnlt_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpnltpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpnle_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpnlepd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpngt_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpngtpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpnge_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpngepd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpord_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpordpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpunord_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpunordpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpeq_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpeqsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmplt_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpltsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmple_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmplesd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpgt_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,\n+\t\t\t\t\t (__v2df)\n+\t\t\t\t\t __builtin_ia32_cmpltsd ((__v2df) __B,\n+\t\t\t\t\t\t\t\t (__v2df)\n+\t\t\t\t\t\t\t\t __A));\n+}\n+\n+static __inline __m128d\n+_mm_cmpge_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,\n+\t\t\t\t\t (__v2df)\n+\t\t\t\t\t __builtin_ia32_cmplesd ((__v2df) __B,\n+\t\t\t\t\t\t\t\t (__v2df)\n+\t\t\t\t\t\t\t\t __A));\n+}\n+\n+static __inline __m128d\n+_mm_cmpneq_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpneqsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpnlt_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpnltsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpnle_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpnlesd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpngt_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,\n+\t\t\t\t\t (__v2df)\n+\t\t\t\t\t __builtin_ia32_cmpnltsd ((__v2df) __B,\n+\t\t\t\t\t\t\t\t  (__v2df)\n+\t\t\t\t\t\t\t\t  __A));\n+}\n+\n+static __inline __m128d\n+_mm_cmpnge_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,\n+\t\t\t\t\t (__v2df)\n+\t\t\t\t\t __builtin_ia32_cmpnlesd ((__v2df) __B,\n+\t\t\t\t\t\t\t\t  (__v2df)\n+\t\t\t\t\t\t\t\t  __A));\n+}\n+\n+static __inline __m128d\n+_mm_cmpord_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpordsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpunord_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpunordsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_comieq_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_comisdeq ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_comilt_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_comisdlt ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_comile_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_comisdle ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_comigt_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_comisdgt ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_comige_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_comisdge ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_comineq_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_comisdneq ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_ucomieq_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_ucomisdeq ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_ucomilt_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_ucomisdlt ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_ucomile_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_ucomisdle ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_ucomigt_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_ucomisdgt ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_ucomige_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_ucomisdge ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_ucomineq_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_ucomisdneq ((__v2df)__A, (__v2df)__B);\n+}\n+\n+/* Create a vector with element 0 as *P and the rest zero.  */\n+\n+static __inline __m128i\n+_mm_load_si128 (__m128i const *__P)\n+{\n+  return (__m128i) __builtin_ia32_loaddqa ((char const *)__P);\n+}\n+\n+static __inline __m128i\n+_mm_loadu_si128 (__m128i const *__P)\n+{\n+  return (__m128i) __builtin_ia32_loaddqu ((char const *)__P);\n+}\n+\n+static __inline __m128i\n+_mm_loadl_epi64 (__m128i const *__P)\n+{\n+  return (__m128i) __builtin_ia32_movq2dq (*(unsigned long long *)__P);\n+}\n+\n+static __inline void\n+_mm_store_si128 (__m128i *__P, __m128i __B)\n+{\n+  __builtin_ia32_storedqa ((char *)__P, (__v16qi)__B);\n+}\n+\n+static __inline void\n+_mm_storeu_si128 (__m128i *__P, __m128i __B)\n+{\n+  __builtin_ia32_storedqu ((char *)__P, (__v16qi)__B);\n+}\n+\n+static __inline void\n+_mm_storel_epi64 (__m128i *__P, __m128i __B)\n+{\n+  *(long long *)__P = __builtin_ia32_movdq2q ((__v2di)__B);\n+}\n+\n+static __inline __m64\n+_mm_movepi64_pi64 (__m128i __B)\n+{\n+  return (__m64) __builtin_ia32_movdq2q ((__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_move_epi64 (__m128i __A)\n+{\n+  return (__m128i) __builtin_ia32_movq ((__v2di)__A);\n+}\n+\n+/* Create a vector of zeros.  */\n+static __inline __m128i\n+_mm_setzero_si128 (void)\n+{\n+  return (__m128i) __builtin_ia32_setzero128 ();\n+}\n+\n+static __inline __m128i\n+_mm_set_epi64 (__m64 __A,  __m64 __B)\n+{\n+  __v2di __tmp = (__v2di)__builtin_ia32_movq2dq ((unsigned long long)__A);\n+  __v2di __tmp2 = (__v2di)__builtin_ia32_movq2dq ((unsigned long long)__B);\n+  return (__m128i)__builtin_ia32_punpcklqdq128 (__tmp2, __tmp);\n+}\n+\n+/* Create the vector [Z Y X W].  */\n+static __inline __m128i\n+_mm_set_epi32 (int __Z, int __Y, int __X, int __W)\n+{\n+  union {\n+    int __a[4];\n+    __m128i __v;\n+  } __u;\n+\n+  __u.__a[0] = __W;\n+  __u.__a[1] = __X;\n+  __u.__a[2] = __Y;\n+  __u.__a[3] = __Z;\n+\n+  return __u.__v;\n+}\n+\n+#ifdef __x86_64__\n+/* Create the vector [Z Y].  */\n+static __inline __m128i\n+_mm_set_epi64x (long long __Z, long long __Y)\n+{\n+  union {\n+    long __a[2];\n+    __m128i __v;\n+  } __u;\n+\n+  __u.__a[0] = __Y;\n+  __u.__a[1] = __Z;\n+\n+  return __u.__v;\n+}\n+#endif\n+\n+/* Create the vector [S T U V Z Y X W].  */\n+static __inline __m128i\n+_mm_set_epi16 (short __Z, short __Y, short __X, short __W,\n+\t       short __V, short __U, short __T, short __S)\n+{\n+  union {\n+    short __a[8];\n+    __m128i __v;\n+  } __u;\n+\n+  __u.__a[0] = __S;\n+  __u.__a[1] = __T;\n+  __u.__a[2] = __U;\n+  __u.__a[3] = __V;\n+  __u.__a[4] = __W;\n+  __u.__a[5] = __X;\n+  __u.__a[6] = __Y;\n+  __u.__a[7] = __Z;\n+\n+  return __u.__v;\n+}\n+\n+/* Create the vector [S T U V Z Y X W].  */\n+static __inline __m128i\n+_mm_set_epi8 (char __Z, char __Y, char __X, char __W,\n+\t      char __V, char __U, char __T, char __S,\n+\t      char __Z1, char __Y1, char __X1, char __W1,\n+\t      char __V1, char __U1, char __T1, char __S1)\n+{\n+  union {\n+    char __a[16];\n+    __m128i __v;\n+  } __u;\n+\n+  __u.__a[0] = __S1;\n+  __u.__a[1] = __T1;\n+  __u.__a[2] = __U1;\n+  __u.__a[3] = __V1;\n+  __u.__a[4] = __W1;\n+  __u.__a[5] = __X1;\n+  __u.__a[6] = __Y1;\n+  __u.__a[7] = __Z1;\n+  __u.__a[8] = __S;\n+  __u.__a[9] = __T;\n+  __u.__a[10] = __U;\n+  __u.__a[11] = __V;\n+  __u.__a[12] = __W;\n+  __u.__a[13] = __X;\n+  __u.__a[14] = __Y;\n+  __u.__a[15] = __Z;\n+\n+  return __u.__v;\n+}\n+\n+static __inline __m128i\n+_mm_set1_epi64 (__m64 __A)\n+{\n+  __v2di __tmp = (__v2di)__builtin_ia32_movq2dq ((unsigned long long)__A);\n+  return (__m128i)__builtin_ia32_punpcklqdq128 (__tmp, __tmp);\n+}\n+\n+static __inline __m128i\n+_mm_set1_epi32 (int __A)\n+{\n+  __v4si __tmp = (__v4si)__builtin_ia32_loadd (&__A);\n+  return (__m128i) __builtin_ia32_pshufd ((__v4si)__tmp, _MM_SHUFFLE (0,0,0,0));\n+}\n+\n+#ifdef __x86_64__\n+static __inline __m128i\n+_mm_set1_epi64x (long long __A)\n+{\n+  __v2di __tmp = (__v2di)__builtin_ia32_movq2dq ((unsigned long long)__A);\n+  return (__m128i) __builtin_ia32_shufpd ((__v2df)__tmp, (__v2df)__tmp, _MM_SHUFFLE2 (0,0));\n+}\n+#endif\n+\n+static __inline __m128i\n+_mm_set1_epi16 (short __A)\n+{\n+  int __Acopy = (unsigned short)__A;\n+  __v4si __tmp = (__v4si)__builtin_ia32_loadd (&__Acopy);\n+  __tmp = (__v4si)__builtin_ia32_punpcklwd128 ((__v8hi)__tmp, (__v8hi)__tmp);\n+  return (__m128i) __builtin_ia32_pshufd ((__v4si)__tmp, _MM_SHUFFLE (0,0,0,0));\n+}\n+\n+static __inline __m128i\n+_mm_set1_epi8 (char __A)\n+{\n+  int __Acopy = (unsigned char)__A;\n+  __v4si __tmp = (__v4si)__builtin_ia32_loadd (&__Acopy);\n+  __tmp = (__v4si)__builtin_ia32_punpcklbw128 ((__v16qi)__tmp, (__v16qi)__tmp);\n+  __tmp = (__v4si)__builtin_ia32_punpcklbw128 ((__v16qi)__tmp, (__v16qi)__tmp);\n+  return (__m128i) __builtin_ia32_pshufd ((__v4si)__tmp, _MM_SHUFFLE (0,0,0,0));\n+}\n+\n+static __inline __m128i\n+_mm_setr_epi64 (__m64 __A,  __m64 __B)\n+{\n+  __v2di __tmp = (__v2di)__builtin_ia32_movq2dq ((unsigned long long)__A);\n+  __v2di __tmp2 = (__v2di)__builtin_ia32_movq2dq ((unsigned long long)__B);\n+  return (__m128i)__builtin_ia32_punpcklqdq128 (__tmp, __tmp2);\n+}\n+\n+/* Create the vector [Z Y X W].  */\n+static __inline __m128i\n+_mm_setr_epi32 (int __W, int __X, int __Y, int __Z)\n+{\n+  union {\n+    int __a[4];\n+    __m128i __v;\n+  } __u;\n+\n+  __u.__a[0] = __W;\n+  __u.__a[1] = __X;\n+  __u.__a[2] = __Y;\n+  __u.__a[3] = __Z;\n+\n+  return __u.__v;\n+}\n+/* Create the vector [S T U V Z Y X W].  */\n+static __inline __m128i\n+_mm_setr_epi16 (short __S, short __T, short __U, short __V,\n+\t        short __W, short __X, short __Y, short __Z)\n+{\n+  union {\n+    short __a[8];\n+    __m128i __v;\n+  } __u;\n+\n+  __u.__a[0] = __S;\n+  __u.__a[1] = __T;\n+  __u.__a[2] = __U;\n+  __u.__a[3] = __V;\n+  __u.__a[4] = __W;\n+  __u.__a[5] = __X;\n+  __u.__a[6] = __Y;\n+  __u.__a[7] = __Z;\n+\n+  return __u.__v;\n+}\n+\n+/* Create the vector [S T U V Z Y X W].  */\n+static __inline __m128i\n+_mm_setr_epi8 (char __S1, char __T1, char __U1, char __V1,\n+\t       char __W1, char __X1, char __Y1, char __Z1,\n+\t       char __S, char __T, char __U, char __V,\n+\t       char __W, char __X, char __Y, char __Z)\n+{\n+  union {\n+    char __a[16];\n+    __m128i __v;\n+  } __u;\n+\n+  __u.__a[0] = __S1;\n+  __u.__a[1] = __T1;\n+  __u.__a[2] = __U1;\n+  __u.__a[3] = __V1;\n+  __u.__a[4] = __W1;\n+  __u.__a[5] = __X1;\n+  __u.__a[6] = __Y1;\n+  __u.__a[7] = __Z1;\n+  __u.__a[8] = __S;\n+  __u.__a[9] = __T;\n+  __u.__a[10] = __U;\n+  __u.__a[11] = __V;\n+  __u.__a[12] = __W;\n+  __u.__a[13] = __X;\n+  __u.__a[14] = __Y;\n+  __u.__a[15] = __Z;\n+\n+  return __u.__v;\n+}\n+\n+static __inline __m128d\n+_mm_cvtepi32_pd (__m128i __A)\n+{\n+  return (__m128d)__builtin_ia32_cvtdq2pd ((__v4si) __A);\n+}\n+\n+static __inline __m128\n+_mm_cvtepi32_ps (__m128i __A)\n+{\n+  return (__m128)__builtin_ia32_cvtdq2ps ((__v4si) __A);\n+}\n+\n+static __inline __m128i\n+_mm_cvtpd_epi32 (__m128d __A)\n+{\n+  return (__m128i)__builtin_ia32_cvtpd2dq ((__v2df) __A);\n+}\n+\n+static __inline __m64\n+_mm_cvtpd_pi32 (__m128d __A)\n+{\n+  return (__m64)__builtin_ia32_cvtpd2pi ((__v2df) __A);\n+}\n+\n+static __inline __m128\n+_mm_cvtpd_ps (__m128d __A)\n+{\n+  return (__m128)__builtin_ia32_cvtpd2ps ((__v2df) __A);\n+}\n+\n+static __inline __m128i\n+_mm_cvttpd_epi32 (__m128d __A)\n+{\n+  return (__m128i)__builtin_ia32_cvttpd2dq ((__v2df) __A);\n+}\n+\n+static __inline __m64\n+_mm_cvttpd_pi32 (__m128d __A)\n+{\n+  return (__m64)__builtin_ia32_cvttpd2pi ((__v2df) __A);\n+}\n+\n+static __inline __m128d\n+_mm_cvtpi32_pd (__m64 __A)\n+{\n+  return (__m128d)__builtin_ia32_cvtpi2pd ((__v2si) __A);\n+}\n+\n+static __inline __m128i\n+_mm_cvtps_epi32 (__m128 __A)\n+{\n+  return (__m128i)__builtin_ia32_cvtps2dq ((__v4sf) __A);\n+}\n+\n+static __inline __m128i\n+_mm_cvttps_epi32 (__m128 __A)\n+{\n+  return (__m128i)__builtin_ia32_cvttps2dq ((__v4sf) __A);\n+}\n+\n+static __inline __m128d\n+_mm_cvtps_pd (__m128 __A)\n+{\n+  return (__m128d)__builtin_ia32_cvtps2pd ((__v4sf) __A);\n+}\n+\n+static __inline int\n+_mm_cvtsd_si32 (__m128d __A)\n+{\n+  return __builtin_ia32_cvtsd2si ((__v2df) __A);\n+}\n+\n+#ifdef __x86_64__\n+static __inline long long\n+_mm_cvtsd_si64x (__m128d __A)\n+{\n+  return __builtin_ia32_cvtsd2si64 ((__v2df) __A);\n+}\n+#endif\n+\n+static __inline int\n+_mm_cvttsd_si32 (__m128d __A)\n+{\n+  return __builtin_ia32_cvttsd2si ((__v2df) __A);\n+}\n+\n+#ifdef __x86_64__\n+static __inline long long\n+_mm_cvttsd_si64x (__m128d __A)\n+{\n+  return __builtin_ia32_cvttsd2si64 ((__v2df) __A);\n+}\n+#endif\n+\n+static __inline __m128\n+_mm_cvtsd_ss (__m128 __A, __m128d __B)\n+{\n+  return (__m128)__builtin_ia32_cvtsd2ss ((__v4sf) __A, (__v2df) __B);\n+}\n+\n+static __inline __m128d\n+_mm_cvtsi32_sd (__m128d __A, int __B)\n+{\n+  return (__m128d)__builtin_ia32_cvtsi2sd ((__v2df) __A, __B);\n+}\n+\n+#ifdef __x86_64__\n+static __inline __m128d\n+_mm_cvtsi64x_sd (__m128d __A, long long __B)\n+{\n+  return (__m128d)__builtin_ia32_cvtsi642sd ((__v2df) __A, __B);\n+}\n+#endif\n+\n+static __inline __m128d\n+_mm_cvtss_sd (__m128d __A, __m128 __B)\n+{\n+  return (__m128d)__builtin_ia32_cvtss2sd ((__v2df) __A, (__v4sf)__B);\n+}\n+\n+#define _mm_shuffle_pd(__A, __B, __C) ((__m128d)__builtin_ia32_shufpd ((__v2df)__A, (__v2df)__B, (__C)))\n+\n+static __inline __m128d\n+_mm_unpackhi_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_unpckhpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_unpacklo_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_unpcklpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_loadh_pd (__m128d __A, double const *__B)\n+{\n+  return (__m128d)__builtin_ia32_loadhpd ((__v2df)__A, (__v2si *)__B);\n+}\n+\n+static __inline void\n+_mm_storeh_pd (double *__A, __m128d __B)\n+{\n+  __builtin_ia32_storehpd ((__v2si *)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_loadl_pd (__m128d __A, double const *__B)\n+{\n+  return (__m128d)__builtin_ia32_loadlpd ((__v2df)__A, (__v2si *)__B);\n+}\n+\n+static __inline void\n+_mm_storel_pd (double *__A, __m128d __B)\n+{\n+  __builtin_ia32_storelpd ((__v2si *)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_movemask_pd (__m128d __A)\n+{\n+  return __builtin_ia32_movmskpd ((__v2df)__A);\n+}\n+\n+static __inline __m128i\n+_mm_packs_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_packsswb128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_packs_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_packssdw128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_packus_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_packuswb128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_unpackhi_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_punpckhbw128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_unpackhi_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_punpckhwd128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_unpackhi_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_punpckhdq128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_unpackhi_epi64 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_punpckhqdq128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_unpacklo_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_punpcklbw128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_unpacklo_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_punpcklwd128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_unpacklo_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_punpckldq128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_unpacklo_epi64 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_punpcklqdq128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_add_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_add_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_add_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddd128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_add_epi64 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddq128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_adds_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddsb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_adds_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddsw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_adds_epu8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddusb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_adds_epu16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddusw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sub_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sub_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sub_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubd128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sub_epi64 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubq128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_subs_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubsb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_subs_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubsw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_subs_epu8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubusb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_subs_epu16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubusw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_madd_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pmaddwd128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_mulhi_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pmulhw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_mullo_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pmullw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m64\n+_mm_mul_su32 (__m64 __A, __m64 __B)\n+{\n+  return (__m64)__builtin_ia32_pmuludq ((__v2si)__A, (__v2si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_mul_epu32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pmuludq128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sll_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psllw128 ((__v8hi)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sll_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pslld128 ((__v4si)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sll_epi64 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psllq128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sra_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psraw128 ((__v8hi)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sra_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psrad128 ((__v4si)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_srl_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psrlw128 ((__v8hi)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_srl_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psrld128 ((__v4si)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_srl_epi64 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psrlq128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_slli_epi16 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_psllwi128 ((__v8hi)__A, __B);\n+}\n+\n+static __inline __m128i\n+_mm_slli_epi32 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_pslldi128 ((__v4si)__A, __B);\n+}\n+\n+static __inline __m128i\n+_mm_slli_epi64 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_psllqi128 ((__v2di)__A, __B);\n+}\n+\n+static __inline __m128i\n+_mm_srai_epi16 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_psrawi128 ((__v8hi)__A, __B);\n+}\n+\n+static __inline __m128i\n+_mm_srai_epi32 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_psradi128 ((__v4si)__A, __B);\n+}\n+\n+#if 0\n+static __m128i __attribute__((__always_inline__))\n+_mm_srli_si128 (__m128i __A, const int __B)\n+{\n+  return ((__m128i)__builtin_ia32_psrldqi128 (__A, __B))\n+}\n+\n+static __m128i __attribute__((__always_inline__))\n+_mm_srli_si128 (__m128i __A, const int __B)\n+{\n+  return ((__m128i)__builtin_ia32_pslldqi128 (__A, __B))\n+}\n+#endif\n+#define _mm_srli_si128(__A, __B) ((__m128i)__builtin_ia32_psrldqi128 (__A, __B))\n+#define _mm_slli_si128(__A, __B) ((__m128i)__builtin_ia32_pslldqi128 (__A, __B))\n+\n+static __inline __m128i\n+_mm_srli_epi16 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_psrlwi128 ((__v8hi)__A, __B);\n+}\n+\n+static __inline __m128i\n+_mm_srli_epi32 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_psrldi128 ((__v4si)__A, __B);\n+}\n+\n+static __inline __m128i\n+_mm_srli_epi64 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_psrlqi128 ((__v2di)__A, __B);\n+}\n+\n+static __inline __m128i\n+_mm_and_si128 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pand128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_andnot_si128 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pandn128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_or_si128 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_por128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_xor_si128 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pxor128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_cmpeq_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pcmpeqb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_cmpeq_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pcmpeqw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_cmpeq_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pcmpeqd128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_cmplt_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pcmpgtb128 ((__v16qi)__B, (__v16qi)__A);\n+}\n+\n+static __inline __m128i\n+_mm_cmplt_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pcmpgtw128 ((__v8hi)__B, (__v8hi)__A);\n+}\n+\n+static __inline __m128i\n+_mm_cmplt_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pcmpgtd128 ((__v4si)__B, (__v4si)__A);\n+}\n+\n+static __inline __m128i\n+_mm_cmpgt_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pcmpgtb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_cmpgt_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pcmpgtw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_cmpgt_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pcmpgtd128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+#define _mm_extract_epi16(__A, __B) __builtin_ia32_pextrw128 ((__v8hi)__A, __B)\n+\n+#define _mm_insert_epi16(__A, __B, __C) ((__m128i)__builtin_ia32_pinsrw128 ((__v8hi)__A, __B, __C))\n+\n+static __inline __m128i\n+_mm_max_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pmaxsw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_max_epu8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pmaxub128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_min_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pminsw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_min_epu8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pminub128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline int\n+_mm_movemask_epi8 (__m128i __A)\n+{\n+  return __builtin_ia32_pmovmskb128 ((__v16qi)__A);\n+}\n+\n+static __inline __m128i\n+_mm_mulhi_epu16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pmulhuw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+#define _mm_shufflehi_epi16(__A, __B) ((__m128i)__builtin_ia32_pshufhw ((__v8hi)__A, __B))\n+#define _mm_shufflelo_epi16(__A, __B) ((__m128i)__builtin_ia32_pshuflw ((__v8hi)__A, __B))\n+#define _mm_shuffle_epi32(__A, __B) ((__m128i)__builtin_ia32_pshufd ((__v4si)__A, __B))\n+\n+static __inline void\n+_mm_maskmoveu_si128 (__m128i __A, __m128i __B, char *__C)\n+{\n+  __builtin_ia32_maskmovdqu ((__v16qi)__A, (__v16qi)__B, __C);\n+}\n+\n+static __inline __m128i\n+_mm_avg_epu8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pavgb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_avg_epu16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pavgw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sad_epu8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psadbw128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline void\n+_mm_stream_si32 (int *__A, int __B)\n+{\n+  __builtin_ia32_movnti (__A, __B);\n+}\n+\n+static __inline void\n+_mm_stream_si128 (__m128i *__A, __m128i __B)\n+{\n+  __builtin_ia32_movntdq ((__v2di *)__A, (__v2di)__B);\n+}\n+\n+static __inline void\n+_mm_stream_pd (double *__A, __m128d __B)\n+{\n+  __builtin_ia32_movntpd (__A, (__v2df)__B);\n+}\n+\n+static __inline __m128i\n+_mm_movpi64_epi64 (__m64 __A)\n+{\n+  return (__m128i)__builtin_ia32_movq2dq ((unsigned long long)__A);\n+}\n+\n+static __inline void\n+_mm_clflush (void const *__A)\n+{\n+  return __builtin_ia32_clflush (__A);\n+}\n+\n+static __inline void\n+_mm_lfence (void)\n+{\n+  __builtin_ia32_lfence ();\n+}\n+\n+static __inline void\n+_mm_mfence (void)\n+{\n+  __builtin_ia32_mfence ();\n+}\n+\n+static __inline __m128i\n+_mm_cvtsi32_si128 (int __A)\n+{\n+  return (__m128i) __builtin_ia32_loadd (&__A);\n+}\n+\n+#ifdef __x86_64__\n+static __inline __m128i\n+_mm_cvtsi64x_si128 (long long __A)\n+{\n+  return (__m128i) __builtin_ia32_movq2dq (__A);\n+}\n+#endif\n+\n+static __inline int\n+_mm_cvtsi128_si32 (__m128i __A)\n+{\n+  int __tmp;\n+  __builtin_ia32_stored (&__tmp, (__v4si)__A);\n+  return __tmp;\n+}\n+\n+#ifdef __x86_64__\n+static __inline long long\n+_mm_cvtsi128_si64x (__m128i __A)\n+{\n+  return __builtin_ia32_movdq2q ((__v2di)__A);\n+}\n+#endif\n+\n+#endif /* __SSE2__  */\n+\n+#endif /* _EMMINTRIN_H_INCLUDED */"}, {"sha": "0efe8601e623d6448a5295ccc248cc2fa6f33724", "filename": "gcc/config/i386/mmintrin.h", "status": "modified", "additions": 59, "deletions": 2, "changes": 61, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30fb3231107d372c2e9df88e18714baae783870e/gcc%2Fconfig%2Fi386%2Fmmintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30fb3231107d372c2e9df88e18714baae783870e/gcc%2Fconfig%2Fi386%2Fmmintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fmmintrin.h?ref=30fb3231107d372c2e9df88e18714baae783870e", "patch": "@@ -1,4 +1,4 @@\n-/* Copyright (C) 2002 Free Software Foundation, Inc.\n+/* Copyright (C) 2002, 2003 Free Software Foundation, Inc.\n \n    This file is part of GNU CC.\n \n@@ -25,7 +25,7 @@\n    Public License.  */\n \n /* Implemented from the specification included in the Intel C++ Compiler\n-   User Guide and Reference, version 5.0.  */\n+   User Guide and Reference, version 8.0.  */\n \n #ifndef _MMINTRIN_H_INCLUDED\n #define _MMINTRIN_H_INCLUDED\n@@ -583,5 +583,62 @@ _mm_set1_pi8 (char __b)\n   return _mm_set1_pi32 (__i);\n }\n \n+/* Alternate intrinsic name definitions.  */\n+#define\t_m_empty\t_mm_empty\n+#define\t_m_from_int\t_mm_cvtsi32_si64\n+#define\t_m_to_int\t_mm_cvtsi64_si32\n+#define\t_m_packsswb\t_mm_packs_pi16\n+#define\t_m_packssdw\t_mm_packs_pi32\n+#define\t_m_packuswb\t_mm_packs_pu16\n+#define\t_m_punpckhbw\t_mm_unpackhi_pi8\n+#define\t_m_punpckhwd\t_mm_unpackhi_pi16\n+#define\t_m_punpckhdq\t_mm_unpackhi_pi32\n+#define\t_m_punpcklbw\t_mm_unpacklo_pi8\n+#define\t_m_punpcklwd\t_mm_unpacklo_pi16\n+#define\t_m_punpckldq\t_mm_unpacklo_pi32\n+#define\t_m_paddb\t_mm_add_pi8\n+#define\t_m_paddw\t_mm_add_pi16\n+#define\t_m_paddd\t_mm_add_pi32\n+#define\t_m_paddsb\t_mm_adds_pi8\n+#define\t_m_paddsw\t_mm_adds_pi16\n+#define\t_m_paddusb\t_mm_adds_pu8\n+#define\t_m_paddusw\t_mm_adds_pu16\n+#define\t_m_psubb\t_mm_sub_pi8\n+#define\t_m_psubw\t_mm_sub_pi16\n+#define\t_m_psubd\t_mm_sub_pi32\n+#define\t_m_psubsb\t_mm_subs_pi8\n+#define\t_m_psubsw\t_mm_subs_pi16\n+#define\t_m_psubusb\t_mm_subs_pu8\n+#define\t_m_psubusw\t_mm_subs_pu16\n+#define\t_m_pmaddwd\t_mm_madd_pi16\n+#define\t_m_pmulhw\t_mm_mulhi_pi16\n+#define\t_m_pmullw\t_mm_mullo_pi16\n+#define\t_m_psllw\t_mm_sll_pi16\n+#define\t_m_psllwi\t_mm_slli_pi16\n+#define\t_m_pslld\t_mm_sll_pi32\n+#define\t_m_pslldi\t_mm_slli_pi32\n+#define\t_m_psllq\t_mm_sll_si64\n+#define\t_m_psllqi\t_mm_slli_si64\n+#define\t_m_psraw\t_mm_sra_pi16\n+#define\t_m_psrawi\t_mm_srai_pi16\n+#define\t_m_psrad\t_mm_sra_pi32\n+#define\t_m_psradi\t_mm_srai_pi32\n+#define\t_m_psrlw\t_mm_srl_pi16\n+#define\t_m_psrlwi\t_mm_srli_pi16\n+#define\t_m_psrld\t_mm_srl_pi32\n+#define\t_m_psrldi\t_mm_srli_pi32\n+#define\t_m_psrlq\t_mm_srl_si64\n+#define\t_m_psrlqi\t_mm_srli_si64\n+#define\t_m_pand\t\t_mm_and_si64\n+#define\t_m_pandn\t_mm_andnot_si64\n+#define\t_m_por\t\t_mm_or_si64\n+#define\t_m_pxor\t\t_mm_xor_si64\n+#define\t_m_pcmpeqb\t_mm_cmpeq_pi8\n+#define\t_m_pcmpeqw\t_mm_cmpeq_pi16\n+#define\t_m_pcmpeqd\t_mm_cmpeq_pi32\n+#define\t_m_pcmpgtb\t_mm_cmpgt_pi8\n+#define\t_m_pcmpgtw\t_mm_cmpgt_pi16\n+#define\t_m_pcmpgtd\t_mm_cmpgt_pi32\n+\n #endif /* __MMX__ */\n #endif /* _MMINTRIN_H_INCLUDED */"}, {"sha": "ecdd866c66e32f821f42e141ef265aef9abbc6e3", "filename": "gcc/config/i386/xmmintrin.h", "status": "modified", "additions": 28, "deletions": 1465, "changes": 1493, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/30fb3231107d372c2e9df88e18714baae783870e/gcc%2Fconfig%2Fi386%2Fxmmintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/30fb3231107d372c2e9df88e18714baae783870e/gcc%2Fconfig%2Fi386%2Fxmmintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fxmmintrin.h?ref=30fb3231107d372c2e9df88e18714baae783870e", "patch": "@@ -1,4 +1,4 @@\n-/* Copyright (C) 2002 Free Software Foundation, Inc.\n+/* Copyright (C) 2002, 2003 Free Software Foundation, Inc.\n \n    This file is part of GNU CC.\n \n@@ -25,7 +25,7 @@\n    Public License.  */\n \n /* Implemented from the specification included in the Intel C++ Compiler\n-   User Guide and Reference, version 5.0.  */\n+   User Guide and Reference, version 8.0.  */\n \n #ifndef _XMMINTRIN_H_INCLUDED\n #define _XMMINTRIN_H_INCLUDED\n@@ -1106,1469 +1106,32 @@ do {\t\t\t\t\t\t\t\t\t\\\n   (row3) = __builtin_ia32_shufps (__t2, __t3, 0xDD);\t\t\t\\\n } while (0)\n \n-#ifdef __SSE2__\n-/* SSE2 */\n-typedef int __v2df __attribute__ ((mode (V2DF)));\n-typedef int __v2di __attribute__ ((mode (V2DI)));\n-typedef int __v4si __attribute__ ((mode (V4SI)));\n-typedef int __v8hi __attribute__ ((mode (V8HI)));\n-typedef int __v16qi __attribute__ ((mode (V16QI)));\n-\n-/* Create a selector for use with the SHUFPD instruction.  */\n-#define _MM_SHUFFLE2(fp1,fp0) \\\n- (((fp1) << 1) | (fp0))\n-\n-#define __m128i __v2di\n-#define __m128d __v2df\n-\n-/* Create a vector with element 0 as *P and the rest zero.  */\n-static __inline __m128d\n-_mm_load_sd (double const *__P)\n-{\n-  return (__m128d) __builtin_ia32_loadsd (__P);\n-}\n-\n-/* Create a vector with all two elements equal to *P.  */\n-static __inline __m128d\n-_mm_load1_pd (double const *__P)\n-{\n-  __v2df __tmp = __builtin_ia32_loadsd (__P);\n-  return (__m128d) __builtin_ia32_shufpd (__tmp, __tmp, _MM_SHUFFLE2 (0,0));\n-}\n-\n-static __inline __m128d\n-_mm_load_pd1 (double const *__P)\n-{\n-  return _mm_load1_pd (__P);\n-}\n-\n-/* Load two DPFP values from P.  The address must be 16-byte aligned.  */\n-static __inline __m128d\n-_mm_load_pd (double const *__P)\n-{\n-  return (__m128d) __builtin_ia32_loadapd (__P);\n-}\n-\n-/* Load two DPFP values from P.  The address need not be 16-byte aligned.  */\n-static __inline __m128d\n-_mm_loadu_pd (double const *__P)\n-{\n-  return (__m128d) __builtin_ia32_loadupd (__P);\n-}\n-\n-/* Load two DPFP values in reverse order.  The address must be aligned.  */\n-static __inline __m128d\n-_mm_loadr_pd (double const *__P)\n-{\n-  __v2df __tmp = __builtin_ia32_loadapd (__P);\n-  return (__m128d) __builtin_ia32_shufpd (__tmp, __tmp, _MM_SHUFFLE2 (0,1));\n-}\n-\n-/* Create a vector with element 0 as F and the rest zero.  */\n-static __inline __m128d\n-_mm_set_sd (double __F)\n-{\n-  return (__m128d) __builtin_ia32_loadsd (&__F);\n-}\n-\n-/* Create a vector with all two elements equal to F.  */\n-static __inline __m128d\n-_mm_set1_pd (double __F)\n-{\n-  __v2df __tmp = __builtin_ia32_loadsd (&__F);\n-  return (__m128d) __builtin_ia32_shufpd (__tmp, __tmp, _MM_SHUFFLE2 (0,0));\n-}\n-\n-static __inline __m128d\n-_mm_set_pd1 (double __F)\n-{\n-  return _mm_set1_pd (__F);\n-}\n-\n-/* Create the vector [Z Y].  */\n-static __inline __m128d\n-_mm_set_pd (double __Z, double __Y)\n-{\n-  union {\n-    double __a[2];\n-    __m128d __v;\n-  } __u;\n-\n-  __u.__a[0] = __Y;\n-  __u.__a[1] = __Z;\n-\n-  return __u.__v;\n-}\n-\n-/* Create the vector [Y Z].  */\n-static __inline __m128d\n-_mm_setr_pd (double __Z, double __Y)\n-{\n-  return _mm_set_pd (__Y, __Z);\n-}\n-\n-/* Create a vector of zeros.  */\n-static __inline __m128d\n-_mm_setzero_pd (void)\n-{\n-  return (__m128d) __builtin_ia32_setzeropd ();\n-}\n-\n-/* Stores the lower DPFP value.  */\n-static __inline void\n-_mm_store_sd (double *__P, __m128d __A)\n-{\n-  __builtin_ia32_storesd (__P, (__v2df)__A);\n-}\n-\n-/* Store the lower DPFP value acrosd two words.  */\n-static __inline void\n-_mm_store1_pd (double *__P, __m128d __A)\n-{\n-  __v2df __va = (__v2df)__A;\n-  __v2df __tmp = __builtin_ia32_shufpd (__va, __va, _MM_SHUFFLE2 (0,0));\n-  __builtin_ia32_storeapd (__P, __tmp);\n-}\n-\n-static __inline void\n-_mm_store_pd1 (double *__P, __m128d __A)\n-{\n-  _mm_store1_pd (__P, __A);\n-}\n-\n-/* Store two DPFP values.  The address must be 16-byte aligned.  */\n-static __inline void\n-_mm_store_pd (double *__P, __m128d __A)\n-{\n-  __builtin_ia32_storeapd (__P, (__v2df)__A);\n-}\n-\n-/* Store two DPFP values.  The address need not be 16-byte aligned.  */\n-static __inline void\n-_mm_storeu_pd (double *__P, __m128d __A)\n-{\n-  __builtin_ia32_storeupd (__P, (__v2df)__A);\n-}\n-\n-/* Store two DPFP values in reverse order.  The address must be aligned.  */\n-static __inline void\n-_mm_storer_pd (double *__P, __m128d __A)\n-{\n-  __v2df __va = (__v2df)__A;\n-  __v2df __tmp = __builtin_ia32_shufpd (__va, __va, _MM_SHUFFLE2 (0,1));\n-  __builtin_ia32_storeapd (__P, __tmp);\n-}\n-\n-/* Sets the low DPFP value of A from the low value of B.  */\n-static __inline __m128d\n-_mm_move_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d) __builtin_ia32_movsd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-\n-static __inline __m128d\n-_mm_add_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_addpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_add_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_addsd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_sub_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_subpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_sub_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_subsd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_mul_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_mulpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_mul_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_mulsd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_div_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_divpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_div_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_divsd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_sqrt_pd (__m128d __A)\n-{\n-  return (__m128d)__builtin_ia32_sqrtpd ((__v2df)__A);\n-}\n-\n-/* Return pair {sqrt (A[0), B[1]}.  */\n-static __inline __m128d\n-_mm_sqrt_sd (__m128d __A, __m128d __B)\n-{\n-  __v2df __tmp = __builtin_ia32_movsd ((__v2df)__A, (__v2df)__B);\n-  return (__m128d)__builtin_ia32_sqrtsd ((__v2df)__tmp);\n-}\n-\n-static __inline __m128d\n-_mm_min_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_minpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_min_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_minsd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_max_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_maxpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_max_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_maxsd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_and_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_andpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_andnot_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_andnpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_or_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_orpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_xor_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_xorpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpeq_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpeqpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmplt_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpltpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmple_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmplepd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpgt_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpgtpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpge_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpgepd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpneq_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpneqpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpnlt_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpnltpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpnle_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpnlepd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpngt_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpngtpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpnge_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpngepd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpord_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpordpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpunord_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpunordpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpeq_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpeqsd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmplt_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpltsd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmple_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmplesd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpgt_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,\n-\t\t\t\t\t (__v2df)\n-\t\t\t\t\t __builtin_ia32_cmpltsd ((__v2df) __B,\n-\t\t\t\t\t\t\t\t (__v2df)\n-\t\t\t\t\t\t\t\t __A));\n-}\n-\n-static __inline __m128d\n-_mm_cmpge_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,\n-\t\t\t\t\t (__v2df)\n-\t\t\t\t\t __builtin_ia32_cmplesd ((__v2df) __B,\n-\t\t\t\t\t\t\t\t (__v2df)\n-\t\t\t\t\t\t\t\t __A));\n-}\n-\n-static __inline __m128d\n-_mm_cmpneq_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpneqsd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpnlt_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpnltsd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpnle_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpnlesd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpngt_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,\n-\t\t\t\t\t (__v2df)\n-\t\t\t\t\t __builtin_ia32_cmpnltsd ((__v2df) __B,\n-\t\t\t\t\t\t\t\t  (__v2df)\n-\t\t\t\t\t\t\t\t  __A));\n-}\n-\n-static __inline __m128d\n-_mm_cmpnge_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,\n-\t\t\t\t\t (__v2df)\n-\t\t\t\t\t __builtin_ia32_cmpnlesd ((__v2df) __B,\n-\t\t\t\t\t\t\t\t  (__v2df)\n-\t\t\t\t\t\t\t\t  __A));\n-}\n-\n-static __inline __m128d\n-_mm_cmpord_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpordsd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_cmpunord_sd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_cmpunordsd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline int\n-_mm_comieq_sd (__m128d __A, __m128d __B)\n-{\n-  return __builtin_ia32_comisdeq ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline int\n-_mm_comilt_sd (__m128d __A, __m128d __B)\n-{\n-  return __builtin_ia32_comisdlt ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline int\n-_mm_comile_sd (__m128d __A, __m128d __B)\n-{\n-  return __builtin_ia32_comisdle ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline int\n-_mm_comigt_sd (__m128d __A, __m128d __B)\n-{\n-  return __builtin_ia32_comisdgt ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline int\n-_mm_comige_sd (__m128d __A, __m128d __B)\n-{\n-  return __builtin_ia32_comisdge ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline int\n-_mm_comineq_sd (__m128d __A, __m128d __B)\n-{\n-  return __builtin_ia32_comisdneq ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline int\n-_mm_ucomieq_sd (__m128d __A, __m128d __B)\n-{\n-  return __builtin_ia32_ucomisdeq ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline int\n-_mm_ucomilt_sd (__m128d __A, __m128d __B)\n-{\n-  return __builtin_ia32_ucomisdlt ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline int\n-_mm_ucomile_sd (__m128d __A, __m128d __B)\n-{\n-  return __builtin_ia32_ucomisdle ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline int\n-_mm_ucomigt_sd (__m128d __A, __m128d __B)\n-{\n-  return __builtin_ia32_ucomisdgt ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline int\n-_mm_ucomige_sd (__m128d __A, __m128d __B)\n-{\n-  return __builtin_ia32_ucomisdge ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline int\n-_mm_ucomineq_sd (__m128d __A, __m128d __B)\n-{\n-  return __builtin_ia32_ucomisdneq ((__v2df)__A, (__v2df)__B);\n-}\n-\n-/* Create a vector with element 0 as *P and the rest zero.  */\n-\n-static __inline __m128i\n-_mm_load_si128 (__m128i const *__P)\n-{\n-  return (__m128i) __builtin_ia32_loaddqa ((char const *)__P);\n-}\n-\n-static __inline __m128i\n-_mm_loadu_si128 (__m128i const *__P)\n-{\n-  return (__m128i) __builtin_ia32_loaddqu ((char const *)__P);\n-}\n-\n-static __inline __m128i\n-_mm_loadl_epi64 (__m128i const *__P)\n-{\n-  return (__m128i) __builtin_ia32_movq2dq (*(unsigned long long *)__P);\n-}\n-\n-static __inline void\n-_mm_store_si128 (__m128i *__P, __m128i __B)\n-{\n-  __builtin_ia32_storedqa ((char *)__P, (__v16qi)__B);\n-}\n-\n-static __inline void\n-_mm_storeu_si128 (__m128i *__P, __m128i __B)\n-{\n-  __builtin_ia32_storedqu ((char *)__P, (__v16qi)__B);\n-}\n-\n-static __inline void\n-_mm_storel_epi64 (__m128i *__P, __m128i __B)\n-{\n-  *(long long *)__P = __builtin_ia32_movdq2q ((__v2di)__B);\n-}\n-\n-static __inline __m64\n-_mm_movepi64_pi64 (__m128i __B)\n-{\n-  return (__m64) __builtin_ia32_movdq2q ((__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_move_epi64 (__m128i __A)\n-{\n-  return (__m128i) __builtin_ia32_movq ((__v2di)__A);\n-}\n-\n-/* Create a vector of zeros.  */\n-static __inline __m128i\n-_mm_setzero_si128 (void)\n-{\n-  return (__m128i) __builtin_ia32_setzero128 ();\n-}\n-\n-static __inline __m128i\n-_mm_set_epi64 (__m64 __A,  __m64 __B)\n-{\n-  __v2di __tmp = (__v2di)__builtin_ia32_movq2dq ((unsigned long long)__A);\n-  __v2di __tmp2 = (__v2di)__builtin_ia32_movq2dq ((unsigned long long)__B);\n-  return (__m128i)__builtin_ia32_punpcklqdq128 (__tmp2, __tmp);\n-}\n-\n-/* Create the vector [Z Y X W].  */\n-static __inline __m128i\n-_mm_set_epi32 (int __Z, int __Y, int __X, int __W)\n-{\n-  union {\n-    int __a[4];\n-    __m128i __v;\n-  } __u;\n-\n-  __u.__a[0] = __W;\n-  __u.__a[1] = __X;\n-  __u.__a[2] = __Y;\n-  __u.__a[3] = __Z;\n-\n-  return __u.__v;\n-}\n-\n-#ifdef __x86_64__\n-/* Create the vector [Z Y].  */\n-static __inline __m128i\n-_mm_set_epi64x (long long __Z, long long __Y)\n-{\n-  union {\n-    long __a[2];\n-    __m128i __v;\n-  } __u;\n-\n-  __u.__a[0] = __Y;\n-  __u.__a[1] = __Z;\n-\n-  return __u.__v;\n-}\n-#endif\n-\n-/* Create the vector [S T U V Z Y X W].  */\n-static __inline __m128i\n-_mm_set_epi16 (short __Z, short __Y, short __X, short __W,\n-\t       short __V, short __U, short __T, short __S)\n-{\n-  union {\n-    short __a[8];\n-    __m128i __v;\n-  } __u;\n-\n-  __u.__a[0] = __S;\n-  __u.__a[1] = __T;\n-  __u.__a[2] = __U;\n-  __u.__a[3] = __V;\n-  __u.__a[4] = __W;\n-  __u.__a[5] = __X;\n-  __u.__a[6] = __Y;\n-  __u.__a[7] = __Z;\n-\n-  return __u.__v;\n-}\n-\n-/* Create the vector [S T U V Z Y X W].  */\n-static __inline __m128i\n-_mm_set_epi8 (char __Z, char __Y, char __X, char __W,\n-\t      char __V, char __U, char __T, char __S,\n-\t      char __Z1, char __Y1, char __X1, char __W1,\n-\t      char __V1, char __U1, char __T1, char __S1)\n-{\n-  union {\n-    char __a[16];\n-    __m128i __v;\n-  } __u;\n-\n-  __u.__a[0] = __S1;\n-  __u.__a[1] = __T1;\n-  __u.__a[2] = __U1;\n-  __u.__a[3] = __V1;\n-  __u.__a[4] = __W1;\n-  __u.__a[5] = __X1;\n-  __u.__a[6] = __Y1;\n-  __u.__a[7] = __Z1;\n-  __u.__a[8] = __S;\n-  __u.__a[9] = __T;\n-  __u.__a[10] = __U;\n-  __u.__a[11] = __V;\n-  __u.__a[12] = __W;\n-  __u.__a[13] = __X;\n-  __u.__a[14] = __Y;\n-  __u.__a[15] = __Z;\n-\n-  return __u.__v;\n-}\n-\n-static __inline __m128i\n-_mm_set1_epi64 (__m64 __A)\n-{\n-  __v2di __tmp = (__v2di)__builtin_ia32_movq2dq ((unsigned long long)__A);\n-  return (__m128i)__builtin_ia32_punpcklqdq128 (__tmp, __tmp);\n-}\n-\n-static __inline __m128i\n-_mm_set1_epi32 (int __A)\n-{\n-  __v4si __tmp = (__v4si)__builtin_ia32_loadd (&__A);\n-  return (__m128i) __builtin_ia32_pshufd ((__v4si)__tmp, _MM_SHUFFLE (0,0,0,0));\n-}\n-\n-#ifdef __x86_64__\n-static __inline __m128i\n-_mm_set1_epi64x (long long __A)\n-{\n-  __v2di __tmp = (__v2di)__builtin_ia32_movq2dq ((unsigned long long)__A);\n-  return (__m128i) __builtin_ia32_shufpd ((__v2df)__tmp, (__v2df)__tmp, _MM_SHUFFLE2 (0,0));\n-}\n-#endif\n-\n-static __inline __m128i\n-_mm_set1_epi16 (short __A)\n-{\n-  int __Acopy = (unsigned short)__A;\n-  __v4si __tmp = (__v4si)__builtin_ia32_loadd (&__Acopy);\n-  __tmp = (__v4si)__builtin_ia32_punpcklwd128 ((__v8hi)__tmp, (__v8hi)__tmp);\n-  return (__m128i) __builtin_ia32_pshufd ((__v4si)__tmp, _MM_SHUFFLE (0,0,0,0));\n-}\n-\n-static __inline __m128i\n-_mm_set1_epi8 (char __A)\n-{\n-  int __Acopy = (unsigned char)__A;\n-  __v4si __tmp = (__v4si)__builtin_ia32_loadd (&__Acopy);\n-  __tmp = (__v4si)__builtin_ia32_punpcklbw128 ((__v16qi)__tmp, (__v16qi)__tmp);\n-  __tmp = (__v4si)__builtin_ia32_punpcklbw128 ((__v16qi)__tmp, (__v16qi)__tmp);\n-  return (__m128i) __builtin_ia32_pshufd ((__v4si)__tmp, _MM_SHUFFLE (0,0,0,0));\n-}\n-\n-static __inline __m128i\n-_mm_setr_epi64 (__m64 __A,  __m64 __B)\n-{\n-  __v2di __tmp = (__v2di)__builtin_ia32_movq2dq ((unsigned long long)__A);\n-  __v2di __tmp2 = (__v2di)__builtin_ia32_movq2dq ((unsigned long long)__B);\n-  return (__m128i)__builtin_ia32_punpcklqdq128 (__tmp, __tmp2);\n-}\n-\n-/* Create the vector [Z Y X W].  */\n-static __inline __m128i\n-_mm_setr_epi32 (int __W, int __X, int __Y, int __Z)\n-{\n-  union {\n-    int __a[4];\n-    __m128i __v;\n-  } __u;\n-\n-  __u.__a[0] = __W;\n-  __u.__a[1] = __X;\n-  __u.__a[2] = __Y;\n-  __u.__a[3] = __Z;\n-\n-  return __u.__v;\n-}\n-/* Create the vector [S T U V Z Y X W].  */\n-static __inline __m128i\n-_mm_setr_epi16 (short __S, short __T, short __U, short __V,\n-\t        short __W, short __X, short __Y, short __Z)\n-{\n-  union {\n-    short __a[8];\n-    __m128i __v;\n-  } __u;\n-\n-  __u.__a[0] = __S;\n-  __u.__a[1] = __T;\n-  __u.__a[2] = __U;\n-  __u.__a[3] = __V;\n-  __u.__a[4] = __W;\n-  __u.__a[5] = __X;\n-  __u.__a[6] = __Y;\n-  __u.__a[7] = __Z;\n-\n-  return __u.__v;\n-}\n-\n-/* Create the vector [S T U V Z Y X W].  */\n-static __inline __m128i\n-_mm_setr_epi8 (char __S1, char __T1, char __U1, char __V1,\n-\t       char __W1, char __X1, char __Y1, char __Z1,\n-\t       char __S, char __T, char __U, char __V,\n-\t       char __W, char __X, char __Y, char __Z)\n-{\n-  union {\n-    char __a[16];\n-    __m128i __v;\n-  } __u;\n-\n-  __u.__a[0] = __S1;\n-  __u.__a[1] = __T1;\n-  __u.__a[2] = __U1;\n-  __u.__a[3] = __V1;\n-  __u.__a[4] = __W1;\n-  __u.__a[5] = __X1;\n-  __u.__a[6] = __Y1;\n-  __u.__a[7] = __Z1;\n-  __u.__a[8] = __S;\n-  __u.__a[9] = __T;\n-  __u.__a[10] = __U;\n-  __u.__a[11] = __V;\n-  __u.__a[12] = __W;\n-  __u.__a[13] = __X;\n-  __u.__a[14] = __Y;\n-  __u.__a[15] = __Z;\n-\n-  return __u.__v;\n-}\n-\n-static __inline __m128d\n-_mm_cvtepi32_pd (__m128i __A)\n-{\n-  return (__m128d)__builtin_ia32_cvtdq2pd ((__v4si) __A);\n-}\n-\n-static __inline __m128\n-_mm_cvtepi32_ps (__m128i __A)\n-{\n-  return (__m128)__builtin_ia32_cvtdq2ps ((__v4si) __A);\n-}\n-\n-static __inline __m128i\n-_mm_cvtpd_epi32 (__m128d __A)\n-{\n-  return (__m128i)__builtin_ia32_cvtpd2dq ((__v2df) __A);\n-}\n-\n-static __inline __m64\n-_mm_cvtpd_pi32 (__m128d __A)\n-{\n-  return (__m64)__builtin_ia32_cvtpd2pi ((__v2df) __A);\n-}\n-\n-static __inline __m128\n-_mm_cvtpd_ps (__m128d __A)\n-{\n-  return (__m128)__builtin_ia32_cvtpd2ps ((__v2df) __A);\n-}\n-\n-static __inline __m128i\n-_mm_cvttpd_epi32 (__m128d __A)\n-{\n-  return (__m128i)__builtin_ia32_cvttpd2dq ((__v2df) __A);\n-}\n-\n-static __inline __m64\n-_mm_cvttpd_pi32 (__m128d __A)\n-{\n-  return (__m64)__builtin_ia32_cvttpd2pi ((__v2df) __A);\n-}\n-\n-static __inline __m128d\n-_mm_cvtpi32_pd (__m64 __A)\n-{\n-  return (__m128d)__builtin_ia32_cvtpi2pd ((__v2si) __A);\n-}\n-\n-static __inline __m128i\n-_mm_cvtps_epi32 (__m128 __A)\n-{\n-  return (__m128i)__builtin_ia32_cvtps2dq ((__v4sf) __A);\n-}\n-\n-static __inline __m128i\n-_mm_cvttps_epi32 (__m128 __A)\n-{\n-  return (__m128i)__builtin_ia32_cvttps2dq ((__v4sf) __A);\n-}\n-\n-static __inline __m128d\n-_mm_cvtps_pd (__m128 __A)\n-{\n-  return (__m128d)__builtin_ia32_cvtps2pd ((__v4sf) __A);\n-}\n-\n-static __inline int\n-_mm_cvtsd_si32 (__m128d __A)\n-{\n-  return __builtin_ia32_cvtsd2si ((__v2df) __A);\n-}\n-\n-#ifdef __x86_64__\n-static __inline long long\n-_mm_cvtsd_si64x (__m128d __A)\n-{\n-  return __builtin_ia32_cvtsd2si64 ((__v2df) __A);\n-}\n-#endif\n-\n-static __inline int\n-_mm_cvttsd_si32 (__m128d __A)\n-{\n-  return __builtin_ia32_cvttsd2si ((__v2df) __A);\n-}\n-\n-#ifdef __x86_64__\n-static __inline long long\n-_mm_cvttsd_si64x (__m128d __A)\n-{\n-  return __builtin_ia32_cvttsd2si64 ((__v2df) __A);\n-}\n-#endif\n-\n-static __inline __m128\n-_mm_cvtsd_ss (__m128 __A, __m128d __B)\n-{\n-  return (__m128)__builtin_ia32_cvtsd2ss ((__v4sf) __A, (__v2df) __B);\n-}\n-\n-static __inline __m128d\n-_mm_cvtsi32_sd (__m128d __A, int __B)\n-{\n-  return (__m128d)__builtin_ia32_cvtsi2sd ((__v2df) __A, __B);\n-}\n-\n-#ifdef __x86_64__\n-static __inline __m128d\n-_mm_cvtsi64x_sd (__m128d __A, long long __B)\n-{\n-  return (__m128d)__builtin_ia32_cvtsi642sd ((__v2df) __A, __B);\n-}\n-#endif\n-\n-static __inline __m128d\n-_mm_cvtss_sd (__m128d __A, __m128 __B)\n-{\n-  return (__m128d)__builtin_ia32_cvtss2sd ((__v2df) __A, (__v4sf)__B);\n-}\n-\n-#define _mm_shuffle_pd(__A, __B, __C) ((__m128d)__builtin_ia32_shufpd ((__v2df)__A, (__v2df)__B, (__C)))\n-\n-static __inline __m128d\n-_mm_unpackhi_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_unpckhpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_unpacklo_pd (__m128d __A, __m128d __B)\n-{\n-  return (__m128d)__builtin_ia32_unpcklpd ((__v2df)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_loadh_pd (__m128d __A, double const *__B)\n-{\n-  return (__m128d)__builtin_ia32_loadhpd ((__v2df)__A, (__v2si *)__B);\n-}\n-\n-static __inline void\n-_mm_storeh_pd (double *__A, __m128d __B)\n-{\n-  __builtin_ia32_storehpd ((__v2si *)__A, (__v2df)__B);\n-}\n-\n-static __inline __m128d\n-_mm_loadl_pd (__m128d __A, double const *__B)\n-{\n-  return (__m128d)__builtin_ia32_loadlpd ((__v2df)__A, (__v2si *)__B);\n-}\n-\n-static __inline void\n-_mm_storel_pd (double *__A, __m128d __B)\n-{\n-  __builtin_ia32_storelpd ((__v2si *)__A, (__v2df)__B);\n-}\n-\n-static __inline int\n-_mm_movemask_pd (__m128d __A)\n-{\n-  return __builtin_ia32_movmskpd ((__v2df)__A);\n-}\n-\n-static __inline __m128i\n-_mm_packs_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_packsswb128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_packs_epi32 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_packssdw128 ((__v4si)__A, (__v4si)__B);\n-}\n-\n-static __inline __m128i\n-_mm_packus_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_packuswb128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_unpackhi_epi8 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_punpckhbw128 ((__v16qi)__A, (__v16qi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_unpackhi_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_punpckhwd128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_unpackhi_epi32 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_punpckhdq128 ((__v4si)__A, (__v4si)__B);\n-}\n-\n-static __inline __m128i\n-_mm_unpackhi_epi64 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_punpckhqdq128 ((__v2di)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_unpacklo_epi8 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_punpcklbw128 ((__v16qi)__A, (__v16qi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_unpacklo_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_punpcklwd128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_unpacklo_epi32 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_punpckldq128 ((__v4si)__A, (__v4si)__B);\n-}\n-\n-static __inline __m128i\n-_mm_unpacklo_epi64 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_punpcklqdq128 ((__v2di)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_add_epi8 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_paddb128 ((__v16qi)__A, (__v16qi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_add_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_paddw128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_add_epi32 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_paddd128 ((__v4si)__A, (__v4si)__B);\n-}\n-\n-static __inline __m128i\n-_mm_add_epi64 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_paddq128 ((__v2di)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_adds_epi8 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_paddsb128 ((__v16qi)__A, (__v16qi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_adds_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_paddsw128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_adds_epu8 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_paddusb128 ((__v16qi)__A, (__v16qi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_adds_epu16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_paddusw128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_sub_epi8 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psubb128 ((__v16qi)__A, (__v16qi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_sub_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psubw128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_sub_epi32 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psubd128 ((__v4si)__A, (__v4si)__B);\n-}\n-\n-static __inline __m128i\n-_mm_sub_epi64 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psubq128 ((__v2di)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_subs_epi8 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psubsb128 ((__v16qi)__A, (__v16qi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_subs_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psubsw128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_subs_epu8 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psubusb128 ((__v16qi)__A, (__v16qi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_subs_epu16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psubusw128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_madd_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pmaddwd128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_mulhi_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pmulhw128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_mullo_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pmullw128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m64\n-_mm_mul_su32 (__m64 __A, __m64 __B)\n-{\n-  return (__m64)__builtin_ia32_pmuludq ((__v2si)__A, (__v2si)__B);\n-}\n-\n-static __inline __m128i\n-_mm_mul_epu32 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pmuludq128 ((__v4si)__A, (__v4si)__B);\n-}\n-\n-static __inline __m128i\n-_mm_sll_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psllw128 ((__v8hi)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_sll_epi32 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pslld128 ((__v4si)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_sll_epi64 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psllq128 ((__v2di)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_sra_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psraw128 ((__v8hi)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_sra_epi32 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psrad128 ((__v4si)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_srl_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psrlw128 ((__v8hi)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_srl_epi32 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psrld128 ((__v4si)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_srl_epi64 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psrlq128 ((__v2di)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_slli_epi16 (__m128i __A, int __B)\n-{\n-  return (__m128i)__builtin_ia32_psllwi128 ((__v8hi)__A, __B);\n-}\n-\n-static __inline __m128i\n-_mm_slli_epi32 (__m128i __A, int __B)\n-{\n-  return (__m128i)__builtin_ia32_pslldi128 ((__v4si)__A, __B);\n-}\n-\n-static __inline __m128i\n-_mm_slli_epi64 (__m128i __A, int __B)\n-{\n-  return (__m128i)__builtin_ia32_psllqi128 ((__v2di)__A, __B);\n-}\n-\n-static __inline __m128i\n-_mm_srai_epi16 (__m128i __A, int __B)\n-{\n-  return (__m128i)__builtin_ia32_psrawi128 ((__v8hi)__A, __B);\n-}\n-\n-static __inline __m128i\n-_mm_srai_epi32 (__m128i __A, int __B)\n-{\n-  return (__m128i)__builtin_ia32_psradi128 ((__v4si)__A, __B);\n-}\n-\n-#if 0\n-static __m128i __attribute__((__always_inline__))\n-_mm_srli_si128 (__m128i __A, const int __B)\n-{\n-  return ((__m128i)__builtin_ia32_psrldqi128 (__A, __B))\n-}\n-\n-static __m128i __attribute__((__always_inline__))\n-_mm_srli_si128 (__m128i __A, const int __B)\n-{\n-  return ((__m128i)__builtin_ia32_pslldqi128 (__A, __B))\n-}\n-#endif\n-#define _mm_srli_si128(__A, __B) ((__m128i)__builtin_ia32_psrldqi128 (__A, __B))\n-#define _mm_slli_si128(__A, __B) ((__m128i)__builtin_ia32_pslldqi128 (__A, __B))\n-\n-static __inline __m128i\n-_mm_srli_epi16 (__m128i __A, int __B)\n-{\n-  return (__m128i)__builtin_ia32_psrlwi128 ((__v8hi)__A, __B);\n-}\n-\n-static __inline __m128i\n-_mm_srli_epi32 (__m128i __A, int __B)\n-{\n-  return (__m128i)__builtin_ia32_psrldi128 ((__v4si)__A, __B);\n-}\n-\n-static __inline __m128i\n-_mm_srli_epi64 (__m128i __A, int __B)\n-{\n-  return (__m128i)__builtin_ia32_psrlqi128 ((__v2di)__A, __B);\n-}\n-\n-static __inline __m128i\n-_mm_and_si128 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pand128 ((__v2di)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_andnot_si128 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pandn128 ((__v2di)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_or_si128 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_por128 ((__v2di)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_xor_si128 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pxor128 ((__v2di)__A, (__v2di)__B);\n-}\n-\n-static __inline __m128i\n-_mm_cmpeq_epi8 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pcmpeqb128 ((__v16qi)__A, (__v16qi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_cmpeq_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pcmpeqw128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_cmpeq_epi32 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pcmpeqd128 ((__v4si)__A, (__v4si)__B);\n-}\n-\n-static __inline __m128i\n-_mm_cmplt_epi8 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pcmpgtb128 ((__v16qi)__B, (__v16qi)__A);\n-}\n-\n-static __inline __m128i\n-_mm_cmplt_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pcmpgtw128 ((__v8hi)__B, (__v8hi)__A);\n-}\n-\n-static __inline __m128i\n-_mm_cmplt_epi32 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pcmpgtd128 ((__v4si)__B, (__v4si)__A);\n-}\n-\n-static __inline __m128i\n-_mm_cmpgt_epi8 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pcmpgtb128 ((__v16qi)__A, (__v16qi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_cmpgt_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pcmpgtw128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_cmpgt_epi32 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pcmpgtd128 ((__v4si)__A, (__v4si)__B);\n-}\n-\n-#define _mm_extract_epi16(__A, __B) __builtin_ia32_pextrw128 ((__v8hi)__A, __B)\n-\n-#define _mm_insert_epi16(__A, __B, __C) ((__m128i)__builtin_ia32_pinsrw128 ((__v8hi)__A, __B, __C))\n-\n-static __inline __m128i\n-_mm_max_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pmaxsw128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_max_epu8 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pmaxub128 ((__v16qi)__A, (__v16qi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_min_epi16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pminsw128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_min_epu8 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pminub128 ((__v16qi)__A, (__v16qi)__B);\n-}\n-\n-static __inline int\n-_mm_movemask_epi8 (__m128i __A)\n-{\n-  return __builtin_ia32_pmovmskb128 ((__v16qi)__A);\n-}\n-\n-static __inline __m128i\n-_mm_mulhi_epu16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pmulhuw128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-#define _mm_shufflehi_epi16(__A, __B) ((__m128i)__builtin_ia32_pshufhw ((__v8hi)__A, __B))\n-#define _mm_shufflelo_epi16(__A, __B) ((__m128i)__builtin_ia32_pshuflw ((__v8hi)__A, __B))\n-#define _mm_shuffle_epi32(__A, __B) ((__m128i)__builtin_ia32_pshufd ((__v4si)__A, __B))\n-\n-static __inline void\n-_mm_maskmoveu_si128 (__m128i __A, __m128i __B, char *__C)\n-{\n-  __builtin_ia32_maskmovdqu ((__v16qi)__A, (__v16qi)__B, __C);\n-}\n-\n-static __inline __m128i\n-_mm_avg_epu8 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pavgb128 ((__v16qi)__A, (__v16qi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_avg_epu16 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_pavgw128 ((__v8hi)__A, (__v8hi)__B);\n-}\n-\n-static __inline __m128i\n-_mm_sad_epu8 (__m128i __A, __m128i __B)\n-{\n-  return (__m128i)__builtin_ia32_psadbw128 ((__v16qi)__A, (__v16qi)__B);\n-}\n-\n-static __inline void\n-_mm_stream_si32 (int *__A, int __B)\n-{\n-  __builtin_ia32_movnti (__A, __B);\n-}\n-\n-static __inline void\n-_mm_stream_si128 (__m128i *__A, __m128i __B)\n-{\n-  __builtin_ia32_movntdq ((__v2di *)__A, (__v2di)__B);\n-}\n-\n-static __inline void\n-_mm_stream_pd (double *__A, __m128d __B)\n-{\n-  __builtin_ia32_movntpd (__A, (__v2df)__B);\n-}\n-\n-static __inline __m128i\n-_mm_movpi64_epi64 (__m64 __A)\n-{\n-  return (__m128i)__builtin_ia32_movq2dq ((unsigned long long)__A);\n-}\n-\n-static __inline void\n-_mm_clflush (void const *__A)\n-{\n-  return __builtin_ia32_clflush (__A);\n-}\n-\n-static __inline void\n-_mm_lfence (void)\n-{\n-  __builtin_ia32_lfence ();\n-}\n-\n-static __inline void\n-_mm_mfence (void)\n-{\n-  __builtin_ia32_mfence ();\n-}\n-\n-static __inline __m128i\n-_mm_cvtsi32_si128 (int __A)\n-{\n-  return (__m128i) __builtin_ia32_loadd (&__A);\n-}\n-\n-#ifdef __x86_64__\n-static __inline __m128i\n-_mm_cvtsi64x_si128 (long long __A)\n-{\n-  return (__m128i) __builtin_ia32_movq2dq (__A);\n-}\n-#endif\n-\n-static __inline int\n-_mm_cvtsi128_si32 (__m128i __A)\n-{\n-  int __tmp;\n-  __builtin_ia32_stored (&__tmp, (__v4si)__A);\n-  return __tmp;\n-}\n-\n-#ifdef __x86_64__\n-static __inline long long\n-_mm_cvtsi128_si64x (__m128i __A)\n-{\n-  return __builtin_ia32_movdq2q ((__v2di)__A);\n-}\n-#endif\n-\n-#endif /* __SSE2__  */\n+/* Alternate intrinsic name definitions.  */\n+#define\t_mm_cvt_ss2si\t_mm_cvtss_si32\n+#define\t_mm_cvt_ps2pi\t_mm_cvtps_pi32\n+#define\t_mm_cvtt_ss2si\t_mm_cvttss_si32\n+#define\t_mm_cvtt_ps2pi\t_mm_cvttps_pi32\n+#define\t_mm_cvt_si2ss\t_mm_cvtsi32_ss\n+#define\t_mm_cvt_pi2ps\t_mm_cvtpi32_ps\n+#define\t_m_pextrw\t_mm_extract_pi16\n+#define\t_m_pinsrw\t_mm_insert_pi16\n+#define\t_m_pmaxsw\t_mm_max_pi16\n+#define\t_m_pmaxub\t_mm_max_pu8\n+#define\t_m_pminsw\t_mm_min_pi16\n+#define\t_m_pminub\t_mm_min_pu8\n+#define\t_m_pmovmskb\t_mm_movemask_pi8\n+#define\t_m_pmulhuw\t_mm_mulhi_pu16\n+#define\t_m_pshufw\t_mm_shuffle_pi16\n+#define\t_m_maskmovq\t_mm_maskmove_si64\n+#define\t_m_pavgb\t_mm_avg_pu8\n+#define\t_m_pavgw\t_mm_avg_pu16\n+#define\t_m_psadbw\t_mm_sad_pu8\n+#define\t_mm_set_ps1\t_mm_set1_ps\n+#define\t_mm_load_ps1\t_mm_load1_ps\n+#define\t_mm_store_ps1\t_mm_store1_ps\n+\n+/* For backward source compatibility.  */\n+#include <emmintrin.h>\n \n #endif /* __SSE__ */\n #endif /* _XMMINTRIN_H_INCLUDED */"}]}