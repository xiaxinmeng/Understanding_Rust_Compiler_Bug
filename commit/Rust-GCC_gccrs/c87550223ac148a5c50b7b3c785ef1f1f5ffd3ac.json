{"sha": "c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Yzg3NTUwMjIzYWMxNDhhNWM1MGI3YjNjNzg1ZWYxZjFmNWZmZDNhYw==", "commit": {"author": {"name": "Jeff Law", "email": "law@redhat.com", "date": "2017-03-16T19:21:33Z"}, "committer": {"name": "Jeff Law", "email": "law@gcc.gnu.org", "date": "2017-03-16T19:21:33Z"}, "message": "re PR tree-optimization/71437 (Performance regression after r235817)\n\n\tPR tree-optimization/71437\n\t* tree-ssa-dom.c (dom_opt_dom_walker): Remove thread_across_edge\n\tmember function.  Implementation moved into after_dom_children\n\tmember function and into the threader's thread_outgoing_edges\n\tfunction.\n\t(dom_opt_dom_walker::after_dom_children): Simplify by moving\n\tsome code into new thread_outgoing_edges.\n\t* tree-ssa-threadedge.c (thread_across_edge): Make static and simplify\n\tdefinition.  Simplify marker handling (do it here).   Assume we always\n\thave the available expression and the const/copies tables.\n\t(thread_outgoing_edges): New function extracted from tree-ssa-dom.c\n\tand tree-vrp.c\n\t* tree-ssa-threadedge.h (thread_outgoing_edges): Declare.\n\t* tree-vrp.c (equiv_stack): No longer file scoped.\n\t(vrp_dom_walker): New class.\n\t(vrp_dom_walker::before_dom_children): New member function.\n\t(vrp_dom_walker::after_dom_children): Likewise.\n\t(identify_jump_threads):  Setup domwalker.  Use it rather than\n\twalking edges in a random order by hand.  Simplify setup/finalization.\n\t(finalize_jump_threads): Remove.\n\t(vrp_finalize): Do not call identify_jump_threads here.\n\t(execute_vrp): Do it here instead and call thread_through_all_blocks\n\there too.\n\nFrom-SVN: r246208", "tree": {"sha": "2015d481070a9147dbdeef1dd1ffd15cc2a515b3", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/2015d481070a9147dbdeef1dd1ffd15cc2a515b3"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac/comments", "author": null, "committer": null, "parents": [{"sha": "8d7437be4725af093548429f6e4c80a7867cdb41", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8d7437be4725af093548429f6e4c80a7867cdb41", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8d7437be4725af093548429f6e4c80a7867cdb41"}], "stats": {"total": 353, "additions": 193, "deletions": 160}, "files": [{"sha": "96e1592daae167120871df9c92759e9b67639aa4", "filename": "gcc/ChangeLog", "status": "modified", "additions": 24, "deletions": 0, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac", "patch": "@@ -1,5 +1,29 @@\n 2017-03-16  Jeff Law  <law@redhat.com>\n \n+\tPR tree-optimization/71437\n+\t* tree-ssa-dom.c (dom_opt_dom_walker): Remove thread_across_edge\n+\tmember function.  Implementation moved into after_dom_children\n+\tmember function and into the threader's thread_outgoing_edges\n+\tfunction.\n+\t(dom_opt_dom_walker::after_dom_children): Simplify by moving\n+\tsome code into new thread_outgoing_edges.\n+\t* tree-ssa-threadedge.c (thread_across_edge): Make static and simplify\n+\tdefinition.  Simplify marker handling (do it here).   Assume we always\n+\thave the available expression and the const/copies tables.\n+\t(thread_outgoing_edges): New function extracted from tree-ssa-dom.c\n+\tand tree-vrp.c\n+\t* tree-ssa-threadedge.h (thread_outgoing_edges): Declare.\n+\t* tree-vrp.c (equiv_stack): No longer file scoped.\n+\t(vrp_dom_walker): New class.\n+\t(vrp_dom_walker::before_dom_children): New member function.\n+\t(vrp_dom_walker::after_dom_children): Likewise.\n+\t(identify_jump_threads):  Setup domwalker.  Use it rather than\n+\twalking edges in a random order by hand.  Simplify setup/finalization.\n+\t(finalize_jump_threads): Remove.\n+\t(vrp_finalize): Do not call identify_jump_threads here.\n+\t(execute_vrp): Do it here instead and call thread_through_all_blocks\n+\there too.\n+\t\n \tPR tree-optimization/71437\n \t* tree-ssa-dom.c (pfn_simplify): Add basic_block argument.  All\n \tcallers changed."}, {"sha": "c6ffc38e1a8f1d89ddb4ad84e7bdf3862c6c3cc6", "filename": "gcc/tree-ssa-dom.c", "status": "modified", "additions": 6, "deletions": 65, "changes": 71, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac/gcc%2Ftree-ssa-dom.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac/gcc%2Ftree-ssa-dom.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-dom.c?ref=c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac", "patch": "@@ -350,7 +350,6 @@ class dom_opt_dom_walker : public dom_walker\n   virtual void after_dom_children (basic_block);\n \n private:\n-  void thread_across_edge (edge);\n \n   /* Unwindable equivalences, both const/copy and expression varieties.  */\n   class const_and_copies *m_const_and_copies;\n@@ -816,39 +815,6 @@ record_temporary_equivalences (edge e,\n     }\n }\n \n-/* Wrapper for common code to attempt to thread an edge.  For example,\n-   it handles lazily building the dummy condition and the bookkeeping\n-   when jump threading is successful.  */\n-\n-void\n-dom_opt_dom_walker::thread_across_edge (edge e)\n-{\n-  if (! m_dummy_cond)\n-    m_dummy_cond =\n-        gimple_build_cond (NE_EXPR,\n-                           integer_zero_node, integer_zero_node,\n-                           NULL, NULL);\n-\n-  /* Push a marker on both stacks so we can unwind the tables back to their\n-     current state.  */\n-  m_avail_exprs_stack->push_marker ();\n-  m_const_and_copies->push_marker ();\n-\n-  /* With all the edge equivalences in the tables, go ahead and attempt\n-     to thread through E->dest.  */\n-  ::thread_across_edge (m_dummy_cond, e,\n-\t\t        m_const_and_copies, m_avail_exprs_stack,\n-\t\t        simplify_stmt_for_jump_threading);\n-\n-  /* And restore the various tables to their state before\n-     we threaded this edge.\n-\n-     XXX The code in tree-ssa-threadedge.c will restore the state of\n-     the const_and_copies table.  We we just have to restore the expression\n-     table.  */\n-  m_avail_exprs_stack->pop_to_marker ();\n-}\n-\n /* PHI nodes can create equivalences too.\n \n    Ignoring any alternatives which are the same as the result, if\n@@ -1224,38 +1190,13 @@ dom_opt_dom_walker::before_dom_children (basic_block bb)\n void\n dom_opt_dom_walker::after_dom_children (basic_block bb)\n {\n-  gimple *last;\n-\n-  /* If we have an outgoing edge to a block with multiple incoming and\n-     outgoing edges, then we may be able to thread the edge, i.e., we\n-     may be able to statically determine which of the outgoing edges\n-     will be traversed when the incoming edge from BB is traversed.  */\n-  if (single_succ_p (bb)\n-      && (single_succ_edge (bb)->flags & EDGE_ABNORMAL) == 0\n-      && potentially_threadable_block (single_succ (bb)))\n-    {\n-      thread_across_edge (single_succ_edge (bb));\n-    }\n-  else if ((last = last_stmt (bb))\n-\t   && gimple_code (last) == GIMPLE_COND\n-\t   && EDGE_COUNT (bb->succs) == 2\n-\t   && (EDGE_SUCC (bb, 0)->flags & EDGE_ABNORMAL) == 0\n-\t   && (EDGE_SUCC (bb, 1)->flags & EDGE_ABNORMAL) == 0)\n-    {\n-      edge true_edge, false_edge;\n-\n-      extract_true_false_edges_from_block (bb, &true_edge, &false_edge);\n-\n-      /* Only try to thread the edge if it reaches a target block with\n-\t more than one predecessor and more than one successor.  */\n-      if (potentially_threadable_block (true_edge->dest))\n-\tthread_across_edge (true_edge);\n-\n-      /* Similarly for the ELSE arm.  */\n-      if (potentially_threadable_block (false_edge->dest))\n-\tthread_across_edge (false_edge);\n+  if (! m_dummy_cond)\n+    m_dummy_cond = gimple_build_cond (NE_EXPR, integer_zero_node,\n+\t\t\t\t      integer_zero_node, NULL, NULL);\n \n-    }\n+  thread_outgoing_edges (bb, m_dummy_cond, m_const_and_copies,\n+\t\t\t m_avail_exprs_stack,\n+\t\t\t simplify_stmt_for_jump_threading);\n \n   /* These remove expressions local to BB from the tables.  */\n   m_avail_exprs_stack->pop_to_marker ();"}, {"sha": "536c4717b725b2ec488ad9dc9f506540e498ac1f", "filename": "gcc/tree-ssa-threadedge.c", "status": "modified", "additions": 70, "deletions": 7, "changes": 77, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac/gcc%2Ftree-ssa-threadedge.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac/gcc%2Ftree-ssa-threadedge.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-threadedge.c?ref=c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac", "patch": "@@ -1100,16 +1100,18 @@ thread_through_normal_block (edge e,\n \n    SIMPLIFY is a pass-specific function used to simplify statements.  */\n \n-void\n+static void\n thread_across_edge (gcond *dummy_cond,\n \t\t    edge e,\n \t\t    class const_and_copies *const_and_copies,\n \t\t    class avail_exprs_stack *avail_exprs_stack,\n-\t\t    tree (*simplify) (gimple *, gimple *,\n-\t\t\t\t      class avail_exprs_stack *, basic_block))\n+\t\t    pfn_simplify simplify)\n {\n   bitmap visited = BITMAP_ALLOC (NULL);\n \n+  const_and_copies->push_marker ();\n+  avail_exprs_stack->push_marker ();\n+\n   stmt_count = 0;\n \n   vec<jump_thread_edge *> *path = new vec<jump_thread_edge *> ();\n@@ -1132,6 +1134,7 @@ thread_across_edge (gcond *dummy_cond,\n       propagate_threaded_block_debug_into (path->last ()->e->dest,\n \t\t\t\t\t   e->dest);\n       const_and_copies->pop_to_marker ();\n+      avail_exprs_stack->pop_to_marker ();\n       BITMAP_FREE (visited);\n       register_jump_thread (path);\n       return;\n@@ -1156,6 +1159,7 @@ thread_across_edge (gcond *dummy_cond,\n \t{\n \t  BITMAP_FREE (visited);\n \t  const_and_copies->pop_to_marker ();\n+          avail_exprs_stack->pop_to_marker ();\n \t  return;\n \t}\n     }\n@@ -1182,6 +1186,7 @@ thread_across_edge (gcond *dummy_cond,\n       if (taken_edge->flags & EDGE_ABNORMAL)\n \t{\n \t  const_and_copies->pop_to_marker ();\n+          avail_exprs_stack->pop_to_marker ();\n \t  BITMAP_FREE (visited);\n \t  return;\n \t}\n@@ -1196,8 +1201,7 @@ thread_across_edge (gcond *dummy_cond,\n \t/* Push a fresh marker so we can unwind the equivalences created\n \t   for each of E->dest's successors.  */\n \tconst_and_copies->push_marker ();\n-\tif (avail_exprs_stack)\n-\t  avail_exprs_stack->push_marker ();\n+\tavail_exprs_stack->push_marker ();\n \n \t/* Avoid threading to any block we have already visited.  */\n \tbitmap_clear (visited);\n@@ -1240,12 +1244,71 @@ thread_across_edge (gcond *dummy_cond,\n \t  delete_jump_thread_path (path);\n \n \t/* And unwind the equivalence table.  */\n-\tif (avail_exprs_stack)\n-\t  avail_exprs_stack->pop_to_marker ();\n+\tavail_exprs_stack->pop_to_marker ();\n \tconst_and_copies->pop_to_marker ();\n       }\n     BITMAP_FREE (visited);\n   }\n \n   const_and_copies->pop_to_marker ();\n+  avail_exprs_stack->pop_to_marker ();\n+}\n+\n+/* Examine the outgoing edges from BB and conditionally\n+   try to thread them.\n+\n+   DUMMY_COND is a shared cond_expr used by condition simplification as scratch,\n+   to avoid allocating memory.\n+\n+   CONST_AND_COPIES is used to undo temporary equivalences created during the\n+   walk of E->dest.\n+\n+   The available expression table is referenced vai AVAIL_EXPRS_STACK.\n+\n+   SIMPLIFY is a pass-specific function used to simplify statements.  */\n+\n+void\n+thread_outgoing_edges (basic_block bb, gcond *dummy_cond,\n+\t\t       class const_and_copies *const_and_copies,\n+\t\t       class avail_exprs_stack *avail_exprs_stack,\n+\t\t       tree (*simplify) (gimple *, gimple *,\n+\t\t\t\t\t class avail_exprs_stack *,\n+\t\t\t\t\t basic_block))\n+{\n+  int flags = (EDGE_IGNORE | EDGE_COMPLEX | EDGE_ABNORMAL);\n+  gimple *last;\n+\n+  /* If we have an outgoing edge to a block with multiple incoming and\n+     outgoing edges, then we may be able to thread the edge, i.e., we\n+     may be able to statically determine which of the outgoing edges\n+     will be traversed when the incoming edge from BB is traversed.  */\n+  if (single_succ_p (bb)\n+      && (single_succ_edge (bb)->flags & flags) == 0\n+      && potentially_threadable_block (single_succ (bb)))\n+    {\n+      thread_across_edge (dummy_cond, single_succ_edge (bb),\n+\t\t\t  const_and_copies, avail_exprs_stack,\n+\t\t\t  simplify);\n+    }\n+  else if ((last = last_stmt (bb))\n+\t   && gimple_code (last) == GIMPLE_COND\n+\t   && EDGE_COUNT (bb->succs) == 2\n+\t   && (EDGE_SUCC (bb, 0)->flags & flags) == 0\n+\t   && (EDGE_SUCC (bb, 1)->flags & flags) == 0)\n+    {\n+      edge true_edge, false_edge;\n+\n+      extract_true_false_edges_from_block (bb, &true_edge, &false_edge);\n+\n+      /* Only try to thread the edge if it reaches a target block with\n+\t more than one predecessor and more than one successor.  */\n+      if (potentially_threadable_block (true_edge->dest))\n+\tthread_across_edge (dummy_cond, true_edge,\n+\t\t\t    const_and_copies, avail_exprs_stack, simplify);\n+\n+      /* Similarly for the ELSE arm.  */\n+      if (potentially_threadable_block (false_edge->dest))\n+\tthread_across_edge (dummy_cond, false_edge,\n+\t\t\t    const_and_copies, avail_exprs_stack, simplify);\n+    }\n }"}, {"sha": "49dfa9c94d47d4b2ed97549660b854a819723715", "filename": "gcc/tree-ssa-threadedge.h", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac/gcc%2Ftree-ssa-threadedge.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac/gcc%2Ftree-ssa-threadedge.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-threadedge.h?ref=c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac", "patch": "@@ -30,10 +30,10 @@ extern void threadedge_initialize_values (void);\n extern void threadedge_finalize_values (void);\n extern bool potentially_threadable_block (basic_block);\n extern void propagate_threaded_block_debug_into (basic_block, basic_block);\n-extern void thread_across_edge (gcond *, edge,\n-\t\t\t\tconst_and_copies *,\n-\t\t\t\tavail_exprs_stack *,\n-\t\t\t\ttree (*) (gimple *, gimple *,\n-\t\t\t\t\t  avail_exprs_stack *, basic_block));\n+extern void thread_outgoing_edges (basic_block, gcond *,\n+\t\t\t\t   const_and_copies *,\n+\t\t\t\t   avail_exprs_stack *,\n+\t\t\t\t   tree (*) (gimple *, gimple *,\n+\t\t\t\t\t     avail_exprs_stack *, basic_block));\n \n #endif /* GCC_TREE_SSA_THREADEDGE_H */"}, {"sha": "4a09a57d72708e4ecd9e0f72080a6badfe68555d", "filename": "gcc/tree-vrp.c", "status": "modified", "additions": 88, "deletions": 83, "changes": 171, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac/gcc%2Ftree-vrp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac/gcc%2Ftree-vrp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vrp.c?ref=c87550223ac148a5c50b7b3c785ef1f1f5ffd3ac", "patch": "@@ -10746,9 +10746,6 @@ vrp_fold_stmt (gimple_stmt_iterator *si)\n   return simplify_stmt_using_ranges (si);\n }\n \n-/* Unwindable const/copy equivalences.  */\n-const_and_copies *equiv_stack;\n-\n /* Return the LHS of any ASSERT_EXPR where OP appears as the first\n    argument to the ASSERT_EXPR and in which the ASSERT_EXPR dominates\n    BB.  If no such ASSERT_EXPR is found, return OP.  */\n@@ -10879,6 +10876,74 @@ simplify_stmt_for_jump_threading (gimple *stmt, gimple *within_stmt,\n   return NULL_TREE;\n }\n \n+class vrp_dom_walker : public dom_walker\n+{\n+public:\n+  vrp_dom_walker (cdi_direction direction,\n+\t\t  class const_and_copies *const_and_copies,\n+\t\t  class avail_exprs_stack *avail_exprs_stack)\n+    : dom_walker (direction, true),\n+      m_const_and_copies (const_and_copies),\n+      m_avail_exprs_stack (avail_exprs_stack),\n+      m_dummy_cond (NULL) {}\n+\n+  virtual edge before_dom_children (basic_block);\n+  virtual void after_dom_children (basic_block);\n+\n+private:\n+  class const_and_copies *m_const_and_copies;\n+  class avail_exprs_stack *m_avail_exprs_stack;\n+\n+  gcond *m_dummy_cond;\n+};\n+\n+/* Called before processing dominator children of BB.  We want to look\n+   at ASSERT_EXPRs and record information from them in the appropriate\n+   tables.\n+\n+   We could look at other statements here.  It's not seen as likely\n+   to significantly increase the jump threads we discover.  */\n+\n+edge\n+vrp_dom_walker::before_dom_children (basic_block bb)\n+{\n+  gimple_stmt_iterator gsi;\n+\n+  for (gsi = gsi_start_nondebug_bb (bb); !gsi_end_p (gsi); gsi_next (&gsi))\n+    {\n+      gimple *stmt = gsi_stmt (gsi);\n+      if (gimple_assign_single_p (stmt)\n+         && TREE_CODE (gimple_assign_rhs1 (stmt)) == ASSERT_EXPR)\n+\t{\n+\t  tree lhs = gimple_assign_lhs (stmt);\n+\t  tree rhs1 = gimple_assign_rhs1 (stmt);\n+\t  m_const_and_copies->record_const_or_copy (lhs,\n+\t\t\t\t\t\t    TREE_OPERAND (rhs1, 0));\n+\t  continue;\n+\t}\n+      break;\n+    }\n+  return NULL;\n+}\n+\n+/* Called after processing dominator children of BB.  This is where we\n+   actually call into the threader.  */\n+void\n+vrp_dom_walker::after_dom_children (basic_block bb)\n+{\n+  if (!m_dummy_cond)\n+    m_dummy_cond = gimple_build_cond (NE_EXPR,\n+\t\t\t\t      integer_zero_node, integer_zero_node,\n+\t\t\t\t      NULL, NULL);\n+\n+  thread_outgoing_edges (bb, m_dummy_cond, m_const_and_copies,\n+\t\t\t m_avail_exprs_stack,\n+\t\t\t simplify_stmt_for_jump_threading);\n+\n+  m_avail_exprs_stack->pop_to_marker ();\n+  m_const_and_copies->pop_to_marker ();\n+}\n+\n /* Blocks which have more than one predecessor and more than\n    one successor present jump threading opportunities, i.e.,\n    when the block is reached from a specific predecessor, we\n@@ -10902,8 +10967,6 @@ simplify_stmt_for_jump_threading (gimple *stmt, gimple *within_stmt,\n static void\n identify_jump_threads (void)\n {\n-  basic_block bb;\n-  gcond *dummy;\n   int i;\n   edge e;\n \n@@ -10926,69 +10989,15 @@ identify_jump_threads (void)\n \n   /* Allocate our unwinder stack to unwind any temporary equivalences\n      that might be recorded.  */\n-  equiv_stack = new const_and_copies ();\n-\n-  /* To avoid lots of silly node creation, we create a single\n-     conditional and just modify it in-place when attempting to\n-     thread jumps.  */\n-  dummy = gimple_build_cond (EQ_EXPR,\n-\t\t\t     integer_zero_node, integer_zero_node,\n-\t\t\t     NULL, NULL);\n-\n-  /* Walk through all the blocks finding those which present a\n-     potential jump threading opportunity.  We could set this up\n-     as a dominator walker and record data during the walk, but\n-     I doubt it's worth the effort for the classes of jump\n-     threading opportunities we are trying to identify at this\n-     point in compilation.  */\n-  FOR_EACH_BB_FN (bb, cfun)\n-    {\n-      gimple *last;\n+  const_and_copies *equiv_stack = new const_and_copies ();\n \n-      /* If the generic jump threading code does not find this block\n-\t interesting, then there is nothing to do.  */\n-      if (! potentially_threadable_block (bb))\n-\tcontinue;\n+  hash_table<expr_elt_hasher> *avail_exprs\n+    = new hash_table<expr_elt_hasher> (1024);\n+  avail_exprs_stack *avail_exprs_stack\n+    = new class avail_exprs_stack (avail_exprs);\n \n-      last = last_stmt (bb);\n-\n-      /* We're basically looking for a switch or any kind of conditional with\n-\t integral or pointer type arguments.  Note the type of the second\n-\t argument will be the same as the first argument, so no need to\n-\t check it explicitly. \n-\n-\t We also handle the case where there are no statements in the\n-\t block.  This come up with forwarder blocks that are not\n-\t optimized away because they lead to a loop header.  But we do\n-\t want to thread through them as we can sometimes thread to the\n-\t loop exit which is obviously profitable.  */\n-      if (!last\n-\t  || gimple_code (last) == GIMPLE_SWITCH\n-\t  || (gimple_code (last) == GIMPLE_COND\n-      \t      && TREE_CODE (gimple_cond_lhs (last)) == SSA_NAME\n-\t      && (INTEGRAL_TYPE_P (TREE_TYPE (gimple_cond_lhs (last)))\n-\t\t  || POINTER_TYPE_P (TREE_TYPE (gimple_cond_lhs (last))))\n-\t      && (TREE_CODE (gimple_cond_rhs (last)) == SSA_NAME\n-\t\t  || is_gimple_min_invariant (gimple_cond_rhs (last)))))\n-\t{\n-\t  edge_iterator ei;\n-\n-\t  /* We've got a block with multiple predecessors and multiple\n-\t     successors which also ends in a suitable conditional or\n-\t     switch statement.  For each predecessor, see if we can thread\n-\t     it to a specific successor.  */\n-\t  FOR_EACH_EDGE (e, ei, bb->preds)\n-\t    {\n-\t      /* Do not thread across edges marked to ignoreor abnormal\n-\t\t edges in the CFG.  */\n-\t      if (e->flags & (EDGE_IGNORE | EDGE_COMPLEX))\n-\t\tcontinue;\n-\n-\t      thread_across_edge (dummy, e, equiv_stack, NULL,\n-\t\t\t\t  simplify_stmt_for_jump_threading);\n-\t    }\n-\t}\n-    }\n+  vrp_dom_walker walker (CDI_DOMINATORS, equiv_stack, avail_exprs_stack);\n+  walker.walk (cfun->cfg->x_entry_block_ptr);\n \n   /* Clear EDGE_IGNORE.  */\n   FOR_EACH_VEC_ELT (to_remove_edges, i, e)\n@@ -10997,19 +11006,8 @@ identify_jump_threads (void)\n   /* We do not actually update the CFG or SSA graphs at this point as\n      ASSERT_EXPRs are still in the IL and cfg cleanup code does not yet\n      handle ASSERT_EXPRs gracefully.  */\n-}\n-\n-/* We identified all the jump threading opportunities earlier, but could\n-   not transform the CFG at that time.  This routine transforms the\n-   CFG and arranges for the dominator tree to be rebuilt if necessary.\n-\n-   Note the SSA graph update will occur during the normal TODO\n-   processing by the pass manager.  */\n-static void\n-finalize_jump_threads (void)\n-{\n-  thread_through_all_blocks (false);\n   delete equiv_stack;\n+  delete avail_exprs_stack;\n }\n \n /* Free VRP lattice.  */\n@@ -11075,10 +11073,6 @@ vrp_finalize (bool warn_array_bounds_p)\n \n   if (warn_array_bounds && warn_array_bounds_p)\n     check_all_array_refs ();\n-\n-  /* We must identify jump threading opportunities before we release\n-     the datastructures built by VRP.  */\n-  identify_jump_threads ();\n }\n \n /* evrp_dom_walker visits the basic blocks in the dominance order and set\n@@ -11670,6 +11664,11 @@ execute_vrp (bool warn_array_bounds_p)\n   vrp_initialize ();\n   ssa_propagate (vrp_visit_stmt, vrp_visit_phi_node);\n   vrp_finalize (warn_array_bounds_p);\n+\n+  /* We must identify jump threading opportunities before we release\n+     the datastructures built by VRP.  */\n+  identify_jump_threads ();\n+\n   vrp_free_lattice ();\n \n   free_numbers_of_iterations_estimates (cfun);\n@@ -11686,7 +11685,13 @@ execute_vrp (bool warn_array_bounds_p)\n      duplication and CFG manipulation.  */\n   update_ssa (TODO_update_ssa);\n \n-  finalize_jump_threads ();\n+  /* We identified all the jump threading opportunities earlier, but could\n+     not transform the CFG at that time.  This routine transforms the\n+     CFG and arranges for the dominator tree to be rebuilt if necessary.\n+\n+     Note the SSA graph update will occur during the normal TODO\n+     processing by the pass manager.  */\n+  thread_through_all_blocks (false);\n \n   /* Remove dead edges from SWITCH_EXPR optimization.  This leaves the\n      CFG in a broken state and requires a cfg_cleanup run.  */"}]}