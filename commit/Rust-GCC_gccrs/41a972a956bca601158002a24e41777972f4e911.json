{"sha": "41a972a956bca601158002a24e41777972f4e911", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NDFhOTcyYTk1NmJjYTYwMTE1ODAwMmEyNGU0MTc3Nzk3MmY0ZTkxMQ==", "commit": {"author": {"name": "Mark Mitchell", "email": "mark@markmitchell.com", "date": "1998-08-19T12:30:47Z"}, "committer": {"name": "Jeff Law", "email": "law@gcc.gnu.org", "date": "1998-08-19T12:30:47Z"}, "message": "rtl.h (rtx_function): New type.\n\n\t* rtl.h (rtx_function): New type.\n\t(for_each_rtx): New function.\n\t* rtlanal.c (for_each_rtx): Define it.\n\t* recog.c (change_t): New type.\n\t(change_objects, change_old_codes, change_locs, change_olds):\n\tReplace with ...\n\t(changes): New variable.\n\t(validate_change): Dynamically allocate room for more changes, if\n\tnecessary.  Uses changes array instead of change_objects, etc.\n\t(apply_change_group):  Use changes array instead of\n\tchange_objects, etc.\n\t* loop.c (loop_mem_info): New type.\n\t(loop_mems): New variable.\n\t(loop_mems_idx): Likewise.\n\t(looop_mems_allocated): Likewise.\n\t(scan_loop): Remove nregs parameter.\n\t(next_insn_in_loop): New function.\n\t(load_mems_and_recount_loop_regs_set): Likewise.\n\t(load_mems): Likewise.\n\t(insert_loop_mem): Likewise.\n\t(replace_loop_mem): Likewise.\n\t(replace_label): Likewise.\n\t(INSN_IN_RANGE_P): New macro.\n\t(loop_optimize): Don't pass max_reg_num() to scan_loop.\n\t(scan_loop): Remove nregs parameter, compute it after any new\n\tregisters are created by load_mems.  Use INSN_IN_RANGE_P and\n\tnext_insn_in_loop rather than expanding them inline.  Call\n\tload_mems to load memory into pseudos, if appropriate.\n\t(prescan_loop): Figure out whether or not there are jumps from the\n\tloop to targets other than the label immediately following the\n\tloop.  Call insert_loop_mem to notice all the MEMs used in the\n\tloop, if it could be safe to pull MEMs into REGs for the duration\n\tof the loop.\n\t(strength_reduce): Use next_insn_in_loop.  Tweak comments.\n\nFrom-SVN: r21845", "tree": {"sha": "881990d9aab58e7712420adce4215423daab83f5", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/881990d9aab58e7712420adce4215423daab83f5"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/41a972a956bca601158002a24e41777972f4e911", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/41a972a956bca601158002a24e41777972f4e911", "html_url": "https://github.com/Rust-GCC/gccrs/commit/41a972a956bca601158002a24e41777972f4e911", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/41a972a956bca601158002a24e41777972f4e911/comments", "author": null, "committer": null, "parents": [{"sha": "031fec007065aa597c47b5e251cf2ed9a69d83aa", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/031fec007065aa597c47b5e251cf2ed9a69d83aa", "html_url": "https://github.com/Rust-GCC/gccrs/commit/031fec007065aa597c47b5e251cf2ed9a69d83aa"}], "stats": {"total": 732, "additions": 641, "deletions": 91}, "files": [{"sha": "31bd3d10a5aef771f9bf14ac1bab5d4cb382be38", "filename": "gcc/ChangeLog", "status": "modified", "additions": 39, "deletions": 0, "changes": 39, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/41a972a956bca601158002a24e41777972f4e911/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/41a972a956bca601158002a24e41777972f4e911/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=41a972a956bca601158002a24e41777972f4e911", "patch": "@@ -1,3 +1,42 @@\n+Wed Aug 19 13:28:41 1998  Mark Mitchell  <mark@markmitchell.com>\n+\n+\t* rtl.h (rtx_function): New type.\n+\t(for_each_rtx): New function.\n+\t* rtlanal.c (for_each_rtx): Define it.\n+\t\n+\t* recog.c (change_t): New type.\n+\t(change_objects, change_old_codes, change_locs, change_olds):\n+\tReplace with ...\n+\t(changes): New variable.\n+\t(validate_change): Dynamically allocate room for more changes, if\n+\tnecessary.  Uses changes array instead of change_objects, etc.\n+\t(apply_change_group):  Use changes array instead of\n+\tchange_objects, etc.\n+\t\n+\t* loop.c (loop_mem_info): New type.\n+\t(loop_mems): New variable.\n+\t(loop_mems_idx): Likewise.\n+\t(looop_mems_allocated): Likewise.\n+\t(scan_loop): Remove nregs parameter.\n+\t(next_insn_in_loop): New function.\n+\t(load_mems_and_recount_loop_regs_set): Likewise.\n+\t(load_mems): Likewise.\n+\t(insert_loop_mem): Likewise.\n+\t(replace_loop_mem): Likewise.\n+\t(replace_label): Likewise.\n+\t(INSN_IN_RANGE_P): New macro.\n+\t(loop_optimize): Don't pass max_reg_num() to scan_loop.\n+\t(scan_loop): Remove nregs parameter, compute it after any new\n+\tregisters are created by load_mems.  Use INSN_IN_RANGE_P and\n+\tnext_insn_in_loop rather than expanding them inline.  Call\n+\tload_mems to load memory into pseudos, if appropriate.\n+\t(prescan_loop): Figure out whether or not there are jumps from the\n+\tloop to targets other than the label immediately following the\n+\tloop.  Call insert_loop_mem to notice all the MEMs used in the\n+\tloop, if it could be safe to pull MEMs into REGs for the duration\n+\tof the loop.\n+\t(strength_reduce): Use next_insn_in_loop.  Tweak comments.\n+\n Wed Aug 19 08:29:44 1998  Richard Earnshaw (rearnsha@arm.com)\n \n \t* arm.c (arm_override_options): Remove lie about ignoring PIC flag."}, {"sha": "86782d7292de245ca3b4f7d563d7dd3cadd2c27e", "filename": "gcc/loop.c", "status": "modified", "additions": 567, "deletions": 70, "changes": 637, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/41a972a956bca601158002a24e41777972f4e911/gcc%2Floop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/41a972a956bca601158002a24e41777972f4e911/gcc%2Floop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop.c?ref=41a972a956bca601158002a24e41777972f4e911", "patch": "@@ -195,6 +195,27 @@ static rtx loop_store_mems[NUM_STORES];\n /* Index of first available slot in above array.  */\n static int loop_store_mems_idx;\n \n+typedef struct loop_mem_info {\n+  rtx mem;      /* The MEM itself.  */\n+  rtx reg;      /* Corresponding pseudo, if any.  */\n+  int optimize; /* Nonzero if we can optimize access to this MEM.  */\n+} loop_mem_info;\n+\n+/* Array of MEMs that are used (read or written) in this loop, but\n+   cannot be aliased by anything in this loop, except perhaps\n+   themselves.  In other words, if loop_mems[i] is altered during the\n+   loop, it is altered by an expression that is rtx_equal_p to it.  */\n+\n+static loop_mem_info *loop_mems;\n+\n+/* The index of the next available slot in LOOP_MEMS.  */\n+\n+static int loop_mems_idx;\n+\n+/* The number of elements allocated in LOOP_MEMs.  */\n+\n+static int loop_mems_allocated;\n+\n /* Nonzero if we don't know what MEMs were changed in the current loop.\n    This happens if the loop contains a call (in which case `loop_has_call'\n    will also be set) or if we store into more than NUM_STORES MEMs.  */\n@@ -288,7 +309,7 @@ static int labels_in_range_p PROTO((rtx, int));\n static void count_loop_regs_set PROTO((rtx, rtx, char *, rtx *, int *, int));\n static void note_addr_stored PROTO((rtx, rtx));\n static int loop_reg_used_before_p PROTO((rtx, rtx, rtx, rtx, rtx));\n-static void scan_loop PROTO((rtx, rtx, int, int));\n+static void scan_loop PROTO((rtx, rtx, int));\n #if 0\n static void replace_call_address PROTO((rtx, rtx, rtx));\n #endif\n@@ -325,6 +346,29 @@ static int maybe_eliminate_biv_1 PROTO((rtx, rtx, struct iv_class *, int, rtx));\n static int last_use_this_basic_block PROTO((rtx, rtx));\n static void record_initial PROTO((rtx, rtx));\n static void update_reg_last_use PROTO((rtx, rtx));\n+static rtx next_insn_in_loop PROTO((rtx, rtx, rtx, rtx));\n+static void load_mems_and_recount_loop_regs_set PROTO((rtx, rtx, rtx,\n+\t\t\t\t\t\t       rtx, rtx *, int *));\n+static void load_mems PROTO((rtx, rtx, rtx, rtx));\n+static int insert_loop_mem PROTO((rtx *, void *));\n+static int replace_loop_mem PROTO((rtx *, void *));\n+static int replace_label PROTO((rtx *, void *));\n+\n+typedef struct rtx_and_int {\n+  rtx r;\n+  int i;\n+} rtx_and_int;\n+\n+typedef struct rtx_pair {\n+  rtx r1;\n+  rtx r2;\n+} rtx_pair;\n+\n+/* Nonzero iff INSN is between START and END, inclusive.  */\n+#define INSN_IN_RANGE_P(INSN, START, END) \t\\\n+  (INSN_UID (INSN) < max_uid_for_loop \t\t\\\n+   && INSN_LUID (INSN) >= INSN_LUID (START)\t\\\n+   && INSN_LUID (INSN) <= INSN_LUID (END))\n \n #ifdef HAIFA\n /* This is extern from unroll.c */\n@@ -543,7 +587,7 @@ loop_optimize (f, dumpfile, unroll_p)\n   for (i = max_loop_num-1; i >= 0; i--)\n     if (! loop_invalid[i] && loop_number_loop_ends[i])\n       scan_loop (loop_number_loop_starts[i], loop_number_loop_ends[i],\n-\t\t max_reg_num (), unroll_p);\n+\t\t unroll_p);\n \n   /* If debugging and unrolling loops, we must replicate the tree nodes\n      corresponding to the blocks inside the loop, so that the original one\n@@ -554,6 +598,38 @@ loop_optimize (f, dumpfile, unroll_p)\n   end_alias_analysis ();\n }\n \f\n+/* Returns the next insn, in execution order, after INSN.  START and\n+   END are the NOTE_INSN_LOOP_BEG and NOTE_INSN_LOOP_END for the loop,\n+   respectively.  LOOP_TOP, if non-NULL, is the top of the loop in the\n+   insn-stream; it is used with loops that are entered near the\n+   bottom.  */\n+\n+static rtx\n+next_insn_in_loop (insn, start, end, loop_top)\n+     rtx insn;\n+     rtx start;\n+     rtx end;\n+     rtx loop_top;\n+{\n+  insn = NEXT_INSN (insn);\n+\n+  if (insn == end)\n+    {\n+      if (loop_top)\n+\t/* Go to the top of the loop, and continue there.  */\n+\tinsn = loop_top;\n+      else\n+\t/* We're done.  */\n+\tinsn = NULL_RTX;\n+    }\n+\n+  if (insn == start)\n+    /* We're done.  */\n+    insn = NULL_RTX;\n+\n+  return insn;\n+}\n+\n /* Optimize one loop whose start is LOOP_START and end is END.\n    LOOP_START is the NOTE_INSN_LOOP_BEG and END is the matching\n    NOTE_INSN_LOOP_END.  */\n@@ -565,13 +641,12 @@ loop_optimize (f, dumpfile, unroll_p)\n    write, then we can also mark the memory read as invariant.  */\n \n static void\n-scan_loop (loop_start, end, nregs, unroll_p)\n+scan_loop (loop_start, end, unroll_p)\n      rtx loop_start, end;\n-     int nregs;\n      int unroll_p;\n {\n   register int i;\n-  register rtx p;\n+  rtx p;\n   /* 1 if we are scanning insns that could be executed zero times.  */\n   int maybe_never = 0;\n   /* 1 if we are scanning insns that might never be executed\n@@ -606,10 +681,7 @@ scan_loop (loop_start, end, nregs, unroll_p)\n   rtx *reg_single_usage = 0;\n   /* Nonzero if we are scanning instructions in a sub-loop.  */\n   int loop_depth = 0;\n-\n-  n_times_set = (int *) alloca (nregs * sizeof (int));\n-  n_times_used = (int *) alloca (nregs * sizeof (int));\n-  may_not_optimize = (char *) alloca (nregs);\n+  int nregs;\n \n   /* Determine whether this loop starts with a jump down to a test at\n      the end.  This will occur for a small number of loops with a test\n@@ -660,9 +732,7 @@ scan_loop (loop_start, end, nregs, unroll_p)\n \t     do {..} while (0).  If this label was generated previously\n \t     by loop, we can't tell anything about it and have to reject\n \t     the loop.  */\n-\t  && INSN_UID (JUMP_LABEL (p)) < max_uid_for_loop\n-\t  && INSN_LUID (JUMP_LABEL (p)) >= INSN_LUID (loop_start)\n-\t  && INSN_LUID (JUMP_LABEL (p)) < INSN_LUID (end))\n+\t  && INSN_IN_RANGE_P (JUMP_LABEL (p), loop_start, end))\n \t{\n \t  loop_top = next_label (scan_start);\n \t  scan_start = JUMP_LABEL (p);\n@@ -690,7 +760,13 @@ scan_loop (loop_start, end, nregs, unroll_p)\n      Set may_not_optimize[I] if it is not safe to move out\n      the setting of register I.  If this loop has calls, set\n      reg_single_usage[I].  */\n-\n+  \n+  /* Allocate extra space for REGS that might be created by\n+     load_mems.  */\n+  nregs = max_reg_num () + loop_mems_idx;\n+  n_times_set = (int *) alloca (nregs * sizeof (int));\n+  n_times_used = (int *) alloca (nregs * sizeof (int));\n+  may_not_optimize = (char *) alloca (nregs);\n   bzero ((char *) n_times_set, nregs * sizeof (int));\n   bzero (may_not_optimize, nregs);\n \n@@ -729,24 +805,10 @@ scan_loop (loop_start, end, nregs, unroll_p)\n      When MAYBE_NEVER is 0, all insns will be executed at least once\n      so that is not a problem.  */\n \n-  p = scan_start;\n-  while (1)\n+  for (p = next_insn_in_loop (scan_start, scan_start, end, loop_top); \n+       p != NULL_RTX;\n+       p = next_insn_in_loop (p, scan_start, end, loop_top))\n     {\n-      p = NEXT_INSN (p);\n-      /* At end of a straight-in loop, we are done.\n-\t At end of a loop entered at the bottom, scan the top.  */\n-      if (p == scan_start)\n-\tbreak;\n-      if (p == end)\n-\t{\n-\t  if (loop_top != 0)\n-\t    p = loop_top;\n-\t  else\n-\t    break;\n-\t  if (p == scan_start)\n-\t    break;\n-\t}\n-\n       if (GET_RTX_CLASS (GET_CODE (p)) == 'i'\n \t  && find_reg_note (p, REG_LIBCALL, NULL_RTX))\n \tin_libcall = 1;\n@@ -1093,6 +1155,13 @@ scan_loop (loop_start, end, nregs, unroll_p)\n     if (n_times_set[i] < 0)\n       n_times_set[i] = n_times_used[i];\n \n+  /* Now that we've moved some things out of the loop, we able to\n+     hoist even more memory references.  There's no need to pass\n+     reg_single_usage this time, since we're done with it.  */\n+  load_mems_and_recount_loop_regs_set (scan_start, end, loop_top,\n+\t\t\t\t       loop_start, 0,\n+\t\t\t\t       &insn_count);\n+\n   if (flag_strength_reduce)\n     {\n       the_movables = movables;\n@@ -2293,20 +2362,29 @@ constant_high_bytes (p, loop_start)\n \f\n /* Scan a loop setting the variables `unknown_address_altered',\n    `num_mem_sets', `loop_continue', loops_enclosed', `loop_has_call',\n-   and `loop_has_volatile'.\n-   Also, fill in the array `loop_store_mems'.  */\n+   and `loop_has_volatile'.  Also, fill in the arrays `loop_mems' and\n+   `loop_store_mems'.  */\n \n static void\n prescan_loop (start, end)\n      rtx start, end;\n {\n   register int level = 1;\n-  register rtx insn;\n+  rtx insn;\n+  int loop_has_multiple_exit_targets = 0;\n+  /* The label after END.  Jumping here is just like falling off the\n+     end of the loop.  We use next_nonnote_insn instead of next_label\n+     as a hedge against the (pathological) case where some actual insn\n+     might end up between the two.  */\n+  rtx exit_target = next_nonnote_insn (end);\n+  if (exit_target == NULL_RTX || GET_CODE (exit_target) != CODE_LABEL)\n+    loop_has_multiple_exit_targets = 1;\n \n   unknown_address_altered = 0;\n   loop_has_call = 0;\n   loop_has_volatile = 0;\n   loop_store_mems_idx = 0;\n+  loop_mems_idx = 0;\n \n   num_mem_sets = 0;\n   loops_enclosed = 1;\n@@ -2344,17 +2422,75 @@ prescan_loop (start, end)\n \t    unknown_address_altered = 1;\n \t  loop_has_call = 1;\n \t}\n-      else\n+      else if (GET_CODE (insn) == INSN || GET_CODE (insn) == JUMP_INSN)\n \t{\n-\t  if (GET_CODE (insn) == INSN || GET_CODE (insn) == JUMP_INSN)\n+\t  rtx label1 = NULL_RTX;\n+\t  rtx label2 = NULL_RTX;\n+\n+\t  if (volatile_refs_p (PATTERN (insn)))\n+\t    loop_has_volatile = 1;\n+\t  \n+\t  note_stores (PATTERN (insn), note_addr_stored);\n+\n+\t  if (!loop_has_multiple_exit_targets\n+\t      && GET_CODE (insn) == JUMP_INSN\n+\t      && GET_CODE (PATTERN (insn)) == SET\n+\t      && SET_DEST (PATTERN (insn)) == pc_rtx)\n \t    {\n-\t      if (volatile_refs_p (PATTERN (insn)))\n-\t\tloop_has_volatile = 1;\n+\t      if (GET_CODE (SET_SRC (PATTERN (insn))) == IF_THEN_ELSE)\n+\t\t{\n+\t\t  label1 = XEXP (SET_SRC (PATTERN (insn)), 1);\n+\t\t  label2 = XEXP (SET_SRC (PATTERN (insn)), 2);\n+\t\t}\n+\t      else\n+\t\t{\n+\t\t  label1 = SET_SRC (PATTERN (insn));\n+\t\t}\n+\n+\t      do {\n+\t\tif (label1 && label1 != pc_rtx)\n+\t\t  {\n+\t\t    if (GET_CODE (label1) != LABEL_REF)\n+\t\t      {\n+\t\t\t/* Something tricky.  */\n+\t\t\tloop_has_multiple_exit_targets = 1;\n+\t\t\tbreak;\n+\t\t      }\n+\t\t    else if (XEXP (label1, 0) != exit_target\n+\t\t\t     && LABEL_OUTSIDE_LOOP_P (label1))\n+\t\t      {\n+\t\t\t/* A jump outside the current loop.  */\n+\t\t\tloop_has_multiple_exit_targets = 1;\n+\t\t\tbreak;\n+\t\t      }\n+\t\t  }\n \n-\t      note_stores (PATTERN (insn), note_addr_stored);\n+\t\tlabel1 = label2;\n+\t\tlabel2 = NULL_RTX;\n+\t      } while (label1);\n \t    }\n \t}\n+      else if (GET_CODE (insn) == RETURN)\n+\tloop_has_multiple_exit_targets = 1;\n     }\n+\n+  /* Now, rescan the loop, setting up the LOOP_MEMS array.  */\n+  if (/* We can't tell what MEMs are aliased by what.  */\n+      !unknown_address_altered \n+      /* An exception thrown by a called function might land us\n+\t anywhere.  */\n+      && !loop_has_call\n+      /* We don't want loads for MEMs moved to a location before the\n+\t one at which their stack memory becomes allocated.  (Note\n+\t that this is not a problem for malloc, etc., since those\n+\t require actual function calls.  */\n+      && !current_function_calls_alloca\n+      /* There are ways to leave the loop other than falling off the\n+\t end.  */\n+      && !loop_has_multiple_exit_targets)\n+    for (insn = NEXT_INSN (start); insn != NEXT_INSN (end);\n+\t insn = NEXT_INSN (insn))\n+      for_each_rtx (&insn, insert_loop_mem, 0);\n }\n \f\n /* Scan the function looking for loops.  Record the start and end of each loop.\n@@ -3360,18 +3496,6 @@ static rtx addr_placeholder;\n /* ??? Unfinished optimizations, and possible future optimizations,\n    for the strength reduction code.  */\n \n-/* ??? There is one more optimization you might be interested in doing: to\n-   allocate pseudo registers for frequently-accessed memory locations.\n-   If the same memory location is referenced each time around, it might\n-   be possible to copy it into a register before and out after.\n-   This is especially useful when the memory location is a variable which\n-   is in a stack slot because somewhere its address is taken.  If the\n-   loop doesn't contain a function call and the variable isn't volatile,\n-   it is safe to keep the value in a register for the duration of the\n-   loop. One tricky thing is that the copying of the value back from the\n-   register has to be done on all exits from the loop.  You need to check that\n-   all the exits from the loop go to the same place.  */\n-\n /* ??? The interaction of biv elimination, and recognition of 'constant'\n    bivs, may cause problems.  */\n \n@@ -3396,13 +3520,18 @@ static rtx addr_placeholder;\n    was rerun in loop_optimize whenever a register was added or moved.\n    Also, some of the optimizations could be a little less conservative.  */\n \f\n-/* Perform strength reduction and induction variable elimination.  */\n+/* Perform strength reduction and induction variable elimination.  \n \n-/* Pseudo registers created during this function will be beyond the last\n+   Pseudo registers created during this function will be beyond the last\n    valid index in several tables including n_times_set and regno_last_uid.\n    This does not cause a problem here, because the added registers cannot be\n    givs outside of their loop, and hence will never be reconsidered.\n-   But scan_loop must check regnos to make sure they are in bounds.  */\n+   But scan_loop must check regnos to make sure they are in bounds. \n+   \n+   SCAN_START is the first instruction in the loop, as the loop would\n+   actually be executed.  END is the NOTE_INSN_LOOP_END.  LOOP_TOP is\n+   the first instruction in the loop, as it is layed out in the\n+   instruction stream.  LOOP_START is the NOTE_INSN_LOOP_BEG.  */\n \n static void\n strength_reduce (scan_start, end, loop_top, insn_count,\n@@ -3470,24 +3599,10 @@ strength_reduce (scan_start, end, loop_top, insn_count,\n \n   /* Scan through loop to find all possible bivs.  */\n \n-  p = scan_start;\n-  while (1)\n+  for (p = next_insn_in_loop (scan_start, scan_start, end, loop_top);\n+       p != NULL_RTX;\n+       p = next_insn_in_loop (p, scan_start, end, loop_top))\n     {\n-      p = NEXT_INSN (p);\n-      /* At end of a straight-in loop, we are done.\n-\t At end of a loop entered at the bottom, scan the top.  */\n-      if (p == scan_start)\n-\tbreak;\n-      if (p == end)\n-\t{\n-\t  if (loop_top != 0)\n-\t    p = loop_top;\n-\t  else\n-\t    break;\n-\t  if (p == scan_start)\n-\t    break;\n-\t}\n-\n       if (GET_CODE (p) == INSN\n \t  && (set = single_set (p))\n \t  && GET_CODE (SET_DEST (set)) == REG)\n@@ -8208,3 +8323,385 @@ indirect_jump_in_function_p (start)\n \n   return 0;\n }\n+\n+/* Add MEM to the LOOP_MEMS array, if appropriate.  See the\n+   documentation for LOOP_MEMS for the definition of `appropriate'.\n+   This function is called from prescan_loop via for_each_rtx.  */\n+\n+static int\n+insert_loop_mem (mem, data)\n+     rtx *mem;\n+     void *data;\n+{\n+  int i;\n+  rtx m = *mem;\n+\n+  if (m == NULL_RTX)\n+    return 0;\n+\n+  switch (GET_CODE (m))\n+    {\n+    case MEM:\n+      break;\n+\n+    case CONST_DOUBLE:\n+      /* We're not interested in the MEM associated with a\n+\t CONST_DOUBLE, so there's no need to traverse into this.  */\n+      return -1;\n+\n+    default:\n+      /* This is not a MEM.  */\n+      return 0;\n+    }\n+\n+  /* See if we've already seen this MEM.  */\n+  for (i = 0; i < loop_mems_idx; ++i)\n+    if (rtx_equal_p (m, loop_mems[i].mem)) \n+      {\n+\tif (GET_MODE (m) != GET_MODE (loop_mems[i].mem))\n+\t  /* The modes of the two memory accesses are different.  If\n+\t     this happens, something tricky is going on, and we just\n+\t     don't optimize accesses to this MEM.  */\n+\t  loop_mems[i].optimize = 0;\n+\n+\treturn 0;\n+      }\n+\n+  /* Resize the array, if necessary.  */\n+  if (loop_mems_idx == loop_mems_allocated) \n+    {\n+      if (loop_mems_allocated != 0)\n+\tloop_mems_allocated *= 2;\n+      else\n+\tloop_mems_allocated = 32;\n+\n+      loop_mems = (loop_mem_info*) \n+\txrealloc (loop_mems,\n+\t\t  loop_mems_allocated * sizeof (loop_mem_info)); \n+    }\n+\n+  /* Actually insert the MEM.  */\n+  loop_mems[loop_mems_idx].mem = m;\n+  /* We can't hoist this MEM out of the loop if it's a BLKmode MEM\n+     because we can't put it in a register.  We still store it in the\n+     table, though, so that if we see the same address later, but in a\n+     non-BLK mode, we'll not think we can optimize it at that point.  */\n+  loop_mems[loop_mems_idx].optimize = (GET_MODE (m) != BLKmode);\n+  loop_mems[loop_mems_idx].reg = NULL_RTX;\n+  ++loop_mems_idx;\n+}\n+\n+/* Like load_mems, but also ensures that N_TIMES_SET,\n+   MAY_NOT_OPTIMIZE, REG_SINGLE_USAGE, and INSN_COUNT have the correct\n+   values after load_mems.  */\n+\n+static void\n+load_mems_and_recount_loop_regs_set (scan_start, end, loop_top, start,\n+\t\t\t\t     reg_single_usage, insn_count)\n+     rtx scan_start;\n+     rtx end;\n+     rtx loop_top;\n+     rtx start;\n+     rtx *reg_single_usage;\n+     int *insn_count;\n+{\n+  int nregs = max_reg_num ();\n+\n+  load_mems (scan_start, end, loop_top, start);\n+  \n+  /* Recalculate n_times_set and friends since load_mems may have\n+     created new registers.  */\n+  if (max_reg_num () > nregs)\n+    {\n+      int i;\n+      int old_nregs;\n+\n+      old_nregs = nregs;\n+      nregs = max_reg_num ();\n+\n+      /* Note that we assume here that enough room was allocated in\n+\t the various arrays to accomodate the extra registers created\n+\t by load_mems.  */\n+      bzero ((char *) n_times_set, nregs * sizeof (int));\n+      bzero (may_not_optimize, nregs);\n+      if (loop_has_call && reg_single_usage)\n+\tbzero ((char *) reg_single_usage, nregs * sizeof (rtx));\n+\n+      count_loop_regs_set (loop_top ? loop_top : start, end,\n+\t\t\t   may_not_optimize, reg_single_usage,\n+\t\t\t   insn_count, nregs); \n+\n+      for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n+\tmay_not_optimize[i] = 1, n_times_set[i] = 1;\n+      \n+      /* Set n_times_used for the new registers.  */\n+      bcopy ((char *) (n_times_set + old_nregs),\n+\t     (char *) (n_times_used + old_nregs),\n+\t     (nregs - old_nregs) * sizeof (int));\n+    }\n+}\n+\n+/* Move MEMs into registers for the duration of the loop.  SCAN_START\n+   is the first instruction in the loop (as it is executed).  The\n+   other parameters are as for next_insn_in_loop.  */\n+\n+static void\n+load_mems (scan_start, end, loop_top, start)\n+     rtx scan_start;\n+     rtx end;\n+     rtx loop_top;\n+     rtx start;\n+{\n+  int maybe_never = 0;\n+  int i;\n+  rtx p;\n+  rtx label = NULL_RTX;\n+  rtx end_label;\n+\n+  if (loop_mems_idx > 0) \n+    {\n+      /* Nonzero if the next instruction may never be executed.  */\n+      int next_maybe_never = 0;\n+\n+      /* Check to see if it's possible that some instructions in the\n+\t loop are never executed.  */\n+      for (p = next_insn_in_loop (scan_start, scan_start, end, loop_top); \n+\t   p != NULL_RTX && !maybe_never; \n+\t   p = next_insn_in_loop (p, scan_start, end, loop_top))\n+\t{\n+\t  if (GET_CODE (p) == CODE_LABEL)\n+\t    maybe_never = 1;\n+\t  else if (GET_CODE (p) == JUMP_INSN\n+\t\t   /* If we enter the loop in the middle, and scan\n+\t\t      around to the beginning, don't set maybe_never\n+\t\t      for that.  This must be an unconditional jump,\n+\t\t      otherwise the code at the top of the loop might\n+\t\t      never be executed.  Unconditional jumps are\n+\t\t      followed a by barrier then loop end.  */\n+\t\t   && ! (GET_CODE (p) == JUMP_INSN \n+\t\t\t && JUMP_LABEL (p) == loop_top\n+\t\t\t && NEXT_INSN (NEXT_INSN (p)) == end\n+\t\t\t && simplejump_p (p)))\n+\t    {\n+\t      if (!condjump_p (p))\n+\t\t/* Something complicated.  */\n+\t\tmaybe_never = 1;\n+\t      else\n+\t\t/* If there are any more instructions in the loop, they\n+\t\t   might not be reached.  */\n+\t\tnext_maybe_never = 1; \n+\t    } \n+\t  else if (next_maybe_never)\n+\t    maybe_never = 1;\n+\t}\n+\n+      /* Actually move the MEMs.  */\n+      for (i = 0; i < loop_mems_idx; ++i) \n+\t{\n+\t  int j;\n+\t  int written = 0;\n+\t  rtx reg;\n+\t  rtx mem = loop_mems[i].mem;\n+\n+\t  if (MEM_VOLATILE_P (mem) \n+\t      || invariant_p (XEXP (mem, 0)) != 1)\n+\t    /* There's no telling whether or not MEM is modified.  */\n+\t    loop_mems[i].optimize = 0;\n+\n+\t  /* Go through the MEMs written to in the loop to see if this\n+\t     one is aliased by one of them.  */\n+\t  for (j = 0; j < loop_store_mems_idx; ++j) \n+\t    {\n+\t      if (rtx_equal_p (mem, loop_store_mems[j]))\n+\t\twritten = 1;\n+\t      else if (true_dependence (loop_store_mems[j], VOIDmode,\n+\t\t\t\t\tmem, rtx_varies_p))\n+\t\t{\n+\t\t  /* MEM is indeed aliased by this store.  */\n+\t\t  loop_mems[i].optimize = 0;\n+\t\t  break;\n+\t\t}\n+\t    }\n+\t  \n+\t  /* If this MEM is written to, we must be sure that there\n+\t     are no reads from another MEM that aliases this one.  */ \n+\t  if (loop_mems[i].optimize && written)\n+\t    {\n+\t      int j;\n+\n+\t      for (j = 0; j < loop_mems_idx; ++j)\n+\t\t{\n+\t\t  if (j == i)\n+\t\t    continue;\n+\t\t  else if (true_dependence (mem,\n+\t\t\t\t\t    VOIDmode,\n+\t\t\t\t\t    loop_mems[j].mem,\n+\t\t\t\t\t    rtx_varies_p))\n+\t\t    {\n+\t\t      /* It's not safe to hoist loop_mems[i] out of\n+\t\t\t the loop because writes to it might not be\n+\t\t\t seen by reads from loop_mems[j].  */\n+\t\t      loop_mems[i].optimize = 0;\n+\t\t      break;\n+\t\t    }\n+\t\t}\n+\t    }\n+\n+\t  if (maybe_never && may_trap_p (mem))\n+\t    /* We can't access the MEM outside the loop; it might\n+\t       cause a trap that wouldn't have happened otherwise.  */\n+\t    loop_mems[i].optimize = 0;\n+\t  \n+\t  if (!loop_mems[i].optimize)\n+\t    /* We thought we were going to lift this MEM out of the\n+\t       loop, but later discovered that we could not.  */\n+\t    continue;\n+\n+\t  /* Allocate a pseudo for this MEM.  We set REG_USERVAR_P in\n+\t     order to keep scan_loop from moving stores to this MEM\n+\t     out of the loop just because this REG is neither a\n+\t     user-variable nor used in the loop test.  */\n+\t  reg = gen_reg_rtx (GET_MODE (mem));\n+\t  REG_USERVAR_P (reg) = 1;\n+\t  loop_mems[i].reg = reg;\n+\n+\t  /* Now, replace all references to the MEM with the\n+\t     corresponding pesudos.  */\n+\t  for (p = next_insn_in_loop (scan_start, scan_start, end, loop_top);\n+\t       p != NULL_RTX;\n+\t       p = next_insn_in_loop (p, scan_start, end, loop_top))\n+\t    {\n+\t      rtx_and_int ri = { p, i };\n+\t      for_each_rtx (&p, replace_loop_mem, &ri);\n+\t    }\n+\n+\t  if (!apply_change_group ())\n+\t    /* We couldn't replace all occurrences of the MEM.  */\n+\t    loop_mems[i].optimize = 0;\n+\t  else\n+\t    {\n+\t      rtx set;\n+\n+\t      /* Load the memory immediately before START, which is\n+\t\t the NOTE_LOOP_BEG.  */\n+\t      set = gen_rtx_SET (GET_MODE (reg), reg, mem);\n+\t      emit_insn_before (set, start);\n+\n+\t      if (written)\n+\t\t{\n+\t\t  if (label == NULL_RTX)\n+\t\t    {\n+\t\t      /* We must compute the former\n+\t\t\t right-after-the-end label before we insert\n+\t\t\t the new one.  */\n+\t\t      end_label = next_label (end);\n+\t\t      label = gen_label_rtx ();\n+\t\t      emit_label_after (label, end);\n+\t\t    }\n+\n+\t\t  /* Store the memory immediately after END, which is\n+\t\t   the NOTE_LOOP_END.  */\n+\t\t  set = gen_rtx_SET (GET_MODE (reg), mem, reg); \n+\t\t  emit_insn_after (set, label);\n+\t\t}\n+\n+\t      if (loop_dump_stream)\n+\t\t{\n+\t\t  fprintf (loop_dump_stream, \"Hoisted regno %d %s from \",\n+\t\t\t   REGNO (reg), (written ? \"r/w\" : \"r/o\"));\n+\t\t  print_rtl (loop_dump_stream, mem);\n+\t\t  fputc ('\\n', loop_dump_stream);\n+\t\t}\n+\t    }\n+\t}\n+    }\n+\n+  if (label != NULL_RTX)\n+    {\n+      /* Now, we need to replace all references to the previous exit\n+\t label with the new one.  */\n+      rtx_pair rr = { end_label, label };\n+\n+      for (p = start; p != end; p = NEXT_INSN (p))\n+\tfor_each_rtx (&p, replace_label, &rr);\n+    }\n+}\n+\n+/* Replace MEM with its associated pseudo register.  This function is\n+   called from load_mems via for_each_rtx.  DATA is actually an\n+   rtx_and_int * describing the instruction currently being scanned\n+   and the MEM we are currently replacing.  */\n+\n+static int\n+replace_loop_mem (mem, data)\n+     rtx *mem;\n+     void *data;\n+{\n+  rtx_and_int *ri; \n+  rtx insn;\n+  int i;\n+  rtx m = *mem;\n+\n+  if (m == NULL_RTX)\n+    return 0;\n+\n+  switch (GET_CODE (m))\n+    {\n+    case MEM:\n+      break;\n+\n+    case CONST_DOUBLE:\n+      /* We're not interested in the MEM associated with a\n+\t CONST_DOUBLE, so there's no need to traverse into one.  */\n+      return -1;\n+\n+    default:\n+      /* This is not a MEM.  */\n+      return 0;\n+    }\n+\n+  ri = (rtx_and_int*) data;\n+  i = ri->i;\n+\n+  if (!rtx_equal_p (loop_mems[i].mem, m))\n+    /* This is not the MEM we are currently replacing.  */\n+    return 0;\n+\n+  insn = ri->r;\n+\n+  /* Actually replace the MEM.  */\n+  validate_change (insn, mem, loop_mems[i].reg, 1);\n+\n+  return 0;\n+}\n+\n+/* Replace occurrences of the old exit label for the loop with the new\n+   one.  DATA is an rtx_pair containing the old and new labels,\n+   respectively.  */\n+\n+static int\n+replace_label (x, data)\n+     rtx *x;\n+     void *data;\n+{\n+  rtx l = *x;\n+  rtx old_label = ((rtx_pair*) data)->r1;\n+  rtx new_label = ((rtx_pair*) data)->r2;\n+\n+  if (l == NULL_RTX)\n+    return 0;\n+\n+  if (GET_CODE (l) != LABEL_REF)\n+    return 0;\n+\n+  if (XEXP (l, 0) != old_label)\n+    return 0;\n+  \n+  XEXP (l, 0) = new_label;\n+  ++LABEL_NUSES (new_label);\n+  --LABEL_NUSES (old_label);\n+\n+  return 0;\n+}\n+\n+     "}, {"sha": "dd73a46bdc90068ed27c258f80052e5a2585d32e", "filename": "gcc/recog.c", "status": "modified", "additions": 33, "deletions": 21, "changes": 54, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/41a972a956bca601158002a24e41777972f4e911/gcc%2Frecog.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/41a972a956bca601158002a24e41777972f4e911/gcc%2Frecog.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frecog.c?ref=41a972a956bca601158002a24e41777972f4e911", "patch": "@@ -128,19 +128,18 @@ check_asm_operands (x)\n   return 1;\n }\n \f\n-/* Static data for the next two routines.\n+/* Static data for the next two routines.  */\n \n-   The maximum number of changes supported is defined as the maximum\n-   number of operands times 5.  This allows for repeated substitutions\n-   inside complex indexed address, or, alternatively, changes in up\n-   to 5 insns.  */\n-\n-#define MAX_CHANGE_LOCS\t(MAX_RECOG_OPERANDS * 5)\n+typedef struct change_t\n+{\n+  rtx object;\n+  int old_code;\n+  rtx *loc;\n+  rtx old;\n+} change_t;\n \n-static rtx change_objects[MAX_CHANGE_LOCS];\n-static int change_old_codes[MAX_CHANGE_LOCS];\n-static rtx *change_locs[MAX_CHANGE_LOCS];\n-static rtx change_olds[MAX_CHANGE_LOCS];\n+static change_t *changes;\n+static int changes_allocated;\n \n static int num_changes = 0;\n \n@@ -174,22 +173,35 @@ validate_change (object, loc, new, in_group)\n   if (old == new || rtx_equal_p (old, new))\n     return 1;\n \n-  if (num_changes >= MAX_CHANGE_LOCS\n-      || (in_group == 0 && num_changes != 0))\n+  if (in_group == 0 && num_changes != 0)\n     abort ();\n \n   *loc = new;\n \n   /* Save the information describing this change.  */\n-  change_objects[num_changes] = object;\n-  change_locs[num_changes] = loc;\n-  change_olds[num_changes] = old;\n+  if (num_changes >= changes_allocated)\n+    {\n+      if (changes_allocated == 0)\n+\t/* This value allows for repeated substitutions inside complex\n+\t   indexed addresses, or changes in up to 5 insns.  */\n+\tchanges_allocated = MAX_RECOG_OPERANDS * 5;\n+      else\n+\tchanges_allocated *= 2;\n+\n+      changes = \n+\t(change_t*) xrealloc (changes, \n+\t\t\t      sizeof (change_t) * changes_allocated); \n+    }\n+  \n+  changes[num_changes].object = object;\n+  changes[num_changes].loc = loc;\n+  changes[num_changes].old = old;\n \n   if (object && GET_CODE (object) != MEM)\n     {\n       /* Set INSN_CODE to force rerecognition of insn.  Save old code in\n \t case invalid.  */\n-      change_old_codes[num_changes] = INSN_CODE (object);\n+      changes[num_changes].old_code = INSN_CODE (object);\n       INSN_CODE (object) = -1;\n     }\n \n@@ -224,7 +236,7 @@ apply_change_group ()\n \n   for (i = 0; i < num_changes; i++)\n     {\n-      rtx object = change_objects[i];\n+      rtx object = changes[i].object;\n \n       if (object == 0)\n \tcontinue;\n@@ -319,9 +331,9 @@ cancel_changes (num)\n      they were made.  */\n   for (i = num_changes - 1; i >= num; i--)\n     {\n-      *change_locs[i] = change_olds[i];\n-      if (change_objects[i] && GET_CODE (change_objects[i]) != MEM)\n-\tINSN_CODE (change_objects[i]) = change_old_codes[i];\n+      *changes[i].loc = changes[i].old;\n+      if (changes[i].object && GET_CODE (changes[i].object) != MEM)\n+\tINSN_CODE (changes[i].object) = changes[i].old_code;\n     }\n   num_changes = num;\n }"}, {"sha": "c26b76eb1efbf5030fda63a6e4e7ac4757025f35", "filename": "gcc/rtl.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/41a972a956bca601158002a24e41777972f4e911/gcc%2Frtl.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/41a972a956bca601158002a24e41777972f4e911/gcc%2Frtl.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl.h?ref=41a972a956bca601158002a24e41777972f4e911", "patch": "@@ -1000,6 +1000,8 @@ extern int inequality_comparison_p\tPROTO((rtx));\n extern rtx replace_rtx\t\t\tPROTO((rtx, rtx, rtx));\n extern rtx replace_regs\t\t\tPROTO((rtx, rtx *, int, int));\n extern int computed_jump_p\t\tPROTO((rtx));\n+typedef int (*rtx_function)             PROTO((rtx *, void *));\n+extern int for_each_rtx                 PROTO((rtx *, rtx_function, void *));\n \n /* Maximum number of parallel sets and clobbers in any insn in this fn.\n    Always at least 3, since the combiner could put that many togetherm"}]}