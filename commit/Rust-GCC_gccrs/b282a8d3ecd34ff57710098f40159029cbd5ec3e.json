{"sha": "b282a8d3ecd34ff57710098f40159029cbd5ec3e", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YjI4MmE4ZDNlY2QzNGZmNTc3MTAwOThmNDAxNTkwMjljYmQ1ZWMzZQ==", "commit": {"author": {"name": "H.J. Lu", "email": "hongjiu.lu@intel.com", "date": "2008-05-10T12:56:45Z"}, "committer": {"name": "H.J. Lu", "email": "hjl@gcc.gnu.org", "date": "2008-05-10T12:56:45Z"}, "message": "i386.c (bdesc_ptest): Removed.\n\n2008-05-10  H.J. Lu  <hongjiu.lu@intel.com>\n\n\t* config/i386/i386.c (bdesc_ptest): Removed.\n\t(ix86_builtin_type): Add INT_FTYPE_V2DI_V2DI_PTEST.\n\t(bdesc_args): Add __builtin_ia32_ptestz128,\n\t__builtin_ia32_ptestc128 and __builtin_ia32_ptestnzc128.\n\t(ix86_init_mmx_sse_builtins): Updated.\n\t(ix86_expand_args_builtin): Handle INT_FTYPE_V2DI_V2DI_PTEST.\n\t(ix86_expand_builtin): Updated.\n\nFrom-SVN: r135144", "tree": {"sha": "d98833eef8223a3ef83a0275206c05cb7ea9536c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/d98833eef8223a3ef83a0275206c05cb7ea9536c"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/b282a8d3ecd34ff57710098f40159029cbd5ec3e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b282a8d3ecd34ff57710098f40159029cbd5ec3e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b282a8d3ecd34ff57710098f40159029cbd5ec3e", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b282a8d3ecd34ff57710098f40159029cbd5ec3e/comments", "author": {"login": "hjl-tools", "id": 1072356, "node_id": "MDQ6VXNlcjEwNzIzNTY=", "avatar_url": "https://avatars.githubusercontent.com/u/1072356?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hjl-tools", "html_url": "https://github.com/hjl-tools", "followers_url": "https://api.github.com/users/hjl-tools/followers", "following_url": "https://api.github.com/users/hjl-tools/following{/other_user}", "gists_url": "https://api.github.com/users/hjl-tools/gists{/gist_id}", "starred_url": "https://api.github.com/users/hjl-tools/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hjl-tools/subscriptions", "organizations_url": "https://api.github.com/users/hjl-tools/orgs", "repos_url": "https://api.github.com/users/hjl-tools/repos", "events_url": "https://api.github.com/users/hjl-tools/events{/privacy}", "received_events_url": "https://api.github.com/users/hjl-tools/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "17d23165ffa88ad006418be8e1dcf5f649c6ff91", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/17d23165ffa88ad006418be8e1dcf5f649c6ff91", "html_url": "https://github.com/Rust-GCC/gccrs/commit/17d23165ffa88ad006418be8e1dcf5f649c6ff91"}], "stats": {"total": 1236, "additions": 620, "deletions": 616}, "files": [{"sha": "b6b752159335ac63487c86c0ac2213b864e6c943", "filename": "gcc/ChangeLog", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b282a8d3ecd34ff57710098f40159029cbd5ec3e/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b282a8d3ecd34ff57710098f40159029cbd5ec3e/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=b282a8d3ecd34ff57710098f40159029cbd5ec3e", "patch": "@@ -1,3 +1,13 @@\n+2008-05-10  H.J. Lu  <hongjiu.lu@intel.com>\n+\n+\t* config/i386/i386.c (bdesc_ptest): Removed.\n+\t(ix86_builtin_type): Add INT_FTYPE_V2DI_V2DI_PTEST.\n+\t(bdesc_args): Add __builtin_ia32_ptestz128,\n+\t__builtin_ia32_ptestc128 and __builtin_ia32_ptestnzc128.\n+\t(ix86_init_mmx_sse_builtins): Updated.\n+\t(ix86_expand_args_builtin): Handle INT_FTYPE_V2DI_V2DI_PTEST.\n+\t(ix86_expand_builtin): Updated.\n+\n 2008-05-10  Richard Sandiford  <rdsandiford@googlemail.com>\n \n \t* tree-cfg.c (valid_fixed_convert_types_p): New function."}, {"sha": "0ebfb1b7617d37856ea22e80c5b47ed639b04520", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 610, "deletions": 616, "changes": 1226, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b282a8d3ecd34ff57710098f40159029cbd5ec3e/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b282a8d3ecd34ff57710098f40159029cbd5ec3e/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=b282a8d3ecd34ff57710098f40159029cbd5ec3e", "patch": "@@ -17989,14 +17989,6 @@ static const struct builtin_description bdesc_comi[] =\n   { OPTION_MASK_ISA_SSE2, CODE_FOR_sse2_ucomi, \"__builtin_ia32_ucomisdneq\", IX86_BUILTIN_UCOMINEQSD, LTGT, 0 },\n };\n \n-static const struct builtin_description bdesc_ptest[] =\n-{\n-  /* SSE4.1 */\n-  { OPTION_MASK_ISA_ROUND, CODE_FOR_sse4_1_ptest, \"__builtin_ia32_ptestz128\", IX86_BUILTIN_PTESTZ, EQ, 0 },\n-  { OPTION_MASK_ISA_ROUND, CODE_FOR_sse4_1_ptest, \"__builtin_ia32_ptestc128\", IX86_BUILTIN_PTESTC, LTU, 0 },\n-  { OPTION_MASK_ISA_ROUND, CODE_FOR_sse4_1_ptest, \"__builtin_ia32_ptestnzc128\", IX86_BUILTIN_PTESTNZC, GTU, 0 },\n-};\n-\n static const struct builtin_description bdesc_pcmpestr[] =\n {\n   /* SSE4.2 */\n@@ -18048,6 +18040,7 @@ enum ix86_builtin_type\n   FLOAT128_FTYPE_FLOAT128,\n   FLOAT_FTYPE_FLOAT,\n   FLOAT128_FTYPE_FLOAT128_FLOAT128,\n+  INT_FTYPE_V2DI_V2DI_PTEST,\n   INT64_FTYPE_V4SF,\n   INT64_FTYPE_V2DF,\n   INT_FTYPE_V16QI,\n@@ -18655,6 +18648,10 @@ static const struct builtin_description bdesc_args[] =\n   { OPTION_MASK_ISA_ROUND, CODE_FOR_sse4_1_roundsd, \"__builtin_ia32_roundsd\", IX86_BUILTIN_ROUNDSD, UNKNOWN, (int) V2DF_FTYPE_V2DF_V2DF_INT },\n   { OPTION_MASK_ISA_ROUND, CODE_FOR_sse4_1_roundss, \"__builtin_ia32_roundss\", IX86_BUILTIN_ROUNDSS, UNKNOWN, (int) V4SF_FTYPE_V4SF_V4SF_INT },\n \n+  { OPTION_MASK_ISA_ROUND, CODE_FOR_sse4_1_ptest, \"__builtin_ia32_ptestz128\", IX86_BUILTIN_PTESTZ, EQ, (int) INT_FTYPE_V2DI_V2DI_PTEST },\n+  { OPTION_MASK_ISA_ROUND, CODE_FOR_sse4_1_ptest, \"__builtin_ia32_ptestc128\", IX86_BUILTIN_PTESTC, LTU, (int) INT_FTYPE_V2DI_V2DI_PTEST },\n+  { OPTION_MASK_ISA_ROUND, CODE_FOR_sse4_1_ptest, \"__builtin_ia32_ptestnzc128\", IX86_BUILTIN_PTESTNZC, GTU, (int) INT_FTYPE_V2DI_V2DI_PTEST },\n+\n   /* SSE4.2 */\n   { OPTION_MASK_ISA_SSE4_2, CODE_FOR_sse4_2_gtv2di3, \"__builtin_ia32_pcmpgtq\", IX86_BUILTIN_PCMPGTQ, UNKNOWN, (int) V2DI_FTYPE_V2DI_V2DI },\n   { OPTION_MASK_ISA_SSE4_2, CODE_FOR_sse4_2_crc32qi, \"__builtin_ia32_crc32qi\", IX86_BUILTIN_CRC32QI, UNKNOWN, (int) UINT_FTYPE_UINT_UCHAR },\n@@ -19597,6 +19594,9 @@ ix86_init_mmx_sse_builtins (void)\n \tcase FLOAT_FTYPE_FLOAT:\n \t  type = float_ftype_float;\n \t  break;\n+\tcase INT_FTYPE_V2DI_V2DI_PTEST:\n+\t  type = int_ftype_v2di_v2di;\n+\t  break;\n \tcase INT64_FTYPE_V4SF:\n \t  type = int64_ftype_v4sf;\n \t  break;\n@@ -19935,10 +19935,6 @@ ix86_init_mmx_sse_builtins (void)\n     else\n       def_builtin_const (d->mask, d->name, int_ftype_v4sf_v4sf, d->code);\n \n-  /* ptest insns.  */\n-  for (i = 0, d = bdesc_ptest; i < ARRAY_SIZE (bdesc_ptest); i++, d++)\n-    def_builtin_const (d->mask, d->name, int_ftype_v2di_v2di, d->code);\n-\n   /* SSE */\n   def_builtin (OPTION_MASK_ISA_SSE, \"__builtin_ia32_ldmxcsr\", void_ftype_unsigned, IX86_BUILTIN_LDMXCSR);\n   def_builtin (OPTION_MASK_ISA_SSE, \"__builtin_ia32_stmxcsr\", unsigned_ftype_void, IX86_BUILTIN_STMXCSR);\n@@ -20451,462 +20447,64 @@ ix86_expand_sse_compare (const struct builtin_description *d,\n   return target;\n }\n \n-/* Subroutine of ix86_expand_builtin to take care of insns with\n-   variable number of operands.  */\n+/* Subroutine of ix86_expand_builtin to take care of comi insns.  */\n \n static rtx\n-ix86_expand_args_builtin (const struct builtin_description *d,\n-\t\t\t  tree exp, rtx target)\n+ix86_expand_sse_comi (const struct builtin_description *d, tree exp,\n+\t\t      rtx target)\n {\n-  rtx pat, real_target;\n-  unsigned int i, nargs;\n-  unsigned int nargs_constant = 0;\n-  int num_memory = 0;\n-  struct\n-    {\n-      rtx op;\n-      enum machine_mode mode;\n-    } args[4];\n-  bool last_arg_count = false;\n-  enum insn_code icode = d->icode;\n-  const struct insn_data *insn_p = &insn_data[icode];\n-  enum machine_mode tmode = insn_p->operand[0].mode;\n-  enum machine_mode rmode = VOIDmode;\n-  bool swap = false;\n+  rtx pat;\n+  tree arg0 = CALL_EXPR_ARG (exp, 0);\n+  tree arg1 = CALL_EXPR_ARG (exp, 1);\n+  rtx op0 = expand_normal (arg0);\n+  rtx op1 = expand_normal (arg1);\n+  enum machine_mode mode0 = insn_data[d->icode].operand[0].mode;\n+  enum machine_mode mode1 = insn_data[d->icode].operand[1].mode;\n   enum rtx_code comparison = d->comparison;\n \n-  switch ((enum ix86_builtin_type) d->flag)\n+  if (VECTOR_MODE_P (mode0))\n+    op0 = safe_vector_operand (op0, mode0);\n+  if (VECTOR_MODE_P (mode1))\n+    op1 = safe_vector_operand (op1, mode1);\n+\n+  /* Swap operands if we have a comparison that isn't available in\n+     hardware.  */\n+  if (d->flag & BUILTIN_DESC_SWAP_OPERANDS)\n     {\n-    case FLOAT128_FTYPE_FLOAT128:\n-    case FLOAT_FTYPE_FLOAT:\n-    case INT64_FTYPE_V4SF:\n-    case INT64_FTYPE_V2DF:\n-    case INT_FTYPE_V16QI:\n-    case INT_FTYPE_V8QI:\n-    case INT_FTYPE_V4SF:\n-    case INT_FTYPE_V2DF:\n-    case V16QI_FTYPE_V16QI:\n-    case V8HI_FTYPE_V8HI:\n-    case V8HI_FTYPE_V16QI:\n-    case V8QI_FTYPE_V8QI:\n-    case V4SI_FTYPE_V4SI:\n-    case V4SI_FTYPE_V16QI:\n-    case V4SI_FTYPE_V4SF:\n-    case V4SI_FTYPE_V8HI:\n-    case V4SI_FTYPE_V2DF:\n-    case V4HI_FTYPE_V4HI:\n-    case V4SF_FTYPE_V4SF:\n-    case V4SF_FTYPE_V4SI:\n-    case V4SF_FTYPE_V2DF:\n-    case V2DI_FTYPE_V2DI:\n-    case V2DI_FTYPE_V16QI:\n-    case V2DI_FTYPE_V8HI:\n-    case V2DI_FTYPE_V4SI:\n-    case V2DF_FTYPE_V2DF:\n-    case V2DF_FTYPE_V4SI:\n-    case V2DF_FTYPE_V4SF:\n-    case V2DF_FTYPE_V2SI:\n-    case V2SI_FTYPE_V2SI:\n-    case V2SI_FTYPE_V4SF:\n-    case V2SI_FTYPE_V2SF:\n-    case V2SI_FTYPE_V2DF:\n-    case V2SF_FTYPE_V2SF:\n-    case V2SF_FTYPE_V2SI:\n-      nargs = 1;\n-      break;\n-    case V4SF_FTYPE_V4SF_VEC_MERGE:\n-    case V2DF_FTYPE_V2DF_VEC_MERGE:\n-      return ix86_expand_unop_vec_merge_builtin (icode, exp, target);\n-    case FLOAT128_FTYPE_FLOAT128_FLOAT128:\n-    case V16QI_FTYPE_V16QI_V16QI:\n-    case V16QI_FTYPE_V8HI_V8HI:\n-    case V8QI_FTYPE_V8QI_V8QI:\n-    case V8QI_FTYPE_V4HI_V4HI:\n-    case V8HI_FTYPE_V8HI_V8HI:\n-    case V8HI_FTYPE_V16QI_V16QI:\n-    case V8HI_FTYPE_V4SI_V4SI:\n-    case V4SI_FTYPE_V4SI_V4SI:\n-    case V4SI_FTYPE_V8HI_V8HI:\n-    case V4SI_FTYPE_V4SF_V4SF:\n-    case V4SI_FTYPE_V2DF_V2DF:\n-    case V4HI_FTYPE_V4HI_V4HI:\n-    case V4HI_FTYPE_V8QI_V8QI:\n-    case V4HI_FTYPE_V2SI_V2SI:\n-    case V4SF_FTYPE_V4SF_V4SF:\n-    case V4SF_FTYPE_V4SF_V2SI:\n-    case V4SF_FTYPE_V4SF_V2DF:\n-    case V4SF_FTYPE_V4SF_DI:\n-    case V4SF_FTYPE_V4SF_SI:\n-    case V2DI_FTYPE_V2DI_V2DI:\n-    case V2DI_FTYPE_V16QI_V16QI:\n-    case V2DI_FTYPE_V4SI_V4SI:\n-    case V2DI_FTYPE_V2DI_V16QI:\n-    case V2DI_FTYPE_V2DF_V2DF:\n-    case V2SI_FTYPE_V2SI_V2SI:\n-    case V2SI_FTYPE_V4HI_V4HI:\n-    case V2SI_FTYPE_V2SF_V2SF:\n-    case V2DF_FTYPE_V2DF_V2DF:\n-    case V2DF_FTYPE_V2DF_V4SF:\n-    case V2DF_FTYPE_V2DF_DI:\n-    case V2DF_FTYPE_V2DF_SI:\n-    case V2SF_FTYPE_V2SF_V2SF:\n-    case V1DI_FTYPE_V1DI_V1DI:\n-    case V1DI_FTYPE_V8QI_V8QI:\n-    case V1DI_FTYPE_V2SI_V2SI:\n-      if (comparison == UNKNOWN)\n-\treturn ix86_expand_binop_builtin (icode, exp, target);\n-      nargs = 2;\n-      break;\n-    case V4SF_FTYPE_V4SF_V4SF_SWAP:\n-    case V2DF_FTYPE_V2DF_V2DF_SWAP:\n-      gcc_assert (comparison != UNKNOWN);\n-      nargs = 2;\n-      swap = true;\n-      break;\n-    case V8HI_FTYPE_V8HI_V8HI_COUNT:\n-    case V8HI_FTYPE_V8HI_SI_COUNT:\n-    case V4SI_FTYPE_V4SI_V4SI_COUNT:\n-    case V4SI_FTYPE_V4SI_SI_COUNT:\n-    case V4HI_FTYPE_V4HI_V4HI_COUNT:\n-    case V4HI_FTYPE_V4HI_SI_COUNT:\n-    case V2DI_FTYPE_V2DI_V2DI_COUNT:\n-    case V2DI_FTYPE_V2DI_SI_COUNT:\n-    case V2SI_FTYPE_V2SI_V2SI_COUNT:\n-    case V2SI_FTYPE_V2SI_SI_COUNT:\n-    case V1DI_FTYPE_V1DI_V1DI_COUNT:\n-    case V1DI_FTYPE_V1DI_SI_COUNT:\n-      nargs = 2;\n-      last_arg_count = true;\n-      break;\n-    case UINT64_FTYPE_UINT64_UINT64:\n-    case UINT_FTYPE_UINT_UINT:\n-    case UINT_FTYPE_UINT_USHORT:\n-    case UINT_FTYPE_UINT_UCHAR:\n-      nargs = 2;\n-      break;\n-    case V2DI2TI_FTYPE_V2DI_INT:\n-      nargs = 2;\n-      rmode = V2DImode;\n-      nargs_constant = 1;\n-      break;\n-    case V8HI_FTYPE_V8HI_INT:\n-    case V4SI_FTYPE_V4SI_INT:\n-    case V4HI_FTYPE_V4HI_INT:\n-    case V4SF_FTYPE_V4SF_INT:\n-    case V2DI_FTYPE_V2DI_INT:\n-    case V2DF_FTYPE_V2DF_INT:\n-      nargs = 2;\n-      nargs_constant = 1;\n-      break;\n-    case V16QI_FTYPE_V16QI_V16QI_V16QI:\n-    case V4SF_FTYPE_V4SF_V4SF_V4SF:\n-    case V2DF_FTYPE_V2DF_V2DF_V2DF:\n-      nargs = 3;\n-      break;\n-    case V16QI_FTYPE_V16QI_V16QI_INT:\n-    case V8HI_FTYPE_V8HI_V8HI_INT:\n-    case V4SI_FTYPE_V4SI_V4SI_INT:\n-    case V4SF_FTYPE_V4SF_V4SF_INT:\n-    case V2DI_FTYPE_V2DI_V2DI_INT:\n-    case V2DF_FTYPE_V2DF_V2DF_INT:\n-      nargs = 3;\n-      nargs_constant = 1;\n-      break;\n-    case V2DI2TI_FTYPE_V2DI_V2DI_INT:\n-      nargs = 3;\n-      rmode = V2DImode;\n-      nargs_constant = 1;\n-      break;\n-    case V1DI2DI_FTYPE_V1DI_V1DI_INT:\n-      nargs = 3;\n-      rmode = DImode;\n-      nargs_constant = 1;\n-      break;\n-    case V2DI_FTYPE_V2DI_UINT_UINT:\n-      nargs = 3;\n-      nargs_constant = 2;\n-      break;\n-    case V2DI_FTYPE_V2DI_V2DI_UINT_UINT:\n-      nargs = 4;\n-      nargs_constant = 2;\n-      break;\n-    default:\n-      gcc_unreachable ();\n+      rtx tmp = op1;\n+      op1 = op0;\n+      op0 = tmp;\n     }\n \n-  gcc_assert (nargs <= ARRAY_SIZE (args));\n+  target = gen_reg_rtx (SImode);\n+  emit_move_insn (target, const0_rtx);\n+  target = gen_rtx_SUBREG (QImode, target, 0);\n \n-  if (comparison != UNKNOWN)\n-    {\n-      gcc_assert (nargs == 2);\n-      return ix86_expand_sse_compare (d, exp, target, swap);\n-    }\n+  if ((optimize && !register_operand (op0, mode0))\n+      || !(*insn_data[d->icode].operand[0].predicate) (op0, mode0))\n+    op0 = copy_to_mode_reg (mode0, op0);\n+  if ((optimize && !register_operand (op1, mode1))\n+      || !(*insn_data[d->icode].operand[1].predicate) (op1, mode1))\n+    op1 = copy_to_mode_reg (mode1, op1);\n \n-  if (rmode == VOIDmode || rmode == tmode)\n-    {\n-      if (optimize\n-\t  || target == 0\n-\t  || GET_MODE (target) != tmode\n-\t  || ! (*insn_p->operand[0].predicate) (target, tmode))\n-\ttarget = gen_reg_rtx (tmode);\n-      real_target = target;\n-    }\n-  else\n-    {\n-      target = gen_reg_rtx (rmode);\n-      real_target = simplify_gen_subreg (tmode, target, rmode, 0);\n-    }\n+  pat = GEN_FCN (d->icode) (op0, op1);\n+  if (! pat)\n+    return 0;\n+  emit_insn (pat);\n+  emit_insn (gen_rtx_SET (VOIDmode,\n+\t\t\t  gen_rtx_STRICT_LOW_PART (VOIDmode, target),\n+\t\t\t  gen_rtx_fmt_ee (comparison, QImode,\n+\t\t\t\t\t  SET_DEST (pat),\n+\t\t\t\t\t  const0_rtx)));\n \n-  for (i = 0; i < nargs; i++)\n-    {\n-      tree arg = CALL_EXPR_ARG (exp, i);\n-      rtx op = expand_normal (arg);\n-      enum machine_mode mode = insn_p->operand[i + 1].mode;\n-      bool match = (*insn_p->operand[i + 1].predicate) (op, mode);\n+  return SUBREG_REG (target);\n+}\n \n-      if (last_arg_count && (i + 1) == nargs)\n-\t{\n-\t  /* SIMD shift insns take either an 8-bit immediate or\n-\t     register as count.  But builtin functions take int as\n-\t     count.  If count doesn't match, we put it in register.  */\n-\t  if (!match)\n-\t    {\n-\t      op = simplify_gen_subreg (SImode, op, GET_MODE (op), 0);\n-\t      if (!(*insn_p->operand[i + 1].predicate) (op, mode))\n-\t\top = copy_to_reg (op);\n-\t    }\n-\t}\n-      else if ((nargs - i) <= nargs_constant)\n-\t{\n-\t  if (!match)\n-\t    switch (icode)\n-\t      {\n-\t      case CODE_FOR_sse4_1_roundpd:\n-\t      case CODE_FOR_sse4_1_roundps:\n-\t      case CODE_FOR_sse4_1_roundsd:\n-\t      case CODE_FOR_sse4_1_roundss:\n-\t      case CODE_FOR_sse4_1_blendps:\n-\t\terror (\"the last argument must be a 4-bit immediate\");\n-\t\treturn const0_rtx;\n-\n-\t      case CODE_FOR_sse4_1_blendpd:\n-\t\terror (\"the last argument must be a 2-bit immediate\");\n-\t\treturn const0_rtx;\n-\n-\t     default:\n-\t\tswitch (nargs_constant)\n-\t\t  {\n-\t\t  case 2:\n-\t\t    if ((nargs - i) == nargs_constant)\n-\t\t      {\n-\t\t\terror (\"the next to last argument must be an 8-bit immediate\");\n-\t\t\tbreak;\n-\t\t      }\n-\t\t  case 1:\n-\t\t    error (\"the last argument must be an 8-bit immediate\");\n-\t\t    break;\n-\t\t  default:\n-\t\t    gcc_unreachable ();\n-\t\t  }\n-\t\treturn const0_rtx;\n-\t      }\n-\t}\n-      else\n-\t{\n-\t  if (VECTOR_MODE_P (mode))\n-\t    op = safe_vector_operand (op, mode);\n-\n-\t  /* If we aren't optimizing, only allow one memory operand to\n-\t     be generated.  */\n-\t  if (memory_operand (op, mode))\n-\t    num_memory++;\n-\n-\t  if (GET_MODE (op) == mode || GET_MODE (op) == VOIDmode)\n-\t    {\n-\t      if (optimize || !match || num_memory > 1)\n-\t\top = copy_to_mode_reg (mode, op);\n-\t    }\n-\t  else\n-\t    {\n-\t      op = copy_to_reg (op);\n-\t      op = simplify_gen_subreg (mode, op, GET_MODE (op), 0);\n-\t    }\n-\t}\n-\n-      args[i].op = op;\n-      args[i].mode = mode;\n-    }\n-\n-  switch (nargs)\n-    {\n-    case 1:\n-      pat = GEN_FCN (icode) (real_target, args[0].op);\n-      break;\n-    case 2:\n-      pat = GEN_FCN (icode) (real_target, args[0].op, args[1].op);\n-      break;\n-    case 3:\n-      pat = GEN_FCN (icode) (real_target, args[0].op, args[1].op,\n-\t\t\t     args[2].op);\n-      break;\n-    case 4:\n-      pat = GEN_FCN (icode) (real_target, args[0].op, args[1].op,\n-\t\t\t     args[2].op, args[3].op);\n-      break;\n-    default:\n-      gcc_unreachable ();\n-    }\n-\n-  if (! pat)\n-    return 0;\n-\n-  emit_insn (pat);\n-  return target;\n-}\n-\n-/* Subroutine of ix86_expand_builtin to take care of special insns\n-   with variable number of operands.  */\n-\n-static rtx\n-ix86_expand_special_args_builtin (const struct builtin_description *d,\n-\t\t\t\t    tree exp, rtx target)\n-{\n-  tree arg;\n-  rtx pat, op;\n-  unsigned int i, nargs, arg_adjust, memory;\n-  struct\n-    {\n-      rtx op;\n-      enum machine_mode mode;\n-    } args[2];\n-  enum insn_code icode = d->icode;\n-  bool last_arg_constant = false;\n-  const struct insn_data *insn_p = &insn_data[icode];\n-  enum machine_mode tmode = insn_p->operand[0].mode;\n-  enum { load, store } class;\n-\n-  switch ((enum ix86_special_builtin_type) d->flag)\n-    {\n-    case VOID_FTYPE_VOID:\n-      emit_insn (GEN_FCN (icode) (target));\n-      return 0;\n-    case V2DI_FTYPE_PV2DI:\n-    case V16QI_FTYPE_PCCHAR:\n-    case V4SF_FTYPE_PCFLOAT:\n-    case V2DF_FTYPE_PCDOUBLE:\n-      nargs = 1;\n-      class = load;\n-      memory = 0;\n-      break;\n-    case VOID_FTYPE_PV2SF_V4SF:\n-    case VOID_FTYPE_PV2DI_V2DI:\n-    case VOID_FTYPE_PCHAR_V16QI:\n-    case VOID_FTYPE_PFLOAT_V4SF:\n-    case VOID_FTYPE_PDOUBLE_V2DF:\n-    case VOID_FTYPE_PDI_DI:\n-    case VOID_FTYPE_PINT_INT:\n-      nargs = 1;\n-      class = store;\n-      /* Reserve memory operand for target.  */\n-      memory = ARRAY_SIZE (args);\n-      break;\n-    case V4SF_FTYPE_V4SF_PCV2SF:\n-    case V2DF_FTYPE_V2DF_PCDOUBLE:\n-      nargs = 2;\n-      class = load;\n-      memory = 1;\n-      break;\n-    default:\n-      gcc_unreachable ();\n-    }\n-\n-  gcc_assert (nargs <= ARRAY_SIZE (args));\n-\n-  if (class == store)\n-    {\n-      arg = CALL_EXPR_ARG (exp, 0);\n-      op = expand_normal (arg);\n-      gcc_assert (target == 0);\n-      target = gen_rtx_MEM (tmode, copy_to_mode_reg (Pmode, op));\n-      arg_adjust = 1;\n-    }\n-  else\n-    {\n-      arg_adjust = 0;\n-      if (optimize\n-\t  || target == 0\n-\t  || GET_MODE (target) != tmode\n-\t  || ! (*insn_p->operand[0].predicate) (target, tmode))\n-\ttarget = gen_reg_rtx (tmode);\n-    }\n-\n-  for (i = 0; i < nargs; i++)\n-    {\n-      enum machine_mode mode = insn_p->operand[i + 1].mode;\n-      bool match;\n-\n-      arg = CALL_EXPR_ARG (exp, i + arg_adjust);\n-      op = expand_normal (arg);\n-      match = (*insn_p->operand[i + 1].predicate) (op, mode);\n-\n-      if (last_arg_constant && (i + 1) == nargs)\n-\t{\n-\t  if (!match)\n-\t    switch (icode)\n-\t      {\n-\t     default:\n-\t\terror (\"the last argument must be an 8-bit immediate\");\n-\t\treturn const0_rtx;\n-\t      }\n-\t}\n-      else\n-\t{\n-\t  if (i == memory)\n-\t    {\n-\t      /* This must be the memory operand.  */\n-\t      op = gen_rtx_MEM (mode, copy_to_mode_reg (Pmode, op));\n-\t      gcc_assert (GET_MODE (op) == mode\n-\t\t\t  || GET_MODE (op) == VOIDmode);\n-\t    }\n-\t  else\n-\t    {\n-\t      /* This must be register.  */\n-\t      if (VECTOR_MODE_P (mode))\n-\t\top = safe_vector_operand (op, mode);\n-\n-\t      gcc_assert (GET_MODE (op) == mode\n-\t\t\t  || GET_MODE (op) == VOIDmode);\n-\t      op = copy_to_mode_reg (mode, op);\n-\t    }\n-\t}\n-\n-      args[i].op = op;\n-      args[i].mode = mode;\n-    }\n-\n-  switch (nargs)\n-    {\n-    case 1:\n-      pat = GEN_FCN (icode) (target, args[0].op);\n-      break;\n-    case 2:\n-      pat = GEN_FCN (icode) (target, args[0].op, args[1].op);\n-      break;\n-    default:\n-      gcc_unreachable ();\n-    }\n-\n-  if (! pat)\n-    return 0;\n-  emit_insn (pat);\n-  return class == store ? 0 : target;\n-}\n-\n-/* Subroutine of ix86_expand_builtin to take care of comi insns.  */\n+/* Subroutine of ix86_expand_builtin to take care of ptest insns.  */\n \n static rtx\n-ix86_expand_sse_comi (const struct builtin_description *d, tree exp,\n-\t\t      rtx target)\n+ix86_expand_sse_ptest (const struct builtin_description *d, tree exp,\n+\t\t       rtx target)\n {\n   rtx pat;\n   tree arg0 = CALL_EXPR_ARG (exp, 0);\n@@ -20922,15 +20520,6 @@ ix86_expand_sse_comi (const struct builtin_description *d, tree exp,\n   if (VECTOR_MODE_P (mode1))\n     op1 = safe_vector_operand (op1, mode1);\n \n-  /* Swap operands if we have a comparison that isn't available in\n-     hardware.  */\n-  if (d->flag & BUILTIN_DESC_SWAP_OPERANDS)\n-    {\n-      rtx tmp = op1;\n-      op1 = op0;\n-      op0 = tmp;\n-    }\n-\n   target = gen_reg_rtx (SImode);\n   emit_move_insn (target, const0_rtx);\n   target = gen_rtx_SUBREG (QImode, target, 0);\n@@ -20955,63 +20544,19 @@ ix86_expand_sse_comi (const struct builtin_description *d, tree exp,\n   return SUBREG_REG (target);\n }\n \n-/* Subroutine of ix86_expand_builtin to take care of ptest insns.  */\n+/* Subroutine of ix86_expand_builtin to take care of pcmpestr[im] insns.  */\n \n static rtx\n-ix86_expand_sse_ptest (const struct builtin_description *d, tree exp,\n-\t\t       rtx target)\n+ix86_expand_sse_pcmpestr (const struct builtin_description *d,\n+\t\t\t  tree exp, rtx target)\n {\n   rtx pat;\n   tree arg0 = CALL_EXPR_ARG (exp, 0);\n   tree arg1 = CALL_EXPR_ARG (exp, 1);\n-  rtx op0 = expand_normal (arg0);\n-  rtx op1 = expand_normal (arg1);\n-  enum machine_mode mode0 = insn_data[d->icode].operand[0].mode;\n-  enum machine_mode mode1 = insn_data[d->icode].operand[1].mode;\n-  enum rtx_code comparison = d->comparison;\n-\n-  if (VECTOR_MODE_P (mode0))\n-    op0 = safe_vector_operand (op0, mode0);\n-  if (VECTOR_MODE_P (mode1))\n-    op1 = safe_vector_operand (op1, mode1);\n-\n-  target = gen_reg_rtx (SImode);\n-  emit_move_insn (target, const0_rtx);\n-  target = gen_rtx_SUBREG (QImode, target, 0);\n-\n-  if ((optimize && !register_operand (op0, mode0))\n-      || !(*insn_data[d->icode].operand[0].predicate) (op0, mode0))\n-    op0 = copy_to_mode_reg (mode0, op0);\n-  if ((optimize && !register_operand (op1, mode1))\n-      || !(*insn_data[d->icode].operand[1].predicate) (op1, mode1))\n-    op1 = copy_to_mode_reg (mode1, op1);\n-\n-  pat = GEN_FCN (d->icode) (op0, op1);\n-  if (! pat)\n-    return 0;\n-  emit_insn (pat);\n-  emit_insn (gen_rtx_SET (VOIDmode,\n-\t\t\t  gen_rtx_STRICT_LOW_PART (VOIDmode, target),\n-\t\t\t  gen_rtx_fmt_ee (comparison, QImode,\n-\t\t\t\t\t  SET_DEST (pat),\n-\t\t\t\t\t  const0_rtx)));\n-\n-  return SUBREG_REG (target);\n-}\n-\n-/* Subroutine of ix86_expand_builtin to take care of pcmpestr[im] insns.  */\n-\n-static rtx\n-ix86_expand_sse_pcmpestr (const struct builtin_description *d,\n-\t\t\t  tree exp, rtx target)\n-{\n-  rtx pat;\n-  tree arg0 = CALL_EXPR_ARG (exp, 0);\n-  tree arg1 = CALL_EXPR_ARG (exp, 1);\n-  tree arg2 = CALL_EXPR_ARG (exp, 2);\n-  tree arg3 = CALL_EXPR_ARG (exp, 3);\n-  tree arg4 = CALL_EXPR_ARG (exp, 4);\n-  rtx scratch0, scratch1;\n+  tree arg2 = CALL_EXPR_ARG (exp, 2);\n+  tree arg3 = CALL_EXPR_ARG (exp, 3);\n+  tree arg4 = CALL_EXPR_ARG (exp, 4);\n+  rtx scratch0, scratch1;\n   rtx op0 = expand_normal (arg0);\n   rtx op1 = expand_normal (arg1);\n   rtx op2 = expand_normal (arg2);\n@@ -21066,136 +20611,589 @@ ix86_expand_sse_pcmpestr (const struct builtin_description *d,\n \t  || ! (*insn_data[d->icode].operand[1].predicate) (target, tmode1))\n \ttarget = gen_reg_rtx (tmode1);\n \n-      scratch0 = gen_reg_rtx (tmode0);\n+      scratch0 = gen_reg_rtx (tmode0);\n+\n+      pat = GEN_FCN (d->icode) (scratch0, target, op0, op1, op2, op3, op4);\n+    }\n+  else\n+    {\n+      gcc_assert (d->flag);\n+\n+      scratch0 = gen_reg_rtx (tmode0);\n+      scratch1 = gen_reg_rtx (tmode1);\n+\n+      pat = GEN_FCN (d->icode) (scratch0, scratch1, op0, op1, op2, op3, op4);\n+    }\n+\n+  if (! pat)\n+    return 0;\n+\n+  emit_insn (pat);\n+\n+  if (d->flag)\n+    {\n+      target = gen_reg_rtx (SImode);\n+      emit_move_insn (target, const0_rtx);\n+      target = gen_rtx_SUBREG (QImode, target, 0);\n+\n+      emit_insn\n+\t(gen_rtx_SET (VOIDmode, gen_rtx_STRICT_LOW_PART (VOIDmode, target),\n+\t\t      gen_rtx_fmt_ee (EQ, QImode,\n+\t\t\t\t      gen_rtx_REG ((enum machine_mode) d->flag,\n+\t\t\t\t\t\t   FLAGS_REG),\n+\t\t\t\t      const0_rtx)));\n+      return SUBREG_REG (target);\n+    }\n+  else\n+    return target;\n+}\n+\n+\n+/* Subroutine of ix86_expand_builtin to take care of pcmpistr[im] insns.  */\n+\n+static rtx\n+ix86_expand_sse_pcmpistr (const struct builtin_description *d,\n+\t\t\t  tree exp, rtx target)\n+{\n+  rtx pat;\n+  tree arg0 = CALL_EXPR_ARG (exp, 0);\n+  tree arg1 = CALL_EXPR_ARG (exp, 1);\n+  tree arg2 = CALL_EXPR_ARG (exp, 2);\n+  rtx scratch0, scratch1;\n+  rtx op0 = expand_normal (arg0);\n+  rtx op1 = expand_normal (arg1);\n+  rtx op2 = expand_normal (arg2);\n+  enum machine_mode tmode0, tmode1, modev2, modev3, modeimm;\n+\n+  tmode0 = insn_data[d->icode].operand[0].mode;\n+  tmode1 = insn_data[d->icode].operand[1].mode;\n+  modev2 = insn_data[d->icode].operand[2].mode;\n+  modev3 = insn_data[d->icode].operand[3].mode;\n+  modeimm = insn_data[d->icode].operand[4].mode;\n+\n+  if (VECTOR_MODE_P (modev2))\n+    op0 = safe_vector_operand (op0, modev2);\n+  if (VECTOR_MODE_P (modev3))\n+    op1 = safe_vector_operand (op1, modev3);\n+\n+  if (! (*insn_data[d->icode].operand[2].predicate) (op0, modev2))\n+    op0 = copy_to_mode_reg (modev2, op0);\n+  if ((optimize && !register_operand (op1, modev3))\n+      || !(*insn_data[d->icode].operand[3].predicate) (op1, modev3))\n+    op1 = copy_to_mode_reg (modev3, op1);\n+\n+  if (! (*insn_data[d->icode].operand[4].predicate) (op2, modeimm))\n+    {\n+      error (\"the third argument must be a 8-bit immediate\");\n+      return const0_rtx;\n+    }\n+\n+  if (d->code == IX86_BUILTIN_PCMPISTRI128)\n+    {\n+      if (optimize || !target\n+\t  || GET_MODE (target) != tmode0\n+\t  || ! (*insn_data[d->icode].operand[0].predicate) (target, tmode0))\n+\ttarget = gen_reg_rtx (tmode0);\n+\n+      scratch1 = gen_reg_rtx (tmode1);\n+\n+      pat = GEN_FCN (d->icode) (target, scratch1, op0, op1, op2);\n+    }\n+  else if (d->code == IX86_BUILTIN_PCMPISTRM128)\n+    {\n+      if (optimize || !target\n+\t  || GET_MODE (target) != tmode1\n+\t  || ! (*insn_data[d->icode].operand[1].predicate) (target, tmode1))\n+\ttarget = gen_reg_rtx (tmode1);\n+\n+      scratch0 = gen_reg_rtx (tmode0);\n+\n+      pat = GEN_FCN (d->icode) (scratch0, target, op0, op1, op2);\n+    }\n+  else\n+    {\n+      gcc_assert (d->flag);\n+\n+      scratch0 = gen_reg_rtx (tmode0);\n+      scratch1 = gen_reg_rtx (tmode1);\n+\n+      pat = GEN_FCN (d->icode) (scratch0, scratch1, op0, op1, op2);\n+    }\n+\n+  if (! pat)\n+    return 0;\n+\n+  emit_insn (pat);\n+\n+  if (d->flag)\n+    {\n+      target = gen_reg_rtx (SImode);\n+      emit_move_insn (target, const0_rtx);\n+      target = gen_rtx_SUBREG (QImode, target, 0);\n+\n+      emit_insn\n+\t(gen_rtx_SET (VOIDmode, gen_rtx_STRICT_LOW_PART (VOIDmode, target),\n+\t\t      gen_rtx_fmt_ee (EQ, QImode,\n+\t\t\t\t      gen_rtx_REG ((enum machine_mode) d->flag,\n+\t\t\t\t\t\t   FLAGS_REG),\n+\t\t\t\t      const0_rtx)));\n+      return SUBREG_REG (target);\n+    }\n+  else\n+    return target;\n+}\n+\n+/* Subroutine of ix86_expand_builtin to take care of insns with\n+   variable number of operands.  */\n+\n+static rtx\n+ix86_expand_args_builtin (const struct builtin_description *d,\n+\t\t\t  tree exp, rtx target)\n+{\n+  rtx pat, real_target;\n+  unsigned int i, nargs;\n+  unsigned int nargs_constant = 0;\n+  int num_memory = 0;\n+  struct\n+    {\n+      rtx op;\n+      enum machine_mode mode;\n+    } args[4];\n+  bool last_arg_count = false;\n+  enum insn_code icode = d->icode;\n+  const struct insn_data *insn_p = &insn_data[icode];\n+  enum machine_mode tmode = insn_p->operand[0].mode;\n+  enum machine_mode rmode = VOIDmode;\n+  bool swap = false;\n+  enum rtx_code comparison = d->comparison;\n+\n+  switch ((enum ix86_builtin_type) d->flag)\n+    {\n+    case INT_FTYPE_V2DI_V2DI_PTEST:\n+      return ix86_expand_sse_ptest (d, exp, target);\n+    case FLOAT128_FTYPE_FLOAT128:\n+    case FLOAT_FTYPE_FLOAT:\n+    case INT64_FTYPE_V4SF:\n+    case INT64_FTYPE_V2DF:\n+    case INT_FTYPE_V16QI:\n+    case INT_FTYPE_V8QI:\n+    case INT_FTYPE_V4SF:\n+    case INT_FTYPE_V2DF:\n+    case V16QI_FTYPE_V16QI:\n+    case V8HI_FTYPE_V8HI:\n+    case V8HI_FTYPE_V16QI:\n+    case V8QI_FTYPE_V8QI:\n+    case V4SI_FTYPE_V4SI:\n+    case V4SI_FTYPE_V16QI:\n+    case V4SI_FTYPE_V4SF:\n+    case V4SI_FTYPE_V8HI:\n+    case V4SI_FTYPE_V2DF:\n+    case V4HI_FTYPE_V4HI:\n+    case V4SF_FTYPE_V4SF:\n+    case V4SF_FTYPE_V4SI:\n+    case V4SF_FTYPE_V2DF:\n+    case V2DI_FTYPE_V2DI:\n+    case V2DI_FTYPE_V16QI:\n+    case V2DI_FTYPE_V8HI:\n+    case V2DI_FTYPE_V4SI:\n+    case V2DF_FTYPE_V2DF:\n+    case V2DF_FTYPE_V4SI:\n+    case V2DF_FTYPE_V4SF:\n+    case V2DF_FTYPE_V2SI:\n+    case V2SI_FTYPE_V2SI:\n+    case V2SI_FTYPE_V4SF:\n+    case V2SI_FTYPE_V2SF:\n+    case V2SI_FTYPE_V2DF:\n+    case V2SF_FTYPE_V2SF:\n+    case V2SF_FTYPE_V2SI:\n+      nargs = 1;\n+      break;\n+    case V4SF_FTYPE_V4SF_VEC_MERGE:\n+    case V2DF_FTYPE_V2DF_VEC_MERGE:\n+      return ix86_expand_unop_vec_merge_builtin (icode, exp, target);\n+    case FLOAT128_FTYPE_FLOAT128_FLOAT128:\n+    case V16QI_FTYPE_V16QI_V16QI:\n+    case V16QI_FTYPE_V8HI_V8HI:\n+    case V8QI_FTYPE_V8QI_V8QI:\n+    case V8QI_FTYPE_V4HI_V4HI:\n+    case V8HI_FTYPE_V8HI_V8HI:\n+    case V8HI_FTYPE_V16QI_V16QI:\n+    case V8HI_FTYPE_V4SI_V4SI:\n+    case V4SI_FTYPE_V4SI_V4SI:\n+    case V4SI_FTYPE_V8HI_V8HI:\n+    case V4SI_FTYPE_V4SF_V4SF:\n+    case V4SI_FTYPE_V2DF_V2DF:\n+    case V4HI_FTYPE_V4HI_V4HI:\n+    case V4HI_FTYPE_V8QI_V8QI:\n+    case V4HI_FTYPE_V2SI_V2SI:\n+    case V4SF_FTYPE_V4SF_V4SF:\n+    case V4SF_FTYPE_V4SF_V2SI:\n+    case V4SF_FTYPE_V4SF_V2DF:\n+    case V4SF_FTYPE_V4SF_DI:\n+    case V4SF_FTYPE_V4SF_SI:\n+    case V2DI_FTYPE_V2DI_V2DI:\n+    case V2DI_FTYPE_V16QI_V16QI:\n+    case V2DI_FTYPE_V4SI_V4SI:\n+    case V2DI_FTYPE_V2DI_V16QI:\n+    case V2DI_FTYPE_V2DF_V2DF:\n+    case V2SI_FTYPE_V2SI_V2SI:\n+    case V2SI_FTYPE_V4HI_V4HI:\n+    case V2SI_FTYPE_V2SF_V2SF:\n+    case V2DF_FTYPE_V2DF_V2DF:\n+    case V2DF_FTYPE_V2DF_V4SF:\n+    case V2DF_FTYPE_V2DF_DI:\n+    case V2DF_FTYPE_V2DF_SI:\n+    case V2SF_FTYPE_V2SF_V2SF:\n+    case V1DI_FTYPE_V1DI_V1DI:\n+    case V1DI_FTYPE_V8QI_V8QI:\n+    case V1DI_FTYPE_V2SI_V2SI:\n+      if (comparison == UNKNOWN)\n+\treturn ix86_expand_binop_builtin (icode, exp, target);\n+      nargs = 2;\n+      break;\n+    case V4SF_FTYPE_V4SF_V4SF_SWAP:\n+    case V2DF_FTYPE_V2DF_V2DF_SWAP:\n+      gcc_assert (comparison != UNKNOWN);\n+      nargs = 2;\n+      swap = true;\n+      break;\n+    case V8HI_FTYPE_V8HI_V8HI_COUNT:\n+    case V8HI_FTYPE_V8HI_SI_COUNT:\n+    case V4SI_FTYPE_V4SI_V4SI_COUNT:\n+    case V4SI_FTYPE_V4SI_SI_COUNT:\n+    case V4HI_FTYPE_V4HI_V4HI_COUNT:\n+    case V4HI_FTYPE_V4HI_SI_COUNT:\n+    case V2DI_FTYPE_V2DI_V2DI_COUNT:\n+    case V2DI_FTYPE_V2DI_SI_COUNT:\n+    case V2SI_FTYPE_V2SI_V2SI_COUNT:\n+    case V2SI_FTYPE_V2SI_SI_COUNT:\n+    case V1DI_FTYPE_V1DI_V1DI_COUNT:\n+    case V1DI_FTYPE_V1DI_SI_COUNT:\n+      nargs = 2;\n+      last_arg_count = true;\n+      break;\n+    case UINT64_FTYPE_UINT64_UINT64:\n+    case UINT_FTYPE_UINT_UINT:\n+    case UINT_FTYPE_UINT_USHORT:\n+    case UINT_FTYPE_UINT_UCHAR:\n+      nargs = 2;\n+      break;\n+    case V2DI2TI_FTYPE_V2DI_INT:\n+      nargs = 2;\n+      rmode = V2DImode;\n+      nargs_constant = 1;\n+      break;\n+    case V8HI_FTYPE_V8HI_INT:\n+    case V4SI_FTYPE_V4SI_INT:\n+    case V4HI_FTYPE_V4HI_INT:\n+    case V4SF_FTYPE_V4SF_INT:\n+    case V2DI_FTYPE_V2DI_INT:\n+    case V2DF_FTYPE_V2DF_INT:\n+      nargs = 2;\n+      nargs_constant = 1;\n+      break;\n+    case V16QI_FTYPE_V16QI_V16QI_V16QI:\n+    case V4SF_FTYPE_V4SF_V4SF_V4SF:\n+    case V2DF_FTYPE_V2DF_V2DF_V2DF:\n+      nargs = 3;\n+      break;\n+    case V16QI_FTYPE_V16QI_V16QI_INT:\n+    case V8HI_FTYPE_V8HI_V8HI_INT:\n+    case V4SI_FTYPE_V4SI_V4SI_INT:\n+    case V4SF_FTYPE_V4SF_V4SF_INT:\n+    case V2DI_FTYPE_V2DI_V2DI_INT:\n+    case V2DF_FTYPE_V2DF_V2DF_INT:\n+      nargs = 3;\n+      nargs_constant = 1;\n+      break;\n+    case V2DI2TI_FTYPE_V2DI_V2DI_INT:\n+      nargs = 3;\n+      rmode = V2DImode;\n+      nargs_constant = 1;\n+      break;\n+    case V1DI2DI_FTYPE_V1DI_V1DI_INT:\n+      nargs = 3;\n+      rmode = DImode;\n+      nargs_constant = 1;\n+      break;\n+    case V2DI_FTYPE_V2DI_UINT_UINT:\n+      nargs = 3;\n+      nargs_constant = 2;\n+      break;\n+    case V2DI_FTYPE_V2DI_V2DI_UINT_UINT:\n+      nargs = 4;\n+      nargs_constant = 2;\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  gcc_assert (nargs <= ARRAY_SIZE (args));\n+\n+  if (comparison != UNKNOWN)\n+    {\n+      gcc_assert (nargs == 2);\n+      return ix86_expand_sse_compare (d, exp, target, swap);\n+    }\n+\n+  if (rmode == VOIDmode || rmode == tmode)\n+    {\n+      if (optimize\n+\t  || target == 0\n+\t  || GET_MODE (target) != tmode\n+\t  || ! (*insn_p->operand[0].predicate) (target, tmode))\n+\ttarget = gen_reg_rtx (tmode);\n+      real_target = target;\n+    }\n+  else\n+    {\n+      target = gen_reg_rtx (rmode);\n+      real_target = simplify_gen_subreg (tmode, target, rmode, 0);\n+    }\n+\n+  for (i = 0; i < nargs; i++)\n+    {\n+      tree arg = CALL_EXPR_ARG (exp, i);\n+      rtx op = expand_normal (arg);\n+      enum machine_mode mode = insn_p->operand[i + 1].mode;\n+      bool match = (*insn_p->operand[i + 1].predicate) (op, mode);\n+\n+      if (last_arg_count && (i + 1) == nargs)\n+\t{\n+\t  /* SIMD shift insns take either an 8-bit immediate or\n+\t     register as count.  But builtin functions take int as\n+\t     count.  If count doesn't match, we put it in register.  */\n+\t  if (!match)\n+\t    {\n+\t      op = simplify_gen_subreg (SImode, op, GET_MODE (op), 0);\n+\t      if (!(*insn_p->operand[i + 1].predicate) (op, mode))\n+\t\top = copy_to_reg (op);\n+\t    }\n+\t}\n+      else if ((nargs - i) <= nargs_constant)\n+\t{\n+\t  if (!match)\n+\t    switch (icode)\n+\t      {\n+\t      case CODE_FOR_sse4_1_roundpd:\n+\t      case CODE_FOR_sse4_1_roundps:\n+\t      case CODE_FOR_sse4_1_roundsd:\n+\t      case CODE_FOR_sse4_1_roundss:\n+\t      case CODE_FOR_sse4_1_blendps:\n+\t\terror (\"the last argument must be a 4-bit immediate\");\n+\t\treturn const0_rtx;\n+\n+\t      case CODE_FOR_sse4_1_blendpd:\n+\t\terror (\"the last argument must be a 2-bit immediate\");\n+\t\treturn const0_rtx;\n+\n+\t     default:\n+\t\tswitch (nargs_constant)\n+\t\t  {\n+\t\t  case 2:\n+\t\t    if ((nargs - i) == nargs_constant)\n+\t\t      {\n+\t\t\terror (\"the next to last argument must be an 8-bit immediate\");\n+\t\t\tbreak;\n+\t\t      }\n+\t\t  case 1:\n+\t\t    error (\"the last argument must be an 8-bit immediate\");\n+\t\t    break;\n+\t\t  default:\n+\t\t    gcc_unreachable ();\n+\t\t  }\n+\t\treturn const0_rtx;\n+\t      }\n+\t}\n+      else\n+\t{\n+\t  if (VECTOR_MODE_P (mode))\n+\t    op = safe_vector_operand (op, mode);\n+\n+\t  /* If we aren't optimizing, only allow one memory operand to\n+\t     be generated.  */\n+\t  if (memory_operand (op, mode))\n+\t    num_memory++;\n \n-      pat = GEN_FCN (d->icode) (scratch0, target, op0, op1, op2, op3, op4);\n-    }\n-  else\n-    {\n-      gcc_assert (d->flag);\n+\t  if (GET_MODE (op) == mode || GET_MODE (op) == VOIDmode)\n+\t    {\n+\t      if (optimize || !match || num_memory > 1)\n+\t\top = copy_to_mode_reg (mode, op);\n+\t    }\n+\t  else\n+\t    {\n+\t      op = copy_to_reg (op);\n+\t      op = simplify_gen_subreg (mode, op, GET_MODE (op), 0);\n+\t    }\n+\t}\n \n-      scratch0 = gen_reg_rtx (tmode0);\n-      scratch1 = gen_reg_rtx (tmode1);\n+      args[i].op = op;\n+      args[i].mode = mode;\n+    }\n \n-      pat = GEN_FCN (d->icode) (scratch0, scratch1, op0, op1, op2, op3, op4);\n+  switch (nargs)\n+    {\n+    case 1:\n+      pat = GEN_FCN (icode) (real_target, args[0].op);\n+      break;\n+    case 2:\n+      pat = GEN_FCN (icode) (real_target, args[0].op, args[1].op);\n+      break;\n+    case 3:\n+      pat = GEN_FCN (icode) (real_target, args[0].op, args[1].op,\n+\t\t\t     args[2].op);\n+      break;\n+    case 4:\n+      pat = GEN_FCN (icode) (real_target, args[0].op, args[1].op,\n+\t\t\t     args[2].op, args[3].op);\n+      break;\n+    default:\n+      gcc_unreachable ();\n     }\n \n   if (! pat)\n     return 0;\n \n   emit_insn (pat);\n-\n-  if (d->flag)\n-    {\n-      target = gen_reg_rtx (SImode);\n-      emit_move_insn (target, const0_rtx);\n-      target = gen_rtx_SUBREG (QImode, target, 0);\n-\n-      emit_insn\n-\t(gen_rtx_SET (VOIDmode, gen_rtx_STRICT_LOW_PART (VOIDmode, target),\n-\t\t      gen_rtx_fmt_ee (EQ, QImode,\n-\t\t\t\t      gen_rtx_REG ((enum machine_mode) d->flag,\n-\t\t\t\t\t\t   FLAGS_REG),\n-\t\t\t\t      const0_rtx)));\n-      return SUBREG_REG (target);\n-    }\n-  else\n-    return target;\n+  return target;\n }\n \n-\n-/* Subroutine of ix86_expand_builtin to take care of pcmpistr[im] insns.  */\n+/* Subroutine of ix86_expand_builtin to take care of special insns\n+   with variable number of operands.  */\n \n static rtx\n-ix86_expand_sse_pcmpistr (const struct builtin_description *d,\n-\t\t\t  tree exp, rtx target)\n+ix86_expand_special_args_builtin (const struct builtin_description *d,\n+\t\t\t\t    tree exp, rtx target)\n {\n-  rtx pat;\n-  tree arg0 = CALL_EXPR_ARG (exp, 0);\n-  tree arg1 = CALL_EXPR_ARG (exp, 1);\n-  tree arg2 = CALL_EXPR_ARG (exp, 2);\n-  rtx scratch0, scratch1;\n-  rtx op0 = expand_normal (arg0);\n-  rtx op1 = expand_normal (arg1);\n-  rtx op2 = expand_normal (arg2);\n-  enum machine_mode tmode0, tmode1, modev2, modev3, modeimm;\n-\n-  tmode0 = insn_data[d->icode].operand[0].mode;\n-  tmode1 = insn_data[d->icode].operand[1].mode;\n-  modev2 = insn_data[d->icode].operand[2].mode;\n-  modev3 = insn_data[d->icode].operand[3].mode;\n-  modeimm = insn_data[d->icode].operand[4].mode;\n+  tree arg;\n+  rtx pat, op;\n+  unsigned int i, nargs, arg_adjust, memory;\n+  struct\n+    {\n+      rtx op;\n+      enum machine_mode mode;\n+    } args[2];\n+  enum insn_code icode = d->icode;\n+  bool last_arg_constant = false;\n+  const struct insn_data *insn_p = &insn_data[icode];\n+  enum machine_mode tmode = insn_p->operand[0].mode;\n+  enum { load, store } class;\n \n-  if (VECTOR_MODE_P (modev2))\n-    op0 = safe_vector_operand (op0, modev2);\n-  if (VECTOR_MODE_P (modev3))\n-    op1 = safe_vector_operand (op1, modev3);\n+  switch ((enum ix86_special_builtin_type) d->flag)\n+    {\n+    case VOID_FTYPE_VOID:\n+      emit_insn (GEN_FCN (icode) (target));\n+      return 0;\n+    case V2DI_FTYPE_PV2DI:\n+    case V16QI_FTYPE_PCCHAR:\n+    case V4SF_FTYPE_PCFLOAT:\n+    case V2DF_FTYPE_PCDOUBLE:\n+      nargs = 1;\n+      class = load;\n+      memory = 0;\n+      break;\n+    case VOID_FTYPE_PV2SF_V4SF:\n+    case VOID_FTYPE_PV2DI_V2DI:\n+    case VOID_FTYPE_PCHAR_V16QI:\n+    case VOID_FTYPE_PFLOAT_V4SF:\n+    case VOID_FTYPE_PDOUBLE_V2DF:\n+    case VOID_FTYPE_PDI_DI:\n+    case VOID_FTYPE_PINT_INT:\n+      nargs = 1;\n+      class = store;\n+      /* Reserve memory operand for target.  */\n+      memory = ARRAY_SIZE (args);\n+      break;\n+    case V4SF_FTYPE_V4SF_PCV2SF:\n+    case V2DF_FTYPE_V2DF_PCDOUBLE:\n+      nargs = 2;\n+      class = load;\n+      memory = 1;\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n \n-  if (! (*insn_data[d->icode].operand[2].predicate) (op0, modev2))\n-    op0 = copy_to_mode_reg (modev2, op0);\n-  if ((optimize && !register_operand (op1, modev3))\n-      || !(*insn_data[d->icode].operand[3].predicate) (op1, modev3))\n-    op1 = copy_to_mode_reg (modev3, op1);\n+  gcc_assert (nargs <= ARRAY_SIZE (args));\n \n-  if (! (*insn_data[d->icode].operand[4].predicate) (op2, modeimm))\n+  if (class == store)\n     {\n-      error (\"the third argument must be a 8-bit immediate\");\n-      return const0_rtx;\n+      arg = CALL_EXPR_ARG (exp, 0);\n+      op = expand_normal (arg);\n+      gcc_assert (target == 0);\n+      target = gen_rtx_MEM (tmode, copy_to_mode_reg (Pmode, op));\n+      arg_adjust = 1;\n+    }\n+  else\n+    {\n+      arg_adjust = 0;\n+      if (optimize\n+\t  || target == 0\n+\t  || GET_MODE (target) != tmode\n+\t  || ! (*insn_p->operand[0].predicate) (target, tmode))\n+\ttarget = gen_reg_rtx (tmode);\n     }\n \n-  if (d->code == IX86_BUILTIN_PCMPISTRI128)\n+  for (i = 0; i < nargs; i++)\n     {\n-      if (optimize || !target\n-\t  || GET_MODE (target) != tmode0\n-\t  || ! (*insn_data[d->icode].operand[0].predicate) (target, tmode0))\n-\ttarget = gen_reg_rtx (tmode0);\n+      enum machine_mode mode = insn_p->operand[i + 1].mode;\n+      bool match;\n \n-      scratch1 = gen_reg_rtx (tmode1);\n+      arg = CALL_EXPR_ARG (exp, i + arg_adjust);\n+      op = expand_normal (arg);\n+      match = (*insn_p->operand[i + 1].predicate) (op, mode);\n \n-      pat = GEN_FCN (d->icode) (target, scratch1, op0, op1, op2);\n-    }\n-  else if (d->code == IX86_BUILTIN_PCMPISTRM128)\n-    {\n-      if (optimize || !target\n-\t  || GET_MODE (target) != tmode1\n-\t  || ! (*insn_data[d->icode].operand[1].predicate) (target, tmode1))\n-\ttarget = gen_reg_rtx (tmode1);\n+      if (last_arg_constant && (i + 1) == nargs)\n+\t{\n+\t  if (!match)\n+\t    switch (icode)\n+\t      {\n+\t     default:\n+\t\terror (\"the last argument must be an 8-bit immediate\");\n+\t\treturn const0_rtx;\n+\t      }\n+\t}\n+      else\n+\t{\n+\t  if (i == memory)\n+\t    {\n+\t      /* This must be the memory operand.  */\n+\t      op = gen_rtx_MEM (mode, copy_to_mode_reg (Pmode, op));\n+\t      gcc_assert (GET_MODE (op) == mode\n+\t\t\t  || GET_MODE (op) == VOIDmode);\n+\t    }\n+\t  else\n+\t    {\n+\t      /* This must be register.  */\n+\t      if (VECTOR_MODE_P (mode))\n+\t\top = safe_vector_operand (op, mode);\n \n-      scratch0 = gen_reg_rtx (tmode0);\n+\t      gcc_assert (GET_MODE (op) == mode\n+\t\t\t  || GET_MODE (op) == VOIDmode);\n+\t      op = copy_to_mode_reg (mode, op);\n+\t    }\n+\t}\n \n-      pat = GEN_FCN (d->icode) (scratch0, target, op0, op1, op2);\n+      args[i].op = op;\n+      args[i].mode = mode;\n     }\n-  else\n-    {\n-      gcc_assert (d->flag);\n \n-      scratch0 = gen_reg_rtx (tmode0);\n-      scratch1 = gen_reg_rtx (tmode1);\n-\n-      pat = GEN_FCN (d->icode) (scratch0, scratch1, op0, op1, op2);\n+  switch (nargs)\n+    {\n+    case 1:\n+      pat = GEN_FCN (icode) (target, args[0].op);\n+      break;\n+    case 2:\n+      pat = GEN_FCN (icode) (target, args[0].op, args[1].op);\n+      break;\n+    default:\n+      gcc_unreachable ();\n     }\n \n   if (! pat)\n     return 0;\n-\n   emit_insn (pat);\n-\n-  if (d->flag)\n-    {\n-      target = gen_reg_rtx (SImode);\n-      emit_move_insn (target, const0_rtx);\n-      target = gen_rtx_SUBREG (QImode, target, 0);\n-\n-      emit_insn\n-\t(gen_rtx_SET (VOIDmode, gen_rtx_STRICT_LOW_PART (VOIDmode, target),\n-\t\t      gen_rtx_fmt_ee (EQ, QImode,\n-\t\t\t\t      gen_rtx_REG ((enum machine_mode) d->flag,\n-\t\t\t\t\t\t   FLAGS_REG),\n-\t\t\t\t      const0_rtx)));\n-      return SUBREG_REG (target);\n-    }\n-  else\n-    return target;\n+  return class == store ? 0 : target;\n }\n \n /* Return the integer constant in ARG.  Constrain it to be in the range\n@@ -21486,10 +21484,6 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n     if (d->code == fcode)\n       return ix86_expand_sse_comi (d, exp, target);\n \n-  for (i = 0, d = bdesc_ptest; i < ARRAY_SIZE (bdesc_ptest); i++, d++)\n-    if (d->code == fcode)\n-      return ix86_expand_sse_ptest (d, exp, target);\n-\n   for (i = 0, d = bdesc_pcmpestr;\n        i < ARRAY_SIZE (bdesc_pcmpestr);\n        i++, d++)"}]}