{"sha": "cfa118fc089e38a94ec60ccf5b667aea015e5f60", "node_id": "C_kwDOANBUbNoAKGNmYTExOGZjMDg5ZTM4YTk0ZWM2MGNjZjViNjY3YWVhMDE1ZTVmNjA", "commit": {"author": {"name": "Alexandre Oliva", "email": "oliva@adacore.com", "date": "2023-03-03T18:59:17Z"}, "committer": {"name": "Alexandre Oliva", "email": "oliva@gnu.org", "date": "2023-03-03T18:59:17Z"}, "message": "[arm] complete vmsr/vmrs blank and case adjustments\n\nBack in September last year, some of the vmsr and vmrs patterns had an\nextraneous blank removed, and the case of register names lowered, but\nanother instance remained, and so did a testcase.\n\n\nfor  gcc/ChangeLog\n\n\t* config/arm/vfp.md (*thumb2_movsi_vfp): Drop blank after tab\n\tafter vmsr and vmrs, and lower the case of P0.\n\nfor  gcc/testsuite/ChangeLog\n\n\t* gcc.target/arm/acle/cde-mve-full-assembly.c: Drop blank\n\tafter tab after vmsr, and lower the case of P0.", "tree": {"sha": "af533015753507ba0afec68658389afd773627bf", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/af533015753507ba0afec68658389afd773627bf"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/cfa118fc089e38a94ec60ccf5b667aea015e5f60", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/cfa118fc089e38a94ec60ccf5b667aea015e5f60", "html_url": "https://github.com/Rust-GCC/gccrs/commit/cfa118fc089e38a94ec60ccf5b667aea015e5f60", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/cfa118fc089e38a94ec60ccf5b667aea015e5f60/comments", "author": null, "committer": null, "parents": [{"sha": "220008eafaaed7433b1c18e394279391e885a138", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/220008eafaaed7433b1c18e394279391e885a138", "html_url": "https://github.com/Rust-GCC/gccrs/commit/220008eafaaed7433b1c18e394279391e885a138"}], "stats": {"total": 268, "additions": 134, "deletions": 134}, "files": [{"sha": "60e7ba35d8b2525c3a255e8039a500d0f79b29e4", "filename": "gcc/config/arm/vfp.md", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfa118fc089e38a94ec60ccf5b667aea015e5f60/gcc%2Fconfig%2Farm%2Fvfp.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfa118fc089e38a94ec60ccf5b667aea015e5f60/gcc%2Fconfig%2Farm%2Fvfp.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fvfp.md?ref=cfa118fc089e38a94ec60ccf5b667aea015e5f60", "patch": "@@ -312,9 +312,9 @@\n     case 12: case 13:\n       return output_move_vfp (operands);\n     case 14:\n-      return \\\"vmsr\\\\t P0, %1\\\";\n+      return \\\"vmsr\\\\tp0, %1\\\";\n     case 15:\n-      return \\\"vmrs\\\\t %0, P0\\\";\n+      return \\\"vmrs\\\\t%0, p0\\\";\n     case 16:\n       return \\\"mcr\\\\tp10, 7, %1, cr1, cr0, 0\\\\t @SET_FPSCR\\\";\n     case 17:"}, {"sha": "72f330185944ad27a5e3c11e6e6514a333365c41", "filename": "gcc/testsuite/gcc.target/arm/acle/cde-mve-full-assembly.c", "status": "modified", "additions": 132, "deletions": 132, "changes": 264, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cfa118fc089e38a94ec60ccf5b667aea015e5f60/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Facle%2Fcde-mve-full-assembly.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cfa118fc089e38a94ec60ccf5b667aea015e5f60/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Facle%2Fcde-mve-full-assembly.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Facle%2Fcde-mve-full-assembly.c?ref=cfa118fc089e38a94ec60ccf5b667aea015e5f60", "patch": "@@ -534,80 +534,80 @@\n    contain back references).  */\n /*\n ** test_cde_vcx1q_mfloat16x8_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1t\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1q_mfloat32x4_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1t\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1q_muint8x16_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1t\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1q_muint16x8_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1t\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1q_muint32x4_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1t\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1q_muint64x2_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1t\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1q_mint8x16_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1t\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1q_mint16x8_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1t\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1q_mint32x4_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1t\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1q_mint64x2_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1t\tp0, q0, #32\n ** \tbx\tlr\n@@ -616,80 +616,80 @@\n \n /*\n ** test_cde_vcx1qa_mfloat16x8_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1at\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1qa_mfloat32x4_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1at\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1qa_muint8x16_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1at\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1qa_muint16x8_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1at\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1qa_muint32x4_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1at\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1qa_muint64x2_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1at\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1qa_mint8x16_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1at\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1qa_mint16x8_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1at\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1qa_mint32x4_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1at\tp0, q0, #32\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx1qa_mint64x2_tintint:\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n-** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\t P0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n+** \t(?:vmov\\.i32\tq0, #0  @ v16qi|vmsr\tp0, r2\t@ movhi)\n ** \tvpst\n ** \tvcx1at\tp0, q0, #32\n ** \tbx\tlr\n@@ -698,89 +698,89 @@\n \n /*\n ** test_cde_vcx2q_mfloat16x8_tuint16x8_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2t\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2q_mfloat16x8_tfloat32x4_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2t\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2q_mfloat32x4_tuint8x16_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2t\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2q_mint64x2_tuint8x16_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2t\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2q_mint8x16_tuint8x16_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2t\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2q_muint16x8_tuint8x16_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2t\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2q_muint8x16_tint64x2_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2t\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2q_muint8x16_tint8x16_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2t\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2q_muint8x16_tuint16x8_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2t\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2q_muint8x16_tuint8x16_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2t\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n@@ -790,89 +790,89 @@\n \n /*\n ** test_cde_vcx2qa_mfloat16x8_tuint16x8_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2at\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2qa_mfloat16x8_tfloat32x4_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2at\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2qa_mfloat32x4_tuint8x16_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2at\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2qa_mint64x2_tuint8x16_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2at\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2qa_mint8x16_tuint8x16_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2at\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2qa_muint16x8_tuint8x16_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2at\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2qa_muint8x16_tint64x2_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2at\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2qa_muint8x16_tint8x16_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2at\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2qa_muint8x16_tuint16x8_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2at\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx2qa_muint8x16_tuint8x16_tint:\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n-** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\t P0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n+** \t(?:vmov\\.i32\tq[1-7], #0  @ v16qi|vmsr\tp0, r1\t@ movhi)\n ** \tvpst\n ** \tvcx2at\tp0, (q[1-7]), q0, #32\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n@@ -882,116 +882,116 @@\n \n /*\n ** test_cde_vcx3q_muint8x16_tuint8x16_tuint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3t\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3q_mfloat16x8_tfloat16x8_tfloat16x8_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3t\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3q_mfloat32x4_tuint64x2_tfloat16x8_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3t\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3q_muint16x8_tuint8x16_tuint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3t\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3q_muint8x16_tuint16x8_tuint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3t\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3q_muint8x16_tuint8x16_tuint16x8_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3t\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3q_mint8x16_tuint8x16_tuint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3t\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3q_muint8x16_tint8x16_tuint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3t\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3q_muint8x16_tuint8x16_tint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3t\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3q_mint64x2_tuint8x16_tuint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3t\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3q_muint8x16_tint64x2_tuint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3t\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3q_muint8x16_tuint8x16_tint64x2_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3t\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3q_muint8x16_tint64x2_tint64x2_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3t\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n@@ -1001,116 +1001,116 @@\n \n /*\n ** test_cde_vcx3qa_muint8x16_tuint8x16_tuint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3at\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3qa_mfloat16x8_tfloat16x8_tfloat16x8_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3at\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3qa_mfloat32x4_tuint64x2_tfloat16x8_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3at\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3qa_muint16x8_tuint8x16_tuint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3at\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3qa_muint8x16_tuint16x8_tuint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3at\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3qa_muint8x16_tuint8x16_tuint16x8_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3at\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3qa_mint8x16_tuint8x16_tuint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3at\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3qa_muint8x16_tint8x16_tuint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3at\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3qa_muint8x16_tuint8x16_tint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3at\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3qa_mint64x2_tuint8x16_tuint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3at\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3qa_muint8x16_tint64x2_tuint8x16_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3at\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3qa_muint8x16_tuint8x16_tint64x2_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3at\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?\n ** \tbx\tlr\n */\n /*\n ** test_cde_vcx3qa_muint8x16_tint64x2_tint64x2_t:\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n-** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\t P0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n+** \t(?:vmov\\.i32\tq[2-7], #0  @ v16qi|vmsr\tp0, r0\t@ movhi)\n ** \tvpst\n ** \tvcx3at\tp0, (q[2-7]), q0, q1, #15\n ** \tvmov\tq0, \\1([[:space:]]+@ [^\\n]*)?"}]}