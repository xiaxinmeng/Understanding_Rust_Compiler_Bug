{"sha": "aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YWVlMmQ2MTE5ZDA0MzhkYWU4ZWIwZTdmMGZkYzdiOWVjOWY2N2QyNw==", "commit": {"author": {"name": "Jeff Law", "email": "law@redhat.com", "date": "2013-10-01T13:42:16Z"}, "committer": {"name": "Jeff Law", "email": "law@gcc.gnu.org", "date": "2013-10-01T13:42:16Z"}, "message": "tree-ssa-threadedge.c (thread_across_edge): Make path a pointer to a vec.\n\n\t* tree-ssa-threadedge.c (thread_across_edge): Make path a pointer to\n\ta vec.  Only delete the path if we create one without successfully\n\tregistering a jump thread.\n\t* tree-ssa-threadupdate.h (register_jump_thread): Pass in path vector\n\tas a pointer.\n\t* tree-ssa-threadupdate.c (threaded_edges): Remove.  No longer used\n\t(paths): New vector of jump threading paths.\n\t(THREAD_TARGET, THREAD_TARGET2): Remove accessor macros.\n\t(THREAD_PATH): New accessor macro for the entire thread path.\n\t(lookup_redirection_data): Get intermediate and final outgoing edge\n\tfrom the thread path.\n\t(create_edge_and_update_destination_phis): Copy the threading path.\n\t(ssa_fix_duplicate_block_edges): Get edges and block types from the\n\tjump threading path.\n\t(ssa_redirect_edges): Get edges and block types from the jump threading\n\tpath.  Free the path vector.\n\t(thread_block): Get edges from the jump threading path.  Look at the\n\tentire path to see if we thread to a loop exit.  If we cancel a jump\n\tthread request, then free the path vector.\n\t(thread_single_edge): Get edges and block types from the jump threading\n\tpath.  Free the path vector.\n\t(thread_through_loop_header): Get edges and block types from the jump\n\tthreading path.  Free the path vector.\n\t(mark_threaded_blocks): Iterate over the vector of paths and store\n\tthe path on the appropriate edge.  Get edges and block types from the\n\tjump threading path.\n\t(mark_threaded_blocks): Get edges and block types from the jump\n\tthreading path.  Free the path vector.\n\t(thread_through_all_blocks): Use the vector of paths rather than\n\ta vector of 3-edge sets.\n\t(register_jump_thread): Accept pointer to a path vector rather\n\tthan the path vector itself.  Store the path vector for later use.\n\tSimplify.\n\nFrom-SVN: r203061", "tree": {"sha": "b33755bbbed7cadc1a56cdbed01f43bdf885f843", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/b33755bbbed7cadc1a56cdbed01f43bdf885f843"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27", "html_url": "https://github.com/Rust-GCC/gccrs/commit/aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27/comments", "author": null, "committer": null, "parents": [{"sha": "966f97ac018548b15dbcee50790f32dc0d0b595f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/966f97ac018548b15dbcee50790f32dc0d0b595f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/966f97ac018548b15dbcee50790f32dc0d0b595f"}], "stats": {"total": 304, "additions": 179, "deletions": 125}, "files": [{"sha": "515872d63fe365afcae7b9dd491375214d29e45d", "filename": "gcc/ChangeLog", "status": "modified", "additions": 36, "deletions": 0, "changes": 36, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27", "patch": "@@ -1,3 +1,39 @@\n+2013-10-01  Jeff Law  <law@redhat.com>\n+\n+\t* tree-ssa-threadedge.c (thread_across_edge): Make path a pointer to\n+\ta vec.  Only delete the path if we create one without successfully\n+\tregistering a jump thread.\n+\t* tree-ssa-threadupdate.h (register_jump_thread): Pass in path vector\n+\tas a pointer.\n+\t* tree-ssa-threadupdate.c (threaded_edges): Remove.  No longer used\n+\t(paths): New vector of jump threading paths.\n+\t(THREAD_TARGET, THREAD_TARGET2): Remove accessor macros.\n+\t(THREAD_PATH): New accessor macro for the entire thread path.\n+\t(lookup_redirection_data): Get intermediate and final outgoing edge\n+\tfrom the thread path.\n+\t(create_edge_and_update_destination_phis): Copy the threading path.\n+\t(ssa_fix_duplicate_block_edges): Get edges and block types from the\n+\tjump threading path.\n+\t(ssa_redirect_edges): Get edges and block types from the jump threading\n+\tpath.  Free the path vector.\n+\t(thread_block): Get edges from the jump threading path.  Look at the\n+\tentire path to see if we thread to a loop exit.  If we cancel a jump\n+\tthread request, then free the path vector.\n+\t(thread_single_edge): Get edges and block types from the jump threading\n+\tpath.  Free the path vector.\n+\t(thread_through_loop_header): Get edges and block types from the jump\n+\tthreading path.  Free the path vector.\n+\t(mark_threaded_blocks): Iterate over the vector of paths and store\n+\tthe path on the appropriate edge.  Get edges and block types from the\n+\tjump threading path.\n+\t(mark_threaded_blocks): Get edges and block types from the jump\n+\tthreading path.  Free the path vector.\n+\t(thread_through_all_blocks): Use the vector of paths rather than\n+\ta vector of 3-edge sets.\n+\t(register_jump_thread): Accept pointer to a path vector rather\n+\tthan the path vector itself.  Store the path vector for later use.\n+\tSimplify.\n+\n 2013-10-01  Jakub Jelinek  <jakub@redhat.com>\n             Andreas Krebbel  <Andreas.Krebbel@de.ibm.com>\n "}, {"sha": "39e921b270c9e7c9ae916b4671e08d7a06563eac", "filename": "gcc/tree-ssa-threadedge.c", "status": "modified", "additions": 17, "deletions": 18, "changes": 35, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27/gcc%2Ftree-ssa-threadedge.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27/gcc%2Ftree-ssa-threadedge.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-threadedge.c?ref=aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27", "patch": "@@ -929,13 +929,13 @@ thread_across_edge (gimple dummy_cond,\n \t  if (dest == NULL || dest == e->dest)\n \t    goto fail;\n \n-\t  vec<jump_thread_edge *> path = vNULL;\n+\t  vec<jump_thread_edge *> *path = new vec<jump_thread_edge *> ();\n           jump_thread_edge *x\n \t    = new jump_thread_edge (e, EDGE_START_JUMP_THREAD);\n-\t  path.safe_push (x);\n+\t  path->safe_push (x);\n \n \t  x = new jump_thread_edge (taken_edge, EDGE_COPY_SRC_BLOCK);\n-\t  path.safe_push (x);\n+\t  path->safe_push (x);\n \n \t  /* See if we can thread through DEST as well, this helps capture\n \t     secondary effects of threading without having to re-run DOM or\n@@ -953,17 +953,14 @@ thread_across_edge (gimple dummy_cond,\n \t\t\t\t\t  handle_dominating_asserts,\n \t\t\t\t\t  simplify,\n \t\t\t\t\t  visited,\n-\t\t\t\t\t  &path);\n+\t\t\t\t\t  path);\n \t      BITMAP_FREE (visited);\n \t    }\n \n \t  remove_temporary_equivalences (stack);\n-\t  propagate_threaded_block_debug_into (path.last ()->e->dest,\n+\t  propagate_threaded_block_debug_into (path->last ()->e->dest,\n \t\t\t\t\t       e->dest);\n \t  register_jump_thread (path);\n-\t  for (unsigned int i = 0; i < path.length (); i++)\n-\t    delete path[i];\n-\t  path.release ();\n \t  return;\n \t}\n     }\n@@ -992,37 +989,39 @@ thread_across_edge (gimple dummy_cond,\n \tbitmap_clear (visited);\n \tbitmap_set_bit (visited, taken_edge->dest->index);\n \tbitmap_set_bit (visited, e->dest->index);\n-        vec<jump_thread_edge *> path = vNULL;\n+        vec<jump_thread_edge *> *path = new vec<jump_thread_edge *> ();\n \n \t/* Record whether or not we were able to thread through a successor\n \t   of E->dest.  */\n         jump_thread_edge *x = new jump_thread_edge (e, EDGE_START_JUMP_THREAD);\n-\tpath.safe_push (x);\n+\tpath->safe_push (x);\n \n         x = new jump_thread_edge (taken_edge, EDGE_COPY_SRC_JOINER_BLOCK);\n-\tpath.safe_push (x);\n+\tpath->safe_push (x);\n \tfound = false;\n \tif ((e->flags & EDGE_DFS_BACK) == 0\n-\t    || ! cond_arg_set_in_bb (path.last ()->e, e->dest))\n+\t    || ! cond_arg_set_in_bb (path->last ()->e, e->dest))\n \t  found = thread_around_empty_blocks (taken_edge,\n \t\t\t\t\t      dummy_cond,\n \t\t\t\t\t      handle_dominating_asserts,\n \t\t\t\t\t      simplify,\n \t\t\t\t\t      visited,\n-\t\t\t\t\t      &path);\n+\t\t\t\t\t      path);\n \n \t/* If we were able to thread through a successor of E->dest, then\n \t   record the jump threading opportunity.  */\n \tif (found)\n \t  {\n-\t    propagate_threaded_block_debug_into (path.last ()->e->dest,\n+\t    propagate_threaded_block_debug_into (path->last ()->e->dest,\n \t\t\t\t\t\t taken_edge->dest);\n \t    register_jump_thread (path);\n \t  }\n-\n-\tfor (unsigned int i = 0; i < path.length (); i++)\n-\t  delete path[i];\n-        path.release ();\n+\telse\n+\t  {\n+\t    for (unsigned int i = 0; i < path->length (); i++)\n+\t      delete (*path)[i];\n+\t    path->release();\n+\t  }\n       }\n     BITMAP_FREE (visited);\n   }"}, {"sha": "ecf9baf5430b239993f1c2a24de17c3f238d6b57", "filename": "gcc/tree-ssa-threadupdate.c", "status": "modified", "additions": 125, "deletions": 106, "changes": 231, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27/gcc%2Ftree-ssa-threadupdate.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27/gcc%2Ftree-ssa-threadupdate.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-threadupdate.c?ref=aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27", "patch": "@@ -70,14 +70,14 @@ along with GCC; see the file COPYING3.  If not see\n    set of unique destination blocks that the incoming edges should\n    be threaded to.\n \n-   Block duplication can be further minimized by using B instead of \n+   Block duplication can be further minimized by using B instead of\n    creating B' for one destination if all edges into B are going to be\n    threaded to a successor of B.  We had code to do this at one time, but\n    I'm not convinced it is correct with the changes to avoid mucking up\n    the loop structure (which may cancel threading requests, thus a block\n    which we thought was going to become unreachable may still be reachable).\n    This code was also going to get ugly with the introduction of the ability\n-   for a single jump thread request to bypass multiple blocks. \n+   for a single jump thread request to bypass multiple blocks.\n \n    We further reduce the number of edges and statements we create by\n    not copying all the outgoing edges and the control statement in\n@@ -168,13 +168,12 @@ struct ssa_local_info_t\n    opportunities as they are discovered.  We keep the registered\n    jump threading opportunities in this vector as edge pairs\n    (original_edge, target_edge).  */\n-static vec<edge> threaded_edges;\n+static vec<vec<jump_thread_edge *> *> paths;\n \n /* When we start updating the CFG for threading, data necessary for jump\n    threading is attached to the AUX field for the incoming edge.  Use these\n    macros to access the underlying structure attached to the AUX field.  */\n-#define THREAD_TARGET(E) ((edge *)(E)->aux)[0]\n-#define THREAD_TARGET2(E) ((edge *)(E)->aux)[1]\n+#define THREAD_PATH(E) ((vec<jump_thread_edge *> *)(E)->aux)\n \n /* Jump threading statistics.  */\n \n@@ -255,13 +254,15 @@ lookup_redirection_data (edge e, enum insert_option insert)\n {\n   struct redirection_data **slot;\n   struct redirection_data *elt;\n+  vec<jump_thread_edge *> *path = THREAD_PATH (e);\n \n  /* Build a hash table element so we can see if E is already\n      in the table.  */\n   elt = XNEW (struct redirection_data);\n-  elt->intermediate_edge = THREAD_TARGET2 (e) ? THREAD_TARGET (e) : NULL;\n-  elt->outgoing_edge = THREAD_TARGET2 (e) ? THREAD_TARGET2 (e) \n-\t\t\t\t\t  : THREAD_TARGET (e);\n+  /* Right now, if we have a joiner, it is always index 1 into the vector.  */\n+  elt->intermediate_edge\n+    = (*path)[1]->type == EDGE_COPY_SRC_JOINER_BLOCK ? (*path)[1]->e : NULL;\n+  elt->outgoing_edge = path->last ()->e;\n   elt->dup_block = NULL;\n   elt->incoming_edges = NULL;\n \n@@ -361,11 +362,22 @@ create_edge_and_update_destination_phis (struct redirection_data *rd,\n   e->probability = REG_BR_PROB_BASE;\n   e->count = bb->count;\n \n+  /* We have to copy path -- which means creating a new vector as well\n+     as all the jump_thread_edge entries.  */\n   if (rd->outgoing_edge->aux)\n     {\n-      e->aux = XNEWVEC (edge, 2);\n-      THREAD_TARGET (e) = THREAD_TARGET (rd->outgoing_edge);\n-      THREAD_TARGET2 (e) = THREAD_TARGET2 (rd->outgoing_edge);\n+      vec<jump_thread_edge *> *path = THREAD_PATH (rd->outgoing_edge);\n+      vec<jump_thread_edge *> *copy = new vec<jump_thread_edge *> ();\n+\n+      /* Sadly, the elements of the vector are pointers and need to\n+\t be copied as well.  */\n+      for (unsigned int i = 0; i < path->length (); i++)\n+\t{\n+\t  jump_thread_edge *x\n+\t    = new jump_thread_edge ((*path)[i]->e, (*path)[i]->type);\n+\t  copy->safe_push (x);\n+\t}\n+     e->aux = (void *)copy;\n     }\n   else\n     {\n@@ -385,31 +397,33 @@ void\n ssa_fix_duplicate_block_edges (struct redirection_data *rd,\n \t\t\t       ssa_local_info_t *local_info)\n {\n+  edge e = rd->incoming_edges->e;\n+  vec<jump_thread_edge *> *path = THREAD_PATH (e);\n+\n   /* If we were threading through an joiner block, then we want\n      to keep its control statement and redirect an outgoing edge.\n      Else we want to remove the control statement & edges, then create\n      a new outgoing edge.  In both cases we may need to update PHIs.  */\n-  if (THREAD_TARGET2 (rd->incoming_edges->e))\n+  if ((*path)[1]->type == EDGE_COPY_SRC_JOINER_BLOCK)\n     {\n       edge victim;\n       edge e2;\n-      edge e = rd->incoming_edges->e;\n \n       /* This updates the PHIs at the destination of the duplicate\n \t block.  */\n       update_destination_phis (local_info->bb, rd->dup_block);\n \n       /* Find the edge from the duplicate block to the block we're\n \t threading through.  That's the edge we want to redirect.  */\n-      victim = find_edge (rd->dup_block, THREAD_TARGET (e)->dest);\n-      e2 = redirect_edge_and_branch (victim, THREAD_TARGET2 (e)->dest);\n-      e2->count = THREAD_TARGET2 (e)->count;\n+      victim = find_edge (rd->dup_block, (*path)[1]->e->dest);\n+      e2 = redirect_edge_and_branch (victim, path->last ()->e->dest);\n+      e2->count = path->last ()->e->count;\n \n       /* If we redirected the edge, then we need to copy PHI arguments\n \t at the target.  If the edge already existed (e2 != victim case),\n \t then the PHIs in the target already have the correct arguments.  */\n       if (e2 == victim)\n-\tcopy_phi_args (e2->dest, THREAD_TARGET2 (e), e2);\n+\tcopy_phi_args (e2->dest, path->last ()->e, e2);\n     }\n   else\n     {\n@@ -490,6 +504,7 @@ ssa_redirect_edges (struct redirection_data **slot,\n   for (el = rd->incoming_edges; el; el = next)\n     {\n       edge e = el->e;\n+      vec<jump_thread_edge *> *path = THREAD_PATH (e);\n \n       /* Go ahead and free this element from the list.  Doing this now\n \t avoids the need for another list walk when we destroy the hash\n@@ -517,7 +532,7 @@ ssa_redirect_edges (struct redirection_data **slot,\n \t  /* In the case of threading through a joiner block, the outgoing\n \t     edges from the duplicate block were updated when they were\n \t     redirected during ssa_fix_duplicate_block_edges.  */\n-\t  if (!THREAD_TARGET2 (e))\n+\t  if ((*path)[1]->type != EDGE_COPY_SRC_JOINER_BLOCK)\n \t    EDGE_SUCC (rd->dup_block, 0)->count += e->count;\n \n \t  /* Redirect the incoming edge (possibly to the joiner block) to the\n@@ -529,7 +544,9 @@ ssa_redirect_edges (struct redirection_data **slot,\n \n       /* Go ahead and clear E->aux.  It's not needed anymore and failure\n          to clear it will cause all kinds of unpleasant problems later.  */\n-      free (e->aux);\n+      for (unsigned int i = 0; i < path->length (); i++)\n+\tdelete (*path)[i];\n+      path->release ();\n       e->aux = NULL;\n \n     }\n@@ -612,17 +629,21 @@ thread_block (basic_block bb, bool noloop_only)\n   if (loop->header == bb)\n     {\n       e = loop_latch_edge (loop);\n+      vec<jump_thread_edge *> *path = THREAD_PATH (e);\n \n-      if (e->aux)\n-\te2 = THREAD_TARGET (e);\n-      else\n-\te2 = NULL;\n-\n-      if (e2 && loop_exit_edge_p (loop, e2))\n+      if (path)\n \t{\n-\t  loop->header = NULL;\n-\t  loop->latch = NULL;\n-\t  loops_state_set (LOOPS_NEED_FIXUP);\n+\t  for (unsigned int i = 1; i < path->length (); i++)\n+\t    {\n+\t      edge e2 = (*path)[i]->e;\n+\n+\t      if (loop_exit_edge_p (loop, e2))\n+\t\t{\n+\t\t  loop->header = NULL;\n+\t\t  loop->latch = NULL;\n+\t\t  loops_state_set (LOOPS_NEED_FIXUP);\n+\t\t}\n+\t    }\n \t}\n     }\n \n@@ -633,23 +654,20 @@ thread_block (basic_block bb, bool noloop_only)\n       if (e->aux == NULL)\n \tcontinue;\n \n-      if (THREAD_TARGET2 (e))\n-\te2 = THREAD_TARGET2 (e);\n-      else\n-\te2 = THREAD_TARGET (e);\n-\n+      vec<jump_thread_edge *> *path = THREAD_PATH (e);\n+      e2 = path->last ()->e;\n       if (!e2 || noloop_only)\n \t{\n \t  /* If NOLOOP_ONLY is true, we only allow threading through the\n-\t     header of a loop to exit edges. \n+\t     header of a loop to exit edges.\n \n \t     There are two cases to consider.  The first when BB is the\n \t     loop header.  We will attempt to thread this elsewhere, so\n \t     we can just continue here.  */\n \n \t  if (bb == bb->loop_father->header\n \t      && (!loop_exit_edge_p (bb->loop_father, e2)\n-\t\t  || THREAD_TARGET2 (e)))\n+\t\t  || (*path)[1]->type == EDGE_COPY_SRC_JOINER_BLOCK))\n \t    continue;\n \n \n@@ -665,15 +683,17 @@ thread_block (basic_block bb, bool noloop_only)\n \t      /* Since this case is not handled by our special code\n \t\t to thread through a loop header, we must explicitly\n \t\t cancel the threading request here.  */\n-\t      free (e->aux);\n+\t      for (unsigned int i = 0; i < path->length (); i++)\n+\t\tdelete (*path)[i];\n+\t      path->release ();\n \t      e->aux = NULL;\n \t      continue;\n \t    }\n \t}\n \n       if (e->dest == e2->src)\n \tupdate_bb_profile_for_threading (e->dest, EDGE_FREQUENCY (e),\n-\t\t\t\t         e->count, THREAD_TARGET (e));\n+\t\t\t\t         e->count, (*THREAD_PATH (e))[1]->e);\n \n       /* Insert the outgoing edge into the hash table if it is not\n \t already in the hash table.  */\n@@ -739,10 +759,13 @@ static basic_block\n thread_single_edge (edge e)\n {\n   basic_block bb = e->dest;\n-  edge eto = THREAD_TARGET (e);\n   struct redirection_data rd;\n+  vec<jump_thread_edge *> *path = THREAD_PATH (e);\n+  edge eto = (*path)[1]->e;\n \n-  free (e->aux);\n+  for (unsigned int i = 0; i < path->length (); i++)\n+    delete (*path)[i];\n+  delete path;\n   e->aux = NULL;\n \n   thread_stats.num_threaded_edges++;\n@@ -963,9 +986,10 @@ thread_through_loop_header (struct loop *loop, bool may_peel_loop_headers)\n \n   if (latch->aux)\n     {\n-      if (THREAD_TARGET2 (latch))\n+      vec<jump_thread_edge *> *path = THREAD_PATH (latch);\n+      if ((*path)[1]->type == EDGE_COPY_SRC_JOINER_BLOCK)\n \tgoto fail;\n-      tgt_edge = THREAD_TARGET (latch);\n+      tgt_edge = (*path)[1]->e;\n       tgt_bb = tgt_edge->dest;\n     }\n   else if (!may_peel_loop_headers\n@@ -988,9 +1012,11 @@ thread_through_loop_header (struct loop *loop, bool may_peel_loop_headers)\n \t      goto fail;\n \t    }\n \n-\t  if (THREAD_TARGET2 (e))\n+\t  vec<jump_thread_edge *> *path = THREAD_PATH (e);\n+\n+\t  if ((*path)[1]->type == EDGE_COPY_SRC_JOINER_BLOCK)\n \t    goto fail;\n-\t  tgt_edge = THREAD_TARGET (e);\n+\t  tgt_edge = (*path)[1]->e;\n \t  atgt_bb = tgt_edge->dest;\n \t  if (!tgt_bb)\n \t    tgt_bb = atgt_bb;\n@@ -1085,15 +1111,15 @@ thread_through_loop_header (struct loop *loop, bool may_peel_loop_headers)\n \t  if (e->aux == NULL)\n \t    continue;\n \n-\t  if (THREAD_TARGET2 (e))\n-\t    e2 = THREAD_TARGET2 (e);\n-\t  else\n-\t    e2 = THREAD_TARGET (e);\n+\t  vec<jump_thread_edge *> *path = THREAD_PATH (e);\n+\t  e2 = path->last ()->e;\n \n \t  if (e->src->loop_father != e2->dest->loop_father\n \t      && e2->dest != loop->header)\n \t    {\n-\t      free (e->aux);\n+\t      for (unsigned int i = 0; i < path->length (); i++)\n+\t\tdelete (*path)[i];\n+\t      path->release ();\n \t      e->aux = NULL;\n \t    }\n \t}\n@@ -1139,8 +1165,15 @@ thread_through_loop_header (struct loop *loop, bool may_peel_loop_headers)\n   /* We failed to thread anything.  Cancel the requests.  */\n   FOR_EACH_EDGE (e, ei, header->preds)\n     {\n-      free (e->aux);\n-      e->aux = NULL;\n+      vec<jump_thread_edge *> *path = THREAD_PATH (e);\n+\n+      if (path)\n+\t{\n+\t  for (unsigned int i = 0; i < path->length (); i++)\n+\t    delete (*path)[i];\n+\t  path->release ();\n+\t  e->aux = NULL;\n+\t}\n     }\n   return false;\n }\n@@ -1200,21 +1233,18 @@ mark_threaded_blocks (bitmap threaded_blocks)\n      This results in less block copying, simpler CFGs.  More improtantly,\n      when we duplicate the joiner block, B, in this case we will create\n      a new threading opportunity that we wouldn't be able to optimize\n-     until the next jump threading iteration. \n+     until the next jump threading iteration.\n \n      So first convert the jump thread requests which do not require a\n      joiner block.  */\n-  for (i = 0; i < threaded_edges.length (); i += 3)\n+  for (i = 0; i < paths.length (); i++)\n     {\n-      edge e = threaded_edges[i];\n+      vec<jump_thread_edge *> *path = paths[i];\n \n-      if (threaded_edges[i + 2] == NULL)\n+      if ((*path)[1]->type != EDGE_COPY_SRC_JOINER_BLOCK)\n \t{\n-\t  edge *x = XNEWVEC (edge, 2);\n-\n-\t  e->aux = x;\n-\t  THREAD_TARGET (e) = threaded_edges[i + 1];\n-\t  THREAD_TARGET2 (e) = NULL;\n+\t  edge e = (*path)[0]->e;\n+\t  e->aux = (void *)path;\n \t  bitmap_set_bit (tmp, e->dest->index);\n \t}\n     }\n@@ -1223,18 +1253,15 @@ mark_threaded_blocks (bitmap threaded_blocks)\n   /* Now iterate again, converting cases where we threaded through\n      a joiner block, but ignoring those where we have already\n      threaded through the joiner block.  */\n-  for (i = 0; i < threaded_edges.length (); i += 3)\n+  for (i = 0; i < paths.length (); i++)\n     {\n-      edge e = threaded_edges[i];\n+      vec<jump_thread_edge *> *path = paths[i];\n \n-      if (threaded_edges[i + 2] != NULL\n-\t  && threaded_edges[i + 1]->aux == NULL)\n+      if ((*path)[1]->type == EDGE_COPY_SRC_JOINER_BLOCK\n+\t  && (*path)[0]->e->aux == NULL)\n \t{\n-\t  edge *x = XNEWVEC (edge, 2);\n-\n-\t  e->aux = x;\n-\t  THREAD_TARGET (e) = threaded_edges[i + 1];\n-\t  THREAD_TARGET2 (e) = threaded_edges[i + 2];\n+\t  edge e = (*path)[0]->e;\n+\t  e->aux = path;\n \t  bitmap_set_bit (tmp, e->dest->index);\n \t}\n     }\n@@ -1246,10 +1273,10 @@ mark_threaded_blocks (bitmap threaded_blocks)\n \n      We used to detect this prior to registering the jump thread, but\n      that prohibits propagation of edge equivalences into non-dominated\n-     PHI nodes as the equivalency test might occur before propagation. \n+     PHI nodes as the equivalency test might occur before propagation.\n \n      This works for now, but will need improvement as part of the FSA\n-     optimization. \n+     optimization.\n \n      Note since we've moved the thread request data to the edges,\n      we have to iterate on those rather than the threaded_edges vector.  */\n@@ -1260,18 +1287,21 @@ mark_threaded_blocks (bitmap threaded_blocks)\n \t{\n \t  if (e->aux)\n \t    {\n-\t      bool have_joiner = THREAD_TARGET2 (e) != NULL;\n+\t      vec<jump_thread_edge *> *path = THREAD_PATH (e);\n+\t      bool have_joiner = ((*path)[1]->type == EDGE_COPY_SRC_JOINER_BLOCK);\n \n \t      if (have_joiner)\n \t\t{\n \t\t  basic_block joiner = e->dest;\n-\t\t  edge final_edge = THREAD_TARGET2 (e);\n+\t\t  edge final_edge = path->last ()->e;\n \t\t  basic_block final_dest = final_edge->dest;\n \t\t  edge e2 = find_edge (joiner, final_dest);\n \n \t\t  if (e2 && !phi_args_equal_on_edges (e2, final_edge))\n \t\t    {\n-\t\t      free (e->aux);\n+\t\t      for (unsigned int i = 0; i < path->length (); i++)\n+\t\t\tdelete (*path)[i];\n+\t\t      path->release ();\n \t\t      e->aux = NULL;\n \t\t    }\n \t\t}\n@@ -1292,8 +1322,14 @@ mark_threaded_blocks (bitmap threaded_blocks)\n \t    {\n \t      FOR_EACH_EDGE (e, ei, bb->preds)\n \t\t{\n-\t\t  free (e->aux);\n-\t\t  e->aux = NULL;\n+\t\t  if (e->aux)\n+\t\t    {\n+\t\t      vec<jump_thread_edge *> *path = THREAD_PATH (e);\n+\t\t      for (unsigned int i = 0; i < path->length (); i++)\n+\t\t        delete (*path)[i];\n+\t\t      path->release ();\n+\t\t      e->aux = NULL;\n+\t\t    }\n \t\t}\n \t    }\n \t  else\n@@ -1331,7 +1367,7 @@ thread_through_all_blocks (bool may_peel_loop_headers)\n   /* We must know about loops in order to preserve them.  */\n   gcc_assert (current_loops != NULL);\n \n-  if (!threaded_edges.exists ())\n+  if (!paths.exists ())\n     return false;\n \n   threaded_blocks = BITMAP_ALLOC (NULL);\n@@ -1370,7 +1406,7 @@ thread_through_all_blocks (bool may_peel_loop_headers)\n \n   BITMAP_FREE (threaded_blocks);\n   threaded_blocks = NULL;\n-  threaded_edges.release ();\n+  paths.release ();\n \n   if (retval)\n     loops_state_set (LOOPS_NEED_FIXUP);\n@@ -1410,7 +1446,6 @@ dump_jump_thread_path (FILE *dump_file, vec<jump_thread_edge *> path)\n   fputc ('\\n', dump_file);\n }\n \n-\n /* Register a jump threading opportunity.  We queue up all the jump\n    threading opportunities discovered by a pass and update the CFG\n    and SSA form all at once.\n@@ -1420,47 +1455,31 @@ dump_jump_thread_path (FILE *dump_file, vec<jump_thread_edge *> path)\n    after fixing the SSA graph.  */\n \n void\n-register_jump_thread (vec<jump_thread_edge *> path)\n+register_jump_thread (vec<jump_thread_edge *> *path)\n {\n   /* First make sure there are no NULL outgoing edges on the jump threading\n      path.  That can happen for jumping to a constant address.  */\n-  for (unsigned int i = 0; i < path.length (); i++)\n-    if (path[i]->e == NULL)\n+  for (unsigned int i = 0; i < path->length (); i++)\n+    if ((*path)[i]->e == NULL)\n       {\n \tif (dump_file && (dump_flags & TDF_DETAILS))\n \t  {\n \t    fprintf (dump_file,\n \t\t     \"Found NULL edge in jump threading path.  Cancelling jump thread:\\n\");\n-\t    dump_jump_thread_path (dump_file, path);\n+\t    dump_jump_thread_path (dump_file, *path);\n \t  }\n+\n+\tfor (unsigned int i = 0; i < path->length (); i++)\n+\t  delete (*path)[i];\n+\tpath->release ();\n \treturn;\n       }\n \n-  if (!threaded_edges.exists ())\n-    threaded_edges.create (15);\n-\n   if (dump_file && (dump_flags & TDF_DETAILS))\n-    dump_jump_thread_path (dump_file, path);\n+    dump_jump_thread_path (dump_file, *path);\n \n-  /* The first entry in the vector is always the start of the\n-     jump threading path.  */\n-  threaded_edges.safe_push (path[0]->e);\n+  if (!paths.exists ())\n+    paths.create (5);\n \n-  /* In our 3-edge representation, the joiner, if it exists is always the\n-     2nd edge and the final block on the path is the 3rd edge.  If no\n-     jointer exists, then the final block on the path is the 2nd edge\n-     and the 3rd edge is NULL.\n-\n-     With upcoming improvements, we're going to be holding onto the entire\n-     path, so we'll be able to clean this wart up shortly.  */\n-  if (path[1]->type == EDGE_COPY_SRC_JOINER_BLOCK)\n-    {\n-      threaded_edges.safe_push (path[1]->e);\n-      threaded_edges.safe_push (path.last ()->e);\n-    }\n-  else\n-    {\n-      threaded_edges.safe_push (path.last ()->e);\n-      threaded_edges.safe_push (NULL);\n-    }\n+  paths.safe_push (path);\n }"}, {"sha": "f84c02e9b3cdb8e4c91b2bb343705009c4b8c890", "filename": "gcc/tree-ssa-threadupdate.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27/gcc%2Ftree-ssa-threadupdate.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27/gcc%2Ftree-ssa-threadupdate.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-threadupdate.h?ref=aee2d6119d0438dae8eb0e7f0fdc7b9ec9f67d27", "patch": "@@ -41,5 +41,5 @@ class jump_thread_edge\n   enum jump_thread_edge_type type;\n };\n \n-extern void register_jump_thread (vec<class jump_thread_edge *>);\n+extern void register_jump_thread (vec <class jump_thread_edge *> *);\n #endif"}]}