{"sha": "4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NGNhYzlkMDBlOTNhNDBjN2IxOWYwMDYwYjhiNGY4ZjViM2U0ZDY3Ng==", "commit": {"author": {"name": "Martin Liska", "email": "mliska@suse.cz", "date": "2018-09-25T07:08:44Z"}, "committer": {"name": "Martin Liska", "email": "marxin@gcc.gnu.org", "date": "2018-09-25T07:08:44Z"}, "message": "Document all param values and remove defaults (PR middle-end/86078).\n\n2018-09-25  Martin Liska  <mliska@suse.cz>\n\n\tPR middle-end/86078\n\t* doc/invoke.texi: Document all parameters and remove default\n\tof the parameters.\n2018-09-25  Martin Liska  <mliska@suse.cz>\n\n\tPR middle-end/86078\n\t* check-params-in-docs.py: New file.\n\nFrom-SVN: r264558", "tree": {"sha": "804deaf68b6ca4cd2870eaba57b823bbb2cc43c2", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/804deaf68b6ca4cd2870eaba57b823bbb2cc43c2"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676/comments", "author": {"login": "marxin", "id": 2658545, "node_id": "MDQ6VXNlcjI2NTg1NDU=", "avatar_url": "https://avatars.githubusercontent.com/u/2658545?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marxin", "html_url": "https://github.com/marxin", "followers_url": "https://api.github.com/users/marxin/followers", "following_url": "https://api.github.com/users/marxin/following{/other_user}", "gists_url": "https://api.github.com/users/marxin/gists{/gist_id}", "starred_url": "https://api.github.com/users/marxin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marxin/subscriptions", "organizations_url": "https://api.github.com/users/marxin/orgs", "repos_url": "https://api.github.com/users/marxin/repos", "events_url": "https://api.github.com/users/marxin/events{/privacy}", "received_events_url": "https://api.github.com/users/marxin/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "d5c4f75ddbf2994b6c462ed4b624ab5fcf23674f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d5c4f75ddbf2994b6c462ed4b624ab5fcf23674f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d5c4f75ddbf2994b6c462ed4b624ab5fcf23674f"}], "stats": {"total": 414, "additions": 296, "deletions": 118}, "files": [{"sha": "14b8ee25d7e5fabc2b41f66376b29599b7a1f295", "filename": "contrib/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676/contrib%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676/contrib%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/contrib%2FChangeLog?ref=4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676", "patch": "@@ -1,3 +1,8 @@\n+2018-09-25  Martin Liska  <mliska@suse.cz>\n+\n+\tPR middle-end/86078\n+\t* check-params-in-docs.py: New file.\n+\n 2018-08-17  Jojo  <jijie_rong@c-sky.com>\n \t    Huibin Wang  <huibin_wang@c-sky.com>\n \t    Sandra Loosemore  <sandra@codesourcery.com>"}, {"sha": "eb36f4b865499ca3bd315337fc2e1037ecb66afd", "filename": "contrib/check-params-in-docs.py", "status": "added", "additions": 76, "deletions": 0, "changes": 76, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676/contrib%2Fcheck-params-in-docs.py", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676/contrib%2Fcheck-params-in-docs.py", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/contrib%2Fcheck-params-in-docs.py?ref=4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676", "patch": "@@ -0,0 +1,76 @@\n+#!/usr/bin/env python3\n+#\n+# Find missing and extra parameters in documentation compared to\n+# output of: gcc --help=params.\n+#\n+# This file is part of GCC.\n+#\n+# GCC is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU General Public License as published by the Free\n+# Software Foundation; either version 3, or (at your option) any later\n+# version.\n+#\n+# GCC is distributed in the hope that it will be useful, but WITHOUT ANY\n+# WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+# for more details.\n+#\n+# You should have received a copy of the GNU General Public License\n+# along with GCC; see the file COPYING3.  If not see\n+# <http://www.gnu.org/licenses/>.  */\n+#\n+#\n+#\n+\n+import sys\n+import json\n+import argparse\n+\n+from itertools import *\n+\n+def get_param_tuple(line):\n+    line = line.strip()\n+    i = line.find(' ')\n+    return (line[:i], line[i:].strip())\n+\n+parser = argparse.ArgumentParser()\n+parser.add_argument('texi_file')\n+parser.add_argument('params_output')\n+\n+args = parser.parse_args()\n+\n+params = {}\n+\n+for line in open(args.params_output).readlines():\n+    if line.startswith('  '):\n+        r = get_param_tuple(line)\n+        params[r[0]] = r[1]\n+\n+# Find section in .texi manual with parameters\n+texi = ([x.strip() for x in open(args.texi_file).readlines()])\n+texi = dropwhile(lambda x: not 'item --param' in x, texi)\n+texi = takewhile(lambda x: not '@node Instrumentation Options' in x, texi)\n+texi = list(texi)[1:]\n+\n+token = '@item '\n+texi = [x[len(token):] for x in texi if x.startswith(token)]\n+sorted_texi = sorted(texi)\n+\n+texi_set = set(texi)\n+params_set = set(params.keys())\n+\n+extra = texi_set - params_set\n+if len(extra):\n+    print('Extra:')\n+    print(extra)\n+\n+missing = params_set - texi_set\n+if len(missing):\n+    print('Missing:')\n+    for m in missing:\n+        print('@item ' + m)\n+        print(params[m])\n+        print()\n+\n+if texi != sorted_texi:\n+    print('WARNING: not sorted alphabetically!')"}, {"sha": "033a5fa7a791dc8aa6616de2a5d585fd761498b5", "filename": "gcc/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676", "patch": "@@ -1,3 +1,9 @@\n+2018-09-25  Martin Liska  <mliska@suse.cz>\n+\n+\tPR middle-end/86078\n+\t* doc/invoke.texi: Document all parameters and remove default\n+\tof the parameters.\n+\n 2018-09-25  Ilya Leoshkevich  <iii@linux.ibm.com>\n \n \tPR bootstrap/87417"}, {"sha": "dba1e622b8075933492b7cc3c607339345af5ccf", "filename": "gcc/doc/invoke.texi", "status": "modified", "additions": 209, "deletions": 118, "changes": 327, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676/gcc%2Fdoc%2Finvoke.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676/gcc%2Fdoc%2Finvoke.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finvoke.texi?ref=4cac9d00e93a40c7b19f0060b8b4f8f5b3e4d676", "patch": "@@ -10428,19 +10428,22 @@ The names of specific parameters, and the meaning of the values, are\n tied to the internals of the compiler, and are subject to change\n without notice in future releases.\n \n+In order to get minimal, maximal and default value of a parameter,\n+one can use @option{--help=param -Q} options.\n+\n In each case, the @var{value} is an integer.  The allowable choices for\n @var{name} are:\n \n @table @gcctabopt\n @item predictable-branch-outcome\n When branch is predicted to be taken with probability lower than this threshold\n-(in percent), then it is considered well predictable. The default is 10.\n+(in percent), then it is considered well predictable.\n \n @item max-rtl-if-conversion-insns\n RTL if-conversion tries to remove conditional branches around a block and\n replace them with conditionally executed instructions.  This parameter\n gives the maximum number of instructions in a block which should be\n-considered for if-conversion.  The default is 10, though the compiler will\n+considered for if-conversion.  The compiler will\n also use other heuristics to decide whether if-conversion is likely to be\n profitable.\n \n@@ -10466,20 +10469,19 @@ probably small improvement in executable size.\n The minimum number of instructions that must be matched at the end\n of two blocks before cross-jumping is performed on them.  This\n value is ignored in the case where all instructions in the block being\n-cross-jumped from are matched.  The default value is 5.\n+cross-jumped from are matched.\n \n @item max-grow-copy-bb-insns\n The maximum code size expansion factor when copying basic blocks\n instead of jumping.  The expansion is relative to a jump instruction.\n-The default value is 8.\n \n @item max-goto-duplication-insns\n The maximum number of instructions to duplicate to a block that jumps\n to a computed goto.  To avoid @math{O(N^2)} behavior in a number of\n passes, GCC factors computed gotos early in the compilation process,\n and unfactors them as late as possible.  Only computed jumps at the\n end of a basic blocks with no more than max-goto-duplication-insns are\n-unfactored.  The default value is 8.\n+unfactored.\n \n @item max-delay-slot-insn-search\n The maximum number of instructions to consider when looking for an\n@@ -10506,7 +10508,7 @@ optimization is not done.\n @item max-gcse-insertion-ratio\n If the ratio of expression insertions to deletions is larger than this value\n for any expression, then RTL PRE inserts or removes the expression and thus\n-leaves partially redundant computations in the instruction stream.  The default value is 20.\n+leaves partially redundant computations in the instruction stream.\n \n @item max-pending-list-length\n The maximum number of pending dependencies scheduling allows\n@@ -10525,34 +10527,30 @@ This number sets the maximum number of instructions (counted in GCC's\n internal representation) in a single function that the tree inliner\n considers for inlining.  This only affects functions declared\n inline and methods implemented in a class declaration (C++).\n-The default value is 400.\n \n @item max-inline-insns-auto\n When you use @option{-finline-functions} (included in @option{-O3}),\n a lot of functions that would otherwise not be considered for inlining\n by the compiler are investigated.  To those functions, a different\n (more restrictive) limit compared to functions declared inline can\n be applied.\n-The default value is 30.\n \n @item inline-min-speedup\n When estimated performance improvement of caller + callee runtime exceeds this\n threshold (in percent), the function can be inlined regardless of the limit on\n @option{--param max-inline-insns-single} and @option{--param\n max-inline-insns-auto}.\n-The default value is 15.\n \n @item large-function-insns\n The limit specifying really large functions.  For functions larger than this\n limit after inlining, inlining is constrained by\n @option{--param large-function-growth}.  This parameter is useful primarily\n to avoid extreme compilation time caused by non-linear algorithms used by the\n back end.\n-The default value is 2700.\n \n @item large-function-growth\n Specifies maximal growth of large function caused by inlining in percents.\n-The default value is 100 which limits large function growth to 2.0 times\n+For example, parameter value 100 limits large function growth to 2.0 times\n the original size.\n \n @item large-unit-insns\n@@ -10565,26 +10563,26 @@ A, the growth of unit is 300\\% and yet such inlining is very sane.  For very\n large units consisting of small inlineable functions, however, the overall unit\n growth limit is needed to avoid exponential explosion of code size.  Thus for\n smaller units, the size is increased to @option{--param large-unit-insns}\n-before applying @option{--param inline-unit-growth}.  The default is 10000.\n+before applying @option{--param inline-unit-growth}.\n \n @item inline-unit-growth\n Specifies maximal overall growth of the compilation unit caused by inlining.\n-The default value is 20 which limits unit growth to 1.2 times the original\n+For example, parameter value 20 limits unit growth to 1.2 times the original\n size. Cold functions (either marked cold via an attribute or by profile\n feedback) are not accounted into the unit size.\n \n @item ipcp-unit-growth\n Specifies maximal overall growth of the compilation unit caused by\n-interprocedural constant propagation.  The default value is 10 which limits\n+interprocedural constant propagation.  For example, parameter value 10 limits\n unit growth to 1.1 times the original size.\n \n @item large-stack-frame\n The limit specifying large stack frames.  While inlining the algorithm is trying\n-to not grow past this limit too much.  The default value is 256 bytes.\n+to not grow past this limit too much.\n \n @item large-stack-frame-growth\n Specifies maximal growth of large stack frames caused by inlining in percents.\n-The default value is 1000 which limits large stack frame growth to 11 times\n+For example, parameter value 1000 limits large stack frame growth to 11 times\n the original size.\n \n @item max-inline-insns-recursive\n@@ -10597,8 +10595,7 @@ function can grow into by performing recursive inlining.\n declared inline.\n For functions not declared inline, recursive inlining\n happens only when @option{-finline-functions} (included in @option{-O3}) is\n-enabled; @option{--param max-inline-insns-recursive-auto} applies instead.  The\n-default value is 450.\n+enabled; @option{--param max-inline-insns-recursive-auto} applies instead.\n \n @item max-inline-recursive-depth\n @itemx max-inline-recursive-depth-auto\n@@ -10607,8 +10604,7 @@ Specifies the maximum recursion depth used for recursive inlining.\n @option{--param max-inline-recursive-depth} applies to functions\n declared inline.  For functions not declared inline, recursive inlining\n happens only when @option{-finline-functions} (included in @option{-O3}) is\n-enabled; @option{--param max-inline-recursive-depth-auto} applies instead.  The\n-default value is 8.\n+enabled; @option{--param max-inline-recursive-depth-auto} applies instead.\n \n @item min-inline-recursive-probability\n Recursive inlining is profitable only for function having deep recursion\n@@ -10620,12 +10616,10 @@ When profile feedback is available (see @option{-fprofile-generate}) the actual\n recursion depth can be guessed from the probability that function recurses\n via a given call expression.  This parameter limits inlining only to call\n expressions whose probability exceeds the given threshold (in percents).\n-The default value is 10.\n \n @item early-inlining-insns\n Specify growth that the early inliner can make.  In effect it increases\n the amount of inlining for code having a large abstraction penalty.\n-The default value is 14.\n \n @item max-early-inliner-iterations\n Limit of iterations of the early inliner.  This basically bounds\n@@ -10634,28 +10628,27 @@ Deeper chains are still handled by late inlining.\n \n @item comdat-sharing-probability\n Probability (in percent) that C++ inline function with comdat visibility\n-are shared across multiple compilation units.  The default value is 20.\n+are shared across multiple compilation units.\n \n @item profile-func-internal-id\n A parameter to control whether to use function internal id in profile\n database lookup. If the value is 0, the compiler uses an id that\n is based on function assembler name and filename, which makes old profile\n data more tolerant to source changes such as function reordering etc.\n-The default value is 0.\n \n @item min-vect-loop-bound\n The minimum number of iterations under which loops are not vectorized\n when @option{-ftree-vectorize} is used.  The number of iterations after\n vectorization needs to be greater than the value specified by this option\n-to allow vectorization.  The default value is 0.\n+to allow vectorization.\n \n @item gcse-cost-distance-ratio\n Scaling factor in calculation of maximum distance an expression\n can be moved by GCSE optimizations.  This is currently supported only in the\n code hoisting pass.  The bigger the ratio, the more aggressive code hoisting\n is with simple expressions, i.e., the expressions that have cost\n less than @option{gcse-unrestricted-cost}.  Specifying 0 disables\n-hoisting of simple expressions.  The default value is 10.\n+hoisting of simple expressions.\n \n @item gcse-unrestricted-cost\n Cost, roughly measured as the cost of a single typical machine\n@@ -10664,29 +10657,28 @@ the distance an expression can travel.  This is currently\n supported only in the code hoisting pass.  The lesser the cost,\n the more aggressive code hoisting is.  Specifying 0 \n allows all expressions to travel unrestricted distances.\n-The default value is 3.\n \n @item max-hoist-depth\n The depth of search in the dominator tree for expressions to hoist.\n This is used to avoid quadratic behavior in hoisting algorithm.\n The value of 0 does not limit on the search, but may slow down compilation\n-of huge functions.  The default value is 30.\n+of huge functions.\n \n @item max-tail-merge-comparisons\n The maximum amount of similar bbs to compare a bb with.  This is used to\n-avoid quadratic behavior in tree tail merging.  The default value is 10.\n+avoid quadratic behavior in tree tail merging.\n \n @item max-tail-merge-iterations\n The maximum amount of iterations of the pass over the function.  This is used to\n-limit compilation time in tree tail merging.  The default value is 2.\n+limit compilation time in tree tail merging.\n \n @item store-merging-allow-unaligned\n Allow the store merging pass to introduce unaligned stores if it is legal to\n-do so.  The default value is 1.\n+do so.\n \n @item max-stores-to-merge\n The maximum number of stores to attempt to merge into wider stores in the store\n-merging pass.  The minimum value is 2 and the default is 64.\n+merging pass.\n \n @item max-unrolled-insns\n The maximum number of instructions that a loop may have to be unrolled.\n@@ -10727,10 +10719,6 @@ The maximum number of insns of an unswitched loop.\n @item max-unswitch-level\n The maximum number of branches unswitched in a single loop.\n \n-@item max-loop-headers-insns\n-The maximum number of insns in loop header duplicated by the copy loop headers\n-pass.\n-\n @item lim-expensive\n The minimum cost of an expensive expression in the loop invariant motion.\n \n@@ -10808,12 +10796,10 @@ loop without bounds appears artificially cold relative to the other one.\n @item builtin-expect-probability\n Control the probability of the expression having the specified value. This\n parameter takes a percentage (i.e. 0 ... 100) as input.\n-The default probability of 90 is obtained empirically.\n \n @item builtin-string-cmp-inline-length\n The maximum length of a constant string for a builtin string cmp call \n eligible for inlining.\n-The default value is 3.\n \n @item align-threshold\n \n@@ -10863,27 +10849,23 @@ effective.\n \n @item stack-clash-protection-guard-size\n Specify the size of the operating system provided stack guard as\n-2 raised to @var{num} bytes.  The default value is 12 (4096 bytes).\n-Acceptable values are between 12 and 30.  Higher values may reduce the\n+2 raised to @var{num} bytes.  Higher values may reduce the\n number of explicit probes, but a value larger than the operating system\n provided guard will leave code vulnerable to stack clash style attacks.\n \n @item stack-clash-protection-probe-interval\n Stack clash protection involves probing stack space as it is allocated.  This\n param controls the maximum distance between probes into the stack as 2 raised\n-to @var{num} bytes.  Acceptable values are between 10 and 16 and defaults to\n-12.  Higher values may reduce the number of explicit probes, but a value\n+to @var{num} bytes.  Higher values may reduce the number of explicit probes, but a value\n larger than the operating system provided guard will leave code vulnerable to\n stack clash style attacks.\n \n @item max-cse-path-length\n \n The maximum number of basic blocks on path that CSE considers.\n-The default is 10.\n \n @item max-cse-insns\n The maximum number of instructions CSE processes before flushing.\n-The default is 1000.\n \n @item ggc-min-expand\n \n@@ -10923,110 +10905,101 @@ to occur at every opportunity.\n The maximum number of instruction reload should look backward for equivalent\n register.  Increasing values mean more aggressive optimization, making the\n compilation time increase with probably slightly better performance.\n-The default value is 100.\n \n @item max-cselib-memory-locations\n The maximum number of memory locations cselib should take into account.\n Increasing values mean more aggressive optimization, making the compilation time\n-increase with probably slightly better performance.  The default value is 500.\n+increase with probably slightly better performance.\n \n @item max-sched-ready-insns\n The maximum number of instructions ready to be issued the scheduler should\n consider at any given time during the first scheduling pass.  Increasing\n values mean more thorough searches, making the compilation time increase\n-with probably little benefit.  The default value is 100.\n+with probably little benefit.\n \n @item max-sched-region-blocks\n The maximum number of blocks in a region to be considered for\n-interblock scheduling.  The default value is 10.\n+interblock scheduling.\n \n @item max-pipeline-region-blocks\n The maximum number of blocks in a region to be considered for\n-pipelining in the selective scheduler.  The default value is 15.\n+pipelining in the selective scheduler.\n \n @item max-sched-region-insns\n The maximum number of insns in a region to be considered for\n-interblock scheduling.  The default value is 100.\n+interblock scheduling.\n \n @item max-pipeline-region-insns\n The maximum number of insns in a region to be considered for\n-pipelining in the selective scheduler.  The default value is 200.\n+pipelining in the selective scheduler.\n \n @item min-spec-prob\n The minimum probability (in percents) of reaching a source block\n-for interblock speculative scheduling.  The default value is 40.\n+for interblock speculative scheduling.\n \n @item max-sched-extend-regions-iters\n The maximum number of iterations through CFG to extend regions.\n-A value of 0 (the default) disables region extensions.\n+A value of 0 disables region extensions.\n \n @item max-sched-insn-conflict-delay\n The maximum conflict delay for an insn to be considered for speculative motion.\n-The default value is 3.\n \n @item sched-spec-prob-cutoff\n The minimal probability of speculation success (in percents), so that\n speculative insns are scheduled.\n-The default value is 40.\n \n @item sched-state-edge-prob-cutoff\n The minimum probability an edge must have for the scheduler to save its\n state across it.\n-The default value is 10.\n \n @item sched-mem-true-dep-cost\n Minimal distance (in CPU cycles) between store and load targeting same\n-memory locations.  The default value is 1.\n+memory locations.\n \n @item selsched-max-lookahead\n The maximum size of the lookahead window of selective scheduling.  It is a\n depth of search for available instructions.\n-The default value is 50.\n \n @item selsched-max-sched-times\n The maximum number of times that an instruction is scheduled during\n selective scheduling.  This is the limit on the number of iterations\n-through which the instruction may be pipelined.  The default value is 2.\n+through which the instruction may be pipelined.\n \n @item selsched-insns-to-rename\n The maximum number of best instructions in the ready list that are considered\n-for renaming in the selective scheduler.  The default value is 2.\n+for renaming in the selective scheduler.\n \n @item sms-min-sc\n The minimum value of stage count that swing modulo scheduler\n-generates.  The default value is 2.\n+generates.\n \n @item max-last-value-rtl\n The maximum size measured as number of RTLs that can be recorded in an expression\n-in combiner for a pseudo register as last known value of that register.  The default\n-is 10000.\n+in combiner for a pseudo register as last known value of that register.\n \n @item max-combine-insns\n The maximum number of instructions the RTL combiner tries to combine.\n-The default value is 2 at @option{-Og} and 4 otherwise.\n \n @item integer-share-limit\n Small integer constants can use a shared data structure, reducing the\n compiler's memory usage and increasing its speed.  This sets the maximum\n-value of a shared integer constant.  The default value is 256.\n+value of a shared integer constant.\n \n @item ssp-buffer-size\n The minimum size of buffers (i.e.@: arrays) that receive stack smashing\n protection when @option{-fstack-protection} is used.\n \n @item min-size-for-stack-sharing\n The minimum size of variables taking part in stack slot sharing when not\n-optimizing. The default value is 32.\n+optimizing.\n \n @item max-jump-thread-duplication-stmts\n Maximum number of statements allowed in a block that needs to be\n duplicated when threading jumps.\n \n @item max-fields-for-field-sensitive\n Maximum number of fields in a structure treated in\n-a field sensitive manner during pointer analysis.  The default is zero\n-for @option{-O0} and @option{-O1},\n-and 100 for @option{-Os}, @option{-O2}, and @option{-O3}.\n+a field sensitive manner during pointer analysis.\n \n @item prefetch-latency\n Estimate on average number of instructions that are executed before\n@@ -11052,7 +11025,7 @@ for strides that are non-constant.  In some cases this may be\n beneficial, though the fact the stride is non-constant may make it\n hard to predict when there is clear benefit to issuing these hints.\n \n-Set to 1, the default, if the prefetch hints should be issued for non-constant\n+Set to 1 if the prefetch hints should be issued for non-constant\n strides.  Set to 0 if prefetch hints should be issued only for strides that\n are known to be constant and below @option{prefetch-minimum-stride}.\n \n@@ -11066,7 +11039,7 @@ the software prefetchers.  If the hardware prefetchers have a maximum\n stride they can handle, it should be used here to improve the use of\n software prefetchers.\n \n-A value of -1, the default, means we don't have a threshold and therefore\n+A value of -1 means we don't have a threshold and therefore\n prefetch hints can be issued for any constant stride.\n \n This setting is only useful for strides that are known and constant.\n@@ -11086,8 +11059,8 @@ The minimum ratio between the number of instructions and the\n number of memory references to enable prefetching in a loop.\n \n @item use-canonical-types\n-Whether the compiler should use the ``canonical'' type system.  By\n-default, this should always be 1, which uses a more efficient internal\n+Whether the compiler should use the ``canonical'' type system.\n+Should always be 1, which uses a more efficient internal\n mechanism for comparing types in C++ and Objective-C++.  However, if\n bugs in the canonical type system are causing compilation failures,\n set this value to 0 to disable canonical types.\n@@ -11108,26 +11081,23 @@ which prevents the runaway behavior.  Setting a value of 0 for\n this parameter allows an unlimited set length.\n \n @item rpo-vn-max-loop-depth\n-Maximum loop depth that is value-numbered optimistically.  The default\n-maximum loop depth is three.  When the limit hits the innermost\n+Maximum loop depth that is value-numbered optimistically.\n+When the limit hits the innermost\n @var{rpo-vn-max-loop-depth} loops and the outermost loop in the\n loop nest are value-numbered optimistically and the remaining ones not.\n-The default maximum loop depth is seven.\n \n @item sccvn-max-alias-queries-per-access\n Maximum number of alias-oracle queries we perform when looking for\n redundancies for loads and stores.  If this limit is hit the search\n is aborted and the load or store is not considered redundant.  The\n number of queries is algorithmically limited to the number of\n stores on all paths from the load to the function entry.\n-The default maximum number of queries is 1000.\n \n @item ira-max-loops-num\n IRA uses regional register allocation by default.  If a function\n contains more loops than the number given by this parameter, only at most\n the given number of the most frequently-executed loops form regions\n-for regional register allocation.  The default value of the\n-parameter is 100.\n+for regional register allocation.\n \n @item ira-max-conflict-table-size \n Although IRA uses a sophisticated algorithm to compress the conflict\n@@ -11136,37 +11106,33 @@ huge functions.  If the conflict table for a function could be more\n than the size in MB given by this parameter, the register allocator\n instead uses a faster, simpler, and lower-quality\n algorithm that does not require building a pseudo-register conflict table.  \n-The default value of the parameter is 2000.\n \n @item ira-loop-reserved-regs\n IRA can be used to evaluate more accurate register pressure in loops\n for decisions to move loop invariants (see @option{-O3}).  The number\n of available registers reserved for some other purposes is given\n-by this parameter.  The default value of the parameter is 2, which is\n-the minimal number of registers needed by typical instructions.\n-This value is the best found from numerous experiments.\n+by this parameter.  Default of the parameter\n+is the best found from numerous experiments.\n \n @item lra-inheritance-ebb-probability-cutoff\n LRA tries to reuse values reloaded in registers in subsequent insns.\n This optimization is called inheritance.  EBB is used as a region to\n do this optimization.  The parameter defines a minimal fall-through\n edge probability in percentage used to add BB to inheritance EBB in\n-LRA.  The default value of the parameter is 40.  The value was chosen\n+LRA.  The default value was chosen\n from numerous runs of SPEC2000 on x86-64.\n \n @item loop-invariant-max-bbs-in-loop\n Loop invariant motion can be very expensive, both in compilation time and\n in amount of needed compile-time memory, with very large loops.  Loops\n with more basic blocks than this parameter won't have loop invariant\n-motion optimization performed on them.  The default value of the\n-parameter is 1000 for @option{-O1} and 10000 for @option{-O2} and above.\n+motion optimization performed on them.\n \n @item loop-max-datarefs-for-datadeps\n Building data dependencies is expensive for very large loops.  This\n parameter limits the number of data references in loops that are\n considered for data dependence analysis.  These large loops are no\n handled by the optimizations using loop data dependencies.\n-The default value is 1000.\n \n @item max-vartrack-size\n Sets a maximum number of hash table slots to use during variable\n@@ -11184,14 +11150,14 @@ compilation time for more complete debug information.  If this is set too\n low, value expressions that are available and could be represented in\n debug information may end up not being used; setting this higher may\n enable the compiler to find more complex debug expressions, but compile\n-time and memory use may grow.  The default is 12.\n+time and memory use may grow.\n \n @item max-debug-marker-count\n Sets a threshold on the number of debug markers (e.g. begin stmt\n markers) to avoid complexity explosion at inlining or expanding to RTL.\n If a function has more such gimple stmts than the set limit, such stmts\n will be dropped from the inlined copy of a function, and from its RTL\n-expansion.  The default is 100000.\n+expansion.\n \n @item min-nondebug-insn-uid\n Use uids starting at this parameter for nondebug insns.  The range below\n@@ -11224,8 +11190,8 @@ sequence pairs.  This option only applies when using\n \n @item graphite-max-nb-scop-params\n To avoid exponential effects in the Graphite loop transforms, the\n-number of parameters in a Static Control Part (SCoP) is bounded.  The\n-default value is 10 parameters, a value of zero can be used to lift\n+number of parameters in a Static Control Part (SCoP) is bounded.\n+A value of zero can be used to lift\n the bound.  A variable whose value is unknown at compilation time and\n defined outside a SCoP is a parameter of the SCoP.\n \n@@ -11234,15 +11200,7 @@ Loop blocking or strip mining transforms, enabled with\n @option{-floop-block} or @option{-floop-strip-mine}, strip mine each\n loop in the loop nest by a given number of iterations.  The strip\n length can be changed using the @option{loop-block-tile-size}\n-parameter.  The default value is 51 iterations.\n-\n-@item loop-unroll-jam-size\n-Specify the unroll factor for the @option{-floop-unroll-and-jam} option.  The \n-default value is 4.\n-\n-@item loop-unroll-jam-depth\n-Specify the dimension to be unrolled (counting from the most inner loop)\n-for the  @option{-floop-unroll-and-jam}.  The default value is 2.\n+parameter.\n \n @item ipa-cp-value-list-size\n IPA-CP attempts to track all possible values and types passed to a function's\n@@ -11263,7 +11221,6 @@ are evaluated for cloning.\n Percentage penalty functions containing a single call to another\n function will receive when they are evaluated for cloning.\n \n-\n @item ipa-max-agg-items\n IPA-CP is also capable to propagate a number of scalar values passed\n in an aggregate. @option{ipa-max-agg-items} controls the maximum\n@@ -11291,7 +11248,6 @@ consider all memory clobbered after examining\n @item lto-partitions\n Specify desired number of partitions produced during WHOPR compilation.\n The number of partitions should exceed the number of CPUs used for compilation.\n-The default value is 32.\n \n @item lto-min-partition\n Size of minimal partition for WHOPR (in estimated instructions).\n@@ -11305,29 +11261,28 @@ Meant to be used only with balanced partitioning.\n \n @item cxx-max-namespaces-for-diagnostic-help\n The maximum number of namespaces to consult for suggestions when C++\n-name lookup fails for an identifier.  The default is 1000.\n+name lookup fails for an identifier.\n \n @item sink-frequency-threshold\n The maximum relative execution frequency (in percents) of the target block\n relative to a statement's original block to allow statement sinking of a\n statement.  Larger numbers result in more aggressive statement sinking.\n-The default value is 75.  A small positive adjustment is applied for\n+A small positive adjustment is applied for\n statements with memory operands as those are even more profitable so sink.\n \n @item max-stores-to-sink\n The maximum number of conditional store pairs that can be sunk.  Set to 0\n if either vectorization (@option{-ftree-vectorize}) or if-conversion\n-(@option{-ftree-loop-if-convert}) is disabled.  The default is 2.\n+(@option{-ftree-loop-if-convert}) is disabled.\n \n @item allow-store-data-races\n Allow optimizers to introduce new data races on stores.\n-Set to 1 to allow, otherwise to 0.  This option is enabled by default\n-at optimization level @option{-Ofast}.\n+Set to 1 to allow, otherwise to 0.\n \n @item case-values-threshold\n The smallest number of different values for which it is best to use a\n jump-table instead of a tree of conditional branches.  If the value is\n-0, use the default for the machine.  The default is 0.\n+0, use the default for the machine.\n \n @item tree-reassoc-width\n Set the maximum number of instructions executed in parallel in\n@@ -11397,32 +11352,31 @@ E.g. to disable inline code use\n @item use-after-scope-direct-emission-threshold\n If the size of a local variable in bytes is smaller or equal to this\n number, directly poison (or unpoison) shadow memory instead of using\n-run-time callbacks.  The default value is 256.\n+run-time callbacks.\n \n @item max-fsm-thread-path-insns\n Maximum number of instructions to copy when duplicating blocks on a\n-finite state automaton jump thread path.  The default is 100.\n+finite state automaton jump thread path.\n \n @item max-fsm-thread-length\n Maximum number of basic blocks on a finite state automaton jump thread\n-path.  The default is 10.\n+path.\n \n @item max-fsm-thread-paths\n Maximum number of new jump thread paths to create for a finite state\n-automaton.  The default is 50.\n+automaton.\n \n @item parloops-chunk-size\n-Chunk size of omp schedule for loops parallelized by parloops.  The default\n-is 0.\n+Chunk size of omp schedule for loops parallelized by parloops.\n \n @item parloops-schedule\n Schedule type of omp schedule for loops parallelized by parloops (static,\n-dynamic, guided, auto, runtime).  The default is static.\n+dynamic, guided, auto, runtime).\n \n @item parloops-min-per-thread\n The minimum number of iterations per thread of an innermost parallelized\n-loop for which the parallelized variant is prefered over the single threaded\n-one.  The default is 100.  Note that for a parallelized loop nest the\n+loop for which the parallelized variant is preferred over the single threaded\n+one.  Note that for a parallelized loop nest the\n minimum number of iterations of the outermost loop per thread is two.\n \n @item max-ssa-name-query-depth\n@@ -11443,7 +11397,7 @@ we may be able to devirtualize speculatively.\n \n @item max-vrp-switch-assertions\n The maximum number of assertions to add along the default edge of a switch\n-statement during VRP.  The default is 10.\n+statement during VRP.\n \n @item unroll-jam-min-percent\n The minimum percentage of memory references that must be optimized\n@@ -11452,6 +11406,143 @@ away for the unroll-and-jam transformation to be considered profitable.\n @item unroll-jam-max-unroll\n The maximum number of times the outer loop should be unrolled by\n the unroll-and-jam transformation.\n+\n+@item max-rtl-if-conversion-unpredictable-cost\n+Maximum permissible cost for the sequence that would be generated\n+by the RTL if-conversion pass for a branch that is considered unpredictable.\n+\n+@item max-variable-expansions-in-unroller\n+If @option{-fvariable-expansion-in-unroller} is used, the maximum number\n+of times that an individual variable will be expanded during loop unrolling.\n+\n+@item tracer-min-branch-probability-feedback\n+Stop forward growth if the probability of best edge is less than\n+this threshold (in percent). Used when profile feedback is available.\n+\n+@item partial-inlining-entry-probability\n+Maximum probability of the entry BB of split region\n+(in percent relative to entry BB of the function)\n+to make partial inlining happen.\n+\n+@item max-tracked-strlens\n+Maximum number of strings for which strlen optimization pass will\n+track string lengths.\n+\n+@item gcse-after-reload-partial-fraction\n+The threshold ratio for performing partial redundancy\n+elimination after reload.\n+\n+@item gcse-after-reload-critical-fraction\n+The threshold ratio of critical edges execution count that\n+permit performing redundancy elimination after reload.\n+\n+@item max-loop-header-insns\n+The maximum number of insns in loop header duplicated\n+by the copy loop headers pass.\n+\n+@item vect-epilogues-nomask\n+Enable loop epilogue vectorization using smaller vector size.\n+\n+@item slp-max-insns-in-bb\n+Maximum number of instructions in basic block to be\n+considered for SLP vectorization.\n+\n+@item avoid-fma-max-bits\n+Maximum number of bits for which we avoid creating FMAs.\n+\n+@item sms-loop-average-count-threshold\n+A threshold on the average loop count considered by the swing modulo scheduler.\n+\n+@item sms-dfa-history\n+The number of cycles the swing modulo scheduler considers when checking\n+conflicts using DFA.\n+\n+@item hot-bb-count-fraction\n+Select fraction of the maximal count of repetitions of basic block\n+in program given basic block needs\n+to have to be considered hot (used in non-LTO mode)\n+\n+@item max-inline-insns-recursive-auto\n+The maximum number of instructions non-inline function\n+can grow to via recursive inlining.\n+\n+@item graphite-allow-codegen-errors\n+Whether codegen errors should be ICEs when @option{-fchecking}.\n+\n+@item sms-max-ii-factor\n+A factor for tuning the upper bound that swing modulo scheduler\n+uses for scheduling a loop.\n+\n+@item lra-max-considered-reload-pseudos\n+The max number of reload pseudos which are considered during\n+spilling a non-reload pseudo.\n+\n+@item max-pow-sqrt-depth\n+Maximum depth of sqrt chains to use when synthesizing exponentiation\n+by a real constant.\n+\n+@item max-dse-active-local-stores\n+Maximum number of active local stores in RTL dead store elimination.\n+\n+@item asan-instrument-allocas\n+Enable asan allocas/VLAs protection.\n+\n+@item max-iterations-computation-cost\n+Bound on the cost of an expression to compute the number of iterations.\n+\n+@item max-isl-operations\n+Maximum number of isl operations, 0 means unlimited.\n+\n+@item graphite-max-arrays-per-scop\n+Maximum number of arrays per scop.\n+\n+@item max-vartrack-reverse-op-size\n+Max. size of loc list for which reverse ops should be added.\n+\n+@item unlikely-bb-count-fraction\n+The minimum fraction of profile runs a given basic block execution count\n+must be not to be considered unlikely.\n+\n+@item tracer-dynamic-coverage-feedback\n+The percentage of function, weighted by execution frequency,\n+that must be covered by trace formation.\n+Used when profile feedback is available.\n+\n+@item max-inline-recursive-depth-auto\n+The maximum depth of recursive inlining for non-inline functions.\n+\n+@item fsm-scale-path-stmts\n+Scale factor to apply to the number of statements in a threading path\n+when comparing to the number of (scaled) blocks.\n+\n+@item fsm-maximum-phi-arguments\n+Maximum number of arguments a PHI may have before the FSM threader\n+will not try to thread through its block.\n+\n+@item uninit-control-dep-attempts\n+Maximum number of nested calls to search for control dependencies\n+during uninitialized variable analysis.\n+\n+@item indir-call-topn-profile\n+Track top N target addresses in indirect-call profile.\n+\n+@item max-once-peeled-insns\n+The maximum number of insns of a peeled loop that rolls only once.\n+\n+@item sra-max-scalarization-size-Osize\n+Maximum size, in storage units, of an aggregate\n+which should be considered for scalarization when compiling for size.\n+\n+@item fsm-scale-path-blocks\n+Scale factor to apply to the number of blocks in a threading path\n+when comparing to the number of (scaled) statements.\n+\n+@item sched-autopref-queue-depth\n+Hardware autoprefetcher scheduler model control flag.\n+Number of lookahead cycles the model looks into; at '\n+' only enable instruction sorting heuristic.\n+\n+\n @end table\n @end table\n "}]}