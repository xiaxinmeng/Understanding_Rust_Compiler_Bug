{"sha": "e358acde2cc2c540b85ab7c5df397d653032b70d", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTM1OGFjZGUyY2MyYzU0MGI4NWFiN2M1ZGYzOTdkNjUzMDMyYjcwZA==", "commit": {"author": {"name": "Richard Henderson", "email": "rth@redhat.com", "date": "2005-01-06T06:22:32Z"}, "committer": {"name": "Richard Henderson", "email": "rth@gcc.gnu.org", "date": "2005-01-06T06:22:32Z"}, "message": "re PR rtl-optimization/11327 (Non-optimal code when using MMX/SSE builtins)\n\n        PR target/11327\n        * config/i386/i386.c (BUILTIN_DESC_SWAP_OPERANDS): New.\n        (bdesc_2arg): Use it.\n        (ix86_expand_binop_builtin): Force operands into registers\n        when optimizing.\n        (ix86_expand_unop_builtin, ix86_expand_unop1_builtin,\n        ix86_expand_sse_compare, ix86_expand_sse_comi,\n        ix86_expand_builtin): Likewise.\n\nFrom-SVN: r92988", "tree": {"sha": "c9384bc8107956e150e097f383e98ca029b78464", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/c9384bc8107956e150e097f383e98ca029b78464"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e358acde2cc2c540b85ab7c5df397d653032b70d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e358acde2cc2c540b85ab7c5df397d653032b70d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e358acde2cc2c540b85ab7c5df397d653032b70d", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e358acde2cc2c540b85ab7c5df397d653032b70d/comments", "author": null, "committer": null, "parents": [{"sha": "051d8245886f5f133fad42d38b9d4ce12afd1394", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/051d8245886f5f133fad42d38b9d4ce12afd1394", "html_url": "https://github.com/Rust-GCC/gccrs/commit/051d8245886f5f133fad42d38b9d4ce12afd1394"}], "stats": {"total": 98, "additions": 66, "deletions": 32}, "files": [{"sha": "43e651c84bf480b9041509026a7ba10fdb7bd975", "filename": "gcc/ChangeLog", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e358acde2cc2c540b85ab7c5df397d653032b70d/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e358acde2cc2c540b85ab7c5df397d653032b70d/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=e358acde2cc2c540b85ab7c5df397d653032b70d", "patch": "@@ -1,3 +1,14 @@\n+2005-01-05  Richard Henderson  <rth@redhat.com>\n+\n+\tPR target/11327\n+\t* config/i386/i386.c (BUILTIN_DESC_SWAP_OPERANDS): New.\n+\t(bdesc_2arg): Use it.\n+\t(ix86_expand_binop_builtin): Force operands into registers\n+\twhen optimizing.\n+\t(ix86_expand_unop_builtin, ix86_expand_unop1_builtin,\n+\tix86_expand_sse_compare, ix86_expand_sse_comi, \n+\tix86_expand_builtin): Likewise.\n+\n 2005-01-05  Richard Henderson  <rth@redhat.com>\n \n \t* config/ia64/ia64.c (rtx_needs_barrier): Handle CONST_VECTOR"}, {"sha": "0031959278597403bb99f1fb86c027a0d134ee36", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 55, "deletions": 32, "changes": 87, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e358acde2cc2c540b85ab7c5df397d653032b70d/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e358acde2cc2c540b85ab7c5df397d653032b70d/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=e358acde2cc2c540b85ab7c5df397d653032b70d", "patch": "@@ -12077,6 +12077,12 @@ do {\t\t\t\t\t\t\t\t\t\\\n \t\t\t\t NULL, NULL_TREE);\t\t\t\\\n } while (0)\n \n+/* Bits for builtin_description.flag.  */\n+\n+/* Set when we don't support the comparison natively, and should\n+   swap_comparison in order to support it.  */\n+#define BUILTIN_DESC_SWAP_OPERANDS\t1\n+\n struct builtin_description\n {\n   const unsigned int mask;\n@@ -12130,14 +12136,18 @@ static const struct builtin_description bdesc_2arg[] =\n   { MASK_SSE, CODE_FOR_maskcmpv4sf3, \"__builtin_ia32_cmpeqps\", IX86_BUILTIN_CMPEQPS, EQ, 0 },\n   { MASK_SSE, CODE_FOR_maskcmpv4sf3, \"__builtin_ia32_cmpltps\", IX86_BUILTIN_CMPLTPS, LT, 0 },\n   { MASK_SSE, CODE_FOR_maskcmpv4sf3, \"__builtin_ia32_cmpleps\", IX86_BUILTIN_CMPLEPS, LE, 0 },\n-  { MASK_SSE, CODE_FOR_maskcmpv4sf3, \"__builtin_ia32_cmpgtps\", IX86_BUILTIN_CMPGTPS, LT, 1 },\n-  { MASK_SSE, CODE_FOR_maskcmpv4sf3, \"__builtin_ia32_cmpgeps\", IX86_BUILTIN_CMPGEPS, LE, 1 },\n+  { MASK_SSE, CODE_FOR_maskcmpv4sf3, \"__builtin_ia32_cmpgtps\", IX86_BUILTIN_CMPGTPS, LT,\n+    BUILTIN_DESC_SWAP_OPERANDS },\n+  { MASK_SSE, CODE_FOR_maskcmpv4sf3, \"__builtin_ia32_cmpgeps\", IX86_BUILTIN_CMPGEPS, LE,\n+    BUILTIN_DESC_SWAP_OPERANDS },\n   { MASK_SSE, CODE_FOR_maskcmpv4sf3, \"__builtin_ia32_cmpunordps\", IX86_BUILTIN_CMPUNORDPS, UNORDERED, 0 },\n   { MASK_SSE, CODE_FOR_maskncmpv4sf3, \"__builtin_ia32_cmpneqps\", IX86_BUILTIN_CMPNEQPS, EQ, 0 },\n   { MASK_SSE, CODE_FOR_maskncmpv4sf3, \"__builtin_ia32_cmpnltps\", IX86_BUILTIN_CMPNLTPS, LT, 0 },\n   { MASK_SSE, CODE_FOR_maskncmpv4sf3, \"__builtin_ia32_cmpnleps\", IX86_BUILTIN_CMPNLEPS, LE, 0 },\n-  { MASK_SSE, CODE_FOR_maskncmpv4sf3, \"__builtin_ia32_cmpngtps\", IX86_BUILTIN_CMPNGTPS, LT, 1 },\n-  { MASK_SSE, CODE_FOR_maskncmpv4sf3, \"__builtin_ia32_cmpngeps\", IX86_BUILTIN_CMPNGEPS, LE, 1 },\n+  { MASK_SSE, CODE_FOR_maskncmpv4sf3, \"__builtin_ia32_cmpngtps\", IX86_BUILTIN_CMPNGTPS, LT,\n+    BUILTIN_DESC_SWAP_OPERANDS },\n+  { MASK_SSE, CODE_FOR_maskncmpv4sf3, \"__builtin_ia32_cmpngeps\", IX86_BUILTIN_CMPNGEPS, LE,\n+    BUILTIN_DESC_SWAP_OPERANDS },\n   { MASK_SSE, CODE_FOR_maskncmpv4sf3, \"__builtin_ia32_cmpordps\", IX86_BUILTIN_CMPORDPS, UNORDERED, 0 },\n   { MASK_SSE, CODE_FOR_vmmaskcmpv4sf3, \"__builtin_ia32_cmpeqss\", IX86_BUILTIN_CMPEQSS, EQ, 0 },\n   { MASK_SSE, CODE_FOR_vmmaskcmpv4sf3, \"__builtin_ia32_cmpltss\", IX86_BUILTIN_CMPLTSS, LT, 0 },\n@@ -12258,14 +12268,18 @@ static const struct builtin_description bdesc_2arg[] =\n   { MASK_SSE2, CODE_FOR_maskcmpv2df3, \"__builtin_ia32_cmpeqpd\", IX86_BUILTIN_CMPEQPD, EQ, 0 },\n   { MASK_SSE2, CODE_FOR_maskcmpv2df3, \"__builtin_ia32_cmpltpd\", IX86_BUILTIN_CMPLTPD, LT, 0 },\n   { MASK_SSE2, CODE_FOR_maskcmpv2df3, \"__builtin_ia32_cmplepd\", IX86_BUILTIN_CMPLEPD, LE, 0 },\n-  { MASK_SSE2, CODE_FOR_maskcmpv2df3, \"__builtin_ia32_cmpgtpd\", IX86_BUILTIN_CMPGTPD, LT, 1 },\n-  { MASK_SSE2, CODE_FOR_maskcmpv2df3, \"__builtin_ia32_cmpgepd\", IX86_BUILTIN_CMPGEPD, LE, 1 },\n+  { MASK_SSE2, CODE_FOR_maskcmpv2df3, \"__builtin_ia32_cmpgtpd\", IX86_BUILTIN_CMPGTPD, LT,\n+    BUILTIN_DESC_SWAP_OPERANDS },\n+  { MASK_SSE2, CODE_FOR_maskcmpv2df3, \"__builtin_ia32_cmpgepd\", IX86_BUILTIN_CMPGEPD, LE,\n+    BUILTIN_DESC_SWAP_OPERANDS },\n   { MASK_SSE2, CODE_FOR_maskcmpv2df3, \"__builtin_ia32_cmpunordpd\", IX86_BUILTIN_CMPUNORDPD, UNORDERED, 0 },\n   { MASK_SSE2, CODE_FOR_maskncmpv2df3, \"__builtin_ia32_cmpneqpd\", IX86_BUILTIN_CMPNEQPD, EQ, 0 },\n   { MASK_SSE2, CODE_FOR_maskncmpv2df3, \"__builtin_ia32_cmpnltpd\", IX86_BUILTIN_CMPNLTPD, LT, 0 },\n   { MASK_SSE2, CODE_FOR_maskncmpv2df3, \"__builtin_ia32_cmpnlepd\", IX86_BUILTIN_CMPNLEPD, LE, 0 },\n-  { MASK_SSE2, CODE_FOR_maskncmpv2df3, \"__builtin_ia32_cmpngtpd\", IX86_BUILTIN_CMPNGTPD, LT, 1 },\n-  { MASK_SSE2, CODE_FOR_maskncmpv2df3, \"__builtin_ia32_cmpngepd\", IX86_BUILTIN_CMPNGEPD, LE, 1 },\n+  { MASK_SSE2, CODE_FOR_maskncmpv2df3, \"__builtin_ia32_cmpngtpd\", IX86_BUILTIN_CMPNGTPD, LT,\n+    BUILTIN_DESC_SWAP_OPERANDS },\n+  { MASK_SSE2, CODE_FOR_maskncmpv2df3, \"__builtin_ia32_cmpngepd\", IX86_BUILTIN_CMPNGEPD, LE,\n+    BUILTIN_DESC_SWAP_OPERANDS },\n   { MASK_SSE2, CODE_FOR_maskncmpv2df3, \"__builtin_ia32_cmpordpd\", IX86_BUILTIN_CMPORDPD, UNORDERED, 0 },\n   { MASK_SSE2, CODE_FOR_vmmaskcmpv2df3, \"__builtin_ia32_cmpeqsd\", IX86_BUILTIN_CMPEQSD, EQ, 0 },\n   { MASK_SSE2, CODE_FOR_vmmaskcmpv2df3, \"__builtin_ia32_cmpltsd\", IX86_BUILTIN_CMPLTSD, LT, 0 },\n@@ -13137,7 +13151,7 @@ ix86_expand_binop_builtin (enum insn_code icode, tree arglist, rtx target)\n   if (VECTOR_MODE_P (mode1))\n     op1 = safe_vector_operand (op1, mode1);\n \n-  if (! target\n+  if (optimize || !target\n       || GET_MODE (target) != tmode\n       || ! (*insn_data[icode].operand[0].predicate) (target, tmode))\n     target = gen_reg_rtx (tmode);\n@@ -13155,9 +13169,11 @@ ix86_expand_binop_builtin (enum insn_code icode, tree arglist, rtx target)\n       || (GET_MODE (op1) != mode1 && GET_MODE (op1) != VOIDmode))\n     abort ();\n \n-  if (! (*insn_data[icode].operand[1].predicate) (op0, mode0))\n+  if ((optimize && !register_operand (op0, mode0))\n+      || !(*insn_data[icode].operand[1].predicate) (op0, mode0))\n     op0 = copy_to_mode_reg (mode0, op0);\n-  if (! (*insn_data[icode].operand[2].predicate) (op1, mode1))\n+  if ((optimize && !register_operand (op1, mode1))\n+      || !(*insn_data[icode].operand[2].predicate) (op1, mode1))\n     op1 = copy_to_mode_reg (mode1, op1);\n \n   /* In the commutative cases, both op0 and op1 are nonimmediate_operand,\n@@ -13210,7 +13226,7 @@ ix86_expand_unop_builtin (enum insn_code icode, tree arglist,\n   enum machine_mode tmode = insn_data[icode].operand[0].mode;\n   enum machine_mode mode0 = insn_data[icode].operand[1].mode;\n \n-  if (! target\n+  if (optimize || !target\n       || GET_MODE (target) != tmode\n       || ! (*insn_data[icode].operand[0].predicate) (target, tmode))\n     target = gen_reg_rtx (tmode);\n@@ -13221,7 +13237,8 @@ ix86_expand_unop_builtin (enum insn_code icode, tree arglist,\n       if (VECTOR_MODE_P (mode0))\n \top0 = safe_vector_operand (op0, mode0);\n \n-      if (! (*insn_data[icode].operand[1].predicate) (op0, mode0))\n+      if ((optimize && !register_operand (op0, mode0))\n+\t  || ! (*insn_data[icode].operand[1].predicate) (op0, mode0))\n \top0 = copy_to_mode_reg (mode0, op0);\n     }\n \n@@ -13244,15 +13261,16 @@ ix86_expand_unop1_builtin (enum insn_code icode, tree arglist, rtx target)\n   enum machine_mode tmode = insn_data[icode].operand[0].mode;\n   enum machine_mode mode0 = insn_data[icode].operand[1].mode;\n \n-  if (! target\n+  if (optimize || !target\n       || GET_MODE (target) != tmode\n       || ! (*insn_data[icode].operand[0].predicate) (target, tmode))\n     target = gen_reg_rtx (tmode);\n \n   if (VECTOR_MODE_P (mode0))\n     op0 = safe_vector_operand (op0, mode0);\n \n-  if (! (*insn_data[icode].operand[1].predicate) (op0, mode0))\n+  if ((optimize && !register_operand (op0, mode0))\n+      || ! (*insn_data[icode].operand[1].predicate) (op0, mode0))\n     op0 = copy_to_mode_reg (mode0, op0);\n \n   op1 = op0;\n@@ -13290,22 +13308,24 @@ ix86_expand_sse_compare (const struct builtin_description *d, tree arglist,\n \n   /* Swap operands if we have a comparison that isn't available in\n      hardware.  */\n-  if (d->flag)\n+  if (d->flag & BUILTIN_DESC_SWAP_OPERANDS)\n     {\n       rtx tmp = gen_reg_rtx (mode1);\n       emit_move_insn (tmp, op1);\n       op1 = op0;\n       op0 = tmp;\n     }\n \n-  if (! target\n+  if (optimize || !target\n       || GET_MODE (target) != tmode\n       || ! (*insn_data[d->icode].operand[0].predicate) (target, tmode))\n     target = gen_reg_rtx (tmode);\n \n-  if (! (*insn_data[d->icode].operand[1].predicate) (op0, mode0))\n+  if ((optimize && !register_operand (op0, mode0))\n+      || ! (*insn_data[d->icode].operand[1].predicate) (op0, mode0))\n     op0 = copy_to_mode_reg (mode0, op0);\n-  if (! (*insn_data[d->icode].operand[2].predicate) (op1, mode1))\n+  if ((optimize && !register_operand (op1, mode1))\n+      || ! (*insn_data[d->icode].operand[2].predicate) (op1, mode1))\n     op1 = copy_to_mode_reg (mode1, op1);\n \n   op2 = gen_rtx_fmt_ee (comparison, mode0, op0, op1);\n@@ -13339,7 +13359,7 @@ ix86_expand_sse_comi (const struct builtin_description *d, tree arglist,\n \n   /* Swap operands if we have a comparison that isn't available in\n      hardware.  */\n-  if (d->flag)\n+  if (d->flag & BUILTIN_DESC_SWAP_OPERANDS)\n     {\n       rtx tmp = op1;\n       op1 = op0;\n@@ -13350,9 +13370,11 @@ ix86_expand_sse_comi (const struct builtin_description *d, tree arglist,\n   emit_move_insn (target, const0_rtx);\n   target = gen_rtx_SUBREG (QImode, target, 0);\n \n-  if (! (*insn_data[d->icode].operand[0].predicate) (op0, mode0))\n+  if ((optimize && !register_operand (op0, mode0))\n+      || !(*insn_data[d->icode].operand[0].predicate) (op0, mode0))\n     op0 = copy_to_mode_reg (mode0, op0);\n-  if (! (*insn_data[d->icode].operand[1].predicate) (op1, mode1))\n+  if ((optimize && !register_operand (op1, mode1))\n+      || !(*insn_data[d->icode].operand[1].predicate) (op1, mode1))\n     op1 = copy_to_mode_reg (mode1, op1);\n \n   op2 = gen_rtx_fmt_ee (comparison, mode0, op0, op1);\n@@ -13449,7 +13471,8 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n \n       if (! (*insn_data[icode].operand[1].predicate) (op0, mode0))\n \top0 = copy_to_mode_reg (mode0, op0);\n-      if (! (*insn_data[icode].operand[2].predicate) (op1, mode1))\n+      if ((optimize && !register_operand (op1, mode1))\n+\t  || ! (*insn_data[icode].operand[2].predicate) (op1, mode1))\n \top1 = copy_to_mode_reg (mode1, op1);\n       if (! (*insn_data[icode].operand[3].predicate) (op2, mode2))\n \t{\n@@ -13470,7 +13493,8 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n     case IX86_BUILTIN_MASKMOVQ:\n     case IX86_BUILTIN_MASKMOVDQU:\n       icode = (fcode == IX86_BUILTIN_MASKMOVQ\n-\t       ? (TARGET_64BIT ? CODE_FOR_mmx_maskmovq_rex : CODE_FOR_mmx_maskmovq)\n+\t       ? (TARGET_64BIT ? CODE_FOR_mmx_maskmovq_rex\n+\t\t  : CODE_FOR_mmx_maskmovq)\n \t       : (TARGET_64BIT ? CODE_FOR_sse2_maskmovdqu_rex64\n \t\t  : CODE_FOR_sse2_maskmovdqu));\n       /* Note the arg order is different from the operand order.  */\n@@ -13537,12 +13561,11 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n       mode0 = insn_data[icode].operand[1].mode;\n       mode1 = insn_data[icode].operand[2].mode;\n \n-      if (! (*insn_data[icode].operand[1].predicate) (op0, mode0))\n-\top0 = copy_to_mode_reg (mode0, op0);\n+      op0 = force_reg (mode0, op0);\n       op1 = gen_rtx_MEM (mode1, copy_to_mode_reg (Pmode, op1));\n-      if (target == 0\n+      if (optimize || target == 0\n \t  || GET_MODE (target) != tmode\n-\t  || ! (*insn_data[icode].operand[0].predicate) (target, tmode))\n+\t  || !register_operand (target, tmode))\n \ttarget = gen_reg_rtx (tmode);\n       pat = GEN_FCN (icode) (target, op0, op1);\n       if (! pat)\n@@ -13566,8 +13589,7 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n       mode1 = insn_data[icode].operand[1].mode;\n \n       op0 = gen_rtx_MEM (mode0, copy_to_mode_reg (Pmode, op0));\n-      if (! (*insn_data[icode].operand[1].predicate) (op1, mode1))\n-\top1 = copy_to_mode_reg (mode1, op1);\n+      op1 = force_reg (mode1, op1);\n \n       pat = GEN_FCN (icode) (op0, op1);\n       if (! pat)\n@@ -13610,15 +13632,16 @@ ix86_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n \n       if (! (*insn_data[icode].operand[1].predicate) (op0, mode0))\n \top0 = copy_to_mode_reg (mode0, op0);\n-      if (! (*insn_data[icode].operand[2].predicate) (op1, mode1))\n+      if ((optimize && !register_operand (op1, mode1))\n+\t  || !(*insn_data[icode].operand[2].predicate) (op1, mode1))\n \top1 = copy_to_mode_reg (mode1, op1);\n       if (! (*insn_data[icode].operand[3].predicate) (op2, mode2))\n \t{\n \t  /* @@@ better error message */\n \t  error (\"mask must be an immediate\");\n \t  return gen_reg_rtx (tmode);\n \t}\n-      if (target == 0\n+      if (optimize || target == 0\n \t  || GET_MODE (target) != tmode\n \t  || ! (*insn_data[icode].operand[0].predicate) (target, tmode))\n \ttarget = gen_reg_rtx (tmode);"}]}