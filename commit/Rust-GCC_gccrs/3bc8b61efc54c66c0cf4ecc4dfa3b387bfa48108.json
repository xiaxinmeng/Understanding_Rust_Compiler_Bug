{"sha": "3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6M2JjOGI2MWVmYzU0YzY2YzBjZjRlY2M0ZGZhM2IzODdiZmE0ODEwOA==", "commit": {"author": {"name": "David S. Miller", "email": "davem@pierdol.cobaltmicro.com", "date": "1998-08-16T18:50:32Z"}, "committer": {"name": "David S. Miller", "email": "davem@gcc.gnu.org", "date": "1998-08-16T18:50:32Z"}, "message": "sparc.c (ultra_code_from_mask, [...]): New functions to describe UltraSPARC pipeline exactly to Haifa.\n\n\t* config/sparc/sparc.c (ultra_code_from_mask,\n\tultra_cmove_results_ready_p, ultra_fpmode_conflict_exists,\n\tultra_find_type, ultra_schedule_insn, ultra_flush_pipeline,\n\tultrasparc_sched_init, ultrasparc_variable_issue,\n\tultra_rescan_pipeline_state, ultrasparc_sched_reorder): New\n\tfunctions to describe UltraSPARC pipeline exactly to Haifa.\n\t(ultrasparc_adjust_cost): Indicate IMUL type insns have zero cost,\n\tas there is nothing the scheduler can do about it.  Indicate that\n\tREG_DEP_OUTPUT's collide.  Fixup formatting.\n\t* config/sparc/sparc.h (RTX_COSTS): Fixup integer multiply and\n\tdivide costs on Ultra for DImode.\n\t(MD_SCHED_INIT, MD_SCHED_REORDER, MD_SCHED_VARIABLE_ISSUE):\n\tDefine.\n\t* config/sparc/sparc.md (ieu_unnamed function unit): Rename to\n\tieuN and add call_no_delay_slot to type list.\n\t(cti function unit): New unit for branches on UltraSPARC.\n\t(subx/addx insns): Set type to misc.\n\t(sidi zero/sign extension insns on arch64): Set type to shift.\n\t(sign_extendhidi2_insn): Set type to sload.\n\nFrom-SVN: r21767", "tree": {"sha": "8316eb209268ee3d8953ab45b5578a30f7fad3a7", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/8316eb209268ee3d8953ab45b5578a30f7fad3a7"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108", "html_url": "https://github.com/Rust-GCC/gccrs/commit/3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108/comments", "author": null, "committer": null, "parents": [{"sha": "a6c2a102ae9d2c9686c19777d8ede68f1b5a42c6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a6c2a102ae9d2c9686c19777d8ede68f1b5a42c6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a6c2a102ae9d2c9686c19777d8ede68f1b5a42c6"}], "stats": {"total": 978, "additions": 874, "deletions": 104}, "files": [{"sha": "68164b61f07710dc9cc36ef1431adb6b36cddd4e", "filename": "gcc/ChangeLog", "status": "modified", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108", "patch": "@@ -1,3 +1,25 @@\n+Sun Aug 16 17:37:06 1998  David S. Miller  <davem@pierdol.cobaltmicro.com>\n+\n+\t* config/sparc/sparc.c (ultra_code_from_mask,\n+\tultra_cmove_results_ready_p, ultra_fpmode_conflict_exists,\n+\tultra_find_type, ultra_schedule_insn, ultra_flush_pipeline,\n+\tultrasparc_sched_init, ultrasparc_variable_issue,\n+\tultra_rescan_pipeline_state, ultrasparc_sched_reorder): New\n+\tfunctions to describe UltraSPARC pipeline exactly to Haifa.\n+\t(ultrasparc_adjust_cost): Indicate IMUL type insns have zero cost,\n+\tas there is nothing the scheduler can do about it.  Indicate that\n+\tREG_DEP_OUTPUT's collide.  Fixup formatting.\n+\t* config/sparc/sparc.h (RTX_COSTS): Fixup integer multiply and\n+\tdivide costs on Ultra for DImode.\n+\t(MD_SCHED_INIT, MD_SCHED_REORDER, MD_SCHED_VARIABLE_ISSUE):\n+\tDefine.\n+\t* config/sparc/sparc.md (ieu_unnamed function unit): Rename to\n+\tieuN and add call_no_delay_slot to type list.\n+\t(cti function unit): New unit for branches on UltraSPARC.\n+\t(subx/addx insns): Set type to misc.\n+\t(sidi zero/sign extension insns on arch64): Set type to shift.\n+\t(sign_extendhidi2_insn): Set type to sload.\n+\n Sun Aug 16 13:52:00 1998  David Edelsohn  <edelsohn@mhpcc.edu>\n \n \t* rs6000.c (rs6000_stack_info): Use if == 0 for sizes."}, {"sha": "0dbd10c3463f51a531e4f5c22ddbff082aeedb1a", "filename": "gcc/config/sparc/sparc.c", "status": "modified", "additions": 767, "deletions": 68, "changes": 835, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108/gcc%2Fconfig%2Fsparc%2Fsparc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108/gcc%2Fconfig%2Fsparc%2Fsparc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsparc%2Fsparc.c?ref=3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108", "patch": "@@ -6102,8 +6102,8 @@ supersparc_adjust_cost (insn, link, dep_insn, cost)\n \t cycles later.  */\n \n       /* if a load, then the dependence must be on the memory address;\n-\t add an extra 'cycle'.  Note that the cost could be two cycles\n-\t if the reg was written late in an instruction group; we can't tell\n+\t add an extra \"cycle\".  Note that the cost could be two cycles\n+\t if the reg was written late in an instruction group; we ca not tell\n \t here.  */\n       if (insn_type == TYPE_LOAD || insn_type == TYPE_FPLOAD)\n \treturn cost + 3;\n@@ -6115,7 +6115,7 @@ supersparc_adjust_cost (insn, link, dep_insn, cost)\n \t  rtx dep_pat = PATTERN (dep_insn);\n \n \t  if (GET_CODE (pat) != SET || GET_CODE (dep_pat) != SET)\n-\t    return cost;  /* This shouldn't happen!  */\n+\t    return cost;  /* This should not happen!  */\n \n \t  /* The dependency between the two instructions was on the data that\n \t     is being stored.  Assume that this implies that the address of the\n@@ -6147,140 +6147,839 @@ supersparc_adjust_cost (insn, link, dep_insn, cost)\n   return cost;\n }\n \n+/* This describes the state of the UltraSPARC pipeline during\n+   instruction scheduling.  */\n+\n+#define TMASK(__x)\t(1U << ((int)(__x)))\n+#define UMASK(__x)\t(1U << ((int)(__x)))\n+\n+enum ultra_code { NONE=0, /* no insn at all\t\t\t\t*/\n+\t\t  IEU0,   /* shifts and conditional moves\t\t*/\n+\t\t  IEU1,   /* condition code setting insns, calls+jumps\t*/\n+\t\t  IEUN,   /* all other single cycle ieu insns\t\t*/\n+\t\t  LSU,    /* loads and stores\t\t\t\t*/\n+\t\t  CTI,    /* branches\t\t\t\t\t*/\n+\t\t  FPM,    /* FPU pipeline 1, multiplies and divides\t*/\n+\t\t  FPA,    /* FPU pipeline 2, all other operations\t*/\n+\t\t  SINGLE, /* single issue instructions\t\t\t*/\n+\t\t  NUM_ULTRA_CODES };\n+\n+static char *ultra_code_names[NUM_ULTRA_CODES] = {\n+  \"NONE\", \"IEU0\", \"IEU1\", \"IEUN\", \"LSU\", \"CTI\",\n+  \"FPM\", \"FPA\", \"SINGLE\" };\n+\n+struct ultrasparc_pipeline_state {\n+  /* The insns in this group.  */\n+  rtx group[4];\n+\n+  /* The code for each insn.  */\n+  enum ultra_code codes[4];\n+\n+  /* Which insns in this group have been committed by the\n+     scheduler.  This is how we determine how many more\n+     can issue this cycle.  */\n+  char commit[4];\n+\n+  /* How many insns in this group.  */\n+  char group_size;\n+\n+  /* Mask of free slots still in this group.  */\n+  char free_slot_mask;\n+\n+  /* The slotter uses the following to determine what other\n+     insn types can still make their way into this group.  */\n+  char contents [NUM_ULTRA_CODES];\n+  char num_ieu_insns;\n+};\n+\n+#define ULTRA_NUM_HIST\t8\n+static struct ultrasparc_pipeline_state ultra_pipe_hist[ULTRA_NUM_HIST];\n+static int ultra_cur_hist;\n+static int ultra_cycles_elapsed;\n+\n+#define ultra_pipe\t(ultra_pipe_hist[ultra_cur_hist])\n+\n+/* Given TYPE_MASK compute the ultra_code it has.  */\n+static enum ultra_code\n+ultra_code_from_mask (type_mask)\n+     int type_mask;\n+{\n+  int mask;\n+\n+  if (type_mask & (TMASK (TYPE_SHIFT) | TMASK (TYPE_CMOVE)))\n+    return IEU0;\n+  else if (type_mask & (TMASK (TYPE_COMPARE) |\n+\t\t\tTMASK (TYPE_CALL) |\n+\t\t\tTMASK (TYPE_UNCOND_BRANCH)))\n+    return IEU1;\n+  else if (type_mask & (TMASK (TYPE_IALU) | TMASK (TYPE_BINARY) |\n+\t\t\tTMASK (TYPE_MOVE) | TMASK (TYPE_UNARY)))\n+    return IEUN;\n+  else if (type_mask & (TMASK (TYPE_LOAD) | TMASK (TYPE_SLOAD) |\n+\t\t\tTMASK (TYPE_STORE) | TMASK (TYPE_FPLOAD) |\n+\t\t\tTMASK (TYPE_FPSTORE)))\n+    return LSU;\n+  else if (type_mask & (TMASK (TYPE_FPMUL) | TMASK (TYPE_FPDIVS) |\n+\t\t\tTMASK (TYPE_FPDIVD) | TMASK (TYPE_FPSQRT)))\n+    return FPM;\n+  else if (type_mask & (TMASK (TYPE_FPMOVE) | TMASK (TYPE_FPCMOVE) |\n+\t\t\tTMASK (TYPE_FP) | TMASK (TYPE_FPCMP)))\n+    return FPA;\n+  else if (type_mask & TMASK (TYPE_BRANCH))\n+    return CTI;\n+\n+  return SINGLE;\n+}\n+\n+/* Check INSN (a conditional move) and make sure that it's\n+   results are available at this cycle.  Return 1 if the\n+   results are in fact ready.  */\n+static int\n+ultra_cmove_results_ready_p (insn)\n+     rtx insn;\n+{\n+  struct ultrasparc_pipeline_state *up;\n+  int entry, slot;\n+\n+  /* If this got dispatched in the previous\n+     group, the results are not ready.  */\n+  entry = (ultra_cur_hist - 1) % ULTRA_NUM_HIST;\n+  up = &ultra_pipe_hist[entry];\n+  slot = 4;\n+  while (--slot >= 0)\n+    if (up->group[slot] == insn)\n+      return 1;\n+\n+  return 0;\n+}\n+\n+/* Walk backwards in pipeline history looking for FPU\n+   operations which use a mode different than FPMODE and\n+   will create a stall if an insn using FPMODE were to be\n+   dispatched this cycle.  */\n+static int\n+ultra_fpmode_conflict_exists (fpmode)\n+     enum machine_mode fpmode;\n+{\n+  int hist_ent;\n+  int hist_lim;\n+\n+  hist_ent = (ultra_cur_hist - 1) % ULTRA_NUM_HIST;\n+  if (ultra_cycles_elapsed < 4)\n+    hist_lim = ultra_cycles_elapsed;\n+  else\n+    hist_lim = 4;\n+  while (hist_lim > 0)\n+    {\n+      struct ultrasparc_pipeline_state *up = &ultra_pipe_hist[hist_ent];\n+      int slot = 4;\n+\n+      while (--slot >= 0)\n+\t{\n+\t  rtx insn = up->group[slot];\n+\t  enum machine_mode this_mode;\n+\t  enum attr_type this_type;\n+\t  rtx pat;\n+\n+\t  if (! insn\n+\t      || GET_CODE (insn) != INSN\n+\t      || (pat = PATTERN (insn)) == 0\n+\t      || GET_CODE (pat) != SET)\n+\t    continue;\n+\n+\t  this_mode = GET_MODE (SET_DEST (pat));\n+\t  if ((this_mode != SFmode\n+\t       && this_mode != DFmode)\n+\t      || this_mode == fpmode)\n+\t    continue;\n+\n+\t  /* If it is not FMOV, FABS, FNEG, FDIV, or FSQRT then\n+\t     we will get a stall.  */\n+\t  if (GET_CODE (SET_SRC (pat)) != ABS\n+\t      && GET_CODE (SET_SRC (pat)) != NEG\n+\t      && ((TMASK (get_attr_type (insn)) &\n+\t\t   (TMASK (TYPE_FPDIVS) | TMASK (TYPE_FPDIVD) |\n+\t\t    TMASK (TYPE_FPMOVE) | TMASK (TYPE_FPSQRT))) == 0))\n+\t    return 1;\n+\t}\n+      hist_lim--;\n+      hist_ent = (hist_ent - 1) % ULTRA_NUM_HIST;\n+    }\n+\n+  /* No conflicts, safe to dispatch.  */\n+  return 0;\n+}\n+\n+/* Find an instruction in LIST which has one of the\n+   type attributes enumerated in TYPE_MASK.  START\n+   says where to begin the search.\n+\n+   NOTE: This scheme depends upon the fact that we\n+         have less than 32 distinct type attributes.  */\n+static rtx *\n+ultra_find_type (type_mask, list, start)\n+     int type_mask;\n+     rtx *list;\n+     int start;\n+{\n+  int i;\n+\n+  for (i = start; i >= 0; i--)\n+    {\n+      rtx insn = list[i];\n+\n+      if (recog_memoized (insn) >= 0\n+\t  && (TMASK(get_attr_type (insn)) & type_mask))\n+\t{\n+\t  enum machine_mode fpmode;\n+\t  rtx pat = 0;\n+\t  int slot;\n+\t  int check_depend = 0;\n+\t  int check_fpmode_conflict = 0;\n+\n+\t  if (GET_CODE (insn) == INSN\n+\t      && (pat = PATTERN(insn)) != 0\n+\t      && GET_CODE (pat) == SET\n+\t      && !(type_mask & (TMASK (TYPE_STORE) |\n+\t\t\t\tTMASK (TYPE_FPSTORE))))\n+\t    {\n+\t      check_depend = 1;\n+\t      if (GET_MODE (SET_DEST (pat)) == SFmode\n+\t\t  || GET_MODE (SET_DEST (pat)) == DFmode)\n+\t\t{\n+\t\t  fpmode = GET_MODE (SET_DEST (pat));\n+\t\t  check_fpmode_conflict = 1;\n+\t\t}\n+\t    }\n+\n+\t  slot = 4;\n+\t  while(--slot >= 0)\n+\t    {\n+\t      rtx slot_insn = ultra_pipe.group[slot];\n+\t      rtx slot_pat;\n+\n+\t      /* Already issued, bad dependency, or FPU\n+\t\t mode conflict.  */\n+\t      if (slot_insn != 0\n+\t\t  && (slot_pat = PATTERN (slot_insn)) != 0\n+\t\t  && ((insn == slot_insn)\n+\t\t      || (check_depend == 1\n+\t\t\t  && GET_CODE (slot_insn) == INSN\n+\t\t\t  && GET_CODE (slot_pat) == SET\n+\t\t\t  && rtx_equal_p (SET_DEST (slot_pat),\n+\t\t\t\t\t  SET_SRC (pat)))\n+\t\t      || (check_fpmode_conflict == 1\n+\t\t\t  && GET_CODE (slot_insn) == INSN\n+\t\t\t  && GET_CODE (slot_pat) == SET\n+\t\t\t  && ((GET_MODE (SET_DEST (slot_pat)) == SFmode\n+\t\t\t       || GET_MODE (SET_DEST (slot_pat)) == DFmode)\n+\t\t\t      && GET_MODE (SET_DEST (slot_pat)) != fpmode))))\n+\t\tgoto next;\n+\t    }\n+\n+\t  /* Check for peculiar result availability and dispatch\n+\t     interference situations.  */\n+\t  if (pat != 0\n+\t      && ultra_cycles_elapsed > 0)\n+\t    {\n+\t      rtx link;\n+\n+\t      for (link = LOG_LINKS (insn); link; link = XEXP (link, 1))\n+\t\t{\n+\t\t  rtx link_insn = XEXP (link, 0);\n+\t\t  if (GET_CODE (link_insn) == INSN\n+\t\t      && recog_memoized (link_insn) >= 0\n+\t\t      && (TMASK (get_attr_type (link_insn)) &\n+\t\t\t  (TMASK (TYPE_CMOVE) | TMASK (TYPE_FPCMOVE)))\n+\t\t      && ! ultra_cmove_results_ready_p (link_insn))\n+\t\t    goto next;\n+\t\t}\n+\n+\t      if (check_fpmode_conflict\n+\t\t  && ultra_fpmode_conflict_exists (fpmode))\n+\t\tgoto next;\n+\t    }\n+\n+\t  return &list[i];\n+\t}\n+    next:\n+    }\n+  return 0;\n+}\n+\n+/* Place insn pointed to my IP into the pipeline.\n+   Make element THIS of READY be that insn if it\n+   is not already.  TYPE indicates the pipeline class\n+   this insn falls into.  */\n+static void\n+ultra_schedule_insn (ip, ready, this, type)\n+     rtx *ip;\n+     rtx *ready;\n+     int this;\n+     enum ultra_code type;\n+{\n+  int pipe_slot;\n+  char mask = ultra_pipe.free_slot_mask;\n+\n+  /* Obtain free slot.  */\n+  for (pipe_slot = 0; pipe_slot < 4; pipe_slot++)\n+    if ((mask & (1 << pipe_slot)) != 0)\n+      break;\n+  if (pipe_slot == 4)\n+    abort ();\n+\n+  /* In it goes, and it hasn't been committed yet.  */\n+  ultra_pipe.group[pipe_slot] = *ip;\n+  ultra_pipe.codes[pipe_slot] = type;\n+  ultra_pipe.contents[type] = 1;\n+  if (UMASK (type) &\n+      (UMASK (IEUN) | UMASK (IEU0) | UMASK (IEU1)))\n+    ultra_pipe.num_ieu_insns += 1;\n+\n+  ultra_pipe.free_slot_mask = (mask & ~(1 << pipe_slot));\n+  ultra_pipe.group_size += 1;\n+  ultra_pipe.commit[pipe_slot] = 0;\n+\n+  /* Update ready list.  */\n+  if (ip != &ready[this])\n+    {\n+      rtx temp = *ip;\n+\n+      *ip = ready[this];\n+      ready[this] = temp;\n+    }\n+}\n+\n+/* Advance to the next pipeline group.  */\n+static void\n+ultra_flush_pipeline ()\n+{\n+  ultra_cur_hist = (ultra_cur_hist + 1) % ULTRA_NUM_HIST;\n+  ultra_cycles_elapsed += 1;\n+  bzero ((char *) &ultra_pipe, sizeof ultra_pipe);\n+  ultra_pipe.free_slot_mask = 0xf;\n+}\n+\n+static int ultra_reorder_called_this_block;\n+\n+/* Init our data structures for this current block.  */\n+void\n+ultrasparc_sched_init (dump, sched_verbose)\n+     FILE *dump;\n+     int sched_verbose;\n+{\n+  bzero ((char *) &ultra_pipe_hist, sizeof ultra_pipe_hist);\n+  ultra_pipe.free_slot_mask = 0xf;\n+  ultra_cur_hist = 0;\n+  ultra_cycles_elapsed = 0;\n+  ultra_reorder_called_this_block = 0;\n+}\n+\n+/* INSN has been scheduled, update pipeline commit state\n+   and return how many instructions are still to be\n+   scheduled in this group.  */\n int\n-ultrasparc_adjust_cost (insn, link, dep_insn, cost)\n-     rtx insn;                                     \n-     rtx link;                                     \n-     rtx dep_insn;                                     \n-     int cost;                                     \n+ultrasparc_variable_issue (insn)\n+     rtx insn;\n+{\n+  struct ultrasparc_pipeline_state *up = &ultra_pipe;\n+  int i, left_to_fire;\n+\n+  left_to_fire = 0;\n+  for (i = 0; i < 4; i++)\n+    {\n+      if (up->group[i] == 0)\n+\tcontinue;\n+\n+      if (up->group[i] == insn)\n+\t{\n+\t  up->commit[i] = 1;\n+\t}\n+      else if (! up->commit[i])\n+\tleft_to_fire++;\n+    }\n+\n+  return left_to_fire;\n+}\n+\n+/* In actual_hazard_this_instance, we may have yanked some\n+   instructions from the ready list due to conflict cost\n+   adjustments.  If so, and such an insn was in our pipeline\n+   group, remove it and update state.  */\n+static void\n+ultra_rescan_pipeline_state (ready, n_ready)\n+     rtx *ready;\n+     int n_ready;\n+{\n+  struct ultrasparc_pipeline_state *up = &ultra_pipe;\n+  int i;\n+\n+  for (i = 0; i < 4; i++)\n+    {\n+      rtx insn = up->group[i];\n+      enum ultra_code ucode;\n+      int j;\n+\n+      if (! insn)\n+\tcontinue;\n+\n+      /* If it has been committed, then it was removed from\n+\t the ready list because it was actually scheduled,\n+\t and that is not the case we are searching for here.  */\n+      if (up->commit[i] != 0)\n+\tcontinue;\n+\n+      for (j = n_ready - 1; j >= 0; j--)\n+\tif (ready[j] == insn)\n+\t  break;\n+\n+      /* If we didn't find it, toss it.  */\n+      if (j < 0)\n+\t{\n+\t  enum ultra_code ucode = up->codes[i];\n+\n+\t  up->group[i] = 0;\n+\t  up->codes[i] = NONE;\n+\t  up->contents[ucode] = 0;\n+\t  if (UMASK (ucode) &\n+\t      (UMASK (IEUN) | UMASK (IEU0) | UMASK (IEU1)))\n+\t    up->num_ieu_insns -= 1;\n+\n+\t  up->free_slot_mask |= (1 << i);\n+\t  up->group_size -= 1;\n+\t  up->commit[i] = 0;\n+\t}\n+    }\n+}\n+\n+void\n+ultrasparc_sched_reorder (dump, sched_verbose, ready, n_ready)\n+     FILE *dump;\n+     int sched_verbose;\n+     rtx *ready;\n+     int n_ready;\n+{\n+  struct ultrasparc_pipeline_state *up = &ultra_pipe;\n+  int i, this_insn;\n+\n+  /* We get called once unnecessarily per block of insns\n+     scheduled.  */\n+  if (ultra_reorder_called_this_block == 0)\n+    {\n+      ultra_reorder_called_this_block = 1;\n+      return;\n+    }\n+\n+  if (sched_verbose)\n+    {\n+      int n;\n+\n+      fprintf (dump, \"\\n;;\\tUltraSPARC Looking at [\");\n+      for (n = n_ready - 1; n >= 0; n--)\n+\t{\n+\t  rtx insn = ready[n];\n+\t  enum ultra_code ucode;\n+\n+\t  if (recog_memoized (insn) < 0)\n+\t    continue;\n+\t  ucode = ultra_code_from_mask (TMASK (get_attr_type (insn)));\n+\t  if (n != 0)\n+\t    fprintf (dump, \"%s(%d) \",\n+\t\t     ultra_code_names[ucode],\n+\t\t     INSN_UID (insn));\n+\t  else\n+\t    fprintf (dump, \"%s(%d)\",\n+\t\t     ultra_code_names[ucode],\n+\t\t     INSN_UID (insn));\n+\t}\n+      fprintf (dump, \"]\\n\");\n+    }\n+\n+  this_insn = n_ready - 1;\n+\n+  /* Skip over junk we don't understand.  */\n+  while ((this_insn >= 0)\n+\t && recog_memoized (ready[this_insn]) < 0)\n+    this_insn--;\n+\n+  while (this_insn >= 0) {\n+    int old_group_size = up->group_size;\n+\n+    if (up->group_size != 0)\n+      {\n+\tint num_committed;\n+\n+\tnum_committed = (up->commit[0] + up->commit[1] +\n+\t\t\t up->commit[2] + up->commit[3]);\n+\t/* If nothing has been commited from our group, or all of\n+\t   them have.  Clear out the (current cycle's) pipeline\n+\t   state and start afresh.  */\n+\tif (num_committed == 0\n+\t    || num_committed == up->group_size)\n+\t  {\n+\t    bzero ((char *) &ultra_pipe, sizeof ultra_pipe);\n+\t    ultra_pipe.free_slot_mask = 0xf;\n+\t    old_group_size = 0;\n+\t  }\n+\telse\n+\t  {\n+\t    /* OK, some ready list insns got requeued and thus removed\n+\t       from the ready list.  Account for this fact.  */\n+\t    ultra_rescan_pipeline_state (ready, n_ready);\n+\n+\t    /* Something \"changed\", make this look like a newly\n+\t       formed group so the code at the end of the loop\n+\t       knows that progress was in fact made.  */\n+\t    if (up->group_size != old_group_size)\n+\t      old_group_size == 0;\n+\t  }\n+      }\n+\n+    if (up->group_size == 0)\n+      {\n+\t/* If the pipeline is (still) empty and we have any single\n+\t   group insns, get them out now as this is a good time.  */\n+\trtx *ip = ultra_find_type ((TMASK (TYPE_RETURN) | TMASK (TYPE_ADDRESS) |\n+\t\t\t\t    TMASK (TYPE_IMUL) | TMASK (TYPE_CMOVE) |\n+\t\t\t\t    TMASK (TYPE_MULTI) | TMASK (TYPE_MISC)),\n+\t\t\t\t   ready, this_insn);\n+\tif (ip)\n+\t  {\n+\t    ultra_schedule_insn (ip, ready, this_insn, SINGLE);\n+\t    break;\n+\t  }\n+\n+\t/* If we are not in the process of emptying out the pipe, try to\n+\t   obtain an instruction which must be the first in it's group.  */\n+\tip = ultra_find_type ((TMASK (TYPE_CALL) |\n+\t\t\t       TMASK (TYPE_CALL_NO_DELAY_SLOT) |\n+\t\t\t       TMASK (TYPE_UNCOND_BRANCH)),\n+\t\t\t      ready, this_insn);\n+\tif (ip)\n+\t  {\n+\t    ultra_schedule_insn (ip, ready, this_insn, IEU1);\n+\t    this_insn--;\n+\t  }\n+\telse if ((ip = ultra_find_type ((TMASK (TYPE_FPDIVS) |\n+\t\t\t\t\t TMASK (TYPE_FPDIVD) |\n+\t\t\t\t\t TMASK (TYPE_FPSQRT)),\n+\t\t\t\t\tready, this_insn)) != 0)\n+\t  {\n+\t    ultra_schedule_insn (ip, ready, this_insn, FPM);\n+\t    this_insn--;\n+\t  }\n+      }\n+\n+    /* Try to fill the integer pipeline.  First, look for an IEU0 specific\n+       operation.  We can't do more IEU operations if the first 3 slots are\n+       all full or we have dispatched two IEU insns already.  */\n+    if ((up->free_slot_mask & 0x7) != 0\n+\t&& up->num_ieu_insns < 2\n+\t&& up->contents[IEU0] == 0\n+\t&& up->contents[IEUN] == 0)\n+      {\n+\trtx *ip = ultra_find_type (TMASK(TYPE_SHIFT), ready, this_insn);\n+\tif (ip)\n+\t  {\n+\t    ultra_schedule_insn (ip, ready, this_insn, IEU0);\n+\t    this_insn--;\n+\t  }\n+      }\n+\n+    /* If we can, try to find an IEU1 specific or an unnamed\n+       IEU instruction.  */\n+    if ((up->free_slot_mask & 0x7) != 0\n+\t&& up->num_ieu_insns < 2)\n+      {\n+\trtx *ip = ultra_find_type ((TMASK (TYPE_IALU) | TMASK (TYPE_BINARY) |\n+\t\t\t\t    TMASK (TYPE_MOVE) | TMASK (TYPE_UNARY) |\n+\t\t\t\t    (up->contents[IEU1] == 0 ? TMASK (TYPE_COMPARE) : 0)),\n+\t\t\t\t   ready, this_insn);\n+\tif (ip)\n+\t  {\n+\t    rtx insn = *ip;\n+\n+\t    ultra_schedule_insn (ip, ready, this_insn,\n+\t\t\t\t (!up->contents[IEU1]\n+\t\t\t\t  && get_attr_type (insn) == TYPE_COMPARE)\n+\t\t\t\t ? IEU1 : IEUN);\n+\t    this_insn--;\n+\t  }\n+      }\n+\n+    /* If only one IEU insn has been found, try to find another unnamed\n+       IEU operation or an IEU1 specific one.  */\n+    if ((up->free_slot_mask & 0x7) != 0\n+\t&& up->num_ieu_insns < 2)\n+      {\n+\trtx *ip;\n+\tint tmask = (TMASK (TYPE_IALU) | TMASK (TYPE_BINARY) |\n+\t\t     TMASK (TYPE_MOVE) | TMASK (TYPE_UNARY));\n+\n+\tif (!up->contents[IEU1])\n+\t  tmask |= TMASK (TYPE_COMPARE);\n+\tip = ultra_find_type (tmask, ready, this_insn);\n+\tif (ip)\n+\t  {\n+\t    rtx insn = *ip;\n+\n+\t    ultra_schedule_insn (ip, ready, this_insn,\n+\t\t\t\t (!up->contents[IEU1]\n+\t\t\t\t  && get_attr_type (insn) == TYPE_COMPARE)\n+\t\t\t\t ? IEU1 : IEUN);\n+\t    this_insn--;\n+\t  }\n+      }\n+\n+    /* Try for a load or store, but such an insn can only be issued\n+       if it is within' one of the first 3 slots.  */\n+    if ((up->free_slot_mask & 0x7) != 0\n+        && up->contents[LSU] == 0)\n+      {\n+\trtx *ip = ultra_find_type ((TMASK (TYPE_LOAD) | TMASK (TYPE_SLOAD) |\n+\t\t\t\t   TMASK (TYPE_STORE) | TMASK (TYPE_FPLOAD) |\n+\t\t\t\t   TMASK (TYPE_FPSTORE)), ready, this_insn);\n+\tif (ip)\n+\t  {\n+\t    ultra_schedule_insn (ip, ready, this_insn, LSU);\n+\t    this_insn--;\n+\t  }\n+      }\n+\n+    /* Now find FPU operations, first FPM class.  But not divisions or\n+       square-roots because those will break the group up.  Unlike all\n+       the previous types, these can go in any slot.  */\n+    if (up->free_slot_mask != 0\n+\t&& up->contents[FPM] == 0)\n+      {\n+\trtx *ip = ultra_find_type (TMASK (TYPE_FPMUL), ready, this_insn);\n+\tif (ip)\n+\t  {\n+\t    ultra_schedule_insn (ip, ready, this_insn, FPM);\n+\t    this_insn--;\n+\t  }\n+      }\n+    \n+    /* Continue on with FPA class if we have not filled the group already.  */\n+    if (up->free_slot_mask != 0\n+\t&& up->contents[FPA] == 0)\n+      {\n+\trtx *ip = ultra_find_type ((TMASK (TYPE_FPMOVE) | TMASK (TYPE_FPCMOVE) |\n+\t\t\t\t    TMASK (TYPE_FP) | TMASK (TYPE_FPCMP)),\n+\t\t\t\t   ready, this_insn);\n+\tif (ip)\n+\t  {\n+\t    ultra_schedule_insn (ip, ready, this_insn, FPA);\n+\t    this_insn--;\n+\t  }\n+      }\n+\n+    /* Finally, maybe stick a branch in here.  */\n+    if (up->free_slot_mask != 0\n+\t&& up->contents[CTI] == 0)\n+      {\n+\trtx *ip = ultra_find_type (TMASK (TYPE_BRANCH), ready, this_insn);\n+\n+\t/* Try to slip in a branch only if it is one of the\n+\t   next 2 in the ready list.  */\n+\tif (ip && ((&ready[this_insn] - ip) < 2))\n+\t  {\n+\t    ultra_schedule_insn (ip, ready, this_insn, CTI);\n+\t    this_insn--;\n+\t  }\n+      }\n+\n+    up->group_size = 0;\n+    for (i = 0; i < 4; i++)\n+      if ((up->free_slot_mask & (1 << i)) == 0)\n+\tup->group_size++;\n+\n+    /* See if we made any progress...  */\n+    if (old_group_size != up->group_size)\n+      break;\n+\n+    /* Clean out the (current cycle's) pipeline state\n+       and try once more.  */\n+    bzero ((char *) &ultra_pipe, sizeof ultra_pipe);\n+    ultra_pipe.free_slot_mask = 0xf;\n+  }\n+\n+  if (sched_verbose)\n+    {\n+      int n, gsize;\n+\n+      fprintf (dump, \";;\\tUltraSPARC Launched   [\");\n+      gsize = up->group_size;\n+      for (n = 0; n < 4; n++)\n+\t{\n+\t  rtx insn = up->group[n];\n+\n+\t  if (! insn)\n+\t    continue;\n+\n+\t  gsize -= 1;\n+\t  if (gsize != 0)\n+\t    fprintf (dump, \"%s(%d) \",\n+\t\t     ultra_code_names[up->codes[n]],\n+\t\t     INSN_UID (insn));\n+\t  else\n+\t    fprintf (dump, \"%s(%d)\",\n+\t\t     ultra_code_names[up->codes[n]],\n+\t\t     INSN_UID (insn));\n+\t}\n+      fprintf (dump, \"]\\n\");\n+    }\n+}\n+\n+int\n+ultrasparc_adjust_cost (insn, link, dep_insn, previous, cost)\n+     rtx insn;\n+     rtx link;\n+     rtx dep_insn;\n+     rtx previous;\n+     int cost;\n {\n   enum attr_type insn_type, dep_type;\n-  rtx pat = PATTERN(insn);                                                    \n-  rtx dep_pat = PATTERN (dep_insn);                                           \n+  rtx pat = PATTERN(insn);\n+  rtx dep_pat = PATTERN (dep_insn);\n \n-  if (recog_memoized (insn) < 0 || recog_memoized (dep_insn) < 0)        \n-    return cost;                                     \n+  if (recog_memoized (insn) < 0 || recog_memoized (dep_insn) < 0)\n+    return cost;\n \n-  insn_type = get_attr_type (insn);                     \n-  dep_type = get_attr_type (dep_insn);                  \n+  insn_type = get_attr_type (insn);\n+  dep_type = get_attr_type (dep_insn);\n+\n+  /* Nothing issues in parallel with integer multiplies, so\n+     mark as zero cost since the scheduler can not do anything\n+     about it.  */\n+  if (insn_type == TYPE_IMUL)\n+    return 0;\n \n #define SLOW_FP(dep_type) \\\n (dep_type == TYPE_FPSQRT || dep_type == TYPE_FPDIVS || dep_type == TYPE_FPDIVD)\n \n   switch (REG_NOTE_KIND (link))\n-    {                                              \n-    case 0:                                        \n+    {\n+    case 0:\n       /* Data dependency; DEP_INSN writes a register that INSN reads some\n-\t cycles later.  */                               \n+\t cycles later.  */\n+\n+      if (dep_type == TYPE_CMOVE)\n+\t{\n+\t  /* Instructions that read the result of conditional moves cannot\n+\t     be in the same group or the following group.  */\n+\t  return cost + 1;\n+\t}\n \n       switch (insn_type)\n-\t{                              \n-\t  /* UltraSPARC can dual issue a store and an instruction setting       \n-\t     the value stored, except for divide and square root.  */           \n+\t{\n+\t  /* UltraSPARC can dual issue a store and an instruction setting\n+\t     the value stored, except for divide and square root.  */\n \tcase TYPE_FPSTORE:\n-\t  if (! SLOW_FP (dep_type))        \n-\t    return 0;                                     \n+\t  if (! SLOW_FP (dep_type))\n+\t    return 0;\n \t  return cost;\n \n-\tcase TYPE_STORE:                                  \n+\tcase TYPE_STORE:\n \t  if (GET_CODE (pat) != SET || GET_CODE (dep_pat) != SET)\n-\t    return cost;     \n+\t    return cost;\n \n \t  if (rtx_equal_p (SET_DEST (dep_pat), SET_SRC (pat)))\n-\t  /* The dependency between the two instructions is on the data\n-\t     that is being stored.  Assume that the address of the store\n-\t     is not also dependent.  */\n-\t    return 0;                                \n-\t  return cost;                                   \n-\n-\tcase TYPE_LOAD:   \n-\tcase TYPE_SLOAD:               \n-\tcase TYPE_FPLOAD:                                                       \n-\t  /* A load does not return data until at least 11 cycles after         \n+\t    /* The dependency between the two instructions is on the data\n+\t       that is being stored.  Assume that the address of the store\n+\t       is not also dependent.  */\n+\t    return 0;\n+\t  return cost;\n+\n+\tcase TYPE_LOAD:\n+\tcase TYPE_SLOAD:\n+\tcase TYPE_FPLOAD:\n+\t  /* A load does not return data until at least 11 cycles after\n \t     a store to the same location.  3 cycles are accounted for\n \t     in the load latency; add the other 8 here.  */\n \t  if (dep_type == TYPE_STORE || dep_type == TYPE_FPSTORE)\n-\t    {   \n+\t    {\n \t      /* If the addresses are not equal this may be a false\n \t\t dependency because pointer aliasing could not be\n \t\t determined.  Add only 2 cycles in that case.  2 is\n \t\t an arbitrary compromise between 8, which would cause\n \t\t the scheduler to generate worse code elsewhere to\n-\t\t compensate for a dependency which might not really    \n-\t\t exist, and 0.  */                                      \n+\t\t compensate for a dependency which might not really\n+\t\t exist, and 0.  */\n \t      if (GET_CODE (pat) != SET || GET_CODE (dep_pat) != SET\n \t\t  || GET_CODE (SET_SRC (pat)) != MEM\n \t\t  || GET_CODE (SET_DEST (dep_pat)) != MEM\n \t\t  || ! rtx_equal_p (XEXP (SET_SRC (pat), 0),\n \t\t\t\t    XEXP (SET_DEST (dep_pat), 0)))\n \t\treturn cost + 2;\n \n-\t      return cost + 8;         \n-\t    }                                                                   \n+\t      return cost + 8;\n+\t    }\n \t  return cost;\n \n-\tcase TYPE_BRANCH:                                  \n+\tcase TYPE_BRANCH:\n \t  /* Compare to branch latency is 0.  There is no benefit from\n \t     separating compare and branch.  */\n-\t  if (dep_type == TYPE_COMPARE)                            \n-\t    return 0;                                            \n-\t  /* Floating point compare to branch latency is less than \n-\t     compare to conditional move.  */                        \n-\t  if (dep_type == TYPE_FPCMP)                             \n-\t    return cost - 1;                                           \n+\t  if (dep_type == TYPE_COMPARE)\n+\t    return 0;\n+\t  /* Floating point compare to branch latency is less than\n+\t     compare to conditional move.  */\n+\t  if (dep_type == TYPE_FPCMP)\n+\t    return cost - 1;\n \t  return cost;\n \n-\tcase TYPE_FPCMOVE:                                    \n+\tcase TYPE_FPCMOVE:\n \t  /* FMOVR class instructions can not issue in the same cycle\n \t     or the cycle after an instruction which writes any\n \t     integer register.  Model this as cost 2 for dependent\n-\t     instructions.  */  \n+\t     instructions.  */\n \t  if ((dep_type == TYPE_IALU || dep_type == TYPE_UNARY\n \t       || dep_type == TYPE_BINARY)\n-\t      && cost < 2)                                                      \n+\t      && cost < 2)\n \t    return 2;\n \t  /* Otherwise check as for integer conditional moves. */\n \n-\tcase TYPE_CMOVE:                       \n+\tcase TYPE_CMOVE:\n \t  /* Conditional moves involving integer registers wait until\n \t     3 cycles after loads return data.  The interlock applies\n \t     to all loads, not just dependent loads, but that is hard\n-\t     to model.  */                        \n-\t  if (dep_type == TYPE_LOAD || dep_type == TYPE_SLOAD)                  \n-\t    return cost + 3;                                           \n+\t     to model.  */\n+\t  if (dep_type == TYPE_LOAD || dep_type == TYPE_SLOAD)\n+\t    return cost + 3;\n \t  return cost;\n \n \tdefault:\n \t  break;\n \t}\n-\tbreak;                                                \n+      break;\n \n-    case REG_DEP_ANTI:                                       \n+    case REG_DEP_ANTI:\n       /* Divide and square root lock destination registers for full latency. */\n-      if (! SLOW_FP (dep_type))             \n-\treturn 0;                                               \n-      break;                                                                  \n+      if (! SLOW_FP (dep_type))\n+\treturn 0;\n+      break;\n+\n+    case REG_DEP_OUTPUT:\n+      /* IEU and FPU instruction that have the same destination\n+\t register cannot be grouped together.  */\n+      return cost + 1;\n \n     default:\n       break;\n     }\n \n-  /* Other costs not accounted for:                            \n-     - Multiply should be modeled as having no latency because there is\n-       nothing the scheduler can do about it.  \n-     - Single precision floating point loads lock the other half of  \n-       the even/odd register pair.                                   \n+  /* Other costs not accounted for:\n+     - Single precision floating point loads lock the other half of\n+       the even/odd register pair.\n      - Several hazards associated with ldd/std are ignored because these\n-       instructions are rarely generated for V9.  \n-     - A shift following an integer instruction which does not set the\n-       condition codes can not issue in the same cycle.\n+       instructions are rarely generated for V9.\n      - The floating point pipeline can not have both a single and double\n        precision operation active at the same time.  Format conversions\n        and graphics instructions are given honorary double precision status.\n      - call and jmpl are always the first instruction in a group.  */\n \n-  return cost;                                                              \n-}  \n+  return cost;\n+}\n \n int                                                           \n sparc_issue_rate ()"}, {"sha": "81c72fd4e8301a5c3e509b847b91a09b546344c1", "filename": "gcc/config/sparc/sparc.h", "status": "modified", "additions": 26, "deletions": 1, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108/gcc%2Fconfig%2Fsparc%2Fsparc.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108/gcc%2Fconfig%2Fsparc%2Fsparc.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsparc%2Fsparc.h?ref=3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108", "patch": "@@ -2704,11 +2704,17 @@ extern struct rtx_def *legitimize_pic_address ();\n \n #define RTX_COSTS(X,CODE,OUTER_CODE)\t\t\t\\\n   case MULT:\t\t\t\t\t\t\\\n+    if (sparc_cpu == PROCESSOR_ULTRASPARC)\t\t\\\n+      return (GET_MODE (X) == DImode ?\t\t\t\\\n+              COSTS_N_INSNS (34) : COSTS_N_INSNS (19));\t\\\n     return TARGET_HARD_MUL ? COSTS_N_INSNS (5) : COSTS_N_INSNS (25); \\\n   case DIV:\t\t\t\t\t\t\\\n   case UDIV:\t\t\t\t\t\t\\\n   case MOD:\t\t\t\t\t\t\\\n   case UMOD:\t\t\t\t\t\t\\\n+    if (sparc_cpu == PROCESSOR_ULTRASPARC)\t\t\\\n+      return (GET_MODE (X) == DImode ?\t\t\t\\\n+              COSTS_N_INSNS (68) : COSTS_N_INSNS (37));\t\\\n     return COSTS_N_INSNS (25);\t\t\t\t\\\n   /* Make FLOAT and FIX more expensive than CONST_DOUBLE,\\\n      so that cse will favor the latter.  */\t\t\\\n@@ -2723,9 +2729,28 @@ extern struct rtx_def *legitimize_pic_address ();\n   if (sparc_cpu == PROCESSOR_SUPERSPARC)\t\t\t\\\n     (COST) = supersparc_adjust_cost (INSN, LINK, DEP, COST);\t\\\n   else if (sparc_cpu == PROCESSOR_ULTRASPARC)\t\t\t\\\n-    (COST) = ultrasparc_adjust_cost (INSN, LINK, DEP, COST);\t\\\n+    (COST) = ultrasparc_adjust_cost (INSN, LINK, DEP,\t\t\\\n+\t\t\t\t     last_scheduled_insn, COST);\\\n   else\n \n+extern void ultrasparc_sched_reorder ();\n+extern void ultrasparc_sched_init ();\n+extern int ultrasparc_variable_issue ();\n+\n+#define MD_SCHED_INIT(DUMP, SCHED_VERBOSE)\t\t\t\t\\\n+  if (sparc_cpu == PROCESSOR_ULTRASPARC)\t\t\t\t\\\n+    ultrasparc_sched_init (DUMP, SCHED_VERBOSE)\n+\n+#define MD_SCHED_REORDER(DUMP, SCHED_VERBOSE, READY, N_READY)\t\t\\\n+  if (sparc_cpu == PROCESSOR_ULTRASPARC)\t\t\t\t\\\n+    ultrasparc_sched_reorder (DUMP, SCHED_VERBOSE, READY, N_READY)\n+\n+#define MD_SCHED_VARIABLE_ISSUE(DUMP, SCHED_VERBOSE, INSN, CAN_ISSUE_MORE) \\\n+  if (sparc_cpu == PROCESSOR_ULTRASPARC)\t\t\t\\\n+    (CAN_ISSUE_MORE) = ultrasparc_variable_issue (INSN);\t\\\n+  else\t\t\t\t\t\t\t\t\\\n+    (CAN_ISSUE_MORE)--\n+\n /* Conditional branches with empty delay slots have a length of two.  */\n #define ADJUST_INSN_LENGTH(INSN, LENGTH)\t\t\t\t\\\n   if (GET_CODE (INSN) == CALL_INSN\t\t\t\t\t\\"}, {"sha": "cd23e8260c12fd9a4cef8404499ee7c734e82ec4", "filename": "gcc/config/sparc/sparc.md", "status": "modified", "additions": 59, "deletions": 35, "changes": 94, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108/gcc%2Fconfig%2Fsparc%2Fsparc.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108/gcc%2Fconfig%2Fsparc%2Fsparc.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsparc%2Fsparc.md?ref=3bc8b61efc54c66c0cf4ecc4dfa3b387bfa48108", "patch": "@@ -398,9 +398,9 @@\n     (eq_attr \"type\" \"store,fpstore\"))\n   1 1)\n \n-(define_function_unit \"ieu_unnamed\" 2 0\n+(define_function_unit \"ieuN\" 2 0\n   (and (eq_attr \"cpu\" \"ultrasparc\")\n-    (eq_attr \"type\" \"ialu,binary,move,unary,shift,cmove,compare,call\"))\n+    (eq_attr \"type\" \"ialu,binary,move,unary,shift,compare,call,call_no_delay_slot,uncond_branch\"))\n   1 1)\n \n (define_function_unit \"ieu0\" 1 0\n@@ -415,7 +415,12 @@\n \n (define_function_unit \"ieu1\" 1 0\n   (and (eq_attr \"cpu\" \"ultrasparc\")\n-    (eq_attr \"type\" \"compare,call,uncond_branch\"))\n+    (eq_attr \"type\" \"compare,call,call_no_delay_slot,uncond_branch\"))\n+  1 1)\n+\n+(define_function_unit \"cti\" 1 0\n+  (and (eq_attr \"cpu\" \"ultrasparc\")\n+    (eq_attr \"type\" \"branch\"))\n   1 1)\n \n ;; Timings; throughput/latency\n@@ -1416,7 +1421,7 @@\n \t\t  (match_operand:SI 1 \"arith_operand\" \"rI\")))]\n   \"! TARGET_LIVE_G0\"\n   \"subx\\\\t%%g0, %1, %0\"\n-  [(set_attr \"type\" \"unary\")\n+  [(set_attr \"type\" \"misc\")\n    (set_attr \"length\" \"1\")])\n \n (define_insn \"*neg_sltu_plus_x\"\n@@ -1425,7 +1430,7 @@\n \t\t\t (match_operand:SI 1 \"arith_operand\" \"rI\"))))]\n   \"! TARGET_LIVE_G0\"\n   \"subx\\\\t%%g0, %1, %0\"\n-  [(set_attr \"type\" \"unary\")\n+  [(set_attr \"type\" \"misc\")\n    (set_attr \"length\" \"1\")])\n \n (define_insn \"*sgeu_insn\"\n@@ -1454,7 +1459,7 @@\n \t\t (match_operand:SI 1 \"arith_operand\" \"rI\")))]\n   \"! TARGET_LIVE_G0\"\n   \"addx\\\\t%%g0, %1, %0\"\n-  [(set_attr \"type\" \"unary\")\n+  [(set_attr \"type\" \"misc\")\n    (set_attr \"length\" \"1\")])\n \n (define_insn \"*sltu_plus_x_plus_y\"\n@@ -1464,7 +1469,7 @@\n \t\t\t  (match_operand:SI 2 \"arith_operand\" \"rI\"))))]\n   \"\"\n   \"addx\\\\t%1, %2, %0\"\n-  [(set_attr \"type\" \"binary\")\n+  [(set_attr \"type\" \"misc\")\n    (set_attr \"length\" \"1\")])\n \n (define_insn \"*x_minus_sltu\"\n@@ -1473,7 +1478,7 @@\n \t\t  (ltu:SI (reg:CC 100) (const_int 0))))]\n   \"\"\n   \"subx\\\\t%1, 0, %0\"\n-  [(set_attr \"type\" \"unary\")\n+  [(set_attr \"type\" \"misc\")\n    (set_attr \"length\" \"1\")])\n \n ;; ??? Combine should canonicalize these next two to the same pattern.\n@@ -1484,7 +1489,7 @@\n \t\t  (ltu:SI (reg:CC 100) (const_int 0))))]\n   \"\"\n   \"subx\\\\t%r1, %2, %0\"\n-  [(set_attr \"type\" \"binary\")\n+  [(set_attr \"type\" \"misc\")\n    (set_attr \"length\" \"1\")])\n \n (define_insn \"*x_minus_sltu_plus_y\"\n@@ -1494,7 +1499,7 @@\n \t\t\t   (match_operand:SI 2 \"arith_operand\" \"rI\"))))]\n   \"\"\n   \"subx\\\\t%r1, %2, %0\"\n-  [(set_attr \"type\" \"binary\")\n+  [(set_attr \"type\" \"misc\")\n    (set_attr \"length\" \"1\")])\n \n (define_insn \"*sgeu_plus_x\"\n@@ -1503,7 +1508,7 @@\n \t\t (match_operand:SI 1 \"register_operand\" \"r\")))]\n   \"\"\n   \"subx\\\\t%1, -1, %0\"\n-  [(set_attr \"type\" \"unary\")\n+  [(set_attr \"type\" \"misc\")\n    (set_attr \"length\" \"1\")])\n \n (define_insn \"*x_minus_sgeu\"\n@@ -1512,7 +1517,7 @@\n \t\t  (geu:SI (reg:CC 100) (const_int 0))))]\n   \"\"\n   \"addx\\\\t%1, -1, %0\"\n-  [(set_attr \"type\" \"unary\")\n+  [(set_attr \"type\" \"misc\")\n    (set_attr \"length\" \"1\")])\n \n (define_split\n@@ -2167,7 +2172,8 @@\n                    (unspec:SI [(match_operand:SI 2 \"immediate_operand\" \"in\")] 0)))]\n   \"flag_pic\"\n   \"or\\\\t%1, %%lo(%a2), %0\"\n-  [(set_attr \"length\" \"1\")])\n+  [(set_attr \"type\" \"ialu\")\n+   (set_attr \"length\" \"1\")])\n \n (define_insn \"movsi_high_pic\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=r\")\n@@ -2212,7 +2218,8 @@\n \t\t    (match_operand:SI 3 \"\" \"\")] 5)))]\n   \"flag_pic\"\n   \"or\\\\t%1, %%lo(%a3-(%a2-.)), %0\"\n-  [(set_attr \"length\" \"1\")])\n+  [(set_attr \"type\" \"ialu\")\n+   (set_attr \"length\" \"1\")])\n \n (define_expand \"movdi\"\n   [(set (match_operand:DI 0 \"reg_or_nonsymb_mem_operand\" \"\")\n@@ -2394,7 +2401,8 @@\n                    (unspec:DI [(match_operand:DI 2 \"immediate_operand\" \"in\")] 0)))]\n   \"TARGET_ARCH64 && flag_pic\"\n   \"or\\\\t%1, %%lo(%a2), %0\"\n-  [(set_attr \"length\" \"1\")])\n+  [(set_attr \"type\" \"ialu\")\n+   (set_attr \"length\" \"1\")])\n \n (define_insn \"*pic_sethi_di\"\n   [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n@@ -2426,7 +2434,8 @@\n                    (match_operand:DI 2 \"symbolic_operand\" \"\")))]\n   \"TARGET_CM_MEDLOW\"\n   \"or\\\\t%1, %%lo(%a2), %0\"\n-  [(set_attr \"length\" \"1\")])\n+  [(set_attr \"type\" \"ialu\")\n+   (set_attr \"length\" \"1\")])\n \n (define_insn \"seth44\"\n   [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n@@ -2451,7 +2460,8 @@\n                    (match_operand:DI 2 \"symbolic_operand\" \"\")))]\n   \"TARGET_CM_MEDMID\"\n   \"or\\\\t%1, %%l44(%a2), %0\"\n-  [(set_attr \"length\" \"1\")])\n+  [(set_attr \"type\" \"ialu\")\n+   (set_attr \"length\" \"1\")])\n \n (define_insn \"sethh\"\n   [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n@@ -2475,15 +2485,17 @@\n                    (unspec:DI [(match_operand:DI 2 \"symbolic_operand\" \"\")] 18)))]\n   \"TARGET_CM_MEDANY\"\n   \"or\\\\t%1, %%hm(%a2), %0\"\n-  [(set_attr \"length\" \"1\")])\n+  [(set_attr \"type\" \"ialu\")\n+   (set_attr \"length\" \"1\")])\n \n (define_insn \"setlo\"\n   [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n         (lo_sum:DI (match_operand:DI 1 \"register_operand\" \"r\")\n                    (match_operand:DI 2 \"symbolic_operand\" \"\")))]\n   \"TARGET_CM_MEDANY\"\n   \"or\\\\t%1, %%lo(%a2), %0\"\n-  [(set_attr \"length\" \"1\")])\n+  [(set_attr \"type\" \"ialu\")\n+   (set_attr \"length\" \"1\")])\n \n (define_insn \"embmedany_sethi\"\n   [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n@@ -2499,7 +2511,8 @@\n                    (match_operand:DI 2 \"data_segment_operand\" \"\")))]\n   \"TARGET_CM_EMBMEDANY\"\n   \"add\\\\t%1, %%lo(%a2), %0\"\n-  [(set_attr \"length\" \"1\")])\n+  [(set_attr \"type\" \"ialu\")\n+   (set_attr \"length\" \"1\")])\n \n (define_insn \"embmedany_brsum\"\n   [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n@@ -2530,15 +2543,17 @@\n                    (unspec:DI [(match_operand:DI 2 \"text_segment_operand\" \"\")] 15)))]\n   \"TARGET_CM_EMBMEDANY\"\n   \"or\\\\t%1, %%ulo(%a2), %0\"\n-  [(set_attr \"length\" \"1\")])\n+  [(set_attr \"type\" \"ialu\")\n+   (set_attr \"length\" \"1\")])\n \n (define_insn \"embmedany_textlo\"\n   [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n         (lo_sum:DI (match_operand:DI 1 \"register_operand\" \"r\")\n                    (match_operand:DI 2 \"text_segment_operand\" \"\")))]\n   \"TARGET_CM_EMBMEDANY\"\n   \"or\\\\t%1, %%lo(%a2), %0\"\n-  [(set_attr \"length\" \"1\")])\n+  [(set_attr \"type\" \"ialu\")\n+   (set_attr \"length\" \"1\")])\n \n ;; Now some patterns to help reload out a bit.\n (define_expand \"reload_indi\"\n@@ -3797,7 +3812,7 @@\n   \"@\n    srl\\\\t%1, 0, %0\n    lduw\\\\t%1, %0\"\n-  [(set_attr \"type\" \"unary,load\")\n+  [(set_attr \"type\" \"shift,load\")\n    (set_attr \"length\" \"1\")])\n \n (define_insn \"*zero_extendsidi2_insn_sp32\"\n@@ -4090,7 +4105,7 @@\n \t(sign_extend:DI (match_operand:HI 1 \"memory_operand\" \"m\")))]\n   \"TARGET_ARCH64\"\n   \"ldsh\\\\t%1, %0\"\n-  [(set_attr \"type\" \"load\")\n+  [(set_attr \"type\" \"sload\")\n    (set_attr \"length\" \"1\")])\n \n (define_expand \"extendsidi2\"\n@@ -4106,7 +4121,7 @@\n   \"@\n   sra\\\\t%1, 0, %0\n   ldsw\\\\t%1, %0\"\n-  [(set_attr \"type\" \"unary,sload\")\n+  [(set_attr \"type\" \"shift,sload\")\n    (set_attr \"length\" \"1\")])\n \f\n ;; Special pattern for optimizing bit-field compares.  This is needed\n@@ -4469,7 +4484,7 @@\n                                  (ltu:SI (reg:CC_NOOV 100) (const_int 0)))))]\n   \"TARGET_ARCH64\"\n   \"addx\\\\t%r1, %2, %0\"\n-  [(set_attr \"type\" \"unary\")\n+  [(set_attr \"type\" \"misc\")\n    (set_attr \"length\" \"1\")])\n \n (define_insn \"subx\"\n@@ -4479,7 +4494,7 @@\n \t\t  (ltu:SI (reg:CC_NOOV 100) (const_int 0))))]\n   \"\"\n   \"subx\\\\t%r1, %2, %0\"\n-  [(set_attr \"type\" \"unary\")\n+  [(set_attr \"type\" \"misc\")\n    (set_attr \"length\" \"1\")])\n \n (define_insn \"*subx_extend_sp64\"\n@@ -4489,7 +4504,7 @@\n                                   (ltu:SI (reg:CC_NOOV 100) (const_int 0)))))]\n   \"TARGET_ARCH64\"\n   \"subx\\\\t%r1, %2, %0\"\n-  [(set_attr \"type\" \"unary\")\n+  [(set_attr \"type\" \"misc\")\n    (set_attr \"length\" \"1\")])\n \n (define_insn \"*subx_extend\"\n@@ -4547,7 +4562,9 @@\n \t(plus:DI (match_operand:DI 1 \"arith_double_operand\" \"%r\")\n \t\t (match_operand:DI 2 \"arith_double_operand\" \"rHI\")))]\n   \"TARGET_ARCH64\"\n-  \"add\\\\t%1, %2, %0\")\n+  \"add\\\\t%1, %2, %0\"\n+  [(set_attr \"type\" \"binary\")\n+   (set_attr \"length\" \"1\")])\n \n (define_insn \"addsi3\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=r,d\")\n@@ -7016,7 +7033,9 @@\n (define_insn \"nop\"\n   [(const_int 0)]\n   \"\"\n-  \"nop\")\n+  \"nop\"\n+  [(set_attr \"type\" \"ialu\")\n+   (set_attr \"length\" \"1\")])\n \n (define_expand \"indirect_jump\"\n   [(set (pc) (match_operand 0 \"address_operand\" \"p\"))]\n@@ -7096,7 +7115,8 @@\n   [(unspec_volatile [(const_int 0)] 1)]\n   \"\"\n   \"* return TARGET_V9 ? \\\"flushw\\\" : \\\"ta\\\\t3\\\";\"\n-  [(set_attr \"type\" \"misc\")])\n+  [(set_attr \"type\" \"misc\")\n+   (set_attr \"length\" \"1\")])\n \n (define_insn \"goto_handler_and_restore\"\n   [(unspec_volatile [(match_operand:SI 0 \"register_operand\" \"=r\")] 2)]\n@@ -7162,7 +7182,8 @@\n   [(unspec_volatile [(match_operand 0 \"memory_operand\" \"m\")] 4)]\n   \"\"\n   \"* return TARGET_V9 ? \\\"flush\\\\t%f0\\\" : \\\"iflush\\\\t%f0\\\";\"\n-  [(set_attr \"type\" \"misc\")])\n+  [(set_attr \"type\" \"misc\")\n+   (set_attr \"length\" \"1\")])\n \f\n ;; find first set.\n \n@@ -7527,7 +7548,8 @@\n   [(trap_if (const_int 1) (const_int 5))]\n   \"\"\n   \"ta\\\\t5\"\n-  [(set_attr \"type\" \"misc\")])\n+  [(set_attr \"type\" \"misc\")\n+   (set_attr \"length\" \"1\")])\n \n (define_expand \"conditional_trap\"\n   [(trap_if (match_operator 0 \"noov_compare_op\"\n@@ -7543,12 +7565,14 @@\n \t    (match_operand:SI 1 \"arith_operand\" \"rM\"))]\n   \"\"\n   \"t%C0\\\\t%1\"\n-  [(set_attr \"type\" \"misc\")])\n+  [(set_attr \"type\" \"misc\")\n+   (set_attr \"length\" \"1\")])\n \n (define_insn \"\"\n   [(trap_if (match_operator 0 \"noov_compare_op\" [(reg:CCX 100) (const_int 0)])\n \t    (match_operand:SI 1 \"arith_operand\" \"rM\"))]\n   \"TARGET_V9\"\n   \"t%C0\\\\t%%xcc, %1\"\n-  [(set_attr \"type\" \"misc\")])\n+  [(set_attr \"type\" \"misc\")\n+   (set_attr \"length\" \"1\")])\n "}]}