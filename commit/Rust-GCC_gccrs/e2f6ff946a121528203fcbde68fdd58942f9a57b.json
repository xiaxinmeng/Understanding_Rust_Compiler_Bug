{"sha": "e2f6ff946a121528203fcbde68fdd58942f9a57b", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTJmNmZmOTQ2YTEyMTUyODIwM2ZjYmRlNjhmZGQ1ODk0MmY5YTU3Yg==", "commit": {"author": {"name": "Maxim Kuvyrkov", "email": "maxim@codesourcery.com", "date": "2007-08-14T06:40:34Z"}, "committer": {"name": "Maxim Kuvyrkov", "email": "mkuvyrkov@gcc.gnu.org", "date": "2007-08-14T06:40:34Z"}, "message": "sched-int.h (struct _dep): Rename field 'kind' to 'type'.\n\n\t* sched-int.h (struct _dep): Rename field 'kind' to 'type'.\n\t(DEP_KIND): Rename to DEP_TYPE.  Update all uses.\n\t(dep_def): New typedef.\n\t(init_dep_1, sd_debug_dep): Declare functions.\n\t(DEP_LINK_KIND): Rename to DEP_LINK_TYPE.\n\t(debug_dep_links): Remove.\n\t(struct _deps_list): New field 'n_links'.\n\t(DEPS_LIST_N_LINKS): New macro.\n\t(FOR_EACH_DEP_LINK): Remove.\n\t(create_deps_list, free_deps_list, delete_deps_list): Remove\n\tdeclaration.\n\t(deps_list_empty_p, debug_deps_list, add_back_dep_to_deps_list): Ditto.\n\t(find_link_by_pro_in_deps_list, find_link_by_con_in_deps_list): Ditto.\n\t(copy_deps_list_change_con, move_dep_link): Ditto.\n\t(struct haifa_insn_data): Split field 'back_deps' into 'hard_back_deps'\n\tand 'spec_back_deps'.  New field 'resolved_forw_deps'.  Remove field\n\t'dep_count'.\n\t(INSN_BACK_DEPS): Remove.\n\t(INSN_HARD_BACK_DEPS, INSN_SPEC_BACK_DEPS, INSN_RESOLVED_FORW_DEPS):\n\tNew macros.\n\t(INSN_DEP_COUNT): Remove.\n\t(enum DEPS_ADJUST_RESULT): Add new constant DEP_NODEP.  Fix comments.\n\t(spec_info, haifa_recovery_block_was_added_during_scheduling_p):\n\tDeclare global variables.\n\t(deps_pools_are_empty_p, sched_free_deps): Declare functions.\n\t(add_forw_dep, compute_forward_dependences): Remove declarations.\n\t(add_or_update_back_dep, add_or_update_back_forw_dep): Ditto.\n\t(add_back_forw_dep, delete_back_forw_dep): Ditto.\n\t(debug_ds, sched_insn_is_legitimate_for_speculation_p): Declare\n\tfunctions.\n\t(SD_LIST_NONE, SD_LIST_HARD_BACK, SD_LIST_SPEC_BACK, SD_LIST_FORW): New\n\tconstants.\n\t(SD_LIST_RES_BACK, SD_LIST_RES_FORW, SD_LIST_BACK): Ditto.\n\t(sd_list_types_def): New typedef.\n\t(sd_next_list): Declare function.\n\t(struct _sd_iterator): New type.\n\t(sd_iterator_def): New typedef.\n\t(sd_iterator_start, sd_iterator_cond, sd_iterator_next): New inline\n\tfunctions.\n\t(FOR_EACH_DEP): New cycle wrapper.\n\t(sd_lists_size, sd_lists_empty_p, sd_init_insn, sd_finish_insn):\n\tDeclare functions.\n\t(sd_find_dep_between, sd_add_dep, sd_add_or_update_dep): Ditto.\n\t(sd_resolve_dep, sd_copy_back_deps, sd_delete_dep, sd_debug_lists):\n\tDitto.\n\n\t* sched-deps.c (init_dep_1): Make global.\n\t(DUMP_DEP_PRO, DUMP_DEP_CON, DUMP_DEP_STATUS, DUMP_DEP_ALL): New\n\tconstants.\n\t(dump_dep): New static function.\n\t(dump_dep_flags): New static variable.\n\t(sd_debug_dep): New function.\n\t(add_to_deps_list, remove_from_deps_list): Update 'n_links' field of\n\tthe list.\n\t(move_dep_link): Use remove_from_deps_list (), instead of\n\tdetach_dep_link ().\n\t(dep_links_consistent_p, dump_dep_links, debug_dep_links): Remove.\n\t(dep_link_is_detached_p): New static function.\n\t(deps_obstack, dl_obstack, dn_obstack): Remove.  Use dn_pool, dl_pool\n\tinstead.\n\t(dn_pool, dl_pool): New alloc_pools.\n\t(dn_pool_diff, dl_pool_diff): New static variables.\n\t(create_dep_node, delete_dep_node): New static function.\n\t(create_deps_list): Make it static.  Use alloc_pool 'dl_pool'.\n\t(deps_list_empty_p): Make it static.  Use 'n_links' field.\n\t(deps_pools_are_empty_p): New static function.\n\t(alloc_deps_list, delete_deps_list): Remove.\n\t(dump_deps_list, debug_deps_list, add_back_dep_to_deps_list): Remove.\n\t(find_link_by_pro_in_deps_list, find_link_by_con_in_deps_list): Ditto.\n\t(copy_deps_list_change_con): Remove.  Use sd_copy_back_deps () instead.\n\t(forward_dependency_cache): Remove.\n\t(maybe_add_or_update_back_dep_1, add_or_update_back_dep_1): Remove\n\t'back' from the names.  Change signature to use dep_t instead of\n\tequivalent quad.\n\t(add_back_dep): Ditto.  Make global.\n\t(check_dep_status): Rename to check_dep ().\n\t(sd_next_list, sd_lists_size, sd_lists_empty_p, sd_init_insn):\n\tNew functions.\n\t(sd_finish_insn): Ditto.\n\t(sd_find_dep_between_no_cache): New static function.\n\t(sd_find_dep_between): New function.\n\t(ask_dependency_caches, set_dependency_caches): New static functions.\n\t(update_dependency_caches, change_spec_dep_to_hard, update_dep): Ditto.\n\t(add_or_update_dep_1): Separate pieces of functionality into\n\task_dependency_caches (), update_dependency_caches (),\n\tchange_spec_dep_to_hard (), update_dep ().\n\t(get_back_and_forw_lists): New static function.\n\t(sd_add_dep): Separate setting of dependency caches into\n\tset_dependency_caches ().\n\t(sd_add_or_update_dep, sd_resolve_dep, sd_copy_back_deps):\n\tNew functions.\n\t(sd_delete_dep): Ditto.\n\t(DUMP_LISTS_SIZE, DUMP_LISTS_DEPS, DUMP_LISTS_ALL): New constants.\n\t(dump_lists): New static function.\n\t(sd_debug_lists): New debug function.\n\t(delete_all_dependences, fixup_sched_groups): Update to use\n\tsd_* infrastructure.\n\t(sched_analyze_2): Create data-speculative dependency only if\n\tdata-speculation is enabled.\n\t(sched_analyze_insn): If insn cannot be speculative, make all its\n\tdependencies non-speculative.\n\t(sched_analyze): Use sd_init_insn ().\n\t(add_forw_dep, compute_forward_dependencies): Remove.\n\t(delete_dep_nodes_in_back_deps): New static function.\n\t(sched_free_deps): New function.\n\t(init_dependency_caches): Init alloc_pools.\n\t(extend_depedency_caches): Update after removing of\n\tforward_dependency_cache.\n\t(free_dependency_caches): Ditto.  Free alloc_pools.\n\t(adjust_add_sorted_back_dep, adjust_back_add_forw_dep): Remove.\n\t(delete_forw_dep, add_or_update_back_dep, add_or_update_back_forw_dep):\n\tDitto.\n\t(add_back_forw_dep, delete_back_forw_dep): Ditto.\n\t(add_dependence): Use init_dep ().\n\t(get_dep_weak_1): New static function.\n\t(get_dep_weak): Move logic to get_dep_weak_1 ().\n\t(dump_ds): New static function moved from haifa-sched.c:\n\tdebug_spec_status ().\n\t(debug_ds): New debug function.\n\t(check_dep_status): Rename to check_dep ().  Update to check whole\n\tdependencies.\n\n\t* haifa-sched.c (spec_info): Make global.\n\t(added_recovery_block_p): Rename to\n\t'haifa_recovery_block_was_added_during_current_schedule_block_p'.\n\t(haifa_recovery_block_was_added_during_scheduling_p): New variable.\n\t(dep_cost, priority, rank_for_schedule, schedule_insn): Update\n\tto use new interfaces.\n\t(ok_for_early_queue_removal): Ditto.\n\t(schedule_block): Initialize logical uids of insns emitted by the\n\ttarget.\n\t(sched_init): Initialize new variable.\n\t(fix_inter_tick, try_ready, fix_tick_ready): Update to use new\n\tinterfaces.\n\t(extend_global): Initialize insn data.\n\t(init_h_i_d): Remove code that is now handled in sd_init_insn ().\n\t(process_insn_forw_deps_be_in_spec): Change signature.  Update to use\n\tnew interfaces.\n\t(add_to_speculative_block): Update to use new interfaces.\n\t(create_recovery_block): Set new variables.\n\t(create_check_block_twin, fix_recovery_deps): Update to use new\n\tinterfaces.\n\t(sched_insn_is_legitimate_for_speculation_p): New function.\n\t(speculate_insn): Move checking logic to\n\tsched_insn_is_legitimate_for_speculation_p ().\n\t(sched_remove_insn): Finalize sched-deps information of instruction.\n\t(clear_priorities, add_jump_dependencies): Update to use new\n\tinterfaces.\n\t(debug_spec_status): Rename to dump_ds () and move to sched-deps.c.\n\t\n\t* sched-rgn.c (set_spec_fed, find_conditional_protection): Update\n\tto use new interfaces.\n\t(is_conditionally_protected, is_pfree, is_prisky) Ditto.\n\t(new_ready): Try to use control speculation only if it is available.\n\t(add_branch_dependences): Update to use new interfaces.\n\t(compute_block_backward_dependences): Rename to\n\tcompute_block_dependences ().  Call\n\ttargetm.sched.dependencies_evaluation_hook ().\n\t(free_block_dependencies): New static function.\n\t(debug_dependencies): Update to use new interfaces.\n\t(schedule_region): Remove separate computation of forward dependencies.\n\tMove call of targetm.sched.dependencies_evaluation_hook () to\n\tcompute_block_dependences ().  Free dependencies at the end of\n\tscheduling the region.\n\n\t* sched-ebb.c (earliest_block_with_similiar_load): Update to use\n\tnew interfaces.\n\t(add_deps_for_risky_insns): Ditto.\n\t(schedule_ebb): Remove separate computation of forward dependencies.\n\tFree dependencies at the end of\tscheduling the ebb.\n\n\t* ddg.c (create_ddg_dependence): Update to use new interfaces.\n\t(build_intra_loop_deps): Ditto.  Remove separate computation of forward\n\tdependencies.  Free sched-deps dependencies.\n\n\t* config/ia64/ia64.c (ia64_dependencies_evaluation_hook): Update\n\tto use new interfaces.\n\t(ia64_dfa_new_cycle, ia64_gen_check): Ditto.\n\n\t* config/rs6000/rs6000.c (rs6000_is_costly_dependence): Update to use\n\tnew interfaces.\n\t(is_costly_group): Ditto.\n\nFrom-SVN: r127405", "tree": {"sha": "d517b0ed31fd405d601bc3b37c58e656d118405d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/d517b0ed31fd405d601bc3b37c58e656d118405d"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e2f6ff946a121528203fcbde68fdd58942f9a57b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e2f6ff946a121528203fcbde68fdd58942f9a57b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e2f6ff946a121528203fcbde68fdd58942f9a57b", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e2f6ff946a121528203fcbde68fdd58942f9a57b/comments", "author": null, "committer": null, "parents": [{"sha": "ed7a4b4b30c6054ef0500d2fde45beba399da929", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ed7a4b4b30c6054ef0500d2fde45beba399da929", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ed7a4b4b30c6054ef0500d2fde45beba399da929"}], "stats": {"total": 3045, "additions": 1854, "deletions": 1191}, "files": [{"sha": "08c819d6b492d587313d61ff85806c1de8fdeee5", "filename": "gcc/ChangeLog", "status": "modified", "additions": 185, "deletions": 0, "changes": 185, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=e2f6ff946a121528203fcbde68fdd58942f9a57b", "patch": "@@ -1,3 +1,188 @@\n+2007-08-14  Maxim Kuvyrkov  <maxim@codesourcery.com>\n+\n+\t* sched-int.h (struct _dep): Rename field 'kind' to 'type'.\n+\t(DEP_KIND): Rename to DEP_TYPE.  Update all uses.\n+\t(dep_def): New typedef.\n+\t(init_dep_1, sd_debug_dep): Declare functions.\n+\t(DEP_LINK_KIND): Rename to DEP_LINK_TYPE.\n+\t(debug_dep_links): Remove.\n+\t(struct _deps_list): New field 'n_links'.\n+\t(DEPS_LIST_N_LINKS): New macro.\n+\t(FOR_EACH_DEP_LINK): Remove.\n+\t(create_deps_list, free_deps_list, delete_deps_list): Remove\n+\tdeclaration.\n+\t(deps_list_empty_p, debug_deps_list, add_back_dep_to_deps_list): Ditto.\n+\t(find_link_by_pro_in_deps_list, find_link_by_con_in_deps_list): Ditto.\n+\t(copy_deps_list_change_con, move_dep_link): Ditto.\n+\t(struct haifa_insn_data): Split field 'back_deps' into 'hard_back_deps'\n+\tand 'spec_back_deps'.  New field 'resolved_forw_deps'.  Remove field\n+\t'dep_count'.\n+\t(INSN_BACK_DEPS): Remove.\n+\t(INSN_HARD_BACK_DEPS, INSN_SPEC_BACK_DEPS, INSN_RESOLVED_FORW_DEPS):\n+\tNew macros.\n+\t(INSN_DEP_COUNT): Remove.\n+\t(enum DEPS_ADJUST_RESULT): Add new constant DEP_NODEP.  Fix comments.\n+\t(spec_info, haifa_recovery_block_was_added_during_scheduling_p):\n+\tDeclare global variables.\n+\t(deps_pools_are_empty_p, sched_free_deps): Declare functions.\n+\t(add_forw_dep, compute_forward_dependences): Remove declarations.\n+\t(add_or_update_back_dep, add_or_update_back_forw_dep): Ditto.\n+\t(add_back_forw_dep, delete_back_forw_dep): Ditto.\n+\t(debug_ds, sched_insn_is_legitimate_for_speculation_p): Declare\n+\tfunctions.\n+\t(SD_LIST_NONE, SD_LIST_HARD_BACK, SD_LIST_SPEC_BACK, SD_LIST_FORW): New\n+\tconstants.\n+\t(SD_LIST_RES_BACK, SD_LIST_RES_FORW, SD_LIST_BACK): Ditto.\n+\t(sd_list_types_def): New typedef.\n+\t(sd_next_list): Declare function.\n+\t(struct _sd_iterator): New type.\n+\t(sd_iterator_def): New typedef.\n+\t(sd_iterator_start, sd_iterator_cond, sd_iterator_next): New inline\n+\tfunctions.\n+\t(FOR_EACH_DEP): New cycle wrapper.\n+\t(sd_lists_size, sd_lists_empty_p, sd_init_insn, sd_finish_insn):\n+\tDeclare functions.\n+\t(sd_find_dep_between, sd_add_dep, sd_add_or_update_dep): Ditto.\n+\t(sd_resolve_dep, sd_copy_back_deps, sd_delete_dep, sd_debug_lists):\n+\tDitto.\n+\n+\t* sched-deps.c (init_dep_1): Make global.\n+\t(DUMP_DEP_PRO, DUMP_DEP_CON, DUMP_DEP_STATUS, DUMP_DEP_ALL): New\n+\tconstants.\n+\t(dump_dep): New static function.\n+\t(dump_dep_flags): New static variable.\n+\t(sd_debug_dep): New function.\n+\t(add_to_deps_list, remove_from_deps_list): Update 'n_links' field of\n+\tthe list.\n+\t(move_dep_link): Use remove_from_deps_list (), instead of\n+\tdetach_dep_link ().\n+\t(dep_links_consistent_p, dump_dep_links, debug_dep_links): Remove.\n+\t(dep_link_is_detached_p): New static function.\n+\t(deps_obstack, dl_obstack, dn_obstack): Remove.  Use dn_pool, dl_pool\n+\tinstead.\n+\t(dn_pool, dl_pool): New alloc_pools.\n+\t(dn_pool_diff, dl_pool_diff): New static variables.\n+\t(create_dep_node, delete_dep_node): New static function.\n+\t(create_deps_list): Make it static.  Use alloc_pool 'dl_pool'.\n+\t(deps_list_empty_p): Make it static.  Use 'n_links' field.\n+\t(deps_pools_are_empty_p): New static function.\n+\t(alloc_deps_list, delete_deps_list): Remove.\n+\t(dump_deps_list, debug_deps_list, add_back_dep_to_deps_list): Remove.\n+\t(find_link_by_pro_in_deps_list, find_link_by_con_in_deps_list): Ditto.\n+\t(copy_deps_list_change_con): Remove.  Use sd_copy_back_deps () instead.\n+\t(forward_dependency_cache): Remove.\n+\t(maybe_add_or_update_back_dep_1, add_or_update_back_dep_1): Remove\n+\t'back' from the names.  Change signature to use dep_t instead of\n+\tequivalent quad.\n+\t(add_back_dep): Ditto.  Make global.\n+\t(check_dep_status): Rename to check_dep ().\n+\t(sd_next_list, sd_lists_size, sd_lists_empty_p, sd_init_insn):\n+\tNew functions.\n+\t(sd_finish_insn): Ditto.\n+\t(sd_find_dep_between_no_cache): New static function.\n+\t(sd_find_dep_between): New function.\n+\t(ask_dependency_caches, set_dependency_caches): New static functions.\n+\t(update_dependency_caches, change_spec_dep_to_hard, update_dep): Ditto.\n+\t(add_or_update_dep_1): Separate pieces of functionality into\n+\task_dependency_caches (), update_dependency_caches (),\n+\tchange_spec_dep_to_hard (), update_dep ().\n+\t(get_back_and_forw_lists): New static function.\n+\t(sd_add_dep): Separate setting of dependency caches into\n+\tset_dependency_caches ().\n+\t(sd_add_or_update_dep, sd_resolve_dep, sd_copy_back_deps):\n+\tNew functions.\n+\t(sd_delete_dep): Ditto.\n+\t(DUMP_LISTS_SIZE, DUMP_LISTS_DEPS, DUMP_LISTS_ALL): New constants.\n+\t(dump_lists): New static function.\n+\t(sd_debug_lists): New debug function.\n+\t(delete_all_dependences, fixup_sched_groups): Update to use\n+\tsd_* infrastructure.\n+\t(sched_analyze_2): Create data-speculative dependency only if\n+\tdata-speculation is enabled.\n+\t(sched_analyze_insn): If insn cannot be speculative, make all its\n+\tdependencies non-speculative.\n+\t(sched_analyze): Use sd_init_insn ().\n+\t(add_forw_dep, compute_forward_dependencies): Remove.\n+\t(delete_dep_nodes_in_back_deps): New static function.\n+\t(sched_free_deps): New function.\n+\t(init_dependency_caches): Init alloc_pools.\n+\t(extend_depedency_caches): Update after removing of\n+\tforward_dependency_cache.\n+\t(free_dependency_caches): Ditto.  Free alloc_pools.\n+\t(adjust_add_sorted_back_dep, adjust_back_add_forw_dep): Remove.\n+\t(delete_forw_dep, add_or_update_back_dep, add_or_update_back_forw_dep):\n+\tDitto.\n+\t(add_back_forw_dep, delete_back_forw_dep): Ditto.\n+\t(add_dependence): Use init_dep ().\n+\t(get_dep_weak_1): New static function.\n+\t(get_dep_weak): Move logic to get_dep_weak_1 ().\n+\t(dump_ds): New static function moved from haifa-sched.c:\n+\tdebug_spec_status ().\n+\t(debug_ds): New debug function.\n+\t(check_dep_status): Rename to check_dep ().  Update to check whole\n+\tdependencies.\n+\n+\t* haifa-sched.c (spec_info): Make global.\n+\t(added_recovery_block_p): Rename to\n+\t'haifa_recovery_block_was_added_during_current_schedule_block_p'.\n+\t(haifa_recovery_block_was_added_during_scheduling_p): New variable.\n+\t(dep_cost, priority, rank_for_schedule, schedule_insn): Update\n+\tto use new interfaces.\n+\t(ok_for_early_queue_removal): Ditto.\n+\t(schedule_block): Initialize logical uids of insns emitted by the\n+\ttarget.\n+\t(sched_init): Initialize new variable.\n+\t(fix_inter_tick, try_ready, fix_tick_ready): Update to use new\n+\tinterfaces.\n+\t(extend_global): Initialize insn data.\n+\t(init_h_i_d): Remove code that is now handled in sd_init_insn ().\n+\t(process_insn_forw_deps_be_in_spec): Change signature.  Update to use\n+\tnew interfaces.\n+\t(add_to_speculative_block): Update to use new interfaces.\n+\t(create_recovery_block): Set new variables.\n+\t(create_check_block_twin, fix_recovery_deps): Update to use new\n+\tinterfaces.\n+\t(sched_insn_is_legitimate_for_speculation_p): New function.\n+\t(speculate_insn): Move checking logic to\n+\tsched_insn_is_legitimate_for_speculation_p ().\n+\t(sched_remove_insn): Finalize sched-deps information of instruction.\n+\t(clear_priorities, add_jump_dependencies): Update to use new\n+\tinterfaces.\n+\t(debug_spec_status): Rename to dump_ds () and move to sched-deps.c.\n+\t\n+\t* sched-rgn.c (set_spec_fed, find_conditional_protection): Update\n+\tto use new interfaces.\n+\t(is_conditionally_protected, is_pfree, is_prisky) Ditto.\n+\t(new_ready): Try to use control speculation only if it is available.\n+\t(add_branch_dependences): Update to use new interfaces.\n+\t(compute_block_backward_dependences): Rename to\n+\tcompute_block_dependences ().  Call\n+\ttargetm.sched.dependencies_evaluation_hook ().\n+\t(free_block_dependencies): New static function.\n+\t(debug_dependencies): Update to use new interfaces.\n+\t(schedule_region): Remove separate computation of forward dependencies.\n+\tMove call of targetm.sched.dependencies_evaluation_hook () to\n+\tcompute_block_dependences ().  Free dependencies at the end of\n+\tscheduling the region.\n+\n+\t* sched-ebb.c (earliest_block_with_similiar_load): Update to use\n+\tnew interfaces.\n+\t(add_deps_for_risky_insns): Ditto.\n+\t(schedule_ebb): Remove separate computation of forward dependencies.\n+\tFree dependencies at the end of\tscheduling the ebb.\n+\n+\t* ddg.c (create_ddg_dependence): Update to use new interfaces.\n+\t(build_intra_loop_deps): Ditto.  Remove separate computation of forward\n+\tdependencies.  Free sched-deps dependencies.\n+\n+\t* config/ia64/ia64.c (ia64_dependencies_evaluation_hook): Update\n+\tto use new interfaces.\n+\t(ia64_dfa_new_cycle, ia64_gen_check): Ditto.\n+\n+\t* config/rs6000/rs6000.c (rs6000_is_costly_dependence): Update to use\n+\tnew interfaces.\n+\t(is_costly_group): Ditto.\n+\n 2007-08-14  Kaveh R. Ghazi  <ghazi@caip.rutgers.edu>\n \n \t* alias.c (rtx_equal_for_memref_p): Constify."}, {"sha": "bb5515169a31b2f2655b5894c4db1a6c50e1cd55", "filename": "gcc/config/ia64/ia64.c", "status": "modified", "additions": 25, "deletions": 14, "changes": 39, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fconfig%2Fia64%2Fia64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fconfig%2Fia64%2Fia64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fia64%2Fia64.c?ref=e2f6ff946a121528203fcbde68fdd58942f9a57b", "patch": "@@ -6341,28 +6341,37 @@ ia64_dependencies_evaluation_hook (rtx head, rtx tail)\n     if (INSN_P (insn)\n \t&& ia64_safe_itanium_class (insn) == ITANIUM_CLASS_IALU)\n       {\n-\tdep_link_t link;\n+\tsd_iterator_def sd_it;\n+\tdep_t dep;\n+\tbool has_mem_op_consumer_p = false;\n \n-\tFOR_EACH_DEP_LINK (link, INSN_FORW_DEPS (insn))\n+\tFOR_EACH_DEP (insn, SD_LIST_FORW, sd_it, dep)\n \t  {\n \t    enum attr_itanium_class c;\n \n-\t    if (DEP_LINK_KIND (link) != REG_DEP_TRUE)\n+\t    if (DEP_TYPE (dep) != REG_DEP_TRUE)\n \t      continue;\n \n-\t    next = DEP_LINK_CON (link);\n+\t    next = DEP_CON (dep);\n \t    c = ia64_safe_itanium_class (next);\n \t    if ((c == ITANIUM_CLASS_ST\n \t\t || c == ITANIUM_CLASS_STF)\n \t\t&& ia64_st_address_bypass_p (insn, next))\n-\t      break;\n+\t      {\n+\t\thas_mem_op_consumer_p = true;\n+\t\tbreak;\n+\t      }\n \t    else if ((c == ITANIUM_CLASS_LD\n \t\t      || c == ITANIUM_CLASS_FLD\n \t\t      || c == ITANIUM_CLASS_FLDP)\n \t\t     && ia64_ld_address_bypass_p (insn, next))\n-\t      break;\n+\t      {\n+\t\thas_mem_op_consumer_p = true;\n+\t\tbreak;\n+\t      }\n \t  }\n-\tinsn->call = link != 0;\n+\n+\tinsn->call = has_mem_op_consumer_p;\n       }\n }\n \n@@ -6639,14 +6648,15 @@ ia64_dfa_new_cycle (FILE *dump, int verbose, rtx insn, int last_clock,\n \n       if (c != ITANIUM_CLASS_MMMUL && c != ITANIUM_CLASS_MMSHF)\n \t{\n-\t  dep_link_t link;\n+\t  sd_iterator_def sd_it;\n+\t  dep_t dep;\n \t  int d = -1;\n \n-\t  FOR_EACH_DEP_LINK (link, INSN_BACK_DEPS (insn))\n-\t    if (DEP_LINK_KIND (link) == REG_DEP_TRUE)\n+\t  FOR_EACH_DEP (insn, SD_LIST_BACK, sd_it, dep)\n+\t    if (DEP_TYPE (dep) == REG_DEP_TRUE)\n \t      {\n \t\tenum attr_itanium_class dep_class;\n-\t\trtx dep_insn = DEP_LINK_PRO (link);\n+\t\trtx dep_insn = DEP_PRO (dep);\n \n \t\tdep_class = ia64_safe_itanium_class (dep_insn);\n \t\tif ((dep_class == ITANIUM_CLASS_MMMUL\n@@ -7177,13 +7187,14 @@ ia64_gen_check (rtx insn, rtx label, bool mutate_p)\n        As long as patterns are unique for each instruction, this can be\n        accomplished by matching ORIG_PAT fields.  */\n     {\n-      dep_link_t link;\n+      sd_iterator_def sd_it;\n+      dep_t dep;\n       int check_no = 0;\n       rtx orig_pat = ORIG_PAT (insn);\n \n-      FOR_EACH_DEP_LINK (link, INSN_RESOLVED_BACK_DEPS (insn))\n+      FOR_EACH_DEP (insn, SD_LIST_RES_BACK, sd_it, dep)\n \t{\n-\t  rtx x = DEP_LINK_PRO (link);\n+\t  rtx x = DEP_PRO (dep);\n \n \t  if (ORIG_PAT (x) == orig_pat)\n \t    check_no = spec_check_no[INSN_UID (x)];"}, {"sha": "dc53ef9d73b6ee9a7c49f5cc00ee42b0ae7e13d8", "filename": "gcc/config/rs6000/rs6000.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fconfig%2Frs6000%2Frs6000.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fconfig%2Frs6000%2Frs6000.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.c?ref=e2f6ff946a121528203fcbde68fdd58942f9a57b", "patch": "@@ -17951,7 +17951,7 @@ rs6000_is_costly_dependence (dep_t dep, int cost, int distance)\n   if (rs6000_sched_costly_dep == true_store_to_load_dep_costly\n       && is_load_insn (next)\n       && is_store_insn (insn)\n-      && DEP_KIND (dep) == REG_DEP_TRUE)\n+      && DEP_TYPE (dep) == REG_DEP_TRUE)\n      /* Prevent load after store in the same group if it is a true\n \tdependence.  */\n      return true;\n@@ -18427,15 +18427,15 @@ is_costly_group (rtx *group_insns, rtx next_insn)\n \n   for (i = 0; i < issue_rate; i++)\n     {\n-      dep_link_t link;\n+      sd_iterator_def sd_it;\n+      dep_t dep;\n       rtx insn = group_insns[i];\n \n       if (!insn)\n \tcontinue;\n \n-      FOR_EACH_DEP_LINK (link, INSN_FORW_DEPS (insn))\n+      FOR_EACH_DEP (insn, SD_LIST_FORW, sd_it, dep)\n \t{\n-\t  dep_t dep = DEP_LINK_DEP (link);\n \t  rtx next = DEP_CON (dep);\n \n \t  if (next == next_insn"}, {"sha": "295811db4c158deb585aba95014f6bc304fd9e46", "filename": "gcc/ddg.c", "status": "modified", "additions": 8, "deletions": 6, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fddg.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fddg.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fddg.c?ref=e2f6ff946a121528203fcbde68fdd58942f9a57b", "patch": "@@ -159,9 +159,9 @@ create_ddg_dep_from_intra_loop_link (ddg_ptr g, ddg_node_ptr src_node,\n   gcc_assert (link);\n \n   /* Note: REG_DEP_ANTI applies to MEM ANTI_DEP as well!!  */\n-  if (DEP_KIND (link) == REG_DEP_ANTI)\n+  if (DEP_TYPE (link) == REG_DEP_ANTI)\n     t = ANTI_DEP;\n-  else if (DEP_KIND (link) == REG_DEP_OUTPUT)\n+  else if (DEP_TYPE (link) == REG_DEP_OUTPUT)\n     t = OUTPUT_DEP;\n \n   /* We currently choose not to create certain anti-deps edges and\n@@ -368,7 +368,6 @@ build_intra_loop_deps (ddg_ptr g)\n   /* Hold the dependency analysis state during dependency calculations.  */\n   struct deps tmp_deps;\n   rtx head, tail;\n-  dep_link_t link;\n \n   /* Build the dependence information, using the sched_analyze function.  */\n   init_deps_global ();\n@@ -383,19 +382,19 @@ build_intra_loop_deps (ddg_ptr g)\n   for (i = 0; i < g->num_nodes; i++)\n     {\n       ddg_node_ptr dest_node = &g->nodes[i];\n+      sd_iterator_def sd_it;\n+      dep_t dep;\n \n       if (! INSN_P (dest_node->insn))\n \tcontinue;\n \n-      FOR_EACH_DEP_LINK (link, INSN_BACK_DEPS (dest_node->insn))\n+      FOR_EACH_DEP (dest_node->insn, SD_LIST_BACK, sd_it, dep)\n \t{\n-\t  dep_t dep = DEP_LINK_DEP (link);\n \t  ddg_node_ptr src_node = get_node_of_insn (g, DEP_PRO (dep));\n \n \t  if (!src_node)\n \t    continue;\n \n-      \t  add_forw_dep (link);\n \t  create_ddg_dep_from_intra_loop_link (g, src_node, dest_node, dep);\n \t}\n \n@@ -420,6 +419,9 @@ build_intra_loop_deps (ddg_ptr g)\n   /* Free the INSN_LISTs.  */\n   finish_deps_global ();\n   free_deps (&tmp_deps);\n+\n+  /* Free dependencies.  */\n+  sched_free_deps (head, tail, false);\n }\n \n "}, {"sha": "d9a8f782a64f9c377384ca8d527445b9f341a1f4", "filename": "gcc/haifa-sched.c", "status": "modified", "additions": 309, "deletions": 279, "changes": 588, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fhaifa-sched.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fhaifa-sched.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhaifa-sched.c?ref=e2f6ff946a121528203fcbde68fdd58942f9a57b", "patch": "@@ -206,11 +206,16 @@ static rtx note_list;\n static struct spec_info_def spec_info_var;\n /* Description of the speculative part of the scheduling.\n    If NULL - no speculation.  */\n-static spec_info_t spec_info;\n+spec_info_t spec_info;\n \n /* True, if recovery block was added during scheduling of current block.\n    Used to determine, if we need to fix INSN_TICKs.  */\n-static bool added_recovery_block_p;\n+static bool haifa_recovery_bb_recently_added_p;\n+\n+/* True, if recovery block was added during this scheduling pass.\n+   Used to determine if we should have empty memory pools of dependencies\n+   after finishing current region.  */\n+bool haifa_recovery_bb_ever_added_p;\n \n /* Counters of different types of speculative instructions.  */\n static int nr_begin_data, nr_be_in_data, nr_begin_control, nr_be_in_control;\n@@ -553,7 +558,7 @@ static void extend_global (rtx);\n static void extend_all (rtx);\n static void init_h_i_d (rtx);\n static void generate_recovery_code (rtx);\n-static void process_insn_forw_deps_be_in_spec (deps_list_t, rtx, ds_t);\n+static void process_insn_forw_deps_be_in_spec (rtx, rtx, ds_t);\n static void begin_speculative_block (rtx);\n static void add_to_speculative_block (rtx);\n static dw_t dep_weak (ds_t);\n@@ -654,7 +659,7 @@ dep_cost (dep_t link)\n   else\n     {\n       rtx insn = DEP_PRO (link);\n-      enum reg_note dep_type = DEP_KIND (link);\n+      enum reg_note dep_type = DEP_TYPE (link);\n \n       cost = insn_cost (insn);\n \n@@ -684,7 +689,7 @@ dep_cost (dep_t link)\n \t  XEXP (dep_cost_rtx_link, 1) = dep_cost_rtx_link;\n \n \t  /* Targets use only REG_NOTE_KIND of the link.  */\n-\t  PUT_REG_NOTE_KIND (dep_cost_rtx_link, DEP_KIND (link));\n+\t  PUT_REG_NOTE_KIND (dep_cost_rtx_link, DEP_TYPE (link));\n \n \t  cost = targetm.sched.adjust_cost (used, dep_cost_rtx_link,\n \t\t\t\t\t    insn, cost);\n@@ -726,8 +731,6 @@ contributes_to_priority_p (dep_t dep)\n static int\n priority (rtx insn)\n {\n-  dep_link_t link;\n-\n   if (! INSN_P (insn))\n     return 0;\n \n@@ -738,7 +741,7 @@ priority (rtx insn)\n     {\n       int this_priority = 0;\n \n-      if (deps_list_empty_p (INSN_FORW_DEPS (insn)))\n+      if (sd_lists_empty_p (insn, SD_LIST_FORW))\n \t/* ??? We should set INSN_PRIORITY to insn_cost when and insn has\n \t   some forward deps but all of them are ignored by\n \t   contributes_to_priority hook.  At the moment we set priority of\n@@ -769,11 +772,13 @@ priority (rtx insn)\n \n \t  do\n \t    {\n-\t      FOR_EACH_DEP_LINK (link, INSN_FORW_DEPS (twin))\n+\t      sd_iterator_def sd_it;\n+\t      dep_t dep;\n+\n+\t      FOR_EACH_DEP (twin, SD_LIST_FORW, sd_it, dep)\n \t\t{\n \t\t  rtx next;\n \t\t  int next_priority;\n-\t\t  dep_t dep = DEP_LINK_DEP (link);\n \n \t\t  next = DEP_CON (dep);\n \n@@ -832,7 +837,6 @@ rank_for_schedule (const void *x, const void *y)\n {\n   rtx tmp = *(const rtx *) y;\n   rtx tmp2 = *(const rtx *) x;\n-  dep_link_t link1, link2;\n   int tmp_class, tmp2_class;\n   int val, priority_val, weight_val, info_val;\n \n@@ -885,31 +889,30 @@ rank_for_schedule (const void *x, const void *y)\n   /* Compare insns based on their relation to the last-scheduled-insn.  */\n   if (INSN_P (last_scheduled_insn))\n     {\n+      dep_t dep1;\n+      dep_t dep2;\n+\n       /* Classify the instructions into three classes:\n          1) Data dependent on last schedule insn.\n          2) Anti/Output dependent on last scheduled insn.\n          3) Independent of last scheduled insn, or has latency of one.\n          Choose the insn from the highest numbered class if different.  */\n-      link1\n-\t= find_link_by_con_in_deps_list (INSN_FORW_DEPS (last_scheduled_insn),\n-\t\t\t\t\t tmp);\n+      dep1 = sd_find_dep_between (last_scheduled_insn, tmp, true);\n \n-      if (link1 == NULL || dep_cost (DEP_LINK_DEP (link1)) == 1)\n+      if (dep1 == NULL || dep_cost (dep1) == 1)\n \ttmp_class = 3;\n       else if (/* Data dependence.  */\n-\t       DEP_LINK_KIND (link1) == REG_DEP_TRUE)\n+\t       DEP_TYPE (dep1) == REG_DEP_TRUE)\n \ttmp_class = 1;\n       else\n \ttmp_class = 2;\n \n-      link2\n-\t= find_link_by_con_in_deps_list (INSN_FORW_DEPS (last_scheduled_insn),\n-\t\t\t\t\t tmp2);\n+      dep2 = sd_find_dep_between (last_scheduled_insn, tmp2, true);\n \n-      if (link2 == NULL || dep_cost (DEP_LINK_DEP (link2))  == 1)\n+      if (dep2 == NULL || dep_cost (dep2)  == 1)\n \ttmp2_class = 3;\n       else if (/* Data dependence.  */\n-\t       DEP_LINK_KIND (link2) == REG_DEP_TRUE)\n+\t       DEP_TYPE (dep2) == REG_DEP_TRUE)\n \ttmp2_class = 1;\n       else\n \ttmp2_class = 2;\n@@ -922,21 +925,11 @@ rank_for_schedule (const void *x, const void *y)\n      This gives the scheduler more freedom when scheduling later\n      instructions at the expense of added register pressure.  */\n \n-  link1 = DEPS_LIST_FIRST (INSN_FORW_DEPS (tmp));\n-  link2 = DEPS_LIST_FIRST (INSN_FORW_DEPS (tmp2));\n+  val = (sd_lists_size (tmp2, SD_LIST_FORW)\n+\t - sd_lists_size (tmp, SD_LIST_FORW));\n \n-  while (link1 != NULL && link2 != NULL)\n-    {\n-      link1 = DEP_LINK_NEXT (link1);\n-      link2 = DEP_LINK_NEXT (link2);\n-    }\n-\n-  if (link1 != NULL && link2 == NULL)\n-    /* TMP (Y) has more insns that depend on it.  */\n-    return -1;\n-  if (link1 == NULL && link2 != NULL)\n-    /* TMP2 (X) has more insns that depend on it.  */\n-    return 1;\n+  if (val != 0)\n+    return val;\n \n   /* If insns are equally good, sort by INSN_LUID (original insn order),\n      so that we make the sort stable.  This minimizes instruction movement,\n@@ -1172,7 +1165,8 @@ static int last_clock_var;\n static int\n schedule_insn (rtx insn)\n {\n-  dep_link_t link;\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n   int advance = 0;\n \n   if (sched_verbose >= 1)\n@@ -1192,12 +1186,7 @@ schedule_insn (rtx insn)\n \n   /* Scheduling instruction should have all its dependencies resolved and\n      should have been removed from the ready list.  */\n-  gcc_assert (INSN_DEP_COUNT (insn) == 0\n-\t      && deps_list_empty_p (INSN_BACK_DEPS (insn)));\n-  free_deps_list (INSN_BACK_DEPS (insn));\n-\n-  /* Now we can free INSN_RESOLVED_BACK_DEPS list.  */\n-  delete_deps_list (INSN_RESOLVED_BACK_DEPS (insn));\n+  gcc_assert (sd_lists_empty_p (insn, SD_LIST_BACK));\n \n   gcc_assert (QUEUE_INDEX (insn) == QUEUE_NOWHERE);\n   QUEUE_INDEX (insn) = QUEUE_SCHEDULED;\n@@ -1213,19 +1202,15 @@ schedule_insn (rtx insn)\n   INSN_TICK (insn) = clock_var;\n \n   /* Update dependent instructions.  */\n-  FOR_EACH_DEP_LINK (link, INSN_FORW_DEPS (insn))\n+  for (sd_it = sd_iterator_start (insn, SD_LIST_FORW);\n+       sd_iterator_cond (&sd_it, &dep);)\n     {\n-      rtx next = DEP_LINK_CON (link);\n-\n-      /* Resolve the dependence between INSN and NEXT.  */\n-\n-      INSN_DEP_COUNT (next)--;\n+      rtx next = DEP_CON (dep);\n \n-      move_dep_link (DEP_NODE_BACK (DEP_LINK_NODE (link)),\n-\t\t\tINSN_RESOLVED_BACK_DEPS (next));\n-\n-      gcc_assert ((INSN_DEP_COUNT (next) == 0)\n-\t\t  == deps_list_empty_p (INSN_BACK_DEPS (next)));\n+      /* Resolve the dependence between INSN and NEXT.\n+\t sd_resolve_dep () moves current dep to another list thus\n+\t advancing the iterator.  */\n+      sd_resolve_dep (sd_it);\n \n       if (!IS_SPECULATION_BRANCHY_CHECK_P (insn))\n \t{\n@@ -1242,11 +1227,23 @@ schedule_insn (rtx insn)\n \t/* Check always has only one forward dependence (to the first insn in\n \t   the recovery block), therefore, this will be executed only once.  */\n \t{\n-\t  gcc_assert (DEP_LINK_NEXT (link) == NULL);\n+\t  gcc_assert (sd_lists_empty_p (insn, SD_LIST_FORW));\n \t  fix_recovery_deps (RECOVERY_BLOCK (insn));\n \t}\n     }\n \n+  /* This is the place where scheduler doesn't *basically* need backward and\n+     forward dependencies for INSN anymore.  Nevertheless they are used in\n+     heuristics in rank_for_schedule (), early_queue_to_ready () and in\n+     some targets (e.g. rs6000).  Thus the earliest place where we *can*\n+     remove dependencies is after targetm.sched.md_finish () call in\n+     schedule_block ().  But, on the other side, the safest place to remove\n+     dependencies is when we are finishing scheduling entire region.  As we\n+     don't generate [many] dependencies during scheduling itself, we won't\n+     need memory until beginning of next region.\n+     Bottom line: Dependencies are removed for all insns in the end of\n+     scheduling the region.  */\n+\n   /* Annotate the instruction with issue information -- TImode\n      indicates that the instruction is expected not to be able\n      to issue on the same cycle as the previous insn.  A machine\n@@ -1589,15 +1586,12 @@ ok_for_early_queue_removal (rtx insn)\n \n \t      if (!NOTE_P (prev_insn))\n \t\t{\n-\t\t  dep_link_t dep_link;\n+\t\t  dep_t dep;\n \n-\t\t  dep_link = (find_link_by_con_in_deps_list\n-\t\t\t      (INSN_FORW_DEPS (prev_insn), insn));\n+\t\t  dep = sd_find_dep_between (prev_insn, insn, true);\n \n-\t\t  if (dep_link)\n+\t\t  if (dep != NULL)\n \t\t    {\n-\t\t      dep_t dep = DEP_LINK_DEP (dep_link);\n-\n \t\t      cost = dep_cost (dep);\n \n \t\t      if (targetm.sched.is_costly_dependence (dep, cost,\n@@ -2148,7 +2142,7 @@ schedule_block (basic_block *target_bb, int rgn_n_insns1)\n \n   gcc_assert (head != tail || INSN_P (head));\n \n-  added_recovery_block_p = false;\n+  haifa_recovery_bb_recently_added_p = false;\n \n   /* Debug info.  */\n   if (sched_verbose)\n@@ -2539,7 +2533,7 @@ schedule_block (basic_block *target_bb, int rgn_n_insns1)\n     }\n \n   if (!current_sched_info->queue_must_finish_empty\n-      || added_recovery_block_p)\n+      || haifa_recovery_bb_recently_added_p)\n     {\n       /* INSN_TICK (minimum clock tick at which the insn becomes\n          ready) may be not correct for the insn in the subsequent\n@@ -2551,7 +2545,15 @@ schedule_block (basic_block *target_bb, int rgn_n_insns1)\n     }\n \n   if (targetm.sched.md_finish)\n-    targetm.sched.md_finish (sched_dump, sched_verbose);\n+    {\n+      targetm.sched.md_finish (sched_dump, sched_verbose);\n+\n+      /* Target might have added some instructions to the scheduled block.\n+\t in its md_finish () hook.  These new insns don't have any data\n+\t initialized and to identify them we extend h_i_d so that they'll\n+\t get zero luids.*/\n+      extend_h_i_d ();\n+    }\n \n   /* Update head/tail boundaries.  */\n   head = NEXT_INSN (prev_head);\n@@ -2759,6 +2761,8 @@ sched_init (void)\n   nr_begin_data = nr_begin_control = nr_be_in_data = nr_be_in_control = 0;\n   before_recovery = 0;\n \n+  haifa_recovery_bb_ever_added_p = false;\n+\n #ifdef ENABLE_CHECKING\n   /* This is used preferably for finding bugs in check_cfg () itself.  */\n   check_cfg (0, 0);\n@@ -2817,6 +2821,10 @@ fix_inter_tick (rtx head, rtx tail)\n {\n   /* Set of instructions with corrected INSN_TICK.  */\n   bitmap_head processed;\n+  /* ??? It is doubtful if we should assume that cycle advance happens on\n+     basic block boundaries.  Basically insns that are unconditionally ready\n+     on the start of the block are more preferable then those which have\n+     a one cycle dependency over insn from the previous block.  */\n   int next_clock = clock_var + 1;\n \n   bitmap_initialize (&processed, 0);\n@@ -2829,7 +2837,8 @@ fix_inter_tick (rtx head, rtx tail)\n       if (INSN_P (head))\n \t{\n \t  int tick;\n-\t  dep_link_t link;\n+\t  sd_iterator_def sd_it;\n+\t  dep_t dep;\n                   \n \t  tick = INSN_TICK (head);\n \t  gcc_assert (tick >= MIN_TICK);\n@@ -2846,11 +2855,11 @@ fix_inter_tick (rtx head, rtx tail)\n \t      INSN_TICK (head) = tick;\t\t \n \t    }\n \t  \n-\t  FOR_EACH_DEP_LINK (link, INSN_FORW_DEPS (head))\n+\t  FOR_EACH_DEP (head, SD_LIST_RES_FORW, sd_it, dep)\n \t    {\n \t      rtx next;\n \t      \n-\t      next = DEP_LINK_CON (link);\n+\t      next = DEP_CON (dep);\n \t      tick = INSN_TICK (next);\n \n \t      if (tick != INVALID_TICK\n@@ -2869,7 +2878,7 @@ fix_inter_tick (rtx head, rtx tail)\n \t\t    INTER_TICK (next) = tick;\n \t\t  else\n \t\t    tick = INTER_TICK (next);\n-\t\t  \n+\n \t\t  INSN_TICK (next) = tick;\n \t\t}\n \t    }\n@@ -2888,7 +2897,6 @@ int\n try_ready (rtx next)\n {  \n   ds_t old_ts, *ts;\n-  dep_link_t link;\n \n   ts = &TODO_SPEC (next);\n   old_ts = *ts;\n@@ -2897,44 +2905,52 @@ try_ready (rtx next)\n \t      && ((old_ts & HARD_DEP)\n \t\t  || (old_ts & SPECULATIVE)));\n   \n-  if (!(current_sched_info->flags & DO_SPECULATION))\n+  if (sd_lists_empty_p (next, SD_LIST_BACK))\n+    /* NEXT has all its dependencies resolved.  */\n     {\n-      if (deps_list_empty_p (INSN_BACK_DEPS (next)))\n-        *ts &= ~HARD_DEP;\n+      /* Remove HARD_DEP bit from NEXT's status.  */\n+      *ts &= ~HARD_DEP;\n+\n+      if (current_sched_info->flags & DO_SPECULATION)\n+\t/* Remove all speculative bits from NEXT's status.  */\n+\t*ts &= ~SPECULATIVE;\n     }\n   else\n     {\n+      /* One of the NEXT's dependencies has been resolved.\n+\t Recalcute NEXT's status.  */\n+\n       *ts &= ~SPECULATIVE & ~HARD_DEP;\n \n-      link = DEPS_LIST_FIRST (INSN_BACK_DEPS (next));\n+      if (sd_lists_empty_p (next, SD_LIST_HARD_BACK))\n+\t/* Now we've got NEXT with speculative deps only.\n+\t   1. Look at the deps to see what we have to do.\n+\t   2. Check if we can do 'todo'.  */\n+\t{\n+\t  sd_iterator_def sd_it;\n+\t  dep_t dep;\n+\t  bool first_p = true;\n \n-      if (link != NULL)\n-        {\n-\t  ds_t ds = DEP_LINK_STATUS (link) & SPECULATIVE;\n-\n-          /* Backward dependencies of the insn are maintained sorted. \n-             So if DEP_STATUS of the first dep is SPECULATIVE,\n-             than all other deps are speculative too.  */\n-          if (ds != 0)\n-            {          \n-              /* Now we've got NEXT with speculative deps only.\n-                 1. Look at the deps to see what we have to do.\n-                 2. Check if we can do 'todo'.  */\n-\t      *ts = ds;\n-\n-              while ((link = DEP_LINK_NEXT (link)) != NULL)\n+\t  FOR_EACH_DEP (next, SD_LIST_BACK, sd_it, dep)\n+\t    {\n+\t      ds_t ds = DEP_STATUS (dep) & SPECULATIVE;\n+\n+\t      if (first_p)\n \t\t{\n-\t\t  ds = DEP_LINK_STATUS (link) & SPECULATIVE;\n-\t\t  *ts = ds_merge (*ts, ds);\n-\t\t}\n+\t\t  first_p = false;\n \n-\t      if (dep_weak (*ts) < spec_info->weakness_cutoff)\n-\t\t/* Too few points.  */\n-\t\t*ts = (*ts & ~SPECULATIVE) | HARD_DEP;\n+\t\t  *ts = ds;\n+\t\t}\n+\t      else\n+\t\t*ts = ds_merge (*ts, ds);\n \t    }\n-          else\n-            *ts |= HARD_DEP;\n-        }\n+\n+\t  if (dep_weak (*ts) < spec_info->weakness_cutoff)\n+\t    /* Too few points.  */\n+\t    *ts = (*ts & ~SPECULATIVE) | HARD_DEP;\n+\t}\n+      else\n+\t*ts |= HARD_DEP;\n     }\n \n   if (*ts & HARD_DEP)\n@@ -3053,20 +3069,20 @@ fix_tick_ready (rtx next)\n {\n   int tick, delay;\n \n-  if (!deps_list_empty_p (INSN_RESOLVED_BACK_DEPS (next)))\n+  if (!sd_lists_empty_p (next, SD_LIST_RES_BACK))\n     {\n       int full_p;\n-      dep_link_t link;\n+      sd_iterator_def sd_it;\n+      dep_t dep;\n \n       tick = INSN_TICK (next);\n       /* if tick is not equal to INVALID_TICK, then update\n \t INSN_TICK of NEXT with the most recent resolved dependence\n \t cost.  Otherwise, recalculate from scratch.  */\n       full_p = (tick == INVALID_TICK);\n \n-      FOR_EACH_DEP_LINK (link, INSN_RESOLVED_BACK_DEPS (next))\n+      FOR_EACH_DEP (next, SD_LIST_RES_BACK, sd_it, dep)\n         {       \n-\t  dep_t dep = DEP_LINK_DEP (link);\n           rtx pro = DEP_PRO (dep);\n           int tick1;\n               \n@@ -3180,11 +3196,18 @@ static void\n extend_global (rtx insn)\n {\n   gcc_assert (INSN_P (insn));\n+\n   /* These structures have scheduler scope.  */\n+\n+  /* Init h_i_d.  */\n   extend_h_i_d ();\n   init_h_i_d (insn);\n \n-  extend_dependency_caches (1, 0);\n+  /* Init data handled in sched-deps.c.  */\n+  sd_init_insn (insn);\n+\n+  /* Extend dependency caches by one element.  */\n+  extend_dependency_caches (1, false);\n }\n \n /* Extends global and local scheduler structures to include information\n@@ -3212,14 +3235,6 @@ init_h_i_d (rtx insn)\n   INSN_TICK (insn) = INVALID_TICK;\n   INTER_TICK (insn) = INVALID_TICK;\n   find_insn_reg_weight1 (insn);\n-\n-  /* These two lists will be freed in schedule_insn ().  */\n-  INSN_BACK_DEPS (insn) = create_deps_list (false);\n-  INSN_RESOLVED_BACK_DEPS (insn) = create_deps_list (false);\n-\n-  /* This one should be allocated on the obstack because it should live till\n-     the scheduling ends.  */\n-  INSN_FORW_DEPS (insn) = create_deps_list (true);\n }\n \n /* Generates recovery code for INSN.  */\n@@ -3240,18 +3255,19 @@ generate_recovery_code (rtx insn)\n    Tries to add speculative dependencies of type FS between instructions\n    in deps_list L and TWIN.  */\n static void\n-process_insn_forw_deps_be_in_spec (deps_list_t l, rtx twin, ds_t fs)\n+process_insn_forw_deps_be_in_spec (rtx insn, rtx twin, ds_t fs)\n {\n-  dep_link_t link;\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n \n-  FOR_EACH_DEP_LINK (link, l)\n+  FOR_EACH_DEP (insn, SD_LIST_FORW, sd_it, dep)\n     {\n       ds_t ds;\n       rtx consumer;\n \n-      consumer = DEP_LINK_CON (link);\n+      consumer = DEP_CON (dep);\n \n-      ds = DEP_LINK_STATUS (link);\n+      ds = DEP_STATUS (dep);\n \n       if (/* If we want to create speculative dep.  */\n \t  fs\n@@ -3278,7 +3294,12 @@ process_insn_forw_deps_be_in_spec (deps_list_t l, rtx twin, ds_t fs)\n \t    ds |= fs;\n \t}\n \n-      add_back_forw_dep (consumer, twin, DEP_LINK_KIND (link), ds);\n+      {\n+\tdep_def _new_dep, *new_dep = &_new_dep;\n+\n+\tinit_dep_1 (new_dep, twin, consumer, DEP_TYPE (dep), ds);\n+\tsd_add_dep (new_dep, false);\n+      }\n     }\n }\n \n@@ -3301,7 +3322,8 @@ static void\n add_to_speculative_block (rtx insn)\n {\n   ds_t ts;\n-  dep_link_t link;\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n   rtx twins = NULL;\n   rtx_vec_t priorities_roots;\n \n@@ -3319,50 +3341,52 @@ add_to_speculative_block (rtx insn)\n   DONE_SPEC (insn) |= ts;\n \n   /* First we convert all simple checks to branchy.  */\n-  for (link = DEPS_LIST_FIRST (INSN_BACK_DEPS (insn)); link != NULL;)\n+  for (sd_it = sd_iterator_start (insn, SD_LIST_SPEC_BACK);\n+       sd_iterator_cond (&sd_it, &dep);)\n     {\n-      rtx check = DEP_LINK_PRO (link);\n+      rtx check = DEP_PRO (dep);\n \n       if (IS_SPECULATION_SIMPLE_CHECK_P (check))\n \t{\n \t  create_check_block_twin (check, true);\n \n \t  /* Restart search.  */\n-\t  link = DEPS_LIST_FIRST (INSN_BACK_DEPS (insn));\n+\t  sd_it = sd_iterator_start (insn, SD_LIST_SPEC_BACK);\n \t}\n       else\n \t/* Continue search.  */\n-\tlink = DEP_LINK_NEXT (link);\n+\tsd_iterator_next (&sd_it);\n     }\n \n   priorities_roots = NULL;\n   clear_priorities (insn, &priorities_roots);\n- \n-  do\n+\n+  while (1)\n     {\n-      dep_link_t link;\n       rtx check, twin;\n       basic_block rec;\n \n-      link = DEPS_LIST_FIRST (INSN_BACK_DEPS (insn));\n+      /* Get the first backward dependency of INSN.  */\n+      sd_it = sd_iterator_start (insn, SD_LIST_SPEC_BACK);\n+      if (!sd_iterator_cond (&sd_it, &dep))\n+\t/* INSN has no backward dependencies left.  */\n+\tbreak;\n \n-      gcc_assert ((DEP_LINK_STATUS (link) & BEGIN_SPEC) == 0\n-\t\t  && (DEP_LINK_STATUS (link) & BE_IN_SPEC) != 0\n-\t\t  && (DEP_LINK_STATUS (link) & DEP_TYPES) == DEP_TRUE);\n+      gcc_assert ((DEP_STATUS (dep) & BEGIN_SPEC) == 0\n+\t\t  && (DEP_STATUS (dep) & BE_IN_SPEC) != 0\n+\t\t  && (DEP_STATUS (dep) & DEP_TYPES) == DEP_TRUE);\n \n-      check = DEP_LINK_PRO (link);\n+      check = DEP_PRO (dep);\n \n       gcc_assert (!IS_SPECULATION_CHECK_P (check) && !ORIG_PAT (check)\n \t\t  && QUEUE_INDEX (check) == QUEUE_NOWHERE);\n-      \n+\n       rec = BLOCK_FOR_INSN (check);\n-      \n+\n       twin = emit_insn_before (copy_insn (PATTERN (insn)), BB_END (rec));\n       extend_global (twin);\n \n-      copy_deps_list_change_con (INSN_RESOLVED_BACK_DEPS (twin),\n-\t\t\t\t INSN_RESOLVED_BACK_DEPS (insn),\n-\t\t\t\t twin);\n+      sd_copy_back_deps (twin, insn, true);\n \n       if (sched_verbose && spec_info->dump)\n         /* INSN_BB (insn) isn't determined for twin insns yet.\n@@ -3374,47 +3398,38 @@ add_to_speculative_block (rtx insn)\n \n       /* Add dependences between TWIN and all appropriate\n \t instructions from REC.  */\n-      do\n-\t{\t  \n-\t  add_back_forw_dep (twin, check, REG_DEP_TRUE, DEP_TRUE);\n-\t  \n-\t  do\t    \t  \n-\t    {  \n-\t      link = DEP_LINK_NEXT (link);\n+      FOR_EACH_DEP (insn, SD_LIST_SPEC_BACK, sd_it, dep)\n+\t{\n+\t  rtx pro = DEP_PRO (dep);\n \n-\t      if (link != NULL)\n-\t\t{\n-\t\t  check = DEP_LINK_PRO (link);\n-\t\t  if (BLOCK_FOR_INSN (check) == rec)\n-\t\t    break;\n-\t\t}\n-\t      else\n-\t\tbreak;\n+\t  gcc_assert (DEP_TYPE (dep) == REG_DEP_TRUE);\n+\n+\t  /* INSN might have dependencies from the instructions from\n+\t     several recovery blocks.  At this iteration we process those\n+\t     producers that reside in REC.  */\n+\t  if (BLOCK_FOR_INSN (pro) == rec)\n+\t    {\n+\t      dep_def _new_dep, *new_dep = &_new_dep;\n+\n+\t      init_dep (new_dep, pro, twin, REG_DEP_TRUE);\n+\t      sd_add_dep (new_dep, false);\n \t    }\n-\t  while (1);\n \t}\n-      while (link != NULL);\n \n-      process_insn_forw_deps_be_in_spec (INSN_FORW_DEPS (insn), twin, ts);\n+      process_insn_forw_deps_be_in_spec (insn, twin, ts);\n \n       /* Remove all dependencies between INSN and insns in REC.  */\n-      for (link = DEPS_LIST_FIRST (INSN_BACK_DEPS (insn)); link != NULL;)\n+      for (sd_it = sd_iterator_start (insn, SD_LIST_SPEC_BACK);\n+\t   sd_iterator_cond (&sd_it, &dep);)\n \t{\n-\t  check = DEP_LINK_PRO (link);\n-\n-\t  if (BLOCK_FOR_INSN (check) == rec)\n-\t    {\n-\t      delete_back_forw_dep (link);\n+\t  rtx pro = DEP_PRO (dep);\n \n-\t      /* Restart search.  */\n-\t      link = DEPS_LIST_FIRST (INSN_BACK_DEPS (insn));\n-\t    }\n+\t  if (BLOCK_FOR_INSN (pro) == rec)\n+\t    sd_delete_dep (sd_it);\n \t  else\n-\t    /* Continue search.  */\n-\t    link = DEP_LINK_NEXT (link);\n+\t    sd_iterator_next (&sd_it);\n \t}\n     }\n-  while (!deps_list_empty_p (INSN_BACK_DEPS (insn)));\n \n   /* We couldn't have added the dependencies between INSN and TWINS earlier\n      because that would make TWINS appear in the INSN_BACK_DEPS (INSN).  */\n@@ -3423,7 +3438,13 @@ add_to_speculative_block (rtx insn)\n       rtx twin;\n \n       twin = XEXP (twins, 0);\n-      add_back_forw_dep (twin, insn, REG_DEP_OUTPUT, DEP_OUTPUT);\n+\n+      {\n+\tdep_def _new_dep, *new_dep = &_new_dep;\n+\n+\tinit_dep (new_dep, insn, twin, REG_DEP_OUTPUT);\n+\tsd_add_dep (new_dep, false);\n+      }\n \n       twin = XEXP (twins, 1);\n       free_INSN_LIST_node (twins);\n@@ -3579,7 +3600,8 @@ create_recovery_block (void)\n   rtx barrier;\n   basic_block rec;\n   \n-  added_recovery_block_p = true;\n+  haifa_recovery_bb_recently_added_p = true;\n+  haifa_recovery_bb_ever_added_p = true;\n \n   if (!before_recovery)\n     init_before_recovery ();\n@@ -3613,8 +3635,10 @@ create_check_block_twin (rtx insn, bool mutate_p)\n {\n   basic_block rec;\n   rtx label, check, twin;\n-  dep_link_t link;\n   ds_t fs;\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n+  dep_def _new_dep, *new_dep = &_new_dep;\n \n   gcc_assert (ORIG_PAT (insn)\n \t      && (!mutate_p \n@@ -3663,14 +3687,17 @@ create_check_block_twin (rtx insn, bool mutate_p)\n      in the recovery block).  */\n   if (rec != EXIT_BLOCK_PTR)\n     {\n-      FOR_EACH_DEP_LINK (link, INSN_RESOLVED_BACK_DEPS (insn))\n-\tif ((DEP_LINK_STATUS (link) & DEP_OUTPUT) != 0)\n+      sd_iterator_def sd_it;\n+      dep_t dep;\n+\n+      FOR_EACH_DEP (insn, SD_LIST_RES_BACK, sd_it, dep)\n+\tif ((DEP_STATUS (dep) & DEP_OUTPUT) != 0)\n \t  {\n-\t    struct _dep _dep, *dep = &_dep;\n+\t    struct _dep _dep2, *dep2 = &_dep2;\n \n-\t    init_dep (dep, DEP_LINK_PRO (link), check, REG_DEP_TRUE);\n+\t    init_dep (dep2, DEP_PRO (dep), check, REG_DEP_TRUE);\n \n-\t    add_back_dep_to_deps_list (INSN_RESOLVED_BACK_DEPS (check), dep);\n+\t    sd_add_dep (dep2, true);\n \t  }\n \n       twin = emit_insn_after (ORIG_PAT (insn), BB_END (rec));\n@@ -3691,9 +3718,9 @@ create_check_block_twin (rtx insn, bool mutate_p)\n \t (TRUE | OUTPUT).  */\n     }\n \n-  copy_deps_list_change_con (INSN_RESOLVED_BACK_DEPS (twin),\n-\t\t\t     INSN_RESOLVED_BACK_DEPS (insn),\n-\t\t\t     twin);\n+  /* Copy all resolved back dependencies of INSN to TWIN.  This will\n+     provide correct value for INSN_TICK (TWIN).  */\n+  sd_copy_back_deps (twin, insn, true);\n \n   if (rec != EXIT_BLOCK_PTR)\n     /* In case of branchy check, fix CFG.  */\n@@ -3756,10 +3783,11 @@ create_check_block_twin (rtx insn, bool mutate_p)\n \n   /* Move backward dependences from INSN to CHECK and \n      move forward dependences from INSN to TWIN.  */\n-  FOR_EACH_DEP_LINK (link, INSN_BACK_DEPS (insn))\n+\n+  /* First, create dependencies between INSN's producers and CHECK & TWIN.  */\n+  FOR_EACH_DEP (insn, SD_LIST_BACK, sd_it, dep)\n     {\n-      rtx pro = DEP_LINK_PRO (link);\n-      enum reg_note dk = DEP_LINK_KIND (link);\n+      rtx pro = DEP_PRO (dep);\n       ds_t ds;\n \n       /* If BEGIN_DATA: [insn ~~TRUE~~> producer]:\n@@ -3777,38 +3805,38 @@ create_check_block_twin (rtx insn, bool mutate_p)\n \t twin  ~~TRUE~~> producer\n \t twin  --ANTI--> check  */\t      \t  \n \n-      ds = DEP_LINK_STATUS (link);\n+      ds = DEP_STATUS (dep);\n \n       if (ds & BEGIN_SPEC)\n \t{\n \t  gcc_assert (!mutate_p);\n \t  ds &= ~BEGIN_SPEC;\n \t}\n \n+      init_dep_1 (new_dep, pro, check, DEP_TYPE (dep), ds);\n+      sd_add_dep (new_dep, false);\n+\n       if (rec != EXIT_BLOCK_PTR)\n \t{\n-\t  add_back_forw_dep (check, pro, dk, ds);\n-\t  add_back_forw_dep (twin, pro, dk, ds);\n+\t  DEP_CON (new_dep) = twin;\n+\t  sd_add_dep (new_dep, false);\n \t}    \n-      else\n-\tadd_back_forw_dep (check, pro, dk, ds);\n     }\n \n-  for (link = DEPS_LIST_FIRST (INSN_BACK_DEPS (insn)); link != NULL;)\n-    if ((DEP_LINK_STATUS (link) & BEGIN_SPEC)\n-\t|| mutate_p)\n-      /* We can delete this dep only if we totally overcome it with\n-\t BEGIN_SPECULATION.  */\n-      {\n-        delete_back_forw_dep (link);\n-\n-\t/* Restart search.  */\n-        link = DEPS_LIST_FIRST (INSN_BACK_DEPS (insn));\n-      }\n-    else\n-      /* Continue search.  */\n-      link = DEP_LINK_NEXT (link);    \n+  /* Second, remove backward dependencies of INSN.  */\n+  for (sd_it = sd_iterator_start (insn, SD_LIST_SPEC_BACK);\n+       sd_iterator_cond (&sd_it, &dep);)\n+    {\n+      if ((DEP_STATUS (dep) & BEGIN_SPEC)\n+\t  || mutate_p)\n+\t/* We can delete this dep because we overcome it with\n+\t   BEGIN_SPECULATION.  */\n+\tsd_delete_dep (sd_it);\n+      else\n+\tsd_iterator_next (&sd_it);\n+    }\n \n+  /* Future Speculations.  Determine what BE_IN speculations will be like.  */\n   fs = 0;\n \n   /* Fields (DONE_SPEC (x) & BEGIN_SPEC) and CHECK_SPEC (x) are set only\n@@ -3823,16 +3851,19 @@ create_check_block_twin (rtx insn, bool mutate_p)\n       DONE_SPEC (insn) = ts & BEGIN_SPEC;\n       CHECK_SPEC (check) = ts & BEGIN_SPEC;\n \n+      /* Luckyness of future speculations solely depends upon initial\n+\t BEGIN speculation.  */\n       if (ts & BEGIN_DATA)\n \tfs = set_dep_weak (fs, BE_IN_DATA, get_dep_weak (ts, BEGIN_DATA));\n       if (ts & BEGIN_CONTROL)\n-\tfs = set_dep_weak (fs, BE_IN_CONTROL, get_dep_weak (ts, BEGIN_CONTROL));\n+\tfs = set_dep_weak (fs, BE_IN_CONTROL,\n+\t\t\t   get_dep_weak (ts, BEGIN_CONTROL));\n     }\n   else\n     CHECK_SPEC (check) = CHECK_SPEC (insn);\n \n   /* Future speculations: call the helper.  */\n-  process_insn_forw_deps_be_in_spec (INSN_FORW_DEPS (insn), twin, fs);\n+  process_insn_forw_deps_be_in_spec (insn, twin, fs);\n \n   if (rec != EXIT_BLOCK_PTR)\n     {\n@@ -3842,35 +3873,45 @@ create_check_block_twin (rtx insn, bool mutate_p)\n \n       if (!mutate_p)\n \t{\n-\t  add_back_forw_dep (check, insn, REG_DEP_TRUE, DEP_TRUE);\n-\t  add_back_forw_dep (twin, insn, REG_DEP_OUTPUT, DEP_OUTPUT);\n+\t  init_dep (new_dep, insn, check, REG_DEP_TRUE);\n+\t  sd_add_dep (new_dep, false);\n+\n+\t  init_dep (new_dep, insn, twin, REG_DEP_OUTPUT);\n+\t  sd_add_dep (new_dep, false);\n \t}\n       else\n \t{\n-\t  dep_link_t link;\n-\n \t  if (spec_info->dump)    \n \t    fprintf (spec_info->dump, \";;\\t\\tRemoved simple check : %s\\n\",\n \t\t     (*current_sched_info->print_insn) (insn, 0));\n \n-\t  /* Remove all forward dependencies of the INSN.  */\n-\t  link = DEPS_LIST_FIRST (INSN_FORW_DEPS (insn));\n-\t  while (link != NULL)\n-\t    {\n-\t      delete_back_forw_dep (link);\n-\t      link = DEPS_LIST_FIRST (INSN_FORW_DEPS (insn));\n-\t    }\n+\t  /* Remove all dependencies of the INSN.  */\n+\t  {\n+\t    sd_it = sd_iterator_start (insn, (SD_LIST_FORW\n+\t\t\t\t\t      | SD_LIST_BACK\n+\t\t\t\t\t      | SD_LIST_RES_BACK));\n+\t    while (sd_iterator_cond (&sd_it, &dep))\n+\t      sd_delete_dep (sd_it);\n+\t  }\n \n+\t  /* If former check (INSN) already was moved to the ready (or queue)\n+\t     list, add new check (CHECK) there too.  */\n \t  if (QUEUE_INDEX (insn) != QUEUE_NOWHERE)\n \t    try_ready (check);\n \n+\t  /* Remove old check from instruction stream and free its\n+\t     data.  */\n \t  sched_remove_insn (insn);\n \t}\n \n-      add_back_forw_dep (twin, check, REG_DEP_ANTI, DEP_ANTI);\n+      init_dep (new_dep, check, twin, REG_DEP_ANTI);\n+      sd_add_dep (new_dep, false);\n     }\n   else\n-    add_back_forw_dep (check, insn, REG_DEP_TRUE, DEP_TRUE | DEP_OUTPUT);\n+    {\n+      init_dep_1 (new_dep, insn, check, REG_DEP_TRUE, DEP_TRUE | DEP_OUTPUT);\n+      sd_add_dep (new_dep, false);\n+    }\n \n   if (!mutate_p)\n     /* Fix priorities.  If MUTATE_P is nonzero, this is not necessary,\n@@ -3890,10 +3931,9 @@ create_check_block_twin (rtx insn, bool mutate_p)\n static void\n fix_recovery_deps (basic_block rec)\n {\n-  dep_link_t link;\n   rtx note, insn, jump, ready_list = 0;\n   bitmap_head in_ready;\n-  rtx link1;\n+  rtx link;\n \n   bitmap_initialize (&in_ready, 0);\n   \n@@ -3905,32 +3945,30 @@ fix_recovery_deps (basic_block rec)\n   insn = PREV_INSN (insn);\n \n   do\n-    {    \n-      for (link = DEPS_LIST_FIRST (INSN_FORW_DEPS (insn)); link != NULL;)\n-\t{\n-\t  rtx consumer;\n+    {\n+      sd_iterator_def sd_it;\n+      dep_t dep;\n \n-\t  consumer = DEP_LINK_CON (link);\n+      for (sd_it = sd_iterator_start (insn, SD_LIST_FORW);\n+\t   sd_iterator_cond (&sd_it, &dep);)\n+\t{\n+\t  rtx consumer = DEP_CON (dep);\n \n \t  if (BLOCK_FOR_INSN (consumer) != rec)\n \t    {\n-\t      delete_back_forw_dep (link);\n+\t      sd_delete_dep (sd_it);\n \n \t      if (!bitmap_bit_p (&in_ready, INSN_LUID (consumer)))\n \t\t{\n \t\t  ready_list = alloc_INSN_LIST (consumer, ready_list);\n \t\t  bitmap_set_bit (&in_ready, INSN_LUID (consumer));\n \t\t}\n-\n-\t      /* Restart search.  */\n-\t      link = DEPS_LIST_FIRST (INSN_FORW_DEPS (insn));\n \t    }\n \t  else\n \t    {\n-\t      gcc_assert ((DEP_LINK_STATUS (link) & DEP_TYPES) == DEP_TRUE);\n+\t      gcc_assert ((DEP_STATUS (dep) & DEP_TYPES) == DEP_TRUE);\n \n-\t      /* Continue search.  */\n-\t      link = DEP_LINK_NEXT (link);\n+\t      sd_iterator_next (&sd_it);\n \t    }\n \t}\n       \n@@ -3941,8 +3979,8 @@ fix_recovery_deps (basic_block rec)\n   bitmap_clear (&in_ready);\n \n   /* Try to add instructions to the ready or queue list.  */\n-  for (link1 = ready_list; link1; link1 = XEXP (link1, 1))\n-    try_ready (XEXP (link1, 0));\n+  for (link = ready_list; link; link = XEXP (link, 1))\n+    try_ready (XEXP (link, 0));\n   free_INSN_LIST_list (&ready_list);\n \n   /* Fixing jump's dependences.  */\n@@ -3971,6 +4009,31 @@ change_pattern (rtx insn, rtx new_pat)\n   dfa_clear_single_insn_cache (insn);\n }\n \n+/* Return true if INSN can potentially be speculated with type DS.  */\n+bool\n+sched_insn_is_legitimate_for_speculation_p (rtx insn, ds_t ds)\n+{\n+  if (HAS_INTERNAL_DEP (insn))\n+    return false;\n+\n+  if (!NONJUMP_INSN_P (insn))\n+    return false;\n+\n+  if (SCHED_GROUP_P (insn))\n+    return false;\n+\n+  if (IS_SPECULATION_CHECK_P (insn))\n+    return false;\n+\n+  if (side_effects_p (PATTERN (insn)))\n+    return false;\n+\n+  if ((ds & BE_IN_SPEC)\n+      && may_trap_p (PATTERN (insn)))\n+    return false;\n+\n+  return true;\n+}\n \n /* -1 - can't speculate,\n    0 - for speculation with REQUEST mode it is OK to use\n@@ -3980,25 +4043,15 @@ static int\n speculate_insn (rtx insn, ds_t request, rtx *new_pat)\n {\n   gcc_assert (current_sched_info->flags & DO_SPECULATION\n-              && (request & SPECULATIVE));\n+              && (request & SPECULATIVE)\n+\t      && sched_insn_is_legitimate_for_speculation_p (insn, request));\n \n-  if (!NONJUMP_INSN_P (insn)\n-      || HAS_INTERNAL_DEP (insn)\n-      || SCHED_GROUP_P (insn)\n-      || side_effects_p (PATTERN (insn))\n-      || (request & spec_info->mask) != request)    \n+  if ((request & spec_info->mask) != request)\n     return -1;\n-  \n-  gcc_assert (!IS_SPECULATION_CHECK_P (insn));\n \n-  if (request & BE_IN_SPEC)\n-    {            \n-      if (may_trap_p (PATTERN (insn)))\n-        return -1;\n-      \n-      if (!(request & BEGIN_SPEC))\n-        return 0;\n-    }\n+  if (request & BE_IN_SPEC\n+      && !(request & BEGIN_SPEC))\n+    return 0;\n \n   return targetm.sched.speculate_insn (insn, request & BEGIN_SPEC, new_pat);\n }\n@@ -4244,6 +4297,8 @@ move_succs (VEC(edge,gc) **succsp, basic_block to)\n static void\n sched_remove_insn (rtx insn)\n {\n+  sd_finish_insn (insn);\n+\n   change_queue_index (insn, QUEUE_NOWHERE);\n   current_sched_info->add_remove_insn (insn, 1);\n   remove_insn (insn);\n@@ -4255,14 +4310,14 @@ sched_remove_insn (rtx insn)\n static void\n clear_priorities (rtx insn, rtx_vec_t *roots_ptr)\n {\n-  dep_link_t link;\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n   bool insn_is_root_p = true;\n \n   gcc_assert (QUEUE_INDEX (insn) != QUEUE_SCHEDULED);\n \n-  FOR_EACH_DEP_LINK (link, INSN_BACK_DEPS (insn))\n+  FOR_EACH_DEP (insn, SD_LIST_BACK, sd_it, dep)\n     {\n-      dep_t dep = DEP_LINK_DEP (link);\n       rtx pro = DEP_PRO (dep);\n \n       if (INSN_PRIORITY_STATUS (pro) >= 0\n@@ -4307,12 +4362,17 @@ add_jump_dependencies (rtx insn, rtx jump)\n       if (insn == jump)\n \tbreak;\n       \n-      if (deps_list_empty_p (INSN_FORW_DEPS (insn)))\n-\tadd_back_forw_dep (jump, insn, REG_DEP_ANTI, DEP_ANTI);\n+      if (sd_lists_empty_p (insn, SD_LIST_FORW))\n+\t{\n+\t  dep_def _new_dep, *new_dep = &_new_dep;\n+\n+\t  init_dep (new_dep, insn, jump, REG_DEP_ANTI);\n+\t  sd_add_dep (new_dep, false);\n+\t}\n     }\n   while (1);\n \n-  gcc_assert (!deps_list_empty_p (INSN_BACK_DEPS (jump)));\n+  gcc_assert (!sd_lists_empty_p (jump, SD_LIST_BACK));\n }\n \n /* Return the NOTE_INSN_BASIC_BLOCK of BB.  */\n@@ -4330,36 +4390,6 @@ bb_note (basic_block bb)\n }\n \n #ifdef ENABLE_CHECKING\n-extern void debug_spec_status (ds_t);\n-\n-/* Dump information about the dependence status S.  */\n-void\n-debug_spec_status (ds_t s)\n-{\n-  FILE *f = stderr;\n-\n-  if (s & BEGIN_DATA)\n-    fprintf (f, \"BEGIN_DATA: %d; \", get_dep_weak (s, BEGIN_DATA));\n-  if (s & BE_IN_DATA)\n-    fprintf (f, \"BE_IN_DATA: %d; \", get_dep_weak (s, BE_IN_DATA));\n-  if (s & BEGIN_CONTROL)\n-    fprintf (f, \"BEGIN_CONTROL: %d; \", get_dep_weak (s, BEGIN_CONTROL));\n-  if (s & BE_IN_CONTROL)\n-    fprintf (f, \"BE_IN_CONTROL: %d; \", get_dep_weak (s, BE_IN_CONTROL));\n-\n-  if (s & HARD_DEP)\n-    fprintf (f, \"HARD_DEP; \");\n-\n-  if (s & DEP_TRUE)\n-    fprintf (f, \"DEP_TRUE; \");\n-  if (s & DEP_ANTI)\n-    fprintf (f, \"DEP_ANTI; \");\n-  if (s & DEP_OUTPUT)\n-    fprintf (f, \"DEP_OUTPUT; \");\n-\n-  fprintf (f, \"\\n\");\n-}\n-\n /* Helper function for check_cfg.\n    Return nonzero, if edge vector pointed to by EL has edge with TYPE in\n    its flags.  */"}, {"sha": "dd74e29dcb58fc8618d5bbda0e4301ab11df95c9", "filename": "gcc/sched-deps.c", "status": "modified", "additions": 1023, "deletions": 751, "changes": 1774, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fsched-deps.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fsched-deps.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-deps.c?ref=e2f6ff946a121528203fcbde68fdd58942f9a57b", "patch": "@@ -84,12 +84,12 @@ dk_to_ds (enum reg_note dk)\n /* Functions to operate with dependence information container - dep_t.  */\n \n /* Init DEP with the arguments.  */\n-static void\n-init_dep_1 (dep_t dep, rtx pro, rtx con, enum reg_note kind, ds_t ds)\n+void\n+init_dep_1 (dep_t dep, rtx pro, rtx con, enum reg_note type, ds_t ds)\n {\n   DEP_PRO (dep) = pro;\n   DEP_CON (dep) = con;\n-  DEP_KIND (dep) = kind;\n+  DEP_TYPE (dep) = type;\n   DEP_STATUS (dep) = ds;\n }\n \n@@ -101,7 +101,7 @@ init_dep (dep_t dep, rtx pro, rtx con, enum reg_note kind)\n {\n   ds_t ds;\n \n-  if ((current_sched_info->flags & USE_DEPS_LIST) != 0)\n+  if ((current_sched_info->flags & USE_DEPS_LIST))\n     ds = dk_to_ds (kind);\n   else\n     ds = -1;\n@@ -116,19 +116,95 @@ copy_dep (dep_t to, dep_t from)\n   memcpy (to, from, sizeof (*to));\n }\n \n-/* Functions to operate with a single link from the dependencies lists -\n-   dep_link_t.  */\n+static void dump_ds (FILE *, ds_t);\n \n-/* Return true if dep_link L is consistent.  */\n-static bool\n-dep_link_consistent_p (dep_link_t l)\n+/* Define flags for dump_dep ().  */\n+\n+/* Dump producer of the dependence.  */\n+#define DUMP_DEP_PRO (2)\n+\n+/* Dump consumer of the dependence.  */\n+#define DUMP_DEP_CON (4)\n+\n+/* Dump type of the dependence.  */\n+#define DUMP_DEP_TYPE (8)\n+\n+/* Dump status of the dependence.  */\n+#define DUMP_DEP_STATUS (16)\n+\n+/* Dump all information about the dependence.  */\n+#define DUMP_DEP_ALL (DUMP_DEP_PRO | DUMP_DEP_CON | DUMP_DEP_TYPE\t\\\n+\t\t      |DUMP_DEP_STATUS)\n+\n+/* Dump DEP to DUMP.\n+   FLAGS is a bit mask specifying what information about DEP needs\n+   to be printed.\n+   If FLAGS has the very first bit set, then dump all information about DEP\n+   and propagate this bit into the callee dump functions.  */\n+static void\n+dump_dep (FILE *dump, dep_t dep, int flags)\n {\n-  dep_link_t next = DEP_LINK_NEXT (l);\n+  if (flags & 1)\n+    flags |= DUMP_DEP_ALL;\n+\n+  fprintf (dump, \"<\");\n+\n+  if (flags & DUMP_DEP_PRO)\n+    fprintf (dump, \"%d; \", INSN_UID (DEP_PRO (dep)));\n+\n+  if (flags & DUMP_DEP_CON)\n+    fprintf (dump, \"%d; \", INSN_UID (DEP_CON (dep)));\n+\n+  if (flags & DUMP_DEP_TYPE)\n+    {\n+      char t;\n+      enum reg_note type = DEP_TYPE (dep);\n+\n+      switch (type)\n+\t{\n+\tcase REG_DEP_TRUE:\n+\t  t = 't';\n+\t  break;\n+\n+\tcase REG_DEP_OUTPUT:\n+\t  t = 'o';\n+\t  break;\n \n-  return (next == NULL\n-\t  || &DEP_LINK_NEXT (l) == DEP_LINK_PREV_NEXTP (next));\n+\tcase REG_DEP_ANTI:\n+\t  t = 'a';\n+\t  break;\n+\n+\tdefault:\n+\t  gcc_unreachable ();\n+\t  break;\n+\t}\n+\n+      fprintf (dump, \"%c; \", t);\n+    }\n+\n+  if (flags & DUMP_DEP_STATUS)\n+    {\n+      if (current_sched_info->flags & USE_DEPS_LIST)\n+\tdump_ds (dump, DEP_STATUS (dep));\n+    }\n+\n+  fprintf (dump, \">\");\n+}\n+\n+/* Default flags for dump_dep ().  */\n+static int dump_dep_flags = (DUMP_DEP_PRO | DUMP_DEP_CON);\n+\n+/* Dump all fields of DEP to STDERR.  */\n+void\n+sd_debug_dep (dep_t dep)\n+{\n+  dump_dep (stderr, dep, 1);\n+  fprintf (stderr, \"\\n\");\n }\n \n+/* Functions to operate with a single link from the dependencies lists -\n+   dep_link_t.  */\n+\n /* Attach L to appear after link X whose &DEP_LINK_NEXT (X) is given by\n    PREV_NEXT_P.  */\n static void\n@@ -160,6 +236,8 @@ static void\n add_to_deps_list (dep_link_t link, deps_list_t l)\n {\n   attach_dep_link (link, &DEPS_LIST_FIRST (l));\n+\n+  ++DEPS_LIST_N_LINKS (l);\n }\n \n /* Detach dep_link L from the list.  */\n@@ -174,232 +252,135 @@ detach_dep_link (dep_link_t l)\n   if (next != NULL)\n     DEP_LINK_PREV_NEXTP (next) = prev_nextp;\n \n-  /* Though this is property is not used anywhere but in the assert in\n-     attach_dep_link (), this can prevent latent errors.  */\n   DEP_LINK_PREV_NEXTP (l) = NULL;\n   DEP_LINK_NEXT (l) = NULL;\n }\n \n-/* Move LINK from whatever list it is now to L.  */\n-void\n-move_dep_link (dep_link_t link, deps_list_t l)\n+/* Remove link LINK from list LIST.  */\n+static void\n+remove_from_deps_list (dep_link_t link, deps_list_t list)\n {\n   detach_dep_link (link);\n-  add_to_deps_list (link, l);\n-}\n \n-/* Check L's and its successors' consistency.\n-   This is, potentially, an expensive check, hence it should be guarded by\n-   ENABLE_CHECKING at all times.  */\n-static bool\n-dep_links_consistent_p (dep_link_t l)\n-{\n-  while (l != NULL)\n-    {\n-      if (dep_link_consistent_p (l))\n-\tl = DEP_LINK_NEXT (l);\n-      else\n-\treturn false;\n-    }\n-\n-  return true;\n+  --DEPS_LIST_N_LINKS (list);\n }\n \n-/* Dump dep_nodes starting from l.  */\n+/* Move link LINK from list FROM to list TO.  */\n static void\n-dump_dep_links (FILE *dump, dep_link_t l)\n+move_dep_link (dep_link_t link, deps_list_t from, deps_list_t to)\n {\n-  while (l != NULL)\n-    {\n-      dep_t d = DEP_LINK_DEP (l);\n-\n-      fprintf (dump, \"%d%c>%d \", INSN_UID (DEP_PRO (d)),\n-\t       dep_link_consistent_p (l) ? '-' : '!', INSN_UID (DEP_CON (d)));\n-\n-      l = DEP_LINK_NEXT (l);\n-    }\n-\n-  fprintf (dump, \"\\n\");\n+  remove_from_deps_list (link, from);\n+  add_to_deps_list (link, to);\n }\n \n-/* Dump dep_nodes starting from L to stderr.  */\n-void\n-debug_dep_links (dep_link_t l)\n+/* Return true of LINK is not attached to any list.  */\n+static bool\n+dep_link_is_detached_p (dep_link_t link)\n {\n-  dump_dep_links (stderr, l);\n+  return DEP_LINK_PREV_NEXTP (link) == NULL;\n }\n \n-/* Obstack to allocate dep_nodes and deps_lists on.  */\n-static struct obstack deps_obstack;\n+/* Pool to hold all dependency nodes (dep_node_t).  */\n+static alloc_pool dn_pool;\n \n-/* Obstack to hold forward dependencies lists (deps_list_t).  */\n-static struct obstack *dl_obstack = &deps_obstack;\n+/* Number of dep_nodes out there.  */\n+static int dn_pool_diff = 0;\n \n-/* Obstack to hold all dependency nodes (dep_node_t).  */\n-static struct obstack *dn_obstack = &deps_obstack;\n+/* Create a dep_node.  */\n+static dep_node_t\n+create_dep_node (void)\n+{\n+  dep_node_t n = (dep_node_t) pool_alloc (dn_pool);\n+  dep_link_t back = DEP_NODE_BACK (n);\n+  dep_link_t forw = DEP_NODE_FORW (n);\n \n-/* Functions to operate with dependences lists - deps_list_t.  */\n+  DEP_LINK_NODE (back) = n;\n+  DEP_LINK_NEXT (back) = NULL;\n+  DEP_LINK_PREV_NEXTP (back) = NULL;\n \n-/* Allocate deps_list.\n+  DEP_LINK_NODE (forw) = n;\n+  DEP_LINK_NEXT (forw) = NULL;\n+  DEP_LINK_PREV_NEXTP (forw) = NULL;\n \n-   If ON_OBSTACK_P is true, allocate the list on the obstack.  This is done for\n-   INSN_FORW_DEPS lists because they should live till the end of scheduling.\n+  ++dn_pool_diff;\n \n-   INSN_BACK_DEPS and INSN_RESOLVED_BACK_DEPS lists are allocated on the free\n-   store and are being freed in haifa-sched.c: schedule_insn ().  */\n-static deps_list_t\n-alloc_deps_list (bool on_obstack_p)\n-{\n-  if (on_obstack_p)\n-    return obstack_alloc (dl_obstack, sizeof (struct _deps_list));\n-  else\n-    return xmalloc (sizeof (struct _deps_list));\n+  return n;\n }\n \n-/* Initialize deps_list L.  */\n+/* Delete dep_node N.  N must not be connected to any deps_list.  */\n static void\n-init_deps_list (deps_list_t l)\n+delete_dep_node (dep_node_t n)\n {\n-  DEPS_LIST_FIRST (l) = NULL;\n-}\n+  gcc_assert (dep_link_is_detached_p (DEP_NODE_BACK (n))\n+\t      && dep_link_is_detached_p (DEP_NODE_FORW (n)));\n \n-/* Create (allocate and init) deps_list.\n-   The meaning of ON_OBSTACK_P is the same as in alloc_deps_list ().  */\n-deps_list_t\n-create_deps_list (bool on_obstack_p)\n-{\n-  deps_list_t l = alloc_deps_list (on_obstack_p);\n+  --dn_pool_diff;\n \n-  init_deps_list (l);\n-  return l;\n+  pool_free (dn_pool, n);\n }\n \n-/* Free dep_data_nodes that present in L.  */\n-static void\n-clear_deps_list (deps_list_t l)\n-{\n-  /* All dep_nodes are allocated on the dn_obstack.  They'll be freed with\n-     the obstack.  */\n+/* Pool to hold dependencies lists (deps_list_t).  */\n+static alloc_pool dl_pool;\n \n-  DEPS_LIST_FIRST (l) = NULL;\n-}\n+/* Number of deps_lists out there.  */\n+static int dl_pool_diff = 0;\n \n-/* Free deps_list L.  */\n-void\n-free_deps_list (deps_list_t l)\n-{\n-  gcc_assert (deps_list_empty_p (l));\n-  free (l);\n-}\n-\n-/* Delete (clear and free) deps_list L.  */\n-void\n-delete_deps_list (deps_list_t l)\n-{\n-  clear_deps_list (l);\n-  free_deps_list (l);\n-}\n+/* Functions to operate with dependences lists - deps_list_t.  */\n \n-/* Return true if L is empty.  */\n-bool\n+/* Return true if list L is empty.  */\n+static bool\n deps_list_empty_p (deps_list_t l)\n {\n-  return DEPS_LIST_FIRST (l) == NULL;\n+  return DEPS_LIST_N_LINKS (l) == 0;\n }\n \n-/* Check L's consistency.\n-   This is, potentially, an expensive check, hence it should be guarded by\n-   ENABLE_CHECKING at all times.  */\n-static bool\n-deps_list_consistent_p (deps_list_t l)\n+/* Create a new deps_list.  */\n+static deps_list_t\n+create_deps_list (void)\n {\n-  dep_link_t first = DEPS_LIST_FIRST (l);\n-\n-  return (first == NULL\n-\t  || (&DEPS_LIST_FIRST (l) == DEP_LINK_PREV_NEXTP (first)\n-\t      && dep_links_consistent_p (first)));\n-}\n+  deps_list_t l = (deps_list_t) pool_alloc (dl_pool);\n \n-/* Dump L to F.  */\n-static void\n-dump_deps_list (FILE *f, deps_list_t l)\n-{\n-  dump_dep_links (f, DEPS_LIST_FIRST (l));\n-}\n+  DEPS_LIST_FIRST (l) = NULL;\n+  DEPS_LIST_N_LINKS (l) = 0;\n \n-/* Dump L to STDERR.  */\n-void\n-debug_deps_list (deps_list_t l)\n-{\n-  dump_deps_list (stderr, l);\n+  ++dl_pool_diff;\n+  return l;\n }\n \n-/* Add a dependency described by DEP to the list L.\n-   L should be either INSN_BACK_DEPS or INSN_RESOLVED_BACK_DEPS.  */\n-void\n-add_back_dep_to_deps_list (deps_list_t l, dep_t dep_from)\n+/* Free deps_list L.  */\n+static void\n+free_deps_list (deps_list_t l)\n {\n-  dep_node_t n = (dep_node_t) obstack_alloc (dn_obstack,\n-\t\t\t\t\t     sizeof (*n));\n-  dep_t dep_to = DEP_NODE_DEP (n);\n-  dep_link_t back = DEP_NODE_BACK (n);\n-  dep_link_t forw = DEP_NODE_FORW (n);\n-\n-  copy_dep (dep_to, dep_from);\n-\n-  DEP_LINK_NODE (back) = n;\n-  DEP_LINK_NODE (forw) = n;\n+  gcc_assert (deps_list_empty_p (l));\n \n-  /* There is no particular need to initialize these four fields except to make\n-     assert in attach_dep_link () happy.  */\n-  DEP_LINK_NEXT (back) = NULL;\n-  DEP_LINK_PREV_NEXTP (back) = NULL;\n-  DEP_LINK_NEXT (forw) = NULL;\n-  DEP_LINK_PREV_NEXTP (forw) = NULL;\n+  --dl_pool_diff;\n \n-  add_to_deps_list (back, l);\n+  pool_free (dl_pool, l);\n }\n \n-/* Find the dep_link with producer PRO in deps_list L.  */\n-dep_link_t\n-find_link_by_pro_in_deps_list (deps_list_t l, rtx pro)\n+/* Return true if there is no dep_nodes and deps_lists out there.\n+   After the region is scheduled all the depedency nodes and lists\n+   should [generally] be returned to pool.  */\n+bool\n+deps_pools_are_empty_p (void)\n {\n-  dep_link_t link;\n-\n-  FOR_EACH_DEP_LINK (link, l)\n-    if (DEP_LINK_PRO (link) == pro)\n-      return link;\n-\n-  return NULL;\n+  return dn_pool_diff == 0 && dl_pool_diff == 0;\n }\n \n-/* Find the dep_link with consumer CON in deps_list L.  */\n-dep_link_t\n-find_link_by_con_in_deps_list (deps_list_t l, rtx con)\n-{\n-  dep_link_t link;\n-\n-  FOR_EACH_DEP_LINK (link, l)\n-    if (DEP_LINK_CON (link) == con)\n-      return link;\n-\n-  return NULL;\n-}\n-\n-/* Make a copy of FROM in TO with substituting consumer with CON.\n-   TO and FROM should be RESOLVED_BACK_DEPS lists.  */\n-void\n-copy_deps_list_change_con (deps_list_t to, deps_list_t from, rtx con)\n+/* Remove all elements from L.  */\n+static void\n+clear_deps_list (deps_list_t l)\n {\n-  dep_link_t l;\n+  do\n+    {\n+      dep_link_t link = DEPS_LIST_FIRST (l);\n \n-  gcc_assert (deps_list_empty_p (to));\n+      if (link == NULL)\n+\tbreak;\n \n-  FOR_EACH_DEP_LINK (l, from)\n-    {\n-      add_back_dep_to_deps_list (to, DEP_LINK_DEP (l));\n-      DEP_LINK_CON (DEPS_LIST_FIRST (to)) = con;\n+      remove_from_deps_list (link, l);\n     }\n+  while (1);\n }\n \n static regset reg_pending_sets;\n@@ -437,14 +418,6 @@ static bitmap_head *anti_dependency_cache;\n static bitmap_head *spec_dependency_cache;\n static int cache_size;\n \n-/* To speed up checking consistency of formed forward insn\n-   dependencies we use the following cache.  Another possible solution\n-   could be switching off checking duplication of insns in forward\n-   dependencies.  */\n-#ifdef ENABLE_CHECKING\n-static bitmap_head *forward_dependency_cache;\n-#endif\n-\n static int deps_may_trap_p (rtx);\n static void add_dependence_list (rtx, rtx, int, enum reg_note);\n static void add_dependence_list_and_free (rtx, rtx *, int, enum reg_note);\n@@ -459,19 +432,14 @@ static void sched_analyze_insn (struct deps *, rtx, rtx);\n static rtx sched_get_condition (rtx);\n static int conditions_mutex_p (rtx, rtx);\n \n-static enum DEPS_ADJUST_RESULT maybe_add_or_update_back_dep_1 (rtx, rtx, \n-\t\t\t       enum reg_note, ds_t, rtx, rtx, dep_link_t **);\n-static enum DEPS_ADJUST_RESULT add_or_update_back_dep_1 (rtx, rtx, \n-                               enum reg_note, ds_t, rtx, rtx, dep_link_t **);\n-static void add_back_dep (rtx, rtx, enum reg_note, ds_t);\n+static enum DEPS_ADJUST_RESULT maybe_add_or_update_dep_1 (dep_t, bool,\n+\t\t\t\t\t\t\t  rtx, rtx);\n+static enum DEPS_ADJUST_RESULT add_or_update_dep_1 (dep_t, bool, rtx, rtx);\n \n-static void adjust_add_sorted_back_dep (rtx, dep_link_t, dep_link_t *);\n-static void adjust_back_add_forw_dep (rtx, dep_link_t *);\n-static void delete_forw_dep (dep_link_t);\n static dw_t estimate_dep_weak (rtx, rtx);\n #ifdef INSN_SCHEDULING\n #ifdef ENABLE_CHECKING\n-static void check_dep_status (enum reg_note, ds_t, bool);\n+static void check_dep (dep_t, bool);\n #endif\n #endif\n \f\n@@ -567,23 +535,218 @@ sched_insns_conditions_mutex_p (rtx insn1, rtx insn2)\n   return false;\n }\n \f\n-/* Add ELEM wrapped in an dep_link with reg note kind DEP_TYPE to the\n-   INSN_BACK_DEPS (INSN), if it is not already there.  DEP_TYPE indicates the\n-   type of dependence that this link represents.  DS, if nonzero,\n-   indicates speculations, through which this dependence can be overcome.\n-   MEM1 and MEM2, if non-null, corresponds to memory locations in case of\n-   data speculation.  The function returns a value indicating if an old entry\n-   has been changed or a new entry has been added to insn's backward deps.\n-   In case of changed entry CHANGED_LINKPP sets to its address.\n-   See also the definition of enum DEPS_ADJUST_RESULT in sched-int.h.  \n-   Actual manipulation of dependence data structures is performed in \n-   add_or_update_back_dep_1.  */\n \n+/* Initialize LIST_PTR to point to one of the lists present in TYPES_PTR,\n+   initialize RESOLVED_P_PTR with true if that list consists of resolved deps,\n+   and remove the type of returned [through LIST_PTR] list from TYPES_PTR.\n+   This function is used to switch sd_iterator to the next list.\n+   !!! For internal use only.  Might consider moving it to sched-int.h.  */\n+void\n+sd_next_list (rtx insn, sd_list_types_def *types_ptr,\n+\t      deps_list_t *list_ptr, bool *resolved_p_ptr)\n+{\n+  sd_list_types_def types = *types_ptr;\n+\n+  if (types & SD_LIST_HARD_BACK)\n+    {\n+      *list_ptr = INSN_HARD_BACK_DEPS (insn);\n+      *resolved_p_ptr = false;\n+      *types_ptr = types & ~SD_LIST_HARD_BACK;\n+    }\n+  else if (types & SD_LIST_SPEC_BACK)\n+    {\n+      *list_ptr = INSN_SPEC_BACK_DEPS (insn);\n+      *resolved_p_ptr = false;\n+      *types_ptr = types & ~SD_LIST_SPEC_BACK;\n+    }\n+  else if (types & SD_LIST_FORW)\n+    {\n+      *list_ptr = INSN_FORW_DEPS (insn);\n+      *resolved_p_ptr = false;\n+      *types_ptr = types & ~SD_LIST_FORW;\n+    }\n+  else if (types & SD_LIST_RES_BACK)\n+    {\n+      *list_ptr = INSN_RESOLVED_BACK_DEPS (insn);\n+      *resolved_p_ptr = true;\n+      *types_ptr = types & ~SD_LIST_RES_BACK;\n+    }\n+  else if (types & SD_LIST_RES_FORW)\n+    {\n+      *list_ptr = INSN_RESOLVED_FORW_DEPS (insn);\n+      *resolved_p_ptr = true;\n+      *types_ptr = types & ~SD_LIST_RES_FORW;\n+    }\n+  else\n+    {\n+      *list_ptr = NULL;\n+      *resolved_p_ptr = false;\n+      *types_ptr = SD_LIST_NONE;\n+    }\n+}\n+\n+/* Return the summary size of INSN's lists defined by LIST_TYPES.  */\n+int\n+sd_lists_size (rtx insn, sd_list_types_def list_types)\n+{\n+  int size = 0;\n+\n+  while (list_types != SD_LIST_NONE)\n+    {\n+      deps_list_t list;\n+      bool resolved_p;\n+\n+      sd_next_list (insn, &list_types, &list, &resolved_p);\n+      size += DEPS_LIST_N_LINKS (list);\n+    }\n+\n+  return size;\n+}\n+\n+/* Return true if INSN's lists defined by LIST_TYPES are all empty.  */\n+bool\n+sd_lists_empty_p (rtx insn, sd_list_types_def list_types)\n+{\n+  return sd_lists_size (insn, list_types) == 0;\n+}\n+\n+/* Initialize data for INSN.  */\n+void\n+sd_init_insn (rtx insn)\n+{\n+  INSN_HARD_BACK_DEPS (insn) = create_deps_list ();\n+  INSN_SPEC_BACK_DEPS (insn) = create_deps_list ();\n+  INSN_RESOLVED_BACK_DEPS (insn) = create_deps_list ();\n+  INSN_FORW_DEPS (insn) = create_deps_list ();\n+  INSN_RESOLVED_FORW_DEPS (insn) = create_deps_list ();\n+\n+  /* ??? It would be nice to allocate dependency caches here.  */\n+}\n+\n+/* Free data for INSN.  */\n+void\n+sd_finish_insn (rtx insn)\n+{\n+  /* ??? It would be nice to deallocate dependency caches here.  */\n+\n+  free_deps_list (INSN_HARD_BACK_DEPS (insn));\n+  INSN_HARD_BACK_DEPS (insn) = NULL;\n+\n+  free_deps_list (INSN_SPEC_BACK_DEPS (insn));\n+  INSN_SPEC_BACK_DEPS (insn) = NULL;\n+\n+  free_deps_list (INSN_RESOLVED_BACK_DEPS (insn));\n+  INSN_RESOLVED_BACK_DEPS (insn) = NULL;\n+\n+  free_deps_list (INSN_FORW_DEPS (insn));\n+  INSN_FORW_DEPS (insn) = NULL;\n+\n+  free_deps_list (INSN_RESOLVED_FORW_DEPS (insn));\n+  INSN_RESOLVED_FORW_DEPS (insn) = NULL;\n+}\n+\n+/* Find a dependency between producer PRO and consumer CON.\n+   Search through resolved dependency lists if RESOLVED_P is true.\n+   If no such dependency is found return NULL,\n+   overwise return the dependency and initialize SD_IT_PTR [if it is nonnull]\n+   with an iterator pointing to it.  */\n+static dep_t\n+sd_find_dep_between_no_cache (rtx pro, rtx con, bool resolved_p,\n+\t\t\t      sd_iterator_def *sd_it_ptr)\n+{\n+  sd_list_types_def pro_list_type;\n+  sd_list_types_def con_list_type;\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n+  bool found_p = false;\n+\n+  if (resolved_p)\n+    {\n+      pro_list_type = SD_LIST_RES_FORW;\n+      con_list_type = SD_LIST_RES_BACK;\n+    }\n+  else\n+    {\n+      pro_list_type = SD_LIST_FORW;\n+      con_list_type = SD_LIST_BACK;\n+    }\n+\n+  /* Walk through either back list of INSN or forw list of ELEM\n+     depending on which one is shorter.  */\n+  if (sd_lists_size (con, con_list_type) < sd_lists_size (pro, pro_list_type))\n+    {\n+      /* Find the dep_link with producer PRO in consumer's back_deps.  */\n+      FOR_EACH_DEP (con, con_list_type, sd_it, dep)\n+\tif (DEP_PRO (dep) == pro)\n+\t  {\n+\t    found_p = true;\n+\t    break;\n+\t  }\n+    }\n+  else\n+    {\n+      /* Find the dep_link with consumer CON in producer's forw_deps.  */\n+      FOR_EACH_DEP (pro, pro_list_type, sd_it, dep)\n+\tif (DEP_CON (dep) == con)\n+\t  {\n+\t    found_p = true;\n+\t    break;\n+\t  }\n+    }\n+\n+  if (found_p)\n+    {\n+      if (sd_it_ptr != NULL)\n+\t*sd_it_ptr = sd_it;\n+\n+      return dep;\n+    }\n+\n+  return NULL;\n+}\n+\n+/* Find a dependency between producer PRO and consumer CON.\n+   Use dependency [if available] to check if dependency is present at all.\n+   Search through resolved dependency lists if RESOLVED_P is true.\n+   If the dependency or NULL if none found.  */\n+dep_t\n+sd_find_dep_between (rtx pro, rtx con, bool resolved_p)\n+{\n+  if (true_dependency_cache != NULL)\n+    /* Avoiding the list walk below can cut compile times dramatically\n+       for some code.  */\n+    {\n+      int elem_luid = INSN_LUID (pro);\n+      int insn_luid = INSN_LUID (con);\n+\n+      gcc_assert (output_dependency_cache != NULL\n+\t\t  && anti_dependency_cache != NULL);\n+\n+      if (!bitmap_bit_p (&true_dependency_cache[insn_luid], elem_luid)\n+\t  && !bitmap_bit_p (&output_dependency_cache[insn_luid], elem_luid)\n+\t  && !bitmap_bit_p (&anti_dependency_cache[insn_luid], elem_luid))\n+\treturn NULL;\n+    }\n+\n+  return sd_find_dep_between_no_cache (pro, con, resolved_p, NULL);\n+}\n+\n+/* Add or update  a dependence described by DEP.\n+   MEM1 and MEM2, if non-null, correspond to memory locations in case of\n+   data speculation.\n+\n+   The function returns a value indicating if an old entry has been changed\n+   or a new entry has been added to insn's backward deps.\n+\n+   This function merely checks if producer and consumer is the same insn\n+   and doesn't create a dep in this case.  Actual manipulation of\n+   dependence data structures is performed in add_or_update_dep_1.  */\n static enum DEPS_ADJUST_RESULT\n-maybe_add_or_update_back_dep_1 (rtx insn, rtx elem, enum reg_note dep_type,\n-\t\t\t\tds_t ds, rtx mem1, rtx mem2,\n-\t\t\t\tdep_link_t **changed_linkpp)\n+maybe_add_or_update_dep_1 (dep_t dep, bool resolved_p, rtx mem1, rtx mem2)\n {\n+  rtx elem = DEP_PRO (dep);\n+  rtx insn = DEP_CON (dep);\n+\n   gcc_assert (INSN_P (insn) && INSN_P (elem));\n \n   /* Don't depend an insn on itself.  */\n@@ -594,319 +757,543 @@ maybe_add_or_update_back_dep_1 (rtx insn, rtx elem, enum reg_note dep_type,\n         /* INSN has an internal dependence, which we can't overcome.  */\n         HAS_INTERNAL_DEP (insn) = 1;\n #endif\n-      return 0;\n+\n+      return DEP_NODEP;\n     }\n \n-  return add_or_update_back_dep_1 (insn, elem, dep_type,\n-\t\t\t\t   ds, mem1, mem2, changed_linkpp);\n+  return add_or_update_dep_1 (dep, resolved_p, mem1, mem2);\n }\n \n-/* This function has the same meaning of parameters and return values\n-   as maybe_add_or_update_back_dep_1.  The only difference between these\n-   two functions is that INSN and ELEM are guaranteed not to be the same\n-   in this one.  */\n+#ifdef INSN_SCHEDULING\n+/* Ask dependency caches what needs to be done for dependence DEP.\n+   Return DEP_CREATED if new dependence should be created and there is no\n+   need to try to find one searching the dependencies lists.\n+   Return DEP_PRESENT if there already is a dependence described by DEP and\n+   hence nothing is to be done.\n+   Return DEP_CHANGED if there already is a dependence, but it should be\n+   updated to incorporate additional information from DEP.  */\n static enum DEPS_ADJUST_RESULT\n-add_or_update_back_dep_1 (rtx insn, rtx elem, enum reg_note dep_type, \n-\t\t\t  ds_t ds ATTRIBUTE_UNUSED,\n-\t\t\t  rtx mem1 ATTRIBUTE_UNUSED, rtx mem2 ATTRIBUTE_UNUSED,\n-\t\t\t  dep_link_t **changed_linkpp ATTRIBUTE_UNUSED)\n+ask_dependency_caches (dep_t dep)\n {\n-  bool maybe_present_p = true, present_p = false;\n+  int elem_luid = INSN_LUID (DEP_PRO (dep));\n+  int insn_luid = INSN_LUID (DEP_CON (dep));\n \n-  gcc_assert (INSN_P (insn) && INSN_P (elem) && insn != elem);\n-  \n-#ifdef INSN_SCHEDULING\n+  gcc_assert (true_dependency_cache != NULL\n+\t      && output_dependency_cache != NULL\n+\t      && anti_dependency_cache != NULL);\n \n-#ifdef ENABLE_CHECKING\n-  check_dep_status (dep_type, ds, mem1 != NULL);\n-#endif\n+  if (!(current_sched_info->flags & USE_DEPS_LIST))\n+    {          \n+      enum reg_note present_dep_type;\n+\n+      if (bitmap_bit_p (&true_dependency_cache[insn_luid], elem_luid))\n+\tpresent_dep_type = REG_DEP_TRUE;\n+      else if (bitmap_bit_p (&output_dependency_cache[insn_luid], elem_luid))\n+\tpresent_dep_type = REG_DEP_OUTPUT;\n+      else if (bitmap_bit_p (&anti_dependency_cache[insn_luid], elem_luid))\n+\tpresent_dep_type = REG_DEP_ANTI;\n+      else\n+\t/* There is no existing dep so it should be created.  */\n+\treturn DEP_CREATED;\n+\n+      if ((int) DEP_TYPE (dep) >= (int) present_dep_type)\n+\t/* DEP does not add anything to the existing dependence.  */\n+\treturn DEP_PRESENT;\n+    }\n+  else\n+    {      \n+      ds_t present_dep_types = 0;\n+          \n+      if (bitmap_bit_p (&true_dependency_cache[insn_luid], elem_luid))\n+\tpresent_dep_types |= DEP_TRUE;\n+      if (bitmap_bit_p (&output_dependency_cache[insn_luid], elem_luid))\n+\tpresent_dep_types |= DEP_OUTPUT;\n+      if (bitmap_bit_p (&anti_dependency_cache[insn_luid], elem_luid))\n+\tpresent_dep_types |= DEP_ANTI;\n+\n+      if (present_dep_types == 0)\n+\t/* There is no existing dep so it should be created.  */\n+\treturn DEP_CREATED;\n+\n+      if (!(current_sched_info->flags & DO_SPECULATION)\n+\t  || !bitmap_bit_p (&spec_dependency_cache[insn_luid], elem_luid))\n+\t{\n+\t  if ((present_dep_types | (DEP_STATUS (dep) & DEP_TYPES))\n+\t      == present_dep_types)\n+\t    /* DEP does not add anything to the existing dependence.  */\n+\t    return DEP_PRESENT;\n+\t}\n+      else\n+\t{\n+\t  /* Only true dependencies can be data speculative and\n+\t     only anti dependencies can be control speculative.  */\n+\t  gcc_assert ((present_dep_types & (DEP_TRUE | DEP_ANTI))\n+\t\t      == present_dep_types);\n+\n+\t  /* if (DEP is SPECULATIVE) then\n+\t     ..we should update DEP_STATUS\n+\t     else\n+\t     ..we should reset existing dep to non-speculative.  */\n+\t}\n+    }\n+\n+  return DEP_CHANGED;\n+}\n+\n+/* Set dependency caches according to DEP.  */\n+static void\n+set_dependency_caches (dep_t dep)\n+{\n+  int elem_luid = INSN_LUID (DEP_PRO (dep));\n+  int insn_luid = INSN_LUID (DEP_CON (dep));\n+\n+  if (!(current_sched_info->flags & USE_DEPS_LIST))\n+    {\n+      switch (DEP_TYPE (dep))\n+\t{\n+\tcase REG_DEP_TRUE:\n+\t  bitmap_set_bit (&true_dependency_cache[insn_luid], elem_luid);\n+\t  break;\n+\n+\tcase REG_DEP_OUTPUT:\n+\t  bitmap_set_bit (&output_dependency_cache[insn_luid], elem_luid);\n+\t  break;\n+\n+\tcase REG_DEP_ANTI:\n+\t  bitmap_set_bit (&anti_dependency_cache[insn_luid], elem_luid);\n+\t  break;\n+\n+\tdefault:\n+\t  gcc_unreachable ();\n+\t}\n+    }\n+  else\n+    {\n+      ds_t ds = DEP_STATUS (dep);\n+\n+      if (ds & DEP_TRUE)\n+\tbitmap_set_bit (&true_dependency_cache[insn_luid], elem_luid);\n+      if (ds & DEP_OUTPUT)\n+\tbitmap_set_bit (&output_dependency_cache[insn_luid], elem_luid);\n+      if (ds & DEP_ANTI)\n+\tbitmap_set_bit (&anti_dependency_cache[insn_luid], elem_luid);\n+\n+      if (ds & SPECULATIVE)\n+\t{\n+\t  gcc_assert (current_sched_info->flags & DO_SPECULATION);\n+\t  bitmap_set_bit (&spec_dependency_cache[insn_luid], elem_luid);\n+\t}\n+    }\n+}\n+\n+/* Type of dependence DEP have changed from OLD_TYPE.  Update dependency\n+   caches accordingly.  */\n+static void\n+update_dependency_caches (dep_t dep, enum reg_note old_type)\n+{\n+  int elem_luid = INSN_LUID (DEP_PRO (dep));\n+  int insn_luid = INSN_LUID (DEP_CON (dep));\n+\n+  /* Clear corresponding cache entry because type of the link\n+     may have changed.  Keep them if we use_deps_list.  */\n+  if (!(current_sched_info->flags & USE_DEPS_LIST))\n+    {\n+      switch (old_type)\n+\t{\n+\tcase REG_DEP_OUTPUT:\n+\t  bitmap_clear_bit (&output_dependency_cache[insn_luid], elem_luid);\n+\t  break;\n+\n+\tcase REG_DEP_ANTI:\n+\t  bitmap_clear_bit (&anti_dependency_cache[insn_luid], elem_luid);\n+\t  break;\n+\n+\tdefault:\n+\t  gcc_unreachable ();                        \n+\t}\n+    }\n+\n+  set_dependency_caches (dep);\n+}\n+\n+/* Convert a dependence pointed to by SD_IT to be non-speculative.  */\n+static void\n+change_spec_dep_to_hard (sd_iterator_def sd_it)\n+{\n+  dep_node_t node = DEP_LINK_NODE (*sd_it.linkp);\n+  dep_link_t link = DEP_NODE_BACK (node);\n+  dep_t dep = DEP_NODE_DEP (node);\n+  rtx elem = DEP_PRO (dep);\n+  rtx insn = DEP_CON (dep);\n+\n+  move_dep_link (link, INSN_SPEC_BACK_DEPS (insn), INSN_HARD_BACK_DEPS (insn));\n+\n+  DEP_STATUS (dep) &= ~SPECULATIVE;\n \n-  /* If we already have a dependency for ELEM, then we do not need to\n-     do anything.  Avoiding the list walk below can cut compile times\n-     dramatically for some code.  */\n   if (true_dependency_cache != NULL)\n+    /* Clear the cache entry.  */\n+    bitmap_clear_bit (&spec_dependency_cache[INSN_LUID (insn)],\n+\t\t      INSN_LUID (elem));\n+}\n+#endif\n+\n+/* Update DEP to incorporate information from NEW_DEP.\n+   SD_IT points to DEP in case it should be moved to another list.\n+   MEM1 and MEM2, if nonnull, correspond to memory locations in case if\n+   data-speculative dependence should be updated.  */\n+static enum DEPS_ADJUST_RESULT\n+update_dep (dep_t dep, dep_t new_dep,\n+\t    sd_iterator_def sd_it, rtx mem1, rtx mem2)\n+{\n+  enum DEPS_ADJUST_RESULT res = DEP_PRESENT;\n+  enum reg_note old_type = DEP_TYPE (dep);\n+\n+  /* If this is a more restrictive type of dependence than the\n+     existing one, then change the existing dependence to this\n+     type.  */\n+  if ((int) DEP_TYPE (new_dep) < (int) old_type)\n     {\n-      enum reg_note present_dep_type;\n-      \n-      gcc_assert (output_dependency_cache);\n-      gcc_assert (anti_dependency_cache);\n-      if (!(current_sched_info->flags & USE_DEPS_LIST))\n-        {          \n-          if (bitmap_bit_p (&true_dependency_cache[INSN_LUID (insn)],\n-\t\t\t    INSN_LUID (elem)))\n-            present_dep_type = REG_DEP_TRUE;\n-          else if (bitmap_bit_p (&output_dependency_cache[INSN_LUID (insn)],\n-\t\t\t\t INSN_LUID (elem)))\n-            present_dep_type = REG_DEP_OUTPUT;\n-          else if (bitmap_bit_p (&anti_dependency_cache[INSN_LUID (insn)],\n-\t\t\t\t INSN_LUID (elem)))\n-            present_dep_type = REG_DEP_ANTI;\n-          else\n-            maybe_present_p = false;\n-\n-\t  if (maybe_present_p)\n+      DEP_TYPE (dep) = DEP_TYPE (new_dep);\n+      res = DEP_CHANGED;\n+    }\n+\n+#ifdef INSN_SCHEDULING\n+  if (current_sched_info->flags & USE_DEPS_LIST)\n+    /* Update DEP_STATUS.  */\n+    {\n+      ds_t dep_status = DEP_STATUS (dep);\n+      ds_t ds = DEP_STATUS (new_dep);\n+      ds_t new_status = ds | dep_status;\n+\n+      if (new_status & SPECULATIVE)\n+\t/* Either existing dep or a dep we're adding or both are\n+\t   speculative.  */\n+\t{\n+\t  if (!(ds & SPECULATIVE)\n+\t      || !(dep_status & SPECULATIVE))\n+\t    /* The new dep can't be speculative.  */\n \t    {\n-\t      if ((int) dep_type >= (int) present_dep_type)\n-\t\treturn DEP_PRESENT;\n-\t      \n-\t      present_p = true;\n+\t      new_status &= ~SPECULATIVE;\n+\n+\t      if (dep_status & SPECULATIVE)\n+\t\t/* The old dep was speculative, but now it\n+\t\t   isn't.  */\n+\t\tchange_spec_dep_to_hard (sd_it);\n \t    }\n-        }\n-      else\n-        {      \n-          ds_t present_dep_types = 0;\n-          \n-          if (bitmap_bit_p (&true_dependency_cache[INSN_LUID (insn)],\n-\t\t\t    INSN_LUID (elem)))\n-            present_dep_types |= DEP_TRUE;\n-          if (bitmap_bit_p (&output_dependency_cache[INSN_LUID (insn)],\n-\t\t\t    INSN_LUID (elem)))\n-            present_dep_types |= DEP_OUTPUT;\n-          if (bitmap_bit_p (&anti_dependency_cache[INSN_LUID (insn)],\n-\t\t\t    INSN_LUID (elem)))\n-            present_dep_types |= DEP_ANTI;\n-\n-          if (present_dep_types)\n+\t  else\n \t    {\n-\t      if (!(current_sched_info->flags & DO_SPECULATION)\n-\t\t  || !bitmap_bit_p (&spec_dependency_cache[INSN_LUID (insn)],\n-\t\t\t\t    INSN_LUID (elem)))\n+\t      /* Both are speculative.  Merge probabilities.  */\n+\t      if (mem1 != NULL)\n \t\t{\n-\t\t  if ((present_dep_types | (ds & DEP_TYPES))\n-\t\t      == present_dep_types)\n-\t\t    /* We already have all these bits.  */\n-\t\t    return DEP_PRESENT;\n-\t\t}\n-\t      else\n-\t\t{\n-\t\t  /* Only true dependencies can be data speculative and\n-\t\t     only anti dependencies can be control speculative.  */\n-\t\t  gcc_assert ((present_dep_types & (DEP_TRUE | DEP_ANTI))\n-\t\t\t      == present_dep_types);\n-\t\t  \n-\t\t  /* if (additional dep is SPECULATIVE) then\n- \t\t       we should update DEP_STATUS\n-\t\t     else\n-\t\t       we should reset existing dep to non-speculative.  */\n+\t\t  dw_t dw;\n+\n+\t\t  dw = estimate_dep_weak (mem1, mem2);\n+\t\t  ds = set_dep_weak (ds, BEGIN_DATA, dw);\n \t\t}\n-\t  \t\n-\t      present_p = true;\n+\t\t\t\t\t\t\t \n+\t      new_status = ds_merge (dep_status, ds);\n \t    }\n-\t  else\n-\t    maybe_present_p = false;\n-        }\n+\t}\n+\n+      ds = new_status;\n+\n+      if (dep_status != ds)\n+\t{\n+\t  DEP_STATUS (dep) = ds;\n+\t  res = DEP_CHANGED;\n+\t}\n+    }\n+\n+  if (true_dependency_cache != NULL\n+      && res == DEP_CHANGED)\n+    update_dependency_caches (dep, old_type);\n+#endif\n+\n+  return res;\n+}\n+\n+/* Add or update  a dependence described by DEP.\n+   MEM1 and MEM2, if non-null, correspond to memory locations in case of\n+   data speculation.\n+\n+   The function returns a value indicating if an old entry has been changed\n+   or a new entry has been added to insn's backward deps or nothing has\n+   been updated at all.  */\n+static enum DEPS_ADJUST_RESULT\n+add_or_update_dep_1 (dep_t new_dep, bool resolved_p,\n+\t\t     rtx mem1 ATTRIBUTE_UNUSED, rtx mem2 ATTRIBUTE_UNUSED)\n+{\n+  bool maybe_present_p = true;\n+  bool present_p = false;\n+\n+  gcc_assert (INSN_P (DEP_PRO (new_dep)) && INSN_P (DEP_CON (new_dep))\n+\t      && DEP_PRO (new_dep) != DEP_CON (new_dep));\n+  \n+#ifdef INSN_SCHEDULING\n+\n+#ifdef ENABLE_CHECKING\n+  check_dep (new_dep, mem1 != NULL);\n+#endif\n+\n+  if (true_dependency_cache != NULL)\n+    {\n+      switch (ask_dependency_caches (new_dep))\n+\t{\n+\tcase DEP_PRESENT:\n+\t  return DEP_PRESENT;\n+\n+\tcase DEP_CHANGED:\n+\t  maybe_present_p = true;\n+\t  present_p = true;\n+\t  break;\n+\n+\tcase DEP_CREATED:\n+\t  maybe_present_p = false;\n+\t  present_p = false;\n+\t  break;\n+\n+\tdefault:\n+\t  gcc_unreachable ();\n+\t  break;\n+\t}\n     }\n #endif\n \n   /* Check that we don't already have this dependence.  */\n   if (maybe_present_p)\n     {\n-      dep_link_t *linkp;\n-\n-      for (linkp = &DEPS_LIST_FIRST (INSN_BACK_DEPS (insn));\n-\t   *linkp != NULL;\n-\t   linkp = &DEP_LINK_NEXT (*linkp))\n-        {\n-          dep_t link = DEP_LINK_DEP (*linkp);\n-\n-\t  gcc_assert (true_dependency_cache == 0 || present_p);\n-\t  \n-          if (DEP_PRO (link) == elem)\n-            {\n-              enum DEPS_ADJUST_RESULT changed_p = DEP_PRESENT;\n-\n-#ifdef INSN_SCHEDULING\n-              if (current_sched_info->flags & USE_DEPS_LIST)\n-                {\n-                  ds_t new_status = ds | DEP_STATUS (link);\n-\n-\t\t  if (new_status & SPECULATIVE)\n-\t\t    {\n-\t\t      if (!(ds & SPECULATIVE)\n-\t\t\t  || !(DEP_STATUS (link) & SPECULATIVE))\n-\t\t\t/* Then this dep can't be speculative.  */\n-\t\t\t{\n-\t\t\t  new_status &= ~SPECULATIVE;\n-\t\t\t  if (true_dependency_cache\n-\t\t\t      && (DEP_STATUS (link) & SPECULATIVE))\n-\t\t\t    bitmap_clear_bit (&spec_dependency_cache\n-\t\t\t\t\t      [INSN_LUID (insn)],\n-\t\t\t\t\t      INSN_LUID (elem));\n-\t\t\t}\n-\t\t      else\n-\t\t\t{\n-\t\t\t  /* Both are speculative.  Merging probabilities.  */\n-\t\t\t  if (mem1)\n-\t\t\t    {\n-\t\t\t      dw_t dw;\n-\n-\t\t\t      dw = estimate_dep_weak (mem1, mem2);\n-\t\t\t      ds = set_dep_weak (ds, BEGIN_DATA, dw);\n-\t\t\t    }\n-\t\t\t\t\t\t\t \n-\t\t\t  new_status = ds_merge (DEP_STATUS (link), ds);\n-\t\t\t}\n-\t\t    }\n-\n-\t\t  ds = new_status;\n-                }\n+      dep_t present_dep;\n+      sd_iterator_def sd_it;\n \n-              /* Clear corresponding cache entry because type of the link\n-                 may have changed.  Keep them if we use_deps_list.  */\n-              if (true_dependency_cache != NULL\n-\t\t  && !(current_sched_info->flags & USE_DEPS_LIST))\n-\t\t{\n-\t\t  enum reg_note kind = DEP_KIND (link);\n-\n-\t\t  switch (kind)\n-\t\t    {\n-\t\t    case REG_DEP_OUTPUT:\n-\t\t      bitmap_clear_bit (&output_dependency_cache\n-\t\t\t\t\t[INSN_LUID (insn)], INSN_LUID (elem));\n-\t\t      break;\n-\t\t    case REG_DEP_ANTI:\n-\t\t      bitmap_clear_bit (&anti_dependency_cache\n-\t\t\t\t\t[INSN_LUID (insn)], INSN_LUID (elem));\n-\t\t      break;\n-\t\t    default:\n-\t\t      gcc_unreachable ();                        \n-                    }\n-                }\n-\n-              if ((current_sched_info->flags & USE_DEPS_LIST)\n-\t\t  && DEP_STATUS (link) != ds)\n-\t\t{\n-\t\t  DEP_STATUS (link) = ds;\n-\t\t  changed_p = DEP_CHANGED;\n-\t\t}\n-#endif\n+      gcc_assert (true_dependency_cache == NULL || present_p);\n \n-              /* If this is a more restrictive type of dependence than the\n-\t\t existing one, then change the existing dependence to this\n-\t\t type.  */\n-              if ((int) dep_type < (int) DEP_KIND (link))\n-                {\n-\t\t  DEP_KIND (link) = dep_type;\n-                  changed_p = DEP_CHANGED;\n-                }\n+      present_dep = sd_find_dep_between_no_cache (DEP_PRO (new_dep),\n+\t\t\t\t\t\t  DEP_CON (new_dep),\n+\t\t\t\t\t\t  resolved_p, &sd_it);\n \n-#ifdef INSN_SCHEDULING\n-              /* If we are adding a dependency to INSN's LOG_LINKs, then\n-                 note that in the bitmap caches of dependency information.  */\n-              if (true_dependency_cache != NULL)\n-                {\n-                  if (!(current_sched_info->flags & USE_DEPS_LIST))\n-                    {\n-                      if (DEP_KIND (link) == REG_DEP_TRUE)\n-                        bitmap_set_bit (&true_dependency_cache\n-\t\t\t\t\t[INSN_LUID (insn)], INSN_LUID (elem));\n-                      else if (DEP_KIND (link) == REG_DEP_OUTPUT)\n-                        bitmap_set_bit (&output_dependency_cache\n-\t\t\t\t\t[INSN_LUID (insn)], INSN_LUID (elem));\n-                      else if (DEP_KIND (link) == REG_DEP_ANTI)\n-                        bitmap_set_bit (&anti_dependency_cache\n-\t\t\t\t\t[INSN_LUID (insn)], INSN_LUID (elem));\n-                    }\n-                  else\n-                    {\n-                      if (ds & DEP_TRUE)\n-                        bitmap_set_bit (&true_dependency_cache\n-\t\t\t\t\t[INSN_LUID (insn)], INSN_LUID (elem));\n-                      if (ds & DEP_OUTPUT)\n-                        bitmap_set_bit (&output_dependency_cache\n-\t\t\t\t\t[INSN_LUID (insn)], INSN_LUID (elem));\n-                      if (ds & DEP_ANTI)\n-                        bitmap_set_bit (&anti_dependency_cache\n-\t\t\t\t\t[INSN_LUID (insn)], INSN_LUID (elem));\n-                      /* Note, that dep can become speculative only \n-                         at the moment of creation. Thus, we don't need to \n-\t\t         check for it here.  */\n-                    }\n-                }\n-              \n-              if (changed_linkpp && changed_p == DEP_CHANGED)\n-                *changed_linkpp = linkp;\n-#endif\n-              return changed_p;\n-            }\t  \n-        }\n-      /* We didn't find a dep. It shouldn't be present in the cache.  */\n-      gcc_assert (!present_p);\n+      if (present_dep != NULL)\n+\t/* We found an existing dependency between ELEM and INSN.  */\n+\treturn update_dep (present_dep, new_dep, sd_it, mem1, mem2);\n+      else\n+\t/* We didn't find a dep, it shouldn't present in the cache.  */\n+\tgcc_assert (!present_p);\n     }\n \n   /* Might want to check one level of transitivity to save conses.\n-     This check should be done in maybe_add_or_update_back_dep_1.\n-     Since we made it to add_or_update_back_dep_1, we must create\n+     This check should be done in maybe_add_or_update_dep_1.\n+     Since we made it to add_or_update_dep_1, we must create\n      (or update) a link.  */\n \n-  if (mem1)\n+  if (mem1 != NULL_RTX)\n     {\n       gcc_assert (current_sched_info->flags & DO_SPECULATION);\n-      ds = set_dep_weak (ds, BEGIN_DATA, estimate_dep_weak (mem1, mem2));\n+      DEP_STATUS (new_dep) = set_dep_weak (DEP_STATUS (new_dep), BEGIN_DATA,\n+\t\t\t\t\t   estimate_dep_weak (mem1, mem2));\n     }\n-  \n-  add_back_dep (insn, elem, dep_type, ds);\n+\n+  sd_add_dep (new_dep, resolved_p);\n   \n   return DEP_CREATED;\n }\n \n-/* This function creates a link between INSN and ELEM under any\n-   conditions.  DS describes speculative status of the link.  */\n+/* Initialize BACK_LIST_PTR with consumer's backward list and\n+   FORW_LIST_PTR with producer's forward list.  If RESOLVED_P is true\n+   initialize with lists that hold resolved deps.  */\n static void\n-add_back_dep (rtx insn, rtx elem, enum reg_note dep_type, ds_t ds)\n+get_back_and_forw_lists (dep_t dep, bool resolved_p,\n+\t\t\t deps_list_t *back_list_ptr,\n+\t\t\t deps_list_t *forw_list_ptr)\n {\n-  struct _dep _dep, *dep = &_dep;\n+  rtx con = DEP_CON (dep);\n \n-  gcc_assert (INSN_P (insn) && INSN_P (elem) && insn != elem);\n+  if (!resolved_p)\n+    {\n+      if ((current_sched_info->flags & DO_SPECULATION)\n+\t  && (DEP_STATUS (dep) & SPECULATIVE))\n+\t*back_list_ptr = INSN_SPEC_BACK_DEPS (con);\n+      else\n+\t*back_list_ptr = INSN_HARD_BACK_DEPS (con);\n \n-  if (current_sched_info->flags & USE_DEPS_LIST)\n-    init_dep_1 (dep, elem, insn, dep_type, ds);\n+      *forw_list_ptr = INSN_FORW_DEPS (DEP_PRO (dep));\n+    }\n   else\n-    init_dep_1 (dep, elem, insn, dep_type, -1);\n+    {\n+      *back_list_ptr = INSN_RESOLVED_BACK_DEPS (con);\n+      *forw_list_ptr = INSN_RESOLVED_FORW_DEPS (DEP_PRO (dep));\n+    }\n+}\n+\n+/* Add dependence described by DEP.\n+   If RESOLVED_P is true treat the dependence as a resolved one.  */\n+void\n+sd_add_dep (dep_t dep, bool resolved_p)\n+{\n+  dep_node_t n = create_dep_node ();\n+  deps_list_t con_back_deps;\n+  deps_list_t pro_forw_deps;\n+  rtx elem = DEP_PRO (dep);\n+  rtx insn = DEP_CON (dep);\n+\n+  gcc_assert (INSN_P (insn) && INSN_P (elem) && insn != elem);\n+\n+  if ((current_sched_info->flags & DO_SPECULATION)\n+      && !sched_insn_is_legitimate_for_speculation_p (insn, DEP_STATUS (dep)))\n+    DEP_STATUS (dep) &= ~SPECULATIVE;\n+\n+  copy_dep (DEP_NODE_DEP (n), dep);\n+\n+  get_back_and_forw_lists (dep, resolved_p, &con_back_deps, &pro_forw_deps);\n \n-  add_back_dep_to_deps_list (INSN_BACK_DEPS (insn), dep);\n+  add_to_deps_list (DEP_NODE_BACK (n), con_back_deps);\n \n #ifdef INSN_SCHEDULING\n #ifdef ENABLE_CHECKING\n-  check_dep_status (dep_type, ds, false);\n+  check_dep (dep, false);\n #endif\n \n+  add_to_deps_list (DEP_NODE_FORW (n), pro_forw_deps);\n+\n   /* If we are adding a dependency to INSN's LOG_LINKs, then note that\n      in the bitmap caches of dependency information.  */\n   if (true_dependency_cache != NULL)\n+    set_dependency_caches (dep);\n+#endif\n+}\n+\n+/* Add or update backward dependence between INSN and ELEM\n+   with given type DEP_TYPE and dep_status DS.\n+   This function is a convenience wrapper.  */\n+enum DEPS_ADJUST_RESULT\n+sd_add_or_update_dep (dep_t dep, bool resolved_p)\n+{\n+  return add_or_update_dep_1 (dep, resolved_p, NULL_RTX, NULL_RTX);\n+}\n+\n+/* Resolved dependence pointed to by SD_IT.\n+   SD_IT will advance to the next element.  */\n+void\n+sd_resolve_dep (sd_iterator_def sd_it)\n+{\n+  dep_node_t node = DEP_LINK_NODE (*sd_it.linkp);\n+  dep_t dep = DEP_NODE_DEP (node);\n+  rtx pro = DEP_PRO (dep);\n+  rtx con = DEP_CON (dep);\n+\n+  if ((current_sched_info->flags & DO_SPECULATION)\n+      && (DEP_STATUS (dep) & SPECULATIVE))\n+    move_dep_link (DEP_NODE_BACK (node), INSN_SPEC_BACK_DEPS (con),\n+\t\t   INSN_RESOLVED_BACK_DEPS (con));\n+  else\n+    move_dep_link (DEP_NODE_BACK (node), INSN_HARD_BACK_DEPS (con),\n+\t\t   INSN_RESOLVED_BACK_DEPS (con));\n+\n+  move_dep_link (DEP_NODE_FORW (node), INSN_FORW_DEPS (pro),\n+\t\t INSN_RESOLVED_FORW_DEPS (pro));\n+}\n+\n+/* Make TO depend on all the FROM's producers.\n+   If RESOLVED_P is true add dependencies to the resolved lists.  */\n+void\n+sd_copy_back_deps (rtx to, rtx from, bool resolved_p)\n+{\n+  sd_list_types_def list_type;\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n+\n+  list_type = resolved_p ? SD_LIST_RES_BACK : SD_LIST_BACK;\n+\n+  FOR_EACH_DEP (from, list_type, sd_it, dep)\n     {\n-      if (!(current_sched_info->flags & USE_DEPS_LIST))\n-        {\n-          if (dep_type == REG_DEP_TRUE)\n-            bitmap_set_bit (&true_dependency_cache[INSN_LUID (insn)],\n-\t\t\t    INSN_LUID (elem));\n-          else if (dep_type == REG_DEP_OUTPUT)\n-            bitmap_set_bit (&output_dependency_cache[INSN_LUID (insn)],\n-\t\t\t    INSN_LUID (elem));\n-          else if (dep_type == REG_DEP_ANTI)\n-                bitmap_set_bit (&anti_dependency_cache[INSN_LUID (insn)],\n-\t\t\t\tINSN_LUID (elem));\n-        }\n-      else\n-        {\n-          if (ds & DEP_TRUE)\n-            bitmap_set_bit (&true_dependency_cache[INSN_LUID (insn)],\n-\t\t\t    INSN_LUID (elem));\n-          if (ds & DEP_OUTPUT)\n-            bitmap_set_bit (&output_dependency_cache[INSN_LUID (insn)],\n-\t\t\t    INSN_LUID (elem));\n-          if (ds & DEP_ANTI)\n-            bitmap_set_bit (&anti_dependency_cache[INSN_LUID (insn)],\n-\t\t\t    INSN_LUID (elem));\n-          if (ds & SPECULATIVE)\n-\t    {\n-\t      gcc_assert (current_sched_info->flags & DO_SPECULATION);\n-\t      bitmap_set_bit (&spec_dependency_cache[INSN_LUID (insn)],\n-\t\t\t      INSN_LUID (elem));\n-\t    }\n-        }\n+      dep_def _new_dep, *new_dep = &_new_dep;\n+\n+      copy_dep (new_dep, dep);\n+      DEP_CON (new_dep) = to;\n+      sd_add_dep (new_dep, resolved_p);\n     }\n-#endif\n+}\n+\n+/* Remove a dependency referred to by SD_IT.\n+   SD_IT will point to the next dependence after removal.  */\n+void\n+sd_delete_dep (sd_iterator_def sd_it)\n+{\n+  dep_node_t n = DEP_LINK_NODE (*sd_it.linkp);\n+  dep_t dep = DEP_NODE_DEP (n);\n+  rtx pro = DEP_PRO (dep);\n+  rtx con = DEP_CON (dep);\n+  deps_list_t con_back_deps;\n+  deps_list_t pro_forw_deps;\n+\n+  if (true_dependency_cache != NULL)\n+    {\n+      int elem_luid = INSN_LUID (pro);\n+      int insn_luid = INSN_LUID (con);\n+\n+      bitmap_clear_bit (&true_dependency_cache[insn_luid], elem_luid);\n+      bitmap_clear_bit (&anti_dependency_cache[insn_luid], elem_luid);\n+      bitmap_clear_bit (&output_dependency_cache[insn_luid], elem_luid);\n+\n+      if (current_sched_info->flags & DO_SPECULATION)\n+\tbitmap_clear_bit (&spec_dependency_cache[insn_luid], elem_luid);\n+    }\n+\n+  get_back_and_forw_lists (dep, sd_it.resolved_p,\n+\t\t\t   &con_back_deps, &pro_forw_deps);\n+\n+  remove_from_deps_list (DEP_NODE_BACK (n), con_back_deps);\n+  remove_from_deps_list (DEP_NODE_FORW (n), pro_forw_deps);\n+\n+  delete_dep_node (n);\n+}\n+\n+/* Dump size of the lists.  */\n+#define DUMP_LISTS_SIZE (2)\n+\n+/* Dump dependencies of the lists.  */\n+#define DUMP_LISTS_DEPS (4)\n+\n+/* Dump all information about the lists.  */\n+#define DUMP_LISTS_ALL (DUMP_LISTS_SIZE | DUMP_LISTS_DEPS)\n+\n+/* Dump deps_lists of INSN specified by TYPES to DUMP.\n+   FLAGS is a bit mask specifying what information about the lists needs\n+   to be printed.\n+   If FLAGS has the very first bit set, then dump all information about\n+   the lists and propagate this bit into the callee dump functions.  */\n+static void\n+dump_lists (FILE *dump, rtx insn, sd_list_types_def types, int flags)\n+{\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n+  int all;\n+\n+  all = (flags & 1);\n+\n+  if (all)\n+    flags |= DUMP_LISTS_ALL;\n+\n+  fprintf (dump, \"[\");\n+\n+  if (flags & DUMP_LISTS_SIZE)\n+    fprintf (dump, \"%d; \", sd_lists_size (insn, types));\n+\n+  if (flags & DUMP_LISTS_DEPS)\n+    {\n+      FOR_EACH_DEP (insn, types, sd_it, dep)\n+\t{\n+\t  dump_dep (dump, dep, dump_dep_flags | all);\n+\t  fprintf (dump, \" \");\n+\t}\n+    }\n+}\n+\n+/* Dump all information about deps_lists of INSN specified by TYPES\n+   to STDERR.  */\n+void\n+sd_debug_lists (rtx insn, sd_list_types_def types)\n+{\n+  dump_lists (stderr, insn, types, 1);\n+  fprintf (stderr, \"\\n\");\n }\n \n /* A convenience wrapper to operate on an entire list.  */\n@@ -938,26 +1325,19 @@ add_dependence_list_and_free (rtx insn, rtx *listp, int uncond,\n }\n \n /* Clear all dependencies for an insn.  */\n-\n static void\n delete_all_dependences (rtx insn)\n {\n-  /* Clear caches, if they exist, as well as free the dependence.  */\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n \n-#ifdef INSN_SCHEDULING\n-  if (true_dependency_cache != NULL)\n-    {\n-      bitmap_clear (&true_dependency_cache[INSN_LUID (insn)]);\n-      bitmap_clear (&output_dependency_cache[INSN_LUID (insn)]);\n-      bitmap_clear (&anti_dependency_cache[INSN_LUID (insn)]);\n-      /* We don't have to clear forward_dependency_cache here,\n-\t because it is formed later.  */\n-      if (current_sched_info->flags & DO_SPECULATION)\n-        bitmap_clear (&spec_dependency_cache[INSN_LUID (insn)]);\n-    }\n-#endif\n+  /* The below cycle can be optimized to clear the caches and back_deps\n+     in one call but that would provoke duplication of code from\n+     delete_dep ().  */\n \n-  clear_deps_list (INSN_BACK_DEPS (insn));  \n+  for (sd_it = sd_iterator_start (insn, SD_LIST_BACK);\n+       sd_iterator_cond (&sd_it, &dep);)\n+    sd_delete_dep (sd_it);\n }\n \n /* All insns in a scheduling group except the first should only have\n@@ -969,13 +1349,13 @@ delete_all_dependences (rtx insn)\n static void\n fixup_sched_groups (rtx insn)\n {\n-  dep_link_t link;\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n   rtx prev_nonnote;\n \n-  FOR_EACH_DEP_LINK (link, INSN_BACK_DEPS (insn))\n+  FOR_EACH_DEP (insn, SD_LIST_BACK, sd_it, dep)\n     {\n       rtx i = insn;\n-      dep_t dep = DEP_LINK_DEP (link);\n       rtx pro = DEP_PRO (dep);\n \n       do\n@@ -987,7 +1367,7 @@ fixup_sched_groups (rtx insn)\n \t} while (SCHED_GROUP_P (i));\n \n       if (! sched_insns_conditions_mutex_p (i, pro))\n-\tadd_dependence (i, pro, DEP_KIND (dep));\n+\tadd_dependence (i, pro, DEP_TYPE (dep));\n     next_link:;\n     }\n \n@@ -1373,11 +1753,19 @@ sched_analyze_2 (struct deps *deps, rtx x, rtx insn)\n \t\t\t\t t, rtx_varies_p)\n \t\t&& ! sched_insns_conditions_mutex_p (insn, XEXP (pending, 0)))\n               {\n-                if (current_sched_info->flags & DO_SPECULATION)\n-                  maybe_add_or_update_back_dep_1 (insn, XEXP (pending, 0),\n-\t\t\t\t\t\t  REG_DEP_TRUE,\n-\t\t\t\t\t\t  BEGIN_DATA | DEP_TRUE,\n-\t\t\t\t\t\t  XEXP (pending_mem, 0), t, 0);\n+                if ((current_sched_info->flags & DO_SPECULATION)\n+\t\t    && (spec_info->mask & BEGIN_DATA))\n+\t\t  /* Create a data-speculative dependence between producer\n+\t\t     and consumer.  */\n+\t\t  {\n+\t\t    dep_def _dep, *dep = &_dep;\n+\n+\t\t    init_dep_1 (dep, XEXP (pending, 0), insn, REG_DEP_TRUE,\n+\t\t\t\tBEGIN_DATA | DEP_TRUE);\n+\n+\t\t    maybe_add_or_update_dep_1 (dep, false,\n+\t\t\t\t\t       XEXP (pending_mem, 0), t);\n+\t\t  }\n                 else\n                   add_dependence (insn, XEXP (pending, 0), REG_DEP_TRUE);\n               }\n@@ -1810,6 +2198,19 @@ sched_analyze_insn (struct deps *deps, rtx x, rtx insn)\n   /* Fixup the dependencies in the sched group.  */\n   if (SCHED_GROUP_P (insn))\n     fixup_sched_groups (insn);\n+\n+  if ((current_sched_info->flags & DO_SPECULATION)\n+      && !sched_insn_is_legitimate_for_speculation_p (insn, 0))\n+    /* INSN has an internal dependency (e.g. r14 = [r14]) and thus cannot\n+       be speculated.  */\n+    {\n+      sd_iterator_def sd_it;\n+      dep_t dep;\n+\n+      for (sd_it = sd_iterator_start (insn, SD_LIST_SPEC_BACK);\n+\t   sd_iterator_cond (&sd_it, &dep);)\n+\tchange_spec_dep_to_hard (sd_it);\n+    }\n }\n \n /* Analyze every insn between HEAD and TAIL inclusive, creating backward\n@@ -1838,13 +2239,8 @@ sched_analyze (struct deps *deps, rtx head, rtx tail)\n \n       if (INSN_P (insn))\n \t{\n-\t  /* These two lists will be freed in schedule_insn ().  */\n-\t  INSN_BACK_DEPS (insn) = create_deps_list (false);\n-\t  INSN_RESOLVED_BACK_DEPS (insn) = create_deps_list (false);\n-\n-\t  /* This one should be allocated on the obstack because it should live\n-\t     till the scheduling ends.  */\n-\t  INSN_FORW_DEPS (insn) = create_deps_list (true);\n+\t  /* And initialize deps_lists.  */\n+\t  sd_init_insn (insn);\n \t}\n \n       if (NONJUMP_INSN_P (insn) || JUMP_P (insn))\n@@ -1986,94 +2382,58 @@ sched_analyze (struct deps *deps, rtx head, rtx tail)\n     }\n   gcc_unreachable ();\n }\n-\f\n-\n-/* The following function adds forward dependence (FROM, TO) with\n-   given DEP_TYPE.  The forward dependence should be not exist before.  */\n \n-void\n-add_forw_dep (dep_link_t link)\n+/* Helper for sched_free_deps ().\n+   Delete INSN's (RESOLVED_P) backward dependencies.  */\n+static void\n+delete_dep_nodes_in_back_deps (rtx insn, bool resolved_p)\n {\n-  dep_t dep = DEP_LINK_DEP (link);\n-  rtx to = DEP_CON (dep);\n-  rtx from = DEP_PRO (dep);\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n+  sd_list_types_def types;\n \n-#ifdef ENABLE_CHECKING\n-  /* If add_dependence is working properly there should never\n-     be notes, deleted insns or duplicates in the backward\n-     links.  Thus we need not check for them here.\n-\n-     However, if we have enabled checking we might as well go\n-     ahead and verify that add_dependence worked properly.  */\n-  gcc_assert (INSN_P (from));\n-  gcc_assert (!INSN_DELETED_P (from));\n-  if (true_dependency_cache)\n+  if (resolved_p)\n+    types = SD_LIST_RES_BACK;\n+  else\n+    types = SD_LIST_BACK;\n+\n+  for (sd_it = sd_iterator_start (insn, types);\n+       sd_iterator_cond (&sd_it, &dep);)\n     {\n-      gcc_assert (!bitmap_bit_p (&forward_dependency_cache[INSN_LUID (from)],\n-\t\t\t\t INSN_LUID (to)));\n-      bitmap_set_bit (&forward_dependency_cache[INSN_LUID (from)],\n-\t\t      INSN_LUID (to));\n+      dep_link_t link = *sd_it.linkp;\n+      dep_node_t node = DEP_LINK_NODE (link);\n+      deps_list_t back_list;\n+      deps_list_t forw_list;\n+\n+      get_back_and_forw_lists (dep, resolved_p, &back_list, &forw_list);\n+      remove_from_deps_list (link, back_list);\n+      delete_dep_node (node);\n     }\n-\n-  gcc_assert (find_link_by_con_in_deps_list (INSN_FORW_DEPS (from), to)\n-\t      == NULL);\n-#endif\n-\n-  add_to_deps_list (DEP_NODE_FORW (DEP_LINK_NODE (link)),\n-\t\t    INSN_FORW_DEPS (from));\n-\n-  INSN_DEP_COUNT (to) += 1;\n }\n \n-/* Examine insns in the range [ HEAD, TAIL ] and Use the backward\n-   dependences from INSN_BACK_DEPS list to build forward dependences in\n-   INSN_FORW_DEPS.  */\n-\n+/* Delete (RESOLVED_P) dependencies between HEAD and TAIL together with\n+   deps_lists.  */\n void\n-compute_forward_dependences (rtx head, rtx tail)\n+sched_free_deps (rtx head, rtx tail, bool resolved_p)\n {\n   rtx insn;\n-  rtx next_tail;\n+  rtx next_tail = NEXT_INSN (tail);\n \n-  next_tail = NEXT_INSN (tail);\n   for (insn = head; insn != next_tail; insn = NEXT_INSN (insn))\n-    {\n-      dep_link_t link;\n-      \n-      if (! INSN_P (insn))\n-\tcontinue;\n-      \n-      if (current_sched_info->flags & DO_SPECULATION)\n-        {\n-\t  /* We will add links, preserving order, from INSN_BACK_DEPS to\n-\t     NEW.  */\n-          dep_link_t new = NULL;\n-\n-\t  link = DEPS_LIST_FIRST (INSN_BACK_DEPS (insn));\n-\n-\t  while (link != NULL)\n-            {\n-\t      dep_link_t next = DEP_LINK_NEXT (link);\n-\n-\t      detach_dep_link (link);\n-              adjust_add_sorted_back_dep (insn, link, &new);\n-\n-\t      link = next;\n-            }\n-\n-\t  /* Attach NEW to be the list of backward dependencies.  */\n-\t  if (new != NULL)\n-\t    {\n-\t      DEP_LINK_PREV_NEXTP (new)\n-\t\t= &DEPS_LIST_FIRST (INSN_BACK_DEPS (insn));\n+    if (INSN_P (insn) && INSN_LUID (insn) > 0)\n+      {\n+\t/* Clear resolved back deps together with its dep_nodes.  */\n+\tdelete_dep_nodes_in_back_deps (insn, resolved_p);\n \n-\t      DEPS_LIST_FIRST (INSN_BACK_DEPS (insn)) = new;\n-\t    }\n-        }\n+\t/* Clear forward deps and leave the dep_nodes to the\n+\t   corresponding back_deps list.  */\n+\tif (resolved_p)\n+\t  clear_deps_list (INSN_RESOLVED_FORW_DEPS (insn));\n+\telse\n+\t  clear_deps_list (INSN_FORW_DEPS (insn));\n \n-      FOR_EACH_DEP_LINK (link, INSN_BACK_DEPS (insn))\n-        add_forw_dep (link);\n-    }\n+\tsd_finish_insn (insn);\n+      }\n }\n \f\n /* Initialize variables for region data dependence analysis.\n@@ -2143,27 +2503,31 @@ free_deps (struct deps *deps)\n void\n init_dependency_caches (int luid)\n {\n+  /* Average number of insns in the basic block.\n+     '+ 1' is used to make it nonzero.  */\n+  int insns_in_block = luid / n_basic_blocks + 1;\n+\n   /* ?!? We could save some memory by computing a per-region luid mapping\n      which could reduce both the number of vectors in the cache and the size\n      of each vector.  Instead we just avoid the cache entirely unless the\n      average number of instructions in a basic block is very high.  See\n      the comment before the declaration of true_dependency_cache for\n      what we consider \"very high\".  */\n-  if (luid / n_basic_blocks > 100 * 5)\n+  if (insns_in_block > 100 * 5)\n     {\n       cache_size = 0;\n       extend_dependency_caches (luid, true);\n     }\n \n-  /* Lifetime of this obstack is whole function scheduling (not single region\n-     scheduling) because some dependencies can be manually generated for\n-     outside regions.  See dont_calc_deps in sched-{rgn, ebb}.c .\n+  dl_pool = create_alloc_pool (\"deps_list\", sizeof (struct _deps_list),\n+\t\t\t       /* Allocate lists for one block at a time.  */\n+\t\t\t       insns_in_block);\n \n-     Possible solution would be to have two obstacks:\n-     * the big one for regular dependencies with region scheduling lifetime,\n-     * and the small one for manually generated dependencies with function\n-     scheduling lifetime.  */\n-  gcc_obstack_init (&deps_obstack);\n+  dn_pool = create_alloc_pool (\"dep_node\", sizeof (struct _dep_node),\n+\t\t\t       /* Allocate nodes for one block at a time.\n+\t\t\t\t  We assume that average insn has\n+\t\t\t\t  5 producers.  */\n+\t\t\t       5 * insns_in_block);\n }\n \n /* Create or extend (depending on CREATE_P) dependency caches to\n@@ -2181,10 +2545,7 @@ extend_dependency_caches (int n, bool create_p)\n \t\t\t\t\t    output_dependency_cache, luid);\n       anti_dependency_cache = XRESIZEVEC (bitmap_head, anti_dependency_cache,\n \t\t\t\t\t  luid);\n-#ifdef ENABLE_CHECKING\n-      forward_dependency_cache = XRESIZEVEC (bitmap_head,\n-\t\t\t\t\t     forward_dependency_cache, luid);\n-#endif\n+\n       if (current_sched_info->flags & DO_SPECULATION)\n         spec_dependency_cache = XRESIZEVEC (bitmap_head, spec_dependency_cache,\n \t\t\t\t\t    luid);\n@@ -2194,9 +2555,7 @@ extend_dependency_caches (int n, bool create_p)\n \t  bitmap_initialize (&true_dependency_cache[i], 0);\n \t  bitmap_initialize (&output_dependency_cache[i], 0);\n \t  bitmap_initialize (&anti_dependency_cache[i], 0);\n-#ifdef ENABLE_CHECKING\n-\t  bitmap_initialize (&forward_dependency_cache[i], 0);\n-#endif\n+\n           if (current_sched_info->flags & DO_SPECULATION)\n             bitmap_initialize (&spec_dependency_cache[i], 0);\n \t}\n@@ -2209,7 +2568,10 @@ extend_dependency_caches (int n, bool create_p)\n void\n free_dependency_caches (void)\n {\n-  obstack_free (&deps_obstack, NULL);\n+  gcc_assert (deps_pools_are_empty_p ());\n+  free_alloc_pool_if_empty (&dn_pool);\n+  free_alloc_pool_if_empty (&dl_pool);\n+  gcc_assert (dn_pool == NULL && dl_pool == NULL);\n \n   if (true_dependency_cache)\n     {\n@@ -2220,9 +2582,7 @@ free_dependency_caches (void)\n \t  bitmap_clear (&true_dependency_cache[i]);\n \t  bitmap_clear (&output_dependency_cache[i]);\n \t  bitmap_clear (&anti_dependency_cache[i]);\n-#ifdef ENABLE_CHECKING\n-\t  bitmap_clear (&forward_dependency_cache[i]);\n-#endif\n+\n           if (current_sched_info->flags & DO_SPECULATION)\n             bitmap_clear (&spec_dependency_cache[i]);\n \t}\n@@ -2232,10 +2592,7 @@ free_dependency_caches (void)\n       output_dependency_cache = NULL;\n       free (anti_dependency_cache);\n       anti_dependency_cache = NULL;\n-#ifdef ENABLE_CHECKING\n-      free (forward_dependency_cache);\n-      forward_dependency_cache = NULL;\n-#endif\n+\n       if (current_sched_info->flags & DO_SPECULATION)\n         {\n           free (spec_dependency_cache);\n@@ -2266,72 +2623,6 @@ finish_deps_global (void)\n   FREE_REG_SET (reg_pending_uses);\n }\n \n-/* Insert LINK into the dependence chain pointed to by LINKP and \n-   maintain the sort order.  */\n-static void\n-adjust_add_sorted_back_dep (rtx insn, dep_link_t link, dep_link_t *linkp)\n-{\n-  gcc_assert (current_sched_info->flags & DO_SPECULATION);\n-  \n-  /* If the insn cannot move speculatively, but the link is speculative,   \n-     make it hard dependence.  */\n-  if (HAS_INTERNAL_DEP (insn)\n-      && (DEP_LINK_STATUS (link) & SPECULATIVE))\n-    {      \n-      DEP_LINK_STATUS (link) &= ~SPECULATIVE;\n-      \n-      if (true_dependency_cache)\n-        bitmap_clear_bit (&spec_dependency_cache[INSN_LUID (insn)],\n-\t\t\t  INSN_LUID (DEP_LINK_PRO (link)));\n-    }\n-\n-  /* Non-speculative links go at the head of deps_list, followed by\n-     speculative links.  */\n-  if (DEP_LINK_STATUS (link) & SPECULATIVE)\n-    while (*linkp && !(DEP_LINK_STATUS (*linkp) & SPECULATIVE))\n-      linkp = &DEP_LINK_NEXT (*linkp);\n-\n-  attach_dep_link (link, linkp);\n-\n-  if (CHECK)\n-    gcc_assert (deps_list_consistent_p (INSN_BACK_DEPS (insn)));\n-}\n-\n-/* Move the dependence pointed to by LINKP to the back dependencies  \n-   of INSN, and also add this dependence to the forward ones.  All dep_links,\n-   except one pointed to by LINKP, must be sorted.  */\n-static void\n-adjust_back_add_forw_dep (rtx insn, dep_link_t *linkp)\n-{\n-  dep_link_t link;\n-\n-  gcc_assert (current_sched_info->flags & DO_SPECULATION);\n-\n-  link = *linkp;\n-  detach_dep_link (link);\n-\n-  adjust_add_sorted_back_dep (insn, link,\n-\t\t\t      &DEPS_LIST_FIRST (INSN_BACK_DEPS (insn)));\n-  add_forw_dep (link);\n-}\n-\n-/* Remove forward dependence described by L.  */\n-static void\n-delete_forw_dep (dep_link_t l)\n-{\n-  gcc_assert (current_sched_info->flags & DO_SPECULATION);\n-\n-#ifdef ENABLE_CHECKING\n-  if (true_dependency_cache)\n-    bitmap_clear_bit (&forward_dependency_cache[INSN_LUID (DEP_LINK_PRO (l))],\n-\t\t      INSN_LUID (DEP_LINK_CON (l)));\n-#endif\n-\n-  detach_dep_link (l);\n-\n-  INSN_DEP_COUNT (DEP_LINK_CON (l))--;\n-}\n-\n /* Estimate the weakness of dependence between MEM1 and MEM2.  */\n static dw_t\n estimate_dep_weak (rtx mem1, rtx mem2)\n@@ -2366,90 +2657,15 @@ estimate_dep_weak (rtx mem1, rtx mem2)\n void\n add_dependence (rtx insn, rtx elem, enum reg_note dep_type)\n {\n-  ds_t ds;\n-  \n-  if (dep_type == REG_DEP_TRUE)\n-    ds = DEP_TRUE;\n-  else if (dep_type == REG_DEP_OUTPUT)\n-    ds = DEP_OUTPUT;\n-  else if (dep_type == REG_DEP_ANTI)\n-    ds = DEP_ANTI;\n-  else\n-    gcc_unreachable ();\n-\n-  maybe_add_or_update_back_dep_1 (insn, elem, dep_type, ds, 0, 0, 0);\n-}\n-\n-/* Add or update backward dependence between INSN and ELEM\n-   with given type DEP_TYPE and dep_status DS.\n-   This function is a convenience wrapper.  */\n-enum DEPS_ADJUST_RESULT\n-add_or_update_back_dep (rtx insn, rtx elem, enum reg_note dep_type, ds_t ds)\n-{\n-  return add_or_update_back_dep_1 (insn, elem, dep_type, ds, 0, 0, 0);\n-}\n-\n-/* Add or update both backward and forward dependencies between INSN and ELEM\n-   with given type DEP_TYPE and dep_status DS.  */\n-void\n-add_or_update_back_forw_dep (rtx insn, rtx elem, enum reg_note dep_type,\n-\t\t\t     ds_t ds)\n-{\n-  enum DEPS_ADJUST_RESULT res;\n-  dep_link_t *linkp;\n-\n-  res = add_or_update_back_dep_1 (insn, elem, dep_type, ds, 0, 0, &linkp);\n-\n-  if (res == DEP_CHANGED || res == DEP_CREATED)\n-    {\n-      if (res == DEP_CHANGED)\n-\tdelete_forw_dep (DEP_NODE_FORW (DEP_LINK_NODE (*linkp)));\n-      else if (res == DEP_CREATED)\n-\tlinkp = &DEPS_LIST_FIRST (INSN_BACK_DEPS (insn));\n-\n-      adjust_back_add_forw_dep (insn, linkp);\n-    }\n-}\n-\n-/* Add both backward and forward dependencies between INSN and ELEM\n-   with given type DEP_TYPE and dep_status DS.  */\n-void\n-add_back_forw_dep (rtx insn, rtx elem, enum reg_note dep_type, ds_t ds)\n-{\n-  add_back_dep (insn, elem, dep_type, ds);\n-  adjust_back_add_forw_dep (insn, &DEPS_LIST_FIRST (INSN_BACK_DEPS (insn)));\n-\n-  if (CHECK)\n-    gcc_assert (deps_list_consistent_p (INSN_BACK_DEPS (insn)));\n-}\n-\n-/* Remove a dependency referred to by L.  */\n-void\n-delete_back_forw_dep (dep_link_t l)\n-{\n-  dep_node_t n = DEP_LINK_NODE (l);\n-\n-  gcc_assert (current_sched_info->flags & DO_SPECULATION);\n-\n-  if (true_dependency_cache != NULL)\n-    {\n-      dep_t dep = DEP_NODE_DEP (n);\n-      int elem_luid = INSN_LUID (DEP_PRO (dep));\n-      int insn_luid = INSN_LUID (DEP_CON (dep));\n-\n-      bitmap_clear_bit (&true_dependency_cache[insn_luid], elem_luid);\n-      bitmap_clear_bit (&anti_dependency_cache[insn_luid], elem_luid);\n-      bitmap_clear_bit (&output_dependency_cache[insn_luid], elem_luid);\n-      bitmap_clear_bit (&spec_dependency_cache[insn_luid], elem_luid);\n-    }\n+  dep_def _dep, *dep = &_dep;\n \n-  delete_forw_dep (DEP_NODE_FORW (n));\n-  detach_dep_link (DEP_NODE_BACK (n));\n+  init_dep (dep, elem, insn, dep_type);\n+  maybe_add_or_update_dep_1 (dep, false, NULL_RTX, NULL_RTX);\n }\n \n /* Return weakness of speculative type TYPE in the dep_status DS.  */\n-dw_t\n-get_dep_weak (ds_t ds, ds_t type)\n+static dw_t\n+get_dep_weak_1 (ds_t ds, ds_t type)\n {\n   ds = ds & type;\n   switch (type)\n@@ -2461,10 +2677,20 @@ get_dep_weak (ds_t ds, ds_t type)\n     default: gcc_unreachable ();\n     }\n \n-  gcc_assert (MIN_DEP_WEAK <= ds && ds <= MAX_DEP_WEAK);\n   return (dw_t) ds;\n }\n \n+/* Return weakness of speculative type TYPE in the dep_status DS.  */\n+dw_t\n+get_dep_weak (ds_t ds, ds_t type)\n+{\n+  dw_t dw = get_dep_weak_1 (ds, type);\n+\n+  gcc_assert (MIN_DEP_WEAK <= dw && dw <= MAX_DEP_WEAK);\n+\n+  return dw;\n+}\n+\n /* Return the dep_status, which has the same parameters as DS, except for\n    speculative type TYPE, that will have weakness DW.  */\n ds_t\n@@ -2522,13 +2748,59 @@ ds_merge (ds_t ds1, ds_t ds2)\n   return ds;\n }\n \n+/* Dump information about the dependence status S.  */\n+static void\n+dump_ds (FILE *f, ds_t s)\n+{\n+  fprintf (f, \"{\");\n+\n+  if (s & BEGIN_DATA)\n+    fprintf (f, \"BEGIN_DATA: %d; \", get_dep_weak_1 (s, BEGIN_DATA));\n+  if (s & BE_IN_DATA)\n+    fprintf (f, \"BE_IN_DATA: %d; \", get_dep_weak_1 (s, BE_IN_DATA));\n+  if (s & BEGIN_CONTROL)\n+    fprintf (f, \"BEGIN_CONTROL: %d; \", get_dep_weak_1 (s, BEGIN_CONTROL));\n+  if (s & BE_IN_CONTROL)\n+    fprintf (f, \"BE_IN_CONTROL: %d; \", get_dep_weak_1 (s, BE_IN_CONTROL));\n+\n+  if (s & HARD_DEP)\n+    fprintf (f, \"HARD_DEP; \");\n+\n+  if (s & DEP_TRUE)\n+    fprintf (f, \"DEP_TRUE; \");\n+  if (s & DEP_ANTI)\n+    fprintf (f, \"DEP_ANTI; \");\n+  if (s & DEP_OUTPUT)\n+    fprintf (f, \"DEP_OUTPUT; \");\n+\n+  fprintf (f, \"}\");\n+}\n+\n+void\n+debug_ds (ds_t s)\n+{\n+  dump_ds (stderr, s);\n+  fprintf (stderr, \"\\n\");\n+}\n+\n #ifdef INSN_SCHEDULING\n #ifdef ENABLE_CHECKING\n /* Verify that dependence type and status are consistent.\n    If RELAXED_P is true, then skip dep_weakness checks.  */\n static void\n-check_dep_status (enum reg_note dt, ds_t ds, bool relaxed_p)\n+check_dep (dep_t dep, bool relaxed_p)\n {\n+  enum reg_note dt = DEP_TYPE (dep);\n+  ds_t ds = DEP_STATUS (dep);\n+\n+  gcc_assert (DEP_PRO (dep) != DEP_CON (dep));\n+\n+  if (!(current_sched_info->flags & USE_DEPS_LIST))\n+    {\n+      gcc_assert (ds == -1);\n+      return;\n+    }\n+\n   /* Check that dependence type contains the same bits as the status.  */\n   if (dt == REG_DEP_TRUE)\n     gcc_assert (ds & DEP_TRUE);"}, {"sha": "4e7596cf62ee34fc9807ef9b5c211c051656dd5f", "filename": "gcc/sched-ebb.c", "status": "modified", "additions": 40, "deletions": 28, "changes": 68, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fsched-ebb.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fsched-ebb.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-ebb.c?ref=e2f6ff946a121528203fcbde68fdd58942f9a57b", "patch": "@@ -303,24 +303,26 @@ static struct sched_info ebb_sched_info =\n static basic_block\n earliest_block_with_similiar_load (basic_block last_block, rtx load_insn)\n {\n-  dep_link_t back_link;\n+  sd_iterator_def back_sd_it;\n+  dep_t back_dep;\n   basic_block bb, earliest_block = NULL;\n \n-  FOR_EACH_DEP_LINK (back_link, INSN_BACK_DEPS (load_insn))\n+  FOR_EACH_DEP (load_insn, SD_LIST_BACK, back_sd_it, back_dep)\n     {\n-      rtx insn1 = DEP_LINK_PRO (back_link);\n+      rtx insn1 = DEP_PRO (back_dep);\n \n-      if (DEP_LINK_KIND (back_link) == REG_DEP_TRUE)\n+      if (DEP_TYPE (back_dep) == REG_DEP_TRUE)\t\n+\t/* Found a DEF-USE dependence (insn1, load_insn).  */\n \t{\n-\t  /* Found a DEF-USE dependence (insn1, load_insn).  */\n-\t  dep_link_t fore_link;\n+\t  sd_iterator_def fore_sd_it;\n+\t  dep_t fore_dep;\n \n-\t  FOR_EACH_DEP_LINK (fore_link, INSN_FORW_DEPS (insn1))\n+\t  FOR_EACH_DEP (insn1, SD_LIST_FORW, fore_sd_it, fore_dep)\n \t    {\n-\t      rtx insn2 = DEP_LINK_CON (fore_link);\n+\t      rtx insn2 = DEP_CON (fore_dep);\n \t      basic_block insn2_block = BLOCK_FOR_INSN (insn2);\n \n-\t      if (DEP_LINK_KIND (fore_link) == REG_DEP_TRUE)\n+\t      if (DEP_TYPE (fore_dep) == REG_DEP_TRUE)\n \t\t{\n \t\t  if (earliest_block != NULL\n \t\t      && earliest_block->index < insn2_block->index)\n@@ -395,23 +397,32 @@ add_deps_for_risky_insns (rtx head, rtx tail)\n \t       rank.  */\n \t    if (! sched_insns_conditions_mutex_p (insn, prev))\n \t      {\n-\t\tif (!(current_sched_info->flags & DO_SPECULATION))\n+\t\tdep_def _dep, *dep = &_dep;\n+\n+\t\tinit_dep (dep, prev, insn, REG_DEP_ANTI);\n+\n+\t\tif (!(current_sched_info->flags & USE_DEPS_LIST))\n \t\t  {\n \t\t    enum DEPS_ADJUST_RESULT res;\n-\t\t    \n-\t\t    res = add_or_update_back_dep (insn, prev,\n-\t\t\t\t\t\t  REG_DEP_ANTI, DEP_ANTI);\n-\n-\t\t    if (res == DEP_CREATED)\n-\t\t      add_forw_dep (DEPS_LIST_FIRST (INSN_BACK_DEPS (insn)));\n-\t\t    else\n-\t\t      gcc_assert (res != DEP_CHANGED);\n+\n+\t\t    res = sd_add_or_update_dep (dep, false);\n+\n+\t\t    /* We can't change an existing dependency with\n+\t\t       DEP_ANTI.  */\n+\t\t    gcc_assert (res != DEP_CHANGED);\n \t\t  }\n \t\telse\n-\t\t  add_or_update_back_forw_dep (insn, prev, REG_DEP_ANTI,\n-\t\t\t\t\t       set_dep_weak (DEP_ANTI,\n-\t\t\t\t\t\t\t     BEGIN_CONTROL,\n-\t\t\t\t\t\t\t     MAX_DEP_WEAK));\n+\t\t  {\n+\t\t    if ((current_sched_info->flags & DO_SPECULATION)\n+\t\t\t&& (spec_info->mask & BEGIN_CONTROL))\n+\t\t      DEP_STATUS (dep) = set_dep_weak (DEP_ANTI, BEGIN_CONTROL,\n+\t\t\t\t\t\t       MAX_DEP_WEAK);\n+\n+\t\t    sd_add_or_update_dep (dep, false);\n+\n+\t\t    /* Dep_status could have been changed.\n+\t\t       No assertion here.  */\n+\t\t  }\n \t      }\n \n             break;\n@@ -450,14 +461,11 @@ schedule_ebb (rtx head, rtx tail)\n     {\n       init_deps_global ();\n \n-      /* Compute backward dependencies.  */\n+      /* Compute dependencies.  */\n       init_deps (&tmp_deps);\n       sched_analyze (&tmp_deps, head, tail);\n       free_deps (&tmp_deps);\n \n-      /* Compute forward dependencies.  */\n-      compute_forward_dependences (head, tail);\n-\n       add_deps_for_risky_insns (head, tail);\n \n       if (targetm.sched.dependencies_evaluation_hook)\n@@ -510,8 +518,12 @@ schedule_ebb (rtx head, rtx tail)\n   \n   /* Sanity check: verify that all region insns were scheduled.  */\n   gcc_assert (sched_n_insns == n_insns);\n-  head = current_sched_info->head;\n-  tail = current_sched_info->tail;\n+\n+  /* Free dependencies.  */\n+  sched_free_deps (current_sched_info->head, current_sched_info->tail, true);\n+\n+  gcc_assert (haifa_recovery_bb_ever_added_p\n+\t      || deps_pools_are_empty_p ());\n \n   if (EDGE_COUNT (last_bb->preds) == 0)\n     /* LAST_BB is unreachable.  */"}, {"sha": "ec5f8205a47f5b806a8c862601bfd72f20d4e6ee", "filename": "gcc/sched-int.h", "status": "modified", "additions": 192, "deletions": 58, "changes": 250, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fsched-int.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fsched-int.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-int.h?ref=e2f6ff946a121528203fcbde68fdd58942f9a57b", "patch": "@@ -54,35 +54,40 @@ struct _dep\n   /* Consumer.  */\n   rtx con;\n \n-  /* Dependency kind (aka dependency major type).  This field is superseded\n-     by STATUS below.  Though, it is still in place because all the backends\n-     use it.  */\n-  enum reg_note kind;\n+  /* Dependency major type.  This field is superseded by STATUS below.\n+     Though, it is still in place because some targets use it.  */\n+  enum reg_note type;\n \n   /* Dependency status.  This field holds all dependency types and additional\n      information for speculative dependencies.  */\n   ds_t status;\n };\n-typedef struct _dep *dep_t;\n+\n+typedef struct _dep dep_def;\n+typedef dep_def *dep_t;\n \n #define DEP_PRO(D) ((D)->pro)\n #define DEP_CON(D) ((D)->con)\n-#define DEP_KIND(D) ((D)->kind)\n+#define DEP_TYPE(D) ((D)->type)\n #define DEP_STATUS(D) ((D)->status)\n \n /* Functions to work with dep.  */\n \n+extern void init_dep_1 (dep_t, rtx, rtx, enum reg_note, ds_t);\n extern void init_dep (dep_t, rtx, rtx, enum reg_note);\n \n+extern void sd_debug_dep (dep_t);\n+\n /* Definition of this struct resides below.  */\n struct _dep_node;\n+typedef struct _dep_node *dep_node_t;\n \n /* A link in the dependency list.  This is essentially an equivalent of a\n    single {INSN, DEPS}_LIST rtx.  */\n struct _dep_link\n {\n   /* Dep node with all the data.  */\n-  struct _dep_node *node;\n+  dep_node_t node;\n \n   /* Next link in the list. For the last one it is NULL.  */\n   struct _dep_link *next;\n@@ -107,39 +112,22 @@ typedef struct _dep_link *dep_link_t;\n #define DEP_LINK_DEP(N) (DEP_NODE_DEP (DEP_LINK_NODE (N)))\n #define DEP_LINK_PRO(N) (DEP_PRO (DEP_LINK_DEP (N)))\n #define DEP_LINK_CON(N) (DEP_CON (DEP_LINK_DEP (N)))\n-#define DEP_LINK_KIND(N) (DEP_KIND (DEP_LINK_DEP (N)))\n+#define DEP_LINK_TYPE(N) (DEP_TYPE (DEP_LINK_DEP (N)))\n #define DEP_LINK_STATUS(N) (DEP_STATUS (DEP_LINK_DEP (N)))\n \n-void debug_dep_links (dep_link_t);\n-\n /* A list of dep_links.  */\n struct _deps_list\n {\n+  /* First element.  */\n   dep_link_t first;\n+\n+  /* Total number of elements in the list.  */\n+  int n_links;\n };\n typedef struct _deps_list *deps_list_t;\n \n #define DEPS_LIST_FIRST(L) ((L)->first)\n-\n-/* Macro to walk through deps_list.  */\n-#define FOR_EACH_DEP_LINK(LINK, LIST) \\\n-  for ((LINK) = DEPS_LIST_FIRST (LIST); \\\n-       (LINK) != NULL; \\\n-       (LINK) = DEP_LINK_NEXT (LINK))\n-\n-/* Functions to work with deps_list.  */\n-\n-deps_list_t create_deps_list (bool);\n-void free_deps_list (deps_list_t);\n-void delete_deps_list (deps_list_t);\n-bool deps_list_empty_p (deps_list_t);\n-void debug_deps_list (deps_list_t);\n-void add_back_dep_to_deps_list (deps_list_t, dep_t);\n-dep_link_t find_link_by_pro_in_deps_list (deps_list_t, rtx);\n-dep_link_t find_link_by_con_in_deps_list (deps_list_t, rtx);\n-void copy_deps_list_change_con (deps_list_t, deps_list_t, rtx);\n-\n-void move_dep_link (dep_link_t, deps_list_t);\n+#define DEPS_LIST_N_LINKS(L) ((L)->n_links)\n \n /* Suppose we have a dependence Y between insn pro1 and con1, where pro1 has\n    additional dependents con0 and con2, and con1 is dependent on additional\n@@ -247,7 +235,6 @@ struct _dep_node\n   /* Forward link.  */\n   struct _dep_link forw;\n };\n-typedef struct _dep_node *dep_node_t;\n \n #define DEP_NODE_BACK(N) (&(N)->back)\n #define DEP_NODE_DEP(N) (&(N)->dep)\n@@ -469,15 +456,17 @@ extern struct sched_info *current_sched_info;\n \n struct haifa_insn_data\n {\n-  /* NB: We can't place 'struct _deps_list' here instead of deps_list_t into\n-     h_i_d because when h_i_d extends, addresses of the deps_list->first\n-     change without updating deps_list->first->next->prev_nextp.  Thus\n-     BACK_DEPS and RESOLVED_BACK_DEPS are allocated on the heap and FORW_DEPS\n-     list is allocated on the obstack.  */\n+  /* We can't place 'struct _deps_list' into h_i_d instead of deps_list_t\n+     because when h_i_d extends, addresses of the deps_list->first\n+     change without updating deps_list->first->next->prev_nextp.  */\n \n-  /* A list of backward dependencies.  The insn is a consumer of all the\n+  /* A list of hard backward dependencies.  The insn is a consumer of all the\n      deps mentioned here.  */\n-  deps_list_t back_deps;\n+  deps_list_t hard_back_deps;\n+\n+  /* A list of speculative (weak) dependencies.  The insn is a consumer of all\n+     the deps mentioned here.  */\n+  deps_list_t spec_back_deps;\n \n   /* A list of insns which depend on the instruction.  Unlike 'back_deps',\n      it represents forward dependencies.  */\n@@ -486,18 +475,18 @@ struct haifa_insn_data\n   /* A list of scheduled producers of the instruction.  Links are being moved\n      from 'back_deps' to 'resolved_back_deps' while scheduling.  */\n   deps_list_t resolved_back_deps;\n+\n+  /* A list of scheduled consumers of the instruction.  Links are being moved\n+     from 'forw_deps' to 'resolved_forw_deps' while scheduling to fasten the\n+     search in 'forw_deps'.  */\n+  deps_list_t resolved_forw_deps;\n  \n   /* Logical uid gives the original ordering of the insns.  */\n   int luid;\n \n   /* A priority for each insn.  */\n   int priority;\n \n-  /* The number of incoming edges in the forward dependency graph.\n-     As scheduling proceeds, counts are decreased.  An insn moves to\n-     the ready queue when its counter reaches zero.  */\n-  int dep_count;\n-\n   /* Number of instructions referring to this insn.  */\n   int ref_count;\n \n@@ -553,13 +542,16 @@ extern struct haifa_insn_data *h_i_d;\n \n /* Accessor macros for h_i_d.  There are more in haifa-sched.c and\n    sched-rgn.c.  */\n-#define INSN_BACK_DEPS(INSN) (h_i_d[INSN_UID (INSN)].back_deps)\n+\n+#define INSN_HARD_BACK_DEPS(INSN) (h_i_d[INSN_UID (INSN)].hard_back_deps)\n+#define INSN_SPEC_BACK_DEPS(INSN) (h_i_d[INSN_UID (INSN)].spec_back_deps)\n #define INSN_FORW_DEPS(INSN) (h_i_d[INSN_UID (INSN)].forw_deps)\n #define INSN_RESOLVED_BACK_DEPS(INSN) \\\n   (h_i_d[INSN_UID (INSN)].resolved_back_deps)\n+#define INSN_RESOLVED_FORW_DEPS(INSN) \\\n+  (h_i_d[INSN_UID (INSN)].resolved_forw_deps)\n #define INSN_LUID(INSN)\t\t(h_i_d[INSN_UID (INSN)].luid)\n #define CANT_MOVE(insn)\t\t(h_i_d[INSN_UID (insn)].cant_move)\n-#define INSN_DEP_COUNT(INSN)\t(h_i_d[INSN_UID (INSN)].dep_count)\n #define INSN_PRIORITY(INSN)\t(h_i_d[INSN_UID (INSN)].priority)\n #define INSN_PRIORITY_STATUS(INSN) (h_i_d[INSN_UID (INSN)].priority_status)\n #define INSN_PRIORITY_KNOWN(INSN) (INSN_PRIORITY_STATUS (INSN) > 0)\n@@ -694,13 +686,16 @@ enum SPEC_TYPES_OFFSETS {\n #define HARD_DEP (DEP_ANTI << 1)\n \n /* This represents the results of calling sched-deps.c functions, \n-   which modify dependencies.  Possible choices are: a dependence\n-   is already present and nothing has been changed; a dependence type\n-   has been changed; brand new dependence has been created.  */\n+   which modify dependencies.  */\n enum DEPS_ADJUST_RESULT {\n-  DEP_PRESENT = 1,\n-  DEP_CHANGED = 2,\n-  DEP_CREATED = 3\n+  /* No dependence needed (e.g. producer == consumer).  */\n+  DEP_NODEP,\n+  /* Dependence is already present and wasn't modified.  */\n+  DEP_PRESENT,\n+  /* Existing dependence was modified to include additional information.  */\n+  DEP_CHANGED,\n+  /* New dependence has been created.  */\n+  DEP_CREATED\n };\n \n /* Represents the bits that can be set in the flags field of the \n@@ -731,6 +726,9 @@ enum SPEC_SCHED_FLAGS {\n extern FILE *sched_dump;\n extern int sched_verbose;\n \n+extern spec_info_t spec_info;\n+extern bool haifa_recovery_bb_ever_added_p;\n+\n /* Exception Free Loads:\n \n    We define five classes of speculative loads: IFREE, IRISKY,\n@@ -816,23 +814,19 @@ extern void print_insn (char *, rtx, int);\n extern bool sched_insns_conditions_mutex_p (rtx, rtx);\n extern void add_dependence (rtx, rtx, enum reg_note);\n extern void sched_analyze (struct deps *, rtx, rtx);\n+extern bool deps_pools_are_empty_p (void);\n+extern void sched_free_deps (rtx, rtx, bool);\n extern void init_deps (struct deps *);\n extern void free_deps (struct deps *);\n extern void init_deps_global (void);\n extern void finish_deps_global (void);\n-extern void add_forw_dep (dep_link_t);\n-extern void compute_forward_dependences (rtx, rtx);\n extern void init_dependency_caches (int);\n extern void free_dependency_caches (void);\n extern void extend_dependency_caches (int, bool);\n-extern enum DEPS_ADJUST_RESULT add_or_update_back_dep (rtx, rtx, \n-\t\t\t\t\t\t       enum reg_note, ds_t);\n-extern void add_or_update_back_forw_dep (rtx, rtx, enum reg_note, ds_t);\n-extern void add_back_forw_dep (rtx, rtx, enum reg_note, ds_t);\n-extern void delete_back_forw_dep (dep_link_t);\n extern dw_t get_dep_weak (ds_t, ds_t);\n extern ds_t set_dep_weak (ds_t, ds_t, dw_t);\n extern ds_t ds_merge (ds_t, ds_t);\n+extern void debug_ds (ds_t);\n \n /* Functions in haifa-sched.c.  */\n extern int haifa_classify_insn (rtx);\n@@ -851,11 +845,151 @@ extern void sched_finish (void);\n \n extern int try_ready (rtx);\n extern void * xrecalloc (void *, size_t, size_t, size_t);\n+extern bool sched_insn_is_legitimate_for_speculation_p (rtx, ds_t);\n extern void unlink_bb_notes (basic_block, basic_block);\n extern void add_block (basic_block, basic_block);\n extern rtx bb_note (basic_block);\n \n /* Functions in sched-rgn.c.  */\n+\n extern void debug_dependencies (rtx, rtx);\n \n+/* sched-deps.c interface to walk, add, search, update, resolve, delete\n+   and debug instruction dependencies.  */\n+\n+/* Constants defining dependences lists.  */\n+\n+/* No list.  */\n+#define SD_LIST_NONE (0)\n+\n+/* hard_back_deps.  */\n+#define SD_LIST_HARD_BACK (1)\n+\n+/* spec_back_deps.  */\n+#define SD_LIST_SPEC_BACK (2)\n+\n+/* forw_deps.  */\n+#define SD_LIST_FORW (4)\n+\n+/* resolved_back_deps.  */\n+#define SD_LIST_RES_BACK (8)\n+\n+/* resolved_forw_deps.  */\n+#define SD_LIST_RES_FORW (16)\n+\n+#define SD_LIST_BACK (SD_LIST_HARD_BACK | SD_LIST_SPEC_BACK)\n+\n+/* A type to hold above flags.  */\n+typedef int sd_list_types_def;\n+\n+extern void sd_next_list (rtx, sd_list_types_def *, deps_list_t *, bool *);\n+\n+/* Iterator to walk through, resolve and delete dependencies.  */\n+struct _sd_iterator\n+{\n+  /* What lists to walk.  Can be any combination of SD_LIST_* flags.  */\n+  sd_list_types_def types;\n+\n+  /* Instruction dependencies lists of which will be walked.  */\n+  rtx insn;\n+\n+  /* Pointer to the next field of the previous element.  This is not\n+     simply a pointer to the next element to allow easy deletion from the\n+     list.  When a dep is being removed from the list the iterator\n+     will automatically advance because the value in *linkp will start\n+     reffering to the next element.  */\n+  dep_link_t *linkp;\n+\n+  /* True if the current list is a resolved one.  */\n+  bool resolved_p;\n+};\n+\n+typedef struct _sd_iterator sd_iterator_def;\n+\n+/* ??? We can move some definitions that are used in below inline functions\n+   out of sched-int.h to sched-deps.c provided that the below functions will\n+   become global externals.\n+   These definitions include:\n+   * struct _deps_list: opaque pointer is needed at global scope.\n+   * struct _dep_link: opaque pointer is needed at scope of sd_iterator_def.\n+   * struct _dep_node: opaque pointer is needed at scope of\n+   struct _deps_link.  */\n+\n+/* Return initialized iterator.  */\n+static inline sd_iterator_def\n+sd_iterator_start (rtx insn, sd_list_types_def types)\n+{\n+  /* Some dep_link a pointer to which will return NULL.  */\n+  static dep_link_t null_link = NULL;\n+\n+  sd_iterator_def i;\n+\n+  i.types = types;\n+  i.insn = insn;\n+  i.linkp = &null_link;\n+\n+  /* Avoid 'uninitialized warning'.  */\n+  i.resolved_p = false;\n+\n+  return i;\n+}\n+\n+/* Return the current element.  */\n+static inline bool\n+sd_iterator_cond (sd_iterator_def *it_ptr, dep_t *dep_ptr)\n+{\n+  dep_link_t link = *it_ptr->linkp;\n+\n+  if (link != NULL)\n+    {\n+      *dep_ptr = DEP_LINK_DEP (link);\n+      return true;\n+    }\n+  else\n+    {\n+      sd_list_types_def types = it_ptr->types;\n+\n+      if (types != SD_LIST_NONE)\n+\t/* Switch to next list.  */\n+\t{\n+\t  deps_list_t list;\n+\n+\t  sd_next_list (it_ptr->insn,\n+\t\t\t&it_ptr->types, &list, &it_ptr->resolved_p);\n+\n+\t  it_ptr->linkp = &DEPS_LIST_FIRST (list);\n+\n+\t  return sd_iterator_cond (it_ptr, dep_ptr);\n+\t}\n+\n+      *dep_ptr = NULL;\n+      return false;\n+    }\n+}\n+\n+/* Advance iterator.  */\n+static inline void\n+sd_iterator_next (sd_iterator_def *it_ptr)\n+{\n+  it_ptr->linkp = &DEP_LINK_NEXT (*it_ptr->linkp);\n+}\n+\n+/* A cycle wrapper.  */\n+#define FOR_EACH_DEP(INSN, LIST_TYPES, ITER, DEP)\t\t\\\n+  for ((ITER) = sd_iterator_start ((INSN), (LIST_TYPES));\t\\\n+       sd_iterator_cond (&(ITER), &(DEP));\t\t\t\\\n+       sd_iterator_next (&(ITER)))\n+\n+extern int sd_lists_size (rtx, sd_list_types_def);\n+extern bool sd_lists_empty_p (rtx, sd_list_types_def);\n+extern void sd_init_insn (rtx);\n+extern void sd_finish_insn (rtx);\n+extern dep_t sd_find_dep_between (rtx, rtx, bool);\n+extern void sd_add_dep (dep_t, bool);\n+extern enum DEPS_ADJUST_RESULT sd_add_or_update_dep (dep_t, bool);\n+extern void sd_resolve_dep (sd_iterator_def);\n+extern void sd_copy_back_deps (rtx, rtx, bool);\n+extern void sd_delete_dep (sd_iterator_def);\n+extern void sd_debug_lists (rtx, sd_list_types_def);\n+\n #endif /* GCC_SCHED_INT_H */"}, {"sha": "760420be50b8fc34d66f4d63b665170cc66e9c41", "filename": "gcc/sched-rgn.c", "status": "modified", "additions": 68, "deletions": 51, "changes": 119, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fsched-rgn.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2f6ff946a121528203fcbde68fdd58942f9a57b/gcc%2Fsched-rgn.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsched-rgn.c?ref=e2f6ff946a121528203fcbde68fdd58942f9a57b", "patch": "@@ -277,7 +277,7 @@ static int is_exception_free (rtx, int, int);\n static bool sets_likely_spilled (rtx);\n static void sets_likely_spilled_1 (rtx, const_rtx, void *);\n static void add_branch_dependences (rtx, rtx);\n-static void compute_block_backward_dependences (int);\n+static void compute_block_dependences (int);\n \n static void init_regions (void);\n static void schedule_region (int);\n@@ -1697,11 +1697,12 @@ update_live (rtx insn, int src)\n static void\n set_spec_fed (rtx load_insn)\n {\n-  dep_link_t link;\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n \n-  FOR_EACH_DEP_LINK (link, INSN_FORW_DEPS (load_insn))\n-    if (DEP_LINK_KIND (link) == REG_DEP_TRUE)\n-      FED_BY_SPEC_LOAD (DEP_LINK_CON (link)) = 1;\n+  FOR_EACH_DEP (load_insn, SD_LIST_FORW, sd_it, dep)\n+    if (DEP_TYPE (dep) == REG_DEP_TRUE)\n+      FED_BY_SPEC_LOAD (DEP_CON (dep)) = 1;\n }\n \n /* On the path from the insn to load_insn_bb, find a conditional\n@@ -1710,18 +1711,19 @@ branch depending on insn, that guards the speculative load.  */\n static int\n find_conditional_protection (rtx insn, int load_insn_bb)\n {\n-  dep_link_t link;\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n \n   /* Iterate through DEF-USE forward dependences.  */\n-  FOR_EACH_DEP_LINK (link, INSN_FORW_DEPS (insn))\n+  FOR_EACH_DEP (insn, SD_LIST_FORW, sd_it, dep)\n     {\n-      rtx next = DEP_LINK_CON (link);\n+      rtx next = DEP_CON (dep);\n \n       if ((CONTAINING_RGN (BLOCK_NUM (next)) ==\n \t   CONTAINING_RGN (BB_TO_BLOCK (load_insn_bb)))\n \t  && IS_REACHABLE (INSN_BB (next), load_insn_bb)\n \t  && load_insn_bb != INSN_BB (next)\n-\t  && DEP_LINK_KIND (link) == REG_DEP_TRUE\n+\t  && DEP_TYPE (dep) == REG_DEP_TRUE\n \t  && (JUMP_P (next)\n \t      || find_conditional_protection (next, load_insn_bb)))\n \treturn 1;\n@@ -1746,14 +1748,15 @@ find_conditional_protection (rtx insn, int load_insn_bb)\n static int\n is_conditionally_protected (rtx load_insn, int bb_src, int bb_trg)\n {\n-  dep_link_t link;\n+  sd_iterator_def sd_it;\n+  dep_t dep;\n \n-  FOR_EACH_DEP_LINK (link, INSN_BACK_DEPS (load_insn))\n+  FOR_EACH_DEP (load_insn, SD_LIST_BACK, sd_it, dep)\n     {\n-      rtx insn1 = DEP_LINK_PRO (link);\n+      rtx insn1 = DEP_PRO (dep);\n \n       /* Must be a DEF-USE dependence upon non-branch.  */\n-      if (DEP_LINK_KIND (link) != REG_DEP_TRUE\n+      if (DEP_TYPE (dep) != REG_DEP_TRUE\n \t  || JUMP_P (insn1))\n \tcontinue;\n \n@@ -1796,27 +1799,29 @@ is_conditionally_protected (rtx load_insn, int bb_src, int bb_trg)\n static int\n is_pfree (rtx load_insn, int bb_src, int bb_trg)\n {\n-  dep_link_t back_link;\n+  sd_iterator_def back_sd_it;\n+  dep_t back_dep;\n   candidate *candp = candidate_table + bb_src;\n \n   if (candp->split_bbs.nr_members != 1)\n     /* Must have exactly one escape block.  */\n     return 0;\n \n-  FOR_EACH_DEP_LINK (back_link, INSN_BACK_DEPS (load_insn))\n+  FOR_EACH_DEP (load_insn, SD_LIST_BACK, back_sd_it, back_dep)\n     {\n-      rtx insn1 = DEP_LINK_PRO (back_link);\n+      rtx insn1 = DEP_PRO (back_dep);\n \n-      if (DEP_LINK_KIND (back_link) == REG_DEP_TRUE)\n+      if (DEP_TYPE (back_dep) == REG_DEP_TRUE)\n+\t/* Found a DEF-USE dependence (insn1, load_insn).  */\n \t{\n-\t  /* Found a DEF-USE dependence (insn1, load_insn).  */\n-\t  dep_link_t fore_link;\n+\t  sd_iterator_def fore_sd_it;\n+\t  dep_t fore_dep;\n \n-\t  FOR_EACH_DEP_LINK (fore_link, INSN_FORW_DEPS (insn1))\n+\t  FOR_EACH_DEP (insn1, SD_LIST_FORW, fore_sd_it, fore_dep)\n \t    {\n-\t      rtx insn2 = DEP_LINK_CON (fore_link);\n+\t      rtx insn2 = DEP_CON (fore_dep);\n \n-\t      if (DEP_LINK_KIND (fore_link) == REG_DEP_TRUE)\n+\t      if (DEP_TYPE (fore_dep) == REG_DEP_TRUE)\n \t\t{\n \t\t  /* Found a DEF-USE dependence (insn1, insn2).  */\n \t\t  if (haifa_classify_insn (insn2) != PFREE_CANDIDATE)\n@@ -1849,7 +1854,7 @@ is_prisky (rtx load_insn, int bb_src, int bb_trg)\n   if (FED_BY_SPEC_LOAD (load_insn))\n     return 1;\n \n-  if (deps_list_empty_p (INSN_BACK_DEPS (load_insn)))\n+  if (sd_lists_empty_p (load_insn, SD_LIST_BACK))\n     /* Dependence may 'hide' out of the region.  */\n     return 1;\n \n@@ -2081,7 +2086,8 @@ new_ready (rtx next, ds_t ts)\n \t  if (not_ex_free\n \t      /* We are here because is_exception_free () == false.\n \t\t But we possibly can handle that with control speculation.  */\n-\t      && current_sched_info->flags & DO_SPECULATION)\n+\t      && (current_sched_info->flags & DO_SPECULATION)\n+\t      && (spec_info->mask & BEGIN_CONTROL))\n             /* Here we got new control-speculative instruction.  */\n             ts = set_dep_weak (ts, BEGIN_CONTROL, MAX_DEP_WEAK);\n \t  else\n@@ -2263,8 +2269,7 @@ add_branch_dependences (rtx head, rtx tail)\n       if (!NOTE_P (insn))\n \t{\n \t  if (last != 0\n-\t      && (find_link_by_pro_in_deps_list (INSN_BACK_DEPS (last), insn)\n-\t\t  == NULL))\n+\t      && sd_find_dep_between (insn, last, false) == NULL)\n \t    {\n \t      if (! sched_insns_conditions_mutex_p (last, insn))\n \t\tadd_dependence (last, insn, REG_DEP_ANTI);\n@@ -2472,7 +2477,7 @@ propagate_deps (int bb, struct deps *pred_deps)\n   pred_deps->pending_write_mems = 0;\n }\n \n-/* Compute backward dependences inside bb.  In a multiple blocks region:\n+/* Compute dependences inside bb.  In a multiple blocks region:\n    (1) a bb is analyzed after its predecessors, and (2) the lists in\n    effect at the end of bb (after analyzing for bb) are inherited by\n    bb's successors.\n@@ -2490,7 +2495,7 @@ propagate_deps (int bb, struct deps *pred_deps)\n    similar, and the result is interblock dependences in the region.  */\n \n static void\n-compute_block_backward_dependences (int bb)\n+compute_block_dependences (int bb)\n {\n   rtx head, tail;\n   struct deps tmp_deps;\n@@ -2500,6 +2505,7 @@ compute_block_backward_dependences (int bb)\n   /* Do the analysis for this block.  */\n   gcc_assert (EBB_FIRST_BB (bb) == EBB_LAST_BB (bb));\n   get_ebb_head_tail (EBB_FIRST_BB (bb), EBB_LAST_BB (bb), &head, &tail);\n+\n   sched_analyze (&tmp_deps, head, tail);\n   add_branch_dependences (head, tail);\n \n@@ -2508,6 +2514,21 @@ compute_block_backward_dependences (int bb)\n \n   /* Free up the INSN_LISTs.  */\n   free_deps (&tmp_deps);\n+\n+  if (targetm.sched.dependencies_evaluation_hook)\n+    targetm.sched.dependencies_evaluation_hook (head, tail);\n+}\n+\n+/* Free dependencies of instructions inside BB.  */\n+static void\n+free_block_dependencies (int bb)\n+{\n+  rtx head;\n+  rtx tail;\n+\n+  get_ebb_head_tail (EBB_FIRST_BB (bb), EBB_LAST_BB (bb), &head, &tail);\n+\n+  sched_free_deps (head, tail, true);\n }\n \n /* Remove all INSN_LISTs and EXPR_LISTs from the pending lists and add\n@@ -2527,7 +2548,8 @@ free_pending_lists (void)\n     }\n }\n \f\n-\n+/* Print dependences for debugging starting from FROM_BB.\n+   Callable from debugger.  */\n /* Print dependences for debugging starting from FROM_BB.\n    Callable from debugger.  */\n void\n@@ -2567,8 +2589,6 @@ void debug_dependencies (rtx head, rtx tail)\n \n   for (insn = head; insn != next_tail; insn = NEXT_INSN (insn))\n     {\n-      dep_link_t link;\n-\n       if (! INSN_P (insn))\n \t{\n \t  int n;\n@@ -2589,7 +2609,7 @@ void debug_dependencies (rtx head, rtx tail)\n \t       INSN_UID (insn),\n \t       INSN_CODE (insn),\n \t       BLOCK_NUM (insn),\n-\t       INSN_DEP_COUNT (insn),\n+\t       sd_lists_size (insn, SD_LIST_BACK),\n \t       INSN_PRIORITY (insn),\n \t       insn_cost (insn));\n \n@@ -2599,8 +2619,13 @@ void debug_dependencies (rtx head, rtx tail)\n \tprint_reservation (sched_dump, insn);\n \n       fprintf (sched_dump, \"\\t: \");\n-      FOR_EACH_DEP_LINK (link, INSN_FORW_DEPS (insn))\n-\tfprintf (sched_dump, \"%d \", INSN_UID (DEP_LINK_CON (link)));\n+      {\n+\tsd_iterator_def sd_it;\n+\tdep_t dep;\n+\n+\tFOR_EACH_DEP (insn, SD_LIST_FORW, sd_it, dep)\n+\t  fprintf (sched_dump, \"%d \", INSN_UID (DEP_CON (dep)));\n+      }\n       fprintf (sched_dump, \"\\n\");\n     }\n \n@@ -2658,23 +2683,9 @@ schedule_region (int rgn)\n       for (bb = 0; bb < current_nr_blocks; bb++)\n \tinit_deps (bb_deps + bb);\n \n-      /* Compute backward dependencies.  */\n+      /* Compute dependencies.  */\n       for (bb = 0; bb < current_nr_blocks; bb++)\n-        compute_block_backward_dependences (bb);\n-\n-      /* Compute forward dependencies.  */\n-      for (bb = current_nr_blocks - 1; bb >= 0; bb--)\n-        {\n-          rtx head, tail;\n-\n-\t  gcc_assert (EBB_FIRST_BB (bb) == EBB_LAST_BB (bb));\n-          get_ebb_head_tail (EBB_FIRST_BB (bb), EBB_LAST_BB (bb), &head, &tail);\n-\n-          compute_forward_dependences (head, tail);\n-\n-          if (targetm.sched.dependencies_evaluation_hook)\n-            targetm.sched.dependencies_evaluation_hook (head, tail);\n-        }\n+\tcompute_block_dependences (bb);\n \n       free_pending_lists ();\n \n@@ -2826,7 +2837,6 @@ schedule_region (int rgn)\n   /* Sanity check: verify that all region insns were scheduled.  */\n   gcc_assert (sched_rgn_n_insns == rgn_n_insns);\n \n-\n   /* Done with this region.  */\n \n   if (current_nr_blocks > 1)\n@@ -2837,6 +2847,13 @@ schedule_region (int rgn)\n       sbitmap_vector_free (ancestor_edges);\n       free (rgn_edges);\n     }\n+\n+  /* Free dependencies.  */\n+  for (bb = 0; bb < current_nr_blocks; ++bb)\n+    free_block_dependencies (bb);\n+\n+  gcc_assert (haifa_recovery_bb_ever_added_p\n+\t      || deps_pools_are_empty_p ());\n }\n \n /* Initialize data structures for region scheduling.  */"}]}