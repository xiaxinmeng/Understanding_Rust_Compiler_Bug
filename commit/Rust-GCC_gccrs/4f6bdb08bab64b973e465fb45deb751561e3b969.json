{"sha": "4f6bdb08bab64b973e465fb45deb751561e3b969", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NGY2YmRiMDhiYWI2NGI5NzNlNDY1ZmI0NWRlYjc1MTU2MWUzYjk2OQ==", "commit": {"author": {"name": "Ian Lance Taylor", "email": "ian@gcc.gnu.org", "date": "2019-08-19T19:09:50Z"}, "committer": {"name": "Ian Lance Taylor", "email": "ian@gcc.gnu.org", "date": "2019-08-19T19:09:50Z"}, "message": "runtime: be more strict in GC\n    \n    With CL 190599, along with what we do in greyobject, we ensure\n    that we only mark allocated heap objects. As a result we can be\n    more strict in GC:\n    \n    - Enable \"sweep increased allocation count\" check, which checks\n      that the number of mark bits set are no more than the number of\n      allocation bits.\n    \n    - Enable invalid pointer check on heap scan. We only trace\n      allocated heap objects, which should not contain invalid\n      pointer.\n    \n    This also makes the libgo runtime more convergent with the gc\n    runtime.\n    \n    Reviewed-on: https://go-review.googlesource.com/c/gofrontend/+/190797\n\nFrom-SVN: r274678", "tree": {"sha": "1945ba0d73dd9ecc9361beaaa2fa056653e3bce8", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/1945ba0d73dd9ecc9361beaaa2fa056653e3bce8"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/4f6bdb08bab64b973e465fb45deb751561e3b969", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4f6bdb08bab64b973e465fb45deb751561e3b969", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4f6bdb08bab64b973e465fb45deb751561e3b969", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4f6bdb08bab64b973e465fb45deb751561e3b969/comments", "author": null, "committer": null, "parents": [{"sha": "188d00796f5bd338b9b8ab1cc8ba4b43af8ab8fd", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/188d00796f5bd338b9b8ab1cc8ba4b43af8ab8fd", "html_url": "https://github.com/Rust-GCC/gccrs/commit/188d00796f5bd338b9b8ab1cc8ba4b43af8ab8fd"}], "stats": {"total": 68, "additions": 13, "deletions": 55}, "files": [{"sha": "b1a6579afadc7c254981bcb1dbe92e465e0f69dd", "filename": "gcc/go/gofrontend/MERGE", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4f6bdb08bab64b973e465fb45deb751561e3b969/gcc%2Fgo%2Fgofrontend%2FMERGE", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4f6bdb08bab64b973e465fb45deb751561e3b969/gcc%2Fgo%2Fgofrontend%2FMERGE", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgo%2Fgofrontend%2FMERGE?ref=4f6bdb08bab64b973e465fb45deb751561e3b969", "patch": "@@ -1,4 +1,4 @@\n-85857977230437f2b3dcbeea009efbb8b2789039\n+b0ba5daa8216a0424b24f74466cedab0b986f3b4\n \n The first line of this file holds the git revision number of the last\n merge done from the gofrontend repository."}, {"sha": "a60eb9fd0ca5bc753f13228edf5c13610caa30b6", "filename": "libgo/go/runtime/mcentral.go", "status": "modified", "additions": 0, "deletions": 9, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4f6bdb08bab64b973e465fb45deb751561e3b969/libgo%2Fgo%2Fruntime%2Fmcentral.go", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4f6bdb08bab64b973e465fb45deb751561e3b969/libgo%2Fgo%2Fruntime%2Fmcentral.go", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fgo%2Fruntime%2Fmcentral.go?ref=4f6bdb08bab64b973e465fb45deb751561e3b969", "patch": "@@ -56,15 +56,6 @@ retry:\n \t\t\tc.empty.insertBack(s)\n \t\t\tunlock(&c.lock)\n \t\t\ts.sweep(true)\n-\n-\t\t\t// With gccgo's conservative GC, the returned span may\n-\t\t\t// now be full. See the comments in mspan.sweep.\n-\t\t\tif uintptr(s.allocCount) == s.nelems {\n-\t\t\t\ts.freeindex = s.nelems\n-\t\t\t\tlock(&c.lock)\n-\t\t\t\tgoto retry\n-\t\t\t}\n-\n \t\t\tgoto havespan\n \t\t}\n \t\tif s.sweepgen == sg-1 {"}, {"sha": "539a982c39d7e579cfd9ca44f297ee6c1ffb6496", "filename": "libgo/go/runtime/mgcsweep.go", "status": "modified", "additions": 6, "deletions": 32, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4f6bdb08bab64b973e465fb45deb751561e3b969/libgo%2Fgo%2Fruntime%2Fmgcsweep.go", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4f6bdb08bab64b973e465fb45deb751561e3b969/libgo%2Fgo%2Fruntime%2Fmgcsweep.go", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fgo%2Fruntime%2Fmgcsweep.go?ref=4f6bdb08bab64b973e465fb45deb751561e3b969", "patch": "@@ -326,39 +326,16 @@ func (s *mspan) sweep(preserve bool) bool {\n \t\tfreeToHeap = true\n \t}\n \tnfreed := s.allocCount - nalloc\n-\n-\t// This check is not reliable with gccgo, because of\n-\t// conservative stack scanning. The test boils down to\n-\t// checking that no new bits have been set in gcmarkBits since\n-\t// the span was added to the sweep count. New bits are set by\n-\t// greyobject. Seeing a new bit means that a live pointer has\n-\t// appeared that was not found during the mark phase. That can\n-\t// not happen when pointers are followed strictly. However,\n-\t// with conservative checking, it is possible for a pointer\n-\t// that will never be used to appear live and to cause a mark\n-\t// to be added. That is unfortunate in that it causes this\n-\t// check to be inaccurate, and it will keep an object live\n-\t// unnecessarily, but provided the pointer is not really live\n-\t// it is not otherwise a problem. So we disable the test for gccgo.\n-\tnfreedSigned := int(nfreed)\n \tif nalloc > s.allocCount {\n-\t\tif usestackmaps {\n-\t\t\tprint(\"runtime: nelems=\", s.nelems, \" nalloc=\", nalloc, \" previous allocCount=\", s.allocCount, \" nfreed=\", nfreed, \"\\n\")\n-\t\t\tthrow(\"sweep increased allocation count\")\n-\t\t}\n-\n-\t\t// For gccgo, adjust the freed count as a signed number.\n-\t\tnfreedSigned = int(s.allocCount) - int(nalloc)\n-\t\tif uintptr(nalloc) == s.nelems {\n-\t\t\ts.freeindex = s.nelems\n-\t\t}\n+\t\tprint(\"runtime: nelems=\", s.nelems, \" nalloc=\", nalloc, \" previous allocCount=\", s.allocCount, \" nfreed=\", nfreed, \"\\n\")\n+\t\tthrow(\"sweep increased allocation count\")\n \t}\n \n \ts.allocCount = nalloc\n \twasempty := s.nextFreeIndex() == s.nelems\n \ts.freeindex = 0 // reset allocation index to start of span.\n \tif trace.enabled {\n-\t\tgetg().m.p.ptr().traceReclaimed += uintptr(nfreedSigned) * s.elemsize\n+\t\tgetg().m.p.ptr().traceReclaimed += uintptr(nfreed) * s.elemsize\n \t}\n \n \t// gcmarkBits becomes the allocBits.\n@@ -374,7 +351,7 @@ func (s *mspan) sweep(preserve bool) bool {\n \t// But we need to set it before we make the span available for allocation\n \t// (return it to heap or mcentral), because allocation code assumes that a\n \t// span is already swept if available for allocation.\n-\tif freeToHeap || nfreedSigned <= 0 {\n+\tif freeToHeap || nfreed == 0 {\n \t\t// The span must be in our exclusive ownership until we update sweepgen,\n \t\t// check for potential races.\n \t\tif s.state != mSpanInUse || s.sweepgen != sweepgen-1 {\n@@ -387,11 +364,8 @@ func (s *mspan) sweep(preserve bool) bool {\n \t\tatomic.Store(&s.sweepgen, sweepgen)\n \t}\n \n-\tif spc.sizeclass() != 0 {\n-\t\tc.local_nsmallfree[spc.sizeclass()] += uintptr(nfreedSigned)\n-\t}\n-\n-\tif nfreedSigned > 0 && spc.sizeclass() != 0 {\n+\tif nfreed > 0 && spc.sizeclass() != 0 {\n+\t\tc.local_nsmallfree[spc.sizeclass()] += uintptr(nfreed)\n \t\tres = mheap_.central[spc].mcentral.freeSpan(s, preserve, wasempty)\n \t\t// mcentral.freeSpan updates sweepgen\n \t} else if freeToHeap {"}, {"sha": "2424f2030cd24cbe77644c50915379c26c9a3bad", "filename": "libgo/go/runtime/runtime1.go", "status": "modified", "additions": 6, "deletions": 13, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4f6bdb08bab64b973e465fb45deb751561e3b969/libgo%2Fgo%2Fruntime%2Fruntime1.go", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4f6bdb08bab64b973e465fb45deb751561e3b969/libgo%2Fgo%2Fruntime%2Fruntime1.go", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/libgo%2Fgo%2Fruntime%2Fruntime1.go?ref=4f6bdb08bab64b973e465fb45deb751561e3b969", "patch": "@@ -352,19 +352,12 @@ func parsedebugvars() {\n \t// defaults\n \tdebug.cgocheck = 1\n \n-\t// Unfortunately, because gccgo uses conservative stack scanning,\n-\t// we can not enable invalid pointer checking. It is possible for\n-\t// memory block M1 to point to M2, and for both to be dead.\n-\t// We release M2, causing the entire span to be released.\n-\t// Before we release M1, a stack pointer appears that point into it.\n-\t// This stack pointer is presumably dead, but causes M1 to be marked.\n-\t// We scan M1 and see the pointer to M2 on a released span.\n-\t// At that point, if debug.invalidptr is set, we crash.\n-\t// This is not a problem, assuming that M1 really is dead and\n-\t// the pointer we discovered to it will not be used.\n-\tif usestackmaps {\n-\t\tdebug.invalidptr = 1\n-\t}\n+\t// Gccgo uses conservative stack scanning, so we cannot check\n+\t// invalid pointers on stack. But we can still enable invalid\n+\t// pointer check on heap scanning. When scanning the heap, we\n+\t// ensure that we only trace allocated heap objects, which should\n+\t// not contain invalid pointers.\n+\tdebug.invalidptr = 1\n \n \tfor p := gogetenv(\"GODEBUG\"); p != \"\"; {\n \t\tfield := \"\""}]}