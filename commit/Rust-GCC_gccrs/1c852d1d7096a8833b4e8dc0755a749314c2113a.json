{"sha": "1c852d1d7096a8833b4e8dc0755a749314c2113a", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MWM4NTJkMWQ3MDk2YTg4MzNiNGU4ZGMwNzU1YTc0OTMxNGMyMTEzYQ==", "commit": {"author": {"name": "Richard Biener", "email": "rguenther@suse.de", "date": "2018-12-20T11:39:59Z"}, "committer": {"name": "Richard Biener", "email": "rguenth@gcc.gnu.org", "date": "2018-12-20T11:39:59Z"}, "message": "re PR tree-optimization/84362 (Auto-vectorization regression when accessing member variable through getter/accessor)\n\n2018-12-20  Richard Biener  <rguenther@suse.de>\n\n\tPR tree-optimization/84362\n\t* tree-ssa-loop-im.c: Include alias.h, builtins.h and tree-dfa.h.\n\t(struct im_mem_ref): add ref_canonical flag.\n\t(struct mem_ref_hasher): Use ao_ref as compare_type.\n\t(mem_ref_hasher::equal): Adjust and add variant comparing ao_ref\n\tparts.\n\t(mem_ref_alloc): Take ao_ref parameter, initialize ref_canonical\n\tmember.\n\t(gather_mem_refs_stmt): Set up ao_ref early and do the lookup\n\tusing it.  If we have non-equal refs canonicalize the one\n\tin the hashtable used for insertion.\n\t(tree_ssa_lim_initialize): Adjust.\n\n\t* g++.dg/vect/pr84362.cc: New testcase.\n\nFrom-SVN: r267296", "tree": {"sha": "a7ab4ddd34dbf6dc0e3bc3b434f9a5b493b35cc9", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/a7ab4ddd34dbf6dc0e3bc3b434f9a5b493b35cc9"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/1c852d1d7096a8833b4e8dc0755a749314c2113a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1c852d1d7096a8833b4e8dc0755a749314c2113a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1c852d1d7096a8833b4e8dc0755a749314c2113a", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1c852d1d7096a8833b4e8dc0755a749314c2113a/comments", "author": {"login": "rguenth", "id": 2046526, "node_id": "MDQ6VXNlcjIwNDY1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/2046526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rguenth", "html_url": "https://github.com/rguenth", "followers_url": "https://api.github.com/users/rguenth/followers", "following_url": "https://api.github.com/users/rguenth/following{/other_user}", "gists_url": "https://api.github.com/users/rguenth/gists{/gist_id}", "starred_url": "https://api.github.com/users/rguenth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rguenth/subscriptions", "organizations_url": "https://api.github.com/users/rguenth/orgs", "repos_url": "https://api.github.com/users/rguenth/repos", "events_url": "https://api.github.com/users/rguenth/events{/privacy}", "received_events_url": "https://api.github.com/users/rguenth/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "f0355446cb66c85c5d4790c63bc53c3093186e8a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f0355446cb66c85c5d4790c63bc53c3093186e8a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f0355446cb66c85c5d4790c63bc53c3093186e8a"}], "stats": {"total": 152, "additions": 140, "deletions": 12}, "files": [{"sha": "e405a4a882549f03fd127bb0d04a69f1fc9fb65a", "filename": "gcc/ChangeLog", "status": "modified", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1c852d1d7096a8833b4e8dc0755a749314c2113a/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1c852d1d7096a8833b4e8dc0755a749314c2113a/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=1c852d1d7096a8833b4e8dc0755a749314c2113a", "patch": "@@ -1,3 +1,18 @@\n+2018-12-20  Richard Biener  <rguenther@suse.de>\n+\n+\tPR tree-optimization/84362\n+\t* tree-ssa-loop-im.c: Include alias.h, builtins.h and tree-dfa.h.\n+\t(struct im_mem_ref): add ref_canonical flag.\n+\t(struct mem_ref_hasher): Use ao_ref as compare_type.\n+\t(mem_ref_hasher::equal): Adjust and add variant comparing ao_ref\n+\tparts.\n+\t(mem_ref_alloc): Take ao_ref parameter, initialize ref_canonical\n+\tmember.\n+\t(gather_mem_refs_stmt): Set up ao_ref early and do the lookup\n+\tusing it.  If we have non-equal refs canonicalize the one\n+\tin the hashtable used for insertion.\n+\t(tree_ssa_lim_initialize): Adjust.\n+\n 2018-12-20  Jakub Jelinek  <jakub@redhat.com>\n \n \tPR target/88547"}, {"sha": "8bc30db37497d9370a41342d327ac2b8b895b8c2", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1c852d1d7096a8833b4e8dc0755a749314c2113a/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1c852d1d7096a8833b4e8dc0755a749314c2113a/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=1c852d1d7096a8833b4e8dc0755a749314c2113a", "patch": "@@ -1,3 +1,8 @@\n+2018-12-20  Richard Biener  <rguenther@suse.de>\n+\n+\tPR tree-optimization/84362\n+\t* g++.dg/vect/pr84362.cc: New testcase.\n+\n 2018-12-20  Jakub Jelinek  <jakub@redhat.com>\n \n \tPR target/88547"}, {"sha": "680ac12a0959e52940131c24cee02adc2b0dfc43", "filename": "gcc/testsuite/g++.dg/vect/pr84362.cc", "status": "added", "additions": 28, "deletions": 0, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1c852d1d7096a8833b4e8dc0755a749314c2113a/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fvect%2Fpr84362.cc", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1c852d1d7096a8833b4e8dc0755a749314c2113a/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fvect%2Fpr84362.cc", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fvect%2Fpr84362.cc?ref=1c852d1d7096a8833b4e8dc0755a749314c2113a", "patch": "@@ -0,0 +1,28 @@\n+// { dg-do compile }\n+// { dg-require-effective-target c++11 }\n+\n+constexpr unsigned int capacity = 1000;\n+\n+struct vec\n+{\n+  int values[capacity];\n+  unsigned int _size = 0;\n+  unsigned int size() const noexcept { return _size; }\n+  void push(int x)\n+    {\n+      values[size()] = x;\n+      ++_size;\n+    }\n+};\n+\n+int main()\n+{\n+  vec v;\n+  for(unsigned int i{0}; i != capacity; ++i)\n+    {\n+      v.push(i);\n+    }\n+  asm volatile(\"\" : : \"g\"(&v) : \"memory\");\n+}\n+\n+// { dg-final { scan-tree-dump \"vectorized 1 loops in function\" \"vect\" { target vect_int } } }"}, {"sha": "796d334bba67c4bd001aead21e5b75527f9efeb8", "filename": "gcc/tree-ssa-loop-im.c", "status": "modified", "additions": 92, "deletions": 12, "changes": 104, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1c852d1d7096a8833b4e8dc0755a749314c2113a/gcc%2Ftree-ssa-loop-im.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1c852d1d7096a8833b4e8dc0755a749314c2113a/gcc%2Ftree-ssa-loop-im.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-im.c?ref=1c852d1d7096a8833b4e8dc0755a749314c2113a", "patch": "@@ -45,6 +45,9 @@ along with GCC; see the file COPYING3.  If not see\n #include \"gimple-fold.h\"\n #include \"tree-scalar-evolution.h\"\n #include \"tree-ssa-loop-niter.h\"\n+#include \"alias.h\"\n+#include \"builtins.h\"\n+#include \"tree-dfa.h\"\n \n /* TODO:  Support for predicated code motion.  I.e.\n \n@@ -112,8 +115,9 @@ struct mem_ref_loc\n \n struct im_mem_ref\n {\n-  unsigned id;\t\t\t/* ID assigned to the memory reference\n+  unsigned id : 31;\t\t/* ID assigned to the memory reference\n \t\t\t\t   (its index in memory_accesses.refs_list)  */\n+  unsigned ref_canonical : 1;   /* Whether mem.ref was canonicalized.  */\n   hashval_t hash;\t\t/* Its hash value.  */\n \n   /* The memory access itself and associated caching of alias-oracle\n@@ -149,9 +153,9 @@ struct im_mem_ref\n \n struct mem_ref_hasher : nofree_ptr_hash <im_mem_ref>\n {\n-  typedef tree_node *compare_type;\n+  typedef ao_ref *compare_type;\n   static inline hashval_t hash (const im_mem_ref *);\n-  static inline bool equal (const im_mem_ref *, const tree_node *);\n+  static inline bool equal (const im_mem_ref *, const ao_ref *);\n };\n \n /* A hash function for struct im_mem_ref object OBJ.  */\n@@ -166,9 +170,19 @@ mem_ref_hasher::hash (const im_mem_ref *mem)\n    memory reference OBJ2.  */\n \n inline bool\n-mem_ref_hasher::equal (const im_mem_ref *mem1, const tree_node *obj2)\n-{\n-  return operand_equal_p (mem1->mem.ref, (const_tree) obj2, 0);\n+mem_ref_hasher::equal (const im_mem_ref *mem1, const ao_ref *obj2)\n+{\n+  if (obj2->max_size_known_p ())\n+    return (operand_equal_p (mem1->mem.base, obj2->base, 0)\n+\t    && known_eq (mem1->mem.offset, obj2->offset)\n+\t    && known_eq (mem1->mem.size, obj2->size)\n+\t    && known_eq (mem1->mem.max_size, obj2->max_size)\n+\t    && mem1->mem.volatile_p == obj2->volatile_p\n+\t    && mem1->mem.ref_alias_set == obj2->ref_alias_set\n+\t    && types_compatible_p (TREE_TYPE (mem1->mem.ref),\n+\t\t\t\t   TREE_TYPE (obj2->ref)));\n+  else\n+    return operand_equal_p (mem1->mem.ref, obj2->ref, 0);\n }\n \n \n@@ -1356,11 +1370,15 @@ memref_free (struct im_mem_ref *mem)\n    value is HASH and id is ID.  */\n \n static im_mem_ref *\n-mem_ref_alloc (tree mem, unsigned hash, unsigned id)\n+mem_ref_alloc (ao_ref *mem, unsigned hash, unsigned id)\n {\n   im_mem_ref *ref = XOBNEW (&mem_ref_obstack, struct im_mem_ref);\n-  ao_ref_init (&ref->mem, mem);\n+  if (mem)\n+    ref->mem = *mem;\n+  else\n+    ao_ref_init (&ref->mem, error_mark_node);\n   ref->id = id;\n+  ref->ref_canonical = false;\n   ref->hash = hash;\n   ref->stored = NULL;\n   bitmap_initialize (&ref->indep_loop, &lim_bitmap_obstack);\n@@ -1436,17 +1454,79 @@ gather_mem_refs_stmt (struct loop *loop, gimple *stmt)\n     }\n   else\n     {\n-      hash = iterative_hash_expr (*mem, 0);\n-      slot = memory_accesses.refs->find_slot_with_hash (*mem, hash, INSERT);\n+      /* We are looking for equal refs that might differ in structure\n+         such as a.b vs. MEM[&a + 4].  So we key off the ao_ref but\n+\t make sure we can canonicalize the ref in the hashtable if\n+\t non-operand_equal_p refs are found.  For the lookup we mark\n+\t the case we want strict equality with aor.max_size == -1.  */\n+      ao_ref aor;\n+      ao_ref_init (&aor, *mem);\n+      ao_ref_base (&aor);\n+      ao_ref_alias_set (&aor);\n+      HOST_WIDE_INT offset, size, max_size;\n+      poly_int64 saved_maxsize = aor.max_size, mem_off;\n+      tree mem_base;\n+      if (aor.max_size_known_p ()\n+\t  && aor.offset.is_constant (&offset)\n+\t  && aor.offset.is_constant (&size)\n+\t  && aor.offset.is_constant (&max_size)\n+\t  && size == max_size\n+\t  && (mem_base = get_addr_base_and_unit_offset (aor.ref, &mem_off)))\n+\t{\n+\t  hash = iterative_hash_expr (ao_ref_base (&aor), 0);\n+\t  hash = iterative_hash_host_wide_int (offset, hash);\n+\t  hash = iterative_hash_host_wide_int (size, hash);\n+\t}\n+      else\n+\t{\n+\t  hash = iterative_hash_expr (aor.ref, 0);\n+\t  aor.max_size = -1;\n+\t}\n+      slot = memory_accesses.refs->find_slot_with_hash (&aor, hash, INSERT);\n+      aor.max_size = saved_maxsize;\n       if (*slot)\n \t{\n+\t  if (!(*slot)->ref_canonical \n+\t      && !operand_equal_p (*mem, (*slot)->mem.ref, 0))\n+\t    {\n+\t      /* If we didn't yet canonicalize the hashtable ref (which\n+\t         we'll end up using for code insertion) and hit a second\n+\t\t equal ref that is not structurally equivalent create\n+\t\t a canonical ref which is a bare MEM_REF.  */\n+\t      if (TREE_CODE (*mem) == MEM_REF\n+\t\t  || TREE_CODE (*mem) == TARGET_MEM_REF)\n+\t\t{\n+\t\t  (*slot)->mem.ref = *mem;\n+\t\t  (*slot)->mem.base_alias_set = ao_ref_base_alias_set (&aor);\n+\t\t}\n+\t      else\n+\t\t{\n+\t\t  tree ref_alias_type = reference_alias_ptr_type (*mem);\n+\t\t  unsigned int ref_align = get_object_alignment (*mem);\n+\t\t  tree ref_type = TREE_TYPE (*mem);\n+\t\t  tree tmp = build_fold_addr_expr (unshare_expr (mem_base));\n+\t\t  if (TYPE_ALIGN (ref_type) != ref_align)\n+\t\t    ref_type = build_aligned_type (ref_type, ref_align);\n+\t\t  (*slot)->mem.ref\n+\t\t    = fold_build2 (MEM_REF, ref_type, tmp,\n+\t\t\t\t   build_int_cst (ref_alias_type, mem_off));\n+\t\t  if ((*slot)->mem.volatile_p)\n+\t\t    TREE_THIS_VOLATILE ((*slot)->mem.ref) = 1;\n+\t\t  gcc_checking_assert (TREE_CODE ((*slot)->mem.ref) == MEM_REF\n+\t\t\t\t       && is_gimple_mem_ref_addr\n+\t\t\t\t            (TREE_OPERAND ((*slot)->mem.ref,\n+\t\t\t\t\t\t\t   0)));\n+\t\t  (*slot)->mem.base_alias_set = (*slot)->mem.ref_alias_set;\n+\t\t}\n+\t      (*slot)->ref_canonical = true;\n+\t    }\n \t  ref = *slot;\n \t  id = ref->id;\n \t}\n       else\n \t{\n \t  id = memory_accesses.refs_list.length ();\n-\t  ref = mem_ref_alloc (*mem, hash, id);\n+\t  ref = mem_ref_alloc (&aor, hash, id);\n \t  memory_accesses.refs_list.safe_push (ref);\n \t  *slot = ref;\n \n@@ -2472,7 +2552,7 @@ tree_ssa_lim_initialize (void)\n   memory_accesses.refs_list.create (100);\n   /* Allocate a special, unanalyzable mem-ref with ID zero.  */\n   memory_accesses.refs_list.quick_push\n-    (mem_ref_alloc (error_mark_node, 0, UNANALYZABLE_MEM_ID));\n+    (mem_ref_alloc (NULL, 0, UNANALYZABLE_MEM_ID));\n \n   memory_accesses.refs_in_loop.create (number_of_loops (cfun));\n   memory_accesses.refs_in_loop.quick_grow (number_of_loops (cfun));"}]}