{"sha": "308bc496884706af4b3077171cbac684c7a6f7c6", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MzA4YmM0OTY4ODQ3MDZhZjRiMzA3NzE3MWNiYWM2ODRjN2E2ZjdjNg==", "commit": {"author": {"name": "Richard Biener", "email": "rguenther@suse.de", "date": "2020-03-16T10:47:00Z"}, "committer": {"name": "Richard Biener", "email": "rguenther@suse.de", "date": "2020-05-05T07:48:03Z"}, "message": "add vec_info * parameters where needed\n\nSoonish we'll get SLP nodes which have no corresponding scalar\nstmt and thus not stmt_vec_info and thus no way to get back to\nthe associated vec_info.  This patch makes the vec_info available\nas part of the APIs instead of putting in that back-pointer into\nthe leaf data structures.\n\n2020-05-05  Richard Biener  <rguenther@suse.de>\n\n\t* tree-vectorizer.h (_stmt_vec_info::vinfo): Remove.\n\t(STMT_VINFO_LOOP_VINFO): Likewise.\n\t(STMT_VINFO_BB_VINFO): Likewise.\n\t* tree-vect-data-refs.c: Adjust for the above, adding vec_info *\n\tparameters and adjusting calls.\n\t* tree-vect-loop-manip.c: Likewise.\n\t* tree-vect-loop.c: Likewise.\n\t* tree-vect-patterns.c: Likewise.\n\t* tree-vect-slp.c: Likewise.\n\t* tree-vect-stmts.c: Likewise.\n\t* tree-vectorizer.c: Likewise.\n\n\t* target.def (add_stmt_cost): Add vec_info * parameter.\n\t* target.h (stmt_in_inner_loop_p): Likewise.\n\t* targhooks.c (default_add_stmt_cost): Adjust.\n\t* doc/tm.texi: Re-generate.\n\n\t* config/aarch64/aarch64.c (aarch64_extending_load_p): Add\n\tvec_info * parameter and adjust.\n\t(aarch64_sve_adjust_stmt_cost): Likewise.\n\t(aarch64_add_stmt_cost): Likewise.\n\t* config/arm/arm.c (arm_add_stmt_cost): Likewise.\n\t* config/i386/i386.c (ix86_add_stmt_cost): Likewise.\n\t* config/rs6000/rs6000.c (rs6000_add_stmt_cost): Likewise.", "tree": {"sha": "c7fb9f12b283cb185bd33cf5b3fcd34e2d56f10c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/c7fb9f12b283cb185bd33cf5b3fcd34e2d56f10c"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/308bc496884706af4b3077171cbac684c7a6f7c6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/308bc496884706af4b3077171cbac684c7a6f7c6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/308bc496884706af4b3077171cbac684c7a6f7c6", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/308bc496884706af4b3077171cbac684c7a6f7c6/comments", "author": {"login": "rguenth", "id": 2046526, "node_id": "MDQ6VXNlcjIwNDY1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/2046526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rguenth", "html_url": "https://github.com/rguenth", "followers_url": "https://api.github.com/users/rguenth/followers", "following_url": "https://api.github.com/users/rguenth/following{/other_user}", "gists_url": "https://api.github.com/users/rguenth/gists{/gist_id}", "starred_url": "https://api.github.com/users/rguenth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rguenth/subscriptions", "organizations_url": "https://api.github.com/users/rguenth/orgs", "repos_url": "https://api.github.com/users/rguenth/repos", "events_url": "https://api.github.com/users/rguenth/events{/privacy}", "received_events_url": "https://api.github.com/users/rguenth/received_events", "type": "User", "site_admin": false}, "committer": {"login": "rguenth", "id": 2046526, "node_id": "MDQ6VXNlcjIwNDY1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/2046526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rguenth", "html_url": "https://github.com/rguenth", "followers_url": "https://api.github.com/users/rguenth/followers", "following_url": "https://api.github.com/users/rguenth/following{/other_user}", "gists_url": "https://api.github.com/users/rguenth/gists{/gist_id}", "starred_url": "https://api.github.com/users/rguenth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rguenth/subscriptions", "organizations_url": "https://api.github.com/users/rguenth/orgs", "repos_url": "https://api.github.com/users/rguenth/repos", "events_url": "https://api.github.com/users/rguenth/events{/privacy}", "received_events_url": "https://api.github.com/users/rguenth/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "228646a64fc1013f9133159d2e7b05fdd9972772", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/228646a64fc1013f9133159d2e7b05fdd9972772", "html_url": "https://github.com/Rust-GCC/gccrs/commit/228646a64fc1013f9133159d2e7b05fdd9972772"}], "stats": {"total": 2186, "additions": 1169, "deletions": 1017}, "files": [{"sha": "e92c7e69fcb7a8689a8b7098b86ff050dc9ab78b", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 10, "deletions": 8, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=308bc496884706af4b3077171cbac684c7a6f7c6", "patch": "@@ -13639,7 +13639,7 @@ aarch64_advsimd_ldp_stp_p (enum vect_cost_for_stmt kind,\n \n /* Return true if STMT_INFO extends the result of a load.  */\n static bool\n-aarch64_extending_load_p (stmt_vec_info stmt_info)\n+aarch64_extending_load_p (class vec_info *vinfo, stmt_vec_info stmt_info)\n {\n   gassign *assign = dyn_cast <gassign *> (stmt_info->stmt);\n   if (!assign || !CONVERT_EXPR_CODE_P (gimple_assign_rhs_code (assign)))\n@@ -13653,7 +13653,7 @@ aarch64_extending_load_p (stmt_vec_info stmt_info)\n       || TYPE_PRECISION (lhs_type) <= TYPE_PRECISION (rhs_type))\n     return false;\n \n-  stmt_vec_info def_stmt_info = stmt_info->vinfo->lookup_def (rhs);\n+  stmt_vec_info def_stmt_info = vinfo->lookup_def (rhs);\n   return (def_stmt_info\n \t  && STMT_VINFO_DATA_REF (def_stmt_info)\n \t  && DR_IS_READ (STMT_VINFO_DATA_REF (def_stmt_info)));\n@@ -13679,7 +13679,7 @@ aarch64_integer_truncation_p (stmt_vec_info stmt_info)\n    operate on vector type VECTYPE.  Adjust the cost as necessary for SVE\n    targets.  */\n static unsigned int\n-aarch64_sve_adjust_stmt_cost (vect_cost_for_stmt kind,\n+aarch64_sve_adjust_stmt_cost (class vec_info *vinfo, vect_cost_for_stmt kind,\n \t\t\t      stmt_vec_info stmt_info, tree vectype,\n \t\t\t      unsigned int stmt_cost)\n {\n@@ -13691,7 +13691,7 @@ aarch64_sve_adjust_stmt_cost (vect_cost_for_stmt kind,\n      on the fly.  Optimistically assume that a load followed by an extension\n      will fold to this form during combine, and that the extension therefore\n      comes for free.  */\n-  if (kind == vector_stmt && aarch64_extending_load_p (stmt_info))\n+  if (kind == vector_stmt && aarch64_extending_load_p (vinfo, stmt_info))\n     stmt_cost = 0;\n \n   /* For similar reasons, vector_stmt integer truncations are a no-op,\n@@ -13744,7 +13744,8 @@ aarch64_sve_adjust_stmt_cost (vect_cost_for_stmt kind,\n \n /* Implement targetm.vectorize.add_stmt_cost.  */\n static unsigned\n-aarch64_add_stmt_cost (void *data, int count, enum vect_cost_for_stmt kind,\n+aarch64_add_stmt_cost (class vec_info *vinfo, void *data, int count,\n+\t\t       enum vect_cost_for_stmt kind,\n \t\t       struct _stmt_vec_info *stmt_info, int misalign,\n \t\t       enum vect_cost_model_location where)\n {\n@@ -13758,13 +13759,14 @@ aarch64_add_stmt_cost (void *data, int count, enum vect_cost_for_stmt kind,\n \t    aarch64_builtin_vectorization_cost (kind, vectype, misalign);\n \n       if (stmt_info && vectype && aarch64_sve_mode_p (TYPE_MODE (vectype)))\n-\tstmt_cost = aarch64_sve_adjust_stmt_cost (kind, stmt_info, vectype,\n-\t\t\t\t\t\t  stmt_cost);\n+\tstmt_cost = aarch64_sve_adjust_stmt_cost (vinfo, kind, stmt_info,\n+\t\t\t\t\t\t  vectype, stmt_cost);\n \n       /* Statements in an inner loop relative to the loop being\n \t vectorized are weighted more heavily.  The value here is\n \t arbitrary and could potentially be improved with analysis.  */\n-      if (where == vect_body && stmt_info && stmt_in_inner_loop_p (stmt_info))\n+      if (where == vect_body && stmt_info\n+\t  && stmt_in_inner_loop_p (vinfo, stmt_info))\n \tcount *= 50; /*  FIXME  */\n \n       retval = (unsigned) (count * stmt_cost);"}, {"sha": "bbd7dc5316c52513626150e89c9b12700606834b", "filename": "gcc/config/arm/arm.c", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Fconfig%2Farm%2Farm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Fconfig%2Farm%2Farm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm.c?ref=308bc496884706af4b3077171cbac684c7a6f7c6", "patch": "@@ -12131,7 +12131,8 @@ arm_builtin_vectorization_cost (enum vect_cost_for_stmt type_of_cost,\n /* Implement targetm.vectorize.add_stmt_cost.  */\n \n static unsigned\n-arm_add_stmt_cost (void *data, int count, enum vect_cost_for_stmt kind,\n+arm_add_stmt_cost (class vec_info *vinfo, void *data, int count,\n+\t\t   enum vect_cost_for_stmt kind,\n \t\t   struct _stmt_vec_info *stmt_info, int misalign,\n \t\t   enum vect_cost_model_location where)\n {\n@@ -12146,7 +12147,8 @@ arm_add_stmt_cost (void *data, int count, enum vect_cost_for_stmt kind,\n       /* Statements in an inner loop relative to the loop being\n \t vectorized are weighted more heavily.  The value here is\n \t arbitrary and could potentially be improved with analysis.  */\n-      if (where == vect_body && stmt_info && stmt_in_inner_loop_p (stmt_info))\n+      if (where == vect_body && stmt_info\n+\t  && stmt_in_inner_loop_p (vinfo, stmt_info))\n \tcount *= 50;  /* FIXME.  */\n \n       retval = (unsigned) (count * stmt_cost);"}, {"sha": "b40f443ba8a6e16025b92c60eb9fc13d20b621a6", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=308bc496884706af4b3077171cbac684c7a6f7c6", "patch": "@@ -21878,7 +21878,8 @@ ix86_init_cost (class loop *)\n /* Implement targetm.vectorize.add_stmt_cost.  */\n \n static unsigned\n-ix86_add_stmt_cost (void *data, int count, enum vect_cost_for_stmt kind,\n+ix86_add_stmt_cost (class vec_info *vinfo, void *data, int count,\n+\t\t    enum vect_cost_for_stmt kind,\n \t\t    class _stmt_vec_info *stmt_info, int misalign,\n \t\t    enum vect_cost_model_location where)\n {\n@@ -22039,7 +22040,8 @@ ix86_add_stmt_cost (void *data, int count, enum vect_cost_for_stmt kind,\n   /* Statements in an inner loop relative to the loop being\n      vectorized are weighted more heavily.  The value here is\n      arbitrary and could potentially be improved with analysis.  */\n-  if (where == vect_body && stmt_info && stmt_in_inner_loop_p (stmt_info))\n+  if (where == vect_body && stmt_info\n+      && stmt_in_inner_loop_p (vinfo, stmt_info))\n     count *= 50;  /* FIXME.  */\n \n   retval = (unsigned) (count * stmt_cost);"}, {"sha": "355aea8628def909bef27e6baaed8bbeae887207", "filename": "gcc/config/rs6000/rs6000.c", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Fconfig%2Frs6000%2Frs6000.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Fconfig%2Frs6000%2Frs6000.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Frs6000%2Frs6000.c?ref=308bc496884706af4b3077171cbac684c7a6f7c6", "patch": "@@ -5046,7 +5046,8 @@ adjust_vectorization_cost (enum vect_cost_for_stmt kind,\n /* Implement targetm.vectorize.add_stmt_cost.  */\n \n static unsigned\n-rs6000_add_stmt_cost (void *data, int count, enum vect_cost_for_stmt kind,\n+rs6000_add_stmt_cost (class vec_info *vinfo, void *data, int count,\n+\t\t      enum vect_cost_for_stmt kind,\n \t\t      struct _stmt_vec_info *stmt_info, int misalign,\n \t\t      enum vect_cost_model_location where)\n {\n@@ -5062,7 +5063,8 @@ rs6000_add_stmt_cost (void *data, int count, enum vect_cost_for_stmt kind,\n       /* Statements in an inner loop relative to the loop being\n \t vectorized are weighted more heavily.  The value here is\n \t arbitrary and could potentially be improved with analysis.  */\n-      if (where == vect_body && stmt_info && stmt_in_inner_loop_p (stmt_info))\n+      if (where == vect_body && stmt_info\n+\t  && stmt_in_inner_loop_p (vinfo, stmt_info))\n \tcount *= 50;  /* FIXME.  */\n \n       retval = (unsigned) (count * stmt_cost);"}, {"sha": "710f674860aeba0af4153277d49f8c09526272f2", "filename": "gcc/doc/tm.texi", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Fdoc%2Ftm.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Fdoc%2Ftm.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Ftm.texi?ref=308bc496884706af4b3077171cbac684c7a6f7c6", "patch": "@@ -6094,7 +6094,7 @@ all zeros.  GCC can then try to branch around the instruction instead.\n This hook should initialize target-specific data structures in preparation for modeling the costs of vectorizing a loop or basic block.  The default allocates three unsigned integers for accumulating costs for the prologue, body, and epilogue of the loop or basic block.  If @var{loop_info} is non-NULL, it identifies the loop being vectorized; otherwise a single block is being vectorized.\n @end deftypefn\n \n-@deftypefn {Target Hook} unsigned TARGET_VECTORIZE_ADD_STMT_COST (void *@var{data}, int @var{count}, enum vect_cost_for_stmt @var{kind}, class _stmt_vec_info *@var{stmt_info}, int @var{misalign}, enum vect_cost_model_location @var{where})\n+@deftypefn {Target Hook} unsigned TARGET_VECTORIZE_ADD_STMT_COST (class vec_info *@var{}, void *@var{data}, int @var{count}, enum vect_cost_for_stmt @var{kind}, class _stmt_vec_info *@var{stmt_info}, int @var{misalign}, enum vect_cost_model_location @var{where})\n This hook should update the target-specific @var{data} in response to adding @var{count} copies of the given @var{kind} of statement to a loop or basic block.  The default adds the builtin vectorizer cost for the copies of the statement to the accumulator specified by @var{where}, (the prologue, body, or epilogue) and returns the amount added.  The return value should be viewed as a tentative cost that may later be revised.\n @end deftypefn\n "}, {"sha": "f8d26e63021c498187603ff4c3f95ea10de58bae", "filename": "gcc/target.def", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftarget.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftarget.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftarget.def?ref=308bc496884706af4b3077171cbac684c7a6f7c6", "patch": "@@ -2030,7 +2030,7 @@ DEFHOOK\n  \"return value should be viewed as a tentative cost that may later be \"\n  \"revised.\",\n  unsigned,\n- (void *data, int count, enum vect_cost_for_stmt kind,\n+ (class vec_info *, void *data, int count, enum vect_cost_for_stmt kind,\n   class _stmt_vec_info *stmt_info, int misalign,\n   enum vect_cost_model_location where),\n  default_add_stmt_cost)"}, {"sha": "440cd25f2975e51660149f9fba88b87a7bea37ed", "filename": "gcc/target.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftarget.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftarget.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftarget.h?ref=308bc496884706af4b3077171cbac684c7a6f7c6", "patch": "@@ -157,7 +157,7 @@ class predefined_function_abi;\n \n /* These are defined in tree-vect-stmts.c.  */\n extern tree stmt_vectype (class _stmt_vec_info *);\n-extern bool stmt_in_inner_loop_p (class _stmt_vec_info *);\n+extern bool stmt_in_inner_loop_p (class vec_info *, class _stmt_vec_info *);\n \n /* Assembler instructions for creating various kinds of integer object.  */\n "}, {"sha": "4caab8cfbfabe04b2fe011d6333e26c41ad9fe6d", "filename": "gcc/targhooks.c", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftarghooks.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftarghooks.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftarghooks.c?ref=308bc496884706af4b3077171cbac684c7a6f7c6", "patch": "@@ -1348,7 +1348,8 @@ default_init_cost (class loop *loop_info ATTRIBUTE_UNUSED)\n    it into the cost specified by WHERE, and returns the cost added.  */\n \n unsigned\n-default_add_stmt_cost (void *data, int count, enum vect_cost_for_stmt kind,\n+default_add_stmt_cost (class vec_info *vinfo, void *data, int count,\n+\t\t       enum vect_cost_for_stmt kind,\n \t\t       class _stmt_vec_info *stmt_info, int misalign,\n \t\t       enum vect_cost_model_location where)\n {\n@@ -1361,7 +1362,8 @@ default_add_stmt_cost (void *data, int count, enum vect_cost_for_stmt kind,\n    /* Statements in an inner loop relative to the loop being\n       vectorized are weighted more heavily.  The value here is\n       arbitrary and could potentially be improved with analysis.  */\n-  if (where == vect_body && stmt_info && stmt_in_inner_loop_p (stmt_info))\n+  if (where == vect_body && stmt_info\n+      && stmt_in_inner_loop_p (vinfo, stmt_info))\n     count *= 50;  /* FIXME.  */\n \n   retval = (unsigned) (count * stmt_cost);"}, {"sha": "7e9ab3ec3332fbdb447efdec7f4b72763cefde2f", "filename": "gcc/tree-vect-data-refs.c", "status": "modified", "additions": 103, "deletions": 96, "changes": 199, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vect-data-refs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vect-data-refs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-data-refs.c?ref=308bc496884706af4b3077171cbac684c7a6f7c6", "patch": "@@ -695,15 +695,15 @@ vect_slp_analyze_data_ref_dependence (vec_info *vinfo,\n    disambiguating the loads.  */\n \n static bool\n-vect_slp_analyze_node_dependences (slp_instance instance, slp_tree node,\n+vect_slp_analyze_node_dependences (vec_info *vinfo,\n+\t\t\t\t   slp_instance instance, slp_tree node,\n \t\t\t\t   vec<stmt_vec_info> stores,\n \t\t\t\t   stmt_vec_info last_store_info)\n {\n   /* This walks over all stmts involved in the SLP load/store done\n      in NODE verifying we can sink them up to the last stmt in the\n      group.  */\n   stmt_vec_info last_access_info = vect_find_last_scalar_stmt_in_slp (node);\n-  vec_info *vinfo = last_access_info->vinfo;\n   for (unsigned k = 0; k < SLP_INSTANCE_GROUP_SIZE (instance); ++k)\n     {\n       stmt_vec_info access_info = SLP_TREE_SCALAR_STMTS (node)[k];\n@@ -781,7 +781,7 @@ vect_slp_analyze_node_dependences (slp_instance instance, slp_tree node,\n    the maximum vectorization factor the data dependences allow.  */\n \n bool\n-vect_slp_analyze_instance_dependence (slp_instance instance)\n+vect_slp_analyze_instance_dependence (vec_info *vinfo, slp_instance instance)\n {\n   DUMP_VECT_SCOPE (\"vect_slp_analyze_instance_dependence\");\n \n@@ -794,7 +794,8 @@ vect_slp_analyze_instance_dependence (slp_instance instance)\n   stmt_vec_info last_store_info = NULL;\n   if (store)\n     {\n-      if (! vect_slp_analyze_node_dependences (instance, store, vNULL, NULL))\n+      if (! vect_slp_analyze_node_dependences (vinfo, instance, store,\n+\t\t\t\t\t       vNULL, NULL))\n \treturn false;\n \n       /* Mark stores in this instance and remember the last one.  */\n@@ -810,7 +811,7 @@ vect_slp_analyze_instance_dependence (slp_instance instance)\n   slp_tree load;\n   unsigned int i;\n   FOR_EACH_VEC_ELT (SLP_INSTANCE_LOADS (instance), i, load)\n-    if (! vect_slp_analyze_node_dependences (instance, load,\n+    if (! vect_slp_analyze_node_dependences (vinfo, instance, load,\n \t\t\t\t\t     store\n \t\t\t\t\t     ? SLP_TREE_SCALAR_STMTS (store)\n \t\t\t\t\t     : vNULL, last_store_info))\n@@ -831,10 +832,9 @@ vect_slp_analyze_instance_dependence (slp_instance instance)\n    in STMT_INFO.  */\n \n static void\n-vect_record_base_alignment (stmt_vec_info stmt_info,\n+vect_record_base_alignment (vec_info *vinfo, stmt_vec_info stmt_info,\n \t\t\t    innermost_loop_behavior *drb)\n {\n-  vec_info *vinfo = stmt_info->vinfo;\n   bool existed;\n   innermost_loop_behavior *&entry\n     = vinfo->base_alignments.get_or_insert (drb->base_address, &existed);\n@@ -877,13 +877,13 @@ vect_record_base_alignments (vec_info *vinfo)\n \t  && STMT_VINFO_VECTORIZABLE (stmt_info)\n \t  && !STMT_VINFO_GATHER_SCATTER_P (stmt_info))\n \t{\n-\t  vect_record_base_alignment (stmt_info, &DR_INNERMOST (dr));\n+\t  vect_record_base_alignment (vinfo, stmt_info, &DR_INNERMOST (dr));\n \n \t  /* If DR is nested in the loop that is being vectorized, we can also\n \t     record the alignment of the base wrt the outer loop.  */\n \t  if (loop && nested_in_vect_loop_p (loop, stmt_info))\n \t    vect_record_base_alignment\n-\t      (stmt_info, &STMT_VINFO_DR_WRT_VEC_LOOP (stmt_info));\n+\t      (vinfo, stmt_info, &STMT_VINFO_DR_WRT_VEC_LOOP (stmt_info));\n \t}\n     }\n }\n@@ -908,11 +908,11 @@ vect_calculate_target_alignment (dr_vec_info *dr_info)\n    only for trivial cases. TODO.  */\n \n static void\n-vect_compute_data_ref_alignment (dr_vec_info *dr_info)\n+vect_compute_data_ref_alignment (vec_info *vinfo, dr_vec_info *dr_info)\n {\n   stmt_vec_info stmt_info = dr_info->stmt;\n-  vec_base_alignments *base_alignments = &stmt_info->vinfo->base_alignments;\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n+  vec_base_alignments *base_alignments = &vinfo->base_alignments;\n+  loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (vinfo);\n   class loop *loop = NULL;\n   tree ref = DR_REF (dr_info->dr);\n   tree vectype = STMT_VINFO_VECTYPE (stmt_info);\n@@ -930,7 +930,7 @@ vect_compute_data_ref_alignment (dr_vec_info *dr_info)\n   if (STMT_VINFO_GATHER_SCATTER_P (stmt_info))\n     return;\n \n-  innermost_loop_behavior *drb = vect_dr_behavior (dr_info);\n+  innermost_loop_behavior *drb = vect_dr_behavior (vinfo, dr_info);\n   bool step_preserves_misalignment_p;\n \n   poly_uint64 vector_alignment\n@@ -1137,10 +1137,10 @@ vect_update_misalignment_for_peel (dr_vec_info *dr_info,\n    Return TRUE if DR_INFO can be handled with respect to alignment.  */\n \n static opt_result\n-verify_data_ref_alignment (dr_vec_info *dr_info)\n+verify_data_ref_alignment (vec_info *vinfo, dr_vec_info *dr_info)\n {\n   enum dr_alignment_support supportable_dr_alignment\n-    = vect_supportable_dr_alignment (dr_info, false);\n+    = vect_supportable_dr_alignment (vinfo, dr_info, false);\n   if (!supportable_dr_alignment)\n     return opt_result::failure_at\n       (dr_info->stmt->stmt,\n@@ -1187,7 +1187,7 @@ vect_verify_datarefs_alignment (loop_vec_info vinfo)\n \t  && !STMT_VINFO_GROUPED_ACCESS (stmt_info))\n \tcontinue;\n \n-      opt_result res = verify_data_ref_alignment (dr_info);\n+      opt_result res = verify_data_ref_alignment (vinfo, dr_info);\n       if (!res)\n \treturn res;\n     }\n@@ -1278,14 +1278,14 @@ vector_alignment_reachable_p (dr_vec_info *dr_info)\n /* Calculate the cost of the memory access represented by DR_INFO.  */\n \n static void\n-vect_get_data_access_cost (dr_vec_info *dr_info,\n+vect_get_data_access_cost (vec_info *vinfo, dr_vec_info *dr_info,\n                            unsigned int *inside_cost,\n                            unsigned int *outside_cost,\n \t\t\t   stmt_vector_for_cost *body_cost_vec,\n \t\t\t   stmt_vector_for_cost *prologue_cost_vec)\n {\n   stmt_vec_info stmt_info = dr_info->stmt;\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n+  loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (vinfo);\n   int ncopies;\n \n   if (PURE_SLP_STMT (stmt_info))\n@@ -1294,10 +1294,10 @@ vect_get_data_access_cost (dr_vec_info *dr_info,\n     ncopies = vect_get_num_copies (loop_vinfo, STMT_VINFO_VECTYPE (stmt_info));\n \n   if (DR_IS_READ (dr_info->dr))\n-    vect_get_load_cost (stmt_info, ncopies, true, inside_cost, outside_cost,\n-\t\t\tprologue_cost_vec, body_cost_vec, false);\n+    vect_get_load_cost (vinfo, stmt_info, ncopies, true, inside_cost,\n+\t\t\toutside_cost, prologue_cost_vec, body_cost_vec, false);\n   else\n-    vect_get_store_cost (stmt_info, ncopies, inside_cost, body_cost_vec);\n+    vect_get_store_cost (vinfo,stmt_info, ncopies, inside_cost, body_cost_vec);\n \n   if (dump_enabled_p ())\n     dump_printf_loc (MSG_NOTE, vect_location,\n@@ -1315,6 +1315,7 @@ typedef struct _vect_peel_info\n \n typedef struct _vect_peel_extended_info\n {\n+  vec_info *vinfo;\n   struct _vect_peel_info peel_info;\n   unsigned int inside_cost;\n   unsigned int outside_cost;\n@@ -1352,7 +1353,7 @@ vect_peeling_hash_insert (hash_table<peel_info_hasher> *peeling_htab,\n   struct _vect_peel_info elem, *slot;\n   _vect_peel_info **new_slot;\n   bool supportable_dr_alignment\n-    = vect_supportable_dr_alignment (dr_info, true);\n+    = vect_supportable_dr_alignment (loop_vinfo, dr_info, true);\n \n   elem.npeel = npeel;\n   slot = peeling_htab->find (&elem);\n@@ -1440,7 +1441,7 @@ vect_get_peeling_costs_all_drs (loop_vec_info loop_vinfo,\n \tSET_DR_MISALIGNMENT (dr_info, 0);\n       else\n \tvect_update_misalignment_for_peel (dr_info, dr0_info, npeel);\n-      vect_get_data_access_cost (dr_info, inside_cost, outside_cost,\n+      vect_get_data_access_cost (loop_vinfo, dr_info, inside_cost, outside_cost,\n \t\t\t\t body_cost_vec, prologue_cost_vec);\n       SET_DR_MISALIGNMENT (dr_info, save_misalignment);\n     }\n@@ -1456,8 +1457,7 @@ vect_peeling_hash_get_lowest_cost (_vect_peel_info **slot,\n   vect_peel_info elem = *slot;\n   int dummy;\n   unsigned int inside_cost = 0, outside_cost = 0;\n-  stmt_vec_info stmt_info = elem->dr_info->stmt;\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n+  loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (min->vinfo);\n   stmt_vector_for_cost prologue_cost_vec, body_cost_vec,\n \t\t       epilogue_cost_vec;\n \n@@ -1509,6 +1509,7 @@ vect_peeling_hash_choose_best_peeling (hash_table<peel_info_hasher> *peeling_hta\n    struct _vect_peel_extended_info res;\n \n    res.peel_info.dr_info = NULL;\n+   res.vinfo = loop_vinfo;\n \n    if (!unlimited_cost_model (LOOP_VINFO_LOOP (loop_vinfo)))\n      {\n@@ -1565,7 +1566,7 @@ vect_peeling_supportable (loop_vec_info loop_vinfo, dr_vec_info *dr0_info,\n       save_misalignment = DR_MISALIGNMENT (dr_info);\n       vect_update_misalignment_for_peel (dr_info, dr0_info, npeel);\n       supportable_dr_alignment\n-\t= vect_supportable_dr_alignment (dr_info, false);\n+\t= vect_supportable_dr_alignment (loop_vinfo, dr_info, false);\n       SET_DR_MISALIGNMENT (dr_info, save_misalignment);\n \n       if (!supportable_dr_alignment)\n@@ -1753,7 +1754,8 @@ vect_enhance_data_refs_alignment (loop_vec_info loop_vinfo)\n \t  && !STMT_VINFO_GROUPED_ACCESS (stmt_info))\n \tcontinue;\n \n-      supportable_dr_alignment = vect_supportable_dr_alignment (dr_info, true);\n+      supportable_dr_alignment\n+\t= vect_supportable_dr_alignment (loop_vinfo, dr_info, true);\n       do_peeling = vector_alignment_reachable_p (dr_info);\n       if (do_peeling)\n         {\n@@ -2217,7 +2219,7 @@ vect_enhance_data_refs_alignment (loop_vec_info loop_vinfo)\n \t    }\n \n \t  supportable_dr_alignment\n-\t    = vect_supportable_dr_alignment (dr_info, false);\n+\t    = vect_supportable_dr_alignment (loop_vinfo, dr_info, false);\n \n           if (!supportable_dr_alignment)\n             {\n@@ -2415,7 +2417,7 @@ vect_analyze_data_refs_alignment (loop_vec_info vinfo)\n     {\n       dr_vec_info *dr_info = vinfo->lookup_dr (dr);\n       if (STMT_VINFO_VECTORIZABLE (dr_info->stmt))\n-\tvect_compute_data_ref_alignment (dr_info);\n+\tvect_compute_data_ref_alignment (vinfo, dr_info);\n     }\n \n   return opt_result::success ();\n@@ -2425,7 +2427,7 @@ vect_analyze_data_refs_alignment (loop_vec_info vinfo)\n /* Analyze alignment of DRs of stmts in NODE.  */\n \n static bool\n-vect_slp_analyze_and_verify_node_alignment (slp_tree node)\n+vect_slp_analyze_and_verify_node_alignment (vec_info *vinfo, slp_tree node)\n {\n   /* We vectorize from the first scalar stmt in the node unless\n      the node is permuted in which case we start from the first\n@@ -2436,12 +2438,12 @@ vect_slp_analyze_and_verify_node_alignment (slp_tree node)\n     first_stmt_info = DR_GROUP_FIRST_ELEMENT (first_stmt_info);\n \n   dr_vec_info *dr_info = STMT_VINFO_DR_INFO (first_stmt_info);\n-  vect_compute_data_ref_alignment (dr_info);\n+  vect_compute_data_ref_alignment (vinfo, dr_info);\n   /* For creating the data-ref pointer we need alignment of the\n      first element anyway.  */\n   if (dr_info != first_dr_info)\n-    vect_compute_data_ref_alignment (first_dr_info);\n-  if (! verify_data_ref_alignment (dr_info))\n+    vect_compute_data_ref_alignment (vinfo, first_dr_info);\n+  if (! verify_data_ref_alignment (vinfo, dr_info))\n     {\n       if (dump_enabled_p ())\n \tdump_printf_loc (MSG_MISSED_OPTIMIZATION, vect_location,\n@@ -2459,20 +2461,21 @@ vect_slp_analyze_and_verify_node_alignment (slp_tree node)\n    Return FALSE if a data reference is found that cannot be vectorized.  */\n \n bool\n-vect_slp_analyze_and_verify_instance_alignment (slp_instance instance)\n+vect_slp_analyze_and_verify_instance_alignment (vec_info *vinfo,\n+\t\t\t\t\t\tslp_instance instance)\n {\n   DUMP_VECT_SCOPE (\"vect_slp_analyze_and_verify_instance_alignment\");\n \n   slp_tree node;\n   unsigned i;\n   FOR_EACH_VEC_ELT (SLP_INSTANCE_LOADS (instance), i, node)\n-    if (! vect_slp_analyze_and_verify_node_alignment (node))\n+    if (! vect_slp_analyze_and_verify_node_alignment (vinfo, node))\n       return false;\n \n   node = SLP_INSTANCE_TREE (instance);\n   if (STMT_VINFO_DATA_REF (SLP_TREE_SCALAR_STMTS (node)[0])\n       && ! vect_slp_analyze_and_verify_node_alignment\n-\t     (SLP_INSTANCE_TREE (instance)))\n+\t     (vinfo, SLP_INSTANCE_TREE (instance)))\n     return false;\n \n   return true;\n@@ -2486,15 +2489,15 @@ vect_slp_analyze_and_verify_instance_alignment (slp_instance instance)\n    Worker for vect_analyze_group_access.  */\n \n static bool\n-vect_analyze_group_access_1 (dr_vec_info *dr_info)\n+vect_analyze_group_access_1 (vec_info *vinfo, dr_vec_info *dr_info)\n {\n   data_reference *dr = dr_info->dr;\n   tree step = DR_STEP (dr);\n   tree scalar_type = TREE_TYPE (DR_REF (dr));\n   HOST_WIDE_INT type_size = TREE_INT_CST_LOW (TYPE_SIZE_UNIT (scalar_type));\n   stmt_vec_info stmt_info = dr_info->stmt;\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n-  bb_vec_info bb_vinfo = STMT_VINFO_BB_VINFO (stmt_info);\n+  loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (vinfo);\n+  bb_vec_info bb_vinfo = dyn_cast <bb_vec_info> (vinfo);\n   HOST_WIDE_INT dr_step = -1;\n   HOST_WIDE_INT groupsize, last_accessed_element = 1;\n   bool slp_impossible = false;\n@@ -2696,9 +2699,9 @@ vect_analyze_group_access_1 (dr_vec_info *dr_info)\n    Collect groups of strided stores for further use in SLP analysis.  */\n \n static bool\n-vect_analyze_group_access (dr_vec_info *dr_info)\n+vect_analyze_group_access (vec_info *vinfo, dr_vec_info *dr_info)\n {\n-  if (!vect_analyze_group_access_1 (dr_info))\n+  if (!vect_analyze_group_access_1 (vinfo, dr_info))\n     {\n       /* Dissolve the group if present.  */\n       stmt_vec_info stmt_info = DR_GROUP_FIRST_ELEMENT (dr_info->stmt);\n@@ -2719,13 +2722,13 @@ vect_analyze_group_access (dr_vec_info *dr_info)\n    analyze groups of accesses.  */\n \n static bool\n-vect_analyze_data_ref_access (dr_vec_info *dr_info)\n+vect_analyze_data_ref_access (vec_info *vinfo, dr_vec_info *dr_info)\n {\n   data_reference *dr = dr_info->dr;\n   tree step = DR_STEP (dr);\n   tree scalar_type = TREE_TYPE (DR_REF (dr));\n   stmt_vec_info stmt_info = dr_info->stmt;\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n+  loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (vinfo);\n   class loop *loop = NULL;\n \n   if (STMT_VINFO_GATHER_SCATTER_P (stmt_info))\n@@ -2804,10 +2807,10 @@ vect_analyze_data_ref_access (dr_vec_info *dr_info)\n   if (TREE_CODE (step) != INTEGER_CST)\n     return (STMT_VINFO_STRIDED_P (stmt_info)\n \t    && (!STMT_VINFO_GROUPED_ACCESS (stmt_info)\n-\t\t|| vect_analyze_group_access (dr_info)));\n+\t\t|| vect_analyze_group_access (vinfo, dr_info)));\n \n   /* Not consecutive access - check if it's a part of interleaving group.  */\n-  return vect_analyze_group_access (dr_info);\n+  return vect_analyze_group_access (vinfo, dr_info);\n }\n \n /* Compare two data-references DRA and DRB to group them into chunks\n@@ -3153,7 +3156,7 @@ vect_analyze_data_ref_accesses (vec_info *vinfo)\n     {\n       dr_vec_info *dr_info = vinfo->lookup_dr (dr);\n       if (STMT_VINFO_VECTORIZABLE (dr_info->stmt)\n-\t  && !vect_analyze_data_ref_access (dr_info))\n+\t  && !vect_analyze_data_ref_access (vinfo, dr_info))\n \t{\n \t  if (dump_enabled_p ())\n \t    dump_printf_loc (MSG_MISSED_OPTIMIZATION, vect_location,\n@@ -3204,7 +3207,7 @@ vect_vfa_segment_size (dr_vec_info *dr_info, tree length_factor)\n    gives the worst-case number of bytes covered by the segment.  */\n \n static unsigned HOST_WIDE_INT\n-vect_vfa_access_size (dr_vec_info *dr_info)\n+vect_vfa_access_size (vec_info *vinfo, dr_vec_info *dr_info)\n {\n   stmt_vec_info stmt_vinfo = dr_info->stmt;\n   tree ref_type = TREE_TYPE (DR_REF (dr_info->dr));\n@@ -3216,7 +3219,7 @@ vect_vfa_access_size (dr_vec_info *dr_info)\n       access_size *= DR_GROUP_SIZE (stmt_vinfo) - DR_GROUP_GAP (stmt_vinfo);\n     }\n   if (STMT_VINFO_VEC_STMT (stmt_vinfo)\n-      && (vect_supportable_dr_alignment (dr_info, false)\n+      && (vect_supportable_dr_alignment (vinfo, dr_info, false)\n \t  == dr_explicit_realign_optimized))\n     {\n       /* We might access a full vector's worth.  */\n@@ -3592,8 +3595,8 @@ vect_prune_runtime_alias_test_list (loop_vec_info loop_vinfo)\n \t  segment_length_a = vect_vfa_segment_size (dr_info_a, length_factor);\n \t  segment_length_b = vect_vfa_segment_size (dr_info_b, length_factor);\n \t}\n-      access_size_a = vect_vfa_access_size (dr_info_a);\n-      access_size_b = vect_vfa_access_size (dr_info_b);\n+      access_size_a = vect_vfa_access_size (loop_vinfo, dr_info_a);\n+      access_size_b = vect_vfa_access_size (loop_vinfo, dr_info_b);\n       align_a = vect_vfa_align (dr_info_a);\n       align_b = vect_vfa_align (dr_info_b);\n \n@@ -4580,7 +4583,7 @@ vect_duplicate_ssa_name_ptr_info (tree name, dr_vec_info *dr_info)\n    FORNOW: We are only handling array accesses with step 1.  */\n \n tree\n-vect_create_addr_base_for_vector_ref (stmt_vec_info stmt_info,\n+vect_create_addr_base_for_vector_ref (vec_info *vinfo, stmt_vec_info stmt_info,\n \t\t\t\t      gimple_seq *new_stmt_list,\n \t\t\t\t      tree offset,\n \t\t\t\t      tree byte_offset)\n@@ -4593,11 +4596,11 @@ vect_create_addr_base_for_vector_ref (stmt_vec_info stmt_info,\n   gimple_seq seq = NULL;\n   tree vect_ptr_type;\n   tree step = TYPE_SIZE_UNIT (TREE_TYPE (DR_REF (dr)));\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n-  innermost_loop_behavior *drb = vect_dr_behavior (dr_info);\n+  loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (vinfo);\n+  innermost_loop_behavior *drb = vect_dr_behavior (vinfo, dr_info);\n \n   tree data_ref_base = unshare_expr (drb->base_address);\n-  tree base_offset = unshare_expr (get_dr_vinfo_offset (dr_info, true));\n+  tree base_offset = unshare_expr (get_dr_vinfo_offset (vinfo, dr_info, true));\n   tree init = unshare_expr (drb->init);\n \n   if (loop_vinfo)\n@@ -4714,14 +4717,14 @@ vect_create_addr_base_for_vector_ref (stmt_vec_info stmt_info,\n    3. Return the pointer.  */\n \n tree\n-vect_create_data_ref_ptr (stmt_vec_info stmt_info, tree aggr_type,\n-\t\t\t  class loop *at_loop, tree offset,\n+vect_create_data_ref_ptr (vec_info *vinfo, stmt_vec_info stmt_info,\n+\t\t\t  tree aggr_type, class loop *at_loop, tree offset,\n \t\t\t  tree *initial_address, gimple_stmt_iterator *gsi,\n \t\t\t  gimple **ptr_incr, bool only_init,\n \t\t\t  tree byte_offset, tree iv_step)\n {\n   const char *base_name;\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n+  loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (vinfo);\n   class loop *loop = NULL;\n   bool nested_in_vect_loop = false;\n   class loop *containing_loop = NULL;\n@@ -4739,7 +4742,7 @@ vect_create_data_ref_ptr (stmt_vec_info stmt_info, tree aggr_type,\n   bool insert_after;\n   tree indx_before_incr, indx_after_incr;\n   gimple *incr;\n-  bb_vec_info bb_vinfo = STMT_VINFO_BB_VINFO (stmt_info);\n+  bb_vec_info bb_vinfo = dyn_cast <bb_vec_info> (vinfo);\n \n   gcc_assert (iv_step != NULL_TREE\n \t      || TREE_CODE (aggr_type) == ARRAY_TYPE\n@@ -4848,7 +4851,8 @@ vect_create_data_ref_ptr (stmt_vec_info stmt_info, tree aggr_type,\n \n   /* Create: (&(base[init_val+offset]+byte_offset) in the loop preheader.  */\n \n-  new_temp = vect_create_addr_base_for_vector_ref (stmt_info, &new_stmt_list,\n+  new_temp = vect_create_addr_base_for_vector_ref (vinfo,\n+\t\t\t\t\t\t   stmt_info, &new_stmt_list,\n \t\t\t\t\t\t   offset, byte_offset);\n   if (new_stmt_list)\n     {\n@@ -4875,7 +4879,7 @@ vect_create_data_ref_ptr (stmt_vec_info stmt_info, tree aggr_type,\n     {\n       /* Accesses to invariant addresses should be handled specially\n \t by the caller.  */\n-      tree step = vect_dr_behavior (dr_info)->step;\n+      tree step = vect_dr_behavior (vinfo, dr_info)->step;\n       gcc_assert (!integer_zerop (step));\n \n       if (iv_step == NULL_TREE)\n@@ -4977,7 +4981,8 @@ vect_create_data_ref_ptr (stmt_vec_info stmt_info, tree aggr_type,\n */\n \n tree\n-bump_vector_ptr (tree dataref_ptr, gimple *ptr_incr, gimple_stmt_iterator *gsi,\n+bump_vector_ptr (vec_info *vinfo,\n+\t\t tree dataref_ptr, gimple *ptr_incr, gimple_stmt_iterator *gsi,\n \t\t stmt_vec_info stmt_info, tree bump)\n {\n   struct data_reference *dr = STMT_VINFO_DATA_REF (stmt_info);\n@@ -4997,7 +5002,7 @@ bump_vector_ptr (tree dataref_ptr, gimple *ptr_incr, gimple_stmt_iterator *gsi,\n     new_dataref_ptr = make_ssa_name (TREE_TYPE (dataref_ptr));\n   incr_stmt = gimple_build_assign (new_dataref_ptr, POINTER_PLUS_EXPR,\n \t\t\t\t   dataref_ptr, update);\n-  vect_finish_stmt_generation (stmt_info, incr_stmt, gsi);\n+  vect_finish_stmt_generation (vinfo, stmt_info, incr_stmt, gsi);\n \n   /* Copy the points-to information if it exists. */\n   if (DR_PTR_INFO (dr))\n@@ -5277,7 +5282,7 @@ vect_store_lanes_supported (tree vectype, unsigned HOST_WIDE_INT count,\n    I4:  6 14 22 30  7 15 23 31.  */\n \n void\n-vect_permute_store_chain (vec<tree> dr_chain,\n+vect_permute_store_chain (vec_info *vinfo, vec<tree> dr_chain,\n \t\t\t  unsigned int length,\n \t\t\t  stmt_vec_info stmt_info,\n \t\t\t  gimple_stmt_iterator *gsi,\n@@ -5344,7 +5349,7 @@ vect_permute_store_chain (vec<tree> dr_chain,\n \t  data_ref = make_temp_ssa_name (vectype, NULL, \"vect_shuffle3_low\");\n \t  perm_stmt = gimple_build_assign (data_ref, VEC_PERM_EXPR, vect1,\n \t\t\t\t\t   vect2, perm3_mask_low);\n-\t  vect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+\t  vect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n \n \t  vect1 = data_ref;\n \t  vect2 = dr_chain[2];\n@@ -5355,7 +5360,7 @@ vect_permute_store_chain (vec<tree> dr_chain,\n \t  data_ref = make_temp_ssa_name (vectype, NULL, \"vect_shuffle3_high\");\n \t  perm_stmt = gimple_build_assign (data_ref, VEC_PERM_EXPR, vect1,\n \t\t\t\t\t   vect2, perm3_mask_high);\n-\t  vect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+\t  vect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n \t  (*result_chain)[j] = data_ref;\n \t}\n     }\n@@ -5394,7 +5399,7 @@ vect_permute_store_chain (vec<tree> dr_chain,\n \t\thigh = make_temp_ssa_name (vectype, NULL, \"vect_inter_high\");\n \t\tperm_stmt = gimple_build_assign (high, VEC_PERM_EXPR, vect1,\n \t\t\t\t\t\t vect2, perm_mask_high);\n-\t\tvect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+\t\tvect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n \t\t(*result_chain)[2*j] = high;\n \n \t\t/* Create interleaving stmt:\n@@ -5404,7 +5409,7 @@ vect_permute_store_chain (vec<tree> dr_chain,\n \t\tlow = make_temp_ssa_name (vectype, NULL, \"vect_inter_low\");\n \t\tperm_stmt = gimple_build_assign (low, VEC_PERM_EXPR, vect1,\n \t\t\t\t\t\t vect2, perm_mask_low);\n-\t\tvect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+\t\tvect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n \t\t(*result_chain)[2*j+1] = low;\n \t      }\n \t    memcpy (dr_chain.address (), result_chain->address (),\n@@ -5465,14 +5470,14 @@ vect_permute_store_chain (vec<tree> dr_chain,\n    Return value - the result of the loop-header phi node.  */\n \n tree\n-vect_setup_realignment (stmt_vec_info stmt_info, gimple_stmt_iterator *gsi,\n-                        tree *realignment_token,\n+vect_setup_realignment (vec_info *vinfo, stmt_vec_info stmt_info,\n+\t\t\tgimple_stmt_iterator *gsi, tree *realignment_token,\n \t\t\tenum dr_alignment_support alignment_support_scheme,\n \t\t\ttree init_addr,\n \t\t\tclass loop **at_loop)\n {\n   tree vectype = STMT_VINFO_VECTYPE (stmt_info);\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n+  loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (vinfo);\n   dr_vec_info *dr_info = STMT_VINFO_DR_INFO (stmt_info);\n   struct data_reference *dr = dr_info->dr;\n   class loop *loop = NULL;\n@@ -5579,7 +5584,7 @@ vect_setup_realignment (stmt_vec_info stmt_info, gimple_stmt_iterator *gsi,\n \n       gcc_assert (!compute_in_loop);\n       vec_dest = vect_create_destination_var (scalar_dest, vectype);\n-      ptr = vect_create_data_ref_ptr (stmt_info, vectype,\n+      ptr = vect_create_data_ref_ptr (vinfo, stmt_info, vectype,\n \t\t\t\t      loop_for_initial_load, NULL_TREE,\n \t\t\t\t      &init_addr, NULL, &inc, true);\n       if (TREE_CODE (ptr) == SSA_NAME)\n@@ -5626,7 +5631,8 @@ vect_setup_realignment (stmt_vec_info stmt_info, gimple_stmt_iterator *gsi,\n       if (!init_addr)\n \t{\n \t  /* Generate the INIT_ADDR computation outside LOOP.  */\n-\t  init_addr = vect_create_addr_base_for_vector_ref (stmt_info, &stmts,\n+\t  init_addr = vect_create_addr_base_for_vector_ref (vinfo,\n+\t\t\t\t\t\t\t    stmt_info, &stmts,\n \t\t\t\t\t\t\t    NULL_TREE);\n           if (loop)\n             {\n@@ -5900,7 +5906,7 @@ vect_load_lanes_supported (tree vectype, unsigned HOST_WIDE_INT count,\n    4th vec (E4):  3 7 11 15 19 23 27 31.  */\n \n static void\n-vect_permute_load_chain (vec<tree> dr_chain,\n+vect_permute_load_chain (vec_info *vinfo, vec<tree> dr_chain,\n \t\t\t unsigned int length,\n \t\t\t stmt_vec_info stmt_info,\n \t\t\t gimple_stmt_iterator *gsi,\n@@ -5953,7 +5959,7 @@ vect_permute_load_chain (vec<tree> dr_chain,\n \t  data_ref = make_temp_ssa_name (vectype, NULL, \"vect_shuffle3_low\");\n \t  perm_stmt = gimple_build_assign (data_ref, VEC_PERM_EXPR, first_vect,\n \t\t\t\t\t   second_vect, perm3_mask_low);\n-\t  vect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+\t  vect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n \n \t  /* Create interleaving stmt (high part of):\n \t     high = VEC_PERM_EXPR <first_vect, second_vect2, {k, 3 + k, 6 + k,\n@@ -5963,7 +5969,7 @@ vect_permute_load_chain (vec<tree> dr_chain,\n \t  data_ref = make_temp_ssa_name (vectype, NULL, \"vect_shuffle3_high\");\n \t  perm_stmt = gimple_build_assign (data_ref, VEC_PERM_EXPR, first_vect,\n \t\t\t\t\t   second_vect, perm3_mask_high);\n-\t  vect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+\t  vect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n \t  (*result_chain)[k] = data_ref;\n \t}\n     }\n@@ -5998,15 +6004,15 @@ vect_permute_load_chain (vec<tree> dr_chain,\n \t      perm_stmt = gimple_build_assign (data_ref, VEC_PERM_EXPR,\n \t\t\t\t\t       first_vect, second_vect,\n \t\t\t\t\t       perm_mask_even);\n-\t      vect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+\t      vect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n \t      (*result_chain)[j/2] = data_ref;\n \n \t      /* data_ref = permute_odd (first_data_ref, second_data_ref);  */\n \t      data_ref = make_temp_ssa_name (vectype, NULL, \"vect_perm_odd\");\n \t      perm_stmt = gimple_build_assign (data_ref, VEC_PERM_EXPR,\n \t\t\t\t\t       first_vect, second_vect,\n \t\t\t\t\t       perm_mask_odd);\n-\t      vect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+\t      vect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n \t      (*result_chain)[j/2+length/2] = data_ref;\n \t    }\n \t  memcpy (dr_chain.address (), result_chain->address (),\n@@ -6103,7 +6109,7 @@ vect_permute_load_chain (vec<tree> dr_chain,\n */\n \n static bool\n-vect_shift_permute_load_chain (vec<tree> dr_chain,\n+vect_shift_permute_load_chain (vec_info *vinfo, vec<tree> dr_chain,\n \t\t\t       unsigned int length,\n \t\t\t       stmt_vec_info stmt_info,\n \t\t\t       gimple_stmt_iterator *gsi,\n@@ -6116,7 +6122,7 @@ vect_shift_permute_load_chain (vec<tree> dr_chain,\n \n   tree vectype = STMT_VINFO_VECTYPE (stmt_info);\n   unsigned int i;\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n+  loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (vinfo);\n \n   unsigned HOST_WIDE_INT nelt, vf;\n   if (!TYPE_VECTOR_SUBPARTS (vectype).is_constant (&nelt)\n@@ -6205,26 +6211,26 @@ vect_shift_permute_load_chain (vec<tree> dr_chain,\n \t      perm_stmt = gimple_build_assign (data_ref, VEC_PERM_EXPR,\n \t\t\t\t\t       first_vect, first_vect,\n \t\t\t\t\t       perm2_mask1);\n-\t      vect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+\t      vect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n \t      vect[0] = data_ref;\n \n \t      data_ref = make_temp_ssa_name (vectype, NULL, \"vect_shuffle2\");\n \t      perm_stmt = gimple_build_assign (data_ref, VEC_PERM_EXPR,\n \t\t\t\t\t       second_vect, second_vect,\n \t\t\t\t\t       perm2_mask2);\n-\t      vect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+\t      vect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n \t      vect[1] = data_ref;\n \n \t      data_ref = make_temp_ssa_name (vectype, NULL, \"vect_shift\");\n \t      perm_stmt = gimple_build_assign (data_ref, VEC_PERM_EXPR,\n \t\t\t\t\t       vect[0], vect[1], shift1_mask);\n-\t      vect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+\t      vect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n \t      (*result_chain)[j/2 + length/2] = data_ref;\n \n \t      data_ref = make_temp_ssa_name (vectype, NULL, \"vect_select\");\n \t      perm_stmt = gimple_build_assign (data_ref, VEC_PERM_EXPR,\n \t\t\t\t\t       vect[0], vect[1], select_mask);\n-\t      vect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+\t      vect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n \t      (*result_chain)[j/2] = data_ref;\n \t    }\n \t  memcpy (dr_chain.address (), result_chain->address (),\n@@ -6321,7 +6327,7 @@ vect_shift_permute_load_chain (vec<tree> dr_chain,\n \t  perm_stmt = gimple_build_assign (data_ref, VEC_PERM_EXPR,\n \t\t\t\t\t   dr_chain[k], dr_chain[k],\n \t\t\t\t\t   perm3_mask);\n-\t  vect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+\t  vect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n \t  vect[k] = data_ref;\n \t}\n \n@@ -6331,7 +6337,7 @@ vect_shift_permute_load_chain (vec<tree> dr_chain,\n \t  perm_stmt = gimple_build_assign (data_ref, VEC_PERM_EXPR,\n \t\t\t\t\t   vect[k % 3], vect[(k + 1) % 3],\n \t\t\t\t\t   shift1_mask);\n-\t  vect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+\t  vect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n \t  vect_shift[k] = data_ref;\n \t}\n \n@@ -6342,7 +6348,7 @@ vect_shift_permute_load_chain (vec<tree> dr_chain,\n \t\t\t\t\t   vect_shift[(4 - k) % 3],\n \t\t\t\t\t   vect_shift[(3 - k) % 3],\n \t\t\t\t\t   shift2_mask);\n-\t  vect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+\t  vect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n \t  vect[k] = data_ref;\n \t}\n \n@@ -6351,13 +6357,13 @@ vect_shift_permute_load_chain (vec<tree> dr_chain,\n       data_ref = make_temp_ssa_name (vectype, NULL, \"vect_shift3\");\n       perm_stmt = gimple_build_assign (data_ref, VEC_PERM_EXPR, vect[0],\n \t\t\t\t       vect[0], shift3_mask);\n-      vect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+      vect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n       (*result_chain)[nelt % 3] = data_ref;\n \n       data_ref = make_temp_ssa_name (vectype, NULL, \"vect_shift4\");\n       perm_stmt = gimple_build_assign (data_ref, VEC_PERM_EXPR, vect[1],\n \t\t\t\t       vect[1], shift4_mask);\n-      vect_finish_stmt_generation (stmt_info, perm_stmt, gsi);\n+      vect_finish_stmt_generation (vinfo, stmt_info, perm_stmt, gsi);\n       (*result_chain)[0] = data_ref;\n       return true;\n     }\n@@ -6372,7 +6378,8 @@ vect_shift_permute_load_chain (vec<tree> dr_chain,\n */\n \n void\n-vect_transform_grouped_load (stmt_vec_info stmt_info, vec<tree> dr_chain,\n+vect_transform_grouped_load (vec_info *vinfo, stmt_vec_info stmt_info,\n+\t\t\t     vec<tree> dr_chain,\n \t\t\t     int size, gimple_stmt_iterator *gsi)\n {\n   machine_mode mode;\n@@ -6389,10 +6396,11 @@ vect_transform_grouped_load (stmt_vec_info stmt_info, vec<tree> dr_chain,\n   mode = TYPE_MODE (STMT_VINFO_VECTYPE (stmt_info));\n   if (targetm.sched.reassociation_width (VEC_PERM_EXPR, mode) > 1\n       || pow2p_hwi (size)\n-      || !vect_shift_permute_load_chain (dr_chain, size, stmt_info,\n+      || !vect_shift_permute_load_chain (vinfo, dr_chain, size, stmt_info,\n \t\t\t\t\t gsi, &result_chain))\n-    vect_permute_load_chain (dr_chain, size, stmt_info, gsi, &result_chain);\n-  vect_record_grouped_load_vectors (stmt_info, result_chain);\n+    vect_permute_load_chain (vinfo, dr_chain,\n+\t\t\t     size, stmt_info, gsi, &result_chain);\n+  vect_record_grouped_load_vectors (vinfo, stmt_info, result_chain);\n   result_chain.release ();\n }\n \n@@ -6401,10 +6409,9 @@ vect_transform_grouped_load (stmt_vec_info stmt_info, vec<tree> dr_chain,\n    for each vector to the associated scalar statement.  */\n \n void\n-vect_record_grouped_load_vectors (stmt_vec_info stmt_info,\n+vect_record_grouped_load_vectors (vec_info *vinfo, stmt_vec_info stmt_info,\n \t\t\t\t  vec<tree> result_chain)\n {\n-  vec_info *vinfo = stmt_info->vinfo;\n   stmt_vec_info first_stmt_info = DR_GROUP_FIRST_ELEMENT (stmt_info);\n   unsigned int i, gap_count;\n   tree tmp_data_ref;\n@@ -6493,14 +6500,14 @@ vect_can_force_dr_alignment_p (const_tree decl, poly_uint64 alignment)\n    alignment.  */\n \n enum dr_alignment_support\n-vect_supportable_dr_alignment (dr_vec_info *dr_info,\n+vect_supportable_dr_alignment (vec_info *vinfo, dr_vec_info *dr_info,\n                                bool check_aligned_accesses)\n {\n   data_reference *dr = dr_info->dr;\n   stmt_vec_info stmt_info = dr_info->stmt;\n   tree vectype = STMT_VINFO_VECTYPE (stmt_info);\n   machine_mode mode = TYPE_MODE (vectype);\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n+  loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (vinfo);\n   class loop *vect_loop = NULL;\n   bool nested_in_vect_loop = false;\n "}, {"sha": "8c5e696b9951a90e0e900819a76809b12d75fc27", "filename": "gcc/tree-vect-loop-manip.c", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vect-loop-manip.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vect-loop-manip.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-loop-manip.c?ref=308bc496884706af4b3077171cbac684c7a6f7c6", "patch": "@@ -1568,7 +1568,8 @@ get_misalign_in_elems (gimple **seq, loop_vec_info loop_vinfo)\n   tree offset = (negative\n \t\t ? size_int (-TYPE_VECTOR_SUBPARTS (vectype) + 1)\n \t\t : size_zero_node);\n-  tree start_addr = vect_create_addr_base_for_vector_ref (stmt_info, seq,\n+  tree start_addr = vect_create_addr_base_for_vector_ref (loop_vinfo,\n+\t\t\t\t\t\t\t  stmt_info, seq,\n \t\t\t\t\t\t\t  offset);\n   tree type = unsigned_type_for (TREE_TYPE (start_addr));\n   if (target_align.is_constant (&target_align_c))\n@@ -3057,7 +3058,8 @@ vect_create_cond_for_align_checks (loop_vec_info loop_vinfo,\n \n       /* create: addr_tmp = (int)(address_of_first_vector) */\n       addr_base =\n-\tvect_create_addr_base_for_vector_ref (stmt_info, &new_stmt_list,\n+\tvect_create_addr_base_for_vector_ref (loop_vinfo,\n+\t\t\t\t\t      stmt_info, &new_stmt_list,\n \t\t\t\t\t      offset);\n       if (new_stmt_list != NULL)\n \tgimple_seq_add_seq (cond_expr_stmt_list, new_stmt_list);"}, {"sha": "c4c3cc9ecaa41ffb01b3c59181de2b0ca22724e9", "filename": "gcc/tree-vect-loop.c", "status": "modified", "additions": 123, "deletions": 98, "changes": 221, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vect-loop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vect-loop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-loop.c?ref=308bc496884706af4b3077171cbac684c7a6f7c6", "patch": "@@ -161,7 +161,7 @@ static stmt_vec_info vect_is_simple_reduction (loop_vec_info, stmt_vec_info,\n    may already be set for general statements (not just data refs).  */\n \n static opt_result\n-vect_determine_vf_for_stmt_1 (stmt_vec_info stmt_info,\n+vect_determine_vf_for_stmt_1 (vec_info *vinfo, stmt_vec_info stmt_info,\n \t\t\t      bool vectype_maybe_set_p,\n \t\t\t      poly_uint64 *vf)\n {\n@@ -177,7 +177,8 @@ vect_determine_vf_for_stmt_1 (stmt_vec_info stmt_info,\n     }\n \n   tree stmt_vectype, nunits_vectype;\n-  opt_result res = vect_get_vector_types_for_stmt (stmt_info, &stmt_vectype,\n+  opt_result res = vect_get_vector_types_for_stmt (vinfo, stmt_info,\n+\t\t\t\t\t\t   &stmt_vectype,\n \t\t\t\t\t\t   &nunits_vectype);\n   if (!res)\n     return res;\n@@ -207,13 +208,13 @@ vect_determine_vf_for_stmt_1 (stmt_vec_info stmt_info,\n    or false if something prevented vectorization.  */\n \n static opt_result\n-vect_determine_vf_for_stmt (stmt_vec_info stmt_info, poly_uint64 *vf)\n+vect_determine_vf_for_stmt (vec_info *vinfo,\n+\t\t\t    stmt_vec_info stmt_info, poly_uint64 *vf)\n {\n-  vec_info *vinfo = stmt_info->vinfo;\n   if (dump_enabled_p ())\n     dump_printf_loc (MSG_NOTE, vect_location, \"==> examining statement: %G\",\n \t\t     stmt_info->stmt);\n-  opt_result res = vect_determine_vf_for_stmt_1 (stmt_info, false, vf);\n+  opt_result res = vect_determine_vf_for_stmt_1 (vinfo, stmt_info, false, vf);\n   if (!res)\n     return res;\n \n@@ -232,7 +233,7 @@ vect_determine_vf_for_stmt (stmt_vec_info stmt_info, poly_uint64 *vf)\n \t    dump_printf_loc (MSG_NOTE, vect_location,\n \t\t\t     \"==> examining pattern def stmt: %G\",\n \t\t\t     def_stmt_info->stmt);\n-\t  res = vect_determine_vf_for_stmt_1 (def_stmt_info, true, vf);\n+\t  res = vect_determine_vf_for_stmt_1 (vinfo, def_stmt_info, true, vf);\n \t  if (!res)\n \t    return res;\n \t}\n@@ -241,7 +242,7 @@ vect_determine_vf_for_stmt (stmt_vec_info stmt_info, poly_uint64 *vf)\n \tdump_printf_loc (MSG_NOTE, vect_location,\n \t\t\t \"==> examining pattern statement: %G\",\n \t\t\t stmt_info->stmt);\n-      res = vect_determine_vf_for_stmt_1 (stmt_info, true, vf);\n+      res = vect_determine_vf_for_stmt_1 (vinfo, stmt_info, true, vf);\n       if (!res)\n \treturn res;\n     }\n@@ -343,7 +344,8 @@ vect_determine_vectorization_factor (loop_vec_info loop_vinfo)\n \t{\n \t  stmt_info = loop_vinfo->lookup_stmt (gsi_stmt (si));\n \t  opt_result res\n-\t    = vect_determine_vf_for_stmt (stmt_info, &vectorization_factor);\n+\t    = vect_determine_vf_for_stmt (loop_vinfo,\n+\t\t\t\t\t  stmt_info, &vectorization_factor);\n \t  if (!res)\n \t    return res;\n         }\n@@ -440,9 +442,8 @@ vect_is_simple_iv_evolution (unsigned loop_nb, tree access_fn, tree * init,\n    this function would then return true for x_2.  */\n \n static bool\n-vect_inner_phi_in_double_reduction_p (stmt_vec_info stmt_info, gphi *phi)\n+vect_inner_phi_in_double_reduction_p (loop_vec_info loop_vinfo, gphi *phi)\n {\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n   use_operand_p use_p;\n   ssa_op_iter op_iter;\n   FOR_EACH_PHI_ARG (use_p, phi, op_iter, SSA_OP_USE)\n@@ -505,7 +506,7 @@ vect_analyze_scalar_cycles_1 (loop_vec_info loop_vinfo, class loop *loop)\n \t}\n \n       if (!access_fn\n-\t  || vect_inner_phi_in_double_reduction_p (stmt_vinfo, phi)\n+\t  || vect_inner_phi_in_double_reduction_p (loop_vinfo, phi)\n \t  || !vect_is_simple_iv_evolution (loop->num, access_fn, &init, &step)\n \t  || (LOOP_VINFO_LOOP (loop_vinfo) != loop\n \t      && TREE_CODE (step) != INTEGER_CST))\n@@ -1122,7 +1123,7 @@ vect_compute_single_scalar_iteration_cost (loop_vec_info loop_vinfo)\n   int j;\n   FOR_EACH_VEC_ELT (LOOP_VINFO_SCALAR_ITERATION_COST (loop_vinfo),\n \t\t    j, si)\n-    (void) add_stmt_cost (target_cost_data, si->count,\n+    (void) add_stmt_cost (loop_vinfo, target_cost_data, si->count,\n \t\t\t  si->kind, si->stmt_info, si->misalign,\n \t\t\t  vect_body);\n   unsigned dummy, body_cost = 0;\n@@ -1529,7 +1530,8 @@ vect_analyze_loop_operations (loop_vec_info loop_vinfo)\n \t\t  if ((STMT_VINFO_DEF_TYPE (stmt_info) == vect_internal_def\n \t\t       || (STMT_VINFO_DEF_TYPE (stmt_info)\n \t\t\t   == vect_double_reduction_def))\n-\t\t      && !vectorizable_lc_phi (stmt_info, NULL, NULL))\n+\t\t      && !vectorizable_lc_phi (loop_vinfo,\n+\t\t\t\t\t       stmt_info, NULL, NULL))\n \t\t    return opt_result::failure_at (phi, \"unsupported phi\\n\");\n                 }\n \n@@ -1551,21 +1553,24 @@ vect_analyze_loop_operations (loop_vec_info loop_vinfo)\n               need_to_vectorize = true;\n               if (STMT_VINFO_DEF_TYPE (stmt_info) == vect_induction_def\n \t\t  && ! PURE_SLP_STMT (stmt_info))\n-\t\tok = vectorizable_induction (stmt_info, NULL, NULL, NULL,\n+\t\tok = vectorizable_induction (loop_vinfo,\n+\t\t\t\t\t     stmt_info, NULL, NULL, NULL,\n \t\t\t\t\t     &cost_vec);\n \t      else if ((STMT_VINFO_DEF_TYPE (stmt_info) == vect_reduction_def\n \t\t\t|| (STMT_VINFO_DEF_TYPE (stmt_info)\n \t\t\t    == vect_double_reduction_def)\n \t\t\t|| STMT_VINFO_DEF_TYPE (stmt_info) == vect_nested_cycle)\n \t\t       && ! PURE_SLP_STMT (stmt_info))\n-\t\tok = vectorizable_reduction (stmt_info, NULL, NULL, &cost_vec);\n+\t\tok = vectorizable_reduction (loop_vinfo,\n+\t\t\t\t\t     stmt_info, NULL, NULL, &cost_vec);\n             }\n \n \t  /* SLP PHIs are tested by vect_slp_analyze_node_operations.  */\n \t  if (ok\n \t      && STMT_VINFO_LIVE_P (stmt_info)\n \t      && !PURE_SLP_STMT (stmt_info))\n-\t    ok = vectorizable_live_operation (stmt_info, NULL, NULL, NULL,\n+\t    ok = vectorizable_live_operation (loop_vinfo,\n+\t\t\t\t\t      stmt_info, NULL, NULL, NULL,\n \t\t\t\t\t      -1, false, &cost_vec);\n \n           if (!ok)\n@@ -1582,7 +1587,8 @@ vect_analyze_loop_operations (loop_vec_info loop_vinfo)\n \t  if (!gimple_clobber_p (stmt))\n \t    {\n \t      opt_result res\n-\t\t= vect_analyze_stmt (loop_vinfo->lookup_stmt (stmt),\n+\t\t= vect_analyze_stmt (loop_vinfo,\n+\t\t\t\t     loop_vinfo->lookup_stmt (stmt),\n \t\t\t\t     &need_to_vectorize,\n \t\t\t\t     NULL, NULL, &cost_vec);\n \t      if (!res)\n@@ -1591,7 +1597,7 @@ vect_analyze_loop_operations (loop_vec_info loop_vinfo)\n         }\n     } /* bbs */\n \n-  add_stmt_costs (loop_vinfo->target_cost_data, &cost_vec);\n+  add_stmt_costs (loop_vinfo, loop_vinfo->target_cost_data, &cost_vec);\n \n   /* All operations in the loop are either irrelevant (deal with loop\n      control, or dead), or only used outside the loop and can be moved\n@@ -3397,8 +3403,8 @@ vect_estimate_min_profitable_iters (loop_vec_info loop_vinfo,\n     {\n       /*  FIXME: Make cost depend on complexity of individual check.  */\n       unsigned len = LOOP_VINFO_MAY_MISALIGN_STMTS (loop_vinfo).length ();\n-      (void) add_stmt_cost (target_cost_data, len, vector_stmt, NULL, 0,\n-\t\t\t    vect_prologue);\n+      (void) add_stmt_cost (loop_vinfo, target_cost_data, len, vector_stmt,\n+\t\t\t    NULL, 0, vect_prologue);\n       if (dump_enabled_p ())\n \tdump_printf (MSG_NOTE,\n \t\t     \"cost model: Adding cost of checks for loop \"\n@@ -3410,13 +3416,13 @@ vect_estimate_min_profitable_iters (loop_vec_info loop_vinfo,\n     {\n       /*  FIXME: Make cost depend on complexity of individual check.  */\n       unsigned len = LOOP_VINFO_COMP_ALIAS_DDRS (loop_vinfo).length ();\n-      (void) add_stmt_cost (target_cost_data, len, vector_stmt, NULL, 0,\n-\t\t\t    vect_prologue);\n+      (void) add_stmt_cost (loop_vinfo, target_cost_data, len, vector_stmt,\n+\t\t\t    NULL, 0, vect_prologue);\n       len = LOOP_VINFO_CHECK_UNEQUAL_ADDRS (loop_vinfo).length ();\n       if (len)\n \t/* Count LEN - 1 ANDs and LEN comparisons.  */\n-\t(void) add_stmt_cost (target_cost_data, len * 2 - 1, scalar_stmt,\n-\t\t\t      NULL, 0, vect_prologue);\n+\t(void) add_stmt_cost (loop_vinfo, target_cost_data, len * 2 - 1,\n+\t\t\t      scalar_stmt, NULL, 0, vect_prologue);\n       len = LOOP_VINFO_LOWER_BOUNDS (loop_vinfo).length ();\n       if (len)\n \t{\n@@ -3426,8 +3432,8 @@ vect_estimate_min_profitable_iters (loop_vec_info loop_vinfo,\n \t  for (unsigned int i = 0; i < len; ++i)\n \t    if (!LOOP_VINFO_LOWER_BOUNDS (loop_vinfo)[i].unsigned_p)\n \t      nstmts += 1;\n-\t  (void) add_stmt_cost (target_cost_data, nstmts, scalar_stmt,\n-\t\t\t\tNULL, 0, vect_prologue);\n+\t  (void) add_stmt_cost (loop_vinfo, target_cost_data, nstmts,\n+\t\t\t\tscalar_stmt, NULL, 0, vect_prologue);\n \t}\n       if (dump_enabled_p ())\n \tdump_printf (MSG_NOTE,\n@@ -3439,17 +3445,17 @@ vect_estimate_min_profitable_iters (loop_vec_info loop_vinfo,\n   if (LOOP_REQUIRES_VERSIONING_FOR_NITERS (loop_vinfo))\n     {\n       /*  FIXME: Make cost depend on complexity of individual check.  */\n-      (void) add_stmt_cost (target_cost_data, 1, vector_stmt, NULL, 0,\n-\t\t\t    vect_prologue);\n+      (void) add_stmt_cost (loop_vinfo, target_cost_data, 1, vector_stmt,\n+\t\t\t    NULL, 0, vect_prologue);\n       if (dump_enabled_p ())\n \tdump_printf (MSG_NOTE,\n \t\t     \"cost model: Adding cost of checks for loop \"\n \t\t     \"versioning niters.\\n\");\n     }\n \n   if (LOOP_REQUIRES_VERSIONING (loop_vinfo))\n-    (void) add_stmt_cost (target_cost_data, 1, cond_branch_taken, NULL, 0,\n-\t\t\t  vect_prologue);\n+    (void) add_stmt_cost (loop_vinfo, target_cost_data, 1, cond_branch_taken,\n+\t\t\t  NULL, 0, vect_prologue);\n \n   /* Count statements in scalar loop.  Using this as scalar cost for a single\n      iteration for now.\n@@ -3484,7 +3490,7 @@ vect_estimate_min_profitable_iters (loop_vec_info loop_vinfo,\n \t  int j;\n \t  FOR_EACH_VEC_ELT (LOOP_VINFO_SCALAR_ITERATION_COST (loop_vinfo),\n \t\t\t    j, si)\n-\t    (void) add_stmt_cost (target_cost_data, si->count,\n+\t    (void) add_stmt_cost (loop_vinfo, target_cost_data, si->count,\n \t\t\t\t  si->kind, si->stmt_info, si->misalign,\n \t\t\t\t  vect_epilogue);\n \t}\n@@ -3510,9 +3516,11 @@ vect_estimate_min_profitable_iters (loop_vec_info loop_vinfo,\n \t simpler and safer to use the worst-case cost; if this ends up\n \t being the tie-breaker between vectorizing or not, then it's\n \t probably better not to vectorize.  */\n-      (void) add_stmt_cost (target_cost_data, num_masks, vector_stmt,\n+      (void) add_stmt_cost (loop_vinfo,\n+\t\t\t    target_cost_data, num_masks, vector_stmt,\n \t\t\t    NULL, 0, vect_prologue);\n-      (void) add_stmt_cost (target_cost_data, num_masks - 1, vector_stmt,\n+      (void) add_stmt_cost (loop_vinfo,\n+\t\t\t    target_cost_data, num_masks - 1, vector_stmt,\n \t\t\t    NULL, 0, vect_body);\n     }\n   else if (npeel < 0)\n@@ -3534,23 +3542,25 @@ vect_estimate_min_profitable_iters (loop_vec_info loop_vinfo,\n          branch per peeled loop. Even if scalar loop iterations are known,\n          vector iterations are not known since peeled prologue iterations are\n          not known. Hence guards remain the same.  */\n-      (void) add_stmt_cost (target_cost_data, 1, cond_branch_taken,\n+      (void) add_stmt_cost (loop_vinfo, target_cost_data, 1, cond_branch_taken,\n \t\t\t    NULL, 0, vect_prologue);\n-      (void) add_stmt_cost (target_cost_data, 1, cond_branch_not_taken,\n+      (void) add_stmt_cost (loop_vinfo,\n+\t\t\t    target_cost_data, 1, cond_branch_not_taken,\n \t\t\t    NULL, 0, vect_prologue);\n-      (void) add_stmt_cost (target_cost_data, 1, cond_branch_taken,\n+      (void) add_stmt_cost (loop_vinfo, target_cost_data, 1, cond_branch_taken,\n \t\t\t    NULL, 0, vect_epilogue);\n-      (void) add_stmt_cost (target_cost_data, 1, cond_branch_not_taken,\n+      (void) add_stmt_cost (loop_vinfo,\n+\t\t\t    target_cost_data, 1, cond_branch_not_taken,\n \t\t\t    NULL, 0, vect_epilogue);\n       stmt_info_for_cost *si;\n       int j;\n       FOR_EACH_VEC_ELT (LOOP_VINFO_SCALAR_ITERATION_COST (loop_vinfo), j, si)\n \t{\n-\t  (void) add_stmt_cost (target_cost_data,\n+\t  (void) add_stmt_cost (loop_vinfo, target_cost_data,\n \t\t\t\tsi->count * peel_iters_prologue,\n \t\t\t\tsi->kind, si->stmt_info, si->misalign,\n \t\t\t\tvect_prologue);\n-\t  (void) add_stmt_cost (target_cost_data,\n+\t  (void) add_stmt_cost (loop_vinfo, target_cost_data,\n \t\t\t\tsi->count * peel_iters_epilogue,\n \t\t\t\tsi->kind, si->stmt_info, si->misalign,\n \t\t\t\tvect_epilogue);\n@@ -3575,11 +3585,13 @@ vect_estimate_min_profitable_iters (loop_vec_info loop_vinfo,\n \t\t\t\t\t  &epilogue_cost_vec);\n \n       FOR_EACH_VEC_ELT (prologue_cost_vec, j, si)\n-\t(void) add_stmt_cost (data, si->count, si->kind, si->stmt_info,\n+\t(void) add_stmt_cost (loop_vinfo,\n+\t\t\t      data, si->count, si->kind, si->stmt_info,\n \t\t\t      si->misalign, vect_prologue);\n \n       FOR_EACH_VEC_ELT (epilogue_cost_vec, j, si)\n-\t(void) add_stmt_cost (data, si->count, si->kind, si->stmt_info,\n+\t(void) add_stmt_cost (loop_vinfo,\n+\t\t\t      data, si->count, si->kind, si->stmt_info,\n \t\t\t      si->misalign, vect_epilogue);\n \n       prologue_cost_vec.release ();\n@@ -3910,7 +3922,8 @@ have_whole_vector_shift (machine_mode mode)\n    the loop, and the epilogue code that must be generated.  */\n \n static void\n-vect_model_reduction_cost (stmt_vec_info stmt_info, internal_fn reduc_fn,\n+vect_model_reduction_cost (loop_vec_info loop_vinfo,\n+\t\t\t   stmt_vec_info stmt_info, internal_fn reduc_fn,\n \t\t\t   vect_reduction_type reduction_type,\n \t\t\t   int ncopies, stmt_vector_for_cost *cost_vec)\n {\n@@ -3919,7 +3932,6 @@ vect_model_reduction_cost (stmt_vec_info stmt_info, internal_fn reduc_fn,\n   optab optab;\n   tree vectype;\n   machine_mode mode;\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n   class loop *loop = NULL;\n \n   if (loop_vinfo)\n@@ -4148,11 +4160,11 @@ vect_model_induction_cost (stmt_vec_info stmt_info, int ncopies,\n    A cost model should help decide between these two schemes.  */\n \n static tree\n-get_initial_def_for_reduction (stmt_vec_info stmt_vinfo,\n+get_initial_def_for_reduction (loop_vec_info loop_vinfo,\n+\t\t\t       stmt_vec_info stmt_vinfo,\n \t\t\t       enum tree_code code, tree init_val,\n                                tree *adjustment_def)\n {\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_vinfo);\n   class loop *loop = LOOP_VINFO_LOOP (loop_vinfo);\n   tree scalar_type = TREE_TYPE (init_val);\n   tree vectype = get_vectype_for_scalar_type (loop_vinfo, scalar_type);\n@@ -4252,14 +4264,14 @@ get_initial_def_for_reduction (stmt_vec_info stmt_vinfo,\n    value will not change the result.  */\n \n static void\n-get_initial_defs_for_reduction (slp_tree slp_node,\n+get_initial_defs_for_reduction (vec_info *vinfo,\n+\t\t\t\tslp_tree slp_node,\n \t\t\t\tvec<tree> *vec_oprnds,\n \t\t\t\tunsigned int number_of_vectors,\n \t\t\t\tbool reduc_chain, tree neutral_op)\n {\n   vec<stmt_vec_info> stmts = SLP_TREE_SCALAR_STMTS (slp_node);\n   stmt_vec_info stmt_vinfo = stmts[0];\n-  vec_info *vinfo = stmt_vinfo->vinfo;\n   unsigned HOST_WIDE_INT nunits;\n   unsigned j, number_of_places_left_in_vector;\n   tree vector_type;\n@@ -4372,7 +4384,7 @@ get_initial_defs_for_reduction (slp_tree slp_node,\n    the stmt_vec_info the meta information is stored on.  */\n \n stmt_vec_info\n-info_for_reduction (stmt_vec_info stmt_info)\n+info_for_reduction (vec_info *vinfo, stmt_vec_info stmt_info)\n {\n   stmt_info = vect_orig_stmt (stmt_info);\n   gcc_assert (STMT_VINFO_REDUC_DEF (stmt_info));\n@@ -4388,7 +4400,7 @@ info_for_reduction (stmt_vec_info stmt_info)\n     {\n       edge pe = loop_preheader_edge (gimple_bb (phi)->loop_father);\n       stmt_vec_info info\n-\t  = stmt_info->vinfo->lookup_def (PHI_ARG_DEF_FROM_EDGE (phi, pe));\n+\t  = vinfo->lookup_def (PHI_ARG_DEF_FROM_EDGE (phi, pe));\n       if (info && STMT_VINFO_DEF_TYPE (info) == vect_double_reduction_def)\n \tstmt_info = info;\n     }\n@@ -4443,13 +4455,13 @@ info_for_reduction (stmt_vec_info stmt_info)\n */\n \n static void\n-vect_create_epilog_for_reduction (stmt_vec_info stmt_info,\n+vect_create_epilog_for_reduction (loop_vec_info loop_vinfo,\n+\t\t\t\t  stmt_vec_info stmt_info,\n \t\t\t\t  slp_tree slp_node,\n \t\t\t\t  slp_instance slp_node_instance)\n {\n-  stmt_vec_info reduc_info = info_for_reduction (stmt_info);\n+  stmt_vec_info reduc_info = info_for_reduction (loop_vinfo, stmt_info);\n   gcc_assert (reduc_info->is_reduc_info);\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n   /* For double reductions we need to get at the inner loop reduction\n      stmt which has the meta info attached.  Our stmt_info is that of the\n      loop-closed PHI of the inner loop which we remember as\n@@ -5659,15 +5671,15 @@ get_masked_reduction_fn (internal_fn reduc_fn, tree vectype_in)\n    that should be used to control the operation in a fully-masked loop.  */\n \n static bool\n-vectorize_fold_left_reduction (stmt_vec_info stmt_info,\n+vectorize_fold_left_reduction (loop_vec_info loop_vinfo,\n+\t\t\t       stmt_vec_info stmt_info,\n \t\t\t       gimple_stmt_iterator *gsi,\n \t\t\t       stmt_vec_info *vec_stmt, slp_tree slp_node,\n \t\t\t       gimple *reduc_def_stmt,\n \t\t\t       tree_code code, internal_fn reduc_fn,\n \t\t\t       tree ops[3], tree vectype_in,\n \t\t\t       int reduc_index, vec_loop_masks *masks)\n {\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n   class loop *loop = LOOP_VINFO_LOOP (loop_vinfo);\n   tree vectype_out = STMT_VINFO_VECTYPE (stmt_info);\n   stmt_vec_info new_stmt_info = NULL;\n@@ -5695,7 +5707,7 @@ vectorize_fold_left_reduction (stmt_vec_info stmt_info,\n   if (slp_node)\n     {\n       auto_vec<vec<tree> > vec_defs (2);\n-      vect_get_slp_defs (slp_node, &vec_defs);\n+      vect_get_slp_defs (loop_vinfo, slp_node, &vec_defs);\n       vec_oprnds0.safe_splice (vec_defs[1 - reduc_index]);\n       vec_defs[0].release ();\n       vec_defs[1].release ();\n@@ -5704,7 +5716,8 @@ vectorize_fold_left_reduction (stmt_vec_info stmt_info,\n     }\n   else\n     {\n-      tree loop_vec_def0 = vect_get_vec_def_for_operand (op0, stmt_info);\n+      tree loop_vec_def0 = vect_get_vec_def_for_operand (loop_vinfo,\n+\t\t\t\t\t\t\t op0, stmt_info);\n       vec_oprnds0.create (1);\n       vec_oprnds0.quick_push (loop_vec_def0);\n       scalar_dest_def_info = stmt_info;\n@@ -5782,11 +5795,13 @@ vectorize_fold_left_reduction (stmt_vec_info stmt_info,\n       if (i == vec_num - 1)\n \t{\n \t  gimple_set_lhs (new_stmt, scalar_dest);\n-\t  new_stmt_info = vect_finish_replace_stmt (scalar_dest_def_info,\n+\t  new_stmt_info = vect_finish_replace_stmt (loop_vinfo,\n+\t\t\t\t\t\t    scalar_dest_def_info,\n \t\t\t\t\t\t    new_stmt);\n \t}\n       else\n-\tnew_stmt_info = vect_finish_stmt_generation (scalar_dest_def_info,\n+\tnew_stmt_info = vect_finish_stmt_generation (loop_vinfo,\n+\t\t\t\t\t\t     scalar_dest_def_info,\n \t\t\t\t\t\t     new_stmt, gsi);\n \n       if (slp_node)\n@@ -5953,13 +5968,13 @@ build_vect_cond_expr (enum tree_code code, tree vop[3], tree mask,\n    does *NOT* necessarily hold for reduction patterns.  */\n \n bool\n-vectorizable_reduction (stmt_vec_info stmt_info, slp_tree slp_node,\n+vectorizable_reduction (loop_vec_info loop_vinfo,\n+\t\t\tstmt_vec_info stmt_info, slp_tree slp_node,\n \t\t\tslp_instance slp_node_instance,\n \t\t\tstmt_vector_for_cost *cost_vec)\n {\n   tree scalar_dest;\n   tree vectype_in = NULL_TREE;\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n   class loop *loop = LOOP_VINFO_LOOP (loop_vinfo);\n   enum vect_def_type cond_reduc_dt = vect_unknown_def_type;\n   stmt_vec_info cond_stmt_vinfo = NULL;\n@@ -5981,7 +5996,7 @@ vectorizable_reduction (stmt_vec_info stmt_info, slp_tree slp_node,\n     return false;\n \n   /* The stmt we store reduction analysis meta on.  */\n-  stmt_vec_info reduc_info = info_for_reduction (stmt_info);\n+  stmt_vec_info reduc_info = info_for_reduction (loop_vinfo, stmt_info);\n   reduc_info->is_reduc_info = true;\n \n   if (STMT_VINFO_DEF_TYPE (stmt_info) == vect_nested_cycle)\n@@ -6714,8 +6729,8 @@ vectorizable_reduction (stmt_vec_info stmt_info, slp_tree slp_node,\n   else\n     vec_num = 1;\n \n-  vect_model_reduction_cost (stmt_info, reduc_fn, reduction_type, ncopies,\n-\t\t\t     cost_vec);\n+  vect_model_reduction_cost (loop_vinfo, stmt_info, reduc_fn,\n+\t\t\t     reduction_type, ncopies, cost_vec);\n   if (dump_enabled_p ()\n       && reduction_type == FOLD_LEFT_REDUCTION)\n     dump_printf_loc (MSG_NOTE, vect_location,\n@@ -6779,18 +6794,18 @@ vectorizable_reduction (stmt_vec_info stmt_info, slp_tree slp_node,\n    value.  */\n \n bool\n-vect_transform_reduction (stmt_vec_info stmt_info, gimple_stmt_iterator *gsi,\n+vect_transform_reduction (loop_vec_info loop_vinfo,\n+\t\t\t  stmt_vec_info stmt_info, gimple_stmt_iterator *gsi,\n \t\t\t  stmt_vec_info *vec_stmt, slp_tree slp_node)\n {\n   tree vectype_out = STMT_VINFO_VECTYPE (stmt_info);\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n   class loop *loop = LOOP_VINFO_LOOP (loop_vinfo);\n   int i;\n   int ncopies;\n   int j;\n   int vec_num;\n \n-  stmt_vec_info reduc_info = info_for_reduction (stmt_info);\n+  stmt_vec_info reduc_info = info_for_reduction (loop_vinfo, stmt_info);\n   gcc_assert (reduc_info->is_reduc_info);\n \n   if (nested_in_vect_loop_p (loop, stmt_info))\n@@ -6865,7 +6880,7 @@ vect_transform_reduction (stmt_vec_info stmt_info, gimple_stmt_iterator *gsi,\n     {\n       internal_fn reduc_fn = STMT_VINFO_REDUC_FN (reduc_info);\n       return vectorize_fold_left_reduction\n-\t  (stmt_info, gsi, vec_stmt, slp_node, reduc_def_phi, code,\n+\t  (loop_vinfo, stmt_info, gsi, vec_stmt, slp_node, reduc_def_phi, code,\n \t   reduc_fn, ops, vectype_in, reduc_index, masks);\n     }\n \n@@ -6898,7 +6913,7 @@ vect_transform_reduction (stmt_vec_info stmt_info, gimple_stmt_iterator *gsi,\n \t      /* Get vec defs for all the operands except the reduction index,\n \t\t ensuring the ordering of the ops in the vector is kept.  */\n \t      auto_vec<vec<tree>, 3> vec_defs;\n-\t      vect_get_slp_defs (slp_node, &vec_defs);\n+\t      vect_get_slp_defs (loop_vinfo, slp_node, &vec_defs);\n \t      vec_oprnds0.safe_splice (vec_defs[0]);\n \t      vec_defs[0].release ();\n \t      vec_oprnds1.safe_splice (vec_defs[1]);\n@@ -6912,12 +6927,12 @@ vect_transform_reduction (stmt_vec_info stmt_info, gimple_stmt_iterator *gsi,\n           else\n \t    {\n               vec_oprnds0.quick_push\n-\t\t(vect_get_vec_def_for_operand (ops[0], stmt_info));\n+\t\t(vect_get_vec_def_for_operand (loop_vinfo, ops[0], stmt_info));\n               vec_oprnds1.quick_push\n-\t\t(vect_get_vec_def_for_operand (ops[1], stmt_info));\n+\t\t(vect_get_vec_def_for_operand (loop_vinfo, ops[1], stmt_info));\n               if (op_type == ternary_op)\n \t\tvec_oprnds2.quick_push \n-\t\t  (vect_get_vec_def_for_operand (ops[2], stmt_info));\n+\t\t  (vect_get_vec_def_for_operand (loop_vinfo, ops[2], stmt_info));\n \t    }\n         }\n       else\n@@ -6970,7 +6985,8 @@ vect_transform_reduction (stmt_vec_info stmt_info, gimple_stmt_iterator *gsi,\n \t      gimple_call_set_lhs (call, new_temp);\n \t      gimple_call_set_nothrow (call, true);\n \t      new_stmt_info\n-\t\t= vect_finish_stmt_generation (stmt_info, call, gsi);\n+\t\t= vect_finish_stmt_generation (loop_vinfo,\n+\t\t\t\t\t       stmt_info, call, gsi);\n \t    }\n \t  else\n \t    {\n@@ -6990,7 +7006,8 @@ vect_transform_reduction (stmt_vec_info stmt_info, gimple_stmt_iterator *gsi,\n \t      new_temp = make_ssa_name (vec_dest, new_stmt);\n \t      gimple_assign_set_lhs (new_stmt, new_temp);\n \t      new_stmt_info\n-\t\t= vect_finish_stmt_generation (stmt_info, new_stmt, gsi);\n+\t\t= vect_finish_stmt_generation (loop_vinfo,\n+\t\t\t\t\t       stmt_info, new_stmt, gsi);\n \t    }\n \n           if (slp_node)\n@@ -7017,11 +7034,11 @@ vect_transform_reduction (stmt_vec_info stmt_info, gimple_stmt_iterator *gsi,\n /* Transform phase of a cycle PHI.  */\n \n bool\n-vect_transform_cycle_phi (stmt_vec_info stmt_info, stmt_vec_info *vec_stmt,\n+vect_transform_cycle_phi (loop_vec_info loop_vinfo,\n+\t\t\t  stmt_vec_info stmt_info, stmt_vec_info *vec_stmt,\n \t\t\t  slp_tree slp_node, slp_instance slp_node_instance)\n {\n   tree vectype_out = STMT_VINFO_VECTYPE (stmt_info);\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n   class loop *loop = LOOP_VINFO_LOOP (loop_vinfo);\n   int i;\n   int ncopies;\n@@ -7038,7 +7055,7 @@ vect_transform_cycle_phi (stmt_vec_info stmt_info, stmt_vec_info *vec_stmt,\n \n   stmt_vec_info reduc_stmt_info = STMT_VINFO_REDUC_DEF (stmt_info);\n   reduc_stmt_info = vect_stmt_to_vectorize (reduc_stmt_info);\n-  stmt_vec_info reduc_info = info_for_reduction (stmt_info);\n+  stmt_vec_info reduc_info = info_for_reduction (loop_vinfo, stmt_info);\n   gcc_assert (reduc_info->is_reduc_info);\n \n   if (STMT_VINFO_REDUC_TYPE (reduc_info) == EXTRACT_LAST_REDUCTION\n@@ -7088,7 +7105,7 @@ vect_transform_cycle_phi (stmt_vec_info stmt_info, stmt_vec_info *vec_stmt,\n \t= neutral_op_for_slp_reduction (slp_node, vectype_out,\n \t\t\t\t\tSTMT_VINFO_REDUC_CODE (reduc_info),\n \t\t\t\t\tfirst != NULL);\n-      get_initial_defs_for_reduction (slp_node_instance->reduc_phis,\n+      get_initial_defs_for_reduction (loop_vinfo, slp_node_instance->reduc_phis,\n \t\t\t\t      &vec_initial_defs, vec_num,\n \t\t\t\t      first != NULL, neutral_op);\n     }\n@@ -7122,7 +7139,8 @@ vect_transform_cycle_phi (stmt_vec_info stmt_info, stmt_vec_info *vec_stmt,\n \t{\n \t  /* Do not use an adjustment def as that case is not supported\n \t     correctly if ncopies is not one.  */\n-\t  vec_initial_def = vect_get_vec_def_for_operand (initial_def,\n+\t  vec_initial_def = vect_get_vec_def_for_operand (loop_vinfo,\n+\t\t\t\t\t\t\t  initial_def,\n \t\t\t\t\t\t\t  reduc_stmt_info);\n \t}\n       else\n@@ -7133,7 +7151,7 @@ vect_transform_cycle_phi (stmt_vec_info stmt_info, stmt_vec_info *vec_stmt,\n \t  if (STMT_VINFO_DEF_TYPE (stmt_info) == vect_double_reduction_def)\n \t    adjustment_defp = NULL;\n \t  vec_initial_def\n-\t    = get_initial_def_for_reduction (reduc_stmt_info, code,\n+\t    = get_initial_def_for_reduction (loop_vinfo, reduc_stmt_info, code,\n \t\t\t\t\t     initial_def, adjustment_defp);\n \t  STMT_VINFO_REDUC_EPILOGUE_ADJUSTMENT (reduc_info) = adjustment_def;\n \t}\n@@ -7181,10 +7199,10 @@ vect_transform_cycle_phi (stmt_vec_info stmt_info, stmt_vec_info *vec_stmt,\n /* Vectorizes LC PHIs.  */\n \n bool\n-vectorizable_lc_phi (stmt_vec_info stmt_info, stmt_vec_info *vec_stmt,\n+vectorizable_lc_phi (loop_vec_info loop_vinfo,\n+\t\t     stmt_vec_info stmt_info, stmt_vec_info *vec_stmt,\n \t\t     slp_tree slp_node)\n {\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n   if (!loop_vinfo\n       || !is_a <gphi *> (stmt_info->stmt)\n       || gimple_phi_num_args (stmt_info->stmt) != 1)\n@@ -7206,7 +7224,8 @@ vectorizable_lc_phi (stmt_vec_info stmt_info, stmt_vec_info *vec_stmt,\n   edge e = single_pred_edge (bb);\n   tree vec_dest = vect_create_destination_var (scalar_dest, vectype);\n   vec<tree> vec_oprnds = vNULL;\n-  vect_get_vec_defs (gimple_phi_arg_def (stmt_info->stmt, 0), NULL_TREE,\n+  vect_get_vec_defs (loop_vinfo,\n+\t\t     gimple_phi_arg_def (stmt_info->stmt, 0), NULL_TREE,\n \t\t     stmt_info, &vec_oprnds, NULL, slp_node);\n   if (slp_node)\n     {\n@@ -7294,12 +7313,12 @@ vect_worthwhile_without_simd_p (vec_info *vinfo, tree_code code)\n    Return true if STMT_INFO is vectorizable in this way.  */\n \n bool\n-vectorizable_induction (stmt_vec_info stmt_info,\n+vectorizable_induction (loop_vec_info loop_vinfo,\n+\t\t\tstmt_vec_info stmt_info,\n \t\t\tgimple_stmt_iterator *gsi ATTRIBUTE_UNUSED,\n \t\t\tstmt_vec_info *vec_stmt, slp_tree slp_node,\n \t\t\tstmt_vector_for_cost *cost_vec)\n {\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n   class loop *loop = LOOP_VINFO_LOOP (loop_vinfo);\n   unsigned ncopies;\n   bool nested_in_vect_loop = false;\n@@ -7494,10 +7513,11 @@ vectorizable_induction (stmt_vec_info stmt_info,\n       new_name = fold_build2 (MULT_EXPR, TREE_TYPE (step_expr),\n \t\t\t      expr, step_expr);\n       if (! CONSTANT_CLASS_P (new_name))\n-\tnew_name = vect_init_vector (stmt_info, new_name,\n+\tnew_name = vect_init_vector (loop_vinfo, stmt_info, new_name,\n \t\t\t\t     TREE_TYPE (step_expr), NULL);\n       new_vec = build_vector_from_val (step_vectype, new_name);\n-      vec_step = vect_init_vector (stmt_info, new_vec, step_vectype, NULL);\n+      vec_step = vect_init_vector (loop_vinfo, stmt_info,\n+\t\t\t\t   new_vec, step_vectype, NULL);\n \n       /* Now generate the IVs.  */\n       unsigned group_size = SLP_TREE_SCALAR_STMTS (slp_node).length ();\n@@ -7568,10 +7588,11 @@ vectorizable_induction (stmt_vec_info stmt_info,\n \t  new_name = fold_build2 (MULT_EXPR, TREE_TYPE (step_expr),\n \t\t\t\t  expr, step_expr);\n \t  if (! CONSTANT_CLASS_P (new_name))\n-\t    new_name = vect_init_vector (stmt_info, new_name,\n+\t    new_name = vect_init_vector (loop_vinfo, stmt_info, new_name,\n \t\t\t\t\t TREE_TYPE (step_expr), NULL);\n \t  new_vec = build_vector_from_val (step_vectype, new_name);\n-\t  vec_step = vect_init_vector (stmt_info, new_vec, step_vectype, NULL);\n+\t  vec_step = vect_init_vector (loop_vinfo, stmt_info, new_vec,\n+\t\t\t\t       step_vectype, NULL);\n \t  for (; ivn < nvects; ++ivn)\n \t    {\n \t      gimple *iv = SLP_TREE_VEC_STMTS (slp_node)[ivn - nivs]->stmt;\n@@ -7606,7 +7627,8 @@ vectorizable_induction (stmt_vec_info stmt_info,\n       /* iv_loop is nested in the loop to be vectorized.  init_expr had already\n \t been created during vectorization of previous stmts.  We obtain it\n \t from the STMT_VINFO_VEC_STMT of the defining stmt.  */\n-      vec_init = vect_get_vec_def_for_operand (init_expr, stmt_info);\n+      vec_init = vect_get_vec_def_for_operand (loop_vinfo,\n+\t\t\t\t\t       init_expr, stmt_info);\n       /* If the initial value is not of proper type, convert it.  */\n       if (!useless_type_conversion_p (vectype, TREE_TYPE (vec_init)))\n \t{\n@@ -7709,7 +7731,8 @@ vectorizable_induction (stmt_vec_info stmt_info,\n   gcc_assert (CONSTANT_CLASS_P (new_name)\n \t      || TREE_CODE (new_name) == SSA_NAME);\n   new_vec = build_vector_from_val (step_vectype, t);\n-  vec_step = vect_init_vector (stmt_info, new_vec, step_vectype, NULL);\n+  vec_step = vect_init_vector (loop_vinfo, stmt_info,\n+\t\t\t       new_vec, step_vectype, NULL);\n \n \n   /* Create the following def-use cycle:\n@@ -7778,7 +7801,8 @@ vectorizable_induction (stmt_vec_info stmt_info,\n       gcc_assert (CONSTANT_CLASS_P (new_name)\n \t\t  || TREE_CODE (new_name) == SSA_NAME);\n       new_vec = build_vector_from_val (step_vectype, t);\n-      vec_step = vect_init_vector (stmt_info, new_vec, step_vectype, NULL);\n+      vec_step = vect_init_vector (loop_vinfo, stmt_info,\n+\t\t\t\t   new_vec, step_vectype, NULL);\n \n       vec_def = induc_def;\n       prev_stmt_vinfo = induction_phi_info;\n@@ -7847,13 +7871,13 @@ vectorizable_induction (stmt_vec_info stmt_info,\n    it can be supported.  */\n \n bool\n-vectorizable_live_operation (stmt_vec_info stmt_info,\n+vectorizable_live_operation (loop_vec_info loop_vinfo,\n+\t\t\t     stmt_vec_info stmt_info,\n \t\t\t     gimple_stmt_iterator *gsi,\n \t\t\t     slp_tree slp_node, slp_instance slp_node_instance,\n \t\t\t     int slp_index, bool vec_stmt_p,\n \t\t\t     stmt_vector_for_cost *)\n {\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n   class loop *loop = LOOP_VINFO_LOOP (loop_vinfo);\n   imm_use_iterator imm_iter;\n   tree lhs, lhs_type, bitsize, vec_bitsize;\n@@ -7885,12 +7909,12 @@ vectorizable_live_operation (stmt_vec_info stmt_info,\n \t  else if (slp_index != 0)\n \t    return true;\n \t}\n-      stmt_vec_info reduc_info = info_for_reduction (stmt_info);\n+      stmt_vec_info reduc_info = info_for_reduction (loop_vinfo, stmt_info);\n       gcc_assert (reduc_info->is_reduc_info);\n       if (STMT_VINFO_REDUC_TYPE (reduc_info) == FOLD_LEFT_REDUCTION\n \t  || STMT_VINFO_REDUC_TYPE (reduc_info) == EXTRACT_LAST_REDUCTION)\n \treturn true;\n-      vect_create_epilog_for_reduction (stmt_info, slp_node,\n+      vect_create_epilog_for_reduction (loop_vinfo, stmt_info, slp_node,\n \t\t\t\t\tslp_node_instance);\n       return true;\n     }\n@@ -8371,7 +8395,7 @@ vect_transform_loop_stmt (loop_vec_info loop_vinfo, stmt_vec_info stmt_info,\n   if (dump_enabled_p ())\n     dump_printf_loc (MSG_NOTE, vect_location, \"transform statement.\\n\");\n \n-  if (vect_transform_stmt (stmt_info, gsi, NULL, NULL))\n+  if (vect_transform_stmt (loop_vinfo, stmt_info, gsi, NULL, NULL))\n     *seen_store = stmt_info;\n }\n \n@@ -8730,7 +8754,7 @@ vect_transform_loop (loop_vec_info loop_vinfo, gimple *loop_vectorized_call)\n \t    {\n \t      if (dump_enabled_p ())\n \t\tdump_printf_loc (MSG_NOTE, vect_location, \"transform phi.\\n\");\n-\t      vect_transform_stmt (stmt_info, NULL, NULL, NULL);\n+\t      vect_transform_stmt (loop_vinfo, stmt_info, NULL, NULL, NULL);\n \t    }\n \t}\n \n@@ -8781,7 +8805,8 @@ vect_transform_loop (loop_vec_info loop_vinfo, gimple *loop_vectorized_call)\n \t\t    /* Interleaving.  If IS_STORE is TRUE, the\n \t\t       vectorization of the interleaving chain was\n \t\t       completed - free all the stores in the chain.  */\n-\t\t    vect_remove_stores (DR_GROUP_FIRST_ELEMENT (seen_store));\n+\t\t    vect_remove_stores (loop_vinfo,\n+\t\t\t\t\tDR_GROUP_FIRST_ELEMENT (seen_store));\n \t\t  else\n \t\t    /* Free the attached stmt_vec_info and remove the stmt.  */\n \t\t    loop_vinfo->remove_stmt (stmt_info);"}, {"sha": "1f148a0e620943a6b16762ac0a481c46ab6dd6b5", "filename": "gcc/tree-vect-patterns.c", "status": "modified", "additions": 243, "deletions": 231, "changes": 474, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vect-patterns.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vect-patterns.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-patterns.c?ref=308bc496884706af4b3077171cbac684c7a6f7c6", "patch": "@@ -98,13 +98,12 @@ vect_pattern_detected (const char *name, gimple *stmt)\n    VECTYPE if it doesn't have one already.  */\n \n static stmt_vec_info\n-vect_init_pattern_stmt (gimple *pattern_stmt, stmt_vec_info orig_stmt_info,\n-\t\t\ttree vectype)\n+vect_init_pattern_stmt (vec_info *vinfo, gimple *pattern_stmt,\n+\t\t\tstmt_vec_info orig_stmt_info, tree vectype)\n {\n-  vec_info *vinfo = orig_stmt_info->vinfo;\n   stmt_vec_info pattern_stmt_info = vinfo->lookup_stmt (pattern_stmt);\n   if (pattern_stmt_info == NULL)\n-    pattern_stmt_info = orig_stmt_info->vinfo->add_stmt (pattern_stmt);\n+    pattern_stmt_info = vinfo->add_stmt (pattern_stmt);\n   gimple_set_bb (pattern_stmt, gimple_bb (orig_stmt_info->stmt));\n \n   pattern_stmt_info->pattern_stmt_p = true;\n@@ -126,12 +125,12 @@ vect_init_pattern_stmt (gimple *pattern_stmt, stmt_vec_info orig_stmt_info,\n    have one already.  */\n \n static void\n-vect_set_pattern_stmt (gimple *pattern_stmt, stmt_vec_info orig_stmt_info,\n-\t\t       tree vectype)\n+vect_set_pattern_stmt (vec_info *vinfo, gimple *pattern_stmt,\n+\t\t       stmt_vec_info orig_stmt_info, tree vectype)\n {\n   STMT_VINFO_IN_PATTERN_P (orig_stmt_info) = true;\n   STMT_VINFO_RELATED_STMT (orig_stmt_info)\n-    = vect_init_pattern_stmt (pattern_stmt, orig_stmt_info, vectype);\n+    = vect_init_pattern_stmt (vinfo, pattern_stmt, orig_stmt_info, vectype);\n }\n \n /* Add NEW_STMT to STMT_INFO's pattern definition statements.  If VECTYPE\n@@ -141,13 +140,13 @@ vect_set_pattern_stmt (gimple *pattern_stmt, stmt_vec_info orig_stmt_info,\n    from which it was derived.  */\n \n static inline void\n-append_pattern_def_seq (stmt_vec_info stmt_info, gimple *new_stmt,\n+append_pattern_def_seq (vec_info *vinfo,\n+\t\t\tstmt_vec_info stmt_info, gimple *new_stmt,\n \t\t\ttree vectype = NULL_TREE,\n \t\t\ttree scalar_type_for_mask = NULL_TREE)\n {\n   gcc_assert (!scalar_type_for_mask\n \t      == (!vectype || !VECTOR_BOOLEAN_TYPE_P (vectype)));\n-  vec_info *vinfo = stmt_info->vinfo;\n   if (vectype)\n     {\n       stmt_vec_info new_stmt_info = vinfo->add_stmt (new_stmt);\n@@ -256,16 +255,15 @@ vect_get_internal_def (vec_info *vinfo, tree op)\n    unsigned.  */\n \n static bool\n-type_conversion_p (tree name, stmt_vec_info stmt_vinfo, bool check_sign,\n+type_conversion_p (vec_info *vinfo, tree name, bool check_sign,\n \t\t   tree *orig_type, gimple **def_stmt, bool *promotion)\n {\n   tree type = TREE_TYPE (name);\n   tree oprnd0;\n   enum vect_def_type dt;\n \n   stmt_vec_info def_stmt_info;\n-  if (!vect_is_simple_use (name, stmt_vinfo->vinfo, &dt, &def_stmt_info,\n-\t\t\t   def_stmt))\n+  if (!vect_is_simple_use (name, vinfo, &dt, &def_stmt_info, def_stmt))\n     return false;\n \n   if (dt != vect_internal_def\n@@ -293,7 +291,7 @@ type_conversion_p (tree name, stmt_vec_info stmt_vinfo, bool check_sign,\n   else\n     *promotion = false;\n \n-  if (!vect_is_simple_use (oprnd0, stmt_vinfo->vinfo, &dt))\n+  if (!vect_is_simple_use (oprnd0, vinfo, &dt))\n     return false;\n \n   return true;\n@@ -538,13 +536,12 @@ vect_joust_widened_type (tree type, tree new_type, tree *common_type)\n    exists.  */\n \n static unsigned int\n-vect_widened_op_tree (stmt_vec_info stmt_info, tree_code code,\n+vect_widened_op_tree (vec_info *vinfo, stmt_vec_info stmt_info, tree_code code,\n \t\t      tree_code widened_code, bool shift_p,\n \t\t      unsigned int max_nops,\n \t\t      vect_unpromoted_value *unprom, tree *common_type)\n {\n   /* Check for an integer operation with the right code.  */\n-  vec_info *vinfo = stmt_info->vinfo;\n   gassign *assign = dyn_cast <gassign *> (stmt_info->stmt);\n   if (!assign)\n     return 0;\n@@ -581,8 +578,7 @@ vect_widened_op_tree (stmt_vec_info stmt_info, tree_code code,\n \t  if (shift_p && i == 1)\n \t    return 0;\n \n-\t  if (!vect_look_through_possible_promotion (stmt_info->vinfo, op,\n-\t\t\t\t\t\t     this_unprom))\n+\t  if (!vect_look_through_possible_promotion (vinfo, op, this_unprom))\n \t    return 0;\n \n \t  if (TYPE_PRECISION (this_unprom->type) == TYPE_PRECISION (type))\n@@ -602,9 +598,9 @@ vect_widened_op_tree (stmt_vec_info stmt_info, tree_code code,\n \t      /* Recursively process the definition of the operand.  */\n \t      stmt_vec_info def_stmt_info\n \t\t= vinfo->lookup_def (this_unprom->op);\n-\t      nops = vect_widened_op_tree (def_stmt_info, code, widened_code,\n-\t\t\t\t\t   shift_p, max_nops, this_unprom,\n-\t\t\t\t\t   common_type);\n+\t      nops = vect_widened_op_tree (vinfo, def_stmt_info, code,\n+\t\t\t\t\t   widened_code, shift_p, max_nops,\n+\t\t\t\t\t   this_unprom, common_type);\n \t      if (nops == 0)\n \t\treturn 0;\n \n@@ -645,16 +641,15 @@ vect_recog_temp_ssa_var (tree type, gimple *stmt)\n    success.  */\n \n static bool\n-vect_split_statement (stmt_vec_info stmt2_info, tree new_rhs,\n+vect_split_statement (vec_info *vinfo, stmt_vec_info stmt2_info, tree new_rhs,\n \t\t      gimple *stmt1, tree vectype)\n {\n-  vec_info *vinfo = stmt2_info->vinfo;\n   if (is_pattern_stmt_p (stmt2_info))\n     {\n       /* STMT2_INFO is part of a pattern.  Get the statement to which\n \t the pattern is attached.  */\n       stmt_vec_info orig_stmt2_info = STMT_VINFO_RELATED_STMT (stmt2_info);\n-      vect_init_pattern_stmt (stmt1, orig_stmt2_info, vectype);\n+      vect_init_pattern_stmt (vinfo, stmt1, orig_stmt2_info, vectype);\n \n       if (dump_enabled_p ())\n \tdump_printf_loc (MSG_NOTE, vect_location,\n@@ -702,13 +697,13 @@ vect_split_statement (stmt_vec_info stmt2_info, tree new_rhs,\n \n       /* Add STMT1 as a singleton pattern definition sequence.  */\n       gimple_seq *def_seq = &STMT_VINFO_PATTERN_DEF_SEQ (stmt2_info);\n-      vect_init_pattern_stmt (stmt1, stmt2_info, vectype);\n+      vect_init_pattern_stmt (vinfo, stmt1, stmt2_info, vectype);\n       gimple_seq_add_stmt_without_update (def_seq, stmt1);\n \n       /* Build the second of the two pattern statements.  */\n       tree new_lhs = vect_recog_temp_ssa_var (lhs_type, NULL);\n       gassign *new_stmt2 = gimple_build_assign (new_lhs, NOP_EXPR, new_rhs);\n-      vect_set_pattern_stmt (new_stmt2, stmt2_info, lhs_vectype);\n+      vect_set_pattern_stmt (vinfo, new_stmt2, stmt2_info, lhs_vectype);\n \n       if (dump_enabled_p ())\n \t{\n@@ -726,11 +721,9 @@ vect_split_statement (stmt_vec_info stmt2_info, tree new_rhs,\n    available.  VECTYPE is the vector form of TYPE.  */\n \n static tree\n-vect_convert_input (stmt_vec_info stmt_info, tree type,\n+vect_convert_input (vec_info *vinfo, stmt_vec_info stmt_info, tree type,\n \t\t    vect_unpromoted_value *unprom, tree vectype)\n {\n-  vec_info *vinfo = stmt_info->vinfo;\n-\n   /* Check for a no-op conversion.  */\n   if (types_compatible_p (type, TREE_TYPE (unprom->op)))\n     return unprom->op;\n@@ -774,9 +767,10 @@ vect_convert_input (stmt_vec_info stmt_info, tree type,\n \t      input = vect_recog_temp_ssa_var (midtype, NULL);\n \t      gassign *new_stmt = gimple_build_assign (input, NOP_EXPR,\n \t\t\t\t\t\t       unprom->op);\n-\t      if (!vect_split_statement (unprom->caster, input, new_stmt,\n+\t      if (!vect_split_statement (vinfo, unprom->caster, input, new_stmt,\n \t\t\t\t\t vec_midtype))\n-\t\tappend_pattern_def_seq (stmt_info, new_stmt, vec_midtype);\n+\t\tappend_pattern_def_seq (vinfo, stmt_info,\n+\t\t\t\t\tnew_stmt, vec_midtype);\n \t    }\n \t}\n \n@@ -792,23 +786,23 @@ vect_convert_input (stmt_vec_info stmt_info, tree type,\n   /* If OP is an external value, see if we can insert the new statement\n      on an incoming edge.  */\n   if (input == unprom->op && unprom->dt == vect_external_def)\n-    if (edge e = vect_get_external_def_edge (stmt_info->vinfo, input))\n+    if (edge e = vect_get_external_def_edge (vinfo, input))\n       {\n \tbasic_block new_bb = gsi_insert_on_edge_immediate (e, new_stmt);\n \tgcc_assert (!new_bb);\n \treturn new_op;\n       }\n \n   /* As a (common) last resort, add the statement to the pattern itself.  */\n-  append_pattern_def_seq (stmt_info, new_stmt, vectype);\n+  append_pattern_def_seq (vinfo, stmt_info, new_stmt, vectype);\n   return new_op;\n }\n \n /* Invoke vect_convert_input for N elements of UNPROM and store the\n    result in the corresponding elements of RESULT.  */\n \n static void\n-vect_convert_inputs (stmt_vec_info stmt_info, unsigned int n,\n+vect_convert_inputs (vec_info *vinfo, stmt_vec_info stmt_info, unsigned int n,\n \t\t     tree *result, tree type, vect_unpromoted_value *unprom,\n \t\t     tree vectype)\n {\n@@ -821,7 +815,8 @@ vect_convert_inputs (stmt_vec_info stmt_info, unsigned int n,\n       if (j < i)\n \tresult[i] = result[j];\n       else\n-\tresult[i] = vect_convert_input (stmt_info, type, &unprom[i], vectype);\n+\tresult[i] = vect_convert_input (vinfo, stmt_info,\n+\t\t\t\t\ttype, &unprom[i], vectype);\n     }\n }\n \n@@ -833,13 +828,13 @@ vect_convert_inputs (stmt_vec_info stmt_info, unsigned int n,\n    VECITYPE is the vector form of PATTERN_STMT's result type.  */\n \n static gimple *\n-vect_convert_output (stmt_vec_info stmt_info, tree type, gimple *pattern_stmt,\n-\t\t     tree vecitype)\n+vect_convert_output (vec_info *vinfo, stmt_vec_info stmt_info, tree type,\n+\t\t     gimple *pattern_stmt, tree vecitype)\n {\n   tree lhs = gimple_get_lhs (pattern_stmt);\n   if (!types_compatible_p (type, TREE_TYPE (lhs)))\n     {\n-      append_pattern_def_seq (stmt_info, pattern_stmt, vecitype);\n+      append_pattern_def_seq (vinfo, stmt_info, pattern_stmt, vecitype);\n       tree cast_var = vect_recog_temp_ssa_var (type, NULL);\n       pattern_stmt = gimple_build_assign (cast_var, NOP_EXPR, lhs);\n     }\n@@ -855,10 +850,11 @@ vect_convert_output (stmt_vec_info stmt_info, tree type, gimple *pattern_stmt,\n    *OP0_OUT and *OP1_OUT.  */\n \n static bool\n-vect_reassociating_reduction_p (stmt_vec_info stmt_info, tree_code code,\n+vect_reassociating_reduction_p (vec_info *vinfo,\n+\t\t\t\tstmt_vec_info stmt_info, tree_code code,\n \t\t\t\ttree *op0_out, tree *op1_out)\n {\n-  loop_vec_info loop_info = STMT_VINFO_LOOP_VINFO (stmt_info);\n+  loop_vec_info loop_info = dyn_cast <loop_vec_info> (vinfo);\n   if (!loop_info)\n     return false;\n \n@@ -932,11 +928,11 @@ vect_reassociating_reduction_p (stmt_vec_info stmt_info, tree_code code,\n          inner-loop nested in an outer-loop that us being vectorized).  */\n \n static gimple *\n-vect_recog_dot_prod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n+vect_recog_dot_prod_pattern (vec_info *vinfo,\n+\t\t\t     stmt_vec_info stmt_vinfo, tree *type_out)\n {\n   tree oprnd0, oprnd1;\n   gimple *last_stmt = stmt_vinfo->stmt;\n-  vec_info *vinfo = stmt_vinfo->vinfo;\n   tree type, half_type;\n   gimple *pattern_stmt;\n   tree var;\n@@ -965,7 +961,7 @@ vect_recog_dot_prod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n   /* Starting from LAST_STMT, follow the defs of its uses in search\n      of the above pattern.  */\n \n-  if (!vect_reassociating_reduction_p (stmt_vinfo, PLUS_EXPR,\n+  if (!vect_reassociating_reduction_p (vinfo, stmt_vinfo, PLUS_EXPR,\n \t\t\t\t       &oprnd0, &oprnd1))\n     return NULL;\n \n@@ -988,7 +984,7 @@ vect_recog_dot_prod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n   /* FORNOW.  Can continue analyzing the def-use chain when this stmt in a phi\n      inside the loop (in case we are analyzing an outer-loop).  */\n   vect_unpromoted_value unprom0[2];\n-  if (!vect_widened_op_tree (mult_vinfo, MULT_EXPR, WIDEN_MULT_EXPR,\n+  if (!vect_widened_op_tree (vinfo, mult_vinfo, MULT_EXPR, WIDEN_MULT_EXPR,\n \t\t\t     false, 2, unprom0, &half_type))\n     return NULL;\n \n@@ -1007,7 +1003,7 @@ vect_recog_dot_prod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \n   /* Get the inputs in the appropriate types.  */\n   tree mult_oprnd[2];\n-  vect_convert_inputs (stmt_vinfo, 2, mult_oprnd, half_type,\n+  vect_convert_inputs (vinfo, stmt_vinfo, 2, mult_oprnd, half_type,\n \t\t       unprom0, half_vectype);\n \n   var = vect_recog_temp_ssa_var (type, NULL);\n@@ -1056,10 +1052,10 @@ vect_recog_dot_prod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n   */\n \n static gimple *\n-vect_recog_sad_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n+vect_recog_sad_pattern (vec_info *vinfo,\n+\t\t\tstmt_vec_info stmt_vinfo, tree *type_out)\n {\n   gimple *last_stmt = stmt_vinfo->stmt;\n-  vec_info *vinfo = stmt_vinfo->vinfo;\n   tree half_type;\n \n   /* Look for the following pattern\n@@ -1090,7 +1086,7 @@ vect_recog_sad_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n      of the above pattern.  */\n \n   tree plus_oprnd0, plus_oprnd1;\n-  if (!vect_reassociating_reduction_p (stmt_vinfo, PLUS_EXPR,\n+  if (!vect_reassociating_reduction_p (vinfo, stmt_vinfo, PLUS_EXPR,\n \t\t\t\t       &plus_oprnd0, &plus_oprnd1))\n     return NULL;\n \n@@ -1152,7 +1148,7 @@ vect_recog_sad_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n   /* FORNOW.  Can continue analyzing the def-use chain when this stmt in a phi\n      inside the loop (in case we are analyzing an outer-loop).  */\n   vect_unpromoted_value unprom[2];\n-  if (!vect_widened_op_tree (diff_stmt_vinfo, MINUS_EXPR, MINUS_EXPR,\n+  if (!vect_widened_op_tree (vinfo, diff_stmt_vinfo, MINUS_EXPR, MINUS_EXPR,\n \t\t\t     false, 2, unprom, &half_type))\n     return NULL;\n \n@@ -1165,7 +1161,7 @@ vect_recog_sad_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \n   /* Get the inputs to the SAD_EXPR in the appropriate types.  */\n   tree sad_oprnd[2];\n-  vect_convert_inputs (stmt_vinfo, 2, sad_oprnd, half_type,\n+  vect_convert_inputs (vinfo, stmt_vinfo, 2, sad_oprnd, half_type,\n \t\t       unprom, half_vectype);\n \n   tree var = vect_recog_temp_ssa_var (sum_type, NULL);\n@@ -1201,16 +1197,16 @@ vect_recog_sad_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n    name of the pattern being matched, for dump purposes.  */\n \n static gimple *\n-vect_recog_widen_op_pattern (stmt_vec_info last_stmt_info, tree *type_out,\n+vect_recog_widen_op_pattern (vec_info *vinfo,\n+\t\t\t     stmt_vec_info last_stmt_info, tree *type_out,\n \t\t\t     tree_code orig_code, tree_code wide_code,\n \t\t\t     bool shift_p, const char *name)\n {\n-  vec_info *vinfo = last_stmt_info->vinfo;\n   gimple *last_stmt = last_stmt_info->stmt;\n \n   vect_unpromoted_value unprom[2];\n   tree half_type;\n-  if (!vect_widened_op_tree (last_stmt_info, orig_code, orig_code,\n+  if (!vect_widened_op_tree (vinfo, last_stmt_info, orig_code, orig_code,\n \t\t\t     shift_p, 2, unprom, &half_type))\n     return NULL;\n \n@@ -1232,7 +1228,7 @@ vect_recog_widen_op_pattern (stmt_vec_info last_stmt_info, tree *type_out,\n   auto_vec<tree> dummy_vec;\n   if (!vectype\n       || !vecitype\n-      || !supportable_widening_operation (wide_code, last_stmt_info,\n+      || !supportable_widening_operation (vinfo, wide_code, last_stmt_info,\n \t\t\t\t\t  vecitype, vectype,\n \t\t\t\t\t  &dummy_code, &dummy_code,\n \t\t\t\t\t  &dummy_int, &dummy_vec))\n@@ -1243,23 +1239,26 @@ vect_recog_widen_op_pattern (stmt_vec_info last_stmt_info, tree *type_out,\n     return NULL;\n \n   tree oprnd[2];\n-  vect_convert_inputs (last_stmt_info, 2, oprnd, half_type, unprom, vectype);\n+  vect_convert_inputs (vinfo, last_stmt_info,\n+\t\t       2, oprnd, half_type, unprom, vectype);\n \n   tree var = vect_recog_temp_ssa_var (itype, NULL);\n   gimple *pattern_stmt = gimple_build_assign (var, wide_code,\n \t\t\t\t\t      oprnd[0], oprnd[1]);\n \n-  return vect_convert_output (last_stmt_info, type, pattern_stmt, vecitype);\n+  return vect_convert_output (vinfo, last_stmt_info,\n+\t\t\t      type, pattern_stmt, vecitype);\n }\n \n /* Try to detect multiplication on widened inputs, converting MULT_EXPR\n    to WIDEN_MULT_EXPR.  See vect_recog_widen_op_pattern for details.  */\n \n static gimple *\n-vect_recog_widen_mult_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n+vect_recog_widen_mult_pattern (vec_info *vinfo, stmt_vec_info last_stmt_info,\n+\t\t\t       tree *type_out)\n {\n-  return vect_recog_widen_op_pattern (last_stmt_info, type_out, MULT_EXPR,\n-\t\t\t\t      WIDEN_MULT_EXPR, false,\n+  return vect_recog_widen_op_pattern (vinfo, last_stmt_info, type_out,\n+\t\t\t\t      MULT_EXPR, WIDEN_MULT_EXPR, false,\n \t\t\t\t      \"vect_recog_widen_mult_pattern\");\n }\n \n@@ -1288,9 +1287,9 @@ vect_recog_widen_mult_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n */\n \n static gimple *\n-vect_recog_pow_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n+vect_recog_pow_pattern (vec_info *vinfo,\n+\t\t\tstmt_vec_info stmt_vinfo, tree *type_out)\n {\n-  vec_info *vinfo = stmt_vinfo->vinfo;\n   gimple *last_stmt = stmt_vinfo->stmt;\n   tree base, exp;\n   gimple *stmt;\n@@ -1364,7 +1363,7 @@ vect_recog_pow_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \t\treturn NULL;\n \t      tree def = vect_recog_temp_ssa_var (TREE_TYPE (base), NULL);\n \t      gimple *g = gimple_build_assign (def, MULT_EXPR, exp, logc);\n-\t      append_pattern_def_seq (stmt_vinfo, g);\n+\t      append_pattern_def_seq (vinfo, stmt_vinfo, g);\n \t      tree res = vect_recog_temp_ssa_var (TREE_TYPE (base), NULL);\n \t      g = gimple_build_call (exp_decl, 1, def);\n \t      gimple_call_set_lhs (g, res);\n@@ -1452,11 +1451,11 @@ vect_recog_pow_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \t inner-loop nested in an outer-loop that us being vectorized).  */\n \n static gimple *\n-vect_recog_widen_sum_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n+vect_recog_widen_sum_pattern (vec_info *vinfo,\n+\t\t\t      stmt_vec_info stmt_vinfo, tree *type_out)\n {\n   gimple *last_stmt = stmt_vinfo->stmt;\n   tree oprnd0, oprnd1;\n-  vec_info *vinfo = stmt_vinfo->vinfo;\n   tree type;\n   gimple *pattern_stmt;\n   tree var;\n@@ -1471,7 +1470,7 @@ vect_recog_widen_sum_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n   /* Starting from LAST_STMT, follow the defs of its uses in search\n      of the above pattern.  */\n \n-  if (!vect_reassociating_reduction_p (stmt_vinfo, PLUS_EXPR,\n+  if (!vect_reassociating_reduction_p (vinfo, stmt_vinfo, PLUS_EXPR,\n \t\t\t\t       &oprnd0, &oprnd1))\n     return NULL;\n \n@@ -1540,7 +1539,8 @@ vect_recog_widen_sum_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n    by users of the result.  */\n \n static gimple *\n-vect_recog_over_widening_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n+vect_recog_over_widening_pattern (vec_info *vinfo,\n+\t\t\t\t  stmt_vec_info last_stmt_info, tree *type_out)\n {\n   gassign *last_stmt = dyn_cast <gassign *> (last_stmt_info->stmt);\n   if (!last_stmt)\n@@ -1552,7 +1552,6 @@ vect_recog_over_widening_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n   if (!new_precision)\n     return NULL;\n \n-  vec_info *vinfo = last_stmt_info->vinfo;\n   tree lhs = gimple_assign_lhs (last_stmt);\n   tree type = TREE_TYPE (lhs);\n   tree_code code = gimple_assign_rhs_code (last_stmt);\n@@ -1716,7 +1715,7 @@ vect_recog_over_widening_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n   tree ops[3] = {};\n   for (unsigned int i = 1; i < first_op; ++i)\n     ops[i - 1] = gimple_op (last_stmt, i);\n-  vect_convert_inputs (last_stmt_info, nops, &ops[first_op - 1],\n+  vect_convert_inputs (vinfo, last_stmt_info, nops, &ops[first_op - 1],\n \t\t       op_type, &unprom[0], op_vectype);\n \n   /* Use the operation to produce a result of type OP_TYPE.  */\n@@ -1732,11 +1731,11 @@ vect_recog_over_widening_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n   /* Convert back to the original signedness, if OP_TYPE is different\n      from NEW_TYPE.  */\n   if (op_type != new_type)\n-    pattern_stmt = vect_convert_output (last_stmt_info, new_type,\n+    pattern_stmt = vect_convert_output (vinfo, last_stmt_info, new_type,\n \t\t\t\t\tpattern_stmt, op_vectype);\n \n   /* Promote the result to the original type.  */\n-  pattern_stmt = vect_convert_output (last_stmt_info, type,\n+  pattern_stmt = vect_convert_output (vinfo, last_stmt_info, type,\n \t\t\t\t      pattern_stmt, new_vectype);\n \n   return pattern_stmt;\n@@ -1755,14 +1754,14 @@ vect_recog_over_widening_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n    where only the bottom half of res is used.  */\n \n static gimple *\n-vect_recog_mulhs_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n+vect_recog_mulhs_pattern (vec_info *vinfo,\n+\t\t\t  stmt_vec_info last_stmt_info, tree *type_out)\n {\n   /* Check for a right shift.  */\n   gassign *last_stmt = dyn_cast <gassign *> (last_stmt_info->stmt);\n   if (!last_stmt\n       || gimple_assign_rhs_code (last_stmt) != RSHIFT_EXPR)\n     return NULL;\n-  vec_info *vinfo = last_stmt_info->vinfo;\n \n   /* Check that the shift result is wider than the users of the\n      result need (i.e. that narrowing would be a natural choice).  */\n@@ -1868,7 +1867,7 @@ vect_recog_mulhs_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n   vect_unpromoted_value unprom_mult[2];\n   tree new_type;\n   unsigned int nops\n-    = vect_widened_op_tree (mulh_stmt_info, MULT_EXPR, WIDEN_MULT_EXPR,\n+    = vect_widened_op_tree (vinfo, mulh_stmt_info, MULT_EXPR, WIDEN_MULT_EXPR,\n \t\t\t    false, 2, unprom_mult, &new_type);\n   if (nops != 2)\n     return NULL;\n@@ -1896,7 +1895,7 @@ vect_recog_mulhs_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n   /* Generate the IFN_MULHRS call.  */\n   tree new_var = vect_recog_temp_ssa_var (new_type, NULL);\n   tree new_ops[2];\n-  vect_convert_inputs (last_stmt_info, 2, new_ops, new_type,\n+  vect_convert_inputs (vinfo, last_stmt_info, 2, new_ops, new_type,\n \t\t       unprom_mult, new_vectype);\n   gcall *mulhrs_stmt\n     = gimple_build_call_internal (ifn, 2, new_ops[0], new_ops[1]);\n@@ -1907,7 +1906,7 @@ vect_recog_mulhs_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n     dump_printf_loc (MSG_NOTE, vect_location,\n \t\t     \"created pattern stmt: %G\", mulhrs_stmt);\n \n-  return vect_convert_output (last_stmt_info, lhs_type,\n+  return vect_convert_output (vinfo, last_stmt_info, lhs_type,\n \t\t\t      mulhrs_stmt, new_vectype);\n }\n \n@@ -1934,11 +1933,11 @@ vect_recog_mulhs_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n   over plus and add a carry.  */\n \n static gimple *\n-vect_recog_average_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n+vect_recog_average_pattern (vec_info *vinfo,\n+\t\t\t    stmt_vec_info last_stmt_info, tree *type_out)\n {\n   /* Check for a shift right by one bit.  */\n   gassign *last_stmt = dyn_cast <gassign *> (last_stmt_info->stmt);\n-  vec_info *vinfo = last_stmt_info->vinfo;\n   if (!last_stmt\n       || gimple_assign_rhs_code (last_stmt) != RSHIFT_EXPR\n       || !integer_onep (gimple_assign_rhs2 (last_stmt)))\n@@ -1976,7 +1975,7 @@ vect_recog_average_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n   internal_fn ifn = IFN_AVG_FLOOR;\n   vect_unpromoted_value unprom[3];\n   tree new_type;\n-  unsigned int nops = vect_widened_op_tree (plus_stmt_info, PLUS_EXPR,\n+  unsigned int nops = vect_widened_op_tree (vinfo, plus_stmt_info, PLUS_EXPR,\n \t\t\t\t\t    PLUS_EXPR, false, 3,\n \t\t\t\t\t    unprom, &new_type);\n   if (nops == 0)\n@@ -2059,7 +2058,7 @@ vect_recog_average_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n \n   tree new_var = vect_recog_temp_ssa_var (new_type, NULL);\n   tree new_ops[2];\n-  vect_convert_inputs (last_stmt_info, 2, new_ops, new_type,\n+  vect_convert_inputs (vinfo, last_stmt_info, 2, new_ops, new_type,\n \t\t       unprom, new_vectype);\n \n   if (fallback_p)\n@@ -2079,28 +2078,28 @@ vect_recog_average_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n \n       tree shifted_op0 = vect_recog_temp_ssa_var (new_type, NULL);\n       g = gimple_build_assign (shifted_op0, RSHIFT_EXPR, new_ops[0], one_cst);\n-      append_pattern_def_seq (last_stmt_info, g, new_vectype);\n+      append_pattern_def_seq (vinfo, last_stmt_info, g, new_vectype);\n \n       tree shifted_op1 = vect_recog_temp_ssa_var (new_type, NULL);\n       g = gimple_build_assign (shifted_op1, RSHIFT_EXPR, new_ops[1], one_cst);\n-      append_pattern_def_seq (last_stmt_info, g, new_vectype);\n+      append_pattern_def_seq (vinfo, last_stmt_info, g, new_vectype);\n \n       tree sum_of_shifted = vect_recog_temp_ssa_var (new_type, NULL);\n       g = gimple_build_assign (sum_of_shifted, PLUS_EXPR,\n \t\t\t       shifted_op0, shifted_op1);\n-      append_pattern_def_seq (last_stmt_info, g, new_vectype);\n+      append_pattern_def_seq (vinfo, last_stmt_info, g, new_vectype);\n       \n       tree unmasked_carry = vect_recog_temp_ssa_var (new_type, NULL);\n       tree_code c = (ifn == IFN_AVG_CEIL) ? BIT_IOR_EXPR : BIT_AND_EXPR;\n       g = gimple_build_assign (unmasked_carry, c, new_ops[0], new_ops[1]);\n-      append_pattern_def_seq (last_stmt_info, g, new_vectype);\n+      append_pattern_def_seq (vinfo, last_stmt_info, g, new_vectype);\n  \n       tree carry = vect_recog_temp_ssa_var (new_type, NULL);\n       g = gimple_build_assign (carry, BIT_AND_EXPR, unmasked_carry, one_cst);\n-      append_pattern_def_seq (last_stmt_info, g, new_vectype);\n+      append_pattern_def_seq (vinfo, last_stmt_info, g, new_vectype);\n \n       g = gimple_build_assign (new_var, PLUS_EXPR, sum_of_shifted, carry);\n-      return vect_convert_output (last_stmt_info, type, g, new_vectype);\n+      return vect_convert_output (vinfo, last_stmt_info, type, g, new_vectype);\n     }\n \n   /* Generate the IFN_AVG* call.  */\n@@ -2113,7 +2112,8 @@ vect_recog_average_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n     dump_printf_loc (MSG_NOTE, vect_location,\n \t\t     \"created pattern stmt: %G\", average_stmt);\n \n-  return vect_convert_output (last_stmt_info, type, average_stmt, new_vectype);\n+  return vect_convert_output (vinfo, last_stmt_info,\n+\t\t\t      type, average_stmt, new_vectype);\n }\n \n /* Recognize cases in which the input to a cast is wider than its\n@@ -2136,7 +2136,8 @@ vect_recog_average_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n    input doesn't.  */\n \n static gimple *\n-vect_recog_cast_forwprop_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n+vect_recog_cast_forwprop_pattern (vec_info *vinfo,\n+\t\t\t\t  stmt_vec_info last_stmt_info, tree *type_out)\n {\n   /* Check for a cast, including an integer-to-float conversion.  */\n   gassign *last_stmt = dyn_cast <gassign *> (last_stmt_info->stmt);\n@@ -2165,7 +2166,6 @@ vect_recog_cast_forwprop_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n     return NULL;\n \n   /* Try to find an unpromoted input.  */\n-  vec_info *vinfo = last_stmt_info->vinfo;\n   vect_unpromoted_value unprom;\n   if (!vect_look_through_possible_promotion (vinfo, rhs, &unprom)\n       || TYPE_PRECISION (unprom.type) >= TYPE_PRECISION (rhs_type))\n@@ -2196,10 +2196,11 @@ vect_recog_cast_forwprop_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n    to WIDEN_LSHIFT_EXPR.  See vect_recog_widen_op_pattern for details.  */\n \n static gimple *\n-vect_recog_widen_shift_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n+vect_recog_widen_shift_pattern (vec_info *vinfo,\n+\t\t\t\tstmt_vec_info last_stmt_info, tree *type_out)\n {\n-  return vect_recog_widen_op_pattern (last_stmt_info, type_out, LSHIFT_EXPR,\n-\t\t\t\t      WIDEN_LSHIFT_EXPR, true,\n+  return vect_recog_widen_op_pattern (vinfo, last_stmt_info, type_out,\n+\t\t\t\t      LSHIFT_EXPR, WIDEN_LSHIFT_EXPR, true,\n \t\t\t\t      \"vect_recog_widen_shift_pattern\");\n }\n \n@@ -2231,13 +2232,13 @@ vect_recog_widen_shift_pattern (stmt_vec_info last_stmt_info, tree *type_out)\n     S0 stmt.  */\n \n static gimple *\n-vect_recog_rotate_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n+vect_recog_rotate_pattern (vec_info *vinfo,\n+\t\t\t   stmt_vec_info stmt_vinfo, tree *type_out)\n {\n   gimple *last_stmt = stmt_vinfo->stmt;\n   tree oprnd0, oprnd1, lhs, var, var1, var2, vectype, type, stype, def, def2;\n   gimple *pattern_stmt, *def_stmt;\n   enum tree_code rhs_code;\n-  vec_info *vinfo = stmt_vinfo->vinfo;\n   enum vect_def_type dt;\n   optab optab1, optab2;\n   edge ext_def = NULL;\n@@ -2315,7 +2316,7 @@ vect_recog_rotate_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \t\t{\n \t\t  def = vect_recog_temp_ssa_var (type, NULL);\n \t\t  def_stmt = gimple_build_assign (def, NOP_EXPR, oprnd0);\n-\t\t  append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t\t  append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \t\t  oprnd0 = def;\n \t\t}\n \n@@ -2375,7 +2376,7 @@ vect_recog_rotate_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \t    {\n \t      def = vect_recog_temp_ssa_var (type, NULL);\n \t      def_stmt = gimple_build_assign (def, NOP_EXPR, oprnd0);\n-\t      append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t      append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \t      oprnd0 = def;\n \t    }\n \n@@ -2428,7 +2429,7 @@ vect_recog_rotate_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n     {\n       def = vect_recog_temp_ssa_var (type, NULL);\n       def_stmt = gimple_build_assign (def, NOP_EXPR, oprnd0);\n-      append_pattern_def_seq (stmt_vinfo, def_stmt);\n+      append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n       oprnd0 = def;\n     }\n \n@@ -2452,7 +2453,7 @@ vect_recog_rotate_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n     {\n       def = vect_recog_temp_ssa_var (type, NULL);\n       def_stmt = gimple_build_assign (def, NOP_EXPR, oprnd1);\n-      append_pattern_def_seq (stmt_vinfo, def_stmt);\n+      append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n     }\n   stype = TREE_TYPE (def);\n   scalar_int_mode smode = SCALAR_INT_TYPE_MODE (stype);\n@@ -2481,7 +2482,7 @@ vect_recog_rotate_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \t  gcc_assert (!new_bb);\n \t}\n       else\n-\tappend_pattern_def_seq (stmt_vinfo, def_stmt, vecstype);\n+\tappend_pattern_def_seq (vinfo, stmt_vinfo, def_stmt, vecstype);\n \n       def2 = vect_recog_temp_ssa_var (stype, NULL);\n       tree mask = build_int_cst (stype, GET_MODE_PRECISION (smode) - 1);\n@@ -2494,20 +2495,20 @@ vect_recog_rotate_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \t  gcc_assert (!new_bb);\n \t}\n       else\n-\tappend_pattern_def_seq (stmt_vinfo, def_stmt, vecstype);\n+\tappend_pattern_def_seq (vinfo, stmt_vinfo, def_stmt, vecstype);\n     }\n \n   var1 = vect_recog_temp_ssa_var (type, NULL);\n   def_stmt = gimple_build_assign (var1, rhs_code == LROTATE_EXPR\n \t\t\t\t\t? LSHIFT_EXPR : RSHIFT_EXPR,\n \t\t\t\t  oprnd0, def);\n-  append_pattern_def_seq (stmt_vinfo, def_stmt);\n+  append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \n   var2 = vect_recog_temp_ssa_var (type, NULL);\n   def_stmt = gimple_build_assign (var2, rhs_code == LROTATE_EXPR\n \t\t\t\t\t? RSHIFT_EXPR : LSHIFT_EXPR,\n \t\t\t\t  oprnd0, def2);\n-  append_pattern_def_seq (stmt_vinfo, def_stmt);\n+  append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \n   /* Pattern detected.  */\n   vect_pattern_detected (\"vect_recog_rotate_pattern\", last_stmt);\n@@ -2558,14 +2559,14 @@ vect_recog_rotate_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n     S3 stmt.  */\n \n static gimple *\n-vect_recog_vector_vector_shift_pattern (stmt_vec_info stmt_vinfo,\n+vect_recog_vector_vector_shift_pattern (vec_info *vinfo,\n+\t\t\t\t\tstmt_vec_info stmt_vinfo,\n \t\t\t\t\ttree *type_out)\n {\n   gimple *last_stmt = stmt_vinfo->stmt;\n   tree oprnd0, oprnd1, lhs, var;\n   gimple *pattern_stmt;\n   enum tree_code rhs_code;\n-  vec_info *vinfo = stmt_vinfo->vinfo;\n \n   if (!is_gimple_assign (last_stmt))\n     return NULL;\n@@ -2622,7 +2623,7 @@ vect_recog_vector_vector_shift_pattern (stmt_vec_info stmt_vinfo,\n \t      def_stmt = gimple_build_assign (def, BIT_AND_EXPR, rhs1, mask);\n \t      tree vecstype = get_vectype_for_scalar_type (vinfo,\n \t\t\t\t\t\t\t   TREE_TYPE (rhs1));\n-\t      append_pattern_def_seq (stmt_vinfo, def_stmt, vecstype);\n+\t      append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt, vecstype);\n \t    }\n \t}\n     }\n@@ -2631,7 +2632,7 @@ vect_recog_vector_vector_shift_pattern (stmt_vec_info stmt_vinfo,\n     {\n       def = vect_recog_temp_ssa_var (TREE_TYPE (oprnd0), NULL);\n       def_stmt = gimple_build_assign (def, NOP_EXPR, oprnd1);\n-      append_pattern_def_seq (stmt_vinfo, def_stmt);\n+      append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n     }\n \n   /* Pattern detected.  */\n@@ -2715,8 +2716,9 @@ target_supports_mult_synth_alg (struct algorithm *alg, mult_variant var,\n    VINFO.  Return the last statement.  */\n \n static gimple *\n-synth_lshift_by_additions (tree dest, tree op, HOST_WIDE_INT amnt,\n-\t\t\t   stmt_vec_info vinfo)\n+synth_lshift_by_additions (vec_info *vinfo,\n+\t\t\t   tree dest, tree op, HOST_WIDE_INT amnt,\n+\t\t\t   stmt_vec_info stmt_info)\n {\n   HOST_WIDE_INT i;\n   tree itype = TREE_TYPE (op);\n@@ -2730,7 +2732,7 @@ synth_lshift_by_additions (tree dest, tree op, HOST_WIDE_INT amnt,\n         = gimple_build_assign (tmp_var, PLUS_EXPR, prev_res, prev_res);\n       prev_res = tmp_var;\n       if (i < amnt - 1)\n-\tappend_pattern_def_seq (vinfo, stmt);\n+\tappend_pattern_def_seq (vinfo, stmt_info, stmt);\n       else\n \treturn stmt;\n     }\n@@ -2746,7 +2748,8 @@ synth_lshift_by_additions (tree dest, tree op, HOST_WIDE_INT amnt,\n    left shifts using additions.  */\n \n static tree\n-apply_binop_and_append_stmt (tree_code code, tree op1, tree op2,\n+apply_binop_and_append_stmt (vec_info *vinfo,\n+\t\t\t     tree_code code, tree op1, tree op2,\n \t\t\t     stmt_vec_info stmt_vinfo, bool synth_shift_p)\n {\n   if (integer_zerop (op2)\n@@ -2764,14 +2767,14 @@ apply_binop_and_append_stmt (tree_code code, tree op1, tree op2,\n   if (code == LSHIFT_EXPR\n       && synth_shift_p)\n     {\n-      stmt = synth_lshift_by_additions (tmp_var, op1, TREE_INT_CST_LOW (op2),\n-\t\t\t\t\t stmt_vinfo);\n-      append_pattern_def_seq (stmt_vinfo, stmt);\n+      stmt = synth_lshift_by_additions (vinfo, tmp_var, op1,\n+\t\t\t\t\tTREE_INT_CST_LOW (op2), stmt_vinfo);\n+      append_pattern_def_seq (vinfo, stmt_vinfo, stmt);\n       return tmp_var;\n     }\n \n   stmt = gimple_build_assign (tmp_var, code, op1, op2);\n-  append_pattern_def_seq (stmt_vinfo, stmt);\n+  append_pattern_def_seq (vinfo, stmt_vinfo, stmt);\n   return tmp_var;\n }\n \n@@ -2783,10 +2786,9 @@ apply_binop_and_append_stmt (tree_code code, tree op1, tree op2,\n    works on tree-ssa form.  */\n \n static gimple *\n-vect_synth_mult_by_constant (tree op, tree val,\n+vect_synth_mult_by_constant (vec_info *vinfo, tree op, tree val,\n \t\t\t     stmt_vec_info stmt_vinfo)\n {\n-  vec_info *vinfo = stmt_vinfo->vinfo;\n   tree itype = TREE_TYPE (op);\n   machine_mode mode = TYPE_MODE (itype);\n   struct algorithm alg;\n@@ -2832,7 +2834,7 @@ vect_synth_mult_by_constant (tree op, tree val,\n     {\n       tree tmp_op = vect_recog_temp_ssa_var (multtype, NULL);\n       stmt = gimple_build_assign (tmp_op, CONVERT_EXPR, op);\n-      append_pattern_def_seq (stmt_vinfo, stmt);\n+      append_pattern_def_seq (vinfo, stmt_vinfo, stmt);\n       op = tmp_op;\n     }\n \n@@ -2855,23 +2857,23 @@ vect_synth_mult_by_constant (tree op, tree val,\n \tcase alg_shift:\n \t  if (synth_shift_p)\n \t    stmt\n-\t      = synth_lshift_by_additions (accum_tmp, accumulator, alg.log[i],\n-\t\t\t\t\t    stmt_vinfo);\n+\t      = synth_lshift_by_additions (vinfo, accum_tmp, accumulator,\n+\t\t\t\t\t   alg.log[i], stmt_vinfo);\n \t  else\n \t    stmt = gimple_build_assign (accum_tmp, LSHIFT_EXPR, accumulator,\n \t\t\t\t\t shft_log);\n \t  break;\n \tcase alg_add_t_m2:\n \t  tmp_var\n-\t    = apply_binop_and_append_stmt (LSHIFT_EXPR, op, shft_log,\n-\t\t\t\t\t    stmt_vinfo, synth_shift_p);\n+\t    = apply_binop_and_append_stmt (vinfo, LSHIFT_EXPR, op, shft_log,\n+\t\t\t\t\t   stmt_vinfo, synth_shift_p);\n \t  stmt = gimple_build_assign (accum_tmp, PLUS_EXPR, accumulator,\n \t\t\t\t       tmp_var);\n \t  break;\n \tcase alg_sub_t_m2:\n-\t  tmp_var = apply_binop_and_append_stmt (LSHIFT_EXPR, op,\n-\t\t\t\t\t\t  shft_log, stmt_vinfo,\n-\t\t\t\t\t\t  synth_shift_p);\n+\t  tmp_var = apply_binop_and_append_stmt (vinfo, LSHIFT_EXPR, op,\n+\t\t\t\t\t\t shft_log, stmt_vinfo,\n+\t\t\t\t\t\t synth_shift_p);\n \t  /* In some algorithms the first step involves zeroing the\n \t     accumulator.  If subtracting from such an accumulator\n \t     just emit the negation directly.  */\n@@ -2883,27 +2885,27 @@ vect_synth_mult_by_constant (tree op, tree val,\n \t  break;\n \tcase alg_add_t2_m:\n \t  tmp_var\n-\t    = apply_binop_and_append_stmt (LSHIFT_EXPR, accumulator, shft_log,\n-\t\t\t\t\t   stmt_vinfo, synth_shift_p);\n+\t    = apply_binop_and_append_stmt (vinfo, LSHIFT_EXPR, accumulator,\n+\t\t\t\t\t   shft_log, stmt_vinfo, synth_shift_p);\n \t  stmt = gimple_build_assign (accum_tmp, PLUS_EXPR, tmp_var, op);\n \t  break;\n \tcase alg_sub_t2_m:\n \t  tmp_var\n-\t    = apply_binop_and_append_stmt (LSHIFT_EXPR, accumulator, shft_log,\n-\t\t\t\t\t   stmt_vinfo, synth_shift_p);\n+\t    = apply_binop_and_append_stmt (vinfo, LSHIFT_EXPR, accumulator,\n+\t\t\t\t\t   shft_log, stmt_vinfo, synth_shift_p);\n \t  stmt = gimple_build_assign (accum_tmp, MINUS_EXPR, tmp_var, op);\n \t  break;\n \tcase alg_add_factor:\n \t  tmp_var\n-\t    = apply_binop_and_append_stmt (LSHIFT_EXPR, accumulator, shft_log,\n-\t\t\t\t\t    stmt_vinfo, synth_shift_p);\n+\t    = apply_binop_and_append_stmt (vinfo, LSHIFT_EXPR, accumulator,\n+\t\t\t\t\t   shft_log, stmt_vinfo, synth_shift_p);\n \t  stmt = gimple_build_assign (accum_tmp, PLUS_EXPR, accumulator,\n \t\t\t\t       tmp_var);\n \t  break;\n \tcase alg_sub_factor:\n \t  tmp_var\n-\t    = apply_binop_and_append_stmt (LSHIFT_EXPR, accumulator, shft_log,\n-\t\t\t\t\t   stmt_vinfo, synth_shift_p);\n+\t    = apply_binop_and_append_stmt (vinfo, LSHIFT_EXPR, accumulator,\n+\t\t\t\t\t   shft_log, stmt_vinfo, synth_shift_p);\n \t  stmt = gimple_build_assign (accum_tmp, MINUS_EXPR, tmp_var,\n \t\t\t\t      accumulator);\n \t  break;\n@@ -2914,7 +2916,7 @@ vect_synth_mult_by_constant (tree op, tree val,\n \t but rather return it directly.  */\n \n       if ((i < alg.ops - 1) || needs_fixup || cast_to_unsigned_p)\n-\tappend_pattern_def_seq (stmt_vinfo, stmt);\n+\tappend_pattern_def_seq (vinfo, stmt_vinfo, stmt);\n       accumulator = accum_tmp;\n     }\n   if (variant == negate_variant)\n@@ -2923,15 +2925,15 @@ vect_synth_mult_by_constant (tree op, tree val,\n       stmt = gimple_build_assign (accum_tmp, NEGATE_EXPR, accumulator);\n       accumulator = accum_tmp;\n       if (cast_to_unsigned_p)\n-\tappend_pattern_def_seq (stmt_vinfo, stmt);\n+\tappend_pattern_def_seq (vinfo, stmt_vinfo, stmt);\n     }\n   else if (variant == add_variant)\n     {\n       tree accum_tmp = vect_recog_temp_ssa_var (multtype, NULL);\n       stmt = gimple_build_assign (accum_tmp, PLUS_EXPR, accumulator, op);\n       accumulator = accum_tmp;\n       if (cast_to_unsigned_p)\n-\tappend_pattern_def_seq (stmt_vinfo, stmt);\n+\tappend_pattern_def_seq (vinfo, stmt_vinfo, stmt);\n     }\n   /* Move back to a signed if needed.  */\n   if (cast_to_unsigned_p)\n@@ -2960,9 +2962,9 @@ vect_synth_mult_by_constant (tree op, tree val,\n     the multiplication.  */\n \n static gimple *\n-vect_recog_mult_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n+vect_recog_mult_pattern (vec_info *vinfo,\n+\t\t\t stmt_vec_info stmt_vinfo, tree *type_out)\n {\n-  vec_info *vinfo = stmt_vinfo->vinfo;\n   gimple *last_stmt = stmt_vinfo->stmt;\n   tree oprnd0, oprnd1, vectype, itype;\n   gimple *pattern_stmt;\n@@ -2998,7 +3000,8 @@ vect_recog_mult_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n        return NULL;\n     }\n \n-  pattern_stmt = vect_synth_mult_by_constant (oprnd0, oprnd1, stmt_vinfo);\n+  pattern_stmt = vect_synth_mult_by_constant (vinfo,\n+\t\t\t\t\t      oprnd0, oprnd1, stmt_vinfo);\n   if (!pattern_stmt)\n     return NULL;\n \n@@ -3049,9 +3052,9 @@ vect_recog_mult_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n     S1 or modulo S4 stmt.  */\n \n static gimple *\n-vect_recog_divmod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n+vect_recog_divmod_pattern (vec_info *vinfo,\n+\t\t\t   stmt_vec_info stmt_vinfo, tree *type_out)\n {\n-  vec_info *vinfo = stmt_vinfo->vinfo;\n   gimple *last_stmt = stmt_vinfo->stmt;\n   tree oprnd0, oprnd1, vectype, itype, cond;\n   gimple *pattern_stmt, *def_stmt;\n@@ -3126,11 +3129,11 @@ vect_recog_divmod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \n \t  if (rhs_code == TRUNC_MOD_EXPR)\n \t    {\n-\t      append_pattern_def_seq (stmt_vinfo, div_stmt);\n+\t      append_pattern_def_seq (vinfo, stmt_vinfo, div_stmt);\n \t      def_stmt\n \t\t= gimple_build_assign (vect_recog_temp_ssa_var (itype, NULL),\n \t\t\t\t       LSHIFT_EXPR, var_div, shift);\n-\t      append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t      append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \t      pattern_stmt\n \t\t= gimple_build_assign (vect_recog_temp_ssa_var (itype, NULL),\n \t\t\t\t       MINUS_EXPR, oprnd0,\n@@ -3155,12 +3158,12 @@ vect_recog_divmod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \t\t\t\t   fold_build2 (MINUS_EXPR, itype, oprnd1,\n \t\t\t\t\t\tbuild_int_cst (itype, 1)),\n \t\t\t\t   build_int_cst (itype, 0));\n-\t  append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t  append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \t  var = vect_recog_temp_ssa_var (itype, NULL);\n \t  def_stmt\n \t    = gimple_build_assign (var, PLUS_EXPR, oprnd0,\n \t\t\t\t   gimple_assign_lhs (def_stmt));\n-\t  append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t  append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \n \t  shift = build_int_cst (itype, tree_log2 (oprnd1));\n \t  pattern_stmt\n@@ -3176,7 +3179,7 @@ vect_recog_divmod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \t      def_stmt = gimple_build_assign (signmask, COND_EXPR, cond,\n \t\t\t\t\t      build_int_cst (itype, 1),\n \t\t\t\t\t      build_int_cst (itype, 0));\n-\t      append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t      append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \t    }\n \t  else\n \t    {\n@@ -3191,27 +3194,27 @@ vect_recog_divmod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \t      def_stmt = gimple_build_assign (var, COND_EXPR, cond,\n \t\t\t\t\t      build_int_cst (utype, -1),\n \t\t\t\t\t      build_int_cst (utype, 0));\n-\t      append_pattern_def_seq (stmt_vinfo, def_stmt, vecutype);\n+\t      append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt, vecutype);\n \t      var = vect_recog_temp_ssa_var (utype, NULL);\n \t      def_stmt = gimple_build_assign (var, RSHIFT_EXPR,\n \t\t\t\t\t      gimple_assign_lhs (def_stmt),\n \t\t\t\t\t      shift);\n-\t      append_pattern_def_seq (stmt_vinfo, def_stmt, vecutype);\n+\t      append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt, vecutype);\n \t      signmask = vect_recog_temp_ssa_var (itype, NULL);\n \t      def_stmt\n \t\t= gimple_build_assign (signmask, NOP_EXPR, var);\n-\t      append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t      append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \t    }\n \t  def_stmt\n \t    = gimple_build_assign (vect_recog_temp_ssa_var (itype, NULL),\n \t\t\t\t   PLUS_EXPR, oprnd0, signmask);\n-\t  append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t  append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \t  def_stmt\n \t    = gimple_build_assign (vect_recog_temp_ssa_var (itype, NULL),\n \t\t\t\t   BIT_AND_EXPR, gimple_assign_lhs (def_stmt),\n \t\t\t\t   fold_build2 (MINUS_EXPR, itype, oprnd1,\n \t\t\t\t\t\tbuild_int_cst (itype, 1)));\n-\t  append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t  append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \n \t  pattern_stmt\n \t    = gimple_build_assign (vect_recog_temp_ssa_var (itype, NULL),\n@@ -3270,25 +3273,25 @@ vect_recog_divmod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \t  t1 = vect_recog_temp_ssa_var (itype, NULL);\n \t  def_stmt = gimple_build_assign (t1, MULT_HIGHPART_EXPR, oprnd0,\n \t\t\t\t\t  build_int_cst (itype, ml));\n-\t  append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t  append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \n \t  t2 = vect_recog_temp_ssa_var (itype, NULL);\n \t  def_stmt\n \t    = gimple_build_assign (t2, MINUS_EXPR, oprnd0, t1);\n-\t  append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t  append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \n \t  t3 = vect_recog_temp_ssa_var (itype, NULL);\n \t  def_stmt\n \t    = gimple_build_assign (t3, RSHIFT_EXPR, t2, integer_one_node);\n-\t  append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t  append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \n \t  t4 = vect_recog_temp_ssa_var (itype, NULL);\n \t  def_stmt\n \t    = gimple_build_assign (t4, PLUS_EXPR, t1, t3);\n \n \t  if (post_shift != 1)\n \t    {\n-\t      append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t      append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \n \t      q = vect_recog_temp_ssa_var (itype, NULL);\n \t      pattern_stmt\n@@ -3315,7 +3318,7 @@ vect_recog_divmod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \t      def_stmt\n \t\t= gimple_build_assign (t1, RSHIFT_EXPR, oprnd0,\n \t\t\t\t       build_int_cst (NULL, pre_shift));\n-\t      append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t      append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \t    }\n \t  else\n \t    t1 = oprnd0;\n@@ -3326,7 +3329,7 @@ vect_recog_divmod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \n \t  if (post_shift)\n \t    {\n-\t      append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t      append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \n \t      q = vect_recog_temp_ssa_var (itype, NULL);\n \t      def_stmt\n@@ -3387,7 +3390,7 @@ vect_recog_divmod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n       if (add)\n \t{\n \t  /* t2 = t1 + oprnd0;  */\n-\t  append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t  append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \t  t2 = vect_recog_temp_ssa_var (itype, NULL);\n \t  def_stmt = gimple_build_assign (t2, PLUS_EXPR, t1, oprnd0);\n \t}\n@@ -3397,7 +3400,7 @@ vect_recog_divmod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n       if (post_shift)\n \t{\n \t  /* t3 = t2 >> post_shift;  */\n-\t  append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t  append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \t  t3 = vect_recog_temp_ssa_var (itype, NULL);\n \t  def_stmt = gimple_build_assign (t3, RSHIFT_EXPR, t2,\n \t\t\t\t\t  build_int_cst (itype, post_shift));\n@@ -3428,15 +3431,15 @@ vect_recog_divmod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \t     t4 = 0;\n \t     or if we know from VRP that oprnd0 < 0\n \t     t4 = -1;  */\n-\t  append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t  append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \t  t4 = vect_recog_temp_ssa_var (itype, NULL);\n \t  if (msb != 1)\n \t    def_stmt = gimple_build_assign (t4, INTEGER_CST,\n \t\t\t\t\t    build_int_cst (itype, msb));\n \t  else\n \t    def_stmt = gimple_build_assign (t4, RSHIFT_EXPR, oprnd0,\n \t\t\t\t\t    build_int_cst (itype, prec - 1));\n-\t  append_pattern_def_seq (stmt_vinfo, def_stmt);\n+\t  append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \n \t  /* q = t3 - t4;  or q = t4 - t3;  */\n \t  q = vect_recog_temp_ssa_var (itype, NULL);\n@@ -3452,11 +3455,11 @@ vect_recog_divmod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n       /* We divided.  Now finish by:\n \t t1 = q * oprnd1;\n \t r = oprnd0 - t1;  */\n-      append_pattern_def_seq (stmt_vinfo, pattern_stmt);\n+      append_pattern_def_seq (vinfo, stmt_vinfo, pattern_stmt);\n \n       t1 = vect_recog_temp_ssa_var (itype, NULL);\n       def_stmt = gimple_build_assign (t1, MULT_EXPR, q, oprnd1);\n-      append_pattern_def_seq (stmt_vinfo, def_stmt);\n+      append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt);\n \n       r = vect_recog_temp_ssa_var (itype, NULL);\n       pattern_stmt = gimple_build_assign (r, MINUS_EXPR, oprnd0, t1);\n@@ -3498,9 +3501,9 @@ vect_recog_divmod_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \ta_T = (TYPE) a_it;  */\n \n static gimple *\n-vect_recog_mixed_size_cond_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n+vect_recog_mixed_size_cond_pattern (vec_info *vinfo,\n+\t\t\t\t    stmt_vec_info stmt_vinfo, tree *type_out)\n {\n-  vec_info *vinfo = stmt_vinfo->vinfo;\n   gimple *last_stmt = stmt_vinfo->stmt;\n   tree cond_expr, then_clause, else_clause;\n   tree type, vectype, comp_vectype, itype = NULL_TREE, vecitype;\n@@ -3536,11 +3539,11 @@ vect_recog_mixed_size_cond_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n     return NULL;\n \n   if ((TREE_CODE (then_clause) != INTEGER_CST\n-       && !type_conversion_p (then_clause, stmt_vinfo, false, &orig_type0,\n-\t\t\t      &def_stmt0, &promotion))\n+       && !type_conversion_p (vinfo, then_clause, false,\n+\t\t\t      &orig_type0, &def_stmt0, &promotion))\n       || (TREE_CODE (else_clause) != INTEGER_CST\n-\t  && !type_conversion_p (else_clause, stmt_vinfo, false, &orig_type1,\n-\t\t\t\t &def_stmt1, &promotion)))\n+\t  && !type_conversion_p (vinfo, else_clause, false,\n+\t\t\t\t &orig_type1, &def_stmt1, &promotion)))\n     return NULL;\n \n   if (orig_type0 && orig_type1\n@@ -3609,7 +3612,7 @@ vect_recog_mixed_size_cond_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n   pattern_stmt = gimple_build_assign (vect_recog_temp_ssa_var (type, NULL),\n \t\t\t\t      NOP_EXPR, gimple_assign_lhs (def_stmt));\n \n-  append_pattern_def_seq (stmt_vinfo, def_stmt, vecitype);\n+  append_pattern_def_seq (vinfo, stmt_vinfo, def_stmt, vecitype);\n   *type_out = vectype;\n \n   vect_pattern_detected (\"vect_recog_mixed_size_cond_pattern\", last_stmt);\n@@ -3722,12 +3725,12 @@ check_bool_pattern (tree var, vec_info *vinfo, hash_set<gimple *> &stmts)\n    pattern sequence.  */\n \n static tree\n-adjust_bool_pattern_cast (tree type, tree var, stmt_vec_info stmt_info)\n+adjust_bool_pattern_cast (vec_info *vinfo,\n+\t\t\t  tree type, tree var, stmt_vec_info stmt_info)\n {\n-  vec_info *vinfo = stmt_info->vinfo;\n   gimple *cast_stmt = gimple_build_assign (vect_recog_temp_ssa_var (type, NULL),\n \t\t\t\t\t   NOP_EXPR, var);\n-  append_pattern_def_seq (stmt_info, cast_stmt,\n+  append_pattern_def_seq (vinfo, stmt_info, cast_stmt,\n \t\t\t  get_vectype_for_scalar_type (vinfo, type));\n   return gimple_assign_lhs (cast_stmt);\n }\n@@ -3739,10 +3742,9 @@ adjust_bool_pattern_cast (tree type, tree var, stmt_vec_info stmt_info)\n    be associated with.  DEFS is a map of pattern defs.  */\n \n static void\n-adjust_bool_pattern (tree var, tree out_type,\n+adjust_bool_pattern (vec_info *vinfo, tree var, tree out_type,\n \t\t     stmt_vec_info stmt_info, hash_map <tree, tree> &defs)\n {\n-  vec_info *vinfo = stmt_info->vinfo;\n   gimple *stmt = SSA_NAME_DEF_STMT (var);\n   enum tree_code rhs_code, def_rhs_code;\n   tree itype, cond_expr, rhs1, rhs2, irhs1, irhs2;\n@@ -3858,15 +3860,17 @@ adjust_bool_pattern (tree var, tree out_type,\n \t  int prec2 = TYPE_PRECISION (TREE_TYPE (irhs2));\n \t  int out_prec = TYPE_PRECISION (out_type);\n \t  if (absu_hwi (out_prec - prec1) < absu_hwi (out_prec - prec2))\n-\t    irhs2 = adjust_bool_pattern_cast (TREE_TYPE (irhs1), irhs2,\n+\t    irhs2 = adjust_bool_pattern_cast (vinfo, TREE_TYPE (irhs1), irhs2,\n \t\t\t\t\t      stmt_info);\n \t  else if (absu_hwi (out_prec - prec1) > absu_hwi (out_prec - prec2))\n-\t    irhs1 = adjust_bool_pattern_cast (TREE_TYPE (irhs2), irhs1,\n+\t    irhs1 = adjust_bool_pattern_cast (vinfo, TREE_TYPE (irhs2), irhs1,\n \t\t\t\t\t      stmt_info);\n \t  else\n \t    {\n-\t      irhs1 = adjust_bool_pattern_cast (out_type, irhs1, stmt_info);\n-\t      irhs2 = adjust_bool_pattern_cast (out_type, irhs2, stmt_info);\n+\t      irhs1 = adjust_bool_pattern_cast (vinfo,\n+\t\t\t\t\t\tout_type, irhs1, stmt_info);\n+\t      irhs2 = adjust_bool_pattern_cast (vinfo,\n+\t\t\t\t\t\tout_type, irhs2, stmt_info);\n \t    }\n \t}\n       itype = TREE_TYPE (irhs1);\n@@ -3903,7 +3907,7 @@ adjust_bool_pattern (tree var, tree out_type,\n     }\n \n   gimple_set_location (pattern_stmt, loc);\n-  append_pattern_def_seq (stmt_info, pattern_stmt,\n+  append_pattern_def_seq (vinfo, stmt_info, pattern_stmt,\n \t\t\t  get_vectype_for_scalar_type (vinfo, itype));\n   defs.put (var, gimple_assign_lhs (pattern_stmt));\n }\n@@ -3923,7 +3927,7 @@ sort_after_uid (const void *p1, const void *p2)\n    OUT_TYPE.  Return the def of the pattern root.  */\n \n static tree\n-adjust_bool_stmts (hash_set <gimple *> &bool_stmt_set,\n+adjust_bool_stmts (vec_info *vinfo, hash_set <gimple *> &bool_stmt_set,\n \t\t   tree out_type, stmt_vec_info stmt_info)\n {\n   /* Gather original stmts in the bool pattern in their order of appearance\n@@ -3937,7 +3941,7 @@ adjust_bool_stmts (hash_set <gimple *> &bool_stmt_set,\n   /* Now process them in that order, producing pattern stmts.  */\n   hash_map <tree, tree> defs;\n   for (unsigned i = 0; i < bool_stmts.length (); ++i)\n-    adjust_bool_pattern (gimple_assign_lhs (bool_stmts[i]),\n+    adjust_bool_pattern (vinfo, gimple_assign_lhs (bool_stmts[i]),\n \t\t\t out_type, stmt_info, defs);\n \n   /* Pop the last pattern seq stmt and install it as pattern root for STMT.  */\n@@ -4012,12 +4016,12 @@ integer_type_for_mask (tree var, vec_info *vinfo)\n \tbut the above is more efficient.  */\n \n static gimple *\n-vect_recog_bool_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n+vect_recog_bool_pattern (vec_info *vinfo,\n+\t\t\t stmt_vec_info stmt_vinfo, tree *type_out)\n {\n   gimple *last_stmt = stmt_vinfo->stmt;\n   enum tree_code rhs_code;\n   tree var, lhs, rhs, vectype;\n-  vec_info *vinfo = stmt_vinfo->vinfo;\n   gimple *pattern_stmt;\n \n   if (!is_gimple_assign (last_stmt))\n@@ -4043,7 +4047,8 @@ vect_recog_bool_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \n       if (check_bool_pattern (var, vinfo, bool_stmts))\n \t{\n-\t  rhs = adjust_bool_stmts (bool_stmts, TREE_TYPE (lhs), stmt_vinfo);\n+\t  rhs = adjust_bool_stmts (vinfo, bool_stmts,\n+\t\t\t\t   TREE_TYPE (lhs), stmt_vinfo);\n \t  lhs = vect_recog_temp_ssa_var (TREE_TYPE (lhs), NULL);\n \t  if (useless_type_conversion_p (TREE_TYPE (lhs), TREE_TYPE (rhs)))\n \t    pattern_stmt = gimple_build_assign (lhs, SSA_NAME, rhs);\n@@ -4075,7 +4080,8 @@ vect_recog_bool_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \t  if (!useless_type_conversion_p (type, TREE_TYPE (lhs)))\n \t    {\n \t      tree new_vectype = get_vectype_for_scalar_type (vinfo, type);\n-\t      append_pattern_def_seq (stmt_vinfo, pattern_stmt, new_vectype);\n+\t      append_pattern_def_seq (vinfo, stmt_vinfo,\n+\t\t\t\t      pattern_stmt, new_vectype);\n \n \t      lhs = vect_recog_temp_ssa_var (TREE_TYPE (lhs), NULL);\n \t      pattern_stmt = gimple_build_assign (lhs, CONVERT_EXPR, tmp);\n@@ -4110,7 +4116,7 @@ vect_recog_bool_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n       if (!check_bool_pattern (var, vinfo, bool_stmts))\n \treturn NULL;\n \n-      rhs = adjust_bool_stmts (bool_stmts, type, stmt_vinfo);\n+      rhs = adjust_bool_stmts (vinfo, bool_stmts, type, stmt_vinfo);\n \n       lhs = vect_recog_temp_ssa_var (TREE_TYPE (lhs), NULL);\n       pattern_stmt \n@@ -4129,13 +4135,14 @@ vect_recog_bool_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n     {\n       stmt_vec_info pattern_stmt_info;\n       tree nunits_vectype;\n-      if (!vect_get_vector_types_for_stmt (stmt_vinfo, &vectype,\n+      if (!vect_get_vector_types_for_stmt (vinfo, stmt_vinfo, &vectype,\n \t\t\t\t\t   &nunits_vectype)\n \t  || !VECTOR_MODE_P (TYPE_MODE (vectype)))\n \treturn NULL;\n \n       if (check_bool_pattern (var, vinfo, bool_stmts))\n-\trhs = adjust_bool_stmts (bool_stmts, TREE_TYPE (vectype), stmt_vinfo);\n+\trhs = adjust_bool_stmts (vinfo, bool_stmts,\n+\t\t\t\t TREE_TYPE (vectype), stmt_vinfo);\n       else\n \t{\n \t  tree type = integer_type_for_mask (var, vinfo);\n@@ -4153,15 +4160,15 @@ vect_recog_bool_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \n \t  rhs = vect_recog_temp_ssa_var (type, NULL);\n \t  pattern_stmt = gimple_build_assign (rhs, COND_EXPR, var, cst1, cst0);\n-\t  append_pattern_def_seq (stmt_vinfo, pattern_stmt, new_vectype);\n+\t  append_pattern_def_seq (vinfo, stmt_vinfo, pattern_stmt, new_vectype);\n \t}\n \n       lhs = build1 (VIEW_CONVERT_EXPR, TREE_TYPE (vectype), lhs);\n       if (!useless_type_conversion_p (TREE_TYPE (lhs), TREE_TYPE (rhs)))\n \t{\n \t  tree rhs2 = vect_recog_temp_ssa_var (TREE_TYPE (lhs), NULL);\n \t  gimple *cast_stmt = gimple_build_assign (rhs2, NOP_EXPR, rhs);\n-\t  append_pattern_def_seq (stmt_vinfo, cast_stmt);\n+\t  append_pattern_def_seq (vinfo, stmt_vinfo, cast_stmt);\n \t  rhs = rhs2;\n \t}\n       pattern_stmt = gimple_build_assign (lhs, SSA_NAME, rhs);\n@@ -4185,15 +4192,17 @@ vect_recog_bool_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n    Return converted mask.  */\n \n static tree\n-build_mask_conversion (tree mask, tree vectype, stmt_vec_info stmt_vinfo)\n+build_mask_conversion (vec_info *vinfo,\n+\t\t       tree mask, tree vectype, stmt_vec_info stmt_vinfo)\n {\n   gimple *stmt;\n   tree masktype, tmp;\n \n   masktype = truth_type_for (vectype);\n   tmp = vect_recog_temp_ssa_var (TREE_TYPE (masktype), NULL);\n   stmt = gimple_build_assign (tmp, CONVERT_EXPR, mask);\n-  append_pattern_def_seq (stmt_vinfo, stmt, masktype, TREE_TYPE (vectype));\n+  append_pattern_def_seq (vinfo, stmt_vinfo,\n+\t\t\t  stmt, masktype, TREE_TYPE (vectype));\n \n   return tmp;\n }\n@@ -4225,14 +4234,14 @@ build_mask_conversion (tree mask, tree vectype, stmt_vec_info stmt_vinfo)\n    S4'  c_1' = m_3'' ? c_2 : c_3;  */\n \n static gimple *\n-vect_recog_mask_conversion_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n+vect_recog_mask_conversion_pattern (vec_info *vinfo,\n+\t\t\t\t    stmt_vec_info stmt_vinfo, tree *type_out)\n {\n   gimple *last_stmt = stmt_vinfo->stmt;\n   enum tree_code rhs_code;\n   tree lhs = NULL_TREE, rhs1, rhs2, tmp, rhs1_type, rhs2_type;\n   tree vectype1, vectype2;\n   stmt_vec_info pattern_stmt_info;\n-  vec_info *vinfo = stmt_vinfo->vinfo;\n \n   /* Check for MASK_LOAD ans MASK_STORE calls requiring mask conversion.  */\n   if (is_gimple_call (last_stmt)\n@@ -4269,7 +4278,7 @@ vect_recog_mask_conversion_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \t\t       TYPE_VECTOR_SUBPARTS (vectype2)))\n \treturn NULL;\n \n-      tmp = build_mask_conversion (mask_arg, vectype1, stmt_vinfo);\n+      tmp = build_mask_conversion (vinfo, mask_arg, vectype1, stmt_vinfo);\n \n       auto_vec<tree, 8> args;\n       unsigned int nargs = gimple_call_num_args (last_stmt);\n@@ -4388,13 +4397,13 @@ vect_recog_mask_conversion_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n \t  tmp = vect_recog_temp_ssa_var (TREE_TYPE (rhs1), NULL);\n \t  pattern_stmt = gimple_build_assign (tmp, rhs1);\n \t  rhs1 = tmp;\n-\t  append_pattern_def_seq (stmt_vinfo, pattern_stmt, vectype2,\n+\t  append_pattern_def_seq (vinfo, stmt_vinfo, pattern_stmt, vectype2,\n \t\t\t\t  rhs1_type);\n \t}\n \n       if (maybe_ne (TYPE_VECTOR_SUBPARTS (vectype1),\n \t\t    TYPE_VECTOR_SUBPARTS (vectype2)))\n-\ttmp = build_mask_conversion (rhs1, vectype1, stmt_vinfo);\n+\ttmp = build_mask_conversion (vinfo, rhs1, vectype1, stmt_vinfo);\n       else\n \ttmp = rhs1;\n \n@@ -4434,14 +4443,14 @@ vect_recog_mask_conversion_pattern (stmt_vec_info stmt_vinfo, tree *type_out)\n       vectype1 = get_mask_type_for_scalar_type (vinfo, rhs1_type);\n       if (!vectype1)\n \treturn NULL;\n-      rhs2 = build_mask_conversion (rhs2, vectype1, stmt_vinfo);\n+      rhs2 = build_mask_conversion (vinfo, rhs2, vectype1, stmt_vinfo);\n     }\n   else\n     {\n       vectype1 = get_mask_type_for_scalar_type (vinfo, rhs2_type);\n       if (!vectype1)\n \treturn NULL;\n-      rhs1 = build_mask_conversion (rhs1, vectype1, stmt_vinfo);\n+      rhs1 = build_mask_conversion (vinfo, rhs1, vectype1, stmt_vinfo);\n     }\n \n   lhs = vect_recog_temp_ssa_var (TREE_TYPE (lhs), NULL);\n@@ -4491,7 +4500,7 @@ vect_convert_mask_for_vectype (tree mask, tree vectype,\n       if (mask_vectype\n \t  && maybe_ne (TYPE_VECTOR_SUBPARTS (vectype),\n \t\t       TYPE_VECTOR_SUBPARTS (mask_vectype)))\n-\tmask = build_mask_conversion (mask, vectype, stmt_info);\n+\tmask = build_mask_conversion (vinfo, mask, vectype, stmt_info);\n     }\n   return mask;\n }\n@@ -4505,15 +4514,15 @@ vect_convert_mask_for_vectype (tree mask, tree vectype,\n    to STMT_INFO.  */\n \n static tree\n-vect_add_conversion_to_pattern (tree type, tree value, stmt_vec_info stmt_info)\n+vect_add_conversion_to_pattern (vec_info *vinfo,\n+\t\t\t\ttree type, tree value, stmt_vec_info stmt_info)\n {\n   if (useless_type_conversion_p (type, TREE_TYPE (value)))\n     return value;\n \n-  vec_info *vinfo = stmt_info->vinfo;\n   tree new_value = vect_recog_temp_ssa_var (type, NULL);\n   gassign *conversion = gimple_build_assign (new_value, CONVERT_EXPR, value);\n-  append_pattern_def_seq (stmt_info, conversion,\n+  append_pattern_def_seq (vinfo, stmt_info, conversion,\n \t\t\t  get_vectype_for_scalar_type (vinfo, type));\n   return new_value;\n }\n@@ -4526,10 +4535,11 @@ vect_add_conversion_to_pattern (tree type, tree value, stmt_vec_info stmt_info)\n    as such from the outset (indicated by STMT_VINFO_GATHER_SCATTER_P).  */\n \n static gimple *\n-vect_recog_gather_scatter_pattern (stmt_vec_info stmt_info, tree *type_out)\n+vect_recog_gather_scatter_pattern (vec_info *vinfo,\n+\t\t\t\t   stmt_vec_info stmt_info, tree *type_out)\n {\n   /* Currently we only support this for loop vectorization.  */\n-  loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (stmt_info->vinfo);\n+  loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (vinfo);\n   if (!loop_vinfo)\n     return NULL;\n \n@@ -4560,8 +4570,8 @@ vect_recog_gather_scatter_pattern (stmt_vec_info stmt_info, tree *type_out)\n      latter to the same width as the vector elements.  */\n   tree base = gs_info.base;\n   tree offset_type = TREE_TYPE (gs_info.offset_vectype);\n-  tree offset = vect_add_conversion_to_pattern (offset_type, gs_info.offset,\n-\t\t\t\t\t\tstmt_info);\n+  tree offset = vect_add_conversion_to_pattern (vinfo, offset_type,\n+\t\t\t\t\t\tgs_info.offset, stmt_info);\n \n   /* Build the new pattern statement.  */\n   tree scale = size_int (gs_info.scale);\n@@ -4705,10 +4715,10 @@ vect_set_min_input_precision (stmt_vec_info stmt_info, tree type,\n    whose result is LHS.  */\n \n static bool\n-vect_determine_min_output_precision_1 (stmt_vec_info stmt_info, tree lhs)\n+vect_determine_min_output_precision_1 (vec_info *vinfo,\n+\t\t\t\t       stmt_vec_info stmt_info, tree lhs)\n {\n   /* Take the maximum precision required by users of the result.  */\n-  vec_info *vinfo = stmt_info->vinfo;\n   unsigned int precision = 0;\n   imm_use_iterator iter;\n   use_operand_p use;\n@@ -4742,7 +4752,7 @@ vect_determine_min_output_precision_1 (stmt_vec_info stmt_info, tree lhs)\n /* Calculate min_output_precision for STMT_INFO.  */\n \n static void\n-vect_determine_min_output_precision (stmt_vec_info stmt_info)\n+vect_determine_min_output_precision (vec_info *vinfo, stmt_vec_info stmt_info)\n {\n   /* We're only interested in statements with a narrowable result.  */\n   tree lhs = gimple_get_lhs (stmt_info->stmt);\n@@ -4751,7 +4761,7 @@ vect_determine_min_output_precision (stmt_vec_info stmt_info)\n       || !vect_narrowable_type_p (TREE_TYPE (lhs)))\n     return;\n \n-  if (!vect_determine_min_output_precision_1 (stmt_info, lhs))\n+  if (!vect_determine_min_output_precision_1 (vinfo, stmt_info, lhs))\n     stmt_info->min_output_precision = TYPE_PRECISION (TREE_TYPE (lhs));\n }\n \n@@ -4962,10 +4972,8 @@ possible_vector_mask_operation_p (stmt_vec_info stmt_info)\n    result in STMT_INFO->mask_precision.  */\n \n static void\n-vect_determine_mask_precision (stmt_vec_info stmt_info)\n+vect_determine_mask_precision (vec_info *vinfo, stmt_vec_info stmt_info)\n {\n-  vec_info *vinfo = stmt_info->vinfo;\n-\n   if (!possible_vector_mask_operation_p (stmt_info)\n       || stmt_info->mask_precision)\n     return;\n@@ -5070,15 +5078,15 @@ vect_determine_mask_precision (stmt_vec_info stmt_info)\n    have already done so for the users of its result.  */\n \n void\n-vect_determine_stmt_precisions (stmt_vec_info stmt_info)\n+vect_determine_stmt_precisions (vec_info *vinfo, stmt_vec_info stmt_info)\n {\n-  vect_determine_min_output_precision (stmt_info);\n+  vect_determine_min_output_precision (vinfo, stmt_info);\n   if (gassign *stmt = dyn_cast <gassign *> (stmt_info->stmt))\n     {\n       vect_determine_precisions_from_range (stmt_info, stmt);\n       vect_determine_precisions_from_users (stmt_info, stmt);\n     }\n-  vect_determine_mask_precision (stmt_info);\n+  vect_determine_mask_precision (vinfo, stmt_info);\n }\n \n /* Walk backwards through the vectorizable region to determine the\n@@ -5106,7 +5114,7 @@ vect_determine_precisions (vec_info *vinfo)\n \t  for (gimple_stmt_iterator si = gsi_last_bb (bb);\n \t       !gsi_end_p (si); gsi_prev (&si))\n \t    vect_determine_stmt_precisions\n-\t      (vinfo->lookup_stmt (gsi_stmt (si)));\n+\t      (vinfo, vinfo->lookup_stmt (gsi_stmt (si)));\n \t}\n     }\n   else\n@@ -5123,13 +5131,13 @@ vect_determine_precisions (vec_info *vinfo)\n \t  stmt = gsi_stmt (si);\n \t  stmt_vec_info stmt_info = vinfo->lookup_stmt (stmt);\n \t  if (stmt_info && STMT_VINFO_VECTORIZABLE (stmt_info))\n-\t    vect_determine_stmt_precisions (stmt_info);\n+\t    vect_determine_stmt_precisions (vinfo, stmt_info);\n \t}\n       while (stmt != gsi_stmt (bb_vinfo->region_begin));\n     }\n }\n \n-typedef gimple *(*vect_recog_func_ptr) (stmt_vec_info, tree *);\n+typedef gimple *(*vect_recog_func_ptr) (vec_info *, stmt_vec_info, tree *);\n \n struct vect_recog_func\n {\n@@ -5171,7 +5179,8 @@ const unsigned int NUM_PATTERNS = ARRAY_SIZE (vect_vect_recog_func_ptrs);\n /* Mark statements that are involved in a pattern.  */\n \n static inline void\n-vect_mark_pattern_stmts (stmt_vec_info orig_stmt_info, gimple *pattern_stmt,\n+vect_mark_pattern_stmts (vec_info *vinfo,\n+\t\t\t stmt_vec_info orig_stmt_info, gimple *pattern_stmt,\n                          tree pattern_vectype)\n {\n   stmt_vec_info orig_stmt_info_saved = orig_stmt_info;\n@@ -5213,7 +5222,7 @@ vect_mark_pattern_stmts (stmt_vec_info orig_stmt_info, gimple *pattern_stmt,\n \t  dump_printf_loc (MSG_NOTE, vect_location,\n \t\t\t   \"extra pattern stmt: %G\", gsi_stmt (si));\n \tstmt_vec_info pattern_stmt_info\n-\t  = vect_init_pattern_stmt (gsi_stmt (si),\n+\t  = vect_init_pattern_stmt (vinfo, gsi_stmt (si),\n \t\t\t\t    orig_stmt_info, pattern_vectype);\n \t/* Stmts in the def sequence are not vectorizable cycle or\n \t   induction defs, instead they should all be vect_internal_def\n@@ -5223,7 +5232,8 @@ vect_mark_pattern_stmts (stmt_vec_info orig_stmt_info, gimple *pattern_stmt,\n \n   if (orig_pattern_stmt)\n     {\n-      vect_init_pattern_stmt (pattern_stmt, orig_stmt_info, pattern_vectype);\n+      vect_init_pattern_stmt (vinfo, pattern_stmt,\n+\t\t\t      orig_stmt_info, pattern_vectype);\n \n       /* Insert all the new pattern statements before the original one.  */\n       gimple_seq *orig_def_seq = &STMT_VINFO_PATTERN_DEF_SEQ (orig_stmt_info);\n@@ -5236,12 +5246,12 @@ vect_mark_pattern_stmts (stmt_vec_info orig_stmt_info, gimple *pattern_stmt,\n       gsi_remove (&gsi, false);\n     }\n   else\n-    vect_set_pattern_stmt (pattern_stmt, orig_stmt_info, pattern_vectype);\n+    vect_set_pattern_stmt (vinfo,\n+\t\t\t   pattern_stmt, orig_stmt_info, pattern_vectype);\n \n   /* Transfer reduction path info to the pattern.  */\n   if (STMT_VINFO_REDUC_IDX (orig_stmt_info_saved) != -1)\n     {\n-      vec_info *vinfo = orig_stmt_info_saved->vinfo;\n       tree lookfor = gimple_op (orig_stmt_info_saved->stmt,\n \t\t\t\t1 + STMT_VINFO_REDUC_IDX (orig_stmt_info));\n       /* Search the pattern def sequence and the main pattern stmt.  Note\n@@ -5312,9 +5322,9 @@ vect_mark_pattern_stmts (stmt_vec_info orig_stmt_info, gimple *pattern_stmt,\n    for vect_recog_pattern.  */\n \n static void\n-vect_pattern_recog_1 (vect_recog_func *recog_func, stmt_vec_info stmt_info)\n+vect_pattern_recog_1 (vec_info *vinfo,\n+\t\t      vect_recog_func *recog_func, stmt_vec_info stmt_info)\n {\n-  vec_info *vinfo = stmt_info->vinfo;\n   gimple *pattern_stmt;\n   loop_vec_info loop_vinfo;\n   tree pattern_vectype;\n@@ -5328,20 +5338,21 @@ vect_pattern_recog_1 (vect_recog_func *recog_func, stmt_vec_info stmt_info)\n       gimple_stmt_iterator gsi;\n       for (gsi = gsi_start (STMT_VINFO_PATTERN_DEF_SEQ (stmt_info));\n \t   !gsi_end_p (gsi); gsi_next (&gsi))\n-\tvect_pattern_recog_1 (recog_func, vinfo->lookup_stmt (gsi_stmt (gsi)));\n+\tvect_pattern_recog_1 (vinfo, recog_func,\n+\t\t\t      vinfo->lookup_stmt (gsi_stmt (gsi)));\n       return;\n     }\n \n   gcc_assert (!STMT_VINFO_PATTERN_DEF_SEQ (stmt_info));\n-  pattern_stmt = recog_func->fn (stmt_info, &pattern_vectype);\n+  pattern_stmt = recog_func->fn (vinfo, stmt_info, &pattern_vectype);\n   if (!pattern_stmt)\n     {\n       /* Clear any half-formed pattern definition sequence.  */\n       STMT_VINFO_PATTERN_DEF_SEQ (stmt_info) = NULL;\n       return;\n     }\n \n-  loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n+  loop_vinfo = dyn_cast <loop_vec_info> (vinfo);\n   gcc_assert (pattern_vectype);\n  \n   /* Found a vectorizable pattern.  */\n@@ -5351,7 +5362,7 @@ vect_pattern_recog_1 (vect_recog_func *recog_func, stmt_vec_info stmt_info)\n \t\t     recog_func->name, pattern_stmt);\n \n   /* Mark the stmts that are involved in the pattern. */\n-  vect_mark_pattern_stmts (stmt_info, pattern_stmt, pattern_vectype);\n+  vect_mark_pattern_stmts (vinfo, stmt_info, pattern_stmt, pattern_vectype);\n \n   /* Patterns cannot be vectorized using SLP, because they change the order of\n      computation.  */\n@@ -5471,7 +5482,7 @@ vect_pattern_recog (vec_info *vinfo)\n \t      stmt_vec_info stmt_info = vinfo->lookup_stmt (gsi_stmt (si));\n \t      /* Scan over all generic vect_recog_xxx_pattern functions.  */\n \t      for (j = 0; j < NUM_PATTERNS; j++)\n-\t\tvect_pattern_recog_1 (&vect_vect_recog_func_ptrs[j],\n+\t\tvect_pattern_recog_1 (vinfo, &vect_vect_recog_func_ptrs[j],\n \t\t\t\t      stmt_info);\n \t    }\n \t}\n@@ -5489,7 +5500,8 @@ vect_pattern_recog (vec_info *vinfo)\n \n \t  /* Scan over all generic vect_recog_xxx_pattern functions.  */\n \t  for (j = 0; j < NUM_PATTERNS; j++)\n-\t    vect_pattern_recog_1 (&vect_vect_recog_func_ptrs[j], stmt_info);\n+\t    vect_pattern_recog_1 (vinfo,\n+\t\t\t\t  &vect_vect_recog_func_ptrs[j], stmt_info);\n \t}\n     }\n }"}, {"sha": "45cf491ddd9da18004c7c1fd90caf78d5c3d2c92", "filename": "gcc/tree-vect-slp.c", "status": "modified", "additions": 70, "deletions": 62, "changes": 132, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vect-slp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vect-slp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-slp.c?ref=308bc496884706af4b3077171cbac684c7a6f7c6", "patch": "@@ -627,10 +627,10 @@ vect_update_shared_vectype (stmt_vec_info stmt_info, tree vectype)\n    Used only for BB vectorization.  */\n \n static bool\n-vect_update_all_shared_vectypes (vec<stmt_vec_info> stmts)\n+vect_update_all_shared_vectypes (vec_info *vinfo, vec<stmt_vec_info> stmts)\n {\n   tree vectype, nunits_vectype;\n-  if (!vect_get_vector_types_for_stmt (stmts[0], &vectype,\n+  if (!vect_get_vector_types_for_stmt (vinfo, stmts[0], &vectype,\n \t\t\t\t       &nunits_vectype, stmts.length ()))\n     return false;\n \n@@ -686,7 +686,8 @@ compatible_calls_p (gcall *call1, gcall *call2)\n    vect_build_slp_tree.  */\n \n static bool\n-vect_record_max_nunits (stmt_vec_info stmt_info, unsigned int group_size,\n+vect_record_max_nunits (vec_info *vinfo, stmt_vec_info stmt_info,\n+\t\t\tunsigned int group_size,\n \t\t\ttree vectype, poly_uint64 *max_nunits)\n {\n   if (!vectype)\n@@ -703,7 +704,7 @@ vect_record_max_nunits (stmt_vec_info stmt_info, unsigned int group_size,\n      before adjusting *max_nunits for basic-block vectorization.  */\n   poly_uint64 nunits = TYPE_VECTOR_SUBPARTS (vectype);\n   unsigned HOST_WIDE_INT const_nunits;\n-  if (STMT_VINFO_BB_VINFO (stmt_info)\n+  if (is_a <bb_vec_info> (vinfo)\n       && (!nunits.is_constant (&const_nunits)\n \t  || const_nunits > group_size))\n     {\n@@ -764,7 +765,7 @@ vect_two_operations_perm_ok_p (vec<stmt_vec_info> stmts,\n    to (B1 <= A1 ? X1 : Y1); or be inverted to (A1 < B1) ? Y1 : X1.  */\n \n static bool\n-vect_build_slp_tree_1 (unsigned char *swap,\n+vect_build_slp_tree_1 (vec_info *vinfo, unsigned char *swap,\n \t\t       vec<stmt_vec_info> stmts, unsigned int group_size,\n \t\t       poly_uint64 *max_nunits, bool *matches,\n \t\t       bool *two_operators)\n@@ -789,7 +790,6 @@ vect_build_slp_tree_1 (unsigned char *swap,\n   stmt_vec_info stmt_info;\n   FOR_EACH_VEC_ELT (stmts, i, stmt_info)\n     {\n-      vec_info *vinfo = stmt_info->vinfo;\n       gimple *stmt = stmt_info->stmt;\n       swap[i] = 0;\n       matches[i] = false;\n@@ -822,10 +822,10 @@ vect_build_slp_tree_1 (unsigned char *swap,\n \t}\n \n       tree nunits_vectype;\n-      if (!vect_get_vector_types_for_stmt (stmt_info, &vectype,\n+      if (!vect_get_vector_types_for_stmt (vinfo, stmt_info, &vectype,\n \t\t\t\t\t   &nunits_vectype, group_size)\n \t  || (nunits_vectype\n-\t      && !vect_record_max_nunits (stmt_info, group_size,\n+\t      && !vect_record_max_nunits (vinfo, stmt_info, group_size,\n \t\t\t\t\t  nunits_vectype, max_nunits)))\n \t{\n \t  /* Fatal mismatch.  */\n@@ -1256,7 +1256,8 @@ vect_build_slp_tree_2 (vec_info *vinfo,\n     {\n       tree scalar_type = TREE_TYPE (PHI_RESULT (stmt));\n       tree vectype = get_vectype_for_scalar_type (vinfo, scalar_type);\n-      if (!vect_record_max_nunits (stmt_info, group_size, vectype, max_nunits))\n+      if (!vect_record_max_nunits (vinfo, stmt_info, group_size, vectype,\n+\t\t\t\t   max_nunits))\n \treturn NULL;\n \n       vect_def_type def_type = STMT_VINFO_DEF_TYPE (stmt_info);\n@@ -1288,7 +1289,7 @@ vect_build_slp_tree_2 (vec_info *vinfo,\n \n   bool two_operators = false;\n   unsigned char *swap = XALLOCAVEC (unsigned char, group_size);\n-  if (!vect_build_slp_tree_1 (swap, stmts, group_size,\n+  if (!vect_build_slp_tree_1 (vinfo, swap, stmts, group_size,\n \t\t\t      &this_max_nunits, matches, &two_operators))\n     return NULL;\n \n@@ -1398,7 +1399,8 @@ vect_build_slp_tree_2 (vec_info *vinfo,\n \t\tif (SLP_TREE_DEF_TYPE (grandchild) != vect_external_def)\n \t\t  break;\n \t      if (!grandchild\n-\t\t  && vect_update_all_shared_vectypes (oprnd_info->def_stmts))\n+\t\t  && vect_update_all_shared_vectypes (vinfo,\n+\t\t\t\t\t\t      oprnd_info->def_stmts))\n \t\t{\n \t\t  /* Roll back.  */\n \t\t  this_tree_size = old_tree_size;\n@@ -1440,7 +1442,7 @@ vect_build_slp_tree_2 (vec_info *vinfo,\n \t     scalar version.  */\n \t  && !is_pattern_stmt_p (stmt_info)\n \t  && !oprnd_info->any_pattern\n-\t  && vect_update_all_shared_vectypes (oprnd_info->def_stmts))\n+\t  && vect_update_all_shared_vectypes (vinfo, oprnd_info->def_stmts))\n \t{\n \t  if (dump_enabled_p ())\n \t    dump_printf_loc (MSG_NOTE, vect_location,\n@@ -1540,7 +1542,7 @@ vect_build_slp_tree_2 (vec_info *vinfo,\n \t\t      break;\n \t\t  if (!grandchild\n \t\t      && (vect_update_all_shared_vectypes\n-\t\t\t  (oprnd_info->def_stmts)))\n+\t\t\t    (vinfo, oprnd_info->def_stmts)))\n \t\t    {\n \t\t      /* Roll back.  */\n \t\t      this_tree_size = old_tree_size;\n@@ -1922,7 +1924,7 @@ vect_gather_slp_loads (slp_instance inst, slp_tree node)\n    SLP_INSTN are supported.  */\n \n static bool\n-vect_supported_load_permutation_p (slp_instance slp_instn)\n+vect_supported_load_permutation_p (vec_info *vinfo, slp_instance slp_instn)\n {\n   unsigned int group_size = SLP_INSTANCE_GROUP_SIZE (slp_instn);\n   unsigned int i, j, k, next;\n@@ -1966,7 +1968,7 @@ vect_supported_load_permutation_p (slp_instance slp_instn)\n   /* In basic block vectorization we allow any subchain of an interleaving\n      chain.\n      FORNOW: not supported in loop SLP because of realignment compications.  */\n-  if (STMT_VINFO_BB_VINFO (stmt_info))\n+  if (is_a <bb_vec_info> (vinfo))\n     {\n       /* Check whether the loads in an instance form a subchain and thus\n          no permutation is necessary.  */\n@@ -2015,7 +2017,7 @@ vect_supported_load_permutation_p (slp_instance slp_instn)\n \t      /* Verify the permutation can be generated.  */\n \t      vec<tree> tem;\n \t      unsigned n_perms;\n-\t      if (!vect_transform_slp_perm_load (node, tem, NULL,\n+\t      if (!vect_transform_slp_perm_load (vinfo, node, tem, NULL,\n \t\t\t\t\t\t 1, slp_instn, true, &n_perms))\n \t\t{\n \t\t  if (dump_enabled_p ())\n@@ -2038,10 +2040,10 @@ vect_supported_load_permutation_p (slp_instance slp_instn)\n   poly_uint64 test_vf\n     = force_common_multiple (SLP_INSTANCE_UNROLLING_FACTOR (slp_instn),\n \t\t\t     LOOP_VINFO_VECT_FACTOR\n-\t\t\t     (STMT_VINFO_LOOP_VINFO (stmt_info)));\n+\t\t\t       (as_a <loop_vec_info> (vinfo)));\n   FOR_EACH_VEC_ELT (SLP_INSTANCE_LOADS (slp_instn), i, node)\n     if (node->load_permutation.exists ()\n-\t&& !vect_transform_slp_perm_load (node, vNULL, NULL, test_vf,\n+\t&& !vect_transform_slp_perm_load (vinfo, node, vNULL, NULL, test_vf,\n \t\t\t\t\t  slp_instn, true, &n_perms))\n       return false;\n \n@@ -2321,7 +2323,7 @@ vect_analyze_slp_instance (vec_info *vinfo,\n \n \t  if (loads_permuted)\n \t    {\n-\t      if (!vect_supported_load_permutation_p (new_instance))\n+\t      if (!vect_supported_load_permutation_p (vinfo, new_instance))\n \t\t{\n \t\t  if (dump_enabled_p ())\n \t\t    dump_printf_loc (MSG_MISSED_OPTIMIZATION, vect_location,\n@@ -2569,15 +2571,15 @@ vect_make_slp_decision (loop_vec_info loop_vinfo)\n    can't be SLPed) in the tree rooted at NODE.  Mark such stmts as HYBRID.  */\n \n static void\n-vect_detect_hybrid_slp_stmts (slp_tree node, unsigned i, slp_vect_type stype,\n+vect_detect_hybrid_slp_stmts (loop_vec_info loop_vinfo, slp_tree node,\n+\t\t\t      unsigned i, slp_vect_type stype,\n \t\t\t      hash_map<slp_tree, unsigned> &visited)\n {\n   stmt_vec_info stmt_vinfo = SLP_TREE_SCALAR_STMTS (node)[i];\n   imm_use_iterator imm_iter;\n   gimple *use_stmt;\n   stmt_vec_info use_vinfo;\n   slp_tree child;\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_vinfo);\n   int j;\n \n   /* We need to union stype over the incoming graph edges but we still\n@@ -2637,7 +2639,7 @@ vect_detect_hybrid_slp_stmts (slp_tree node, unsigned i, slp_vect_type stype,\n     FOR_EACH_VEC_ELT (SLP_TREE_CHILDREN (node), j, child)\n       if (SLP_TREE_DEF_TYPE (child) != vect_external_def\n \t  && SLP_TREE_DEF_TYPE (child) != vect_constant_def)\n-\tvect_detect_hybrid_slp_stmts (child, i, stype, visited);\n+\tvect_detect_hybrid_slp_stmts (loop_vinfo, child, i, stype, visited);\n }\n \n /* Helpers for vect_detect_hybrid_slp walking pattern stmt uses.  */\n@@ -2730,7 +2732,8 @@ vect_detect_hybrid_slp (loop_vec_info loop_vinfo)\n \tif (j < SLP_INSTANCE_GROUP_SIZE (instance))\n \t  {\n \t    any = true;\n-\t    vect_detect_hybrid_slp_stmts (SLP_INSTANCE_TREE (instance),\n+\t    vect_detect_hybrid_slp_stmts (loop_vinfo,\n+\t\t\t\t\t  SLP_INSTANCE_TREE (instance),\n \t\t\t\t\t  j, pure_slp, visited);\n \t  }\n       if (!any)\n@@ -2820,7 +2823,8 @@ vect_slp_analyze_node_operations_1 (vec_info *vinfo, slp_tree node,\n     }\n \n   bool dummy;\n-  return vect_analyze_stmt (stmt_info, &dummy, node, node_instance, cost_vec);\n+  return vect_analyze_stmt (vinfo, stmt_info, &dummy,\n+\t\t\t    node, node_instance, cost_vec);\n }\n \n /* Try to build NODE from scalars, returning true on success.\n@@ -2987,7 +2991,7 @@ vect_slp_analyze_operations (vec_info *vinfo)\n \t    visited.add (*x);\n \t  i++;\n \n-\t  add_stmt_costs (vinfo->target_cost_data, &cost_vec);\n+\t  add_stmt_costs (vinfo, vinfo->target_cost_data, &cost_vec);\n \t  cost_vec.release ();\n \t}\n     }\n@@ -3001,7 +3005,7 @@ vect_slp_analyze_operations (vec_info *vinfo)\n    update LIFE according to uses of NODE.  */\n \n static void \n-vect_bb_slp_scalar_cost (basic_block bb,\n+vect_bb_slp_scalar_cost (vec_info *vinfo, basic_block bb,\n \t\t\t slp_tree node, vec<bool, va_heap> *life,\n \t\t\t stmt_vector_for_cost *cost_vec,\n \t\t\t hash_set<slp_tree> &visited)\n@@ -3016,7 +3020,6 @@ vect_bb_slp_scalar_cost (basic_block bb,\n   FOR_EACH_VEC_ELT (SLP_TREE_SCALAR_STMTS (node), i, stmt_info)\n     {\n       gimple *stmt = stmt_info->stmt;\n-      vec_info *vinfo = stmt_info->vinfo;\n       ssa_op_iter op_iter;\n       def_operand_p def_p;\n \n@@ -3074,7 +3077,7 @@ vect_bb_slp_scalar_cost (basic_block bb,\n \t  /* Do not directly pass LIFE to the recursive call, copy it to\n \t     confine changes in the callee to the current child/subtree.  */\n \t  subtree_life.safe_splice (*life);\n-\t  vect_bb_slp_scalar_cost (bb, child, &subtree_life, cost_vec,\n+\t  vect_bb_slp_scalar_cost (vinfo, bb, child, &subtree_life, cost_vec,\n \t\t\t\t   visited);\n \t  subtree_life.truncate (0);\n \t}\n@@ -3100,12 +3103,12 @@ vect_bb_vectorization_profitable_p (bb_vec_info bb_vinfo)\n     {\n       auto_vec<bool, 20> life;\n       life.safe_grow_cleared (SLP_INSTANCE_GROUP_SIZE (instance));\n-      vect_bb_slp_scalar_cost (BB_VINFO_BB (bb_vinfo),\n+      vect_bb_slp_scalar_cost (bb_vinfo, BB_VINFO_BB (bb_vinfo),\n \t\t\t       SLP_INSTANCE_TREE (instance),\n \t\t\t       &life, &scalar_costs, visited);\n     }\n   void *target_cost_data = init_cost (NULL);\n-  add_stmt_costs (target_cost_data, &scalar_costs);\n+  add_stmt_costs (bb_vinfo, target_cost_data, &scalar_costs);\n   scalar_costs.release ();\n   unsigned dummy;\n   finish_cost (target_cost_data, &dummy, &scalar_cost, &dummy);\n@@ -3258,8 +3261,8 @@ vect_slp_analyze_bb_1 (bb_vec_info bb_vinfo, int n_stmts, bool &fatal)\n      dependence in the SLP instances.  */\n   for (i = 0; BB_VINFO_SLP_INSTANCES (bb_vinfo).iterate (i, &instance); )\n     {\n-      if (! vect_slp_analyze_and_verify_instance_alignment (instance)\n-\t  || ! vect_slp_analyze_instance_dependence (instance))\n+      if (! vect_slp_analyze_and_verify_instance_alignment (bb_vinfo, instance)\n+\t  || ! vect_slp_analyze_instance_dependence (bb_vinfo, instance))\n \t{\n \t  slp_tree node = SLP_INSTANCE_TREE (instance);\n \t  stmt_vec_info stmt_info = SLP_TREE_SCALAR_STMTS (node)[0];\n@@ -3497,7 +3500,8 @@ vect_slp_bb (basic_block bb)\n /* Return 1 if vector type STMT_VINFO is a boolean vector.  */\n \n static bool\n-vect_mask_constant_operand_p (stmt_vec_info stmt_vinfo, unsigned op_num)\n+vect_mask_constant_operand_p (vec_info *vinfo,\n+\t\t\t      stmt_vec_info stmt_vinfo, unsigned op_num)\n {\n   enum tree_code code = gimple_expr_code (stmt_vinfo->stmt);\n   tree op, vectype;\n@@ -3510,7 +3514,7 @@ vect_mask_constant_operand_p (stmt_vec_info stmt_vinfo, unsigned op_num)\n       gassign *stmt = as_a <gassign *> (stmt_vinfo->stmt);\n       op = gimple_assign_rhs1 (stmt);\n \n-      if (!vect_is_simple_use (op, stmt_vinfo->vinfo, &dt, &vectype))\n+      if (!vect_is_simple_use (op, vinfo, &dt, &vectype))\n \tgcc_unreachable ();\n \n       return !vectype || VECTOR_BOOLEAN_TYPE_P (vectype);\n@@ -3534,7 +3538,7 @@ vect_mask_constant_operand_p (stmt_vec_info stmt_vinfo, unsigned op_num)\n \t  op = TREE_OPERAND (cond, 0);\n \t}\n \n-      if (!vect_is_simple_use (op, stmt_vinfo->vinfo, &dt, &vectype))\n+      if (!vect_is_simple_use (op, vinfo, &dt, &vectype))\n \tgcc_unreachable ();\n \n       return !vectype || VECTOR_BOOLEAN_TYPE_P (vectype);\n@@ -3663,12 +3667,12 @@ duplicate_and_interleave (vec_info *vinfo, gimple_seq *seq, tree vector_type,\n    operands.  */\n \n static void\n-vect_get_constant_vectors (slp_tree slp_node, unsigned op_num,\n+vect_get_constant_vectors (vec_info *vinfo,\n+\t\t\t   slp_tree slp_node, unsigned op_num,\n                            vec<tree> *vec_oprnds)\n {\n   slp_tree op_node = SLP_TREE_CHILDREN (slp_node)[op_num];\n   stmt_vec_info stmt_vinfo = SLP_TREE_SCALAR_STMTS (slp_node)[0];\n-  vec_info *vinfo = stmt_vinfo->vinfo;\n   unsigned HOST_WIDE_INT nunits;\n   tree vec_cst;\n   unsigned j, number_of_places_left_in_vector;\n@@ -3688,7 +3692,7 @@ vect_get_constant_vectors (slp_tree slp_node, unsigned op_num,\n   /* Check if vector type is a boolean vector.  */\n   tree stmt_vectype = STMT_VINFO_VECTYPE (stmt_vinfo);\n   if (VECT_SCALAR_BOOLEAN_TYPE_P (TREE_TYPE (op))\n-      && vect_mask_constant_operand_p (stmt_vinfo, op_num))\n+      && vect_mask_constant_operand_p (vinfo, stmt_vinfo, op_num))\n     vector_type = truth_type_for (stmt_vectype);\n   else\n     vector_type = get_vectype_for_scalar_type (vinfo, TREE_TYPE (op), op_node);\n@@ -3797,8 +3801,8 @@ vect_get_constant_vectors (slp_tree slp_node, unsigned op_num,\n \t    constant_p = false;\n \t  if (TREE_CODE (orig_op) == SSA_NAME\n \t      && !SSA_NAME_IS_DEFAULT_DEF (orig_op)\n-\t      && STMT_VINFO_BB_VINFO (stmt_vinfo)\n-\t      && (STMT_VINFO_BB_VINFO (stmt_vinfo)->bb\n+\t      && is_a <bb_vec_info> (vinfo)\n+\t      && (as_a <bb_vec_info> (vinfo)->bb\n \t\t  == gimple_bb (SSA_NAME_DEF_STMT (orig_op))))\n \t    place_after_defs = true;\n \n@@ -3823,12 +3827,12 @@ vect_get_constant_vectors (slp_tree slp_node, unsigned op_num,\n \t\t  stmt_vec_info last_stmt_info\n \t\t    = vect_find_last_scalar_stmt_in_slp (slp_node);\n \t\t  gsi = gsi_for_stmt (last_stmt_info->stmt);\n-\t\t  init = vect_init_vector (stmt_vinfo, vec_cst, vector_type,\n-\t\t\t\t\t   &gsi);\n+\t\t  init = vect_init_vector (vinfo, stmt_vinfo, vec_cst,\n+\t\t\t\t\t   vector_type, &gsi);\n \t\t}\n \t      else\n-\t\tinit = vect_init_vector (stmt_vinfo, vec_cst, vector_type,\n-\t\t\t\t\t NULL);\n+\t\tinit = vect_init_vector (vinfo, stmt_vinfo, vec_cst,\n+\t\t\t\t\t vector_type, NULL);\n \t      if (ctor_seq != NULL)\n \t\t{\n \t\t  gsi = gsi_for_stmt (SSA_NAME_DEF_STMT (init));\n@@ -3902,7 +3906,8 @@ vect_get_slp_vect_defs (slp_tree slp_node, vec<tree> *vec_oprnds)\n    vect_get_slp_vect_defs () to retrieve them.  */\n \n void\n-vect_get_slp_defs (slp_tree slp_node, vec<vec<tree> > *vec_oprnds, unsigned n)\n+vect_get_slp_defs (vec_info *vinfo,\n+\t\t   slp_tree slp_node, vec<vec<tree> > *vec_oprnds, unsigned n)\n {\n   if (n == -1U)\n     n = SLP_TREE_CHILDREN (slp_node).length ();\n@@ -3921,7 +3926,7 @@ vect_get_slp_defs (slp_tree slp_node, vec<vec<tree> > *vec_oprnds, unsigned n)\n \t  vect_get_slp_vect_defs (child, &vec_defs);\n \t}\n       else\n-\tvect_get_constant_vectors (slp_node, i, &vec_defs);\n+\tvect_get_constant_vectors (vinfo, slp_node, i, &vec_defs);\n \n       vec_oprnds->quick_push (vec_defs);\n     }\n@@ -3933,13 +3938,13 @@ vect_get_slp_defs (slp_tree slp_node, vec<vec<tree> > *vec_oprnds, unsigned n)\n    SLP_NODE_INSTANCE.  */\n \n bool\n-vect_transform_slp_perm_load (slp_tree node, vec<tree> dr_chain,\n+vect_transform_slp_perm_load (vec_info *vinfo,\n+\t\t\t      slp_tree node, vec<tree> dr_chain,\n \t\t\t      gimple_stmt_iterator *gsi, poly_uint64 vf,\n \t\t\t      slp_instance slp_node_instance, bool analyze_only,\n \t\t\t      unsigned *n_perms)\n {\n   stmt_vec_info stmt_info = SLP_TREE_SCALAR_STMTS (node)[0];\n-  vec_info *vinfo = stmt_info->vinfo;\n   int vec_index = 0;\n   tree vectype = STMT_VINFO_VECTYPE (stmt_info);\n   unsigned int group_size = SLP_INSTANCE_GROUP_SIZE (slp_node_instance);\n@@ -4116,7 +4121,8 @@ vect_transform_slp_perm_load (slp_tree node, vec<tree> dr_chain,\n \t\t\t\t\t       first_vec, second_vec,\n \t\t\t\t\t       mask_vec);\n \t\t      perm_stmt_info\n-\t\t\t= vect_finish_stmt_generation (stmt_info, perm_stmt,\n+\t\t\t= vect_finish_stmt_generation (vinfo,\n+\t\t\t\t\t\t       stmt_info, perm_stmt,\n \t\t\t\t\t\t       gsi);\n \t\t    }\n \t\t  else\n@@ -4143,7 +4149,8 @@ vect_transform_slp_perm_load (slp_tree node, vec<tree> dr_chain,\n /* Vectorize SLP instance tree in postorder.  */\n \n static void\n-vect_schedule_slp_instance (slp_tree node, slp_instance instance)\n+vect_schedule_slp_instance (vec_info *vinfo,\n+\t\t\t    slp_tree node, slp_instance instance)\n {\n   gimple_stmt_iterator si;\n   stmt_vec_info stmt_info;\n@@ -4161,7 +4168,7 @@ vect_schedule_slp_instance (slp_tree node, slp_instance instance)\n     return;\n \n   FOR_EACH_VEC_ELT (SLP_TREE_CHILDREN (node), i, child)\n-    vect_schedule_slp_instance (child, instance);\n+    vect_schedule_slp_instance (vinfo, child, instance);\n \n   /* Push SLP node def-type to stmts.  */\n   FOR_EACH_VEC_ELT (SLP_TREE_CHILDREN (node), i, child)\n@@ -4219,11 +4226,11 @@ vect_schedule_slp_instance (slp_tree node, slp_instance instance)\n \t  vec<stmt_vec_info> v1;\n \t  unsigned j;\n \t  tree tmask = NULL_TREE;\n-\t  vect_transform_stmt (stmt_info, &si, node, instance);\n+\t  vect_transform_stmt (vinfo, stmt_info, &si, node, instance);\n \t  v0 = SLP_TREE_VEC_STMTS (node).copy ();\n \t  SLP_TREE_VEC_STMTS (node).truncate (0);\n \t  gimple_assign_set_rhs_code (stmt, ocode);\n-\t  vect_transform_stmt (stmt_info, &si, node, instance);\n+\t  vect_transform_stmt (vinfo, stmt_info, &si, node, instance);\n \t  gimple_assign_set_rhs_code (stmt, code0);\n \t  v1 = SLP_TREE_VEC_STMTS (node).copy ();\n \t  SLP_TREE_VEC_STMTS (node).truncate (0);\n@@ -4261,15 +4268,15 @@ vect_schedule_slp_instance (slp_tree node, slp_instance instance)\n \t\t\t\t\t   gimple_assign_lhs (v1[j]->stmt),\n \t\t\t\t\t   tmask);\n \t      SLP_TREE_VEC_STMTS (node).quick_push\n-\t\t(vect_finish_stmt_generation (stmt_info, vstmt, &si));\n+\t\t(vect_finish_stmt_generation (vinfo, stmt_info, vstmt, &si));\n \t    }\n \t  v0.release ();\n \t  v1.release ();\n \t  done_p = true;\n \t}\n     }\n   if (!done_p)\n-    vect_transform_stmt (stmt_info, &si, node, instance);\n+    vect_transform_stmt (vinfo, stmt_info, &si, node, instance);\n \n   /* Restore stmt def-types.  */\n   FOR_EACH_VEC_ELT (SLP_TREE_CHILDREN (node), i, child)\n@@ -4287,7 +4294,8 @@ vect_schedule_slp_instance (slp_tree node, slp_instance instance)\n    SLP instances may refer to the same scalar stmt.  */\n \n static void\n-vect_remove_slp_scalar_calls (slp_tree node, hash_set<slp_tree> &visited)\n+vect_remove_slp_scalar_calls (vec_info *vinfo,\n+\t\t\t      slp_tree node, hash_set<slp_tree> &visited)\n {\n   gimple *new_stmt;\n   gimple_stmt_iterator gsi;\n@@ -4303,7 +4311,7 @@ vect_remove_slp_scalar_calls (slp_tree node, hash_set<slp_tree> &visited)\n     return;\n \n   FOR_EACH_VEC_ELT (SLP_TREE_CHILDREN (node), i, child)\n-    vect_remove_slp_scalar_calls (child, visited);\n+    vect_remove_slp_scalar_calls (vinfo, child, visited);\n \n   FOR_EACH_VEC_ELT (SLP_TREE_SCALAR_STMTS (node), i, stmt_info)\n     {\n@@ -4316,16 +4324,16 @@ vect_remove_slp_scalar_calls (slp_tree node, hash_set<slp_tree> &visited)\n       lhs = gimple_call_lhs (stmt);\n       new_stmt = gimple_build_assign (lhs, build_zero_cst (TREE_TYPE (lhs)));\n       gsi = gsi_for_stmt (stmt);\n-      stmt_info->vinfo->replace_stmt (&gsi, stmt_info, new_stmt);\n+      vinfo->replace_stmt (&gsi, stmt_info, new_stmt);\n       SSA_NAME_DEF_STMT (gimple_assign_lhs (new_stmt)) = new_stmt;\n     }\n }\n \n static void\n-vect_remove_slp_scalar_calls (slp_tree node)\n+vect_remove_slp_scalar_calls (vec_info *vinfo, slp_tree node)\n {\n   hash_set<slp_tree> visited;\n-  vect_remove_slp_scalar_calls (node, visited);\n+  vect_remove_slp_scalar_calls (vinfo, node, visited);\n }\n \n /* Vectorize the instance root.  */\n@@ -4392,7 +4400,7 @@ vect_schedule_slp (vec_info *vinfo)\n     {\n       slp_tree node = SLP_INSTANCE_TREE (instance);\n       /* Schedule the tree of INSTANCE.  */\n-      vect_schedule_slp_instance (node, instance);\n+      vect_schedule_slp_instance (vinfo, node, instance);\n \n       if (SLP_INSTANCE_ROOT_STMT (instance))\n \tvectorize_slp_instance_root_stmt (node, instance);\n@@ -4416,7 +4424,7 @@ vect_schedule_slp (vec_info *vinfo)\n \t stmts starting from the SLP tree root if they have no\n \t uses.  */\n       if (is_a <loop_vec_info> (vinfo))\n-\tvect_remove_slp_scalar_calls (root);\n+\tvect_remove_slp_scalar_calls (vinfo, root);\n \n       for (j = 0; SLP_TREE_SCALAR_STMTS (root).iterate (j, &store_info)\n                   && j < SLP_INSTANCE_GROUP_SIZE (instance); j++)"}, {"sha": "33210e1485b5b08083e3bdc28af3e723c09dc1cd", "filename": "gcc/tree-vect-stmts.c", "status": "modified", "additions": 533, "deletions": 449, "changes": 982, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vect-stmts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vect-stmts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-stmts.c?ref=308bc496884706af4b3077171cbac684c7a6f7c6"}, {"sha": "41ff67919668019f1e8b8f27741e255c764c8939", "filename": "gcc/tree-vectorizer.c", "status": "modified", "additions": 0, "deletions": 1, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vectorizer.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vectorizer.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vectorizer.c?ref=308bc496884706af4b3077171cbac684c7a6f7c6", "patch": "@@ -631,7 +631,6 @@ stmt_vec_info\n vec_info::new_stmt_vec_info (gimple *stmt)\n {\n   stmt_vec_info res = XCNEW (class _stmt_vec_info);\n-  res->vinfo = this;\n   res->stmt = stmt;\n \n   STMT_VINFO_TYPE (res) = undef_vec_info_type;"}, {"sha": "a47ba1a6742a52424fcfe8b630efa2173fc882dc", "filename": "gcc/tree-vectorizer.h", "status": "modified", "additions": 64, "deletions": 59, "changes": 123, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vectorizer.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/308bc496884706af4b3077171cbac684c7a6f7c6/gcc%2Ftree-vectorizer.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vectorizer.h?ref=308bc496884706af4b3077171cbac684c7a6f7c6", "patch": "@@ -945,9 +945,6 @@ class _stmt_vec_info {\n   /* The stmt to which this info struct refers to.  */\n   gimple *stmt;\n \n-  /* The vec_info with respect to which STMT is vectorized.  */\n-  vec_info *vinfo;\n-\n   /* The vector type to be used for the LHS of this statement.  */\n   tree vectype;\n \n@@ -1152,20 +1149,6 @@ struct gather_scatter_info {\n /* Access Functions.  */\n #define STMT_VINFO_TYPE(S)                 (S)->type\n #define STMT_VINFO_STMT(S)                 (S)->stmt\n-inline loop_vec_info\n-STMT_VINFO_LOOP_VINFO (stmt_vec_info stmt_vinfo)\n-{\n-  if (loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (stmt_vinfo->vinfo))\n-    return loop_vinfo;\n-  return NULL;\n-}\n-inline bb_vec_info\n-STMT_VINFO_BB_VINFO (stmt_vec_info stmt_vinfo)\n-{\n-  if (bb_vec_info bb_vinfo = dyn_cast <bb_vec_info> (stmt_vinfo->vinfo))\n-    return bb_vinfo;\n-  return NULL;\n-}\n #define STMT_VINFO_RELEVANT(S)             (S)->relevant\n #define STMT_VINFO_LIVE_P(S)               (S)->live\n #define STMT_VINFO_VECTYPE(S)              (S)->vectype\n@@ -1377,11 +1360,12 @@ extern void dump_stmt_cost (FILE *, void *, int, enum vect_cost_for_stmt,\n /* Alias targetm.vectorize.add_stmt_cost.  */\n \n static inline unsigned\n-add_stmt_cost (void *data, int count, enum vect_cost_for_stmt kind,\n+add_stmt_cost (vec_info *vinfo, void *data, int count,\n+\t       enum vect_cost_for_stmt kind,\n \t       stmt_vec_info stmt_info, int misalign,\n \t       enum vect_cost_model_location where)\n {\n-  unsigned cost = targetm.vectorize.add_stmt_cost (data, count, kind,\n+  unsigned cost = targetm.vectorize.add_stmt_cost (vinfo, data, count, kind,\n \t\t\t\t\t\t   stmt_info, misalign, where);\n   if (dump_file && (dump_flags & TDF_DETAILS))\n     dump_stmt_cost (dump_file, data, count, kind, stmt_info, misalign,\n@@ -1407,12 +1391,12 @@ destroy_cost_data (void *data)\n }\n \n inline void\n-add_stmt_costs (void *data, stmt_vector_for_cost *cost_vec)\n+add_stmt_costs (vec_info *vinfo, void *data, stmt_vector_for_cost *cost_vec)\n {\n   stmt_info_for_cost *cost;\n   unsigned i;\n   FOR_EACH_VEC_ELT (*cost_vec, i, cost)\n-    add_stmt_cost (data, cost->count, cost->kind, cost->stmt_info,\n+    add_stmt_cost (vinfo, data, cost->count, cost->kind, cost->stmt_info,\n \t\t   cost->misalign, cost->where);\n }\n \n@@ -1480,10 +1464,10 @@ vect_known_alignment_in_bytes (dr_vec_info *dr_info)\n    in DR_INFO itself).  */\n \n static inline innermost_loop_behavior *\n-vect_dr_behavior (dr_vec_info *dr_info)\n+vect_dr_behavior (vec_info *vinfo, dr_vec_info *dr_info)\n {\n   stmt_vec_info stmt_info = dr_info->stmt;\n-  loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n+  loop_vec_info loop_vinfo = dyn_cast<loop_vec_info> (vinfo);\n   if (loop_vinfo == NULL\n       || !nested_in_vect_loop_p (LOOP_VINFO_LOOP (loop_vinfo), stmt_info))\n     return &DR_INNERMOST (dr_info->dr);\n@@ -1496,11 +1480,12 @@ vect_dr_behavior (dr_vec_info *dr_info)\n    vect_dr_behavior to select the appropriate data_reference to use.  */\n \n inline tree\n-get_dr_vinfo_offset (dr_vec_info *dr_info, bool check_outer = false)\n+get_dr_vinfo_offset (vec_info *vinfo,\n+\t\t     dr_vec_info *dr_info, bool check_outer = false)\n {\n   innermost_loop_behavior *base;\n   if (check_outer)\n-    base = vect_dr_behavior (dr_info);\n+    base = vect_dr_behavior (vinfo, dr_info);\n   else\n     base = &dr_info->dr->innermost;\n \n@@ -1705,7 +1690,8 @@ extern bool vect_is_simple_use (tree, vec_info *, enum vect_def_type *,\n extern bool vect_is_simple_use (tree, vec_info *, enum vect_def_type *,\n \t\t\t\ttree *, stmt_vec_info * = NULL,\n \t\t\t\tgimple ** = NULL);\n-extern bool supportable_widening_operation (enum tree_code, stmt_vec_info,\n+extern bool supportable_widening_operation (vec_info *,\n+\t\t\t\t\t    enum tree_code, stmt_vec_info,\n \t\t\t\t\t    tree, tree, enum tree_code *,\n \t\t\t\t\t    enum tree_code *, int *,\n \t\t\t\t\t    vec<tree> *);\n@@ -1715,54 +1701,61 @@ extern bool supportable_narrowing_operation (enum tree_code, tree, tree,\n extern unsigned record_stmt_cost (stmt_vector_for_cost *, int,\n \t\t\t\t  enum vect_cost_for_stmt, stmt_vec_info,\n \t\t\t\t  int, enum vect_cost_model_location);\n-extern stmt_vec_info vect_finish_replace_stmt (stmt_vec_info, gimple *);\n-extern stmt_vec_info vect_finish_stmt_generation (stmt_vec_info, gimple *,\n+extern stmt_vec_info vect_finish_replace_stmt (vec_info *,\n+\t\t\t\t\t       stmt_vec_info, gimple *);\n+extern stmt_vec_info vect_finish_stmt_generation (vec_info *,\n+\t\t\t\t\t\t  stmt_vec_info, gimple *,\n \t\t\t\t\t\t  gimple_stmt_iterator *);\n extern opt_result vect_mark_stmts_to_be_vectorized (loop_vec_info, bool *);\n extern tree vect_get_store_rhs (stmt_vec_info);\n extern tree vect_get_vec_def_for_operand_1 (stmt_vec_info, enum vect_def_type);\n-extern tree vect_get_vec_def_for_operand (tree, stmt_vec_info, tree = NULL);\n-extern void vect_get_vec_defs (tree, tree, stmt_vec_info, vec<tree> *,\n-\t\t\t       vec<tree> *, slp_tree);\n+extern tree vect_get_vec_def_for_operand (vec_info *, tree,\n+\t\t\t\t\t  stmt_vec_info, tree = NULL);\n+extern void vect_get_vec_defs (vec_info *, tree, tree, stmt_vec_info,\n+\t\t\t       vec<tree> *, vec<tree> *, slp_tree);\n extern void vect_get_vec_defs_for_stmt_copy (vec_info *,\n \t\t\t\t\t     vec<tree> *, vec<tree> *);\n-extern tree vect_init_vector (stmt_vec_info, tree, tree,\n+extern tree vect_init_vector (vec_info *, stmt_vec_info, tree, tree,\n                               gimple_stmt_iterator *);\n extern tree vect_get_vec_def_for_stmt_copy (vec_info *, tree);\n-extern bool vect_transform_stmt (stmt_vec_info, gimple_stmt_iterator *,\n+extern bool vect_transform_stmt (vec_info *, stmt_vec_info,\n+\t\t\t\t gimple_stmt_iterator *,\n \t\t\t\t slp_tree, slp_instance);\n-extern void vect_remove_stores (stmt_vec_info);\n+extern void vect_remove_stores (vec_info *, stmt_vec_info);\n extern bool vect_nop_conversion_p (stmt_vec_info);\n-extern opt_result vect_analyze_stmt (stmt_vec_info, bool *, slp_tree,\n+extern opt_result vect_analyze_stmt (vec_info *, stmt_vec_info, bool *,\n+\t\t\t\t     slp_tree,\n \t\t\t\t     slp_instance, stmt_vector_for_cost *);\n-extern void vect_get_load_cost (stmt_vec_info, int, bool,\n+extern void vect_get_load_cost (vec_info *, stmt_vec_info, int, bool,\n \t\t\t\tunsigned int *, unsigned int *,\n \t\t\t\tstmt_vector_for_cost *,\n \t\t\t\tstmt_vector_for_cost *, bool);\n-extern void vect_get_store_cost (stmt_vec_info, int,\n+extern void vect_get_store_cost (vec_info *, stmt_vec_info, int,\n \t\t\t\t unsigned int *, stmt_vector_for_cost *);\n extern bool vect_supportable_shift (vec_info *, enum tree_code, tree);\n extern tree vect_gen_perm_mask_any (tree, const vec_perm_indices &);\n extern tree vect_gen_perm_mask_checked (tree, const vec_perm_indices &);\n extern void optimize_mask_stores (class loop*);\n extern gcall *vect_gen_while (tree, tree, tree);\n extern tree vect_gen_while_not (gimple_seq *, tree, tree, tree);\n-extern opt_result vect_get_vector_types_for_stmt (stmt_vec_info, tree *,\n+extern opt_result vect_get_vector_types_for_stmt (vec_info *,\n+\t\t\t\t\t\t  stmt_vec_info, tree *,\n \t\t\t\t\t\t  tree *, unsigned int = 0);\n extern opt_tree vect_get_mask_type_for_stmt (stmt_vec_info, unsigned int = 0);\n \n /* In tree-vect-data-refs.c.  */\n extern bool vect_can_force_dr_alignment_p (const_tree, poly_uint64);\n extern enum dr_alignment_support vect_supportable_dr_alignment\n-                                           (dr_vec_info *, bool);\n+                                           (vec_info *, dr_vec_info *, bool);\n extern tree vect_get_smallest_scalar_type (stmt_vec_info, HOST_WIDE_INT *,\n                                            HOST_WIDE_INT *);\n extern opt_result vect_analyze_data_ref_dependences (loop_vec_info, unsigned int *);\n-extern bool vect_slp_analyze_instance_dependence (slp_instance);\n+extern bool vect_slp_analyze_instance_dependence (vec_info *, slp_instance);\n extern opt_result vect_enhance_data_refs_alignment (loop_vec_info);\n extern opt_result vect_analyze_data_refs_alignment (loop_vec_info);\n extern opt_result vect_verify_datarefs_alignment (loop_vec_info);\n-extern bool vect_slp_analyze_and_verify_instance_alignment (slp_instance);\n+extern bool vect_slp_analyze_and_verify_instance_alignment (vec_info *,\n+\t\t\t\t\t\t\t    slp_instance);\n extern opt_result vect_analyze_data_ref_accesses (vec_info *);\n extern opt_result vect_prune_runtime_alias_test_list (loop_vec_info);\n extern bool vect_gather_scatter_fn_p (vec_info *, bool, bool, tree, tree,\n@@ -1773,30 +1766,35 @@ extern opt_result vect_find_stmt_data_reference (loop_p, gimple *,\n \t\t\t\t\t\t vec<data_reference_p> *);\n extern opt_result vect_analyze_data_refs (vec_info *, poly_uint64 *, bool *);\n extern void vect_record_base_alignments (vec_info *);\n-extern tree vect_create_data_ref_ptr (stmt_vec_info, tree, class loop *, tree,\n+extern tree vect_create_data_ref_ptr (vec_info *,\n+\t\t\t\t      stmt_vec_info, tree, class loop *, tree,\n \t\t\t\t      tree *, gimple_stmt_iterator *,\n \t\t\t\t      gimple **, bool,\n \t\t\t\t      tree = NULL_TREE, tree = NULL_TREE);\n-extern tree bump_vector_ptr (tree, gimple *, gimple_stmt_iterator *,\n+extern tree bump_vector_ptr (vec_info *, tree, gimple *, gimple_stmt_iterator *,\n \t\t\t     stmt_vec_info, tree);\n extern void vect_copy_ref_info (tree, tree);\n extern tree vect_create_destination_var (tree, tree);\n extern bool vect_grouped_store_supported (tree, unsigned HOST_WIDE_INT);\n extern bool vect_store_lanes_supported (tree, unsigned HOST_WIDE_INT, bool);\n extern bool vect_grouped_load_supported (tree, bool, unsigned HOST_WIDE_INT);\n extern bool vect_load_lanes_supported (tree, unsigned HOST_WIDE_INT, bool);\n-extern void vect_permute_store_chain (vec<tree> ,unsigned int, stmt_vec_info,\n-                                    gimple_stmt_iterator *, vec<tree> *);\n-extern tree vect_setup_realignment (stmt_vec_info, gimple_stmt_iterator *,\n+extern void vect_permute_store_chain (vec_info *,\n+\t\t\t\t      vec<tree> ,unsigned int, stmt_vec_info,\n+\t\t\t\t      gimple_stmt_iterator *, vec<tree> *);\n+extern tree vect_setup_realignment (vec_info *,\n+\t\t\t\t    stmt_vec_info, gimple_stmt_iterator *,\n \t\t\t\t    tree *, enum dr_alignment_support, tree,\n \t                            class loop **);\n-extern void vect_transform_grouped_load (stmt_vec_info, vec<tree> , int,\n-                                         gimple_stmt_iterator *);\n-extern void vect_record_grouped_load_vectors (stmt_vec_info, vec<tree>);\n+extern void vect_transform_grouped_load (vec_info *, stmt_vec_info, vec<tree>,\n+\t\t\t\t\t int, gimple_stmt_iterator *);\n+extern void vect_record_grouped_load_vectors (vec_info *,\n+\t\t\t\t\t      stmt_vec_info, vec<tree>);\n extern tree vect_get_new_vect_var (tree, enum vect_var_kind, const char *);\n extern tree vect_get_new_ssa_name (tree, enum vect_var_kind,\n \t\t\t\t   const char * = NULL);\n-extern tree vect_create_addr_base_for_vector_ref (stmt_vec_info, gimple_seq *,\n+extern tree vect_create_addr_base_for_vector_ref (vec_info *,\n+\t\t\t\t\t\t  stmt_vec_info, gimple_seq *,\n \t\t\t\t\t\t  tree, tree = NULL_TREE);\n \n /* In tree-vect-loop.c.  */\n@@ -1818,25 +1816,31 @@ extern void vect_record_loop_mask (loop_vec_info, vec_loop_masks *,\n \t\t\t\t   unsigned int, tree, tree);\n extern tree vect_get_loop_mask (gimple_stmt_iterator *, vec_loop_masks *,\n \t\t\t\tunsigned int, tree, unsigned int);\n-extern stmt_vec_info info_for_reduction (stmt_vec_info);\n+extern stmt_vec_info info_for_reduction (vec_info *, stmt_vec_info);\n \n /* Drive for loop transformation stage.  */\n extern class loop *vect_transform_loop (loop_vec_info, gimple *);\n extern opt_loop_vec_info vect_analyze_loop_form (class loop *,\n \t\t\t\t\t\t vec_info_shared *);\n-extern bool vectorizable_live_operation (stmt_vec_info, gimple_stmt_iterator *,\n+extern bool vectorizable_live_operation (loop_vec_info,\n+\t\t\t\t\t stmt_vec_info, gimple_stmt_iterator *,\n \t\t\t\t\t slp_tree, slp_instance, int,\n \t\t\t\t\t bool, stmt_vector_for_cost *);\n-extern bool vectorizable_reduction (stmt_vec_info, slp_tree, slp_instance,\n+extern bool vectorizable_reduction (loop_vec_info, stmt_vec_info,\n+\t\t\t\t    slp_tree, slp_instance,\n \t\t\t\t    stmt_vector_for_cost *);\n-extern bool vectorizable_induction (stmt_vec_info, gimple_stmt_iterator *,\n+extern bool vectorizable_induction (loop_vec_info, stmt_vec_info,\n+\t\t\t\t    gimple_stmt_iterator *,\n \t\t\t\t    stmt_vec_info *, slp_tree,\n \t\t\t\t    stmt_vector_for_cost *);\n-extern bool vect_transform_reduction (stmt_vec_info, gimple_stmt_iterator *,\n+extern bool vect_transform_reduction (loop_vec_info, stmt_vec_info,\n+\t\t\t\t      gimple_stmt_iterator *,\n \t\t\t\t      stmt_vec_info *, slp_tree);\n-extern bool vect_transform_cycle_phi (stmt_vec_info, stmt_vec_info *,\n+extern bool vect_transform_cycle_phi (loop_vec_info, stmt_vec_info,\n+\t\t\t\t      stmt_vec_info *,\n \t\t\t\t      slp_tree, slp_instance);\n-extern bool vectorizable_lc_phi (stmt_vec_info, stmt_vec_info *, slp_tree);\n+extern bool vectorizable_lc_phi (loop_vec_info, stmt_vec_info,\n+\t\t\t\t stmt_vec_info *, slp_tree);\n extern bool vect_worthwhile_without_simd_p (vec_info *, tree_code);\n extern int vect_get_known_peeling_cost (loop_vec_info, int, int *,\n \t\t\t\t\tstmt_vector_for_cost *,\n@@ -1846,15 +1850,16 @@ extern tree cse_and_gimplify_to_preheader (loop_vec_info, tree);\n \n /* In tree-vect-slp.c.  */\n extern void vect_free_slp_instance (slp_instance, bool);\n-extern bool vect_transform_slp_perm_load (slp_tree, vec<tree> ,\n+extern bool vect_transform_slp_perm_load (vec_info *, slp_tree, vec<tree>,\n \t\t\t\t\t  gimple_stmt_iterator *, poly_uint64,\n \t\t\t\t\t  slp_instance, bool, unsigned *);\n extern bool vect_slp_analyze_operations (vec_info *);\n extern void vect_schedule_slp (vec_info *);\n extern opt_result vect_analyze_slp (vec_info *, unsigned);\n extern bool vect_make_slp_decision (loop_vec_info);\n extern void vect_detect_hybrid_slp (loop_vec_info);\n-extern void vect_get_slp_defs (slp_tree, vec<vec<tree> > *, unsigned n = -1U);\n+extern void vect_get_slp_defs (vec_info *, slp_tree, vec<vec<tree> > *,\n+\t\t\t       unsigned n = -1U);\n extern bool vect_slp_bb (basic_block);\n extern stmt_vec_info vect_find_last_scalar_stmt_in_slp (slp_tree);\n extern bool is_simple_and_all_uses_invariant (stmt_vec_info, loop_vec_info);"}]}