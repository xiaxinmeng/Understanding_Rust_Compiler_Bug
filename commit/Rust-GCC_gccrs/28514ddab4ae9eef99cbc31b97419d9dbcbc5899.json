{"sha": "28514ddab4ae9eef99cbc31b97419d9dbcbc5899", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Mjg1MTRkZGFiNGFlOWVlZjk5Y2JjMzFiOTc0MTlkOWRiY2JjNTg5OQ==", "commit": {"author": {"name": "Yufeng Zhang", "email": "yufeng.zhang@arm.com", "date": "2013-07-23T12:20:05Z"}, "committer": {"name": "Yufeng Zhang", "email": "yufeng@gcc.gnu.org", "date": "2013-07-23T12:20:05Z"}, "message": "[AArch64, ILP32] 2/6 More backend changes and support for small absolute and\nsmall PIC addressing models\n\ngcc/\n\n\t* config/aarch64/aarch64.c (POINTER_BYTES): New define.\n\t(aarch64_load_symref_appropriately): In the case of\n\tSYMBOL_SMALL_ABSOLUTE, use the mode of 'dest' instead of Pmode\n\tto generate new rtx; likewise to the case of SYMBOL_SMALL_GOT.\n\t(aarch64_expand_mov_immediate): In the case of SYMBOL_FORCE_TO_MEM,\n\tchange to pass 'ptr_mode' to force_const_mem and zero-extend 'mem'\n\tif 'mode' doesn't equal to 'ptr_mode'.\n\t(aarch64_output_mi_thunk): Add an assertion on the alignment of\n\t'vcall_offset'; change to call aarch64_emit_move differently depending\n\ton whether 'Pmode' equals to 'ptr_mode' or not; use 'POINTER_BYTES'\n\tto calculate the upper bound of 'vcall_offset'.\n\t(aarch64_cannot_force_const_mem): Change to also return true if\n\tmode != ptr_mode.\n\t(aarch64_legitimize_reload_address): In the case of large\n\tdisplacements, add new local variable 'xmode' and an assertion\n\tbased on it; change to use 'xmode' to generate the new rtx and\n\treload.\n\t(aarch64_asm_trampoline_template): Change to generate the template\n\tdifferently depending on TARGET_ILP32 or not; change to use\n\t'POINTER_BYTES' in the argument passed to assemble_aligned_integer.\n\t(aarch64_trampoline_size): Removed.\n\t(aarch64_trampoline_init): Add new local constant 'tramp_code_sz'\n\tand replace immediate literals with it.  Change to use 'ptr_mode'\n\tinstead of 'DImode' and call convert_memory_address if the mode\n\tof 'fnaddr' doesn't equal to 'ptr_mode'.\n\t(aarch64_elf_asm_constructor): Change to use assemble_aligned_integer\n\tto output symbol.\n\t(aarch64_elf_asm_destructor): Likewise.\n\t* config/aarch64/aarch64.h (TRAMPOLINE_SIZE): Change to be dependent\n\ton TARGET_ILP32 instead of aarch64_trampoline_size.\n\t* config/aarch64/aarch64.md (movsi_aarch64): Add new alternatives\n\tof 'mov' between WSP and W registers as well as 'adr' and 'adrp'.\n\t(loadwb_pair<GPI:mode>_<PTR:mode>): Rename to ...\n\t(loadwb_pair<GPI:mode>_<P:mode>): ... this.  Replace PTR with P.\n\t(storewb_pair<GPI:mode>_<PTR:mode>): Likewise; rename to ...\n\t(storewb_pair<GPI:mode>_<P:mode>): ... this.\n\t(add_losym): Change to 'define_expand' and call gen_add_losym_<mode>\n\tdepending on the value of 'mode'.\n\t(add_losym_<mode>): New.\n\t(ldr_got_small_<mode>): New, based on ldr_got_small.\n\t(ldr_got_small): Remove.\n\t(ldr_got_small_sidi): New.\n\t* config/aarch64/iterators.md (P): New.\n\t(PTR): Change to 'ptr_mode' in the condition.\n\nFrom-SVN: r201165", "tree": {"sha": "7912222e247a4432b302e43f66515e4553b9d494", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/7912222e247a4432b302e43f66515e4553b9d494"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/28514ddab4ae9eef99cbc31b97419d9dbcbc5899", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/28514ddab4ae9eef99cbc31b97419d9dbcbc5899", "html_url": "https://github.com/Rust-GCC/gccrs/commit/28514ddab4ae9eef99cbc31b97419d9dbcbc5899", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/28514ddab4ae9eef99cbc31b97419d9dbcbc5899/comments", "author": null, "committer": null, "parents": [{"sha": "17a819cb0d6becdfe32f6b26164fb14b77d96369", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/17a819cb0d6becdfe32f6b26164fb14b77d96369", "html_url": "https://github.com/Rust-GCC/gccrs/commit/17a819cb0d6becdfe32f6b26164fb14b77d96369"}], "stats": {"total": 284, "additions": 212, "deletions": 72}, "files": [{"sha": "963320cec731996bc153b3b3906e2083fcdd57c2", "filename": "gcc/ChangeLog", "status": "modified", "additions": 47, "deletions": 0, "changes": 47, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/28514ddab4ae9eef99cbc31b97419d9dbcbc5899/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/28514ddab4ae9eef99cbc31b97419d9dbcbc5899/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=28514ddab4ae9eef99cbc31b97419d9dbcbc5899", "patch": "@@ -1,3 +1,50 @@\n+2013-07-23  Yufeng Zhang  <yufeng.zhang@arm.com>\n+\n+\t* config/aarch64/aarch64.c (POINTER_BYTES): New define.\n+\t(aarch64_load_symref_appropriately): In the case of\n+\tSYMBOL_SMALL_ABSOLUTE, use the mode of 'dest' instead of Pmode\n+\tto generate new rtx; likewise to the case of SYMBOL_SMALL_GOT.\n+\t(aarch64_expand_mov_immediate): In the case of SYMBOL_FORCE_TO_MEM,\n+\tchange to pass 'ptr_mode' to force_const_mem and zero-extend 'mem'\n+\tif 'mode' doesn't equal to 'ptr_mode'.\n+\t(aarch64_output_mi_thunk): Add an assertion on the alignment of\n+\t'vcall_offset'; change to call aarch64_emit_move differently depending\n+\ton whether 'Pmode' equals to 'ptr_mode' or not; use 'POINTER_BYTES'\n+\tto calculate the upper bound of 'vcall_offset'.\n+\t(aarch64_cannot_force_const_mem): Change to also return true if\n+\tmode != ptr_mode.\n+\t(aarch64_legitimize_reload_address): In the case of large\n+\tdisplacements, add new local variable 'xmode' and an assertion\n+\tbased on it; change to use 'xmode' to generate the new rtx and\n+\treload.\n+\t(aarch64_asm_trampoline_template): Change to generate the template\n+\tdifferently depending on TARGET_ILP32 or not; change to use\n+\t'POINTER_BYTES' in the argument passed to assemble_aligned_integer.\n+\t(aarch64_trampoline_size): Removed.\n+\t(aarch64_trampoline_init): Add new local constant 'tramp_code_sz'\n+\tand replace immediate literals with it.  Change to use 'ptr_mode'\n+\tinstead of 'DImode' and call convert_memory_address if the mode\n+\tof 'fnaddr' doesn't equal to 'ptr_mode'.\n+\t(aarch64_elf_asm_constructor): Change to use assemble_aligned_integer\n+\tto output symbol.\n+\t(aarch64_elf_asm_destructor): Likewise.\n+\t* config/aarch64/aarch64.h (TRAMPOLINE_SIZE): Change to be dependent\n+\ton TARGET_ILP32 instead of aarch64_trampoline_size.\n+\t* config/aarch64/aarch64.md (movsi_aarch64): Add new alternatives\n+\tof 'mov' between WSP and W registers as well as 'adr' and 'adrp'.\n+\t(loadwb_pair<GPI:mode>_<PTR:mode>): Rename to ...\n+\t(loadwb_pair<GPI:mode>_<P:mode>): ... this.  Replace PTR with P.\n+\t(storewb_pair<GPI:mode>_<PTR:mode>): Likewise; rename to ...\n+\t(storewb_pair<GPI:mode>_<P:mode>): ... this.\n+\t(add_losym): Change to 'define_expand' and call gen_add_losym_<mode>\n+\tdepending on the value of 'mode'.\n+\t(add_losym_<mode>): New.\n+\t(ldr_got_small_<mode>): New, based on ldr_got_small.\n+\t(ldr_got_small): Remove.\n+\t(ldr_got_small_sidi): New.\n+\t* config/aarch64/iterators.md (P): New.\n+\t(PTR): Change to 'ptr_mode' in the condition.\n+\n 2013-07-23  Yufeng Zhang  <yufeng.zhang@arm.com>\n \n \t* config.gcc (aarch64*-*-*): Support --with-abi."}, {"sha": "da041f8e3f89c86ad7b43d6cfc82bdc2b263ef4a", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 93, "deletions": 39, "changes": 132, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/28514ddab4ae9eef99cbc31b97419d9dbcbc5899/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/28514ddab4ae9eef99cbc31b97419d9dbcbc5899/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=28514ddab4ae9eef99cbc31b97419d9dbcbc5899", "patch": "@@ -48,6 +48,9 @@\n #include \"cfgloop.h\"\n #include \"tree-vectorizer.h\"\n \n+/* Defined for convenience.  */\n+#define POINTER_BYTES (POINTER_SIZE / BITS_PER_UNIT)\n+\n /* Classifies an address.\n \n    ADDRESS_REG_IMM\n@@ -543,13 +546,16 @@ aarch64_load_symref_appropriately (rtx dest, rtx imm,\n     {\n     case SYMBOL_SMALL_ABSOLUTE:\n       {\n+\t/* In ILP32, the mode of dest can be either SImode or DImode.  */\n \trtx tmp_reg = dest;\n+\tenum machine_mode mode = GET_MODE (dest);\n+\n+\tgcc_assert (mode == Pmode || mode == ptr_mode);\n+\n \tif (can_create_pseudo_p ())\n-\t  {\n-\t    tmp_reg =  gen_reg_rtx (Pmode);\n-\t  }\n+\t  tmp_reg = gen_reg_rtx (mode);\n \n-\temit_move_insn (tmp_reg, gen_rtx_HIGH (Pmode, imm));\n+\temit_move_insn (tmp_reg, gen_rtx_HIGH (mode, imm));\n \temit_insn (gen_add_losym (dest, tmp_reg, imm));\n \treturn;\n       }\n@@ -560,11 +566,33 @@ aarch64_load_symref_appropriately (rtx dest, rtx imm,\n \n     case SYMBOL_SMALL_GOT:\n       {\n+\t/* In ILP32, the mode of dest can be either SImode or DImode,\n+\t   while the got entry is always of SImode size.  The mode of\n+\t   dest depends on how dest is used: if dest is assigned to a\n+\t   pointer (e.g. in the memory), it has SImode; it may have\n+\t   DImode if dest is dereferenced to access the memeory.\n+\t   This is why we have to handle three different ldr_got_small\n+\t   patterns here (two patterns for ILP32).  */\n \trtx tmp_reg = dest;\n+\tenum machine_mode mode = GET_MODE (dest);\n+\n \tif (can_create_pseudo_p ())\n-\t  tmp_reg =  gen_reg_rtx (Pmode);\n-\temit_move_insn (tmp_reg, gen_rtx_HIGH (Pmode, imm));\n-\temit_insn (gen_ldr_got_small (dest, tmp_reg, imm));\n+\t  tmp_reg = gen_reg_rtx (mode);\n+\n+\temit_move_insn (tmp_reg, gen_rtx_HIGH (mode, imm));\n+\tif (mode == ptr_mode)\n+\t  {\n+\t    if (mode == DImode)\n+\t      emit_insn (gen_ldr_got_small_di (dest, tmp_reg, imm));\n+\t    else\n+\t      emit_insn (gen_ldr_got_small_si (dest, tmp_reg, imm));\n+\t  }\n+\telse\n+\t  {\n+\t    gcc_assert (mode == Pmode);\n+\t    emit_insn (gen_ldr_got_small_sidi (dest, tmp_reg, imm));\n+\t  }\n+\n \treturn;\n       }\n \n@@ -885,8 +913,10 @@ aarch64_expand_mov_immediate (rtx dest, rtx imm)\n \t      aarch64_emit_move (dest, base);\n \t      return;\n \t    }\n-\t  mem = force_const_mem (mode, imm);\n+\t  mem = force_const_mem (ptr_mode, imm);\n \t  gcc_assert (mem);\n+\t  if (mode != ptr_mode)\n+\t    mem = gen_rtx_ZERO_EXTEND (mode, mem);\n \t  emit_insn (gen_rtx_SET (VOIDmode, dest, mem));\n \t  return;\n \n@@ -2518,7 +2548,7 @@ aarch64_output_mi_thunk (FILE *file, tree thunk ATTRIBUTE_UNUSED,\n     aarch64_add_constant (this_regno, IP1_REGNUM, delta);\n   else\n     {\n-      gcc_assert ((vcall_offset & 0x7) == 0);\n+      gcc_assert ((vcall_offset & (POINTER_BYTES - 1)) == 0);\n \n       this_rtx = gen_rtx_REG (Pmode, this_regno);\n       temp0 = gen_rtx_REG (Pmode, IP0_REGNUM);\n@@ -2534,17 +2564,28 @@ aarch64_output_mi_thunk (FILE *file, tree thunk ATTRIBUTE_UNUSED,\n \t    aarch64_add_constant (this_regno, IP1_REGNUM, delta);\n \t}\n \n-      aarch64_emit_move (temp0, gen_rtx_MEM (Pmode, addr));\n+      if (Pmode == ptr_mode)\n+\taarch64_emit_move (temp0, gen_rtx_MEM (ptr_mode, addr));\n+      else\n+\taarch64_emit_move (temp0,\n+\t\t\t   gen_rtx_ZERO_EXTEND (Pmode,\n+\t\t\t\t\t\tgen_rtx_MEM (ptr_mode, addr)));\n \n-      if (vcall_offset >= -256 && vcall_offset < 32768)\n+      if (vcall_offset >= -256 && vcall_offset < 4096 * POINTER_BYTES)\n \t  addr = plus_constant (Pmode, temp0, vcall_offset);\n       else\n \t{\n \t  aarch64_build_constant (IP1_REGNUM, vcall_offset);\n \t  addr = gen_rtx_PLUS (Pmode, temp0, temp1);\n \t}\n \n-      aarch64_emit_move (temp1, gen_rtx_MEM (Pmode,addr));\n+      if (Pmode == ptr_mode)\n+\taarch64_emit_move (temp1, gen_rtx_MEM (ptr_mode,addr));\n+      else\n+\taarch64_emit_move (temp1,\n+\t\t\t   gen_rtx_SIGN_EXTEND (Pmode,\n+\t\t\t\t\t\tgen_rtx_MEM (ptr_mode, addr)));\n+\n       emit_insn (gen_add2_insn (this_rtx, temp1));\n     }\n \n@@ -2722,8 +2763,15 @@ aarch64_cannot_force_const_mem (enum machine_mode mode ATTRIBUTE_UNUSED, rtx x)\n \n   split_const (x, &base, &offset);\n   if (GET_CODE (base) == SYMBOL_REF || GET_CODE (base) == LABEL_REF)\n-    return (aarch64_classify_symbol (base, SYMBOL_CONTEXT_ADR)\n-\t    != SYMBOL_FORCE_TO_MEM);\n+    {\n+      if (aarch64_classify_symbol (base, SYMBOL_CONTEXT_ADR)\n+\t  != SYMBOL_FORCE_TO_MEM)\n+\treturn true;\n+      else\n+\t/* Avoid generating a 64-bit relocation in ILP32; leave\n+\t   to aarch64_expand_mov_immediate to handle it properly.  */\n+\treturn mode != ptr_mode;\n+    }\n \n   return aarch64_tls_referenced_p (x);\n }\n@@ -3918,6 +3966,10 @@ aarch64_legitimize_reload_address (rtx *x_p,\n       HOST_WIDE_INT high = val - low;\n       HOST_WIDE_INT offs;\n       rtx cst;\n+      enum machine_mode xmode = GET_MODE (x);\n+\n+      /* In ILP32, xmode can be either DImode or SImode.  */\n+      gcc_assert (xmode == DImode || xmode == SImode);\n \n       /* Reload non-zero BLKmode offsets.  This is because we cannot ascertain\n \t BLKmode alignment.  */\n@@ -3951,16 +4003,16 @@ aarch64_legitimize_reload_address (rtx *x_p,\n \n       cst = GEN_INT (high);\n       if (!aarch64_uimm12_shift (high))\n-\tcst = force_const_mem (Pmode, cst);\n+\tcst = force_const_mem (xmode, cst);\n \n       /* Reload high part into base reg, leaving the low part\n \t in the mem instruction.  */\n-      x = gen_rtx_PLUS (Pmode,\n-\t\t\tgen_rtx_PLUS (Pmode, XEXP (x, 0), cst),\n+      x = gen_rtx_PLUS (xmode,\n+\t\t\tgen_rtx_PLUS (xmode, XEXP (x, 0), cst),\n \t\t\tGEN_INT (low));\n \n       push_reload (XEXP (x, 0), NULL_RTX, &XEXP (x, 0), NULL,\n-\t\t   BASE_REG_CLASS, Pmode, VOIDmode, 0, 0,\n+\t\t   BASE_REG_CLASS, xmode, VOIDmode, 0, 0,\n \t\t   opnum, (enum reload_type) type);\n       return x;\n     }\n@@ -4108,41 +4160,47 @@ aarch64_return_addr (int count, rtx frame ATTRIBUTE_UNUSED)\n static void\n aarch64_asm_trampoline_template (FILE *f)\n {\n-  asm_fprintf (f, \"\\tldr\\t%s, .+16\\n\", reg_names [IP1_REGNUM]);\n-  asm_fprintf (f, \"\\tldr\\t%s, .+20\\n\", reg_names [STATIC_CHAIN_REGNUM]);\n+  if (TARGET_ILP32)\n+    {\n+      asm_fprintf (f, \"\\tldr\\tw%d, .+16\\n\", IP1_REGNUM - R0_REGNUM);\n+      asm_fprintf (f, \"\\tldr\\tw%d, .+16\\n\", STATIC_CHAIN_REGNUM - R0_REGNUM);\n+    }\n+  else\n+    {\n+      asm_fprintf (f, \"\\tldr\\t%s, .+16\\n\", reg_names [IP1_REGNUM]);\n+      asm_fprintf (f, \"\\tldr\\t%s, .+20\\n\", reg_names [STATIC_CHAIN_REGNUM]);\n+    }\n   asm_fprintf (f, \"\\tbr\\t%s\\n\", reg_names [IP1_REGNUM]);\n   assemble_aligned_integer (4, const0_rtx);\n-  assemble_aligned_integer (UNITS_PER_WORD, const0_rtx);\n-  assemble_aligned_integer (UNITS_PER_WORD, const0_rtx);\n-}\n-\n-unsigned\n-aarch64_trampoline_size (void)\n-{\n-  return 32;  /* 3 insns + padding + 2 dwords.  */\n+  assemble_aligned_integer (POINTER_BYTES, const0_rtx);\n+  assemble_aligned_integer (POINTER_BYTES, const0_rtx);\n }\n \n static void\n aarch64_trampoline_init (rtx m_tramp, tree fndecl, rtx chain_value)\n {\n   rtx fnaddr, mem, a_tramp;\n+  const int tramp_code_sz = 16;\n \n   /* Don't need to copy the trailing D-words, we fill those in below.  */\n   emit_block_move (m_tramp, assemble_trampoline_template (),\n-\t\t   GEN_INT (TRAMPOLINE_SIZE - 16), BLOCK_OP_NORMAL);\n-  mem = adjust_address (m_tramp, DImode, 16);\n+\t\t   GEN_INT (tramp_code_sz), BLOCK_OP_NORMAL);\n+  mem = adjust_address (m_tramp, ptr_mode, tramp_code_sz);\n   fnaddr = XEXP (DECL_RTL (fndecl), 0);\n+  if (GET_MODE (fnaddr) != ptr_mode)\n+    fnaddr = convert_memory_address (ptr_mode, fnaddr);\n   emit_move_insn (mem, fnaddr);\n \n-  mem = adjust_address (m_tramp, DImode, 24);\n+  mem = adjust_address (m_tramp, ptr_mode, tramp_code_sz + POINTER_BYTES);\n   emit_move_insn (mem, chain_value);\n \n   /* XXX We should really define a \"clear_cache\" pattern and use\n      gen_clear_cache().  */\n   a_tramp = XEXP (m_tramp, 0);\n   emit_library_call (gen_rtx_SYMBOL_REF (Pmode, \"__clear_cache\"),\n-\t\t     LCT_NORMAL, VOIDmode, 2, a_tramp, Pmode,\n-\t\t     plus_constant (Pmode, a_tramp, TRAMPOLINE_SIZE), Pmode);\n+\t\t     LCT_NORMAL, VOIDmode, 2, a_tramp, ptr_mode,\n+\t\t     plus_constant (ptr_mode, a_tramp, TRAMPOLINE_SIZE),\n+\t\t     ptr_mode);\n }\n \n static unsigned char\n@@ -4197,9 +4255,7 @@ aarch64_elf_asm_constructor (rtx symbol, int priority)\n       s = get_section (buf, SECTION_WRITE, NULL);\n       switch_to_section (s);\n       assemble_align (POINTER_SIZE);\n-      fputs (\"\\t.dword\\t\", asm_out_file);\n-      output_addr_const (asm_out_file, symbol);\n-      fputc ('\\n', asm_out_file);\n+      assemble_aligned_integer (POINTER_BYTES, symbol);\n     }\n }\n \n@@ -4216,9 +4272,7 @@ aarch64_elf_asm_destructor (rtx symbol, int priority)\n       s = get_section (buf, SECTION_WRITE, NULL);\n       switch_to_section (s);\n       assemble_align (POINTER_SIZE);\n-      fputs (\"\\t.dword\\t\", asm_out_file);\n-      output_addr_const (asm_out_file, symbol);\n-      fputc ('\\n', asm_out_file);\n+      assemble_aligned_integer (POINTER_BYTES, symbol);\n     }\n }\n "}, {"sha": "413f97de200f8afea74837d9d4775d95b246e0f3", "filename": "gcc/config/aarch64/aarch64.h", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/28514ddab4ae9eef99cbc31b97419d9dbcbc5899/gcc%2Fconfig%2Faarch64%2Faarch64.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/28514ddab4ae9eef99cbc31b97419d9dbcbc5899/gcc%2Fconfig%2Faarch64%2Faarch64.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.h?ref=28514ddab4ae9eef99cbc31b97419d9dbcbc5899", "patch": "@@ -740,7 +740,8 @@ do {\t\t\t\t\t\t\t\t\t     \\\n \n #define RETURN_ADDR_RTX aarch64_return_addr\n \n-#define TRAMPOLINE_SIZE\taarch64_trampoline_size ()\n+/* 3 insns + padding + 2 pointer-sized entries.  */\n+#define TRAMPOLINE_SIZE\t(TARGET_ILP32 ? 24 : 32)\n \n /* Trampolines contain dwords, so must be dword aligned.  */\n #define TRAMPOLINE_ALIGNMENT 64"}, {"sha": "233014eb43630eb877e5dcfcccd30191b3909bbb", "filename": "gcc/config/aarch64/aarch64.md", "status": "modified", "additions": 63, "deletions": 31, "changes": 94, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/28514ddab4ae9eef99cbc31b97419d9dbcbc5899/gcc%2Fconfig%2Faarch64%2Faarch64.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/28514ddab4ae9eef99cbc31b97419d9dbcbc5899/gcc%2Fconfig%2Faarch64%2Faarch64.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.md?ref=28514ddab4ae9eef99cbc31b97419d9dbcbc5899", "patch": "@@ -827,23 +827,27 @@\n )\n \n (define_insn \"*movsi_aarch64\"\n-  [(set (match_operand:SI 0 \"nonimmediate_operand\" \"=r,r,r,*w,m,  m,*w, r,*w\")\n-\t(match_operand:SI 1 \"aarch64_mov_operand\"  \" r,M,m, m,rZ,*w,rZ,*w,*w\"))]\n+  [(set (match_operand:SI 0 \"nonimmediate_operand\" \"=r,k,r,r,r,*w,m,  m,r,r  ,*w, r,*w\")\n+\t(match_operand:SI 1 \"aarch64_mov_operand\"  \" r,r,k,M,m, m,rZ,*w,S,Ush,rZ,*w,*w\"))]\n   \"(register_operand (operands[0], SImode)\n     || aarch64_reg_or_zero (operands[1], SImode))\"\n   \"@\n+   mov\\\\t%w0, %w1\n+   mov\\\\t%w0, %w1\n    mov\\\\t%w0, %w1\n    mov\\\\t%w0, %1\n    ldr\\\\t%w0, %1\n    ldr\\\\t%s0, %1\n    str\\\\t%w1, %0\n    str\\\\t%s1, %0\n+   adr\\\\t%x0, %a1\n+   adrp\\\\t%x0, %A1\n    fmov\\\\t%s0, %w1\n    fmov\\\\t%w0, %s1\n    fmov\\\\t%s0, %s1\"\n-  [(set_attr \"v8type\" \"move,alu,load1,load1,store1,store1,fmov,fmov,fmov\")\n+  [(set_attr \"v8type\" \"move,move,move,alu,load1,load1,store1,store1,adr,adr,fmov,fmov,fmov\")\n    (set_attr \"mode\" \"SI\")\n-   (set_attr \"fp\" \"*,*,*,yes,*,yes,yes,yes,yes\")]\n+   (set_attr \"fp\" \"*,*,*,*,*,yes,*,yes,*,*,yes,yes,yes\")]\n )\n \n (define_insn \"*movdi_aarch64\"\n@@ -1108,17 +1112,17 @@\n \n ;; Load pair with writeback.  This is primarily used in function epilogues\n ;; when restoring [fp,lr]\n-(define_insn \"loadwb_pair<GPI:mode>_<PTR:mode>\"\n+(define_insn \"loadwb_pair<GPI:mode>_<P:mode>\"\n   [(parallel\n-    [(set (match_operand:PTR 0 \"register_operand\" \"=k\")\n-          (plus:PTR (match_operand:PTR 1 \"register_operand\" \"0\")\n-                  (match_operand:PTR 4 \"const_int_operand\" \"n\")))\n+    [(set (match_operand:P 0 \"register_operand\" \"=k\")\n+          (plus:P (match_operand:P 1 \"register_operand\" \"0\")\n+                  (match_operand:P 4 \"const_int_operand\" \"n\")))\n      (set (match_operand:GPI 2 \"register_operand\" \"=r\")\n-          (mem:GPI (plus:PTR (match_dup 1)\n+          (mem:GPI (plus:P (match_dup 1)\n                    (match_dup 4))))\n      (set (match_operand:GPI 3 \"register_operand\" \"=r\")\n-          (mem:GPI (plus:PTR (match_dup 1)\n-                   (match_operand:PTR 5 \"const_int_operand\" \"n\"))))])]\n+          (mem:GPI (plus:P (match_dup 1)\n+                   (match_operand:P 5 \"const_int_operand\" \"n\"))))])]\n   \"INTVAL (operands[5]) == INTVAL (operands[4]) + GET_MODE_SIZE (<GPI:MODE>mode)\"\n   \"ldp\\\\t%<w>2, %<w>3, [%1], %4\"\n   [(set_attr \"v8type\" \"load2\")\n@@ -1127,16 +1131,16 @@\n \n ;; Store pair with writeback.  This is primarily used in function prologues\n ;; when saving [fp,lr]\n-(define_insn \"storewb_pair<GPI:mode>_<PTR:mode>\"\n+(define_insn \"storewb_pair<GPI:mode>_<P:mode>\"\n   [(parallel\n-    [(set (match_operand:PTR 0 \"register_operand\" \"=&k\")\n-          (plus:PTR (match_operand:PTR 1 \"register_operand\" \"0\")\n-                  (match_operand:PTR 4 \"const_int_operand\" \"n\")))\n-     (set (mem:GPI (plus:PTR (match_dup 0)\n+    [(set (match_operand:P 0 \"register_operand\" \"=&k\")\n+          (plus:P (match_operand:P 1 \"register_operand\" \"0\")\n+                  (match_operand:P 4 \"const_int_operand\" \"n\")))\n+     (set (mem:GPI (plus:P (match_dup 0)\n                    (match_dup 4)))\n           (match_operand:GPI 2 \"register_operand\" \"r\"))\n-     (set (mem:GPI (plus:PTR (match_dup 0)\n-                   (match_operand:PTR 5 \"const_int_operand\" \"n\")))\n+     (set (mem:GPI (plus:P (match_dup 0)\n+                   (match_operand:P 5 \"const_int_operand\" \"n\")))\n           (match_operand:GPI 3 \"register_operand\" \"r\"))])]\n   \"INTVAL (operands[5]) == INTVAL (operands[4]) + GET_MODE_SIZE (<GPI:MODE>mode)\"\n   \"stp\\\\t%<w>2, %<w>3, [%0, %4]!\"\n@@ -3729,25 +3733,53 @@\n ;; and lo_sum's to be used with the labels defining the jump tables in\n ;; rodata section.\n \n-(define_insn \"add_losym\"\n-  [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n-\t(lo_sum:DI (match_operand:DI 1 \"register_operand\" \"r\")\n-\t\t   (match_operand 2 \"aarch64_valid_symref\" \"S\")))]\n+(define_expand \"add_losym\"\n+  [(set (match_operand 0 \"register_operand\" \"=r\")\n+\t(lo_sum (match_operand 1 \"register_operand\" \"r\")\n+\t\t(match_operand 2 \"aarch64_valid_symref\" \"S\")))]\n   \"\"\n-  \"add\\\\t%0, %1, :lo12:%a2\"\n+{\n+  enum machine_mode mode = GET_MODE (operands[0]);\n+\n+  emit_insn ((mode == DImode\n+\t      ? gen_add_losym_di\n+\t      : gen_add_losym_si) (operands[0],\n+\t\t\t\t   operands[1],\n+\t\t\t\t   operands[2]));\n+  DONE;\n+})\n+\n+(define_insn \"add_losym_<mode>\"\n+  [(set (match_operand:P 0 \"register_operand\" \"=r\")\n+\t(lo_sum:P (match_operand:P 1 \"register_operand\" \"r\")\n+\t\t  (match_operand 2 \"aarch64_valid_symref\" \"S\")))]\n+  \"\"\n+  \"add\\\\t%<w>0, %<w>1, :lo12:%a2\"\n   [(set_attr \"v8type\" \"alu\")\n-   (set_attr \"mode\" \"DI\")]\n+   (set_attr \"mode\" \"<MODE>\")]\n+)\n \n+(define_insn \"ldr_got_small_<mode>\"\n+  [(set (match_operand:PTR 0 \"register_operand\" \"=r\")\n+\t(unspec:PTR [(mem:PTR (lo_sum:PTR\n+\t\t\t      (match_operand:PTR 1 \"register_operand\" \"r\")\n+\t\t\t      (match_operand:PTR 2 \"aarch64_valid_symref\" \"S\")))]\n+\t\t    UNSPEC_GOTSMALLPIC))]\n+  \"\"\n+  \"ldr\\\\t%<w>0, [%1, #:got_lo12:%a2]\"\n+  [(set_attr \"v8type\" \"load1\")\n+   (set_attr \"mode\" \"<MODE>\")]\n )\n \n-(define_insn \"ldr_got_small\"\n+(define_insn \"ldr_got_small_sidi\"\n   [(set (match_operand:DI 0 \"register_operand\" \"=r\")\n-\t(unspec:DI [(mem:DI (lo_sum:DI\n-\t\t\t      (match_operand:DI 1 \"register_operand\" \"r\")\n-\t\t\t      (match_operand:DI 2 \"aarch64_valid_symref\" \"S\")))]\n-\t\t   UNSPEC_GOTSMALLPIC))]\n-  \"\"\n-  \"ldr\\\\t%0, [%1, #:got_lo12:%a2]\"\n+\t(zero_extend:DI\n+\t (unspec:SI [(mem:SI (lo_sum:DI\n+\t\t\t     (match_operand:DI 1 \"register_operand\" \"r\")\n+\t\t\t     (match_operand:DI 2 \"aarch64_valid_symref\" \"S\")))]\n+\t\t    UNSPEC_GOTSMALLPIC)))]\n+  \"TARGET_ILP32\"\n+  \"ldr\\\\t%w0, [%1, #:got_lo12:%a2]\"\n   [(set_attr \"v8type\" \"load1\")\n    (set_attr \"mode\" \"DI\")]\n )"}, {"sha": "76ff15d9a01dfdc0cd544ca6d3f828f77fda49b2", "filename": "gcc/config/aarch64/iterators.md", "status": "modified", "additions": 7, "deletions": 1, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/28514ddab4ae9eef99cbc31b97419d9dbcbc5899/gcc%2Fconfig%2Faarch64%2Fiterators.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/28514ddab4ae9eef99cbc31b97419d9dbcbc5899/gcc%2Fconfig%2Faarch64%2Fiterators.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Fiterators.md?ref=28514ddab4ae9eef99cbc31b97419d9dbcbc5899", "patch": "@@ -76,9 +76,15 @@\n ;; Vector modes for moves.\n (define_mode_iterator VDQM [V8QI V16QI V4HI V8HI V2SI V4SI])\n \n+;; This mode iterator allows :P to be used for patterns that operate on\n+;; addresses in different modes.  In LP64, only DI will match, while in\n+;; ILP32, either can match.\n+(define_mode_iterator P [(SI \"ptr_mode == SImode || Pmode == SImode\")\n+\t\t\t (DI \"ptr_mode == DImode || Pmode == DImode\")])\n+\n ;; This mode iterator allows :PTR to be used for patterns that operate on\n ;; pointer-sized quantities.  Exactly one of the two alternatives will match.\n-(define_mode_iterator PTR [(SI \"Pmode == SImode\") (DI \"Pmode == DImode\")])\n+(define_mode_iterator PTR [(SI \"ptr_mode == SImode\") (DI \"ptr_mode == DImode\")])\n \n ;; Vector Float modes.\n (define_mode_iterator VDQF [V2SF V4SF V2DF])"}]}