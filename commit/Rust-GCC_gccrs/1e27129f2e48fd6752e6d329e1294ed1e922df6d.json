{"sha": "1e27129f2e48fd6752e6d329e1294ed1e922df6d", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MWUyNzEyOWYyZTQ4ZmQ2NzUyZTZkMzI5ZTEyOTRlZDFlOTIyZGY2ZA==", "commit": {"author": {"name": "H.J. Lu", "email": "hjl@gcc.gnu.org", "date": "2010-10-13T21:20:07Z"}, "committer": {"name": "H.J. Lu", "email": "hjl@gcc.gnu.org", "date": "2010-10-13T21:20:07Z"}, "message": "Addd 256bit AVX vectorizer patterns.\n\n2010-10-13  H.J. Lu  <hongjiu.lu@intel.com>\n\n\t* config/i386/i386.c (ix86_build_const_vector): Check vector\n\tmode instead of scalar mode.\n\t(ix86_build_signbit_mask): Likewise.\n\t(ix86_expand_fp_absneg_operator): Updated.\n\t(ix86_expand_copysign): Likewise.\n\t(ix86_expand_int_vcond): Likewise.\n\t(ix86_emit_swdivsf): Likewise.\n\t(ix86_sse_copysign_to_positive): Likewise.\n\t(ix86_expand_sse_fabs): Likewise.\n\t* config/i386/i386.md (fixuns_trunc<mode>si2): Likewise.\n\t* config/i386/sse.md (copysign<mode>3): Likewise.\n\t(sse2_cvtudq2ps): Likewise.\n\t(vec_unpacku_float_hi_v4si): Likewise.\n\t(vec_unpacku_float_lo_v4si): Likewise.\n\n\t* config/i386/i386.c (ix86_builtins): Add\n\tIX86_BUILTIN_CPYSGNPS256 and IX86_BUILTIN_CPYSGNPD256.\n\t(bdesc_args): Likewise.\n\t(ix86_builtin_vectorized_function): Support \n\tIX86_BUILTIN_CPYSGNPS256, IX86_BUILTIN_CPYSGNPD256,\n\tIX86_BUILTIN_SQRTPD256, IX86_BUILTIN_SQRTPS_NR256,\n\tand IX86_BUILTIN_CVTPS2DQ256.\n\t(ix86_builtin_reciprocal): Support IX86_BUILTIN_SQRTPS_NR256.\n\n\t* config/i386/sse.md (STORENT_MODE): New.\n\t(VEC_FLOAT_MODE): Likewise.\n\t(VEC_EXTRACT_MODE): Likewise.\n\t(*avx_cvtdq2pd256_2): Likewise.\n\t(vec_pack_trunc_v4df): Likewise.\n\t(vec_interleave_highv8sf): Likewise.\n\t(vec_interleave_lowv8sf): Likewise.\n\t(storent<mode>): Macroized.\n\t(<code><mode>2: absneg): Likewise.\n\t(copysign<mode>3): Likewise.\n\t(vec_extract<mode>): Likewise.\n\n\tPR target/44180\n\t* config/i386/i386.c (expand_vec_perm_even_odd_1): Rewritten\n\tfor V8SFmode.\n\n2010-10-13  Richard Guenther  <rguenther@suse.de>\n\t    H.J. Lu  <hongjiu.lu@intel.com>\n\n\t* config/i386/sse.md (reduc_splus_v8sf): Add.\n\t(reduc_splus_v4df): Likewise.\n\t(vec_unpacks_hi_v8sf): Likewise.\n\t(vec_unpacks_lo_v8sf): Likewise.\n\t(*avx_cvtps2pd256_2): Likewise.\n\t(vec_unpacks_float_hi_v8si): Likewise.\n\t(vec_unpacks_float_lo_v8si): Likewise.\n\t(vec_interleave_highv4df): Likewise.\n\t(vec_interleave_lowv4df): Likewise.\n\nFrom-SVN: r165436", "tree": {"sha": "980dc27c04d33954d8e87fd53db2006b91b286cf", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/980dc27c04d33954d8e87fd53db2006b91b286cf"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/1e27129f2e48fd6752e6d329e1294ed1e922df6d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1e27129f2e48fd6752e6d329e1294ed1e922df6d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1e27129f2e48fd6752e6d329e1294ed1e922df6d", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1e27129f2e48fd6752e6d329e1294ed1e922df6d/comments", "author": null, "committer": null, "parents": [{"sha": "0d8485e009278fccd6f6faffc81726bfd6d83716", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0d8485e009278fccd6f6faffc81726bfd6d83716", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0d8485e009278fccd6f6faffc81726bfd6d83716"}], "stats": {"total": 596, "additions": 482, "deletions": 114}, "files": [{"sha": "cb6aa57add27fd98c34c0075ba6a36b84047a2f1", "filename": "gcc/ChangeLog", "status": "modified", "additions": 55, "deletions": 0, "changes": 55, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1e27129f2e48fd6752e6d329e1294ed1e922df6d/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1e27129f2e48fd6752e6d329e1294ed1e922df6d/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=1e27129f2e48fd6752e6d329e1294ed1e922df6d", "patch": "@@ -1,3 +1,58 @@\n+2010-10-13  H.J. Lu  <hongjiu.lu@intel.com>\n+\n+\t* config/i386/i386.c (ix86_build_const_vector): Check vector\n+\tmode instead of scalar mode.\n+\t(ix86_build_signbit_mask): Likewise.\n+\t(ix86_expand_fp_absneg_operator): Updated.\n+\t(ix86_expand_copysign): Likewise.\n+\t(ix86_expand_int_vcond): Likewise.\n+\t(ix86_emit_swdivsf): Likewise.\n+\t(ix86_sse_copysign_to_positive): Likewise.\n+\t(ix86_expand_sse_fabs): Likewise.\n+\t* config/i386/i386.md (fixuns_trunc<mode>si2): Likewise.\n+\t* config/i386/sse.md (copysign<mode>3): Likewise.\n+\t(sse2_cvtudq2ps): Likewise.\n+\t(vec_unpacku_float_hi_v4si): Likewise.\n+\t(vec_unpacku_float_lo_v4si): Likewise.\n+\n+\t* config/i386/i386.c (ix86_builtins): Add\n+\tIX86_BUILTIN_CPYSGNPS256 and IX86_BUILTIN_CPYSGNPD256.\n+\t(bdesc_args): Likewise.\n+\t(ix86_builtin_vectorized_function): Support \n+\tIX86_BUILTIN_CPYSGNPS256, IX86_BUILTIN_CPYSGNPD256,\n+\tIX86_BUILTIN_SQRTPD256, IX86_BUILTIN_SQRTPS_NR256,\n+\tand IX86_BUILTIN_CVTPS2DQ256.\n+\t(ix86_builtin_reciprocal): Support IX86_BUILTIN_SQRTPS_NR256.\n+\n+\t* config/i386/sse.md (STORENT_MODE): New.\n+\t(VEC_FLOAT_MODE): Likewise.\n+\t(VEC_EXTRACT_MODE): Likewise.\n+\t(*avx_cvtdq2pd256_2): Likewise.\n+\t(vec_pack_trunc_v4df): Likewise.\n+\t(vec_interleave_highv8sf): Likewise.\n+\t(vec_interleave_lowv8sf): Likewise.\n+\t(storent<mode>): Macroized.\n+\t(<code><mode>2: absneg): Likewise.\n+\t(copysign<mode>3): Likewise.\n+\t(vec_extract<mode>): Likewise.\n+\n+\tPR target/44180\n+\t* config/i386/i386.c (expand_vec_perm_even_odd_1): Rewritten\n+\tfor V8SFmode.\n+\n+2010-10-13  Richard Guenther  <rguenther@suse.de>\n+\t    H.J. Lu  <hongjiu.lu@intel.com>\n+\n+\t* config/i386/sse.md (reduc_splus_v8sf): Add.\n+\t(reduc_splus_v4df): Likewise.\n+\t(vec_unpacks_hi_v8sf): Likewise.\n+\t(vec_unpacks_lo_v8sf): Likewise.\n+\t(*avx_cvtps2pd256_2): Likewise.\n+\t(vec_unpacks_float_hi_v8si): Likewise.\n+\t(vec_unpacks_float_lo_v8si): Likewise.\n+\t(vec_interleave_highv4df): Likewise.\n+\t(vec_interleave_lowv4df): Likewise.\n+\n 2010-10-13  Richard Guenther  <rguenther@suse.de>\n \n \tPR objc/45878"}, {"sha": "0987b4597bff6c055060530438f664539b178aa3", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 142, "deletions": 71, "changes": 213, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1e27129f2e48fd6752e6d329e1294ed1e922df6d/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1e27129f2e48fd6752e6d329e1294ed1e922df6d/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=1e27129f2e48fd6752e6d329e1294ed1e922df6d", "patch": "@@ -15752,25 +15752,44 @@ ix86_build_const_vector (enum machine_mode mode, bool vect, rtx value)\n   rtvec v;\n   switch (mode)\n     {\n-    case SImode:\n+    case V4SImode:\n       gcc_assert (vect);\n       v = gen_rtvec (4, value, value, value, value);\n       return gen_rtx_CONST_VECTOR (V4SImode, v);\n \n-    case DImode:\n+    case V2DImode:\n       gcc_assert (vect);\n       v = gen_rtvec (2, value, value);\n       return gen_rtx_CONST_VECTOR (V2DImode, v);\n \n-    case SFmode:\n+    case V8SFmode:\n+      if (vect)\n+\tv = gen_rtvec (8, value, value, value, value,\n+\t\t       value, value, value, value);\n+      else\n+\tv = gen_rtvec (8, value, CONST0_RTX (SFmode),\n+\t\t       CONST0_RTX (SFmode), CONST0_RTX (SFmode),\n+\t\t       CONST0_RTX (SFmode), CONST0_RTX (SFmode),\n+\t\t       CONST0_RTX (SFmode), CONST0_RTX (SFmode));\n+      return gen_rtx_CONST_VECTOR (V8SFmode, v);\n+\n+    case V4SFmode:\n       if (vect)\n \tv = gen_rtvec (4, value, value, value, value);\n       else\n \tv = gen_rtvec (4, value, CONST0_RTX (SFmode),\n \t\t       CONST0_RTX (SFmode), CONST0_RTX (SFmode));\n       return gen_rtx_CONST_VECTOR (V4SFmode, v);\n \n-    case DFmode:\n+    case V4DFmode:\n+      if (vect)\n+\tv = gen_rtvec (4, value, value, value, value);\n+      else\n+\tv = gen_rtvec (4, value, CONST0_RTX (DFmode),\n+\t\t       CONST0_RTX (DFmode), CONST0_RTX (DFmode));\n+      return gen_rtx_CONST_VECTOR (V4DFmode, v);\n+\n+    case V2DFmode:\n       if (vect)\n \tv = gen_rtvec (2, value, value);\n       else\n@@ -15800,17 +15819,21 @@ ix86_build_signbit_mask (enum machine_mode mode, bool vect, bool invert)\n   /* Find the sign bit, sign extended to 2*HWI.  */\n   switch (mode)\n     {\n-    case SImode:\n-    case SFmode:\n+    case V4SImode:\n+    case V8SFmode:\n+    case V4SFmode:\n+      vec_mode = mode;\n+      mode = GET_MODE_INNER (mode);\n       imode = SImode;\n-      vec_mode = (mode == SImode) ? V4SImode : V4SFmode;\n       lo = 0x80000000, hi = lo < 0;\n       break;\n \n-    case DImode:\n-    case DFmode:\n+    case V2DImode:\n+    case V4DFmode:\n+    case V2DFmode:\n+      vec_mode = mode;\n+      mode = GET_MODE_INNER (mode);\n       imode = DImode;\n-      vec_mode = (mode == DImode) ? V2DImode : V2DFmode;\n       if (HOST_BITS_PER_WIDE_INT >= 64)\n \tlo = (HOST_WIDE_INT)1 << shift, hi = -1;\n       else\n@@ -15864,7 +15887,7 @@ ix86_build_signbit_mask (enum machine_mode mode, bool vect, bool invert)\n   if (vec_mode == VOIDmode)\n     return force_reg (mode, mask);\n \n-  v = ix86_build_const_vector (mode, vect, mask);\n+  v = ix86_build_const_vector (vec_mode, vect, mask);\n   return force_reg (vec_mode, v);\n }\n \n@@ -15877,22 +15900,25 @@ ix86_expand_fp_absneg_operator (enum rtx_code code, enum machine_mode mode,\n   rtx mask, set, use, clob, dst, src;\n   bool use_sse = false;\n   bool vector_mode = VECTOR_MODE_P (mode);\n-  enum machine_mode elt_mode = mode;\n+  enum machine_mode vmode = mode;\n \n   if (vector_mode)\n-    {\n-      elt_mode = GET_MODE_INNER (mode);\n-      use_sse = true;\n-    }\n+    use_sse = true;\n   else if (mode == TFmode)\n     use_sse = true;\n   else if (TARGET_SSE_MATH)\n-    use_sse = SSE_FLOAT_MODE_P (mode);\n+    {\n+      use_sse = SSE_FLOAT_MODE_P (mode);\n+      if (mode == SFmode)\n+\tvmode = V4SFmode;\n+      else if (mode == DFmode)\n+\tvmode = V2DFmode;\n+    }\n \n   /* NEG and ABS performed with SSE use bitwise mask operations.\n      Create the appropriate mask now.  */\n   if (use_sse)\n-    mask = ix86_build_signbit_mask (elt_mode, vector_mode, code == ABS);\n+    mask = ix86_build_signbit_mask (vmode, vector_mode, code == ABS);\n   else\n     mask = NULL_RTX;\n \n@@ -15926,7 +15952,7 @@ ix86_expand_fp_absneg_operator (enum rtx_code code, enum machine_mode mode,\n void\n ix86_expand_copysign (rtx operands[])\n {\n-  enum machine_mode mode;\n+  enum machine_mode mode, vmode;\n   rtx dest, op0, op1, mask, nmask;\n \n   dest = operands[0];\n@@ -15935,6 +15961,13 @@ ix86_expand_copysign (rtx operands[])\n \n   mode = GET_MODE (dest);\n \n+  if (mode == SFmode)\n+    vmode = V4SFmode;\n+  else if (mode == DFmode)\n+    vmode = V2DFmode;\n+  else\n+    vmode = mode;\n+\n   if (GET_CODE (op0) == CONST_DOUBLE)\n     {\n       rtx (*copysign_insn)(rtx, rtx, rtx, rtx);\n@@ -15944,23 +15977,19 @@ ix86_expand_copysign (rtx operands[])\n \n       if (mode == SFmode || mode == DFmode)\n \t{\n-\t  enum machine_mode vmode;\n-\n-\t  vmode = mode == SFmode ? V4SFmode : V2DFmode;\n-\n \t  if (op0 == CONST0_RTX (mode))\n \t    op0 = CONST0_RTX (vmode);\n \t  else\n \t    {\n-\t      rtx v = ix86_build_const_vector (mode, false, op0);\n+\t      rtx v = ix86_build_const_vector (vmode, false, op0);\n \n \t      op0 = force_reg (vmode, v);\n \t    }\n \t}\n       else if (op0 != CONST0_RTX (mode))\n \top0 = force_reg (mode, op0);\n \n-      mask = ix86_build_signbit_mask (mode, 0, 0);\n+      mask = ix86_build_signbit_mask (vmode, 0, 0);\n \n       if (mode == SFmode)\n \tcopysign_insn = gen_copysignsf3_const;\n@@ -15975,8 +16004,8 @@ ix86_expand_copysign (rtx operands[])\n     {\n       rtx (*copysign_insn)(rtx, rtx, rtx, rtx, rtx, rtx);\n \n-      nmask = ix86_build_signbit_mask (mode, 0, 1);\n-      mask = ix86_build_signbit_mask (mode, 0, 0);\n+      nmask = ix86_build_signbit_mask (vmode, 0, 1);\n+      mask = ix86_build_signbit_mask (vmode, 0, 0);\n \n       if (mode == SFmode)\n \tcopysign_insn = gen_copysignsf3_var;\n@@ -17877,8 +17906,7 @@ ix86_expand_int_vcond (rtx operands[])\n \n \t\t  /* Subtract (-(INT MAX) - 1) from both operands to make\n \t\t     them signed.  */\n-\t\t  mask = ix86_build_signbit_mask (GET_MODE_INNER (mode),\n-\t\t\t\t\t\t  true, false);\n+\t\t  mask = ix86_build_signbit_mask (mode, true, false);\n \t\t  gen_sub3 = (mode == V4SImode\n \t\t\t      ? gen_subv4si3 : gen_subv2di3);\n \t\t  t1 = gen_reg_rtx (mode);\n@@ -22713,6 +22741,8 @@ enum ix86_builtins\n   /* Vectorizer support builtins.  */\n   IX86_BUILTIN_CPYSGNPS,\n   IX86_BUILTIN_CPYSGNPD,\n+  IX86_BUILTIN_CPYSGNPS256,\n+  IX86_BUILTIN_CPYSGNPD256,\n \n   IX86_BUILTIN_CVTUDQ2PS,\n \n@@ -23850,6 +23880,9 @@ static const struct builtin_description bdesc_args[] =\n   { OPTION_MASK_ISA_AVX, CODE_FOR_avx_movmskpd256, \"__builtin_ia32_movmskpd256\", IX86_BUILTIN_MOVMSKPD256, UNKNOWN, (int) INT_FTYPE_V4DF  },\n   { OPTION_MASK_ISA_AVX, CODE_FOR_avx_movmskps256, \"__builtin_ia32_movmskps256\", IX86_BUILTIN_MOVMSKPS256, UNKNOWN, (int) INT_FTYPE_V8SF },\n \n+  { OPTION_MASK_ISA_AVX, CODE_FOR_copysignv8sf3,  \"__builtin_ia32_copysignps256\", IX86_BUILTIN_CPYSGNPS256, UNKNOWN, (int) V8SF_FTYPE_V8SF_V8SF },\n+  { OPTION_MASK_ISA_AVX, CODE_FOR_copysignv4df3,  \"__builtin_ia32_copysignpd256\", IX86_BUILTIN_CPYSGNPD256, UNKNOWN, (int) V4DF_FTYPE_V4DF_V4DF },\n+\n   { OPTION_MASK_ISA_ABM, CODE_FOR_clzhi2_abm,   \"__builtin_clzs\",   IX86_BUILTIN_CLZS,    UNKNOWN,     (int) UINT16_FTYPE_UINT16 },\n \n   /* F16C */\n@@ -26036,15 +26069,23 @@ ix86_builtin_vectorized_function (tree fndecl, tree type_out,\n   switch (fn)\n     {\n     case BUILT_IN_SQRT:\n-      if (out_mode == DFmode && out_n == 2\n-\t  && in_mode == DFmode && in_n == 2)\n-\treturn ix86_builtins[IX86_BUILTIN_SQRTPD];\n+      if (out_mode == DFmode && in_mode == DFmode)\n+\t{\n+\t  if (out_n == 2 && in_n == 2)\n+\t    return ix86_builtins[IX86_BUILTIN_SQRTPD];\n+\t  else if (out_n == 4 && in_n == 4)\n+\t    return ix86_builtins[IX86_BUILTIN_SQRTPD256];\n+\t}\n       break;\n \n     case BUILT_IN_SQRTF:\n-      if (out_mode == SFmode && out_n == 4\n-\t  && in_mode == SFmode && in_n == 4)\n-\treturn ix86_builtins[IX86_BUILTIN_SQRTPS_NR];\n+      if (out_mode == SFmode && in_mode == SFmode)\n+\t{\n+\t  if (out_n == 4 && in_n == 4)\n+\t    return ix86_builtins[IX86_BUILTIN_SQRTPS_NR];\n+\t  else if (out_n == 8 && in_n == 8)\n+\t    return ix86_builtins[IX86_BUILTIN_SQRTPS_NR256];\n+\t}\n       break;\n \n     case BUILT_IN_LRINT:\n@@ -26054,21 +26095,33 @@ ix86_builtin_vectorized_function (tree fndecl, tree type_out,\n       break;\n \n     case BUILT_IN_LRINTF:\n-      if (out_mode == SImode && out_n == 4\n-\t  && in_mode == SFmode && in_n == 4)\n-\treturn ix86_builtins[IX86_BUILTIN_CVTPS2DQ];\n+      if (out_mode == SImode && in_mode == SFmode)\n+\t{\n+\t  if (out_n == 4 && in_n == 4)\n+\t    return ix86_builtins[IX86_BUILTIN_CVTPS2DQ];\n+\t  else if (out_n == 8 && in_n == 8)\n+\t    return ix86_builtins[IX86_BUILTIN_CVTPS2DQ256];\n+\t}\n       break;\n \n     case BUILT_IN_COPYSIGN:\n-      if (out_mode == DFmode && out_n == 2\n-\t  && in_mode == DFmode && in_n == 2)\n-\treturn ix86_builtins[IX86_BUILTIN_CPYSGNPD];\n+      if (out_mode == DFmode && in_mode == DFmode)\n+\t{\n+\t  if (out_n == 2 && in_n == 2)\n+\t    return ix86_builtins[IX86_BUILTIN_CPYSGNPD];\n+\t  else if (out_n == 4 && in_n == 4)\n+\t    return ix86_builtins[IX86_BUILTIN_CPYSGNPD256];\n+\t}\n       break;\n \n     case BUILT_IN_COPYSIGNF:\n-      if (out_mode == SFmode && out_n == 4\n-\t  && in_mode == SFmode && in_n == 4)\n-\treturn ix86_builtins[IX86_BUILTIN_CPYSGNPS];\n+      if (out_mode == SFmode && in_mode == SFmode)\n+\t{\n+\t  if (out_n == 4 && in_n == 4)\n+\t    return ix86_builtins[IX86_BUILTIN_CPYSGNPS];\n+\t  else if (out_n == 8 && in_n == 8)\n+\t    return ix86_builtins[IX86_BUILTIN_CPYSGNPS256];\n+\t}\n       break;\n \n     default:\n@@ -26391,6 +26444,9 @@ ix86_builtin_reciprocal (unsigned int fn, bool md_fn,\n       case IX86_BUILTIN_SQRTPS_NR:\n \treturn ix86_builtins[IX86_BUILTIN_RSQRTPS_NR];\n \n+      case IX86_BUILTIN_SQRTPS_NR256:\n+\treturn ix86_builtins[IX86_BUILTIN_RSQRTPS_NR256];\n+\n       default:\n \treturn NULL_TREE;\n       }\n@@ -30053,7 +30109,7 @@ void ix86_emit_swdivsf (rtx res, rtx a, rtx b, enum machine_mode mode)\n   two = CONST_DOUBLE_FROM_REAL_VALUE (dconst2, SFmode);\n \n   if (VECTOR_MODE_P (mode))\n-    two = ix86_build_const_vector (SFmode, true, two);\n+    two = ix86_build_const_vector (mode, true, two);\n \n   two = force_reg (mode, two);\n \n@@ -30100,8 +30156,8 @@ void ix86_emit_swsqrtsf (rtx res, rtx a, enum machine_mode mode,\n \n   if (VECTOR_MODE_P (mode))\n     {\n-      mthree = ix86_build_const_vector (SFmode, true, mthree);\n-      mhalf = ix86_build_const_vector (SFmode, true, mhalf);\n+      mthree = ix86_build_const_vector (mode, true, mthree);\n+      mhalf = ix86_build_const_vector (mode, true, mhalf);\n     }\n \n   /* sqrt(a)  = -0.5 * a * rsqrtss(a) * (a * rsqrtss(a) * rsqrtss(a) - 3.0)\n@@ -30246,7 +30302,16 @@ ix86_sse_copysign_to_positive (rtx result, rtx abs_value, rtx sign, rtx mask)\n   rtx sgn = gen_reg_rtx (mode);\n   if (mask == NULL_RTX)\n     {\n-      mask = ix86_build_signbit_mask (mode, VECTOR_MODE_P (mode), false);\n+      enum machine_mode vmode;\n+\n+      if (mode == SFmode)\n+\tvmode = V4SFmode;\n+      else if (mode == DFmode)\n+\tvmode = V2DFmode;\n+      else\n+\tvmode = mode;\n+\n+      mask = ix86_build_signbit_mask (vmode, VECTOR_MODE_P (mode), false);\n       if (!VECTOR_MODE_P (mode))\n \t{\n \t  /* We need to generate a scalar mode mask in this case.  */\n@@ -30270,11 +30335,17 @@ ix86_sse_copysign_to_positive (rtx result, rtx abs_value, rtx sign, rtx mask)\n static rtx\n ix86_expand_sse_fabs (rtx op0, rtx *smask)\n {\n-  enum machine_mode mode = GET_MODE (op0);\n+  enum machine_mode vmode, mode = GET_MODE (op0);\n   rtx xa, mask;\n \n   xa = gen_reg_rtx (mode);\n-  mask = ix86_build_signbit_mask (mode, VECTOR_MODE_P (mode), true);\n+  if (mode == SFmode)\n+    vmode = V4SFmode;\n+  else if (mode == DFmode)\n+    vmode = V2DFmode;\n+  else\n+    vmode = mode;\n+  mask = ix86_build_signbit_mask (vmode, VECTOR_MODE_P (mode), true);\n   if (!VECTOR_MODE_P (mode))\n     {\n       /* We need to generate a scalar mode mask in this case.  */\n@@ -31617,7 +31688,7 @@ expand_vec_perm_pshufb2 (struct expand_vec_perm_d *d)\n static bool\n expand_vec_perm_even_odd_1 (struct expand_vec_perm_d *d, unsigned odd)\n {\n-  rtx t1, t2, t3, t4;\n+  rtx t1, t2, t3;\n \n   switch (d->vmode)\n     {\n@@ -31639,34 +31710,34 @@ expand_vec_perm_even_odd_1 (struct expand_vec_perm_d *d, unsigned odd)\n \n     case V8SFmode:\n       {\n-\tstatic const unsigned char perm1[8] = { 0, 2, 1, 3, 5, 6, 5, 7 };\n-\tstatic const unsigned char perme[8] = { 0, 1,  8,  9, 4, 5, 12, 13 };\n-\tstatic const unsigned char permo[8] = { 2, 3, 10, 11, 6, 7, 14, 15 };\n+\tint mask = odd ? 0xdd : 0x88;\n \n \tt1 = gen_reg_rtx (V8SFmode);\n \tt2 = gen_reg_rtx (V8SFmode);\n \tt3 = gen_reg_rtx (V8SFmode);\n-\tt4 = gen_reg_rtx (V8SFmode);\n \n \t/* Shuffle within the 128-bit lanes to produce:\n-\t   { 0 2 1 3 4 6 5 7 } and { 8 a 9 b c e d f }.  */\n-\texpand_vselect (t1, d->op0, perm1, 8);\n-\texpand_vselect (t2, d->op1, perm1, 8);\n+\t   { 0 2 8 a 4 6 c e } | { 1 3 9 b 5 7 d f }.  */\n+\temit_insn (gen_avx_shufps256 (t1, d->op0, d->op1,\n+\t\t\t\t      GEN_INT (mask)));\n+\n+\t/* Shuffle the lanes around to produce:\n+\t   { 4 6 c e 0 2 8 a } and { 5 7 d f 1 3 9 b }.  */\n+\temit_insn (gen_avx_vperm2f128v8sf3 (t2, t1, t1,\n+\t\t\t\t\t    GEN_INT (0x3)));\n+\n+\t/* Shuffle within the 128-bit lanes to produce:\n+\t   { 0 2 4 6 4 6 0 2 } | { 1 3 5 7 5 7 1 3 }.  */\n+\temit_insn (gen_avx_shufps256 (t3, t1, t2, GEN_INT (0x44)));\n+\n+\t/* Shuffle within the 128-bit lanes to produce:\n+\t   { 8 a c e c e 8 a } | { 9 b d f d f 9 b }.  */\n+\temit_insn (gen_avx_shufps256 (t2, t1, t2, GEN_INT (0xee)));\n \n \t/* Shuffle the lanes around to produce:\n-\t   { 0 2 1 3 8 a 9 b } and { 4 6 5 7 c e d f }.  */\n-\temit_insn (gen_avx_vperm2f128v8sf3 (t3, t1, t2, GEN_INT (0x20)));\n-\temit_insn (gen_avx_vperm2f128v8sf3 (t4, t1, t2, GEN_INT (0x31)));\n-\n-\t/* Now a vpermil2p will produce the result required.  */\n-\t/* ??? The vpermil2p requires a vector constant.  Another option\n-\t   is a unpck[lh]ps to merge the two vectors to produce\n-\t   { 0 4 2 6 8 c a e } or { 1 5 3 7 9 d b f }.  Then use another\n-\t   vpermilps to get the elements into the final order.  */\n-\td->op0 = t3;\n-\td->op1 = t4;\n-\tmemcpy (d->perm, odd ? permo: perme, 8);\n-\texpand_vec_perm_vpermil (d);\n+\t   { 0 2 4 6 8 a c e } | { 1 3 5 7 9 b d f }.  */\n+\temit_insn (gen_avx_vperm2f128v8sf3 (d->target, t3, t2,\n+\t\t\t\t\t    GEN_INT (0x20)));\n       }\n       break;\n "}, {"sha": "d2ad8b19cd30283c8663873f653d2edbbe1433dc", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1e27129f2e48fd6752e6d329e1294ed1e922df6d/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1e27129f2e48fd6752e6d329e1294ed1e922df6d/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=1e27129f2e48fd6752e6d329e1294ed1e922df6d", "patch": "@@ -4509,7 +4509,7 @@\n \n   real_ldexp (&TWO31r, &dconst1, 31);\n   two31 = const_double_from_real_value (TWO31r, mode);\n-  two31 = ix86_build_const_vector (mode, true, two31);\n+  two31 = ix86_build_const_vector (vecmode, true, two31);\n   operands[2] = force_reg (vecmode, two31);\n })\n "}, {"sha": "db5e4de382192c490c4cf27f2bf723b46b7129be", "filename": "gcc/config/i386/sse.md", "status": "modified", "additions": 284, "deletions": 42, "changes": 326, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1e27129f2e48fd6752e6d329e1294ed1e922df6d/gcc%2Fconfig%2Fi386%2Fsse.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1e27129f2e48fd6752e6d329e1294ed1e922df6d/gcc%2Fconfig%2Fi386%2Fsse.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fsse.md?ref=1e27129f2e48fd6752e6d329e1294ed1e922df6d", "patch": "@@ -86,6 +86,25 @@\n    (V8HI \"TARGET_SSE2\") (V16QI \"TARGET_SSE2\")\n    (V4DF \"TARGET_AVX\") (V8SF \"TARGET_AVX\")])\n \n+;; Modes handled by storent patterns.\n+(define_mode_iterator STORENT_MODE\n+  [(SF \"TARGET_SSE4A\") (DF \"TARGET_SSE4A\")\n+   (SI \"TARGET_SSE2\") (V2DI \"TARGET_SSE2\") (V2DF \"TARGET_SSE2\")\n+   (V4SF \"TARGET_SSE\")\n+   (V4DF \"TARGET_AVX\") (V8SF \"TARGET_AVX\")])\n+\n+;; Modes handled by vector float patterns.\n+(define_mode_iterator VEC_FLOAT_MODE\n+  [(V2DF \"TARGET_SSE2\") (V4SF \"TARGET_SSE\")\n+   (V4DF \"TARGET_AVX\") (V8SF \"TARGET_AVX\")])\n+\n+;; Modes handled by vector extract patterns.\n+(define_mode_iterator VEC_EXTRACT_MODE\n+  [(V2DI \"TARGET_SSE\") (V4SI \"TARGET_SSE\")\n+   (V8HI \"TARGET_SSE\") (V16QI \"TARGET_SSE\")\n+   (V2DF \"TARGET_SSE\") (V4SF \"TARGET_SSE\")\n+   (V4DF \"TARGET_AVX\") (V8SF \"TARGET_AVX\")])\n+\n ;; Mapping from float mode to required SSE level\n (define_mode_attr sse [(SF \"sse\") (DF \"sse2\") (V4SF \"sse\") (V2DF \"sse2\")])\n \n@@ -504,30 +523,10 @@\n ; define patterns for other modes that would expand to several insns.\n \n (define_expand \"storent<mode>\"\n-  [(set (match_operand:SSEMODEF2P 0 \"memory_operand\" \"\")\n-\t(unspec:SSEMODEF2P\n-\t  [(match_operand:SSEMODEF2P 1 \"register_operand\" \"\")]\n-\t  UNSPEC_MOVNT))]\n-  \"SSE_VEC_FLOAT_MODE_P (<MODE>mode)\")\n-\n-(define_expand \"storent<mode>\"\n-  [(set (match_operand:MODEF 0 \"memory_operand\" \"\")\n-\t(unspec:MODEF\n-\t  [(match_operand:MODEF 1 \"register_operand\" \"\")]\n-\t  UNSPEC_MOVNT))]\n-  \"TARGET_SSE4A\")\n-\n-(define_expand \"storentv2di\"\n-  [(set (match_operand:V2DI 0 \"memory_operand\" \"\")\n-\t(unspec:V2DI [(match_operand:V2DI 1 \"register_operand\" \"\")]\n-\t\t     UNSPEC_MOVNT))]\n-  \"TARGET_SSE2\")\n-\n-(define_expand \"storentsi\"\n-  [(set (match_operand:SI 0 \"memory_operand\" \"\")\n-\t(unspec:SI [(match_operand:SI 1 \"register_operand\" \"\")]\n-\t\t   UNSPEC_MOVNT))]\n-  \"TARGET_SSE2\")\n+  [(set (match_operand:STORENT_MODE 0 \"memory_operand\" \"\")\n+\t(unspec:STORENT_MODE\n+\t  [(match_operand:STORENT_MODE 1 \"register_operand\" \"\")]\n+\t  UNSPEC_MOVNT))])\n \n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n ;;\n@@ -536,10 +535,10 @@\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n (define_expand \"<code><mode>2\"\n-  [(set (match_operand:SSEMODEF2P 0 \"register_operand\" \"\")\n-\t(absneg:SSEMODEF2P\n-\t  (match_operand:SSEMODEF2P 1 \"register_operand\" \"\")))]\n-  \"SSE_VEC_FLOAT_MODE_P (<MODE>mode)\"\n+  [(set (match_operand:VEC_FLOAT_MODE 0 \"register_operand\" \"\")\n+\t(absneg:VEC_FLOAT_MODE\n+\t  (match_operand:VEC_FLOAT_MODE 1 \"register_operand\" \"\")))]\n+  \"\"\n   \"ix86_expand_fp_absneg_operator (<CODE>, <MODE>mode, operands); DONE;\")\n \n (define_expand \"<plusminus_insn><mode>3\"\n@@ -1380,6 +1379,19 @@\n   [(set_attr \"type\" \"sseadd\")\n    (set_attr \"mode\" \"V2DF\")])\n \n+(define_expand \"reduc_splus_v8sf\"\n+  [(match_operand:V8SF 0 \"register_operand\" \"\")\n+   (match_operand:V8SF 1 \"register_operand\" \"\")]\n+  \"TARGET_AVX\"\n+{\n+  rtx tmp = gen_reg_rtx (V8SFmode);\n+  rtx tmp2 = gen_reg_rtx (V8SFmode);\n+  emit_insn (gen_avx_haddv8sf3 (tmp, operands[1], operands[1]));\n+  emit_insn (gen_avx_haddv8sf3 (tmp2, operands[1], operands[1]));\n+  emit_insn (gen_avx_haddv8sf3 (operands[0], tmp2, tmp2));\n+  DONE;\n+})\n+\n (define_expand \"reduc_splus_v4sf\"\n   [(match_operand:V4SF 0 \"register_operand\" \"\")\n    (match_operand:V4SF 1 \"register_operand\" \"\")]\n@@ -1396,6 +1408,17 @@\n   DONE;\n })\n \n+(define_expand \"reduc_splus_v4df\"\n+  [(match_operand:V4DF 0 \"register_operand\" \"\")\n+   (match_operand:V4DF 1 \"register_operand\" \"\")]\n+  \"TARGET_AVX\"\n+{\n+  rtx tmp = gen_reg_rtx (V4DFmode);\n+  emit_insn (gen_avx_haddv4df3 (tmp, operands[1], operands[1]));\n+  emit_insn (gen_avx_haddv4df3 (operands[0], tmp, tmp));\n+  DONE;\n+})\n+\n (define_expand \"reduc_splus_v2df\"\n   [(match_operand:V2DF 0 \"register_operand\" \"\")\n    (match_operand:V2DF 1 \"register_operand\" \"\")]\n@@ -1650,17 +1673,17 @@\n \n (define_expand \"copysign<mode>3\"\n   [(set (match_dup 4)\n-\t(and:SSEMODEF2P \n-\t  (not:SSEMODEF2P (match_dup 3))\n-\t  (match_operand:SSEMODEF2P 1 \"nonimmediate_operand\" \"\")))\n+\t(and:VEC_FLOAT_MODE\n+\t  (not:VEC_FLOAT_MODE (match_dup 3))\n+\t  (match_operand:VEC_FLOAT_MODE 1 \"nonimmediate_operand\" \"\")))\n    (set (match_dup 5)\n-\t(and:SSEMODEF2P (match_dup 3)\n-\t\t\t(match_operand:SSEMODEF2P 2 \"nonimmediate_operand\" \"\")))\n-   (set (match_operand:SSEMODEF2P 0 \"register_operand\" \"\")\n-\t(ior:SSEMODEF2P (match_dup 4) (match_dup 5)))]\n-  \"SSE_VEC_FLOAT_MODE_P (<MODE>mode)\"\n+\t(and:VEC_FLOAT_MODE (match_dup 3)\n+\t\t\t    (match_operand:VEC_FLOAT_MODE 2 \"nonimmediate_operand\" \"\")))\n+   (set (match_operand:VEC_FLOAT_MODE 0 \"register_operand\" \"\")\n+\t(ior:VEC_FLOAT_MODE (match_dup 4) (match_dup 5)))]\n+  \"\"\n {\n-  operands[3] = ix86_build_signbit_mask (<ssescalarmode>mode, 1, 0);\n+  operands[3] = ix86_build_signbit_mask (<MODE>mode, 1, 0);\n \n   operands[4] = gen_reg_rtx (<MODE>mode);\n   operands[5] = gen_reg_rtx (<MODE>mode);\n@@ -2657,7 +2680,8 @@\n   x = const_double_from_real_value (TWO32r, SFmode);\n \n   operands[3] = force_reg (V4SFmode, CONST0_RTX (V4SFmode));\n-  operands[4] = force_reg (V4SFmode, ix86_build_const_vector (SFmode, 1, x));\n+  operands[4] = force_reg (V4SFmode,\n+\t\t\t   ix86_build_const_vector (V4SFmode, 1, x));\n \n   for (i = 5; i < 8; i++)\n     operands[i] = gen_reg_rtx (V4SFmode);\n@@ -2892,6 +2916,18 @@\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"V4DF\")])\n \n+(define_insn \"*avx_cvtdq2pd256_2\"\n+  [(set (match_operand:V4DF 0 \"register_operand\" \"=x\")\n+\t(float:V4DF\n+\t  (vec_select:V4SI\n+\t    (match_operand:V8SI 1 \"nonimmediate_operand\" \"xm\")\n+\t    (parallel [(const_int 0) (const_int 1) (const_int 2) (const_int 3)]))))]\n+  \"TARGET_AVX\"\n+  \"vcvtdq2pd\\t{%x1, %0|%0, %x1}\"\n+  [(set_attr \"type\" \"ssecvt\")\n+   (set_attr \"prefix\" \"vex\")\n+   (set_attr \"mode\" \"V4DF\")])\n+\n (define_insn \"sse2_cvtdq2pd\"\n   [(set (match_operand:V2DF 0 \"register_operand\" \"=x\")\n \t(float:V2DF\n@@ -3072,6 +3108,18 @@\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"V4DF\")])\n \n+(define_insn \"*avx_cvtps2pd256_2\"\n+  [(set (match_operand:V4DF 0 \"register_operand\" \"=x\")\n+\t(float_extend:V4DF\n+\t  (vec_select:V4SF\n+\t    (match_operand:V8SF 1 \"nonimmediate_operand\" \"xm\")\n+\t    (parallel [(const_int 0) (const_int 1) (const_int 2) (const_int 3)]))))]\n+  \"TARGET_AVX\"\n+  \"vcvtps2pd\\t{%x1, %0|%0, %x1}\"\n+  [(set_attr \"type\" \"ssecvt\")\n+   (set_attr \"prefix\" \"vex\")\n+   (set_attr \"mode\" \"V4DF\")])\n+\n (define_insn \"sse2_cvtps2pd\"\n   [(set (match_operand:V2DF 0 \"register_operand\" \"=x\")\n \t(float_extend:V2DF\n@@ -3104,6 +3152,22 @@\n   \"TARGET_SSE2\"\n   \"operands[2] = gen_reg_rtx (V4SFmode);\")\n \n+(define_expand \"vec_unpacks_hi_v8sf\"\n+  [(set (match_dup 2)\n+\t(vec_select:V4SF\n+\t  (match_operand:V8SF 1 \"nonimmediate_operand\" \"\")\n+\t  (parallel [(const_int 4)\n+\t\t     (const_int 5)\n+\t\t     (const_int 6)\n+\t\t     (const_int 7)])))\n+   (set (match_operand:V4DF 0 \"register_operand\" \"\")\n+\t(float_extend:V4DF\n+\t  (match_dup 2)))]\n+  \"TARGET_AVX\"\n+{\n+  operands[2] = gen_reg_rtx (V4SFmode);\n+})\n+\n (define_expand \"vec_unpacks_lo_v4sf\"\n   [(set (match_operand:V2DF 0 \"register_operand\" \"\")\n \t(float_extend:V2DF\n@@ -3112,6 +3176,14 @@\n \t    (parallel [(const_int 0) (const_int 1)]))))]\n   \"TARGET_SSE2\")\n \n+(define_expand \"vec_unpacks_lo_v8sf\"\n+  [(set (match_operand:V4DF 0 \"register_operand\" \"\")\n+\t(float_extend:V4DF\n+\t  (vec_select:V4SF\n+\t    (match_operand:V8SF 1 \"nonimmediate_operand\" \"\")\n+\t    (parallel [(const_int 0) (const_int 1) (const_int 2) (const_int 3)]))))]\n+  \"TARGET_AVX\")\n+\n (define_expand \"vec_unpacks_float_hi_v8hi\"\n   [(match_operand:V4SF 0 \"register_operand\" \"\")\n    (match_operand:V8HI 1 \"register_operand\" \"\")]\n@@ -3184,6 +3256,28 @@\n \t    (parallel [(const_int 0) (const_int 1)]))))]\n   \"TARGET_SSE2\")\n \n+(define_expand \"vec_unpacks_float_hi_v8si\"\n+  [(set (match_dup 2)\n+\t(vec_select:V4SI\n+\t  (match_operand:V8SI 1 \"nonimmediate_operand\" \"\")\n+\t  (parallel [(const_int 4)\n+\t\t     (const_int 5)\n+\t\t     (const_int 6)\n+\t\t     (const_int 7)])))\n+   (set (match_operand:V4DF 0 \"register_operand\" \"\")\n+        (float:V4DF\n+\t  (match_dup 2)))]\n+  \"TARGET_AVX\"\n+  \"operands[2] = gen_reg_rtx (V4SImode);\")\n+\n+(define_expand \"vec_unpacks_float_lo_v8si\"\n+  [(set (match_operand:V4DF 0 \"register_operand\" \"\")\n+\t(float:V4DF\n+\t  (vec_select:V4SI\n+\t    (match_operand:V8SI 1 \"nonimmediate_operand\" \"\")\n+\t    (parallel [(const_int 0) (const_int 1) (const_int 2) (const_int 3)]))))]\n+  \"TARGET_AVX\")\n+\n (define_expand \"vec_unpacku_float_hi_v4si\"\n   [(set (match_dup 5)\n \t(vec_select:V4SI\n@@ -3213,7 +3307,8 @@\n   x = const_double_from_real_value (TWO32r, DFmode);\n \n   operands[3] = force_reg (V2DFmode, CONST0_RTX (V2DFmode));\n-  operands[4] = force_reg (V2DFmode, ix86_build_const_vector (DFmode, 1, x));\n+  operands[4] = force_reg (V2DFmode,\n+\t\t\t   ix86_build_const_vector (V2DFmode, 1, x));\n \n   operands[5] = gen_reg_rtx (V4SImode);\n  \n@@ -3243,12 +3338,30 @@\n   x = const_double_from_real_value (TWO32r, DFmode);\n \n   operands[3] = force_reg (V2DFmode, CONST0_RTX (V2DFmode));\n-  operands[4] = force_reg (V2DFmode, ix86_build_const_vector (DFmode, 1, x));\n+  operands[4] = force_reg (V2DFmode,\n+\t\t\t   ix86_build_const_vector (V2DFmode, 1, x));\n \n   for (i = 5; i < 8; i++)\n     operands[i] = gen_reg_rtx (V2DFmode);\n })\n \n+(define_expand \"vec_pack_trunc_v4df\"\n+  [(set (match_dup 3)\n+\t(float_truncate:V4SF\n+\t  (match_operand:V4DF 1 \"nonimmediate_operand\" \"\")))\n+   (set (match_dup 4)\n+\t(float_truncate:V4SF\n+\t  (match_operand:V4DF 2 \"nonimmediate_operand\" \"\")))\n+   (set (match_operand:V8SF 0 \"register_operand\" \"\")\n+\t(vec_concat:V8SF\n+\t  (match_dup 3)\n+\t  (match_dup 4)))]\n+  \"TARGET_AVX\"\n+{\n+  operands[3] = gen_reg_rtx (V4SFmode);\n+  operands[4] = gen_reg_rtx (V4SFmode);\n+})\n+\n (define_expand \"vec_pack_trunc_v2df\"\n   [(match_operand:V4SF 0 \"register_operand\" \"\")\n    (match_operand:V2DF 1 \"nonimmediate_operand\" \"\")\n@@ -3441,6 +3554,41 @@\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"V4SF\")])\n \n+(define_expand \"vec_interleave_highv8sf\"\n+  [(set (match_dup 3)\n+\t(vec_select:V8SF\n+\t  (vec_concat:V16SF\n+\t    (match_operand:V8SF 1 \"register_operand\" \"x\")\n+\t    (match_operand:V8SF 2 \"nonimmediate_operand\" \"xm\"))\n+\t  (parallel [(const_int 0) (const_int 8)\n+\t\t     (const_int 1) (const_int 9)\n+\t\t     (const_int 4) (const_int 12)\n+\t\t     (const_int 5) (const_int 13)])))\n+   (set (match_dup 4)\n+\t(vec_select:V8SF\n+\t  (vec_concat:V16SF\n+\t    (match_dup 1)\n+\t    (match_dup 2))\n+\t  (parallel [(const_int 2) (const_int 10)\n+\t\t     (const_int 3) (const_int 11)\n+\t\t     (const_int 6) (const_int 14)\n+\t\t     (const_int 7) (const_int 15)])))\n+   (set (match_operand:V8SF 0 \"register_operand\" \"\")\n+\t(vec_concat:V8SF\n+\t  (vec_select:V4SF\n+\t    (match_dup 3)\n+\t    (parallel [(const_int 4) (const_int 5)\n+\t\t       (const_int 6) (const_int 7)]))\n+\t  (vec_select:V4SF\n+\t    (match_dup 4)\n+\t    (parallel [(const_int 4) (const_int 5)\n+\t\t       (const_int 6) (const_int 7)]))))]\n+ \"TARGET_AVX\"\n+{\n+  operands[3] = gen_reg_rtx (V8SFmode);\n+  operands[4] = gen_reg_rtx (V8SFmode);\n+})\n+\n (define_insn \"vec_interleave_highv4sf\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n \t(vec_select:V4SF\n@@ -3485,6 +3633,41 @@\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"V4SF\")])\n \n+(define_expand \"vec_interleave_lowv8sf\"\n+  [(set (match_dup 3)\n+\t(vec_select:V8SF\n+\t  (vec_concat:V16SF\n+\t    (match_operand:V8SF 1 \"register_operand\" \"x\")\n+\t    (match_operand:V8SF 2 \"nonimmediate_operand\" \"xm\"))\n+\t  (parallel [(const_int 0) (const_int 8)\n+\t\t     (const_int 1) (const_int 9)\n+\t\t     (const_int 4) (const_int 12)\n+\t\t     (const_int 5) (const_int 13)])))\n+   (set (match_dup 4)\n+\t(vec_select:V8SF\n+\t  (vec_concat:V16SF\n+\t    (match_dup 1)\n+\t    (match_dup 2))\n+\t  (parallel [(const_int 2) (const_int 10)\n+\t\t     (const_int 3) (const_int 11)\n+\t\t     (const_int 6) (const_int 14)\n+\t\t     (const_int 7) (const_int 15)])))\n+   (set (match_operand:V8SF 0 \"register_operand\" \"\")\n+\t(vec_concat:V8SF\n+\t  (vec_select:V4SF\n+\t    (match_dup 3)\n+\t    (parallel [(const_int 0) (const_int 1)\n+\t\t       (const_int 2) (const_int 3)]))\n+\t  (vec_select:V4SF\n+\t    (match_dup 4)\n+\t    (parallel [(const_int 0) (const_int 1)\n+\t\t       (const_int 2) (const_int 3)]))))]\n+ \"TARGET_AVX\"\n+{\n+  operands[3] = gen_reg_rtx (V8SFmode);\n+  operands[4] = gen_reg_rtx (V8SFmode);\n+})\n+\n (define_insn \"vec_interleave_lowv4sf\"\n   [(set (match_operand:V4SF 0 \"register_operand\" \"=x\")\n \t(vec_select:V4SF\n@@ -4353,8 +4536,8 @@\n })\n \n (define_expand \"vec_extract<mode>\"\n-  [(match_operand:<ssescalarmode> 0 \"register_operand\" \"\")\n-   (match_operand:SSEMODE 1 \"register_operand\" \"\")\n+  [(match_operand:<avxscalarmode> 0 \"register_operand\" \"\")\n+   (match_operand:VEC_EXTRACT_MODE 1 \"register_operand\" \"\")\n    (match_operand 2 \"const_int_operand\" \"\")]\n   \"TARGET_SSE\"\n {\n@@ -4384,6 +4567,36 @@\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"V4DF\")])\n \n+(define_expand \"vec_interleave_highv4df\"\n+  [(set (match_dup 3)\n+\t(vec_select:V4DF\n+\t  (vec_concat:V8DF\n+\t    (match_operand:V4DF 1 \"register_operand\" \"x\")\n+\t    (match_operand:V4DF 2 \"nonimmediate_operand\" \"xm\"))\n+\t  (parallel [(const_int 0) (const_int 4)\n+\t\t     (const_int 2) (const_int 6)])))\n+   (set (match_dup 4)\n+\t(vec_select:V4DF\n+\t  (vec_concat:V8DF\n+\t    (match_dup 1)\n+\t    (match_dup 2))\n+\t  (parallel [(const_int 1) (const_int 5)\n+\t\t     (const_int 3) (const_int 7)])))\n+   (set (match_operand:V4DF 0 \"register_operand\" \"\")\n+\t(vec_concat:V4DF\n+\t  (vec_select:V2DF\n+\t    (match_dup 3)\n+\t    (parallel [(const_int 2) (const_int 3)]))\n+\t  (vec_select:V2DF\n+\t    (match_dup 4)\n+\t    (parallel [(const_int 2) (const_int 3)]))))]\n+ \"TARGET_AVX\"\n+{\n+  operands[3] = gen_reg_rtx (V4DFmode);\n+  operands[4] = gen_reg_rtx (V4DFmode);\n+})\n+\n+\n (define_expand \"vec_interleave_highv2df\"\n   [(set (match_operand:V2DF 0 \"register_operand\" \"\")\n \t(vec_select:V2DF\n@@ -4489,6 +4702,35 @@\n    (set_attr \"prefix\" \"vex\")\n    (set_attr \"mode\" \"V4DF\")])\n \n+(define_expand \"vec_interleave_lowv4df\"\n+  [(set (match_dup 3)\n+\t(vec_select:V4DF\n+\t  (vec_concat:V8DF\n+\t    (match_operand:V4DF 1 \"register_operand\" \"x\")\n+\t    (match_operand:V4DF 2 \"nonimmediate_operand\" \"xm\"))\n+\t  (parallel [(const_int 0) (const_int 4)\n+\t\t     (const_int 2) (const_int 6)])))\n+   (set (match_dup 4)\n+\t(vec_select:V4DF\n+\t  (vec_concat:V8DF\n+\t    (match_dup 1)\n+\t    (match_dup 2))\n+\t  (parallel [(const_int 1) (const_int 5)\n+\t\t     (const_int 3) (const_int 7)])))\n+   (set (match_operand:V4DF 0 \"register_operand\" \"\")\n+\t(vec_concat:V4DF\n+\t  (vec_select:V2DF\n+\t    (match_dup 3)\n+\t    (parallel [(const_int 0) (const_int 1)]))\n+\t  (vec_select:V2DF\n+\t    (match_dup 4)\n+\t    (parallel [(const_int 0) (const_int 1)]))))]\n+ \"TARGET_AVX\"\n+{\n+  operands[3] = gen_reg_rtx (V4DFmode);\n+  operands[4] = gen_reg_rtx (V4DFmode);\n+})\n+\n (define_expand \"vec_interleave_lowv2df\"\n   [(set (match_operand:V2DF 0 \"register_operand\" \"\")\n \t(vec_select:V2DF"}]}