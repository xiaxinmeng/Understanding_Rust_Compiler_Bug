{"sha": "7b02f4e02bdf68d57d3bf3aef6e359516312ce32", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6N2IwMmY0ZTAyYmRmNjhkNTdkM2JmM2FlZjZlMzU5NTE2MzEyY2UzMg==", "commit": {"author": {"name": "Steven Bosscher", "email": "steven@gcc.gnu.org", "date": "2012-03-21T23:01:42Z"}, "committer": {"name": "Steven Bosscher", "email": "steven@gcc.gnu.org", "date": "2012-03-21T23:01:42Z"}, "message": "cse.c (invalidate_from_sets_and_clobbers, [...]): Split out from ...\n\n\t* cse.c (invalidate_from_sets_and_clobbers, try_back_substitute_reg,\n\tfind_sets_in_insn, canonicalize_insn): Split out from ...\n\t(cse_insn): ... here.\n\t(invalidate_from_clobbers): Take an insn instead of the pattern.\n\nFrom-SVN: r185622", "tree": {"sha": "0be5e38c3e2144449a880d3cf6286548732d3fc6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/0be5e38c3e2144449a880d3cf6286548732d3fc6"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/7b02f4e02bdf68d57d3bf3aef6e359516312ce32", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7b02f4e02bdf68d57d3bf3aef6e359516312ce32", "html_url": "https://github.com/Rust-GCC/gccrs/commit/7b02f4e02bdf68d57d3bf3aef6e359516312ce32", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/7b02f4e02bdf68d57d3bf3aef6e359516312ce32/comments", "author": null, "committer": null, "parents": [{"sha": "05e0ab9a493cddf10cccc4497b54660c72b04677", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/05e0ab9a493cddf10cccc4497b54660c72b04677", "html_url": "https://github.com/Rust-GCC/gccrs/commit/05e0ab9a493cddf10cccc4497b54660c72b04677"}], "stats": {"total": 506, "additions": 320, "deletions": 186}, "files": [{"sha": "3fce28fd668f6a593cd0ba3ab37d879c2473016b", "filename": "gcc/ChangeLog", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7b02f4e02bdf68d57d3bf3aef6e359516312ce32/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7b02f4e02bdf68d57d3bf3aef6e359516312ce32/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=7b02f4e02bdf68d57d3bf3aef6e359516312ce32", "patch": "@@ -1,3 +1,10 @@\n+2012-03-21  Steven Bosscher  <steven@gcc.gnu.org>\n+\n+\t* cse.c (invalidate_from_sets_and_clobbers, try_back_substitute_reg,\n+\tfind_sets_in_insn, canonicalize_insn): Split out from ...\n+\t(cse_insn): ... here.\n+\t(invalidate_from_clobbers): Take an insn instead of the pattern.\n+\n 2012-03-21  Oleg Endo  <olegendo@gcc.gnu.org>\n \n \tPR target/52479"}, {"sha": "a414590718387c40c609c5d49506dd8197def931", "filename": "gcc/cse.c", "status": "modified", "additions": 313, "deletions": 186, "changes": 499, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/7b02f4e02bdf68d57d3bf3aef6e359516312ce32/gcc%2Fcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/7b02f4e02bdf68d57d3bf3aef6e359516312ce32/gcc%2Fcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcse.c?ref=7b02f4e02bdf68d57d3bf3aef6e359516312ce32", "patch": "@@ -597,6 +597,7 @@ static void record_jump_cond (enum rtx_code, enum machine_mode, rtx, rtx,\n static void cse_insn (rtx);\n static void cse_prescan_path (struct cse_basic_block_data *);\n static void invalidate_from_clobbers (rtx);\n+static void invalidate_from_sets_and_clobbers (rtx);\n static rtx cse_process_notes (rtx, rtx, bool *);\n static void cse_extended_basic_block (struct cse_basic_block_data *);\n static void count_reg_usage (rtx, int *, rtx, int);\n@@ -4089,10 +4090,22 @@ record_jump_cond (enum rtx_code code, enum machine_mode mode, rtx op0,\n }\n \f\n /* CSE processing for one instruction.\n-   First simplify sources and addresses of all assignments\n-   in the instruction, using previously-computed equivalents values.\n-   Then install the new sources and destinations in the table\n-   of available values.  */\n+\n+   Most \"true\" common subexpressions are mostly optimized away in GIMPLE,\n+   but the few that \"leak through\" are cleaned up by cse_insn, and complex\n+   addressing modes are often formed here.\n+\n+   The main function is cse_insn, and between here and that function\n+   a couple of helper functions is defined to keep the size of cse_insn\n+   within reasonable proportions.\n+   \n+   Data is shared between the main and helper functions via STRUCT SET,\n+   that contains all data related for every set in the instruction that\n+   is being processed.\n+   \n+   Note that cse_main processes all sets in the instruction.  Most\n+   passes in GCC only process simple SET insns or single_set insns, but\n+   CSE processes insns with multiple sets as well.  */\n \n /* Data on one SET contained in the instruction.  */\n \n@@ -4128,50 +4141,93 @@ struct set\n   /* Table entry for the destination address.  */\n   struct table_elt *dest_addr_elt;\n };\n+\f\n+/* Special handling for (set REG0 REG1) where REG0 is the\n+   \"cheapest\", cheaper than REG1.  After cse, REG1 will probably not\n+   be used in the sequel, so (if easily done) change this insn to\n+   (set REG1 REG0) and replace REG1 with REG0 in the previous insn\n+   that computed their value.  Then REG1 will become a dead store\n+   and won't cloud the situation for later optimizations.\n+\n+   Do not make this change if REG1 is a hard register, because it will\n+   then be used in the sequel and we may be changing a two-operand insn\n+   into a three-operand insn.\n+   \n+   This is the last transformation that cse_insn will try to do.  */\n \n static void\n-cse_insn (rtx insn)\n+try_back_substitute_reg (rtx set, rtx insn)\n {\n-  rtx x = PATTERN (insn);\n-  int i;\n-  rtx tem;\n-  int n_sets = 0;\n+  rtx dest = SET_DEST (set);\n+  rtx src = SET_SRC (set);\n \n-  rtx src_eqv = 0;\n-  struct table_elt *src_eqv_elt = 0;\n-  int src_eqv_volatile = 0;\n-  int src_eqv_in_memory = 0;\n-  unsigned src_eqv_hash = 0;\n+  if (REG_P (dest)\n+      && REG_P (src) && ! HARD_REGISTER_P (src)\n+      && REGNO_QTY_VALID_P (REGNO (src)))\n+    {\n+      int src_q = REG_QTY (REGNO (src));\n+      struct qty_table_elem *src_ent = &qty_table[src_q];\n \n-  struct set *sets = (struct set *) 0;\n+      if (src_ent->first_reg == REGNO (dest))\n+\t{\n+\t  /* Scan for the previous nonnote insn, but stop at a basic\n+\t     block boundary.  */\n+\t  rtx prev = insn;\n+\t  rtx bb_head = BB_HEAD (BLOCK_FOR_INSN (insn));\n+\t  do\n+\t    {\n+\t      prev = PREV_INSN (prev);\n+\t    }\n+\t  while (prev != bb_head && (NOTE_P (prev) || DEBUG_INSN_P (prev)));\n \n-  this_insn = insn;\n-#ifdef HAVE_cc0\n-  /* Records what this insn does to set CC0.  */\n-  this_insn_cc0 = 0;\n-  this_insn_cc0_mode = VOIDmode;\n-#endif\n+\t  /* Do not swap the registers around if the previous instruction\n+\t     attaches a REG_EQUIV note to REG1.\n \n-  /* Find all the SETs and CLOBBERs in this instruction.\n-     Record all the SETs in the array `set' and count them.\n-     Also determine whether there is a CLOBBER that invalidates\n-     all memory references, or all references at varying addresses.  */\n+\t     ??? It's not entirely clear whether we can transfer a REG_EQUIV\n+\t     from the pseudo that originally shadowed an incoming argument\n+\t     to another register.  Some uses of REG_EQUIV might rely on it\n+\t     being attached to REG1 rather than REG2.\n \n-  if (CALL_P (insn))\n-    {\n-      for (tem = CALL_INSN_FUNCTION_USAGE (insn); tem; tem = XEXP (tem, 1))\n-\t{\n-\t  if (GET_CODE (XEXP (tem, 0)) == CLOBBER)\n-\t    invalidate (SET_DEST (XEXP (tem, 0)), VOIDmode);\n-\t  XEXP (tem, 0) = canon_reg (XEXP (tem, 0), insn);\n+\t     This section previously turned the REG_EQUIV into a REG_EQUAL\n+\t     note.  We cannot do that because REG_EQUIV may provide an\n+\t     uninitialized stack slot when REG_PARM_STACK_SPACE is used.  */\n+\t  if (NONJUMP_INSN_P (prev)\n+\t      && GET_CODE (PATTERN (prev)) == SET\n+\t      && SET_DEST (PATTERN (prev)) == src\n+\t      && ! find_reg_note (prev, REG_EQUIV, NULL_RTX))\n+\t    {\n+\t      rtx note;\n+\n+\t      validate_change (prev, &SET_DEST (PATTERN (prev)), dest, 1);\n+\t      validate_change (insn, &SET_DEST (set), src, 1);\n+\t      validate_change (insn, &SET_SRC (set), dest, 1);\n+\t      apply_change_group ();\n+\n+\t      /* If INSN has a REG_EQUAL note, and this note mentions\n+\t\t REG0, then we must delete it, because the value in\n+\t\t REG0 has changed.  If the note's value is REG1, we must\n+\t\t also delete it because that is now this insn's dest.  */\n+\t      note = find_reg_note (insn, REG_EQUAL, NULL_RTX);\n+\t      if (note != 0\n+\t\t  && (reg_mentioned_p (dest, XEXP (note, 0))\n+\t\t      || rtx_equal_p (src, XEXP (note, 0))))\n+\t\tremove_note (insn, note);\n+\t    }\n \t}\n     }\n+}\n+\f\n+/* Record all the SETs in this instruction into SETS_PTR,\n+   and return the number of recorded sets.  */\n+static int\n+find_sets_in_insn (rtx insn, struct set **psets)\n+{\n+  struct set *sets = *psets;\n+  int n_sets = 0;\n+  rtx x = PATTERN (insn);\n \n   if (GET_CODE (x) == SET)\n     {\n-      sets = XALLOCA (struct set);\n-      sets[0].rtl = x;\n-\n       /* Ignore SETs that are unconditional jumps.\n \t They never need cse processing, so this does not hurt.\n \t The reason is not efficiency but rather\n@@ -4182,108 +4238,101 @@ cse_insn (rtx insn)\n       if (SET_DEST (x) == pc_rtx\n \t  && GET_CODE (SET_SRC (x)) == LABEL_REF)\n \t;\n-\n       /* Don't count call-insns, (set (reg 0) (call ...)), as a set.\n \t The hard function value register is used only once, to copy to\n-\t someplace else, so it isn't worth cse'ing (and on 80386 is unsafe)!\n-\t Ensure we invalidate the destination register.  On the 80386 no\n-\t other code would invalidate it since it is a fixed_reg.\n-\t We need not check the return of apply_change_group; see canon_reg.  */\n-\n+\t someplace else, so it isn't worth cse'ing.  */\n       else if (GET_CODE (SET_SRC (x)) == CALL)\n-\t{\n-\t  canon_reg (SET_SRC (x), insn);\n-\t  apply_change_group ();\n-\t  fold_rtx (SET_SRC (x), insn);\n-\t  invalidate (SET_DEST (x), VOIDmode);\n-\t}\n+\t;\n       else\n-\tn_sets = 1;\n+\tsets[n_sets++].rtl = x;\n     }\n   else if (GET_CODE (x) == PARALLEL)\n     {\n-      int lim = XVECLEN (x, 0);\n-\n-      sets = XALLOCAVEC (struct set, lim);\n-\n-      /* Find all regs explicitly clobbered in this insn,\n-\t and ensure they are not replaced with any other regs\n-\t elsewhere in this insn.\n-\t When a reg that is clobbered is also used for input,\n-\t we should presume that that is for a reason,\n-\t and we should not substitute some other register\n-\t which is not supposed to be clobbered.\n-\t Therefore, this loop cannot be merged into the one below\n-\t because a CALL may precede a CLOBBER and refer to the\n-\t value clobbered.  We must not let a canonicalization do\n-\t anything in that case.  */\n-      for (i = 0; i < lim; i++)\n-\t{\n-\t  rtx y = XVECEXP (x, 0, i);\n-\t  if (GET_CODE (y) == CLOBBER)\n-\t    {\n-\t      rtx clobbered = XEXP (y, 0);\n-\n-\t      if (REG_P (clobbered)\n-\t\t  || GET_CODE (clobbered) == SUBREG)\n-\t\tinvalidate (clobbered, VOIDmode);\n-\t      else if (GET_CODE (clobbered) == STRICT_LOW_PART\n-\t\t       || GET_CODE (clobbered) == ZERO_EXTRACT)\n-\t\tinvalidate (XEXP (clobbered, 0), GET_MODE (clobbered));\n-\t    }\n-\t}\n+      int i, lim = XVECLEN (x, 0);\n \n+      /* Go over the epressions of the PARALLEL in forward order, to\n+\t put them in the same order in the SETS array.  */\n       for (i = 0; i < lim; i++)\n \t{\n \t  rtx y = XVECEXP (x, 0, i);\n \t  if (GET_CODE (y) == SET)\n \t    {\n \t      /* As above, we ignore unconditional jumps and call-insns and\n \t\t ignore the result of apply_change_group.  */\n-\t      if (GET_CODE (SET_SRC (y)) == CALL)\n-\t\t{\n-\t\t  canon_reg (SET_SRC (y), insn);\n-\t\t  apply_change_group ();\n-\t\t  fold_rtx (SET_SRC (y), insn);\n-\t\t  invalidate (SET_DEST (y), VOIDmode);\n-\t\t}\n-\t      else if (SET_DEST (y) == pc_rtx\n-\t\t       && GET_CODE (SET_SRC (y)) == LABEL_REF)\n+\t      if (SET_DEST (y) == pc_rtx\n+\t\t  && GET_CODE (SET_SRC (y)) == LABEL_REF)\n+\t\t;\n+\t      else if (GET_CODE (SET_SRC (y)) == CALL)\n \t\t;\n \t      else\n \t\tsets[n_sets++].rtl = y;\n \t    }\n-\t  else if (GET_CODE (y) == CLOBBER)\n-\t    {\n-\t      /* If we clobber memory, canon the address.\n-\t\t This does nothing when a register is clobbered\n-\t\t because we have already invalidated the reg.  */\n-\t      if (MEM_P (XEXP (y, 0)))\n-\t\tcanon_reg (XEXP (y, 0), insn);\n-\t    }\n-\t  else if (GET_CODE (y) == USE\n-\t\t   && ! (REG_P (XEXP (y, 0))\n-\t\t\t && REGNO (XEXP (y, 0)) < FIRST_PSEUDO_REGISTER))\n-\t    canon_reg (y, insn);\n-\t  else if (GET_CODE (y) == CALL)\n-\t    {\n-\t      /* The result of apply_change_group can be ignored; see\n-\t\t canon_reg.  */\n-\t      canon_reg (y, insn);\n-\t      apply_change_group ();\n-\t      fold_rtx (y, insn);\n-\t    }\n \t}\n     }\n+\n+  return n_sets;\n+}\n+\f\n+/* Where possible, substitute every register reference in the N_SETS\n+   number of SETS in INSN with the the canonical register.\n+\n+   Register canonicalization propagatest the earliest register (i.e.\n+   one that is set before INSN) with the same value.  This is a very\n+   useful, simple form of CSE, to clean up warts from expanding GIMPLE\n+   to RTL.  For instance, a CONST for an address is usually expanded\n+   multiple times to loads into different registers, thus creating many\n+   subexpressions of the form:\n+\n+   (set (reg1) (some_const))\n+   (set (mem (... reg1 ...) (thing)))\n+   (set (reg2) (some_const))\n+   (set (mem (... reg2 ...) (thing)))\n+\n+   After canonicalizing, the code takes the following form:\n+\n+   (set (reg1) (some_const))\n+   (set (mem (... reg1 ...) (thing)))\n+   (set (reg2) (some_const))\n+   (set (mem (... reg1 ...) (thing)))\n+\n+   The set to reg2 is now trivially dead, and the memory reference (or\n+   address, or whatever) may be a candidate for further CSEing.\n+\n+   In this function, the result of apply_change_group can be ignored;\n+   see canon_reg.  */\n+\n+static void\n+canonicalize_insn (rtx insn, struct set **psets, int n_sets)\n+{\n+  struct set *sets = *psets;\n+  rtx tem;\n+  rtx x = PATTERN (insn);\n+  int i;\n+\n+  if (CALL_P (insn))\n+    {\n+      for (tem = CALL_INSN_FUNCTION_USAGE (insn); tem; tem = XEXP (tem, 1))\n+\tXEXP (tem, 0) = canon_reg (XEXP (tem, 0), insn);\n+    }\n+\n+  if (GET_CODE (x) == SET && GET_CODE (SET_SRC (x)) == CALL)\n+    {\n+      canon_reg (SET_SRC (x), insn);\n+      apply_change_group ();\n+      fold_rtx (SET_SRC (x), insn);\n+    }\n   else if (GET_CODE (x) == CLOBBER)\n     {\n+      /* If we clobber memory, canon the address.\n+\t This does nothing when a register is clobbered\n+\t because we have already invalidated the reg.  */\n       if (MEM_P (XEXP (x, 0)))\n \tcanon_reg (XEXP (x, 0), insn);\n     }\n-  /* Canonicalize a USE of a pseudo register or memory location.  */\n   else if (GET_CODE (x) == USE\n \t   && ! (REG_P (XEXP (x, 0))\n \t\t && REGNO (XEXP (x, 0)) < FIRST_PSEUDO_REGISTER))\n+    /* Canonicalize a USE of a pseudo register or memory location.  */\n     canon_reg (x, insn);\n   else if (GET_CODE (x) == ASM_OPERANDS)\n     {\n@@ -4299,29 +4348,60 @@ cse_insn (rtx insn)\n     }\n   else if (GET_CODE (x) == CALL)\n     {\n-      /* The result of apply_change_group can be ignored; see canon_reg.  */\n       canon_reg (x, insn);\n       apply_change_group ();\n       fold_rtx (x, insn);\n     }\n   else if (DEBUG_INSN_P (insn))\n     canon_reg (PATTERN (insn), insn);\n+  else if (GET_CODE (x) == PARALLEL)\n+    {\n+      for (i = XVECLEN (x, 0) - 1; i >= 0; i--)\n+\t{\n+\t  rtx y = XVECEXP (x, 0, i);\n+\t  if (GET_CODE (y) == SET && GET_CODE (SET_SRC (y)) == CALL)\n+\t    {\n+\t      canon_reg (SET_SRC (y), insn);\n+\t      apply_change_group ();\n+\t      fold_rtx (SET_SRC (y), insn);\n+\t    }\n+\t  else if (GET_CODE (y) == CLOBBER)\n+\t    {\n+\t      if (MEM_P (XEXP (y, 0)))\n+\t\tcanon_reg (XEXP (y, 0), insn);\n+\t    }\n+\t  else if (GET_CODE (y) == USE\n+\t\t   && ! (REG_P (XEXP (y, 0))\n+\t\t\t && REGNO (XEXP (y, 0)) < FIRST_PSEUDO_REGISTER))\n+\t    canon_reg (y, insn);\n+\t  else if (GET_CODE (y) == CALL)\n+\t    {\n+\t      canon_reg (y, insn);\n+\t      apply_change_group ();\n+\t      fold_rtx (y, insn);\n+\t    }\n+\t}\n+    }\n \n-  /* Store the equivalent value in SRC_EQV, if different, or if the DEST\n-     is a STRICT_LOW_PART.  The latter condition is necessary because SRC_EQV\n-     is handled specially for this case, and if it isn't set, then there will\n-     be no equivalence for the destination.  */\n   if (n_sets == 1 && REG_NOTES (insn) != 0\n-      && (tem = find_reg_note (insn, REG_EQUAL, NULL_RTX)) != 0\n-      && (! rtx_equal_p (XEXP (tem, 0), SET_SRC (sets[0].rtl))\n-\t  || GET_CODE (SET_DEST (sets[0].rtl)) == STRICT_LOW_PART))\n+      && (tem = find_reg_note (insn, REG_EQUAL, NULL_RTX)) != 0)\n     {\n-      /* The result of apply_change_group can be ignored; see canon_reg.  */\n-      canon_reg (XEXP (tem, 0), insn);\n-      apply_change_group ();\n-      src_eqv = fold_rtx (XEXP (tem, 0), insn);\n-      XEXP (tem, 0) = copy_rtx (src_eqv);\n-      df_notes_rescan (insn);\n+      /* We potentially will process this insn many times.  Therefore,\n+\t drop the REG_EQUAL note if it is equal to the SET_SRC of the\n+\t unique set in INSN.\n+\n+\t Do not do so if the REG_EQUAL note is for a STRICT_LOW_PART,\n+\t because cse_insn handles those specially.  */\n+      if (GET_CODE (SET_DEST (sets[0].rtl)) != STRICT_LOW_PART\n+\t  && rtx_equal_p (XEXP (tem, 0), SET_SRC (sets[0].rtl)))\n+\tremove_note (insn, tem);\n+      else\n+\t{\n+\t  canon_reg (XEXP (tem, 0), insn);\n+\t  apply_change_group ();\n+\t  XEXP (tem, 0) = fold_rtx (XEXP (tem, 0), insn);\n+\t  df_notes_rescan (insn);\n+\t}\n     }\n \n   /* Canonicalize sources and addresses of destinations.\n@@ -4368,6 +4448,62 @@ cse_insn (rtx insn)\n      The result of apply_change_group can be ignored; see canon_reg.  */\n \n   apply_change_group ();\n+}\n+\f\n+/* Main function of CSE.\n+   First simplify sources and addresses of all assignments\n+   in the instruction, using previously-computed equivalents values.\n+   Then install the new sources and destinations in the table\n+   of available values.  */\n+\n+static void\n+cse_insn (rtx insn)\n+{\n+  rtx x = PATTERN (insn);\n+  int i;\n+  rtx tem;\n+  int n_sets = 0;\n+\n+  rtx src_eqv = 0;\n+  struct table_elt *src_eqv_elt = 0;\n+  int src_eqv_volatile = 0;\n+  int src_eqv_in_memory = 0;\n+  unsigned src_eqv_hash = 0;\n+\n+  struct set *sets = (struct set *) 0;\n+\n+  if (GET_CODE (x) == SET)\n+    sets = XALLOCA (struct set);\n+  else if (GET_CODE (x) == PARALLEL)\n+    sets = XALLOCAVEC (struct set, XVECLEN (x, 0));\n+\n+  this_insn = insn;\n+#ifdef HAVE_cc0\n+  /* Records what this insn does to set CC0.  */\n+  this_insn_cc0 = 0;\n+  this_insn_cc0_mode = VOIDmode;\n+#endif\n+\n+  /* Find all regs explicitly clobbered in this insn,\n+     to ensure they are not replaced with any other regs\n+     elsewhere in this insn.  */\n+  invalidate_from_sets_and_clobbers (insn);\n+\n+  /* Record all the SETs in this instruction.  */\n+  n_sets = find_sets_in_insn (insn, &sets);\n+\n+  /* Substitute the canonical register where possible.  */\n+  canonicalize_insn (insn, &sets, n_sets);\n+\n+  /* If this insn has a REG_EQUAL note, store the equivalent value in SRC_EQV,\n+     if different, or if the DEST is a STRICT_LOW_PART.  The latter condition\n+     is necessary because SRC_EQV is handled specially for this case, and if\n+     it isn't set, then there will be no equivalence for the destination.  */\n+  if (n_sets == 1 && REG_NOTES (insn) != 0\n+      && (tem = find_reg_note (insn, REG_EQUAL, NULL_RTX)) != 0\n+      && (! rtx_equal_p (XEXP (tem, 0), SET_SRC (sets[0].rtl))\n+\t  || GET_CODE (SET_DEST (sets[0].rtl)) == STRICT_LOW_PART))\n+    src_eqv = copy_rtx (XEXP (tem, 0));\n \n   /* Set sets[i].src_elt to the class each source belongs to.\n      Detect assignments from or to volatile things\n@@ -5492,7 +5628,7 @@ cse_insn (rtx insn)\n \t}\n     }\n \n-  invalidate_from_clobbers (x);\n+  invalidate_from_clobbers (insn);\n \n   /* Some registers are invalidated by subroutine calls.  Memory is\n      invalidated by non-constant calls.  */\n@@ -5788,64 +5924,8 @@ cse_insn (rtx insn)\n \n      Also do not do this if we are operating on a copy of INSN.  */\n \n-  if (n_sets == 1 && sets[0].rtl && REG_P (SET_DEST (sets[0].rtl))\n-      && NEXT_INSN (PREV_INSN (insn)) == insn\n-      && REG_P (SET_SRC (sets[0].rtl))\n-      && REGNO (SET_SRC (sets[0].rtl)) >= FIRST_PSEUDO_REGISTER\n-      && REGNO_QTY_VALID_P (REGNO (SET_SRC (sets[0].rtl))))\n-    {\n-      int src_q = REG_QTY (REGNO (SET_SRC (sets[0].rtl)));\n-      struct qty_table_elem *src_ent = &qty_table[src_q];\n-\n-      if (src_ent->first_reg == REGNO (SET_DEST (sets[0].rtl)))\n-\t{\n-\t  /* Scan for the previous nonnote insn, but stop at a basic\n-\t     block boundary.  */\n-\t  rtx prev = insn;\n-\t  rtx bb_head = BB_HEAD (BLOCK_FOR_INSN (insn));\n-\t  do\n-\t    {\n-\t      prev = PREV_INSN (prev);\n-\t    }\n-\t  while (prev != bb_head && (NOTE_P (prev) || DEBUG_INSN_P (prev)));\n-\n-\t  /* Do not swap the registers around if the previous instruction\n-\t     attaches a REG_EQUIV note to REG1.\n-\n-\t     ??? It's not entirely clear whether we can transfer a REG_EQUIV\n-\t     from the pseudo that originally shadowed an incoming argument\n-\t     to another register.  Some uses of REG_EQUIV might rely on it\n-\t     being attached to REG1 rather than REG2.\n-\n-\t     This section previously turned the REG_EQUIV into a REG_EQUAL\n-\t     note.  We cannot do that because REG_EQUIV may provide an\n-\t     uninitialized stack slot when REG_PARM_STACK_SPACE is used.  */\n-\t  if (NONJUMP_INSN_P (prev)\n-\t      && GET_CODE (PATTERN (prev)) == SET\n-\t      && SET_DEST (PATTERN (prev)) == SET_SRC (sets[0].rtl)\n-\t      && ! find_reg_note (prev, REG_EQUIV, NULL_RTX))\n-\t    {\n-\t      rtx dest = SET_DEST (sets[0].rtl);\n-\t      rtx src = SET_SRC (sets[0].rtl);\n-\t      rtx note;\n-\n-\t      validate_change (prev, &SET_DEST (PATTERN (prev)), dest, 1);\n-\t      validate_change (insn, &SET_DEST (sets[0].rtl), src, 1);\n-\t      validate_change (insn, &SET_SRC (sets[0].rtl), dest, 1);\n-\t      apply_change_group ();\n-\n-\t      /* If INSN has a REG_EQUAL note, and this note mentions\n-\t\t REG0, then we must delete it, because the value in\n-\t\t REG0 has changed.  If the note's value is REG1, we must\n-\t\t also delete it because that is now this insn's dest.  */\n-\t      note = find_reg_note (insn, REG_EQUAL, NULL_RTX);\n-\t      if (note != 0\n-\t\t  && (reg_mentioned_p (dest, XEXP (note, 0))\n-\t\t      || rtx_equal_p (src, XEXP (note, 0))))\n-\t\tremove_note (insn, note);\n-\t    }\n-\t}\n-    }\n+  if (n_sets == 1 && sets[0].rtl)\n+    try_back_substitute_reg (sets[0].rtl, insn);\n \n done:;\n }\n@@ -5867,16 +5947,16 @@ invalidate_memory (void)\n       }\n }\n \n-/* Perform invalidation on the basis of everything about an insn\n+/* Perform invalidation on the basis of everything about INSN,\n    except for invalidating the actual places that are SET in it.\n    This includes the places CLOBBERed, and anything that might\n-   alias with something that is SET or CLOBBERed.\n-\n-   X is the pattern of the insn.  */\n+   alias with something that is SET or CLOBBERed.  */\n \n static void\n-invalidate_from_clobbers (rtx x)\n+invalidate_from_clobbers (rtx insn)\n {\n+  rtx x = PATTERN (insn);\n+\n   if (GET_CODE (x) == CLOBBER)\n     {\n       rtx ref = XEXP (x, 0);\n@@ -5910,6 +5990,53 @@ invalidate_from_clobbers (rtx x)\n     }\n }\n \f\n+/* Perform invalidation on the basis of everything about INSN.\n+   This includes the places CLOBBERed, and anything that might\n+   alias with something that is SET or CLOBBERed.  */\n+\n+static void\n+invalidate_from_sets_and_clobbers (rtx insn)\n+{\n+  rtx tem;\n+  rtx x = PATTERN (insn);\n+\n+  if (CALL_P (insn))\n+    {\n+      for (tem = CALL_INSN_FUNCTION_USAGE (insn); tem; tem = XEXP (tem, 1))\n+\tif (GET_CODE (XEXP (tem, 0)) == CLOBBER)\n+\t  invalidate (SET_DEST (XEXP (tem, 0)), VOIDmode);\n+    }\n+\n+  /* Ensure we invalidate the destination register of a CALL insn.\n+     This is necessary for machines where this register is a fixed_reg,\n+     because no other code would invalidate it.  */\n+  if (GET_CODE (x) == SET && GET_CODE (SET_SRC (x)) == CALL)\n+    invalidate (SET_DEST (x), VOIDmode);\n+\n+  else if (GET_CODE (x) == PARALLEL)\n+    {\n+      int i;\n+\n+      for (i = XVECLEN (x, 0) - 1; i >= 0; i--)\n+\t{\n+\t  rtx y = XVECEXP (x, 0, i);\n+\t  if (GET_CODE (y) == CLOBBER)\n+\t    {\n+\t      rtx clobbered = XEXP (y, 0);\n+\n+\t      if (REG_P (clobbered)\n+\t\t  || GET_CODE (clobbered) == SUBREG)\n+\t\tinvalidate (clobbered, VOIDmode);\n+\t      else if (GET_CODE (clobbered) == STRICT_LOW_PART\n+\t\t       || GET_CODE (clobbered) == ZERO_EXTRACT)\n+\t\tinvalidate (XEXP (clobbered, 0), GET_MODE (clobbered));\n+\t    }\n+\t  else if (GET_CODE (y) == SET && GET_CODE (SET_SRC (y)) == CALL)\n+\t    invalidate (SET_DEST (y), VOIDmode);\n+\t}\n+    }\n+}\n+\f\n /* Process X, part of the REG_NOTES of an insn.  Look at any REG_EQUAL notes\n    and replace any registers in them with either an equivalent constant\n    or the canonical form of the register.  If we are inside an address,"}]}