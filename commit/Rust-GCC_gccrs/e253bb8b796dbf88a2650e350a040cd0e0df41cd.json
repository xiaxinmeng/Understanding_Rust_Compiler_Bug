{"sha": "e253bb8b796dbf88a2650e350a040cd0e0df41cd", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTI1M2JiOGI3OTZkYmY4OGEyNjUwZTM1MGEwNDBjZDBlMGRmNDFjZA==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2021-03-26T16:08:29Z"}, "committer": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2021-03-26T16:08:29Z"}, "message": "aarch64: Add reduction costs to simd_vec_costs\n\nThis patch is part of a series that makes opt-in tweaks to the\nAArch64 vector cost model.\n\nAt the moment, all reductions are costed as vec_to_scalar, which\nalso includes things like extracting a single element from a vector.\nThis is a bit too coarse in practice, since the cost of a reduction\ndepends very much on the type of value that it's processing.\nThis patch therefore adds separate costs for each case.  To start with,\nall the new costs are copied from the associated vec_to_scalar ones.\n\nDue the extreme lateness of this patch in the GCC 11 cycle, I've added\na new tuning flag (use_new_vector_costs) that selects the new behaviour.\nThis should help to ensure that the risk of the new code is only borne\nby the CPUs that need it.  Generic tuning is not affected.\n\ngcc/\n\t* config/aarch64/aarch64-tuning-flags.def (use_new_vector_costs):\n\tNew tuning flag.\n\t* config/aarch64/aarch64-protos.h (simd_vec_cost): Put comments\n\tabove the fields rather than to the right.\n\t(simd_vec_cost::reduc_i8_cost): New member variable.\n\t(simd_vec_cost::reduc_i16_cost): Likewise.\n\t(simd_vec_cost::reduc_i32_cost): Likewise.\n\t(simd_vec_cost::reduc_i64_cost): Likewise.\n\t(simd_vec_cost::reduc_f16_cost): Likewise.\n\t(simd_vec_cost::reduc_f32_cost): Likewise.\n\t(simd_vec_cost::reduc_f64_cost): Likewise.\n\t* config/aarch64/aarch64.c (generic_advsimd_vector_cost): Update\n\taccordingly, using the vec_to_scalar_cost for the new fields.\n\t(generic_sve_vector_cost, a64fx_advsimd_vector_cost): Likewise.\n\t(a64fx_sve_vector_cost, qdf24xx_advsimd_vector_cost): Likewise.\n\t(thunderx_advsimd_vector_cost, tsv110_advsimd_vector_cost): Likewise.\n\t(cortexa57_advsimd_vector_cost, exynosm1_advsimd_vector_cost)\n\t(xgene1_advsimd_vector_cost, thunderx2t99_advsimd_vector_cost)\n\t(thunderx3t110_advsimd_vector_cost): Likewise.\n\t(aarch64_use_new_vector_costs_p): New function.\n\t(aarch64_simd_vec_costs): New function, split out from...\n\t(aarch64_builtin_vectorization_cost): ...here.\n\t(aarch64_is_reduction): New function.\n\t(aarch64_detect_vector_stmt_subtype): Likewise.\n\t(aarch64_add_stmt_cost): Call aarch64_detect_vector_stmt_subtype if\n\tusing the new vector costs.", "tree": {"sha": "9413204af2cfbde4eccbd8ef82b20598421f4500", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/9413204af2cfbde4eccbd8ef82b20598421f4500"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e253bb8b796dbf88a2650e350a040cd0e0df41cd", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e253bb8b796dbf88a2650e350a040cd0e0df41cd", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e253bb8b796dbf88a2650e350a040cd0e0df41cd", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e253bb8b796dbf88a2650e350a040cd0e0df41cd/comments", "author": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "committer": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "fdfcb5353cc2b06fc80205cfcb3bc5ba25556264", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/fdfcb5353cc2b06fc80205cfcb3bc5ba25556264", "html_url": "https://github.com/Rust-GCC/gccrs/commit/fdfcb5353cc2b06fc80205cfcb3bc5ba25556264"}], "stats": {"total": 238, "additions": 216, "deletions": 22}, "files": [{"sha": "e4eeb2ce1420f679eb941ea1742d76aaf3778756", "filename": "gcc/config/aarch64/aarch64-protos.h", "status": "modified", "additions": 40, "deletions": 16, "changes": 56, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e253bb8b796dbf88a2650e350a040cd0e0df41cd/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e253bb8b796dbf88a2650e350a040cd0e0df41cd/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-protos.h?ref=e253bb8b796dbf88a2650e350a040cd0e0df41cd", "patch": "@@ -194,22 +194,46 @@ struct cpu_regmove_cost\n \n struct simd_vec_cost\n {\n-  const int int_stmt_cost;\t\t/* Cost of any int vector operation,\n-\t\t\t\t\t   excluding load, store, permute,\n-\t\t\t\t\t   vector-to-scalar and\n-\t\t\t\t\t   scalar-to-vector operation.  */\n-  const int fp_stmt_cost;\t\t /* Cost of any fp vector operation,\n-\t\t\t\t\t    excluding load, store, permute,\n-\t\t\t\t\t    vector-to-scalar and\n-\t\t\t\t\t    scalar-to-vector operation.  */\n-  const int permute_cost;\t\t /* Cost of permute operation.  */\n-  const int vec_to_scalar_cost;\t\t /* Cost of vec-to-scalar operation.  */\n-  const int scalar_to_vec_cost;\t\t /* Cost of scalar-to-vector\n-\t\t\t\t\t    operation.  */\n-  const int align_load_cost;\t /* Cost of aligned vector load.  */\n-  const int unalign_load_cost;\t /* Cost of unaligned vector load.  */\n-  const int unalign_store_cost;\t /* Cost of unaligned vector store.  */\n-  const int store_cost;\t\t /* Cost of vector store.  */\n+  /* Cost of any integer vector operation, excluding the ones handled\n+     specially below.  */\n+  const int int_stmt_cost;\n+\n+  /* Cost of any fp vector operation, excluding the ones handled\n+     specially below.  */\n+  const int fp_stmt_cost;\n+\n+  /* Cost of a permute operation.  */\n+  const int permute_cost;\n+\n+  /* Cost of reductions for various vector types: iN is for N-bit\n+     integer elements and fN is for N-bit floating-point elements.\n+     We need to single out the element type because it affects the\n+     depth of the reduction.  */\n+  const int reduc_i8_cost;\n+  const int reduc_i16_cost;\n+  const int reduc_i32_cost;\n+  const int reduc_i64_cost;\n+  const int reduc_f16_cost;\n+  const int reduc_f32_cost;\n+  const int reduc_f64_cost;\n+\n+  /* Cost of a vector-to-scalar operation.  */\n+  const int vec_to_scalar_cost;\n+\n+  /* Cost of a scalar-to-vector operation.  */\n+  const int scalar_to_vec_cost;\n+\n+  /* Cost of an aligned vector load.  */\n+  const int align_load_cost;\n+\n+  /* Cost of an unaligned vector load.  */\n+  const int unalign_load_cost;\n+\n+  /* Cost of an unaligned vector store.  */\n+  const int unalign_store_cost;\n+\n+  /* Cost of a vector store.  */\n+  const int store_cost;\n };\n \n typedef struct simd_vec_cost advsimd_vec_cost;"}, {"sha": "a61fcf94916574f78505c079deda2653c53bcd0a", "filename": "gcc/config/aarch64/aarch64-tuning-flags.def", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e253bb8b796dbf88a2650e350a040cd0e0df41cd/gcc%2Fconfig%2Faarch64%2Faarch64-tuning-flags.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e253bb8b796dbf88a2650e350a040cd0e0df41cd/gcc%2Fconfig%2Faarch64%2Faarch64-tuning-flags.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-tuning-flags.def?ref=e253bb8b796dbf88a2650e350a040cd0e0df41cd", "patch": "@@ -48,4 +48,6 @@ AARCH64_EXTRA_TUNING_OPTION (\"rename_load_regs\", RENAME_LOAD_REGS)\n \n AARCH64_EXTRA_TUNING_OPTION (\"cse_sve_vl_constants\", CSE_SVE_VL_CONSTANTS)\n \n+AARCH64_EXTRA_TUNING_OPTION (\"use_new_vector_costs\", USE_NEW_VECTOR_COSTS)\n+\n #undef AARCH64_EXTRA_TUNING_OPTION"}, {"sha": "b44dcdc6a6eb2056a32e5827c536de6f5d0bf880", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 174, "deletions": 6, "changes": 180, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e253bb8b796dbf88a2650e350a040cd0e0df41cd/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e253bb8b796dbf88a2650e350a040cd0e0df41cd/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=e253bb8b796dbf88a2650e350a040cd0e0df41cd", "patch": "@@ -591,6 +591,13 @@ static const advsimd_vec_cost generic_advsimd_vector_cost =\n   1, /* int_stmt_cost  */\n   1, /* fp_stmt_cost  */\n   2, /* permute_cost  */\n+  2, /* reduc_i8_cost  */\n+  2, /* reduc_i16_cost  */\n+  2, /* reduc_i32_cost  */\n+  2, /* reduc_i64_cost  */\n+  2, /* reduc_f16_cost  */\n+  2, /* reduc_f32_cost  */\n+  2, /* reduc_f64_cost  */\n   2, /* vec_to_scalar_cost  */\n   1, /* scalar_to_vec_cost  */\n   1, /* align_load_cost  */\n@@ -605,6 +612,13 @@ static const sve_vec_cost generic_sve_vector_cost =\n   1, /* int_stmt_cost  */\n   1, /* fp_stmt_cost  */\n   2, /* permute_cost  */\n+  2, /* reduc_i8_cost  */\n+  2, /* reduc_i16_cost  */\n+  2, /* reduc_i32_cost  */\n+  2, /* reduc_i64_cost  */\n+  2, /* reduc_f16_cost  */\n+  2, /* reduc_f32_cost  */\n+  2, /* reduc_f64_cost  */\n   2, /* vec_to_scalar_cost  */\n   1, /* scalar_to_vec_cost  */\n   1, /* align_load_cost  */\n@@ -631,6 +645,13 @@ static const advsimd_vec_cost a64fx_advsimd_vector_cost =\n   2, /* int_stmt_cost  */\n   5, /* fp_stmt_cost  */\n   3, /* permute_cost  */\n+  13, /* reduc_i8_cost  */\n+  13, /* reduc_i16_cost  */\n+  13, /* reduc_i32_cost  */\n+  13, /* reduc_i64_cost  */\n+  13, /* reduc_f16_cost  */\n+  13, /* reduc_f32_cost  */\n+  13, /* reduc_f64_cost  */\n   13, /* vec_to_scalar_cost  */\n   4, /* scalar_to_vec_cost  */\n   6, /* align_load_cost  */\n@@ -644,6 +665,13 @@ static const sve_vec_cost a64fx_sve_vector_cost =\n   2, /* int_stmt_cost  */\n   5, /* fp_stmt_cost  */\n   3, /* permute_cost  */\n+  13, /* reduc_i8_cost  */\n+  13, /* reduc_i16_cost  */\n+  13, /* reduc_i32_cost  */\n+  13, /* reduc_i64_cost  */\n+  13, /* reduc_f16_cost  */\n+  13, /* reduc_f32_cost  */\n+  13, /* reduc_f64_cost  */\n   13, /* vec_to_scalar_cost  */\n   4, /* scalar_to_vec_cost  */\n   6, /* align_load_cost  */\n@@ -669,6 +697,13 @@ static const advsimd_vec_cost qdf24xx_advsimd_vector_cost =\n   1, /* int_stmt_cost  */\n   3, /* fp_stmt_cost  */\n   2, /* permute_cost  */\n+  1, /* reduc_i8_cost  */\n+  1, /* reduc_i16_cost  */\n+  1, /* reduc_i32_cost  */\n+  1, /* reduc_i64_cost  */\n+  1, /* reduc_f16_cost  */\n+  1, /* reduc_f32_cost  */\n+  1, /* reduc_f64_cost  */\n   1, /* vec_to_scalar_cost  */\n   1, /* scalar_to_vec_cost  */\n   1, /* align_load_cost  */\n@@ -696,6 +731,13 @@ static const advsimd_vec_cost thunderx_advsimd_vector_cost =\n   4, /* int_stmt_cost  */\n   1, /* fp_stmt_cost  */\n   4, /* permute_cost  */\n+  2, /* reduc_i8_cost  */\n+  2, /* reduc_i16_cost  */\n+  2, /* reduc_i32_cost  */\n+  2, /* reduc_i64_cost  */\n+  2, /* reduc_f16_cost  */\n+  2, /* reduc_f32_cost  */\n+  2, /* reduc_f64_cost  */\n   2, /* vec_to_scalar_cost  */\n   2, /* scalar_to_vec_cost  */\n   3, /* align_load_cost  */\n@@ -722,6 +764,13 @@ static const advsimd_vec_cost tsv110_advsimd_vector_cost =\n   2, /* int_stmt_cost  */\n   2, /* fp_stmt_cost  */\n   2, /* permute_cost  */\n+  3, /* reduc_i8_cost  */\n+  3, /* reduc_i16_cost  */\n+  3, /* reduc_i32_cost  */\n+  3, /* reduc_i64_cost  */\n+  3, /* reduc_f16_cost  */\n+  3, /* reduc_f32_cost  */\n+  3, /* reduc_f64_cost  */\n   3, /* vec_to_scalar_cost  */\n   2, /* scalar_to_vec_cost  */\n   5, /* align_load_cost  */\n@@ -747,6 +796,13 @@ static const advsimd_vec_cost cortexa57_advsimd_vector_cost =\n   2, /* int_stmt_cost  */\n   2, /* fp_stmt_cost  */\n   3, /* permute_cost  */\n+  8, /* reduc_i8_cost  */\n+  8, /* reduc_i16_cost  */\n+  8, /* reduc_i32_cost  */\n+  8, /* reduc_i64_cost  */\n+  8, /* reduc_f16_cost  */\n+  8, /* reduc_f32_cost  */\n+  8, /* reduc_f64_cost  */\n   8, /* vec_to_scalar_cost  */\n   8, /* scalar_to_vec_cost  */\n   4, /* align_load_cost  */\n@@ -773,6 +829,13 @@ static const advsimd_vec_cost exynosm1_advsimd_vector_cost =\n   3, /* int_stmt_cost  */\n   3, /* fp_stmt_cost  */\n   3, /* permute_cost  */\n+  3, /* reduc_i8_cost  */\n+  3, /* reduc_i16_cost  */\n+  3, /* reduc_i32_cost  */\n+  3, /* reduc_i64_cost  */\n+  3, /* reduc_f16_cost  */\n+  3, /* reduc_f32_cost  */\n+  3, /* reduc_f64_cost  */\n   3, /* vec_to_scalar_cost  */\n   3, /* scalar_to_vec_cost  */\n   5, /* align_load_cost  */\n@@ -798,6 +861,13 @@ static const advsimd_vec_cost xgene1_advsimd_vector_cost =\n   2, /* int_stmt_cost  */\n   2, /* fp_stmt_cost  */\n   2, /* permute_cost  */\n+  4, /* reduc_i8_cost  */\n+  4, /* reduc_i16_cost  */\n+  4, /* reduc_i32_cost  */\n+  4, /* reduc_i64_cost  */\n+  4, /* reduc_f16_cost  */\n+  4, /* reduc_f32_cost  */\n+  4, /* reduc_f64_cost  */\n   4, /* vec_to_scalar_cost  */\n   4, /* scalar_to_vec_cost  */\n   10, /* align_load_cost  */\n@@ -824,6 +894,13 @@ static const advsimd_vec_cost thunderx2t99_advsimd_vector_cost =\n   4, /* int_stmt_cost  */\n   5, /* fp_stmt_cost  */\n   10, /* permute_cost  */\n+  6, /* reduc_i8_cost  */\n+  6, /* reduc_i16_cost  */\n+  6, /* reduc_i32_cost  */\n+  6, /* reduc_i64_cost  */\n+  6, /* reduc_f16_cost  */\n+  6, /* reduc_f32_cost  */\n+  6, /* reduc_f64_cost  */\n   6, /* vec_to_scalar_cost  */\n   5, /* scalar_to_vec_cost  */\n   4, /* align_load_cost  */\n@@ -850,6 +927,13 @@ static const advsimd_vec_cost thunderx3t110_advsimd_vector_cost =\n   5, /* int_stmt_cost  */\n   5, /* fp_stmt_cost  */\n   10, /* permute_cost  */\n+  5, /* reduc_i8_cost  */\n+  5, /* reduc_i16_cost  */\n+  5, /* reduc_i32_cost  */\n+  5, /* reduc_i64_cost  */\n+  5, /* reduc_f16_cost  */\n+  5, /* reduc_f32_cost  */\n+  5, /* reduc_f64_cost  */\n   5, /* vec_to_scalar_cost  */\n   5, /* scalar_to_vec_cost  */\n   4, /* align_load_cost  */\n@@ -13874,6 +13958,28 @@ aarch64_first_cycle_multipass_dfa_lookahead_guard (rtx_insn *insn,\n \n /* Vectorizer cost model target hooks.  */\n \n+/* Return true if the current CPU should use the new costs defined\n+   in GCC 11.  This should be removed for GCC 12 and above, with the\n+   costs applying to all CPUs instead.  */\n+static bool\n+aarch64_use_new_vector_costs_p ()\n+{\n+  return (aarch64_tune_params.extra_tuning_flags\n+\t  & AARCH64_EXTRA_TUNE_USE_NEW_VECTOR_COSTS);\n+}\n+\n+/* Return the appropriate SIMD costs for vectors of type VECTYPE.  */\n+static const simd_vec_cost *\n+aarch64_simd_vec_costs (tree vectype)\n+{\n+  const cpu_vector_cost *costs = aarch64_tune_params.vec_costs;\n+  if (vectype != NULL\n+      && aarch64_sve_mode_p (TYPE_MODE (vectype))\n+      && costs->sve != NULL)\n+    return costs->sve;\n+  return costs->advsimd;\n+}\n+\n /* Implement targetm.vectorize.builtin_vectorization_cost.  */\n static int\n aarch64_builtin_vectorization_cost (enum vect_cost_for_stmt type_of_cost,\n@@ -13887,12 +13993,7 @@ aarch64_builtin_vectorization_cost (enum vect_cost_for_stmt type_of_cost,\n   if (vectype != NULL)\n     fp = FLOAT_TYPE_P (vectype);\n \n-  const simd_vec_cost *simd_costs;\n-  if (vectype != NULL && aarch64_sve_mode_p (TYPE_MODE (vectype))\n-      && costs->sve != NULL)\n-    simd_costs = costs->sve;\n-  else\n-    simd_costs = costs->advsimd;\n+  const simd_vec_cost *simd_costs = aarch64_simd_vec_costs (vectype);\n \n   switch (type_of_cost)\n     {\n@@ -13951,6 +14052,14 @@ aarch64_builtin_vectorization_cost (enum vect_cost_for_stmt type_of_cost,\n     }\n }\n \n+/* Return true if STMT_INFO represents part of a reduction.  */\n+static bool\n+aarch64_is_reduction (stmt_vec_info stmt_info)\n+{\n+  return (STMT_VINFO_REDUC_DEF (stmt_info)\n+\t  || VECTORIZABLE_CYCLE_DEF (STMT_VINFO_DEF_TYPE (stmt_info)));\n+}\n+\n /* Return true if creating multiple copies of STMT_INFO for Advanced SIMD\n    vectors would produce a series of LDP or STP operations.  KIND is the\n    kind of statement that STMT_INFO represents.  */\n@@ -14014,6 +14123,57 @@ aarch64_integer_truncation_p (stmt_vec_info stmt_info)\n \t  && TYPE_PRECISION (lhs_type) < TYPE_PRECISION (rhs_type));\n }\n \n+/* STMT_COST is the cost calculated by aarch64_builtin_vectorization_cost\n+   for the vectorized form of STMT_INFO, which has cost kind KIND and which\n+   when vectorized would operate on vector type VECTYPE.  Try to subdivide\n+   the target-independent categorization provided by KIND to get a more\n+   accurate cost.  WHERE specifies where the cost associated with KIND\n+   occurs.  */\n+static unsigned int\n+aarch64_detect_vector_stmt_subtype (vect_cost_for_stmt kind,\n+\t\t\t\t    stmt_vec_info stmt_info, tree vectype,\n+\t\t\t\t    enum vect_cost_model_location where,\n+\t\t\t\t    unsigned int stmt_cost)\n+{\n+  const simd_vec_cost *simd_costs = aarch64_simd_vec_costs (vectype);\n+\n+  /* Detect cases in which vec_to_scalar represents a single reduction\n+     instruction like FADDP or MAXV.  */\n+  if (kind == vec_to_scalar\n+      && where == vect_epilogue\n+      && aarch64_is_reduction (stmt_info))\n+    switch (GET_MODE_INNER (TYPE_MODE (vectype)))\n+      {\n+      case E_QImode:\n+\treturn simd_costs->reduc_i8_cost;\n+\n+      case E_HImode:\n+\treturn simd_costs->reduc_i16_cost;\n+\n+      case E_SImode:\n+\treturn simd_costs->reduc_i32_cost;\n+\n+      case E_DImode:\n+\treturn simd_costs->reduc_i64_cost;\n+\n+      case E_HFmode:\n+      case E_BFmode:\n+\treturn simd_costs->reduc_f16_cost;\n+\n+      case E_SFmode:\n+\treturn simd_costs->reduc_f32_cost;\n+\n+      case E_DFmode:\n+\treturn simd_costs->reduc_f64_cost;\n+\n+      default:\n+\tbreak;\n+      }\n+\n+  /* Otherwise stick with the original categorization.  */\n+  return stmt_cost;\n+}\n+\n /* STMT_COST is the cost calculated by aarch64_builtin_vectorization_cost\n    for STMT_INFO, which has cost kind KIND and which when vectorized would\n    operate on vector type VECTYPE.  Adjust the cost as necessary for SVE\n@@ -14097,6 +14257,14 @@ aarch64_add_stmt_cost (class vec_info *vinfo, void *data, int count,\n       int stmt_cost =\n \t    aarch64_builtin_vectorization_cost (kind, vectype, misalign);\n \n+      /* Try to get a more accurate cost by looking at STMT_INFO instead\n+\t of just looking at KIND.  */\n+      if (stmt_info && vectype && aarch64_use_new_vector_costs_p ())\n+\tstmt_cost = aarch64_detect_vector_stmt_subtype (kind, stmt_info,\n+\t\t\t\t\t\t\tvectype, where,\n+\t\t\t\t\t\t\tstmt_cost);\n+\n+      /* Do any SVE-specific adjustments to the cost.  */\n       if (stmt_info && vectype && aarch64_sve_mode_p (TYPE_MODE (vectype)))\n \tstmt_cost = aarch64_sve_adjust_stmt_cost (vinfo, kind, stmt_info,\n \t\t\t\t\t\t  vectype, stmt_cost);"}]}