{"sha": "753a9523414fee2502d81dfec067e2ad24bfe272", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NzUzYTk1MjM0MTRmZWUyNTAyZDgxZGZlYzA2N2UyYWQyNGJmZTI3Mg==", "commit": {"author": {"name": "Tamar Christina", "email": "tamar.christina@arm.com", "date": "2016-11-29T14:53:46Z"}, "committer": {"name": "Tamar Christina", "email": "tnfchris@gcc.gnu.org", "date": "2016-11-29T14:53:46Z"}, "message": "2016-11-29  Tamar Christina  <tamar.christina@arm.com>\n\n\t* gcc.target/aarch64/advsimd-intrinsics/arm-neon-ref.h\n\t(AARCH64_ONLY, CHECK_CRYPTO): New macros.\n\t(Poly64x1_t, Poly64x2_t): Added types.\n\t* gcc.target/aarch64/advsimd-intrinsics/p64_p128.c\n\t(vmov_n_p64, vmovq_n_p64): Added.\n\t(vld2_lane_p64, vld2q_lane_p64): Likewise.\n\t(vld3_lane_p64, vld3q_lane_p64): Likewise.\n\t(vld4_lane_p64, vld4q_lane_p64): Likewise.\n\t(vst2_lane_p64, vst2q_lane_p64): Likewise.\n\t(vst3_lane_p64, vst3q_lane_p64): Likewise.\n\t(vst4_lane_p64, vst4q_lane_p64): Likewise.\n\t(vget_lane_p64, vgetq_lane_p64): Likewise.\n\t(vget_high_p64): Likewise.\n\t* gcc.target/aarch64/advsimd-intrinsics/vreinterpret_p128.c:\n\tAdded AArch64 flags.\n\t(vreint_vector, vreint_vector_res): Moved to header.\n\t* gcc.target/aarch64/advsimd-intrinsics/vreinterpret_p64.c:\n\tAdded Aarch64 flags.\n\t(vreint_vector, vreint_vector_res): Moved to header.\n\nFrom-SVN: r242962", "tree": {"sha": "4682caa20a7f696189f9a5ee2487c2f87a9e8174", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/4682caa20a7f696189f9a5ee2487c2f87a9e8174"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/753a9523414fee2502d81dfec067e2ad24bfe272", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/753a9523414fee2502d81dfec067e2ad24bfe272", "html_url": "https://github.com/Rust-GCC/gccrs/commit/753a9523414fee2502d81dfec067e2ad24bfe272", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/753a9523414fee2502d81dfec067e2ad24bfe272/comments", "author": {"login": "TamarChristinaArm", "id": 48126768, "node_id": "MDQ6VXNlcjQ4MTI2NzY4", "avatar_url": "https://avatars.githubusercontent.com/u/48126768?v=4", "gravatar_id": "", "url": "https://api.github.com/users/TamarChristinaArm", "html_url": "https://github.com/TamarChristinaArm", "followers_url": "https://api.github.com/users/TamarChristinaArm/followers", "following_url": "https://api.github.com/users/TamarChristinaArm/following{/other_user}", "gists_url": "https://api.github.com/users/TamarChristinaArm/gists{/gist_id}", "starred_url": "https://api.github.com/users/TamarChristinaArm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/TamarChristinaArm/subscriptions", "organizations_url": "https://api.github.com/users/TamarChristinaArm/orgs", "repos_url": "https://api.github.com/users/TamarChristinaArm/repos", "events_url": "https://api.github.com/users/TamarChristinaArm/events{/privacy}", "received_events_url": "https://api.github.com/users/TamarChristinaArm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "6323c98156164b42b0383fc54c29b8f76387a73a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6323c98156164b42b0383fc54c29b8f76387a73a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6323c98156164b42b0383fc54c29b8f76387a73a"}], "stats": {"total": 451, "additions": 439, "deletions": 12}, "files": [{"sha": "71b86849e0c8ff8eb7bf96bafd6033ea139ba50b", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 22, "deletions": 0, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/753a9523414fee2502d81dfec067e2ad24bfe272/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/753a9523414fee2502d81dfec067e2ad24bfe272/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=753a9523414fee2502d81dfec067e2ad24bfe272", "patch": "@@ -1,3 +1,25 @@\n+2016-11-29  Tamar Christina  <tamar.christina@arm.com>\n+\n+\t* gcc.target/aarch64/advsimd-intrinsics/arm-neon-ref.h\n+\t(AARCH64_ONLY, CHECK_CRYPTO): New macros.\n+\t(Poly64x1_t, Poly64x2_t): Added types.\n+\t* gcc.target/aarch64/advsimd-intrinsics/p64_p128.c\n+\t(vmov_n_p64, vmovq_n_p64): Added.\n+\t(vld2_lane_p64, vld2q_lane_p64): Likewise.\n+\t(vld3_lane_p64, vld3q_lane_p64): Likewise.\n+\t(vld4_lane_p64, vld4q_lane_p64): Likewise.\n+\t(vst2_lane_p64, vst2q_lane_p64): Likewise.\n+\t(vst3_lane_p64, vst3q_lane_p64): Likewise.\n+\t(vst4_lane_p64, vst4q_lane_p64): Likewise.\n+\t(vget_lane_p64, vgetq_lane_p64): Likewise.\n+\t(vget_high_p64): Likewise.\n+\t* gcc.target/aarch64/advsimd-intrinsics/vreinterpret_p128.c:\n+\tAdded AArch64 flags.\n+\t(vreint_vector, vreint_vector_res): Moved to header.\n+\t* gcc.target/aarch64/advsimd-intrinsics/vreinterpret_p64.c:\n+\tAdded Aarch64 flags.\n+\t(vreint_vector, vreint_vector_res): Moved to header.\n+\n 2016-11-29  Janus Weil  <janus@gcc.gnu.org>\n \n \tPR fortran/58175"}, {"sha": "beaf6ac31d5c5affe3702a505ad0df8679229e32", "filename": "gcc/testsuite/gcc.target/aarch64/advsimd-intrinsics/arm-neon-ref.h", "status": "modified", "additions": 50, "deletions": 2, "changes": 52, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/753a9523414fee2502d81dfec067e2ad24bfe272/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fadvsimd-intrinsics%2Farm-neon-ref.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/753a9523414fee2502d81dfec067e2ad24bfe272/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fadvsimd-intrinsics%2Farm-neon-ref.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fadvsimd-intrinsics%2Farm-neon-ref.h?ref=753a9523414fee2502d81dfec067e2ad24bfe272", "patch": "@@ -32,6 +32,13 @@ extern size_t strlen(const char *);\n    VECT_VAR(expected, int, 16, 4) -> expected_int16x4\n    VECT_VAR_DECL(expected, int, 16, 4) -> int16x4_t expected_int16x4\n */\n+/* Some instructions don't exist on ARM.\n+   Use this macro to guard against them.  */\n+#ifdef __aarch64__\n+#define AARCH64_ONLY(X) X\n+#else\n+#define AARCH64_ONLY(X)\n+#endif\n \n #define xSTR(X) #X\n #define STR(X) xSTR(X)\n@@ -92,6 +99,13 @@ extern size_t strlen(const char *);\n     fprintf(stderr, \"CHECKED %s %s\\n\", STR(VECT_TYPE(T, W, N)), MSG);\t\\\n   }\n \n+#if defined (__ARM_FEATURE_CRYPTO)\n+#define CHECK_CRYPTO(MSG,T,W,N,FMT,EXPECTED,COMMENT) \\\n+\t       CHECK(MSG,T,W,N,FMT,EXPECTED,COMMENT)\n+#else\n+#define CHECK_CRYPTO(MSG,T,W,N,FMT,EXPECTED,COMMENT)\n+#endif\n+\n /* Floating-point variant.  */\n #define CHECK_FP(MSG,T,W,N,FMT,EXPECTED,COMMENT)\t\t\t\\\n   {\t\t\t\t\t\t\t\t\t\\\n@@ -184,6 +198,9 @@ extern ARRAY(expected, uint, 32, 2);\n extern ARRAY(expected, uint, 64, 1);\n extern ARRAY(expected, poly, 8, 8);\n extern ARRAY(expected, poly, 16, 4);\n+#if defined (__ARM_FEATURE_CRYPTO)\n+extern ARRAY(expected, poly, 64, 1);\n+#endif\n extern ARRAY(expected, hfloat, 16, 4);\n extern ARRAY(expected, hfloat, 32, 2);\n extern ARRAY(expected, hfloat, 64, 1);\n@@ -197,6 +214,9 @@ extern ARRAY(expected, uint, 32, 4);\n extern ARRAY(expected, uint, 64, 2);\n extern ARRAY(expected, poly, 8, 16);\n extern ARRAY(expected, poly, 16, 8);\n+#if defined (__ARM_FEATURE_CRYPTO)\n+extern ARRAY(expected, poly, 64, 2);\n+#endif\n extern ARRAY(expected, hfloat, 16, 8);\n extern ARRAY(expected, hfloat, 32, 4);\n extern ARRAY(expected, hfloat, 64, 2);\n@@ -213,6 +233,7 @@ extern ARRAY(expected, hfloat, 64, 2);\n     CHECK(test_name, uint, 64, 1, PRIx64, EXPECTED, comment);\t\t\\\n     CHECK(test_name, poly, 8, 8, PRIx8, EXPECTED, comment);\t\t\\\n     CHECK(test_name, poly, 16, 4, PRIx16, EXPECTED, comment);\t\t\\\n+    CHECK_CRYPTO(test_name, poly, 64, 1, PRIx64, EXPECTED, comment);\t\\\n     CHECK_FP(test_name, float, 32, 2, PRIx32, EXPECTED, comment);\t\\\n \t\t\t\t\t\t\t\t\t\\\n     CHECK(test_name, int, 8, 16, PRIx8, EXPECTED, comment);\t\t\\\n@@ -225,6 +246,7 @@ extern ARRAY(expected, hfloat, 64, 2);\n     CHECK(test_name, uint, 64, 2, PRIx64, EXPECTED, comment);\t\t\\\n     CHECK(test_name, poly, 8, 16, PRIx8, EXPECTED, comment);\t\t\\\n     CHECK(test_name, poly, 16, 8, PRIx16, EXPECTED, comment);\t\t\\\n+    CHECK_CRYPTO(test_name, poly, 64, 2, PRIx64, EXPECTED, comment);\t\\\n     CHECK_FP(test_name, float, 32, 4, PRIx32, EXPECTED, comment);\t\\\n   }\t\t\t\t\t\t\t\t\t\\\n \n@@ -398,6 +420,9 @@ static void clean_results (void)\n   CLEAN(result, uint, 64, 1);\n   CLEAN(result, poly, 8, 8);\n   CLEAN(result, poly, 16, 4);\n+#if defined (__ARM_FEATURE_CRYPTO)\n+  CLEAN(result, poly, 64, 1);\n+#endif\n #if defined (__ARM_FP16_FORMAT_IEEE) || defined (__ARM_FP16_FORMAT_ALTERNATIVE)\n   CLEAN(result, float, 16, 4);\n #endif\n@@ -413,6 +438,9 @@ static void clean_results (void)\n   CLEAN(result, uint, 64, 2);\n   CLEAN(result, poly, 8, 16);\n   CLEAN(result, poly, 16, 8);\n+#if defined (__ARM_FEATURE_CRYPTO)\n+  CLEAN(result, poly, 64, 2);\n+#endif\n #if defined (__ARM_FP16_FORMAT_IEEE) || defined (__ARM_FP16_FORMAT_ALTERNATIVE)\n   CLEAN(result, float, 16, 8);\n #endif\n@@ -438,6 +466,13 @@ static void clean_results (void)\n #define DECL_VARIABLE(VAR, T1, W, N)\t\t\\\n   VECT_TYPE(T1, W, N) VECT_VAR(VAR, T1, W, N)\n \n+#if defined (__ARM_FEATURE_CRYPTO)\n+#define DECL_VARIABLE_CRYPTO(VAR, T1, W, N) \\\n+  DECL_VARIABLE(VAR, T1, W, N)\n+#else\n+#define DECL_VARIABLE_CRYPTO(VAR, T1, W, N)\n+#endif\n+\n /* Declare only 64 bits signed variants.  */\n #define DECL_VARIABLE_64BITS_SIGNED_VARIANTS(VAR)\t\\\n   DECL_VARIABLE(VAR, int, 8, 8);\t\t\t\\\n@@ -473,6 +508,7 @@ static void clean_results (void)\n   DECL_VARIABLE_64BITS_UNSIGNED_VARIANTS(VAR);\t\\\n   DECL_VARIABLE(VAR, poly, 8, 8);\t\t\\\n   DECL_VARIABLE(VAR, poly, 16, 4);\t\t\\\n+  DECL_VARIABLE_CRYPTO(VAR, poly, 64, 1);\t\\\n   DECL_VARIABLE(VAR, float, 16, 4);\t\t\\\n   DECL_VARIABLE(VAR, float, 32, 2)\n #else\n@@ -481,6 +517,7 @@ static void clean_results (void)\n   DECL_VARIABLE_64BITS_UNSIGNED_VARIANTS(VAR);\t\\\n   DECL_VARIABLE(VAR, poly, 8, 8);\t\t\\\n   DECL_VARIABLE(VAR, poly, 16, 4);\t\t\\\n+  DECL_VARIABLE_CRYPTO(VAR, poly, 64, 1);\t\\\n   DECL_VARIABLE(VAR, float, 32, 2)\n #endif\n \n@@ -491,6 +528,7 @@ static void clean_results (void)\n   DECL_VARIABLE_128BITS_UNSIGNED_VARIANTS(VAR);\t\\\n   DECL_VARIABLE(VAR, poly, 8, 16);\t\t\\\n   DECL_VARIABLE(VAR, poly, 16, 8);\t\t\\\n+  DECL_VARIABLE_CRYPTO(VAR, poly, 64, 2);\t\\\n   DECL_VARIABLE(VAR, float, 16, 8);\t\t\\\n   DECL_VARIABLE(VAR, float, 32, 4)\n #else\n@@ -499,6 +537,7 @@ static void clean_results (void)\n   DECL_VARIABLE_128BITS_UNSIGNED_VARIANTS(VAR);\t\\\n   DECL_VARIABLE(VAR, poly, 8, 16);\t\t\\\n   DECL_VARIABLE(VAR, poly, 16, 8);\t\t\\\n+  DECL_VARIABLE_CRYPTO(VAR, poly, 64, 2);\t\\\n   DECL_VARIABLE(VAR, float, 32, 4)\n #endif\n /* Declare all variants.  */\n@@ -531,6 +570,13 @@ static void clean_results (void)\n \n /* Helpers to call macros with 1 constant and 5 variable\n    arguments.  */\n+#if defined (__ARM_FEATURE_CRYPTO)\n+#define MACRO_CRYPTO(MACRO, VAR1, VAR2, T1, T2, T3, W, N) \\\n+  MACRO(VAR1, VAR2, T1, T2, T3, W, N)\n+#else\n+#define MACRO_CRYPTO(MACRO, VAR1, VAR2, T1, T2, T3, W, N)\n+#endif\n+\n #define TEST_MACRO_64BITS_SIGNED_VARIANTS_1_5(MACRO, VAR)\t\\\n   MACRO(VAR, , int, s, 8, 8);\t\t\t\t\t\\\n   MACRO(VAR, , int, s, 16, 4);\t\t\t\t\t\\\n@@ -601,13 +647,15 @@ static void clean_results (void)\n   TEST_MACRO_64BITS_SIGNED_VARIANTS_2_5(MACRO, VAR1, VAR2);\t\\\n   TEST_MACRO_64BITS_UNSIGNED_VARIANTS_2_5(MACRO, VAR1, VAR2);\t\\\n   MACRO(VAR1, VAR2, , poly, p, 8, 8);\t\t\t\t\\\n-  MACRO(VAR1, VAR2, , poly, p, 16, 4)\n+  MACRO(VAR1, VAR2, , poly, p, 16, 4);\t\t\t\t\\\n+  MACRO_CRYPTO(MACRO, VAR1, VAR2, , poly, p, 64, 1)\n \n #define TEST_MACRO_128BITS_VARIANTS_2_5(MACRO, VAR1, VAR2)\t\\\n   TEST_MACRO_128BITS_SIGNED_VARIANTS_2_5(MACRO, VAR1, VAR2);\t\\\n   TEST_MACRO_128BITS_UNSIGNED_VARIANTS_2_5(MACRO, VAR1, VAR2);\t\\\n   MACRO(VAR1, VAR2, q, poly, p, 8, 16);\t\t\t\t\\\n-  MACRO(VAR1, VAR2, q, poly, p, 16, 8)\n+  MACRO(VAR1, VAR2, q, poly, p, 16, 8);\t\t\t\t\\\n+  MACRO_CRYPTO(MACRO, VAR1, VAR2, q, poly, p, 64, 2)\n \n #define TEST_MACRO_ALL_VARIANTS_2_5(MACRO, VAR1, VAR2)\t\\\n   TEST_MACRO_64BITS_VARIANTS_2_5(MACRO, VAR1, VAR2);\t\\"}, {"sha": "8907b38cde90b44a8f1501f72b2c4e812cba5707", "filename": "gcc/testsuite/gcc.target/aarch64/advsimd-intrinsics/p64_p128.c", "status": "modified", "additions": 363, "deletions": 2, "changes": 365, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/753a9523414fee2502d81dfec067e2ad24bfe272/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fadvsimd-intrinsics%2Fp64_p128.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/753a9523414fee2502d81dfec067e2ad24bfe272/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fadvsimd-intrinsics%2Fp64_p128.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fadvsimd-intrinsics%2Fp64_p128.c?ref=753a9523414fee2502d81dfec067e2ad24bfe272", "patch": "@@ -1,8 +1,9 @@\n /* This file contains tests for all the *p64 intrinsics, except for\n    vreinterpret which have their own testcase.  */\n \n-/* { dg-require-effective-target arm_crypto_ok } */\n+/* { dg-require-effective-target arm_crypto_ok { target { arm*-*-* } } } */\n /* { dg-add-options arm_crypto } */\n+/* { dg-additional-options \"-march=armv8-a+crypto\" { target { aarch64*-*-* } } }*/\n \n #include <arm_neon.h>\n #include \"arm-neon-ref.h\"\n@@ -38,13 +39,27 @@ VECT_VAR_DECL(vdup_n_expected2,poly,64,1) [] = { 0xfffffffffffffff2 };\n VECT_VAR_DECL(vdup_n_expected2,poly,64,2) [] = { 0xfffffffffffffff2,\n \t\t\t\t\t\t 0xfffffffffffffff2 };\n \n+/* Expected results: vmov_n.  */\n+VECT_VAR_DECL(vmov_n_expected0,poly,64,1) [] = { 0xfffffffffffffff0 };\n+VECT_VAR_DECL(vmov_n_expected0,poly,64,2) [] = { 0xfffffffffffffff0,\n+\t\t\t\t\t\t 0xfffffffffffffff0 };\n+VECT_VAR_DECL(vmov_n_expected1,poly,64,1) [] = { 0xfffffffffffffff1 };\n+VECT_VAR_DECL(vmov_n_expected1,poly,64,2) [] = { 0xfffffffffffffff1,\n+\t\t\t\t\t\t 0xfffffffffffffff1 };\n+VECT_VAR_DECL(vmov_n_expected2,poly,64,1) [] = { 0xfffffffffffffff2 };\n+VECT_VAR_DECL(vmov_n_expected2,poly,64,2) [] = { 0xfffffffffffffff2,\n+\t\t\t\t\t\t 0xfffffffffffffff2 };\n+\n /* Expected results: vext.  */\n VECT_VAR_DECL(vext_expected,poly,64,1) [] = { 0xfffffffffffffff0 };\n VECT_VAR_DECL(vext_expected,poly,64,2) [] = { 0xfffffffffffffff1, 0x88 };\n \n /* Expected results: vget_low.  */\n VECT_VAR_DECL(vget_low_expected,poly,64,1) [] = { 0xfffffffffffffff0 };\n \n+/* Expected results: vget_high.  */\n+VECT_VAR_DECL(vget_high_expected,poly,64,1) [] = { 0xfffffffffffffff1 };\n+\n /* Expected results: vld1.  */\n VECT_VAR_DECL(vld1_expected,poly,64,1) [] = { 0xfffffffffffffff0 };\n VECT_VAR_DECL(vld1_expected,poly,64,2) [] = { 0xfffffffffffffff0,\n@@ -109,6 +124,39 @@ VECT_VAR_DECL(vst1_lane_expected,poly,64,1) [] = { 0xfffffffffffffff0 };\n VECT_VAR_DECL(vst1_lane_expected,poly,64,2) [] = { 0xfffffffffffffff0,\n \t\t\t\t\t\t   0x3333333333333333 };\n \n+/* Expected results: vldX_lane.  */\n+VECT_VAR_DECL(expected_vld_st2_0,poly,64,1) [] = { 0xfffffffffffffff0 };\n+VECT_VAR_DECL(expected_vld_st2_0,poly,64,2) [] = { 0xfffffffffffffff0,\n+\t\t\t\t\t\t   0xfffffffffffffff1 };\n+VECT_VAR_DECL(expected_vld_st2_1,poly,64,1) [] = { 0xfffffffffffffff1 };\n+VECT_VAR_DECL(expected_vld_st2_1,poly,64,2) [] = { 0xaaaaaaaaaaaaaaaa,\n+\t\t\t\t\t\t   0xaaaaaaaaaaaaaaaa };\n+VECT_VAR_DECL(expected_vld_st3_0,poly,64,1) [] = { 0xfffffffffffffff0 };\n+VECT_VAR_DECL(expected_vld_st3_0,poly,64,2) [] = { 0xfffffffffffffff0,\n+\t\t\t\t\t\t   0xfffffffffffffff1 };\n+VECT_VAR_DECL(expected_vld_st3_1,poly,64,1) [] = { 0xfffffffffffffff1 };\n+VECT_VAR_DECL(expected_vld_st3_1,poly,64,2) [] = { 0xfffffffffffffff2,\n+\t\t\t\t\t\t   0xaaaaaaaaaaaaaaaa };\n+VECT_VAR_DECL(expected_vld_st3_2,poly,64,1) [] = { 0xfffffffffffffff2 };\n+VECT_VAR_DECL(expected_vld_st3_2,poly,64,2) [] = { 0xaaaaaaaaaaaaaaaa,\n+\t\t\t\t\t\t   0xaaaaaaaaaaaaaaaa };\n+VECT_VAR_DECL(expected_vld_st4_0,poly,64,1) [] = { 0xfffffffffffffff0 };\n+VECT_VAR_DECL(expected_vld_st4_0,poly,64,2) [] = { 0xfffffffffffffff0,\n+\t\t\t\t\t\t   0xfffffffffffffff1 };\n+VECT_VAR_DECL(expected_vld_st4_1,poly,64,1) [] = { 0xfffffffffffffff1 };\n+VECT_VAR_DECL(expected_vld_st4_1,poly,64,2) [] = { 0xfffffffffffffff2,\n+\t\t\t\t\t\t   0xfffffffffffffff3 };\n+VECT_VAR_DECL(expected_vld_st4_2,poly,64,1) [] = { 0xfffffffffffffff2 };\n+VECT_VAR_DECL(expected_vld_st4_2,poly,64,2) [] = { 0xaaaaaaaaaaaaaaaa,\n+\t\t\t\t\t\t   0xaaaaaaaaaaaaaaaa };\n+VECT_VAR_DECL(expected_vld_st4_3,poly,64,1) [] = { 0xfffffffffffffff3 };\n+VECT_VAR_DECL(expected_vld_st4_3,poly,64,2) [] = { 0xaaaaaaaaaaaaaaaa,\n+\t\t\t\t\t\t   0xaaaaaaaaaaaaaaaa };\n+\n+/* Expected results: vget_lane.  */\n+VECT_VAR_DECL(vget_lane_expected,poly,64,1) = 0xfffffffffffffff0;\n+VECT_VAR_DECL(vget_lane_expected,poly,64,2) = 0xfffffffffffffff0;\n+\n int main (void)\n {\n   int i;\n@@ -341,6 +389,26 @@ int main (void)\n \n   CHECK(TEST_MSG, poly, 64, 1, PRIx64, vget_low_expected, \"\");\n \n+  /* vget_high_p64 tests.  */\n+#undef TEST_MSG\n+#define TEST_MSG \"VGET_HIGH\"\n+\n+#define TEST_VGET_HIGH(T1, T2, W, N, N2)\t\t\t\t\t\\\n+  VECT_VAR(vget_high_vector64, T1, W, N) =\t\t\t\t\\\n+    vget_high_##T2##W(VECT_VAR(vget_high_vector128, T1, W, N2));\t\t\\\n+  vst1_##T2##W(VECT_VAR(result, T1, W, N), VECT_VAR(vget_high_vector64, T1, W, N))\n+\n+  DECL_VARIABLE(vget_high_vector64, poly, 64, 1);\n+  DECL_VARIABLE(vget_high_vector128, poly, 64, 2);\n+\n+  CLEAN(result, poly, 64, 1);\n+\n+  VLOAD(vget_high_vector128, buffer, q, poly, p, 64, 2);\n+\n+  TEST_VGET_HIGH(poly, p, 64, 1, 2);\n+\n+  CHECK(TEST_MSG, poly, 64, 1, PRIx64, vget_high_expected, \"\");\n+\n   /* vld1_p64 tests.  */\n #undef TEST_MSG\n #define TEST_MSG \"VLD1/VLD1Q\"\n@@ -645,7 +713,7 @@ int main (void)\n   VECT_VAR(vst1_lane_vector, T1, W, N) =\t\t\t\t\\\n     vld1##Q##_##T2##W(VECT_VAR(buffer, T1, W, N));\t\t\t\\\n   vst1##Q##_lane_##T2##W(VECT_VAR(result, T1, W, N),\t\t\t\\\n-\t\t\t VECT_VAR(vst1_lane_vector, T1, W, N), L)\n+\t\t\t VECT_VAR(vst1_lane_vector, T1, W, N), L);\n \n   DECL_VARIABLE(vst1_lane_vector, poly, 64, 1);\n   DECL_VARIABLE(vst1_lane_vector, poly, 64, 2);\n@@ -659,5 +727,298 @@ int main (void)\n   CHECK(TEST_MSG, poly, 64, 1, PRIx64, vst1_lane_expected, \"\");\n   CHECK(TEST_MSG, poly, 64, 2, PRIx64, vst1_lane_expected, \"\");\n \n+#ifdef __aarch64__\n+\n+  /* vmov_n_p64 tests.  */\n+#undef TEST_MSG\n+#define TEST_MSG \"VMOV/VMOVQ\"\n+\n+#define TEST_VMOV(Q, T1, T2, W, N)\t\t\t\t\t\\\n+  VECT_VAR(vmov_n_vector, T1, W, N) =\t\t\t\t\t\\\n+    vmov##Q##_n_##T2##W(VECT_VAR(buffer_dup, T1, W, N)[i]);\t\t\\\n+  vst1##Q##_##T2##W(VECT_VAR(result, T1, W, N), VECT_VAR(vmov_n_vector, T1, W, N))\n+\n+  DECL_VARIABLE(vmov_n_vector, poly, 64, 1);\n+  DECL_VARIABLE(vmov_n_vector, poly, 64, 2);\n+\n+  /* Try to read different places from the input buffer.  */\n+  for (i=0; i< 3; i++) {\n+    CLEAN(result, poly, 64, 1);\n+    CLEAN(result, poly, 64, 2);\n+\n+    TEST_VMOV(, poly, p, 64, 1);\n+    TEST_VMOV(q, poly, p, 64, 2);\n+\n+    switch (i) {\n+    case 0:\n+      CHECK(TEST_MSG, poly, 64, 1, PRIx64, vmov_n_expected0, \"\");\n+      CHECK(TEST_MSG, poly, 64, 2, PRIx64, vmov_n_expected0, \"\");\n+      break;\n+    case 1:\n+      CHECK(TEST_MSG, poly, 64, 1, PRIx64, vmov_n_expected1, \"\");\n+      CHECK(TEST_MSG, poly, 64, 2, PRIx64, vmov_n_expected1, \"\");\n+      break;\n+    case 2:\n+      CHECK(TEST_MSG, poly, 64, 1, PRIx64, vmov_n_expected2, \"\");\n+      CHECK(TEST_MSG, poly, 64, 2, PRIx64, vmov_n_expected2, \"\");\n+      break;\n+    default:\n+      abort();\n+    }\n+  }\n+\n+  /* vget_lane_p64 tests.  */\n+#undef TEST_MSG\n+#define TEST_MSG \"VGET_LANE/VGETQ_LANE\"\n+\n+#define TEST_VGET_LANE(Q, T1, T2, W, N, L)\t\t\t\t   \\\n+  VECT_VAR(vget_lane_vector, T1, W, N) = vget##Q##_lane_##T2##W(VECT_VAR(vector, T1, W, N), L); \\\n+  if (VECT_VAR(vget_lane_vector, T1, W, N) != VECT_VAR(vget_lane_expected, T1, W, N)) {\t\t\\\n+    fprintf(stderr,\t\t\t\t\t\t\t   \\\n+\t    \"ERROR in %s (%s line %d in result '%s') at type %s \"\t   \\\n+\t    \"got 0x%\" PRIx##W \" != 0x%\" PRIx##W \"\\n\",\t\t\t   \\\n+\t    TEST_MSG, __FILE__, __LINE__,\t\t\t\t   \\\n+\t    STR(VECT_VAR(vget_lane_expected, T1, W, N)),\t\t   \\\n+\t    STR(VECT_NAME(T1, W, N)),\t\t\t\t\t   \\\n+\t    VECT_VAR(vget_lane_vector, T1, W, N),\t\t\t   \\\n+\t    VECT_VAR(vget_lane_expected, T1, W, N));\t\t\t   \\\n+    abort ();\t\t\t\t\t\t\t\t   \\\n+  }\n+\n+  /* Initialize input values.  */\n+  DECL_VARIABLE(vector, poly, 64, 1);\n+  DECL_VARIABLE(vector, poly, 64, 2);\n+\n+  VLOAD(vector, buffer,  , poly, p, 64, 1);\n+  VLOAD(vector, buffer, q, poly, p, 64, 2);\n+\n+  VECT_VAR_DECL(vget_lane_vector, poly, 64, 1);\n+  VECT_VAR_DECL(vget_lane_vector, poly, 64, 2);\n+\n+  TEST_VGET_LANE( , poly, p, 64, 1, 0);\n+  TEST_VGET_LANE(q, poly, p, 64, 2, 0);\n+\n+  /* vldx_lane_p64 tests.  */\n+#undef TEST_MSG\n+#define TEST_MSG \"VLDX_LANE/VLDXQ_LANE\"\n+\n+VECT_VAR_DECL_INIT(buffer_vld2_lane, poly, 64, 2);\n+VECT_VAR_DECL_INIT(buffer_vld3_lane, poly, 64, 3);\n+VECT_VAR_DECL_INIT(buffer_vld4_lane, poly, 64, 4);\n+\n+  /* In this case, input variables are arrays of vectors.  */\n+#define DECL_VLD_STX_LANE(T1, W, N, X)\t\t\t\t\t\\\n+  VECT_ARRAY_TYPE(T1, W, N, X) VECT_ARRAY_VAR(vector, T1, W, N, X);\t\\\n+  VECT_ARRAY_TYPE(T1, W, N, X) VECT_ARRAY_VAR(vector_src, T1, W, N, X);\t\\\n+  VECT_VAR_DECL(result_bis_##X, T1, W, N)[X * N]\n+\n+  /* We need to use a temporary result buffer (result_bis), because\n+     the one used for other tests is not large enough. A subset of the\n+     result data is moved from result_bis to result, and it is this\n+     subset which is used to check the actual behavior. The next\n+     macro enables to move another chunk of data from result_bis to\n+     result.  */\n+  /* We also use another extra input buffer (buffer_src), which we\n+     fill with 0xAA, and which it used to load a vector from which we\n+     read a given lane.  */\n+\n+#define TEST_VLDX_LANE(Q, T1, T2, W, N, X, L)\t\t\t\t\\\n+  memset (VECT_VAR(buffer_src, T1, W, N), 0xAA,\t\t\t\t\\\n+\t  sizeof(VECT_VAR(buffer_src, T1, W, N)));\t\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+  VECT_ARRAY_VAR(vector_src, T1, W, N, X) =\t\t\t\t\\\n+    vld##X##Q##_##T2##W(VECT_VAR(buffer_src, T1, W, N));\t\t\\\n+\t\t\t\t\t\t\t\t\t\\\n+  VECT_ARRAY_VAR(vector, T1, W, N, X) =\t\t\t\t\t\\\n+    /* Use dedicated init buffer, of size.  X */\t\t\t\\\n+    vld##X##Q##_lane_##T2##W(VECT_VAR(buffer_vld##X##_lane, T1, W, X),\t\\\n+\t\t\t     VECT_ARRAY_VAR(vector_src, T1, W, N, X),\t\\\n+\t\t\t     L);\t\t\t\t\t\\\n+  vst##X##Q##_##T2##W(VECT_VAR(result_bis_##X, T1, W, N),\t\t\\\n+\t\t      VECT_ARRAY_VAR(vector, T1, W, N, X));\t\t\\\n+  memcpy(VECT_VAR(result, T1, W, N), VECT_VAR(result_bis_##X, T1, W, N), \\\n+\t sizeof(VECT_VAR(result, T1, W, N)))\n+\n+  /* Overwrite \"result\" with the contents of \"result_bis\"[Y].  */\n+#undef TEST_EXTRA_CHUNK\n+#define TEST_EXTRA_CHUNK(T1, W, N, X, Y)\t\t\\\n+  memcpy(VECT_VAR(result, T1, W, N),\t\t\t\\\n+\t &(VECT_VAR(result_bis_##X, T1, W, N)[Y*N]),\t\\\n+\t sizeof(VECT_VAR(result, T1, W, N)));\n+\n+  /* Add some padding to try to catch out of bound accesses.  */\n+#define ARRAY1(V, T, W, N) VECT_VAR_DECL(V,T,W,N)[1]={42}\n+#define DUMMY_ARRAY(V, T, W, N, L) \\\n+  VECT_VAR_DECL(V,T,W,N)[N*L]={0}; \\\n+  ARRAY1(V##_pad,T,W,N)\n+\n+#define DECL_ALL_VLD_STX_LANE(X)     \\\n+  DECL_VLD_STX_LANE(poly, 64, 1, X); \\\n+  DECL_VLD_STX_LANE(poly, 64, 2, X);\n+\n+#define TEST_ALL_VLDX_LANE(X)\t\t  \\\n+  TEST_VLDX_LANE(, poly, p, 64, 1, X, 0); \\\n+  TEST_VLDX_LANE(q, poly, p, 64, 2, X, 0);\n+\n+#define TEST_ALL_EXTRA_CHUNKS(X,Y)\t     \\\n+  TEST_EXTRA_CHUNK(poly, 64, 1, X, Y) \\\n+  TEST_EXTRA_CHUNK(poly, 64, 2, X, Y)\n+\n+#define CHECK_RESULTS_VLD_STX_LANE(test_name,EXPECTED,comment)\t\\\n+  CHECK(test_name, poly, 64, 1, PRIx64, EXPECTED, comment);\t\\\n+  CHECK(test_name, poly, 64, 2, PRIx64, EXPECTED, comment);\n+\n+  /* Declare the temporary buffers / variables.  */\n+  DECL_ALL_VLD_STX_LANE(2);\n+  DECL_ALL_VLD_STX_LANE(3);\n+  DECL_ALL_VLD_STX_LANE(4);\n+\n+  DUMMY_ARRAY(buffer_src, poly, 64, 1, 4);\n+  DUMMY_ARRAY(buffer_src, poly, 64, 2, 4);\n+\n+  /* Check vld2_lane/vld2q_lane.  */\n+  clean_results ();\n+#undef TEST_MSG\n+#define TEST_MSG \"VLD2_LANE/VLD2Q_LANE\"\n+  TEST_ALL_VLDX_LANE(2);\n+  CHECK_RESULTS_VLD_STX_LANE (TEST_MSG, expected_vld_st2_0, \" chunk 0\");\n+\n+  TEST_ALL_EXTRA_CHUNKS(2, 1);\n+  CHECK_RESULTS_VLD_STX_LANE (TEST_MSG, expected_vld_st2_1, \" chunk 1\");\n+\n+  /* Check vld3_lane/vld3q_lane.  */\n+  clean_results ();\n+#undef TEST_MSG\n+#define TEST_MSG \"VLD3_LANE/VLD3Q_LANE\"\n+  TEST_ALL_VLDX_LANE(3);\n+  CHECK_RESULTS_VLD_STX_LANE (TEST_MSG, expected_vld_st3_0, \" chunk 0\");\n+\n+  TEST_ALL_EXTRA_CHUNKS(3, 1);\n+  CHECK_RESULTS_VLD_STX_LANE (TEST_MSG, expected_vld_st3_1, \" chunk 1\");\n+\n+  TEST_ALL_EXTRA_CHUNKS(3, 2);\n+  CHECK_RESULTS_VLD_STX_LANE (TEST_MSG, expected_vld_st3_2, \" chunk 2\");\n+\n+  /* Check vld4_lane/vld4q_lane.  */\n+  clean_results ();\n+#undef TEST_MSG\n+#define TEST_MSG \"VLD4_LANE/VLD4Q_LANE\"\n+  TEST_ALL_VLDX_LANE(4);\n+  CHECK_RESULTS_VLD_STX_LANE (TEST_MSG, expected_vld_st4_0, \" chunk 0\");\n+\n+  TEST_ALL_EXTRA_CHUNKS(4, 1);\n+  CHECK_RESULTS_VLD_STX_LANE (TEST_MSG, expected_vld_st4_1, \" chunk 1\");\n+  TEST_ALL_EXTRA_CHUNKS(4, 2);\n+\n+  CHECK_RESULTS_VLD_STX_LANE (TEST_MSG, expected_vld_st4_2, \" chunk 2\");\n+\n+  TEST_ALL_EXTRA_CHUNKS(4, 3);\n+  CHECK_RESULTS_VLD_STX_LANE (TEST_MSG, expected_vld_st4_3, \" chunk 3\");\n+\n+  /* In this case, input variables are arrays of vectors.  */\n+#define DECL_VSTX_LANE(T1, W, N, X)\t\t\t\t\t\\\n+  VECT_ARRAY_TYPE(T1, W, N, X) VECT_ARRAY_VAR(vector, T1, W, N, X);\t\\\n+  VECT_ARRAY_TYPE(T1, W, N, X) VECT_ARRAY_VAR(vector_src, T1, W, N, X);\t\\\n+  VECT_VAR_DECL(result_bis_##X, T1, W, N)[X * N]\n+\n+  /* We need to use a temporary result buffer (result_bis), because\n+     the one used for other tests is not large enough. A subset of the\n+     result data is moved from result_bis to result, and it is this\n+     subset which is used to check the actual behavior. The next\n+     macro enables to move another chunk of data from result_bis to\n+     result.  */\n+  /* We also use another extra input buffer (buffer_src), which we\n+     fill with 0xAA, and which it used to load a vector from which we\n+     read a given lane.  */\n+#define TEST_VSTX_LANE(Q, T1, T2, W, N, X, L)\t\t\t\t \\\n+  memset (VECT_VAR(buffer_src, T1, W, N), 0xAA,\t\t\t\t \\\n+\t  sizeof(VECT_VAR(buffer_src, T1, W, N)));\t\t\t \\\n+  memset (VECT_VAR(result_bis_##X, T1, W, N), 0,\t\t\t \\\n+\t  sizeof(VECT_VAR(result_bis_##X, T1, W, N)));\t\t\t \\\n+\t\t\t\t\t\t\t\t\t \\\n+  VECT_ARRAY_VAR(vector_src, T1, W, N, X) =\t\t\t\t \\\n+    vld##X##Q##_##T2##W(VECT_VAR(buffer_src, T1, W, N));\t\t \\\n+\t\t\t\t\t\t\t\t\t \\\n+  VECT_ARRAY_VAR(vector, T1, W, N, X) =\t\t\t\t\t \\\n+    /* Use dedicated init buffer, of size X.  */\t\t\t \\\n+    vld##X##Q##_lane_##T2##W(VECT_VAR(buffer_vld##X##_lane, T1, W, X),\t \\\n+\t\t\t     VECT_ARRAY_VAR(vector_src, T1, W, N, X),\t \\\n+\t\t\t     L);\t\t\t\t\t \\\n+  vst##X##Q##_lane_##T2##W(VECT_VAR(result_bis_##X, T1, W, N),\t\t \\\n+\t\t\t   VECT_ARRAY_VAR(vector, T1, W, N, X),\t\t \\\n+\t\t\t   L);\t\t\t\t\t\t \\\n+  memcpy(VECT_VAR(result, T1, W, N), VECT_VAR(result_bis_##X, T1, W, N), \\\n+\t sizeof(VECT_VAR(result, T1, W, N)));\n+\n+#define TEST_ALL_VSTX_LANE(X)\t\t  \\\n+  TEST_VSTX_LANE(, poly, p, 64, 1, X, 0); \\\n+  TEST_VSTX_LANE(q, poly, p, 64, 2, X, 0);\n+\n+  /* Check vst2_lane/vst2q_lane.  */\n+  clean_results ();\n+#undef TEST_MSG\n+#define TEST_MSG \"VST2_LANE/VST2Q_LANE\"\n+  TEST_ALL_VSTX_LANE(2);\n+\n+#define CMT \" (chunk 0)\"\n+  CHECK(TEST_MSG, poly, 64, 1, PRIx64, expected_vld_st2_0, CMT);\n+\n+  TEST_ALL_EXTRA_CHUNKS(2, 1);\n+#undef CMT\n+#define CMT \" chunk 1\"\n+  CHECK(TEST_MSG, poly, 64, 1, PRIx64, expected_vld_st2_1, CMT);\n+\n+  /* Check vst3_lane/vst3q_lane.  */\n+  clean_results ();\n+#undef TEST_MSG\n+#define TEST_MSG \"VST3_LANE/VST3Q_LANE\"\n+  TEST_ALL_VSTX_LANE(3);\n+\n+#undef CMT\n+#define CMT \" (chunk 0)\"\n+  CHECK(TEST_MSG, poly, 64, 1, PRIx64, expected_vld_st3_0, CMT);\n+\n+  TEST_ALL_EXTRA_CHUNKS(3, 1);\n+\n+#undef CMT\n+#define CMT \" (chunk 1)\"\n+  CHECK(TEST_MSG, poly, 64, 1, PRIx64, expected_vld_st3_1, CMT);\n+\n+  TEST_ALL_EXTRA_CHUNKS(3, 2);\n+\n+#undef CMT\n+#define CMT \" (chunk 2)\"\n+  CHECK(TEST_MSG, poly, 64, 1, PRIx64, expected_vld_st3_2, CMT);\n+\n+  /* Check vst4_lane/vst4q_lane.  */\n+  clean_results ();\n+#undef TEST_MSG\n+#define TEST_MSG \"VST4_LANE/VST4Q_LANE\"\n+  TEST_ALL_VSTX_LANE(4);\n+\n+#undef CMT\n+#define CMT \" (chunk 0)\"\n+  CHECK(TEST_MSG, poly, 64, 1, PRIx64, expected_vld_st4_0, CMT);\n+\n+  TEST_ALL_EXTRA_CHUNKS(4, 1);\n+\n+#undef CMT\n+#define CMT \" (chunk 1)\"\n+  CHECK(TEST_MSG, poly, 64, 1, PRIx64, expected_vld_st4_1, CMT);\n+\n+  TEST_ALL_EXTRA_CHUNKS(4, 2);\n+\n+#undef CMT\n+#define CMT \" (chunk 2)\"\n+  CHECK(TEST_MSG, poly, 64, 1, PRIx64, expected_vld_st4_2, CMT);\n+\n+  TEST_ALL_EXTRA_CHUNKS(4, 3);\n+\n+#undef CMT\n+#define CMT \" (chunk 3)\"\n+  CHECK(TEST_MSG, poly, 64, 1, PRIx64, expected_vld_st4_3, CMT);\n+\n+#endif /* __aarch64__.  */\n+\n   return 0;\n }"}, {"sha": "f192d4dda514287c8417e7fc922bc580b209b163", "filename": "gcc/testsuite/gcc.target/aarch64/advsimd-intrinsics/vreinterpret_p128.c", "status": "modified", "additions": 2, "deletions": 3, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/753a9523414fee2502d81dfec067e2ad24bfe272/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fadvsimd-intrinsics%2Fvreinterpret_p128.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/753a9523414fee2502d81dfec067e2ad24bfe272/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fadvsimd-intrinsics%2Fvreinterpret_p128.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fadvsimd-intrinsics%2Fvreinterpret_p128.c?ref=753a9523414fee2502d81dfec067e2ad24bfe272", "patch": "@@ -1,7 +1,8 @@\n /* This file contains tests for the vreinterpret *p128 intrinsics.  */\n \n-/* { dg-require-effective-target arm_crypto_ok } */\n+/* { dg-require-effective-target arm_crypto_ok { target { arm*-*-* } } } */\n /* { dg-add-options arm_crypto } */\n+/* { dg-additional-options \"-march=armv8-a+crypto\" { target { aarch64*-*-* } } }*/\n \n #include <arm_neon.h>\n #include \"arm-neon-ref.h\"\n@@ -78,9 +79,7 @@ VECT_VAR_DECL(vreint_expected_q_f16_p128,hfloat,16,8) [] = { 0xfff0, 0xffff,\n int main (void)\n {\n   DECL_VARIABLE_128BITS_VARIANTS(vreint_vector);\n-  DECL_VARIABLE(vreint_vector, poly, 64, 2);\n   DECL_VARIABLE_128BITS_VARIANTS(vreint_vector_res);\n-  DECL_VARIABLE(vreint_vector_res, poly, 64, 2);\n \n   clean_results ();\n "}, {"sha": "c915fd2fea6b4d8770c9a4aab88caad391105d89", "filename": "gcc/testsuite/gcc.target/aarch64/advsimd-intrinsics/vreinterpret_p64.c", "status": "modified", "additions": 2, "deletions": 5, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/753a9523414fee2502d81dfec067e2ad24bfe272/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fadvsimd-intrinsics%2Fvreinterpret_p64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/753a9523414fee2502d81dfec067e2ad24bfe272/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fadvsimd-intrinsics%2Fvreinterpret_p64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fadvsimd-intrinsics%2Fvreinterpret_p64.c?ref=753a9523414fee2502d81dfec067e2ad24bfe272", "patch": "@@ -1,7 +1,8 @@\n /* This file contains tests for the vreinterpret *p64 intrinsics.  */\n \n-/* { dg-require-effective-target arm_crypto_ok } */\n+/* { dg-require-effective-target arm_crypto_ok { target { arm*-*-* } } } */\n /* { dg-add-options arm_crypto } */\n+/* { dg-additional-options \"-march=armv8-a+crypto\" { target { aarch64*-*-* } } }*/\n \n #include <arm_neon.h>\n #include \"arm-neon-ref.h\"\n@@ -121,11 +122,7 @@ int main (void)\n   CHECK_FP(TEST_MSG, T1, W, N, PRIx##W, EXPECTED, \"\");\n \n   DECL_VARIABLE_ALL_VARIANTS(vreint_vector);\n-  DECL_VARIABLE(vreint_vector, poly, 64, 1);\n-  DECL_VARIABLE(vreint_vector, poly, 64, 2);\n   DECL_VARIABLE_ALL_VARIANTS(vreint_vector_res);\n-  DECL_VARIABLE(vreint_vector_res, poly, 64, 1);\n-  DECL_VARIABLE(vreint_vector_res, poly, 64, 2);\n \n   clean_results ();\n "}]}