{"sha": "de10bcced9188d068a5448917141171e393b9cc9", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZGUxMGJjY2VkOTE4OGQwNjhhNTQ0ODkxNzE0MTE3MWUzOTNiOWNjOQ==", "commit": {"author": {"name": "Alan Lawrence", "email": "alan.lawrence@arm.com", "date": "2014-06-03T14:57:22Z"}, "committer": {"name": "Alan Lawrence", "email": "alalaw01@gcc.gnu.org", "date": "2014-06-03T14:57:22Z"}, "message": "[PATCH AArch64 1/2] Correct signedness of builtins, remove casts from arm_neon.h\n\n\t* gcc/config/aarch64/aarch64-builtins.c\n\t(aarch64_types_binop_uus_qualifiers,\n\taarch64_types_shift_to_unsigned_qualifiers,\n\taarch64_types_unsigned_shiftacc_qualifiers): Define.\n\t* gcc/config/aarch64/aarch64-simd-builtins.def (uqshl, uqrshl, uqadd,\n\tuqsub, usqadd, usra_n, ursra_n, uqshrn_n, uqrshrn_n, usri_n, usli_n,\n\tsqshlu_n, uqshl_n): Update qualifiers.\n\t* gcc/config/aarch64/arm_neon.h (vqadd_u8, vqadd_u16, vqadd_u32,\n\tvqadd_u64, vqaddq_u8, vqaddq_u16, vqaddq_u32, vqaddq_u64, vqsub_u8,\n\tvqsub_u16, vqsub_u32, vqsub_u64, vqsubq_u8, vqsubq_u16, vqsubq_u32,\n\tvqsubq_u64, vqaddb_u8, vqaddh_u16, vqadds_u32, vqaddd_u64, vqrshl_u8,\n\tvqrshl_u16, vqrshl_u32, vqrshl_u64, vqrshlq_u8, vqrshlq_u16,\n\tvqrshlq_u32, vqrshlq_u64, vqrshlb_u8, vqrshlh_u16, vqrshls_u32,\n\tvqrshld_u64, vqrshrn_n_u16, vqrshrn_n_u32, vqrshrn_n_u64,\n\tvqrshrnh_n_u16, vqrshrns_n_u32, vqrshrnd_n_u64, vqshl_u8, vqshl_u16,\n\tvqshl_u32, vqshl_u64, vqshlq_u8, vqshlq_u16, vqshlq_u32, vqshlq_u64,\n\tvqshlb_u8, vqshlh_u16, vqshls_u32, vqshld_u64, vqshl_n_u8, vqshl_n_u16,\n\tvqshl_n_u32, vqshl_n_u64, vqshlq_n_u8, vqshlq_n_u16, vqshlq_n_u32,\n\tvqshlq_n_u64, vqshlb_n_u8, vqshlh_n_u16, vqshls_n_u32, vqshld_n_u64,\n\tvqshlu_n_s8, vqshlu_n_s16, vqshlu_n_s32, vqshlu_n_s64, vqshluq_n_s8,\n\tvqshluq_n_s16, vqshluq_n_s32, vqshluq_n_s64, vqshlub_n_s8,\n\tvqshluh_n_s16, vqshlus_n_s32, vqshlud_n_s64, vqshrn_n_u16,\n\tvqshrn_n_u32, vqshrn_n_u64, vqshrnh_n_u16, vqshrns_n_u32,\n\tvqshrnd_n_u64, vqsubb_u8, vqsubh_u16, vqsubs_u32, vqsubd_u64,\n\tvrsra_n_u8, vrsra_n_u16, vrsra_n_u32, vrsra_n_u64, vrsraq_n_u8,\n\tvrsraq_n_u16, vrsraq_n_u32, vrsraq_n_u64, vrsrad_n_u64, vsli_n_u8,\n\tvsli_n_u16, vsli_n_u32,vsli_n_u64, vsliq_n_u8, vsliq_n_u16,\n\tvsliq_n_u32, vsliq_n_u64, vslid_n_u64, vsqadd_u8, vsqadd_u16,\n\tvsqadd_u32, vsqadd_u64, vsqaddq_u8, vsqaddq_u16, vsqaddq_u32,\n\tvsqaddq_u64, vsqaddb_u8, vsqaddh_u16, vsqadds_u32, vsqaddd_u64,\n\tvsra_n_u8, vsra_n_u16, vsra_n_u32, vsra_n_u64, vsraq_n_u8,\n\tvsraq_n_u16, vsraq_n_u32, vsraq_n_u64, vsrad_n_u64, vsri_n_u8,\n\tvsri_n_u16, vsri_n_u32, vsri_n_u64, vsriq_n_u8, vsriq_n_u16,\n\tvsriq_n_u32, vsriq_n_u64, vsrid_n_u64): Remove casts.\n\nFrom-SVN: r211185", "tree": {"sha": "432c121dbae874c917b10367104928453d5d4ed1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/432c121dbae874c917b10367104928453d5d4ed1"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/de10bcced9188d068a5448917141171e393b9cc9", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/de10bcced9188d068a5448917141171e393b9cc9", "html_url": "https://github.com/Rust-GCC/gccrs/commit/de10bcced9188d068a5448917141171e393b9cc9", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/de10bcced9188d068a5448917141171e393b9cc9/comments", "author": null, "committer": null, "parents": [{"sha": "878d361864946a4295aa94bbc2f84ed4a6e37814", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/878d361864946a4295aa94bbc2f84ed4a6e37814", "html_url": "https://github.com/Rust-GCC/gccrs/commit/878d361864946a4295aa94bbc2f84ed4a6e37814"}], "stats": {"total": 402, "additions": 202, "deletions": 200}, "files": [{"sha": "c196684ade03f6b708b2345cadf5f973ce857032", "filename": "gcc/ChangeLog", "status": "modified", "additions": 37, "deletions": 0, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/de10bcced9188d068a5448917141171e393b9cc9/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/de10bcced9188d068a5448917141171e393b9cc9/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=de10bcced9188d068a5448917141171e393b9cc9", "patch": "@@ -1,3 +1,40 @@\n+2014-06-03  Alan Lawrence  <alan.lawrence@arm.com>\n+\n+\t* gcc/config/aarch64/aarch64-builtins.c\n+\t(aarch64_types_binop_uus_qualifiers,\n+\taarch64_types_shift_to_unsigned_qualifiers,\n+\taarch64_types_unsigned_shiftacc_qualifiers): Define.\n+\t* gcc/config/aarch64/aarch64-simd-builtins.def (uqshl, uqrshl, uqadd,\n+\tuqsub, usqadd, usra_n, ursra_n, uqshrn_n, uqrshrn_n, usri_n, usli_n,\n+\tsqshlu_n, uqshl_n): Update qualifiers.\n+\t* gcc/config/aarch64/arm_neon.h (vqadd_u8, vqadd_u16, vqadd_u32,\n+\tvqadd_u64, vqaddq_u8, vqaddq_u16, vqaddq_u32, vqaddq_u64, vqsub_u8,\n+\tvqsub_u16, vqsub_u32, vqsub_u64, vqsubq_u8, vqsubq_u16, vqsubq_u32,\n+\tvqsubq_u64, vqaddb_u8, vqaddh_u16, vqadds_u32, vqaddd_u64, vqrshl_u8,\n+\tvqrshl_u16, vqrshl_u32, vqrshl_u64, vqrshlq_u8, vqrshlq_u16,\n+\tvqrshlq_u32, vqrshlq_u64, vqrshlb_u8, vqrshlh_u16, vqrshls_u32,\n+\tvqrshld_u64, vqrshrn_n_u16, vqrshrn_n_u32, vqrshrn_n_u64,\n+\tvqrshrnh_n_u16, vqrshrns_n_u32, vqrshrnd_n_u64, vqshl_u8, vqshl_u16,\n+\tvqshl_u32, vqshl_u64, vqshlq_u8, vqshlq_u16, vqshlq_u32, vqshlq_u64,\n+\tvqshlb_u8, vqshlh_u16, vqshls_u32, vqshld_u64, vqshl_n_u8, vqshl_n_u16,\n+\tvqshl_n_u32, vqshl_n_u64, vqshlq_n_u8, vqshlq_n_u16, vqshlq_n_u32,\n+\tvqshlq_n_u64, vqshlb_n_u8, vqshlh_n_u16, vqshls_n_u32, vqshld_n_u64,\n+\tvqshlu_n_s8, vqshlu_n_s16, vqshlu_n_s32, vqshlu_n_s64, vqshluq_n_s8,\n+\tvqshluq_n_s16, vqshluq_n_s32, vqshluq_n_s64, vqshlub_n_s8,\n+\tvqshluh_n_s16, vqshlus_n_s32, vqshlud_n_s64, vqshrn_n_u16,\n+\tvqshrn_n_u32, vqshrn_n_u64, vqshrnh_n_u16, vqshrns_n_u32,\n+\tvqshrnd_n_u64, vqsubb_u8, vqsubh_u16, vqsubs_u32, vqsubd_u64,\n+\tvrsra_n_u8, vrsra_n_u16, vrsra_n_u32, vrsra_n_u64, vrsraq_n_u8,\n+\tvrsraq_n_u16, vrsraq_n_u32, vrsraq_n_u64, vrsrad_n_u64, vsli_n_u8,\n+\tvsli_n_u16, vsli_n_u32,vsli_n_u64, vsliq_n_u8, vsliq_n_u16,\n+\tvsliq_n_u32, vsliq_n_u64, vslid_n_u64, vsqadd_u8, vsqadd_u16,\n+\tvsqadd_u32, vsqadd_u64, vsqaddq_u8, vsqaddq_u16, vsqaddq_u32,\n+\tvsqaddq_u64, vsqaddb_u8, vsqaddh_u16, vsqadds_u32, vsqaddd_u64,\n+\tvsra_n_u8, vsra_n_u16, vsra_n_u32, vsra_n_u64, vsraq_n_u8,\n+\tvsraq_n_u16, vsraq_n_u32, vsraq_n_u64, vsrad_n_u64, vsri_n_u8,\n+\tvsri_n_u16, vsri_n_u32, vsri_n_u64, vsriq_n_u8, vsriq_n_u16,\n+\tvsriq_n_u32, vsriq_n_u64, vsrid_n_u64): Remove casts.\n+\n 2014-06-03  Teresa Johnson  <tejohnson@google.com>\n \n \t* tree-sra.c (modify_function): Record caller nodes after rebuild."}, {"sha": "eee3f2fd45ad4063eaebb0a9e265835bea2ae7cf", "filename": "gcc/config/aarch64/aarch64-builtins.c", "status": "modified", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/de10bcced9188d068a5448917141171e393b9cc9/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/de10bcced9188d068a5448917141171e393b9cc9/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c?ref=de10bcced9188d068a5448917141171e393b9cc9", "patch": "@@ -177,6 +177,10 @@ aarch64_types_binopu_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n   = { qualifier_unsigned, qualifier_unsigned, qualifier_unsigned };\n #define TYPES_BINOPU (aarch64_types_binopu_qualifiers)\n static enum aarch64_type_qualifiers\n+aarch64_types_binop_uus_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n+  = { qualifier_unsigned, qualifier_unsigned, qualifier_none };\n+#define TYPES_BINOP_UUS (aarch64_types_binop_uus_qualifiers)\n+static enum aarch64_type_qualifiers\n aarch64_types_binopp_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n   = { qualifier_poly, qualifier_poly, qualifier_poly };\n #define TYPES_BINOPP (aarch64_types_binopp_qualifiers)\n@@ -203,16 +207,28 @@ aarch64_types_getlane_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n #define TYPES_GETLANE (aarch64_types_getlane_qualifiers)\n #define TYPES_SHIFTIMM (aarch64_types_getlane_qualifiers)\n static enum aarch64_type_qualifiers\n+aarch64_types_shift_to_unsigned_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n+  = { qualifier_unsigned, qualifier_none, qualifier_immediate };\n+#define TYPES_SHIFTIMM_USS (aarch64_types_shift_to_unsigned_qualifiers)\n+static enum aarch64_type_qualifiers\n aarch64_types_unsigned_shift_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n   = { qualifier_unsigned, qualifier_unsigned, qualifier_immediate };\n #define TYPES_USHIFTIMM (aarch64_types_unsigned_shift_qualifiers)\n+\n static enum aarch64_type_qualifiers\n aarch64_types_setlane_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n   = { qualifier_none, qualifier_none, qualifier_none, qualifier_immediate };\n #define TYPES_SETLANE (aarch64_types_setlane_qualifiers)\n #define TYPES_SHIFTINSERT (aarch64_types_setlane_qualifiers)\n #define TYPES_SHIFTACC (aarch64_types_setlane_qualifiers)\n \n+static enum aarch64_type_qualifiers\n+aarch64_types_unsigned_shiftacc_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n+  = { qualifier_unsigned, qualifier_unsigned, qualifier_unsigned,\n+      qualifier_immediate };\n+#define TYPES_USHIFTACC (aarch64_types_unsigned_shiftacc_qualifiers)\n+\n+\n static enum aarch64_type_qualifiers\n aarch64_types_combine_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n   = { qualifier_none, qualifier_none, qualifier_none };"}, {"sha": "b357be4d890276a5d3b2eda2aca34c9c70c1bc02", "filename": "gcc/config/aarch64/aarch64-simd-builtins.def", "status": "modified", "additions": 13, "deletions": 13, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/de10bcced9188d068a5448917141171e393b9cc9/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/de10bcced9188d068a5448917141171e393b9cc9/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def?ref=de10bcced9188d068a5448917141171e393b9cc9", "patch": "@@ -77,17 +77,17 @@\n   BUILTIN_VDQ_I (BINOP, dup_lane, 0)\n   /* Implemented by aarch64_<sur>q<r>shl<mode>.  */\n   BUILTIN_VSDQ_I (BINOP, sqshl, 0)\n-  BUILTIN_VSDQ_I (BINOP, uqshl, 0)\n+  BUILTIN_VSDQ_I (BINOP_UUS, uqshl, 0)\n   BUILTIN_VSDQ_I (BINOP, sqrshl, 0)\n-  BUILTIN_VSDQ_I (BINOP, uqrshl, 0)\n+  BUILTIN_VSDQ_I (BINOP_UUS, uqrshl, 0)\n   /* Implemented by aarch64_<su_optab><optab><mode>.  */\n   BUILTIN_VSDQ_I (BINOP, sqadd, 0)\n-  BUILTIN_VSDQ_I (BINOP, uqadd, 0)\n+  BUILTIN_VSDQ_I (BINOPU, uqadd, 0)\n   BUILTIN_VSDQ_I (BINOP, sqsub, 0)\n-  BUILTIN_VSDQ_I (BINOP, uqsub, 0)\n+  BUILTIN_VSDQ_I (BINOPU, uqsub, 0)\n   /* Implemented by aarch64_<sur>qadd<mode>.  */\n   BUILTIN_VSDQ_I (BINOP, suqadd, 0)\n-  BUILTIN_VSDQ_I (BINOP, usqadd, 0)\n+  BUILTIN_VSDQ_I (BINOP_UUS, usqadd, 0)\n \n   /* Implemented by aarch64_get_dreg<VSTRUCT:mode><VDC:mode>.  */\n   BUILTIN_VDC (GETLANE, get_dregoi, 0)\n@@ -214,9 +214,9 @@\n   BUILTIN_VSDQ_I_DI (SHIFTIMM, urshr_n, 0)\n   /* Implemented by aarch64_<sur>sra_n<mode>.  */\n   BUILTIN_VSDQ_I_DI (SHIFTACC, ssra_n, 0)\n-  BUILTIN_VSDQ_I_DI (SHIFTACC, usra_n, 0)\n+  BUILTIN_VSDQ_I_DI (USHIFTACC, usra_n, 0)\n   BUILTIN_VSDQ_I_DI (SHIFTACC, srsra_n, 0)\n-  BUILTIN_VSDQ_I_DI (SHIFTACC, ursra_n, 0)\n+  BUILTIN_VSDQ_I_DI (USHIFTACC, ursra_n, 0)\n   /* Implemented by aarch64_<sur>shll_n<mode>.  */\n   BUILTIN_VDW (SHIFTIMM, sshll_n, 0)\n   BUILTIN_VDW (SHIFTIMM, ushll_n, 0)\n@@ -227,18 +227,18 @@\n   BUILTIN_VSQN_HSDI (SHIFTIMM, sqshrun_n, 0)\n   BUILTIN_VSQN_HSDI (SHIFTIMM, sqrshrun_n, 0)\n   BUILTIN_VSQN_HSDI (SHIFTIMM, sqshrn_n, 0)\n-  BUILTIN_VSQN_HSDI (SHIFTIMM, uqshrn_n, 0)\n+  BUILTIN_VSQN_HSDI (USHIFTIMM, uqshrn_n, 0)\n   BUILTIN_VSQN_HSDI (SHIFTIMM, sqrshrn_n, 0)\n-  BUILTIN_VSQN_HSDI (SHIFTIMM, uqrshrn_n, 0)\n+  BUILTIN_VSQN_HSDI (USHIFTIMM, uqrshrn_n, 0)\n   /* Implemented by aarch64_<sur>s<lr>i_n<mode>.  */\n   BUILTIN_VSDQ_I_DI (SHIFTINSERT, ssri_n, 0)\n-  BUILTIN_VSDQ_I_DI (SHIFTINSERT, usri_n, 0)\n+  BUILTIN_VSDQ_I_DI (USHIFTACC, usri_n, 0)\n   BUILTIN_VSDQ_I_DI (SHIFTINSERT, ssli_n, 0)\n-  BUILTIN_VSDQ_I_DI (SHIFTINSERT, usli_n, 0)\n+  BUILTIN_VSDQ_I_DI (USHIFTACC, usli_n, 0)\n   /* Implemented by aarch64_<sur>qshl<u>_n<mode>.  */\n-  BUILTIN_VSDQ_I (SHIFTIMM, sqshlu_n, 0)\n+  BUILTIN_VSDQ_I (SHIFTIMM_USS, sqshlu_n, 0)\n   BUILTIN_VSDQ_I (SHIFTIMM, sqshl_n, 0)\n-  BUILTIN_VSDQ_I (SHIFTIMM, uqshl_n, 0)\n+  BUILTIN_VSDQ_I (USHIFTIMM, uqshl_n, 0)\n \n   /* Implemented by aarch64_cm<cmp><mode>.  */\n   BUILTIN_VALLDI (BINOP, cmeq, 0)"}, {"sha": "18de229eab086ee2d267e71a6c93da52de9a15e9", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 136, "deletions": 187, "changes": 323, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/de10bcced9188d068a5448917141171e393b9cc9/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/de10bcced9188d068a5448917141171e393b9cc9/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=de10bcced9188d068a5448917141171e393b9cc9", "patch": "@@ -2119,29 +2119,26 @@ vqadd_s64 (int64x1_t __a, int64x1_t __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vqadd_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_uqaddv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t  (int8x8_t) __b);\n+  return __builtin_aarch64_uqaddv8qi_uuu (__a, __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vqadd_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_uqaddv4hi ((int16x4_t) __a,\n-\t\t\t\t\t\t   (int16x4_t) __b);\n+  return __builtin_aarch64_uqaddv4hi_uuu (__a, __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vqadd_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_uqaddv2si ((int32x2_t) __a,\n-\t\t\t\t\t\t   (int32x2_t) __b);\n+  return __builtin_aarch64_uqaddv2si_uuu (__a, __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vqadd_u64 (uint64x1_t __a, uint64x1_t __b)\n {\n-  return (uint64x1_t) __builtin_aarch64_uqadddi ((int64x1_t) __a,\n-\t\t\t\t\t\t (int64x1_t) __b);\n+  return (uint64x1_t) __builtin_aarch64_uqadddi_uuu ((uint64_t) __a,\n+\t\t\t\t\t\t     (uint64_t) __b);\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n@@ -2171,29 +2168,25 @@ vqaddq_s64 (int64x2_t __a, int64x2_t __b)\n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vqaddq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_uqaddv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t    (int8x16_t) __b);\n+  return __builtin_aarch64_uqaddv16qi_uuu (__a, __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vqaddq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_uqaddv8hi ((int16x8_t) __a,\n-\t\t\t\t\t\t   (int16x8_t) __b);\n+  return __builtin_aarch64_uqaddv8hi_uuu (__a, __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vqaddq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_uqaddv4si ((int32x4_t) __a,\n-\t\t\t\t\t\t   (int32x4_t) __b);\n+  return __builtin_aarch64_uqaddv4si_uuu (__a, __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vqaddq_u64 (uint64x2_t __a, uint64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_uqaddv2di ((int64x2_t) __a,\n-\t\t\t\t\t\t   (int64x2_t) __b);\n+  return __builtin_aarch64_uqaddv2di_uuu (__a, __b);\n }\n \n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n@@ -2223,29 +2216,26 @@ vqsub_s64 (int64x1_t __a, int64x1_t __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vqsub_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_uqsubv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t  (int8x8_t) __b);\n+  return __builtin_aarch64_uqsubv8qi_uuu (__a, __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vqsub_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_uqsubv4hi ((int16x4_t) __a,\n-\t\t\t\t\t\t   (int16x4_t) __b);\n+  return __builtin_aarch64_uqsubv4hi_uuu (__a, __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vqsub_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_uqsubv2si ((int32x2_t) __a,\n-\t\t\t\t\t\t   (int32x2_t) __b);\n+  return __builtin_aarch64_uqsubv2si_uuu (__a, __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vqsub_u64 (uint64x1_t __a, uint64x1_t __b)\n {\n-  return (uint64x1_t) __builtin_aarch64_uqsubdi ((int64x1_t) __a,\n-\t\t\t\t\t\t (int64x1_t) __b);\n+  return (uint64x1_t) __builtin_aarch64_uqsubdi_uuu ((uint64_t) __a,\n+\t\t\t\t\t\t     (uint64_t) __b);\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n@@ -2275,29 +2265,25 @@ vqsubq_s64 (int64x2_t __a, int64x2_t __b)\n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vqsubq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_uqsubv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t    (int8x16_t) __b);\n+  return __builtin_aarch64_uqsubv16qi_uuu (__a, __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vqsubq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_uqsubv8hi ((int16x8_t) __a,\n-\t\t\t\t\t\t   (int16x8_t) __b);\n+  return __builtin_aarch64_uqsubv8hi_uuu (__a, __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vqsubq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_uqsubv4si ((int32x4_t) __a,\n-\t\t\t\t\t\t   (int32x4_t) __b);\n+  return __builtin_aarch64_uqsubv4si_uuu (__a, __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vqsubq_u64 (uint64x2_t __a, uint64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_uqsubv2di ((int64x2_t) __a,\n-\t\t\t\t\t\t   (int64x2_t) __b);\n+  return __builtin_aarch64_uqsubv2di_uuu (__a, __b);\n }\n \n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n@@ -19511,25 +19497,26 @@ vqaddd_s64 (int64x1_t __a, int64x1_t __b)\n __extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))\n vqaddb_u8 (uint8x1_t __a, uint8x1_t __b)\n {\n-  return (uint8x1_t) __builtin_aarch64_uqaddqi (__a, __b);\n+  return (uint8x1_t) __builtin_aarch64_uqaddqi_uuu (__a, __b);\n }\n \n __extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))\n vqaddh_u16 (uint16x1_t __a, uint16x1_t __b)\n {\n-  return (uint16x1_t) __builtin_aarch64_uqaddhi (__a, __b);\n+  return (uint16x1_t) __builtin_aarch64_uqaddhi_uuu (__a, __b);\n }\n \n __extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))\n vqadds_u32 (uint32x1_t __a, uint32x1_t __b)\n {\n-  return (uint32x1_t) __builtin_aarch64_uqaddsi (__a, __b);\n+  return (uint32x1_t) __builtin_aarch64_uqaddsi_uuu (__a, __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vqaddd_u64 (uint64x1_t __a, uint64x1_t __b)\n {\n-  return (uint64x1_t) __builtin_aarch64_uqadddi (__a, __b);\n+  return (uint64x1_t) __builtin_aarch64_uqadddi_uuu ((uint64_t) __a,\n+\t\t\t\t\t\t     (uint64_t) __b);\n }\n \n /* vqdmlal */\n@@ -20185,25 +20172,25 @@ vqrshl_s64 (int64x1_t __a, int64x1_t __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vqrshl_u8 (uint8x8_t __a, int8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_uqrshlv8qi ((int8x8_t) __a, __b);\n+  return __builtin_aarch64_uqrshlv8qi_uus ( __a, __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vqrshl_u16 (uint16x4_t __a, int16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_uqrshlv4hi ((int16x4_t) __a, __b);\n+  return __builtin_aarch64_uqrshlv4hi_uus ( __a, __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vqrshl_u32 (uint32x2_t __a, int32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_uqrshlv2si ((int32x2_t) __a, __b);\n+  return __builtin_aarch64_uqrshlv2si_uus ( __a, __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vqrshl_u64 (uint64x1_t __a, int64x1_t __b)\n {\n-  return (uint64x1_t) __builtin_aarch64_uqrshldi ((int64x1_t) __a, __b);\n+  return __builtin_aarch64_uqrshldi_uus ( __a, __b);\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n@@ -20233,25 +20220,25 @@ vqrshlq_s64 (int64x2_t __a, int64x2_t __b)\n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vqrshlq_u8 (uint8x16_t __a, int8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_uqrshlv16qi ((int8x16_t) __a, __b);\n+  return __builtin_aarch64_uqrshlv16qi_uus ( __a, __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vqrshlq_u16 (uint16x8_t __a, int16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_uqrshlv8hi ((int16x8_t) __a, __b);\n+  return __builtin_aarch64_uqrshlv8hi_uus ( __a, __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vqrshlq_u32 (uint32x4_t __a, int32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_uqrshlv4si ((int32x4_t) __a, __b);\n+  return __builtin_aarch64_uqrshlv4si_uus ( __a, __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vqrshlq_u64 (uint64x2_t __a, int64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_uqrshlv2di ((int64x2_t) __a, __b);\n+  return __builtin_aarch64_uqrshlv2di_uus ( __a, __b);\n }\n \n __extension__ static __inline int8x1_t __attribute__ ((__always_inline__))\n@@ -20281,25 +20268,25 @@ vqrshld_s64 (int64x1_t __a, int64x1_t __b)\n __extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))\n vqrshlb_u8 (uint8x1_t __a, uint8x1_t __b)\n {\n-  return (uint8x1_t) __builtin_aarch64_uqrshlqi (__a, __b);\n+  return __builtin_aarch64_uqrshlqi_uus (__a, __b);\n }\n \n __extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))\n vqrshlh_u16 (uint16x1_t __a, uint16x1_t __b)\n {\n-  return (uint16x1_t) __builtin_aarch64_uqrshlhi (__a, __b);\n+  return __builtin_aarch64_uqrshlhi_uus (__a, __b);\n }\n \n __extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))\n vqrshls_u32 (uint32x1_t __a, uint32x1_t __b)\n {\n-  return (uint32x1_t) __builtin_aarch64_uqrshlsi (__a, __b);\n+  return __builtin_aarch64_uqrshlsi_uus (__a, __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vqrshld_u64 (uint64x1_t __a, uint64x1_t __b)\n {\n-  return (uint64x1_t) __builtin_aarch64_uqrshldi (__a, __b);\n+  return __builtin_aarch64_uqrshldi_uus (__a, __b);\n }\n \n /* vqrshrn */\n@@ -20325,19 +20312,19 @@ vqrshrn_n_s64 (int64x2_t __a, const int __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vqrshrn_n_u16 (uint16x8_t __a, const int __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_uqrshrn_nv8hi ((int16x8_t) __a, __b);\n+  return __builtin_aarch64_uqrshrn_nv8hi_uus ( __a, __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vqrshrn_n_u32 (uint32x4_t __a, const int __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_uqrshrn_nv4si ((int32x4_t) __a, __b);\n+  return __builtin_aarch64_uqrshrn_nv4si_uus ( __a, __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vqrshrn_n_u64 (uint64x2_t __a, const int __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_uqrshrn_nv2di ((int64x2_t) __a, __b);\n+  return __builtin_aarch64_uqrshrn_nv2di_uus ( __a, __b);\n }\n \n __extension__ static __inline int8x1_t __attribute__ ((__always_inline__))\n@@ -20361,19 +20348,19 @@ vqrshrnd_n_s64 (int64x1_t __a, const int __b)\n __extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))\n vqrshrnh_n_u16 (uint16x1_t __a, const int __b)\n {\n-  return (uint8x1_t) __builtin_aarch64_uqrshrn_nhi (__a, __b);\n+  return __builtin_aarch64_uqrshrn_nhi_uus (__a, __b);\n }\n \n __extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))\n vqrshrns_n_u32 (uint32x1_t __a, const int __b)\n {\n-  return (uint16x1_t) __builtin_aarch64_uqrshrn_nsi (__a, __b);\n+  return __builtin_aarch64_uqrshrn_nsi_uus (__a, __b);\n }\n \n __extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))\n vqrshrnd_n_u64 (uint64x1_t __a, const int __b)\n {\n-  return (uint32x1_t) __builtin_aarch64_uqrshrn_ndi (__a, __b);\n+  return __builtin_aarch64_uqrshrn_ndi_uus (__a, __b);\n }\n \n /* vqrshrun */\n@@ -20443,25 +20430,25 @@ vqshl_s64 (int64x1_t __a, int64x1_t __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vqshl_u8 (uint8x8_t __a, int8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_uqshlv8qi ((int8x8_t) __a, __b);\n+  return __builtin_aarch64_uqshlv8qi_uus ( __a, __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vqshl_u16 (uint16x4_t __a, int16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_uqshlv4hi ((int16x4_t) __a, __b);\n+  return __builtin_aarch64_uqshlv4hi_uus ( __a, __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vqshl_u32 (uint32x2_t __a, int32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_uqshlv2si ((int32x2_t) __a, __b);\n+  return __builtin_aarch64_uqshlv2si_uus ( __a, __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vqshl_u64 (uint64x1_t __a, int64x1_t __b)\n {\n-  return (uint64x1_t) __builtin_aarch64_uqshldi ((int64x1_t) __a, __b);\n+  return __builtin_aarch64_uqshldi_uus ( __a, __b);\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n@@ -20491,25 +20478,25 @@ vqshlq_s64 (int64x2_t __a, int64x2_t __b)\n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vqshlq_u8 (uint8x16_t __a, int8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_uqshlv16qi ((int8x16_t) __a, __b);\n+  return __builtin_aarch64_uqshlv16qi_uus ( __a, __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vqshlq_u16 (uint16x8_t __a, int16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_uqshlv8hi ((int16x8_t) __a, __b);\n+  return __builtin_aarch64_uqshlv8hi_uus ( __a, __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vqshlq_u32 (uint32x4_t __a, int32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_uqshlv4si ((int32x4_t) __a, __b);\n+  return __builtin_aarch64_uqshlv4si_uus ( __a, __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vqshlq_u64 (uint64x2_t __a, int64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_uqshlv2di ((int64x2_t) __a, __b);\n+  return __builtin_aarch64_uqshlv2di_uus ( __a, __b);\n }\n \n __extension__ static __inline int8x1_t __attribute__ ((__always_inline__))\n@@ -20539,25 +20526,25 @@ vqshld_s64 (int64x1_t __a, int64x1_t __b)\n __extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))\n vqshlb_u8 (uint8x1_t __a, uint8x1_t __b)\n {\n-  return (uint8x1_t) __builtin_aarch64_uqshlqi (__a, __b);\n+  return __builtin_aarch64_uqshlqi_uus (__a, __b);\n }\n \n __extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))\n vqshlh_u16 (uint16x1_t __a, uint16x1_t __b)\n {\n-  return (uint16x1_t) __builtin_aarch64_uqshlhi (__a, __b);\n+  return __builtin_aarch64_uqshlhi_uus (__a, __b);\n }\n \n __extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))\n vqshls_u32 (uint32x1_t __a, uint32x1_t __b)\n {\n-  return (uint32x1_t) __builtin_aarch64_uqshlsi (__a, __b);\n+  return __builtin_aarch64_uqshlsi_uus (__a, __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vqshld_u64 (uint64x1_t __a, uint64x1_t __b)\n {\n-  return (uint64x1_t) __builtin_aarch64_uqshldi (__a, __b);\n+  return __builtin_aarch64_uqshldi_uus (__a, __b);\n }\n \n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n@@ -20587,25 +20574,25 @@ vqshl_n_s64 (int64x1_t __a, const int __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vqshl_n_u8 (uint8x8_t __a, const int __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_uqshl_nv8qi ((int8x8_t) __a, __b);\n+  return __builtin_aarch64_uqshl_nv8qi_uus (__a, __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vqshl_n_u16 (uint16x4_t __a, const int __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_uqshl_nv4hi ((int16x4_t) __a, __b);\n+  return __builtin_aarch64_uqshl_nv4hi_uus (__a, __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vqshl_n_u32 (uint32x2_t __a, const int __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_uqshl_nv2si ((int32x2_t) __a, __b);\n+  return __builtin_aarch64_uqshl_nv2si_uus (__a, __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vqshl_n_u64 (uint64x1_t __a, const int __b)\n {\n-  return (uint64x1_t) __builtin_aarch64_uqshl_ndi ((int64x1_t) __a, __b);\n+  return __builtin_aarch64_uqshl_ndi_uus (__a, __b);\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n@@ -20635,25 +20622,25 @@ vqshlq_n_s64 (int64x2_t __a, const int __b)\n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vqshlq_n_u8 (uint8x16_t __a, const int __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_uqshl_nv16qi ((int8x16_t) __a, __b);\n+  return __builtin_aarch64_uqshl_nv16qi_uus (__a, __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vqshlq_n_u16 (uint16x8_t __a, const int __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_uqshl_nv8hi ((int16x8_t) __a, __b);\n+  return __builtin_aarch64_uqshl_nv8hi_uus (__a, __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vqshlq_n_u32 (uint32x4_t __a, const int __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_uqshl_nv4si ((int32x4_t) __a, __b);\n+  return __builtin_aarch64_uqshl_nv4si_uus (__a, __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vqshlq_n_u64 (uint64x2_t __a, const int __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_uqshl_nv2di ((int64x2_t) __a, __b);\n+  return __builtin_aarch64_uqshl_nv2di_uus (__a, __b);\n }\n \n __extension__ static __inline int8x1_t __attribute__ ((__always_inline__))\n@@ -20683,99 +20670,99 @@ vqshld_n_s64 (int64x1_t __a, const int __b)\n __extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))\n vqshlb_n_u8 (uint8x1_t __a, const int __b)\n {\n-  return (uint8x1_t) __builtin_aarch64_uqshl_nqi (__a, __b);\n+  return __builtin_aarch64_uqshl_nqi_uus (__a, __b);\n }\n \n __extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))\n vqshlh_n_u16 (uint16x1_t __a, const int __b)\n {\n-  return (uint16x1_t) __builtin_aarch64_uqshl_nhi (__a, __b);\n+  return __builtin_aarch64_uqshl_nhi_uus (__a, __b);\n }\n \n __extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))\n vqshls_n_u32 (uint32x1_t __a, const int __b)\n {\n-  return (uint32x1_t) __builtin_aarch64_uqshl_nsi (__a, __b);\n+  return __builtin_aarch64_uqshl_nsi_uus (__a, __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vqshld_n_u64 (uint64x1_t __a, const int __b)\n {\n-  return (uint64x1_t) __builtin_aarch64_uqshl_ndi (__a, __b);\n+  return __builtin_aarch64_uqshl_ndi_uus (__a, __b);\n }\n \n /* vqshlu */\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vqshlu_n_s8 (int8x8_t __a, const int __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_sqshlu_nv8qi (__a, __b);\n+  return __builtin_aarch64_sqshlu_nv8qi_uss (__a, __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vqshlu_n_s16 (int16x4_t __a, const int __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_sqshlu_nv4hi (__a, __b);\n+  return __builtin_aarch64_sqshlu_nv4hi_uss (__a, __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vqshlu_n_s32 (int32x2_t __a, const int __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_sqshlu_nv2si (__a, __b);\n+  return __builtin_aarch64_sqshlu_nv2si_uss (__a, __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vqshlu_n_s64 (int64x1_t __a, const int __b)\n {\n-  return (uint64x1_t) __builtin_aarch64_sqshlu_ndi (__a, __b);\n+  return __builtin_aarch64_sqshlu_ndi_uss (__a, __b);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vqshluq_n_s8 (int8x16_t __a, const int __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_sqshlu_nv16qi (__a, __b);\n+  return __builtin_aarch64_sqshlu_nv16qi_uss (__a, __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vqshluq_n_s16 (int16x8_t __a, const int __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_sqshlu_nv8hi (__a, __b);\n+  return __builtin_aarch64_sqshlu_nv8hi_uss (__a, __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vqshluq_n_s32 (int32x4_t __a, const int __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_sqshlu_nv4si (__a, __b);\n+  return __builtin_aarch64_sqshlu_nv4si_uss (__a, __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vqshluq_n_s64 (int64x2_t __a, const int __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_sqshlu_nv2di (__a, __b);\n+  return __builtin_aarch64_sqshlu_nv2di_uss (__a, __b);\n }\n \n __extension__ static __inline int8x1_t __attribute__ ((__always_inline__))\n vqshlub_n_s8 (int8x1_t __a, const int __b)\n {\n-  return (int8x1_t) __builtin_aarch64_sqshlu_nqi (__a, __b);\n+  return (int8x1_t) __builtin_aarch64_sqshlu_nqi_uss (__a, __b);\n }\n \n __extension__ static __inline int16x1_t __attribute__ ((__always_inline__))\n vqshluh_n_s16 (int16x1_t __a, const int __b)\n {\n-  return (int16x1_t) __builtin_aarch64_sqshlu_nhi (__a, __b);\n+  return (int16x1_t) __builtin_aarch64_sqshlu_nhi_uss (__a, __b);\n }\n \n __extension__ static __inline int32x1_t __attribute__ ((__always_inline__))\n vqshlus_n_s32 (int32x1_t __a, const int __b)\n {\n-  return (int32x1_t) __builtin_aarch64_sqshlu_nsi (__a, __b);\n+  return (int32x1_t) __builtin_aarch64_sqshlu_nsi_uss (__a, __b);\n }\n \n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n vqshlud_n_s64 (int64x1_t __a, const int __b)\n {\n-  return (int64x1_t) __builtin_aarch64_sqshlu_ndi (__a, __b);\n+  return (int64x1_t) __builtin_aarch64_sqshlu_ndi_uss (__a, __b);\n }\n \n /* vqshrn */\n@@ -20801,19 +20788,19 @@ vqshrn_n_s64 (int64x2_t __a, const int __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vqshrn_n_u16 (uint16x8_t __a, const int __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_uqshrn_nv8hi ((int16x8_t) __a, __b);\n+  return __builtin_aarch64_uqshrn_nv8hi_uus ( __a, __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vqshrn_n_u32 (uint32x4_t __a, const int __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_uqshrn_nv4si ((int32x4_t) __a, __b);\n+  return __builtin_aarch64_uqshrn_nv4si_uus ( __a, __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vqshrn_n_u64 (uint64x2_t __a, const int __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_uqshrn_nv2di ((int64x2_t) __a, __b);\n+  return __builtin_aarch64_uqshrn_nv2di_uus ( __a, __b);\n }\n \n __extension__ static __inline int8x1_t __attribute__ ((__always_inline__))\n@@ -20837,19 +20824,19 @@ vqshrnd_n_s64 (int64x1_t __a, const int __b)\n __extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))\n vqshrnh_n_u16 (uint16x1_t __a, const int __b)\n {\n-  return (uint8x1_t) __builtin_aarch64_uqshrn_nhi (__a, __b);\n+  return __builtin_aarch64_uqshrn_nhi_uus (__a, __b);\n }\n \n __extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))\n vqshrns_n_u32 (uint32x1_t __a, const int __b)\n {\n-  return (uint16x1_t) __builtin_aarch64_uqshrn_nsi (__a, __b);\n+  return __builtin_aarch64_uqshrn_nsi_uus (__a, __b);\n }\n \n __extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))\n vqshrnd_n_u64 (uint64x1_t __a, const int __b)\n {\n-  return (uint32x1_t) __builtin_aarch64_uqshrn_ndi (__a, __b);\n+  return __builtin_aarch64_uqshrn_ndi_uus (__a, __b);\n }\n \n /* vqshrun */\n@@ -20919,25 +20906,26 @@ vqsubd_s64 (int64x1_t __a, int64x1_t __b)\n __extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))\n vqsubb_u8 (uint8x1_t __a, uint8x1_t __b)\n {\n-  return (uint8x1_t) __builtin_aarch64_uqsubqi (__a, __b);\n+  return (uint8x1_t) __builtin_aarch64_uqsubqi_uuu (__a, __b);\n }\n \n __extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))\n vqsubh_u16 (uint16x1_t __a, uint16x1_t __b)\n {\n-  return (uint16x1_t) __builtin_aarch64_uqsubhi (__a, __b);\n+  return (uint16x1_t) __builtin_aarch64_uqsubhi_uuu (__a, __b);\n }\n \n __extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))\n vqsubs_u32 (uint32x1_t __a, uint32x1_t __b)\n {\n-  return (uint32x1_t) __builtin_aarch64_uqsubsi (__a, __b);\n+  return (uint32x1_t) __builtin_aarch64_uqsubsi_uuu (__a, __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vqsubd_u64 (uint64x1_t __a, uint64x1_t __b)\n {\n-  return (uint64x1_t) __builtin_aarch64_uqsubdi (__a, __b);\n+  return (uint64x1_t) __builtin_aarch64_uqsubdi_uuu ((uint64_t) __a,\n+\t\t\t\t\t\t     (uint64_t) __b);\n }\n \n /* vrecpe  */\n@@ -21677,29 +21665,25 @@ vrsra_n_s64 (int64x1_t __a, int64x1_t __b, const int __c)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vrsra_n_u8 (uint8x8_t __a, uint8x8_t __b, const int __c)\n {\n-  return (uint8x8_t) __builtin_aarch64_ursra_nv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t    (int8x8_t) __b, __c);\n+  return __builtin_aarch64_ursra_nv8qi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vrsra_n_u16 (uint16x4_t __a, uint16x4_t __b, const int __c)\n {\n-  return (uint16x4_t) __builtin_aarch64_ursra_nv4hi ((int16x4_t) __a,\n-\t\t\t\t\t\t     (int16x4_t) __b, __c);\n+  return __builtin_aarch64_ursra_nv4hi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vrsra_n_u32 (uint32x2_t __a, uint32x2_t __b, const int __c)\n {\n-  return (uint32x2_t) __builtin_aarch64_ursra_nv2si ((int32x2_t) __a,\n-\t\t\t\t\t\t     (int32x2_t) __b, __c);\n+  return __builtin_aarch64_ursra_nv2si_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vrsra_n_u64 (uint64x1_t __a, uint64x1_t __b, const int __c)\n {\n-  return (uint64x1_t) __builtin_aarch64_ursra_ndi ((int64x1_t) __a,\n-\t\t\t\t\t\t   (int64x1_t) __b, __c);\n+  return __builtin_aarch64_ursra_ndi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n@@ -21729,29 +21713,25 @@ vrsraq_n_s64 (int64x2_t __a, int64x2_t __b, const int __c)\n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vrsraq_n_u8 (uint8x16_t __a, uint8x16_t __b, const int __c)\n {\n-  return (uint8x16_t) __builtin_aarch64_ursra_nv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t      (int8x16_t) __b, __c);\n+  return __builtin_aarch64_ursra_nv16qi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vrsraq_n_u16 (uint16x8_t __a, uint16x8_t __b, const int __c)\n {\n-  return (uint16x8_t) __builtin_aarch64_ursra_nv8hi ((int16x8_t) __a,\n-\t\t\t\t\t\t     (int16x8_t) __b, __c);\n+  return __builtin_aarch64_ursra_nv8hi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vrsraq_n_u32 (uint32x4_t __a, uint32x4_t __b, const int __c)\n {\n-  return (uint32x4_t) __builtin_aarch64_ursra_nv4si ((int32x4_t) __a,\n-\t\t\t\t\t\t     (int32x4_t) __b, __c);\n+  return __builtin_aarch64_ursra_nv4si_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vrsraq_n_u64 (uint64x2_t __a, uint64x2_t __b, const int __c)\n {\n-  return (uint64x2_t) __builtin_aarch64_ursra_nv2di ((int64x2_t) __a,\n-\t\t\t\t\t\t     (int64x2_t) __b, __c);\n+  return __builtin_aarch64_ursra_nv2di_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n@@ -21763,7 +21743,7 @@ vrsrad_n_s64 (int64x1_t __a, int64x1_t __b, const int __c)\n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vrsrad_n_u64 (uint64x1_t __a, uint64x1_t __b, const int __c)\n {\n-  return (uint64x1_t) __builtin_aarch64_ursra_ndi (__a, __b, __c);\n+  return __builtin_aarch64_ursra_ndi_uuus (__a, __b, __c);\n }\n \n #ifdef __ARM_FEATURE_CRYPTO\n@@ -22272,29 +22252,25 @@ vsli_n_s64 (int64x1_t __a, int64x1_t __b, const int __c)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vsli_n_u8 (uint8x8_t __a, uint8x8_t __b, const int __c)\n {\n-  return (uint8x8_t) __builtin_aarch64_usli_nv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t   (int8x8_t) __b, __c);\n+  return __builtin_aarch64_usli_nv8qi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vsli_n_u16 (uint16x4_t __a, uint16x4_t __b, const int __c)\n {\n-  return (uint16x4_t) __builtin_aarch64_usli_nv4hi ((int16x4_t) __a,\n-\t\t\t\t\t\t    (int16x4_t) __b, __c);\n+  return __builtin_aarch64_usli_nv4hi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vsli_n_u32 (uint32x2_t __a, uint32x2_t __b, const int __c)\n {\n-  return (uint32x2_t) __builtin_aarch64_usli_nv2si ((int32x2_t) __a,\n-\t\t\t\t\t\t    (int32x2_t) __b, __c);\n+  return __builtin_aarch64_usli_nv2si_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vsli_n_u64 (uint64x1_t __a, uint64x1_t __b, const int __c)\n {\n-  return (uint64x1_t) __builtin_aarch64_usli_ndi ((int64x1_t) __a,\n-\t\t\t\t\t\t  (int64x1_t) __b, __c);\n+  return __builtin_aarch64_usli_ndi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n@@ -22324,29 +22300,25 @@ vsliq_n_s64 (int64x2_t __a, int64x2_t __b, const int __c)\n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vsliq_n_u8 (uint8x16_t __a, uint8x16_t __b, const int __c)\n {\n-  return (uint8x16_t) __builtin_aarch64_usli_nv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t     (int8x16_t) __b, __c);\n+  return __builtin_aarch64_usli_nv16qi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vsliq_n_u16 (uint16x8_t __a, uint16x8_t __b, const int __c)\n {\n-  return (uint16x8_t) __builtin_aarch64_usli_nv8hi ((int16x8_t) __a,\n-\t\t\t\t\t\t    (int16x8_t) __b, __c);\n+  return __builtin_aarch64_usli_nv8hi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vsliq_n_u32 (uint32x4_t __a, uint32x4_t __b, const int __c)\n {\n-  return (uint32x4_t) __builtin_aarch64_usli_nv4si ((int32x4_t) __a,\n-\t\t\t\t\t\t    (int32x4_t) __b, __c);\n+  return __builtin_aarch64_usli_nv4si_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vsliq_n_u64 (uint64x2_t __a, uint64x2_t __b, const int __c)\n {\n-  return (uint64x2_t) __builtin_aarch64_usli_nv2di ((int64x2_t) __a,\n-\t\t\t\t\t\t    (int64x2_t) __b, __c);\n+  return __builtin_aarch64_usli_nv2di_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n@@ -22358,88 +22330,81 @@ vslid_n_s64 (int64x1_t __a, int64x1_t __b, const int __c)\n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vslid_n_u64 (uint64x1_t __a, uint64x1_t __b, const int __c)\n {\n-  return (uint64x1_t) __builtin_aarch64_usli_ndi (__a, __b, __c);\n+  return __builtin_aarch64_usli_ndi_uuus (__a, __b, __c);\n }\n \n /* vsqadd */\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vsqadd_u8 (uint8x8_t __a, int8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_usqaddv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t   (int8x8_t) __b);\n+  return __builtin_aarch64_usqaddv8qi_uus (__a, __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vsqadd_u16 (uint16x4_t __a, int16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_usqaddv4hi ((int16x4_t) __a,\n-\t\t\t\t\t\t    (int16x4_t) __b);\n+  return __builtin_aarch64_usqaddv4hi_uus (__a, __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vsqadd_u32 (uint32x2_t __a, int32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_usqaddv2si ((int32x2_t) __a,\n-\t\t\t\t\t\t    (int32x2_t) __b);\n+  return __builtin_aarch64_usqaddv2si_uus (__a, __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vsqadd_u64 (uint64x1_t __a, int64x1_t __b)\n {\n-  return (uint64x1_t) __builtin_aarch64_usqadddi ((int64x1_t) __a, __b);\n+  return __builtin_aarch64_usqadddi_uus (__a, __b);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vsqaddq_u8 (uint8x16_t __a, int8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_usqaddv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t     (int8x16_t) __b);\n+  return __builtin_aarch64_usqaddv16qi_uus (__a, __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vsqaddq_u16 (uint16x8_t __a, int16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_usqaddv8hi ((int16x8_t) __a,\n-\t\t\t\t\t\t    (int16x8_t) __b);\n+  return __builtin_aarch64_usqaddv8hi_uus (__a, __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vsqaddq_u32 (uint32x4_t __a, int32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_usqaddv4si ((int32x4_t) __a,\n-\t\t\t\t\t\t    (int32x4_t) __b);\n+  return __builtin_aarch64_usqaddv4si_uus (__a, __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vsqaddq_u64 (uint64x2_t __a, int64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_usqaddv2di ((int64x2_t) __a,\n-\t\t\t\t\t\t    (int64x2_t) __b);\n+  return __builtin_aarch64_usqaddv2di_uus (__a, __b);\n }\n \n __extension__ static __inline uint8x1_t __attribute__ ((__always_inline__))\n vsqaddb_u8 (uint8x1_t __a, int8x1_t __b)\n {\n-  return (uint8x1_t) __builtin_aarch64_usqaddqi ((int8x1_t) __a, __b);\n+  return __builtin_aarch64_usqaddqi_uus (__a, __b);\n }\n \n __extension__ static __inline uint16x1_t __attribute__ ((__always_inline__))\n vsqaddh_u16 (uint16x1_t __a, int16x1_t __b)\n {\n-  return (uint16x1_t) __builtin_aarch64_usqaddhi ((int16x1_t) __a, __b);\n+  return __builtin_aarch64_usqaddhi_uus (__a, __b);\n }\n \n __extension__ static __inline uint32x1_t __attribute__ ((__always_inline__))\n vsqadds_u32 (uint32x1_t __a, int32x1_t __b)\n {\n-  return (uint32x1_t) __builtin_aarch64_usqaddsi ((int32x1_t) __a, __b);\n+  return __builtin_aarch64_usqaddsi_uus (__a, __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vsqaddd_u64 (uint64x1_t __a, int64x1_t __b)\n {\n-  return (uint64x1_t) __builtin_aarch64_usqadddi ((int64x1_t) __a, __b);\n+  return __builtin_aarch64_usqadddi_uus (__a, __b);\n }\n \n /* vsqrt */\n@@ -22490,29 +22455,25 @@ vsra_n_s64 (int64x1_t __a, int64x1_t __b, const int __c)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vsra_n_u8 (uint8x8_t __a, uint8x8_t __b, const int __c)\n {\n-  return (uint8x8_t) __builtin_aarch64_usra_nv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t   (int8x8_t) __b, __c);\n+  return __builtin_aarch64_usra_nv8qi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vsra_n_u16 (uint16x4_t __a, uint16x4_t __b, const int __c)\n {\n-  return (uint16x4_t) __builtin_aarch64_usra_nv4hi ((int16x4_t) __a,\n-\t\t\t\t\t\t    (int16x4_t) __b, __c);\n+  return __builtin_aarch64_usra_nv4hi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vsra_n_u32 (uint32x2_t __a, uint32x2_t __b, const int __c)\n {\n-  return (uint32x2_t) __builtin_aarch64_usra_nv2si ((int32x2_t) __a,\n-\t\t\t\t\t\t    (int32x2_t) __b, __c);\n+  return __builtin_aarch64_usra_nv2si_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vsra_n_u64 (uint64x1_t __a, uint64x1_t __b, const int __c)\n {\n-  return (uint64x1_t) __builtin_aarch64_usra_ndi ((int64x1_t) __a,\n-\t\t\t\t\t\t  (int64x1_t) __b, __c);\n+  return __builtin_aarch64_usra_ndi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n@@ -22542,29 +22503,25 @@ vsraq_n_s64 (int64x2_t __a, int64x2_t __b, const int __c)\n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vsraq_n_u8 (uint8x16_t __a, uint8x16_t __b, const int __c)\n {\n-  return (uint8x16_t) __builtin_aarch64_usra_nv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t     (int8x16_t) __b, __c);\n+  return __builtin_aarch64_usra_nv16qi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vsraq_n_u16 (uint16x8_t __a, uint16x8_t __b, const int __c)\n {\n-  return (uint16x8_t) __builtin_aarch64_usra_nv8hi ((int16x8_t) __a,\n-\t\t\t\t\t\t    (int16x8_t) __b, __c);\n+  return __builtin_aarch64_usra_nv8hi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vsraq_n_u32 (uint32x4_t __a, uint32x4_t __b, const int __c)\n {\n-  return (uint32x4_t) __builtin_aarch64_usra_nv4si ((int32x4_t) __a,\n-\t\t\t\t\t\t    (int32x4_t) __b, __c);\n+  return __builtin_aarch64_usra_nv4si_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vsraq_n_u64 (uint64x2_t __a, uint64x2_t __b, const int __c)\n {\n-  return (uint64x2_t) __builtin_aarch64_usra_nv2di ((int64x2_t) __a,\n-\t\t\t\t\t\t    (int64x2_t) __b, __c);\n+  return __builtin_aarch64_usra_nv2di_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n@@ -22576,7 +22533,7 @@ vsrad_n_s64 (int64x1_t __a, int64x1_t __b, const int __c)\n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vsrad_n_u64 (uint64x1_t __a, uint64x1_t __b, const int __c)\n {\n-  return (uint64x1_t) __builtin_aarch64_usra_ndi (__a, __b, __c);\n+  return __builtin_aarch64_usra_ndi_uuus (__a, __b, __c);\n }\n \n /* vsri */\n@@ -22608,29 +22565,25 @@ vsri_n_s64 (int64x1_t __a, int64x1_t __b, const int __c)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vsri_n_u8 (uint8x8_t __a, uint8x8_t __b, const int __c)\n {\n-  return (uint8x8_t) __builtin_aarch64_usri_nv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t   (int8x8_t) __b, __c);\n+  return __builtin_aarch64_usri_nv8qi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vsri_n_u16 (uint16x4_t __a, uint16x4_t __b, const int __c)\n {\n-  return (uint16x4_t) __builtin_aarch64_usri_nv4hi ((int16x4_t) __a,\n-\t\t\t\t\t\t    (int16x4_t) __b, __c);\n+  return __builtin_aarch64_usri_nv4hi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vsri_n_u32 (uint32x2_t __a, uint32x2_t __b, const int __c)\n {\n-  return (uint32x2_t) __builtin_aarch64_usri_nv2si ((int32x2_t) __a,\n-\t\t\t\t\t\t    (int32x2_t) __b, __c);\n+  return __builtin_aarch64_usri_nv2si_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vsri_n_u64 (uint64x1_t __a, uint64x1_t __b, const int __c)\n {\n-  return (uint64x1_t) __builtin_aarch64_usri_ndi ((int64x1_t) __a,\n-\t\t\t\t\t\t  (int64x1_t) __b, __c);\n+  return __builtin_aarch64_usri_ndi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n@@ -22660,29 +22613,25 @@ vsriq_n_s64 (int64x2_t __a, int64x2_t __b, const int __c)\n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vsriq_n_u8 (uint8x16_t __a, uint8x16_t __b, const int __c)\n {\n-  return (uint8x16_t) __builtin_aarch64_usri_nv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t     (int8x16_t) __b, __c);\n+  return __builtin_aarch64_usri_nv16qi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vsriq_n_u16 (uint16x8_t __a, uint16x8_t __b, const int __c)\n {\n-  return (uint16x8_t) __builtin_aarch64_usri_nv8hi ((int16x8_t) __a,\n-\t\t\t\t\t\t    (int16x8_t) __b, __c);\n+  return __builtin_aarch64_usri_nv8hi_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vsriq_n_u32 (uint32x4_t __a, uint32x4_t __b, const int __c)\n {\n-  return (uint32x4_t) __builtin_aarch64_usri_nv4si ((int32x4_t) __a,\n-\t\t\t\t\t\t    (int32x4_t) __b, __c);\n+  return __builtin_aarch64_usri_nv4si_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vsriq_n_u64 (uint64x2_t __a, uint64x2_t __b, const int __c)\n {\n-  return (uint64x2_t) __builtin_aarch64_usri_nv2di ((int64x2_t) __a,\n-\t\t\t\t\t\t    (int64x2_t) __b, __c);\n+  return __builtin_aarch64_usri_nv2di_uuus (__a, __b, __c);\n }\n \n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n@@ -22694,7 +22643,7 @@ vsrid_n_s64 (int64x1_t __a, int64x1_t __b, const int __c)\n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vsrid_n_u64 (uint64x1_t __a, uint64x1_t __b, const int __c)\n {\n-  return (uint64x1_t) __builtin_aarch64_usri_ndi (__a, __b, __c);\n+  return __builtin_aarch64_usri_ndi_uuus (__a, __b, __c);\n }\n \n /* vst1 */"}]}