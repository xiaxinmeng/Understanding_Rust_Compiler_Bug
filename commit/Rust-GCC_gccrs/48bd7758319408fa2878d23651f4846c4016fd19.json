{"sha": "48bd7758319408fa2878d23651f4846c4016fd19", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NDhiZDc3NTgzMTk0MDhmYTI4NzhkMjM2NTFmNDg0NmM0MDE2ZmQxOQ==", "commit": {"author": {"name": "Alan Modra", "email": "amodra@one.net.au", "date": "2001-04-13T05:19:02Z"}, "committer": {"name": "Alan Modra", "email": "amodra@gcc.gnu.org", "date": "2001-04-13T05:19:02Z"}, "message": "mill32.S: New file.\n\n\t* config/pa/mill32.S: New file.\n\t* config/pa/mill64.S: New file.\n\t* config/pa/t-linux (LIBGCC1, CROSS_LIBGCC1, LIB1ASMFUNCS,\n\tLIB1ASMSRC, CRTSTUFF_T_CFLAGS_S, TARGET_LIBGCC2_CFLAGS): Define.\n\t* config/pa/t-linux64: New file.\n\t* config/pa/t-pa64 (CROSS_LIBGCC1): Change to libgcc1-asm.a\n\t(LIB1ASMFUNCS, LIB1ASMSRC): Define.\n\t(TARGET_LIBGCC2_CFLAGS): Add -Dpa64=1 -DELF=1.\n\nFrom-SVN: r41324", "tree": {"sha": "d25a561406bab7c05bf41c45709867d26e1bf2a5", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/d25a561406bab7c05bf41c45709867d26e1bf2a5"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/48bd7758319408fa2878d23651f4846c4016fd19", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/48bd7758319408fa2878d23651f4846c4016fd19", "html_url": "https://github.com/Rust-GCC/gccrs/commit/48bd7758319408fa2878d23651f4846c4016fd19", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/48bd7758319408fa2878d23651f4846c4016fd19/comments", "author": null, "committer": null, "parents": [{"sha": "a7e184fc5f6e000def7e85ba9719a8451196730a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/a7e184fc5f6e000def7e85ba9719a8451196730a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/a7e184fc5f6e000def7e85ba9719a8451196730a"}], "stats": {"total": 3286, "additions": 3283, "deletions": 3}, "files": [{"sha": "329c90ecdb226680de2446d87dbc2a800034b2a7", "filename": "gcc/ChangeLog", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48bd7758319408fa2878d23651f4846c4016fd19/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48bd7758319408fa2878d23651f4846c4016fd19/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=48bd7758319408fa2878d23651f4846c4016fd19", "patch": "@@ -1,5 +1,14 @@\n 2001-04-13  Alan Modra  <amodra@one.net.au>\n \n+\t* config/pa/mill32.S: New file.\n+\t* config/pa/mill64.S: New file.\n+\t* config/pa/t-linux (LIBGCC1, CROSS_LIBGCC1, LIB1ASMFUNCS,\n+\tLIB1ASMSRC, CRTSTUFF_T_CFLAGS_S, TARGET_LIBGCC2_CFLAGS): Define.\n+\t* config/pa/t-linux64: New file.\n+\t* config/pa/t-pa64 (CROSS_LIBGCC1): Change to libgcc1-asm.a\n+\t(LIB1ASMFUNCS, LIB1ASMSRC): Define.\n+\t(TARGET_LIBGCC2_CFLAGS): Add -Dpa64=1 -DELF=1.\n+\n \t* elfos.h (SELECT_SECTION): Undef before defining.\n \t* pa-linux.h (LINUX_DEFAULT_ELF, PTRDIFF_TYPE, CPP_SPEC): Remove.\n \t(LIB_SPEC): Remove -lmilli."}, {"sha": "726869a8ab1d92a618fe7611e49283518c100c61", "filename": "gcc/config/pa/milli32.S", "status": "added", "additions": 1134, "deletions": 0, "changes": 1134, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48bd7758319408fa2878d23651f4846c4016fd19/gcc%2Fconfig%2Fpa%2Fmilli32.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48bd7758319408fa2878d23651f4846c4016fd19/gcc%2Fconfig%2Fpa%2Fmilli32.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fpa%2Fmilli32.S?ref=48bd7758319408fa2878d23651f4846c4016fd19", "patch": "@@ -0,0 +1,1134 @@\n+;  Low level integer divide, multiply, remainder, etc routines for the HPPA.\n+;  Copyright 1995, 2000, 2001 Free Software Foundation, Inc.\n+\n+;  This file is part of GNU CC.\n+\n+;  GNU CC is free software; you can redistribute it and/or modify\n+;  it under the terms of the GNU General Public License as published by\n+;  the Free Software Foundation; either version 2, or (at your option)\n+;  any later version.\n+\n+;  In addition to the permissions in the GNU General Public License, the\n+;  Free Software Foundation gives you unlimited permission to link the\n+;  compiled version of this file with other programs, and to distribute\n+;  those programs without any restriction coming from the use of this\n+;  file.  (The General Public License restrictions do apply in other\n+;  respects; for example, they cover modification of the file, and\n+;  distribution when not linked into another program.)\n+\n+;  GNU CC is distributed in the hope that it will be useful,\n+;  but WITHOUT ANY WARRANTY; without even the implied warranty of\n+;  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+;  GNU General Public License for more details.\n+\n+;  You should have received a copy of the GNU General Public License\n+;  along with GNU CC; see the file COPYING.  If not, write to\n+;  the Free Software Foundation, 59 Temple Place - Suite 330,\n+;  Boston, MA 02111-1307, USA.\n+\n+#ifdef __STDC__\n+#define CAT(a,b)\ta##b\n+#else\n+#define CAT(a,b)\ta/**/b\n+#endif\n+\n+#ifdef ELF\n+\n+#define SPACE \\\n+! .text! .align 4\n+#define GSYM(sym) \\\n+! .export sym,millicode!sym:\n+#define LSYM(sym) \\\n+!CAT(.L,sym:)\n+#define LREF(sym) CAT(.L,sym)\n+\n+#else\n+\n+#define SPACE \\\n+! .space $TEXT$! .subspa $MILLICODE$,quad=0,align=8,access=0x2c,sort=8! .align 4\n+#define GSYM(sym) \\\n+! .export sym,millicode!sym\n+#define LSYM(sym) \\\n+!CAT(L$,sym)\n+#define LREF(sym) CAT(L$,sym)\n+#endif\n+\n+#ifdef L_dyncall\n+SPACE\n+GSYM($$dyncall)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tbb,>=,n\t%r22,30,LREF(1)\t\t; branch if not plabel address\n+\tdepi\t0,31,2,%r22\t\t; clear the two least significant bits\n+\tldw\t4(%r22),%r19\t\t; load new LTP value\n+\tldw\t0(%r22),%r22\t\t; load address of target\n+LSYM(1)\n+#ifdef LINUX\n+\tbv\t%r0(%r22)\t\t; branch to the real target\n+#else\n+\tldsid\t(%sr0,%r22),%r1\t\t; get the \"space ident\" selected by r22\n+\tmtsp\t%r1,%sr0\t\t; move that space identifier into sr0\n+\tbe\t0(%sr0,%r22)\t\t; branch to the real target\n+#endif\n+\tstw\t%r2,-24(%r30)\t\t; save return address into frame marker\n+\t.exit\n+\t.procend\n+#endif\n+\n+\n+#ifdef L_multiply\n+#define\top0\t%r26\n+#define\top1\t%r25\n+#define res\t%r29\n+#define ret\t%r31\n+#define tmp\t%r1\n+\n+SPACE\n+GSYM($$mulU)\n+GSYM($$mulI)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\taddi,tr\t\t0,%r0,res\t; clear out res, skip next insn\n+LSYM(loop)\n+\tzdep\t\top1,26,27,op1\t; shift up op1 by 5\n+LSYM(lo)\n+\tzdep\t\top0,30,5,tmp\t; extract next 5 bits and shift up\n+\tblr\t\ttmp,%r0\n+\textru\t\top0,26,27,op0\t; shift down op0 by 5\n+LSYM(0)\n+\tcomib,<>\t0,op0,LREF(lo)\n+\tzdep\t\top1,26,27,op1\t; shift up op1 by 5\n+\tbv\t\t%r0(ret)\n+\tnop\n+LSYM(1)\n+\tb\t\tLREF(loop)\n+\taddl\t\top1,res,res\n+\tnop\n+\tnop\n+LSYM(2)\n+\tb\t\tLREF(loop)\n+\tsh1addl\t\top1,res,res\n+\tnop\n+\tnop\n+LSYM(3)\n+\tsh1addl\t\top1,op1,tmp\t; 3x\n+\tb\t\tLREF(loop)\n+\taddl\t\ttmp,res,res\n+\tnop\n+LSYM(4)\n+\tb\t\tLREF(loop)\n+\tsh2addl\t\top1,res,res\n+\tnop\n+\tnop\n+LSYM(5)\n+\tsh2addl\t\top1,op1,tmp\t; 5x\n+\tb\t\tLREF(loop)\n+\taddl\t\ttmp,res,res\n+\tnop\n+LSYM(6)\n+\tsh1addl\t\top1,op1,tmp\t; 3x\n+\tb\t\tLREF(loop)\n+\tsh1addl\t\ttmp,res,res\n+\tnop\n+LSYM(7)\n+\tzdep\t\top1,28,29,tmp\t; 8x\n+\tsub\t\ttmp,op1,tmp\t; 7x\n+\tb\t\tLREF(loop)\n+\taddl\t\ttmp,res,res\n+LSYM(8)\n+\tb\t\tLREF(loop)\n+\tsh3addl\t\top1,res,res\n+\tnop\n+\tnop\n+LSYM(9)\n+\tsh3addl\t\top1,op1,tmp\t; 9x\n+\tb\t\tLREF(loop)\n+\taddl\t\ttmp,res,res\n+\tnop\n+LSYM(10)\n+\tsh2addl\t\top1,op1,tmp\t; 5x\n+\tb\t\tLREF(loop)\n+\tsh1addl\t\ttmp,res,res\n+\tnop\n+LSYM(11)\n+\tsh2addl\t\top1,op1,tmp\t; 5x\n+\tsh1addl\t\ttmp,op1,tmp\t; 11x\n+\tb\t\tLREF(loop)\n+\taddl\t\ttmp,res,res\n+LSYM(12)\n+\tsh1addl\t\top1,op1,tmp\t; 3x\n+\tb\t\tLREF(loop)\n+\tsh2addl\t\ttmp,res,res\n+\tnop\n+LSYM(13)\n+\tsh1addl\t\top1,op1,tmp\t; 3x\n+\tsh2addl\t\ttmp,op1,tmp\t; 13x\n+\tb\t\tLREF(loop)\n+\taddl\t\ttmp,res,res\n+LSYM(14)\n+\tzdep\t\top1,28,29,tmp\t; 8x\n+\tsub\t\ttmp,op1,tmp\t; 7x\n+\tb\t\tLREF(loop)\n+\tsh1addl\t\ttmp,res,res\n+LSYM(15)\n+\tzdep\t\top1,27,28,tmp\t; 16x\n+\tsub\t\ttmp,op1,tmp\t; 15x\n+\tb\t\tLREF(loop)\n+\taddl\t\ttmp,res,res\n+LSYM(16)\n+\tzdep\t\top1,27,28,tmp\t; 16x\n+\tb\t\tLREF(loop)\n+\taddl\t\ttmp,res,res\n+\tnop\n+LSYM(17)\n+\tzdep\t\top1,27,28,tmp\t; 16x\n+\taddl\t\ttmp,op1,tmp\t; 17x\n+\tb\t\tLREF(loop)\n+\taddl\t\ttmp,res,res\n+LSYM(18)\n+\tsh3addl\t\top1,op1,tmp\t; 9x\n+\tb\t\tLREF(loop)\n+\tsh1addl\t\ttmp,res,res\n+\tnop\n+LSYM(19)\n+\tsh3addl\t\top1,op1,tmp\t; 9x\n+\tsh1addl\t\ttmp,op1,tmp\t; 19x\n+\tb\t\tLREF(loop)\n+\taddl\t\ttmp,res,res\n+LSYM(20)\n+\tsh2addl\t\top1,op1,tmp\t; 5x\n+\tb\t\tLREF(loop)\n+\tsh2addl\t\ttmp,res,res\n+\tnop\n+LSYM(21)\n+\tsh2addl\t\top1,op1,tmp\t; 5x\n+\tsh2addl\t\ttmp,op1,tmp\t; 21x\n+\tb\t\tLREF(loop)\n+\taddl\t\ttmp,res,res\n+LSYM(22)\n+\tsh2addl\t\top1,op1,tmp\t; 5x\n+\tsh1addl\t\ttmp,op1,tmp\t; 11x\n+\tb\t\tLREF(loop)\n+\tsh1addl\t\ttmp,res,res\n+LSYM(23)\n+\tsh1addl\t\top1,op1,tmp\t; 3x\n+\tsh3addl\t\ttmp,res,res\t; += 8x3\n+\tb\t\tLREF(loop)\n+\tsub\t\tres,op1,res\t; -= x\n+LSYM(24)\n+\tsh1addl\t\top1,op1,tmp\t; 3x\n+\tb\t\tLREF(loop)\n+\tsh3addl\t\ttmp,res,res\t; += 8x3\n+\tnop\n+LSYM(25)\n+\tsh2addl\t\top1,op1,tmp\t; 5x\n+\tsh2addl\t\ttmp,tmp,tmp\t; 25x\n+\tb\t\tLREF(loop)\n+\taddl\t\ttmp,res,res\n+LSYM(26)\n+\tsh1addl\t\top1,op1,tmp\t; 3x\n+\tsh2addl\t\ttmp,op1,tmp\t; 13x\n+\tb\t\tLREF(loop)\n+\tsh1addl\t\ttmp,res,res\t; += 2x13\n+LSYM(27)\n+\tsh1addl\t\top1,op1,tmp\t; 3x\n+\tsh3addl\t\ttmp,tmp,tmp\t; 27x\n+\tb\t\tLREF(loop)\n+\taddl\t\ttmp,res,res\n+LSYM(28)\n+\tzdep\t\top1,28,29,tmp\t; 8x\n+\tsub\t\ttmp,op1,tmp\t; 7x\n+\tb\t\tLREF(loop)\n+\tsh2addl\t\ttmp,res,res\t; += 4x7\n+LSYM(29)\n+\tsh1addl\t\top1,op1,tmp\t; 3x\n+\tsub\t\tres,tmp,res\t; -= 3x\n+\tb\t\tLREF(foo)\n+\tzdep\t\top1,26,27,tmp\t; 32x\n+LSYM(30)\n+\tzdep\t\top1,27,28,tmp\t; 16x\n+\tsub\t\ttmp,op1,tmp\t; 15x\n+\tb\t\tLREF(loop)\n+\tsh1addl\t\ttmp,res,res\t; += 2x15\n+LSYM(31)\n+\tzdep\t\top1,26,27,tmp\t; 32x\n+\tsub\t\ttmp,op1,tmp\t; 31x\n+LSYM(foo)\n+\tb\t\tLREF(loop)\n+\taddl\t\ttmp,res,res\n+\t.exit\n+\t.procend\n+#endif\n+\n+\n+#ifdef L_divU\n+#define dividend %r26\n+#define divisor %r25\n+#define tmp %r1\n+#define quotient %r29\n+#define ret %r31\n+\n+SPACE\n+GSYM($$divU)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tcomb,<\t\tdivisor,0,LREF(largedivisor)\n+\t sub\t\t%r0,divisor,%r1\t\t; clear cy as side-effect\n+\tds\t\t%r0,%r1,%r0\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r0,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,quotient\n+\tds\t\t%r1,divisor,%r1\n+\tbv\t\t%r0(ret)\n+\taddc\t\tquotient,quotient,quotient\n+LSYM(largedivisor)\n+\tcomclr,<<\tdividend,divisor,quotient\n+\tldi\t\t1,quotient\n+\tbv,n\t\t%r0(ret)\n+\t.exit\n+\t.procend\n+#endif\n+\n+\n+#ifdef L_remU\n+#define dividend %r26\n+#define divisor %r25\n+#define quotient %r29\n+#define tmp %r1\n+#define ret %r31\n+\n+SPACE\n+GSYM($$remU)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tcomb,<\t\tdivisor,0,LREF(largedivisor)\n+\t sub\t\t%r0,divisor,%r1\t\t; clear cy as side-effect\n+\tds\t\t%r0,%r1,%r0\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r0,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,quotient\n+\tds\t\t%r1,divisor,%r1\n+\tcomclr,>=\t%r1,%r0,%r0\n+\taddl\t\t%r1,divisor,%r1\n+\tbv\t\t%r0(ret)\n+\tcopy\t\t%r1,quotient\n+LSYM(largedivisor)\n+\tsub,>>=\t\tdividend,divisor,quotient\n+\tcopy\t\tdividend,quotient\n+\tbv,n\t\t%r0(ret)\n+\t.exit\n+\t.procend\n+#endif\n+\n+\n+#ifdef L_divI\n+#define dividend %r26\n+#define divisor %r25\n+#define quotient %r29\n+#define tmp %r1\n+#define ret %r31\n+\n+SPACE\n+GSYM($$divI)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\txor\t\tdividend,divisor,quotient\t; result sign\n+\tcomclr,>=\tdivisor,%r0,%r0\t\t\t; get absolute values\n+\tsub\t\t%r0,divisor,divisor\n+\tcomclr,>=\tdividend,%r0,%r0\n+\tsub\t\t%r0,dividend,dividend\n+\n+\tcomb,<\t\tdivisor,0,LREF(largedivisor)\n+\t sub\t\t%r0,divisor,%r1\t\t; clear cy as side-effect\n+\tds\t\t%r0,%r1,%r0\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r0,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tcomclr,>=\t%r1,%r0,%r0\n+\taddl\t\t%r1,divisor,%r1\n+\tcomclr,>=\tquotient,%r0,%r0\t; skip of no need to negate\n+\tsub\t\t%r0,dividend,dividend\n+\tbv\t\t%r0(ret)\n+\tcopy\t\tdividend,quotient\n+LSYM(largedivisor)\n+\tcomclr,<<\tdividend,divisor,quotient\n+\tldi\t\t1,quotient\n+\tbv,n\t\t%r0(ret)\n+\t.exit\n+\t.procend\n+#endif\n+\n+\n+#ifdef L_remI\n+#define dividend %r26\n+#define divisor %r25\n+#define quotient %r29\n+#define tmp %r1\n+#define ret %r31\n+\n+SPACE\n+GSYM($$remI)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\txor\t\tdividend,%r0,quotient\t\t; result sign\n+\tcomclr,>=\tdivisor,%r0,%r0\t\t\t; get absolute values\n+\tsub\t\t%r0,divisor,divisor\n+\tcomclr,>=\tdividend,%r0,%r0\n+\tsub\t\t%r0,dividend,dividend\n+\n+\tcomb,<\t\tdivisor,0,LREF(largedivisor)\n+\t sub\t\t%r0,divisor,%r1\t\t; clear cy as side-effect\n+\tds\t\t%r0,%r1,%r0\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r0,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tds\t\t%r1,divisor,%r1\n+\taddc\t\tdividend,dividend,dividend\n+\tcomclr,>=\t%r1,%r0,%r0\n+\taddl\t\t%r1,divisor,%r1\n+\tcomclr,>=\tquotient,%r0,%r0\t; skip of no need to negate\n+\tsub\t\t%r0,%r1,%r1\n+\tbv\t\t%r0(ret)\n+\tcopy\t\t%r1,quotient\n+LSYM(largedivisor)\n+\tsub,>>=\t\tdividend,divisor,quotient\n+\tcopy\t\tdividend,quotient\n+\tbv,n\t\t%r0(ret)\n+\t.exit\n+\t.procend\n+#endif\n+\n+\n+#if defined (L_divU_3) && !defined (SMALL_LIB)\n+#undef L_divU_3\n+#define dividend %r26\n+#define divisor %r25\n+#define tmp %r1\n+#define result %r29\n+#define ret %r31\n+\n+SPACE\n+GSYM($$divU_3)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tsh2add\t%r26,%r26,%r29\t\t; r29 = lo(101 x r)\n+\tshd\t%r0,%r26,30,%r1\t\t;  r1 = hi(100 x r)\n+\taddc\t%r1,%r0,%r1\t\t;  r1 = hi(101 x r)\n+; r in r1,,r29\n+\tzdep\t%r29,27,28,%r25\t\t; r25 = lo(10000 x r)\n+\tadd\t%r25,%r29,%r25\t\t; r25 = lo(10001 x r)\n+\tshd\t%r1,%r29,28,%r29\t; r29 = hi(10000 x r)\n+\taddc\t%r29,%r1,%r29\t\t; r29 = hi(10001 x r)\n+; r in r29,,r25\n+\tzdep\t%r25,23,24,%r1\t\t;  r1 = lo(100000000 x r)\n+\tadd\t%r1,%r25,%r1\t\t;  r1 = lo(100000001 x r)\n+\tshd\t%r29,%r25,24,%r25\t; r25 = hi(100000000 x r)\n+\taddc\t%r25,%r29,%r25\t\t; r25 = hi(100000001 x r)\n+; r in r25,,r1\n+\tzdep\t%r1,15,16,%r29\n+\tadd\t%r29,%r1,%r29\n+\tshd\t%r25,%r1,16,%r1\n+\taddc\t%r1,%r25,%r1\n+; r in r1,,r29\n+\tsh1add\t%r29,%r26,%r0\t\t;  r0 = lo(10 x r) + dividend\n+\tshd\t%r1,%r29,31,%r29\t; r29 = hi(10 x r)\n+\taddc\t%r29,%r0,%r29\n+\tbv\t%r0(ret)\n+\textru\t%r29,30,31,result\n+\t.exit\n+\t.procend\n+#endif\n+\n+\n+#if defined (L_divU_5) && !defined (SMALL_LIB)\n+#undef L_divU_5\n+#define dividend %r26\n+#define divisor %r25\n+#define tmp %r1\n+#define result %r29\n+#define ret %r31\n+\n+SPACE\n+GSYM($$divU_5)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tsh1add\t%r26,%r26,%r29\t\t; r29 = lo(11 x r)\n+\tshd\t%r0,%r26,31,%r1\t\t;  r1 = hi(10 x r)\n+\taddc\t%r1,%r0,%r1\t\t;  r1 = hi(11 x r)\n+; r in r1,,r29\n+\tzdep\t%r29,27,28,%r25\t\t; r25 = lo(10000 x r)\n+\tadd\t%r25,%r29,%r25\t\t; r25 = lo(10001 x r)\n+\tshd\t%r1,%r29,28,%r29\t; r29 = hi(10000 x r)\n+\taddc\t%r29,%r1,%r29\t\t; r29 = hi(10001 x r)\n+; r in r29,,r25\n+\tzdep\t%r25,23,24,%r1\t\t;  r1 = lo(100000000 x r)\n+\tadd\t%r1,%r25,%r1\t\t;  r1 = lo(100000001 x r)\n+\tshd\t%r29,%r25,24,%r25\t; r25 = hi(100000000 x r)\n+\taddc\t%r25,%r29,%r25\t\t; r25 = hi(100000001 x r)\n+; r in r25,,r1\n+\tzdep\t%r1,15,16,%r29\n+\tadd\t%r29,%r1,%r29\n+\tshd\t%r25,%r1,16,%r1\n+\taddc\t%r1,%r25,%r1\n+; r in r1,,r29\n+\tsh2add\t%r29,%r26,%r0\t\t;  r0 = lo(1000 x r) + dividend\n+\tshd\t%r1,%r29,30,%r29\t; r29 = hi(1000 x r)\n+\taddc\t%r29,%r0,%r29\n+\tbv\t%r0(ret)\n+\textru\t%r29,29,30,result\n+\t.exit\n+\t.procend\n+#endif\n+\n+\n+#if defined (L_divU_6) && !defined (SMALL_LIB)\n+#undef L_divU_6\n+#define dividend %r26\n+#define divisor %r25\n+#define tmp %r1\n+#define result %r29\n+#define ret %r31\n+\n+SPACE\n+GSYM($$divU_6)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tsh2add\t%r26,%r26,%r29\t\t; r29 = lo(101 x r)\n+\tshd\t%r0,%r26,30,%r1\t\t;  r1 = hi(100 x r)\n+\taddc\t%r1,%r0,%r1\t\t;  r1 = hi(101 x r)\n+; r in r1,,r29\n+\tzdep\t%r29,27,28,%r25\t\t; r25 = lo(10000 x r)\n+\tadd\t%r25,%r29,%r25\t\t; r25 = lo(10001 x r)\n+\tshd\t%r1,%r29,28,%r29\t; r29 = hi(10000 x r)\n+\taddc\t%r29,%r1,%r29\t\t; r29 = hi(10001 x r)\n+; r in r29,,r25\n+\tzdep\t%r25,23,24,%r1\t\t;  r1 = lo(100000000 x r)\n+\tadd\t%r1,%r25,%r1\t\t;  r1 = lo(100000001 x r)\n+\tshd\t%r29,%r25,24,%r25\t; r25 = hi(100000000 x r)\n+\taddc\t%r25,%r29,%r25\t\t; r25 = hi(100000001 x r)\n+; r in r25,,r1\n+\tzdep\t%r1,15,16,%r29\n+\tadd\t%r29,%r1,%r29\n+\tshd\t%r25,%r1,16,%r1\n+\taddc\t%r1,%r25,%r1\n+; r in r1,,r29\n+\tsh1add\t%r29,%r26,%r0\t\t;  r0 = lo(10 x r) + dividend\n+\tshd\t%r1,%r29,31,%r29\t; r29 = hi(10 x r)\n+\taddc\t%r29,%r0,%r29\n+\tbv\t%r0(ret)\n+\textru\t%r29,29,30,result\n+\t.exit\n+\t.procend\n+#endif\n+\n+\n+#if defined (L_divU_9) && !defined (SMALL_LIB)\n+#undef L_divU_9\n+#define dividend %r26\n+#define divisor %r25\n+#define tmp %r1\n+#define result %r29\n+#define ret %r31\n+\n+SPACE\n+GSYM($$divU_9)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tzdep\t%r26,28,29,%r29\n+\tsub\t%r29,%r26,%r29\n+\tshd\t0,%r26,29,%r1\n+\tsubb\t%r1,0,%r1\t\t/* 111 */\n+\n+\tzdep\t%r29,25,26,%r25\n+\tadd\t%r25,%r29,%r25\n+\tshd\t%r1,%r29,26,%r29\n+\taddc\t%r29,%r1,%r29\t\t/* 111000111 */\n+\n+\tsh3add\t%r25,%r26,%r1\n+\tshd\t%r29,%r25,29,%r25\n+\taddc\t%r25,0,%r25\t\t/* 111000111001 */\n+\n+\tzdep\t%r1,16,17,%r29\n+\tsub\t%r29,%r1,%r29\n+\tshd\t%r25,%r1,17,%r1\n+\tsubb\t%r1,%r25,%r1\t\t/* 111000111000111000111000111 */\n+\n+\tsh3add\t%r29,%r26,%r0\n+\tshd\t%r1,%r29,29,%r29\n+\taddc\t%r29,0,%r29\t\t/* 111000111000111000111000111001 */\n+\tbv\t%r0(ret)\n+\textru\t%r29,30,31,result\n+\t.exit\n+\t.procend\n+#endif\n+\n+\n+#if defined (L_divU_10) && !defined (SMALL_LIB)\n+#undef L_divU_10\n+#define dividend %r26\n+#define divisor %r25\n+#define tmp %r1\n+#define result %r29\n+#define ret %r31\n+\n+SPACE\n+GSYM($$divU_10)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tsh1add\t%r26,%r26,%r29\t\t; r29 = lo(11 x r)\n+\tshd\t%r0,%r26,31,%r1\t\t;  r1 = hi(10 x r)\n+\taddc\t%r1,%r0,%r1\t\t;  r1 = hi(11 x r)\n+; r in r1,,r29\n+\tzdep\t%r29,27,28,%r25\t\t; r25 = lo(10000 x r)\n+\tadd\t%r25,%r29,%r25\t\t; r25 = lo(10001 x r)\n+\tshd\t%r1,%r29,28,%r29\t; r29 = hi(10000 x r)\n+\taddc\t%r29,%r1,%r29\t\t; r29 = hi(10001 x r)\n+; r in r29,,r25\n+\tzdep\t%r25,23,24,%r1\t\t;  r1 = lo(100000000 x r)\n+\tadd\t%r1,%r25,%r1\t\t;  r1 = lo(100000001 x r)\n+\tshd\t%r29,%r25,24,%r25\t; r25 = hi(100000000 x r)\n+\taddc\t%r25,%r29,%r25\t\t; r25 = hi(100000001 x r)\n+; r in r25,,r1\n+\tzdep\t%r1,15,16,%r29\n+\tadd\t%r29,%r1,%r29\n+\tshd\t%r25,%r1,16,%r1\n+\taddc\t%r1,%r25,%r1\n+; r in r1,,r29\n+\tsh2add\t%r29,%r26,%r0\t\t;  r0 = lo(1000 x r) + dividend\n+\tshd\t%r1,%r29,30,%r29\t; r29 = hi(1000 x r)\n+\taddc\t%r29,%r0,%r29\n+\tbv\t%r0(ret)\n+\textru\t%r29,28,29,result\n+\t.exit\n+\t.procend\n+#endif\n+\n+\n+#if defined (L_divU_12) && !defined (SMALL_LIB)\n+#undef L_divU_12\n+#define dividend %r26\n+#define divisor %r25\n+#define tmp %r1\n+#define result %r29\n+#define ret %r31\n+\n+SPACE\n+GSYM($$divU_12)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tsh2add\t%r26,%r26,%r29\t\t; r29 = lo(101 x r)\n+\tshd\t%r0,%r26,30,%r1\t\t;  r1 = hi(100 x r)\n+\taddc\t%r1,%r0,%r1\t\t;  r1 = hi(101 x r)\n+; r in r1,,r29\n+\tzdep\t%r29,27,28,%r25\t\t; r25 = lo(10000 x r)\n+\tadd\t%r25,%r29,%r25\t\t; r25 = lo(10001 x r)\n+\tshd\t%r1,%r29,28,%r29\t; r29 = hi(10000 x r)\n+\taddc\t%r29,%r1,%r29\t\t; r29 = hi(10001 x r)\n+; r in r29,,r25\n+\tzdep\t%r25,23,24,%r1\t\t;  r1 = lo(100000000 x r)\n+\tadd\t%r1,%r25,%r1\t\t;  r1 = lo(100000001 x r)\n+\tshd\t%r29,%r25,24,%r25\t; r25 = hi(100000000 x r)\n+\taddc\t%r25,%r29,%r25\t\t; r25 = hi(100000001 x r)\n+; r in r25,,r1\n+\tzdep\t%r1,15,16,%r29\n+\tadd\t%r29,%r1,%r29\n+\tshd\t%r25,%r1,16,%r1\n+\taddc\t%r1,%r25,%r1\n+; r in r1,,r29\n+\tsh1add\t%r29,%r26,%r0\t\t;  r0 = lo(10 x r) + dividend\n+\tshd\t%r1,%r29,31,%r29\t; r29 = hi(10 x r)\n+\taddc\t%r29,%r0,%r29\n+\tbv\t%r0(ret)\n+\textru\t%r29,28,29,result\n+\t.exit\n+\t.procend\n+#endif\n+\n+\n+#ifdef L_divU_3\n+SPACE\n+GSYM($$divU_3)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divU\n+\tldi\t\t3,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divU,MILLICODE\n+#endif\n+\n+#ifdef L_divU_5\n+SPACE\n+GSYM($$divU_5)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divU\n+\tldi\t\t5,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divU,MILLICODE\n+#endif\n+\n+#ifdef L_divU_6\n+SPACE\n+GSYM($$divU_6)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divU\n+\tldi\t\t6,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divU,MILLICODE\n+#endif\n+\n+#ifdef L_divU_7\n+SPACE\n+GSYM($$divU_7)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divU\n+\tldi\t\t7,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divU,MILLICODE\n+#endif\n+\n+#ifdef L_divU_9\n+SPACE\n+GSYM($$divU_9)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divU\n+\tldi\t\t9,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divU,MILLICODE\n+#endif\n+\n+#ifdef L_divU_10\n+SPACE\n+GSYM($$divU_10)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divU\n+\tldi\t\t10,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divU,MILLICODE\n+#endif\n+\n+#ifdef L_divU_12\n+SPACE\n+GSYM($$divU_12)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divU\n+\tldi\t\t12,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divU,MILLICODE\n+#endif\n+\n+#ifdef L_divU_14\n+SPACE\n+GSYM($$divU_14)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divU\n+\tldi\t\t14,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divU,MILLICODE\n+#endif\n+\n+#ifdef L_divU_15\n+SPACE\n+GSYM($$divU_15)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divU\n+\tldi\t\t15,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divU,MILLICODE\n+#endif\n+\n+#ifdef L_divI_3\n+SPACE\n+GSYM($$divI_3)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divI\n+\tldi\t\t3,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divI,MILLICODE\n+#endif\n+\n+#ifdef L_divI_5\n+SPACE\n+GSYM($$divI_5)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divI\n+\tldi\t\t5,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divI,MILLICODE\n+#endif\n+\n+#ifdef L_divI_6\n+SPACE\n+GSYM($$divI_6)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divI\n+\tldi\t\t6,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divI,MILLICODE\n+#endif\n+\n+#ifdef L_divI_7\n+SPACE\n+GSYM($$divI_7)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divI\n+\tldi\t\t7,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divI,MILLICODE\n+#endif\n+\n+#ifdef L_divI_9\n+SPACE\n+GSYM($$divI_9)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divI\n+\tldi\t\t9,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divI,MILLICODE\n+#endif\n+\n+#ifdef L_divI_10\n+SPACE\n+GSYM($$divI_10)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divI\n+\tldi\t\t10,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divI,MILLICODE\n+#endif\n+\n+#ifdef L_divI_12\n+SPACE\n+GSYM($$divI_12)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divI\n+\tldi\t\t12,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divI,MILLICODE\n+#endif\n+\n+#ifdef L_divI_14\n+SPACE\n+GSYM($$divI_14)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divI\n+\tldi\t\t14,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divI,MILLICODE\n+#endif\n+\n+#ifdef L_divI_15\n+SPACE\n+GSYM($$divI_15)\n+\t.proc\n+\t.callinfo\tframe=0,no_calls\n+\t.entry\n+\tb\t\t$$divI\n+\tldi\t\t15,%r25\n+\t.exit\n+\t.procend\n+\t.import\t\t$$divI,MILLICODE\n+#endif"}, {"sha": "1a3fb2b42a58b8a39d7602b7afad946e2a63ef85", "filename": "gcc/config/pa/milli64.S", "status": "added", "additions": 2096, "deletions": 0, "changes": 2096, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48bd7758319408fa2878d23651f4846c4016fd19/gcc%2Fconfig%2Fpa%2Fmilli64.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48bd7758319408fa2878d23651f4846c4016fd19/gcc%2Fconfig%2Fpa%2Fmilli64.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fpa%2Fmilli64.S?ref=48bd7758319408fa2878d23651f4846c4016fd19", "patch": "@@ -0,0 +1,2096 @@\n+/* 64-bit millicode, original author Hewlett-Packard\n+   adapted for gcc by Paul Bame <bame@debian.org>\n+   and Alan Modra <alan@linuxcare.com.au>\n+\n+   Copyright 2001 Free Software Foundation, Inc.\n+\n+   This file is part of GNU CC and is released under the terms of\n+   of the GNU General Public License as published by the Free Software\n+   Foundation; either version 2, or (at your option) any later version.\n+   See the file COPYING in the top-level GNU CC source directory for a copy\n+   of the license.  */\n+\n+\n+#ifdef pa64\n+        .level  2.0w\n+#endif\n+\n+/* Hardware General Registers.  */\n+r0:\t.reg\t%r0\n+r1:\t.reg\t%r1\n+r2:\t.reg\t%r2\n+r3:\t.reg\t%r3\n+r4:\t.reg\t%r4\n+r5:\t.reg\t%r5\n+r6:\t.reg\t%r6\n+r7:\t.reg\t%r7\n+r8:\t.reg\t%r8\n+r9:\t.reg\t%r9\n+r10:\t.reg\t%r10\n+r11:\t.reg\t%r11\n+r12:\t.reg\t%r12\n+r13:\t.reg\t%r13\n+r14:\t.reg\t%r14\n+r15:\t.reg\t%r15\n+r16:\t.reg\t%r16\n+r17:\t.reg\t%r17\n+r18:\t.reg\t%r18\n+r19:\t.reg\t%r19\n+r20:\t.reg\t%r20\n+r21:\t.reg\t%r21\n+r22:\t.reg\t%r22\n+r23:\t.reg\t%r23\n+r24:\t.reg\t%r24\n+r25:\t.reg\t%r25\n+r26:\t.reg\t%r26\n+r27:\t.reg\t%r27\n+r28:\t.reg\t%r28\n+r29:\t.reg\t%r29\n+r30:\t.reg\t%r30\n+r31:\t.reg\t%r31\n+\n+/* Hardware Space Registers.  */\n+sr0:\t.reg\t%sr0\n+sr1:\t.reg\t%sr1\n+sr2:\t.reg\t%sr2\n+sr3:\t.reg\t%sr3\n+sr4:\t.reg\t%sr4\n+sr5:\t.reg\t%sr5\n+sr6:\t.reg\t%sr6\n+sr7:\t.reg\t%sr7\n+\n+/* Hardware Floating Point Registers.  */\n+fr0:\t.reg\t%fr0\n+fr1:\t.reg\t%fr1\n+fr2:\t.reg\t%fr2\n+fr3:\t.reg\t%fr3\n+fr4:\t.reg\t%fr4\n+fr5:\t.reg\t%fr5\n+fr6:\t.reg\t%fr6\n+fr7:\t.reg\t%fr7\n+fr8:\t.reg\t%fr8\n+fr9:\t.reg\t%fr9\n+fr10:\t.reg\t%fr10\n+fr11:\t.reg\t%fr11\n+fr12:\t.reg\t%fr12\n+fr13:\t.reg\t%fr13\n+fr14:\t.reg\t%fr14\n+fr15:\t.reg\t%fr15\n+\n+/* Hardware Control Registers.  */\n+cr11:\t.reg\t%cr11\n+sar:\t.reg\t%cr11\t/* Shift Amount Register */\n+\n+/* Software Architecture General Registers.  */\n+rp:\t.reg    r2\t/* return pointer */\n+#ifdef pa64\n+mrp:\t.reg\tr2 \t/* millicode return pointer */\n+#else\n+mrp:\t.reg\tr31\t/* millicode return pointer */\n+#endif\n+ret0:\t.reg    r28\t/* return value */\n+ret1:\t.reg    r29\t/* return value (high part of double) */\n+sp:\t.reg \tr30\t/* stack pointer */\n+dp:\t.reg\tr27\t/* data pointer */\n+arg0:\t.reg\tr26\t/* argument */\n+arg1:\t.reg\tr25\t/* argument or high part of double argument */\n+arg2:\t.reg\tr24\t/* argument */\n+arg3:\t.reg\tr23\t/* argument or high part of double argument */\n+\n+/* Software Architecture Space Registers.  */\n+/* \t\tsr0\t; return link from BLE */\n+sret:\t.reg\tsr1\t/* return value */\n+sarg:\t.reg\tsr1\t/* argument */\n+/* \t\tsr4\t; PC SPACE tracker */\n+/* \t\tsr5\t; process private data */\n+\n+/* Frame Offsets (millicode convention!)  Used when calling other\n+   millicode routines.  Stack unwinding is dependent upon these\n+   definitions.  */\n+r31_slot:\t.equ\t-20\t/* \"current RP\" slot */\n+sr0_slot:\t.equ\t-16     /* \"static link\" slot */\n+#if defined(pa64)\n+mrp_slot:       .equ    -16\t/* \"current RP\" slot */\n+psp_slot:       .equ    -8\t/* \"previous SP\" slot */\n+#else\n+mrp_slot:\t.equ\t-20     /* \"current RP\" slot (replacing \"r31_slot\") */\n+#endif\n+\n+\n+#define DEFINE(name,value)name:\t.EQU\tvalue\n+#define RDEFINE(name,value)name:\t.REG\tvalue\n+#ifdef milliext\n+#define MILLI_BE(lbl)   BE    lbl(sr7,r0)\n+#define MILLI_BEN(lbl)  BE,n  lbl(sr7,r0)\n+#define MILLI_BLE(lbl)\tBLE   lbl(sr7,r0)\n+#define MILLI_BLEN(lbl)\tBLE,n lbl(sr7,r0)\n+#define MILLIRETN\tBE,n  0(sr0,mrp)\n+#define MILLIRET\tBE    0(sr0,mrp)\n+#define MILLI_RETN\tBE,n  0(sr0,mrp)\n+#define MILLI_RET\tBE    0(sr0,mrp)\n+#else\n+#define MILLI_BE(lbl)\tB     lbl\n+#define MILLI_BEN(lbl)  B,n   lbl\n+#define MILLI_BLE(lbl)\tBL    lbl,mrp\n+#define MILLI_BLEN(lbl)\tBL,n  lbl,mrp\n+#define MILLIRETN\tBV,n  0(mrp)\n+#define MILLIRET\tBV    0(mrp)\n+#define MILLI_RETN\tBV,n  0(mrp)\n+#define MILLI_RET\tBV    0(mrp)\n+#endif\n+\n+#ifdef __STDC__\n+#define CAT(a,b)\ta##b\n+#else\n+#define CAT(a,b)\ta/**/b\n+#endif\n+\n+#ifdef ELF\n+#define SUBSPA_MILLI\t .section .text\n+#define SUBSPA_MILLI_DIV .section .text.div,\"ax\",@progbits! .align 16\n+#define SUBSPA_MILLI_MUL .section .text.mul,\"ax\",@progbits! .align 16\n+#define ATTR_MILLI\n+#define SUBSPA_DATA\t .section .data\n+#define ATTR_DATA\n+#define GLOBAL\t\t $global$\n+#define GSYM(sym) \t !sym:\n+#define LSYM(sym)\t !CAT(.L,sym:)\n+#define LREF(sym)\t CAT(.L,sym)\n+\n+#else\n+\n+#ifdef coff\n+/* This used to be .milli but since link32 places different named\n+   sections in different segments millicode ends up a long ways away\n+   from .text (1meg?).  This way they will be a lot closer.\n+\n+   The SUBSPA_MILLI_* specify locality sets for certain millicode\n+   modules in order to ensure that modules that call one another are\n+   placed close together. Without locality sets this is unlikely to\n+   happen because of the Dynamite linker library search algorithm. We\n+   want these modules close together so that short calls always reach\n+   (we don't want to require long calls or use long call stubs).  */\n+\n+#define SUBSPA_MILLI\t .subspa .text\n+#define SUBSPA_MILLI_DIV .subspa .text$dv,align=16\n+#define SUBSPA_MILLI_MUL .subspa .text$mu,align=16\n+#define ATTR_MILLI\t .attr code,read,execute\n+#define SUBSPA_DATA\t .subspa .data\n+#define ATTR_DATA\t .attr init_data,read,write\n+#define GLOBAL\t\t _gp\n+#else\n+#define SUBSPA_MILLI\t .subspa $MILLICODE$,QUAD=0,ALIGN=4,ACCESS=0x2c,SORT=8\n+#define SUBSPA_MILLI_DIV SUBSPA_MILLI\n+#define SUBSPA_MILLI_MUL SUBSPA_MILLI\n+#define ATTR_MILLI\n+#define SUBSPA_DATA\t .subspa $BSS$,quad=1,align=8,access=0x1f,sort=80,zero\n+#define ATTR_DATA\n+#define GLOBAL\t\t $global$\n+#endif\n+#define SPACE_DATA\t .space $PRIVATE$,spnum=1,sort=16\n+\n+#define GSYM(sym)\t !sym\n+#define LSYM(sym)\t !CAT(L$,sym)\n+#define LREF(sym)\t CAT(L$,sym)\n+#endif\n+\n+\n+#ifdef L_divI\n+/* ROUTINES:\t$$divI, $$divoI\n+\n+   Single precision divide for signed binary integers.\n+\n+   The quotient is truncated towards zero.\n+   The sign of the quotient is the XOR of the signs of the dividend and\n+   divisor.\n+   Divide by zero is trapped.\n+   Divide of -2**31 by -1 is trapped for $$divoI but not for $$divI.\n+\n+   INPUT REGISTERS:\n+   .\targ0 ==\tdividend\n+   .\targ1 ==\tdivisor\n+   .\tmrp  == return pc\n+   .\tsr0  == return space when called externally\n+\n+   OUTPUT REGISTERS:\n+   .\targ0 =\tundefined\n+   .\targ1 =\tundefined\n+   .\tret1 =\tquotient\n+\n+   OTHER REGISTERS AFFECTED:\n+   .\tr1   =\tundefined\n+\n+   SIDE EFFECTS:\n+   .\tCauses a trap under the following conditions:\n+   .\t\tdivisor is zero  (traps with ADDIT,=  0,25,0)\n+   .\t\tdividend==-2**31  and divisor==-1 and routine is $$divoI\n+   .\t\t\t\t (traps with ADDO  26,25,0)\n+   .\tChanges memory at the following places:\n+   .\t\tNONE\n+\n+   PERMISSIBLE CONTEXT:\n+   .\tUnwindable.\n+   .\tSuitable for internal or external millicode.\n+   .\tAssumes the special millicode register conventions.\n+\n+   DISCUSSION:\n+   .\tBranchs to other millicode routines using BE\n+   .\t\t$$div_# for # being 2,3,4,5,6,7,8,9,10,12,14,15\n+   .\n+   .\tFor selected divisors, calls a divide by constant routine written by\n+   .\tKarl Pettis.  Eligible divisors are 1..15 excluding 11 and 13.\n+   .\n+   .\tThe only overflow case is -2**31 divided by -1.\n+   .\tBoth routines return -2**31 but only $$divoI traps.  */\n+\n+RDEFINE(temp,r1)\n+RDEFINE(retreg,ret1)\t/*  r29 */\n+RDEFINE(temp1,arg0)\n+\tSUBSPA_MILLI_DIV\n+\tATTR_MILLI\n+\t.import $$divI_2,millicode\n+\t.import $$divI_3,millicode\n+\t.import $$divI_4,millicode\n+\t.import $$divI_5,millicode\n+\t.import $$divI_6,millicode\n+\t.import $$divI_7,millicode\n+\t.import $$divI_8,millicode\n+\t.import $$divI_9,millicode\n+\t.import $$divI_10,millicode\n+\t.import $$divI_12,millicode\n+\t.import $$divI_14,millicode\n+\t.import $$divI_15,millicode\n+\t.export $$divI,millicode\n+\t.export\t$$divoI,millicode\n+\t.proc\n+\t.callinfo\tmillicode\n+\t.entry\n+GSYM($$divoI)\n+\tcomib,=,n  -1,arg1,LREF(negative1)\t/*  when divisor == -1 */\n+GSYM($$divI)\n+\tldo\t-1(arg1),temp\t\t/*  is there at most one bit set ? */\n+\tand,<>\targ1,temp,r0\t\t/*  if not, don't use power of 2 divide */\n+\taddi,>\t0,arg1,r0\t\t/*  if divisor > 0, use power of 2 divide */\n+\tb,n\tLREF(neg_denom)\n+LSYM(pow2)\n+\taddi,>=\t0,arg0,retreg\t\t/*  if numerator is negative, add the */\n+\tadd\targ0,temp,retreg\t/*  (denominaotr -1) to correct for shifts */\n+\textru,=\targ1,15,16,temp\t\t/*  test denominator with 0xffff0000 */\n+\textrs\tretreg,15,16,retreg\t/*  retreg = retreg >> 16 */\n+\tor\targ1,temp,arg1\t\t/*  arg1 = arg1 | (arg1 >> 16) */\n+\tldi\t0xcc,temp1\t\t/*  setup 0xcc in temp1 */\n+\textru,= arg1,23,8,temp\t\t/*  test denominator with 0xff00 */\n+\textrs\tretreg,23,24,retreg\t/*  retreg = retreg >> 8 */\n+\tor\targ1,temp,arg1\t\t/*  arg1 = arg1 | (arg1 >> 8) */\n+\tldi\t0xaa,temp\t\t/*  setup 0xaa in temp */\n+\textru,= arg1,27,4,r0\t\t/*  test denominator with 0xf0 */\n+\textrs\tretreg,27,28,retreg\t/*  retreg = retreg >> 4 */\n+\tand,=\targ1,temp1,r0\t\t/*  test denominator with 0xcc */\n+\textrs\tretreg,29,30,retreg\t/*  retreg = retreg >> 2 */\n+\tand,=\targ1,temp,r0\t\t/*  test denominator with 0xaa */\n+\textrs\tretreg,30,31,retreg\t/*  retreg = retreg >> 1 */\n+\tMILLIRETN\n+LSYM(neg_denom)\n+\taddi,<\t0,arg1,r0\t\t/*  if arg1 >= 0, it's not power of 2 */\n+\tb,n\tLREF(regular_seq)\n+\tsub\tr0,arg1,temp\t\t/*  make denominator positive */\n+\tcomb,=,n  arg1,temp,LREF(regular_seq)\t/*  test against 0x80000000 and 0 */\n+\tldo\t-1(temp),retreg\t\t/*  is there at most one bit set ? */\n+\tand,=\ttemp,retreg,r0\t\t/*  if so, the denominator is power of 2 */\n+\tb,n\tLREF(regular_seq)\n+\tsub\tr0,arg0,retreg\t\t/*  negate numerator */\n+\tcomb,=,n arg0,retreg,LREF(regular_seq) /*  test against 0x80000000 */\n+\tcopy\tretreg,arg0\t\t/*  set up arg0, arg1 and temp\t*/\n+\tcopy\ttemp,arg1\t\t/*  before branching to pow2 */\n+\tb\tLREF(pow2)\n+\tldo\t-1(arg1),temp\n+LSYM(regular_seq)\n+\tcomib,>>=,n 15,arg1,LREF(small_divisor)\n+\tadd,>=\t0,arg0,retreg\t\t/*  move dividend, if retreg < 0, */\n+LSYM(normal)\n+\tsubi\t0,retreg,retreg\t\t/*    make it positive */\n+\tsub\t0,arg1,temp\t\t/*  clear carry,  */\n+\t\t\t\t\t/*    negate the divisor */\n+\tds\t0,temp,0\t\t/*  set V-bit to the comple- */\n+\t\t\t\t\t/*    ment of the divisor sign */\n+\tadd\tretreg,retreg,retreg\t/*  shift msb bit into carry */\n+\tds\tr0,arg1,temp\t\t/*  1st divide step, if no carry */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  2nd divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  3rd divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  4th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  5th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  6th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  7th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  8th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  9th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  10th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  11th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  12th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  13th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  14th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  15th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  16th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  17th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  18th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  19th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  20th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  21st divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  22nd divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  23rd divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  24th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  25th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  26th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  27th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  28th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  29th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  30th divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  31st divide step */\n+\taddc\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/*  32nd divide step, */\n+\taddc\tretreg,retreg,retreg\t/*  shift last retreg bit into retreg */\n+\txor,>=\targ0,arg1,0\t\t/*  get correct sign of quotient */\n+\t  sub\t0,retreg,retreg\t\t/*    based on operand signs */\n+\tMILLIRETN\n+\tnop\n+\n+LSYM(small_divisor)\n+\n+#if defined(pa64)\n+/*  Clear the upper 32 bits of the arg1 register.  We are working with\t*/\n+/*  small divisors (and 32 bit integers)   We must not be mislead  */\n+/*  by \"1\" bits left in the upper 32 bits. */\n+\tdepd r0,31,32,arg1\n+#endif\n+\tblr,n\targ1,r0\n+\tnop\n+/*  table for divisor == 0,1, ... ,15 */\n+\taddit,=\t0,arg1,r0\t/*  trap if divisor == 0 */\n+\tnop\n+\tMILLIRET\t\t/*  divisor == 1 */\n+\tcopy\targ0,retreg\n+\tMILLI_BEN($$divI_2)\t/*  divisor == 2 */\n+\tnop\n+\tMILLI_BEN($$divI_3)\t/*  divisor == 3 */\n+\tnop\n+\tMILLI_BEN($$divI_4)\t/*  divisor == 4 */\n+\tnop\n+\tMILLI_BEN($$divI_5)\t/*  divisor == 5 */\n+\tnop\n+\tMILLI_BEN($$divI_6)\t/*  divisor == 6 */\n+\tnop\n+\tMILLI_BEN($$divI_7)\t/*  divisor == 7 */\n+\tnop\n+\tMILLI_BEN($$divI_8)\t/*  divisor == 8 */\n+\tnop\n+\tMILLI_BEN($$divI_9)\t/*  divisor == 9 */\n+\tnop\n+\tMILLI_BEN($$divI_10)\t/*  divisor == 10 */\n+\tnop\n+\tb\tLREF(normal)\t\t/*  divisor == 11 */\n+\tadd,>=\t0,arg0,retreg\n+\tMILLI_BEN($$divI_12)\t/*  divisor == 12 */\n+\tnop\n+\tb\tLREF(normal)\t\t/*  divisor == 13 */\n+\tadd,>=\t0,arg0,retreg\n+\tMILLI_BEN($$divI_14)\t/*  divisor == 14 */\n+\tnop\n+\tMILLI_BEN($$divI_15)\t/*  divisor == 15 */\n+\tnop\n+\n+LSYM(negative1)\n+\tsub\t0,arg0,retreg\t/*  result is negation of dividend */\n+\tMILLIRET\n+\taddo\targ0,arg1,r0\t/*  trap iff dividend==0x80000000 && divisor==-1 */\n+\t.exit\n+\t.procend\n+\t.end\n+#endif\n+\n+#ifdef L_divU\n+/* ROUTINE:\t$$divU\n+   .\n+   .\tSingle precision divide for unsigned integers.\n+   .\n+   .\tQuotient is truncated towards zero.\n+   .\tTraps on divide by zero.\n+\n+   INPUT REGISTERS:\n+   .\targ0 ==\tdividend\n+   .\targ1 ==\tdivisor\n+   .\tmrp  == return pc\n+   .\tsr0  == return space when called externally\n+\n+   OUTPUT REGISTERS:\n+   .\targ0 =\tundefined\n+   .\targ1 =\tundefined\n+   .\tret1 =\tquotient\n+\n+   OTHER REGISTERS AFFECTED:\n+   .\tr1   =\tundefined\n+\n+   SIDE EFFECTS:\n+   .\tCauses a trap under the following conditions:\n+   .\t\tdivisor is zero\n+   .\tChanges memory at the following places:\n+   .\t\tNONE\n+\n+   PERMISSIBLE CONTEXT:\n+   .\tUnwindable.\n+   .\tDoes not create a stack frame.\n+   .\tSuitable for internal or external millicode.\n+   .\tAssumes the special millicode register conventions.\n+\n+   DISCUSSION:\n+   .\tBranchs to other millicode routines using BE:\n+   .\t\t$$divU_# for 3,5,6,7,9,10,12,14,15\n+   .\n+   .\tFor selected small divisors calls the special divide by constant\n+   .\troutines written by Karl Pettis.  These are: 3,5,6,7,9,10,12,14,15.  */\n+\n+RDEFINE(temp,r1)\n+RDEFINE(retreg,ret1)\t/* r29 */\n+RDEFINE(temp1,arg0)\n+\tSUBSPA_MILLI_DIV\n+\tATTR_MILLI\n+\t.export $$divU,millicode\n+\t.import $$divU_3,millicode\n+\t.import $$divU_5,millicode\n+\t.import $$divU_6,millicode\n+\t.import $$divU_7,millicode\n+\t.import $$divU_9,millicode\n+\t.import $$divU_10,millicode\n+\t.import $$divU_12,millicode\n+\t.import $$divU_14,millicode\n+\t.import $$divU_15,millicode\n+\t.proc\n+\t.callinfo\tmillicode\n+\t.entry\n+GSYM($$divU)\n+/* The subtract is not nullified since it does no harm and can be used\n+   by the two cases that branch back to \"normal\".  */\n+\tldo\t-1(arg1),temp\t\t/* is there at most one bit set ? */\n+\tand,=\targ1,temp,r0\t\t/* if so, denominator is power of 2 */\n+\tb\tLREF(regular_seq)\n+\taddit,=\t0,arg1,0\t\t/* trap for zero dvr */\n+\tcopy\targ0,retreg\n+\textru,= arg1,15,16,temp\t\t/* test denominator with 0xffff0000 */\n+\textru\tretreg,15,16,retreg\t/* retreg = retreg >> 16 */\n+\tor\targ1,temp,arg1\t\t/* arg1 = arg1 | (arg1 >> 16) */\n+\tldi\t0xcc,temp1\t\t/* setup 0xcc in temp1 */\n+\textru,= arg1,23,8,temp\t\t/* test denominator with 0xff00 */\n+\textru\tretreg,23,24,retreg\t/* retreg = retreg >> 8 */\n+\tor\targ1,temp,arg1\t\t/* arg1 = arg1 | (arg1 >> 8) */\n+\tldi\t0xaa,temp\t\t/* setup 0xaa in temp */\n+\textru,= arg1,27,4,r0\t\t/* test denominator with 0xf0 */\n+\textru\tretreg,27,28,retreg\t/* retreg = retreg >> 4 */\n+\tand,=\targ1,temp1,r0\t\t/* test denominator with 0xcc */\n+\textru\tretreg,29,30,retreg\t/* retreg = retreg >> 2 */\n+\tand,=\targ1,temp,r0\t\t/* test denominator with 0xaa */\n+\textru\tretreg,30,31,retreg\t/* retreg = retreg >> 1 */\n+\tMILLIRETN\n+\tnop\t\n+LSYM(regular_seq)\n+\tcomib,>=  15,arg1,LREF(special_divisor)\n+\tsubi\t0,arg1,temp\t\t/* clear carry, negate the divisor */\n+\tds\tr0,temp,r0\t\t/* set V-bit to 1 */\n+LSYM(normal)\n+\tadd\targ0,arg0,retreg\t/* shift msb bit into carry */\n+\tds\tr0,arg1,temp\t\t/* 1st divide step, if no carry */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 2nd divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 3rd divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 4th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 5th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 6th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 7th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 8th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 9th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 10th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 11th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 12th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 13th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 14th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 15th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 16th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 17th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 18th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 19th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 20th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 21st divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 22nd divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 23rd divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 24th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 25th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 26th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 27th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 28th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 29th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 30th divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 31st divide step */\n+\taddc\tretreg,retreg,retreg\t/* shift retreg with/into carry */\n+\tds\ttemp,arg1,temp\t\t/* 32nd divide step, */\n+\tMILLIRET\n+\taddc\tretreg,retreg,retreg\t/* shift last retreg bit into retreg */\n+\n+/* Handle the cases where divisor is a small constant or has high bit on.  */\n+LSYM(special_divisor)\n+/*\tblr\targ1,r0 */\n+/*\tcomib,>,n  0,arg1,LREF(big_divisor) ; nullify previous instruction */\n+\n+/* Pratap 8/13/90. The 815 Stirling chip set has a bug that prevents us from\n+   generating such a blr, comib sequence. A problem in nullification. So I\n+   rewrote this code.  */\n+\n+#if defined(pa64)\n+/* Clear the upper 32 bits of the arg1 register.  We are working with\n+   small divisors (and 32 bit unsigned integers)   We must not be mislead\n+   by \"1\" bits left in the upper 32 bits.  */\n+\tdepd r0,31,32,arg1\n+#endif\n+\tcomib,>\t0,arg1,LREF(big_divisor)\n+\tnop\n+\tblr\targ1,r0\n+\tnop\n+\n+LSYM(zero_divisor)\t/* this label is here to provide external visibility */\n+\taddit,=\t0,arg1,0\t\t/* trap for zero dvr */\n+\tnop\n+\tMILLIRET\t\t\t/* divisor == 1 */\n+\tcopy\targ0,retreg\n+\tMILLIRET\t\t\t/* divisor == 2 */\n+\textru\targ0,30,31,retreg\n+\tMILLI_BEN($$divU_3)\t\t/* divisor == 3 */\n+\tnop\n+\tMILLIRET\t\t\t/* divisor == 4 */\n+\textru\targ0,29,30,retreg\n+\tMILLI_BEN($$divU_5)\t\t/* divisor == 5 */\n+\tnop\n+\tMILLI_BEN($$divU_6)\t\t/* divisor == 6 */\n+\tnop\n+\tMILLI_BEN($$divU_7)\t\t/* divisor == 7 */\n+\tnop\n+\tMILLIRET\t\t\t/* divisor == 8 */\n+\textru\targ0,28,29,retreg\n+\tMILLI_BEN($$divU_9)\t\t/* divisor == 9 */\n+\tnop\n+\tMILLI_BEN($$divU_10)\t\t/* divisor == 10 */\n+\tnop\n+\tb\tLREF(normal)\t\t/* divisor == 11 */\n+\tds\tr0,temp,r0\t\t/* set V-bit to 1 */\n+\tMILLI_BEN($$divU_12)\t\t/* divisor == 12 */\n+\tnop\n+\tb\tLREF(normal)\t\t/* divisor == 13 */\n+\tds\tr0,temp,r0\t\t/* set V-bit to 1 */\n+\tMILLI_BEN($$divU_14)\t\t/* divisor == 14 */\n+\tnop\n+\tMILLI_BEN($$divU_15)\t\t/* divisor == 15 */\n+\tnop\n+\n+/* Handle the case where the high bit is on in the divisor.\n+   Compute:\tif( dividend>=divisor) quotient=1; else quotient=0;\n+   Note:\tdividend>==divisor iff dividend-divisor does not borrow\n+   and\t\tnot borrow iff carry.  */\n+LSYM(big_divisor)\n+\tsub\targ0,arg1,r0\n+\tMILLIRET\n+\taddc\tr0,r0,retreg\n+\t.exit\n+\t.procend\n+\t.end\n+#endif\n+\n+#ifdef L_remI\n+/* ROUTINE:\t$$remI\n+\n+   DESCRIPTION:\n+   .\t$$remI returns the remainder of the division of two signed 32-bit\n+   .\tintegers.  The sign of the remainder is the same as the sign of\n+   .\tthe dividend.\n+\n+\n+   INPUT REGISTERS:\n+   .\targ0 == dividend\n+   .\targ1 == divisor\n+   .\tmrp  == return pc\n+   .\tsr0  == return space when called externally\n+\n+   OUTPUT REGISTERS:\n+   .\targ0 = destroyed\n+   .\targ1 = destroyed\n+   .\tret1 = remainder\n+\n+   OTHER REGISTERS AFFECTED:\n+   .\tr1   = undefined\n+\n+   SIDE EFFECTS:\n+   .\tCauses a trap under the following conditions:  DIVIDE BY ZERO\n+   .\tChanges memory at the following places:  NONE\n+\n+   PERMISSIBLE CONTEXT:\n+   .\tUnwindable\n+   .\tDoes not create a stack frame\n+   .\tIs usable for internal or external microcode\n+\n+   DISCUSSION:\n+   .\tCalls other millicode routines via mrp:  NONE\n+   .\tCalls other millicode routines:  NONE  */\n+\n+RDEFINE(tmp,r1)\n+RDEFINE(retreg,ret1)\n+\n+\tSUBSPA_MILLI\n+\tATTR_MILLI\n+\t.proc\n+\t.callinfo millicode\n+\t.entry\n+GSYM($$remI)\n+GSYM($$remoI)\n+\t.export $$remI,MILLICODE\n+\t.export $$remoI,MILLICODE\n+\tldo\t\t-1(arg1),tmp\t\t/*  is there at most one bit set ? */\n+\tand,<>\t\targ1,tmp,r0\t\t/*  if not, don't use power of 2 */\n+\taddi,>\t\t0,arg1,r0\t\t/*  if denominator > 0, use power */\n+\t\t\t\t\t\t/*  of 2 */\n+\tb,n\t\tLREF(neg_denom)\n+LSYM(pow2)\n+\tcomb,>,n\t0,arg0,LREF(neg_num)\t/*  is numerator < 0 ? */\n+\tand\t\targ0,tmp,retreg\t\t/*  get the result */\n+\tMILLIRETN\n+LSYM(neg_num)\n+\tsubi\t\t0,arg0,arg0\t\t/*  negate numerator */\n+\tand\t\targ0,tmp,retreg\t\t/*  get the result */\n+\tsubi\t\t0,retreg,retreg\t\t/*  negate result */\n+\tMILLIRETN\n+LSYM(neg_denom)\n+\taddi,<\t\t0,arg1,r0\t\t/*  if arg1 >= 0, it's not power */\n+\t\t\t\t\t\t/*  of 2 */\n+\tb,n\t\tLREF(regular_seq)\n+\tsub\t\tr0,arg1,tmp\t\t/*  make denominator positive */\n+\tcomb,=,n\targ1,tmp,LREF(regular_seq) /*  test against 0x80000000 and 0 */\n+\tldo\t\t-1(tmp),retreg\t\t/*  is there at most one bit set ? */\n+\tand,=\t\ttmp,retreg,r0\t\t/*  if not, go to regular_seq */\n+\tb,n\t\tLREF(regular_seq)\n+\tcomb,>,n\t0,arg0,LREF(neg_num_2)\t/*  if arg0 < 0, negate it  */\n+\tand\t\targ0,retreg,retreg\n+\tMILLIRETN\n+LSYM(neg_num_2)\n+\tsubi\t\t0,arg0,tmp\t\t/*  test against 0x80000000 */\n+\tand\t\ttmp,retreg,retreg\n+\tsubi\t\t0,retreg,retreg\n+\tMILLIRETN\n+LSYM(regular_seq)\n+\taddit,=\t\t0,arg1,0\t\t/*  trap if div by zero */\n+\tadd,>=\t\t0,arg0,retreg\t\t/*  move dividend, if retreg < 0, */\n+\tsub\t\t0,retreg,retreg\t\t/*    make it positive */\n+\tsub\t\t0,arg1, tmp\t\t/*  clear carry,  */\n+\t\t\t\t\t\t/*    negate the divisor */\n+\tds\t\t0, tmp,0\t\t/*  set V-bit to the comple- */\n+\t\t\t\t\t\t/*    ment of the divisor sign */\n+\tor\t\t0,0, tmp\t\t/*  clear  tmp */\n+\tadd\t\tretreg,retreg,retreg\t/*  shift msb bit into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  1st divide step, if no carry */\n+\t\t\t\t\t\t/*    out, msb of quotient = 0 */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+LSYM(t1)\n+\tds\t\t tmp,arg1, tmp\t\t/*  2nd divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  3rd divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  4th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  5th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  6th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  7th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  8th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  9th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  10th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  11th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  12th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  13th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  14th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  15th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  16th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  17th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  18th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  19th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  20th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  21st divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  22nd divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  23rd divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  24th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  25th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  26th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  27th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  28th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  29th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  30th divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  31st divide step */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift retreg with/into carry */\n+\tds\t\t tmp,arg1, tmp\t\t/*  32nd divide step, */\n+\taddc\t\tretreg,retreg,retreg\t/*  shift last bit into retreg */\n+\tmovb,>=,n\t tmp,retreg,LREF(finish) /*  branch if pos.  tmp */\n+\tadd,<\t\targ1,0,0\t\t/*  if arg1 > 0, add arg1 */\n+\tadd,tr\t\t tmp,arg1,retreg\t/*    for correcting remainder tmp */\n+\tsub\t\t tmp,arg1,retreg\t/*  else add absolute value arg1 */\n+LSYM(finish)\n+\tadd,>=\t\targ0,0,0\t\t/*  set sign of remainder */\n+\tsub\t\t0,retreg,retreg\t\t/*    to sign of dividend */\n+\tMILLIRET\n+\tnop\n+\t.exit\n+\t.procend\n+#ifdef milliext\n+\t.origin 0x00000200\n+#endif\n+\t.end\n+#endif\n+\n+#ifdef L_remU\n+/* ROUTINE:\t$$remU\n+   .\tSingle precision divide for remainder with unsigned binary integers.\n+   .\n+   .\tThe remainder must be dividend-(dividend/divisor)*divisor.\n+   .\tDivide by zero is trapped.\n+\n+   INPUT REGISTERS:\n+   .\targ0 ==\tdividend\n+   .\targ1 == divisor\n+   .\tmrp  == return pc\n+   .\tsr0  == return space when called externally\n+\n+   OUTPUT REGISTERS:\n+   .\targ0 =\tundefined\n+   .\targ1 =\tundefined\n+   .\tret1 =\tremainder\n+\n+   OTHER REGISTERS AFFECTED:\n+   .\tr1   =\tundefined\n+\n+   SIDE EFFECTS:\n+   .\tCauses a trap under the following conditions:  DIVIDE BY ZERO\n+   .\tChanges memory at the following places:  NONE\n+\n+   PERMISSIBLE CONTEXT:\n+   .\tUnwindable.\n+   .\tDoes not create a stack frame.\n+   .\tSuitable for internal or external millicode.\n+   .\tAssumes the special millicode register conventions.\n+\n+   DISCUSSION:\n+   .\tCalls other millicode routines using mrp: NONE\n+   .\tCalls other millicode routines: NONE  */\n+\n+\n+RDEFINE(temp,r1)\n+RDEFINE(rmndr,ret1)\t/*  r29 */\n+\tSUBSPA_MILLI\n+\tATTR_MILLI\n+\t.export $$remU,millicode\n+\t.proc\n+\t.callinfo\tmillicode\n+\t.entry\n+GSYM($$remU)\n+\tldo\t-1(arg1),temp\t\t/*  is there at most one bit set ? */\n+\tand,=\targ1,temp,r0\t\t/*  if not, don't use power of 2 */\n+\tb\tLREF(regular_seq)\n+\taddit,=\t0,arg1,r0\t\t/*  trap on div by zero */\n+\tand\targ0,temp,rmndr\t\t/*  get the result for power of 2 */\n+\tMILLIRETN\n+LSYM(regular_seq)\n+\tcomib,>=,n  0,arg1,LREF(special_case)\n+\tsubi\t0,arg1,rmndr\t\t/*  clear carry, negate the divisor */\n+\tds\tr0,rmndr,r0\t\t/*  set V-bit to 1 */\n+\tadd\targ0,arg0,temp\t\t/*  shift msb bit into carry */\n+\tds\tr0,arg1,rmndr\t\t/*  1st divide step, if no carry */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  2nd divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  3rd divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  4th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  5th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  6th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  7th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  8th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  9th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  10th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  11th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  12th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  13th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  14th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  15th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  16th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  17th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  18th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  19th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  20th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  21st divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  22nd divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  23rd divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  24th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  25th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  26th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  27th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  28th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  29th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  30th divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  31st divide step */\n+\taddc\ttemp,temp,temp\t\t/*  shift temp with/into carry */\n+\tds\trmndr,arg1,rmndr\t\t/*  32nd divide step, */\n+\tcomiclr,<= 0,rmndr,r0\n+\t  add\trmndr,arg1,rmndr\t/*  correction */\n+\tMILLIRETN\n+\tnop\n+\n+/* Putting >= on the last DS and deleting COMICLR does not work!  */\n+LSYM(special_case)\n+\tsub,>>=\targ0,arg1,rmndr\n+\t  copy\targ0,rmndr\n+\tMILLIRETN\n+\tnop\n+\t.exit\n+\t.procend\n+\t.end\n+#endif\n+\n+#ifdef L_div_const\n+/* ROUTINE:\t$$divI_2\n+   .\t\t$$divI_3\t$$divU_3\n+   .\t\t$$divI_4\n+   .\t\t$$divI_5\t$$divU_5\n+   .\t\t$$divI_6\t$$divU_6\n+   .\t\t$$divI_7\t$$divU_7\n+   .\t\t$$divI_8\n+   .\t\t$$divI_9\t$$divU_9\n+   .\t\t$$divI_10\t$$divU_10\n+   .\n+   .\t\t$$divI_12\t$$divU_12\n+   .\n+   .\t\t$$divI_14\t$$divU_14\n+   .\t\t$$divI_15\t$$divU_15\n+   .\t\t$$divI_16\n+   .\t\t$$divI_17\t$$divU_17\n+   .\n+   .\tDivide by selected constants for single precision binary integers.\n+\n+   INPUT REGISTERS:\n+   .\targ0 ==\tdividend\n+   .\tmrp  == return pc\n+   .\tsr0  == return space when called externally\n+\n+   OUTPUT REGISTERS:\n+   .\targ0 =\tundefined\n+   .\targ1 =\tundefined\n+   .\tret1 =\tquotient\n+\n+   OTHER REGISTERS AFFECTED:\n+   .\tr1   =\tundefined\n+\n+   SIDE EFFECTS:\n+   .\tCauses a trap under the following conditions: NONE\n+   .\tChanges memory at the following places:  NONE\n+\n+   PERMISSIBLE CONTEXT:\n+   .\tUnwindable.\n+   .\tDoes not create a stack frame.\n+   .\tSuitable for internal or external millicode.\n+   .\tAssumes the special millicode register conventions.\n+\n+   DISCUSSION:\n+   .\tCalls other millicode routines using mrp:  NONE\n+   .\tCalls other millicode routines:  NONE  */\n+\n+\n+/* TRUNCATED DIVISION BY SMALL INTEGERS\n+\n+   We are interested in q(x) = floor(x/y), where x >= 0 and y > 0\n+   (with y fixed).\n+\n+   Let a = floor(z/y), for some choice of z.  Note that z will be\n+   chosen so that division by z is cheap.\n+\n+   Let r be the remainder(z/y).  In other words, r = z - ay.\n+\n+   Now, our method is to choose a value for b such that\n+\n+   q'(x) = floor((ax+b)/z)\n+\n+   is equal to q(x) over as large a range of x as possible.  If the\n+   two are equal over a sufficiently large range, and if it is easy to\n+   form the product (ax), and it is easy to divide by z, then we can\n+   perform the division much faster than the general division algorithm.\n+\n+   So, we want the following to be true:\n+\n+   .\tFor x in the following range:\n+   .\n+   .\t    ky <= x < (k+1)y\n+   .\n+   .\timplies that\n+   .\n+   .\t    k <= (ax+b)/z < (k+1)\n+\n+   We want to determine b such that this is true for all k in the\n+   range {0..K} for some maximum K.\n+\n+   Since (ax+b) is an increasing function of x, we can take each\n+   bound separately to determine the \"best\" value for b.\n+\n+   (ax+b)/z < (k+1)\t       implies\n+\n+   (a((k+1)y-1)+b < (k+1)z     implies\n+\n+   b < a + (k+1)(z-ay)\t       implies\n+\n+   b < a + (k+1)r\n+\n+   This needs to be true for all k in the range {0..K}.  In\n+   particular, it is true for k = 0 and this leads to a maximum\n+   acceptable value for b.\n+\n+   b < a+r   or   b <= a+r-1\n+\n+   Taking the other bound, we have\n+\n+   k <= (ax+b)/z\t       implies\n+\n+   k <= (aky+b)/z\t       implies\n+\n+   k(z-ay) <= b\t\t       implies\n+\n+   kr <= b\n+\n+   Clearly, the largest range for k will be achieved by maximizing b,\n+   when r is not zero.\tWhen r is zero, then the simplest choice for b\n+   is 0.  When r is not 0, set\n+\n+   .\tb = a+r-1\n+\n+   Now, by construction, q'(x) = floor((ax+b)/z) = q(x) = floor(x/y)\n+   for all x in the range:\n+\n+   .\t0 <= x < (K+1)y\n+\n+   We need to determine what K is.  Of our two bounds,\n+\n+   .\tb < a+(k+1)r\tis satisfied for all k >= 0, by construction.\n+\n+   The other bound is\n+\n+   .\tkr <= b\n+\n+   This is always true if r = 0.  If r is not 0 (the usual case), then\n+   K = floor((a+r-1)/r), is the maximum value for k.\n+\n+   Therefore, the formula q'(x) = floor((ax+b)/z) yields the correct\n+   answer for q(x) = floor(x/y) when x is in the range\n+\n+   (0,(K+1)y-1)\t       K = floor((a+r-1)/r)\n+\n+   To be most useful, we want (K+1)y-1 = (max x) >= 2**32-1 so that\n+   the formula for q'(x) yields the correct value of q(x) for all x\n+   representable by a single word in HPPA.\n+\n+   We are also constrained in that computing the product (ax), adding\n+   b, and dividing by z must all be done quickly, otherwise we will be\n+   better off going through the general algorithm using the DS\n+   instruction, which uses approximately 70 cycles.\n+\n+   For each y, there is a choice of z which satisfies the constraints\n+   for (K+1)y >= 2**32.  We may not, however, be able to satisfy the\n+   timing constraints for arbitrary y.\tIt seems that z being equal to\n+   a power of 2 or a power of 2 minus 1 is as good as we can do, since\n+   it minimizes the time to do division by z.  We want the choice of z\n+   to also result in a value for (a) that minimizes the computation of\n+   the product (ax).  This is best achieved if (a) has a regular bit\n+   pattern (so the multiplication can be done with shifts and adds).\n+   The value of (a) also needs to be less than 2**32 so the product is\n+   always guaranteed to fit in 2 words.\n+\n+   In actual practice, the following should be done:\n+\n+   1) For negative x, you should take the absolute value and remember\n+   .  the fact so that the result can be negated.  This obviously does\n+   .  not apply in the unsigned case.\n+   2) For even y, you should factor out the power of 2 that divides y\n+   .  and divide x by it.  You can then proceed by dividing by the\n+   .  odd factor of y.\n+\n+   Here is a table of some odd values of y, and corresponding choices\n+   for z which are \"good\".\n+\n+    y\t  z\t  r\t a (hex)     max x (hex)\n+\n+    3\t2**32\t  1\t55555555      100000001\n+    5\t2**32\t  1\t33333333      100000003\n+    7  2**24-1\t  0\t  249249     (infinite)\n+    9  2**24-1\t  0\t  1c71c7     (infinite)\n+   11  2**20-1\t  0\t   1745d     (infinite)\n+   13  2**24-1\t  0\t  13b13b     (infinite)\n+   15\t2**32\t  1\t11111111      10000000d\n+   17\t2**32\t  1\t f0f0f0f      10000000f\n+\n+   If r is 1, then b = a+r-1 = a.  This simplifies the computation\n+   of (ax+b), since you can compute (x+1)(a) instead.  If r is 0,\n+   then b = 0 is ok to use which simplifies (ax+b).\n+\n+   The bit patterns for 55555555, 33333333, and 11111111 are obviously\n+   very regular.  The bit patterns for the other values of a above are:\n+\n+    y\t   (hex)\t  (binary)\n+\n+    7\t  249249  001001001001001001001001  << regular >>\n+    9\t  1c71c7  000111000111000111000111  << regular >>\n+   11\t   1745d  000000010111010001011101  << irregular >>\n+   13\t  13b13b  000100111011000100111011  << irregular >>\n+\n+   The bit patterns for (a) corresponding to (y) of 11 and 13 may be\n+   too irregular to warrant using this method.\n+\n+   When z is a power of 2 minus 1, then the division by z is slightly\n+   more complicated, involving an iterative solution.\n+\n+   The code presented here solves division by 1 through 17, except for\n+   11 and 13. There are algorithms for both signed and unsigned\n+   quantities given.\n+\n+   TIMINGS (cycles)\n+\n+   divisor  positive  negative\tunsigned\n+\n+   .   1\t2\t   2\t     2\n+   .   2\t4\t   4\t     2\n+   .   3       19\t  21\t    19\n+   .   4\t4\t   4\t     2\n+   .   5       18\t  22\t    19\n+   .   6       19\t  22\t    19\n+   .   8\t4\t   4\t     2\n+   .  10       18\t  19\t    17\n+   .  12       18\t  20\t    18\n+   .  15       16\t  18\t    16\n+   .  16\t4\t   4\t     2\n+   .  17       16\t  18\t    16\n+\n+   Now, the algorithm for 7, 9, and 14 is an iterative one.  That is,\n+   a loop body is executed until the tentative quotient is 0.  The\n+   number of times the loop body is executed varies depending on the\n+   dividend, but is never more than two times.\tIf the dividend is\n+   less than the divisor, then the loop body is not executed at all.\n+   Each iteration adds 4 cycles to the timings.\n+\n+   divisor  positive  negative\tunsigned\n+\n+   .   7       19+4n\t 20+4n\t   20+4n    n = number of iterations\n+   .   9       21+4n\t 22+4n\t   21+4n\n+   .  14       21+4n\t 22+4n\t   20+4n\n+\n+   To give an idea of how the number of iterations varies, here is a\n+   table of dividend versus number of iterations when dividing by 7.\n+\n+   smallest\t largest       required\n+   dividend\tdividend      iterations\n+\n+   .\t0\t     6\t\t    0\n+   .\t7\t 0x6ffffff\t    1\n+   0x1000006\t0xffffffff\t    2\n+\n+   There is some overlap in the range of numbers requiring 1 and 2\n+   iterations.\t*/\n+\n+RDEFINE(t2,r1)\n+RDEFINE(x2,arg0)\t/*  r26 */\n+RDEFINE(t1,arg1)\t/*  r25 */\n+RDEFINE(x1,ret1)\t/*  r29 */\n+\n+\tSUBSPA_MILLI_DIV\n+\tATTR_MILLI\n+\n+\t.proc\n+\t.callinfo\tmillicode\n+\t.entry\n+/* NONE of these routines require a stack frame\n+   ALL of these routines are unwindable from millicode\t*/\n+\n+GSYM($$divide_by_constant)\n+\t.export $$divide_by_constant,millicode\n+/*  Provides a \"nice\" label for the code covered by the unwind descriptor\n+    for things like gprof.  */\n+\n+/* DIVISION BY 2 (shift by 1) */\n+GSYM($$divI_2)\n+\t.export\t\t$$divI_2,millicode\n+\tcomclr,>=\targ0,0,0\n+\taddi\t\t1,arg0,arg0\n+\tMILLIRET\n+\textrs\t\targ0,30,31,ret1\n+\n+\n+/* DIVISION BY 4 (shift by 2) */\n+GSYM($$divI_4)\n+\t.export\t\t$$divI_4,millicode\n+\tcomclr,>=\targ0,0,0\n+\taddi\t\t3,arg0,arg0\n+\tMILLIRET\n+\textrs\t\targ0,29,30,ret1\n+\n+\n+/* DIVISION BY 8 (shift by 3) */\n+GSYM($$divI_8)\n+\t.export\t\t$$divI_8,millicode\n+\tcomclr,>=\targ0,0,0\n+\taddi\t\t7,arg0,arg0\n+\tMILLIRET\n+\textrs\t\targ0,28,29,ret1\n+\n+/* DIVISION BY 16 (shift by 4) */\n+GSYM($$divI_16)\n+\t.export\t\t$$divI_16,millicode\n+\tcomclr,>=\targ0,0,0\n+\taddi\t\t15,arg0,arg0\n+\tMILLIRET\n+\textrs\t\targ0,27,28,ret1\n+\n+/****************************************************************************\n+*\n+*\tDIVISION BY DIVISORS OF FFFFFFFF, and powers of 2 times these\n+*\n+*\tincludes 3,5,15,17 and also 6,10,12\n+*\n+****************************************************************************/\n+\n+/* DIVISION BY 3 (use z = 2**32; a = 55555555) */\n+\n+GSYM($$divI_3)\n+\t.export\t\t$$divI_3,millicode\n+\tcomb,<,N\tx2,0,LREF(neg3)\n+\n+\taddi\t\t1,x2,x2\t\t/* this can not overflow\t*/\n+\textru\t\tx2,1,2,x1\t/* multiply by 5 to get started */\n+\tsh2add\t\tx2,x2,x2\n+\tb\t\tLREF(pos)\n+\taddc\t\tx1,0,x1\n+\n+LSYM(neg3)\n+\tsubi\t\t1,x2,x2\t\t/* this can not overflow\t*/\n+\textru\t\tx2,1,2,x1\t/* multiply by 5 to get started */\n+\tsh2add\t\tx2,x2,x2\n+\tb\t\tLREF(neg)\n+\taddc\t\tx1,0,x1\n+\n+GSYM($$divU_3)\n+\t.export\t\t$$divU_3,millicode\n+\taddi\t\t1,x2,x2\t\t/* this CAN overflow */\n+\taddc\t\t0,0,x1\n+\tshd\t\tx1,x2,30,t1\t/* multiply by 5 to get started */\n+\tsh2add\t\tx2,x2,x2\n+\tb\t\tLREF(pos)\n+\taddc\t\tx1,t1,x1\n+\n+/* DIVISION BY 5 (use z = 2**32; a = 33333333) */\n+\n+GSYM($$divI_5)\n+\t.export\t\t$$divI_5,millicode\n+\tcomb,<,N\tx2,0,LREF(neg5)\n+\n+\taddi\t\t3,x2,t1\t\t/* this can not overflow\t*/\n+\tsh1add\t\tx2,t1,x2\t/* multiply by 3 to get started */\n+\tb\t\tLREF(pos)\n+\taddc\t\t0,0,x1\n+\n+LSYM(neg5)\n+\tsub\t\t0,x2,x2\t\t/* negate x2\t\t\t*/\n+\taddi\t\t1,x2,x2\t\t/* this can not overflow\t*/\n+\tshd\t\t0,x2,31,x1\t/* get top bit (can be 1)\t*/\n+\tsh1add\t\tx2,x2,x2\t/* multiply by 3 to get started */\n+\tb\t\tLREF(neg)\n+\taddc\t\tx1,0,x1\n+\n+GSYM($$divU_5)\n+\t.export\t\t$$divU_5,millicode\n+\taddi\t\t1,x2,x2\t\t/* this CAN overflow */\n+\taddc\t\t0,0,x1\n+\tshd\t\tx1,x2,31,t1\t/* multiply by 3 to get started */\n+\tsh1add\t\tx2,x2,x2\n+\tb\t\tLREF(pos)\n+\taddc\t\tt1,x1,x1\n+\n+/* DIVISION BY\t6 (shift to divide by 2 then divide by 3) */\n+GSYM($$divI_6)\n+\t.export\t\t$$divI_6,millicode\n+\tcomb,<,N\tx2,0,LREF(neg6)\n+\textru\t\tx2,30,31,x2\t/* divide by 2\t\t\t*/\n+\taddi\t\t5,x2,t1\t\t/* compute 5*(x2+1) = 5*x2+5\t*/\n+\tsh2add\t\tx2,t1,x2\t/* multiply by 5 to get started */\n+\tb\t\tLREF(pos)\n+\taddc\t\t0,0,x1\n+\n+LSYM(neg6)\n+\tsubi\t\t2,x2,x2\t\t/* negate, divide by 2, and add 1 */\n+\t\t\t\t\t/* negation and adding 1 are done */\n+\t\t\t\t\t/* at the same time by the SUBI   */\n+\textru\t\tx2,30,31,x2\n+\tshd\t\t0,x2,30,x1\n+\tsh2add\t\tx2,x2,x2\t/* multiply by 5 to get started */\n+\tb\t\tLREF(neg)\n+\taddc\t\tx1,0,x1\n+\n+GSYM($$divU_6)\n+\t.export\t\t$$divU_6,millicode\n+\textru\t\tx2,30,31,x2\t/* divide by 2 */\n+\taddi\t\t1,x2,x2\t\t/* can not carry */\n+\tshd\t\t0,x2,30,x1\t/* multiply by 5 to get started */\n+\tsh2add\t\tx2,x2,x2\n+\tb\t\tLREF(pos)\n+\taddc\t\tx1,0,x1\n+\n+/* DIVISION BY 10 (shift to divide by 2 then divide by 5) */\n+GSYM($$divU_10)\n+\t.export\t\t$$divU_10,millicode\n+\textru\t\tx2,30,31,x2\t/* divide by 2 */\n+\taddi\t\t3,x2,t1\t\t/* compute 3*(x2+1) = (3*x2)+3\t*/\n+\tsh1add\t\tx2,t1,x2\t/* multiply by 3 to get started */\n+\taddc\t\t0,0,x1\n+LSYM(pos)\n+\tshd\t\tx1,x2,28,t1\t/* multiply by 0x11 */\n+\tshd\t\tx2,0,28,t2\n+\tadd\t\tx2,t2,x2\n+\taddc\t\tx1,t1,x1\n+LSYM(pos_for_17)\n+\tshd\t\tx1,x2,24,t1\t/* multiply by 0x101 */\n+\tshd\t\tx2,0,24,t2\n+\tadd\t\tx2,t2,x2\n+\taddc\t\tx1,t1,x1\n+\n+\tshd\t\tx1,x2,16,t1\t/* multiply by 0x10001 */\n+\tshd\t\tx2,0,16,t2\n+\tadd\t\tx2,t2,x2\n+\tMILLIRET\n+\taddc\t\tx1,t1,x1\n+\n+GSYM($$divI_10)\n+\t.export\t\t$$divI_10,millicode\n+\tcomb,<\t\tx2,0,LREF(neg10)\n+\tcopy\t\t0,x1\n+\textru\t\tx2,30,31,x2\t/* divide by 2 */\n+\taddib,TR\t1,x2,LREF(pos)\t/* add 1 (can not overflow)     */\n+\tsh1add\t\tx2,x2,x2\t/* multiply by 3 to get started */\n+\n+LSYM(neg10)\n+\tsubi\t\t2,x2,x2\t\t/* negate, divide by 2, and add 1 */\n+\t\t\t\t\t/* negation and adding 1 are done */\n+\t\t\t\t\t/* at the same time by the SUBI   */\n+\textru\t\tx2,30,31,x2\n+\tsh1add\t\tx2,x2,x2\t/* multiply by 3 to get started */\n+LSYM(neg)\n+\tshd\t\tx1,x2,28,t1\t/* multiply by 0x11 */\n+\tshd\t\tx2,0,28,t2\n+\tadd\t\tx2,t2,x2\n+\taddc\t\tx1,t1,x1\n+LSYM(neg_for_17)\n+\tshd\t\tx1,x2,24,t1\t/* multiply by 0x101 */\n+\tshd\t\tx2,0,24,t2\n+\tadd\t\tx2,t2,x2\n+\taddc\t\tx1,t1,x1\n+\n+\tshd\t\tx1,x2,16,t1\t/* multiply by 0x10001 */\n+\tshd\t\tx2,0,16,t2\n+\tadd\t\tx2,t2,x2\n+\taddc\t\tx1,t1,x1\n+\tMILLIRET\n+\tsub\t\t0,x1,x1\n+\n+/* DIVISION BY 12 (shift to divide by 4 then divide by 3) */\n+GSYM($$divI_12)\n+\t.export\t\t$$divI_12,millicode\n+\tcomb,<\t\tx2,0,LREF(neg12)\n+\tcopy\t\t0,x1\n+\textru\t\tx2,29,30,x2\t/* divide by 4\t\t\t*/\n+\taddib,tr\t1,x2,LREF(pos)\t/* compute 5*(x2+1) = 5*x2+5    */\n+\tsh2add\t\tx2,x2,x2\t/* multiply by 5 to get started */\n+\n+LSYM(neg12)\n+\tsubi\t\t4,x2,x2\t\t/* negate, divide by 4, and add 1 */\n+\t\t\t\t\t/* negation and adding 1 are done */\n+\t\t\t\t\t/* at the same time by the SUBI   */\n+\textru\t\tx2,29,30,x2\n+\tb\t\tLREF(neg)\n+\tsh2add\t\tx2,x2,x2\t/* multiply by 5 to get started */\n+\n+GSYM($$divU_12)\n+\t.export\t\t$$divU_12,millicode\n+\textru\t\tx2,29,30,x2\t/* divide by 4   */\n+\taddi\t\t5,x2,t1\t\t/* can not carry */\n+\tsh2add\t\tx2,t1,x2\t/* multiply by 5 to get started */\n+\tb\t\tLREF(pos)\n+\taddc\t\t0,0,x1\n+\n+/* DIVISION BY 15 (use z = 2**32; a = 11111111) */\n+GSYM($$divI_15)\n+\t.export\t\t$$divI_15,millicode\n+\tcomb,<\t\tx2,0,LREF(neg15)\n+\tcopy\t\t0,x1\n+\taddib,tr\t1,x2,LREF(pos)+4\n+\tshd\t\tx1,x2,28,t1\n+\n+LSYM(neg15)\n+\tb\t\tLREF(neg)\n+\tsubi\t\t1,x2,x2\n+\n+GSYM($$divU_15)\n+\t.export\t\t$$divU_15,millicode\n+\taddi\t\t1,x2,x2\t\t/* this CAN overflow */\n+\tb\t\tLREF(pos)\n+\taddc\t\t0,0,x1\n+\n+/* DIVISION BY 17 (use z = 2**32; a =  f0f0f0f) */\n+GSYM($$divI_17)\n+\t.export\t\t$$divI_17,millicode\n+\tcomb,<,n\tx2,0,LREF(neg17)\n+\taddi\t\t1,x2,x2\t\t/* this can not overflow */\n+\tshd\t\t0,x2,28,t1\t/* multiply by 0xf to get started */\n+\tshd\t\tx2,0,28,t2\n+\tsub\t\tt2,x2,x2\n+\tb\t\tLREF(pos_for_17)\n+\tsubb\t\tt1,0,x1\n+\n+LSYM(neg17)\n+\tsubi\t\t1,x2,x2\t\t/* this can not overflow */\n+\tshd\t\t0,x2,28,t1\t/* multiply by 0xf to get started */\n+\tshd\t\tx2,0,28,t2\n+\tsub\t\tt2,x2,x2\n+\tb\t\tLREF(neg_for_17)\n+\tsubb\t\tt1,0,x1\n+\n+GSYM($$divU_17)\n+\t.export\t\t$$divU_17,millicode\n+\taddi\t\t1,x2,x2\t\t/* this CAN overflow */\n+\taddc\t\t0,0,x1\n+\tshd\t\tx1,x2,28,t1\t/* multiply by 0xf to get started */\n+LSYM(u17)\n+\tshd\t\tx2,0,28,t2\n+\tsub\t\tt2,x2,x2\n+\tb\t\tLREF(pos_for_17)\n+\tsubb\t\tt1,x1,x1\n+\n+\n+/* DIVISION BY DIVISORS OF FFFFFF, and powers of 2 times these\n+   includes 7,9 and also 14\n+\n+\n+   z = 2**24-1\n+   r = z mod x = 0\n+\n+   so choose b = 0\n+\n+   Also, in order to divide by z = 2**24-1, we approximate by dividing\n+   by (z+1) = 2**24 (which is easy), and then correcting.\n+\n+   (ax) = (z+1)q' + r\n+   .\t= zq' + (q'+r)\n+\n+   So to compute (ax)/z, compute q' = (ax)/(z+1) and r = (ax) mod (z+1)\n+   Then the true remainder of (ax)/z is (q'+r).  Repeat the process\n+   with this new remainder, adding the tentative quotients together,\n+   until a tentative quotient is 0 (and then we are done).  There is\n+   one last correction to be done.  It is possible that (q'+r) = z.\n+   If so, then (q'+r)/(z+1) = 0 and it looks like we are done.\tBut,\n+   in fact, we need to add 1 more to the quotient.  Now, it turns\n+   out that this happens if and only if the original value x is\n+   an exact multiple of y.  So, to avoid a three instruction test at\n+   the end, instead use 1 instruction to add 1 to x at the beginning.  */\n+\n+/* DIVISION BY 7 (use z = 2**24-1; a = 249249) */\n+GSYM($$divI_7)\n+\t.export\t\t$$divI_7,millicode\n+\tcomb,<,n\tx2,0,LREF(neg7)\n+LSYM(7)\n+\taddi\t\t1,x2,x2\t\t/* can not overflow */\n+\tshd\t\t0,x2,29,x1\n+\tsh3add\t\tx2,x2,x2\n+\taddc\t\tx1,0,x1\n+LSYM(pos7)\n+\tshd\t\tx1,x2,26,t1\n+\tshd\t\tx2,0,26,t2\n+\tadd\t\tx2,t2,x2\n+\taddc\t\tx1,t1,x1\n+\n+\tshd\t\tx1,x2,20,t1\n+\tshd\t\tx2,0,20,t2\n+\tadd\t\tx2,t2,x2\n+\taddc\t\tx1,t1,t1\n+\n+\t/* computed <t1,x2>.  Now divide it by (2**24 - 1)\t*/\n+\n+\tcopy\t\t0,x1\n+\tshd,=\t\tt1,x2,24,t1\t/* tentative quotient  */\n+LSYM(1)\n+\taddb,tr\t\tt1,x1,LREF(2)\t/* add to previous quotient   */\n+\textru\t\tx2,31,24,x2\t/* new remainder (unadjusted) */\n+\n+\tMILLIRETN\n+\n+LSYM(2)\n+\taddb,tr\t\tt1,x2,LREF(1)\t/* adjust remainder */\n+\textru,=\t\tx2,7,8,t1\t/* new quotient     */\n+\n+LSYM(neg7)\n+\tsubi\t\t1,x2,x2\t\t/* negate x2 and add 1 */\n+LSYM(8)\n+\tshd\t\t0,x2,29,x1\n+\tsh3add\t\tx2,x2,x2\n+\taddc\t\tx1,0,x1\n+\n+LSYM(neg7_shift)\n+\tshd\t\tx1,x2,26,t1\n+\tshd\t\tx2,0,26,t2\n+\tadd\t\tx2,t2,x2\n+\taddc\t\tx1,t1,x1\n+\n+\tshd\t\tx1,x2,20,t1\n+\tshd\t\tx2,0,20,t2\n+\tadd\t\tx2,t2,x2\n+\taddc\t\tx1,t1,t1\n+\n+\t/* computed <t1,x2>.  Now divide it by (2**24 - 1)\t*/\n+\n+\tcopy\t\t0,x1\n+\tshd,=\t\tt1,x2,24,t1\t/* tentative quotient  */\n+LSYM(3)\n+\taddb,tr\t\tt1,x1,LREF(4)\t/* add to previous quotient   */\n+\textru\t\tx2,31,24,x2\t/* new remainder (unadjusted) */\n+\n+\tMILLIRET\n+\tsub\t\t0,x1,x1\t\t/* negate result    */\n+\n+LSYM(4)\n+\taddb,tr\t\tt1,x2,LREF(3)\t/* adjust remainder */\n+\textru,=\t\tx2,7,8,t1\t/* new quotient     */\n+\n+GSYM($$divU_7)\n+\t.export\t\t$$divU_7,millicode\n+\taddi\t\t1,x2,x2\t\t/* can carry */\n+\taddc\t\t0,0,x1\n+\tshd\t\tx1,x2,29,t1\n+\tsh3add\t\tx2,x2,x2\n+\tb\t\tLREF(pos7)\n+\taddc\t\tt1,x1,x1\n+\n+/* DIVISION BY 9 (use z = 2**24-1; a = 1c71c7) */\n+GSYM($$divI_9)\n+\t.export\t\t$$divI_9,millicode\n+\tcomb,<,n\tx2,0,LREF(neg9)\n+\taddi\t\t1,x2,x2\t\t/* can not overflow */\n+\tshd\t\t0,x2,29,t1\n+\tshd\t\tx2,0,29,t2\n+\tsub\t\tt2,x2,x2\n+\tb\t\tLREF(pos7)\n+\tsubb\t\tt1,0,x1\n+\n+LSYM(neg9)\n+\tsubi\t\t1,x2,x2\t\t/* negate and add 1 */\n+\tshd\t\t0,x2,29,t1\n+\tshd\t\tx2,0,29,t2\n+\tsub\t\tt2,x2,x2\n+\tb\t\tLREF(neg7_shift)\n+\tsubb\t\tt1,0,x1\n+\n+GSYM($$divU_9)\n+\t.export\t\t$$divU_9,millicode\n+\taddi\t\t1,x2,x2\t\t/* can carry */\n+\taddc\t\t0,0,x1\n+\tshd\t\tx1,x2,29,t1\n+\tshd\t\tx2,0,29,t2\n+\tsub\t\tt2,x2,x2\n+\tb\t\tLREF(pos7)\n+\tsubb\t\tt1,x1,x1\n+\n+/* DIVISION BY 14 (shift to divide by 2 then divide by 7) */\n+GSYM($$divI_14)\n+\t.export\t\t$$divI_14,millicode\n+\tcomb,<,n\tx2,0,LREF(neg14)\n+GSYM($$divU_14)\n+\t.export\t\t$$divU_14,millicode\n+\tb\t\tLREF(7)\t\t/* go to 7 case */\n+\textru\t\tx2,30,31,x2\t/* divide by 2  */\n+\n+LSYM(neg14)\n+\tsubi\t\t2,x2,x2\t\t/* negate (and add 2) */\n+\tb\t\tLREF(8)\n+\textru\t\tx2,30,31,x2\t/* divide by 2\t      */\n+\t.exit\n+\t.procend\n+\t.end\n+#endif\n+\n+#ifdef L_mulI\n+/* VERSION \"@(#)$$mulI $ Revision: 12.4 $ $ Date: 94/03/17 17:18:51 $\" */\n+/******************************************************************************\n+This routine is used on PA2.0 processors when gcc -mno-fpregs is used\n+\n+ROUTINE:\t$$mulI\n+\n+\n+DESCRIPTION:\t\n+\n+\t$$mulI multiplies two single word integers, giving a single \n+\tword result.  \n+\n+\n+INPUT REGISTERS:\n+\n+\targ0 = Operand 1\n+\targ1 = Operand 2\n+\tr31  == return pc\n+\tsr0  == return space when called externally \n+\n+\n+OUTPUT REGISTERS:\n+\n+\targ0 = undefined\n+\targ1 = undefined\n+\tret1 = result \n+\n+OTHER REGISTERS AFFECTED:\n+\n+\tr1   = undefined\n+\n+SIDE EFFECTS:\n+\n+\tCauses a trap under the following conditions:  NONE\n+\tChanges memory at the following places:  NONE\n+\n+PERMISSIBLE CONTEXT:\n+\n+\tUnwindable\n+\tDoes not create a stack frame\n+\tIs usable for internal or external microcode\n+\n+DISCUSSION:\n+\n+\tCalls other millicode routines via mrp:  NONE\n+\tCalls other millicode routines:  NONE\n+\n+***************************************************************************/\n+\n+\n+#define\ta0\t%arg0\n+#define\ta1\t%arg1\n+#define\tt0\t%r1\n+#define\tr\t%ret1\n+\n+#define\ta0__128a0\tzdep\ta0,24,25,a0\n+#define\ta0__256a0\tzdep\ta0,23,24,a0\n+#define\ta1_ne_0_b_l0\tcomb,<>\ta1,0,LREF(l0)\n+#define\ta1_ne_0_b_l1\tcomb,<>\ta1,0,LREF(l1)\n+#define\ta1_ne_0_b_l2\tcomb,<>\ta1,0,LREF(l2)\n+#define\tb_n_ret_t0\tb,n\tLREF(ret_t0)\n+#define\tb_e_shift\tb\tLREF(e_shift)\n+#define\tb_e_t0ma0\tb\tLREF(e_t0ma0)\n+#define\tb_e_t0\t\tb\tLREF(e_t0)\n+#define\tb_e_t0a0\tb\tLREF(e_t0a0)\n+#define\tb_e_t02a0\tb\tLREF(e_t02a0)\n+#define\tb_e_t04a0\tb\tLREF(e_t04a0)\n+#define\tb_e_2t0\t\tb\tLREF(e_2t0)\n+#define\tb_e_2t0a0\tb\tLREF(e_2t0a0)\n+#define\tb_e_2t04a0\tb\tLREF(e2t04a0)\n+#define\tb_e_3t0\t\tb\tLREF(e_3t0)\n+#define\tb_e_4t0\t\tb\tLREF(e_4t0)\n+#define\tb_e_4t0a0\tb\tLREF(e_4t0a0)\n+#define\tb_e_4t08a0\tb\tLREF(e4t08a0)\n+#define\tb_e_5t0\t\tb\tLREF(e_5t0)\n+#define\tb_e_8t0\t\tb\tLREF(e_8t0)\n+#define\tb_e_8t0a0\tb\tLREF(e_8t0a0)\n+#define\tr__r_a0\t\tadd\tr,a0,r\n+#define\tr__r_2a0\tsh1add\ta0,r,r\n+#define\tr__r_4a0\tsh2add\ta0,r,r\n+#define\tr__r_8a0\tsh3add\ta0,r,r\n+#define\tr__r_t0\t\tadd\tr,t0,r\n+#define\tr__r_2t0\tsh1add\tt0,r,r\n+#define\tr__r_4t0\tsh2add\tt0,r,r\n+#define\tr__r_8t0\tsh3add\tt0,r,r\n+#define\tt0__3a0\t\tsh1add\ta0,a0,t0\n+#define\tt0__4a0\t\tsh2add\ta0,0,t0\n+#define\tt0__5a0\t\tsh2add\ta0,a0,t0\n+#define\tt0__8a0\t\tsh3add\ta0,0,t0\n+#define\tt0__9a0\t\tsh3add\ta0,a0,t0\n+#define\tt0__16a0\tzdep\ta0,27,28,t0\n+#define\tt0__32a0\tzdep\ta0,26,27,t0\n+#define\tt0__64a0\tzdep\ta0,25,26,t0\n+#define\tt0__128a0\tzdep\ta0,24,25,t0\n+#define\tt0__t0ma0\tsub\tt0,a0,t0\n+#define\tt0__t0_a0\tadd\tt0,a0,t0\n+#define\tt0__t0_2a0\tsh1add\ta0,t0,t0\n+#define\tt0__t0_4a0\tsh2add\ta0,t0,t0\n+#define\tt0__t0_8a0\tsh3add\ta0,t0,t0\n+#define\tt0__2t0_a0\tsh1add\tt0,a0,t0\n+#define\tt0__3t0\t\tsh1add\tt0,t0,t0\n+#define\tt0__4t0\t\tsh2add\tt0,0,t0\n+#define\tt0__4t0_a0\tsh2add\tt0,a0,t0\n+#define\tt0__5t0\t\tsh2add\tt0,t0,t0\n+#define\tt0__8t0\t\tsh3add\tt0,0,t0\n+#define\tt0__8t0_a0\tsh3add\tt0,a0,t0\n+#define\tt0__9t0\t\tsh3add\tt0,t0,t0\n+#define\tt0__16t0\tzdep\tt0,27,28,t0\n+#define\tt0__32t0\tzdep\tt0,26,27,t0\n+#define\tt0__256a0\tzdep\ta0,23,24,t0\n+\n+\n+\tSUBSPA_MILLI\n+\tATTR_MILLI\n+\t.align 16\n+\t.proc\n+\t.callinfo millicode\n+\t.export $$mulI, millicode\n+GSYM($$mulI)\t\n+\tcombt,<<=\ta1,a0,LREF(l4)\t/* swap args if unsigned a1>a0 */\n+\tcopy\t\t0,r\t\t/* zero out the result */\n+\txor\t\ta0,a1,a0\t/* swap a0 & a1 using the */\n+\txor\t\ta0,a1,a1\t/*  old xor trick */\n+\txor\t\ta0,a1,a0\n+LSYM(l4)\n+\tcombt,<=\t0,a0,LREF(l3)\t\t/* if a0>=0 then proceed like unsigned */\n+\tzdep\t\ta1,30,8,t0\t/* t0 = (a1&0xff)<<1 ********* */\n+\tsub,>\t\t0,a1,t0\t\t/* otherwise negate both and */\n+\tcombt,<=,n\ta0,t0,LREF(l2)\t/*  swap back if |a0|<|a1| */\n+\tsub\t\t0,a0,a1\n+\tmovb,tr,n\tt0,a0,LREF(l2)\t/* 10th inst. */\n+\n+LSYM(l0)\tr__r_t0\t\t\t\t/* add in this partial product */\n+LSYM(l1)\ta0__256a0\t\t\t/* a0 <<= 8 ****************** */\n+LSYM(l2)\tzdep\t\ta1,30,8,t0\t/* t0 = (a1&0xff)<<1 ********* */\n+LSYM(l3)\tblr\t\tt0,0\t\t/* case on these 8 bits ****** */\n+\t\textru\t\ta1,23,24,a1\t/* a1 >>= 8 ****************** */\n+\n+/*16 insts before this. */\n+/*\t\t\t  a0 <<= 8 ************************** */\n+LSYM(x0)\ta1_ne_0_b_l2\t! a0__256a0\t! MILLIRETN\t! nop\n+LSYM(x1)\ta1_ne_0_b_l1\t! r__r_a0\t! MILLIRETN\t! nop\n+LSYM(x2)\ta1_ne_0_b_l1\t! r__r_2a0\t! MILLIRETN\t! nop\n+LSYM(x3)\ta1_ne_0_b_l0\t! t0__3a0\t! MILLIRET\t! r__r_t0\n+LSYM(x4)\ta1_ne_0_b_l1\t! r__r_4a0\t! MILLIRETN\t! nop\n+LSYM(x5)\ta1_ne_0_b_l0\t! t0__5a0\t! MILLIRET\t! r__r_t0\n+LSYM(x6)\tt0__3a0\t\t! a1_ne_0_b_l1\t! r__r_2t0\t! MILLIRETN\n+LSYM(x7)\tt0__3a0\t\t! a1_ne_0_b_l0\t! r__r_4a0\t! b_n_ret_t0\n+LSYM(x8)\ta1_ne_0_b_l1\t! r__r_8a0\t! MILLIRETN\t! nop\n+LSYM(x9)\ta1_ne_0_b_l0\t! t0__9a0\t! MILLIRET\t! r__r_t0\n+LSYM(x10)\tt0__5a0\t\t! a1_ne_0_b_l1\t! r__r_2t0\t! MILLIRETN\n+LSYM(x11)\tt0__3a0\t\t! a1_ne_0_b_l0\t! r__r_8a0\t! b_n_ret_t0\n+LSYM(x12)\tt0__3a0\t\t! a1_ne_0_b_l1\t! r__r_4t0\t! MILLIRETN\n+LSYM(x13)\tt0__5a0\t\t! a1_ne_0_b_l0\t! r__r_8a0\t! b_n_ret_t0\n+LSYM(x14)\tt0__3a0\t\t! t0__2t0_a0\t! b_e_shift\t! r__r_2t0\n+LSYM(x15)\tt0__5a0\t\t! a1_ne_0_b_l0\t! t0__3t0\t! b_n_ret_t0\n+LSYM(x16)\tt0__16a0\t! a1_ne_0_b_l1\t! r__r_t0\t! MILLIRETN\n+LSYM(x17)\tt0__9a0\t\t! a1_ne_0_b_l0\t! t0__t0_8a0\t! b_n_ret_t0\n+LSYM(x18)\tt0__9a0\t\t! a1_ne_0_b_l1\t! r__r_2t0\t! MILLIRETN\n+LSYM(x19)\tt0__9a0\t\t! a1_ne_0_b_l0\t! t0__2t0_a0\t! b_n_ret_t0\n+LSYM(x20)\tt0__5a0\t\t! a1_ne_0_b_l1\t! r__r_4t0\t! MILLIRETN\n+LSYM(x21)\tt0__5a0\t\t! a1_ne_0_b_l0\t! t0__4t0_a0\t! b_n_ret_t0\n+LSYM(x22)\tt0__5a0\t\t! t0__2t0_a0\t! b_e_shift\t! r__r_2t0\n+LSYM(x23)\tt0__5a0\t\t! t0__2t0_a0\t! b_e_t0\t! t0__2t0_a0\n+LSYM(x24)\tt0__3a0\t\t! a1_ne_0_b_l1\t! r__r_8t0\t! MILLIRETN\n+LSYM(x25)\tt0__5a0\t\t! a1_ne_0_b_l0\t! t0__5t0\t! b_n_ret_t0\n+LSYM(x26)\tt0__3a0\t\t! t0__4t0_a0\t! b_e_shift\t! r__r_2t0\n+LSYM(x27)\tt0__3a0\t\t! a1_ne_0_b_l0\t! t0__9t0\t! b_n_ret_t0\n+LSYM(x28)\tt0__3a0\t\t! t0__2t0_a0\t! b_e_shift\t! r__r_4t0\n+LSYM(x29)\tt0__3a0\t\t! t0__2t0_a0\t! b_e_t0\t! t0__4t0_a0\n+LSYM(x30)\tt0__5a0\t\t! t0__3t0\t! b_e_shift\t! r__r_2t0\n+LSYM(x31)\tt0__32a0\t! a1_ne_0_b_l0\t! t0__t0ma0\t! b_n_ret_t0\n+LSYM(x32)\tt0__32a0\t! a1_ne_0_b_l1\t! r__r_t0\t! MILLIRETN\n+LSYM(x33)\tt0__8a0\t\t! a1_ne_0_b_l0\t! t0__4t0_a0\t! b_n_ret_t0\n+LSYM(x34)\tt0__16a0\t! t0__t0_a0\t! b_e_shift\t! r__r_2t0\n+LSYM(x35)\tt0__9a0\t\t! t0__3t0\t! b_e_t0\t! t0__t0_8a0\n+LSYM(x36)\tt0__9a0\t\t! a1_ne_0_b_l1\t! r__r_4t0\t! MILLIRETN\n+LSYM(x37)\tt0__9a0\t\t! a1_ne_0_b_l0\t! t0__4t0_a0\t! b_n_ret_t0\n+LSYM(x38)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_shift\t! r__r_2t0\n+LSYM(x39)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_t0\t! t0__2t0_a0\n+LSYM(x40)\tt0__5a0\t\t! a1_ne_0_b_l1\t! r__r_8t0\t! MILLIRETN\n+LSYM(x41)\tt0__5a0\t\t! a1_ne_0_b_l0\t! t0__8t0_a0\t! b_n_ret_t0\n+LSYM(x42)\tt0__5a0\t\t! t0__4t0_a0\t! b_e_shift\t! r__r_2t0\n+LSYM(x43)\tt0__5a0\t\t! t0__4t0_a0\t! b_e_t0\t! t0__2t0_a0\n+LSYM(x44)\tt0__5a0\t\t! t0__2t0_a0\t! b_e_shift\t! r__r_4t0\n+LSYM(x45)\tt0__9a0\t\t! a1_ne_0_b_l0\t! t0__5t0\t! b_n_ret_t0\n+LSYM(x46)\tt0__9a0\t\t! t0__5t0\t! b_e_t0\t! t0__t0_a0\n+LSYM(x47)\tt0__9a0\t\t! t0__5t0\t! b_e_t0\t! t0__t0_2a0\n+LSYM(x48)\tt0__3a0\t\t! a1_ne_0_b_l0\t! t0__16t0\t! b_n_ret_t0\n+LSYM(x49)\tt0__9a0\t\t! t0__5t0\t! b_e_t0\t! t0__t0_4a0\n+LSYM(x50)\tt0__5a0\t\t! t0__5t0\t! b_e_shift\t! r__r_2t0\n+LSYM(x51)\tt0__9a0\t\t! t0__t0_8a0\t! b_e_t0\t! t0__3t0\n+LSYM(x52)\tt0__3a0\t\t! t0__4t0_a0\t! b_e_shift\t! r__r_4t0\n+LSYM(x53)\tt0__3a0\t\t! t0__4t0_a0\t! b_e_t0\t! t0__4t0_a0\n+LSYM(x54)\tt0__9a0\t\t! t0__3t0\t! b_e_shift\t! r__r_2t0\n+LSYM(x55)\tt0__9a0\t\t! t0__3t0\t! b_e_t0\t! t0__2t0_a0\n+LSYM(x56)\tt0__3a0\t\t! t0__2t0_a0\t! b_e_shift\t! r__r_8t0\n+LSYM(x57)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_t0\t! t0__3t0\n+LSYM(x58)\tt0__3a0\t\t! t0__2t0_a0\t! b_e_2t0\t! t0__4t0_a0\n+LSYM(x59)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_t02a0\t! t0__3t0\n+LSYM(x60)\tt0__5a0\t\t! t0__3t0\t! b_e_shift\t! r__r_4t0\n+LSYM(x61)\tt0__5a0\t\t! t0__3t0\t! b_e_t0\t! t0__4t0_a0\n+LSYM(x62)\tt0__32a0\t! t0__t0ma0\t! b_e_shift\t! r__r_2t0\n+LSYM(x63)\tt0__64a0\t! a1_ne_0_b_l0\t! t0__t0ma0\t! b_n_ret_t0\n+LSYM(x64)\tt0__64a0\t! a1_ne_0_b_l1\t! r__r_t0\t! MILLIRETN\n+LSYM(x65)\tt0__8a0\t\t! a1_ne_0_b_l0\t! t0__8t0_a0\t! b_n_ret_t0\n+LSYM(x66)\tt0__32a0\t! t0__t0_a0\t! b_e_shift\t! r__r_2t0\n+LSYM(x67)\tt0__8a0\t\t! t0__4t0_a0\t! b_e_t0\t! t0__2t0_a0\n+LSYM(x68)\tt0__8a0\t\t! t0__2t0_a0\t! b_e_shift\t! r__r_4t0\n+LSYM(x69)\tt0__8a0\t\t! t0__2t0_a0\t! b_e_t0\t! t0__4t0_a0\n+LSYM(x70)\tt0__64a0\t! t0__t0_4a0\t! b_e_t0\t! t0__t0_2a0\n+LSYM(x71)\tt0__9a0\t\t! t0__8t0\t! b_e_t0\t! t0__t0ma0\n+LSYM(x72)\tt0__9a0\t\t! a1_ne_0_b_l1\t! r__r_8t0\t! MILLIRETN\n+LSYM(x73)\tt0__9a0\t\t! t0__8t0_a0\t! b_e_shift\t! r__r_t0\n+LSYM(x74)\tt0__9a0\t\t! t0__4t0_a0\t! b_e_shift\t! r__r_2t0\n+LSYM(x75)\tt0__9a0\t\t! t0__4t0_a0\t! b_e_t0\t! t0__2t0_a0\n+LSYM(x76)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_shift\t! r__r_4t0\n+LSYM(x77)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_t0\t! t0__4t0_a0\n+LSYM(x78)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_2t0\t! t0__2t0_a0\n+LSYM(x79)\tt0__16a0\t! t0__5t0\t! b_e_t0\t! t0__t0ma0\n+LSYM(x80)\tt0__16a0\t! t0__5t0\t! b_e_shift\t! r__r_t0\n+LSYM(x81)\tt0__9a0\t\t! t0__9t0\t! b_e_shift\t! r__r_t0\n+LSYM(x82)\tt0__5a0\t\t! t0__8t0_a0\t! b_e_shift\t! r__r_2t0\n+LSYM(x83)\tt0__5a0\t\t! t0__8t0_a0\t! b_e_t0\t! t0__2t0_a0\n+LSYM(x84)\tt0__5a0\t\t! t0__4t0_a0\t! b_e_shift\t! r__r_4t0\n+LSYM(x85)\tt0__8a0\t\t! t0__2t0_a0\t! b_e_t0\t! t0__5t0\n+LSYM(x86)\tt0__5a0\t\t! t0__4t0_a0\t! b_e_2t0\t! t0__2t0_a0\n+LSYM(x87)\tt0__9a0\t\t! t0__9t0\t! b_e_t02a0\t! t0__t0_4a0\n+LSYM(x88)\tt0__5a0\t\t! t0__2t0_a0\t! b_e_shift\t! r__r_8t0\n+LSYM(x89)\tt0__5a0\t\t! t0__2t0_a0\t! b_e_t0\t! t0__8t0_a0\n+LSYM(x90)\tt0__9a0\t\t! t0__5t0\t! b_e_shift\t! r__r_2t0\n+LSYM(x91)\tt0__9a0\t\t! t0__5t0\t! b_e_t0\t! t0__2t0_a0\n+LSYM(x92)\tt0__5a0\t\t! t0__2t0_a0\t! b_e_4t0\t! t0__2t0_a0\n+LSYM(x93)\tt0__32a0\t! t0__t0ma0\t! b_e_t0\t! t0__3t0\n+LSYM(x94)\tt0__9a0\t\t! t0__5t0\t! b_e_2t0\t! t0__t0_2a0\n+LSYM(x95)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_t0\t! t0__5t0\n+LSYM(x96)\tt0__8a0\t\t! t0__3t0\t! b_e_shift\t! r__r_4t0\n+LSYM(x97)\tt0__8a0\t\t! t0__3t0\t! b_e_t0\t! t0__4t0_a0\n+LSYM(x98)\tt0__32a0\t! t0__3t0\t! b_e_t0\t! t0__t0_2a0\n+LSYM(x99)\tt0__8a0\t\t! t0__4t0_a0\t! b_e_t0\t! t0__3t0\n+LSYM(x100)\tt0__5a0\t\t! t0__5t0\t! b_e_shift\t! r__r_4t0\n+LSYM(x101)\tt0__5a0\t\t! t0__5t0\t! b_e_t0\t! t0__4t0_a0\n+LSYM(x102)\tt0__32a0\t! t0__t0_2a0\t! b_e_t0\t! t0__3t0\n+LSYM(x103)\tt0__5a0\t\t! t0__5t0\t! b_e_t02a0\t! t0__4t0_a0\n+LSYM(x104)\tt0__3a0\t\t! t0__4t0_a0\t! b_e_shift\t! r__r_8t0\n+LSYM(x105)\tt0__5a0\t\t! t0__4t0_a0\t! b_e_t0\t! t0__5t0\n+LSYM(x106)\tt0__3a0\t\t! t0__4t0_a0\t! b_e_2t0\t! t0__4t0_a0\n+LSYM(x107)\tt0__9a0\t\t! t0__t0_4a0\t! b_e_t02a0\t! t0__8t0_a0\n+LSYM(x108)\tt0__9a0\t\t! t0__3t0\t! b_e_shift\t! r__r_4t0\n+LSYM(x109)\tt0__9a0\t\t! t0__3t0\t! b_e_t0\t! t0__4t0_a0\n+LSYM(x110)\tt0__9a0\t\t! t0__3t0\t! b_e_2t0\t! t0__2t0_a0\n+LSYM(x111)\tt0__9a0\t\t! t0__4t0_a0\t! b_e_t0\t! t0__3t0\n+LSYM(x112)\tt0__3a0\t\t! t0__2t0_a0\t! b_e_t0\t! t0__16t0\n+LSYM(x113)\tt0__9a0\t\t! t0__4t0_a0\t! b_e_t02a0\t! t0__3t0\n+LSYM(x114)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_2t0\t! t0__3t0\n+LSYM(x115)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_2t0a0\t! t0__3t0\n+LSYM(x116)\tt0__3a0\t\t! t0__2t0_a0\t! b_e_4t0\t! t0__4t0_a0\n+LSYM(x117)\tt0__3a0\t\t! t0__4t0_a0\t! b_e_t0\t! t0__9t0\n+LSYM(x118)\tt0__3a0\t\t! t0__4t0_a0\t! b_e_t0a0\t! t0__9t0\n+LSYM(x119)\tt0__3a0\t\t! t0__4t0_a0\t! b_e_t02a0\t! t0__9t0\n+LSYM(x120)\tt0__5a0\t\t! t0__3t0\t! b_e_shift\t! r__r_8t0\n+LSYM(x121)\tt0__5a0\t\t! t0__3t0\t! b_e_t0\t! t0__8t0_a0\n+LSYM(x122)\tt0__5a0\t\t! t0__3t0\t! b_e_2t0\t! t0__4t0_a0\n+LSYM(x123)\tt0__5a0\t\t! t0__8t0_a0\t! b_e_t0\t! t0__3t0\n+LSYM(x124)\tt0__32a0\t! t0__t0ma0\t! b_e_shift\t! r__r_4t0\n+LSYM(x125)\tt0__5a0\t\t! t0__5t0\t! b_e_t0\t! t0__5t0\n+LSYM(x126)\tt0__64a0\t! t0__t0ma0\t! b_e_shift\t! r__r_2t0\n+LSYM(x127)\tt0__128a0\t! a1_ne_0_b_l0\t! t0__t0ma0\t! b_n_ret_t0\n+LSYM(x128)\tt0__128a0\t! a1_ne_0_b_l1\t! r__r_t0\t! MILLIRETN\n+LSYM(x129)\tt0__128a0\t! a1_ne_0_b_l0\t! t0__t0_a0\t! b_n_ret_t0\n+LSYM(x130)\tt0__64a0\t! t0__t0_a0\t! b_e_shift\t! r__r_2t0\n+LSYM(x131)\tt0__8a0\t\t! t0__8t0_a0\t! b_e_t0\t! t0__2t0_a0\n+LSYM(x132)\tt0__8a0\t\t! t0__4t0_a0\t! b_e_shift\t! r__r_4t0\n+LSYM(x133)\tt0__8a0\t\t! t0__4t0_a0\t! b_e_t0\t! t0__4t0_a0\n+LSYM(x134)\tt0__8a0\t\t! t0__4t0_a0\t! b_e_2t0\t! t0__2t0_a0\n+LSYM(x135)\tt0__9a0\t\t! t0__5t0\t! b_e_t0\t! t0__3t0\n+LSYM(x136)\tt0__8a0\t\t! t0__2t0_a0\t! b_e_shift\t! r__r_8t0\n+LSYM(x137)\tt0__8a0\t\t! t0__2t0_a0\t! b_e_t0\t! t0__8t0_a0\n+LSYM(x138)\tt0__8a0\t\t! t0__2t0_a0\t! b_e_2t0\t! t0__4t0_a0\n+LSYM(x139)\tt0__8a0\t\t! t0__2t0_a0\t! b_e_2t0a0\t! t0__4t0_a0\n+LSYM(x140)\tt0__3a0\t\t! t0__2t0_a0\t! b_e_4t0\t! t0__5t0\n+LSYM(x141)\tt0__8a0\t\t! t0__2t0_a0\t! b_e_4t0a0\t! t0__2t0_a0\n+LSYM(x142)\tt0__9a0\t\t! t0__8t0\t! b_e_2t0\t! t0__t0ma0\n+LSYM(x143)\tt0__16a0\t! t0__9t0\t! b_e_t0\t! t0__t0ma0\n+LSYM(x144)\tt0__9a0\t\t! t0__8t0\t! b_e_shift\t! r__r_2t0\n+LSYM(x145)\tt0__9a0\t\t! t0__8t0\t! b_e_t0\t! t0__2t0_a0\n+LSYM(x146)\tt0__9a0\t\t! t0__8t0_a0\t! b_e_shift\t! r__r_2t0\n+LSYM(x147)\tt0__9a0\t\t! t0__8t0_a0\t! b_e_t0\t! t0__2t0_a0\n+LSYM(x148)\tt0__9a0\t\t! t0__4t0_a0\t! b_e_shift\t! r__r_4t0\n+LSYM(x149)\tt0__9a0\t\t! t0__4t0_a0\t! b_e_t0\t! t0__4t0_a0\n+LSYM(x150)\tt0__9a0\t\t! t0__4t0_a0\t! b_e_2t0\t! t0__2t0_a0\n+LSYM(x151)\tt0__9a0\t\t! t0__4t0_a0\t! b_e_2t0a0\t! t0__2t0_a0\n+LSYM(x152)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_shift\t! r__r_8t0\n+LSYM(x153)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_t0\t! t0__8t0_a0\n+LSYM(x154)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_2t0\t! t0__4t0_a0\n+LSYM(x155)\tt0__32a0\t! t0__t0ma0\t! b_e_t0\t! t0__5t0\n+LSYM(x156)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_4t0\t! t0__2t0_a0\n+LSYM(x157)\tt0__32a0\t! t0__t0ma0\t! b_e_t02a0\t! t0__5t0\n+LSYM(x158)\tt0__16a0\t! t0__5t0\t! b_e_2t0\t! t0__t0ma0\n+LSYM(x159)\tt0__32a0\t! t0__5t0\t! b_e_t0\t! t0__t0ma0\n+LSYM(x160)\tt0__5a0\t\t! t0__4t0\t! b_e_shift\t! r__r_8t0\n+LSYM(x161)\tt0__8a0\t\t! t0__5t0\t! b_e_t0\t! t0__4t0_a0\n+LSYM(x162)\tt0__9a0\t\t! t0__9t0\t! b_e_shift\t! r__r_2t0\n+LSYM(x163)\tt0__9a0\t\t! t0__9t0\t! b_e_t0\t! t0__2t0_a0\n+LSYM(x164)\tt0__5a0\t\t! t0__8t0_a0\t! b_e_shift\t! r__r_4t0\n+LSYM(x165)\tt0__8a0\t\t! t0__4t0_a0\t! b_e_t0\t! t0__5t0\n+LSYM(x166)\tt0__5a0\t\t! t0__8t0_a0\t! b_e_2t0\t! t0__2t0_a0\n+LSYM(x167)\tt0__5a0\t\t! t0__8t0_a0\t! b_e_2t0a0\t! t0__2t0_a0\n+LSYM(x168)\tt0__5a0\t\t! t0__4t0_a0\t! b_e_shift\t! r__r_8t0\n+LSYM(x169)\tt0__5a0\t\t! t0__4t0_a0\t! b_e_t0\t! t0__8t0_a0\n+LSYM(x170)\tt0__32a0\t! t0__t0_2a0\t! b_e_t0\t! t0__5t0\n+LSYM(x171)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_t0\t! t0__9t0\n+LSYM(x172)\tt0__5a0\t\t! t0__4t0_a0\t! b_e_4t0\t! t0__2t0_a0\n+LSYM(x173)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_t02a0\t! t0__9t0\n+LSYM(x174)\tt0__32a0\t! t0__t0_2a0\t! b_e_t04a0\t! t0__5t0\n+LSYM(x175)\tt0__8a0\t\t! t0__2t0_a0\t! b_e_5t0\t! t0__2t0_a0\n+LSYM(x176)\tt0__5a0\t\t! t0__4t0_a0\t! b_e_8t0\t! t0__t0_a0\n+LSYM(x177)\tt0__5a0\t\t! t0__4t0_a0\t! b_e_8t0a0\t! t0__t0_a0\n+LSYM(x178)\tt0__5a0\t\t! t0__2t0_a0\t! b_e_2t0\t! t0__8t0_a0\n+LSYM(x179)\tt0__5a0\t\t! t0__2t0_a0\t! b_e_2t0a0\t! t0__8t0_a0\n+LSYM(x180)\tt0__9a0\t\t! t0__5t0\t! b_e_shift\t! r__r_4t0\n+LSYM(x181)\tt0__9a0\t\t! t0__5t0\t! b_e_t0\t! t0__4t0_a0\n+LSYM(x182)\tt0__9a0\t\t! t0__5t0\t! b_e_2t0\t! t0__2t0_a0\n+LSYM(x183)\tt0__9a0\t\t! t0__5t0\t! b_e_2t0a0\t! t0__2t0_a0\n+LSYM(x184)\tt0__5a0\t\t! t0__9t0\t! b_e_4t0\t! t0__t0_a0\n+LSYM(x185)\tt0__9a0\t\t! t0__4t0_a0\t! b_e_t0\t! t0__5t0\n+LSYM(x186)\tt0__32a0\t! t0__t0ma0\t! b_e_2t0\t! t0__3t0\n+LSYM(x187)\tt0__9a0\t\t! t0__4t0_a0\t! b_e_t02a0\t! t0__5t0\n+LSYM(x188)\tt0__9a0\t\t! t0__5t0\t! b_e_4t0\t! t0__t0_2a0\n+LSYM(x189)\tt0__5a0\t\t! t0__4t0_a0\t! b_e_t0\t! t0__9t0\n+LSYM(x190)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_2t0\t! t0__5t0\n+LSYM(x191)\tt0__64a0\t! t0__3t0\t! b_e_t0\t! t0__t0ma0\n+LSYM(x192)\tt0__8a0\t\t! t0__3t0\t! b_e_shift\t! r__r_8t0\n+LSYM(x193)\tt0__8a0\t\t! t0__3t0\t! b_e_t0\t! t0__8t0_a0\n+LSYM(x194)\tt0__8a0\t\t! t0__3t0\t! b_e_2t0\t! t0__4t0_a0\n+LSYM(x195)\tt0__8a0\t\t! t0__8t0_a0\t! b_e_t0\t! t0__3t0\n+LSYM(x196)\tt0__8a0\t\t! t0__3t0\t! b_e_4t0\t! t0__2t0_a0\n+LSYM(x197)\tt0__8a0\t\t! t0__3t0\t! b_e_4t0a0\t! t0__2t0_a0\n+LSYM(x198)\tt0__64a0\t! t0__t0_2a0\t! b_e_t0\t! t0__3t0\n+LSYM(x199)\tt0__8a0\t\t! t0__4t0_a0\t! b_e_2t0a0\t! t0__3t0\n+LSYM(x200)\tt0__5a0\t\t! t0__5t0\t! b_e_shift\t! r__r_8t0\n+LSYM(x201)\tt0__5a0\t\t! t0__5t0\t! b_e_t0\t! t0__8t0_a0\n+LSYM(x202)\tt0__5a0\t\t! t0__5t0\t! b_e_2t0\t! t0__4t0_a0\n+LSYM(x203)\tt0__5a0\t\t! t0__5t0\t! b_e_2t0a0\t! t0__4t0_a0\n+LSYM(x204)\tt0__8a0\t\t! t0__2t0_a0\t! b_e_4t0\t! t0__3t0\n+LSYM(x205)\tt0__5a0\t\t! t0__8t0_a0\t! b_e_t0\t! t0__5t0\n+LSYM(x206)\tt0__64a0\t! t0__t0_4a0\t! b_e_t02a0\t! t0__3t0\n+LSYM(x207)\tt0__8a0\t\t! t0__2t0_a0\t! b_e_3t0\t! t0__4t0_a0\n+LSYM(x208)\tt0__5a0\t\t! t0__5t0\t! b_e_8t0\t! t0__t0_a0\n+LSYM(x209)\tt0__5a0\t\t! t0__5t0\t! b_e_8t0a0\t! t0__t0_a0\n+LSYM(x210)\tt0__5a0\t\t! t0__4t0_a0\t! b_e_2t0\t! t0__5t0\n+LSYM(x211)\tt0__5a0\t\t! t0__4t0_a0\t! b_e_2t0a0\t! t0__5t0\n+LSYM(x212)\tt0__3a0\t\t! t0__4t0_a0\t! b_e_4t0\t! t0__4t0_a0\n+LSYM(x213)\tt0__3a0\t\t! t0__4t0_a0\t! b_e_4t0a0\t! t0__4t0_a0\n+LSYM(x214)\tt0__9a0\t\t! t0__t0_4a0\t! b_e_2t04a0\t! t0__8t0_a0\n+LSYM(x215)\tt0__5a0\t\t! t0__4t0_a0\t! b_e_5t0\t! t0__2t0_a0\n+LSYM(x216)\tt0__9a0\t\t! t0__3t0\t! b_e_shift\t! r__r_8t0\n+LSYM(x217)\tt0__9a0\t\t! t0__3t0\t! b_e_t0\t! t0__8t0_a0\n+LSYM(x218)\tt0__9a0\t\t! t0__3t0\t! b_e_2t0\t! t0__4t0_a0\n+LSYM(x219)\tt0__9a0\t\t! t0__8t0_a0\t! b_e_t0\t! t0__3t0\n+LSYM(x220)\tt0__3a0\t\t! t0__9t0\t! b_e_4t0\t! t0__2t0_a0\n+LSYM(x221)\tt0__3a0\t\t! t0__9t0\t! b_e_4t0a0\t! t0__2t0_a0\n+LSYM(x222)\tt0__9a0\t\t! t0__4t0_a0\t! b_e_2t0\t! t0__3t0\n+LSYM(x223)\tt0__9a0\t\t! t0__4t0_a0\t! b_e_2t0a0\t! t0__3t0\n+LSYM(x224)\tt0__9a0\t\t! t0__3t0\t! b_e_8t0\t! t0__t0_a0\n+LSYM(x225)\tt0__9a0\t\t! t0__5t0\t! b_e_t0\t! t0__5t0\n+LSYM(x226)\tt0__3a0\t\t! t0__2t0_a0\t! b_e_t02a0\t! t0__32t0\n+LSYM(x227)\tt0__9a0\t\t! t0__5t0\t! b_e_t02a0\t! t0__5t0\n+LSYM(x228)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_4t0\t! t0__3t0\n+LSYM(x229)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_4t0a0\t! t0__3t0\n+LSYM(x230)\tt0__9a0\t\t! t0__5t0\t! b_e_5t0\t! t0__t0_a0\n+LSYM(x231)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_3t0\t! t0__4t0_a0\n+LSYM(x232)\tt0__3a0\t\t! t0__2t0_a0\t! b_e_8t0\t! t0__4t0_a0\n+LSYM(x233)\tt0__3a0\t\t! t0__2t0_a0\t! b_e_8t0a0\t! t0__4t0_a0\n+LSYM(x234)\tt0__3a0\t\t! t0__4t0_a0\t! b_e_2t0\t! t0__9t0\n+LSYM(x235)\tt0__3a0\t\t! t0__4t0_a0\t! b_e_2t0a0\t! t0__9t0\n+LSYM(x236)\tt0__9a0\t\t! t0__2t0_a0\t! b_e_4t08a0\t! t0__3t0\n+LSYM(x237)\tt0__16a0\t! t0__5t0\t! b_e_3t0\t! t0__t0ma0\n+LSYM(x238)\tt0__3a0\t\t! t0__4t0_a0\t! b_e_2t04a0\t! t0__9t0\n+LSYM(x239)\tt0__16a0\t! t0__5t0\t! b_e_t0ma0\t! t0__3t0\n+LSYM(x240)\tt0__9a0\t\t! t0__t0_a0\t! b_e_8t0\t! t0__3t0\n+LSYM(x241)\tt0__9a0\t\t! t0__t0_a0\t! b_e_8t0a0\t! t0__3t0\n+LSYM(x242)\tt0__5a0\t\t! t0__3t0\t! b_e_2t0\t! t0__8t0_a0\n+LSYM(x243)\tt0__9a0\t\t! t0__9t0\t! b_e_t0\t! t0__3t0\n+LSYM(x244)\tt0__5a0\t\t! t0__3t0\t! b_e_4t0\t! t0__4t0_a0\n+LSYM(x245)\tt0__8a0\t\t! t0__3t0\t! b_e_5t0\t! t0__2t0_a0\n+LSYM(x246)\tt0__5a0\t\t! t0__8t0_a0\t! b_e_2t0\t! t0__3t0\n+LSYM(x247)\tt0__5a0\t\t! t0__8t0_a0\t! b_e_2t0a0\t! t0__3t0\n+LSYM(x248)\tt0__32a0\t! t0__t0ma0\t! b_e_shift\t! r__r_8t0\n+LSYM(x249)\tt0__32a0\t! t0__t0ma0\t! b_e_t0\t! t0__8t0_a0\n+LSYM(x250)\tt0__5a0\t\t! t0__5t0\t! b_e_2t0\t! t0__5t0\n+LSYM(x251)\tt0__5a0\t\t! t0__5t0\t! b_e_2t0a0\t! t0__5t0\n+LSYM(x252)\tt0__64a0\t! t0__t0ma0\t! b_e_shift\t! r__r_4t0\n+LSYM(x253)\tt0__64a0\t! t0__t0ma0\t! b_e_t0\t! t0__4t0_a0\n+LSYM(x254)\tt0__128a0\t! t0__t0ma0\t! b_e_shift\t! r__r_2t0\n+LSYM(x255)\tt0__256a0\t! a1_ne_0_b_l0\t! t0__t0ma0\t! b_n_ret_t0\n+/*1040 insts before this. */\n+LSYM(ret_t0)\tMILLIRET\n+LSYM(e_t0)\tr__r_t0\n+LSYM(e_shift)\ta1_ne_0_b_l2\n+\ta0__256a0\t/* a0 <<= 8 *********** */\n+\tMILLIRETN\n+LSYM(e_t0ma0)\ta1_ne_0_b_l0\n+\tt0__t0ma0\n+\tMILLIRET\n+\tr__r_t0\n+LSYM(e_t0a0)\ta1_ne_0_b_l0\n+\tt0__t0_a0\n+\tMILLIRET\n+\tr__r_t0\n+LSYM(e_t02a0)\ta1_ne_0_b_l0\n+\tt0__t0_2a0\n+\tMILLIRET\n+\tr__r_t0\n+LSYM(e_t04a0)\ta1_ne_0_b_l0\n+\tt0__t0_4a0\n+\tMILLIRET\n+\tr__r_t0\n+LSYM(e_2t0)\ta1_ne_0_b_l1\n+\tr__r_2t0\n+\tMILLIRETN\n+LSYM(e_2t0a0)\ta1_ne_0_b_l0\n+\tt0__2t0_a0\n+\tMILLIRET\n+\tr__r_t0\n+LSYM(e2t04a0)\tt0__t0_2a0\n+\ta1_ne_0_b_l1\n+\tr__r_2t0\n+\tMILLIRETN\n+LSYM(e_3t0)\ta1_ne_0_b_l0\n+\tt0__3t0\n+\tMILLIRET\n+\tr__r_t0\n+LSYM(e_4t0)\ta1_ne_0_b_l1\n+\tr__r_4t0\n+\tMILLIRETN\n+LSYM(e_4t0a0)\ta1_ne_0_b_l0\n+\tt0__4t0_a0\n+\tMILLIRET\n+\tr__r_t0\n+LSYM(e4t08a0)\tt0__t0_2a0\n+\ta1_ne_0_b_l1\n+\tr__r_4t0\n+\tMILLIRETN\n+LSYM(e_5t0)\ta1_ne_0_b_l0\n+\tt0__5t0\n+\tMILLIRET\n+\tr__r_t0\n+LSYM(e_8t0)\ta1_ne_0_b_l1\n+\tr__r_8t0\n+\tMILLIRETN\n+LSYM(e_8t0a0)\ta1_ne_0_b_l0\n+\tt0__8t0_a0\n+\tMILLIRET\n+\tr__r_t0\n+\n+\t.procend\n+\t.end\n+#endif"}, {"sha": "5e9b037dc0ebdde84a483daa6c4b3565dec95d46", "filename": "gcc/config/pa/t-linux", "status": "modified", "additions": 21, "deletions": 0, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48bd7758319408fa2878d23651f4846c4016fd19/gcc%2Fconfig%2Fpa%2Ft-linux", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48bd7758319408fa2878d23651f4846c4016fd19/gcc%2Fconfig%2Fpa%2Ft-linux", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fpa%2Ft-linux?ref=48bd7758319408fa2878d23651f4846c4016fd19", "patch": "@@ -1 +1,22 @@\n+LIBGCC1=libgcc1-asm.a\n+CROSS_LIBGCC1=libgcc1-asm.a\n+\n+#Plug millicode routines into libgcc.a  We want these on both native and\n+#cross compiles.\n+\n+LIB1ASMFUNCS =  _divI _divU _remI _remU _multiply \\\n+\t_divI_15 _divI_14 _divI_12 _divI_10 _divI_9 \\\n+\t_divI_7 _divI_6 _divI_5 _divI_3 \\\n+\t_divU_15 _divU_14 _divU_12 _divU_10 _divU_9 \\\n+\t_divU_7 _divU_6 _divU_5 _divU_3 _dyncall\n+\n+LIB1ASMSRC = pa/milli32.S\n+\n+# Compile crtbeginS.o and crtendS.o as PIC.\n+CRTSTUFF_T_CFLAGS_S = -fPIC\n+\n+# Compile libgcc2.a as PIC.\n+# This is also used when compiling libgcc1 if libgcc1 is the asm variety.\n+TARGET_LIBGCC2_CFLAGS = -fPIC -DELF=1 -DLINUX=1\n+\n ADA_CFLAGS=-mdisable-indexing"}, {"sha": "9ab751004260e0527c155a9f69819f04eb7cdc38", "filename": "gcc/config/pa/t-linux64", "status": "added", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48bd7758319408fa2878d23651f4846c4016fd19/gcc%2Fconfig%2Fpa%2Ft-linux64", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48bd7758319408fa2878d23651f4846c4016fd19/gcc%2Fconfig%2Fpa%2Ft-linux64", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fpa%2Ft-linux64?ref=48bd7758319408fa2878d23651f4846c4016fd19", "patch": "@@ -0,0 +1,17 @@\n+LIBGCC1=libgcc1-asm.a\n+CROSS_LIBGCC1=libgcc1-asm.a\n+\n+#Plug millicode routines into libgcc.a  We want these on both native and\n+#cross compiles.\n+\n+LIB1ASMFUNCS =  _divI _divU _remI _remU _div_const _mulI\n+\n+LIB1ASMSRC = pa/milli64.S\n+\n+# Compile crtbeginS.o and crtendS.o as PIC.\n+# Actually, hppa64 is always PIC but adding -fPIC does no harm.\n+CRTSTUFF_T_CFLAGS_S = -fPIC\n+\n+# Compile libgcc2.a as PIC.\n+# This is also used when compiling libgcc1 if libgcc1 is the asm variety.\n+TARGET_LIBGCC2_CFLAGS = -fPIC -Dpa64=1 -DELF=1"}, {"sha": "790b32c236c5fd8b544c97857b410bac9fd3b847", "filename": "gcc/config/pa/t-pa64", "status": "modified", "additions": 6, "deletions": 3, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/48bd7758319408fa2878d23651f4846c4016fd19/gcc%2Fconfig%2Fpa%2Ft-pa64", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/48bd7758319408fa2878d23651f4846c4016fd19/gcc%2Fconfig%2Fpa%2Ft-pa64", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fpa%2Ft-pa64?ref=48bd7758319408fa2878d23651f4846c4016fd19", "patch": "@@ -1,10 +1,13 @@\n LIBGCC1=libgcc1.null\n-CROSS_LIBGCC1=libgcc1.null\n+CROSS_LIBGCC1=libgcc1-asm.a\n+\n+LIB1ASMFUNCS =  _divI _divU _remI _remU _div_const\n+LIB1ASMSRC = pa/milli64.S\n+TARGET_LIBGCC2_CFLAGS = -fPIC -Dpa64=1 -DELF=1\n+\n ADA_CFLAGS=-mdisable-indexing\n LIB2FUNCS_EXTRA=quadlib.c\n \n-TARGET_LIBGCC2_CFLAGS = -fPIC\n-\n # We'll need this once .init sections are enabled on PA64.\n #EXTRA_PARTS = crtbegin.o crtend.o\n "}]}