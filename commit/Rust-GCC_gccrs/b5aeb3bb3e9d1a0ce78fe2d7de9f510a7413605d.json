{"sha": "b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YjVhZWIzYmIzZTlkMWEwY2U3OGZlMmQ3ZGU5ZjUxMGE3NDEzNjA1ZA==", "commit": {"author": {"name": "Ira Rosen", "email": "irar@il.ibm.com", "date": "2010-04-19T09:10:45Z"}, "committer": {"name": "Ira Rosen", "email": "irar@gcc.gnu.org", "date": "2010-04-19T09:10:45Z"}, "message": "re PR tree-optimization/37027 (SLP loop vectorization missing support for reductions)\n\n\n\tPR tree-optimization/37027\n\t* tree-vectorizer.h (struct _loop_vec_info): Add new field reductions \n\tand macro to access it.\n\t(vectorizable_reduction): Add argument.\n\t(vect_get_slp_defs): Likewise.\n\t* tree-vect-loop.c (vect_analyze_scalar_cycles_1): Collect reduction\n\tstatements for possible use in SLP.\n\t(new_loop_vec_info): Initialize LOOP_VINFO_REDUCTIONS.\n\t(destroy_loop_vec_info): Free LOOP_VINFO_REDUCTIONS.\n\t(vect_create_epilog_for_reduction): Handle SLP. Modify documentation,\n\tadd new argument.\n\t(vectorizable_reduction): Likewise.\n\t* tree-vect-stmts.c (vect_get_vec_defs): Update call to \n\tvect_get_slp_defs.\n\t(vectorizable_type_demotion, vectorizable_type_promotion,\n\tvectorizable_store): Likewise.\n\t(vect_analyze_stmt): Update call to vectorizable_reduction.\n\t(vect_transform_stmt): Likewise.\n\t* tree-vect-slp.c (vect_get_and_check_slp_defs): Handle reduction.\n\t(vect_build_slp_tree): Fix indentation. Check that there are no loads\n\tfrom different interleaving chains in same node.\n\t(vect_slp_rearrange_stmts): New function.\n\t(vect_supported_load_permutation_p): Allow load permutations for \n\treductions. Call vect_slp_rearrange_stmts() to rearrange statements\n\tinside SLP nodes if necessary.\n\t(vect_analyze_slp_instance): Handle reductions.\n\t(vect_analyze_slp): Try to build SLP instances originating from groups\n\tof reductions.\n\t(vect_detect_hybrid_slp_stmts): Skip reduction statements.\n\t(vect_get_constant_vectors): Create initial vectors for reductions\n\taccording to reduction code. Add new argument.\n\t(vect_get_slp_defs): Add new argument, pass it to \n\tvect_get_constant_vectors.\n\t(vect_schedule_slp_instance): Remove SLP tree root statements.\n\nFrom-SVN: r158506", "tree": {"sha": "3e32ed80e44c4287a38f498c1bd5e752b9a57b20", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/3e32ed80e44c4287a38f498c1bd5e752b9a57b20"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/comments", "author": {"login": "irar2", "id": 16818592, "node_id": "MDQ6VXNlcjE2ODE4NTky", "avatar_url": "https://avatars.githubusercontent.com/u/16818592?v=4", "gravatar_id": "", "url": "https://api.github.com/users/irar2", "html_url": "https://github.com/irar2", "followers_url": "https://api.github.com/users/irar2/followers", "following_url": "https://api.github.com/users/irar2/following{/other_user}", "gists_url": "https://api.github.com/users/irar2/gists{/gist_id}", "starred_url": "https://api.github.com/users/irar2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/irar2/subscriptions", "organizations_url": "https://api.github.com/users/irar2/orgs", "repos_url": "https://api.github.com/users/irar2/repos", "events_url": "https://api.github.com/users/irar2/events{/privacy}", "received_events_url": "https://api.github.com/users/irar2/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "5a2fa9e8bf068aaacb57627c058b0d5891763857", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5a2fa9e8bf068aaacb57627c058b0d5891763857", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5a2fa9e8bf068aaacb57627c058b0d5891763857"}], "stats": {"total": 1827, "additions": 1363, "deletions": 464}, "files": [{"sha": "98c80045f99dd5c67d64b3aaee286b64805f3fa7", "filename": "gcc/ChangeLog", "status": "modified", "additions": 37, "deletions": 0, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "patch": "@@ -1,3 +1,40 @@\n+2010-04-19 Ira Rosen <irar@il.ibm.com>\n+\n+\tPR tree-optimization/37027\n+\t* tree-vectorizer.h (struct _loop_vec_info): Add new field reductions \n+\tand macro to access it.\n+\t(vectorizable_reduction): Add argument.\n+\t(vect_get_slp_defs): Likewise.\n+\t* tree-vect-loop.c (vect_analyze_scalar_cycles_1): Collect reduction\n+\tstatements for possible use in SLP.\n+\t(new_loop_vec_info): Initialize LOOP_VINFO_REDUCTIONS.\n+\t(destroy_loop_vec_info): Free LOOP_VINFO_REDUCTIONS.\n+\t(vect_create_epilog_for_reduction): Handle SLP. Modify documentation,\n+\tadd new argument.\n+\t(vectorizable_reduction): Likewise.\n+\t* tree-vect-stmts.c (vect_get_vec_defs): Update call to \n+\tvect_get_slp_defs.\n+\t(vectorizable_type_demotion, vectorizable_type_promotion,\n+\tvectorizable_store): Likewise.\n+\t(vect_analyze_stmt): Update call to vectorizable_reduction.\n+\t(vect_transform_stmt): Likewise.\n+\t* tree-vect-slp.c (vect_get_and_check_slp_defs): Handle reduction.\n+\t(vect_build_slp_tree): Fix indentation. Check that there are no loads\n+\tfrom different interleaving chains in same node.\n+\t(vect_slp_rearrange_stmts): New function.\n+\t(vect_supported_load_permutation_p): Allow load permutations for \n+\treductions. Call vect_slp_rearrange_stmts() to rearrange statements\n+\tinside SLP nodes if necessary.\n+\t(vect_analyze_slp_instance): Handle reductions.\n+\t(vect_analyze_slp): Try to build SLP instances originating from groups\n+\tof reductions.\n+\t(vect_detect_hybrid_slp_stmts): Skip reduction statements.\n+\t(vect_get_constant_vectors): Create initial vectors for reductions\n+\taccording to reduction code. Add new argument.\n+\t(vect_get_slp_defs): Add new argument, pass it to \n+\tvect_get_constant_vectors.\n+\t(vect_schedule_slp_instance): Remove SLP tree root statements.\n+\n 2010-04-19  Jakub Jelinek  <jakub@redhat.com>\n \n \t* tree.h (ENUM_IS_SCOPED): Define."}, {"sha": "868ce20d31edacc4c1267735946be81186cee502", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 11, "deletions": 0, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "patch": "@@ -1,3 +1,14 @@\n+2010-04-19 Ira Rosen <irar@il.ibm.com>\n+\n+\tPR tree-optimization/37027\t\n+\t* lib/target-supports.exp \n+\t(check_effective_target_vect_widen_sum_hi_to_si_pattern): New.\n+\t* gcc.dg/vect/pr37027.c: New test.\n+\t* gcc.dg/vect/slp-reduc-1.c, gcc.dg/vect/slp-reduc-2.c, \n+\tgcc.dg/vect/slp-reduc-3.c, gcc.dg/vect/slp-reduc-4.c, \n+\tgcc.dg/vect/slp-reduc-5.c, gcc.dg/vect/slp-reduc-6.c, \n+\tgcc.dg/vect/vect-complex-6.c: Likewise.\t\n+\n 2010-04-19  Jakub Jelinek  <jakub@redhat.com>\n \n \t* g++.dg/debug/dwarf2/enum1.C: New test."}, {"sha": "dcfed348d110da345ed676054dc856efd6eaed22", "filename": "gcc/testsuite/gcc.dg/vect/pr37027.c", "status": "added", "additions": 37, "deletions": 0, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fpr37027.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fpr37027.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fpr37027.c?ref=b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "patch": "@@ -0,0 +1,37 @@\n+/* { dg-do compile } */\n+/* { dg-require-effective-target vect_int } */\n+\n+#include <stdarg.h>\n+\n+struct mystr\n+{\n+  int f1;\n+  int f2;\n+};\n+\n+struct mystr a[16];\n+struct mystr b[16];\n+int res1, res2;\n+\n+\n+void\n+foo (void)\n+{\n+  int i;\n+  int sum1;\n+  int sum2;\n+\n+  for (i = 0; i < 16; i++)\n+  {\n+    sum1 += a[i].f1 + b[i].f1;\n+    sum2 += a[i].f2 + b[i].f2;\n+  }\n+\n+  res1 = sum1;\n+  res2 = sum2;\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 1 \"vect\" { xfail vect_no_int_add } } } */\n+/* { dg-final { scan-tree-dump-times \"vectorizing stmts using SLP\" 1 \"vect\" { xfail vect_no_int_add } } } */\n+/* { dg-final { cleanup-tree-dump \"vect\" } } */\n+"}, {"sha": "95faba8e9d43345a1e22ea8cc5c65ca3f41dee01", "filename": "gcc/testsuite/gcc.dg/vect/slp-reduc-1.c", "status": "added", "additions": 49, "deletions": 0, "changes": 49, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-1.c?ref=b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "patch": "@@ -0,0 +1,49 @@\n+/* { dg-require-effective-target vect_int } */\n+\n+#include <stdarg.h>\n+#include <stdio.h>\n+#include \"tree-vect.h\"\n+\n+#define N 16\n+\n+unsigned int ub[N] = {0,3,6,9,12,15,18,21,24,27,30,33,36,39,42,45};\n+unsigned int uc[N] = {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15};\n+\n+/* Vectorization of reduction using loop-aware SLP.  */\n+\n+__attribute__ ((noinline))\n+int main1 (int n, int res0, int res1, int res2, int res3)\n+{\n+  int i;\n+  unsigned int udiff0 = 5, udiff1 = 10, udiff2 = 20, udiff3 = 30;\n+\n+  for (i = 0; i < n; i++) {\n+    udiff3 += (ub[4*i + 3] - uc[4*i + 3]);\n+    udiff2 += (ub[4*i + 2] - uc[4*i + 2]);\n+    udiff1 += (ub[4*i + 1] - uc[4*i + 1]);\n+    udiff0 += (ub[4*i] - uc[4*i]);\n+  }\n+\n+  /* Check results:  */\n+  if (udiff0 != res0\n+      || udiff1 != res1\n+      || udiff2 != res2\n+      || udiff3 != res3)\n+    abort ();\n+\n+  return 0;\n+}\n+\n+int main (void)\n+{\n+  check_vect ();\n+\n+  main1 (N/4, 53, 66, 84, 102);\n+  main1 (N/4 - 1, 29, 40, 56, 72);\n+  return 0;\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 1 \"vect\" { xfail vect_no_int_add } } } */\n+/* { dg-final { scan-tree-dump-times \"vectorizing stmts using SLP\" 1 \"vect\" { xfail vect_no_int_add } } } */\n+/* { dg-final { cleanup-tree-dump \"vect\" } } */\n+"}, {"sha": "cb59c8c07ea28e47f71178c56a6f7de36a38228a", "filename": "gcc/testsuite/gcc.dg/vect/slp-reduc-2.c", "status": "added", "additions": 44, "deletions": 0, "changes": 44, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-2.c?ref=b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "patch": "@@ -0,0 +1,44 @@\n+/* { dg-require-effective-target vect_int } */\n+\n+#include <stdarg.h>\n+#include <stdio.h>\n+#include \"tree-vect.h\"\n+\n+#define N 16\n+\n+unsigned int ub[N] = {0,3,6,9,12,15,18,21,24,27,30,33,36,39,42,45};\n+unsigned int uc[N] = {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15};\n+\n+/* Vectorization of reduction using loop-aware SLP (with unrolling).  */\n+\n+__attribute__ ((noinline))\n+int main1 (int n, int res0, int res1, int res2, int res3)\n+{\n+  int i;\n+  unsigned int udiff0 = 5, udiff1 = 10;\n+\n+  for (i = 0; i < n; i++) {\n+    udiff1 += (ub[2*i + 1] - uc[2*i + 1]);\n+    udiff0 += (ub[2*i] - uc[2*i]);\n+  }\n+\n+  /* Check results:  */\n+  if (udiff0 != res0\n+      || udiff1 != res1)\n+    abort ();\n+\n+  return 0;\n+}\n+\n+int main (void)\n+{\n+  check_vect ();\n+\n+  main1 (N/2, 117, 138, 84, 102);\n+  return 0;\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 1 \"vect\" { xfail vect_no_int_add } } } */\n+/* { dg-final { scan-tree-dump-times \"vectorizing stmts using SLP\" 1 \"vect\" { xfail vect_no_int_add } } } */\n+/* { dg-final { cleanup-tree-dump \"vect\" } } */\n+"}, {"sha": "3220d3912ba36fa353dcd8a5d327b29b48e51c6f", "filename": "gcc/testsuite/gcc.dg/vect/slp-reduc-3.c", "status": "added", "additions": 62, "deletions": 0, "changes": 62, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-3.c?ref=b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "patch": "@@ -0,0 +1,62 @@\n+/* { dg-require-effective-target vect_int } */\n+\n+#include <stdarg.h>\n+#include \"tree-vect.h\"\n+\n+#define N 64\n+\n+#define DOT1 21834 \n+#define DOT2 21876\n+\n+unsigned short X[N] __attribute__ ((__aligned__(__BIGGEST_ALIGNMENT__)));\n+unsigned short Y[N] __attribute__ ((__aligned__(__BIGGEST_ALIGNMENT__)));\n+\n+/* short->short->int dot product. \n+   Not detected as a dot-product pattern.\n+   Requires support for non-widneing multiplication and widening-summation.  \n+   Vectorized with loop-aware SLP. */\n+__attribute__ ((noinline)) unsigned int\n+foo1(int len, int *result1, int *result2) \n+{\n+  int i;\n+  unsigned int res1 = 10, res2 = 20;\n+  unsigned short prod;\n+\n+  for (i=0; i<len; i++) {\n+    prod = X[2*i] * Y[2*i];\n+    res1 += prod;\n+    prod = X[2*i+1] * Y[2*i+1];\n+    res2 += prod;\n+  }\n+\n+  *result1 = res1;\n+  *result2 = res2;\n+\n+  return 0;\n+}\n+\n+int main (void)\n+{\n+  unsigned int dot1, dot2;\n+  unsigned short i;\n+\n+  check_vect ();\n+\n+  for (i=0; i<N; i++) {\n+    X[i] = i;\n+    Y[i] = 64-i;\n+  }\n+\n+  foo1 (N/2, &dot1, &dot2);\n+\n+  if (dot1 != DOT1 || dot2 != DOT2)\n+    abort ();\n+\n+  return 0;\n+}\n+\n+/* The initialization loop in main also gets vectorized.  */\n+/* { dg-final { scan-tree-dump-times \"vect_recog_dot_prod_pattern: detected\" 1 \"vect\" { xfail *-*-* } } } */\n+/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 2 \"vect\" { target { vect_short_mult && vect_widen_sum_hi_to_si } } } } */ \n+/* { dg-final { scan-tree-dump-times \"vectorizing stmts using SLP\" 1 \"vect\" { xfail { vect_widen_sum_hi_to_si_pattern } } } } */\n+/* { dg-final { cleanup-tree-dump \"vect\" } } */"}, {"sha": "ad5b3ce07009dc518eb40202a497cd125dd9467c", "filename": "gcc/testsuite/gcc.dg/vect/slp-reduc-4.c", "status": "added", "additions": 60, "deletions": 0, "changes": 60, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-4.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-4.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-4.c?ref=b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "patch": "@@ -0,0 +1,60 @@\n+/* { dg-require-effective-target vect_int } */\n+\n+#include <stdarg.h>\n+#include <stdio.h>\n+#include \"tree-vect.h\"\n+\n+#define N 128 \n+\n+unsigned int uc[N];\n+\n+/* Vectorization of reduction using loop-aware SLP.  */\n+\n+__attribute__ ((noinline))\n+int main1 (int n, int res0, int res1, int res2, int res3, int res4, int res5, int res6, int res7)\n+{\n+  int i;\n+  unsigned int max0 = 5, max1 = 10, max2 = 20, max3 = 30, max4 = 2, max5 = 13, max6 = 7, max7 = 313;\n+\n+  for (i = 0; i < n; i++) {\n+    max2 = max2 < uc[8*i+2] ? uc[8*i+2] : max2;\n+    max3 = max3 < uc[8*i+3] ? uc[8*i+3] : max3;\n+    max1 = max1 < uc[8*i+1] ? uc[8*i+1] : max1;\n+    max7 = max7 < uc[8*i+7] ? uc[8*i+7] : max7;\n+    max6 = max6 < uc[8*i+6] ? uc[8*i+6] : max6;\n+    max0 = max0 < uc[8*i] ? uc[8*i] : max0;\n+    max4 = max4 < uc[8*i+4] ? uc[8*i+4] : max4;\n+    max5 = max5 < uc[8*i+5] ? uc[8*i+5] : max5;\n+  }\n+\n+  /* Check results:  */\n+  if (max0 != res0\n+      || max1 != res1\n+      || max2 != res2\n+      || max3 != res3\n+      || max4 != res4\n+      || max5 != res5\n+      || max6 != res6\n+      || max7 != res7)\n+    abort ();\n+\n+  return 0;\n+}\n+\n+int main (void)\n+{\n+  int i;\n+\n+  check_vect ();\n+\n+  for (i = 0; i < N; i++)\n+    uc[i] = i+3;\n+\n+  main1 (N/8, 123, 124, 125, 126, 127, 128, 129, 313);\n+  return 0;\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 1 \"vect\" { xfail vect_no_int_max } } } */\n+/* { dg-final { scan-tree-dump-times \"vectorizing stmts using SLP\" 1 \"vect\" { xfail vect_no_int_max } } } */\n+/* { dg-final { cleanup-tree-dump \"vect\" } } */\n+"}, {"sha": "0974b6642d831ec8a20965874003eaeb74901fa2", "filename": "gcc/testsuite/gcc.dg/vect/slp-reduc-5.c", "status": "added", "additions": 49, "deletions": 0, "changes": 49, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-5.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-5.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-5.c?ref=b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "patch": "@@ -0,0 +1,49 @@\n+/* { dg-require-effective-target vect_int } */\n+\n+#include <stdarg.h>\n+#include <stdio.h>\n+#include \"tree-vect.h\"\n+\n+#define N 128 \n+\n+int c[N];\n+\n+/* Vectorization of reduction using loop-aware SLP.  */\n+\n+__attribute__ ((noinline))\n+int main1 (int n, int res0, int res1)\n+{\n+  int i;\n+  int max0 = -100, max1 = -313;\n+\n+  for (i = 0; i < n; i++) {\n+    max1 = max1 < c[2*i+1] ? c[2*i+1] : max1;\n+    max0 = max0 < c[2*i] ? c[2*i] : max0;\n+  }\n+\n+  /* Check results:  */\n+  if (max0 != res0\n+      || max1 != res1)\n+    abort ();\n+\n+  return 0;\n+}\n+\n+int main (void)\n+{\n+  int i;\n+\n+  check_vect ();\n+\n+  for (i = 0; i < N; i++)\n+    c[i] = (i+3) * -1;\n+\n+  c[0] = c[1] = -100;\n+  main1 (N/2, -5, -6);\n+  return 0;\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 2 \"vect\" { xfail vect_no_int_max } } } */\n+/* { dg-final { scan-tree-dump-times \"vectorizing stmts using SLP\" 1 \"vect\" { xfail vect_no_int_max } } } */\n+/* { dg-final { cleanup-tree-dump \"vect\" } } */\n+"}, {"sha": "c69251a76e2ccf5a3fc038a07f9fb1dd3382cd84", "filename": "gcc/testsuite/gcc.dg/vect/slp-reduc-6.c", "status": "added", "additions": 50, "deletions": 0, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-6.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-6.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fslp-reduc-6.c?ref=b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "patch": "@@ -0,0 +1,50 @@\n+/* { dg-require-effective-target vect_int } */\n+\n+#include <stdarg.h>\n+#include <stdio.h>\n+#include \"tree-vect.h\"\n+\n+#define N 128 \n+\n+int a[N], b[N];\n+\n+/* Vectorization of reduction. Loop-aware SLP is not possible, because of \n+   different arrays.  */\n+\n+__attribute__ ((noinline))\n+int main1 (int n, int res0, int res1)\n+{\n+  int i;\n+  int sum0 = 0, sum1 = 0;\n+\n+  for (i = 0; i < n; i++) {\n+    sum1 += a[2*i];\n+    sum0 += b[2*i];\n+  }\n+\n+  /* Check results:  */\n+  if (sum0 != res0\n+      || sum1 != res1)\n+    abort ();\n+\n+  return 0;\n+}\n+\n+int main (void)\n+{\n+  int i;\n+\n+  check_vect ();\n+\n+  for (i = 0; i < N; i++)\n+    a[i] = b[i] = i;\n+\n+  main1 (N/2, 4032, 4032);\n+  return 0;\n+}\n+\n+/* { dg-final { scan-tree-dump-times \"vectorized 1 loops\" 2 \"vect\" { xfail vect_no_int_add } } } */\n+/* { dg-final { scan-tree-dump-times \"vectorizing stmts using SLP\" 0 \"vect\" } } */\n+/* { dg-final { scan-tree-dump-times \"different interleaving chains in one node\" 1 \"vect\" { target { ! vect_no_int_add } } } } */\n+/* { dg-final { cleanup-tree-dump \"vect\" } } */\n+"}, {"sha": "e91c0331516c132a682ca6d487cd6d5a79f68f9e", "filename": "gcc/testsuite/lib/target-supports.exp", "status": "modified", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Flib%2Ftarget-supports.exp", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftestsuite%2Flib%2Ftarget-supports.exp", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Flib%2Ftarget-supports.exp?ref=b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "patch": "@@ -2105,6 +2105,25 @@ proc check_effective_target_vect_perm { } {\n     return $et_vect_perm_saved\n }\n \n+# Return 1 if the target plus current options supports a vector\n+# widening summation of *short* args into *int* result, 0 otherwise.\n+#\n+# This won't change for different subtargets so cache the result.\n+\n+proc check_effective_target_vect_widen_sum_hi_to_si_pattern { } {\n+    global et_vect_widen_sum_hi_to_si_pattern\n+\n+    if [info exists et_vect_widen_sum_hi_to_si_pattern_saved] {\n+        verbose \"check_effective_target_vect_widen_sum_hi_to_si_pattern: using cached result\" 2\n+    } else {\n+        set et_vect_widen_sum_hi_to_si_pattern_saved 0\n+        if { [istarget powerpc*-*-*] } {\n+            set et_vect_widen_sum_hi_to_si_pattern_saved 1\n+        }\n+    }\n+    verbose \"check_effective_target_vect_widen_sum_hi_to_si_pattern: returning $et_vect_widen_sum_hi_to_si_pattern_saved\" 2\n+    return $et_vect_widen_sum_hi_to_si_pattern_saved\n+}\n \n # Return 1 if the target plus current options supports a vector\n # widening summation of *short* args into *int* result, 0 otherwise."}, {"sha": "e6e9008ea3774eea8a670fd8c08b66231605200d", "filename": "gcc/tree-vect-loop.c", "status": "modified", "additions": 598, "deletions": 380, "changes": 978, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftree-vect-loop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftree-vect-loop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-loop.c?ref=b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "patch": "@@ -545,6 +545,11 @@ vect_analyze_scalar_cycles_1 (loop_vec_info loop_vinfo, struct loop *loop)\n                   STMT_VINFO_DEF_TYPE (stmt_vinfo) = vect_reduction_def;\n                   STMT_VINFO_DEF_TYPE (vinfo_for_stmt (reduc_stmt)) =\n                                                            vect_reduction_def;\n+                  /* Store the reduction cycles for possible vectorization in\n+                     loop-aware SLP.  */\n+                  VEC_safe_push (gimple, heap,\n+                                 LOOP_VINFO_REDUCTIONS (loop_vinfo),\n+                                 reduc_stmt);\n                 }\n             }\n         }\n@@ -745,6 +750,7 @@ new_loop_vec_info (struct loop *loop)\n     VEC_alloc (ddr_p, heap,\n                PARAM_VALUE (PARAM_VECT_MAX_VERSION_FOR_ALIAS_CHECKS));\n   LOOP_VINFO_STRIDED_STORES (res) = VEC_alloc (gimple, heap, 10);\n+  LOOP_VINFO_REDUCTIONS (res) = VEC_alloc (gimple, heap, 10);\n   LOOP_VINFO_SLP_INSTANCES (res) = VEC_alloc (slp_instance, heap, 10);\n   LOOP_VINFO_SLP_UNROLLING_FACTOR (res) = 1;\n \n@@ -835,6 +841,7 @@ destroy_loop_vec_info (loop_vec_info loop_vinfo, bool clean_stmts)\n \n   VEC_free (slp_instance, heap, LOOP_VINFO_SLP_INSTANCES (loop_vinfo));\n   VEC_free (gimple, heap, LOOP_VINFO_STRIDED_STORES (loop_vinfo));\n+  VEC_free (gimple, heap, LOOP_VINFO_REDUCTIONS (loop_vinfo));\n \n   free (loop_vinfo);\n   loop->aux = NULL;\n@@ -1223,7 +1230,6 @@ vect_analyze_loop_operations (loop_vec_info loop_vinfo)\n           if ((STMT_VINFO_RELEVANT_P (stmt_info)\n                || VECTORIZABLE_CYCLE_DEF (STMT_VINFO_DEF_TYPE (stmt_info)))\n               && !PURE_SLP_STMT (stmt_info))\n-\n             /* STMT needs both SLP and loop-based vectorization.  */\n             only_slp_in_loop = false;\n         }\n@@ -2860,28 +2866,33 @@ get_initial_def_for_reduction (gimple stmt, tree init_val,\n /* Function vect_create_epilog_for_reduction\n \n    Create code at the loop-epilog to finalize the result of a reduction\n-   computation.\n-\n-   VECT_DEF is a vector of partial results.\n-   REDUC_CODE is the tree-code for the epilog reduction.\n+   computation. \n+  \n+   VECT_DEFS is list of vector of partial results, i.e., the lhs's of vector \n+     reduction statements. \n+   STMT is the scalar reduction stmt that is being vectorized.\n    NCOPIES is > 1 in case the vectorization factor (VF) is bigger than the\n      number of elements that we can fit in a vectype (nunits). In this case\n      we have to generate more than one vector stmt - i.e - we need to \"unroll\"\n      the vector stmt by a factor VF/nunits.  For more details see documentation\n      in vectorizable_operation.\n-   STMT is the scalar reduction stmt that is being vectorized.\n-   REDUCTION_PHI is the phi-node that carries the reduction computation.\n-   REDUC_INDEX is the index of the operand in the right hand side of the\n+   REDUC_CODE is the tree-code for the epilog reduction.\n+   REDUCTION_PHIS is a list of the phi-nodes that carry the reduction \n+     computation.\n+   REDUC_INDEX is the index of the operand in the right hand side of the \n      statement that is defined by REDUCTION_PHI.\n    DOUBLE_REDUC is TRUE if double reduction phi nodes should be handled.\n+   SLP_NODE is an SLP node containing a group of reduction statements. The \n+     first one in this group is STMT.\n \n    This function:\n-   1. Creates the reduction def-use cycle: sets the arguments for\n-      REDUCTION_PHI:\n+   1. Creates the reduction def-use cycles: sets the arguments for \n+      REDUCTION_PHIS:\n       The loop-entry argument is the vectorized initial-value of the reduction.\n-      The loop-latch argument is VECT_DEF - the vector of partial sums.\n-   2. \"Reduces\" the vector of partial results VECT_DEF into a single result,\n-      by applying the operation specified by REDUC_CODE if available, or by\n+      The loop-latch argument is taken from VECT_DEFS - the vector of partial \n+      sums.\n+   2. \"Reduces\" each vector of partial results VECT_DEFS into a single result,\n+      by applying the operation specified by REDUC_CODE if available, or by \n       other means (whole-vector shifts or a scalar loop).\n       The function also creates a new phi node at the loop exit to preserve\n       loop-closed form, as illustrated below.\n@@ -2914,12 +2925,11 @@ get_initial_def_for_reduction (gimple stmt, tree init_val,\n */\n \n static void\n-vect_create_epilog_for_reduction (tree vect_def, gimple stmt,\n-\t\t\t\t  int ncopies,\n-\t\t\t\t  enum tree_code reduc_code,\n-\t\t\t\t  gimple reduction_phi,\n-                                  int reduc_index,\n-                                  bool double_reduc)\n+vect_create_epilog_for_reduction (VEC (tree, heap) *vect_defs, gimple stmt,\n+\t\t\t\t  int ncopies, enum tree_code reduc_code,\n+\t\t\t\t  VEC (gimple, heap) *reduction_phis,\n+                                  int reduc_index, bool double_reduc, \n+                                  slp_tree slp_node)\n {\n   stmt_vec_info stmt_info = vinfo_for_stmt (stmt);\n   stmt_vec_info prev_phi_info;\n@@ -2933,32 +2943,37 @@ vect_create_epilog_for_reduction (tree vect_def, gimple stmt,\n   gimple new_phi = NULL, phi;\n   gimple_stmt_iterator exit_gsi;\n   tree vec_dest;\n-  tree new_temp = NULL_TREE;\n-  tree new_name;\n+  tree new_temp = NULL_TREE, new_dest, new_name, new_scalar_dest;\n   gimple epilog_stmt = NULL;\n-  tree new_scalar_dest, new_dest;\n+  enum tree_code code = gimple_assign_rhs_code (stmt);\n   gimple exit_phi;\n   tree bitsize, bitpos;\n-  enum tree_code code = gimple_assign_rhs_code (stmt);\n-  tree adjustment_def;\n-  tree vec_initial_def, def;\n-  tree orig_name;\n+  tree adjustment_def = NULL;\n+  tree vec_initial_def = NULL;\n+  tree reduction_op, expr, def;\n+  tree orig_name, scalar_result;\n   imm_use_iterator imm_iter;\n   use_operand_p use_p;\n   bool extract_scalar_result = false;\n-  tree reduction_op, expr;\n-  gimple orig_stmt;\n-  gimple use_stmt;\n+  gimple use_stmt, orig_stmt, reduction_phi = NULL;\n   bool nested_in_vect_loop = false;\n-  VEC(gimple,heap) *phis = NULL;\n+  VEC (gimple, heap) *new_phis = NULL;\n   enum vect_def_type dt = vect_unknown_def_type;\n   int j, i;\n+  VEC (tree, heap) *scalar_results = NULL;\n+  int group_size = 1, k, ratio;\n+  VEC (tree, heap) *vec_initial_defs = NULL;\n+  VEC (gimple, heap) *phis;\n+\n+  if (slp_node)\n+    group_size = VEC_length (gimple, SLP_TREE_SCALAR_STMTS (slp_node)); \n \n   if (nested_in_vect_loop_p (loop, stmt))\n     {\n       outer_loop = loop;\n       loop = loop->inner;\n       nested_in_vect_loop = true;\n+      gcc_assert (!slp_node);\n     }\n \n   switch (get_gimple_rhs_class (gimple_assign_rhs_code (stmt)))\n@@ -2983,47 +2998,80 @@ vect_create_epilog_for_reduction (tree vect_def, gimple stmt,\n   gcc_assert (vectype);\n   mode = TYPE_MODE (vectype);\n \n-  /*** 1. Create the reduction def-use cycle  ***/\n+  /* 1. Create the reduction def-use cycle:\n+     Set the arguments of REDUCTION_PHIS, i.e., transform\n+\n+        loop:\n+          vec_def = phi <null, null>            # REDUCTION_PHI\n+          VECT_DEF = vector_stmt                # vectorized form of STMT\n+          ...\n \n-  /* For the case of reduction, vect_get_vec_def_for_operand returns\n-     the scalar def before the loop, that defines the initial value\n-     of the reduction variable.  */\n-  vec_initial_def = vect_get_vec_def_for_operand (reduction_op, stmt,\n-\t\t\t\t\t          &adjustment_def);\n+     into:\n \n-  phi = reduction_phi;\n-  def = vect_def;\n-  for (j = 0; j < ncopies; j++)\n+        loop:\n+          vec_def = phi <vec_init, VECT_DEF>    # REDUCTION_PHI\n+          VECT_DEF = vector_stmt                # vectorized form of STMT\n+          ...\n+\n+     (in case of SLP, do it for all the phis). */\n+\n+  /* Get the loop-entry arguments.  */\n+  if (slp_node)\n+    vect_get_slp_defs (slp_node, &vec_initial_defs, NULL, reduc_index);\n+  else\n     {\n-      /* 1.1 set the loop-entry arg of the reduction-phi:  */\n-      add_phi_arg (phi, vec_initial_def, loop_preheader_edge (loop),\n-\t\t   UNKNOWN_LOCATION);\n+      vec_initial_defs = VEC_alloc (tree, heap, 1);\n+     /* For the case of reduction, vect_get_vec_def_for_operand returns\n+        the scalar def before the loop, that defines the initial value\n+        of the reduction variable.  */\n+      vec_initial_def = vect_get_vec_def_for_operand (reduction_op, stmt,\n+                                                      &adjustment_def);\n+      VEC_quick_push (tree, vec_initial_defs, vec_initial_def);\n+    }\n \n-      /* 1.2 set the loop-latch arg for the reduction-phi:  */\n-      if (j > 0)\n-        def = vect_get_vec_def_for_stmt_copy (dt, def);\n-      add_phi_arg (phi, def, loop_latch_edge (loop), UNKNOWN_LOCATION);\n+  /* Set phi nodes arguments.  */\n+  for (i = 0; VEC_iterate (gimple, reduction_phis, i, phi); i++)\n+    {\n+      tree vec_init_def = VEC_index (tree, vec_initial_defs, i);\n+      tree def = VEC_index (tree, vect_defs, i);\n+      for (j = 0; j < ncopies; j++)\n+        {\n+          /* Set the loop-entry arg of the reduction-phi.  */\n+          add_phi_arg (phi, vec_init_def, loop_preheader_edge (loop),\n+                       UNKNOWN_LOCATION);\n \n-      if (vect_print_dump_info (REPORT_DETAILS))\n-\t{\n-\t  fprintf (vect_dump, \"transform reduction: created def-use cycle: \");\n-\t  print_gimple_stmt (vect_dump, phi, 0, TDF_SLIM);\n-          fprintf (vect_dump, \"\\n\");\n-          print_gimple_stmt (vect_dump, SSA_NAME_DEF_STMT (def), 0, TDF_SLIM);\n-\t}\n+          /* Set the loop-latch arg for the reduction-phi.  */\n+          if (j > 0)\n+            def = vect_get_vec_def_for_stmt_copy (vect_unknown_def_type, def);\n \n-      phi = STMT_VINFO_RELATED_STMT (vinfo_for_stmt (phi));\n+          add_phi_arg (phi, def, loop_latch_edge (loop), UNKNOWN_LOCATION);\n+\n+          if (vect_print_dump_info (REPORT_DETAILS))\n+            {\n+              fprintf (vect_dump, \"transform reduction: created def-use\"\n+                                  \" cycle: \");\n+              print_gimple_stmt (vect_dump, phi, 0, TDF_SLIM);\n+              fprintf (vect_dump, \"\\n\");\n+              print_gimple_stmt (vect_dump, SSA_NAME_DEF_STMT (def), 0,\n+                                 TDF_SLIM);\n+            }\n+\n+          phi = STMT_VINFO_RELATED_STMT (vinfo_for_stmt (phi));\n+        }\n     }\n \n-  /*** 2. Create epilog code\n-\t  The reduction epilog code operates across the elements of the vector\n-          of partial results computed by the vectorized loop.\n-          The reduction epilog code consists of:\n-          step 1: compute the scalar result in a vector (v_out2)\n-          step 2: extract the scalar result (s_out3) from the vector (v_out2)\n-          step 3: adjust the scalar result (s_out3) if needed.\n+  VEC_free (tree, heap, vec_initial_defs);\n+\n+  /* 2. Create epilog code.\n+        The reduction epilog code operates across the elements of the vector\n+        of partial results computed by the vectorized loop.\n+        The reduction epilog code consists of:\n+\n+        step 1: compute the scalar result in a vector (v_out2)\n+        step 2: extract the scalar result (s_out3) from the vector (v_out2)\n+        step 3: adjust the scalar result (s_out3) if needed.\n \n-          Step 1 can be accomplished using one the following three schemes:\n+        Step 1 can be accomplished using one the following three schemes:\n           (scheme 1) using reduc_code, if available.\n           (scheme 2) using whole-vector shifts, if available.\n           (scheme 3) using a scalar loop. In this case steps 1+2 above are\n@@ -3038,29 +3086,33 @@ vect_create_epilog_for_reduction (tree vect_def, gimple stmt,\n           s_out4 = adjust_result <s_out3>       # step 3\n \n           (step 3 is optional, and steps 1 and 2 may be combined).\n-          Lastly, the uses of s_out0 are replaced by s_out4.\n+          Lastly, the uses of s_out0 are replaced by s_out4.  */\n \n-\t  ***/\n \n-  /* 2.1 Create new loop-exit-phi to preserve loop-closed form:\n-        v_out1 = phi <v_loop>  */\n+  /* 2.1 Create new loop-exit-phis to preserve loop-closed form:\n+         v_out1 = phi <VECT_DEF> \n+         Store them in NEW_PHIS.  */\n \n   exit_bb = single_exit (loop)->dest;\n-  def = vect_def;\n   prev_phi_info = NULL;\n-  for (j = 0; j < ncopies; j++)\n+  new_phis = VEC_alloc (gimple, heap, VEC_length (tree, vect_defs));\n+  for (i = 0; VEC_iterate (tree, vect_defs, i, def); i++)\n     {\n-      phi = create_phi_node (SSA_NAME_VAR (vect_def), exit_bb);\n-      set_vinfo_for_stmt (phi, new_stmt_vec_info (phi, loop_vinfo, NULL));\n-      if (j == 0)\n-\tnew_phi = phi;\n-      else\n-\t{\n-\t  def = vect_get_vec_def_for_stmt_copy (dt, def);\n-\t  STMT_VINFO_RELATED_STMT (prev_phi_info) = phi;\n-\t}\n-      SET_PHI_ARG_DEF (phi, single_exit (loop)->dest_idx, def);\n-      prev_phi_info = vinfo_for_stmt (phi);\n+      for (j = 0; j < ncopies; j++)\n+        {\n+          phi = create_phi_node (SSA_NAME_VAR (def), exit_bb);\n+          set_vinfo_for_stmt (phi, new_stmt_vec_info (phi, loop_vinfo, NULL));\n+          if (j == 0)\n+            VEC_quick_push (gimple, new_phis, phi);\n+          else\n+\t    {\n+\t      def = vect_get_vec_def_for_stmt_copy (dt, def);\n+\t      STMT_VINFO_RELATED_STMT (prev_phi_info) = phi;\n+\t    }\n+\n+          SET_PHI_ARG_DEF (phi, single_exit (loop)->dest_idx, def);\n+          prev_phi_info = vinfo_for_stmt (phi);\n+        }\n     }\n \n   exit_gsi = gsi_after_labels (exit_bb);\n@@ -3089,16 +3141,17 @@ vect_create_epilog_for_reduction (tree vect_def, gimple stmt,\n     }\n \n   code = gimple_assign_rhs_code (orig_stmt);\n+  /* For MINUS_EXPR the initial vector is [init_val,0,...,0], therefore,\n+     partial results are added and not subtracted.  */\n+  if (code == MINUS_EXPR) \n+    code = PLUS_EXPR;\n+  \n   scalar_dest = gimple_assign_lhs (orig_stmt);\n   scalar_type = TREE_TYPE (scalar_dest);\n+  scalar_results = VEC_alloc (tree, heap, group_size); \n   new_scalar_dest = vect_create_destination_var (scalar_dest, NULL);\n   bitsize = TYPE_SIZE (scalar_type);\n \n-  /* For MINUS_EXPR the initial vector is [init_val,0,...,0], therefore,\n-     partial results are added and not subtracted.  */\n-  if (code == MINUS_EXPR)\n-    code = PLUS_EXPR;\n-\n   /* In case this is a reduction in an inner-loop while vectorizing an outer\n      loop - we don't need to extract a single scalar result at the end of the\n      inner-loop (unless it is double reduction, i.e., the use of reduction is\n@@ -3108,28 +3161,21 @@ vect_create_epilog_for_reduction (tree vect_def, gimple stmt,\n   if (nested_in_vect_loop && !double_reduc)\n     goto vect_finalize_reduction;\n \n-  /* The epilogue is created for the outer-loop, i.e., for the loop being\n-     vectorized.  */\n-  if (double_reduc)\n-    loop = outer_loop;\n-\n-  /* FORNOW */\n-  gcc_assert (ncopies == 1);\n-\n   /* 2.3 Create the reduction code, using one of the three schemes described\n-         above.  */\n-\n-  if (reduc_code != ERROR_MARK)\n+         above. In SLP we simply need to extract all the elements from the \n+         vector (without reducing them), so we use scalar shifts.  */\n+  if (reduc_code != ERROR_MARK && !slp_node)\n     {\n       tree tmp;\n \n       /*** Case 1:  Create:\n-\t   v_out2 = reduc_expr <v_out1>  */\n+           v_out2 = reduc_expr <v_out1>  */\n \n       if (vect_print_dump_info (REPORT_DETAILS))\n-\tfprintf (vect_dump, \"Reduce using direct vector reduction.\");\n+        fprintf (vect_dump, \"Reduce using direct vector reduction.\");\n \n       vec_dest = vect_create_destination_var (scalar_dest, vectype);\n+      new_phi = VEC_index (gimple, new_phis, 0);\n       tmp = build1 (reduc_code, vectype,  PHI_RESULT (new_phi));\n       epilog_stmt = gimple_build_assign (vec_dest, tmp);\n       new_temp = make_ssa_name (vec_dest, epilog_stmt);\n@@ -3148,157 +3194,200 @@ vect_create_epilog_for_reduction (tree vect_def, gimple stmt,\n       tree vec_temp;\n \n       if (optab_handler (vec_shr_optab, mode)->insn_code != CODE_FOR_nothing)\n-\tshift_code = VEC_RSHIFT_EXPR;\n+        shift_code = VEC_RSHIFT_EXPR;\n       else\n-\thave_whole_vector_shift = false;\n+        have_whole_vector_shift = false;\n \n       /* Regardless of whether we have a whole vector shift, if we're\n-\t emulating the operation via tree-vect-generic, we don't want\n-\t to use it.  Only the first round of the reduction is likely\n-\t to still be profitable via emulation.  */\n+         emulating the operation via tree-vect-generic, we don't want\n+         to use it.  Only the first round of the reduction is likely\n+         to still be profitable via emulation.  */\n       /* ??? It might be better to emit a reduction tree code here, so that\n-\t tree-vect-generic can expand the first round via bit tricks.  */\n+         tree-vect-generic can expand the first round via bit tricks.  */\n       if (!VECTOR_MODE_P (mode))\n-\thave_whole_vector_shift = false;\n+        have_whole_vector_shift = false;\n       else\n-\t{\n-\t  optab optab = optab_for_tree_code (code, vectype, optab_default);\n-\t  if (optab_handler (optab, mode)->insn_code == CODE_FOR_nothing)\n-\t    have_whole_vector_shift = false;\n-\t}\n-\n-      if (have_whole_vector_shift)\n         {\n-\t  /*** Case 2: Create:\n-\t     for (offset = VS/2; offset >= element_size; offset/=2)\n-\t        {\n-\t          Create:  va' = vec_shift <va, offset>\n-\t          Create:  va = vop <va, va'>\n-\t        }  */\n-\n-\t  if (vect_print_dump_info (REPORT_DETAILS))\n-\t    fprintf (vect_dump, \"Reduce using vector shifts\");\n+          optab optab = optab_for_tree_code (code, vectype, optab_default);\n+          if (optab_handler (optab, mode)->insn_code == CODE_FOR_nothing)\n+            have_whole_vector_shift = false;\n+        }\n \n-\t  vec_dest = vect_create_destination_var (scalar_dest, vectype);\n-\t  new_temp = PHI_RESULT (new_phi);\n+      if (have_whole_vector_shift && !slp_node)\n+        {\n+          /*** Case 2: Create:\n+             for (offset = VS/2; offset >= element_size; offset/=2)\n+                {\n+                  Create:  va' = vec_shift <va, offset>\n+                  Create:  va = vop <va, va'>\n+                }  */\n \n-\t  for (bit_offset = vec_size_in_bits/2;\n-\t       bit_offset >= element_bitsize;\n-\t       bit_offset /= 2)\n-\t    {\n-\t      tree bitpos = size_int (bit_offset);\n-\n-\t      epilog_stmt = gimple_build_assign_with_ops (shift_code, vec_dest,\n-\t\t\t\t\t\t\t  new_temp, bitpos);\n-\t      new_name = make_ssa_name (vec_dest, epilog_stmt);\n-\t      gimple_assign_set_lhs (epilog_stmt, new_name);\n-\t      gsi_insert_before (&exit_gsi, epilog_stmt, GSI_SAME_STMT);\n-\n-\t      epilog_stmt = gimple_build_assign_with_ops (code, vec_dest,\n-\t\t\t\t\t\t\t  new_name, new_temp);\n-\t      new_temp = make_ssa_name (vec_dest, epilog_stmt);\n-\t      gimple_assign_set_lhs (epilog_stmt, new_temp);\n-\t      gsi_insert_before (&exit_gsi, epilog_stmt, GSI_SAME_STMT);\n-\t    }\n+          if (vect_print_dump_info (REPORT_DETAILS))\n+            fprintf (vect_dump, \"Reduce using vector shifts\");\n+\n+          vec_dest = vect_create_destination_var (scalar_dest, vectype);\n+          new_phi = VEC_index (gimple, new_phis, 0);\n+          new_temp = PHI_RESULT (new_phi);\n+          for (bit_offset = vec_size_in_bits/2;\n+               bit_offset >= element_bitsize;\n+               bit_offset /= 2)\n+            {\n+              tree bitpos = size_int (bit_offset);\n+\n+              epilog_stmt = gimple_build_assign_with_ops (shift_code,\n+                                               vec_dest, new_temp, bitpos);\n+              new_name = make_ssa_name (vec_dest, epilog_stmt);\n+              gimple_assign_set_lhs (epilog_stmt, new_name);\n+              gsi_insert_before (&exit_gsi, epilog_stmt, GSI_SAME_STMT);\n+\n+              epilog_stmt = gimple_build_assign_with_ops (code, vec_dest,\n+                                                          new_name, new_temp);\n+              new_temp = make_ssa_name (vec_dest, epilog_stmt);\n+              gimple_assign_set_lhs (epilog_stmt, new_temp);\n+              gsi_insert_before (&exit_gsi, epilog_stmt, GSI_SAME_STMT);\n+            }\n \n-\t  extract_scalar_result = true;\n-\t}\n+          extract_scalar_result = true;\n+        }\n       else\n         {\n-\t  tree rhs;\n-\n-\t  /*** Case 3: Create:\n-\t     s = extract_field <v_out2, 0>\n-\t     for (offset = element_size;\n-\t\t  offset < vector_size;\n-\t\t  offset += element_size;)\n-\t       {\n-\t         Create:  s' = extract_field <v_out2, offset>\n-\t         Create:  s = op <s, s'>\n-\t       }  */\n+          tree rhs;\n+\n+          /*** Case 3: Create:\n+             s = extract_field <v_out2, 0>\n+             for (offset = element_size;\n+                  offset < vector_size;\n+                  offset += element_size;)\n+               {\n+                 Create:  s' = extract_field <v_out2, offset>\n+                 Create:  s = op <s, s'>  // For non SLP cases\n+               }  */\n \n-\t  if (vect_print_dump_info (REPORT_DETAILS))\n-\t    fprintf (vect_dump, \"Reduce using scalar code. \");\n-\n-\t  vec_temp = PHI_RESULT (new_phi);\n-\t  vec_size_in_bits = tree_low_cst (TYPE_SIZE (vectype), 1);\n-\t  rhs = build3 (BIT_FIELD_REF, scalar_type, vec_temp, bitsize,\n-\t\t\t bitsize_zero_node);\n-\t  epilog_stmt = gimple_build_assign (new_scalar_dest, rhs);\n-\t  new_temp = make_ssa_name (new_scalar_dest, epilog_stmt);\n-\t  gimple_assign_set_lhs (epilog_stmt, new_temp);\n-\t  gsi_insert_before (&exit_gsi, epilog_stmt, GSI_SAME_STMT);\n-\n-\t  for (bit_offset = element_bitsize;\n-\t       bit_offset < vec_size_in_bits;\n-\t       bit_offset += element_bitsize)\n-\t    {\n-\t      tree bitpos = bitsize_int (bit_offset);\n-\t      tree rhs = build3 (BIT_FIELD_REF, scalar_type, vec_temp, bitsize,\n-\t\t\t\t bitpos);\n-\n-\t      epilog_stmt = gimple_build_assign (new_scalar_dest, rhs);\n-\t      new_name = make_ssa_name (new_scalar_dest, epilog_stmt);\n-\t      gimple_assign_set_lhs (epilog_stmt, new_name);\n-\t      gsi_insert_before (&exit_gsi, epilog_stmt, GSI_SAME_STMT);\n-\n-\t      epilog_stmt = gimple_build_assign_with_ops (code,\n-\t\t\t\t\t\t\t  new_scalar_dest,\n-\t\t\t\t\t\t\t  new_name, new_temp);\n-\t      new_temp = make_ssa_name (new_scalar_dest, epilog_stmt);\n-\t      gimple_assign_set_lhs (epilog_stmt, new_temp);\n-\t      gsi_insert_before (&exit_gsi, epilog_stmt, GSI_SAME_STMT);\n-\t    }\n+          if (vect_print_dump_info (REPORT_DETAILS))\n+            fprintf (vect_dump, \"Reduce using scalar code. \");\n \n-\t  extract_scalar_result = false;\n-\t}\n+          vec_size_in_bits = tree_low_cst (TYPE_SIZE (vectype), 1);\n+          for (i = 0; VEC_iterate (gimple, new_phis, i, new_phi); i++)\n+            {\n+              vec_temp = PHI_RESULT (new_phi);\n+              rhs = build3 (BIT_FIELD_REF, scalar_type, vec_temp, bitsize,\n+                            bitsize_zero_node);\n+              epilog_stmt = gimple_build_assign (new_scalar_dest, rhs);\n+              new_temp = make_ssa_name (new_scalar_dest, epilog_stmt);\n+              gimple_assign_set_lhs (epilog_stmt, new_temp);\n+              gsi_insert_before (&exit_gsi, epilog_stmt, GSI_SAME_STMT);\n+\n+              /* In SLP we don't need to apply reduction operation, so we just\n+                 collect s' values in SCALAR_RESULTS.  */\n+              if (slp_node)\n+                VEC_safe_push (tree, heap, scalar_results, new_temp);\n+\n+              for (bit_offset = element_bitsize;\n+                   bit_offset < vec_size_in_bits;\n+                   bit_offset += element_bitsize)\n+                {\n+                  tree bitpos = bitsize_int (bit_offset);\n+                  tree rhs = build3 (BIT_FIELD_REF, scalar_type, vec_temp,\n+                                     bitsize, bitpos);\n+\n+                  epilog_stmt = gimple_build_assign (new_scalar_dest, rhs);\n+                  new_name = make_ssa_name (new_scalar_dest, epilog_stmt);\n+                  gimple_assign_set_lhs (epilog_stmt, new_name);\n+                  gsi_insert_before (&exit_gsi, epilog_stmt, GSI_SAME_STMT);\n+\n+                  if (slp_node)\n+                    {\n+                      /* In SLP we don't need to apply reduction operation, so \n+                         we just collect s' values in SCALAR_RESULTS.  */\n+                      new_temp = new_name;\n+                      VEC_safe_push (tree, heap, scalar_results, new_name);\n+                    }\n+                  else\n+                    {\n+                      epilog_stmt = gimple_build_assign_with_ops (code,\n+                                          new_scalar_dest, new_name, new_temp);\n+                      new_temp = make_ssa_name (new_scalar_dest, epilog_stmt);\n+                      gimple_assign_set_lhs (epilog_stmt, new_temp);\n+                      gsi_insert_before (&exit_gsi, epilog_stmt, GSI_SAME_STMT);\n+                    }\n+                }\n+            }\n+\n+          /* The only case where we need to reduce scalar results in SLP, is\n+             unrolling. If the size of SCALAR_RESULTS is greater than \n+             GROUP_SIZE, we reduce them combining elements modulo \n+             GROUP_SIZE.  */\n+          if (slp_node)\n+            {\n+              tree res, first_res, new_res;\n+              gimple new_stmt;\n+            \n+              /* Reduce multiple scalar results in case of SLP unrolling.  */\n+              for (j = group_size; VEC_iterate (tree, scalar_results, j, res);\n+                   j++)\n+                {\n+                  first_res = VEC_index (tree, scalar_results, j % group_size);\n+                  new_stmt = gimple_build_assign_with_ops (code,\n+                                              new_scalar_dest, first_res, res);\n+                  new_res = make_ssa_name (new_scalar_dest, new_stmt);\n+                  gimple_assign_set_lhs (new_stmt, new_res);\n+                  gsi_insert_before (&exit_gsi, new_stmt, GSI_SAME_STMT);\n+                  VEC_replace (tree, scalar_results, j % group_size, new_res);\n+                }\n+            }\n+          else\n+            /* Not SLP - we have one scalar to keep in SCALAR_RESULTS.  */\n+            VEC_safe_push (tree, heap, scalar_results, new_temp);\n+\n+          extract_scalar_result = false;\n+        }\n     }\n \n   /* 2.4  Extract the final scalar result.  Create:\n-         s_out3 = extract_field <v_out2, bitpos>  */\n+          s_out3 = extract_field <v_out2, bitpos>  */\n \n   if (extract_scalar_result)\n     {\n       tree rhs;\n \n-      gcc_assert (!nested_in_vect_loop || double_reduc);\n       if (vect_print_dump_info (REPORT_DETAILS))\n-\tfprintf (vect_dump, \"extract scalar result\");\n+        fprintf (vect_dump, \"extract scalar result\");\n \n       if (BYTES_BIG_ENDIAN)\n-\tbitpos = size_binop (MULT_EXPR,\n-\t\t       bitsize_int (TYPE_VECTOR_SUBPARTS (vectype) - 1),\n-\t\t       TYPE_SIZE (scalar_type));\n+        bitpos = size_binop (MULT_EXPR,\n+                             bitsize_int (TYPE_VECTOR_SUBPARTS (vectype) - 1),\n+                             TYPE_SIZE (scalar_type));\n       else\n-\tbitpos = bitsize_zero_node;\n+        bitpos = bitsize_zero_node;\n \n       rhs = build3 (BIT_FIELD_REF, scalar_type, new_temp, bitsize, bitpos);\n       epilog_stmt = gimple_build_assign (new_scalar_dest, rhs);\n       new_temp = make_ssa_name (new_scalar_dest, epilog_stmt);\n       gimple_assign_set_lhs (epilog_stmt, new_temp);\n       gsi_insert_before (&exit_gsi, epilog_stmt, GSI_SAME_STMT);\n+      VEC_safe_push (tree, heap, scalar_results, new_temp);\n     }\n-\n+  \n vect_finalize_reduction:\n \n-  if (double_reduc)\n-    loop = loop->inner;\n-\n   /* 2.5 Adjust the final result by the initial value of the reduction\n \t variable. (When such adjustment is not needed, then\n \t 'adjustment_def' is zero).  For example, if code is PLUS we create:\n \t new_temp = loop_exit_def + adjustment_def  */\n \n   if (adjustment_def)\n     {\n+      gcc_assert (!slp_node);\n       if (nested_in_vect_loop)\n \t{\n+          new_phi = VEC_index (gimple, new_phis, 0);\n \t  gcc_assert (TREE_CODE (TREE_TYPE (adjustment_def)) == VECTOR_TYPE);\n \t  expr = build2 (code, vectype, PHI_RESULT (new_phi), adjustment_def);\n \t  new_dest = vect_create_destination_var (scalar_dest, vectype);\n \t}\n       else\n \t{\n+          new_temp = VEC_index (tree, scalar_results, 0);\n \t  gcc_assert (TREE_CODE (TREE_TYPE (adjustment_def)) != VECTOR_TYPE);\n \t  expr = build2 (code, scalar_type, new_temp, adjustment_def);\n \t  new_dest = vect_create_destination_var (scalar_dest, scalar_type);\n@@ -3309,142 +3398,206 @@ vect_create_epilog_for_reduction (tree vect_def, gimple stmt,\n       gimple_assign_set_lhs (epilog_stmt, new_temp);\n       SSA_NAME_DEF_STMT (new_temp) = epilog_stmt;\n       gsi_insert_before (&exit_gsi, epilog_stmt, GSI_SAME_STMT);\n+      if (nested_in_vect_loop)\n+        {\n+          set_vinfo_for_stmt (epilog_stmt,\n+                              new_stmt_vec_info (epilog_stmt, loop_vinfo,\n+                                                 NULL));\n+          STMT_VINFO_RELATED_STMT (vinfo_for_stmt (epilog_stmt)) =\n+                STMT_VINFO_RELATED_STMT (vinfo_for_stmt (new_phi));\n+\n+          if (!double_reduc)\n+            VEC_quick_push (tree, scalar_results, new_temp);\n+          else\n+            VEC_replace (tree, scalar_results, 0, new_temp);\n+        }\n+      else\n+        VEC_replace (tree, scalar_results, 0, new_temp);\n+\n+      VEC_replace (gimple, new_phis, 0, epilog_stmt);\n     }\n \n+  /* 2.6  Handle the loop-exit phis. Replace the uses of scalar loop-exit\n+          phis with new adjusted scalar results, i.e., replace use <s_out0>\n+          with use <s_out4>.        \n \n-  /* 2.6  Handle the loop-exit phi  */\n+     Transform:\n+        loop_exit:\n+          s_out0 = phi <s_loop>                 # (scalar) EXIT_PHI\n+          v_out1 = phi <VECT_DEF>               # NEW_EXIT_PHI\n+          v_out2 = reduce <v_out1>\n+          s_out3 = extract_field <v_out2, 0>\n+          s_out4 = adjust_result <s_out3>\n+          use <s_out0>\n+          use <s_out0>\n+\n+     into:\n \n-  /* Replace uses of s_out0 with uses of s_out3:\n-     Find the loop-closed-use at the loop exit of the original scalar result.\n-     (The reduction result is expected to have two immediate uses - one at the\n-     latch block, and one at the loop exit).  */\n-  phis = VEC_alloc (gimple, heap, 10);\n-  FOR_EACH_IMM_USE_FAST (use_p, imm_iter, scalar_dest)\n+        loop_exit:\n+          s_out0 = phi <s_loop>                 # (scalar) EXIT_PHI\n+          v_out1 = phi <VECT_DEF>               # NEW_EXIT_PHI\n+          v_out2 = reduce <v_out1>\n+          s_out3 = extract_field <v_out2, 0>\n+          s_out4 = adjust_result <s_out3>\n+          use <s_out4>  */\n+\n+  /* In SLP we may have several statements in NEW_PHIS and REDUCTION_PHIS (in \n+     case that GROUP_SIZE is greater than vectorization factor). Therefore, we\n+     need to match SCALAR_RESULTS with corresponding statements. The first\n+     (GROUP_SIZE / number of new vector stmts) scalar results correspond to\n+     the first vector stmt, etc.  \n+     (RATIO is equal to (GROUP_SIZE / number of new vector stmts)).  */ \n+  ratio = group_size / VEC_length (gimple, new_phis);\n+  gcc_assert (!(group_size % VEC_length (gimple, new_phis)));\n+\n+  for (k = 0; k < group_size; k++)\n     {\n-      if (!flow_bb_inside_loop_p (loop, gimple_bb (USE_STMT (use_p))))\n-\t{\n-\t  exit_phi = USE_STMT (use_p);\n-\t  VEC_quick_push (gimple, phis, exit_phi);\n-\t}\n-    }\n+      if (k % ratio == 0)\n+        {\n+          epilog_stmt = VEC_index (gimple, new_phis, k / ratio);\n+          reduction_phi = VEC_index (gimple, reduction_phis, k / ratio);\n+        }\n \n-  /* We expect to have found an exit_phi because of loop-closed-ssa form.  */\n-  gcc_assert (!VEC_empty (gimple, phis));\n+      if (slp_node)\n+        {\n+          gimple current_stmt = VEC_index (gimple,\n+                                       SLP_TREE_SCALAR_STMTS (slp_node), k);\n \n-  for (i = 0; VEC_iterate (gimple, phis, i, exit_phi); i++)\n-    {\n-      if (nested_in_vect_loop)\n-\t{\n-\t  stmt_vec_info stmt_vinfo = vinfo_for_stmt (exit_phi);\n-          gimple vect_phi;\n-\n-\t  /* FORNOW. Currently not supporting the case that an inner-loop\n-\t     reduction is not used in the outer-loop (but only outside the\n-\t     outer-loop), unless it is double reduction.  */\n-\t  gcc_assert ((STMT_VINFO_RELEVANT_P (stmt_vinfo)\n-                      && !STMT_VINFO_LIVE_P (stmt_vinfo)) || double_reduc);\n-\n-\t  epilog_stmt = adjustment_def ? epilog_stmt : new_phi;\n-\t  STMT_VINFO_VEC_STMT (stmt_vinfo) = epilog_stmt;\n-\t  set_vinfo_for_stmt (epilog_stmt,\n-\t\t\t      new_stmt_vec_info (epilog_stmt, loop_vinfo,\n-\t\t\t                         NULL));\n-\t  if (adjustment_def)\n-\t    STMT_VINFO_RELATED_STMT (vinfo_for_stmt (epilog_stmt)) =\n-\t\tSTMT_VINFO_RELATED_STMT (vinfo_for_stmt (new_phi));\n-\n-          if (!double_reduc\n-              || STMT_VINFO_DEF_TYPE (stmt_vinfo) != vect_double_reduction_def)\n-            continue;\n-\n-          /* Handle double reduction:\n-\n-             stmt1: s1 = phi <s0, s2>  - double reduction phi (outer loop)\n-             stmt2:   s3 = phi <s1, s4> - (regular) reduction phi (inner loop)\n-             stmt3:   s4 = use (s3)     - (regular) reduction stmt (inner loop)\n-             stmt4: s2 = phi <s4>      - double reduction stmt (outer loop)\n-\n-             At that point the regular reduction (stmt2 and stmt3) is already\n-             vectorized, as well as the exit phi node, stmt4.\n-             Here we vectorize the phi node of double reduction, stmt1, and\n-             update all relevant statements.  */\n-\n-          /* Go through all the uses of s2 to find double reduction phi node,\n-             i.e., stmt1 above.  */\n-          orig_name = PHI_RESULT (exit_phi);\n-          FOR_EACH_IMM_USE_STMT (use_stmt, imm_iter, orig_name)\n+          orig_stmt = STMT_VINFO_RELATED_STMT (vinfo_for_stmt (current_stmt));\n+          /* SLP statements can't participate in patterns.  */\n+          gcc_assert (!orig_stmt);\n+          scalar_dest = gimple_assign_lhs (current_stmt);\n+        }\n+\n+      phis = VEC_alloc (gimple, heap, 3);\n+      /* Find the loop-closed-use at the loop exit of the original scalar\n+         result. (The reduction result is expected to have two immediate uses -\n+         one at the latch block, and one at the loop exit).  */\n+      FOR_EACH_IMM_USE_FAST (use_p, imm_iter, scalar_dest)\n+        if (!flow_bb_inside_loop_p (loop, gimple_bb (USE_STMT (use_p))))\n+          VEC_safe_push (gimple, heap, phis, USE_STMT (use_p));\n+\n+      /* We expect to have found an exit_phi because of loop-closed-ssa\n+         form.  */\n+      gcc_assert (!VEC_empty (gimple, phis));\n+\n+      for (i = 0; VEC_iterate (gimple, phis, i, exit_phi); i++)\n+        {\n+          if (outer_loop)\n             {\n-              stmt_vec_info use_stmt_vinfo = vinfo_for_stmt (use_stmt);\n-              stmt_vec_info new_phi_vinfo;\n-              tree vect_phi_init, preheader_arg, vect_phi_res, init_def;\n-              basic_block bb = gimple_bb (use_stmt);\n-              gimple use;\n-\n-              /* Check that USE_STMT is really double reduction phi node.  */\n-              if (gimple_code (use_stmt) != GIMPLE_PHI\n-                  || gimple_phi_num_args (use_stmt) != 2\n-                  || !use_stmt_vinfo\n-                  || STMT_VINFO_DEF_TYPE (use_stmt_vinfo)\n-                      != vect_double_reduction_def\n-                  || bb->loop_father != outer_loop)\n+              stmt_vec_info exit_phi_vinfo = vinfo_for_stmt (exit_phi);\n+              gimple vect_phi;\n+\n+              /* FORNOW. Currently not supporting the case that an inner-loop\n+                 reduction is not used in the outer-loop (but only outside the\n+                 outer-loop), unless it is double reduction.  */\n+              gcc_assert ((STMT_VINFO_RELEVANT_P (exit_phi_vinfo)\n+                           && !STMT_VINFO_LIVE_P (exit_phi_vinfo))\n+                          || double_reduc);\n+\n+              STMT_VINFO_VEC_STMT (exit_phi_vinfo) = epilog_stmt;\n+              if (!double_reduc\n+                  || STMT_VINFO_DEF_TYPE (exit_phi_vinfo)\n+                      != vect_double_reduction_def)\n                 continue;\n \n-              /* Create vector phi node for double reduction:\n-                 vs1 = phi <vs0, vs2>\n-                 vs1 was created previously in this function by a call to\n-                 vect_get_vec_def_for_operand and is stored in vec_initial_def;\n-                 vs2 is defined by EPILOG_STMT, the vectorized EXIT_PHI;\n-                 vs0 is created here.  */\n+              /* Handle double reduction:\n \n-              /* Create vector phi node.  */\n-              vect_phi = create_phi_node (vec_initial_def, bb);\n-              new_phi_vinfo = new_stmt_vec_info (vect_phi,\n-                                    loop_vec_info_for_loop (outer_loop), NULL);\n-              set_vinfo_for_stmt (vect_phi, new_phi_vinfo);\n+                 stmt1: s1 = phi <s0, s2>  - double reduction phi (outer loop)\n+                 stmt2:   s3 = phi <s1, s4> - (regular) reduc phi (inner loop)\n+                 stmt3:   s4 = use (s3)     - (regular) reduc stmt (inner loop)\n+                 stmt4: s2 = phi <s4>      - double reduction stmt (outer loop)\n \n-              /* Create vs0 - initial def of the double reduction phi.  */\n-              preheader_arg = PHI_ARG_DEF_FROM_EDGE (use_stmt,\n-                                             loop_preheader_edge (outer_loop));\n-              init_def = get_initial_def_for_reduction (stmt, preheader_arg,\n-                                                        NULL);\n-              vect_phi_init = vect_init_vector (use_stmt, init_def, vectype,\n-                                                NULL);\n-\n-              /* Update phi node arguments with vs0 and vs2.  */\n-              add_phi_arg (vect_phi, vect_phi_init,\n-                           loop_preheader_edge (outer_loop), UNKNOWN_LOCATION);\n-              add_phi_arg (vect_phi, PHI_RESULT (epilog_stmt),\n-                           loop_latch_edge (outer_loop), UNKNOWN_LOCATION);\n-              if (vect_print_dump_info (REPORT_DETAILS))\n-                {\n-                  fprintf (vect_dump, \"created double reduction phi node: \");\n-                  print_gimple_stmt (vect_dump, vect_phi, 0, TDF_SLIM);\n-                }\n-\n-              vect_phi_res = PHI_RESULT (vect_phi);\n+                 At that point the regular reduction (stmt2 and stmt3) is\n+                 already vectorized, as well as the exit phi node, stmt4.\n+                 Here we vectorize the phi node of double reduction, stmt1, and\n+                 update all relevant statements.  */\n \n-              /* Replace the use, i.e., set the correct vs1 in the regular\n-                 reduction phi node. FORNOW, NCOPIES is always 1, so the loop\n-                 is redundant.  */\n-              use = reduction_phi;\n-              for (j = 0; j < ncopies; j++)\n+              /* Go through all the uses of s2 to find double reduction phi\n+                 node, i.e., stmt1 above.  */\n+              orig_name = PHI_RESULT (exit_phi);\n+              FOR_EACH_IMM_USE_STMT (use_stmt, imm_iter, orig_name)\n                 {\n-                  edge pr_edge = loop_preheader_edge (loop);\n-                  SET_PHI_ARG_DEF (use, pr_edge->dest_idx, vect_phi_res);\n-                  use = STMT_VINFO_RELATED_STMT (vinfo_for_stmt (use));\n+                  stmt_vec_info use_stmt_vinfo = vinfo_for_stmt (use_stmt);\n+                  stmt_vec_info new_phi_vinfo;\n+                  tree vect_phi_init, preheader_arg, vect_phi_res, init_def;\n+                  basic_block bb = gimple_bb (use_stmt);\n+                  gimple use;\n+\n+                  /* Check that USE_STMT is really double reduction phi\n+                     node.  */\n+                  if (gimple_code (use_stmt) != GIMPLE_PHI\n+                      || gimple_phi_num_args (use_stmt) != 2\n+                      || !use_stmt_vinfo\n+                      || STMT_VINFO_DEF_TYPE (use_stmt_vinfo)\n+                          != vect_double_reduction_def\n+                      || bb->loop_father != outer_loop)\n+                    continue;\n+\n+                  /* Create vector phi node for double reduction:\n+                     vs1 = phi <vs0, vs2>\n+                     vs1 was created previously in this function by a call to\n+                       vect_get_vec_def_for_operand and is stored in\n+                       vec_initial_def;\n+                     vs2 is defined by EPILOG_STMT, the vectorized EXIT_PHI;\n+                     vs0 is created here.  */\n+\n+                  /* Create vector phi node.  */\n+                  vect_phi = create_phi_node (vec_initial_def, bb);\n+                  new_phi_vinfo = new_stmt_vec_info (vect_phi,\n+                                    loop_vec_info_for_loop (outer_loop), NULL);\n+                  set_vinfo_for_stmt (vect_phi, new_phi_vinfo);\n+\n+                  /* Create vs0 - initial def of the double reduction phi.  */\n+                  preheader_arg = PHI_ARG_DEF_FROM_EDGE (use_stmt,\n+                                             loop_preheader_edge (outer_loop));\n+                  init_def = get_initial_def_for_reduction (stmt,\n+                                                          preheader_arg, NULL);\n+                  vect_phi_init = vect_init_vector (use_stmt, init_def,\n+                                                    vectype, NULL);\n+\n+                  /* Update phi node arguments with vs0 and vs2.  */\n+                  add_phi_arg (vect_phi, vect_phi_init,\n+                               loop_preheader_edge (outer_loop),\n+                               UNKNOWN_LOCATION);\n+                  add_phi_arg (vect_phi, PHI_RESULT (epilog_stmt),\n+                               loop_latch_edge (outer_loop), UNKNOWN_LOCATION);\n+                  if (vect_print_dump_info (REPORT_DETAILS))\n+                    {\n+                      fprintf (vect_dump, \"created double reduction phi \"\n+                                          \"node: \");\n+                      print_gimple_stmt (vect_dump, vect_phi, 0, TDF_SLIM);\n+                    }\n+\n+                  vect_phi_res = PHI_RESULT (vect_phi);\n+\n+                  /* Replace the use, i.e., set the correct vs1 in the regular\n+                     reduction phi node. FORNOW, NCOPIES is always 1, so the\n+                     loop is redundant.  */\n+                  use = reduction_phi;\n+                  for (j = 0; j < ncopies; j++)\n+                    {\n+                      edge pr_edge = loop_preheader_edge (loop);\n+                      SET_PHI_ARG_DEF (use, pr_edge->dest_idx, vect_phi_res);\n+                      use = STMT_VINFO_RELATED_STMT (vinfo_for_stmt (use));\n+                    }\n                 }\n             }\n-\t}\n \n-      /* Replace the uses:  */\n-      orig_name = PHI_RESULT (exit_phi);\n-      FOR_EACH_IMM_USE_STMT (use_stmt, imm_iter, orig_name)\n-\tFOR_EACH_IMM_USE_ON_STMT (use_p, imm_iter)\n-\t  SET_USE (use_p, new_temp);\n+          /* Replace the uses:  */\n+          orig_name = PHI_RESULT (exit_phi);\n+          scalar_result = VEC_index (tree, scalar_results, k);\n+          FOR_EACH_IMM_USE_STMT (use_stmt, imm_iter, orig_name)\n+            FOR_EACH_IMM_USE_ON_STMT (use_p, imm_iter)\n+              SET_USE (use_p, scalar_result);\n+        }\n+\n+      VEC_free (gimple, heap, phis);\n     }\n \n-  VEC_free (gimple, heap, phis);\n-}\n+  VEC_free (tree, heap, scalar_results);\n+  VEC_free (gimple, heap, new_phis);\n+} \n \n \n /* Function vectorizable_reduction.\n@@ -3489,7 +3642,7 @@ vect_create_epilog_for_reduction (tree vect_def, gimple stmt,\n \n bool\n vectorizable_reduction (gimple stmt, gimple_stmt_iterator *gsi,\n-\t\t\tgimple *vec_stmt)\n+\t\t\tgimple *vec_stmt, slp_tree slp_node)\n {\n   tree vec_dest;\n   tree scalar_dest;\n@@ -3517,7 +3670,6 @@ vectorizable_reduction (gimple stmt, gimple_stmt_iterator *gsi,\n   int ncopies;\n   int epilog_copies;\n   stmt_vec_info prev_stmt_info, prev_phi_info;\n-  gimple first_phi = NULL;\n   bool single_defuse_cycle = false;\n   tree reduc_def = NULL_TREE;\n   gimple new_stmt = NULL;\n@@ -3532,6 +3684,10 @@ vectorizable_reduction (gimple stmt, gimple_stmt_iterator *gsi,\n   struct loop * def_stmt_loop, *outer_loop = NULL;\n   tree def_arg;\n   gimple def_arg_stmt;\n+  VEC (tree, heap) *vec_oprnds0 = NULL, *vec_oprnds1 = NULL, *vect_defs = NULL;\n+  VEC (gimple, heap) *phis = NULL;\n+  int vec_num;\n+  tree def0, def1;\n \n   if (nested_in_vect_loop_p (loop, stmt))\n     {\n@@ -3540,10 +3696,6 @@ vectorizable_reduction (gimple stmt, gimple_stmt_iterator *gsi,\n       nested_cycle = true;\n     }\n \n-  /* FORNOW: SLP not supported.  */\n-  if (STMT_SLP_TYPE (stmt_info))\n-    return false;\n-\n   /* 1. Is vectorizable reduction?  */\n   /* Not supportable if the reduction variable is used in the loop.  */\n   if (STMT_VINFO_RELEVANT (stmt_info) > vect_used_in_outer)\n@@ -3676,9 +3828,12 @@ vectorizable_reduction (gimple stmt, gimple_stmt_iterator *gsi,\n   if (STMT_VINFO_LIVE_P (vinfo_for_stmt (reduc_def_stmt)))\n     return false;\n \n+  if (slp_node)\n+    ncopies = 1;\n+  else\n+    ncopies = (LOOP_VINFO_VECT_FACTOR (loop_vinfo)\n+               / TYPE_VECTOR_SUBPARTS (vectype_in));\n \n-  ncopies = (LOOP_VINFO_VECT_FACTOR (loop_vinfo)\n-\t     / TYPE_VECTOR_SUBPARTS (vectype_in));\n   gcc_assert (ncopies >= 1);\n \n   vec_mode = TYPE_MODE (vectype_in);\n@@ -3897,89 +4052,143 @@ vectorizable_reduction (gimple stmt, gimple_stmt_iterator *gsi,\n \n   prev_stmt_info = NULL;\n   prev_phi_info = NULL;\n+  if (slp_node)\n+    {\n+      vec_num = SLP_TREE_NUMBER_OF_VEC_STMTS (slp_node);\n+      gcc_assert (TYPE_VECTOR_SUBPARTS (vectype_out) \n+                  == TYPE_VECTOR_SUBPARTS (vectype_in));\n+    }\n+  else\n+    {\n+      vec_num = 1;\n+      vec_oprnds0 = VEC_alloc (tree, heap, 1);\n+      if (op_type == ternary_op)\n+        vec_oprnds1 = VEC_alloc (tree, heap, 1);\n+    }\n+\n+  phis = VEC_alloc (gimple, heap, vec_num);\n+  vect_defs = VEC_alloc (tree, heap, vec_num);\n+  if (!slp_node)\n+    VEC_quick_push (tree, vect_defs, NULL_TREE);\n+\n   for (j = 0; j < ncopies; j++)\n     {\n       if (j == 0 || !single_defuse_cycle)\n \t{\n-\t  /* Create the reduction-phi that defines the reduction-operand.  */\n-\t  new_phi = create_phi_node (vec_dest, loop->header);\n-\t  set_vinfo_for_stmt (new_phi, new_stmt_vec_info (new_phi, loop_vinfo,\n-\t                                                  NULL));\n-          /* Get the vector def for the reduction variable from the phi\n-             node.  */\n-          reduc_def = PHI_RESULT (new_phi);\n-\t}\n+          for (i = 0; i < vec_num; i++)\n+            {\n+              /* Create the reduction-phi that defines the reduction\n+                 operand.  */\n+              new_phi = create_phi_node (vec_dest, loop->header);\n+              set_vinfo_for_stmt (new_phi,\n+                                  new_stmt_vec_info (new_phi, loop_vinfo,\n+                                                     NULL));\n+               if (j == 0 || slp_node)\n+                 VEC_quick_push (gimple, phis, new_phi);\n+            }\n+        }\n \n       if (code == COND_EXPR)\n         {\n-          first_phi = new_phi;\n-          vectorizable_condition (stmt, gsi, vec_stmt, reduc_def, reduc_index);\n+          gcc_assert (!slp_node);\n+          vectorizable_condition (stmt, gsi, vec_stmt, \n+                                  PHI_RESULT (VEC_index (gimple, phis, 0)), \n+                                  reduc_index);\n           /* Multiple types are not supported for condition.  */\n           break;\n         }\n \n       /* Handle uses.  */\n       if (j == 0)\n         {\n-\t  loop_vec_def0 = vect_get_vec_def_for_operand (ops[!reduc_index],\n-                                                        stmt, NULL);\n-          if (op_type == ternary_op)\n+          if (slp_node)\n+            vect_get_slp_defs (slp_node, &vec_oprnds0, &vec_oprnds1, -1);\n+          else\n             {\n-              if (reduc_index == 0)\n- \t        loop_vec_def1 = vect_get_vec_def_for_operand (ops[2], stmt,\n-                                                              NULL);\n-              else\n-                loop_vec_def1 = vect_get_vec_def_for_operand (ops[1], stmt,\n-                                                              NULL);\n+              loop_vec_def0 = vect_get_vec_def_for_operand (ops[!reduc_index],\n+                                                            stmt, NULL);\n+              VEC_quick_push (tree, vec_oprnds0, loop_vec_def0);\n+              if (op_type == ternary_op)\n+               {\n+                 if (reduc_index == 0)\n+                   loop_vec_def1 = vect_get_vec_def_for_operand (ops[2], stmt,\n+                                                                 NULL);\n+                 else\n+                   loop_vec_def1 = vect_get_vec_def_for_operand (ops[1], stmt,\n+                                                                 NULL);\n+\n+                 VEC_quick_push (tree, vec_oprnds1, loop_vec_def1);\n+               }\n             }\n-\n-          /* Get the vector def for the reduction variable from the phi\n-             node.  */\n-\t  first_phi = new_phi;\n         }\n       else\n         {\n-          enum vect_def_type dt = vect_unknown_def_type; /* Dummy */\n-          loop_vec_def0 = vect_get_vec_def_for_stmt_copy (dt, loop_vec_def0);\n-          if (op_type == ternary_op)\n-            loop_vec_def1 = vect_get_vec_def_for_stmt_copy (dt, loop_vec_def1);\n+          if (!slp_node)\n+            {\n+              enum vect_def_type dt = vect_unknown_def_type; /* Dummy */\n+              loop_vec_def0 = vect_get_vec_def_for_stmt_copy (dt, loop_vec_def0);\n+              VEC_replace (tree, vec_oprnds0, 0, loop_vec_def0);\n+              if (op_type == ternary_op)\n+                {\n+                  loop_vec_def1 = vect_get_vec_def_for_stmt_copy (dt,\n+                                                                loop_vec_def1);\n+                  VEC_replace (tree, vec_oprnds1, 0, loop_vec_def1);\n+                }\n+            }\n \n-\t  if (single_defuse_cycle)\n-\t    reduc_def = gimple_assign_lhs (new_stmt);\n-\t  else\n-\t    reduc_def = PHI_RESULT (new_phi);\n+          if (single_defuse_cycle)\n+            reduc_def = gimple_assign_lhs (new_stmt);\n \n-\t  STMT_VINFO_RELATED_STMT (prev_phi_info) = new_phi;\n+          STMT_VINFO_RELATED_STMT (prev_phi_info) = new_phi;\n         }\n \n-      /* Arguments are ready. Create the new vector stmt.  */\n-      if (op_type == binary_op)\n+      for (i = 0; VEC_iterate (tree, vec_oprnds0, i, def0); i++)\n         {\n-          if (reduc_index == 0)\n-            expr = build2 (code, vectype_out, reduc_def, loop_vec_def0);\n+          if (slp_node)\n+            reduc_def = PHI_RESULT (VEC_index (gimple, phis, i));\n           else\n-            expr = build2 (code, vectype_out, loop_vec_def0, reduc_def);\n-        }\n-      else\n-        {\n-          if (reduc_index == 0)\n-            expr = build3 (code, vectype_out, reduc_def, loop_vec_def0,\n-                           loop_vec_def1);\n+            {\n+              if (!single_defuse_cycle || j == 0)\n+                reduc_def = PHI_RESULT (new_phi);\n+            }\n+\n+          def1 = ((op_type == ternary_op)\n+                  ? VEC_index (tree, vec_oprnds1, i) : NULL);\n+          if (op_type == binary_op)\n+            {\n+              if (reduc_index == 0)\n+                expr = build2 (code, vectype_out, reduc_def, def0);\n+              else\n+                expr = build2 (code, vectype_out, def0, reduc_def);\n+            }\n           else\n             {\n-              if (reduc_index == 1)\n-                expr = build3 (code, vectype_out, loop_vec_def0, reduc_def,\n-                               loop_vec_def1);\n+              if (reduc_index == 0)\n+                expr = build3 (code, vectype_out, reduc_def, def0, def1);\n               else\n-                expr = build3 (code, vectype_out, loop_vec_def0, loop_vec_def1,\n-\t     \t               reduc_def);\n+                {\n+                  if (reduc_index == 1)\n+                    expr = build3 (code, vectype_out, def0, reduc_def, def1);\n+                  else\n+                    expr = build3 (code, vectype_out, def0, def1, reduc_def);\n+                }\n+            }\n+\n+          new_stmt = gimple_build_assign (vec_dest, expr);\n+          new_temp = make_ssa_name (vec_dest, new_stmt);\n+          gimple_assign_set_lhs (new_stmt, new_temp);\n+          vect_finish_stmt_generation (stmt, new_stmt, gsi);\n+          if (slp_node)\n+            {\n+              VEC_quick_push (gimple, SLP_TREE_VEC_STMTS (slp_node), new_stmt);\n+              VEC_quick_push (tree, vect_defs, new_temp);\n             }\n+          else\n+            VEC_replace (tree, vect_defs, 0, new_temp);\n         }\n \n-      new_stmt = gimple_build_assign (vec_dest, expr);\n-      new_temp = make_ssa_name (vec_dest, new_stmt);\n-      gimple_assign_set_lhs (new_stmt, new_temp);\n-      vect_finish_stmt_generation (stmt, new_stmt, gsi);\n+      if (slp_node)\n+        continue;\n \n       if (j == 0)\n \tSTMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt;\n@@ -3992,12 +4201,21 @@ vectorizable_reduction (gimple stmt, gimple_stmt_iterator *gsi,\n \n   /* Finalize the reduction-phi (set its arguments) and create the\n      epilog reduction code.  */\n-  if (!single_defuse_cycle || code == COND_EXPR)\n-    new_temp = gimple_assign_lhs (*vec_stmt);\n+  if ((!single_defuse_cycle || code == COND_EXPR) && !slp_node)\n+    {\n+      new_temp = gimple_assign_lhs (*vec_stmt);\n+      VEC_replace (tree, vect_defs, 0, new_temp);\n+    }\n+\n+  vect_create_epilog_for_reduction (vect_defs, stmt, epilog_copies,\n+                                    epilog_reduc_code, phis, reduc_index,\n+                                    double_reduc, slp_node);\n+\n+  VEC_free (gimple, heap, phis);\n+  VEC_free (tree, heap, vec_oprnds0);\n+  if (vec_oprnds1)\n+    VEC_free (tree, heap, vec_oprnds1);\n \n-  vect_create_epilog_for_reduction (new_temp, stmt, epilog_copies,\n-\t\t\t\t    epilog_reduc_code, first_phi, reduc_index,\n-                                    double_reduc);\n   return true;\n }\n "}, {"sha": "ea827559195b5306cd200f7078ae18f5b9267db2", "filename": "gcc/tree-vect-patterns.c", "status": "modified", "additions": 9, "deletions": 1, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftree-vect-patterns.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftree-vect-patterns.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-patterns.c?ref=b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "patch": "@@ -670,6 +670,8 @@ vect_pattern_recog_1 (\n   tree pattern_vectype;\n   tree type_in, type_out;\n   enum tree_code code;\n+  int i;\n+  gimple next;\n \n   pattern_stmt = (* vect_recog_func) (stmt, &type_in, &type_out);\n   if (!pattern_stmt)\n@@ -735,7 +737,13 @@ vect_pattern_recog_1 (\n   STMT_VINFO_IN_PATTERN_P (stmt_info) = true;\n   STMT_VINFO_RELATED_STMT (stmt_info) = pattern_stmt;\n \n-  return;\n+  /* Patterns cannot be vectorized using SLP, because they change the order of\n+     computation.  */\n+  for (i = 0; VEC_iterate (gimple, LOOP_VINFO_REDUCTIONS (loop_vinfo), i,\n+                           next);\n+       i++)\n+    if (next == stmt)\n+      VEC_ordered_remove (gimple, LOOP_VINFO_REDUCTIONS (loop_vinfo), i); \n }\n \n "}, {"sha": "99a865fee20f1c6446ce857b46195a5d701e6395", "filename": "gcc/tree-vect-slp.c", "status": "modified", "additions": 325, "deletions": 74, "changes": 399, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftree-vect-slp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftree-vect-slp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-slp.c?ref=b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "patch": "@@ -273,6 +273,7 @@ vect_get_and_check_slp_defs (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo,\n \t  break;\n \n \tcase vect_internal_def:\n+        case vect_reduction_def:\n \t  if (i == 0)\n \t    VEC_safe_push (gimple, heap, *def_stmts0, def_stmt);\n \t  else\n@@ -332,7 +333,7 @@ vect_build_slp_tree (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo,\n   HOST_WIDE_INT dummy;\n   bool permutation = false;\n   unsigned int load_place;\n-  gimple first_load;\n+  gimple first_load, prev_first_load = NULL;\n \n   /* For every stmt in NODE find its def stmt/s.  */\n   for (i = 0; VEC_iterate (gimple, stmts, i, stmt); i++)\n@@ -485,42 +486,62 @@ vect_build_slp_tree (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo,\n                                                 &pattern0, &pattern1))\n \t\treturn false;\n \t    }\n-\t    else\n-\t      {\n-\t\t/* Load.  */\n-                /* FORNOW: Check that there is no gap between the loads.  */\n-                if ((DR_GROUP_FIRST_DR (vinfo_for_stmt (stmt)) == stmt\n-                     && DR_GROUP_GAP (vinfo_for_stmt (stmt)) != 0)\n-                    || (DR_GROUP_FIRST_DR (vinfo_for_stmt (stmt)) != stmt\n-                        && DR_GROUP_GAP (vinfo_for_stmt (stmt)) != 1))\n-                  {\n-                    if (vect_print_dump_info (REPORT_SLP))\n-                      {\n-                        fprintf (vect_dump, \"Build SLP failed: strided \"\n-                                            \"loads have gaps \");\n-                        print_gimple_stmt (vect_dump, stmt, 0, TDF_SLIM);\n-                      }\n+\t  else\n+\t    {\n+\t      /* Load.  */\n+              /* FORNOW: Check that there is no gap between the loads.  */\n+              if ((DR_GROUP_FIRST_DR (vinfo_for_stmt (stmt)) == stmt\n+                   && DR_GROUP_GAP (vinfo_for_stmt (stmt)) != 0)\n+                  || (DR_GROUP_FIRST_DR (vinfo_for_stmt (stmt)) != stmt\n+                      && DR_GROUP_GAP (vinfo_for_stmt (stmt)) != 1))\n+                {\n+                  if (vect_print_dump_info (REPORT_SLP))\n+                    {\n+                      fprintf (vect_dump, \"Build SLP failed: strided \"\n+                                          \"loads have gaps \");\n+                      print_gimple_stmt (vect_dump, stmt, 0, TDF_SLIM);\n+                    }\n \n-                    return false;\n-                  }\n-\n-                /* Check that the size of interleaved loads group is not\n-                   greater than the SLP group size.  */\n-                if (DR_GROUP_SIZE (vinfo_for_stmt (stmt))\n-                    > ncopies * group_size)\n-                  {\n-                    if (vect_print_dump_info (REPORT_SLP))\n-                      {\n-                        fprintf (vect_dump, \"Build SLP failed: the number of \"\n-                                            \"interleaved loads is greater than\"\n-                                            \" the SLP group size \");\n-                        print_gimple_stmt (vect_dump, stmt, 0, TDF_SLIM);\n-                      }\n+                  return false;\n+                }\n \n-                    return false;\n-                  }\n+              /* Check that the size of interleaved loads group is not\n+                 greater than the SLP group size.  */\n+              if (DR_GROUP_SIZE (vinfo_for_stmt (stmt)) > ncopies * group_size)\n+                {\n+                  if (vect_print_dump_info (REPORT_SLP))\n+                    {\n+                      fprintf (vect_dump, \"Build SLP failed: the number of \"\n+                                          \"interleaved loads is greater than\"\n+                                          \" the SLP group size \");\n+                      print_gimple_stmt (vect_dump, stmt, 0, TDF_SLIM);\n+                    }\n \n-                first_load = DR_GROUP_FIRST_DR (vinfo_for_stmt (stmt));\n+                  return false;\n+                }\n+\n+              first_load = DR_GROUP_FIRST_DR (vinfo_for_stmt (stmt));\n+              if (prev_first_load)\n+                {\n+                  /* Check that there are no loads from different interleaving\n+                     chains in the same node. The only exception is complex\n+                     numbers.  */\n+                  if (prev_first_load != first_load\n+                      && rhs_code != REALPART_EXPR \n+                      && rhs_code != IMAGPART_EXPR)\n+                    {    \n+                      if (vect_print_dump_info (REPORT_SLP))\n+                        {\n+                          fprintf (vect_dump, \"Build SLP failed: different \"\n+                                           \"interleaving chains in one node \");\n+                          print_gimple_stmt (vect_dump, stmt, 0, TDF_SLIM);\n+                        }\n+ \n+                      return false;\n+                    }\n+                }\n+              else\n+                prev_first_load = first_load;\n \n               if (first_load == stmt)\n                 {\n@@ -787,6 +808,39 @@ vect_supported_slp_permutation_p (slp_instance instance)\n }\n \n \n+/* Rearrange the statements of NODE according to PERMUTATION.  */\n+\n+static void\n+vect_slp_rearrange_stmts (slp_tree node, unsigned int group_size,\n+                          VEC (int, heap) *permutation)\n+{\n+  gimple stmt;\n+  VEC (gimple, heap) *tmp_stmts;\n+  unsigned int index, i;\n+\n+  if (!node)\n+    return;\n+\n+  vect_slp_rearrange_stmts (SLP_TREE_LEFT (node), group_size, permutation);\n+  vect_slp_rearrange_stmts (SLP_TREE_RIGHT (node), group_size, permutation);\n+\n+  gcc_assert (group_size == VEC_length (gimple, SLP_TREE_SCALAR_STMTS (node)));\n+  tmp_stmts = VEC_alloc (gimple, heap, group_size);\n+\n+  for (i = 0; i < group_size; i++)\n+    VEC_safe_push (gimple, heap, tmp_stmts, NULL);\n+\n+  for (i = 0; VEC_iterate (gimple, SLP_TREE_SCALAR_STMTS (node), i, stmt); i++)\n+    {\n+      index = VEC_index (int, permutation, i);\n+      VEC_replace (gimple, tmp_stmts, index, stmt);\n+    }\n+\n+  VEC_free (gimple, heap, SLP_TREE_SCALAR_STMTS (node));\n+  SLP_TREE_SCALAR_STMTS (node) = tmp_stmts;\n+}\n+\n+\n /* Check if the required load permutation is supported.\n    LOAD_PERMUTATION contains a list of indices of the loads.\n    In SLP this permutation is relative to the order of strided stores that are\n@@ -796,9 +850,11 @@ static bool\n vect_supported_load_permutation_p (slp_instance slp_instn, int group_size,\n                                    VEC (int, heap) *load_permutation)\n {\n-  int i = 0, j, prev = -1, next, k;\n-  bool supported;\n+  int i = 0, j, prev = -1, next, k, number_of_groups;\n+  bool supported, bad_permutation = false;\n   sbitmap load_index;\n+  slp_tree node;\n+  gimple stmt;\n \n   /* FORNOW: permutations are only supported in SLP.  */\n   if (!slp_instn)\n@@ -811,9 +867,72 @@ vect_supported_load_permutation_p (slp_instance slp_instn, int group_size,\n         fprintf (vect_dump, \"%d \", next);\n     }\n \n+  /* In case of reduction every load permutation is allowed, since the order\n+     of the reduction statements is not important (as opposed to the case of\n+     strided stores). The only condition we need to check is that all the \n+     load nodes are of the same size and have the same permutation (and then\n+     rearrange all the nodes of the SLP instance according to this \n+     permutation).  */\n+\n+  /* Check that all the load nodes are of the same size.  */\n+  for (i = 0;\n+       VEC_iterate (slp_tree, SLP_INSTANCE_LOADS (slp_instn), i, node);\n+       i++)\n+    if (VEC_length (gimple, SLP_TREE_SCALAR_STMTS (node))\n+        != (unsigned) group_size)\n+      return false;\n+     \n+  node = SLP_INSTANCE_TREE (slp_instn);\n+  stmt = VEC_index (gimple, SLP_TREE_SCALAR_STMTS (node), 0);\n+  /* LOAD_PERMUTATION is a list of indices of all the loads of the SLP\n+     instance, not all the loads belong to the same node or interleaving\n+     group. Hence, we need to divide them into groups according to\n+     GROUP_SIZE.  */\n+  number_of_groups = VEC_length (int, load_permutation) / group_size;\n+\n+  /* Reduction (there are no data-refs in the root).  */\n+  if (!STMT_VINFO_DATA_REF (vinfo_for_stmt (stmt)))\n+    {\n+      int first_group_load_index;\n+\n+      /* Compare all the permutation sequences to the first one.  */\n+      for (i = 1; i < number_of_groups; i++)\n+        {\n+          k = 0;\n+          for (j = i * group_size; j < i * group_size + group_size; j++)\n+            {\n+              next = VEC_index (int, load_permutation, j);\n+              first_group_load_index = VEC_index (int, load_permutation, k);\n+\n+              if (next != first_group_load_index)\n+                {\n+                  bad_permutation = true;\n+                  break;\n+                }\n+\n+              k++;\n+            }\n+\n+          if (bad_permutation)\n+            break;\n+        }\n+\n+      if (!bad_permutation)\n+        {\n+          /* This permutaion is valid for reduction. Since the order of the\n+             statements in the nodes is not important unless they are memory\n+             accesses, we can rearrange the statements in all the nodes \n+             according to the order of the loads.  */\n+          vect_slp_rearrange_stmts (SLP_INSTANCE_TREE (slp_instn), group_size,\n+                                    load_permutation);\n+          VEC_free (int, heap, SLP_INSTANCE_LOAD_PERMUTATION (slp_instn));\n+          return true;\n+        }\n+    }\n+\n   /* FORNOW: the only supported permutation is 0..01..1.. of length equal to\n      GROUP_SIZE and where each sequence of same drs is of GROUP_SIZE length as\n-     well.  */\n+     well (unless it's reduction).  */\n   if (VEC_length (int, load_permutation)\n       != (unsigned int) (group_size * group_size))\n     return false;\n@@ -896,24 +1015,36 @@ vect_analyze_slp_instance (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo,\n   slp_tree node = XNEW (struct _slp_tree);\n   unsigned int group_size = DR_GROUP_SIZE (vinfo_for_stmt (stmt));\n   unsigned int unrolling_factor = 1, nunits;\n-  tree vectype, scalar_type;\n+  tree vectype, scalar_type = NULL_TREE;\n   gimple next;\n   unsigned int vectorization_factor = 0;\n-  int inside_cost = 0, outside_cost = 0, ncopies_for_cost;\n+  int inside_cost = 0, outside_cost = 0, ncopies_for_cost, i;\n   unsigned int max_nunits = 0;\n   VEC (int, heap) *load_permutation;\n   VEC (slp_tree, heap) *loads;\n+  struct data_reference *dr = STMT_VINFO_DATA_REF (vinfo_for_stmt (stmt));\n+\n+  if (dr)\n+    {\n+      scalar_type = TREE_TYPE (DR_REF (dr));\n+      vectype = get_vectype_for_scalar_type (scalar_type);\n+      group_size = DR_GROUP_SIZE (vinfo_for_stmt (stmt));\n+    }\n+  else\n+    {\n+      gcc_assert (loop_vinfo);\n+      vectype = STMT_VINFO_VECTYPE (vinfo_for_stmt (stmt));\n+      group_size = VEC_length (gimple, LOOP_VINFO_REDUCTIONS (loop_vinfo));\n+    }\n \n-  scalar_type = TREE_TYPE (DR_REF (STMT_VINFO_DATA_REF (\n-                                             vinfo_for_stmt (stmt))));\n-  vectype = get_vectype_for_scalar_type (scalar_type);\n   if (!vectype)\n     {\n       if (vect_print_dump_info (REPORT_SLP))\n         {\n           fprintf (vect_dump, \"Build SLP failed: unsupported data-type \");\n           print_generic_expr (vect_dump, scalar_type, TDF_SLIM);\n         }\n+\n       return false;\n     }\n \n@@ -938,11 +1069,29 @@ vect_analyze_slp_instance (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo,\n   /* Create a node (a root of the SLP tree) for the packed strided stores.  */\n   SLP_TREE_SCALAR_STMTS (node) = VEC_alloc (gimple, heap, group_size);\n   next = stmt;\n-  /* Collect the stores and store them in SLP_TREE_SCALAR_STMTS.  */\n-  while (next)\n+  if (dr)\n     {\n-      VEC_safe_push (gimple, heap, SLP_TREE_SCALAR_STMTS (node), next);\n-      next = DR_GROUP_NEXT_DR (vinfo_for_stmt (next));\n+      /* Collect the stores and store them in SLP_TREE_SCALAR_STMTS.  */\n+      while (next)\n+        {\n+          VEC_safe_push (gimple, heap, SLP_TREE_SCALAR_STMTS (node), next);\n+          next = DR_GROUP_NEXT_DR (vinfo_for_stmt (next));\n+        }\n+    }\n+  else\n+    {\n+      /* Collect reduction statements.  */\n+      for (i = 0; VEC_iterate (gimple, LOOP_VINFO_REDUCTIONS (loop_vinfo), i, \n+                               next); \n+           i++)\n+        {\n+          VEC_safe_push (gimple, heap, SLP_TREE_SCALAR_STMTS (node), next);\n+          if (vect_print_dump_info (REPORT_DETAILS))\n+            {\n+              fprintf (vect_dump, \"pushing reduction into node: \");\n+              print_gimple_stmt (vect_dump, next, 0, TDF_SLIM);\n+            }\n+        }\n     }\n \n   SLP_TREE_VEC_STMTS (node) = NULL;\n@@ -1035,18 +1184,22 @@ bool\n vect_analyze_slp (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo)\n {\n   unsigned int i;\n-  VEC (gimple, heap) *strided_stores;\n+  VEC (gimple, heap) *strided_stores, *reductions = NULL;\n   gimple store;\n   bool ok = false;\n \n   if (vect_print_dump_info (REPORT_SLP))\n     fprintf (vect_dump, \"=== vect_analyze_slp ===\");\n \n   if (loop_vinfo)\n-    strided_stores = LOOP_VINFO_STRIDED_STORES (loop_vinfo);\n+    {\n+      strided_stores = LOOP_VINFO_STRIDED_STORES (loop_vinfo);\n+      reductions = LOOP_VINFO_REDUCTIONS (loop_vinfo);\n+    }\n   else\n     strided_stores = BB_VINFO_STRIDED_STORES (bb_vinfo);\n \n+  /* Find SLP sequences starting from groups of strided stores.  */\n   for (i = 0; VEC_iterate (gimple, strided_stores, i, store); i++)\n     if (vect_analyze_slp_instance (loop_vinfo, bb_vinfo, store))\n       ok = true;\n@@ -1059,6 +1212,12 @@ vect_analyze_slp (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo)\n       return false;\n     }\n \n+  /* Find SLP sequences starting from groups of reductions.  */\n+  if (loop_vinfo &&  VEC_length (gimple, LOOP_VINFO_REDUCTIONS (loop_vinfo))\n+      && vect_analyze_slp_instance (loop_vinfo, bb_vinfo, \n+                                    VEC_index (gimple, reductions, 0)))\n+    ok = true;\n+\n   return true;\n }\n \n@@ -1120,7 +1279,10 @@ vect_detect_hybrid_slp_stmts (slp_tree node)\n \tif ((stmt_vinfo = vinfo_for_stmt (use_stmt))\n \t    && !STMT_SLP_TYPE (stmt_vinfo)\n             && (STMT_VINFO_RELEVANT (stmt_vinfo)\n-                || VECTORIZABLE_CYCLE_DEF (STMT_VINFO_DEF_TYPE (stmt_vinfo))))\n+                || VECTORIZABLE_CYCLE_DEF (STMT_VINFO_DEF_TYPE (stmt_vinfo)))\n+            && !(gimple_code (use_stmt) == GIMPLE_PHI\n+                 && STMT_VINFO_DEF_TYPE (vinfo_for_stmt (use_stmt)) \n+                     == vect_reduction_def))\n \t  vect_mark_slp_stmts (node, hybrid, i);\n \n   vect_detect_hybrid_slp_stmts (SLP_TREE_LEFT (node));\n@@ -1429,11 +1591,14 @@ vect_update_slp_costs_according_to_vf (loop_vec_info loop_vinfo)\n /* For constant and loop invariant defs of SLP_NODE this function returns\n    (vector) defs (VEC_OPRNDS) that will be used in the vectorized stmts.\n    OP_NUM determines if we gather defs for operand 0 or operand 1 of the scalar\n-   stmts. NUMBER_OF_VECTORS is the number of vector defs to create.  */\n+   stmts. NUMBER_OF_VECTORS is the number of vector defs to create.  \n+   REDUC_INDEX is the index of the reduction operand in the statements, unless\n+   it is -1.  */\n \n static void\n vect_get_constant_vectors (slp_tree slp_node, VEC(tree,heap) **vec_oprnds,\n-\t\t\t   unsigned int op_num, unsigned int number_of_vectors)\n+\t\t\t   unsigned int op_num, unsigned int number_of_vectors,\n+                           int reduc_index)\n {\n   VEC (gimple, heap) *stmts = SLP_TREE_SCALAR_STMTS (slp_node);\n   gimple stmt = VEC_index (gimple, stmts, 0);\n@@ -1449,6 +1614,50 @@ vect_get_constant_vectors (slp_tree slp_node, VEC(tree,heap) **vec_oprnds,\n   int number_of_copies = 1;\n   VEC (tree, heap) *voprnds = VEC_alloc (tree, heap, number_of_vectors);\n   bool constant_p, is_store;\n+  tree neutral_op = NULL;\n+\n+  if (STMT_VINFO_DEF_TYPE (stmt_vinfo) == vect_reduction_def)\n+    {\n+      enum tree_code code = gimple_assign_rhs_code (stmt);\n+      if (reduc_index == -1)\n+        {\n+          VEC_free (tree, heap, *vec_oprnds);\n+          return;\n+        }\n+\n+      op_num = reduc_index - 1;\n+      op = gimple_op (stmt, op_num + 1);\n+      /* For additional copies (see the explanation of NUMBER_OF_COPIES below)\n+         we need either neutral operands or the original operands. See\n+         get_initial_def_for_reduction() for details.  */\n+      switch (code)\n+        {\n+          case WIDEN_SUM_EXPR:\n+          case DOT_PROD_EXPR:\n+          case PLUS_EXPR:\n+          case MINUS_EXPR:\n+          case BIT_IOR_EXPR:\n+          case BIT_XOR_EXPR:\n+             if (SCALAR_FLOAT_TYPE_P (TREE_TYPE (op)))\n+               neutral_op = build_real (TREE_TYPE (op), dconst0);\n+             else\n+               neutral_op = build_int_cst (TREE_TYPE (op), 0);\n+\n+             break;\n+\n+          case MULT_EXPR:\n+          case BIT_AND_EXPR:\n+             if (SCALAR_FLOAT_TYPE_P (TREE_TYPE (op)))\n+               neutral_op = build_real (TREE_TYPE (op), dconst1);\n+             else\n+               neutral_op = build_int_cst (TREE_TYPE (op), 1);\n+\n+             break;\n+\n+          default:\n+             neutral_op = NULL;\n+        }\n+    }\n \n   if (STMT_VINFO_DATA_REF (stmt_vinfo))\n     {\n@@ -1499,6 +1708,19 @@ vect_get_constant_vectors (slp_tree slp_node, VEC(tree,heap) **vec_oprnds,\n           else\n             op = gimple_op (stmt, op_num + 1);\n \n+          if (reduc_index != -1)\n+            {\n+              struct loop *loop = (gimple_bb (stmt))->loop_father;\n+              gimple def_stmt = SSA_NAME_DEF_STMT (op);\n+\n+              gcc_assert (loop);\n+              /* Get the def before the loop.  */\n+              op = PHI_ARG_DEF_FROM_EDGE (def_stmt, \n+                                          loop_preheader_edge (loop));\n+              if (j != (number_of_copies - 1) && neutral_op)\n+                op = neutral_op;\n+            }\n+\n           /* Create 'vect_ = {op0,op1,...,opn}'.  */\n           t = tree_cons (NULL_TREE, op, t);\n \n@@ -1536,8 +1758,25 @@ vect_get_constant_vectors (slp_tree slp_node, VEC(tree,heap) **vec_oprnds,\n      to replicate the vectors.  */\n   while (number_of_vectors > VEC_length (tree, *vec_oprnds))\n     {\n-      for (i = 0; VEC_iterate (tree, *vec_oprnds, i, vop) && i < vec_num; i++)\n-        VEC_quick_push (tree, *vec_oprnds, vop);\n+      tree neutral_vec = NULL;\n+\n+      if (neutral_op)\n+        {\n+          if (!neutral_vec)\n+            {\n+              t = NULL;\n+              for (i = 0; i < (unsigned) nunits; i++)\n+                 t = tree_cons (NULL_TREE, neutral_op, t);\n+              neutral_vec = build_vector (vector_type, t);\n+            }\n+\n+          VEC_quick_push (tree, *vec_oprnds, neutral_vec);\n+        }\n+      else\n+        {\n+          for (i = 0; VEC_iterate (tree, *vec_oprnds, i, vop) && i < vec_num; i++)\n+            VEC_quick_push (tree, *vec_oprnds, vop);\n+        }\n     }\n }\n \n@@ -1576,7 +1815,7 @@ vect_get_slp_vect_defs (slp_tree slp_node, VEC (tree,heap) **vec_oprnds)\n \n void\n vect_get_slp_defs (slp_tree slp_node, VEC (tree,heap) **vec_oprnds0,\n-                   VEC (tree,heap) **vec_oprnds1)\n+                   VEC (tree,heap) **vec_oprnds1, int reduc_index)\n {\n   gimple first_stmt;\n   enum tree_code code;\n@@ -1607,19 +1846,26 @@ vect_get_slp_defs (slp_tree slp_node, VEC (tree,heap) **vec_oprnds0,\n   *vec_oprnds0 = VEC_alloc (tree, heap, number_of_vects);\n \n   /* SLP_NODE corresponds either to a group of stores or to a group of\n-     unary/binary operations. We don't call this function for loads.  */\n-  if (SLP_TREE_LEFT (slp_node))\n+     unary/binary operations. We don't call this function for loads.  \n+     For reduction defs we call vect_get_constant_vectors(), since we are\n+     looking for initial loop invariant values.  */\n+  if (SLP_TREE_LEFT (slp_node) && reduc_index == -1)\n     /* The defs are already vectorized.  */\n     vect_get_slp_vect_defs (SLP_TREE_LEFT (slp_node), vec_oprnds0);\n   else\n     /* Build vectors from scalar defs.  */\n-    vect_get_constant_vectors (slp_node, vec_oprnds0, 0, number_of_vects);\n+    vect_get_constant_vectors (slp_node, vec_oprnds0, 0, number_of_vects,\n+                               reduc_index);\n \n   if (STMT_VINFO_DATA_REF (vinfo_for_stmt (first_stmt)))\n     /* Since we don't call this function with loads, this is a group of\n        stores.  */\n     return;\n \n+  /* For reductions, we only need initial values.  */\n+  if (reduc_index != -1)\n+    return;\n+\n   code = gimple_assign_rhs_code (first_stmt);\n   if (get_gimple_rhs_class (code) != GIMPLE_BINARY_RHS || !vec_oprnds1)\n     return;\n@@ -1638,7 +1884,7 @@ vect_get_slp_defs (slp_tree slp_node, VEC (tree,heap) **vec_oprnds0,\n     vect_get_slp_vect_defs (SLP_TREE_RIGHT (slp_node), vec_oprnds1);\n   else\n     /* Build vectors from scalar defs.  */\n-    vect_get_constant_vectors (slp_node, vec_oprnds1, 1, number_of_vects);\n+    vect_get_constant_vectors (slp_node, vec_oprnds1, 1, number_of_vects, -1);\n }\n \n \n@@ -2027,22 +2273,7 @@ vect_schedule_slp_instance (slp_tree node, slp_instance instance,\n     si = gsi_for_stmt (stmt);\n \n   is_store = vect_transform_stmt (stmt, &si, &strided_store, node, instance);\n-  if (is_store)\n-    {\n-      if (DR_GROUP_FIRST_DR (stmt_info))\n-\t/* If IS_STORE is TRUE, the vectorization of the\n-\t   interleaving chain was completed - free all the stores in\n-\t   the chain.  */\n-\tvect_remove_stores (DR_GROUP_FIRST_DR (stmt_info));\n-      else\n-\t/* FORNOW: SLP originates only from strided stores.  */\n-\tgcc_unreachable ();\n-\n-      return true;\n-    }\n-\n-  /* FORNOW: SLP originates only from strided stores.  */\n-  return false;\n+  return is_store;\n }\n \n \n@@ -2075,6 +2306,26 @@ vect_schedule_slp (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo)\n \tfprintf (vect_dump, \"vectorizing stmts using SLP.\");\n     }\n \n+  for (i = 0; VEC_iterate (slp_instance, slp_instances, i, instance); i++)\n+    {\n+      slp_tree root = SLP_INSTANCE_TREE (instance);\n+      gimple store;\n+      unsigned int j;\n+      gimple_stmt_iterator gsi;\n+\n+      for (j = 0; VEC_iterate (gimple, SLP_TREE_SCALAR_STMTS (root), j, store)\n+                  && j < SLP_INSTANCE_GROUP_SIZE (instance); j++)\n+        {\n+          if (!STMT_VINFO_DATA_REF (vinfo_for_stmt (store)))\n+            break;\n+\n+          /* Free the attached stmt_vec_info and remove the stmt.  */\n+          gsi = gsi_for_stmt (store);\n+          gsi_remove (&gsi, true);\n+          free_stmt_vec_info (store);\n+        }\n+    }\n+\n   return is_store;\n }\n "}, {"sha": "988749b792f7b92edf34cec4936eab28c3cddefa", "filename": "gcc/tree-vect-stmts.c", "status": "modified", "additions": 6, "deletions": 7, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftree-vect-stmts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftree-vect-stmts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-stmts.c?ref=b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "patch": "@@ -1134,7 +1134,7 @@ vect_get_vec_defs (tree op0, tree op1, gimple stmt,\n \t\t   slp_tree slp_node)\n {\n   if (slp_node)\n-    vect_get_slp_defs (slp_node, vec_oprnds0, vec_oprnds1);\n+    vect_get_slp_defs (slp_node, vec_oprnds0, vec_oprnds1, -1);\n   else\n     {\n       tree vec_oprnd;\n@@ -2519,7 +2519,7 @@ vectorizable_type_demotion (gimple stmt, gimple_stmt_iterator *gsi,\n     {\n       /* Handle uses.  */\n       if (slp_node)\n-        vect_get_slp_defs (slp_node, &vec_oprnds0, NULL);\n+        vect_get_slp_defs (slp_node, &vec_oprnds0, NULL, -1);\n       else\n         {\n           VEC_free (tree, heap, vec_oprnds0);\n@@ -2819,7 +2819,7 @@ vectorizable_type_promotion (gimple stmt, gimple_stmt_iterator *gsi,\n       if (j == 0)\n         {\n           if (slp_node)\n-              vect_get_slp_defs (slp_node, &vec_oprnds0, &vec_oprnds1);\n+              vect_get_slp_defs (slp_node, &vec_oprnds0, &vec_oprnds1, -1);\n           else\n             {\n               vec_oprnd0 = vect_get_vec_def_for_operand (op0, stmt, NULL);\n@@ -3105,7 +3105,7 @@ vectorizable_store (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n           if (slp)\n             {\n \t      /* Get vectorized arguments for SLP_NODE.  */\n-              vect_get_slp_defs (slp_node, &vec_oprnds, NULL);\n+              vect_get_slp_defs (slp_node, &vec_oprnds, NULL, -1);\n \n               vec_oprnd = VEC_index (tree, vec_oprnds, 0);\n             }\n@@ -4049,7 +4049,7 @@ vect_analyze_stmt (gimple stmt, bool *need_to_vectorize, slp_tree node)\n             || vectorizable_load (stmt, NULL, NULL, NULL, NULL)\n             || vectorizable_call (stmt, NULL, NULL)\n             || vectorizable_store (stmt, NULL, NULL, NULL)\n-            || vectorizable_reduction (stmt, NULL, NULL)\n+            || vectorizable_reduction (stmt, NULL, NULL, NULL)\n             || vectorizable_condition (stmt, NULL, NULL, NULL, 0));\n     else\n       {\n@@ -4201,8 +4201,7 @@ vect_transform_stmt (gimple stmt, gimple_stmt_iterator *gsi,\n       break;\n \n     case reduc_vec_info_type:\n-      gcc_assert (!slp_node);\n-      done = vectorizable_reduction (stmt, gsi, &vec_stmt);\n+      done = vectorizable_reduction (stmt, gsi, &vec_stmt, slp_node);\n       gcc_assert (done);\n       break;\n "}, {"sha": "bd43a4bc17315809bc382dd4a66bfe7e17aae201", "filename": "gcc/tree-vectorizer.h", "status": "modified", "additions": 7, "deletions": 2, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftree-vectorizer.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d/gcc%2Ftree-vectorizer.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vectorizer.h?ref=b5aeb3bb3e9d1a0ce78fe2d7de9f510a7413605d", "patch": "@@ -242,6 +242,9 @@ typedef struct _loop_vec_info {\n   /* The unrolling factor needed to SLP the loop. In case of that pure SLP is\n      applied to the loop, i.e., no unrolling is needed, this is 1.  */\n   unsigned slp_unrolling_factor;\n+\n+  /* Reduction cycles detected in the loop. Used in loop-aware SLP.  */\n+  VEC (gimple, heap) *reductions;\n } *loop_vec_info;\n \n /* Access Functions.  */\n@@ -266,6 +269,7 @@ typedef struct _loop_vec_info {\n #define LOOP_VINFO_STRIDED_STORES(L)       (L)->strided_stores\n #define LOOP_VINFO_SLP_INSTANCES(L)        (L)->slp_instances\n #define LOOP_VINFO_SLP_UNROLLING_FACTOR(L) (L)->slp_unrolling_factor\n+#define LOOP_VINFO_REDUCTIONS(L)           (L)->reductions\n \n #define LOOP_REQUIRES_VERSIONING_FOR_ALIGNMENT(L) \\\n VEC_length (gimple, (L)->may_misalign_stmts) > 0\n@@ -844,7 +848,8 @@ extern void vect_transform_loop (loop_vec_info);\n extern loop_vec_info vect_analyze_loop_form (struct loop *);\n extern bool vectorizable_live_operation (gimple, gimple_stmt_iterator *,\n                                          gimple *);\n-extern bool vectorizable_reduction (gimple, gimple_stmt_iterator *, gimple *);\n+extern bool vectorizable_reduction (gimple, gimple_stmt_iterator *, gimple *,\n+                                    slp_tree);\n extern bool vectorizable_induction (gimple, gimple_stmt_iterator *, gimple *);\n extern int vect_estimate_min_profitable_iters (loop_vec_info);\n extern tree get_initial_def_for_reduction (gimple, tree, tree *);\n@@ -862,7 +867,7 @@ extern bool vect_analyze_slp (loop_vec_info, bb_vec_info);\n extern void vect_make_slp_decision (loop_vec_info);\n extern void vect_detect_hybrid_slp (loop_vec_info);\n extern void vect_get_slp_defs (slp_tree, VEC (tree,heap) **,\n-                               VEC (tree,heap) **);\n+                               VEC (tree,heap) **, int);\n extern LOC find_bb_location (basic_block);\n extern bb_vec_info vect_slp_analyze_bb (basic_block);\n extern void vect_slp_transform_bb (basic_block);"}]}