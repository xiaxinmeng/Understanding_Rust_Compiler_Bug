{"sha": "cdc1afa3c04e6ddf2d2119a4144754cabcfe419a", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6Y2RjMWFmYTNjMDRlNmRkZjJkMjExOWE0MTQ0NzU0Y2FiY2ZlNDE5YQ==", "commit": {"author": {"name": "James Greenhalgh", "email": "james.greenhalgh@arm.com", "date": "2015-10-01T09:33:40Z"}, "committer": {"name": "James Greenhalgh", "email": "jgreenhalgh@gcc.gnu.org", "date": "2015-10-01T09:33:40Z"}, "message": "[Patch 2/2 ARM/AArch64] Add a new Cortex-A53 scheduling model\n\n\t* config/arm/aarch-common-protos.h\n\t(aarch_accumulator_forwarding): New.\n\t(aarch_forward_to_shift_is_not_shifted_reg): Likewise.\n\t* config/arm/aarch-common.c (aarch_accumulator_forwarding): New.\n\t(aarch_forward_to_shift_is_not_shifted_reg): Liekwise.\n\t* config/arm/cortex-a53.md: Rewrite.\n\nFrom-SVN: r228324", "tree": {"sha": "a761d52740934b009615ba7ff8c4bc9430922f59", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/a761d52740934b009615ba7ff8c4bc9430922f59"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/cdc1afa3c04e6ddf2d2119a4144754cabcfe419a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/cdc1afa3c04e6ddf2d2119a4144754cabcfe419a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/cdc1afa3c04e6ddf2d2119a4144754cabcfe419a", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/cdc1afa3c04e6ddf2d2119a4144754cabcfe419a/comments", "author": {"login": "jgreenhalgh-arm", "id": 6104025, "node_id": "MDQ6VXNlcjYxMDQwMjU=", "avatar_url": "https://avatars.githubusercontent.com/u/6104025?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jgreenhalgh-arm", "html_url": "https://github.com/jgreenhalgh-arm", "followers_url": "https://api.github.com/users/jgreenhalgh-arm/followers", "following_url": "https://api.github.com/users/jgreenhalgh-arm/following{/other_user}", "gists_url": "https://api.github.com/users/jgreenhalgh-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/jgreenhalgh-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jgreenhalgh-arm/subscriptions", "organizations_url": "https://api.github.com/users/jgreenhalgh-arm/orgs", "repos_url": "https://api.github.com/users/jgreenhalgh-arm/repos", "events_url": "https://api.github.com/users/jgreenhalgh-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/jgreenhalgh-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "34050b6bee181a12099a9bc31a4d25469573bc6d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/34050b6bee181a12099a9bc31a4d25469573bc6d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/34050b6bee181a12099a9bc31a4d25469573bc6d"}], "stats": {"total": 874, "additions": 673, "deletions": 201}, "files": [{"sha": "8fdc84d545491be29d989edc5b288a587b59d9da", "filename": "gcc/ChangeLog", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cdc1afa3c04e6ddf2d2119a4144754cabcfe419a/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cdc1afa3c04e6ddf2d2119a4144754cabcfe419a/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=cdc1afa3c04e6ddf2d2119a4144754cabcfe419a", "patch": "@@ -1,3 +1,12 @@\n+2015-10-01  James Greenhalgh  <james.greenhalgh@arm.com>\n+\n+\t* config/arm/aarch-common-protos.h\n+\t(aarch_accumulator_forwarding): New.\n+\t(aarch_forward_to_shift_is_not_shifted_reg): Likewise.\n+\t* config/arm/aarch-common.c (aarch_accumulator_forwarding): New.\n+\t(aarch_forward_to_shift_is_not_shifted_reg): Liekwise.\n+\t* config/arm/cortex-a53.md: Rewrite.\n+\n 2015-10-01  Richard Biener  <rguenther@suse.de>\n \n \t* gimple-match.h (mprts_hook): Declare."}, {"sha": "348ae7495fe7dff01f896ffce68dfc9597e6995f", "filename": "gcc/config/arm/aarch-common-protos.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cdc1afa3c04e6ddf2d2119a4144754cabcfe419a/gcc%2Fconfig%2Farm%2Faarch-common-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cdc1afa3c04e6ddf2d2119a4144754cabcfe419a/gcc%2Fconfig%2Farm%2Faarch-common-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Faarch-common-protos.h?ref=cdc1afa3c04e6ddf2d2119a4144754cabcfe419a", "patch": "@@ -23,7 +23,9 @@\n #ifndef GCC_AARCH_COMMON_PROTOS_H\n #define GCC_AARCH_COMMON_PROTOS_H\n \n+extern int aarch_accumulator_forwarding (rtx_insn *, rtx_insn *);\n extern int aarch_crypto_can_dual_issue (rtx_insn *, rtx_insn *);\n+extern int aarch_forward_to_shift_is_not_shifted_reg (rtx_insn *, rtx_insn *);\n extern bool aarch_rev16_p (rtx);\n extern bool aarch_rev16_shleft_mask_imm_p (rtx, machine_mode);\n extern bool aarch_rev16_shright_mask_imm_p (rtx, machine_mode);"}, {"sha": "43579d8be70b8a9084bdf882aac5cdabc504d855", "filename": "gcc/config/arm/aarch-common.c", "status": "modified", "additions": 106, "deletions": 0, "changes": 106, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cdc1afa3c04e6ddf2d2119a4144754cabcfe419a/gcc%2Fconfig%2Farm%2Faarch-common.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cdc1afa3c04e6ddf2d2119a4144754cabcfe419a/gcc%2Fconfig%2Farm%2Faarch-common.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Faarch-common.c?ref=cdc1afa3c04e6ddf2d2119a4144754cabcfe419a", "patch": "@@ -394,6 +394,112 @@ arm_mac_accumulator_is_result (rtx producer, rtx consumer)\n           && !reg_overlap_mentioned_p (result, op1));\n }\n \n+/* Return non-zero if the destination of PRODUCER feeds the accumulator\n+   operand of an MLA-like operation.  */\n+\n+int\n+aarch_accumulator_forwarding (rtx_insn *producer, rtx_insn *consumer)\n+{\n+  rtx producer_set = single_set (producer);\n+  rtx consumer_set = single_set (consumer);\n+\n+  /* We are looking for a SET feeding a SET.  */\n+  if (!producer_set || !consumer_set)\n+    return 0;\n+\n+  rtx dest = SET_DEST (producer_set);\n+  rtx mla = SET_SRC (consumer_set);\n+\n+  /* We're looking for a register SET.  */\n+  if (!REG_P (dest))\n+    return 0;\n+\n+  rtx accumulator;\n+\n+  /* Strip a zero_extend.  */\n+  if (GET_CODE (mla) == ZERO_EXTEND)\n+    mla = XEXP (mla, 0);\n+\n+  switch (GET_CODE (mla))\n+    {\n+    case PLUS:\n+      /* Possibly an MADD.  */\n+      if (GET_CODE (XEXP (mla, 0)) == MULT)\n+\taccumulator = XEXP (mla, 1);\n+      else\n+\treturn 0;\n+      break;\n+    case MINUS:\n+      /* Possibly an MSUB.  */\n+      if (GET_CODE (XEXP (mla, 1)) == MULT)\n+\taccumulator = XEXP (mla, 0);\n+      else\n+\treturn 0;\n+      break;\n+    case FMA:\n+\t{\n+\t  /* Possibly an FMADD/FMSUB/FNMADD/FNMSUB.  */\n+\t  if (REG_P (XEXP (mla, 1))\n+\t      && REG_P (XEXP (mla, 2))\n+\t      && (REG_P (XEXP (mla, 0))\n+\t\t  || GET_CODE (XEXP (mla, 0)) == NEG))\n+\n+\t    {\n+\t      /* FMADD/FMSUB.  */\n+\t      accumulator = XEXP (mla, 2);\n+\t    }\n+\t  else if (REG_P (XEXP (mla, 1))\n+\t\t   && GET_CODE (XEXP (mla, 2)) == NEG\n+\t\t   && (REG_P (XEXP (mla, 0))\n+\t\t       || GET_CODE (XEXP (mla, 0)) == NEG))\n+\t    {\n+\t      /* FNMADD/FNMSUB.  */\n+\t      accumulator = XEXP (XEXP (mla, 2), 0);\n+\t    }\n+\t  else\n+\t    return 0;\n+\t  break;\n+\t}\n+      default:\n+\t/* Not an MLA-like operation.  */\n+\treturn 0;\n+    }\n+\n+  return (REGNO (dest) == REGNO (accumulator));\n+}\n+\n+/* Return nonzero if the CONSUMER instruction is some sort of\n+   arithmetic or logic + shift operation, and the register we are\n+   writing in PRODUCER is not used in a register shift by register\n+   operation.  */\n+\n+int\n+aarch_forward_to_shift_is_not_shifted_reg (rtx_insn *producer,\n+\t\t\t\t\t   rtx_insn *consumer)\n+{\n+  rtx value, op;\n+  rtx early_op;\n+\n+  if (!arm_get_set_operands (producer, consumer, &value, &op))\n+    return 0;\n+\n+  if ((early_op = arm_find_shift_sub_rtx (op)))\n+    {\n+      if (REG_P (early_op))\n+\tearly_op = op;\n+\n+      /* Any other canonicalisation of a shift is a shift-by-constant\n+\t so we don't care.  */\n+      if (GET_CODE (early_op) == ASHIFT)\n+\treturn (!REG_P (XEXP (early_op, 0))\n+\t\t|| !REG_P (XEXP (early_op, 1)));\n+      else\n+\treturn 1;\n+    }\n+\n+  return 0;\n+}\n+\n /* Return non-zero if the consumer (a multiply-accumulate instruction)\n    has an accumulator dependency on the result of the producer (a\n    multiplication instruction) and no other dependency on that result.  */"}, {"sha": "4632cd88f2388d7e19ebd7e8459badade6ea67eb", "filename": "gcc/config/arm/cortex-a53.md", "status": "modified", "additions": 556, "deletions": 201, "changes": 757, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/cdc1afa3c04e6ddf2d2119a4144754cabcfe419a/gcc%2Fconfig%2Farm%2Fcortex-a53.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/cdc1afa3c04e6ddf2d2119a4144754cabcfe419a/gcc%2Fconfig%2Farm%2Fcortex-a53.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fcortex-a53.md?ref=cdc1afa3c04e6ddf2d2119a4144754cabcfe419a", "patch": "@@ -22,345 +22,700 @@\n (define_automaton \"cortex_a53\")\n \n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n-;; Functional units.\n+;; General-purpose functional units.\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n-;; There are two main integer execution pipelines, described as\n-;; slot 0 and issue slot 1.\n+;; We use slot0 and slot1 to model constraints on which instructions may\n+;; dual-issue.\n \n (define_cpu_unit \"cortex_a53_slot0\" \"cortex_a53\")\n (define_cpu_unit \"cortex_a53_slot1\" \"cortex_a53\")\n \n-(define_reservation \"cortex_a53_slot_any\" \"cortex_a53_slot0|cortex_a53_slot1\")\n-(define_reservation \"cortex_a53_single_issue\" \"cortex_a53_slot0+cortex_a53_slot1\")\n+(define_reservation \"cortex_a53_slot_any\"\n+\t\t    \"cortex_a53_slot0\\\n+\t\t     |cortex_a53_slot1\")\n \n-;; The load/store pipeline.  Load/store instructions can dual-issue from\n-;; either pipeline, but two load/stores cannot simultaneously issue.\n+(define_reservation \"cortex_a53_single_issue\"\n+\t\t    \"cortex_a53_slot0\\\n+\t\t     +cortex_a53_slot1\")\n \n-(define_cpu_unit \"cortex_a53_ls\" \"cortex_a53\")\n-\n-;; The store pipeline.  Shared between both execution pipelines.\n+;; Used to model load and store pipelines.  Load/store instructions\n+;; can dual-issue with other instructions, but two load/stores cannot\n+;; simultaneously issue.\n \n (define_cpu_unit \"cortex_a53_store\" \"cortex_a53\")\n+(define_cpu_unit \"cortex_a53_load\" \"cortex_a53\")\n+(define_cpu_unit \"cortex_a53_ls_agen\" \"cortex_a53\")\n \n-;; The branch pipeline.  Branches can dual-issue with other instructions\n-;; (except when those instructions take multiple cycles to issue).\n+;; Used to model a branch pipeline.  Branches can dual-issue with other\n+;; instructions (except when those instructions take multiple cycles\n+;; to issue).\n \n (define_cpu_unit \"cortex_a53_branch\" \"cortex_a53\")\n \n-;; The integer divider.\n+;; Used to model an integer divide pipeline.\n \n (define_cpu_unit \"cortex_a53_idiv\" \"cortex_a53\")\n \n-;; The floating-point add pipeline used to model the usage\n-;; of the add pipeline by fmac instructions.\n-\n-(define_cpu_unit \"cortex_a53_fpadd_pipe\" \"cortex_a53\")\n+;; Used to model an integer multiply/multiply-accumulate pipeline.\n \n-;; Floating-point div/sqrt (long latency, out-of-order completion).\n+(define_cpu_unit \"cortex_a53_imul\" \"cortex_a53\")\n \n-(define_cpu_unit \"cortex_a53_fp_div_sqrt\" \"cortex_a53\")\n+;; Model general structural hazards, for wherever we need them.\n \n-;; The Advanced SIMD pipelines.\n-\n-(define_cpu_unit \"cortex_a53_simd0\" \"cortex_a53\")\n-(define_cpu_unit \"cortex_a53_simd1\" \"cortex_a53\")\n+(define_cpu_unit \"cortex_a53_hazard\" \"cortex_a53\")\n \n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n ;; ALU instructions.\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n-(define_insn_reservation \"cortex_a53_alu\" 2\n+(define_insn_reservation \"cortex_a53_shift\" 2\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"alu_imm,alus_imm,logic_imm,logics_imm,\\\n-                        alu_sreg,alus_sreg,logic_reg,logics_reg,\\\n-                        adc_imm,adcs_imm,adc_reg,adcs_reg,\\\n-                        adr,bfm,csel,clz,rbit,rev,alu_dsp_reg,\\\n-                        rotate_imm,shift_imm,shift_reg,\\\n-                        mov_imm,mov_reg,mvn_imm,mvn_reg,\\\n-                        mrs,multiple,no_insn\"))\n+       (eq_attr \"type\" \"adr,shift_imm,shift_reg,mov_imm,mvn_imm\"))\n   \"cortex_a53_slot_any\")\n \n-(define_insn_reservation \"cortex_a53_alu_shift\" 2\n+(define_insn_reservation \"cortex_a53_alu_rotate_imm\" 2\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"alu_shift_imm,alus_shift_imm,\\\n-                        crc,logic_shift_imm,logics_shift_imm,\\\n-                        alu_ext,alus_ext,alu_shift_reg,alus_shift_reg,\\\n-                        logic_shift_reg,logics_shift_reg,\\\n-                        extend,mov_shift,mov_shift_reg,\\\n-                        mvn_shift,mvn_shift_reg\"))\n-  \"cortex_a53_slot_any\")\n+       (eq_attr \"type\" \"rotate_imm\"))\n+  \"(cortex_a53_slot1)\n+   | (cortex_a53_single_issue)\")\n \n-;; Forwarding path for unshifted operands.\n-\n-(define_bypass 1 \"cortex_a53_alu,cortex_a53_alu_shift\"\n-  \"cortex_a53_alu\")\n+(define_insn_reservation \"cortex_a53_alu\" 3\n+  (and (eq_attr \"tune\" \"cortexa53\")\n+       (eq_attr \"type\" \"alu_imm,alus_imm,logic_imm,logics_imm,\n+\t\t\talu_sreg,alus_sreg,logic_reg,logics_reg,\n+\t\t\tadc_imm,adcs_imm,adc_reg,adcs_reg,\n+\t\t\tbfm,csel,clz,rbit,rev,alu_dsp_reg,\n+\t\t\tmov_reg,mvn_reg,\n+\t\t\tmrs,multiple,no_insn\"))\n+  \"cortex_a53_slot_any\")\n \n-(define_bypass 1 \"cortex_a53_alu,cortex_a53_alu_shift\"\n-  \"cortex_a53_alu_shift\"\n-  \"arm_no_early_alu_shift_dep\")\n+(define_insn_reservation \"cortex_a53_alu_shift\" 3\n+  (and (eq_attr \"tune\" \"cortexa53\")\n+       (eq_attr \"type\" \"alu_shift_imm,alus_shift_imm,\n+\t\t\tcrc,logic_shift_imm,logics_shift_imm,\n+\t\t\talu_ext,alus_ext,\n+\t\t\textend,mov_shift,mvn_shift\"))\n+  \"cortex_a53_slot_any\")\n \n-;; The multiplier pipeline can forward results so there's no need to specify\n-;; bypasses. Multiplies can only single-issue currently.\n+(define_insn_reservation \"cortex_a53_alu_shift_reg\" 3\n+  (and (eq_attr \"tune\" \"cortexa53\")\n+       (eq_attr \"type\" \"alu_shift_reg,alus_shift_reg,\n+\t\t\tlogic_shift_reg,logics_shift_reg,\n+\t\t\tmov_shift_reg,mvn_shift_reg\"))\n+  \"cortex_a53_slot_any+cortex_a53_hazard\")\n \n (define_insn_reservation \"cortex_a53_mul\" 3\n   (and (eq_attr \"tune\" \"cortexa53\")\n        (ior (eq_attr \"mul32\" \"yes\")\n-            (eq_attr \"mul64\" \"yes\")))\n-  \"cortex_a53_single_issue\")\n-\n-;; A multiply with a single-register result or an MLA, followed by an\n-;; MLA with an accumulator dependency, has its result forwarded so two\n-;; such instructions can issue back-to-back.\n-\n-(define_bypass 1 \"cortex_a53_mul\"\n-               \"cortex_a53_mul\"\n-               \"arm_mac_accumulator_is_mul_result\")\n+\t    (eq_attr \"mul64\" \"yes\")))\n+  \"cortex_a53_slot_any+cortex_a53_imul\")\n \n-;; Punt with a high enough latency for divides.\n-(define_insn_reservation \"cortex_a53_udiv\" 8\n-  (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"udiv\"))\n-  \"(cortex_a53_slot0+cortex_a53_idiv),cortex_a53_idiv*7\")\n+;; From the perspective of the GCC scheduling state machine, if we wish to\n+;; model an instruction as serialising other instructions, we are best to do\n+;; so by modelling it as taking very few cycles.  Scheduling many other\n+;; instructions underneath it at the cost of freedom to pick from the\n+;; ready list is likely to hurt us more than it helps.  However, we do\n+;; want to model some resource and latency cost for divide instructions in\n+;; order to avoid divides ending up too lumpy.\n \n-(define_insn_reservation \"cortex_a53_sdiv\" 9\n+(define_insn_reservation \"cortex_a53_div\" 4\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"sdiv\"))\n-  \"(cortex_a53_slot0+cortex_a53_idiv),cortex_a53_idiv*8\")\n-\n-\n-(define_bypass 2 \"cortex_a53_mul,cortex_a53_udiv,cortex_a53_sdiv\"\n-               \"cortex_a53_alu\")\n-(define_bypass 2 \"cortex_a53_mul,cortex_a53_udiv,cortex_a53_sdiv\"\n-               \"cortex_a53_alu_shift\"\n-               \"arm_no_early_alu_shift_dep\")\n+       (eq_attr \"type\" \"udiv,sdiv\"))\n+  \"cortex_a53_slot0,cortex_a53_idiv*2\")\n \n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n ;; Load/store instructions.\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n-;; Address-generation happens in the issue stage.\n+;; TODO: load<n> is not prescriptive about how much data is to be loaded.\n+;; This is most obvious for LDRD from AArch32 and LDP (X register) from\n+;; AArch64, both are tagged load2 but LDP will load 128-bits compared to\n+;; LDRD which is 64-bits.\n+;;\n+;; For the below, we assume AArch64 X-registers for load2, and AArch32\n+;; registers for load3/load4.\n \n-(define_insn_reservation \"cortex_a53_load1\" 3\n+(define_insn_reservation \"cortex_a53_load1\" 4\n   (and (eq_attr \"tune\" \"cortexa53\")\n        (eq_attr \"type\" \"load_byte,load1,load_acq\"))\n-  \"cortex_a53_slot_any+cortex_a53_ls\")\n+  \"cortex_a53_slot_any+cortex_a53_ls_agen,\n+   cortex_a53_load\")\n \n (define_insn_reservation \"cortex_a53_store1\" 2\n   (and (eq_attr \"tune\" \"cortexa53\")\n        (eq_attr \"type\" \"store1,store_rel\"))\n-  \"cortex_a53_slot_any+cortex_a53_ls+cortex_a53_store\")\n+  \"cortex_a53_slot_any+cortex_a53_ls_agen,\n+   cortex_a53_store\")\n \n-(define_insn_reservation \"cortex_a53_load2\" 3\n+;; Model AArch64-sized LDP Xm, Xn, [Xa]\n+\n+(define_insn_reservation \"cortex_a53_load2\" 4\n   (and (eq_attr \"tune\" \"cortexa53\")\n        (eq_attr \"type\" \"load2\"))\n-  \"cortex_a53_single_issue+cortex_a53_ls\")\n+  \"cortex_a53_single_issue+cortex_a53_ls_agen,\n+   cortex_a53_load+cortex_a53_slot0,\n+   cortex_a53_load\")\n \n (define_insn_reservation \"cortex_a53_store2\" 2\n   (and (eq_attr \"tune\" \"cortexa53\")\n        (eq_attr \"type\" \"store2\"))\n-  \"cortex_a53_single_issue+cortex_a53_ls+cortex_a53_store\")\n+  \"cortex_a53_slot_any+cortex_a53_ls_agen,\n+   cortex_a53_store\")\n+\n+;; Model AArch32-sized LDM Ra, {Rm, Rn, Ro}\n \n-(define_insn_reservation \"cortex_a53_load3plus\" 4\n+(define_insn_reservation \"cortex_a53_load3plus\" 6\n   (and (eq_attr \"tune\" \"cortexa53\")\n        (eq_attr \"type\" \"load3,load4\"))\n-  \"(cortex_a53_single_issue+cortex_a53_ls)*2\")\n+  \"cortex_a53_single_issue+cortex_a53_ls_agen,\n+   cortex_a53_load+cortex_a53_slot0,\n+   cortex_a53_load\")\n \n-(define_insn_reservation \"cortex_a53_store3plus\" 3\n+(define_insn_reservation \"cortex_a53_store3plus\" 2\n   (and (eq_attr \"tune\" \"cortexa53\")\n        (eq_attr \"type\" \"store3,store4\"))\n-  \"(cortex_a53_single_issue+cortex_a53_ls+cortex_a53_store)*2\")\n-\n-;; Load/store addresses are required early in Issue.\n-(define_bypass 3 \"cortex_a53_load1,cortex_a53_load2,cortex_a53_load3plus,cortex_a53_alu,cortex_a53_alu_shift\"\n-                 \"cortex_a53_load*\"\n-                 \"arm_early_load_addr_dep\")\n-(define_bypass 3 \"cortex_a53_load1,cortex_a53_load2,cortex_a53_load3plus,cortex_a53_alu,cortex_a53_alu_shift\"\n-                 \"cortex_a53_store*\"\n-                 \"arm_early_store_addr_dep\")\n-\n-;; Load data can forward in the ALU pipeline\n-(define_bypass 2 \"cortex_a53_load1,cortex_a53_load2\"\n-               \"cortex_a53_alu\")\n-(define_bypass 2 \"cortex_a53_load1,cortex_a53_load2\"\n-               \"cortex_a53_alu_shift\"\n-               \"arm_no_early_alu_shift_dep\")\n-\n-;; ALU ops can forward to stores.\n-(define_bypass 0 \"cortex_a53_alu,cortex_a53_alu_shift\"\n-                 \"cortex_a53_store1,cortex_a53_store2,cortex_a53_store3plus\"\n-                 \"arm_no_early_store_addr_dep\")\n-\n-(define_bypass 1 \"cortex_a53_mul,cortex_a53_udiv,cortex_a53_sdiv,cortex_a53_load1,cortex_a53_load2,cortex_a53_load3plus\"\n-                 \"cortex_a53_store1,cortex_a53_store2,cortex_a53_store3plus\"\n-                 \"arm_no_early_store_addr_dep\")\n+  \"cortex_a53_slot_any+cortex_a53_ls_agen,\n+   cortex_a53_store+cortex_a53_slot0,\n+   cortex_a53_store\")\n \n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n ;; Branches.\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n-;; Currently models all branches as dual-issuable from either execution\n-;; slot, which isn't true for all cases. We still need to model indirect\n-;; branches.\n+;; Model all branches as dual-issuable from either execution, which\n+;; is not strictly true for all cases (indirect branches).\n \n (define_insn_reservation \"cortex_a53_branch\" 0\n   (and (eq_attr \"tune\" \"cortexa53\")\n        (eq_attr \"type\" \"branch,call\"))\n-  \"cortex_a53_slot_any+cortex_a53_branch\")\n+  \"cortex_a53_slot_any,cortex_a53_branch\")\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; General-purpose register bypasses\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+;; Model bypasses for unshifted operands to ALU instructions.\n+\n+(define_bypass 1 \"cortex_a53_shift\"\n+\t\t \"cortex_a53_shift\")\n+\n+(define_bypass 1 \"cortex_a53_alu,\n+\t\t  cortex_a53_alu_shift*,\n+\t\t  cortex_a53_alu_rotate_imm,\n+\t\t  cortex_a53_shift\"\n+\t\t \"cortex_a53_alu\")\n+\n+(define_bypass 2 \"cortex_a53_alu,\n+\t\t  cortex_a53_alu_shift*\"\n+\t\t \"cortex_a53_alu_shift*\"\n+\t\t \"aarch_forward_to_shift_is_not_shifted_reg\")\n+\n+;; In our model, we allow any general-purpose register operation to\n+;; bypass to the accumulator operand of an integer MADD-like operation.\n+\n+(define_bypass 1 \"cortex_a53_alu*,\n+\t\t  cortex_a53_load*,\n+\t\t  cortex_a53_mul\"\n+\t\t \"cortex_a53_mul\"\n+\t\t \"aarch_accumulator_forwarding\")\n+\n+;; Model a bypass from MLA/MUL to many ALU instructions.\n+\n+(define_bypass 2 \"cortex_a53_mul\"\n+\t\t \"cortex_a53_alu,\n+\t\t  cortex_a53_alu_shift*\")\n+\n+;; We get neater schedules by allowing an MLA/MUL to feed an\n+;; early load address dependency to a load.\n+\n+(define_bypass 2 \"cortex_a53_mul\"\n+\t\t \"cortex_a53_load*\"\n+\t\t \"arm_early_load_addr_dep\")\n+\n+;; Model bypasses for loads which are to be consumed by the ALU.\n+\n+(define_bypass 2 \"cortex_a53_load1\"\n+\t\t \"cortex_a53_alu\")\n+\n+(define_bypass 3 \"cortex_a53_load1\"\n+\t\t \"cortex_a53_alu_shift*\")\n+\n+;; Model a bypass for ALU instructions feeding stores.\n+\n+(define_bypass 1 \"cortex_a53_alu*\"\n+\t\t \"cortex_a53_store1,\n+\t\t  cortex_a53_store2,\n+\t\t  cortex_a53_store3plus\"\n+\t\t \"arm_no_early_store_addr_dep\")\n+\n+;; Model a bypass for load and multiply instructions feeding stores.\n+\n+(define_bypass 2 \"cortex_a53_mul,\n+\t\t  cortex_a53_load1,\n+\t\t  cortex_a53_load2,\n+\t\t  cortex_a53_load3plus\"\n+\t\t \"cortex_a53_store1,\n+\t\t  cortex_a53_store2,\n+\t\t  cortex_a53_store3plus\"\n+\t\t \"arm_no_early_store_addr_dep\")\n+\n+;; Model a GP->FP register move as similar to stores.\n+\n+(define_bypass 1 \"cortex_a53_alu*\"\n+\t\t \"cortex_a53_r2f\")\n+\n+(define_bypass 2 \"cortex_a53_mul,\n+\t\t  cortex_a53_load1,\n+\t\t  cortex_a53_load2,\n+\t\t  cortex_a53_load3plus\"\n+\t\t \"cortex_a53_r2f\")\n+\n+;; Shifts feeding Load/Store addresses may not be ready in time.\n+\n+(define_bypass 3 \"cortex_a53_shift\"\n+\t\t \"cortex_a53_load*\"\n+\t\t \"arm_early_load_addr_dep\")\n+\n+(define_bypass 3 \"cortex_a53_shift\"\n+\t\t \"cortex_a53_store*\"\n+\t\t \"arm_early_store_addr_dep\")\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; Floating-point/Advanced SIMD.\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+(define_automaton \"cortex_a53_advsimd\")\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; Broad Advanced SIMD type categorisation\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+(define_attr \"cortex_a53_advsimd_type\"\n+  \"advsimd_alu, advsimd_alu_q,\n+   advsimd_mul, advsimd_mul_q,\n+   advsimd_div_s, advsimd_div_s_q,\n+   advsimd_div_d, advsimd_div_d_q,\n+   advsimd_load_64, advsimd_store_64,\n+   advsimd_load_128, advsimd_store_128,\n+   advsimd_load_lots, advsimd_store_lots,\n+   unknown\"\n+  (cond [\n+    (eq_attr \"type\" \"neon_add, neon_qadd, neon_add_halve, neon_sub, neon_qsub,\\\n+\t\t     neon_sub_halve, neon_abs, neon_neg, neon_qneg,\\\n+\t\t     neon_qabs, neon_abd, neon_minmax, neon_compare,\\\n+\t\t     neon_compare_zero, neon_arith_acc, neon_reduc_add,\\\n+\t\t     neon_reduc_add_acc, neon_reduc_minmax,\\\n+\t\t     neon_logic, neon_tst, neon_shift_imm,\\\n+\t\t     neon_shift_reg, neon_shift_acc, neon_sat_shift_imm,\\\n+\t\t     neon_sat_shift_reg, neon_ins, neon_move,\\\n+\t\t     neon_permute, neon_zip, neon_tbl1,\\\n+\t\t     neon_tbl2, neon_tbl3, neon_tbl4, neon_bsl,\\\n+\t\t     neon_cls, neon_cnt, neon_dup,\\\n+\t\t     neon_ext, neon_rbit, neon_rev,\\\n+\t\t     neon_fp_abd_s, neon_fp_abd_d,\\\n+\t\t     neon_fp_abs_s, neon_fp_abs_d,\\\n+\t\t     neon_fp_addsub_s, neon_fp_addsub_d, neon_fp_compare_s,\\\n+\t\t     neon_fp_compare_d, neon_fp_minmax_s,\\\n+\t\t     neon_fp_minmax_d, neon_fp_neg_s, neon_fp_neg_d,\\\n+\t\t     neon_fp_reduc_add_s, neon_fp_reduc_add_d,\\\n+\t\t     neon_fp_reduc_minmax_s, neon_fp_reduc_minmax_d,\\\n+\t\t     neon_fp_cvt_widen_h, neon_fp_to_int_s,neon_fp_to_int_d,\\\n+\t\t     neon_int_to_fp_s, neon_int_to_fp_d, neon_fp_round_s,\\\n+\t\t     neon_fp_recpe_s, neon_fp_recpe_d, neon_fp_recps_s,\\\n+\t\t     neon_fp_recps_d, neon_fp_recpx_s, neon_fp_recpx_d,\\\n+\t\t     neon_fp_rsqrte_s, neon_fp_rsqrte_d, neon_fp_rsqrts_s,\\\n+\t\t     neon_fp_rsqrts_d\")\n+      (const_string \"advsimd_alu\")\n+    (eq_attr \"type\" \"neon_add_q, neon_add_widen, neon_add_long,\\\n+\t\t     neon_qadd_q, neon_add_halve_q, neon_add_halve_narrow_q,\\\n+\t\t     neon_sub_q, neon_sub_widen, neon_sub_long,\\\n+\t\t     neon_qsub_q, neon_sub_halve_q, neon_sub_halve_narrow_q,\\\n+\t\t     neon_abs_q, neon_neg_q, neon_qneg_q, neon_qabs_q,\\\n+\t\t     neon_abd_q, neon_abd_long, neon_minmax_q,\\\n+\t\t     neon_compare_q, neon_compare_zero_q,\\\n+\t\t     neon_arith_acc_q, neon_reduc_add_q,\\\n+\t\t     neon_reduc_add_long, neon_reduc_add_acc_q,\\\n+\t\t     neon_reduc_minmax_q, neon_logic_q, neon_tst_q,\\\n+\t\t     neon_shift_imm_q, neon_shift_imm_narrow_q,\\\n+\t\t     neon_shift_imm_long, neon_shift_reg_q,\\\n+\t\t     neon_shift_acc_q, neon_sat_shift_imm_q,\\\n+\t\t     neon_sat_shift_imm_narrow_q, neon_sat_shift_reg_q,\\\n+\t\t     neon_ins_q, neon_move_q, neon_move_narrow_q,\\\n+\t\t     neon_permute_q, neon_zip_q,\\\n+\t\t     neon_tbl1_q, neon_tbl2_q, neon_tbl3_q,\\\n+\t\t     neon_tbl4_q, neon_bsl_q, neon_cls_q, neon_cnt_q,\\\n+\t\t     neon_dup_q, neon_ext_q, neon_rbit_q,\\\n+\t\t     neon_rev_q, neon_fp_abd_s_q, neon_fp_abd_d_q,\\\n+\t\t     neon_fp_abs_s_q, neon_fp_abs_d_q,\\\n+\t\t     neon_fp_addsub_s_q, neon_fp_addsub_d_q,\\\n+\t\t     neon_fp_compare_s_q, neon_fp_compare_d_q,\\\n+\t\t     neon_fp_minmax_s_q, neon_fp_minmax_d_q,\\\n+\t\t     neon_fp_cvt_widen_s, neon_fp_neg_s_q, neon_fp_neg_d_q,\\\n+\t\t     neon_fp_reduc_add_s_q, neon_fp_reduc_add_d_q,\\\n+\t\t     neon_fp_reduc_minmax_s_q, neon_fp_reduc_minmax_d_q,\\\n+\t\t     neon_fp_cvt_narrow_s_q, neon_fp_cvt_narrow_d_q,\\\n+\t\t     neon_fp_to_int_s_q, neon_fp_to_int_d_q,\\\n+\t\t     neon_int_to_fp_s_q, neon_int_to_fp_d_q,\\\n+\t\t     neon_fp_round_s_q,\\\n+\t\t     neon_fp_recpe_s_q, neon_fp_recpe_d_q,\\\n+\t\t     neon_fp_recps_s_q, neon_fp_recps_d_q,\\\n+\t\t     neon_fp_recpx_s_q, neon_fp_recpx_d_q,\\\n+\t\t     neon_fp_rsqrte_s_q, neon_fp_rsqrte_d_q,\\\n+\t\t     neon_fp_rsqrts_s_q, neon_fp_rsqrts_d_q\")\n+      (const_string \"advsimd_alu_q\")\n+    (eq_attr \"type\" \"neon_mul_b, neon_mul_h, neon_mul_s,\\\n+\t\t     neon_mul_h_scalar, neon_mul_s_scalar,\\\n+\t\t     neon_sat_mul_b, neon_sat_mul_h, neon_sat_mul_s,\\\n+\t\t     neon_sat_mul_h_scalar, neon_sat_mul_s_scalar,\\\n+\t\t     neon_mla_b, neon_mla_h, neon_mla_s,\\\n+\t\t     neon_mla_h_scalar, neon_mla_s_scalar,\\\n+\t\t     neon_fp_mul_s, neon_fp_mul_s_scalar,\\\n+\t\t     neon_fp_mul_d, neon_fp_mla_s,\\\n+\t\t     neon_fp_mla_s_scalar, neon_fp_mla_d\")\n+      (const_string \"advsimd_mul\")\n+    (eq_attr \"type\" \"neon_mul_b_q, neon_mul_h_q, neon_mul_s_q,\\\n+\t\t     neon_mul_b_long, neon_mul_h_long, neon_mul_s_long,\\\n+\t\t     neon_mul_d_long, neon_mul_h_scalar_q,\\\n+\t\t     neon_mul_s_scalar_q, neon_mul_h_scalar_long,\\\n+\t\t     neon_mul_s_scalar_long, neon_sat_mul_b_q,\\\n+\t\t     neon_sat_mul_h_q, neon_sat_mul_s_q,\\\n+\t\t     neon_sat_mul_b_long, neon_sat_mul_h_long,\\\n+\t\t     neon_sat_mul_s_long, neon_sat_mul_h_scalar_q,\\\n+\t\t     neon_sat_mul_s_scalar_q, neon_sat_mul_h_scalar_long,\\\n+\t\t     neon_sat_mul_s_scalar_long, neon_mla_b_q,\\\n+\t\t     neon_mla_h_q, neon_mla_s_q, neon_mla_b_long,\\\n+\t\t     neon_mla_h_long, neon_mla_s_long,\\\n+\t\t     neon_mla_h_scalar_q, neon_mla_s_scalar_q,\\\n+\t\t     neon_mla_h_scalar_long, neon_mla_s_scalar_long,\\\n+\t\t     neon_sat_mla_b_long, neon_sat_mla_h_long,\\\n+\t\t     neon_sat_mla_s_long, neon_sat_mla_h_scalar_long,\\\n+\t\t     neon_sat_mla_s_scalar_long,\\\n+\t\t     neon_fp_mul_s_q, neon_fp_mul_s_scalar_q,\\\n+\t\t     neon_fp_mul_d_q, neon_fp_mul_d_scalar_q,\\\n+\t\t     neon_fp_mla_s_q, neon_fp_mla_s_scalar_q,\\\n+\t\t     neon_fp_mla_d_q, neon_fp_mla_d_scalar_q\")\n+      (const_string \"advsimd_mul_q\")\n+    (eq_attr \"type\" \"neon_fp_sqrt_s, neon_fp_div_s\")\n+      (const_string \"advsimd_div_s\")\n+    (eq_attr \"type\" \"neon_fp_sqrt_s_q, neon_fp_div_s_q\")\n+      (const_string \"advsimd_div_s_q\")\n+    (eq_attr \"type\" \"neon_fp_sqrt_d, neon_fp_div_d\")\n+      (const_string \"advsimd_div_d\")\n+    (eq_attr \"type\" \"neon_fp_sqrt_d_q, neon_fp_div_d_q\")\n+      (const_string \"advsimd_div_d_q\")\n+    (eq_attr \"type\" \"neon_ldr, neon_load1_1reg,\\\n+\t\t     neon_load1_all_lanes, neon_load1_all_lanes_q,\\\n+\t\t     neon_load1_one_lane, neon_load1_one_lane_q\")\n+      (const_string \"advsimd_load_64\")\n+    (eq_attr \"type\" \"neon_str, neon_store1_1reg,\\\n+\t\t     neon_store1_one_lane,neon_store1_one_lane_q\")\n+      (const_string \"advsimd_store_64\")\n+    (eq_attr \"type\" \"neon_load1_1reg_q, neon_load1_2reg,\\\n+\t\t     neon_load2_2reg,\\\n+\t\t     neon_load2_all_lanes, neon_load2_all_lanes_q,\\\n+\t\t     neon_load2_one_lane, neon_load2_one_lane_q\")\n+      (const_string \"advsimd_load_128\")\n+    (eq_attr \"type\" \"neon_store1_1reg_q, neon_store1_2reg,\\\n+\t\t     neon_store2_2reg,\\\n+\t\t     neon_store2_one_lane, neon_store2_one_lane_q\")\n+      (const_string \"advsimd_store_128\")\n+    (eq_attr \"type\" \"neon_load1_2reg_q, neon_load1_3reg, neon_load1_3reg_q,\\\n+\t\t     neon_load1_4reg, neon_load1_4reg_q, \\\n+\t\t     neon_load2_2reg_q, neon_load2_4reg,\\\n+\t\t     neon_load2_4reg_q, neon_load3_3reg,\\\n+\t\t     neon_load3_3reg_q, neon_load3_all_lanes,\\\n+\t\t     neon_load3_all_lanes_q, neon_load3_one_lane,\\\n+\t\t     neon_load3_one_lane_q, neon_load4_4reg,\\\n+\t\t     neon_load4_4reg_q, neon_load4_all_lanes,\\\n+\t\t     neon_load4_all_lanes_q, neon_load4_one_lane,\\\n+\t\t     neon_load4_one_lane_q, neon_ldp, neon_ldp_q\")\n+      (const_string \"advsimd_load_lots\")\n+    (eq_attr \"type\" \"neon_store1_2reg_q, neon_store1_3reg,\\\n+\t\t     neon_store1_3reg_q, neon_store1_4reg,\\\n+\t\t     neon_store1_4reg_q, neon_store2_2reg_q,\\\n+\t\t     neon_store2_4reg, neon_store2_4reg_q,\\\n+\t\t     neon_store3_3reg, neon_store3_3reg_q,\\\n+\t\t     neon_store3_one_lane, neon_store3_one_lane_q,\\\n+\t\t     neon_store4_4reg, neon_store4_4reg_q,\\\n+\t\t     neon_store4_one_lane, neon_store4_one_lane_q,\\\n+\t\t     neon_stp, neon_stp_q\")\n+      (const_string \"advsimd_store_lots\")]\n+      (const_string \"unknown\")))\n+\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; Floating-point/Advanced SIMD functional units.\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+\n+;; We model the Advanced SIMD unit as two 64-bit units, each with three\n+;; pipes, FP_ALU, FP_MUL, FP_DIV.  We also give convenient reservations\n+;; for 128-bit Advanced SIMD instructions, which use both units.\n+\n+;; The floating-point/Advanced SIMD ALU pipelines.\n+\n+(define_cpu_unit \"cortex_a53_fp_alu_lo,\\\n+\t\t  cortex_a53_fp_alu_hi\"\n+\t\t \"cortex_a53_advsimd\")\n+\n+(define_reservation \"cortex_a53_fp_alu\"\n+\t\t    \"cortex_a53_fp_alu_lo\\\n+\t\t     |cortex_a53_fp_alu_hi\")\n+\n+(define_reservation \"cortex_a53_fp_alu_q\"\n+\t\t    \"cortex_a53_fp_alu_lo\\\n+\t\t     +cortex_a53_fp_alu_hi\")\n+\n+;; The floating-point/Advanced SIMD multiply/multiply-accumulate\n+;; pipelines.\n+\n+(define_cpu_unit \"cortex_a53_fp_mul_lo,\\\n+\t\t  cortex_a53_fp_mul_hi\"\n+\t\t \"cortex_a53_advsimd\")\n+\n+(define_reservation \"cortex_a53_fp_mul\"\n+\t\t    \"cortex_a53_fp_mul_lo\\\n+\t\t     |cortex_a53_fp_mul_hi\")\n+\n+(define_reservation \"cortex_a53_fp_mul_q\"\n+\t\t    \"cortex_a53_fp_mul_lo\\\n+\t\t     +cortex_a53_fp_mul_hi\")\n+\n+;; Floating-point/Advanced SIMD divide/square root.\n+\n+(define_cpu_unit \"cortex_a53_fp_div_lo,\\\n+\t\t  cortex_a53_fp_div_hi\"\n+\t\t \"cortex_a53_advsimd\")\n+\n+;; Once we choose a pipe, stick with it for three simulated cycles.\n+\n+(define_reservation \"cortex_a53_fp_div\"\n+\t\t    \"(cortex_a53_fp_div_lo*3)\\\n+\t\t     |(cortex_a53_fp_div_hi*3)\")\n+\n+(define_reservation \"cortex_a53_fp_div_q\"\n+\t\t    \"(cortex_a53_fp_div_lo*3)\\\n+\t\t     +(cortex_a53_fp_div_hi*3)\")\n+\n+;; Cryptographic extensions\n+\n+(define_cpu_unit \"cortex_a53_crypto\"\n+\t\t \"cortex_a53_advsimd\")\n \n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n ;; Floating-point arithmetic.\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n-(define_insn_reservation \"cortex_a53_fpalu\" 4\n+(define_insn_reservation \"cortex_a53_fpalu\" 5\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"ffariths, fadds, ffarithd, faddd, fmov, fmuls,\\\n-                        f_cvt,f_cvtf2i,f_cvti2f,\\\n-                        fcmps, fcmpd, fcsel, f_rints, f_rintd, f_minmaxs,\\\n-                        f_minmaxd\"))\n-  \"cortex_a53_slot0+cortex_a53_fpadd_pipe\")\n+\t(eq_attr \"type\" \"ffariths, fadds, ffarithd, faddd, fmov,\n+\t\t\tf_cvt, fcmps, fcmpd, fcsel, f_rints, f_rintd,\n+\t\t\tf_minmaxs, f_minmaxd\"))\n+  \"cortex_a53_slot_any,cortex_a53_fp_alu\")\n \n-(define_insn_reservation \"cortex_a53_fconst\" 2\n+(define_insn_reservation \"cortex_a53_fconst\" 3\n   (and (eq_attr \"tune\" \"cortexa53\")\n        (eq_attr \"type\" \"fconsts,fconstd\"))\n-  \"cortex_a53_slot0+cortex_a53_fpadd_pipe\")\n+  \"cortex_a53_slot_any,cortex_a53_fp_alu\")\n \n-(define_insn_reservation \"cortex_a53_fpmul\" 4\n+(define_insn_reservation \"cortex_a53_fpmul\" 5\n   (and (eq_attr \"tune\" \"cortexa53\")\n        (eq_attr \"type\" \"fmuls,fmuld\"))\n-  \"cortex_a53_slot0\")\n+  \"cortex_a53_slot_any,cortex_a53_fp_mul\")\n \n-;; For single-precision multiply-accumulate, the add (accumulate) is issued after\n-;; the multiply completes. Model that accordingly.\n+;; For multiply-accumulate, model the add (accumulate) as being issued\n+;; after the multiply completes.\n \n (define_insn_reservation \"cortex_a53_fpmac\" 8\n   (and (eq_attr \"tune\" \"cortexa53\")\n        (eq_attr \"type\" \"fmacs,fmacd,ffmas,ffmad\"))\n-  \"cortex_a53_slot0, nothing*3, cortex_a53_fpadd_pipe\")\n+  \"cortex_a53_slot_any,cortex_a53_fp_mul,\n+   nothing*3, cortex_a53_fp_alu\")\n \n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n-;; Floating-point divide/square root instructions.\n+;; Floating-point to/from core transfers.\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n-;; fsqrt really takes one cycle less, but that is not modelled.\n \n-(define_insn_reservation \"cortex_a53_fdivs\" 14\n+(define_insn_reservation \"cortex_a53_r2f\" 6\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"fdivs, fsqrts\"))\n-  \"cortex_a53_slot0, cortex_a53_fp_div_sqrt * 5\")\n+       (eq_attr \"type\" \"f_mcr,f_mcrr,f_cvti2f,\n+\t\t\tneon_from_gp, neon_from_gp_q\"))\n+  \"cortex_a53_slot_any,cortex_a53_store,\n+   nothing,cortex_a53_fp_alu\")\n \n-(define_insn_reservation \"cortex_a53_fdivd\" 29\n+(define_insn_reservation \"cortex_a53_f2r\" 6\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"fdivd, fsqrtd\"))\n-  \"cortex_a53_slot0, cortex_a53_fp_div_sqrt * 8\")\n+       (eq_attr \"type\" \"f_mrc,f_mrrc,f_cvtf2i,\n+\t\t\tneon_to_gp, neon_to_gp_q\"))\n+  \"cortex_a53_slot_any,cortex_a53_fp_alu,\n+   nothing,cortex_a53_store\")\n \n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n-;; ARMv8-A Cryptographic extensions.\n+;; Floating-point flag transfer.\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n-(define_insn_reservation \"cortex_a53_crypto_aese\" 2\n+(define_insn_reservation \"cortex_a53_f_flags\" 5\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"crypto_aese\"))\n-  \"cortex_a53_simd0\")\n+       (eq_attr \"type\" \"f_flag\"))\n+  \"cortex_a53_slot_any\")\n \n-(define_insn_reservation \"cortex_a53_crypto_aesmc\" 2\n-  (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"crypto_aesmc\"))\n-  \"cortex_a53_simd0 | cortex_a53_simd1\")\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; Floating-point load/store.\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n-(define_insn_reservation \"cortex_a53_crypto_sha1_fast\" 2\n+(define_insn_reservation \"cortex_a53_f_load_64\" 4\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"crypto_sha1_fast, crypto_sha256_fast\"))\n-  \"cortex_a53_simd0\")\n+       (ior (eq_attr \"type\" \"f_loads,f_loadd\")\n+\t    (eq_attr \"cortex_a53_advsimd_type\"\n+\t\t     \"advsimd_load_64\")))\n+  \"cortex_a53_slot_any+cortex_a53_ls_agen,\n+   cortex_a53_load\")\n \n-(define_insn_reservation \"cortex_a53_crypto_sha1_xor\" 3\n+(define_insn_reservation \"cortex_a53_f_load_many\" 5\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"crypto_sha1_xor\"))\n-  \"cortex_a53_simd0\")\n+       (eq_attr \"cortex_a53_advsimd_type\"\n+\t\t\"advsimd_load_128,advsimd_load_lots\"))\n+  \"cortex_a53_single_issue+cortex_a53_ls_agen,\n+   cortex_a53_load+cortex_a53_slot0,\n+   cortex_a53_load\")\n \n-(define_insn_reservation \"cortex_a53_crypto_sha_slow\" 5\n+(define_insn_reservation \"cortex_a53_f_store_64\" 0\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"crypto_sha1_slow, crypto_sha256_slow\"))\n-  \"cortex_a53_simd0\")\n+       (ior (eq_attr \"type\" \"f_stores,f_stored\")\n+\t    (eq_attr \"cortex_a53_advsimd_type\"\n+\t\t     \"advsimd_store_64\")))\n+  \"cortex_a53_slot_any+cortex_a53_ls_agen,\n+   cortex_a53_store\")\n \n-(define_bypass 0 \"cortex_a53_crypto_aese\"\n-                 \"cortex_a53_crypto_aesmc\"\n-                 \"aarch_crypto_can_dual_issue\")\n+(define_insn_reservation \"cortex_a53_f_store_many\" 0\n+  (and (eq_attr \"tune\" \"cortexa53\")\n+       (eq_attr \"cortex_a53_advsimd_type\"\n+\t\t\"advsimd_store_128,advsimd_store_lots\"))\n+  \"cortex_a53_slot_any+cortex_a53_ls_agen,\n+   cortex_a53_store+cortex_a53_slot0,\n+   cortex_a53_store\")\n \n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n-;; VFP to/from core transfers.\n+;; Advanced SIMD.\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n-(define_insn_reservation \"cortex_a53_r2f\" 4\n+;; Either we want to model use of the ALU pipe, the multiply pipe or the\n+;; divide/sqrt pipe.  In all cases we need to check if we are a 64-bit\n+;; operation (in which case we model dual-issue without penalty)\n+;; or a 128-bit operation in which case we require in our model that we\n+;; issue from slot 0.\n+\n+(define_insn_reservation \"cortex_a53_advsimd_alu\" 5\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"f_mcr,f_mcrr\"))\n-  \"cortex_a53_slot0\")\n+       (eq_attr \"cortex_a53_advsimd_type\" \"advsimd_alu\"))\n+  \"cortex_a53_slot_any,cortex_a53_fp_alu\")\n \n-(define_insn_reservation \"cortex_a53_f2r\" 2\n+(define_insn_reservation \"cortex_a53_advsimd_alu_q\" 5\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"f_mrc,f_mrrc\"))\n-  \"cortex_a53_slot0\")\n+       (eq_attr \"cortex_a53_advsimd_type\" \"advsimd_alu_q\"))\n+  \"cortex_a53_slot0,cortex_a53_fp_alu_q\")\n \n-;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n-;; VFP flag transfer.\n-;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+(define_insn_reservation \"cortex_a53_advsimd_mul\" 5\n+  (and (eq_attr \"tune\" \"cortexa53\")\n+       (eq_attr \"cortex_a53_advsimd_type\" \"advsimd_mul\"))\n+  \"cortex_a53_slot_any,cortex_a53_fp_mul\")\n \n-(define_insn_reservation \"cortex_a53_f_flags\" 4\n+(define_insn_reservation \"cortex_a53_advsimd_mul_q\" 5\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"f_flag\"))\n-  \"cortex_a53_slot0\")\n+       (eq_attr \"cortex_a53_advsimd_type\" \"advsimd_mul_q\"))\n+  \"cortex_a53_slot0,cortex_a53_fp_mul_q\")\n+\n+;; SIMD Dividers.\n+\n+(define_insn_reservation \"cortex_a53_advsimd_div_s\" 14\n+  (and (eq_attr \"tune\" \"cortexa53\")\n+       (ior (eq_attr \"type\" \"fdivs,fsqrts\")\n+       (eq_attr \"cortex_a53_advsimd_type\" \"advsimd_div_s\")))\n+  \"cortex_a53_slot0,cortex_a53_fp_mul,\n+   cortex_a53_fp_div\")\n+\n+(define_insn_reservation \"cortex_a53_advsimd_div_d\" 29\n+  (and (eq_attr \"tune\" \"cortexa53\")\n+       (ior (eq_attr \"type\" \"fdivd,fsqrtd\")\n+\t    (eq_attr \"cortex_a53_advsimd_type\" \"advsimd_div_d\")))\n+  \"cortex_a53_slot0,cortex_a53_fp_mul,\n+   cortex_a53_fp_div\")\n+\n+(define_insn_reservation \"cortex_a53_advsimd_div_s_q\" 14\n+  (and (eq_attr \"tune\" \"cortexa53\")\n+       (eq_attr \"cortex_a53_advsimd_type\" \"advsimd_div_s_q\"))\n+  \"cortex_a53_single_issue,cortex_a53_fp_mul_q,\n+   cortex_a53_fp_div_q\")\n+\n+(define_insn_reservation \"cortex_a53_advsimd_divd_q\" 29\n+  (and (eq_attr \"tune\" \"cortexa53\")\n+       (eq_attr \"cortex_a53_advsimd_type\" \"advsimd_div_d_q\"))\n+  \"cortex_a53_single_issue,cortex_a53_fp_mul_q,\n+   cortex_a53_fp_div_q\")\n \n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n-;; VFP load/store.\n+;; ARMv8-A Cryptographic extensions.\n ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n-(define_insn_reservation \"cortex_a53_f_loads\" 4\n+;; We want AESE and AESMC to end up consecutive to one another.\n+\n+(define_insn_reservation \"cortex_a53_crypto_aese\" 3\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"f_loads\"))\n+       (eq_attr \"type\" \"crypto_aese\"))\n   \"cortex_a53_slot0\")\n \n-(define_insn_reservation \"cortex_a53_f_loadd\" 5\n+(define_insn_reservation \"cortex_a53_crypto_aesmc\" 3\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"f_loadd\"))\n-  \"cortex_a53_slot0\")\n+       (eq_attr \"type\" \"crypto_aesmc\"))\n+  \"cortex_a53_slot_any\")\n \n-(define_insn_reservation \"cortex_a53_f_load_2reg\" 5\n+;; SHA1H\n+\n+(define_insn_reservation \"cortex_a53_crypto_sha1_fast\" 3\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"neon_ldp, neon_ldp_q, neon_load2_2reg_q\"))\n-  \"(cortex_a53_slot_any+cortex_a53_ls)*2\")\n+       (eq_attr \"type\" \"crypto_sha1_fast\"))\n+  \"cortex_a53_slot_any,cortex_a53_crypto\")\n \n-(define_insn_reservation \"cortex_a53_f_loadq\" 5\n+(define_insn_reservation \"cortex_a53_crypto_sha256_fast\" 3\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"neon_load1_1reg_q\"))\n-  \"cortex_a53_slot_any+cortex_a53_ls\")\n+       (eq_attr \"type\" \"crypto_sha256_fast\"))\n+  \"cortex_a53_slot0,cortex_a53_crypto\")\n \n-(define_insn_reservation \"cortex_a53_f_stores\" 0\n+(define_insn_reservation \"cortex_a53_crypto_sha1_xor\" 4\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"f_stores\"))\n-  \"cortex_a53_slot0\")\n+       (eq_attr \"type\" \"crypto_sha1_xor\"))\n+  \"cortex_a53_slot0,cortex_a53_crypto\")\n \n-(define_insn_reservation \"cortex_a53_f_stored\" 0\n+(define_insn_reservation \"cortex_a53_crypto_sha_slow\" 5\n   (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"type\" \"f_stored\"))\n-  \"cortex_a53_slot0\")\n+       (eq_attr \"type\" \"crypto_sha1_slow, crypto_sha256_slow\"))\n+  \"cortex_a53_slot0,cortex_a53_crypto\")\n \n-;; Load-to-use for floating-point values has a penalty of one cycle,\n-;; i.e. a latency of two.\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; Floating-point/Advanced SIMD register bypasses.\n+;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n \n-(define_bypass 2 \"cortex_a53_f_loads\"\n-                 \"cortex_a53_fpalu, cortex_a53_fpmac, cortex_a53_fpmul,\\\n-\t\t  cortex_a53_fdivs, cortex_a53_fdivd,\\\n-\t\t  cortex_a53_f2r\")\n+;; Model the late use of the accumulator operand for floating-point\n+;; multiply-accumulate operations as a bypass reducing the latency\n+;; of producing instructions to near zero.\n \n-(define_bypass 2 \"cortex_a53_f_loadd\"\n-                 \"cortex_a53_fpalu, cortex_a53_fpmac, cortex_a53_fpmul,\\\n-\t\t  cortex_a53_fdivs, cortex_a53_fdivd,\\\n-\t\t  cortex_a53_f2r\")\n+(define_bypass 1 \"cortex_a53_fp*,\n+\t\t  cortex_a53_r2f,\n+\t\t  cortex_a53_f_load*\"\n+\t\t \"cortex_a53_fpmac\"\n+\t\t \"aarch_accumulator_forwarding\")\n \n-;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n-;; Crude Advanced SIMD approximation.\n-;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n+;; Model a bypass from the result of an FP operation to a use.\n+\n+(define_bypass 4 \"cortex_a53_fpalu,\n+\t\t  cortex_a53_fpmul\"\n+\t\t \"cortex_a53_fpalu,\n+\t\t  cortex_a53_fpmul,\n+\t\t  cortex_a53_fpmac,\n+\t\t  cortex_a53_advsimd_div*\")\n+\n+;; We want AESE and AESMC to end up consecutive to one another.\n+\n+(define_bypass 0 \"cortex_a53_crypto_aese\"\n+\t\t \"cortex_a53_crypto_aesmc\"\n+\t\t \"aarch_crypto_can_dual_issue\")\n \n-(define_insn_reservation \"cortex_a53_advsimd\" 4\n-  (and (eq_attr \"tune\" \"cortexa53\")\n-       (eq_attr \"is_neon_type\" \"yes\"))\n-  \"cortex_a53_simd0\")"}]}