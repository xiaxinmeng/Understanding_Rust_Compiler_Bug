{"sha": "916b60b71e4ac6ef8184427616df27b843de4271", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OTE2YjYwYjcxZTRhYzZlZjgxODQ0Mjc2MTZkZjI3Yjg0M2RlNDI3MQ==", "commit": {"author": {"name": "Bernd Schmidt", "email": "bernds@redhat.com", "date": "2002-05-04T17:06:56Z"}, "committer": {"name": "Bernd Schmidt", "email": "bernds@gcc.gnu.org", "date": "2002-05-04T17:06:56Z"}, "message": "Fix bugs in SSE2 suppport and add SSE2 functions to xmmintrin.h\n\nFrom-SVN: r53161", "tree": {"sha": "6b703160d494e8e275d928ede8cc050c11f41a6f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/6b703160d494e8e275d928ede8cc050c11f41a6f"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/916b60b71e4ac6ef8184427616df27b843de4271", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/916b60b71e4ac6ef8184427616df27b843de4271", "html_url": "https://github.com/Rust-GCC/gccrs/commit/916b60b71e4ac6ef8184427616df27b843de4271", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/916b60b71e4ac6ef8184427616df27b843de4271/comments", "author": null, "committer": null, "parents": [{"sha": "c26fbbca7a192b39e2f918b050b44564c710abb6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c26fbbca7a192b39e2f918b050b44564c710abb6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c26fbbca7a192b39e2f918b050b44564c710abb6"}], "stats": {"total": 1273, "additions": 1227, "deletions": 46}, "files": [{"sha": "e84fe90d86bd048b814eb5520e746a74051770ff", "filename": "gcc/ChangeLog", "status": "modified", "additions": 67, "deletions": 0, "changes": 67, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/916b60b71e4ac6ef8184427616df27b843de4271/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/916b60b71e4ac6ef8184427616df27b843de4271/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=916b60b71e4ac6ef8184427616df27b843de4271", "patch": "@@ -1,3 +1,70 @@\n+2002-05-04  Bernd Schmidt  <bernds@redhat.com>\n+\n+\t* config/i386/i386.c (bdesc_2arg): Add a couple of missing SSE2\n+\tbuiltins.  Use V2DI patterns instead of TI for logical operations.\n+\t(ix86_init_mmx_sse_builtins): Add a couple of missing SSE2 builtins.\n+\tCorrect definitions of psadbw, pmovmskb128, movntdq, cvtdq2ps.\n+\t(ix86_expand_builtins): Change the pattern used for movntdq.\n+\t* config/i386/i386.md (sse2_andv2di3, sse2_iorv2di3, sse2_xorv2di3,\n+\tsse2_nandv2di3): New patterns.\n+\t(sse2_anddf3, sse2_nanddf3, sse2_iordf3, sse2_xordf3): Correct modes\n+\ton operands.\n+\t(sse2_movntv2di): Renamed from sse2_movntti and modes adjusted.\n+\t(cvtdq2pd): Correct mode on operand 1.\n+\t(sse2_umulsidi3): Describe without unspec.\n+\t(sse2_psadbw, mmx_psadbw): Describe with unspec; use more appropriate\n+\tmachine modes.\n+\t(lshrv2di3): Renamed from sse2_lshrv2di3 and removed unspec.\n+\t(ashlv2di3): Likewise, from sse2_ashlv2di3.\n+\t(ashrv8hi3, ashrv4si3, lshrv8hi3, lshrv4si3, lshrv2di3, ashlv8hi3,\n+\tashlv4si3, ashlv2di3): Use SImode for shift count.\n+\t(ashrv8hi3_ti, ashrv4si3_ti, lshrv8hi3_ti, lshrv4si3_ti, lshrv2di3_ti,\n+\tlshrv4si3_ti, lshrv2di3_ti, ashlv8hi3_ti, ashlv4si3_ti, ashlv2di3_ti):\n+\tNew patterns.\n+\t* config/i386/xmmintrin.h (__v2df, __v2di, __v4si, __v8hi, __v16qi):\n+\tNew typedefs.\n+\t(__m128i, __m128d): New macros.\n+\t(_mm_add_pd, _mm_add_sd, _mm_sub_pd, _mm_sub_sd, _mm_mul_pd,\n+\t_mm_mul_sd, _mm_div_pd, _mm_div_sd, _mm_sqrt_pd, _mm_sqrt_sd,\n+\t_mm_min_pd, _mm_min_sd, _mm_max_sd, _mm_max_pd, _mm_and_pd,\n+\t_mm_andnot_pd, _mm_xor_pd, _mm_or_pd, _mm_cmpeq_pd, _mm_cmplt_pd,\n+\t_mm_cmple_pd, _mm_cmpgt_pd, _mm_cmpge_pd, _mm_cmpneq_pd,\n+\t_mm_cmpnlt_pd, _mm_cmpnle_pd, _mm_cmpngt_pd, _mm_cmpnge_pd, \n+\t_mm_cmpord_pd, _mm_cmpunord_pd, _mm_cmpeq_sd, _mm_cmplt_sd,\n+\t_mm_cmple_sd, _mm_cmpgt_sd, _mm_cmpge_sd, _mm_cmpneq_sd,\n+\t_mm_cmpnlt_sd, _mm_cmpnle_sd, _mm_cmpngt_sd, _mm_cmpnge_sd, \n+\t_mm_cmpord_sd, _mm_cmpunord_sd, _mm_comieq_sd, _mm_comilt_sd,\n+\t_mm_comile_sd, _mm_comigt_sd, _mm_comige_sd, _mm_comineq_sd,\n+\t_mm_ucomieq_sd, _mm_ucomieq_sd, _mm_ucomilt_sd, _mm_ucomile_sd,\n+\t_mm_ucomigt_sd, _mm_ucomige_sd, _mm_ucomineq_sd, _mm_cvtepi32_pd,\n+\t_mm_cvtepi32_ps, _mm_cvtpd_epi32, _mm_cvtpd_pi32, _mm_cvtpd_ps,\n+\t_mm_cvttpd_epi32, _mm_cvttpd_pi32, _mm_cvtpi32_pd, _mm_cvtps_epi32,\n+\t_mm_cvttps_epi32, _mm_cvtps_pd, _mm_cvtsd_si32, _mm_cvttsd_si32,\n+\t_mm_cvtsd_ss, _mm_cvtsi32_sd, _mm_cvtss_sd, _mm_unpackhi_pd,\n+\t_mm_unpacklo_pd, _mm_loadh_pd, _mm_storeh_pd, _mm_storel_pd,\n+\t_mm_movemask_pd, _mm_packs_epi16, _mm_packs_epi32, _mm_packus_epi16,\n+\t_mm_unpackhi_epi8, _mm_unpackhi_epi16, _mm_unpackhi_epi32,\n+\t_mm_unpacklo_epi8, _mm_unpacklo_epi16, _mm_unpacklo_epi32,\n+\t_mm_add_epi8, _mm_add_epi16, _mm_add_epi32, _mm_add_epi64,\n+\t_mm_adds_epi8, _mm_adds_epi16, _mm_adds_epu8, _mm_adds_epu16,\n+\t_mm_sub_epi8, _mm_sub_epi16, _mm_sub_epi32, _mm_sub_epi64,\n+\t_mm_subs_epi8, _mm_subs_epi16, _mm_subs_epu8, _mm_subs_epu16,\n+\t_mm_madd_epi16, _mm_mulhi_epi16, _mm_mullo_epi16, _mm_mul_pu16,\n+\t_mm_mul_epu16, _mm_sll_epi16, _mm_sll_epi32, _mm_sll_epi64,\n+\t_mm_sra_epi16, _mm_sra_epi32, _mm_srl_epi16, _mm_srl_epi32,\n+\t_mm_srl_epi64, _mm_slli_epi16, _mm_slli_epi32, _mm_slli_epi64,\n+\t_mm_srai_epi16, _mm_srai_epi32, _mm_srli_epi16, _mm_srli_epi32,\n+\t_mm_srli_epi64, _mm_and_si128, _mm_andnot_si128, _mm_or_si128,\n+\t_mm_xor_si128, _mm_cmpeq_epi8, _mm_cmpeq_epi16, _mm_cmpeq_epi32,\n+\t_mm_cmpgt_epi8, _mm_cmpgt_epi16, _mm_cmpgt_epi32, _mm_max_epi16,\n+\t_mm_max_epu8, _mm_min_epi16, _mm_min_epu8, _mm_movemask_epi8,\n+\t_mm_mulhi_epu16, _mm_maskmoveu_si128, _mm_avg_epu8, _mm_avg_epu16,\n+\t_mm_sad_epu8, _mm_stream_si32, _mm_stream_si128, _mm_stream_pd,\n+\t_mm_movpi64_epi64, _mm_clflush, _mm_lfence, _mm_mfence): New\n+\tfunctions.\n+\t(_mm_shufflehi_epi16, _mm_shufflelo_epi16, _mm_shuffle_epi32, \n+\t_mm_extract_epi16, _mm_insert_epi16, _mm_shuffle_pd): New macros.\n+\n 2002-05-04  Kazu Hirata  <kazu@cs.umass.edu>\n \n \t* dwarf2out.c: Fix formatting."}, {"sha": "bc4cf7b589b4f9fb2d87538d66b570eea220cb7e", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 102, "deletions": 15, "changes": 117, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/916b60b71e4ac6ef8184427616df27b843de4271/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/916b60b71e4ac6ef8184427616df27b843de4271/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=916b60b71e4ac6ef8184427616df27b843de4271", "patch": "@@ -11179,10 +11179,10 @@ static const struct builtin_description bdesc_2arg[] =\n   { MASK_SSE2, CODE_FOR_sse2_umulsidi3, \"__builtin_ia32_pmuludq\", IX86_BUILTIN_PMULUDQ, 0, 0 },\n   { MASK_SSE2, CODE_FOR_sse2_umulv2siv2di3, \"__builtin_ia32_pmuludq128\", IX86_BUILTIN_PMULUDQ128, 0, 0 },\n \n-  { MASK_SSE2, CODE_FOR_sse2_andti3, \"__builtin_ia32_pand128\", IX86_BUILTIN_PAND128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_sse2_nandti3, \"__builtin_ia32_pandn128\", IX86_BUILTIN_PANDN128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_sse2_iorti3, \"__builtin_ia32_por128\", IX86_BUILTIN_POR128, 0, 0 },\n-  { MASK_SSE2, CODE_FOR_sse2_xorti3, \"__builtin_ia32_pxor128\", IX86_BUILTIN_PXOR128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_andv2di3, \"__builtin_ia32_pand128\", IX86_BUILTIN_PAND128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_nandv2di3, \"__builtin_ia32_pandn128\", IX86_BUILTIN_PANDN128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_iorv2di3, \"__builtin_ia32_por128\", IX86_BUILTIN_POR128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_xorv2di3, \"__builtin_ia32_pxor128\", IX86_BUILTIN_PXOR128, 0, 0 },\n \n   { MASK_SSE2, CODE_FOR_sse2_uavgv16qi3, \"__builtin_ia32_pavgb128\", IX86_BUILTIN_PAVGB128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_sse2_uavgv8hi3, \"__builtin_ia32_pavgw128\", IX86_BUILTIN_PAVGW128, 0, 0 },\n@@ -11206,6 +11206,34 @@ static const struct builtin_description bdesc_2arg[] =\n   { MASK_SSE2, CODE_FOR_sse2_punpcklwd, \"__builtin_ia32_punpcklwd128\", IX86_BUILTIN_PUNPCKLWD128, 0, 0 },\n   { MASK_SSE2, CODE_FOR_sse2_punpckldq, \"__builtin_ia32_punpckldq128\", IX86_BUILTIN_PUNPCKLDQ128, 0, 0 },\n \n+  { MASK_SSE2, CODE_FOR_sse2_packsswb, \"__builtin_ia32_packsswb128\", IX86_BUILTIN_PACKSSWB128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_packssdw, \"__builtin_ia32_packssdw128\", IX86_BUILTIN_PACKSSDW128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_packuswb, \"__builtin_ia32_packuswb128\", IX86_BUILTIN_PACKUSWB128, 0, 0 },\n+\n+  { MASK_SSE2, CODE_FOR_umulv8hi3_highpart, \"__builtin_ia32_pmulhuw128\", IX86_BUILTIN_PMULHUW128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_sse2_psadbw, 0, IX86_BUILTIN_PSADBW128, 0, 0 },\n+\n+  { MASK_SSE2, CODE_FOR_ashlv8hi3_ti, 0, IX86_BUILTIN_PSLLW128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_ashlv8hi3, 0, IX86_BUILTIN_PSLLWI128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_ashlv4si3_ti, 0, IX86_BUILTIN_PSLLD128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_ashlv4si3, 0, IX86_BUILTIN_PSLLDI128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_ashlv2di3_ti, 0, IX86_BUILTIN_PSLLQ128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_ashlv2di3, 0, IX86_BUILTIN_PSLLQI128, 0, 0 },\n+\n+  { MASK_SSE2, CODE_FOR_lshrv8hi3_ti, 0, IX86_BUILTIN_PSRLW128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_lshrv8hi3, 0, IX86_BUILTIN_PSRLWI128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_lshrv4si3_ti, 0, IX86_BUILTIN_PSRLD128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_lshrv4si3, 0, IX86_BUILTIN_PSRLDI128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_lshrv2di3_ti, 0, IX86_BUILTIN_PSRLQ128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_lshrv2di3, 0, IX86_BUILTIN_PSRLQI128, 0, 0 },\n+\n+  { MASK_SSE2, CODE_FOR_ashrv8hi3_ti, 0, IX86_BUILTIN_PSRAW128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_ashrv8hi3, 0, IX86_BUILTIN_PSRAWI128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_ashrv4si3_ti, 0, IX86_BUILTIN_PSRAD128, 0, 0 },\n+  { MASK_SSE2, CODE_FOR_ashrv4si3, 0, IX86_BUILTIN_PSRADI128, 0, 0 },\n+\n+  { MASK_SSE2, CODE_FOR_sse2_pmaddwd, 0, IX86_BUILTIN_PMADDWD128, 0, 0 },\n+\n   { MASK_SSE2, CODE_FOR_cvtsi2sd, 0, IX86_BUILTIN_CVTSI2SD, 0, 0 },\n   { MASK_SSE2, CODE_FOR_cvtsd2ss, 0, IX86_BUILTIN_CVTSD2SS, 0, 0 },\n   { MASK_SSE2, CODE_FOR_cvtss2sd, 0, IX86_BUILTIN_CVTSS2SD, 0, 0 }\n@@ -11270,6 +11298,7 @@ ix86_init_mmx_sse_builtins ()\n   tree pchar_type_node = build_pointer_type (char_type_node);\n   tree pfloat_type_node = build_pointer_type (float_type_node);\n   tree pv2si_type_node = build_pointer_type (V2SI_type_node);\n+  tree pv2di_type_node = build_pointer_type (V2DI_type_node);\n   tree pdi_type_node = build_pointer_type (long_long_unsigned_type_node);\n \n   /* Comparisons.  */\n@@ -11334,11 +11363,6 @@ ix86_init_mmx_sse_builtins ()\n \t\t\t\t\t\t tree_cons (NULL_TREE,\n \t\t\t\t\t\t\t    integer_type_node,\n \t\t\t\t\t\t\t    endlink))));\n-  tree v4hi_ftype_v8qi_v8qi\n-    = build_function_type (V4HI_type_node,\n-\t\t\t   tree_cons (NULL_TREE, V8QI_type_node,\n-\t\t\t\t      tree_cons (NULL_TREE, V8QI_type_node,\n-\t\t\t\t\t\t endlink)));\n   tree v2si_ftype_v4hi_v4hi\n     = build_function_type (V2SI_type_node,\n \t\t\t   tree_cons (NULL_TREE, V4HI_type_node,\n@@ -11411,6 +11435,12 @@ ix86_init_mmx_sse_builtins ()\n \t\t\t\t      tree_cons (NULL_TREE,\n \t\t\t\t\t\t long_long_unsigned_type_node,\n \t\t\t\t\t\t endlink)));\n+  tree void_ftype_pv2di_v2di\n+    = build_function_type (void_type_node,\n+\t\t\t   tree_cons (NULL_TREE, pv2di_type_node,\n+\t\t\t\t      tree_cons (NULL_TREE,\n+\t\t\t\t\t\t V2DI_type_node,\n+\t\t\t\t\t\t endlink)));\n   /* Normal vector unops.  */\n   tree v4sf_ftype_v4sf\n     = build_function_type (V4SF_type_node,\n@@ -11629,6 +11659,11 @@ ix86_init_mmx_sse_builtins ()\n \t\t\t\t\t\t tree_cons (NULL_TREE,\n \t\t\t\t\t\t\t    integer_type_node,\n \t\t\t\t\t\t\t    endlink))));\n+  tree v2di_ftype_v2di_int\n+    = build_function_type (V2DI_type_node,\n+\t\t\t   tree_cons (NULL_TREE, V2DI_type_node,\n+\t\t\t\t      tree_cons (NULL_TREE, integer_type_node,\n+\t\t\t\t\t\t endlink)));\n   tree v4si_ftype_v4si_int\n     = build_function_type (V4SI_type_node,\n \t\t\t   tree_cons (NULL_TREE, V4SI_type_node,\n@@ -11639,6 +11674,34 @@ ix86_init_mmx_sse_builtins ()\n \t\t\t   tree_cons (NULL_TREE, V8HI_type_node,\n \t\t\t\t      tree_cons (NULL_TREE, integer_type_node,\n \t\t\t\t\t\t endlink)));\n+  tree v8hi_ftype_v8hi_v2di\n+    = build_function_type (V8HI_type_node,\n+\t\t\t   tree_cons (NULL_TREE, V8HI_type_node,\n+\t\t\t\t      tree_cons (NULL_TREE, V2DI_type_node,\n+\t\t\t\t\t\t endlink)));\n+  tree v4si_ftype_v4si_v2di\n+    = build_function_type (V4SI_type_node,\n+\t\t\t   tree_cons (NULL_TREE, V4SI_type_node,\n+\t\t\t\t      tree_cons (NULL_TREE, V2DI_type_node,\n+\t\t\t\t\t\t endlink)));\n+  tree v4si_ftype_v8hi_v8hi\n+    = build_function_type (V4SI_type_node,\n+\t\t\t   tree_cons (NULL_TREE, V8HI_type_node,\n+\t\t\t\t      tree_cons (NULL_TREE, V8HI_type_node,\n+\t\t\t\t\t\t endlink)));\n+  tree di_ftype_v8qi_v8qi\n+    = build_function_type (long_long_unsigned_type_node,\n+\t\t\t   tree_cons (NULL_TREE, V8QI_type_node,\n+\t\t\t\t      tree_cons (NULL_TREE, V8QI_type_node,\n+\t\t\t\t\t\t endlink)));\n+  tree v2di_ftype_v16qi_v16qi\n+    = build_function_type (V2DI_type_node,\n+\t\t\t   tree_cons (NULL_TREE, V16QI_type_node,\n+\t\t\t\t      tree_cons (NULL_TREE, V16QI_type_node,\n+\t\t\t\t\t\t endlink)));\n+  tree int_ftype_v16qi\n+    = build_function_type (integer_type_node,\n+\t\t\t   tree_cons (NULL_TREE, V16QI_type_node, endlink));\n \n   /* Add all builtins that are more or less simple operations on two\n      operands.  */\n@@ -11775,7 +11838,7 @@ ix86_init_mmx_sse_builtins ()\n \n   def_builtin (MASK_SSE1 | MASK_3DNOW_A, \"__builtin_ia32_sfence\", void_ftype_void, IX86_BUILTIN_SFENCE);\n \n-  def_builtin (MASK_SSE1 | MASK_3DNOW_A, \"__builtin_ia32_psadbw\", v4hi_ftype_v8qi_v8qi, IX86_BUILTIN_PSADBW);\n+  def_builtin (MASK_SSE1 | MASK_3DNOW_A, \"__builtin_ia32_psadbw\", di_ftype_v8qi_v8qi, IX86_BUILTIN_PSADBW);\n \n   def_builtin (MASK_SSE1, \"__builtin_ia32_rcpps\", v4sf_ftype_v4sf, IX86_BUILTIN_RCPPS);\n   def_builtin (MASK_SSE1, \"__builtin_ia32_rcpss\", v4sf_ftype_v4sf, IX86_BUILTIN_RCPSS);\n@@ -11838,23 +11901,23 @@ ix86_init_mmx_sse_builtins ()\n   def_builtin (MASK_SSE2, \"__builtin_ia32_storelpd\", void_ftype_pv2si_v2df, IX86_BUILTIN_STORELPD);\n \n   def_builtin (MASK_SSE2, \"__builtin_ia32_movmskpd\", int_ftype_v2df, IX86_BUILTIN_MOVMSKPD);\n-  def_builtin (MASK_SSE2, \"__builtin_ia32_pmovmskb128\", int_ftype_v8qi, IX86_BUILTIN_PMOVMSKB128);\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_pmovmskb128\", int_ftype_v16qi, IX86_BUILTIN_PMOVMSKB128);\n   def_builtin (MASK_SSE2, \"__builtin_ia32_movnti\", void_ftype_pint_int, IX86_BUILTIN_MOVNTI);\n   def_builtin (MASK_SSE2, \"__builtin_ia32_movntpd\", void_ftype_pdouble_v2df, IX86_BUILTIN_MOVNTPD);\n-  def_builtin (MASK_SSE2, \"__builtin_ia32_movntdq\", void_ftype_pdi_di, IX86_BUILTIN_MOVNTDQ);\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_movntdq\", void_ftype_pv2di_v2di, IX86_BUILTIN_MOVNTDQ);\n \n   def_builtin (MASK_SSE2, \"__builtin_ia32_pshufd\", v4si_ftype_v4si_int, IX86_BUILTIN_PSHUFD);\n   def_builtin (MASK_SSE2, \"__builtin_ia32_pshuflw\", v8hi_ftype_v8hi_int, IX86_BUILTIN_PSHUFLW);\n   def_builtin (MASK_SSE2, \"__builtin_ia32_pshufhw\", v8hi_ftype_v8hi_int, IX86_BUILTIN_PSHUFHW);\n-  def_builtin (MASK_SSE2, \"__builtin_ia32_psadbw128\", v4hi_ftype_v8qi_v8qi, IX86_BUILTIN_PSADBW128);\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_psadbw128\", v2di_ftype_v16qi_v16qi, IX86_BUILTIN_PSADBW128);\n \n   def_builtin (MASK_SSE2, \"__builtin_ia32_sqrtpd\", v2df_ftype_v2df, IX86_BUILTIN_SQRTPD);\n   def_builtin (MASK_SSE2, \"__builtin_ia32_sqrtsd\", v2df_ftype_v2df, IX86_BUILTIN_SQRTSD);\n \n   def_builtin (MASK_SSE2, \"__builtin_ia32_shufpd\", v2df_ftype_v2df_v2df_int, IX86_BUILTIN_SHUFPD);\n \n   def_builtin (MASK_SSE2, \"__builtin_ia32_cvtdq2pd\", v2df_ftype_v4si, IX86_BUILTIN_CVTDQ2PD);\n-  def_builtin (MASK_SSE2, \"__builtin_ia32_cvtdq2ps\", v4sf_ftype_v4si, IX86_BUILTIN_CVTDQ2PD);\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_cvtdq2ps\", v4sf_ftype_v4si, IX86_BUILTIN_CVTDQ2PS);\n \n   def_builtin (MASK_SSE2, \"__builtin_ia32_cvtpd2dq\", v4si_ftype_v2df, IX86_BUILTIN_CVTPD2DQ);\n   def_builtin (MASK_SSE2, \"__builtin_ia32_cvtpd2pi\", v2si_ftype_v2df, IX86_BUILTIN_CVTPD2PI);\n@@ -11886,6 +11949,30 @@ ix86_init_mmx_sse_builtins ()\n   def_builtin (MASK_SSE2, \"__builtin_ia32_clflush\", void_ftype_pvoid, IX86_BUILTIN_CLFLUSH);\n   def_builtin (MASK_SSE2, \"__builtin_ia32_lfence\", void_ftype_void, IX86_BUILTIN_LFENCE);\n   def_builtin (MASK_SSE2, \"__builtin_ia32_mfence\", void_ftype_void, IX86_BUILTIN_MFENCE);\n+\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_psllw128\", v8hi_ftype_v8hi_v2di, IX86_BUILTIN_PSLLW128);\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_pslld128\", v4si_ftype_v4si_v2di, IX86_BUILTIN_PSLLD128);\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_psllq128\", v2di_ftype_v2di_v2di, IX86_BUILTIN_PSLLQ128);\n+\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_psrlw128\", v8hi_ftype_v8hi_v2di, IX86_BUILTIN_PSRLW128);\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_psrld128\", v4si_ftype_v4si_v2di, IX86_BUILTIN_PSRLD128);\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_psrlq128\", v2di_ftype_v2di_v2di, IX86_BUILTIN_PSRLQ128);\n+\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_psraw128\", v8hi_ftype_v8hi_v2di, IX86_BUILTIN_PSRAW128);\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_psrad128\", v4si_ftype_v4si_v2di, IX86_BUILTIN_PSRAD128);\n+\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_psllwi128\", v8hi_ftype_v8hi_int, IX86_BUILTIN_PSLLWI128);\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_pslldi128\", v4si_ftype_v4si_int, IX86_BUILTIN_PSLLDI128);\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_psllqi128\", v2di_ftype_v2di_int, IX86_BUILTIN_PSLLQI128);\n+\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_psrlwi128\", v8hi_ftype_v8hi_int, IX86_BUILTIN_PSRLWI128);\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_psrldi128\", v4si_ftype_v4si_int, IX86_BUILTIN_PSRLDI128);\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_psrlqi128\", v2di_ftype_v2di_int, IX86_BUILTIN_PSRLQI128);\n+\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_psrawi128\", v8hi_ftype_v8hi_int, IX86_BUILTIN_PSRAWI128);\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_psradi128\", v4si_ftype_v4si_int, IX86_BUILTIN_PSRADI128);\n+\n+  def_builtin (MASK_SSE2, \"__builtin_ia32_pmaddwd128\", v4si_ftype_v8hi_v8hi, IX86_BUILTIN_PMADDWD128);\n }\n \n /* Errors in the source file can cause expand_expr to return const0_rtx\n@@ -12681,7 +12768,7 @@ ix86_expand_builtin (exp, target, subtarget, mode, ignore)\n     case IX86_BUILTIN_MOVNTPD:\n       return ix86_expand_store_builtin (CODE_FOR_sse2_movntv2df, arglist);\n     case IX86_BUILTIN_MOVNTDQ:\n-      return ix86_expand_store_builtin (CODE_FOR_sse2_movntti, arglist);\n+      return ix86_expand_store_builtin (CODE_FOR_sse2_movntv2di, arglist);\n     case IX86_BUILTIN_MOVNTI:\n       return ix86_expand_store_builtin (CODE_FOR_sse2_movntsi, arglist);\n "}, {"sha": "5fff4b624437feeb6c9568afa11ee9bb1debd4d7", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 135, "deletions": 31, "changes": 166, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/916b60b71e4ac6ef8184427616df27b843de4271/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/916b60b71e4ac6ef8184427616df27b843de4271/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=916b60b71e4ac6ef8184427616df27b843de4271", "patch": "@@ -104,6 +104,7 @@\n ;; 58 This is a `sfence' operation.\n ;; 59 This is a `mfence' operation.\n ;; 60 This is a `lfence' operation.\n+;; 61 This is a `psadbw' operation.\n \n ;; Insns whose names begin with \"x86_\" are emitted by gen_FOO calls\n ;; from i386.c.\n@@ -18593,6 +18594,15 @@\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"mode\" \"TI\")])\n \n+(define_insn \"sse2_andv2di3\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n+        (and:V2DI (match_operand:V2DI 1 \"nonimmediate_operand\" \"%0\")\n+\t\t  (match_operand:V2DI 2 \"nonimmediate_operand\" \"xm\")))]\n+  \"TARGET_SSE2\n+   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+  \"pand\\t{%2, %0|%0, %2}\"\n+  [(set_attr \"type\" \"sse\")])\n+\n (define_insn \"*sse_nandti3_df\"\n   [(set (subreg:TI (match_operand:DF 0 \"register_operand\" \"=Y\") 0)\n         (and:TI (not:TI (subreg:TI (match_operand:DF 1 \"register_operand\" \"0\") 0))\n@@ -18628,6 +18638,15 @@\n   \"pandn\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sselog\")])\n \n+(define_insn \"sse2_nandv2di3\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n+        (and:V2DI (not:V2DI (match_operand:V2DI 1 \"nonimmediate_operand\" \"%0\"))\n+\t\t  (match_operand:V2DI 2 \"nonimmediate_operand\" \"xm\")))]\n+  \"TARGET_SSE2\n+   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+  \"pandn\\t{%2, %0|%0, %2}\"\n+  [(set_attr \"type\" \"sse\")])\n+\n (define_insn \"*sse_iorti3_df_1\"\n   [(set (subreg:TI (match_operand:DF 0 \"register_operand\" \"=Y\") 0)\n         (ior:TI (subreg:TI (match_operand:DF 1 \"register_operand\" \"%0\") 0)\n@@ -18684,6 +18703,15 @@\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"mode\" \"TI\")])\n \n+(define_insn \"sse2_iorv2di3\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n+        (ior:V2DI (match_operand:V2DI 1 \"nonimmediate_operand\" \"%0\")\n+\t\t  (match_operand:V2DI 2 \"nonimmediate_operand\" \"xm\")))]\n+  \"TARGET_SSE2\n+   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+  \"por\\t{%2, %0|%0, %2}\"\n+  [(set_attr \"type\" \"sse\")])\n+\n (define_insn \"*sse_xorti3_df_1\"\n   [(set (subreg:TI (match_operand:DF 0 \"register_operand\" \"=Y\") 0)\n         (xor:TI (subreg:TI (match_operand:DF 1 \"register_operand\" \"%0\") 0)\n@@ -18740,6 +18768,15 @@\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"mode\" \"TI\")])\n \n+(define_insn \"sse2_xorv2di3\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n+        (xor:V2DI (match_operand:V2DI 1 \"nonimmediate_operand\" \"%0\")\n+\t\t  (match_operand:V2DI 2 \"nonimmediate_operand\" \"xm\")))]\n+  \"TARGET_SSE2\n+   && (GET_CODE (operands[1]) != MEM || GET_CODE (operands[2]) != MEM)\"\n+  \"pxor\\t{%2, %0|%0, %2}\"\n+  [(set_attr \"type\" \"sse\")])\n+\n ;; Use xor, but don't show input operands so they aren't live before\n ;; this insn.\n (define_insn \"sse_clrv4sf\"\n@@ -19279,9 +19316,9 @@\n    (set_attr \"mode\" \"DI\")])\n \n (define_insn \"mmx_psadbw\"\n-  [(set (match_operand:V8QI 0 \"register_operand\" \"=y\")\n-        (abs:V8QI (minus:V8QI (match_operand:V8QI 1 \"register_operand\" \"0\")\n-\t\t\t      (match_operand:V8QI 2 \"nonimmediate_operand\" \"ym\"))))]\n+  [(set (match_operand:DI 0 \"register_operand\" \"=y\")\n+        (unspec:DI [(match_operand:V8QI 1 \"register_operand\" \"0\")\n+\t\t    (match_operand:V8QI 2 \"nonimmediate_operand\" \"ym\")] 61))]\n   \"TARGET_SSE || TARGET_3DNOW_A\"\n   \"psadbw\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"mmxshft\")\n@@ -20250,35 +20287,35 @@\n \n (define_insn \"sse2_anddf3\"\n   [(set (match_operand:V2DF 0 \"register_operand\" \"=x\")\n-        (subreg:V2DF (and:TI (subreg:TI (match_operand:TI 1 \"register_operand\" \"%0\") 0)\n-\t\t\t     (subreg:TI (match_operand:TI 2 \"nonimmediate_operand\" \"xm\") 0)) 0))]\n+        (subreg:V2DF (and:TI (subreg:TI (match_operand:V2DF 1 \"register_operand\" \"%0\") 0)\n+\t\t\t     (subreg:TI (match_operand:V2DF 2 \"nonimmediate_operand\" \"xm\") 0)) 0))]\n   \"TARGET_SSE2\"\n   \"andpd\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"mode\" \"V2DF\")])\n \n (define_insn \"sse2_nanddf3\"\n   [(set (match_operand:V2DF 0 \"register_operand\" \"=x\")\n-        (subreg:V2DF (and:TI (not:TI (subreg:TI (match_operand:TI 1 \"register_operand\" \"0\") 0))\n-\t\t\t     (subreg:TI (match_operand:TI 2 \"nonimmediate_operand\" \"xm\") 0)) 0))]\n+        (subreg:V2DF (and:TI (not:TI (subreg:TI (match_operand:V2DF 1 \"register_operand\" \"0\") 0))\n+\t\t\t     (subreg:TI (match_operand:V2DF 2 \"nonimmediate_operand\" \"xm\") 0)) 0))]\n   \"TARGET_SSE2\"\n   \"andnpd\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"mode\" \"V2DF\")])\n \n (define_insn \"sse2_iordf3\"\n   [(set (match_operand:V2DF 0 \"register_operand\" \"=x\")\n-        (subreg:V2DF (ior:TI (subreg:TI (match_operand:TI 1 \"register_operand\" \"%0\") 0)\n-\t\t\t     (subreg:TI (match_operand:TI 2 \"nonimmediate_operand\" \"xm\") 0)) 0))]\n+        (subreg:V2DF (ior:TI (subreg:TI (match_operand:V2DF 1 \"register_operand\" \"%0\") 0)\n+\t\t\t     (subreg:TI (match_operand:V2DF 2 \"nonimmediate_operand\" \"xm\") 0)) 0))]\n   \"TARGET_SSE2\"\n   \"orpd\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sselog\")\n    (set_attr \"mode\" \"V2DF\")])\n \n (define_insn \"sse2_xordf3\"\n   [(set (match_operand:V2DF 0 \"register_operand\" \"=x\")\n-        (subreg:V2DF (xor:TI (subreg:TI (match_operand:TI 1 \"register_operand\" \"%0\") 0)\n-\t\t\t     (subreg:TI (match_operand:TI 2 \"nonimmediate_operand\" \"xm\") 0)) 0))]\n+        (subreg:V2DF (xor:TI (subreg:TI (match_operand:V2DF 1 \"register_operand\" \"%0\") 0)\n+\t\t\t     (subreg:TI (match_operand:V2DF 2 \"nonimmediate_operand\" \"xm\") 0)) 0))]\n   \"TARGET_SSE2\"\n   \"xorpd\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sselog\")\n@@ -20418,9 +20455,9 @@\n   [(set_attr \"type\" \"ssecvt\")\n    (set_attr \"mode\" \"V2DF\")])\n \n-(define_insn \"sse2_movntti\"\n-  [(set (match_operand:TI 0 \"memory_operand\" \"=m\")\n-\t(unspec:TI [(match_operand:TI 1 \"register_operand\" \"x\")] 34))]\n+(define_insn \"sse2_movntv2di\"\n+  [(set (match_operand:V2DI 0 \"memory_operand\" \"=m\")\n+\t(unspec:V2DI [(match_operand:V2DI 1 \"register_operand\" \"x\")] 34))]\n   \"TARGET_SSE2\"\n   \"movntdq\\t{%1, %0|%0, %1}\"\n   [(set_attr \"type\" \"ssecvt\")\n@@ -20467,7 +20504,7 @@\n (define_insn \"cvtdq2pd\"\n   [(set (match_operand:V2DF 0 \"register_operand\" \"=x\")\n \t(float:V2DF (vec_select:V2SI\n-\t\t     (match_operand:V2SI 1 \"nonimmediate_operand\" \"xm\")\n+\t\t     (match_operand:V4SI 1 \"nonimmediate_operand\" \"xm\")\n \t\t     (parallel\n \t\t      [(const_int 0)\n \t\t       (const_int 1)]))))]\n@@ -20784,11 +20821,14 @@\n   [(set_attr \"type\" \"sseimul\")\n    (set_attr \"mode\" \"TI\")])\n \n-;; See the MMX logical operations for the reason for the unspec\n (define_insn \"sse2_umulsidi3\"\n   [(set (match_operand:DI 0 \"register_operand\" \"=y\")\n-        (unspec:DI [(mult:DI (zero_extend:DI (match_operand:DI 1 \"register_operand\" \"0\"))\n-\t\t\t     (zero_extend:DI (match_operand:DI 2 \"nonimmediate_operand\" \"ym\")))] 45))]\n+        (mult:DI (zero_extend:DI (vec_select:SI\n+\t\t\t\t  (match_operand:V2SI 1 \"register_operand\" \"0\")\n+\t\t\t\t  (parallel [(const_int 0)])))\n+\t\t (zero_extend:DI (vec_select:SI\n+\t\t\t\t  (match_operand:V2SI 2 \"nonimmediate_operand\" \"ym\")\n+\t\t\t\t  (parallel [(const_int 0)])))))]\n   \"TARGET_SSE2\"\n   \"pmuludq\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sseimul\")\n@@ -20889,9 +20929,9 @@\n \n ;; @@@ this isn't the right representation.\n (define_insn \"sse2_psadbw\"\n-  [(set (match_operand:V16QI 0 \"register_operand\" \"=x\")\n-        (abs:V16QI (minus:V16QI (match_operand:V16QI 1 \"register_operand\" \"0\")\n-\t\t\t\t(match_operand:V16QI 2 \"nonimmediate_operand\" \"ym\"))))]\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n+        (unspec:V2DI [(match_operand:V16QI 1 \"register_operand\" \"0\")\n+\t\t      (match_operand:V16QI 2 \"nonimmediate_operand\" \"ym\")] 61))]\n   \"TARGET_SSE2\"\n   \"psadbw\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sseiadd\")\n@@ -21050,7 +21090,7 @@\n (define_insn \"ashrv8hi3\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=x\")\n         (ashiftrt:V8HI (match_operand:V8HI 1 \"register_operand\" \"0\")\n-\t\t       (match_operand:TI 2 \"nonmemory_operand\" \"xi\")))]\n+\t\t       (match_operand:SI 2 \"nonmemory_operand\" \"ri\")))]\n   \"TARGET_SSE2\"\n   \"psraw\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sseishft\")\n@@ -21059,7 +21099,7 @@\n (define_insn \"ashrv4si3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=x\")\n         (ashiftrt:V4SI (match_operand:V4SI 1 \"register_operand\" \"0\")\n-\t\t       (match_operand:TI 2 \"nonmemory_operand\" \"xi\")))]\n+\t\t       (match_operand:SI 2 \"nonmemory_operand\" \"ri\")))]\n   \"TARGET_SSE2\"\n   \"psrad\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sseishft\")\n@@ -21068,7 +21108,7 @@\n (define_insn \"lshrv8hi3\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=x\")\n         (lshiftrt:V8HI (match_operand:V8HI 1 \"register_operand\" \"0\")\n-\t\t       (match_operand:TI 2 \"nonmemory_operand\" \"xi\")))]\n+\t\t       (match_operand:SI 2 \"nonmemory_operand\" \"ri\")))]\n   \"TARGET_SSE2\"\n   \"psrlw\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sseishft\")\n@@ -21077,16 +21117,16 @@\n (define_insn \"lshrv4si3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=x\")\n         (lshiftrt:V4SI (match_operand:V4SI 1 \"register_operand\" \"0\")\n-\t\t       (match_operand:TI 2 \"nonmemory_operand\" \"xi\")))]\n+\t\t       (match_operand:SI 2 \"nonmemory_operand\" \"ri\")))]\n   \"TARGET_SSE2\"\n   \"psrld\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sseishft\")\n    (set_attr \"mode\" \"TI\")])\n \n-(define_insn \"sse2_lshrv2di3\"\n+(define_insn \"lshrv2di3\"\n   [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n         (lshiftrt:V2DI (match_operand:V2DI 1 \"register_operand\" \"0\")\n-\t\t       (match_operand:TI 2 \"nonmemory_operand\" \"xi\")))]\n+\t\t       (match_operand:SI 2 \"nonmemory_operand\" \"ri\")))]\n   \"TARGET_SSE2\"\n   \"psrlq\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sseishft\")\n@@ -21095,7 +21135,7 @@\n (define_insn \"ashlv8hi3\"\n   [(set (match_operand:V8HI 0 \"register_operand\" \"=x\")\n         (ashift:V8HI (match_operand:V8HI 1 \"register_operand\" \"0\")\n-\t\t     (match_operand:TI 2 \"nonmemory_operand\" \"xi\")))]\n+\t\t     (match_operand:SI 2 \"nonmemory_operand\" \"ri\")))]\n   \"TARGET_SSE2\"\n   \"psllw\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sseishft\")\n@@ -21104,16 +21144,80 @@\n (define_insn \"ashlv4si3\"\n   [(set (match_operand:V4SI 0 \"register_operand\" \"=x\")\n         (ashift:V4SI (match_operand:V4SI 1 \"register_operand\" \"0\")\n-\t\t     (match_operand:TI 2 \"nonmemory_operand\" \"xi\")))]\n+\t\t     (match_operand:SI 2 \"nonmemory_operand\" \"ri\")))]\n+  \"TARGET_SSE2\"\n+  \"pslld\\t{%2, %0|%0, %2}\"\n+  [(set_attr \"type\" \"sse\")])\n+\n+(define_insn \"ashlv2di3\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n+        (ashift:V2DI (match_operand:V2DI 1 \"register_operand\" \"0\")\n+\t\t     (match_operand:SI 2 \"nonmemory_operand\" \"ri\")))]\n+  \"TARGET_SSE2\"\n+  \"psllq\\t{%2, %0|%0, %2}\"\n+  [(set_attr \"type\" \"sse\")])\n+\n+(define_insn \"ashrv8hi3_ti\"\n+  [(set (match_operand:V8HI 0 \"register_operand\" \"=x\")\n+        (ashiftrt:V8HI (match_operand:V8HI 1 \"register_operand\" \"0\")\n+\t\t       (subreg:TI (match_operand:V2DI 2 \"nonmemory_operand\" \"xi\") 0)))]\n+  \"TARGET_SSE2\"\n+  \"psraw\\t{%2, %0|%0, %2}\"\n+  [(set_attr \"type\" \"sse\")])\n+\n+(define_insn \"ashrv4si3_ti\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x\")\n+        (ashiftrt:V4SI (match_operand:V4SI 1 \"register_operand\" \"0\")\n+\t\t       (subreg:TI (match_operand:V2DI 2 \"nonmemory_operand\" \"xi\") 0)))]\n+  \"TARGET_SSE2\"\n+  \"psrad\\t{%2, %0|%0, %2}\"\n+  [(set_attr \"type\" \"sse\")])\n+\n+(define_insn \"lshrv8hi3_ti\"\n+  [(set (match_operand:V8HI 0 \"register_operand\" \"=x\")\n+        (lshiftrt:V8HI (match_operand:V8HI 1 \"register_operand\" \"0\")\n+\t\t       (subreg:TI (match_operand:V2DI 2 \"nonmemory_operand\" \"xi\") 0)))]\n+  \"TARGET_SSE2\"\n+  \"psrlw\\t{%2, %0|%0, %2}\"\n+  [(set_attr \"type\" \"sse\")])\n+\n+(define_insn \"lshrv4si3_ti\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x\")\n+        (lshiftrt:V4SI (match_operand:V4SI 1 \"register_operand\" \"0\")\n+\t\t       (subreg:TI (match_operand:V2DI 2 \"nonmemory_operand\" \"xi\") 0)))]\n+  \"TARGET_SSE2\"\n+  \"psrld\\t{%2, %0|%0, %2}\"\n+  [(set_attr \"type\" \"sse\")])\n+\n+(define_insn \"lshrv2di3_ti\"\n+  [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n+        (lshiftrt:V2DI (match_operand:V2DI 1 \"register_operand\" \"0\")\n+\t\t       (subreg:TI (match_operand:V2DI 2 \"nonmemory_operand\" \"xi\") 0)))]\n+  \"TARGET_SSE2\"\n+  \"psrlq\\t{%2, %0|%0, %2}\"\n+  [(set_attr \"type\" \"sse\")])\n+\n+(define_insn \"ashlv8hi3_ti\"\n+  [(set (match_operand:V8HI 0 \"register_operand\" \"=x\")\n+        (ashift:V8HI (match_operand:V8HI 1 \"register_operand\" \"0\")\n+\t\t     (subreg:TI (match_operand:V2DI 2 \"nonmemory_operand\" \"xi\") 0)))]\n+  \"TARGET_SSE2\"\n+  \"psllw\\t{%2, %0|%0, %2}\"\n+  [(set_attr \"type\" \"sse\")])\n+\n+(define_insn \"ashlv4si3_ti\"\n+  [(set (match_operand:V4SI 0 \"register_operand\" \"=x\")\n+        (ashift:V4SI (match_operand:V4SI 1 \"register_operand\" \"0\")\n+\t\t     (subreg:TI (match_operand:V2DI 2 \"nonmemory_operand\" \"xi\") 0)))]\n   \"TARGET_SSE2\"\n   \"pslld\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sseishft\")\n    (set_attr \"mode\" \"TI\")])\n \n-(define_insn \"sse2_ashlv2di3\"\n+(define_insn \"ashlv2di3_ti\"\n   [(set (match_operand:V2DI 0 \"register_operand\" \"=x\")\n         (ashift:V2DI (match_operand:V2DI 1 \"register_operand\" \"0\")\n-\t\t     (match_operand:TI 2 \"nonmemory_operand\" \"xi\")))]\n+\t\t     (subreg:TI (match_operand:V2DI 2 \"nonmemory_operand\" \"xi\") 0)))]\n   \"TARGET_SSE2\"\n   \"psllq\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"sseishft\")"}, {"sha": "294df600cb9692a1d77dd0b285b616f8ae149179", "filename": "gcc/config/i386/xmmintrin.h", "status": "modified", "additions": 923, "deletions": 0, "changes": 923, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/916b60b71e4ac6ef8184427616df27b843de4271/gcc%2Fconfig%2Fi386%2Fxmmintrin.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/916b60b71e4ac6ef8184427616df27b843de4271/gcc%2Fconfig%2Fi386%2Fxmmintrin.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fxmmintrin.h?ref=916b60b71e4ac6ef8184427616df27b843de4271", "patch": "@@ -1058,4 +1058,927 @@ do {\t\t\t\t\t\t\t\t\t\\\n   (row3) = __builtin_ia32_shufps (__t2, __t3, 0xDD);\t\t\t\\\n } while (0)\n \n+/* SSE2 */\n+typedef int __v2df __attribute__ ((mode (V2DF)));\n+typedef int __v2di __attribute__ ((mode (V2DI)));\n+typedef int __v4si __attribute__ ((mode (V4SI)));\n+typedef int __v8hi __attribute__ ((mode (V8HI)));\n+typedef int __v16qi __attribute__ ((mode (V16QI)));\n+\n+#define __m128i __m128\n+#define __m128d __v2df\n+\n+static __inline __m128d\n+_mm_add_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_addpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_add_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_addsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_sub_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_subpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_sub_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_subsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_mul_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_mulpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_mul_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_mulsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_div_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_divpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_div_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_divsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_sqrt_pd (__m128d __A)\n+{\n+  return (__m128d)__builtin_ia32_sqrtpd ((__v2df)__A);\n+}\n+\n+static __inline __m128d\n+_mm_sqrt_sd (__m128d __A)\n+{\n+  return (__m128d)__builtin_ia32_sqrtsd ((__v2df)__A);\n+}\n+\n+static __inline __m128d\n+_mm_min_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_minpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_min_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_minsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_max_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_maxpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_max_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_minsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_and_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_andpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_andnot_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_andnpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_or_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_orpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_xor_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_xorpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpeq_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpeqpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmplt_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpltpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmple_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmplepd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpgt_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpgtpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpge_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpgepd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpneq_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpneqpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpnlt_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpnltpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpnle_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpnlepd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpngt_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpngtpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpnge_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpngepd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpord_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpordpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpunord_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpunordpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpeq_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpeqsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmplt_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpltsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmple_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmplesd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpgt_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpgtsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpge_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpgesd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpneq_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpneqsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpnlt_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpnltsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpnle_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpnlesd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpngt_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpngtsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpnge_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpngesd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpord_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpordsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cmpunord_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cmpunordsd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_comieq_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_comisdeq ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_comilt_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_comisdlt ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_comile_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_comisdle ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_comigt_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_comisdgt ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_comige_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_comisdge ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_comineq_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_comisdneq ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_ucomieq_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_ucomisdeq ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_ucomilt_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_ucomisdlt ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_ucomile_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_ucomisdle ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_ucomigt_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_ucomisdgt ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_ucomige_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_ucomisdge ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_ucomineq_sd (__m128d __A, __m128d __B)\n+{\n+  return __builtin_ia32_ucomisdneq ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_cvtepi32_pd (__m128i __A)\n+{\n+  return (__m128d)__builtin_ia32_cvtdq2pd ((__v4si) __A);\n+}\n+\n+static __inline __m128d\n+_mm_cvtepi32_ps (__m128i __A)\n+{\n+  return (__m128d)__builtin_ia32_cvtdq2ps ((__v4si) __A);\n+}\n+\n+static __inline __m128d\n+_mm_cvtpd_epi32 (__m128d __A)\n+{\n+  return (__m128d)__builtin_ia32_cvtpd2dq ((__v2df) __A);\n+}\n+\n+static __inline __m64\n+_mm_cvtpd_pi32 (__m128d __A)\n+{\n+  return (__m64)__builtin_ia32_cvtpd2pi ((__v2df) __A);\n+}\n+\n+static __inline __m128d\n+_mm_cvtpd_ps (__m128d __A)\n+{\n+  return (__m128d)__builtin_ia32_cvtpd2ps ((__v2df) __A);\n+}\n+\n+static __inline __m128d\n+_mm_cvttpd_epi32 (__m128d __A)\n+{\n+  return (__m128d)__builtin_ia32_cvttpd2dq ((__v2df) __A);\n+}\n+\n+static __inline __m64\n+_mm_cvttpd_pi32 (__m128d __A)\n+{\n+  return (__m64)__builtin_ia32_cvttpd2pi ((__v2df) __A);\n+}\n+\n+static __inline __m128d\n+_mm_cvtpi32_pd (__m64 __A)\n+{\n+  return (__m128d)__builtin_ia32_cvtpi2pd ((__v2si) __A);\n+}\n+\n+static __inline __m128d\n+_mm_cvtps_epi32 (__m128d __A)\n+{\n+  return (__m128d)__builtin_ia32_cvtps2dq ((__v4sf) __A);\n+}\n+\n+static __inline __m128d\n+_mm_cvttps_epi32 (__m128d __A)\n+{\n+  return (__m128d)__builtin_ia32_cvttps2dq ((__v4sf) __A);\n+}\n+\n+static __inline __m128d\n+_mm_cvtps_pd (__m128d __A)\n+{\n+  return (__m128d)__builtin_ia32_cvtps2pd ((__v4sf) __A);\n+}\n+\n+static __inline int\n+_mm_cvtsd_si32 (__m128d __A)\n+{\n+  return __builtin_ia32_cvtsd2si ((__v2df) __A);\n+}\n+\n+static __inline int\n+_mm_cvttsd_si32 (__m128d __A)\n+{\n+  return __builtin_ia32_cvttsd2si ((__v2df) __A);\n+}\n+\n+static __inline __m128d\n+_mm_cvtsd_ss (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cvtsd2ss ((__v4sf) __A, (__v2df) __B);\n+}\n+\n+static __inline __m128d\n+_mm_cvtsi32_sd (__m128d __A, int __B)\n+{\n+  return (__m128d)__builtin_ia32_cvtsi2sd ((__v2df) __A, __B);\n+}\n+\n+static __inline __m128d\n+_mm_cvtss_sd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_cvtss2sd ((__v2df) __A, (__v4sf)__B);\n+}\n+\n+#define _mm_shuffle_pd(__A, __B, __C) ((__m128d)__builtin_ia32_shufpd ((__v2df)__A, (__v2df)__B, (C)))\n+\n+static __inline __m128d\n+_mm_unpackhi_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_unpckhpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_unpacklo_pd (__m128d __A, __m128d __B)\n+{\n+  return (__m128d)__builtin_ia32_unpcklpd ((__v2df)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_loadh_pd (__m128d __A, __m128d *__B)\n+{\n+  return (__m128d)__builtin_ia32_loadhpd ((__v2df)__A, (__v2si *)__B);\n+}\n+\n+static __inline void\n+_mm_storeh_pd (__m128d *__A, __m128d __B)\n+{\n+  __builtin_ia32_storehpd ((__v2si *)__A, (__v2df)__B);\n+}\n+\n+static __inline __m128d\n+_mm_loadl_pd (__m128d __A, __m128d *__B)\n+{\n+  return (__m128d)__builtin_ia32_loadlpd ((__v2df)__A, (__v2si *)__B);\n+}\n+\n+static __inline void\n+_mm_storel_pd (__m128d *__A, __m128d __B)\n+{\n+  __builtin_ia32_storelpd ((__v2si *)__A, (__v2df)__B);\n+}\n+\n+static __inline int\n+_mm_movemask_pd (__m128d __A)\n+{\n+  return __builtin_ia32_movmskpd ((__v2df)__A);\n+}\n+\n+static __inline __m128i\n+_mm_packs_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_packsswb128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_packs_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_packssdw128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_packus_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_packuswb128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_unpackhi_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_punpckhbw128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_unpackhi_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_punpckhwd128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_unpackhi_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_punpckhdq128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_unpacklo_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_punpcklbw128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_unpacklo_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_punpcklwd128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_unpacklo_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_punpckldq128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_add_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_add_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_add_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddd128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_add_epi64 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddq128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_adds_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddsb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_adds_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddsw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_adds_epu8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddusb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_adds_epu16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_paddusw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sub_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sub_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sub_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubd128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sub_epi64 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubq128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_subs_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubsb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_subs_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubsw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_subs_epu8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubusb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_subs_epu16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psubusw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_madd_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pmaddwd128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_mulhi_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pmulhw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_mullo_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pmullw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m64\n+_mm_mul_pu16 (__m64 __A, __m64 __B)\n+{\n+  return (__m64)__builtin_ia32_pmuludq ((__v2si)__A, (__v2si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_mul_epu16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pmuludq128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sll_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psllw128 ((__v8hi)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sll_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pslld128 ((__v4si)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sll_epi64 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psllq128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sra_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psraw128 ((__v8hi)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sra_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psrad128 ((__v4si)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_srl_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psrlw128 ((__v8hi)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_srl_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psrld128 ((__v4si)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_srl_epi64 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psrlq128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_slli_epi16 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_psllwi128 ((__v8hi)__A, __B);\n+}\n+\n+static __inline __m128i\n+_mm_slli_epi32 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_pslldi128 ((__v4si)__A, __B);\n+}\n+\n+static __inline __m128i\n+_mm_slli_epi64 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_psllqi128 ((__v2di)__A, __B);\n+}\n+\n+static __inline __m128i\n+_mm_srai_epi16 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_psrawi128 ((__v8hi)__A, __B);\n+}\n+\n+static __inline __m128i\n+_mm_srai_epi32 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_psradi128 ((__v4si)__A, __B);\n+}\n+\n+static __inline __m128i\n+_mm_srli_epi16 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_psrlwi128 ((__v8hi)__A, __B);\n+}\n+\n+static __inline __m128i\n+_mm_srli_epi32 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_psrldi128 ((__v4si)__A, __B);\n+}\n+\n+static __inline __m128i\n+_mm_srli_epi64 (__m128i __A, int __B)\n+{\n+  return (__m128i)__builtin_ia32_psrlqi128 ((__v2di)__A, __B);\n+}\n+\n+static __inline __m128i\n+_mm_and_si128 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pand128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_andnot_si128 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pandn128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_or_si128 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_por128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_xor_si128 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pxor128 ((__v2di)__A, (__v2di)__B);\n+}\n+\n+static __inline __m128i\n+_mm_cmpeq_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pcmpeqb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_cmpeq_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pcmpeqw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_cmpeq_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pcmpeqd128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+static __inline __m128i\n+_mm_cmpgt_epi8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pcmpgtb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_cmpgt_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pcmpgtw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_cmpgt_epi32 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pcmpgtd128 ((__v4si)__A, (__v4si)__B);\n+}\n+\n+#define _mm_extract_epi16(__A, __B) __builtin_ia32_pextrw128 ((__v8hi)__A, __B)\n+\n+#define _mm_insert_epi16 (__A, __B, __C) ((__m128i)__builtin_ia32_pinsrw128 ((__v8hi)__A, __B, __C))\n+\n+static __inline __m128i\n+_mm_max_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pmaxsw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_max_epu8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pmaxub128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_min_epi16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pminsw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_min_epu8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pminub128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline int\n+_mm_movemask_epi8 (__m128i __A)\n+{\n+  return __builtin_ia32_pmovmskb128 ((__v16qi)__A);\n+}\n+\n+static __inline __m128i\n+_mm_mulhi_epu16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pmulhuw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+#define _mm_shufflehi_epi16(__A, __B) ((__m128i)__builtin_ia32_pshufhw128 ((__v8hi)__A, __B))\n+#define _mm_shufflelo_epi16(__A, __B) ((__m128i)__builtin_ia32_pshuflw128 ((__v8hi)__A, __B))\n+#define _mm_shuffle_epi32(__A, __B) ((__m128i)__builtin_ia32_pshufd ((__v4si)__A, __B))\n+\n+static __inline void\n+_mm_maskmoveu_si128 (__m128i __A, __m128i __B, char *__C)\n+{\n+  __builtin_ia32_maskmovdqu ((__v16qi)__A, (__v16qi)__B, __C);\n+}\n+\n+static __inline __m128i\n+_mm_avg_epu8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pavgb128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_avg_epu16 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_pavgw128 ((__v8hi)__A, (__v8hi)__B);\n+}\n+\n+static __inline __m128i\n+_mm_sad_epu8 (__m128i __A, __m128i __B)\n+{\n+  return (__m128i)__builtin_ia32_psadbw128 ((__v16qi)__A, (__v16qi)__B);\n+}\n+\n+static __inline void\n+_mm_stream_si32 (int *__A, int __B)\n+{\n+  __builtin_ia32_movnti (__A, __B);\n+}\n+\n+static __inline void\n+_mm_stream_si128 (__m128i *__A, __m128i __B)\n+{\n+  __builtin_ia32_movntdq ((__v2di *)__A, (__v2di)__B);\n+}\n+\n+static __inline void\n+_mm_stream_pd (__m128d *__A, __m128d __B)\n+{\n+  __builtin_ia32_movntpd (__A, (__v2df)__B);\n+}\n+\n+static __inline __m128i\n+_mm_movpi64_epi64 (__m64 __A)\n+{\n+  return (__m128i)__builtin_ia32_movq2dq ((unsigned long long)__A);\n+}\n+\n+static __inline void\n+_mm_clflush (void *__A)\n+{\n+  return __builtin_ia32_clflush (__A);\n+}\n+\n+static __inline void\n+_mm_lfence (void)\n+{\n+  __builtin_ia32_lfence ();\n+}\n+\n+static __inline void\n+_mm_mfence (void)\n+{\n+  __builtin_ia32_mfence ();\n+}\n+\n+/* End of SSE2.  */\n+\n+\n #endif /* _XMMINTRIN_H_INCLUDED */"}]}