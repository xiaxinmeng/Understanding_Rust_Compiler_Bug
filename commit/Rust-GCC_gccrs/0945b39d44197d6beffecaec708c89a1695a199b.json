{"sha": "0945b39d44197d6beffecaec708c89a1695a199b", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MDk0NWIzOWQ0NDE5N2Q2YmVmZmVjYWVjNzA4Yzg5YTE2OTVhMTk5Yg==", "commit": {"author": {"name": "Jan Hubicka", "email": "jh@suse.cz", "date": "2001-03-25T12:26:42Z"}, "committer": {"name": "Jan Hubicka", "email": "hubicka@gcc.gnu.org", "date": "2001-03-25T12:26:42Z"}, "message": "i386.md (movstrsi): Move offline.\n\n\t* i386.md (movstrsi): Move offline.\n\t(movstrdi): New.\n\t(strmovdi_rex64): New.\n\t(strmov?i): Accept 64bit.\n\t(strmov?i_rex64): New.\n\t(strmov?i_rex_1): New.\n\t(strmov?i_1): Disable for 64bit.\n\t(rep_mov?i_rex64): New.\n\t(rep_mov?i): Disable for 64bit.\n\t(clrstrsi): Move offline.\n\t(strset?i_rex64): New.\n\t(strset?i: Accept 64bit.\n\t(rep_stos?i): Disable for 64bit.\n\t(rep_stos?i_rex64): New.\n\t(strset?i_rex_1): New.\n\t(strset?i_1): Disable for 64bit.\n\t(cmpstrsi): Accept 64bit.\n\t(cmpstrsi_nz_1): Rename to cmpstrqi_nz_1; Disable for 64bit.\n\t(cmpstrqi_nz_rex_1): New.\n\t(cmpstrsi_1): Rename to cmpstrqi_1; Disable for 64bit.\n\t(strlensi): Move offline.\n\t(strlendi): New.\n\t(strlenqi_1): Disable for 64bit; fix constraints.\n\t(strlenqi_rex_1): New.\n\t* i386.c (ix86_adjust_counter): New static function.\n\t(ix86_zero_extend_to_Pmode): Likewise.\n\t(ix86_expand_aligntest): Likweise.\n\t(ix86_expand_strlensi_unroll_1): Make static; update for 64bit.\n\t(ix86_expand_movstr): New global function.\n\t(ix86_expand_clrstr): New global function.\n\t(ix86_expand_strlen): New global function.\n\t* i386-protos.h (ix86_expand_movstr, ix86_expand_clrstr,\n\tix86_expand_strlen): Declare.\n\t(ix86_expand_strlensi_unroll_1): Delete.\n\nFrom-SVN: r40826", "tree": {"sha": "730b0ce92a0797055f0799c51145e7908f93dcc5", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/730b0ce92a0797055f0799c51145e7908f93dcc5"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/0945b39d44197d6beffecaec708c89a1695a199b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0945b39d44197d6beffecaec708c89a1695a199b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0945b39d44197d6beffecaec708c89a1695a199b", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0945b39d44197d6beffecaec708c89a1695a199b/comments", "author": null, "committer": null, "parents": [{"sha": "392f8d40cd63ce39dfe7500c0f31decc81cdce9f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/392f8d40cd63ce39dfe7500c0f31decc81cdce9f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/392f8d40cd63ce39dfe7500c0f31decc81cdce9f"}], "stats": {"total": 1627, "additions": 1171, "deletions": 456}, "files": [{"sha": "e681730c832f1d0e3ddaf2d9cb54eec7e66fe54b", "filename": "gcc/ChangeLog", "status": "modified", "additions": 37, "deletions": 0, "changes": 37, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0945b39d44197d6beffecaec708c89a1695a199b/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0945b39d44197d6beffecaec708c89a1695a199b/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=0945b39d44197d6beffecaec708c89a1695a199b", "patch": "@@ -1,3 +1,40 @@\n+Sun Mar 25 14:25:33 CEST 2001  Jan Hubicka  <jh@suse.cz>\n+\n+\t* i386.md (movstrsi): Move offline.\n+\t(movstrdi): New.\n+\t(strmovdi_rex64): New.\n+\t(strmov?i): Accept 64bit.\n+\t(strmov?i_rex64): New.\n+\t(strmov?i_rex_1): New.\n+\t(strmov?i_1): Disable for 64bit.\n+\t(rep_mov?i_rex64): New.\n+\t(rep_mov?i): Disable for 64bit.\n+\t(clrstrsi): Move offline.\n+\t(strset?i_rex64): New.\n+\t(strset?i: Accept 64bit.\n+\t(rep_stos?i): Disable for 64bit.\n+\t(rep_stos?i_rex64): New.\n+\t(strset?i_rex_1): New.\n+\t(strset?i_1): Disable for 64bit.\n+\t(cmpstrsi): Accept 64bit.\n+\t(cmpstrsi_nz_1): Rename to cmpstrqi_nz_1; Disable for 64bit.\n+\t(cmpstrqi_nz_rex_1): New.\n+\t(cmpstrsi_1): Rename to cmpstrqi_1; Disable for 64bit.\n+\t(strlensi): Move offline.\n+\t(strlendi): New.\n+\t(strlenqi_1): Disable for 64bit; fix constraints.\n+\t(strlenqi_rex_1): New.\n+\t* i386.c (ix86_adjust_counter): New static function.\n+\t(ix86_zero_extend_to_Pmode): Likewise.\n+\t(ix86_expand_aligntest): Likweise.\n+\t(ix86_expand_strlensi_unroll_1): Make static; update for 64bit.\n+\t(ix86_expand_movstr): New global function.\n+\t(ix86_expand_clrstr): New global function.\n+\t(ix86_expand_strlen): New global function.\n+\t* i386-protos.h (ix86_expand_movstr, ix86_expand_clrstr,\n+\tix86_expand_strlen): Declare.\n+\t(ix86_expand_strlensi_unroll_1): Delete.\n+\n Sat Mar 24 23:15:19 CET 2001  Jan Hubicka  <jh@suse.cz>\n \n \t* i386.md (cmpdi): Fix operand predicates."}, {"sha": "28fc3ffebfe1035944fe8d9f8e296cce5804182e", "filename": "gcc/config/i386/i386-protos.h", "status": "modified", "additions": 3, "deletions": 1, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0945b39d44197d6beffecaec708c89a1695a199b/gcc%2Fconfig%2Fi386%2Fi386-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0945b39d44197d6beffecaec708c89a1695a199b/gcc%2Fconfig%2Fi386%2Fi386-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-protos.h?ref=0945b39d44197d6beffecaec708c89a1695a199b", "patch": "@@ -80,6 +80,9 @@ extern int long_memory_operand PARAMS ((rtx, enum machine_mode));\n extern int aligned_operand PARAMS ((rtx, enum machine_mode));\n extern enum machine_mode ix86_cc_mode PARAMS ((enum rtx_code, rtx, rtx));\n \n+extern int ix86_expand_movstr PARAMS ((rtx, rtx, rtx, rtx));\n+extern int ix86_expand_clrstr PARAMS ((rtx, rtx, rtx));\n+extern int ix86_expand_strlen PARAMS ((rtx, rtx, rtx, rtx));\n \n extern int legitimate_pic_address_disp_p PARAMS ((rtx));\n extern int legitimate_address_p PARAMS ((enum machine_mode, rtx, int));\n@@ -119,7 +122,6 @@ extern void ix86_split_long_move PARAMS ((rtx[]));\n extern void ix86_split_ashldi PARAMS ((rtx *, rtx));\n extern void ix86_split_ashrdi PARAMS ((rtx *, rtx));\n extern void ix86_split_lshrdi PARAMS ((rtx *, rtx));\n-extern void ix86_expand_strlensi_unroll_1 PARAMS ((rtx, rtx, rtx));\n extern int ix86_address_cost PARAMS ((rtx));\n extern rtx ix86_find_base_term PARAMS ((rtx));\n "}, {"sha": "962d053994994ec6911840ffaeb07eb05dea1dc8", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 582, "deletions": 20, "changes": 602, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0945b39d44197d6beffecaec708c89a1695a199b/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0945b39d44197d6beffecaec708c89a1695a199b/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=0945b39d44197d6beffecaec708c89a1695a199b", "patch": "@@ -566,6 +566,10 @@ static void ix86_set_move_mem_attrs_1 PARAMS ((rtx, rtx, rtx, rtx, rtx));\n static void ix86_sched_reorder_pentium PARAMS((rtx *, rtx *));\n static void ix86_sched_reorder_ppro PARAMS((rtx *, rtx *));\n static HOST_WIDE_INT ix86_GOT_alias_set PARAMS ((void));\n+static void ix86_adjust_counter PARAMS ((rtx, HOST_WIDE_INT));\n+static rtx ix86_zero_extend_to_Pmode PARAMS ((rtx));\n+static rtx ix86_expand_aligntest PARAMS ((rtx, int));\n+static void ix86_expand_strlensi_unroll_1 PARAMS ((rtx, rtx));\n \n struct ix86_address\n {\n@@ -7068,6 +7072,542 @@ ix86_split_lshrdi (operands, scratch)\n     }\n }\n \n+/* Helper function for the string operations bellow.  Dest VARIABLE whether\n+   it is aligned to VALUE bytes.  If true, jump to the label.  */\n+static rtx\n+ix86_expand_aligntest (variable, value)\n+     rtx variable;\n+     int value;\n+{\n+  rtx label = gen_label_rtx ();\n+  rtx tmpcount = gen_reg_rtx (GET_MODE (variable));\n+  if (GET_MODE (variable) == DImode)\n+    emit_insn (gen_anddi3 (tmpcount, variable, GEN_INT (value)));\n+  else\n+    emit_insn (gen_andsi3 (tmpcount, variable, GEN_INT (value)));\n+  emit_cmp_and_jump_insns (tmpcount, const0_rtx, EQ, 0, GET_MODE (variable),\n+\t\t\t   1, 0, label);\n+  return label;\n+}\n+\n+/* Adjust COUNTER by the VALUE.  */\n+static void\n+ix86_adjust_counter (countreg, value)\n+     rtx countreg;\n+     HOST_WIDE_INT value;\n+{\n+  if (GET_MODE (countreg) == DImode)\n+    emit_insn (gen_adddi3 (countreg, countreg, GEN_INT (-value)));\n+  else\n+    emit_insn (gen_addsi3 (countreg, countreg, GEN_INT (-value)));\n+}\n+\n+/* Zero extend possibly SImode EXP to Pmode register.  */\n+static rtx\n+ix86_zero_extend_to_Pmode (exp)\n+   rtx exp;\n+{\n+  rtx r;\n+  if (GET_MODE (exp) == VOIDmode)\n+    return force_reg (Pmode, exp);\n+  if (GET_MODE (exp) == Pmode)\n+    return copy_to_mode_reg (Pmode, exp);\n+  r = gen_reg_rtx (Pmode);\n+  emit_insn (gen_zero_extendsidi2 (r, exp));\n+  return r;\n+}\n+\n+/* Expand string move (memcpy) operation.  Use i386 string operations when\n+   profitable.  expand_clrstr contains similar code.  */\n+int\n+ix86_expand_movstr (dst, src, count_exp, align_exp)\n+     rtx dst, src, count_exp, align_exp;\n+{\n+  rtx srcreg, destreg, countreg;\n+  enum machine_mode counter_mode;\n+  HOST_WIDE_INT align = 0;\n+  unsigned HOST_WIDE_INT count = 0;\n+  rtx insns;\n+\n+  start_sequence ();\n+\n+  if (GET_CODE (align_exp) == CONST_INT)\n+    align = INTVAL (align_exp);\n+\n+  /* This simple hack avoids all inlining code and simplifies code bellow.  */\n+  if (!TARGET_ALIGN_STRINGOPS)\n+    align = 64;\n+\n+  if (GET_CODE (count_exp) == CONST_INT)\n+    count = INTVAL (count_exp);\n+\n+  /* Figure out proper mode for counter.  For 32bits it is always SImode,\n+     for 64bits use SImode when possible, otherwise DImode.\n+     Set count to number of bytes copied when known at compile time.  */\n+  if (!TARGET_64BIT || GET_MODE (count_exp) == SImode\n+      || x86_64_zero_extended_value (count_exp))\n+    counter_mode = SImode;\n+  else\n+    counter_mode = DImode;\n+\n+  if (counter_mode != SImode && counter_mode != DImode)\n+    abort ();\n+\n+  destreg = copy_to_mode_reg (Pmode, XEXP (dst, 0));\n+  srcreg = copy_to_mode_reg (Pmode, XEXP (src, 0));\n+\n+  emit_insn (gen_cld ());\n+\n+  /* When optimizing for size emit simple rep ; movsb instruction for\n+     counts not divisible by 4.  */\n+\n+  if ((!optimize || optimize_size) && (count == 0 || (count & 0x03)))\n+    {\n+      countreg = ix86_zero_extend_to_Pmode (count_exp);\n+      if (TARGET_64BIT)\n+\temit_insn (gen_rep_movqi_rex64 (destreg, srcreg, countreg,\n+\t\t\t\t        destreg, srcreg, countreg));\n+      else\n+\temit_insn (gen_rep_movqi (destreg, srcreg, countreg,\n+\t\t\t\t  destreg, srcreg, countreg));\n+    }\n+\n+  /* For constant aligned (or small unaligned) copies use rep movsl\n+     followed by code copying the rest.  For PentiumPro ensure 8 byte\n+     alignment to allow rep movsl acceleration.  */\n+\n+  else if (count != 0\n+\t   && (align >= 8\n+\t       || (!TARGET_PENTIUMPRO && !TARGET_64BIT && align >= 4)\n+\t       || optimize_size || count < (unsigned int)64))\n+    {\n+      int size = TARGET_64BIT && !optimize_size ? 8 : 4;\n+      if (count & ~(size - 1))\n+\t{\n+\t  countreg = copy_to_mode_reg (counter_mode,\n+\t\t\t\t       GEN_INT ((count >> (size == 4 ? 2 : 3))\n+\t\t\t\t\t\t& (TARGET_64BIT ? -1 : 0x3fffffff)));\n+\t  countreg = ix86_zero_extend_to_Pmode (countreg);\n+\t  if (size == 4)\n+\t    {\n+\t      if (TARGET_64BIT)\n+\t\temit_insn (gen_rep_movsi_rex64 (destreg, srcreg, countreg,\n+\t\t\t\t\t        destreg, srcreg, countreg));\n+\t      else\n+\t\temit_insn (gen_rep_movsi (destreg, srcreg, countreg,\n+\t\t\t\t\t  destreg, srcreg, countreg));\n+\t    }\n+\t  else\n+\t    emit_insn (gen_rep_movdi_rex64 (destreg, srcreg, countreg,\n+\t\t\t\t\t    destreg, srcreg, countreg));\n+\t}\n+      if (size == 8 && (count & 0x04))\n+\temit_insn (gen_strmovsi (destreg, srcreg));\n+      if (count & 0x02)\n+\temit_insn (gen_strmovhi (destreg, srcreg));\n+      if (count & 0x01)\n+\temit_insn (gen_strmovqi (destreg, srcreg));\n+    }\n+  /* The generic code based on the glibc implementation:\n+     - align destination to 4 bytes (8 byte alignment is used for PentiumPro\n+     allowing accelerated copying there)\n+     - copy the data using rep movsl\n+     - copy the rest.  */\n+  else\n+    {\n+      rtx countreg2;\n+      rtx label = NULL;\n+\n+      /* In case we don't know anything about the alignment, default to\n+         library version, since it is usually equally fast and result in\n+         shorter code.  */\n+      if (!TARGET_INLINE_ALL_STRINGOPS && align < UNITS_PER_WORD)\n+\t{\n+\t  end_sequence ();\n+\t  return 0;\n+\t}\n+\n+      if (TARGET_SINGLE_STRINGOP)\n+\temit_insn (gen_cld ());\n+\n+      countreg2 = gen_reg_rtx (Pmode);\n+      countreg = copy_to_mode_reg (counter_mode, count_exp);\n+\n+      /* We don't use loops to align destination and to copy parts smaller\n+         than 4 bytes, because gcc is able to optimize such code better (in\n+         the case the destination or the count really is aligned, gcc is often\n+         able to predict the branches) and also it is friendlier to the\n+         hardware branch prediction.  \n+\n+         Using loops is benefical for generic case, because we can\n+         handle small counts using the loops.  Many CPUs (such as Athlon)\n+         have large REP prefix setup costs.\n+\n+         This is quite costy.  Maybe we can revisit this decision later or\n+         add some customizability to this code.  */\n+\n+      if (count == 0\n+\t  && align < (TARGET_PENTIUMPRO && (count == 0\n+\t\t\t\t\t    || count >= (unsigned int)260)\n+\t\t      ? 8 : UNITS_PER_WORD))\n+\t{\n+\t  label = gen_label_rtx ();\n+\t  emit_cmp_and_jump_insns (countreg, GEN_INT (UNITS_PER_WORD - 1),\n+\t\t\t\t   LEU, 0, counter_mode, 1, 0, label);\n+\t}\n+      if (align <= 1)\n+\t{\n+\t  rtx label = ix86_expand_aligntest (destreg, 1);\n+\t  emit_insn (gen_strmovqi (destreg, srcreg));\n+\t  ix86_adjust_counter (countreg, 1);\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label) = 1;\n+\t}\n+      if (align <= 2)\n+\t{\n+\t  rtx label = ix86_expand_aligntest (destreg, 2);\n+\t  emit_insn (gen_strmovhi (destreg, srcreg));\n+\t  ix86_adjust_counter (countreg, 2);\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label) = 1;\n+\t}\n+      if (align <= 4\n+\t  && ((TARGET_PENTIUMPRO && (count == 0\n+\t\t\t\t     || count >= (unsigned int)260))\n+\t      || TARGET_64BIT))\n+\t{\n+\t  rtx label = ix86_expand_aligntest (destreg, 4);\n+\t  emit_insn (gen_strmovsi (destreg, srcreg));\n+\t  ix86_adjust_counter (countreg, 4);\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label) = 1;\n+\t}\n+\n+      if (!TARGET_SINGLE_STRINGOP)\n+\temit_insn (gen_cld ());\n+      if (TARGET_64BIT)\n+\t{\n+\t  emit_insn (gen_lshrdi3 (countreg2, ix86_zero_extend_to_Pmode (countreg),\n+\t\t\t\t  GEN_INT (3)));\n+\t  emit_insn (gen_rep_movdi_rex64 (destreg, srcreg, countreg2,\n+\t\t\t\t\t  destreg, srcreg, countreg2));\n+\t}\n+      else\n+\t{\n+\t  emit_insn (gen_lshrsi3 (countreg2, countreg, GEN_INT (2)));\n+\t  emit_insn (gen_rep_movsi (destreg, srcreg, countreg2,\n+\t\t\t\t    destreg, srcreg, countreg2));\n+\t}\n+\n+      if (label)\n+\t{\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label) = 1;\n+\t}\n+      if (TARGET_64BIT && align > 4 && count != 0 && (count & 4))\n+\temit_insn (gen_strmovsi (destreg, srcreg));\n+      if ((align <= 4 || count == 0) && TARGET_64BIT)\n+\t{\n+\t  rtx label = ix86_expand_aligntest (countreg, 4);\n+\t  emit_insn (gen_strmovsi (destreg, srcreg));\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label) = 1;\n+\t}\n+      if (align > 2 && count != 0 && (count & 2))\n+\temit_insn (gen_strmovhi (destreg, srcreg));\n+      if (align <= 2 || count == 0)\n+\t{\n+\t  rtx label = ix86_expand_aligntest (countreg, 2);\n+\t  emit_insn (gen_strmovhi (destreg, srcreg));\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label) = 1;\n+\t}\n+      if (align > 1 && count != 0 && (count & 1))\n+\temit_insn (gen_strmovqi (destreg, srcreg));\n+      if (align <= 1 || count == 0)\n+\t{\n+\t  rtx label = ix86_expand_aligntest (countreg, 1);\n+\t  emit_insn (gen_strmovqi (destreg, srcreg));\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label) = 1;\n+\t}\n+    }\n+\n+  insns = get_insns ();\n+  end_sequence ();\n+\n+  ix86_set_move_mem_attrs (insns, dst, src, destreg, srcreg);\n+  emit_insns (insns);\n+  return 1;\n+}\n+\n+/* Expand string clear operation (bzero).  Use i386 string operations when\n+   profitable.  expand_movstr contains similar code.  */\n+int\n+ix86_expand_clrstr (src, count_exp, align_exp)\n+     rtx src, count_exp, align_exp;\n+{\n+  rtx destreg, zeroreg, countreg;\n+  enum machine_mode counter_mode;\n+  HOST_WIDE_INT align = 0;\n+  unsigned HOST_WIDE_INT count = 0;\n+\n+  if (GET_CODE (align_exp) == CONST_INT)\n+    align = INTVAL (align_exp);\n+\n+  /* This simple hack avoids all inlining code and simplifies code bellow.  */\n+  if (!TARGET_ALIGN_STRINGOPS)\n+    align = 32;\n+\n+  if (GET_CODE (count_exp) == CONST_INT)\n+    count = INTVAL (count_exp);\n+  /* Figure out proper mode for counter.  For 32bits it is always SImode,\n+     for 64bits use SImode when possible, otherwise DImode.\n+     Set count to number of bytes copied when known at compile time.  */\n+  if (!TARGET_64BIT || GET_MODE (count_exp) == SImode\n+      || x86_64_zero_extended_value (count_exp))\n+    counter_mode = SImode;\n+  else\n+    counter_mode = DImode;\n+\n+  destreg = copy_to_mode_reg (Pmode, XEXP (src, 0));\n+\n+  emit_insn (gen_cld ());\n+\n+  /* When optimizing for size emit simple rep ; movsb instruction for\n+     counts not divisible by 4.  */\n+\n+  if ((!optimize || optimize_size) && (count == 0 || (count & 0x03)))\n+    {\n+      countreg = ix86_zero_extend_to_Pmode (count_exp);\n+      zeroreg = copy_to_mode_reg (QImode, const0_rtx);\n+      if (TARGET_64BIT)\n+\temit_insn (gen_rep_stosqi_rex64 (destreg, countreg, zeroreg,\n+\t\t\t\t         destreg, countreg));\n+      else\n+\temit_insn (gen_rep_stosqi (destreg, countreg, zeroreg,\n+\t\t\t\t   destreg, countreg));\n+    }\n+  else if (count != 0\n+\t   && (align >= 8\n+\t       || (!TARGET_PENTIUMPRO && !TARGET_64BIT && align >= 4)\n+\t       || optimize_size || count < (unsigned int)64))\n+    {\n+      int size = TARGET_64BIT && !optimize_size ? 8 : 4;\n+      zeroreg = copy_to_mode_reg (size == 4 ? SImode : DImode, const0_rtx);\n+      if (count & ~(size - 1))\n+\t{\n+\t  countreg = copy_to_mode_reg (counter_mode,\n+\t\t\t\t       GEN_INT ((count >> (size == 4 ? 2 : 3))\n+\t\t\t\t\t\t& (TARGET_64BIT ? -1 : 0x3fffffff)));\n+\t  countreg = ix86_zero_extend_to_Pmode (countreg);\n+\t  if (size == 4)\n+\t    {\n+\t      if (TARGET_64BIT)\n+\t\temit_insn (gen_rep_stossi_rex64 (destreg, countreg, zeroreg,\n+\t\t\t\t\t         destreg, countreg));\n+\t      else\n+\t\temit_insn (gen_rep_stossi (destreg, countreg, zeroreg,\n+\t\t\t\t\t   destreg, countreg));\n+\t    }\n+\t  else\n+\t    emit_insn (gen_rep_stosdi_rex64 (destreg, countreg, zeroreg,\n+\t\t\t\t\t     destreg, countreg));\n+\t}\n+      if (size == 8 && (count & 0x04))\n+\temit_insn (gen_strsetsi (destreg,\n+\t\t\t\t gen_rtx_SUBREG (SImode, zeroreg, 0)));\n+      if (count & 0x02)\n+\temit_insn (gen_strsethi (destreg,\n+\t\t\t\t gen_rtx_SUBREG (HImode, zeroreg, 0)));\n+      if (count & 0x01)\n+\temit_insn (gen_strsetqi (destreg,\n+\t\t\t\t gen_rtx_SUBREG (QImode, zeroreg, 0)));\n+    }\n+  else\n+    {\n+      rtx countreg2;\n+      rtx label = NULL;\n+\n+      /* In case we don't know anything about the alignment, default to\n+         library version, since it is usually equally fast and result in\n+         shorter code.  */\n+      if (!TARGET_INLINE_ALL_STRINGOPS && align < UNITS_PER_WORD)\n+\treturn 0;\n+\n+      if (TARGET_SINGLE_STRINGOP)\n+\temit_insn (gen_cld ());\n+\n+      countreg2 = gen_reg_rtx (Pmode);\n+      countreg = copy_to_mode_reg (counter_mode, count_exp);\n+      zeroreg = copy_to_mode_reg (Pmode, const0_rtx);\n+\n+      if (count == 0\n+\t  && align < (TARGET_PENTIUMPRO && (count == 0\n+\t\t\t\t\t    || count >= (unsigned int)260)\n+\t\t      ? 8 : UNITS_PER_WORD))\n+\t{\n+\t  label = gen_label_rtx ();\n+\t  emit_cmp_and_jump_insns (countreg, GEN_INT (UNITS_PER_WORD - 1),\n+\t\t\t\t   LEU, 0, counter_mode, 1, 0, label);\n+\t}\n+      if (align <= 1)\n+\t{\n+\t  rtx label = ix86_expand_aligntest (destreg, 1);\n+\t  emit_insn (gen_strsetqi (destreg,\n+\t\t\t\t   gen_rtx_SUBREG (QImode, zeroreg, 0)));\n+\t  ix86_adjust_counter (countreg, 1);\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label) = 1;\n+\t}\n+      if (align <= 2)\n+\t{\n+\t  rtx label = ix86_expand_aligntest (destreg, 2);\n+\t  emit_insn (gen_strsethi (destreg,\n+\t\t\t\t   gen_rtx_SUBREG (HImode, zeroreg, 0)));\n+\t  ix86_adjust_counter (countreg, 2);\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label) = 1;\n+\t}\n+      if (align <= 4 && TARGET_PENTIUMPRO && (count == 0\n+\t\t\t\t\t      || count >= (unsigned int)260))\n+\t{\n+\t  rtx label = ix86_expand_aligntest (destreg, 4);\n+\t  emit_insn (gen_strsetsi (destreg, (TARGET_64BIT\n+\t\t\t\t\t     ? gen_rtx_SUBREG (SImode, zeroreg, 0)\n+\t\t\t\t\t     : zeroreg)));\n+\t  ix86_adjust_counter (countreg, 4);\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label) = 1;\n+\t}\n+\n+      if (!TARGET_SINGLE_STRINGOP)\n+\temit_insn (gen_cld ());\n+      if (TARGET_64BIT)\n+\t{\n+\t  emit_insn (gen_lshrdi3 (countreg2, ix86_zero_extend_to_Pmode (countreg),\n+\t\t\t\t  GEN_INT (3)));\n+\t  emit_insn (gen_rep_stosdi_rex64 (destreg, countreg2, zeroreg,\n+\t\t\t\t\t   destreg, countreg2));\n+\t}\n+      else\n+\t{\n+\t  emit_insn (gen_lshrsi3 (countreg2, countreg, GEN_INT (2)));\n+\t  emit_insn (gen_rep_stossi (destreg, countreg2, zeroreg,\n+\t\t\t\t     destreg, countreg2));\n+\t}\n+\n+      if (label)\n+\t{\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label) = 1;\n+\t}\n+      if (TARGET_64BIT && align > 4 && count != 0 && (count & 4))\n+\temit_insn (gen_strsetsi (destreg,\n+\t\t\t\t gen_rtx_SUBREG (SImode, zeroreg, 0)));\n+      if (TARGET_64BIT && (align <= 4 || count == 0))\n+\t{\n+\t  rtx label = ix86_expand_aligntest (destreg, 2);\n+\t  emit_insn (gen_strsetsi (destreg,\n+\t\t\t\t   gen_rtx_SUBREG (SImode, zeroreg, 0)));\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label) = 1;\n+\t}\n+      if (align > 2 && count != 0 && (count & 2))\n+\temit_insn (gen_strsethi (destreg,\n+\t\t\t\t gen_rtx_SUBREG (HImode, zeroreg, 0)));\n+      if (align <= 2 || count == 0)\n+\t{\n+\t  rtx label = ix86_expand_aligntest (destreg, 2);\n+\t  emit_insn (gen_strsethi (destreg,\n+\t\t\t\t   gen_rtx_SUBREG (HImode, zeroreg, 0)));\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label) = 1;\n+\t}\n+      if (align > 1 && count != 0 && (count & 1))\n+\temit_insn (gen_strsetqi (destreg,\n+\t\t\t\t gen_rtx_SUBREG (QImode, zeroreg, 0)));\n+      if (align <= 1 || count == 0)\n+\t{\n+\t  rtx label = ix86_expand_aligntest (destreg, 1);\n+\t  emit_insn (gen_strsetqi (destreg,\n+\t\t\t\t   gen_rtx_SUBREG (QImode, zeroreg, 0)));\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label) = 1;\n+\t}\n+    }\n+  return 1;\n+}\n+/* Expand strlen.  */\n+int\n+ix86_expand_strlen (out, src, eoschar, align)\n+     rtx out, src, eoschar, align;\n+{\n+  rtx addr, scratch1, scratch2, scratch3, scratch4;\n+\n+  /* The generic case of strlen expander is long.  Avoid it's\n+     expanding unless TARGET_INLINE_ALL_STRINGOPS.  */\n+\n+  if (TARGET_UNROLL_STRLEN && eoschar == const0_rtx && optimize > 1\n+      && !TARGET_INLINE_ALL_STRINGOPS\n+      && !optimize_size\n+      && (GET_CODE (align) != CONST_INT || INTVAL (align) < 4))\n+    return 0;\n+\n+  addr = force_reg (Pmode, XEXP (src, 0));\n+  scratch1 = gen_reg_rtx (Pmode);\n+\n+  if (TARGET_UNROLL_STRLEN && eoschar == const0_rtx && optimize > 1\n+      && !optimize_size)\n+    {\n+      /* Well it seems that some optimizer does not combine a call like\n+         foo(strlen(bar), strlen(bar));\n+         when the move and the subtraction is done here.  It does calculate\n+         the length just once when these instructions are done inside of\n+         output_strlen_unroll().  But I think since &bar[strlen(bar)] is\n+         often used and I use one fewer register for the lifetime of\n+         output_strlen_unroll() this is better.  */\n+\n+      emit_move_insn (out, addr);\n+\n+      ix86_expand_strlensi_unroll_1 (out, align);\n+\n+      /* strlensi_unroll_1 returns the address of the zero at the end of\n+         the string, like memchr(), so compute the length by subtracting\n+         the start address.  */\n+      if (TARGET_64BIT)\n+\temit_insn (gen_subdi3 (out, out, addr));\n+      else\n+\temit_insn (gen_subsi3 (out, out, addr));\n+    }\n+  else\n+    {\n+      scratch2 = gen_reg_rtx (Pmode);\n+      scratch3 = gen_reg_rtx (Pmode);\n+      scratch4 = force_reg (Pmode, constm1_rtx);\n+\n+      emit_move_insn (scratch3, addr);\n+      eoschar = force_reg (QImode, eoschar);\n+\n+      emit_insn (gen_cld ());\n+      if (TARGET_64BIT)\n+\t{\n+\t  emit_insn (gen_strlenqi_rex_1 (scratch1, scratch3, eoschar,\n+\t\t\t\t\t align, scratch4, scratch3));\n+\t  emit_insn (gen_one_cmpldi2 (scratch2, scratch1));\n+\t  emit_insn (gen_adddi3 (out, scratch2, constm1_rtx));\n+\t}\n+      else\n+\t{\n+\t  emit_insn (gen_strlenqi_1 (scratch1, scratch3, eoschar,\n+\t\t\t\t     align, scratch4, scratch3));\n+\t  emit_insn (gen_one_cmplsi2 (scratch2, scratch1));\n+\t  emit_insn (gen_addsi3 (out, scratch2, constm1_rtx));\n+\t}\n+    }\n+  return 1;\n+}\n+\n /* Expand the appropriate insns for doing strlen if not just doing\n    repnz; scasb\n \n@@ -7079,9 +7619,9 @@ ix86_split_lshrdi (operands, scratch)\n    This is just the body. It needs the initialisations mentioned above and\n    some address computing at the end.  These things are done in i386.md.  */\n \n-void\n-ix86_expand_strlensi_unroll_1 (out, align_rtx, scratch)\n-     rtx out, align_rtx, scratch;\n+static void\n+ix86_expand_strlensi_unroll_1 (out, align_rtx)\n+     rtx out, align_rtx;\n {\n   int align;\n   rtx tmp;\n@@ -7091,6 +7631,7 @@ ix86_expand_strlensi_unroll_1 (out, align_rtx, scratch)\n   rtx end_0_label = gen_label_rtx ();\n   rtx mem;\n   rtx tmpreg = gen_reg_rtx (SImode);\n+  rtx scratch = gen_reg_rtx (SImode);\n \n   align = 0;\n   if (GET_CODE (align_rtx) == CONST_INT)\n@@ -7101,33 +7642,35 @@ ix86_expand_strlensi_unroll_1 (out, align_rtx, scratch)\n   /* Is there a known alignment and is it less than 4?  */\n   if (align < 4)\n     {\n+      rtx scratch1 = gen_reg_rtx (Pmode);\n+      emit_move_insn (scratch1, out);\n       /* Is there a known alignment and is it not 2? */\n       if (align != 2)\n \t{\n \t  align_3_label = gen_label_rtx (); /* Label when aligned to 3-byte */\n \t  align_2_label = gen_label_rtx (); /* Label when aligned to 2-byte */\n \n \t  /* Leave just the 3 lower bits.  */\n-\t  align_rtx = expand_binop (SImode, and_optab, scratch, GEN_INT (3),\n+\t  align_rtx = expand_binop (Pmode, and_optab, scratch1, GEN_INT (3),\n \t\t\t\t    NULL_RTX, 0, OPTAB_WIDEN);\n \n \t  emit_cmp_and_jump_insns (align_rtx, const0_rtx, EQ, NULL,\n-\t\t\t\t   SImode, 1, 0, align_4_label);\n+\t\t\t\t   Pmode, 1, 0, align_4_label);\n \t  emit_cmp_and_jump_insns (align_rtx, GEN_INT (2), EQ, NULL,\n-\t\t\t\t   SImode, 1, 0, align_2_label);\n+\t\t\t\t   Pmode, 1, 0, align_2_label);\n \t  emit_cmp_and_jump_insns (align_rtx, GEN_INT (2), GTU, NULL,\n-\t\t\t\t   SImode, 1, 0, align_3_label);\n+\t\t\t\t   Pmode, 1, 0, align_3_label);\n \t}\n       else\n         {\n \t  /* Since the alignment is 2, we have to check 2 or 0 bytes;\n \t     check if is aligned to 4 - byte.  */\n \n-\t  align_rtx = expand_binop (SImode, and_optab, scratch, GEN_INT (2),\n+\t  align_rtx = expand_binop (Pmode, and_optab, scratch1, GEN_INT (2),\n \t\t\t\t    NULL_RTX, 0, OPTAB_WIDEN);\n \n \t  emit_cmp_and_jump_insns (align_rtx, const0_rtx, EQ, NULL,\n-\t\t\t\t   SImode, 1, 0, align_4_label);\n+\t\t\t\t   Pmode, 1, 0, align_4_label);\n         }\n \n       mem = gen_rtx_MEM (QImode, out);\n@@ -7139,7 +7682,10 @@ ix86_expand_strlensi_unroll_1 (out, align_rtx, scratch)\n \t\t\t       QImode, 1, 0, end_0_label);\n \n       /* Increment the address.  */\n-      emit_insn (gen_addsi3 (out, out, const1_rtx));\n+      if (TARGET_64BIT)\n+\temit_insn (gen_adddi3 (out, out, const1_rtx));\n+      else\n+\temit_insn (gen_addsi3 (out, out, const1_rtx));\n \n       /* Not needed with an alignment of 2 */\n       if (align != 2)\n@@ -7149,15 +7695,21 @@ ix86_expand_strlensi_unroll_1 (out, align_rtx, scratch)\n \t  emit_cmp_and_jump_insns (mem, const0_rtx, EQ, NULL,\n \t\t\t\t   QImode, 1, 0, end_0_label);\n \n-\t  emit_insn (gen_addsi3 (out, out, const1_rtx));\n+\t  if (TARGET_64BIT)\n+\t    emit_insn (gen_adddi3 (out, out, const1_rtx));\n+\t  else\n+\t    emit_insn (gen_addsi3 (out, out, const1_rtx));\n \n \t  emit_label (align_3_label);\n \t}\n \n       emit_cmp_and_jump_insns (mem, const0_rtx, EQ, NULL,\n \t\t\t       QImode, 1, 0, end_0_label);\n \n-      emit_insn (gen_addsi3 (out, out, const1_rtx));\n+      if (TARGET_64BIT)\n+\temit_insn (gen_adddi3 (out, out, const1_rtx));\n+      else\n+\temit_insn (gen_addsi3 (out, out, const1_rtx));\n     }\n \n   /* Generate loop to check 4 bytes at a time.  It is not a good idea to\n@@ -7167,7 +7719,10 @@ ix86_expand_strlensi_unroll_1 (out, align_rtx, scratch)\n \n   mem = gen_rtx_MEM (SImode, out);\n   emit_move_insn (scratch, mem);\n-  emit_insn (gen_addsi3 (out, out, GEN_INT (4)));\n+  if (TARGET_64BIT)\n+    emit_insn (gen_adddi3 (out, out, GEN_INT (4)));\n+  else\n+    emit_insn (gen_addsi3 (out, out, GEN_INT (4)));\n \n   /* This formula yields a nonzero result iff one of the bytes is zero.\n      This saves three branches inside loop and many cycles.  */\n@@ -7182,6 +7737,7 @@ ix86_expand_strlensi_unroll_1 (out, align_rtx, scratch)\n   if (TARGET_CMOVE)\n     {\n        rtx reg = gen_reg_rtx (SImode);\n+       rtx reg2 = gen_reg_rtx (Pmode);\n        emit_move_insn (reg, tmpreg);\n        emit_insn (gen_lshrsi3 (reg, reg, GEN_INT (16)));\n \n@@ -7194,15 +7750,15 @@ ix86_expand_strlensi_unroll_1 (out, align_rtx, scratch)\n \t\t\t\t\t\t     reg,\n \t\t\t\t\t\t     tmpreg)));\n        /* Emit lea manually to avoid clobbering of flags.  */\n-       emit_insn (gen_rtx_SET (SImode, reg,\n-\t\t\t       gen_rtx_PLUS (SImode, out, GEN_INT (2))));\n+       emit_insn (gen_rtx_SET (SImode, reg2,\n+\t\t\t       gen_rtx_PLUS (Pmode, out, GEN_INT (2))));\n \n        tmp = gen_rtx_REG (CCNOmode, FLAGS_REG);\n        tmp = gen_rtx_EQ (VOIDmode, tmp, const0_rtx);\n        emit_insn (gen_rtx_SET (VOIDmode, out,\n-\t\t\t       gen_rtx_IF_THEN_ELSE (SImode, tmp,\n-\t\t\t\t\t\t     reg,\n-\t\t\t\t\t\t     out)));\n+\t\t\t       gen_rtx_IF_THEN_ELSE (Pmode, tmp,\n+\t\t\t\t       \t\t     reg2,\n+\t\t\t\t       \t\t     out)));\n \n     }\n   else\n@@ -7221,7 +7777,10 @@ ix86_expand_strlensi_unroll_1 (out, align_rtx, scratch)\n \n        /* Not in the first two.  Move two bytes forward.  */\n        emit_insn (gen_lshrsi3 (tmpreg, tmpreg, GEN_INT (16)));\n-       emit_insn (gen_addsi3 (out, out, GEN_INT (2)));\n+       if (TARGET_64BIT)\n+\t emit_insn (gen_adddi3 (out, out, GEN_INT (2)));\n+       else\n+\t emit_insn (gen_addsi3 (out, out, GEN_INT (2)));\n \n        emit_label (end_2_label);\n \n@@ -7230,7 +7789,10 @@ ix86_expand_strlensi_unroll_1 (out, align_rtx, scratch)\n   /* Avoid branch in fixing the byte.  */\n   tmpreg = gen_lowpart (QImode, tmpreg);\n   emit_insn (gen_addqi3_cc (tmpreg, tmpreg, tmpreg));\n-  emit_insn (gen_subsi3_carry (out, out, GEN_INT (3)));\n+  if (TARGET_64BIT)\n+    emit_insn (gen_subdi3_carry_rex64 (out, out, GEN_INT (3)));\n+  else\n+    emit_insn (gen_subsi3_carry (out, out, GEN_INT (3)));\n \n   emit_label (end_0_label);\n }"}, {"sha": "7a4e0fc4e54f2b1b721a98ce525564c485875d7a", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 549, "deletions": 435, "changes": 984, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0945b39d44197d6beffecaec708c89a1695a199b/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0945b39d44197d6beffecaec708c89a1695a199b/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=0945b39d44197d6beffecaec708c89a1695a199b", "patch": "@@ -13340,192 +13340,51 @@\n   \"\"\n   \"\n {\n-  rtx srcreg, destreg, countreg;\n-  int align = 0;\n-  int count = -1;\n-  rtx insns;\n-\n-  start_sequence ();\n-\n-  if (GET_CODE (operands[3]) == CONST_INT)\n-    align = INTVAL (operands[3]);\n-\n-  /* This simple hack avoids all inlining code and simplifies code bellow.  */\n-  if (!TARGET_ALIGN_STRINGOPS)\n-    align = 32;\n-\n-  if (GET_CODE (operands[2]) == CONST_INT)\n-    count = INTVAL (operands[2]);\n-\n-  destreg = copy_to_mode_reg (Pmode, XEXP (operands[0], 0));\n-  srcreg = copy_to_mode_reg (Pmode, XEXP (operands[1], 0));\n-\n-  emit_insn (gen_cld ());\n-\n-  /* When optimizing for size emit simple rep ; movsb instruction for\n-     counts not divisible by 4.  */\n+ if (ix86_expand_movstr (operands[0], operands[1], operands[2], operands[3]))\n+   DONE;\n+ else\n+   FAIL;\n+}\")\n \n-  if ((!optimize || optimize_size) \n-      && (count < 0 || (count & 0x03)))\n-    {\n-      countreg = copy_to_mode_reg (SImode, operands[2]);\n-      emit_insn (gen_rep_movqi (destreg, srcreg, countreg,\n-      \t\t\t\tdestreg, srcreg, countreg));\n-    }\n+(define_expand \"movstrdi\"\n+  [(use (match_operand:BLK 0 \"memory_operand\" \"\"))\n+   (use (match_operand:BLK 1 \"memory_operand\" \"\"))\n+   (use (match_operand:DI 2 \"nonmemory_operand\" \"\"))\n+   (use (match_operand:DI 3 \"const_int_operand\" \"\"))]\n+  \"TARGET_64BIT\"\n+  \"\n+{\n+ if (ix86_expand_movstr (operands[0], operands[1], operands[2], operands[3]))\n+   DONE;\n+ else\n+   FAIL;\n+}\")\n \n-  /* For constant aligned (or small unaligned) copies use rep movsl\n-     followed by code copying the rest.  For PentiumPro ensure 8 byte\n-     alignment to allow rep movsl acceleration.  */\n+;; Most CPUs don't like single string operations\n+;; Handle this case here to simplify previous expander.\n \n-  else if (count >= 0 \n-\t   && (align >= 8\n-\t       || (!TARGET_PENTIUMPRO && align >= 4)\n-\t       || optimize_size || count < 64))\n-    {\n-      if (count & ~0x03)\n-\t{\n-\t  countreg = copy_to_mode_reg (SImode,\n-\t  \t\t\t       GEN_INT ((count >> 2)\n-\t\t\t\t\t\t& 0x3fffffff));\n-\t  emit_insn (gen_rep_movsi (destreg, srcreg, countreg,\n-\t\t\t\t    destreg, srcreg, countreg));\n-\t}\n-      if (count & 0x02)\n-\temit_insn (gen_strmovhi (destreg, srcreg));\n-      if (count & 0x01)\n-\temit_insn (gen_strmovqi (destreg, srcreg));\n-    }\n-  /* The generic code based on the glibc implementation:\n-     - align destination to 4 bytes (8 byte alignment is used for PentiumPro\n-       allowing accelerated copying there)\n-     - copy the data using rep movsl\n-     - copy the rest.  */\n-  else\n+(define_expand \"strmovdi_rex64\"\n+  [(set (match_dup 2)\n+  \t(mem:DI (match_operand:DI 1 \"register_operand\" \"\")))\n+   (set (mem:DI (match_operand:DI 0 \"register_operand\" \"\"))\n+        (match_dup 2))\n+   (parallel [(set (match_dup 0) (plus:DI (match_dup 0) (const_int 8)))\n+\t      (clobber (reg:CC 17))])\n+   (parallel [(set (match_dup 1) (plus:DI (match_dup 1) (const_int 8)))\n+\t      (clobber (reg:CC 17))])]\n+  \"TARGET_64BIT\"\n+  \"\n+{\n+  if (TARGET_SINGLE_STRINGOP || optimize_size)\n     {\n-      rtx countreg2;\n-      rtx label = NULL;\n-\n-      /* In case we don't know anything about the alignment, default to\n-         library version, since it is usually equally fast and result in\n-\t shorter code.  */\n-      if (!TARGET_INLINE_ALL_STRINGOPS && align < 4)\n-\t{\n-\t  end_sequence ();\n-\t  FAIL;\n-\t}\n-\n-      if (TARGET_SINGLE_STRINGOP)\n-\temit_insn (gen_cld ());\n-\n-      countreg2 = gen_reg_rtx (SImode);\n-      countreg = copy_to_mode_reg (SImode, operands[2]);\n-\n-      /* We don't use loops to align destination and to copy parts smaller\n-\t than 4 bytes, because gcc is able to optimize such code better (in\n-\t the case the destination or the count really is aligned, gcc is often\n-\t able to predict the branches) and also it is friendlier to the\n-\t hardware branch prediction.  \n-\n-\t Using loops is benefical for generic case, because we can\n-\t handle small counts using the loops.  Many CPUs (such as Athlon)\n-\t have large REP prefix setup costs.\n-\n-\t This is quite costy.  Maybe we can revisit this decision later or\n-\t add some customizability to this code.  */\n-\n-      if (count < 0\n-\t  && align < (TARGET_PENTIUMPRO && (count < 0 || count >= 260) ? 8 : 4))\n-\t{\n-\t  label = gen_label_rtx ();\n-\t  emit_cmp_and_jump_insns (countreg, GEN_INT (3),\n-\t\t\t\t   LEU, 0, SImode, 1, 0, label);\n-\t}\n-      if (align <= 1)\n-\t{\n-\t  rtx label = gen_label_rtx ();\n-\t  rtx tmpcount = gen_reg_rtx (SImode);\n-\t  emit_insn (gen_andsi3 (tmpcount, destreg, GEN_INT (1)));\n-\t  emit_cmp_and_jump_insns (tmpcount, GEN_INT (0), EQ, 0,\n-\t\t\t\t   SImode, 1, 0, label);\n-\t  emit_insn (gen_strmovqi (destreg, srcreg));\n-\t  emit_insn (gen_addsi3 (countreg, countreg, constm1_rtx));\n-\t  emit_label (label);\n-\t  LABEL_NUSES (label) = 1;\n-\t}\n-      if (align <= 2)\n-\t{\n-\t  rtx label = gen_label_rtx ();\n-\t  rtx tmpcount = gen_reg_rtx (SImode);\n-\t  emit_insn (gen_andsi3 (tmpcount, destreg, GEN_INT (2)));\n-\t  emit_cmp_and_jump_insns (tmpcount, GEN_INT (0), EQ, 0,\n-\t\t\t\t   SImode, 1, 0, label);\n-\t  emit_insn (gen_strmovhi (destreg, srcreg));\n-\t  emit_insn (gen_addsi3 (countreg, countreg, GEN_INT (-2)));\n-\t  emit_label (label);\n-\t  LABEL_NUSES (label) = 1;\n-\t}\n-      if (align <= 4 && TARGET_PENTIUMPRO && (count < 1 || count >= 260))\n-\t{\n-\t  rtx label = gen_label_rtx ();\n-\t  rtx tmpcount = gen_reg_rtx (SImode);\n-\t  emit_insn (gen_andsi3 (tmpcount, destreg, GEN_INT (4)));\n-\t  emit_cmp_and_jump_insns (tmpcount, GEN_INT (0), EQ, 0,\n-\t\t\t\t   SImode, 1, 0, label);\n-\t  emit_insn (gen_strmovsi (destreg, srcreg));\n-\t  emit_insn (gen_addsi3 (countreg, countreg, GEN_INT (-4)));\n-\t  emit_label (label);\n-\t  LABEL_NUSES (label) = 1;\n-\t}\n-\n-      if (!TARGET_SINGLE_STRINGOP)\n-\temit_insn (gen_cld());\n-      emit_insn (gen_lshrsi3 (countreg2, countreg, GEN_INT (2)));\n-      emit_insn (gen_rep_movsi (destreg, srcreg, countreg2,\n-\t\t\t\tdestreg, srcreg, countreg2));\n-\n-      if (label)\n-\t{\n-\t  emit_label (label);\n-\t  LABEL_NUSES (label) = 1;\n-\t}\n-      if (align > 2 && count > 0 && (count & 2))\n-\temit_insn (gen_strmovhi (destreg, srcreg));\n-      if (align <= 2 || count < 0)\n-\t{\n-\t  rtx label = gen_label_rtx ();\n-\t  rtx tmpcount = gen_reg_rtx (SImode);\n-\t  emit_insn (gen_andsi3 (tmpcount, countreg, GEN_INT (2)));\n-\t  emit_cmp_and_jump_insns (tmpcount, GEN_INT (0), EQ, 0,\n-\t\t\t\t   SImode, 1, 0, label);\n-\t  emit_insn (gen_strmovhi (destreg, srcreg));\n-\t  emit_label (label);\n-\t  LABEL_NUSES (label) = 1;\n-\t}\n-      if (align > 1 && count > 0 && (count & 1))\n-\temit_insn (gen_strmovsi (destreg, srcreg));\n-      if (align <= 1 || count < 0)\n-\t{\n-\t  rtx label = gen_label_rtx ();\n-\t  rtx tmpcount = gen_reg_rtx (SImode);\n-\t  emit_insn (gen_andsi3 (tmpcount, countreg, GEN_INT (1)));\n-\t  emit_cmp_and_jump_insns (tmpcount, GEN_INT (0), EQ, 0,\n-\t\t\t\t   SImode, 1, 0, label);\n-\t  emit_insn (gen_strmovqi (destreg, srcreg));\n-\t  emit_label (label);\n-\t  LABEL_NUSES (label) = 1;\n-\t}\n+      emit_insn (gen_strmovdi_rex_1 (operands[0], operands[1], operands[0],\n+\t\t\t\t     operands[1]));\n+      DONE;\n     }\n-\n-  insns = get_insns ();\n-  end_sequence ();\n-\n-  ix86_set_move_mem_attrs (insns, operands[0], operands[1], destreg, srcreg);\n-  emit_insns (insns);\n-  DONE;\n+  else \n+    operands[2] = gen_reg_rtx (DImode);\n }\")\n \n-;; Most CPUs don't like single string operations\n-;; Handle this case here to simplify previous expander.\n \n (define_expand \"strmovsi\"\n   [(set (match_dup 2)\n@@ -13539,6 +13398,11 @@\n   \"\"\n   \"\n {\n+  if (TARGET_64BIT)\n+    {\n+      emit_insn (gen_strmovsi_rex64 (operands[0], operands[1]));\n+      DONE;\n+    }\n   if (TARGET_SINGLE_STRINGOP || optimize_size)\n     {\n       emit_insn (gen_strmovsi_1 (operands[0], operands[1], operands[0],\n@@ -13549,6 +13413,28 @@\n     operands[2] = gen_reg_rtx (SImode);\n }\")\n \n+(define_expand \"strmovsi_rex64\"\n+  [(set (match_dup 2)\n+  \t(mem:SI (match_operand:DI 1 \"register_operand\" \"\")))\n+   (set (mem:SI (match_operand:DI 0 \"register_operand\" \"\"))\n+        (match_dup 2))\n+   (parallel [(set (match_dup 0) (plus:DI (match_dup 0) (const_int 4)))\n+\t      (clobber (reg:CC 17))])\n+   (parallel [(set (match_dup 1) (plus:DI (match_dup 1) (const_int 4)))\n+\t      (clobber (reg:CC 17))])]\n+  \"TARGET_64BIT\"\n+  \"\n+{\n+  if (TARGET_SINGLE_STRINGOP || optimize_size)\n+    {\n+      emit_insn (gen_strmovsi_rex_1 (operands[0], operands[1], operands[0],\n+\t\t\t\t     operands[1]));\n+      DONE;\n+    }\n+  else \n+    operands[2] = gen_reg_rtx (SImode);\n+}\")\n+\n (define_expand \"strmovhi\"\n   [(set (match_dup 2)\n   \t(mem:HI (match_operand:SI 1 \"register_operand\" \"\")))\n@@ -13561,6 +13447,11 @@\n   \"\"\n   \"\n {\n+  if (TARGET_64BIT)\n+    {\n+      emit_insn (gen_strmovhi_rex64 (operands[0], operands[1]));\n+      DONE;\n+    }\n   if (TARGET_SINGLE_STRINGOP || optimize_size)\n     {\n       emit_insn (gen_strmovhi_1 (operands[0], operands[1], operands[0],\n@@ -13571,6 +13462,28 @@\n     operands[2] = gen_reg_rtx (HImode);\n }\")\n \n+(define_expand \"strmovhi_rex64\"\n+  [(set (match_dup 2)\n+  \t(mem:HI (match_operand:DI 1 \"register_operand\" \"\")))\n+   (set (mem:HI (match_operand:DI 0 \"register_operand\" \"\"))\n+        (match_dup 2))\n+   (parallel [(set (match_dup 0) (plus:DI (match_dup 0) (const_int 2)))\n+\t      (clobber (reg:CC 17))])\n+   (parallel [(set (match_dup 1) (plus:DI (match_dup 1) (const_int 2)))\n+\t      (clobber (reg:CC 17))])]\n+  \"TARGET_64BIT\"\n+  \"\n+{\n+  if (TARGET_SINGLE_STRINGOP || optimize_size)\n+    {\n+      emit_insn (gen_strmovhi_rex_1 (operands[0], operands[1], operands[0],\n+\t\t\t\t     operands[1]));\n+      DONE;\n+    }\n+  else \n+    operands[2] = gen_reg_rtx (HImode);\n+}\")\n+\n (define_expand \"strmovqi\"\n   [(set (match_dup 2)\n   \t(mem:QI (match_operand:SI 1 \"register_operand\" \"\")))\n@@ -13583,6 +13496,11 @@\n   \"\"\n   \"\n {\n+  if (TARGET_64BIT)\n+    {\n+      emit_insn (gen_strmovqi_rex64 (operands[0], operands[1]));\n+      DONE;\n+    }\n   if (TARGET_SINGLE_STRINGOP || optimize_size)\n     {\n       emit_insn (gen_strmovqi_1 (operands[0], operands[1], operands[0],\n@@ -13593,6 +13511,44 @@\n     operands[2] = gen_reg_rtx (QImode);\n }\")\n \n+(define_expand \"strmovqi_rex64\"\n+  [(set (match_dup 2)\n+  \t(mem:QI (match_operand:DI 1 \"register_operand\" \"\")))\n+   (set (mem:QI (match_operand:DI 0 \"register_operand\" \"\"))\n+        (match_dup 2))\n+   (parallel [(set (match_dup 0) (plus:DI (match_dup 0) (const_int 1)))\n+\t      (clobber (reg:CC 17))])\n+   (parallel [(set (match_dup 1) (plus:DI (match_dup 1) (const_int 1)))\n+\t      (clobber (reg:CC 17))])]\n+  \"!TARGET_64BIT\"\n+  \"\n+{\n+  if (TARGET_SINGLE_STRINGOP || optimize_size)\n+    {\n+      emit_insn (gen_strmovqi_rex_1 (operands[0], operands[1], operands[0],\n+\t\t\t\t     operands[1]));\n+      DONE;\n+    }\n+  else \n+    operands[2] = gen_reg_rtx (QImode);\n+}\")\n+\n+(define_insn \"strmovdi_rex_1\"\n+  [(set (mem:DI (match_operand:DI 2 \"register_operand\" \"0\"))\n+\t(mem:DI (match_operand:DI 3 \"register_operand\" \"1\")))\n+   (set (match_operand:DI 0 \"register_operand\" \"=D\")\n+\t(plus:DI (match_dup 2)\n+\t\t (const_int 8)))\n+   (set (match_operand:DI 1 \"register_operand\" \"=S\")\n+\t(plus:DI (match_dup 3)\n+\t\t (const_int 8)))\n+   (use (reg:SI 19))]\n+  \"TARGET_64BIT && (TARGET_SINGLE_STRINGOP || optimize_size)\"\n+  \"movsq\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"mode\" \"DI\")\n+   (set_attr \"memory\" \"both\")])\n+\n (define_insn \"strmovsi_1\"\n   [(set (mem:SI (match_operand:SI 2 \"register_operand\" \"0\"))\n \t(mem:SI (match_operand:SI 3 \"register_operand\" \"1\")))\n@@ -13603,8 +13559,24 @@\n \t(plus:SI (match_dup 3)\n \t\t (const_int 4)))\n    (use (reg:SI 19))]\n-  \"TARGET_SINGLE_STRINGOP || optimize_size\"\n-  \"movsl\"\n+  \"!TARGET_64BIT && (TARGET_SINGLE_STRINGOP || optimize_size)\"\n+  \"movsl|movsd\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"mode\" \"SI\")\n+   (set_attr \"memory\" \"both\")])\n+\n+(define_insn \"strmovsi_rex_1\"\n+  [(set (mem:SI (match_operand:DI 2 \"register_operand\" \"0\"))\n+\t(mem:SI (match_operand:DI 3 \"register_operand\" \"1\")))\n+   (set (match_operand:DI 0 \"register_operand\" \"=D\")\n+\t(plus:DI (match_dup 2)\n+\t\t (const_int 4)))\n+   (set (match_operand:DI 1 \"register_operand\" \"=S\")\n+\t(plus:DI (match_dup 3)\n+\t\t (const_int 4)))\n+   (use (reg:SI 19))]\n+  \"TARGET_64BIT && (TARGET_SINGLE_STRINGOP || optimize_size)\"\n+  \"movsl|movsd\"\n   [(set_attr \"type\" \"str\")\n    (set_attr \"mode\" \"SI\")\n    (set_attr \"memory\" \"both\")])\n@@ -13619,7 +13591,23 @@\n \t(plus:SI (match_dup 3)\n \t\t (const_int 2)))\n    (use (reg:SI 19))]\n-  \"TARGET_SINGLE_STRINGOP || optimize_size\"\n+  \"!TARGET_64BIT && (TARGET_SINGLE_STRINGOP || optimize_size)\"\n+  \"movsw\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"memory\" \"both\")\n+   (set_attr \"mode\" \"HI\")])\n+\n+(define_insn \"strmovhi_rex_1\"\n+  [(set (mem:HI (match_operand:DI 2 \"register_operand\" \"0\"))\n+\t(mem:HI (match_operand:DI 3 \"register_operand\" \"1\")))\n+   (set (match_operand:DI 0 \"register_operand\" \"=D\")\n+\t(plus:DI (match_dup 2)\n+\t\t (const_int 2)))\n+   (set (match_operand:DI 1 \"register_operand\" \"=S\")\n+\t(plus:DI (match_dup 3)\n+\t\t (const_int 2)))\n+   (use (reg:SI 19))]\n+  \"TARGET_64BIT && (TARGET_SINGLE_STRINGOP || optimize_size)\"\n   \"movsw\"\n   [(set_attr \"type\" \"str\")\n    (set_attr \"memory\" \"both\")\n@@ -13635,12 +13623,48 @@\n \t(plus:SI (match_dup 3)\n \t\t (const_int 1)))\n    (use (reg:SI 19))]\n-  \"TARGET_SINGLE_STRINGOP || optimize_size\"\n+  \"!TARGET_64BIT && (TARGET_SINGLE_STRINGOP || optimize_size)\"\n   \"movsb\"\n   [(set_attr \"type\" \"str\")\n    (set_attr \"memory\" \"both\")\n    (set_attr \"mode\" \"QI\")])\n \n+(define_insn \"strmovqi_rex_1\"\n+  [(set (mem:QI (match_operand:DI 2 \"register_operand\" \"0\"))\n+\t(mem:QI (match_operand:DI 3 \"register_operand\" \"1\")))\n+   (set (match_operand:DI 0 \"register_operand\" \"=D\")\n+\t(plus:DI (match_dup 2)\n+\t\t (const_int 1)))\n+   (set (match_operand:DI 1 \"register_operand\" \"=S\")\n+\t(plus:DI (match_dup 3)\n+\t\t (const_int 1)))\n+   (use (reg:SI 19))]\n+  \"TARGET_64BIT && (TARGET_SINGLE_STRINGOP || optimize_size)\"\n+  \"movsb\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"memory\" \"both\")\n+   (set_attr \"mode\" \"QI\")])\n+\n+(define_insn \"rep_movdi_rex64\"\n+  [(set (match_operand:DI 2 \"register_operand\" \"=c\") (const_int 0))\n+   (set (match_operand:DI 0 \"register_operand\" \"=D\") \n+        (plus:DI (ashift:DI (match_operand:DI 5 \"register_operand\" \"2\")\n+\t\t\t    (const_int 3))\n+\t\t (match_operand:DI 3 \"register_operand\" \"0\")))\n+   (set (match_operand:DI 1 \"register_operand\" \"=S\") \n+        (plus:DI (ashift:DI (match_dup 5) (const_int 3))\n+\t\t (match_operand:DI 4 \"register_operand\" \"1\")))\n+   (set (mem:BLK (match_dup 3))\n+\t(mem:BLK (match_dup 4)))\n+   (use (match_dup 5))\n+   (use (reg:SI 19))]\n+  \"TARGET_64BIT\"\n+  \"rep\\;movsq|rep movsq\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"prefix_rep\" \"1\")\n+   (set_attr \"memory\" \"both\")\n+   (set_attr \"mode\" \"DI\")])\n+\n (define_insn \"rep_movsi\"\n   [(set (match_operand:SI 2 \"register_operand\" \"=c\") (const_int 0))\n    (set (match_operand:SI 0 \"register_operand\" \"=D\") \n@@ -13654,7 +13678,27 @@\n \t(mem:BLK (match_dup 4)))\n    (use (match_dup 5))\n    (use (reg:SI 19))]\n-  \"\"\n+  \"!TARGET_64BIT\"\n+  \"rep\\;movsl|rep movsd\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"prefix_rep\" \"1\")\n+   (set_attr \"memory\" \"both\")\n+   (set_attr \"mode\" \"SI\")])\n+\n+(define_insn \"rep_movsi_rex64\"\n+  [(set (match_operand:DI 2 \"register_operand\" \"=c\") (const_int 0))\n+   (set (match_operand:DI 0 \"register_operand\" \"=D\") \n+        (plus:DI (ashift:DI (match_operand:DI 5 \"register_operand\" \"2\")\n+\t\t\t    (const_int 2))\n+\t\t (match_operand:DI 3 \"register_operand\" \"0\")))\n+   (set (match_operand:DI 1 \"register_operand\" \"=S\") \n+        (plus:DI (ashift:DI (match_dup 5) (const_int 2))\n+\t\t (match_operand:DI 4 \"register_operand\" \"1\")))\n+   (set (mem:BLK (match_dup 3))\n+\t(mem:BLK (match_dup 4)))\n+   (use (match_dup 5))\n+   (use (reg:SI 19))]\n+  \"TARGET_64BIT\"\n   \"rep\\;movsl|rep movsd\"\n   [(set_attr \"type\" \"str\")\n    (set_attr \"prefix_rep\" \"1\")\n@@ -13672,7 +13716,25 @@\n \t(mem:BLK (match_dup 4)))\n    (use (match_dup 5))\n    (use (reg:SI 19))]\n-  \"\"\n+  \"!TARGET_64BIT\"\n+  \"rep\\;movsb|rep movsb\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"prefix_rep\" \"1\")\n+   (set_attr \"memory\" \"both\")\n+   (set_attr \"mode\" \"SI\")])\n+\n+(define_insn \"rep_movqi_rex64\"\n+  [(set (match_operand:DI 2 \"register_operand\" \"=c\") (const_int 0))\n+   (set (match_operand:DI 0 \"register_operand\" \"=D\") \n+        (plus:DI (match_operand:DI 3 \"register_operand\" \"0\")\n+\t\t (match_operand:DI 5 \"register_operand\" \"2\")))\n+   (set (match_operand:DI 1 \"register_operand\" \"=S\") \n+        (plus:DI (match_operand:DI 4 \"register_operand\" \"1\") (match_dup 5)))\n+   (set (mem:BLK (match_dup 3))\n+\t(mem:BLK (match_dup 4)))\n+   (use (match_dup 5))\n+   (use (reg:SI 19))]\n+  \"TARGET_64BIT\"\n   \"rep\\;movsb|rep movsb\"\n   [(set_attr \"type\" \"str\")\n    (set_attr \"prefix_rep\" \"1\")\n@@ -13682,187 +13744,47 @@\n (define_expand \"clrstrsi\"\n    [(use (match_operand:BLK 0 \"memory_operand\" \"\"))\n     (use (match_operand:SI 1 \"nonmemory_operand\" \"\"))\n-    (use (match_operand:SI 2 \"const_int_operand\" \"\"))]\n+    (use (match_operand 2 \"const_int_operand\" \"\"))]\n   \"\"\n   \"\n {\n-  /* See comments in movstr expanders.  The code is mostly identical.  */\n-\n-  rtx destreg, zeroreg, countreg;\n-  int align = 0;\n-  int count = -1;\n-  rtx insns;\n-\n-  start_sequence ();\n-\n-  if (GET_CODE (operands[2]) == CONST_INT)\n-    align = INTVAL (operands[2]);\n-\n-  /* This simple hack avoids all inlining code and simplifies code bellow.  */\n-  if (!TARGET_ALIGN_STRINGOPS)\n-    align = 32;\n-\n-  if (GET_CODE (operands[1]) == CONST_INT)\n-    count = INTVAL (operands[1]);\n-\n-  destreg = copy_to_mode_reg (Pmode, XEXP (operands[0], 0));\n+ if (ix86_expand_clrstr (operands[0], operands[1], operands[2]))\n+   DONE;\n+ else\n+   FAIL;\n+}\")\n \n-  emit_insn (gen_cld ());\n+(define_expand \"clrstrdi\"\n+   [(use (match_operand:BLK 0 \"memory_operand\" \"\"))\n+    (use (match_operand:DI 1 \"nonmemory_operand\" \"\"))\n+    (use (match_operand 2 \"const_int_operand\" \"\"))]\n+  \"TARGET_64BIT\"\n+  \"\n+{\n+ if (ix86_expand_clrstr (operands[0], operands[1], operands[2]))\n+   DONE;\n+ else\n+   FAIL;\n+}\")\n \n-  /* When optimizing for size emit simple rep ; movsb instruction for\n-     counts not divisible by 4.  */\n+;; Most CPUs don't like single string operations\n+;; Handle this case here to simplify previous expander.\n \n-  if ((!optimize || optimize_size) \n-      && (count < 0 || (count & 0x03)))\n-    {\n-      countreg = copy_to_mode_reg (SImode, operands[1]);\n-      zeroreg = copy_to_mode_reg (QImode, const0_rtx);\n-      emit_insn (gen_rep_stosqi (destreg, countreg, zeroreg,\n-\t\t\t\t destreg, countreg));\n-    }\n-  else if (count >= 0 \n-\t   && (align >= 8\n-\t       || (!TARGET_PENTIUMPRO && align >= 4)\n-\t       || optimize_size || count < 64))\n-    {\n-      zeroreg = copy_to_mode_reg (SImode, const0_rtx);\n-      if (INTVAL (operands[1]) & ~0x03)\n-\t{\n-\t  countreg = copy_to_mode_reg (SImode,\n-\t  \t\t\t       GEN_INT ((INTVAL (operands[1]) >> 2)\n-\t\t\t\t\t\t& 0x3fffffff));\n-\t  emit_insn (gen_rep_stossi (destreg, countreg, zeroreg,\n-\t\t\t\t     destreg, countreg));\n-\t}\n-      if (INTVAL (operands[1]) & 0x02)\n-\temit_insn (gen_strsethi (destreg,\n-\t\t\t\t gen_rtx_SUBREG (HImode, zeroreg, 0)));\n-      if (INTVAL (operands[1]) & 0x01)\n-\temit_insn (gen_strsetqi (destreg,\n-\t\t\t\t gen_rtx_SUBREG (QImode, zeroreg, 0)));\n-    }\n-  else\n+(define_expand \"strsetdi_rex64\"\n+  [(set (mem:DI (match_operand:DI 0 \"register_operand\" \"\"))\n+\t(match_operand:DI 1 \"register_operand\" \"\"))\n+   (parallel [(set (match_dup 0) (plus:DI (match_dup 0) (const_int 8)))\n+\t      (clobber (reg:CC 17))])]\n+  \"TARGET_64BIT\"\n+  \"\n+{\n+  if (TARGET_SINGLE_STRINGOP || optimize_size)\n     {\n-      rtx countreg2;\n-      rtx label = NULL;\n-\n-      /* In case we don't know anything about the alignment, default to\n-         library version, since it is usually equally fast and result in\n-\t shorter code.  */\n-      if (!TARGET_INLINE_ALL_STRINGOPS && align < 4)\n-\t{\n-\t  end_sequence ();\n-\t  FAIL;\n-\t}\n-\n-      if (TARGET_SINGLE_STRINGOP)\n-\temit_insn (gen_cld ());\n-\n-      countreg2 = gen_reg_rtx (SImode);\n-      countreg = copy_to_mode_reg (SImode, operands[1]);\n-      zeroreg = copy_to_mode_reg (SImode, const0_rtx);\n-\n-      if (count < 0\n-\t  && align < (TARGET_PENTIUMPRO && (count < 0 || count >= 260) ? 8 : 4))\n-\t{\n-\t  label = gen_label_rtx ();\n-\t  emit_cmp_and_jump_insns (countreg, GEN_INT (3),\n-\t\t\t\t   LEU, 0, SImode, 1, 0, label);\n-\t}\n-      if (align <= 1)\n-\t{\n-\t  rtx label = gen_label_rtx ();\n-\t  rtx tmpcount = gen_reg_rtx (SImode);\n-\t  emit_insn (gen_andsi3 (tmpcount, destreg, GEN_INT (1)));\n-\t  emit_cmp_and_jump_insns (tmpcount, GEN_INT (0), EQ, 0,\n-\t\t\t\t   SImode, 1, 0, label);\n-\t  emit_insn (gen_strsetqi (destreg,\n-\t\t\t\t   gen_rtx_SUBREG (QImode, zeroreg, 0)));\n-\t  emit_insn (gen_addsi3 (countreg, countreg, constm1_rtx));\n-\t  emit_label (label);\n-\t  LABEL_NUSES (label) = 1;\n-\t}\n-      if (align <= 2)\n-\t{\n-\t  rtx label = gen_label_rtx ();\n-\t  rtx tmpcount = gen_reg_rtx (SImode);\n-\t  emit_insn (gen_andsi3 (tmpcount, destreg, GEN_INT (2)));\n-\t  emit_cmp_and_jump_insns (tmpcount, GEN_INT (0), EQ, 0,\n-\t\t\t\t   SImode, 1, 0, label);\n-\t  emit_insn (gen_strsethi (destreg,\n-\t\t\t\t   gen_rtx_SUBREG (HImode, zeroreg, 0)));\n-\t  emit_insn (gen_addsi3 (countreg, countreg, GEN_INT (-2)));\n-\t  emit_label (label);\n-\t  LABEL_NUSES (label) = 1;\n-\t}\n-      if (align <= 4 && TARGET_PENTIUMPRO && (count < 1 || count >= 260))\n-\t{\n-\t  rtx label = gen_label_rtx ();\n-\t  rtx tmpcount = gen_reg_rtx (SImode);\n-\t  emit_insn (gen_andsi3 (tmpcount, destreg, GEN_INT (4)));\n-\t  emit_cmp_and_jump_insns (tmpcount, GEN_INT (0), EQ, 0,\n-\t\t\t\t   SImode, 1, 0, label);\n-\t  emit_insn (gen_strsetsi (destreg, zeroreg));\n-\t  emit_insn (gen_addsi3 (countreg, countreg, GEN_INT (-4)));\n-\t  emit_label (label);\n-\t  LABEL_NUSES (label) = 1;\n-\t}\n-\n-      if (!TARGET_SINGLE_STRINGOP)\n-\temit_insn (gen_cld());\n-      emit_insn (gen_lshrsi3 (countreg2, countreg, GEN_INT (2)));\n-      emit_insn (gen_rep_stossi (destreg, countreg2, zeroreg,\n-\t\t\t\t destreg, countreg2));\n-\n-      if (label)\n-\t{\n-\t  emit_label (label);\n-\t  LABEL_NUSES (label) = 1;\n-\t}\n-      if (align > 2 && count > 0 && (count & 2))\n-\temit_insn (gen_strsethi (destreg,\n-\t\t\t\t gen_rtx_SUBREG (HImode, zeroreg, 0)));\n-      if (align <= 2 || count < 0)\n-\t{\n-\t  rtx label = gen_label_rtx ();\n-\t  rtx tmpcount = gen_reg_rtx (SImode);\n-\t  emit_insn (gen_andsi3 (tmpcount, countreg, GEN_INT (2)));\n-\t  emit_cmp_and_jump_insns (tmpcount, GEN_INT (0), EQ, 0,\n-\t\t\t\t   SImode, 1, 0, label);\n-\t  emit_insn (gen_strsethi (destreg,\n-\t\t\t\t   gen_rtx_SUBREG (HImode, zeroreg, 0)));\n-\t  emit_label (label);\n-\t  LABEL_NUSES (label) = 1;\n-\t}\n-      if (align > 1 && count > 0 && (count & 1))\n-\temit_insn (gen_strsetqi (destreg,\n-\t\t\t\t gen_rtx_SUBREG (QImode, zeroreg, 0)));\n-      if (align <= 1 || count < 0)\n-\t{\n-\t  rtx label = gen_label_rtx ();\n-\t  rtx tmpcount = gen_reg_rtx (SImode);\n-\t  emit_insn (gen_andsi3 (tmpcount, countreg, GEN_INT (1)));\n-\t  emit_cmp_and_jump_insns (tmpcount, GEN_INT (0), EQ, 0,\n-\t\t\t\t   SImode, 1, 0, label);\n-\t  emit_insn (gen_strsetqi (destreg,\n-\t\t\t\t   gen_rtx_SUBREG (QImode, zeroreg, 0)));\n-\t  emit_label (label);\n-\t  LABEL_NUSES (label) = 1;\n-\t}\n+      emit_insn (gen_strsetdi_rex_1 (operands[0], operands[0], operands[1]));\n+      DONE;\n     }\n-\n-  insns = get_insns ();\n-  end_sequence ();\n-\n-  ix86_set_move_mem_attrs (insns, operands[0], operands[0], destreg, destreg);\n-  emit_insns (insns);\n-\n-  DONE;\n }\")\n \n-;; Most CPUs don't like single string operations\n-;; Handle this case here to simplify previous expander.\n-\n (define_expand \"strsetsi\"\n   [(set (mem:SI (match_operand:SI 0 \"register_operand\" \"\"))\n \t(match_operand:SI 1 \"register_operand\" \"\"))\n@@ -13871,13 +13793,33 @@\n   \"\"\n   \"\n {\n-  if (TARGET_SINGLE_STRINGOP || optimize_size)\n+  if (TARGET_64BIT)\n+    {\n+      emit_insn (gen_strsetsi_rex64 (operands[0], operands[1]));\n+      DONE;\n+    }\n+  else if (TARGET_SINGLE_STRINGOP || optimize_size)\n     {\n       emit_insn (gen_strsetsi_1 (operands[0], operands[0], operands[1]));\n       DONE;\n     }\n }\")\n \n+(define_expand \"strsetsi_rex64\"\n+  [(set (mem:SI (match_operand:DI 0 \"register_operand\" \"\"))\n+\t(match_operand:SI 1 \"register_operand\" \"\"))\n+   (parallel [(set (match_dup 0) (plus:DI (match_dup 0) (const_int 4)))\n+\t      (clobber (reg:CC 17))])]\n+  \"TARGET_64BIT\"\n+  \"\n+{\n+  if (TARGET_SINGLE_STRINGOP || optimize_size)\n+    {\n+      emit_insn (gen_strsetsi_rex_1 (operands[0], operands[0], operands[1]));\n+      DONE;\n+    }\n+}\")\n+\n (define_expand \"strsethi\"\n   [(set (mem:HI (match_operand:SI 0 \"register_operand\" \"\"))\n \t(match_operand:HI 1 \"register_operand\" \"\"))\n@@ -13886,13 +13828,33 @@\n   \"\"\n   \"\n {\n-  if (TARGET_SINGLE_STRINGOP || optimize_size)\n+  if (TARGET_64BIT)\n+    {\n+      emit_insn (gen_strsethi_rex64 (operands[0], operands[1]));\n+      DONE;\n+    }\n+  else if (TARGET_SINGLE_STRINGOP || optimize_size)\n     {\n       emit_insn (gen_strsethi_1 (operands[0], operands[0], operands[1]));\n       DONE;\n     }\n }\")\n \n+(define_expand \"strsethi_rex64\"\n+  [(set (mem:HI (match_operand:DI 0 \"register_operand\" \"\"))\n+\t(match_operand:HI 1 \"register_operand\" \"\"))\n+   (parallel [(set (match_dup 0) (plus:DI (match_dup 0) (const_int 2)))\n+\t      (clobber (reg:CC 17))])]\n+  \"TARGET_64BIT\"\n+  \"\n+{\n+  if (TARGET_SINGLE_STRINGOP || optimize_size)\n+    {\n+      emit_insn (gen_strsethi_rex_1 (operands[0], operands[0], operands[1]));\n+      DONE;\n+    }\n+}\")\n+\n (define_expand \"strsetqi\"\n   [(set (mem:QI (match_operand:SI 0 \"register_operand\" \"\"))\n \t(match_operand:QI 1 \"register_operand\" \"\"))\n@@ -13901,22 +13863,68 @@\n   \"\"\n   \"\n {\n-  if (TARGET_SINGLE_STRINGOP || optimize_size)\n+  if (TARGET_64BIT)\n+    {\n+      emit_insn (gen_strsetqi_rex64 (operands[0], operands[1]));\n+      DONE;\n+    }\n+  else if (TARGET_SINGLE_STRINGOP || optimize_size)\n     {\n       emit_insn (gen_strsetqi_1 (operands[0], operands[0], operands[1]));\n       DONE;\n     }\n }\")\n \n+(define_expand \"strsetqi_rex64\"\n+  [(set (mem:QI (match_operand:DI 0 \"register_operand\" \"\"))\n+\t(match_operand:QI 1 \"register_operand\" \"\"))\n+   (parallel [(set (match_dup 0) (plus:DI (match_dup 0) (const_int 1)))\n+\t      (clobber (reg:CC 17))])]\n+  \"TARGET_64BIT\"\n+  \"\n+{\n+  if (TARGET_SINGLE_STRINGOP || optimize_size)\n+    {\n+      emit_insn (gen_strsetqi_rex_1 (operands[0], operands[0], operands[1]));\n+      DONE;\n+    }\n+}\")\n+\n+(define_insn \"strsetdi_rex_1\"\n+  [(set (mem:SI (match_operand:DI 1 \"register_operand\" \"0\"))\n+\t(match_operand:SI 2 \"register_operand\" \"a\"))\n+   (set (match_operand:DI 0 \"register_operand\" \"=D\")\n+\t(plus:DI (match_dup 1)\n+\t\t (const_int 8)))\n+   (use (reg:SI 19))]\n+  \"TARGET_64BIT && (TARGET_SINGLE_STRINGOP || optimize_size)\"\n+  \"stosq\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"mode\" \"DI\")])\n+\n (define_insn \"strsetsi_1\"\n   [(set (mem:SI (match_operand:SI 1 \"register_operand\" \"0\"))\n \t(match_operand:SI 2 \"register_operand\" \"a\"))\n    (set (match_operand:SI 0 \"register_operand\" \"=D\")\n \t(plus:SI (match_dup 1)\n \t\t (const_int 4)))\n    (use (reg:SI 19))]\n-  \"TARGET_SINGLE_STRINGOP || optimize_size\"\n-  \"stosl\"\n+  \"!TARGET_64BIT && (TARGET_SINGLE_STRINGOP || optimize_size)\"\n+  \"stosl|stosd\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"mode\" \"SI\")])\n+\n+(define_insn \"strsetsi_rex_1\"\n+  [(set (mem:SI (match_operand:DI 1 \"register_operand\" \"0\"))\n+\t(match_operand:SI 2 \"register_operand\" \"a\"))\n+   (set (match_operand:DI 0 \"register_operand\" \"=D\")\n+\t(plus:DI (match_dup 1)\n+\t\t (const_int 4)))\n+   (use (reg:SI 19))]\n+  \"TARGET_64BIT && (TARGET_SINGLE_STRINGOP || optimize_size)\"\n+  \"stosl|stosd\"\n   [(set_attr \"type\" \"str\")\n    (set_attr \"memory\" \"store\")\n    (set_attr \"mode\" \"SI\")])\n@@ -13928,7 +13936,20 @@\n \t(plus:SI (match_dup 1)\n \t\t (const_int 2)))\n    (use (reg:SI 19))]\n-  \"TARGET_SINGLE_STRINGOP || optimize_size\"\n+  \"!TARGET_64BIT && (TARGET_SINGLE_STRINGOP || optimize_size)\"\n+  \"stosw\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"mode\" \"HI\")])\n+\n+(define_insn \"strsethi_rex_1\"\n+  [(set (mem:HI (match_operand:DI 1 \"register_operand\" \"0\"))\n+\t(match_operand:HI 2 \"register_operand\" \"a\"))\n+   (set (match_operand:DI 0 \"register_operand\" \"=D\")\n+\t(plus:DI (match_dup 1)\n+\t\t (const_int 2)))\n+   (use (reg:SI 19))]\n+  \"TARGET_64BIT && (TARGET_SINGLE_STRINGOP || optimize_size)\"\n   \"stosw\"\n   [(set_attr \"type\" \"str\")\n    (set_attr \"memory\" \"store\")\n@@ -13941,12 +13962,43 @@\n \t(plus:SI (match_dup 1)\n \t\t (const_int 1)))\n    (use (reg:SI 19))]\n-  \"TARGET_SINGLE_STRINGOP || optimize_size\"\n+  \"!TARGET_64BIT && (TARGET_SINGLE_STRINGOP || optimize_size)\"\n   \"stosb\"\n   [(set_attr \"type\" \"str\")\n    (set_attr \"memory\" \"store\")\n    (set_attr \"mode\" \"QI\")])\n \n+(define_insn \"strsetqi_rex_1\"\n+  [(set (mem:QI (match_operand:DI 1 \"register_operand\" \"0\"))\n+\t(match_operand:QI 2 \"register_operand\" \"a\"))\n+   (set (match_operand:DI 0 \"register_operand\" \"=D\")\n+\t(plus:DI (match_dup 1)\n+\t\t (const_int 1)))\n+   (use (reg:SI 19))]\n+  \"TARGET_64BIT && (TARGET_SINGLE_STRINGOP || optimize_size)\"\n+  \"stosb\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"mode\" \"QI\")])\n+\n+(define_insn \"rep_stosdi_rex64\"\n+  [(set (match_operand:DI 1 \"register_operand\" \"=c\") (const_int 0))\n+   (set (match_operand:DI 0 \"register_operand\" \"=D\") \n+        (plus:DI (ashift:DI (match_operand:DI 4 \"register_operand\" \"1\")\n+\t\t\t    (const_int 3))\n+\t\t (match_operand:DI 3 \"register_operand\" \"0\")))\n+   (set (mem:BLK (match_dup 3))\n+\t(const_int 0))\n+   (use (match_operand:DI 2 \"register_operand\" \"a\"))\n+   (use (match_dup 4))\n+   (use (reg:SI 19))]\n+  \"TARGET_64BIT\"\n+  \"rep\\;stosq|rep stosq\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"prefix_rep\" \"1\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"mode\" \"DI\")])\n+\n (define_insn \"rep_stossi\"\n   [(set (match_operand:SI 1 \"register_operand\" \"=c\") (const_int 0))\n    (set (match_operand:SI 0 \"register_operand\" \"=D\") \n@@ -13958,7 +14010,25 @@\n    (use (match_operand:SI 2 \"register_operand\" \"a\"))\n    (use (match_dup 4))\n    (use (reg:SI 19))]\n-  \"\"\n+  \"!TARGET_64BIT\"\n+  \"rep\\;stosl|rep stosd\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"prefix_rep\" \"1\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"mode\" \"SI\")])\n+\n+(define_insn \"rep_stossi_rex64\"\n+  [(set (match_operand:DI 1 \"register_operand\" \"=c\") (const_int 0))\n+   (set (match_operand:DI 0 \"register_operand\" \"=D\") \n+        (plus:DI (ashift:DI (match_operand:DI 4 \"register_operand\" \"1\")\n+\t\t\t    (const_int 2))\n+\t\t (match_operand:DI 3 \"register_operand\" \"0\")))\n+   (set (mem:BLK (match_dup 3))\n+\t(const_int 0))\n+   (use (match_operand:SI 2 \"register_operand\" \"a\"))\n+   (use (match_dup 4))\n+   (use (reg:SI 19))]\n+  \"TARGET_64BIT\"\n   \"rep\\;stosl|rep stosd\"\n   [(set_attr \"type\" \"str\")\n    (set_attr \"prefix_rep\" \"1\")\n@@ -13975,7 +14045,24 @@\n    (use (match_operand:QI 2 \"register_operand\" \"a\"))\n    (use (match_dup 4))\n    (use (reg:SI 19))]\n-  \"\"\n+  \"!TARGET_64BIT\"\n+  \"rep\\;stosb|rep stosb\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"prefix_rep\" \"1\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"mode\" \"QI\")])\n+\n+(define_insn \"rep_stosqi_rex64\"\n+  [(set (match_operand:DI 1 \"register_operand\" \"=c\") (const_int 0))\n+   (set (match_operand:DI 0 \"register_operand\" \"=D\") \n+        (plus:DI (match_operand:DI 3 \"register_operand\" \"0\")\n+\t\t (match_operand:DI 4 \"register_operand\" \"1\")))\n+   (set (mem:BLK (match_dup 3))\n+\t(const_int 0))\n+   (use (match_operand:QI 2 \"register_operand\" \"a\"))\n+   (use (match_dup 4))\n+   (use (reg:DI 19))]\n+  \"TARGET_64BIT\"\n   \"rep\\;stosb|rep stosb\"\n   [(set_attr \"type\" \"str\")\n    (set_attr \"prefix_rep\" \"1\")\n@@ -13986,8 +14073,8 @@\n   [(set (match_operand:SI 0 \"register_operand\" \"\")\n \t(compare:SI (match_operand:BLK 1 \"general_operand\" \"\")\n \t\t    (match_operand:BLK 2 \"general_operand\" \"\")))\n-   (use (match_operand:SI 3 \"general_operand\" \"\"))\n-   (use (match_operand:SI 4 \"immediate_operand\" \"\"))]\n+   (use (match_operand 3 \"general_operand\" \"\"))\n+   (use (match_operand 4 \"immediate_operand\" \"\"))]\n   \"\"\n   \"\n {\n@@ -14001,7 +14088,7 @@\n   addr2 = copy_to_mode_reg (Pmode, XEXP (operands[2], 0));\n   \n   count = operands[3];\n-  countreg = copy_to_mode_reg (SImode, count);\n+  countreg = copy_to_mode_reg (Pmode, count);\n \n   /* %%% Iff we are testing strict equality, we can use known alignment\n      to good advantage.  This may be possible with combine, particularly\n@@ -14016,14 +14103,27 @@\n \t  emit_move_insn (operands[0], const0_rtx);\n \t  DONE;\n \t}\n-      emit_insn (gen_cmpstrsi_nz_1 (addr1, addr2, countreg, align,\n-\t\t\t\t    addr1, addr2, countreg));\n+      if (TARGET_64BIT)\n+\temit_insn (gen_cmpstrqi_nz_rex_1 (addr1, addr2, countreg, align,\n+\t\t\t\t\t  addr1, addr2, countreg));\n+      else\n+\temit_insn (gen_cmpstrqi_nz_1 (addr1, addr2, countreg, align,\n+\t\t\t\t      addr1, addr2, countreg));\n     }\n   else\n     {\n-      emit_insn (gen_cmpsi_1 (countreg, countreg));\n-      emit_insn (gen_cmpstrsi_1 (addr1, addr2, countreg, align,\n-\t\t\t\t addr1, addr2, countreg));\n+      if (TARGET_64BIT)\n+\t{\n+\t  emit_insn (gen_cmpdi_1_rex64 (countreg, countreg));\n+\t  emit_insn (gen_cmpstrqi_rex_1 (addr1, addr2, countreg, align,\n+\t\t\t\t\t addr1, addr2, countreg));\n+\t}\n+      else\n+\t{\n+\t  emit_insn (gen_cmpsi_1 (countreg, countreg));\n+\t  emit_insn (gen_cmpstrqi_1 (addr1, addr2, countreg, align,\n+\t\t\t\t     addr1, addr2, countreg));\n+\t}\n     }\n \n   outlow = gen_lowpart (QImode, out);\n@@ -14054,7 +14154,7 @@\n ;; memcmp recognizers.  The `cmpsb' opcode does nothing if the count is\n ;; zero.  Emit extra code to make sure that a zero-length compare is EQ.\n \n-(define_insn \"cmpstrsi_nz_1\"\n+(define_insn \"cmpstrqi_nz_1\"\n   [(set (reg:CC 17)\n \t(compare:CC (mem:BLK (match_operand:SI 4 \"register_operand\" \"0\"))\n \t\t    (mem:BLK (match_operand:SI 5 \"register_operand\" \"1\"))))\n@@ -14064,15 +14164,31 @@\n    (clobber (match_operand:SI 0 \"register_operand\" \"=S\"))\n    (clobber (match_operand:SI 1 \"register_operand\" \"=D\"))\n    (clobber (match_operand:SI 2 \"register_operand\" \"=c\"))]\n-  \"\"\n+  \"!TARGET_64BIT\"\n+  \"repz{\\;| }cmpsb\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"mode\" \"QI\")\n+   (set_attr \"prefix_rep\" \"1\")])\n+\n+(define_insn \"cmpstrqi_nz_rex_1\"\n+  [(set (reg:CC 17)\n+\t(compare:CC (mem:BLK (match_operand:DI 4 \"register_operand\" \"0\"))\n+\t\t    (mem:BLK (match_operand:DI 5 \"register_operand\" \"1\"))))\n+   (use (match_operand:DI 6 \"register_operand\" \"2\"))\n+   (use (match_operand:SI 3 \"immediate_operand\" \"i\"))\n+   (use (reg:SI 19))\n+   (clobber (match_operand:DI 0 \"register_operand\" \"=S\"))\n+   (clobber (match_operand:DI 1 \"register_operand\" \"=D\"))\n+   (clobber (match_operand:DI 2 \"register_operand\" \"=c\"))]\n+  \"TARGET_64BIT\"\n   \"repz{\\;| }cmpsb\"\n   [(set_attr \"type\" \"str\")\n    (set_attr \"mode\" \"QI\")\n    (set_attr \"prefix_rep\" \"1\")])\n \n ;; The same, but the count is not known to not be zero.\n \n-(define_insn \"cmpstrsi_1\"\n+(define_insn \"cmpstrqi_1\"\n   [(set (reg:CC 17)\n \t(if_then_else:CC (ne (match_operand:SI 6 \"register_operand\" \"2\")\n \t\t\t     (const_int 0))\n@@ -14085,7 +14201,26 @@\n    (clobber (match_operand:SI 0 \"register_operand\" \"=S\"))\n    (clobber (match_operand:SI 1 \"register_operand\" \"=D\"))\n    (clobber (match_operand:SI 2 \"register_operand\" \"=c\"))]\n-  \"\"\n+  \"!TARGET_64BIT\"\n+  \"repz{\\;| }cmpsb\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"mode\" \"QI\")\n+   (set_attr \"prefix_rep\" \"1\")])\n+\n+(define_insn \"cmpstrqi_rex_1\"\n+  [(set (reg:CC 17)\n+\t(if_then_else:CC (ne (match_operand:DI 6 \"register_operand\" \"2\")\n+\t\t\t     (const_int 0))\n+\t  (compare:CC (mem:BLK (match_operand:DI 4 \"register_operand\" \"0\"))\n+\t\t      (mem:BLK (match_operand:DI 5 \"register_operand\" \"1\")))\n+\t  (const_int 0)))\n+   (use (match_operand:SI 3 \"immediate_operand\" \"i\"))\n+   (use (reg:CC 17))\n+   (use (reg:SI 19))\n+   (clobber (match_operand:DI 0 \"register_operand\" \"=S\"))\n+   (clobber (match_operand:DI 1 \"register_operand\" \"=D\"))\n+   (clobber (match_operand:DI 2 \"register_operand\" \"=c\"))]\n+  \"TARGET_64BIT\"\n   \"repz{\\;| }cmpsb\"\n   [(set_attr \"type\" \"str\")\n    (set_attr \"mode\" \"QI\")\n@@ -14095,76 +14230,55 @@\n   [(set (match_operand:SI 0 \"register_operand\" \"\")\n \t(unspec:SI [(match_operand:BLK 1 \"general_operand\" \"\")\n \t\t    (match_operand:QI 2 \"immediate_operand\" \"\")\n-\t\t    (match_operand:SI 3 \"immediate_operand\" \"\")] 0))]\n+\t\t    (match_operand 3 \"immediate_operand\" \"\")] 0))]\n   \"\"\n   \"\n {\n-  rtx out, addr, scratch1, scratch2, scratch3;\n-  rtx eoschar = operands[2];\n-  rtx align = operands[3];\n-\n-  /* The generic case of strlen expander is long.  Avoid it's\n-     expanding unless TARGET_INLINE_ALL_STRINGOPS.  */\n-\n-  if (TARGET_UNROLL_STRLEN && eoschar == const0_rtx && optimize > 1\n-      && !TARGET_INLINE_ALL_STRINGOPS\n-      && !optimize_size\n-      && (GET_CODE (align) != CONST_INT || INTVAL (align) < 4))\n-    FAIL;\n-\n-  out = operands[0];\n-  addr = force_reg (Pmode, XEXP (operands[1], 0));\n-  scratch1 = gen_reg_rtx (SImode);\n-\n-  if (TARGET_UNROLL_STRLEN && eoschar == const0_rtx && optimize > 1\n-      && !optimize_size)\n-    {\n-      /* Well it seems that some optimizer does not combine a call like\n-\t     foo(strlen(bar), strlen(bar));\n-\t when the move and the subtraction is done here.  It does calculate\n-\t the length just once when these instructions are done inside of\n-\t output_strlen_unroll().  But I think since &bar[strlen(bar)] is\n-\t often used and I use one fewer register for the lifetime of\n-\t output_strlen_unroll() this is better.  */\n-\n-      if (GET_CODE (align) != CONST_INT || INTVAL (align) < 4)\n-\temit_move_insn (scratch1, addr);\n-\n-      emit_move_insn (out, addr);\n-\n-      ix86_expand_strlensi_unroll_1 (out, align, scratch1);\n-\n-      /* strlensi_unroll_1 returns the address of the zero at the end of\n-\t the string, like memchr(), so compute the length by subtracting\n-\t the start address.  */\n-      emit_insn (gen_subsi3 (out, out, addr));\n-    }\n-  else\n-    {\n-      scratch2 = gen_reg_rtx (SImode);\n-      scratch3 = gen_reg_rtx (SImode);\n-\n-      emit_move_insn (scratch3, addr);\n+ if (ix86_expand_strlen (operands[0], operands[1], operands[2], operands[3]))\n+   DONE;\n+ else\n+   FAIL;\n+}\")\n \n-      emit_insn (gen_cld ());\n-      emit_insn (gen_strlensi_1 (scratch1, scratch3, eoschar,\n-\t\t\t\t align, constm1_rtx, scratch3));\n-      emit_insn (gen_one_cmplsi2 (scratch2, scratch1));\n-      emit_insn (gen_addsi3 (out, scratch2, constm1_rtx));\n-    }\n-  DONE;\n+(define_expand \"strlendi\"\n+  [(set (match_operand:DI 0 \"register_operand\" \"\")\n+\t(unspec:DI [(match_operand:BLK 1 \"general_operand\" \"\")\n+\t\t    (match_operand:QI 2 \"immediate_operand\" \"\")\n+\t\t    (match_operand 3 \"immediate_operand\" \"\")] 0))]\n+  \"\"\n+  \"\n+{\n+ if (ix86_expand_strlen (operands[0], operands[1], operands[2], operands[3]))\n+   DONE;\n+ else\n+   FAIL;\n }\")\n \n-(define_insn \"strlensi_1\"\n+(define_insn \"strlenqi_1\"\n   [(set (match_operand:SI 0 \"register_operand\" \"=&c\")\n \t(unspec:SI [(mem:BLK (match_operand:SI 5 \"register_operand\" \"1\"))\n-\t\t    (match_operand:QI 2 \"general_operand\" \"a\")\n+\t\t    (match_operand:QI 2 \"register_operand\" \"a\")\n \t\t    (match_operand:SI 3 \"immediate_operand\" \"i\")\n-\t\t    (match_operand:SI 4 \"immediate_operand\" \"0\")] 0))\n+\t\t    (match_operand:SI 4 \"register_operand\" \"0\")] 0))\n    (use (reg:SI 19))\n    (clobber (match_operand:SI 1 \"register_operand\" \"=D\"))\n    (clobber (reg:CC 17))]\n-  \"\"\n+  \"!TARGET_64BIT\"\n+  \"repnz{\\;| }scasb\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"mode\" \"QI\")\n+   (set_attr \"prefix_rep\" \"1\")])\n+\n+(define_insn \"strlenqi_rex_1\"\n+  [(set (match_operand:DI 0 \"register_operand\" \"=&c\")\n+\t(unspec:DI [(mem:BLK (match_operand:DI 5 \"register_operand\" \"1\"))\n+\t\t    (match_operand:QI 2 \"register_operand\" \"a\")\n+\t\t    (match_operand:DI 3 \"immediate_operand\" \"i\")\n+\t\t    (match_operand:DI 4 \"register_operand\" \"0\")] 0))\n+   (use (reg:SI 19))\n+   (clobber (match_operand:DI 1 \"register_operand\" \"=D\"))\n+   (clobber (reg:CC 17))]\n+  \"TARGET_64BIT\"\n   \"repnz{\\;| }scasb\"\n   [(set_attr \"type\" \"str\")\n    (set_attr \"mode\" \"QI\")"}]}