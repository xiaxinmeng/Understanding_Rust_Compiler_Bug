{"sha": "bd1ef757767f6d9e4b8ba3dfdaf38e89fd282c52", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YmQxZWY3NTc3NjdmNmQ5ZTRiOGJhM2RmZGFmMzhlODlmZDI4MmM1Mg==", "commit": {"author": {"name": "Paolo Bonzini", "email": "bonzini@gnu.org", "date": "2005-12-16T09:24:19Z"}, "committer": {"name": "Paolo Bonzini", "email": "bonzini@gcc.gnu.org", "date": "2005-12-16T09:24:19Z"}, "message": "combine.c (combine_simplify_rtx <case NOT, [...]): Move simplifications that do not require additional infrastructure...\n\n2005-12-16  Paolo Bonzini  <bonzini@gnu.org>\n\n\t* combine.c (combine_simplify_rtx <case NOT, NEG, TRUNCATE,\n\tFLOAT_TRUNCATE, FLOAT_EXTEND, PLUS, MINUS, AND, IOR, XOR,\n\tABS, VEC_SELECT, POPCOUNT, PARITY, FFS, FLOAT>,\n\tsimplify_logical): Move simplifications that do not require\n\tadditional infrastructure...\n\t* simplify-rtx.c (simplify_unary_operation_1,\n\tsimplify_binary_operation_1): ... here.\n\nFrom-SVN: r108634", "tree": {"sha": "0e7e58e483b53cd800360158ace182ae3de997f6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/0e7e58e483b53cd800360158ace182ae3de997f6"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/bd1ef757767f6d9e4b8ba3dfdaf38e89fd282c52", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bd1ef757767f6d9e4b8ba3dfdaf38e89fd282c52", "html_url": "https://github.com/Rust-GCC/gccrs/commit/bd1ef757767f6d9e4b8ba3dfdaf38e89fd282c52", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/bd1ef757767f6d9e4b8ba3dfdaf38e89fd282c52/comments", "author": {"login": "bonzini", "id": 42082, "node_id": "MDQ6VXNlcjQyMDgy", "avatar_url": "https://avatars.githubusercontent.com/u/42082?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bonzini", "html_url": "https://github.com/bonzini", "followers_url": "https://api.github.com/users/bonzini/followers", "following_url": "https://api.github.com/users/bonzini/following{/other_user}", "gists_url": "https://api.github.com/users/bonzini/gists{/gist_id}", "starred_url": "https://api.github.com/users/bonzini/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bonzini/subscriptions", "organizations_url": "https://api.github.com/users/bonzini/orgs", "repos_url": "https://api.github.com/users/bonzini/repos", "events_url": "https://api.github.com/users/bonzini/events{/privacy}", "received_events_url": "https://api.github.com/users/bonzini/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "488ce07ba2af2b5d6175511025539989afd317a2", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/488ce07ba2af2b5d6175511025539989afd317a2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/488ce07ba2af2b5d6175511025539989afd317a2"}], "stats": {"total": 1108, "additions": 543, "deletions": 565}, "files": [{"sha": "bfa1e941d70c7626687243b4c9521833caff77bf", "filename": "gcc/ChangeLog", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd1ef757767f6d9e4b8ba3dfdaf38e89fd282c52/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd1ef757767f6d9e4b8ba3dfdaf38e89fd282c52/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=bd1ef757767f6d9e4b8ba3dfdaf38e89fd282c52", "patch": "@@ -1,3 +1,13 @@\n+2005-12-16  Paolo Bonzini  <bonzini@gnu.org>\n+\n+\t* combine.c (combine_simplify_rtx <case NOT, NEG, TRUNCATE,\n+\tFLOAT_TRUNCATE, FLOAT_EXTEND, PLUS, MINUS, AND, IOR, XOR,\n+\tABS, VEC_SELECT, POPCOUNT, PARITY, FFS, FLOAT>,\n+\tsimplify_logical): Move simplifications that do not require\n+\tadditional infrastructure...\n+\t* simplify-rtx.c (simplify_unary_operation_1,\n+\tsimplify_binary_operation_1): ... here.\n+\n 2005-12-16  Andreas Krebbel  <krebbel1@de.ibm.com>\n \n \tPR 24823"}, {"sha": "f3ae4ea95fab651bd1db521192acb10080deb68d", "filename": "gcc/combine.c", "status": "modified", "additions": 3, "deletions": 553, "changes": 556, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd1ef757767f6d9e4b8ba3dfdaf38e89fd282c52/gcc%2Fcombine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd1ef757767f6d9e4b8ba3dfdaf38e89fd282c52/gcc%2Fcombine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcombine.c?ref=bd1ef757767f6d9e4b8ba3dfdaf38e89fd282c52", "patch": "@@ -3902,7 +3902,6 @@ combine_simplify_rtx (rtx x, enum machine_mode op0_mode, int in_dest)\n   enum rtx_code code = GET_CODE (x);\n   enum machine_mode mode = GET_MODE (x);\n   rtx temp;\n-  rtx reversed;\n   int i;\n \n   /* If this is a commutative operation, put a constant last and a complex\n@@ -4159,60 +4158,7 @@ combine_simplify_rtx (rtx x, enum machine_mode op0_mode, int in_dest)\n \n       break;\n \n-    case NOT:\n-      if (GET_CODE (XEXP (x, 0)) == SUBREG\n-\t  && subreg_lowpart_p (XEXP (x, 0))\n-\t  && (GET_MODE_SIZE (GET_MODE (XEXP (x, 0)))\n-\t      < GET_MODE_SIZE (GET_MODE (SUBREG_REG (XEXP (x, 0)))))\n-\t  && GET_CODE (SUBREG_REG (XEXP (x, 0))) == ASHIFT\n-\t  && XEXP (SUBREG_REG (XEXP (x, 0)), 0) == const1_rtx)\n-\t{\n-\t  enum machine_mode inner_mode = GET_MODE (SUBREG_REG (XEXP (x, 0)));\n-\n-\t  x = gen_rtx_ROTATE (inner_mode,\n-\t\t\t      simplify_gen_unary (NOT, inner_mode, const1_rtx,\n-\t\t\t\t\t\t  inner_mode),\n-\t\t\t      XEXP (SUBREG_REG (XEXP (x, 0)), 1));\n-\t  return gen_lowpart (mode, x);\n-\t}\n-\n-      /* Apply De Morgan's laws to reduce number of patterns for machines\n-\t with negating logical insns (and-not, nand, etc.).  If result has\n-\t only one NOT, put it first, since that is how the patterns are\n-\t coded.  */\n-\n-      if (GET_CODE (XEXP (x, 0)) == IOR || GET_CODE (XEXP (x, 0)) == AND)\n-\t{\n-\t  rtx in1 = XEXP (XEXP (x, 0), 0), in2 = XEXP (XEXP (x, 0), 1);\n-\t  enum machine_mode op_mode;\n-\n-\t  op_mode = GET_MODE (in1);\n-\t  in1 = simplify_gen_unary (NOT, op_mode, in1, op_mode);\n-\n-\t  op_mode = GET_MODE (in2);\n-\t  if (op_mode == VOIDmode)\n-\t    op_mode = mode;\n-\t  in2 = simplify_gen_unary (NOT, op_mode, in2, op_mode);\n-\n-\t  if (GET_CODE (in2) == NOT && GET_CODE (in1) != NOT)\n-\t    {\n-\t      rtx tem = in2;\n-\t      in2 = in1; in1 = tem;\n-\t    }\n-\n-\t  return gen_rtx_fmt_ee (GET_CODE (XEXP (x, 0)) == IOR ? AND : IOR,\n-\t\t\t\t mode, in1, in2);\n-\t}\n-      break;\n-\n     case NEG:\n-      /* (neg (xor A 1)) is (plus A -1) if A is known to be either 0 or 1.  */\n-      if (GET_CODE (XEXP (x, 0)) == XOR\n-\t  && XEXP (XEXP (x, 0), 1) == const1_rtx\n-\t  && nonzero_bits (XEXP (XEXP (x, 0), 0), mode) == 1)\n-\treturn simplify_gen_binary (PLUS, mode, XEXP (XEXP (x, 0), 0),\n-\t\t\t\t    constm1_rtx);\n-\n       temp = expand_compound_operation (XEXP (x, 0));\n \n       /* For C equal to the width of MODE minus 1, (neg (ashiftrt X C)) can be\n@@ -4267,131 +4213,16 @@ combine_simplify_rtx (rtx x, enum machine_mode op0_mode, int in_dest)\n \t       force_to_mode (XEXP (x, 0), GET_MODE (XEXP (x, 0)),\n \t\t\t      GET_MODE_MASK (mode), 0));\n \n-      /* (truncate:SI ({sign,zero}_extend:DI foo:SI)) == foo:SI.  */\n-      if ((GET_CODE (XEXP (x, 0)) == SIGN_EXTEND\n-\t   || GET_CODE (XEXP (x, 0)) == ZERO_EXTEND)\n-\t  && GET_MODE (XEXP (XEXP (x, 0), 0)) == mode)\n-\treturn XEXP (XEXP (x, 0), 0);\n-\n-      /* (truncate:SI (OP:DI ({sign,zero}_extend:DI foo:SI))) is\n-\t (OP:SI foo:SI) if OP is NEG or ABS.  */\n-      if ((GET_CODE (XEXP (x, 0)) == ABS\n-\t   || GET_CODE (XEXP (x, 0)) == NEG)\n-\t  && (GET_CODE (XEXP (XEXP (x, 0), 0)) == SIGN_EXTEND\n-\t      || GET_CODE (XEXP (XEXP (x, 0), 0)) == ZERO_EXTEND)\n-\t  && GET_MODE (XEXP (XEXP (XEXP (x, 0), 0), 0)) == mode)\n-\treturn simplify_gen_unary (GET_CODE (XEXP (x, 0)), mode,\n-\t\t\t\t   XEXP (XEXP (XEXP (x, 0), 0), 0), mode);\n-\n-      /* (truncate:SI (subreg:DI (truncate:SI X) 0)) is\n-\t (truncate:SI x).  */\n-      if (GET_CODE (XEXP (x, 0)) == SUBREG\n-\t  && GET_CODE (SUBREG_REG (XEXP (x, 0))) == TRUNCATE\n-\t  && subreg_lowpart_p (XEXP (x, 0)))\n-\treturn SUBREG_REG (XEXP (x, 0));\n-\n-      /* If we know that the value is already truncated, we can\n-         replace the TRUNCATE with a SUBREG if TRULY_NOOP_TRUNCATION\n-         is nonzero for the corresponding modes.  But don't do this\n-         for an (LSHIFTRT (MULT ...)) since this will cause problems\n-         with the umulXi3_highpart patterns.  */\n-      if (TRULY_NOOP_TRUNCATION (GET_MODE_BITSIZE (mode),\n-\t\t\t\t GET_MODE_BITSIZE (GET_MODE (XEXP (x, 0))))\n-\t  && num_sign_bit_copies (XEXP (x, 0), GET_MODE (XEXP (x, 0)))\n-\t     >= (unsigned int) (GET_MODE_BITSIZE (mode) + 1)\n-\t  && ! (GET_CODE (XEXP (x, 0)) == LSHIFTRT\n-\t\t&& GET_CODE (XEXP (XEXP (x, 0), 0)) == MULT))\n-\treturn gen_lowpart (mode, XEXP (x, 0));\n-\n-      /* A truncate of a comparison can be replaced with a subreg if\n-         STORE_FLAG_VALUE permits.  This is like the previous test,\n-         but it works even if the comparison is done in a mode larger\n-         than HOST_BITS_PER_WIDE_INT.  */\n-      if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n-\t  && COMPARISON_P (XEXP (x, 0))\n-\t  && ((HOST_WIDE_INT) STORE_FLAG_VALUE & ~GET_MODE_MASK (mode)) == 0)\n-\treturn gen_lowpart (mode, XEXP (x, 0));\n-\n-      /* Similarly, a truncate of a register whose value is a\n-         comparison can be replaced with a subreg if STORE_FLAG_VALUE\n-         permits.  */\n+      /* Similarly to what we do in simplify-rtx.c, a truncate of a register\n+\t whose value is a comparison can be replaced with a subreg if\n+\t STORE_FLAG_VALUE permits.  */\n       if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n \t  && ((HOST_WIDE_INT) STORE_FLAG_VALUE & ~GET_MODE_MASK (mode)) == 0\n \t  && (temp = get_last_value (XEXP (x, 0)))\n \t  && COMPARISON_P (temp))\n \treturn gen_lowpart (mode, XEXP (x, 0));\n-\n       break;\n \n-    case FLOAT_TRUNCATE:\n-      /* (float_truncate:SF (float_extend:DF foo:SF)) = foo:SF.  */\n-      if (GET_CODE (XEXP (x, 0)) == FLOAT_EXTEND\n-\t  && GET_MODE (XEXP (XEXP (x, 0), 0)) == mode)\n-\treturn XEXP (XEXP (x, 0), 0);\n-\n-      /* (float_truncate:SF (float_truncate:DF foo:XF))\n-         = (float_truncate:SF foo:XF).\n-\t This may eliminate double rounding, so it is unsafe.\n-\n-         (float_truncate:SF (float_extend:XF foo:DF))\n-         = (float_truncate:SF foo:DF).\n-\n-         (float_truncate:DF (float_extend:XF foo:SF))\n-         = (float_extend:SF foo:DF).  */\n-      if ((GET_CODE (XEXP (x, 0)) == FLOAT_TRUNCATE\n-\t   && flag_unsafe_math_optimizations)\n-\t  || GET_CODE (XEXP (x, 0)) == FLOAT_EXTEND)\n-\treturn simplify_gen_unary (GET_MODE_SIZE (GET_MODE (XEXP (XEXP (x, 0),\n-\t\t\t\t\t\t\t    0)))\n-\t\t\t\t   > GET_MODE_SIZE (mode)\n-\t\t\t\t   ? FLOAT_TRUNCATE : FLOAT_EXTEND,\n-\t\t\t\t   mode,\n-\t\t\t\t   XEXP (XEXP (x, 0), 0), mode);\n-\n-      /*  (float_truncate (float x)) is (float x)  */\n-      if (GET_CODE (XEXP (x, 0)) == FLOAT\n-\t  && (flag_unsafe_math_optimizations\n-\t      || ((unsigned)significand_size (GET_MODE (XEXP (x, 0)))\n-\t\t  >= (GET_MODE_BITSIZE (GET_MODE (XEXP (XEXP (x, 0), 0)))\n-\t\t      - num_sign_bit_copies (XEXP (XEXP (x, 0), 0),\n-\t\t\t\t\t     GET_MODE (XEXP (XEXP (x, 0), 0)))))))\n-\treturn simplify_gen_unary (FLOAT, mode,\n-\t\t\t\t   XEXP (XEXP (x, 0), 0),\n-\t\t\t\t   GET_MODE (XEXP (XEXP (x, 0), 0)));\n-\n-      /* (float_truncate:SF (OP:DF (float_extend:DF foo:sf))) is\n-\t (OP:SF foo:SF) if OP is NEG or ABS.  */\n-      if ((GET_CODE (XEXP (x, 0)) == ABS\n-\t   || GET_CODE (XEXP (x, 0)) == NEG)\n-\t  && GET_CODE (XEXP (XEXP (x, 0), 0)) == FLOAT_EXTEND\n-\t  && GET_MODE (XEXP (XEXP (XEXP (x, 0), 0), 0)) == mode)\n-\treturn simplify_gen_unary (GET_CODE (XEXP (x, 0)), mode,\n-\t\t\t\t   XEXP (XEXP (XEXP (x, 0), 0), 0), mode);\n-\n-      /* (float_truncate:SF (subreg:DF (float_truncate:SF X) 0))\n-\t is (float_truncate:SF x).  */\n-      if (GET_CODE (XEXP (x, 0)) == SUBREG\n-\t  && subreg_lowpart_p (XEXP (x, 0))\n-\t  && GET_CODE (SUBREG_REG (XEXP (x, 0))) == FLOAT_TRUNCATE)\n-\treturn SUBREG_REG (XEXP (x, 0));\n-      break;\n-    case FLOAT_EXTEND:\n-      /*  (float_extend (float_extend x)) is (float_extend x)\n-\n-\t  (float_extend (float x)) is (float x) assuming that double\n-\t  rounding can't happen.\n-          */\n-      if (GET_CODE (XEXP (x, 0)) == FLOAT_EXTEND\n-\t  || (GET_CODE (XEXP (x, 0)) == FLOAT\n-\t      && ((unsigned)significand_size (GET_MODE (XEXP (x, 0)))\n-\t\t  >= (GET_MODE_BITSIZE (GET_MODE (XEXP (XEXP (x, 0), 0)))\n-\t\t      - num_sign_bit_copies (XEXP (XEXP (x, 0), 0),\n-\t\t\t\t\t     GET_MODE (XEXP (XEXP (x, 0), 0)))))))\n-\treturn simplify_gen_unary (GET_CODE (XEXP (x, 0)), mode,\n-\t\t\t\t   XEXP (XEXP (x, 0), 0),\n-\t\t\t\t   GET_MODE (XEXP (XEXP (x, 0), 0)));\n-\n-      break;\n #ifdef HAVE_cc0\n     case COMPARE:\n       /* Convert (compare FOO (const_int 0)) to FOO unless we aren't\n@@ -4430,32 +4261,6 @@ combine_simplify_rtx (rtx x, enum machine_mode op0_mode, int in_dest)\n #endif\n \n     case PLUS:\n-      /* Canonicalize (plus (mult (neg B) C) A) to (minus A (mult B C)).\n-       */\n-      if (GET_CODE (XEXP (x, 0)) == MULT\n-\t  && GET_CODE (XEXP (XEXP (x, 0), 0)) == NEG)\n-\t{\n-\t  rtx in1, in2;\n-\n-\t  in1 = XEXP (XEXP (XEXP (x, 0), 0), 0);\n-\t  in2 = XEXP (XEXP (x, 0), 1);\n-\t  return simplify_gen_binary (MINUS, mode, XEXP (x, 1),\n-\t\t\t\t      simplify_gen_binary (MULT, mode,\n-\t\t\t\t\t\t\t   in1, in2));\n-\t}\n-\n-      /* If we have (plus (plus (A const) B)), associate it so that CONST is\n-\t outermost.  That's because that's the way indexed addresses are\n-\t supposed to appear.  This code used to check many more cases, but\n-\t they are now checked elsewhere.  */\n-      if (GET_CODE (XEXP (x, 0)) == PLUS\n-\t  && CONSTANT_ADDRESS_P (XEXP (XEXP (x, 0), 1)))\n-\treturn simplify_gen_binary (PLUS, mode,\n-\t\t\t   \t    simplify_gen_binary (PLUS, mode,\n-\t\t\t\t\t\t\t XEXP (XEXP (x, 0), 0),\n-\t\t\t\t\t\t\t XEXP (x, 1)),\n-\t\t\t\t    XEXP (XEXP (x, 0), 1));\n-\n       /* (plus (xor (and <foo> (const_int pow2 - 1)) <c>) <-c>)\n \t when c is (const_int (pow2 + 1) / 2) is a sign extension of a\n \t bit-field and can be replaced by either a sign_extend or a\n@@ -4482,17 +4287,6 @@ combine_simplify_rtx (rtx x, enum machine_mode op0_mode, int in_dest)\n \t\t\t\t GET_MODE_BITSIZE (mode) - (i + 1)),\n \t   GET_MODE_BITSIZE (mode) - (i + 1));\n \n-      /* (plus (comparison A B) C) can become (neg (rev-comp A B)) if\n-\t C is 1 and STORE_FLAG_VALUE is -1 or if C is -1 and STORE_FLAG_VALUE\n-\t is 1.  This produces better code than the alternative immediately\n-\t below.  */\n-      if (COMPARISON_P (XEXP (x, 0))\n-\t  && ((STORE_FLAG_VALUE == -1 && XEXP (x, 1) == const1_rtx)\n-\t      || (STORE_FLAG_VALUE == 1 && XEXP (x, 1) == constm1_rtx))\n-\t  && (reversed = reversed_comparison (XEXP (x, 0), mode)))\n-\treturn\n-\t  simplify_gen_unary (NEG, mode, reversed, mode);\n-\n       /* If only the low-order bit of X is possibly nonzero, (plus x -1)\n \t can become (ashiftrt (ashift (xor x 1) C) C) where C is\n \t the bitsize of the mode - 1.  This allows simplification of\n@@ -4530,14 +4324,6 @@ combine_simplify_rtx (rtx x, enum machine_mode op0_mode, int in_dest)\n       break;\n \n     case MINUS:\n-      /* If STORE_FLAG_VALUE is 1, (minus 1 (comparison foo bar)) can be done\n-\t by reversing the comparison code if valid.  */\n-      if (STORE_FLAG_VALUE == 1\n-\t  && XEXP (x, 0) == const1_rtx\n-\t  && COMPARISON_P (XEXP (x, 1))\n-\t  && (reversed = reversed_comparison (XEXP (x, 1), mode)))\n-\treturn reversed;\n-\n       /* (minus <foo> (and <foo> (const_int -pow2))) becomes\n \t (and <foo> (const_int pow2-1))  */\n       if (GET_CODE (XEXP (x, 1)) == AND\n@@ -4546,45 +4332,6 @@ combine_simplify_rtx (rtx x, enum machine_mode op0_mode, int in_dest)\n \t  && rtx_equal_p (XEXP (XEXP (x, 1), 0), XEXP (x, 0)))\n \treturn simplify_and_const_int (NULL_RTX, mode, XEXP (x, 0),\n \t\t\t\t       -INTVAL (XEXP (XEXP (x, 1), 1)) - 1);\n-\n-      /* Canonicalize (minus A (mult (neg B) C)) to (plus (mult B C) A).\n-       */\n-      if (GET_CODE (XEXP (x, 1)) == MULT\n-\t  && GET_CODE (XEXP (XEXP (x, 1), 0)) == NEG)\n-\t{\n-\t  rtx in1, in2;\n-\n-\t  in1 = XEXP (XEXP (XEXP (x, 1), 0), 0);\n-\t  in2 = XEXP (XEXP (x, 1), 1);\n-\t  return simplify_gen_binary (PLUS, mode,\n-\t\t\t\t      simplify_gen_binary (MULT, mode,\n-\t\t\t\t\t\t\t   in1, in2),\n-\t\t\t\t      XEXP (x, 0));\n-\t}\n-\n-      /* Canonicalize (minus (neg A) (mult B C)) to\n-\t (minus (mult (neg B) C) A).  */\n-      if (GET_CODE (XEXP (x, 1)) == MULT\n-\t  && GET_CODE (XEXP (x, 0)) == NEG)\n-\t{\n-\t  rtx in1, in2;\n-\n-\t  in1 = simplify_gen_unary (NEG, mode, XEXP (XEXP (x, 1), 0), mode);\n-\t  in2 = XEXP (XEXP (x, 1), 1);\n-\t  return simplify_gen_binary (MINUS, mode,\n-\t\t\t\t      simplify_gen_binary (MULT, mode,\n-\t\t\t\t\t\t\t   in1, in2),\n-\t\t\t\t      XEXP (XEXP (x, 0), 0));\n-\t}\n-\n-      /* Canonicalize (minus A (plus B C)) to (minus (minus A B) C) for\n-\t integers.  */\n-      if (GET_CODE (XEXP (x, 1)) == PLUS && INTEGRAL_MODE_P (mode))\n-\treturn simplify_gen_binary (MINUS, mode,\n-\t\t\t\t    simplify_gen_binary (MINUS, mode,\n-\t\t\t\t\t\t\t XEXP (x, 0),\n-\t\t\t\t\t\t         XEXP (XEXP (x, 1), 0)),\n-\t\t\t\t    XEXP (XEXP (x, 1), 1));\n       break;\n \n     case MULT:\n@@ -4800,55 +4547,8 @@ combine_simplify_rtx (rtx x, enum machine_mode op0_mode, int in_dest)\n \n     case AND:\n     case IOR:\n-    case XOR:\n       return simplify_logical (x);\n \n-    case ABS:\n-      /* (abs (neg <foo>)) -> (abs <foo>) */\n-      if (GET_CODE (XEXP (x, 0)) == NEG)\n-\tSUBST (XEXP (x, 0), XEXP (XEXP (x, 0), 0));\n-\n-      /* If the mode of the operand is VOIDmode (i.e. if it is ASM_OPERANDS),\n-         do nothing.  */\n-      if (GET_MODE (XEXP (x, 0)) == VOIDmode)\n-\tbreak;\n-\n-      /* If operand is something known to be positive, ignore the ABS.  */\n-      if (GET_CODE (XEXP (x, 0)) == FFS || GET_CODE (XEXP (x, 0)) == ABS\n-\t  || ((GET_MODE_BITSIZE (GET_MODE (XEXP (x, 0)))\n-\t       <= HOST_BITS_PER_WIDE_INT)\n-\t      && ((nonzero_bits (XEXP (x, 0), GET_MODE (XEXP (x, 0)))\n-\t\t   & ((HOST_WIDE_INT) 1\n-\t\t      << (GET_MODE_BITSIZE (GET_MODE (XEXP (x, 0))) - 1)))\n-\t\t  == 0)))\n-\treturn XEXP (x, 0);\n-\n-      /* If operand is known to be only -1 or 0, convert ABS to NEG.  */\n-      if (num_sign_bit_copies (XEXP (x, 0), mode) == GET_MODE_BITSIZE (mode))\n-\treturn gen_rtx_NEG (mode, XEXP (x, 0));\n-\n-      break;\n-\n-    case FFS:\n-      /* (ffs (*_extend <X>)) = (ffs <X>) */\n-      if (GET_CODE (XEXP (x, 0)) == SIGN_EXTEND\n-\t  || GET_CODE (XEXP (x, 0)) == ZERO_EXTEND)\n-\tSUBST (XEXP (x, 0), XEXP (XEXP (x, 0), 0));\n-      break;\n-\n-    case POPCOUNT:\n-    case PARITY:\n-      /* (pop* (zero_extend <X>)) = (pop* <X>) */\n-      if (GET_CODE (XEXP (x, 0)) == ZERO_EXTEND)\n-\tSUBST (XEXP (x, 0), XEXP (XEXP (x, 0), 0));\n-      break;\n-\n-    case FLOAT:\n-      /* (float (sign_extend <X>)) = (float <X>).  */\n-      if (GET_CODE (XEXP (x, 0)) == SIGN_EXTEND)\n-\tSUBST (XEXP (x, 0), XEXP (XEXP (x, 0), 0));\n-      break;\n-\n     case ASHIFT:\n     case LSHIFTRT:\n     case ASHIFTRT:\n@@ -4868,44 +4568,6 @@ combine_simplify_rtx (rtx x, enum machine_mode op0_mode, int in_dest)\n \t\t\t      0));\n       break;\n \n-    case VEC_SELECT:\n-      {\n-\trtx op0 = XEXP (x, 0);\n-\trtx op1 = XEXP (x, 1);\n-\tint len;\n-\n-\tgcc_assert (GET_CODE (op1) == PARALLEL);\n-\tlen = XVECLEN (op1, 0);\n-\tif (len == 1\n-\t    && GET_CODE (XVECEXP (op1, 0, 0)) == CONST_INT\n-\t    && GET_CODE (op0) == VEC_CONCAT)\n-\t  {\n-\t    int offset = INTVAL (XVECEXP (op1, 0, 0)) * GET_MODE_SIZE (GET_MODE (x));\n-\n-\t    /* Try to find the element in the VEC_CONCAT.  */\n-\t    for (;;)\n-\t      {\n-\t\tif (GET_MODE (op0) == GET_MODE (x))\n-\t\t  return op0;\n-\t\tif (GET_CODE (op0) == VEC_CONCAT)\n-\t\t  {\n-\t\t    HOST_WIDE_INT op0_size = GET_MODE_SIZE (GET_MODE (XEXP (op0, 0)));\n-\t\t    if (offset < op0_size)\n-\t\t      op0 = XEXP (op0, 0);\n-\t\t    else\n-\t\t      {\n-\t\t\toffset -= op0_size;\n-\t\t\top0 = XEXP (op0, 1);\n-\t\t      }\n-\t\t  }\n-\t\telse\n-\t\t  break;\n-\t      }\n-\t  }\n-      }\n-\n-      break;\n-\n     default:\n       break;\n     }\n@@ -5598,42 +5260,10 @@ simplify_logical (rtx x)\n   enum machine_mode mode = GET_MODE (x);\n   rtx op0 = XEXP (x, 0);\n   rtx op1 = XEXP (x, 1);\n-  rtx tmp, reversed;\n \n   switch (GET_CODE (x))\n     {\n     case AND:\n-      /* Convert (A ^ B) & A to A & (~B) since the latter is often a single\n-\t insn (and may simplify more).  */\n-      if (GET_CODE (op0) == XOR\n-\t  && rtx_equal_p (XEXP (op0, 0), op1)\n-\t  && ! side_effects_p (op1))\n-\tx = simplify_gen_binary (AND, mode,\n-\t\t\t\t simplify_gen_unary (NOT, mode,\n-\t\t\t\t\t\t     XEXP (op0, 1), mode),\n-\t\t\t\t op1);\n-\n-      if (GET_CODE (op0) == XOR\n-\t  && rtx_equal_p (XEXP (op0, 1), op1)\n-\t  && ! side_effects_p (op1))\n-\tx = simplify_gen_binary (AND, mode,\n-\t\t\t\t simplify_gen_unary (NOT, mode,\n-\t\t\t\t\t\t     XEXP (op0, 0), mode),\n-\t\t\t\t op1);\n-\n-      /* Similarly for (~(A ^ B)) & A.  */\n-      if (GET_CODE (op0) == NOT\n-\t  && GET_CODE (XEXP (op0, 0)) == XOR\n-\t  && rtx_equal_p (XEXP (XEXP (op0, 0), 0), op1)\n-\t  && ! side_effects_p (op1))\n-\tx = simplify_gen_binary (AND, mode, XEXP (XEXP (op0, 0), 1), op1);\n-\n-      if (GET_CODE (op0) == NOT\n-\t  && GET_CODE (XEXP (op0, 0)) == XOR\n-\t  && rtx_equal_p (XEXP (XEXP (op0, 0), 1), op1)\n-\t  && ! side_effects_p (op1))\n-\tx = simplify_gen_binary (AND, mode, XEXP (XEXP (op0, 0), 0), op1);\n-\n       /* We can call simplify_and_const_int only if we don't lose\n \t any (sign) bits when converting INTVAL (op1) to\n \t \"unsigned HOST_WIDE_INT\".  */\n@@ -5642,37 +5272,13 @@ simplify_logical (rtx x)\n \t      || INTVAL (op1) > 0))\n \t{\n \t  x = simplify_and_const_int (x, mode, op0, INTVAL (op1));\n-\n-\t  /* If we have (ior (and (X C1) C2)) and the next restart would be\n-\t     the last, simplify this by making C1 as small as possible\n-\t     and then exit.  Only do this if C1 actually changes: for now\n-\t     this only saves memory but, should this transformation be\n-\t     moved to simplify-rtx.c, we'd risk unbounded recursion there.  */\n-\t  if (GET_CODE (x) == IOR && GET_CODE (op0) == AND\n-\t      && GET_CODE (XEXP (op0, 1)) == CONST_INT\n-\t      && GET_CODE (op1) == CONST_INT\n-\t      && (INTVAL (XEXP (op0, 1)) & INTVAL (op1)) != 0)\n-\t    return simplify_gen_binary (IOR, mode,\n-\t\t\t\t        simplify_gen_binary\n-\t\t\t\t\t  (AND, mode, XEXP (op0, 0),\n-\t\t\t\t\t   GEN_INT (INTVAL (XEXP (op0, 1))\n-\t\t\t\t\t\t    & ~INTVAL (op1))), op1);\n-\n \t  if (GET_CODE (x) != AND)\n \t    return x;\n \n \t  op0 = XEXP (x, 0);\n \t  op1 = XEXP (x, 1);\n \t}\n \n-      /* Convert (A | B) & A to A.  */\n-      if (GET_CODE (op0) == IOR\n-\t  && (rtx_equal_p (XEXP (op0, 0), op1)\n-\t      || rtx_equal_p (XEXP (op0, 1), op1))\n-\t  && ! side_effects_p (XEXP (op0, 0))\n-\t  && ! side_effects_p (XEXP (op0, 1)))\n-\treturn op1;\n-\n       /* If we have any of (and (ior A B) C) or (and (xor A B) C),\n \t apply the distributive law and then the inverse distributive\n \t law to see if things simplify.  */\n@@ -5691,20 +5297,6 @@ simplify_logical (rtx x)\n       break;\n \n     case IOR:\n-      /* (ior A C) is C if all bits of A that might be nonzero are on in C.  */\n-      if (GET_CODE (op1) == CONST_INT\n-\t  && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n-\t  && (nonzero_bits (op0, mode) & ~INTVAL (op1)) == 0)\n-\treturn op1;\n-\n-      /* Convert (A & B) | A to A.  */\n-      if (GET_CODE (op0) == AND\n-\t  && (rtx_equal_p (XEXP (op0, 0), op1)\n-\t      || rtx_equal_p (XEXP (op0, 1), op1))\n-\t  && ! side_effects_p (XEXP (op0, 0))\n-\t  && ! side_effects_p (XEXP (op0, 1)))\n-\treturn op1;\n-\n       /* If we have (ior (and A B) C), apply the distributive law and then\n \t the inverse distributive law to see if things simplify.  */\n \n@@ -5721,148 +5313,6 @@ simplify_logical (rtx x)\n \t  if (result)\n \t    return result;\n \t}\n-\n-      /* Convert (ior (ashift A CX) (lshiftrt A CY)) where CX+CY equals the\n-\t mode size to (rotate A CX).  */\n-\n-      if (GET_CODE (op1) == ASHIFT\n-\t  || GET_CODE (op1) == SUBREG)\n-\ttmp = op1, op1 = op0, op0 = tmp;\n-\n-      if (GET_CODE (op0) == ASHIFT && GET_CODE (op1) == LSHIFTRT\n-\t  && rtx_equal_p (XEXP (op0, 0), XEXP (op1, 0))\n-\t  && GET_CODE (XEXP (op0, 1)) == CONST_INT\n-\t  && GET_CODE (XEXP (op1, 1)) == CONST_INT\n-\t  && (INTVAL (XEXP (op0, 1)) + INTVAL (XEXP (op1, 1))\n-\t      == GET_MODE_BITSIZE (mode)))\n-\treturn gen_rtx_ROTATE (mode, XEXP (op1, 0), XEXP (op0, 1));\n-\n-      /* Same, but for ashift that has been \"simplified\" to a wider mode\n-\t by simplify_shift_const.  */\n-\n-      if (GET_CODE (op0) == SUBREG\n-\t  && GET_CODE (SUBREG_REG (op0)) == ASHIFT\n-\t  && GET_CODE (op1) == LSHIFTRT\n-\t  && GET_CODE (XEXP (op1, 0)) == SUBREG\n-\t  && GET_MODE (op0) == GET_MODE (XEXP (op1, 0))\n-\t  && SUBREG_BYTE (op0) == SUBREG_BYTE (XEXP (op1, 0))\n-\t  && (GET_MODE_SIZE (GET_MODE (op0))\n-\t      < GET_MODE_SIZE (GET_MODE (SUBREG_REG (op0))))\n-\t  && rtx_equal_p (XEXP (SUBREG_REG (op0), 0),\n-\t\t\t  SUBREG_REG (XEXP (op1, 0)))\n-\t  && GET_CODE (XEXP (SUBREG_REG (op0), 1)) == CONST_INT\n-\t  && GET_CODE (XEXP (op1, 1)) == CONST_INT\n-\t  && (INTVAL (XEXP (SUBREG_REG (op0), 1)) + INTVAL (XEXP (op1, 1))\n-\t      == GET_MODE_BITSIZE (mode)))\n-\treturn gen_rtx_ROTATE (mode, XEXP (op1, 0),\n-\t\t\t       XEXP (SUBREG_REG (op0), 1));\n-\n-      /* If OP0 is (ashiftrt (plus ...) C), it might actually be\n-\t a (sign_extend (plus ...)).  If so, OP1 is a CONST_INT, and the PLUS\n-\t does not affect any of the bits in OP1, it can really be done\n-\t as a PLUS and we can associate.  We do this by seeing if OP1\n-\t can be safely shifted left C bits.  */\n-      if (GET_CODE (op1) == CONST_INT && GET_CODE (op0) == ASHIFTRT\n-\t  && GET_CODE (XEXP (op0, 0)) == PLUS\n-\t  && GET_CODE (XEXP (XEXP (op0, 0), 1)) == CONST_INT\n-\t  && GET_CODE (XEXP (op0, 1)) == CONST_INT\n-\t  && INTVAL (XEXP (op0, 1)) < HOST_BITS_PER_WIDE_INT)\n-\t{\n-\t  int count = INTVAL (XEXP (op0, 1));\n-\t  HOST_WIDE_INT mask = INTVAL (op1) << count;\n-\n-\t  if (mask >> count == INTVAL (op1)\n-\t      && (mask & nonzero_bits (XEXP (op0, 0), mode)) == 0)\n-\t    {\n-\t      SUBST (XEXP (XEXP (op0, 0), 1),\n-\t\t     GEN_INT (INTVAL (XEXP (XEXP (op0, 0), 1)) | mask));\n-\t      return op0;\n-\t    }\n-\t}\n-      break;\n-\n-    case XOR:\n-      /* If we are XORing two things that have no bits in common,\n-\t convert them into an IOR.  This helps to detect rotation encoded\n-\t using those methods and possibly other simplifications.  */\n-\n-      if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n-\t  && (nonzero_bits (op0, mode)\n-\t      & nonzero_bits (op1, mode)) == 0)\n-\treturn (simplify_gen_binary (IOR, mode, op0, op1));\n-\n-      /* Convert (XOR (NOT x) (NOT y)) to (XOR x y).\n-\t Also convert (XOR (NOT x) y) to (NOT (XOR x y)), similarly for\n-\t (NOT y).  */\n-      {\n-\tint num_negated = 0;\n-\n-\tif (GET_CODE (op0) == NOT)\n-\t  num_negated++, op0 = XEXP (op0, 0);\n-\tif (GET_CODE (op1) == NOT)\n-\t  num_negated++, op1 = XEXP (op1, 0);\n-\n-\tif (num_negated == 2)\n-\t  {\n-\t    SUBST (XEXP (x, 0), op0);\n-\t    SUBST (XEXP (x, 1), op1);\n-\t  }\n-\telse if (num_negated == 1)\n-\t  return\n-\t    simplify_gen_unary (NOT, mode,\n-\t\t\t\tsimplify_gen_binary (XOR, mode, op0, op1),\n-\t\t\t\tmode);\n-      }\n-\n-      /* Convert (xor (and A B) B) to (and (not A) B).  The latter may\n-\t correspond to a machine insn or result in further simplifications\n-\t if B is a constant.  */\n-\n-      if (GET_CODE (op0) == AND\n-\t  && rtx_equal_p (XEXP (op0, 1), op1)\n-\t  && ! side_effects_p (op1))\n-\treturn simplify_gen_binary (AND, mode,\n-\t\t\t\t    simplify_gen_unary (NOT, mode,\n-\t\t\t\t\t\t\tXEXP (op0, 0), mode),\n-\t\t\t\t    op1);\n-\n-      else if (GET_CODE (op0) == AND\n-\t       && rtx_equal_p (XEXP (op0, 0), op1)\n-\t       && ! side_effects_p (op1))\n-\treturn simplify_gen_binary (AND, mode,\n-\t\t\t\t    simplify_gen_unary (NOT, mode,\n-\t\t\t\t\t\t\tXEXP (op0, 1), mode),\n-\t\t\t\t    op1);\n-\n-      /* (xor (comparison foo bar) (const_int 1)) can become the reversed\n-\t comparison if STORE_FLAG_VALUE is 1.  */\n-      if (STORE_FLAG_VALUE == 1\n-\t  && op1 == const1_rtx\n-\t  && COMPARISON_P (op0)\n-\t  && (reversed = reversed_comparison (op0, mode)))\n-\treturn reversed;\n-\n-      /* (lshiftrt foo C) where C is the number of bits in FOO minus 1\n-\t is (lt foo (const_int 0)), so we can perform the above\n-\t simplification if STORE_FLAG_VALUE is 1.  */\n-\n-      if (STORE_FLAG_VALUE == 1\n-\t  && op1 == const1_rtx\n-\t  && GET_CODE (op0) == LSHIFTRT\n-\t  && GET_CODE (XEXP (op0, 1)) == CONST_INT\n-\t  && INTVAL (XEXP (op0, 1)) == GET_MODE_BITSIZE (mode) - 1)\n-\treturn gen_rtx_GE (mode, XEXP (op0, 0), const0_rtx);\n-\n-      /* (xor (comparison foo bar) (const_int sign-bit))\n-\t when STORE_FLAG_VALUE is the sign bit.  */\n-      if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n-\t  && ((STORE_FLAG_VALUE & GET_MODE_MASK (mode))\n-\t      == (unsigned HOST_WIDE_INT) 1 << (GET_MODE_BITSIZE (mode) - 1))\n-\t  && op1 == const_true_rtx\n-\t  && COMPARISON_P (op0)\n-\t  && (reversed = reversed_comparison (op0, mode)))\n-\treturn reversed;\n-\n       break;\n \n     default:"}, {"sha": "7e9f771e40b9cefbf54a9806dde35bec40c90e53", "filename": "gcc/simplify-rtx.c", "status": "modified", "additions": 530, "deletions": 12, "changes": 542, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/bd1ef757767f6d9e4b8ba3dfdaf38e89fd282c52/gcc%2Fsimplify-rtx.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/bd1ef757767f6d9e4b8ba3dfdaf38e89fd282c52/gcc%2Fsimplify-rtx.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsimplify-rtx.c?ref=bd1ef757767f6d9e4b8ba3dfdaf38e89fd282c52", "patch": "@@ -399,7 +399,8 @@ simplify_unary_operation_1 (enum rtx_code code, enum machine_mode mode, rtx op)\n       if (GET_CODE (op) == NOT)\n \treturn XEXP (op, 0);\n \n-      /* (not (eq X Y)) == (ne X Y), etc.  */\n+      /* (not (eq X Y)) == (ne X Y), etc. if BImode or the result of the\n+\t comparison is all ones.   */\n       if (COMPARISON_P (op)\n \t  && (mode == BImode || STORE_FLAG_VALUE == -1)\n \t  && ((reversed = reversed_comparison_code (op, NULL_RTX)) != UNKNOWN))\n@@ -443,25 +444,62 @@ simplify_unary_operation_1 (enum rtx_code code, enum machine_mode mode, rtx op)\n \t  return simplify_gen_binary (ROTATE, mode, temp, XEXP (op, 1));\n \t}\n \n-      /* If STORE_FLAG_VALUE is -1, (not (comparison X Y)) can be done\n-\t by reversing the comparison code if valid.  */\n-      if (STORE_FLAG_VALUE == -1\n-\t  && COMPARISON_P (op)\n-\t  && (reversed = reversed_comparison_code (op, NULL_RTX)) != UNKNOWN)\n-\treturn simplify_gen_relational (reversed, mode, VOIDmode,\n-\t\t\t\t\tXEXP (op, 0), XEXP (op, 1));\n-\n       /* (not (ashiftrt foo C)) where C is the number of bits in FOO\n \t minus 1 is (ge foo (const_int 0)) if STORE_FLAG_VALUE is -1,\n \t so we can perform the above simplification.  */\n-      \n+ \n       if (STORE_FLAG_VALUE == -1\n \t  && GET_CODE (op) == ASHIFTRT\n \t  && GET_CODE (XEXP (op, 1)) == CONST_INT\n \t  && INTVAL (XEXP (op, 1)) == GET_MODE_BITSIZE (mode) - 1)\n \treturn simplify_gen_relational (GE, mode, VOIDmode,\n \t\t\t\t\tXEXP (op, 0), const0_rtx);\n \n+\n+      if (GET_CODE (op) == SUBREG\n+\t  && subreg_lowpart_p (op)\n+\t  && (GET_MODE_SIZE (GET_MODE (op))\n+\t      < GET_MODE_SIZE (GET_MODE (SUBREG_REG (op))))\n+\t  && GET_CODE (SUBREG_REG (op)) == ASHIFT\n+\t  && XEXP (SUBREG_REG (op), 0) == const1_rtx)\n+\t{\n+\t  enum machine_mode inner_mode = GET_MODE (SUBREG_REG (op));\n+\t  rtx x;\n+\n+\t  x = gen_rtx_ROTATE (inner_mode,\n+\t\t\t      simplify_gen_unary (NOT, inner_mode, const1_rtx,\n+\t\t\t\t\t\t  inner_mode),\n+\t\t\t      XEXP (SUBREG_REG (op), 1));\n+\t  return rtl_hooks.gen_lowpart_no_emit (mode, x);\n+\t}\n+\n+      /* Apply De Morgan's laws to reduce number of patterns for machines\n+\t with negating logical insns (and-not, nand, etc.).  If result has\n+\t only one NOT, put it first, since that is how the patterns are\n+\t coded.  */\n+\n+      if (GET_CODE (op) == IOR || GET_CODE (op) == AND)\n+\t{\n+\t  rtx in1 = XEXP (op, 0), in2 = XEXP (op, 1);\n+\t  enum machine_mode op_mode;\n+\n+\t  op_mode = GET_MODE (in1);\n+\t  in1 = simplify_gen_unary (NOT, op_mode, in1, op_mode);\n+\n+\t  op_mode = GET_MODE (in2);\n+\t  if (op_mode == VOIDmode)\n+\t    op_mode = mode;\n+\t  in2 = simplify_gen_unary (NOT, op_mode, in2, op_mode);\n+\n+\t  if (GET_CODE (in2) == NOT && GET_CODE (in1) != NOT)\n+\t    {\n+\t      rtx tem = in2;\n+\t      in2 = in1; in1 = tem;\n+\t    }\n+\n+\t  return gen_rtx_fmt_ee (GET_CODE (op) == IOR ? AND : IOR,\n+\t\t\t\t mode, in1, in2);\n+\t}\n       break;\n \n     case NEG:\n@@ -541,6 +579,185 @@ simplify_unary_operation_1 (enum rtx_code code, enum machine_mode mode, rtx op)\n \treturn simplify_gen_binary (ASHIFTRT, mode,\n \t\t\t\t    XEXP (op, 0), XEXP (op, 1));\n       \n+      /* (neg (xor A 1)) is (plus A -1) if A is known to be either 0 or 1.  */\n+      if (GET_CODE (op) == XOR\n+\t  && XEXP (op, 1) == const1_rtx\n+\t  && nonzero_bits (XEXP (op, 0), mode) == 1)\n+\treturn plus_constant (XEXP (op, 0), -1);\n+      break;\n+\n+    case TRUNCATE:\n+      /* We can't handle truncation to a partial integer mode here\n+         because we don't know the real bitsize of the partial\n+         integer mode.  */\n+      if (GET_MODE_CLASS (mode) == MODE_PARTIAL_INT)\n+        break;\n+\n+      /* (truncate:SI ({sign,zero}_extend:DI foo:SI)) == foo:SI.  */\n+      if ((GET_CODE (op) == SIGN_EXTEND\n+\t   || GET_CODE (op) == ZERO_EXTEND)\n+\t  && GET_MODE (XEXP (op, 0)) == mode)\n+\treturn XEXP (op, 0);\n+\n+      /* (truncate:SI (OP:DI ({sign,zero}_extend:DI foo:SI))) is\n+\t (OP:SI foo:SI) if OP is NEG or ABS.  */\n+      if ((GET_CODE (op) == ABS\n+\t   || GET_CODE (op) == NEG)\n+\t  && (GET_CODE (XEXP (op, 0)) == SIGN_EXTEND\n+\t      || GET_CODE (XEXP (op, 0)) == ZERO_EXTEND)\n+\t  && GET_MODE (XEXP (XEXP (op, 0), 0)) == mode)\n+\treturn simplify_gen_unary (GET_CODE (op), mode,\n+\t\t\t\t   XEXP (XEXP (op, 0), 0), mode);\n+\n+      /* (truncate:SI (subreg:DI (truncate:SI X) 0)) is\n+\t (truncate:SI x).  */\n+      if (GET_CODE (op) == SUBREG\n+\t  && GET_CODE (SUBREG_REG (op)) == TRUNCATE\n+\t  && subreg_lowpart_p (op))\n+\treturn SUBREG_REG (op);\n+\n+      /* If we know that the value is already truncated, we can\n+         replace the TRUNCATE with a SUBREG if TRULY_NOOP_TRUNCATION\n+         is nonzero for the corresponding modes.  But don't do this\n+         for an (LSHIFTRT (MULT ...)) since this will cause problems\n+         with the umulXi3_highpart patterns.  */\n+      if (TRULY_NOOP_TRUNCATION (GET_MODE_BITSIZE (mode),\n+\t\t\t\t GET_MODE_BITSIZE (GET_MODE (op)))\n+\t  && num_sign_bit_copies (op, GET_MODE (op))\n+\t     >= (unsigned int) (GET_MODE_BITSIZE (mode) + 1)\n+\t  && ! (GET_CODE (op) == LSHIFTRT\n+\t\t&& GET_CODE (XEXP (op, 0)) == MULT))\n+\treturn rtl_hooks.gen_lowpart_no_emit (mode, op);\n+\n+      /* A truncate of a comparison can be replaced with a subreg if\n+         STORE_FLAG_VALUE permits.  This is like the previous test,\n+         but it works even if the comparison is done in a mode larger\n+         than HOST_BITS_PER_WIDE_INT.  */\n+      if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t  && COMPARISON_P (op)\n+\t  && ((HOST_WIDE_INT) STORE_FLAG_VALUE & ~GET_MODE_MASK (mode)) == 0)\n+\treturn rtl_hooks.gen_lowpart_no_emit (mode, op);\n+      break;\n+\n+    case FLOAT_TRUNCATE:\n+      /* (float_truncate:SF (float_extend:DF foo:SF)) = foo:SF.  */\n+      if (GET_CODE (op) == FLOAT_EXTEND\n+\t  && GET_MODE (XEXP (op, 0)) == mode)\n+\treturn XEXP (op, 0);\n+\n+      /* (float_truncate:SF (float_truncate:DF foo:XF))\n+         = (float_truncate:SF foo:XF).\n+\t This may eliminate double rounding, so it is unsafe.\n+\n+         (float_truncate:SF (float_extend:XF foo:DF))\n+         = (float_truncate:SF foo:DF).\n+\n+         (float_truncate:DF (float_extend:XF foo:SF))\n+         = (float_extend:SF foo:DF).  */\n+      if ((GET_CODE (op) == FLOAT_TRUNCATE\n+\t   && flag_unsafe_math_optimizations)\n+\t  || GET_CODE (op) == FLOAT_EXTEND)\n+\treturn simplify_gen_unary (GET_MODE_SIZE (GET_MODE (XEXP (op,\n+\t\t\t\t\t\t\t    0)))\n+\t\t\t\t   > GET_MODE_SIZE (mode)\n+\t\t\t\t   ? FLOAT_TRUNCATE : FLOAT_EXTEND,\n+\t\t\t\t   mode,\n+\t\t\t\t   XEXP (op, 0), mode);\n+\n+      /*  (float_truncate (float x)) is (float x)  */\n+      if (GET_CODE (op) == FLOAT\n+\t  && (flag_unsafe_math_optimizations\n+\t      || ((unsigned)significand_size (GET_MODE (op))\n+\t\t  >= (GET_MODE_BITSIZE (GET_MODE (XEXP (op, 0)))\n+\t\t      - num_sign_bit_copies (XEXP (op, 0),\n+\t\t\t\t\t     GET_MODE (XEXP (op, 0)))))))\n+\treturn simplify_gen_unary (FLOAT, mode,\n+\t\t\t\t   XEXP (op, 0),\n+\t\t\t\t   GET_MODE (XEXP (op, 0)));\n+\n+      /* (float_truncate:SF (OP:DF (float_extend:DF foo:sf))) is\n+\t (OP:SF foo:SF) if OP is NEG or ABS.  */\n+      if ((GET_CODE (op) == ABS\n+\t   || GET_CODE (op) == NEG)\n+\t  && GET_CODE (XEXP (op, 0)) == FLOAT_EXTEND\n+\t  && GET_MODE (XEXP (XEXP (op, 0), 0)) == mode)\n+\treturn simplify_gen_unary (GET_CODE (op), mode,\n+\t\t\t\t   XEXP (XEXP (op, 0), 0), mode);\n+\n+      /* (float_truncate:SF (subreg:DF (float_truncate:SF X) 0))\n+\t is (float_truncate:SF x).  */\n+      if (GET_CODE (op) == SUBREG\n+\t  && subreg_lowpart_p (op)\n+\t  && GET_CODE (SUBREG_REG (op)) == FLOAT_TRUNCATE)\n+\treturn SUBREG_REG (op);\n+      break;\n+\n+    case FLOAT_EXTEND:\n+      /*  (float_extend (float_extend x)) is (float_extend x)\n+\n+\t  (float_extend (float x)) is (float x) assuming that double\n+\t  rounding can't happen.\n+          */\n+      if (GET_CODE (op) == FLOAT_EXTEND\n+\t  || (GET_CODE (op) == FLOAT\n+\t      && ((unsigned)significand_size (GET_MODE (op))\n+\t\t  >= (GET_MODE_BITSIZE (GET_MODE (XEXP (op, 0)))\n+\t\t      - num_sign_bit_copies (XEXP (op, 0),\n+\t\t\t\t\t     GET_MODE (XEXP (op, 0)))))))\n+\treturn simplify_gen_unary (GET_CODE (op), mode,\n+\t\t\t\t   XEXP (op, 0),\n+\t\t\t\t   GET_MODE (XEXP (op, 0)));\n+\n+      break;\n+\n+    case ABS:\n+      /* (abs (neg <foo>)) -> (abs <foo>) */\n+      if (GET_CODE (op) == NEG)\n+\treturn simplify_gen_unary (ABS, mode, XEXP (op, 0),\n+\t\t\t\t   GET_MODE (XEXP (op, 0)));\n+\n+      /* If the mode of the operand is VOIDmode (i.e. if it is ASM_OPERANDS),\n+         do nothing.  */\n+      if (GET_MODE (op) == VOIDmode)\n+\tbreak;\n+\n+      /* If operand is something known to be positive, ignore the ABS.  */\n+      if (GET_CODE (op) == FFS || GET_CODE (op) == ABS\n+\t  || ((GET_MODE_BITSIZE (GET_MODE (op))\n+\t       <= HOST_BITS_PER_WIDE_INT)\n+\t      && ((nonzero_bits (op, GET_MODE (op))\n+\t\t   & ((HOST_WIDE_INT) 1\n+\t\t      << (GET_MODE_BITSIZE (GET_MODE (op)) - 1)))\n+\t\t  == 0)))\n+\treturn op;\n+\n+      /* If operand is known to be only -1 or 0, convert ABS to NEG.  */\n+      if (num_sign_bit_copies (op, mode) == GET_MODE_BITSIZE (mode))\n+\treturn gen_rtx_NEG (mode, op);\n+\n+      break;\n+\n+    case FFS:\n+      /* (ffs (*_extend <X>)) = (ffs <X>) */\n+      if (GET_CODE (op) == SIGN_EXTEND\n+\t  || GET_CODE (op) == ZERO_EXTEND)\n+\treturn simplify_gen_unary (FFS, mode, XEXP (op, 0),\n+\t\t\t\t   GET_MODE (XEXP (op, 0)));\n+      break;\n+\n+    case POPCOUNT:\n+    case PARITY:\n+      /* (pop* (zero_extend <X>)) = (pop* <X>) */\n+      if (GET_CODE (op) == ZERO_EXTEND)\n+\treturn simplify_gen_unary (code, mode, XEXP (op, 0),\n+\t\t\t\t   GET_MODE (XEXP (op, 0)));\n+      break;\n+\n+    case FLOAT:\n+      /* (float (sign_extend <X>)) = (float <X>).  */\n+      if (GET_CODE (op) == SIGN_EXTEND)\n+\treturn simplify_gen_unary (FLOAT, mode, XEXP (op, 0),\n+\t\t\t\t   GET_MODE (XEXP (op, 0)));\n       break;\n \n     case SIGN_EXTEND:\n@@ -1218,7 +1435,7 @@ static rtx\n simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n \t\t\t     rtx op0, rtx op1, rtx trueop0, rtx trueop1)\n {\n-  rtx tem;\n+  rtx tem, reversed, opleft, opright;\n   HOST_WIDE_INT val;\n   unsigned int width = GET_MODE_BITSIZE (mode);\n \n@@ -1346,6 +1563,29 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n \t\t\t\t    simplify_gen_binary (XOR, mode, op1,\n \t\t\t\t\t\t\t XEXP (op0, 1)));\n \n+      /* Canonicalize (plus (mult (neg B) C) A) to (minus A (mult B C)).  */\n+      if (GET_CODE (op0) == MULT\n+\t  && GET_CODE (XEXP (op0, 0)) == NEG)\n+\t{\n+\t  rtx in1, in2;\n+\n+\t  in1 = XEXP (XEXP (op0, 0), 0);\n+\t  in2 = XEXP (op0, 1);\n+\t  return simplify_gen_binary (MINUS, mode, op1,\n+\t\t\t\t      simplify_gen_binary (MULT, mode,\n+\t\t\t\t\t\t\t   in1, in2));\n+\t}\n+\n+      /* (plus (comparison A B) C) can become (neg (rev-comp A B)) if\n+\t C is 1 and STORE_FLAG_VALUE is -1 or if C is -1 and STORE_FLAG_VALUE\n+\t is 1.  */\n+      if (COMPARISON_P (op0)\n+\t  && ((STORE_FLAG_VALUE == -1 && trueop1 == const1_rtx)\n+\t      || (STORE_FLAG_VALUE == 1 && trueop1 == constm1_rtx))\n+\t  && (reversed = reversed_comparison (op0, mode)))\n+\treturn\n+\t  simplify_gen_unary (NEG, mode, reversed, mode);\n+\n       /* If one of the operands is a PLUS or a MINUS, see if we can\n \t simplify this by the associative law.\n \t Don't use the associative law for floating point.\n@@ -1543,6 +1783,43 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n \t    }\n \t}\n \n+      /* If STORE_FLAG_VALUE is 1, (minus 1 (comparison foo bar)) can be done\n+\t by reversing the comparison code if valid.  */\n+      if (STORE_FLAG_VALUE == 1\n+\t  && trueop0 == const1_rtx\n+\t  && COMPARISON_P (op1)\n+\t  && (reversed = reversed_comparison (op1, mode)))\n+\treturn reversed;\n+\n+      /* Canonicalize (minus A (mult (neg B) C)) to (plus (mult B C) A).  */\n+      if (GET_CODE (op1) == MULT\n+\t  && GET_CODE (XEXP (op1, 0)) == NEG)\n+\t{\n+\t  rtx in1, in2;\n+\n+\t  in1 = XEXP (XEXP (op1, 0), 0);\n+\t  in2 = XEXP (op1, 1);\n+\t  return simplify_gen_binary (PLUS, mode,\n+\t\t\t\t      simplify_gen_binary (MULT, mode,\n+\t\t\t\t\t\t\t   in1, in2),\n+\t\t\t\t      op0);\n+\t}\n+\n+      /* Canonicalize (minus (neg A) (mult B C)) to\n+\t (minus (mult (neg B) C) A).  */\n+      if (GET_CODE (op1) == MULT\n+\t  && GET_CODE (op0) == NEG)\n+\t{\n+\t  rtx in1, in2;\n+\n+\t  in1 = simplify_gen_unary (NEG, mode, XEXP (op1, 0), mode);\n+\t  in2 = XEXP (op1, 1);\n+\t  return simplify_gen_binary (MINUS, mode,\n+\t\t\t\t      simplify_gen_binary (MULT, mode,\n+\t\t\t\t\t\t\t   in1, in2),\n+\t\t\t\t      XEXP (op0, 0));\n+\t}\n+\n       /* If one of the operands is a PLUS or a MINUS, see if we can\n \t simplify this by the associative law.  This will, for example,\n          canonicalize (minus A (plus B C)) to (minus (minus A B) C).\n@@ -1639,6 +1916,101 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n \t  && ! side_effects_p (op0)\n \t  && SCALAR_INT_MODE_P (mode))\n \treturn constm1_rtx;\n+\n+      /* (ior A C) is C if all bits of A that might be nonzero are on in C.  */\n+      if (GET_CODE (op1) == CONST_INT\n+\t  && GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t  && (nonzero_bits (op0, mode) & ~INTVAL (op1)) == 0)\n+\treturn op1;\n+ \n+      /* Convert (A & B) | A to A.  */\n+      if (GET_CODE (op0) == AND\n+\t  && (rtx_equal_p (XEXP (op0, 0), op1)\n+\t      || rtx_equal_p (XEXP (op0, 1), op1))\n+\t  && ! side_effects_p (XEXP (op0, 0))\n+\t  && ! side_effects_p (XEXP (op0, 1)))\n+\treturn op1;\n+\n+      /* Convert (ior (ashift A CX) (lshiftrt A CY)) where CX+CY equals the\n+         mode size to (rotate A CX).  */\n+\n+      if (GET_CODE (op1) == ASHIFT\n+          || GET_CODE (op1) == SUBREG)\n+        {\n+\t  opleft = op1;\n+\t  opright = op0;\n+\t}\n+      else\n+        {\n+\t  opright = op1;\n+\t  opleft = op0;\n+\t}\n+\n+      if (GET_CODE (opleft) == ASHIFT && GET_CODE (opright) == LSHIFTRT\n+          && rtx_equal_p (XEXP (opleft, 0), XEXP (opright, 0))\n+          && GET_CODE (XEXP (opleft, 1)) == CONST_INT\n+          && GET_CODE (XEXP (opright, 1)) == CONST_INT\n+          && (INTVAL (XEXP (opleft, 1)) + INTVAL (XEXP (opright, 1))\n+              == GET_MODE_BITSIZE (mode)))\n+        return gen_rtx_ROTATE (mode, XEXP (opright, 0), XEXP (opleft, 1));\n+\n+      /* Same, but for ashift that has been \"simplified\" to a wider mode\n+        by simplify_shift_const.  */\n+\n+      if (GET_CODE (opleft) == SUBREG\n+          && GET_CODE (SUBREG_REG (opleft)) == ASHIFT\n+          && GET_CODE (opright) == LSHIFTRT\n+          && GET_CODE (XEXP (opright, 0)) == SUBREG\n+          && GET_MODE (opleft) == GET_MODE (XEXP (opright, 0))\n+          && SUBREG_BYTE (opleft) == SUBREG_BYTE (XEXP (opright, 0))\n+          && (GET_MODE_SIZE (GET_MODE (opleft))\n+              < GET_MODE_SIZE (GET_MODE (SUBREG_REG (opleft))))\n+          && rtx_equal_p (XEXP (SUBREG_REG (opleft), 0),\n+                          SUBREG_REG (XEXP (opright, 0)))\n+          && GET_CODE (XEXP (SUBREG_REG (opleft), 1)) == CONST_INT\n+          && GET_CODE (XEXP (opright, 1)) == CONST_INT\n+          && (INTVAL (XEXP (SUBREG_REG (opleft), 1)) + INTVAL (XEXP (opright, 1))\n+              == GET_MODE_BITSIZE (mode)))\n+        return gen_rtx_ROTATE (mode, XEXP (opright, 0),\n+                               XEXP (SUBREG_REG (opright), 1));\n+\n+      /* If we have (ior (and (X C1) C2)), simplify this by making\n+\t C1 as small as possible if C1 actually changes.  */\n+      if (GET_CODE (op1) == CONST_INT\n+\t  && (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t      || INTVAL (op1) > 0)\n+\t  && GET_CODE (op0) == AND\n+\t  && GET_CODE (XEXP (op0, 1)) == CONST_INT\n+\t  && GET_CODE (op1) == CONST_INT\n+\t  && (INTVAL (XEXP (op0, 1)) & INTVAL (op1)) != 0)\n+\treturn simplify_gen_binary (IOR, mode,\n+\t\t\t\t    simplify_gen_binary\n+\t\t\t\t\t  (AND, mode, XEXP (op0, 0),\n+\t\t\t\t\t   GEN_INT (INTVAL (XEXP (op0, 1))\n+\t\t\t\t\t\t    & ~INTVAL (op1))),\n+\t\t\t\t    op1);\n+\n+      /* If OP0 is (ashiftrt (plus ...) C), it might actually be\n+         a (sign_extend (plus ...)).  Then check if OP1 is a CONST_INT and\n+\t the PLUS does not affect any of the bits in OP1: then we can do\n+\t the IOR as a PLUS and we can associate.  This is valid if OP1\n+         can be safely shifted left C bits.  */\n+      if (GET_CODE (trueop1) == CONST_INT && GET_CODE (op0) == ASHIFTRT\n+          && GET_CODE (XEXP (op0, 0)) == PLUS\n+          && GET_CODE (XEXP (XEXP (op0, 0), 1)) == CONST_INT\n+          && GET_CODE (XEXP (op0, 1)) == CONST_INT\n+          && INTVAL (XEXP (op0, 1)) < HOST_BITS_PER_WIDE_INT)\n+        {\n+          int count = INTVAL (XEXP (op0, 1));\n+          HOST_WIDE_INT mask = INTVAL (trueop1) << count;\n+\n+          if (mask >> count == INTVAL (trueop1)\n+              && (mask & nonzero_bits (XEXP (op0, 0), mode)) == 0)\n+\t    return simplify_gen_binary (ASHIFTRT, mode,\n+\t\t\t\t\tplus_constant (XEXP (op0, 0), mask),\n+\t\t\t\t\tXEXP (op0, 1));\n+        }\n+\n       tem = simplify_associative_operation (code, mode, op0, op1);\n       if (tem)\n \treturn tem;\n@@ -1671,7 +2043,86 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n \treturn simplify_gen_binary (XOR, mode, XEXP (op0, 0),\n \t\t\t\t    simplify_gen_binary (XOR, mode, op1,\n \t\t\t\t\t\t\t XEXP (op0, 1)));\n-\t      \n+\n+      /* If we are XORing two things that have no bits in common,\n+\t convert them into an IOR.  This helps to detect rotation encoded\n+\t using those methods and possibly other simplifications.  */\n+\n+      if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t  && (nonzero_bits (op0, mode)\n+\t      & nonzero_bits (op1, mode)) == 0)\n+\treturn (simplify_gen_binary (IOR, mode, op0, op1));\n+\n+      /* Convert (XOR (NOT x) (NOT y)) to (XOR x y).\n+\t Also convert (XOR (NOT x) y) to (NOT (XOR x y)), similarly for\n+\t (NOT y).  */\n+      {\n+\tint num_negated = 0;\n+\n+\tif (GET_CODE (op0) == NOT)\n+\t  num_negated++, op0 = XEXP (op0, 0);\n+\tif (GET_CODE (op1) == NOT)\n+\t  num_negated++, op1 = XEXP (op1, 0);\n+\n+\tif (num_negated == 2)\n+\t  return simplify_gen_binary (XOR, mode, op0, op1);\n+\telse if (num_negated == 1)\n+\t  return simplify_gen_unary (NOT, mode,\n+\t\t\t\t     simplify_gen_binary (XOR, mode, op0, op1),\n+\t\t\t\t     mode);\n+      }\n+\n+      /* Convert (xor (and A B) B) to (and (not A) B).  The latter may\n+\t correspond to a machine insn or result in further simplifications\n+\t if B is a constant.  */\n+\n+      if (GET_CODE (op0) == AND\n+\t  && rtx_equal_p (XEXP (op0, 1), op1)\n+\t  && ! side_effects_p (op1))\n+\treturn simplify_gen_binary (AND, mode,\n+\t\t\t\t    simplify_gen_unary (NOT, mode,\n+\t\t\t\t\t\t\tXEXP (op0, 0), mode),\n+\t\t\t\t    op1);\n+\n+      else if (GET_CODE (op0) == AND\n+\t       && rtx_equal_p (XEXP (op0, 0), op1)\n+\t       && ! side_effects_p (op1))\n+\treturn simplify_gen_binary (AND, mode,\n+\t\t\t\t    simplify_gen_unary (NOT, mode,\n+\t\t\t\t\t\t\tXEXP (op0, 1), mode),\n+\t\t\t\t    op1);\n+\n+      /* (xor (comparison foo bar) (const_int 1)) can become the reversed\n+\t comparison if STORE_FLAG_VALUE is 1.  */\n+      if (STORE_FLAG_VALUE == 1\n+\t  && trueop1 == const1_rtx\n+\t  && COMPARISON_P (op0)\n+\t  && (reversed = reversed_comparison (op0, mode)))\n+\treturn reversed;\n+\n+      /* (lshiftrt foo C) where C is the number of bits in FOO minus 1\n+\t is (lt foo (const_int 0)), so we can perform the above\n+\t simplification if STORE_FLAG_VALUE is 1.  */\n+\n+      if (STORE_FLAG_VALUE == 1\n+\t  && trueop1 == const1_rtx\n+\t  && GET_CODE (op0) == LSHIFTRT\n+\t  && GET_CODE (XEXP (op0, 1)) == CONST_INT\n+\t  && INTVAL (XEXP (op0, 1)) == GET_MODE_BITSIZE (mode) - 1)\n+\treturn gen_rtx_GE (mode, XEXP (op0, 0), const0_rtx);\n+\n+      /* (xor (comparison foo bar) (const_int sign-bit))\n+\t when STORE_FLAG_VALUE is the sign bit.  */\n+      if (GET_MODE_BITSIZE (mode) <= HOST_BITS_PER_WIDE_INT\n+\t  && ((STORE_FLAG_VALUE & GET_MODE_MASK (mode))\n+\t      == (unsigned HOST_WIDE_INT) 1 << (GET_MODE_BITSIZE (mode) - 1))\n+\t  && trueop1 == const_true_rtx\n+\t  && COMPARISON_P (op0)\n+\t  && (reversed = reversed_comparison (op0, mode)))\n+\treturn reversed;\n+\n+      break;\n+      \n       tem = simplify_associative_operation (code, mode, op0, op1);\n       if (tem)\n \treturn tem;\n@@ -1712,6 +2163,45 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n \t  return simplify_gen_unary (ZERO_EXTEND, mode, tem, imode);\n \t}\n \n+      /* Convert (A ^ B) & A to A & (~B) since the latter is often a single\n+\t insn (and may simplify more).  */\n+      if (GET_CODE (op0) == XOR\n+\t  && rtx_equal_p (XEXP (op0, 0), op1)\n+\t  && ! side_effects_p (op1))\n+\treturn simplify_gen_binary (AND, mode,\n+\t\t\t\t    simplify_gen_unary (NOT, mode,\n+\t\t\t\t\t\t\tXEXP (op0, 1), mode),\n+\t\t\t\t    op1);\n+\n+      if (GET_CODE (op0) == XOR\n+\t  && rtx_equal_p (XEXP (op0, 1), op1)\n+\t  && ! side_effects_p (op1))\n+\treturn simplify_gen_binary (AND, mode,\n+\t\t\t\t    simplify_gen_unary (NOT, mode,\n+\t\t\t\t\t\t\tXEXP (op0, 0), mode),\n+\t\t\t\t    op1);\n+\n+      /* Similarly for (~(A ^ B)) & A.  */\n+      if (GET_CODE (op0) == NOT\n+\t  && GET_CODE (XEXP (op0, 0)) == XOR\n+\t  && rtx_equal_p (XEXP (XEXP (op0, 0), 0), op1)\n+\t  && ! side_effects_p (op1))\n+\treturn simplify_gen_binary (AND, mode, XEXP (XEXP (op0, 0), 1), op1);\n+\n+      if (GET_CODE (op0) == NOT\n+\t  && GET_CODE (XEXP (op0, 0)) == XOR\n+\t  && rtx_equal_p (XEXP (XEXP (op0, 0), 1), op1)\n+\t  && ! side_effects_p (op1))\n+\treturn simplify_gen_binary (AND, mode, XEXP (XEXP (op0, 0), 0), op1);\n+\n+      /* Convert (A | B) & A to A.  */\n+      if (GET_CODE (op0) == IOR\n+\t  && (rtx_equal_p (XEXP (op0, 0), op1)\n+\t      || rtx_equal_p (XEXP (op0, 1), op1))\n+\t  && ! side_effects_p (XEXP (op0, 0))\n+\t  && ! side_effects_p (XEXP (op0, 1)))\n+\treturn op1;\n+\n       /* For constants M and N, if M == (1LL << cst) - 1 && (N & M) == M,\n \t ((A & N) + B) & M -> (A + B) & M\n \t Similarly if (N & M) == 0,\n@@ -1993,6 +2483,33 @@ simplify_binary_operation_1 (enum rtx_code code, enum machine_mode mode,\n \t      return gen_rtx_CONST_VECTOR (mode, v);\n \t    }\n \t}\n+\n+      if (XVECLEN (trueop1, 0) == 1\n+\t  && GET_CODE (XVECEXP (trueop1, 0, 0)) == CONST_INT\n+\t  && GET_CODE (trueop0) == VEC_CONCAT)\n+\t{\n+\t  rtx vec = trueop0;\n+\t  int offset = INTVAL (XVECEXP (trueop1, 0, 0)) * GET_MODE_SIZE (mode);\n+\n+\t  /* Try to find the element in the VEC_CONCAT.  */\n+\t  while (GET_MODE (vec) != mode\n+\t\t && GET_CODE (vec) == VEC_CONCAT)\n+\t    {\n+\t      HOST_WIDE_INT vec_size = GET_MODE_SIZE (GET_MODE (XEXP (vec, 0)));\n+\t      if (offset < vec_size)\n+\t\tvec = XEXP (vec, 0);\n+\t      else\n+\t\t{\n+\t\t  offset -= vec_size;\n+\t\t  vec = XEXP (vec, 1);\n+\t\t}\n+\t      vec = avoid_constant_pool_reference (vec);\n+\t    }\n+\n+\t  if (GET_MODE (vec) == mode)\n+\t    return vec;\n+\t}\n+\n       return 0;\n     case VEC_CONCAT:\n       {\n@@ -4192,3 +4709,4 @@ simplify_rtx (rtx x)\n     }\n   return NULL;\n }\n+"}]}