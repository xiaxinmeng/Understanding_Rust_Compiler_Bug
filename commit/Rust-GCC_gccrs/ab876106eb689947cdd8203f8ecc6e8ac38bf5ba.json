{"sha": "ab876106eb689947cdd8203f8ecc6e8ac38bf5ba", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YWI4NzYxMDZlYjY4OTk0N2NkZDgyMDNmOGVjYzZlOGFjMzhiZjViYQ==", "commit": {"author": {"name": "Matthew Wahab", "email": "matthew.wahab@arm.com", "date": "2015-06-01T15:21:02Z"}, "committer": {"name": "Matthew Wahab", "email": "mwahab@gcc.gnu.org", "date": "2015-06-01T15:21:02Z"}, "message": "re PR target/65697 (__atomic memory barriers not strong enough for __sync builtins)\n\n\tPR target/65697\n\t* config/aarch64/aarch64.c (aarch64_split_compare_and_swap): Check\n\tfor __sync memory models, emit initial loads and final barriers as\n\tappropriate.\n\nFrom-SVN: r223984", "tree": {"sha": "f5bad7721528b5d821e13a00eb571dace099e0b0", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/f5bad7721528b5d821e13a00eb571dace099e0b0"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/ab876106eb689947cdd8203f8ecc6e8ac38bf5ba", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ab876106eb689947cdd8203f8ecc6e8ac38bf5ba", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ab876106eb689947cdd8203f8ecc6e8ac38bf5ba", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ab876106eb689947cdd8203f8ecc6e8ac38bf5ba/comments", "author": null, "committer": null, "parents": [{"sha": "f70fb3b635f9618c6d2ee3848ba836914f7951c2", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/f70fb3b635f9618c6d2ee3848ba836914f7951c2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/f70fb3b635f9618c6d2ee3848ba836914f7951c2"}], "stats": {"total": 25, "additions": 23, "deletions": 2}, "files": [{"sha": "b0c172c6f15eca2cb3d839ab0b37a28f70112807", "filename": "gcc/ChangeLog", "status": "modified", "additions": 7, "deletions": 0, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ab876106eb689947cdd8203f8ecc6e8ac38bf5ba/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ab876106eb689947cdd8203f8ecc6e8ac38bf5ba/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=ab876106eb689947cdd8203f8ecc6e8ac38bf5ba", "patch": "@@ -1,3 +1,10 @@\n+2015-06-01  Matthew Wahab  <matthew.wahab@arm.com>\n+\n+\tPR target/65697\n+\t* config/aarch64/aarch64.c (aarch64_split_compare_and_swap): Check\n+\tfor __sync memory models, emit initial loads and final barriers as\n+\tappropriate.\n+\n 2015-06-01  Matthew Wahab  <matthew.wahab@arm.com>\n \n         PR target/65697"}, {"sha": "62c8c8fe47ab94ebaa58bcb6de29c6da7cb01975", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 16, "deletions": 2, "changes": 18, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/ab876106eb689947cdd8203f8ecc6e8ac38bf5ba/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/ab876106eb689947cdd8203f8ecc6e8ac38bf5ba/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=ab876106eb689947cdd8203f8ecc6e8ac38bf5ba", "patch": "@@ -9436,14 +9436,18 @@ aarch64_split_compare_and_swap (rtx operands[])\n   bool is_weak;\n   rtx_code_label *label1, *label2;\n   rtx x, cond;\n+  enum memmodel model;\n+  rtx model_rtx;\n \n   rval = operands[0];\n   mem = operands[1];\n   oldval = operands[2];\n   newval = operands[3];\n   is_weak = (operands[4] != const0_rtx);\n+  model_rtx = operands[5];\n   scratch = operands[7];\n   mode = GET_MODE (mem);\n+  model = memmodel_from_int (INTVAL (model_rtx));\n \n   label1 = NULL;\n   if (!is_weak)\n@@ -9453,15 +9457,21 @@ aarch64_split_compare_and_swap (rtx operands[])\n     }\n   label2 = gen_label_rtx ();\n \n-  aarch64_emit_load_exclusive (mode, rval, mem, operands[5]);\n+  /* The initial load can be relaxed for a __sync operation since a final\n+     barrier will be emitted to stop code hoisting.  */\n+  if (is_mm_sync (model))\n+    aarch64_emit_load_exclusive (mode, rval, mem,\n+\t\t\t\t GEN_INT (MEMMODEL_RELAXED));\n+  else\n+    aarch64_emit_load_exclusive (mode, rval, mem, model_rtx);\n \n   cond = aarch64_gen_compare_reg (NE, rval, oldval);\n   x = gen_rtx_NE (VOIDmode, cond, const0_rtx);\n   x = gen_rtx_IF_THEN_ELSE (VOIDmode, x,\n \t\t\t    gen_rtx_LABEL_REF (Pmode, label2), pc_rtx);\n   aarch64_emit_unlikely_jump (gen_rtx_SET (pc_rtx, x));\n \n-  aarch64_emit_store_exclusive (mode, scratch, mem, newval, operands[5]);\n+  aarch64_emit_store_exclusive (mode, scratch, mem, newval, model_rtx);\n \n   if (!is_weak)\n     {\n@@ -9478,6 +9488,10 @@ aarch64_split_compare_and_swap (rtx operands[])\n     }\n \n   emit_label (label2);\n+\n+  /* Emit any final barrier needed for a __sync operation.  */\n+  if (is_mm_sync (model))\n+    aarch64_emit_post_barrier (model);\n }\n \n /* Split an atomic operation.  */"}]}