{"sha": "1e09922c5f98eada179244ba266dd971c416b1d1", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MWUwOTkyMmM1Zjk4ZWFkYTE3OTI0NGJhMjY2ZGQ5NzFjNDE2YjFkMQ==", "commit": {"author": {"name": "Alex Velenko", "email": "Alex.Velenko@arm.com", "date": "2013-11-22T15:39:45Z"}, "committer": {"name": "James Greenhalgh", "email": "jgreenhalgh@gcc.gnu.org", "date": "2013-11-22T15:39:45Z"}, "message": "[AArch64] vmov_n changes\n\ngcc/\n\t* config/aarch64/arm_neon.h (vmov_n_f32): Implemented in C.\n\t(vmov_n_f64): Likewise.\n\t(vmov_n_p8): Likewise.\n\t(vmov_n_p16): Likewise.\n\t(vmov_n_s8): Likewise.\n\t(vmov_n_s16): Likewise.\n\t(vmov_n_s32): Likewise.\n\t(vmov_n_s64): Likewise.\n\t(vmov_n_u8): Likewise.\n\t(vmov_n_u16): Likewise.\n\t(vmov_n_u32): Likewise.\n\t(vmov_n_u64): Likewise.\n\t(vmovq_n_f32): Likewise.\n\t(vmovq_n_f64): Likewise.\n\t(vmovq_n_p8): Likewise.\n\t(vmovq_n_p16): Likewise.\n\t(vmovq_n_s8): Likewise.\n\t(vmovq_n_s16): Likewise.\n\t(vmovq_n_s32): Likewise.\n\t(vmovq_n_s64): Likewise.\n\t(vmovq_n_u8): Likewise.\n\t(vmovq_n_u16): Likewise.\n\t(vmovq_n_u32): Likewise.\n\t(vmovq_n_u64): Likewise.\n\ngcc/testsuite/\n\t* gcc.target/aarch64/vmov_n_1.c: New testcase.\n\nFrom-SVN: r205270", "tree": {"sha": "9960de298ce66b61082f5d400544b9045953058b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/9960de298ce66b61082f5d400544b9045953058b"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/1e09922c5f98eada179244ba266dd971c416b1d1", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1e09922c5f98eada179244ba266dd971c416b1d1", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1e09922c5f98eada179244ba266dd971c416b1d1", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1e09922c5f98eada179244ba266dd971c416b1d1/comments", "author": null, "committer": null, "parents": [{"sha": "928353177b4843b05a7675d1b504086b3eb5686a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/928353177b4843b05a7675d1b504086b3eb5686a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/928353177b4843b05a7675d1b504086b3eb5686a"}], "stats": {"total": 774, "additions": 526, "deletions": 248}, "files": [{"sha": "fcfae83e0cd4790a8400a1fa010645a0e42c4a83", "filename": "gcc/ChangeLog", "status": "modified", "additions": 27, "deletions": 0, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1e09922c5f98eada179244ba266dd971c416b1d1/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1e09922c5f98eada179244ba266dd971c416b1d1/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=1e09922c5f98eada179244ba266dd971c416b1d1", "patch": "@@ -1,3 +1,30 @@\n+2013-11-22  Alex Velenko  <Alex.Velenko@arm.com>\n+\n+\t* config/aarch64/arm_neon.h (vmov_n_f32): Implemented in C.\n+\t(vmov_n_f64): Likewise.\n+\t(vmov_n_p8): Likewise.\n+\t(vmov_n_p16): Likewise.\n+\t(vmov_n_s8): Likewise.\n+\t(vmov_n_s16): Likewise.\n+\t(vmov_n_s32): Likewise.\n+\t(vmov_n_s64): Likewise.\n+\t(vmov_n_u8): Likewise.\n+\t(vmov_n_u16): Likewise.\n+\t(vmov_n_u32): Likewise.\n+\t(vmov_n_u64): Likewise.\n+\t(vmovq_n_f32): Likewise.\n+\t(vmovq_n_f64): Likewise.\n+\t(vmovq_n_p8): Likewise.\n+\t(vmovq_n_p16): Likewise.\n+\t(vmovq_n_s8): Likewise.\n+\t(vmovq_n_s16): Likewise.\n+\t(vmovq_n_s32): Likewise.\n+\t(vmovq_n_s64): Likewise.\n+\t(vmovq_n_u8): Likewise.\n+\t(vmovq_n_u16): Likewise.\n+\t(vmovq_n_u32): Likewise.\n+\t(vmovq_n_u64): Likewise.\n+\n 2013-11-22  Tejas Belagod  <tejas.belagod@arm.com>\n \n \t* config/aarch64/aarch64-simd.md (vec_pack_trunc_<mode>,"}, {"sha": "dc561701e97cd5133b070ce2c74f3b8194a43e60", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 146, "deletions": 248, "changes": 394, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1e09922c5f98eada179244ba266dd971c416b1d1/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1e09922c5f98eada179244ba266dd971c416b1d1/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=1e09922c5f98eada179244ba266dd971c416b1d1", "patch": "@@ -8314,127 +8314,6 @@ vmlsq_u32 (uint32x4_t a, uint32x4_t b, uint32x4_t c)\n   return result;\n }\n \n-__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n-vmov_n_f32 (float32_t a)\n-{\n-  float32x2_t result;\n-  __asm__ (\"dup %0.2s, %w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n-vmov_n_p8 (uint32_t a)\n-{\n-  poly8x8_t result;\n-  __asm__ (\"dup %0.8b,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n-vmov_n_p16 (uint32_t a)\n-{\n-  poly16x4_t result;\n-  __asm__ (\"dup %0.4h,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n-vmov_n_s8 (int32_t a)\n-{\n-  int8x8_t result;\n-  __asm__ (\"dup %0.8b,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n-vmov_n_s16 (int32_t a)\n-{\n-  int16x4_t result;\n-  __asm__ (\"dup %0.4h,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n-vmov_n_s32 (int32_t a)\n-{\n-  int32x2_t result;\n-  __asm__ (\"dup %0.2s,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n-vmov_n_s64 (int64_t a)\n-{\n-  int64x1_t result;\n-  __asm__ (\"ins %0.d[0],%x1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n-vmov_n_u8 (uint32_t a)\n-{\n-  uint8x8_t result;\n-  __asm__ (\"dup %0.8b,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n-vmov_n_u16 (uint32_t a)\n-{\n-  uint16x4_t result;\n-  __asm__ (\"dup %0.4h,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n-vmov_n_u32 (uint32_t a)\n-{\n-  uint32x2_t result;\n-  __asm__ (\"dup %0.2s,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n-vmov_n_u64 (uint64_t a)\n-{\n-  uint64x1_t result;\n-  __asm__ (\"ins %0.d[0],%x1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n vmovl_high_s8 (int8x16_t a)\n {\n@@ -8699,133 +8578,6 @@ vmovn_u64 (uint64x2_t a)\n   return result;\n }\n \n-__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n-vmovq_n_f32 (float32_t a)\n-{\n-  float32x4_t result;\n-  __asm__ (\"dup %0.4s, %w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n-vmovq_n_f64 (float64_t a)\n-{\n-  return (float64x2_t) {a, a};\n-}\n-\n-__extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n-vmovq_n_p8 (uint32_t a)\n-{\n-  poly8x16_t result;\n-  __asm__ (\"dup %0.16b,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline poly16x8_t __attribute__ ((__always_inline__))\n-vmovq_n_p16 (uint32_t a)\n-{\n-  poly16x8_t result;\n-  __asm__ (\"dup %0.8h,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n-vmovq_n_s8 (int32_t a)\n-{\n-  int8x16_t result;\n-  __asm__ (\"dup %0.16b,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n-vmovq_n_s16 (int32_t a)\n-{\n-  int16x8_t result;\n-  __asm__ (\"dup %0.8h,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n-vmovq_n_s32 (int32_t a)\n-{\n-  int32x4_t result;\n-  __asm__ (\"dup %0.4s,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n-vmovq_n_s64 (int64_t a)\n-{\n-  int64x2_t result;\n-  __asm__ (\"dup %0.2d,%x1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n-vmovq_n_u8 (uint32_t a)\n-{\n-  uint8x16_t result;\n-  __asm__ (\"dup %0.16b,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n-vmovq_n_u16 (uint32_t a)\n-{\n-  uint16x8_t result;\n-  __asm__ (\"dup %0.8h,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n-vmovq_n_u32 (uint32_t a)\n-{\n-  uint32x4_t result;\n-  __asm__ (\"dup %0.4s,%w1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n-__extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n-vmovq_n_u64 (uint64_t a)\n-{\n-  uint64x2_t result;\n-  __asm__ (\"dup %0.2d,%x1\"\n-           : \"=w\"(result)\n-           : \"r\"(a)\n-           : /* No clobbers */);\n-  return result;\n-}\n-\n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vmul_n_f32 (float32x2_t a, float32_t b)\n {\n@@ -20983,6 +20735,152 @@ vmlsq_laneq_u32 (uint32x4_t __a, uint32x4_t __b,\n   return (__a - (__b * __aarch64_vgetq_lane_u32 (__c, __lane)));\n }\n \n+/* vmov_n_  */\n+\n+__extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n+vmov_n_f32 (float32_t __a)\n+{\n+  return vdup_n_f32 (__a);\n+}\n+\n+__extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n+vmov_n_f64 (float64_t __a)\n+{\n+  return __a;\n+}\n+\n+__extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n+vmov_n_p8 (poly8_t __a)\n+{\n+  return vdup_n_p8 (__a);\n+}\n+\n+__extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n+vmov_n_p16 (poly16_t __a)\n+{\n+  return vdup_n_p16 (__a);\n+}\n+\n+__extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n+vmov_n_s8 (int8_t __a)\n+{\n+  return vdup_n_s8 (__a);\n+}\n+\n+__extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n+vmov_n_s16 (int16_t __a)\n+{\n+  return vdup_n_s16 (__a);\n+}\n+\n+__extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n+vmov_n_s32 (int32_t __a)\n+{\n+  return vdup_n_s32 (__a);\n+}\n+\n+__extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n+vmov_n_s64 (int64_t __a)\n+{\n+  return __a;\n+}\n+\n+__extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n+vmov_n_u8 (uint8_t __a)\n+{\n+  return vdup_n_u8 (__a);\n+}\n+\n+__extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n+vmov_n_u16 (uint16_t __a)\n+{\n+    return vdup_n_u16 (__a);\n+}\n+\n+__extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n+vmov_n_u32 (uint32_t __a)\n+{\n+   return vdup_n_u32 (__a);\n+}\n+\n+__extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n+vmov_n_u64 (uint64_t __a)\n+{\n+   return __a;\n+}\n+\n+__extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n+vmovq_n_f32 (float32_t __a)\n+{\n+  return vdupq_n_f32 (__a);\n+}\n+\n+__extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n+vmovq_n_f64 (float64_t __a)\n+{\n+  return vdupq_n_f64 (__a);\n+}\n+\n+__extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n+vmovq_n_p8 (poly8_t __a)\n+{\n+  return vdupq_n_p8 (__a);\n+}\n+\n+__extension__ static __inline poly16x8_t __attribute__ ((__always_inline__))\n+vmovq_n_p16 (poly16_t __a)\n+{\n+  return vdupq_n_p16 (__a);\n+}\n+\n+__extension__ static __inline int8x16_t __attribute__ ((__always_inline__))\n+vmovq_n_s8 (int8_t __a)\n+{\n+  return vdupq_n_s8 (__a);\n+}\n+\n+__extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n+vmovq_n_s16 (int16_t __a)\n+{\n+  return vdupq_n_s16 (__a);\n+}\n+\n+__extension__ static __inline int32x4_t __attribute__ ((__always_inline__))\n+vmovq_n_s32 (int32_t __a)\n+{\n+  return vdupq_n_s32 (__a);\n+}\n+\n+__extension__ static __inline int64x2_t __attribute__ ((__always_inline__))\n+vmovq_n_s64 (int64_t __a)\n+{\n+  return vdupq_n_s64 (__a);\n+}\n+\n+__extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n+vmovq_n_u8 (uint8_t __a)\n+{\n+  return vdupq_n_u8 (__a);\n+}\n+\n+__extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n+vmovq_n_u16 (uint16_t __a)\n+{\n+  return vdupq_n_u16 (__a);\n+}\n+\n+__extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n+vmovq_n_u32 (uint32_t __a)\n+{\n+  return vdupq_n_u32 (__a);\n+}\n+\n+__extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n+vmovq_n_u64 (uint64_t __a)\n+{\n+  return vdupq_n_u64 (__a);\n+}\n+\n /* vmul_lane  */\n \n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))"}, {"sha": "270c53cbc5bec236c6907c105524f54bd543f316", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1e09922c5f98eada179244ba266dd971c416b1d1/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1e09922c5f98eada179244ba266dd971c416b1d1/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=1e09922c5f98eada179244ba266dd971c416b1d1", "patch": "@@ -1,3 +1,7 @@\n+2013-11-22  Alex Velenko  <Alex.Velenko@arm.com>\n+\n+\t* gcc.target/aarch64/vmov_n_1.c: New testcase.\n+\n 2013-11-22  Richard Biener  <rguenther@suse.de>\n \n \t* gcc.dg/torture/20131122-0.c: New testcase."}, {"sha": "b9d094a044ac5bf6117d2b49ad0c339184553cb2", "filename": "gcc/testsuite/gcc.target/aarch64/vmov_n_1.c", "status": "added", "additions": 349, "deletions": 0, "changes": 349, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/1e09922c5f98eada179244ba266dd971c416b1d1/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvmov_n_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/1e09922c5f98eada179244ba266dd971c416b1d1/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvmov_n_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvmov_n_1.c?ref=1e09922c5f98eada179244ba266dd971c416b1d1", "patch": "@@ -0,0 +1,349 @@\n+/* Test vmov_n works correctly.  */\n+/* { dg-do run } */\n+/* { dg-options \"-O3 --save-temps\" } */\n+\n+#include <arm_neon.h>\n+\n+extern void abort (void);\n+\n+#define INHIB_OPTIMIZATION asm volatile (\"\" : : : \"memory\")\n+\n+#define CONCAT(a, b) a##b\n+#define CONCAT1(a, b) CONCAT (a, b)\n+#define REG_INFEX64 _\n+#define REG_INFEX128 q_\n+#define REG_INFEX(reg_len) REG_INFEX##reg_len\n+#define POSTFIX_N(reg_len, data_len, data_type)\t\\\n+  CONCAT1 (REG_INFEX (reg_len), n_##data_type##data_len)\n+#define LANE_POSTFIX(reg_len, data_len, data_type) \\\n+  CONCAT1 (REG_INFEX (reg_len),lane_##data_type##data_len)\n+\n+/* Test values consist of bytes with following hex values.\n+   For example:\n+   TEST1 for int16_t will be 0xaaaa\n+   TEST1 for int32_t will be 0xaaaaaaaa\n+   etc.  */\n+\n+#define TEST1h aa\n+#define TEST2h 55\n+#define TEST3h ff\n+#define TEST4h 00\n+#define TEST5h cc\n+#define TEST6h 33\n+\n+#define TESTh_8(x) TEST##x##h\n+#define TESTh_16(x) CONCAT1 (TESTh_8 (x), TESTh_8 (x))\n+#define TESTh_32(x) CONCAT1 (TESTh_16 (x), TESTh_16 (x))\n+#define TESTh_64(x) CONCAT1 (TESTh_32 (x), TESTh_32 (x))\n+\n+#define TEST_8(x) CONCAT1 (0x, TESTh_8 (x))\n+#define TEST_16(x) CONCAT1 (0x, TESTh_16 (x))\n+#define TEST_32(x) CONCAT1 (0x, TESTh_32 (x))\n+#define TEST_64(x) CONCAT1 (0x, TESTh_64 (x))\n+\n+#define TEST(test, data_len) \\\n+  CONCAT1 (TEST, _##data_len) (test)\n+\n+#define GET_ELEMENT(reg_len, data_len, data_type)\t\t\\\n+  CONCAT1 (vget, LANE_POSTFIX (reg_len, data_len, data_type))\n+\n+#define VMOV_INST(reg_len, data_len, data_type)\t\t\t\\\n+  CONCAT1 (vmov, POSTFIX_N (reg_len, data_len, data_type))\n+\n+#define VMOV_OBSCURE_INST(reg_len, data_len, data_type)\t\t\\\n+  CONCAT1 (VMOV_INST (reg_len, data_len, data_type), _obscure)\n+\n+#define RUN_TEST(reg_len, data_len, data_type,\t\t\t\t\\\n+\t\t test, n, a, b, c)\t\t\t\t\t\\\n+{\t\t\t\t\t\t\t\t\t\\\n+  int i;\t\t\t\t\t\t\t\t\\\n+  INHIB_OPTIMIZATION;\t\t\t\t\t\t\t\\\n+  (a) = TEST (test, data_len);\t\t\t\t\t\t\\\n+  INHIB_OPTIMIZATION;\t\t\t\t\t\t\t\\\n+  (b) = VMOV_OBSCURE_INST (reg_len, data_len, data_type) (&(a));\t\\\n+  (c) = TEST (test, data_len);\t\t\t\t\t\t\\\n+  for (i = 0; i < n; i++)\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\t\t\\\n+      INHIB_OPTIMIZATION;\t\t\t\t\t\t\\\n+      a = GET_ELEMENT (reg_len, data_len, data_type) (b, i);\t\t\\\n+      if ((a) != (c))\t\t\t\t\t\t\t\\\n+\treturn 1;\t\t\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+}\n+\n+#define TYPE_f32 float32_t\n+#define TYPE_64_f32 float32x2_t\n+#define TYPE_128_f32 float32x4_t\n+\n+#define TYPE_f64 float64_t\n+#define TYPE_64_f64 float64x1_t\n+#define TYPE_128_f64 float64x2_t\n+\n+#define TYPE_s8 int8_t\n+#define TYPE_64_s8 int8x8_t\n+#define TYPE_128_s8 int8x16_t\n+\n+#define TYPE_s16 int16_t\n+#define TYPE_64_s16 int16x4_t\n+#define TYPE_128_s16 int16x8_t\n+\n+#define TYPE_s32 int32_t\n+#define TYPE_64_s32 int32x2_t\n+#define TYPE_128_s32 int32x4_t\n+\n+#define TYPE_s64 int64_t\n+#define TYPE_64_s64 int64x1_t\n+#define TYPE_128_s64 int64x2_t\n+\n+#define TYPE_u8 uint8_t\n+#define TYPE_64_u8 uint8x8_t\n+#define TYPE_128_u8 uint8x16_t\n+\n+#define TYPE_u16 uint16_t\n+#define TYPE_64_u16 uint16x4_t\n+#define TYPE_128_u16 uint16x8_t\n+\n+#define TYPE_u32 uint32_t\n+#define TYPE_64_u32 uint32x2_t\n+#define TYPE_128_u32 uint32x4_t\n+\n+#define TYPE_u64 uint64_t\n+#define TYPE_64_u64 uint64x1_t\n+#define TYPE_128_u64 uint64x2_t\n+\n+#define TYPE_p8 poly8_t\n+#define TYPE_64_p8 poly8x8_t\n+#define TYPE_128_p8 poly8x16_t\n+\n+#define TYPE_p16 poly16_t\n+#define TYPE_64_p16 poly16x4_t\n+#define TYPE_128_p16 poly16x8_t\n+\n+#define DIV64_8  8\n+#define DIV64_16 4\n+#define DIV64_32 2\n+#define DIV64_64 1\n+\n+#define DIV128_8  16\n+#define DIV128_16 8\n+#define DIV128_32 4\n+#define DIV128_64 2\n+\n+#define DIV(reg_len, data_len)\t\t\t\\\n+CONCAT1 (CONCAT1 (DIV, reg_len),\t\t\\\n+\t CONCAT1 (_, data_len))\n+\n+#define VECTOR_TYPE(reg_len, data_len, data_type)\t\\\n+CONCAT1 (CONCAT1 (CONCAT1 (TYPE_,reg_len),\t\t\\\n+\t\t  CONCAT1 (_,data_type)),\t\t\\\n+\t data_len)\n+\n+#define SIMPLE_TYPE(data_len, data_type)\t\\\n+CONCAT1 (TYPE_,\t\t\t\t\t\\\n+\t CONCAT1 (data_type,\t\t\t\\\n+\t\t  data_len))\n+\n+#define OBSCURE_FUNC_NAME(reg_len, data_type, data_len)\t\t\\\n+CONCAT1 (CONCAT1 (vmov,\t\t\t\t\t\t\\\n+\t\t  POSTFIX_N (reg_len, data_len, data_type)),\t\\\n+\t _obscure)\n+\n+#define OBSCURE_FUNC(reg_len, data_len, data_type)\t\\\n+VECTOR_TYPE (reg_len, data_len, data_type)\t\t\\\n+__attribute__ ((noinline))\t\t\t\t\\\n+OBSCURE_FUNC_NAME (reg_len, data_type, data_len)\t\\\n+ (SIMPLE_TYPE (data_len, data_type) *ap)\t\t\\\n+{\t\t\t\t\t\t\t\\\n+  SIMPLE_TYPE (data_len, data_type) register a;\t\t\\\n+  INHIB_OPTIMIZATION;\t\t\t\t\t\\\n+  a = *ap;\t\t\t\t\t\t\\\n+  INHIB_OPTIMIZATION;\t\t\t\t\t\\\n+  return VMOV_INST (reg_len, data_len, data_type) (a);\t\\\n+}\n+\n+#define TESTFUNC_NAME(reg_len, data_type, data_len)\t\\\n+CONCAT1 (test_vmov,\t\t\t\t\t\\\n+\t POSTFIX_N (reg_len, data_len, data_type))\n+\n+#define TESTFUNC(reg_len, data_len, data_type)\t\\\n+int\t\t\t\t\t\t\\\n+TESTFUNC_NAME (reg_len, data_type, data_len) ()\t\\\n+{\t\t\t\t\t\t\\\n+  SIMPLE_TYPE (data_len, data_type) a;\t\t\\\n+  VECTOR_TYPE (reg_len, data_len, data_type) b;\t\\\n+  SIMPLE_TYPE (data_len, data_type) c;\t\t\\\n+\t\t\t\t\t\t\\\n+  RUN_TEST (reg_len, data_len, data_type, 1,\t\\\n+\t    DIV (reg_len, data_len), a, b, c);\t\\\n+  RUN_TEST (reg_len, data_len, data_type, 2,\t\\\n+\t    DIV (reg_len, data_len), a, b, c);\t\\\n+  RUN_TEST (reg_len, data_len, data_type, 3,\t\\\n+\t    DIV (reg_len, data_len), a, b, c);\t\\\n+  RUN_TEST (reg_len, data_len, data_type, 4,\t\\\n+\t    DIV (reg_len, data_len), a, b, c);\t\\\n+  RUN_TEST (reg_len, data_len, data_type, 5,\t\\\n+\t    DIV (reg_len, data_len), a, b, c);\t\\\n+  RUN_TEST (reg_len, data_len, data_type, 6,\t\\\n+\t    DIV (reg_len, data_len), a, b, c);\t\\\n+  return 0;\t\t\t\t\t\\\n+}\n+\n+OBSCURE_FUNC (64, 32, f)\n+TESTFUNC (64, 32, f)\n+/* \"dup  Vd.2s, Rn\" is less preferable then \"dup  Vd.2s, Vn.s[lane]\".  */\n+/* { dg-final { scan-assembler-times \"dup\\\\tv\\[0-9\\]+\\.2s, v\\[0-9\\]+\\.s\\\\\\[\\[0-9\\]+\\\\\\]\" 1 } } */\n+\n+OBSCURE_FUNC (64, 64, f)\n+TESTFUNC (64, 64, f)\n+/* \"fmov  Dd, Rn\" is generated instead of \"dup  Dd, Rn\".\n+   No assembley scan included.  */\n+\n+OBSCURE_FUNC (64, 8, p)\n+TESTFUNC (64, 8, p)\n+/* Generates \"dup  Vd.8b, Rn\". Scan found near s8 version.  */\n+\n+OBSCURE_FUNC (64, 16, p)\n+TESTFUNC (64, 16, p)\n+/* Generates \"dup  Vd.4h, Rn\". Scan found near s16 version.  */\n+\n+OBSCURE_FUNC (64, 8, s)\n+TESTFUNC (64, 8, s)\n+/* { dg-final { scan-assembler-times \"dup\\\\tv\\[0-9\\]+\\.8b, w\\[0-9\\]+\" 3 } } */\n+\n+OBSCURE_FUNC (64, 16, s)\n+TESTFUNC (64, 16, s)\n+/* { dg-final { scan-assembler-times \"dup\\\\tv\\[0-9\\]+\\.4h, w\\[0-9\\]+\" 3 } } */\n+\n+OBSCURE_FUNC (64, 32, s)\n+TESTFUNC (64, 32, s)\n+/* { dg-final { scan-assembler-times \"dup\\\\tv\\[0-9\\]+\\.2s, w\\[0-9\\]+\" 2 } } */\n+\n+OBSCURE_FUNC (64, 64, s)\n+TESTFUNC (64, 64, s)\n+/* \"fmov  Dd, Rn\" is generated instead of \"dup  Dd, Rn\".\n+   No assembley scan included.  */\n+\n+OBSCURE_FUNC (64, 8, u)\n+TESTFUNC (64, 8, u)\n+/* Generates \"dup  Vd.8b, Rn\". Scan found near s8 version.  */\n+\n+OBSCURE_FUNC (64, 16, u)\n+TESTFUNC (64, 16, u)\n+/* Generates \"dup  Vd.4h, Rn\". Scan found near s16 version.  */\n+\n+OBSCURE_FUNC (64, 32, u)\n+TESTFUNC (64, 32, u)\n+/* Generates \"dup  Vd.2s, Rn\". Scan found near s32 version.  */\n+\n+OBSCURE_FUNC (64, 64, u)\n+TESTFUNC (64, 64, u)\n+/* \"fmov  Dd, Rn\" is generated instead of \"dup  Dd, Rn\".\n+   No assembley scan included.  */\n+\n+OBSCURE_FUNC (128, 32, f)\n+TESTFUNC (128, 32, f)\n+/* \"dup  Vd.4s, Rn\" is less preferable then \"dup  Vd.4s, Vn.s[lane]\".  */\n+/* { dg-final { scan-assembler-times \"dup\\\\tv\\[0-9\\]+\\.4s, v\\[0-9\\]+\\.s\\\\\\[\\[0-9\\]+\\\\\\]\" 1 } } */\n+\n+OBSCURE_FUNC (128, 64, f)\n+TESTFUNC (128, 64, f)\n+/* \"dup  Vd.2d, Rn\" is less preferable then \"dup  Vd.2d, Vn.d[lane]\".  */\n+/* { dg-final { scan-assembler-times \"dup\\\\tv\\[0-9\\]+\\.2d, v\\[0-9\\]+\\.d\\\\\\[\\[0-9\\]+\\\\\\]\" 1 } } */\n+\n+OBSCURE_FUNC (128, 8, p)\n+TESTFUNC (128, 8, p)\n+/* Generates \"dup  Vd.16b, Rn\". Scan found near s8 version.  */\n+\n+OBSCURE_FUNC (128, 16, p)\n+TESTFUNC (128, 16, p)\n+/* Generates \"dup  Vd.8h, Rn\". Scan found near s16 version.  */\n+\n+OBSCURE_FUNC (128, 8, s)\n+TESTFUNC (128, 8, s)\n+/* { dg-final { scan-assembler-times \"dup\\\\tv\\[0-9\\]+\\.16b, w\\[0-9\\]+\" 3 } } */\n+\n+OBSCURE_FUNC (128, 16, s)\n+TESTFUNC (128, 16, s)\n+/* { dg-final { scan-assembler-times \"dup\\\\tv\\[0-9\\]+\\.8h, w\\[0-9\\]+\" 3 } } */\n+\n+OBSCURE_FUNC (128, 32, s)\n+TESTFUNC (128, 32, s)\n+/* { dg-final { scan-assembler-times \"dup\\\\tv\\[0-9\\]+\\.4s, w\\[0-9\\]+\" 2 } } */\n+\n+OBSCURE_FUNC (128, 64, s)\n+TESTFUNC (128, 64, s)\n+/* { dg-final { scan-assembler-times \"dup\\\\tv\\[0-9\\]+\\.2d, x\\[0-9\\]+\" 2 } } */\n+\n+OBSCURE_FUNC (128, 8, u)\n+TESTFUNC (128, 8, u)\n+/* Generates \"dup  Vd.16b, Rn\". Scan found near s8 version.  */\n+\n+OBSCURE_FUNC (128, 16, u)\n+TESTFUNC (128, 16, u)\n+/* Generates \"dup  Vd.8h, Rn\". Scan found near s16 version.  */\n+\n+OBSCURE_FUNC (128, 32, u)\n+TESTFUNC (128, 32, u)\n+/* Generates \"dup  Vd.4s, Rn\". Scan found near s32 version.  */\n+\n+OBSCURE_FUNC (128, 64, u)\n+TESTFUNC (128, 64, u)\n+/* Generates \"dup  Vd.2d, Rn\". Scan found near s64 version.  */\n+\n+int\n+main (int argc, char **argv)\n+{\n+  if (test_vmov_n_f32 ())\n+    abort ();\n+  if (test_vmov_n_f64 ())\n+    abort ();\n+  if (test_vmov_n_p8 ())\n+    abort ();\n+  if (test_vmov_n_p16 ())\n+    abort ();\n+  if (test_vmov_n_s8 ())\n+    abort ();\n+  if (test_vmov_n_s16 ())\n+    abort ();\n+  if (test_vmov_n_s32 ())\n+    abort ();\n+  if (test_vmov_n_s64 ())\n+    abort ();\n+  if (test_vmov_n_u8 ())\n+    abort ();\n+  if (test_vmov_n_u16 ())\n+    abort ();\n+  if (test_vmov_n_u32 ())\n+    abort ();\n+  if (test_vmov_n_u64 ())\n+    abort ();\n+\n+  if (test_vmovq_n_f32 ())\n+    abort ();\n+  if (test_vmovq_n_f64 ())\n+    abort ();\n+  if (test_vmovq_n_p8 ())\n+    abort ();\n+  if (test_vmovq_n_p16 ())\n+    abort ();\n+  if (test_vmovq_n_s8 ())\n+    abort ();\n+  if (test_vmovq_n_s16 ())\n+    abort ();\n+  if (test_vmovq_n_s32 ())\n+    abort ();\n+  if (test_vmovq_n_s64 ())\n+    abort ();\n+  if (test_vmovq_n_u8 ())\n+    abort ();\n+  if (test_vmovq_n_u16 ())\n+    abort ();\n+  if (test_vmovq_n_u32 ())\n+    abort ();\n+  if (test_vmovq_n_u64 ())\n+    abort ();\n+\n+  return 0;\n+}\n+\n+/* { dg-final { cleanup-saved-temps } } */"}]}