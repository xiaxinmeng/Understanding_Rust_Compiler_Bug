{"sha": "b05d5563f4be13b4a0d0951375a82adf483973c0", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YjA1ZDU1NjNmNGJlMTNiNGEwZDA5NTEzNzVhODJhZGY0ODM5NzNjMA==", "commit": {"author": {"name": "Richard Biener", "email": "rguenther@suse.de", "date": "2020-06-09T14:07:45Z"}, "committer": {"name": "Richard Biener", "email": "rguenther@suse.de", "date": "2020-06-10T10:05:36Z"}, "message": "Introduce STMT_VINFO_VEC_STMTS\n\nThis gets rid of the linked list of STMT_VINFO_VECT_STMT and\nSTMT_VINFO_RELATED_STMT in preparation for vectorized stmts no\nlonger needing a stmt_vec_info (just for this chaining).  This\nhas ripple-down effects in all places we gather vectorized\ndefs.  For this new interfaces are introduced and used\nthroughout vectorization, simplifying code in a lot of places\nand merging it with the SLP way of gathering vectorized\noperands.  There is vect_get_vec_defs as the new recommended\nunified interface and vect_get_vec_defs_for_operand as one\nfor non-SLP operation.  I've resorted to keep the structure\nof the code the same where using vect_get_vec_defs would have\nbeen too disruptive for this already large patch.\n\n2020-06-10  Richard Biener  <rguenther@suse.de>\n\n\t* tree-vect-data-refs.c (vect_vfa_access_size): Adjust.\n\t(vect_record_grouped_load_vectors): Likewise.\n\t* tree-vect-loop.c (vect_create_epilog_for_reduction): Likewise.\n\t(vectorize_fold_left_reduction): Likewise.\n\t(vect_transform_reduction): Likewise.\n\t(vect_transform_cycle_phi): Likewise.\n\t(vectorizable_lc_phi): Likewise.\n\t(vectorizable_induction): Likewise.\n\t(vectorizable_live_operation): Likewise.\n\t(vect_transform_loop): Likewise.\n\t* tree-vect-slp.c (vect_get_slp_defs): New function, split out\n\tfrom overload.\n\t* tree-vect-stmts.c (vect_get_vec_def_for_operand_1): Remove.\n\t(vect_get_vec_def_for_operand): Likewise.\n\t(vect_get_vec_def_for_stmt_copy): Likewise.\n\t(vect_get_vec_defs_for_stmt_copy): Likewise.\n\t(vect_get_vec_defs_for_operand): New function.\n\t(vect_get_vec_defs): Likewise.\n\t(vect_build_gather_load_calls): Adjust.\n\t(vect_get_gather_scatter_ops): Likewise.\n\t(vectorizable_bswap): Likewise.\n\t(vectorizable_call): Likewise.\n\t(vectorizable_simd_clone_call): Likewise.\n\t(vect_get_loop_based_defs): Remove.\n\t(vect_create_vectorized_demotion_stmts): Adjust.\n\t(vectorizable_conversion): Likewise.\n\t(vectorizable_assignment): Likewise.\n\t(vectorizable_shift): Likewise.\n\t(vectorizable_operation): Likewise.\n\t(vectorizable_scan_store): Likewise.\n\t(vectorizable_store): Likewise.\n\t(vectorizable_load): Likewise.\n\t(vectorizable_condition): Likewise.\n\t(vectorizable_comparison): Likewise.\n\t(vect_transform_stmt): Adjust and remove no longer applicable\n\tsanity checks.\n\t* tree-vectorizer.c (vec_info::new_stmt_vec_info): Initialize\n\tSTMT_VINFO_VEC_STMTS.\n\t(vec_info::free_stmt_vec_info): Relase it.\n\t* tree-vectorizer.h (_stmt_vec_info::vectorized_stmt): Remove.\n\t(_stmt_vec_info::vec_stmts): Add.\n\t(STMT_VINFO_VEC_STMT): Remove.\n\t(STMT_VINFO_VEC_STMTS): New.\n\t(vect_get_vec_def_for_operand_1): Remove.\n\t(vect_get_vec_def_for_operand): Likewise.\n\t(vect_get_vec_defs_for_stmt_copy): Likewise.\n\t(vect_get_vec_def_for_stmt_copy): Likewise.\n\t(vect_get_vec_defs): New overloads.\n\t(vect_get_vec_defs_for_operand): New.\n\t(vect_get_slp_defs): Declare.", "tree": {"sha": "83e292c616beb23613b4e904e2809887b773e839", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/83e292c616beb23613b4e904e2809887b773e839"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/b05d5563f4be13b4a0d0951375a82adf483973c0", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b05d5563f4be13b4a0d0951375a82adf483973c0", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b05d5563f4be13b4a0d0951375a82adf483973c0", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b05d5563f4be13b4a0d0951375a82adf483973c0/comments", "author": {"login": "rguenth", "id": 2046526, "node_id": "MDQ6VXNlcjIwNDY1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/2046526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rguenth", "html_url": "https://github.com/rguenth", "followers_url": "https://api.github.com/users/rguenth/followers", "following_url": "https://api.github.com/users/rguenth/following{/other_user}", "gists_url": "https://api.github.com/users/rguenth/gists{/gist_id}", "starred_url": "https://api.github.com/users/rguenth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rguenth/subscriptions", "organizations_url": "https://api.github.com/users/rguenth/orgs", "repos_url": "https://api.github.com/users/rguenth/repos", "events_url": "https://api.github.com/users/rguenth/events{/privacy}", "received_events_url": "https://api.github.com/users/rguenth/received_events", "type": "User", "site_admin": false}, "committer": {"login": "rguenth", "id": 2046526, "node_id": "MDQ6VXNlcjIwNDY1MjY=", "avatar_url": "https://avatars.githubusercontent.com/u/2046526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rguenth", "html_url": "https://github.com/rguenth", "followers_url": "https://api.github.com/users/rguenth/followers", "following_url": "https://api.github.com/users/rguenth/following{/other_user}", "gists_url": "https://api.github.com/users/rguenth/gists{/gist_id}", "starred_url": "https://api.github.com/users/rguenth/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rguenth/subscriptions", "organizations_url": "https://api.github.com/users/rguenth/orgs", "repos_url": "https://api.github.com/users/rguenth/repos", "events_url": "https://api.github.com/users/rguenth/events{/privacy}", "received_events_url": "https://api.github.com/users/rguenth/received_events", "type": "User", "site_admin": false}, "parents": [{"sha": "6d9ef0621f8e1aaafd458dba1a8b5476e655b479", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6d9ef0621f8e1aaafd458dba1a8b5476e655b479", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6d9ef0621f8e1aaafd458dba1a8b5476e655b479"}], "stats": {"total": 2391, "additions": 882, "deletions": 1509}, "files": [{"sha": "7edd9ebe3b63869691fa346eacabfd9dcc411fb9", "filename": "gcc/tree-vect-data-refs.c", "status": "modified", "additions": 3, "deletions": 19, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b05d5563f4be13b4a0d0951375a82adf483973c0/gcc%2Ftree-vect-data-refs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b05d5563f4be13b4a0d0951375a82adf483973c0/gcc%2Ftree-vect-data-refs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-data-refs.c?ref=b05d5563f4be13b4a0d0951375a82adf483973c0", "patch": "@@ -3216,7 +3216,7 @@ vect_vfa_access_size (vec_info *vinfo, dr_vec_info *dr_info)\n       gcc_assert (DR_GROUP_FIRST_ELEMENT (stmt_vinfo) == stmt_vinfo);\n       access_size *= DR_GROUP_SIZE (stmt_vinfo) - DR_GROUP_GAP (stmt_vinfo);\n     }\n-  if (STMT_VINFO_VEC_STMT (stmt_vinfo)\n+  if (STMT_VINFO_VEC_STMTS (stmt_vinfo).exists ()\n       && (vect_supportable_dr_alignment (vinfo, dr_info, false)\n \t  == dr_explicit_realign_optimized))\n     {\n@@ -6443,24 +6443,8 @@ vect_record_grouped_load_vectors (vec_info *vinfo, stmt_vec_info stmt_info,\n         {\n \t  stmt_vec_info new_stmt_info = vinfo->lookup_def (tmp_data_ref);\n \t  /* We assume that if VEC_STMT is not NULL, this is a case of multiple\n-\t     copies, and we put the new vector statement in the first available\n-\t     RELATED_STMT.  */\n-\t  if (!STMT_VINFO_VEC_STMT (next_stmt_info))\n-\t    STMT_VINFO_VEC_STMT (next_stmt_info) = new_stmt_info;\n-\t  else\n-            {\n-\t      stmt_vec_info prev_stmt_info\n-\t\t= STMT_VINFO_VEC_STMT (next_stmt_info);\n-\t      stmt_vec_info rel_stmt_info\n-\t\t= STMT_VINFO_RELATED_STMT (prev_stmt_info);\n-\t      while (rel_stmt_info)\n-\t\t{\n-\t\t  prev_stmt_info = rel_stmt_info;\n-\t\t  rel_stmt_info = STMT_VINFO_RELATED_STMT (rel_stmt_info);\n-\t\t}\n-\n-\t      STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-            }\n+\t     copies, and we put the new vector statement last.  */\n+\t  STMT_VINFO_VEC_STMTS (next_stmt_info).safe_push (new_stmt_info);\n \n \t  next_stmt_info = DR_GROUP_NEXT_ELEMENT (next_stmt_info);\n \t  gap_count = 1;"}, {"sha": "cc3d391d7c2e4c8625ddedb56038104df36c69e5", "filename": "gcc/tree-vect-loop.c", "status": "modified", "additions": 111, "deletions": 208, "changes": 319, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b05d5563f4be13b4a0d0951375a82adf483973c0/gcc%2Ftree-vect-loop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b05d5563f4be13b4a0d0951375a82adf483973c0/gcc%2Ftree-vect-loop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-loop.c?ref=b05d5563f4be13b4a0d0951375a82adf483973c0", "patch": "@@ -4485,15 +4485,13 @@ vect_create_epilog_for_reduction (loop_vec_info loop_vinfo,\n     = as_a <gphi *> (STMT_VINFO_REDUC_DEF (vect_orig_stmt (stmt_info))->stmt);\n   enum tree_code code = STMT_VINFO_REDUC_CODE (reduc_info);\n   internal_fn reduc_fn = STMT_VINFO_REDUC_FN (reduc_info);\n-  stmt_vec_info prev_phi_info;\n   tree vectype;\n   machine_mode mode;\n   class loop *loop = LOOP_VINFO_LOOP (loop_vinfo), *outer_loop = NULL;\n   basic_block exit_bb;\n   tree scalar_dest;\n   tree scalar_type;\n   gimple *new_phi = NULL, *phi;\n-  stmt_vec_info phi_info;\n   gimple_stmt_iterator exit_gsi;\n   tree new_temp = NULL_TREE, new_name, new_scalar_dest;\n   gimple *epilog_stmt = NULL;\n@@ -4563,15 +4561,9 @@ vect_create_epilog_for_reduction (loop_vec_info loop_vinfo,\n     }\n   else\n     {\n+      stmt_vec_info reduc_info = loop_vinfo->lookup_stmt (reduc_def_stmt);\n       vec_num = 1;\n-      ncopies = 0;\n-      phi_info = STMT_VINFO_VEC_STMT (loop_vinfo->lookup_stmt (reduc_def_stmt));\n-      do\n-\t{\n-\t  ncopies++;\n-\t  phi_info = STMT_VINFO_RELATED_STMT (phi_info);\n-\t}\n-      while (phi_info);\n+      ncopies = STMT_VINFO_VEC_STMTS (reduc_info).length ();\n     }\n \n   /* For cond reductions we want to create a new vector (INDEX_COND_EXPR)\n@@ -4593,7 +4585,7 @@ vect_create_epilog_for_reduction (loop_vec_info loop_vinfo,\n \t{\n \t  if (gimple_assign_rhs_code (cond_info->stmt) == COND_EXPR)\n \t    {\n-\t      gimple *vec_stmt = STMT_VINFO_VEC_STMT (cond_info)->stmt;\n+\t      gimple *vec_stmt = STMT_VINFO_VEC_STMTS (cond_info)[0]->stmt;\n \t      gcc_assert (gimple_assign_rhs_code (vec_stmt) == VEC_COND_EXPR);\n \t      ccompares.safe_push\n \t\t(std::make_pair (unshare_expr (gimple_assign_rhs1 (vec_stmt)),\n@@ -4714,29 +4706,27 @@ vect_create_epilog_for_reduction (loop_vec_info loop_vinfo,\n   if (double_reduc)\n     loop = outer_loop;\n   exit_bb = single_exit (loop)->dest;\n-  prev_phi_info = NULL;\n   new_phis.create (slp_node ? vec_num : ncopies);\n   for (unsigned i = 0; i < vec_num; i++)\n     {\n       if (slp_node)\n \tdef = vect_get_slp_vect_def (slp_node, i);\n       else\n-\tdef = gimple_get_lhs (STMT_VINFO_VEC_STMT (rdef_info)->stmt);\n+\tdef = gimple_get_lhs (STMT_VINFO_VEC_STMTS (rdef_info)[0]->stmt);\n       for (j = 0; j < ncopies; j++)\n         {\n \t  tree new_def = copy_ssa_name (def);\n           phi = create_phi_node (new_def, exit_bb);\n-\t  stmt_vec_info phi_info = loop_vinfo->add_stmt (phi);\n+\t  loop_vinfo->add_stmt (phi);\n           if (j == 0)\n             new_phis.quick_push (phi);\n           else\n \t    {\n-\t      def = vect_get_vec_def_for_stmt_copy (loop_vinfo, def);\n-\t      STMT_VINFO_RELATED_STMT (prev_phi_info) = phi_info;\n+\t      def = gimple_get_lhs (STMT_VINFO_VEC_STMTS (rdef_info)[j]->stmt);\n+\t      new_phis.quick_push (phi);\n \t    }\n \n           SET_PHI_ARG_DEF (phi, single_exit (loop)->dest_idx, def);\n-\t  prev_phi_info = phi_info;\n         }\n     }\n \n@@ -4807,15 +4797,12 @@ vect_create_epilog_for_reduction (loop_vec_info loop_vinfo,\n   /* Likewise if we couldn't use a single defuse cycle.  */\n   else if (ncopies > 1)\n     {\n-      gcc_assert (new_phis.length () == 1);\n       gimple_seq stmts = NULL;\n       tree first_vect = PHI_RESULT (new_phis[0]);\n       first_vect = gimple_convert (&stmts, vectype, first_vect);\n-      stmt_vec_info next_phi_info = loop_vinfo->lookup_stmt (new_phis[0]);\n       for (int k = 1; k < ncopies; ++k)\n \t{\n-\t  next_phi_info = STMT_VINFO_RELATED_STMT (next_phi_info);\n-\t  tree second_vect = PHI_RESULT (next_phi_info->stmt);\n+\t  tree second_vect = PHI_RESULT (new_phis[k]);\n \t  second_vect = gimple_convert (&stmts, vectype, second_vect);\n \t  first_vect = gimple_build (&stmts, code, vectype,\n \t\t\t\t     first_vect, second_vect);\n@@ -5721,10 +5708,8 @@ vectorize_fold_left_reduction (loop_vec_info loop_vinfo,\n     }\n   else\n     {\n-      tree loop_vec_def0 = vect_get_vec_def_for_operand (loop_vinfo,\n-\t\t\t\t\t\t\t op0, stmt_info);\n-      vec_oprnds0.create (1);\n-      vec_oprnds0.quick_push (loop_vec_def0);\n+      vect_get_vec_defs_for_operand (loop_vinfo, stmt_info, 1,\n+\t\t\t\t     op0, &vec_oprnds0);\n       scalar_dest_def_info = stmt_info;\n     }\n \n@@ -5814,7 +5799,10 @@ vectorize_fold_left_reduction (loop_vec_info loop_vinfo,\n     }\n \n   if (!slp_node)\n-    STMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n+    {\n+      STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n+      *vec_stmt = new_stmt_info;\n+    }\n \n   return true;\n }\n@@ -6840,7 +6828,6 @@ vect_transform_reduction (loop_vec_info loop_vinfo,\n   class loop *loop = LOOP_VINFO_LOOP (loop_vinfo);\n   int i;\n   int ncopies;\n-  int j;\n   int vec_num;\n \n   stmt_vec_info reduc_info = info_for_reduction (loop_vinfo, stmt_info);\n@@ -6897,7 +6884,6 @@ vect_transform_reduction (loop_vec_info loop_vinfo,\n \n   /* Transform.  */\n   stmt_vec_info new_stmt_info = NULL;\n-  stmt_vec_info prev_stmt_info;\n   tree new_temp = NULL_TREE;\n   auto_vec<tree> vec_oprnds0;\n   auto_vec<tree> vec_oprnds1;\n@@ -6932,139 +6918,83 @@ vect_transform_reduction (loop_vec_info loop_vinfo,\n   tree scalar_dest = gimple_assign_lhs (stmt);\n   tree vec_dest = vect_create_destination_var (scalar_dest, vectype_out);\n \n-  prev_stmt_info = NULL;\n-  if (!slp_node)\n+  vect_get_vec_defs (loop_vinfo, stmt_info, slp_node, ncopies,\n+\t\t     single_defuse_cycle && reduc_index == 0\n+\t\t     ? NULL_TREE : ops[0], &vec_oprnds0,\n+\t\t     single_defuse_cycle && reduc_index == 1\n+\t\t     ? NULL_TREE : ops[1], &vec_oprnds1,\n+\t\t     op_type == ternary_op\n+\t\t     && !(single_defuse_cycle && reduc_index == 2)\n+\t\t     ? ops[2] : NULL_TREE, &vec_oprnds2);\n+  if (single_defuse_cycle)\n     {\n-      vec_oprnds0.create (1);\n-      vec_oprnds1.create (1);\n-      if (op_type == ternary_op)\n-        vec_oprnds2.create (1);\n+      gcc_assert (!slp_node);\n+      vect_get_vec_defs_for_operand (loop_vinfo, stmt_info, 1,\n+\t\t\t\t     ops[reduc_index],\n+\t\t\t\t     reduc_index == 0 ? &vec_oprnds0\n+\t\t\t\t     : (reduc_index == 1 ? &vec_oprnds1\n+\t\t\t\t\t: &vec_oprnds2));\n     }\n \n-  for (j = 0; j < ncopies; j++)\n+  FOR_EACH_VEC_ELT (vec_oprnds0, i, def0)\n     {\n-      /* Handle uses.  */\n-      if (j == 0)\n-        {\n-\t  if (slp_node)\n-\t    {\n-\t      /* Get vec defs for all the operands except the reduction index,\n-\t\t ensuring the ordering of the ops in the vector is kept.  */\n-\t      auto_vec<vec<tree>, 3> vec_defs;\n-\t      vect_get_slp_defs (loop_vinfo, slp_node, &vec_defs);\n-\t      vec_oprnds0.safe_splice (vec_defs[0]);\n-\t      vec_defs[0].release ();\n-\t      vec_oprnds1.safe_splice (vec_defs[1]);\n-\t      vec_defs[1].release ();\n-\t      if (op_type == ternary_op)\n-\t\t{\n-\t\t  vec_oprnds2.safe_splice (vec_defs[2]);\n-\t\t  vec_defs[2].release ();\n-\t\t}\n-\t    }\n-          else\n+      tree vop[3] = { def0, vec_oprnds1[i], NULL_TREE };\n+      if (masked_loop_p && !mask_by_cond_expr)\n+\t{\n+\t  /* Make sure that the reduction accumulator is vop[0].  */\n+\t  if (reduc_index == 1)\n \t    {\n-              vec_oprnds0.quick_push\n-\t\t(vect_get_vec_def_for_operand (loop_vinfo, ops[0], stmt_info));\n-              vec_oprnds1.quick_push\n-\t\t(vect_get_vec_def_for_operand (loop_vinfo, ops[1], stmt_info));\n-              if (op_type == ternary_op)\n-\t\tvec_oprnds2.quick_push \n-\t\t  (vect_get_vec_def_for_operand (loop_vinfo, ops[2], stmt_info));\n+\t      gcc_assert (commutative_tree_code (code));\n+\t      std::swap (vop[0], vop[1]);\n \t    }\n-        }\n+\t  tree mask = vect_get_loop_mask (gsi, masks, vec_num * ncopies,\n+\t\t\t\t\t  vectype_in, i);\n+\t  gcall *call = gimple_build_call_internal (cond_fn, 4, mask,\n+\t\t\t\t\t\t    vop[0], vop[1], vop[0]);\n+\t  new_temp = make_ssa_name (vec_dest, call);\n+\t  gimple_call_set_lhs (call, new_temp);\n+\t  gimple_call_set_nothrow (call, true);\n+\t  new_stmt_info = vect_finish_stmt_generation (loop_vinfo,\n+\t\t\t\t\t\t       stmt_info, call, gsi);\n+\t}\n       else\n-        {\n-          if (!slp_node)\n-            {\n-\t      gcc_assert (reduc_index != -1 || ! single_defuse_cycle);\n-\n-\t      if (single_defuse_cycle && reduc_index == 0)\n-\t\tvec_oprnds0[0] = gimple_get_lhs (new_stmt_info->stmt);\n-\t      else\n-\t\tvec_oprnds0[0]\n-\t\t  = vect_get_vec_def_for_stmt_copy (loop_vinfo,\n-\t\t\t\t\t\t    vec_oprnds0[0]);\n-\t      if (single_defuse_cycle && reduc_index == 1)\n-\t\tvec_oprnds1[0] = gimple_get_lhs (new_stmt_info->stmt);\n-\t      else\n-\t\tvec_oprnds1[0]\n-\t\t  = vect_get_vec_def_for_stmt_copy (loop_vinfo,\n-\t\t\t\t\t\t    vec_oprnds1[0]);\n-\t      if (op_type == ternary_op)\n-\t\t{\n-\t\t  if (single_defuse_cycle && reduc_index == 2)\n-\t\t    vec_oprnds2[0] = gimple_get_lhs (new_stmt_info->stmt);\n-\t\t  else\n-\t\t    vec_oprnds2[0] \n-\t\t      = vect_get_vec_def_for_stmt_copy (loop_vinfo,\n-\t\t\t\t\t\t\tvec_oprnds2[0]);\n-\t\t}\n-            }\n-        }\n+\t{\n+\t  if (op_type == ternary_op)\n+\t    vop[2] = vec_oprnds2[i];\n \n-      FOR_EACH_VEC_ELT (vec_oprnds0, i, def0)\n-        {\n-\t  tree vop[3] = { def0, vec_oprnds1[i], NULL_TREE };\n-\t  if (masked_loop_p && !mask_by_cond_expr)\n+\t  if (masked_loop_p && mask_by_cond_expr)\n \t    {\n-\t      /* Make sure that the reduction accumulator is vop[0].  */\n-\t      if (reduc_index == 1)\n-\t\t{\n-\t\t  gcc_assert (commutative_tree_code (code));\n-\t\t  std::swap (vop[0], vop[1]);\n-\t\t}\n \t      tree mask = vect_get_loop_mask (gsi, masks, vec_num * ncopies,\n-\t\t\t\t\t      vectype_in, i * ncopies + j);\n-\t      gcall *call = gimple_build_call_internal (cond_fn, 4, mask,\n-\t\t\t\t\t\t\tvop[0], vop[1],\n-\t\t\t\t\t\t\tvop[0]);\n-\t      new_temp = make_ssa_name (vec_dest, call);\n-\t      gimple_call_set_lhs (call, new_temp);\n-\t      gimple_call_set_nothrow (call, true);\n-\t      new_stmt_info\n-\t\t= vect_finish_stmt_generation (loop_vinfo,\n-\t\t\t\t\t       stmt_info, call, gsi);\n-\t    }\n-\t  else\n-\t    {\n-\t      if (op_type == ternary_op)\n-\t\tvop[2] = vec_oprnds2[i];\n-\n-\t      if (masked_loop_p && mask_by_cond_expr)\n-\t\t{\n-\t\t  tree mask = vect_get_loop_mask (gsi, masks,\n-\t\t\t\t\t\t  vec_num * ncopies,\n-\t\t\t\t\t\t  vectype_in, i * ncopies + j);\n-\t\t  build_vect_cond_expr (code, vop, mask, gsi);\n-\t\t}\n-\n-\t      gassign *new_stmt = gimple_build_assign (vec_dest, code,\n-\t\t\t\t\t\t       vop[0], vop[1], vop[2]);\n-\t      new_temp = make_ssa_name (vec_dest, new_stmt);\n-\t      gimple_assign_set_lhs (new_stmt, new_temp);\n-\t      new_stmt_info\n-\t\t= vect_finish_stmt_generation (loop_vinfo,\n-\t\t\t\t\t       stmt_info, new_stmt, gsi);\n+\t\t\t\t\t      vectype_in, i);\n+\t      build_vect_cond_expr (code, vop, mask, gsi);\n \t    }\n \n-          if (slp_node)\n-\t    SLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n-        }\n-\n-      if (slp_node || single_defuse_cycle)\n-        continue;\n+\t  gassign *new_stmt = gimple_build_assign (vec_dest, code,\n+\t\t\t\t\t\t   vop[0], vop[1], vop[2]);\n+\t  new_temp = make_ssa_name (vec_dest, new_stmt);\n+\t  gimple_assign_set_lhs (new_stmt, new_temp);\n+\t  new_stmt_info = vect_finish_stmt_generation (loop_vinfo, stmt_info,\n+\t\t\t\t\t\t       new_stmt, gsi);\n+\t}\n \n-      if (j == 0)\n-\tSTMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n+      if (slp_node)\n+\tSLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n+      else if (single_defuse_cycle\n+\t       && i < ncopies - 1)\n+\t{\n+\t  if (reduc_index == 0)\n+\t    vec_oprnds0.safe_push (gimple_get_lhs (new_stmt_info->stmt));\n+\t  else if (reduc_index == 1)\n+\t    vec_oprnds1.safe_push (gimple_get_lhs (new_stmt_info->stmt));\n+\t  else if (reduc_index == 2)\n+\t    vec_oprnds2.safe_push (gimple_get_lhs (new_stmt_info->stmt));\n+\t}\n       else\n-\tSTMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\n-      prev_stmt_info = new_stmt_info;\n+\tSTMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n     }\n \n-  if (single_defuse_cycle && !slp_node)\n-    STMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n+  if (!slp_node)\n+    *vec_stmt = STMT_VINFO_VEC_STMTS (stmt_info)[0];\n \n   return true;\n }\n@@ -7080,7 +7010,6 @@ vect_transform_cycle_phi (loop_vec_info loop_vinfo,\n   class loop *loop = LOOP_VINFO_LOOP (loop_vinfo);\n   int i;\n   int ncopies;\n-  stmt_vec_info prev_phi_info;\n   int j;\n   bool nested_cycle = false;\n   int vec_num;\n@@ -7171,14 +7100,17 @@ vect_transform_cycle_phi (loop_vec_info loop_vinfo,\n \t      STMT_VINFO_VEC_INDUC_COND_INITIAL_VAL (reduc_info) = NULL_TREE;\n \t    }\n \t  vec_initial_def = build_vector_from_val (vectype_out, induc_val);\n+\t  vec_initial_defs.create (ncopies);\n+\t  for (i = 0; i < ncopies; ++i)\n+\t    vec_initial_defs.quick_push (vec_initial_def);\n \t}\n       else if (nested_cycle)\n \t{\n \t  /* Do not use an adjustment def as that case is not supported\n \t     correctly if ncopies is not one.  */\n-\t  vec_initial_def = vect_get_vec_def_for_operand (loop_vinfo,\n-\t\t\t\t\t\t\t  initial_def,\n-\t\t\t\t\t\t\t  reduc_stmt_info);\n+\t  vect_get_vec_defs_for_operand (loop_vinfo, reduc_stmt_info,\n+\t\t\t\t\t ncopies, initial_def,\n+\t\t\t\t\t &vec_initial_defs);\n \t}\n       else\n \t{\n@@ -7191,13 +7123,13 @@ vect_transform_cycle_phi (loop_vec_info loop_vinfo,\n \t    = get_initial_def_for_reduction (loop_vinfo, reduc_stmt_info, code,\n \t\t\t\t\t     initial_def, adjustment_defp);\n \t  STMT_VINFO_REDUC_EPILOGUE_ADJUSTMENT (reduc_info) = adjustment_def;\n+\t  vec_initial_defs.create (ncopies);\n+\t  for (i = 0; i < ncopies; ++i)\n+\t    vec_initial_defs.quick_push (vec_initial_def);\n \t}\n-      vec_initial_defs.create (1);\n-      vec_initial_defs.quick_push (vec_initial_def);\n     }\n \n   /* Generate the reduction PHIs upfront.  */\n-  prev_phi_info = NULL;\n   for (i = 0; i < vec_num; i++)\n     {\n       tree vec_init_def = vec_initial_defs[i];\n@@ -7210,8 +7142,7 @@ vect_transform_cycle_phi (loop_vec_info loop_vinfo,\n \n \t  /* Set the loop-entry arg of the reduction-phi.  */\n \t  if (j != 0 && nested_cycle)\n-\t    vec_init_def = vect_get_vec_def_for_stmt_copy (loop_vinfo,\n-\t\t\t\t\t\t\t   vec_init_def);\n+\t    vec_init_def = vec_initial_defs[j];\n \t  add_phi_arg (new_phi, vec_init_def, loop_preheader_edge (loop),\n \t\t       UNKNOWN_LOCATION);\n \n@@ -7222,10 +7153,8 @@ vect_transform_cycle_phi (loop_vec_info loop_vinfo,\n \t  else\n \t    {\n \t      if (j == 0)\n-\t\tSTMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_phi_info;\n-\t      else\n-\t\tSTMT_VINFO_RELATED_STMT (prev_phi_info) = new_phi_info;\n-\t      prev_phi_info = new_phi_info;\n+\t\t*vec_stmt = new_phi_info;\n+\t      STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_phi_info);\n \t    }\n \t}\n     }\n@@ -7260,43 +7189,23 @@ vectorizable_lc_phi (loop_vec_info loop_vinfo,\n   basic_block bb = gimple_bb (stmt_info->stmt);\n   edge e = single_pred_edge (bb);\n   tree vec_dest = vect_create_destination_var (scalar_dest, vectype);\n-  vec<tree> vec_oprnds = vNULL;\n-  vect_get_vec_defs (loop_vinfo,\n-\t\t     gimple_phi_arg_def (stmt_info->stmt, 0), NULL_TREE,\n-\t\t     stmt_info, &vec_oprnds, NULL, slp_node);\n-  if (slp_node)\n-    {\n-      unsigned vec_num = SLP_TREE_NUMBER_OF_VEC_STMTS (slp_node);\n-      gcc_assert (vec_oprnds.length () == vec_num);\n-      for (unsigned i = 0; i < vec_num; i++)\n-\t{\n-\t  /* Create the vectorized LC PHI node.  */\n-\t  gphi *new_phi = create_phi_node (vec_dest, bb);\n-\t  add_phi_arg (new_phi, vec_oprnds[i], e, UNKNOWN_LOCATION);\n-\t  stmt_vec_info new_phi_info = loop_vinfo->add_stmt (new_phi);\n-\t  SLP_TREE_VEC_STMTS (slp_node).quick_push (new_phi_info);\n-\t}\n-    }\n-  else\n-    {\n-      unsigned ncopies = vect_get_num_copies (loop_vinfo, vectype);\n-      stmt_vec_info prev_phi_info = NULL;\n-      for (unsigned i = 0; i < ncopies; i++)\n-\t{\n-\t  if (i != 0)\n-\t    vect_get_vec_defs_for_stmt_copy (loop_vinfo, &vec_oprnds, NULL);\n-\t  /* Create the vectorized LC PHI node.  */\n-\t  gphi *new_phi = create_phi_node (vec_dest, bb);\n-\t  add_phi_arg (new_phi, vec_oprnds[0], e, UNKNOWN_LOCATION);\n-\t  stmt_vec_info new_phi_info = loop_vinfo->add_stmt (new_phi);\n-\t  if (i == 0)\n-\t    STMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_phi_info;\n-\t  else\n-\t    STMT_VINFO_RELATED_STMT (prev_phi_info) = new_phi_info;\n-\t  prev_phi_info = new_phi_info;\n-\t}\n+  auto_vec<tree> vec_oprnds;\n+  vect_get_vec_defs (loop_vinfo, stmt_info, slp_node,\n+\t\t     !slp_node ? vect_get_num_copies (loop_vinfo, vectype) : 1,\n+\t\t     gimple_phi_arg_def (stmt_info->stmt, 0), &vec_oprnds);\n+  for (unsigned i = 0; i < vec_oprnds.length (); i++)\n+    {\n+      /* Create the vectorized LC PHI node.  */\n+      gphi *new_phi = create_phi_node (vec_dest, bb);\n+      add_phi_arg (new_phi, vec_oprnds[i], e, UNKNOWN_LOCATION);\n+      stmt_vec_info new_phi_info = loop_vinfo->add_stmt (new_phi);\n+      if (slp_node)\n+\tSLP_TREE_VEC_STMTS (slp_node).quick_push (new_phi_info);\n+      else\n+\tSTMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_phi_info);\n     }\n-  vec_oprnds.release ();\n+  if (!slp_node)\n+    *vec_stmt = STMT_VINFO_VEC_STMTS (stmt_info)[0];\n \n   return true;\n }\n@@ -7668,8 +7577,10 @@ vectorizable_induction (loop_vec_info loop_vinfo,\n       /* iv_loop is nested in the loop to be vectorized.  init_expr had already\n \t been created during vectorization of previous stmts.  We obtain it\n \t from the STMT_VINFO_VEC_STMT of the defining stmt.  */\n-      vec_init = vect_get_vec_def_for_operand (loop_vinfo,\n-\t\t\t\t\t       init_expr, stmt_info);\n+      auto_vec<tree> vec_inits;\n+      vect_get_vec_defs_for_operand (loop_vinfo, stmt_info, 1,\n+\t\t\t\t     init_expr, &vec_inits);\n+      vec_init = vec_inits[0];\n       /* If the initial value is not of proper type, convert it.  */\n       if (!useless_type_conversion_p (vectype, TREE_TYPE (vec_init)))\n \t{\n@@ -7807,7 +7718,8 @@ vectorizable_induction (loop_vec_info loop_vinfo,\n   add_phi_arg (induction_phi, vec_def, loop_latch_edge (iv_loop),\n \t       UNKNOWN_LOCATION);\n \n-  STMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = induction_phi_info;\n+  STMT_VINFO_VEC_STMTS (stmt_info).safe_push (induction_phi_info);\n+  *vec_stmt = induction_phi_info;\n \n   /* In case that vectorization factor (VF) is bigger than the number\n      of elements that we can fit in a vectype (nunits), we have to generate\n@@ -7818,7 +7730,6 @@ vectorizable_induction (loop_vec_info loop_vinfo,\n   if (ncopies > 1)\n     {\n       gimple_seq seq = NULL;\n-      stmt_vec_info prev_stmt_vinfo;\n       /* FORNOW. This restriction should be relaxed.  */\n       gcc_assert (!nested_in_vect_loop);\n \n@@ -7846,7 +7757,6 @@ vectorizable_induction (loop_vec_info loop_vinfo,\n \t\t\t\t   new_vec, step_vectype, NULL);\n \n       vec_def = induc_def;\n-      prev_stmt_vinfo = induction_phi_info;\n       for (i = 1; i < ncopies; i++)\n \t{\n \t  /* vec_i = vec_prev + vec_step  */\n@@ -7859,8 +7769,7 @@ vectorizable_induction (loop_vec_info loop_vinfo,\n \t  gsi_insert_seq_before (&si, stmts, GSI_SAME_STMT);\n \t  new_stmt = SSA_NAME_DEF_STMT (vec_def);\n \t  new_stmt_info = loop_vinfo->add_stmt (new_stmt);\n-\t  STMT_VINFO_RELATED_STMT (prev_stmt_vinfo) = new_stmt_info;\n-\t  prev_stmt_vinfo = new_stmt_info;\n+\t  STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \t}\n     }\n \n@@ -8047,14 +7956,8 @@ vectorizable_live_operation (loop_vec_info loop_vinfo,\n     }\n   else\n     {\n-      enum vect_def_type dt = STMT_VINFO_DEF_TYPE (stmt_info);\n-      vec_lhs = vect_get_vec_def_for_operand_1 (stmt_info, dt);\n-      gcc_checking_assert (ncopies == 1\n-\t\t\t   || !LOOP_VINFO_FULLY_MASKED_P (loop_vinfo));\n-\n       /* For multiple copies, get the last copy.  */\n-      for (int i = 1; i < ncopies; ++i)\n-\tvec_lhs = vect_get_vec_def_for_stmt_copy (loop_vinfo, vec_lhs);\n+      vec_lhs = gimple_get_lhs (STMT_VINFO_VEC_STMTS (stmt_info).last ()->stmt);\n \n       /* Get the last lane in the vector.  */\n       bitstart = int_const_binop (MINUS_EXPR, vec_bitsize, bitsize);"}, {"sha": "44944bf89646ac4f32d693d5f46aa8152480d16d", "filename": "gcc/tree-vect-slp.c", "status": "modified", "additions": 18, "deletions": 15, "changes": 33, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b05d5563f4be13b4a0d0951375a82adf483973c0/gcc%2Ftree-vect-slp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b05d5563f4be13b4a0d0951375a82adf483973c0/gcc%2Ftree-vect-slp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-slp.c?ref=b05d5563f4be13b4a0d0951375a82adf483973c0", "patch": "@@ -3671,6 +3671,23 @@ vect_get_slp_vect_def (slp_tree slp_node, unsigned i)\n     return SLP_TREE_VEC_DEFS (slp_node)[i];\n }\n \n+/* Get the vectorized definitions of SLP_NODE in *VEC_DEFS.  */\n+\n+void\n+vect_get_slp_defs (slp_tree slp_node, vec<tree> *vec_defs)\n+{\n+  vec_defs->create (SLP_TREE_NUMBER_OF_VEC_STMTS (slp_node));\n+  if (SLP_TREE_DEF_TYPE (slp_node) == vect_internal_def)\n+    {\n+      unsigned j;\n+      stmt_vec_info vec_def_stmt_info;\n+      FOR_EACH_VEC_ELT (SLP_TREE_VEC_STMTS (slp_node), j, vec_def_stmt_info)\n+\tvec_defs->quick_push (gimple_get_lhs (vec_def_stmt_info->stmt));\n+    }\n+  else\n+    vec_defs->splice (SLP_TREE_VEC_DEFS (slp_node));\n+}\n+\n /* Get N vectorized definitions for SLP_NODE.  */\n \n void\n@@ -3683,22 +3700,8 @@ vect_get_slp_defs (vec_info *,\n   for (unsigned i = 0; i < n; ++i)\n     {\n       slp_tree child = SLP_TREE_CHILDREN (slp_node)[i];\n-\n       vec<tree> vec_defs = vNULL;\n-\n-      /* For each operand we check if it has vectorized definitions in a child\n-\t node or we need to create them (for invariants and constants).  */\n-      vec_defs.create (SLP_TREE_NUMBER_OF_VEC_STMTS (child));\n-      if (SLP_TREE_DEF_TYPE (child) == vect_internal_def)\n-\t{\n-\t  unsigned j;\n-\t  stmt_vec_info vec_def_stmt_info;\n-\t  FOR_EACH_VEC_ELT (SLP_TREE_VEC_STMTS (child), j, vec_def_stmt_info)\n-\t    vec_defs.quick_push (gimple_get_lhs (vec_def_stmt_info->stmt));\n-\t}\n-      else\n-\tvec_defs.splice (SLP_TREE_VEC_DEFS (child));\n-\n+      vect_get_slp_defs (child, &vec_defs);\n       vec_oprnds->quick_push (vec_defs);\n     }\n }"}, {"sha": "d9db2f079ad62116e5df40d58310eb0f1d171f16", "filename": "gcc/tree-vect-stmts.c", "status": "modified", "additions": 730, "deletions": 1255, "changes": 1985, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b05d5563f4be13b4a0d0951375a82adf483973c0/gcc%2Ftree-vect-stmts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b05d5563f4be13b4a0d0951375a82adf483973c0/gcc%2Ftree-vect-stmts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-stmts.c?ref=b05d5563f4be13b4a0d0951375a82adf483973c0", "patch": "@@ -1419,76 +1419,23 @@ vect_init_vector (vec_info *vinfo, stmt_vec_info stmt_info, tree val, tree type,\n   return new_temp;\n }\n \n-/* Function vect_get_vec_def_for_operand_1.\n \n-   For a defining stmt DEF_STMT_INFO of a scalar stmt, return a vector def\n-   with type DT that will be used in the vectorized stmt.  */\n+/* Function vect_get_vec_defs_for_operand.\n \n-tree\n-vect_get_vec_def_for_operand_1 (stmt_vec_info def_stmt_info,\n-\t\t\t\tenum vect_def_type dt)\n-{\n-  tree vec_oprnd;\n-  stmt_vec_info vec_stmt_info;\n-\n-  switch (dt)\n-    {\n-    /* operand is a constant or a loop invariant.  */\n-    case vect_constant_def:\n-    case vect_external_def:\n-      /* Code should use vect_get_vec_def_for_operand.  */\n-      gcc_unreachable ();\n-\n-    /* Operand is defined by a loop header phi.  In case of nested\n-       cycles we also may have uses of the backedge def.  */\n-    case vect_reduction_def:\n-    case vect_double_reduction_def:\n-    case vect_nested_cycle:\n-    case vect_induction_def:\n-      gcc_assert (gimple_code (def_stmt_info->stmt) == GIMPLE_PHI\n-\t\t  || dt == vect_nested_cycle);\n-      /* Fallthru.  */\n-\n-    /* operand is defined inside the loop.  */\n-    case vect_internal_def:\n-      {\n-        /* Get the def from the vectorized stmt.  */\n-\tvec_stmt_info = STMT_VINFO_VEC_STMT (def_stmt_info);\n-\t/* Get vectorized pattern statement.  */\n-\tif (!vec_stmt_info\n-\t    && STMT_VINFO_IN_PATTERN_P (def_stmt_info)\n-\t    && !STMT_VINFO_RELEVANT (def_stmt_info))\n-\t  vec_stmt_info = (STMT_VINFO_VEC_STMT\n-\t\t\t   (STMT_VINFO_RELATED_STMT (def_stmt_info)));\n-\tgcc_assert (vec_stmt_info);\n-\tif (gphi *phi = dyn_cast <gphi *> (vec_stmt_info->stmt))\n-\t  vec_oprnd = PHI_RESULT (phi);\n-\telse\n-\t  vec_oprnd = gimple_get_lhs (vec_stmt_info->stmt);\n-\treturn vec_oprnd;\n-      }\n-\n-    default:\n-      gcc_unreachable ();\n-    }\n-}\n-\n-\n-/* Function vect_get_vec_def_for_operand.\n-\n-   OP is an operand in STMT_VINFO.  This function returns a (vector) def\n-   that will be used in the vectorized stmt for STMT_VINFO.\n+   OP is an operand in STMT_VINFO.  This function returns a vector of\n+   NCOPIES defs that will be used in the vectorized stmts for STMT_VINFO.\n \n    In the case that OP is an SSA_NAME which is defined in the loop, then\n-   STMT_VINFO_VEC_STMT of the defining stmt holds the relevant def.\n+   STMT_VINFO_VEC_STMTS of the defining stmt holds the relevant defs.\n \n    In case OP is an invariant or constant, a new stmt that creates a vector def\n    needs to be introduced.  VECTYPE may be used to specify a required type for\n    vector invariant.  */\n \n-tree\n-vect_get_vec_def_for_operand (vec_info *vinfo,\n-\t\t\t      tree op, stmt_vec_info stmt_vinfo, tree vectype)\n+void\n+vect_get_vec_defs_for_operand (vec_info *vinfo, stmt_vec_info stmt_vinfo,\n+\t\t\t       unsigned ncopies,\n+\t\t\t       tree op, vec<tree> *vec_oprnds, tree vectype)\n {\n   gimple *def_stmt;\n   enum vect_def_type dt;\n@@ -1497,7 +1444,7 @@ vect_get_vec_def_for_operand (vec_info *vinfo,\n \n   if (dump_enabled_p ())\n     dump_printf_loc (MSG_NOTE, vect_location,\n-\t\t     \"vect_get_vec_def_for_operand: %T\\n\", op);\n+\t\t     \"vect_get_vec_defs_for_operand: %T\\n\", op);\n \n   stmt_vec_info def_stmt_info;\n   is_simple_use = vect_is_simple_use (op, loop_vinfo, &dt,\n@@ -1506,6 +1453,7 @@ vect_get_vec_def_for_operand (vec_info *vinfo,\n   if (def_stmt && dump_enabled_p ())\n     dump_printf_loc (MSG_NOTE, vect_location, \"  def_stmt =  %G\", def_stmt);\n \n+  vec_oprnds->create (ncopies);\n   if (dt == vect_constant_def || dt == vect_external_def)\n     {\n       tree stmt_vectype = STMT_VINFO_VECTYPE (stmt_vinfo);\n@@ -1520,141 +1468,74 @@ vect_get_vec_def_for_operand (vec_info *vinfo,\n \tvector_type = get_vectype_for_scalar_type (loop_vinfo, TREE_TYPE (op));\n \n       gcc_assert (vector_type);\n-      return vect_init_vector (vinfo, stmt_vinfo, op, vector_type, NULL);\n+      tree vop = vect_init_vector (vinfo, stmt_vinfo, op, vector_type, NULL);\n+      while (ncopies--)\n+\tvec_oprnds->quick_push (vop);\n     }\n   else\n-    return vect_get_vec_def_for_operand_1 (def_stmt_info, dt);\n-}\n-\n-\n-/* Function vect_get_vec_def_for_stmt_copy\n-\n-   Return a vector-def for an operand.  This function is used when the\n-   vectorized stmt to be created (by the caller to this function) is a \"copy\"\n-   created in case the vectorized result cannot fit in one vector, and several\n-   copies of the vector-stmt are required.  In this case the vector-def is\n-   retrieved from the vector stmt recorded in the STMT_VINFO_RELATED_STMT field\n-   of the stmt that defines VEC_OPRND.  VINFO describes the vectorization.\n-\n-   Context:\n-        In case the vectorization factor (VF) is bigger than the number\n-   of elements that can fit in a vectype (nunits), we have to generate\n-   more than one vector stmt to vectorize the scalar stmt.  This situation\n-   arises when there are multiple data-types operated upon in the loop; the\n-   smallest data-type determines the VF, and as a result, when vectorizing\n-   stmts operating on wider types we need to create 'VF/nunits' \"copies\" of the\n-   vector stmt (each computing a vector of 'nunits' results, and together\n-   computing 'VF' results in each iteration).  This function is called when\n-   vectorizing such a stmt (e.g. vectorizing S2 in the illustration below, in\n-   which VF=16 and nunits=4, so the number of copies required is 4):\n-\n-   scalar stmt:         vectorized into:        STMT_VINFO_RELATED_STMT\n-\n-   S1: x = load         VS1.0:  vx.0 = memref0      VS1.1\n-                        VS1.1:  vx.1 = memref1      VS1.2\n-                        VS1.2:  vx.2 = memref2      VS1.3\n-                        VS1.3:  vx.3 = memref3\n-\n-   S2: z = x + ...      VSnew.0:  vz0 = vx.0 + ...  VSnew.1\n-                        VSnew.1:  vz1 = vx.1 + ...  VSnew.2\n-                        VSnew.2:  vz2 = vx.2 + ...  VSnew.3\n-                        VSnew.3:  vz3 = vx.3 + ...\n-\n-   The vectorization of S1 is explained in vectorizable_load.\n-   The vectorization of S2:\n-        To create the first vector-stmt out of the 4 copies - VSnew.0 -\n-   the function 'vect_get_vec_def_for_operand' is called to\n-   get the relevant vector-def for each operand of S2.  For operand x it\n-   returns  the vector-def 'vx.0'.\n-\n-        To create the remaining copies of the vector-stmt (VSnew.j), this\n-   function is called to get the relevant vector-def for each operand.  It is\n-   obtained from the respective VS1.j stmt, which is recorded in the\n-   STMT_VINFO_RELATED_STMT field of the stmt that defines VEC_OPRND.\n-\n-        For example, to obtain the vector-def 'vx.1' in order to create the\n-   vector stmt 'VSnew.1', this function is called with VEC_OPRND='vx.0'.\n-   Given 'vx0' we obtain the stmt that defines it ('VS1.0'); from the\n-   STMT_VINFO_RELATED_STMT field of 'VS1.0' we obtain the next copy - 'VS1.1',\n-   and return its def ('vx.1').\n-   Overall, to create the above sequence this function will be called 3 times:\n-\tvx.1 = vect_get_vec_def_for_stmt_copy (vinfo, vx.0);\n-\tvx.2 = vect_get_vec_def_for_stmt_copy (vinfo, vx.1);\n-\tvx.3 = vect_get_vec_def_for_stmt_copy (vinfo, vx.2);  */\n-\n-tree\n-vect_get_vec_def_for_stmt_copy (vec_info *vinfo, tree vec_oprnd)\n-{\n-  stmt_vec_info def_stmt_info = vinfo->lookup_def (vec_oprnd);\n-  if (!def_stmt_info)\n-    /* Do nothing; can reuse same def.  */\n-    return vec_oprnd;\n-\n-  def_stmt_info = STMT_VINFO_RELATED_STMT (def_stmt_info);\n-  gcc_assert (def_stmt_info);\n-  if (gphi *phi = dyn_cast <gphi *> (def_stmt_info->stmt))\n-    vec_oprnd = PHI_RESULT (phi);\n-  else\n-    vec_oprnd = gimple_get_lhs (def_stmt_info->stmt);\n-  return vec_oprnd;\n-}\n-\n-\n-/* Get vectorized definitions for the operands to create a copy of an original\n-   stmt.  See vect_get_vec_def_for_stmt_copy () for details.  */\n-\n-void\n-vect_get_vec_defs_for_stmt_copy (vec_info *vinfo,\n-\t\t\t\t vec<tree> *vec_oprnds0,\n-\t\t\t\t vec<tree> *vec_oprnds1)\n-{\n-  tree vec_oprnd = vec_oprnds0->pop ();\n-\n-  vec_oprnd = vect_get_vec_def_for_stmt_copy (vinfo, vec_oprnd);\n-  vec_oprnds0->quick_push (vec_oprnd);\n-\n-  if (vec_oprnds1 && vec_oprnds1->length ())\n     {\n-      vec_oprnd = vec_oprnds1->pop ();\n-      vec_oprnd = vect_get_vec_def_for_stmt_copy (vinfo, vec_oprnd);\n-      vec_oprnds1->quick_push (vec_oprnd);\n+      def_stmt_info = vect_stmt_to_vectorize (def_stmt_info);\n+      gcc_assert (STMT_VINFO_VEC_STMTS (def_stmt_info).length () == ncopies);\n+      for (unsigned i = 0; i < ncopies; ++i)\n+\tvec_oprnds->quick_push (gimple_get_lhs\n+\t\t\t\t  (STMT_VINFO_VEC_STMTS (def_stmt_info)[i]->stmt));\n     }\n }\n \n \n /* Get vectorized definitions for OP0 and OP1.  */\n \n void\n-vect_get_vec_defs (vec_info *vinfo, tree op0, tree op1, stmt_vec_info stmt_info,\n-\t\t   vec<tree> *vec_oprnds0,\n-\t\t   vec<tree> *vec_oprnds1,\n-\t\t   slp_tree slp_node)\n+vect_get_vec_defs (vec_info *vinfo, stmt_vec_info stmt_info, slp_tree slp_node,\n+\t\t   unsigned ncopies,\n+\t\t   tree op0, vec<tree> *vec_oprnds0, tree vectype0,\n+\t\t   tree op1, vec<tree> *vec_oprnds1, tree vectype1,\n+\t\t   tree op2, vec<tree> *vec_oprnds2, tree vectype2,\n+\t\t   tree op3, vec<tree> *vec_oprnds3, tree vectype3)\n {\n   if (slp_node)\n     {\n-      auto_vec<vec<tree> > vec_defs (SLP_TREE_CHILDREN (slp_node).length ());\n-      vect_get_slp_defs (vinfo, slp_node, &vec_defs, op1 ? 2 : 1);\n-      *vec_oprnds0 = vec_defs[0];\n+      if (op0)\n+\tvect_get_slp_defs (SLP_TREE_CHILDREN (slp_node)[0], vec_oprnds0);\n       if (op1)\n-\t*vec_oprnds1 = vec_defs[1];\n+\tvect_get_slp_defs (SLP_TREE_CHILDREN (slp_node)[1], vec_oprnds1);\n+      if (op2)\n+\tvect_get_slp_defs (SLP_TREE_CHILDREN (slp_node)[2], vec_oprnds2);\n+      if (op3)\n+\tvect_get_slp_defs (SLP_TREE_CHILDREN (slp_node)[3], vec_oprnds3);\n     }\n   else\n     {\n-      tree vec_oprnd;\n-\n-      vec_oprnds0->create (1);\n-      vec_oprnd = vect_get_vec_def_for_operand (vinfo, op0, stmt_info);\n-      vec_oprnds0->quick_push (vec_oprnd);\n-\n+      if (op0)\n+\tvect_get_vec_defs_for_operand (vinfo, stmt_info, ncopies,\n+\t\t\t\t       op0, vec_oprnds0, vectype0);\n       if (op1)\n-\t{\n-\t  vec_oprnds1->create (1);\n-\t  vec_oprnd = vect_get_vec_def_for_operand (vinfo, op1, stmt_info);\n-\t  vec_oprnds1->quick_push (vec_oprnd);\n-\t}\n+\tvect_get_vec_defs_for_operand (vinfo, stmt_info, ncopies,\n+\t\t\t\t       op1, vec_oprnds1, vectype1);\n+      if (op2)\n+\tvect_get_vec_defs_for_operand (vinfo, stmt_info, ncopies,\n+\t\t\t\t       op2, vec_oprnds2, vectype2);\n+      if (op3)\n+\tvect_get_vec_defs_for_operand (vinfo, stmt_info, ncopies,\n+\t\t\t\t       op3, vec_oprnds3, vectype3);\n     }\n }\n \n+void\n+vect_get_vec_defs (vec_info *vinfo, stmt_vec_info stmt_info, slp_tree slp_node,\n+\t\t   unsigned ncopies,\n+\t\t   tree op0, vec<tree> *vec_oprnds0,\n+\t\t   tree op1, vec<tree> *vec_oprnds1,\n+\t\t   tree op2, vec<tree> *vec_oprnds2,\n+\t\t   tree op3, vec<tree> *vec_oprnds3)\n+{\n+  vect_get_vec_defs (vinfo, stmt_info, slp_node, ncopies,\n+\t\t     op0, vec_oprnds0, NULL_TREE,\n+\t\t     op1, vec_oprnds1, NULL_TREE,\n+\t\t     op2, vec_oprnds2, NULL_TREE,\n+\t\t     op3, vec_oprnds3, NULL_TREE);\n+}\n+\n /* Helper function called by vect_finish_replace_stmt and\n    vect_finish_stmt_generation.  Set the location of the new\n    statement and create and return a stmt_vec_info for it.  */\n@@ -1664,6 +1545,7 @@ vect_finish_stmt_generation_1 (vec_info *vinfo,\n \t\t\t       stmt_vec_info stmt_info, gimple *vec_stmt)\n {\n   stmt_vec_info vec_stmt_info = vinfo->add_stmt (vec_stmt);\n+  vec_stmt_info->vector_stmt = 1;\n \n   if (dump_enabled_p ())\n     dump_printf_loc (MSG_NOTE, vect_location, \"add new stmt: %G\", vec_stmt);\n@@ -2787,18 +2669,23 @@ vect_build_gather_load_calls (vec_info *vinfo, stmt_vec_info stmt_info,\n       mask_op = vect_build_all_ones_mask (vinfo, stmt_info, masktype);\n     }\n \n+  auto_vec<tree> vec_oprnds0;\n+  auto_vec<tree> vec_masks;\n+  vect_get_vec_defs_for_operand (vinfo, stmt_info,\n+\t\t\t\t modifier == WIDEN ? ncopies / 2 : ncopies,\n+\t\t\t\t gs_info->offset, &vec_oprnds0);\n+  if (mask)\n+    vect_get_vec_defs_for_operand (vinfo, stmt_info,\n+\t\t\t\t   modifier == NARROW ? ncopies / 2 : ncopies,\n+\t\t\t\t   mask, &vec_masks);\n   for (int j = 0; j < ncopies; ++j)\n     {\n       tree op, var;\n       if (modifier == WIDEN && (j & 1))\n \top = permute_vec_elements (vinfo, vec_oprnd0, vec_oprnd0,\n \t\t\t\t   perm_mask, stmt_info, gsi);\n-      else if (j == 0)\n-\top = vec_oprnd0\n-\t  = vect_get_vec_def_for_operand (vinfo, gs_info->offset, stmt_info);\n       else\n-\top = vec_oprnd0 = vect_get_vec_def_for_stmt_copy (loop_vinfo,\n-\t\t\t\t\t\t\t  vec_oprnd0);\n+\top = vec_oprnd0 = vec_oprnds0[modifier == WIDEN ? j / 2 : j];\n \n       if (!useless_type_conversion_p (idxtype, TREE_TYPE (op)))\n \t{\n@@ -2818,11 +2705,13 @@ vect_build_gather_load_calls (vec_info *vinfo, stmt_vec_info stmt_info,\n \t\t\t\t\t    mask_perm_mask, stmt_info, gsi);\n \t  else\n \t    {\n-\t      if (j == 0)\n-\t\tvec_mask = vect_get_vec_def_for_operand (vinfo, mask, stmt_info);\n-\t      else if (modifier != NARROW || (j & 1) == 0)\n-\t\tvec_mask = vect_get_vec_def_for_stmt_copy (loop_vinfo,\n-\t\t\t\t\t\t\t   vec_mask);\n+\t      if (modifier == NARROW)\n+\t\t{\n+\t\t  if ((j & 1) == 0)\n+\t\t    vec_mask = vec_masks[j / 2];\n+\t\t}\n+\t      else\n+\t\tvec_mask = vec_masks[j];\n \n \t      mask_op = vec_mask;\n \t      if (!useless_type_conversion_p (masktype, TREE_TYPE (vec_mask)))\n@@ -2913,10 +2802,9 @@ vect_build_gather_load_calls (vec_info *vinfo, stmt_vec_info stmt_info,\n \t  new_stmt_info = loop_vinfo->lookup_def (var);\n \t}\n \n+      STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n       if (prev_stmt_info == NULL)\n-\tSTMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n-      else\n-\tSTMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n+\t*vec_stmt = new_stmt_info;\n       prev_stmt_info = new_stmt_info;\n     }\n }\n@@ -2931,7 +2819,8 @@ static void\n vect_get_gather_scatter_ops (vec_info *vinfo,\n \t\t\t     class loop *loop, stmt_vec_info stmt_info,\n \t\t\t     gather_scatter_info *gs_info,\n-\t\t\t     tree *dataref_ptr, tree *vec_offset)\n+\t\t\t     tree *dataref_ptr, vec<tree> *vec_offset,\n+\t\t\t     unsigned ncopies)\n {\n   gimple_seq stmts = NULL;\n   *dataref_ptr = force_gimple_operand (gs_info->base, &stmts, true, NULL_TREE);\n@@ -2942,8 +2831,8 @@ vect_get_gather_scatter_ops (vec_info *vinfo,\n       new_bb = gsi_insert_seq_on_edge_immediate (pe, stmts);\n       gcc_assert (!new_bb);\n     }\n-  *vec_offset = vect_get_vec_def_for_operand (vinfo, gs_info->offset, stmt_info,\n-\t\t\t\t\t      gs_info->offset_vectype);\n+  vect_get_vec_defs_for_operand (vinfo, stmt_info, ncopies, gs_info->offset,\n+\t\t\t\t vec_offset, gs_info->offset_vectype);\n }\n \n /* Prepare to implement a grouped or strided load or store using\n@@ -3085,51 +2974,36 @@ vectorizable_bswap (vec_info *vinfo,\n \n   /* Transform.  */\n   vec<tree> vec_oprnds = vNULL;\n-  stmt_vec_info new_stmt_info = NULL;\n-  stmt_vec_info prev_stmt_info = NULL;\n-  for (unsigned j = 0; j < ncopies; j++)\n-    {\n-      /* Handle uses.  */\n-      if (j == 0)\n-\tvect_get_vec_defs (vinfo, op, NULL, stmt_info, &vec_oprnds, NULL,\n-\t\t\t   slp_node);\n-      else\n-\tvect_get_vec_defs_for_stmt_copy (vinfo, &vec_oprnds, NULL);\n-\n-      /* Arguments are ready. create the new vector stmt.  */\n-      unsigned i;\n-      tree vop;\n-      FOR_EACH_VEC_ELT (vec_oprnds, i, vop)\n-       {\n-\t gimple *new_stmt;\n-\t tree tem = make_ssa_name (char_vectype);\n-\t new_stmt = gimple_build_assign (tem, build1 (VIEW_CONVERT_EXPR,\n-\t\t\t\t\t\t      char_vectype, vop));\n-\t vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n-\t tree tem2 = make_ssa_name (char_vectype);\n-\t new_stmt = gimple_build_assign (tem2, VEC_PERM_EXPR,\n-\t\t\t\t\t tem, tem, bswap_vconst);\n-\t vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n-\t tem = make_ssa_name (vectype);\n-\t new_stmt = gimple_build_assign (tem, build1 (VIEW_CONVERT_EXPR,\n-\t\t\t\t\t\t      vectype, tem2));\n-\t new_stmt_info\n-\t   = vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n-         if (slp_node)\n-\t   SLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n-       }\n-\n+  vect_get_vec_defs (vinfo, stmt_info, slp_node, ncopies,\n+\t\t     op, &vec_oprnds);\n+  /* Arguments are ready. create the new vector stmt.  */\n+  unsigned i;\n+  tree vop;\n+  FOR_EACH_VEC_ELT (vec_oprnds, i, vop)\n+    {\n+      gimple *new_stmt;\n+      tree tem = make_ssa_name (char_vectype);\n+      new_stmt = gimple_build_assign (tem, build1 (VIEW_CONVERT_EXPR,\n+\t\t\t\t\t\t   char_vectype, vop));\n+      vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n+      tree tem2 = make_ssa_name (char_vectype);\n+      new_stmt = gimple_build_assign (tem2, VEC_PERM_EXPR,\n+\t\t\t\t      tem, tem, bswap_vconst);\n+      vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n+      tem = make_ssa_name (vectype);\n+      new_stmt = gimple_build_assign (tem, build1 (VIEW_CONVERT_EXPR,\n+\t\t\t\t\t\t   vectype, tem2));\n+      stmt_vec_info new_stmt_info\n+\t= vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n       if (slp_node)\n-        continue;\n-\n-      if (j == 0)\n-\tSTMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n+\tSLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n       else\n-\tSTMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\n-      prev_stmt_info = new_stmt_info;\n+\tSTMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n     }\n \n+  if (!slp_node)\n+    *vec_stmt = STMT_VINFO_VEC_STMTS (stmt_info)[0];\n+\n   vec_oprnds.release ();\n   return true;\n }\n@@ -3177,7 +3051,6 @@ vectorizable_call (vec_info *vinfo,\n   tree scalar_dest;\n   tree op;\n   tree vec_oprnd0 = NULL_TREE, vec_oprnd1 = NULL_TREE;\n-  stmt_vec_info prev_stmt_info;\n   tree vectype_out, vectype_in;\n   poly_uint64 nunits_in;\n   poly_uint64 nunits_out;\n@@ -3461,18 +3334,17 @@ vectorizable_call (vec_info *vinfo,\n   bool masked_loop_p = loop_vinfo && LOOP_VINFO_FULLY_MASKED_P (loop_vinfo);\n \n   stmt_vec_info new_stmt_info = NULL;\n-  prev_stmt_info = NULL;\n   if (modifier == NONE || ifn != IFN_LAST)\n     {\n       tree prev_res = NULL_TREE;\n       vargs.safe_grow (nargs);\n       orig_vargs.safe_grow (nargs);\n+      auto_vec<vec<tree> > vec_defs (nargs);\n       for (j = 0; j < ncopies; ++j)\n \t{\n \t  /* Build argument list for the vectorized call.  */\n \t  if (slp_node)\n \t    {\n-\t      auto_vec<vec<tree> > vec_defs (nargs);\n \t      vec<tree> vec_oprnds0;\n \n \t      vect_get_slp_defs (vinfo, slp_node, &vec_defs);\n@@ -3538,27 +3410,19 @@ vectorizable_call (vec_info *vinfo,\n \t\t    }\n \t\t  SLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n \t\t}\n-\n-\t      for (i = 0; i < nargs; i++)\n-\t\t{\n-\t\t  vec<tree> vec_oprndsi = vec_defs[i];\n-\t\t  vec_oprndsi.release ();\n-\t\t}\n \t      continue;\n \t    }\n \n \t  for (i = 0; i < nargs; i++)\n \t    {\n \t      op = gimple_call_arg (stmt, i);\n \t      if (j == 0)\n-\t\tvec_oprnd0\n-\t\t  = vect_get_vec_def_for_operand (vinfo,\n-\t\t\t\t\t\t  op, stmt_info, vectypes[i]);\n-\t      else\n-\t\tvec_oprnd0\n-\t\t  = vect_get_vec_def_for_stmt_copy (vinfo, orig_vargs[i]);\n-\n-\t      orig_vargs[i] = vargs[i] = vec_oprnd0;\n+\t\t{\n+\t\t  vec_defs.quick_push (vNULL);\n+\t\t  vect_get_vec_defs_for_operand (vinfo, stmt_info, ncopies,\n+\t\t\t\t\t\t op, &vec_defs[i]);\n+\t\t}\n+\t      orig_vargs[i] = vargs[i] = vec_defs[i][j];\n \t    }\n \n \t  if (mask_opno >= 0 && masked_loop_p)\n@@ -3618,15 +3482,18 @@ vectorizable_call (vec_info *vinfo,\n \t    }\n \n \t  if (j == (modifier == NARROW ? 1 : 0))\n-\t    STMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n-\t  else\n-\t    STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\n-\t  prev_stmt_info = new_stmt_info;\n+\t    *vec_stmt = new_stmt_info;\n+\t  STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n+\t}\n+      for (i = 0; i < nargs; i++)\n+\t{\n+\t  vec<tree> vec_oprndsi = vec_defs[i];\n+\t  vec_oprndsi.release ();\n \t}\n     }\n   else if (modifier == NARROW)\n     {\n+      auto_vec<vec<tree> > vec_defs (nargs);\n       /* We don't define any narrowing conditional functions at present.  */\n       gcc_assert (mask_opno < 0);\n       for (j = 0; j < ncopies; ++j)\n@@ -3639,7 +3506,6 @@ vectorizable_call (vec_info *vinfo,\n \n \t  if (slp_node)\n \t    {\n-\t      auto_vec<vec<tree> > vec_defs (nargs);\n \t      vec<tree> vec_oprnds0;\n \n \t      vect_get_slp_defs (vinfo, slp_node, &vec_defs);\n@@ -3668,12 +3534,6 @@ vectorizable_call (vec_info *vinfo,\n \t\t    = vect_finish_stmt_generation (vinfo, stmt_info, call, gsi);\n \t\t  SLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n \t\t}\n-\n-\t      for (i = 0; i < nargs; i++)\n-\t\t{\n-\t\t  vec<tree> vec_oprndsi = vec_defs[i];\n-\t\t  vec_oprndsi.release ();\n-\t\t}\n \t      continue;\n \t    }\n \n@@ -3682,21 +3542,12 @@ vectorizable_call (vec_info *vinfo,\n \t      op = gimple_call_arg (stmt, i);\n \t      if (j == 0)\n \t\t{\n-\t\t  vec_oprnd0\n-\t\t    = vect_get_vec_def_for_operand (vinfo, op, stmt_info,\n-\t\t\t\t\t\t    vectypes[i]);\n-\t\t  vec_oprnd1\n-\t\t    = vect_get_vec_def_for_stmt_copy (vinfo, vec_oprnd0);\n-\t\t}\n-\t      else\n-\t\t{\n-\t\t  vec_oprnd1 = gimple_call_arg (new_stmt_info->stmt,\n-\t\t\t\t\t\t2 * i + 1);\n-\t\t  vec_oprnd0\n-\t\t    = vect_get_vec_def_for_stmt_copy (vinfo, vec_oprnd1);\n-\t\t  vec_oprnd1\n-\t\t    = vect_get_vec_def_for_stmt_copy (vinfo, vec_oprnd0);\n+\t\t  vec_defs.quick_push (vNULL);\n+\t\t  vect_get_vec_defs_for_operand (vinfo, stmt_info, 2 * ncopies,\n+\t\t\t\t\t\t op, &vec_defs[i], vectypes[i]);\n \t\t}\n+\t      vec_oprnd0 = vec_defs[i][2*j];\n+\t      vec_oprnd1 = vec_defs[i][2*j+1];\n \n \t      vargs.quick_push (vec_oprnd0);\n \t      vargs.quick_push (vec_oprnd1);\n@@ -3708,15 +3559,17 @@ vectorizable_call (vec_info *vinfo,\n \t  new_stmt_info\n \t    = vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n \n-\t  if (j == 0)\n-\t    STMT_VINFO_VEC_STMT (stmt_info) = new_stmt_info;\n-\t  else\n-\t    STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\n-\t  prev_stmt_info = new_stmt_info;\n+\t  STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \t}\n \n-      *vec_stmt = STMT_VINFO_VEC_STMT (stmt_info);\n+      if (!slp_node)\n+\t*vec_stmt = STMT_VINFO_VEC_STMTS (stmt_info)[0];\n+\n+      for (i = 0; i < nargs; i++)\n+\t{\n+\t  vec<tree> vec_oprndsi = vec_defs[i];\n+\t  vec_oprndsi.release ();\n+\t}\n     }\n   else\n     /* No current target implements this case.  */\n@@ -3849,7 +3702,6 @@ vectorizable_simd_clone_call (vec_info *vinfo, stmt_vec_info stmt_info,\n   tree scalar_dest;\n   tree op, type;\n   tree vec_oprnd0 = NULL_TREE;\n-  stmt_vec_info prev_stmt_info;\n   tree vectype;\n   unsigned int nunits;\n   loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (vinfo);\n@@ -4176,7 +4028,10 @@ vectorizable_simd_clone_call (vec_info *vinfo, stmt_vec_info stmt_info,\n \t}\n     }\n \n-  prev_stmt_info = NULL;\n+  auto_vec<vec<tree> > vec_oprnds;\n+  auto_vec<unsigned> vec_oprnds_i;\n+  vec_oprnds.safe_grow_cleared (nargs);\n+  vec_oprnds_i.safe_grow_cleared (nargs);\n   for (j = 0; j < ncopies; ++j)\n     {\n       /* Build argument list for the vectorized call.  */\n@@ -4205,15 +4060,18 @@ vectorizable_simd_clone_call (vec_info *vinfo, stmt_vec_info stmt_info,\n \t\t\t   / simd_clone_subparts (atype));\n \t\t      gcc_assert ((k & (k - 1)) == 0);\n \t\t      if (m == 0)\n-\t\t\tvec_oprnd0\n-\t\t\t  = vect_get_vec_def_for_operand (vinfo, op, stmt_info);\n+\t\t\t{\n+\t\t\t  vect_get_vec_defs_for_operand (vinfo, stmt_info,\n+\t\t\t\t\t\t\t ncopies * o / k, op,\n+\t\t\t\t\t\t\t &vec_oprnds[i]);\n+\t\t\t  vec_oprnds_i[i] = 0;\n+\t\t\t  vec_oprnd0 = vec_oprnds[i][vec_oprnds_i[i]++];\n+\t\t\t}\n \t\t      else\n \t\t\t{\n \t\t\t  vec_oprnd0 = arginfo[i].op;\n \t\t\t  if ((m & (k - 1)) == 0)\n-\t\t\t    vec_oprnd0\n-\t\t\t      = vect_get_vec_def_for_stmt_copy (vinfo,\n-\t\t\t\t\t\t\t\tvec_oprnd0);\n+\t\t\t    vec_oprnd0 = vec_oprnds[i][vec_oprnds_i[i]++];\n \t\t\t}\n \t\t      arginfo[i].op = vec_oprnd0;\n \t\t      vec_oprnd0\n@@ -4240,13 +4098,16 @@ vectorizable_simd_clone_call (vec_info *vinfo, stmt_vec_info stmt_info,\n \t\t      for (l = 0; l < k; l++)\n \t\t\t{\n \t\t\t  if (m == 0 && l == 0)\n-\t\t\t    vec_oprnd0\n-\t\t\t      = vect_get_vec_def_for_operand (vinfo,\n-\t\t\t\t\t\t\t      op, stmt_info);\n+\t\t\t    {\n+\t\t\t      vect_get_vec_defs_for_operand (vinfo, stmt_info,\n+\t\t\t\t\t\t\t     k * o * ncopies,\n+\t\t\t\t\t\t\t     op,\n+\t\t\t\t\t\t\t     &vec_oprnds[i]);\n+\t\t\t      vec_oprnds_i[i] = 0;\n+\t\t\t      vec_oprnd0 = vec_oprnds[i][vec_oprnds_i[i]++];\n+\t\t\t    }\n \t\t\t  else\n-\t\t\t    vec_oprnd0\n-\t\t\t      = vect_get_vec_def_for_stmt_copy (vinfo,\n-\t\t\t\t\t\t\t\targinfo[i].op);\n+\t\t\t    vec_oprnd0 = vec_oprnds[i][vec_oprnds_i[i]++];\n \t\t\t  arginfo[i].op = vec_oprnd0;\n \t\t\t  if (k == 1)\n \t\t\t    break;\n@@ -4390,12 +4251,8 @@ vectorizable_simd_clone_call (vec_info *vinfo, stmt_vec_info stmt_info,\n \t\t\t\t\t\t   new_stmt, gsi);\n \n \t\t  if (j == 0 && l == 0)\n-\t\t    STMT_VINFO_VEC_STMT (stmt_info)\n-\t\t      = *vec_stmt = new_stmt_info;\n-\t\t  else\n-\t\t    STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\n-\t\t  prev_stmt_info = new_stmt_info;\n+\t\t    *vec_stmt = new_stmt_info;\n+\t\t  STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \t\t}\n \n \t      if (ratype)\n@@ -4437,11 +4294,8 @@ vectorizable_simd_clone_call (vec_info *vinfo, stmt_vec_info stmt_info,\n \t\t= vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n \n \t      if ((unsigned) j == k - 1)\n-\t\tSTMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n-\t      else\n-\t\tSTMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\n-\t      prev_stmt_info = new_stmt_info;\n+\t\t*vec_stmt = new_stmt_info;\n+\t      STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \t      continue;\n \t    }\n \t  else if (ratype)\n@@ -4458,13 +4312,15 @@ vectorizable_simd_clone_call (vec_info *vinfo, stmt_vec_info stmt_info,\n \t}\n \n       if (j == 0)\n-\tSTMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n-      else\n-\tSTMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\n-      prev_stmt_info = new_stmt_info;\n+\t*vec_stmt = new_stmt_info;\n+      STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n     }\n \n+  for (i = 0; i < nargs; ++i)\n+    {\n+      vec<tree> oprndsi = vec_oprnds[i];\n+      oprndsi.release ();\n+    }\n   vargs.release ();\n \n   /* The call in STMT might prevent it from being removed in dce.\n@@ -4522,43 +4378,6 @@ vect_gen_widened_results_half (vec_info *vinfo, enum tree_code code,\n }\n \n \n-/* Get vectorized definitions for loop-based vectorization of STMT_INFO.\n-   For the first operand we call vect_get_vec_def_for_operand (with OPRND\n-   containing scalar operand), and for the rest we get a copy with\n-   vect_get_vec_def_for_stmt_copy() using the previous vector definition\n-   (stored in OPRND). See vect_get_vec_def_for_stmt_copy() for details.\n-   The vectors are collected into VEC_OPRNDS.  */\n-\n-static void\n-vect_get_loop_based_defs (vec_info *vinfo, tree *oprnd, stmt_vec_info stmt_info,\n-\t\t\t  vec<tree> *vec_oprnds, int multi_step_cvt)\n-{\n-  tree vec_oprnd;\n-\n-  /* Get first vector operand.  */\n-  /* All the vector operands except the very first one (that is scalar oprnd)\n-     are stmt copies.  */\n-  if (TREE_CODE (TREE_TYPE (*oprnd)) != VECTOR_TYPE)\n-    vec_oprnd = vect_get_vec_def_for_operand (vinfo, *oprnd, stmt_info);\n-  else\n-    vec_oprnd = vect_get_vec_def_for_stmt_copy (vinfo, *oprnd);\n-\n-  vec_oprnds->quick_push (vec_oprnd);\n-\n-  /* Get second vector operand.  */\n-  vec_oprnd = vect_get_vec_def_for_stmt_copy (vinfo, vec_oprnd);\n-  vec_oprnds->quick_push (vec_oprnd);\n-\n-  *oprnd = vec_oprnd;\n-\n-  /* For conversion in multiple steps, continue to get operands\n-     recursively.  */\n-  if (multi_step_cvt)\n-    vect_get_loop_based_defs (vinfo, oprnd, stmt_info, vec_oprnds,\n-\t\t\t      multi_step_cvt - 1);\n-}\n-\n-\n /* Create vectorized demotion statements for vector operands from VEC_OPRNDS.\n    For multi-step conversions store the resulting vectors and call the function\n    recursively.  */\n@@ -4569,8 +4388,7 @@ vect_create_vectorized_demotion_stmts (vec_info *vinfo, vec<tree> *vec_oprnds,\n \t\t\t\t       stmt_vec_info stmt_info,\n \t\t\t\t       vec<tree> vec_dsts,\n \t\t\t\t       gimple_stmt_iterator *gsi,\n-\t\t\t\t       slp_tree slp_node, enum tree_code code,\n-\t\t\t\t       stmt_vec_info *prev_stmt_info)\n+\t\t\t\t       slp_tree slp_node, enum tree_code code)\n {\n   unsigned int i;\n   tree vop0, vop1, new_tmp, vec_dest;\n@@ -4599,14 +4417,7 @@ vect_create_vectorized_demotion_stmts (vec_info *vinfo, vec<tree> *vec_oprnds,\n \t  if (slp_node)\n \t    SLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n \t  else\n-\t    {\n-\t      if (!*prev_stmt_info)\n-\t\tSTMT_VINFO_VEC_STMT (stmt_info) = new_stmt_info;\n-\t      else\n-\t\tSTMT_VINFO_RELATED_STMT (*prev_stmt_info) = new_stmt_info;\n-\n-\t      *prev_stmt_info = new_stmt_info;\n-\t    }\n+\t    STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \t}\n     }\n \n@@ -4622,8 +4433,7 @@ vect_create_vectorized_demotion_stmts (vec_info *vinfo, vec<tree> *vec_oprnds,\n       vect_create_vectorized_demotion_stmts (vinfo, vec_oprnds,\n \t\t\t\t\t     multi_step_cvt - 1,\n \t\t\t\t\t     stmt_info, vec_dsts, gsi,\n-\t\t\t\t\t     slp_node, VEC_PACK_TRUNC_EXPR,\n-\t\t\t\t\t     prev_stmt_info);\n+\t\t\t\t\t     slp_node, VEC_PACK_TRUNC_EXPR);\n     }\n \n   vec_dsts.quick_push (vec_dest);\n@@ -4699,18 +4509,16 @@ vectorizable_conversion (vec_info *vinfo,\n   tree vec_dest;\n   tree scalar_dest;\n   tree op0, op1 = NULL_TREE;\n-  tree vec_oprnd0 = NULL_TREE, vec_oprnd1 = NULL_TREE;\n   loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (vinfo);\n   enum tree_code code, code1 = ERROR_MARK, code2 = ERROR_MARK;\n   enum tree_code codecvt1 = ERROR_MARK, codecvt2 = ERROR_MARK;\n   tree new_temp;\n   enum vect_def_type dt[2] = {vect_unknown_def_type, vect_unknown_def_type};\n   int ndts = 2;\n-  stmt_vec_info prev_stmt_info;\n   poly_uint64 nunits_in;\n   poly_uint64 nunits_out;\n   tree vectype_out, vectype_in;\n-  int ncopies, i, j;\n+  int ncopies, i;\n   tree lhs_type, rhs_type;\n   enum { NARROW, NONE, WIDEN } modifier;\n   vec<tree> vec_oprnds0 = vNULL;\n@@ -4719,7 +4527,7 @@ vectorizable_conversion (vec_info *vinfo,\n   bb_vec_info bb_vinfo = dyn_cast <bb_vec_info> (vinfo);\n   int multi_step_cvt = 0;\n   vec<tree> interm_types = vNULL;\n-  tree last_oprnd, intermediate_type, cvt_type = NULL_TREE;\n+  tree intermediate_type, cvt_type = NULL_TREE;\n   int op_type;\n   unsigned short fltsz;\n \n@@ -5059,57 +4867,39 @@ vectorizable_conversion (vec_info *vinfo,\n \t\t\t\t\t    modifier == WIDEN\n \t\t\t\t\t    ? vectype_out : cvt_type);\n \n+  int ninputs = 1;\n   if (!slp_node)\n     {\n       if (modifier == WIDEN)\n+\t;\n+      else if (modifier == NARROW)\n \t{\n-\t  vec_oprnds0.create (multi_step_cvt ? vect_pow2 (multi_step_cvt) : 1);\n-\t  if (op_type == binary_op)\n-\t    vec_oprnds1.create (1);\n+\t  if (multi_step_cvt)\n+\t    ninputs = vect_pow2 (multi_step_cvt);\n+\t  ninputs *= 2;\n \t}\n-      else if (modifier == NARROW)\n-\tvec_oprnds0.create (\n-\t\t   2 * (multi_step_cvt ? vect_pow2 (multi_step_cvt) : 1));\n     }\n-  else if (code == WIDEN_LSHIFT_EXPR)\n-    vec_oprnds1.create (slp_node->vec_stmts_size);\n \n-  last_oprnd = op0;\n-  prev_stmt_info = NULL;\n   switch (modifier)\n     {\n     case NONE:\n-      for (j = 0; j < ncopies; j++)\n+      vect_get_vec_defs (vinfo, stmt_info, slp_node, ncopies,\n+\t\t\t op0, &vec_oprnds0);\n+      FOR_EACH_VEC_ELT (vec_oprnds0, i, vop0)\n \t{\n-\t  if (j == 0)\n-\t    vect_get_vec_defs (vinfo, op0, NULL, stmt_info, &vec_oprnds0,\n-\t\t\t       NULL, slp_node);\n-\t  else\n-\t    vect_get_vec_defs_for_stmt_copy (vinfo, &vec_oprnds0, NULL);\n-\n-\t  FOR_EACH_VEC_ELT (vec_oprnds0, i, vop0)\n-\t    {\n-\t      stmt_vec_info new_stmt_info;\n-\t      /* Arguments are ready, create the new vector stmt.  */\n-\t      gcc_assert (TREE_CODE_LENGTH (code1) == unary_op);\n-\t      gassign *new_stmt = gimple_build_assign (vec_dest, code1, vop0);\n-\t      new_temp = make_ssa_name (vec_dest, new_stmt);\n-\t      gimple_assign_set_lhs (new_stmt, new_temp);\n-\t      new_stmt_info\n-\t\t= vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n+\t  stmt_vec_info new_stmt_info;\n+\t  /* Arguments are ready, create the new vector stmt.  */\n+\t  gcc_assert (TREE_CODE_LENGTH (code1) == unary_op);\n+\t  gassign *new_stmt = gimple_build_assign (vec_dest, code1, vop0);\n+\t  new_temp = make_ssa_name (vec_dest, new_stmt);\n+\t  gimple_assign_set_lhs (new_stmt, new_temp);\n+\t  new_stmt_info\n+\t    = vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n \n-\t      if (slp_node)\n-\t\tSLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n-\t      else\n-\t\t{\n-\t\t  if (!prev_stmt_info)\n-\t\t    STMT_VINFO_VEC_STMT (stmt_info)\n-\t\t      = *vec_stmt = new_stmt_info;\n-\t\t  else\n-\t\t    STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\t\t  prev_stmt_info = new_stmt_info;\n-\t\t}\n-\t    }\n+\t  if (slp_node)\n+\t    SLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n+\t  else\n+\t    STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \t}\n       break;\n \n@@ -5118,154 +4908,81 @@ vectorizable_conversion (vec_info *vinfo,\n \t of elements that we can fit in a vectype (nunits), we have to\n \t generate more than one vector stmt - i.e - we need to \"unroll\"\n \t the vector stmt by a factor VF/nunits.  */\n-      for (j = 0; j < ncopies; j++)\n-\t{\n-\t  /* Handle uses.  */\n-\t  if (j == 0)\n-\t    {\n-\t      if (slp_node)\n-\t\t{\n-\t\t  if (code == WIDEN_LSHIFT_EXPR)\n-\t\t    {\n-\t\t      unsigned int k;\n-\n-\t\t      vec_oprnd1 = op1;\n-\t\t      /* Store vec_oprnd1 for every vector stmt to be created\n-\t\t\t for SLP_NODE.  We check during the analysis that all\n-\t\t\t the shift arguments are the same.  */\n-\t\t      for (k = 0; k < slp_node->vec_stmts_size - 1; k++)\n-\t\t\tvec_oprnds1.quick_push (vec_oprnd1);\n-\n-\t\t      vect_get_vec_defs (vinfo, op0, NULL_TREE, stmt_info,\n-\t\t\t\t\t &vec_oprnds0, NULL, slp_node);\n-\t\t    }\n-\t\t  else\n-\t\t    vect_get_vec_defs (vinfo, op0, op1, stmt_info, &vec_oprnds0,\n-\t\t\t\t       &vec_oprnds1, slp_node);\n-\t\t}\n-\t      else\n-\t\t{\n-\t\t  vec_oprnd0 = vect_get_vec_def_for_operand (vinfo,\n-\t\t\t\t\t\t\t     op0, stmt_info);\n-\t\t  vec_oprnds0.quick_push (vec_oprnd0);\n-\t\t  if (op_type == binary_op)\n-\t\t    {\n-\t\t      if (code == WIDEN_LSHIFT_EXPR)\n-\t\t\tvec_oprnd1 = op1;\n-\t\t      else\n-\t\t\tvec_oprnd1\n-\t\t\t  = vect_get_vec_def_for_operand (vinfo,\n-\t\t\t\t\t\t\t  op1, stmt_info);\n-\t\t      vec_oprnds1.quick_push (vec_oprnd1);\n-\t\t    }\n-\t\t}\n-\t    }\n-\t  else\n+      vect_get_vec_defs (vinfo, stmt_info, slp_node, ncopies * ninputs,\n+\t\t\t op0, &vec_oprnds0,\n+\t\t\t code == WIDEN_LSHIFT_EXPR ? NULL_TREE : op1,\n+\t\t\t &vec_oprnds1);\n+      if (code == WIDEN_LSHIFT_EXPR)\n+\t{\n+\t  vec_oprnds1.create (ncopies * ninputs);\n+\t  for (i = 0; i < ncopies * ninputs; ++i)\n+\t    vec_oprnds1.quick_push (op1);\n+\t}\n+      /* Arguments are ready.  Create the new vector stmts.  */\n+      for (i = multi_step_cvt; i >= 0; i--)\n+\t{\n+\t  tree this_dest = vec_dsts[i];\n+\t  enum tree_code c1 = code1, c2 = code2;\n+\t  if (i == 0 && codecvt2 != ERROR_MARK)\n \t    {\n-\t      vec_oprnd0 = vect_get_vec_def_for_stmt_copy (vinfo, vec_oprnd0);\n-\t      vec_oprnds0.truncate (0);\n-\t      vec_oprnds0.quick_push (vec_oprnd0);\n-\t      if (op_type == binary_op)\n-\t\t{\n-\t\t  if (code == WIDEN_LSHIFT_EXPR)\n-\t\t    vec_oprnd1 = op1;\n-\t\t  else\n-\t\t    vec_oprnd1 = vect_get_vec_def_for_stmt_copy (vinfo,\n-\t\t\t\t\t\t\t\t vec_oprnd1);\n-\t\t  vec_oprnds1.truncate (0);\n-\t\t  vec_oprnds1.quick_push (vec_oprnd1);\n-\t\t}\n+\t      c1 = codecvt1;\n+\t      c2 = codecvt2;\n \t    }\n+\t  vect_create_vectorized_promotion_stmts (vinfo, &vec_oprnds0,\n+\t\t\t\t\t\t  &vec_oprnds1, stmt_info,\n+\t\t\t\t\t\t  this_dest, gsi,\n+\t\t\t\t\t\t  c1, c2, op_type);\n+\t}\n \n-\t  /* Arguments are ready.  Create the new vector stmts.  */\n-\t  for (i = multi_step_cvt; i >= 0; i--)\n+      FOR_EACH_VEC_ELT (vec_oprnds0, i, vop0)\n+\t{\n+\t  stmt_vec_info new_stmt_info;\n+\t  if (cvt_type)\n \t    {\n-\t      tree this_dest = vec_dsts[i];\n-\t      enum tree_code c1 = code1, c2 = code2;\n-\t      if (i == 0 && codecvt2 != ERROR_MARK)\n-\t\t{\n-\t\t  c1 = codecvt1;\n-\t\t  c2 = codecvt2;\n-\t\t}\n-\t      vect_create_vectorized_promotion_stmts (vinfo, &vec_oprnds0,\n-\t\t\t\t\t\t      &vec_oprnds1, stmt_info,\n-\t\t\t\t\t\t      this_dest, gsi,\n-\t\t\t\t\t\t      c1, c2, op_type);\n+\t      gcc_assert (TREE_CODE_LENGTH (codecvt1) == unary_op);\n+\t      new_temp = make_ssa_name (vec_dest);\n+\t      gassign *new_stmt\n+\t\t= gimple_build_assign (new_temp, codecvt1, vop0);\n+\t      new_stmt_info\n+\t\t= vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n \t    }\n+\t  else\n+\t    new_stmt_info = vinfo->lookup_def (vop0);\n \n-\t  FOR_EACH_VEC_ELT (vec_oprnds0, i, vop0)\n-\t    {\n-\t      stmt_vec_info new_stmt_info;\n-\t      if (cvt_type)\n-\t\t{\n-\t\t  gcc_assert (TREE_CODE_LENGTH (codecvt1) == unary_op);\n-\t\t  new_temp = make_ssa_name (vec_dest);\n-\t\t  gassign *new_stmt\n-\t\t    = gimple_build_assign (new_temp, codecvt1, vop0);\n-\t\t  new_stmt_info\n-\t\t    = vect_finish_stmt_generation (vinfo, stmt_info,\n-\t\t\t\t\t\t   new_stmt, gsi);\n-\t\t}\n-\t      else\n-\t\tnew_stmt_info = vinfo->lookup_def (vop0);\n-\n-\t      if (slp_node)\n-\t\tSLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n-\t      else\n-\t\t{\n-\t\t  if (!prev_stmt_info)\n-\t\t    STMT_VINFO_VEC_STMT (stmt_info) = new_stmt_info;\n-\t\t  else\n-\t\t    STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\t\t  prev_stmt_info = new_stmt_info;\n-\t\t}\n-\t    }\n+\t  if (slp_node)\n+\t    SLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n+\t  else\n+\t    STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \t}\n-\n-      *vec_stmt = STMT_VINFO_VEC_STMT (stmt_info);\n       break;\n \n     case NARROW:\n       /* In case the vectorization factor (VF) is bigger than the number\n \t of elements that we can fit in a vectype (nunits), we have to\n \t generate more than one vector stmt - i.e - we need to \"unroll\"\n \t the vector stmt by a factor VF/nunits.  */\n-      for (j = 0; j < ncopies; j++)\n-\t{\n-\t  /* Handle uses.  */\n-\t  if (slp_node)\n-\t    vect_get_vec_defs (vinfo, op0, NULL_TREE, stmt_info, &vec_oprnds0,\n-\t\t\t       NULL, slp_node);\n-\t  else\n-\t    {\n-\t      vec_oprnds0.truncate (0);\n-\t      vect_get_loop_based_defs (vinfo,\n-\t\t\t\t\t&last_oprnd, stmt_info, &vec_oprnds0,\n-\t\t\t\t\tvect_pow2 (multi_step_cvt) - 1);\n-\t    }\n-\n-\t  /* Arguments are ready.  Create the new vector stmts.  */\n-\t  if (cvt_type)\n-\t    FOR_EACH_VEC_ELT (vec_oprnds0, i, vop0)\n-\t      {\n-\t\tgcc_assert (TREE_CODE_LENGTH (codecvt1) == unary_op);\n-\t\tnew_temp = make_ssa_name (vec_dest);\n-\t\tgassign *new_stmt\n-\t\t    = gimple_build_assign (new_temp, codecvt1, vop0);\n-\t\tvect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n-\t\tvec_oprnds0[i] = new_temp;\n-\t      }\n-\n-\t  vect_create_vectorized_demotion_stmts (vinfo, &vec_oprnds0,\n-\t\t\t\t\t\t multi_step_cvt,\n-\t\t\t\t\t\t stmt_info, vec_dsts, gsi,\n-\t\t\t\t\t\t slp_node, code1,\n-\t\t\t\t\t\t &prev_stmt_info);\n-\t}\n+      vect_get_vec_defs (vinfo, stmt_info, slp_node, ncopies * ninputs,\n+\t\t\t op0, &vec_oprnds0);\n+      /* Arguments are ready.  Create the new vector stmts.  */\n+      if (cvt_type)\n+\tFOR_EACH_VEC_ELT (vec_oprnds0, i, vop0)\n+\t  {\n+\t    gcc_assert (TREE_CODE_LENGTH (codecvt1) == unary_op);\n+\t    new_temp = make_ssa_name (vec_dest);\n+\t    gassign *new_stmt\n+\t      = gimple_build_assign (new_temp, codecvt1, vop0);\n+\t    vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n+\t    vec_oprnds0[i] = new_temp;\n+\t  }\n \n-      *vec_stmt = STMT_VINFO_VEC_STMT (stmt_info);\n+      vect_create_vectorized_demotion_stmts (vinfo, &vec_oprnds0,\n+\t\t\t\t\t     multi_step_cvt,\n+\t\t\t\t\t     stmt_info, vec_dsts, gsi,\n+\t\t\t\t\t     slp_node, code1);\n       break;\n     }\n+  if (!slp_node)\n+    *vec_stmt = STMT_VINFO_VEC_STMTS (stmt_info)[0];\n \n   vec_oprnds0.release ();\n   vec_oprnds1.release ();\n@@ -5319,11 +5036,10 @@ vectorizable_assignment (vec_info *vinfo,\n   enum vect_def_type dt[1] = {vect_unknown_def_type};\n   int ndts = 1;\n   int ncopies;\n-  int i, j;\n+  int i;\n   vec<tree> vec_oprnds = vNULL;\n   tree vop;\n   bb_vec_info bb_vinfo = dyn_cast <bb_vec_info> (vinfo);\n-  stmt_vec_info prev_stmt_info = NULL;\n   enum tree_code code;\n   tree vectype_in;\n \n@@ -5436,41 +5152,27 @@ vectorizable_assignment (vec_info *vinfo,\n   vec_dest = vect_create_destination_var (scalar_dest, vectype);\n \n   /* Handle use.  */\n-  for (j = 0; j < ncopies; j++)\n-    {\n-      /* Handle uses.  */\n-      if (j == 0)\n-\tvect_get_vec_defs (vinfo, op, NULL, stmt_info, &vec_oprnds, NULL,\n-\t\t\t   slp_node);\n-      else\n-\tvect_get_vec_defs_for_stmt_copy (vinfo, &vec_oprnds, NULL);\n-\n-      /* Arguments are ready. create the new vector stmt.  */\n-      stmt_vec_info new_stmt_info = NULL;\n-      FOR_EACH_VEC_ELT (vec_oprnds, i, vop)\n-       {\n-\t if (CONVERT_EXPR_CODE_P (code)\n-\t     || code == VIEW_CONVERT_EXPR)\n-\t   vop = build1 (VIEW_CONVERT_EXPR, vectype, vop);\n-\t gassign *new_stmt = gimple_build_assign (vec_dest, vop);\n-         new_temp = make_ssa_name (vec_dest, new_stmt);\n-         gimple_assign_set_lhs (new_stmt, new_temp);\n-\t new_stmt_info\n-\t   = vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n-         if (slp_node)\n-\t   SLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n-       }\n+  vect_get_vec_defs (vinfo, stmt_info, slp_node, ncopies, op, &vec_oprnds);\n \n+  /* Arguments are ready. create the new vector stmt.  */\n+  stmt_vec_info new_stmt_info = NULL;\n+  FOR_EACH_VEC_ELT (vec_oprnds, i, vop)\n+    {\n+      if (CONVERT_EXPR_CODE_P (code)\n+\t  || code == VIEW_CONVERT_EXPR)\n+\tvop = build1 (VIEW_CONVERT_EXPR, vectype, vop);\n+      gassign *new_stmt = gimple_build_assign (vec_dest, vop);\n+      new_temp = make_ssa_name (vec_dest, new_stmt);\n+      gimple_assign_set_lhs (new_stmt, new_temp);\n+      new_stmt_info\n+\t  = vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n       if (slp_node)\n-        continue;\n-\n-      if (j == 0)\n-\tSTMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n+\tSLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n       else\n-\tSTMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\n-      prev_stmt_info = new_stmt_info;\n+\tSTMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n     }\n+  if (!slp_node)\n+    *vec_stmt = STMT_VINFO_VEC_STMTS (stmt_info)[0];\n \n   vec_oprnds.release ();\n   return true;\n@@ -5540,13 +5242,12 @@ vectorizable_shift (vec_info *vinfo,\n   machine_mode optab_op2_mode;\n   enum vect_def_type dt[2] = {vect_unknown_def_type, vect_unknown_def_type};\n   int ndts = 2;\n-  stmt_vec_info prev_stmt_info;\n   poly_uint64 nunits_in;\n   poly_uint64 nunits_out;\n   tree vectype_out;\n   tree op1_vectype;\n   int ncopies;\n-  int j, i;\n+  int i;\n   vec<tree> vec_oprnds0 = vNULL;\n   vec<tree> vec_oprnds1 = vNULL;\n   tree vop0, vop1;\n@@ -5850,99 +5551,79 @@ vectorizable_shift (vec_info *vinfo,\n   /* Handle def.  */\n   vec_dest = vect_create_destination_var (scalar_dest, vectype);\n \n-  prev_stmt_info = NULL;\n-  for (j = 0; j < ncopies; j++)\n+  if (scalar_shift_arg)\n     {\n-      /* Handle uses.  */\n-      if (j == 0)\n-        {\n-          if (scalar_shift_arg)\n-            {\n-              /* Vector shl and shr insn patterns can be defined with scalar\n-                 operand 2 (shift operand).  In this case, use constant or loop\n-                 invariant op1 directly, without extending it to vector mode\n-                 first.  */\n-              optab_op2_mode = insn_data[icode].operand[2].mode;\n-              if (!VECTOR_MODE_P (optab_op2_mode))\n-                {\n-                  if (dump_enabled_p ())\n-                    dump_printf_loc (MSG_NOTE, vect_location,\n-                                     \"operand 1 using scalar mode.\\n\");\n-                  vec_oprnd1 = op1;\n-                  vec_oprnds1.create (slp_node ? slp_node->vec_stmts_size : 1);\n-                  vec_oprnds1.quick_push (vec_oprnd1);\n-                  if (slp_node)\n-                    {\n-                      /* Store vec_oprnd1 for every vector stmt to be created\n-                         for SLP_NODE.  We check during the analysis that all\n-                         the shift arguments are the same.\n-                         TODO: Allow different constants for different vector\n-                         stmts generated for an SLP instance.  */\n-                      for (k = 0; k < slp_node->vec_stmts_size - 1; k++)\n-                        vec_oprnds1.quick_push (vec_oprnd1);\n-                    }\n-                }\n-            }\n-\t  else if (slp_node && incompatible_op1_vectype_p)\n-\t    {\n-\t      if (was_scalar_shift_arg)\n-\t\t{\n-\t\t  /* If the argument was the same in all lanes create\n-\t\t     the correctly typed vector shift amount directly.  */\n-\t\t  op1 = fold_convert (TREE_TYPE (vectype), op1);\n-\t\t  op1 = vect_init_vector (vinfo, stmt_info,\n-\t\t\t\t\t  op1, TREE_TYPE (vectype),\n-\t\t\t\t\t  !loop_vinfo ? gsi : NULL);\n-\t\t  vec_oprnd1 = vect_init_vector (vinfo, stmt_info, op1, vectype,\n-\t\t\t\t\t\t !loop_vinfo ? gsi : NULL);\n-                  vec_oprnds1.create (slp_node->vec_stmts_size);\n-\t\t  for (k = 0; k < slp_node->vec_stmts_size; k++)\n-\t\t    vec_oprnds1.quick_push (vec_oprnd1);\n-\t\t}\n-\t      else if (dt[1] == vect_constant_def)\n-\t\t/* The constant shift amount has been adjusted in place.  */\n-\t\t;\n-\t      else\n-\t\tgcc_assert (TYPE_MODE (op1_vectype) == TYPE_MODE (vectype));\n-\t    }\n-\n-          /* vec_oprnd1 is available if operand 1 should be of a scalar-type\n-             (a special case for certain kind of vector shifts); otherwise,\n-             operand 1 should be of a vector type (the usual case).  */\n-          if (vec_oprnd1)\n-\t    vect_get_vec_defs (vinfo, op0, NULL_TREE, stmt_info,\n-\t\t\t       &vec_oprnds0, NULL, slp_node);\n-          else\n-\t    vect_get_vec_defs (vinfo, op0, op1, stmt_info,\n-\t\t\t       &vec_oprnds0, &vec_oprnds1, slp_node);\n-        }\n+      /* Vector shl and shr insn patterns can be defined with scalar\n+\t operand 2 (shift operand).  In this case, use constant or loop\n+\t invariant op1 directly, without extending it to vector mode\n+\t first.  */\n+      optab_op2_mode = insn_data[icode].operand[2].mode;\n+      if (!VECTOR_MODE_P (optab_op2_mode))\n+\t{\n+\t  if (dump_enabled_p ())\n+\t    dump_printf_loc (MSG_NOTE, vect_location,\n+\t\t\t     \"operand 1 using scalar mode.\\n\");\n+\t  vec_oprnd1 = op1;\n+\t  vec_oprnds1.create (slp_node ? slp_node->vec_stmts_size : ncopies);\n+\t  vec_oprnds1.quick_push (vec_oprnd1);\n+\t      /* Store vec_oprnd1 for every vector stmt to be created.\n+\t\t We check during the analysis that all the shift arguments\n+\t\t are the same.\n+\t\t TODO: Allow different constants for different vector\n+\t\t stmts generated for an SLP instance.  */\n+\t  for (k = 0;\n+\t       k < (slp_node ? slp_node->vec_stmts_size - 1 : ncopies - 1); k++)\n+\t    vec_oprnds1.quick_push (vec_oprnd1);\n+\t}\n+    }\n+  else if (slp_node && incompatible_op1_vectype_p)\n+    {\n+      if (was_scalar_shift_arg)\n+\t{\n+\t  /* If the argument was the same in all lanes create\n+\t     the correctly typed vector shift amount directly.  */\n+\t  op1 = fold_convert (TREE_TYPE (vectype), op1);\n+\t  op1 = vect_init_vector (vinfo, stmt_info, op1, TREE_TYPE (vectype),\n+\t\t\t\t  !loop_vinfo ? gsi : NULL);\n+\t  vec_oprnd1 = vect_init_vector (vinfo, stmt_info, op1, vectype,\n+\t\t\t\t\t !loop_vinfo ? gsi : NULL);\n+\t  vec_oprnds1.create (slp_node->vec_stmts_size);\n+\t  for (k = 0; k < slp_node->vec_stmts_size; k++)\n+\t    vec_oprnds1.quick_push (vec_oprnd1);\n+\t}\n+      else if (dt[1] == vect_constant_def)\n+\t/* The constant shift amount has been adjusted in place.  */\n+\t;\n       else\n-\tvect_get_vec_defs_for_stmt_copy (vinfo, &vec_oprnds0, &vec_oprnds1);\n+\tgcc_assert (TYPE_MODE (op1_vectype) == TYPE_MODE (vectype));\n+    }\n \n-      /* Arguments are ready.  Create the new vector stmt.  */\n-      stmt_vec_info new_stmt_info = NULL;\n-      FOR_EACH_VEC_ELT (vec_oprnds0, i, vop0)\n-        {\n-          vop1 = vec_oprnds1[i];\n-\t  gassign *new_stmt = gimple_build_assign (vec_dest, code, vop0, vop1);\n-          new_temp = make_ssa_name (vec_dest, new_stmt);\n-          gimple_assign_set_lhs (new_stmt, new_temp);\n-\t  new_stmt_info\n-\t    = vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n-          if (slp_node)\n-\t    SLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n-        }\n+  /* vec_oprnd1 is available if operand 1 should be of a scalar-type\n+     (a special case for certain kind of vector shifts); otherwise,\n+     operand 1 should be of a vector type (the usual case).  */\n+  vect_get_vec_defs (vinfo, stmt_info, slp_node, ncopies,\n+\t\t     op0, &vec_oprnds0,\n+\t\t     vec_oprnd1 ? NULL_TREE : op1, &vec_oprnds1);\n \n+  /* Arguments are ready.  Create the new vector stmt.  */\n+  stmt_vec_info new_stmt_info = NULL;\n+  FOR_EACH_VEC_ELT (vec_oprnds0, i, vop0)\n+    {\n+      vop1 = vec_oprnds1[i];\n+      gassign *new_stmt = gimple_build_assign (vec_dest, code, vop0, vop1);\n+      new_temp = make_ssa_name (vec_dest, new_stmt);\n+      gimple_assign_set_lhs (new_stmt, new_temp);\n+      new_stmt_info\n+\t= vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n       if (slp_node)\n-        continue;\n-\n-      if (j == 0)\n-\tSTMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n+\tSLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n       else\n-\tSTMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-      prev_stmt_info = new_stmt_info;\n+\tSTMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n     }\n \n+  if (!slp_node)\n+    *vec_stmt = STMT_VINFO_VEC_STMTS (stmt_info)[0];\n+\n   vec_oprnds0.release ();\n   vec_oprnds1.release ();\n \n@@ -5978,12 +5659,11 @@ vectorizable_operation (vec_info *vinfo,\n   enum vect_def_type dt[3]\n     = {vect_unknown_def_type, vect_unknown_def_type, vect_unknown_def_type};\n   int ndts = 3;\n-  stmt_vec_info prev_stmt_info;\n   poly_uint64 nunits_in;\n   poly_uint64 nunits_out;\n   tree vectype_out;\n   int ncopies, vec_num;\n-  int j, i;\n+  int i;\n   vec<tree> vec_oprnds0 = vNULL;\n   vec<tree> vec_oprnds1 = vNULL;\n   vec<tree> vec_oprnds2 = vNULL;\n@@ -6326,112 +6006,66 @@ vectorizable_operation (vec_info *vinfo,\n         VS1_2:  vx2 = memref2   VS1_3           -\n         VS1_3:  vx3 = memref3   -               -\n         S1:     x = load        -               VS1_0\n-        VS2_0:  vz0 = vx0 + v1  VS2_1           -\n-        VS2_1:  vz1 = vx1 + v1  VS2_2           -\n-        VS2_2:  vz2 = vx2 + v1  VS2_3           -\n-        VS2_3:  vz3 = vx3 + v1  -               -\n-        S2:     z = x + 1       -               VS2_0  */\n-\n-  prev_stmt_info = NULL;\n-  for (j = 0; j < ncopies; j++)\n-    {\n-      /* Handle uses.  */\n-      if (j == 0)\n-\t{\n-\t  if (op_type == binary_op)\n-\t    vect_get_vec_defs (vinfo, op0, op1, stmt_info,\n-\t\t\t       &vec_oprnds0, &vec_oprnds1, slp_node);\n-\t  else if (op_type == ternary_op)\n-\t    {\n-\t      if (slp_node)\n-\t\t{\n-\t\t  auto_vec<vec<tree> > vec_defs(3);\n-\t\t  vect_get_slp_defs (vinfo, slp_node, &vec_defs);\n-\t\t  vec_oprnds0 = vec_defs[0];\n-\t\t  vec_oprnds1 = vec_defs[1];\n-\t\t  vec_oprnds2 = vec_defs[2];\n-\t\t}\n-\t      else\n-\t\t{\n-\t\t  vect_get_vec_defs (vinfo, op0, op1, stmt_info, &vec_oprnds0,\n-\t\t\t\t     &vec_oprnds1, NULL);\n-\t\t  vect_get_vec_defs (vinfo, op2, NULL_TREE, stmt_info,\n-\t\t\t\t     &vec_oprnds2, NULL, NULL);\n-\t\t}\n-\t    }\n-\t  else\n-\t    vect_get_vec_defs (vinfo, op0, NULL_TREE, stmt_info, &vec_oprnds0,\n-\t\t\t       NULL, slp_node);\n-\t}\n-      else\n-\t{\n-\t  vect_get_vec_defs_for_stmt_copy (vinfo, &vec_oprnds0, &vec_oprnds1);\n-\t  if (op_type == ternary_op)\n-\t    {\n-\t      tree vec_oprnd = vec_oprnds2.pop ();\n-\t      vec_oprnds2.quick_push (vect_get_vec_def_for_stmt_copy (vinfo,\n-\t\t\t\t\t\t\t           vec_oprnd));\n-\t    }\n-\t}\n-\n-      /* Arguments are ready.  Create the new vector stmt.  */\n-      stmt_vec_info new_stmt_info = NULL;\n-      FOR_EACH_VEC_ELT (vec_oprnds0, i, vop0)\n-        {\n-\t  vop1 = ((op_type == binary_op || op_type == ternary_op)\n-\t\t  ? vec_oprnds1[i] : NULL_TREE);\n-\t  vop2 = ((op_type == ternary_op)\n-\t\t  ? vec_oprnds2[i] : NULL_TREE);\n-\t  if (masked_loop_p && reduc_idx >= 0)\n-\t    {\n-\t      /* Perform the operation on active elements only and take\n-\t\t inactive elements from the reduction chain input.  */\n-\t      gcc_assert (!vop2);\n-\t      vop2 = reduc_idx == 1 ? vop1 : vop0;\n-\t      tree mask = vect_get_loop_mask (gsi, masks, vec_num * ncopies,\n-\t\t\t\t\t      vectype, i * ncopies + j);\n-\t      gcall *call = gimple_build_call_internal (cond_fn, 4, mask,\n-\t\t\t\t\t\t\tvop0, vop1, vop2);\n-\t      new_temp = make_ssa_name (vec_dest, call);\n-\t      gimple_call_set_lhs (call, new_temp);\n-\t      gimple_call_set_nothrow (call, true);\n-\t      new_stmt_info\n-\t\t= vect_finish_stmt_generation (vinfo, stmt_info, call, gsi);\n-\t    }\n-\t  else\n+        VS2_0:  vz0 = vx0 + v1  VS2_1           -\n+        VS2_1:  vz1 = vx1 + v1  VS2_2           -\n+        VS2_2:  vz2 = vx2 + v1  VS2_3           -\n+        VS2_3:  vz3 = vx3 + v1  -               -\n+        S2:     z = x + 1       -               VS2_0  */\n+\n+  vect_get_vec_defs (vinfo, stmt_info, slp_node, ncopies,\n+\t\t     op0, &vec_oprnds0, op1, &vec_oprnds1, op2, &vec_oprnds2);\n+  /* Arguments are ready.  Create the new vector stmt.  */\n+  stmt_vec_info new_stmt_info = NULL;\n+  FOR_EACH_VEC_ELT (vec_oprnds0, i, vop0)\n+    {\n+      vop1 = ((op_type == binary_op || op_type == ternary_op)\n+\t      ? vec_oprnds1[i] : NULL_TREE);\n+      vop2 = ((op_type == ternary_op) ? vec_oprnds2[i] : NULL_TREE);\n+      if (masked_loop_p && reduc_idx >= 0)\n+\t{\n+\t  /* Perform the operation on active elements only and take\n+\t     inactive elements from the reduction chain input.  */\n+\t  gcc_assert (!vop2);\n+\t  vop2 = reduc_idx == 1 ? vop1 : vop0;\n+\t  tree mask = vect_get_loop_mask (gsi, masks, vec_num * ncopies,\n+\t\t\t\t\t  vectype, i);\n+\t  gcall *call = gimple_build_call_internal (cond_fn, 4, mask,\n+\t\t\t\t\t\t    vop0, vop1, vop2);\n+\t  new_temp = make_ssa_name (vec_dest, call);\n+\t  gimple_call_set_lhs (call, new_temp);\n+\t  gimple_call_set_nothrow (call, true);\n+\t  new_stmt_info\n+\t    = vect_finish_stmt_generation (vinfo, stmt_info, call, gsi);\n+\t}\n+      else\n+\t{\n+\t  gassign *new_stmt = gimple_build_assign (vec_dest, code,\n+\t\t\t\t\t\t   vop0, vop1, vop2);\n+\t  new_temp = make_ssa_name (vec_dest, new_stmt);\n+\t  gimple_assign_set_lhs (new_stmt, new_temp);\n+\t  new_stmt_info\n+\t    = vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n+\t  if (vec_cvt_dest)\n \t    {\n-\t      gassign *new_stmt = gimple_build_assign (vec_dest, code,\n-\t\t\t\t\t\t       vop0, vop1, vop2);\n-\t      new_temp = make_ssa_name (vec_dest, new_stmt);\n+\t      new_temp = build1 (VIEW_CONVERT_EXPR, vectype_out, new_temp);\n+\t      gassign *new_stmt\n+\t\t= gimple_build_assign (vec_cvt_dest, VIEW_CONVERT_EXPR,\n+\t\t\t\t       new_temp);\n+\t      new_temp = make_ssa_name (vec_cvt_dest, new_stmt);\n \t      gimple_assign_set_lhs (new_stmt, new_temp);\n-\t      new_stmt_info\n-\t\t= vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n-\t      if (vec_cvt_dest)\n-\t\t{\n-\t\t  new_temp = build1 (VIEW_CONVERT_EXPR, vectype_out, new_temp);\n-\t\t  gassign *new_stmt\n-\t\t    = gimple_build_assign (vec_cvt_dest, VIEW_CONVERT_EXPR,\n-\t\t\t\t\t   new_temp);\n-\t\t  new_temp = make_ssa_name (vec_cvt_dest, new_stmt);\n-\t\t  gimple_assign_set_lhs (new_stmt, new_temp);\n-\t\t  new_stmt_info = vect_finish_stmt_generation (vinfo, stmt_info,\n-\t\t\t\t\t\t\t       new_stmt, gsi);\n-\t\t}\n+\t      new_stmt_info = vect_finish_stmt_generation (vinfo, stmt_info,\n+\t\t\t\t\t\t\t   new_stmt, gsi);\n \t    }\n-          if (slp_node)\n-\t    SLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n-        }\n-\n+\t}\n       if (slp_node)\n-        continue;\n-\n-      if (j == 0)\n-\tSTMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n+\tSLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n       else\n-\tSTMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-      prev_stmt_info = new_stmt_info;\n+\tSTMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n     }\n \n+  if (!slp_node)\n+    *vec_stmt = STMT_VINFO_VEC_STMTS (stmt_info)[0];\n+\n   vec_oprnds0.release ();\n   vec_oprnds1.release ();\n   vec_oprnds2.release ();\n@@ -7189,7 +6823,6 @@ vectorizable_scan_store (vec_info *vinfo,\n \tperms[i] = vect_gen_perm_mask_checked (vectype, indices);\n     }\n \n-  stmt_vec_info prev_stmt_info = NULL;\n   tree vec_oprnd1 = NULL_TREE;\n   tree vec_oprnd2 = NULL_TREE;\n   tree vec_oprnd3 = NULL_TREE;\n@@ -7201,26 +6834,24 @@ vectorizable_scan_store (vec_info *vinfo,\n   tree orig = NULL_TREE;\n   if (STMT_VINFO_SIMD_LANE_ACCESS_P (stmt_info) == 4 && !inscan_var_store)\n     ldataref_ptr = DR_BASE_ADDRESS (load1_dr_info->dr);\n+  auto_vec<tree> vec_oprnds1;\n+  auto_vec<tree> vec_oprnds2;\n+  auto_vec<tree> vec_oprnds3;\n+  vect_get_vec_defs (vinfo, stmt_info, NULL, ncopies,\n+\t\t     *init, &vec_oprnds1,\n+\t\t     ldataref_ptr == NULL ? rhs1 : NULL, &vec_oprnds2,\n+\t\t     rhs2, &vec_oprnds3);\n   for (int j = 0; j < ncopies; j++)\n     {\n       stmt_vec_info new_stmt_info;\n+      vec_oprnd1 = vec_oprnds1[j];\n+      if (ldataref_ptr == NULL)\n+\tvec_oprnd2 = vec_oprnds2[j];\n+      vec_oprnd3 = vec_oprnds3[j];\n       if (j == 0)\n-\t{\n-\t  vec_oprnd1 = vect_get_vec_def_for_operand (vinfo, *init, stmt_info);\n-\t  if (ldataref_ptr == NULL)\n-\t    vec_oprnd2 = vect_get_vec_def_for_operand (vinfo, rhs1, stmt_info);\n-\t  vec_oprnd3 = vect_get_vec_def_for_operand (vinfo, rhs2, stmt_info);\n-\t  orig = vec_oprnd3;\n-\t}\n-      else\n-\t{\n-\t  vec_oprnd1 = vect_get_vec_def_for_stmt_copy (vinfo, vec_oprnd1);\n-\t  if (ldataref_ptr == NULL)\n-\t    vec_oprnd2 = vect_get_vec_def_for_stmt_copy (vinfo, vec_oprnd2);\n-\t  vec_oprnd3 = vect_get_vec_def_for_stmt_copy (vinfo, vec_oprnd3);\n-\t  if (!inscan_var_store)\n-\t    dataref_offset = int_const_binop (PLUS_EXPR, dataref_offset, bump);\n-\t}\n+\torig = vec_oprnd3;\n+      else if (!inscan_var_store)\n+\tdataref_offset = int_const_binop (PLUS_EXPR, dataref_offset, bump);\n \n       if (ldataref_ptr)\n \t{\n@@ -7231,11 +6862,8 @@ vectorizable_scan_store (vec_info *vinfo,\n \t  vect_copy_ref_info (data_ref, DR_REF (load1_dr_info->dr));\n \t  gimple *g = gimple_build_assign (vec_oprnd2, data_ref);\n \t  new_stmt_info = vect_finish_stmt_generation (vinfo, stmt_info, g, gsi);\n-\t  if (prev_stmt_info == NULL)\n-\t    STMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n-\t  else\n-\t    STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\t  prev_stmt_info = new_stmt_info;\n+\t  STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n+\t  *vec_stmt = STMT_VINFO_VEC_STMTS (stmt_info)[0];\n \t}\n \n       tree v = vec_oprnd2;\n@@ -7249,11 +6877,8 @@ vectorizable_scan_store (vec_info *vinfo,\n \t\t\t\t\t   ? zero_vec : vec_oprnd1, v,\n \t\t\t\t\t   perms[i]);\n \t  new_stmt_info = vect_finish_stmt_generation (vinfo, stmt_info, g, gsi);\n-\t  if (prev_stmt_info == NULL)\n-\t    STMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n-\t  else\n-\t    STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\t  prev_stmt_info = new_stmt_info;\n+\t  STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n+\t  *vec_stmt = STMT_VINFO_VEC_STMTS (stmt_info)[0];\n \n \t  if (zero_vec && use_whole_vector[i] == scan_store_kind_lshift_cond)\n \t    {\n@@ -7270,8 +6895,7 @@ vectorizable_scan_store (vec_info *vinfo,\n \t\t\t\t       new_temp, vec_oprnd1);\n \t      new_stmt_info = vect_finish_stmt_generation (vinfo, stmt_info,\n \t\t\t\t\t\t\t   g, gsi);\n-\t      STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\t      prev_stmt_info = new_stmt_info;\n+\t      STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \t      new_temp = new_temp2;\n \t    }\n \n@@ -7289,17 +6913,15 @@ vectorizable_scan_store (vec_info *vinfo,\n \t  tree new_temp2 = make_ssa_name (vectype);\n \t  g = gimple_build_assign (new_temp2, code, v, new_temp);\n \t  new_stmt_info = vect_finish_stmt_generation (vinfo, stmt_info, g, gsi);\n-\t  STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\t  prev_stmt_info = new_stmt_info;\n+\t  STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \n \t  v = new_temp2;\n \t}\n \n       tree new_temp = make_ssa_name (vectype);\n       gimple *g = gimple_build_assign (new_temp, code, orig, v);\n       new_stmt_info = vect_finish_stmt_generation (vinfo, stmt_info, g, gsi);\n-      STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-      prev_stmt_info = new_stmt_info;\n+      STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \n       tree last_perm_arg = new_temp;\n       /* For exclusive scan, new_temp computed above is the exclusive scan\n@@ -7310,16 +6932,14 @@ vectorizable_scan_store (vec_info *vinfo,\n \t  last_perm_arg = make_ssa_name (vectype);\n \t  g = gimple_build_assign (last_perm_arg, code, new_temp, vec_oprnd2);\n \t  new_stmt_info = vect_finish_stmt_generation (vinfo, stmt_info, g, gsi);\n-\t  STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\t  prev_stmt_info = new_stmt_info;\n+\t  STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \t}\n \n       orig = make_ssa_name (vectype);\n       g = gimple_build_assign (orig, VEC_PERM_EXPR, last_perm_arg,\n \t\t\t       last_perm_arg, perms[units_log2]);\n       new_stmt_info = vect_finish_stmt_generation (vinfo, stmt_info, g, gsi);\n-      STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-      prev_stmt_info = new_stmt_info;\n+      STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \n       if (!inscan_var_store)\n \t{\n@@ -7329,8 +6949,7 @@ vectorizable_scan_store (vec_info *vinfo,\n \t  vect_copy_ref_info (data_ref, DR_REF (dr_info->dr));\n \t  g = gimple_build_assign (data_ref, new_temp);\n \t  new_stmt_info = vect_finish_stmt_generation (vinfo, stmt_info, g, gsi);\n-\t  STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\t  prev_stmt_info = new_stmt_info;\n+\t  STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \t}\n     }\n \n@@ -7347,8 +6966,7 @@ vectorizable_scan_store (vec_info *vinfo,\n \tgimple *g = gimple_build_assign (data_ref, orig);\n \tstmt_vec_info new_stmt_info\n \t  = vect_finish_stmt_generation (vinfo, stmt_info, g, gsi);\n-\tSTMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\tprev_stmt_info = new_stmt_info;\n+\tSTMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n       }\n   return true;\n }\n@@ -7379,7 +6997,6 @@ vectorizable_store (vec_info *vinfo,\n   enum dr_alignment_support alignment_support_scheme;\n   enum vect_def_type rhs_dt = vect_unknown_def_type;\n   enum vect_def_type mask_dt = vect_unknown_def_type;\n-  stmt_vec_info prev_stmt_info = NULL;\n   tree dataref_ptr = NULL_TREE;\n   tree dataref_offset = NULL_TREE;\n   gimple *ptr_incr = NULL;\n@@ -7668,57 +7285,55 @@ vectorizable_store (vec_info *vinfo,\n \n       scale = build_int_cst (scaletype, gs_info.scale);\n \n-      prev_stmt_info = NULL;\n+      auto_vec<tree> vec_oprnds0;\n+      auto_vec<tree> vec_oprnds1;\n+      auto_vec<tree> vec_masks;\n+      if (mask)\n+\t{\n+\t  tree mask_vectype = truth_type_for (vectype);\n+\t  vect_get_vec_defs_for_operand (vinfo, stmt_info,\n+\t\t\t\t\t modifier == NARROW\n+\t\t\t\t\t ? ncopies / 2 : ncopies,\n+\t\t\t\t\t mask, &vec_masks, mask_vectype);\n+\t}\n+      vect_get_vec_defs_for_operand (vinfo, stmt_info,\n+\t\t\t\t     modifier == WIDEN\n+\t\t\t\t     ? ncopies / 2 : ncopies,\n+\t\t\t\t     gs_info.offset, &vec_oprnds0);\n+      vect_get_vec_defs_for_operand (vinfo, stmt_info,\n+\t\t\t\t     modifier == NARROW\n+\t\t\t\t     ? ncopies / 2 : ncopies,\n+\t\t\t\t     op, &vec_oprnds1);\n       for (j = 0; j < ncopies; ++j)\n \t{\n-\t  if (j == 0)\n+\t  if (modifier == WIDEN)\n \t    {\n-\t      src = vec_oprnd1 = vect_get_vec_def_for_operand (vinfo,\n-\t\t\t\t\t\t\t       op, stmt_info);\n-\t      op = vec_oprnd0 = vect_get_vec_def_for_operand (vinfo,\n-\t\t\t\t\t\t\t      gs_info.offset,\n-\t\t\t\t\t\t\t      stmt_info);\n+\t      if (j & 1)\n+\t\top = permute_vec_elements (vinfo, vec_oprnd0, vec_oprnd0,\n+\t\t\t\t\t   perm_mask, stmt_info, gsi);\n+\t      else\n+\t\top = vec_oprnd0 = vec_oprnds0[j / 2];\n+\t      src = vec_oprnd1 = vec_oprnds1[j];\n \t      if (mask)\n-\t\t{\n-\t\t  tree mask_vectype = truth_type_for (vectype);\n-\t\t  mask_op = vec_mask\n-\t\t    = vect_get_vec_def_for_operand (vinfo, mask,\n-\t\t\t\t\t\t    stmt_info, mask_vectype);\n-\t\t}\n+\t\tmask_op = vec_mask = vec_masks[j];\n \t    }\n-\t  else if (modifier != NONE && (j & 1))\n+\t  else if (modifier == NARROW)\n \t    {\n-\t      if (modifier == WIDEN)\n-\t\t{\n-\t\t  src\n-\t\t    = vec_oprnd1 = vect_get_vec_def_for_stmt_copy (vinfo,\n-\t\t\t\t\t\t\t\t   vec_oprnd1);\n-\t\t  op = permute_vec_elements (vinfo, vec_oprnd0, vec_oprnd0,\n-\t\t\t\t\t     perm_mask, stmt_info, gsi);\n-\t\t  if (mask)\n-\t\t    mask_op\n-\t\t      = vec_mask = vect_get_vec_def_for_stmt_copy (vinfo,\n-\t\t\t\t\t\t\t\t   vec_mask);\n-\t\t}\n-\t      else if (modifier == NARROW)\n-\t\t{\n-\t\t  src = permute_vec_elements (vinfo, vec_oprnd1, vec_oprnd1,\n-\t\t\t\t\t      perm_mask, stmt_info, gsi);\n-\t\t  op = vec_oprnd0 = vect_get_vec_def_for_stmt_copy (vinfo,\n-\t\t\t\t\t\t\t\t    vec_oprnd0);\n-\t\t}\n+\t      if (j & 1)\n+\t\tsrc = permute_vec_elements (vinfo, vec_oprnd1, vec_oprnd1,\n+\t\t\t\t\t    perm_mask, stmt_info, gsi);\n \t      else\n-\t\tgcc_unreachable ();\n+\t\tsrc = vec_oprnd1 = vec_oprnds1[j / 2];\n+\t      op = vec_oprnd0 = vec_oprnds0[j];\n+\t      if (mask)\n+\t\tmask_op = vec_mask = vec_masks[j / 2];\n \t    }\n \t  else\n \t    {\n-\t      src = vec_oprnd1 = vect_get_vec_def_for_stmt_copy (vinfo,\n-\t\t\t\t\t\t\t\t vec_oprnd1);\n-\t      op = vec_oprnd0 = vect_get_vec_def_for_stmt_copy (vinfo,\n-\t\t\t\t\t\t\t\tvec_oprnd0);\n+\t      op = vec_oprnd0 = vec_oprnds0[j];\n+\t      src = vec_oprnd1 = vec_oprnds1[j];\n \t      if (mask)\n-\t\tmask_op = vec_mask = vect_get_vec_def_for_stmt_copy (vinfo,\n-\t\t\t\t\t\t\t\t     vec_mask);\n+\t\tmask_op = vec_mask = vec_masks[j];\n \t    }\n \n \t  if (!useless_type_conversion_p (srctype, TREE_TYPE (src)))\n@@ -7787,12 +7402,9 @@ vectorizable_store (vec_info *vinfo,\n \t  stmt_vec_info new_stmt_info\n \t    = vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n \n-\t  if (prev_stmt_info == NULL)\n-\t    STMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n-\t  else\n-\t    STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\t  prev_stmt_info = new_stmt_info;\n+\t  STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \t}\n+      *vec_stmt = STMT_VINFO_VEC_STMTS (stmt_info)[0];\n       return true;\n     }\n   else if (STMT_VINFO_SIMD_LANE_ACCESS_P (stmt_info) >= 3)\n@@ -7972,7 +7584,6 @@ vectorizable_store (vec_info *vinfo,\n \n       stride_step = cse_and_gimplify_to_preheader (loop_vinfo, stride_step);\n \n-      prev_stmt_info = NULL;\n       alias_off = build_int_cst (ref_type, 0);\n       stmt_vec_info next_stmt_info = first_stmt_info;\n       for (g = 0; g < group_size; g++)\n@@ -7989,36 +7600,16 @@ vectorizable_store (vec_info *vinfo,\n \t      vect_finish_stmt_generation (vinfo, stmt_info, incr, gsi);\n \t      running_off = newoff;\n \t    }\n+\t  if (!slp)\n+\t    op = vect_get_store_rhs (next_stmt_info);\n+\t  vect_get_vec_defs (vinfo, next_stmt_info, slp_node, ncopies,\n+\t\t\t     op, &vec_oprnds);\n \t  unsigned int group_el = 0;\n \t  unsigned HOST_WIDE_INT\n \t    elsz = tree_to_uhwi (TYPE_SIZE_UNIT (TREE_TYPE (vectype)));\n \t  for (j = 0; j < ncopies; j++)\n \t    {\n-\t      /* We've set op and dt above, from vect_get_store_rhs,\n-\t\t and first_stmt_info == stmt_info.  */\n-\t      if (j == 0)\n-\t\t{\n-\t\t  if (slp)\n-\t\t    {\n-\t\t      vect_get_vec_defs (vinfo, op, NULL_TREE, stmt_info,\n-\t\t\t\t\t &vec_oprnds, NULL, slp_node);\n-\t\t      vec_oprnd = vec_oprnds[0];\n-\t\t    }\n-\t\t  else\n-\t\t    {\n-\t\t      op = vect_get_store_rhs (next_stmt_info);\n-\t\t      vec_oprnd = vect_get_vec_def_for_operand\n-\t\t\t(vinfo, op, next_stmt_info);\n-\t\t    }\n-\t\t}\n-\t      else\n-\t\t{\n-\t\t  if (slp)\n-\t\t    vec_oprnd = vec_oprnds[j];\n-\t\t  else\n-\t\t    vec_oprnd = vect_get_vec_def_for_stmt_copy (vinfo,\n-\t\t\t\t\t\t\t\tvec_oprnd);\n-\t\t}\n+\t      vec_oprnd = vec_oprnds[j];\n \t      /* Pun the vector to extract from if necessary.  */\n \t      if (lvectype != vectype)\n \t\t{\n@@ -8072,11 +7663,8 @@ vectorizable_store (vec_info *vinfo,\n \t\t      && !slp)\n \t\t    {\n \t\t      if (j == 0 && i == 0)\n-\t\t\tSTMT_VINFO_VEC_STMT (stmt_info)\n-\t\t\t    = *vec_stmt = assign_info;\n-\t\t      else\n-\t\t\tSTMT_VINFO_RELATED_STMT (prev_stmt_info) = assign_info;\n-\t\t      prev_stmt_info = assign_info;\n+\t\t\t*vec_stmt = assign_info;\n+\t\t      STMT_VINFO_VEC_STMTS (stmt_info).safe_push (assign_info);\n \t\t    }\n \t\t}\n \t    }\n@@ -8147,8 +7735,7 @@ vectorizable_store (vec_info *vinfo,\n   /* In case the vectorization factor (VF) is bigger than the number\n      of elements that we can fit in a vectype (nunits), we have to generate\n      more than one vector stmt - i.e - we need to \"unroll\" the\n-     vector stmt by a factor VF/nunits.  For more details see documentation in\n-     vect_get_vec_def_for_copy_stmt.  */\n+     vector stmt by a factor VF/nunits.  */\n \n   /* In case of interleaving (non-unit grouped access):\n \n@@ -8183,8 +7770,11 @@ vectorizable_store (vec_info *vinfo,\n      STMT_VINFO_RELATED_STMT for the next copies.\n   */\n \n-  prev_stmt_info = NULL;\n-  tree vec_mask = NULL_TREE;\n+  auto_vec<tree> vec_masks;\n+  tree vec_mask = NULL;\n+  auto_vec<tree> vec_offsets;\n+  auto_vec<vec<tree> > gvec_oprnds;\n+  gvec_oprnds.safe_grow_cleared (group_size);\n   for (j = 0; j < ncopies; j++)\n     {\n       stmt_vec_info new_stmt_info;\n@@ -8193,20 +7783,18 @@ vectorizable_store (vec_info *vinfo,\n           if (slp)\n             {\n \t      /* Get vectorized arguments for SLP_NODE.  */\n-\t      vect_get_vec_defs (vinfo, op, NULL_TREE, stmt_info, &vec_oprnds,\n-\t\t\t\t NULL, slp_node);\n-\n+\t      vect_get_vec_defs (vinfo, stmt_info, slp_node, 1,\n+\t\t\t\t op, &vec_oprnds);\n               vec_oprnd = vec_oprnds[0];\n             }\n           else\n             {\n \t      /* For interleaved stores we collect vectorized defs for all the\n \t\t stores in the group in DR_CHAIN and OPRNDS. DR_CHAIN is then\n-\t\t used as an input to vect_permute_store_chain(), and OPRNDS as\n-\t\t an input to vect_get_vec_def_for_stmt_copy() for the next copy.\n+\t\t used as an input to vect_permute_store_chain().\n \n-\t\t If the store is not grouped, DR_GROUP_SIZE is 1, and DR_CHAIN and\n-\t\t OPRNDS are of size 1.  */\n+\t\t If the store is not grouped, DR_GROUP_SIZE is 1, and DR_CHAIN\n+\t\t and OPRNDS are of size 1.  */\n \t      stmt_vec_info next_stmt_info = first_stmt_info;\n \t      for (i = 0; i < group_size; i++)\n \t\t{\n@@ -8216,15 +7804,19 @@ vectorizable_store (vec_info *vinfo,\n \t\t     that there is no interleaving, DR_GROUP_SIZE is 1,\n \t\t     and only one iteration of the loop will be executed.  */\n \t\t  op = vect_get_store_rhs (next_stmt_info);\n-\t\t  vec_oprnd = vect_get_vec_def_for_operand\n-\t\t    (vinfo, op, next_stmt_info);\n-\t\t  dr_chain.quick_push (vec_oprnd);\n-\t\t  oprnds.quick_push (vec_oprnd);\n+\t\t  vect_get_vec_defs_for_operand (vinfo, next_stmt_info,\n+\t\t\t\t\t\t ncopies, op, &gvec_oprnds[i]);\n+\t\t  vec_oprnd = gvec_oprnds[i][0];\n+\t\t  dr_chain.quick_push (gvec_oprnds[i][0]);\n+\t\t  oprnds.quick_push (gvec_oprnds[i][0]);\n \t\t  next_stmt_info = DR_GROUP_NEXT_ELEMENT (next_stmt_info);\n \t\t}\n \t      if (mask)\n-\t\tvec_mask = vect_get_vec_def_for_operand (vinfo, mask, stmt_info,\n-\t\t\t\t\t\t\t mask_vectype);\n+\t\t{\n+\t\t  vect_get_vec_defs_for_operand (vinfo, stmt_info, ncopies,\n+\t\t\t\t\t\t mask, &vec_masks, mask_vectype);\n+\t\t  vec_mask = vec_masks[0];\n+\t\t}\n \t    }\n \n \t  /* We should have catched mismatched types earlier.  */\n@@ -8245,8 +7837,11 @@ vectorizable_store (vec_info *vinfo,\n \t      dataref_offset = build_int_cst (ref_type, 0);\n \t    }\n \t  else if (STMT_VINFO_GATHER_SCATTER_P (stmt_info))\n-\t    vect_get_gather_scatter_ops (vinfo, loop, stmt_info, &gs_info,\n-\t\t\t\t\t &dataref_ptr, &vec_offset);\n+\t    {\n+\t      vect_get_gather_scatter_ops (vinfo, loop, stmt_info, &gs_info,\n+\t\t\t\t\t   &dataref_ptr, &vec_offsets, ncopies);\n+\t      vec_offset = vec_offsets[0];\n+\t    }\n \t  else\n \t    dataref_ptr\n \t      = vect_create_data_ref_ptr (vinfo, first_stmt_info, aggr_type,\n@@ -8258,25 +7853,22 @@ vectorizable_store (vec_info *vinfo,\n \t{\n \t  /* For interleaved stores we created vectorized defs for all the\n \t     defs stored in OPRNDS in the previous iteration (previous copy).\n-\t     DR_CHAIN is then used as an input to vect_permute_store_chain(),\n-\t     and OPRNDS as an input to vect_get_vec_def_for_stmt_copy() for the\n-\t     next copy.\n+\t     DR_CHAIN is then used as an input to vect_permute_store_chain().\n \t     If the store is not grouped, DR_GROUP_SIZE is 1, and DR_CHAIN and\n \t     OPRNDS are of size 1.  */\n \t  for (i = 0; i < group_size; i++)\n \t    {\n-\t      op = oprnds[i];\n-\t      vec_oprnd = vect_get_vec_def_for_stmt_copy (vinfo, op);\n-\t      dr_chain[i] = vec_oprnd;\n-\t      oprnds[i] = vec_oprnd;\n+\t      vec_oprnd = gvec_oprnds[i][j];\n+\t      dr_chain[i] = gvec_oprnds[i][j];\n+\t      oprnds[i] = gvec_oprnds[i][j];\n \t    }\n \t  if (mask)\n-\t    vec_mask = vect_get_vec_def_for_stmt_copy (vinfo, vec_mask);\n+\t    vec_mask = vec_masks[j];\n \t  if (dataref_offset)\n \t    dataref_offset\n \t      = int_const_binop (PLUS_EXPR, dataref_offset, bump);\n \t  else if (STMT_VINFO_GATHER_SCATTER_P (stmt_info))\n-\t    vec_offset = vect_get_vec_def_for_stmt_copy (vinfo, vec_offset);\n+\t    vec_offset = vec_offsets[j];\n \t  else\n \t    dataref_ptr = bump_vector_ptr (vinfo, dataref_ptr, ptr_incr, gsi,\n \t\t\t\t\t   stmt_info, bump);\n@@ -8475,13 +8067,16 @@ vectorizable_store (vec_info *vinfo,\n       if (!slp)\n \t{\n \t  if (j == 0)\n-\t    STMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n-\t  else\n-\t    STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\t  prev_stmt_info = new_stmt_info;\n+\t    *vec_stmt = new_stmt_info;\n+\t  STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \t}\n     }\n \n+  for (i = 0; i < group_size; ++i)\n+    {\n+      vec<tree> oprndsi = gvec_oprnds[i];\n+      oprndsi.release ();\n+    }\n   oprnds.release ();\n   result_chain.release ();\n   vec_oprnds.release ();\n@@ -8616,7 +8211,6 @@ vectorizable_load (vec_info *vinfo,\n   tree scalar_dest;\n   tree vec_dest = NULL;\n   tree data_ref = NULL;\n-  stmt_vec_info prev_stmt_info;\n   loop_vec_info loop_vinfo = dyn_cast <loop_vec_info> (vinfo);\n   class loop *loop = NULL;\n   class loop *containing_loop = gimple_bb (stmt_info->stmt)->loop_father;\n@@ -8937,7 +8531,6 @@ vectorizable_load (vec_info *vinfo,\n \t}\n       /* These copies are all equivalent, but currently the representation\n \t requires a separate STMT_VINFO_VEC_STMT for each one.  */\n-      prev_stmt_info = NULL;\n       gimple_stmt_iterator gsi2 = *gsi;\n       gsi_next (&gsi2);\n       for (j = 0; j < ncopies; j++)\n@@ -8958,11 +8551,12 @@ vectorizable_load (vec_info *vinfo,\n \t    }\n \t  if (slp)\n \t    SLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n-\t  else if (j == 0)\n-\t    STMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n \t  else\n-\t    STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\t  prev_stmt_info = new_stmt_info;\n+\t    {\n+\t      if (j == 0)\n+\t\t*vec_stmt = new_stmt_info;\n+\t      STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n+\t    }\n \t}\n       return true;\n     }\n@@ -9052,7 +8646,6 @@ vectorizable_load (vec_info *vinfo,\n \n       stride_step = cse_and_gimplify_to_preheader (loop_vinfo, stride_step);\n \n-      prev_stmt_info = NULL;\n       running_off = offvar;\n       alias_off = build_int_cst (ref_type, 0);\n       int nloads = const_nunits;\n@@ -9176,10 +8769,8 @@ vectorizable_load (vec_info *vinfo,\n \t  else\n \t    {\n \t      if (j == 0)\n-\t\tSTMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n-\t      else\n-\t\tSTMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\t      prev_stmt_info = new_stmt_info;\n+\t\t*vec_stmt = new_stmt_info;\n+\t      STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \t    }\n \t}\n       if (slp_perm)\n@@ -9209,7 +8800,7 @@ vectorizable_load (vec_info *vinfo,\n \tfirst_stmt_info_for_drptr = SLP_TREE_SCALAR_STMTS (slp_node)[0];\n \n       /* Check if the chain of loads is already vectorized.  */\n-      if (STMT_VINFO_VEC_STMT (first_stmt_info)\n+      if (STMT_VINFO_VEC_STMTS (first_stmt_info).exists ()\n \t  /* For SLP we would need to copy over SLP_TREE_VEC_STMTS.\n \t     ???  But we can only do so if there is exactly one\n \t     as we have no way to get at the rest.  Leave the CSE\n@@ -9220,7 +8811,7 @@ vectorizable_load (vec_info *vinfo,\n \t     is even wrong code.  See PR56270.  */\n \t  && !slp)\n \t{\n-\t  *vec_stmt = STMT_VINFO_VEC_STMT (stmt_info);\n+\t  *vec_stmt = STMT_VINFO_VEC_STMTS (stmt_info)[0];\n \t  return true;\n \t}\n       first_dr_info = STMT_VINFO_DR_INFO (first_stmt_info);\n@@ -9321,10 +8912,7 @@ vectorizable_load (vec_info *vinfo,\n         VS1_3:  vx3 = memref3   -               -\n         S1:     x = load        -               VS1_0\n         S2:     z = x + 1       -               -\n-\n-     See in documentation in vect_get_vec_def_for_stmt_copy for how the\n-     information we recorded in RELATED_STMT field is used to vectorize\n-     stmt S2.  */\n+  */\n \n   /* In case of interleaving (non-unit grouped access):\n \n@@ -9455,8 +9043,12 @@ vectorizable_load (vec_info *vinfo,\n \t\t\t\t\t  memory_access_type);\n     }\n \n+  vec<tree> vec_offsets = vNULL;\n+  auto_vec<tree> vec_masks;\n+  if (mask)\n+    vect_get_vec_defs (vinfo, stmt_info, slp_node, ncopies,\n+\t\t       mask, &vec_masks, mask_vectype, NULL_TREE);\n   tree vec_mask = NULL_TREE;\n-  prev_stmt_info = NULL;\n   poly_uint64 group_elt = 0;\n   for (j = 0; j < ncopies; j++)\n     {\n@@ -9507,8 +9099,11 @@ vectorizable_load (vec_info *vinfo,\n \t\t}\n \t    }\n \t  else if (STMT_VINFO_GATHER_SCATTER_P (stmt_info))\n-\t    vect_get_gather_scatter_ops (vinfo, loop, stmt_info, &gs_info,\n-\t\t\t\t\t &dataref_ptr, &vec_offset);\n+\t    {\n+\t      vect_get_gather_scatter_ops (vinfo, loop, stmt_info, &gs_info,\n+\t\t\t\t\t   &dataref_ptr, &vec_offsets, ncopies);\n+\t      vec_offset = vec_offsets[0];\n+\t    }\n \t  else\n \t    dataref_ptr\n \t      = vect_create_data_ref_ptr (vinfo, first_stmt_info, aggr_type,\n@@ -9517,30 +9112,20 @@ vectorizable_load (vec_info *vinfo,\n \t\t\t\t\t  simd_lane_access_p,\n \t\t\t\t\t  byte_offset, bump);\n \t  if (mask)\n-\t    {\n-\t      if (slp_node)\n-\t\t{\n-\t\t  auto_vec<vec<tree> > vec_defs (1);\n-\t\t  vect_get_slp_defs (vinfo, slp_node, &vec_defs);\n-\t\t  vec_mask = vec_defs[0][0];\n-\t\t}\n-\t      else\n-\t\tvec_mask = vect_get_vec_def_for_operand (vinfo, mask, stmt_info,\n-\t\t\t\t\t\t\t mask_vectype);\n-\t    }\n+\t    vec_mask = vec_masks[0];\n \t}\n       else\n \t{\n \t  if (dataref_offset)\n \t    dataref_offset = int_const_binop (PLUS_EXPR, dataref_offset,\n \t\t\t\t\t      bump);\n \t  else if (STMT_VINFO_GATHER_SCATTER_P (stmt_info))\n-\t    vec_offset = vect_get_vec_def_for_stmt_copy (vinfo, vec_offset);\n+\t    vec_offset = vec_offsets[j];\n \t  else\n \t    dataref_ptr = bump_vector_ptr (vinfo, dataref_ptr, ptr_incr, gsi,\n \t\t\t\t\t   stmt_info, bump);\n \t  if (mask)\n-\t    vec_mask = vect_get_vec_def_for_stmt_copy (vinfo, vec_mask);\n+\t    vec_mask = vec_masks[j];\n \t}\n \n       if (grouped_load || slp_perm)\n@@ -9960,15 +9545,13 @@ vectorizable_load (vec_info *vinfo,\n \t      if (memory_access_type != VMAT_LOAD_STORE_LANES)\n \t\tvect_transform_grouped_load (vinfo, stmt_info, dr_chain,\n \t\t\t\t\t     group_size, gsi);\n-\t      *vec_stmt = STMT_VINFO_VEC_STMT (stmt_info);\n+\t      *vec_stmt = STMT_VINFO_VEC_STMTS (stmt_info)[0];\n \t    }\n           else\n \t    {\n \t      if (j == 0)\n-\t        STMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n-\t      else\n-\t        STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\t      prev_stmt_info = new_stmt_info;\n+\t\t*vec_stmt = new_stmt_info;\n+\t      STMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n \t    }\n         }\n       dr_chain.release ();\n@@ -10104,8 +9687,7 @@ vectorizable_condition (vec_info *vinfo,\n   int ncopies;\n   int vec_num;\n   enum tree_code code, cond_code, bitop1 = NOP_EXPR, bitop2 = NOP_EXPR;\n-  stmt_vec_info prev_stmt_info = NULL;\n-  int i, j;\n+  int i;\n   bb_vec_info bb_vinfo = dyn_cast <bb_vec_info> (vinfo);\n   vec<tree> vec_oprnds0 = vNULL;\n   vec<tree> vec_oprnds1 = vNULL;\n@@ -10354,258 +9936,202 @@ vectorizable_condition (vec_info *vinfo,\n   if (reduction_type != EXTRACT_LAST_REDUCTION)\n     vec_dest = vect_create_destination_var (scalar_dest, vectype);\n \n-  /* Handle cond expr.  */\n-  for (j = 0; j < ncopies; j++)\n-    {\n-      bool swap_cond_operands = false;\n+  bool swap_cond_operands = false;\n \n-      /* See whether another part of the vectorized code applies a loop\n-\t mask to the condition, or to its inverse.  */\n+  /* See whether another part of the vectorized code applies a loop\n+     mask to the condition, or to its inverse.  */\n \n-      vec_loop_masks *masks = NULL;\n-      if (loop_vinfo && LOOP_VINFO_FULLY_MASKED_P (loop_vinfo))\n+  vec_loop_masks *masks = NULL;\n+  if (loop_vinfo && LOOP_VINFO_FULLY_MASKED_P (loop_vinfo))\n+    {\n+      if (reduction_type == EXTRACT_LAST_REDUCTION)\n+\tmasks = &LOOP_VINFO_MASKS (loop_vinfo);\n+      else\n \t{\n-\t  if (reduction_type == EXTRACT_LAST_REDUCTION)\n+\t  scalar_cond_masked_key cond (cond_expr, ncopies);\n+\t  if (loop_vinfo->scalar_cond_masked_set.contains (cond))\n \t    masks = &LOOP_VINFO_MASKS (loop_vinfo);\n \t  else\n \t    {\n-\t      scalar_cond_masked_key cond (cond_expr, ncopies);\n+\t      bool honor_nans = HONOR_NANS (TREE_TYPE (cond.op0));\n+\t      cond.code = invert_tree_comparison (cond.code, honor_nans);\n \t      if (loop_vinfo->scalar_cond_masked_set.contains (cond))\n-\t\tmasks = &LOOP_VINFO_MASKS (loop_vinfo);\n-\t      else\n-\t\t{\n-\t\t  bool honor_nans = HONOR_NANS (TREE_TYPE (cond.op0));\n-\t\t  cond.code = invert_tree_comparison (cond.code, honor_nans);\n-\t\t  if (loop_vinfo->scalar_cond_masked_set.contains (cond))\n-\t\t    {\n-\t\t      masks = &LOOP_VINFO_MASKS (loop_vinfo);\n-\t\t      cond_code = cond.code;\n-\t\t      swap_cond_operands = true;\n-\t\t    }\n-\t\t}\n-\t    }\n-\t}\n-\n-      stmt_vec_info new_stmt_info = NULL;\n-      if (j == 0)\n-\t{\n-          if (slp_node)\n-            {\n-\t      auto_vec<vec<tree>, 4> vec_defs;\n-              vect_get_slp_defs (vinfo, slp_node, &vec_defs);\n-\t      vec_oprnds3 = vec_defs.pop ();\n-\t      vec_oprnds2 = vec_defs.pop ();\n-\t      if (!masked)\n-\t\tvec_oprnds1 = vec_defs.pop ();\n-\t      vec_oprnds0 = vec_defs.pop ();\n-            }\n-          else\n-            {\n-\t      if (masked)\n-\t\t{\n-\t\t  vec_cond_lhs\n-\t\t    = vect_get_vec_def_for_operand (vinfo, cond_expr, stmt_info,\n-\t\t\t\t\t\t    comp_vectype);\n-\t\t}\n-\t      else\n \t\t{\n-\t\t  vec_cond_lhs\n-\t\t    = vect_get_vec_def_for_operand (vinfo, cond_expr0,\n-\t\t\t\t\t\t    stmt_info, comp_vectype);\n-\t\t  vec_cond_rhs\n-\t\t    = vect_get_vec_def_for_operand (vinfo, cond_expr1,\n-\t\t\t\t\t\t    stmt_info, comp_vectype);\n+\t\t  masks = &LOOP_VINFO_MASKS (loop_vinfo);\n+\t\t  cond_code = cond.code;\n+\t\t  swap_cond_operands = true;\n \t\t}\n-\t      vec_then_clause = vect_get_vec_def_for_operand (vinfo,\n-\t\t\t\t\t\t\t      then_clause,\n-\t\t\t\t\t\t\t      stmt_info);\n-\t      if (reduction_type != EXTRACT_LAST_REDUCTION)\n-\t\tvec_else_clause = vect_get_vec_def_for_operand (vinfo,\n-\t\t\t\t\t\t\t\telse_clause,\n-\t\t\t\t\t\t\t\tstmt_info);\n \t    }\n \t}\n-      else\n-\t{\n-\t  vec_cond_lhs\n-\t    = vect_get_vec_def_for_stmt_copy (vinfo, vec_oprnds0.pop ());\n-\t  if (!masked)\n-\t    vec_cond_rhs\n-\t      = vect_get_vec_def_for_stmt_copy (vinfo, vec_oprnds1.pop ());\n-\n-\t  vec_then_clause = vect_get_vec_def_for_stmt_copy (vinfo,\n-\t\t\t\t\t\t\t    vec_oprnds2.pop ());\n-\t  vec_else_clause = vect_get_vec_def_for_stmt_copy (vinfo,\n-\t\t\t\t\t\t\t    vec_oprnds3.pop ());\n-\t}\n+    }\n \n-      if (!slp_node)\n-        {\n-\t  vec_oprnds0.quick_push (vec_cond_lhs);\n-\t  if (!masked)\n-\t    vec_oprnds1.quick_push (vec_cond_rhs);\n-\t  vec_oprnds2.quick_push (vec_then_clause);\n-\t  vec_oprnds3.quick_push (vec_else_clause);\n-\t}\n+  /* Handle cond expr.  */\n+  if (masked)\n+    vect_get_vec_defs (vinfo, stmt_info, slp_node, ncopies,\n+\t\t       cond_expr, &vec_oprnds0, comp_vectype,\n+\t\t       then_clause, &vec_oprnds2, vectype,\n+\t\t       reduction_type != EXTRACT_LAST_REDUCTION\n+\t\t       ? else_clause : NULL, &vec_oprnds3, vectype);\n+  else\n+    vect_get_vec_defs (vinfo, stmt_info, slp_node, ncopies,\n+\t\t       cond_expr0, &vec_oprnds0, comp_vectype,\n+\t\t       cond_expr1, &vec_oprnds1, comp_vectype,\n+\t\t       then_clause, &vec_oprnds2, vectype,\n+\t\t       reduction_type != EXTRACT_LAST_REDUCTION\n+\t\t       ? else_clause : NULL, &vec_oprnds3, vectype);\n \n-      /* Arguments are ready.  Create the new vector stmt.  */\n-      FOR_EACH_VEC_ELT (vec_oprnds0, i, vec_cond_lhs)\n-        {\n-          vec_then_clause = vec_oprnds2[i];\n-          vec_else_clause = vec_oprnds3[i];\n+  /* Arguments are ready.  Create the new vector stmt.  */\n+  FOR_EACH_VEC_ELT (vec_oprnds0, i, vec_cond_lhs)\n+    {\n+      vec_then_clause = vec_oprnds2[i];\n+      vec_else_clause = vec_oprnds3[i];\n \n-\t  if (swap_cond_operands)\n-\t    std::swap (vec_then_clause, vec_else_clause);\n+      if (swap_cond_operands)\n+\tstd::swap (vec_then_clause, vec_else_clause);\n \n-\t  if (masked)\n-\t    vec_compare = vec_cond_lhs;\n+      if (masked)\n+\tvec_compare = vec_cond_lhs;\n+      else\n+\t{\n+\t  vec_cond_rhs = vec_oprnds1[i];\n+\t  if (bitop1 == NOP_EXPR)\n+\t    vec_compare = build2 (cond_code, vec_cmp_type,\n+\t\t\t\t  vec_cond_lhs, vec_cond_rhs);\n \t  else\n \t    {\n-\t      vec_cond_rhs = vec_oprnds1[i];\n-\t      if (bitop1 == NOP_EXPR)\n-\t\tvec_compare = build2 (cond_code, vec_cmp_type,\n-\t\t\t\t      vec_cond_lhs, vec_cond_rhs);\n+\t      new_temp = make_ssa_name (vec_cmp_type);\n+\t      gassign *new_stmt;\n+\t      if (bitop1 == BIT_NOT_EXPR)\n+\t\tnew_stmt = gimple_build_assign (new_temp, bitop1,\n+\t\t\t\t\t\tvec_cond_rhs);\n \t      else\n+\t\tnew_stmt\n+\t\t  = gimple_build_assign (new_temp, bitop1, vec_cond_lhs,\n+\t\t\t\t\t vec_cond_rhs);\n+\t      vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n+\t      if (bitop2 == NOP_EXPR)\n+\t\tvec_compare = new_temp;\n+\t      else if (bitop2 == BIT_NOT_EXPR)\n \t\t{\n-\t\t  new_temp = make_ssa_name (vec_cmp_type);\n-\t\t  gassign *new_stmt;\n-\t\t  if (bitop1 == BIT_NOT_EXPR)\n-\t\t    new_stmt = gimple_build_assign (new_temp, bitop1,\n-\t\t\t\t\t\t    vec_cond_rhs);\n-\t\t  else\n-\t\t    new_stmt\n-\t\t      = gimple_build_assign (new_temp, bitop1, vec_cond_lhs,\n-\t\t\t\t\t     vec_cond_rhs);\n-\t\t  vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n-\t\t  if (bitop2 == NOP_EXPR)\n-\t\t    vec_compare = new_temp;\n-\t\t  else if (bitop2 == BIT_NOT_EXPR)\n-\t\t    {\n-\t\t      /* Instead of doing ~x ? y : z do x ? z : y.  */\n-\t\t      vec_compare = new_temp;\n-\t\t      std::swap (vec_then_clause, vec_else_clause);\n-\t\t    }\n-\t\t  else\n-\t\t    {\n-\t\t      vec_compare = make_ssa_name (vec_cmp_type);\n-\t\t      new_stmt\n-\t\t\t= gimple_build_assign (vec_compare, bitop2,\n-\t\t\t\t\t       vec_cond_lhs, new_temp);\n-\t\t      vect_finish_stmt_generation (vinfo, stmt_info,\n-\t\t\t\t\t\t   new_stmt, gsi);\n-\t\t    }\n+\t\t  /* Instead of doing ~x ? y : z do x ? z : y.  */\n+\t\t  vec_compare = new_temp;\n+\t\t  std::swap (vec_then_clause, vec_else_clause);\n+\t\t}\n+\t      else\n+\t\t{\n+\t\t  vec_compare = make_ssa_name (vec_cmp_type);\n+\t\t  new_stmt\n+\t\t    = gimple_build_assign (vec_compare, bitop2,\n+\t\t\t\t\t   vec_cond_lhs, new_temp);\n+\t\t  vect_finish_stmt_generation (vinfo, stmt_info,\n+\t\t\t\t\t       new_stmt, gsi);\n \t\t}\n \t    }\n+\t}\n \n-\t  /* If we decided to apply a loop mask to the result of the vector\n-             comparison, AND the comparison with the mask now.  Later passes\n-             should then be able to reuse the AND results between mulitple\n-             vector statements.\n+      /* If we decided to apply a loop mask to the result of the vector\n+\t comparison, AND the comparison with the mask now.  Later passes\n+\t should then be able to reuse the AND results between mulitple\n+\t vector statements.\n \n-\t     For example:\n-\t     for (int i = 0; i < 100; ++i)\n-\t       x[i] = y[i] ? z[i] : 10;\n+\t For example:\n+\t for (int i = 0; i < 100; ++i)\n+\t x[i] = y[i] ? z[i] : 10;\n \n-\t     results in following optimized GIMPLE:\n+\t results in following optimized GIMPLE:\n \n-\t     mask__35.8_43 = vect__4.7_41 != { 0, ... };\n-\t     vec_mask_and_46 = loop_mask_40 & mask__35.8_43;\n-\t     _19 = &MEM[base: z_12(D), index: ivtmp_56, step: 4, offset: 0B];\n-\t     vect_iftmp.11_47 = .MASK_LOAD (_19, 4B, vec_mask_and_46);\n-\t     vect_iftmp.12_52 = VEC_COND_EXPR <vec_mask_and_46,\n-\t\t\t\t\t       vect_iftmp.11_47, { 10, ... }>;\n+\t mask__35.8_43 = vect__4.7_41 != { 0, ... };\n+\t vec_mask_and_46 = loop_mask_40 & mask__35.8_43;\n+\t _19 = &MEM[base: z_12(D), index: ivtmp_56, step: 4, offset: 0B];\n+\t vect_iftmp.11_47 = .MASK_LOAD (_19, 4B, vec_mask_and_46);\n+\t vect_iftmp.12_52 = VEC_COND_EXPR <vec_mask_and_46,\n+\t vect_iftmp.11_47, { 10, ... }>;\n \n-\t     instead of using a masked and unmasked forms of\n-\t     vec != { 0, ... } (masked in the MASK_LOAD,\n-\t     unmasked in the VEC_COND_EXPR).  */\n+\t instead of using a masked and unmasked forms of\n+\t vec != { 0, ... } (masked in the MASK_LOAD,\n+\t unmasked in the VEC_COND_EXPR).  */\n \n-\t  /* Force vec_compare to be an SSA_NAME rather than a comparison,\n-\t     in cases where that's necessary.  */\n+      /* Force vec_compare to be an SSA_NAME rather than a comparison,\n+\t in cases where that's necessary.  */\n \n-\t  if (masks || reduction_type == EXTRACT_LAST_REDUCTION)\n+      if (masks || reduction_type == EXTRACT_LAST_REDUCTION)\n+\t{\n+\t  if (!is_gimple_val (vec_compare))\n \t    {\n-\t      if (!is_gimple_val (vec_compare))\n-\t\t{\n-\t\t  tree vec_compare_name = make_ssa_name (vec_cmp_type);\n-\t\t  gassign *new_stmt = gimple_build_assign (vec_compare_name,\n-\t\t\t\t\t\t\t   vec_compare);\n-\t\t  vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n-\t\t  vec_compare = vec_compare_name;\n-\t\t}\n-\n-\t      if (must_invert_cmp_result)\n-\t\t{\n-\t\t  tree vec_compare_name = make_ssa_name (vec_cmp_type);\n-\t\t  gassign *new_stmt = gimple_build_assign (vec_compare_name,\n-\t\t\t\t\t\t\t   BIT_NOT_EXPR,\n-\t\t\t\t\t\t\t   vec_compare);\n-\t\t  vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n-\t\t  vec_compare = vec_compare_name;\n-\t\t}\n+\t      tree vec_compare_name = make_ssa_name (vec_cmp_type);\n+\t      gassign *new_stmt = gimple_build_assign (vec_compare_name,\n+\t\t\t\t\t\t       vec_compare);\n+\t      vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n+\t      vec_compare = vec_compare_name;\n+\t    }\n \n-\t      if (masks)\n-\t\t{\n-\t\t  unsigned vec_num = vec_oprnds0.length ();\n-\t\t  tree loop_mask\n-\t\t    = vect_get_loop_mask (gsi, masks, vec_num * ncopies,\n-\t\t\t\t\t  vectype, vec_num * j + i);\n-\t\t  tree tmp2 = make_ssa_name (vec_cmp_type);\n-\t\t  gassign *g\n-\t\t    = gimple_build_assign (tmp2, BIT_AND_EXPR, vec_compare,\n-\t\t\t\t\t   loop_mask);\n-\t\t  vect_finish_stmt_generation (vinfo, stmt_info, g, gsi);\n-\t\t  vec_compare = tmp2;\n-\t\t}\n+\t  if (must_invert_cmp_result)\n+\t    {\n+\t      tree vec_compare_name = make_ssa_name (vec_cmp_type);\n+\t      gassign *new_stmt = gimple_build_assign (vec_compare_name,\n+\t\t\t\t\t\t       BIT_NOT_EXPR,\n+\t\t\t\t\t\t       vec_compare);\n+\t      vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n+\t      vec_compare = vec_compare_name;\n \t    }\n \n-\t  if (reduction_type == EXTRACT_LAST_REDUCTION)\n+\t  if (masks)\n \t    {\n-\t      gimple *old_stmt = vect_orig_stmt (stmt_info)->stmt;\n-\t      tree lhs = gimple_get_lhs (old_stmt);\n-\t      gcall *new_stmt = gimple_build_call_internal\n-\t\t(IFN_FOLD_EXTRACT_LAST, 3, else_clause, vec_compare,\n-\t\t vec_then_clause);\n-\t      gimple_call_set_lhs (new_stmt, lhs);\n-\t      SSA_NAME_DEF_STMT (lhs) = new_stmt;\n-\t      if (old_stmt == gsi_stmt (*gsi))\n-\t\tnew_stmt_info = vect_finish_replace_stmt (vinfo,\n-\t\t\t\t\t\t\t  stmt_info, new_stmt);\n-\t      else\n-\t\t{\n-\t\t  /* In this case we're moving the definition to later in the\n-\t\t     block.  That doesn't matter because the only uses of the\n-\t\t     lhs are in phi statements.  */\n-\t\t  gimple_stmt_iterator old_gsi = gsi_for_stmt (old_stmt);\n-\t\t  gsi_remove (&old_gsi, true);\n-\t\t  new_stmt_info\n-\t\t    = vect_finish_stmt_generation (vinfo, stmt_info,\n-\t\t\t\t\t\t   new_stmt, gsi);\n-\t\t}\n+\t      unsigned vec_num = vec_oprnds0.length ();\n+\t      tree loop_mask\n+\t\t= vect_get_loop_mask (gsi, masks, vec_num * ncopies,\n+\t\t\t\t      vectype, i);\n+\t      tree tmp2 = make_ssa_name (vec_cmp_type);\n+\t      gassign *g\n+\t\t= gimple_build_assign (tmp2, BIT_AND_EXPR, vec_compare,\n+\t\t\t\t       loop_mask);\n+\t      vect_finish_stmt_generation (vinfo, stmt_info, g, gsi);\n+\t      vec_compare = tmp2;\n \t    }\n+\t}\n+\n+      stmt_vec_info new_stmt_info;\n+      if (reduction_type == EXTRACT_LAST_REDUCTION)\n+\t{\n+\t  gimple *old_stmt = vect_orig_stmt (stmt_info)->stmt;\n+\t  tree lhs = gimple_get_lhs (old_stmt);\n+\t  gcall *new_stmt = gimple_build_call_internal\n+\t      (IFN_FOLD_EXTRACT_LAST, 3, else_clause, vec_compare,\n+\t       vec_then_clause);\n+\t  gimple_call_set_lhs (new_stmt, lhs);\n+\t  SSA_NAME_DEF_STMT (lhs) = new_stmt;\n+\t  if (old_stmt == gsi_stmt (*gsi))\n+\t    new_stmt_info = vect_finish_replace_stmt (vinfo,\n+\t\t\t\t\t\t      stmt_info, new_stmt);\n \t  else\n \t    {\n-\t      new_temp = make_ssa_name (vec_dest);\n-\t      gassign *new_stmt\n-\t\t= gimple_build_assign (new_temp, VEC_COND_EXPR, vec_compare,\n-\t\t\t\t       vec_then_clause, vec_else_clause);\n+\t      /* In this case we're moving the definition to later in the\n+\t\t block.  That doesn't matter because the only uses of the\n+\t\t lhs are in phi statements.  */\n+\t      gimple_stmt_iterator old_gsi = gsi_for_stmt (old_stmt);\n+\t      gsi_remove (&old_gsi, true);\n \t      new_stmt_info\n \t\t= vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n \t    }\n-          if (slp_node)\n-\t    SLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n-        }\n-\n-        if (slp_node)\n-          continue;\n-\n-\tif (j == 0)\n-\t  STMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n-\telse\n-\t  STMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\n-\tprev_stmt_info = new_stmt_info;\n+\t}\n+      else\n+\t{\n+\t  new_temp = make_ssa_name (vec_dest);\n+\t  gassign *new_stmt\n+\t    = gimple_build_assign (new_temp, VEC_COND_EXPR, vec_compare,\n+\t\t\t\t   vec_then_clause, vec_else_clause);\n+\t  new_stmt_info\n+\t    = vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n+\t}\n+      if (slp_node)\n+\tSLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n+      else\n+\tSTMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n     }\n \n+  if (!slp_node)\n+    *vec_stmt = STMT_VINFO_VEC_STMTS (stmt_info)[0];\n+\n   vec_oprnds0.release ();\n   vec_oprnds1.release ();\n   vec_oprnds2.release ();\n@@ -10639,8 +10165,7 @@ vectorizable_comparison (vec_info *vinfo,\n   poly_uint64 nunits;\n   int ncopies;\n   enum tree_code code, bitop1 = NOP_EXPR, bitop2 = NOP_EXPR;\n-  stmt_vec_info prev_stmt_info = NULL;\n-  int i, j;\n+  int i;\n   bb_vec_info bb_vinfo = dyn_cast <bb_vec_info> (vinfo);\n   vec<tree> vec_oprnds0 = vNULL;\n   vec<tree> vec_oprnds1 = vNULL;\n@@ -10810,96 +10335,57 @@ vectorizable_comparison (vec_info *vinfo,\n   lhs = gimple_assign_lhs (stmt);\n   mask = vect_create_destination_var (lhs, mask_type);\n \n-  /* Handle cmp expr.  */\n-  for (j = 0; j < ncopies; j++)\n+  vect_get_vec_defs (vinfo, stmt_info, slp_node, ncopies,\n+\t\t     rhs1, &vec_oprnds0, vectype,\n+\t\t     rhs2, &vec_oprnds1, vectype);\n+  if (swap_p)\n+    std::swap (vec_oprnds0, vec_oprnds1);\n+\n+  /* Arguments are ready.  Create the new vector stmt.  */\n+  FOR_EACH_VEC_ELT (vec_oprnds0, i, vec_rhs1)\n     {\n-      stmt_vec_info new_stmt_info = NULL;\n-      if (j == 0)\n-\t{\n-\t  if (slp_node)\n-\t    {\n-\t      auto_vec<vec<tree>, 2> vec_defs;\n-\t      vect_get_slp_defs (vinfo, slp_node, &vec_defs);\n-\t      vec_oprnds1 = vec_defs.pop ();\n-\t      vec_oprnds0 = vec_defs.pop ();\n-\t      if (swap_p)\n-\t\tstd::swap (vec_oprnds0, vec_oprnds1);\n-\t    }\n-\t  else\n-\t    {\n-\t      vec_rhs1 = vect_get_vec_def_for_operand (vinfo, rhs1, stmt_info,\n-\t\t\t\t\t\t       vectype);\n-\t      vec_rhs2 = vect_get_vec_def_for_operand (vinfo, rhs2, stmt_info,\n-\t\t\t\t\t\t       vectype);\n-\t    }\n-\t}\n-      else\n-\t{\n-\t  vec_rhs1 = vect_get_vec_def_for_stmt_copy (vinfo,\n-\t\t\t\t\t\t     vec_oprnds0.pop ());\n-\t  vec_rhs2 = vect_get_vec_def_for_stmt_copy (vinfo,\n-\t\t\t\t\t\t     vec_oprnds1.pop ());\n-\t}\n+      stmt_vec_info new_stmt_info;\n+      vec_rhs2 = vec_oprnds1[i];\n \n-      if (!slp_node)\n+      new_temp = make_ssa_name (mask);\n+      if (bitop1 == NOP_EXPR)\n \t{\n-\t  if (swap_p && j == 0)\n-\t    std::swap (vec_rhs1, vec_rhs2);\n-\t  vec_oprnds0.quick_push (vec_rhs1);\n-\t  vec_oprnds1.quick_push (vec_rhs2);\n+\t  gassign *new_stmt = gimple_build_assign (new_temp, code,\n+\t\t\t\t\t\t   vec_rhs1, vec_rhs2);\n+\t  new_stmt_info\n+\t    = vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n \t}\n-\n-      /* Arguments are ready.  Create the new vector stmt.  */\n-      FOR_EACH_VEC_ELT (vec_oprnds0, i, vec_rhs1)\n+      else\n \t{\n-\t  vec_rhs2 = vec_oprnds1[i];\n-\n-\t  new_temp = make_ssa_name (mask);\n-\t  if (bitop1 == NOP_EXPR)\n-\t    {\n-\t      gassign *new_stmt = gimple_build_assign (new_temp, code,\n-\t\t\t\t\t\t       vec_rhs1, vec_rhs2);\n-\t      new_stmt_info\n-\t\t= vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n-\t    }\n+\t  gassign *new_stmt;\n+\t  if (bitop1 == BIT_NOT_EXPR)\n+\t    new_stmt = gimple_build_assign (new_temp, bitop1, vec_rhs2);\n \t  else\n+\t    new_stmt = gimple_build_assign (new_temp, bitop1, vec_rhs1,\n+\t\t\t\t\t    vec_rhs2);\n+\t  new_stmt_info\n+\t    = vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n+\t  if (bitop2 != NOP_EXPR)\n \t    {\n-\t      gassign *new_stmt;\n-\t      if (bitop1 == BIT_NOT_EXPR)\n-\t\tnew_stmt = gimple_build_assign (new_temp, bitop1, vec_rhs2);\n+\t      tree res = make_ssa_name (mask);\n+\t      if (bitop2 == BIT_NOT_EXPR)\n+\t\tnew_stmt = gimple_build_assign (res, bitop2, new_temp);\n \t      else\n-\t\tnew_stmt = gimple_build_assign (new_temp, bitop1, vec_rhs1,\n-\t\t\t\t\t\tvec_rhs2);\n+\t\tnew_stmt = gimple_build_assign (res, bitop2, vec_rhs1,\n+\t\t\t\t\t\tnew_temp);\n \t      new_stmt_info\n \t\t= vect_finish_stmt_generation (vinfo, stmt_info, new_stmt, gsi);\n-\t      if (bitop2 != NOP_EXPR)\n-\t\t{\n-\t\t  tree res = make_ssa_name (mask);\n-\t\t  if (bitop2 == BIT_NOT_EXPR)\n-\t\t    new_stmt = gimple_build_assign (res, bitop2, new_temp);\n-\t\t  else\n-\t\t    new_stmt = gimple_build_assign (res, bitop2, vec_rhs1,\n-\t\t\t\t\t\t    new_temp);\n-\t\t  new_stmt_info\n-\t\t    = vect_finish_stmt_generation (vinfo, stmt_info,\n-\t\t\t\t\t\t   new_stmt, gsi);\n-\t\t}\n \t    }\n-\t  if (slp_node)\n-\t    SLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n \t}\n-\n       if (slp_node)\n-\tcontinue;\n-\n-      if (j == 0)\n-\tSTMT_VINFO_VEC_STMT (stmt_info) = *vec_stmt = new_stmt_info;\n+\tSLP_TREE_VEC_STMTS (slp_node).quick_push (new_stmt_info);\n       else\n-\tSTMT_VINFO_RELATED_STMT (prev_stmt_info) = new_stmt_info;\n-\n-      prev_stmt_info = new_stmt_info;\n+\tSTMT_VINFO_VEC_STMTS (stmt_info).safe_push (new_stmt_info);\n     }\n \n+  if (!slp_node)\n+    *vec_stmt = STMT_VINFO_VEC_STMTS (stmt_info)[0];\n+\n   vec_oprnds0.release ();\n   vec_oprnds1.release ();\n \n@@ -11184,7 +10670,6 @@ vect_transform_stmt (vec_info *vinfo,\n   bool done;\n \n   gcc_assert (slp_node || !PURE_SLP_STMT (stmt_info));\n-  stmt_vec_info old_vec_stmt_info = STMT_VINFO_VEC_STMT (stmt_info);\n \n   switch (STMT_VINFO_TYPE (stmt_info))\n     {\n@@ -11296,14 +10781,8 @@ vect_transform_stmt (vec_info *vinfo,\n       done = true;\n     }\n \n-  /* Verify SLP vectorization doesn't mess with STMT_VINFO_VEC_STMT.\n-     This would break hybrid SLP vectorization.  */\n-  if (slp_node)\n-    gcc_assert (!vec_stmt\n-\t\t&& STMT_VINFO_VEC_STMT (stmt_info) == old_vec_stmt_info);\n-\n-  if (vec_stmt)\n-    STMT_VINFO_VEC_STMT (stmt_info) = vec_stmt;\n+  if (!slp_node && vec_stmt)\n+    gcc_assert (STMT_VINFO_VEC_STMTS (stmt_info).exists ());\n \n   if (STMT_VINFO_TYPE (stmt_info) == store_vec_info_type)\n     return is_store;\n@@ -11329,19 +10808,15 @@ vect_transform_stmt (vec_info *vinfo,\n \t  && (PHI_ARG_DEF_FROM_EDGE (phi, e)\n \t      == gimple_get_lhs (orig_stmt_info->stmt)))\n \t{\n-\t  stmt_vec_info phi_info\n-\t    = STMT_VINFO_VEC_STMT (STMT_VINFO_REDUC_DEF (orig_stmt_info));\n-\t  stmt_vec_info vec_stmt = STMT_VINFO_VEC_STMT (stmt_info);\n-\t  do\n-\t    {\n-\t      add_phi_arg (as_a <gphi *> (phi_info->stmt),\n-\t\t\t   gimple_get_lhs (vec_stmt->stmt), e,\n-\t\t\t   gimple_phi_arg_location (phi, e->dest_idx));\n-\t      phi_info = STMT_VINFO_RELATED_STMT (phi_info);\n-\t      vec_stmt = STMT_VINFO_RELATED_STMT (vec_stmt);\n-\t    }\n-\t  while (phi_info);\n-\t  gcc_assert (!vec_stmt);\n+\t  vec<stmt_vec_info> &phi_info\n+\t    = STMT_VINFO_VEC_STMTS (STMT_VINFO_REDUC_DEF (orig_stmt_info));\n+\t  vec<stmt_vec_info> &vec_stmt\n+\t    = STMT_VINFO_VEC_STMTS (stmt_info);\n+\t  gcc_assert (phi_info.length () == vec_stmt.length ());\n+\t  for (unsigned i = 0; i < phi_info.length (); ++i)\n+\t    add_phi_arg (as_a <gphi *> (phi_info[i]->stmt),\n+\t\t\t gimple_get_lhs (vec_stmt[i]->stmt), e,\n+\t\t\t gimple_phi_arg_location (phi, e->dest_idx));\n \t}\n       else if (slp_node\n \t       && slp_node != slp_node_instance->reduc_phis)"}, {"sha": "e9fe3840e1e24e1fca6bac527c138ca8fba72009", "filename": "gcc/tree-vectorizer.c", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b05d5563f4be13b4a0d0951375a82adf483973c0/gcc%2Ftree-vectorizer.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b05d5563f4be13b4a0d0951375a82adf483973c0/gcc%2Ftree-vectorizer.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vectorizer.c?ref=b05d5563f4be13b4a0d0951375a82adf483973c0", "patch": "@@ -641,6 +641,7 @@ vec_info::new_stmt_vec_info (gimple *stmt)\n   STMT_VINFO_REDUC_FN (res) = IFN_LAST;\n   STMT_VINFO_REDUC_IDX (res) = -1;\n   STMT_VINFO_SLP_VECT_ONLY (res) = false;\n+  STMT_VINFO_VEC_STMTS (res) = vNULL;\n \n   if (gimple_code (stmt) == GIMPLE_PHI\n       && is_loop_header_bb_p (gimple_bb (stmt)))\n@@ -705,6 +706,7 @@ vec_info::free_stmt_vec_info (stmt_vec_info stmt_info)\n \n   STMT_VINFO_SAME_ALIGN_REFS (stmt_info).release ();\n   STMT_VINFO_SIMD_CLONE_INFO (stmt_info).release ();\n+  STMT_VINFO_VEC_STMTS (stmt_info).release ();\n   free (stmt_info);\n }\n "}, {"sha": "df0563815312250813608565b5f26896a7ae9556", "filename": "gcc/tree-vectorizer.h", "status": "modified", "additions": 18, "deletions": 12, "changes": 30, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/b05d5563f4be13b4a0d0951375a82adf483973c0/gcc%2Ftree-vectorizer.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/b05d5563f4be13b4a0d0951375a82adf483973c0/gcc%2Ftree-vectorizer.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vectorizer.h?ref=b05d5563f4be13b4a0d0951375a82adf483973c0", "patch": "@@ -964,9 +964,8 @@ class _stmt_vec_info {\n   /* The vector type to be used for the LHS of this statement.  */\n   tree vectype;\n \n-  /* The vectorized version of the stmt.  */\n-  stmt_vec_info vectorized_stmt;\n-\n+  /* The vectorized stmts.  */\n+  vec<stmt_vec_info> vec_stmts;\n \n   /* The following is relevant only for stmts that contain a non-scalar\n      data-ref (array/pointer/struct access). A GIMPLE stmt is expected to have\n@@ -1127,6 +1126,8 @@ class _stmt_vec_info {\n \n   /* True if this is only suitable for SLP vectorization.  */\n   bool slp_vect_only_p;\n+\n+  bool vector_stmt;\n };\n \n /* Information about a gather/scatter call.  */\n@@ -1168,7 +1169,7 @@ struct gather_scatter_info {\n #define STMT_VINFO_RELEVANT(S)             (S)->relevant\n #define STMT_VINFO_LIVE_P(S)               (S)->live\n #define STMT_VINFO_VECTYPE(S)              (S)->vectype\n-#define STMT_VINFO_VEC_STMT(S)             (S)->vectorized_stmt\n+#define STMT_VINFO_VEC_STMTS(S)             (S)->vec_stmts\n #define STMT_VINFO_VECTORIZABLE(S)         (S)->vectorizable\n #define STMT_VINFO_DATA_REF(S)             ((S)->dr_aux.dr + 0)\n #define STMT_VINFO_GATHER_SCATTER_P(S)\t   (S)->gather_scatter_p\n@@ -1743,16 +1744,20 @@ extern stmt_vec_info vect_finish_stmt_generation (vec_info *,\n \t\t\t\t\t\t  gimple_stmt_iterator *);\n extern opt_result vect_mark_stmts_to_be_vectorized (loop_vec_info, bool *);\n extern tree vect_get_store_rhs (stmt_vec_info);\n-extern tree vect_get_vec_def_for_operand_1 (stmt_vec_info, enum vect_def_type);\n-extern tree vect_get_vec_def_for_operand (vec_info *, tree,\n-\t\t\t\t\t  stmt_vec_info, tree = NULL);\n-extern void vect_get_vec_defs (vec_info *, tree, tree, stmt_vec_info,\n-\t\t\t       vec<tree> *, vec<tree> *, slp_tree);\n-extern void vect_get_vec_defs_for_stmt_copy (vec_info *,\n-\t\t\t\t\t     vec<tree> *, vec<tree> *);\n+void vect_get_vec_defs_for_operand (vec_info *vinfo, stmt_vec_info, unsigned,\n+\t\t\t\t    tree op, vec<tree> *, tree = NULL);\n+void vect_get_vec_defs (vec_info *, stmt_vec_info, slp_tree, unsigned,\n+\t\t\ttree, vec<tree> *,\n+\t\t\ttree = NULL, vec<tree> * = NULL,\n+\t\t\ttree = NULL, vec<tree> * = NULL,\n+\t\t\ttree = NULL, vec<tree> * = NULL);\n+void vect_get_vec_defs (vec_info *, stmt_vec_info, slp_tree, unsigned,\n+\t\t\ttree, vec<tree> *, tree,\n+\t\t\ttree = NULL, vec<tree> * = NULL, tree = NULL,\n+\t\t\ttree = NULL, vec<tree> * = NULL, tree = NULL,\n+\t\t\ttree = NULL, vec<tree> * = NULL, tree = NULL);\n extern tree vect_init_vector (vec_info *, stmt_vec_info, tree, tree,\n                               gimple_stmt_iterator *);\n-extern tree vect_get_vec_def_for_stmt_copy (vec_info *, tree);\n extern tree vect_get_slp_vect_def (slp_tree, unsigned);\n extern bool vect_transform_stmt (vec_info *, stmt_vec_info,\n \t\t\t\t gimple_stmt_iterator *,\n@@ -1895,6 +1900,7 @@ extern opt_result vect_analyze_slp (vec_info *, unsigned);\n extern bool vect_make_slp_decision (loop_vec_info);\n extern void vect_detect_hybrid_slp (loop_vec_info);\n extern void vect_optimize_slp (vec_info *);\n+extern void vect_get_slp_defs (slp_tree, vec<tree> *);\n extern void vect_get_slp_defs (vec_info *, slp_tree, vec<vec<tree> > *,\n \t\t\t       unsigned n = -1U);\n extern bool vect_slp_bb (basic_block);"}]}