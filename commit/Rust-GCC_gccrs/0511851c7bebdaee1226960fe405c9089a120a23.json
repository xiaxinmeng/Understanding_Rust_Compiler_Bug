{"sha": "0511851c7bebdaee1226960fe405c9089a120a23", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MDUxMTg1MWM3YmViZGFlZTEyMjY5NjBmZTQwNWM5MDg5YTEyMGEyMw==", "commit": {"author": {"name": "Mark Mitchell", "email": "mark@codesourcery.com", "date": "1999-11-03T22:45:45Z"}, "committer": {"name": "Mark Mitchell", "email": "mmitchel@gcc.gnu.org", "date": "1999-11-03T22:45:45Z"}, "message": "gcse.c (struct null_pointer_info): New type.\n\n\t* gcse.c (struct null_pointer_info): New type.\n\t(get_bitmap_width): New function.\n\t(current_block): Remove.\n\t(nonnull_local): Likewise.\n\t(nonnull_killed): Likewise.\n\t(invalidate_nonnull_info): Take a null_pointer_info as input.\n\t(delete_null_pointer_checks_1): New function.\n\t(delete_null_pointer_checks): Use it.\n\nFrom-SVN: r30384", "tree": {"sha": "1fea2ecb5a5e9533654a8466ce98b970d99793af", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/1fea2ecb5a5e9533654a8466ce98b970d99793af"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/0511851c7bebdaee1226960fe405c9089a120a23", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0511851c7bebdaee1226960fe405c9089a120a23", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0511851c7bebdaee1226960fe405c9089a120a23", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0511851c7bebdaee1226960fe405c9089a120a23/comments", "author": null, "committer": null, "parents": [{"sha": "989037420d10d9dcd81032ccf8d5e4307f6d9a40", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/989037420d10d9dcd81032ccf8d5e4307f6d9a40", "html_url": "https://github.com/Rust-GCC/gccrs/commit/989037420d10d9dcd81032ccf8d5e4307f6d9a40"}], "stats": {"total": 362, "additions": 251, "deletions": 111}, "files": [{"sha": "b090806ac411c476c839b7bbb6321459af7232c6", "filename": "gcc/ChangeLog", "status": "modified", "additions": 9, "deletions": 0, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0511851c7bebdaee1226960fe405c9089a120a23/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0511851c7bebdaee1226960fe405c9089a120a23/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=0511851c7bebdaee1226960fe405c9089a120a23", "patch": "@@ -1,5 +1,14 @@\n Wed Nov  3 14:51:59 1999  Mark P. Mitchell  <mark@codesourcery.com>\n \n+\t* gcse.c (struct null_pointer_info): New type.\n+\t(get_bitmap_width): New function.\n+\t(current_block): Remove.\n+\t(nonnull_local): Likewise.\n+\t(nonnull_killed): Likewise.\n+\t(invalidate_nonnull_info): Take a null_pointer_info as input.\n+\t(delete_null_pointer_checks_1): New function.\n+\t(delete_null_pointer_checks): Use it.\n+\n \t* haifa-sched.c (find_rgns): Replace uses of alloca with xmalloc.\n \t(split_edges): Likewise.\n \t(schedule_block): Likewise."}, {"sha": "067cfbfdd912b24519656338b1b9afa6f2e5fcc3", "filename": "gcc/gcse.c", "status": "modified", "additions": 242, "deletions": 111, "changes": 353, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0511851c7bebdaee1226960fe405c9089a120a23/gcc%2Fgcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0511851c7bebdaee1226960fe405c9089a120a23/gcc%2Fgcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgcse.c?ref=0511851c7bebdaee1226960fe405c9089a120a23", "patch": "@@ -510,6 +510,18 @@ static sbitmap *rd_kill, *rd_gen, *reaching_defs, *rd_out;\n /* for available exprs */\n static sbitmap *ae_kill, *ae_gen, *ae_in, *ae_out;\n \n+/* Objects of this type are passed around by the null-pointer check\n+   removal routines.  */\n+struct null_pointer_info {\n+  /* The basic block being processed.  */\n+  int current_block;\n+  /* The first register to be handled in this pass.  */\n+  int min_reg;\n+  /* One greater than the last register to be handled in this pass.  */\n+  int max_reg;\n+  sbitmap *nonnull_local;\n+  sbitmap *nonnull_killed;\n+};\n \f\n static void compute_can_copy\t  PROTO ((void));\n \n@@ -520,6 +532,7 @@ static void alloc_gcse_mem\t    PROTO ((rtx));\n static void free_gcse_mem\t     PROTO ((void));\n static void alloc_reg_set_mem\t PROTO ((int));\n static void free_reg_set_mem\t  PROTO ((void));\n+static int get_bitmap_width           PROTO ((int, int, int));\n static void record_one_set\t    PROTO ((int, rtx));\n static void record_set_info\t   PROTO ((rtx, rtx, void *));\n static void compute_sets\t      PROTO ((rtx));\n@@ -622,6 +635,9 @@ static int handle_avail_expr\t  PROTO ((rtx, struct expr *));\n static int classic_gcse\t       PROTO ((void));\n static int one_classic_gcse_pass      PROTO ((int));\n static void invalidate_nonnull_info\tPROTO ((rtx, rtx, void *));\n+static void delete_null_pointer_checks_1 PROTO ((int_list_ptr *, int *, \n+\t\t\t\t\t\t sbitmap *, sbitmap *,\n+\t\t\t\t\t\t struct null_pointer_info *));\n static rtx process_insert_insn\tPROTO ((struct expr *));\n static int pre_edge_insert\tPROTO ((struct edge_list *, struct expr **));\n static int expr_reaches_here_p_work\tPROTO ((struct occr *, struct expr *, int, int, char *));\n@@ -948,6 +964,50 @@ free_gcse_mem ()\n   free (mem_set_in_block);\n }\n \n+/* Many of the global optimization algorithms work by solving dataflow\n+   equations for various expressions.  Initially, some local value is\n+   computed for each expression in each block.  Then, the values\n+   across the various blocks are combined (by following flow graph\n+   edges) to arrive at global values.  Conceptually, each set of\n+   equations is independent.  We may therefore solve all the equations\n+   in parallel, solve them one at a time, or pick any intermediate\n+   approach.  \n+\n+   When you're going to need N two-dimensional bitmaps, each X (say,\n+   the number of blocks) by Y (say, the number of expressions), call\n+   this function.  It's not important what X and Y represent; only\n+   that Y correspond to the things that can be done in parallel.  This\n+   function will return an appropriate chunking factor C; you should\n+   solve C sets of equations in parallel.  By going through this\n+   function, we can easily trade space against time; by solving fewer\n+   equations in parallel we use less space.  */\n+\n+static int\n+get_bitmap_width (n, x, y)\n+     int n;\n+     int x;\n+     int y;\n+{\n+  /* It's not really worth figuring out *exactly* how much memory will\n+     be used by a particular choice.  The important thing is to get\n+     something approximately right.  */\n+  size_t max_bitmap_memory = 10 * 1024 * 1024;\n+\n+  /* The number of bytes we'd use for a single column of minimum\n+     width.  */\n+  size_t column_size = n * x * sizeof (SBITMAP_ELT_TYPE);\n+\n+  /* Often, it's reasonable just to solve all the equations in\n+     parallel.  */\n+  if (column_size * SBITMAP_SET_SIZE (y) <= max_bitmap_memory)\n+    return y;\n+\n+  /* Otherwise, pick the largest width we can, without going over the\n+     limit.  */\n+  return SBITMAP_ELT_BITS * ((max_bitmap_memory + column_size - 1)\n+\t\t\t     / column_size);\n+}\n+ \n \f\n /* Compute the local properties of each recorded expression.\n    Local properties are those that are defined by the block, irrespective\n@@ -4923,113 +4983,54 @@ compute_transpout ()\n \n /* Removal of useless null pointer checks */\n \n-/* These need to be file static for communication between \n-   invalidate_nonnull_info and delete_null_pointer_checks.  */\n-static int current_block;\n-static sbitmap *nonnull_local;\n-static sbitmap *nonnull_killed;\n-\n /* Called via note_stores.  X is set by SETTER.  If X is a register we must\n-   invalidate nonnull_local and set nonnull_killed.\n+   invalidate nonnull_local and set nonnull_killed.  DATA is really a\n+   `null_pointer_info *'.\n \n    We ignore hard registers.  */\n static void\n invalidate_nonnull_info (x, setter, data)\n      rtx x;\n      rtx setter ATTRIBUTE_UNUSED;\n-     void *data ATTRIBUTE_UNUSED;\n+     void *data;\n {\n   int offset, regno;\n+  struct null_pointer_info* npi = (struct null_pointer_info *) data;\n \n   offset = 0;\n   while (GET_CODE (x) == SUBREG)\n     x = SUBREG_REG (x);\n \n   /* Ignore anything that is not a register or is a hard register.  */\n   if (GET_CODE (x) != REG\n-      || REGNO (x) < FIRST_PSEUDO_REGISTER)\n+      || REGNO (x) < npi->min_reg\n+      || REGNO (x) >= npi->max_reg)\n     return;\n \n-  regno = REGNO (x);\n+  regno = REGNO (x) - npi->min_reg;\n \n-  RESET_BIT (nonnull_local[current_block], regno);\n-  SET_BIT (nonnull_killed[current_block], regno);\n-  \n+  RESET_BIT (npi->nonnull_local[npi->current_block], regno);\n+  SET_BIT (npi->nonnull_killed[npi->current_block], regno);\n }\n \n-/* Find EQ/NE comparisons against zero which can be (indirectly) evaluated\n-   at compile time.\n-\n-   This is conceptually similar to global constant/copy propagation and\n-   classic global CSE (it even uses the same dataflow equations as cprop).\n-\n-   If a register is used as memory address with the form (mem (reg)), then we\n-   know that REG can not be zero at that point in the program.  Any instruction\n-   which sets REG \"kills\" this property.\n-\n-   So, if every path leading to a conditional branch has an available memory\n-   reference of that form, then we know the register can not have the value\n-   zero at the conditional branch.  \n-\n-   So we merely need to compute the local properies and propagate that data\n-   around the cfg, then optimize where possible.\n+/* Do null-pointer check elimination for the registers indicated in\n+   NPI.  NONNULL_AVIN and NONNULL_AVOUT are pre-allocated sbitmaps;\n+   they are not our responsibility to free.  */\n \n-   We run this pass two times.  Once before CSE, then again after CSE.  This\n-   has proven to be the most profitable approach.  It is rare for new\n-   optimization opportunities of this nature to appear after the first CSE\n-   pass.\n-\n-   This could probably be integrated with global cprop with a little work.  */\n-\n-void\n-delete_null_pointer_checks (f)\n-     rtx f;\n+static void\n+delete_null_pointer_checks_1 (s_preds, block_reg, nonnull_avin, \n+\t\t\t      nonnull_avout, npi)\n+     int_list_ptr *s_preds;\n+     int *block_reg;\n+     sbitmap *nonnull_avin;\n+     sbitmap *nonnull_avout;\n+     struct null_pointer_info *npi;\n {\n-  int_list_ptr *s_preds, *s_succs;\n-  int *num_preds, *num_succs;\n   int changed, bb;\n-  sbitmap *nonnull_avin, *nonnull_avout;\n+  int current_block;\n+  sbitmap *nonnull_local = npi->nonnull_local;\n+  sbitmap *nonnull_killed = npi->nonnull_killed;\n   \n-  /* First break the program into basic blocks.  */\n-  find_basic_blocks (f, max_reg_num (), NULL, 1);\n-\n-  /* If we have only a single block, then there's nothing to do.  */\n-  if (n_basic_blocks <= 1)\n-    {\n-      /* Free storage allocated by find_basic_blocks.  */\n-      free_basic_block_vars (0);\n-      return;\n-    }\n-\n-  /* Trying to perform global optimizations on flow graphs which have\n-     a high connectivity will take a long time and is unlikely to be\n-     particularly useful.\n-\n-     In normal circumstances a cfg should have about twice has many edges\n-     as blocks.  But we do not want to punish small functions which have\n-     a couple switch statements.  So we require a relatively large number\n-     of basic blocks and the ratio of edges to blocks to be high.  */\n-  if (n_basic_blocks > 1000 && n_edges / n_basic_blocks >= 20)\n-    {\n-      /* Free storage allocated by find_basic_blocks.  */\n-      free_basic_block_vars (0);\n-      return;\n-    }\n-\n-  /* We need predecessor/successor lists as well as pred/succ counts for\n-     each basic block.  */\n-  s_preds = (int_list_ptr *) gmalloc (n_basic_blocks * sizeof (int_list_ptr));\n-  s_succs = (int_list_ptr *) gmalloc (n_basic_blocks * sizeof (int_list_ptr));\n-  num_preds = (int *) gmalloc (n_basic_blocks * sizeof (int));\n-  num_succs = (int *) gmalloc (n_basic_blocks * sizeof (int));\n-  compute_preds_succs (s_preds, s_succs, num_preds, num_succs);\n-\n-  /* Allocate bitmaps to hold local and global properties.  */\n-  nonnull_local = sbitmap_vector_alloc (n_basic_blocks, max_reg_num ());\n-  nonnull_killed = sbitmap_vector_alloc (n_basic_blocks, max_reg_num ());\n-  nonnull_avin = sbitmap_vector_alloc (n_basic_blocks, max_reg_num ());\n-  nonnull_avout = sbitmap_vector_alloc (n_basic_blocks, max_reg_num ());\n-\n   /* Compute local properties, nonnull and killed.  A register will have\n      the nonnull property if at the end of the current block its value is\n      known to be nonnull.  The killed property indicates that somewhere in\n@@ -5044,6 +5045,9 @@ delete_null_pointer_checks (f)\n     {\n       rtx insn, stop_insn;\n \n+      /* Set the current block for invalidate_nonnull_info.  */\n+      npi->current_block = current_block;\n+\n       /* Scan each insn in the basic block looking for memory references and\n \t register sets.  */\n       stop_insn = NEXT_INSN (BLOCK_END (current_block));\n@@ -5052,6 +5056,7 @@ delete_null_pointer_checks (f)\n \t   insn = NEXT_INSN (insn))\n \t{\n \t  rtx set;\n+\t  rtx reg;\n \n \t  /* Ignore anything that is not a normal insn.  */\n \t  if (GET_RTX_CLASS (GET_CODE (insn)) != 'i')\n@@ -5063,30 +5068,32 @@ delete_null_pointer_checks (f)\n \t  set = single_set (insn);\n \t  if (!set)\n \t    {\n-\t      note_stores (PATTERN (insn), invalidate_nonnull_info, NULL);\n+\t      note_stores (PATTERN (insn), invalidate_nonnull_info, npi);\n \t      continue;\n \t    }\n \n \t  /* See if we've got a useable memory load.  We handle it first\n \t     in case it uses its address register as a dest (which kills\n \t     the nonnull property).  */\n \t  if (GET_CODE (SET_SRC (set)) == MEM\n-\t      && GET_CODE (XEXP (SET_SRC (set), 0)) == REG\n-\t      && REGNO (XEXP (SET_SRC (set), 0)) >= FIRST_PSEUDO_REGISTER)\n+\t      && GET_CODE ((reg = XEXP (SET_SRC (set), 0))) == REG\n+\t      && REGNO (reg) >= npi->min_reg\n+\t      && REGNO (reg) < npi->max_reg)\n \t    SET_BIT (nonnull_local[current_block],\n-\t\t     REGNO (XEXP (SET_SRC (set), 0)));\n+\t\t     REGNO (reg) - npi->min_reg);\n \n \t  /* Now invalidate stuff clobbered by this insn.  */\n-\t  note_stores (PATTERN (insn), invalidate_nonnull_info, NULL);\n+\t  note_stores (PATTERN (insn), invalidate_nonnull_info, npi);\n \n \t  /* And handle stores, we do these last since any sets in INSN can\n \t     not kill the nonnull property if it is derived from a MEM\n \t     appearing in a SET_DEST.  */\n \t  if (GET_CODE (SET_DEST (set)) == MEM\n-\t      && GET_CODE (XEXP (SET_DEST (set), 0)) == REG\n-\t      && REGNO (XEXP (SET_DEST (set), 0)) >= FIRST_PSEUDO_REGISTER)\n+\t      && GET_CODE ((reg = XEXP (SET_DEST (set), 0))) == REG\n+\t      && REGNO (reg) >= npi->min_reg\n+\t      && REGNO (reg) < npi->max_reg)\n \t    SET_BIT (nonnull_local[current_block],\n-\t\t     REGNO (XEXP (SET_DEST (set), 0)));\n+\t\t     REGNO (reg) - npi->min_reg);\n \t}\n     }\n \n@@ -5117,33 +5124,21 @@ delete_null_pointer_checks (f)\n   for (bb = 0; bb < n_basic_blocks; bb++)\n     {\n       rtx last_insn = BLOCK_END (bb);\n-      rtx condition, earliest, reg;\n+      rtx condition, earliest;\n       int compare_and_branch;\n \n-      /* We only want conditional branches.  */\n-      if (GET_CODE (last_insn) != JUMP_INSN\n-\t  || !condjump_p (last_insn)\n-\t  || simplejump_p (last_insn))\n+      /* Since MIN_REG is always at least FIRST_PSEUDO_REGISTER, and\n+\t since BLOCK_REG[BB] is zero if this block did not end with a\n+\t comparison against zero, this condition works.  */\n+      if (block_reg[bb] < npi->min_reg\n+\t  || block_reg[bb] >= npi->max_reg)\n \tcontinue;\n \n       /* LAST_INSN is a conditional jump.  Get its condition.  */\n       condition = get_condition (last_insn, &earliest);\n \n-      /* If we were unable to get the condition, or it is not a equality\n-\t comparison against zero then there's nothing we can do.  */\n-      if (!condition\n-\t  || (GET_CODE (condition) != NE && GET_CODE (condition) != EQ)\n-\t  || GET_CODE (XEXP (condition, 1)) != CONST_INT\n-\t  || XEXP (condition, 1) != CONST0_RTX (GET_MODE (XEXP (condition, 0))))\n-\tcontinue;\n-\n-      /* We must be checking a register against zero.  */\n-      reg = XEXP (condition, 0);\n-      if (GET_CODE (reg) != REG)\n-\tcontinue;\n-\n       /* Is the register known to have a nonzero value?  */\n-      if (!TEST_BIT (nonnull_avout[bb], REGNO (reg)))\n+      if (!TEST_BIT (nonnull_avout[bb], block_reg[bb] - npi->min_reg))\n \tcontinue;\n \n       /* Try to compute whether the compare/branch at the loop end is one or\n@@ -5170,6 +5165,139 @@ delete_null_pointer_checks (f)\n       delete_insn (last_insn);\n       if (compare_and_branch == 2)\n \tdelete_insn (earliest);\n+\n+      /* Don't check this block again.  (Note that BLOCK_END is\n+\t invalid here; we deleted the last instruction in the \n+\t block.)  */\n+      block_reg[bb] = 0;\n+    }\n+}\n+\n+/* Find EQ/NE comparisons against zero which can be (indirectly) evaluated\n+   at compile time.\n+\n+   This is conceptually similar to global constant/copy propagation and\n+   classic global CSE (it even uses the same dataflow equations as cprop).\n+\n+   If a register is used as memory address with the form (mem (reg)), then we\n+   know that REG can not be zero at that point in the program.  Any instruction\n+   which sets REG \"kills\" this property.\n+\n+   So, if every path leading to a conditional branch has an available memory\n+   reference of that form, then we know the register can not have the value\n+   zero at the conditional branch.  \n+\n+   So we merely need to compute the local properies and propagate that data\n+   around the cfg, then optimize where possible.\n+\n+   We run this pass two times.  Once before CSE, then again after CSE.  This\n+   has proven to be the most profitable approach.  It is rare for new\n+   optimization opportunities of this nature to appear after the first CSE\n+   pass.\n+\n+   This could probably be integrated with global cprop with a little work.  */\n+\n+void\n+delete_null_pointer_checks (f)\n+     rtx f;\n+{\n+  int_list_ptr *s_preds, *s_succs;\n+  int *num_preds, *num_succs;\n+  sbitmap *nonnull_avin, *nonnull_avout;\n+  int *block_reg;\n+  int bb;\n+  int reg;\n+  int regs_per_pass;\n+  int max_reg;\n+  struct null_pointer_info npi;\n+\n+  /* First break the program into basic blocks.  */\n+  find_basic_blocks (f, max_reg_num (), NULL, 1);\n+\n+  /* If we have only a single block, then there's nothing to do.  */\n+  if (n_basic_blocks <= 1)\n+    {\n+      /* Free storage allocated by find_basic_blocks.  */\n+      free_basic_block_vars (0);\n+      return;\n+    }\n+\n+  /* Trying to perform global optimizations on flow graphs which have\n+     a high connectivity will take a long time and is unlikely to be\n+     particularly useful.\n+\n+     In normal circumstances a cfg should have about twice has many edges\n+     as blocks.  But we do not want to punish small functions which have\n+     a couple switch statements.  So we require a relatively large number\n+     of basic blocks and the ratio of edges to blocks to be high.  */\n+  if (n_basic_blocks > 1000 && n_edges / n_basic_blocks >= 20)\n+    {\n+      /* Free storage allocated by find_basic_blocks.  */\n+      free_basic_block_vars (0);\n+      return;\n+    }\n+\n+  /* We need predecessor/successor lists as well as pred/succ counts for\n+     each basic block.  */\n+  s_preds = (int_list_ptr *) gmalloc (n_basic_blocks * sizeof (int_list_ptr));\n+  s_succs = (int_list_ptr *) gmalloc (n_basic_blocks * sizeof (int_list_ptr));\n+  num_preds = (int *) gmalloc (n_basic_blocks * sizeof (int));\n+  num_succs = (int *) gmalloc (n_basic_blocks * sizeof (int));\n+  compute_preds_succs (s_preds, s_succs, num_preds, num_succs);\n+\n+  /* We need four bitmaps, each with a bit for each register in each\n+     basic block.  */\n+  max_reg = max_reg_num ();\n+  regs_per_pass = get_bitmap_width (4, n_basic_blocks, max_reg);\n+\n+  /* Allocate bitmaps to hold local and global properties.  */\n+  npi.nonnull_local = sbitmap_vector_alloc (n_basic_blocks, regs_per_pass);\n+  npi.nonnull_killed = sbitmap_vector_alloc (n_basic_blocks, regs_per_pass);\n+  nonnull_avin = sbitmap_vector_alloc (n_basic_blocks, regs_per_pass);\n+  nonnull_avout = sbitmap_vector_alloc (n_basic_blocks, regs_per_pass);\n+\n+  /* Go through the basic blocks, seeing whether or not each block\n+     ends with a conditional branch whose condition is a comparison\n+     against zero.  Record the register compared in BLOCK_REG.  */\n+  block_reg = (int *) xcalloc (n_basic_blocks, sizeof (int));\n+  for (bb = 0; bb < n_basic_blocks; bb++)\n+    {\n+      rtx last_insn = BLOCK_END (bb);\n+      rtx condition, earliest, reg;\n+\n+      /* We only want conditional branches.  */\n+      if (GET_CODE (last_insn) != JUMP_INSN\n+\t  || !condjump_p (last_insn)\n+\t  || simplejump_p (last_insn))\n+\tcontinue;\n+\n+      /* LAST_INSN is a conditional jump.  Get its condition.  */\n+      condition = get_condition (last_insn, &earliest);\n+\n+      /* If we were unable to get the condition, or it is not a equality\n+\t comparison against zero then there's nothing we can do.  */\n+      if (!condition\n+\t  || (GET_CODE (condition) != NE && GET_CODE (condition) != EQ)\n+\t  || GET_CODE (XEXP (condition, 1)) != CONST_INT\n+\t  || (XEXP (condition, 1) \n+\t      != CONST0_RTX (GET_MODE (XEXP (condition, 0)))))\n+\tcontinue;\n+\n+      /* We must be checking a register against zero.  */\n+      reg = XEXP (condition, 0);\n+      if (GET_CODE (reg) != REG)\n+\tcontinue;\n+\n+      block_reg[bb] = REGNO (reg);\n+    }\n+\n+  /* Go through the algorithm for each block of registers.  */\n+  for (reg = FIRST_PSEUDO_REGISTER; reg < max_reg; reg += regs_per_pass)\n+    {\n+      npi.min_reg = reg;\n+      npi.max_reg = MIN (reg + regs_per_pass, max_reg);\n+      delete_null_pointer_checks_1 (s_preds, block_reg, nonnull_avin,\n+\t\t\t\t    nonnull_avout, &npi);\n     }\n \n   /* Free storage allocated by find_basic_blocks.  */\n@@ -5181,9 +5309,12 @@ delete_null_pointer_checks (f)\n   free (num_preds);\n   free (num_succs);\n \n+  /* Free the table of registers compared at the end of every block.  */\n+  free (block_reg);\n+\n   /* Free bitmaps.  */\n-  free (nonnull_local);\n-  free (nonnull_killed);\n+  free (npi.nonnull_local);\n+  free (npi.nonnull_killed);\n   free (nonnull_avin);\n   free (nonnull_avout);\n }"}]}