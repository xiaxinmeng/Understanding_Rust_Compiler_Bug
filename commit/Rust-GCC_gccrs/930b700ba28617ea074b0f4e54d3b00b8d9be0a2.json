{"sha": "930b700ba28617ea074b0f4e54d3b00b8d9be0a2", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6OTMwYjcwMGJhMjg2MTdlYTA3NGIwZjRlNTRkM2IwMGI4ZDliZTBhMg==", "commit": {"author": {"name": "Michael Zolotukhin", "email": "michael.v.zolotukhin@gmail.com", "date": "2013-07-08T06:48:15Z"}, "committer": {"name": "Kirill Yukhin", "email": "kyukhin@gcc.gnu.org", "date": "2013-07-08T06:48:15Z"}, "message": "i386-opts.h (enum stringop_alg): Add vector_loop.\n\nChangeLog:\n        * config/i386/i386-opts.h (enum stringop_alg): Add vector_loop.\n        * config/i386/i386.c (expand_set_or_movmem_via_loop): Use\n        adjust_address instead of change_address to keep info about alignment.\n        (emit_strmov): Remove.\n        (emit_memmov): New function.\n        (expand_movmem_epilogue): Refactor to properly handle bigger sizes.\n        (expand_movmem_epilogue): Likewise and return updated rtx for\n        destination.\n        (expand_constant_movmem_prologue): Likewise and return updated rtx for\n        destination and source.\n        (decide_alignment): Refactor, handle vector_loop.\n        (ix86_expand_movmem): Likewise.\n        (ix86_expand_setmem): Likewise.\n        * config/i386/i386.opt (Enum): Add vector_loop to option stringop_alg.\n\ntestsuite/ChangeLog:\n        * gcc.target/i386/memcpy-vector_loop-1.c: New.\n        * gcc.target/i386/memcpy-vector_loop-2.c: New.\n\nFrom-SVN: r200751", "tree": {"sha": "ba89b5940f5318ef03d3bc4262cca5673f95b354", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/ba89b5940f5318ef03d3bc4262cca5673f95b354"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/930b700ba28617ea074b0f4e54d3b00b8d9be0a2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/930b700ba28617ea074b0f4e54d3b00b8d9be0a2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/930b700ba28617ea074b0f4e54d3b00b8d9be0a2", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/930b700ba28617ea074b0f4e54d3b00b8d9be0a2/comments", "author": {"login": "ZolotukhinM", "id": 4588111, "node_id": "MDQ6VXNlcjQ1ODgxMTE=", "avatar_url": "https://avatars.githubusercontent.com/u/4588111?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ZolotukhinM", "html_url": "https://github.com/ZolotukhinM", "followers_url": "https://api.github.com/users/ZolotukhinM/followers", "following_url": "https://api.github.com/users/ZolotukhinM/following{/other_user}", "gists_url": "https://api.github.com/users/ZolotukhinM/gists{/gist_id}", "starred_url": "https://api.github.com/users/ZolotukhinM/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ZolotukhinM/subscriptions", "organizations_url": "https://api.github.com/users/ZolotukhinM/orgs", "repos_url": "https://api.github.com/users/ZolotukhinM/repos", "events_url": "https://api.github.com/users/ZolotukhinM/events{/privacy}", "received_events_url": "https://api.github.com/users/ZolotukhinM/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "c8dfadf8f35a6d636f8dbc51590f7b530ef34d4f", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c8dfadf8f35a6d636f8dbc51590f7b530ef34d4f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c8dfadf8f35a6d636f8dbc51590f7b530ef34d4f"}], "stats": {"total": 485, "additions": 259, "deletions": 226}, "files": [{"sha": "6ece60c2148bd9559db684b0c6731e241a9cd790", "filename": "gcc/ChangeLog", "status": "modified", "additions": 17, "deletions": 0, "changes": 17, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/930b700ba28617ea074b0f4e54d3b00b8d9be0a2/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/930b700ba28617ea074b0f4e54d3b00b8d9be0a2/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=930b700ba28617ea074b0f4e54d3b00b8d9be0a2", "patch": "@@ -1,3 +1,20 @@\n+2013-07-08  Michael Zolotukhin  <michael.v.zolotukhin@gmail.com>\n+\n+\t* config/i386/i386-opts.h (enum stringop_alg): Add vector_loop.\n+\t* config/i386/i386.c (expand_set_or_movmem_via_loop): Use\n+\tadjust_address instead of change_address to keep info about alignment.\n+\t(emit_strmov): Remove.\n+\t(emit_memmov): New function.\n+\t(expand_movmem_epilogue): Refactor to properly handle bigger sizes.\n+\t(expand_movmem_epilogue): Likewise and return updated rtx for\n+\tdestination.\n+\t(expand_constant_movmem_prologue): Likewise and return updated rtx for\n+\tdestination and source.\n+\t(decide_alignment): Refactor, handle vector_loop.\n+\t(ix86_expand_movmem): Likewise.\n+\t(ix86_expand_setmem): Likewise.\n+\t* config/i386/i386.opt (Enum): Add vector_loop to option stringop_alg.\n+\n 2013-07-07  Uros Bizjak  <ubizjak@gmail.com>\n \n \t* config/i386/driver-i386.c (host_detect_local_cpu): Do not check"}, {"sha": "bea1c2578301a0a2db86b6bc2bd492911f439b9a", "filename": "gcc/config/i386/i386-opts.h", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/930b700ba28617ea074b0f4e54d3b00b8d9be0a2/gcc%2Fconfig%2Fi386%2Fi386-opts.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/930b700ba28617ea074b0f4e54d3b00b8d9be0a2/gcc%2Fconfig%2Fi386%2Fi386-opts.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386-opts.h?ref=930b700ba28617ea074b0f4e54d3b00b8d9be0a2", "patch": "@@ -35,7 +35,8 @@ enum stringop_alg\n    rep_prefix_8_byte,\n    loop_1_byte,\n    loop,\n-   unrolled_loop\n+   unrolled_loop,\n+   vector_loop\n };\n \n /* Available call abi.  */"}, {"sha": "77268391ae20e4e5e7caef45b0c70ccf998c7521", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 208, "deletions": 225, "changes": 433, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/930b700ba28617ea074b0f4e54d3b00b8d9be0a2/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/930b700ba28617ea074b0f4e54d3b00b8d9be0a2/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=930b700ba28617ea074b0f4e54d3b00b8d9be0a2", "patch": "@@ -21953,11 +21953,10 @@ expand_set_or_movmem_via_loop (rtx destmem, rtx srcmem,\n {\n   rtx out_label, top_label, iter, tmp;\n   enum machine_mode iter_mode = counter_mode (count);\n-  rtx piece_size = GEN_INT (GET_MODE_SIZE (mode) * unroll);\n+  int piece_size_n = GET_MODE_SIZE (mode) * unroll;\n+  rtx piece_size = GEN_INT (piece_size_n);\n   rtx piece_size_mask = GEN_INT (~((GET_MODE_SIZE (mode) * unroll) - 1));\n   rtx size;\n-  rtx x_addr;\n-  rtx y_addr;\n   int i;\n \n   top_label = gen_label_rtx ();\n@@ -21978,13 +21977,18 @@ expand_set_or_movmem_via_loop (rtx destmem, rtx srcmem,\n   emit_label (top_label);\n \n   tmp = convert_modes (Pmode, iter_mode, iter, true);\n-  x_addr = gen_rtx_PLUS (Pmode, destptr, tmp);\n-  destmem = change_address (destmem, mode, x_addr);\n+\n+  /* This assert could be relaxed - in this case we'll need to compute\n+     smallest power of two, containing in PIECE_SIZE_N and pass it to\n+     offset_address.  */\n+  gcc_assert ((piece_size_n & (piece_size_n - 1)) == 0);\n+  destmem = offset_address (destmem, tmp, piece_size_n);\n+  destmem = adjust_address (destmem, mode, 0);\n \n   if (srcmem)\n     {\n-      y_addr = gen_rtx_PLUS (Pmode, srcptr, copy_rtx (tmp));\n-      srcmem = change_address (srcmem, mode, y_addr);\n+      srcmem = offset_address (srcmem, copy_rtx (tmp), piece_size_n);\n+      srcmem = adjust_address (srcmem, mode, 0);\n \n       /* When unrolling for chips that reorder memory reads and writes,\n \t we can save registers by using single temporary.\n@@ -22163,13 +22167,76 @@ expand_setmem_via_rep_stos (rtx destmem, rtx destptr, rtx value,\n   emit_insn (gen_rep_stos (destptr, countreg, destmem, value, destexp));\n }\n \n-static void\n-emit_strmov (rtx destmem, rtx srcmem,\n-\t     rtx destptr, rtx srcptr, enum machine_mode mode, int offset)\n+/* This function emits moves to copy SIZE_TO_MOVE bytes from SRCMEM to\n+   DESTMEM.\n+   SRC is passed by pointer to be updated on return.\n+   Return value is updated DST.  */\n+static rtx\n+emit_memmov (rtx destmem, rtx *srcmem, rtx destptr, rtx srcptr,\n+\t     HOST_WIDE_INT size_to_move)\n {\n-  rtx src = adjust_automodify_address_nv (srcmem, mode, srcptr, offset);\n-  rtx dest = adjust_automodify_address_nv (destmem, mode, destptr, offset);\n-  emit_insn (gen_strmov (destptr, dest, srcptr, src));\n+  rtx dst = destmem, src = *srcmem, adjust, tempreg;\n+  enum insn_code code;\n+  enum machine_mode move_mode;\n+  int piece_size, i;\n+\n+  /* Find the widest mode in which we could perform moves.\n+     Start with the biggest power of 2 less than SIZE_TO_MOVE and half\n+     it until move of such size is supported.  */\n+  piece_size = 1 << floor_log2 (size_to_move);\n+  move_mode = mode_for_size (piece_size * BITS_PER_UNIT, MODE_INT, 0);\n+  code = optab_handler (mov_optab, move_mode);\n+  while (code == CODE_FOR_nothing && piece_size > 1)\n+    {\n+      piece_size >>= 1;\n+      move_mode = mode_for_size (piece_size * BITS_PER_UNIT, MODE_INT, 0);\n+      code = optab_handler (mov_optab, move_mode);\n+    }\n+\n+  /* Find the corresponding vector mode with the same size as MOVE_MODE.\n+     MOVE_MODE is an integer mode at the moment (SI, DI, TI, etc.).  */\n+  if (GET_MODE_SIZE (move_mode) > GET_MODE_SIZE (word_mode))\n+    {\n+      int nunits = GET_MODE_SIZE (move_mode) / GET_MODE_SIZE (word_mode);\n+      move_mode = mode_for_vector (word_mode, nunits);\n+      code = optab_handler (mov_optab, move_mode);\n+      if (code == CODE_FOR_nothing)\n+\t{\n+\t  move_mode = word_mode;\n+\t  piece_size = GET_MODE_SIZE (move_mode);\n+\t  code = optab_handler (mov_optab, move_mode);\n+\t}\n+    }\n+  gcc_assert (code != CODE_FOR_nothing);\n+\n+  dst = adjust_automodify_address_nv (dst, move_mode, destptr, 0);\n+  src = adjust_automodify_address_nv (src, move_mode, srcptr, 0);\n+\n+  /* Emit moves.  We'll need SIZE_TO_MOVE/PIECE_SIZES moves.  */\n+  gcc_assert (size_to_move % piece_size == 0);\n+  adjust = GEN_INT (piece_size);\n+  for (i = 0; i < size_to_move; i += piece_size)\n+    {\n+      /* We move from memory to memory, so we'll need to do it via\n+\t a temporary register.  */\n+      tempreg = gen_reg_rtx (move_mode);\n+      emit_insn (GEN_FCN (code) (tempreg, src));\n+      emit_insn (GEN_FCN (code) (dst, tempreg));\n+\n+      emit_move_insn (destptr,\n+\t\t      gen_rtx_PLUS (Pmode, copy_rtx (destptr), adjust));\n+      emit_move_insn (srcptr,\n+\t\t      gen_rtx_PLUS (Pmode, copy_rtx (srcptr), adjust));\n+\n+      dst = adjust_automodify_address_nv (dst, move_mode, destptr,\n+\t\t\t\t\t  piece_size);\n+      src = adjust_automodify_address_nv (src, move_mode, srcptr,\n+\t\t\t\t\t  piece_size);\n+    }\n+\n+  /* Update DST and SRC rtx.  */\n+  *srcmem = src;\n+  return dst;\n }\n \n /* Output code to copy at most count & (max_size - 1) bytes from SRC to DEST.  */\n@@ -22181,44 +22248,17 @@ expand_movmem_epilogue (rtx destmem, rtx srcmem,\n   if (CONST_INT_P (count))\n     {\n       HOST_WIDE_INT countval = INTVAL (count);\n-      int offset = 0;\n+      HOST_WIDE_INT epilogue_size = countval % max_size;\n+      int i;\n \n-      if ((countval & 0x10) && max_size > 16)\n+      /* For now MAX_SIZE should be a power of 2.  This assert could be\n+\t relaxed, but it'll require a bit more complicated epilogue\n+\t expanding.  */\n+      gcc_assert ((max_size & (max_size - 1)) == 0);\n+      for (i = max_size; i >= 1; i >>= 1)\n \t{\n-\t  if (TARGET_64BIT)\n-\t    {\n-\t      emit_strmov (destmem, srcmem, destptr, srcptr, DImode, offset);\n-\t      emit_strmov (destmem, srcmem, destptr, srcptr, DImode, offset + 8);\n-\t    }\n-\t  else\n-\t    gcc_unreachable ();\n-\t  offset += 16;\n-\t}\n-      if ((countval & 0x08) && max_size > 8)\n-\t{\n-\t  if (TARGET_64BIT)\n-\t    emit_strmov (destmem, srcmem, destptr, srcptr, DImode, offset);\n-\t  else\n-\t    {\n-\t      emit_strmov (destmem, srcmem, destptr, srcptr, SImode, offset);\n-\t      emit_strmov (destmem, srcmem, destptr, srcptr, SImode, offset + 4);\n-\t    }\n-\t  offset += 8;\n-\t}\n-      if ((countval & 0x04) && max_size > 4)\n-\t{\n-          emit_strmov (destmem, srcmem, destptr, srcptr, SImode, offset);\n-\t  offset += 4;\n-\t}\n-      if ((countval & 0x02) && max_size > 2)\n-\t{\n-          emit_strmov (destmem, srcmem, destptr, srcptr, HImode, offset);\n-\t  offset += 2;\n-\t}\n-      if ((countval & 0x01) && max_size > 1)\n-\t{\n-          emit_strmov (destmem, srcmem, destptr, srcptr, QImode, offset);\n-\t  offset += 1;\n+\t  if (epilogue_size & i)\n+\t    destmem = emit_memmov (destmem, &srcmem, destptr, srcptr, i);\n \t}\n       return;\n     }\n@@ -22454,110 +22494,68 @@ expand_setmem_epilogue (rtx destmem, rtx destptr, rtx value, rtx count, int max_\n }\n \n /* Copy enough from DEST to SRC to align DEST known to by aligned by ALIGN to\n-   DESIRED_ALIGNMENT.  */\n-static void\n+   DESIRED_ALIGNMENT.\n+   Return value is updated DESTMEM.  */\n+static rtx\n expand_movmem_prologue (rtx destmem, rtx srcmem,\n \t\t\trtx destptr, rtx srcptr, rtx count,\n \t\t\tint align, int desired_alignment)\n {\n-  if (align <= 1 && desired_alignment > 1)\n-    {\n-      rtx label = ix86_expand_aligntest (destptr, 1, false);\n-      srcmem = change_address (srcmem, QImode, srcptr);\n-      destmem = change_address (destmem, QImode, destptr);\n-      emit_insn (gen_strmov (destptr, destmem, srcptr, srcmem));\n-      ix86_adjust_counter (count, 1);\n-      emit_label (label);\n-      LABEL_NUSES (label) = 1;\n-    }\n-  if (align <= 2 && desired_alignment > 2)\n-    {\n-      rtx label = ix86_expand_aligntest (destptr, 2, false);\n-      srcmem = change_address (srcmem, HImode, srcptr);\n-      destmem = change_address (destmem, HImode, destptr);\n-      emit_insn (gen_strmov (destptr, destmem, srcptr, srcmem));\n-      ix86_adjust_counter (count, 2);\n-      emit_label (label);\n-      LABEL_NUSES (label) = 1;\n-    }\n-  if (align <= 4 && desired_alignment > 4)\n+  int i;\n+  for (i = 1; i < desired_alignment; i <<= 1)\n     {\n-      rtx label = ix86_expand_aligntest (destptr, 4, false);\n-      srcmem = change_address (srcmem, SImode, srcptr);\n-      destmem = change_address (destmem, SImode, destptr);\n-      emit_insn (gen_strmov (destptr, destmem, srcptr, srcmem));\n-      ix86_adjust_counter (count, 4);\n-      emit_label (label);\n-      LABEL_NUSES (label) = 1;\n+      if (align <= i)\n+\t{\n+\t  rtx label = ix86_expand_aligntest (destptr, i, false);\n+\t  destmem = emit_memmov (destmem, &srcmem, destptr, srcptr, i);\n+\t  ix86_adjust_counter (count, i);\n+\t  emit_label (label);\n+\t  LABEL_NUSES (label) = 1;\n+\t  set_mem_align (destmem, i * 2 * BITS_PER_UNIT);\n+\t}\n     }\n-  gcc_assert (desired_alignment <= 8);\n+  return destmem;\n }\n \n /* Copy enough from DST to SRC to align DST known to DESIRED_ALIGN.\n-   ALIGN_BYTES is how many bytes need to be copied.  */\n+   ALIGN_BYTES is how many bytes need to be copied.\n+   The function updates DST and SRC, namely, it sets proper alignment.\n+   DST is returned via return value, SRC is updated via pointer SRCP.  */\n static rtx\n expand_constant_movmem_prologue (rtx dst, rtx *srcp, rtx destreg, rtx srcreg,\n \t\t\t\t int desired_align, int align_bytes)\n {\n   rtx src = *srcp;\n   rtx orig_dst = dst;\n   rtx orig_src = src;\n-  int off = 0;\n+  int piece_size = 1;\n+  int copied_bytes = 0;\n   int src_align_bytes = get_mem_align_offset (src, desired_align * BITS_PER_UNIT);\n   if (src_align_bytes >= 0)\n     src_align_bytes = desired_align - src_align_bytes;\n-  if (align_bytes & 1)\n-    {\n-      dst = adjust_automodify_address_nv (dst, QImode, destreg, 0);\n-      src = adjust_automodify_address_nv (src, QImode, srcreg, 0);\n-      off = 1;\n-      emit_insn (gen_strmov (destreg, dst, srcreg, src));\n-    }\n-  if (align_bytes & 2)\n-    {\n-      dst = adjust_automodify_address_nv (dst, HImode, destreg, off);\n-      src = adjust_automodify_address_nv (src, HImode, srcreg, off);\n-      if (MEM_ALIGN (dst) < 2 * BITS_PER_UNIT)\n-\tset_mem_align (dst, 2 * BITS_PER_UNIT);\n-      if (src_align_bytes >= 0\n-\t  && (src_align_bytes & 1) == (align_bytes & 1)\n-\t  && MEM_ALIGN (src) < 2 * BITS_PER_UNIT)\n-\tset_mem_align (src, 2 * BITS_PER_UNIT);\n-      off = 2;\n-      emit_insn (gen_strmov (destreg, dst, srcreg, src));\n-    }\n-  if (align_bytes & 4)\n+\n+  for (piece_size = 1;\n+       piece_size <= desired_align && copied_bytes < align_bytes;\n+       piece_size <<= 1)\n     {\n-      dst = adjust_automodify_address_nv (dst, SImode, destreg, off);\n-      src = adjust_automodify_address_nv (src, SImode, srcreg, off);\n-      if (MEM_ALIGN (dst) < 4 * BITS_PER_UNIT)\n-\tset_mem_align (dst, 4 * BITS_PER_UNIT);\n-      if (src_align_bytes >= 0)\n+      if (align_bytes & piece_size)\n \t{\n-\t  unsigned int src_align = 0;\n-\t  if ((src_align_bytes & 3) == (align_bytes & 3))\n-\t    src_align = 4;\n-\t  else if ((src_align_bytes & 1) == (align_bytes & 1))\n-\t    src_align = 2;\n-\t  if (MEM_ALIGN (src) < src_align * BITS_PER_UNIT)\n-\t    set_mem_align (src, src_align * BITS_PER_UNIT);\n+\t  dst = emit_memmov (dst, &src, destreg, srcreg, piece_size);\n+\t  copied_bytes += piece_size;\n \t}\n-      off = 4;\n-      emit_insn (gen_strmov (destreg, dst, srcreg, src));\n     }\n-  dst = adjust_automodify_address_nv (dst, BLKmode, destreg, off);\n-  src = adjust_automodify_address_nv (src, BLKmode, srcreg, off);\n+\n   if (MEM_ALIGN (dst) < (unsigned int) desired_align * BITS_PER_UNIT)\n     set_mem_align (dst, desired_align * BITS_PER_UNIT);\n   if (src_align_bytes >= 0)\n     {\n-      unsigned int src_align = 0;\n-      if ((src_align_bytes & 7) == (align_bytes & 7))\n-\tsrc_align = 8;\n-      else if ((src_align_bytes & 3) == (align_bytes & 3))\n-\tsrc_align = 4;\n-      else if ((src_align_bytes & 1) == (align_bytes & 1))\n-\tsrc_align = 2;\n+      unsigned int src_align;\n+      for (src_align = desired_align; src_align >= 2; src_align >>= 1)\n+\t{\n+\t  if ((src_align_bytes & (src_align - 1))\n+\t       == (align_bytes & (src_align - 1)))\n+\t    break;\n+\t}\n       if (src_align > (unsigned int) desired_align)\n \tsrc_align = desired_align;\n       if (MEM_ALIGN (src) < src_align * BITS_PER_UNIT)\n@@ -22790,60 +22788,33 @@ decide_alg (HOST_WIDE_INT count, HOST_WIDE_INT expected_size, bool memset,\n static int\n decide_alignment (int align,\n \t\t  enum stringop_alg alg,\n-\t\t  int expected_size)\n+\t\t  int expected_size,\n+\t\t  enum machine_mode move_mode)\n {\n   int desired_align = 0;\n-  switch (alg)\n-    {\n-      case no_stringop:\n-\tgcc_unreachable ();\n-      case loop:\n-      case unrolled_loop:\n-\tdesired_align = GET_MODE_SIZE (Pmode);\n-\tbreak;\n-      case rep_prefix_8_byte:\n-\tdesired_align = 8;\n-\tbreak;\n-      case rep_prefix_4_byte:\n-\t/* PentiumPro has special logic triggering for 8 byte aligned blocks.\n-\t   copying whole cacheline at once.  */\n-\tif (TARGET_PENTIUMPRO)\n-\t  desired_align = 8;\n-\telse\n-\t  desired_align = 4;\n-\tbreak;\n-      case rep_prefix_1_byte:\n-\t/* PentiumPro has special logic triggering for 8 byte aligned blocks.\n-\t   copying whole cacheline at once.  */\n-\tif (TARGET_PENTIUMPRO)\n-\t  desired_align = 8;\n-\telse\n-\t  desired_align = 1;\n-\tbreak;\n-      case loop_1_byte:\n-\tdesired_align = 1;\n-\tbreak;\n-      case libcall:\n-\treturn 0;\n-    }\n+\n+  gcc_assert (alg != no_stringop);\n+\n+  if (alg == libcall)\n+    return 0;\n+  if (move_mode == VOIDmode)\n+    return 0;\n+\n+  desired_align = GET_MODE_SIZE (move_mode);\n+  /* PentiumPro has special logic triggering for 8 byte aligned blocks.\n+     copying whole cacheline at once.  */\n+  if (TARGET_PENTIUMPRO\n+      && (alg == rep_prefix_4_byte || alg == rep_prefix_1_byte))\n+    desired_align = 8;\n \n   if (optimize_size)\n     desired_align = 1;\n   if (desired_align < align)\n     desired_align = align;\n   if (expected_size != -1 && expected_size < 4)\n     desired_align = align;\n-  return desired_align;\n-}\n \n-/* Return the smallest power of 2 greater than VAL.  */\n-static int\n-smallest_pow2_greater_than (int val)\n-{\n-  int ret = 1;\n-  while (ret <= val)\n-    ret <<= 1;\n-  return ret;\n+  return desired_align;\n }\n \n /* Expand string move (memcpy) operation.  Use i386 string operations\n@@ -22889,6 +22860,8 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n   int dynamic_check;\n   bool need_zero_guard = false;\n   bool noalign;\n+  enum machine_mode move_mode = VOIDmode;\n+  int unroll_factor = 1;\n \n   if (CONST_INT_P (align_exp))\n     align = INTVAL (align_exp);\n@@ -22912,50 +22885,71 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n \n   /* Step 0: Decide on preferred algorithm, desired alignment and\n      size of chunks to be copied by main loop.  */\n-\n   alg = decide_alg (count, expected_size, false, &dynamic_check, &noalign);\n-  desired_align = decide_alignment (align, alg, expected_size);\n-\n-  if (!TARGET_ALIGN_STRINGOPS || noalign)\n-    align = desired_align;\n-\n   if (alg == libcall)\n     return false;\n   gcc_assert (alg != no_stringop);\n+\n   if (!count)\n     count_exp = copy_to_mode_reg (GET_MODE (count_exp), count_exp);\n   destreg = copy_addr_to_reg (XEXP (dst, 0));\n   srcreg = copy_addr_to_reg (XEXP (src, 0));\n+\n+  unroll_factor = 1;\n+  move_mode = word_mode;\n   switch (alg)\n     {\n     case libcall:\n     case no_stringop:\n       gcc_unreachable ();\n+    case loop_1_byte:\n+      need_zero_guard = true;\n+      move_mode = QImode;\n+      break;\n     case loop:\n       need_zero_guard = true;\n-      size_needed = GET_MODE_SIZE (word_mode);\n       break;\n     case unrolled_loop:\n       need_zero_guard = true;\n-      size_needed = GET_MODE_SIZE (word_mode) * (TARGET_64BIT ? 4 : 2);\n+      unroll_factor = (TARGET_64BIT ? 4 : 2);\n+      break;\n+    case vector_loop:\n+      need_zero_guard = true;\n+      unroll_factor = 4;\n+      /* Find the widest supported mode.  */\n+      move_mode = word_mode;\n+      while (optab_handler (mov_optab, GET_MODE_WIDER_MODE (move_mode))\n+\t     != CODE_FOR_nothing)\n+\t  move_mode = GET_MODE_WIDER_MODE (move_mode);\n+\n+      /* Find the corresponding vector mode with the same size as MOVE_MODE.\n+\t MOVE_MODE is an integer mode at the moment (SI, DI, TI, etc.).  */\n+      if (GET_MODE_SIZE (move_mode) > GET_MODE_SIZE (word_mode))\n+\t{\n+\t  int nunits = GET_MODE_SIZE (move_mode) / GET_MODE_SIZE (word_mode);\n+\t  move_mode = mode_for_vector (word_mode, nunits);\n+\t  if (optab_handler (mov_optab, move_mode) == CODE_FOR_nothing)\n+\t    move_mode = word_mode;\n+\t}\n+      gcc_assert (optab_handler (mov_optab, move_mode) != CODE_FOR_nothing);\n       break;\n     case rep_prefix_8_byte:\n-      size_needed = 8;\n+      move_mode = DImode;\n       break;\n     case rep_prefix_4_byte:\n-      size_needed = 4;\n+      move_mode = SImode;\n       break;\n     case rep_prefix_1_byte:\n-      size_needed = 1;\n-      break;\n-    case loop_1_byte:\n-      need_zero_guard = true;\n-      size_needed = 1;\n+      move_mode = QImode;\n       break;\n     }\n-\n+  size_needed = GET_MODE_SIZE (move_mode) * unroll_factor;\n   epilogue_size_needed = size_needed;\n \n+  desired_align = decide_alignment (align, alg, expected_size, move_mode);\n+  if (!TARGET_ALIGN_STRINGOPS || noalign)\n+    align = desired_align;\n+\n   /* Step 1: Prologue guard.  */\n \n   /* Alignment code needs count to be in register.  */\n@@ -22982,7 +22976,7 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n       epilogue_size_needed = MAX (size_needed - 1, desired_align - align);\n       /* Epilogue always copies COUNT_EXP & EPILOGUE_SIZE_NEEDED bytes.\n \t Make sure it is power of 2.  */\n-      epilogue_size_needed = smallest_pow2_greater_than (epilogue_size_needed);\n+      epilogue_size_needed = 1 << (floor_log2 (epilogue_size_needed) + 1);\n \n       if (count)\n \t{\n@@ -23047,8 +23041,8 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n \t     the info early.  */\n \t  src = change_address (src, BLKmode, srcreg);\n \t  dst = change_address (dst, BLKmode, destreg);\n-\t  expand_movmem_prologue (dst, src, destreg, srcreg, count_exp, align,\n-\t\t\t\t  desired_align);\n+\t  dst = expand_movmem_prologue (dst, src, destreg, srcreg, count_exp, align,\n+\t\t\t\t\tdesired_align);\n \t}\n       else\n \t{\n@@ -23099,31 +23093,18 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n     case no_stringop:\n       gcc_unreachable ();\n     case loop_1_byte:\n-      expand_set_or_movmem_via_loop (dst, src, destreg, srcreg, NULL,\n-\t\t\t\t     count_exp, QImode, 1, expected_size);\n-      break;\n     case loop:\n-      expand_set_or_movmem_via_loop (dst, src, destreg, srcreg, NULL,\n-\t\t\t\t     count_exp, word_mode, 1, expected_size);\n-      break;\n     case unrolled_loop:\n-      /* Unroll only by factor of 2 in 32bit mode, since we don't have enough\n-\t registers for 4 temporaries anyway.  */\n+    case vector_loop:\n       expand_set_or_movmem_via_loop (dst, src, destreg, srcreg, NULL,\n-\t\t\t\t     count_exp, word_mode, TARGET_64BIT ? 4 : 2,\n+\t\t\t\t     count_exp, move_mode, unroll_factor,\n \t\t\t\t     expected_size);\n       break;\n     case rep_prefix_8_byte:\n-      expand_movmem_via_rep_mov (dst, src, destreg, srcreg, count_exp,\n-\t\t\t\t DImode);\n-      break;\n     case rep_prefix_4_byte:\n-      expand_movmem_via_rep_mov (dst, src, destreg, srcreg, count_exp,\n-\t\t\t\t SImode);\n-      break;\n     case rep_prefix_1_byte:\n       expand_movmem_via_rep_mov (dst, src, destreg, srcreg, count_exp,\n-\t\t\t\t QImode);\n+\t\t\t\t move_mode);\n       break;\n     }\n   /* Adjust properly the offset of src and dest memory for aliasing.  */\n@@ -23164,7 +23145,7 @@ ix86_expand_movmem (rtx dst, rtx src, rtx count_exp, rtx align_exp,\n \n   if (count_exp != const0_rtx && epilogue_size_needed > 1)\n     expand_movmem_epilogue (dst, src, destreg, srcreg, count_exp,\n-\t\t\t    epilogue_size_needed);\n+\t\t\t    size_needed);\n   if (jump_around_label)\n     emit_label (jump_around_label);\n   return true;\n@@ -23285,6 +23266,8 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n   int dynamic_check;\n   bool need_zero_guard = false;\n   bool noalign;\n+  enum machine_mode move_mode = VOIDmode;\n+  int unroll_factor;\n \n   if (CONST_INT_P (align_exp))\n     align = INTVAL (align_exp);\n@@ -23305,46 +23288,50 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n      size of chunks to be copied by main loop.  */\n \n   alg = decide_alg (count, expected_size, true, &dynamic_check, &noalign);\n-  desired_align = decide_alignment (align, alg, expected_size);\n-\n-  if (!TARGET_ALIGN_STRINGOPS || noalign)\n-    align = desired_align;\n-\n   if (alg == libcall)\n     return false;\n   gcc_assert (alg != no_stringop);\n+\n   if (!count)\n     count_exp = copy_to_mode_reg (counter_mode (count_exp), count_exp);\n   destreg = copy_addr_to_reg (XEXP (dst, 0));\n+\n+  move_mode = word_mode;\n+  unroll_factor = 1;\n   switch (alg)\n     {\n     case libcall:\n     case no_stringop:\n       gcc_unreachable ();\n     case loop:\n       need_zero_guard = true;\n-      size_needed = GET_MODE_SIZE (word_mode);\n       break;\n+    case vector_loop:\n     case unrolled_loop:\n       need_zero_guard = true;\n-      size_needed = GET_MODE_SIZE (word_mode) * 4;\n+      unroll_factor = 4;\n       break;\n     case rep_prefix_8_byte:\n-      size_needed = 8;\n+      move_mode = DImode;\n       break;\n     case rep_prefix_4_byte:\n-      size_needed = 4;\n+      move_mode = SImode;\n       break;\n     case rep_prefix_1_byte:\n-      size_needed = 1;\n+      move_mode = QImode;\n       break;\n     case loop_1_byte:\n       need_zero_guard = true;\n-      size_needed = 1;\n+      move_mode = QImode;\n       break;\n     }\n+  size_needed = GET_MODE_SIZE (move_mode) * unroll_factor;\n   epilogue_size_needed = size_needed;\n \n+  desired_align = decide_alignment (align, alg, expected_size, move_mode);\n+  if (!TARGET_ALIGN_STRINGOPS || noalign)\n+    align = desired_align;\n+\n   /* Step 1: Prologue guard.  */\n \n   /* Alignment code needs count to be in register.  */\n@@ -23380,7 +23367,7 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n       epilogue_size_needed = MAX (size_needed - 1, desired_align - align);\n       /* Epilogue always copies COUNT_EXP & (EPILOGUE_SIZE_NEEDED - 1) bytes.\n \t Make sure it is power of 2.  */\n-      epilogue_size_needed = smallest_pow2_greater_than (epilogue_size_needed);\n+      epilogue_size_needed = 1 << (floor_log2 (epilogue_size_needed) + 1);\n \n       /* To improve performance of small blocks, we jump around the VAL\n \t promoting mode.  This mean that if the promoted VAL is not constant,\n@@ -23494,16 +23481,12 @@ ix86_expand_setmem (rtx dst, rtx count_exp, rtx val_exp, rtx align_exp,\n     case no_stringop:\n       gcc_unreachable ();\n     case loop_1_byte:\n-      expand_set_or_movmem_via_loop (dst, NULL, destreg, NULL, promoted_val,\n-\t\t\t\t     count_exp, QImode, 1, expected_size);\n-      break;\n     case loop:\n-      expand_set_or_movmem_via_loop (dst, NULL, destreg, NULL, promoted_val,\n-\t\t\t\t     count_exp, word_mode, 1, expected_size);\n-      break;\n+    case vector_loop:\n     case unrolled_loop:\n       expand_set_or_movmem_via_loop (dst, NULL, destreg, NULL, promoted_val,\n-\t\t\t\t     count_exp, word_mode, 4, expected_size);\n+\t\t\t\t     count_exp, move_mode, unroll_factor,\n+\t\t\t\t     expected_size);\n       break;\n     case rep_prefix_8_byte:\n       expand_setmem_via_rep_stos (dst, destreg, promoted_val, count_exp,"}, {"sha": "9fbf5451e9cd1958ebc5e58460a4f78ed602fbb5", "filename": "gcc/config/i386/i386.opt", "status": "modified", "additions": 3, "deletions": 0, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/930b700ba28617ea074b0f4e54d3b00b8d9be0a2/gcc%2Fconfig%2Fi386%2Fi386.opt", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/930b700ba28617ea074b0f4e54d3b00b8d9be0a2/gcc%2Fconfig%2Fi386%2Fi386.opt", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.opt?ref=930b700ba28617ea074b0f4e54d3b00b8d9be0a2", "patch": "@@ -345,6 +345,9 @@ Enum(stringop_alg) String(loop) Value(loop)\n EnumValue\n Enum(stringop_alg) String(unrolled_loop) Value(unrolled_loop)\n \n+EnumValue\n+Enum(stringop_alg) String(vector_loop) Value(vector_loop)\n+\n mtls-dialect=\n Target RejectNegative Joined Var(ix86_tls_dialect) Enum(tls_dialect) Init(TLS_DIALECT_GNU)\n Use given thread-local storage dialect"}, {"sha": "c0a3b599d8ecbf7b2fe1b0b06e590b30d31337e6", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/930b700ba28617ea074b0f4e54d3b00b8d9be0a2/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/930b700ba28617ea074b0f4e54d3b00b8d9be0a2/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=930b700ba28617ea074b0f4e54d3b00b8d9be0a2", "patch": "@@ -1,3 +1,8 @@\n+2013-07-08  Michael Zolotukhin  <michael.v.zolotukhin@gmail.com>\n+\n+\t* gcc.target/i386/memcpy-vector_loop-1.c: New.\n+\t* gcc.target/i386/memcpy-vector_loop-2.c: New.\n+\n 2013-07-06  Uros Bizjak  <ubizjak@gmail.com>\n \n \tPR target/57807"}, {"sha": "c61c067951b0aad6efdd5369b91f6ef0f826b548", "filename": "gcc/testsuite/gcc.target/i386/memcpy-vector_loop-1.c", "status": "added", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/930b700ba28617ea074b0f4e54d3b00b8d9be0a2/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fmemcpy-vector_loop-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/930b700ba28617ea074b0f4e54d3b00b8d9be0a2/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fmemcpy-vector_loop-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fmemcpy-vector_loop-1.c?ref=930b700ba28617ea074b0f4e54d3b00b8d9be0a2", "patch": "@@ -0,0 +1,12 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O2 -march=atom -minline-all-stringops -mstringop-strategy=vector_loop\" } */\n+/* { dg-final { scan-assembler-times \"movdqa\" 8 { target { ! { ia32 } } } } } */\n+/* { dg-final { scan-assembler-times \"movdqa\" 4 { target { ia32 } } } } */\n+\n+char a[2048];\n+char b[2048];\n+void t (void)\n+{\n+  __builtin_memcpy (a, b, 2048);\n+}\n+"}, {"sha": "8a646d509a18d4d5c294e4c14610a40185eec83e", "filename": "gcc/testsuite/gcc.target/i386/memcpy-vector_loop-2.c", "status": "added", "additions": 12, "deletions": 0, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/930b700ba28617ea074b0f4e54d3b00b8d9be0a2/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fmemcpy-vector_loop-2.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/930b700ba28617ea074b0f4e54d3b00b8d9be0a2/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fmemcpy-vector_loop-2.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Fi386%2Fmemcpy-vector_loop-2.c?ref=930b700ba28617ea074b0f4e54d3b00b8d9be0a2", "patch": "@@ -0,0 +1,12 @@\n+/* { dg-do compile } */\n+/* { dg-options \"-O2 -march=atom -minline-all-stringops -mstringop-strategy=vector_loop\" } */\n+/* { dg-final { scan-assembler-times \"movdqa\" 4} } */\n+\n+char *a;\n+char *b;\n+void t (void)\n+{\n+  __builtin_memcpy (a, b, 2048);\n+}\n+\n+"}]}