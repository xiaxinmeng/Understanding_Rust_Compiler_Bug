{"sha": "c25696045a8422510cc2bdea80cd68eabc16d25f", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YzI1Njk2MDQ1YTg0MjI1MTBjYzJiZGVhODBjZDY4ZWFiYzE2ZDI1Zg==", "commit": {"author": {"name": "Ian Lance Taylor", "email": "iant@google.com", "date": "2009-06-10T16:21:03Z"}, "committer": {"name": "Ian Lance Taylor", "email": "ian@gcc.gnu.org", "date": "2009-06-10T16:21:03Z"}, "message": "vec.h (DEF_VEC_ALLOC_I): Use DEF_VEC_NONALLOC_FUNCS_I.\n\n\t* vec.h (DEF_VEC_ALLOC_I): Use DEF_VEC_NONALLOC_FUNCS_I.\n\t(DEF_VEC_ALLOC_P): Use DEF_VEC_NONALLOC_FUNCS_P.\n\t(DEF_VEC_ALLOC_O): Use DEF_VEC_NONALLOC_FUNCS_O.\n\t(DEF_VEC_ALLOC_FUNC_P): Only define VEC_OP (T,A,alloc).\n\t(DEF_VEC_NONALLOC_FUNCS_P): New macro, broken out of old\n\tDEF_VEC_ALLOC_FUNC_P.\n\t(DEF_VEC_ALLOC_FUNC_O): Only define VEC_OP (T,A,alloc).\n\t(DEF_VEC_NONALLOC_FUNCS_O): New macro, broken out of old\n\tDEF_VEC_ALLOC_FUNC_O.\n\t(DEF_VEC_ALLOC_FUNC_I): Only define VEC_OP (T,A,alloc).\n\t(DEF_VEC_NONALLOC_FUNCS_I): New macro, broken out of old\n\tDEF_VEC_ALLOC_FUNC_I.\n\t(vec_stack_p_reserve, vec_stack_p_reserve_exact): Declare.\n\t(vec_stack_p_reserve_exact_1): Declare.\n\t(vec_stack_o_reserve, vec_stack_o_reserve_exact): Declare.\n\t(vec_stack_free): Declare.\n\t(VEC_stack_alloc): Define.\n\t(DEF_VEC_ALLOC_P_STACK, DEF_VEC_ALLOC_FUNC_P_STACK): Define.\n\t(DEF_VEC_ALLOC_O_STACK, DEF_VEC_ALLOC_FUNC_O_STACK): Define.\n\t(DEF_VEC_ALLOC_I_STACK, DEF_VEC_ALLOC_FUNC_I_STACK): Define.\n\t* vec.c (void_p): New type.  Call DEF_VEC_P and DEF_VEC_ALLOC_P\n\tfor void_p.\n\t(stack_vecs): New static variable.\n\t(vec_stack_p_reserve_exact_1): New function.\n\t(vec_stack_o_reserve_1): New static function.\n\t(vec_stack_p_reserve, vec_stack_p_reserve_exact): New functions.\n\t(vec_stack_o_reserve, vec_stack_o_reserve_exact): New functions.\n\t(vec_stack_free): New function.\n\t* df-scan.c (df_ref): Use DEF_VEC_P and DEF_VEC_ALLOC_P_STACK.\n\t(VEC_df_ref_stack_alloc): Define.\n\t(df_mw_hardreg_ptr): New type.  Use DEF_VEC_P and\n\tDEF_VEC_ALLOC_P_STACK.\n\t(VEC_df_mw_hardreg_ptr_stack_alloc): Define.\n\t(struct df_collection_rec): Change _vec fields to VEC.  Remove\n\t_use fields.\n\t(df_free_collection_rec): Adjust for new fields.\n\t(df_insn_rescan): Use new df_collection_rec fields.\n\t(df_notes_rescan, df_canonize_collection_rec): Likewise.\n\t(df_ref_create_structure, df_ref_record): Likewise.\n\t(df_get_conditional_uses, df_get_call_refs): Likewise.\n\t(df_insn_refs_collect, df_bb_refs_collect): Likewise.\n\t(df_bb_refs_record, df_record_entry_block_defs): Likewise.\n\t(df_record_exit_block_uses, df_bb_verify): Likewise.\n\t(df_swap_refs): Change ref_vec parameter to VEC.  Change all\n\tcallers.\n\t(df_sort_and_compress_refs): Change ref_vec parameter to VEC.\n\tRemove count parameter.  Change return type to void.  Change all\n\tcallers.\n\t(df_sort_and_compress_mws): Change mw_vec parameter to VEC.\n\tRemove count parameter.  Change return type to void.  Change all\n\tcallers.\n\t(df_install_refs): Change old_vec parameter to VEC.  Remove count\n\tparameter.  Change all callers.\n\t(df_install_mws): Change old_vec parameter to VEC.  Remove count\n\tparameter.  Change all callers.\n\t(df_refs_verify): Change new_rec parameter to VEC.  Change call\n\tcallers.\n\t(df_mws_verify): Likewise.\n\nFrom-SVN: r148347", "tree": {"sha": "146a14ca67c6acb094e53fa2571c06b76f178775", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/146a14ca67c6acb094e53fa2571c06b76f178775"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/c25696045a8422510cc2bdea80cd68eabc16d25f", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c25696045a8422510cc2bdea80cd68eabc16d25f", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c25696045a8422510cc2bdea80cd68eabc16d25f", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c25696045a8422510cc2bdea80cd68eabc16d25f/comments", "author": null, "committer": null, "parents": [{"sha": "e7aae3e8dfb1b09c77c86877ec1acfd19ce386ea", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e7aae3e8dfb1b09c77c86877ec1acfd19ce386ea", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e7aae3e8dfb1b09c77c86877ec1acfd19ce386ea"}], "stats": {"total": 645, "additions": 485, "deletions": 160}, "files": [{"sha": "6e4a25f1d15311dc7054f06731d54127bf86d635", "filename": "gcc/ChangeLog", "status": "modified", "additions": 61, "deletions": 0, "changes": 61, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c25696045a8422510cc2bdea80cd68eabc16d25f/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c25696045a8422510cc2bdea80cd68eabc16d25f/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=c25696045a8422510cc2bdea80cd68eabc16d25f", "patch": "@@ -1,3 +1,64 @@\n+2009-06-10  Ian Lance Taylor  <iant@google.com>\n+\n+\t* vec.h (DEF_VEC_ALLOC_I): Use DEF_VEC_NONALLOC_FUNCS_I.\n+\t(DEF_VEC_ALLOC_P): Use DEF_VEC_NONALLOC_FUNCS_P.\n+\t(DEF_VEC_ALLOC_O): Use DEF_VEC_NONALLOC_FUNCS_O.\n+\t(DEF_VEC_ALLOC_FUNC_P): Only define VEC_OP (T,A,alloc).\n+\t(DEF_VEC_NONALLOC_FUNCS_P): New macro, broken out of old\n+\tDEF_VEC_ALLOC_FUNC_P.\n+\t(DEF_VEC_ALLOC_FUNC_O): Only define VEC_OP (T,A,alloc).\n+\t(DEF_VEC_NONALLOC_FUNCS_O): New macro, broken out of old\n+\tDEF_VEC_ALLOC_FUNC_O.\n+\t(DEF_VEC_ALLOC_FUNC_I): Only define VEC_OP (T,A,alloc).\n+\t(DEF_VEC_NONALLOC_FUNCS_I): New macro, broken out of old\n+\tDEF_VEC_ALLOC_FUNC_I.\n+\t(vec_stack_p_reserve, vec_stack_p_reserve_exact): Declare.\n+\t(vec_stack_p_reserve_exact_1): Declare.\n+\t(vec_stack_o_reserve, vec_stack_o_reserve_exact): Declare.\n+\t(vec_stack_free): Declare.\n+\t(VEC_stack_alloc): Define.\n+\t(DEF_VEC_ALLOC_P_STACK, DEF_VEC_ALLOC_FUNC_P_STACK): Define.\n+\t(DEF_VEC_ALLOC_O_STACK, DEF_VEC_ALLOC_FUNC_O_STACK): Define.\n+\t(DEF_VEC_ALLOC_I_STACK, DEF_VEC_ALLOC_FUNC_I_STACK): Define.\n+\t* vec.c (void_p): New type.  Call DEF_VEC_P and DEF_VEC_ALLOC_P\n+\tfor void_p.\n+\t(stack_vecs): New static variable.\n+\t(vec_stack_p_reserve_exact_1): New function.\n+\t(vec_stack_o_reserve_1): New static function.\n+\t(vec_stack_p_reserve, vec_stack_p_reserve_exact): New functions.\n+\t(vec_stack_o_reserve, vec_stack_o_reserve_exact): New functions.\n+\t(vec_stack_free): New function.\n+\t* df-scan.c (df_ref): Use DEF_VEC_P and DEF_VEC_ALLOC_P_STACK.\n+\t(VEC_df_ref_stack_alloc): Define.\n+\t(df_mw_hardreg_ptr): New type.  Use DEF_VEC_P and\n+\tDEF_VEC_ALLOC_P_STACK.\n+\t(VEC_df_mw_hardreg_ptr_stack_alloc): Define.\n+\t(struct df_collection_rec): Change _vec fields to VEC.  Remove\n+\t_use fields.\n+\t(df_free_collection_rec): Adjust for new fields.\n+\t(df_insn_rescan): Use new df_collection_rec fields.\n+\t(df_notes_rescan, df_canonize_collection_rec): Likewise.\n+\t(df_ref_create_structure, df_ref_record): Likewise.\n+\t(df_get_conditional_uses, df_get_call_refs): Likewise.\n+\t(df_insn_refs_collect, df_bb_refs_collect): Likewise.\n+\t(df_bb_refs_record, df_record_entry_block_defs): Likewise.\n+\t(df_record_exit_block_uses, df_bb_verify): Likewise.\n+\t(df_swap_refs): Change ref_vec parameter to VEC.  Change all\n+\tcallers.\n+\t(df_sort_and_compress_refs): Change ref_vec parameter to VEC.\n+\tRemove count parameter.  Change return type to void.  Change all\n+\tcallers.\n+\t(df_sort_and_compress_mws): Change mw_vec parameter to VEC.\n+\tRemove count parameter.  Change return type to void.  Change all\n+\tcallers.\n+\t(df_install_refs): Change old_vec parameter to VEC.  Remove count\n+\tparameter.  Change all callers.\n+\t(df_install_mws): Change old_vec parameter to VEC.  Remove count\n+\tparameter.  Change all callers.\n+\t(df_refs_verify): Change new_rec parameter to VEC.  Change call\n+\tcallers.\n+\t(df_mws_verify): Likewise.\n+\n 2009-06-10  Alexandre Oliva  <aoliva@redhat.com>\n \n \t* gcc.c (compare_files): Cast munmap argumento to caddr_t."}, {"sha": "51903da7a9836d1d2429f3a762a35f5beab6ce77", "filename": "gcc/df-scan.c", "status": "modified", "additions": 200, "deletions": 154, "changes": 354, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c25696045a8422510cc2bdea80cd68eabc16d25f/gcc%2Fdf-scan.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c25696045a8422510cc2bdea80cd68eabc16d25f/gcc%2Fdf-scan.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdf-scan.c?ref=c25696045a8422510cc2bdea80cd68eabc16d25f", "patch": "@@ -46,6 +46,19 @@ along with GCC; see the file COPYING3.  If not see\n #include \"df.h\"\n #include \"tree-pass.h\"\n \n+DEF_VEC_P(df_ref);\n+DEF_VEC_ALLOC_P_STACK(df_ref);\n+\n+#define VEC_df_ref_stack_alloc(alloc) VEC_stack_alloc (df_ref, alloc)\n+\n+typedef struct df_mw_hardreg *df_mw_hardreg_ptr;\n+\n+DEF_VEC_P(df_mw_hardreg_ptr);\n+DEF_VEC_ALLOC_P_STACK(df_mw_hardreg_ptr);\n+\n+#define VEC_df_mw_hardreg_ptr_stack_alloc(alloc) \\\n+  VEC_stack_alloc (df_mw_hardreg_ptr, alloc)\n+\n #ifndef HAVE_epilogue\n #define HAVE_epilogue 0\n #endif\n@@ -84,14 +97,10 @@ static HARD_REG_SET elim_reg_set;\n \n struct df_collection_rec\n {\n-  df_ref * def_vec;\n-  df_ref * use_vec;\n-  unsigned int next_def;\n-  unsigned int next_use;\n-  df_ref * eq_use_vec;\n-  struct df_mw_hardreg **mw_vec;\n-  unsigned int next_eq_use;\n-  unsigned int next_mw;\n+  VEC(df_ref,stack) *def_vec;\n+  VEC(df_ref,stack) *use_vec;\n+  VEC(df_ref,stack) *eq_use_vec;\n+  VEC(df_mw_hardreg_ptr,stack) *mw_vec;\n };\n \n static df_ref df_null_ref_rec[1];\n@@ -1180,26 +1189,29 @@ df_insn_delete (basic_block bb, unsigned int uid)\n static void\n df_free_collection_rec (struct df_collection_rec *collection_rec)\n {\n+  unsigned int ix;\n   struct df_scan_problem_data *problem_data \n     = (struct df_scan_problem_data *) df_scan->problem_data;\n-  df_ref *ref;\n-  struct df_mw_hardreg **mw;\n-\n-  if (collection_rec->def_vec)\n-    for (ref = collection_rec->def_vec; *ref; ref++)\n-      df_free_ref (*ref);\n-  if (collection_rec->use_vec)\n-    for (ref = collection_rec->use_vec; *ref; ref++)\n-      df_free_ref (*ref);\n-  if (collection_rec->eq_use_vec)\n-    for (ref = collection_rec->eq_use_vec; *ref; ref++)\n-      df_free_ref (*ref);\n-  if (collection_rec->mw_vec)\n-    for (mw = collection_rec->mw_vec; *mw; mw++)\n-      pool_free (problem_data->mw_reg_pool, *mw);\n+  df_ref ref;\n+  struct df_mw_hardreg *mw;\n+\n+  for (ix = 0; VEC_iterate (df_ref, collection_rec->def_vec, ix, ref); ++ix)\n+    df_free_ref (ref);\n+  for (ix = 0; VEC_iterate (df_ref, collection_rec->use_vec, ix, ref); ++ix)\n+    df_free_ref (ref);\n+  for (ix = 0; VEC_iterate (df_ref, collection_rec->eq_use_vec, ix, ref); ++ix)\n+    df_free_ref (ref);\n+  for (ix = 0;\n+       VEC_iterate (df_mw_hardreg_ptr, collection_rec->mw_vec, ix, mw);\n+       ++ix)\n+    pool_free (problem_data->mw_reg_pool, mw);\n+\n+  VEC_free (df_ref, stack, collection_rec->def_vec);\n+  VEC_free (df_ref, stack, collection_rec->use_vec);\n+  VEC_free (df_ref, stack, collection_rec->eq_use_vec);\n+  VEC_free (df_mw_hardreg_ptr, stack, collection_rec->mw_vec);\n }\n \n-\n /* Rescan INSN.  Return TRUE if the rescanning produced any changes.  */\n \n bool \n@@ -1209,10 +1221,6 @@ df_insn_rescan (rtx insn)\n   struct df_insn_info *insn_info = NULL;\n   basic_block bb = BLOCK_FOR_INSN (insn);\n   struct df_collection_rec collection_rec;\n-  collection_rec.def_vec = XALLOCAVEC (df_ref, 1000);\n-  collection_rec.use_vec = XALLOCAVEC (df_ref, 1000);\n-  collection_rec.eq_use_vec = XALLOCAVEC (df_ref, 1000);\n-  collection_rec.mw_vec = XALLOCAVEC (struct df_mw_hardreg *, 100);\n \n   if ((!df) || (!INSN_P (insn)))\n     return false;\n@@ -1253,6 +1261,11 @@ df_insn_rescan (rtx insn)\n       return false;\n     }\n \n+  collection_rec.def_vec = VEC_alloc (df_ref, stack, 128);\n+  collection_rec.use_vec = VEC_alloc (df_ref, stack, 32);\n+  collection_rec.eq_use_vec = VEC_alloc (df_ref, stack, 32);\n+  collection_rec.mw_vec = VEC_alloc (df_mw_hardreg_ptr, stack, 32);\n+\n   bitmap_clear_bit (df->insns_to_delete, uid);\n   bitmap_clear_bit (df->insns_to_rescan, uid);\n   bitmap_clear_bit (df->insns_to_notes_rescan, uid);\n@@ -1288,6 +1301,12 @@ df_insn_rescan (rtx insn)\n \n   df_refs_add_to_chains (&collection_rec, bb, insn);\n   df_set_bb_dirty (bb);\n+\n+  VEC_free (df_ref, stack, collection_rec.def_vec);\n+  VEC_free (df_ref, stack, collection_rec.use_vec);\n+  VEC_free (df_ref, stack, collection_rec.eq_use_vec);\n+  VEC_free (df_mw_hardreg_ptr, stack, collection_rec.mw_vec);\n+\n   return true;\n }\n \n@@ -2131,10 +2150,11 @@ df_notes_rescan (rtx insn)\n       rtx note;\n       struct df_collection_rec collection_rec;\n       unsigned int num_deleted;\n+      unsigned int mw_len;\n \n       memset (&collection_rec, 0, sizeof (struct df_collection_rec));\n-      collection_rec.eq_use_vec = XALLOCAVEC (df_ref, 1000);\n-      collection_rec.mw_vec = XALLOCAVEC (struct df_mw_hardreg *, 1000);\n+      collection_rec.eq_use_vec = VEC_alloc (df_ref, stack, 32);\n+      collection_rec.mw_vec = VEC_alloc (df_mw_hardreg_ptr, stack, 32);\n \n       num_deleted = df_mw_hardreg_chain_delete_eq_uses (insn_info);\n       df_ref_chain_delete (insn_info->eq_uses);\n@@ -2158,7 +2178,8 @@ df_notes_rescan (rtx insn)\n \n       /* Find some place to put any new mw_hardregs.  */\n       df_canonize_collection_rec (&collection_rec);\n-      if (collection_rec.next_mw)\n+      mw_len = VEC_length (df_mw_hardreg_ptr, collection_rec.mw_vec);\n+      if (mw_len)\n \t{\n \t  unsigned int count = 0;\n \t  struct df_mw_hardreg **mw_rec = insn_info->mw_hardregs;\n@@ -2172,33 +2193,36 @@ df_notes_rescan (rtx insn)\n \t    {\n \t      /* Append to the end of the existing record after\n \t\t expanding it if necessary.  */\n-\t      if (collection_rec.next_mw > num_deleted)\n+\t      if (mw_len > num_deleted)\n \t\t{\n \t\t  insn_info->mw_hardregs = \n \t\t    XRESIZEVEC (struct df_mw_hardreg *,\n-\t\t\t\tinsn_info->mw_hardregs, \n-\t\t\t\tcount + 1 + collection_rec.next_mw);\n+\t\t\t\tinsn_info->mw_hardregs,\n+\t\t\t\tcount + 1 + mw_len);\n \t\t}\n-\t      memcpy (&insn_info->mw_hardregs[count], collection_rec.mw_vec, \n-\t\t      (collection_rec.next_mw + 1) * sizeof (struct df_mw_hardreg *));\n-\t      qsort (insn_info->mw_hardregs, count + collection_rec.next_mw, \n+\t      memcpy (&insn_info->mw_hardregs[count],\n+\t\t      VEC_address (df_mw_hardreg_ptr, collection_rec.mw_vec), \n+\t\t      mw_len * sizeof (struct df_mw_hardreg *));\n+\t      insn_info->mw_hardregs[count + mw_len] = NULL;\n+\t      qsort (insn_info->mw_hardregs, count + mw_len, \n \t\t     sizeof (struct df_mw_hardreg *), df_mw_compare);\n \t    }\n \t  else\n \t    {\n \t      /* No vector there. */  \n \t      insn_info->mw_hardregs \n-\t\t= XNEWVEC (struct df_mw_hardreg*, \n-\t\t\t   count + 1 + collection_rec.next_mw);\n-\t      memcpy (insn_info->mw_hardregs, collection_rec.mw_vec, \n-\t\t      (collection_rec.next_mw + 1) * sizeof (struct df_mw_hardreg *));\n+\t\t= XNEWVEC (struct df_mw_hardreg*, 1 + mw_len);\n+\t      memcpy (insn_info->mw_hardregs,\n+\t\t      VEC_address (df_mw_hardreg_ptr, collection_rec.mw_vec),\n+\t\t      mw_len * sizeof (struct df_mw_hardreg *));\n+\t      insn_info->mw_hardregs[mw_len] = NULL;\n \t    }\n \t}\n       /* Get rid of the mw_rec so that df_refs_add_to_chains will\n \t ignore it.  */\n-      collection_rec.mw_vec = NULL;\n-      collection_rec.next_mw = 0;\n+      VEC_free (df_mw_hardreg_ptr, stack, collection_rec.mw_vec);\n       df_refs_add_to_chains (&collection_rec, bb, insn);\n+      VEC_free (df_ref, stack, collection_rec.eq_use_vec);\n     }\n   else\n     df_insn_rescan (insn);\n@@ -2316,35 +2340,43 @@ df_ref_compare (const void *r1, const void *r2)\n }\n \n static void\n-df_swap_refs (df_ref *ref_vec, int i, int j)\n+df_swap_refs (VEC(df_ref,stack) **ref_vec, int i, int j)\n {\n-  df_ref tmp = ref_vec[i];\n-  ref_vec[i] = ref_vec[j];\n-  ref_vec[j] = tmp;\n+  df_ref tmp = VEC_index (df_ref, *ref_vec, i);\n+  VEC_replace (df_ref, *ref_vec, i, VEC_index (df_ref, *ref_vec, j));\n+  VEC_replace (df_ref, *ref_vec, j, tmp);\n }\n \n /* Sort and compress a set of refs.  */\n \n-static unsigned int\n-df_sort_and_compress_refs (df_ref *ref_vec, unsigned int count)\n+static void\n+df_sort_and_compress_refs (VEC(df_ref,stack) **ref_vec)\n {\n+  unsigned int count;\n   unsigned int i;\n   unsigned int dist = 0;\n \n-  ref_vec[count] = NULL;\n+  count = VEC_length (df_ref, *ref_vec);\n+\n   /* If there are 1 or 0 elements, there is nothing to do.  */\n   if (count < 2)\n-    return count;\n+    return;\n   else if (count == 2)\n     {\n-      if (df_ref_compare (&ref_vec[0], &ref_vec[1]) > 0)\n+      df_ref r0 = VEC_index (df_ref, *ref_vec, 0);\n+      df_ref r1 = VEC_index (df_ref, *ref_vec, 1);\n+      if (df_ref_compare (&r0, &r1) > 0)\n         df_swap_refs (ref_vec, 0, 1);\n     }\n   else\n     {\n       for (i = 0; i < count - 1; i++)\n-        if (df_ref_compare (&ref_vec[i], &ref_vec[i+1]) >= 0)\n-          break;\n+\t{\n+\t  df_ref r0 = VEC_index (df_ref, *ref_vec, i);\n+\t  df_ref r1 = VEC_index (df_ref, *ref_vec, i + 1);\n+\t  if (df_ref_compare (&r0, &r1) >= 0)\n+\t    break;\n+\t}\n       /* If the array is already strictly ordered,\n          which is the most common case for large COUNT case\n          (which happens for CALL INSNs),\n@@ -2353,26 +2385,29 @@ df_sort_and_compress_refs (df_ref *ref_vec, unsigned int count)\n          Make sure DF_GET_ADD_REFS adds refs in the increasing order\n          of DF_REF_COMPARE.  */\n       if (i == count - 1)\n-        return count;\n-      qsort (ref_vec, count, sizeof (df_ref), df_ref_compare);\n+        return;\n+      qsort (VEC_address (df_ref, *ref_vec), count, sizeof (df_ref),\n+\t     df_ref_compare);\n     }\n \n   for (i=0; i<count-dist; i++)\n     {\n       /* Find the next ref that is not equal to the current ref.  */\n-      while (df_ref_equal_p (ref_vec[i], ref_vec[i + dist + 1]))\n+      while (i + dist + 1 < count\n+\t     && df_ref_equal_p (VEC_index (df_ref, *ref_vec, i),\n+\t\t\t\tVEC_index (df_ref, *ref_vec, i + dist + 1)))\n \t{\n-\t  df_free_ref (ref_vec[i + dist + 1]);\n+\t  df_free_ref (VEC_index (df_ref, *ref_vec, i + dist + 1));\n \t  dist++;\n \t}\n       /* Copy it down to the next position.  */\n-      if (dist)\n-\tref_vec[i+1] = ref_vec[i + dist + 1];\n+      if (dist && i + dist + 1 < count)\n+\tVEC_replace (df_ref, *ref_vec, i + 1,\n+\t\t     VEC_index (df_ref, *ref_vec, i + dist + 1));\n     }\n \n   count -= dist;\n-  ref_vec[count] = NULL;\n-  return count;\n+  VEC_truncate (df_ref, *ref_vec, count);\n }\n \n \n@@ -2425,45 +2460,55 @@ df_mw_compare (const void *m1, const void *m2)\n \n /* Sort and compress a set of refs.  */\n \n-static unsigned int\n-df_sort_and_compress_mws (struct df_mw_hardreg **mw_vec, unsigned int count)\n+static void\n+df_sort_and_compress_mws (VEC(df_mw_hardreg_ptr,stack) **mw_vec)\n {\n+  unsigned int count;\n   struct df_scan_problem_data *problem_data \n     = (struct df_scan_problem_data *) df_scan->problem_data;\n   unsigned int i;\n   unsigned int dist = 0;\n-  mw_vec[count] = NULL;\n \n+  count = VEC_length (df_mw_hardreg_ptr, *mw_vec);\n   if (count < 2)\n-    return count;\n+    return;\n   else if (count == 2)\n     {\n-      if (df_mw_compare (&mw_vec[0], &mw_vec[1]) > 0)\n+      struct df_mw_hardreg *m0 = VEC_index (df_mw_hardreg_ptr, *mw_vec, 0);\n+      struct df_mw_hardreg *m1 = VEC_index (df_mw_hardreg_ptr, *mw_vec, 1);\n+      if (df_mw_compare (&m0, &m1) > 0)\n         {\n-          struct df_mw_hardreg *tmp = mw_vec[0];\n-          mw_vec[0] = mw_vec[1];\n-          mw_vec[1] = tmp;\n+          struct df_mw_hardreg *tmp = VEC_index (df_mw_hardreg_ptr,\n+\t\t\t\t\t\t *mw_vec, 0);\n+\t  VEC_replace (df_mw_hardreg_ptr, *mw_vec, 0,\n+\t\t       VEC_index (df_mw_hardreg_ptr, *mw_vec, 1));\n+\t  VEC_replace (df_mw_hardreg_ptr, *mw_vec, 1, tmp);\n         }\n     }\n   else\n-    qsort (mw_vec, count, sizeof (struct df_mw_hardreg *), df_mw_compare);\n+    qsort (VEC_address (df_mw_hardreg_ptr, *mw_vec), count,\n+\t   sizeof (struct df_mw_hardreg *), df_mw_compare);\n \n   for (i=0; i<count-dist; i++)\n     {\n       /* Find the next ref that is not equal to the current ref.  */\n-      while (df_mw_equal_p (mw_vec[i], mw_vec[i + dist + 1]))\n+      while (i + dist + 1 < count\n+\t     && df_mw_equal_p (VEC_index (df_mw_hardreg_ptr, *mw_vec, i),\n+\t\t\t       VEC_index (df_mw_hardreg_ptr, *mw_vec,\n+\t\t\t\t\t  i + dist + 1)))\n \t{\n-\t  pool_free (problem_data->mw_reg_pool, mw_vec[i + dist + 1]);\n+\t  pool_free (problem_data->mw_reg_pool,\n+\t\t     VEC_index (df_mw_hardreg_ptr, *mw_vec, i + dist + 1));\n \t  dist++;\n \t}\n       /* Copy it down to the next position.  */\n-      if (dist)\n-\tmw_vec[i+1] = mw_vec[i + dist + 1];\n+      if (dist && i + dist + 1 < count)\n+\tVEC_replace (df_mw_hardreg_ptr, *mw_vec, i + 1,\n+\t\t     VEC_index (df_mw_hardreg_ptr, *mw_vec, i + dist + 1));\n     }\n \n   count -= dist;\n-  mw_vec[count] = NULL;\n-  return count;\n+  VEC_truncate (df_mw_hardreg_ptr, *mw_vec, count);\n }\n \n \n@@ -2472,22 +2517,10 @@ df_sort_and_compress_mws (struct df_mw_hardreg **mw_vec, unsigned int count)\n static void\n df_canonize_collection_rec (struct df_collection_rec *collection_rec)\n {\n-  if (collection_rec->def_vec)\n-    collection_rec->next_def \n-      = df_sort_and_compress_refs (collection_rec->def_vec,\n-\t\t\t\t   collection_rec->next_def);\n-  if (collection_rec->use_vec)\n-    collection_rec->next_use \n-      = df_sort_and_compress_refs (collection_rec->use_vec,\n-\t\t\t\t   collection_rec->next_use);\n-  if (collection_rec->eq_use_vec)\n-    collection_rec->next_eq_use \n-      = df_sort_and_compress_refs (collection_rec->eq_use_vec,\n-\t\t\t\t   collection_rec->next_eq_use);\n-  if (collection_rec->mw_vec)\n-    collection_rec->next_mw \n-      = df_sort_and_compress_mws (collection_rec->mw_vec,\n-\t\t\t\t  collection_rec->next_mw);\n+  df_sort_and_compress_refs (&collection_rec->def_vec);\n+  df_sort_and_compress_refs (&collection_rec->use_vec);\n+  df_sort_and_compress_refs (&collection_rec->eq_use_vec);\n+  df_sort_and_compress_mws (&collection_rec->mw_vec);\n }\n \n \n@@ -2545,16 +2578,20 @@ df_install_ref (df_ref this_ref,\n \n static df_ref *\n df_install_refs (basic_block bb,\n-\t\t df_ref *old_vec, unsigned int count, \n+\t\t VEC(df_ref,stack)* old_vec,\n \t\t struct df_reg_info **reg_info, \n \t\t struct df_ref_info *ref_info,\n \t\t bool is_notes)\n {\n+  unsigned int count;\n+\n+  count = VEC_length (df_ref, old_vec);\n   if (count)\n     {\n-      unsigned int i;\n       df_ref *new_vec = XNEWVEC (df_ref, count + 1);\n       bool add_to_table;\n+      df_ref this_ref;\n+      unsigned int ix;\n \n       switch (ref_info->ref_order)\n \t{\n@@ -2579,10 +2616,9 @@ df_install_refs (basic_block bb,\n       if (add_to_table && df->analyze_subset)\n \tadd_to_table = bitmap_bit_p (df->blocks_to_analyze, bb->index);\n \n-      for (i = 0; i < count; i++)\n+      for (ix = 0; VEC_iterate (df_ref, old_vec, ix, this_ref); ++ix)\n \t{\n-\t  df_ref this_ref = old_vec[i];\n-\t  new_vec[i] = this_ref;\n+\t  new_vec[ix] = this_ref;\n \t  df_install_ref (this_ref, reg_info[DF_REF_REGNO (this_ref)], \n \t\t\t  ref_info, add_to_table);\n \t}\n@@ -2599,14 +2635,18 @@ df_install_refs (basic_block bb,\n    insn.  */\n \n static struct df_mw_hardreg **\n-df_install_mws (struct df_mw_hardreg **old_vec, unsigned int count)\n+df_install_mws (VEC(df_mw_hardreg_ptr,stack) *old_vec)\n {\n+  unsigned int count;\n+\n+  count = VEC_length (df_mw_hardreg_ptr, old_vec);\n   if (count)\n     {\n       struct df_mw_hardreg **new_vec \n \t= XNEWVEC (struct df_mw_hardreg*, count + 1);\n-      memcpy (new_vec, old_vec, \n-\t      sizeof (struct df_mw_hardreg*) * (count + 1));\n+      memcpy (new_vec, VEC_address (df_mw_hardreg_ptr, old_vec), \n+\t      sizeof (struct df_mw_hardreg*) * count);\n+      new_vec[count] = NULL;\n       return new_vec;\n     }\n   else\n@@ -2631,8 +2671,7 @@ df_refs_add_to_chains (struct df_collection_rec *collection_rec,\n \t{\n \t  df_scan_free_ref_vec (insn_rec->defs);\n \t  insn_rec->defs \n-\t    = df_install_refs (bb, collection_rec->def_vec, \n-\t\t\t       collection_rec->next_def,\n+\t    = df_install_refs (bb, collection_rec->def_vec,\n \t\t\t       df->def_regs,\n \t\t\t       &df->def_info, false);\n \t}\n@@ -2641,7 +2680,6 @@ df_refs_add_to_chains (struct df_collection_rec *collection_rec,\n \t  df_scan_free_ref_vec (insn_rec->uses);\n \t  insn_rec->uses \n \t    = df_install_refs (bb, collection_rec->use_vec, \n-\t\t\t       collection_rec->next_use,\n \t\t\t       df->use_regs,\n \t\t\t       &df->use_info, false);\n \t}\n@@ -2650,16 +2688,14 @@ df_refs_add_to_chains (struct df_collection_rec *collection_rec,\n \t  df_scan_free_ref_vec (insn_rec->eq_uses);\n \t  insn_rec->eq_uses \n \t    = df_install_refs (bb, collection_rec->eq_use_vec, \n-\t\t\t       collection_rec->next_eq_use,\n \t\t\t       df->eq_use_regs,\n \t\t\t       &df->use_info, true);\n \t}\n       if (collection_rec->mw_vec)\n \t{\n \t  df_scan_free_mws_vec (insn_rec->mw_hardregs);\n \t  insn_rec->mw_hardregs \n-\t    = df_install_mws (collection_rec->mw_vec, \n-\t\t\t      collection_rec->next_mw);\n+\t    = df_install_mws (collection_rec->mw_vec);\n \t}\n     }\n   else\n@@ -2668,14 +2704,12 @@ df_refs_add_to_chains (struct df_collection_rec *collection_rec,\n \n       df_scan_free_ref_vec (bb_info->artificial_defs);\n       bb_info->artificial_defs \n-\t= df_install_refs (bb, collection_rec->def_vec, \n-\t\t\t   collection_rec->next_def,\n+\t= df_install_refs (bb, collection_rec->def_vec,\n \t\t\t   df->def_regs,\n \t\t\t   &df->def_info, false);\n       df_scan_free_ref_vec (bb_info->artificial_uses);\n       bb_info->artificial_uses \n \t= df_install_refs (bb, collection_rec->use_vec, \n-\t\t\t   collection_rec->next_use,\n \t\t\t   df->use_regs,\n \t\t\t   &df->use_info, false);\n     }\n@@ -2767,11 +2801,11 @@ df_ref_create_structure (enum df_ref_class cl,\n   if (collection_rec)\n     {\n       if (DF_REF_REG_DEF_P (this_ref))\n-\tcollection_rec->def_vec[collection_rec->next_def++] = this_ref;\n+\tVEC_safe_push (df_ref, stack, collection_rec->def_vec, this_ref);\n       else if (DF_REF_FLAGS (this_ref) & DF_REF_IN_NOTE)\n-\tcollection_rec->eq_use_vec[collection_rec->next_eq_use++] = this_ref;\n+\tVEC_safe_push (df_ref, stack, collection_rec->eq_use_vec, this_ref);\n       else\n-\tcollection_rec->use_vec[collection_rec->next_use++] = this_ref;\n+\tVEC_safe_push (df_ref, stack, collection_rec->use_vec, this_ref);\n     }\n \n   return this_ref;\n@@ -2837,7 +2871,8 @@ df_ref_record (enum df_ref_class cl,\n \t  hardreg->start_regno = regno;\n \t  hardreg->end_regno = endregno - 1;\n \t  hardreg->mw_order = df->ref_order++;\n-\t  collection_rec->mw_vec[collection_rec->next_mw++] = hardreg;\n+\t  VEC_safe_push (df_mw_hardreg_ptr, stack, collection_rec->mw_vec,\n+\t\t\t hardreg);\n \t}\n \n       for (i = regno; i < endregno; i++)\n@@ -3291,10 +3326,11 @@ df_uses_record (enum df_ref_class cl, struct df_collection_rec *collection_rec,\n static void\n df_get_conditional_uses (struct df_collection_rec *collection_rec)\n {\n-  unsigned int i;\n-  for (i = 0; i < collection_rec->next_def; i++)\n+  unsigned int ix;\n+  df_ref ref;\n+\n+  for (ix = 0; VEC_iterate (df_ref, collection_rec->def_vec, ix, ref); ++ix)\n     {\n-      df_ref ref = collection_rec->def_vec[i];\n       if (DF_REF_FLAGS_IS_SET (ref, DF_REF_CONDITIONAL))\n         {\n \t  int width = -1;\n@@ -3333,16 +3369,14 @@ df_get_call_refs (struct df_collection_rec * collection_rec,\n   unsigned int ui;\n   bool is_sibling_call;\n   unsigned int i;\n+  df_ref def;\n   bitmap defs_generated = BITMAP_ALLOC (&df_bitmap_obstack);\n \n   /* Do not generate clobbers for registers that are the result of the\n      call.  This causes ordering problems in the chain building code\n      depending on which def is seen first.  */\n-  for (i=0; i<collection_rec->next_def; i++)\n-    {\n-      df_ref def = collection_rec->def_vec[i];\n-      bitmap_set_bit (defs_generated, DF_REF_REGNO (def));\n-    }\n+  for (i = 0; VEC_iterate (df_ref, collection_rec->def_vec, i, def); ++i)\n+    bitmap_set_bit (defs_generated, DF_REF_REGNO (def));\n \n   /* Record the registers used to pass arguments, and explicitly\n      noted as clobbered.  */\n@@ -3420,10 +3454,10 @@ df_insn_refs_collect (struct df_collection_rec* collection_rec,\n   bool is_cond_exec = (GET_CODE (PATTERN (insn_info->insn)) == COND_EXEC);\n \n   /* Clear out the collection record.  */\n-  collection_rec->next_def = 0;\n-  collection_rec->next_use = 0;\n-  collection_rec->next_eq_use = 0;\n-  collection_rec->next_mw = 0;\n+  VEC_truncate (df_ref, collection_rec->def_vec, 0);\n+  VEC_truncate (df_ref, collection_rec->use_vec, 0);\n+  VEC_truncate (df_ref, collection_rec->eq_use_vec, 0);\n+  VEC_truncate (df_mw_hardreg_ptr, collection_rec->mw_vec, 0);\n \n   /* Record register defs.  */\n   df_defs_record (collection_rec, PATTERN (insn_info->insn), bb, insn_info, 0);\n@@ -3521,10 +3555,10 @@ df_need_static_chain_reg (struct function *fun)\n static void\n df_bb_refs_collect (struct df_collection_rec *collection_rec, basic_block bb)\n {\n-  collection_rec->next_def = 0;\n-  collection_rec->next_use = 0;\n-  collection_rec->next_eq_use = 0;\n-  collection_rec->next_mw = 0;\n+  VEC_truncate (df_ref, collection_rec->def_vec, 0);\n+  VEC_truncate (df_ref, collection_rec->use_vec, 0);\n+  VEC_truncate (df_ref, collection_rec->eq_use_vec, 0);\n+  VEC_truncate (df_mw_hardreg_ptr, collection_rec->mw_vec, 0);\n \n   if (bb->index == ENTRY_BLOCK)\n     {\n@@ -3590,10 +3624,6 @@ df_bb_refs_record (int bb_index, bool scan_insns)\n   int luid = 0;\n   struct df_scan_bb_info *bb_info;\n   struct df_collection_rec collection_rec;\n-  collection_rec.def_vec = XALLOCAVEC (df_ref, 1000);\n-  collection_rec.use_vec = XALLOCAVEC (df_ref, 1000);\n-  collection_rec.eq_use_vec = XALLOCAVEC (df_ref, 1000);\n-  collection_rec.mw_vec = XALLOCAVEC (struct df_mw_hardreg *, 100);\n \n   if (!df)\n     return;\n@@ -3609,6 +3639,11 @@ df_bb_refs_record (int bb_index, bool scan_insns)\n       bb_info->artificial_uses = NULL;\n     }\n \n+  collection_rec.def_vec = VEC_alloc (df_ref, stack, 128);\n+  collection_rec.use_vec = VEC_alloc (df_ref, stack, 32);\n+  collection_rec.eq_use_vec = VEC_alloc (df_ref, stack, 32);\n+  collection_rec.mw_vec = VEC_alloc (df_mw_hardreg_ptr, stack, 32);\n+\n   if (scan_insns)\n     /* Scan the block an insn at a time from beginning to end.  */\n     FOR_BB_INSNS (bb, insn)\n@@ -3631,6 +3666,11 @@ df_bb_refs_record (int bb_index, bool scan_insns)\n   df_bb_refs_collect (&collection_rec, bb);\n   df_refs_add_to_chains (&collection_rec, bb, NULL);\n \n+  VEC_free (df_ref, stack, collection_rec.def_vec);\n+  VEC_free (df_ref, stack, collection_rec.use_vec);\n+  VEC_free (df_ref, stack, collection_rec.eq_use_vec);\n+  VEC_free (df_mw_hardreg_ptr, stack, collection_rec.mw_vec);\n+\n   /* Now that the block has been processed, set the block as dirty so\n      LR and LIVE will get it processed.  */\n   df_set_bb_dirty (bb);\n@@ -3889,12 +3929,12 @@ df_record_entry_block_defs (bitmap entry_block_defs)\n {\n   struct df_collection_rec collection_rec;\n   memset (&collection_rec, 0, sizeof (struct df_collection_rec));\n-  collection_rec.def_vec = XALLOCAVEC (df_ref, FIRST_PSEUDO_REGISTER);\n-\n+  collection_rec.def_vec = VEC_alloc (df_ref, stack, FIRST_PSEUDO_REGISTER);\n   df_entry_block_defs_collect (&collection_rec, entry_block_defs);\n \n   /* Process bb_refs chain */\n   df_refs_add_to_chains (&collection_rec, BASIC_BLOCK (ENTRY_BLOCK), NULL);\n+  VEC_free (df_ref, stack, collection_rec.def_vec);\n }\n \n \n@@ -4060,12 +4100,13 @@ df_record_exit_block_uses (bitmap exit_block_uses)\n {\n   struct df_collection_rec collection_rec;\n   memset (&collection_rec, 0, sizeof (struct df_collection_rec));\n-  collection_rec.use_vec = XALLOCAVEC (df_ref, FIRST_PSEUDO_REGISTER);\n+  collection_rec.use_vec = VEC_alloc (df_ref, stack, FIRST_PSEUDO_REGISTER);\n \n   df_exit_block_uses_collect (&collection_rec, exit_block_uses);\n \n   /* Process bb_refs chain */\n   df_refs_add_to_chains (&collection_rec, BASIC_BLOCK (EXIT_BLOCK), NULL);\n+  VEC_free (df_ref, stack, collection_rec.use_vec);\n }\n \n \n@@ -4242,7 +4283,7 @@ df_compute_regs_ever_live (bool reset)\n \n   df_reg_chain_mark (refs, regno, is_def, is_eq_use)\n   df_reg_chain_verify_unmarked (refs)\n-  df_refs_verify (ref*, ref*, bool)\n+  df_refs_verify (VEC(stack,df_ref)*, ref*, bool)\n   df_mws_verify (mw*, mw*, bool)\n   df_insn_refs_verify (collection_rec, bb, insn, bool)\n   df_bb_refs_verify (bb, refs, bool)\n@@ -4306,12 +4347,15 @@ df_reg_chain_verify_unmarked (df_ref refs)\n /* Verify that NEW_REC and OLD_REC have exactly the same members. */\n \n static bool\n-df_refs_verify (df_ref *new_rec, df_ref *old_rec,\n+df_refs_verify (VEC(df_ref,stack) *new_rec, df_ref *old_rec,\n \t\tbool abort_if_fail)\n {\n-  while ((*new_rec) && (*old_rec))\n+  unsigned int ix;\n+  df_ref new_ref;\n+\n+  for (ix = 0; VEC_iterate (df_ref, new_rec, ix, new_ref); ++ix)\n     {\n-      if (!df_ref_equal_p (*new_rec, *old_rec))\n+      if (*old_rec == NULL || !df_ref_equal_p (new_ref, *old_rec))\n \t{\n \t  if (abort_if_fail)\n \t    gcc_assert (0);\n@@ -4327,41 +4371,43 @@ df_refs_verify (df_ref *new_rec, df_ref *old_rec,\n \t  DF_REF_REG_UNMARK (*old_rec);\n \t}\n \n-      new_rec++;\n       old_rec++;\n     }\n \n   if (abort_if_fail)\n-    gcc_assert ((*new_rec == NULL) && (*old_rec == NULL));\n+    gcc_assert (*old_rec == NULL);\n   else\n-    return ((*new_rec == NULL) && (*old_rec == NULL));\n+    return *old_rec == NULL;\n   return false;\n }\n \n \n /* Verify that NEW_REC and OLD_REC have exactly the same members. */\n \n static bool\n-df_mws_verify (struct df_mw_hardreg **new_rec, struct df_mw_hardreg **old_rec,\n+df_mws_verify (VEC(df_mw_hardreg_ptr,stack) *new_rec,\n+\t       struct df_mw_hardreg **old_rec,\n \t       bool abort_if_fail)\n {\n-  while ((*new_rec) && (*old_rec))\n+  unsigned int ix;\n+  struct df_mw_hardreg *new_reg;\n+\n+  for (ix = 0; VEC_iterate (df_mw_hardreg_ptr, new_rec, ix, new_reg); ++ix)\n     {\n-      if (!df_mw_equal_p (*new_rec, *old_rec))\n+      if (*old_rec == NULL || !df_mw_equal_p (new_reg, *old_rec))\n \t{\n \t  if (abort_if_fail)\n \t    gcc_assert (0);\n \t  else\n \t    return false;\n \t}\n-      new_rec++;\n       old_rec++;\n     }\n \n   if (abort_if_fail)\n-    gcc_assert ((*new_rec == NULL) && (*old_rec == NULL));\n+    gcc_assert (*old_rec == NULL);\n   else\n-    return ((*new_rec == NULL) && (*old_rec == NULL));\n+    return *old_rec == NULL;\n   return false;\n }\n \n@@ -4424,10 +4470,10 @@ df_bb_verify (basic_block bb)\n   struct df_collection_rec collection_rec;\n   \n   memset (&collection_rec, 0, sizeof (struct df_collection_rec));\n-  collection_rec.def_vec = XALLOCAVEC (df_ref, 1000);\n-  collection_rec.use_vec = XALLOCAVEC (df_ref, 1000);\n-  collection_rec.eq_use_vec = XALLOCAVEC (df_ref, 1000);\n-  collection_rec.mw_vec = XALLOCAVEC (struct df_mw_hardreg *, 100);\n+  collection_rec.def_vec = VEC_alloc (df_ref, stack, 128);\n+  collection_rec.use_vec = VEC_alloc (df_ref, stack, 32);\n+  collection_rec.eq_use_vec = VEC_alloc (df_ref, stack, 32);\n+  collection_rec.mw_vec = VEC_alloc (df_mw_hardreg_ptr, stack, 32);\n \n   gcc_assert (bb_info);\n "}, {"sha": "6563fd372b7ef06d8d829b7c83685a8c0d6ed40d", "filename": "gcc/vec.c", "status": "modified", "additions": 141, "deletions": 0, "changes": 141, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c25696045a8422510cc2bdea80cd68eabc16d25f/gcc%2Fvec.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c25696045a8422510cc2bdea80cd68eabc16d25f/gcc%2Fvec.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fvec.c?ref=c25696045a8422510cc2bdea80cd68eabc16d25f", "patch": "@@ -372,6 +372,147 @@ vec_heap_o_reserve_exact (void *vec, int reserve, size_t vec_offset,\n \t\t\t       PASS_MEM_STAT);\n }\n \n+/* Stack vectors are a little different.  VEC_alloc turns into a call\n+   to vec_stack_p_reserve_exact1 and passes in space allocated via a\n+   call to alloca.  We record that pointer so that we know that we\n+   shouldn't free it.  If the vector is resized, we resize it on the\n+   heap.  We record the pointers in a vector and search it in LIFO\n+   order--i.e., we look for the newest stack vectors first.  We don't\n+   expect too many stack vectors at any one level, and searching from\n+   the end should normally be efficient even if they are used in a\n+   recursive function.  */\n+\n+typedef void *void_p;\n+DEF_VEC_P(void_p);\n+DEF_VEC_ALLOC_P(void_p,heap);\n+\n+static VEC(void_p,heap) *stack_vecs;\n+\n+/* Allocate a vector which uses alloca for the initial allocation.\n+   SPACE is space allocated using alloca, ALLOC is the number of\n+   entries allocated.  */\n+\n+void *\n+vec_stack_p_reserve_exact_1 (int alloc, void *space)\n+{\n+  struct vec_prefix *pfx = (struct vec_prefix *) space;\n+\n+  VEC_safe_push (void_p, heap, stack_vecs, space);\n+\n+  pfx->num = 0;\n+  pfx->alloc = alloc;\n+\n+  return space;\n+}\n+\n+/* Grow a vector allocated using alloca.  When this happens, we switch\n+   back to heap allocation.  We remove the vector from stack_vecs, if\n+   it is there, since we no longer need to avoid freeing it.  */\n+\n+static void *\n+vec_stack_o_reserve_1 (void *vec, int reserve, size_t vec_offset,\n+\t\t       size_t elt_size, bool exact MEM_STAT_DECL)\n+{\n+  bool found;\n+  unsigned int ix;\n+  void *newvec;\n+\n+  found = false;\n+  for (ix = VEC_length (void_p, stack_vecs); ix > 0; --ix)\n+    {\n+      if (VEC_index (void_p, stack_vecs, ix - 1) == vec)\n+\t{\n+\t  VEC_unordered_remove (void_p, stack_vecs, ix - 1);\n+\t  found = true;\n+\t  break;\n+\t}\n+    }\n+\n+  if (!found)\n+    {\n+      /* VEC is already on the heap.  */\n+      return vec_heap_o_reserve_1 (vec, reserve, vec_offset, elt_size,\n+\t\t\t\t   exact PASS_MEM_STAT);\n+    }\n+\n+  /* Move VEC to the heap.  */\n+  reserve += ((struct vec_prefix *) vec)->num;\n+  newvec = vec_heap_o_reserve_1 (NULL, reserve, vec_offset, elt_size,\n+\t\t\t\t exact PASS_MEM_STAT);\n+  if (newvec && vec)\n+    {\n+      ((struct vec_prefix *) newvec)->num = ((struct vec_prefix *) vec)->num;\n+      memcpy (((struct vec_prefix *) newvec)->vec,\n+\t      ((struct vec_prefix *) vec)->vec,\n+\t      ((struct vec_prefix *) vec)->num * elt_size);\n+    }\n+  return newvec;\n+}\n+\n+/* Grow a vector allocated on the stack.  */\n+\n+void *\n+vec_stack_p_reserve (void *vec, int reserve MEM_STAT_DECL)\n+{\n+  return vec_stack_o_reserve_1 (vec, reserve,\n+\t\t\t\toffsetof (struct vec_prefix, vec),\n+\t\t\t\tsizeof (void *), false\n+\t\t\t\tPASS_MEM_STAT);\n+}\n+\n+/* Exact version of vec_stack_p_reserve.  */\n+\n+void *\n+vec_stack_p_reserve_exact (void *vec, int reserve MEM_STAT_DECL)\n+{\n+  return vec_stack_o_reserve_1 (vec, reserve,\n+\t\t\t\toffsetof (struct vec_prefix, vec),\n+\t\t\t\tsizeof (void *), true\n+\t\t\t\tPASS_MEM_STAT);\n+}\n+\n+/* Like vec_stack_p_reserve, but for objects.  */\n+\n+void *\n+vec_stack_o_reserve (void *vec, int reserve, size_t vec_offset,\n+\t\t     size_t elt_size MEM_STAT_DECL)\n+{\n+  return vec_stack_o_reserve_1 (vec, reserve, vec_offset, elt_size, false\n+\t\t\t\tPASS_MEM_STAT);\n+}\n+\n+/* Like vec_stack_p_reserve_exact, but for objects.  */\n+\n+void *\n+vec_stack_o_reserve_exact (void *vec, int reserve, size_t vec_offset,\n+\t\t\t    size_t elt_size MEM_STAT_DECL)\n+{\n+  return vec_stack_o_reserve_1 (vec, reserve, vec_offset, elt_size, true\n+\t\t\t\tPASS_MEM_STAT);\n+}\n+\n+/* Free a vector allocated on the stack.  Don't actually free it if we\n+   find it in the hash table.  */\n+\n+void\n+vec_stack_free (void *vec)\n+{\n+  unsigned int ix;\n+\n+  for (ix = VEC_length (void_p, stack_vecs); ix > 0; --ix)\n+    {\n+      if (VEC_index (void_p, stack_vecs, ix - 1) == vec)\n+\t{\n+\t  VEC_unordered_remove (void_p, stack_vecs, ix - 1);\n+\t  return;\n+\t}\n+    }\n+\n+  /* VEC was not on the list of vecs allocated on the stack, so it\n+     must be allocated on the heap.  */\n+  vec_heap_free (vec);\n+}\n+\n #if ENABLE_CHECKING\n /* Issue a vector domain error, and then fall over.  */\n "}, {"sha": "d408c6d1a1a934a642d00515ac8498c400b95f25", "filename": "gcc/vec.h", "status": "modified", "additions": 83, "deletions": 6, "changes": 89, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c25696045a8422510cc2bdea80cd68eabc16d25f/gcc%2Fvec.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c25696045a8422510cc2bdea80cd68eabc16d25f/gcc%2Fvec.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fvec.h?ref=c25696045a8422510cc2bdea80cd68eabc16d25f", "patch": "@@ -508,6 +508,7 @@ struct vec_swallow_trailing_semi\n #define DEF_VEC_ALLOC_I(T,A)\t\t\t\t\t\t  \\\n VEC_TA(T,base,A);\t\t\t\t\t\t\t  \\\n DEF_VEC_ALLOC_FUNC_I(T,A)\t\t\t\t\t\t  \\\n+DEF_VEC_NONALLOC_FUNCS_I(T,A)\t\t\t\t\t\t  \\\n struct vec_swallow_trailing_semi\n \n /* Vector of pointer to object.  */\n@@ -524,6 +525,7 @@ struct vec_swallow_trailing_semi\n #define DEF_VEC_ALLOC_P(T,A)\t\t\t\t\t\t  \\\n VEC_TA(T,base,A);\t\t\t\t\t\t\t  \\\n DEF_VEC_ALLOC_FUNC_P(T,A)\t\t\t\t\t\t  \\\n+DEF_VEC_NONALLOC_FUNCS_P(T,A)\t\t\t\t\t\t  \\\n struct vec_swallow_trailing_semi\n \n #define DEF_VEC_FUNC_P(T)\t\t\t\t\t\t  \\\n@@ -716,8 +718,10 @@ static inline VEC(T,A) *VEC_OP (T,A,alloc)\t\t\t\t  \\\n {\t\t\t\t\t\t\t\t\t  \\\n   return (VEC(T,A) *) vec_##A##_p_reserve_exact (NULL, alloc_\t\t  \\\n \t\t\t\t\t\t PASS_MEM_STAT);\t  \\\n-}\t\t\t\t\t\t\t\t\t  \\\n-\t\t\t\t\t\t\t\t\t  \\\n+}\n+\n+\n+#define DEF_VEC_NONALLOC_FUNCS_P(T,A)\t\t\t\t\t  \\\n static inline void VEC_OP (T,A,free)\t\t\t\t\t  \\\n      (VEC(T,A) **vec_)\t\t\t\t\t\t\t  \\\n {\t\t\t\t\t\t\t\t\t  \\\n@@ -814,6 +818,7 @@ struct vec_swallow_trailing_semi\n #define DEF_VEC_ALLOC_O(T,A)\t\t\t\t\t\t  \\\n VEC_TA(T,base,A);\t\t\t\t\t\t\t  \\\n DEF_VEC_ALLOC_FUNC_O(T,A)\t\t\t\t\t\t  \\\n+DEF_VEC_NONALLOC_FUNCS_O(T,A)\t\t\t\t\t\t  \\\n struct vec_swallow_trailing_semi\n \n #define DEF_VEC_FUNC_O(T)\t\t\t\t\t\t  \\\n@@ -995,8 +1000,9 @@ static inline VEC(T,A) *VEC_OP (T,A,alloc)      \t\t\t  \\\n \t\t\t\t\t\t offsetof (VEC(T,A),base.vec), \\\n \t\t\t\t\t\t sizeof (T)\t\t  \\\n \t\t\t\t\t\t PASS_MEM_STAT);\t  \\\n-}\t\t\t\t\t\t\t\t\t  \\\n-\t\t\t\t\t\t\t\t\t  \\\n+}\n+\n+#define DEF_VEC_NONALLOC_FUNCS_O(T,A)\t\t\t\t\t  \\\n static inline VEC(T,A) *VEC_OP (T,A,copy) (VEC(T,base) *vec_ MEM_STAT_DECL) \\\n {\t\t\t\t\t\t\t\t\t  \\\n   size_t len_ = vec_ ? vec_->num : 0;\t\t\t\t\t  \\\n@@ -1099,8 +1105,9 @@ static inline VEC(T,A) *VEC_OP (T,A,alloc)      \t\t\t  \\\n   return (VEC(T,A) *) vec_##A##_o_reserve_exact\t\t\t\t  \\\n \t\t      (NULL, alloc_, offsetof (VEC(T,A),base.vec),\t  \\\n \t\t       sizeof (T) PASS_MEM_STAT);\t\t\t  \\\n-}\t\t\t\t\t\t\t\t\t  \\\n-\t\t\t\t\t\t\t\t\t  \\\n+}\n+\n+#define DEF_VEC_NONALLOC_FUNCS_I(T,A)\t\t\t\t\t  \\\n static inline VEC(T,A) *VEC_OP (T,A,copy) (VEC(T,base) *vec_ MEM_STAT_DECL) \\\n {\t\t\t\t\t\t\t\t\t  \\\n   size_t len_ = vec_ ? vec_->num : 0;\t\t\t\t\t  \\\n@@ -1195,4 +1202,74 @@ static inline T *VEC_OP (T,A,safe_insert)\t\t     \t  \t  \\\n \t\t\t\t       VEC_CHECK_PASS);\t\t\t  \\\n }\n \n+/* We support a vector which starts out with space on the stack and\n+   switches to heap space when forced to reallocate.  This works a\n+   little differently.  Instead of DEF_VEC_ALLOC_P(TYPE, heap|gc), use\n+   DEF_VEC_ALLOC_P_STACK(TYPE).  This uses alloca to get the initial\n+   space; because alloca can not be usefully called in an inline\n+   function, and because a macro can not define a macro, you must then\n+   write a #define for each type:\n+\n+   #define VEC_{TYPE}_stack_alloc(alloc)                          \\\n+     VEC_stack_alloc({TYPE}, alloc)\n+\n+   This is really a hack and perhaps can be made better.  Note that\n+   this macro will wind up evaluating the ALLOC parameter twice.\n+\n+   Only the initial allocation will be made using alloca, so pass a\n+   reasonable estimate that doesn't use too much stack space; don't\n+   pass zero.  Don't return a VEC(TYPE,stack) vector from the function\n+   which allocated it.  */\n+\n+extern void *vec_stack_p_reserve (void *, int MEM_STAT_DECL);\n+extern void *vec_stack_p_reserve_exact (void *, int MEM_STAT_DECL);\n+extern void *vec_stack_p_reserve_exact_1 (int, void *);\n+extern void *vec_stack_o_reserve (void *, int, size_t, size_t MEM_STAT_DECL);\n+extern void *vec_stack_o_reserve_exact (void *, int, size_t, size_t\n+\t\t\t\t\t MEM_STAT_DECL);\n+extern void vec_stack_free (void *);\n+\n+#define VEC_stack_alloc(T,alloc)\t\t\t\t\t  \\\n+  (VEC_OP (T,stack,alloc1)\t\t\t\t\t\t  \\\n+   (alloc, XALLOCAVAR (VEC(T,stack), VEC_embedded_size (T, alloc))))\n+\n+#define DEF_VEC_ALLOC_P_STACK(T)\t\t\t\t\t  \\\n+VEC_TA(T,base,stack);\t\t\t\t\t\t\t  \\\n+DEF_VEC_ALLOC_FUNC_P_STACK(T)\t\t\t\t\t\t  \\\n+DEF_VEC_NONALLOC_FUNCS_P(T,stack)\t\t\t\t\t  \\\n+struct vec_swallow_trailing_semi\n+\n+#define DEF_VEC_ALLOC_FUNC_P_STACK(T)\t\t\t\t\t  \\\n+static inline VEC(T,stack) *VEC_OP (T,stack,alloc1)\t\t\t  \\\n+     (int alloc_, VEC(T,stack)* space MEM_STAT_DECL)\t\t\t  \\\n+{\t\t\t\t\t\t\t\t\t  \\\n+   return (VEC(T,stack) *) vec_stack_p_reserve_exact_1 (alloc_, space); \\\n+}\n+\n+#define DEF_VEC_ALLOC_O_STACK(T)\t\t\t\t\t  \\\n+VEC_TA(T,base,stack);\t\t\t\t\t\t\t  \\\n+DEF_VEC_ALLOC_FUNC_O_STACK(T)\t\t\t\t\t\t  \\\n+DEF_VEC_NONALLOC_FUNCS_O(T,stack)\t\t\t\t\t  \\\n+struct vec_swallow_trailing_semi\n+\n+#define DEF_VEC_ALLOC_FUNC_O_STACK(T)\t\t\t\t\t  \\\n+static inline VEC(T,stack) *VEC_OP (T,stack,alloc1)\t\t\t  \\\n+     (int alloc_, VEC(T,stack)* space MEM_STAT_DECL)\t\t\t  \\\n+{\t\t\t\t\t\t\t\t\t  \\\n+  return ((VEC(T,stack) *) vec_stack_p_reserve_exact_1 (alloc_, space); \\\n+}\n+\n+#define DEF_VEC_ALLOC_I_STACK(T)\t\t\t\t\t  \\\n+VEC_TA(T,base,stack);\t\t\t\t\t\t\t  \\\n+DEF_VEC_ALLOC_FUNC_I_STACK(T)\t\t\t\t\t\t  \\\n+DEF_VEC_NONALLOC_FUNCS_I(T,stack)\t\t\t\t\t  \\\n+struct vec_swallow_trailing_semi\n+\n+#define DEF_VEC_ALLOC_FUNC_I_STACK(T)\t\t\t\t\t  \\\n+static inline VEC(T,stack) *VEC_OP (T,stack,alloc1)\t\t\t  \\\n+     (int alloc_, VEC(T,stack)* space MEM_STAT_DECL)\t\t\t  \\\n+{\t\t\t\t\t\t\t\t\t  \\\n+  return ((VEC(T,stack) *) vec_stack_p_reserve_exact_1 (alloc_, space); \\\n+}\n+\n #endif /* GCC_VEC_H */"}]}