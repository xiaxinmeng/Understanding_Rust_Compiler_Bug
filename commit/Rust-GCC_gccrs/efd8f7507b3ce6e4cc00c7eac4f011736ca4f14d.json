{"sha": "efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZWZkOGY3NTA3YjNjZTZlNGNjMDBjN2VhYzRmMDExNzM2Y2E0ZjE0ZA==", "commit": {"author": {"name": "Jan Hubicka", "email": "jh@suse.cz", "date": "2008-08-29T10:35:57Z"}, "committer": {"name": "Jan Hubicka", "email": "hubicka@gcc.gnu.org", "date": "2008-08-29T10:35:57Z"}, "message": "loop-unswitch.c (unswitch_single_loop): Use optimize_loop_for_speed_p.\n\n\n\n\t* loop-unswitch.c (unswitch_single_loop): Use optimize_loop_for_speed_p.\n\t* tree-ssa-threadupdate.c (mark_threaded_blocks): Use optimize_function_for_size_p.\n\t* tracer.c (ignore_bb_p): Use optimize_bb_for_size_p.\n\t* postreload-gcse.c (eliminate_partially_redundant_load): Use optimize_bb_for_size_p.\n\t* value-prof.c (gimple_divmod_fixed_value_transform,\n\tgimple_mod_pow2_value_transform, gimple_mod_subtract_transform,\n\tgimple_stringops_transform): Use optimize_bb_for_size_p.\n\t* ipa-cp.c (ipcp_insert_stage): Use optimize_function_for_size_p.\n\t* final.c (compute_alignments): Use optimize_function_for_size_p.\n\t* builtins.c (fold_builtin_cabs): Use optimize_function_for_speed_p.\n\t(fold_builtin_strcpy, fold_builtin_fputs): Use\n\toptimize_function_for_size_p.\n\t* fold-const.c (tree_swap_operands_p): Use optimize_function_for_size_p.\n\t* recog.c (relax_delay_slots): Likewise.\n\t* tree-ssa-math-opts.c (replace_reciprocal): Use optimize_bb_for_speed_p.\n\t(execute_cse_reciprocals): Use optimize_bb_for_size_p.\n\t* ipa-inline.c (cgraph_decide_recursive_inlining): Use\n\toptimize_function_for_size_p.\n\t(cgraph_decide_inlining_of_small_function): Use\n\toptimize_function_for_size_p.\n\t* global.c (find_reg): Use optimize_function_for_size_p.\n\t* opts.c (decode_options): Do not clear flag_tree_ch, flag_inline_functions,\n\tflag_unswitch_loops, flag_unroll_loops, flag_unroll_all_loops and\n\tflag_prefetch_loop_arrays. Those can work it out from profile.\n\t* tree-ssa-loop-ivcanon.c (tree_unroll_loops_completely): Use\n\toptimize_loop_for_speed_p.\n\t* predict.c (optimize_bb_for_size_p, optimize_bb_for_speed_p): Constify\n\targument.\n\t(optimize_loop_nest_for_size_p, optimize_loop_nest_for_speed_p): New.\n\t* tree-parloops.c (parallelize_loops): Use optimize_loop_for_size_p.\n\t* tree-eh.c (decide_copy_try_finally): Use optimize_function_for_size_p.\n\t* local-alloc.c (block_alloc): Pass BB pointer.\n\t(find_free_reg): Add BB pointer, use optimize_bb_for_size_p.\n\t* gcse.c (gcse_main): Use optimize_function_for_size_p.\n\t* loop-unroll.c (decide_unrolling_and_peeling): Use optimize_loop_for_size_p.\n\t(decide_peel_completely): Likewise.\n\t* tree-vect-analyze.c (vect_mark_for_runtime_alias_test): Use\n\toptimize_loop_for_size_p.\n\t(vect_enhance_data_refs_alignment): Likewise.\n\t* tree-ssa-coalesce.c (coalesce_cost): Add optimize_for_size argument.\n\t(coalesce_cost_bb, coalesce_cost_edge, create_outofssa_var_map): Update call.\n\t* cfgcleanup.c (outgoing_edges_match): Use optimize_bb_for_speed_p.\n\t(try_crossjump_bb): Use optimize_bb_for_size_p.\n\t* tree-ssa-loop-prefetch.c (loop_prefetch_arrays): Use\n\toptimize_loop_for_speed_p.\n\t* bb-reorder.c (find_traces_1_round): Likewise.\n\t(copy_bb): Use optimize_bb_for_speed_p.\n\t(duplicate_computed_gotos): Likewise.\n\t* basic-block.h (optimize_loop_nest_for_size_p,\n\toptimize_loop_nest_for_speed_p): New.\n\t* stmt.c (expand_case): Use optimize_insn_for_size_p.\n\nFrom-SVN: r139760", "tree": {"sha": "1c6f479b4b71cd53544bd1eb2bcc1d8b5055b58e", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/1c6f479b4b71cd53544bd1eb2bcc1d8b5055b58e"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/comments", "author": null, "committer": null, "parents": [{"sha": "e3536b82d746016fdb16f3480097329f26b12c9b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e3536b82d746016fdb16f3480097329f26b12c9b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e3536b82d746016fdb16f3480097329f26b12c9b"}], "stats": {"total": 261, "additions": 167, "deletions": 94}, "files": [{"sha": "637a89edd7367f63d197208fbef2ffa010b39846", "filename": "gcc/ChangeLog", "status": "modified", "additions": 54, "deletions": 0, "changes": 54, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -1,3 +1,57 @@\n+2008-08-29  Jan Hubicka  <jh@suse.cz>\n+\n+\t* loop-unswitch.c (unswitch_single_loop): Use optimize_loop_for_speed_p.\n+\t* tree-ssa-threadupdate.c (mark_threaded_blocks): Use optimize_function_for_size_p.\n+\t* tracer.c (ignore_bb_p): Use optimize_bb_for_size_p.\n+\t* postreload-gcse.c (eliminate_partially_redundant_load): Use optimize_bb_for_size_p.\n+\t* value-prof.c (gimple_divmod_fixed_value_transform,\n+\tgimple_mod_pow2_value_transform, gimple_mod_subtract_transform,\n+\tgimple_stringops_transform): Use optimize_bb_for_size_p.\n+\t* ipa-cp.c (ipcp_insert_stage): Use optimize_function_for_size_p.\n+\t* final.c (compute_alignments): Use optimize_function_for_size_p.\n+\t* builtins.c (fold_builtin_cabs): Use optimize_function_for_speed_p.\n+\t(fold_builtin_strcpy, fold_builtin_fputs): Use\n+\toptimize_function_for_size_p.\n+\t* fold-const.c (tree_swap_operands_p): Use optimize_function_for_size_p.\n+\t* recog.c (relax_delay_slots): Likewise.\n+\t* tree-ssa-math-opts.c (replace_reciprocal): Use optimize_bb_for_speed_p.\n+\t(execute_cse_reciprocals): Use optimize_bb_for_size_p.\n+\t* ipa-inline.c (cgraph_decide_recursive_inlining): Use\n+\toptimize_function_for_size_p.\n+\t(cgraph_decide_inlining_of_small_function): Use\n+\toptimize_function_for_size_p.\n+\t* global.c (find_reg): Use optimize_function_for_size_p.\n+\t* opts.c (decode_options): Do not clear flag_tree_ch, flag_inline_functions,\n+\tflag_unswitch_loops, flag_unroll_loops, flag_unroll_all_loops and\n+\tflag_prefetch_loop_arrays. Those can work it out from profile.\n+\t* tree-ssa-loop-ivcanon.c (tree_unroll_loops_completely): Use\n+\toptimize_loop_for_speed_p.\n+\t* predict.c (optimize_bb_for_size_p, optimize_bb_for_speed_p): Constify\n+\targument.\n+\t(optimize_loop_nest_for_size_p, optimize_loop_nest_for_speed_p): New.\n+\t* tree-parloops.c (parallelize_loops): Use optimize_loop_for_size_p.\n+\t* tree-eh.c (decide_copy_try_finally): Use optimize_function_for_size_p.\n+\t* local-alloc.c (block_alloc): Pass BB pointer.\n+\t(find_free_reg): Add BB pointer, use optimize_bb_for_size_p.\n+\t* gcse.c (gcse_main): Use optimize_function_for_size_p.\n+\t* loop-unroll.c (decide_unrolling_and_peeling): Use optimize_loop_for_size_p.\n+\t(decide_peel_completely): Likewise.\n+\t* tree-vect-analyze.c (vect_mark_for_runtime_alias_test): Use\n+\toptimize_loop_for_size_p.\n+\t(vect_enhance_data_refs_alignment): Likewise.\n+\t* tree-ssa-coalesce.c (coalesce_cost): Add optimize_for_size argument.\n+\t(coalesce_cost_bb, coalesce_cost_edge, create_outofssa_var_map): Update call.\n+\t* cfgcleanup.c (outgoing_edges_match): Use optimize_bb_for_speed_p.\n+\t(try_crossjump_bb): Use optimize_bb_for_size_p.\n+\t* tree-ssa-loop-prefetch.c (loop_prefetch_arrays): Use\n+\toptimize_loop_for_speed_p.\n+\t* bb-reorder.c (find_traces_1_round): Likewise.\n+\t(copy_bb): Use optimize_bb_for_speed_p.\n+\t(duplicate_computed_gotos): Likewise.\n+\t* basic-block.h (optimize_loop_nest_for_size_p,\n+\toptimize_loop_nest_for_speed_p): New.\n+\t* stmt.c (expand_case): Use optimize_insn_for_size_p.\n+\n 2008-08-29  Tristan Gingold  <gingold@adacore.com>\n \n \t* gcov.c (main): Call expandargv."}, {"sha": "e891f9e56757f5144cfe45ef2578fa42b1bba053", "filename": "gcc/basic-block.h", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fbasic-block.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fbasic-block.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbasic-block.h?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -841,6 +841,8 @@ extern bool optimize_function_for_size_p (struct function *);\n extern bool optimize_function_for_speed_p (struct function *);\n extern bool optimize_loop_for_size_p (struct loop *);\n extern bool optimize_loop_for_speed_p (struct loop *);\n+extern bool optimize_loop_nest_for_size_p (struct loop *);\n+extern bool optimize_loop_nest_for_speed_p (struct loop *);\n extern bool gimple_predicted_by_p (const_basic_block, enum br_predictor);\n extern bool rtl_predicted_by_p (const_basic_block, enum br_predictor);\n extern void gimple_predict_edge (edge, enum br_predictor, int);"}, {"sha": "3bf2dc72c7efb0b5e8e7e7febc4299d492820b0f", "filename": "gcc/bb-reorder.c", "status": "modified", "additions": 8, "deletions": 4, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fbb-reorder.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fbb-reorder.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbb-reorder.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -648,7 +648,8 @@ find_traces_1_round (int branch_th, int exec_th, gcov_type count_th,\n \t\t\t  /* The loop has less than 4 iterations.  */\n \n \t\t\t  if (single_succ_p (bb)\n-\t\t\t      && copy_bb_p (best_edge->dest, !optimize_size))\n+\t\t\t      && copy_bb_p (best_edge->dest,\n+\t\t\t      \t\t    optimize_edge_for_speed_p (best_edge)))\n \t\t\t    {\n \t\t\t      bb = copy_bb (best_edge->dest, best_edge, bb,\n \t\t\t\t\t    *n_traces);\n@@ -1102,7 +1103,7 @@ connect_traces (int n_traces, struct trace *traces)\n \t\t edge is traversed frequently enough.  */\n \t      if (try_copy\n \t\t  && copy_bb_p (best->dest,\n-\t\t\t\t!optimize_size\n+\t\t\t\toptimize_edge_for_speed_p (best)\n \t\t\t\t&& EDGE_FREQUENCY (best) >= freq_threshold\n \t\t\t\t&& best->count >= count_threshold))\n \t\t{\n@@ -1173,7 +1174,7 @@ copy_bb_p (const_basic_block bb, int code_may_grow)\n   if (EDGE_COUNT (bb->succs) > 8)\n     return false;\n \n-  if (code_may_grow && maybe_hot_bb_p (bb))\n+  if (code_may_grow && optimize_bb_for_speed_p (bb))\n     max_size *= PARAM_VALUE (PARAM_MAX_GROW_COPY_BB_INSNS);\n \n   FOR_BB_INSNS (bb, insn)\n@@ -1984,7 +1985,7 @@ gate_duplicate_computed_gotos (void)\n {\n   if (targetm.cannot_modify_jumps_p ())\n     return false;\n-  return (optimize > 0 && flag_expensive_optimizations && !optimize_size);\n+  return (optimize > 0 && flag_expensive_optimizations);\n }\n \n \n@@ -2075,6 +2076,9 @@ duplicate_computed_gotos (void)\n \t  || single_pred_p (single_succ (bb)))\n \tcontinue;\n \n+      if (!optimize_bb_for_size_p (bb))\n+\tcontinue;\n+\n       /* The successor block has to be a duplication candidate.  */\n       if (!bitmap_bit_p (candidates, single_succ (bb)->index))\n \tcontinue;"}, {"sha": "81d0ab1dfa178f883ee06acaf43521f7e9e2f7d2", "filename": "gcc/builtins.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fbuiltins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fbuiltins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbuiltins.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -7530,7 +7530,7 @@ fold_builtin_cabs (tree arg, tree type, tree fndecl)\n \n   /* Don't do this when optimizing for size.  */\n   if (flag_unsafe_math_optimizations\n-      && optimize && !optimize_size)\n+      && optimize && optimize_function_for_speed_p (cfun))\n     {\n       tree sqrtfn = mathfn_built_in (type, BUILT_IN_SQRT);\n \n@@ -8882,7 +8882,7 @@ fold_builtin_strcpy (tree fndecl, tree dest, tree src, tree len)\n   if (operand_equal_p (src, dest, 0))\n     return fold_convert (TREE_TYPE (TREE_TYPE (fndecl)), dest);\n \n-  if (optimize_size)\n+  if (optimize_function_for_size_p (cfun))\n     return NULL_TREE;\n \n   fn = implicit_built_in_decls[BUILT_IN_MEMCPY];\n@@ -11501,7 +11501,7 @@ fold_builtin_fputs (tree arg0, tree arg1, bool ignore, bool unlocked, tree len)\n     case 1: /* length is greater than 1, call fwrite.  */\n       {\n \t/* If optimizing for size keep fputs.  */\n-\tif (optimize_size)\n+\tif (optimize_function_for_size_p (cfun))\n \t  return NULL_TREE;\n \t/* New argument list transforming fputs(string, stream) to\n \t   fwrite(string, 1, len, stream).  */"}, {"sha": "a778e28e3869a3f7faf8aef0dd36b52825859bb3", "filename": "gcc/cfgcleanup.c", "status": "modified", "additions": 3, "deletions": 4, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fcfgcleanup.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fcfgcleanup.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcfgcleanup.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -1235,9 +1235,8 @@ outgoing_edges_match (int mode, basic_block bb1, basic_block bb2)\n \t we require the existing branches to have probabilities that are\n \t roughly similar.  */\n       if (match\n-\t  && !optimize_size\n-\t  && maybe_hot_bb_p (bb1)\n-\t  && maybe_hot_bb_p (bb2))\n+\t  && optimize_bb_for_speed_p (bb1)\n+\t  && optimize_bb_for_speed_p (bb2))\n \t{\n \t  int prob2;\n \n@@ -1684,7 +1683,7 @@ try_crossjump_bb (int mode, basic_block bb)\n \n   /* Don't crossjump if this block ends in a computed jump,\n      unless we are optimizing for size.  */\n-  if (!optimize_size\n+  if (optimize_bb_for_size_p (bb)\n       && bb != EXIT_BLOCK_PTR\n       && computed_jump_p (BB_END (bb)))\n     return false;"}, {"sha": "01689c16301e18f3873c44e98091af8024bef006", "filename": "gcc/final.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ffinal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ffinal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffinal.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -683,7 +683,7 @@ compute_alignments (void)\n   label_align = XCNEWVEC (struct label_alignment, max_labelno - min_labelno + 1);\n \n   /* If not optimizing or optimizing for size, don't assign any alignments.  */\n-  if (! optimize || optimize_size)\n+  if (! optimize || optimize_function_for_size_p (cfun))\n     return 0;\n \n   if (dump_file)\n@@ -765,7 +765,7 @@ compute_alignments (void)\n       /* In case block is frequent and reached mostly by non-fallthru edge,\n \t align it.  It is most likely a first block of loop.  */\n       if (has_fallthru\n-\t  && maybe_hot_bb_p (bb)\n+\t  && optimize_bb_for_speed_p (bb)\n \t  && branch_frequency + fallthru_frequency > freq_threshold\n \t  && (branch_frequency\n \t      > fallthru_frequency * PARAM_VALUE (PARAM_ALIGN_LOOP_ITERATIONS)))"}, {"sha": "af1643376f1ba332a7bfebf08837a916cdb75ac6", "filename": "gcc/fold-const.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ffold-const.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ffold-const.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffold-const.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -6679,7 +6679,7 @@ tree_swap_operands_p (const_tree arg0, const_tree arg1, bool reorder)\n   if (TREE_CONSTANT (arg0))\n     return 1;\n \n-  if (optimize_size)\n+  if (cfun && optimize_function_for_size_p (cfun))\n     return 0;\n \n   if (reorder && flag_evaluation_order\n@@ -10407,7 +10407,7 @@ fold_binary (enum tree_code code, tree type, tree op0, tree op1)\n \t\t}\n \n \t      /* Optimize x*x as pow(x,2.0), which is expanded as x*x.  */\n-\t      if (! optimize_size\n+\t      if (optimize_function_for_speed_p (cfun)\n \t\t  && operand_equal_p (arg0, arg1, 0))\n \t\t{\n \t\t  tree powfn = mathfn_built_in (type, BUILT_IN_POW);"}, {"sha": "ee2d31e0a42df54a0c6288a95318debe8ceb55a6", "filename": "gcc/gcse.c", "status": "modified", "additions": 3, "deletions": 5, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fgcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fgcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fgcse.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -738,9 +738,7 @@ gcse_main (rtx f ATTRIBUTE_UNUSED)\n \t  timevar_pop (TV_CPROP1);\n \t}\n \n-      if (optimize_size)\n-\t/* Do nothing.  */ ;\n-      else\n+      if (optimize_function_for_speed_p (cfun))\n \t{\n \t  timevar_push (TV_PRE);\n \t  changed |= one_pre_gcse_pass (pass + 1);\n@@ -773,7 +771,7 @@ gcse_main (rtx f ATTRIBUTE_UNUSED)\n \t for code size -- it rarely makes programs faster, and can make\n \t them bigger if we did partial redundancy elimination (when optimizing\n \t for space, we don't run the partial redundancy algorithms).  */\n-      if (optimize_size)\n+      if (optimize_function_for_size_p (cfun))\n \t{\n \t  timevar_push (TV_HOIST);\n \t  max_gcse_regno = max_reg_num ();\n@@ -825,7 +823,7 @@ gcse_main (rtx f ATTRIBUTE_UNUSED)\n   /* We are finished with alias.  */\n   end_alias_analysis ();\n \n-  if (!optimize_size && flag_gcse_sm)\n+  if (optimize_function_for_speed_p (cfun) && flag_gcse_sm)\n     {\n       timevar_push (TV_LSM);\n       store_motion ();"}, {"sha": "88fe38352f7312b92726eb1bdd675cfa2ee64c89", "filename": "gcc/global.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fglobal.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fglobal.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fglobal.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -1168,8 +1168,8 @@ find_reg (int num, HARD_REG_SET losers, int alt_regs_p, int accept_call_clobbere\n       if (! accept_call_clobbered\n \t  && allocno[num].calls_crossed != 0\n \t  && allocno[num].throwing_calls_crossed == 0\n-\t  && CALLER_SAVE_PROFITABLE (optimize_size ? allocno[num].n_refs : allocno[num].freq,\n-\t\t\t\t     optimize_size ? allocno[num].calls_crossed\n+\t  && CALLER_SAVE_PROFITABLE (optimize_function_for_size_p (cfun) ? allocno[num].n_refs : allocno[num].freq,\n+\t\t\t\t     optimize_function_for_size_p (cfun) ? allocno[num].calls_crossed\n \t\t\t\t     : allocno[num].freq_calls_crossed))\n \t{\n \t  HARD_REG_SET new_losers;"}, {"sha": "ca7e231904b926a2e7c2b7f1092f3c6f4913413b", "filename": "gcc/ipa-cp.c", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fipa-cp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fipa-cp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-cp.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -1019,9 +1019,7 @@ ipcp_insert_stage (void)\n       if (new_insns + growth > max_new_insns)\n \tbreak;\n       if (growth\n-          && (optimize_size\n-\t      || (DECL_STRUCT_FUNCTION (node->decl)\n-\t          ->function_frequency == FUNCTION_FREQUENCY_UNLIKELY_EXECUTED)))\n+\t  && optimize_function_for_size_p (DECL_STRUCT_FUNCTION (node->decl)))\n \t{\n \t  if (dump_file)\n \t    fprintf (dump_file, \"Not versioning, cold code would grow\");"}, {"sha": "94062f2a0f2a5b64cddbd1e864f935c6b6e6a7c2", "filename": "gcc/ipa-inline.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fipa-inline.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fipa-inline.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fipa-inline.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -674,7 +674,7 @@ cgraph_decide_recursive_inlining (struct cgraph_node *node,\n   int depth = 0;\n   int n = 0;\n \n-  if (optimize_size\n+  if (optimize_function_for_size_p (DECL_STRUCT_FUNCTION (node->decl))\n       || (!flag_inline_functions && !DECL_DECLARED_INLINE_P (node->decl)))\n     return false;\n \n@@ -951,7 +951,7 @@ cgraph_decide_inlining_of_small_functions (void)\n       if (!flag_inline_functions\n \t  && !DECL_DECLARED_INLINE_P (edge->callee->decl))\n  \tnot_good = N_(\"function not declared inline and code size would grow\");\n-      if (optimize_size)\n+      if (optimize_function_for_size_p (DECL_STRUCT_FUNCTION(edge->caller->decl)))\n  \tnot_good = N_(\"optimizing for size and code size would grow\");\n       if (not_good && growth > 0 && cgraph_estimate_growth (edge->callee) > 0)\n \t{"}, {"sha": "5926d6af3549d4b53a9ebc3cae5b14992125314e", "filename": "gcc/local-alloc.c", "status": "modified", "additions": 23, "deletions": 22, "changes": 45, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Flocal-alloc.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Flocal-alloc.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Flocal-alloc.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -299,7 +299,7 @@ static int contains_replace_regs (rtx);\n static int memref_referenced_p (rtx, rtx);\n static int memref_used_between_p (rtx, rtx, rtx);\n static void no_equiv (rtx, const_rtx, void *);\n-static void block_alloc (int);\n+static void block_alloc (basic_block);\n static int qty_sugg_compare (int, int);\n static int qty_sugg_compare_1 (const void *, const void *);\n static int qty_compare (int, int);\n@@ -311,7 +311,7 @@ static void reg_is_set (rtx, const_rtx, void *);\n static void reg_is_born (rtx, int);\n static void wipe_dead_reg (rtx, int);\n static int find_free_reg (enum reg_class, enum machine_mode, int, int, int,\n-\t\t\t  int, int);\n+\t\t\t  int, int, basic_block);\n static void mark_life (int, enum machine_mode, int);\n static void post_mark_life (int, enum machine_mode, int, int, int);\n static int requires_inout (const char *);\n@@ -436,7 +436,7 @@ local_alloc (void)\n \n       next_qty = 0;\n \n-      block_alloc (b->index);\n+      block_alloc (b);\n     }\n \n   free (qty);\n@@ -1270,7 +1270,7 @@ no_equiv (rtx reg, const_rtx store ATTRIBUTE_UNUSED, void *data ATTRIBUTE_UNUSED\n    Only the pseudos that die but once can be handled.  */\n \n static void\n-block_alloc (int b)\n+block_alloc (basic_block b)\n {\n   int i, q;\n   rtx insn;\n@@ -1283,15 +1283,15 @@ block_alloc (int b)\n \n   /* Count the instructions in the basic block.  */\n \n-  insn = BB_END (BASIC_BLOCK (b));\n+  insn = BB_END (b);\n   while (1)\n     {\n       if (!NOTE_P (insn))\n \t{\n \t  ++insn_count;\n \t  gcc_assert (insn_count <= max_uid);\n \t}\n-      if (insn == BB_HEAD (BASIC_BLOCK (b)))\n+      if (insn == BB_HEAD (b))\n \tbreak;\n       insn = PREV_INSN (insn);\n     }\n@@ -1302,14 +1302,14 @@ block_alloc (int b)\n \n   /* Initialize table of hardware registers currently live.  */\n \n-  REG_SET_TO_HARD_REG_SET (regs_live, DF_LR_IN (BASIC_BLOCK (b)));\n+  REG_SET_TO_HARD_REG_SET (regs_live, DF_LR_IN (b));\n \n   /* This is conservative, as this would include registers that are\n      artificial-def'ed-but-not-used.  However, artificial-defs are\n      rare, and such uninitialized use is rarer still, and the chance\n      of this having any performance impact is even less, while the\n      benefit is not having to compute and keep the TOP set around.  */\n-  for (def_rec = df_get_artificial_defs (b); *def_rec; def_rec++)\n+  for (def_rec = df_get_artificial_defs (b->index); *def_rec; def_rec++)\n     {\n       int regno = DF_REF_REGNO (*def_rec);\n       if (regno < FIRST_PSEUDO_REGISTER)\n@@ -1320,7 +1320,7 @@ block_alloc (int b)\n      and assigns quantities to registers.\n      It computes which registers to tie.  */\n \n-  insn = BB_HEAD (BASIC_BLOCK (b));\n+  insn = BB_HEAD (b);\n   while (1)\n     {\n       if (!NOTE_P (insn))\n@@ -1487,7 +1487,7 @@ block_alloc (int b)\n       IOR_HARD_REG_SET (regs_live_at[2 * insn_number], regs_live);\n       IOR_HARD_REG_SET (regs_live_at[2 * insn_number + 1], regs_live);\n \n-      if (insn == BB_END (BASIC_BLOCK (b)))\n+      if (insn == BB_END (b))\n \tbreak;\n \n       insn = NEXT_INSN (insn);\n@@ -1542,7 +1542,7 @@ block_alloc (int b)\n       q = qty_order[i];\n       if (qty_phys_num_sugg[q] != 0 || qty_phys_num_copy_sugg[q] != 0)\n \tqty[q].phys_reg = find_free_reg (qty[q].min_class, qty[q].mode, q,\n-\t\t\t\t\t 0, 1, qty[q].birth, qty[q].death);\n+\t\t\t\t\t 0, 1, qty[q].birth, qty[q].death, b);\n       else\n \tqty[q].phys_reg = -1;\n     }\n@@ -1627,37 +1627,37 @@ block_alloc (int b)\n \t\t a scheduling pass after reload and we are not optimizing\n \t\t for code size.  */\n \t      if (flag_schedule_insns_after_reload && dbg_cnt (local_alloc_for_sched)\n-\t\t  && !optimize_size\n+\t\t  && optimize_bb_for_speed_p (b)\n \t\t  && !SMALL_REGISTER_CLASSES)\n \t\t{\n \t\t  qty[q].phys_reg = find_free_reg (qty[q].min_class,\n \t\t\t\t\t\t   qty[q].mode, q, 0, 0,\n-\t\t\t\t\t\t   fake_birth, fake_death);\n+\t\t\t\t\t\t   fake_birth, fake_death, b);\n \t\t  if (qty[q].phys_reg >= 0)\n \t\t    continue;\n \t\t}\n #endif\n \t      qty[q].phys_reg = find_free_reg (qty[q].min_class,\n \t\t\t\t\t       qty[q].mode, q, 0, 0,\n-\t\t\t\t\t       qty[q].birth, qty[q].death);\n+\t\t\t\t\t       qty[q].birth, qty[q].death, b);\n \t      if (qty[q].phys_reg >= 0)\n \t\tcontinue;\n \t    }\n \n #ifdef INSN_SCHEDULING\n \t  /* Similarly, avoid false dependencies.  */\n \t  if (flag_schedule_insns_after_reload && dbg_cnt (local_alloc_for_sched)\n-\t      && !optimize_size\n+\t      && optimize_bb_for_speed_p (b)\n \t      && !SMALL_REGISTER_CLASSES\n \t      && qty[q].alternate_class != NO_REGS)\n \t    qty[q].phys_reg = find_free_reg (qty[q].alternate_class,\n \t\t\t\t\t     qty[q].mode, q, 0, 0,\n-\t\t\t\t\t     fake_birth, fake_death);\n+\t\t\t\t\t     fake_birth, fake_death, b);\n #endif\n \t  if (qty[q].alternate_class != NO_REGS)\n \t    qty[q].phys_reg = find_free_reg (qty[q].alternate_class,\n \t\t\t\t\t     qty[q].mode, q, 0, 0,\n-\t\t\t\t\t     qty[q].birth, qty[q].death);\n+\t\t\t\t\t     qty[q].birth, qty[q].death, b);\n \t}\n     }\n \n@@ -2145,7 +2145,7 @@ wipe_dead_reg (rtx reg, int output_p)\n static int\n find_free_reg (enum reg_class rclass, enum machine_mode mode, int qtyno,\n \t       int accept_call_clobbered, int just_try_suggested,\n-\t       int born_index, int dead_index)\n+\t       int born_index, int dead_index, basic_block bb)\n {\n   int i, ins;\n   HARD_REG_SET first_used, used;\n@@ -2261,7 +2261,7 @@ find_free_reg (enum reg_class rclass, enum machine_mode mode, int qtyno,\n       /* Don't try the copy-suggested regs again.  */\n       qty_phys_num_copy_sugg[qtyno] = 0;\n       return find_free_reg (rclass, mode, qtyno, accept_call_clobbered, 1,\n-\t\t\t    born_index, dead_index);\n+\t\t\t    born_index, dead_index, bb);\n     }\n \n   /* We need not check to see if the current function has nonlocal\n@@ -2274,11 +2274,12 @@ find_free_reg (enum reg_class rclass, enum machine_mode mode, int qtyno,\n       && ! just_try_suggested\n       && qty[qtyno].n_calls_crossed != 0\n       && qty[qtyno].n_throwing_calls_crossed == 0\n-      && CALLER_SAVE_PROFITABLE (optimize_size ? qty[qtyno].n_refs : qty[qtyno].freq,\n-\t\t\t\t optimize_size ? qty[qtyno].n_calls_crossed\n+      && CALLER_SAVE_PROFITABLE (optimize_bb_for_size_p (bb) ? qty[qtyno].n_refs\n+      \t\t\t\t : qty[qtyno].freq,\n+\t\t\t\t optimize_bb_for_size_p (bb) ? qty[qtyno].n_calls_crossed\n \t\t\t\t : qty[qtyno].freq_calls_crossed))\n     {\n-      i = find_free_reg (rclass, mode, qtyno, 1, 0, born_index, dead_index);\n+      i = find_free_reg (rclass, mode, qtyno, 1, 0, born_index, dead_index, bb);\n       if (i >= 0)\n \tcaller_save_needed = 1;\n       return i;"}, {"sha": "7995786329caeca81223c8dcbea606f5c7a8de61", "filename": "gcc/loop-unroll.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Floop-unroll.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Floop-unroll.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop-unroll.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -269,7 +269,7 @@ decide_unrolling_and_peeling (int flags)\n \tfprintf (dump_file, \"\\n;; *** Considering loop %d ***\\n\", loop->num);\n \n       /* Do not peel cold areas.  */\n-      if (!maybe_hot_bb_p (loop->header))\n+      if (optimize_loop_for_size_p (loop))\n \t{\n \t  if (dump_file)\n \t    fprintf (dump_file, \";; Not considering loop, cold area\\n\");\n@@ -368,7 +368,7 @@ decide_peel_completely (struct loop *loop, int flags ATTRIBUTE_UNUSED)\n     }\n \n   /* Do not peel cold areas.  */\n-  if (!maybe_hot_bb_p (loop->header))\n+  if (optimize_loop_for_size_p (loop))\n     {\n       if (dump_file)\n \tfprintf (dump_file, \";; Not considering loop, cold area\\n\");"}, {"sha": "8770bf6b5a86de0d290b3503134ab1e3f5c79294", "filename": "gcc/loop-unswitch.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Floop-unswitch.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Floop-unswitch.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop-unswitch.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -290,7 +290,7 @@ unswitch_single_loop (struct loop *loop, rtx cond_checked, int num)\n     }\n \n   /* Do not unswitch in cold areas.  */\n-  if (!maybe_hot_bb_p (loop->header))\n+  if (optimize_loop_for_size_p (loop))\n     {\n       if (dump_file)\n \tfprintf (dump_file, \";; Not unswitching, not hot area\\n\");"}, {"sha": "8c46dfa9cf734c989b4cfde28f0689285f89c26d", "filename": "gcc/opts.c", "status": "modified", "additions": 0, "deletions": 14, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fopts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fopts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fopts.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -990,12 +990,6 @@ decode_options (unsigned int argc, const char **argv)\n \n   if (optimize_size)\n     {\n-      /* Loop header copying usually increases size of the code.  This used not to\n-\t be true, since quite often it is possible to verify that the condition is\n-\t satisfied in the first iteration and therefore to eliminate it.  Jump\n-\t threading handles these cases now.  */\n-      flag_tree_ch = 0;\n-\n       /* Conditional DCE generates bigger code.  */\n       flag_tree_builtin_call_dce = 0;\n \n@@ -1004,8 +998,6 @@ decode_options (unsigned int argc, const char **argv)\n \n       /* These options are set with -O3, so reset for -Os */\n       flag_predictive_commoning = 0;\n-      flag_inline_functions = 0;\n-      flag_unswitch_loops = 0;\n       flag_gcse_after_reload = 0;\n       flag_tree_vectorize = 0;\n \n@@ -1029,12 +1021,6 @@ decode_options (unsigned int argc, const char **argv)\n       align_labels = 1;\n       align_functions = 1;\n \n-      /* Unroll/prefetch switches that may be set on the command line, and tend to\n-\t generate bigger code.  */\n-      flag_unroll_loops = 0;\n-      flag_unroll_all_loops = 0;\n-      flag_prefetch_loop_arrays = 0;\n-\n       /* Basic optimization options.  */\n       optimize_size = 1;\n       if (optimize > 2)"}, {"sha": "352503fcaae481bbbd060b1ea1ce1ff6ac6e17db", "filename": "gcc/postreload-gcse.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fpostreload-gcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fpostreload-gcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpostreload-gcse.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -1066,7 +1066,7 @@ eliminate_partially_redundant_load (basic_block bb, rtx insn,\n   if (/* No load can be replaced by copy.  */\n       npred_ok == 0\n       /* Prevent exploding the code.  */ \n-      || (optimize_size && npred_ok > 1)\n+      || (optimize_bb_for_size_p (bb) && npred_ok > 1)\n       /* If we don't have profile information we cannot tell if splitting \n          a critical edge is profitable or not so don't do it.  */\n       || ((! profile_info || ! flag_branch_probabilities"}, {"sha": "bd9635e102c6fb2b5b5815bbb013fe4acb6e8f3c", "filename": "gcc/predict.c", "status": "modified", "additions": 31, "deletions": 0, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fpredict.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fpredict.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fpredict.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -261,6 +261,37 @@ optimize_loop_for_speed_p (struct loop *loop)\n   return optimize_bb_for_speed_p (loop->header);\n }\n \n+/* Return TRUE when LOOP nest should be optimized for speed.  */\n+\n+bool\n+optimize_loop_nest_for_speed_p (struct loop *loop)\n+{\n+  struct loop *l = loop;\n+  if (optimize_loop_for_speed_p (loop))\n+    return true;\n+  l = loop->inner;\n+  while (l != loop)\n+    {\n+      if (optimize_loop_for_speed_p (l))\n+        return true;\n+      if (l->inner)\n+        l = l->inner;\n+      else if (l->next)\n+        l = l->next;\n+      else\n+\tl = loop_outer (l);\n+    }\n+  return false;\n+}\n+\n+/* Return TRUE when LOOP nest should be optimized for size.  */\n+\n+bool\n+optimize_loop_nest_for_size_p (struct loop *loop)\n+{\n+  return !optimize_loop_nest_for_speed_p (loop);\n+}\n+\n /* Set RTL expansion for BB profile.  */\n \n void"}, {"sha": "97570e858ddd4ef44007fd1cb2eb74c37c559d6e", "filename": "gcc/reorg.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Freorg.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Freorg.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freorg.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -3439,7 +3439,7 @@ relax_delay_slots (rtx first)\n \n \t Only do so if optimizing for size since this results in slower, but\n \t smaller code.  */\n-      if (optimize_size\n+      if (optimize_function_for_size_p (cfun)\n \t  && GET_CODE (PATTERN (delay_insn)) == RETURN\n \t  && next\n \t  && JUMP_P (next)"}, {"sha": "2464466b376e4536576089147eeeaa7e9c28a47a", "filename": "gcc/stmt.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fstmt.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fstmt.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fstmt.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -2419,7 +2419,7 @@ expand_case (tree exp)\n \n       else if (count < case_values_threshold ()\n \t       || compare_tree_int (range,\n-\t\t\t\t    (optimize_size ? 3 : 10) * count) > 0\n+\t\t\t\t    (optimize_insn_for_size_p () ? 3 : 10) * count) > 0\n \t       /* RANGE may be signed, and really large ranges will show up\n \t\t  as negative numbers.  */\n \t       || compare_tree_int (range, 0) < 0\n@@ -2489,7 +2489,7 @@ expand_case (tree exp)\n \n \t      /* Index jumptables from zero for suitable values of\n                  minval to avoid a subtraction.  */\n-\t      if (! optimize_size\n+\t      if (optimize_insn_for_speed_p ()\n \t\t  && compare_tree_int (minval, 0) > 0\n \t\t  && compare_tree_int (minval, 3) < 0)\n \t\t{"}, {"sha": "9bf2c57ded390bdb5bb757229500397a9528ed66", "filename": "gcc/tracer.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftracer.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftracer.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftracer.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -92,7 +92,7 @@ ignore_bb_p (const_basic_block bb)\n {\n   if (bb->index < NUM_FIXED_BLOCKS)\n     return true;\n-  if (!maybe_hot_bb_p (bb))\n+  if (optimize_bb_for_size_p (bb))\n     return true;\n   return false;\n }"}, {"sha": "5fe8f24ed27149676bffb0188af817a163365f85", "filename": "gcc/tree-eh.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-eh.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-eh.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-eh.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -1535,7 +1535,7 @@ decide_copy_try_finally (int ndests, gimple_seq finally)\n   sw_estimate = 10 + 2 * ndests;\n \n   /* Optimize for size clearly wants our best guess.  */\n-  if (optimize_size)\n+  if (optimize_function_for_size_p (cfun))\n     return f_estimate < sw_estimate;\n \n   /* ??? These numbers are completely made up so far.  */"}, {"sha": "0373205c9f3db1afd8721bb6abda642d0e12735c", "filename": "gcc/tree-parloops.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-parloops.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-parloops.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-parloops.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -1843,7 +1843,7 @@ parallelize_loops (void)\n     {\n       htab_empty (reduction_list);\n       if (/* Do not bother with loops in cold areas.  */\n-\t  !maybe_hot_bb_p (loop->header)\n+\t  optimize_loop_nest_for_size_p (loop)\n \t  /* Or loops that roll too little.  */\n \t  || expected_loop_iterations (loop) <= n_threads\n \t  /* And of course, the loop must be parallelizable.  */"}, {"sha": "3af0c3285d82ed0e291677e8d4305b78fd6771b7", "filename": "gcc/tree-ssa-coalesce.c", "status": "modified", "additions": 5, "deletions": 9, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-ssa-coalesce.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-ssa-coalesce.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-coalesce.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -75,20 +75,16 @@ typedef struct coalesce_list_d\n    possibly on CRITICAL edge and in HOT basic block.  */\n \n static inline int\n-coalesce_cost (int frequency, bool hot, bool critical)\n+coalesce_cost (int frequency, bool optimize_for_size, bool critical)\n {\n   /* Base costs on BB frequencies bounded by 1.  */\n   int cost = frequency;\n \n   if (!cost)\n     cost = 1;\n \n-  if (optimize_size)\n+  if (optimize_for_size)\n     cost = 1;\n-  else\n-    /* It is more important to coalesce in HOT blocks.  */\n-    if (hot)\n-      cost *= 2;\n \n   /* Inserting copy on critical edge costs more than inserting it elsewhere.  */\n   if (critical)\n@@ -102,7 +98,7 @@ coalesce_cost (int frequency, bool hot, bool critical)\n static inline int \n coalesce_cost_bb (basic_block bb)\n {\n-  return coalesce_cost (bb->frequency, maybe_hot_bb_p (bb), false);\n+  return coalesce_cost (bb->frequency, optimize_bb_for_size_p (bb), false);\n }\n \n \n@@ -115,7 +111,7 @@ coalesce_cost_edge (edge e)\n     return MUST_COALESCE_COST;\n \n   return coalesce_cost (EDGE_FREQUENCY (e), \n-\t\t\tmaybe_hot_edge_p (e), \n+\t\t\toptimize_edge_for_size_p (e), \n \t\t\tEDGE_CRITICAL_P (e));\n }\n \n@@ -1099,7 +1095,7 @@ create_outofssa_var_map (coalesce_list_p cl, bitmap used_in_copy)\n \t\t    if (SSA_NAME_VAR (outputs[match]) == SSA_NAME_VAR (input))\n \t\t      {\n \t\t\tcost = coalesce_cost (REG_BR_PROB_BASE, \n-\t\t\t\t\t      maybe_hot_bb_p (bb),\n+\t\t\t\t\t      optimize_bb_for_size_p (bb),\n \t\t\t\t\t      false);\n \t\t\tadd_coalesce (cl, v1, v2, cost);\n \t\t\tbitmap_set_bit (used_in_copy, v1);"}, {"sha": "e278c55b08bbd3f0387bf8f03a968f13fd1e9441", "filename": "gcc/tree-ssa-loop-ivcanon.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-ssa-loop-ivcanon.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-ssa-loop-ivcanon.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-ivcanon.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -359,7 +359,7 @@ tree_unroll_loops_completely (bool may_increase_size, bool unroll_outer)\n \n       FOR_EACH_LOOP (li, loop, LI_ONLY_INNERMOST)\n \t{\n-\t  if (may_increase_size && maybe_hot_bb_p (loop->header)\n+\t  if (may_increase_size && optimize_loop_for_speed_p (loop)\n \t      /* Unroll outermost loops only if asked to do so or they do\n \t\t not cause code growth.  */\n \t      && (unroll_outer"}, {"sha": "6da4bf232aaa9b52b8d3a1059ac8824e3dc1e4fe", "filename": "gcc/tree-ssa-loop-prefetch.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-ssa-loop-prefetch.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-ssa-loop-prefetch.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-loop-prefetch.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -1460,7 +1460,7 @@ loop_prefetch_arrays (struct loop *loop)\n   struct tree_niter_desc desc;\n   bool unrolled = false, no_other_refs;\n \n-  if (!maybe_hot_bb_p (loop->header))\n+  if (optimize_loop_nest_for_size_p (loop))\n     {\n       if (dump_file && (dump_flags & TDF_DETAILS))\n \tfprintf (dump_file, \"  ignored (cold area)\\n\");"}, {"sha": "9f88ba6aec7beea75e8af7fd38a1d2a8463ebe22", "filename": "gcc/tree-ssa-math-opts.c", "status": "modified", "additions": 6, "deletions": 2, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-ssa-math-opts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-ssa-math-opts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-math-opts.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -353,7 +353,8 @@ replace_reciprocal (use_operand_p use_p)\n   basic_block bb = gimple_bb (use_stmt);\n   struct occurrence *occ = (struct occurrence *) bb->aux;\n \n-  if (occ->recip_def && use_stmt != occ->recip_def_stmt)\n+  if (optimize_bb_for_speed_p (bb)\n+      && occ->recip_def && use_stmt != occ->recip_def_stmt)\n     {\n       gimple_assign_set_rhs_code (use_stmt, MULT_EXPR);\n       SET_USE (use_p, occ->recip_def);\n@@ -445,7 +446,7 @@ execute_cse_reciprocals_1 (gimple_stmt_iterator *def_gsi, tree def)\n static bool\n gate_cse_reciprocals (void)\n {\n-  return optimize && !optimize_size && flag_reciprocal_math;\n+  return optimize && flag_reciprocal_math;\n }\n \n /* Go through all the floating-point SSA_NAMEs, and call\n@@ -500,6 +501,9 @@ execute_cse_reciprocals (void)\n \t    execute_cse_reciprocals_1 (&gsi, def);\n \t}\n \n+      if (optimize_bb_for_size_p (bb))\n+        continue;\n+\n       /* Scan for a/func(b) and convert it to reciprocal a*rfunc(b).  */\n       for (gsi = gsi_after_labels (bb); !gsi_end_p (gsi); gsi_next (&gsi))\n         {"}, {"sha": "b6d2fafaa0fd377fb2d24657ddd32bc5223a7c00", "filename": "gcc/tree-ssa-threadupdate.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-ssa-threadupdate.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-ssa-threadupdate.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-ssa-threadupdate.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -994,7 +994,7 @@ mark_threaded_blocks (bitmap threaded_blocks)\n \n   /* If optimizing for size, only thread through block if we don't have\n      to duplicate it or it's an otherwise empty redirection block.  */\n-  if (optimize_size)\n+  if (optimize_function_for_size_p (cfun))\n     {\n       EXECUTE_IF_SET_IN_BITMAP (tmp, 0, i, bi)\n \t{"}, {"sha": "93cd643d0f2ac17d8e85ba86debd8f1743639214", "filename": "gcc/tree-vect-analyze.c", "status": "modified", "additions": 3, "deletions": 3, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-vect-analyze.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Ftree-vect-analyze.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-analyze.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -1219,7 +1219,7 @@ vect_mark_for_runtime_alias_test (ddr_p ddr, loop_vec_info loop_vinfo)\n       print_generic_expr (vect_dump, DR_REF (DDR_B (ddr)), TDF_SLIM);\n     }\n \n-  if (optimize_size)\n+  if (optimize_loop_nest_for_size_p (loop))\n     {\n       if (vect_print_dump_info (REPORT_DR_DETAILS))\n \tfprintf (vect_dump, \"versioning not supported when optimizing for size.\");\n@@ -1993,15 +1993,15 @@ vect_enhance_data_refs_alignment (loop_vec_info loop_vinfo)\n \n   /* Try versioning if:\n      1) flag_tree_vect_loop_version is TRUE\n-     2) optimize_size is FALSE\n+     2) optimize loop for speed\n      3) there is at least one unsupported misaligned data ref with an unknown\n         misalignment, and\n      4) all misaligned data refs with a known misalignment are supported, and\n      5) the number of runtime alignment checks is within reason.  */\n \n   do_versioning = \n \tflag_tree_vect_loop_version \n-\t&& (!optimize_size)\n+\t&& optimize_loop_nest_for_speed_p (loop)\n \t&& (!loop->inner); /* FORNOW */\n \n   if (do_versioning)"}, {"sha": "fac124ffddf554834abf1e5e9f43c7bc4c629008", "filename": "gcc/value-prof.c", "status": "modified", "additions": 4, "deletions": 4, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fvalue-prof.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d/gcc%2Fvalue-prof.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fvalue-prof.c?ref=efd8f7507b3ce6e4cc00c7eac4f011736ca4f14d", "patch": "@@ -669,7 +669,7 @@ gimple_divmod_fixed_value_transform (gimple_stmt_iterator *si)\n      at least 50% of time (and 75% gives the guarantee of usage).  */\n   if (simple_cst_equal (gimple_assign_rhs2 (stmt), value) != 1\n       || 2 * count < all\n-      || !maybe_hot_bb_p (gimple_bb (stmt)))\n+      || optimize_bb_for_size_p (gimple_bb (stmt)))\n     return false;\n \n   if (check_counter (stmt, \"value\", &count, &all, gimple_bb (stmt)->count))\n@@ -820,7 +820,7 @@ gimple_mod_pow2_value_transform (gimple_stmt_iterator *si)\n   /* We require that we hit a power of 2 at least half of all evaluations.  */\n   if (simple_cst_equal (gimple_assign_rhs2 (stmt), value) != 1\n       || count < wrong_values\n-      || !maybe_hot_bb_p (gimple_bb (stmt)))\n+      || optimize_bb_for_size_p (gimple_bb (stmt)))\n     return false;\n \n   if (dump_file)\n@@ -1017,7 +1017,7 @@ gimple_mod_subtract_transform (gimple_stmt_iterator *si)\n \tbreak;\n     }\n   if (i == steps\n-      || !maybe_hot_bb_p (gimple_bb (stmt)))\n+      || optimize_bb_for_size_p (gimple_bb (stmt)))\n     return false;\n \n   gimple_remove_histogram_value (cfun, stmt, histogram);\n@@ -1397,7 +1397,7 @@ gimple_stringops_transform (gimple_stmt_iterator *gsi)\n   /* We require that count is at least half of all; this means\n      that for the transformation to fire the value must be constant\n      at least 80% of time.  */\n-  if ((6 * count / 5) < all || !maybe_hot_bb_p (gimple_bb (stmt)))\n+  if ((6 * count / 5) < all || optimize_bb_for_size_p (gimple_bb (stmt)))\n     return false;\n   if (check_counter (stmt, \"value\", &count, &all, gimple_bb (stmt)->count))\n     return false;"}]}