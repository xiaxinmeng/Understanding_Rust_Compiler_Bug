{"sha": "46fac66482f1cf5cc61f7fef9de8b7593c8357e7", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NDZmYWM2NjQ4MmYxY2Y1Y2M2MWY3ZmVmOWRlOGI3NTkzYzgzNTdlNw==", "commit": {"author": {"name": "Jan Hubicka", "email": "jh@suse.cz", "date": "2001-07-11T19:42:35Z"}, "committer": {"name": "Jan Hubicka", "email": "hubicka@gcc.gnu.org", "date": "2001-07-11T19:42:35Z"}, "message": "flow.c (merge_blocks_move_successor_nojumps): Do not crash when fallthru edge is present.\n\n\t* flow.c (merge_blocks_move_successor_nojumps): Do not crash\n\twhen fallthru edge is present.\n\t(mege_blocks): Handle case where creation of jump insn\n\tis required.\n\n\t* basic-block.h (CLEANUP_EXPENSIVE, CLEANUP_CROSSJUMP,\n\tCLEANUP_POST_REGSTACK): New constants.\n\t* except.c (finish_eh_generation): Update call of cleanup_cfg,\n\t* jump.c (rtx_renumbered_equal_p): Handle 't' fields.\n\t* output.h (cleanup_cfg): Update prototype.\n\t* reg-stack.c (reg_to_stack): Use cleanup_cfg instead of jump_optimize\n\t* sibcall.c (optimize_sibling_and_tail_recursive_call): Update\n\tcleanup_cfg call; kill missleading comment.\n\t* toplev.c (rest_of_compilation): Update all cleanup_cfg calls.\n\t* flow.c (merge_blocks, try_optimize_cfg, cleanup_cfg): Accept mode\n\tparameter; control optimizations performed using it.\n\t(flow_find_cross_jump, outgoing_edges_match, try_crossjump_to_edge,\n\ttry_crossjump_bb): New functions.\n\nFrom-SVN: r43950", "tree": {"sha": "60903d3543bd7ef55ab3cdb0ddd8b7aed79a1788", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/60903d3543bd7ef55ab3cdb0ddd8b7aed79a1788"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/46fac66482f1cf5cc61f7fef9de8b7593c8357e7", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/46fac66482f1cf5cc61f7fef9de8b7593c8357e7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/46fac66482f1cf5cc61f7fef9de8b7593c8357e7", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/comments", "author": null, "committer": null, "parents": [{"sha": "669f7a035a384894ac482e00c291d393a21ba2d0", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/669f7a035a384894ac482e00c291d393a21ba2d0", "html_url": "https://github.com/Rust-GCC/gccrs/commit/669f7a035a384894ac482e00c291d393a21ba2d0"}], "stats": {"total": 656, "additions": 614, "deletions": 42}, "files": [{"sha": "35cfd305e77592002bd684437a52815ebbb78fba", "filename": "gcc/ChangeLog", "status": "modified", "additions": 21, "deletions": 0, "changes": 21, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=46fac66482f1cf5cc61f7fef9de8b7593c8357e7", "patch": "@@ -1,3 +1,24 @@\n+Wed Jul 11 21:27:25 CEST 2001  Jan Hubicka  <jh@suse.cz>\n+\n+\t* flow.c (merge_blocks_move_successor_nojumps): Do not crash\n+\twhen fallthru edge is present.\n+\t(mege_blocks): Handle case where creation of jump insn\n+\tis required.\n+\n+\t* basic-block.h (CLEANUP_EXPENSIVE, CLEANUP_CROSSJUMP,\n+\tCLEANUP_POST_REGSTACK): New constants.\n+\t* except.c (finish_eh_generation): Update call of cleanup_cfg,\n+\t* jump.c (rtx_renumbered_equal_p): Handle 't' fields.\n+\t* output.h (cleanup_cfg): Update prototype.\n+\t* reg-stack.c (reg_to_stack): Use cleanup_cfg instead of jump_optimize\n+\t* sibcall.c (optimize_sibling_and_tail_recursive_call): Update \n+\tcleanup_cfg call; kill missleading comment.\n+\t* toplev.c (rest_of_compilation): Update all cleanup_cfg calls.\n+\t* flow.c (merge_blocks, try_optimize_cfg, cleanup_cfg): Accept mode\n+\tparameter; control optimizations performed using it.\n+\t(flow_find_cross_jump, outgoing_edges_match, try_crossjump_to_edge,\n+\ttry_crossjump_bb): New functions.\n+\n 2001-07-11  John David Anglin  <dave@hiauly1.hia.nrc.ca>\n \n \t* pa.c (pa_output_function_prologue): Delete prototype.  Make function"}, {"sha": "fc5907387051d22a02820834ca2e4ec66e13f6bc", "filename": "gcc/basic-block.h", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Fbasic-block.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Fbasic-block.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fbasic-block.h?ref=46fac66482f1cf5cc61f7fef9de8b7593c8357e7", "patch": "@@ -535,6 +535,11 @@ enum update_life_extent\n #define PROP_AUTOINC\t\t32\t/* Create autoinc mem references.  */\n #define PROP_FINAL\t\t63\t/* All of the above.  */\n \n+#define CLEANUP_EXPENSIVE\t1\t/* Do relativly expensive optimizations\n+\t\t\t\t\t   except for edge forwarding */\n+#define CLEANUP_CROSSJUMP\t2\t/* Do crossjumping.  */\n+#define CLEANUP_POST_REGSTACK\t4\t/* We run after reg-stack and need\n+\t\t\t\t\t   to care REG_DEAD notes.  */\n /* Flags for loop discovery.  */\n \n #define LOOP_TREE\t\t1 \t/* Build loop hierarchy tree.  */"}, {"sha": "82ef3fe0944cc8cf8cf99192b0a58828d3e4ad9a", "filename": "gcc/except.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Fexcept.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Fexcept.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fexcept.c?ref=46fac66482f1cf5cc61f7fef9de8b7593c8357e7", "patch": "@@ -2349,7 +2349,7 @@ finish_eh_generation ()\n \n   jump_optimize_minimal (get_insns ());\n   find_basic_blocks (get_insns (), max_reg_num (), 0);\n-  cleanup_cfg ();\n+  cleanup_cfg (0);\n \n   /* These registers are used by the landing pads.  Make sure they\n      have been generated.  */\n@@ -2372,7 +2372,7 @@ finish_eh_generation ()\n   find_exception_handler_labels ();\n   jump_optimize_minimal (get_insns ());\n   find_basic_blocks (get_insns (), max_reg_num (), 0);\n-  cleanup_cfg ();\n+  cleanup_cfg (0);\n }\n \f\n /* This section handles removing dead code for flow.  */"}, {"sha": "356433351aeae1cfe9d5c0749b390b17c87c48ac", "filename": "gcc/flow.c", "status": "modified", "additions": 570, "deletions": 22, "changes": 592, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Fflow.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Fflow.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fflow.c?ref=46fac66482f1cf5cc61f7fef9de8b7593c8357e7", "patch": "@@ -365,6 +365,11 @@ typedef struct depth_first_search_dsS *depth_first_search_ds;\n   print_rtl_and_abort_fcn (__FILE__, __LINE__, __FUNCTION__)\n \n /* Forward declarations */\n+static bool try_crossjump_to_edge \tPARAMS ((int, edge, edge));\n+static bool try_crossjump_bb\t\tPARAMS ((int, basic_block));\n+static bool outgoing_edges_match\tPARAMS ((basic_block, basic_block));\n+static int flow_find_cross_jump\t\tPARAMS ((int, basic_block, basic_block,\n+\t\t\t\t\t\t rtx *, rtx *));\n static int count_basic_blocks\t\tPARAMS ((rtx));\n static void find_basic_blocks_1\t\tPARAMS ((rtx));\n static rtx find_label_refs\t\tPARAMS ((rtx, rtx));\n@@ -384,8 +389,9 @@ static int merge_blocks_move_predecessor_nojumps PARAMS ((basic_block,\n \t\t\t\t\t\t\t  basic_block));\n static int merge_blocks_move_successor_nojumps PARAMS ((basic_block,\n \t\t\t\t\t\t\tbasic_block));\n-static int merge_blocks\t\t\tPARAMS ((edge,basic_block,basic_block));\n-static bool try_optimize_cfg\t\tPARAMS ((void));\n+static int merge_blocks\t\t\tPARAMS ((edge,basic_block,basic_block,\n+\t\t\t\t\t\t int));\n+static bool try_optimize_cfg\t\tPARAMS ((int));\n static bool forwarder_block_p\t\tPARAMS ((basic_block));\n static bool can_fallthru\t\tPARAMS ((basic_block, basic_block));\n static bool try_redirect_by_replacing_jump PARAMS ((edge, basic_block));\n@@ -1016,10 +1022,11 @@ find_basic_blocks_1 (f)\n /* Tidy the CFG by deleting unreachable code and whatnot.  */\n \n void\n-cleanup_cfg ()\n+cleanup_cfg (mode)\n+     int mode;\n {\n   delete_unreachable_blocks ();\n-  if (try_optimize_cfg ())\n+  if (try_optimize_cfg (mode))\n     delete_unreachable_blocks ();\n   mark_critical_edges ();\n \n@@ -2890,7 +2897,8 @@ merge_blocks_move_successor_nojumps (a, b)\n   barrier = NEXT_INSN (end);\n \n   /* Recognize a jump table following block B.  */\n-  if (GET_CODE (barrier) == CODE_LABEL\n+  if (barrier\n+      && GET_CODE (barrier) == CODE_LABEL\n       && NEXT_INSN (barrier)\n       && GET_CODE (NEXT_INSN (barrier)) == JUMP_INSN\n       && (GET_CODE (PATTERN (NEXT_INSN (barrier))) == ADDR_VEC\n@@ -2901,9 +2909,8 @@ merge_blocks_move_successor_nojumps (a, b)\n     }\n \n   /* There had better have been a barrier there.  Delete it.  */\n-  if (GET_CODE (barrier) != BARRIER)\n-    abort ();\n-  flow_delete_insn (barrier);\n+  if (barrier && GET_CODE (barrier) == BARRIER)\n+    flow_delete_insn (barrier);\n \n   /* Move block and loop notes out of the chain so that we do not\n      disturb their order.\n@@ -2933,9 +2940,10 @@ merge_blocks_move_successor_nojumps (a, b)\n    Return true iff the attempt succeeded.  */\n \n static int\n-merge_blocks (e, b, c)\n+merge_blocks (e, b, c, mode)\n      edge e;\n      basic_block b, c;\n+     int mode;\n {\n   /* If C has a tail recursion label, do not merge.  There is no\n      edge recorded from the call_placeholder back to this label, as\n@@ -2958,9 +2966,11 @@ merge_blocks (e, b, c)\n \n       return 1;\n     }\n-  else\n+  /* Otherwise we will need to move code around.  Do that only if expensive\n+     transformations are allowed.  */\n+  else if (mode & CLEANUP_EXPENSIVE)\n     {\n-      edge tmp_edge;\n+      edge tmp_edge, c_fallthru_edge;\n       int c_has_outgoing_fallthru;\n       int b_has_incoming_fallthru;\n \n@@ -2982,6 +2992,7 @@ merge_blocks (e, b, c)\n \tif (tmp_edge->flags & EDGE_FALLTHRU)\n \t  break;\n       c_has_outgoing_fallthru = (tmp_edge != NULL);\n+      c_fallthru_edge = tmp_edge;\n \n       for (tmp_edge = b->pred; tmp_edge; tmp_edge = tmp_edge->pred_next)\n \tif (tmp_edge->flags & EDGE_FALLTHRU)\n@@ -3002,11 +3013,36 @@ merge_blocks (e, b, c)\n \treturn merge_blocks_move_successor_nojumps (b, c);\n \n       /* Otherwise, we'll need to insert an extra jump, and possibly\n-\t a new block to contain it.  */\n-      /* ??? Not implemented yet.  */\n+\t a new block to contain it.  We can't redirect to EXIT_BLOCK_PTR,\n+\t as we don't have explicit return instructions before epilogues\n+\t are generated, so give up on that case.  */\n+\n+      if (c_fallthru_edge->dest != EXIT_BLOCK_PTR\n+\t  && merge_blocks_move_successor_nojumps (b, c))\n+        {\n+\t  basic_block target = c_fallthru_edge->dest;\n+\t  rtx barrier;\n+\t  basic_block new;\n+\n+\t  /* This is a dirty hack to avoid code duplication.\n+\n+\t     Set edge to point to wrong basic block, so\n+\t     redirect_edge_and_branch_force will do the trick\n+\t     and rewire edge back to the original location.  */\n+\t  redirect_edge_succ (c_fallthru_edge, ENTRY_BLOCK_PTR);\n+\t  new = redirect_edge_and_branch_force (c_fallthru_edge, target);\n+\n+\t  /* We've just created barrier, but other barrier is already present\n+\t     in the stream.  Avoid duplicate.  */\n+\t  barrier = next_nonnote_insn (new ? new->end : b->end);\n+\t  if (GET_CODE (barrier) != BARRIER)\n+\t    abort ();\n+\t  flow_delete_insn (barrier);\n+        }\n \n       return 0;\n     }\n+  return 0;\n }\n \n /* Simplify conditional jump around an jump.  \n@@ -3117,17 +3153,507 @@ try_forward_edges (b)\n   return changed;\n }\n \n+/* Compare the instructions before end of B1 and B2\n+   to find an opportunity for cross jumping.\n+   (This means detecting identical sequences of insns)\n+   Find the longest possible equivalent sequences\n+   and store the first insns of those sequences into *F1 and *F2\n+   and return length of that sequence.\n+\n+   To simplify callers of this function, in the\n+   all instructions were matched, allways store bb->head.  */\n+\n+static int\n+flow_find_cross_jump (mode, bb1, bb2, f1, f2)\n+     int mode;\n+     basic_block bb1, bb2;\n+     rtx *f1, *f2;\n+{\n+  rtx i1 = onlyjump_p (bb1->end) ? PREV_INSN (bb1->end): bb1->end;\n+  rtx i2 = onlyjump_p (bb2->end) ? PREV_INSN (bb2->end): bb2->end;\n+  rtx p1, p2;\n+  int lose = 0;\n+  int ninsns = 0;\n+  rtx last1 = bb1->end, last2 = bb2->end;\n+  rtx afterlast1 = bb1->end, afterlast2 = bb2->end;\n+\n+  /* In case basic block ends by nontrivial jump instruction, count it as\n+     an instruction.  Do not count an unconditional jump, as it will be\n+     removed by basic_block reordering pass in case it is on the common\n+     path.  */\n+  if (bb1->succ->succ_next && bb1->end != i1)\n+    ninsns++;\n+\n+  for (;i1 != bb1->head; i1 = PREV_INSN (i1))\n+    {\n+      /* Ignore notes.  */\n+      if (GET_CODE (i1) == NOTE)\n+\tcontinue;\n+      while ((GET_CODE (i2) == NOTE && i2 != bb2->head))\n+\ti2 = PREV_INSN (i2);\n+\n+      if (GET_CODE (i1) != GET_CODE (i2))\n+\tbreak;\n+\n+      p1 = PATTERN (i1);\n+      p2 = PATTERN (i2);\n+\n+      /* If this is a CALL_INSN, compare register usage information.\n+\t If we don't check this on stack register machines, the two\n+\t CALL_INSNs might be merged leaving reg-stack.c with mismatching\n+\t numbers of stack registers in the same basic block.\n+\t If we don't check this on machines with delay slots, a delay slot may\n+\t be filled that clobbers a parameter expected by the subroutine.\n+\n+\t ??? We take the simple route for now and assume that if they're\n+\t equal, they were constructed identically.  */\n+\n+      if (GET_CODE (i1) == CALL_INSN\n+\t  && ! rtx_equal_p (CALL_INSN_FUNCTION_USAGE (i1),\n+\t\t\t    CALL_INSN_FUNCTION_USAGE (i2)))\n+\tlose = 1;\n+\n+#ifdef STACK_REGS\n+      /* If cross_jump_death_matters is not 0, the insn's mode\n+\t indicates whether or not the insn contains any stack-like\n+\t regs.  */\n+\n+      if (!lose && (mode & CLEANUP_POST_REGSTACK ) && stack_regs_mentioned (i1))\n+\t{\n+\t  /* If register stack conversion has already been done, then\n+\t     death notes must also be compared before it is certain that\n+\t     the two instruction streams match.  */\n+\n+\t  rtx note;\n+\t  HARD_REG_SET i1_regset, i2_regset;\n+\n+\t  CLEAR_HARD_REG_SET (i1_regset);\n+\t  CLEAR_HARD_REG_SET (i2_regset);\n+\n+\t  for (note = REG_NOTES (i1); note; note = XEXP (note, 1))\n+\t    if (REG_NOTE_KIND (note) == REG_DEAD\n+\t\t&& STACK_REG_P (XEXP (note, 0)))\n+\t      SET_HARD_REG_BIT (i1_regset, REGNO (XEXP (note, 0)));\n+\n+\t  for (note = REG_NOTES (i2); note; note = XEXP (note, 1))\n+\t    if (REG_NOTE_KIND (note) == REG_DEAD\n+\t\t&& STACK_REG_P (XEXP (note, 0)))\n+\t      SET_HARD_REG_BIT (i2_regset, REGNO (XEXP (note, 0)));\n+\n+\t  GO_IF_HARD_REG_EQUAL (i1_regset, i2_regset, done);\n+\n+\t  lose = 1;\n+\n+\tdone:\n+\t  ;\n+\t}\n+#endif\n+\n+      if (lose || GET_CODE (p1) != GET_CODE (p2)\n+\t  || ! rtx_renumbered_equal_p (p1, p2))\n+\t{\n+\t  /* The following code helps take care of G++ cleanups.  */\n+\t  rtx equiv1;\n+\t  rtx equiv2;\n+\n+\t  if (!lose && GET_CODE (p1) == GET_CODE (p2)\n+\t      && ((equiv1 = find_reg_note (i1, REG_EQUAL, NULL_RTX)) != 0\n+\t\t  || (equiv1 = find_reg_note (i1, REG_EQUIV, NULL_RTX)) != 0)\n+\t      && ((equiv2 = find_reg_note (i2, REG_EQUAL, NULL_RTX)) != 0\n+\t\t  || (equiv2 = find_reg_note (i2, REG_EQUIV, NULL_RTX)) != 0)\n+\t      /* If the equivalences are not to a constant, they may\n+\t\t reference pseudos that no longer exist, so we can't\n+\t\t use them.  */\n+\t      && CONSTANT_P (XEXP (equiv1, 0))\n+\t      && rtx_equal_p (XEXP (equiv1, 0), XEXP (equiv2, 0)))\n+\t    {\n+\t      rtx s1 = single_set (i1);\n+\t      rtx s2 = single_set (i2);\n+\t      if (s1 != 0 && s2 != 0\n+\t\t  && rtx_renumbered_equal_p (SET_DEST (s1), SET_DEST (s2)))\n+\t\t{\n+\t\t  validate_change (i1, &SET_SRC (s1), XEXP (equiv1, 0), 1);\n+\t\t  validate_change (i2, &SET_SRC (s2), XEXP (equiv2, 0), 1);\n+\t\t  if (! rtx_renumbered_equal_p (p1, p2))\n+\t\t    cancel_changes (0);\n+\t\t  else if (apply_change_group ())\n+\t\t    goto win;\n+\t\t}\n+\t    }\n+\n+\t  /* Insns fail to match; cross jumping is limited to the following\n+\t     insns.  */\n+\n+#ifdef HAVE_cc0\n+\t  /* Don't allow the insn after a compare to be shared by\n+\t     cross-jumping unless the compare is also shared.\n+\t     Here, if either of these non-matching insns is a compare,\n+\t     exclude the following insn from possible cross-jumping.  */\n+\t  if (sets_cc0_p (p1) || sets_cc0_p (p2))\n+\t    last1 = afterlast1, last2 = afterlast2, ninsns--;\n+#endif\n+\t  break;\n+\t}\n+\n+    win:\n+      if (GET_CODE (p1) != USE && GET_CODE (p1) != CLOBBER)\n+\t{\n+\t  /* Ok, this insn is potentially includable in a cross-jump here.  */\n+\t  afterlast1 = last1, afterlast2 = last2;\n+\t  last1 = i1, last2 = i2;\n+          ninsns++;\n+\t}\n+\n+      if (i2 == bb2->end)\n+\tbreak;\n+      i2 = PREV_INSN (i2);\n+    }\n+\n+  /* Skip the notes to reach potential head of basic block.  */\n+  while (last1 != bb1->head && GET_CODE (PREV_INSN (last1)) == NOTE)\n+    last1 = PREV_INSN (last1);\n+  if (last1 != bb1->head && GET_CODE (PREV_INSN (last1)) == CODE_LABEL)\n+    last1 = PREV_INSN (last1);\n+  while (last2 != bb2->head && GET_CODE (PREV_INSN (last2)) == NOTE)\n+    last2 = PREV_INSN (last2);\n+  if (last2 != bb2->head && GET_CODE (PREV_INSN (last2)) == CODE_LABEL)\n+    last2 = PREV_INSN (last2);\n+\n+  *f1 = last1;\n+  *f2 = last2;\n+  return ninsns;\n+}\n+\n+/* Return true iff outgoing edges of BB1 and BB2 match, together with\n+   the branch instruction.  This means that if we commonize the control\n+   flow before end of the basic block, the semantic remains unchanged.  \n+\n+   Assume that at least one outgoing edge is forwarded to the same\n+   location.  */\n+static bool\n+outgoing_edges_match (bb1, bb2)\n+     basic_block bb1;\n+     basic_block bb2;\n+{\n+  /* bb1 has one succesor,  so we are seeing unconditional jump.  */\n+  if (bb1->succ && !bb1->succ->succ_next)\n+    return (bb2->succ && !bb2->succ->succ_next);\n+\n+  /* Match conditional jumps - this may get tricky when fallthru and branch\n+     edges are crossed.  */\n+  if (bb1->succ && bb1->succ->succ_next && !bb1->succ->succ_next->succ_next\n+      && any_condjump_p (bb1->end))\n+    {\n+      edge b1, f1, b2, f2;\n+      bool reverse, match;\n+      rtx set1, set2, cond1, cond2;\n+      enum rtx_code code1, code2;\n+\n+      if (!bb2->succ || !bb2->succ->succ_next\n+\t  || bb1->succ->succ_next->succ_next || !any_condjump_p (bb2->end))\n+\treturn false;\n+      b1 = BRANCH_EDGE (bb1);\n+      b2 = BRANCH_EDGE (bb2);\n+      f1 = FALLTHRU_EDGE (bb1);\n+      f2 = FALLTHRU_EDGE (bb2);\n+\n+      /* Get around possible forwarders on fallthru edges.  Other cases\n+         should be optimized out already.  */\n+      if (forwarder_block_p (f1->dest))\n+\tf1 = f1->dest->succ;\n+      if (forwarder_block_p (f2->dest))\n+\tf2 = f2->dest->succ;\n+\n+      /* To simplify use of this function, return false if there are\n+\t unneeded forwarder blocks.  These will get eliminated later\n+\t during cleanup_cfg.  */\n+      if (forwarder_block_p (f1->dest)\n+\t  || forwarder_block_p (f2->dest)\n+\t  || forwarder_block_p (b1->dest)\n+\t  || forwarder_block_p (b2->dest))\n+\treturn false;\n+\n+      if (f1->dest == f2->dest && b1->dest == b2->dest)\n+\treverse = false;\n+      else if (f1->dest == b2->dest && b1->dest == f2->dest)\n+\treverse = true;\n+      else\n+\treturn false;\n+\n+      set1 = pc_set (bb1->end);\n+      set2 = pc_set (bb2->end);\n+      if ((XEXP (SET_SRC (set1), 1) == pc_rtx)\n+\t  != (XEXP (SET_SRC (set2), 1) == pc_rtx))\n+\treverse = !reverse;\n+\n+      cond1 = XEXP (SET_SRC (set1), 0);\n+      cond2 = XEXP (SET_SRC (set2), 0);\n+      code1 = GET_CODE (cond1);\n+      if (reverse)\n+\tcode2 = reversed_comparison_code (cond2, bb2->end);\n+      else\n+\tcode2 = GET_CODE (cond2);\n+\n+      /* See if we don have (cross) match in the codes and operands.  */\n+      match = ((code1 == code2\n+\t\t&& rtx_renumbered_equal_p (XEXP (cond1, 0), XEXP (cond2, 0))\n+\t\t&& rtx_renumbered_equal_p (XEXP (cond1, 1), XEXP (cond2, 1)))\n+\t       || (code1 == swap_condition (code2)\n+\t\t   && rtx_renumbered_equal_p (XEXP (cond1, 1),\n+\t\t\t\t\t      XEXP (cond2, 0))\n+\t\t   && rtx_renumbered_equal_p (XEXP (cond1, 0),\n+\t\t\t\t\t      XEXP (cond2, 1))));\n+      /* In case of returning true, we will commonize the flow.\n+\t This also means, that both branches will contain only single\n+\t branch prediction algorithm.  To match require resulting branch\n+\t to be still well predictable.  */\n+      if (match && !optimize_size)\n+\t{\n+\t  rtx note1, note2;\n+\t  int prob1, prob2;\n+\t  note1 = find_reg_note (bb1->end, REG_BR_PROB, 0);\n+\t  note2 = find_reg_note (bb2->end, REG_BR_PROB, 0);\n+\t  if (!note1 || !note2)\n+\t    return false;\n+\t  prob1 = INTVAL (XEXP (note1, 0));\n+\t  prob2 = INTVAL (XEXP (note2, 0));\n+\t  if (reverse)\n+\t    prob2 = REG_BR_PROB_BASE - prob2;\n+\n+\t  /* ??? Later we should use basic block frequency to allow merging\n+\t     in the infrequent blocks, but at the moment it is not\n+\t     available when cleanup_cfg is run.  */\n+\t  if (abs (prob1 - prob2) > REG_BR_PROB_BASE / 90)\n+\t    return false;\n+\t}\n+      if (rtl_dump_file && match)\n+\tfprintf (rtl_dump_file, \"Conditionals in bb %i and %i match.\\n\",\n+\t\t bb1->index, bb2->index);\n+      return match;\n+    }\n+  /* ??? We can handle computed jumps too.  This may be important for\n+     inlined functions containing switch statements.  Also jumps w/o\n+     fallthru edges can be handled by simply matching whole insn.  */\n+  return false;\n+}\n+\n+/* Assume that e1 and e2 are the edges from the same basic block.\n+   Attempt to find common code on both paths and forward control flow\n+   from the first path to second if such exist.  */\n+static bool\n+try_crossjump_to_edge (mode, e1, e2)\n+     int mode;\n+     edge e1, e2;\n+{\n+  int nmatch;\n+  basic_block redirect_to;\n+  rtx newpos1, newpos2;\n+  rtx first, last;\n+  edge s;\n+  rtx note;\n+  rtx label;\n+  rtx barrier;\n+\n+  /* Skip forwarder blocks.  This is needed to avoid forced forwarders\n+     after conditional jumps from making us to miss optimization.\n+\n+     We don't need to worry about multiple entry or chained forwarders, as they\n+     will be optimized out.  */\n+  if (e1->src->pred && !e1->src->pred->pred_next\n+      && forwarder_block_p (e1->src))\n+    e1 = e1->src->pred;\n+  if (e2->src->pred && !e2->src->pred->pred_next\n+      && forwarder_block_p (e2->src))\n+    e2 = e2->src->pred;\n+\n+  if (e1->src == ENTRY_BLOCK_PTR || e2->src == ENTRY_BLOCK_PTR)\n+    return false;\n+  if (e1->src == e2->src)\n+    return false;\n+\n+  /* Seeing more than 1 forwarder blocks would confuse us later...  */\n+  if (forwarder_block_p (e1->dest)\n+      && forwarder_block_p (e1->dest->succ->dest))\n+    return false;\n+  if (forwarder_block_p (e2->dest)\n+      && forwarder_block_p (e2->dest->succ->dest))\n+    return false;\n+  /* ... similary as seeing dead code...  */\n+  if (!e1->src->pred || !e2->src->pred)\n+    return false;\n+  /* ...similary non-jump edges.  */\n+  if (e1->flags & EDGE_COMPLEX)\n+    return false;\n+\n+  if (!outgoing_edges_match (e1->src, e2->src))\n+    return false;\n+  nmatch = flow_find_cross_jump (mode, e1->src, e2->src, &newpos1, &newpos2);\n+  if (!nmatch)\n+    return false;\n+\n+  /* Avoid splitting if possible.  */\n+  if (newpos2 == e2->src->head)\n+    redirect_to = e2->src;\n+  else\n+    {\n+      if (rtl_dump_file)\n+\tfprintf (rtl_dump_file, \"Splitting bb %i before %i insns\\n\",\n+\t\t e2->src->index, nmatch);\n+      redirect_to = split_block (e2->src, PREV_INSN (newpos2))->dest;\n+    }\n+\n+  if (rtl_dump_file)\n+    fprintf (rtl_dump_file,\n+\t     \"Cross jumping from bb %i to bb %i. %i insn commoized\\n\",\n+\t     e1->src->index, e2->src->index, nmatch);\n+\n+  redirect_to->count += e1->src->count;\n+  redirect_to->frequency += e1->src->frequency;\n+\n+  /* Recompute the frequencies and counts of outgoing edges.  */\n+  for (s = redirect_to->succ; s; s = s->succ_next)\n+    {\n+      edge s2;\n+      basic_block d = (forwarder_block_p (s->dest) ? s->dest->succ->dest\n+\t\t       : s->dest);\n+      for (s2 = e1->src->succ;; s2 = s2->succ_next)\n+\t{\n+\t  basic_block d2 =\n+\t    (forwarder_block_p (s2->dest) ? s2->dest->succ->dest : s2->dest);\n+\t  if (d == d2)\n+\t    break;\n+\t}\n+      s->count += s2->count;\n+\n+      /* Take care to update possible forwarder blocks.  We took care\n+         that there is no more than one in chain, so we can't run\n+         into infinite loop.  */\n+      if (forwarder_block_p (s->dest))\n+\t{\n+\t  s->dest->succ->count += s2->count;\n+\t  s->dest->count += s2->count;\n+\t  s->dest->frequency += ((s->probability * s->src->frequency)\n+\t\t\t\t / REG_BR_PROB_BASE);\n+\t}\n+      if (forwarder_block_p (s2->dest))\n+\t{\n+\t  s2->dest->succ->count -= s2->count;\n+\t  s2->dest->count -= s2->count;\n+\t  s2->dest->frequency -= ((s->probability * s->src->frequency)\n+\t\t\t\t  / REG_BR_PROB_BASE);\n+\t}\n+      if (!redirect_to->frequency && !e1->src->frequency)\n+\ts->probability = (s->probability + s2->probability) / 2;\n+      else\n+\ts->probability =\n+\t  ((s->probability * redirect_to->frequency +\n+\t    s2->probability * e1->src->frequency)\n+\t   / (redirect_to->frequency + e1->src->frequency));\n+    }\n+\n+  /* FIXME: enable once probabilities are fetched properly at\n+     CFG build.  */\n+#if 0\n+  note = find_reg_note (redirect_to->end, REG_BR_PROB, 0);\n+  if (note)\n+    XEXP (note, 0) = GEN_INT (BRANCH_EDGE (redirect_to)->probability);\n+#endif\n+\n+  /* Skip possible basic block header.  */\n+  first = newpos1;\n+  if (GET_CODE (first) == CODE_LABEL)\n+    first = NEXT_INSN (first);\n+  if (GET_CODE (first) == NOTE)\n+    first = NEXT_INSN (first);\n+\n+  last = e1->src->end;\n+\n+  /* Now emit the jump insn.   */\n+  label = block_label (redirect_to);\n+  e1->src->end = emit_jump_insn_after (gen_jump (label), e1->src->end);\n+  JUMP_LABEL (e1->src->end) = label;\n+  LABEL_NUSES (label)++;\n+  if (basic_block_for_insn)\n+    set_block_for_insn (e1->src->end, e1->src);\n+\n+  flow_delete_insn_chain (first, last);\n+\n+  barrier = next_nonnote_insn (e1->src->end);\n+  if (!barrier || GET_CODE (barrier) != BARRIER)\n+    emit_barrier_after (e1->src->end);\n+\n+  /* Update CFG.  */\n+  while (e1->src->succ->succ_next)\n+    remove_edge (e1->src->succ);\n+  e1->src->succ->flags = 0;\n+  redirect_edge_succ (e1->src->succ, redirect_to);\n+  return true;\n+}\n+\n+/* Attempt to implement cross jumping.  This means moving one or more branches\n+   to BB earlier to BB predecesors commonizing some code.  */\n+static bool\n+try_crossjump_bb (mode, bb)\n+     int mode;\n+     basic_block bb;\n+{\n+  edge e, e2, nexte2, nexte, fallthru;\n+  bool changed = false;\n+\n+  /* In case basic block has single predecesor, do nothing.  */\n+  if (!bb->pred || !bb->pred->pred_next)\n+    return false;\n+\n+  /* It is always cheapest to jump into fallthru edge.  */\n+  for (fallthru = bb->pred; fallthru; fallthru = fallthru->pred_next)\n+    if (fallthru->flags & EDGE_FALLTHRU)\n+      break;\n+\n+  for (e = bb->pred; e; e = nexte)\n+    {\n+      nexte = e->pred_next;\n+      /* First of all prioritize the fallthru edge, as the cheapest.  */\n+      if (e != fallthru && fallthru\n+\t  && try_crossjump_to_edge (mode, e, fallthru))\n+\tchanged = true, nexte = bb->pred;\n+      else\n+\t/* Try match in other incomming edges.\n+\n+\t   Loop only over the earlier edges to avoid,as the later\n+\t   will be examined in the oposite direction.  */\n+\tfor (e2 = bb->pred; e2 != e; e2 = nexte2)\n+\t  {\n+\t    nexte2 = e2->pred_next;\n+\t    if (e2 != fallthru && try_crossjump_to_edge (mode, e, e2))\n+\t      {\n+\t\tchanged = true;\n+\t\tnexte = bb->pred;\n+\n+\t\t/* We may've removed the fallthru edge.  */\n+\t\tfor (fallthru = bb->pred; fallthru;\n+\t\t     fallthru = fallthru->pred_next)\n+\t\t  if (fallthru->flags & EDGE_FALLTHRU)\n+\t\t    break;\n+\t\tbreak;\n+\t      }\n+\t  }\n+    }\n+  return changed;\n+}\n+\n /* Do simple CFG optimizations - basic block merging, simplifying of jump\n    instructions etc.\n \n    Return nonzero in case some optimizations matched.  */\n \n static bool\n-try_optimize_cfg ()\n+try_optimize_cfg (mode)\n+     int mode;\n {\n   int i;\n   bool changed_overall = 0;\n   bool changed;\n+  int iterations = 0;\n \n   /* Attempt to merge blocks as made possible by edge removal.  If a block\n      has only one successor, and the successor has only one predecessor,\n@@ -3136,6 +3662,10 @@ try_optimize_cfg ()\n   do\n     {\n       changed = 0;\n+      iterations++;\n+      if (rtl_dump_file)\n+\tfprintf (rtl_dump_file, \"\\n\\ntry_optimize_cfg iteration %i\\n\\n\",\n+\t\t iterations);\n       for (i = 0; i < n_basic_blocks;)\n \t{\n \t  basic_block c, b = BASIC_BLOCK (i);\n@@ -3175,12 +3705,13 @@ try_optimize_cfg ()\n \t\t && (s->flags & EDGE_EH) == 0\n \t\t && (c = s->dest) != EXIT_BLOCK_PTR\n \t\t && c->pred->pred_next == NULL\n-\t\t /* If the jump insn has side effects, we can't kill the edge.  */\n+\t\t /* If the jump insn has side effects,\n+\t\t    we can't kill the edge.  */\n \t\t && (GET_CODE (b->end) != JUMP_INSN\n-\t\t     || onlyjump_p (b->end)) && merge_blocks (s, b, c))\n+\t\t     || onlyjump_p (b->end)) && merge_blocks (s, b, c, mode))\n \t    changed_here = 1;\n \n-\t  if (try_simplify_condjump (b))\n+\t  if ((mode & CLEANUP_EXPENSIVE) && try_simplify_condjump (b))\n \t    changed_here = 1;\n \n \t  /* In the case basic blocks has single outgoing edge, but over by the\n@@ -3201,21 +3732,25 @@ try_optimize_cfg ()\n \t  if (try_forward_edges (b))\n \t    changed_here = 1;\n \n+\t  if ((mode & CLEANUP_CROSSJUMP) && try_crossjump_bb (mode, b))\n+\t    changed_here = 1;\n+\n \t  /* Don't get confused by the index shift caused by deleting\n \t     blocks.  */\n \t  if (!changed_here)\n \t    i = b->index + 1;\n \t  else\n \t    changed = 1;\n \t}\n+      if ((mode & CLEANUP_CROSSJUMP) && try_crossjump_bb (mode, EXIT_BLOCK_PTR))\n+\tchanged = 1;\n+#ifdef ENABLE_CHECKING\n+      if (changed)\n+\tverify_flow_info ();\n+#endif\n       changed_overall |= changed;\n-      changed = 0;\n     }\n   while (changed);\n-#ifdef ENABLE_CHECKING\n-  if (changed)\n-    verify_flow_info ();\n-#endif\n   return changed_overall;\n }\n \n@@ -7401,6 +7936,19 @@ verify_flow_info ()\n       e = bb->succ;\n       while (e)\n \t{\n+\t  if ((e->flags & EDGE_FALLTHRU)\n+\t      && e->src != ENTRY_BLOCK_PTR\n+\t      && e->dest != EXIT_BLOCK_PTR\n+\t      && (e->src->index + 1 != e->dest->index\n+\t\t  || !can_fallthru (e->src, e->dest)))\n+\t    {\n+\t      fprintf (stderr,\n+\t\t       \"verify_flow_info: Incorrect fallthru edge %i->%i\\n\",\n+\t\t       e->src->index, e->dest->index);\n+\t      fflush (stderr);\n+\t      err = 1;\n+\t    }\n+\t    \n \t  if (e->src != bb)\n \t    {\n \t      fprintf (stderr,"}, {"sha": "010c1c7319d9a2e7b7b22e059c643cd241d70206", "filename": "gcc/jump.c", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Fjump.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Fjump.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fjump.c?ref=46fac66482f1cf5cc61f7fef9de8b7593c8357e7", "patch": "@@ -3669,6 +3669,11 @@ rtx_renumbered_equal_p (x, y)\n \t    return 0;\n \t  break;\n \n+\tcase 't':\n+\t  if (XTREE (x, i) != XTREE (y, i))\n+\t    return 0;\n+\t  break;\n+\n \tcase 's':\n \t  if (strcmp (XSTR (x, i), XSTR (y, i)))\n \t    return 0;"}, {"sha": "071d24097c4446febc140f01b20f957291f0059d", "filename": "gcc/output.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Foutput.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Foutput.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Foutput.h?ref=46fac66482f1cf5cc61f7fef9de8b7593c8357e7", "patch": "@@ -137,7 +137,7 @@ extern void allocate_for_life_analysis\tPARAMS ((void));\n extern int regno_uninitialized\t\tPARAMS ((int));\n extern int regno_clobbered_at_setjmp\tPARAMS ((int));\n extern void find_basic_blocks\t\tPARAMS ((rtx, int, FILE *));\n-extern void cleanup_cfg\t\t\tPARAMS ((void));\n+extern void cleanup_cfg\t\t\tPARAMS ((int));\n extern void check_function_return_warnings PARAMS ((void));\n #endif\n "}, {"sha": "af5453db5865315adc8be65201efefef3bf5d22d", "filename": "gcc/reg-stack.c", "status": "modified", "additions": 1, "deletions": 4, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Freg-stack.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Freg-stack.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freg-stack.c?ref=46fac66482f1cf5cc61f7fef9de8b7593c8357e7", "patch": "@@ -476,10 +476,7 @@ reg_to_stack (first, file)\n \t\t    \"stack_regs_mentioned cache\");\n \n   if (convert_regs (file) && optimize)\n-    {\n-      jump_optimize (first, JUMP_CROSS_JUMP_DEATH_MATTERS,\n-\t\t     !JUMP_NOOP_MOVES, !JUMP_AFTER_REGSCAN);\n-    }\n+    cleanup_cfg (CLEANUP_EXPENSIVE | CLEANUP_CROSSJUMP | CLEANUP_POST_REGSTACK);\n \n   /* Clean up.  */\n   VARRAY_FREE (stack_regs_mentioned_data);"}, {"sha": "62184e84a5b0da881d561b60ce3a69ff11fac6da", "filename": "gcc/sibcall.c", "status": "modified", "additions": 1, "deletions": 5, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Fsibcall.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Fsibcall.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fsibcall.c?ref=46fac66482f1cf5cc61f7fef9de8b7593c8357e7", "patch": "@@ -565,15 +565,11 @@ optimize_sibling_and_tail_recursive_calls ()\n      ahead and find all the EH labels.  */\n   find_exception_handler_labels ();\n \n-  /* Run a jump optimization pass to clean up the CFG.  We primarily want\n-     this to thread jumps so that it is obvious which blocks jump to the\n-     epilouge.  */\n   jump_optimize_minimal (insns);\n-\n   /* We need cfg information to determine which blocks are succeeded\n      only by the epilogue.  */\n   find_basic_blocks (insns, max_reg_num (), 0);\n-  cleanup_cfg ();\n+  cleanup_cfg (0);\n \n   /* If there are no basic blocks, then there is nothing to do.  */\n   if (n_basic_blocks == 0)"}, {"sha": "3bef83a30ecacc9af198631b7f5aaddf5d6408a1", "filename": "gcc/toplev.c", "status": "modified", "additions": 8, "deletions": 8, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Ftoplev.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/46fac66482f1cf5cc61f7fef9de8b7593c8357e7/gcc%2Ftoplev.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftoplev.c?ref=46fac66482f1cf5cc61f7fef9de8b7593c8357e7", "patch": "@@ -2963,7 +2963,7 @@ rest_of_compilation (decl)\n       open_dump_file (DFI_ssa, decl);\n \n       find_basic_blocks (insns, max_reg_num (), rtl_dump_file);\n-      cleanup_cfg ();\n+      cleanup_cfg (CLEANUP_EXPENSIVE);\n       convert_to_ssa ();\n \n       close_dump_file (DFI_ssa, print_rtl_with_bb, insns);\n@@ -3028,7 +3028,7 @@ rest_of_compilation (decl)\n   if (optimize > 0)\n     {\n       find_basic_blocks (insns, max_reg_num (), rtl_dump_file);\n-      cleanup_cfg ();\n+      cleanup_cfg (CLEANUP_EXPENSIVE);\n \n       /* ??? Run if-conversion before delete_null_pointer_checks,\n          since the later does not preserve the CFG.  This should\n@@ -3098,7 +3098,7 @@ rest_of_compilation (decl)\n \t  timevar_push (TV_JUMP);\n \t  find_basic_blocks (insns, max_reg_num (), rtl_dump_file);\n \n-\t  cleanup_cfg ();\n+\t  cleanup_cfg (CLEANUP_EXPENSIVE);\n \n \t  delete_null_pointer_checks (insns);\n \t  timevar_pop (TV_JUMP);\n@@ -3132,7 +3132,7 @@ rest_of_compilation (decl)\n       open_dump_file (DFI_gcse, decl);\n \n       find_basic_blocks (insns, max_reg_num (), rtl_dump_file);\n-      cleanup_cfg ();\n+      cleanup_cfg (CLEANUP_EXPENSIVE);\n       tem = gcse_main (insns, rtl_dump_file);\n \n       save_csb = flag_cse_skip_blocks;\n@@ -3236,7 +3236,7 @@ rest_of_compilation (decl)\n \t  timevar_push (TV_IFCVT);\n \n \t  find_basic_blocks (insns, max_reg_num (), rtl_dump_file);\n-\t  cleanup_cfg ();\n+\t  cleanup_cfg (CLEANUP_EXPENSIVE);\n \t  if_convert (0);\n \n \t  timevar_pop(TV_IFCVT);\n@@ -3282,7 +3282,7 @@ rest_of_compilation (decl)\n   open_dump_file (DFI_cfg, decl);\n \n   find_basic_blocks (insns, max_reg_num (), rtl_dump_file);\n-  cleanup_cfg ();\n+  cleanup_cfg (optimize ? CLEANUP_EXPENSIVE : 0);\n   check_function_return_warnings ();\n \n   /* It may make more sense to mark constant functions after dead code is\n@@ -3365,7 +3365,7 @@ rest_of_compilation (decl)\n \n \t  timevar_push (TV_FLOW);\n \t  find_basic_blocks (insns, max_reg_num (), rtl_dump_file);\n-\t  cleanup_cfg ();\n+\t  cleanup_cfg (CLEANUP_EXPENSIVE);\n \n \t  /* Blimey.  We've got to have the CFG up to date for the call to\n \t     if_convert below.  However, the random deletion of blocks\n@@ -3576,7 +3576,7 @@ rest_of_compilation (decl)\n \n   if (optimize)\n     {\n-      cleanup_cfg ();\n+      cleanup_cfg (CLEANUP_EXPENSIVE | CLEANUP_CROSSJUMP);\n       life_analysis (insns, rtl_dump_file, PROP_FINAL);\n \n       /* This is kind of a heuristic.  We need to run combine_stack_adjustments"}]}