{"sha": "eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZWFiN2FhZWRjNzVhM2ZjMTgyYWQzNzBmZTQ5ZjJkMmI0NWZjYTliYw==", "commit": {"author": {"name": "Kito Cheng", "email": "kito.cheng@gmail.com", "date": "2018-03-04T16:43:09Z"}, "committer": {"name": "Chung-Ju Wu", "email": "jasonwucj@gcc.gnu.org", "date": "2018-03-04T16:43:09Z"}, "message": "[NDS32] Rename nds32_expand_movmemqi to nds32_expand_movmemsi and rewrite its implementation.\n\ngcc/\n\t*config/nds32/nds32-memory-manipulation.c\n\t(nds32_emit_load_store): New.\n\t(nds32_emit_post_inc_load_store): New.\n\t(nds32_emit_mem_move): New.\n\t(nds32_emit_mem_move_block): New.\n\t(nds32_expand_movmemsi_loop_unknown_size): New.\n\t(nds32_expand_movmemsi_loop_known_size): New.\n\t(nds32_expand_movmemsi_loop): New.\n\t(nds32_expand_movmemsi_unroll): New.\n\t(nds32_expand_movmemqi): Rename ...\n\t(nds32_expand_movmemsi): ... to this.\n\t*config/nds32/nds32-multiple.md (movmemqi): Rename ...\n\t(movmemsi): ... to this.\n\t*config/nds32/nds32-protos.h (nds32_expand_movmemqi): Rename ...\n\t(nds32_expand_movmemsi): ... to this.\n\nCo-Authored-By: Chung-Ju Wu <jasonwucj@gmail.com>\n\nFrom-SVN: r258235", "tree": {"sha": "39a3759c5db7359299c3f2330dc7aaaf7067d60c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/39a3759c5db7359299c3f2330dc7aaaf7067d60c"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc", "html_url": "https://github.com/Rust-GCC/gccrs/commit/eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc/comments", "author": {"login": "kito-cheng", "id": 2723185, "node_id": "MDQ6VXNlcjI3MjMxODU=", "avatar_url": "https://avatars.githubusercontent.com/u/2723185?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kito-cheng", "html_url": "https://github.com/kito-cheng", "followers_url": "https://api.github.com/users/kito-cheng/followers", "following_url": "https://api.github.com/users/kito-cheng/following{/other_user}", "gists_url": "https://api.github.com/users/kito-cheng/gists{/gist_id}", "starred_url": "https://api.github.com/users/kito-cheng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kito-cheng/subscriptions", "organizations_url": "https://api.github.com/users/kito-cheng/orgs", "repos_url": "https://api.github.com/users/kito-cheng/repos", "events_url": "https://api.github.com/users/kito-cheng/events{/privacy}", "received_events_url": "https://api.github.com/users/kito-cheng/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "32a6f4f4886bdd41db8c2b342316da42e9c5f392", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/32a6f4f4886bdd41db8c2b342316da42e9c5f392", "html_url": "https://github.com/Rust-GCC/gccrs/commit/32a6f4f4886bdd41db8c2b342316da42e9c5f392"}], "stats": {"total": 474, "additions": 418, "deletions": 56}, "files": [{"sha": "9cc5c6b376db08ba408b18e03946417bb7f9a87e", "filename": "gcc/ChangeLog", "status": "modified", "additions": 19, "deletions": 0, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc", "patch": "@@ -1,3 +1,22 @@\n+2018-03-04  Kito Cheng  <kito.cheng@gmail.com>\n+\t    Chung-Ju Wu  <jasonwucj@gmail.com>\n+\n+\t*config/nds32/nds32-memory-manipulation.c\n+\t(nds32_emit_load_store): New.\n+\t(nds32_emit_post_inc_load_store): New.\n+\t(nds32_emit_mem_move): New.\n+\t(nds32_emit_mem_move_block): New.\n+\t(nds32_expand_movmemsi_loop_unknown_size): New.\n+\t(nds32_expand_movmemsi_loop_known_size): New.\n+\t(nds32_expand_movmemsi_loop): New.\n+\t(nds32_expand_movmemsi_unroll): New.\n+\t(nds32_expand_movmemqi): Rename ...\n+\t(nds32_expand_movmemsi): ... to this.\n+\t*config/nds32/nds32-multiple.md (movmemqi): Rename ...\n+\t(movmemsi): ... to this.\n+\t*config/nds32/nds32-protos.h (nds32_expand_movmemqi): Rename ...\n+\t(nds32_expand_movmemsi): ... to this.\n+\n 2018-03-04  Kito Cheng  <kito.cheng@gmail.com>\n \t    Monk Chiang  <sh.chiang04@gmail.com>\n \t    Chung-Ju Wu  <jasonwucj@gmail.com>"}, {"sha": "e8b9be459c46b4db838380a1a4bb76775666f161", "filename": "gcc/config/nds32/nds32-memory-manipulation.c", "status": "modified", "additions": 394, "deletions": 52, "changes": 446, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc/gcc%2Fconfig%2Fnds32%2Fnds32-memory-manipulation.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc/gcc%2Fconfig%2Fnds32%2Fnds32-memory-manipulation.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fnds32%2Fnds32-memory-manipulation.c?ref=eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc", "patch": "@@ -32,9 +32,403 @@\n #include \"memmodel.h\"\n #include \"emit-rtl.h\"\n #include \"explow.h\"\n+#include \"tree.h\"\n+#include \"expr.h\"\n+#include \"optabs.h\"\n+#include \"nds32-protos.h\"\n \n /* ------------------------------------------------------------------------ */\n \n+/* Auxiliary static function definitions.  */\n+\n+static void\n+nds32_emit_load_store (rtx reg, rtx mem,\n+\t\t       enum machine_mode mode,\n+\t\t       int offset, bool load_p)\n+{\n+  rtx new_mem;\n+  new_mem = adjust_address (mem, mode, offset);\n+  if (load_p)\n+    emit_move_insn (reg, new_mem);\n+  else\n+    emit_move_insn (new_mem, reg);\n+}\n+\n+static void\n+nds32_emit_post_inc_load_store (rtx reg, rtx base_reg,\n+\t\t\t\tenum machine_mode mode,\n+\t\t\t\tbool load_p)\n+{\n+  gcc_assert (GET_MODE (reg) == mode);\n+  gcc_assert (GET_MODE (base_reg) == Pmode);\n+\n+  /* Do not gen (set (reg) (mem (post_inc (reg)))) directly here since it may\n+     not recognize by gcc, so let gcc combine it at auto_inc_dec pass.  */\n+  if (load_p)\n+    emit_move_insn (reg,\n+\t\t    gen_rtx_MEM (mode,\n+\t\t\t\t base_reg));\n+  else\n+    emit_move_insn (gen_rtx_MEM (mode,\n+\t\t\t\t base_reg),\n+\t\t    reg);\n+\n+  emit_move_insn (base_reg,\n+\t\t  plus_constant(Pmode, base_reg, GET_MODE_SIZE (mode)));\n+}\n+\n+static void\n+nds32_emit_mem_move (rtx src, rtx dst,\n+\t\t     enum machine_mode mode,\n+\t\t     int addr_offset)\n+{\n+  gcc_assert (MEM_P (src) && MEM_P (dst));\n+  rtx tmp_reg = gen_reg_rtx (mode);\n+  nds32_emit_load_store (tmp_reg, src, mode,\n+\t\t\t addr_offset, /* load_p */ true);\n+  nds32_emit_load_store (tmp_reg, dst, mode,\n+\t\t\t addr_offset, /* load_p */ false);\n+}\n+\n+static void\n+nds32_emit_mem_move_block (int base_regno, int count,\n+\t\t\t   rtx *dst_base_reg, rtx *dst_mem,\n+\t\t\t   rtx *src_base_reg, rtx *src_mem,\n+\t\t\t   bool update_base_reg_p)\n+{\n+  rtx new_base_reg;\n+\n+  emit_insn (nds32_expand_load_multiple (base_regno, count,\n+\t\t\t\t\t *src_base_reg, *src_mem,\n+\t\t\t\t\t update_base_reg_p, &new_base_reg));\n+  if (update_base_reg_p)\n+    {\n+      *src_base_reg = new_base_reg;\n+      *src_mem = gen_rtx_MEM (SImode, *src_base_reg);\n+    }\n+\n+  emit_insn (nds32_expand_store_multiple (base_regno, count,\n+\t\t\t\t\t  *dst_base_reg, *dst_mem,\n+\t\t\t\t\t  update_base_reg_p, &new_base_reg));\n+\n+  if (update_base_reg_p)\n+    {\n+      *dst_base_reg = new_base_reg;\n+      *dst_mem = gen_rtx_MEM (SImode, *dst_base_reg);\n+    }\n+}\n+\n+/* ------------------------------------------------------------------------ */\n+\n+/* Auxiliary function for expand movmem pattern.  */\n+\n+static bool\n+nds32_expand_movmemsi_loop_unknown_size (rtx dstmem, rtx srcmem,\n+\t\t\t\t\t rtx size,\n+\t\t\t\t\t rtx alignment)\n+{\n+  /* Emit loop version of movmem.\n+\n+       andi    $size_least_3_bit, $size, #~7\n+       add     $dst_end, $dst, $size\n+       move    $dst_itr, $dst\n+       move    $src_itr, $src\n+       beqz    $size_least_3_bit, .Lbyte_mode_entry ! Not large enough.\n+       add     $double_word_end, $dst, $size_least_3_bit\n+\n+     .Ldouble_word_mode_loop:\n+       lmw.bim $tmp-begin, [$src_itr], $tmp-end, #0 ! $src_itr' = $src_itr\n+       smw.bim $tmp-begin, [$dst_itr], $tmp-end, #0 ! $dst_itr' = $dst_itr\n+       ! move will delete after register allocation\n+       move    $src_itr, $src_itr'\n+       move    $dst_itr, $dst_itr'\n+       ! Not readch upper bound. Loop.\n+       bne     $double_word_end, $dst_itr, .Ldouble_word_mode_loop\n+\n+     .Lbyte_mode_entry:\n+       beq     $dst_itr, $dst_end, .Lend_label\n+     .Lbyte_mode_loop:\n+       lbi.bi  $tmp, [$src_itr], #1\n+       sbi.bi  $tmp, [$dst_itr], #1\n+       ! Not readch upper bound. Loop.\n+       bne     $dst_itr, $dst_end, .Lbyte_mode_loop\n+     .Lend_label:\n+  */\n+  rtx dst_base_reg, src_base_reg;\n+  rtx dst_itr, src_itr;\n+  rtx dstmem_m, srcmem_m, dst_itr_m, src_itr_m;\n+  rtx dst_end;\n+  rtx size_least_3_bit;\n+  rtx double_word_end;\n+  rtx double_word_mode_loop, byte_mode_entry, byte_mode_loop, end_label;\n+  rtx tmp;\n+  rtx mask_least_3_bit;\n+  int start_regno;\n+  bool align_to_4_bytes = (INTVAL (alignment) & 3) == 0;\n+\n+  if (TARGET_ISA_V3M && !align_to_4_bytes)\n+    return 0;\n+\n+  if (TARGET_REDUCED_REGS)\n+    start_regno = 2;\n+  else\n+    start_regno = 16;\n+\n+  dst_itr = gen_reg_rtx (Pmode);\n+  src_itr = gen_reg_rtx (Pmode);\n+  dst_end = gen_reg_rtx (Pmode);\n+  tmp = gen_reg_rtx (QImode);\n+  mask_least_3_bit = GEN_INT (~7);\n+\n+  double_word_mode_loop = gen_label_rtx ();\n+  byte_mode_entry = gen_label_rtx ();\n+  byte_mode_loop = gen_label_rtx ();\n+  end_label = gen_label_rtx ();\n+\n+  dst_base_reg = copy_to_mode_reg (Pmode, XEXP (dstmem, 0));\n+  src_base_reg = copy_to_mode_reg (Pmode, XEXP (srcmem, 0));\n+  /* andi   $size_least_3_bit, $size, #~7 */\n+  size_least_3_bit = expand_binop (SImode, and_optab, size, mask_least_3_bit,\n+\t\t\t\t   NULL_RTX, 0, OPTAB_WIDEN);\n+  /* add     $dst_end, $dst, $size */\n+  dst_end = expand_binop (Pmode, add_optab, dst_base_reg, size,\n+\t\t\t  NULL_RTX, 0, OPTAB_WIDEN);\n+\n+  /* move    $dst_itr, $dst\n+     move    $src_itr, $src */\n+  emit_move_insn (dst_itr, dst_base_reg);\n+  emit_move_insn (src_itr, src_base_reg);\n+\n+  /* beqz    $size_least_3_bit, .Lbyte_mode_entry ! Not large enough. */\n+  emit_cmp_and_jump_insns (size_least_3_bit, const0_rtx, EQ, NULL,\n+\t\t\t   SImode, 1, byte_mode_entry);\n+  /* add     $double_word_end, $dst, $size_least_3_bit */\n+  double_word_end = expand_binop (Pmode, add_optab,\n+\t\t\t\t  dst_base_reg, size_least_3_bit,\n+\t\t\t\t  NULL_RTX, 0, OPTAB_WIDEN);\n+\n+  /* .Ldouble_word_mode_loop: */\n+  emit_label (double_word_mode_loop);\n+  /* lmw.bim $tmp-begin, [$src_itr], $tmp-end, #0 ! $src_itr' = $src_itr\n+     smw.bim $tmp-begin, [$dst_itr], $tmp-end, #0 ! $dst_itr' = $dst_itr */\n+  src_itr_m = src_itr;\n+  dst_itr_m = dst_itr;\n+  srcmem_m = srcmem;\n+  dstmem_m = dstmem;\n+  nds32_emit_mem_move_block (start_regno, 2,\n+\t\t\t     &dst_itr_m, &dstmem_m,\n+\t\t\t     &src_itr_m, &srcmem_m,\n+\t\t\t     true);\n+  /* move    $src_itr, $src_itr'\n+     move    $dst_itr, $dst_itr' */\n+  emit_move_insn (dst_itr, dst_itr_m);\n+  emit_move_insn (src_itr, src_itr_m);\n+\n+  /* ! Not readch upper bound. Loop.\n+     bne     $double_word_end, $dst_itr, .Ldouble_word_mode_loop */\n+  emit_cmp_and_jump_insns (double_word_end, dst_itr, NE, NULL,\n+\t\t\t   Pmode, 1, double_word_mode_loop);\n+  /* .Lbyte_mode_entry: */\n+  emit_label (byte_mode_entry);\n+\n+  /* beq     $dst_itr, $dst_end, .Lend_label */\n+  emit_cmp_and_jump_insns (dst_itr, dst_end, EQ, NULL,\n+\t\t\t   Pmode, 1, end_label);\n+  /* .Lbyte_mode_loop: */\n+  emit_label (byte_mode_loop);\n+\n+  /* lbi.bi  $tmp, [$src_itr], #1 */\n+  nds32_emit_post_inc_load_store (tmp, src_itr, QImode, true);\n+\n+  /* sbi.bi  $tmp, [$dst_itr], #1 */\n+  nds32_emit_post_inc_load_store (tmp, dst_itr, QImode, false);\n+  /* ! Not readch upper bound. Loop.\n+     bne     $dst_itr, $dst_end, .Lbyte_mode_loop */\n+  emit_cmp_and_jump_insns (dst_itr, dst_end, NE, NULL,\n+\t\t\t   SImode, 1, byte_mode_loop);\n+\n+  /* .Lend_label: */\n+  emit_label (end_label);\n+\n+  return true;\n+}\n+\n+static bool\n+nds32_expand_movmemsi_loop_known_size (rtx dstmem, rtx srcmem,\n+\t\t\t\t       rtx size, rtx alignment)\n+{\n+  return nds32_expand_movmemsi_loop_unknown_size (dstmem, srcmem,\n+\t\t\t\t\t\t  size, alignment);\n+}\n+\n+static bool\n+nds32_expand_movmemsi_loop (rtx dstmem, rtx srcmem,\n+\t\t\t    rtx size, rtx alignment)\n+{\n+  if (CONST_INT_P (size))\n+    return nds32_expand_movmemsi_loop_known_size (dstmem, srcmem,\n+\t\t\t\t\t\t  size, alignment);\n+  else\n+    return nds32_expand_movmemsi_loop_unknown_size (dstmem, srcmem,\n+\t\t\t\t\t\t    size, alignment);\n+}\n+\n+static bool\n+nds32_expand_movmemsi_unroll (rtx dstmem, rtx srcmem,\n+\t\t\t      rtx total_bytes, rtx alignment)\n+{\n+  rtx dst_base_reg, src_base_reg;\n+  rtx tmp_reg;\n+  int maximum_bytes;\n+  int maximum_bytes_per_inst;\n+  int maximum_regs;\n+  int start_regno;\n+  int i, inst_num;\n+  HOST_WIDE_INT remain_bytes, remain_words;\n+  bool align_to_4_bytes = (INTVAL (alignment) & 3) == 0;\n+  bool align_to_2_bytes = (INTVAL (alignment) & 1) == 0;\n+\n+  /* Because reduced-set regsiters has few registers\n+     (r0~r5, r6~10, r15, r28~r31, where 'r15' and 'r28~r31'\n+      cannot be used for register allocation),\n+     using 8 registers (32 bytes) for moving memory block\n+     may easily consume all of them.\n+     It makes register allocation/spilling hard to work.\n+     So we only allow maximum=4 registers (16 bytes) for\n+     moving memory block under reduced-set registers.  */\n+  if (TARGET_REDUCED_REGS)\n+    {\n+      maximum_regs  = 4;\n+      maximum_bytes = 64;\n+      start_regno   = 2;\n+    }\n+  else\n+    {\n+      /* $r25 is $tp so we use up to 8 registers.  */\n+      maximum_regs  = 8;\n+      maximum_bytes = 160;\n+      start_regno   = 16;\n+    }\n+  maximum_bytes_per_inst = maximum_regs * UNITS_PER_WORD;\n+\n+  /* 1. Total_bytes is integer for sure.\n+     2. Alignment is integer for sure.\n+     3. Maximum 4 or 10 registers and up to 4 instructions,\n+\t4 * 4 * 4 = 64 bytes, 8 * 4 * 10 = 160 bytes.\n+     4. The dstmem cannot be volatile memory access.\n+     5. The srcmem cannot be volatile memory access.\n+     6. Known shared alignment not align to 4 byte in v3m since lmw/smw *NOT*\n+\tsupport unalign access with v3m configure.  */\n+  if (GET_CODE (total_bytes) != CONST_INT\n+      || GET_CODE (alignment) != CONST_INT\n+      || INTVAL (total_bytes) > maximum_bytes\n+      || MEM_VOLATILE_P (dstmem)\n+      || MEM_VOLATILE_P (srcmem)\n+      || (TARGET_ISA_V3M && !align_to_4_bytes))\n+    return false;\n+\n+  dst_base_reg = copy_to_mode_reg (SImode, XEXP (dstmem, 0));\n+  src_base_reg = copy_to_mode_reg (SImode, XEXP (srcmem, 0));\n+  remain_bytes = INTVAL (total_bytes);\n+\n+  /* Do not update base address for last lmw/smw pair.  */\n+  inst_num = ((INTVAL (total_bytes) + (maximum_bytes_per_inst - 1))\n+\t      / maximum_bytes_per_inst) - 1;\n+\n+  for (i = 0; i < inst_num; i++)\n+    {\n+      nds32_emit_mem_move_block (start_regno, maximum_regs,\n+\t\t\t\t &dst_base_reg, &dstmem,\n+\t\t\t\t &src_base_reg, &srcmem,\n+\t\t\t\t true);\n+    }\n+  remain_bytes -= maximum_bytes_per_inst * inst_num;\n+\n+  remain_words = remain_bytes / UNITS_PER_WORD;\n+  remain_bytes = remain_bytes - (remain_words * UNITS_PER_WORD);\n+\n+  if (remain_words != 0)\n+    {\n+      if (remain_bytes != 0)\n+\tnds32_emit_mem_move_block (start_regno, remain_words,\n+\t\t\t\t   &dst_base_reg, &dstmem,\n+\t\t\t\t   &src_base_reg, &srcmem,\n+\t\t\t\t   true);\n+      else\n+\t{\n+\t  /* Do not update address if no further byte to move.  */\n+\t  if (remain_words == 1)\n+\t   {\n+\t      /* emit move instruction if align to 4 byte and only 1\n+\t\t word to move.  */\n+\t      if (align_to_4_bytes)\n+\t\tnds32_emit_mem_move (srcmem, dstmem, SImode, 0);\n+\t      else\n+\t\t{\n+\t\t  tmp_reg = gen_reg_rtx (SImode);\n+\t\t  emit_insn (\n+\t\t    gen_unaligned_load_w (tmp_reg,\n+\t\t\t\t\t  gen_rtx_MEM (SImode, src_base_reg)));\n+\t\t  emit_insn (\n+\t\t    gen_unaligned_store_w (gen_rtx_MEM (SImode, dst_base_reg),\n+\t\t\t\t\t   tmp_reg));\n+\t\t}\n+\t    }\n+\t  else\n+\t    nds32_emit_mem_move_block (start_regno, remain_words,\n+\t\t\t\t       &dst_base_reg, &dstmem,\n+\t\t\t\t       &src_base_reg, &srcmem,\n+\t\t\t\t       false);\n+\t}\n+    }\n+\n+  switch (remain_bytes)\n+    {\n+    case 3:\n+    case 2:\n+      {\n+\tif (align_to_2_bytes)\n+\t  nds32_emit_mem_move (srcmem, dstmem, HImode, 0);\n+\telse\n+\t  {\n+\t    nds32_emit_mem_move (srcmem, dstmem, QImode, 0);\n+\t    nds32_emit_mem_move (srcmem, dstmem, QImode, 1);\n+\t  }\n+\n+\tif (remain_bytes == 3)\n+\t  nds32_emit_mem_move (srcmem, dstmem, QImode, 2);\n+\tbreak;\n+      }\n+    case 1:\n+      nds32_emit_mem_move (srcmem, dstmem, QImode, 0);\n+      break;\n+    case 0:\n+      break;\n+    default:\n+      gcc_unreachable ();\n+    }\n+\n+  /* Successfully create patterns, return true.  */\n+  return true;\n+}\n+\n+/* Function to move block memory content by\n+   using load_multiple and store_multiple.\n+   This is auxiliary extern function to help create rtx template.\n+   Check nds32-multiple.md file for the patterns.  */\n+bool\n+nds32_expand_movmemsi (rtx dstmem, rtx srcmem, rtx total_bytes, rtx alignment)\n+{\n+  if (nds32_expand_movmemsi_unroll (dstmem, srcmem, total_bytes, alignment))\n+    return true;\n+\n+  if (!optimize_size && optimize > 2)\n+    return nds32_expand_movmemsi_loop (dstmem, srcmem, total_bytes, alignment);\n+\n+  return false;\n+}\n+\n+\n /* Functions to expand load_multiple and store_multiple.\n    They are auxiliary extern functions to help create rtx template.\n    Check nds32-multiple.md file for the patterns.  */\n@@ -161,56 +555,4 @@ nds32_expand_store_multiple (int base_regno, int count,\n   return result;\n }\n \n-/* Function to move block memory content by\n-   using load_multiple and store_multiple.\n-   This is auxiliary extern function to help create rtx template.\n-   Check nds32-multiple.md file for the patterns.  */\n-int\n-nds32_expand_movmemqi (rtx dstmem, rtx srcmem, rtx total_bytes, rtx alignment)\n-{\n-  HOST_WIDE_INT in_words, out_words;\n-  rtx dst_base_reg, src_base_reg;\n-  int maximum_bytes;\n-\n-  /* Because reduced-set regsiters has few registers\n-     (r0~r5, r6~10, r15, r28~r31, where 'r15' and 'r28~r31'\n-      cannot be used for register allocation),\n-     using 8 registers (32 bytes) for moving memory block\n-     may easily consume all of them.\n-     It makes register allocation/spilling hard to work.\n-     So we only allow maximum=4 registers (16 bytes) for\n-     moving memory block under reduced-set registers.  */\n-  if (TARGET_REDUCED_REGS)\n-    maximum_bytes = 16;\n-  else\n-    maximum_bytes = 32;\n-\n-  /* 1. Total_bytes is integer for sure.\n-     2. Alignment is integer for sure.\n-     3. Maximum 4 or 8 registers, 4 * 4 = 16 bytes, 8 * 4 = 32 bytes.\n-     4. Requires (n * 4) block size.\n-     5. Requires 4-byte alignment.  */\n-  if (GET_CODE (total_bytes) != CONST_INT\n-      || GET_CODE (alignment) != CONST_INT\n-      || INTVAL (total_bytes) > maximum_bytes\n-      || INTVAL (total_bytes) & 3\n-      || INTVAL (alignment) & 3)\n-    return 0;\n-\n-  dst_base_reg = copy_to_mode_reg (SImode, XEXP (dstmem, 0));\n-  src_base_reg = copy_to_mode_reg (SImode, XEXP (srcmem, 0));\n-\n-  out_words = in_words = INTVAL (total_bytes) / UNITS_PER_WORD;\n-\n-  emit_insn (\n-    nds32_expand_load_multiple (0, in_words, src_base_reg,\n-\t\t\t\tsrcmem, false, NULL));\n-  emit_insn (\n-    nds32_expand_store_multiple (0, out_words, dst_base_reg,\n-\t\t\t\t dstmem, false, NULL));\n-\n-  /* Successfully create patterns, return 1.  */\n-  return 1;\n-}\n-\n /* ------------------------------------------------------------------------ */"}, {"sha": "f266533dd868ad7f10c23df46b32d13049d0726b", "filename": "gcc/config/nds32/nds32-multiple.md", "status": "modified", "additions": 4, "deletions": 3, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc/gcc%2Fconfig%2Fnds32%2Fnds32-multiple.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc/gcc%2Fconfig%2Fnds32%2Fnds32-multiple.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fnds32%2Fnds32-multiple.md?ref=eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc", "patch": "@@ -3731,14 +3731,15 @@\n ;; operands[2] is the number of bytes to move.\n ;; operands[3] is the known shared alignment.\n \n-(define_expand \"movmemqi\"\n+\n+(define_expand \"movmemsi\"\n   [(match_operand:BLK 0 \"general_operand\" \"\")\n    (match_operand:BLK 1 \"general_operand\" \"\")\n-   (match_operand:SI 2 \"const_int_operand\" \"\")\n+   (match_operand:SI 2 \"nds32_reg_constant_operand\" \"\")\n    (match_operand:SI 3 \"const_int_operand\" \"\")]\n   \"\"\n {\n-  if (nds32_expand_movmemqi (operands[0],\n+  if (nds32_expand_movmemsi (operands[0],\n \t\t\t     operands[1],\n \t\t\t     operands[2],\n \t\t\t     operands[3]))"}, {"sha": "6ed152295b30697b9a49d3a93505d001fde95cd8", "filename": "gcc/config/nds32/nds32-protos.h", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc/gcc%2Fconfig%2Fnds32%2Fnds32-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc/gcc%2Fconfig%2Fnds32%2Fnds32-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fnds32%2Fnds32-protos.h?ref=eab7aaedc75a3fc182ad370fe49f2d2b45fca9bc", "patch": "@@ -68,7 +68,7 @@ extern bool nds32_valid_smw_lwm_base_p (rtx);\n \n extern rtx nds32_expand_load_multiple (int, int, rtx, rtx, bool, rtx *);\n extern rtx nds32_expand_store_multiple (int, int, rtx, rtx, bool, rtx *);\n-extern int nds32_expand_movmemqi (rtx, rtx, rtx, rtx);\n+extern bool nds32_expand_movmemsi (rtx, rtx, rtx, rtx);\n \n /* Auxiliary functions for expand unalign load instruction.  */\n "}]}