{"sha": "4c442790ef8625f6e6f5dfda20648f055be114e2", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NGM0NDI3OTBlZjg2MjVmNmU2ZjVkZmRhMjA2NDhmMDU1YmUxMTRlMg==", "commit": {"author": {"name": "Paolo Bonzini", "email": "bonzini@gnu.org", "date": "2004-01-23T02:03:25Z"}, "committer": {"name": "Roger Sayle", "email": "sayle@gcc.gnu.org", "date": "2004-01-23T02:03:25Z"}, "message": "re PR rtl-optimization/13724 (Bad code generated for unsigned int -> long long multiplication)\n\n2004-01-22  Paolo Bonzini  <bonzini@gnu.org>\n\n\tPR optimization/13724\n\t* cse.c (fold_rtx) <SUBREG>:  Fold a SUBREG to zero if it\n\trepresents the zero bits produced by a ZERO_EXTEND operation.\n\nFrom-SVN: r76394", "tree": {"sha": "cbaa0c0558529ef8b3e2a376fabe71f0cf8feb21", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/cbaa0c0558529ef8b3e2a376fabe71f0cf8feb21"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/4c442790ef8625f6e6f5dfda20648f055be114e2", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4c442790ef8625f6e6f5dfda20648f055be114e2", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4c442790ef8625f6e6f5dfda20648f055be114e2", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4c442790ef8625f6e6f5dfda20648f055be114e2/comments", "author": {"login": "bonzini", "id": 42082, "node_id": "MDQ6VXNlcjQyMDgy", "avatar_url": "https://avatars.githubusercontent.com/u/42082?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bonzini", "html_url": "https://github.com/bonzini", "followers_url": "https://api.github.com/users/bonzini/followers", "following_url": "https://api.github.com/users/bonzini/following{/other_user}", "gists_url": "https://api.github.com/users/bonzini/gists{/gist_id}", "starred_url": "https://api.github.com/users/bonzini/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bonzini/subscriptions", "organizations_url": "https://api.github.com/users/bonzini/orgs", "repos_url": "https://api.github.com/users/bonzini/repos", "events_url": "https://api.github.com/users/bonzini/events{/privacy}", "received_events_url": "https://api.github.com/users/bonzini/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "dc4bbaf76f904bc3004ef0d6123f6654b714230c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/dc4bbaf76f904bc3004ef0d6123f6654b714230c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/dc4bbaf76f904bc3004ef0d6123f6654b714230c"}], "stats": {"total": 209, "additions": 113, "deletions": 96}, "files": [{"sha": "3c532898643043ceac1ffaac94e87fee871e5218", "filename": "gcc/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4c442790ef8625f6e6f5dfda20648f055be114e2/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4c442790ef8625f6e6f5dfda20648f055be114e2/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=4c442790ef8625f6e6f5dfda20648f055be114e2", "patch": "@@ -1,3 +1,9 @@\n+2004-01-22  Paolo Bonzini  <bonzini@gnu.org>\n+\n+\tPR optimization/13724\n+\t* cse.c (fold_rtx) <SUBREG>:  Fold a SUBREG to zero if it\n+\trepresents the zero bits produced by a ZERO_EXTEND operation.\n+\n 2004-01-22  Roger Sayle  <roger@eyesopen.com>\n \n \tPR optimization/13821"}, {"sha": "d5a37fdbaa0bc7eb45f9052f6076da10d463a60f", "filename": "gcc/cse.c", "status": "modified", "additions": 107, "deletions": 96, "changes": 203, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4c442790ef8625f6e6f5dfda20648f055be114e2/gcc%2Fcse.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4c442790ef8625f6e6f5dfda20648f055be114e2/gcc%2Fcse.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcse.c?ref=4c442790ef8625f6e6f5dfda20648f055be114e2", "patch": "@@ -3353,24 +3353,8 @@ fold_rtx (rtx x, rtx insn)\n \t    return new;\n \t}\n \n-      /* If this is a narrowing SUBREG and our operand is a REG, see if\n-\t we can find an equivalence for REG that is an arithmetic operation\n-\t in a wider mode where both operands are paradoxical SUBREGs\n-\t from objects of our result mode.  In that case, we couldn't report\n-\t an equivalent value for that operation, since we don't know what the\n-\t extra bits will be.  But we can find an equivalence for this SUBREG\n-\t by folding that operation is the narrow mode.  This allows us to\n-\t fold arithmetic in narrow modes when the machine only supports\n-\t word-sized arithmetic.\n-\n-\t Also look for a case where we have a SUBREG whose operand is the\n-\t same as our result.  If both modes are smaller than a word, we\n-\t are simply interpreting a register in different modes and we\n-\t can use the inner value.  */\n-\n       if (GET_CODE (folded_arg0) == REG\n-\t  && GET_MODE_SIZE (mode) < GET_MODE_SIZE (GET_MODE (folded_arg0))\n-\t  && subreg_lowpart_p (x))\n+\t  && GET_MODE_SIZE (mode) < GET_MODE_SIZE (GET_MODE (folded_arg0)))\n \t{\n \t  struct table_elt *elt;\n \n@@ -3383,95 +3367,122 @@ fold_rtx (rtx x, rtx insn)\n \t  if (elt)\n \t    elt = elt->first_same_value;\n \n-\t  for (; elt; elt = elt->next_same_value)\n-\t    {\n-\t      enum rtx_code eltcode = GET_CODE (elt->exp);\n-\n-\t      /* Just check for unary and binary operations.  */\n-\t      if (GET_RTX_CLASS (GET_CODE (elt->exp)) == '1'\n-\t\t  && GET_CODE (elt->exp) != SIGN_EXTEND\n-\t\t  && GET_CODE (elt->exp) != ZERO_EXTEND\n-\t\t  && GET_CODE (XEXP (elt->exp, 0)) == SUBREG\n-\t\t  && GET_MODE (SUBREG_REG (XEXP (elt->exp, 0))) == mode\n-\t\t  && (GET_MODE_CLASS (mode)\n-\t\t      == GET_MODE_CLASS (GET_MODE (XEXP (elt->exp, 0)))))\n-\t\t{\n-\t\t  rtx op0 = SUBREG_REG (XEXP (elt->exp, 0));\n+\t  if (subreg_lowpart_p (x))\n+\t    /* If this is a narrowing SUBREG and our operand is a REG, see\n+\t       if we can find an equivalence for REG that is an arithmetic\n+\t       operation in a wider mode where both operands are paradoxical\n+\t       SUBREGs from objects of our result mode.  In that case, we\n+\t       couldn-t report an equivalent value for that operation, since we\n+\t       don't know what the extra bits will be.  But we can find an\n+\t       equivalence for this SUBREG by folding that operation in the\n+\t       narrow mode.  This allows us to fold arithmetic in narrow modes\n+\t       when the machine only supports word-sized arithmetic.\n+\n+\t       Also look for a case where we have a SUBREG whose operand\n+\t       is the same as our result.  If both modes are smaller\n+\t       than a word, we are simply interpreting a register in\n+\t       different modes and we can use the inner value.\t*/\n+\n+\t    for (; elt; elt = elt->next_same_value)\n+\t      {\n+\t\tenum rtx_code eltcode = GET_CODE (elt->exp);\n+\n+\t        /* Just check for unary and binary operations.  */\n+\t        if (GET_RTX_CLASS (GET_CODE (elt->exp)) == '1'\n+\t\t    && GET_CODE (elt->exp) != SIGN_EXTEND\n+\t\t    && GET_CODE (elt->exp) != ZERO_EXTEND\n+\t\t    && GET_CODE (XEXP (elt->exp, 0)) == SUBREG\n+\t\t    && GET_MODE (SUBREG_REG (XEXP (elt->exp, 0))) == mode\n+\t\t    && (GET_MODE_CLASS (mode)\n+\t\t        == GET_MODE_CLASS (GET_MODE (XEXP (elt->exp, 0)))))\n+\t\t  {\n+\t\t    rtx op0 = SUBREG_REG (XEXP (elt->exp, 0));\n \n-\t\t  if (GET_CODE (op0) != REG && ! CONSTANT_P (op0))\n-\t\t    op0 = fold_rtx (op0, NULL_RTX);\n+\t\t    if (GET_CODE (op0) != REG && ! CONSTANT_P (op0))\n+\t\t      op0 = fold_rtx (op0, NULL_RTX);\n \n-\t\t  op0 = equiv_constant (op0);\n-\t\t  if (op0)\n-\t\t    new = simplify_unary_operation (GET_CODE (elt->exp), mode,\n-\t\t\t\t\t\t    op0, mode);\n-\t\t}\n-\t      else if ((GET_RTX_CLASS (GET_CODE (elt->exp)) == '2'\n-\t\t\t|| GET_RTX_CLASS (GET_CODE (elt->exp)) == 'c')\n-\t\t       && eltcode != DIV && eltcode != MOD\n-\t\t       && eltcode != UDIV && eltcode != UMOD\n-\t\t       && eltcode != ASHIFTRT && eltcode != LSHIFTRT\n-\t\t       && eltcode != ROTATE && eltcode != ROTATERT\n-\t\t       && ((GET_CODE (XEXP (elt->exp, 0)) == SUBREG\n-\t\t\t    && (GET_MODE (SUBREG_REG (XEXP (elt->exp, 0)))\n-\t\t\t\t== mode))\n-\t\t\t   || CONSTANT_P (XEXP (elt->exp, 0)))\n-\t\t       && ((GET_CODE (XEXP (elt->exp, 1)) == SUBREG\n-\t\t\t    && (GET_MODE (SUBREG_REG (XEXP (elt->exp, 1)))\n-\t\t\t\t== mode))\n-\t\t\t   || CONSTANT_P (XEXP (elt->exp, 1))))\n-\t\t{\n-\t\t  rtx op0 = gen_lowpart_common (mode, XEXP (elt->exp, 0));\n-\t\t  rtx op1 = gen_lowpart_common (mode, XEXP (elt->exp, 1));\n+\t\t    op0 = equiv_constant (op0);\n+\t\t    if (op0)\n+\t\t      new = simplify_unary_operation (GET_CODE (elt->exp), mode,\n+\t\t\t\t\t\t      op0, mode);\n+\t\t  }\n+\t        else if ((GET_RTX_CLASS (GET_CODE (elt->exp)) == '2'\n+\t\t\t  || GET_RTX_CLASS (GET_CODE (elt->exp)) == 'c')\n+\t\t         && eltcode != DIV && eltcode != MOD\n+\t\t         && eltcode != UDIV && eltcode != UMOD\n+\t\t         && eltcode != ASHIFTRT && eltcode != LSHIFTRT\n+\t\t         && eltcode != ROTATE && eltcode != ROTATERT\n+\t\t         && ((GET_CODE (XEXP (elt->exp, 0)) == SUBREG\n+\t\t\t      && (GET_MODE (SUBREG_REG (XEXP (elt->exp, 0)))\n+\t\t\t\t  == mode))\n+\t\t\t     || CONSTANT_P (XEXP (elt->exp, 0)))\n+\t\t         && ((GET_CODE (XEXP (elt->exp, 1)) == SUBREG\n+\t\t\t      && (GET_MODE (SUBREG_REG (XEXP (elt->exp, 1)))\n+\t\t\t\t  == mode))\n+\t\t\t     || CONSTANT_P (XEXP (elt->exp, 1))))\n+\t\t  {\n+\t\t    rtx op0 = gen_lowpart_common (mode, XEXP (elt->exp, 0));\n+\t\t    rtx op1 = gen_lowpart_common (mode, XEXP (elt->exp, 1));\n \n-\t\t  if (op0 && GET_CODE (op0) != REG && ! CONSTANT_P (op0))\n-\t\t    op0 = fold_rtx (op0, NULL_RTX);\n+\t\t    if (op0 && GET_CODE (op0) != REG && ! CONSTANT_P (op0))\n+\t\t      op0 = fold_rtx (op0, NULL_RTX);\n \n-\t\t  if (op0)\n-\t\t    op0 = equiv_constant (op0);\n+\t\t    if (op0)\n+\t\t      op0 = equiv_constant (op0);\n \n-\t\t  if (op1 && GET_CODE (op1) != REG && ! CONSTANT_P (op1))\n-\t\t    op1 = fold_rtx (op1, NULL_RTX);\n+\t\t    if (op1 && GET_CODE (op1) != REG && ! CONSTANT_P (op1))\n+\t\t      op1 = fold_rtx (op1, NULL_RTX);\n \n-\t\t  if (op1)\n-\t\t    op1 = equiv_constant (op1);\n+\t\t    if (op1)\n+\t\t      op1 = equiv_constant (op1);\n \n-\t\t  /* If we are looking for the low SImode part of\n-\t\t     (ashift:DI c (const_int 32)), it doesn't work\n-\t\t     to compute that in SImode, because a 32-bit shift\n-\t\t     in SImode is unpredictable.  We know the value is 0.  */\n-\t\t  if (op0 && op1\n-\t\t      && GET_CODE (elt->exp) == ASHIFT\n-\t\t      && GET_CODE (op1) == CONST_INT\n-\t\t      && INTVAL (op1) >= GET_MODE_BITSIZE (mode))\n-\t\t    {\n-\t\t      if (INTVAL (op1) < GET_MODE_BITSIZE (GET_MODE (elt->exp)))\n-\n-\t\t\t/* If the count fits in the inner mode's width,\n-\t\t\t   but exceeds the outer mode's width,\n-\t\t\t   the value will get truncated to 0\n-\t\t\t   by the subreg.  */\n-\t\t\tnew = const0_rtx;\n-\t\t      else\n-\t\t\t/* If the count exceeds even the inner mode's width,\n+\t\t    /* If we are looking for the low SImode part of\n+\t\t       (ashift:DI c (const_int 32)), it doesn't work\n+\t\t       to compute that in SImode, because a 32-bit shift\n+\t\t       in SImode is unpredictable.  We know the value is 0.  */\n+\t\t    if (op0 && op1\n+\t\t        && GET_CODE (elt->exp) == ASHIFT\n+\t\t        && GET_CODE (op1) == CONST_INT\n+\t\t        && INTVAL (op1) >= GET_MODE_BITSIZE (mode))\n+\t\t      {\n+\t\t        if (INTVAL (op1)\n+\t\t\t    < GET_MODE_BITSIZE (GET_MODE (elt->exp)))\n+\t\t\t  /* If the count fits in the inner mode's width,\n+\t\t\t     but exceeds the outer mode's width,\n+\t\t\t     the value will get truncated to 0\n+\t\t\t     by the subreg.  */\n+\t\t\t  new = CONST0_RTX (mode);\n+\t\t        else\n+\t\t\t  /* If the count exceeds even the inner mode's width,\n \t\t\t   don't fold this expression.  */\n-\t\t\tnew = 0;\n-\t\t    }\n-\t\t  else if (op0 && op1)\n-\t\t    new = simplify_binary_operation (GET_CODE (elt->exp), mode,\n-\t\t\t\t\t\t     op0, op1);\n-\t\t}\n+\t\t\t  new = 0;\n+\t\t      }\n+\t\t    else if (op0 && op1)\n+\t\t      new = simplify_binary_operation (GET_CODE (elt->exp),\t\t\t\t\t\t\t       mode, op0, op1);\n+\t\t  }\n \n-\t      else if (GET_CODE (elt->exp) == SUBREG\n-\t\t       && GET_MODE (SUBREG_REG (elt->exp)) == mode\n-\t\t       && (GET_MODE_SIZE (GET_MODE (folded_arg0))\n-\t\t\t   <= UNITS_PER_WORD)\n-\t\t       && exp_equiv_p (elt->exp, elt->exp, 1, 0))\n-\t\tnew = copy_rtx (SUBREG_REG (elt->exp));\n+\t        else if (GET_CODE (elt->exp) == SUBREG\n+\t\t         && GET_MODE (SUBREG_REG (elt->exp)) == mode\n+\t\t         && (GET_MODE_SIZE (GET_MODE (folded_arg0))\n+\t\t\t     <= UNITS_PER_WORD)\n+\t\t         && exp_equiv_p (elt->exp, elt->exp, 1, 0))\n+\t\t  new = copy_rtx (SUBREG_REG (elt->exp));\n \n-\t      if (new)\n-\t\treturn new;\n-\t    }\n+\t        if (new)\n+\t\t  return new;\n+\t      }\n+\t  else\n+\t    /* A SUBREG resulting from a zero extension may fold to zero if\n+\t       it extracts higher bits than the ZERO_EXTEND's source bits.\n+\t       FIXME: if combine tried to, er, combine these instructions,\n+\t       this transformation may be moved to simplify_subreg.  */\n+\t    for (; elt; elt = elt->next_same_value)\n+\t      {\n+\t      \tif (GET_CODE (elt->exp) == ZERO_EXTEND\n+\t\t    && subreg_lsb (x)\n+\t\t       >= GET_MODE_BITSIZE (GET_MODE (XEXP (elt->exp, 0))))\n+\t\t  return CONST0_RTX (mode);\n+\t      }\n \t}\n \n       return x;"}]}