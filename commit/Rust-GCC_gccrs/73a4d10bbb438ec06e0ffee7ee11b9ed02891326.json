{"sha": "73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NzNhNGQxMGJiYjQzOGVjMDZlMGZmZWU3ZWUxMWI5ZWQwMjg5MTMyNg==", "commit": {"author": {"name": "J\"orn Rennecke", "email": "joern.rennecke@st.com", "date": "2005-05-09T17:42:55Z"}, "committer": {"name": "Joern Rennecke", "email": "amylaar@gcc.gnu.org", "date": "2005-05-09T17:42:55Z"}, "message": "re PR target/20695 (sh64-*-* port deos not handle 32 / 64 bit conversions properly)\n\n\ngcc:\n\n2005-05-09  J\"orn Rennecke <joern.rennecke@st.com>\n\n\t* config/sh/sh.h (OVERRIDE_OPTIONS): Don't set flag_finite_math_only\n\tif flag_signaling_nans is set.\n\tFor TARGET_SH2E, if flag_finite_math_only is not set, set IEEE_BIT.\n\t* doc/invoke.texi (SH -mieee): Document relation to -ffinite-math-only.\n\n2005-05-06  J\"orn Rennecke <joern.rennecke@st.com>\n\tMerge of sh-elf specific patches from sh-elf-4_1-branch:\n\n\t2005-05-05  Kaz Kojima  <kkojima@gcc.gnu.org>\n\n\t  * config/sh/sh.h (ASM_OUTPUT_REG_PUSH): Provide SHMEDIA version.\n\t  (ASM_OUTPUT_REG_POP): Likewise.\n\n\t2005-05-05  J\"orn Rennecke  <joern.rennecke@st.com>\n\t\t    Kaz Kojima  <kkojima@gcc.gnu.org>\n\n\t  * config/sh/sh.c (sh_builtin_saveregs): Use copy_to_mode_reg\n\t  and plus_constant.\n\n\t2005-05-04  Kaz Kojima  <kkojima@gcc.gnu.org>\n\n\t  * config/sh/sh.c (sh_div_strategy): Initialize with\n\t  SH_DIV_STRATEGY_DEFAULT.\n\t  * config/sh/sh.c (SH_DIV_STR_FOR_SIZE): Define.\n\t  (SH_DIV_STRATEGY_DEFAULT): Likewise.\n\t  (OPTIMIZATION_OPTIONS): Set sh_div_str to SH_DIV_STR_FOR_SIZE\n\t  when optimized for size.\n\t  * config/sh/linux.h (SH_DIV_STRATEGY_DEFAULT): Redefine.\n\t  (SH_DIV_STR_FOR_SIZE): Likewise.\n\t  * config/sh/netbsd-elf.h (SH_DIV_STRATEGY_DEFAULT): Likewise.\n\t  (SH_DIV_STR_FOR_SIZE): Likewise.\n\n\t2005-05-04  J\"orn Rennecke <joern.rennecke@st.com>\n\n\t  * config/sh/sh-modes.def (PDImode): Add.\n\t  * config/sh/sh-protos.h (shmedia_prepare_call_address): Declare.\n\t  * config/sh/sh.c (print_operand): Handle IF_THEN_ELSE.\n\t  (target_reg_operand): Allow PDImode.\n\t  (sh_register_move_cost): If neither sh_gettrcost_str nor\n\t  TARGET_PT_FIXED is set, assume gettr costs 100.\n\t  (shmedia_prepare_call_address): New function.\n\t  (sh_gettrcost_str): Initialize to empty string.\n\t  (sh_divsi3_libfunc): New variable.\n\t  * config/sh/sh.h (PT_FIXED_BIT, TARGET_INVALID_SYMBOLS): Define.\n\t  (TARGET_SWITCH_SH5_32_ANY_EXTRA): Likewise.\n\t  (TARGET_SWITCH_SH5_MEDIA_ANY_EXTRA): Likewise.\n\t  (TARGET_SWITCHES): Use TARGET_SWITCH_SH5_32_ANY_EXTRA and\n\t  TARGET_SWITCH_SH5_MEDIA_ANY_EXTRA.\n\t  (TARGET_OPTIONS): Add -mdivsi3_libfunc.\n\t  (OVERRIDE_OPTIONS): Set sh_divsi3_libfunc if it hasn't been set\n\t  by the user.\n\t  Also set flag_no_function_cse for (TARGET_SHMEDIA && !TARGET_PT_FIXED).\n\t  (HARD_REGNO_MODE_OK): Allow TARGET_REGS in PDImode.\n\t  (CONSTRAINT_LEN): Remove debug version.\n\t  (SECONDARY_INOUT_RELOAD_CLASS:) Break out of\n\t  (SECONDARY_OUTPUT_RELOAD_CLASS).  Use EXTRA_CONSTRAINT_Csy for check\n\t  if a target register needs a secondary reload through GENERAL_REGS.\n\t  (SECONDARY_INPUT_RELOAD_CLASS): Use SECONDARY_INOUT_RELOAD_CLASS.\n\t  (sh_divsi3_libfunc): Declare.\n\t  (FUNCTION_PROFILER): Provide SHMEDIA version.\n\t  * config/sh/predicates.md: New file.\n\t  * config/sh/sh.md (predicates.md): Include.\n\t  (divsi_inv_call_combine, divsi3): Use sh_divsi3_libfunc.\n\t  (reload_insi): Fix predicates and constraints.\n\t  (ptabs): New expander.\n\t  (*extendsipdi_media, *truncdipdi_media): New insns.\n\t  (call, call_value, sibcall): Use shmedia_prepare_call_address.\n\t  * doc/invoke.texi (-multcost, -mdiv): Document new SH options.\n\t  (-mdivsi3_libfunc, -madjust-unroll, -mindexed-addressing): Likewise.\n\t  (-mgettrcost, -mpt-fixed, -minvalid-symbols): Likewise.\n\n\t2005-04-11  J\"orn Rennecke <joern.rennecke@st.com>\n\n\t  * sh.c (print_operand): Remove sh_rep_vec extraction.\n\t  (sh_output_mi_thunk): Make i unsigned.\n\n\t  * sh.c (TARGET_ADJUST_UNROLL_MAX): Only redefine if already defined.\n\t  (sh_adjust_unroll_max): Only define if TARGET_ADJUST_UNROLL_MAX\n\t  is defined.  Update label detection code and iteration lookup,\n\t  enable basic functionality, but without IV analysis.\n\n\t2005-04-11  J\"orn Rennecke <joern.rennecke@st.com>\n\n\t  * sh.h (OPTIMIZATION_OPTIONS): Don't make setting of\n\t  flag_branch_target_load_optimize dependent on TARGET_SHMEDIA.\n\t  Set flag_finite_math_only to 2.\n\t  If flag_finite_math_only set set to 2, set it to 1 iff\n\t  we use SH2E..SH4 arithmetic without full IEEE support.\n\n\t2005-04-09  Kaz Kojima  <kkojima@gcc.gnu.org>\n\n\t  * config/sh/lib1funcs.asm (ic_invalidate): Fix typos.\n\t  * config/sh/t-linux (LIB1ASMFUNCS_CACHE): Add _ic_invalidate_array.\n\n\t2005-04-06  J\"orn Rennecke <joern.rennecke@st.com>\n\n\t  Merge of SuperH / STM SH specific patches, including fix for\n\t  PR target/20695:\n\t  * config.gcc (sh*-superh-elf, sh*elf (newlib)): Use newlib.h\n\t  when building with libgloss.\n\t  (sh*elf): Implement --without-fp option.\n\t  (sh64-superh-linux*): Don't multilib.\n\t  (sh*-*-linux): Use sh3 as basic multilib.\n\t  * config/sh/crt1.asm (SHmedia start): Add code to enable the MMU,\n\t  and to set up vbr.  Enable FPU before calling set_fpscr.\n\t  Load atexit address just before use.  Use __SH_FPU_ANY__.\n\t  (SH3*/SH4* start): Add code to set up vbr.  Use __SH_FPU_ANY__.\n\t  Set DN bit in fpscr.\n\t  * config/sh/elf.h (SUBTARGET_ASM_ISA_SPEC): Merge into:\n\t   config/sh/sh.h (SH_ASM_SPEC, SUBTARGET_ASM_ISA_SPEC): Here.\n\t  * config/sh/lib1funcs.asm (HIDDEN_FUNC, HIDDEN_ALIAS): Define.\n\t  (FMOVD_WORKS): Don't define for __SH5__.\n\t  (ashiftrt_r4_0, ashiftrt_r4_1, ashiftrt_r4_2, ashiftrt_r4_3): Hide.\n\t  (ashiftrt_r4_4, ashiftrt_r4_5, ashiftrt_r4_6, ashiftrt_r4_7): Hide.\n\t  (ashiftrt_r4_8, ashiftrt_r4_9, ashiftrt_r4_10, ashiftrt_r4_11): Hide.\n\t  (ashiftrt_r4_12, ashiftrt_r4_13, ashiftrt_r4_14, ashiftrt_r4_15): Hide.\n\t  (ashiftrt_r4_16, ashiftrt_r4_17, ashiftrt_r4_18, ashiftrt_r4_19): Hide.\n\t  (ashiftrt_r4_20, ashiftrt_r4_21, ashiftrt_r4_22, ashiftrt_r4_23): Hide.\n\t  (ashiftrt_r4_24, ashiftrt_r4_25, ashiftrt_r4_26, ashiftrt_r4_27): Hide.\n\t  (ashiftrt_r4_28, ashiftrt_r4_29, ashiftrt_r4_30, ashiftrt_r4_31): Hide.\n\t  (ashiftrt_r4_32, ashrsi3, ashlsi3, lshrsi3, movmem, movstr): Hide.\n\t  (movstrSI64, movmemSI64, movstrSI60, movmemSI60): Hide.\n\t  (movstrSI56, movmemSI56, movstrSI52, movmemSI52): Hide.\n\t  (movstrSI48, movmemSI48, movstrSI44, movmemSI44): Hide.\n\t  (movstrSI40, movmemSI40, movstrSI36, movmemSI36): Hide.\n\t  (movstrSI32, movmemSI32, movstrSI28, movmemSI28): Hide.\n\t  (movstrSI24, movmemSI24, movstrSI20, movmemSI20): Hide.\n\t  (movstrSI16,movmemSI16, movstrSI12,movmemSI12): Hide.\n\t  (movstrSI8,movmemSI8, movstrSI4,movmemSI4): Hide.\n\t  (movmemSI0, movstrSI0): Remove.\n\t  (movmemSI4): Schedule last store into rts delay slot.\n\t  (movmem): Shorten code.  Provide ENDFUNC.\n\t  (movmem_i4_even, movmem_i4_odd, movmemSI12_i4, mulsi3): Hide.\n\t  (mulsi3): Provide ENDFUNC.\n\t  (sdivsi3_i4, sdivsi3_i4, udivsi3_i4, udivsi3, set_fpscr): Hide.\n\t  (SH5 sdivsi3): Reimplement, using:\n\t  (div_table): New, linear approximation table lookup for division seed.\n\t  (sdivsi3_2): New SH5 entry point.\n\t  (divdi3): Use hidden alias for udivdi3.\n\t  (moddi3): Use hidden alias for umoddi3.\n\t  (init_trampoline): Hide.  Provide exact ENDFUNC.\n\t  (ic_invalidate): Hide.  Re-implement SH4 version, using\n\t  (ic_invalidate_array): New global.\n\t  (GCC_shcompact_return_trampoline, GCC_nested_trampoline): Hide.\n\t  (GCC_push_shmedia_regs_nofpu): Only provide for __SH4_NOFPU__.\n\t  (GCC_pop_shmedia_regs_nofpu): Likewise.\n\t  * config/sh/libgcc-excl.ver (__mulsi3): Add.\n\t  * config/sh/linux.h (TARGET_DEFAULT): Include TARGET_OPT_DEFAULT.\n\t  * config/sh/sh-protos.h (sh_function_kind): New enum.\n\t  (sh_gen_truncate, replace_n_hard_rtx): Declare.\n\t  (function_symbol): Update declaration.\n\t  (shmedia_cleanup_truncate, sh_contains_memref_p): Declare.\n\t  * sh.c (cfgloop.h): Include.\n\t  (TARGET_ADJUST_UNROLL_MAX): Redefine.\n\t  (print_operand): Add '>' and 'U' support.  Handle TRUNCATE and\n\t  SIGN_EXTEND.\n\t  (function_sybol): Add arguments for target and kind of symbol.\n\t  If not an ordinary function symbol, make sure the string becomes\n\t  unique.  For PIC, load appropriately depending on kind of symbol.\n\t  Changed all callers.\n\t  (prepare_move_operands): Dont copy R0 to a pseudo for SHmedia.\n\t  (multcosts): Check sh_multcost_str.  If not set, return 2 for\n\t  SHMEDIA TARGET_SMALLCODE.\n\t  (sh_rtx_costs): Lower some costs when outer_code is SET.  Add code\n\t  for CONST_VECTOR, MINUS and PARALLEL.\n\t  (gen_shifty_op): Don't emit nop.\n\t  (expand_ashiftrt): While expanding to rtl, do shift by 31 using a\n\t  register set to zero.\n\t  (gen_datalabel_ref): Make sure that the string is shared.\n\t  (MAX_POOL_SIZE): Define as 372.\n\t  (find_barrier): Remove spurious adjustment.\n\t  (sh_media_register_for_return): Return -1 for interrupt handlers.\n\t  (sh_pch_valid_p): Use a copy of TARGET_OPTIONS.\n\t  (general_movsrc_operand): Accept vector that match sh_rep_vec.\n\t  (general_movdst_operand): For SHmedia, recject paradoxical DImode\n\t  subregs before high_life / reload.\n\t  (arith_reg_operand): Allow no-op sign extensions.\n\t  (logical_reg_operand, fp_arith_reg_dest, xor_operand): New functions.\n\t  (cmp_operand, shift_operator, logical_operator): Likewise.\n\t  (minuend_operand, ua_address_operand, cache_address_operand): Likewise.\n\t  (ua_offset, shift_count_reg_operand, shift_count_operand): Likewise.\n\t  (sh_adjust_unroll_max, replace_n_hard_rtx, sh_gen_truncate): Likewise.\n\t  (shmedia_cleanup_truncate, sh_contains_memref_p_1): Likewise.\n\t  (sh_contains_memref_p): Likewise.\n\t  (shmedia_6bit_operand): Remove.\n\t  (arith_operand): Allow some TRUNCATEs.\n\t  (logical_operand): Disallow subregs <= SImode of >= DImode.\n\t  (greater_comparison_operator): Fix mode comparison.\n\t  (less_comparison_operator): Likewise.\n\t  (target_reg_operand, target_operand): Compare modes with Pmode.\n\t  (sh_adjust_cost): Consider the dependency between a target register\n\t  load and its use in a subsequent block.\n\t  Implement mac_media latency exception.\n\t  Before reload, anticipate floating point latencies to be at least four.\n\t  Give preference to the ptabs feeding a casesi_jump_media.\n\t  Handle UNSPEC in a CALL address.\n\t  (sh_optimize_target_register_callee_saved): Improve handling of\n\t  borderline cases.\n\t  (sh_function_ok_for_sibcall): Allow for non-pic, and also when we\n\t  will use the symbol with @GOTOFF addressing.\n\t  (SH_BLTIN_UDI): Remove.\n\t  (SH_BLTIN_LDUA_L64, SH_BLTIN_LDUA_Q64, SH_BLTIN_STUA_L64): New.\n\t  (SH_BLTIN_STUA_Q64): Likewise.\n\t  (signature_args, SH_BLTIN_NUM_SHARED_SIGNATURES): Update.\n\t  (SH_BLTIN_2, SH_BLTIN_SU, SH_BLTIN_3, SH_BLTIN_SUS): Renumber.\n\t  (SH_BLTIN_PSSV, SH_BLTIN_XXUU, SH_BLTIN_UUUU, SH_BLTIN_PV): Likewise.\n\t  (bdesc): Add entries for alloco, mac_media, sqrtdf2, sqrtsf2, fsrra_s,\n\t  {ld,st}{hi,lo}.[lq] and prefetch.\n\t  Change mextr entries to use SH_BLTIN_V8QI3.\n\t  (sh_media_init_builtins): Implement specific TARGET_SHMEDIA32 /\n\t  TARGET_SHMEDIA64 checks for pointer arguments.\n\t  (sh_expand_builtin): For pointer types, use ptr_mode / ptr_type_mode.\n\t  (sh_register_move_cost): Check sh_gettrcost_str.\n\t  (cmpsi_operand): T_REG is only allowed for TARGET_SH1.\n\t  (sh_output_mi_thunk): Make static.  Check that needed registers are\n\t  actually available.  Make sure that the sibcall won't go via the PLT.\n\t  (sh_multcost_str, sh_gettrcost_str, sh_div_str): New variables.\n\t  (cut2_workaround_str, sh_div_strategy, boardtype, osruntime): Likewise.\n\t  (arith_reg_dest): Allow paradoxical DImode subreg for ! TARGET_SHMEDIA.\n\t  * sh.h (TARGET_CPU_CPP_BUILTINS): Define __SH_FPU_ANY__ and\n\t  __SH_FPU_DOUBLE__.\n\t  (INDEXED_ADDRESS_BIT, ADJUST_UNROLL_BIT, TARGET_DIVIDE_INV): Define.\n\t  (TARGET_HARVARD): Also true for TARGET_SH5.\n\t  (TARGET_DIVIDE_FP, TARGET_DIVIDE_INV_FP, TARGET_DIVIDE_CALL2): Define.\n\t  (TARGET_DIVIDE_INV_MINLAT, TARGET_DIVIDE_INV20U): Define.\n\t  (TARGET_DIVIDE_INV20L, TARGET_DIVIDE_INV_CALL): Define.\n\t  (TARGET_DIVIDE_INV_CALL2, TARGET_ALLOW_INDEXED_ADDRESS): Define.\n\t  (TARGET_ADJUST_UNROLL, TARGET_OPT_DEFAULT, SUBTARGET_OPTIONS): Define.\n\t  (TARGET_SWITCHES): Removed excessive whitespace.  Added options\n\t  indexed-addressing, no-indexed-addressing, adjust-unroll and\n\t  no-adjust-unroll.\n\t  (TARGET_DEFAULT): Add TARGET_OPT_DEFAULT.\n\t  (TARGET_OPTIONS): Define.\n\t  (EXTRA_SPECS): Add subtarget_asm_spec.\n\t  (SH_ASM_SPEC): Pass cut2-workaround option.\n\t  (SUBTARGET_ASM_ISA_SPEC): Enforce STRICT_NOFPU for SH4 --without-fp.\n\t  (LINK_EMUL_PREFIX): If target defaults to little endian, default to shl.\n\t  (OPTIMIZATION_OPTIONS): Set sh_div_str.  If not using if not -mieee,\n\t  set flag_finite_math_only.\n\t  (sh_divide_strategy_e): New enum.\n\t  (sh_div_strategy): Declare.\n\t  (OVERRIDE_OPTIONS): Don't set FMOVD_BIT for TARGET_SHCOMPACT.\n\t  Clear flag_if_conversion2 for SHMEDIA.\n\t  Set sh_div_strategy.\n\t  Leave profile_flag and profile_arc_flag alone.\n\t  (LOOP_ALIGN): Replace TARGET_HARVARD test with TARGET_HARD_SH4 test.\n\t  (HARD_REGNO_MODE_OK): Allow TImode in aligned FP registers.\n\t  (MODES_TIEABLE_P): For TARGET_SHMEDIA, allow tying of integral modes\n\t  of the same size.\n\t  (CONST_OK_FOR_I): Fix detection of I06 constraint.\n\t  (PREFERRED_RELOAD_CLASS): Also choose GENERAL_REGS for\n\t  PIC_DIRECT_ADDR_P.\n\t  (SECONDARY_INPUT_RELOAD_CLASS): Fix parentheses.  For TARGET_SHMEDIA,\n\t  check for inqhi_operand, LABEL_REF and PIC_DIRECT_ADDR_P.\n\t  (FUNCTION_VALUE, PROMOTE_MODE): Don't promote from SImode.  For\n\t  TARGET_SHMEDIA32, promote to SImode.\n\t  (EXTRA_CONSTRAINT_C16): Allow SIGN_EXTEND to SImode.\n\t  (DATALABEL_REF_NO_CONST_P: Don't allow SYMBOL_REF.\n\t  (DATALABEL_REF_P): Don't define.\n\t  (NON_PIC_REFERENCE_P): Allow LABEL_REF and SYMBOL_REF directly inside\n\t  a CONST.  Don't allow DATALABEL_REF_NO_CONST_P outside of a CONST.\n\t  Allow a LABEL_REF in a sum.\n\t  (BASE_REGISTER_RTX_P): Check TRULY_NOOP_TRUNCATION.\n\t  (INDEX_REGISTER_RTX_P): Likewise.\n\t  (GO_IF_LEGITIMATE_INDEX): Check if pased the address of an unaligned\n\t  load / store.\n\t  (ALLOW_INDEXED_ADDRESS): Define.\n\t  (GO_IF_LEGITIMATE_ADDRESS): Use it.\n\t  (TRULY_NOOP_TRUNCATION): Don't allow no-op truncation from 64 bit or\n\t  beyond to less than 64 bit.\n\t  (PRINT_OPERAND_PUNCT_VALID_P): Allow '>'.\n\t  (rtx_equal_function_value_matters): Don't declare.\n\t  (arith_reg_operand): Allow sign_extend.\n\t  (PREDICATE_CODES): Allow SIGN_EXTEND in arith_reg_operand.  Add\n\t  any_arith_reg_dest, cache_address_operand, cmp_operand,\n\t  fp_arith_reg_dest, logical_operator, logical_reg_operand,\n\t  minuend_operand, shift_count_operand, shift_count_reg_operand,\n\t  shift_operator, ua_address_operand, ua_offset, unary_float_operator,\n\t  xor_operand.  Don't allow PARALLEL in sh_1el_vec and sh_rep_vec\n\t  Remove shmedia_6bit_operand.\n\t  (SPECIAL_MODE_PREDICATES): Add any-arith_reg_dest, target_operand\n\t  and target_reg_operand.\n\t  (SIDI_OFF, SIMULTANEOUS_PREFETCHES, high_life_started): Define.\n\t  (sh_multcost_str, sh_gettrcost_str, sh_div_str): Declare.\n\t  (cut2_workaround_str): Declare.\n\t  (INDEX_REG_CLASS): Is NO_REGS if ALLOW_INDEXED_ADDRESS is zero.\n\t  (LEGITIMIZE_RELOAD_ADDRESS): Check ALLOW_INDEXED_ADDRESS.\n\t  Substitute INDEX_REG_CLASS with R0_REGS.\n\t  * sh.md (UNSPEC_DIV_INV_M0, UNSPEC_DIV_INV_M1): New constants.\n\t  (UNSPEC_DIV_INV_M2, UNSPEC_DIV_INV_M3, UNSPEC_DIV_INV20): Likewise.\n\t  (UNSPEC_ASHIFTRT, UNSPEC_THUNK): Likewise.\n\t  (Attribute \"length\"): jump_media has length 8 if\n\t  TARGET_SH5_CUT2_WORKAROUND is true.\n\t  (\"highpart\"): New attribute.\n\t  (cmpsi): Allow TARGET_SHMEDIA.\n\t  (cmpeqsi_media, cmpgtsi_media, cmpgtusi_media): New patterns.\n\t  (cmpsieqsi_media, cmpsieqdi_media, cmpsigtsi_media): Likewise.\n\t  (cmpsigtdi_media, cmpsigtusi_media, cmpsigtudi_media): Likewise.\n\t  (*cmpne0si_media, *cmpne0sisi_media, movdicc_true+1): Likewise.\n\t  (movdicc_true+2, movsicc_false, movsicc_true): Likewise.\n\t  (movsicc_true+1, movsicc_true+2, movsicc_true+3): Likewise.\n\t  (*movsicc_umin, movsicc, movqicc, *adddisi3_media): Likewise.\n\t  (addsidi3_media, subdisi3_media, mov_neg_si_t): Likewise.\n\t  (*subsi3_media+1, *subsi3_media+2, divsi3_media_2): Likewise.\n\t  (divsi_inv_call, *divsi_inv_call_combine, divsi_inv_m0): Likewise.\n\t  (divsi_inv_m1, divsi_inv_m2, divsi_inv_m3, divsi_inv_m1_3): Likewise.\n\t  (divsi_inv20, divsi_inv_fp, *divsi_inv_fp_combine, muldi3): Likewise.\n\t  (*andsi3_media, andcsi3): Likewise.\n\t  (cmpeqdi_media): Use cmp_operand operand predicate.\n\t  (*adddi3_media, adddi3z_media): Use arith_reg_dest operand predicate.\n\t  (adddi3_compact, adddi3_compact+1, addc, addc1): Likewise.\n\t  (addsi3_media, *addsi3_compact, *subdi3_media): Likewise.\n\t  (subdi3_compact, subdi3_compact+1, subc, subc1): Likewise.\n\t  (*subsi3_internal, *subsi3_media, udivsi3_sh2a, divsi3_sh2a): Likewise.\n\t  (mul_r, mulsidi3_media, mulsidi3_compact): Likewise.\n\t  (mulsidi3_compact+1, umulsidi3_media, umulsidi3_compact): Likewise.\n\t  (umulsidi3_compact+1, *andsi3_compact, anddi3, andcdi3): Likewise.\n\t  (*subsi3_media): Make define_insn_and_split.  Use minuend_operand\n\t  operand predicate.\n\t  (subsi3): Don't force operand 1 into a register if it is a SUBREG.\n\t  (udivsi3_i1_media, udivsi3): Use Pmode for function/target address.\n\t  (divsi3_i1_media, beq_media, *beq_media_i, bne_media): Likewise.\n\t  (bgt_media, bge_media, bgtu_media, bgeu_media, *bgt_media_i): Likewise.\n\t  (*blt_media_i, bunordered, jump_media, jump, call_media): Likewise.\n\t  (call_value_media, call, call_value, sibcall_media, sibcall): Likewise.\n\t  (indirect_jump, casesi_jump_media, GOTaddr2picreg, *ptb): Likewise.\n\t  (symGOT_load, casesi, casesi_shift_media, casesi_load_media): Likewise.\n\t  (return_media_i, return_media): Likewise.\n\t  (udivsi3_i1_media): Enable also for ! TARGET_DIVIDE_FP.\n\t  (divsi3_i1_media): Likewise.  Don't clobber R2 / R3 / TR1 / TR2.\n\t  (divsi3): Add support for division by multiplying with inverse.\n\t  (andsi3): Use logical_reg_operand predicate.  Add SHmedia support.\n\t  (iorsi3): Rename to:\n\t  (*iorsi3_compact).\n\t  (xorsi3): Rename to:\n\t  (*xorsi3_compact).\n\t  (iorsi3, *iorsi3_media, *logical_sidi3, xorsi3): New patterns.\n\t  (*logical_sidisi3, *logical_sidi3_2, rotrdi3_mextr+1): Likewise.\n\t  (ashrsi2_31+2, *ashlsi_c_void, *ashldisi3_media): Likewise.\n\t  (*lshrdisi3_media, *ashrdisi3_media, ashrdisi3_media_high): Likewise.\n\t  (ashrdisi3_media_opaque, one_cmpldi2+1, cneg, movsi_const): Likewise.\n\t  (movsi_const_16bit, *movdi_media_I16, *shori_media_si): Likewise.\n\t  (*beq_media_i32, *bgt_media_i32, *blt_media_i32): Likewise.\n\t  (bunordered+1, sibcalli_thunk, ptrel_si, cmpsieqsf_media): Likewise.\n\t  (cmpsieqdf_media, addv2hi3, ashlv2si3+1, subv2hi3, ldhi_l): Likewise.\n\t  (ldhi_q, *ldhi_q_comb0, *ldhi_q_comb1, ldlo_l, ldlo_q): Likewise.\n\t  (*ldlo_q_comb0, *ldlo_q_comb1, sthi_l, sthi_q): Likewise.\n\t  (*sthi_q_comb0, *sthi_q_comb1, stlo_l, stlo_q): Likewise.\n\t  (*stlo_q_comb0, *stlo_q_comb1, ldhi_l64, ldhi_q64, ldlo_l64): Likewise.\n\t  (ldlo_q64, sthi_l64, sthi_q64, stlo_l64, stlo_q64, alloco_i): Likewise.\n\t  (alloca_i+1): Likewise.\n\t  (prefetch_media): Inhibit generator function generation.\n\t  (prefetch_i4): Likewise.  Also enable for TARGET_SHCOMPACT.\n\t  (*iorsi3_compact, iordi3): Use arith_reg_dest operand predicate.\n\t  (*xorsi3_compact, xordi3, xordi3+1, rotlsi3_1, rotlsi3_31): Likewise.\n\t  (rotlsi3_16, rotlsi3, *rotlhi3_8, ashlsi3_sh2a, ashlsi3_std): Likewise.\n\t  (ashlhi3_k, ashlsi3_n, ashlsi3_n+1, ashlsi3_media): Likewise.\n\t  (*ashlhi3_n, ashlhi3+1, ashrsi3_sh2a, ashrsi3_k, ashrsi2_16): Likewise.\n\t  (ashrsi2_16+1, ashrsi2_31, ashrsi2_31+1, ashlsi_c): Likewise.\n\t  (ashrsi3_d, ashrsi3_media, lshrsi3_sh2a, lshrsi3_d): Likewise.\n\t  (lshrsi3_m, lshrsi3_k, lshrsi3_n, lshrsi3_n, lshrsi3_media): Likewise.\n\t  (lshrsi3, ashldi3_k, ashldi3_mediai, lshrdi3_k): Likewise.\n\t  (ashrdi3_k, xtrct_left, xtrct_right, negc, *negdi_media): Likewise.\n\t  (negsi2, one_cmplsi2, one_cmpldi2, zero_extendsidi2): Likewise.\n\t  (*zero_extendhisi2_compact, *zero_extendqisi2_compact): Likewise.\n\t  (zero_extendqihi2, extendhisi2, *extendhisi2_compact): Likewise.\n\t  (extendqisi2, *extendqisi2_compact, extendqihi2): Likewise.\n\t  (movsi_const_16bit+1, *movdi_media_I16+1): Likewise.\n\t  (movdf_media_nofpu+1, movsf_media_nofpu+1, dect, movt, seq): Likewise.\n\t  (movnegt+1, divsf3_i): Likewise.\n\t  (xordi3): Use xor_operand operand predicate.\n\t  (ashlsi3_media): Use shift_count_operand operand predicate.\n\t  (ashrsi3_media, lshrsi3_media, ashldi3_media, lshrdi3_media): Likewise.\n\t  (ashrdi3_media): Likewise.\n\t  (ashrsi2_31+1): Use mov_neg_si_t.\n\t  (lshrdi3_media, ashrdi3_media): Use ext_dest_operand predicate.\n\t  Make sure that either the destination is not a subreg, or that the\n\t  shift generates a sufficient number of sign bit copies.\n\t  (*loaddi_trunc): Use any_register_operand predicate.\n\t  (ic_invalidate_line_sh4a): Likewise.\n\t  (*zero_extendhisi2_media+1): Use simplify_gen_subreg.\n\t  (*extendhisi2_media+1i, *extendqisi2_media+1): Likewise.\n\t  (extendsidi2): Add fmov.sl alternative.\n\t  (load_ra): Add mode for operand 1.\n\t  (*movsi_media): Discourage the use of floating point registers.\n\t  Allow TRUNCATE.\n\t  (*movsi_media_nofpu): Ignore target register alternative for register\n\t  preferencing.  Allow TRUNCATE.\n\t  (movsi_const_16bit+1): Use gen_movsi_const, and add an REG_EQUAL note.\n\t  (*movqi_media): Use extend_reg_or_0_operand predicate.\n\t  (*movdi_media): Ignore target register alternative for register\n\t  preferencing.  Discourage the use of floating point registers.\n\t  (*movdi_media_nofpu): Ignore target register alternative for register\n\t  preferencing.\n\t  (movdi_const_16bit+1): If the source is subregged from SImode,\n\t  sign-extend highpart.  Use ext_dest_operand predicate.\n\t  (movdi_const_16bit+2, shori_media): Use ext_dest_operand predicate.\n\t  (reload_outdf+7, reload_outdf+8): Check ALLOW_INDEXED_ADDRESS.\n\t  (stuff_delay_slot): Add modes for operands 0 and 1.\n\t  (*beq_media_i, *bgt_media_i): Add '>' to output templates.\n\t  (*blt_media_i, jump_media): Likewise.\n\t  (beq, bne): Pass through SImode inputs, and I06 constants.\n\t  (bgt, blt, ble, bge, bgtu): Pass through SImode inputs, the constant 0.\n\t  (bltu, bgeu, bleu): Likewise.\n\t  (GOTaddr2picreg): Don't call gen_datalabel_ref.\n\t  (ptrel): Rename to:\n\t  (ptrel_di).\n\t  (tls_global_dynamic, tls_local_dynamic): Add mode for call.\n\t  (seq): Properly support input modes other than DImode.\n\t  (slt, sle, sgt, sge,sne): Properly support SImode.\n\t  (addsf3_i, negdf2_i, sqrtdf2_i, absdf2_i): Use fp_arith_reg_operand.\n\t  (mac_media) Enable generator function generation.\n\t  (fix_truncsfdi2): Use fp_arith_reg_dest operand predicate.\n\t  (fix_truncdfdi2): Likewise.\n\t  (movv8qi_i+3): Enable for CONST0_RTX too.\n\t  (movv2hi_i): Use add.l, not addz.l.\n\t  (ashlv2si3, ashlv4hi3, lshrv2si3): Use shift_count_reg_operand.\n\t  (lshrv4hi3): Likewise.\n\t  (ussubv8qi3): Allow zero for operand 1.\n\t  (prefetch): Allow any mode for operand 0.  Enable for SHCOMPACT.\n\t  Use force_reg.\n\t  * config/sh/shmedia.md: (shmedia): Remove automaton declaration.\n\t  (sh5inst_pipe, sh5fpu_pipe): New automatons.\n\t  (sh5issue): Use sh5inst_pipe.\n\t  (sh5fds): Use sh5fpu_pipe.\n\t  (shmedia_fdiv, shmedia_dfdiv): Also use sh5issue.\n\t  * config/sh/sshmedia.h (sh_media_GETCON, sh_media_PUTCON): Declare\n\t  with always_inline Attribute.\n\t  * t-sh64 (LIB1ASMFUNCS): Add _div_table.\n\t  * config/sh/ushmedia.h (sh_media_MABS_L): Use builtin function.\n\t  (sh_media_MABS_W, sh_media_MADD_L, sh_media_MADD_W): Likewise.\n\t  (sh_media_MADDS_L, sh_media_MADDS_UB, sh_media_MADDS_W): Likewise.\n\t  (sh_media_MCMPEQ_B, sh_media_MCMPEQ_L, sh_media_MCMPEQ_W): Likewise.\n\t  (sh_media_MCMPGT_UB, sh_media_MCMPGT_L, sh_media_MCMPGT_W): Likewise.\n\t  (sh_media_MCMV, sh_media_MCNVS_LW, sh_media_MCNVS_WB): Likewise.\n\t  (sh_media_MCNVS_WUB, sh_media_MEXTR1, sh_media_MEXTR2): Likewise.\n\t  (sh_media_MEXTR3, sh_media_MEXTR4, sh_media_MEXTR5): Likewise.\n\t  (sh_media_MEXTR6, sh_media_MEXTR7, sh_media_MMACFX_WL): Likewise.\n\t  (sh_media_MMACNFX_WL, sh_media_MMUL_L, sh_media_MMUL_W): Likewise.\n\t  (sh_media_MMULFX_L, sh_media_MMULFX_W, sh_media_MMULFXRP_W): Likewise.\n\t  (sh_media_MMULHI_WL, sh_media_MMULLO_WL): Likewise.\n\t  (sh_media_MMULSUM_WQ, sh_media_MPERM_W, sh_media_MSAD_UBQ): Likewise.\n\t  (sh_media_MSHALDS_L, sh_media_MSHALDS_W, sh_media_MSHARD_L): Likewise.\n\t  (sh_media_MSHARD_W, sh_media_MSHARDS_Q, sh_media_MSHFHI_B): Likewise.\n\t  (sh_media_MSHFHI_L, sh_media_MSHFHI_W, sh_media_MSHFLO_B): Likewise.\n\t  (sh_media_MSHFLO_L, sh_media_MSHFLO_W, sh_media_MSHLLD_L): Likewise.\n\t  (sh_media_MSHLLD_W, sh_media_MSHLRD_L, sh_media_MSHLRD_W): Likewise.\n\t  (sh_media_MSUB_L, sh_media_MSUB_W, sh_media_MSUBS_L): Likewise.\n\t  (sh_media_MSUBS_UB, sh_media_MSUBS_W, sh_media_FABS_D): Likewise.\n\t  (sh_media_FABS_S, sh_media_FCMPUN_D, sh_media_FCMPUN_S): Likewise.\n\t  (sh_media_FIPR_S, sh_media_FMAC_S, sh_media_FSQRT_D): Likewise.\n\t  (sh_media_FSQRT_S, sh_media_FTRV_S, sh_media_LDHI_L): Likewise.\n\t  (sh_media_LDHI_Q, sh_media_LDLO_L, sh_media_LDLO_Q): Likewise.\n\t  (sh_media_STHI_L, sh_media_STHI_Q, sh_media_STLO_L): Likewise.\n\t  (sh_media_STLO_Q, sh_media_NSB, sh_media_BYTEREV): Likewise.\n\t  (sh_media_PREFO, sh_media_ALLOCO): Likewise.\n\t  (sh_media_FCOSA_S, sh_media_FSINA_S): New function.\n\t  (sh_media_FMOV_DQ, sh_media_FMOV_LS): Use union assignment.\n\t  (sh_media_FMOV_QD, sh_media_FMOV_SL): Likewise.\n\t  (sh_media_CMVEQ): Use C code. Add attribute always_inline.\n\t  (sh_media_CMVNE): Likewise.\n\t  (sh_media_ADDZ_L): Use C code.\n\t  (sh_media_unaligned_LD_L): Use intrinsics directly.\n\t  (sh_media_unaligned_LD_Q, sh_media_unaligned_ST_L): Likewise.\n\t  (sh_media_unaligned_ST_Q): Likewise.\n\t  * config/sh/divtab.c: New file.\n\n\t2005-04-06  Andrew Stubbs <andrew.stubbs@superh.com>\n\t\t    J\"orn Rennecke <joern.rennecke@superh.com>\n\n\t  * config/sh/superh64.h, config/sh/superh.h: New files.\n\t  * config/sh/newlib.h, config/sh/t-superh: Likewise.\n\t  * config.gcc: Add support for sh*-superh-elf* and sh64-superh-linux*.\n\ngcc/testsuite:\n\n2005-05-06  J\"orn Rennecke <joern.rennecke@st.com>\n\n\t* gcc.dg/pr15784-3.c: Add -fno-finite-math-only option.\n\n\t* gcc.dg/20021029-1.c: For sh64*-*-*, add -mpt-fixed.\n\nFrom-SVN: r99460", "tree": {"sha": "1c4460163b21563fa573216bf31246f144d5c158", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/1c4460163b21563fa573216bf31246f144d5c158"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "html_url": "https://github.com/Rust-GCC/gccrs/commit/73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/comments", "author": null, "committer": null, "parents": [{"sha": "ae156f850a09b8252c5d68fa7f2032057b85a66c", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ae156f850a09b8252c5d68fa7f2032057b85a66c", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ae156f850a09b8252c5d68fa7f2032057b85a66c"}], "stats": {"total": 8546, "additions": 6952, "deletions": 1594}, "files": [{"sha": "2fab84d0985993eded62e48ca75a8a61a13aba15", "filename": "gcc/config/sh/crt1.asm", "status": "modified", "additions": 1070, "deletions": 22, "changes": 1092, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fcrt1.asm", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fcrt1.asm", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fcrt1.asm?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -1,4 +1,4 @@\n-/* Copyright (C) 2000, 2001, 2003 Free Software Foundation, Inc.\n+/* Copyright (C) 2000, 2001, 2003, 2004 Free Software Foundation, Inc.\n    This file was pretty much copied from newlib.\n \n This file is part of GCC.\n@@ -27,6 +27,19 @@ along with this program; see the file COPYING.  If not, write to\n the Free Software Foundation, 59 Temple Place - Suite 330,\n Boston, MA 02111-1307, USA.  */\n \n+#ifdef MMU_SUPPORT\n+\t/* Section used for exception/timer interrupt stack area */\n+\t.section .data.vbr.stack,\"aw\"\n+\t.align 4\n+\t.global __ST_VBR\n+__ST_VBR:\n+\t.zero 1024 * 2          /* ; 2k for VBR handlers */\n+/* Label at the highest stack address where the stack grows from */\n+__timer_stack:\n+#endif /* MMU_SUPPORT */\n+\t\n+\t/* ;----------------------------------------\n+\tNormal newlib crt1.asm */\n \n #ifdef __SH5__\n \t.section .data,\"aw\"\n@@ -37,6 +50,89 @@ ___data:\n \t.global ___rodata\n ___rodata:\n \n+#define ICCR_BASE  0x01600000\n+#define OCCR_BASE  0x01e00000\n+#define MMUIR_BASE 0x00000000\n+#define MMUDR_BASE 0x00800000\n+\n+#define PTE_ENABLED     1\n+#define PTE_DISABLED    0\n+\n+#define PTE_SHARED (1 << 1)\n+#define PTE_NOT_SHARED  0\n+\n+#define PTE_CB_UNCACHEABLE  0\n+#define PTE_CB_DEVICE       1\n+#define PTE_CB_CACHEABLE_WB 2\n+#define PTE_CB_CACHEABLE_WT 3\n+\n+#define PTE_SZ_4KB   (0 << 3)\n+#define PTE_SZ_64KB  (1 << 3)\n+#define PTE_SZ_1MB   (2 << 3)\n+#define PTE_SZ_512MB (3 << 3)\n+\n+#define PTE_PRR      (1 << 6)\n+#define PTE_PRX      (1 << 7)\n+#define PTE_PRW      (1 << 8)\n+#define PTE_PRU      (1 << 9)\n+\n+#define SR_MMU_BIT          31\n+#define SR_BL_BIT           28\n+\n+#define ALIGN_4KB  (0xfff)\n+#define ALIGN_1MB  (0xfffff)\n+#define ALIGN_512MB (0x1fffffff)\n+\n+#define DYNACON_BASE               0x0f000000\n+#define DM_CB_DLINK_BASE           0x0c000000\n+#define DM_DB_DLINK_BASE           0x0b000000\n+\n+#define FEMI_AREA_0                0x00000000\n+#define FEMI_AREA_1                0x04000000\n+#define FEMI_AREA_2                0x05000000\n+#define FEMI_AREA_3                0x06000000\n+#define FEMI_AREA_4                0x07000000\n+#define FEMI_CB                    0x08000000\n+\n+#define EMI_BASE                   0X80000000\n+\n+#define DMA_BASE                   0X0e000000\n+\n+#define CPU_BASE                   0X0d000000\n+\n+#define PERIPH_BASE                0X09000000\n+#define DMAC_BASE                  0x0e000000\n+#define INTC_BASE                  0x0a000000\n+#define CPRC_BASE                  0x0a010000\n+#define TMU_BASE                   0x0a020000\n+#define SCIF_BASE                  0x0a030000\n+#define RTC_BASE                   0x0a040000\n+\n+\n+\n+#define LOAD_CONST32(val, reg) \\\n+\tmovi\t((val) >> 16) & 65535, reg; \\\n+\tshori\t(val) & 65535, reg\n+\n+#define LOAD_PTEH_VAL(sym, align, bits, scratch_reg, reg) \\\n+\tLOAD_ADDR (sym, reg); \\\n+\tLOAD_CONST32 ((align), scratch_reg); \\\n+\tandc\treg, scratch_reg, reg; \\\n+\tLOAD_CONST32 ((bits), scratch_reg); \\\n+\tor\treg, scratch_reg, reg\n+\n+#define LOAD_PTEL_VAL(sym, align, bits, scratch_reg, reg) \\\n+\tLOAD_ADDR (sym, reg); \\\n+\tLOAD_CONST32 ((align), scratch_reg); \\\n+\tandc\treg, scratch_reg, reg; \\\n+\tLOAD_CONST32 ((bits), scratch_reg); \\\n+\tor\treg, scratch_reg, reg\n+\n+#define SET_PTE(pte_addr_reg, pteh_val_reg, ptel_val_reg) \\\n+\tputcfg  pte_addr_reg, 0, r63; \\\n+\tputcfg  pte_addr_reg, 1, ptel_val_reg; \\\n+\tputcfg  pte_addr_reg, 0, pteh_val_reg\n+\n #if __SH5__ == 64\n \t.section .text,\"ax\"\n #define LOAD_ADDR(sym, reg) \\\n@@ -55,8 +151,279 @@ ___rodata:\n start:\n \tLOAD_ADDR (_stack, r15)\n \n+#ifdef MMU_SUPPORT\n+\t! Set up the VM using the MMU and caches\n+\n+\t! .vm_ep is first instruction to execute\n+\t! after VM initialization\n+\tpt/l\t.vm_ep, tr1\n+\t\n+\t! Configure instruction cache (ICCR)\n+\tmovi\t3, r2\n+\tmovi\t0, r3\n+\tLOAD_ADDR (ICCR_BASE, r1)\n+\tputcfg\tr1, 0, r2\n+\tputcfg\tr1, 1, r3\n+\n+\t! movi\t7, r2 ! write through\n+\t! Configure operand cache (OCCR)\n+\tLOAD_ADDR (OCCR_BASE, r1)\n+\tputcfg\tr1, 0, r2\n+\tputcfg\tr1, 1, r3\n+\n+\t! Disable all PTE translations\n+\tLOAD_ADDR (MMUIR_BASE, r1)\n+\tLOAD_ADDR (MMUDR_BASE, r2)\n+\tmovi\t64, r3\n+\tpt/l\t.disable_ptes_loop, tr0\n+.disable_ptes_loop:\n+\tputcfg\tr1, 0, r63\n+\tputcfg\tr2, 0, r63\n+\taddi\tr1, 16, r1\n+\taddi\tr2, 16, r2\n+\taddi\tr3, -1, r3\n+\tbgt\tr3, r63, tr0\n+\n+\tLOAD_ADDR (MMUIR_BASE, r1)\n+\n+\t! FEMI instruction mappings\n+\t!   Area 0 - 1Mb cacheable at 0x00000000\n+\t!   Area 1 - None\n+\t!   Area 2 - 1Mb cacheable at 0x05000000\n+\t!          - 1Mb cacheable at 0x05100000\n+\t!   Area 3 - None\n+\t!   Area 4 - None\n+\n+\t! Map a 1Mb page for instructions at 0x00000000\n+\tLOAD_PTEH_VAL (FEMI_AREA_0, ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (FEMI_AREA_0, ALIGN_1MB, PTE_CB_CACHEABLE_WB | PTE_SZ_1MB | PTE_PRX | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 1Mb page for instructions at 0x05000000\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (FEMI_AREA_2, ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (FEMI_AREA_2, ALIGN_1MB, PTE_CB_CACHEABLE_WB | PTE_SZ_1MB | PTE_PRX | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 1Mb page for instructions at 0x05100000\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL ((FEMI_AREA_2+0x100000), ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL ((FEMI_AREA_2+0x100000), ALIGN_1MB, PTE_CB_CACHEABLE_WB | PTE_SZ_1MB | PTE_PRX | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 512M page for instructions at EMI base\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (EMI_BASE, ALIGN_512MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (EMI_BASE, ALIGN_512MB, PTE_CB_CACHEABLE_WB | PTE_SZ_512MB | PTE_PRX | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 4K page for instructions at DM_DB_DLINK_BASE\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (DM_DB_DLINK_BASE, ALIGN_4KB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (DM_DB_DLINK_BASE, ALIGN_4KB, PTE_CB_CACHEABLE_WB | PTE_SZ_4KB | PTE_PRX | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\tLOAD_ADDR (MMUDR_BASE, r1)\n+\n+\t! FEMI data mappings\n+\t!   Area 0 - 1Mb cacheable at 0x00000000\n+\t!   Area 1 - 1Mb device at 0x04000000\n+\t!   Area 2 - 1Mb cacheable at 0x05000000\n+\t!          - 1Mb cacheable at 0x05100000\n+\t!   Area 3 - None\n+\t!   Area 4 - None\n+\t!   CB     - 1Mb device at 0x08000000\n+\n+\t! Map a 1Mb page for data at 0x00000000\n+\tLOAD_PTEH_VAL (FEMI_AREA_0, ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (FEMI_AREA_0, ALIGN_1MB, PTE_CB_CACHEABLE_WB | PTE_SZ_1MB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 1Mb page for data at 0x04000000\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (FEMI_AREA_1, ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (FEMI_AREA_1, ALIGN_1MB, PTE_CB_DEVICE | PTE_SZ_1MB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 1Mb page for data at 0x05000000\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (FEMI_AREA_2, ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (FEMI_AREA_2, ALIGN_1MB, PTE_CB_CACHEABLE_WB | PTE_SZ_1MB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 1Mb page for data at 0x05100000\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL ((FEMI_AREA_2+0x100000), ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL ((FEMI_AREA_2+0x100000), ALIGN_1MB, PTE_CB_CACHEABLE_WB | PTE_SZ_1MB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 4K page for registers at 0x08000000\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (FEMI_CB, ALIGN_4KB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (FEMI_CB, ALIGN_4KB, PTE_CB_DEVICE | PTE_SZ_4KB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 512M page for data at EMI\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (EMI_BASE, ALIGN_512MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (EMI_BASE, ALIGN_512MB, PTE_CB_CACHEABLE_WB | PTE_SZ_512MB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 4K page for DYNACON at DYNACON_BASE\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (DYNACON_BASE, ALIGN_4KB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (DYNACON_BASE, ALIGN_4KB, PTE_CB_DEVICE | PTE_SZ_4KB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 4K page for instructions at DM_DB_DLINK_BASE\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (DM_DB_DLINK_BASE, ALIGN_4KB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (DM_DB_DLINK_BASE, ALIGN_4KB, PTE_CB_CACHEABLE_WB | PTE_SZ_4KB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 4K page for data at DM_DB_DLINK_BASE+0x1000\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL ((DM_DB_DLINK_BASE+0x1000), ALIGN_4KB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL ((DM_DB_DLINK_BASE+0x1000), ALIGN_4KB, PTE_CB_UNCACHEABLE | PTE_SZ_4KB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 4K page for stack DM_DB_DLINK_BASE+0x2000\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL ((DM_DB_DLINK_BASE+0x2000), ALIGN_4KB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL ((DM_DB_DLINK_BASE+0x2000), ALIGN_4KB, PTE_CB_CACHEABLE_WB | PTE_SZ_4KB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 1M page for DM_CB_BASE2 at DM_CB_DLINK \n+\t! 0x0c000000 - 0x0c0fffff\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (DM_CB_DLINK_BASE, ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (DM_CB_DLINK_BASE, ALIGN_1MB, PTE_CB_DEVICE | PTE_SZ_1MB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 1M page for DM_CB_BASE2 at DM_CB_DLINK \n+\t! 0x0c100000 - 0x0c1fffff\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL ((DM_CB_DLINK_BASE+0x100000), ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL ((DM_CB_DLINK_BASE+0x100000), ALIGN_1MB, PTE_CB_DEVICE | PTE_SZ_1MB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 1M page for DM_CB_BASE2 at DM_CB_DLINK \n+\t! 0x0c200000 - 0x0c2fffff\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL ((DM_CB_DLINK_BASE+0x200000), ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL ((DM_CB_DLINK_BASE+0x200000), ALIGN_1MB, PTE_CB_DEVICE | PTE_SZ_1MB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 1M page for DM_CB_BASE2 at DM_CB_DLINK \n+\t! 0x0c400000 - 0x0c4fffff\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL ((DM_CB_DLINK_BASE+0x400000), ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL ((DM_CB_DLINK_BASE+0x400000), ALIGN_1MB, PTE_CB_DEVICE | PTE_SZ_1MB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 1M page for DM_CB_BASE2 at DM_CB_DLINK \n+\t! 0x0c800000 - 0x0c8fffff\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL ((DM_CB_DLINK_BASE+0x800000), ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL ((DM_CB_DLINK_BASE+0x800000), ALIGN_1MB, PTE_CB_DEVICE | PTE_SZ_1MB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map a 4K page for DMA control registers\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (DMA_BASE, ALIGN_4KB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (DMA_BASE, ALIGN_4KB, PTE_CB_DEVICE | PTE_SZ_4KB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map lots of 4K pages for peripherals\n+\n+\t! /* peripheral */\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (PERIPH_BASE, ALIGN_4KB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (PERIPH_BASE, ALIGN_4KB, PTE_CB_DEVICE | PTE_SZ_4KB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\t! /* dmac */\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (DMAC_BASE, ALIGN_4KB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (DMAC_BASE, ALIGN_4KB, PTE_CB_DEVICE | PTE_SZ_4KB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\t! /* intc */\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (INTC_BASE, ALIGN_4KB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (INTC_BASE, ALIGN_4KB, PTE_CB_DEVICE | PTE_SZ_4KB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\t! /* rtc */\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (RTC_BASE, ALIGN_4KB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (RTC_BASE, ALIGN_4KB, PTE_CB_DEVICE | PTE_SZ_4KB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\t! /* dmac */\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (TMU_BASE, ALIGN_4KB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (TMU_BASE, ALIGN_4KB, PTE_CB_DEVICE | PTE_SZ_4KB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\t! /* scif */\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (SCIF_BASE, ALIGN_4KB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (SCIF_BASE, ALIGN_4KB, PTE_CB_DEVICE | PTE_SZ_4KB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\t! /* cprc */\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (CPRC_BASE, ALIGN_4KB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (CPRC_BASE, ALIGN_4KB, PTE_CB_DEVICE | PTE_SZ_4KB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Map CPU WPC registers \n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL (CPU_BASE, ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL (CPU_BASE, ALIGN_1MB, PTE_CB_DEVICE | PTE_SZ_1MB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\taddi\tr1, 16, r1\n+\n+\tLOAD_PTEH_VAL ((CPU_BASE+0x100000), ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL ((CPU_BASE+0x100000), ALIGN_1MB, PTE_CB_DEVICE | PTE_SZ_1MB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL ((CPU_BASE+0x200000), ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL ((CPU_BASE+0x200000), ALIGN_1MB, PTE_CB_DEVICE | PTE_SZ_1MB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\taddi\tr1, 16, r1\n+\tLOAD_PTEH_VAL ((CPU_BASE+0x400000), ALIGN_1MB, PTE_ENABLED | PTE_NOT_SHARED, r25, r2)\n+\tLOAD_PTEL_VAL ((CPU_BASE+0x400000), ALIGN_1MB, PTE_CB_DEVICE | PTE_SZ_1MB | PTE_PRR | PTE_PRW | PTE_PRU, r25, r3)\n+\tSET_PTE (r1, r2, r3)\n+\n+\t! Switch over to virtual addressing and enabled cache\n+\tgetcon\tsr, r1\n+\tmovi\t1, r2\n+\tshlli\tr2, SR_BL_BIT, r2\n+\tor\tr1, r2, r1\n+\tputcon\tr1, ssr\n+\tgetcon\tsr, r1\n+\tmovi\t1, r2\n+\tshlli\tr2, SR_MMU_BIT, r2\n+\tor\tr1, r2, r1\n+\tputcon\tr1, ssr\n+\tgettr\ttr1, r1\n+\tputcon\tr1, spc\n+\tsynco\n+\trte\n+\n+\t! VM entry point.  From now on, we are in VM mode.\n+.vm_ep:\n+\n+\t! Install the trap handler, by seeding vbr with the\n+\t! correct value, and by assigning sr.bl = 0.\n+\n+\tLOAD_ADDR (vbr_start, r1)\n+\tputcon\tr1, vbr\n+\tmovi\t~(1<<28), r1\n+\tgetcon\tsr, r2\n+\tand     r1, r2, r2\n+\tputcon\tr2, sr\n+#endif /* MMU_SUPPORT */\n+\n \tpt/l\t.Lzero_bss_loop, tr0\n-\tpt/l\t_atexit, tr1\n \tpt/l\t_init, tr5\n \tpt/l\t___setup_argv_and_call_main, tr6\n \tpt/l\t_exit, tr7\n@@ -72,22 +439,23 @@ start:\n \tLOAD_ADDR (___data, r26)\n \tLOAD_ADDR (___rodata, r27)\n \n-#if ! __SH4_NOFPU__ && ! __SH2A_NOFPU__\n-#if __SH5__ == 32\n-\tpt/l ___set_fpscr, tr0\n-\tmovi\t0, r4\n-\tblink\ttr0, r18\n-#endif\n+#ifdef __SH_FPU_ANY__\n \tgetcon\tsr, r0\n \t! enable the FP unit, by resetting SR.FD\n \t! also zero out SR.FR, SR.SZ and SR.PR, as mandated by the ABI\n \tmovi\t0, r1\n \tshori\t0xf000, r1\n \tandc\tr0, r1, r0\n \tputcon\tr0, sr\n+#if __SH5__ == 32\n+\tpt/l ___set_fpscr, tr0\n+\tmovi\t0, r4\n+\tblink\ttr0, r18\n+#endif\n #endif\n \n \t! arrange for exit to call fini\n+\tpt/l\t_atexit, tr1\n \tLOAD_ADDR (_fini, r2)\n \tblink\ttr1, r18\n \n@@ -99,13 +467,253 @@ start:\n \n \t! call exit\n \tblink\ttr7, r18\n+\t! We should never return from _exit but in case we do we would enter the\n+\t! the following tight loop. This avoids executing any data that might follow.\n+limbo:\n+\tpt/l limbo, tr0\n+\tblink tr0, r63\n \t\n-#else\n+#ifdef MMU_SUPPORT\n+\t! All these traps are handled in the same place. \n+\t.balign 256\n+vbr_start:\n+\tpt/l handler, tr0\t! tr0 trashed.\n+\tblink tr0, r63\n+\t.balign 256\n+vbr_100:\n+\tpt/l handler, tr0\t! tr0 trashed.\n+\tblink tr0, r63\n+vbr_100_end:\n+\t.balign 256\n+vbr_200:\n+\tpt/l handler, tr0\t! tr0 trashed.\n+\tblink tr0, r63\n+\t.balign 256\n+vbr_300:\n+\tpt/l handler, tr0\t! tr0 trashed.\n+\tblink tr0, r63\n+\t.balign 256\t\n+vbr_400:\t! Should be at vbr+0x400\n+handler:\n+\t/* If the trap handler is there call it */\n+\tLOAD_ADDR (__superh_trap_handler, r2)\n+\tpta chandler,tr2\n+\tbeq r2, r63, tr2 /* If zero, ie not present branch around to chandler */\n+\t/* Now call the trap handler with as much of the context unchanged as possible.\n+\t   Move trapping address into R18 to make it look like the trap point */\n+\tgetcon spc, r18\n+\tpt/l __superh_trap_handler, tr0\n+\tblink tr0, r7\n+chandler:\t\n+\tgetcon\tspc, r62\n+\tgetcon expevt, r2\n+\tpt/l\t_exit, tr0\n+\tblink\ttr0, r63\n+\n+\t/* Simulated trap handler */\n+\t.section\t.text..SHmedia32,\"ax\"\n+gcc2_compiled.:\n+\t.section\t.debug_abbrev\n+.Ldebug_abbrev0:\n+\t.section\t.text..SHmedia32\n+.Ltext0:\n+\t.section\t.debug_info\n+.Ldebug_info0:\n+\t.section\t.debug_line\n+.Ldebug_line0:\n+\t.section\t.text..SHmedia32,\"ax\"\n+\t.align 5\n+\t.global\t__superh_trap_handler\n+\t.type\t__superh_trap_handler,@function\n+__superh_trap_handler:\n+.LFB1:\n+\tptabs\tr18, tr0\n+\taddi.l\tr15, -8, r15\n+\tst.l\tr15, 4, r14\n+\taddi.l\tr15, -8, r15\n+\tadd.l\tr15, r63, r14\n+\tst.l\tr14, 0, r2\n+\t ptabs r7, tr0 \n+\taddi.l\tr14, 8, r14\n+\tadd.l\tr14, r63, r15\n+\tld.l\tr15, 4, r14\n+\taddi.l\tr15, 8, r15\n+\tblink\ttr0, r63\n+.LFE1:\n+.Lfe1:\n+\t.size\t__superh_trap_handler,.Lfe1-__superh_trap_handler\n+\n+\t.section\t.text..SHmedia32\n+.Letext0:\n+\n+\t.section\t.debug_info\n+\t.ualong\t0xa7\n+\t.uaword\t0x2\n+\t.ualong\t.Ldebug_abbrev0\n+\t.byte\t0x4\n+\t.byte\t0x1\n+\t.ualong\t.Ldebug_line0\n+\t.ualong\t.Letext0\n+\t.ualong\t.Ltext0\n+\t.string\t\"trap_handler.c\"\n+\n+\t.string\t\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n+\n+\t.string\t\"GNU C 2.97-sh5-010522\"\n+\n+\t.byte\t0x1\n+\t.byte\t0x2\n+\t.ualong\t0x9a\n+\t.byte\t0x1\n+\t.string\t\"_superh_trap_handler\"\n+\n+\t.byte\t0x1\n+\t.byte\t0x2\n+\t.byte\t0x1\n+\t.ualong\t.LFB1\n+\t.ualong\t.LFE1\n+\t.byte\t0x1\n+\t.byte\t0x5e\n+\t.byte\t0x3\n+\t.string\t\"trap_reason\"\n+\n+\t.byte\t0x1\n+\t.byte\t0x1\n+\t.ualong\t0x9a\n+\t.byte\t0x2\n+\t.byte\t0x91\n+\t.byte\t0x0\n+\t.byte\t0x0\n+\t.byte\t0x4\n+\t.string\t\"unsigned int\"\n+\n+\t.byte\t0x4\n+\t.byte\t0x7\n+\t.byte\t0x0\n+\n+\t.section\t.debug_abbrev\n+\t.byte\t0x1\n+\t.byte\t0x11\n+\t.byte\t0x1\n+\t.byte\t0x10\n+\t.byte\t0x6\n+\t.byte\t0x12\n+\t.byte\t0x1\n+\t.byte\t0x11\n+\t.byte\t0x1\n+\t.byte\t0x3\n+\t.byte\t0x8\n+\t.byte\t0x1b\n+\t.byte\t0x8\n+\t.byte\t0x25\n+\t.byte\t0x8\n+\t.byte\t0x13\n+\t.byte\t0xb\n+\t.byte\t0,0\n+\t.byte\t0x2\n+\t.byte\t0x2e\n+\t.byte\t0x1\n+\t.byte\t0x1\n+\t.byte\t0x13\n+\t.byte\t0x3f\n+\t.byte\t0xc\n+\t.byte\t0x3\n+\t.byte\t0x8\n+\t.byte\t0x3a\n+\t.byte\t0xb\n+\t.byte\t0x3b\n+\t.byte\t0xb\n+\t.byte\t0x27\n+\t.byte\t0xc\n+\t.byte\t0x11\n+\t.byte\t0x1\n+\t.byte\t0x12\n+\t.byte\t0x1\n+\t.byte\t0x40\n+\t.byte\t0xa\n+\t.byte\t0,0\n+\t.byte\t0x3\n+\t.byte\t0x5\n+\t.byte\t0x0\n+\t.byte\t0x3\n+\t.byte\t0x8\n+\t.byte\t0x3a\n+\t.byte\t0xb\n+\t.byte\t0x3b\n+\t.byte\t0xb\n+\t.byte\t0x49\n+\t.byte\t0x13\n+\t.byte\t0x2\n+\t.byte\t0xa\n+\t.byte\t0,0\n+\t.byte\t0x4\n+\t.byte\t0x24\n+\t.byte\t0x0\n+\t.byte\t0x3\n+\t.byte\t0x8\n+\t.byte\t0xb\n+\t.byte\t0xb\n+\t.byte\t0x3e\n+\t.byte\t0xb\n+\t.byte\t0,0\n+\t.byte\t0\n+\n+\t.section\t.debug_pubnames\n+\t.ualong\t0x27\n+\t.uaword\t0x2\n+\t.ualong\t.Ldebug_info0\n+\t.ualong\t0xab\n+\t.ualong\t0x5b\n+\t.string\t\"_superh_trap_handler\"\n+\n+\t.ualong\t0x0\n+\n+\t.section\t.debug_aranges\n+\t.ualong\t0x1c\n+\t.uaword\t0x2\n+\t.ualong\t.Ldebug_info0\n+\t.byte\t0x4\n+\t.byte\t0x0\n+\t.uaword\t0x0,0\n+\t.ualong\t.Ltext0\n+\t.ualong\t.Letext0-.Ltext0\n+\t.ualong\t0x0\n+\t.ualong\t0x0\n+\t.ident\t\"GCC: (GNU) 2.97-sh5-010522\"\n+#endif /* MMU_SUPPORT */\n+#else /* ! __SH5__ */\n+\n+\t! make a place to keep any previous value of the vbr register\n+\t! this will only have a value if it has been set by redboot (for example)\n+\t.section .bss\n+old_vbr:\n+\t.long 0\n+\n \t.section .text\n \t.global\tstart\n+\t.import ___rtos_profiler_start_timer\n+\t.weak   ___rtos_profiler_start_timer\n start:\n \tmov.l\tstack_k,r15\n \n+#if defined (__SH3__) || (defined (__SH_FPU_ANY__) && ! defined (__SH2A__)) || defined (__SH4_NOFPU__)\n+#define VBR_SETUP\n+\t! before zeroing the bss ...\n+\t! if the vbr is already set to vbr_start then the program has been restarted\n+\t! (i.e. it is not the first time the program has been run since reset)\n+\t! reset the vbr to its old value before old_vbr (in bss) is wiped\n+\t! this ensures that the later code does not create a circular vbr chain\n+\tstc\tvbr, r1\n+\tmov.l\tvbr_start_k, r2\n+\tcmp/eq\tr1, r2\n+\tbf\t0f\n+\t! reset the old vbr value\n+\tmov.l\told_vbr_k, r1\n+\tmov.l\t@r1, r2\n+\tldc\tr2, vbr\n+0:\t\n+#endif /* VBR_SETUP */\n+\t\n \t! zero out bss\n \tmov.l\tedata_k,r0\n \tmov.l\tend_k,r1\n@@ -116,14 +724,39 @@ start_l:\n \tcmp/ge\tr0,r1\n \tbt\tstart_l\n \n-#if ! __SH2A_NOFPU__\n-#if defined (__SH2E__) || defined (__SH2A__) || defined (__SH3E__) || defined(__SH4_SINGLE__) || defined(__SH4__) || defined(__SH4_SINGLE_ONLY__)\n+#if defined (__SH_FPU_ANY__)\n \tmov.l set_fpscr_k, r1\n+\tmov #4,r4\n \tjsr @r1\n-\tmov #0,r4\n-\tlds r3,fpscr\n-#endif /*  defined (__SH2E__) || defined (__SH2A__) || defined (__SH3E__) || defined(__SH4_SINGLE__) || defined(__SH4__) || defined(__SH4_SINGLE_ONLY__) */\n-#endif /* ! __SH2A_NOFPU__ */\n+\tshll16 r4\t! Set DN bit (flush denormal inputs to zero)\n+\tlds r3,fpscr\t! Switch to default precision\n+#endif /* defined (__SH_FPU_ANY__) */\n+\n+#ifdef VBR_SETUP\n+\t! save the existing contents of the vbr\n+\t! there will only be a prior value when using something like redboot\n+\t! otherwise it will be zero\n+\tstc\tvbr, r1\n+\tmov.l\told_vbr_k, r2\n+\tmov.l\tr1, @r2\n+\t! setup vbr\n+\tmov.l\tvbr_start_k, r1\n+\tldc\tr1,vbr\n+#endif /* VBR_SETUP */\n+\n+\t! if an rtos is exporting a timer start fn,\n+\t! then pick up an SR which does not enable ints\n+\t! (the rtos will take care of this)\n+\tmov.l rtos_start_fn, r0\n+\tmov.l sr_initial_bare, r1\n+\ttst\tr0, r0\n+\tbt\tset_sr\n+\n+\tmov.l sr_initial_rtos, r1\n+\n+set_sr:\n+\t! Set status register (sr)\n+\tldc\tr1, sr\n \n \t! arrange for exit to call fini\n \tmov.l\tatexit_k,r0\n@@ -146,14 +779,12 @@ start_l:\n \tmov.l\texit_k,r0\n \tjsr\t@r0\n \tnop\n-\n+\t\n \t.align 2\n-#if ! __SH2A_NOFPU__\n-#if defined (__SH2E__) || defined (__SH2A__) || defined (__SH3E__) || defined(__SH4_SINGLE__) || defined(__SH4__) || defined(__SH4_SINGLE_ONLY__)\n+#if defined (__SH_FPU_ANY__)\n set_fpscr_k:\n \t.long\t___set_fpscr\n-#endif /*  defined (__SH2E__) || defined (__SH2A__) || defined (__SH3E__) || defined(__SH4_SINGLE__) || defined(__SH4__) || defined(__SH4_SINGLE_ONLY__) */\n-#endif /* ! __SH2A_NOFPU__ */\n+#endif /*  defined (__SH_FPU_ANY__) */\n \n stack_k:\n \t.long\t_stack\t\n@@ -171,11 +802,428 @@ init_k:\n \t.long\t_init\n fini_k:\n \t.long\t_fini\n+#ifdef VBR_SETUP\n+old_vbr_k:\n+\t.long\told_vbr\n+vbr_start_k:\n+\t.long\tvbr_start\n+#endif /* VBR_SETUP */\n+\t\n+sr_initial_rtos:\n+\t! Privileged mode RB 1 BL 0. Keep BL 0 to allow default trap handlers to work.\n+\t! Whether profiling or not, keep interrupts masked,\n+\t! the RTOS will enable these if required.\n+\t.long 0x600000f1 \n+\n+rtos_start_fn:\n+\t.long ___rtos_profiler_start_timer\n+\t\n+sr_initial_bare:\n+\t! Privileged mode RB 1 BL 0. Keep BL 0 to allow default trap handlers to work.\n+\t! Keep interrupts disabled - the application will enable as required.\n+\t.long 0x600000f1\n \n \t! supplied for backward compatibility only, in case of linking\n \t! code whose main() was compiled with an older version of GCC.\n-\t.global\t___main\n+\t.global ___main\n ___main:\n \trts\n \tnop\n-#endif\n+#ifdef VBR_SETUP\n+! Exception handlers\t\n+\t.balign 256\n+vbr_start:\n+\tmov.l 2f, r0     ! load the old vbr setting (if any)\n+\tmov.l @r0, r0\n+\tcmp/eq #0, r0\n+\tbf 1f\n+\t! no previous vbr - jump to own generic handler\n+\tbra handler\n+\tnop\n+1:\t! there was a previous handler - chain them\n+\tjmp @r0\n+\tnop\n+\t.balign 4\n+2:\n+\t.long old_vbr\n+\n+\t.balign 256\n+vbr_100:\n+\t! Non profiling case.\n+handler_100:\n+\tmov.l 2f, r0     ! load the old vbr setting (if any)\n+\tmov.l @r0, r0\n+\tcmp/eq #0, r0\n+\tbf 1f\n+\t! no previous vbr - jump to own generic handler\n+\tbra handler\n+\tnop\t\n+1:\t! there was a previous handler - chain them\n+\tadd #0x7f, r0\t ! 0x7f\n+\tadd #0x7f, r0\t ! 0xfe\n+\tadd #0x2, r0     ! add 0x100 without corrupting another register\n+\tjmp @r0\n+\tnop\n+\t.balign 4\n+2:\t\n+\t.long old_vbr\n+\n+\t.balign 256\n+vbr_200:\n+\tmov.l 2f, r0     ! load the old vbr setting (if any)\n+\tmov.l @r0, r0\n+\tcmp/eq #0, r0\n+\tbf 1f\n+\t! no previous vbr - jump to own generic handler\n+\tbra handler\n+\tnop\t\n+1:\t! there was a previous handler - chain them\n+\tadd #0x7f, r0\t ! 0x7f\n+\tadd #0x7f, r0\t ! 0xfe\n+\tadd #0x7f, r0\t ! 0x17d\n+\tadd #0x7f, r0    ! 0x1fc\n+\tadd #0x4, r0     ! add 0x200 without corrupting another register\n+\tjmp @r0\n+\tnop\n+\t.balign 4\n+2:\n+\t.long old_vbr\n+\n+\t.balign 256\n+vbr_300:\n+\tmov.l 2f, r0     ! load the old vbr setting (if any)\n+\tmov.l @r0, r0\n+\tcmp/eq #0, r0\n+\tbf 1f\n+\t! no previous vbr - jump to own generic handler\n+\tbra handler\n+\tnop\t\n+1:\t! there was a previous handler - chain them\n+\tadd #0x7f, r0\t ! 0x7f\n+\tadd #0x7f, r0\t ! 0xfe\n+\tadd #0x7f, r0\t ! 0x17d\n+\tadd #0x7f, r0    ! 0x1fc\n+\tadd #0x7f, r0\t ! 0x27b\n+\tadd #0x7f, r0    ! 0x2fa\n+\tadd #0x6, r0     ! add 0x300 without corrupting another register\n+\tjmp @r0\n+\tnop\n+\t.balign 4\n+2:\n+\t.long old_vbr\n+\n+\t.balign 256\t\n+vbr_400:\t! Should be at vbr+0x400\n+\tmov.l 2f, r0     ! load the old vbr setting (if any)\n+\tmov.l @r0, r0\n+\tcmp/eq #0, r0\n+\t! no previous vbr - jump to own generic handler\n+\tbt handler\n+\t! there was a previous handler - chain them\n+\tadd #0x7f, r0\t ! 0x7f\n+\tadd #0x7f, r0\t ! 0xfe\n+\tadd #0x7f, r0\t ! 0x17d\n+\tadd #0x7f, r0    ! 0x1fc\n+\tadd #0x7f, r0\t ! 0x27b\n+\tadd #0x7f, r0    ! 0x2fa\n+\tadd #0x7f, r0\t ! 0x379\n+\tadd #0x7f, r0    ! 0x3f8\n+\tadd #0x8, r0     ! add 0x400 without corrupting another register\n+\tjmp @r0\n+\tnop\n+\t.balign 4\n+2:\n+\t.long old_vbr\n+handler:\n+\t/* If the trap handler is there call it */\n+\tmov.l\tsuperh_trap_handler_k, r0\n+\tcmp/eq\t#0, r0       ! True if zero.\n+\tbf 3f\n+\tbra   chandler\n+\tnop\n+3:\t\n+\t! Here handler available, call it. \n+\t/* Now call the trap handler with as much of the context unchanged as possible.\n+\t   Move trapping address into PR to make it look like the trap point */\n+\tstc spc, r1\n+\tlds r1, pr\n+\tmov.l expevt_k, r4\n+\tmov.l @r4, r4 ! r4 is value of expevt, first parameter.\n+\tmov r1, r5   ! Remember trapping pc.\n+\tmov r1, r6   ! Remember trapping pc.\n+\tmov.l chandler_k, r1\n+\tmov.l superh_trap_handler_k, r2\n+\t! jmp to trap handler to avoid disturbing pr. \n+\tjmp @r2\n+\tnop\n+\n+\t.balign 256\n+vbr_500:\n+\tmov.l 2f, r0     ! load the old vbr setting (if any)\n+\tmov.l @r0, r0\n+\tcmp/eq #0, r0\n+\t! no previous vbr - jump to own generic handler\n+\tbt handler\n+\t! there was a previous handler - chain them\n+\tadd #0x7f, r0\t ! 0x7f\n+\tadd #0x7f, r0\t ! 0xfe\n+\tadd #0x7f, r0\t ! 0x17d\n+\tadd #0x7f, r0    ! 0x1fc\n+\tadd #0x7f, r0\t ! 0x27b\n+\tadd #0x7f, r0    ! 0x2fa\n+\tadd #0x7f, r0\t ! 0x379\n+\tadd #0x7f, r0    ! 0x3f8\n+\tadd #0x7f, r0\t ! 0x477\n+\tadd #0x7f, r0    ! 0x4f6\n+\tadd #0xa, r0     ! add 0x500 without corrupting another register\n+\tjmp @r0\n+\tnop\n+\t.balign 4\n+2:\n+\t.long old_vbr\n+\n+\t.balign 256\n+vbr_600:\n+\tmov.l 2f, r0     ! load the old vbr setting (if any)\n+\tmov.l @r0, r0\n+\tcmp/eq #0, r0\n+\t! no previous vbr - jump to own handler\n+\tbt chandler\n+\t! there was a previous handler - chain them\n+\tadd #0x7f, r0\t ! 0x7f\n+\tadd #0x7f, r0\t ! 0xfe\n+\tadd #0x7f, r0\t ! 0x17d\n+\tadd #0x7f, r0    ! 0x1fc\n+\tadd #0x7f, r0\t ! 0x27b\n+\tadd #0x7f, r0    ! 0x2fa\n+\tadd #0x7f, r0\t ! 0x379\n+\tadd #0x7f, r0    ! 0x3f8\n+\tadd #0x7f, r0\t ! 0x477\n+\tadd #0x7f, r0    ! 0x4f6\n+\tadd #0x7f, r0\t ! 0x575\n+\tadd #0x7f, r0    ! 0x5f4\n+\tadd #0xc, r0     ! add 0x600 without corrupting another register\n+\tjmp @r0\n+\tnop\n+\t.balign 4\n+2:\n+\t.long old_vbr\n+chandler:\n+\tmov.l expevt_k, r4\n+\tmov.l @r4, r4 ! r4 is value of expevt hence making this the return code\n+\tmov.l handler_exit_k,r0\n+\tjsr   @r0\n+\tnop\n+\t! We should never return from _exit but in case we do we would enter the\n+\t! the following tight loop\n+limbo:\n+\tbra limbo\n+\tnop\n+\t.balign 4\n+expevt_k:\n+\t.long 0xff000024 ! Address of expevt\n+chandler_k:\t\n+\t.long chandler\t\n+superh_trap_handler_k:\n+\t.long\t__superh_trap_handler\n+handler_exit_k:\n+\t.long _exit\n+\t.align 2\n+! Simulated compile of trap handler.\n+\t.section\t.debug_abbrev,\"\",@progbits\n+.Ldebug_abbrev0:\n+\t.section\t.debug_info,\"\",@progbits\n+.Ldebug_info0:\n+\t.section\t.debug_line,\"\",@progbits\n+.Ldebug_line0:\n+\t.text\n+.Ltext0:\n+\t.align 5\n+\t.type\t__superh_trap_handler,@function\n+__superh_trap_handler:\n+.LFB1:\n+\tmov.l\tr14,@-r15\n+.LCFI0:\n+\tadd\t#-4,r15\n+.LCFI1:\n+\tmov\tr15,r14\n+.LCFI2:\n+\tmov.l\tr4,@r14\n+\tlds\tr1, pr\n+\tadd\t#4,r14\n+\tmov\tr14,r15\n+\tmov.l\t@r15+,r14\n+\trts\t\n+\tnop\n+.LFE1:\n+.Lfe1:\n+\t.size\t__superh_trap_handler,.Lfe1-__superh_trap_handler\n+\t.section\t.debug_frame,\"\",@progbits\n+.Lframe0:\n+\t.ualong\t.LECIE0-.LSCIE0\n+.LSCIE0:\n+\t.ualong\t0xffffffff\n+\t.byte\t0x1\n+\t.string\t\"\"\n+\t.uleb128 0x1\n+\t.sleb128 -4\n+\t.byte\t0x11\n+\t.byte\t0xc\n+\t.uleb128 0xf\n+\t.uleb128 0x0\n+\t.align 2\n+.LECIE0:\n+.LSFDE0:\n+\t.ualong\t.LEFDE0-.LASFDE0\n+.LASFDE0:\n+\t.ualong\t.Lframe0\n+\t.ualong\t.LFB1\n+\t.ualong\t.LFE1-.LFB1\n+\t.byte\t0x4\n+\t.ualong\t.LCFI0-.LFB1\n+\t.byte\t0xe\n+\t.uleb128 0x4\n+\t.byte\t0x4\n+\t.ualong\t.LCFI1-.LCFI0\n+\t.byte\t0xe\n+\t.uleb128 0x8\n+\t.byte\t0x8e\n+\t.uleb128 0x1\n+\t.byte\t0x4\n+\t.ualong\t.LCFI2-.LCFI1\n+\t.byte\t0xd\n+\t.uleb128 0xe\n+\t.align 2\n+.LEFDE0:\n+\t.text\n+.Letext0:\n+\t.section\t.debug_info\n+\t.ualong\t0xb3\n+\t.uaword\t0x2\n+\t.ualong\t.Ldebug_abbrev0\n+\t.byte\t0x4\n+\t.uleb128 0x1\n+\t.ualong\t.Ldebug_line0\n+\t.ualong\t.Letext0\n+\t.ualong\t.Ltext0\n+\t.string\t\"trap_handler.c\"\n+\t.string\t\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n+\t.string\t\"GNU C 3.2 20020529 (experimental)\"\n+\t.byte\t0x1\n+\t.uleb128 0x2\n+\t.ualong\t0xa6\n+\t.byte\t0x1\n+\t.string\t\"_superh_trap_handler\"\n+\t.byte\t0x1\n+\t.byte\t0x2\n+\t.byte\t0x1\n+\t.ualong\t.LFB1\n+\t.ualong\t.LFE1\n+\t.byte\t0x1\n+\t.byte\t0x5e\n+\t.uleb128 0x3\n+\t.string\t\"trap_reason\"\n+\t.byte\t0x1\n+\t.byte\t0x1\n+\t.ualong\t0xa6\n+\t.byte\t0x2\n+\t.byte\t0x91\n+\t.sleb128 0\n+\t.byte\t0x0\n+\t.uleb128 0x4\n+\t.string\t\"unsigned int\"\n+\t.byte\t0x4\n+\t.byte\t0x7\n+\t.byte\t0x0\n+\t.section\t.debug_abbrev\n+\t.uleb128 0x1\n+\t.uleb128 0x11\n+\t.byte\t0x1\n+\t.uleb128 0x10\n+\t.uleb128 0x6\n+\t.uleb128 0x12\n+\t.uleb128 0x1\n+\t.uleb128 0x11\n+\t.uleb128 0x1\n+\t.uleb128 0x3\n+\t.uleb128 0x8\n+\t.uleb128 0x1b\n+\t.uleb128 0x8\n+\t.uleb128 0x25\n+\t.uleb128 0x8\n+\t.uleb128 0x13\n+\t.uleb128 0xb\n+\t.byte\t0x0\n+\t.byte\t0x0\n+\t.uleb128 0x2\n+\t.uleb128 0x2e\n+\t.byte\t0x1\n+\t.uleb128 0x1\n+\t.uleb128 0x13\n+\t.uleb128 0x3f\n+\t.uleb128 0xc\n+\t.uleb128 0x3\n+\t.uleb128 0x8\n+\t.uleb128 0x3a\n+\t.uleb128 0xb\n+\t.uleb128 0x3b\n+\t.uleb128 0xb\n+\t.uleb128 0x27\n+\t.uleb128 0xc\n+\t.uleb128 0x11\n+\t.uleb128 0x1\n+\t.uleb128 0x12\n+\t.uleb128 0x1\n+\t.uleb128 0x40\n+\t.uleb128 0xa\n+\t.byte\t0x0\n+\t.byte\t0x0\n+\t.uleb128 0x3\n+\t.uleb128 0x5\n+\t.byte\t0x0\n+\t.uleb128 0x3\n+\t.uleb128 0x8\n+\t.uleb128 0x3a\n+\t.uleb128 0xb\n+\t.uleb128 0x3b\n+\t.uleb128 0xb\n+\t.uleb128 0x49\n+\t.uleb128 0x13\n+\t.uleb128 0x2\n+\t.uleb128 0xa\n+\t.byte\t0x0\n+\t.byte\t0x0\n+\t.uleb128 0x4\n+\t.uleb128 0x24\n+\t.byte\t0x0\n+\t.uleb128 0x3\n+\t.uleb128 0x8\n+\t.uleb128 0xb\n+\t.uleb128 0xb\n+\t.uleb128 0x3e\n+\t.uleb128 0xb\n+\t.byte\t0x0\n+\t.byte\t0x0\n+\t.byte\t0x0\n+\t.section\t.debug_pubnames,\"\",@progbits\n+\t.ualong\t0x27\n+\t.uaword\t0x2\n+\t.ualong\t.Ldebug_info0\n+\t.ualong\t0xb7\n+\t.ualong\t0x67\n+\t.string\t\"_superh_trap_handler\"\n+\t.ualong\t0x0\n+\t.section\t.debug_aranges,\"\",@progbits\n+\t.ualong\t0x1c\n+\t.uaword\t0x2\n+\t.ualong\t.Ldebug_info0\n+\t.byte\t0x4\n+\t.byte\t0x0\n+\t.uaword\t0x0\n+\t.uaword\t0x0\n+\t.ualong\t.Ltext0\n+\t.ualong\t.Letext0-.Ltext0\n+\t.ualong\t0x0\n+\t.ualong\t0x0\n+#endif /* VBR_SETUP */\n+#endif /* ! __SH5__ */"}, {"sha": "31b4463ac461dc33b683e03ed0f7144fa61f1211", "filename": "gcc/config/sh/divtab.c", "status": "added", "additions": 204, "deletions": 0, "changes": 204, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fdivtab.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fdivtab.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fdivtab.c?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -0,0 +1,204 @@\n+/* Copyright (C) 2003 Free Software Foundation, Inc.\n+\n+This file is free software; you can redistribute it and/or modify it\n+under the terms of the GNU General Public License as published by the\n+Free Software Foundation; either version 2, or (at your option) any\n+later version.\n+\n+In addition to the permissions in the GNU General Public License, the\n+Free Software Foundation gives you unlimited permission to link the\n+compiled version of this file into combinations with other programs,\n+and to distribute those combinations without any restriction coming\n+from the use of this file.  (The General Public License restrictions\n+do apply in other respects; for example, they cover modification of\n+the file, and distribution when not linked into a combine\n+executable.)\n+\n+This file is distributed in the hope that it will be useful, but\n+WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with this program; see the file COPYING.  If not, write to\n+the Free Software Foundation, 59 Temple Place - Suite 330,\n+Boston, MA 02111-1307, USA.  */\n+\n+/* Calculate division table for SH5Media integer division\n+   Contributed by Joern Rernnecke\n+   joern.rennecke@superh.com  */\n+\n+#include <stdio.h>\n+#include <math.h>\n+\n+#define BITS 5\n+#define N_ENTRIES (1 << BITS)\n+#define CUTOFF_BITS 20\n+\n+#define BIAS (-330)\n+\n+double max_defect = 0.;\n+double max_defect_x;\n+\n+double min_defect = 1e9;\n+double min_defect_x;\n+\n+double max_defect2 = 0.;\n+double max_defect2_x;\n+\n+double min_defect2 = 0.;\n+double min_defect2_x;\n+\n+double min_defect3 = 01e9;\n+double min_defect3_x;\n+int min_defect3_val;\n+\n+double max_defect3 = 0.;\n+double max_defect3_x;\n+int max_defect3_val;\n+\n+static double note_defect3 (int val, double d2, double y2d, double x)\n+{\n+  int cutoff_val = val >> CUTOFF_BITS;\n+  double cutoff;\n+  double defect;\n+\n+  if (val < 0)\n+    cutoff_val++;\n+  cutoff = (cutoff_val * (1<<CUTOFF_BITS) - val) * y2d;\n+  defect = cutoff + val * d2;\n+  if (val < 0)\n+    defect = - defect;\n+  if (defect > max_defect3)\n+    {\n+      max_defect3 = defect;\n+      max_defect3_x = x;\n+      max_defect3_val = val;\n+    }\n+  if (defect < min_defect3)\n+    {\n+      min_defect3 = defect;\n+      min_defect3_x = x;\n+      min_defect3_val = val;\n+    }\n+}\n+\n+/* This function assumes 32 bit integers.  */\n+static double\n+calc_defect (double x, int constant, int factor)\n+{\n+  double y0 = (constant - (int) floor ((x * factor * 64.))) / 16384.;\n+  double y1 = 2 * y0 -y0 * y0 * (x + BIAS / (1.*(1LL<<30)));\n+  double y2d0, y2d;\n+  int y2d1;\n+  double d, d2;\n+\n+  y1 = floor (y1 * (1024 * 1024 * 1024)) / (1024 * 1024 * 1024);\n+  d = y1 - 1 / x;\n+  if (d > max_defect)\n+    {\n+      max_defect = d;\n+      max_defect_x = x;\n+    }\n+  if (d < min_defect)\n+    {\n+      min_defect = d;\n+      min_defect_x = x;\n+    }\n+  y2d0 = floor (y1 * x * (1LL << 60-16));\n+  y2d1 = (int) (long long) y2d0;\n+  y2d = - floor ((y1 - y0 / (1<<30-14)) * y2d1) / (1LL<<44);\n+  d2 = y1 + y2d - 1/x;\n+  if (d2 > max_defect2)\n+    {\n+      max_defect2 = d2;\n+      max_defect2_x = x;\n+    }\n+  if (d2 < min_defect2)\n+    {\n+      min_defect2 = d2;\n+      min_defect2_x = x;\n+    }\n+  /* zero times anything is trivially zero.  */\n+  note_defect3 ((1 << CUTOFF_BITS) - 1, d2, y2d, x);\n+  note_defect3 (1 << CUTOFF_BITS, d2, y2d, x);\n+  note_defect3 ((1U << 31) - (1 << CUTOFF_BITS), d2, y2d, x);\n+  note_defect3 ((1U << 31) - 1, d2, y2d, x);\n+  note_defect3 (-1, d2, y2d, x);\n+  note_defect3 (-(1 << CUTOFF_BITS), d2, y2d, x);\n+  note_defect3 ((1U << 31) - (1 << CUTOFF_BITS) + 1, d2, y2d, x);\n+  note_defect3 (-(1U << 31), d2, y2d, x);\n+  return d;\n+}\n+\n+int\n+main ()\n+{\n+  int i;\n+  unsigned char factors[N_ENTRIES];\n+  short constants[N_ENTRIES];\n+  int steps = N_ENTRIES / 2;\n+  double step = 1. / steps;\n+  double eps30 = 1. / (1024 * 1024 * 1024);\n+\n+  for (i = 0; i < N_ENTRIES; i++)\n+    {\n+      double x_low = (i < steps ? 1. : -3.) + i * step;\n+      double x_high = x_low + step - eps30;\n+      double x_med;\n+      int factor, constant;\n+      double low_defect, med_defect, high_defect, max_defect;\n+\n+      factor = (1./x_low- 1./x_high) / step * 256. + 0.5;\n+      if (factor == 256)\n+\tfactor = 255;\n+      factors[i] = factor;\n+      /* Use minimum of error function for x_med.  */\n+      x_med = sqrt (256./factor);\n+      if (x_low < 0)\n+\tx_med = - x_med;\n+      low_defect = 1. / x_low + x_low * factor / 256.;\n+      high_defect = 1. / x_high + x_high * factor / 256.;\n+      med_defect = 1. / x_med + x_med * factor / 256.;\n+      max_defect\n+\t= ((low_defect > high_defect) ^ (x_med < 0)) ? low_defect : high_defect;\n+      constant = (med_defect + max_defect) * 0.5 * 16384. + 0.5;\n+      if (constant < -32768 || constant > 32767)\n+\tabort ();\n+      constants[i] = constant;\n+      calc_defect (x_low, constant, factor);\n+      calc_defect (x_med, constant, factor);\n+      calc_defect (x_high, constant, factor);\n+    }\n+    printf (\"/* This table has been generated by divtab.c .\\n\");\n+    printf (\"Defects for bias %d:\\n\", BIAS);\n+    printf (\"   Max defect: %e at %e\\n\", max_defect, max_defect_x);\n+    printf (\"   Min defect: %e at %e\\n\", min_defect, min_defect_x);\n+    printf (\"   Max 2nd step defect: %e at %e\\n\", max_defect2, max_defect2_x);\n+    printf (\"   Min 2nd step defect: %e at %e\\n\", min_defect2, min_defect2_x);\n+    printf (\"   Max div defect: %e at %d:%e\\n\", max_defect3, max_defect3_val, max_defect3_x);\n+    printf (\"   Min div defect: %e at %d:%e\\n\", min_defect3, min_defect3_val, min_defect3_x);\n+    printf (\"   Defect at 1: %e\\n\",\n+\t    calc_defect (1., constants[0], factors[0]));\n+    printf (\"   Defect at -2: %e */\\n\",\n+\t    calc_defect (-2., constants[steps], factors[steps]));\n+    printf (\"\\t.section\\t.rodata\\n\");\n+    printf (\"\\t.balign 2\\n\");\n+    printf (\"/* negative division constants */\\n\");\n+    for (i = steps; i < 2 * steps; i++)\n+      printf (\"\\t.word\\t%d\\n\", constants[i]);\n+    printf (\"/* negative division factors */\\n\");\n+    for (i = steps; i < 2*steps; i++)\n+      printf (\"\\t.byte\\t%d\\n\", factors[i]);\n+    printf (\"\\t.skip %d\\n\", steps);\n+    printf (\"\\t.global\tGLOBAL(div_table):\\n\");\n+    printf (\"GLOBAL(div_table):\\n\");\n+    printf (\"\\t.skip %d\\n\", steps);\n+    printf (\"/* positive division factors */\\n\");\n+    for (i = 0; i < steps; i++)\n+      printf (\"\\t.byte\\t%d\\n\", factors[i]);\n+    printf (\"/* positive division constants */\\n\");\n+    for (i = 0; i < steps; i++)\n+      printf (\"\\t.word\\t%d\\n\", constants[i]);\n+  exit (0);\n+}"}, {"sha": "0dab7d894cd3874b41646a2305712f334505c21c", "filename": "gcc/config/sh/elf.h", "status": "modified", "additions": 0, "deletions": 8, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Felf.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Felf.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Felf.h?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -57,14 +57,6 @@ Boston, MA 02111-1307, USA.  */\n /* Pass -ml and -mrelax to the assembler and linker.  */\n #undef ASM_SPEC\n #define ASM_SPEC SH_ASM_SPEC\n-#undef SUBTARGET_ASM_ISA_SPEC\n-#define SUBTARGET_ASM_ISA_SPEC \"\\\n-%{m2a:--isa=sh2a} \\\n-%{m2a-single:--isa=sh2a} \\\n-%{m2a-single-only:--isa=sh2a} \\\n-%{m2a-nofpu:--isa=sh2a-nofpu} \\\n-%{m5-compact*:--isa=SHcompact} %{m5-32media*:--isa=SHmedia --abi=32} \\\n-%{m5-64media*:--isa=SHmedia --abi=64}\" ASM_ISA_DEFAULT_SPEC\n \n #undef LINK_SPEC\n #define LINK_SPEC SH_LINK_SPEC"}, {"sha": "546a90869d37e50addc03ca952b6f47af2a4da35", "filename": "gcc/config/sh/lib1funcs.asm", "status": "modified", "additions": 533, "deletions": 218, "changes": 751, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Flib1funcs.asm", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Flib1funcs.asm", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Flib1funcs.asm?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -40,11 +40,15 @@ Boston, MA 02111-1307, USA.  */\n #ifdef __ELF__\n #define LOCAL(X)\t.L_##X\n #define FUNC(X)\t\t.type X,@function\n+#define HIDDEN_FUNC(X)\tFUNC(X); .hidden X\n+#define HIDDEN_ALIAS(X,Y) ALIAS (X,Y); .hidden GLOBAL(X)\n #define ENDFUNC0(X)\t.Lfe_##X: .size X,.Lfe_##X-X\n #define ENDFUNC(X)\tENDFUNC0(X)\n #else\n #define LOCAL(X)\tL_##X\n #define FUNC(X)\n+#define HIDDEN_FUNC(X)\n+#define HIDDEN_ALIAS(X,Y) ALIAS (X,Y)\n #define ENDFUNC(X)\n #endif\n \n@@ -54,10 +58,6 @@ Boston, MA 02111-1307, USA.  */\n \n #define ALIAS(X,Y)\t.global GLOBAL(X); .set GLOBAL(X),GLOBAL(Y)\n \n-#if defined __SH5__ && ! defined __SH4_NOFPU__ && ! defined (__LITTLE_ENDIAN__)\n-#define FMOVD_WORKS\n-#endif\n-\n #ifdef __SH2A__\n #undef FMOVD_WORKS\n #define FMOVD_WORKS\n@@ -99,39 +99,39 @@ Boston, MA 02111-1307, USA.  */\n \t.global\tGLOBAL(ashiftrt_r4_31)\n \t.global\tGLOBAL(ashiftrt_r4_32)\n \n-\tFUNC(GLOBAL(ashiftrt_r4_0))\n-\tFUNC(GLOBAL(ashiftrt_r4_1))\n-\tFUNC(GLOBAL(ashiftrt_r4_2))\n-\tFUNC(GLOBAL(ashiftrt_r4_3))\n-\tFUNC(GLOBAL(ashiftrt_r4_4))\n-\tFUNC(GLOBAL(ashiftrt_r4_5))\n-\tFUNC(GLOBAL(ashiftrt_r4_6))\n-\tFUNC(GLOBAL(ashiftrt_r4_7))\n-\tFUNC(GLOBAL(ashiftrt_r4_8))\n-\tFUNC(GLOBAL(ashiftrt_r4_9))\n-\tFUNC(GLOBAL(ashiftrt_r4_10))\n-\tFUNC(GLOBAL(ashiftrt_r4_11))\n-\tFUNC(GLOBAL(ashiftrt_r4_12))\n-\tFUNC(GLOBAL(ashiftrt_r4_13))\n-\tFUNC(GLOBAL(ashiftrt_r4_14))\n-\tFUNC(GLOBAL(ashiftrt_r4_15))\n-\tFUNC(GLOBAL(ashiftrt_r4_16))\n-\tFUNC(GLOBAL(ashiftrt_r4_17))\n-\tFUNC(GLOBAL(ashiftrt_r4_18))\n-\tFUNC(GLOBAL(ashiftrt_r4_19))\n-\tFUNC(GLOBAL(ashiftrt_r4_20))\n-\tFUNC(GLOBAL(ashiftrt_r4_21))\n-\tFUNC(GLOBAL(ashiftrt_r4_22))\n-\tFUNC(GLOBAL(ashiftrt_r4_23))\n-\tFUNC(GLOBAL(ashiftrt_r4_24))\n-\tFUNC(GLOBAL(ashiftrt_r4_25))\n-\tFUNC(GLOBAL(ashiftrt_r4_26))\n-\tFUNC(GLOBAL(ashiftrt_r4_27))\n-\tFUNC(GLOBAL(ashiftrt_r4_28))\n-\tFUNC(GLOBAL(ashiftrt_r4_29))\n-\tFUNC(GLOBAL(ashiftrt_r4_30))\n-\tFUNC(GLOBAL(ashiftrt_r4_31))\n-\tFUNC(GLOBAL(ashiftrt_r4_32))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_0))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_1))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_2))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_3))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_4))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_5))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_6))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_7))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_8))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_9))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_10))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_11))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_12))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_13))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_14))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_15))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_16))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_17))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_18))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_19))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_20))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_21))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_22))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_23))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_24))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_25))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_26))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_27))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_28))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_29))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_30))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_31))\n+\tHIDDEN_FUNC(GLOBAL(ashiftrt_r4_32))\n \n \t.align\t1\n GLOBAL(ashiftrt_r4_32):\n@@ -268,7 +268,7 @@ GLOBAL(ashiftrt_r4_0):\n !\n \n \t.global\tGLOBAL(ashrsi3)\n-\tFUNC(GLOBAL(ashrsi3))\n+\tHIDDEN_FUNC(GLOBAL(ashrsi3))\n \t.align\t2\n GLOBAL(ashrsi3):\n \tmov\t#31,r0\n@@ -418,7 +418,7 @@ LOCAL(ashrsi3_0):\n ! (none)\n !\n \t.global\tGLOBAL(ashlsi3)\n-\tFUNC(GLOBAL(ashlsi3))\n+\tHIDDEN_FUNC(GLOBAL(ashlsi3))\n \t.align\t2\n GLOBAL(ashlsi3):\n \tmov\t#31,r0\n@@ -577,7 +577,7 @@ LOCAL(ashlsi3_0):\n ! (none)\n !\n \t.global\tGLOBAL(lshrsi3)\n-\tFUNC(GLOBAL(lshrsi3))\n+\tHIDDEN_FUNC(GLOBAL(lshrsi3))\n \t.align\t2\n GLOBAL(lshrsi3):\n \tmov\t#31,r0\n@@ -719,121 +719,143 @@ LOCAL(lshrsi3_0):\n \n #ifdef L_movmem\n \t.text\n+\t.balign\t4\n+\t.global\tGLOBAL(movmem)\n+\tHIDDEN_FUNC(GLOBAL(movmem))\n+\tHIDDEN_ALIAS(movstr,movmem)\n+\t/* This would be a lot simpler if r6 contained the byte count\n+\t   minus 64, and we wouldn't be called here for a byte count of 64.  */\n+GLOBAL(movmem):\n+\tsts.l\tpr,@-r15\n+\tshll2\tr6\n+\tbsr\tGLOBAL(movmemSI52+2)\n+\tmov.l\t@(48,r5),r0\n+\t.balign\t4\n+LOCAL(movmem_loop): /* Reached with rts */\n+\tmov.l\t@(60,r5),r0\n+\tadd\t#-64,r6\n+\tmov.l\tr0,@(60,r4)\n+\ttst\tr6,r6\n+\tmov.l\t@(56,r5),r0\n+\tbt\tLOCAL(movmem_done)\n+\tmov.l\tr0,@(56,r4)\n+\tcmp/pl\tr6\n+\tmov.l\t@(52,r5),r0\n+\tadd\t#64,r5\n+\tmov.l\tr0,@(52,r4)\n+\tadd\t#64,r4\n+\tbt\tGLOBAL(movmemSI52)\n ! done all the large groups, do the remainder\n-\n ! jump to movmem+\n-done:\n-\tadd\t#64,r5\n-\tmova\tGLOBAL(movmemSI0),r0\n-\tshll2\tr6\n+\tmova\tGLOBAL(movmemSI4)+4,r0\n \tadd\tr6,r0\n \tjmp\t@r0\n-\tadd\t#64,r4\n-\t.align\t4\n+LOCAL(movmem_done): ! share slot insn, works out aligned.\n+\tlds.l\t@r15+,pr\n+\tmov.l\tr0,@(56,r4)\n+\tmov.l\t@(52,r5),r0\n+\trts\n+\tmov.l\tr0,@(52,r4)\n+\t.balign\t4\n ! ??? We need aliases movstr* for movmem* for the older libraries.  These\n ! aliases will be removed at the some point in the future.\n \t.global\tGLOBAL(movmemSI64)\n-\tFUNC(GLOBAL(movmemSI64))\n-\tALIAS(movstrSI64,movmemSI64)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI64))\n+\tHIDDEN_ALIAS(movstrSI64,movmemSI64)\n GLOBAL(movmemSI64):\n \tmov.l\t@(60,r5),r0\n \tmov.l\tr0,@(60,r4)\n \t.global\tGLOBAL(movmemSI60)\n-\tFUNC(GLOBAL(movmemSI60))\n-\tALIAS(movstrSI60,movmemSI60)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI60))\n+\tHIDDEN_ALIAS(movstrSI60,movmemSI60)\n GLOBAL(movmemSI60):\n \tmov.l\t@(56,r5),r0\n \tmov.l\tr0,@(56,r4)\n \t.global\tGLOBAL(movmemSI56)\n-\tFUNC(GLOBAL(movmemSI56))\n-\tALIAS(movstrSI56,movmemSI56)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI56))\n+\tHIDDEN_ALIAS(movstrSI56,movmemSI56)\n GLOBAL(movmemSI56):\n \tmov.l\t@(52,r5),r0\n \tmov.l\tr0,@(52,r4)\n \t.global\tGLOBAL(movmemSI52)\n-\tFUNC(GLOBAL(movmemSI52))\n-\tALIAS(movstrSI52,movmemSI52)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI52))\n+\tHIDDEN_ALIAS(movstrSI52,movmemSI52)\n GLOBAL(movmemSI52):\n \tmov.l\t@(48,r5),r0\n \tmov.l\tr0,@(48,r4)\n \t.global\tGLOBAL(movmemSI48)\n-\tFUNC(GLOBAL(movmemSI48))\n-\tALIAS(movstrSI48,movmemSI48)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI48))\n+\tHIDDEN_ALIAS(movstrSI48,movmemSI48)\n GLOBAL(movmemSI48):\n \tmov.l\t@(44,r5),r0\n \tmov.l\tr0,@(44,r4)\n \t.global\tGLOBAL(movmemSI44)\n-\tFUNC(GLOBAL(movmemSI44))\n-\tALIAS(movstrSI44,movmemSI44)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI44))\n+\tHIDDEN_ALIAS(movstrSI44,movmemSI44)\n GLOBAL(movmemSI44):\n \tmov.l\t@(40,r5),r0\n \tmov.l\tr0,@(40,r4)\n \t.global\tGLOBAL(movmemSI40)\n-\tFUNC(GLOBAL(movmemSI40))\n-\tALIAS(movstrSI40,movmemSI40)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI40))\n+\tHIDDEN_ALIAS(movstrSI40,movmemSI40)\n GLOBAL(movmemSI40):\n \tmov.l\t@(36,r5),r0\n \tmov.l\tr0,@(36,r4)\n \t.global\tGLOBAL(movmemSI36)\n-\tFUNC(GLOBAL(movmemSI36))\n-\tALIAS(movstrSI36,movmemSI36)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI36))\n+\tHIDDEN_ALIAS(movstrSI36,movmemSI36)\n GLOBAL(movmemSI36):\n \tmov.l\t@(32,r5),r0\n \tmov.l\tr0,@(32,r4)\n \t.global\tGLOBAL(movmemSI32)\n-\tFUNC(GLOBAL(movmemSI32))\n-\tALIAS(movstrSI32,movmemSI32)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI32))\n+\tHIDDEN_ALIAS(movstrSI32,movmemSI32)\n GLOBAL(movmemSI32):\n \tmov.l\t@(28,r5),r0\n \tmov.l\tr0,@(28,r4)\n \t.global\tGLOBAL(movmemSI28)\n-\tFUNC(GLOBAL(movmemSI28))\n-\tALIAS(movstrSI28,movmemSI28)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI28))\n+\tHIDDEN_ALIAS(movstrSI28,movmemSI28)\n GLOBAL(movmemSI28):\n \tmov.l\t@(24,r5),r0\n \tmov.l\tr0,@(24,r4)\n \t.global\tGLOBAL(movmemSI24)\n-\tFUNC(GLOBAL(movmemSI24))\n-\tALIAS(movstrSI24,movmemSI24)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI24))\n+\tHIDDEN_ALIAS(movstrSI24,movmemSI24)\n GLOBAL(movmemSI24):\n \tmov.l\t@(20,r5),r0\n \tmov.l\tr0,@(20,r4)\n \t.global\tGLOBAL(movmemSI20)\n-\tFUNC(GLOBAL(movmemSI20))\n-\tALIAS(movstrSI20,movmemSI20)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI20))\n+\tHIDDEN_ALIAS(movstrSI20,movmemSI20)\n GLOBAL(movmemSI20):\n \tmov.l\t@(16,r5),r0\n \tmov.l\tr0,@(16,r4)\n \t.global\tGLOBAL(movmemSI16)\n-\tFUNC(GLOBAL(movmemSI16))\n-\tALIAS(movstrSI16,movmemSI16)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI16))\n+\tHIDDEN_ALIAS(movstrSI16,movmemSI16)\n GLOBAL(movmemSI16):\n \tmov.l\t@(12,r5),r0\n \tmov.l\tr0,@(12,r4)\n \t.global\tGLOBAL(movmemSI12)\n-\tFUNC(GLOBAL(movmemSI12))\n-\tALIAS(movstrSI12,movmemSI12)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI12))\n+\tHIDDEN_ALIAS(movstrSI12,movmemSI12)\n GLOBAL(movmemSI12):\n \tmov.l\t@(8,r5),r0\n \tmov.l\tr0,@(8,r4)\n \t.global\tGLOBAL(movmemSI8)\n-\tFUNC(GLOBAL(movmemSI8))\n-\tALIAS(movstrSI8,movmemSI8)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI8))\n+\tHIDDEN_ALIAS(movstrSI8,movmemSI8)\n GLOBAL(movmemSI8):\n \tmov.l\t@(4,r5),r0\n \tmov.l\tr0,@(4,r4)\n \t.global\tGLOBAL(movmemSI4)\n-\tFUNC(GLOBAL(movmemSI4))\n-\tALIAS(movstrSI4,movmemSI4)\n+\tHIDDEN_FUNC(GLOBAL(movmemSI4))\n+\tHIDDEN_ALIAS(movstrSI4,movmemSI4)\n GLOBAL(movmemSI4):\n \tmov.l\t@(0,r5),r0\n-\tmov.l\tr0,@(0,r4)\n-\t.global\tGLOBAL(movmemSI0)\n-\tFUNC(GLOBAL(movmemSI0))\n-\tALIAS(movstrSI0,movmemSI0)\n-GLOBAL(movmemSI0):\n \trts\n-\tnop\n+\tmov.l\tr0,@(0,r4)\n \n \tENDFUNC(GLOBAL(movmemSI64))\n \tENDFUNC(GLOBAL(movmemSI60))\n@@ -851,71 +873,7 @@ GLOBAL(movmemSI0):\n \tENDFUNC(GLOBAL(movmemSI12))\n \tENDFUNC(GLOBAL(movmemSI8))\n \tENDFUNC(GLOBAL(movmemSI4))\n-\tENDFUNC(GLOBAL(movmemSI0))\n-\n-\t.align\t4\n-\n-\t.global\tGLOBAL(movmem)\n-\tFUNC(GLOBAL(movmem))\n-\tALIAS(movstr,movmem)\n-GLOBAL(movmem):\n-\tmov.l\t@(60,r5),r0\n-\tmov.l\tr0,@(60,r4)\n-\n-\tmov.l\t@(56,r5),r0\n-\tmov.l\tr0,@(56,r4)\n-\n-\tmov.l\t@(52,r5),r0\n-\tmov.l\tr0,@(52,r4)\n-\n-\tmov.l\t@(48,r5),r0\n-\tmov.l\tr0,@(48,r4)\n-\n-\tmov.l\t@(44,r5),r0\n-\tmov.l\tr0,@(44,r4)\n-\n-\tmov.l\t@(40,r5),r0\n-\tmov.l\tr0,@(40,r4)\n-\n-\tmov.l\t@(36,r5),r0\n-\tmov.l\tr0,@(36,r4)\n-\n-\tmov.l\t@(32,r5),r0\n-\tmov.l\tr0,@(32,r4)\n-\n-\tmov.l\t@(28,r5),r0\n-\tmov.l\tr0,@(28,r4)\n-\n-\tmov.l\t@(24,r5),r0\n-\tmov.l\tr0,@(24,r4)\n-\n-\tmov.l\t@(20,r5),r0\n-\tmov.l\tr0,@(20,r4)\n-\n-\tmov.l\t@(16,r5),r0\n-\tmov.l\tr0,@(16,r4)\n-\n-\tmov.l\t@(12,r5),r0\n-\tmov.l\tr0,@(12,r4)\n-\n-\tmov.l\t@(8,r5),r0\n-\tmov.l\tr0,@(8,r4)\n-\n-\tmov.l\t@(4,r5),r0\n-\tmov.l\tr0,@(4,r4)\n-\n-\tmov.l\t@(0,r5),r0\n-\tmov.l\tr0,@(0,r4)\n-\n-\tadd\t#-16,r6\n-\tcmp/pl\tr6\n-\tbf\tdone\n-\n-\tadd\t#64,r5\n-\tbra\tGLOBAL(movmem)\n-\tadd\t#64,r4\n-\n-\tFUNC(GLOBAL(movmem))\n+\tENDFUNC(GLOBAL(movmem))\n #endif\n \n #ifdef L_movmem_i4\n@@ -924,13 +882,13 @@ GLOBAL(movmem):\n \t.global\tGLOBAL(movmem_i4_odd)\n \t.global\tGLOBAL(movmemSI12_i4)\n \n-\tFUNC(GLOBAL(movmem_i4_even))\n-\tFUNC(GLOBAL(movmem_i4_odd))\n-\tFUNC(GLOBAL(movmemSI12_i4))\n+\tHIDDEN_FUNC(GLOBAL(movmem_i4_even))\n+\tHIDDEN_FUNC(GLOBAL(movmem_i4_odd))\n+\tHIDDEN_FUNC(GLOBAL(movmemSI12_i4))\n \n-\tALIAS(movstr_i4_even,movmem_i4_even)\n-\tALIAS(movstr_i4_odd,movmem_i4_odd)\n-\tALIAS(movstrSI12_i4,movmemSI12_i4)\n+\tHIDDEN_ALIAS(movstr_i4_even,movmem_i4_even)\n+\tHIDDEN_ALIAS(movstr_i4_odd,movmem_i4_odd)\n+\tHIDDEN_ALIAS(movstrSI12_i4,movmemSI12_i4)\n \n \t.p2align\t5\n L_movmem_2mod4_end:\n@@ -991,7 +949,7 @@ GLOBAL(movmemSI12_i4):\n \n \n \t.global\tGLOBAL(mulsi3)\n-\tFUNC(GLOBAL(mulsi3))\n+\tHIDDEN_FUNC(GLOBAL(mulsi3))\n \n ! r4 =       aabb\n ! r5 =       ccdd\n@@ -1024,7 +982,7 @@ hiset:\tsts\tmacl,r0\t\t! r0 = bb*dd\n \trts\n \tadd\tr2,r0\n \n-\tFUNC(GLOBAL(mulsi3))\n+\tENDFUNC(GLOBAL(mulsi3))\n #endif\n #endif /* ! __SH5__ */\n #ifdef L_sdivsi3_i4\n@@ -1034,7 +992,7 @@ hiset:\tsts\tmacl,r0\t\t! r0 = bb*dd\n !! args in r4 and r5, result in fpul, clobber dr0, dr2\n \n \t.global\tGLOBAL(sdivsi3_i4)\n-\tFUNC(GLOBAL(sdivsi3_i4))\n+\tHIDDEN_FUNC(GLOBAL(sdivsi3_i4))\n GLOBAL(sdivsi3_i4):\n \tlds r4,fpul\n \tfloat fpul,dr0\n@@ -1053,7 +1011,7 @@ GLOBAL(sdivsi3_i4):\n \t.mode\tSHcompact\n #endif\n \t.global\tGLOBAL(sdivsi3_i4)\n-\tFUNC(GLOBAL(sdivsi3_i4))\n+\tHIDDEN_FUNC(GLOBAL(sdivsi3_i4))\n GLOBAL(sdivsi3_i4):\n \tsts.l fpscr,@-r15\n \tmov #8,r2\n@@ -1086,7 +1044,6 @@ GLOBAL(sdivsi3_i4):\n !! args in r4 and r5, result in r0 clobber r1, r2, r3, and t bit\n \n \t.global\tGLOBAL(sdivsi3)\n-\tFUNC(GLOBAL(sdivsi3))\n #if __SHMEDIA__\n #if __SH5__ == 32\n \t.section\t.text..SHmedia32,\"ax\"\n@@ -1152,7 +1109,7 @@ LOCAL(sdivsi3_dontadd):\n \tmuls.l\tr0, r2, r0\n \tadd.l\tr0, r63, r0\n \tblink\ttr0, r63\n-#else /* ! 0 */\n+#elif 0 /* ! 0 */\n  // inputs: r4,r5\n  // clobbered: r1,r2,r3,r18,r19,r20,r21,r25,tr0\n  // result in r0\n@@ -1214,13 +1171,73 @@ GLOBAL(sdivsi3):\n  add.l r19,r25,r0\n  xor r0,r18,r0\n  blink tr0,r63\n+#else /* ! 0 && ! 0 */\n+\n+ // inputs: r4,r5\n+ // clobbered: r1,r18,r19,r20,r21,r25,tr0\n+ // result in r0\n+\tHIDDEN_FUNC(GLOBAL(sdivsi3_2))\n+#ifndef __pic__\n+\tFUNC(GLOBAL(sdivsi3))\n+GLOBAL(sdivsi3): /* this is the shcompact entry point */\n+ // The special SHmedia entry point sdivsi3_1 prevents accidental linking\n+ // with the SHcompact implementation, which clobbers tr1 / tr2.\n+ .global GLOBAL(sdivsi3_1)\n+GLOBAL(sdivsi3_1):\n+ .global GLOBAL(div_table_internal)\n+ movi (GLOBAL(div_table_internal) >> 16) & 65535, r20\n+ shori GLOBAL(div_table_internal) & 65535, r20\n+#endif\n+ .global GLOBAL(sdivsi3_2)\n+ // div_table in r20\n+ // clobbered: r1,r18,r19,r21,r25,tr0\n+GLOBAL(sdivsi3_2):\n+ nsb r5, r1\n+ shlld r5, r1, r25    // normalize; [-2 ..1, 1..2) in s2.62\n+ shari r25, 58, r21   // extract 5(6) bit index (s2.4 with hole -1..1)\n+ ldx.ub r20, r21, r19 // u0.8\n+ shari r25, 32, r25   // normalize to s2.30\n+ shlli r21, 1, r21\n+ muls.l r25, r19, r19 // s2.38\n+ ldx.w r20, r21, r21  // s2.14\n+  ptabs r18, tr0\n+ shari r19, 24, r19   // truncate to s2.14\n+ sub r21, r19, r19    // some 11 bit inverse in s1.14\n+ muls.l r19, r19, r21 // u0.28\n+  sub r63, r1, r1\n+  addi r1, 92, r1\n+ muls.l r25, r21, r18 // s2.58\n+ shlli r19, 45, r19   // multiply by two and convert to s2.58\n+  /* bubble */\n+ sub r19, r18, r18\n+ shari r18, 28, r18   // some 22 bit inverse in s1.30\n+ muls.l r18, r25, r0  // s2.60\n+  muls.l r18, r4, r25 // s32.30\n+  /* bubble */\n+ shari r0, 16, r19   // s-16.44\n+ muls.l r19, r18, r19 // s-16.74\n+  shari r25, 63, r0\n+  shari r4, 14, r18   // s19.-14\n+ shari r19, 30, r19   // s-16.44\n+ muls.l r19, r18, r19 // s15.30\n+  xor r21, r0, r21    // You could also use the constant 1 << 27.\n+  add r21, r25, r21\n+ sub r21, r19, r21\n+ shard r21, r1, r21\n+ sub r21, r0, r0\n+ blink tr0, r63\n+#ifndef __pic__\n+\tENDFUNC(GLOBAL(sdivsi3))\n+#endif\n+\tENDFUNC(GLOBAL(sdivsi3_2))\n #endif\n #elif defined __SHMEDIA__\n /* m5compact-nofpu */\n  // clobbered: r18,r19,r20,r21,r25,tr0,tr1,tr2\n \t.mode\tSHmedia\n \t.section\t.text..SHmedia32,\"ax\"\n \t.align\t2\n+\tFUNC(GLOBAL(sdivsi3))\n GLOBAL(sdivsi3):\n \tpt/l LOCAL(sdivsi3_dontsub), tr0\n \tpt/l LOCAL(sdivsi3_loop), tr1\n@@ -1245,7 +1262,9 @@ LOCAL(sdivsi3_dontsub):\n \txor r20,r19,r20\n \tsub.l r20,r19,r0\n \tblink tr2,r63\n+\tENDFUNC(GLOBAL(sdivsi3))\n #else /* ! __SHMEDIA__ */\n+\tFUNC(GLOBAL(sdivsi3))\n GLOBAL(sdivsi3):\n \tmov\tr4,r1\n \tmov\tr5,r0\n@@ -1343,7 +1362,7 @@ div0:\trts\n !! and t bit\n \n \t.global\tGLOBAL(udivsi3_i4)\n-\tFUNC(GLOBAL(udivsi3_i4))\n+\tHIDDEN_FUNC(GLOBAL(udivsi3_i4))\n GLOBAL(udivsi3_i4):\n \tmov #1,r1\n \tcmp/hi r1,r5\n@@ -1390,7 +1409,7 @@ L1:\n !! args in r4 and r5, result in fpul, clobber r20, r21, dr0, fr33\n \t.mode\tSHmedia\n \t.global\tGLOBAL(udivsi3_i4)\n-\tFUNC(GLOBAL(udivsi3_i4))\n+\tHIDDEN_FUNC(GLOBAL(udivsi3_i4))\n GLOBAL(udivsi3_i4):\n \taddz.l\tr4,r63,r20\n \taddz.l\tr5,r63,r21\n@@ -1410,6 +1429,7 @@ GLOBAL(udivsi3_i4):\n !! args in r4 and r5, result in fpul, clobber r0, r1, r4, r5, dr0, dr2, dr4\n \n \t.global\tGLOBAL(udivsi3_i4)\n+\tHIDDEN_FUNC(GLOBAL(udivsi3_i4))\n GLOBAL(udivsi3_i4):\n \tmov #1,r1\n \tcmp/hi r1,r5\n@@ -1469,7 +1489,7 @@ L1:\n \n !! args in r4 and r5, result in r0, clobbers r4, pr, and t bit\n \t.global\tGLOBAL(udivsi3)\n-\tFUNC(GLOBAL(udivsi3))\n+\tHIDDEN_FUNC(GLOBAL(udivsi3))\n \n #if __SHMEDIA__\n #if __SH5__ == 32\n@@ -1671,6 +1691,7 @@ LOCAL(large_divisor):\n \t.global\tGLOBAL(udivdi3)\n \tFUNC(GLOBAL(udivdi3))\n GLOBAL(udivdi3):\n+\tHIDDEN_ALIAS(udivdi3_internal,udivdi3)\n \tshlri r3,1,r4\n \tnsb r4,r22\n \tshlld r3,r22,r6\n@@ -1798,7 +1819,7 @@ LOCAL(no_lo_adj):\n \t.global\tGLOBAL(divdi3)\n \tFUNC(GLOBAL(divdi3))\n GLOBAL(divdi3):\n-\tpta GLOBAL(udivdi3),tr0\n+\tpta GLOBAL(udivdi3_internal),tr0\n \tshari r2,63,r22\n \tshari r3,63,r23\n \txor r2,r22,r2\n@@ -1822,6 +1843,7 @@ GLOBAL(divdi3):\n \t.global\tGLOBAL(umoddi3)\n \tFUNC(GLOBAL(umoddi3))\n GLOBAL(umoddi3):\n+\tHIDDEN_ALIAS(umoddi3_internal,umoddi3)\n \tshlri r3,1,r4\n \tnsb r4,r22\n \tshlld r3,r22,r6\n@@ -1950,7 +1972,7 @@ LOCAL(no_lo_adj):\n \t.global\tGLOBAL(moddi3)\n \tFUNC(GLOBAL(moddi3))\n GLOBAL(moddi3):\n-\tpta GLOBAL(umoddi3),tr0\n+\tpta GLOBAL(umoddi3_internal),tr0\n \tshari r2,63,r22\n \tshari r3,63,r23\n \txor r2,r22,r2\n@@ -1973,7 +1995,7 @@ GLOBAL(moddi3):\n \t.mode\tSHcompact\n #endif\n \t.global GLOBAL(set_fpscr)\n-\tFUNC(GLOBAL(set_fpscr))\n+\tHIDDEN_FUNC(GLOBAL(set_fpscr))\n GLOBAL(set_fpscr):\n \tlds r4,fpscr\n #ifdef __PIC__\n@@ -2041,7 +2063,7 @@ LOCAL(set_fpscr_L1):\n \t.section\t.text..SHmedia32,\"ax\"\n \t.align\t2\n \t.global\tGLOBAL(init_trampoline)\n-\tFUNC(GLOBAL(init_trampoline))\n+\tHIDDEN_FUNC(GLOBAL(init_trampoline))\n GLOBAL(init_trampoline):\n \tst.l\tr0,8,r2\n #ifdef __LITTLE_ENDIAN__\n@@ -2057,74 +2079,133 @@ GLOBAL(init_trampoline):\n #endif\n \tst.q\tr0,0,r20\n \tst.l\tr0,12,r3\n+\tENDFUNC(GLOBAL(init_trampoline))\n \t.global\tGLOBAL(ic_invalidate)\n-\tFUNC(GLOBAL(ic_invalidate))\n+\tHIDDEN_FUNC(GLOBAL(ic_invalidate))\n GLOBAL(ic_invalidate):\n \tocbwb\tr0,0\n \tsynco\n \ticbi\tr0, 0\n \tptabs\tr18, tr0\n \tsynci\n \tblink\ttr0, r63\n-\n \tENDFUNC(GLOBAL(ic_invalidate))\n-\tENDFUNC(GLOBAL(init_trampoline))\n #elif defined(__SH4A__)\n \t.global GLOBAL(ic_invalidate)\n-\tFUNC(GLOBAL(ic_invalidate))\n+\tHIDDEN_FUNC(GLOBAL(ic_invalidate))\n GLOBAL(ic_invalidate):\n \tocbwb\t@r4\n \tsynco\n \trts\n \ticbi\t@r4\n \tENDFUNC(GLOBAL(ic_invalidate))\n-#elif defined(__SH4_SINGLE__) || defined(__SH4__) || defined(__SH4_SINGLE_ONLY__)\n-\t/* This assumes a direct-mapped cache, which is the case for\n-\tthe first SH4, but not for the second version of SH4, that\n-\tuses a 2-way set-associative cache, nor SH4a, that is 4-way.\n-\tSH4a fortunately offers an instruction to invalidate the\n-\tinstruction cache, and we use it above, but SH4 doesn't.\n-\tHowever, since the libraries don't contain any nested\n-\tfunctions (the only case in which GCC would emit this pattern)\n-\tand we actually emit the ic_invalidate_line_i pattern for\n-\tcache invalidation on all SH4 multilibs (even 4-nofpu, that\n-\tisn't even corevered here), and pre-SH4 cores don't have\n-\tcaches, it seems like this code is pointless, unless it's\n-\tmeant for backward binary compatibility or for userland-only\n-\tcache invalidation for say sh4-*-linux-gnu.  Such a feature\n-\tshould probably be moved into a system call, such that the\n-\tkernel could do whatever it takes to invalidate a cache line\n-\ton the core it's actually running on.  I.e., this hideous :-)\n-\tpiece of code should go away at some point.  */\n-\n+#elif defined(__SH4_SINGLE__) || defined(__SH4__) || defined(__SH4_SINGLE_ONLY__) || (defined(__SH4_NOFPU__) && !defined(__SH5__))\n+\t/* For system code, we use ic_invalidate_line_i, but user code\n+\t   needs a different mechanism.  A kernel call is generally not\n+\t   available, and it would also be slow.  Different SH4 variants use\n+\t   different sizes and associativities of the Icache.  We use a small\n+\t   bit of dispatch code that can be put hidden in every shared object,\n+\t   which calls the actual processor-specific invalidation code in a\n+\t   separate module.\n+\t   Or if you have operating system support, the OS could mmap the\n+\t   procesor-specific code from a single page, since it is highly\n+\t   repetitive.  */\n \t.global GLOBAL(ic_invalidate)\n-\tFUNC(GLOBAL(ic_invalidate))\n+\tHIDDEN_FUNC(GLOBAL(ic_invalidate))\n GLOBAL(ic_invalidate):\n-\tocbwb\t@r4\n+\tmov.l\t0f,r1\n+#ifdef __pic__\n \tmova\t0f,r0\n-\tmov.w\t1f,r1\n-/* Compute how many cache lines 0f is away from r4.  */\n-\tsub\tr0,r4\n-\tand\tr1,r4\n-/* Prepare to branch to 0f plus the cache-line offset.  */\n-\tadd\t# 0f - 1f,r4\n-\tbraf\tr4\n-\tnop\n-1:\n-\t.short\t0x1fe0\n+\tmov.l\t1f,r2\n+\tadd\tr1,r0\n+\tmov.l\t@(r0,r2),r1\n+#endif\n+\tocbwb\t@r4\n+\tmov.l\t@(8,r1),r0\n+\tsub\tr1,r4\n+\tand\tr4,r0\n+\tadd\tr1,r0\n+\tjmp\t@r0\n+\tmov.l\t@(4,r1),r0\n+#ifndef __pic__\n+0:\t.long   GLOBAL(ic_invalidate_array)\n+#else /* __pic__ */\n+\t.global GLOBAL(ic_invalidate_array)\n+\t/* ??? Why won't the assembler allow to add these two constants?  */\n+0:\t.long   _GLOBAL_OFFSET_TABLE_\n+1:\t.long   GLOBAL(ic_invalidate_array)@GOT\n+\tENDFUNC(GLOBAL(ic_invalidate))\n+#endif /* __pic__ */\n+#endif /* SH4 */\n+#endif /* L_ic_invalidate */\n+\n+#ifdef L_ic_invalidate_array\n+#if defined(__SH4A__)\n+\t/* This is needed when an SH4 dso with trampolines is used on SH4A.  */\n+\t.global GLOBAL(ic_invalidate_array)\n+\tFUNC(GLOBAL(ic_invalidate_array))\n+GLOBAL(ic_invalidate_array):\n+\tadd\tr1,r4\n+\tsynco\n+\trts\n+\ticbi\t@r4\n+\t.long\t0\n+\tENDFUNC(GLOBAL(ic_invalidate_array))\n+#elif defined(__SH4_SINGLE__) || defined(__SH4__) || defined(__SH4_SINGLE_ONLY__) || (defined(__SH4_NOFPU__) && !defined(__SH5__))\n+\t.global GLOBAL(ic_invalidate_array)\n \t.p2align 5\n+\tFUNC(GLOBAL(ic_invalidate_array))\n /* This must be aligned to the beginning of a cache line.  */\n-0:\n-\t.rept\t256 /* There are 256 cache lines of 32 bytes.  */\n+GLOBAL(ic_invalidate_array):\n+#ifndef WAYS\n+#define WAYS 4\n+#define WAY_SIZE 0x4000\n+#endif\n+#if WAYS == 1\n+\t.rept\tWAY_SIZE * WAYS / 32\n+\trts\n+\tnop\n+\t.rept\t7\n+\t.long\tWAY_SIZE - 32\n+\t.endr\n+\t.endr\n+#elif WAYS <= 6\n+\t.rept\tWAY_SIZE * WAYS / 32\n+\tbraf\tr0\n+\tadd\t#-8,r0\n+\t.long\tWAY_SIZE + 8\n+\t.long\tWAY_SIZE - 32\n+\t.rept\tWAYS-2\n+\tbraf\tr0\n+\tnop\n+\t.endr\n+\t.rept\t7 - WAYS\n+\trts\n+\tnop\n+\t.endr\n+\t.endr\n+#else /* WAYS > 6 */\n+\t/* This variant needs two different pages for mmap-ing.  */\n+ \t.rept\tWAYS-1\n+\t.rept\tWAY_SIZE / 32\n+\tbraf\tr0\n+\tnop\n+\t.long\tWAY_SIZE\n+\t.rept 6\n+\t.long\tWAY_SIZE - 32\n+\t.endr\n+\t.endr\n+\t.endr\n+\t.rept\tWAY_SIZE / 32\n \trts\n \t.rept\t15\n \tnop\n \t.endr\n \t.endr\n-\n-\tENDFUNC(GLOBAL(ic_invalidate))\n+#endif /* WAYS */\n+\tENDFUNC(GLOBAL(ic_invalidate_array))\n #endif /* SH4 */\n-#endif /* L_ic_invalidate */\n+#endif /* L_ic_invalidate_array */\n \n #if defined (__SH5__) && __SH5__ == 32\n #ifdef L_shcompact_call_trampoline\n@@ -2546,7 +2627,7 @@ LOCAL(ct_ret_wide):\t/* Call the function, so that we can unpack its\n \t.section\t.text..SHmedia32, \"ax\"\n \t.align\t2\n \t.global\tGLOBAL(GCC_shcompact_return_trampoline)\n-\tFUNC(GLOBAL(GCC_shcompact_return_trampoline))\n+\tHIDDEN_FUNC(GLOBAL(GCC_shcompact_return_trampoline))\n GLOBAL(GCC_shcompact_return_trampoline):\n \tptabs/l\tr18, tr0\n #if __LITTLE_ENDIAN__\n@@ -2614,7 +2695,7 @@ LOCAL(ia_main_table):\n \tactual bit pattern.  */\n \t\n \t.global\tGLOBAL(GCC_shcompact_incoming_args)\n-\tFUNC(GLOBAL(GCC_shcompact_incoming_args))\n+ \tFUNC(GLOBAL(GCC_shcompact_incoming_args))\n GLOBAL(GCC_shcompact_incoming_args):\n \tptabs/l\tr18, tr0\t/* Prepare to return.  */\n \tshlri\tr17, 32, r0\t/* Load the cookie.  */\n@@ -2779,7 +2860,7 @@ LOCAL(ia_end_of_push_seq): /* Label used to compute the first push instruction.\n #endif\n \t.align\t3 /* It is copied in units of 8 bytes in SHmedia mode.  */\n \t.global\tGLOBAL(GCC_nested_trampoline)\n-\tFUNC(GLOBAL(GCC_nested_trampoline))\n+\tHIDDEN_FUNC(GLOBAL(GCC_nested_trampoline))\n GLOBAL(GCC_nested_trampoline):\n \t.mode\tSHmedia\n \tptrel/u\tr63, tr0\n@@ -2824,10 +2905,11 @@ GLOBAL(GCC_push_shmedia_regs):\n \tfst.d\tr15,  2*8, dr40\n \tfst.d\tr15,  1*8, dr38\n \tfst.d\tr15,  0*8, dr36\n-#endif\n+#else /* ! __SH4_NOFPU__ */\n \t.global\tGLOBAL(GCC_push_shmedia_regs_nofpu)\n \tFUNC(GLOBAL(GCC_push_shmedia_regs_nofpu))\n GLOBAL(GCC_push_shmedia_regs_nofpu):\n+#endif /* ! __SH4_NOFPU__ */\n \tptabs/l\tr18, tr0\n \taddi.l\tr15, -27*8, r15\n \tgettr\ttr7, r62\n@@ -2861,12 +2943,12 @@ GLOBAL(GCC_push_shmedia_regs_nofpu):\n \tst.q\tr15,  1*8, r29\n \tst.q\tr15,  0*8, r28\n \tblink\ttr0, r63\n-\n #ifndef __SH4_NOFPU__\t\n \tENDFUNC(GLOBAL(GCC_push_shmedia_regs))\n-#endif\n+#else\n \tENDFUNC(GLOBAL(GCC_push_shmedia_regs_nofpu))\n-#ifndef __SH4_NOFPU__\n+#endif\n+#ifndef __SH4_NOFPU__\t\n \t.global\tGLOBAL(GCC_pop_shmedia_regs)\n \tFUNC(GLOBAL(GCC_pop_shmedia_regs))\n GLOBAL(GCC_pop_shmedia_regs):\n@@ -2887,10 +2969,11 @@ GLOBAL(GCC_pop_shmedia_regs):\n \tfld.d\tr15, 28*8, dr38\n \tfld.d\tr15, 27*8, dr36\n \tblink\ttr1, r63\n-#endif\n+#else /* ! __SH4_NOFPU__\t*/\n \t.global\tGLOBAL(GCC_pop_shmedia_regs_nofpu)\n \tFUNC(GLOBAL(GCC_pop_shmedia_regs_nofpu))\n GLOBAL(GCC_pop_shmedia_regs_nofpu):\n+#endif /* ! __SH4_NOFPU__\t*/\n \tmovi\t27*8, r0\n .L0:\n \tptabs\tr18, tr0\n@@ -2929,7 +3012,239 @@ GLOBAL(GCC_pop_shmedia_regs_nofpu):\n \n #ifndef __SH4_NOFPU__\n \tENDFUNC(GLOBAL(GCC_pop_shmedia_regs))\n-#endif\n+#else\n \tENDFUNC(GLOBAL(GCC_pop_shmedia_regs_nofpu))\n+#endif\n #endif /* __SH5__ == 32 */\n #endif /* L_push_pop_shmedia_regs */\n+\n+#if __SH5__\n+#ifdef L_div_table\n+#if defined(__pic__) && defined(__SHMEDIA__)\n+\t.global\tGLOBAL(sdivsi3)\n+\tFUNC(GLOBAL(sdivsi3))\n+#if __SH5__ == 32\n+\t.section\t.text..SHmedia32,\"ax\"\n+#else\n+\t.text\n+#endif\n+#if 0\n+/* ??? FIXME: Presumably due to a linker bug, exporting data symbols\n+   in a text section does not work (at least for shared libraries):\n+   the linker sets the LSB of the address as if this was SHmedia code.  */\n+#define TEXT_DATA_BUG\n+#endif\n+\t.align\t2\n+ // inputs: r4,r5\n+ // clobbered: r1,r18,r19,r20,r21,r25,tr0\n+ // result in r0\n+ .global GLOBAL(sdivsi3)\n+GLOBAL(sdivsi3):\n+#ifdef TEXT_DATA_BUG\n+ ptb datalabel Local_div_table,tr0\n+#else\n+ ptb GLOBAL(div_table_internal),tr0\n+#endif\n+ nsb r5, r1\n+ shlld r5, r1, r25    // normalize; [-2 ..1, 1..2) in s2.62\n+ shari r25, 58, r21   // extract 5(6) bit index (s2.4 with hole -1..1)\n+ /* bubble */\n+ gettr tr0,r20\n+ ldx.ub r20, r21, r19 // u0.8\n+ shari r25, 32, r25   // normalize to s2.30\n+ shlli r21, 1, r21\n+ muls.l r25, r19, r19 // s2.38\n+ ldx.w r20, r21, r21  // s2.14\n+  ptabs r18, tr0\n+ shari r19, 24, r19   // truncate to s2.14\n+ sub r21, r19, r19    // some 11 bit inverse in s1.14\n+ muls.l r19, r19, r21 // u0.28\n+  sub r63, r1, r1\n+  addi r1, 92, r1\n+ muls.l r25, r21, r18 // s2.58\n+ shlli r19, 45, r19   // multiply by two and convert to s2.58\n+  /* bubble */\n+ sub r19, r18, r18\n+ shari r18, 28, r18   // some 22 bit inverse in s1.30\n+ muls.l r18, r25, r0  // s2.60\n+  muls.l r18, r4, r25 // s32.30\n+  /* bubble */\n+ shari r0, 16, r19   // s-16.44\n+ muls.l r19, r18, r19 // s-16.74\n+  shari r25, 63, r0\n+  shari r4, 14, r18   // s19.-14\n+ shari r19, 30, r19   // s-16.44\n+ muls.l r19, r18, r19 // s15.30\n+  xor r21, r0, r21    // You could also use the constant 1 << 27.\n+  add r21, r25, r21\n+ sub r21, r19, r21\n+ shard r21, r1, r21\n+ sub r21, r0, r0\n+ blink tr0, r63\n+\tENDFUNC(GLOBAL(sdivsi3))\n+/* This table has been generated by divtab.c .\n+Defects for bias -330:\n+   Max defect: 6.081536e-07 at -1.000000e+00\n+   Min defect: 2.849516e-08 at 1.030651e+00\n+   Max 2nd step defect: 9.606539e-12 at -1.000000e+00\n+   Min 2nd step defect: 0.000000e+00 at 0.000000e+00\n+   Defect at 1: 1.238659e-07\n+   Defect at -2: 1.061708e-07 */\n+#else /* ! __pic__ || ! __SHMEDIA__ */\n+\t.section\t.rodata\n+#endif /* __pic__ */\n+#if defined(TEXT_DATA_BUG) && defined(__pic__) && defined(__SHMEDIA__)\n+\t.balign 2\n+\t.type\tLocal_div_table,@object\n+\t.size\tLocal_div_table,128\n+/* negative division constants */\n+\t.word\t-16638\n+\t.word\t-17135\n+\t.word\t-17737\n+\t.word\t-18433\n+\t.word\t-19103\n+\t.word\t-19751\n+\t.word\t-20583\n+\t.word\t-21383\n+\t.word\t-22343\n+\t.word\t-23353\n+\t.word\t-24407\n+\t.word\t-25582\n+\t.word\t-26863\n+\t.word\t-28382\n+\t.word\t-29965\n+\t.word\t-31800\n+/* negative division factors */\n+\t.byte\t66\n+\t.byte\t70\n+\t.byte\t75\n+\t.byte\t81\n+\t.byte\t87\n+\t.byte\t93\n+\t.byte\t101\n+\t.byte\t109\n+\t.byte\t119\n+\t.byte\t130\n+\t.byte\t142\n+\t.byte\t156\n+\t.byte\t172\n+\t.byte\t192\n+\t.byte\t214\n+\t.byte\t241\n+\t.skip 16\n+Local_div_table:\n+\t.skip 16\n+/* positive division factors */\n+\t.byte\t241\n+\t.byte\t214\n+\t.byte\t192\n+\t.byte\t172\n+\t.byte\t156\n+\t.byte\t142\n+\t.byte\t130\n+\t.byte\t119\n+\t.byte\t109\n+\t.byte\t101\n+\t.byte\t93\n+\t.byte\t87\n+\t.byte\t81\n+\t.byte\t75\n+\t.byte\t70\n+\t.byte\t66\n+/* positive division constants */\n+\t.word\t31801\n+\t.word\t29966\n+\t.word\t28383\n+\t.word\t26864\n+\t.word\t25583\n+\t.word\t24408\n+\t.word\t23354\n+\t.word\t22344\n+\t.word\t21384\n+\t.word\t20584\n+\t.word\t19752\n+\t.word\t19104\n+\t.word\t18434\n+\t.word\t17738\n+\t.word\t17136\n+\t.word\t16639\n+\t.section\t.rodata\n+#endif /* TEXT_DATA_BUG */\n+\t.balign 2\n+\t.type\tGLOBAL(div_table),@object\n+\t.size\tGLOBAL(div_table),128\n+/* negative division constants */\n+\t.word\t-16638\n+\t.word\t-17135\n+\t.word\t-17737\n+\t.word\t-18433\n+\t.word\t-19103\n+\t.word\t-19751\n+\t.word\t-20583\n+\t.word\t-21383\n+\t.word\t-22343\n+\t.word\t-23353\n+\t.word\t-24407\n+\t.word\t-25582\n+\t.word\t-26863\n+\t.word\t-28382\n+\t.word\t-29965\n+\t.word\t-31800\n+/* negative division factors */\n+\t.byte\t66\n+\t.byte\t70\n+\t.byte\t75\n+\t.byte\t81\n+\t.byte\t87\n+\t.byte\t93\n+\t.byte\t101\n+\t.byte\t109\n+\t.byte\t119\n+\t.byte\t130\n+\t.byte\t142\n+\t.byte\t156\n+\t.byte\t172\n+\t.byte\t192\n+\t.byte\t214\n+\t.byte\t241\n+\t.skip 16\n+\t.global\tGLOBAL(div_table)\n+GLOBAL(div_table):\n+\tHIDDEN_ALIAS(div_table_internal,div_table)\n+\t.skip 16\n+/* positive division factors */\n+\t.byte\t241\n+\t.byte\t214\n+\t.byte\t192\n+\t.byte\t172\n+\t.byte\t156\n+\t.byte\t142\n+\t.byte\t130\n+\t.byte\t119\n+\t.byte\t109\n+\t.byte\t101\n+\t.byte\t93\n+\t.byte\t87\n+\t.byte\t81\n+\t.byte\t75\n+\t.byte\t70\n+\t.byte\t66\n+/* positive division constants */\n+\t.word\t31801\n+\t.word\t29966\n+\t.word\t28383\n+\t.word\t26864\n+\t.word\t25583\n+\t.word\t24408\n+\t.word\t23354\n+\t.word\t22344\n+\t.word\t21384\n+\t.word\t20584\n+\t.word\t19752\n+\t.word\t19104\n+\t.word\t18434\n+\t.word\t17738\n+\t.word\t17136\n+\t.word\t16639\n+#endif /* L_div_table */\n+#endif /* __SH5__ */"}, {"sha": "325c74054ecf181a2ad042a1f44bcb22a21fbaeb", "filename": "gcc/config/sh/libgcc-excl.ver", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Flibgcc-excl.ver", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Flibgcc-excl.ver", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Flibgcc-excl.ver?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -3,5 +3,6 @@\n   __ashlsi3\n   __ashrsi3\n   __lshrsi3\n+  __mulsi3 # this is an SH1-only symbol.\n   __udivsi3\n }"}, {"sha": "013bf49a8fd9be389b3f3a3e57b8f8b859d3a9f8", "filename": "gcc/config/sh/linux.h", "status": "modified", "additions": 9, "deletions": 1, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Flinux.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Flinux.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Flinux.h?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -48,7 +48,8 @@ Boston, MA 02111-1307, USA.  */\n \n #undef TARGET_DEFAULT\n #define TARGET_DEFAULT \\\n-  (TARGET_CPU_DEFAULT | USERMODE_BIT | TARGET_ENDIAN_DEFAULT)\n+  (TARGET_CPU_DEFAULT | USERMODE_BIT | TARGET_ENDIAN_DEFAULT \\\n+   | TARGET_OPT_DEFAULT)\n \n #define TARGET_ASM_FILE_END file_end_indicate_exec_stack\n \n@@ -104,3 +105,10 @@ Boston, MA 02111-1307, USA.  */\n #undef DBX_REGISTER_NUMBER\n #define DBX_REGISTER_NUMBER(REGNO) \\\n   ((! TARGET_SH5 && (REGNO) == 16) ? 16 : SH_DBX_REGISTER_NUMBER (REGNO))\n+\n+/* Since libgcc is compiled with -fpic for this target, we can't use\n+   __sdivsi3_1 as the division strategy for -O0 and -Os.  */\n+#undef SH_DIV_STRATEGY_DEFAULT\n+#define SH_DIV_STRATEGY_DEFAULT SH_DIV_CALL2\n+#undef SH_DIV_STR_FOR_SIZE\n+#define SH_DIV_STR_FOR_SIZE \"call2\""}, {"sha": "c640ba0d4ceb522975836d927527b6944f1c7020", "filename": "gcc/config/sh/netbsd-elf.h", "status": "modified", "additions": 8, "deletions": 1, "changes": 9, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fnetbsd-elf.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fnetbsd-elf.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fnetbsd-elf.h?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -1,5 +1,5 @@\n /* Definitions for SH running NetBSD using ELF\n-   Copyright (C) 2002, 2003, 2004 Free Software Foundation, Inc.\n+   Copyright (C) 2002, 2003, 2004, 2005 Free Software Foundation, Inc.\n    Contributed by Wasabi Systems, Inc.\n \n This file is part of GCC.\n@@ -109,3 +109,10 @@ do\t\t\t\t\t\t\t\t\t\\\n       }\t\t\t\t\t\t\t\t\t\\\n   }\t\t\t\t\t\t\t\t\t\\\n while (0)\n+\n+/* Since libgcc is compiled with -fpic for this target, we can't use\n+   __sdivsi3_1 as the division strategy for -O0 and -Os.  */\n+#undef SH_DIV_STRATEGY_DEFAULT\n+#define SH_DIV_STRATEGY_DEFAULT SH_DIV_CALL2\n+#undef SH_DIV_STR_FOR_SIZE\n+#define SH_DIV_STR_FOR_SIZE \"call2\""}, {"sha": "062cc7efe4bbcd29953b0548e678231776849313", "filename": "gcc/config/sh/newlib.h", "status": "added", "additions": 26, "deletions": 0, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fnewlib.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fnewlib.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fnewlib.h?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -0,0 +1,26 @@\n+/* Definitions of target machine for gcc for Super-H using sh-superh-elf.\n+   Copyright (C) 2001 Free Software Foundation, Inc.\n+\n+This file is part of GNU CC.\n+\n+GNU CC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 2, or (at your option)\n+any later version.\n+\n+GNU CC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GNU CC; see the file COPYING.  If not, write to\n+the Free Software Foundation, 59 Temple Place - Suite 330,\n+Boston, MA 02111-1307, USA.  */\n+\n+\n+/* This header file is used when with_libgloss is enabled during gcc\n+   configuration.  */\n+\n+#undef LIB_SPEC\n+#define LIB_SPEC \"-lc -lgloss\""}, {"sha": "981cc8f10f5118ab8cc76947c1f6413c8b30d18a", "filename": "gcc/config/sh/predicates.md", "status": "added", "additions": 38, "deletions": 0, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fpredicates.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fpredicates.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fpredicates.md?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -0,0 +1,38 @@\n+(define_predicate \"trapping_target_operand\"\n+  (match_code \"if_then_else\")\n+{\n+  rtx cond, mem, res, tar, and;\n+\n+  if (GET_MODE (op) != PDImode)\n+    return 0;\n+  cond = XEXP (op, 0);\n+  mem = XEXP (op, 1);\n+  res = XEXP (op, 2);\n+  if (GET_CODE (mem) != MEM\n+      || (GET_CODE (res) != SIGN_EXTEND && GET_CODE (res) != TRUNCATE))\n+    return 0;\n+  tar = XEXP (res, 0);\n+  if (!rtx_equal_p (XEXP (mem, 0), tar)\n+      || GET_MODE (tar) != Pmode)\n+    return 0;\n+  if (GET_CODE (cond) == CONST)\n+    {\n+      cond = XEXP (cond, 0);\n+      if (!EXTRA_CONSTRAINT_Csy (tar))\n+\treturn 0;\n+      if (GET_CODE (tar) == CONST)\n+\ttar = XEXP (tar, 0);\n+    }\n+  else if (!arith_reg_operand (tar, VOIDmode)\n+\t   && ! EXTRA_CONSTRAINT_Csy (tar))\n+    return 0;\n+  if (GET_CODE (cond) != EQ)\n+    return 0;\n+  and = XEXP (cond, 0);\n+  return (GET_CODE (and) == AND\n+\t  && rtx_equal_p (XEXP (and, 0), tar)\n+\t  && GET_CODE (XEXP (and, 1)) == CONST_INT\n+\t  && GET_CODE (XEXP (cond, 1)) == CONST_INT\n+\t  && INTVAL (XEXP (and, 1)) == 3\n+\t  && INTVAL (XEXP (cond, 1)) == 3);\n+})"}, {"sha": "917708af6ce890b0ff923196496fab28dc30b654", "filename": "gcc/config/sh/sh-modes.def", "status": "modified", "additions": 2, "deletions": 0, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsh-modes.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsh-modes.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fsh-modes.def?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -20,6 +20,8 @@ Boston, MA 02111-1307, USA.  */\n \n /* The SH uses a partial integer mode to represent the FPSCR register.  */\n PARTIAL_INT_MODE (SI);\n+/* PDI mode is used to represent a function address in a target register.  */\n+PARTIAL_INT_MODE (DI);\n \n /* Vector modes.  */\n VECTOR_MODE  (INT, QI, 2);    /*                 V2QI */"}, {"sha": "4882ee366f29bb40123b0a2b2e895036c0e169f1", "filename": "gcc/config/sh/sh-protos.h", "status": "modified", "additions": 21, "deletions": 1, "changes": 22, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsh-protos.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsh-protos.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fsh-protos.h?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -24,6 +24,19 @@ Boston, MA 02111-1307, USA.  */\n #ifndef GCC_SH_PROTOS_H\n #define GCC_SH_PROTOS_H\n \n+enum sh_function_kind {\n+  /* A function with normal C ABI  */\n+  FUNCTION_ORDINARY,\n+  /* A special function that guarantees that some otherwise call-clobbered\n+     registers are not clobbered.  These can't go through the SH5 resolver,\n+     because it only saves argument passing registers.  */\n+  SFUNC_GOT,\n+  /* A special function that should be linked statically.  These are typically\n+     smaller or not much larger than a PLT entry.\n+     Some also have a non-standard ABI which precludes dynamic linking.  */\n+  SFUNC_STATIC\n+};\n+\n #ifdef RTX_CODE\n extern rtx sh_fsca_sf2int (void);\n extern rtx sh_fsca_df2int (void);\n@@ -101,6 +114,7 @@ extern int sh_can_redirect_branch (rtx, rtx);\n extern void sh_expand_unop_v2sf (enum rtx_code, rtx, rtx);\n extern void sh_expand_binop_v2sf (enum rtx_code, rtx, rtx, rtx);\n extern int sh_expand_t_scc (enum rtx_code code, rtx target);\n+extern rtx sh_gen_truncate (enum machine_mode, rtx, int);\n extern bool sh_vector_mode_supported_p (enum machine_mode);\n #ifdef TREE_CODE\n extern void sh_va_start (tree, rtx);\n@@ -137,7 +151,7 @@ extern void fpscr_set_from_mem (int, HARD_REG_SET);\n extern void sh_pr_interrupt (struct cpp_reader *);\n extern void sh_pr_trapa (struct cpp_reader *);\n extern void sh_pr_nosave_low_regs (struct cpp_reader *);\n-extern rtx function_symbol (const char *);\n+extern rtx function_symbol (rtx, const char *, enum sh_function_kind);\n extern rtx sh_get_pr_initial_val (void);\n \n extern rtx sh_function_arg (CUMULATIVE_ARGS *, enum machine_mode, tree, int);\n@@ -147,6 +161,12 @@ extern void sh_init_cumulative_args (CUMULATIVE_ARGS *, tree, rtx, tree, signed\n extern const char *sh_pch_valid_p (const void *data_p, size_t sz);\n extern bool sh_promote_prototypes (tree);\n \n+extern rtx replace_n_hard_rtx (rtx, rtx *, int , int);\n+extern int shmedia_cleanup_truncate (rtx *, void *);\n+\n+extern int sh_contains_memref_p (rtx);\n+extern rtx shmedia_prepare_call_address (rtx fnaddr, int is_sibcall);\n+\n #endif /* ! GCC_SH_PROTOS_H */\n \n #ifdef SYMBIAN"}, {"sha": "65cd9442a94b3df7d5ef5701d9bd9d297a3a0e8d", "filename": "gcc/config/sh/sh.c", "status": "modified", "additions": 1183, "deletions": 153, "changes": 1336, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsh.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsh.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fsh.c?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -52,6 +52,7 @@ Boston, MA 02111-1307, USA.  */\n #include \"sched-int.h\"\n #include \"ggc.h\"\n #include \"tree-gimple.h\"\n+#include \"cfgloop.h\"\n \n \n int code_for_indirect_jump_scratch = CODE_FOR_indirect_jump_scratch;\n@@ -265,6 +266,7 @@ static bool unspec_caller_rtx_p (rtx);\n static bool sh_cannot_copy_insn_p (rtx);\n static bool sh_rtx_costs (rtx, int, int, int *);\n static int sh_address_cost (rtx);\n+static int sh_adjust_unroll_max (struct loop *, int, int, int, int);\n static int shmedia_target_regs_stack_space (HARD_REG_SET *);\n static int shmedia_reserve_space_for_target_registers_p (int, HARD_REG_SET *);\n static int shmedia_target_regs_stack_adjust (HARD_REG_SET *);\n@@ -480,6 +482,11 @@ static int hard_regs_intersect_p (HARD_REG_SET *, HARD_REG_SET *);\n \n #endif /* SYMBIAN */\n \n+#ifdef TARGET_ADJUST_UNROLL_MAX\n+#undef TARGET_ADJUST_UNROLL_MAX\n+#define TARGET_ADJUST_UNROLL_MAX sh_adjust_unroll_max\n+#endif\n+\n struct gcc_target targetm = TARGET_INITIALIZER;\n \f\n /* Print the operand address in x to the stream.  */\n@@ -546,6 +553,7 @@ print_operand_address (FILE *stream, rtx x)\n    '@'  print trap, rte or rts depending upon pragma interruptness\n    '#'  output a nop if there is nothing to put in the delay slot\n    '''  print likelihood suffix (/u for unlikely).\n+   '>'  print branch target if -fverbose-asm\n    'O'  print a constant without the #\n    'R'  print the LSW of a dp value - changes if in little endian\n    'S'  print the MSW of a dp value - changes if in little endian\n@@ -554,12 +562,16 @@ print_operand_address (FILE *stream, rtx x)\n    'N'  print 'r63' if the operand is (const_int 0).\n    'd'  print a V2SF reg as dN instead of fpN.\n    'm'  print a pair `base,offset' or `base,index', for LD and ST.\n+   'U'  Likewise for {LD,ST}{HI,LO}.\n    'u'  prints the lowest 16 bits of CONST_INT, as an unsigned value.\n    'o'  output an operator.  */\n \n void\n print_operand (FILE *stream, rtx x, int code)\n {\n+  int regno;\n+  enum machine_mode mode;\n+\n   switch (code)\n     {\n     case '.':\n@@ -592,6 +604,13 @@ print_operand (FILE *stream, rtx x, int code)\n \t  fputs (\"/u\", stream);\n \tbreak;\n       }\n+    case '>':\n+      if (flag_verbose_asm && JUMP_LABEL (current_output_insn))\n+\t{\n+\t  fputs (\"\\t! target: \", stream);\n+\t  output_addr_const (stream, JUMP_LABEL (current_output_insn));\n+\t}\n+      break;\n     case 'O':\n       x = mark_constant_pool_use (x);\n       output_addr_const (stream, x);\n@@ -647,6 +666,8 @@ print_operand (FILE *stream, rtx x, int code)\n     case 'm':\n       gcc_assert (GET_CODE (x) == MEM);\n       x = XEXP (x, 0);\n+      /* Fall through.  */\n+    case 'U':\n       switch (GET_CODE (x))\n \t{\n \tcase REG:\n@@ -689,35 +710,87 @@ print_operand (FILE *stream, rtx x, int code)\n \n     default_output:\n     default:\n+      regno = 0;\n+      mode = GET_MODE (x);\n+\n       switch (GET_CODE (x))\n \t{\n+\tcase TRUNCATE:\n+\t  {\n+\t    rtx inner = XEXP (x, 0);\n+\t    int offset = 0;\n+\t    enum machine_mode inner_mode;\n+\n+\t    /* We might see SUBREGs with vector mode registers inside.  */\n+\t    if (GET_CODE (inner) == SUBREG\n+\t\t&& (GET_MODE_SIZE (GET_MODE (inner))\n+\t\t    == GET_MODE_SIZE (GET_MODE (SUBREG_REG (inner))))\n+\t\t&& subreg_lowpart_p (inner))\n+\t      inner = SUBREG_REG (inner);\n+\t    if (GET_CODE (inner) == CONST_INT)\n+\t      {\n+\t\tx = GEN_INT (trunc_int_for_mode (INTVAL (inner), GET_MODE (x)));\n+\t\tgoto default_output;\n+\t      }\n+\t    inner_mode = GET_MODE (inner);\n+\t    if (GET_CODE (inner) == SUBREG\n+\t\t&& (GET_MODE_SIZE (GET_MODE (inner))\n+\t\t    < GET_MODE_SIZE (GET_MODE (SUBREG_REG (inner))))\n+\t\t&& GET_CODE (SUBREG_REG (inner)) == REG)\n+\t      {\n+\t\toffset = subreg_regno_offset (REGNO (SUBREG_REG (inner)),\n+\t\t\t\t\t      GET_MODE (SUBREG_REG (inner)),\n+\t\t\t\t\t      SUBREG_BYTE (inner),\n+\t\t\t\t\t      GET_MODE (inner));\n+\t\tinner = SUBREG_REG (inner);\n+\t      }\n+\t    if (GET_CODE (inner) != REG || GET_MODE_SIZE (inner_mode) > 8)\n+\t      abort ();\n+\t    /* Floating point register pairs are always big endian;\n+\t       general purpose registes are 64 bit wide.  */\n+\t    regno = REGNO (inner);\n+\t    regno = (HARD_REGNO_NREGS (regno, inner_mode)\n+\t\t     - HARD_REGNO_NREGS (regno, mode))\n+\t\t     + offset;\n+\t    x = inner;\n+\t    goto reg;\n+\t  }\n+\tcase SIGN_EXTEND:\n+\t  x = XEXP (x, 0);\n+\t  goto reg;\n \t  /* FIXME: We need this on SHmedia32 because reload generates\n \t     some sign-extended HI or QI loads into DImode registers\n \t     but, because Pmode is SImode, the address ends up with a\n \t     subreg:SI of the DImode register.  Maybe reload should be\n \t     fixed so as to apply alter_subreg to such loads?  */\n+\tcase IF_THEN_ELSE:\n+\t  gcc_assert (trapping_target_operand (x, VOIDmode));\n+\t  x = XEXP (XEXP (x, 2), 0);\n+\t  goto default_output;\n \tcase SUBREG:\n \t  gcc_assert (SUBREG_BYTE (x) == 0\n \t\t      && GET_CODE (SUBREG_REG (x)) == REG);\n \n \t  x = SUBREG_REG (x);\n \t  /* Fall through.  */\n \n+\treg:\n \tcase REG:\n-\t  if (FP_REGISTER_P (REGNO (x))\n-\t      && GET_MODE (x) == V16SFmode)\n-\t    fprintf ((stream), \"mtrx%s\", reg_names[REGNO (x)] + 2);\n+\t  regno += REGNO (x);\n+\t  if (FP_REGISTER_P (regno)\n+\t      && mode == V16SFmode)\n+\t    fprintf ((stream), \"mtrx%s\", reg_names[regno] + 2);\n \t  else if (FP_REGISTER_P (REGNO (x))\n-\t\t   && GET_MODE (x) == V4SFmode)\n-\t    fprintf ((stream), \"fv%s\", reg_names[REGNO (x)] + 2);\n+\t\t   && mode == V4SFmode)\n+\t    fprintf ((stream), \"fv%s\", reg_names[regno] + 2);\n \t  else if (GET_CODE (x) == REG\n-\t\t   && GET_MODE (x) == V2SFmode)\n-\t    fprintf ((stream), \"fp%s\", reg_names[REGNO (x)] + 2);\n+\t\t   && mode == V2SFmode)\n+\t    fprintf ((stream), \"fp%s\", reg_names[regno] + 2);\n \t  else if (FP_REGISTER_P (REGNO (x))\n-\t\t   && GET_MODE_SIZE (GET_MODE (x)) > 4)\n-\t    fprintf ((stream), \"d%s\", reg_names[REGNO (x)] + 1);\n+\t\t   && GET_MODE_SIZE (mode) > 4)\n+\t    fprintf ((stream), \"d%s\", reg_names[regno] + 1);\n \t  else\n-\t    fputs (reg_names[REGNO (x)], (stream));\n+\t    fputs (reg_names[regno], (stream));\n \t  break;\n \n \tcase MEM:\n@@ -727,7 +800,8 @@ print_operand (FILE *stream, rtx x, int code)\n \tcase CONST:\n \t  if (TARGET_SHMEDIA\n \t      && GET_CODE (XEXP (x, 0)) == SIGN_EXTEND\n-\t      && GET_MODE (XEXP (x, 0)) == DImode\n+\t      && (GET_MODE (XEXP (x, 0)) == DImode\n+\t\t  || GET_MODE (XEXP (x, 0)) == SImode)\n \t      && GET_CODE (XEXP (XEXP (x, 0), 0)) == TRUNCATE\n \t      && GET_MODE (XEXP (XEXP (x, 0), 0)) == HImode)\n \t    {\n@@ -842,36 +916,27 @@ expand_block_move (rtx *operands)\n \treturn 0;\n       else if (bytes == 12)\n \t{\n-\t  tree entry_name;\n-\t  rtx sym;\n-\t  rtx func_addr_rtx;\n+\t  rtx func_addr_rtx = gen_reg_rtx (Pmode);\n \t  rtx r4 = gen_rtx_REG (SImode, 4);\n \t  rtx r5 = gen_rtx_REG (SImode, 5);\n \n-\t  entry_name = get_identifier (\"__movmemSI12_i4\");\n-\n-\t  sym = function_symbol (IDENTIFIER_POINTER (entry_name));\n-\t  func_addr_rtx = copy_to_mode_reg (Pmode, sym);\n+\t  function_symbol (func_addr_rtx, \"__movmemSI12_i4\", SFUNC_STATIC);\n \t  force_into (XEXP (operands[0], 0), r4);\n \t  force_into (XEXP (operands[1], 0), r5);\n \t  emit_insn (gen_block_move_real_i4 (func_addr_rtx));\n \t  return 1;\n \t}\n       else if (! TARGET_SMALLCODE)\n \t{\n-\t  tree entry_name;\n-\t  rtx sym;\n-\t  rtx func_addr_rtx;\n+\t  const char *entry_name;\n+\t  rtx func_addr_rtx = gen_reg_rtx (Pmode);\n \t  int dwords;\n \t  rtx r4 = gen_rtx_REG (SImode, 4);\n \t  rtx r5 = gen_rtx_REG (SImode, 5);\n \t  rtx r6 = gen_rtx_REG (SImode, 6);\n \n-\t  entry_name = get_identifier (bytes & 4\n-\t\t\t\t       ? \"__movmem_i4_odd\"\n-\t\t\t\t       : \"__movmem_i4_even\");\n-\t  sym = function_symbol (IDENTIFIER_POINTER (entry_name));\n-\t  func_addr_rtx = copy_to_mode_reg (Pmode, sym);\n+\t  entry_name = (bytes & 4 ? \"__movmem_i4_odd\" : \"__movmem_i4_even\");\n+\t  function_symbol (func_addr_rtx, entry_name, SFUNC_STATIC);\n \t  force_into (XEXP (operands[0], 0), r4);\n \t  force_into (XEXP (operands[1], 0), r5);\n \n@@ -886,16 +951,12 @@ expand_block_move (rtx *operands)\n   if (bytes < 64)\n     {\n       char entry[30];\n-      tree entry_name;\n-      rtx sym;\n-      rtx func_addr_rtx;\n+      rtx func_addr_rtx = gen_reg_rtx (Pmode);\n       rtx r4 = gen_rtx_REG (SImode, 4);\n       rtx r5 = gen_rtx_REG (SImode, 5);\n \n       sprintf (entry, \"__movmemSI%d\", bytes);\n-      entry_name = get_identifier (entry);\n-      sym = function_symbol (IDENTIFIER_POINTER (entry_name));\n-      func_addr_rtx = copy_to_mode_reg (Pmode, sym);\n+      function_symbol (func_addr_rtx, entry, SFUNC_STATIC);\n       force_into (XEXP (operands[0], 0), r4);\n       force_into (XEXP (operands[1], 0), r5);\n       emit_insn (gen_block_move_real (func_addr_rtx));\n@@ -906,17 +967,13 @@ expand_block_move (rtx *operands)\n      less common function name, so this will occasionally use more space.  */\n   if (! TARGET_SMALLCODE)\n     {\n-      tree entry_name;\n-      rtx sym;\n-      rtx func_addr_rtx;\n+      rtx func_addr_rtx = gen_reg_rtx (Pmode);\n       int final_switch, while_loop;\n       rtx r4 = gen_rtx_REG (SImode, 4);\n       rtx r5 = gen_rtx_REG (SImode, 5);\n       rtx r6 = gen_rtx_REG (SImode, 6);\n \n-      entry_name = get_identifier (\"__movmem\");\n-      sym = function_symbol (IDENTIFIER_POINTER (entry_name));\n-      func_addr_rtx = copy_to_mode_reg (Pmode, sym);\n+      function_symbol (func_addr_rtx, \"__movmem\", SFUNC_STATIC);\n       force_into (XEXP (operands[0], 0), r4);\n       force_into (XEXP (operands[1], 0), r5);\n \n@@ -997,7 +1054,8 @@ prepare_move_operands (rtx operands[], enum machine_mode mode)\n \t of a library call to the target.  Reject `st r0,@(rX,rY)' because\n \t reload will fail to find a spill register for rX, since r0 is already\n \t being used for the source.  */\n-      else if (refers_to_regno_p (R0_REG, R0_REG + 1, operands[1], (rtx *)0)\n+      else if (TARGET_SH1\n+\t       && refers_to_regno_p (R0_REG, R0_REG + 1, operands[1], (rtx *)0)\n \t       && GET_CODE (operands[0]) == MEM\n \t       && GET_CODE (XEXP (operands[0], 0)) == PLUS\n \t       && GET_CODE (XEXP (XEXP (operands[0], 0), 1)) == REG)\n@@ -1792,8 +1850,17 @@ addsubcosts (rtx x)\n static inline int\n multcosts (rtx x ATTRIBUTE_UNUSED)\n {\n+  if (*sh_multcost_str)\n+    return atoi (sh_multcost_str);\n   if (TARGET_SHMEDIA)\n-    return 3;\n+    /* ??? We have a mul insn, but it has a latency of three, and doesn't\n+       accept constants.  Ideally, we would use a cost of one or two and\n+       add the cost of the operand, but disregard the latter when inside loops\n+       and loop invariant code motion is still to follow.\n+       Using a multiply first and splitting it later if it's a loss\n+       doesn't work because of different sign / zero extension semantics\n+       of multiplies vs. shifts.  */\n+    return TARGET_SMALLCODE ? 2 : 3;\n \n   if (TARGET_SH2)\n     {\n@@ -1837,7 +1904,7 @@ sh_rtx_costs (rtx x, int code, int outer_code, int *total)\n \t  else if (CONST_OK_FOR_I16 (INTVAL (x)))\n             *total = COSTS_N_INSNS (outer_code != SET);\n \t  else if (CONST_OK_FOR_I16 (INTVAL (x) >> 16))\n-\t    *total = COSTS_N_INSNS (2);\n+\t    *total = COSTS_N_INSNS ((outer_code != SET) + 1);\n \t  else if (CONST_OK_FOR_I16 ((INTVAL (x) >> 16) >> 16))\n \t    *total = COSTS_N_INSNS (3);\n           else\n@@ -1870,8 +1937,19 @@ sh_rtx_costs (rtx x, int code, int outer_code, int *total)\n       else\n         *total = 10;\n       return true;\n+    case CONST_VECTOR:\n+      if (x == CONST0_RTX (GET_MODE (x)))\n+\t*total = 0;\n+      else if (sh_1el_vec (x, VOIDmode))\n+\t*total = outer_code != SET;\n+      if (sh_rep_vec (x, VOIDmode))\n+\t*total = ((GET_MODE_UNIT_SIZE (GET_MODE (x)) + 3) / 4\n+\t\t  + (outer_code != SET));\n+      *total = COSTS_N_INSNS (3) + (outer_code != SET);\n+      return true;\n \n     case PLUS:\n+    case MINUS:\n       *total = COSTS_N_INSNS (addsubcosts (x));\n       return true;\n \n@@ -1896,6 +1974,15 @@ sh_rtx_costs (rtx x, int code, int outer_code, int *total)\n       *total = COSTS_N_INSNS (20);\n       return true;\n \n+    case PARALLEL:\n+      if (sh_1el_vec (x, VOIDmode))\n+\t*total = outer_code != SET;\n+      if (sh_rep_vec (x, VOIDmode))\n+\t*total = ((GET_MODE_UNIT_SIZE (GET_MODE (x)) + 3) / 4\n+\t\t  + (outer_code != SET));\n+      *total = COSTS_N_INSNS (3) + (outer_code != SET);\n+      return true;\n+\n     case FLOAT:\n     case FIX:\n       *total = 100;\n@@ -2024,10 +2111,10 @@ gen_shifty_op (int code, rtx *operands)\n     }\n   else if (value == 0)\n     {\n-      /* This can happen when not optimizing.  We must output something here\n-\t to prevent the compiler from dying in final.c after the try_split\n-\t call.  */\n-      emit_insn (gen_nop ());\n+      /* This can happen even when optimizing, if there were subregs before\n+\t reload.  Don't output a nop here, as this is never optimized away;\n+\t use a no-op move instead.  */\n+      emit_insn (gen_rtx_SET (VOIDmode, operands[0], operands[0]));\n       return;\n     }\n \n@@ -2076,10 +2163,8 @@ gen_shifty_hi_op (int code, rtx *operands)\n int\n expand_ashiftrt (rtx *operands)\n {\n-  rtx sym;\n   rtx wrk;\n   char func[18];\n-  tree func_name;\n   int value;\n \n   if (TARGET_SH3)\n@@ -2107,6 +2192,16 @@ expand_ashiftrt (rtx *operands)\n \n   if (value == 31)\n     {\n+      /* If we are called from abs expansion, arrange things so that we\n+\t we can use a single MT instruction that doesn't clobber the source,\n+\t if LICM can hoist out the load of the constant zero.  */\n+      if (currently_expanding_to_rtl)\n+\t{\n+\t  emit_insn (gen_cmpgtsi_t (force_reg (SImode, CONST0_RTX (SImode)),\n+\t\t\t\t    operands[1]));\n+\t  emit_insn (gen_mov_neg_si_t (operands[0]));\n+\t  return 1;\n+\t}\n       emit_insn (gen_ashrsi2_31 (operands[0], operands[1]));\n       return 1;\n     }\n@@ -2136,9 +2231,7 @@ expand_ashiftrt (rtx *operands)\n   /* Load the value into an arg reg and call a helper.  */\n   emit_move_insn (gen_rtx_REG (SImode, 4), operands[1]);\n   sprintf (func, \"__ashiftrt_r4_%d\", value);\n-  func_name = get_identifier (func);\n-  sym = function_symbol (IDENTIFIER_POINTER (func_name));\n-  emit_move_insn (wrk, sym);\n+  function_symbol (wrk, func, SFUNC_STATIC);\n   emit_insn (gen_ashrsi3_n (GEN_INT (value), wrk));\n   emit_move_insn (operands[0], gen_rtx_REG (SImode, 4));\n   return 1;\n@@ -2680,6 +2773,8 @@ gen_shl_sext (rtx dest, rtx left_rtx, rtx size_rtx, rtx source)\n rtx\n gen_datalabel_ref (rtx sym)\n {\n+  const char *str;\n+\n   if (GET_CODE (sym) == LABEL_REF)\n     return gen_rtx_CONST (GET_MODE (sym),\n \t\t\t  gen_rtx_UNSPEC (GET_MODE (sym),\n@@ -2688,6 +2783,12 @@ gen_datalabel_ref (rtx sym)\n \n   gcc_assert (GET_CODE (sym) == SYMBOL_REF);\n \n+  str = XSTR (sym, 0);\n+  /* Share all SYMBOL_REF strings with the same value - that is important\n+     for cse.  */\n+  str = IDENTIFIER_POINTER (get_identifier (str));\n+  XSTR (sym, 0) = str;\n+\n   return sym;\n }\n \n@@ -2758,10 +2859,10 @@ typedef struct\n } pool_node;\n \n /* The maximum number of constants that can fit into one pool, since\n-   the pc relative range is 0...1020 bytes and constants are at least 4\n-   bytes long.  */\n+   constants in the range 0..510 are at least 2 bytes long, and in the\n+   range from there to 1018 at least 4 bytes.  */\n \n-#define MAX_POOL_SIZE (1020/4)\n+#define MAX_POOL_SIZE 372\n static pool_node pool_vector[MAX_POOL_SIZE];\n static int pool_size;\n static rtx pool_window_label;\n@@ -3261,11 +3362,6 @@ find_barrier (int num_mova, rtx mova, rtx from)\n \t      if (num_mova)\n \t\tsi_limit -= GET_MODE_SIZE (mode);\n \t    }\n-\n-\t  /* See the code in machine_dependent_reorg, which has a similar if\n-\t     statement that generates a new mova insn in many cases.  */\n-\t  if (GET_CODE (dst) == REG && FP_ANY_REGISTER_P (REGNO (dst)))\n-\t    inc += 2;\n \t}\n \n       if (mova_p (from))\n@@ -5292,6 +5388,8 @@ sh_media_register_for_return (void)\n   if (lookup_attribute (\"interrupt_handler\",\n \t\t\tDECL_ATTRIBUTES (current_function_decl)))\n     return -1;\n+  if (sh_cfun_interrupt_handler_p ())\n+    return -1;\n \n   tr0_used = flag_pic && regs_ever_live[PIC_OFFSET_TABLE_REGNUM];\n \n@@ -5760,12 +5858,12 @@ sh_expand_prologue (void)\n \n   if (SHMEDIA_REGS_STACK_ADJUST ())\n     {\n-      emit_move_insn (gen_rtx_REG (Pmode, R0_REG),\n-\t\t      function_symbol (TARGET_FPU_ANY\n-\t\t\t\t       ? \"__GCC_push_shmedia_regs\"\n-\t\t\t\t       : \"__GCC_push_shmedia_regs_nofpu\"));\n       /* This must NOT go through the PLT, otherwise mach and macl\n \t may be clobbered.  */\n+      function_symbol (gen_rtx_REG (Pmode, R0_REG),\n+\t\t       (TARGET_FPU_ANY\n+\t\t\t? \"__GCC_push_shmedia_regs\"\n+\t\t\t: \"__GCC_push_shmedia_regs_nofpu\"), SFUNC_GOT);\n       emit_insn (gen_shmedia_save_restore_regs_compact\n \t\t (GEN_INT (-SHMEDIA_REGS_STACK_ADJUST ())));\n     }\n@@ -5795,8 +5893,8 @@ sh_expand_prologue (void)\n     {\n       /* This must NOT go through the PLT, otherwise mach and macl\n \t may be clobbered.  */\n-      emit_move_insn (gen_rtx_REG (Pmode, R0_REG),\n-\t\t      function_symbol (\"__GCC_shcompact_incoming_args\"));\n+      function_symbol (gen_rtx_REG (Pmode, R0_REG),\n+\t\t      \"__GCC_shcompact_incoming_args\", SFUNC_GOT);\n       emit_insn (gen_shcompact_incoming_args ());\n     }\n }\n@@ -5871,10 +5969,10 @@ sh_expand_epilogue (bool sibcall_p)\n \n   if (SHMEDIA_REGS_STACK_ADJUST ())\n     {\n-      emit_move_insn (gen_rtx_REG (Pmode, R0_REG),\n-\t\t      function_symbol (TARGET_FPU_ANY\n-\t\t\t\t       ? \"__GCC_pop_shmedia_regs\"\n-\t\t\t\t       : \"__GCC_pop_shmedia_regs_nofpu\"));\n+      function_symbol (gen_rtx_REG (Pmode, R0_REG),\n+\t\t       (TARGET_FPU_ANY\n+\t\t\t? \"__GCC_pop_shmedia_regs\"\n+\t\t\t: \"__GCC_pop_shmedia_regs_nofpu\"), SFUNC_GOT);\n       /* This must NOT go through the PLT, otherwise mach and macl\n \t may be clobbered.  */\n       emit_insn (gen_shmedia_save_restore_regs_compact\n@@ -7317,6 +7415,18 @@ sh_target_switches[] = TARGET_SWITCHES;\n const char *\n sh_pch_valid_p (const void *data_p, size_t len)\n {\n+#ifdef TARGET_OPTIONS\n+  /* ??? We have a copy of this in toplev.c, but it is static.  */\n+  static const struct\n+    {\n+      const char *const prefix;\n+      const char **const variable;\n+      const char *const description;\n+      const char *const value;\n+    }\n+  target_options[] = TARGET_OPTIONS;\n+#endif\n+\n   const char *data = (const char *)data_p;\n   const char *flag_that_differs = NULL;\n   size_t i;\n@@ -7437,6 +7547,14 @@ general_movsrc_operand (rtx op, enum machine_mode mode)\n \t  && system_reg_operand (XEXP (op, 0), mode)))\n     return 0;\n \n+  if (TARGET_SHMEDIA\n+      && (GET_CODE (op) == PARALLEL || GET_CODE (op) == CONST_VECTOR)\n+      && sh_rep_vec (op, mode))\n+    return 1;\n+  if (TARGET_SHMEDIA && 1\n+      && GET_CODE (op) == SUBREG && GET_MODE (op) == mode\n+      && SUBREG_REG (op) == const0_rtx && subreg_lowpart_p (op))\n+    /* FIXME */ abort (); // return 1;\n   return general_operand (op, mode);\n }\n \n@@ -7449,6 +7567,10 @@ general_movdst_operand (rtx op, enum machine_mode mode)\n   /* Only pre dec allowed.  */\n   if (GET_CODE (op) == MEM && GET_CODE (XEXP (op, 0)) == POST_INC)\n     return 0;\n+  if (mode == DImode && TARGET_SHMEDIA && GET_CODE (op) == SUBREG\n+      && GET_MODE_SIZE (GET_MODE (SUBREG_REG (op))) < 8\n+      && ! (high_life_started || reload_completed))\n+    return 0;\n \n   return general_operand (op, mode);\n }\n@@ -7474,6 +7596,28 @@ arith_reg_operand (rtx op, enum machine_mode mode)\n \t      && (regno != FPUL_REG || TARGET_SH4)\n \t      && regno != MACH_REG && regno != MACL_REG);\n     }\n+  /* Allow a no-op sign extension - compare LOAD_EXTEND_OP.\n+     We allow SImode here, as not using an FP register is just a matter of\n+     proper register allocation.  */\n+  if (TARGET_SHMEDIA\n+      && GET_MODE (op) == DImode && GET_CODE (op) == SIGN_EXTEND\n+      && GET_MODE (XEXP (op, 0)) == SImode\n+      && GET_CODE (XEXP (op, 0)) != SUBREG)\n+    return register_operand (XEXP (op, 0), VOIDmode);\n+#if 0 /* Can't do this because of PROMOTE_MODE for unsigned vars.  */\n+  if (GET_MODE (op) == SImode && GET_CODE (op) == SIGN_EXTEND\n+      && GET_MODE (XEXP (op, 0)) == HImode\n+      && GET_CODE (XEXP (op, 0)) == REG\n+      && REGNO (XEXP (op, 0)) <= LAST_GENERAL_REG)\n+    return register_operand (XEXP (op, 0), VOIDmode);\n+#endif\n+  if (GET_MODE_CLASS (GET_MODE (op)) == MODE_VECTOR_INT\n+      && GET_CODE (op) == SUBREG\n+      && GET_MODE (SUBREG_REG (op)) == DImode\n+      && GET_CODE (SUBREG_REG (op)) == SIGN_EXTEND\n+      && GET_MODE (XEXP (SUBREG_REG (op), 0)) == SImode\n+      && GET_CODE (XEXP (SUBREG_REG (op), 0)) != SUBREG)\n+    return register_operand (XEXP (SUBREG_REG (op), 0), VOIDmode);\n   return 0;\n }\n \n@@ -7484,7 +7628,21 @@ int\n arith_reg_dest (rtx op, enum machine_mode mode)\n {\n   if (mode == DImode && GET_CODE (op) == SUBREG\n-      && GET_MODE_SIZE (GET_MODE (SUBREG_REG (op))) < 8)\n+      && GET_MODE_SIZE (GET_MODE (SUBREG_REG (op))) < 8\n+      && TARGET_SHMEDIA)\n+    return 0;\n+  return arith_reg_operand (op, mode);\n+}\n+\n+/* Like arith_reg_operand, but for register source operands of narrow\n+  logical SHMEDIA operations: forbid subregs of DImode / TImode regs.  */\n+int\n+logical_reg_operand (rtx op, enum machine_mode mode)\n+{\n+  if (TARGET_SHMEDIA\n+      && GET_CODE (op) == SUBREG\n+      && GET_MODE_SIZE (GET_MODE (SUBREG_REG (op))) > 4\n+      && mode != DImode)\n     return 0;\n   return arith_reg_operand (op, mode);\n }\n@@ -7522,6 +7680,15 @@ fp_arith_reg_operand (rtx op, enum machine_mode mode)\n   return 0;\n }\n \n+int\n+fp_arith_reg_dest (rtx op, enum machine_mode mode)\n+{\n+  if (mode == DImode && GET_CODE (op) == SUBREG\n+      && GET_MODE_SIZE (GET_MODE (SUBREG_REG (op))) < 8)\n+    return 0;\n+  return fp_arith_reg_operand (op, mode);\n+}\n+\n /* Returns 1 if OP is a valid source operand for an arithmetic insn.  */\n \n int\n@@ -7540,6 +7707,14 @@ arith_operand (rtx op, enum machine_mode mode)\n       if (GET_CODE (op) == CONST_INT\n \t  || EXTRA_CONSTRAINT_C16 (op))\n \treturn 1;\n+      else if (GET_CODE (op) == TRUNCATE\n+\t       && ! system_reg_operand (XEXP (op, 0), VOIDmode)\n+\t       && (mode == VOIDmode || mode == GET_MODE (op))\n+\t       && (GET_MODE_SIZE (GET_MODE (op))\n+\t\t   < GET_MODE_SIZE (GET_MODE (XEXP (op, 0))))\n+\t       && (! FP_REGISTER_P (REGNO (XEXP (op, 0)))\n+\t\t   || GET_MODE_SIZE (GET_MODE (op)) == 4))\n+\treturn register_operand (XEXP (op, 0), VOIDmode);\n       else\n \treturn 0;\n     }\n@@ -7563,21 +7738,46 @@ arith_reg_or_0_operand (rtx op, enum machine_mode mode)\n   return 0;\n }\n \n-/* Return 1 if OP is a valid source operand for an SHmedia operation\n-   that takes either a register or a 6-bit immediate.  */\n+/* Return 1 if OP is a valid source operand for xor.  */\n \n int\n-shmedia_6bit_operand (rtx op, enum machine_mode mode)\n+xor_operand (rtx op, enum machine_mode mode)\n {\n-  return (arith_reg_operand (op, mode)\n-\t  || (GET_CODE (op) == CONST_INT && CONST_OK_FOR_I06 (INTVAL (op))));\n+  if (GET_CODE (op) == CONST_INT)\n+    return (TARGET_SHMEDIA\n+\t    ? (CONST_OK_FOR_I06 (INTVAL (op))\n+\t       || (no_new_pseudos && INTVAL (op) == 0xff))\n+\t    : CONST_OK_FOR_K08 (INTVAL (op)));\n+  if (TARGET_SHMEDIA\n+      && mode != DImode && GET_CODE (op) == SUBREG\n+      && GET_MODE_SIZE (GET_MODE (SUBREG_REG (op))) > 4)\n+    return 0;\n+  return arith_reg_operand (op, mode);\n+}\n+\n+/* Return 1 if OP is a valid source operand for shmedia cmpgt / cmpgtu.  */\n+int\n+cmp_operand (rtx op, enum machine_mode mode)\n+{\n+  if (GET_CODE (op) == CONST_INT && CONST_OK_FOR_N (INTVAL (op)))\n+    return 1;\n+  if (TARGET_SHMEDIA\n+      && mode != DImode && GET_CODE (op) == SUBREG\n+      && GET_MODE_SIZE (GET_MODE (SUBREG_REG (op))) > 4)\n+    return 0;\n+  return arith_reg_operand (op, mode);\n }\n \n /* Returns 1 if OP is a valid source operand for a logical operation.  */\n \n int\n logical_operand (rtx op, enum machine_mode mode)\n {\n+  if (TARGET_SHMEDIA\n+      && mode != DImode && GET_CODE (op) == SUBREG\n+      && GET_MODE_SIZE (GET_MODE (SUBREG_REG (op))) > 4)\n+    return 0;\n+\n   if (arith_reg_operand (op, mode))\n     return 1;\n \n@@ -7788,7 +7988,7 @@ equality_comparison_operator (rtx op, enum machine_mode mode)\n int\n greater_comparison_operator (rtx op, enum machine_mode mode)\n {\n-  if (mode != VOIDmode && GET_MODE (op) == mode)\n+  if (mode != VOIDmode && GET_MODE (op) != mode)\n     return 0;\n   switch (GET_CODE (op))\n     {\n@@ -7805,7 +8005,7 @@ greater_comparison_operator (rtx op, enum machine_mode mode)\n int\n less_comparison_operator (rtx op, enum machine_mode mode)\n {\n-  if (mode != VOIDmode && GET_MODE (op) == mode)\n+  if (mode != VOIDmode && GET_MODE (op) != mode)\n     return 0;\n   switch (GET_CODE (op))\n     {\n@@ -7819,12 +8019,45 @@ less_comparison_operator (rtx op, enum machine_mode mode)\n     }\n }\n \n+int\n+shift_operator (rtx op, enum machine_mode mode)\n+{\n+  if (mode != VOIDmode && GET_MODE (op) != mode)\n+    return 0;\n+  switch (GET_CODE (op))\n+    {\n+    case ASHIFT:\n+    case ASHIFTRT:\n+    case LSHIFTRT:\n+      return 1;\n+    default:\n+      return 0;\n+    }\n+}\n+\n+int\n+logical_operator (rtx op, enum machine_mode mode)\n+{\n+  if (mode != VOIDmode && GET_MODE (op) != mode)\n+    return 0;\n+  switch (GET_CODE (op))\n+    {\n+    case AND:\n+    case IOR:\n+    case XOR:\n+      return 1;\n+    default:\n+      return 0;\n+    }\n+}\n+\n /* Accept pseudos and branch target registers.  */\n int\n target_reg_operand (rtx op, enum machine_mode mode)\n {\n-  if (mode != DImode\n-      || GET_MODE (op) != DImode)\n+  if (mode == VOIDmode\n+     ? GET_MODE (op) != Pmode && GET_MODE (op) != PDImode\n+     : mode != GET_MODE (op))\n     return 0;\n \n   if (GET_CODE (op) == SUBREG)\n@@ -7848,10 +8081,10 @@ target_reg_operand (rtx op, enum machine_mode mode)\n int\n target_operand (rtx op, enum machine_mode mode)\n {\n-  if (mode != DImode)\n+  if (mode != VOIDmode && mode != Pmode)\n     return 0;\n \n-  if ((GET_MODE (op) == DImode || GET_MODE (op) == VOIDmode)\n+  if ((GET_MODE (op) == Pmode || GET_MODE (op) == VOIDmode)\n       && EXTRA_CONSTRAINT_Csy (op))\n     return ! reload_completed;\n \n@@ -7896,6 +8129,12 @@ extend_reg_or_0_operand (rtx op, enum machine_mode mode)\n \t  : arith_reg_or_0_operand) (op, mode);\n }\n \n+int\n+minuend_operand (rtx op, enum machine_mode mode)\n+{\n+  return op == constm1_rtx || extend_reg_or_0_operand (op, mode);\n+}\n+\n int\n general_extend_operand (rtx op, enum machine_mode mode)\n {\n@@ -7904,6 +8143,32 @@ general_extend_operand (rtx op, enum machine_mode mode)\n \t  : nonimmediate_operand) (op, mode);\n }\n \n+int\n+ua_address_operand (rtx op, enum machine_mode mode ATTRIBUTE_UNUSED)\n+{\n+  if (GET_CODE (op) == PLUS\n+      && (GET_CODE (XEXP (op, 1)) != CONST_INT\n+\t  || ! CONST_OK_FOR_I06 (INTVAL (XEXP (op, 1)))))\n+    return 0;\n+  return address_operand (op, QImode);\n+}\n+\n+int\n+cache_address_operand (rtx op, enum machine_mode mode)\n+{\n+  if (GET_CODE (op) == PLUS)\n+    {\n+      if (GET_CODE (XEXP (op, 0)) != REG)\n+\treturn 0;\n+      if (GET_CODE (XEXP (op, 1)) != CONST_INT\n+\t  || (INTVAL (XEXP (op, 1)) & 31))\n+\treturn 0;\n+    }\n+  else if (GET_CODE (op) != REG)\n+    return 0;\n+  return address_operand (op, mode);\n+}\n+\n int\n inqhi_operand (rtx op, enum machine_mode mode)\n {\n@@ -8499,6 +8764,14 @@ mark_constant_pool_use (rtx x)\n \n   return lab;\n }\n+\n+int\n+ua_offset (c, mode)\n+     rtx c;\n+     enum machine_mode mode ATTRIBUTE_UNUSED;\n+{\n+  return GET_CODE (c) == CONST_INT && CONST_OK_FOR_I06 (INTVAL (c));\n+}\n \f\n /* Return true if it's possible to redirect BRANCH1 to the destination\n    of an unconditional jump BRANCH2.  We only want to do this if the\n@@ -8566,11 +8839,58 @@ sh_adjust_cost (rtx insn, rtx link ATTRIBUTE_UNUSED, rtx dep_insn, int cost)\n       /* On SHmedia, if the dependence is an anti-dependence or\n          output-dependence, there is no cost.  */\n       if (REG_NOTE_KIND (link) != 0)\n-        cost = 0;\n+\t{\n+\t  /* However, dependencies between target register loads and\n+\t     uses of the register in a subsequent block that are separated\n+\t     by a conditional branch are not modelled - we have to do with\n+\t     the anti-dependency between the target register load and the\n+\t     conditional branch that ends the current block.  */\n+\t  if (REG_NOTE_KIND (link) == REG_DEP_ANTI\n+\t      && GET_CODE (PATTERN (dep_insn)) == SET\n+\t      && (get_attr_type (dep_insn) == TYPE_PT_MEDIA\n+\t\t  || get_attr_type (dep_insn) == TYPE_PTABS_MEDIA)\n+\t      && get_attr_type (insn) == TYPE_CBRANCH_MEDIA)\n+\t    {\n+\t      int orig_cost = cost;\n+\t      rtx note = find_reg_note (insn, REG_BR_PROB, 0);\n+\t      rtx target = ((! note\n+\t\t\t     || INTVAL (XEXP (note, 0)) * 2 < REG_BR_PROB_BASE)\n+\t\t\t    ? insn : JUMP_LABEL (insn));\n+\t      /* On the likely path, the branch costs 1, on the unlikely path,\n+\t\t it costs 3.  */\n+\t      cost--;\n+\t      do\n+\t\ttarget = next_active_insn (target);\n+\t      while (target && ! flow_dependent_p (target, dep_insn)\n+\t\t     && --cost > 0);\n+\t      /* If two branches are executed in immediate succession, with the\n+\t\t first branch properly predicted, this causes a stall at the\n+\t\t second branch, hence we won't need the target for the\n+\t\t second branch for two cycles after the launch of the first\n+\t\t branch.  */\n+\t      if (cost > orig_cost - 2)\n+\t\tcost = orig_cost - 2;\n+\t    }\n+\t  else\n+\t    cost = 0;\n+\t}\n \n-      if (get_attr_is_mac_media (insn)\n-          && get_attr_is_mac_media (dep_insn))\n-        cost = 1;\n+      else if (get_attr_is_mac_media (insn)\n+\t       && get_attr_is_mac_media (dep_insn))\n+\tcost = 1;\n+\n+      else if (! reload_completed\n+\t       && GET_CODE (PATTERN (insn)) == SET\n+\t       && GET_CODE (SET_SRC (PATTERN (insn))) == FLOAT\n+\t       && GET_CODE (PATTERN (dep_insn)) == SET\n+\t       && fp_arith_reg_operand (SET_SRC (PATTERN (dep_insn)), VOIDmode)\n+\t       && cost < 4)\n+\tcost = 4;\n+      /* Schedule the ptabs for a casesi_jump_media in preference to stuff\n+\t that is needed at the target.  */\n+      else if (get_attr_type (insn) == TYPE_JUMP_MEDIA\n+\t       && ! flow_dependent_p (insn, dep_insn))\n+\tcost--;\n     }\n   else if (REG_NOTE_KIND (link) == 0)\n     {\n@@ -8599,7 +8919,9 @@ sh_adjust_cost (rtx insn, rtx link ATTRIBUTE_UNUSED, rtx dep_insn, int cost)\n \t  if (GET_CODE (call) == SET)\n \t    call = SET_SRC (call);\n \t  if (GET_CODE (call) == CALL && GET_CODE (XEXP (call, 0)) == MEM\n-\t      && ! reg_set_p (XEXP (XEXP (call, 0), 0), dep_insn))\n+\t\t  /* sibcalli_thunk uses a symbol_ref in an unspec.  */\n+\t      && (GET_CODE (XEXP (XEXP (call, 0), 0)) == UNSPEC\n+\t\t  || ! reg_set_p (XEXP (XEXP (call, 0), 0), dep_insn)))\n \t    cost = 0;\n \t}\n       /* Likewise, the most timing critical input for an sfuncs call\n@@ -9018,8 +9340,38 @@ sh_target_reg_class (void)\n static bool\n sh_optimize_target_register_callee_saved (bool after_prologue_epilogue_gen)\n {\n-  return (shmedia_space_reserved_for_target_registers\n-\t  && (! after_prologue_epilogue_gen || TARGET_SAVE_ALL_TARGET_REGS));\n+  HARD_REG_SET dummy;\n+  rtx insn;\n+\n+  if (! shmedia_space_reserved_for_target_registers)\n+    return 0;\n+  if (after_prologue_epilogue_gen && ! TARGET_SAVE_ALL_TARGET_REGS)\n+    return 0;\n+  if (calc_live_regs (&dummy) >= 6 * 8)\n+    return 1;\n+  /* This is a borderline case.  See if we got a nested loop, or a loop\n+     with a call, or with more than 4 labels inside.  */\n+  for (insn = get_insns(); insn; insn = NEXT_INSN (insn))\n+    {\n+      if (GET_CODE (insn) == NOTE\n+\t  && NOTE_LINE_NUMBER (insn) == NOTE_INSN_LOOP_BEG)\n+\t{\n+\t  int labels = 0;\n+\n+\t  do\n+\t    {\n+\t      insn = NEXT_INSN (insn);\n+\t      if ((GET_CODE (insn) == NOTE\n+\t\t   && NOTE_LINE_NUMBER (insn) == NOTE_INSN_LOOP_BEG)\n+\t\t  || GET_CODE (insn) == CALL_INSN\n+\t\t  || (GET_CODE (insn) == CODE_LABEL && ++labels > 4))\n+\t\treturn 1;\n+\t    }\n+\t  while (GET_CODE (insn) != NOTE\n+\t\t || NOTE_LINE_NUMBER (insn) != NOTE_INSN_LOOP_END);\n+\t}\n+    }\n+  return 0;\n }\n \n static bool\n@@ -9190,7 +9542,8 @@ sh_initialize_trampoline (rtx tramp, rtx fnaddr, rtx cxt)\n   if (TARGET_HARVARD)\n     {\n       if (TARGET_USERMODE)\n-\temit_library_call (function_symbol (\"__ic_invalidate\"),\n+\temit_library_call (function_symbol (NULL, \"__ic_invalidate\",\n+\t\t\t\t\t    FUNCTION_ORDINARY),\n \t\t\t   0, VOIDmode, 1, tramp, SImode);\n       else\n \temit_insn (gen_ic_invalidate_line (tramp));\n@@ -9201,13 +9554,18 @@ sh_initialize_trampoline (rtx tramp, rtx fnaddr, rtx cxt)\n    receives arguments ``by reference'' will have them stored in its\n    own stack frame, so it must not pass pointers or references to\n    these arguments to other functions by means of sibling calls.  */\n+/* If PIC, we cannot make sibling calls to global functions\n+   because the PLT requires r12 to be live.  */\n static bool\n sh_function_ok_for_sibcall (tree decl, tree exp ATTRIBUTE_UNUSED)\n {\n-  return (decl\n+  return (1\n \t  && (! TARGET_SHCOMPACT\n \t      || current_function_args_info.stack_regs == 0)\n-\t  && ! sh_cfun_interrupt_handler_p ());\n+\t  && ! sh_cfun_interrupt_handler_p ()\n+\t  && (! flag_pic\n+\t      || (decl && ! TREE_PUBLIC (decl))\n+\t      || (decl && DECL_VISIBILITY (decl) != VISIBILITY_DEFAULT)));\n }\n \f\n /* Machine specific built-in functions.  */\n@@ -9221,6 +9579,7 @@ struct builtin_description\n \n /* describe number and signedness of arguments; arg[0] == result\n    (1: unsigned, 2: signed, 4: don't care, 8: pointer 0: no argument */\n+/* 9: 64 bit pointer, 10: 32 bit pointer */\n static const char signature_args[][4] =\n {\n #define SH_BLTIN_V2SI2 0\n@@ -9246,28 +9605,34 @@ static const char signature_args[][4] =\n #define SH_BLTIN_SISF 10\n   { 4, 2 },\n #define SH_BLTIN_LDUA_L 11\n-  { 2, 8 },\n+  { 2, 10 },\n #define SH_BLTIN_LDUA_Q 12\n-  { 1, 8 },\n+  { 1, 10 },\n #define SH_BLTIN_STUA_L 13\n-  { 0, 8, 2 },\n+  { 0, 10, 2 },\n #define SH_BLTIN_STUA_Q 14\n-  { 0, 8, 1 },\n-#define SH_BLTIN_UDI 15\n-  { 0, 8, 1 },\n-#define SH_BLTIN_NUM_SHARED_SIGNATURES 16\n-#define SH_BLTIN_2 16\n-#define SH_BLTIN_SU 16\n+  { 0, 10, 1 },\n+#define SH_BLTIN_LDUA_L64 15\n+  { 2, 9 },\n+#define SH_BLTIN_LDUA_Q64 16\n+  { 1, 9 },\n+#define SH_BLTIN_STUA_L64 17\n+  { 0, 9, 2 },\n+#define SH_BLTIN_STUA_Q64 18\n+  { 0, 9, 1 },\n+#define SH_BLTIN_NUM_SHARED_SIGNATURES 19\n+#define SH_BLTIN_2 19\n+#define SH_BLTIN_SU 19\n   { 1, 2 },\n-#define SH_BLTIN_3 17\n-#define SH_BLTIN_SUS 17\n+#define SH_BLTIN_3 20\n+#define SH_BLTIN_SUS 20\n   { 2, 2, 1 },\n-#define SH_BLTIN_PSSV 18\n+#define SH_BLTIN_PSSV 21\n   { 0, 8, 2, 2 },\n-#define SH_BLTIN_XXUU 19\n-#define SH_BLTIN_UUUU 19\n+#define SH_BLTIN_XXUU 22\n+#define SH_BLTIN_UUUU 22\n   { 1, 1, 1, 1 },\n-#define SH_BLTIN_PV 20\n+#define SH_BLTIN_PV 23\n   { 0, 8 },\n };\n /* mcmv: operands considered unsigned.  */\n@@ -9285,10 +9650,7 @@ static const struct builtin_description bdesc[] =\n   { CODE_FOR_ssaddv2si3,\"__builtin_ssaddv2si3\", SH_BLTIN_V2SI3 },\n   { CODE_FOR_usaddv8qi3,\"__builtin_usaddv8qi3\", SH_BLTIN_V8QI3 },\n   { CODE_FOR_ssaddv4hi3,\"__builtin_ssaddv4hi3\", SH_BLTIN_V4HI3 },\n-#if 0\n-  { CODE_FOR_alloco32,\t\"__builtin_sh_media_ALLOCO\", SH_BLTIN_PV },\n-  { CODE_FOR_alloco64,\t\"__builtin_sh_media_ALLOCO\", SH_BLTIN_PV },\n-#endif\n+  { CODE_FOR_alloco_i,\t\"__builtin_sh_media_ALLOCO\", SH_BLTIN_PV },\n   { CODE_FOR_negcmpeqv8qi,\"__builtin_sh_media_MCMPEQ_B\", SH_BLTIN_V8QI3 },\n   { CODE_FOR_negcmpeqv2si,\"__builtin_sh_media_MCMPEQ_L\", SH_BLTIN_V2SI3 },\n   { CODE_FOR_negcmpeqv4hi,\"__builtin_sh_media_MCMPEQ_W\", SH_BLTIN_V4HI3 },\n@@ -9299,13 +9661,13 @@ static const struct builtin_description bdesc[] =\n   { CODE_FOR_mcnvs_lw,\t\"__builtin_sh_media_MCNVS_LW\", SH_BLTIN_3 },\n   { CODE_FOR_mcnvs_wb,\t\"__builtin_sh_media_MCNVS_WB\", SH_BLTIN_V4HI2V8QI },\n   { CODE_FOR_mcnvs_wub,\t\"__builtin_sh_media_MCNVS_WUB\", SH_BLTIN_V4HI2V8QI },\n-  { CODE_FOR_mextr1,\t\"__builtin_sh_media_MEXTR1\", SH_BLTIN_UDI },\n-  { CODE_FOR_mextr2,\t\"__builtin_sh_media_MEXTR2\", SH_BLTIN_UDI },\n-  { CODE_FOR_mextr3,\t\"__builtin_sh_media_MEXTR3\", SH_BLTIN_UDI },\n-  { CODE_FOR_mextr4,\t\"__builtin_sh_media_MEXTR4\", SH_BLTIN_UDI },\n-  { CODE_FOR_mextr5,\t\"__builtin_sh_media_MEXTR5\", SH_BLTIN_UDI },\n-  { CODE_FOR_mextr6,\t\"__builtin_sh_media_MEXTR6\", SH_BLTIN_UDI },\n-  { CODE_FOR_mextr7,\t\"__builtin_sh_media_MEXTR7\", SH_BLTIN_UDI },\n+  { CODE_FOR_mextr1,\t\"__builtin_sh_media_MEXTR1\", SH_BLTIN_V8QI3 },\n+  { CODE_FOR_mextr2,\t\"__builtin_sh_media_MEXTR2\", SH_BLTIN_V8QI3 },\n+  { CODE_FOR_mextr3,\t\"__builtin_sh_media_MEXTR3\", SH_BLTIN_V8QI3 },\n+  { CODE_FOR_mextr4,\t\"__builtin_sh_media_MEXTR4\", SH_BLTIN_V8QI3 },\n+  { CODE_FOR_mextr5,\t\"__builtin_sh_media_MEXTR5\", SH_BLTIN_V8QI3 },\n+  { CODE_FOR_mextr6,\t\"__builtin_sh_media_MEXTR6\", SH_BLTIN_V8QI3 },\n+  { CODE_FOR_mextr7,\t\"__builtin_sh_media_MEXTR7\", SH_BLTIN_V8QI3 },\n   { CODE_FOR_mmacfx_wl,\t\"__builtin_sh_media_MMACFX_WL\", SH_BLTIN_MAC_HISI },\n   { CODE_FOR_mmacnfx_wl,\"__builtin_sh_media_MMACNFX_WL\", SH_BLTIN_MAC_HISI },\n   { CODE_FOR_mulv2si3,\t\"__builtin_mulv2si3\", SH_BLTIN_V2SI3, },\n@@ -9342,8 +9704,10 @@ static const struct builtin_description bdesc[] =\n   { CODE_FOR_fsina_s,\t\"__builtin_sh_media_FSINA_S\", SH_BLTIN_SISF },\n   { CODE_FOR_fipr,\t\"__builtin_sh_media_FIPR_S\", SH_BLTIN_3 },\n   { CODE_FOR_ftrv,\t\"__builtin_sh_media_FTRV_S\", SH_BLTIN_3 },\n+  { CODE_FOR_mac_media,\t\"__builtin_sh_media_FMAC_S\", SH_BLTIN_3 },\n+  { CODE_FOR_sqrtdf2,\t\"__builtin_sh_media_FSQRT_D\", SH_BLTIN_2 },\n+  { CODE_FOR_sqrtsf2,\t\"__builtin_sh_media_FSQRT_S\", SH_BLTIN_2 },\n   { CODE_FOR_fsrra_s,\t\"__builtin_sh_media_FSRRA_S\", SH_BLTIN_2 },\n-#if 0\n   { CODE_FOR_ldhi_l,\t\"__builtin_sh_media_LDHI_L\", SH_BLTIN_LDUA_L },\n   { CODE_FOR_ldhi_q,\t\"__builtin_sh_media_LDHI_Q\", SH_BLTIN_LDUA_Q },\n   { CODE_FOR_ldlo_l,\t\"__builtin_sh_media_LDLO_L\", SH_BLTIN_LDUA_L },\n@@ -9352,21 +9716,17 @@ static const struct builtin_description bdesc[] =\n   { CODE_FOR_sthi_q,\t\"__builtin_sh_media_STHI_Q\", SH_BLTIN_STUA_Q },\n   { CODE_FOR_stlo_l,\t\"__builtin_sh_media_STLO_L\", SH_BLTIN_STUA_L },\n   { CODE_FOR_stlo_q,\t\"__builtin_sh_media_STLO_Q\", SH_BLTIN_STUA_Q },\n-  { CODE_FOR_ldhi_l64,\t\"__builtin_sh_media_LDHI_L\", SH_BLTIN_LDUA_L },\n-  { CODE_FOR_ldhi_q64,\t\"__builtin_sh_media_LDHI_Q\", SH_BLTIN_LDUA_Q },\n-  { CODE_FOR_ldlo_l64,\t\"__builtin_sh_media_LDLO_L\", SH_BLTIN_LDUA_L },\n-  { CODE_FOR_ldlo_q64,\t\"__builtin_sh_media_LDLO_Q\", SH_BLTIN_LDUA_Q },\n-  { CODE_FOR_sthi_l64,\t\"__builtin_sh_media_STHI_L\", SH_BLTIN_STUA_L },\n-  { CODE_FOR_sthi_q64,\t\"__builtin_sh_media_STHI_Q\", SH_BLTIN_STUA_Q },\n-  { CODE_FOR_stlo_l64,\t\"__builtin_sh_media_STLO_L\", SH_BLTIN_STUA_L },\n-  { CODE_FOR_stlo_q64,\t\"__builtin_sh_media_STLO_Q\", SH_BLTIN_STUA_Q },\n-#endif\n+  { CODE_FOR_ldhi_l64,\t\"__builtin_sh_media_LDHI_L\", SH_BLTIN_LDUA_L64 },\n+  { CODE_FOR_ldhi_q64,\t\"__builtin_sh_media_LDHI_Q\", SH_BLTIN_LDUA_Q64 },\n+  { CODE_FOR_ldlo_l64,\t\"__builtin_sh_media_LDLO_L\", SH_BLTIN_LDUA_L64 },\n+  { CODE_FOR_ldlo_q64,\t\"__builtin_sh_media_LDLO_Q\", SH_BLTIN_LDUA_Q64 },\n+  { CODE_FOR_sthi_l64,\t\"__builtin_sh_media_STHI_L\", SH_BLTIN_STUA_L64 },\n+  { CODE_FOR_sthi_q64,\t\"__builtin_sh_media_STHI_Q\", SH_BLTIN_STUA_Q64 },\n+  { CODE_FOR_stlo_l64,\t\"__builtin_sh_media_STLO_L\", SH_BLTIN_STUA_L64 },\n+  { CODE_FOR_stlo_q64,\t\"__builtin_sh_media_STLO_Q\", SH_BLTIN_STUA_Q64 },\n   { CODE_FOR_nsb,\t\"__builtin_sh_media_NSB\", SH_BLTIN_SU },\n   { CODE_FOR_byterev,\t\"__builtin_sh_media_BYTEREV\", SH_BLTIN_2 },\n-#if 0\n-  { CODE_FOR_prefetch32,\"__builtin_sh_media_PREFO\", SH_BLTIN_PSSV },\n-  { CODE_FOR_prefetch64,\"__builtin_sh_media_PREFO\", SH_BLTIN_PSSV }\n-#endif\n+  { CODE_FOR_prefetch,\t\"__builtin_sh_media_PREFO\", SH_BLTIN_PSSV },\n };\n \n static void\n@@ -9378,7 +9738,7 @@ sh_media_init_builtins (void)\n   memset (shared, 0, sizeof shared);\n   for (d = bdesc; d - bdesc < (int) ARRAY_SIZE (bdesc); d++)\n     {\n-      tree type, arg_type;\n+      tree type, arg_type = 0;\n       int signature = d->signature;\n       int i;\n \n@@ -9388,8 +9748,9 @@ sh_media_init_builtins (void)\n \t{\n \t  int has_result = signature_args[signature][0] != 0;\n \n-\t  if (signature_args[signature][1] == 8\n-\t      && (insn_data[d->icode].operand[has_result].mode != Pmode))\n+\t  if ((signature_args[signature][1] & 8)\n+\t      && (((signature_args[signature][1] & 1) && TARGET_SHMEDIA32)\n+\t\t  || ((signature_args[signature][1] & 2) && TARGET_SHMEDIA64)))\n \t    continue;\n \t  if (! TARGET_FPU_ANY\n \t      && FLOAT_MODE_P (insn_data[d->icode].operand[0].mode))\n@@ -9400,12 +9761,12 @@ sh_media_init_builtins (void)\n \t      int arg = signature_args[signature][i];\n \t      int opno = i - 1 + has_result;\n \n-\t      if (arg == 8)\n+\t      if (arg & 8)\n \t\targ_type = ptr_type_node;\n \t      else if (arg)\n-\t\targ_type = ((*lang_hooks.types.type_for_mode)\n-\t\t\t    (insn_data[d->icode].operand[opno].mode,\n-\t\t\t     (arg & 1)));\n+\t\targ_type = (*lang_hooks.types.type_for_mode)\n+\t\t  (insn_data[d->icode].operand[opno].mode,\n+\t\t   (arg & 1));\n \t      else if (i)\n \t\tcontinue;\n \t      else\n@@ -9480,7 +9841,7 @@ sh_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n   enum machine_mode tmode = VOIDmode;\n   int nop = 0, i;\n   rtx op[4];\n-  rtx pat;\n+  rtx pat = 0;\n \n   if (signature_args[signature][0])\n     {\n@@ -9501,18 +9862,27 @@ sh_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,\n     {\n       tree arg;\n       enum machine_mode opmode, argmode;\n+      tree optype;\n \n       if (! signature_args[signature][i])\n \tbreak;\n       arg = TREE_VALUE (arglist);\n       if (arg == error_mark_node)\n \treturn const0_rtx;\n       arglist = TREE_CHAIN (arglist);\n-      opmode = insn_data[icode].operand[nop].mode;\n+      if (signature_args[signature][i] & 8)\n+\t{\n+\t  opmode = ptr_mode;\n+\t  optype = ptr_type_node;\n+\t}\n+      else\n+\t{\n+\t  opmode = insn_data[icode].operand[nop].mode;\n+\t  optype = (*lang_hooks.types.type_for_mode) (opmode, 0);\n+\t}\n       argmode = TYPE_MODE (TREE_TYPE (arg));\n       if (argmode != opmode)\n-\targ = build1 (NOP_EXPR,\n-\t\t      (*lang_hooks.types.type_for_mode) (opmode, 0), arg);\n+\targ = build1 (NOP_EXPR, optype, arg);\n       op[nop] = expand_expr (arg, NULL_RTX, opmode, 0);\n       if (! (*insn_data[icode].operand[nop].predicate) (op[nop], opmode))\n \top[nop] = copy_to_mode_reg (opmode, op[nop]);\n@@ -9662,6 +10032,16 @@ sh_register_move_cost (enum machine_mode mode,\n       || ((dstclass) == TARGET_REGS && ! REGCLASS_HAS_GENERAL_REG (srcclass)))\n     return 20;\n \n+  /* ??? ptabs faults on (value & 0x3) == 0x3  */\n+  if (TARGET_SHMEDIA\n+      && ((srcclass) == TARGET_REGS || (srcclass) == SIBCALL_REGS))\n+    {\n+      if (*sh_gettrcost_str)\n+\treturn atoi (sh_gettrcost_str);\n+      else if (!TARGET_PT_FIXED)\n+\treturn 100;\n+    }\n+\n   if ((srcclass == FPSCR_REGS && ! REGCLASS_HAS_GENERAL_REG (dstclass))\n       || (dstclass == FPSCR_REGS && ! REGCLASS_HAS_GENERAL_REG (srcclass)))\n   return 4;\n@@ -9689,11 +10069,43 @@ int\n cmpsi_operand (rtx op, enum machine_mode mode)\n {\n   if (GET_CODE (op) == REG && REGNO (op) == T_REG\n-      && GET_MODE (op) == SImode)\n+      && GET_MODE (op) == SImode\n+      && TARGET_SH1)\n     return 1;\n   return arith_operand (op, mode);\n }\n \n+int\n+shift_count_reg_operand (rtx op, enum machine_mode mode)\n+{\n+  if ((GET_CODE (op) == ZERO_EXTEND || GET_CODE (op) == SIGN_EXTEND\n+       || (GET_CODE (op) == SUBREG && SUBREG_BYTE (op) == 0))\n+      && (mode == VOIDmode || mode == GET_MODE (op))\n+      && GET_MODE_BITSIZE (GET_MODE (XEXP (op, 0))) >= 6\n+      && GET_MODE_CLASS (GET_MODE (XEXP (op, 0))) == MODE_INT)\n+    {\n+      mode = VOIDmode;\n+      do\n+\top = XEXP (op, 0);\n+      while ((GET_CODE (op) == ZERO_EXTEND || GET_CODE (op) == SIGN_EXTEND\n+\t      || GET_CODE (op) == TRUNCATE)\n+\t     && GET_MODE_BITSIZE (GET_MODE (XEXP (op, 0))) >= 6\n+\t     && GET_MODE_CLASS (GET_MODE (XEXP (op, 0))) == MODE_INT);\n+\n+    }\n+  return arith_reg_operand (op, mode);\n+}\n+\n+int\n+shift_count_operand (rtx op, enum machine_mode mode)\n+{\n+  return (CONSTANT_P (op)\n+\t  ? (GET_CODE (op) == CONST_INT\n+\t     ? (unsigned) INTVAL (op) < GET_MODE_BITSIZE (mode)\n+\t     : nonmemory_operand (op, mode))\n+\t  : shift_count_reg_operand (op, mode));\n+}\n+\n static rtx emit_load_ptr (rtx, rtx);\n \n static rtx\n@@ -9706,7 +10118,7 @@ emit_load_ptr (rtx reg, rtx addr)\n   return emit_move_insn (reg, mem);\n }\n \n-void\n+static void\n sh_output_mi_thunk (FILE *file, tree thunk_fndecl ATTRIBUTE_UNUSED,\n \t\t    HOST_WIDE_INT delta, HOST_WIDE_INT vcall_offset,\n \t\t    tree function)\n@@ -9718,6 +10130,7 @@ sh_output_mi_thunk (FILE *file, tree thunk_fndecl ATTRIBUTE_UNUSED,\n   int simple_add = CONST_OK_FOR_ADD (delta);\n   int did_load = 0;\n   rtx scratch0, scratch1, scratch2;\n+  unsigned i;\n \n   reload_completed = 1;\n   epilogue_completed = 1;\n@@ -9748,18 +10161,39 @@ sh_output_mi_thunk (FILE *file, tree thunk_fndecl ATTRIBUTE_UNUSED,\n      static chain pointer (even if you can't have nested virtual functions\n      right now, someone might implement them sometime), and the rest of the\n      registers are used for argument passing, are callee-saved, or reserved.  */\n+  /* We need to check call_used_regs / fixed_regs in case -fcall_saved-reg /\n+     -ffixed-reg has been used.  */\n+  if (! call_used_regs[0] || fixed_regs[0])\n+    error (\"r0 needs to be available as a call-clobbered register\");\n   scratch0 = scratch1 = scratch2 = gen_rtx_REG (Pmode, 0);\n   if (! TARGET_SH5)\n     {\n-      scratch1 = gen_rtx_REG (ptr_mode, 1);\n+      if (call_used_regs[1] && ! fixed_regs[1])\n+\tscratch1 = gen_rtx_REG (ptr_mode, 1);\n       /* N.B., if not TARGET_HITACHI, register 2 is used to pass the pointer\n \t pointing where to return struct values.  */\n-      scratch2 = gen_rtx_REG (Pmode, 3);\n+      if (call_used_regs[3] && ! fixed_regs[3])\n+\tscratch2 = gen_rtx_REG (Pmode, 3);\n     }\n   else if (TARGET_SHMEDIA)\n     {\n-      scratch1 = gen_rtx_REG (ptr_mode, 21);\n-      scratch2 = gen_rtx_REG (Pmode, TR0_REG);\n+      for (i = FIRST_GENERAL_REG; i <= LAST_GENERAL_REG; i++)\n+\tif (i != REGNO (scratch0) &&\n+\t    call_used_regs[i] && ! fixed_regs[i] && ! FUNCTION_ARG_REGNO_P (i))\n+\t  {\n+\t    scratch1 = gen_rtx_REG (ptr_mode, i);\n+\t    break;\n+\t  }\n+      if (scratch1 == scratch0)\n+\terror (\"Need a second call-clobbered general purpose register\");\n+      for (i = FIRST_TARGET_REG; i <= LAST_TARGET_REG; i++)\n+\tif (call_used_regs[i] && ! fixed_regs[i])\n+\t  {\n+\t    scratch2 = gen_rtx_REG (Pmode, i);\n+\t    break;\n+\t  }\n+      if (scratch2 == scratch0)\n+\terror (\"Need a call-clobbered target register\");\n     }\n \n   this_value = plus_constant (this, delta);\n@@ -9791,7 +10225,7 @@ sh_output_mi_thunk (FILE *file, tree thunk_fndecl ATTRIBUTE_UNUSED,\n       offset_addr = plus_constant (scratch0, vcall_offset);\n       if (strict_memory_address_p (ptr_mode, offset_addr))\n \t; /* Do nothing.  */\n-      else if (! TARGET_SH5)\n+      else if (! TARGET_SH5 && scratch0 != scratch1)\n \t{\n \t  /* scratch0 != scratch1, and we have indexed loads.  Get better\n \t     schedule by loading the offset into r1 and using an indexed\n@@ -9827,9 +10261,30 @@ sh_output_mi_thunk (FILE *file, tree thunk_fndecl ATTRIBUTE_UNUSED,\n       TREE_USED (function) = 1;\n     }\n   funexp = XEXP (DECL_RTL (function), 0);\n-  emit_move_insn (scratch2, funexp);\n-  funexp = gen_rtx_MEM (FUNCTION_MODE, scratch2);\n-  sibcall = emit_call_insn (gen_sibcall (funexp, const0_rtx, NULL_RTX));\n+  /* If the function is overridden, so is the thunk, hence we don't\n+     need GOT addressing even if this is a public symbol.  */\n+#if 0\n+  if (TARGET_SH1 && ! flag_weak)\n+    sibcall = gen_sibcalli_thunk (funexp, const0_rtx);\n+  else\n+#endif\n+  if (TARGET_SH2 && flag_pic)\n+    {\n+      sibcall = gen_sibcall_pcrel (funexp, const0_rtx);\n+      XEXP (XVECEXP (sibcall, 0, 2), 0) = scratch2;\n+    }\n+  else\n+    {\n+      if (TARGET_SHMEDIA && flag_pic)\n+\t{\n+\t  funexp = gen_sym2PIC (funexp);\n+\t  PUT_MODE (funexp, Pmode);\n+\t}\n+      emit_move_insn (scratch2, funexp);\n+      funexp = gen_rtx_MEM (FUNCTION_MODE, scratch2);\n+      sibcall = gen_sibcall (funexp, const0_rtx, NULL_RTX);\n+    }\n+  sibcall = emit_call_insn (sibcall);\n   SIBLING_CALL_P (sibcall) = 1;\n   use_reg (&CALL_INSN_FUNCTION_USAGE (sibcall), this);\n   emit_barrier ();\n@@ -9882,10 +10337,49 @@ sh_output_mi_thunk (FILE *file, tree thunk_fndecl ATTRIBUTE_UNUSED,\n }\n \n rtx\n-function_symbol (const char *name)\n+function_symbol (rtx target, const char *name, enum sh_function_kind kind)\n {\n-  rtx sym = gen_rtx_SYMBOL_REF (Pmode, name);\n+  rtx sym;\n+\n+  /* If this is not an ordinary function, the name usually comes from a\n+     string literal or an sprintf buffer.  Make sure we use the same\n+     string consistently, so that cse will be able to unify address loads.  */\n+  if (kind != FUNCTION_ORDINARY)\n+    name = IDENTIFIER_POINTER (get_identifier (name));\n+  sym = gen_rtx_SYMBOL_REF (Pmode, name);\n   SYMBOL_REF_FLAGS (sym) = SYMBOL_FLAG_FUNCTION;\n+  if (flag_pic)\n+    switch (kind)\n+      {\n+      case FUNCTION_ORDINARY:\n+\tbreak;\n+      case SFUNC_GOT:\n+\t{\n+\t  rtx reg = target ? target : gen_reg_rtx (Pmode);\n+\n+\t  emit_insn (gen_symGOT2reg (reg, sym));\n+\t  sym = reg;\n+\t  break;\n+\t}\n+      case SFUNC_STATIC:\n+\t{\n+\t  /* ??? To allow cse to work, we use GOTOFF relocations.\n+\t     we could add combiner patterns to transform this into\n+\t     straight pc-relative calls with sym2PIC / bsrf when\n+\t     label load and function call are still 1:1 and in the\n+\t     same basic block during combine.  */\n+\t  rtx reg = target ? target : gen_reg_rtx (Pmode);\n+\n+\t  emit_insn (gen_symGOTOFF2reg (reg, sym));\n+\t  sym = reg;\n+\t  break;\n+\t}\n+      }\n+  if (target && sym != target)\n+    {\n+      emit_move_insn (target, sym);\n+      return target;\n+    }\n   return sym;\n }\n \n@@ -10177,4 +10671,540 @@ hard_regs_intersect_p (HARD_REG_SET *a, HARD_REG_SET *b)\n   return 0;\n }\n \n+#ifdef TARGET_ADJUST_UNROLL_MAX\n+static int\n+sh_adjust_unroll_max (struct loop * loop, int insn_count,\n+\t\t      int max_unrolled_insns, int strength_reduce_p,\n+\t\t      int unroll_type)\n+{\n+/* This doesn't work in 4.0 because the old unroller & loop.h  is gone.  */\n+  if (TARGET_ADJUST_UNROLL && TARGET_SHMEDIA)\n+    {\n+      /* Throttle back loop unrolling so that the costs of using more\n+\t targets than the eight target register we have don't outweigh\n+\t the benefits of unrolling.  */\n+      rtx insn;\n+      int n_labels = 0, n_calls = 0, n_exit_dest = 0, n_inner_loops = -1;\n+      int n_barriers = 0;\n+      rtx dest;\n+      int i;\n+      rtx exit_dest[8];\n+      int threshold;\n+      int unroll_benefit = 0, mem_latency = 0;\n+      int base_cost, best_cost, cost;\n+      int factor, best_factor;\n+      int n_dest;\n+      unsigned max_iterations = 32767;\n+      int n_iterations;\n+      int need_precond = 0, precond = 0;\n+      basic_block * bbs = get_loop_body (loop);\n+      struct niter_desc *desc;\n+\n+      /* Assume that all labels inside the loop are used from inside the\n+\t loop.  If the loop has multiple entry points, it is unlikely to\n+\t be unrolled anyways.\n+\t Also assume that all calls are to different functions.  That is\n+\t somewhat pessimistic, but if you have lots of calls, unrolling the\n+\t loop is not likely to gain you much in the first place.  */\n+      i = loop->num_nodes - 1;\n+      for (insn = BB_HEAD (bbs[i]); ; )\n+\t{\n+\t  if (GET_CODE (insn) == CODE_LABEL)\n+\t    n_labels++;\n+\t  else if (GET_CODE (insn) == CALL_INSN)\n+\t    n_calls++;\n+\t  else if (GET_CODE (insn) == NOTE\n+\t\t   && NOTE_LINE_NUMBER (insn) == NOTE_INSN_LOOP_BEG)\n+\t    n_inner_loops++;\n+\t  else if (GET_CODE (insn) == BARRIER)\n+\t    n_barriers++;\n+\t  if (insn != BB_END (bbs[i]))\n+\t    insn = NEXT_INSN (insn);\n+\t  else if (--i >= 0)\n+\t    insn = BB_HEAD (bbs[i]);\n+\t   else\n+\t    break;\n+\t}\n+      free (bbs);\n+      /* One label for the loop top is normal, and it won't be duplicated by\n+\t unrolling.  */\n+      if (n_labels <= 1)\n+\treturn max_unrolled_insns;\n+      if (n_inner_loops > 0)\n+\treturn 0;\n+      for (dest = loop->exit_labels; dest && n_exit_dest < 8;\n+\t   dest = LABEL_NEXTREF (dest))\n+\t{\n+\t  for (i = n_exit_dest - 1;\n+\t       i >= 0 && XEXP (dest, 0) != XEXP (exit_dest[i], 0); i--);\n+\t  if (i < 0)\n+\t    exit_dest[n_exit_dest++] = dest;\n+\t}\n+      /* If the loop top and call and exit destinations are enough to fill up\n+\t the target registers, we're unlikely to do any more damage by\n+\t unrolling.  */\n+      if (n_calls + n_exit_dest >= 7)\n+\treturn max_unrolled_insns;\n+\n+      /* ??? In the new loop unroller, there is no longer any strength\n+         reduction information available.  Thus, when it comes to unrolling,\n+         we know the cost of everything, but we know the value of nothing.  */\n+#if 0\n+      if (strength_reduce_p\n+\t  && (unroll_type == LPT_UNROLL_RUNTIME\n+\t      || unroll_type == LPT_UNROLL_CONSTANT\n+\t      || unroll_type == LPT_PEEL_COMPLETELY))\n+\t{\n+\t  struct loop_ivs *ivs = LOOP_IVS (loop);\n+\t  struct iv_class *bl;\n+\n+\t  /* We'll save one compare-and-branch in each loop body copy\n+\t     but the last one.  */\n+\t  unroll_benefit = 1;\n+\t  /* Assess the benefit of removing biv & giv updates.  */\n+\t  for (bl = ivs->list; bl; bl = bl->next)\n+\t    {\n+\t      rtx increment = biv_total_increment (bl);\n+\t      struct induction *v;\n+\n+\t      if (increment && GET_CODE (increment) == CONST_INT)\n+\t\t{\n+\t\t  unroll_benefit++;\n+\t\t  for (v = bl->giv; v; v = v->next_iv)\n+\t\t    {\n+\t\t      if (! v->ignore && v->same == 0\n+\t\t\t  && GET_CODE (v->mult_val) == CONST_INT)\n+\t\t\tunroll_benefit++;\n+\t\t      /* If this giv uses an array, try to determine\n+\t\t\t a maximum iteration count from the size of the\n+\t\t\t array.  This need not be correct all the time,\n+\t\t\t but should not be too far off the mark too often.  */\n+\t\t      while (v->giv_type == DEST_ADDR)\n+\t\t\t{\n+\t\t\t  rtx mem = PATTERN (v->insn);\n+\t\t\t  tree mem_expr, type, size_tree;\n+\n+\t\t\t  if (GET_CODE (SET_SRC (mem)) == MEM)\n+\t\t\t    mem = SET_SRC (mem);\n+\t\t\t  else if (GET_CODE (SET_DEST (mem)) == MEM)\n+\t\t\t    mem = SET_DEST (mem);\n+\t\t\t  else\n+\t\t\t    break;\n+\t\t\t  mem_expr = MEM_EXPR (mem);\n+\t\t\t  if (! mem_expr)\n+\t\t\t    break;\n+\t\t\t  type = TREE_TYPE (mem_expr);\n+\t\t\t  if (TREE_CODE (type) != ARRAY_TYPE\n+\t\t\t      || ! TYPE_SIZE (type) || ! TYPE_SIZE_UNIT (type))\n+\t\t\t    break;\n+\t\t\t  size_tree = fold (build (TRUNC_DIV_EXPR,\n+\t\t\t\t\t\t   bitsizetype,\n+\t\t\t\t\t\t   TYPE_SIZE (type),\n+\t\t\t\t\t\t   TYPE_SIZE_UNIT (type)));\n+\t\t\t  if (TREE_CODE (size_tree) == INTEGER_CST\n+\t\t\t      && ! TREE_INT_CST_HIGH (size_tree)\n+\t\t\t      && TREE_INT_CST_LOW  (size_tree) < max_iterations)\n+\t\t\t    max_iterations = TREE_INT_CST_LOW  (size_tree);\n+\t\t\t  break;\n+\t\t\t}\n+\t\t    }\n+\t\t}\n+\t    }\n+\t}\n+#else /* 0 */\n+      /* Assume there is at least some benefit.  */\n+      unroll_benefit = 1;\n+#endif /* 0 */\n+\n+      desc = get_simple_loop_desc (loop);\n+      n_iterations = desc->const_iter ? desc->niter : 0;\n+      max_iterations\n+\t= max_iterations < desc->niter_max ? max_iterations : desc->niter_max;\n+\n+      if (! strength_reduce_p || ! n_iterations)\n+\tneed_precond = 1;\n+      if (! n_iterations)\n+\t{\n+\t  n_iterations\n+\t    = max_iterations < 3 ? max_iterations : max_iterations * 3 / 4;\n+\t  if (! n_iterations)\n+\t    return 0;\n+\t}\n+#if 0 /* ??? See above - missing induction variable information.  */\n+      while (unroll_benefit > 1) /* no loop */\n+\t{\n+\t  /* We include the benefit of biv/ giv updates.  Check if some or\n+\t     all of these updates are likely to fit into a scheduling\n+\t     bubble of a load.\n+\t     We check for the following case:\n+\t     - All the insns leading to the first JUMP_INSN are in a strict\n+\t       dependency chain.\n+\t     - there is at least one memory reference in them.\n+\n+\t     When we find such a pattern, we assume that we can hide as many\n+\t     updates as the total of the load latency is, if we have an\n+\t     unroll factor of at least two.  We might or might not also do\n+\t     this without unrolling, so rather than considering this as an\n+\t     extra unroll benefit, discount it in the unroll benefits of unroll\n+\t     factors higher than two.  */\n+\t\t\n+\t  rtx set, last_set;\n+\n+\t  insn = next_active_insn (loop->start);\n+\t  last_set = single_set (insn);\n+\t  if (! last_set)\n+\t    break;\n+\t  if (GET_CODE (SET_SRC (last_set)) == MEM)\n+\t    mem_latency += 2;\n+\t  for (insn = NEXT_INSN (insn); insn != end; insn = NEXT_INSN (insn))\n+\t    {\n+\t      if (! INSN_P (insn))\n+\t\tcontinue;\n+\t      if (GET_CODE (insn) == JUMP_INSN)\n+\t\tbreak;\n+\t      if (! reg_referenced_p (SET_DEST (last_set), PATTERN (insn)))\n+\t\t{\n+\t\t  /* Check if this is a to-be-reduced giv insn.  */\n+\t\t  struct loop_ivs *ivs = LOOP_IVS (loop);\n+\t\t  struct iv_class *bl;\n+\t\t  struct induction *v;\n+\t\t  for (bl = ivs->list; bl; bl = bl->next)\n+\t\t    {\n+\t\t      if (bl->biv->insn == insn)\n+\t\t\tgoto is_biv;\n+\t\t      for (v = bl->giv; v; v = v->next_iv)\n+\t\t\tif (v->insn == insn)\n+\t\t\t  goto is_giv;\n+\t\t    }\n+\t\t  mem_latency--;\n+\t\tis_biv:\n+\t\tis_giv:\n+\t\t  continue;\n+\t\t}\n+\t      set = single_set (insn);\n+\t      if (! set)\n+\t\tcontinue;\n+\t      if (GET_CODE (SET_SRC (set)) == MEM)\n+\t\tmem_latency += 2;\n+\t      last_set = set;\n+\t    }\n+\t  if (mem_latency < 0)\n+\t    mem_latency = 0;\n+\t  else if (mem_latency > unroll_benefit - 1)\n+\t    mem_latency = unroll_benefit - 1;\n+\t  break;\n+\t}\n+#endif /* 0 */\n+      if (n_labels + (unroll_benefit + n_labels * 8) / n_iterations\n+\t  <= unroll_benefit)\n+\treturn max_unrolled_insns;\n+\n+      n_dest = n_labels + n_calls + n_exit_dest;\n+      base_cost = n_dest <= 8 ? 0 : n_dest - 7;\n+      best_cost = 0;\n+      best_factor = 1;\n+      if (n_barriers * 2 > n_labels - 1)\n+\tn_barriers = (n_labels - 1) / 2;\n+      for (factor = 2; factor <= 8; factor++)\n+\t{\n+\t  /* Bump up preconditioning cost for each power of two.  */\n+\t  if (! (factor & (factor-1)))\n+\t    precond += 4;\n+\t  /* When preconditioning, only powers of two will be considered.  */\n+\t  else if (need_precond)\n+\t    continue;\n+\t  n_dest = ((unroll_type != LPT_PEEL_COMPLETELY)\n+\t\t    + (n_labels - 1) * factor + n_calls + n_exit_dest\n+\t\t    - (n_barriers * factor >> 1)\n+\t\t    + need_precond);\n+\t  cost\n+\t    = ((n_dest <= 8 ? 0 : n_dest - 7)\n+\t       - base_cost * factor\n+\t       - ((factor > 2 ? unroll_benefit - mem_latency : unroll_benefit)\n+\t\t  * (factor - (unroll_type != LPT_PEEL_COMPLETELY)))\n+\t       + ((unroll_benefit + 1 + (n_labels - 1) * factor)\n+\t\t  / n_iterations));\n+\t  if (need_precond)\n+\t    cost += (precond + unroll_benefit * factor / 2) / n_iterations;\n+\t  if (cost < best_cost)\n+\t    {\n+\t      best_cost = cost;\n+\t      best_factor = factor;\n+\t    }\n+\t}\n+      threshold = best_factor * insn_count;\n+      if (max_unrolled_insns > threshold)\n+\tmax_unrolled_insns = threshold;\n+    }\n+  return max_unrolled_insns;\n+}\n+#endif /* TARGET_ADJUST_UNROLL_MAX */\n+\n+/* Replace any occurrence of FROM(n) in X with TO(n).  The function does\n+   not enter into CONST_DOUBLE for the replace.\n+\n+   Note that copying is not done so X must not be shared unless all copies\n+   are to be modified.\n+\n+   This is like replace_rtx, except that we operate on N_REPLACEMENTS\n+   replacements sumultanously - FROM(n) is replacements[n*2] and to(n) is\n+   replacements[n*2+1] - and that we take mode changes into account.\n+\n+   If a replacement is ambigous, return NULL_RTX.\n+\n+   If MODIFY is zero, don't modify any rtl in place,\n+   just return zero or nonzero for failure / success.  */\n+\n+rtx\n+replace_n_hard_rtx (rtx x, rtx *replacements, int n_replacements, int modify)\n+{\n+  int i, j;\n+  const char *fmt;\n+\n+  /* The following prevents loops occurrence when we change MEM in\n+     CONST_DOUBLE onto the same CONST_DOUBLE.  */\n+  if (x != 0 && GET_CODE (x) == CONST_DOUBLE)\n+    return x;\n+\n+  for (i = n_replacements - 1; i >= 0 ; i--)\n+  if (x == replacements[i*2] && GET_MODE (x) == GET_MODE (replacements[i*2+1]))\n+    return replacements[i*2+1];\n+\n+  /* Allow this function to make replacements in EXPR_LISTs.  */\n+  if (x == 0)\n+    return 0;\n+\n+  if (GET_CODE (x) == SUBREG)\n+    {\n+      rtx new = replace_n_hard_rtx (SUBREG_REG (x), replacements,\n+\t\t\t\t    n_replacements, modify);\n+\n+      if (GET_CODE (new) == CONST_INT)\n+\t{\n+\t  x = simplify_subreg (GET_MODE (x), new,\n+\t\t\t       GET_MODE (SUBREG_REG (x)),\n+\t\t\t       SUBREG_BYTE (x));\n+\t  if (! x)\n+\t    abort ();\n+\t}\n+      else if (modify)\n+\tSUBREG_REG (x) = new;\n+\n+      return x;\n+    }\n+  else if (GET_CODE (x) == REG)\n+    {\n+      unsigned regno = REGNO (x);\n+      unsigned nregs = (regno < FIRST_PSEUDO_REGISTER\n+\t\t\t? HARD_REGNO_NREGS (regno, GET_MODE (x)) : 1);\n+      rtx result = NULL_RTX;\n+\n+      for (i = n_replacements - 1; i >= 0; i--)\n+\t{\n+\t  rtx from = replacements[i*2];\n+\t  rtx to = replacements[i*2+1];\n+\t  unsigned from_regno, from_nregs, to_regno, new_regno;\n+\n+\t  if (GET_CODE (from) != REG)\n+\t    continue;\n+\t  from_regno = REGNO (from);\n+\t  from_nregs = (from_regno < FIRST_PSEUDO_REGISTER\n+\t\t\t? HARD_REGNO_NREGS (from_regno, GET_MODE (from)) : 1);\n+\t  if (regno < from_regno + from_nregs && regno + nregs > from_regno)\n+\t    {\n+\t      if (regno < from_regno\n+\t\t  || regno + nregs > from_regno + nregs\n+\t\t  || GET_CODE (to) != REG\n+\t\t  || result)\n+\t\treturn NULL_RTX;\n+\t      to_regno = REGNO (to);\n+\t      if (to_regno < FIRST_PSEUDO_REGISTER)\n+\t\t{\n+\t\t  new_regno = regno + to_regno - from_regno;\n+\t\t  if ((unsigned) HARD_REGNO_NREGS (new_regno, GET_MODE (x))\n+\t\t      != nregs)\n+\t\t    return NULL_RTX;\n+\t\t  result = gen_rtx_REG (GET_MODE (x), new_regno);\n+\t\t}\n+\t      else if (GET_MODE (x) <= GET_MODE (to))\n+\t\tresult = gen_lowpart_common (GET_MODE (x), to);\n+\t      else\n+\t\tresult = gen_lowpart_SUBREG (GET_MODE (x), to);\n+\t    }\n+\t}\n+      return result ? result : x;\n+    }\n+  else if (GET_CODE (x) == ZERO_EXTEND)\n+    {\n+      rtx new = replace_n_hard_rtx (XEXP (x, 0), replacements,\n+\t\t\t\t    n_replacements, modify);\n+\n+      if (GET_CODE (new) == CONST_INT)\n+\t{\n+\t  x = simplify_unary_operation (ZERO_EXTEND, GET_MODE (x),\n+\t\t\t\t\tnew, GET_MODE (XEXP (x, 0)));\n+\t  if (! x)\n+\t    abort ();\n+\t}\n+      else if (modify)\n+\tXEXP (x, 0) = new;\n+\n+      return x;\n+    }\n+\n+  fmt = GET_RTX_FORMAT (GET_CODE (x));\n+  for (i = GET_RTX_LENGTH (GET_CODE (x)) - 1; i >= 0; i--)\n+    {\n+      rtx new;\n+\n+      if (fmt[i] == 'e')\n+\t{\n+\t  new = replace_n_hard_rtx (XEXP (x, i), replacements,\n+\t\t\t\t    n_replacements, modify);\n+\t  if (!new)\n+\t    return NULL_RTX;\n+\t  if (modify)\n+\t    XEXP (x, i) = new;\n+\t}\n+      else if (fmt[i] == 'E')\n+\tfor (j = XVECLEN (x, i) - 1; j >= 0; j--)\n+\t  {\n+\t    new = replace_n_hard_rtx (XVECEXP (x, i, j), replacements,\n+\t\t\t\t      n_replacements, modify);\n+\t  if (!new)\n+\t    return NULL_RTX;\n+\t    if (modify)\n+\t      XVECEXP (x, i, j) = new;\n+\t  }\n+    }\n+\n+  return x;\n+}\n+\n+rtx\n+sh_gen_truncate (enum machine_mode mode, rtx x, int need_sign_ext)\n+{\n+  enum rtx_code code = TRUNCATE;\n+\n+  if (GET_CODE (x) == ZERO_EXTEND || GET_CODE (x) == SIGN_EXTEND)\n+    {\n+      rtx inner = XEXP (x, 0);\n+      enum machine_mode inner_mode = GET_MODE (inner);\n+\n+      if (inner_mode == mode)\n+\treturn inner;\n+      else if (GET_MODE_SIZE (inner_mode) >= GET_MODE_SIZE (mode))\n+\tx = inner;\n+      else if (GET_MODE_SIZE (inner_mode) < GET_MODE_SIZE (mode)\n+\t       && (! need_sign_ext || GET_CODE (x) == SIGN_EXTEND))\n+\t{\n+\t  code = GET_CODE (x);\n+\t  x = inner;\n+\t}\n+    }\n+  return gen_rtx_fmt_e (code, mode, x);\n+}\n+\n+/* called via for_each_rtx after reload, to clean up truncates of\n+   registers that span multiple actual hard registers.  */\n+int\n+shmedia_cleanup_truncate (rtx *p, void *n_changes)\n+{\n+  rtx x = *p, reg;\n+\n+  if (GET_CODE (x) != TRUNCATE)\n+    return 0;\n+  reg = XEXP (x, 0);\n+  if (GET_MODE_SIZE (GET_MODE (reg)) > 8 && GET_CODE (reg) == REG)\n+    {\n+      enum machine_mode reg_mode = GET_MODE (reg);\n+      XEXP (x, 0) = simplify_subreg (DImode, reg, reg_mode,\n+\t\t\t\t     subreg_lowpart_offset (DImode, reg_mode));\n+      *(int*) n_changes += 1;\n+      return -1;\n+    }\n+  return 0;\n+}\n+\n+/* Load and store depend on the highpart of the address.  However,\n+   set_attr_alternative does not give well-defined results before reload,\n+   so we must look at the rtl ourselves to see if any of the feeding\n+   registers is used in a memref.  */\n+\n+/* Called by sh_contains_memref_p via for_each_rtx.  */\n+static int\n+sh_contains_memref_p_1 (rtx *loc, void *data ATTRIBUTE_UNUSED)\n+{\n+  return (GET_CODE (*loc) == MEM);\n+}\n+\n+/* Return non-zero iff INSN contains a MEM.  */\n+int\n+sh_contains_memref_p (rtx insn)\n+{\n+  return for_each_rtx (&PATTERN (insn), &sh_contains_memref_p_1, NULL);\n+}\n+\n+/* FNADDR is the MEM expression from a call expander.  Return an address\n+   to use in an SHmedia insn pattern.  */\n+rtx\n+shmedia_prepare_call_address (rtx fnaddr, int is_sibcall)\n+{\n+  int is_sym;\n+\n+  fnaddr = XEXP (fnaddr, 0);\n+  is_sym = GET_CODE (fnaddr) == SYMBOL_REF;\n+  if (flag_pic && is_sym)\n+    {\n+      if (! SYMBOL_REF_LOCAL_P (fnaddr))\n+\t{\n+\t  rtx reg = gen_reg_rtx (Pmode);\n+\n+\t  /* We must not use GOTPLT for sibcalls, because PIC_REG\n+\t     must be restored before the PLT code gets to run.  */\n+\t  if (is_sibcall)\n+\t    emit_insn (gen_symGOT2reg (reg, fnaddr));\n+\t  else\n+\t    emit_insn (gen_symGOTPLT2reg (reg, fnaddr));\n+\t  fnaddr = reg;\n+\t}\n+      else\n+\t{\n+\t  fnaddr = gen_sym2PIC (fnaddr);\n+\t  PUT_MODE (fnaddr, Pmode);\n+\t}\n+    }\n+  /* If ptabs might trap, make this visible to the rest of the compiler.\n+     We generally assume that symbols pertain to valid locations, but\n+     it is possible to generate invalid symbols with asm or linker tricks.\n+     In a list of functions where each returns its sucessor, an invalid\n+     symbol might denote an empty list.  */\n+  if (!TARGET_PT_FIXED\n+      && (!is_sym || TARGET_INVALID_SYMBOLS)\n+      && (!REG_P (fnaddr) || ! TARGET_REGISTER_P (REGNO (fnaddr))))\n+    {\n+      rtx tr = gen_reg_rtx (PDImode);\n+\n+      emit_insn (gen_ptabs (tr, fnaddr));\n+      fnaddr = tr;\n+    }\n+  else if (! target_reg_operand (fnaddr, Pmode))\n+    fnaddr = copy_to_mode_reg (Pmode, fnaddr);\n+  return fnaddr;\n+}\n+\n+const char *sh_multcost_str = \"\";\n+const char *sh_gettrcost_str = \"\";\n+const char *sh_div_str = \"\";\n+const char *sh_divsi3_libfunc = \"\";\n+const char *cut2_workaround_str = \"\";\n+enum sh_divide_strategy_e sh_div_strategy = SH_DIV_STRATEGY_DEFAULT;\n+\n+/* This defines the storage for the variable part of a -mboard= option.\n+   It is only required when using the sh-superh-elf target */\n+#ifdef _SUPERH_H\n+const char * boardtype = \"7750p2\";\n+const char * osruntime = \"bare\";\n+#endif\n+\n #include \"gt-sh.h\""}, {"sha": "32ad39c0a54163c854c901cbf3f09125ae7ec306", "filename": "gcc/config/sh/sh.h", "status": "modified", "additions": 388, "deletions": 107, "changes": 495, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsh.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsh.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fsh.h?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -84,6 +84,10 @@ do { \\\n \t  builtin_define (\"__SH4_NOFPU__\"); \\\n       } \\\n     } \\\n+  if (TARGET_FPU_ANY) \\\n+    builtin_define (\"__SH_FPU_ANY__\"); \\\n+  if (TARGET_FPU_DOUBLE) \\\n+    builtin_define (\"__SH_FPU_DOUBLE__\"); \\\n   if (TARGET_HITACHI) \\\n     builtin_define (\"__HITACHI__\"); \\\n   builtin_define (TARGET_LITTLE_ENDIAN \\\n@@ -175,6 +179,10 @@ extern int target_flags;\n #define SAVE_ALL_TR_BIT (1<<2)\n #define HARD_SH2A_BIT\t(1<<17)\n #define HARD_SH2A_DOUBLE_BIT\t(1<<18)\n+#define INDEXED_ADDRESS_BIT (1<<19)\n+#define PT_FIXED_BIT\t(1<<21)\n+#define INVALID_SYMBOLS_BIT (1<<25)\n+#define ADJUST_UNROLL_BIT (1<<20)\n \n /* Nonzero if this is an ELF target - compile time only */\n #define TARGET_ELF 0\n@@ -214,7 +222,7 @@ extern int target_flags;\n #define TARGET_SUPERSCALAR (target_flags & HARD_SH4_BIT)\n \n /* Nonzero if the target has separate instruction and data caches.  */\n-#define TARGET_HARVARD (target_flags & HARD_SH4_BIT)\n+#define TARGET_HARVARD (target_flags & HARD_SH4_BIT || TARGET_SH5)\n \n /* Nonzero if compiling for SH4 hardware (to be used for insn costs etc.)  */\n #define TARGET_HARD_SH4 (target_flags & HARD_SH4_BIT)\n@@ -317,6 +325,27 @@ extern int target_flags;\n #define SUPPORT_SH2A_SINGLE\n #endif\n \n+#define TARGET_DIVIDE_INV \\\n+  (sh_div_strategy == SH_DIV_INV || sh_div_strategy == SH_DIV_INV_MINLAT \\\n+   || sh_div_strategy == SH_DIV_INV20U || sh_div_strategy == SH_DIV_INV20L \\\n+   || sh_div_strategy == SH_DIV_INV_CALL \\\n+   || sh_div_strategy == SH_DIV_INV_CALL2 || sh_div_strategy == SH_DIV_INV_FP)\n+#define TARGET_DIVIDE_FP (sh_div_strategy == SH_DIV_FP)\n+#define TARGET_DIVIDE_INV_FP (sh_div_strategy == SH_DIV_INV_FP)\n+#define TARGET_DIVIDE_CALL2 (sh_div_strategy == SH_DIV_CALL2)\n+#define TARGET_DIVIDE_INV_MINLAT (sh_div_strategy == SH_DIV_INV_MINLAT)\n+#define TARGET_DIVIDE_INV20U (sh_div_strategy == SH_DIV_INV20U)\n+#define TARGET_DIVIDE_INV20L (sh_div_strategy == SH_DIV_INV20L)\n+#define TARGET_DIVIDE_INV_CALL (sh_div_strategy == SH_DIV_INV_CALL)\n+#define TARGET_DIVIDE_INV_CALL2 (sh_div_strategy == SH_DIV_INV_CALL2)\n+\n+/* Target macros pertaining to SHmedia architecture bugs.  */\n+#define TARGET_ALLOW_INDEXED_ADDRESS (target_flags & INDEXED_ADDRESS_BIT)\n+#define TARGET_PT_FIXED (target_flags & PT_FIXED_BIT)\n+#define TARGET_INVALID_SYMBOLS (target_flags & INVALID_SYMBOLS_BIT)\n+\n+#define TARGET_ADJUST_UNROLL (target_flags & ADJUST_UNROLL_BIT)\n+\n #define SELECT_SH1               (SH1_BIT)\n #define SELECT_SH2               (SH2_BIT | SELECT_SH1)\n #define SELECT_SH2E              (SH_E_BIT | SH2_BIT | SH1_BIT | FPU_SINGLE_BIT)\n@@ -419,6 +448,14 @@ extern int target_flags;\n #define TARGET_SWITCHES_SH5_32MEDIA_NOFPU\n #endif\n \n+#if defined(TARGET_SWITCHES_SH5_32MEDIA) && defined(TARGET_SWITCHES_SH5_32MEDIA_NOFPU)\n+#define TARGET_SWITCH_SH5_32_ANY_EXTRA\n+#endif\n+\n+#if defined(TARGET_SWITCH_SH5_32_ANY_EXTRA) && !defined(SUPPORT_SH5_64MEDIA) && !defined(SUPPORT_SH5_64MEDIA_NOFPU)\n+#define TARGET_SWITCH_SH5_MEDIA_ANY_EXTRA\n+#endif\n+\n /* Reset all target-selection flags.  */\n #define TARGET_NONE -(SH1_BIT | SH2_BIT | SH3_BIT | SH_E_BIT | SH4_BIT \\\n \t\t      | HARD_SH2A_BIT | HARD_SH2A_DOUBLE_BIT \\\n@@ -539,6 +576,22 @@ extern int target_flags;\n   {\"5-compact-nofpu\", SELECT_SH5_COMPACT_NOFPU, \"Generate FPU-less SHcompact code\" },\n #endif\n \n+#ifndef TARGET_SWITCH_SH5_32_ANY_EXTRA\n+#define TARGET_SWITCH_SH5_32_ANY_EXTRA \\\n+  {\"indexed-addressing\", INDEXED_ADDRESS_BIT, \"Enable the use of the indexed addressing mode for SHmedia32/SHcompact\"}, \\\n+  {\"no-indexed-addressing\", -INDEXED_ADDRESS_BIT, \"Disable the use of the indexed addressing mode for SHmedia32/SHcompact\"},\n+#endif\n+\n+#ifndef TARGET_SWITCH_SH5_MEDIA_ANY_EXTRA\n+#define TARGET_SWITCH_SH5_MEDIA_ANY_EXTRA \\\n+  {\"pt-fixed\",\tPT_FIXED_BIT, \"Assume pt* instructions won't trap\"}, \\\n+  {\"no-pt-fixed\", -PT_FIXED_BIT, \"Assume pt* instructions may trap\"}, \\\n+  {\"invalid-symbols\",INVALID_SYMBOLS_BIT, \"Assume symbols might be invalid\"}, \\\n+  {\"no-invalid-symbols\",-INVALID_SYMBOLS_BIT, \"Assume symbols won't be invalid\"}, \\\n+  {\"adjust-unroll\", ADJUST_UNROLL_BIT, \"Throttle unrolling to avoid thrashing target registers unless the unroll benefit outweighs this\"}, \\\n+  {\"no-adjust-unroll\", -ADJUST_UNROLL_BIT, \"Don't throttle unrolling\"},\n+#endif\n+\n #define TARGET_SWITCHES \\\n { TARGET_SWITCH_SH1 \\\n   TARGET_SWITCH_SH2 \\\n@@ -562,25 +615,27 @@ extern int target_flags;\n   TARGET_SWITCH_SH5_64MEDIA_NOFPU \\\n   TARGET_SWITCHES_SH5_32MEDIA \\\n   TARGET_SWITCHES_SH5_32MEDIA_NOFPU \\\n-  {\"b\",\t\t-LITTLE_ENDIAN_BIT, \"Generate code in big endian mode\" },  \t\\\n-  {\"bigtable\", \tBIGTABLE_BIT, \"Generate 32-bit offsets in switch tables\" },\t\t\\\n-  {\"dalign\",  \tDALIGN_BIT, \"Aligns doubles at 64-bit boundaries\" },\t\t\\\n-  {\"fmovd\",  \tFMOVD_BIT, \"\" },\t\t\\\n-  {\"hitachi\",\tHITACHI_BIT, \"Follow Renesas (formerly Hitachi) / SuperH calling conventions\" },\t\t\\\n-  {\"renesas\",\tHITACHI_BIT, \"Follow Renesas (formerly Hitachi) / SuperH calling conventions\" },\t\t\\\n+  {\"b\",\t\t-LITTLE_ENDIAN_BIT, \"Generate code in big endian mode\" }, \\\n+  {\"bigtable\", \tBIGTABLE_BIT, \"Generate 32-bit offsets in switch tables\" }, \\\n+  {\"dalign\",  \tDALIGN_BIT, \"Aligns doubles at 64-bit boundaries\" },\t\\\n+  {\"fmovd\",  \tFMOVD_BIT, \"\" },\t\t\t\t\t\\\n+  {\"hitachi\",\tHITACHI_BIT, \"Follow Renesas (formerly Hitachi) / SuperH calling conventions\" }, \\\n+  {\"renesas\",\tHITACHI_BIT, \"Follow Renesas (formerly Hitachi) / SuperH calling conventions\" }, \\\n   {\"no-renesas\",-HITACHI_BIT,\"Follow the GCC calling conventions\" },\t\\\n-  {\"nomacsave\", NOMACSAVE_BIT, \"Mark MAC register as call-clobbered\" },\t\t\\\n-  {\"ieee\",  \tIEEE_BIT, \"Increase the IEEE compliance for floating-point code\" },\t\t\t\\\n-  {\"isize\", \tISIZE_BIT, \"\" },\t\t\\\n-  {\"l\",\t\tLITTLE_ENDIAN_BIT, \"Generate code in little endian mode\" },  \t\\\n-  {\"no-ieee\",  \t-IEEE_BIT, \"\" },\t\t\\\n-  {\"padstruct\", PADSTRUCT_BIT, \"\" },    \t\\\n-  {\"prefergot\",\tPREFERGOT_BIT, \"Emit function-calls using global offset table when generating PIC\" },\t\t\\\n-  {\"relax\",\tRELAX_BIT, \"Shorten address references during linking\" },\t\t\\\n+  {\"nomacsave\", NOMACSAVE_BIT, \"Mark MAC register as call-clobbered\" },\t\\\n+  {\"ieee\",  \tIEEE_BIT, \"Increase the IEEE compliance for floating-point code\" }, \\\n+  {\"isize\", \tISIZE_BIT, \"Annotate assembler instructions with estimated addresses\" }, \\\n+  {\"l\",\t\tLITTLE_ENDIAN_BIT, \"Generate code in little endian mode\" }, \\\n+  {\"no-ieee\",  \t-IEEE_BIT, \"Opposite of -mieee\" },\t\t\t\\\n+  {\"padstruct\", PADSTRUCT_BIT, \"Make structs a multiple of 4 bytes (warning: ABI altered)\" }, \\\n+  {\"prefergot\",\tPREFERGOT_BIT, \"Emit function-calls using global offset table when generating PIC\" }, \\\n+  {\"relax\",\tRELAX_BIT, \"Shorten address references during linking\" }, \\\n   {\"space\", \tSPACE_BIT, \"Deprecated. Use -Os instead\" },\t\t\\\n-  {\"usermode\",\tUSERMODE_BIT, \"Generate library function call to invalidate instruction cache entries after fixing trampoline\" },\t\t\\\n-  SUBTARGET_SWITCHES                            \\\n-  {\"\",   \tTARGET_DEFAULT, \"\" } \t\t\\\n+  {\"usermode\",\tUSERMODE_BIT, \"Generate library function call to invalidate instruction cache entries after fixing trampoline\" }, \\\n+  TARGET_SWITCH_SH5_32_ANY_EXTRA \\\n+  TARGET_SWITCH_SH5_MEDIA_ANY_EXTRA \\\n+  SUBTARGET_SWITCHES                            \t\t\t\\\n+  {\"\",   \tTARGET_DEFAULT, \"\" }\t\t\t\t\t\\\n }\n \n /* This are meant to be redefined in the host dependent files */\n@@ -591,7 +646,32 @@ extern int target_flags;\n #define TARGET_ENDIAN_DEFAULT 0\n #endif\n \n-#define TARGET_DEFAULT  (TARGET_CPU_DEFAULT|TARGET_ENDIAN_DEFAULT)\n+#ifndef TARGET_OPT_DEFAULT\n+#define TARGET_OPT_DEFAULT  ADJUST_UNROLL_BIT\n+#endif\n+\n+#define TARGET_DEFAULT \\\n+  (TARGET_CPU_DEFAULT | TARGET_ENDIAN_DEFAULT | TARGET_OPT_DEFAULT)\n+\n+#ifndef SUBTARGET_OPTIONS\n+#define SUBTARGET_OPTIONS\n+#endif\n+\n+#define TARGET_OPTIONS \\\n+{ { \"ultcost=\", &sh_multcost_str, \\\n+    N_(\"Cost to assume for a multiply insn\"), 0 }, \\\n+  { \"gettrcost=\", &sh_gettrcost_str, \\\n+    N_(\"Cost to assume for gettr insn\"), 0 }, \\\n+  { \"div=\", &sh_div_str, \\\n+    N_(\"division strategy, one of: call, call2, fp, inv, inv:minlat, inv20u, inv20l, inv:call, inv:call2, inv:fp\"), 0 }, \\\n+  { \"divsi3_libfunc=\", &sh_divsi3_libfunc, \\\n+    N_(\"Specify name for 32 bit signed division function\"), 0 }, \\\n+  { \"cut2-workaround\", &cut2_workaround_str, \\\n+    N_(\"Enable SH5 cut2 workaround\"), \"\\1\" }, \\\n+  SUBTARGET_OPTIONS \\\n+}\n+\n+#define TARGET_SH5_CUT2_WORKAROUND (*cut2_workaround_str)\n \n #ifndef SH_MULTILIB_CPU_DEFAULT\n #define SH_MULTILIB_CPU_DEFAULT \"m1\"\n@@ -621,7 +701,8 @@ extern int target_flags;\n   { \"subtarget_link_spec\", SUBTARGET_LINK_SPEC },\t\t\\\n   { \"subtarget_asm_endian_spec\", SUBTARGET_ASM_ENDIAN_SPEC },\t\\\n   { \"subtarget_asm_relax_spec\", SUBTARGET_ASM_RELAX_SPEC },\t\\\n-  { \"subtarget_asm_isa_spec\", SUBTARGET_ASM_ISA_SPEC },\t\\\n+  { \"subtarget_asm_isa_spec\", SUBTARGET_ASM_ISA_SPEC },\t\t\\\n+  { \"subtarget_asm_spec\", SUBTARGET_ASM_SPEC },\t\t\t\\\n   SUBTARGET_EXTRA_SPECS\n \n #if TARGET_CPU_DEFAULT & HARD_SH4_BIT\n@@ -632,7 +713,15 @@ extern int target_flags;\n \n #define SH_ASM_SPEC \\\n  \"%(subtarget_asm_endian_spec) %{mrelax:-relax %(subtarget_asm_relax_spec)}\\\n-%(subtarget_asm_isa_spec) %{m4al:-dsp}\"\n+%(subtarget_asm_isa_spec) %(subtarget_asm_spec)\\\n+%{m2a:--isa=sh2a} \\\n+%{m2a-single:--isa=sh2a} \\\n+%{m2a-single-only:--isa=sh2a} \\\n+%{m2a-nofpu:--isa=sh2a-nofpu} \\\n+%{m5-compact*:--isa=SHcompact} \\\n+%{m5-32media*:--isa=SHmedia --abi=32} \\\n+%{m5-64media*:--isa=SHmedia --abi=64} \\\n+%{m4al:-dsp} %{mcut2-workaround:-cut2-workaround}\"\n \n #define ASM_SPEC SH_ASM_SPEC\n \n@@ -644,9 +733,29 @@ extern int target_flags;\n #endif\n #endif\n \n-#define SUBTARGET_ASM_ISA_SPEC \"\"\n+#if STRICT_NOFPU == 1\n+/* Strict nofpu means that the compiler should tell the assembler\n+   to reject FPU instructions. E.g. from ASM inserts.  */\n+#if TARGET_CPU_DEFAULT & HARD_SH4_BIT && !(TARGET_CPU_DEFAULT & SH_E_BIT)\n+#define SUBTARGET_ASM_ISA_SPEC \"%{!m1:%{!m2:%{!m3*:%{m4-nofpu|!m4*:%{!m5:-isa=sh4-nofpu}}}}}\"\n+#else\n+/* If there were an -isa option for sh5-nofpu then it would also go here. */\n+#define SUBTARGET_ASM_ISA_SPEC \\\n+ \"%{m4-nofpu:-isa=sh4-nofpu} \" ASM_ISA_DEFAULT_SPEC\n+#endif\n+#else /* ! STRICT_NOFPU */\n+#define SUBTARGET_ASM_ISA_SPEC ASM_ISA_DEFAULT_SPEC\n+#endif\n \n+#ifndef SUBTARGET_ASM_SPEC\n+#define SUBTARGET_ASM_SPEC \"\"\n+#endif\n+\n+#if TARGET_ENDIAN_DEFAULT == LITTLE_ENDIAN_BIT\n+#define LINK_EMUL_PREFIX \"sh%{!mb:l}\"\n+#else\n #define LINK_EMUL_PREFIX \"sh%{ml:l}\"\n+#endif\n \n #if TARGET_CPU_DEFAULT & SH5_BIT\n #if TARGET_CPU_DEFAULT & SH_E_BIT\n@@ -682,29 +791,73 @@ extern int target_flags;\n %(subtarget_link_emul_suffix) \\\n %{mrelax:-relax} %(subtarget_link_spec)\"\n \n+#ifndef SH_DIV_STR_FOR_SIZE\n+#define SH_DIV_STR_FOR_SIZE \"call\"\n+#endif\n+\n #define DRIVER_SELF_SPECS \"%{m2a:%{ml:%eSH2a does not support little-endian}}\"\n #define OPTIMIZATION_OPTIONS(LEVEL,SIZE)\t\t\t\t\\\n do {\t\t\t\t\t\t\t\t\t\\\n   if (LEVEL)\t\t\t\t\t\t\t\t\\\n-    flag_omit_frame_pointer = -1;\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\t\t\\\n+      flag_omit_frame_pointer = -1;\t\t\t\t\t\\\n+      if (! SIZE)\t\t\t\t\t\t\t\\\n+\tsh_div_str = \"inv:minlat\";\t\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n   if (SIZE)\t\t\t\t\t\t\t\t\\\n-    target_flags |= SPACE_BIT;\t\t\t\t\t\t\\\n-  if (TARGET_SHMEDIA && LEVEL > 1)\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\t\t\\\n+      target_flags |= SPACE_BIT;\t\t\t\t\t\\\n+      sh_div_str = SH_DIV_STR_FOR_SIZE ;\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+  /* We can't meaningfully test TARGET_SHMEDIA here, because -m options\t\\\n+     haven't been parsed yet, hence we';d read only the default.\t\\\n+     sh_target_reg_class will return NO_REGS if this is not SHMEDIA, so\t\\\n+     it's OK to always set flag_branch_target_load_optimize.  */\t\\\n+  if (LEVEL > 1)\t\t\t\t\t\t\t\\\n     {\t\t\t\t\t\t\t\t\t\\\n       flag_branch_target_load_optimize = 1;\t\t\t\t\\\n       if (! (SIZE))\t\t\t\t\t\t\t\\\n \ttarget_flags |= SAVE_ALL_TR_BIT;\t\t\t\t\\\n     }\t\t\t\t\t\t\t\t\t\\\n+  /* Likewise, we can't meaningfully test TARGET_SH2E / TARGET_IEEE\t\\\n+     here, so leave it to OVERRIDE_OPTIONS to set\t\t\t\\\n+    flag_finite_math_only.  We set it to 2 here so we know if the user\t\\\n+    explicitly requested this to be on or off.  */\t\t\t\\\n+  flag_finite_math_only = 2;\t\t\t\t\t\t\\\n } while (0)\n \n #define ASSEMBLER_DIALECT assembler_dialect\n \n extern int assembler_dialect;\n \n+enum sh_divide_strategy_e {\n+  SH_DIV_CALL,\n+  SH_DIV_CALL2,\n+  SH_DIV_FP,\n+  SH_DIV_INV,\n+  SH_DIV_INV_MINLAT,\n+  SH_DIV_INV20U,\n+  SH_DIV_INV20L,\n+  SH_DIV_INV_CALL,\n+  SH_DIV_INV_CALL2,\n+  SH_DIV_INV_FP\n+};\n+\n+extern enum sh_divide_strategy_e sh_div_strategy;\n+\n+#ifndef SH_DIV_STRATEGY_DEFAULT\n+#define SH_DIV_STRATEGY_DEFAULT SH_DIV_CALL\n+#endif\n+\n #define OVERRIDE_OPTIONS \t\t\t\t\t\t\\\n do {\t\t\t\t\t\t\t\t\t\\\n   int regno;\t\t\t\t\t\t\t\t\\\n \t\t\t\t\t\t\t\t\t\\\n+  if (flag_finite_math_only == 2)\t\t\t\t\t\\\n+    flag_finite_math_only\t\t\t\t\t\t\\\n+      = !flag_signaling_nans && TARGET_SH2E && ! TARGET_IEEE;\t\t\\\n+  if (TARGET_SH2E && !flag_finite_math_only)\t\t\t\t\\\n+    target_flags |= IEEE_BIT;\t\t\t\t\t\t\\\n   sh_cpu = CPU_SH1;\t\t\t\t\t\t\t\\\n   assembler_dialect = 0;\t\t\t\t\t\t\\\n   if (TARGET_SH2)\t\t\t\t\t\t\t\\\n@@ -735,32 +888,81 @@ do {\t\t\t\t\t\t\t\t\t\\\n     {\t\t\t\t\t\t\t\t\t\\\n       sh_cpu = CPU_SH5;\t\t\t\t\t\t\t\\\n       target_flags |= DALIGN_BIT;\t\t\t\t\t\\\n-      if (TARGET_FPU_ANY\t\t\t\t\t\t\\\n-\t  && ! (TARGET_SHCOMPACT && TARGET_LITTLE_ENDIAN))\t\t\\\n+      if (TARGET_SHMEDIA_FPU)\t\t\t\t\t\t\\\n \ttarget_flags |= FMOVD_BIT;\t\t\t\t\t\\\n       if (TARGET_SHMEDIA)\t\t\t\t\t\t\\\n \t{\t\t\t\t\t\t\t\t\\\n \t  /* There are no delay slots on SHmedia.  */\t\t\t\\\n \t  flag_delayed_branch = 0;\t\t\t\t\t\\\n \t  /* Relaxation isn't yet supported for SHmedia */\t\t\\\n \t  target_flags &= ~RELAX_BIT;\t\t\t\t\t\\\n+\t  /* After reload, if conversion does little good but can cause \\\n+\t     ICEs:\t\t\t\t\t\t\t\\\n+\t     - find_if_block doesn't do anything for SH because we don't\\\n+\t       have conditional execution patterns.  (We use conditional\\\n+\t       move patterns, which are handled differently, and only\t\\\n+\t       before reload).\t\t\t\t\t\t\\\n+\t     - find_cond_trap doesn't do anything for the SH because we \\\t\n+\t       don't have conditional traps.\t\t\t\t\\\n+\t     - find_if_case_1 uses redirect_edge_and_branch_force in\t\\\n+\t       the only path that does an optimization, and this causes\t\\\n+\t       an ICE when branch targets are in registers.\t\t\\\n+\t     - find_if_case_2 doesn't do anything for the SHmedia after\t\\\n+\t       reload except when it can redirect a tablejump - and\t\\\n+\t       that's rather rare.  */\t\t\t\t\t\\\n+\t  flag_if_conversion2 = 0;\t\t\t\t\t\\\n+\t  if (! strcmp (sh_div_str, \"call\"))\t\t\t\t\\\n+\t    sh_div_strategy = SH_DIV_CALL;\t\t\t\t\\\n+\t  else if (! strcmp (sh_div_str, \"call2\"))\t\t\t\\\n+\t    sh_div_strategy = SH_DIV_CALL2;\t\t\t\t\\\n+\t  if (! strcmp (sh_div_str, \"fp\") && TARGET_FPU_ANY)\t\t\\\n+\t    sh_div_strategy = SH_DIV_FP;\t\t\t\t\\\n+\t  else if (! strcmp (sh_div_str, \"inv\"))\t\t\t\\\n+\t    sh_div_strategy = SH_DIV_INV;\t\t\t\t\\\n+\t  else if (! strcmp (sh_div_str, \"inv:minlat\"))\t\t\t\\\n+\t    sh_div_strategy = SH_DIV_INV_MINLAT;\t\t\t\\\n+\t  else if (! strcmp (sh_div_str, \"inv20u\"))\t\t\t\\\n+\t    sh_div_strategy = SH_DIV_INV20U;\t\t\t\t\\\n+\t  else if (! strcmp (sh_div_str, \"inv20l\"))\t\t\t\\\n+\t    sh_div_strategy = SH_DIV_INV20L;\t\t\t\t\\\n+\t  else if (! strcmp (sh_div_str, \"inv:call2\"))\t\t\t\\\n+\t    sh_div_strategy = SH_DIV_INV_CALL2;\t\t\t\t\\\n+\t  else if (! strcmp (sh_div_str, \"inv:call\"))\t\t\t\\\n+\t    sh_div_strategy = SH_DIV_INV_CALL;\t\t\t\t\\\n+\t  else if (! strcmp (sh_div_str, \"inv:fp\"))\t\t\t\\\n+\t    {\t\t\t\t\t\t\t\t\\\n+\t      if (TARGET_FPU_ANY)\t\t\t\t\t\\\n+\t\tsh_div_strategy = SH_DIV_INV_FP;\t\t\t\\\n+\t      else\t\t\t\t\t\t\t\\\n+\t\tsh_div_strategy = SH_DIV_INV;\t\t\t\t\\\n+\t    }\t\t\t\t\t\t\t\t\\\n \t}\t\t\t\t\t\t\t\t\\\n       /* -fprofile-arcs needs a working libgcov .  In unified tree\t\\\n \t configurations with newlib, this requires to configure with\t\\\n \t --with-newlib --with-headers.  But there is no way to check\t\\\n \t here we have a working libgcov, so just assume that we have.  */\\\n       if (profile_flag)\t\t\t\t\t\t\t\\\n-\t{\t\t\t\t\t\t\t\t\\\n-\t  warning (0, \"Profiling is not supported on this target.\");\t\\\n-\t  profile_flag = profile_arc_flag = 0;\t\t\t\t\\\n-\t}\t\t\t\t\t\t\t\t\\\n+\twarning (0, \"Profiling is still experimental for this target.\");\\\n     }\t\t\t\t\t\t\t\t\t\\\n   else\t\t\t\t\t\t\t\t\t\\\n     {\t\t\t\t\t\t\t\t\t\\\n        /* Only the sh64-elf assembler fully supports .quad properly.  */\\\n        targetm.asm_out.aligned_op.di = NULL;\t\t\t\t\\\n        targetm.asm_out.unaligned_op.di = NULL;\t\t\t\t\\\n     }\t\t\t\t\t\t\t\t\t\\\n+  if (sh_divsi3_libfunc[0])\t\t\t\t\t\t\\\n+    ; /* User supplied - leave it alone.  */\t\t\t\t\\\n+  else if (TARGET_HARD_SH4 && TARGET_SH2E)\t\t\t\t\\\n+    sh_divsi3_libfunc = \"__sdivsi3_i4\";\t\t\t\t\t\\\n+  else if (TARGET_SH5)\t\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\t\t\\\n+      if (TARGET_FPU_ANY && TARGET_SH1)\t\t\t\t\t\\\n+\tsh_divsi3_libfunc = \"__sdivsi3_i4\";\t\t\t\t\\\n+      else\t\t\t\t\t\t\t\t\\\n+\tsh_divsi3_libfunc = \"__sdivsi3_1\";\t\t\t\t\\\n+    }\t\t\t\t\t\t\t\t\t\\\n+  else\t\t\t\t\t\t\t\t\t\\\n+    sh_divsi3_libfunc = \"__sdivsi3\";\t\t\t\t\t\\\n   if (TARGET_FMOVD)\t\t\t\t\t\t\t\\\n     reg_class_from_letter['e' - 'a'] = NO_REGS;\t\t\t\t\\\n \t\t\t\t\t\t\t\t\t\\\n@@ -783,7 +985,8 @@ do {\t\t\t\t\t\t\t\t\t\\\n       flag_omit_frame_pointer = 0;\t\t\t\t\t\\\n    }\t\t\t\t\t\t\t\t\t\\\n \t\t\t\t\t\t\t\t\t\\\n-  if (flag_pic && ! TARGET_PREFERGOT)\t\t\t\t\t\\\n+  if ((flag_pic && ! TARGET_PREFERGOT)\t\t\t\t\t\\\n+      || (TARGET_SHMEDIA && !TARGET_PT_FIXED))\t\t\t\t\\\n     flag_no_function_cse = 1;\t\t\t\t\t\t\\\n \t\t\t\t\t\t\t\t\t\\\n   if (SMALL_REGISTER_CLASSES)\t\t\t\t\t\t\\\n@@ -947,7 +1150,7 @@ do {\t\t\t\t\t\t\t\t\t\\\n   barrier_align (LABEL_AFTER_BARRIER)\n \n #define LOOP_ALIGN(A_LABEL) \\\n-  ((! optimize || TARGET_HARVARD || TARGET_SMALLCODE) \\\n+  ((! optimize || TARGET_HARD_SH4 || TARGET_SMALLCODE) \\\n    ? 0 : sh_loop_align (A_LABEL))\n \n #define LABEL_ALIGN(A_LABEL) \\\n@@ -1293,11 +1496,14 @@ extern char sh_additional_register_names[ADDREGNAMES_SIZE] \\\n       || ((((TARGET_SH4 || TARGET_SH2A_DOUBLE) && (MODE) == DFmode) || (MODE) == DCmode \\\n \t   || (TARGET_SHMEDIA && ((MODE) == DFmode || (MODE) == DImode \\\n \t\t\t\t  || (MODE) == V2SFmode || (MODE) == TImode))) \\\n-\t  && (((REGNO) - FIRST_FP_REG) & 1) == 0)) \\\n+\t  && (((REGNO) - FIRST_FP_REG) & 1) == 0) \\\n+      || ((TARGET_SH4 || TARGET_SHMEDIA) \\\n+\t  && (MODE) == TImode \\\n+\t  && (((REGNO) - FIRST_FP_REG) & 3) == 0)) \\\n    : XD_REGISTER_P (REGNO) \\\n    ? (MODE) == DFmode \\\n    : TARGET_REGISTER_P (REGNO) \\\n-   ? ((MODE) == DImode || (MODE) == SImode) \\\n+   ? ((MODE) == DImode || (MODE) == SImode || (MODE) == PDImode) \\\n    : (REGNO) == PR_REG ? (MODE) == SImode \\\n    : (REGNO) == FPSCR_REG ? (MODE) == PSImode \\\n    : 1)\n@@ -1312,6 +1518,9 @@ extern char sh_additional_register_names[ADDREGNAMES_SIZE] \\\n \n #define MODES_TIEABLE_P(MODE1, MODE2) \\\n   ((MODE1) == (MODE2) \\\n+   || (TARGET_SHMEDIA \\\n+       && GET_MODE_SIZE (MODE1) == GET_MODE_SIZE (MODE2) \\\n+       && INTEGRAL_MODE_P (MODE1) && INTEGRAL_MODE_P (MODE2)) \\\n    || (GET_MODE_CLASS (MODE1) == GET_MODE_CLASS (MODE2) \\\n        && (TARGET_SHMEDIA ? ((GET_MODE_SIZE (MODE1) <= 4) \\\n \t\t\t      && (GET_MODE_SIZE (MODE2) <= 4)) \\\n@@ -1578,7 +1787,8 @@ extern enum reg_class regno_reg_class[FIRST_PSEUDO_REGISTER];\n    145,146,147,148,149,152 }\n \n /* The class value for index registers, and the one for base regs.  */\n-#define INDEX_REG_CLASS  (TARGET_SHMEDIA ? GENERAL_REGS : R0_REGS)\n+#define INDEX_REG_CLASS \\\n+  (!ALLOW_INDEXED_ADDRESS ? NO_REGS : TARGET_SHMEDIA ? GENERAL_REGS : R0_REGS)\n #define BASE_REG_CLASS\t GENERAL_REGS\n \n /* Get reg_class from a letter such as appears in the machine\n@@ -1619,30 +1829,11 @@ extern enum reg_class reg_class_from_letter[];\n    unused CONST_INT constraint letters: LO\n    unused EXTRA_CONSTRAINT letters: D T U Y */\n \n-#if 1 /* check that the transition went well.  */\n-#define CONSTRAINT_LEN(C,STR) \\\n-  (((C) == 'L' || (C) == 'O' || (C) == 'D' || (C) == 'T' || (C) == 'U' \\\n-    || (C) == 'Y' \\\n-    || ((C) == 'I' \\\n-        && (((STR)[1] != '0' && (STR)[1] != '1' && (STR)[1] != '2') \\\n-\t    || (STR)[2] < '0' || (STR)[2] > '9')) \\\n-    || ((C) == 'B' && ((STR)[1] != 's' || (STR)[2] != 'c')) \\\n-    || ((C) == 'J' && ((STR)[1] != '1' || (STR)[2] != '6')) \\\n-    || ((C) == 'K' && ((STR)[1] != '0' || (STR)[2] != '8')) \\\n-    || ((C) == 'P' && ((STR)[1] != '2' || (STR)[2] != '7'))) \\\n-   ? -1 \\\n-   : ((C) == 'A' || (C) == 'B' || (C) == 'C' \\\n-      || (C) == 'I' || (C) == 'J' || (C) == 'K' || (C) == 'P' \\\n-      || (C) == 'R' || (C) == 'S') \\\n-   ? 3 \\\n-   : DEFAULT_CONSTRAINT_LEN ((C), (STR)))\n-#else\n #define CONSTRAINT_LEN(C,STR) \\\n   (((C) == 'A' || (C) == 'B' || (C) == 'C' \\\n     || (C) == 'I' || (C) == 'J' || (C) == 'K' || (C) == 'P' \\\n     || (C) == 'R' || (C) == 'S') \\\n    ? 3 : DEFAULT_CONSTRAINT_LEN ((C), (STR)))\n-#endif\n \n /* The letters I, J, K, L and M in a register constraint string\n    can be used to stand for particular ranges of immediate operands.\n@@ -1671,7 +1862,7 @@ extern enum reg_class reg_class_from_letter[];\n \t\t\t\t && ((HOST_WIDE_INT)(VALUE)) <= 524287 \\\n \t\t\t\t && TARGET_SH2A)\n #define CONST_OK_FOR_I(VALUE, STR) \\\n-  ((STR)[1] == '0' && (STR)[2] == 6 ? CONST_OK_FOR_I06 (VALUE) \\\n+  ((STR)[1] == '0' && (STR)[2] == '6' ? CONST_OK_FOR_I06 (VALUE) \\\n    : (STR)[1] == '0' && (STR)[2] == '8' ? CONST_OK_FOR_I08 (VALUE) \\\n    : (STR)[1] == '1' && (STR)[2] == '0' ? CONST_OK_FOR_I10 (VALUE) \\\n    : (STR)[1] == '1' && (STR)[2] == '6' ? CONST_OK_FOR_I16 (VALUE) \\\n@@ -1722,11 +1913,12 @@ extern enum reg_class reg_class_from_letter[];\n #define PREFERRED_RELOAD_CLASS(X, CLASS) \\\n   ((CLASS) == NO_REGS && TARGET_SHMEDIA \\\n    && (GET_CODE (X) == CONST_DOUBLE \\\n-       || GET_CODE (X) == SYMBOL_REF) \\\n+       || GET_CODE (X) == SYMBOL_REF \\\n+       || PIC_DIRECT_ADDR_P (X)) \\\n    ? GENERAL_REGS \\\n    : (CLASS)) \\\n \n-#define SECONDARY_OUTPUT_RELOAD_CLASS(CLASS,MODE,X) \\\n+#define SECONDARY_INOUT_RELOAD_CLASS(CLASS,MODE,X,ELSE) \\\n   ((((REGCLASS_HAS_FP_REG (CLASS) \t\t\t\t\t\\\n       && (GET_CODE (X) == REG\t\t\t\t\t\t\\\n       && (GENERAL_OR_AP_REGISTER_P (REGNO (X))\t\t\t\t\\\n@@ -1747,18 +1939,21 @@ extern enum reg_class reg_class_from_letter[];\n \t\t  || REGNO (X) == T_REG\t\t\t\t\t\\\n \t\t  || system_reg_operand (X, VOIDmode)))))\t\t\\\n    ? GENERAL_REGS\t\t\t\t\t\t\t\\\n-   : ((CLASS) == TARGET_REGS\t\t\t\t\t\t\\\n-      || (TARGET_SHMEDIA && (CLASS) == SIBCALL_REGS))\t\t\t\\\n-   ? ((target_operand ((X), (MODE))\t\t\t\t\t\\\n-       && ! target_reg_operand ((X), (MODE)))\t\t\t\t\\\n-      ? NO_REGS : GENERAL_REGS)\t\t\t\t\t\t\\\n+   : (((CLASS) == TARGET_REGS\t\t\t\t\t\t\\\n+       || (TARGET_SHMEDIA && (CLASS) == SIBCALL_REGS))\t\t\t\\\n+      && !EXTRA_CONSTRAINT_Csy (X)\t\t\t\t\t\\\n+      && (GET_CODE (X) != REG || ! GENERAL_REGISTER_P (REGNO (X))))\t\\\n+   ? GENERAL_REGS\t\t\t\t\t\t\t\\\n    : (((CLASS) == MAC_REGS || (CLASS) == PR_REGS)\t\t\t\\\n       && GET_CODE (X) == REG && ! GENERAL_REGISTER_P (REGNO (X))\t\\\n       && (CLASS) != REGNO_REG_CLASS (REGNO (X)))\t\t\t\\\n    ? GENERAL_REGS\t\t\t\t\t\t\t\\\n    : ((CLASS) != GENERAL_REGS && GET_CODE (X) == REG\t\t\t\\\n       && TARGET_REGISTER_P (REGNO (X)))\t\t\t\t\t\\\n-   ? GENERAL_REGS : NO_REGS)\n+   ? GENERAL_REGS : (ELSE))\n+\n+#define SECONDARY_OUTPUT_RELOAD_CLASS(CLASS,MODE,X) \\\n+ SECONDARY_INOUT_RELOAD_CLASS(CLASS,MODE,X,NO_REGS)\n \n #define SECONDARY_INPUT_RELOAD_CLASS(CLASS,MODE,X)  \\\n   ((REGCLASS_HAS_FP_REG (CLASS) \t\t\t\t\t\\\n@@ -1767,17 +1962,17 @@ extern enum reg_class reg_class_from_letter[];\n     && ! ((fp_zero_operand (X) || fp_one_operand (X))\t\t\t\\\n \t  && (MODE) == SFmode && fldi_ok ()))\t\t\t\t\\\n    ? R0_REGS\t\t\t\t\t\t\t\t\\\n-   : (CLASS == FPUL_REGS\t\t\t\t\t\t\\\n+   : ((CLASS) == FPUL_REGS\t\t\t\t\t\t\\\n       && ((GET_CODE (X) == REG\t\t\t\t\t\t\\\n \t   && (REGNO (X) == MACL_REG || REGNO (X) == MACH_REG\t\t\\\n \t       || REGNO (X) == T_REG))\t\t\t\t\t\\\n \t  || GET_CODE (X) == PLUS))\t\t\t\t\t\\\n    ? GENERAL_REGS\t\t\t\t\t\t\t\\\n-   : CLASS == FPUL_REGS && immediate_operand ((X), (MODE))\t\t\\\n+   : (CLASS) == FPUL_REGS && immediate_operand ((X), (MODE))\t\t\\\n    ? (GET_CODE (X) == CONST_INT && CONST_OK_FOR_I08 (INTVAL (X))\t\\\n       ? GENERAL_REGS\t\t\t\t\t\t\t\\\n       : R0_REGS)\t\t\t\t\t\t\t\\\n-   : (CLASS == FPSCR_REGS\t\t\t\t\t\t\\\n+   : ((CLASS) == FPSCR_REGS\t\t\t\t\t\t\\\n       && ((GET_CODE (X) == REG && REGNO (X) >= FIRST_PSEUDO_REGISTER)\t\\\n \t  || (GET_CODE (X) == MEM && GET_CODE (XEXP ((X), 0)) == PLUS)))\\\n    ? GENERAL_REGS\t\t\t\t\t\t\t\\\n@@ -1787,7 +1982,13 @@ extern enum reg_class reg_class_from_letter[];\n       && (X) != CONST0_RTX (GET_MODE (X))\t\t\t\t\\\n       && GET_MODE (X) != V4SFmode)\t\t\t\t\t\\\n    ? GENERAL_REGS\t\t\t\t\t\t\t\\\n-   : SECONDARY_OUTPUT_RELOAD_CLASS((CLASS),(MODE),(X)))\n+   : (((MODE) == QImode || (MODE) == HImode)\t\t\t\t\\\n+      && TARGET_SHMEDIA && inqhi_operand ((X), (MODE)))\t\t\t\\\n+   ? GENERAL_REGS\t\t\t\t\t\t\t\\\n+   : (TARGET_SHMEDIA && (CLASS) == GENERAL_REGS\t\t\t\t\\\n+      && (GET_CODE (X) == LABEL_REF || PIC_DIRECT_ADDR_P (X)))\t\t\\\n+   ? TARGET_REGS\t\t\t\t\t\t\t\\\n+   : SECONDARY_INOUT_RELOAD_CLASS((CLASS),(MODE),(X), NO_REGS))\n \n /* Return the maximum number of consecutive registers\n    needed to represent mode MODE in a register of class CLASS.\n@@ -1904,15 +2105,15 @@ extern enum reg_class reg_class_from_letter[];\n #define FUNCTION_VALUE(VALTYPE, FUNC)\t\t\t\t\t\\\n   gen_rtx_REG (\t\t\t\t\t\t\t\t\\\n \t   ((GET_MODE_CLASS (TYPE_MODE (VALTYPE)) == MODE_INT\t\t\\\n-\t     && GET_MODE_SIZE (TYPE_MODE (VALTYPE)) < UNITS_PER_WORD\t\\\n+\t     && GET_MODE_SIZE (TYPE_MODE (VALTYPE)) < 4                 \\\n \t     && (TREE_CODE (VALTYPE) == INTEGER_TYPE\t\t\t\\\n \t\t || TREE_CODE (VALTYPE) == ENUMERAL_TYPE\t\t\\\n \t\t || TREE_CODE (VALTYPE) == BOOLEAN_TYPE\t\t\t\\\n \t\t || TREE_CODE (VALTYPE) == CHAR_TYPE\t\t\t\\\n \t\t || TREE_CODE (VALTYPE) == REAL_TYPE\t\t\t\\\n \t\t || TREE_CODE (VALTYPE) == OFFSET_TYPE))\t\t\\\n              && sh_promote_prototypes (VALTYPE)\t\t\t\t\\\n-\t    ? (TARGET_SHMEDIA ? DImode : SImode) : TYPE_MODE (VALTYPE)), \\\n+\t    ? (TARGET_SHMEDIA64 ? DImode : SImode) : TYPE_MODE (VALTYPE)), \\\n \t   BASE_RETURN_VALUE_REG (TYPE_MODE (VALTYPE)))\n \n /* Define how to find the value returned by a library function\n@@ -2225,10 +2426,19 @@ struct sh_args {\n \n #define FUNCTION_PROFILER(STREAM,LABELNO)\t\t\t\\\n {\t\t\t\t\t\t\t\t\\\n-\tfprintf((STREAM), \"\\t.align\\t2\\n\");\t\t\t\\\n-\tfprintf((STREAM), \"\\ttrapa\\t#33\\n\");\t\t\t\\\n- \tfprintf((STREAM), \"\\t.align\\t2\\n\");\t\t\t\\\n-\tasm_fprintf((STREAM), \"\\t.long\\t%LLP%d\\n\", (LABELNO));\t\\\n+  if (TARGET_SHMEDIA)\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\t\\\n+      fprintf((STREAM), \"\\tmovi\\t33,r0\\n\");\t\t\t\\\n+      fprintf((STREAM), \"\\ttrapa\\tr0\\n\");\t\t\t\\\n+      asm_fprintf((STREAM), \"\\t.long\\t%LLP%d\\n\", (LABELNO));\t\\\n+    }\t\t\t\t\t\t\t\t\\\n+  else\t\t\t\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\t\\\n+      fprintf((STREAM), \"\\t.align\\t2\\n\");\t\t\t\\\n+      fprintf((STREAM), \"\\ttrapa\\t#33\\n\");\t\t\t\\\n+      fprintf((STREAM), \"\\t.align\\t2\\n\");\t\t\t\\\n+      asm_fprintf((STREAM), \"\\t.long\\t%LLP%d\\n\", (LABELNO));\t\\\n+    }\t\t\t\t\t\t\t\t\\\n }\n \n /* Define this macro if the code for function profiling should come\n@@ -2418,7 +2628,8 @@ struct sh_args {\n #define EXTRA_CONSTRAINT_C16(OP) \\\n   (GET_CODE (OP) == CONST \\\n    && GET_CODE (XEXP ((OP), 0)) == SIGN_EXTEND \\\n-   && GET_MODE (XEXP ((OP), 0)) == DImode \\\n+   && (GET_MODE (XEXP ((OP), 0)) == DImode \\\n+       || GET_MODE (XEXP ((OP), 0)) == SImode) \\\n    && GET_CODE (XEXP (XEXP ((OP), 0), 0)) == TRUNCATE \\\n    && GET_MODE (XEXP (XEXP ((OP), 0), 0)) == HImode \\\n    && (MOVI_SHORI_BASE_OPERAND_P (XEXP (XEXP (XEXP ((OP), 0), 0), 0)) \\\n@@ -2433,14 +2644,7 @@ struct sh_args {\n   (GET_CODE (OP) == UNSPEC \\\n    && XINT ((OP), 1) == UNSPEC_DATALABEL \\\n    && XVECLEN ((OP), 0) == 1 \\\n-   && (GET_CODE (XVECEXP ((OP), 0, 0)) == SYMBOL_REF \\\n-       || GET_CODE (XVECEXP ((OP), 0, 0)) == LABEL_REF))\n-\n-/* Check whether OP is a datalabel unspec, possibly enclosed within a\n-   CONST.  */\n-#define DATALABEL_REF_P(OP) \\\n-  ((GET_CODE (OP) == CONST && DATALABEL_REF_NO_CONST_P (XEXP ((OP), 0))) \\\n-   || DATALABEL_REF_NO_CONST_P (OP))\n+   && GET_CODE (XVECEXP ((OP), 0, 0)) == LABEL_REF)\n \n #define GOT_ENTRY_P(OP) \\\n   (GET_CODE (OP) == CONST && GET_CODE (XEXP ((OP), 0)) == UNSPEC \\\n@@ -2474,10 +2678,14 @@ struct sh_args {\n \n #define NON_PIC_REFERENCE_P(OP) \\\n   (GET_CODE (OP) == LABEL_REF || GET_CODE (OP) == SYMBOL_REF \\\n-   || DATALABEL_REF_P (OP) \\\n+   || (GET_CODE (OP) == CONST \\\n+       && (GET_CODE (XEXP ((OP), 0)) == LABEL_REF \\\n+\t   || GET_CODE (XEXP ((OP), 0)) == SYMBOL_REF \\\n+\t   || DATALABEL_REF_NO_CONST_P (XEXP ((OP), 0)))) \\\n    || (GET_CODE (OP) == CONST && GET_CODE (XEXP ((OP), 0)) == PLUS \\\n        && (GET_CODE (XEXP (XEXP ((OP), 0), 0)) == SYMBOL_REF \\\n-\t   || DATALABEL_REF_P (XEXP (XEXP ((OP), 0), 0))) \\\n+\t   || GET_CODE (XEXP (XEXP ((OP), 0), 0)) == LABEL_REF \\\n+\t   || DATALABEL_REF_NO_CONST_P (XEXP (XEXP ((OP), 0), 0))) \\\n        && GET_CODE (XEXP (XEXP ((OP), 0), 1)) == CONST_INT))\n \n #define PIC_REFERENCE_P(OP) \\\n@@ -2574,6 +2782,8 @@ struct sh_args {\n #define BASE_REGISTER_RTX_P(X)\t\t\t\t\\\n   ((GET_CODE (X) == REG && REG_OK_FOR_BASE_P (X))\t\\\n    || (GET_CODE (X) == SUBREG\t\t\t\t\\\n+       && TRULY_NOOP_TRUNCATION (GET_MODE_BITSIZE (GET_MODE ((X))), \\\n+\t\t\t\t GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (X)))) \\\n        && GET_CODE (SUBREG_REG (X)) == REG\t\t\\\n        && REG_OK_FOR_BASE_P (SUBREG_REG (X))))\n \n@@ -2583,6 +2793,8 @@ struct sh_args {\n #define INDEX_REGISTER_RTX_P(X)\t\t\t\t\\\n   ((GET_CODE (X) == REG && REG_OK_FOR_INDEX_P (X))\t\\\n    || (GET_CODE (X) == SUBREG\t\t\t\t\\\n+       && TRULY_NOOP_TRUNCATION (GET_MODE_BITSIZE (GET_MODE ((X))), \\\n+\t\t\t\t GET_MODE_BITSIZE (GET_MODE (SUBREG_REG (X)))) \\\n        && GET_CODE (SUBREG_REG (X)) == REG\t\t\\\n        && SUBREG_OK_FOR_INDEX_P (SUBREG_REG (X), SUBREG_BYTE (X))))\n \n@@ -2614,7 +2826,15 @@ struct sh_args {\n       {\t\t\t\t\t\t\t\t\t\\\n \tif (TARGET_SHMEDIA)\t\t\t\t\t\t\\\n \t  {\t\t\t\t\t\t\t\t\\\n-\t    int MODE_SIZE = GET_MODE_SIZE (MODE);\t\t\t\\\n+\t    int MODE_SIZE;\t\t\t\t\t\t\\\n+\t    /* Check if this the address of an unaligned load / store.  */\\\n+\t    if ((MODE) == VOIDmode)\t\t\t\t\t\\\n+\t     {\t\t\t\t\t\t\t\t\\\n+\t      if (CONST_OK_FOR_I06 (INTVAL (OP)))\t\t\t\\\n+\t\tgoto LABEL;\t\t\t\t\t\t\\\n+\t      break;\t\t\t\t\t\t\t\\\n+\t     }\t\t\t\t\t\t\t\t\\\n+\t    MODE_SIZE = GET_MODE_SIZE (MODE);\t\t\t\t\\\n \t    if (! (INTVAL (OP) & (MODE_SIZE - 1))\t\t\t\\\n \t\t&& INTVAL (OP) >= -512 * MODE_SIZE\t\t\t\\\n \t\t&& INTVAL (OP) < 512 * MODE_SIZE)\t\t\t\\\n@@ -2627,6 +2847,9 @@ struct sh_args {\n       }\t\t\t\t\t\t\t\t\t\\\n   } while(0)\n \n+#define ALLOW_INDEXED_ADDRESS \\\n+  ((!TARGET_SHMEDIA32 && !TARGET_SHCOMPACT) || TARGET_ALLOW_INDEXED_ADDRESS)\n+\n #define GO_IF_LEGITIMATE_ADDRESS(MODE, X, LABEL)\t\t\t\\\n {\t\t\t\t\t\t\t\t\t\\\n   if (BASE_REGISTER_RTX_P (X))\t\t\t\t\t\t\\\n@@ -2642,9 +2865,15 @@ struct sh_args {\n       rtx xop1 = XEXP ((X), 1);\t\t\t\t\t\t\\\n       if (GET_MODE_SIZE (MODE) <= 8 && BASE_REGISTER_RTX_P (xop0))\t\\\n \tGO_IF_LEGITIMATE_INDEX ((MODE), xop1, LABEL);\t\t\t\\\n-      if (GET_MODE_SIZE (MODE) <= 4\t\t\t\t\t\\\n-\t  || (TARGET_SHMEDIA && GET_MODE_SIZE (MODE) <= 8)\t\t\\\n-\t  || ((TARGET_SH4 || TARGET_SH2A_DOUBLE) && TARGET_FMOVD && MODE == DFmode))\t\t\\\n+      if ((ALLOW_INDEXED_ADDRESS || GET_MODE (X) == DImode\t\t\\\n+\t   || ((xop0 == stack_pointer_rtx || xop0 == frame_pointer_rtx)\t\\\n+\t       && REG_P (xop1) && REGNO (xop1) == R0_REG)\t\t\\\n+\t   || ((xop1 == stack_pointer_rtx || xop1 == frame_pointer_rtx)\t\\\n+\t       && REG_P (xop0) && REGNO (xop0) == R0_REG))\t\t\\\n+\t  && ((!TARGET_SHMEDIA && GET_MODE_SIZE (MODE) <= 4)\t\t\\\n+\t      || (TARGET_SHMEDIA && GET_MODE_SIZE (MODE) <= 8)\t\t\\\n+\t      || ((TARGET_SH4 || TARGET_SH2A_DOUBLE)\t\t\t\\\n+\t\t  && TARGET_FMOVD && MODE == DFmode)))\t\t\t\\\n \t{\t\t\t\t\t\t\t\t\\\n \t  if (BASE_REGISTER_RTX_P (xop1) && INDEX_REGISTER_RTX_P (xop0))\\\n \t    goto LABEL;\t\t\t\t\t\t\t\\\n@@ -2731,7 +2960,10 @@ struct sh_args {\n       && BASE_REGISTER_RTX_P (XEXP (X, 0))\t\t\t\t\\\n       && ! TARGET_SHMEDIA\t\t\t\t\t\t\\\n       && ! (TARGET_SH4 && (MODE) == DFmode)\t\t\t\t\\\n-      && ! ((MODE) == PSImode && (TYPE) == RELOAD_FOR_INPUT_ADDRESS))\t\\\n+      && ! ((MODE) == PSImode && (TYPE) == RELOAD_FOR_INPUT_ADDRESS)\t\\\n+      && (ALLOW_INDEXED_ADDRESS\t\t\t\t\t\t\\\n+\t  || XEXP ((X), 0) == stack_pointer_rtx\t\t\t\t\\\n+\t  || XEXP ((X), 0) == frame_pointer_rtx))\t\t\t\\\n     {\t\t\t\t\t\t\t\t\t\\\n       rtx index_rtx = XEXP (X, 1);\t\t\t\t\t\\\n       HOST_WIDE_INT offset = INTVAL (index_rtx), offset_base;\t\t\\\n@@ -2748,7 +2980,7 @@ struct sh_args {\n \t{\t\t\t\t\t\t\t\t\\\n \t  X = copy_rtx (X);\t\t\t\t\t\t\\\n \t  push_reload (index_rtx, NULL_RTX, &XEXP (X, 1), NULL,\t\t\\\n-\t\t       INDEX_REG_CLASS, Pmode, VOIDmode, 0, 0, (OPNUM),\t\\\n+\t\t       R0_REGS, Pmode, VOIDmode, 0, 0, (OPNUM),\t\t\\\n \t\t       (TYPE));\t\t\t\t\t\t\\\n \t  goto WIN;\t\t\t\t\t\t\t\\\n \t}\t\t\t\t\t\t\t\t\\\n@@ -2892,7 +3124,9 @@ struct sh_args {\n #define SHIFT_COUNT_TRUNCATED (! TARGET_SH3 && ! TARGET_SH2A)\n \n /* All integers have the same format so truncation is easy.  */\n-#define TRULY_NOOP_TRUNCATION(OUTPREC,INPREC)  1\n+/* But SHmedia must sign-extend DImode when truncating to SImode.  */\n+#define TRULY_NOOP_TRUNCATION(OUTPREC,INPREC) \\\n+ (!TARGET_SHMEDIA || (INPREC) < 64 || (OUTPREC) >= 64)\n \n /* Define this if addresses of constant functions\n    shouldn't be put through pseudo regs where they can be cse'd.\n@@ -3060,10 +3294,26 @@ struct sh_args {\n }\n \n #define ASM_OUTPUT_REG_PUSH(file, v) \\\n-  fprintf ((file), \"\\tmov.l\\tr%d,@-r15\\n\", (v));\n+{\t\t\t\t\t\t\t\\\n+  if (TARGET_SHMEDIA)\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\\\n+      fprintf ((file), \"\\taddi.l\\tr15,-8,r15\\n\");\t\\\n+      fprintf ((file), \"\\tst.q\\tr15,0,r%d\\n\", (v));\t\\\n+    }\t\t\t\t\t\t\t\\\n+  else\t\t\t\t\t\t\t\\\n+    fprintf ((file), \"\\tmov.l\\tr%d,@-r15\\n\", (v));\t\\\n+}\n \n #define ASM_OUTPUT_REG_POP(file, v) \\\n-  fprintf ((file), \"\\tmov.l\\t@r15+,r%d\\n\", (v));\n+{\t\t\t\t\t\t\t\\\n+  if (TARGET_SHMEDIA)\t\t\t\t\t\\\n+    {\t\t\t\t\t\t\t\\\n+      fprintf ((file), \"\\tld.q\\tr15,0,r%d\\n\", (v));\t\\\n+      fprintf ((file), \"\\taddi.l\\tr15,8,r15\\n\");\t\\\n+    }\t\t\t\t\t\t\t\\\n+  else\t\t\t\t\t\t\t\\\n+    fprintf ((file), \"\\tmov.l\\t@r15+,r%d\\n\", (v));\t\\\n+}\n \n /* DBX register number for a given compiler register number.  */\n /* GDB has FPUL at 23 and FP0 at 25, so we must add one to all FP registers\n@@ -3207,7 +3457,7 @@ struct sh_args {\n \n #define PRINT_OPERAND_PUNCT_VALID_P(CHAR) \\\n   ((CHAR) == '.' || (CHAR) == '#' || (CHAR) == '@' || (CHAR) == ','\t\\\n-   || (CHAR) == '$'|| (CHAR) == '\\'')\n+   || (CHAR) == '$' || (CHAR) == '\\'' || (CHAR) == '>')\n \n /* Recognize machine-specific patterns that may appear within\n    constants.  Used for PIC-specific UNSPECs.  */\n@@ -3326,8 +3576,6 @@ extern int current_function_interrupt;\n    for interrupt functions.  */\n extern struct rtx_def *sp_switch;\n \n-extern int rtx_equal_function_value_matters;\n-\n \f\n /* Instructions with unfilled delay slots take up an\n    extra two bytes for the nop in the delay slot.\n@@ -3339,18 +3587,23 @@ extern int rtx_equal_function_value_matters;\n /* Define the codes that are matched by predicates in sh.c.  */\n #define PREDICATE_CODES \\\n   {\"and_operand\", {SUBREG, REG, CONST_INT}},\t\t\t\t\\\n+  {\"any_arith_reg_dest\", {SUBREG, REG}},\t\t\t\t\\\n   {\"any_register_operand\", {SUBREG, REG}},\t\t\t\t\\\n   {\"arith_operand\", {SUBREG, REG, CONST_INT}},\t\t\t\t\\\n   {\"arith_reg_dest\", {SUBREG, REG}},\t\t\t\t\t\\\n-  {\"arith_reg_operand\", {SUBREG, REG}},\t\t\t\t\t\\\n+  {\"arith_reg_operand\", {SUBREG, REG, SIGN_EXTEND}},\t\t\t\\\n   {\"arith_reg_or_0_operand\", {SUBREG, REG, CONST_INT, CONST_VECTOR}},\t\\\n   {\"binary_float_operator\", {PLUS, MINUS, MULT, DIV}},\t\t\t\\\n   {\"binary_logical_operator\", {AND, IOR, XOR}},\t\t\t\t\\\n+  {\"cache_address_operand\", {PLUS, REG}},\t\t\t\t\\\n+  {\"cmp_operand\", {SUBREG, REG, CONST_INT}},\t\t\t\t\\\n   {\"cmpsi_operand\", {SUBREG, REG, CONST_INT}},\t\t\t\t\\\n   {\"commutative_float_operator\", {PLUS, MULT}},\t\t\t\t\\\n   {\"equality_comparison_operator\", {EQ,NE}},\t\t\t\t\\\n   {\"extend_reg_operand\", {SUBREG, REG, TRUNCATE}},\t\t\t\\\n   {\"extend_reg_or_0_operand\", {SUBREG, REG, TRUNCATE, CONST_INT}},\t\\\n+  {\"ext_dest_operand\", {SUBREG, REG}},\t\t\t\t\t\\\n+  {\"fp_arith_reg_dest\", {SUBREG, REG}},\t\t\t\t\t\\\n   {\"fp_arith_reg_operand\", {SUBREG, REG}},\t\t\t\t\\\n   {\"fpscr_operand\", {REG}},\t\t\t\t\t\t\\\n   {\"fpul_operand\", {REG}},\t\t\t\t\t\t\\\n@@ -3359,30 +3612,44 @@ extern int rtx_equal_function_value_matters;\n   {\"general_movdst_operand\", {SUBREG, REG, MEM}},\t\t\t\\\n   {\"unaligned_load_operand\", {MEM}},\t\t\t\t\t\\\n   {\"greater_comparison_operator\", {GT,GE,GTU,GEU}},\t\t\t\\\n-  {\"int_gpr_dest\", {SUBREG, REG}},\t\t\t\t\t\\\n   {\"inqhi_operand\", {TRUNCATE}},\t\t\t\t\t\\\n+  {\"int_gpr_dest\", {SUBREG, REG}},\t\t\t\t\t\\\n   {\"less_comparison_operator\", {LT,LE,LTU,LEU}},\t\t\t\\\n   {\"logical_operand\", {SUBREG, REG, CONST_INT}},\t\t\t\\\n+  {\"logical_operator\", {AND,IOR,XOR}},\t\t\t\t\t\\\n+  {\"logical_reg_operand\", {SUBREG, REG}},\t\t\t\t\\\n   {\"mextr_bit_offset\", {CONST_INT}},\t\t\t\t\t\\\n+  {\"minuend_operand\", {SUBREG, REG, TRUNCATE, CONST_INT}},\t\t\\\n   {\"noncommutative_float_operator\", {MINUS, DIV}},\t\t\t\\\n-  {\"shmedia_6bit_operand\", {SUBREG, REG, CONST_INT}},\t\t\t\\\n+  {\"sh_const_vec\", {CONST_VECTOR}},\t\t\t\t\t\\\n+  {\"sh_1el_vec\", {CONST_VECTOR}},\t\t\t\t\t\\\n   {\"sh_register_operand\", {REG, SUBREG, CONST_INT}},\t\t\t\\\n-  {\"target_reg_operand\", {SUBREG, REG}},\t\t\t\t\\\n+  {\"sh_rep_vec\", {CONST_VECTOR}},\t\t\t\t\t\\\n+  {\"shift_count_operand\", {CONST_INT, CONST_DOUBLE, CONST, SYMBOL_REF,\t\\\n+\t\t\t   LABEL_REF, SUBREG, REG, ZERO_EXTEND, SIGN_EXTEND}},\\\n+  {\"shift_count_reg_operand\", {SUBREG, REG, ZERO_EXTEND, SIGN_EXTEND}},\t\\\n+  {\"shift_operator\", {ASHIFT, ASHIFTRT, LSHIFTRT}},\t\t\t\\\n+  {\"symbol_ref_operand\", {SYMBOL_REF}},\t\t\t\t\t\\\n   {\"target_operand\", {SUBREG, REG, LABEL_REF, SYMBOL_REF, CONST, UNSPEC}},\\\n+  {\"target_reg_operand\", {SUBREG, REG}},\t\t\t\t\\\n   {\"trunc_hi_operand\", {SUBREG, REG, TRUNCATE}},\t\t\t\\\n-  {\"sh_const_vec\", {CONST_VECTOR}},\t\t\t\t\t\\\n-  {\"sh_1el_vec\", {CONST_VECTOR, PARALLEL}},\t\t\t\t\\\n-  {\"sh_rep_vec\", {CONST_VECTOR, PARALLEL}},\t\t\t\t\\\n-  {\"symbol_ref_operand\", {SYMBOL_REF}},\t\t\t\t\t\\\n+  {\"ua_address_operand\", {SUBREG, REG, PLUS}},\t\t\t\t\\\n+  {\"ua_offset\", {CONST_INT}},\t\t\t\t\t\t\\\n   {\"unary_float_operator\", {ABS, NEG, SQRT}},\t\t\t\t\\\n+  {\"xor_operand\", {SUBREG, REG, CONST_INT}},\t\t\t\t\\\n \n #define SPECIAL_MODE_PREDICATES \\\n+  \"any_arith_reg_dest\", \\\n   \"any_register_operand\", \\\n   \"int_gpr_dest\", \\\n+  \"target_operand\", \\\n+  \"target_reg_operand\", \\\n   \"trunc_hi_operand\", \\\n   /* This line intentionally left blank.  */\n \n #define any_register_operand register_operand\n+#define any_arith_reg_dest arith_reg_dest\n+#define ext_dest_operand arith_reg_operand\n \n /* Define this macro if it is advisable to hold scalars in registers\n    in a wider mode than that declared by the program.  In such cases,\n@@ -3395,12 +3662,15 @@ extern int rtx_equal_function_value_matters;\n    load instructions.  */\n #define PROMOTE_MODE(MODE, UNSIGNEDP, TYPE) \\\n   if (GET_MODE_CLASS (MODE) == MODE_INT\t\t\t\\\n-      && GET_MODE_SIZE (MODE) < UNITS_PER_WORD)\t\t\\\n+      && GET_MODE_SIZE (MODE) < 4/* ! UNITS_PER_WORD */)\\\n     (UNSIGNEDP) = ((MODE) == SImode ? 0 : (UNSIGNEDP)),\t\\\n-    (MODE) = (TARGET_SH1 ? SImode : DImode);\n+    (MODE) = (TARGET_SH1 ? SImode \\\n+\t      : TARGET_SHMEDIA32 ? SImode : DImode);\n \n #define MAX_FIXED_MODE_SIZE (TARGET_SH5 ? 128 : 64)\n \n+#define SIDI_OFF (TARGET_LITTLE_ENDIAN ? 0 : 4)\n+\n /* ??? Define ACCUMULATE_OUTGOING_ARGS?  This is more efficient than pushing\n    and popping arguments.  However, we do have push/pop instructions, and\n    rather limited offsets (4 bits) in load/store instructions, so it isn't\n@@ -3507,4 +3777,15 @@ extern int rtx_equal_function_value_matters;\n       : gen_rtx_MEM (Pmode, return_address_pointer_rtx)) \\\n    : NULL_RTX)\n \n+#define SIMULTANEOUS_PREFETCHES 2\n+\n+extern const char *sh_multcost_str;\n+extern const char *sh_gettrcost_str;\n+extern const char *sh_div_str;\n+extern const char *sh_divsi3_libfunc;\n+extern const char *cut2_workaround_str;\n+\n+/* FIXME: middle-end support for highpart optimizations is missing.  */\n+#define high_life_started reload_in_progress\n+\n #endif /* ! GCC_SH_H */"}, {"sha": "db00ec3ef9e4c83e6b89699dcf65fa420f91468e", "filename": "gcc/config/sh/sh.md", "status": "modified", "additions": 2716, "deletions": 602, "changes": 3318, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsh.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsh.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fsh.md?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326"}, {"sha": "1f7ee9cc0df3694bd0a3c53e080a550bdb63d361", "filename": "gcc/config/sh/shmedia.md", "status": "modified", "additions": 6, "deletions": 4, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fshmedia.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fshmedia.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fshmedia.md?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -25,9 +25,11 @@\n ;; the integer and multimedia unit (imu), the load/store unit (lsu), and\n ;; the floating point unit (fpu).\n \n-(define_automaton \"shmedia\")\n+(define_automaton \"sh5inst_pipe, sh5fpu_pipe\")\n \n-(define_cpu_unit \"sh5issue,sh5fds\" \"shmedia\")\n+(define_cpu_unit \"sh5issue\" \"sh5inst_pipe\")\n+\n+(define_cpu_unit \"sh5fds\" \"sh5fpu_pipe\")\n \n ;; Every instruction on SH-5 occupies the issue resource for at least one\n ;; cycle.\n@@ -86,8 +88,8 @@\n ;; can continue to issue.\n (define_insn_reservation \"shmedia_fdiv\" 19\n   (and (eq_attr \"pipe_model\" \"sh5media\") (eq_attr \"type\" \"fdiv_media\"))\n-  \"sh5fds*19\")\n+  \"sh5issue+sh5fds,sh5fds*18\")\n \n (define_insn_reservation \"shmedia_dfdiv\" 35\n   (and (eq_attr \"pipe_model\" \"sh5media\") (eq_attr \"type\" \"dfdiv_media\"))\n-  \"sh5fds*35\")\n+  \"sh5issue+sh5fds,sh5fds*34\")"}, {"sha": "c94e598149bb01f6ad0e660901c0ce5a8f27cc3f", "filename": "gcc/config/sh/sshmedia.h", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsshmedia.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsshmedia.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fsshmedia.h?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -31,6 +31,9 @@ Boston, MA 02111-1307, USA.  */\n #define _SSHMEDIA_H\n \n #if __SHMEDIA__\n+__inline__ static unsigned long long sh_media_GETCON (unsigned int k)\n+  __attribute__((always_inline));\n+\n __inline__ static\n unsigned long long\n sh_media_GETCON (unsigned int k)\n@@ -40,6 +43,9 @@ sh_media_GETCON (unsigned int k)\n   return res;\n }\n \n+__inline__ static void sh_media_PUTCON (unsigned long long mm, unsigned int k)\n+  __attribute__((always_inline));\n+\n __inline__ static\n void\n sh_media_PUTCON (unsigned long long mm, unsigned int k)"}, {"sha": "ebdd04712edeb78088c4e822bb620ebef1ae04df", "filename": "gcc/config/sh/superh.h", "status": "added", "additions": 151, "deletions": 0, "changes": 151, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsuperh.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsuperh.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fsuperh.h?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -0,0 +1,151 @@\n+/* Definitions of target machine for gcc for Super-H using sh-superh-elf.\n+   Copyright (C) 2001 Free Software Foundation, Inc.\n+\n+This file is part of GNU CC.\n+\n+GNU CC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 2, or (at your option)\n+any later version.\n+\n+GNU CC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GNU CC; see the file COPYING.  If not, write to\n+the Free Software Foundation, 59 Temple Place - Suite 330,\n+Boston, MA 02111-1307, USA.  */\n+\n+\n+/* This header file is used when the vendor name is set to 'superh'.\n+   It configures the compiler for SH4 only and switches the default\n+   endianess to little (although big endian is still available).\n+   It also configures the spec file to the default board configuration\n+   but in such a way that it can be overriden by a boardspecs file\n+   (using the -specs= option). This file is expected to disable the\n+   defaults and provide options --defsym _start and --defsym _stack\n+   which are required by the SuperH configuration of GNU ld.\n+\n+   This file is intended to overide sh.h */\n+\n+\n+#ifndef _SUPERH_H\n+#define _SUPERH_H\n+#endif\n+\n+\n+#undef TARGET_VERSION\n+#define TARGET_VERSION fprintf (stderr, \" (SuperH SH special %s)\", __DATE__);\n+\n+\n+/* We override TARGET_PROCESSOR_SWITCHES in order to remove all the unrequired cpu options\n+   and add options for all the SuperH CPU variants:\n+   -m4-100  is an alias for -m4.\n+   -m4-200  is an alias for -m4.\n+   -m4-400  is an alias for -m4-nofpu and passes -isa=sh4-nommu-nofpu to the assembler.\n+   -m4-500  is an alias for -m4-nofpu and passes -isa=sh4-nofpu to the assembler.  */\n+#undef TARGET_PROCESSOR_SWITCHES\n+#define TARGET_PROCESSOR_SWITCHES \\\n+  {\"4-500\",\tTARGET_NONE, \"SH4 500 series (FPU-less)\" }, \\\n+  {\"4-500\",\tSELECT_SH4_NOFPU, \"\" }, \\\n+  {\"4-400\",\tTARGET_NONE, \"SH4 400 series (MMU/FPU-less)\" },\t\\\n+  {\"4-400\",\tSELECT_SH4_NOFPU, \"\" }, \\\n+  {\"4-200-single-only\",\tTARGET_NONE, \"SH4 200 series with double = float (SH3e ABI)\" },\t\\\n+  {\"4-200-single-only\",\tSELECT_SH4_SINGLE_ONLY, \"\" }, \\\n+  {\"4-200-single\",\tTARGET_NONE, \"SH4 200 series with single precision pervading\" }, \\\n+  {\"4-200-single\",\tSELECT_SH4_SINGLE, \"\" }, \\\n+  {\"4-200-nofpu\",\tTARGET_NONE, \"SH4 200 series using soft floating point\" }, \\\n+  {\"4-200-nofpu\",\tSELECT_SH4_NOFPU, \"\" }, \\\n+  {\"4-200\",\tTARGET_NONE, \"SH4 200 series\" }, \\\n+  {\"4-200\",\tSELECT_SH4_NOFPU, \"\" }, \\\n+  {\"4-100-single-only\",\tTARGET_NONE, \"SH4 100 series with double = float (SH3e ABI)\" },\t\\\n+  {\"4-100-single-only\",\tSELECT_SH4_SINGLE_ONLY, \"\" }, \\\n+  {\"4-100-single\",\tTARGET_NONE, \"SH4 100 series with single precision pervading\" }, \\\n+  {\"4-100-single\",\tSELECT_SH4_SINGLE, \"\" }, \\\n+  {\"4-100-nofpu\",\tTARGET_NONE, \"SH4 100 series using soft floating point\" }, \\\n+  {\"4-100-nofpu\",\tSELECT_SH4_NOFPU, \"\" }, \\\n+  {\"4-100\",\tTARGET_NONE, \"SH4 100 series\" }, \\\n+  {\"4-100\",\tSELECT_SH4_NOFPU, \"\" }, \\\n+  {\"4-single-only\",\tTARGET_NONE, \"Generic SH4 with double = float (SH3e ABI)\" }, \\\n+  {\"4-single-only\",\tSELECT_SH4_SINGLE_ONLY, \"\" }, \\\n+  {\"4-single\",\tTARGET_NONE, \"Generic SH4 with single precision pervading\" }, \\\n+  {\"4-single\",\tSELECT_SH4_SINGLE, \"\" }, \\\n+  {\"4-nofpu\",\tTARGET_NONE, \"Generic SH4 using soft floating point\" },\t\\\n+  {\"4-nofpu\",\tSELECT_SH4_NOFPU, \"\" }, \\\n+  {\"4\",\t        TARGET_NONE, \"Generic SH4 (default)\" },\t\\\n+  {\"4\",\t        SELECT_SH4, \"\" }\n+\n+\n+/* Provide the -mboard= option used by the boardspecs file */\n+#undef SUBTARGET_OPTIONS\n+#define SUBTARGET_OPTIONS \\\n+  { \"board=\",   &boardtype, \"Board name [and momory region].\", 0 }, \\\n+  { \"runtime=\", &osruntime, \"Runtime name.\", 0 }, \\\n+\n+/* These are required by the mboard= option and runtime= option\n+   and are defined in sh.c but are not used anywhere */\n+extern const char * boardtype;\n+extern const char * osruntime;\n+\n+\n+/* Override the linker spec strings to use the new emultation\n+   The specstrings are concatenated as follows\n+   LINK_EMUL_PREFIX.(''|'32'|'64'|LINK_DEFAULT_CPU_EMUL).SUBTARGET_LINK_EMUL_SUFFIX\n+*/\n+#undef LINK_EMUL_PREFIX\n+#undef SUBTARGET_LINK_EMUL_SUFFIX\n+\n+#define LINK_EMUL_PREFIX \"superh\"\n+#define SUBTARGET_LINK_EMUL_SUFFIX \"\"\n+\n+/* Add the SUBTARGET_LINK_SPEC to add the board and runtime support and\n+   change the endianness */\n+#undef SUBTARGET_LINK_SPEC\n+#if  TARGET_ENDIAN_DEFAULT == LITTLE_ENDIAN_BIT\n+#define SUBTARGET_LINK_SPEC \"%(board_link) %(ldruntime) %{ml|!mb:-EL}%{mb:-EB}\"\n+#else\n+#define SUBTARGET_LINK_SPEC \"%(board_link) %(ldruntime) %{ml:-EL}%{mb|!ml:-EB}\"\n+#endif\n+\n+\n+/* This is used by the link spec if the boardspecs file is not used (for whatever reason).\n+   If the boardspecs file overrides this then an alternative can be used. */\n+#undef SUBTARGET_EXTRA_SPECS\n+#define SUBTARGET_EXTRA_SPECS \\\n+{ \"board_link\", \"--defsym _start=0x1000 --defsym _stack=0x30000\" }, \\\n+{ \"asruntime\", \"\" }, \\\n+{ \"cppruntime\", \"-D__GDB_SIM__\" }, \\\n+{ \"cc1runtime\", \"\" }, \\\n+{ \"ldruntime\", \"\" }, \\\n+{ \"libruntime\", \"-lc -lgloss\" }\n+\n+\n+/* Set the SUBTARGET_CPP_SPEC to define __EMBEDDED_CROSS__ which has an effect\n+   on newlib and provide the runtime support */\n+#undef SUBTARGET_CPP_SPEC\n+#define SUBTARGET_CPP_SPEC \\\n+\"-D__EMBEDDED_CROSS__ %{m4-100*:-D__SH4_100__} %{m4-200*:-D__SH4_200__} %{m4-400:-D__SH4_400__} %{m4-500:-D__SH4_500__} \\\n+%(cppruntime)\"\n+\n+/* Override the SUBTARGET_ASM_SPEC to add the runtime support */\n+#undef SUBTARGET_ASM_SPEC\n+#define SUBTARGET_ASM_SPEC \"%{m4-100*|m4-200*:-isa=sh4} %{m4-400:-isa=sh4-nommu-nofpu} %{m4-500:-isa=sh4-nofpu} %(asruntime)\"\n+\n+/* Override the SUBTARGET_ASM_RELAX_SPEC so it doesn't interfere with the\n+   runtime support by adding -isa=sh4 in the wrong place.  */\n+#undef SUBTARGET_ASM_RELAX_SPEC\n+#define SUBTARGET_ASM_RELAX_SPEC \"%{!m4-100*:%{!m4-200*:%{!m4-400:%{!m4-500:-isa=sh4}}}}\"\n+\n+/* Create the CC1_SPEC to add the runtime support */\n+#undef CC1_SPEC\n+#define CC1_SPEC \"%(cc1runtime)\"\n+\n+#undef CC1PLUS_SPEC\n+#define CC1PLUS_SPEC \"%(cc1runtime)\"\n+\n+\n+/* Override the LIB_SPEC to add the runtime support */\n+#undef LIB_SPEC\n+#define LIB_SPEC \"%{!shared:%{!symbolic:%(libruntime) -lc}} %{pg:-lprofile -lc}\""}, {"sha": "1d07e7ed4e6de0b495bf2df50103eb9e4f5790f8", "filename": "gcc/config/sh/superh64.h", "status": "added", "additions": 50, "deletions": 0, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsuperh64.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fsuperh64.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fsuperh64.h?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -0,0 +1,50 @@\n+/* \n+ Definitions of target machine for gcc for SuperH using target sh-superh-elf,\n+ \n+   Copyright 2000 Free Software Foundation, Inc.\n+   Contributed by Alexandre Oliva <aoliva@redhat.com>\n+   Modified for SuperH by Richard Shann\n+\n+This file is part of GNU CC.\n+\n+GNU CC is free software; you can redistribute it and/or modify\n+it under the terms of the GNU General Public License as published by\n+the Free Software Foundation; either version 2, or (at your option)\n+any later version.\n+\n+GNU CC is distributed in the hope that it will be useful,\n+but WITHOUT ANY WARRANTY; without even the implied warranty of\n+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+GNU General Public License for more details.\n+\n+You should have received a copy of the GNU General Public License\n+along with GNU CC; see the file COPYING.  If not, write to\n+the Free Software Foundation, 59 Temple Place - Suite 330,\n+Boston, MA 02111-1307, USA.  */\n+\n+/* This header file is used when the vendor name is set to 'superh'.\n+   It configures the compiler for SH5 only and switches the default\n+   endianess to little.\n+   This file is intended to overide sh.h, superh.h and sh64.h (which\n+   should have been included in that order) */\n+\n+\n+#ifndef _SUPERH_H\n+ #error superh64.h should not be used without superh.h\n+#endif\n+\n+/* We override TARGET_PROCESSOR_SWITCHES in order to remove all the unrequired cpu options */\n+#undef TARGET_PROCESSOR_SWITCHES\n+#define TARGET_PROCESSOR_SWITCHES  \t\t\t\\\n+  {\"5-64media\",\tTARGET_NONE, \"\" },\t\t\\\n+  {\"5-64media\", SELECT_SH5_64, \"SH5 64-bit SHmedia code\" }, \\\n+  {\"5-64media-nofpu\", TARGET_NONE, \"\" },\t\\\n+  {\"5-64media-nofpu\", SELECT_SH5_64_NOFPU, \"SH5 64-bit FPU-less SHmedia code\" }, \\\n+  {\"5-32media\",\tTARGET_NONE, \"\" },\t\t\\\n+  {\"5-32media\", SELECT_SH5_32, \"SH5 32-bit SHmedia code\" }, \\\n+  {\"5-32media-nofpu\", TARGET_NONE, \"\" },\t\\\n+  {\"5-32media-nofpu\", SELECT_SH5_32_NOFPU, \"SH5 32-bit FPU-less SHmedia code\" }, \\\n+  {\"5-compact\",\tTARGET_NONE, \"\" },\t\t\\\n+  {\"5-compact\",\tSELECT_SH5_COMPACT, \"SH5 SHcompact code\" }, \\\n+  {\"5-compact-nofpu\", TARGET_NONE, \"\" },\t\\\n+  {\"5-compact-nofpu\", SELECT_SH5_COMPACT_NOFPU, \"SH5 FPU-less SHcompact code\" }"}, {"sha": "698882fe92e779c885daa390989912a9672b49da", "filename": "gcc/config/sh/t-linux", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Ft-linux", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Ft-linux", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Ft-linux?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -1,5 +1,5 @@\n TARGET_LIBGCC2_CFLAGS = -fpic -DNO_FPSCR_VALUES\n-LIB1ASMFUNCS_CACHE = _ic_invalidate\n+LIB1ASMFUNCS_CACHE = _ic_invalidate _ic_invalidate_array\n \n LIB2FUNCS_EXTRA=\n "}, {"sha": "031180842d20398a8d2fafde80b73e9dc44e2cc1", "filename": "gcc/config/sh/t-sh64", "status": "modified", "additions": 1, "deletions": 3, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Ft-sh64", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Ft-sh64", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Ft-sh64?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -1,11 +1,9 @@\n-EXTRA_MULTILIB_PARTS= crt1.o crti.o crtn.o crtbegin.o crtend.o\n-\n LIB1ASMFUNCS = \\\n   _sdivsi3 _sdivsi3_i4 _udivsi3 _udivsi3_i4 _set_fpscr \\\n   _shcompact_call_trampoline _shcompact_return_trampoline \\\n   _shcompact_incoming_args _ic_invalidate _nested_trampoline \\\n   _push_pop_shmedia_regs \\\n-  _udivdi3 _divdi3 _umoddi3 _moddi3\n+  _udivdi3 _divdi3 _umoddi3 _moddi3 _div_table\n \n MULTILIB_CPU_DIRS= $(ML_sh1) $(ML_sh2e) $(ML_sh2) $(ML_sh3e) $(ML_sh3) $(ML_sh4_nofpu) $(ML_sh4_single_only) $(ML_sh4_single) $(ML_sh4) $(ML_sh5_32media:m5-32media/=media32) $(ML_sh5_32media_nofpu:m5-32media-nofpu/=nofpu/media32) $(ML_sh5_compact:m5-compact/=compact) $(ML_sh5_compact_nofpu:m5-compact-nofpu/=nofpu/compact) $(ML_sh5_64media:m5-64media/=media64) $(ML_sh5_64media_nofpu:m5-64media-nofpu/=nofpu/media64)\n "}, {"sha": "35803caeb05244668b2b131a78a1db80c845f27a", "filename": "gcc/config/sh/t-superh", "status": "added", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Ft-superh", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Ft-superh", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Ft-superh?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -0,0 +1,6 @@\n+MULTILIB_OPTIONS= mb m4-nofpu/m4-single/m4-single-only\n+MULTILIB_DIRNAMES= \n+MULTILIB_MATCHES = m4=m4-100 m4-nofpu=m4-100-nofpu m4-single=m4-100-single m4-single-only=m4-100-single-only \\\n+\t\t   m4=m4-200 m4-nofpu=m4-200-nofpu m4-single=m4-200-single m4-single-only=m4-200-single-only \\\n+\t\t   m4-nofpu=m4-400 \\\n+\t\t   m4-nofpu=m4-500"}, {"sha": "86312af32979552f44a64e61118156d91341494f", "filename": "gcc/config/sh/ushmedia.h", "status": "modified", "additions": 413, "deletions": 471, "changes": 884, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fushmedia.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fconfig%2Fsh%2Fushmedia.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fsh%2Fushmedia.h?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -36,767 +36,706 @@ typedef float __GCC_FV __attribute__ ((vector_size (4 * sizeof (float))));\n typedef float __GCC_MTRX __attribute__ ((vector_size (16 * sizeof (float))));\n #endif\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MABS_L (unsigned long long mm)\n {\n-  unsigned long long res;\n-  __asm__ (\"mabs.l\t%1, %0\" : \"=r\" (res) : \"r\" (mm));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_absv2si2 ((v2si) mm);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MABS_W (unsigned long long mm)\n {\n-  unsigned long long res;\n-  __asm__ (\"mabs.w\t%1, %0\" : \"=r\" (res) : \"r\" (mm));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_absv4hi2 ((v4hi) mm);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MADD_L (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"madd.l\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_addv2si3 ((v2si) mm, (v2si) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MADD_W (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"madd.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_addv4hi3 ((v4hi) mm, (v4hi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MADDS_L (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"madds.l\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_ssaddv2si3 ((v2si) mm, (v2si) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MADDS_UB (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"madds.ub\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v8qi __attribute__ ((mode(V8QI)));\n+\n+  return (unsigned long long) __builtin_usaddv8qi3 ((v8qi) mm, (v8qi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MADDS_W (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"madds.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_ssaddv4hi3 ((v4hi) mm, (v4hi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MCMPEQ_B (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mcmpeq.b\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v8qi __attribute__ ((mode(V8QI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MCMPEQ_B ((v8qi) mm,\n+\t\t\t\t\t\t\t   (v8qi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MCMPEQ_L (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mcmpeq.l\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MCMPEQ_L ((v2si) mm,\n+\t\t\t\t\t\t\t   (v2si) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MCMPEQ_W (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mcmpeq.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n-}\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n \n-__inline__ static\n-unsigned long long\n-sh_media_MCMPGT_L (unsigned long long mm, unsigned long long mn)\n-{\n-  unsigned long long res;\n-  __asm__ (\"mcmpgt.l\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  return (unsigned long long) __builtin_sh_media_MCMPEQ_W ((v4hi) mm,\n+\t\t\t\t\t\t\t   (v4hi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MCMPGT_UB (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mcmpgt.ub\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v8qi __attribute__ ((mode(V8QI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MCMPGT_UB ((v8qi) mm,\n+\t\t\t\t\t\t\t   (v8qi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n-sh_media_MCMPGT_W (unsigned long long mm, unsigned long long mn)\n+static __inline unsigned long long\n+sh_media_MCMPGT_L (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mcmpgt.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MCMPGT_L ((v2si) mm,\n+\t\t\t\t\t\t\t   (v2si) mn);\n }\n \n-__inline__ static\n-unsigned long long\n-sh_media_MCMV (unsigned long long mm, unsigned long long mn, unsigned long long mw)\n+static __inline unsigned long long\n+sh_media_MCMPGT_W (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mcmv\t%1, %2, %0\" : \"=r\" (res)\n-\t   : \"r\" (mm), \"r\" (mn), \"0\" (mw));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MCMPGT_W ((v4hi) mm,\n+\t\t\t\t\t\t\t   (v4hi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+#define sh_media_MCMV __builtin_sh_media_MCMV\n+\n+static __inline unsigned long long\n sh_media_MCNVS_LW (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mcnvs.lw\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+  typedef unsigned int uv2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MCNVS_LW ((v2si) mm,\n+\t\t\t\t\t\t\t   (uv2si) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MCNVS_WB (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mcnvs.wb\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MCNVS_WB ((v4hi) mm,\n+\t\t\t\t\t\t\t   (v4hi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MCNVS_WUB (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mcnvs.wub\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MCNVS_WUB ((v4hi) mm,\n+\t\t\t\t\t\t\t    (v4hi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MEXTR1 (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mextr1\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v8qi __attribute__ ((mode(V8QI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MEXTR1 ((v8qi) mm,\n+\t\t\t\t\t\t\t (v8qi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MEXTR2 (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mextr2\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v8qi __attribute__ ((mode(V8QI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MEXTR2 ((v8qi) mm,\n+\t\t\t\t\t\t\t (v8qi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MEXTR3 (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mextr3\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v8qi __attribute__ ((mode(V8QI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MEXTR3 ((v8qi) mm,\n+\t\t\t\t\t\t\t (v8qi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MEXTR4 (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mextr4\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v8qi __attribute__ ((mode(V8QI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MEXTR4 ((v8qi) mm,\n+\t\t\t\t\t\t\t (v8qi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MEXTR5 (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mextr5\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v8qi __attribute__ ((mode(V8QI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MEXTR5 ((v8qi) mm,\n+\t\t\t\t\t\t\t (v8qi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MEXTR6 (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mextr6\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v8qi __attribute__ ((mode(V8QI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MEXTR6 ((v8qi) mm,\n+\t\t\t\t\t\t\t (v8qi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MEXTR7 (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mextr7\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v8qi __attribute__ ((mode(V8QI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MEXTR7 ((v8qi) mm,\n+\t\t\t\t\t\t\t (v8qi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n-sh_media_MMACFX_WL (unsigned long long mm, unsigned long long mn, unsigned long long mw)\n+static __inline unsigned long long\n+sh_media_MMACFX_WL (unsigned long long mm, unsigned long long mn,\n+\t\t    unsigned long long mw)\n {\n-  unsigned long long res;\n-  __asm__ (\"mmacfx.wl\t%1, %2, %0\" : \"=r\" (res)\n-\t   : \"r\" (mm), \"r\" (mn), \"0\" (mw));\n-  return res;\n+  typedef float v2hi __attribute__ ((mode(V2HI)));\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+  typedef unsigned int uv2si __attribute__ ((mode(V2SI)));\n+\n+  long mm_l = (long) mm;\n+  long mn_l = (long) mn;\n+\n+  return ((unsigned long long)\n+    __builtin_sh_media_MMACFX_WL ((v2hi) mm_l, (v2hi) mn_l,\n+\t\t\t\t  (uv2si) mw));\n }\n \n-__inline__ static\n-unsigned long long\n-sh_media_MMACNFX_WL (unsigned long long mm, unsigned long long mn, unsigned long long mw)\n+static __inline unsigned long long\n+sh_media_MMACNFX_WL (unsigned long long mm, unsigned long long mn,\n+\t\t     unsigned long long mw)\n {\n-  unsigned long long res;\n-  __asm__ (\"mmacnfx.wl\t%1, %2, %0\" : \"=r\" (res)\n-\t   : \"r\" (mm), \"r\" (mn), \"0\" (mw));\n-  return res;\n+  typedef float v2hi __attribute__ ((mode(V2HI)));\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+  typedef unsigned int uv2si __attribute__ ((mode(V2SI)));\n+\n+  long mm_l = (long) mm;\n+  long mn_l = (long) mn;\n+\n+  return ((unsigned long long)\n+    __builtin_sh_media_MMACNFX_WL ((v2hi) mm_l, (v2hi) mn_l,\n+\t\t\t\t   (uv2si) mw));\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MMUL_L (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mmul.l\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_mulv2si3 ((v2si) mm, (v2si) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MMUL_W (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mmul.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_mulv4hi3 ((v4hi) mm, (v4hi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MMULFX_L (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mmulfx.l\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MMULFX_L ((v2si) mm,\n+\t\t\t\t\t\t\t   (v2si) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MMULFX_W (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mmulfx.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MMULFX_W ((v4hi) mm,\n+\t\t\t\t\t\t\t   (v4hi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MMULFXRP_W (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mmulfxrp.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MMULFXRP_W ((v4hi) mm,\n+\t\t\t\t\t\t\t     (v4hi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MMULHI_WL (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mmulhi.wl\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MMULHI_WL ((v4hi) mm,\n+\t\t\t\t\t\t\t    (v4hi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MMULLO_WL (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mmullo.wl\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MMULLO_WL ((v4hi) mm,\n+\t\t\t\t\t\t\t    (v4hi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n-sh_media_MMULSUM_WQ (unsigned long long mm, unsigned long long mn, unsigned long long mw)\n+static __inline unsigned long long\n+sh_media_MMULSUM_WQ (unsigned long long mm, unsigned long long mn,\n+\t\t     unsigned long long mw)\n {\n-  unsigned long long res;\n-  __asm__ (\"mmulsum.wq\t%1, %2, %0\" : \"=r\" (res)\n-\t   : \"r\" (mm), \"r\" (mn), \"0\" (mw));\n-  return res;\n+  typedef unsigned int uv4hi __attribute__ ((mode(V4HI)));\n+\n+  return __builtin_sh_media_MMULSUM_WQ ((uv4hi) mm, (uv4hi) mn, mw);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MPERM_W (unsigned long long mm, unsigned int mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mperm.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MPERM_W ((v4hi) mm, mn);\n }\n \n-__inline__ static\n-unsigned long long\n-sh_media_MSAD_UBQ (unsigned long long mm, unsigned long long mn, unsigned long long mw)\n+static __inline unsigned long long\n+sh_media_MSAD_UBQ (unsigned long long mm, unsigned long long mn,\n+\t\t   unsigned long long mw)\n {\n-  unsigned long long res;\n-  __asm__ (\"msad.ubq\t%1, %2, %0\" : \"=r\" (res)\n-\t   : \"r\" (mm), \"r\" (mn), \"0\" (mw));\n-  return res;\n+  typedef unsigned int uv8qi __attribute__ ((mode(V8QI)));\n+\n+  return __builtin_sh_media_MSAD_UBQ ((uv8qi) mm, (uv8qi) mn, mw);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSHALDS_L (unsigned long long mm, unsigned int mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mshalds.l\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MSHALDS_L ((v2si) mm, mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSHALDS_W (unsigned long long mm, unsigned int mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mshalds.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MSHALDS_W ((v4hi) mm, mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSHARD_L (unsigned long long mm, unsigned int mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mshard.l\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_ashrv2si3 ((v2si) mm, mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSHARD_W (unsigned long long mm, unsigned int mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mshard.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n-}\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n \n-__inline__ static\n-short\n-sh_media_MSHARDS_Q (long long mm, unsigned int mn)\n-{\n-  short res;\n-  __asm__ (\"mshards.q\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  return (unsigned long long) __builtin_ashrv4hi3 ((v4hi) mm, mn);\n }\n \n-__inline__ static\n-unsigned long long\n+#define sh_media_MSHARDS_Q __builtin_sh_media_MSHARDS_Q\n+\n+static __inline unsigned long long\n sh_media_MSHFHI_B (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mshfhi.b\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v8qi __attribute__ ((mode(V8QI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MSHFHI_B ((v8qi) mm,\n+\t\t\t\t\t\t\t   (v8qi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSHFHI_L (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mshfhi.l\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MSHFHI_L ((v2si) mm,\n+\t\t\t\t\t\t\t   (v2si) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSHFHI_W (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mshfhi.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MSHFHI_W ((v4hi) mm,\n+\t\t\t\t\t\t\t   (v4hi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSHFLO_B (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mshflo.b\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v8qi __attribute__ ((mode(V8QI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MSHFLO_B ((v8qi) mm,\n+\t\t\t\t\t\t\t   (v8qi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSHFLO_L (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mshflo.l\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MSHFLO_L ((v2si) mm,\n+\t\t\t\t\t\t\t   (v2si) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSHFLO_W (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mshflo.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_sh_media_MSHFLO_W ((v4hi) mm,\n+\t\t\t\t\t\t\t   (v4hi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSHLLD_L (unsigned long long mm, unsigned int mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mshlld.l\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_ashlv2si3 ((v2si) mm, mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSHLLD_W (unsigned long long mm, unsigned int mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mshlld.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_ashlv4hi3 ((v4hi) mm, mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSHLRD_L (unsigned long long mm, unsigned int mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mshlrd.l\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_lshrv2si3 ((v2si) mm, mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSHLRD_W (unsigned long long mm, unsigned int mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"mshlrd.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_lshrv4hi3 ((v4hi) mm, mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSUB_L (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"msub.l\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_subv2si3 ((v2si) mm, (v2si) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSUB_W (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"msub.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_subv4hi3 ((v4hi) mm, (v4hi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSUBS_L (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"msubs.l\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v2si __attribute__ ((mode(V2SI)));\n+\n+  return (unsigned long long) __builtin_sssubv2si3 ((v2si) mm, (v2si) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSUBS_UB (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"msubs.ub\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v8qi __attribute__ ((mode(V8QI)));\n+\n+  return (unsigned long long) __builtin_ussubv8qi3 ((v8qi) mm, (v8qi) mn);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_MSUBS_W (unsigned long long mm, unsigned long long mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"msubs.w\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  typedef float v4hi __attribute__ ((mode(V4HI)));\n+\n+  return (unsigned long long) __builtin_sssubv4hi3 ((v4hi) mm, (v4hi) mn);\n }\n \n #if ! __SH4_NOFPU__\n-__inline__ static\n-double\n-sh_media_FABS_D (double dg)\n-{\n-  double res;\n-  __asm__ (\"fabs.d\t%1, %0\" : \"=f\" (res) : \"f\" (dg));\n-  return res;\n-}\n+/* Floating-point Intrinsics */\n \n-__inline__ static\n-float \n-sh_media_FABS_S (float fg)\n-{\n-  float res;\n-  __asm__ (\"fabs.s\t%1, %0\" : \"=f\" (res) : \"f\" (fg));\n-  return res;\n-}\n+#define sh_media_FABS_D __builtin_fabs\n+#define sh_media_FABS_S __builtin_fabsf\n+#define sh_media_FCMPUN_D __builtin_isunordered\n+#define sh_media_FCMPUN_S __builtin_isunordered\n \n-__inline__ static\n-int   \n-sh_media_FCMPUN_D (double dg, double dh)\n+static __inline float sh_media_FCOSA_S (float fg)\n {\n-  int res;\n-  __asm__ (\"fcmpun.d\t%1, %2, %0\" : \"=f\" (res) : \"f\" (dg), \"f\" (dh));\n-  return res;\n-}\n+  union { int i; float f; } u;\n \n-__inline__ static\n-int   \n-sh_media_FCMPUN_S (float fg, float fh)\n-{\n-  int res;\n-  __asm__ (\"fcmpun.s\t%1, %2, %0\" : \"=f\" (res) : \"f\" (fg), \"f\" (fh));\n-  return res;\n+  u.f = fg;\n+  return __builtin_sh_media_FCOSA_S (u.i);\n }\n \n-__inline__ static\n-float \n+static __inline float\n sh_media_FGETSCR (void)\n-{\n-  float res;\n-  __asm__ (\"fgetscr\t%0\" : \"=f\" (res));\n-  return res;\n+{ \n+  float f;\n+\n+  __asm volatile (\"fgetscr %0\" : \"=f\" (f));\n+  return f;\n }\n \n-__inline__ static\n-float \n+static __inline float\n sh_media_FIPR_S (const void *fvg, const void *fvh)\n {\n-  float res;\n-  __asm__ (\"fipr.s\t%1, %2, %0\" : \"=f\" (res)\n-\t   : \"f\" (*(const __GCC_FV *)fvg), \"f\" (*(const __GCC_FV *)fvh));\n-  return res;\n+  typedef float v4sf __attribute__ ((mode(V4SF)));\n+  v4sf vg = *(v4sf*) fvg;\n+  v4sf vh = *(v4sf*) fvh;\n+\n+  return __builtin_sh_media_FIPR_S (vg, vh);\n }\n \n-__inline__ static\n-float \n+#if 0\n+/* This gives different results for -O0  */\n+static __inline float\n sh_media_FMAC_S (float fg, float fh, float fq)\n {\n-  float res;\n-  __asm__ (\"fmac.s\t%1, %2, %0\" : \"=f\" (res)\n-\t   : \"f\" (fg), \"f\" (fh), \"0\" (fq));\n-  return res;\n+  return fg * fh + fq;\n }\n+#else\n \n-__inline__ static\n-long long\n+#define sh_media_FMAC_S __builtin_sh_media_FMAC_S\n+#endif\n+\n+static __inline long long\n sh_media_FMOV_DQ (double dg)\n {\n-  long long res;\n-  __asm__ (\"fmov.dq\t%1, %0\" : \"=r\" (res) : \"f\" (dg));\n-  return res;\n+  union { long long l; double d; } u;\n+\n+  u.d = dg;\n+  return u.l;\n }\n \n-__inline__ static\n-float\n+static __inline float\n sh_media_FMOV_LS (int mm)\n {\n-  float res;\n-  __asm__ (\"fmov.ls\t%1, %0\" : \"=f\" (res) : \"r\" (mm));\n-  return res;\n+  union { int i; float f; } u;\n+\n+  u.i = mm;\n+  return u.f;\n }\n \n-__inline__ static\n-double\n+static __inline double\n sh_media_FMOV_QD (long long mm)\n {\n-  double res;\n-  __asm__ (\"fmov.qd\t%1, %0\" : \"=f\" (res) : \"r\" (mm));\n-  return res;\n+  union { long long l; double d; } u;\n+\n+  u.l = mm;\n+  return u.d;\n }\n \n-__inline__ static\n-int\n+static __inline int\n sh_media_FMOV_SL (float fg)\n {\n-  int res;\n-  __asm__ (\"fmov.sl\t%1, %0\" : \"=r\" (res) : \"f\" (fg));\n-  return res;\n+  union { int i; float f; } u;\n+\n+  u.f = fg;\n+  return u.i;\n }\n \n-__inline__ static\n-void  \n+static __inline void\n sh_media_FPUTSCR (float fg)\n-{\n-  __asm__ (\"fputscr\t%0\" : : \"f\" (fg));\n+{ \n+  __asm volatile (\"fputscr %0\" : : \"f\" (fg));\n }\n \n-__inline__ static\n-double\n-sh_media_FSQRT_D (double dg)\n+static __inline float sh_media_FSINA_S (float fg)\n {\n-  double res;\n-  __asm__ (\"fsqrt.d\t%1, %0\" : \"=f\" (res) : \"f\" (dg));\n-  return res;\n-}\n+  union { int i; float f; } u;\n \n-__inline__ static\n-float \n-sh_media_FSQRT_S (float fg)\n-{\n-  float res;\n-  __asm__ (\"fsqrt.s\t%1, %0\" : \"=f\" (res) : \"f\" (fg));\n-  return res;\n+  u.f = fg;\n+  return __builtin_sh_media_FSINA_S (u.i);\n }\n \n-__inline__ static\n-void  \n+/* Can't use __builtin_sqrt / __builtin_sqrtf because they still implement\n+   error handling unless -ffast-math is used.  */\n+#define sh_media_FSQRT_D __builtin_sh_media_FSQRT_D\n+#define sh_media_FSQRT_S __builtin_sh_media_FSQRT_S\n+#define sh_media_FSRRA_S __builtin_sh_media_FSRRA_S\n+\n+static __inline void\n sh_media_FTRV_S (const void *mtrxg, const void *fvh, void *fvf)\n {\n-  __asm__ (\"ftrv.s\t%2, %1, %0\" : \"=f\" (*(__GCC_FV *)fvf)\n-\t   : \"f\" (*(const __GCC_FV *)fvh), \"f\" (*(const __GCC_MTRX *)mtrxg));\n+  typedef float v16sf __attribute__ ((mode(V16SF)));\n+  typedef float v4sf __attribute__ ((mode(V4SF)));\n+  v16sf mtrx = *(v16sf*) mtrxg;\n+  v4sf vh = *(v4sf*) fvh;\n+\n+  *(v4sf*) fvf = __builtin_sh_media_FTRV_S (mtrx, vh);\n }\n #endif /* ! __SH4_NOFPU__ */\n \n-__inline__ static\n-unsigned long long\n+/* Not implemented here: Control and Configuration intrinsics.  */\n+/* Misaligned Access Support intrinsics */\n+\n+static __inline unsigned long long\n sh_media_LDHI_L (void *p, int s)\n {\n-  unsigned long long res;\n-  __asm__ (\"ldhi.l\t%m1, %0\" : \"=r\" (res) : \"o\" (((char*)p)[s]));\n-  return res;\n+  return __builtin_sh_media_LDHI_L ((char *)p + s);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_LDHI_Q (void *p, int s)\n {\n-  unsigned long long res;\n-  __asm__ (\"ldhi.q\t%m1, %0\" : \"=r\" (res) : \"o\" (((char*)p)[s]));\n-  return res;\n+  return __builtin_sh_media_LDHI_Q ((char *)p + s);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_LDLO_L (void *p, int s)\n {\n-  unsigned long long res;\n-  __asm__ (\"ldlo.l\t%m1, %0\" : \"=r\" (res) : \"o\" (((char*)p)[s]));\n-  return res;\n+  return __builtin_sh_media_LDLO_L ((char *)p + s);\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline unsigned long long\n sh_media_LDLO_Q (void *p, int s)\n {\n-  unsigned long long res;\n-  __asm__ (\"ldlo.q\t%m1, %0\" : \"=r\" (res) : \"o\" (((char*)p)[s]));\n-  return res;\n+  return __builtin_sh_media_LDLO_Q ((char *)p + s);\n }\n \n-__inline__ static\n-void     \n+static __inline void\n sh_media_STHI_L (void *p, int s, unsigned int mw)\n {\n-  __asm__ (\"sthi.l %m0, %1\" : \"+o\" (((char*)p)[s]) : \"r\" (mw));\n+  __builtin_sh_media_STHI_L ((char*)p + s, mw);\n }\n \n-__inline__ static\n-void     \n+static __inline void\n sh_media_STHI_Q (void *p, int s, unsigned long long mw)\n {\n-  __asm__ (\"sthi.q %m0, %1\" : \"+o\" (((char*)p)[s]) : \"r\" (mw));\n+  __builtin_sh_media_STHI_Q ((char*)p + s, mw);\n }\n \n-__inline__ static\n-void     \n+static __inline void\n sh_media_STLO_L (void *p, int s, unsigned int mw)\n {\n-  __asm__ (\"stlo.l %m0, %1\" : \"+o\" (((char*)p)[s]) : \"r\" (mw));\n+  __builtin_sh_media_STLO_L ((char*)p + s, mw);\n }\n \n-__inline__ static\n-void     \n+static __inline void\n sh_media_STLO_Q (void *p, int s, unsigned long long mw)\n {\n-  __asm__ (\"stlo.q %m0, %1\" : \"+o\" (((char*)p)[s]) : \"r\" (mw));\n+  __builtin_sh_media_STLO_Q ((char*)p + s, mw);\n }\n \n-__inline__ static\n-unsigned char\n-sh_media_NSB (long long mm)\n-{\n-  unsigned char res;\n-  __asm__ (\"nsb\t%1, %0\" : \"=r\" (res) : \"r\" (mm));\n-  return res;\n-}\n+/* Miscellaneous intrinsics */\n \n-__inline__ static\n-unsigned long long\n+#define sh_media_NSB __builtin_sh_media_NSB\n+\n+static __inline unsigned long long\n sh_media_BYTEREV (unsigned long long mm)\n {\n-  unsigned long long res;\n-  __asm__ (\"byterev\t%1, %0\" : \"=r\" (res) : \"r\" (mm));\n-  return res;\n+  typedef float v8qi __attribute__ ((mode(V8QI)));\n+\n+  return (unsigned long long) __builtin_sh_media_BYTEREV ((v8qi) mm);\n }\n \n-__inline__ static\n-unsigned long long\n+__inline__ static unsigned long long\n+sh_media_CMVEQ (unsigned long long mm, unsigned long long mn, unsigned long long mw) __attribute__ ((always_inline));\n+\n+__inline__ static unsigned long long\n sh_media_CMVEQ (unsigned long long mm, unsigned long long mn, unsigned long long mw)\n {\n-  unsigned long long res;\n-  __asm__ (\"cmveq\t%1, %2, %0\" : \"=r\" (res)\n-\t   : \"r\" (mm), \"r\" (mn), \"0\" (mw));\n-  return res;\n+  return mm == 0 ? mn : mw;\n }\n \n-__inline__ static\n-unsigned long long\n+__inline__ static unsigned long long\n+sh_media_CMVNE (unsigned long long mm, unsigned long long mn, unsigned long long mw) __attribute__ ((always_inline));\n+\n+__inline__ static unsigned long long\n sh_media_CMVNE (unsigned long long mm, unsigned long long mn, unsigned long long mw)\n {\n-  unsigned long long res;\n-  __asm__ (\"cmveq\t%1, %2, %0\" : \"=r\" (res)\n-\t   : \"r\" (mm), \"r\" (mn), \"0\" (mw));\n-  return res;\n+  return mm != 0 ? mn : mw;\n }\n \n-__inline__ static\n-unsigned long long\n+static __inline long long\n sh_media_ADDZ_L (unsigned int mm, unsigned int mn)\n {\n-  unsigned long long res;\n-  __asm__ (\"addz.l\t%1, %2, %0\" : \"=r\" (res) : \"r\" (mm), \"r\" (mn));\n-  return res;\n+  return mm + mn;\n }\n \n-__inline__ static\n+/* NOP and Synchronization instrinsics not implemented here.  */\n+\n+static __inline__ void sh_media_PREFO(void *mm, int s)\n+{\n+  __builtin_sh_media_PREFO (mm + s, 0, 0);\n+}\n+\n+/* Event Handling instrinsics not implemented here.  */\n+\n+/* Old asm stuff */\n+\n+static __inline__\n void\n sh_media_NOP (void)\n {\n-  __asm__ __volatile__ (\"nop\" : :);\n+  __asm__ (\"nop\" : :);\n }\n \n __inline__ static\n@@ -827,7 +766,7 @@ __inline__ static\n void\n sh_media_ALLOCO (void *mm, int s)\n {\n-  __asm__ __volatile__ (\"alloco\t%m0\" : : \"o\" (((char*)mm)[s]));\n+  __builtin_sh_media_ALLOCO (mm + s);\n }\n \n __inline__ static\n@@ -865,13 +804,6 @@ sh_media_PREFI (void *mm, int s)\n   __asm__ __volatile__ (\"prefi\t%m0\" : : \"o\" (((char*)mm)[s]));\n }\n \n-__inline__ static\n-void\n-sh_media_PREFO (void *mm, int s)\n-{\n-  __asm__ __volatile__ (\"ld.b\t%m0, r63\" : : \"o\" (((char*)mm)[s]));\n-}\n-\n __inline__ static\n void\n sh_media_BRK (void)\n@@ -911,14 +843,19 @@ sh_media_unaligned_LD_UW (void *p)\n #endif\n }\n \n+/* We don't use the sh_media_LD* functions here because that turned out\n+   to impede constant propagation of the offsets into the ldhi / ldlo\n+   instructions.  */\n __inline__ static\n int           \n sh_media_unaligned_LD_L (void *p)\n {\n #if __LITTLE_ENDIAN__\n-  return sh_media_LDHI_L (p, 3) | sh_media_LDLO_L (p, 0);\n+  return (__builtin_sh_media_LDHI_L ((char *)p + 3)\n+\t  | __builtin_sh_media_LDLO_L (p));\n #else\n-  return sh_media_LDLO_L (p, 3) | sh_media_LDHI_L (p, 0);\n+  return (__builtin_sh_media_LDLO_L ((char *)p + 3)\n+\t  | __builtin_sh_media_LDHI_L (p));\n #endif\n }\n \n@@ -927,9 +864,11 @@ long long\n sh_media_unaligned_LD_Q (void *p)\n {\n #if __LITTLE_ENDIAN__\n-  return sh_media_LDHI_Q (p, 7) | sh_media_LDLO_Q (p, 0);\n+  return (__builtin_sh_media_LDHI_Q ((char *)p + 7)\n+\t  | __builtin_sh_media_LDLO_Q (p));\n #else\n-  return sh_media_LDLO_Q (p, 7) | sh_media_LDHI_Q (p, 0);\n+  return (__builtin_sh_media_LDLO_Q ((char *)p + 7)\n+\t  | __builtin_sh_media_LDHI_Q (p));\n #endif\n }\n \n@@ -947,16 +886,19 @@ sh_media_unaligned_ST_W (void *p, unsigned int k)\n #endif\n }\n \n+/* We don't use the sh_media_ST* functions here because that turned out\n+   to impede constant propagation of the offsets into the ldhi / ldlo\n+   instructions.  */\n __inline__ static\n void\n sh_media_unaligned_ST_L (void *p, unsigned int k)\n {\n #if __LITTLE_ENDIAN__\n-  sh_media_STHI_L (p, 3, k);\n-  sh_media_STLO_L (p, 0, k);\n+  __builtin_sh_media_STHI_L (p + 3, k);\n+  __builtin_sh_media_STLO_L (p, k);\n #else\n-  sh_media_STLO_L (p, 3, k);\n-  sh_media_STHI_L (p, 0, k);\n+  __builtin_sh_media_STLO_L (p + 3, k);\n+  __builtin_sh_media_STHI_L (p, k);\n #endif\n }\n \n@@ -965,11 +907,11 @@ void\n sh_media_unaligned_ST_Q (void *p, unsigned long long k)\n {\n #if __LITTLE_ENDIAN__\n-  sh_media_STHI_Q (p, 7, k);\n-  sh_media_STLO_Q (p, 0, k);\n+  __builtin_sh_media_STHI_Q (p + 7, k);\n+  __builtin_sh_media_STLO_Q (p, k);\n #else\n-  sh_media_STLO_Q (p, 7, k);\n-  sh_media_STHI_Q (p, 0, k);\n+  __builtin_sh_media_STLO_Q (p + 7, k);\n+  __builtin_sh_media_STHI_Q (p, k);\n #endif\n }\n "}, {"sha": "52d879cdd53acb45a1d365ed7de0b71bc2befbbe", "filename": "gcc/doc/invoke.texi", "status": "modified", "additions": 110, "deletions": 1, "changes": 111, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fdoc%2Finvoke.texi", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Fdoc%2Finvoke.texi", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fdoc%2Finvoke.texi?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -660,7 +660,10 @@ See RS/6000 and PowerPC Options.\n -mb  -ml  -mdalign  -mrelax @gol\n -mbigtable  -mfmovd  -mhitachi -mrenesas -mno-renesas -mnomacsave @gol\n -mieee  -misize  -mpadstruct  -mspace @gol\n--mprefergot  -musermode}\n+-mprefergot  -musermode -multcost=@var{number} -mdiv=@var{strategy} @gol\n+-mdivsi3_libfunc=@var{name}  @gol\n+-madjust-unroll -mindexed-addressing -mgettrcost=@var{number} -mpt-fixed @gol\n+ -minvalid-symbols}\n \n @emph{SPARC Options}\n @gccoptlist{-mcpu=@var{cpu-type} @gol\n@@ -11466,6 +11469,11 @@ Mark the @code{MAC} register as call-clobbered, even if\n @item -mieee\n @opindex mieee\n Increase IEEE-compliance of floating-point code.\n+At the moment, this is equivalent to @option{-fno-finite-math-only}.\n+When generating 16 bit SH opcodes, getting IEEE-conforming results for\n+comparisons of NANs / infinities incurs extra overhead in every\n+floating point comparison, therefore the default is set to\n+@option{-ffinite-math-only}.\n \n @item -misize\n @opindex misize\n@@ -11491,6 +11499,107 @@ Generate a library function call to invalidate instruction cache\n entries, after fixing up a trampoline.  This library function call\n doesn't assume it can write to the whole memory address space.  This\n is the default when the target is @code{sh-*-linux*}.\n+\n+@item -multcost=@var{number}\n+@opindex multcost=@var{number}\n+Set the cost to assume for a multiply insn.\n+\n+@item -mdiv=@var{strategy}\n+@opindex mdiv=@var{strategy}\n+Set the division strategy to use for SHmedia code.  @var{strategy} must be\n+one of: call, call2, fp, inv, inv:minlat, inv20u, inv20l, inv:call,\n+inv:call2, inv:fp .\n+\"fp\" performs the operation in floating point.  This has a very high latency,\n+but needs only a few instructions, so it might be a good choice if\n+your code has enough easily esploitable ILP to allow the compiler to\n+schedule the floating point instructions together with other instructions.\n+Division by zero causes a floating point exception.\n+\"inv\" uses integer operations to calculate the inverse of the divisor,\n+and then multiplies the divident with the inverse.  This strategy allows\n+cse and hoisting of the inverse calculation.  Division by zero calculates\n+an unspecified result, but does not trap.\n+\"inv:minlat\" is a variant of \"inv\" where if no cse / hoisting opportunities\n+have been found, or if the entire operation has been hoisted to the same\n+place, the last stages of the inverse calculation are intertwined with the\n+final multiply to reduce the overall latency, at the expense of using a few\n+more instructions, and thus offering fewer scheduling opportunities with\n+other code.\n+\"call\" calls a library function that usually implements the inv:minlat\n+strategy.\n+This gives high code density for m5-*media-nofpu compilations.\n+\"call2\" uses a different entry point of the same library function, where it\n+assumes that a pointer to a lookup table has already been set up, which\n+exposes the pointer load to cse / code hoisting optimizations.\n+\"inv:call\", \"inv:call2\" and \"inv:fp\" all use the \"inv\" algorithm for initial\n+code generation, but if the code stays unoptimized, revert to the \"call\",\n+\"call2\", or \"fp\" strategies, resspectively.  Note that the\n+potentially-trapping side effect of division by zero is carried by a\n+separate instruction, so it is possible that all the integer instructions\n+are hoisted out, but the marker for the side effect stays where it is.\n+A recombination to fp operations or a call is not possible in that case.\n+\"inv20u\" and \"inv20l\" are variants of the \"inv:minlat\" strategy.  In the case\n+that the inverse calculation was nor separated from the multiply, they speed\n+up division where the dividend fits into 20 bits (plus sign where applicable),\n+by inserting a test to skip a number of operations in this case; this test\n+slows down the case of larger divdends.  inv20u assumes the case of a such\n+a small dividend to be unlikely, and inv20l assumes it to be likely.\n+\n+@item -mdivsi3_libfunc=@var{name}\n+@opindex mdivsi3_libfunc=@var{name}\n+Set the name of the library function used for 32 bit signed division to\n+@var{name}.  This only affect the name used in the call and inv:call\n+division strategies, and the compiler will still expect the same\n+sets of input/output/clobbered registers as if this option was not present.\n+\n+@item -madjust-unroll\n+@opindex madjust-unroll\n+Throttle unrolling to avoid thrashing target registers.\n+This option only has an effect if the gcc code base supports the\n+TARGET_ADJUST_UNROLL_MAX target hook.\n+\n+@item -mindexed-addressing\n+@opindex mindexed-addressing\n+Enable the use of the indexed addressing mode for SHmedia32/SHcompact.\n+This is only safe if the hardware and/or OS implement 32 bit wrap-around\n+semantics for the indexed addressing mode.  The architecture allows the\n+implementation of processors with 64 bit MMU, which the OS could use to\n+get 32 bit addressing, but since no current harware implementation supports\n+this or any other way to make the indexed addressing mode safe to use in\n+the 32 bit ABI, the default is -mno-indexed-addressing.\n+\n+@item -mgettrcost=@var{number}\n+@opindex mgettrcost=@var{number}\n+Set the cost assumed for the gettr instruction to @var{number}.\n+The default is 2 if @option{-mpt-fixed} is in effect, 100 otherwise.\n+\n+@item -mpt-fixed\n+@opindex mpt-fixed\n+Assume pt* instructions won't trap.  This will generally generate better\n+scheduled code, but is unsafe on current hardware.  The current architecture\n+definition says that ptabs and ptrel trap when the target anded with 3 is 3.\n+This has the unintentional effect of making it unsafe to schedule ptabs /\n+ptrel before a branch, or hoist it out of a loop.  For example,\n+__do_global_ctors, a part of libgcc that runs constructors at program\n+startup, calls functions in a list which is delimited by -1.  With the\n+-mpt-fixed option, the ptabs will be done before testing against -1.\n+That means that all the constructors will be run a bit quicker, but when\n+the loop comes to the end of the list, the pprogram crashes because ptabs\n+loads -1 into a target register.  Since this option is unsafe for any\n+hardware implementing the current architecture specification, the default\n+is -mno-pt-fixed.  Unless the user specifies a specific cost with\n+@option{-mgettrcost}, -mno-pt-fixed also implies @option{-mgettrcost=100};\n+this deters register allocation using target registers for storing\n+ordinary integers.\n+\n+@item -minvalid-symbols\n+@opindex minvalid-symbols\n+Assume symbols might be invalid.  Ordinary function symbols generated by\n+the compiler will always be valid to load with movi/shori/ptabs or\n+movi/shori/ptrel, but with assembler and/or linker tricks it is possible\n+to generate symbols that will cause ptabs / ptrel to trap.\n+This option is only meaningful when @option{-mno-pt-fixed} is in effect.\n+It will then prevent cross-basic-block cse, hoisting and most scheduling\n+of symbol loads.  The default is @option{-mno-invalid-symbols}.\n @end table\n \n @node SPARC Options"}, {"sha": "67d948a842524eba468bb6a34597de24c7651abb", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 6, "deletions": 0, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -1,3 +1,9 @@\n+2005-05-06  J\"orn Rennecke <joern.rennecke@st.com>\n+\n+\t* gcc.dg/pr15784-3.c: Add -fno-finite-math-only option.\n+\n+\t* gcc.dg/20021029-1.c: For sh64*-*-*, add -mpt-fixed.\n+\n 2005-05-09  Nathan Sidwell  <nathan@codesourcery.com>\n \n \tPR c++/21427"}, {"sha": "d8dd8c015d5cf6c6a14a161363998b1a3080acf8", "filename": "gcc/testsuite/gcc.dg/20021029-1.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Ftestsuite%2Fgcc.dg%2F20021029-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Ftestsuite%2Fgcc.dg%2F20021029-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2F20021029-1.c?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -2,6 +2,7 @@\n    variables into writable sections.  */\n /* { dg-do compile } */\n /* { dg-options \"-O2 -fpic\" } */\n+/* { dg-options \"-O2 -fpic -mpt-fixed\" { target sh64*-*-* } } */\n /* { dg-final { scan-assembler-not \".data.rel.ro.local\" } } */\n \n int foo (int a)"}, {"sha": "f8a3e5af91939749ab63ea6a8da550963d790771", "filename": "gcc/testsuite/gcc.dg/pr15784-3.c", "status": "modified", "additions": 2, "deletions": 1, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Ftestsuite%2Fgcc.dg%2Fpr15784-3.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/73a4d10bbb438ec06e0ffee7ee11b9ed02891326/gcc%2Ftestsuite%2Fgcc.dg%2Fpr15784-3.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fpr15784-3.c?ref=73a4d10bbb438ec06e0ffee7ee11b9ed02891326", "patch": "@@ -1,5 +1,6 @@\n /* { dg-do compile } */\n-/* { dg-options \"-fdump-tree-generic\" } */\n+/* SH4 without -mieee defaults to -ffinite-math-only.  */\n+/* { dg-options \"-fdump-tree-generic -fno-finite-math-only\" } */\n /* Test for folding abs(x) where appropriate.  */\n #define abs(x) x > 0 ? x : -x\n extern double fabs (double);"}]}