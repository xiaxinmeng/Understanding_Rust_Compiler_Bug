{"sha": "0d0293ace6acfd32edc68f6b9b371661c9b494e4", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MGQwMjkzYWNlNmFjZmQzMmVkYzY4ZjZiOWIzNzE2NjFjOWI0OTRlNA==", "commit": {"author": {"name": "Michael Matz", "email": "matz@suse.de", "date": "2012-04-10T16:09:03Z"}, "committer": {"name": "Michael Matz", "email": "matz@gcc.gnu.org", "date": "2012-04-10T16:09:03Z"}, "message": "tree-vectorizer.h (_loop_vec_info.strided_stores): Rename to grouped_stores.\n\n\t* tree-vectorizer.h (_loop_vec_info.strided_stores): Rename to\n\tgrouped_stores.\n\t(LOOP_VINFO_STRIDED_STORES): Rename to LOOP_VINFO_GROUPED_STORES.\n\t(struce _bb_vec_info.strided_stores): Rename to grouped_stores.\n\t(BB_VINFO_STRIDED_STORES): Rename to BB_VINFO_GROUPED_STORES.\n\t(STMT_VINFO_STRIDED_ACCESS): Rename to STMT_VINFO_GROUPED_ACCESS.\n\t(vect_strided_store_supported): Rename to vect_grouped_store_supported.\n\t(vect_strided_load_supported): Rename to vect_grouped_load_supported.\n\t(vect_transform_strided_load): Rename to vect_transform_grouped_load.\n\t(vect_record_strided_load_vectors): Rename to\n\tvect_record_grouped_load_vectors.\n\t* tree-vect-data-refs.c (vect_update_misalignment_for_peel):\n\tRename use of above macros.\n\t(vect_verify_datarefs_alignment): Ditto.\n\t(vector_alignment_reachable_p): Ditto.\n\t(vect_peeling_hash_get_lowest_cost): Ditto.\n\t(vect_enhance_data_refs_alignment): Ditto.\n\t(vect_analyze_group_access): Ditto and rename stride to groupsize.\n\t(vect_analyze_data_ref_access): Rename \"strided\" to \"grouped\".\n\t(vect_strided_store_supported): Rename to vect_grouped_store_supported.\n\t(vect_strided_load_supported): Rename to vect_grouped_load_supported.\n\t(vect_transform_strided_load): Rename to vect_transform_grouped_load.\n\t(vect_record_strided_load_vectors): Rename to\n\tvect_record_grouped_load_vectors.\n\t* tree-vect-loop.c (new_loop_vec_info): Rename use of above macros.\n\t(destroy_loop_vec_info): Ditto.\n\t(vect_transform_loop): Ditto and rename strided_store to grouped_store.\n\t* tree-vect-slp.c (vect_build_slp_tree): Rename use of above macros.\n\t(vect_analyze_slp): Ditto.\n\t(new_bb_vec_info): Ditto.\n\t(destroy_bb_vec_info): Ditto.\n\t(vect_schedule_slp_instance): Ditto and rename strided_store to\n\tgrouped_store.\n\t* tree-vect-stmts.c (vect_cost_strided_group_size): Rename to\n\tvect_cost_group_size.\n\t(vect_model_store_cost): Rename use of above macros and call\n\tto vect_cost_strided_group_size.\n\t(vect_model_load_cost): Ditto.\n\t(vectorizable_store): Ditto, rename strided_store to grouped_store\n\tand calls to renamed tree-vectorizer.h functions.\n\t(vectorizable_load): Ditto.\n\t(vect_transform_stmt): Rename use of above macros and strided_store\n\tto grouped_store.\n\ntestsuite/\n\t* gcc.dg/vect/vect-outer-1-big-array.c: Adjust.\n\t* gcc.dg/vect/vect-outer-1.c: Adjust.\n\t* gcc.dg/vect/vect-outer-1a-big-array.c: Adjust.\n\t* gcc.dg/vect/vect-outer-1a.c: Adjust.\n\t* gcc.dg/vect/vect-outer-1b-big-array.c: Adjust.\n\t* gcc.dg/vect/vect-outer-1b.c: Adjust.\n\t* gcc.dg/vect/vect-outer-2b.c: Adjust.\n\t* gcc.dg/vect/vect-outer-3b.c: Adjust.\n\nFrom-SVN: r186285", "tree": {"sha": "c1ba5f3475c5b1edde02b5641162698422325689", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/c1ba5f3475c5b1edde02b5641162698422325689"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/0d0293ace6acfd32edc68f6b9b371661c9b494e4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0d0293ace6acfd32edc68f6b9b371661c9b494e4", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0d0293ace6acfd32edc68f6b9b371661c9b494e4", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0d0293ace6acfd32edc68f6b9b371661c9b494e4/comments", "author": {"login": "susematz", "id": 4117296, "node_id": "MDQ6VXNlcjQxMTcyOTY=", "avatar_url": "https://avatars.githubusercontent.com/u/4117296?v=4", "gravatar_id": "", "url": "https://api.github.com/users/susematz", "html_url": "https://github.com/susematz", "followers_url": "https://api.github.com/users/susematz/followers", "following_url": "https://api.github.com/users/susematz/following{/other_user}", "gists_url": "https://api.github.com/users/susematz/gists{/gist_id}", "starred_url": "https://api.github.com/users/susematz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/susematz/subscriptions", "organizations_url": "https://api.github.com/users/susematz/orgs", "repos_url": "https://api.github.com/users/susematz/repos", "events_url": "https://api.github.com/users/susematz/events{/privacy}", "received_events_url": "https://api.github.com/users/susematz/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "1f00098bf3a107ecf463cd31fc1ff50f960e1013", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1f00098bf3a107ecf463cd31fc1ff50f960e1013", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1f00098bf3a107ecf463cd31fc1ff50f960e1013"}], "stats": {"total": 350, "additions": 198, "deletions": 152}, "files": [{"sha": "dfb564c85c8ae2dd1f0938066b9b113c872d749c", "filename": "gcc/ChangeLog", "status": "modified", "additions": 46, "deletions": 0, "changes": 46, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=0d0293ace6acfd32edc68f6b9b371661c9b494e4", "patch": "@@ -1,3 +1,49 @@\n+2010-04-10  Michael Matz  <matz@suse.de>\n+\n+\t* tree-vectorizer.h (_loop_vec_info.strided_stores): Rename to\n+\tgrouped_stores.\n+\t(LOOP_VINFO_STRIDED_STORES): Rename to LOOP_VINFO_GROUPED_STORES.\n+\t(struce _bb_vec_info.strided_stores): Rename to grouped_stores.\n+\t(BB_VINFO_STRIDED_STORES): Rename to BB_VINFO_GROUPED_STORES.\n+\t(STMT_VINFO_STRIDED_ACCESS): Rename to STMT_VINFO_GROUPED_ACCESS.\n+\t(vect_strided_store_supported): Rename to vect_grouped_store_supported.\n+\t(vect_strided_load_supported): Rename to vect_grouped_load_supported.\n+\t(vect_transform_strided_load): Rename to vect_transform_grouped_load.\n+\t(vect_record_strided_load_vectors): Rename to\n+\tvect_record_grouped_load_vectors.\n+\t* tree-vect-data-refs.c (vect_update_misalignment_for_peel):\n+\tRename use of above macros.\n+\t(vect_verify_datarefs_alignment): Ditto.\n+\t(vector_alignment_reachable_p): Ditto.\n+\t(vect_peeling_hash_get_lowest_cost): Ditto.\n+\t(vect_enhance_data_refs_alignment): Ditto.\n+\t(vect_analyze_group_access): Ditto and rename stride to groupsize.\n+\t(vect_analyze_data_ref_access): Rename \"strided\" to \"grouped\".\n+\t(vect_strided_store_supported): Rename to vect_grouped_store_supported.\n+\t(vect_strided_load_supported): Rename to vect_grouped_load_supported.\n+\t(vect_transform_strided_load): Rename to vect_transform_grouped_load.\n+\t(vect_record_strided_load_vectors): Rename to\n+\tvect_record_grouped_load_vectors.\n+\t* tree-vect-loop.c (new_loop_vec_info): Rename use of above macros.\n+\t(destroy_loop_vec_info): Ditto.\n+\t(vect_transform_loop): Ditto and rename strided_store to grouped_store.\n+\t* tree-vect-slp.c (vect_build_slp_tree): Rename use of above macros.\n+\t(vect_analyze_slp): Ditto.\n+\t(new_bb_vec_info): Ditto.\n+\t(destroy_bb_vec_info): Ditto.\n+\t(vect_schedule_slp_instance): Ditto and rename strided_store to\n+\tgrouped_store.\n+\t* tree-vect-stmts.c (vect_cost_strided_group_size): Rename to\n+\tvect_cost_group_size.\n+\t(vect_model_store_cost): Rename use of above macros and call\n+\tto vect_cost_strided_group_size.\n+\t(vect_model_load_cost): Ditto.\n+\t(vectorizable_store): Ditto, rename strided_store to grouped_store\n+\tand calls to renamed tree-vectorizer.h functions.\n+\t(vectorizable_load): Ditto.\n+\t(vect_transform_stmt): Rename use of above macros and strided_store\n+\tto grouped_store.\n+\n 2012-04-10  Jan Hubicka  <jh@suse.cz>\n \n \t* cgraph.h: Remove misledaing comment on ipa-ref.h."}, {"sha": "b896faa7f9526a297a3f86018c3112c9b3885949", "filename": "gcc/testsuite/gcc.dg/vect/vect-outer-1-big-array.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1-big-array.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1-big-array.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1-big-array.c?ref=0d0293ace6acfd32edc68f6b9b371661c9b494e4", "patch": "@@ -22,6 +22,6 @@ foo (){\n }\n \n /* { dg-final { scan-tree-dump-times \"OUTER LOOP VECTORIZED\" 1 \"vect\" { xfail *-*-* } } } */\n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 1 \"vect\" { xfail vect_multiple_sizes } } } */\n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 2 \"vect\" { target vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 1 \"vect\" { xfail vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 2 \"vect\" { target vect_multiple_sizes } } } */\n /* { dg-final { cleanup-tree-dump \"vect\" } } */"}, {"sha": "2abcb1794587d9d2676091e4a9aacd2c72a191c1", "filename": "gcc/testsuite/gcc.dg/vect/vect-outer-1.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1.c?ref=0d0293ace6acfd32edc68f6b9b371661c9b494e4", "patch": "@@ -22,6 +22,6 @@ foo (){\n }\n \n /* { dg-final { scan-tree-dump-times \"OUTER LOOP VECTORIZED\" 1 \"vect\" { xfail *-*-* } } } */\n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 1 \"vect\" { xfail vect_multiple_sizes } } } */\n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 2 \"vect\" { target vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 1 \"vect\" { xfail vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 2 \"vect\" { target vect_multiple_sizes } } } */\n /* { dg-final { cleanup-tree-dump \"vect\" } } */"}, {"sha": "0a53c25484a270d45ca43bd58a0a5bac3bfd131c", "filename": "gcc/testsuite/gcc.dg/vect/vect-outer-1a-big-array.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1a-big-array.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1a-big-array.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1a-big-array.c?ref=0d0293ace6acfd32edc68f6b9b371661c9b494e4", "patch": "@@ -20,6 +20,6 @@ foo (){\n }\n \n /* { dg-final { scan-tree-dump-times \"OUTER LOOP VECTORIZED\" 1 \"vect\" { xfail *-*-* } } } */\n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 1 \"vect\" { xfail vect_multiple_sizes } } } */\n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 2 \"vect\" { target vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 1 \"vect\" { xfail vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 2 \"vect\" { target vect_multiple_sizes } } } */\n /* { dg-final { cleanup-tree-dump \"vect\" } } */"}, {"sha": "acd504c9e0b5142aba1dd8c33b33df1a629b744c", "filename": "gcc/testsuite/gcc.dg/vect/vect-outer-1a.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1a.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1a.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1a.c?ref=0d0293ace6acfd32edc68f6b9b371661c9b494e4", "patch": "@@ -20,6 +20,6 @@ foo (){\n }\n \n /* { dg-final { scan-tree-dump-times \"OUTER LOOP VECTORIZED\" 1 \"vect\" { xfail *-*-* } } } */\n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 1 \"vect\" { xfail vect_multiple_sizes } } } */\n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 2 \"vect\" { target vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 1 \"vect\" { xfail vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 2 \"vect\" { target vect_multiple_sizes } } } */\n /* { dg-final { cleanup-tree-dump \"vect\" } } */"}, {"sha": "551c89fba38ad3d1e6617ba2c214f6c1ab5e9578", "filename": "gcc/testsuite/gcc.dg/vect/vect-outer-1b-big-array.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1b-big-array.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1b-big-array.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1b-big-array.c?ref=0d0293ace6acfd32edc68f6b9b371661c9b494e4", "patch": "@@ -22,6 +22,6 @@ foo (){\n }\n \n /* { dg-final { scan-tree-dump-times \"OUTER LOOP VECTORIZED\" 1 \"vect\" { xfail *-*-* } } } */\n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 1 \"vect\" { xfail vect_multiple_sizes } } } */\n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 2 \"vect\" { target vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 1 \"vect\" { xfail vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 2 \"vect\" { target vect_multiple_sizes } } } */\n /* { dg-final { cleanup-tree-dump \"vect\" } } */"}, {"sha": "c475a5e443e7fab31d04d34765f13772c0109f01", "filename": "gcc/testsuite/gcc.dg/vect/vect-outer-1b.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1b.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1b.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-1b.c?ref=0d0293ace6acfd32edc68f6b9b371661c9b494e4", "patch": "@@ -22,6 +22,6 @@ foo (){\n }\n \n /* { dg-final { scan-tree-dump-times \"OUTER LOOP VECTORIZED\" 1 \"vect\" { xfail *-*-* } } } */\n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 1 \"vect\" { xfail vect_multiple_sizes } } } */\n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 2 \"vect\" { target vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 1 \"vect\" { xfail vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 2 \"vect\" { target vect_multiple_sizes } } } */\n /* { dg-final { cleanup-tree-dump \"vect\" } } */"}, {"sha": "2b3351626ec0821c199fd10bce51ba2af3f1d1c4", "filename": "gcc/testsuite/gcc.dg/vect/vect-outer-2b.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-2b.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-2b.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-2b.c?ref=0d0293ace6acfd32edc68f6b9b371661c9b494e4", "patch": "@@ -37,6 +37,6 @@ int main (void)\n   return 0;\n }\n \n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 1 \"vect\" { xfail vect_multiple_sizes } } } */\n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 2 \"vect\" { target vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 1 \"vect\" { xfail vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 2 \"vect\" { target vect_multiple_sizes } } } */\n /* { dg-final { cleanup-tree-dump \"vect\" } } */"}, {"sha": "4a86af28d8a2b3ecd4ca7b68592a4981a6cb97f3", "filename": "gcc/testsuite/gcc.dg/vect/vect-outer-3b.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-3b.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-3b.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.dg%2Fvect%2Fvect-outer-3b.c?ref=0d0293ace6acfd32edc68f6b9b371661c9b494e4", "patch": "@@ -49,6 +49,6 @@ int main (void)\n }\n \n /* { dg-final { scan-tree-dump-times \"OUTER LOOP VECTORIZED\" 1 \"vect\" { xfail *-*-* } } } */\n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 2 \"vect\" { xfail vect_multiple_sizes } } } */\n-/* { dg-final { scan-tree-dump-times \"strided access in outer loop\" 4 \"vect\" { target vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 2 \"vect\" { xfail vect_multiple_sizes } } } */\n+/* { dg-final { scan-tree-dump-times \"grouped access in outer loop\" 4 \"vect\" { target vect_multiple_sizes } } } */\n /* { dg-final { cleanup-tree-dump \"vect\" } } */"}, {"sha": "4d550a41abab4f89dfb44a35662696423d128b13", "filename": "gcc/tree-vect-data-refs.c", "status": "modified", "additions": 43, "deletions": 43, "changes": 86, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftree-vect-data-refs.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftree-vect-data-refs.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-data-refs.c?ref=0d0293ace6acfd32edc68f6b9b371661c9b494e4", "patch": "@@ -605,7 +605,7 @@ vect_analyze_data_ref_dependence (struct data_dependence_relation *ddr,\n         }\n \n       /* When vectorizing a basic block unknown depnedence can still mean\n-\t strided access.  */\n+\t grouped access.  */\n       if (vect_check_interleaving (dra, drb))\n          return false;\n \n@@ -1000,9 +1000,9 @@ vect_update_misalignment_for_peel (struct data_reference *dr,\n \n  /* For interleaved data accesses the step in the loop must be multiplied by\n      the size of the interleaving group.  */\n-  if (STMT_VINFO_STRIDED_ACCESS (stmt_info))\n+  if (STMT_VINFO_GROUPED_ACCESS (stmt_info))\n     dr_size *= GROUP_SIZE (vinfo_for_stmt (GROUP_FIRST_ELEMENT (stmt_info)));\n-  if (STMT_VINFO_STRIDED_ACCESS (peel_stmt_info))\n+  if (STMT_VINFO_GROUPED_ACCESS (peel_stmt_info))\n     dr_peel_size *= GROUP_SIZE (peel_stmt_info);\n \n   /* It can be assumed that the data refs with the same alignment as dr_peel\n@@ -1062,7 +1062,7 @@ vect_verify_datarefs_alignment (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo)\n \n       /* For interleaving, only the alignment of the first access matters. \n          Skip statements marked as not vectorizable.  */\n-      if ((STMT_VINFO_STRIDED_ACCESS (stmt_info)\n+      if ((STMT_VINFO_GROUPED_ACCESS (stmt_info)\n            && GROUP_FIRST_ELEMENT (stmt_info) != stmt)\n           || !STMT_VINFO_VECTORIZABLE (stmt_info))\n         continue;\n@@ -1103,7 +1103,7 @@ vector_alignment_reachable_p (struct data_reference *dr)\n   stmt_vec_info stmt_info = vinfo_for_stmt (stmt);\n   tree vectype = STMT_VINFO_VECTYPE (stmt_info);\n \n-  if (STMT_VINFO_STRIDED_ACCESS (stmt_info))\n+  if (STMT_VINFO_GROUPED_ACCESS (stmt_info))\n     {\n       /* For interleaved access we peel only if number of iterations in\n \t the prolog loop ({VF - misalignment}), is a multiple of the\n@@ -1288,7 +1288,7 @@ vect_peeling_hash_get_lowest_cost (void **slot, void *data)\n       stmt_info = vinfo_for_stmt (stmt);\n       /* For interleaving, only the alignment of the first access\n          matters.  */\n-      if (STMT_VINFO_STRIDED_ACCESS (stmt_info)\n+      if (STMT_VINFO_GROUPED_ACCESS (stmt_info)\n           && GROUP_FIRST_ELEMENT (stmt_info) != stmt)\n         continue;\n \n@@ -1503,7 +1503,7 @@ vect_enhance_data_refs_alignment (loop_vec_info loop_vinfo)\n \n       /* For interleaving, only the alignment of the first access\n          matters.  */\n-      if (STMT_VINFO_STRIDED_ACCESS (stmt_info)\n+      if (STMT_VINFO_GROUPED_ACCESS (stmt_info)\n           && GROUP_FIRST_ELEMENT (stmt_info) != stmt)\n         continue;\n \n@@ -1745,7 +1745,7 @@ vect_enhance_data_refs_alignment (loop_vec_info loop_vinfo)\n \t     members of the group, therefore we divide the number of iterations\n \t     by the group size.  */\n \t  stmt_info = vinfo_for_stmt (DR_STMT (dr0));\n-\t  if (STMT_VINFO_STRIDED_ACCESS (stmt_info))\n+\t  if (STMT_VINFO_GROUPED_ACCESS (stmt_info))\n \t    npeel /= GROUP_SIZE (stmt_info);\n \n           if (vect_print_dump_info (REPORT_DETAILS))\n@@ -1764,7 +1764,7 @@ vect_enhance_data_refs_alignment (loop_vec_info loop_vinfo)\n \t  stmt_info = vinfo_for_stmt (stmt);\n \t  /* For interleaving, only the alignment of the first access\n             matters.  */\n-\t  if (STMT_VINFO_STRIDED_ACCESS (stmt_info)\n+\t  if (STMT_VINFO_GROUPED_ACCESS (stmt_info)\n \t      && GROUP_FIRST_ELEMENT (stmt_info) != stmt)\n \t    continue;\n \n@@ -1846,7 +1846,7 @@ vect_enhance_data_refs_alignment (loop_vec_info loop_vinfo)\n \t  /* For interleaving, only the alignment of the first access\n \t     matters.  */\n \t  if (aligned_access_p (dr)\n-\t      || (STMT_VINFO_STRIDED_ACCESS (stmt_info)\n+\t      || (STMT_VINFO_GROUPED_ACCESS (stmt_info)\n \t\t  && GROUP_FIRST_ELEMENT (stmt_info) != stmt))\n \t    continue;\n \n@@ -2041,9 +2041,9 @@ vect_analyze_data_refs_alignment (loop_vec_info loop_vinfo,\n }\n \n \n-/* Analyze groups of strided accesses: check that DR belongs to a group of\n-   strided accesses of legal size, step, etc.  Detect gaps, single element\n-   interleaving, and other special cases. Set strided access info.\n+/* Analyze groups of accesses: check that DR belongs to a group of\n+   accesses of legal size, step, etc.  Detect gaps, single element\n+   interleaving, and other special cases. Set grouped access info.\n    Collect groups of strided stores for further use in SLP analysis.  */\n \n static bool\n@@ -2057,16 +2057,16 @@ vect_analyze_group_access (struct data_reference *dr)\n   loop_vec_info loop_vinfo = STMT_VINFO_LOOP_VINFO (stmt_info);\n   bb_vec_info bb_vinfo = STMT_VINFO_BB_VINFO (stmt_info);\n   HOST_WIDE_INT dr_step = TREE_INT_CST_LOW (step);\n-  HOST_WIDE_INT stride, last_accessed_element = 1;\n+  HOST_WIDE_INT groupsize, last_accessed_element = 1;\n   bool slp_impossible = false;\n   struct loop *loop = NULL;\n \n   if (loop_vinfo)\n     loop = LOOP_VINFO_LOOP (loop_vinfo);\n \n-  /* For interleaving, STRIDE is STEP counted in elements, i.e., the size of the\n-     interleaving group (including gaps).  */\n-  stride = dr_step / type_size;\n+  /* For interleaving, GROUPSIZE is STEP counted in elements, i.e., the\n+     size of the interleaving group (including gaps).  */\n+  groupsize = dr_step / type_size;\n \n   /* Not consecutive access is possible only if it is a part of interleaving.  */\n   if (!GROUP_FIRST_ELEMENT (vinfo_for_stmt (stmt)))\n@@ -2078,11 +2078,11 @@ vect_analyze_group_access (struct data_reference *dr)\n \t size.  The size of the group must be a power of 2.  */\n       if (DR_IS_READ (dr)\n \t  && (dr_step % type_size) == 0\n-\t  && stride > 0\n-\t  && exact_log2 (stride) != -1)\n+\t  && groupsize > 0\n+\t  && exact_log2 (groupsize) != -1)\n \t{\n \t  GROUP_FIRST_ELEMENT (vinfo_for_stmt (stmt)) = stmt;\n-\t  GROUP_SIZE (vinfo_for_stmt (stmt)) = stride;\n+\t  GROUP_SIZE (vinfo_for_stmt (stmt)) = groupsize;\n \t  if (vect_print_dump_info (REPORT_DR_DETAILS))\n \t    {\n \t      fprintf (vect_dump, \"Detected single element interleaving \");\n@@ -2239,9 +2239,9 @@ vect_analyze_group_access (struct data_reference *dr)\n             {\n               slp_impossible = true;\n               /* There is a gap after the last load in the group. This gap is a\n-                 difference between the stride and the number of elements. When\n-                 there is no gap, this difference should be 0.  */\n-              GROUP_GAP (vinfo_for_stmt (stmt)) = stride - count;\n+                 difference between the groupsize and the number of elements.\n+\t\t When there is no gap, this difference should be 0.  */\n+              GROUP_GAP (vinfo_for_stmt (stmt)) = groupsize - count;\n             }\n           else\n             {\n@@ -2265,27 +2265,27 @@ vect_analyze_group_access (struct data_reference *dr)\n           return false;\n         }\n \n-      if (stride == 0)\n-        stride = count;\n+      if (groupsize == 0)\n+        groupsize = count;\n \n-      GROUP_SIZE (vinfo_for_stmt (stmt)) = stride;\n+      GROUP_SIZE (vinfo_for_stmt (stmt)) = groupsize;\n       if (vect_print_dump_info (REPORT_DETAILS))\n-        fprintf (vect_dump, \"Detected interleaving of size %d\", (int)stride);\n+        fprintf (vect_dump, \"Detected interleaving of size %d\", (int)groupsize);\n \n       /* SLP: create an SLP data structure for every interleaving group of\n \t stores for further analysis in vect_analyse_slp.  */\n       if (DR_IS_WRITE (dr) && !slp_impossible)\n         {\n           if (loop_vinfo)\n-            VEC_safe_push (gimple, heap, LOOP_VINFO_STRIDED_STORES (loop_vinfo),\n+            VEC_safe_push (gimple, heap, LOOP_VINFO_GROUPED_STORES (loop_vinfo),\n                            stmt);\n           if (bb_vinfo)\n-            VEC_safe_push (gimple, heap, BB_VINFO_STRIDED_STORES (bb_vinfo),\n+            VEC_safe_push (gimple, heap, BB_VINFO_GROUPED_STORES (bb_vinfo),\n                            stmt);\n         }\n \n       /* There is a gap in the end of the group.  */\n-      if (stride - last_accessed_element > 0 && loop_vinfo)\n+      if (groupsize - last_accessed_element > 0 && loop_vinfo)\n \t{\n \t  if (vect_print_dump_info (REPORT_DETAILS))\n \t    fprintf (vect_dump, \"Data access with gaps requires scalar \"\n@@ -2307,7 +2307,7 @@ vect_analyze_group_access (struct data_reference *dr)\n \n /* Analyze the access pattern of the data-reference DR.\n    In case of non-consecutive accesses call vect_analyze_group_access() to\n-   analyze groups of strided accesses.  */\n+   analyze groups of accesses.  */\n \n static bool\n vect_analyze_data_ref_access (struct data_reference *dr)\n@@ -2372,7 +2372,7 @@ vect_analyze_data_ref_access (struct data_reference *dr)\n   if (loop && nested_in_vect_loop_p (loop, stmt))\n     {\n       if (vect_print_dump_info (REPORT_ALIGNMENT))\n-\tfprintf (vect_dump, \"strided access in outer loop.\");\n+\tfprintf (vect_dump, \"grouped access in outer loop.\");\n       return false;\n     }\n \n@@ -3792,21 +3792,21 @@ vect_create_destination_var (tree scalar_dest, tree vectype)\n   return vec_dest;\n }\n \n-/* Function vect_strided_store_supported.\n+/* Function vect_grouped_store_supported.\n \n    Returns TRUE if interleave high and interleave low permutations\n    are supported, and FALSE otherwise.  */\n \n bool\n-vect_strided_store_supported (tree vectype, unsigned HOST_WIDE_INT count)\n+vect_grouped_store_supported (tree vectype, unsigned HOST_WIDE_INT count)\n {\n   enum machine_mode mode = TYPE_MODE (vectype);\n \n   /* vect_permute_store_chain requires the group size to be a power of two.  */\n   if (exact_log2 (count) == -1)\n     {\n       if (vect_print_dump_info (REPORT_DETAILS))\n-\tfprintf (vect_dump, \"the size of the group of strided accesses\"\n+\tfprintf (vect_dump, \"the size of the group of accesses\"\n \t\t \" is not a power of 2\");\n       return false;\n     }\n@@ -4243,21 +4243,21 @@ vect_setup_realignment (gimple stmt, gimple_stmt_iterator *gsi,\n }\n \n \n-/* Function vect_strided_load_supported.\n+/* Function vect_grouped_load_supported.\n \n    Returns TRUE if even and odd permutations are supported,\n    and FALSE otherwise.  */\n \n bool\n-vect_strided_load_supported (tree vectype, unsigned HOST_WIDE_INT count)\n+vect_grouped_load_supported (tree vectype, unsigned HOST_WIDE_INT count)\n {\n   enum machine_mode mode = TYPE_MODE (vectype);\n \n   /* vect_permute_load_chain requires the group size to be a power of two.  */\n   if (exact_log2 (count) == -1)\n     {\n       if (vect_print_dump_info (REPORT_DETAILS))\n-\tfprintf (vect_dump, \"the size of the group of strided accesses\"\n+\tfprintf (vect_dump, \"the size of the group of accesses\"\n \t\t \" is not a power of 2\");\n       return false;\n     }\n@@ -4442,15 +4442,15 @@ vect_permute_load_chain (VEC(tree,heap) *dr_chain,\n }\n \n \n-/* Function vect_transform_strided_load.\n+/* Function vect_transform_grouped_load.\n \n    Given a chain of input interleaved data-refs (in DR_CHAIN), build statements\n    to perform their permutation and ascribe the result vectorized statements to\n    the scalar statements.\n */\n \n void\n-vect_transform_strided_load (gimple stmt, VEC(tree,heap) *dr_chain, int size,\n+vect_transform_grouped_load (gimple stmt, VEC(tree,heap) *dr_chain, int size,\n \t\t\t     gimple_stmt_iterator *gsi)\n {\n   VEC(tree,heap) *result_chain = NULL;\n@@ -4460,16 +4460,16 @@ vect_transform_strided_load (gimple stmt, VEC(tree,heap) *dr_chain, int size,\n      vectors, that are ready for vector computation.  */\n   result_chain = VEC_alloc (tree, heap, size);\n   vect_permute_load_chain (dr_chain, size, stmt, gsi, &result_chain);\n-  vect_record_strided_load_vectors (stmt, result_chain);\n+  vect_record_grouped_load_vectors (stmt, result_chain);\n   VEC_free (tree, heap, result_chain);\n }\n \n-/* RESULT_CHAIN contains the output of a group of strided loads that were\n+/* RESULT_CHAIN contains the output of a group of grouped loads that were\n    generated as part of the vectorization of STMT.  Assign the statement\n    for each vector to the associated scalar statement.  */\n \n void\n-vect_record_strided_load_vectors (gimple stmt, VEC(tree,heap) *result_chain)\n+vect_record_grouped_load_vectors (gimple stmt, VEC(tree,heap) *result_chain)\n {\n   gimple first_stmt = GROUP_FIRST_ELEMENT (vinfo_for_stmt (stmt));\n   gimple next_stmt, new_stmt;"}, {"sha": "91a982957595d7eb35347ce1a30600ea98e0324d", "filename": "gcc/tree-vect-loop.c", "status": "modified", "additions": 6, "deletions": 6, "changes": 12, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftree-vect-loop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftree-vect-loop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-loop.c?ref=0d0293ace6acfd32edc68f6b9b371661c9b494e4", "patch": "@@ -847,7 +847,7 @@ new_loop_vec_info (struct loop *loop)\n   LOOP_VINFO_MAY_ALIAS_DDRS (res) =\n     VEC_alloc (ddr_p, heap,\n                PARAM_VALUE (PARAM_VECT_MAX_VERSION_FOR_ALIAS_CHECKS));\n-  LOOP_VINFO_STRIDED_STORES (res) = VEC_alloc (gimple, heap, 10);\n+  LOOP_VINFO_GROUPED_STORES (res) = VEC_alloc (gimple, heap, 10);\n   LOOP_VINFO_REDUCTIONS (res) = VEC_alloc (gimple, heap, 10);\n   LOOP_VINFO_REDUCTION_CHAINS (res) = VEC_alloc (gimple, heap, 10);\n   LOOP_VINFO_SLP_INSTANCES (res) = VEC_alloc (slp_instance, heap, 10);\n@@ -923,7 +923,7 @@ destroy_loop_vec_info (loop_vec_info loop_vinfo, bool clean_stmts)\n     vect_free_slp_instance (instance);\n \n   VEC_free (slp_instance, heap, LOOP_VINFO_SLP_INSTANCES (loop_vinfo));\n-  VEC_free (gimple, heap, LOOP_VINFO_STRIDED_STORES (loop_vinfo));\n+  VEC_free (gimple, heap, LOOP_VINFO_GROUPED_STORES (loop_vinfo));\n   VEC_free (gimple, heap, LOOP_VINFO_REDUCTIONS (loop_vinfo));\n   VEC_free (gimple, heap, LOOP_VINFO_REDUCTION_CHAINS (loop_vinfo));\n \n@@ -5221,7 +5221,7 @@ vect_transform_loop (loop_vec_info loop_vinfo)\n   int i;\n   tree ratio = NULL;\n   int vectorization_factor = LOOP_VINFO_VECT_FACTOR (loop_vinfo);\n-  bool strided_store;\n+  bool grouped_store;\n   bool slp_scheduled = false;\n   unsigned int nunits;\n   tree cond_expr = NULL_TREE;\n@@ -5460,11 +5460,11 @@ vect_transform_loop (loop_vec_info loop_vinfo)\n \t  if (vect_print_dump_info (REPORT_DETAILS))\n \t    fprintf (vect_dump, \"transform statement.\");\n \n-\t  strided_store = false;\n-\t  is_store = vect_transform_stmt (stmt, &si, &strided_store, NULL, NULL);\n+\t  grouped_store = false;\n+\t  is_store = vect_transform_stmt (stmt, &si, &grouped_store, NULL, NULL);\n           if (is_store)\n             {\n-\t      if (STMT_VINFO_STRIDED_ACCESS (stmt_info))\n+\t      if (STMT_VINFO_GROUPED_ACCESS (stmt_info))\n \t\t{\n \t\t  /* Interleaving. If IS_STORE is TRUE, the vectorization of the\n \t\t     interleaving chain was completed - free all the stores in"}, {"sha": "e189c5071f06f775f0c16578cfd753c4ceb31581", "filename": "gcc/tree-vect-slp.c", "status": "modified", "additions": 25, "deletions": 25, "changes": 50, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftree-vect-slp.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftree-vect-slp.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-slp.c?ref=0d0293ace6acfd32edc68f6b9b371661c9b494e4", "patch": "@@ -651,7 +651,7 @@ vect_build_slp_tree (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo,\n \t\t  || rhs_code != REALPART_EXPR)\n \t      && (first_stmt_code != REALPART_EXPR\n \t\t  || rhs_code != IMAGPART_EXPR)\n-              && !(STMT_VINFO_STRIDED_ACCESS (vinfo_for_stmt (stmt))\n+              && !(STMT_VINFO_GROUPED_ACCESS (vinfo_for_stmt (stmt))\n                    && (first_stmt_code == ARRAY_REF\n                        || first_stmt_code == INDIRECT_REF\n                        || first_stmt_code == COMPONENT_REF\n@@ -704,8 +704,8 @@ vect_build_slp_tree (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo,\n \t    }\n \t}\n \n-      /* Strided store or load.  */\n-      if (STMT_VINFO_STRIDED_ACCESS (vinfo_for_stmt (stmt)))\n+      /* Grouped store or load.  */\n+      if (STMT_VINFO_GROUPED_ACCESS (vinfo_for_stmt (stmt)))\n \t{\n \t  if (REFERENCE_CLASS_P (lhs))\n \t    {\n@@ -729,7 +729,7 @@ vect_build_slp_tree (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo,\n                 {\n                   if (vect_print_dump_info (REPORT_SLP))\n                     {\n-                      fprintf (vect_dump, \"Build SLP failed: strided \"\n+                      fprintf (vect_dump, \"Build SLP failed: grouped \"\n                                           \"loads have gaps \");\n                       print_gimple_stmt (vect_dump, stmt, 0, TDF_SLIM);\n                     }\n@@ -815,19 +815,19 @@ vect_build_slp_tree (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo,\n               stop_recursion = true;\n              continue;\n            }\n-        } /* Strided access.  */\n+        } /* Grouped access.  */\n       else\n \t{\n \t  if (TREE_CODE_CLASS (rhs_code) == tcc_reference)\n \t    {\n-\t      /* Not strided load.  */\n+\t      /* Not grouped load.  */\n \t      if (vect_print_dump_info (REPORT_SLP))\n \t\t{\n-\t\t  fprintf (vect_dump, \"Build SLP failed: not strided load \");\n+\t\t  fprintf (vect_dump, \"Build SLP failed: not grouped load \");\n \t\t  print_gimple_stmt (vect_dump, stmt, 0, TDF_SLIM);\n \t\t}\n \n-\t      /* FORNOW: Not strided loads are not supported.  */\n+\t      /* FORNOW: Not grouped loads are not supported.  */\n \t      vect_free_oprnd_info (&oprnds_info);\n \t      return false;\n \t    }\n@@ -884,7 +884,7 @@ vect_build_slp_tree (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo,\n   *inside_cost += SLP_TREE_INSIDE_OF_LOOP_COST (*node);\n   *outside_cost += SLP_TREE_OUTSIDE_OF_LOOP_COST (*node);\n \n-  /* Strided loads were reached - stop the recursion.  */\n+  /* Grouped loads were reached - stop the recursion.  */\n   if (stop_recursion)\n     {\n       VEC_safe_push (slp_tree, heap, *loads, *node);\n@@ -1109,7 +1109,7 @@ vect_slp_rearrange_stmts (slp_tree node, unsigned int group_size,\n \n /* Check if the required load permutation is supported.\n    LOAD_PERMUTATION contains a list of indices of the loads.\n-   In SLP this permutation is relative to the order of strided stores that are\n+   In SLP this permutation is relative to the order of grouped stores that are\n    the base of the SLP instance.  */\n \n static bool\n@@ -1138,7 +1138,7 @@ vect_supported_load_permutation_p (slp_instance slp_instn, int group_size,\n \n   /* In case of reduction every load permutation is allowed, since the order\n      of the reduction statements is not important (as opposed to the case of\n-     strided stores).  The only condition we need to check is that all the\n+     grouped stores).  The only condition we need to check is that all the\n      load nodes are of the same size and have the same permutation (and then\n      rearrange all the nodes of the SLP instance according to this \n      permutation).  */\n@@ -1444,7 +1444,7 @@ vect_find_last_store_in_slp_instance (slp_instance instance)\n }\n \n \n-/* Analyze an SLP instance starting from a group of strided stores.  Call\n+/* Analyze an SLP instance starting from a group of grouped stores.  Call\n    vect_build_slp_tree to build a tree of packed stmts if possible.\n    Return FALSE if it's impossible to SLP any stmt in the loop.  */\n \n@@ -1517,7 +1517,7 @@ vect_analyze_slp_instance (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo,\n       return false;\n     }\n \n-  /* Create a node (a root of the SLP tree) for the packed strided stores.  */\n+  /* Create a node (a root of the SLP tree) for the packed grouped stores.  */\n   scalar_stmts = VEC_alloc (gimple, heap, group_size);\n   next = stmt;\n   if (GROUP_FIRST_ELEMENT (vinfo_for_stmt (stmt)))\n@@ -1635,7 +1635,7 @@ bool\n vect_analyze_slp (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo)\n {\n   unsigned int i;\n-  VEC (gimple, heap) *strided_stores, *reductions = NULL, *reduc_chains = NULL;\n+  VEC (gimple, heap) *grouped_stores, *reductions = NULL, *reduc_chains = NULL;\n   gimple first_element;\n   bool ok = false;\n \n@@ -1644,15 +1644,15 @@ vect_analyze_slp (loop_vec_info loop_vinfo, bb_vec_info bb_vinfo)\n \n   if (loop_vinfo)\n     {\n-      strided_stores = LOOP_VINFO_STRIDED_STORES (loop_vinfo);\n+      grouped_stores = LOOP_VINFO_GROUPED_STORES (loop_vinfo);\n       reduc_chains = LOOP_VINFO_REDUCTION_CHAINS (loop_vinfo);\n       reductions = LOOP_VINFO_REDUCTIONS (loop_vinfo);\n     }\n   else\n-    strided_stores = BB_VINFO_STRIDED_STORES (bb_vinfo);\n+    grouped_stores = BB_VINFO_GROUPED_STORES (bb_vinfo);\n \n-  /* Find SLP sequences starting from groups of strided stores.  */\n-  FOR_EACH_VEC_ELT (gimple, strided_stores, i, first_element)\n+  /* Find SLP sequences starting from groups of grouped stores.  */\n+  FOR_EACH_VEC_ELT (gimple, grouped_stores, i, first_element)\n     if (vect_analyze_slp_instance (loop_vinfo, bb_vinfo, first_element))\n       ok = true;\n \n@@ -1810,7 +1810,7 @@ new_bb_vec_info (basic_block bb)\n       set_vinfo_for_stmt (stmt, new_stmt_vec_info (stmt, NULL, res));\n     }\n \n-  BB_VINFO_STRIDED_STORES (res) = VEC_alloc (gimple, heap, 10);\n+  BB_VINFO_GROUPED_STORES (res) = VEC_alloc (gimple, heap, 10);\n   BB_VINFO_SLP_INSTANCES (res) = VEC_alloc (slp_instance, heap, 2);\n \n   bb->aux = res;\n@@ -1844,7 +1844,7 @@ destroy_bb_vec_info (bb_vec_info bb_vinfo)\n \n   free_data_refs (BB_VINFO_DATAREFS (bb_vinfo));\n   free_dependence_relations (BB_VINFO_DDRS (bb_vinfo));\n-  VEC_free (gimple, heap, BB_VINFO_STRIDED_STORES (bb_vinfo));\n+  VEC_free (gimple, heap, BB_VINFO_GROUPED_STORES (bb_vinfo));\n   VEC_free (slp_instance, heap, BB_VINFO_SLP_INSTANCES (bb_vinfo));\n   free (bb_vinfo);\n   bb->aux = NULL;\n@@ -2859,7 +2859,7 @@ vect_schedule_slp_instance (slp_tree node, slp_instance instance,\n                             unsigned int vectorization_factor)\n {\n   gimple stmt;\n-  bool strided_store, is_store;\n+  bool grouped_store, is_store;\n   gimple_stmt_iterator si;\n   stmt_vec_info stmt_info;\n   unsigned int vec_stmts_size, nunits, group_size;\n@@ -2919,7 +2919,7 @@ vect_schedule_slp_instance (slp_tree node, slp_instance instance,\n \n   /* Loads should be inserted before the first load.  */\n   if (SLP_INSTANCE_FIRST_LOAD_STMT (instance)\n-      && STMT_VINFO_STRIDED_ACCESS (stmt_info)\n+      && STMT_VINFO_GROUPED_ACCESS (stmt_info)\n       && !REFERENCE_CLASS_P (gimple_get_lhs (stmt))\n       && SLP_INSTANCE_LOAD_PERMUTATION (instance))\n     si = gsi_for_stmt (SLP_INSTANCE_FIRST_LOAD_STMT (instance));\n@@ -2929,7 +2929,7 @@ vect_schedule_slp_instance (slp_tree node, slp_instance instance,\n     si = gsi_for_stmt (stmt);\n \n   /* Stores should be inserted just before the last store.  */\n-  if (STMT_VINFO_STRIDED_ACCESS (stmt_info)\n+  if (STMT_VINFO_GROUPED_ACCESS (stmt_info)\n       && REFERENCE_CLASS_P (gimple_get_lhs (stmt)))\n     { \n       gimple last_store = vect_find_last_store_in_slp_instance (instance);\n@@ -2941,14 +2941,14 @@ vect_schedule_slp_instance (slp_tree node, slp_instance instance,\n   /* Mark the first element of the reduction chain as reduction to properly\n      transform the node.  In the analysis phase only the last element of the\n      chain is marked as reduction.  */\n-  if (GROUP_FIRST_ELEMENT (stmt_info) && !STMT_VINFO_STRIDED_ACCESS (stmt_info)\n+  if (GROUP_FIRST_ELEMENT (stmt_info) && !STMT_VINFO_GROUPED_ACCESS (stmt_info)\n       && GROUP_FIRST_ELEMENT (stmt_info) == stmt)\n     {\n       STMT_VINFO_DEF_TYPE (stmt_info) = vect_reduction_def;\n       STMT_VINFO_TYPE (stmt_info) = reduc_vec_info_type;\n     }\n \n-  is_store = vect_transform_stmt (stmt, &si, &strided_store, node, instance);\n+  is_store = vect_transform_stmt (stmt, &si, &grouped_store, node, instance);\n   return is_store;\n }\n "}, {"sha": "968e4ed1cd730df9a6dc705ac492239ed8b22f51", "filename": "gcc/tree-vect-stmts.c", "status": "modified", "additions": 50, "deletions": 50, "changes": 100, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftree-vect-stmts.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftree-vect-stmts.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vect-stmts.c?ref=0d0293ace6acfd32edc68f6b9b371661c9b494e4", "patch": "@@ -851,14 +851,14 @@ vect_model_promotion_demotion_cost (stmt_vec_info stmt_info,\n   stmt_vinfo_set_outside_of_loop_cost (stmt_info, NULL, outside_cost);\n }\n \n-/* Function vect_cost_strided_group_size\n+/* Function vect_cost_group_size\n \n-   For strided load or store, return the group_size only if it is the first\n+   For grouped load or store, return the group_size only if it is the first\n    load or store of a group, else return 1.  This ensures that group size is\n    only returned once per group.  */\n \n static int\n-vect_cost_strided_group_size (stmt_vec_info stmt_info)\n+vect_cost_group_size (stmt_vec_info stmt_info)\n {\n   gimple first_stmt = GROUP_FIRST_ELEMENT (stmt_info);\n \n@@ -871,8 +871,8 @@ vect_cost_strided_group_size (stmt_vec_info stmt_info)\n \n /* Function vect_model_store_cost\n \n-   Models cost for stores.  In the case of strided accesses, one access\n-   has the overhead of the strided access attributed to it.  */\n+   Models cost for stores.  In the case of grouped accesses, one access\n+   has the overhead of the grouped access attributed to it.  */\n \n void\n vect_model_store_cost (stmt_vec_info stmt_info, int ncopies,\n@@ -891,8 +891,8 @@ vect_model_store_cost (stmt_vec_info stmt_info, int ncopies,\n   if (dt == vect_constant_def || dt == vect_external_def)\n     outside_cost = vect_get_stmt_cost (scalar_to_vec); \n \n-  /* Strided access?  */\n-  if (STMT_VINFO_STRIDED_ACCESS (stmt_info))\n+  /* Grouped access?  */\n+  if (STMT_VINFO_GROUPED_ACCESS (stmt_info))\n     {\n       if (slp_node)\n         {\n@@ -902,20 +902,20 @@ vect_model_store_cost (stmt_vec_info stmt_info, int ncopies,\n       else\n         {\n           first_stmt = GROUP_FIRST_ELEMENT (stmt_info);\n-          group_size = vect_cost_strided_group_size (stmt_info);\n+          group_size = vect_cost_group_size (stmt_info);\n         }\n \n       first_dr = STMT_VINFO_DATA_REF (vinfo_for_stmt (first_stmt));\n     }\n-  /* Not a strided access.  */\n+  /* Not a grouped access.  */\n   else\n     {\n       group_size = 1;\n       first_dr = STMT_VINFO_DATA_REF (stmt_info);\n     }\n \n   /* We assume that the cost of a single store-lanes instruction is\n-     equivalent to the cost of GROUP_SIZE separate stores.  If a strided\n+     equivalent to the cost of GROUP_SIZE separate stores.  If a grouped\n      access is instead being provided by a permute-and-store operation,\n      include the cost of the permutes.  */\n   if (!store_lanes_p && group_size > 1)\n@@ -987,8 +987,8 @@ vect_get_store_cost (struct data_reference *dr, int ncopies,\n \n /* Function vect_model_load_cost\n \n-   Models cost for loads.  In the case of strided accesses, the last access\n-   has the overhead of the strided access attributed to it.  Since unaligned\n+   Models cost for loads.  In the case of grouped accesses, the last access\n+   has the overhead of the grouped access attributed to it.  Since unaligned\n    accesses are supported for loads, we also account for the costs of the\n    access scheme chosen.  */\n \n@@ -1005,22 +1005,22 @@ vect_model_load_cost (stmt_vec_info stmt_info, int ncopies, bool load_lanes_p,\n   if (PURE_SLP_STMT (stmt_info))\n     return;\n \n-  /* Strided accesses?  */\n+  /* Grouped accesses?  */\n   first_stmt = GROUP_FIRST_ELEMENT (stmt_info);\n-  if (STMT_VINFO_STRIDED_ACCESS (stmt_info) && first_stmt && !slp_node)\n+  if (STMT_VINFO_GROUPED_ACCESS (stmt_info) && first_stmt && !slp_node)\n     {\n-      group_size = vect_cost_strided_group_size (stmt_info);\n+      group_size = vect_cost_group_size (stmt_info);\n       first_dr = STMT_VINFO_DATA_REF (vinfo_for_stmt (first_stmt));\n     }\n-  /* Not a strided access.  */\n+  /* Not a grouped access.  */\n   else\n     {\n       group_size = 1;\n       first_dr = dr;\n     }\n \n   /* We assume that the cost of a single load-lanes instruction is\n-     equivalent to the cost of GROUP_SIZE separate loads.  If a strided\n+     equivalent to the cost of GROUP_SIZE separate loads.  If a grouped\n      access is instead being provided by a load-and-permute operation,\n      include the cost of the permutes.  */\n   if (!load_lanes_p && group_size > 1)\n@@ -1036,7 +1036,7 @@ vect_model_load_cost (stmt_vec_info stmt_info, int ncopies, bool load_lanes_p,\n \n   /* The loads themselves.  */\n   vect_get_load_cost (first_dr, ncopies,\n-         ((!STMT_VINFO_STRIDED_ACCESS (stmt_info)) || group_size > 1\n+         ((!STMT_VINFO_GROUPED_ACCESS (stmt_info)) || group_size > 1\n           || slp_node),\n          &inside_cost, &outside_cost);\n \n@@ -1109,7 +1109,7 @@ vect_get_load_cost (struct data_reference *dr, int ncopies,\n \n         /* Unaligned software pipeline has a load of an address, an initial\n            load, and possibly a mask operation to \"prime\" the loop.  However,\n-           if this is an access in a group of loads, which provide strided\n+           if this is an access in a group of loads, which provide grouped\n            access, then the above cost should only be considered for one\n            access in the group.  Inside the loop, there is a load op\n            and a realignment op.  */\n@@ -3692,7 +3692,7 @@ vectorizable_store (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n   int ncopies;\n   int j;\n   gimple next_stmt, first_stmt = NULL;\n-  bool strided_store = false;\n+  bool grouped_store = false;\n   bool store_lanes_p = false;\n   unsigned int group_size, i;\n   VEC(tree,heap) *dr_chain = NULL, *oprnds = NULL, *result_chain = NULL;\n@@ -3777,16 +3777,16 @@ vectorizable_store (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n       return false;\n     }\n \n-  if (STMT_VINFO_STRIDED_ACCESS (stmt_info))\n+  if (STMT_VINFO_GROUPED_ACCESS (stmt_info))\n     {\n-      strided_store = true;\n+      grouped_store = true;\n       first_stmt = GROUP_FIRST_ELEMENT (stmt_info);\n       if (!slp && !PURE_SLP_STMT (stmt_info))\n \t{\n \t  group_size = GROUP_SIZE (vinfo_for_stmt (first_stmt));\n \t  if (vect_store_lanes_supported (vectype, group_size))\n \t    store_lanes_p = true;\n-\t  else if (!vect_strided_store_supported (vectype, group_size))\n+\t  else if (!vect_grouped_store_supported (vectype, group_size))\n \t    return false;\n \t}\n \n@@ -3820,7 +3820,7 @@ vectorizable_store (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \n   /** Transform.  **/\n \n-  if (strided_store)\n+  if (grouped_store)\n     {\n       first_dr = STMT_VINFO_DATA_REF (vinfo_for_stmt (first_stmt));\n       group_size = GROUP_SIZE (vinfo_for_stmt (first_stmt));\n@@ -3842,7 +3842,7 @@ vectorizable_store (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \n       if (slp)\n         {\n-          strided_store = false;\n+          grouped_store = false;\n           /* VEC_NUM is the number of vect stmts to be created for this \n              group.  */\n           vec_num = SLP_TREE_NUMBER_OF_VEC_STMTS (slp_node);\n@@ -3887,7 +3887,7 @@ vectorizable_store (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n      vector stmt by a factor VF/nunits.  For more details see documentation in\n      vect_get_vec_def_for_copy_stmt.  */\n \n-  /* In case of interleaving (non-unit strided access):\n+  /* In case of interleaving (non-unit grouped access):\n \n         S1:  &base + 2 = x2\n         S2:  &base = x0\n@@ -3943,7 +3943,7 @@ vectorizable_store (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \t\t used as an input to vect_permute_store_chain(), and OPRNDS as\n \t\t an input to vect_get_vec_def_for_stmt_copy() for the next copy.\n \n-\t\t If the store is not strided, GROUP_SIZE is 1, and DR_CHAIN and\n+\t\t If the store is not grouped, GROUP_SIZE is 1, and DR_CHAIN and\n \t\t OPRNDS are of size 1.  */\n \t      next_stmt = first_stmt;\n \t      for (i = 0; i < group_size; i++)\n@@ -3980,7 +3980,7 @@ vectorizable_store (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \t     DR_CHAIN is then used as an input to vect_permute_store_chain(),\n \t     and OPRNDS as an input to vect_get_vec_def_for_stmt_copy() for the\n \t     next copy.\n-\t     If the store is not strided, GROUP_SIZE is 1, and DR_CHAIN and\n+\t     If the store is not grouped, GROUP_SIZE is 1, and DR_CHAIN and\n \t     OPRNDS are of size 1.  */\n \t  for (i = 0; i < group_size; i++)\n \t    {\n@@ -4018,7 +4018,7 @@ vectorizable_store (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n       else\n \t{\n \t  new_stmt = NULL;\n-\t  if (strided_store)\n+\t  if (grouped_store)\n \t    {\n \t      result_chain = VEC_alloc (tree, heap, group_size);\n \t      /* Permute.  */\n@@ -4038,8 +4038,8 @@ vectorizable_store (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \n \t      if (slp)\n \t\tvec_oprnd = VEC_index (tree, vec_oprnds, i);\n-\t      else if (strided_store)\n-\t\t/* For strided stores vectorized defs are interleaved in\n+\t      else if (grouped_store)\n+\t\t/* For grouped stores vectorized defs are interleaved in\n \t\t   vect_permute_store_chain().  */\n \t\tvec_oprnd = VEC_index (tree, result_chain, i);\n \n@@ -4208,7 +4208,7 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n   tree realignment_token = NULL_TREE;\n   gimple phi = NULL;\n   VEC(tree,heap) *dr_chain = NULL;\n-  bool strided_load = false;\n+  bool grouped_load = false;\n   bool load_lanes_p = false;\n   gimple first_stmt;\n   bool inv_p;\n@@ -4305,9 +4305,9 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n     }\n \n   /* Check if the load is a part of an interleaving chain.  */\n-  if (STMT_VINFO_STRIDED_ACCESS (stmt_info))\n+  if (STMT_VINFO_GROUPED_ACCESS (stmt_info))\n     {\n-      strided_load = true;\n+      grouped_load = true;\n       /* FORNOW */\n       gcc_assert (! nested_in_vect_loop && !STMT_VINFO_GATHER_P (stmt_info));\n \n@@ -4317,14 +4317,14 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \t  group_size = GROUP_SIZE (vinfo_for_stmt (first_stmt));\n \t  if (vect_load_lanes_supported (vectype, group_size))\n \t    load_lanes_p = true;\n-\t  else if (!vect_strided_load_supported (vectype, group_size))\n+\t  else if (!vect_grouped_load_supported (vectype, group_size))\n \t    return false;\n \t}\n     }\n \n   if (negative)\n     {\n-      gcc_assert (!strided_load && !STMT_VINFO_GATHER_P (stmt_info));\n+      gcc_assert (!grouped_load && !STMT_VINFO_GATHER_P (stmt_info));\n       alignment_support_scheme = vect_supportable_dr_alignment (dr, false);\n       if (alignment_support_scheme != dr_aligned\n \t  && alignment_support_scheme != dr_unaligned_supported)\n@@ -4525,7 +4525,7 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n       return true;\n     }\n \n-  if (strided_load)\n+  if (grouped_load)\n     {\n       first_stmt = GROUP_FIRST_ELEMENT (stmt_info);\n       if (slp\n@@ -4545,7 +4545,7 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n       /* VEC_NUM is the number of vect stmts to be created for this group.  */\n       if (slp)\n \t{\n-\t  strided_load = false;\n+\t  grouped_load = false;\n \t  vec_num = SLP_TREE_NUMBER_OF_VEC_STMTS (slp_node);\n           if (SLP_INSTANCE_LOAD_PERMUTATION (slp_node_instance))\n             slp_perm = true;\n@@ -4603,7 +4603,7 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n      information we recorded in RELATED_STMT field is used to vectorize\n      stmt S2.  */\n \n-  /* In case of interleaving (non-unit strided access):\n+  /* In case of interleaving (non-unit grouped access):\n \n      S1:  x2 = &base + 2\n      S2:  x0 = &base\n@@ -4629,7 +4629,7 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n      corresponds to the order of scalar stmts in the interleaving chain - see\n      the documentation of vect_permute_load_chain()).\n      The generation of permutation stmts and recording them in\n-     STMT_VINFO_VEC_STMT is done in vect_transform_strided_load().\n+     STMT_VINFO_VEC_STMT is done in vect_transform_grouped_load().\n \n      In case of both multiple types and interleaving, the vector loads and\n      permutation stmts above are created for every copy.  The result vector\n@@ -4715,7 +4715,7 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n         dataref_ptr = bump_vector_ptr (dataref_ptr, ptr_incr, gsi, stmt,\n \t\t\t\t       TYPE_SIZE_UNIT (aggr_type));\n \n-      if (strided_load || slp_perm)\n+      if (grouped_load || slp_perm)\n \tdr_chain = VEC_alloc (tree, heap, vec_num);\n \n       if (load_lanes_p)\n@@ -4741,7 +4741,7 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \t    }\n \n \t  /* Record the mapping between SSA_NAMEs and statements.  */\n-\t  vect_record_strided_load_vectors (stmt, dr_chain);\n+\t  vect_record_grouped_load_vectors (stmt, dr_chain);\n \t}\n       else\n \t{\n@@ -4896,7 +4896,7 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \t      if (inv_p && !bb_vinfo)\n \t\t{\n \t\t  gimple_stmt_iterator gsi2 = *gsi;\n-\t\t  gcc_assert (!strided_load);\n+\t\t  gcc_assert (!grouped_load);\n \t\t  gsi_next (&gsi2);\n \t\t  new_temp = vect_init_vector (stmt, scalar_dest,\n \t\t\t\t\t       vectype, &gsi2);\n@@ -4912,8 +4912,8 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n \t\t}\n \n \t      /* Collect vector loads and later create their permutation in\n-\t\t vect_transform_strided_load ().  */\n-\t      if (strided_load || slp_perm)\n+\t\t vect_transform_grouped_load ().  */\n+\t      if (grouped_load || slp_perm)\n \t\tVEC_quick_push (tree, dr_chain, new_temp);\n \n \t      /* Store vector loads in the corresponding SLP_NODE.  */\n@@ -4937,10 +4937,10 @@ vectorizable_load (gimple stmt, gimple_stmt_iterator *gsi, gimple *vec_stmt,\n         }\n       else\n         {\n-          if (strided_load)\n+          if (grouped_load)\n   \t    {\n \t      if (!load_lanes_p)\n-\t\tvect_transform_strided_load (stmt, dr_chain, group_size, gsi);\n+\t\tvect_transform_grouped_load (stmt, dr_chain, group_size, gsi);\n \t      *vec_stmt = STMT_VINFO_VEC_STMT (stmt_info);\n \t    }\n           else\n@@ -5494,7 +5494,7 @@ vect_analyze_stmt (gimple stmt, bool *need_to_vectorize, slp_tree node)\n \n bool\n vect_transform_stmt (gimple stmt, gimple_stmt_iterator *gsi,\n-\t\t     bool *strided_store, slp_tree slp_node,\n+\t\t     bool *grouped_store, slp_tree slp_node,\n                      slp_instance slp_node_instance)\n {\n   bool is_store = false;\n@@ -5541,13 +5541,13 @@ vect_transform_stmt (gimple stmt, gimple_stmt_iterator *gsi,\n     case store_vec_info_type:\n       done = vectorizable_store (stmt, gsi, &vec_stmt, slp_node);\n       gcc_assert (done);\n-      if (STMT_VINFO_STRIDED_ACCESS (stmt_info) && !slp_node)\n+      if (STMT_VINFO_GROUPED_ACCESS (stmt_info) && !slp_node)\n \t{\n \t  /* In case of interleaving, the whole chain is vectorized when the\n \t     last store in the chain is reached.  Store stmts before the last\n \t     one are skipped, and there vec_stmt_info shouldn't be freed\n \t     meanwhile.  */\n-\t  *strided_store = true;\n+\t  *grouped_store = true;\n \t  if (STMT_VINFO_VEC_STMT (stmt_info))\n \t    is_store = true;\n \t  }"}, {"sha": "6804fdce3f04db1f60935abc1dd39d6119af887a", "filename": "gcc/tree-vectorizer.h", "status": "modified", "additions": 12, "deletions": 12, "changes": 24, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftree-vectorizer.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0d0293ace6acfd32edc68f6b9b371661c9b494e4/gcc%2Ftree-vectorizer.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree-vectorizer.h?ref=0d0293ace6acfd32edc68f6b9b371661c9b494e4", "patch": "@@ -253,9 +253,9 @@ typedef struct _loop_vec_info {\n \n   /* All interleaving chains of stores in the loop, represented by the first\n      stmt in the chain.  */\n-  VEC(gimple, heap) *strided_stores;\n+  VEC(gimple, heap) *grouped_stores;\n \n-  /* All SLP instances in the loop. This is a subset of the set of STRIDED_STORES\n+  /* All SLP instances in the loop. This is a subset of the set of GROUP_STORES\n      of the loop.  */\n   VEC(slp_instance, heap) *slp_instances;\n \n@@ -273,7 +273,7 @@ typedef struct _loop_vec_info {\n   /* Hash table used to choose the best peeling option.  */\n   htab_t peeling_htab;\n \n-  /* When we have strided data accesses with gaps, we may introduce invalid\n+  /* When we have grouped data accesses with gaps, we may introduce invalid\n      memory accesses.  We peel the last iteration of the loop to prevent\n      this.  */\n   bool peeling_for_gaps;\n@@ -300,7 +300,7 @@ typedef struct _loop_vec_info {\n #define LOOP_VINFO_MAY_MISALIGN_STMTS(L)   (L)->may_misalign_stmts\n #define LOOP_VINFO_LOC(L)                  (L)->loop_line_number\n #define LOOP_VINFO_MAY_ALIAS_DDRS(L)       (L)->may_alias_ddrs\n-#define LOOP_VINFO_STRIDED_STORES(L)       (L)->strided_stores\n+#define LOOP_VINFO_GROUPED_STORES(L)       (L)->grouped_stores\n #define LOOP_VINFO_SLP_INSTANCES(L)        (L)->slp_instances\n #define LOOP_VINFO_SLP_UNROLLING_FACTOR(L) (L)->slp_unrolling_factor\n #define LOOP_VINFO_REDUCTIONS(L)           (L)->reductions\n@@ -338,10 +338,10 @@ typedef struct _bb_vec_info {\n   basic_block bb;\n   /* All interleaving chains of stores in the basic block, represented by the\n      first stmt in the chain.  */\n-  VEC(gimple, heap) *strided_stores;\n+  VEC(gimple, heap) *grouped_stores;\n \n   /* All SLP instances in the basic block. This is a subset of the set of\n-     STRIDED_STORES of the basic block.  */\n+     GROUP_STORES of the basic block.  */\n   VEC(slp_instance, heap) *slp_instances;\n \n   /* All data references in the basic block.  */\n@@ -352,7 +352,7 @@ typedef struct _bb_vec_info {\n } *bb_vec_info;\n \n #define BB_VINFO_BB(B)              (B)->bb\n-#define BB_VINFO_STRIDED_STORES(B)  (B)->strided_stores\n+#define BB_VINFO_GROUPED_STORES(B)  (B)->grouped_stores\n #define BB_VINFO_SLP_INSTANCES(B)   (B)->slp_instances\n #define BB_VINFO_DATAREFS(B)        (B)->datarefs\n #define BB_VINFO_DDRS(B)            (B)->ddrs\n@@ -578,7 +578,7 @@ typedef struct _stmt_vec_info {\n #define STMT_VINFO_GROUP_GAP(S)            (S)->gap\n #define STMT_VINFO_GROUP_SAME_DR_STMT(S)   (S)->same_dr_stmt\n #define STMT_VINFO_GROUP_READ_WRITE_DEPENDENCE(S)  (S)->read_write_dep\n-#define STMT_VINFO_STRIDED_ACCESS(S)      ((S)->first_element != NULL && (S)->data_ref_info)\n+#define STMT_VINFO_GROUPED_ACCESS(S)      ((S)->first_element != NULL && (S)->data_ref_info)\n #define STMT_VINFO_LOOP_PHI_EVOLUTION_PART(S) (S)->loop_phi_evolution_part\n \n #define GROUP_FIRST_ELEMENT(S)          (S)->first_element\n@@ -881,18 +881,18 @@ extern tree vect_create_data_ref_ptr (gimple, tree, struct loop *, tree,\n \t\t\t\t      gimple *, bool, bool *);\n extern tree bump_vector_ptr (tree, gimple, gimple_stmt_iterator *, gimple, tree);\n extern tree vect_create_destination_var (tree, tree);\n-extern bool vect_strided_store_supported (tree, unsigned HOST_WIDE_INT);\n+extern bool vect_grouped_store_supported (tree, unsigned HOST_WIDE_INT);\n extern bool vect_store_lanes_supported (tree, unsigned HOST_WIDE_INT);\n-extern bool vect_strided_load_supported (tree, unsigned HOST_WIDE_INT);\n+extern bool vect_grouped_load_supported (tree, unsigned HOST_WIDE_INT);\n extern bool vect_load_lanes_supported (tree, unsigned HOST_WIDE_INT);\n extern void vect_permute_store_chain (VEC(tree,heap) *,unsigned int, gimple,\n                                     gimple_stmt_iterator *, VEC(tree,heap) **);\n extern tree vect_setup_realignment (gimple, gimple_stmt_iterator *, tree *,\n                                     enum dr_alignment_support, tree,\n                                     struct loop **);\n-extern void vect_transform_strided_load (gimple, VEC(tree,heap) *, int,\n+extern void vect_transform_grouped_load (gimple, VEC(tree,heap) *, int,\n                                          gimple_stmt_iterator *);\n-extern void vect_record_strided_load_vectors (gimple, VEC(tree,heap) *);\n+extern void vect_record_grouped_load_vectors (gimple, VEC(tree,heap) *);\n extern int vect_get_place_in_interleaving_chain (gimple, gimple);\n extern tree vect_get_new_vect_var (tree, enum vect_var_kind, const char *);\n extern tree vect_create_addr_base_for_vector_ref (gimple, gimple_seq *,"}]}