{"sha": "36edd3cc1b6398015a97897f8e3c07896a5921d4", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MzZlZGQzY2MxYjYzOTgwMTVhOTc4OTdmOGUzYzA3ODk2YTU5MjFkNA==", "commit": {"author": {"name": "Bernd Schmidt", "email": "bernds@cygnus.co.uk", "date": "1999-09-04T13:09:56Z"}, "committer": {"name": "Bernd Schmidt", "email": "crux@gcc.gnu.org", "date": "1999-09-04T13:09:56Z"}, "message": "Change memory mangement and constant pool handling for nested functions to match that of normal functions; add init_machine_status mechanism.\n\nFrom-SVN: r29101", "tree": {"sha": "994384faecb0b7ea09763638c0d3e3b6369993d1", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/994384faecb0b7ea09763638c0d3e3b6369993d1"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/36edd3cc1b6398015a97897f8e3c07896a5921d4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/36edd3cc1b6398015a97897f8e3c07896a5921d4", "html_url": "https://github.com/Rust-GCC/gccrs/commit/36edd3cc1b6398015a97897f8e3c07896a5921d4", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/36edd3cc1b6398015a97897f8e3c07896a5921d4/comments", "author": null, "committer": null, "parents": [{"sha": "1b63ada472f5ebb586c756b0d490eae51abb3bea", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/1b63ada472f5ebb586c756b0d490eae51abb3bea", "html_url": "https://github.com/Rust-GCC/gccrs/commit/1b63ada472f5ebb586c756b0d490eae51abb3bea"}], "stats": {"total": 1768, "additions": 354, "deletions": 1414}, "files": [{"sha": "60c82c66a903c0866e0dc75fa936f40343517b1f", "filename": "gcc/ChangeLog", "status": "modified", "additions": 89, "deletions": 0, "changes": 89, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=36edd3cc1b6398015a97897f8e3c07896a5921d4", "patch": "@@ -1,3 +1,92 @@\n+Sat Sep  4 13:11:01 1999  Bernd Schmidt  <bernds@cygnus.co.uk>\n+\n+\tChange obstack memory management and varasm constant pool handling so\n+ \tthat nested functions are treated like any other functions.\n+\t* function.c (init_machine_status): New variable.\n+\t(push_function_context_to): Set contains_functions for the outer\n+\tfunction.  Don't call save_varasm_status.\n+\t(pop_function_context_from): Don't call restore_varasm_status.  Don't\n+\tset current_function_contains_functions.\n+\t(prepare_function_start): Call init_varasm_status rather than\n+\tinit_const_rtx_hash_table.  Call (*init_machine_status) if the pointer\n+\tis non-null.\n+\t* function.h (struct function) Add field varasm.  Delete fields\n+\tinline_obstacks, inl_emit, const_rtx_hash_table, first_pool,\n+\tlast_pool, const_rtx_sym_hash_table, pool_offset, const_double_chain.\n+\t(init_machine_status): Declare.\n+\t(save_varasm_status, restore_varasm_status): Delete declarations.\n+\t(save_tree_status, restore_tree_status): Delete last argument.\n+\t* integrate.c (initialize_for_inline): Lose arg COPY.  Delete copying\n+\tcode.  All callers changed.\n+\t(copy_decl_list, copy_decl_tree, copy_decl_rtls, copy_for_inline,\n+\tsave_constants_in_decl_trees, restore_constants, save_constants,\n+\tsave_for_inline_eh_labelmap, save_for_inline_copying): Delete\n+\tfunctions.\n+\t(inlining): New variable.\n+\t(reg_map, label_map, insn_map, orig_asm_operands_vector,\n+\tcopy_asm_operands_vector, copy_asm_constraints_vector): Delete\n+\tvariables.\n+\t(save_for_inline_nocopy): Don't save constants.\n+\tDon't set inl_emit field in current_function.\n+\t(expand_inline_function): Use emit field, not inl_emit, of the inlined\n+\tfunction.  Set new variable inlining before\n+\tcalling copy_rtx_and_substitute.\n+\t(copy_rtx_and_substitute): In MEM and SYMBOL_REF cases, handle\n+\tconstant pool references if inlining is nonzero.\n+\tDelete ADDRESS and (most of the) CONST cases.\n+\t(output_inline_function): Save and restore current_function/\n+\tcurrent_function_decl.  Delete restore_constants code.  Don't call\n+\tinit_const_rtx_hash_table.\n+\t* output.h (init_const_rtx_hash_table): Don't declare.\n+\t* rtl.h (struct function): Declare.\n+\t(get_pool_constant_for_function, get_pool_mode_for_function): Declare.\n+\t* toplev.c (rest_of_compilation): Don't treat nested functions or\n+\tfunctions containing them specially.  Delete all code to deal with\n+\tsave_for_inline_copying.\n+\t* tree.c (toplev_inline_obstacks, extra_inline_obstacks,\n+\tinline_obstacks): Delete variables.\n+\t(save_tree_status): Lose arg CONTEXT.  All callers changed.\n+\tSimply allocate a new function_maybepermanent_obstack for the new\n+\tfunction, delete all the special cases.\n+\tDon't save inline_obstacks.\n+\t(restore_tree_status): Lose arg CONTEXT.  All callers changed.\n+\tDelete special handling for function_maybepermanent_obstack; simply\n+\tfree it if empty.\n+\tDon't restore inline_obstacks.\n+\t(permanent_allocation):  Delete code that frees inline_obstacks.\n+\t(print_inline_obstack_statistics): Delete function.\n+\t(dump_tree_statistics): Don't call it.\n+\t* varasm.c (struct varasm_status): New.\n+\t(const_rtx_hash_table, const_rtx_sym_hash_table, first_pool,\n+\tlast_pool, pool_offset, const_double_chain): Delete global\n+\tvariables, replace with accessor macros.\n+\t(immed_double_const): Don't walk const_double_chain outside a\n+\tfunction, but don't treat nested functions specially anymore.\n+\t(immed_real_const_1): Likewise.\n+\t(clear_const_double_mem): Don't treat nested functions specially.\n+\t(init_const_rtx_hash_table): Deleted, code moved to init_varasm_status.\n+\t(save_varasm_status, restore_varasm_status): Delete functions.\n+\t(init_varasm_status): New function.\n+\t(force_const_mem): Don't treat nested functions specially.\n+\t(find_pool_constant): Accept new arg F, search for constants in\n+\tthat function's pool rather than the current one.  All callers\n+\tchanged.\n+\t(get_pool_constant_for_function, get_pool_mode_for_function): New\n+\tfunctions.\n+\n+\t* i386.c (init_386_machine_status): New function, mostly from\n+\tclear_386_stack_locals.\n+\t(struct machine_functions): Rename element names to avoid name\n+\tclashes.\n+\t(pic_label_rtx, pic_label_name, i386_stack_locals): New accessor\n+\tmacros, replacing global variables.\n+\t(clear_386_stack_locals, save_386_machine_status,\n+\trestore_386_machine_status): Delete functions.\n+\t(override_options): Initialize init_machine_status.\n+\t* i386.h (INIT_EXPANDERS): Delete macro.\n+\t(save_386_machine_status, restore_386_machine_status,\n+\tclear_386_stack_locals): Delete declarations.\n+\n Sat Sep  4 16:56:28 1999  Michael Hayes  <m.hayes@elec.canterbury.ac.nz>\n \n \t* config/c4x/c4x.md (rptb_init): Renamed from *rptb_init."}, {"sha": "04b79b8d7e8dccc1c21d613bbe2acc7f41aae8cd", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 21, "deletions": 40, "changes": 61, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=36edd3cc1b6398015a97897f8e3c07896a5921d4", "patch": "@@ -168,6 +168,18 @@ enum reg_class const regclass_map[FIRST_PSEUDO_REGISTER] =\n struct rtx_def *ix86_compare_op0 = NULL_RTX;\n struct rtx_def *ix86_compare_op1 = NULL_RTX;\n \n+#define MAX_386_STACK_LOCALS 2\n+\n+/* Define the structure for the machine field in struct function.  */\n+struct machine_function\n+{\n+  rtx stack_locals[(int) MAX_MACHINE_MODE][MAX_386_STACK_LOCALS];\n+};\n+\n+static int pic_label_no = 0;\n+\n+#define ix86_stack_locals (current_function->machine->stack_locals)\n+\n /* which cpu are we scheduling for */\n enum processor_type ix86_cpu;\n \n@@ -235,6 +247,7 @@ static void ix86_dump_ppro_packet PROTO ((FILE *));\n static void ix86_reorder_insn PROTO ((rtx *, rtx *));\n static rtx * ix86_pent_find_pair PROTO ((rtx *, rtx *, enum attr_pent_pair,\n \t\t\t\t\t rtx));\n+static void ix86_init_machine_status PROTO ((struct function *));\n \n struct ix86_address\n {\n@@ -338,6 +351,9 @@ override_options ()\n   target_flags |= processor_target_table[ix86_cpu].target_enable;\n   target_flags &= ~processor_target_table[ix86_cpu].target_disable;\n \n+  /* Arrange to set up i386_stack_locals for all functions.  */\n+  init_machine_status = ix86_init_machine_status;\n+\n   /* Validate registers in register allocation order.  */\n   if (ix86_reg_alloc_order)\n     {\n@@ -4940,58 +4956,23 @@ ix86_expand_strlensi_unroll_1 (out, align_rtx, scratch)\n   emit_label (end_0_label);\n }\n \f\n-#define MAX_386_STACK_LOCALS 2\n-\n-static rtx ix86_stack_locals[(int) MAX_MACHINE_MODE][MAX_386_STACK_LOCALS];\n-\n-/* Define the structure for the machine field in struct function.  */\n-struct machine_function\n-{\n-  rtx ix86_stack_locals[(int) MAX_MACHINE_MODE][MAX_386_STACK_LOCALS];\n-};\n-\n-/* Functions to save and restore ix86_stack_locals.\n-   These will be called, via pointer variables,\n-   from push_function_context and pop_function_context.  */\n-\n-void\n-save_386_machine_status (p)\n-     struct function *p;\n-{\n-  p->machine\n-    = (struct machine_function *) xmalloc (sizeof (struct machine_function));\n-  bcopy ((char *) ix86_stack_locals, (char *) p->machine->ix86_stack_locals,\n-\t sizeof ix86_stack_locals);\n-}\n-\n-void\n-restore_386_machine_status (p)\n-     struct function *p;\n-{\n-  bcopy ((char *) p->machine->ix86_stack_locals, (char *) ix86_stack_locals,\n-\t sizeof ix86_stack_locals);\n-  free (p->machine);\n-  p->machine = NULL;\n-}\n-\n /* Clear stack slot assignments remembered from previous functions.\n    This is called from INIT_EXPANDERS once before RTL is emitted for each\n    function.  */\n \n-void\n-clear_386_stack_locals ()\n+static void\n+ix86_init_machine_status (p)\n+    struct function *p;\n {\n   enum machine_mode mode;\n   int n;\n+  p->machine\n+    = (struct machine_function *) xmalloc (sizeof (struct machine_function));\n \n   for (mode = VOIDmode; (int) mode < (int) MAX_MACHINE_MODE;\n        mode = (enum machine_mode) ((int) mode + 1))\n     for (n = 0; n < MAX_386_STACK_LOCALS; n++)\n       ix86_stack_locals[(int) mode][n] = NULL_RTX;\n-\n-  /* Arrange to save and restore ix86_stack_locals around nested functions.  */\n-  save_machine_status = save_386_machine_status;\n-  restore_machine_status = restore_386_machine_status;\n }\n \n /* Return a MEM corresponding to a stack slot with mode MODE."}, {"sha": "c3efd72c245865b28804c1d51dad05099e254541", "filename": "gcc/config/i386/i386.h", "status": "modified", "additions": 0, "deletions": 10, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Fconfig%2Fi386%2Fi386.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Fconfig%2Fi386%2Fi386.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.h?ref=36edd3cc1b6398015a97897f8e3c07896a5921d4", "patch": "@@ -1603,13 +1603,6 @@ do\t\t\t\t\t\t\t\t\t\\\n   }\t\t\t\t\t\t\t\t\t\\\n while (0)\n \n-/* Initialize data used by insn expanders.  This is called from\n-   init_emit, once for each function, before code is generated.\n-   For 386, clear stack slot assignments remembered from previous\n-   functions. */\n-\n-#define INIT_EXPANDERS clear_386_stack_locals ()\n-\n /* The `FINALIZE_PIC' macro serves as a hook to emit these special\n    codes once the function is being compiled into assembly code, but\n    not before.  (It is not done before, because in the case of\n@@ -2498,9 +2491,6 @@ extern void ix86_split_ashrdi XPARAMS((xrtx *, xrtx));\n extern void ix86_split_lshrdi XPARAMS((xrtx *, xrtx));\n extern void ix86_expand_strlensi_unroll_1 XPARAMS((xrtx, xrtx, xrtx));\n \n-extern void save_386_machine_status XPARAMS((struct function *));\n-extern void restore_386_machine_status XPARAMS((struct function *));\n-extern void clear_386_stack_locals XPARAMS((void));\n extern xrtx assign_386_stack_local XPARAMS((xmode, int));\n extern int ix86_attr_length_default XPARAMS((xrtx));\n "}, {"sha": "6d07ff351cc4ca5c0335e6b679c66ef1e6a6518d", "filename": "gcc/function.c", "status": "modified", "additions": 18, "deletions": 9, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Ffunction.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Ffunction.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffunction.c?ref=36edd3cc1b6398015a97897f8e3c07896a5921d4", "patch": "@@ -117,6 +117,7 @@ static int virtuals_instantiated;\n /* These variables hold pointers to functions to\n    save and restore machine-specific data,\n    in push_function_context and pop_function_context.  */\n+void (*init_machine_status) PROTO((struct function *));\n void (*save_machine_status) PROTO((struct function *));\n void (*restore_machine_status) PROTO((struct function *));\n \n@@ -300,7 +301,15 @@ void\n push_function_context_to (context)\n      tree context;\n {\n-  struct function *p;\n+  struct function *p, *context_data;\n+\n+  if (context)\n+    {\n+      context_data = (context == current_function_decl\n+\t\t      ? current_function\n+\t\t      : find_function_data (context));\n+      context_data->contains_functions = 1;\n+    }\n \n   if (current_function == 0)\n     init_dummy_function_start ();\n@@ -311,8 +320,7 @@ push_function_context_to (context)\n   p->decl = current_function_decl;\n   p->fixup_var_refs_queue = 0;\n \n-  save_tree_status (p, context);\n-  save_varasm_status (p, context);\n+  save_tree_status (p);\n   if (save_lang_status)\n     (*save_lang_status) (p);\n   if (save_machine_status)\n@@ -340,14 +348,11 @@ pop_function_context_from (context)\n   current_function = p;\n   outer_function_chain = p->next;\n \n-  current_function_contains_functions\n-    |= p->inline_obstacks || context == current_function_decl;\n   current_function_decl = p->decl;\n   reg_renumber = 0;\n \n-  restore_tree_status (p, context);\n+  restore_tree_status (p);\n   restore_emit_status (p);\n-  restore_varasm_status (p);\n \n   if (restore_machine_status)\n     (*restore_machine_status) (p);\n@@ -365,7 +370,8 @@ pop_function_context_from (context)\n   virtuals_instantiated = 0;\n }\n \n-void pop_function_context ()\n+void\n+pop_function_context ()\n {\n   pop_function_context_from (current_function_decl);\n }\n@@ -5576,7 +5582,7 @@ prepare_function_start ()\n   /* We haven't done register allocation yet.  */\n   reg_renumber = 0;\n \n-  init_const_rtx_hash_table ();\n+  init_varasm_status (current_function);\n \n   /* Set if a call to setjmp is seen.  */\n   current_function_calls_setjmp = 0;\n@@ -5640,6 +5646,9 @@ prepare_function_start ()\n   inhibit_defer_pop = 0;\n \n   current_function_outgoing_args_size = 0;\n+\n+  if (init_machine_status)\n+    (*init_machine_status) (current_function);\n }\n \n /* Initialize the rtl expansion mechanism so that we can do simple things"}, {"sha": "d34da4010a04fab3e972ed6f89f2f42160d91294", "filename": "gcc/function.h", "status": "modified", "additions": 9, "deletions": 19, "changes": 28, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Ffunction.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Ffunction.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ffunction.h?ref=36edd3cc1b6398015a97897f8e3c07896a5921d4", "patch": "@@ -182,6 +182,7 @@ struct function\n   struct stmt_status *stmt;\n   struct expr_status *expr;\n   struct emit_status *emit;\n+  struct varasm_status *varasm;\n \n   /* For function.c.  */\n \n@@ -415,12 +416,9 @@ struct function\n   struct obstack *expression_obstack;\n   struct obstack *saveable_obstack;\n   struct obstack *rtl_obstack;\n-  struct simple_obstack_stack *inline_obstacks;\n \n-  /* For integrate.c.  We duplicate some of the fields so that\n-     save_for_inline_copying can keep two versions.  */\n+  /* For integrate.c.  */\n   int inlinable;\n-  struct emit_status *inl_emit;\n   /* This is in fact an rtvec.  */\n   void *original_arg_vector;\n   tree original_decl_initial;\n@@ -448,13 +446,6 @@ struct function\n   /* If some insns can be deferred to the delay slots of the epilogue, the\n      delay list for them is recorded here.  */\n   rtx epilogue_delay_list;\n-\n-  /* For varasm.  */\n-  struct constant_descriptor **const_rtx_hash_table;\n-  struct pool_sym **const_rtx_sym_hash_table;\n-  struct pool_constant *first_pool, *last_pool;\n-  int pool_offset;\n-  rtx const_double_chain;\n };\n \n extern struct function *current_function;\n@@ -534,25 +525,24 @@ extern tree *identify_blocks PROTO((tree, rtx));\n /* Return size needed for stack frame based on slots so far allocated.\n    This size counts from zero.  It is not rounded to STACK_BOUNDARY;\n    the caller may have to do that.  */\n-extern HOST_WIDE_INT get_frame_size PROTO((void));\n+extern HOST_WIDE_INT get_frame_size\tPROTO((void));\n /* Likewise, but for a different than the current function.  */\n-extern HOST_WIDE_INT get_func_frame_size PROTO((struct function *));\n+extern HOST_WIDE_INT get_func_frame_size\tPROTO((struct function *));\n \n /* These variables hold pointers to functions to\n    save and restore machine-specific data,\n    in push_function_context and pop_function_context.  */\n-extern void (*save_machine_status) PROTO((struct function *));\n-extern void (*restore_machine_status) PROTO((struct function *));\n+extern void (*init_machine_status)\tPROTO((struct function *));\n+extern void (*save_machine_status)\tPROTO((struct function *));\n+extern void (*restore_machine_status)\tPROTO((struct function *));\n \n /* Likewise, but for language-specific data.  */\n extern void (*save_lang_status)\t\tPROTO((struct function *));\n extern void (*restore_lang_status)\tPROTO((struct function *));\n \n /* Save and restore status information for a nested function.  */\n-extern void save_tree_status\t\tPROTO((struct function *, tree));\n-extern void restore_tree_status\t\tPROTO((struct function *, tree));\n-extern void save_varasm_status\t\tPROTO((struct function *, tree));\n-extern void restore_varasm_status\tPROTO((struct function *));\n+extern void save_tree_status\t\tPROTO((struct function *));\n+extern void restore_tree_status\t\tPROTO((struct function *));\n extern void restore_emit_status\t\tPROTO((struct function *));\n \n extern rtx get_first_block_beg\t\tPROTO((void));"}, {"sha": "ce7d773912f3f8ba8eed8c45a81b8f7ccce608c1", "filename": "gcc/integrate.c", "status": "modified", "additions": 82, "deletions": 1009, "changes": 1091, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Fintegrate.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Fintegrate.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fintegrate.c?ref=36edd3cc1b6398015a97897f8e3c07896a5921d4", "patch": "@@ -60,22 +60,15 @@ extern struct obstack *function_maybepermanent_obstack;\n    : (8 * (8 + list_length (DECL_ARGUMENTS (DECL)))))\n #endif\n \f\n-static rtvec initialize_for_inline\tPROTO((tree, int));\n+static rtvec initialize_for_inline\tPROTO((tree));\n static void adjust_copied_decl_tree\tPROTO((tree));\n-static tree copy_decl_list\t\tPROTO((tree));\n-static tree copy_decl_tree\t\tPROTO((tree));\n-static void copy_decl_rtls\t\tPROTO((tree));\n-static void save_constants\t\tPROTO((rtx *));\n static void note_modified_parmregs\tPROTO((rtx, rtx));\n-static rtx copy_for_inline\t\tPROTO((rtx));\n static void integrate_parm_decls\tPROTO((tree, struct inline_remap *,\n \t\t\t\t\t       rtvec));\n static void integrate_decl_tree\t\tPROTO((tree, int,\n \t\t\t\t\t       struct inline_remap *));\n-static void save_constants_in_decl_trees PROTO ((tree));\n static void subst_constants\t\tPROTO((rtx *, rtx,\n \t\t\t\t\t       struct inline_remap *));\n-static void restore_constants\t\tPROTO((rtx *));\n static void set_block_origin_self\tPROTO((tree));\n static void set_decl_origin_self\tPROTO((tree));\n static void set_block_abstract_flags\tPROTO((tree, int));\n@@ -95,6 +88,11 @@ static tree copy_and_set_decl_abstract_origin PROTO((tree));\n \n int inline_max_insns = 10000;\n \n+/* Used by copy_rtx_and_substitute; this indicates whether the function is\n+   called for the purpose of inlining or some other purpose (i.e. loop\n+   unrolling).  This affects how constant pool references are handled.\n+   This variable contains the FUNCTION_DECL for the inlined function.  */\n+static struct function *inlining = 0;\n \f\n /* Returns the Ith entry in the label_map contained in MAP.  If the\n    Ith entry has not yet been set, return a fresh label.  This function\n@@ -231,63 +229,20 @@ function_cannot_inline_p (fndecl)\n   return 0;\n }\n \f\n-/* Variables used within save_for_inline.  */\n-\n-/* Mapping from old pseudo-register to new pseudo-registers.\n-   The first element of this map is reg_map[FIRST_PSEUDO_REGISTER].\n-   It is allocated in `save_for_inline' and `expand_inline_function',\n-   and deallocated on exit from each of those routines.  */\n-static rtx *reg_map;\n-\n-/* Mapping from old code-labels to new code-labels.\n-   The first element of this map is label_map[min_labelno].\n-   It is allocated in `save_for_inline' and `expand_inline_function',\n-   and deallocated on exit from each of those routines.  */\n-static rtx *label_map;\n-\n-/* Mapping from old insn uid's to copied insns.\n-   It is allocated in `save_for_inline' and `expand_inline_function',\n-   and deallocated on exit from each of those routines.  */\n-static rtx *insn_map;\n-\n /* Map pseudo reg number into the PARM_DECL for the parm living in the reg.\n    Zero for a reg that isn't a parm's home.\n    Only reg numbers less than max_parm_reg are mapped here.  */\n static tree *parmdecl_map;\n \n-/* When an insn is being copied by copy_for_inline,\n-   this is nonzero if we have copied an ASM_OPERANDS.\n-   In that case, it is the original input-operand vector.  */\n-static rtvec orig_asm_operands_vector;\n-\n-/* When an insn is being copied by copy_for_inline,\n-   this is nonzero if we have copied an ASM_OPERANDS.\n-   In that case, it is the copied input-operand vector.  */\n-static rtvec copy_asm_operands_vector;\n-\n-/* Likewise, this is the copied constraints vector.  */\n-static rtvec copy_asm_constraints_vector;\n-\n /* In save_for_inline, nonzero if past the parm-initialization insns.  */\n static int in_nonparm_insns;\n \f\n-/* subroutines passed to duplicate_eh_handlers to map exception labels */\n-\n-static rtx \n-save_for_inline_eh_labelmap (label)\n-     rtx label;\n-{\n-  int index = CODE_LABEL_NUMBER (label);\n-  return label_map[index];\n-}\n-\n-/* Subroutine for `save_for_inline{copying,nocopy}'.  Performs initialization\n+/* Subroutine for `save_for_inline_nocopy'.  Performs initialization\n    needed to save FNDECL's insns and info for future inline expansion.  */\n-   \n+\n static rtvec\n-initialize_for_inline (fndecl, copy)\n+initialize_for_inline (fndecl)\n      tree fndecl;\n-     int copy;\n {\n   int i;\n   rtvec arg_vector;\n@@ -302,7 +257,6 @@ initialize_for_inline (fndecl, copy)\n        parms = TREE_CHAIN (parms), i++)\n     {\n       rtx p = DECL_RTL (parms);\n-      int copied_incoming = 0;\n \n       /* If we have (mem (addressof (mem ...))), use the inner MEM since\n \t otherwise the copy_rtx call below will not unshare the MEM since\n@@ -311,25 +265,6 @@ initialize_for_inline (fndecl, copy)\n \t  && GET_CODE (XEXP (XEXP (p, 0), 0)) == MEM)\n \tp = XEXP (XEXP (p, 0), 0);\n \n-      if (GET_CODE (p) == MEM && copy)\n-\t{\n-\t  /* Copy the rtl so that modifications of the addresses\n-\t     later in compilation won't affect this arg_vector.\n-\t     Virtual register instantiation can screw the address\n-\t     of the rtl.  */\n-\t  rtx new = copy_rtx (p);\n-\n-\t  /* Don't leave the old copy anywhere in this decl.  */\n-\t  if (DECL_RTL (parms) == DECL_INCOMING_RTL (parms)\n-\t      || (GET_CODE (DECL_RTL (parms)) == MEM\n-\t\t  && GET_CODE (DECL_INCOMING_RTL (parms)) == MEM\n-\t\t  && (XEXP (DECL_RTL (parms), 0)\n-\t\t      == XEXP (DECL_INCOMING_RTL (parms), 0))))\n-\t    DECL_INCOMING_RTL (parms) = new, copied_incoming = 1;\n-\n-\t  DECL_RTL (parms) = new;\n-\t}\n-\n       RTVEC_ELT (arg_vector, i) = p;\n \n       if (GET_CODE (p) == REG)\n@@ -348,23 +283,6 @@ initialize_for_inline (fndecl, copy)\n       /* This flag is cleared later\n \t if the function ever modifies the value of the parm.  */\n       TREE_READONLY (parms) = 1;\n-\n-      /* Copy DECL_INCOMING_RTL if not done already.  This can\n-\t happen if DECL_RTL is a reg.  */\n-      if (copy && ! copied_incoming)\n-\t{\n-\t  p = DECL_INCOMING_RTL (parms);\n-\n-\t  /* If we have (mem (addressof (mem ...))), use the inner MEM since\n-\t     otherwise the copy_rtx call below will not unshare the MEM since\n-\t     it shares ADDRESSOF.  */\n-\t  if (GET_CODE (p) == MEM && GET_CODE (XEXP (p, 0)) == ADDRESSOF\n-\t      && GET_CODE (XEXP (XEXP (p, 0), 0)) == MEM)\n-\t    p = XEXP (XEXP (p, 0), 0);\n-\n-\t  if (GET_CODE (p) == MEM)\n-\t    DECL_INCOMING_RTL (parms) = copy_rtx (p);\n-\t}\n     }\n \n   return arg_vector;\n@@ -394,314 +312,6 @@ adjust_copied_decl_tree (block)\n     adjust_copied_decl_tree (subblock);\n }\n \n-/* Make the insns and PARM_DECLs of the current function permanent\n-   and record other information in DECL_SAVED_INSNS to allow inlining\n-   of this function in subsequent calls.\n-\n-   This function is called when we are going to immediately compile\n-   the insns for FNDECL.  The insns in maybepermanent_obstack cannot be\n-   modified by the compilation process, so we copy all of them to\n-   new storage and consider the new insns to be the insn chain to be\n-   compiled.  Our caller (rest_of_compilation) saves the original\n-   DECL_INITIAL and DECL_ARGUMENTS; here we copy them.  */\n-\n-/* ??? The nonlocal_label list should be adjusted also.  However, since\n-   a function that contains a nested function never gets inlined currently,\n-   the nonlocal_label list will always be empty, so we don't worry about\n-   it for now.  */\n-\n-void\n-save_for_inline_copying (fndecl)\n-     tree fndecl;\n-{\n-  rtvec argvec;\n-  rtx new_first_insn, new_last_insn, insn;\n-  int max_labelno, min_labelno, i, len;\n-  int max_reg;\n-  int max_uid;\n-  rtx first_nonparm_insn;\n-  char *new, *new1;\n-  rtx *new_parm_reg_stack_loc;\n-  rtx *new2;\n-  struct emit_status *es\n-    = (struct emit_status *) xmalloc (sizeof (struct emit_status));\n-\n-  /* Make and emit a return-label if we have not already done so. \n-     Do this before recording the bounds on label numbers.  */\n-\n-  if (return_label == 0)\n-    {\n-      return_label = gen_label_rtx ();\n-      emit_label (return_label);\n-    }\n-\n-  *es = *current_function->emit;\n-\n-  /* Get some bounds on the labels and registers used.  */\n-\n-  max_labelno = max_label_num ();\n-  min_labelno = get_first_label_num ();\n-  max_reg = max_reg_num ();\n-\n-  /* Set up PARMDECL_MAP which maps pseudo-reg number to its PARM_DECL.\n-     Later we set TREE_READONLY to 0 if the parm is modified inside the fn.\n-     Also set up ARG_VECTOR, which holds the unmodified DECL_RTX values\n-     for the parms, prior to elimination of virtual registers.\n-     These values are needed for substituting parms properly.  */\n-\n-  parmdecl_map = (tree *) alloca (max_parm_reg * sizeof (tree));\n-\n-  argvec = initialize_for_inline (fndecl, 1);\n-\n-  if (current_function_uses_const_pool)\n-    {\n-      /* Replace any constant pool references with the actual constant.  We\n-\t will put the constants back in the copy made below.  */\n-      for (insn = get_insns (); insn; insn = NEXT_INSN (insn))\n-\tif (GET_RTX_CLASS (GET_CODE (insn)) == 'i')\n-\t  {\n-\t    save_constants (&PATTERN (insn));\n-\t    if (REG_NOTES (insn))\n-\t      save_constants (&REG_NOTES (insn));\n-\t  }\n-\n-      /* Also scan all decls, and replace any constant pool references with the\n-\t actual constant.  */\n-      save_constants_in_decl_trees (DECL_INITIAL (fndecl));\n-\n-      /* Clear out the constant pool so that we can recreate it with the\n-\t copied constants below.  */\n-      init_const_rtx_hash_table ();\n-      clear_const_double_mem ();\n-    }\n-\n-  max_uid = get_max_uid ();\n-\n-  /* We have now allocated all that needs to be allocated permanently\n-     on the rtx obstack.  Set our high-water mark, so that we\n-     can free the rest of this when the time comes.  */\n-\n-  preserve_data ();\n-\n-  /* Copy the chain insns of this function.\n-     Install the copied chain as the insns of this function,\n-     for continued compilation;\n-     the original chain is recorded as the DECL_SAVED_INSNS\n-     for inlining future calls.  */\n-\n-  /* If there are insns that copy parms from the stack into pseudo registers,\n-     those insns are not copied.  `expand_inline_function' must\n-     emit the correct code to handle such things.  */\n-\n-  insn = get_insns ();\n-  if (GET_CODE (insn) != NOTE)\n-    abort ();\n-  new_first_insn = rtx_alloc (NOTE);\n-  NOTE_SOURCE_FILE (new_first_insn) = NOTE_SOURCE_FILE (insn);\n-  NOTE_LINE_NUMBER (new_first_insn) = NOTE_LINE_NUMBER (insn);\n-  INSN_UID (new_first_insn) = INSN_UID (insn);\n-  PREV_INSN (new_first_insn) = NULL;\n-  NEXT_INSN (new_first_insn) = NULL;\n-  new_last_insn = new_first_insn;\n-\n-  /* Each pseudo-reg in the old insn chain must have a unique rtx in the copy.\n-     Make these new rtx's now, and install them in regno_reg_rtx, so they\n-     will be the official pseudo-reg rtx's for the rest of compilation.  */\n-\n-  reg_map = (rtx *) savealloc (es->regno_pointer_flag_length * sizeof (rtx));\n-\n-  len = sizeof (struct rtx_def) + (GET_RTX_LENGTH (REG) - 1) * sizeof (rtunion);\n-  for (i = max_reg - 1; i > LAST_VIRTUAL_REGISTER; i--)\n-    reg_map[i] = (rtx)obstack_copy (function_maybepermanent_obstack,\n-\t\t\t\t    regno_reg_rtx[i], len);\n-\n-  es->x_regno_reg_rtx = reg_map;\n-\n-  /* Put copies of all the virtual register rtx into the new regno_reg_rtx.  */\n-  init_virtual_regs (es);\n-\n-  /* Likewise each label rtx must have a unique rtx as its copy.  */\n-\n-  /* We used to use alloca here, but the size of what it would try to\n-     allocate would occasionally cause it to exceed the stack limit and\n-     cause unpredictable core dumps.  Some examples were > 2Mb in size.  */\n-  label_map = (rtx *) xmalloc ((max_labelno) * sizeof (rtx));\n-\n-  for (i = min_labelno; i < max_labelno; i++)\n-    label_map[i] = gen_label_rtx ();\n-\n-  /* Likewise for parm_reg_stack_slot.  */\n-  new_parm_reg_stack_loc = (rtx *) savealloc (max_parm_reg * sizeof (rtx));\n-  for (i = 0; i < max_parm_reg; i++)\n-    new_parm_reg_stack_loc[i] = copy_for_inline (parm_reg_stack_loc[i]);\n-\n-  parm_reg_stack_loc = new_parm_reg_stack_loc;\n-\n-  /* Record the mapping of old insns to copied insns.  */\n-\n-  insn_map = (rtx *) alloca (max_uid * sizeof (rtx));\n-  bzero ((char *) insn_map, max_uid * sizeof (rtx));\n-\n-  /* Get the insn which signals the end of parameter setup code.  */\n-  first_nonparm_insn = get_first_nonparm_insn ();\n-\n-  /* Copy any entries in regno_reg_rtx or DECL_RTLs that reference MEM\n-     (the former occurs when a variable has its address taken)\n-     since these may be shared and can be changed by virtual\n-     register instantiation.  DECL_RTL values for our arguments\n-     have already been copied by initialize_for_inline.  */\n-  for (i = LAST_VIRTUAL_REGISTER + 1; i < max_reg; i++)\n-    if (GET_CODE (regno_reg_rtx[i]) == MEM)\n-      XEXP (regno_reg_rtx[i], 0)\n-\t= copy_for_inline (XEXP (regno_reg_rtx[i], 0));\n-\n-  /* Copy the parm_reg_stack_loc array, and substitute for all of the rtx\n-     contained in it.  */\n-  new2 = (rtx *) savealloc (max_parm_reg * sizeof (rtx));\n-  bcopy ((char *) parm_reg_stack_loc, (char *) new2,\n-\t max_parm_reg * sizeof (rtx));\n-  parm_reg_stack_loc = new2;\n-  for (i = LAST_VIRTUAL_REGISTER + 1; i < max_parm_reg; ++i)\n-    if (parm_reg_stack_loc[i])\n-      parm_reg_stack_loc[i] = copy_for_inline (parm_reg_stack_loc[i]);\n-\n-  /* Copy the tree of subblocks of the function, and the decls in them.\n-     We will use the copy for compiling this function, then restore the original\n-     subblocks and decls for use when inlining this function.\n-\n-     Several parts of the compiler modify BLOCK trees.  In particular,\n-     instantiate_virtual_regs will instantiate any virtual regs\n-     mentioned in the DECL_RTLs of the decls, and loop\n-     unrolling will replicate any BLOCK trees inside an unrolled loop.\n-\n-     The modified subblocks or DECL_RTLs would be incorrect for the original rtl\n-     which we will use for inlining.  The rtl might even contain pseudoregs\n-     whose space has been freed.  */\n-\n-  DECL_INITIAL (fndecl) = copy_decl_tree (DECL_INITIAL (fndecl));\n-  DECL_ARGUMENTS (fndecl) = copy_decl_list (DECL_ARGUMENTS (fndecl));\n-\n-  /* Now copy each DECL_RTL which is a MEM,\n-     so it is safe to modify their addresses.  */\n-  copy_decl_rtls (DECL_INITIAL (fndecl));\n-\n-  /* The fndecl node acts as its own progenitor, so mark it as such.  */\n-  DECL_ABSTRACT_ORIGIN (fndecl) = fndecl;\n-\n-  /* Now copy the chain of insns.  Do this twice.  The first copy the insn\n-     itself and its body.  The second time copy of REG_NOTES.  This is because\n-     a REG_NOTE may have a forward pointer to another insn.  */\n-\n-  for (insn = NEXT_INSN (insn); insn; insn = NEXT_INSN (insn))\n-    {\n-      rtx copy;\n-      orig_asm_operands_vector = 0;\n-\n-      if (insn == first_nonparm_insn)\n-\tin_nonparm_insns = 1;\n-\n-      switch (GET_CODE (insn))\n-\t{\n-\tcase NOTE:\n-\t  /* No need to keep these.  */\n-\t  if (NOTE_LINE_NUMBER (insn) == NOTE_INSN_DELETED)\n-\t    continue;\n-\n-\t  copy = rtx_alloc (NOTE);\n-\t  NOTE_LINE_NUMBER (copy) = NOTE_LINE_NUMBER (insn);\n-\t  if (NOTE_LINE_NUMBER (insn) != NOTE_INSN_BLOCK_END)\n-\t    NOTE_SOURCE_FILE (copy) = NOTE_SOURCE_FILE (insn);\n-\t  else\n-\t    {\n-\t      NOTE_SOURCE_FILE (insn) = (char *) copy;\n-\t      NOTE_SOURCE_FILE (copy) = 0;\n-\t    }\n-\t  if (NOTE_LINE_NUMBER (copy) == NOTE_INSN_EH_REGION_BEG\n-\t      || NOTE_LINE_NUMBER (copy) == NOTE_INSN_EH_REGION_END)\n-\t    {\n-              int new_region = CODE_LABEL_NUMBER \n-                                        (label_map[NOTE_BLOCK_NUMBER (copy)]);\n-\n-              /* we have to duplicate the handlers for the original */\n-              if (NOTE_LINE_NUMBER (copy) == NOTE_INSN_EH_REGION_BEG) \n-                duplicate_eh_handlers (NOTE_BLOCK_NUMBER (copy), new_region,\n-                                       save_for_inline_eh_labelmap);\n-                \n-\t      /* We have to forward these both to match the new exception\n-\t\t region.  */\n-\t      NOTE_BLOCK_NUMBER (copy) = new_region;\n-\t      \n-\t    }\n-\t  RTX_INTEGRATED_P (copy) = RTX_INTEGRATED_P (insn);\n-\t  break;\n-\n-\tcase INSN:\n-\tcase JUMP_INSN:\n-\tcase CALL_INSN:\n-\t  copy = rtx_alloc (GET_CODE (insn));\n-\n-\t  if (GET_CODE (insn) == CALL_INSN)\n-\t    CALL_INSN_FUNCTION_USAGE (copy)\n-\t      = copy_for_inline (CALL_INSN_FUNCTION_USAGE (insn));\n-\n-\t  PATTERN (copy) = copy_for_inline (PATTERN (insn));\n-\t  INSN_CODE (copy) = -1;\n-\t  LOG_LINKS (copy) = NULL_RTX;\n-\t  RTX_INTEGRATED_P (copy) = RTX_INTEGRATED_P (insn);\n-\t  break;\n-\n-\tcase CODE_LABEL:\n-\t  copy = label_map[CODE_LABEL_NUMBER (insn)];\n-\t  LABEL_NAME (copy) = LABEL_NAME (insn);\n-\t  break;\n-\n-\tcase BARRIER:\n-\t  copy = rtx_alloc (BARRIER);\n-\t  break;\n-\n-\tdefault:\n-\t  abort ();\n-\t}\n-      INSN_UID (copy) = INSN_UID (insn);\n-      insn_map[INSN_UID (insn)] = copy;\n-      NEXT_INSN (new_last_insn) = copy;\n-      PREV_INSN (copy) = new_last_insn;\n-      new_last_insn = copy;\n-    }\n-\n-  adjust_copied_decl_tree (DECL_INITIAL (fndecl));\n-\n-  /* Now copy the REG_NOTES.  */\n-  for (insn = NEXT_INSN (get_insns ()); insn; insn = NEXT_INSN (insn))\n-    if (GET_RTX_CLASS (GET_CODE (insn)) == 'i'\n-\t&& insn_map[INSN_UID(insn)])\n-      REG_NOTES (insn_map[INSN_UID (insn)])\n-\t= copy_for_inline (REG_NOTES (insn));\n-\n-  NEXT_INSN (new_last_insn) = NULL;\n-\n-  /* Make new versions of the register tables.  */\n-  new = (char *) savealloc (es->regno_pointer_flag_length);\n-  memcpy (new, es->regno_pointer_flag, es->regno_pointer_flag_length);\n-  new1 = (char *) savealloc (es->regno_pointer_flag_length);\n-  memcpy (new1, es->regno_pointer_align, es->regno_pointer_flag_length);\n-  es->regno_pointer_flag = new;\n-  es->regno_pointer_align = new1;\n-\n-  free (label_map);\n-\n-  current_function->inl_max_label_num = max_label_num ();\n-  current_function->inl_last_parm_insn = current_function->x_last_parm_insn;\n-  current_function->original_arg_vector = argvec;\n-  current_function->original_decl_initial = DECL_INITIAL (fndecl);\n-  /* Use the copy we made for compiling the function now, and\n-     use the original values for inlining.  */\n-  current_function->inl_emit = current_function->emit;\n-  current_function->emit = es;\n-  set_new_first_and_last_insn (new_first_insn, new_last_insn);\n-  DECL_SAVED_INSNS (fndecl) = current_function;\n-}\n-\n /* Copy NODE (as with copy_node).  NODE must be a DECL.  Set the\n    DECL_ABSTRACT_ORIGIN for the new accordinly.  */\n \n@@ -723,81 +333,6 @@ copy_and_set_decl_abstract_origin (node)\n   return copy;\n }\n \n-/* Return a copy of a chain of nodes, chained through the TREE_CHAIN field.\n-   For example, this can copy a list made of TREE_LIST nodes.  While copying,\n-   set DECL_ABSTRACT_ORIGIN appropriately.  */\n-\n-static tree\n-copy_decl_list (list)\n-     tree list;\n-{\n-  tree head;\n-  register tree prev, next;\n-\n-  if (list == 0)\n-    return 0;\n-\n-  head = prev = copy_and_set_decl_abstract_origin (list);\n-  next = TREE_CHAIN (list);\n-  while (next)\n-    {\n-      register tree copy;\n-\n-      copy = copy_and_set_decl_abstract_origin (next);\n-      TREE_CHAIN (prev) = copy;\n-      prev = copy;\n-      next = TREE_CHAIN (next);\n-    }\n-  return head;\n-}\n-\n-/* Make a copy of the entire tree of blocks BLOCK, and return it.  */\n-\n-static tree\n-copy_decl_tree (block)\n-     tree block;\n-{\n-  tree t, vars, subblocks;\n-\n-  vars = copy_decl_list (BLOCK_VARS (block));\n-  subblocks = 0;\n-\n-  /* Process all subblocks.  */\n-  for (t = BLOCK_SUBBLOCKS (block); t; t = TREE_CHAIN (t))\n-    {\n-      tree copy = copy_decl_tree (t);\n-      TREE_CHAIN (copy) = subblocks;\n-      subblocks = copy;\n-    }\n-\n-  t = copy_node (block);\n-  BLOCK_VARS (t) = vars;\n-  BLOCK_SUBBLOCKS (t) = nreverse (subblocks);\n-  /* If the BLOCK being cloned is already marked as having been instantiated\n-     from something else, then leave that `origin' marking alone.  Otherwise,\n-     mark the clone as having originated from the BLOCK we are cloning.  */\n-  if (BLOCK_ABSTRACT_ORIGIN (t) == NULL_TREE)\n-    BLOCK_ABSTRACT_ORIGIN (t) = block;\n-  return t;\n-}\n-\n-/* Copy DECL_RTLs in all decls in the given BLOCK node.  */\n-\n-static void\n-copy_decl_rtls (block)\n-     tree block;\n-{\n-  tree t;\n-\n-  for (t = BLOCK_VARS (block); t; t = TREE_CHAIN (t))\n-    if (DECL_RTL (t) && GET_CODE (DECL_RTL (t)) == MEM)\n-      DECL_RTL (t) = copy_for_inline (DECL_RTL (t));\n-\n-  /* Process all subblocks.  */\n-  for (t = BLOCK_SUBBLOCKS (block); t; t = TREE_CHAIN (t))\n-    copy_decl_rtls (t);\n-}\n-\n /* Make the insns and PARM_DECLs of the current function permanent\n    and record other information in DECL_SAVED_INSNS to allow inlining\n    of this function in subsequent calls.\n@@ -841,7 +376,7 @@ save_for_inline_nocopy (fndecl)\n       emit_label (return_label);\n     }\n \n-  argvec = initialize_for_inline (fndecl, 0);\n+  argvec = initialize_for_inline (fndecl);\n \n   /* If there are insns that copy parms from the stack into pseudo registers,\n      those insns are not copied.  `expand_inline_function' must\n@@ -867,121 +402,23 @@ save_for_inline_nocopy (fndecl)\n \tin_nonparm_insns = 1;\n \n       if (GET_RTX_CLASS (GET_CODE (insn)) == 'i')\n-\t{\n-\t  if (current_function_uses_const_pool)\n-\t    {\n-\t      /* Replace any constant pool references with the actual constant.\n-\t\t We will put the constant back if we need to write the\n-\t\t function out after all.  */\n-\t      save_constants (&PATTERN (insn));\n-\t      if (REG_NOTES (insn))\n-\t\tsave_constants (&REG_NOTES (insn));\n-\t    }\n-\n-\t  /* Record what interesting things happen to our parameters.  */\n-\t  note_stores (PATTERN (insn), note_modified_parmregs);\n-\t}\n+\t/* Record what interesting things happen to our parameters.  */\n+\tnote_stores (PATTERN (insn), note_modified_parmregs);\n     }\n \n-  /* Also scan all decls, and replace any constant pool references with the\n-     actual constant.  */\n-  save_constants_in_decl_trees (DECL_INITIAL (fndecl));\n-\n   /* We have now allocated all that needs to be allocated permanently\n      on the rtx obstack.  Set our high-water mark, so that we\n      can free the rest of this when the time comes.  */\n \n   preserve_data ();\n \n-  current_function->inl_emit = current_function->emit;\n   current_function->inl_max_label_num = max_label_num ();\n   current_function->inl_last_parm_insn = current_function->x_last_parm_insn;\n   current_function->original_arg_vector = argvec;\n   current_function->original_decl_initial = DECL_INITIAL (fndecl);\n   DECL_SAVED_INSNS (fndecl) = current_function;\n }\n \f\n-/* Given PX, a pointer into an insn, search for references to the constant\n-   pool.  Replace each with a CONST that has the mode of the original\n-   constant, contains the constant, and has RTX_INTEGRATED_P set.\n-   Similarly, constant pool addresses not enclosed in a MEM are replaced\n-   with an ADDRESS and CONST rtx which also gives the constant, its\n-   mode, the mode of the address, and has RTX_INTEGRATED_P set.  */\n-\n-static void\n-save_constants (px)\n-     rtx *px;\n-{\n-  rtx x;\n-  int i, j;\n-\n- again:\n-  x = *px;\n-\n-  /* If this is a CONST_DOUBLE, don't try to fix things up in \n-     CONST_DOUBLE_MEM, because this is an infinite recursion.  */\n-  if (GET_CODE (x) == CONST_DOUBLE)\n-    return;\n-  else if (GET_CODE (x) == MEM && GET_CODE (XEXP (x, 0)) == SYMBOL_REF\n-\t   && CONSTANT_POOL_ADDRESS_P (XEXP (x,0)))\n-    {\n-      enum machine_mode const_mode = get_pool_mode (XEXP (x, 0));\n-      rtx new = gen_rtx_CONST (const_mode, get_pool_constant (XEXP (x, 0)));\n-      RTX_INTEGRATED_P (new) = 1;\n-\n-      /* If the MEM was in a different mode than the constant (perhaps we\n-\t were only looking at the low-order part), surround it with a \n-\t SUBREG so we can save both modes.  */\n-\n-      if (GET_MODE (x) != const_mode)\n-\t{\n-\t  new = gen_rtx_SUBREG (GET_MODE (x), new, 0);\n-\t  RTX_INTEGRATED_P (new) = 1;\n-\t}\n-\n-      *px = new;\n-      save_constants (&XEXP (*px, 0));\n-    }\n-  else if (GET_CODE (x) == SYMBOL_REF\n-\t   && CONSTANT_POOL_ADDRESS_P (x))\n-    {\n-      *px = gen_rtx_ADDRESS (GET_MODE (x),\n-\t\t\t     gen_rtx_CONST (get_pool_mode (x),\n-\t\t\t\t\t    get_pool_constant (x)));\n-      save_constants (&XEXP (*px, 0));\n-      RTX_INTEGRATED_P (*px) = 1;\n-    }\n-\n-  else\n-    {\n-      const char *fmt = GET_RTX_FORMAT (GET_CODE (x));\n-      int len = GET_RTX_LENGTH (GET_CODE (x));\n-\n-      for (i = len-1; i >= 0; i--)\n-\t{\n-\t  switch (fmt[i])\n-\t    {\n-\t    case 'E':\n-\t      for (j = 0; j < XVECLEN (x, i); j++)\n-\t\tsave_constants (&XVECEXP (x, i, j));\n-\t      break;\n-\n-\t    case 'e':\n-\t      if (XEXP (x, i) == 0)\n-\t\tcontinue;\n-\t      if (i == 0)\n-\t\t{\n-\t\t  /* Hack tail-recursion here.  */\n-\t\t  px = &XEXP (x, 0);\n-\t\t  goto again;\n-\t\t}\n-\t      save_constants (&XEXP (x, i));\n-\t      break;\n-\t    }\n-\t}\n-    }\n-}\n-\f\n /* Note whether a parameter is modified or not.  */\n \n static void\n@@ -996,262 +433,6 @@ note_modified_parmregs (reg, x)\n     TREE_READONLY (parmdecl_map[REGNO (reg)]) = 0;\n }\n \n-/* Copy the rtx ORIG recursively, replacing pseudo-regs and labels\n-   according to `reg_map' and `label_map'.  The original rtl insns\n-   will be saved for inlining; this is used to make a copy\n-   which is used to finish compiling the inline function itself.\n-\n-   If we find a \"saved\" constant pool entry, one which was replaced with\n-   the value of the constant, convert it back to a constant pool entry.\n-   Since the pool wasn't touched, this should simply restore the old\n-   address.\n-\n-   All other kinds of rtx are copied except those that can never be\n-   changed during compilation.  */\n-\n-static rtx\n-copy_for_inline (orig)\n-     rtx orig;\n-{\n-  register rtx x = orig;\n-  register rtx new;\n-  register int i;\n-  register enum rtx_code code;\n-  register const char *format_ptr;\n-\n-  if (x == 0)\n-    return x;\n-\n-  code = GET_CODE (x);\n-\n-  /* These types may be freely shared.  */\n-\n-  switch (code)\n-    {\n-    case QUEUED:\n-    case CONST_INT:\n-    case PC:\n-    case CC0:\n-      return x;\n-\n-    case SYMBOL_REF:\n-      if (! SYMBOL_REF_NEED_ADJUST (x))\n-        return x;\n-      return rethrow_symbol_map (x, save_for_inline_eh_labelmap);\n-\n-    case CONST_DOUBLE:\n-      /* We have to make a new CONST_DOUBLE to ensure that we account for\n-\t it correctly.  Using the old CONST_DOUBLE_MEM data is wrong.  */\n-      if (GET_MODE_CLASS (GET_MODE (x)) == MODE_FLOAT)\n-\t{\n-\t  REAL_VALUE_TYPE d;\n-\n-\t  REAL_VALUE_FROM_CONST_DOUBLE (d, x);\n-\t  return CONST_DOUBLE_FROM_REAL_VALUE (d, GET_MODE (x));\n-\t}\n-      else\n-\treturn immed_double_const (CONST_DOUBLE_LOW (x), CONST_DOUBLE_HIGH (x),\n-\t\t\t\t   VOIDmode);\n-\n-    case CONST:\n-      /* Get constant pool entry for constant in the pool.  */\n-      if (RTX_INTEGRATED_P (x))\n-\treturn validize_mem (force_const_mem (GET_MODE (x),\n-\t\t\t\t\t      copy_for_inline (XEXP (x, 0))));\n-      break;\n-\n-    case SUBREG:\n-      /* Get constant pool entry, but access in different mode.  */\n-      if (RTX_INTEGRATED_P (x))\n-\t{\n-\t  new = force_const_mem (GET_MODE (SUBREG_REG (x)),\n-\t\t\t\t copy_for_inline (XEXP (SUBREG_REG (x), 0)));\n-\n-\t  PUT_MODE (new, GET_MODE (x));\n-\t  return validize_mem (new);\n-\t}\n-      break;\n-\n-    case ADDRESS:\n-      /* If not special for constant pool error.  Else get constant pool\n-\t address.  */\n-      if (! RTX_INTEGRATED_P (x))\n-\tabort ();\n-\n-      new = force_const_mem (GET_MODE (XEXP (x, 0)),\n-\t\t\t     copy_for_inline (XEXP (XEXP (x, 0), 0)));\n-      new = XEXP (new, 0);\n-\n-#ifdef POINTERS_EXTEND_UNSIGNED\n-      if (GET_MODE (new) != GET_MODE (x))\n-\tnew = convert_memory_address (GET_MODE (x), new);\n-#endif\n-\n-      return new;\n-\n-    case ASM_OPERANDS:\n-      /* If a single asm insn contains multiple output operands\n-\t then it contains multiple ASM_OPERANDS rtx's that share operand 3.\n-\t We must make sure that the copied insn continues to share it.  */\n-      if (orig_asm_operands_vector == XVEC (orig, 3))\n-\t{\n-\t  x = rtx_alloc (ASM_OPERANDS);\n-\t  x->volatil = orig->volatil;\n-\t  XSTR (x, 0) = XSTR (orig, 0);\n-\t  XSTR (x, 1) = XSTR (orig, 1);\n-\t  XINT (x, 2) = XINT (orig, 2);\n-\t  XVEC (x, 3) = copy_asm_operands_vector;\n-\t  XVEC (x, 4) = copy_asm_constraints_vector;\n-\t  XSTR (x, 5) = XSTR (orig, 5);\n-\t  XINT (x, 6) = XINT (orig, 6);\n-\t  return x;\n-\t}\n-      break;\n-\n-    case MEM:\n-      /* A MEM is usually allowed to be shared if its address is constant\n-\t or is a constant plus one of the special registers.\n-\n-\t We do not allow sharing of addresses that are either a special\n-\t register or the sum of a constant and a special register because\n-\t it is possible for unshare_all_rtl to copy the address, into memory\n-\t that won't be saved.  Although the MEM can safely be shared, and\n-\t won't be copied there, the address itself cannot be shared, and may\n-\t need to be copied. \n-\n-\t There are also two exceptions with constants: The first is if the\n-\t constant is a LABEL_REF or the sum of the LABEL_REF\n-\t and an integer.  This case can happen if we have an inline\n-\t function that supplies a constant operand to the call of another\n-\t inline function that uses it in a switch statement.  In this case,\n-\t we will be replacing the LABEL_REF, so we have to replace this MEM\n-\t as well.\n-\n-\t The second case is if we have a (const (plus (address ..) ...)).\n-\t In that case we need to put back the address of the constant pool\n-\t entry.  */\n-\n-      if (CONSTANT_ADDRESS_P (XEXP (x, 0))\n-\t  && GET_CODE (XEXP (x, 0)) != LABEL_REF\n-\t  && ! (GET_CODE (XEXP (x, 0)) == CONST\n-\t\t&& (GET_CODE (XEXP (XEXP (x, 0), 0)) == PLUS\n-\t\t    && ((GET_CODE (XEXP (XEXP (XEXP (x, 0), 0), 0))\n-\t\t\t== LABEL_REF)\n-\t\t\t|| (GET_CODE (XEXP (XEXP (XEXP (x, 0), 0), 0))\n-\t\t\t    == ADDRESS)))))\n-\treturn x;\n-      break;\n-\n-    case LABEL_REF:\n-      /* If this is a non-local label, just make a new LABEL_REF.\n-\t Otherwise, use the new label as well.  */\n-      x = gen_rtx_LABEL_REF (GET_MODE (orig),\n-\t\t\t     LABEL_REF_NONLOCAL_P (orig) ? XEXP (orig, 0)\n-\t\t\t     : label_map[CODE_LABEL_NUMBER (XEXP (orig, 0))]);\n-      LABEL_REF_NONLOCAL_P (x) = LABEL_REF_NONLOCAL_P (orig);\n-      LABEL_OUTSIDE_LOOP_P (x) = LABEL_OUTSIDE_LOOP_P (orig);\n-      return x;\n-\n-    case REG:\n-      if (REGNO (x) > LAST_VIRTUAL_REGISTER)\n-\treturn reg_map [REGNO (x)];\n-      else\n-\treturn x;\n-\n-    case SET:\n-      /* If a parm that gets modified lives in a pseudo-reg,\n-\t clear its TREE_READONLY to prevent certain optimizations.  */\n-      {\n-\trtx dest = SET_DEST (x);\n-\n-\twhile (GET_CODE (dest) == STRICT_LOW_PART\n-\t       || GET_CODE (dest) == ZERO_EXTRACT\n-\t       || GET_CODE (dest) == SUBREG)\n-\t  dest = XEXP (dest, 0);\n-\n-\tif (GET_CODE (dest) == REG\n-\t    && REGNO (dest) < max_parm_reg\n-\t    && REGNO (dest) >= FIRST_PSEUDO_REGISTER\n-\t    && parmdecl_map[REGNO (dest)] != 0\n-\t    /* The insn to load an arg pseudo from a stack slot\n-\t       does not count as modifying it.  */\n-\t    && in_nonparm_insns)\n-\t  TREE_READONLY (parmdecl_map[REGNO (dest)]) = 0;\n-      }\n-      break;\n-\n-#if 0 /* This is a good idea, but here is the wrong place for it.  */\n-      /* Arrange that CONST_INTs always appear as the second operand\n-\t if they appear, and that `frame_pointer_rtx' or `arg_pointer_rtx'\n-\t always appear as the first.  */\n-    case PLUS:\n-      if (GET_CODE (XEXP (x, 0)) == CONST_INT\n-\t  || (XEXP (x, 1) == frame_pointer_rtx\n-\t      || (ARG_POINTER_REGNUM != FRAME_POINTER_REGNUM\n-\t\t  && XEXP (x, 1) == arg_pointer_rtx)))\n-\t{\n-\t  rtx t = XEXP (x, 0);\n-\t  XEXP (x, 0) = XEXP (x, 1);\n-\t  XEXP (x, 1) = t;\n-\t}\n-      break;\n-#endif\n-    default:\n-      break;\n-    }\n-\n-  /* Replace this rtx with a copy of itself.  */\n-\n-  x = rtx_alloc (code);\n-  bcopy ((char *) orig, (char *) x,\n-\t (sizeof (*x) - sizeof (x->fld)\n-\t  + sizeof (x->fld[0]) * GET_RTX_LENGTH (code)));\n-\n-  /* Now scan the subexpressions recursively.\n-     We can store any replaced subexpressions directly into X\n-     since we know X is not shared!  Any vectors in X\n-     must be copied if X was copied.  */\n-\n-  format_ptr = GET_RTX_FORMAT (code);\n-\n-  for (i = 0; i < GET_RTX_LENGTH (code); i++)\n-    {\n-      switch (*format_ptr++)\n-\t{\n-\tcase 'e':\n-\t  XEXP (x, i) = copy_for_inline (XEXP (x, i));\n-\t  break;\n-\n-\tcase 'u':\n-\t  /* Change any references to old-insns to point to the\n-\t     corresponding copied insns.  */\n-\t  XEXP (x, i) = insn_map[INSN_UID (XEXP (x, i))];\n-\t  break;\n-\n-\tcase 'E':\n-\t  if (XVEC (x, i) != NULL && XVECLEN (x, i) != 0)\n-\t    {\n-\t      register int j;\n-\n-\t      XVEC (x, i) = gen_rtvec_v (XVECLEN (x, i), XVEC (x, i)->elem);\n-\t      for (j = 0; j < XVECLEN (x, i); j++)\n-\t\tXVECEXP (x, i, j)\n-\t\t  = copy_for_inline (XVECEXP (x, i, j));\n-\t    }\n-\t  break;\n-\t}\n-    }\n-\n-  if (code == ASM_OPERANDS && orig_asm_operands_vector == 0)\n-    {\n-      orig_asm_operands_vector = XVEC (orig, 3);\n-      copy_asm_operands_vector = XVEC (x, 3);\n-      copy_asm_constraints_vector = XVEC (x, 4);\n-    }\n-\n-  return x;\n-}\n-\n /* Unfortunately, we need a global copy of const_equiv map for communication\n    with a function called from note_stores.  Be *very* careful that this\n    is used properly in the presence of recursion.  */\n@@ -1326,9 +507,10 @@ expand_inline_function (fndecl, parms, target, ignore, type,\n      tree type;\n      rtx structure_value_addr;\n {\n+  struct function *inlining_previous;\n   struct function *inl_f = DECL_SAVED_INSNS (fndecl);\n   tree formal, actual, block;\n-  rtx parm_insns = inl_f->inl_emit->x_first_insn;\n+  rtx parm_insns = inl_f->emit->x_first_insn;\n   rtx insns = (inl_f->inl_last_parm_insn\n \t       ? NEXT_INSN (inl_f->inl_last_parm_insn)\n \t       : parm_insns);\n@@ -1337,7 +519,7 @@ expand_inline_function (fndecl, parms, target, ignore, type,\n   rtx insn;\n   int max_regno;\n   register int i;\n-  int min_labelno = inl_f->inl_emit->x_first_label_num;\n+  int min_labelno = inl_f->emit->x_first_label_num;\n   int max_labelno = inl_f->inl_max_label_num;\n   int nargs;\n   rtx local_return_label = 0;\n@@ -1357,7 +539,7 @@ expand_inline_function (fndecl, parms, target, ignore, type,\n   rtx *real_label_map = 0;\n \n   /* Allow for equivalences of the pseudos we make for virtual fp and ap.  */\n-  max_regno = inl_f->inl_emit->x_reg_rtx_no + 3;\n+  max_regno = inl_f->emit->x_reg_rtx_no + 3;\n   if (max_regno < FIRST_PSEUDO_REGISTER)\n     abort ();\n \n@@ -1500,7 +682,7 @@ expand_inline_function (fndecl, parms, target, ignore, type,\n     = (rtx *) xmalloc ((max_labelno) * sizeof (rtx));\n   map->label_map = real_label_map;\n \n-  inl_max_uid = (inl_f->inl_emit->x_cur_insn_uid + 1);\n+  inl_max_uid = (inl_f->emit->x_cur_insn_uid + 1);\n   map->insn_map = (rtx *) alloca (inl_max_uid * sizeof (rtx));\n   bzero ((char *) map->insn_map, inl_max_uid * sizeof (rtx));\n   map->min_insnno = 0;\n@@ -1536,8 +718,8 @@ expand_inline_function (fndecl, parms, target, ignore, type,\n   if (map->insns_at_start == 0)\n     map->insns_at_start = emit_note (NULL_PTR, NOTE_INSN_DELETED);\n \n-  map->regno_pointer_flag = inl_f->inl_emit->regno_pointer_flag;\n-  map->regno_pointer_align = inl_f->inl_emit->regno_pointer_align;\n+  map->regno_pointer_flag = inl_f->emit->regno_pointer_flag;\n+  map->regno_pointer_align = inl_f->emit->regno_pointer_align;\n \n   /* Update the outgoing argument size to allow for those in the inlined\n      function.  */\n@@ -1625,6 +807,12 @@ expand_inline_function (fndecl, parms, target, ignore, type,\n \tabort ();\n     }\n \n+  /* Tell copy_rtx_and_substitute to handle constant pool SYMBOL_REFs\n+     specially.  This function can be called recursively, so we need to\n+     save the previous value.  */\n+  inlining_previous = inlining;\n+  inlining = inl_f;\n+\n   /* Now do the parameters that will be placed in memory.  */\n \n   for (formal = DECL_ARGUMENTS (fndecl), i = 0;\n@@ -2132,6 +1320,7 @@ expand_inline_function (fndecl, parms, target, ignore, type,\n     free (real_label_map);\n   if (map)\n     VARRAY_FREE (map->const_equiv_varray);\n+  inlining = inlining_previous;\n \n   return target;\n }\n@@ -2236,23 +1425,6 @@ integrate_decl_tree (let, level, map)\n \t}\n     }\n }\n-\n-/* Given a BLOCK node LET, search for all DECL_RTL fields, and pass them\n-   through save_constants.  */\n-\n-static void\n-save_constants_in_decl_trees (let)\n-     tree let;\n-{\n-  tree t;\n-\n-  for (t = BLOCK_VARS (let); t; t = TREE_CHAIN (t))\n-    if (DECL_RTL (t) != 0)\n-      save_constants (&DECL_RTL (t));\n-\n-  for (t = BLOCK_SUBBLOCKS (let); t; t = TREE_CHAIN (t))\n-    save_constants_in_decl_trees (t);\n-}\n \f\n /* Create a new copy of an rtx.\n    Recursively copies the operands of the rtx,\n@@ -2506,8 +1678,38 @@ copy_rtx_and_substitute (orig, map)\n \t remapped label.  Otherwise, symbols are returned unchanged.  */\n       if (CONSTANT_POOL_ADDRESS_P (orig))\n \t{\n-\t  rtx constant = get_pool_constant (orig);\n-\t  if (GET_CODE (constant) == LABEL_REF)\n+\t  struct function *f = inlining ? inlining : current_function;\n+\t  rtx constant = get_pool_constant_for_function (f, orig);\n+\t  enum machine_mode const_mode = get_pool_mode_for_function (f, orig);\n+\t  if (inlining)\n+\t    {\n+\t      rtx temp = force_const_mem (const_mode,\n+\t\t\t\t\t  copy_rtx_and_substitute (constant, map));\n+#if 0\n+\t      /* Legitimizing the address here is incorrect.\n+\n+\t\t Since we had a SYMBOL_REF before, we can assume it is valid\n+\t\t to have one in this position in the insn.\n+\n+\t\t Also, change_address may create new registers.  These\n+\t\t registers will not have valid reg_map entries.  This can\n+\t\t cause try_constants() to fail because assumes that all\n+\t\t registers in the rtx have valid reg_map entries, and it may\n+\t\t end up replacing one of these new registers with junk.  */\n+\n+\t      if (! memory_address_p (GET_MODE (temp), XEXP (temp, 0)))\n+\t\ttemp = change_address (temp, GET_MODE (temp), XEXP (temp, 0));\n+#endif\n+\n+\t      temp = XEXP (temp, 0);\n+\n+#ifdef POINTERS_EXTEND_UNSIGNED\n+\t      if (GET_MODE (temp) != GET_MODE (orig))\n+\t\ttemp = convert_memory_address (GET_MODE (orig), temp);\n+#endif\n+\t      return temp;\n+\t    }\n+\t  else if (GET_CODE (constant) == LABEL_REF)\n \t    return XEXP (force_const_mem (GET_MODE (orig),\n \t\t\t\t\t  copy_rtx_and_substitute (constant,\n \t\t\t\t\t\t\t\t   map)),\n@@ -2542,62 +1744,8 @@ copy_rtx_and_substitute (orig, map)\n       /* Make new constant pool entry for a constant\n \t that was in the pool of the inline function.  */\n       if (RTX_INTEGRATED_P (orig))\n-\t{\n-\t  /* If this was an address of a constant pool entry that itself\n-\t     had to be placed in the constant pool, it might not be a\n-\t     valid address.  So the recursive call below might turn it\n-\t     into a register.  In that case, it isn't a constant any\n-\t     more, so return it.  This has the potential of changing a\n-\t     MEM into a REG, but we'll assume that it safe.  */\n-\t  temp = copy_rtx_and_substitute (XEXP (orig, 0), map);\n-\t  if (! CONSTANT_P (temp))\n-\t    return temp;\n-\t  return validize_mem (force_const_mem (GET_MODE (orig), temp));\n-\t}\n-      break;\n-\n-    case ADDRESS:\n-      /* If from constant pool address, make new constant pool entry and\n-\t return its address.  */\n-      if (! RTX_INTEGRATED_P (orig))\n \tabort ();\n-\n-      temp\n-\t= force_const_mem (GET_MODE (XEXP (orig, 0)),\n-\t\t\t   copy_rtx_and_substitute (XEXP (XEXP (orig, 0), 0),\n-\t\t\t\t\t\t    map));\n-\n-#if 0\n-      /* Legitimizing the address here is incorrect.\n-\n-\t The only ADDRESS rtx's that can reach here are ones created by\n-\t save_constants.  Hence the operand of the ADDRESS is always valid\n-\t in this position of the instruction, since the original rtx without\n-\t the ADDRESS was valid.\n-\n-\t The reason we don't legitimize the address here is that on the\n-\t Sparc, the caller may have a (high ...) surrounding this ADDRESS.\n-\t This code forces the operand of the address to a register, which\n-\t fails because we can not take the HIGH part of a register.\n-\n-\t Also, change_address may create new registers.  These registers\n-\t will not have valid reg_map entries.  This can cause try_constants()\n-\t to fail because assumes that all registers in the rtx have valid\n-\t reg_map entries, and it may end up replacing one of these new\n-\t registers with junk.  */\n-\n-      if (! memory_address_p (GET_MODE (temp), XEXP (temp, 0)))\n-\ttemp = change_address (temp, GET_MODE (temp), XEXP (temp, 0));\n-#endif\n-\n-      temp = XEXP (temp, 0);\n-\n-#ifdef POINTERS_EXTEND_UNSIGNED\n-      if (GET_MODE (temp) != GET_MODE (orig))\n-\ttemp = convert_memory_address (GET_MODE (orig), temp);\n-#endif\n-\n-      return temp;\n+      break;\n \n     case ASM_OPERANDS:\n       /* If a single asm insn contains multiple output operands\n@@ -2666,6 +1814,23 @@ copy_rtx_and_substitute (orig, map)\n       break;\n \n     case MEM:\n+      if (inlining\n+\t  && GET_CODE (XEXP (orig, 0)) == SYMBOL_REF\n+\t  && CONSTANT_POOL_ADDRESS_P (XEXP (orig, 0)))\n+\t{\n+\t  enum machine_mode const_mode = get_pool_mode_for_function (inlining, XEXP (orig, 0));\n+\t  rtx constant = get_pool_constant_for_function (inlining, XEXP (orig, 0));\n+\t  constant = copy_rtx_and_substitute (constant, map);\n+\t  /* If this was an address of a constant pool entry that itself\n+\t     had to be placed in the constant pool, it might not be a\n+\t     valid address.  So the recursive call might have turned it\n+\t     into a register.  In that case, it isn't a constant any\n+\t     more, so return it.  This has the potential of changing a\n+\t     MEM into a REG, but we'll assume that it safe.  */\n+\t  if (! CONSTANT_P (constant))\n+\t    return constant;\n+\t  return validize_mem (force_const_mem (const_mode, constant));\n+\t}\n       copy = rtx_alloc (MEM);\n       PUT_MODE (copy, mode);\n       XEXP (copy, 0) = copy_rtx_and_substitute (XEXP (orig, 0), map);\n@@ -3122,88 +2287,6 @@ mark_stores (dest, x)\n     }\n }\n \f\n-/* If any CONST expressions with RTX_INTEGRATED_P are present in the rtx\n-   pointed to by PX, they represent constants in the constant pool.\n-   Replace these with a new memory reference obtained from force_const_mem.\n-   Similarly, ADDRESS expressions with RTX_INTEGRATED_P represent the\n-   address of a constant pool entry.  Replace them with the address of\n-   a new constant pool entry obtained from force_const_mem.  */\n-\n-static void\n-restore_constants (px)\n-     rtx *px;\n-{\n-  rtx x = *px;\n-  int i, j;\n-  const char *fmt;\n-\n-  if (x == 0)\n-    return;\n-\n-  if (GET_CODE (x) == CONST_DOUBLE)\n-    {\n-      /* We have to make a new CONST_DOUBLE to ensure that we account for\n-\t it correctly.  Using the old CONST_DOUBLE_MEM data is wrong.  */\n-      if (GET_MODE_CLASS (GET_MODE (x)) == MODE_FLOAT)\n-\t{\n-\t  REAL_VALUE_TYPE d;\n-\n-\t  REAL_VALUE_FROM_CONST_DOUBLE (d, x);\n-\t  *px = CONST_DOUBLE_FROM_REAL_VALUE (d, GET_MODE (x));\n-\t}\n-      else\n-\t*px = immed_double_const (CONST_DOUBLE_LOW (x), CONST_DOUBLE_HIGH (x),\n-\t\t\t\t  VOIDmode);\n-    }\n-\n-  else if (RTX_INTEGRATED_P (x) && GET_CODE (x) == CONST)\n-    {\n-      restore_constants (&XEXP (x, 0));\n-      *px = validize_mem (force_const_mem (GET_MODE (x), XEXP (x, 0)));\n-    }\n-  else if (RTX_INTEGRATED_P (x) && GET_CODE (x) == SUBREG)\n-    {\n-      /* This must be (subreg/i:M1 (const/i:M2 ...) 0).  */\n-      rtx new = XEXP (SUBREG_REG (x), 0);\n-\n-      restore_constants (&new);\n-      new = force_const_mem (GET_MODE (SUBREG_REG (x)), new);\n-      PUT_MODE (new, GET_MODE (x));\n-      *px = validize_mem (new);\n-    }\n-  else if (RTX_INTEGRATED_P (x) && GET_CODE (x) == ADDRESS)\n-    {\n-      rtx new = XEXP (force_const_mem (GET_MODE (XEXP (x, 0)),\n-\t\t\t\t       XEXP (XEXP (x, 0), 0)),\n-\t\t      0);\n-\n-#ifdef POINTERS_EXTEND_UNSIGNED\n-      if (GET_MODE (new) != GET_MODE (x))\n-\tnew = convert_memory_address (GET_MODE (x), new);\n-#endif\n-\n-      *px = new;\n-    }\n-  else\n-    {\n-      fmt = GET_RTX_FORMAT (GET_CODE (x));\n-      for (i = 0; i < GET_RTX_LENGTH (GET_CODE (x)); i++)\n-\t{\n-\t  switch (*fmt++)\n-\t    {\n-\t    case 'E':\n-\t      for (j = 0; j < XVECLEN (x, i); j++)\n-\t\trestore_constants (&XVECEXP (x, i, j));\n-\t      break;\n-\n-\t    case 'e':\n-\t      restore_constants (&XEXP (x, i));\n-\t      break;\n-\t    }\n-\t}\n-    }\n-}\n-\f\n /* Given a pointer to some BLOCK node, if the BLOCK_ABSTRACT_ORIGIN for the\n    given BLOCK node is NULL, set the BLOCK_ABSTRACT_ORIGIN for the node so\n    that it points to the node itself, thus indicating that the node is its\n@@ -3331,26 +2414,16 @@ void\n output_inline_function (fndecl)\n      tree fndecl;\n {\n+  struct function *curf = current_function;\n   struct function *f = DECL_SAVED_INSNS (fndecl);\n-  rtx last;\n \n-  /* Things we allocate from here on are part of this function, not\n-     permanent.  */\n-  temporary_allocation ();\n   current_function = f;\n   current_function_decl = fndecl;\n   clear_emit_caches ();\n \n-  /* Find last insn and rebuild the constant pool.  */\n-  init_const_rtx_hash_table ();\n-  for (last = get_insns (); NEXT_INSN (last); last = NEXT_INSN (last))\n-    {\n-      if (GET_RTX_CLASS (GET_CODE (last)) == 'i')\n-\t{\n-\t  restore_constants (&PATTERN (last));\n-\t  restore_constants (&REG_NOTES (last));\n-\t}\n-    }\n+  /* Things we allocate from here on are part of this function, not\n+     permanent.  */\n+  temporary_allocation ();\n \n   set_new_last_label_num (f->inl_max_label_num);\n \n@@ -3375,6 +2448,6 @@ output_inline_function (fndecl)\n   /* Compile this function all the way down to assembly code.  */\n   rest_of_compilation (fndecl);\n \n-  current_function = 0;\n-  current_function_decl = 0;\n+  current_function = curf;\n+  current_function_decl = curf ? curf->decl : 0;\n }"}, {"sha": "97794d1f78139c56ba8ab51f325a22a91127a853", "filename": "gcc/output.h", "status": "modified", "additions": 0, "deletions": 3, "changes": 3, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Foutput.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Foutput.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Foutput.h?ref=36edd3cc1b6398015a97897f8e3c07896a5921d4", "patch": "@@ -309,9 +309,6 @@ extern void defer_addressed_constants\tPROTO((void));\n    and output now all those that have been deferred.  */\n extern void output_deferred_addressed_constants PROTO((void));\n \n-/* Initialize constant pool hashing for next function.  */\n-extern void init_const_rtx_hash_table\tPROTO((void));\n-\n /* Return the size of the constant pool.  */\n extern int get_pool_size\t\tPROTO((void));\n "}, {"sha": "acb9f756bb86496d6c95d084093485f46599fe3c", "filename": "gcc/rtl.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Frtl.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Frtl.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Frtl.h?ref=36edd3cc1b6398015a97897f8e3c07896a5921d4", "patch": "@@ -21,6 +21,8 @@ Boston, MA 02111-1307, USA.  */\n #ifndef _RTL_H\n #define _RTL_H\n \n+struct function;\n+\n #include \"machmode.h\"\n \n #undef FFS  /* Some systems predefine this symbol; don't let it interfere.  */\n@@ -1001,6 +1003,8 @@ extern rtx force_const_mem\t\tPROTO((enum machine_mode, rtx));\n extern rtx force_reg\t\t\tPROTO((enum machine_mode, rtx));\n extern rtx get_pool_constant\t\tPROTO((rtx));\n extern enum machine_mode get_pool_mode\tPROTO((rtx));\n+extern rtx get_pool_constant_for_function\tPROTO((struct function *, rtx));\n+extern enum machine_mode get_pool_mode_for_function\tPROTO((struct function *, rtx));\n extern int get_pool_offset\t\tPROTO((rtx));\n extern rtx simplify_subtraction\t\tPROTO((rtx));\n extern rtx assign_stack_local\t\tPROTO((enum machine_mode,"}, {"sha": "3534da7f6e970cf4647fa9d4be728a035c180fba", "filename": "gcc/toplev.c", "status": "modified", "additions": 8, "deletions": 56, "changes": 64, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Ftoplev.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Ftoplev.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftoplev.c?ref=36edd3cc1b6398015a97897f8e3c07896a5921d4", "patch": "@@ -3648,30 +3648,16 @@ rest_of_compilation (decl)\n \t compile it by itself, defer decision till end of compilation.\n \t finish_compilation will call rest_of_compilation again\n \t for those functions that need to be output.  Also defer those\n-\t functions that we are supposed to defer.  We cannot defer\n-\t functions containing nested functions since the nested function\n-\t data is in our non-saved obstack.  We cannot defer nested\n-\t functions for the same reason.  */\n-\n-      /* If this is a nested inline, remove ADDRESSOF now so we can\n-\t finish compiling ourselves.  Otherwise, wait until EOF.\n-\t We have to do this because the purge_addressof transformation\n-\t changes the DECL_RTL for many variables, which confuses integrate.\n-\t Also, save_for_inline_copying can be very expensive.  */\n+\t functions that we are supposed to defer.  */\n+\n       if (inlinable)\n-\t{\n-\t  if (decl_function_context (decl))\n-\t    purge_addressof (insns);\n-\t  else\n-\t    DECL_DEFER_OUTPUT (decl) = 1;\n-\t}\n+\tDECL_DEFER_OUTPUT (decl) = 1;\n \n-      if (! current_function_contains_functions\n-\t  && (DECL_DEFER_OUTPUT (decl)\n-\t      || (DECL_INLINE (decl)\n-\t\t  && ((! TREE_PUBLIC (decl) && ! TREE_ADDRESSABLE (decl)\n-\t\t       && ! flag_keep_inline_functions)\n-\t\t      || DECL_EXTERNAL (decl)))))\n+      if (DECL_DEFER_OUTPUT (decl)\n+\t  || (DECL_INLINE (decl)\n+\t      && ((! TREE_PUBLIC (decl) && ! TREE_ADDRESSABLE (decl)\n+\t\t   && ! flag_keep_inline_functions)\n+\t\t  || DECL_EXTERNAL (decl))))\n \t{\n \t  DECL_DEFER_OUTPUT (decl) = 1;\n \n@@ -3720,40 +3706,6 @@ rest_of_compilation (decl)\n \t  goto exit_rest_of_compilation;\n \t}\n \n-      /* If we have to compile the function now, save its rtl and subdecls\n-\t so that its compilation will not affect what others get.  */\n-      if (inlinable || DECL_DEFER_OUTPUT (decl))\n-\t{\n-#ifdef DWARF_DEBUGGING_INFO\n-\t  /* Generate the DWARF info for the \"abstract\" instance of\n-\t     a function which we will generate an out-of-line instance\n-\t     of almost immediately (and which we may also later generate\n-\t     various inlined instances of).  */\n-\t  if (write_symbols == DWARF_DEBUG)\n-\t    {\n-\t      set_decl_abstract_flags (decl, 1);\n-\t      TIMEVAR (symout_time, dwarfout_file_scope_decl (decl, 0));\n-\t      set_decl_abstract_flags (decl, 0);\n-\t    }\n-#endif\n-#ifdef DWARF2_DEBUGGING_INFO\n-\t  /* Generate the DWARF2 info for the \"abstract\" instance of\n-\t     a function which we will generate an out-of-line instance\n-\t     of almost immediately (and which we may also later generate\n-\t     various inlined instances of).  */\n-\t  if (write_symbols == DWARF2_DEBUG)\n-\t    {\n-\t      set_decl_abstract_flags (decl, 1);\n-\t      TIMEVAR (symout_time, dwarf2out_decl (decl));\n-\t      set_decl_abstract_flags (decl, 0);\n-\t    }\n-#endif\n-\t  saved_block_tree = DECL_INITIAL (decl);\n-\t  saved_arguments = DECL_ARGUMENTS (decl);\n-\t  TIMEVAR (integration_time, save_for_inline_copying (decl));\n-\t  DECL_SAVED_INSNS (decl)->inlinable = inlinable;\n-\t}\n-\n       /* If specified extern inline but we aren't inlining it, we are\n \t done.  This goes for anything that gets here with DECL_EXTERNAL\n \t set, not just things with DECL_INLINE.  */"}, {"sha": "e280190fcd5bf371c97ccab686b7e24a5dd71365", "filename": "gcc/tree.c", "status": "modified", "additions": 11, "deletions": 133, "changes": 144, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Ftree.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Ftree.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftree.c?ref=36edd3cc1b6398015a97897f8e3c07896a5921d4", "patch": "@@ -64,21 +64,6 @@ struct obstack *function_maybepermanent_obstack;\n \n struct obstack maybepermanent_obstack;\n \n-/* This is a list of function_maybepermanent_obstacks for top-level inline\n-   functions that are compiled in the middle of compiling other functions.  */\n-\n-struct simple_obstack_stack *toplev_inline_obstacks;\n-\n-/* Former elements of toplev_inline_obstacks that have been recycled.  */\n-\n-struct simple_obstack_stack *extra_inline_obstacks;\n-\n-/* This is a list of function_maybepermanent_obstacks for inline functions\n-   nested in the current function that were compiled in the middle of\n-   compiling other functions.  */\n-\n-struct simple_obstack_stack *inline_obstacks;\n-\n /* The contents of the current function definition are allocated\n    in this obstack, and all are freed at the end of the function.\n    For top-level functions, this is temporary_obstack.\n@@ -331,9 +316,8 @@ gcc_obstack_init (obstack)\n    compile; if it isn't current_function_decl, we have to play some games.  */\n \n void\n-save_tree_status (p, context)\n+save_tree_status (p)\n      struct function *p;\n-     tree context;\n {\n   p->all_types_permanent = all_types_permanent;\n   p->momentary_stack = momentary_stack;\n@@ -347,50 +331,10 @@ save_tree_status (p, context)\n   p->expression_obstack = expression_obstack;\n   p->saveable_obstack = saveable_obstack;\n   p->rtl_obstack = rtl_obstack;\n-  p->inline_obstacks = inline_obstacks;\n-\n-  if (current_function_decl && context == current_function_decl)\n-    /* Objects that need to be saved in this function can be in the nonsaved\n-       obstack of the enclosing function since they can't possibly be needed\n-       once it has returned.  */\n-    function_maybepermanent_obstack = function_obstack;\n-  else\n-    {\n-      /* We're compiling a function which isn't nested in the current\n-         function.  We need to create a new maybepermanent_obstack for this\n-         function, since it can't go onto any of the existing obstacks.  */\n-      struct simple_obstack_stack **head;\n-      struct simple_obstack_stack *current;\n-\n-      if (context == NULL_TREE)\n-\thead = &toplev_inline_obstacks;\n-      else\n-\t{\n-\t  struct function *f = find_function_data (context);\n-\t  head = &f->inline_obstacks;\n-\t}\n-\n-      if (context == NULL_TREE && extra_inline_obstacks)\n-\t{\n-\t  current = extra_inline_obstacks;\n-\t  extra_inline_obstacks = current->next;\n-\t}\n-      else\n-\t{\n-\t  current = ((struct simple_obstack_stack *)\n-\t\t     xmalloc (sizeof (struct simple_obstack_stack)));\n-\n-\t  current->obstack\n-\t    = (struct obstack *) xmalloc (sizeof (struct obstack));\n-\t  gcc_obstack_init (current->obstack);\n-\t}\n-\n-      function_maybepermanent_obstack = current->obstack;\n-\n-      current->next = *head;\n-      *head = current;\n-    }      \n \n+  function_maybepermanent_obstack\n+    = (struct obstack *) xmalloc (sizeof (struct obstack));\n+  gcc_obstack_init (function_maybepermanent_obstack);\n   maybepermanent_firstobj\n     = (char *) obstack_finish (function_maybepermanent_obstack);\n \n@@ -410,51 +354,25 @@ save_tree_status (p, context)\n    This is used after a nested function.  */\n \n void\n-restore_tree_status (p, context)\n+restore_tree_status (p)\n      struct function *p;\n-     tree context;\n {\n   all_types_permanent = p->all_types_permanent;\n   momentary_stack = p->momentary_stack;\n \n   obstack_free (&momentary_obstack, momentary_function_firstobj);\n \n   /* Free saveable storage used by the function just compiled and not\n-     saved.\n-\n-     CAUTION: This is in function_obstack of the containing function.\n-     So we must be sure that we never allocate from that obstack during\n-     the compilation of a nested function if we expect it to survive\n-     past the nested function's end.  */\n+     saved.  */\n   obstack_free (function_maybepermanent_obstack, maybepermanent_firstobj);\n \n-  /* If we were compiling a toplevel function, we can free this space now.  */\n-  if (context == NULL_TREE)\n-    {\n-      obstack_free (&temporary_obstack, temporary_firstobj);\n-      obstack_free (&momentary_obstack, momentary_function_firstobj);\n-    }\n-\n-  /* If we were compiling a toplevel function that we don't actually want\n-     to save anything from, return the obstack to the pool.  */\n-  if (context == NULL_TREE\n-      && obstack_empty_p (function_maybepermanent_obstack))\n-    {\n-      struct simple_obstack_stack *current, **p = &toplev_inline_obstacks;\n-\n-      if ((*p) != NULL)\n-\t{\n-\t  while ((*p)->obstack != function_maybepermanent_obstack)\n-\t    p = &((*p)->next);\n-\t  current = *p;\n-\t  *p = current->next;\n-\n-\t  current->next = extra_inline_obstacks;\n-\t  extra_inline_obstacks = current;\n-\t}\n-    }\n+  obstack_free (&temporary_obstack, temporary_firstobj);\n+  obstack_free (&momentary_obstack, momentary_function_firstobj);\n \n   obstack_free (function_obstack, 0);\n+\n+  if (obstack_empty_p (function_maybepermanent_obstack))\n+    free (function_maybepermanent_obstack);\n   free (function_obstack);\n \n   temporary_firstobj = p->temporary_firstobj;\n@@ -467,7 +385,6 @@ restore_tree_status (p, context)\n   expression_obstack = p->expression_obstack;\n   saveable_obstack = p->saveable_obstack;\n   rtl_obstack = p->rtl_obstack;\n-  inline_obstacks = p->inline_obstacks;\n }\n \f\n /* Start allocating on the temporary (per function) obstack.\n@@ -484,7 +401,6 @@ temporary_allocation ()\n   expression_obstack = function_obstack;\n   rtl_obstack = saveable_obstack = function_maybepermanent_obstack;\n   momentary_stack = 0;\n-  inline_obstacks = 0;\n }\n \n /* Start allocating on the permanent obstack but don't\n@@ -612,17 +528,6 @@ permanent_allocation (function_end)\n   obstack_free (function_maybepermanent_obstack, maybepermanent_firstobj);\n   obstack_free (&temp_decl_obstack, temp_decl_firstobj);\n \n-  /* Free up the maybepermanent_obstacks for any of our nested functions\n-     which were compiled at a lower level.  */\n-  while (inline_obstacks)\n-    {\n-      struct simple_obstack_stack *current = inline_obstacks;\n-      inline_obstacks = current->next;\n-      obstack_free (current->obstack, 0);\n-      free (current->obstack);\n-      free (current);\n-    }\n-\n   current_obstack = &permanent_obstack;\n   expression_obstack = &permanent_obstack;\n   rtl_obstack = saveable_obstack = &permanent_obstack;\n@@ -4751,32 +4656,6 @@ decl_type_context (decl)\n   return NULL_TREE;\n }\n \n-/* Print debugging information about the size of the\n-   toplev_inline_obstacks.  */\n-\n-void\n-print_inline_obstack_statistics ()\n-{\n-  struct simple_obstack_stack *current = toplev_inline_obstacks;\n-  int n_obstacks = 0;\n-  int n_alloc = 0;\n-  int n_chunks = 0;\n-\n-  for (; current; current = current->next, ++n_obstacks)\n-    {\n-      struct obstack *o = current->obstack;\n-      struct _obstack_chunk *chunk = o->chunk;\n-\n-      n_alloc += o->next_free - chunk->contents;\n-      chunk = chunk->prev;\n-      ++n_chunks;\n-      for (; chunk; chunk = chunk->prev, ++n_chunks)\n-\tn_alloc += chunk->limit - &chunk->contents[0];\n-    }\n-  fprintf (stderr, \"inline obstacks: %d obstacks, %d bytes, %d chunks\\n\",\n-\t   n_obstacks, n_alloc, n_chunks);\n-}\n-\n /* Print debugging information about the obstack O, named STR.  */\n \n void\n@@ -4835,7 +4714,6 @@ dump_tree_statistics ()\n   print_obstack_statistics (\"temporary_obstack\", &temporary_obstack);\n   print_obstack_statistics (\"momentary_obstack\", &momentary_obstack);\n   print_obstack_statistics (\"temp_decl_obstack\", &temp_decl_obstack);\n-  print_inline_obstack_statistics ();\n   print_lang_statistics ();\n }\n \f"}, {"sha": "e7df584a147f2fc4eb285b9a3883c16f7c5178a3", "filename": "gcc/varasm.c", "status": "modified", "additions": 112, "deletions": 135, "changes": 247, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Fvarasm.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/36edd3cc1b6398015a97897f8e3c07896a5921d4/gcc%2Fvarasm.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fvarasm.c?ref=36edd3cc1b6398015a97897f8e3c07896a5921d4", "patch": "@@ -85,6 +85,48 @@ extern struct obstack *rtl_obstack;\n extern struct obstack permanent_obstack;\n #define obstack_chunk_alloc xmalloc\n \n+struct addr_const;\n+struct constant_descriptor;\n+struct rtx_const;\n+struct pool_constant;\n+\n+#define MAX_RTX_HASH_TABLE 61\n+\n+struct varasm_status\n+{\n+  /* Hash facility for making memory-constants\n+     from constant rtl-expressions.  It is used on RISC machines\n+     where immediate integer arguments and constant addresses are restricted\n+     so that such constants must be stored in memory.\n+\n+     This pool of constants is reinitialized for each function\n+     so each function gets its own constants-pool that comes right before\n+     it.  */\n+  struct constant_descriptor **x_const_rtx_hash_table;\n+  struct pool_sym **x_const_rtx_sym_hash_table;\n+\n+  /* Pointers to first and last constant in pool.  */\n+  struct pool_constant *x_first_pool, *x_last_pool;\n+\n+  /* Current offset in constant pool (does not include any machine-specific\n+     header.  */\n+  int x_pool_offset;\n+\n+  /* Chain of all CONST_DOUBLE rtx's constructed for the current function.\n+     They are chained through the CONST_DOUBLE_CHAIN.\n+     A CONST_DOUBLE rtx has CONST_DOUBLE_MEM != cc0_rtx iff it is on this chain.\n+     In that case, CONST_DOUBLE_MEM is either a MEM,\n+     or const0_rtx if no MEM has been made for this CONST_DOUBLE yet.  */\n+  rtx x_const_double_chain;\n+};\n+\n+#define const_rtx_hash_table (current_function->varasm->x_const_rtx_hash_table)\n+#define const_rtx_sym_hash_table (current_function->varasm->x_const_rtx_sym_hash_table)\n+#define first_pool (current_function->varasm->x_first_pool)\n+#define last_pool (current_function->varasm->x_last_pool)\n+#define pool_offset (current_function->varasm->x_pool_offset)\n+#define const_double_chain (current_function->varasm->x_const_double_chain)\n+\n /* Number for making the label on the next\n    constant that is stored in memory.  */\n \n@@ -111,11 +153,6 @@ tree last_assemble_variable_decl;\n \n static int function_defined;\n \n-struct addr_const;\n-struct constant_descriptor;\n-struct rtx_const;\n-struct pool_constant;\n-\n static const char *strip_reg_name\tPROTO((const char *));\n static int contains_pointers_p\t\tPROTO((tree));\n static void decode_addr_const\t\tPROTO((tree, struct addr_const *));\n@@ -134,7 +171,7 @@ static int compare_constant_rtx\t\tPROTO((enum machine_mode, rtx,\n \t\t\t\t\t       struct constant_descriptor *));\n static struct constant_descriptor *record_constant_rtx PROTO((enum machine_mode,\n \t\t\t\t\t\t\t      rtx));\n-static struct pool_constant *find_pool_constant PROTO((rtx));\n+static struct pool_constant *find_pool_constant PROTO((struct function *, rtx));\n static void mark_constant_pool\t\tPROTO((void));\n static void mark_constants\t\tPROTO((rtx));\n static int output_addressed_constants\tPROTO((tree));\n@@ -1960,17 +1997,6 @@ assemble_real (d, mode)\n /* Here we combine duplicate floating constants to make\n    CONST_DOUBLE rtx's, and force those out to memory when necessary.  */\n \n-/* Chain of all CONST_DOUBLE rtx's constructed for the current function.\n-   They are chained through the CONST_DOUBLE_CHAIN.\n-   A CONST_DOUBLE rtx has CONST_DOUBLE_MEM != cc0_rtx iff it is on this chain.\n-   In that case, CONST_DOUBLE_MEM is either a MEM,\n-   or const0_rtx if no MEM has been made for this CONST_DOUBLE yet.\n-\n-   (CONST_DOUBLE_MEM is used only for top-level functions.\n-   See force_const_mem for explanation.)  */\n-\n-static rtx const_double_chain;\n-\n /* Return a CONST_DOUBLE or CONST_INT for a value specified as a pair of ints.\n    For an integer, I0 is the low-order word and I1 is the high-order word.\n    For a real number, I0 is the word with the low address\n@@ -2045,11 +2071,11 @@ immed_double_const (i0, i1, mode)\n \n   /* Search the chain for an existing CONST_DOUBLE with the right value.\n      If one is found, return it.  */\n-\n-  for (r = const_double_chain; r; r = CONST_DOUBLE_CHAIN (r))\n-    if (CONST_DOUBLE_LOW (r) == i0 && CONST_DOUBLE_HIGH (r) == i1\n-\t&& GET_MODE (r) == mode)\n-      return r;\n+  if (current_function != 0)\n+    for (r = const_double_chain; r; r = CONST_DOUBLE_CHAIN (r))\n+      if (CONST_DOUBLE_LOW (r) == i0 && CONST_DOUBLE_HIGH (r) == i1\n+\t  && GET_MODE (r) == mode)\n+\treturn r;\n \n   /* No; make a new one and add it to the chain.\n \n@@ -2064,9 +2090,8 @@ immed_double_const (i0, i1, mode)\n   r = gen_rtx_CONST_DOUBLE (mode, NULL_RTX, i0, i1);\n   pop_obstacks ();\n \n-  /* Don't touch const_double_chain in nested function; see force_const_mem.\n-     Also, don't touch it if not inside any function.  */\n-  if (outer_function_chain == 0 && current_function_decl != 0)\n+  /* Don't touch const_double_chain if not inside any function.  */\n+  if (current_function_decl != 0)\n     {\n       CONST_DOUBLE_CHAIN (r) = const_double_chain;\n       const_double_chain = r;\n@@ -2118,11 +2143,11 @@ immed_real_const_1 (d, mode)\n \n   /* Search the chain for an existing CONST_DOUBLE with the right value.\n      If one is found, return it.  */\n-\n-  for (r = const_double_chain; r; r = CONST_DOUBLE_CHAIN (r))\n-    if (! bcmp ((char *) &CONST_DOUBLE_LOW (r), (char *) &u, sizeof u)\n-\t&& GET_MODE (r) == mode)\n-      return r;\n+  if (current_function != 0)\n+    for (r = const_double_chain; r; r = CONST_DOUBLE_CHAIN (r))\n+      if (! bcmp ((char *) &CONST_DOUBLE_LOW (r), (char *) &u, sizeof u)\n+\t  && GET_MODE (r) == mode)\n+\treturn r;\n \n   /* No; make a new one and add it to the chain.\n \n@@ -2131,17 +2156,15 @@ immed_real_const_1 (d, mode)\n      we will be leaving this constant on the chain, so we cannot tolerate\n      freed memory.  So switch to saveable_obstack for this allocation\n      and then switch back if we were in current_obstack.  */\n-\n   push_obstacks_nochange ();\n   rtl_in_saveable_obstack ();\n   r = rtx_alloc (CONST_DOUBLE);\n+  pop_obstacks ();\n   PUT_MODE (r, mode);\n   bcopy ((char *) &u, (char *) &CONST_DOUBLE_LOW (r), sizeof u);\n-  pop_obstacks ();\n \n-  /* Don't touch const_double_chain in nested function; see force_const_mem.\n-     Also, don't touch it if not inside any function.  */\n-  if (outer_function_chain == 0 && current_function_decl != 0)\n+  /* Don't touch const_double_chain if not inside any function.  */\n+  if (current_function_decl != 0)\n     {\n       CONST_DOUBLE_CHAIN (r) = const_double_chain;\n       const_double_chain = r;\n@@ -2175,11 +2198,6 @@ clear_const_double_mem ()\n {\n   register rtx r, next;\n \n-  /* Don't touch CONST_DOUBLE_MEM for nested functions.\n-     See force_const_mem for explanation.  */\n-  if (outer_function_chain != 0)\n-    return;\n-\n   for (r = const_double_chain; r; r = next)\n     {\n       next = CONST_DOUBLE_CHAIN (r);\n@@ -3110,20 +3128,6 @@ output_constant_def_contents (exp, reloc, labelno)\n \n }\n \f\n-/* Similar hash facility for making memory-constants\n-   from constant rtl-expressions.  It is used on RISC machines\n-   where immediate integer arguments and constant addresses are restricted\n-   so that such constants must be stored in memory.\n-\n-   This pool of constants is reinitialized for each function\n-   so each function gets its own constants-pool that comes right before it.\n-\n-   All structures allocated here are discarded when functions are saved for\n-   inlining, so they do not need to be allocated permanently.  */\n-\n-#define MAX_RTX_HASH_TABLE 61\n-static struct constant_descriptor **const_rtx_hash_table;\n-\n /* Structure to represent sufficient information about a constant so that\n    it can be output when the constant pool is output, so that function\n    integration can be done, and to simplify handling on machines that reference\n@@ -3141,15 +3145,6 @@ struct pool_constant\n   int mark;\n };\n \n-/* Pointers to first and last constant in pool.  */\n-\n-static struct pool_constant *first_pool, *last_pool;\n-\n-/* Current offset in constant pool (does not include any machine-specific\n-   header.  */\n-\n-static int pool_offset;\n-\n /* Structure used to maintain hash table mapping symbols used to their\n    corresponding constants.  */\n \n@@ -3160,63 +3155,35 @@ struct pool_sym\n   struct pool_sym *next;\n };\n \n-static struct pool_sym **const_rtx_sym_hash_table;\n-\n /* Hash code for a SYMBOL_REF with CONSTANT_POOL_ADDRESS_P true.\n    The argument is XSTR (... , 0)  */\n \n #define SYMHASH(LABEL)\t\\\n   ((((unsigned long) (LABEL)) & ((1 << HASHBITS) - 1))  % MAX_RTX_HASH_TABLE)\n \f\n-/* Initialize constant pool hashing for next function.  */\n+/* Initialize constant pool hashing for a new function.  */\n \n void\n-init_const_rtx_hash_table ()\n+init_varasm_status (f)\n+     struct function *f;\n {\n-  const_rtx_hash_table\n+  struct varasm_status *p;\n+  p = (struct varasm_status *) xmalloc (sizeof (struct varasm_status));\n+  f->varasm = p;\n+  p->x_const_rtx_hash_table\n     = ((struct constant_descriptor **)\n-       oballoc (MAX_RTX_HASH_TABLE * sizeof (struct constant_descriptor *)));\n-  const_rtx_sym_hash_table\n+       xmalloc (MAX_RTX_HASH_TABLE * sizeof (struct constant_descriptor *)));\n+  p->x_const_rtx_sym_hash_table\n     = ((struct pool_sym **)\n-       oballoc (MAX_RTX_HASH_TABLE * sizeof (struct pool_sym *)));\n-  bzero ((char *) const_rtx_hash_table,\n+       xmalloc (MAX_RTX_HASH_TABLE * sizeof (struct pool_sym *)));\n+  bzero ((char *) p->x_const_rtx_hash_table,\n \t MAX_RTX_HASH_TABLE * sizeof (struct constant_descriptor *));\n-  bzero ((char *) const_rtx_sym_hash_table,\n+  bzero ((char *) p->x_const_rtx_sym_hash_table,\n \t MAX_RTX_HASH_TABLE * sizeof (struct pool_sym *));\n \n-  first_pool = last_pool = 0;\n-  pool_offset = 0;\n-}\n-\n-/* Save and restore status for a nested function.  */\n-\n-void\n-save_varasm_status (p, context)\n-     struct function *p;\n-     tree context;\n-{\n-  p->const_rtx_hash_table = const_rtx_hash_table;\n-  p->const_rtx_sym_hash_table = const_rtx_sym_hash_table;\n-  p->first_pool = first_pool;\n-  p->last_pool = last_pool;\n-  p->pool_offset = pool_offset;\n-  p->const_double_chain = const_double_chain;\n-\n-  /* If we are pushing to toplevel, we can't reuse const_double_chain.  */\n-  if (context == NULL_TREE)\n-    const_double_chain = 0;\n-}\n-\n-void\n-restore_varasm_status (p)\n-     struct function *p;\n-{\n-  const_rtx_hash_table = p->const_rtx_hash_table;\n-  const_rtx_sym_hash_table = p->const_rtx_sym_hash_table;\n-  first_pool = p->first_pool;\n-  last_pool = p->last_pool;\n-  pool_offset = p->pool_offset;\n-  const_double_chain = p->const_double_chain;\n+  p->x_first_pool = p->x_last_pool = 0;\n+  p->x_pool_offset = 0;\n+  p->x_const_double_chain = 0;\n }\n \f\n enum kind { RTX_DOUBLE, RTX_INT };\n@@ -3439,15 +3406,10 @@ force_const_mem (mode, x)\n      modes in an alternating fashion, we will allocate a lot of different\n      memory locations, but this should be extremely rare.  */\n \n-  /* Don't use CONST_DOUBLE_MEM in a nested function.\n-     Nested functions have their own constant pools,\n-     so they can't share the same values in CONST_DOUBLE_MEM\n-     with the containing function.  */\n-  if (outer_function_chain == 0)\n-    if (GET_CODE (x) == CONST_DOUBLE\n-\t&& GET_CODE (CONST_DOUBLE_MEM (x)) == MEM\n-\t&& GET_MODE (CONST_DOUBLE_MEM (x)) == mode)\n-      return CONST_DOUBLE_MEM (x);\n+  if (GET_CODE (x) == CONST_DOUBLE\n+      && GET_CODE (CONST_DOUBLE_MEM (x)) == MEM\n+      && GET_MODE (CONST_DOUBLE_MEM (x)) == mode)\n+    return CONST_DOUBLE_MEM (x);\n \n   /* Compute hash code of X.  Search the descriptors for that hash code\n      to see if any of them describes X.  If yes, the descriptor records\n@@ -3558,16 +3520,15 @@ force_const_mem (mode, x)\n   CONSTANT_POOL_ADDRESS_P (XEXP (def, 0)) = 1;\n   current_function_uses_const_pool = 1;\n \n-  if (outer_function_chain == 0)\n-    if (GET_CODE (x) == CONST_DOUBLE)\n-      {\n-\tif (CONST_DOUBLE_MEM (x) == cc0_rtx)\n-\t  {\n-\t    CONST_DOUBLE_CHAIN (x) = const_double_chain;\n-\t    const_double_chain = x;\n-\t  }\n-\tCONST_DOUBLE_MEM (x) = def;\n-      }\n+  if (GET_CODE (x) == CONST_DOUBLE)\n+    {\n+      if (CONST_DOUBLE_MEM (x) == cc0_rtx)\n+\t{\n+\t  CONST_DOUBLE_CHAIN (x) = const_double_chain;\n+\t  const_double_chain = x;\n+\t}\n+      CONST_DOUBLE_MEM (x) = def;\n+    }\n \n   return def;\n }\n@@ -3576,13 +3537,14 @@ force_const_mem (mode, x)\n    the corresponding pool_constant structure.  */\n \n static struct pool_constant *\n-find_pool_constant (addr)\n+find_pool_constant (f, addr)\n+     struct function *f;\n      rtx addr;\n {\n   struct pool_sym *sym;\n   char *label = XSTR (addr, 0);\n \n-  for (sym = const_rtx_sym_hash_table[SYMHASH (label)]; sym; sym = sym->next)\n+  for (sym = f->varasm->x_const_rtx_sym_hash_table[SYMHASH (label)]; sym; sym = sym->next)\n     if (sym->label == label)\n       return sym->pool;\n \n@@ -3595,7 +3557,17 @@ rtx\n get_pool_constant (addr)\n      rtx addr;\n {\n-  return (find_pool_constant (addr))->constant;\n+  return (find_pool_constant (current_function, addr))->constant;\n+}\n+\n+/* Likewise, but for the constant pool of a specific function.  */\n+\n+rtx\n+get_pool_constant_for_function (f, addr)\n+     struct function *f;\n+     rtx addr;\n+{\n+  return (find_pool_constant (f, addr))->constant;\n }\n \n /* Similar, return the mode.  */\n@@ -3604,7 +3576,15 @@ enum machine_mode\n get_pool_mode (addr)\n      rtx addr;\n {\n-  return (find_pool_constant (addr))->mode;\n+  return (find_pool_constant (current_function, addr))->mode;\n+}\n+\n+enum machine_mode\n+get_pool_mode_for_function (f, addr)\n+     struct function *f;\n+     rtx addr;\n+{\n+  return (find_pool_constant (f, addr))->mode;\n }\n \n /* Similar, return the offset in the constant pool.  */\n@@ -3613,7 +3593,7 @@ int\n get_pool_offset (addr)\n      rtx addr;\n {\n-  return (find_pool_constant (addr))->offset;\n+  return (find_pool_constant (current_function, addr))->offset;\n }\n \n /* Return the size of the constant pool.  */\n@@ -3786,14 +3766,11 @@ mark_constants (x)\n   if (GET_CODE (x) == SYMBOL_REF)\n     {\n       if (CONSTANT_POOL_ADDRESS_P (x))\n-\tfind_pool_constant (x)->mark = 1;\n+\tfind_pool_constant (current_function, x)->mark = 1;\n       return;\n     }\n   /* Never search inside a CONST_DOUBLE, because CONST_DOUBLE_MEM may be\n-     a MEM, but does not constitute a use of that MEM.  This is particularly\n-     important inside a nested function, because CONST_DOUBLE_MEM may be\n-     a reference to a MEM in the parent's constant pool.  See the comment\n-     in force_const_mem.  */\n+     a MEM, but does not constitute a use of that MEM.  */\n   else if (GET_CODE (x) == CONST_DOUBLE)\n     return;\n "}]}