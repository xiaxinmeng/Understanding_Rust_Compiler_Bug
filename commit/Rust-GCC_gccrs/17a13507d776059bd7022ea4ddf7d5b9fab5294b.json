{"sha": "17a13507d776059bd7022ea4ddf7d5b9fab5294b", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MTdhMTM1MDdkNzc2MDU5YmQ3MDIyZWE0ZGRmN2Q1YjlmYWI1Mjk0Yg==", "commit": {"author": {"name": "Mihail Ionescu", "email": "mihail.ionescu@arm.com", "date": "2020-02-27T16:00:48Z"}, "committer": {"name": "Mihail Ionescu", "email": "mihail.ionescu@arm.com", "date": "2020-02-27T17:23:04Z"}, "message": " [GCC][PATCH][ARM] Add vreinterpret, vdup, vget and vset bfloat16 intrinsics\n\nThis patch adds support for the bf16 vector create, get, set,\nduplicate and reinterpret intrinsics.\nACLE documents are at https://developer.arm.com/docs/101028/latest\nISA documents are at https://developer.arm.com/docs/ddi0596/latest\n\ngcc/ChangeLog:\n\n2020-02-27  Mihail Ionescu  <mihail.ionescu@arm.com>\n\n\t* (__ARM_NUM_LANES, __arm_lane, __arm_lane_q): Move to the\n\tbeginning of the file.\n\t(vcreate_bf16, vcombine_bf16): New.\n\t(vdup_n_bf16, vdupq_n_bf16): New.\n\t(vdup_lane_bf16, vdup_laneq_bf16): New.\n\t(vdupq_lane_bf16, vdupq_laneq_bf16): New.\n\t(vduph_lane_bf16, vduph_laneq_bf16): New.\n\t(vset_lane_bf16, vsetq_lane_bf16): New.\n\t(vget_lane_bf16, vgetq_lane_bf16): New.\n\t(vget_high_bf16, vget_low_bf16): New.\n\t(vreinterpret_bf16_u8, vreinterpretq_bf16_u8): New.\n\t(vreinterpret_bf16_u16, vreinterpretq_bf16_u16): New.\n\t(vreinterpret_bf16_u32, vreinterpretq_bf16_u32): New.\n\t(vreinterpret_bf16_u64, vreinterpretq_bf16_u64): New.\n\t(vreinterpret_bf16_s8, vreinterpretq_bf16_s8): New.\n\t(vreinterpret_bf16_s16, vreinterpretq_bf16_s16): New.\n\t(vreinterpret_bf16_s32, vreinterpretq_bf16_s32): New.\n\t(vreinterpret_bf16_s64, vreinterpretq_bf16_s64): New.\n\t(vreinterpret_bf16_p8, vreinterpretq_bf16_p8): New.\n\t(vreinterpret_bf16_p16, vreinterpretq_bf16_p16): New.\n\t(vreinterpret_bf16_p64, vreinterpretq_bf16_p64): New.\n\t(vreinterpret_bf16_f32, vreinterpretq_bf16_f32): New.\n\t(vreinterpret_bf16_f64, vreinterpretq_bf16_f64): New.\n\t(vreinterpretq_bf16_p128): New.\n\t(vreinterpret_s8_bf16, vreinterpretq_s8_bf16): New.\n\t(vreinterpret_s16_bf16, vreinterpretq_s16_bf16): New.\n\t(vreinterpret_s32_bf16, vreinterpretq_s32_bf16): New.\n\t(vreinterpret_s64_bf16, vreinterpretq_s64_bf16): New.\n\t(vreinterpret_u8_bf16, vreinterpretq_u8_bf16): New.\n\t(vreinterpret_u16_bf16, vreinterpretq_u16_bf16): New.\n\t(vreinterpret_u32_bf16, vreinterpretq_u32_bf16): New.\n\t(vreinterpret_u64_bf16, vreinterpretq_u64_bf16): New.\n\t(vreinterpret_p8_bf16, vreinterpretq_p8_bf16): New.\n\t(vreinterpret_p16_bf16, vreinterpretq_p16_bf16): New.\n\t(vreinterpret_p64_bf16, vreinterpretq_p64_bf16): New.\n\t(vreinterpret_f32_bf16, vreinterpretq_f32_bf16): New.\n\t(vreinterpretq_p128_bf16): New.\n\t* config/arm/arm_neon_builtins.def (VDX): Add V4BF.\n\t(V_elem): Likewise.\n\t(V_elem_l): Likewise.\n\t(VD_LANE): Likewise.\n\t(VQX) Add V8BF.\n\t(V_DOUBLE): Likewise.\n\t(VDQX): Add V4BF and V8BF.\n\t(V_two_elem, V_three_elem, V_four_elem): Likewise.\n\t(V_reg): Likewise.\n\t(V_HALF): Likewise.\n\t(V_double_vector_mode): Likewise.\n\t(V_cmp_result): Likewise.\n\t(V_uf_sclr): Likewise.\n\t(V_sz_elem): Likewise.\n\t(Is_d_reg): Likewise.\n\t(V_mode_nunits): Likewise.\n\t* config/arm/neon.md (neon_vdup_lane): Enable for BFloat.\n\ngcc/testsuite/ChangeLog:\n\n2020-02-27  Mihail Ionescu  <mihail.ionescu@arm.com>\n\n\t* gcc.target/arm/bf16_dup.c: New test.\n\t* gcc.target/arm/bf16_reinterpret.c: Likewise.", "tree": {"sha": "a6e986a620756dbd5f1cdced971941f543cb52b8", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/a6e986a620756dbd5f1cdced971941f543cb52b8"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/17a13507d776059bd7022ea4ddf7d5b9fab5294b", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/17a13507d776059bd7022ea4ddf7d5b9fab5294b", "html_url": "https://github.com/Rust-GCC/gccrs/commit/17a13507d776059bd7022ea4ddf7d5b9fab5294b", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/17a13507d776059bd7022ea4ddf7d5b9fab5294b/comments", "author": null, "committer": null, "parents": [{"sha": "dc941ea9258b24c6656ea3ecc686dc1110679f71", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/dc941ea9258b24c6656ea3ecc686dc1110679f71", "html_url": "https://github.com/Rust-GCC/gccrs/commit/dc941ea9258b24c6656ea3ecc686dc1110679f71"}], "stats": {"total": 1186, "additions": 1158, "deletions": 28}, "files": [{"sha": "6a780a1df60d678f6bc6abe4ad87100c81537904", "filename": "gcc/ChangeLog", "status": "modified", "additions": 57, "deletions": 0, "changes": 57, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=17a13507d776059bd7022ea4ddf7d5b9fab5294b", "patch": "@@ -1,3 +1,60 @@\n+2020-02-27  Mihail Ionescu  <mihail.ionescu@arm.com>\n+\n+\t* (__ARM_NUM_LANES, __arm_lane, __arm_lane_q): Move to the\n+\tbeginning of the file.\n+\t(vcreate_bf16, vcombine_bf16): New.\n+\t(vdup_n_bf16, vdupq_n_bf16): New.\n+\t(vdup_lane_bf16, vdup_laneq_bf16): New.\n+\t(vdupq_lane_bf16, vdupq_laneq_bf16): New.\n+\t(vduph_lane_bf16, vduph_laneq_bf16): New.\n+\t(vset_lane_bf16, vsetq_lane_bf16): New.\n+\t(vget_lane_bf16, vgetq_lane_bf16): New.\n+\t(vget_high_bf16, vget_low_bf16): New.\n+\t(vreinterpret_bf16_u8, vreinterpretq_bf16_u8): New.\n+\t(vreinterpret_bf16_u16, vreinterpretq_bf16_u16): New.\n+\t(vreinterpret_bf16_u32, vreinterpretq_bf16_u32): New.\n+\t(vreinterpret_bf16_u64, vreinterpretq_bf16_u64): New.\n+\t(vreinterpret_bf16_s8, vreinterpretq_bf16_s8): New.\n+\t(vreinterpret_bf16_s16, vreinterpretq_bf16_s16): New.\n+\t(vreinterpret_bf16_s32, vreinterpretq_bf16_s32): New.\n+\t(vreinterpret_bf16_s64, vreinterpretq_bf16_s64): New.\n+\t(vreinterpret_bf16_p8, vreinterpretq_bf16_p8): New.\n+\t(vreinterpret_bf16_p16, vreinterpretq_bf16_p16): New.\n+\t(vreinterpret_bf16_p64, vreinterpretq_bf16_p64): New.\n+\t(vreinterpret_bf16_f32, vreinterpretq_bf16_f32): New.\n+\t(vreinterpret_bf16_f64, vreinterpretq_bf16_f64): New.\n+\t(vreinterpretq_bf16_p128): New.\n+\t(vreinterpret_s8_bf16, vreinterpretq_s8_bf16): New.\n+\t(vreinterpret_s16_bf16, vreinterpretq_s16_bf16): New.\n+\t(vreinterpret_s32_bf16, vreinterpretq_s32_bf16): New.\n+\t(vreinterpret_s64_bf16, vreinterpretq_s64_bf16): New.\n+\t(vreinterpret_u8_bf16, vreinterpretq_u8_bf16): New.\n+\t(vreinterpret_u16_bf16, vreinterpretq_u16_bf16): New.\n+\t(vreinterpret_u32_bf16, vreinterpretq_u32_bf16): New.\n+\t(vreinterpret_u64_bf16, vreinterpretq_u64_bf16): New.\n+\t(vreinterpret_p8_bf16, vreinterpretq_p8_bf16): New.\n+\t(vreinterpret_p16_bf16, vreinterpretq_p16_bf16): New.\n+\t(vreinterpret_p64_bf16, vreinterpretq_p64_bf16): New.\n+\t(vreinterpret_f32_bf16, vreinterpretq_f32_bf16): New.\n+\t(vreinterpretq_p128_bf16): New.\n+\t* config/arm/arm_neon_builtins.def (VDX): Add V4BF.\n+\t(V_elem): Likewise.\n+\t(V_elem_l): Likewise.\n+\t(VD_LANE): Likewise.\n+\t(VQX) Add V8BF.\n+\t(V_DOUBLE): Likewise.\n+\t(VDQX): Add V4BF and V8BF.\n+\t(V_two_elem, V_three_elem, V_four_elem): Likewise.\n+\t(V_reg): Likewise.\n+\t(V_HALF): Likewise.\n+\t(V_double_vector_mode): Likewise.\n+\t(V_cmp_result): Likewise.\n+\t(V_uf_sclr): Likewise.\n+\t(V_sz_elem): Likewise.\n+\t(Is_d_reg): Likewise.\n+\t(V_mode_nunits): Likewise.\n+\t* config/arm/neon.md (neon_vdup_lane): Enable for BFloat16.\n+\n 2020-02-27  Andrew Stubbs  <ams@codesourcery.com>\n \n \t* config/gcn/gcn-valu.md (VEC_SUBDWORD_MODE): New mode iterator."}, {"sha": "81c407f5152004bc74d233369dbea084eef7535a", "filename": "gcc/config/arm/arm_neon.h", "status": "modified", "additions": 520, "deletions": 12, "changes": 532, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2Fconfig%2Farm%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2Fconfig%2Farm%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm_neon.h?ref=17a13507d776059bd7022ea4ddf7d5b9fab5294b", "patch": "@@ -42,6 +42,18 @@ extern \"C\" {\n #include <arm_bf16.h>\n #include <stdint.h>\n \n+/* For big-endian, GCC's vector indices are reversed within each 64\n+   bits compared to the architectural lane indices used by Neon\n+   intrinsics.  */\n+#ifdef __ARM_BIG_ENDIAN\n+#define __ARM_NUM_LANES(__v) (sizeof (__v) / sizeof (__v[0]))\n+#define __arm_lane(__vec, __idx) (__idx ^ (__ARM_NUM_LANES(__vec) - 1))\n+#define __arm_laneq(__vec, __idx) (__idx ^ (__ARM_NUM_LANES(__vec)/2 - 1))\n+#else\n+#define __arm_lane(__vec, __idx) __idx\n+#define __arm_laneq(__vec, __idx) __idx\n+#endif\n+\n typedef __simd64_int8_t int8x8_t;\n typedef __simd64_int16_t int16x4_t;\n typedef __simd64_int32_t int32x2_t;\n@@ -6144,18 +6156,6 @@ vget_lane_s32 (int32x2_t __a, const int __b)\n    were marked always-inline so there were no call sites, the declaration\n    would nonetheless raise an error.  Hence, we must use a macro instead.  */\n \n-  /* For big-endian, GCC's vector indices are reversed within each 64\n-     bits compared to the architectural lane indices used by Neon\n-     intrinsics.  */\n-#ifdef __ARM_BIG_ENDIAN\n-#define __ARM_NUM_LANES(__v) (sizeof (__v) / sizeof (__v[0]))\n-#define __arm_lane(__vec, __idx) (__idx ^ (__ARM_NUM_LANES(__vec) - 1))\n-#define __arm_laneq(__vec, __idx) (__idx ^ (__ARM_NUM_LANES(__vec)/2 - 1))\n-#else\n-#define __arm_lane(__vec, __idx) __idx\n-#define __arm_laneq(__vec, __idx) __idx\n-#endif\n-\n #define vget_lane_f16(__v, __idx)\t\t\t\\\n   __extension__\t\t\t\t\t\t\\\n   ({\t\t\t\t\t\t\t\\\n@@ -14473,6 +14473,15 @@ vreinterpret_p16_u32 (uint32x2_t __a)\n   return (poly16x4_t)__a;\n }\n \n+#if defined (__ARM_FP16_FORMAT_IEEE) || defined (__ARM_FP16_FORMAT_ALTERNATIVE)\n+__extension__ extern __inline float16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_f16_bf16 (bfloat16x4_t __a)\n+{\n+  return (float16x4_t) __a;\n+}\n+#endif\n+\n #if defined (__ARM_FP16_FORMAT_IEEE) || defined (__ARM_FP16_FORMAT_ALTERNATIVE)\n __extension__ extern __inline float16x4_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n@@ -15685,6 +15694,15 @@ vreinterpretq_f16_p16 (poly16x8_t __a)\n }\n #endif\n \n+#if defined (__ARM_FP16_FORMAT_IEEE) || defined (__ARM_FP16_FORMAT_ALTERNATIVE)\n+__extension__ extern __inline float16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_f16_bf16 (bfloat16x8_t __a)\n+{\n+  return (float16x8_t) __a;\n+}\n+#endif\n+\n #if defined (__ARM_FP16_FORMAT_IEEE) || defined (__ARM_FP16_FORMAT_ALTERNATIVE)\n __extension__ extern __inline float16x8_t\n __attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n@@ -18823,6 +18841,496 @@ vusmmlaq_s32 (int32x4_t __r, uint8x16_t __a, int8x16_t __b)\n #pragma GCC push_options\n #pragma GCC target (\"arch=armv8.2-a+bf16\")\n \n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vcreate_bf16 (uint64_t __a)\n+{\n+  return (bfloat16x4_t) __a;\n+}\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vdup_n_bf16 (bfloat16_t __a)\n+{\n+  return __builtin_neon_vdup_nv4bf (__a);\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vdupq_n_bf16 (bfloat16_t __a)\n+{\n+  return __builtin_neon_vdup_nv8bf (__a);\n+}\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vdup_lane_bf16 (bfloat16x4_t __a, const int __b)\n+{\n+  return __builtin_neon_vdup_lanev4bf (__a, __b);\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vdupq_lane_bf16 (bfloat16x4_t __a, const int __b)\n+{\n+  return __builtin_neon_vdup_lanev8bf (__a, __b);\n+}\n+\n+#define vset_lane_bf16(__e, __v, __idx)\t\t\\\n+  __extension__\t\t\t\t\t\\\n+  ({\t\t\t\t\t\t\\\n+    bfloat16_t __elem = (__e);\t\t\t\\\n+    bfloat16x4_t __vec = (__v);\t\t\t\\\n+    __builtin_arm_lane_check (4, __idx);\t\\\n+    __vec[__arm_lane(__vec, __idx)] = __elem;\t\\\n+    __vec;\t\t\t\t\t\\\n+  })\n+\n+#define vsetq_lane_bf16(__e, __v, __idx)\t\t\\\n+  __extension__\t\t\t\t\t\\\n+  ({\t\t\t\t\t\t\\\n+    bfloat16_t __elem = (__e);\t\t\t\\\n+    bfloat16x8_t __vec = (__v);\t\t\t\\\n+    __builtin_arm_lane_check (8, __idx);\t\\\n+    __vec[__arm_laneq(__vec, __idx)] = __elem;\t\\\n+    __vec;\t\t\t\t\t\\\n+  })\n+\n+#define vget_lane_bf16(__v, __idx)\t\t\t\\\n+  __extension__\t\t\t\t\t\t\\\n+  ({\t\t\t\t\t\t\t\\\n+    bfloat16x4_t __vec = (__v);\t\t\t\t\\\n+    __builtin_arm_lane_check (4, __idx);\t\t\\\n+    bfloat16_t __res = __vec[__arm_lane(__vec, __idx)];\t\\\n+    __res;\t\t\t\t\t\t\\\n+  })\n+\n+#define vgetq_lane_bf16(__v, __idx)\t\t\t\\\n+  __extension__\t\t\t\t\t\t\\\n+  ({\t\t\t\t\t\t\t\\\n+    bfloat16x8_t __vec = (__v);\t\t\t\t\\\n+    __builtin_arm_lane_check (8, __idx);\t\t\\\n+    bfloat16_t __res = __vec[__arm_laneq(__vec, __idx)];\t\\\n+    __res;\t\t\t\t\t\t\\\n+  })\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vdup_laneq_bf16 (bfloat16x8_t __a, const int __b)\n+{\n+  return vdup_n_bf16( vgetq_lane_bf16 (__a, __b));\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vdupq_laneq_bf16 (bfloat16x8_t __a, const int __b)\n+{\n+  return vdupq_n_bf16( vgetq_lane_bf16 (__a, __b));\n+}\n+\n+__extension__ extern __inline bfloat16_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vduph_lane_bf16 (bfloat16x4_t __a, const int __b)\n+{\n+  return vget_lane_bf16 (__a, __b);\n+}\n+\n+__extension__ extern __inline bfloat16_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vduph_laneq_bf16 (bfloat16x8_t __a, const int __b)\n+{\n+  return vgetq_lane_bf16 (__a, __b);\n+}\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vget_high_bf16 (bfloat16x8_t __a)\n+{\n+  return __builtin_neon_vget_highv8bf (__a);\n+}\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vget_low_bf16 (bfloat16x8_t __a)\n+{\n+  return __builtin_neon_vget_lowv8bf (__a);\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vcombine_bf16 (bfloat16x4_t __a, bfloat16x4_t __b)\n+{\n+  return __builtin_neon_vcombinev4bf (__a, __b);\n+}\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_bf16_u8 (uint8x8_t __a)\n+{\n+  return (bfloat16x4_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_bf16_u16 (uint16x4_t __a)\n+{\n+  return (bfloat16x4_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_bf16_u32 (uint32x2_t __a)\n+{\n+  return (bfloat16x4_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_bf16_u64 (uint64x1_t __a)\n+{\n+  return (bfloat16x4_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_bf16_s8 (int8x8_t __a)\n+{\n+  return (bfloat16x4_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_bf16_s16 (int16x4_t __a)\n+{\n+  return (bfloat16x4_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_bf16_s32 (int32x2_t __a)\n+{\n+  return (bfloat16x4_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_bf16_s64 (int64x1_t __a)\n+{\n+  return (bfloat16x4_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_bf16_p8 (poly8x8_t __a)\n+{\n+  return (bfloat16x4_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_bf16_p16 (poly16x4_t __a)\n+{\n+  return (bfloat16x4_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_bf16_p64 (poly64x1_t __a)\n+{\n+  return (bfloat16x4_t)__a;\n+}\n+\n+#if defined (__ARM_FP16_FORMAT_IEEE) || defined (__ARM_FP16_FORMAT_ALTERNATIVE)\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_bf16_f16 (float16x4_t __a)\n+{\n+  return (bfloat16x4_t)__a;\n+}\n+#endif\n+\n+__extension__ extern __inline bfloat16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_bf16_f32 (float32x2_t __a)\n+{\n+  return (bfloat16x4_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_bf16_u8 (uint8x16_t __a)\n+{\n+  return (bfloat16x8_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_bf16_u16 (uint16x8_t __a)\n+{\n+  return (bfloat16x8_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_bf16_u32 (uint32x4_t __a)\n+{\n+  return (bfloat16x8_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_bf16_u64 (uint64x2_t __a)\n+{\n+  return (bfloat16x8_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_bf16_s8 (int8x16_t __a)\n+{\n+  return (bfloat16x8_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_bf16_s16 (int16x8_t __a)\n+{\n+  return (bfloat16x8_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_bf16_s32 (int32x4_t __a)\n+{\n+  return (bfloat16x8_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_bf16_s64 (int64x2_t __a)\n+{\n+  return (bfloat16x8_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_bf16_p8 (poly8x16_t __a)\n+{\n+  return (bfloat16x8_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_bf16_p16 (poly16x8_t __a)\n+{\n+  return (bfloat16x8_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_bf16_p64 (poly64x2_t __a)\n+{\n+  return (bfloat16x8_t)__a;\n+}\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_bf16_p128 (poly128_t __a)\n+{\n+  return (bfloat16x8_t)__a;\n+}\n+\n+#if defined (__ARM_FP16_FORMAT_IEEE) || defined (__ARM_FP16_FORMAT_ALTERNATIVE)\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_bf16_f16 (float16x8_t __a)\n+{\n+  return (bfloat16x8_t)__a;\n+}\n+#endif\n+\n+__extension__ extern __inline bfloat16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_bf16_f32 (float32x4_t __a)\n+{\n+  return (bfloat16x8_t)__a;\n+}\n+\n+__extension__ extern __inline int8x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_s8_bf16 (bfloat16x4_t __a)\n+{\n+  return (int8x8_t)__a;\n+}\n+\n+__extension__ extern __inline int16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_s16_bf16 (bfloat16x4_t __a)\n+{\n+  return (int16x4_t)__a;\n+}\n+\n+__extension__ extern __inline int32x2_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_s32_bf16 (bfloat16x4_t __a)\n+{\n+  return (int32x2_t)__a;\n+}\n+\n+__extension__ extern __inline int64x1_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_s64_bf16 (bfloat16x4_t __a)\n+{\n+  return (int64x1_t)__a;\n+}\n+\n+__extension__ extern __inline uint8x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_u8_bf16 (bfloat16x4_t __a)\n+{\n+  return (uint8x8_t)__a;\n+}\n+\n+__extension__ extern __inline uint16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_u16_bf16 (bfloat16x4_t __a)\n+{\n+  return (uint16x4_t)__a;\n+}\n+\n+__extension__ extern __inline uint32x2_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_u32_bf16 (bfloat16x4_t __a)\n+{\n+  return (uint32x2_t)__a;\n+}\n+\n+__extension__ extern __inline uint64x1_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_u64_bf16 (bfloat16x4_t __a)\n+{\n+  return (uint64x1_t)__a;\n+}\n+\n+__extension__ extern __inline float32x2_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_f32_bf16 (bfloat16x4_t __a)\n+{\n+  return (float32x2_t)__a;\n+}\n+\n+__extension__ extern __inline poly8x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_p8_bf16 (bfloat16x4_t __a)\n+{\n+  return (poly8x8_t)__a;\n+}\n+\n+__extension__ extern __inline poly16x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_p16_bf16 (bfloat16x4_t __a)\n+{\n+  return (poly16x4_t)__a;\n+}\n+\n+__extension__ extern __inline poly64x1_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpret_p64_bf16 (bfloat16x4_t __a)\n+{\n+  return (poly64x1_t)__a;\n+}\n+\n+__extension__ extern __inline int8x16_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_s8_bf16 (bfloat16x8_t __a)\n+{\n+  return (int8x16_t)__a;\n+}\n+\n+__extension__ extern __inline int16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_s16_bf16 (bfloat16x8_t __a)\n+{\n+  return (int16x8_t)__a;\n+}\n+\n+__extension__ extern __inline int32x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_s32_bf16 (bfloat16x8_t __a)\n+{\n+  return (int32x4_t)__a;\n+}\n+\n+__extension__ extern __inline int64x2_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_s64_bf16 (bfloat16x8_t __a)\n+{\n+  return (int64x2_t)__a;\n+}\n+\n+__extension__ extern __inline uint8x16_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_u8_bf16 (bfloat16x8_t __a)\n+{\n+  return (uint8x16_t)__a;\n+}\n+\n+__extension__ extern __inline uint16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_u16_bf16 (bfloat16x8_t __a)\n+{\n+  return (uint16x8_t)__a;\n+}\n+\n+__extension__ extern __inline uint32x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_u32_bf16 (bfloat16x8_t __a)\n+{\n+  return (uint32x4_t)__a;\n+}\n+\n+__extension__ extern __inline uint64x2_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_u64_bf16 (bfloat16x8_t __a)\n+{\n+  return (uint64x2_t)__a;\n+}\n+\n+__extension__ extern __inline float32x4_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_f32_bf16 (bfloat16x8_t __a)\n+{\n+  return (float32x4_t)__a;\n+}\n+\n+__extension__ extern __inline poly8x16_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_p8_bf16 (bfloat16x8_t __a)\n+{\n+  return (poly8x16_t)__a;\n+}\n+\n+__extension__ extern __inline poly16x8_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_p16_bf16 (bfloat16x8_t __a)\n+{\n+  return (poly16x8_t)__a;\n+}\n+\n+__extension__ extern __inline poly64x2_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_p64_bf16 (bfloat16x8_t __a)\n+{\n+  return (poly64x2_t)__a;\n+}\n+\n+__extension__ extern __inline poly128_t\n+__attribute__  ((__always_inline__, __gnu_inline__, __artificial__))\n+vreinterpretq_p128_bf16 (bfloat16x8_t __a)\n+{\n+  return (poly128_t)__a;\n+}\n+\n __extension__ extern __inline float32x2_t\n __attribute__ ((__always_inline__, __gnu_inline__, __artificial__))\n vbfdot_f32 (float32x2_t __r, bfloat16x4_t __a, bfloat16x4_t __b)"}, {"sha": "4b4d1c808d87c6b65960664ecf9ff957ac05bf1b", "filename": "gcc/config/arm/arm_neon_builtins.def", "status": "modified", "additions": 5, "deletions": 5, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2Fconfig%2Farm%2Farm_neon_builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2Fconfig%2Farm%2Farm_neon_builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Farm_neon_builtins.def?ref=17a13507d776059bd7022ea4ddf7d5b9fab5294b", "patch": "@@ -221,13 +221,13 @@ VAR10 (SETLANE, vset_lane,\n VAR5 (UNOP, vcreate, v8qi, v4hi, v2si, v2sf, di)\n VAR10 (UNOP, vdup_n,\n \t v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di)\n-VAR2 (UNOP, vdup_n, v8hf, v4hf)\n+VAR4 (UNOP, vdup_n, v8hf, v4hf, v8bf, v4bf)\n VAR10 (GETLANE, vdup_lane,\n \t v8qi, v4hi, v2si, v2sf, di, v16qi, v8hi, v4si, v4sf, v2di)\n-VAR2 (GETLANE, vdup_lane, v8hf, v4hf)\n-VAR6 (COMBINE, vcombine, v8qi, v4hi, v4hf, v2si, v2sf, di)\n-VAR6 (UNOP, vget_high, v16qi, v8hi, v8hf, v4si, v4sf, v2di)\n-VAR6 (UNOP, vget_low, v16qi, v8hi, v8hf, v4si, v4sf, v2di)\n+VAR4 (GETLANE, vdup_lane, v8hf, v4hf, v8bf, v4bf)\n+VAR7 (COMBINE, vcombine, v8qi, v4hi, v4hf, v2si, v2sf, di, v4bf)\n+VAR7 (UNOP, vget_high, v16qi, v8hi, v8hf, v8bf, v4si, v4sf, v2di)\n+VAR7 (UNOP, vget_low, v16qi, v8hi, v8hf, v8bf, v4si, v4sf, v2di)\n VAR3 (UNOP, vmovn, v8hi, v4si, v2di)\n VAR3 (UNOP, vqmovns, v8hi, v4si, v2di)\n VAR3 (UNOP, vqmovnu, v8hi, v4si, v2di)"}, {"sha": "ab30c3715837fd657e42f058e8cab69f3710bb69", "filename": "gcc/config/arm/iterators.md", "status": "modified", "additions": 19, "deletions": 6, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2Fconfig%2Farm%2Fiterators.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2Fconfig%2Farm%2Fiterators.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fiterators.md?ref=17a13507d776059bd7022ea4ddf7d5b9fab5294b", "patch": "@@ -82,14 +82,14 @@\n (define_mode_iterator VD_RE [V8QI V4HI V2SI V2SF DI])\n \n ;; Double-width vector modes plus 64-bit elements.\n-(define_mode_iterator VDX [V8QI V4HI V4HF V2SI V2SF DI])\n+(define_mode_iterator VDX [V8QI V4HI V4HF V4BF V2SI V2SF DI])\n \n ;; Double-width vector modes plus 64-bit elements,\n ;; with V4BFmode added, suitable for moves.\n (define_mode_iterator VDXMOV [V8QI V4HI V4HF V4BF V2SI V2SF DI])\n \n ;; Double-width vector modes, with V4HF - for vldN_lane and vstN_lane.\n-(define_mode_iterator VD_LANE [V8QI V4HI V4HF V2SI V2SF])\n+(define_mode_iterator VD_LANE [V8QI V4HI V4HF V4BF V2SI V2SF])\n \n ;; Double-width vector modes without floating-point elements.\n (define_mode_iterator VDI [V8QI V4HI V2SI])\n@@ -104,7 +104,7 @@\n (define_mode_iterator VQ_HS [V8HI V8HF V4SI V4SF])\n \n ;; Quad-width vector modes plus 64-bit elements.\n-(define_mode_iterator VQX [V16QI V8HI V8HF V4SI V4SF V2DI])\n+(define_mode_iterator VQX [V16QI V8HI V8HF V8BF V4SI V4SF V2DI])\n \n ;; Quad-width vector modes without floating-point elements.\n (define_mode_iterator VQI [V16QI V8HI V4SI])\n@@ -153,7 +153,7 @@\n \n ;; Vector modes, including 64-bit integer elements.\n (define_mode_iterator VDQX [V8QI V16QI V4HI V8HI V2SI V4SI\n-\t\t\t    V4HF V8HF V2SF V4SF DI V2DI])\n+\t\t\t    V4HF V8HF V4BF V8BF V2SF V4SF DI V2DI])\n \n ;; Vector modes including 64-bit integer elements, but no floats.\n (define_mode_iterator VDQIX [V8QI V16QI V4HI V8HI V2SI V4SI DI V2DI])\n@@ -522,6 +522,7 @@\n (define_mode_attr V_elem [(V8QI \"QI\") (V16QI \"QI\")\n \t\t\t  (V4HI \"HI\") (V8HI \"HI\")\n \t\t\t  (V4HF \"HF\") (V8HF \"HF\")\n+\t\t\t  (V4BF \"BF\") (V8BF \"BF\")\n                           (V2SI \"SI\") (V4SI \"SI\")\n                           (V2SF \"SF\") (V4SF \"SF\")\n                           (DI \"DI\")   (V2DI \"DI\")])\n@@ -530,6 +531,7 @@\n (define_mode_attr V_elem_l [(V8QI \"qi\") (V16QI \"qi\")\n \t\t\t    (V4HI \"hi\") (V8HI \"hi\")\n \t\t\t    (V4HF \"hf\") (V8HF \"hf\")\n+\t\t\t    (V4BF \"bf\") (V8BF \"bf\")\n \t\t\t    (V2SI \"si\") (V4SI \"si\")\n \t\t\t    (V2SF \"sf\") (V4SF \"sf\")\n \t\t\t    (DI \"di\")   (V2DI \"di\")])\n@@ -547,6 +549,7 @@\n (define_mode_attr V_two_elem [(V8QI \"HI\")   (V16QI \"HI\")\n                               (V4HI \"SI\")   (V8HI \"SI\")\n                               (V4HF \"SF\")   (V8HF \"SF\")\n+                              (V4BF \"BF\")   (V8BF \"BF\")\n                               (V2SI \"V2SI\") (V4SI \"V2SI\")\n                               (V2SF \"V2SF\") (V4SF \"V2SF\")\n                               (DI \"V2DI\")   (V2DI \"V2DI\")])\n@@ -567,6 +570,7 @@\n (define_mode_attr V_three_elem [(V8QI \"BLK\") (V16QI \"BLK\")\n                                 (V4HI \"BLK\") (V8HI \"BLK\")\n                                 (V4HF \"BLK\") (V8HF \"BLK\")\n+                                (V4BF \"BLK\") (V8BF \"BLK\")\n                                 (V2SI \"BLK\") (V4SI \"BLK\")\n                                 (V2SF \"BLK\") (V4SF \"BLK\")\n                                 (DI \"EI\")    (V2DI \"EI\")])\n@@ -575,6 +579,7 @@\n (define_mode_attr V_four_elem [(V8QI \"SI\")   (V16QI \"SI\")\n                                (V4HI \"V4HI\") (V8HI \"V4HI\")\n                                (V4HF \"V4HF\") (V8HF \"V4HF\")\n+                               (V4BF \"V4BF\") (V8BF \"V4BF\")\n                                (V2SI \"V4SI\") (V4SI \"V4SI\")\n                                (V2SF \"V4SF\") (V4SF \"V4SF\")\n                                (DI \"OI\")     (V2DI \"OI\")])\n@@ -583,6 +588,7 @@\n (define_mode_attr V_reg [(V8QI \"P\") (V16QI \"q\")\n \t\t\t (V4HI \"P\") (V8HI  \"q\")\n \t\t\t (V4HF \"P\") (V8HF  \"q\")\n+\t\t\t (V4BF \"P\") (V8BF  \"q\")\n \t\t\t (V2SI \"P\") (V4SI  \"q\")\n \t\t\t (V2SF \"P\") (V4SF  \"q\")\n \t\t\t (DI   \"P\") (V2DI  \"q\")\n@@ -613,7 +619,8 @@\n (define_mode_attr V_HALF [(V16QI \"V8QI\") (V8HI \"V4HI\")\n \t\t\t  (V8HF \"V4HF\") (V4SI  \"V2SI\")\n \t\t\t  (V4SF \"V2SF\") (V2DF \"DF\")\n-\t\t\t  (V2DI \"DI\") (V4HF \"HF\")])\n+\t\t\t  (V2DI \"DI\") (V4HF \"HF\")\n+\t\t\t  (V4BF \"BF\") (V8BF  \"V4BF\")])\n \n ;; Same, but lower-case.\n (define_mode_attr V_half [(V16QI \"v8qi\") (V8HI \"v4hi\")\n@@ -624,7 +631,7 @@\n (define_mode_attr V_DOUBLE [(V8QI \"V16QI\") (V4HI \"V8HI\")\n \t\t\t    (V2SI \"V4SI\") (V4HF \"V8HF\")\n \t\t\t    (V2SF \"V4SF\") (DF \"V2DF\")\n-\t\t\t    (DI \"V2DI\")])\n+\t\t\t    (DI \"V2DI\")   (V4BF \"V8BF\")])\n \n ;; Same, but lower-case.\n (define_mode_attr V_double [(V8QI \"v16qi\") (V4HI \"v8hi\")\n@@ -643,13 +650,15 @@\n \t\t\t\t\t(V4SI \"V2SI\") (V4SF \"V2SF\")\n \t\t\t\t\t(V8QI \"V8QI\") (V4HI \"V4HI\")\n \t\t\t\t\t(V2SI \"V2SI\") (V2SF \"V2SF\")\n+\t\t\t\t\t(V8BF \"V4BF\") (V4BF \"V4BF\")\n \t\t\t\t\t(V8HF \"V4HF\") (V4HF \"V4HF\")])\n \n ;; Mode of result of comparison operations (and bit-select operand 1).\n (define_mode_attr V_cmp_result [(V8QI \"V8QI\") (V16QI \"V16QI\")\n \t\t\t\t(V4HI \"V4HI\") (V8HI  \"V8HI\")\n                                 (V2SI \"V2SI\") (V4SI  \"V4SI\")\n \t\t\t\t(V4HF \"V4HI\") (V8HF  \"V8HI\")\n+\t\t\t\t(V4BF \"V4HI\") (V8BF  \"V8HI\")\n                                 (V2SF \"V2SI\") (V4SF  \"V4SI\")\n                                 (DI   \"DI\")   (V2DI  \"V2DI\")])\n \n@@ -691,13 +700,15 @@\n                  (V4HI \"u16\") (V8HI \"u16\")\n                              (V2SI \"32\") (V4SI \"32\")\n                              (V4HF \"u16\") (V8HF \"u16\")\n+                             (V4BF \"u16\") (V8BF \"u16\")\n                              (V2SF \"32\") (V4SF \"32\")])\n \n (define_mode_attr V_sz_elem [(V8QI \"8\")  (V16QI \"8\")\n \t\t\t     (V4HI \"16\") (V8HI  \"16\")\n \t\t\t     (V2SI \"32\") (V4SI  \"32\")\n \t\t\t     (DI   \"64\") (V2DI  \"64\")\n \t\t\t     (V4HF \"16\") (V8HF \"16\")\n+\t\t\t     (V4BF \"16\") (V8BF \"16\")\n \t\t\t     (V2SF \"32\") (V4SF  \"32\")])\n \n (define_mode_attr V_elem_ch [(V8QI \"b\")  (V16QI \"b\")\n@@ -768,10 +779,12 @@\n \t\t\t    (V2SI \"true\") (V4SI  \"false\")\n \t\t\t    (V2SF \"true\") (V4SF  \"false\")\n \t\t\t    (DI   \"true\") (V2DI  \"false\")\n+\t\t\t    (V4BF \"true\") (V8BF  \"false\")\n \t\t\t    (V4HF \"true\") (V8HF  \"false\")])\n \n (define_mode_attr V_mode_nunits [(V8QI \"8\") (V16QI \"16\")\n \t\t\t\t (V4HF \"4\") (V8HF \"8\")\n+\t\t\t\t (V4BF \"4\") (V8BF \"8\")\n                                  (V4HI \"4\") (V8HI \"8\")\n                                  (V2SI \"2\") (V4SI \"4\")\n                                  (V2SF \"2\") (V4SF \"4\")"}, {"sha": "fae82131e24e0a1024c119da9a1caf2fd46cb743", "filename": "gcc/config/arm/neon.md", "status": "modified", "additions": 21, "deletions": 5, "changes": 26, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2Fconfig%2Farm%2Fneon.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2Fconfig%2Farm%2Fneon.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fneon.md?ref=17a13507d776059bd7022ea4ddf7d5b9fab5294b", "patch": "@@ -3737,6 +3737,22 @@ if (BYTES_BIG_ENDIAN)\n   [(set_attr \"type\" \"neon_from_gp_q\")]\n )\n \n+(define_insn \"neon_vdup_nv4bf\"\n+  [(set (match_operand:V4BF 0 \"s_register_operand\" \"=w\")\n+        (vec_duplicate:V4BF (match_operand:BF 1 \"s_register_operand\" \"r\")))]\n+  \"TARGET_NEON\"\n+  \"vdup.16\\t%P0, %1\"\n+  [(set_attr \"type\" \"neon_from_gp\")]\n+)\n+\n+(define_insn \"neon_vdup_nv8bf\"\n+  [(set (match_operand:V8BF 0 \"s_register_operand\" \"=w\")\n+        (vec_duplicate:V8BF (match_operand:BF 1 \"s_register_operand\" \"r\")))]\n+  \"TARGET_NEON\"\n+  \"vdup.16\\t%q0, %1\"\n+  [(set_attr \"type\" \"neon_from_gp_q\")]\n+)\n+\n (define_insn \"neon_vdup_n<mode>\"\n   [(set (match_operand:V32 0 \"s_register_operand\" \"=w,w\")\n         (vec_duplicate:V32 (match_operand:<V_elem> 1 \"s_register_operand\" \"r,t\")))]\n@@ -3791,12 +3807,12 @@ if (BYTES_BIG_ENDIAN)\n )\n \n (define_insn \"neon_vdup_lane<mode>_internal\"\n- [(set (match_operand:VH 0 \"s_register_operand\" \"=w\")\n-   (vec_duplicate:VH\n+ [(set (match_operand:VHFBF 0 \"s_register_operand\" \"=w\")\n+   (vec_duplicate:VHFBF\n     (vec_select:<V_elem>\n      (match_operand:<V_double_vector_mode> 1 \"s_register_operand\" \"w\")\n      (parallel [(match_operand:SI 2 \"immediate_operand\" \"i\")]))))]\n- \"TARGET_NEON && TARGET_FP16\"\n+ \"TARGET_NEON && (TARGET_FP16 || TARGET_BF16_SIMD)\"\n {\n   if (BYTES_BIG_ENDIAN)\n     {\n@@ -3832,10 +3848,10 @@ if (BYTES_BIG_ENDIAN)\n })\n \n (define_expand \"neon_vdup_lane<mode>\"\n-  [(match_operand:VH 0 \"s_register_operand\")\n+  [(match_operand:VHFBF 0 \"s_register_operand\")\n    (match_operand:<V_double_vector_mode> 1 \"s_register_operand\")\n    (match_operand:SI 2 \"immediate_operand\")]\n-  \"TARGET_NEON && TARGET_FP16\"\n+  \"TARGET_NEON && (TARGET_FP16 || TARGET_BF16_SIMD)\"\n {\n   if (BYTES_BIG_ENDIAN)\n     {"}, {"sha": "d9b1c3c8e21a2c1e57d8b1cb7d4f5456c0e8f854", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 5, "deletions": 0, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=17a13507d776059bd7022ea4ddf7d5b9fab5294b", "patch": "@@ -1,3 +1,8 @@\n+2020-02-27  Mihail Ionescu  <mihail.ionescu@arm.com>\n+\n+\t* gcc.target/arm/bf16_dup.c: New test.\n+\t* gcc.target/arm/bf16_reinterpret.c: Likewise.\n+\n 2020-02-27  Will Schmidt  <will_schmidt@vnet.ibm.com>\n \n \t* lib/target_supports.exp (check_effective_target_has_arch_pwr5): New."}, {"sha": "94be99a254bdaccc88a000615a4fa706bf324248", "filename": "gcc/testsuite/gcc.target/arm/bf16_dup.c", "status": "added", "additions": 96, "deletions": 0, "changes": 96, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fbf16_dup.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fbf16_dup.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fbf16_dup.c?ref=17a13507d776059bd7022ea4ddf7d5b9fab5294b", "patch": "@@ -0,0 +1,96 @@\n+/* { dg-do assemble { target { arm*-*-* } } } */\n+/* { dg-require-effective-target arm_v8_2a_bf16_neon_ok } */\n+/* { dg-add-options arm_v8_2a_bf16_neon }  */\n+/* { dg-additional-options \"-save-temps -march=armv8.2-a+bf16+fp16 -mfloat-abi=softfp\" } */\n+\n+#include \"arm_neon.h\"\n+\n+float32x2_t\n+test_vbfdot_vcreate (float32x2_t r, uint64_t a, uint64_t b)\n+{\n+  bfloat16x4_t _a = vcreate_bf16(a);\n+  bfloat16x4_t _b = vcreate_bf16(b);\n+\n+  return vbfdot_f32 (r, _a, _b);\n+}\n+/* { dg-final { scan-assembler {vdot.bf16\\td[0-9]+, d[0-9]+, d[0-9]+} } } */\n+\n+bfloat16x8_t test_vcombine_bf16 (bfloat16x4_t a, bfloat16x4_t b)\n+{\n+  return vcombine_bf16 (a, b);\n+}\n+\n+bfloat16x4_t test_vget_high_bf16 (bfloat16x8_t a)\n+{\n+  return vget_high_bf16 (a);\n+}\n+\n+bfloat16x4_t test_vget_low_bf16 (bfloat16x8_t a)\n+{\n+  return vget_low_bf16 (a);\n+}\n+\n+bfloat16_t test_vget_lane_bf16 (bfloat16x4_t a)\n+{\n+  return vget_lane_bf16 (a, 1);\n+}\n+\n+bfloat16_t test_vgetq_lane_bf16 (bfloat16x8_t a)\n+{\n+  return vgetq_lane_bf16 (a, 7);\n+}\n+\n+bfloat16x4_t test_vset_lane_bf16 (bfloat16_t a, bfloat16x4_t b)\n+{\n+  return vset_lane_bf16 (a, b, 1);\n+}\n+\n+bfloat16x8_t test_vsetq_lane_bf16 (bfloat16_t a, bfloat16x8_t b)\n+{\n+  return vsetq_lane_bf16 (a, b, 7);\n+}\n+\n+bfloat16x4_t vdup_test (bfloat16_t a)\n+{\n+  return vdup_n_bf16 (a);\n+}\n+/* { dg-final { scan-assembler {vdup\\.16\\td[0-9]+, r[0-9]+} } }  */\n+\n+bfloat16x8_t vdupq_test (bfloat16_t a)\n+{\n+  return vdupq_n_bf16 (a);\n+}\n+/* { dg-final { scan-assembler {vdup\\.16\\tq[0-9]+, r[0-9]+} } }  */\n+\n+\n+bfloat16x4_t test_vdup_lane_bf16 (bfloat16x4_t a)\n+{\n+  return vdup_lane_bf16 (a, 1);\n+}\n+/* { dg-final { scan-assembler-times {vdup\\.16\\td[0-9]+, d[0-9]+\\[1\\]} 1 } }  */\n+\n+bfloat16x8_t test_vdupq_lane_bf16 (bfloat16x4_t a)\n+{\n+  return vdupq_lane_bf16 (a, 1);\n+}\n+/* { dg-final { scan-assembler-times {vdup\\.16\\tq[0-9]+, d[0-9]+\\[1\\]} 1 } }  */\n+\n+bfloat16x4_t test_vdup_laneq_bf16 (bfloat16x8_t a)\n+{\n+  return vdup_laneq_bf16 (a, 3);\n+}\n+\n+bfloat16x8_t test_vdupq_laneq_bf16 (bfloat16x8_t a)\n+{\n+  return vdupq_laneq_bf16 (a, 3);\n+}\n+\n+bfloat16_t test_vduph_lane_bf16 (bfloat16x4_t a)\n+{\n+  return vduph_lane_bf16 (a, 1);\n+}\n+\n+bfloat16_t test_vduph_laneq_bf16 (bfloat16x8_t a)\n+{\n+  return vduph_laneq_bf16 (a, 7);\n+}"}, {"sha": "e7d30a95fbc3ceaf4a92057a10e6be4a34e1957c", "filename": "gcc/testsuite/gcc.target/arm/bf16_reinterpret.c", "status": "added", "additions": 435, "deletions": 0, "changes": 435, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fbf16_reinterpret.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/17a13507d776059bd7022ea4ddf7d5b9fab5294b/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fbf16_reinterpret.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Farm%2Fbf16_reinterpret.c?ref=17a13507d776059bd7022ea4ddf7d5b9fab5294b", "patch": "@@ -0,0 +1,435 @@\n+/* { dg-do assemble { target { arm*-*-* } } } */\n+/* { dg-require-effective-target arm_v8_2a_bf16_neon_ok } */\n+/* { dg-add-options arm_v8_2a_bf16_neon }  */\n+/* { dg-additional-options \"-save-temps -march=armv8.2-a+fp16+bf16 -mfloat-abi=hard -mfpu=crypto-neon-fp-armv8\" } */\n+\n+#include <arm_neon.h>\n+\n+float32x2_t\n+test_vbfdot_f32_s8 (float32x2_t r, int8x8_t a, int8x8_t b)\n+{\n+  bfloat16x4_t _a = vreinterpret_bf16_s8(a);\n+  bfloat16x4_t _b = vreinterpret_bf16_s8(b);\n+\n+  return vbfdot_f32 (r, _a, _b);\n+}\n+\n+float32x2_t\n+test_vbfdot_f32_s16 (float32x2_t r, int16x4_t a, int16x4_t b)\n+{\n+  bfloat16x4_t _a = vreinterpret_bf16_s16(a);\n+  bfloat16x4_t _b = vreinterpret_bf16_s16(b);\n+\n+  return vbfdot_f32 (r, _a, _b);\n+}\n+\n+float32x2_t\n+test_vbfdot_f32_s32 (float32x2_t r, int32x2_t a, int32x2_t b)\n+{\n+  bfloat16x4_t _a = vreinterpret_bf16_s32(a);\n+  bfloat16x4_t _b = vreinterpret_bf16_s32(b);\n+\n+  return vbfdot_f32 (r, _a, _b);\n+}\n+\n+float32x2_t\n+test_vbfdot_f32_s64 (float32x2_t r, int64x1_t a, int64x1_t b)\n+{\n+  bfloat16x4_t _a = vreinterpret_bf16_s64(a);\n+  bfloat16x4_t _b = vreinterpret_bf16_s64(b);\n+\n+  return vbfdot_f32 (r, _a, _b);\n+}\n+\n+float32x2_t\n+test_vbfdot_f32_u8 (float32x2_t r, uint8x8_t a, uint8x8_t b)\n+{\n+  bfloat16x4_t _a = vreinterpret_bf16_u8(a);\n+  bfloat16x4_t _b = vreinterpret_bf16_u8(b);\n+\n+  return vbfdot_f32 (r, _a, _b);\n+}\n+\n+float32x2_t\n+test_vbfdot_f32_u16 (float32x2_t r, uint16x4_t a, uint16x4_t b)\n+{\n+  bfloat16x4_t _a = vreinterpret_bf16_u16(a);\n+  bfloat16x4_t _b = vreinterpret_bf16_u16(b);\n+\n+  return vbfdot_f32 (r, _a, _b);\n+}\n+\n+float32x2_t\n+test_vbfdot_f32_u32 (float32x2_t r, uint32x2_t a, uint32x2_t b)\n+{\n+  bfloat16x4_t _a = vreinterpret_bf16_u32(a);\n+  bfloat16x4_t _b = vreinterpret_bf16_u32(b);\n+\n+  return vbfdot_f32 (r, _a, _b);\n+}\n+\n+float32x2_t\n+test_vbfdot_f32_u64 (float32x2_t r, uint64x1_t a, uint64x1_t b)\n+{\n+  bfloat16x4_t _a = vreinterpret_bf16_u64(a);\n+  bfloat16x4_t _b = vreinterpret_bf16_u64(b);\n+\n+  return vbfdot_f32 (r, _a, _b);\n+}\n+\n+float32x2_t\n+test_vbfdot_f32_p8 (float32x2_t r, poly8x8_t a, poly8x8_t b)\n+{\n+  bfloat16x4_t _a = vreinterpret_bf16_p8(a);\n+  bfloat16x4_t _b = vreinterpret_bf16_p8(b);\n+\n+  return vbfdot_f32 (r, _a, _b);\n+}\n+\n+float32x2_t\n+test_vbfdot_f32_p16 (float32x2_t r, poly16x4_t a, poly16x4_t b)\n+{\n+  bfloat16x4_t _a = vreinterpret_bf16_p16(a);\n+  bfloat16x4_t _b = vreinterpret_bf16_p16(b);\n+\n+  return vbfdot_f32 (r, _a, _b);\n+}\n+\n+float32x2_t\n+test_vbfdot_f32_p64 (float32x2_t r, poly64x1_t a, poly64x1_t b)\n+{\n+  bfloat16x4_t _a = vreinterpret_bf16_p64(a);\n+  bfloat16x4_t _b = vreinterpret_bf16_p64(b);\n+\n+  return vbfdot_f32 (r, _a, _b);\n+}\n+\n+float32x2_t\n+test_vbfdot_f32_f16 (float32x2_t r, float16x4_t a, float16x4_t b)\n+{\n+  bfloat16x4_t _a = vreinterpret_bf16_f16(a);\n+  bfloat16x4_t _b = vreinterpret_bf16_f16(b);\n+\n+  return vbfdot_f32 (r, _a, _b);\n+}\n+\n+float32x2_t\n+test_vbfdot_f32_f32 (float32x2_t r, float32x2_t a, float32x2_t b)\n+{\n+  bfloat16x4_t _a = vreinterpret_bf16_f32(a);\n+  bfloat16x4_t _b = vreinterpret_bf16_f32(b);\n+\n+  return vbfdot_f32 (r, _a, _b);\n+}\n+\n+float32x4_t\n+test_vbfdotq_f32_s8 (float32x4_t r, int8x16_t a, int8x16_t b)\n+{\n+  bfloat16x8_t _a = vreinterpretq_bf16_s8(a);\n+  bfloat16x8_t _b = vreinterpretq_bf16_s8(b);\n+\n+  return vbfdotq_f32 (r, _a, _b);\n+}\n+\n+float32x4_t\n+test_vbfdotq_f32_s16 (float32x4_t r, int16x8_t a, int16x8_t b)\n+{\n+  bfloat16x8_t _a = vreinterpretq_bf16_s16(a);\n+  bfloat16x8_t _b = vreinterpretq_bf16_s16(b);\n+\n+  return vbfdotq_f32 (r, _a, _b);\n+}\n+\n+float32x4_t\n+test_vbfdotq_f32_s32 (float32x4_t r, int32x4_t a, int32x4_t b)\n+{\n+  bfloat16x8_t _a = vreinterpretq_bf16_s32(a);\n+  bfloat16x8_t _b = vreinterpretq_bf16_s32(b);\n+\n+  return vbfdotq_f32 (r, _a, _b);\n+}\n+\n+float32x4_t\n+test_vbfdotq_f32_s64 (float32x4_t r, int64x2_t a, int64x2_t b)\n+{\n+  bfloat16x8_t _a = vreinterpretq_bf16_s64(a);\n+  bfloat16x8_t _b = vreinterpretq_bf16_s64(b);\n+\n+  return vbfdotq_f32 (r, _a, _b);\n+}\n+\n+float32x4_t\n+test_vbfdotq_f32_u8 (float32x4_t r, uint8x16_t a, uint8x16_t b)\n+{\n+  bfloat16x8_t _a = vreinterpretq_bf16_u8(a);\n+  bfloat16x8_t _b = vreinterpretq_bf16_u8(b);\n+\n+  return vbfdotq_f32 (r, _a, _b);\n+}\n+\n+float32x4_t\n+test_vbfdotq_f32_u16 (float32x4_t r, uint16x8_t a, uint16x8_t b)\n+{\n+  bfloat16x8_t _a = vreinterpretq_bf16_u16(a);\n+  bfloat16x8_t _b = vreinterpretq_bf16_u16(b);\n+\n+  return vbfdotq_f32 (r, _a, _b);\n+}\n+\n+float32x4_t\n+test_vbfdotq_f32_u32 (float32x4_t r, uint32x4_t a, uint32x4_t b)\n+{\n+  bfloat16x8_t _a = vreinterpretq_bf16_u32(a);\n+  bfloat16x8_t _b = vreinterpretq_bf16_u32(b);\n+\n+  return vbfdotq_f32 (r, _a, _b);\n+}\n+\n+float32x4_t\n+test_vbfdotq_f32_u64 (float32x4_t r, uint64x2_t a, uint64x2_t b)\n+{\n+  bfloat16x8_t _a = vreinterpretq_bf16_u64(a);\n+  bfloat16x8_t _b = vreinterpretq_bf16_u64(b);\n+\n+  return vbfdotq_f32 (r, _a, _b);\n+}\n+\n+float32x4_t\n+test_vbfdotq_f32_p8 (float32x4_t r, poly8x16_t a, poly8x16_t b)\n+{\n+  bfloat16x8_t _a = vreinterpretq_bf16_p8(a);\n+  bfloat16x8_t _b = vreinterpretq_bf16_p8(b);\n+\n+  return vbfdotq_f32 (r, _a, _b);\n+}\n+\n+float32x4_t\n+test_vbfdotq_f32_p16 (float32x4_t r, poly16x8_t a, poly16x8_t b)\n+{\n+  bfloat16x8_t _a = vreinterpretq_bf16_p16(a);\n+  bfloat16x8_t _b = vreinterpretq_bf16_p16(b);\n+\n+  return vbfdotq_f32 (r, _a, _b);\n+}\n+\n+float32x4_t\n+test_vbfdotq_f32_p64 (float32x4_t r, poly64x2_t a, poly64x2_t b)\n+{\n+  bfloat16x8_t _a = vreinterpretq_bf16_p64(a);\n+  bfloat16x8_t _b = vreinterpretq_bf16_p64(b);\n+\n+  return vbfdotq_f32 (r, _a, _b);\n+}\n+\n+float32x4_t\n+test_vbfdotq_f32_p128 (float32x4_t r, poly128_t a, poly128_t b)\n+{\n+  bfloat16x8_t _a = vreinterpretq_bf16_p128(a);\n+  bfloat16x8_t _b = vreinterpretq_bf16_p128(b);\n+\n+  return vbfdotq_f32 (r, _a, _b);\n+}\n+\n+float32x4_t\n+test_vbfdotq_f32_f16 (float32x4_t r, float16x8_t a, float16x8_t b)\n+{\n+  bfloat16x8_t _a = vreinterpretq_bf16_f16(a);\n+  bfloat16x8_t _b = vreinterpretq_bf16_f16(b);\n+\n+  return vbfdotq_f32 (r, _a, _b);\n+}\n+\n+float32x4_t\n+test_vbfdotq_f32_f32 (float32x4_t r, float32x4_t a, float32x4_t b)\n+{\n+  bfloat16x8_t _a = vreinterpretq_bf16_f32(a);\n+  bfloat16x8_t _b = vreinterpretq_bf16_f32(b);\n+\n+  return vbfdotq_f32 (r, _a, _b);\n+}\n+\n+/* { dg-final { scan-assembler-times {\\tvdot.bf16\\td[0-9]+, d[0-9]+, d[0-9]+\\n} 13 } } */\n+/* { dg-final { scan-assembler-times {\\tvdot.bf16\\tq[0-9]+, q[0-9]+, q[0-9]+\\n} 14 } } */\n+\n+int8x8_t test_vreinterpret_s8_bf16 (bfloat16x4_t a, int8x8_t b)\n+{\n+  int8x8_t _a = vreinterpret_s8_bf16 (a);\n+  return vadd_s8 (_a, b);\n+}\n+\n+int16x4_t test_vreinterpret_s16_bf16 (bfloat16x4_t a, int16x4_t b)\n+{\n+  int16x4_t _a = vreinterpret_s16_bf16 (a);\n+  return vadd_s16 (_a, b);\n+}\n+\n+int32x2_t test_vreinterpret_s32_bf16 (bfloat16x4_t a, int32x2_t b)\n+{\n+  int32x2_t _a = vreinterpret_s32_bf16 (a);\n+  return vadd_s32 (_a, b);\n+}\n+\n+int64x1_t test_vreinterpret_s64_bf16 (bfloat16x4_t a, int64x1_t b)\n+{\n+  int64x1_t _a = vreinterpret_s64_bf16 (a);\n+  return vrshl_s64 (_a, b);\n+}\n+\n+uint8x8_t test_vreinterpret_u8_bf16 (bfloat16x4_t a, uint8x8_t b)\n+{\n+  uint8x8_t _a = vreinterpret_u8_bf16 (a);\n+  return vadd_u8 (_a, b);\n+}\n+\n+uint16x4_t test_vreinterpret_u16_bf16 (bfloat16x4_t a, uint16x4_t b)\n+{\n+  uint16x4_t _a = vreinterpret_u16_bf16 (a);\n+  return vadd_u16 (_a, b);\n+}\n+\n+uint32x2_t test_vreinterpret_u32_bf16 (bfloat16x4_t a, uint32x2_t b)\n+{\n+  uint32x2_t _a = vreinterpret_u32_bf16 (a);\n+  return vadd_u32 (_a, b);\n+}\n+\n+uint64x1_t test_vreinterpret_u64_bf16 (bfloat16x4_t a, int64x1_t b)\n+{\n+  uint64x1_t _a = vreinterpret_u64_bf16 (a);\n+  return vrshl_u64 (_a, b);\n+}\n+\n+poly8x8x2_t test_vreinterpret_p8_bf16 (bfloat16x4_t a, poly8x8_t b)\n+{\n+  poly8x8_t _a = vreinterpret_p8_bf16 (a);\n+  return vzip_p8 (_a, b);\n+}\n+\n+poly16x4x2_t test_vreinterpret_p16_bf16 (bfloat16x4_t a, poly16x4_t b)\n+{\n+  poly16x4_t _a = vreinterpret_p16_bf16 (a);\n+  return vzip_p16 (_a, b);\n+}\n+\n+poly64x1_t test_vreinterpret_p64_bf16 (bfloat16x4_t a, poly64x1_t b)\n+{\n+  poly64x1_t _a = vreinterpret_p64_bf16 (a);\n+  return vsli_n_p64 (_a, b, 3);\n+}\n+\n+float32x2_t test_vreinterpret_f32_bf16 (bfloat16x4_t a, float32x2_t b)\n+{\n+  float32x2_t _a = vreinterpret_f32_bf16 (a);\n+  return vsub_f32 (_a, b);\n+}\n+\n+int8x16_t test_vreinterpretq_s8_bf16 (bfloat16x8_t a, int8x16_t b)\n+{\n+  int8x16_t _a = vreinterpretq_s8_bf16 (a);\n+  return vaddq_s8 (_a, b);\n+}\n+\n+int16x8_t test_vreinterpretq_s16_bf16 (bfloat16x8_t a, int16x8_t b)\n+{\n+  int16x8_t _a = vreinterpretq_s16_bf16 (a);\n+  return vaddq_s16 (_a, b);\n+}\n+\n+int32x4_t test_vreinterpretq_s32_bf16 (bfloat16x8_t a, int32x4_t b)\n+{\n+  int32x4_t _a = vreinterpretq_s32_bf16 (a);\n+  return vaddq_s32 (_a, b);\n+}\n+\n+int64x2_t test_vreinterpretq_s64_bf16 (bfloat16x8_t a, int64x2_t b)\n+{\n+  int64x2_t _a = vreinterpretq_s64_bf16 (a);\n+  return vaddq_s64 (_a, b);\n+}\n+\n+uint8x16_t test_vreinterpretq_u8_bf16 (bfloat16x8_t a, uint8x16_t b)\n+{\n+  uint8x16_t _a = vreinterpretq_u8_bf16 (a);\n+  return vaddq_u8 (_a, b);\n+}\n+\n+uint16x8_t test_vreinterpretq_u16_bf16 (bfloat16x8_t a, uint16x8_t b)\n+{\n+  uint16x8_t _a = vreinterpretq_u16_bf16 (a);\n+  return vaddq_u16 (_a, b);\n+}\n+\n+uint32x4_t test_vreinterpretq_u32_bf16 (bfloat16x8_t a, uint32x4_t b)\n+{\n+  uint32x4_t _a = vreinterpretq_u32_bf16 (a);\n+  return vaddq_u32 (_a, b);\n+}\n+\n+uint64x2_t test_vreinterpretq_u64_bf16 (bfloat16x8_t a, uint64x2_t b)\n+{\n+  uint64x2_t _a = vreinterpretq_u64_bf16 (a);\n+  return vaddq_u64 (_a, b);\n+}\n+\n+poly8x16x2_t test_vreinterpretq_p8_bf16 (bfloat16x8_t a, poly8x16_t b)\n+{\n+  poly8x16_t _a = vreinterpretq_p8_bf16 (a);\n+  return vzipq_p8 (_a, b);\n+}\n+\n+poly16x8x2_t test_vreinterpretq_p16_bf16 (bfloat16x8_t a, poly16x8_t b)\n+{\n+  poly16x8_t _a = vreinterpretq_p16_bf16 (a);\n+  return vzipq_p16 (_a, b);\n+}\n+\n+poly64x2_t test_vreinterpretq_p64_bf16 (bfloat16x8_t a, poly64x2_t b)\n+{\n+  poly64x2_t _a = vreinterpretq_p64_bf16 (a);\n+  return vsliq_n_p64 (_a, b, 3);\n+}\n+\n+poly128_t test_vreinterpretq_p128_bf16 (bfloat16x8_t a, poly16x8_t b)\n+{\n+  poly128_t _a = vreinterpretq_p128_bf16 (a);\n+  return _a;\n+}\n+\n+float32x4_t test_vreinterpretq_f32_bf16 (bfloat16x8_t a, float32x4_t b)\n+{\n+  float32x4_t _a = vreinterpretq_f32_bf16 (a);\n+  return vsubq_f32 (_a, b);\n+}\n+\n+float16x4_t test_vreinterpret_f16_bf16 (bfloat16x4_t a)\n+{\n+  return vreinterpret_f16_bf16 (a);\n+}\n+\n+float16x8_t test_vreinterpretq_f16_bf16 (bfloat16x8_t a)\n+{\n+  return vreinterpretq_f16_bf16 (a);\n+}\n+\n+/* { dg-final { scan-assembler-times {\\tvadd.i8\\td[0-9]+, d[0-9]+, d[0-9]+\\n} 2 } } */\n+/* { dg-final { scan-assembler-times {\\tvadd.i16\\td[0-9]+, d[0-9]+, d[0-9]+\\n} 2 } } */\n+/* { dg-final { scan-assembler-times {\\tvadd.i32\\td[0-9]+, d[0-9]+, d[0-9]+\\n} 2 } } */\n+\n+/* { dg-final { scan-assembler-times {\\tvadd.i8\\tq[0-9]+, q[0-9]+, q[0-9]+\\n} 2 } } */\n+/* { dg-final { scan-assembler-times {\\tvadd.i16\\tq[0-9]+, q[0-9]+, q[0-9]+\\n} 2 } } */\n+/* { dg-final { scan-assembler-times {\\tvadd.i32\\tq[0-9]+, q[0-9]+, q[0-9]+\\n} 2 } } */\n+/* { dg-final { scan-assembler-times {\\tvadd.i64\\tq[0-9]+, q[0-9]+, q[0-9]+\\n} 2 } } */\n+\n+/* { dg-final { scan-assembler {\\tvsub.f32\\td[0-9]+, d[0-9]+, d[0-9]+\\n} } } */\n+/* { dg-final { scan-assembler {\\tvsub.f32\\tq[0-9]+, q[0-9]+, q[0-9]+\\n} } } */\n+\n+/* { dg-final { scan-assembler {\\tvzip.8\\td[0-9]+, d[0-9]+\\n} } } */\n+/* { dg-final { scan-assembler {\\tvzip.16\\td[0-9]+, d[0-9]+\\n} } } */\n+/* { dg-final { scan-assembler {\\tvzip.8\\tq[0-9]+, q[0-9]+\\n} } } */\n+/* { dg-final { scan-assembler {\\tvzip.16\\tq[0-9]+, q[0-9]+\\n} } } */\n+\n+/* { dg-final { scan-assembler {\\tvrshl.s64\\td[0-9]+, d[0-9]+, d[0-9]+\\n} } } */\n+/* { dg-final { scan-assembler {\\tvrshl.u64\\td[0-9]+, d[0-9]+, d[0-9]+\\n} } } */\n+\n+/* { dg-final { scan-assembler {\\tvsli.64\\td[0-9]+, d[0-9]+, #3\\n} } } */\n+/* { dg-final { scan-assembler {\\tvsli.64\\tq[0-9]+, q[0-9]+, #3\\n} } } */"}]}