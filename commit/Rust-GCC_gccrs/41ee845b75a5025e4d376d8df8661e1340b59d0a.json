{"sha": "41ee845b75a5025e4d376d8df8661e1340b59d0a", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NDFlZTg0NWI3NWE1MDI1ZTRkMzc2ZDhkZjg2NjFlMTM0MGI1OWQwYQ==", "commit": {"author": {"name": "Jan Hubicka", "email": "jh@suse.cz", "date": "2013-10-19T12:11:14Z"}, "committer": {"name": "Jan Hubicka", "email": "hubicka@gcc.gnu.org", "date": "2013-10-19T12:11:14Z"}, "message": "i386.h (ACCUMULATE_OUTGOING_ARGS): Disable accumulation for cold functions.\n\n\t* config/i386/i386.h (ACCUMULATE_OUTGOING_ARGS): Disable accumulation\n\tfor cold functions.\n\t* x86-tune.def (X86_TUNE_USE_LEAVE): Update comment.\n\t(X86_TUNE_PUSH_MEMORY): Likewise.\n\t(X86_TUNE_AVX256_UNALIGNED_LOAD_OPTIMAL,\n\tX86_TUNE_AVX256_UNALIGNED_STORE_OPTIMAL): New.\n\t(X86_TUNE_ACCUMULATE_OUTGOING_ARGS, X86_TUNE_ALWAYS_FANCY_MATH_387): New.\n\t* i386.c (x86_accumulate_outgoing_args, x86_arch_always_fancy_math_387,\n\tx86_avx256_split_unaligned_load, x86_avx256_split_unaligned_store):\n\tRemove.\n\t(ix86_option_override_internal): Update to use tune features instead\n\tof variables.\n\nFrom-SVN: r203855", "tree": {"sha": "432272133578a944dd10eac6df2977c235104f3b", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/432272133578a944dd10eac6df2977c235104f3b"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/41ee845b75a5025e4d376d8df8661e1340b59d0a", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/41ee845b75a5025e4d376d8df8661e1340b59d0a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/41ee845b75a5025e4d376d8df8661e1340b59d0a", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/41ee845b75a5025e4d376d8df8661e1340b59d0a/comments", "author": null, "committer": null, "parents": [{"sha": "322cb62ac5c93e21a859cce27c0d8e8b1b6c1c01", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/322cb62ac5c93e21a859cce27c0d8e8b1b6c1c01", "html_url": "https://github.com/Rust-GCC/gccrs/commit/322cb62ac5c93e21a859cce27c0d8e8b1b6c1c01"}], "stats": {"total": 96, "additions": 70, "deletions": 26}, "files": [{"sha": "086b5b21787fb839efe84522abecfae1022ab3ad", "filename": "gcc/ChangeLog", "status": "modified", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/41ee845b75a5025e4d376d8df8661e1340b59d0a/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/41ee845b75a5025e4d376d8df8661e1340b59d0a/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=41ee845b75a5025e4d376d8df8661e1340b59d0a", "patch": "@@ -1,3 +1,18 @@\n+2013-10-18  Jan Hubicka  <jh@suse.cz>\n+\n+\t* config/i386/i386.h (ACCUMULATE_OUTGOING_ARGS): Disable accumulation\n+\tfor cold functions.\n+\t* x86-tune.def (X86_TUNE_USE_LEAVE): Update comment.\n+\t(X86_TUNE_PUSH_MEMORY): Likewise.\n+\t(X86_TUNE_AVX256_UNALIGNED_LOAD_OPTIMAL,\n+\tX86_TUNE_AVX256_UNALIGNED_STORE_OPTIMAL): New.\n+\t(X86_TUNE_ACCUMULATE_OUTGOING_ARGS, X86_TUNE_ALWAYS_FANCY_MATH_387): New.\n+\t* i386.c (x86_accumulate_outgoing_args, x86_arch_always_fancy_math_387,\n+\tx86_avx256_split_unaligned_load, x86_avx256_split_unaligned_store):\n+\tRemove.\n+\t(ix86_option_override_internal): Update to use tune features instead\n+\tof variables.\n+\n 2013-10-18  Cong Hou  <congh@google.com>\n \n \tPR tree-optimization/58508"}, {"sha": "91e65105a5cb40b7945316a0b67142e5c3bc27e7", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 5, "deletions": 18, "changes": 23, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/41ee845b75a5025e4d376d8df8661e1340b59d0a/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/41ee845b75a5025e4d376d8df8661e1340b59d0a/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=41ee845b75a5025e4d376d8df8661e1340b59d0a", "patch": "@@ -1897,18 +1897,6 @@ static unsigned int initial_ix86_arch_features[X86_ARCH_LAST] = {\n   ~m_386,\n };\n \n-static const unsigned int x86_accumulate_outgoing_args\n-  = m_PPRO | m_P4_NOCONA | m_ATOM | m_SLM | m_AMD_MULTIPLE | m_GENERIC;\n-\n-static const unsigned int x86_arch_always_fancy_math_387\n-  = m_PENT | m_PPRO | m_P4_NOCONA | m_CORE_ALL | m_ATOM | m_SLM | m_AMD_MULTIPLE | m_GENERIC;\n-\n-static const unsigned int x86_avx256_split_unaligned_load\n-  = m_COREI7 | m_GENERIC;\n-\n-static const unsigned int x86_avx256_split_unaligned_store\n-  = m_COREI7 | m_BDVER | m_GENERIC;\n-\n /* In case the average insn count for single function invocation is\n    lower than this constant, emit fast (but longer) prologue and\n    epilogue code.  */\n@@ -2925,7 +2913,7 @@ ix86_option_override_internal (bool main_args_p,\n \t\t\t       struct gcc_options *opts_set)\n {\n   int i;\n-  unsigned int ix86_arch_mask, ix86_tune_mask;\n+  unsigned int ix86_arch_mask;\n   const bool ix86_tune_specified = (opts->x_ix86_tune_string != NULL);\n   const char *prefix;\n   const char *suffix;\n@@ -3693,7 +3681,7 @@ ix86_option_override_internal (bool main_args_p,\n \n   /* If the architecture always has an FPU, turn off NO_FANCY_MATH_387,\n      since the insns won't need emulation.  */\n-  if (x86_arch_always_fancy_math_387 & ix86_arch_mask)\n+  if (ix86_tune_features [X86_TUNE_ALWAYS_FANCY_MATH_387])\n     opts->x_target_flags &= ~MASK_NO_FANCY_MATH_387;\n \n   /* Likewise, if the target doesn't have a 387, or we've specified\n@@ -3835,8 +3823,7 @@ ix86_option_override_internal (bool main_args_p,\n \tgcc_unreachable ();\n       }\n \n-  ix86_tune_mask = 1u << ix86_tune;\n-  if ((x86_accumulate_outgoing_args & ix86_tune_mask)\n+  if (ix86_tune_features [X86_TUNE_ACCUMULATE_OUTGOING_ARGS]\n       && !(opts_set->x_target_flags & MASK_ACCUMULATE_OUTGOING_ARGS)\n       && !opts->x_optimize_size)\n     opts->x_target_flags |= MASK_ACCUMULATE_OUTGOING_ARGS;\n@@ -3976,10 +3963,10 @@ ix86_option_override_internal (bool main_args_p,\n       if (flag_expensive_optimizations\n \t  && !(opts_set->x_target_flags & MASK_VZEROUPPER))\n \topts->x_target_flags |= MASK_VZEROUPPER;\n-      if ((x86_avx256_split_unaligned_load & ix86_tune_mask)\n+      if (!ix86_tune_features[X86_TUNE_SSE_UNALIGNED_LOAD_OPTIMAL]\n \t  && !(opts_set->x_target_flags & MASK_AVX256_SPLIT_UNALIGNED_LOAD))\n \topts->x_target_flags |= MASK_AVX256_SPLIT_UNALIGNED_LOAD;\n-      if ((x86_avx256_split_unaligned_store & ix86_tune_mask)\n+      if (!ix86_tune_features[X86_TUNE_SSE_UNALIGNED_STORE_OPTIMAL]\n \t  && !(opts_set->x_target_flags & MASK_AVX256_SPLIT_UNALIGNED_STORE))\n \topts->x_target_flags |= MASK_AVX256_SPLIT_UNALIGNED_STORE;\n       /* Enable 128-bit AVX instruction generation"}, {"sha": "63e490327481b390163f8529148d69fd48be089c", "filename": "gcc/config/i386/i386.h", "status": "modified", "additions": 16, "deletions": 3, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/41ee845b75a5025e4d376d8df8661e1340b59d0a/gcc%2Fconfig%2Fi386%2Fi386.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/41ee845b75a5025e4d376d8df8661e1340b59d0a/gcc%2Fconfig%2Fi386%2Fi386.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.h?ref=41ee845b75a5025e4d376d8df8661e1340b59d0a", "patch": "@@ -1544,13 +1544,26 @@ enum reg_class\n    will be computed and placed into the variable `crtl->outgoing_args_size'.\n    No space will be pushed onto the stack for each call; instead, the\n    function prologue should increase the stack frame size by this amount.  \n+\n+   In 32bit mode enabling argument accumulation results in about 5% code size\n+   growth becuase move instructions are less compact than push.  In 64bit\n+   mode the difference is less drastic but visible.  \n+\n+   FIXME: Unlike earlier implementations, the size of unwind info seems to\n+   actually grouw with accumulation.  Is that because accumulated args\n+   unwind info became unnecesarily bloated?\n    \n    64-bit MS ABI seem to require 16 byte alignment everywhere except for\n-   function prologue and apilogue.  This is not possible without\n-   ACCUMULATE_OUTGOING_ARGS.  */\n+   function prologue and epilogue.  This is not possible without\n+   ACCUMULATE_OUTGOING_ARGS.  \n+\n+   If stack probes are required, the space used for large function\n+   arguments on the stack must also be probed, so enable\n+   -maccumulate-outgoing-args so this happens in the prologue.  */\n \n #define ACCUMULATE_OUTGOING_ARGS \\\n-  (TARGET_ACCUMULATE_OUTGOING_ARGS || TARGET_64BIT_MS_ABI)\n+  ((TARGET_ACCUMULATE_OUTGOING_ARGS && optimize_function_for_speed_p (cfun)) \\\n+   || TARGET_STACK_PROBE || TARGET_64BIT_MS_ABI)\n \n /* If defined, a C expression whose value is nonzero when we want to use PUSH\n    instructions to pass outgoing arguments.  */"}, {"sha": "42eee33cbe401aa9d35069ab60a3dada1d39dd32", "filename": "gcc/config/i386/x86-tune.def", "status": "modified", "additions": 34, "deletions": 5, "changes": 39, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/41ee845b75a5025e4d376d8df8661e1340b59d0a/gcc%2Fconfig%2Fi386%2Fx86-tune.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/41ee845b75a5025e4d376d8df8661e1340b59d0a/gcc%2Fconfig%2Fi386%2Fx86-tune.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fx86-tune.def?ref=41ee845b75a5025e4d376d8df8661e1340b59d0a", "patch": "@@ -18,15 +18,13 @@ a copy of the GCC Runtime Library Exception along with this program;\n see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n <http://www.gnu.org/licenses/>.  */\n \n-/* X86_TUNE_USE_LEAVE: Leave does not affect Nocona SPEC2000 results\n-   negatively, so enabling for Generic64 seems like good code size\n-   tradeoff.  We can't enable it for 32bit generic because it does not\n-   work well with PPro base chips.  */\n+/* X86_TUNE_USE_LEAVE: Use \"leave\" instruction in epilogues where it fits.  */\n DEF_TUNE (X86_TUNE_USE_LEAVE, \"use_leave\", \n \t  m_386 | m_CORE_ALL | m_K6_GEODE | m_AMD_MULTIPLE | m_GENERIC)\n \n /* X86_TUNE_PUSH_MEMORY: Enable generation of \"push mem\" instructions.\n-   Some chips, like 486 and Pentium have problems with these sequences.  */\n+   Some chips, like 486 and Pentium works faster with separate load\n+   and push instructions.  */\n DEF_TUNE (X86_TUNE_PUSH_MEMORY, \"push_memory\", \n           m_386 | m_P4_NOCONA | m_CORE_ALL | m_K6_GEODE | m_AMD_MULTIPLE \n           | m_GENERIC)\n@@ -210,6 +208,16 @@ DEF_TUNE (X86_TUNE_SSE_UNALIGNED_LOAD_OPTIMAL, \"sse_unaligned_load_optimal\",\n DEF_TUNE (X86_TUNE_SSE_UNALIGNED_STORE_OPTIMAL, \"sse_unaligned_store_optimal\",\n           m_COREI7 | m_BDVER | m_SLM | m_GENERIC)\n \n+/* X86_TUNE_AVX256_UNALIGNED_LOAD_OPTIMAL: if true, unaligned loads are\n+   split.  */\n+DEF_TUNE (X86_TUNE_AVX256_UNALIGNED_LOAD_OPTIMAL, \"256_unaligned_load_optimal\", \n+          ~(m_COREI7 | m_GENERIC))\n+\n+/* X86_TUNE_AVX256_UNALIGNED_STORE_OPTIMAL: if true, unaligned loads are\n+   split.  */\n+DEF_TUNE (X86_TUNE_AVX256_UNALIGNED_STORE_OPTIMAL, \"256_unaligned_load_optimal\", \n+          ~(m_COREI7 | m_BDVER | m_GENERIC))\n+\n /* Use packed single precision instructions where posisble.  I.e. movups instead\n    of movupd.  */\n DEF_TUNE (X86_TUNE_SSE_PACKED_SINGLE_INSN_OPTIMAL, \"sse_packed_single_insn_optimal\",\n@@ -398,3 +406,24 @@ DEF_TUNE (X86_TUNE_AVOID_MEM_OPND_FOR_CMOVE, \"avoid_mem_opnd_for_cmove\",\n    fp converts to destination register.  */\n DEF_TUNE (X86_TUNE_SPLIT_MEM_OPND_FOR_FP_CONVERTS, \"split_mem_opnd_for_fp_converts\",\n           m_SLM)\n+\n+/* X86_TUNE_ACCUMULATE_OUTGOING_ARGS: Allocate stack space for outgoing\n+   arguments in prologue/epilogue instead of separately for each call\n+   by push/pop instructions.\n+   This increase code size by about 5% in 32bit mode, less so in 64bit mode\n+   because parameters are passed in registers.  It is considerable\n+   win for targets without stack engine that prevents multple push operations\n+   to happen in parallel.\n+\n+   FIXME: the flags is incorrectly enabled for amdfam10, Bulldozer,\n+   Bobcat and Generic.  This is because disabling it causes large\n+   regression on mgrid due to IRA limitation leading to unecessary\n+   use of the frame pointer in 32bit mode.  */\n+DEF_TUNE (X86_TUNE_ACCUMULATE_OUTGOING_ARGS, \"accumulate_outgoing_args\", \n+\t  m_PPRO | m_P4_NOCONA | m_ATOM | m_SLM | m_AMD_MULTIPLE | m_GENERIC)\n+\n+/* X86_TUNE_ALWAYS_FANCY_MATH_387: controls use of fancy 387 operations,\n+   such as fsqrt, fprem, fsin, fcos, fsincos etc.\n+   Should be enabled for all targets that always has coprocesor.  */\n+DEF_TUNE (X86_TUNE_ALWAYS_FANCY_MATH_387, \"always_fancy_math_387\", \n+          ~(m_386 | m_486))"}]}