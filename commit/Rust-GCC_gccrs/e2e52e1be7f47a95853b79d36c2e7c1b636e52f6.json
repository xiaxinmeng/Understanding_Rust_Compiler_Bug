{"sha": "e2e52e1be7f47a95853b79d36c2e7c1b636e52f6", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTJlNTJlMWJlN2Y0N2E5NTg1M2I3OWQzNmMyZTdjMWI2MzZlNTJmNg==", "commit": {"author": {"name": "Jan Hubicka", "email": "hubicka@freesoft.cz", "date": "2000-01-18T15:25:05Z"}, "committer": {"name": "Jan Hubicka", "email": "hubicka@gcc.gnu.org", "date": "2000-01-18T15:25:05Z"}, "message": "i386.md (memstr): Do not use rep stosb for counts divisible by 4 when optimize_size.\n\n\t* i386.md (memstr): Do not use rep stosb for counts divisible by 4\n\twhen optimize_size.\n\t(clrstrsi): Rewrite.\n\t(strsethi, strsetqi): New expanders.\n\t(strsethi_1, strsetqi_1, rep_stossi, rep_stosqi): New insn patterns.\n\t(cmpstrsi): Emit compare insn before cmpstrsi_1\n\t(cmpstrsi_nz): use flags, set type to str, prefix_length to 1.\n\t(strlensi_1): Likewise.\n\t(cmpstrsi_1): Likewise; do not output compare.\n\t(strlen expander): Do not unroll when optimizing for size.\n\t(*subsi3_carry): Rename to subsi3_carry\n\t(addqi3_cc): New pattern.\n\t* i386.h (processor_costs): Add move_ratio field.\n\t(MOVE_RATIO): Use move_ratio field, set to 3 for OPTIMIZE_SIZE\n\t* i386.c (*_cost): Set move_ratio.\n\t(x86_unroll_strlen): Enable for Athlon, PPro and K6 too.\n\t(x86_expand_strlensi_1): Rewrite the main loop.\n\nFrom-SVN: r31488", "tree": {"sha": "59d70f3dc18b9115f9b1b36bd1b57390832ce417", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/59d70f3dc18b9115f9b1b36bd1b57390832ce417"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e2e52e1be7f47a95853b79d36c2e7c1b636e52f6", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e2e52e1be7f47a95853b79d36c2e7c1b636e52f6", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e2e52e1be7f47a95853b79d36c2e7c1b636e52f6", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e2e52e1be7f47a95853b79d36c2e7c1b636e52f6/comments", "author": null, "committer": null, "parents": [{"sha": "b9f243c201382f3566742d70ed53a8d300610764", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b9f243c201382f3566742d70ed53a8d300610764", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b9f243c201382f3566742d70ed53a8d300610764"}], "stats": {"total": 361, "additions": 239, "deletions": 122}, "files": [{"sha": "00ce0986c42c4361e76013daba2e86c93d491a79", "filename": "gcc/ChangeLog", "status": "modified", "additions": 20, "deletions": 0, "changes": 20, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2e52e1be7f47a95853b79d36c2e7c1b636e52f6/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2e52e1be7f47a95853b79d36c2e7c1b636e52f6/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=e2e52e1be7f47a95853b79d36c2e7c1b636e52f6", "patch": "@@ -1,3 +1,23 @@\n+Tue Jan 18 16:19:55 MET 2000  Jan Hubicka  <hubicka@freesoft.cz>\n+\n+\t* i386.md (memstr): Do not use rep stosb for counts divisible by 4\n+\twhen optimize_size.\n+\t(clrstrsi): Rewrite.\n+\t(strsethi, strsetqi): New expanders.\n+\t(strsethi_1, strsetqi_1, rep_stossi, rep_stosqi): New insn patterns.\n+\t(cmpstrsi): Emit compare insn before cmpstrsi_1\n+\t(cmpstrsi_nz): use flags, set type to str, prefix_length to 1.\n+\t(strlensi_1): Likewise.\n+\t(cmpstrsi_1): Likewise; do not output compare.\n+\t(strlen expander): Do not unroll when optimizing for size.\n+\t(*subsi3_carry): Rename to subsi3_carry\n+\t(addqi3_cc): New pattern.\n+\t* i386.h (processor_costs): Add move_ratio field.\n+\t(MOVE_RATIO): Use move_ratio field, set to 3 for OPTIMIZE_SIZE\n+\t* i386.c (*_cost): Set move_ratio.\n+\t(x86_unroll_strlen): Enable for Athlon, PPro and K6 too.\n+\t(x86_expand_strlensi_1): Rewrite the main loop.\n+\n 2000-01-17  Richard Henderson  <rth@cygnus.com>\n \n \t* combine.c (combine_simplify_rtx): Give FLOAT_STORE_FLAG_VALUE a mode."}, {"sha": "ded731783b59be8223db6d33a4335fbc347c5ebd", "filename": "gcc/config/i386/i386.c", "status": "modified", "additions": 69, "deletions": 43, "changes": 112, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2e52e1be7f47a95853b79d36c2e7c1b636e52f6/gcc%2Fconfig%2Fi386%2Fi386.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2e52e1be7f47a95853b79d36c2e7c1b636e52f6/gcc%2Fconfig%2Fi386%2Fi386.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.c?ref=e2e52e1be7f47a95853b79d36c2e7c1b636e52f6", "patch": "@@ -64,6 +64,7 @@ struct processor_costs i386_cost = {\t/* 386 specific costs */\n   1,\t\t\t\t\t/* cost of multiply per each bit set */\n   23,\t\t\t\t\t/* cost of a divide/mod */\n   15,\t\t\t\t\t/* \"large\" insn */\n+  3,\t\t\t\t\t/* MOVE_RATIO */\n   4,\t\t\t\t\t/* cost for loading QImode using movzbl */\n   {2, 4, 2},\t\t\t\t/* cost of loading integer registers\n \t\t\t\t\t   in QImode, HImode and SImode.\n@@ -84,6 +85,7 @@ struct processor_costs i486_cost = {\t/* 486 specific costs */\n   1,\t\t\t\t\t/* cost of multiply per each bit set */\n   40,\t\t\t\t\t/* cost of a divide/mod */\n   15,\t\t\t\t\t/* \"large\" insn */\n+  3,\t\t\t\t\t/* MOVE_RATIO */\n   4,\t\t\t\t\t/* cost for loading QImode using movzbl */\n   {2, 4, 2},\t\t\t\t/* cost of loading integer registers\n \t\t\t\t\t   in QImode, HImode and SImode.\n@@ -104,6 +106,7 @@ struct processor_costs pentium_cost = {\n   0,\t\t\t\t\t/* cost of multiply per each bit set */\n   25,\t\t\t\t\t/* cost of a divide/mod */\n   8,\t\t\t\t\t/* \"large\" insn */\n+  6,\t\t\t\t\t/* MOVE_RATIO */\n   6,\t\t\t\t\t/* cost for loading QImode using movzbl */\n   {2, 4, 2},\t\t\t\t/* cost of loading integer registers\n \t\t\t\t\t   in QImode, HImode and SImode.\n@@ -124,6 +127,7 @@ struct processor_costs pentiumpro_cost = {\n   0,\t\t\t\t\t/* cost of multiply per each bit set */\n   17,\t\t\t\t\t/* cost of a divide/mod */\n   8,\t\t\t\t\t/* \"large\" insn */\n+  6,\t\t\t\t\t/* MOVE_RATIO */\n   2,\t\t\t\t\t/* cost for loading QImode using movzbl */\n   {4, 4, 4},\t\t\t\t/* cost of loading integer registers\n \t\t\t\t\t   in QImode, HImode and SImode.\n@@ -144,6 +148,7 @@ struct processor_costs k6_cost = {\n   0,\t\t\t\t\t/* cost of multiply per each bit set */\n   18,\t\t\t\t\t/* cost of a divide/mod */\n   8,\t\t\t\t\t/* \"large\" insn */\n+  4,\t\t\t\t\t/* MOVE_RATIO */\n   3,\t\t\t\t\t/* cost for loading QImode using movzbl */\n   {4, 5, 4},\t\t\t\t/* cost of loading integer registers\n \t\t\t\t\t   in QImode, HImode and SImode.\n@@ -164,6 +169,7 @@ struct processor_costs athlon_cost = {\n   0,\t\t\t\t\t/* cost of multiply per each bit set */\n   19,\t\t\t\t\t/* cost of a divide/mod */\n   8,\t\t\t\t\t/* \"large\" insn */\n+  9,\t\t\t\t\t/* MOVE_RATIO */\n   4,\t\t\t\t\t/* cost for loading QImode using movzbl */\n   {4, 5, 4},\t\t\t\t/* cost of loading integer registers\n \t\t\t\t\t   in QImode, HImode and SImode.\n@@ -191,7 +197,7 @@ const int x86_zero_extend_with_and = m_486 | m_PENT;\n const int x86_movx = m_ATHLON /* m_386 | m_PPRO | m_K6 */;\n const int x86_double_with_add = ~m_386;\n const int x86_use_bit_test = m_386;\n-const int x86_unroll_strlen = m_486 | m_PENT;\n+const int x86_unroll_strlen = m_486 | m_PENT | m_PPRO | m_ATHLON | m_K6;\n const int x86_use_q_reg = m_PENT | m_PPRO | m_K6;\n const int x86_use_any_reg = m_486;\n const int x86_cmove = m_PPRO | m_ATHLON;\n@@ -5149,10 +5155,9 @@ ix86_expand_strlensi_unroll_1 (out, align_rtx, scratch)\n   rtx align_3_label = NULL_RTX;\n   rtx align_4_label = gen_label_rtx ();\n   rtx end_0_label = gen_label_rtx ();\n-  rtx end_2_label = gen_label_rtx ();\n-  rtx end_3_label = gen_label_rtx ();\n   rtx mem;\n   rtx flags = gen_rtx_REG (CCNOmode, FLAGS_REG);\n+  rtx tmpreg = gen_reg_rtx (SImode);\n \n   align = 0;\n   if (GET_CODE (align_rtx) == CONST_INT)\n@@ -5269,48 +5274,69 @@ ix86_expand_strlensi_unroll_1 (out, align_rtx, scratch)\n \n   mem = gen_rtx_MEM (SImode, out);\n   emit_move_insn (scratch, mem);\n-\n-  /* Check first byte. */\n-  emit_insn (gen_cmpqi_0 (gen_lowpart (QImode, scratch), const0_rtx));\n-  tmp = gen_rtx_EQ (VOIDmode, flags, const0_rtx);\n-  tmp = gen_rtx_IF_THEN_ELSE (VOIDmode, tmp, \n-\t\t\t      gen_rtx_LABEL_REF (VOIDmode, end_0_label),\n-\t\t\t      pc_rtx);\n-  emit_jump_insn (gen_rtx_SET (VOIDmode, pc_rtx, tmp));\n-\n-  /* Check second byte. */\n-  emit_insn (gen_cmpqi_ext_3 (scratch, const0_rtx));\n-  tmp = gen_rtx_EQ (VOIDmode, flags, const0_rtx);\n-  tmp = gen_rtx_IF_THEN_ELSE (VOIDmode, tmp, \n-\t\t\t      gen_rtx_LABEL_REF (VOIDmode, end_3_label),\n-\t\t\t      pc_rtx);\n-  emit_jump_insn (gen_rtx_SET (VOIDmode, pc_rtx, tmp));\n-\n-  /* Check third byte. */\n-  emit_insn (gen_testsi_1 (scratch, GEN_INT (0x00ff0000)));\n-  tmp = gen_rtx_EQ (VOIDmode, flags, const0_rtx);\n-  tmp = gen_rtx_IF_THEN_ELSE (VOIDmode, tmp, \n-\t\t\t      gen_rtx_LABEL_REF (VOIDmode, end_2_label),\n-\t\t\t      pc_rtx);\n-  emit_jump_insn (gen_rtx_SET (VOIDmode, pc_rtx, tmp));\n-\n-  /* Check fourth byte and increment address. */\n   emit_insn (gen_addsi3 (out, out, GEN_INT (4)));\n-  emit_insn (gen_testsi_1 (scratch, GEN_INT (0xff000000)));\n-  tmp = gen_rtx_NE (VOIDmode, flags, const0_rtx);\n-  tmp = gen_rtx_IF_THEN_ELSE (VOIDmode, tmp, \n-\t\t\t      gen_rtx_LABEL_REF (VOIDmode, align_4_label),\n-\t\t\t      pc_rtx);\n-  emit_jump_insn (gen_rtx_SET (VOIDmode, pc_rtx, tmp));\n-\n-  /* Now generate fixups when the compare stops within a 4-byte word. */\n-  emit_insn (gen_subsi3 (out, out, GEN_INT (3)));\n-  \n-  emit_label (end_2_label);\n-  emit_insn (gen_addsi3 (out, out, const1_rtx));\n \n-  emit_label (end_3_label);\n-  emit_insn (gen_addsi3 (out, out, const1_rtx));\n+  /* This formula yields a nonzero result iff one of the bytes is zero.\n+     This saves three branches inside loop and many cycles.  */\n+\n+  emit_insn (gen_addsi3 (tmpreg, scratch, GEN_INT (-0x01010101)));\n+  emit_insn (gen_one_cmplsi2 (scratch, scratch));\n+  emit_insn (gen_andsi3 (tmpreg, tmpreg, scratch));\n+  emit_insn (gen_andsi3 (tmpreg, tmpreg, GEN_INT (0x80808080)));\n+  emit_cmp_and_jump_insns (tmpreg, const0_rtx, EQ, 0, SImode, 1, 0, align_4_label);\n+\n+  if (TARGET_CMOVE)\n+    {\n+       rtx reg = gen_reg_rtx (SImode);\n+       emit_move_insn (reg, tmpreg);\n+       emit_insn (gen_lshrsi3 (reg, reg, GEN_INT (16)));\n+\n+       /* If zero is not in the first two bytes, move two bytes forward. */\n+       emit_insn (gen_testsi_1 (tmpreg, GEN_INT (0x8080)));\n+       tmp = gen_rtx_REG (CCNOmode, FLAGS_REG);\n+       tmp = gen_rtx_EQ (VOIDmode, tmp, const0_rtx);\n+       emit_insn (gen_rtx_SET (VOIDmode, tmpreg,\n+\t\t\t       gen_rtx_IF_THEN_ELSE (SImode, tmp,\n+\t\t\t\t       \t\t     reg, \n+\t\t\t\t       \t\t     tmpreg)));\n+       /* Emit lea manually to avoid clobbering of flags.  */\n+       emit_insn (gen_rtx_SET (SImode, reg,\n+\t\t\t       gen_rtx_PLUS (SImode, out, GEN_INT (2))));\n+\n+       tmp = gen_rtx_REG (CCNOmode, FLAGS_REG);\n+       tmp = gen_rtx_EQ (VOIDmode, tmp, const0_rtx);\n+       emit_insn (gen_rtx_SET (VOIDmode, out,\n+\t\t\t       gen_rtx_IF_THEN_ELSE (SImode, tmp,\n+\t\t\t\t       \t\t     reg,\n+\t\t\t\t       \t\t     out)));\n+\n+    }\n+  else\n+    {\n+       rtx end_2_label = gen_label_rtx ();\n+       /* Is zero in the first two bytes? */\n+\n+       emit_insn (gen_testsi_1 (tmpreg, GEN_INT (0x8080)));\n+       tmp = gen_rtx_REG (CCNOmode, FLAGS_REG);\n+       tmp = gen_rtx_NE (VOIDmode, tmp, const0_rtx);\n+       tmp = gen_rtx_IF_THEN_ELSE (VOIDmode, tmp,\n+                            gen_rtx_LABEL_REF (VOIDmode, end_2_label),\n+                            pc_rtx);\n+       tmp = emit_jump_insn (gen_rtx_SET (VOIDmode, pc_rtx, tmp));\n+       JUMP_LABEL (tmp) = end_2_label;\n+\n+       /* Not in the first two.  Move two bytes forward. */\n+       emit_insn (gen_lshrsi3 (tmpreg, tmpreg, GEN_INT (16)));\n+       emit_insn (gen_addsi3 (out, out, GEN_INT (2)));\n+\n+       emit_label (end_2_label);\n+\n+    }\n+\n+  /* Avoid branch in fixing the byte. */\n+  tmpreg = gen_lowpart (QImode, tmpreg);\n+  emit_insn (gen_addqi3_cc (tmpreg, tmpreg, tmpreg));\n+  emit_insn (gen_subsi3_carry (out, out, GEN_INT (3)));\n \n   emit_label (end_0_label);\n }"}, {"sha": "e6111280a7c23857da85a5930200ebd6b04f4b63", "filename": "gcc/config/i386/i386.h", "status": "modified", "additions": 4, "deletions": 6, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2e52e1be7f47a95853b79d36c2e7c1b636e52f6/gcc%2Fconfig%2Fi386%2Fi386.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2e52e1be7f47a95853b79d36c2e7c1b636e52f6/gcc%2Fconfig%2Fi386%2Fi386.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.h?ref=e2e52e1be7f47a95853b79d36c2e7c1b636e52f6", "patch": "@@ -62,6 +62,8 @@ struct processor_costs {\n   int mult_bit;\t\t\t/* cost of multiply per each bit set */\n   int divide;\t\t\t/* cost of a divide/mod */\n   int large_insn;\t\t/* insns larger than this cost more */\n+  int move_ratio;\t\t/* The threshold of number of scalar memory-to-memory\n+\t\t\t\t   move insns.  */\n   int movzbl_load;\t\t/* cost of loading using movzbl */\n   int int_load[3];\t\t/* cost of loading integer registers\n \t\t\t\t   in QImode, HImode and SImode relative\n@@ -1709,13 +1711,9 @@ while (0)\n    Increasing the value will always make code faster, but eventually\n    incurs high cost in increased code size.\n \n-   If you don't define this, a reasonable default is used.\n+   If you don't define this, a reasonable default is used.  */\n \n-   Make this large on i386, since the block move is very inefficient with small\n-   blocks, and the hard register needs of the block move require much reload\n-   work. */\n-\n-#define MOVE_RATIO 5\n+#define MOVE_RATIO (optimize_size ? 3 : ix86_cost->move_ratio)\n \n /* Define if shifts truncate the shift count\n    which implies one can omit a sign-extension or zero-extension"}, {"sha": "0bd532416904b456e311b897f2a0504bad33b8bf", "filename": "gcc/config/i386/i386.md", "status": "modified", "additions": 146, "deletions": 73, "changes": 219, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e2e52e1be7f47a95853b79d36c2e7c1b636e52f6/gcc%2Fconfig%2Fi386%2Fi386.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e2e52e1be7f47a95853b79d36c2e7c1b636e52f6/gcc%2Fconfig%2Fi386%2Fi386.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Fi386%2Fi386.md?ref=e2e52e1be7f47a95853b79d36c2e7c1b636e52f6", "patch": "@@ -3235,6 +3235,15 @@\n   \"add{l}\\\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"alu\")])\n \n+(define_insn \"addqi3_cc\"\n+  [(set (reg:CC 17) (plus:CC (match_operand:QI 1 \"nonimmediate_operand\" \"%0,0\")\n+\t\t    (match_operand:QI 2 \"general_operand\" \"ri,rm\")))\n+   (set (match_operand:QI 0 \"nonimmediate_operand\" \"=rm,r\")\n+\t(plus:QI (match_dup 1) (match_dup 2)))]\n+  \"ix86_binary_operator_ok (PLUS, QImode, operands)\"\n+  \"add{b}\\\\t{%2, %0|%0, %2}\"\n+  [(set_attr \"type\" \"alu\")])\n+\n (define_insn \"*addsi3_carry\"\n   [(set (match_operand:SI 0 \"nonimmediate_operand\" \"=rm,r\")\n \t  (plus:SI (match_operand:SI 1 \"nonimmediate_operand\" \"%0,0\")\n@@ -3736,7 +3745,7 @@\n   \"sub{l}\\\\t{%2, %0|%0, %2}\"\n   [(set_attr \"type\" \"alu\")])\n \n-(define_insn \"*subsi3_carry\"\n+(define_insn \"subsi3_carry\"\n   [(set (match_operand:SI 0 \"nonimmediate_operand\" \"=rm,r\")\n \t  (minus:SI (match_operand:SI 1 \"nonimmediate_operand\" \"0,0\")\n \t    (plus:SI (match_operand:SI 2 \"general_operand\" \"ri,rm\")\n@@ -7841,8 +7850,9 @@\n   srcreg = copy_to_mode_reg (Pmode, XEXP (operands[1], 0));\n \n   emit_insn (gen_cld());\n-  /* When optimizing for size emit simple rep ; movsb instruction.  */\n-  if (!optimize || optimize_size)\n+  /* When optimizing for size emit simple rep ; movsb instruction for\n+     counts not divisible by 4.  */\n+  if ((!optimize || optimize_size) && (INTVAL (operands[2]) & 0x03))\n     {\n       countreg = copy_to_mode_reg (SImode, operands[2]);\n       emit_insn (gen_rep_movqi (destreg, srcreg, countreg,\n@@ -7983,84 +7993,143 @@\n    (set_attr \"memory\" \"both\")])\n \n (define_expand \"clrstrsi\"\n-  [(set (reg:SI 19) (const_int 0))\n-   (set (match_dup 3) (const_int 0))\n-   (parallel [(set (match_operand:BLK 0 \"memory_operand\" \"\")\n-\t\t   (const_int 0))\n-\t      (use (match_operand:SI 1 \"const_int_operand\" \"\"))\n-\t      (use (match_operand:SI 2 \"const_int_operand\" \"\"))\n-\t      (use (match_dup 3))\n-\t      (use (reg:SI 19))\n-\t      (clobber (match_scratch:SI 4 \"\"))\n-\t      (clobber (match_dup 5))])]\n+   [(use (match_operand:BLK 0 \"memory_operand\" \"\"))\n+    (use (match_operand:SI 1 \"const_int_operand\" \"\"))\n+    (use (match_operand:SI 2 \"const_int_operand\" \"\"))]\n   \"\"\n   \"\n {\n-  rtx addr0;\n+  rtx destreg, zeroreg, countreg;\n \n   if (GET_CODE (operands[1]) != CONST_INT)\n     FAIL;\n \n-  addr0 = copy_to_mode_reg (Pmode, XEXP (operands[0], 0));\n+  destreg = copy_to_mode_reg (Pmode, XEXP (operands[0], 0));\n+\n+  emit_insn (gen_cld());\n+\n+  /* When optimizing for size emit simple rep ; movsb instruction for\n+     counts not divisible by 4.  */\n+  if ((!optimize || optimize_size) && (INTVAL (operands[1]) & 0x03))\n+    {\n+      countreg = copy_to_mode_reg (SImode, operands[1]);\n+      zeroreg = copy_to_mode_reg (QImode, const0_rtx);\n+      emit_insn (gen_rep_stosqi (destreg, countreg, zeroreg,\n+\t\t\t\t destreg, countreg));\n+    }\n+  else\n+    {\n+      zeroreg = copy_to_mode_reg (SImode, const0_rtx);\n+      if (INTVAL (operands[1]) & ~0x03)\n+\t{\n+\t  countreg = copy_to_mode_reg (SImode,\n+\t  \t\t\t       GEN_INT ((INTVAL (operands[1]) >> 2)\n+\t\t\t\t\t\t& 0x3fffffff));\n+\t  emit_insn (gen_rep_stossi (destreg, countreg, zeroreg,\n+\t\t\t\t     destreg, countreg));\n+\t}\n+      if (INTVAL (operands[1]) & 0x02)\n+\temit_insn (gen_strsethi (destreg,\n+\t\t\t\t gen_rtx_SUBREG (HImode, zeroreg, 0)));\n+      if (INTVAL (operands[1]) & 0x01)\n+\temit_insn (gen_strsetqi (destreg,\n+\t\t\t\t gen_rtx_SUBREG (QImode, zeroreg, 0)));\n+    }\n+  DONE;\n+}\")\n+\n+;; Most CPUs don't like single string operations\n+;; Handle this case here to simplify previous expander.\n \n-  operands[3] = gen_reg_rtx (SImode);\n-  operands[5] = addr0;\n+(define_expand \"strsethi\"\n+  [(set (mem:HI (match_operand:SI 0 \"register_operand\" \"\"))\n+\t(match_operand:HI 1 \"register_operand\" \"\"))\n+   (parallel [(set (match_dup 0) (plus:SI (match_dup 0) (const_int 2)))\n+\t      (clobber (reg:CC 17))])]\n+  \"\"\n+  \"\n+{\n+  if (TARGET_SINGLE_STRINGOP || optimize_size)\n+    {\n+      emit_insn (gen_strsethi_1 (operands[0], operands[0], operands[1]));\n+      DONE;\n+    }\n+}\")\n \n-  operands[0] = gen_rtx_MEM (BLKmode, addr0);\n+(define_expand \"strsetqi\"\n+  [(set (mem:QI (match_operand:SI 0 \"register_operand\" \"\"))\n+\t(match_operand:QI 1 \"register_operand\" \"\"))\n+   (parallel [(set (match_dup 0) (plus:SI (match_dup 0) (const_int 1)))\n+\t      (clobber (reg:CC 17))])]\n+  \"\"\n+  \"\n+{\n+  if (TARGET_SINGLE_STRINGOP || optimize_size)\n+    {\n+      emit_insn (gen_strsetqi_1 (operands[0], operands[0], operands[1]));\n+      DONE;\n+    }\n }\")\n \n+(define_insn \"strsethi_1\"\n+  [(set (mem:HI (match_operand:SI 1 \"register_operand\" \"0\"))\n+\t(match_operand:HI 2 \"register_operand\" \"a\"))\n+   (set (match_operand:SI 0 \"register_operand\" \"=D\")\n+\t(plus:SI (match_dup 0)\n+\t\t (const_int 2)))\n+   (use (reg:SI 19))]\n+  \"TARGET_SINGLE_STRINGOP || optimize_size\"\n+  \"stosw\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"memory\" \"store\")\n+   (set_attr \"length_prefix\" \"1\")])\n+\n+(define_insn \"strsetqi_1\"\n+  [(set (mem:QI (match_operand:SI 1 \"register_operand\" \"0\"))\n+\t(match_operand:QI 2 \"register_operand\" \"a\"))\n+   (set (match_operand:SI 0 \"register_operand\" \"=D\")\n+\t(plus:SI (match_dup 0)\n+\t\t (const_int 1)))\n+   (use (reg:SI 19))]\n+  \"TARGET_SINGLE_STRINGOP || optimize_size\"\n+  \"stosb\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"memory\" \"store\")])\n+\n ;; It might seem that operand 0 could use predicate register_operand.\n ;; But strength reduction might offset the MEM expression.  So we let\n ;; reload put the address into %edi.\n \n-(define_insn \"*clrstrsi_1\"\n-  [(set (mem:BLK (match_operand:SI 0 \"address_operand\" \"D\"))\n+(define_insn \"rep_stossi\"\n+  [(set (match_operand:SI 1 \"register_operand\" \"=c\") (const_int 0))\n+   (use (match_operand:SI 2 \"register_operand\" \"a\"))\n+   (use (match_operand:SI 4 \"register_operand\" \"1\"))\n+   (set (match_operand:SI 0 \"register_operand\" \"=D\") \n+        (plus:SI (match_operand:SI 3 \"address_operand\" \"0\")\n+\t         (ashift:SI (match_dup 3) (const_int 2))))\n+   (set (mem:BLK (match_dup 3))\n \t(const_int 0))\n-   (use (match_operand:SI 1 \"const_int_operand\" \"n\"))\n-   (use (match_operand:SI 2 \"immediate_operand\" \"i\"))\n-   (use (match_operand:SI 3 \"register_operand\" \"a\"))\n-   (use (reg:SI 19))\n-   (clobber (match_scratch:SI 4 \"=&c\"))\n-   (clobber (match_dup 0))]\n+   (use (reg:SI 19))]\n   \"\"\n-  \"*\n-{\n-  rtx xops[2];\n+  \"rep\\;stosl|rep stosd\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"length_prefix\" \"1\")\n+   (set_attr \"memory\" \"store\")])\n \n-  if (GET_CODE (operands[1]) == CONST_INT)\n-    {\n-      unsigned int count = INTVAL (operands[1]) & 0xffffffff;\n-      if (count & ~0x03)\n-\t{\n-\t  xops[0] = GEN_INT (count / 4);\n-\t  xops[1] = operands[4];\n-\n-\t  /* K6: stos takes 1 cycle, rep stos takes 8 + %ecx cycles.\n-\t     80386: 4/5+5n (+2 for set of ecx)\n-\t     80486: 5/7+5n (+1 for set of ecx)\n-\t     */\n-\t  if (count / 4 < ((int) ix86_cpu < (int)PROCESSOR_PENTIUM ? 4 : 6))\n-\t    {\n-\t      do\n-\t\toutput_asm_insn (\\\"{stosl|stosd}\\\", xops);\n-\t      while ((count -= 4) > 3);\n-\t    }\n-\t  else\n-\t    {\n-\t      output_asm_insn (\\\"mov{l}\\\\t{%0, %1|%1, %0}\\\", xops);\n-\t      output_asm_insn (\\\"{rep\\;stosl|rep stosd}\\\", xops);\n-\t    }\n-\t}\n-      if (INTVAL (operands[1]) & 0x02)\n-\toutput_asm_insn (\\\"stosw\\\", operands);\n-      if (INTVAL (operands[1]) & 0x01)\n-\toutput_asm_insn (\\\"stosb\\\", operands);\n-    }\n-  else\n-    abort ();\n-  RET;\n-}\"\n-  [(set_attr \"type\" \"multi\")])\n+(define_insn \"rep_stosqi\"\n+  [(set (match_operand:SI 1 \"register_operand\" \"=c\") (const_int 0))\n+   (use (match_operand:QI 2 \"register_operand\" \"a\"))\n+   (use (match_operand:SI 4 \"register_operand\" \"1\"))\n+   (set (match_operand:SI 0 \"register_operand\" \"=D\") \n+        (plus:SI (match_operand:SI 3 \"address_operand\" \"0\") (match_dup 3)))\n+   (set (mem:BLK (match_dup 3))\n+\t(const_int 0))\n+   (use (reg:SI 19))]\n+  \"\"\n+  \"rep\\;stosb|rep stosb\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"length_prefix\" \"1\")\n+   (set_attr \"memory\" \"store\")])\n \n (define_expand \"cmpstrsi\"\n   [(set (match_operand:SI 0 \"register_operand\" \"\")\n@@ -8099,7 +8168,10 @@\n       emit_insn (gen_cmpstrsi_nz_1 (addr1, addr2, countreg, align));\n     }\n   else\n-    emit_insn (gen_cmpstrsi_1 (addr1, addr2, countreg, align));\n+    {\n+      emit_insn (gen_cmpsi_1 (countreg, countreg));\n+      emit_insn (gen_cmpstrsi_1 (addr1, addr2, countreg, align));\n+    }\n \n   outlow = gen_lowpart (QImode, out);\n   emit_insn (gen_cmpintqi (outlow));\n@@ -8145,8 +8217,8 @@\n    (clobber (match_dup 2))]\n   \"\"\n   \"repz{\\;| }cmpsb\"\n-  [(set_attr \"type\" \"multi\")\n-   (set_attr \"length\" \"3\")])\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"length_prefix\" \"1\")])\n \n ;; The same, but the count is not known to not be zero.\n \n@@ -8158,15 +8230,15 @@\n \t\t      (mem:BLK (match_operand:SI 1 \"address_operand\" \"D\")))\n \t  (const_int 0)))\n    (use (match_operand:SI 3 \"immediate_operand\" \"i\"))\n+   (use (reg:CC 17))\n    (use (reg:SI 19))\n    (clobber (match_dup 0))\n    (clobber (match_dup 1))\n    (clobber (match_dup 2))]\n   \"\"\n-  ;; The initial compare sets the zero flag.\n-  \"cmp{l}\\\\t%2, %2\\;repz{\\;| }cmpsb\"\n-  [(set_attr \"type\" \"multi\")\n-   (set_attr \"length\" \"5\")])\n+  \"repz{\\;| }cmpsb\"\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"length_prefix\" \"1\")])\n \n (define_expand \"strlensi\"\n   [(set (match_operand:SI 0 \"register_operand\" \"\")\n@@ -8184,7 +8256,8 @@\n   align = operands[3];\n   scratch1 = gen_reg_rtx (SImode);\n \n-  if (TARGET_UNROLL_STRLEN && eoschar == const0_rtx && optimize > 1)\n+  if (TARGET_UNROLL_STRLEN && eoschar == const0_rtx && optimize > 1\n+      && !optimize_size)\n     {\n       /* Well it seems that some optimizer does not combine a call like\n \t     foo(strlen(bar), strlen(bar));\n@@ -8236,8 +8309,8 @@\n    (clobber (reg:CC 17))]\n   \"\"\n   \"repnz{\\;| }scasb\"\n-  [(set_attr \"type\" \"multi\")\n-   (set_attr \"length\" \"3\")])\n+  [(set_attr \"type\" \"str\")\n+   (set_attr \"length_prefix\" \"1\")])\n \f\n ;; Conditional move instructions.\n "}]}