{"sha": "0b73246f1a11354037b6bb069ab1056f121e34fd", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MGI3MzI0NmYxYTExMzU0MDM3YjZiYjA2OWFiMTA1NmYxMjFlMzRmZA==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@linaro.org", "date": "2017-08-30T11:15:28Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2017-08-30T11:15:28Z"}, "message": "[41/77] Split scalar integer handling out of force_to_mode\n\nforce_to_mode exits partway through for modes that aren't scalar\nintegers.  This patch splits the remainder of the function out\ninto a subroutine, force_int_to_mode, so that the modes from that\npoint on can have type scalar_int_mode.\n\nThe patch also makes sure that xmode is kept up-to-date with x\nand uses xmode instead of GET_MODE (x) throughout.\n\n2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n\t    Alan Hayward  <alan.hayward@arm.com>\n\t    David Sherwood  <david.sherwood@arm.com>\n\ngcc/\n\t* combine.c (force_int_to_mode): New function, split out from...\n\t(force_to_mode): ...here.  Keep xmode up-to-date and use it\n\tinstead of GET_MODE (x).\n\nCo-Authored-By: Alan Hayward <alan.hayward@arm.com>\nCo-Authored-By: David Sherwood <david.sherwood@arm.com>\n\nFrom-SVN: r251493", "tree": {"sha": "abbdf6159fb23149e5bcb1c2ed38028bb4c98fa6", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/abbdf6159fb23149e5bcb1c2ed38028bb4c98fa6"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/0b73246f1a11354037b6bb069ab1056f121e34fd", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0b73246f1a11354037b6bb069ab1056f121e34fd", "html_url": "https://github.com/Rust-GCC/gccrs/commit/0b73246f1a11354037b6bb069ab1056f121e34fd", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/0b73246f1a11354037b6bb069ab1056f121e34fd/comments", "author": null, "committer": null, "parents": [{"sha": "5602f58c633e51b03b5f18bbd65924b4b842d075", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5602f58c633e51b03b5f18bbd65924b4b842d075", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5602f58c633e51b03b5f18bbd65924b4b842d075"}], "stats": {"total": 183, "additions": 111, "deletions": 72}, "files": [{"sha": "57cd94c7fcd48779826012ce243e314bbef65fd9", "filename": "gcc/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b73246f1a11354037b6bb069ab1056f121e34fd/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b73246f1a11354037b6bb069ab1056f121e34fd/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=0b73246f1a11354037b6bb069ab1056f121e34fd", "patch": "@@ -1,3 +1,11 @@\n+2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n+\t    Alan Hayward  <alan.hayward@arm.com>\n+\t    David Sherwood  <david.sherwood@arm.com>\n+\n+\t* combine.c (force_int_to_mode): New function, split out from...\n+\t(force_to_mode): ...here.  Keep xmode up-to-date and use it\n+\tinstead of GET_MODE (x).\n+\n 2017-08-30  Richard Sandiford  <richard.sandiford@linaro.org>\n \t    Alan Hayward  <alan.hayward@arm.com>\n \t    David Sherwood  <david.sherwood@arm.com>"}, {"sha": "d41f5e49c93d749c0b43895c3ccfc420c604f56e", "filename": "gcc/combine.c", "status": "modified", "additions": 103, "deletions": 72, "changes": 175, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/0b73246f1a11354037b6bb069ab1056f121e34fd/gcc%2Fcombine.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/0b73246f1a11354037b6bb069ab1056f121e34fd/gcc%2Fcombine.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcombine.c?ref=0b73246f1a11354037b6bb069ab1056f121e34fd", "patch": "@@ -449,6 +449,8 @@ static rtx extract_left_shift (rtx, int);\n static int get_pos_from_mask (unsigned HOST_WIDE_INT,\n \t\t\t      unsigned HOST_WIDE_INT *);\n static rtx canon_reg_for_combine (rtx, rtx);\n+static rtx force_int_to_mode (rtx, scalar_int_mode, scalar_int_mode,\n+\t\t\t      scalar_int_mode, unsigned HOST_WIDE_INT, int);\n static rtx force_to_mode (rtx, machine_mode,\n \t\t\t  unsigned HOST_WIDE_INT, int);\n static rtx if_then_else_cond (rtx, rtx *, rtx *);\n@@ -8495,8 +8497,7 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n   enum rtx_code code = GET_CODE (x);\n   int next_select = just_select || code == XOR || code == NOT || code == NEG;\n   machine_mode op_mode;\n-  unsigned HOST_WIDE_INT fuller_mask, nonzero;\n-  rtx op0, op1, temp;\n+  unsigned HOST_WIDE_INT nonzero;\n \n   /* If this is a CALL or ASM_OPERANDS, don't do anything.  Some of the\n      code below will do the wrong thing since the mode of such an\n@@ -8524,15 +8525,6 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n   if (op_mode)\n     mask &= GET_MODE_MASK (op_mode);\n \n-  /* When we have an arithmetic operation, or a shift whose count we\n-     do not know, we need to assume that all bits up to the highest-order\n-     bit in MASK will be needed.  This is how we form such a mask.  */\n-  if (mask & (HOST_WIDE_INT_1U << (HOST_BITS_PER_WIDE_INT - 1)))\n-    fuller_mask = HOST_WIDE_INT_M1U;\n-  else\n-    fuller_mask = ((HOST_WIDE_INT_1U << (floor_log2 (mask) + 1))\n-\t\t   - 1);\n-\n   /* Determine what bits of X are guaranteed to be (non)zero.  */\n   nonzero = nonzero_bits (x, mode);\n \n@@ -8570,9 +8562,42 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n \t\t    & ~GET_MODE_MASK (GET_MODE (SUBREG_REG (x)))))))\n     return force_to_mode (SUBREG_REG (x), mode, mask, next_select);\n \n-  /* The arithmetic simplifications here only work for scalar integer modes.  */\n-  if (!SCALAR_INT_MODE_P (mode) || !SCALAR_INT_MODE_P (GET_MODE (x)))\n-    return gen_lowpart_or_truncate (mode, x);\n+  scalar_int_mode int_mode, xmode;\n+  if (is_a <scalar_int_mode> (mode, &int_mode)\n+      && is_a <scalar_int_mode> (GET_MODE (x), &xmode))\n+    /* OP_MODE is either MODE or XMODE, so it must be a scalar\n+       integer too.  */\n+    return force_int_to_mode (x, int_mode, xmode,\n+\t\t\t      as_a <scalar_int_mode> (op_mode),\n+\t\t\t      mask, just_select);\n+\n+  return gen_lowpart_or_truncate (mode, x);\n+}\n+\n+/* Subroutine of force_to_mode that handles cases in which both X and\n+   the result are scalar integers.  MODE is the mode of the result,\n+   XMODE is the mode of X, and OP_MODE says which of MODE or XMODE\n+   is preferred for simplified versions of X.  The other arguments\n+   are as for force_to_mode.  */\n+\n+static rtx\n+force_int_to_mode (rtx x, scalar_int_mode mode, scalar_int_mode xmode,\n+\t\t   scalar_int_mode op_mode, unsigned HOST_WIDE_INT mask,\n+\t\t   int just_select)\n+{\n+  enum rtx_code code = GET_CODE (x);\n+  int next_select = just_select || code == XOR || code == NOT || code == NEG;\n+  unsigned HOST_WIDE_INT fuller_mask;\n+  rtx op0, op1, temp;\n+\n+  /* When we have an arithmetic operation, or a shift whose count we\n+     do not know, we need to assume that all bits up to the highest-order\n+     bit in MASK will be needed.  This is how we form such a mask.  */\n+  if (mask & (HOST_WIDE_INT_1U << (HOST_BITS_PER_WIDE_INT - 1)))\n+    fuller_mask = HOST_WIDE_INT_M1U;\n+  else\n+    fuller_mask = ((HOST_WIDE_INT_1U << (floor_log2 (mask) + 1))\n+\t\t   - 1);\n \n   switch (code)\n     {\n@@ -8603,14 +8628,14 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n \t{\n \t  x = simplify_and_const_int (x, op_mode, XEXP (x, 0),\n \t\t\t\t      mask & INTVAL (XEXP (x, 1)));\n+\t  xmode = op_mode;\n \n \t  /* If X is still an AND, see if it is an AND with a mask that\n \t     is just some low-order bits.  If so, and it is MASK, we don't\n \t     need it.  */\n \n \t  if (GET_CODE (x) == AND && CONST_INT_P (XEXP (x, 1))\n-\t      && ((INTVAL (XEXP (x, 1)) & GET_MODE_MASK (GET_MODE (x)))\n-\t\t  == mask))\n+\t      && (INTVAL (XEXP (x, 1)) & GET_MODE_MASK (xmode)) == mask)\n \t    x = XEXP (x, 0);\n \n \t  /* If it remains an AND, try making another AND with the bits\n@@ -8619,18 +8644,17 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n \t     cheaper constant.  */\n \n \t  if (GET_CODE (x) == AND && CONST_INT_P (XEXP (x, 1))\n-\t      && GET_MODE_MASK (GET_MODE (x)) != mask\n-\t      && HWI_COMPUTABLE_MODE_P (GET_MODE (x)))\n+\t      && GET_MODE_MASK (xmode) != mask\n+\t      && HWI_COMPUTABLE_MODE_P (xmode))\n \t    {\n \t      unsigned HOST_WIDE_INT cval\n-\t\t= UINTVAL (XEXP (x, 1))\n-\t\t  | (GET_MODE_MASK (GET_MODE (x)) & ~mask);\n+\t\t= UINTVAL (XEXP (x, 1)) | (GET_MODE_MASK (xmode) & ~mask);\n \t      rtx y;\n \n-\t      y = simplify_gen_binary (AND, GET_MODE (x), XEXP (x, 0),\n-\t\t\t\t       gen_int_mode (cval, GET_MODE (x)));\n-\t      if (set_src_cost (y, GET_MODE (x), optimize_this_for_speed_p)\n-\t          < set_src_cost (x, GET_MODE (x), optimize_this_for_speed_p))\n+\t      y = simplify_gen_binary (AND, xmode, XEXP (x, 0),\n+\t\t\t\t       gen_int_mode (cval, xmode));\n+\t      if (set_src_cost (y, xmode, optimize_this_for_speed_p)\n+\t\t  < set_src_cost (x, xmode, optimize_this_for_speed_p))\n \t\tx = y;\n \t    }\n \n@@ -8660,7 +8684,7 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n \t    && pow2p_hwi (- smask)\n \t    && (nonzero_bits (XEXP (x, 0), mode) & ~smask) == 0\n \t    && (INTVAL (XEXP (x, 1)) & ~smask) != 0)\n-\t  return force_to_mode (plus_constant (GET_MODE (x), XEXP (x, 0),\n+\t  return force_to_mode (plus_constant (xmode, XEXP (x, 0),\n \t\t\t\t\t       (INTVAL (XEXP (x, 1)) & smask)),\n \t\t\t\tmode, smask, next_select);\n       }\n@@ -8691,8 +8715,7 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n       if (CONST_INT_P (XEXP (x, 0))\n \t  && least_bit_hwi (UINTVAL (XEXP (x, 0))) > mask)\n \t{\n-\t  x = simplify_gen_unary (NEG, GET_MODE (x), XEXP (x, 1),\n-\t\t\t\t  GET_MODE (x));\n+\t  x = simplify_gen_unary (NEG, xmode, XEXP (x, 1), xmode);\n \t  return force_to_mode (x, mode, mask, next_select);\n \t}\n \n@@ -8701,8 +8724,7 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n       if (CONST_INT_P (XEXP (x, 0))\n \t  && ((UINTVAL (XEXP (x, 0)) | fuller_mask) == UINTVAL (XEXP (x, 0))))\n \t{\n-\t  x = simplify_gen_unary (NOT, GET_MODE (x),\n-\t\t\t\t  XEXP (x, 1), GET_MODE (x));\n+\t  x = simplify_gen_unary (NOT, xmode, XEXP (x, 1), xmode);\n \t  return force_to_mode (x, mode, mask, next_select);\n \t}\n \n@@ -8723,16 +8745,16 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n \t  && CONST_INT_P (XEXP (x, 1))\n \t  && ((INTVAL (XEXP (XEXP (x, 0), 1))\n \t       + floor_log2 (INTVAL (XEXP (x, 1))))\n-\t      < GET_MODE_PRECISION (GET_MODE (x)))\n+\t      < GET_MODE_PRECISION (xmode))\n \t  && (UINTVAL (XEXP (x, 1))\n-\t      & ~nonzero_bits (XEXP (x, 0), GET_MODE (x))) == 0)\n+\t      & ~nonzero_bits (XEXP (x, 0), xmode)) == 0)\n \t{\n \t  temp = gen_int_mode ((INTVAL (XEXP (x, 1)) & mask)\n \t\t\t       << INTVAL (XEXP (XEXP (x, 0), 1)),\n-\t\t\t       GET_MODE (x));\n-\t  temp = simplify_gen_binary (GET_CODE (x), GET_MODE (x),\n+\t\t\t       xmode);\n+\t  temp = simplify_gen_binary (GET_CODE (x), xmode,\n \t\t\t\t      XEXP (XEXP (x, 0), 0), temp);\n-\t  x = simplify_gen_binary (LSHIFTRT, GET_MODE (x), temp,\n+\t  x = simplify_gen_binary (LSHIFTRT, xmode, temp,\n \t\t\t\t   XEXP (XEXP (x, 0), 1));\n \t  return force_to_mode (x, mode, mask, next_select);\n \t}\n@@ -8756,8 +8778,11 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n       op0 = gen_lowpart_or_truncate (op_mode, op0);\n       op1 = gen_lowpart_or_truncate (op_mode, op1);\n \n-      if (op_mode != GET_MODE (x) || op0 != XEXP (x, 0) || op1 != XEXP (x, 1))\n-\tx = simplify_gen_binary (code, op_mode, op0, op1);\n+      if (op_mode != xmode || op0 != XEXP (x, 0) || op1 != XEXP (x, 1))\n+\t{\n+\t  x = simplify_gen_binary (code, op_mode, op0, op1);\n+\t  xmode = op_mode;\n+\t}\n       break;\n \n     case ASHIFT:\n@@ -8790,8 +8815,11 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n \t\t\t\t     force_to_mode (XEXP (x, 0), op_mode,\n \t\t\t\t\t\t    mask, next_select));\n \n-      if (op_mode != GET_MODE (x) || op0 != XEXP (x, 0))\n-\tx = simplify_gen_binary (code, op_mode, op0, XEXP (x, 1));\n+      if (op_mode != xmode || op0 != XEXP (x, 0))\n+\t{\n+\t  x = simplify_gen_binary (code, op_mode, op0, XEXP (x, 1));\n+\t  xmode = op_mode;\n+\t}\n       break;\n \n     case LSHIFTRT:\n@@ -8813,13 +8841,16 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n \t  /* We can only change the mode of the shift if we can do arithmetic\n \t     in the mode of the shift and INNER_MASK is no wider than the\n \t     width of X's mode.  */\n-\t  if ((inner_mask & ~GET_MODE_MASK (GET_MODE (x))) != 0)\n-\t    op_mode = GET_MODE (x);\n+\t  if ((inner_mask & ~GET_MODE_MASK (xmode)) != 0)\n+\t    op_mode = xmode;\n \n \t  inner = force_to_mode (inner, op_mode, inner_mask, next_select);\n \n-\t  if (GET_MODE (x) != op_mode || inner != XEXP (x, 0))\n-\t    x = simplify_gen_binary (LSHIFTRT, op_mode, inner, XEXP (x, 1));\n+\t  if (xmode != op_mode || inner != XEXP (x, 0))\n+\t    {\n+\t      x = simplify_gen_binary (LSHIFTRT, op_mode, inner, XEXP (x, 1));\n+\t      xmode = op_mode;\n+\t    }\n \t}\n \n       /* If we have (and (lshiftrt FOO C1) C2) where the combination of the\n@@ -8832,25 +8863,25 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n \t     bit.  */\n \t  && ((INTVAL (XEXP (x, 1))\n \t       + num_sign_bit_copies (XEXP (x, 0), GET_MODE (XEXP (x, 0))))\n-\t      >= GET_MODE_PRECISION (GET_MODE (x)))\n+\t      >= GET_MODE_PRECISION (xmode))\n \t  && pow2p_hwi (mask + 1)\n \t  /* Number of bits left after the shift must be more than the mask\n \t     needs.  */\n \t  && ((INTVAL (XEXP (x, 1)) + exact_log2 (mask + 1))\n-\t      <= GET_MODE_PRECISION (GET_MODE (x)))\n+\t      <= GET_MODE_PRECISION (xmode))\n \t  /* Must be more sign bit copies than the mask needs.  */\n \t  && ((int) num_sign_bit_copies (XEXP (x, 0), GET_MODE (XEXP (x, 0)))\n \t      >= exact_log2 (mask + 1)))\n-\tx = simplify_gen_binary (LSHIFTRT, GET_MODE (x), XEXP (x, 0),\n-\t\t\t\t GEN_INT (GET_MODE_PRECISION (GET_MODE (x))\n+\tx = simplify_gen_binary (LSHIFTRT, xmode, XEXP (x, 0),\n+\t\t\t\t GEN_INT (GET_MODE_PRECISION (xmode)\n \t\t\t\t\t  - exact_log2 (mask + 1)));\n \n       goto shiftrt;\n \n     case ASHIFTRT:\n       /* If we are just looking for the sign bit, we don't need this shift at\n \t all, even if it has a variable count.  */\n-      if (val_signbit_p (GET_MODE (x), mask))\n+      if (val_signbit_p (xmode, mask))\n \treturn force_to_mode (XEXP (x, 0), mode, mask, next_select);\n \n       /* If this is a shift by a constant, get a mask that contains those bits\n@@ -8863,13 +8894,14 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n       if (CONST_INT_P (XEXP (x, 1)) && INTVAL (XEXP (x, 1)) >= 0\n \t  && INTVAL (XEXP (x, 1)) < HOST_BITS_PER_WIDE_INT)\n \t{\n+\t  unsigned HOST_WIDE_INT nonzero;\n \t  int i;\n \n \t  /* If the considered data is wider than HOST_WIDE_INT, we can't\n \t     represent a mask for all its bits in a single scalar.\n \t     But we only care about the lower bits, so calculate these.  */\n \n-\t  if (GET_MODE_PRECISION (GET_MODE (x)) > HOST_BITS_PER_WIDE_INT)\n+\t  if (GET_MODE_PRECISION (xmode) > HOST_BITS_PER_WIDE_INT)\n \t    {\n \t      nonzero = HOST_WIDE_INT_M1U;\n \n@@ -8878,21 +8910,21 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n \t\t We need only shift if these are fewer than nonzero can\n \t\t hold.  If not, we must keep all bits set in nonzero.  */\n \n-\t      if (GET_MODE_PRECISION (GET_MODE (x)) - INTVAL (XEXP (x, 1))\n+\t      if (GET_MODE_PRECISION (xmode) - INTVAL (XEXP (x, 1))\n \t\t  < HOST_BITS_PER_WIDE_INT)\n \t\tnonzero >>= INTVAL (XEXP (x, 1))\n \t\t\t    + HOST_BITS_PER_WIDE_INT\n-\t\t\t    - GET_MODE_PRECISION (GET_MODE (x)) ;\n+\t\t\t    - GET_MODE_PRECISION (xmode);\n \t    }\n \t  else\n \t    {\n-\t      nonzero = GET_MODE_MASK (GET_MODE (x));\n+\t      nonzero = GET_MODE_MASK (xmode);\n \t      nonzero >>= INTVAL (XEXP (x, 1));\n \t    }\n \n \t  if ((mask & ~nonzero) == 0)\n \t    {\n-\t      x = simplify_shift_const (NULL_RTX, LSHIFTRT, GET_MODE (x),\n+\t      x = simplify_shift_const (NULL_RTX, LSHIFTRT, xmode,\n \t\t\t\t\tXEXP (x, 0), INTVAL (XEXP (x, 1)));\n \t      if (GET_CODE (x) != ASHIFTRT)\n \t\treturn force_to_mode (x, mode, mask, next_select);\n@@ -8901,8 +8933,8 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n \t  else if ((i = exact_log2 (mask)) >= 0)\n \t    {\n \t      x = simplify_shift_const\n-\t\t  (NULL_RTX, LSHIFTRT, GET_MODE (x), XEXP (x, 0),\n-\t\t   GET_MODE_PRECISION (GET_MODE (x)) - 1 - i);\n+\t\t  (NULL_RTX, LSHIFTRT, xmode, XEXP (x, 0),\n+\t\t   GET_MODE_PRECISION (xmode) - 1 - i);\n \n \t      if (GET_CODE (x) != ASHIFTRT)\n \t\treturn force_to_mode (x, mode, mask, next_select);\n@@ -8912,8 +8944,7 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n       /* If MASK is 1, convert this to an LSHIFTRT.  This can be done\n \t even if the shift count isn't a constant.  */\n       if (mask == 1)\n-\tx = simplify_gen_binary (LSHIFTRT, GET_MODE (x),\n-\t\t\t\t XEXP (x, 0), XEXP (x, 1));\n+\tx = simplify_gen_binary (LSHIFTRT, xmode, XEXP (x, 0), XEXP (x, 1));\n \n     shiftrt:\n \n@@ -8925,7 +8956,7 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n \t  && CONST_INT_P (XEXP (x, 1))\n \t  && INTVAL (XEXP (x, 1)) >= 0\n \t  && (INTVAL (XEXP (x, 1))\n-\t      <= GET_MODE_PRECISION (GET_MODE (x)) - (floor_log2 (mask) + 1))\n+\t      <= GET_MODE_PRECISION (xmode) - (floor_log2 (mask) + 1))\n \t  && GET_CODE (XEXP (x, 0)) == ASHIFT\n \t  && XEXP (XEXP (x, 0), 1) == XEXP (x, 1))\n \treturn force_to_mode (XEXP (XEXP (x, 0), 0), mode, mask,\n@@ -8943,12 +8974,11 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n \t  && INTVAL (XEXP (x, 1)) >= 0)\n \t{\n \t  temp = simplify_binary_operation (code == ROTATE ? ROTATERT : ROTATE,\n-\t\t\t\t\t    GET_MODE (x),\n-\t\t\t\t\t    gen_int_mode (mask, GET_MODE (x)),\n+\t\t\t\t\t    xmode, gen_int_mode (mask, xmode),\n \t\t\t\t\t    XEXP (x, 1));\n \t  if (temp && CONST_INT_P (temp))\n-\t    x = simplify_gen_binary (code, GET_MODE (x),\n-\t\t\t\t     force_to_mode (XEXP (x, 0), GET_MODE (x),\n+\t    x = simplify_gen_binary (code, xmode,\n+\t\t\t\t     force_to_mode (XEXP (x, 0), xmode,\n \t\t\t\t\t\t    INTVAL (temp), next_select),\n \t\t\t\t     XEXP (x, 1));\n \t}\n@@ -8975,14 +9005,12 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n \t  && CONST_INT_P (XEXP (XEXP (x, 0), 1))\n \t  && INTVAL (XEXP (XEXP (x, 0), 1)) >= 0\n \t  && (INTVAL (XEXP (XEXP (x, 0), 1)) + floor_log2 (mask)\n-\t      < GET_MODE_PRECISION (GET_MODE (x)))\n+\t      < GET_MODE_PRECISION (xmode))\n \t  && INTVAL (XEXP (XEXP (x, 0), 1)) < HOST_BITS_PER_WIDE_INT)\n \t{\n-\t  temp = gen_int_mode (mask << INTVAL (XEXP (XEXP (x, 0), 1)),\n-\t\t\t       GET_MODE (x));\n-\t  temp = simplify_gen_binary (XOR, GET_MODE (x),\n-\t\t\t\t      XEXP (XEXP (x, 0), 0), temp);\n-\t  x = simplify_gen_binary (LSHIFTRT, GET_MODE (x),\n+\t  temp = gen_int_mode (mask << INTVAL (XEXP (XEXP (x, 0), 1)), xmode);\n+\t  temp = simplify_gen_binary (XOR, xmode, XEXP (XEXP (x, 0), 0), temp);\n+\t  x = simplify_gen_binary (LSHIFTRT, xmode,\n \t\t\t\t   temp, XEXP (XEXP (x, 0), 1));\n \n \t  return force_to_mode (x, mode, mask, next_select);\n@@ -8996,8 +9024,11 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n       op0 = gen_lowpart_or_truncate (op_mode,\n \t\t\t\t     force_to_mode (XEXP (x, 0), mode, mask,\n \t\t\t\t\t\t    next_select));\n-      if (op_mode != GET_MODE (x) || op0 != XEXP (x, 0))\n-\tx = simplify_gen_unary (code, op_mode, op0, op_mode);\n+      if (op_mode != xmode || op0 != XEXP (x, 0))\n+\t{\n+\t  x = simplify_gen_unary (code, op_mode, op0, op_mode);\n+\t  xmode = op_mode;\n+\t}\n       break;\n \n     case NE:\n@@ -9018,14 +9049,14 @@ force_to_mode (rtx x, machine_mode mode, unsigned HOST_WIDE_INT mask,\n       /* We have no way of knowing if the IF_THEN_ELSE can itself be\n \t written in a narrower mode.  We play it safe and do not do so.  */\n \n-      op0 = gen_lowpart_or_truncate (GET_MODE (x),\n+      op0 = gen_lowpart_or_truncate (xmode,\n \t\t\t\t     force_to_mode (XEXP (x, 1), mode,\n \t\t\t\t\t\t    mask, next_select));\n-      op1 = gen_lowpart_or_truncate (GET_MODE (x),\n+      op1 = gen_lowpart_or_truncate (xmode,\n \t\t\t\t     force_to_mode (XEXP (x, 2), mode,\n \t\t\t\t\t\t    mask, next_select));\n       if (op0 != XEXP (x, 1) || op1 != XEXP (x, 2))\n-\tx = simplify_gen_ternary (IF_THEN_ELSE, GET_MODE (x),\n+\tx = simplify_gen_ternary (IF_THEN_ELSE, xmode,\n \t\t\t\t  GET_MODE (XEXP (x, 0)), XEXP (x, 0),\n \t\t\t\t  op0, op1);\n       break;"}]}