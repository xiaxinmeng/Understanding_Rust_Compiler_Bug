{"sha": "4202ce820181761ad2e25b025894bb9537b42f76", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NDIwMmNlODIwMTgxNzYxYWQyZTI1YjAyNTg5NGJiOTUzN2I0MmY3Ng==", "commit": {"author": {"name": "Richard Earnshaw", "email": "rearnsha@gcc.gnu.org", "date": "2003-08-27T12:52:58Z"}, "committer": {"name": "Richard Earnshaw", "email": "rearnsha@gcc.gnu.org", "date": "2003-08-27T12:52:58Z"}, "message": "[multiple changes]\n\n2003-08-27  Richard Earnshaw  <rearnsha@arm.com>\n\n* lib1funcs.asm (L_ieee754_sp): New.  Include ieee754-sf.S.\n(L_ieee754_dp): New.  Include ieee754-df.S.\n* arm/ieee754-sf.S: Rework to allow interworking, calling from Thumb,\nand compilation in apcs-26 mode.\n* arm/ieee754-df.S: Likewise.\n* t-arm-elf (DPBIT, FPBIT, fp-bit.c dp-bit.c): Delete rules\n(LIB1ASMFUNCS): Add _ieee754_sp and _ieee754_dp targets.\n\n2003-08-27  Nicolas Pitre  <nico@cam.org>\n\n* arm/ieee754-sf.S: New.\n* arm/ieee754-df.S: New.\n\nFrom-SVN: r70845", "tree": {"sha": "8dd03076871f1247d318053ae956e716bc6733bb", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/8dd03076871f1247d318053ae956e716bc6733bb"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/4202ce820181761ad2e25b025894bb9537b42f76", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4202ce820181761ad2e25b025894bb9537b42f76", "html_url": "https://github.com/Rust-GCC/gccrs/commit/4202ce820181761ad2e25b025894bb9537b42f76", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/4202ce820181761ad2e25b025894bb9537b42f76/comments", "author": null, "committer": null, "parents": [{"sha": "b7bc76e3212071f97d999e5e9fd302fe984dae4d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/b7bc76e3212071f97d999e5e9fd302fe984dae4d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/b7bc76e3212071f97d999e5e9fd302fe984dae4d"}], "stats": {"total": 2200, "additions": 2177, "deletions": 23}, "files": [{"sha": "4d398dcc12bc1402f57876fd3398744ec964376c", "filename": "gcc/ChangeLog", "status": "modified", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4202ce820181761ad2e25b025894bb9537b42f76/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4202ce820181761ad2e25b025894bb9537b42f76/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=4202ce820181761ad2e25b025894bb9537b42f76", "patch": "@@ -1,3 +1,18 @@\n+2003-08-27  Richard Earnshaw  <rearnsha@arm.com>\n+\n+\t* lib1funcs.asm (L_ieee754_sp): New.  Include ieee754-sf.S.\n+\t(L_ieee754_dp): New.  Include ieee754-df.S.\n+\t* arm/ieee754-sf.S: Rework to allow interworking, calling from Thumb,\n+\tand compilation in apcs-26 mode.\n+\t* arm/ieee754-df.S: Likewise.\n+\t* t-arm-elf (DPBIT, FPBIT, fp-bit.c dp-bit.c): Delete rules\n+\t(LIB1ASMFUNCS): Add _ieee754_sp and _ieee754_dp targets.\n+\n+2003-08-27  Nicolas Pitre  <nico@cam.org>\n+\n+\t* arm/ieee754-sf.S: New.\n+\t* arm/ieee754-df.S: New.\n+\n 2003-08-27  Jakub Jelinek  <jakub@redhat.com>\n \n \t* builtins.c (expand_builtin_expect_jump): Save pending_stack_adjust"}, {"sha": "9a00dcea25ed32ca91f2253f76d6f878aa711d34", "filename": "gcc/config/arm/ieee754-df.S", "status": "added", "additions": 1331, "deletions": 0, "changes": 1331, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4202ce820181761ad2e25b025894bb9537b42f76/gcc%2Fconfig%2Farm%2Fieee754-df.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4202ce820181761ad2e25b025894bb9537b42f76/gcc%2Fconfig%2Farm%2Fieee754-df.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fieee754-df.S?ref=4202ce820181761ad2e25b025894bb9537b42f76", "patch": "@@ -0,0 +1,1331 @@\n+/* ieee754-df.S double-precision floating point support for ARM\n+\n+   Copyright (C) 2003  Free Software Foundation, Inc.\n+   Contributed by Nicolas Pitre (nico@cam.org)\n+\n+   This file is free software; you can redistribute it and/or modify it\n+   under the terms of the GNU General Public License as published by the\n+   Free Software Foundation; either version 2, or (at your option) any\n+   later version.\n+\n+   In addition to the permissions in the GNU General Public License, the\n+   Free Software Foundation gives you unlimited permission to link the\n+   compiled version of this file into combinations with other programs,\n+   and to distribute those combinations without any restriction coming\n+   from the use of this file.  (The General Public License restrictions\n+   do apply in other respects; for example, they cover modification of\n+   the file, and distribution when not linked into a combine\n+   executable.)\n+\n+   This file is distributed in the hope that it will be useful, but\n+   WITHOUT ANY WARRANTY; without even the implied warranty of\n+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+   General Public License for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this program; see the file COPYING.  If not, write to\n+   the Free Software Foundation, 59 Temple Place - Suite 330,\n+   Boston, MA 02111-1307, USA.  */\n+\n+/*\n+ * Notes: \n+ * \n+ * The goal of this code is to be as fast as possible.  This is\n+ * not meant to be easy to understand for the casual reader.\n+ * For slightly simpler code please see the single precision version\n+ * of this file.\n+ * \n+ * Only the default rounding mode is intended for best performances.\n+ * Exceptions aren't supported yet, but that can be added quite easily\n+ * if necessary without impacting performances.\n+ */\n+\n+@ This selects the minimum architecture level required.\n+#undef __ARM_ARCH__\n+#define __ARM_ARCH__ 3\n+\n+#if defined(__ARM_ARCH_3M__) || defined(__ARM_ARCH_4__) \\\n+\t|| defined(__ARM_ARCH_4T__)\n+#undef __ARM_ARCH__\n+/* We use __ARM_ARCH__ set to 4 here, but in reality it's any processor with\n+   long multiply instructions.  That includes v3M.  */\n+#define __ARM_ARCH__ 4\n+#endif\n+\t\n+#if defined(__ARM_ARCH_5__) || defined(__ARM_ARCH_5T__) \\\n+\t|| defined(__ARM_ARCH_5TE__)\n+#undef __ARM_ARCH__\n+#define __ARM_ARCH__ 5\n+#endif\n+\n+#if (__ARM_ARCH__ > 4) || defined(__ARM_ARCH_4T__)\n+#undef RET\n+#undef RETc\n+#define RET\tbx\tlr\n+#define RETc(x) bx##x\tlr\n+#if (__ARM_ARCH__ == 4) && (defined(__thumb__) || defined(__THUMB_INTERWORK__))\n+#define __FP_INTERWORKING__\n+#endif\n+#endif\n+\n+@ For FPA, float words are always big-endian.\n+@ For VFP, floats words follow the memory system mode.\n+#if defined(__VFP_FP__) && !defined(__ARMEB__)\n+#define xl r0\n+#define xh r1\n+#define yl r2\n+#define yh r3\n+#else\n+#define xh r0\n+#define xl r1\n+#define yh r2\n+#define yl r3\n+#endif\n+\n+\n+#if defined(__thumb__) && !defined(__THUMB_INTERWORK__)\n+.macro\tARM_FUNC_START name\n+\tFUNC_START \\name\n+\tbx\tpc\n+\tnop\n+\t.arm\n+.endm\n+#else\n+.macro\tARM_FUNC_START name\n+\tFUNC_START \\name\n+.endm\n+#endif\n+\n+ARM_FUNC_START negdf2\n+\t@ flip sign bit\n+\teor\txh, xh, #0x80000000\n+\tRET\n+\n+ARM_FUNC_START subdf3\n+\t@ flip sign bit of second arg\n+\teor\tyh, yh, #0x80000000\n+#if defined(__thumb__) && !defined(__THUMB_INTERWORK__)\n+\tb\t1f\t\t\t@ Skip Thumb-code prologue\n+#endif\n+\n+ARM_FUNC_START adddf3\n+\n+1:\t@ Compare both args, return zero if equal but the sign.\n+\tteq\txl, yl\n+\teoreq\tip, xh, yh\n+\tteqeq\tip, #0x80000000\n+\tbeq\tLSYM(Lad_z)\n+\n+\t@ If first arg is 0 or -0, return second arg.\n+\t@ If second arg is 0 or -0, return first arg.\n+\torrs\tip, xl, xh, lsl #1\n+\tmoveq\txl, yl\n+\tmoveq\txh, yh\n+\torrnes\tip, yl, yh, lsl #1\n+\tRETc(eq)\n+\n+\tstmfd\tsp!, {r4, r5, lr}\n+\n+\t@ Mask out exponents.\n+\tmov\tip, #0x7f000000\n+\torr\tip, ip, #0x00f00000\n+\tand\tr4, xh, ip\n+\tand\tr5, yh, ip\n+\n+\t@ If either of them is 0x7ff, result will be INF or NAN\n+\tteq\tr4, ip\n+\tteqne\tr5, ip\n+\tbeq\tLSYM(Lad_i)\n+\n+\t@ Compute exponent difference.  Make largest exponent in r4,\n+\t@ corresponding arg in xh-xl, and positive exponent difference in r5.\n+\tsubs\tr5, r5, r4\n+\trsblt\tr5, r5, #0\n+\tble\t1f\n+\tadd\tr4, r4, r5\n+\teor\tyl, xl, yl\n+\teor\tyh, xh, yh\n+\teor\txl, yl, xl\n+\teor\txh, yh, xh\n+\teor\tyl, xl, yl\n+\teor\tyh, xh, yh\n+1:\n+\n+\t@ If exponent difference is too large, return largest argument\n+\t@ already in xh-xl.  We need up to 54 bit to handle proper rounding\n+\t@ of 0x1p54 - 1.1.\n+\tcmp\tr5, #(54 << 20)\n+#ifdef __FP_INTERWORKING__\n+\tldmhifd\tsp!, {r4, r5, lr}\n+\tbxhi\tlr\n+#else\n+\tldmhifd\tsp!, {r4, r5, pc}RETCOND\n+#endif\n+\n+\t@ Convert mantissa to signed integer.\n+\ttst\txh, #0x80000000\n+\tbic\txh, xh, ip, lsl #1\n+\torr\txh, xh, #0x00100000\n+\tbeq\t1f\n+\trsbs\txl, xl, #0\n+\trsc\txh, xh, #0\n+1:\n+\ttst\tyh, #0x80000000\n+\tbic\tyh, yh, ip, lsl #1\n+\torr\tyh, yh, #0x00100000\n+\tbeq\t1f\n+\trsbs\tyl, yl, #0\n+\trsc\tyh, yh, #0\n+1:\n+\t@ If exponent == difference, one or both args were denormalized.\n+\t@ Since this is not common case, rescale them off line.\n+\tteq\tr4, r5\n+\tbeq\tLSYM(Lad_d)\n+LSYM(Lad_x):\n+\t@ Scale down second arg with exponent difference.\n+\t@ Apply shift one bit left to first arg and the rest to second arg\n+\t@ to simplify things later, but only if exponent does not become 0.\n+\tmov\tip, #0\n+\tmovs\tr5, r5, lsr #20\n+\tbeq\t3f\n+\tteq\tr4, #(1 << 20)\n+\tbeq\t1f\n+\tmovs\txl, xl, lsl #1\n+\tadc\txh, ip, xh, lsl #1\n+\tsub\tr4, r4, #(1 << 20)\n+\tsubs\tr5, r5, #1\n+\tbeq\t3f\n+\n+\t@ Shift yh-yl right per r5, keep leftover bits into ip.\n+1:\trsbs\tlr, r5, #32\n+\tblt\t2f\n+\tmov\tip, yl, lsl lr\n+\tmov\tyl, yl, lsr r5\n+\torr\tyl, yl, yh, lsl lr\n+\tmov\tyh, yh, asr r5\n+\tb\t3f\n+2:\tsub\tr5, r5, #32\n+\tadd\tlr, lr, #32\n+\tcmp\tyl, #1\n+\tadc\tip, ip, yh, lsl lr\n+\tmov\tyl, yh, asr r5\n+\tmov\tyh, yh, asr #32\n+3:\n+\t@ the actual addition\n+\tadds\txl, xl, yl\n+\tadc\txh, xh, yh\n+\n+\t@ We now have a result in xh-xl-ip.\n+\t@ Keep absolute value in xh-xl-ip, sign in r5.\n+\tands\tr5, xh, #0x80000000\n+\tbpl\tLSYM(Lad_p)\n+\trsbs\tip, ip, #0\n+\trscs\txl, xl, #0\n+\trsc\txh, xh, #0\n+\n+\t@ Determine how to normalize the result.\n+LSYM(Lad_p):\n+\tcmp\txh, #0x00100000\n+\tbcc\tLSYM(Lad_l)\n+\tcmp\tr0, #0x00200000\n+\tbcc\tLSYM(Lad_r0)\n+\tcmp\tr0, #0x00400000\n+\tbcc\tLSYM(Lad_r1)\n+\n+\t@ Result needs to be shifted right.\n+\tmovs\txh, xh, lsr #1\n+\tmovs\txl, xl, rrx\n+\tmovs\tip, ip, rrx\n+\torrcs\tip, ip, #1\n+\tadd\tr4, r4, #(1 << 20)\n+LSYM(Lad_r1):\n+\tmovs\txh, xh, lsr #1\n+\tmovs\txl, xl, rrx\n+\tmovs\tip, ip, rrx\n+\torrcs\tip, ip, #1\n+\tadd\tr4, r4, #(1 << 20)\n+\n+\t@ Our result is now properly aligned into xh-xl, remaining bits in ip.\n+\t@ Round with MSB of ip. If halfway between two numbers, round towards\n+\t@ LSB of xl = 0.\n+LSYM(Lad_r0):\n+\tadds\txl, xl, ip, lsr #31\n+\tadc\txh, xh, #0\n+\tteq\tip, #0x80000000\n+\tbiceq\txl, xl, #1\n+\n+\t@ One extreme rounding case may add a new MSB.  Adjust exponent.\n+\t@ That MSB will be cleared when exponent is merged below. \n+\ttst\txh, #0x00200000\n+\taddne\tr4, r4, #(1 << 20)\n+\n+\t@ Make sure we did not bust our exponent.\n+\tadds\tip, r4, #(1 << 20)\n+\tbmi\tLSYM(Lad_o)\n+\n+\t@ Pack final result together.\n+LSYM(Lad_e):\n+\tbic\txh, xh, #0x00300000\n+\torr\txh, xh, r4\n+\torr\txh, xh, r5\n+#ifdef __FP_INTERWORKING__\n+\tldmfd\tsp!, {r4, r5, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, pc}RETCOND\n+#endif\n+\n+LSYM(Lad_l):\t@ Result must be shifted left and exponent adjusted.\n+\t@ No rounding necessary since ip will always be 0.\n+#if __ARM_ARCH__ < 5\n+\n+\tteq\txh, #0\n+\tmovne\tr3, #-11\n+\tmoveq\tr3, #21\n+\tmoveq\txh, xl\n+\tmoveq\txl, #0\n+\tmov\tr2, xh\n+\tmovs\tip, xh, lsr #16\n+\tmoveq\tr2, r2, lsl #16\n+\taddeq\tr3, r3, #16\n+\ttst\tr2, #0xff000000\n+\tmoveq\tr2, r2, lsl #8\n+\taddeq\tr3, r3, #8\n+\ttst\tr2, #0xf0000000\n+\tmoveq\tr2, r2, lsl #4\n+\taddeq\tr3, r3, #4\n+\ttst\tr2, #0xc0000000\n+\tmoveq\tr2, r2, lsl #2\n+\taddeq\tr3, r3, #2\n+\ttst\tr2, #0x80000000\n+\taddeq\tr3, r3, #1\n+\n+#else\n+\n+\tteq\txh, #0\n+\tmoveq\txh, xl\n+\tmoveq\txl, #0\n+\tclz\tr3, xh\n+\taddeq\tr3, r3, #32\n+\tsub\tr3, r3, #11\n+\n+#endif\n+\n+\t@ determine how to shift the value.\n+\tsubs\tr2, r3, #32\n+\tbge\t2f\n+\tadds\tr2, r2, #12\n+\tble\t1f\n+\n+\t@ shift value left 21 to 31 bits, or actually right 11 to 1 bits\n+\t@ since a register switch happened above.\n+\tadd\tip, r2, #20\n+\trsb\tr2, r2, #12\n+\tmov\txl, xh, lsl ip\n+\tmov\txh, xh, lsr r2\n+\tb\t3f\n+\n+\t@ actually shift value left 1 to 20 bits, which might also represent\n+\t@ 32 to 52 bits if counting the register switch that happened earlier.\n+1:\tadd\tr2, r2, #20\n+2:\trsble\tip, r2, #32\n+\tmov\txh, xh, lsl r2\n+\torrle\txh, xh, xl, lsr ip\n+\tmovle\txl, xl, lsl r2\n+\n+\t@ adjust exponent accordingly.\n+3:\tsubs\tr4, r4, r3, lsl #20\n+\tbgt\tLSYM(Lad_e)\n+\n+\t@ Exponent too small, denormalize result.\n+\t@ Find out proper shift value.\n+\tmvn\tr4, r4, asr #20\n+\tsubs\tr4, r4, #30\n+\tbge\t2f\n+\tadds\tr4, r4, #12\n+\tbgt\t1f\n+\n+\t@ shift result right of 1 to 20 bits, sign is in r5.\n+\tadd\tr4, r4, #20\n+\trsb\tr2, r4, #32\n+\tmov\txl, xl, lsr r4\n+\torr\txl, xl, xh, lsl r2\n+\torr\txh, r5, xh, lsr r4\n+#ifdef __FP_INTERWORKING\n+\tldmfd\tsp!, {r4, r5, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, pc}RETCOND\n+#endif\n+\n+\t@ shift result right of 21 to 31 bits, or left 11 to 1 bits after\n+\t@ a register switch from xh to xl.\n+1:\trsb\tr4, r4, #12\n+\trsb\tr2, r4, #32\n+\tmov\txl, xl, lsr r2\n+\torr\txl, xl, xh, lsl r4\n+\tmov\txh, r5\n+#ifdef __FP_INTERWORKING__\n+\tldmfd\tsp!, {r4, r5, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, pc}RETCOND\n+#endif\n+\n+\t@ Shift value right of 32 to 64 bits, or 0 to 32 bits after a switch\n+\t@ from xh to xl.\n+2:\tmov\txl, xh, lsr r4\n+\tmov\txh, r5\n+#ifdef __FP_INTERWORKING__\n+\tldmfd\tsp!, {r4, r5, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, pc}RETCOND\n+#endif\n+\n+\t@ Adjust exponents for denormalized arguments.\n+LSYM(Lad_d):\n+\tteq\tr4, #0\n+\teoreq\txh, xh, #0x00100000\n+\taddeq\tr4, r4, #(1 << 20)\n+\teor\tyh, yh, #0x00100000\n+\tsubne\tr5, r5, #(1 << 20)\n+\tb\tLSYM(Lad_x)\n+\n+\t@ Result is x - x = 0, unless x = INF or NAN.\n+LSYM(Lad_z):\n+\tsub\tip, ip, #0x00100000\t@ ip becomes 0x7ff00000\n+\tand\tr2, xh, ip\n+\tteq\tr2, ip\n+\torreq\txh, ip, #0x00080000\n+\tmovne\txh, #0\n+\tmov\txl, #0\n+\tRET\n+\n+\t@ Overflow: return INF.\n+LSYM(Lad_o):\n+\torr\txh, r5, #0x7f000000\n+\torr\txh, xh, #0x00f00000\n+\tmov\txl, #0\n+#ifdef __FP_INTERWORKING__\n+\tldmfd\tsp!, {r4, r5, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, pc}RETCOND\n+#endif\n+\n+\t@ At least one of x or y is INF/NAN.\n+\t@   if xh-xl != INF/NAN: return yh-yl (which is INF/NAN)\n+\t@   if yh-yl != INF/NAN: return xh-xl (which is INF/NAN)\n+\t@   if either is NAN: return NAN\n+\t@   if opposite sign: return NAN\n+\t@   return xh-xl (which is INF or -INF)\n+LSYM(Lad_i):\n+\tteq\tr4, ip\n+\tmovne\txh, yh\n+\tmovne\txl, yl\n+\tteqeq\tr5, ip\n+#ifdef __FP_INTERWORKING__\n+\tldmnefd\tsp!, {r4, r5, lr}\n+\tbxne\tlr\n+#else\n+\tldmnefd\tsp!, {r4, r5, pc}RETCOND\n+#endif\n+\torrs\tr4, xl, xh, lsl #12\n+\torreqs\tr4, yl, yh, lsl #12\n+\tteqeq\txh, yh\n+\torrne\txh, r5, #0x00080000\n+\tmovne\txl, #0\n+#ifdef __FP_INTERWORKING__\n+\tldmfd\tsp!, {r4, r5, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, pc}RETCOND\n+#endif\n+\n+\n+ARM_FUNC_START floatunsidf\n+\tteq\tr0, #0\n+\tmoveq\tr1, #0\n+\tRETc(eq)\n+\tstmfd\tsp!, {r4, r5, lr}\n+\tmov\tr4, #(0x400 << 20)\t@ initial exponent\n+\tadd\tr4, r4, #((52-1) << 20)\n+\tmov\tr5, #0\t\t\t@ sign bit is 0\n+\tmov\txl, r0\n+\tmov\txh, #0\n+\tb\tLSYM(Lad_l)\n+\n+\n+ARM_FUNC_START floatsidf\n+\tteq\tr0, #0\n+\tmoveq\tr1, #0\n+\tRETc(eq)\n+\tstmfd\tsp!, {r4, r5, lr}\n+\tmov\tr4, #(0x400 << 20)\t@ initial exponent\n+\tadd\tr4, r4, #((52-1) << 20)\n+\tands\tr5, r0, #0x80000000\t@ sign bit in r5\n+\trsbmi\tr0, r0, #0\t\t@ absolute value\n+\tmov\txl, r0\n+\tmov\txh, #0\n+\tb\tLSYM(Lad_l)\n+\n+\n+ARM_FUNC_START extendsfdf2\n+\tmovs\tr2, r0, lsl #1\n+\tbeq\t1f\t\t\t@ value is 0.0 or -0.0\n+\tmov\txh, r2, asr #3\t\t@ stretch exponent\n+\tmov\txh, xh, rrx\t\t@ retrieve sign bit\n+\tmov\txl, r2, lsl #28\t\t@ retrieve remaining bits\n+\tands\tr2, r2, #0xff000000\t@ isolate exponent\n+\tbeq\t2f\t\t\t@ exponent was 0 but not mantissa\n+\tteq\tr2, #0xff000000\t\t@ check if INF or NAN\n+\teorne\txh, xh, #0x38000000\t@ fixup exponent otherwise.\n+\tRET\n+\n+1:\tmov\txh, r0\n+\tmov\txl, #0\n+\tRET\n+\n+2:\t@ value was denormalized.  We can normalize it now.\n+\tstmfd\tsp!, {r4, r5, lr}\n+\tmov\tr4, #(0x380 << 20)\t@ setup corresponding exponent\n+\tadd\tr4, r4, #(1 << 20)\n+\tand\tr5, xh, #0x80000000\t@ move sign bit in r5\n+\tbic\txh, xh, #0x80000000\n+\tb\tLSYM(Lad_l)\n+\n+\n+ARM_FUNC_START muldf3\n+\n+\tstmfd\tsp!, {r4, r5, r6, lr}\n+\n+\t@ Mask out exponents.\n+\tmov\tip, #0x7f000000\n+\torr\tip, ip, #0x00f00000\n+\tand\tr4, xh, ip\n+\tand\tr5, yh, ip\n+\n+\t@ Trap any INF/NAN.\n+\tteq\tr4, ip\n+\tteqne\tr5, ip\n+\tbeq\tLSYM(Lml_s)\n+\n+\t@ Trap any multiplication by 0.\n+\torrs\tr6, xl, xh, lsl #1\n+\torrnes\tr6, yl, yh, lsl #1\n+\tbeq\tLSYM(Lml_z)\n+\n+\t@ Shift exponents right one bit to make room for overflow bit.\n+\t@ If either of them is 0, scale denormalized arguments off line.\n+\t@ Then add both exponents together.\n+\tmovs\tr4, r4, lsr #1\n+\tteqne\tr5, #0\n+\tbeq\tLSYM(Lml_d)\n+LSYM(Lml_x):\n+\tadd\tr4, r4, r5, asr #1\n+\n+\t@ Preserve final sign in r4 along with exponent for now.\n+\tteq\txh, yh\n+\torrmi\tr4, r4, #0x8000\n+\n+\t@ Convert mantissa to unsigned integer.\n+\tbic\txh, xh, ip, lsl #1\n+\tbic\tyh, yh, ip, lsl #1\n+\torr\txh, xh, #0x00100000\n+\torr\tyh, yh, #0x00100000\n+\n+#if __ARM_ARCH__ < 4\n+\n+\t@ Well, no way to make it shorter without the umull instruction.\n+\t@ We must perform that 53 x 53 bit multiplication by hand.\n+\tstmfd\tsp!, {r7, r8, r9, sl, fp}\n+\tmov\tr7, xl, lsr #16\n+\tmov\tr8, yl, lsr #16\n+\tmov\tr9, xh, lsr #16\n+\tmov\tsl, yh, lsr #16\n+\tbic\txl, xl, r7, lsl #16\n+\tbic\tyl, yl, r8, lsl #16\n+\tbic\txh, xh, r9, lsl #16\n+\tbic\tyh, yh, sl, lsl #16\n+\tmul\tip, xl, yl\n+\tmul\tfp, xl, r8\n+\tmov\tlr, #0\n+\tadds\tip, ip, fp, lsl #16\n+\tadc\tlr, lr, fp, lsr #16\n+\tmul\tfp, r7, yl\n+\tadds\tip, ip, fp, lsl #16\n+\tadc\tlr, lr, fp, lsr #16\n+\tmul\tfp, xl, sl\n+\tmov\tr5, #0\n+\tadds\tlr, lr, fp, lsl #16\n+\tadc\tr5, r5, fp, lsr #16\n+\tmul\tfp, r7, yh\n+\tadds\tlr, lr, fp, lsl #16\n+\tadc\tr5, r5, fp, lsr #16\n+\tmul\tfp, xh, r8\n+\tadds\tlr, lr, fp, lsl #16\n+\tadc\tr5, r5, fp, lsr #16\n+\tmul\tfp, r9, yl\n+\tadds\tlr, lr, fp, lsl #16\n+\tadc\tr5, r5, fp, lsr #16\n+\tmul\tfp, xh, sl\n+\tmul\tr6, r9, sl\n+\tadds\tr5, r5, fp, lsl #16\n+\tadc\tr6, r6, fp, lsr #16\n+\tmul\tfp, r9, yh\n+\tadds\tr5, r5, fp, lsl #16\n+\tadc\tr6, r6, fp, lsr #16\n+\tmul\tfp, xl, yh\n+\tadds\tlr, lr, fp\n+\tmul\tfp, r7, sl\n+\tadcs\tr5, r5, fp\n+\tmul\tfp, xh, yl\n+\tadc\tr6, r6, #0\n+\tadds\tlr, lr, fp\n+\tmul\tfp, r9, r8\n+\tadcs\tr5, r5, fp\n+\tmul\tfp, r7, r8\n+\tadc\tr6, r6, #0\n+\tadds\tlr, lr, fp\n+\tmul\tfp, xh, yh\n+\tadcs\tr5, r5, fp\n+\tadc\tr6, r6, #0\n+\tldmfd\tsp!, {r7, r8, r9, sl, fp}\n+\n+#else\n+\n+\t@ Here is the actual multiplication: 53 bits * 53 bits -> 106 bits.\n+\tumull\tip, lr, xl, yl\n+\tmov\tr5, #0\n+\tumlal\tlr, r5, xl, yh\n+\tumlal\tlr, r5, xh, yl\n+\tmov\tr6, #0\n+\tumlal\tr5, r6, xh, yh\n+\n+#endif\n+\n+\t@ The LSBs in ip are only significant for the final rounding.\n+\t@ Fold them into one bit of lr.\n+\tteq\tip, #0\n+\torrne\tlr, lr, #1\n+\n+\t@ Put final sign in xh.\n+\tmov\txh, r4, lsl #16\n+\tbic\tr4, r4, #0x8000\n+\n+\t@ Adjust result if one extra MSB appeared (one of four times).\n+\ttst\tr6, #(1 << 9)\n+\tbeq\t1f\n+\tadd\tr4, r4, #(1 << 19)\n+\tmovs\tr6, r6, lsr #1\n+\tmovs\tr5, r5, rrx\n+\tmovs\tlr, lr, rrx\n+\torrcs\tlr, lr, #1\n+1:\n+\t@ Scale back to 53 bits.\n+\t@ xh contains sign bit already.\n+\torr\txh, xh, r6, lsl #12\n+\torr\txh, xh, r5, lsr #20\n+\tmov\txl, r5, lsl #12\n+\torr\txl, xl, lr, lsr #20\n+\n+\t@ Apply exponent bias, check range for underflow.\n+\tsub\tr4, r4, #0x00f80000\n+\tsubs\tr4, r4, #0x1f000000\n+\tble\tLSYM(Lml_u)\n+\n+\t@ Round the result.\n+\tmovs\tlr, lr, lsl #12\n+\tbpl\t1f\n+\tadds\txl, xl, #1\n+\tadc\txh, xh, #0\n+\tteq\tlr, #0x80000000\n+\tbiceq\txl, xl, #1\n+\n+\t@ Rounding may have produced an extra MSB here.\n+\t@ The extra bit is cleared before merging the exponent below.\n+\ttst\txh, #0x00200000\n+\taddne\tr4, r4, #(1 << 19)\n+1:\n+\t@ Check exponent for overflow.\n+\tadds\tip, r4, #(1 << 19)\n+\ttst\tip, #(1 << 30)\n+\tbne\tLSYM(Lml_o)\n+\n+\t@ Add final exponent.\n+\tbic\txh, xh, #0x00300000\n+\torr\txh, xh, r4, lsl #1\n+#ifdef __FP_INTERWORKING__\n+\tldmfd\tsp!, {r4, r5, r6, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, r6, pc}RETCOND\n+#endif\n+\n+\t@ Result is 0, but determine sign anyway.\n+LSYM(Lml_z):\n+\teor\txh, xh, yh\n+LSYM(Ldv_z):\n+\tbic\txh, xh, #0x7fffffff\n+\tmov\txl, #0\n+#ifdef __FP_INTERWORKING__\n+\tldmfd\tsp!, {r4, r5, r6, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, r6, pc}RETCOND\n+#endif\n+\n+\t@ Check if denormalized result is possible, otherwise return signed 0.\n+LSYM(Lml_u):\n+\tcmn\tr4, #(53 << 19)\n+\tmovle\txl, #0\n+#ifdef __FP_INTERWORKING__\n+\tldmlefd\tsp!, {r4, r5, r6, lr}\n+\tbxle\tlr\n+#else\n+\tldmlefd\tsp!, {r4, r5, r6, pc}RETCOND\n+#endif\n+\n+\t@ Find out proper shift value.\n+LSYM(Lml_r):\n+\tmvn\tr4, r4, asr #19\n+\tsubs\tr4, r4, #30\n+\tbge\t2f\n+\tadds\tr4, r4, #12\n+\tbgt\t1f\n+\n+\t@ shift result right of 1 to 20 bits, preserve sign bit, round, etc.\n+\tadd\tr4, r4, #20\n+\trsb\tr5, r4, #32\n+\tmov\tr3, xl, lsl r5\n+\tmov\txl, xl, lsr r4\n+\torr\txl, xl, xh, lsl r5\n+\tmovs\txh, xh, lsl #1\n+\tmov\txh, xh, lsr r4\n+\tmov\txh, xh, rrx\n+\tadds\txl, xl, r3, lsr #31\n+\tadc\txh, xh, #0\n+\tteq\tlr, #0\n+\tteqeq\tr3, #0x80000000\n+\tbiceq\txl, xl, #1\n+#ifdef __FP_INTERWORKING__\n+\tldmfd\tsp!, {r4, r5, r6, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, r6, pc}RETCOND\n+#endif\n+\n+\t@ shift result right of 21 to 31 bits, or left 11 to 1 bits after\n+\t@ a register switch from xh to xl. Then round.\n+1:\trsb\tr4, r4, #12\n+\trsb\tr5, r4, #32\n+\tmov\tr3, xl, lsl r4\n+\tmov\txl, xl, lsr r5\n+\torr\txl, xl, xh, lsl r4\n+\tbic\txh, xh, #0x7fffffff\n+\tadds\txl, xl, r3, lsr #31\n+\tadc\txh, xh, #0\n+\tteq\tlr, #0\n+\tteqeq\tr3, #0x80000000\n+\tbiceq\txl, xl, #1\n+#ifdef __FP_INTERWORKING__\n+\tldmfd\tsp!, {r4, r5, r6, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, r6, pc}RETCOND\n+#endif\n+\n+\t@ Shift value right of 32 to 64 bits, or 0 to 32 bits after a switch\n+\t@ from xh to xl.  Leftover bits are in r3-r6-lr for rounding.\n+2:\trsb\tr5, r4, #32\n+\tmov\tr6, xl, lsl r5\n+\tmov\tr3, xl, lsr r4\n+\torr\tr3, r3, xh, lsl r5\n+\tmov\txl, xh, lsr r4\n+\tbic\txh, xh, #0x7fffffff\n+\tadds\txl, xl, r3, lsr #31\n+\tadc\txh, xh, #0\n+\torrs\tr6, r6, lr\n+\tteqeq\tr3, #0x80000000\n+\tbiceq\txl, xl, #1\n+#ifdef __FP_INTERWORKING__\n+\tldmfd\tsp!, {r4, r5, r6, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, r6, pc}RETCOND\n+#endif\n+\n+\t@ One or both arguments are denormalized.\n+\t@ Scale them leftwards and preserve sign bit.\n+LSYM(Lml_d):\n+\tmov\tlr, #0\n+\tteq\tr4, #0\n+\tbne\t2f\n+\tand\tr6, xh, #0x80000000\n+1:\tmovs\txl, xl, lsl #1\n+\tadc\txh, lr, xh, lsl #1\n+\ttst\txh, #0x00100000\n+\tsubeq\tr4, r4, #(1 << 19)\n+\tbeq\t1b\n+\torr\txh, xh, r6\n+\tteq\tr5, #0\n+\tbne\tLSYM(Lml_x)\n+2:\tand\tr6, yh, #0x80000000\n+3:\tmovs\tyl, yl, lsl #1\n+\tadc\tyh, lr, yh, lsl #1\n+\ttst\tyh, #0x00100000\n+\tsubeq\tr5, r5, #(1 << 20)\n+\tbeq\t3b\n+\torr\tyh, yh, r6\n+\tb\tLSYM(Lml_x)\n+\n+\t@ One or both args are INF or NAN.\n+LSYM(Lml_s):\n+\torrs\tr6, xl, xh, lsl #1\n+\torrnes\tr6, yl, yh, lsl #1\n+\tbeq\tLSYM(Lml_n)\t\t@ 0 * INF or INF * 0 -> NAN\n+\tteq\tr4, ip\n+\tbne\t1f\n+\torrs\tr6, xl, xh, lsl #12\n+\tbne\tLSYM(Lml_n)\t\t@ NAN * <anything> -> NAN\n+1:\tteq\tr5, ip\n+\tbne\tLSYM(Lml_i)\n+\torrs\tr6, yl, yh, lsl #12\n+\tbne\tLSYM(Lml_n)\t\t@ <anything> * NAN -> NAN\n+\n+\t@ Result is INF, but we need to determine its sign.\n+LSYM(Lml_i):\n+\teor\txh, xh, yh\n+\n+\t@ Overflow: return INF (sign already in xh).\n+LSYM(Lml_o):\n+\tand\txh, xh, #0x80000000\n+\torr\txh, xh, #0x7f000000\n+\torr\txh, xh, #0x00f00000\n+\tmov\txl, #0\n+#ifdef __FP_INTERWORKING__\n+\tldmfd\tsp!, {r4, r5, r6, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, r6, pc}RETCOND\n+#endif\n+\n+\t@ Return NAN.\n+LSYM(Lml_n):\n+\tmov\txh, #0x7f000000\n+\torr\txh, xh, #0x00f80000\n+#ifdef __FP_INTERWORKING__\n+\tldmfd\tsp!, {r4, r5, r6, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, r6, pc}RETCOND\n+#endif\n+\n+\n+ARM_FUNC_START divdf3\n+\n+\tstmfd\tsp!, {r4, r5, r6, lr}\n+\n+\t@ Mask out exponents.\n+\tmov\tip, #0x7f000000\n+\torr\tip, ip, #0x00f00000\n+\tand\tr4, xh, ip\n+\tand\tr5, yh, ip\n+\n+\t@ Trap any INF/NAN or zeroes.\n+\tteq\tr4, ip\n+\tteqne\tr5, ip\n+\torrnes\tr6, xl, xh, lsl #1\n+\torrnes\tr6, yl, yh, lsl #1\n+\tbeq\tLSYM(Ldv_s)\n+\n+\t@ Shift exponents right one bit to make room for overflow bit.\n+\t@ If either of them is 0, scale denormalized arguments off line.\n+\t@ Then substract divisor exponent from dividend''s.\n+\tmovs\tr4, r4, lsr #1\n+\tteqne\tr5, #0\n+\tbeq\tLSYM(Ldv_d)\n+LSYM(Ldv_x):\n+\tsub\tr4, r4, r5, asr #1\n+\n+\t@ Preserve final sign into lr.\n+\teor\tlr, xh, yh\n+\n+\t@ Convert mantissa to unsigned integer.\n+\t@ Dividend -> r5-r6, divisor -> yh-yl.\n+\tmov\tr5, #0x10000000\n+\tmov\tyh, yh, lsl #12\n+\torr\tyh, r5, yh, lsr #4\n+\torr\tyh, yh, yl, lsr #24\n+\tmovs\tyl, yl, lsl #8\n+\tmov\txh, xh, lsl #12\n+\tteqeq\tyh, r5\n+\tbeq\tLSYM(Ldv_1)\n+\torr\tr5, r5, xh, lsr #4\n+\torr\tr5, r5, xl, lsr #24\n+\tmov\tr6, xl, lsl #8\n+\n+\t@ Initialize xh with final sign bit.\n+\tand\txh, lr, #0x80000000\n+\n+\t@ Ensure result will land to known bit position.\n+\tcmp\tr5, yh\n+\tcmpeq\tr6, yl\n+\tbcs\t1f\n+\tsub\tr4, r4, #(1 << 19)\n+\tmovs\tyh, yh, lsr #1\n+\tmov\tyl, yl, rrx\n+1:\n+\t@ Apply exponent bias, check range for over/underflow.\n+\tadd\tr4, r4, #0x1f000000\n+\tadd\tr4, r4, #0x00f80000\n+\tcmn\tr4, #(53 << 19)\n+\tble\tLSYM(Ldv_z)\n+\tcmp\tr4, ip, lsr #1\n+\tbge\tLSYM(Lml_o)\n+\n+\t@ Perform first substraction to align result to a nibble.\n+\tsubs\tr6, r6, yl\n+\tsbc\tr5, r5, yh\n+\tmovs\tyh, yh, lsr #1\n+\tmov\tyl, yl, rrx\n+\tmov\txl, #0x00100000\n+\tmov\tip, #0x00080000\n+\n+\t@ The actual division loop.\n+1:\tsubs\tlr, r6, yl\n+\tsbcs\tlr, r5, yh\n+\tsubcs\tr6, r6, yl\n+\tmovcs\tr5, lr\n+\torrcs\txl, xl, ip\n+\tmovs\tyh, yh, lsr #1\n+\tmov\tyl, yl, rrx\n+\tsubs\tlr, r6, yl\n+\tsbcs\tlr, r5, yh\n+\tsubcs\tr6, r6, yl\n+\tmovcs\tr5, lr\n+\torrcs\txl, xl, ip, lsr #1\n+\tmovs\tyh, yh, lsr #1\n+\tmov\tyl, yl, rrx\n+\tsubs\tlr, r6, yl\n+\tsbcs\tlr, r5, yh\n+\tsubcs\tr6, r6, yl\n+\tmovcs\tr5, lr\n+\torrcs\txl, xl, ip, lsr #2\n+\tmovs\tyh, yh, lsr #1\n+\tmov\tyl, yl, rrx\n+\tsubs\tlr, r6, yl\n+\tsbcs\tlr, r5, yh\n+\tsubcs\tr6, r6, yl\n+\tmovcs\tr5, lr\n+\torrcs\txl, xl, ip, lsr #3\n+\n+\torrs\tlr, r5, r6\n+\tbeq\t2f\n+\tmov\tr5, r5, lsl #4\n+\torr\tr5, r5, r6, lsr #28\n+\tmov\tr6, r6, lsl #4\n+\tmov\tyh, yh, lsl #3\n+\torr\tyh, yh, yl, lsr #29\n+\tmov\tyl, yl, lsl #3\n+\tmovs\tip, ip, lsr #4\n+\tbne\t1b\n+\n+\t@ We are done with a word of the result.\n+\t@ Loop again for the low word if this pass was for the high word.\n+\ttst\txh, #0x00100000\n+\tbne\t3f\n+\torr\txh, xh, xl\n+\tmov\txl, #0\n+\tmov\tip, #0x80000000\n+\tb\t1b\n+2:\n+\t@ Be sure result starts in the high word.\n+\ttst\txh, #0x00100000\n+\torreq\txh, xh, xl\n+\tmoveq\txl, #0\n+3:\n+\t@ Check if denormalized result is needed.\n+\tcmp\tr4, #0\n+\tble\tLSYM(Ldv_u)\n+\n+\t@ Apply proper rounding.\n+\tsubs\tip, r5, yh\n+\tsubeqs\tip, r6, yl\n+\tadcs\txl, xl, #0\n+\tadc\txh, xh, #0\n+\tteq\tip, #0\n+\tbiceq\txl, xl, #1\n+\n+\t@ Add exponent to result.\n+\tbic\txh, xh, #0x00100000\n+\torr\txh, xh, r4, lsl #1\n+#ifdef __FP_INTERWORKING__\n+\tldmfd\tsp!, {r4, r5, r6, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, r6, pc}RETCOND\n+#endif\n+\n+\t@ Division by 0x1p*: shortcut a lot of code.\n+LSYM(Ldv_1):\n+\tand\tlr, lr, #0x80000000\n+\torr\txh, lr, xh, lsr #12\n+\tadd\tr4, r4, #0x1f000000\n+\tadd\tr4, r4, #0x00f80000\n+\tcmp\tr4, ip, lsr #1\n+\tbge\tLSYM(Lml_o)\n+\tcmp\tr4, #0\n+\torrgt\txh, xh, r4, lsl #1\n+#ifdef __FP_INTERWORKING__\n+\tldmgtfd\tsp!, {r4, r5, r6, lr}\n+\tbxgt\tlr\n+#else\n+\tldmgtfd\tsp!, {r4, r5, r6, pc}RETCOND\n+#endif\n+\tcmn\tr4, #(53 << 19)\n+\tble\tLSYM(Ldv_z)\n+\torr\txh, xh, #0x00100000\n+\tmov\tlr, #0\n+\tb\tLSYM(Lml_r)\n+\n+\t@ Result must be denormalized: put remainder in lr for\n+\t@ rounding considerations.\n+LSYM(Ldv_u):\n+\torr\tlr, r5, r6\n+\tb\tLSYM(Lml_r)\n+\n+\t@ One or both arguments are denormalized.\n+\t@ Scale them leftwards and preserve sign bit.\n+LSYM(Ldv_d):\n+\tmov\tlr, #0\n+\tteq\tr4, #0\n+\tbne\t2f\n+\tand\tr6, xh, #0x80000000\n+1:\tmovs\txl, xl, lsl #1\n+\tadc\txh, lr, xh, lsl #1\n+\ttst\txh, #0x00100000\n+\tsubeq\tr4, r4, #(1 << 19)\n+\tbeq\t1b\n+\torr\txh, xh, r6\n+\tteq\tr5, #0\n+\tbne\tLSYM(Ldv_x)\n+2:\tand\tr6, yh, #0x80000000\n+3:\tmovs\tyl, yl, lsl #1\n+\tadc\tyh, lr, yh, lsl #1\n+\ttst\tyh, #0x00100000\n+\tsubeq\tr5, r5, #(1 << 20)\n+\tbeq\t3b\n+\torr\tyh, yh, r6\n+\tb\tLSYM(Ldv_x)\n+\n+\t@ One or both arguments is either INF, NAN or zero.\n+LSYM(Ldv_s):\n+\tteq\tr4, ip\n+\tteqeq\tr5, ip\n+\tbeq\tLSYM(Lml_n)\t\t@ INF/NAN / INF/NAN -> NAN\n+\tteq\tr4, ip\n+\tbne\t1f\n+\torrs\tr4, xl, xh, lsl #12\n+\tbne\tLSYM(Lml_n)\t\t@ NAN / <anything> -> NAN\n+\tb\tLSYM(Lml_i)\t\t@ INF / <anything> -> INF\n+1:\tteq\tr5, ip\n+\tbne\t2f\n+\torrs\tr5, yl, yh, lsl #12\n+\tbne\tLSYM(Lml_n)\t\t@ <anything> / NAN -> NAN\n+\tb\tLSYM(Lml_z)\t\t@ <anything> / INF -> 0\n+2:\t@ One or both arguments are 0.\n+\torrs\tr4, xl, xh, lsl #1\n+\tbne\tLSYM(Lml_i)\t\t@ <non_zero> / 0 -> INF\n+\torrs\tr5, yl, yh, lsl #1\n+\tbne\tLSYM(Lml_z)\t\t@ 0 / <non_zero> -> 0\n+\tb\tLSYM(Lml_n)\t\t@ 0 / 0 -> NAN\n+\n+\n+FUNC_START gedf2\n+ARM_FUNC_START gtdf2\n+\tmov\tip, #-1\n+\tb\t1f\n+\n+FUNC_START ledf2\n+ARM_FUNC_START ltdf2\n+\tmov\tip, #1\n+\tb\t1f\n+\n+FUNC_START nedf2\n+FUNC_START eqdf2\n+ARM_FUNC_START cmpdf2\n+\tmov\tip, #1\t\t\t@ how should we specify unordered here?\n+\n+1:\tstmfd\tsp!, {r4, r5, lr}\n+\n+\t@ Trap any INF/NAN first.\n+\tmov\tlr, #0x7f000000\n+\torr\tlr, lr, #0x00f00000\n+\tand\tr4, xh, lr\n+\tand\tr5, yh, lr\n+\tteq\tr4, lr\n+\tteqne\tr5, lr\n+\tbeq\t3f\n+\n+\t@ Test for equality.\n+\t@ Note that 0.0 is equal to -0.0.\n+2:\torrs\tip, xl, xh, lsl #1\t@ if x == 0.0 or -0.0\n+\torreqs\tip, yl, yh, lsl #1\t@ and y == 0.0 or -0.0\n+\tteqne\txh, yh\t\t\t@ or xh == yh\n+\tteqeq\txl, yl\t\t\t@ and xl == yl\n+\tmoveq\tr0, #0\t\t\t@ then equal.\n+#ifdef __FP_INTERWORKING__\n+\tldmeqfd\tsp!, {r4, r5, lr}\n+\tbxeq\tlr\n+#else\n+\tldmeqfd\tsp!, {r4, r5, pc}RETCOND\n+#endif\n+\n+\t@ Check for sign difference.\n+\tteq\txh, yh\n+\tmovmi\tr0, xh, asr #31\n+\torrmi\tr0, r0, #1\n+#ifdef __FP_INTERWORKING__\n+\tldmmifd\tsp!, {r4, r5, lr}\n+\tbxmi\tlr\n+#else\n+\tldmmifd\tsp!, {r4, r5, pc}RETCOND\n+#endif\n+\n+\t@ Compare exponents.\n+\tcmp\tr4, r5\n+\n+\t@ Compare mantissa if exponents are equal.\n+\tmoveq\txh, xh, lsl #12\n+\tcmpeq\txh, yh, lsl #12\n+\tcmpeq\txl, yl\n+\tmovcs\tr0, yh, asr #31\n+\tmvncc\tr0, yh, asr #31\n+\torr\tr0, r0, #1\n+#ifdef __FP_INTERWORKING__\n+\tldmfd\tsp!, {r4, r5, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, pc}RETCOND\n+#endif\n+\n+\t@ Look for a NAN.\n+3:\tteq\tr4, lr\n+\tbne\t4f\n+\torrs\txl, xl, xh, lsl #12\n+\tbne\t5f\t\t\t@ x is NAN\n+4:\tteq\tr5, lr\n+\tbne\t2b\n+\torrs\tyl, yl, yh, lsl #12\n+\tbeq\t2b\t\t\t@ y is not NAN\n+5:\tmov\tr0, ip\t\t\t@ return unordered code from ip\n+#ifdef __FP_INTERWORKING__\n+\tldmfd\tsp!, {r4, r5, lr}\n+\tbx\tlr\n+#else\n+\tldmfd\tsp!, {r4, r5, pc}RETCOND\n+#endif\n+\n+\n+ARM_FUNC_START unorddf2\n+\tstr\tlr, [sp, #-4]!\n+\tmov\tip, #0x7f000000\n+\torr\tip, ip, #0x00f00000\n+\tand\tlr, xh, ip\n+\tteq\tlr, ip\n+\tbne\t1f\n+\torrs\txl, xl, xh, lsl #12\n+\tbne\t3f\t\t\t@ x is NAN\n+1:\tand\tlr, yh, ip\n+\tteq\tlr, ip\n+\tbne\t2f\n+\torrs\tyl, yl, yh, lsl #12\n+\tbne\t3f\t\t\t@ y is NAN\n+2:\tmov\tr0, #0\t\t\t@ arguments are ordered.\n+#ifdef __FP_INTERWORKING__\n+\tldr\tlr, [sp], #4\n+\tbx\tlr\n+#elif defined (__APCS_26__)\n+\tldmia\tsp!, {pc}^\n+#else\n+\tldr\tpc, [sp], #4\n+#endif\n+3:\tmov\tr0, #1\t\t\t@ arguments are unordered.\n+#ifdef __FP_INTERWORKING__\n+\tldr\tlr, [sp], #4\n+\tbx\tlr\n+#elif defined (__APCS_26__)\n+\tldmia\tsp!, {pc}^\n+#else\n+\tldr\tpc, [sp], #4\n+#endif\n+\n+\n+ARM_FUNC_START fixdfsi\n+\torrs\tip, xl, xh, lsl #1\n+\tbeq\t1f\t\t\t@ value is 0.\n+\n+\t@ preserve C flag (the actual sign)\n+#ifdef __APCS_26__\n+\tmov\tr3, pc\n+#else\n+\tmrs\tr3, cpsr\n+#endif\n+\n+\t@ check exponent range.\n+\tmov\tip, #0x7f000000\n+\torr\tip, ip, #0x00f00000\n+\tand\tr2, xh, ip\n+\tteq\tr2, ip\n+\tbeq\t2f\t\t\t@ value is INF or NAN\n+\tbic\tip, ip, #0x40000000\n+\tcmp\tr2, ip\n+\tbcc\t1f\t\t\t@ value is too small\n+\tadd\tip, ip, #(31 << 20)\n+\tcmp\tr2, ip\n+\tbcs\t3f\t\t\t@ value is too large\n+\n+\trsb\tr2, r2, ip\n+\tmov\tip, xh, lsl #11\n+\torr\tip, ip, #0x80000000\n+\torr\tip, ip, xl, lsr #21\n+\tmov\tr2, r2, lsr #20\n+\tmov\tr0, ip, lsr r2\n+\ttst\tr3, #0x20000000\t\t@ the sign bit\n+\trsbne\tr0, r0, #0\n+\tRET\n+\n+1:\tmov\tr0, #0\n+\tRET\n+\n+2:\torrs\txl, xl, xh, lsl #12\n+\tbne\t4f\t\t\t@ r0 is NAN.\n+3:\ttst\tr3, #0x20000000\t\t@ the sign bit\n+\tmoveq\tr0, #0x7fffffff\t\t@ maximum signed positive si\n+\tmovne\tr0, #0x80000000\t\t@ maximum signed negative si\n+\tRET\n+\n+4:\tmov\tr0, #0\t\t\t@ How should we convert NAN?\n+\tRET\n+\n+ARM_FUNC_START fixunsdfsi\n+\torrs\tip, xl, xh, lsl #1\n+\tbeq\t1b\t\t\t@ value is 0\n+\tbcs\t1b\t\t\t@ value is negative\n+\n+\t@ check exponent range.\n+\tmov\tip, #0x7f000000\n+\torr\tip, ip, #0x00f00000\n+\tand\tr2, xh, ip\n+\tteq\tr2, ip\n+\tbeq\t1f\t\t\t@ value is INF or NAN\n+\tbic\tip, ip, #0x40000000\n+\tcmp\tr2, ip\n+\tbcc\t1b\t\t\t@ value is too small\n+\tadd\tip, ip, #(31 << 20)\n+\tcmp\tr2, ip\n+\tbhi\t2f\t\t\t@ value is too large\n+\n+\trsb\tr2, r2, ip\n+\tmov\tip, xh, lsl #11\n+\torr\tip, ip, #0x80000000\n+\torr\tip, ip, xl, lsr #21\n+\tmov\tr2, r2, lsr #20\n+\tmov\tr0, ip, lsr r2\n+\tRET\n+\n+1:\torrs\txl, xl, xh, lsl #12\n+\tbne\t4b\t\t\t@ value is NAN.\n+2:\tmov\tr0, #0xffffffff\t\t@ maximum unsigned si\n+\tRET\n+\n+\n+ARM_FUNC_START truncdfsf2\n+\torrs\tr2, xl, xh, lsl #1\n+\tmoveq\tr0, r2, rrx\n+\tRETc(eq)\t\t\t@ value is 0.0 or -0.0\n+\t\n+\t@ check exponent range.\n+\tmov\tip, #0x7f000000\n+\torr\tip, ip, #0x00f00000\n+\tand\tr2, ip, xh\n+\tteq\tr2, ip\n+\tbeq\t2f\t\t\t@ value is INF or NAN\n+\tbic\txh, xh, ip\n+\tcmp\tr2, #(0x380 << 20)\n+\tbls\t4f\t\t\t@ value is too small\n+\n+\t@ shift and round mantissa\n+1:\tmovs\tr3, xl, lsr #29\n+\tadc\tr3, r3, xh, lsl #3\n+\n+\t@ if halfway between two numbers, round towards LSB = 0.\n+\tmov\txl, xl, lsl #3\n+\tteq\txl, #0x80000000\n+\tbiceq\tr3, r3, #1\n+\n+\t@ rounding might have created an extra MSB.  If so adjust exponent.\n+\ttst\tr3, #0x00800000\n+\taddne\tr2, r2, #(1 << 20)\n+\tbicne\tr3, r3, #0x00800000\n+\n+\t@ check exponent for overflow\n+\tmov\tip, #(0x400 << 20)\n+\torr\tip, ip, #(0x07f << 20)\n+\tcmp\tr2, ip\n+\tbcs\t3f\t\t\t@ overflow\n+\n+\t@ adjust exponent, merge with sign bit and mantissa.\n+\tmovs\txh, xh, lsl #1\n+\tmov\tr2, r2, lsl #4\n+\torr\tr0, r3, r2, rrx\n+\teor\tr0, r0, #0x40000000\n+\tRET\n+\n+2:\t@ chech for NAN\n+\torrs\txl, xl, xh, lsl #12\n+\tmovne\tr0, #0x7f000000\n+\torrne\tr0, r0, #0x00c00000\n+\tRETc(ne)\t\t\t@ return NAN\n+\n+3:\t@ return INF with sign\n+\tand\tr0, xh, #0x80000000\n+\torr\tr0, r0, #0x7f000000\n+\torr\tr0, r0, #0x00800000\n+\tRET\n+\n+4:\t@ check if denormalized value is possible\n+\tsubs\tr2, r2, #((0x380 - 24) << 20)\n+\tandle\tr0, xh, #0x80000000\t@ too small, return signed 0.\n+\tRETc(le)\n+\t\n+\t@ denormalize value so we can resume with the code above afterwards.\n+\torr\txh, xh, #0x00100000\n+\tmov\tr2, r2, lsr #20\n+\trsb\tr2, r2, #25\n+\tcmp\tr2, #20\n+\tbgt\t6f\n+\n+\trsb\tip, r2, #32\n+\tmov\tr3, xl, lsl ip\n+\tmov\txl, xl, lsr r2\n+\torr\txl, xl, xh, lsl ip\n+\tmovs\txh, xh, lsl #1\n+\tmov\txh, xh, lsr r2\n+\tmov\txh, xh, rrx\n+5:\tteq\tr3, #0\t\t\t@ fold r3 bits into the LSB\n+\torrne\txl, xl, #1\t\t@ for rounding considerations. \n+\tmov\tr2, #(0x380 << 20)\t@ equivalent to the 0 float exponent\n+\tb\t1b\n+\n+6:\trsb\tr2, r2, #(12 + 20)\n+\trsb\tip, r2, #32\n+\tmov\tr3, xl, lsl r2\n+\tmov\txl, xl, lsr ip\n+\torr\txl, xl, xh, lsl r2\n+\tand\txh, xh, #0x80000000\n+\tb\t5b\n+\n+"}, {"sha": "88ded2931bf35d8e7979a33db4264db0b1c4c0c0", "filename": "gcc/config/arm/ieee754-sf.S", "status": "added", "additions": 813, "deletions": 0, "changes": 813, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4202ce820181761ad2e25b025894bb9537b42f76/gcc%2Fconfig%2Farm%2Fieee754-sf.S", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4202ce820181761ad2e25b025894bb9537b42f76/gcc%2Fconfig%2Farm%2Fieee754-sf.S", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Fieee754-sf.S?ref=4202ce820181761ad2e25b025894bb9537b42f76", "patch": "@@ -0,0 +1,813 @@\n+/* ieee754-sf.S single-precision floating point support for ARM\n+\n+   Copyright (C) 2003  Free Software Foundation, Inc.\n+   Contributed by Nicolas Pitre (nico@cam.org)\n+\n+   This file is free software; you can redistribute it and/or modify it\n+   under the terms of the GNU General Public License as published by the\n+   Free Software Foundation; either version 2, or (at your option) any\n+   later version.\n+\n+   In addition to the permissions in the GNU General Public License, the\n+   Free Software Foundation gives you unlimited permission to link the\n+   compiled version of this file into combinations with other programs,\n+   and to distribute those combinations without any restriction coming\n+   from the use of this file.  (The General Public License restrictions\n+   do apply in other respects; for example, they cover modification of\n+   the file, and distribution when not linked into a combine\n+   executable.)\n+\n+   This file is distributed in the hope that it will be useful, but\n+   WITHOUT ANY WARRANTY; without even the implied warranty of\n+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n+   General Public License for more details.\n+\n+   You should have received a copy of the GNU General Public License\n+   along with this program; see the file COPYING.  If not, write to\n+   the Free Software Foundation, 59 Temple Place - Suite 330,\n+   Boston, MA 02111-1307, USA.  */\n+\n+/*\n+ * Notes:\n+ *\n+ * The goal of this code is to be as fast as possible.  This is\n+ * not meant to be easy to understand for the casual reader.\n+ *\n+ * Only the default rounding mode is intended for best performances.\n+ * Exceptions aren't supported yet, but that can be added quite easily\n+ * if necessary without impacting performances.\n+ */\n+\n+@ This selects the minimum architecture level required.\n+#undef __ARM_ARCH__\n+#define __ARM_ARCH__ 3\n+\n+#if defined(__ARM_ARCH_3M__) || defined(__ARM_ARCH_4__) \\\n+\t|| defined(__ARM_ARCH_4T__)\n+#undef __ARM_ARCH__\n+/* We use __ARM_ARCH__ set to 4 here, but in reality it's any processor with\n+   long multiply instructions.  That includes v3M.  */\n+#define __ARM_ARCH__ 4\n+#endif\n+\t\n+#if defined(__ARM_ARCH_5__) || defined(__ARM_ARCH_5T__) \\\n+\t|| defined(__ARM_ARCH_5TE__)\n+#undef __ARM_ARCH__\n+#define __ARM_ARCH__ 5\n+#endif\n+\n+#if (__ARM_ARCH__ > 4) || defined(__ARM_ARCH_4T__)\n+#undef RET\n+#undef RETc\n+#define RET\tbx\tlr\n+#define RETc(x) bx##x\tlr\n+#if (__ARM_ARCH__ == 4) && (defined(__thumb__) || defined(__THUMB_INTERWORK__))\n+#define __FP_INTERWORKING__\n+#endif\n+#endif\n+\n+#if defined(__thumb__) && !defined(__THUMB_INTERWORK__)\n+.macro\tARM_FUNC_START name\n+\tFUNC_START \\name\n+\tbx\tpc\n+\tnop\n+\t.arm\n+.endm\n+#else\n+.macro\tARM_FUNC_START name\n+\tFUNC_START \\name\n+.endm\n+#endif\n+\n+ARM_FUNC_START negsf2\n+\teor\tr0, r0, #0x80000000\t@ flip sign bit\n+\tRET\n+\n+ARM_FUNC_START subsf3\n+\teor\tr1, r1, #0x80000000\t@ flip sign bit of second arg\n+#if defined(__thumb__) && !defined(__THUMB_INTERWORK__)\n+\tb\t1f\t\t\t@ Skip Thumb-code prologue\n+#endif\n+\n+ARM_FUNC_START addsf3\n+\n+1:\t@ Compare both args, return zero if equal but the sign.\n+\teor\tr2, r0, r1\n+\tteq\tr2, #0x80000000\n+\tbeq\tLSYM(Lad_z)\n+\n+\t@ If first arg is 0 or -0, return second arg.\n+\t@ If second arg is 0 or -0, return first arg.\n+\tbics\tr2, r0, #0x80000000\n+\tmoveq\tr0, r1\n+\tbicnes\tr2, r1, #0x80000000\n+\tRETc(eq)\n+\n+\t@ Mask out exponents.\n+\tmov\tip, #0xff000000\n+\tand\tr2, r0, ip, lsr #1\n+\tand\tr3, r1, ip, lsr #1\n+\n+\t@ If either of them is 255, result will be INF or NAN\n+\tteq\tr2, ip, lsr #1\n+\tteqne\tr3, ip, lsr #1\n+\tbeq\tLSYM(Lad_i)\n+\n+\t@ Compute exponent difference.  Make largest exponent in r2,\n+\t@ corresponding arg in r0, and positive exponent difference in r3.\n+\tsubs\tr3, r3, r2\n+\taddgt\tr2, r2, r3\n+\teorgt\tr1, r0, r1\n+\teorgt\tr0, r1, r0\n+\teorgt\tr1, r0, r1\n+\trsblt\tr3, r3, #0\n+\n+\t@ If exponent difference is too large, return largest argument\n+\t@ already in r0.  We need up to 25 bit to handle proper rounding\n+\t@ of 0x1p25 - 1.1.\n+\tcmp\tr3, #(25 << 23)\n+\tRETc(hi)\n+\n+\t@ Convert mantissa to signed integer.\n+\ttst\tr0, #0x80000000\n+\torr\tr0, r0, #0x00800000\n+\tbic\tr0, r0, #0xff000000\n+\trsbne\tr0, r0, #0\n+\ttst\tr1, #0x80000000\n+\torr\tr1, r1, #0x00800000\n+\tbic\tr1, r1, #0xff000000\n+\trsbne\tr1, r1, #0\n+\n+\t@ If exponent == difference, one or both args were denormalized.\n+\t@ Since this is not common case, rescale them off line.\n+\tteq\tr2, r3\n+\tbeq\tLSYM(Lad_d)\n+LSYM(Lad_x):\n+\n+\t@ Scale down second arg with exponent difference.\n+\t@ Apply shift one bit left to first arg and the rest to second arg\n+\t@ to simplify things later, but only if exponent does not become 0.\n+\tmovs\tr3, r3, lsr #23\n+\tteqne\tr2, #(1 << 23)\n+\tmovne\tr0, r0, lsl #1\n+\tsubne\tr2, r2, #(1 << 23)\n+\tsubne\tr3, r3, #1\n+\n+\t@ Shift second arg into ip, keep leftover bits into r1.\n+\tmov\tip, r1, asr r3\n+\trsb\tr3, r3, #32\n+\tmov\tr1, r1, lsl r3\n+\n+\tadd\tr0, r0, ip\t\t@ the actual addition\n+\n+\t@ We now have a 64 bit result in r0-r1.\n+\t@ Keep absolute value in r0-r1, sign in r3.\n+\tands\tr3, r0, #0x80000000\n+\tbpl\tLSYM(Lad_p)\n+\trsbs\tr1, r1, #0\n+\trsc\tr0, r0, #0\n+\n+\t@ Determine how to normalize the result.\n+LSYM(Lad_p):\n+\tcmp\tr0, #0x00800000\n+\tbcc\tLSYM(Lad_l)\n+\tcmp\tr0, #0x01000000\n+\tbcc\tLSYM(Lad_r0)\n+\tcmp\tr0, #0x02000000\n+\tbcc\tLSYM(Lad_r1)\n+\n+\t@ Result needs to be shifted right.\n+\tmovs\tr0, r0, lsr #1\n+\tmov\tr1, r1, rrx\n+\tadd\tr2, r2, #(1 << 23)\n+LSYM(Lad_r1):\n+\tmovs\tr0, r0, lsr #1\n+\tmov\tr1, r1, rrx\n+\tadd\tr2, r2, #(1 << 23)\n+\n+\t@ Our result is now properly aligned into r0, remaining bits in r1.\n+\t@ Round with MSB of r1. If halfway between two numbers, round towards\n+\t@ LSB of r0 = 0. \n+LSYM(Lad_r0):\n+\tadd\tr0, r0, r1, lsr #31\n+\tteq\tr1, #0x80000000\n+\tbiceq\tr0, r0, #1\n+\n+\t@ Rounding may have added a new MSB.  Adjust exponent.\n+\t@ That MSB will be cleared when exponent is merged below.\n+\ttst\tr0, #0x01000000\n+\taddne\tr2, r2, #(1 << 23)\n+\n+\t@ Make sure we did not bust our exponent.\n+\tcmp\tr2, #(254 << 23)\n+\tbhi\tLSYM(Lad_o)\n+\n+\t@ Pack final result together.\n+LSYM(Lad_e):\n+\tbic\tr0, r0, #0x01800000\n+\torr\tr0, r0, r2\n+\torr\tr0, r0, r3\n+\tRET\n+\n+\t@ Result must be shifted left.\n+\t@ No rounding necessary since r1 will always be 0.\n+LSYM(Lad_l):\n+\n+#if __ARM_ARCH__ < 5\n+\n+\tmovs\tip, r0, lsr #12\n+\tmoveq\tr0, r0, lsl #12\n+\tsubeq\tr2, r2, #(12 << 23)\n+\ttst\tr0, #0x00ff0000\n+\tmoveq\tr0, r0, lsl #8\n+\tsubeq\tr2, r2, #(8 << 23)\n+\ttst\tr0, #0x00f00000\n+\tmoveq\tr0, r0, lsl #4\n+\tsubeq\tr2, r2, #(4 << 23)\n+\ttst\tr0, #0x00c00000\n+\tmoveq\tr0, r0, lsl #2\n+\tsubeq\tr2, r2, #(2 << 23)\n+\ttst\tr0, #0x00800000\n+\tmoveq\tr0, r0, lsl #1\n+\tsubeq\tr2, r2, #(1 << 23)\n+\tcmp\tr2, #0\n+\tbgt\tLSYM(Lad_e)\n+\n+#else\n+\n+\tclz\tip, r0\n+\tsub\tip, ip, #8\n+\tmov\tr0, r0, lsl ip\n+\tsubs\tr2, r2, ip, lsl #23\n+\tbgt\tLSYM(Lad_e)\n+\n+#endif\n+\n+\t@ Exponent too small, denormalize result.\n+\tmvn\tr2, r2, asr #23\n+\tadd\tr2, r2, #2\n+\torr\tr0, r3, r0, lsr r2\n+\tRET\n+\n+\t@ Fixup and adjust bit position for denormalized arguments.\n+\t@ Note that r2 must not remain equal to 0.\n+LSYM(Lad_d):\n+\tteq\tr2, #0\n+\teoreq\tr0, r0, #0x00800000\n+\taddeq\tr2, r2, #(1 << 23)\n+\teor\tr1, r1, #0x00800000\n+\tsubne\tr3, r3, #(1 << 23)\n+\tb\tLSYM(Lad_x)\n+\n+\t@ Result is x - x = 0, unless x is INF or NAN.\n+LSYM(Lad_z):\n+\tmov\tip, #0xff000000\n+\tand\tr2, r0, ip, lsr #1\n+\tteq\tr2, ip, lsr #1\n+\tmoveq\tr0, ip, asr #2\n+\tmovne\tr0, #0\n+\tRET\n+\n+\t@ Overflow: return INF.\n+LSYM(Lad_o):\n+\torr\tr0, r3, #0x7f000000\n+\torr\tr0, r0, #0x00800000\n+\tRET\n+\n+\t@ At least one of r0/r1 is INF/NAN.\n+\t@   if r0 != INF/NAN: return r1 (which is INF/NAN)\n+\t@   if r1 != INF/NAN: return r0 (which is INF/NAN)\n+\t@   if r0 or r1 is NAN: return NAN\n+\t@   if opposite sign: return NAN\n+\t@   return r0 (which is INF or -INF)\n+LSYM(Lad_i):\n+\tteq\tr2, ip, lsr #1\n+\tmovne\tr0, r1\n+\tteqeq\tr3, ip, lsr #1\n+\tRETc(ne)\n+\tmovs\tr2, r0, lsl #9\n+\tmoveqs\tr2, r1, lsl #9\n+\tteqeq\tr0, r1\n+\torrne\tr0, r3, #0x00400000\t@ NAN\n+\tRET\n+\n+\n+ARM_FUNC_START floatunsisf\n+\tmov\tr3, #0\n+\tb\t1f\n+\n+ARM_FUNC_START floatsisf\n+\tands\tr3, r0, #0x80000000\n+\trsbmi\tr0, r0, #0\n+\n+1:\tteq\tr0, #0\n+\tRETc(eq)\n+\n+\tmov\tr1, #0\n+\tmov\tr2, #((127 + 23) << 23)\n+\ttst\tr0, #0xfc000000\n+\tbeq\tLSYM(Lad_p)\n+\n+\t@ We need to scale the value a little before branching to code above.\n+\ttst\tr0, #0xf0000000\n+\tmovne\tr1, r0, lsl #28\n+\tmovne\tr0, r0, lsr #4\n+\taddne\tr2, r2, #(4 << 23)\n+\ttst\tr0, #0x0c000000\n+\tbeq\tLSYM(Lad_p)\n+\tmov\tr1, r1, lsr #2\n+\torr\tr1, r1, r0, lsl #30\n+\tmov\tr0, r0, lsr #2\n+\tadd\tr2, r2, #(2 << 23)\n+\tb\tLSYM(Lad_p)\n+\n+\n+ARM_FUNC_START mulsf3\n+\n+\t@ Mask out exponents.\n+\tmov\tip, #0xff000000\n+\tand\tr2, r0, ip, lsr #1\n+\tand\tr3, r1, ip, lsr #1\n+\n+\t@ Trap any INF/NAN.\n+\tteq\tr2, ip, lsr #1\n+\tteqne\tr3, ip, lsr #1\n+\tbeq\tLSYM(Lml_s)\n+\n+\t@ Trap any multiplication by 0.\n+\tbics\tip, r0, #0x80000000\n+\tbicnes\tip, r1, #0x80000000\n+\tbeq\tLSYM(Lml_z)\n+\n+\t@ Shift exponents right one bit to make room for overflow bit.\n+\t@ If either of them is 0, scale denormalized arguments off line.\n+\t@ Then add both exponents together.\n+\tmovs\tr2, r2, lsr #1\n+\tteqne\tr3, #0\n+\tbeq\tLSYM(Lml_d)\n+LSYM(Lml_x):\n+\tadd\tr2, r2, r3, asr #1\n+\n+\t@ Preserve final sign in r2 along with exponent for now.\n+\tteq\tr0, r1\n+\torrmi\tr2, r2, #0x8000\n+\n+\t@ Convert mantissa to unsigned integer.\n+\tbic\tr0, r0, #0xff000000\n+\tbic\tr1, r1, #0xff000000\n+\torr\tr0, r0, #0x00800000\n+\torr\tr1, r1, #0x00800000\n+\n+#if __ARM_ARCH__ < 4\n+\n+\t@ Well, no way to make it shorter without the umull instruction.\n+\t@ We must perform that 24 x 24 -> 48 bit multiplication by hand.\n+\tstmfd\tsp!, {r4, r5}\n+\tmov\tr4, r0, lsr #16\n+\tmov\tr5, r1, lsr #16\n+\tbic\tr0, r0, #0x00ff0000\n+\tbic\tr1, r1, #0x00ff0000\n+\tmul\tip, r4, r5\n+\tmul\tr3, r0, r1\n+\tmul\tr0, r5, r0\n+\tmla\tr0, r4, r1, r0\n+\tadds\tr3, r3, r0, lsl #16\n+\tadc\tip, ip, r0, lsr #16\n+\tldmfd\tsp!, {r4, r5}\n+\n+#else\n+\n+\tumull\tr3, ip, r0, r1\t\t@ The actual multiplication.\n+\n+#endif\n+\n+\t@ Put final sign in r0.\n+\tmov\tr0, r2, lsl #16\n+\tbic\tr2, r2, #0x8000\n+\n+\t@ Adjust result if one extra MSB appeared.\n+\t@ The LSB may be lost but this never changes the result in this case.\n+\ttst\tip, #(1 << 15)\n+\taddne\tr2, r2, #(1 << 22)\n+\tmovnes\tip, ip, lsr #1\n+\tmovne\tr3, r3, rrx\n+\n+\t@ Apply exponent bias, check range for underflow.\n+\tsubs\tr2, r2, #(127 << 22)\n+\tble\tLSYM(Lml_u)\n+\n+\t@ Scale back to 24 bits with rounding.\n+\t@ r0 contains sign bit already.\n+\torrs\tr0, r0, r3, lsr #23\n+\tadc\tr0, r0, ip, lsl #9\n+\n+\t@ If halfway between two numbers, rounding should be towards LSB = 0.\n+\tmov\tr3, r3, lsl #9\n+\tteq\tr3, #0x80000000\n+\tbiceq\tr0, r0, #1\n+\n+\t@ Note: rounding may have produced an extra MSB here.\n+\t@ The extra bit is cleared before merging the exponent below.\n+\ttst\tr0, #0x01000000\n+\taddne\tr2, r2, #(1 << 22)\n+\n+\t@ Check for exponent overflow\n+\tcmp\tr2, #(255 << 22)\n+\tbge\tLSYM(Lml_o)\n+\n+\t@ Add final exponent.\n+\tbic\tr0, r0, #0x01800000\n+\torr\tr0, r0, r2, lsl #1\n+\tRET\n+\n+\t@ Result is 0, but determine sign anyway.\n+LSYM(Lml_z):\teor\tr0, r0, r1\n+\tbic\tr0, r0, #0x7fffffff\n+\tRET\n+\n+\t@ Check if denormalized result is possible, otherwise return signed 0.\n+LSYM(Lml_u):\n+\tcmn\tr2, #(24 << 22)\n+\tRETc(le)\n+\n+\t@ Find out proper shift value.\n+\tmvn\tr1, r2, asr #22\n+\tsubs\tr1, r1, #7\n+\tbgt\tLSYM(Lml_ur)\n+\n+\t@ Shift value left, round, etc.\n+\tadd\tr1, r1, #32\n+\torrs\tr0, r0, r3, lsr r1\n+\trsb\tr1, r1, #32\n+\tadc\tr0, r0, ip, lsl r1\n+\tmov\tip, r3, lsl r1\n+\tteq\tip, #0x80000000\n+\tbiceq\tr0, r0, #1\n+\tRET\n+\n+\t@ Shift value right, round, etc.\n+\t@ Note: r1 must not be 0 otherwise carry does not get set.\n+LSYM(Lml_ur):\n+\torrs\tr0, r0, ip, lsr r1\n+\tadc\tr0, r0, #0\n+\trsb\tr1, r1, #32\n+\tmov\tip, ip, lsl r1\n+\tteq\tr3, #0\n+\tteqeq\tip, #0x80000000\n+\tbiceq\tr0, r0, #1\n+\tRET\n+\n+\t@ One or both arguments are denormalized.\n+\t@ Scale them leftwards and preserve sign bit.\n+LSYM(Lml_d):\n+\tteq\tr2, #0\n+\tand\tip, r0, #0x80000000\n+1:\tmoveq\tr0, r0, lsl #1\n+\ttsteq\tr0, #0x00800000\n+\tsubeq\tr2, r2, #(1 << 22)\n+\tbeq\t1b\n+\torr\tr0, r0, ip\n+\tteq\tr3, #0\n+\tand\tip, r1, #0x80000000\n+2:\tmoveq\tr1, r1, lsl #1\n+\ttsteq\tr1, #0x00800000\n+\tsubeq\tr3, r3, #(1 << 23)\n+\tbeq\t2b\n+\torr\tr1, r1, ip\n+\tb\tLSYM(Lml_x)\n+\n+\t@ One or both args are INF or NAN.\n+LSYM(Lml_s):\n+\tteq\tr0, #0x0\n+\tteqne\tr1, #0x0\n+\tteqne\tr0, #0x80000000\n+\tteqne\tr1, #0x80000000\n+\tbeq\tLSYM(Lml_n)\t\t@ 0 * INF or INF * 0 -> NAN\n+\tteq\tr2, ip, lsr #1\n+\tbne\t1f\n+\tmovs\tr2, r0, lsl #9\n+\tbne\tLSYM(Lml_n)\t\t@ NAN * <anything> -> NAN\n+1:\tteq\tr3, ip, lsr #1\n+\tbne\tLSYM(Lml_i)\n+\tmovs\tr3, r1, lsl #9\n+\tbne\tLSYM(Lml_n)\t\t@ <anything> * NAN -> NAN\n+\n+\t@ Result is INF, but we need to determine its sign.\n+LSYM(Lml_i):\n+\teor\tr0, r0, r1\n+\n+\t@ Overflow: return INF (sign already in r0).\n+LSYM(Lml_o):\n+\tand\tr0, r0, #0x80000000\n+\torr\tr0, r0, #0x7f000000\n+\torr\tr0, r0, #0x00800000\n+\tRET\n+\n+\t@ Return NAN.\n+LSYM(Lml_n):\n+\tmov\tr0, #0x7f000000\n+\torr\tr0, r0, #0x00c00000\n+\tRET\n+\n+\n+ARM_FUNC_START divsf3\n+\n+\t@ Mask out exponents.\n+\tmov\tip, #0xff000000\n+\tand\tr2, r0, ip, lsr #1\n+\tand\tr3, r1, ip, lsr #1\n+\n+\t@ Trap any INF/NAN or zeroes.\n+\tteq\tr2, ip, lsr #1\n+\tteqne\tr3, ip, lsr #1\n+\tbicnes\tip, r0, #0x80000000\n+\tbicnes\tip, r1, #0x80000000\n+\tbeq\tLSYM(Ldv_s)\n+\n+\t@ Shift exponents right one bit to make room for overflow bit.\n+\t@ If either of them is 0, scale denormalized arguments off line.\n+\t@ Then substract divisor exponent from dividend''s.\n+\tmovs\tr2, r2, lsr #1\n+\tteqne\tr3, #0\n+\tbeq\tLSYM(Ldv_d)\n+LSYM(Ldv_x):\n+\tsub\tr2, r2, r3, asr #1\n+\n+\t@ Preserve final sign into ip.\n+\teor\tip, r0, r1\n+\n+\t@ Convert mantissa to unsigned integer.\n+\t@ Dividend -> r3, divisor -> r1.\n+\tmov\tr3, #0x10000000\n+\tmovs\tr1, r1, lsl #9\n+\tmov\tr0, r0, lsl #9\n+\tbeq\tLSYM(Ldv_1)\n+\torr\tr1, r3, r1, lsr #4\n+\torr\tr3, r3, r0, lsr #4\n+\n+\t@ Initialize r0 (result) with final sign bit.\n+\tand\tr0, ip, #0x80000000\n+\n+\t@ Ensure result will land to known bit position.\n+\tcmp\tr3, r1\n+\tsubcc\tr2, r2, #(1 << 22)\n+\tmovcc\tr3, r3, lsl #1\n+\n+\t@ Apply exponent bias, check range for over/underflow.\n+\tadd\tr2, r2, #(127 << 22)\n+\tcmn\tr2, #(24 << 22)\n+\tRETc(le)\n+\tcmp\tr2, #(255 << 22)\n+\tbge\tLSYM(Lml_o)\n+\n+\t@ The actual division loop.\n+\tmov\tip, #0x00800000\n+1:\tcmp\tr3, r1\n+\tsubcs\tr3, r3, r1\n+\torrcs\tr0, r0, ip\n+\tcmp\tr3, r1, lsr #1\n+\tsubcs\tr3, r3, r1, lsr #1\n+\torrcs\tr0, r0, ip, lsr #1\n+\tcmp\tr3, r1, lsr #2\n+\tsubcs\tr3, r3, r1, lsr #2\n+\torrcs\tr0, r0, ip, lsr #2\n+\tcmp\tr3, r1, lsr #3\n+\tsubcs\tr3, r3, r1, lsr #3\n+\torrcs\tr0, r0, ip, lsr #3\n+\tmovs\tr3, r3, lsl #4\n+\tmovnes\tip, ip, lsr #4\n+\tbne\t1b\n+\n+\t@ Check if denormalized result is needed.\n+\tcmp\tr2, #0\n+\tble\tLSYM(Ldv_u)\n+\n+\t@ Apply proper rounding.\n+\tcmp\tr3, r1\n+\taddcs\tr0, r0, #1\n+\tbiceq\tr0, r0, #1\n+\n+\t@ Add exponent to result.\n+\tbic\tr0, r0, #0x00800000\n+\torr\tr0, r0, r2, lsl #1\n+\tRET\n+\n+\t@ Division by 0x1p*: let''s shortcut a lot of code.\n+LSYM(Ldv_1):\n+\tand\tip, ip, #0x80000000\n+\torr\tr0, ip, r0, lsr #9\n+\tadd\tr2, r2, #(127 << 22)\n+\tcmp\tr2, #(255 << 22)\n+\tbge\tLSYM(Lml_o)\n+\tcmp\tr2, #0\n+\torrgt\tr0, r0, r2, lsl #1\n+\tRETc(gt)\n+\tcmn\tr2, #(24 << 22)\n+\tmovle\tr0, ip\n+\tRETc(le)\n+\torr\tr0, r0, #0x00800000\n+\tmov\tr3, #0\n+\n+\t@ Result must be denormalized: prepare parameters to use code above.\n+\t@ r3 already contains remainder for rounding considerations.\n+LSYM(Ldv_u):\n+\tbic\tip, r0, #0x80000000\n+\tand\tr0, r0, #0x80000000\n+\tmvn\tr1, r2, asr #22\n+\tadd\tr1, r1, #2\n+\tb\tLSYM(Lml_ur)\n+\n+\t@ One or both arguments are denormalized.\n+\t@ Scale them leftwards and preserve sign bit.\n+LSYM(Ldv_d):\n+\tteq\tr2, #0\n+\tand\tip, r0, #0x80000000\n+1:\tmoveq\tr0, r0, lsl #1\n+\ttsteq\tr0, #0x00800000\n+\tsubeq\tr2, r2, #(1 << 22)\n+\tbeq\t1b\n+\torr\tr0, r0, ip\n+\tteq\tr3, #0\n+\tand\tip, r1, #0x80000000\n+2:\tmoveq\tr1, r1, lsl #1\n+\ttsteq\tr1, #0x00800000\n+\tsubeq\tr3, r3, #(1 << 23)\n+\tbeq\t2b\n+\torr\tr1, r1, ip\n+\tb\tLSYM(Ldv_x)\n+\n+\t@ One or both arguments is either INF, NAN or zero.\n+LSYM(Ldv_s):\n+\tmov\tip, #0xff000000\n+\tteq\tr2, ip, lsr #1\n+\tteqeq\tr3, ip, lsr #1\n+\tbeq\tLSYM(Lml_n)\t\t@ INF/NAN / INF/NAN -> NAN\n+\tteq\tr2, ip, lsr #1\n+\tbne\t1f\n+\tmovs\tr2, r0, lsl #9\n+\tbne\tLSYM(Lml_n)\t\t@ NAN / <anything> -> NAN\n+\tb\tLSYM(Lml_i)\t\t@ INF / <anything> -> INF\n+1:\tteq\tr3, ip, lsr #1\n+\tbne\t2f\n+\tmovs\tr3, r1, lsl #9\n+\tbne\tLSYM(Lml_n)\t\t@ <anything> / NAN -> NAN\n+\tb\tLSYM(Lml_z)\t\t@ <anything> / INF -> 0\n+2:\t@ One or both arguments are 0.\n+\tbics\tr2, r0, #0x80000000\n+\tbne\tLSYM(Lml_i)\t\t@ <non_zero> / 0 -> INF\n+\tbics\tr3, r1, #0x80000000\n+\tbne\tLSYM(Lml_z)\t\t@ 0 / <non_zero> -> 0\n+\tb\tLSYM(Lml_n)\t\t@ 0 / 0 -> NAN\n+\n+\n+FUNC_START gesf2\n+ARM_FUNC_START gtsf2\n+\tmov\tr3, #-1\n+\tb\t1f\n+\n+FUNC_START lesf2\n+ARM_FUNC_START ltsf2\n+\tmov\tr3, #1\n+\tb\t1f\n+\n+FUNC_START nesf2\n+FUNC_START eqsf2\n+ARM_FUNC_START cmpsf2\n+\tmov\tr3, #1\t\t\t@ how should we specify unordered here?\n+\n+1:\t@ Trap any INF/NAN first.\n+\tmov\tip, #0xff000000\n+\tand\tr2, r1, ip, lsr #1\n+\tteq\tr2, ip, lsr #1\n+\tand\tr2, r0, ip, lsr #1\n+\tteqne\tr2, ip, lsr #1\n+\tbeq\t3f\n+\n+\t@ Test for equality.\n+\t@ Note that 0.0 is equal to -0.0.\n+2:\torr\tr3, r0, r1\n+\tbics\tr3, r3, #0x80000000\t@ either 0.0 or -0.0\n+\tteqne\tr0, r1\t\t\t@ or both the same\n+\tmoveq\tr0, #0\n+\tRETc(eq)\n+\n+\t@ Check for sign difference.  The N flag is set if it is the case.\n+\t@ If so, return sign of r0.\n+\tmovmi\tr0, r0, asr #31\n+\torrmi\tr0, r0, #1\n+\tRETc(mi)\n+\n+\t@ Compare exponents.\n+\tand\tr3, r1, ip, lsr #1\n+\tcmp\tr2, r3\n+\n+\t@ Compare mantissa if exponents are equal\n+\tmoveq\tr0, r0, lsl #9\n+\tcmpeq\tr0, r1, lsl #9\n+\tmovcs\tr0, r1, asr #31\n+\tmvncc\tr0, r1, asr #31\n+\torr\tr0, r0, #1\n+\tRET\n+\n+\t@ Look for a NAN. \n+3:\tand\tr2, r1, ip, lsr #1\n+\tteq\tr2, ip, lsr #1\n+\tbne\t4f\n+\tmovs\tr2, r1, lsl #9\n+\tbne\t5f\t\t\t@ r1 is NAN\n+4:\tand\tr2, r0, ip, lsr #1\n+\tteq\tr2, ip, lsr #1\n+\tbne\t2b\n+\tmovs\tip, r0, lsl #9\n+\tbeq\t2b\t\t\t@ r0 is not NAN\n+5:\tmov\tr0, r3\t\t\t@ return unordered code from r3.\n+\tRET\n+\n+\n+ARM_FUNC_START unordsf2\n+\tmov\tip, #0xff000000\n+\tand\tr2, r1, ip, lsr #1\n+\tteq\tr2, ip, lsr #1\n+\tbne\t1f\n+\tmovs\tr2, r1, lsl #9\n+\tbne\t3f\t\t\t@ r1 is NAN\n+1:\tand\tr2, r0, ip, lsr #1\n+\tteq\tr2, ip, lsr #1\n+\tbne\t2f\n+\tmovs\tr2, r0, lsl #9\n+\tbne\t3f\t\t\t@ r0 is NAN\n+2:\tmov\tr0, #0\t\t\t@ arguments are ordered.\n+\tRET\n+3:\tmov\tr0, #1\t\t\t@ arguments are unordered.\n+\tRET\n+\n+\n+ARM_FUNC_START fixsfsi\n+\tmovs\tr0, r0, lsl #1\n+\tRETc(eq)\t\t\t@ value is 0.\n+\t@ preserve C flag (the actual sign)\n+#ifdef __APCS_26__\n+\tmov\tr1, pc\n+#else\n+\tmrs\tr1, cpsr\n+#endif\n+\n+\t@ check exponent range.\n+\tand\tr2, r0, #0xff000000\n+\tcmp\tr2, #(127 << 24)\n+\tmovcc\tr0, #0\t\t\t@ value is too small\n+\tRETc(cc)\n+\tcmp\tr2, #((127 + 31) << 24)\n+\tbcs\t1f\t\t\t@ value is too large\n+\n+\tmov\tr0, r0, lsl #7\n+\torr\tr0, r0, #0x80000000\n+\tmov\tr2, r2, lsr #24\n+\trsb\tr2, r2, #(127 + 31)\n+\tmov\tr0, r0, lsr r2\n+\ttst\tr1, #0x20000000\t\t@ the sign bit\n+\trsbne\tr0, r0, #0\n+\tRET\n+\n+1:\tteq\tr2, #0xff000000\n+\tbne\t2f\n+\tmovs\tr0, r0, lsl #8\n+\tbne\t3f\t\t\t@ r0 is NAN.\n+2:\ttst\tr1, #0x20000000\t\t@ the sign bit\n+\tmoveq\tr0, #0x7fffffff\t\t@ the maximum signed positive si\n+\tmovne\tr0, #0x80000000\t\t@ the maximum signed negative si\n+\tRET\n+\n+3:\tmov\tr0, #0\t\t\t@ What should we convert NAN to?\n+\tRET\n+\n+\n+ARM_FUNC_START fixunssfsi\n+\tmovs\tr0, r0, lsl #1\n+\tRETc(eq)\t\t\t@ value is 0.\n+\tmovcs\tr0, #0\n+\tRETc(cs)\t\t\t@ value is negative.\n+\n+\t@ check exponent range.\n+\tand\tr2, r0, #0xff000000\n+\tcmp\tr2, #(127 << 24)\n+\tmovcc\tr0, #0\t\t\t@ value is too small\n+\tRETc(cc)\n+\tcmp\tr2, #((127 + 32) << 24)\n+\tbcs\t1f\t\t\t@ value is too large\n+\n+\tmov\tr0, r0, lsl #7\n+\torr\tr0, r0, #0x80000000\n+\tmov\tr2, r2, lsr #24\n+\trsb\tr2, r2, #(127 + 31)\n+\tmov\tr0, r0, lsr r2\n+\tRET\n+\n+1:\tteq\tr2, #0xff000000\n+\tbne\t2f\n+\tmovs\tr0, r0, lsl #8\n+\tbne\t3b\t\t\t@ r0 is NAN.\n+2:\tmov\tr0, #0xffffffff\t\t@ maximum unsigned si\n+\tRET\n+\n+"}, {"sha": "f587bc2969e967da76f6cf7345ada0795d97f016", "filename": "gcc/config/arm/lib1funcs.asm", "status": "modified", "additions": 14, "deletions": 0, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4202ce820181761ad2e25b025894bb9537b42f76/gcc%2Fconfig%2Farm%2Flib1funcs.asm", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4202ce820181761ad2e25b025894bb9537b42f76/gcc%2Fconfig%2Farm%2Flib1funcs.asm", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Flib1funcs.asm?ref=4202ce820181761ad2e25b025894bb9537b42f76", "patch": "@@ -782,3 +782,17 @@ _arm_return:\n \tSIZE\t(_interwork_call_via_lr)\n \t\n #endif /* L_interwork_call_via_rX */\n+\n+#ifdef L_ieee754_dp\n+\t/* These functions are coded in ARM state, even when called from\n+\t   Thumb.  */\n+\t.arm\n+#include \"ieee754-df.S\"\n+#endif\n+\n+#ifdef L_ieee754_sp\n+\t/* These functions are coded in ARM state, even when called from\n+\t   Thumb.  */\n+\t.arm\n+#include \"ieee754-sf.S\"\n+#endif"}, {"sha": "7b0b86754d42b7fe9fdacf8a2a7d8fef1fd32331", "filename": "gcc/config/arm/t-arm-elf", "status": "modified", "additions": 4, "deletions": 23, "changes": 27, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/4202ce820181761ad2e25b025894bb9537b42f76/gcc%2Fconfig%2Farm%2Ft-arm-elf", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/4202ce820181761ad2e25b025894bb9537b42f76/gcc%2Fconfig%2Farm%2Ft-arm-elf", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Farm%2Ft-arm-elf?ref=4202ce820181761ad2e25b025894bb9537b42f76", "patch": "@@ -1,38 +1,18 @@\n LIB1ASMSRC = arm/lib1funcs.asm\n-LIB1ASMFUNCS = _udivsi3 _divsi3 _umodsi3 _modsi3 _dvmd_tls _bb_init_func _call_via_rX _interwork_call_via_rX\n+LIB1ASMFUNCS = _udivsi3 _divsi3 _umodsi3 _modsi3 _dvmd_tls _bb_init_func _call_via_rX _interwork_call_via_rX _ieee754_dp _ieee754_sp\n \n-# We want fine grained libraries, so use the new code to build the\n-# floating point emulation libraries.\n-FPBIT = fp-bit.c\n-DPBIT = dp-bit.c\n-\n-fp-bit.c: $(srcdir)/config/fp-bit.c\n-\techo '#define FLOAT' > fp-bit.c\n-\techo '#ifndef __ARMEB__' >> fp-bit.c\n-\techo '#define FLOAT_BIT_ORDER_MISMATCH' >> fp-bit.c\n-\techo '#endif' >> fp-bit.c\n-\tcat $(srcdir)/config/fp-bit.c >> fp-bit.c\n-\n-dp-bit.c: $(srcdir)/config/fp-bit.c\n-\techo '#ifndef __ARMEB__' > dp-bit.c\n-\techo '#define FLOAT_BIT_ORDER_MISMATCH' >> dp-bit.c\n-\techo '#define FLOAT_WORD_ORDER_MISMATCH' >> dp-bit.c\n-\techo '#endif' >> dp-bit.c\n-\tcat $(srcdir)/config/fp-bit.c >> dp-bit.c\n-\n-\t\n MULTILIB_OPTIONS     = marm/mthumb\n MULTILIB_DIRNAMES    = arm thumb\n MULTILIB_EXCEPTIONS  = \n+MULTILIB_MATCHES     =\n \n # MULTILIB_OPTIONS    += mcpu=ep9312\n # MULTILIB_DIRNAMES   += ep9312\n # MULTILIB_EXCEPTIONS += *mthumb/*mcpu=ep9312*\n \t\n # MULTILIB_OPTIONS     += mlittle-endian/mbig-endian\n # MULTILIB_DIRNAMES    += le be\n-# MULTILIB_EXCEPTIONS  = \n-# MULTILIB_MATCHES     = mbig-endian=mbe mlittle-endian=mle\n+# MULTILIB_MATCHES     += mbig-endian=mbe mlittle-endian=mle\n # \n # MULTILIB_OPTIONS    += mhard-float/msoft-float\n # MULTILIB_DIRNAMES   += fpu soft\n@@ -97,3 +77,4 @@ $(T)crti.o: $(srcdir)/config/arm/crti.asm $(GCC_PASSES)\n $(T)crtn.o: $(srcdir)/config/arm/crtn.asm $(GCC_PASSES)\n \t$(GCC_FOR_TARGET) $(GCC_CFLAGS) $(MULTILIB_CFLAGS) $(INCLUDES) \\\n \t-c -o $(T)crtn.o -x assembler-with-cpp $(srcdir)/config/arm/crtn.asm\n+"}]}