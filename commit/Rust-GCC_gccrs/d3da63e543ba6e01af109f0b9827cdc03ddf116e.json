{"sha": "d3da63e543ba6e01af109f0b9827cdc03ddf116e", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZDNkYTYzZTU0M2JhNmUwMWFmMTA5ZjBiOTgyN2NkYzAzZGRmMTE2ZQ==", "commit": {"author": {"name": "Richard Sandiford", "email": "richard.sandiford@arm.com", "date": "2017-01-13T16:00:26Z"}, "committer": {"name": "Richard Sandiford", "email": "rsandifo@gcc.gnu.org", "date": "2017-01-13T16:00:26Z"}, "message": "Avoid excessively-big hash tables in empty-add cycles\n\nA big source of cache misses when compiling a recent version of\ngimple-match.ii was the call to cv_cache.empty () in clear_cv_cache.\nThe problem was that at one early point the hash table had grown\nto 8191 entries (128k on LP64 hosts).  It then stayed at that size\nfor the rest of the compilation, even though subsequent uses needed\nonly a small number of entries (usually fewer than ten).  We would\nstill clear the whole 128k each time clear_cv_cache was called.\n\nempty() already looks for cases where the hash table is very big\nand cuts it down.  At the moment it fires when the table is 1M\nin size and reduces it to the next selected prime above 1K (so\nalmost 2K in practice).  One fix would have been to lower the\nthreshold, but that didn't feel like the right approach.  Reducing\nthe current limit of 1M by a factor of 8 would be pretty significant\non its own, but I think this cv_cache behaviour would have been a\nproblem even with 64k or 32k tables.\n\nI think the existing check is really for cases in which even a\nwell-populated table would need to be shrunk rather than cleared.\nHere the problem isn't that the table is excessively big in\nabsolute terms, more that one outlier has made the table much\ntoo big for the general case.\n\ntraverse() already shrinks the table if it's \"too empty\",\nwhich is taken to be if:\n\n      no. elements * 8 < capacity && capacity > 32\n\nSo an alternative would be to apply the same test (and the same choice\nof shrunken size) to empty_slow too.  The patch below does this.\nIt gives a 2.5% improvement in gimple-match.ii compile time at -O0 -g\nand doesn't seem to adversely affect any other tests I've tried.\n\nOf course, there's a theoretical risk of a table alternating between\none large element count and one small element count.  If there was a\nfactor of eight difference between the two, we could shrink the table\non seeing each small element count, then grow it again when adding the\nlarge number of elements.  That seems pretty unlikely in practice\nthough.\n\nAlso, empty_slow() does involve a traversal if some form of manual\ngc is needed on active elements, so trying to recover from an outlier\nshould have even more benefit there.  (cv_cache uses automatic gc and so\nthe traversal gets optimised away.)\n\nThe calculation of the existing 1M threshold was assuming that each\nentry was pointer-sized.  This patch makes it use the actual size of the\nentry instead.\n\nTested on aarch64-linux-gnu and x86_64-linux-gnu.\n\ngcc/\n\t* hash-table.h (hash_table::too_empty_p): New function.\n\t(hash_table::expand): Use it.\n\t(hash_table::traverse): Likewise.\n\t(hash_table::empty_slot): Use sizeof (value_type) instead of\n\tsizeof (PTR) to convert bytes to elements.  Shrink the table\n\tif the current size is excessive for the current number of\n\telements.\n\nFrom-SVN: r244447", "tree": {"sha": "117299cf30ca43fe6d79a5a0be58b2a56caa8d68", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/117299cf30ca43fe6d79a5a0be58b2a56caa8d68"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/d3da63e543ba6e01af109f0b9827cdc03ddf116e", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d3da63e543ba6e01af109f0b9827cdc03ddf116e", "html_url": "https://github.com/Rust-GCC/gccrs/commit/d3da63e543ba6e01af109f0b9827cdc03ddf116e", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/d3da63e543ba6e01af109f0b9827cdc03ddf116e/comments", "author": {"login": "rsandifo-arm", "id": 28043039, "node_id": "MDQ6VXNlcjI4MDQzMDM5", "avatar_url": "https://avatars.githubusercontent.com/u/28043039?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rsandifo-arm", "html_url": "https://github.com/rsandifo-arm", "followers_url": "https://api.github.com/users/rsandifo-arm/followers", "following_url": "https://api.github.com/users/rsandifo-arm/following{/other_user}", "gists_url": "https://api.github.com/users/rsandifo-arm/gists{/gist_id}", "starred_url": "https://api.github.com/users/rsandifo-arm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rsandifo-arm/subscriptions", "organizations_url": "https://api.github.com/users/rsandifo-arm/orgs", "repos_url": "https://api.github.com/users/rsandifo-arm/repos", "events_url": "https://api.github.com/users/rsandifo-arm/events{/privacy}", "received_events_url": "https://api.github.com/users/rsandifo-arm/received_events", "type": "User", "site_admin": false}, "committer": null, "parents": [{"sha": "3d8e492088897fadb3434917d73f5728f1bbbc19", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/3d8e492088897fadb3434917d73f5728f1bbbc19", "html_url": "https://github.com/Rust-GCC/gccrs/commit/3d8e492088897fadb3434917d73f5728f1bbbc19"}], "stats": {"total": 35, "additions": 30, "deletions": 5}, "files": [{"sha": "b5f7b08f0a89161e0ddc4a1eb7a9edd61bb2d665", "filename": "gcc/ChangeLog", "status": "modified", "additions": 10, "deletions": 0, "changes": 10, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d3da63e543ba6e01af109f0b9827cdc03ddf116e/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d3da63e543ba6e01af109f0b9827cdc03ddf116e/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=d3da63e543ba6e01af109f0b9827cdc03ddf116e", "patch": "@@ -1,3 +1,13 @@\n+2017-01-13  Richard Sandiford  <richard.sandiford@arm.com>\n+\n+\t* hash-table.h (hash_table::too_empty_p): New function.\n+\t(hash_table::expand): Use it.\n+\t(hash_table::traverse): Likewise.\n+\t(hash_table::empty_slot): Use sizeof (value_type) instead of\n+\tsizeof (PTR) to convert bytes to elements.  Shrink the table\n+\tif the current size is excessive for the current number of\n+\telements.\n+\n 2017-01-13  Richard Sandiford  <richard.sandiford@arm.com>\n \n \t* ira-costs.c (record_reg_classes): Break from the inner loop"}, {"sha": "0f7e21a2cc5e4c22e0f608c8f2ba932d69e5fae2", "filename": "gcc/hash-table.h", "status": "modified", "additions": 20, "deletions": 5, "changes": 25, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/d3da63e543ba6e01af109f0b9827cdc03ddf116e/gcc%2Fhash-table.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/d3da63e543ba6e01af109f0b9827cdc03ddf116e/gcc%2Fhash-table.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fhash-table.h?ref=d3da63e543ba6e01af109f0b9827cdc03ddf116e", "patch": "@@ -503,6 +503,7 @@ class hash_table\n \n   value_type *alloc_entries (size_t n CXX_MEM_STAT_INFO) const;\n   value_type *find_empty_slot_for_expand (hashval_t);\n+  bool too_empty_p (unsigned int);\n   void expand ();\n   static bool is_deleted (value_type &v)\n   {\n@@ -691,6 +692,15 @@ hash_table<Descriptor, Allocator>::find_empty_slot_for_expand (hashval_t hash)\n     }\n }\n \n+/* Return true if the current table is excessively big for ELTS elements.  */\n+\n+template<typename Descriptor, template<typename Type> class Allocator>\n+inline bool\n+hash_table<Descriptor, Allocator>::too_empty_p (unsigned int elts)\n+{\n+  return elts * 8 < m_size && m_size > 32;\n+}\n+\n /* The following function changes size of memory allocated for the\n    entries and repeatedly inserts the table elements.  The occupancy\n    of the table after the call will be about 50%.  Naturally the hash\n@@ -712,7 +722,7 @@ hash_table<Descriptor, Allocator>::expand ()\n      too full or too empty.  */\n   unsigned int nindex;\n   size_t nsize;\n-  if (elts * 2 > osize || (elts * 8 < osize && osize > 32))\n+  if (elts * 2 > osize || too_empty_p (elts))\n     {\n       nindex = hash_table_higher_prime_index (elts * 2);\n       nsize = prime_tab[nindex].prime;\n@@ -764,6 +774,7 @@ void\n hash_table<Descriptor, Allocator>::empty_slow ()\n {\n   size_t size = m_size;\n+  size_t nsize = size;\n   value_type *entries = m_entries;\n   int i;\n \n@@ -772,9 +783,14 @@ hash_table<Descriptor, Allocator>::empty_slow ()\n       Descriptor::remove (entries[i]);\n \n   /* Instead of clearing megabyte, downsize the table.  */\n-  if (size > 1024*1024 / sizeof (PTR))\n+  if (size > 1024*1024 / sizeof (value_type))\n+    nsize = 1024 / sizeof (value_type);\n+  else if (too_empty_p (m_n_elements))\n+    nsize = m_n_elements * 2;\n+\n+  if (nsize != size)\n     {\n-      int nindex = hash_table_higher_prime_index (1024 / sizeof (PTR));\n+      int nindex = hash_table_higher_prime_index (nsize);\n       int nsize = prime_tab[nindex].prime;\n \n       if (!m_ggc)\n@@ -965,8 +981,7 @@ template <typename Argument,\n void\n hash_table<Descriptor, Allocator>::traverse (Argument argument)\n {\n-  size_t size = m_size;\n-  if (elements () * 8 < size && size > 32)\n+  if (too_empty_p (elements ()))\n     expand ();\n \n   traverse_noresize <Argument, Callback> (argument);"}]}