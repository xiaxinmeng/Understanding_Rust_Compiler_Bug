{"sha": "c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YzZhMjlhMDkxYTExYjYzMzdjNzgxMzBiNzM4YTBmNWE5NmIyYTJmNQ==", "commit": {"author": {"name": "Alan Lawrence", "email": "alan.lawrence@arm.com", "date": "2014-06-23T12:46:52Z"}, "committer": {"name": "Alan Lawrence", "email": "alalaw01@gcc.gnu.org", "date": "2014-06-23T12:46:52Z"}, "message": "PR/60825 Make float64x1_t in arm_neon.h a proper vector type\n\ngcc/ChangeLog:\n\tPR target/60825\n\t* config/aarch64/aarch64.c (aarch64_simd_mangle_map): Add entry for\n\tV1DFmode.\n\t* config/aarch64/aarch64-builtins.c (aarch64_simd_builtin_type_mode):\n\tadd V1DFmode\n\t(BUILTIN_VD1): New.\n\t(BUILTIN_VD_RE): Remove.\n\t(aarch64_init_simd_builtins): Add V1DF to modes/modenames.\n\t(aarch64_fold_builtin): Update reinterpret patterns, df becomes v1df.\n\t* config/aarch64/aarch64-simd-builtins.def (create): Make a v1df\n\tvariant but not df.\n\t(vreinterpretv1df*, vreinterpret*v1df): New.\n\t(vreinterpretdf*, vreinterpret*df): Remove.\n\t* config/aarch64/aarch64-simd.md (aarch64_create, aarch64_reinterpret*):\n\tGenerate V1DFmode pattern not DFmode.\n\t* config/aarch64/iterators.md (VD_RE): Include V1DF, remove DF.\n\t(VD1): New.\n\t* config/aarch64/arm_neon.h (float64x1_t): typedef with gcc extensions.\n\t(vcreate_f64): Remove cast, use v1df builtin.\n\t(vcombine_f64): Remove cast, get elements with gcc vector extensions.\n\t(vget_low_f64, vabs_f64, vceq_f64, vceqz_f64, vcge_f64, vgfez_f64,\n\tvcgt_f64, vcgtz_f64, vcle_f64, vclez_f64, vclt_f64, vcltz_f64,\n\tvdup_n_f64, vdupq_lane_f64, vld1_f64, vld2_f64, vld3_f64, vld4_f64,\n\tvmov_n_f64, vst1_f64): Use gcc vector extensions.\n\t(vget_lane_f64, vdupd_lane_f64, vmulq_lane_f64, ): Use gcc extensions,\n\tadd range check using __builtin_aarch64_im_lane_boundsi.\n\t(vfma_lane_f64, vfmad_lane_f64, vfma_laneq_f64, vfmaq_lane_f64,\n\tvfms_lane_f64, vfmsd_lane_f64, vfms_laneq_f64, vfmsq_lane_f64): Fix\n\ttype signature, use gcc vector extensions.\n\t(vreinterpret_p8_f64, vreinterpret_p16_f64, vreinterpret_f32_f64,\n\tvreinterpret_f64_f32, vreinterpret_f64_p8, vreinterpret_f64_p16,\n\tvreinterpret_f64_s8, vreinterpret_f64_s16, vreinterpret_f64_s32,\n\tvreinterpret_f64_s64, vreinterpret_f64_u8, vreinterpret_f64_u16,\n\tvreinterpret_f64_u32, vreinterpret_f64_u64, vreinterpret_s8_f64,\n\tvreinterpret_s16_f64, vreinterpret_s32_f64, vreinterpret_s64_f64,\n\tvreinterpret_u8_f64, vreinterpret_u16_f64, vreinterpret_u32_f64,\n\tvreinterpret_u64_f64): Use v1df builtin not df.\n\ngcc/testsuite/ChangeLog:\n\t* g++.dg/abi/mangle-neon-aarch64.C: Also test mangling of float64x1_t.\n\t* gcc.target/aarch64/aapcs/test_64x1_1.c: New test.\n\t* gcc.target/aarch64/aapcs/func-ret-64x1_1.c: New test.\n\t* gcc.target/aarch64/simd/ext_f64_1.c (main): Compare vector elements.\n\t* gcc.target/aarch64/vadd_f64.c: Rewrite with macro to use vector types.\n\t* gcc.target/aarch64/vsub_f64.c: Likewise.\n\t* gcc.target/aarch64/vdiv_f.c (INDEX*, RUN_TEST): Remove indexing scheme\n\tas now the same for all variants.\n\t* gcc.target/aarch64/vrnd_f64_1.c (compare_f64): Return float64_t not\n\tfloat64x1_t.\n\nFrom-SVN: r211892", "tree": {"sha": "976227fab2198e91de9912d569100cd8e8f82939", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/976227fab2198e91de9912d569100cd8e8f82939"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/comments", "author": null, "committer": null, "parents": [{"sha": "83387bbd28cd1d7e0c45a5e7f807713116ecb410", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/83387bbd28cd1d7e0c45a5e7f807713116ecb410", "html_url": "https://github.com/Rust-GCC/gccrs/commit/83387bbd28cd1d7e0c45a5e7f807713116ecb410"}], "stats": {"total": 557, "additions": 293, "deletions": 264}, "files": [{"sha": "5e30d1f4a91670ce43ad5c10c22312af75d25da2", "filename": "gcc/ChangeLog", "status": "modified", "additions": 40, "deletions": 0, "changes": 40, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -1,3 +1,43 @@\n+2014-06-19  Alan Lawrence  <alan.lawrence@arm.com>\n+\n+\tPR target/60825\n+\t* config/aarch64/aarch64.c (aarch64_simd_mangle_map): Add entry for\n+\tV1DFmode.\n+\t* config/aarch64/aarch64-builtins.c (aarch64_simd_builtin_type_mode):\n+\tadd V1DFmode\n+\t(BUILTIN_VD1): New.\n+\t(BUILTIN_VD_RE): Remove.\n+\t(aarch64_init_simd_builtins): Add V1DF to modes/modenames.\n+\t(aarch64_fold_builtin): Update reinterpret patterns, df becomes v1df.\n+\t* config/aarch64/aarch64-simd-builtins.def (create): Make a v1df\n+\tvariant but not df.\n+\t(vreinterpretv1df*, vreinterpret*v1df): New.\n+\t(vreinterpretdf*, vreinterpret*df): Remove.\n+\t* config/aarch64/aarch64-simd.md (aarch64_create, aarch64_reinterpret*):\n+\tGenerate V1DFmode pattern not DFmode.\n+\t* config/aarch64/iterators.md (VD_RE): Include V1DF, remove DF.\n+\t(VD1): New.\n+\t* config/aarch64/arm_neon.h (float64x1_t): typedef with gcc extensions.\n+\t(vcreate_f64): Remove cast, use v1df builtin.\n+\t(vcombine_f64): Remove cast, get elements with gcc vector extensions.\n+\t(vget_low_f64, vabs_f64, vceq_f64, vceqz_f64, vcge_f64, vgfez_f64,\n+\tvcgt_f64, vcgtz_f64, vcle_f64, vclez_f64, vclt_f64, vcltz_f64,\n+\tvdup_n_f64, vdupq_lane_f64, vld1_f64, vld2_f64, vld3_f64, vld4_f64,\n+\tvmov_n_f64, vst1_f64): Use gcc vector extensions.\n+\t(vget_lane_f64, vdupd_lane_f64, vmulq_lane_f64, ): Use gcc extensions,\n+\tadd range check using __builtin_aarch64_im_lane_boundsi.\n+\t(vfma_lane_f64, vfmad_lane_f64, vfma_laneq_f64, vfmaq_lane_f64,\n+\tvfms_lane_f64, vfmsd_lane_f64, vfms_laneq_f64, vfmsq_lane_f64): Fix\n+\ttype signature, use gcc vector extensions.\n+\t(vreinterpret_p8_f64, vreinterpret_p16_f64, vreinterpret_f32_f64,\n+\tvreinterpret_f64_f32, vreinterpret_f64_p8, vreinterpret_f64_p16,\n+\tvreinterpret_f64_s8, vreinterpret_f64_s16, vreinterpret_f64_s32,\n+\tvreinterpret_f64_s64, vreinterpret_f64_u8, vreinterpret_f64_u16,\n+\tvreinterpret_f64_u32, vreinterpret_f64_u64, vreinterpret_s8_f64,\n+\tvreinterpret_s16_f64, vreinterpret_s32_f64, vreinterpret_s64_f64,\n+\tvreinterpret_u8_f64, vreinterpret_u16_f64, vreinterpret_u32_f64,\n+\tvreinterpret_u64_f64): Use v1df builtin not df.\n+\n 2014-06-23  James Greenhalgh  <james.greenhalgh@arm.com>\n \n \t* config/aarch64/aarch64.md (*addsi3_aarch64): Add alternative in"}, {"sha": "eebb7d3978db193cca7077e27d13adfc3cdde7b2", "filename": "gcc/config/aarch64/aarch64-builtins.c", "status": "modified", "additions": 24, "deletions": 23, "changes": 47, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -53,6 +53,7 @@ enum aarch64_simd_builtin_type_mode\n   T_V4HI,\n   T_V2SI,\n   T_V2SF,\n+  T_V1DF,\n   T_DI,\n   T_DF,\n   T_V16QI,\n@@ -76,6 +77,7 @@ enum aarch64_simd_builtin_type_mode\n #define v4hi_UP  T_V4HI\n #define v2si_UP  T_V2SI\n #define v2sf_UP  T_V2SF\n+#define v1df_UP  T_V1DF\n #define di_UP    T_DI\n #define df_UP    T_DF\n #define v16qi_UP T_V16QI\n@@ -346,6 +348,8 @@ aarch64_types_storestruct_lane_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n   VAR2 (T, N, MAP, v8qi, v16qi)\n #define BUILTIN_VD(T, N, MAP) \\\n   VAR4 (T, N, MAP, v8qi, v4hi, v2si, v2sf)\n+#define BUILTIN_VD1(T, N, MAP) \\\n+  VAR5 (T, N, MAP, v8qi, v4hi, v2si, v2sf, v1df)\n #define BUILTIN_VDC(T, N, MAP) \\\n   VAR6 (T, N, MAP, v8qi, v4hi, v2si, v2sf, di, df)\n #define BUILTIN_VDIC(T, N, MAP) \\\n@@ -380,8 +384,6 @@ aarch64_types_storestruct_lane_qualifiers[SIMD_MAX_BUILTIN_ARGS]\n   VAR3 (T, N, MAP, v8qi, v4hi, v2si)\n #define BUILTIN_VD_HSI(T, N, MAP) \\\n   VAR2 (T, N, MAP, v4hi, v2si)\n-#define BUILTIN_VD_RE(T, N, MAP) \\\n-  VAR6 (T, N, MAP, v8qi, v4hi, v2si, v2sf, di, df)\n #define BUILTIN_VQ(T, N, MAP) \\\n   VAR6 (T, N, MAP, v16qi, v8hi, v4si, v2di, v4sf, v2df)\n #define BUILTIN_VQN(T, N, MAP) \\\n@@ -729,13 +731,13 @@ aarch64_init_simd_builtins (void)\n       aarch64_simd_builtin_datum *d = &aarch64_simd_builtin_data[i];\n       const char *const modenames[] =\n \t{\n-\t  \"v8qi\", \"v4hi\", \"v2si\", \"v2sf\", \"di\", \"df\",\n+\t  \"v8qi\", \"v4hi\", \"v2si\", \"v2sf\", \"v1df\", \"di\", \"df\",\n \t  \"v16qi\", \"v8hi\", \"v4si\", \"v4sf\", \"v2di\", \"v2df\",\n \t  \"ti\", \"ei\", \"oi\", \"xi\", \"si\", \"sf\", \"hi\", \"qi\"\n \t};\n       const enum machine_mode modes[] =\n \t{\n-\t  V8QImode, V4HImode, V2SImode, V2SFmode, DImode, DFmode,\n+\t  V8QImode, V4HImode, V2SImode, V2SFmode, V1DFmode, DImode, DFmode,\n \t  V16QImode, V8HImode, V4SImode, V4SFmode, V2DImode,\n \t  V2DFmode, TImode, EImode, OImode, XImode, SImode,\n \t  SFmode, HImode, QImode\n@@ -1342,24 +1344,23 @@ aarch64_fold_builtin (tree fndecl, int n_args ATTRIBUTE_UNUSED, tree *args,\n \t  return fold_build2 (NE_EXPR, type, and_node, vec_zero_node);\n \t  break;\n \t}\n-      VAR1 (REINTERP_SS, reinterpretdi, 0, df)\n-      VAR1 (REINTERP_SS, reinterpretv8qi, 0, df)\n-      VAR1 (REINTERP_SS, reinterpretv4hi, 0, df)\n-      VAR1 (REINTERP_SS, reinterpretv2si, 0, df)\n-      VAR1 (REINTERP_SS, reinterpretv2sf, 0, df)\n-      BUILTIN_VD (REINTERP_SS, reinterpretdf, 0)\n-      BUILTIN_VD (REINTERP_SU, reinterpretdf, 0)\n-      VAR1 (REINTERP_US, reinterpretdi, 0, df)\n-      VAR1 (REINTERP_US, reinterpretv8qi, 0, df)\n-      VAR1 (REINTERP_US, reinterpretv4hi, 0, df)\n-      VAR1 (REINTERP_US, reinterpretv2si, 0, df)\n-      VAR1 (REINTERP_US, reinterpretv2sf, 0, df)\n-      BUILTIN_VD (REINTERP_SP, reinterpretdf, 0)\n-      VAR1 (REINTERP_PS, reinterpretdi, 0, df)\n-      VAR1 (REINTERP_PS, reinterpretv8qi, 0, df)\n-      VAR1 (REINTERP_PS, reinterpretv4hi, 0, df)\n-      VAR1 (REINTERP_PS, reinterpretv2si, 0, df)\n-      VAR1 (REINTERP_PS, reinterpretv2sf, 0, df)\n+      VAR1 (REINTERP_SS, reinterpretdi, 0, v1df)\n+      VAR1 (REINTERP_SS, reinterpretv8qi, 0, v1df)\n+      VAR1 (REINTERP_SS, reinterpretv4hi, 0, v1df)\n+      VAR1 (REINTERP_SS, reinterpretv2si, 0, v1df)\n+      VAR1 (REINTERP_SS, reinterpretv2sf, 0, v1df)\n+      BUILTIN_VD (REINTERP_SS, reinterpretv1df, 0)\n+      BUILTIN_VD (REINTERP_SU, reinterpretv1df, 0)\n+      VAR1 (REINTERP_US, reinterpretdi, 0, v1df)\n+      VAR1 (REINTERP_US, reinterpretv8qi, 0, v1df)\n+      VAR1 (REINTERP_US, reinterpretv4hi, 0, v1df)\n+      VAR1 (REINTERP_US, reinterpretv2si, 0, v1df)\n+      VAR1 (REINTERP_US, reinterpretv2sf, 0, v1df)\n+      BUILTIN_VD (REINTERP_SP, reinterpretv1df, 0)\n+      VAR1 (REINTERP_PS, reinterpretdi, 0, v1df)\n+      VAR1 (REINTERP_PS, reinterpretv8qi, 0, v1df)\n+      VAR1 (REINTERP_PS, reinterpretv4hi, 0, v1df)\n+      VAR1 (REINTERP_PS, reinterpretv2sf, 0, v1df)\n \treturn fold_build1 (VIEW_CONVERT_EXPR, type, args[0]);\n       VAR1 (UNOP, floatv2si, 2, v2sf)\n       VAR1 (UNOP, floatv4si, 2, v4sf)\n@@ -1539,6 +1540,7 @@ aarch64_atomic_assign_expand_fenv (tree *hold, tree *clear, tree *update)\n #undef BUILTIN_VALL\n #undef BUILTIN_VB\n #undef BUILTIN_VD\n+#undef BUILTIN_VD1\n #undef BUILTIN_VDC\n #undef BUILTIN_VDIC\n #undef BUILTIN_VDN\n@@ -1554,7 +1556,6 @@ aarch64_atomic_assign_expand_fenv (tree *hold, tree *clear, tree *update)\n #undef BUILTIN_VDW\n #undef BUILTIN_VD_BHSI\n #undef BUILTIN_VD_HSI\n-#undef BUILTIN_VD_RE\n #undef BUILTIN_VQ\n #undef BUILTIN_VQN\n #undef BUILTIN_VQW"}, {"sha": "1b931bede943b8e8682064a0bb799f1d285c7301", "filename": "gcc/config/aarch64/aarch64-simd-builtins.def", "status": "modified", "additions": 19, "deletions": 19, "changes": 38, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -39,7 +39,7 @@\n    1-9 - CODE_FOR_<name><mode><1-9>\n    10 - CODE_FOR_<name><mode>.  */\n \n-  BUILTIN_VD_RE (CREATE, create, 0)\n+  BUILTIN_VD1 (CREATE, create, 0)\n   BUILTIN_VDC (COMBINE, combine, 0)\n   BUILTIN_VB (BINOP, pmul, 0)\n   BUILTIN_VDQF (UNOP, sqrt, 2)\n@@ -51,28 +51,28 @@\n   VAR1 (GETLANE, get_lane, 0, di)\n   BUILTIN_VALL (GETLANE, be_checked_get_lane, 0)\n \n-  VAR1 (REINTERP_SS, reinterpretdi, 0, df)\n-  VAR1 (REINTERP_SS, reinterpretv8qi, 0, df)\n-  VAR1 (REINTERP_SS, reinterpretv4hi, 0, df)\n-  VAR1 (REINTERP_SS, reinterpretv2si, 0, df)\n-  VAR1 (REINTERP_SS, reinterpretv2sf, 0, df)\n-  BUILTIN_VD (REINTERP_SS, reinterpretdf, 0)\n+  VAR1 (REINTERP_SS, reinterpretdi, 0, v1df)\n+  VAR1 (REINTERP_SS, reinterpretv8qi, 0, v1df)\n+  VAR1 (REINTERP_SS, reinterpretv4hi, 0, v1df)\n+  VAR1 (REINTERP_SS, reinterpretv2si, 0, v1df)\n+  VAR1 (REINTERP_SS, reinterpretv2sf, 0, v1df)\n+  BUILTIN_VD (REINTERP_SS, reinterpretv1df, 0)\n \n-  BUILTIN_VD (REINTERP_SU, reinterpretdf, 0)\n+  BUILTIN_VD (REINTERP_SU, reinterpretv1df, 0)\n \n-  VAR1 (REINTERP_US, reinterpretdi, 0, df)\n-  VAR1 (REINTERP_US, reinterpretv8qi, 0, df)\n-  VAR1 (REINTERP_US, reinterpretv4hi, 0, df)\n-  VAR1 (REINTERP_US, reinterpretv2si, 0, df)\n-  VAR1 (REINTERP_US, reinterpretv2sf, 0, df)\n+  VAR1 (REINTERP_US, reinterpretdi, 0, v1df)\n+  VAR1 (REINTERP_US, reinterpretv8qi, 0, v1df)\n+  VAR1 (REINTERP_US, reinterpretv4hi, 0, v1df)\n+  VAR1 (REINTERP_US, reinterpretv2si, 0, v1df)\n+  VAR1 (REINTERP_US, reinterpretv2sf, 0, v1df)\n \n-  BUILTIN_VD (REINTERP_SP, reinterpretdf, 0)\n+  BUILTIN_VD (REINTERP_SP, reinterpretv1df, 0)\n \n-  VAR1 (REINTERP_PS, reinterpretdi, 0, df)\n-  VAR1 (REINTERP_PS, reinterpretv8qi, 0, df)\n-  VAR1 (REINTERP_PS, reinterpretv4hi, 0, df)\n-  VAR1 (REINTERP_PS, reinterpretv2si, 0, df)\n-  VAR1 (REINTERP_PS, reinterpretv2sf, 0, df)\n+  VAR1 (REINTERP_PS, reinterpretdi, 0, v1df)\n+  VAR1 (REINTERP_PS, reinterpretv8qi, 0, v1df)\n+  VAR1 (REINTERP_PS, reinterpretv4hi, 0, v1df)\n+  VAR1 (REINTERP_PS, reinterpretv2si, 0, v1df)\n+  VAR1 (REINTERP_PS, reinterpretv2sf, 0, v1df)\n \n   BUILTIN_VDQ_I (BINOP, dup_lane, 0)\n   /* Implemented by aarch64_<sur>q<r>shl<mode>.  */"}, {"sha": "1c32f0c4efa0e9b8e8bc06af726798f6aaecf39f", "filename": "gcc/config/aarch64/aarch64-simd.md", "status": "modified", "additions": 7, "deletions": 7, "changes": 14, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd.md?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -2134,7 +2134,7 @@\n ;; Patterns for AArch64 SIMD Intrinsics.\n \n (define_expand \"aarch64_create<mode>\"\n-  [(match_operand:VD_RE 0 \"register_operand\" \"\")\n+  [(match_operand:VD1 0 \"register_operand\" \"\")\n    (match_operand:DI 1 \"general_operand\" \"\")]\n   \"TARGET_SIMD\"\n {\n@@ -2224,7 +2224,7 @@\n \n (define_expand \"aarch64_reinterpretv8qi<mode>\"\n   [(match_operand:V8QI 0 \"register_operand\" \"\")\n-   (match_operand:VDC 1 \"register_operand\" \"\")]\n+   (match_operand:VD_RE 1 \"register_operand\" \"\")]\n   \"TARGET_SIMD\"\n {\n   aarch64_simd_reinterpret (operands[0], operands[1]);\n@@ -2233,7 +2233,7 @@\n \n (define_expand \"aarch64_reinterpretv4hi<mode>\"\n   [(match_operand:V4HI 0 \"register_operand\" \"\")\n-   (match_operand:VDC 1 \"register_operand\" \"\")]\n+   (match_operand:VD_RE 1 \"register_operand\" \"\")]\n   \"TARGET_SIMD\"\n {\n   aarch64_simd_reinterpret (operands[0], operands[1]);\n@@ -2242,7 +2242,7 @@\n \n (define_expand \"aarch64_reinterpretv2si<mode>\"\n   [(match_operand:V2SI 0 \"register_operand\" \"\")\n-   (match_operand:VDC 1 \"register_operand\" \"\")]\n+   (match_operand:VD_RE 1 \"register_operand\" \"\")]\n   \"TARGET_SIMD\"\n {\n   aarch64_simd_reinterpret (operands[0], operands[1]);\n@@ -2251,7 +2251,7 @@\n \n (define_expand \"aarch64_reinterpretv2sf<mode>\"\n   [(match_operand:V2SF 0 \"register_operand\" \"\")\n-   (match_operand:VDC 1 \"register_operand\" \"\")]\n+   (match_operand:VD_RE 1 \"register_operand\" \"\")]\n   \"TARGET_SIMD\"\n {\n   aarch64_simd_reinterpret (operands[0], operands[1]);\n@@ -2267,8 +2267,8 @@\n   DONE;\n })\n \n-(define_expand \"aarch64_reinterpretdf<mode>\"\n-  [(match_operand:DF 0 \"register_operand\" \"\")\n+(define_expand \"aarch64_reinterpretv1df<mode>\"\n+  [(match_operand:V1DF 0 \"register_operand\" \"\")\n    (match_operand:VD_RE 1 \"register_operand\" \"\")]\n   \"TARGET_SIMD\"\n {"}, {"sha": "1d631f8f6bc4d8e04ef914715c31daa0703d7692", "filename": "gcc/config/aarch64/aarch64.c", "status": "modified", "additions": 1, "deletions": 0, "changes": 1, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Fconfig%2Faarch64%2Faarch64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Fconfig%2Faarch64%2Faarch64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64.c?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -7358,6 +7358,7 @@ static aarch64_simd_mangle_map_entry aarch64_simd_mangle_map[] = {\n   { V2SImode,  \"__builtin_aarch64_simd_si\",     \"11__Int32x2_t\" },\n   { V2SImode,  \"__builtin_aarch64_simd_usi\",    \"12__Uint32x2_t\" },\n   { V2SFmode,  \"__builtin_aarch64_simd_sf\",     \"13__Float32x2_t\" },\n+  { V1DFmode,  \"__builtin_aarch64_simd_df\",\t\"13__Float64x1_t\" },\n   { V8QImode,  \"__builtin_aarch64_simd_poly8\",  \"11__Poly8x8_t\" },\n   { V4HImode,  \"__builtin_aarch64_simd_poly16\", \"12__Poly16x4_t\" },\n   /* 128-bit containerized types.  */"}, {"sha": "701e8c14834ee5e5afe25b8b441216d05f3b37c3", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 90, "deletions": 79, "changes": 169, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -42,7 +42,8 @@ typedef int64_t int64x1_t;\n typedef int32_t int32x1_t;\n typedef int16_t int16x1_t;\n typedef int8_t int8x1_t;\n-typedef double float64x1_t;\n+typedef __builtin_aarch64_simd_df float64x1_t\n+  __attribute__ ((__vector_size__ (8)));\n typedef __builtin_aarch64_simd_sf float32x2_t\n   __attribute__ ((__vector_size__ (8)));\n typedef __builtin_aarch64_simd_poly8 poly8x8_t\n@@ -461,7 +462,11 @@ typedef struct poly16x8x4_t\n \n #define __aarch64_vget_lane_f32(__a, __b) \\\n   __aarch64_vget_lane_any (v2sf, , , __a, __b)\n-#define __aarch64_vget_lane_f64(__a, __b) (__a)\n+#define __aarch64_vget_lane_f64(__a, __b) __extension__\t\\\n+  ({\t\t\t\t\t\t\t\\\n+    __builtin_aarch64_im_lane_boundsi (__b, 1);\t\t\\\n+    __a[0];\t\t\t\t\t\t\\\n+  })\n \n #define __aarch64_vget_lane_p8(__a, __b) \\\n   __aarch64_vget_lane_any (v8qi, (poly8_t), (int8x8_t), __a, __b)\n@@ -518,7 +523,8 @@ typedef struct poly16x8x4_t\n \n #define __aarch64_vdup_lane_f32(__a, __b) \\\n    __aarch64_vdup_lane_any (f32, , , __a, __b)\n-#define __aarch64_vdup_lane_f64(__a, __b) (__a)\n+#define __aarch64_vdup_lane_f64(__a, __b) \\\n+   __aarch64_vdup_lane_any (f64, , , __a, __b)\n #define __aarch64_vdup_lane_p8(__a, __b) \\\n    __aarch64_vdup_lane_any (p8, , , __a, __b)\n #define __aarch64_vdup_lane_p16(__a, __b) \\\n@@ -567,7 +573,8 @@ typedef struct poly16x8x4_t\n /* __aarch64_vdupq_lane internal macros.  */\n #define __aarch64_vdupq_lane_f32(__a, __b) \\\n    __aarch64_vdup_lane_any (f32, q, , __a, __b)\n-#define __aarch64_vdupq_lane_f64(__a, __b) (vdupq_n_f64 (__a))\n+#define __aarch64_vdupq_lane_f64(__a, __b) \\\n+   __aarch64_vdup_lane_any (f64, q, , __a, __b)\n #define __aarch64_vdupq_lane_p8(__a, __b) \\\n    __aarch64_vdup_lane_any (p8, q, , __a, __b)\n #define __aarch64_vdupq_lane_p16(__a, __b) \\\n@@ -2475,7 +2482,7 @@ vcreate_u64 (uint64_t __a)\n __extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n vcreate_f64 (uint64_t __a)\n {\n-  return (float64x1_t) __builtin_aarch64_createdf (__a);\n+  return __builtin_aarch64_createv1df (__a);\n }\n \n __extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n@@ -2643,7 +2650,7 @@ vgetq_lane_u64 (uint64x2_t __a, const int __b)\n __extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n vreinterpret_p8_f64 (float64x1_t __a)\n {\n-  return __builtin_aarch64_reinterpretv8qidf_ps (__a);\n+  return __builtin_aarch64_reinterpretv8qiv1df_ps (__a);\n }\n \n __extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n@@ -2775,7 +2782,7 @@ vreinterpretq_p8_p16 (poly16x8_t __a)\n __extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n vreinterpret_p16_f64 (float64x1_t __a)\n {\n-  return __builtin_aarch64_reinterpretv4hidf_ps (__a);\n+  return __builtin_aarch64_reinterpretv4hiv1df_ps (__a);\n }\n \n __extension__ static __inline poly16x4_t __attribute__ ((__always_inline__))\n@@ -2907,7 +2914,7 @@ vreinterpretq_p16_p8 (poly8x16_t __a)\n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n vreinterpret_f32_f64 (float64x1_t __a)\n {\n-  return __builtin_aarch64_reinterpretv2sfdf (__a);\n+  return __builtin_aarch64_reinterpretv2sfv1df (__a);\n }\n \n __extension__ static __inline float32x2_t __attribute__ ((__always_inline__))\n@@ -3039,67 +3046,67 @@ vreinterpretq_f32_p16 (poly16x8_t __a)\n __extension__ static __inline float64x1_t __attribute__((__always_inline__))\n vreinterpret_f64_f32 (float32x2_t __a)\n {\n-  return __builtin_aarch64_reinterpretdfv2sf (__a);\n+  return __builtin_aarch64_reinterpretv1dfv2sf (__a);\n }\n \n __extension__ static __inline float64x1_t __attribute__((__always_inline__))\n vreinterpret_f64_p8 (poly8x8_t __a)\n {\n-  return __builtin_aarch64_reinterpretdfv8qi_sp (__a);\n+  return __builtin_aarch64_reinterpretv1dfv8qi_sp (__a);\n }\n \n __extension__ static __inline float64x1_t __attribute__((__always_inline__))\n vreinterpret_f64_p16 (poly16x4_t __a)\n {\n-  return __builtin_aarch64_reinterpretdfv4hi_sp (__a);\n+  return __builtin_aarch64_reinterpretv1dfv4hi_sp (__a);\n }\n \n __extension__ static __inline float64x1_t __attribute__((__always_inline__))\n vreinterpret_f64_s8 (int8x8_t __a)\n {\n-  return __builtin_aarch64_reinterpretdfv8qi (__a);\n+  return __builtin_aarch64_reinterpretv1dfv8qi (__a);\n }\n \n __extension__ static __inline float64x1_t __attribute__((__always_inline__))\n vreinterpret_f64_s16 (int16x4_t __a)\n {\n-  return __builtin_aarch64_reinterpretdfv4hi (__a);\n+  return __builtin_aarch64_reinterpretv1dfv4hi (__a);\n }\n \n __extension__ static __inline float64x1_t __attribute__((__always_inline__))\n vreinterpret_f64_s32 (int32x2_t __a)\n {\n-  return __builtin_aarch64_reinterpretdfv2si (__a);\n+  return __builtin_aarch64_reinterpretv1dfv2si (__a);\n }\n \n __extension__ static __inline float64x1_t __attribute__((__always_inline__))\n vreinterpret_f64_s64 (int64x1_t __a)\n {\n-  return __builtin_aarch64_createdf ((uint64_t) vget_lane_s64 (__a, 0));\n+  return __builtin_aarch64_createv1df ((uint64_t) vget_lane_s64 (__a, 0));\n }\n \n __extension__ static __inline float64x1_t __attribute__((__always_inline__))\n vreinterpret_f64_u8 (uint8x8_t __a)\n {\n-  return __builtin_aarch64_reinterpretdfv8qi_su (__a);\n+  return __builtin_aarch64_reinterpretv1dfv8qi_su (__a);\n }\n \n __extension__ static __inline float64x1_t __attribute__((__always_inline__))\n vreinterpret_f64_u16 (uint16x4_t __a)\n {\n-  return __builtin_aarch64_reinterpretdfv4hi_su (__a);\n+  return __builtin_aarch64_reinterpretv1dfv4hi_su (__a);\n }\n \n __extension__ static __inline float64x1_t __attribute__((__always_inline__))\n vreinterpret_f64_u32 (uint32x2_t __a)\n {\n-  return __builtin_aarch64_reinterpretdfv2si_su (__a);\n+  return __builtin_aarch64_reinterpretv1dfv2si_su (__a);\n }\n \n __extension__ static __inline float64x1_t __attribute__((__always_inline__))\n vreinterpret_f64_u64 (uint64x1_t __a)\n {\n-  return __builtin_aarch64_createdf (vget_lane_u64 (__a, 0));\n+  return __builtin_aarch64_createv1df (vget_lane_u64 (__a, 0));\n }\n \n __extension__ static __inline float64x2_t __attribute__((__always_inline__))\n@@ -3171,7 +3178,7 @@ vreinterpretq_f64_u64 (uint64x2_t __a)\n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n vreinterpret_s64_f64 (float64x1_t __a)\n {\n-  return __builtin_aarch64_reinterpretdidf (__a);\n+  return __builtin_aarch64_reinterpretdiv1df (__a);\n }\n \n __extension__ static __inline int64x1_t __attribute__ ((__always_inline__))\n@@ -3303,7 +3310,7 @@ vreinterpretq_s64_p16 (poly16x8_t __a)\n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vreinterpret_u64_f64 (float64x1_t __a)\n {\n-  return __builtin_aarch64_reinterpretdidf_us (__a);\n+  return __builtin_aarch64_reinterpretdiv1df_us (__a);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -3435,7 +3442,7 @@ vreinterpretq_u64_p16 (poly16x8_t __a)\n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n vreinterpret_s8_f64 (float64x1_t __a)\n {\n-  return __builtin_aarch64_reinterpretv8qidf (__a);\n+  return __builtin_aarch64_reinterpretv8qiv1df (__a);\n }\n \n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n@@ -3567,7 +3574,7 @@ vreinterpretq_s8_p16 (poly16x8_t __a)\n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n vreinterpret_s16_f64 (float64x1_t __a)\n {\n-  return __builtin_aarch64_reinterpretv4hidf (__a);\n+  return __builtin_aarch64_reinterpretv4hiv1df (__a);\n }\n \n __extension__ static __inline int16x4_t __attribute__ ((__always_inline__))\n@@ -3699,7 +3706,7 @@ vreinterpretq_s16_p16 (poly16x8_t __a)\n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n vreinterpret_s32_f64 (float64x1_t __a)\n {\n-  return __builtin_aarch64_reinterpretv2sidf (__a);\n+  return __builtin_aarch64_reinterpretv2siv1df (__a);\n }\n \n __extension__ static __inline int32x2_t __attribute__ ((__always_inline__))\n@@ -3831,7 +3838,7 @@ vreinterpretq_s32_p16 (poly16x8_t __a)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vreinterpret_u8_f64 (float64x1_t __a)\n {\n-  return __builtin_aarch64_reinterpretv8qidf_us (__a);\n+  return __builtin_aarch64_reinterpretv8qiv1df_us (__a);\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n@@ -3963,7 +3970,7 @@ vreinterpretq_u8_p16 (poly16x8_t __a)\n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vreinterpret_u16_f64 (float64x1_t __a)\n {\n-  return __builtin_aarch64_reinterpretv4hidf_us (__a);\n+  return __builtin_aarch64_reinterpretv4hiv1df_us (__a);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n@@ -4095,7 +4102,7 @@ vreinterpretq_u16_p16 (poly16x8_t __a)\n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vreinterpret_u32_f64 (float64x1_t __a)\n {\n-  return __builtin_aarch64_reinterpretv2sidf_us (__a);\n+  return __builtin_aarch64_reinterpretv2siv1df_us (__a);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n@@ -4238,7 +4245,7 @@ vget_low_f32 (float32x4_t __a)\n __extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n vget_low_f64 (float64x2_t __a)\n {\n-  return vgetq_lane_f64 (__a, 0);\n+  return (float64x1_t) {vgetq_lane_f64 (__a, 0)};\n }\n \n __extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n@@ -4364,7 +4371,7 @@ vcombine_u64 (uint64x1_t __a, uint64x1_t __b)\n __extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n vcombine_f64 (float64x1_t __a, float64x1_t __b)\n {\n-  return (float64x2_t) __builtin_aarch64_combinedf (__a, __b);\n+  return __builtin_aarch64_combinedf (__a[0], __b[0]);\n }\n \n __extension__ static __inline poly8x16_t __attribute__ ((__always_inline__))\n@@ -13432,7 +13439,7 @@ vabs_f32 (float32x2_t __a)\n __extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n vabs_f64 (float64x1_t __a)\n {\n-  return __builtin_fabs (__a);\n+  return (float64x1_t) {__builtin_fabs (__a[0])};\n }\n \n __extension__ static __inline int8x8_t __attribute__ ((__always_inline__))\n@@ -13916,7 +13923,7 @@ vceq_f32 (float32x2_t __a, float32x2_t __b)\n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vceq_f64 (float64x1_t __a, float64x1_t __b)\n {\n-  return __a == __b ? -1ll : 0ll;\n+  return (uint64x1_t) (__a == __b);\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n@@ -14086,7 +14093,7 @@ vceqz_f32 (float32x2_t __a)\n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vceqz_f64 (float64x1_t __a)\n {\n-  return __a == 0.0 ? -1ll : 0ll;\n+  return (uint64x1_t) (__a == (float64x1_t) {0.0});\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n@@ -14276,7 +14283,7 @@ vcge_f32 (float32x2_t __a, float32x2_t __b)\n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vcge_f64 (float64x1_t __a, float64x1_t __b)\n {\n-  return __a >= __b ? -1ll : 0ll;\n+  return (uint64x1_t) (__a >= __b);\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n@@ -14432,7 +14439,7 @@ vcgez_f32 (float32x2_t __a)\n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vcgez_f64 (float64x1_t __a)\n {\n-  return __a >= 0.0 ? -1ll : 0ll;\n+  return (uint64x1_t) (__a[0] >= (float64x1_t) {0.0});\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n@@ -14536,7 +14543,7 @@ vcgt_f32 (float32x2_t __a, float32x2_t __b)\n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vcgt_f64 (float64x1_t __a, float64x1_t __b)\n {\n-  return __a > __b ? -1ll : 0ll;\n+  return (uint64x1_t) (__a > __b);\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n@@ -14692,7 +14699,7 @@ vcgtz_f32 (float32x2_t __a)\n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vcgtz_f64 (float64x1_t __a)\n {\n-  return __a > 0.0 ? -1ll : 0ll;\n+  return (uint64x1_t) (__a > (float64x1_t) {0.0});\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n@@ -14796,7 +14803,7 @@ vcle_f32 (float32x2_t __a, float32x2_t __b)\n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vcle_f64 (float64x1_t __a, float64x1_t __b)\n {\n-  return __a <= __b ? -1ll : 0ll;\n+  return (uint64x1_t) (__a <= __b);\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n@@ -14952,7 +14959,7 @@ vclez_f32 (float32x2_t __a)\n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vclez_f64 (float64x1_t __a)\n {\n-  return __a <= 0.0 ? -1ll : 0ll;\n+  return (uint64x1_t) (__a <= (float64x1_t) {0.0});\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n@@ -15056,7 +15063,7 @@ vclt_f32 (float32x2_t __a, float32x2_t __b)\n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vclt_f64 (float64x1_t __a, float64x1_t __b)\n {\n-  return __a < __b ? -1ll : 0ll;\n+  return (uint64x1_t) (__a < __b);\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n@@ -15212,7 +15219,7 @@ vcltz_f32 (float32x2_t __a)\n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n vcltz_f64 (float64x1_t __a)\n {\n-  return __a < 0.0 ? -1ll : 0ll;\n+  return (uint64x1_t) (__a < (float64x1_t) {0.0});\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n@@ -15821,7 +15828,7 @@ vdup_n_f32 (float32_t __a)\n __extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n vdup_n_f64 (float64_t __a)\n {\n-  return __a;\n+  return (float64x1_t) {__a};\n }\n \n __extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n@@ -16314,9 +16321,10 @@ vdups_lane_u32 (uint32x2_t __a, const int __b)\n \n /* vdupd_lane  */\n __extension__ static __inline float64_t __attribute__ ((__always_inline__))\n-vdupd_lane_f64 (float64x1_t __a, const int __attribute__ ((unused)) __b)\n+vdupd_lane_f64 (float64x1_t __a, const int __b)\n {\n-  return __a;\n+  __builtin_aarch64_im_lane_boundsi (__b, 1);\n+  return __a[0];\n }\n \n __extension__ static __inline int64_t __attribute__ ((__always_inline__))\n@@ -16704,18 +16712,18 @@ vfma_lane_f32 (float32x2_t __a, float32x2_t __b,\n \t\t\t\t    __a);\n }\n \n-__extension__ static __inline float64_t __attribute__ ((__always_inline__))\n-vfma_lane_f64 (float64_t __a, float64_t __b,\n-\t       float64_t __c, const int __lane)\n+__extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n+vfma_lane_f64 (float64x1_t __a, float64x1_t __b,\n+\t       float64x1_t __c, const int __lane)\n {\n-  return __builtin_fma (__b, __c, __a);\n+  return (float64x1_t) {__builtin_fma (__b[0], __c[0], __a[0])};\n }\n \n __extension__ static __inline float64_t __attribute__ ((__always_inline__))\n vfmad_lane_f64 (float64_t __a, float64_t __b,\n-\t        float64_t __c, const int __lane)\n+\t        float64x1_t __c, const int __lane)\n {\n-  return __builtin_fma (__b, __c, __a);\n+  return __builtin_fma (__b, __c[0], __a);\n }\n \n __extension__ static __inline float32_t __attribute__ ((__always_inline__))\n@@ -16736,11 +16744,12 @@ vfma_laneq_f32 (float32x2_t __a, float32x2_t __b,\n \t\t\t\t    __a);\n }\n \n-__extension__ static __inline float64_t __attribute__ ((__always_inline__))\n-vfma_laneq_f64 (float64_t __a, float64_t __b,\n+__extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n+vfma_laneq_f64 (float64x1_t __a, float64x1_t __b,\n \t        float64x2_t __c, const int __lane)\n {\n-  return __builtin_fma (__b, __aarch64_vgetq_lane_f64 (__c, __lane), __a);\n+  float64_t __c0 = __aarch64_vgetq_lane_f64 (__c, __lane);\n+  return (float64x1_t) {__builtin_fma (__b[0], __c0, __a[0])};\n }\n \n __extension__ static __inline float64_t __attribute__ ((__always_inline__))\n@@ -16770,9 +16779,9 @@ vfmaq_lane_f32 (float32x4_t __a, float32x4_t __b,\n \n __extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n vfmaq_lane_f64 (float64x2_t __a, float64x2_t __b,\n-\t        float64_t __c, const int __lane)\n+\t        float64x1_t __c, const int __lane)\n {\n-  return __builtin_aarch64_fmav2df (__b, vdupq_n_f64 (__c), __a);\n+  return __builtin_aarch64_fmav2df (__b, vdupq_n_f64 (__c[0]), __a);\n }\n \n /* vfmaq_laneq  */\n@@ -16806,18 +16815,18 @@ vfms_lane_f32 (float32x2_t __a, float32x2_t __b,\n \t\t\t\t    __a);\n }\n \n-__extension__ static __inline float64_t __attribute__ ((__always_inline__))\n-vfms_lane_f64 (float64_t __a, float64_t __b,\n-\t       float64_t __c, const int __lane)\n+__extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n+vfms_lane_f64 (float64x1_t __a, float64x1_t __b,\n+\t       float64x1_t __c, const int __lane)\n {\n-  return __builtin_fma (-__b, __c, __a);\n+  return (float64x1_t) {__builtin_fma (-__b[0], __c[0], __a[0])};\n }\n \n __extension__ static __inline float64_t __attribute__ ((__always_inline__))\n vfmsd_lane_f64 (float64_t __a, float64_t __b,\n-\t        float64_t __c, const int __lane)\n+\t        float64x1_t __c, const int __lane)\n {\n-  return __builtin_fma (-__b, __c, __a);\n+  return __builtin_fma (-__b, __c[0], __a);\n }\n \n __extension__ static __inline float32_t __attribute__ ((__always_inline__))\n@@ -16838,11 +16847,12 @@ vfms_laneq_f32 (float32x2_t __a, float32x2_t __b,\n \t\t\t\t    __a);\n }\n \n-__extension__ static __inline float64_t __attribute__ ((__always_inline__))\n-vfms_laneq_f64 (float64_t __a, float64_t __b,\n+__extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n+vfms_laneq_f64 (float64x1_t __a, float64x1_t __b,\n \t        float64x2_t __c, const int __lane)\n {\n-  return __builtin_fma (-__b, __aarch64_vgetq_lane_f64 (__c, __lane), __a);\n+  float64_t __c0 = __aarch64_vgetq_lane_f64 (__c, __lane);\n+  return (float64x1_t) {__builtin_fma (-__b[0], __c0, __a[0])};\n }\n \n __extension__ static __inline float64_t __attribute__ ((__always_inline__))\n@@ -16872,9 +16882,9 @@ vfmsq_lane_f32 (float32x4_t __a, float32x4_t __b,\n \n __extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n vfmsq_lane_f64 (float64x2_t __a, float64x2_t __b,\n-\t        float64_t __c, const int __lane)\n+\t        float64x1_t __c, const int __lane)\n {\n-  return __builtin_aarch64_fmav2df (-__b, vdupq_n_f64 (__c), __a);\n+  return __builtin_aarch64_fmav2df (-__b, vdupq_n_f64 (__c[0]), __a);\n }\n \n /* vfmsq_laneq  */\n@@ -16908,7 +16918,7 @@ vld1_f32 (const float32_t *a)\n __extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n vld1_f64 (const float64_t *a)\n {\n-  return *a;\n+  return (float64x1_t) {*a};\n }\n \n __extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n@@ -17086,8 +17096,8 @@ vld2_f64 (const float64_t * __a)\n   float64x1x2_t ret;\n   __builtin_aarch64_simd_oi __o;\n   __o = __builtin_aarch64_ld2df ((const __builtin_aarch64_simd_df *) __a);\n-  ret.val[0] = (float64x1_t) __builtin_aarch64_get_dregoidf (__o, 0);\n-  ret.val[1] = (float64x1_t) __builtin_aarch64_get_dregoidf (__o, 1);\n+  ret.val[0] = (float64x1_t) {__builtin_aarch64_get_dregoidf (__o, 0)};\n+  ret.val[1] = (float64x1_t) {__builtin_aarch64_get_dregoidf (__o, 1)};\n   return ret;\n }\n \n@@ -17352,9 +17362,9 @@ vld3_f64 (const float64_t * __a)\n   float64x1x3_t ret;\n   __builtin_aarch64_simd_ci __o;\n   __o = __builtin_aarch64_ld3df ((const __builtin_aarch64_simd_df *) __a);\n-  ret.val[0] = (float64x1_t) __builtin_aarch64_get_dregcidf (__o, 0);\n-  ret.val[1] = (float64x1_t) __builtin_aarch64_get_dregcidf (__o, 1);\n-  ret.val[2] = (float64x1_t) __builtin_aarch64_get_dregcidf (__o, 2);\n+  ret.val[0] = (float64x1_t) {__builtin_aarch64_get_dregcidf (__o, 0)};\n+  ret.val[1] = (float64x1_t) {__builtin_aarch64_get_dregcidf (__o, 1)};\n+  ret.val[2] = (float64x1_t) {__builtin_aarch64_get_dregcidf (__o, 2)};\n   return ret;\n }\n \n@@ -17642,10 +17652,10 @@ vld4_f64 (const float64_t * __a)\n   float64x1x4_t ret;\n   __builtin_aarch64_simd_xi __o;\n   __o = __builtin_aarch64_ld4df ((const __builtin_aarch64_simd_df *) __a);\n-  ret.val[0] = (float64x1_t) __builtin_aarch64_get_dregxidf (__o, 0);\n-  ret.val[1] = (float64x1_t) __builtin_aarch64_get_dregxidf (__o, 1);\n-  ret.val[2] = (float64x1_t) __builtin_aarch64_get_dregxidf (__o, 2);\n-  ret.val[3] = (float64x1_t) __builtin_aarch64_get_dregxidf (__o, 3);\n+  ret.val[0] = (float64x1_t) {__builtin_aarch64_get_dregxidf (__o, 0)};\n+  ret.val[1] = (float64x1_t) {__builtin_aarch64_get_dregxidf (__o, 1)};\n+  ret.val[2] = (float64x1_t) {__builtin_aarch64_get_dregxidf (__o, 2)};\n+  ret.val[3] = (float64x1_t) {__builtin_aarch64_get_dregxidf (__o, 3)};\n   return ret;\n }\n \n@@ -18760,7 +18770,7 @@ vmov_n_f32 (float32_t __a)\n __extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n vmov_n_f64 (float64_t __a)\n {\n-  return __a;\n+  return (float64x1_t) {__a};\n }\n \n __extension__ static __inline poly8x8_t __attribute__ ((__always_inline__))\n@@ -18982,7 +18992,8 @@ vmulq_lane_f32 (float32x4_t __a, float32x2_t __b, const int __lane)\n __extension__ static __inline float64x2_t __attribute__ ((__always_inline__))\n vmulq_lane_f64 (float64x2_t __a, float64x1_t __b, const int __lane)\n {\n-  return __a * __b;\n+  __builtin_aarch64_im_lane_boundsi (__lane, 1);\n+  return __a * __b[0];\n }\n \n __extension__ static __inline int16x8_t __attribute__ ((__always_inline__))\n@@ -21028,7 +21039,7 @@ vrndn_f32 (float32x2_t __a)\n __extension__ static __inline float64x1_t __attribute__ ((__always_inline__))\n vrndn_f64 (float64x1_t __a)\n {\n-  return __builtin_aarch64_frintndf (__a);\n+  return (float64x1_t) {__builtin_aarch64_frintndf (__a[0])};\n }\n \n __extension__ static __inline float32x4_t __attribute__ ((__always_inline__))\n@@ -22336,7 +22347,7 @@ vst1_f32 (float32_t *a, float32x2_t b)\n __extension__ static __inline void __attribute__ ((__always_inline__))\n vst1_f64 (float64_t *a, float64x1_t b)\n {\n-  *a = b;\n+  *a = b[0];\n }\n \n __extension__ static __inline void __attribute__ ((__always_inline__))"}, {"sha": "3203c3da7e293d566d1ea329856cbef8fb73a825", "filename": "gcc/config/aarch64/iterators.md", "status": "modified", "additions": 5, "deletions": 2, "changes": 7, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Fconfig%2Faarch64%2Fiterators.md", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Fconfig%2Faarch64%2Fiterators.md", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Fiterators.md?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -138,8 +138,11 @@\n ;; Double vector modes for combines.\n (define_mode_iterator VDIC [V8QI V4HI V2SI])\n \n-;; Double vector modes.\n-(define_mode_iterator VD_RE [V8QI V4HI V2SI DI DF V2SF])\n+;; Double vector modes, inc. V1DF and the DI \"vector\" mode, for VREINTERPRET.\n+(define_mode_iterator VD_RE [V8QI V4HI V2SI DI V1DF V2SF])\n+\n+;; Double vector modes inc V1DF\n+(define_mode_iterator VD1 [V8QI V4HI V2SI V2SF V1DF])\n \n ;; Vector modes except double int.\n (define_mode_iterator VDQIF [V8QI V16QI V4HI V8HI V2SI V4SI V2SF V4SF V2DF])"}, {"sha": "837bb0e46584c61d936b94801199af7848f844c6", "filename": "gcc/testsuite/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2FChangeLog?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -1,3 +1,16 @@\n+2014-06-19  Alan Lawrence  <alan.lawrence@arm.com>\n+\n+\t* g++.dg/abi/mangle-neon-aarch64.C: Also test mangling of float64x1_t.\n+\t* gcc.target/aarch64/aapcs/test_64x1_1.c: New test.\n+\t* gcc.target/aarch64/aapcs/func-ret-64x1_1.c: New test.\n+\t* gcc.target/aarch64/simd/ext_f64_1.c (main): Compare vector elements.\n+\t* gcc.target/aarch64/vadd_f64.c: Rewrite with macro to use vector types.\n+\t* gcc.target/aarch64/vsub_f64.c: Likewise.\n+\t* gcc.target/aarch64/vdiv_f.c (INDEX*, RUN_TEST): Remove indexing scheme\n+\tas now the same for all variants.\n+\t* gcc.target/aarch64/vrnd_f64_1.c (compare_f64): Return float64_t not\n+\tfloat64x1_t.\n+\n 2014-06-23  James Greenhalgh  <james.greenhalgh@arm.com>\n \n \t* gcc.target/aarch64/scalar_shift_1.c: Fix expected assembler."}, {"sha": "025b6904afa9f4ea39550ecd95d91a7be1d48cc6", "filename": "gcc/testsuite/g++.dg/abi/mangle-neon-aarch64.C", "status": "modified", "additions": 4, "deletions": 2, "changes": 6, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fabi%2Fmangle-neon-aarch64.C", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fabi%2Fmangle-neon-aarch64.C", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fg%2B%2B.dg%2Fabi%2Fmangle-neon-aarch64.C?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -27,8 +27,9 @@ void f17 (float32x4_t a) {}\n void f18 (float64x2_t a) {}\n void f19 (poly8x16_t a) {}\n void f20 (poly16x8_t a) {}\n+void f21 (float64x1_t a) {}\n \n-void f21 (int8x16_t, int8x16_t) {}\n+void g1 (int8x16_t, int8x16_t) {}\n \n \n // { dg-final { scan-assembler \"_Z2f010__Int8x8_t:\" } }\n@@ -52,4 +53,5 @@ void f21 (int8x16_t, int8x16_t) {}\n // { dg-final { scan-assembler \"_Z3f1813__Float64x2_t:\" } }\n // { dg-final { scan-assembler \"_Z3f1912__Poly8x16_t:\" } }\n // { dg-final { scan-assembler \"_Z3f2012__Poly16x8_t:\" } }\n-// { dg-final { scan-assembler \"_Z3f2111__Int8x16_tS_:\" } }\n+// { dg-final { scan-assembler \"_Z3f2113__Float64x1_t:\" } }\n+// { dg-final { scan-assembler \"_Z2g111__Int8x16_tS_:\" } }"}, {"sha": "673242687e4946d7bc1cb61c247510dfd128cc81", "filename": "gcc/testsuite/gcc.target/aarch64/aapcs64/func-ret-64x1_1.c", "status": "added", "additions": 15, "deletions": 0, "changes": 15, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Faapcs64%2Ffunc-ret-64x1_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Faapcs64%2Ffunc-ret-64x1_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Faapcs64%2Ffunc-ret-64x1_1.c?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -0,0 +1,15 @@\n+/* Test AAPCS64 layout.\n+\n+  Test 64-bit singleton vector types which should be in FP/SIMD registers.  */\n+\n+/* { dg-do run { target aarch64*-*-* } } */\n+/* { dg-additional-sources \"abitest.S\" } */\n+\n+#ifndef IN_FRAMEWORK\n+#define TESTFILE \"func-ret-64x1_1.c\"\n+#include <arm_neon.h>\n+#include \"abitest-2.h\"\n+#else\n+FUNC_VAL_CHECK ( 0, float64x1_t, (float64x1_t) {123456.789}, D0, flat)\n+#endif\n+"}, {"sha": "f1dc1a759b07fcc8a9c4310ac14f43274a3f378f", "filename": "gcc/testsuite/gcc.target/aarch64/aapcs64/test_64x1_1.c", "status": "added", "additions": 16, "deletions": 0, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Faapcs64%2Ftest_64x1_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Faapcs64%2Ftest_64x1_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Faapcs64%2Ftest_64x1_1.c?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -0,0 +1,16 @@\n+/* Test AAPCS64 layout.\n+\n+   Test 64-bit singleton vector types which should be in FP/SIMD registers.  */\n+\n+/* { dg-do run { target aarch64*-*-* } } */\n+\n+#ifndef IN_FRAMEWORK\n+#define TESTFILE \"test_64x1_1.c\"\n+#include <arm_neon.h>\n+\n+#include \"abitest.h\"\n+#else\n+ARG (float64x1_t, (float64x1_t) {123456.789}, D0)\n+ARG (float64_t, 987654.321, D1)\n+LAST_ARG (float64x1_t, (float64x1_t) {13579.2468}, D2)\n+#endif"}, {"sha": "42389aaaa76b6af2d4c730b7b78ea055163bb44d", "filename": "gcc/testsuite/gcc.target/aarch64/simd/ext_f64_1.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fext_f64_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fext_f64_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fsimd%2Fext_f64_1.c?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -14,7 +14,7 @@ main (int argc, char **argv)\n   float64x1_t in1 = {0};\n   float64x1_t in2 = {1};\n   float64x1_t actual = vext_f64 (in1, in2, 0);\n-  if (actual != in1)\n+  if (actual[0] != in1[0])\n     abort ();\n \n   return 0;"}, {"sha": "f35c42dcfbd2a8da19f183e4d23d365702a087dc", "filename": "gcc/testsuite/gcc.target/aarch64/vadd_f64.c", "status": "modified", "additions": 28, "deletions": 60, "changes": 88, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvadd_f64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvadd_f64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvadd_f64.c?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -4,9 +4,6 @@\n \n #include <arm_neon.h>\n \n-#define FLT_EPSILON __FLT_EPSILON__\n-#define DBL_EPSILON __DBL_EPSILON__\n-\n #define TESTA0 0.33333\n #define TESTA1 -1.7777\n #define TESTA2 0\n@@ -42,70 +39,41 @@ extern void abort (void);\n     || (ABS (a - b) < epsilon)\t\t\t\t\\\n    )\n \n-int\n-test_vadd_f64 ()\n-{\n-  float64x1_t a;\n-  float64x1_t b;\n-  float64x1_t c;\n-\n-  a = TESTA0;\n-  b = TESTB0;\n-  c = ANSW0;\n-\n-  a = vadd_f64 (a, b);\n-  if (!FP_equals (a, c, EPSILON))\n-    return 1;\n-\n-  a = TESTA1;\n-  b = TESTB1;\n-  c = ANSW1;\n-\n-  a = vadd_f64 (a, b);\n-  if (!FP_equals (a, c, EPSILON))\n-    return 1;\n-\n-  a = TESTA2;\n-  b = TESTB2;\n-  c = ANSW2;\n-\n-  a = vadd_f64 (a, b);\n-  if (!FP_equals (a, c, EPSILON))\n-    return 1;\n-\n-  a = TESTA3;\n-  b = TESTB3;\n-  c = ANSW3;\n-\n-  a = vadd_f64 (a, b);\n-  if (!FP_equals (a, c, EPSILON))\n-    return 1;\n-\n-  a = TESTA4;\n-  b = TESTB4;\n-  c = ANSW4;\n-\n-  a = vadd_f64 (a, b);\n-  if (!FP_equals (a, c, EPSILON))\n-    return 1;\n-\n-  a = TESTA5;\n-  b = TESTB5;\n-  c = ANSW5;\n-\n-  a = vadd_f64 (a, b);\n-  if (!FP_equals (a, c, EPSILON))\n-    return 1;\n-\n-  return 0;\n+#define TEST(N)\t\t\t\t\t\\\n+int\t\t\t\t\t\t\\\n+test_vadd_f64_##N ()\t\t\t\t\\\n+{\t\t\t\t\t\t\\\n+  float64x1_t a = { TESTA##N };\t\t\t\\\n+  float64x1_t b = { TESTB##N };\t\t\t\\\n+  float64x1_t c = { ANSW##N };\t\t\t\\\n+\t\t\t\t\t\t\\\n+  a = vadd_f64 (a, b);\t\t\t\t\\\n+  return !FP_equals (a[0], c[0], EPSILON);\t\\\n }\n \n+TEST (0)\n+TEST (1)\n+TEST (2)\n+TEST (3)\n+TEST (4)\n+TEST (5)\n+\n /* { dg-final { scan-assembler-times \"fadd\\\\td\\[0-9\\]+, d\\[0-9\\]+, d\\[0-9\\]+\" 6 } } */\n \n int\n main (int argc, char **argv)\n {\n-  if (test_vadd_f64 ())\n+  if (test_vadd_f64_0 ())\n+    abort ();\n+  if (test_vadd_f64_1 ())\n+    abort ();\n+  if (test_vadd_f64_2 ())\n+    abort ();\n+  if (test_vadd_f64_3 ())\n+    abort ();\n+  if (test_vadd_f64_4 ())\n+    abort ();\n+  if (test_vadd_f64_5 ())\n     abort ();\n \n   return 0;"}, {"sha": "9e1b768eda3a88ea37a5da8ffa405e29ec2f2d60", "filename": "gcc/testsuite/gcc.target/aarch64/vdiv_f.c", "status": "modified", "additions": 1, "deletions": 10, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvdiv_f.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvdiv_f.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvdiv_f.c?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -99,13 +99,6 @@\n #define EPSILON_64 __DBL_EPSILON__\n #define EPSILON(data_len) EPSILON_##data_len\n \n-#define INDEX64_32 [i]\n-#define INDEX64_64\n-#define INDEX128_32 [i]\n-#define INDEX128_64 [i]\n-#define INDEX(reg_len, data_len) \\\n-  CONCAT1 (INDEX, reg_len##_##data_len)\n-\n #define LOAD_INST(reg_len, data_len) \\\n   CONCAT1 (vld1, POSTFIX (reg_len, data_len))\n #define DIV_INST(reg_len, data_len) \\\n@@ -135,9 +128,7 @@\n   for (i = 0; i < n; i++)\t\t\t\t\t\t\\\n   {\t\t\t\t\t\t\t\t\t\\\n     INHIB_OPTIMIZATION;\t\t\t\t\t\t\t\\\n-    if (!FP_equals ((a) INDEX (reg_len, data_len),\t\t\t\\\n-\t\t    (c) INDEX (reg_len, data_len),\t\t\t\\\n-\t\t    EPSILON (data_len)))\t\t\t\t\\\n+    if (!FP_equals ((a) [i], (c) [i], EPSILON (data_len)))\t\t\\\n       return 1;\t\t\t\t\t\t\t\t\\\n   }\t\t\t\t\t\t\t\t\t\\\n }"}, {"sha": "31efc4f2752b6e32808d7ba382c9f378e9e73299", "filename": "gcc/testsuite/gcc.target/aarch64/vrnd_f64_1.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvrnd_f64_1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvrnd_f64_1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvrnd_f64_1.c?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -30,7 +30,7 @@ set_rounding_mode (uint32_t mode)\n   asm volatile (\"msr fpcr, %[r]\" : : [r] \"r\" (r) :);\n }\n \n-float64x1_t __attribute__ ((noinline))\n+float64_t __attribute__ ((noinline))\n compare_f64 (float64x1_t passed, float64_t expected)\n {\n   return (__builtin_fabs (vget_lane_f64 (passed, 0) - expected)"}, {"sha": "91d74638201e386f500717542973ed46f9c7c5cf", "filename": "gcc/testsuite/gcc.target/aarch64/vsub_f64.c", "status": "modified", "additions": 28, "deletions": 60, "changes": 88, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvsub_f64.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c6a29a091a11b6337c78130b738a0f5a96b2a2f5/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvsub_f64.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Ftestsuite%2Fgcc.target%2Faarch64%2Fvsub_f64.c?ref=c6a29a091a11b6337c78130b738a0f5a96b2a2f5", "patch": "@@ -4,9 +4,6 @@\n \n #include <arm_neon.h>\n \n-#define FLT_EPSILON __FLT_EPSILON__\n-#define DBL_EPSILON __DBL_EPSILON__\n-\n #define TESTA0 1\n #define TESTA1 0.2223\n #define TESTA2 0\n@@ -44,70 +41,41 @@ extern void abort (void);\n      || ((b > a) && (b < (a + epsilon))))\t\\\n )\n \n-int\n-test_vsub_f64 ()\n-{\n-  float64x1_t a;\n-  float64x1_t b;\n-  float64x1_t c;\n-\n-  a = TESTA0;\n-  b = TESTB0;\n-  c = ANSW0;\n-\n-  a = vsub_f64 (a, b);\n-  if (!FP_equals (a, c, EPSILON))\n-    return 1;\n-\n-  a = TESTA1;\n-  b = TESTB1;\n-  c = ANSW1;\n-\n-  a = vsub_f64 (a, b);\n-  if (!FP_equals (a, c, EPSILON))\n-    return 1;\n-\n-  a = TESTA2;\n-  b = TESTB2;\n-  c = ANSW2;\n-\n-  a = vsub_f64 (a, b);\n-  if (!FP_equals (a, c, EPSILON))\n-    return 1;\n-\n-  a = TESTA3;\n-  b = TESTB3;\n-  c = ANSW3;\n-\n-  a = vsub_f64 (a, b);\n-  if (!FP_equals (a, c, EPSILON))\n-    return 1;\n-\n-  a = TESTA4;\n-  b = TESTB4;\n-  c = ANSW4;\n-\n-  a = vsub_f64 (a, b);\n-  if (!FP_equals (a, c, EPSILON))\n-    return 1;\n-\n-  a = TESTA5;\n-  b = TESTB5;\n-  c = ANSW5;\n-\n-  a = vsub_f64 (a, b);\n-  if (!FP_equals (a, c, EPSILON))\n-    return 1;\n-\n-  return 0;\n+#define TEST(N)\t\t\t\t\t\\\n+int\t\t\t\t\t\t\\\n+test_vsub_f64_##N ()\t\t\t\t\\\n+{\t\t\t\t\t\t\\\n+  float64x1_t a = { TESTA##N };\t\t\t\\\n+  float64x1_t b = { TESTB##N };\t\t\t\\\n+  float64x1_t c = { ANSW##N };\t\t\t\\\n+\t\t\t\t\t\t\\\n+  a = vsub_f64 (a, b);\t\t\t\t\\\n+  return !FP_equals (a[0], c[0], EPSILON);\t\\\n }\n \n+TEST (0)\n+TEST (1)\n+TEST (2)\n+TEST (3)\n+TEST (4)\n+TEST (5)\n+\n /* { dg-final { scan-assembler-times \"fsub\\\\td\\[0-9\\]+, d\\[0-9\\]+, d\\[0-9\\]+\" 6 } } */\n \n int\n main (int argc, char **argv)\n {\n-  if (test_vsub_f64 ())\n+  if (test_vsub_f64_0 ())\n+    abort ();\n+  if (test_vsub_f64_1 ())\n+    abort ();\n+  if (test_vsub_f64_2 ())\n+    abort ();\n+  if (test_vsub_f64_3 ())\n+    abort ();\n+  if (test_vsub_f64_4 ())\n+    abort ();\n+  if (test_vsub_f64_5 ())\n     abort ();\n \n   return 0;"}]}