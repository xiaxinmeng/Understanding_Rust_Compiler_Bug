{"sha": "e304a8e61a5970791a71e4a4f35509e9574202b7", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6ZTMwNGE4ZTYxYTU5NzA3OTFhNzFlNGE0ZjM1NTA5ZTk1NzQyMDJiNw==", "commit": {"author": {"name": "Michael Hayes", "email": "mhayes@redhat.com", "date": "2001-01-01T00:24:46Z"}, "committer": {"name": "Michael Hayes", "email": "m.hayes@gcc.gnu.org", "date": "2001-01-01T00:24:46Z"}, "message": "loop.c (loop_giv_reduce_benefit): Break out from strength_reduce.\n\n\t* loop.c (loop_giv_reduce_benefit): Break out from strength_reduce.\n\t(loop_givs_dead_check, loop_givs_reduce, loop_givs_rescan): Likewise.\n\t(prescan_loop): Set pre_header_has_call in loop_info.\n\t* loop.h (struct_iv_class): Add `final_value' and `all_reduced'.\n\t(struct loop_info): Add `pre_header_has_call'.\n\nFrom-SVN: r38578", "tree": {"sha": "4fe0d05056fa9a66707db62b080a94c0cdf27fe5", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/4fe0d05056fa9a66707db62b080a94c0cdf27fe5"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/e304a8e61a5970791a71e4a4f35509e9574202b7", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e304a8e61a5970791a71e4a4f35509e9574202b7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e304a8e61a5970791a71e4a4f35509e9574202b7", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e304a8e61a5970791a71e4a4f35509e9574202b7/comments", "author": null, "committer": null, "parents": [{"sha": "6ec73c7cc8bba8fa653d12bccf399623231059b8", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/6ec73c7cc8bba8fa653d12bccf399623231059b8", "html_url": "https://github.com/Rust-GCC/gccrs/commit/6ec73c7cc8bba8fa653d12bccf399623231059b8"}], "stats": {"total": 898, "additions": 469, "deletions": 429}, "files": [{"sha": "faf78886c584ed3f26aaf0aa236f329faca5e89c", "filename": "gcc/ChangeLog", "status": "modified", "additions": 8, "deletions": 0, "changes": 8, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e304a8e61a5970791a71e4a4f35509e9574202b7/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e304a8e61a5970791a71e4a4f35509e9574202b7/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=e304a8e61a5970791a71e4a4f35509e9574202b7", "patch": "@@ -1,3 +1,11 @@\n+2001-01-01  Michael Hayes  <mhayes@redhat.com>\n+\n+\t* loop.c (loop_giv_reduce_benefit): Break out from strength_reduce.\n+\t(loop_givs_dead_check, loop_givs_reduce, loop_givs_rescan): Likewise.\n+\t(prescan_loop): Set pre_header_has_call in loop_info.\n+\t* loop.h (struct_iv_class): Add `final_value' and `all_reduced'.\n+\t(struct loop_info): Add `pre_header_has_call'.\n+\t\n 2001-01-01  Michael Hayes  <mhayes@redhat.com>\n \n \t* loop.c (loop_bivs_find): Break out from strength_reduce."}, {"sha": "d931a573204af5029a647613d6b83d0ae7bd37d3", "filename": "gcc/loop.c", "status": "modified", "additions": 448, "deletions": 423, "changes": 871, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e304a8e61a5970791a71e4a4f35509e9574202b7/gcc%2Floop.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e304a8e61a5970791a71e4a4f35509e9574202b7/gcc%2Floop.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop.c?ref=e304a8e61a5970791a71e4a4f35509e9574202b7", "patch": "@@ -186,8 +186,14 @@ static void loop_bivs_init_find PARAMS((struct loop *));\n static void loop_bivs_check PARAMS((struct loop *));\n static void loop_givs_find PARAMS((struct loop *));\n static void loop_givs_check PARAMS((struct loop *));\n-static void loop_biv_eliminable_p PARAMS((struct loop *, struct iv_class *,\n-\t\t\t\t\t  int, int));\n+static int loop_biv_eliminable_p PARAMS((struct loop *, struct iv_class *,\n+\t\t\t\t\t int, int));\n+static int loop_giv_reduce_benefit PARAMS((struct loop *, struct iv_class *,\n+\t\t\t\t\t   struct induction *, rtx));\n+static void loop_givs_dead_check PARAMS((struct loop *, struct iv_class *));\n+static void loop_givs_reduce PARAMS((struct loop *, struct iv_class *));\n+static void loop_givs_rescan PARAMS((struct loop *, struct iv_class *,\n+\t\t\t\t     rtx *, rtx));\n static void strength_reduce PARAMS ((struct loop *, int, int));\n static void find_single_use_in_loop PARAMS ((rtx, rtx, varray_type));\n static int valid_initial_value_p PARAMS ((rtx, rtx, int, rtx));\n@@ -2301,6 +2307,7 @@ prescan_loop (loop)\n   rtx exit_target = next_nonnote_insn (end);\n \n   loop_info->has_indirect_jump = indirect_jump_in_function;\n+  loop_info->pre_header_has_call = 0;\n   loop_info->has_call = 0;\n   loop_info->has_volatile = 0;\n   loop_info->has_tablejump = 0;\n@@ -2314,6 +2321,17 @@ prescan_loop (loop)\n   loop_info->mems_idx = 0;\n   loop_info->num_mem_sets = 0;\n \n+\n+  for (insn = start; insn && GET_CODE (insn) != CODE_LABEL; \n+       insn = PREV_INSN (insn))\n+    {\n+      if (GET_CODE (insn) == CALL_INSN)\n+\t{\n+\t  loop_info->pre_header_has_call = 1;\n+\t  break;\n+\t}\n+    }\n+\n   for (insn = NEXT_INSN (start); insn != NEXT_INSN (end);\n        insn = NEXT_INSN (insn))\n     {\n@@ -3692,18 +3710,20 @@ static void\n loop_bivs_init_find (loop)\n      struct loop *loop;\n {\n-  struct loop_info *loop_info = LOOP_INFO (loop);\n   struct loop_ivs *ivs = LOOP_IVS (loop);\n   /* Temporary list pointers for traversing ivs->loop_iv_list.  */\n   struct iv_class *bl;\n-  basic_block ebb;\n+  int call_seen;\n+  rtx p;\n \n   /* Find initial value for each biv by searching backwards from loop_start,\n      halting at first label.  Also record any test condition.  */\n \n   call_seen = 0;\n-  for (p = loop_start; p && GET_CODE (p) != CODE_LABEL; p = PREV_INSN (p))\n+  for (p = loop->start; p && GET_CODE (p) != CODE_LABEL; p = PREV_INSN (p))\n     {\n+      rtx test;\n+\n       note_insn = p;\n \n       if (GET_CODE (p) == CALL_INSN)\n@@ -3717,12 +3737,12 @@ loop_bivs_init_find (loop)\n \t constants and registers and only certain of those.  */\n       if (GET_CODE (p) == JUMP_INSN\n \t  && JUMP_LABEL (p) != 0\n-\t  && next_real_insn (JUMP_LABEL (p)) == next_real_insn (loop_end)\n+\t  && next_real_insn (JUMP_LABEL (p)) == next_real_insn (loop->end)\n \t  && (test = get_condition_for_loop (loop, p)) != 0\n \t  && GET_CODE (XEXP (test, 0)) == REG\n \t  && REGNO (XEXP (test, 0)) < max_reg_before_loop\n \t  && (bl = ivs->reg_biv_class[REGNO (XEXP (test, 0))]) != 0\n-\t  && valid_initial_value_p (XEXP (test, 1), p, call_seen, loop_start)\n+\t  && valid_initial_value_p (XEXP (test, 1), p, call_seen, loop->start)\n \t  && bl->init_insn == 0)\n \t{\n \t  /* If an NE test, we have an initial value!  */\n@@ -3776,7 +3796,9 @@ loop_bivs_check (loop)\n \n       if ((GET_MODE (src) == GET_MODE (regno_reg_rtx[bl->regno])\n \t   || GET_MODE (src) == VOIDmode)\n-\t  && valid_initial_value_p (loop, src, bl->init_insn))\n+\t  && valid_initial_value_p (src, bl->init_insn, \n+\t\t\t\t    LOOP_INFO (loop)->pre_header_has_call, \n+\t\t\t\t    loop->start))\n \t{\n \t  bl->initial_value = src;\n \n@@ -3835,45 +3857,407 @@ loop_givs_check (loop)\n }\n \n \n-static void\n+/* Return non-zero if it is possible to eliminate the biv BL provided\n+   all givs are reduced.  This is possible if either the reg is not\n+   used outside the loop, or we can compute what its final value will\n+   be.  */\n+\n+static int\n loop_biv_eliminable_p (loop, bl, threshold, insn_count)\n      struct loop *loop;\n      struct iv_class *bl;\n      int threshold;\n      int insn_count;\n {\n-  /* Test whether it will be possible to eliminate this biv\n-     provided all givs are reduced.  This is possible if either\n-     the reg is not used outside the loop, or we can compute\n-     what its final value will be.\n-     \n-     For architectures with a decrement_and_branch_until_zero insn,\n-     don't do this if we put a REG_NONNEG note on the endtest for\n-     this biv.  */\n-  \n-  /* Compare against bl->init_insn rather than loop_start.\n-     We aren't concerned with any uses of the biv between\n-     init_insn and loop_start since these won't be affected\n-     by the value of the biv elsewhere in the function, so\n-     long as init_insn doesn't use the biv itself.\n-     March 14, 1989 -- self@bayes.arc.nasa.gov */\n+  /* For architectures with a decrement_and_branch_until_zero insn,\n+     don't do this if we put a REG_NONNEG note on the endtest for this\n+     biv.  */\n+\n+#ifdef HAVE_decrement_and_branch_until_zero\n+  if (bl->nonneg)\n+    {\n+      if (loop_dump_stream)\n+\tfprintf (loop_dump_stream,\n+\t\t \"Cannot eliminate nonneg biv %d.\\n\", bl->regno);\n+      return 0;\n+    }\n+#endif\n+\n+  /* Check that biv is used outside loop or if it has a final value.\n+     Compare against bl->init_insn rather than loop->start.  We aren't\n+     concerned with any uses of the biv between init_insn and\n+     loop->start since these won't be affected by the value of the biv\n+     elsewhere in the function, so long as init_insn doesn't use the\n+     biv itself.  */\n   \n   if ((REGNO_LAST_LUID (bl->regno) < INSN_LUID (loop->end)\n        && bl->init_insn\n        && INSN_UID (bl->init_insn) < max_uid_for_loop\n        && REGNO_FIRST_LUID (bl->regno) >= INSN_LUID (bl->init_insn)\n-#ifdef HAVE_decrement_and_branch_until_zero\n-       && ! bl->nonneg\n-#endif\n        && ! reg_mentioned_p (bl->biv->dest_reg, SET_SRC (bl->init_set)))\n-      || ((final_value = final_biv_value (loop, bl))\n-#ifdef HAVE_decrement_and_branch_until_zero\n-\t  && ! bl->nonneg\n-#endif\n-\t  ))\n+      || (bl->final_value = final_biv_value (loop, bl)))\n     return maybe_eliminate_biv (loop, bl, 0, threshold,\tinsn_count);\n-  else\n-    return 0;\n+  \n+  if (loop_dump_stream)\n+    {\n+      fprintf (loop_dump_stream,\n+\t       \"Cannot eliminate biv %d.\\n\",\n+\t       bl->regno);\n+      fprintf (loop_dump_stream,\n+\t       \"First use: insn %d, last use: insn %d.\\n\",\n+\t       REGNO_FIRST_UID (bl->regno),\n+\t       REGNO_LAST_UID (bl->regno));\n+    }\n+  return 0;\n+}\n+\n+\n+/* Reduce each giv of BL that we have decided to reduce.  */\n+\n+static void\n+loop_givs_reduce (loop, bl)\n+     struct loop *loop;\n+     struct iv_class *bl;\n+{\n+  struct induction *v;\n+\n+  for (v = bl->giv; v; v = v->next_iv)\n+    {\n+      struct induction *tv;\n+      if (! v->ignore && v->same == 0)\n+\t{\n+\t  int auto_inc_opt = 0;\n+\t  \n+\t  /* If the code for derived givs immediately below has already\n+\t     allocated a new_reg, we must keep it.  */\n+\t  if (! v->new_reg)\n+\t    v->new_reg = gen_reg_rtx (v->mode);\n+\t  \n+#ifdef AUTO_INC_DEC\n+\t  /* If the target has auto-increment addressing modes, and\n+\t     this is an address giv, then try to put the increment\n+\t     immediately after its use, so that flow can create an\n+\t     auto-increment addressing mode.  */\n+\t  if (v->giv_type == DEST_ADDR && bl->biv_count == 1\n+\t      && bl->biv->always_executed && ! bl->biv->maybe_multiple\n+\t      /* We don't handle reversed biv's because bl->biv->insn\n+\t\t does not have a valid INSN_LUID.  */\n+\t      && ! bl->reversed\n+\t      && v->always_executed && ! v->maybe_multiple\n+\t      && INSN_UID (v->insn) < max_uid_for_loop)\n+\t    {\n+\t      /* If other giv's have been combined with this one, then\n+\t\t this will work only if all uses of the other giv's occur\n+\t\t before this giv's insn.  This is difficult to check.\n+\t\t \n+\t\t We simplify this by looking for the common case where\n+\t\t there is one DEST_REG giv, and this giv's insn is the\n+\t\t last use of the dest_reg of that DEST_REG giv.  If the\n+\t\t increment occurs after the address giv, then we can\n+\t\t perform the optimization.  (Otherwise, the increment\n+\t\t would have to go before other_giv, and we would not be\n+\t\t able to combine it with the address giv to get an\n+\t\t auto-inc address.)  */\n+\t      if (v->combined_with)\n+\t\t{\n+\t\t  struct induction *other_giv = 0;\n+\t\t  \n+\t\t  for (tv = bl->giv; tv; tv = tv->next_iv)\n+\t\t    if (tv->same == v)\n+\t\t      {\n+\t\t\tif (other_giv)\n+\t\t\t  break;\n+\t\t\telse\n+\t\t\t  other_giv = tv;\n+\t\t      }\n+\t\t  if (! tv && other_giv\n+\t\t      && REGNO (other_giv->dest_reg) < max_reg_before_loop\n+\t\t      && (REGNO_LAST_UID (REGNO (other_giv->dest_reg))\n+\t\t\t  == INSN_UID (v->insn))\n+\t\t      && INSN_LUID (v->insn) < INSN_LUID (bl->biv->insn))\n+\t\t    auto_inc_opt = 1;\n+\t\t}\n+\t      /* Check for case where increment is before the address\n+\t\t giv.  Do this test in \"loop order\".  */\n+\t      else if ((INSN_LUID (v->insn) > INSN_LUID (bl->biv->insn)\n+\t\t\t&& (INSN_LUID (v->insn) < INSN_LUID (loop->scan_start)\n+\t\t\t    || (INSN_LUID (bl->biv->insn)\n+\t\t\t\t> INSN_LUID (loop->scan_start))))\n+\t\t       || (INSN_LUID (v->insn) < INSN_LUID (loop->scan_start)\n+\t\t\t   && (INSN_LUID (loop->scan_start)\n+\t\t\t       < INSN_LUID (bl->biv->insn))))\n+\t\tauto_inc_opt = -1;\n+\t      else\n+\t\tauto_inc_opt = 1;\n+\t      \n+#ifdef HAVE_cc0\n+\t      {\n+\t\trtx prev;\n+\t\t\n+\t\t/* We can't put an insn immediately after one setting\n+\t\t   cc0, or immediately before one using cc0.  */\n+\t\tif ((auto_inc_opt == 1 && sets_cc0_p (PATTERN (v->insn)))\n+\t\t    || (auto_inc_opt == -1\n+\t\t\t&& (prev = prev_nonnote_insn (v->insn)) != 0\n+\t\t\t&& INSN_P (prev)\n+\t\t\t&& sets_cc0_p (PATTERN (prev))))\n+\t\t  auto_inc_opt = 0;\n+\t      }\n+#endif\n+\t      \n+\t      if (auto_inc_opt)\n+\t\tv->auto_inc_opt = 1;\n+\t    }\n+#endif\n+\t  \n+\t  /* For each place where the biv is incremented, add an insn\n+\t     to increment the new, reduced reg for the giv.  */\n+\t  for (tv = bl->biv; tv; tv = tv->next_iv)\n+\t    {\n+\t      rtx insert_before;\n+\t      \n+\t      if (! auto_inc_opt)\n+\t\tinsert_before = tv->insn;\n+\t      else if (auto_inc_opt == 1)\n+\t\tinsert_before = NEXT_INSN (v->insn);\n+\t      else\n+\t\tinsert_before = v->insn;\n+\t      \n+\t      if (tv->mult_val == const1_rtx)\n+\t\temit_iv_add_mult (tv->add_val, v->mult_val,\n+\t\t\t\t  v->new_reg, v->new_reg, insert_before);\n+\t      else /* tv->mult_val == const0_rtx */\n+\t\t/* A multiply is acceptable here\n+\t\t   since this is presumed to be seldom executed.  */\n+\t\temit_iv_add_mult (tv->add_val, v->mult_val,\n+\t\t\t\t  v->add_val, v->new_reg, insert_before);\n+\t    }\n+\t  \n+\t  /* Add code at loop start to initialize giv's reduced reg.  */\n+\t  \n+\t  emit_iv_add_mult (extend_value_for_giv (v, bl->initial_value),\n+\t\t\t    v->mult_val, v->add_val, v->new_reg,\n+\t\t\t    loop->start);\n+\t}\n+    }\n+}\n+\n+\n+/* Check for givs whose first use is their definition and whose\n+   last use is the definition of another giv.  If so, it is likely\n+   dead and should not be used to derive another giv nor to\n+   eliminate a biv.  */\n+\n+static void\n+loop_givs_dead_check (loop, bl)\n+     struct loop *loop ATTRIBUTE_UNUSED;\n+     struct iv_class *bl;\n+{\n+  struct induction *v;\n+\n+  for (v = bl->giv; v; v = v->next_iv)\n+    {\n+      if (v->ignore\n+\t  || (v->same && v->same->ignore))\n+\tcontinue;\n+      \n+      if (v->giv_type == DEST_REG\n+\t  && REGNO_FIRST_UID (REGNO (v->dest_reg)) == INSN_UID (v->insn))\n+\t{\n+\t  struct induction *v1;\n+\t  \n+\t  for (v1 = bl->giv; v1; v1 = v1->next_iv)\n+\t    if (REGNO_LAST_UID (REGNO (v->dest_reg)) == INSN_UID (v1->insn))\n+\t      v->maybe_dead = 1;\n+\t}\n+    }\n+}\n+\n+\n+static void\n+loop_givs_rescan (loop, bl, reg_map, end_insert_before)\n+     struct loop *loop;\n+     struct iv_class *bl;\n+     rtx *reg_map;\n+     rtx end_insert_before;\n+{\n+  struct induction *v;\n+\n+  for (v = bl->giv; v; v = v->next_iv)\n+    {\n+      if (v->same && v->same->ignore)\n+\tv->ignore = 1;\n+      \n+      if (v->ignore)\n+\tcontinue;\n+      \n+      /* Update expression if this was combined, in case other giv was\n+\t replaced.  */\n+      if (v->same)\n+\tv->new_reg = replace_rtx (v->new_reg,\n+\t\t\t\t  v->same->dest_reg, v->same->new_reg);\n+      \n+      /* See if this register is known to be a pointer to something.  If\n+\t so, see if we can find the alignment.  First see if there is a\n+\t destination register that is a pointer.  If so, this shares the\n+\t alignment too.  Next see if we can deduce anything from the\n+\t computational information.  If not, and this is a DEST_ADDR\n+\t giv, at least we know that it's a pointer, though we don't know\n+\t the alignment.  */\n+      if (GET_CODE (v->new_reg) == REG\n+\t  && v->giv_type == DEST_REG\n+\t  && REG_POINTER (v->dest_reg))\n+\tmark_reg_pointer (v->new_reg,\n+\t\t\t  REGNO_POINTER_ALIGN (REGNO (v->dest_reg)));\n+      else if (GET_CODE (v->new_reg) == REG\n+\t       && REG_POINTER (v->src_reg))\n+\t{\n+\t  unsigned int align = REGNO_POINTER_ALIGN (REGNO (v->src_reg));\n+\t  \n+\t  if (align == 0\n+\t      || GET_CODE (v->add_val) != CONST_INT\n+\t      || INTVAL (v->add_val) % (align / BITS_PER_UNIT) != 0)\n+\t    align = 0;\n+\t  \n+\t  mark_reg_pointer (v->new_reg, align);\n+\t}\n+      else if (GET_CODE (v->new_reg) == REG\n+\t       && GET_CODE (v->add_val) == REG\n+\t       && REG_POINTER (v->add_val))\n+\t{\n+\t  unsigned int align = REGNO_POINTER_ALIGN (REGNO (v->add_val));\n+\t  \n+\t  if (align == 0 || GET_CODE (v->mult_val) != CONST_INT\n+\t      || INTVAL (v->mult_val) % (align / BITS_PER_UNIT) != 0)\n+\t    align = 0;\n+\t  \n+\t  mark_reg_pointer (v->new_reg, align);\n+\t}\n+      else if (GET_CODE (v->new_reg) == REG && v->giv_type == DEST_ADDR)\n+\tmark_reg_pointer (v->new_reg, 0);\n+      \n+      if (v->giv_type == DEST_ADDR)\n+\t/* Store reduced reg as the address in the memref where we found\n+\t   this giv.  */\n+\tvalidate_change (v->insn, v->location, v->new_reg, 0);\n+      else if (v->replaceable)\n+\t{\n+\t  reg_map[REGNO (v->dest_reg)] = v->new_reg;\n+\t}\n+      else\n+\t{\n+\t  /* Not replaceable; emit an insn to set the original giv reg from\n+\t     the reduced giv, same as above.  */\n+\t  emit_insn_after (gen_move_insn (v->dest_reg, v->new_reg),\n+\t\t\t   v->insn);\n+\t}\n+      \n+      /* When a loop is reversed, givs which depend on the reversed\n+\t biv, and which are live outside the loop, must be set to their\n+\t correct final value.  This insn is only needed if the giv is\n+\t not replaceable.  The correct final value is the same as the\n+\t value that the giv starts the reversed loop with.  */\n+      if (bl->reversed && ! v->replaceable)\n+\temit_iv_add_mult (extend_value_for_giv (v, bl->initial_value),\n+\t\t\t  v->mult_val, v->add_val, v->dest_reg,\n+\t\t\t  end_insert_before);\n+      else if (v->final_value)\n+\t{\n+\t  rtx insert_before;\n+\t  \n+\t  /* If the loop has multiple exits, emit the insn before the\n+\t     loop to ensure that it will always be executed no matter\n+\t     how the loop exits.  Otherwise, emit the insn after the loop,\n+\t     since this is slightly more efficient.  */\n+\t  if (loop->exit_count)\n+\t    insert_before = loop->start;\n+\t  else\n+\t    insert_before = end_insert_before;\n+\t  emit_insn_before (gen_move_insn (v->dest_reg, v->final_value),\n+\t\t\t    insert_before);\n+\t}\n+      \n+      if (loop_dump_stream)\n+\t{\n+\t  fprintf (loop_dump_stream, \"giv at %d reduced to \",\n+\t\t   INSN_UID (v->insn));\n+\t  print_rtl (loop_dump_stream, v->new_reg);\n+\t  fprintf (loop_dump_stream, \"\\n\");\n+\t}\n+    }\n+}\n+\n+\n+static int\n+loop_giv_reduce_benefit (loop, bl, v, test_reg)\n+     struct loop *loop ATTRIBUTE_UNUSED;\n+     struct iv_class *bl;\n+     struct induction *v;\n+     rtx test_reg;\n+{\n+  int add_cost;\n+  int benefit;\n+\n+  benefit = v->benefit;\n+  PUT_MODE (test_reg, v->mode);\n+  add_cost = iv_add_mult_cost (bl->biv->add_val, v->mult_val,\n+\t\t\t       test_reg, test_reg);\n+  \n+  /* Reduce benefit if not replaceable, since we will insert a\n+     move-insn to replace the insn that calculates this giv.  Don't do\n+     this unless the giv is a user variable, since it will often be\n+     marked non-replaceable because of the duplication of the exit\n+     code outside the loop.  In such a case, the copies we insert are\n+     dead and will be deleted.  So they don't have a cost.  Similar\n+     situations exist.  */\n+  /* ??? The new final_[bg]iv_value code does a much better job of\n+     finding replaceable giv's, and hence this code may no longer be\n+     necessary.  */\n+  if (! v->replaceable && ! bl->eliminable\n+      && REG_USERVAR_P (v->dest_reg))\n+    benefit -= copy_cost;\n+  \n+  /* Decrease the benefit to count the add-insns that we will insert\n+     to increment the reduced reg for the giv.  ??? This can\n+     overestimate the run-time cost of the additional insns, e.g. if\n+     there are multiple basic blocks that increment the biv, but only\n+     one of these blocks is executed during each iteration.  There is\n+     no good way to detect cases like this with the current structure\n+     of the loop optimizer.  This code is more accurate for\n+     determining code size than run-time benefits.  */\n+  benefit -= add_cost * bl->biv_count;\n+\n+  /* Decide whether to strength-reduce this giv or to leave the code\n+     unchanged (recompute it from the biv each time it is used).  This\n+     decision can be made independently for each giv.  */\n+\n+#ifdef AUTO_INC_DEC\n+  /* Attempt to guess whether autoincrement will handle some of the\n+     new add insns; if so, increase BENEFIT (undo the subtraction of\n+     add_cost that was done above).  */\n+  if (v->giv_type == DEST_ADDR\n+      /* Increasing the benefit is risky, since this is only a guess.\n+\t Avoid increasing register pressure in cases where there would\n+\t be no other benefit from reducing this giv.  */\n+      && benefit > 0\n+      && GET_CODE (v->mult_val) == CONST_INT)\n+    {\n+      if (HAVE_POST_INCREMENT\n+\t  && INTVAL (v->mult_val) == GET_MODE_SIZE (v->mem_mode))\n+\tbenefit += add_cost * bl->biv_count;\n+      else if (HAVE_PRE_INCREMENT\n+\t       && INTVAL (v->mult_val) == GET_MODE_SIZE (v->mem_mode))\n+\tbenefit += add_cost * bl->biv_count;\n+      else if (HAVE_POST_DECREMENT\n+\t       && -INTVAL (v->mult_val) == GET_MODE_SIZE (v->mem_mode))\n+\tbenefit += add_cost * bl->biv_count;\n+      else if (HAVE_PRE_DECREMENT\n+\t       && -INTVAL (v->mult_val) == GET_MODE_SIZE (v->mem_mode))\n+\tbenefit += add_cost * bl->biv_count;\n+    }\n+#endif\n+\n+  return benefit;\n }\n \n \n@@ -3896,8 +4280,8 @@ strength_reduce (loop, insn_count, flags)\n   struct loop_regs *regs = LOOP_REGS (loop);\n   struct loop_ivs *ivs = LOOP_IVS (loop);\n   rtx p;\n-  /* Temporary list pointers for traversing ivs->loop_iv_list.  */\n-  struct iv_class *bl, **backbl;\n+  /* Temporary list pointer for traversing ivs->loop_iv_list.  */\n+  struct iv_class *bl;\n   /* Ratio of extra register life span we can justify\n      for saving an instruction.  More if loop doesn't call subroutines\n      since in that case saving an insn makes more difference\n@@ -3907,12 +4291,8 @@ strength_reduce (loop, insn_count, flags)\n   /* Map of pseudo-register replacements.  */\n   rtx *reg_map = NULL;\n   int reg_map_size;\n-  int call_seen;\n-  rtx test;\n   rtx end_insert_before;\n   int unrolled_insn_copies = 0;\n-  rtx loop_start = loop->start;\n-  rtx loop_end = loop->end;\n   rtx test_reg = gen_rtx_REG (word_mode, LAST_VIRTUAL_REGISTER + 1);\n \n   addr_placeholder = gen_reg_rtx (Pmode);\n@@ -3924,10 +4304,10 @@ strength_reduce (loop, insn_count, flags)\n      If loop_end is the end of the current function, then emit a\n      NOTE_INSN_DELETED after loop_end and set end_insert_before to the\n      dummy note insn.  */\n-  if (NEXT_INSN (loop_end) != 0)\n-    end_insert_before = NEXT_INSN (loop_end);\n+  if (NEXT_INSN (loop->end) != 0)\n+    end_insert_before = NEXT_INSN (loop->end);\n   else\n-    end_insert_before = emit_note_after (NOTE_INSN_DELETED, loop_end);\n+    end_insert_before = emit_note_after (NOTE_INSN_DELETED, loop->end);\n \n \n   /* Find all BIVs in loop.  */\n@@ -3985,25 +4365,10 @@ strength_reduce (loop, insn_count, flags)\n     {\n       struct induction *v;\n       int benefit;\n-      int all_reduced;\n-      rtx final_value = 0;\n       \n       /* Test whether it will be possible to eliminate this biv\n \t provided all givs are reduced.  */\n-      if (!(bl->eliminable = loop_biv_eliminable_p (loop, bl, \n-\t\t\t\t\t\t    threshold, insn_count)))\n-\t{\n-\t  if (loop_dump_stream)\n-\t    {\n-\t      fprintf (loop_dump_stream,\n-\t\t       \"Cannot eliminate biv %d.\\n\",\n-\t\t       bl->regno);\n-\t      fprintf (loop_dump_stream,\n-\t\t       \"First use: insn %d, last use: insn %d.\\n\",\n-\t\t       REGNO_FIRST_UID (bl->regno),\n-\t\t       REGNO_LAST_UID (bl->regno));\n-\t    }\n-\t}\n+      bl->eliminable = loop_biv_eliminable_p (loop, bl, threshold, insn_count);\n \n       /* Check each extension dependent giv in this class to see if its\n \t root biv is safe from wrapping in the interior mode.  */\n@@ -4015,80 +4380,19 @@ strength_reduce (loop, insn_count, flags)\n       /* This will be true at the end, if all givs which depend on this\n \t biv have been strength reduced.\n \t We can't (currently) eliminate the biv unless this is so.  */\n-      all_reduced = 1;\n+      bl->all_reduced = 1;\n \n-      /* Check each giv in this class to see if we will benefit by reducing\n-\t it.  Skip giv's combined with others.  */\n       for (v = bl->giv; v; v = v->next_iv)\n \t{\n \t  struct induction *tv;\n-\t  int add_cost;\n \n \t  if (v->ignore || v->same)\n \t    continue;\n \n-\t  benefit = v->benefit;\n-\t  PUT_MODE (test_reg, v->mode);\n-\t  add_cost = iv_add_mult_cost (bl->biv->add_val, v->mult_val,\n-\t\t\t\t       test_reg, test_reg);\n-\n-\t  /* Reduce benefit if not replaceable, since we will insert\n-\t     a move-insn to replace the insn that calculates this giv.\n-\t     Don't do this unless the giv is a user variable, since it\n-\t     will often be marked non-replaceable because of the duplication\n-\t     of the exit code outside the loop.  In such a case, the copies\n-\t     we insert are dead and will be deleted.  So they don't have\n-\t     a cost.  Similar situations exist.  */\n-\t  /* ??? The new final_[bg]iv_value code does a much better job\n-\t     of finding replaceable giv's, and hence this code may no longer\n-\t     be necessary.  */\n-\t  if (! v->replaceable && ! bl->eliminable\n-\t      && REG_USERVAR_P (v->dest_reg))\n-\t    benefit -= copy_cost;\n-\n-\t  /* Decrease the benefit to count the add-insns that we will\n-\t     insert to increment the reduced reg for the giv.\n-\t     ??? This can overestimate the run-time cost of the additional\n-\t     insns, e.g. if there are multiple basic blocks that increment\n-\t     the biv, but only one of these blocks is executed during each\n-\t     iteration.  There is no good way to detect cases like this with\n-\t     the current structure of the loop optimizer.\n-\t     This code is more accurate for determining code size than\n-\t     run-time benefits.  */\n-\t  benefit -= add_cost * bl->biv_count;\n-\n-\t  /* Decide whether to strength-reduce this giv or to leave the code\n-\t     unchanged (recompute it from the biv each time it is used).\n-\t     This decision can be made independently for each giv.  */\n-\n-#ifdef AUTO_INC_DEC\n-\t  /* Attempt to guess whether autoincrement will handle some of the\n-\t     new add insns; if so, increase BENEFIT (undo the subtraction of\n-\t     add_cost that was done above).  */\n-\t  if (v->giv_type == DEST_ADDR\n-\t      /* Increasing the benefit is risky, since this is only a guess.\n-\t\t Avoid increasing register pressure in cases where there would\n-\t\t be no other benefit from reducing this giv.  */\n-\t      && benefit > 0\n-\t      && GET_CODE (v->mult_val) == CONST_INT)\n-\t    {\n-\t      if (HAVE_POST_INCREMENT\n-\t\t  && INTVAL (v->mult_val) == GET_MODE_SIZE (v->mem_mode))\n-\t\tbenefit += add_cost * bl->biv_count;\n-\t      else if (HAVE_PRE_INCREMENT\n-\t\t       && INTVAL (v->mult_val) == GET_MODE_SIZE (v->mem_mode))\n-\t\tbenefit += add_cost * bl->biv_count;\n-\t      else if (HAVE_POST_DECREMENT\n-\t\t       && -INTVAL (v->mult_val) == GET_MODE_SIZE (v->mem_mode))\n-\t\tbenefit += add_cost * bl->biv_count;\n-\t      else if (HAVE_PRE_DECREMENT\n-\t\t       && -INTVAL (v->mult_val) == GET_MODE_SIZE (v->mem_mode))\n-\t\tbenefit += add_cost * bl->biv_count;\n-\t    }\n-#endif\n+\t  benefit = loop_giv_reduce_benefit (loop, bl, v, test_reg);\n \n \t  /* If an insn is not to be strength reduced, then set its ignore\n-\t     flag, and clear all_reduced.  */\n+\t     flag, and clear bl->all_reduced.  */\n \n \t  /* A giv that depends on a reversed biv must be reduced if it is\n \t     used after the loop exit, otherwise, it would have the wrong\n@@ -4106,7 +4410,7 @@ strength_reduce (loop, insn_count, flags)\n \t\t\t INSN_UID (v->insn),\n \t\t\t v->lifetime * threshold * benefit, insn_count);\n \t      v->ignore = 1;\n-\t      all_reduced = 0;\n+\t      bl->all_reduced = 0;\n \t    }\n \t  else\n \t    {\n@@ -4122,7 +4426,7 @@ strength_reduce (loop, insn_count, flags)\n \t\t\t       \"giv of insn %d: would need a multiply.\\n\",\n \t\t\t       INSN_UID (v->insn));\n \t\t    v->ignore = 1;\n-\t\t    all_reduced = 0;\n+\t\t    bl->all_reduced = 0;\n \t\t    break;\n \t\t  }\n \t    }\n@@ -4132,286 +4436,18 @@ strength_reduce (loop, insn_count, flags)\n \t last use is the definition of another giv.  If so, it is likely\n \t dead and should not be used to derive another giv nor to\n \t eliminate a biv.  */\n-      for (v = bl->giv; v; v = v->next_iv)\n-\t{\n-\t  if (v->ignore\n-\t      || (v->same && v->same->ignore))\n-\t    continue;\n-\n-\t  if (v->giv_type == DEST_REG\n-\t      && REGNO_FIRST_UID (REGNO (v->dest_reg)) == INSN_UID (v->insn))\n-\t    {\n-\t      struct induction *v1;\n-\n-\t      for (v1 = bl->giv; v1; v1 = v1->next_iv)\n-\t\tif (REGNO_LAST_UID (REGNO (v->dest_reg)) == INSN_UID (v1->insn))\n-\t\t  v->maybe_dead = 1;\n-\t    }\n-\t}\n+      loop_givs_dead_check (loop, bl);\n \n       /* Reduce each giv that we decided to reduce.  */\n-\n-      for (v = bl->giv; v; v = v->next_iv)\n-\t{\n-\t  struct induction *tv;\n-\t  if (! v->ignore && v->same == 0)\n-\t    {\n-\t      int auto_inc_opt = 0;\n-\n-\t      /* If the code for derived givs immediately below has already\n-\t\t allocated a new_reg, we must keep it.  */\n-\t      if (! v->new_reg)\n-\t\tv->new_reg = gen_reg_rtx (v->mode);\n-\n-#ifdef AUTO_INC_DEC\n-\t      /* If the target has auto-increment addressing modes, and\n-\t\t this is an address giv, then try to put the increment\n-\t\t immediately after its use, so that flow can create an\n-\t\t auto-increment addressing mode.  */\n-\t      if (v->giv_type == DEST_ADDR && bl->biv_count == 1\n-\t\t  && bl->biv->always_executed && ! bl->biv->maybe_multiple\n-\t\t  /* We don't handle reversed biv's because bl->biv->insn\n-\t\t     does not have a valid INSN_LUID.  */\n-\t\t  && ! bl->reversed\n-\t\t  && v->always_executed && ! v->maybe_multiple\n-\t\t  && INSN_UID (v->insn) < max_uid_for_loop)\n-\t\t{\n-\t\t  /* If other giv's have been combined with this one, then\n-\t\t     this will work only if all uses of the other giv's occur\n-\t\t     before this giv's insn.  This is difficult to check.\n-\n-\t\t     We simplify this by looking for the common case where\n-\t\t     there is one DEST_REG giv, and this giv's insn is the\n-\t\t     last use of the dest_reg of that DEST_REG giv.  If the\n-\t\t     increment occurs after the address giv, then we can\n-\t\t     perform the optimization.  (Otherwise, the increment\n-\t\t     would have to go before other_giv, and we would not be\n-\t\t     able to combine it with the address giv to get an\n-\t\t     auto-inc address.)  */\n-\t\t  if (v->combined_with)\n-\t\t    {\n-\t\t      struct induction *other_giv = 0;\n-\n-\t\t      for (tv = bl->giv; tv; tv = tv->next_iv)\n-\t\t\tif (tv->same == v)\n-\t\t\t  {\n-\t\t\t    if (other_giv)\n-\t\t\t      break;\n-\t\t\t    else\n-\t\t\t      other_giv = tv;\n-\t\t\t  }\n-\t\t      if (! tv && other_giv\n-\t\t\t  && REGNO (other_giv->dest_reg) < max_reg_before_loop\n-\t\t\t  && (REGNO_LAST_UID (REGNO (other_giv->dest_reg))\n-\t\t\t      == INSN_UID (v->insn))\n-\t\t\t  && INSN_LUID (v->insn) < INSN_LUID (bl->biv->insn))\n-\t\t\tauto_inc_opt = 1;\n-\t\t    }\n-\t\t  /* Check for case where increment is before the address\n-\t\t     giv.  Do this test in \"loop order\".  */\n-\t\t  else if ((INSN_LUID (v->insn) > INSN_LUID (bl->biv->insn)\n-\t\t\t    && (INSN_LUID (v->insn) < INSN_LUID (loop->scan_start)\n-\t\t\t\t|| (INSN_LUID (bl->biv->insn)\n-\t\t\t\t    > INSN_LUID (loop->scan_start))))\n-\t\t\t   || (INSN_LUID (v->insn) < INSN_LUID (loop->scan_start)\n-\t\t\t       && (INSN_LUID (loop->scan_start)\n-\t\t\t\t   < INSN_LUID (bl->biv->insn))))\n-\t\t    auto_inc_opt = -1;\n-\t\t  else\n-\t\t    auto_inc_opt = 1;\n-\n-#ifdef HAVE_cc0\n-\t\t  {\n-\t\t    rtx prev;\n-\n-\t\t    /* We can't put an insn immediately after one setting\n-\t\t       cc0, or immediately before one using cc0.  */\n-\t\t    if ((auto_inc_opt == 1 && sets_cc0_p (PATTERN (v->insn)))\n-\t\t\t|| (auto_inc_opt == -1\n-\t\t\t    && (prev = prev_nonnote_insn (v->insn)) != 0\n-\t\t\t    && INSN_P (prev)\n-\t\t\t    && sets_cc0_p (PATTERN (prev))))\n-\t\t      auto_inc_opt = 0;\n-\t\t  }\n-#endif\n-\n-\t\t  if (auto_inc_opt)\n-\t\t    v->auto_inc_opt = 1;\n-\t\t}\n-#endif\n-\n-\t      /* For each place where the biv is incremented, add an insn\n-\t\t to increment the new, reduced reg for the giv.  */\n-\t      for (tv = bl->biv; tv; tv = tv->next_iv)\n-\t\t{\n-\t\t  rtx insert_before;\n-\n-\t\t  if (! auto_inc_opt)\n-\t\t    insert_before = tv->insn;\n-\t\t  else if (auto_inc_opt == 1)\n-\t\t    insert_before = NEXT_INSN (v->insn);\n-\t\t  else\n-\t\t    insert_before = v->insn;\n-\n-\t\t  if (tv->mult_val == const1_rtx)\n-\t\t    emit_iv_add_mult (tv->add_val, v->mult_val,\n-\t\t\t\t      v->new_reg, v->new_reg, insert_before);\n-\t\t  else /* tv->mult_val == const0_rtx */\n-\t\t    /* A multiply is acceptable here\n-\t\t       since this is presumed to be seldom executed.  */\n-\t\t    emit_iv_add_mult (tv->add_val, v->mult_val,\n-\t\t\t\t      v->add_val, v->new_reg, insert_before);\n-\t\t}\n-\n-\t      /* Add code at loop start to initialize giv's reduced reg.  */\n-\n-\t      emit_iv_add_mult (extend_value_for_giv (v, bl->initial_value),\n-\t\t\t\tv->mult_val, v->add_val, v->new_reg,\n-\t\t\t\tloop_start);\n-\t    }\n-\t}\n+      loop_givs_reduce (loop, bl);\n \n       /* Rescan all givs.  If a giv is the same as a giv not reduced, mark it\n \t as not reduced.\n \n \t For each giv register that can be reduced now: if replaceable,\n \t substitute reduced reg wherever the old giv occurs;\n \t else add new move insn \"giv_reg = reduced_reg\".  */\n-\n-      for (v = bl->giv; v; v = v->next_iv)\n-\t{\n-\t  if (v->same && v->same->ignore)\n-\t    v->ignore = 1;\n-\n-\t  if (v->ignore)\n-\t    continue;\n-\n-\t  /* Update expression if this was combined, in case other giv was\n-\t     replaced.  */\n-\t  if (v->same)\n-\t    v->new_reg = replace_rtx (v->new_reg,\n-\t\t\t\t      v->same->dest_reg, v->same->new_reg);\n-\n-\t  /* See if this register is known to be a pointer to something.  If\n-\t     so, see if we can find the alignment.  First see if there is a\n-\t     destination register that is a pointer.  If so, this shares the\n-\t     alignment too.  Next see if we can deduce anything from the\n-\t     computational information.  If not, and this is a DEST_ADDR\n-\t     giv, at least we know that it's a pointer, though we don't know\n-\t     the alignment.  */\n-\t  if (GET_CODE (v->new_reg) == REG\n-\t      && v->giv_type == DEST_REG\n-\t      && REG_POINTER (v->dest_reg))\n-\t    mark_reg_pointer (v->new_reg,\n-\t\t\t      REGNO_POINTER_ALIGN (REGNO (v->dest_reg)));\n-\t  else if (GET_CODE (v->new_reg) == REG\n-\t\t   && REG_POINTER (v->src_reg))\n-\t    {\n-\t      unsigned int align = REGNO_POINTER_ALIGN (REGNO (v->src_reg));\n-\n-\t      if (align == 0\n-\t\t  || GET_CODE (v->add_val) != CONST_INT\n-\t\t  || INTVAL (v->add_val) % (align / BITS_PER_UNIT) != 0)\n-\t\talign = 0;\n-\n-\t      mark_reg_pointer (v->new_reg, align);\n-\t    }\n-\t  else if (GET_CODE (v->new_reg) == REG\n-\t\t   && GET_CODE (v->add_val) == REG\n-\t\t   && REG_POINTER (v->add_val))\n-\t    {\n-\t      unsigned int align = REGNO_POINTER_ALIGN (REGNO (v->add_val));\n-\n-\t      if (align == 0 || GET_CODE (v->mult_val) != CONST_INT\n-\t\t  || INTVAL (v->mult_val) % (align / BITS_PER_UNIT) != 0)\n-\t\talign = 0;\n-\n-\t      mark_reg_pointer (v->new_reg, align);\n-\t    }\n-\t  else if (GET_CODE (v->new_reg) == REG && v->giv_type == DEST_ADDR)\n-\t    mark_reg_pointer (v->new_reg, 0);\n-\n-\t  if (v->giv_type == DEST_ADDR)\n-\t    /* Store reduced reg as the address in the memref where we found\n-\t       this giv.  */\n-\t    validate_change (v->insn, v->location, v->new_reg, 0);\n-\t  else if (v->replaceable)\n-\t    {\n-\t      reg_map[REGNO (v->dest_reg)] = v->new_reg;\n-\n-#if 0\n-\t      /* I can no longer duplicate the original problem.  Perhaps\n-\t\t this is unnecessary now?  */\n-\n-\t      /* Replaceable; it isn't strictly necessary to delete the old\n-\t\t insn and emit a new one, because v->dest_reg is now dead.\n-\n-\t\t However, especially when unrolling loops, the special\n-\t\t handling for (set REG0 REG1) in the second cse pass may\n-\t\t make v->dest_reg live again.  To avoid this problem, emit\n-\t\t an insn to set the original giv reg from the reduced giv.\n-\t\t We can not delete the original insn, since it may be part\n-\t\t of a LIBCALL, and the code in flow that eliminates dead\n-\t\t libcalls will fail if it is deleted.  */\n-\t      emit_insn_after (gen_move_insn (v->dest_reg, v->new_reg),\n-\t\t\t       v->insn);\n-#endif\n-\t    }\n-\t  else\n-\t    {\n-\t      /* Not replaceable; emit an insn to set the original giv reg from\n-\t\t the reduced giv, same as above.  */\n-\t      emit_insn_after (gen_move_insn (v->dest_reg, v->new_reg),\n-\t\t\t       v->insn);\n-\t    }\n-\n-\t  /* When a loop is reversed, givs which depend on the reversed\n-\t     biv, and which are live outside the loop, must be set to their\n-\t     correct final value.  This insn is only needed if the giv is\n-\t     not replaceable.  The correct final value is the same as the\n-\t     value that the giv starts the reversed loop with.  */\n-\t  if (bl->reversed && ! v->replaceable)\n-\t    emit_iv_add_mult (extend_value_for_giv (v, bl->initial_value),\n-\t\t\t      v->mult_val, v->add_val, v->dest_reg,\n-\t\t\t      end_insert_before);\n-\t  else if (v->final_value)\n-\t    {\n-\t      rtx insert_before;\n-\n-\t      /* If the loop has multiple exits, emit the insn before the\n-\t\t loop to ensure that it will always be executed no matter\n-\t\t how the loop exits.  Otherwise, emit the insn after the loop,\n-\t\t since this is slightly more efficient.  */\n-\t      if (loop->exit_count)\n-\t\tinsert_before = loop_start;\n-\t      else\n-\t\tinsert_before = end_insert_before;\n-\t      emit_insn_before (gen_move_insn (v->dest_reg, v->final_value),\n-\t\t\t\tinsert_before);\n-\n-#if 0\n-\t      /* If the insn to set the final value of the giv was emitted\n-\t\t before the loop, then we must delete the insn inside the loop\n-\t\t that sets it.  If this is a LIBCALL, then we must delete\n-\t\t every insn in the libcall.  Note, however, that\n-\t\t final_giv_value will only succeed when there are multiple\n-\t\t exits if the giv is dead at each exit, hence it does not\n-\t\t matter that the original insn remains because it is dead\n-\t\t anyways.  */\n-\t      /* Delete the insn inside the loop that sets the giv since\n-\t\t the giv is now set before (or after) the loop.  */\n-\t      delete_insn (v->insn);\n-#endif\n-\t    }\n-\n-\t  if (loop_dump_stream)\n-\t    {\n-\t      fprintf (loop_dump_stream, \"giv at %d reduced to \",\n-\t\t       INSN_UID (v->insn));\n-\t      print_rtl (loop_dump_stream, v->new_reg);\n-\t      fprintf (loop_dump_stream, \"\\n\");\n-\t    }\n-\t}\n+      loop_givs_rescan (loop, bl, reg_map, end_insert_before);\n \n       /* All the givs based on the biv bl have been reduced if they\n \t merit it.  */\n@@ -4421,23 +4457,23 @@ strength_reduce (loop, insn_count, flags)\n \t v->new_reg will either be or refer to the register of the giv it\n \t combined with.\n \n-\t Doing this clearing avoids problems in biv elimination where a\n-\t giv's new_reg is a complex value that can't be put in the insn but\n-\t the giv combined with (with a reg as new_reg) is marked maybe_dead.\n-\t Since the register will be used in either case, we'd prefer it be\n-\t used from the simpler giv.  */\n+\t Doing this clearing avoids problems in biv elimination where\n+\t a giv's new_reg is a complex value that can't be put in the\n+\t insn but the giv combined with (with a reg as new_reg) is\n+\t marked maybe_dead.  Since the register will be used in either\n+\t case, we'd prefer it be used from the simpler giv.  */\n \n       for (v = bl->giv; v; v = v->next_iv)\n \tif (! v->maybe_dead && v->same)\n \t  v->same->maybe_dead = 0;\n \n       /* Try to eliminate the biv, if it is a candidate.\n-\t This won't work if ! all_reduced,\n+\t This won't work if ! bl->all_reduced,\n \t since the givs we planned to use might not have been reduced.\n \n-\t We have to be careful that we didn't initially think we could eliminate\n-\t this biv because of a giv that we now think may be dead and shouldn't\n-\t be used as a biv replacement.\n+\t We have to be careful that we didn't initially think we could\n+\t eliminate this biv because of a giv that we now think may be\n+\t dead and shouldn't be used as a biv replacement.\n \n \t Also, there is the possibility that we may have a giv that looks\n \t like it can be used to eliminate a biv, but the resulting insn\n@@ -4449,7 +4485,7 @@ strength_reduce (loop, insn_count, flags)\n \t of the occurrences of the biv with a giv, but no harm was done in\n \t doing so in the rare cases where it can occur.  */\n \n-      if (all_reduced == 1 && bl->eliminable\n+      if (bl->all_reduced == 1 && bl->eliminable\n \t  && maybe_eliminate_biv (loop, bl, 1, threshold, insn_count))\n \t{\n \t  /* ?? If we created a new test to bypass the loop entirely,\n@@ -4464,7 +4500,7 @@ strength_reduce (loop, insn_count, flags)\n \t     Reversed bivs already have an insn after the loop setting their\n \t     value, so we don't need another one.  We can't calculate the\n \t     proper final value for such a biv here anyways.  */\n-\t  if (final_value != 0 && ! bl->reversed)\n+\t  if (bl->final_value && ! bl->reversed)\n \t    {\n \t      rtx insert_before;\n \n@@ -4473,27 +4509,15 @@ strength_reduce (loop, insn_count, flags)\n \t\t how the loop exits.  Otherwise, emit the insn after the\n \t\t loop, since this is slightly more efficient.  */\n \t      if (loop->exit_count)\n-\t\tinsert_before = loop_start;\n+\t\tinsert_before = loop->start;\n \t      else\n \t\tinsert_before = end_insert_before;\n \n-\t      emit_insn_before (gen_move_insn (bl->biv->dest_reg, final_value),\n+\t      emit_insn_before (gen_move_insn (bl->biv->dest_reg, \n+\t\t\t\t\t       bl->final_value),\n \t\t\t\tend_insert_before);\n \t    }\n \n-#if 0\n-\t  /* Delete all of the instructions inside the loop which set\n-\t     the biv, as they are all dead.  If is safe to delete them,\n-\t     because an insn setting a biv will never be part of a libcall.  */\n-\t  /* However, deleting them will invalidate the regno_last_uid info,\n-\t     so keeping them around is more convenient.  Final_biv_value\n-\t     will only succeed when there are multiple exits if the biv\n-\t     is dead at each exit, hence it does not matter that the original\n-\t     insn remains, because it is dead anyways.  */\n-\t  for (v = bl->biv; v; v = v->next_iv)\n-\t    delete_insn (v->insn);\n-#endif\n-\n \t  if (loop_dump_stream)\n \t    fprintf (loop_dump_stream, \"Reg %d: biv eliminated\\n\",\n \t\t     bl->regno);\n@@ -4503,7 +4527,7 @@ strength_reduce (loop, insn_count, flags)\n   /* Go through all the instructions in the loop, making all the\n      register substitutions scheduled in REG_MAP.  */\n \n-  for (p = loop_start; p != loop_end; p = NEXT_INSN (p))\n+  for (p = loop->start; p != loop->end; p = NEXT_INSN (p))\n     if (GET_CODE (p) == INSN || GET_CODE (p) == JUMP_INSN\n \t|| GET_CODE (p) == CALL_INSN)\n       {\n@@ -4906,6 +4930,7 @@ record_biv (loop, v, insn, dest_reg, inc_val, mult_val, location,\n \n       /* Set initial value to the reg itself.  */\n       bl->initial_value = dest_reg;\n+      bl->final_value = 0;\n       /* We haven't seen the initializing insn yet */\n       bl->init_insn = 0;\n       bl->init_set = 0;"}, {"sha": "bea5a808e724fad360782a63d7a3519dcdb66112", "filename": "gcc/loop.h", "status": "modified", "additions": 13, "deletions": 6, "changes": 19, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/e304a8e61a5970791a71e4a4f35509e9574202b7/gcc%2Floop.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/e304a8e61a5970791a71e4a4f35509e9574202b7/gcc%2Floop.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Floop.h?ref=e304a8e61a5970791a71e4a4f35509e9574202b7", "patch": "@@ -164,17 +164,22 @@ struct iv_class\n \t\t\t\t   check_dbra_loop.  */\n   struct induction *giv;\t/* List of all insns that compute a giv\n \t\t\t\t   from this reg.  */\n-  int total_benefit;\t\t/* Sum of BENEFITs of all those givs */\n-  rtx initial_value;\t\t/* Value of reg at loop start */\n-  rtx initial_test;\t\t/* Test performed on BIV before loop */\n-  struct iv_class *next;\t/* Links all class structures together */\n+  int total_benefit;\t\t/* Sum of BENEFITs of all those givs.  */\n+  rtx initial_value;\t\t/* Value of reg at loop start.  */\n+  rtx initial_test;\t\t/* Test performed on BIV before loop.  */\n+  rtx final_value;\t\t/* Value of reg at loop end, if known.  */\n+  struct iv_class *next;\t/* Links all class structures together.  */\n   rtx init_insn;\t\t/* insn which initializes biv, 0 if none.  */\n   rtx init_set;\t\t\t/* SET of INIT_INSN, if any.  */\n   unsigned incremented : 1;\t/* 1 if somewhere incremented/decremented */\n-  unsigned eliminable : 1;\t/* 1 if plausible candidate for elimination.  */\n-  unsigned nonneg : 1;\t\t/* 1 if we added a REG_NONNEG note for this.  */\n+  unsigned eliminable : 1;\t/* 1 if plausible candidate for\n+                                   elimination.  */\n+  unsigned nonneg : 1;\t\t/* 1 if we added a REG_NONNEG note for\n+                                   this.  */\n   unsigned reversed : 1;\t/* 1 if we reversed the loop that this\n \t\t\t\t   biv controls.  */\n+  unsigned all_reduced : 1;\t/* 1 if all givs using this biv have\n+                                   been reduced. */\n };\n \n typedef struct loop_mem_info\n@@ -333,6 +338,8 @@ struct loop_info\n   struct loop_regs regs;\n   /* The induction variable information in loop.  */\n   struct loop_ivs ivs;\n+  /* Non-zero if call is in pre_header extended basic block.  */\n+  int pre_header_has_call;\n };\n \n /* Definitions used by the basic induction variable discovery code.  */"}]}