{"sha": "c162c75e43f4813cd30a1d4a693ce20f35a3f9fb", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YzE2MmM3NWU0M2Y0ODEzY2QzMGExZDRhNjkzY2UyMGYzNWEzZjlmYg==", "commit": {"author": {"name": "Matt Austern", "email": "austern@apple.com", "date": "2004-09-21T02:22:45Z"}, "committer": {"name": "Zack Weinberg", "email": "zack@gcc.gnu.org", "date": "2004-09-21T02:22:45Z"}, "message": "c-common.c (fix_string_type): Build the unqualified array type unconditionally...\n\n2004-09-20  Matt Austern <austern@apple.com>\n\t    Zack Weinberg  <zack@codesourcery.com>\n\n\t* c-common.c (fix_string_type): Build the unqualified array\n\ttype unconditionally, then use c_build_qualified_type to get\n\tthe proper const-qualified variant, and set its\n\tTYPE_MAIN_VARIANT to refer to the unqualified type.\n\t* c-lex.c (c_lex_return_raw_string): New global.\n\t(c_lex_with_flags): Honor it.\n\t* c-pragma.h: Declare it.\n\ncp:\n\t* decl.c (make_rtl_for_nonlocal_decl, start_preparsed_function):\n\tApply lbasename to input_filename before passing to get_fileinfo.\n\t* semantics.c (begin_class_definition): Likewise.\n\t* lex.c (handle_pragma_interface): Apply get_fileinfo to the\n\tcorrect filename.  Rename variables to be less confusing.\n\t(handle_pragma_implementation): Likewise.  Disable \"appears\n\tafter file is included\" diagnostic.\n\n\t* parser.c (struct cp_token): Add in_system_header fiag.\n\t(CP_TOKEN_BLOCK_NUM_TOKENS, struct cp_token_block)\n\t(CP_TOKEN_BUFFER_SIZE, cp_token_cache_push_token)\n\t(CPP_NONE, cp_lexer_read_token): Delete.\n\t(struct cp_lexer): Remove first_token, string_tokens,\n\tmain_lexer_p fields.  Clarify comments.\n\t(struct cp_token_cache): Now just a pair of pointers.\n\t(CP_LEXER_BUFFER_SIZE): New #define.\n\t(CPP_PURGED): New fake token type.\n\t(cp_lexer_new_from_token_array, cp_lexer_destroy)\n\t(cp_lexer_peek_token_emit_debug_info, cp_lexer_skip_purged_tokens)\n\t(cp_lexer_handle_pragma, cp_token_cache_new, cp_parser_string_literal):\n\tNew functions.\n\t(cp_lexer_new_from_tokens): Now a simple wrapper around\n\tcp_lexer_new_from_token_array.\n\t(cp_lexer_set_source_position_from_token): Also update\n\tin_system_header.\n\t(cp_lexer_next_token, cp_lexer_prev_token, cp_lexer_advance_token):\n\tDon't wrap round.\n\t(cp_lexer_token_difference): Dont handle wrapping round.\n\t(cp_lexer_new_main): Enable pragma deferral and raw strings,\n\tread the entire translation unit through c_lex_with_flags into\n\tthis lexer's buffer, then turn raw strings back off again.\n\t(cp_lexer_grow_buffer): Adjust for buffer no longer being circular.\n\t(cp_lexer_get_preprocessor_token): No need to handle not being\n\tthe main lexer.  Set token->in_system_header too.\n\t(cp_lexer_peek_token): Skip purged tokens.  Feed pragma tokens\n\tto cp_lexer_handle_pragma.  No need to call cp_lexer_read_token.\n\t(cp_lexer_peek_nth_token): Likewise.\n\t(cp_lexer_purge_token): Mark the token PURGED, don't shift all\n\tthe other tokens down.\n\t(cp_lexer_purge_tokens_after): Likewise.\n\t(cp_lexer_save_tokens, cp_lexer_rollback_tokens): Don't worry\n\tabout there being no tokens.\n\t(cp_lexer_print_token): Revise to give useful information on\n\tall tokens.\n\t(struct cp_parser): Add field translate_strings_p.\n\t(cp_parser_new): Initialize it.\n\t(cp_parser_translation_unit): Destroy the lexer when done.\n\t(cp_parser_parameter_declaration): Restructure saving of\n\tdefault arguments.\n\t(cp_parser_save_member_function_body): Likewise.\n\t(cp_parser_check_for_invalid_template_id)\n\t(cp_parser_nested_name_specifier_opt, cp_parser_template_id):\n\tAdjust calls to cp_lexer_advance_token.\n\t(cp_parser_skip_to_closing_parenthesis, cp_parser_declaration):\n\tNo need to fiddle c_lex_string_translate.\n\t(cp_parser_primary_expression, cp_parser_linkage_specification)\n\t(cp_parser_asm_definition, cp_parser_asm_specification_opt)\n\t(cp_parser_asm_operand_list, cp_parser_asm_clobber_list)\n\tUse cp_parser_string_literal.\n\t(cp_parser_attribute_list): Save and restore\n\tparser->translate_strings_p, not c_lex_string_translate.\n\t(cp_parser_cache_group): Delete.\n\t(cp_parser_cache_group_1): Rename cp_parser_cache_group.  Do\n\tnot take a cache argument.\n\nFrom-SVN: r87786", "tree": {"sha": "f002886f8df77ba4f971f13ad13d646fe43bff5a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/f002886f8df77ba4f971f13ad13d646fe43bff5a"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/comments", "author": null, "committer": null, "parents": [{"sha": "5cfa876635638a93a8d6d209ce700beb373b9c1d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5cfa876635638a93a8d6d209ce700beb373b9c1d", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5cfa876635638a93a8d6d209ce700beb373b9c1d"}], "stats": {"total": 1233, "additions": 594, "deletions": 639}, "files": [{"sha": "c3fba00641bac280636f4589f9d49a054a417d3b", "filename": "gcc/ChangeLog", "status": "modified", "additions": 12, "deletions": 1, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=c162c75e43f4813cd30a1d4a693ce20f35a3f9fb", "patch": "@@ -1,3 +1,14 @@\n+2004-09-20  Matt Austern <austern@apple.com>\n+\t    Zack Weinberg  <zack@codesourcery.com>\n+\n+\t* c-common.c (fix_string_type): Build the unqualified array\n+\ttype unconditionally, then use c_build_qualified_type to get\n+\tthe proper const-qualified variant, and set its\n+\tTYPE_MAIN_VARIANT to refer to the unqualified type.\n+\t* c-lex.c (c_lex_return_raw_string): New global.\n+\t(c_lex_with_flags): Honor it.\n+\t* c-pragma.h: Declare it.\n+\n 2004-09-20  Daniel Berlin  <dberlin@dberlin.org>\n \n \t* Makefile.in: Fix flags.h dependencies to be $(FLAGS_H).\n@@ -79,7 +90,7 @@\n \n 2004-09-20  Daniel Berlin  <dberlin@dberlin.org>\n \n-\t* tree-ssa-pre.c (compute_antic_aux): Use malloc'd worklist, to avoid \n+\t* tree-ssa-pre.c (compute_antic_aux): Use malloc'd worklist, to avoid\n \tgenerating useless garbage.\n \n 2004-09-20  Paolo Bonzini  <bonzini@gnu.org>"}, {"sha": "7eda4d115d917df9c0f90ed3dc5f411bde3f7d70", "filename": "gcc/c-common.c", "status": "modified", "additions": 22, "deletions": 9, "changes": 31, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fc-common.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fc-common.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-common.c?ref=c162c75e43f4813cd30a1d4a693ce20f35a3f9fb", "patch": "@@ -843,8 +843,8 @@ fix_string_type (tree value)\n   const int nchars_max = flag_isoc99 ? 4095 : 509;\n   int length = TREE_STRING_LENGTH (value);\n   int nchars;\n-  tree e_type, i_type;\n-  \n+  tree e_type, i_type, a_type;\n+\n   /* Compute the number of elements, for the array type.  */\n   nchars = wide_flag ? length / wchar_bytes : length;\n \n@@ -853,15 +853,28 @@ fix_string_type (tree value)\n \t     nchars - 1, nchars_max, flag_isoc99 ? 99 : 89);\n \n   e_type = wide_flag ? wchar_type_node : char_type_node;\n-  /* Create the array type for the string constant.\n-     -Wwrite-strings says make the string constant an array of const char\n-     so that copying it to a non-const pointer will get a warning.\n-     For C++, this is the standard behavior.  */\n-  if (flag_const_strings)\n-    e_type = build_type_variant (e_type, 1, 0);\n+  /* Create the array type for the string constant.  flag_const_strings\n+     says make the string constant an array of const char so that\n+     copying it to a non-const pointer will get a warning.  For C++,\n+     this is the standard behavior.\n+\n+     The C++ front end relies on TYPE_MAIN_VARIANT of a cv-qualified\n+     array type being the unqualified version of that type.\n+     Therefore, if we are constructing an array of const char, we must\n+     construct the matching unqualified array type first.  The C front\n+     end does not require this, but it does no harm, so we do it\n+     unconditionally.  */\n   i_type = build_index_type (build_int_cst (NULL_TREE, nchars - 1));\n-  TREE_TYPE (value) = build_array_type (e_type, i_type);\n+  a_type = build_array_type (e_type, i_type);\n+  if (flag_const_strings)\n+    {\n+      /* bleah, c_build_qualified_type should set TYPE_MAIN_VARIANT.  */\n+      tree qa_type = c_build_qualified_type (a_type, TYPE_QUAL_CONST);\n+      TYPE_MAIN_VARIANT (qa_type) = a_type;\n+      a_type = qa_type;\n+    }\n \n+  TREE_TYPE (value) = a_type;\n   TREE_CONSTANT (value) = 1;\n   TREE_INVARIANT (value) = 1;\n   TREE_READONLY (value) = 1;"}, {"sha": "aff84e0ec892e4e38386c131262988a91b8edadf", "filename": "gcc/c-lex.c", "status": "modified", "additions": 10, "deletions": 1, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fc-lex.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fc-lex.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-lex.c?ref=c162c75e43f4813cd30a1d4a693ce20f35a3f9fb", "patch": "@@ -60,6 +60,10 @@ int c_header_level;\t /* depth in C headers - C++ only */\n    to the untranslated one.  */\n int c_lex_string_translate = 1;\n \n+/* True if strings should be passed to the caller of c_lex completely\n+   unmolested (no concatenation, no translation).  */\n+bool c_lex_return_raw_strings = false;\n+\n static tree interpret_integer (const cpp_token *, unsigned int);\n static tree interpret_float (const cpp_token *, unsigned int);\n static enum integer_type_kind narrowest_unsigned_type\n@@ -428,7 +432,12 @@ c_lex_with_flags (tree *value, unsigned char *cpp_flags)\n \n     case CPP_STRING:\n     case CPP_WSTRING:\n-      return lex_string (tok, value, false);\n+      if (!c_lex_return_raw_strings)\n+\treturn lex_string (tok, value, false);\n+      /* else fall through */\n+\n+    case CPP_PRAGMA:\n+      *value = build_string (tok->val.str.len, (char *)tok->val.str.text);\n       break;\n \n       /* These tokens should not be visible outside cpplib.  */"}, {"sha": "92741ff5cb57304765dd227d6667b275b3fa57dd", "filename": "gcc/c-pragma.h", "status": "modified", "additions": 4, "deletions": 0, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fc-pragma.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fc-pragma.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fc-pragma.h?ref=c162c75e43f4813cd30a1d4a693ce20f35a3f9fb", "patch": "@@ -70,4 +70,8 @@ extern enum cpp_ttype c_lex_with_flags (tree *, unsigned char *);\n    is the TREE_CHAIN of the latter.  */\n extern int c_lex_string_translate;\n \n+/* If true, strings should be passed to the caller of c_lex completely\n+   unmolested (no concatenation, no translation).  */\n+extern bool c_lex_return_raw_strings;\n+\n #endif /* GCC_C_PRAGMA_H */"}, {"sha": "431e32ae6e5b490403f2631fb1ea5061e35d0d99", "filename": "gcc/cp/ChangeLog", "status": "modified", "additions": 68, "deletions": 0, "changes": 68, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fcp%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fcp%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2FChangeLog?ref=c162c75e43f4813cd30a1d4a693ce20f35a3f9fb", "patch": "@@ -1,3 +1,71 @@\n+2004-09-20  Matt Austern <austern@apple.com>\n+\t    Zack Weinberg  <zack@codesourcery.com>\n+\n+\t* decl.c (make_rtl_for_nonlocal_decl, start_preparsed_function):\n+\tApply lbasename to input_filename before passing to get_fileinfo.\n+\t* semantics.c (begin_class_definition): Likewise.\n+\t* lex.c (handle_pragma_interface): Apply get_fileinfo to the\n+\tcorrect filename.  Rename variables to be less confusing.\n+\t(handle_pragma_implementation): Likewise.  Disable \"appears\n+\tafter file is included\" diagnostic.\n+\n+\t* parser.c (struct cp_token): Add in_system_header fiag.\n+\t(CP_TOKEN_BLOCK_NUM_TOKENS, struct cp_token_block)\n+\t(CP_TOKEN_BUFFER_SIZE, cp_token_cache_push_token)\n+\t(CPP_NONE, cp_lexer_read_token): Delete.\n+\t(struct cp_lexer): Remove first_token, string_tokens,\n+\tmain_lexer_p fields.  Clarify comments.\n+\t(struct cp_token_cache): Now just a pair of pointers.\n+\t(CP_LEXER_BUFFER_SIZE): New #define.\n+\t(CPP_PURGED): New fake token type.\n+\t(cp_lexer_new_from_token_array, cp_lexer_destroy)\n+\t(cp_lexer_peek_token_emit_debug_info, cp_lexer_skip_purged_tokens)\n+\t(cp_lexer_handle_pragma, cp_token_cache_new, cp_parser_string_literal):\n+\tNew functions.\n+\t(cp_lexer_new_from_tokens): Now a simple wrapper around\n+\tcp_lexer_new_from_token_array.\n+\t(cp_lexer_set_source_position_from_token): Also update\n+\tin_system_header.\n+\t(cp_lexer_next_token, cp_lexer_prev_token, cp_lexer_advance_token):\n+\tDon't wrap round.\n+\t(cp_lexer_token_difference): Dont handle wrapping round.\n+\t(cp_lexer_new_main): Enable pragma deferral and raw strings,\n+\tread the entire translation unit through c_lex_with_flags into\n+\tthis lexer's buffer, then turn raw strings back off again.\n+\t(cp_lexer_grow_buffer): Adjust for buffer no longer being circular.\n+\t(cp_lexer_get_preprocessor_token): No need to handle not being\n+\tthe main lexer.  Set token->in_system_header too.\n+\t(cp_lexer_peek_token): Skip purged tokens.  Feed pragma tokens\n+\tto cp_lexer_handle_pragma.  No need to call cp_lexer_read_token.\n+\t(cp_lexer_peek_nth_token): Likewise.\n+\t(cp_lexer_purge_token): Mark the token PURGED, don't shift all\n+\tthe other tokens down.\n+\t(cp_lexer_purge_tokens_after): Likewise.\n+\t(cp_lexer_save_tokens, cp_lexer_rollback_tokens): Don't worry\n+\tabout there being no tokens.\n+\t(cp_lexer_print_token): Revise to give useful information on\n+\tall tokens.\n+\t(struct cp_parser): Add field translate_strings_p.\n+\t(cp_parser_new): Initialize it.\n+\t(cp_parser_translation_unit): Destroy the lexer when done.\n+\t(cp_parser_parameter_declaration): Restructure saving of\n+\tdefault arguments.\n+\t(cp_parser_save_member_function_body): Likewise.\n+\t(cp_parser_check_for_invalid_template_id)\n+\t(cp_parser_nested_name_specifier_opt, cp_parser_template_id):\n+\tAdjust calls to cp_lexer_advance_token.\n+\t(cp_parser_skip_to_closing_parenthesis, cp_parser_declaration):\n+\tNo need to fiddle c_lex_string_translate.\n+\t(cp_parser_primary_expression, cp_parser_linkage_specification)\n+\t(cp_parser_asm_definition, cp_parser_asm_specification_opt)\n+\t(cp_parser_asm_operand_list, cp_parser_asm_clobber_list)\n+\tUse cp_parser_string_literal.\n+\t(cp_parser_attribute_list): Save and restore\n+\tparser->translate_strings_p, not c_lex_string_translate.\n+\t(cp_parser_cache_group): Delete.\n+\t(cp_parser_cache_group_1): Rename cp_parser_cache_group.  Do\n+\tnot take a cache argument.\n+\n 2004-09-20  Giovanni Bajo  <giovannibajo@gcc.gnu.org>\n \n \tPR c++/14179"}, {"sha": "282e5072dadf4c1b2a63bdbb34f1228f92b22a17", "filename": "gcc/cp/decl.c", "status": "modified", "additions": 2, "deletions": 2, "changes": 4, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fcp%2Fdecl.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fcp%2Fdecl.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fdecl.c?ref=c162c75e43f4813cd30a1d4a693ce20f35a3f9fb", "patch": "@@ -4637,7 +4637,7 @@ make_rtl_for_nonlocal_decl (tree decl, tree init, const char* asmspec)\n     {\n       /* Fool with the linkage of static consts according to #pragma\n \t interface.  */\n-      struct c_fileinfo *finfo = get_fileinfo (input_filename);\n+      struct c_fileinfo *finfo = get_fileinfo (lbasename (input_filename));\n       if (!finfo->interface_unknown && !TREE_PUBLIC (decl))\n \t{\n \t  TREE_PUBLIC (decl) = 1;\n@@ -9729,7 +9729,7 @@ start_preparsed_function (tree decl1, tree attrs, int flags)\n   int doing_friend = 0;\n   struct cp_binding_level *bl;\n   tree current_function_parms;\n-  struct c_fileinfo *finfo = get_fileinfo (input_filename);\n+  struct c_fileinfo *finfo = get_fileinfo (lbasename (input_filename));\n \n   /* Sanity check.  */\n   gcc_assert (TREE_CODE (TREE_VALUE (void_list_node)) == VOID_TYPE);"}, {"sha": "82dc35ec999796dee84ad36654c6089ffc99cc33", "filename": "gcc/cp/lex.c", "status": "modified", "additions": 24, "deletions": 16, "changes": 40, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fcp%2Flex.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fcp%2Flex.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Flex.c?ref=c162c75e43f4813cd30a1d4a693ce20f35a3f9fb", "patch": "@@ -463,16 +463,16 @@ handle_pragma_interface (cpp_reader* dfile ATTRIBUTE_UNUSED )\n {\n   tree fname = parse_strconst_pragma (\"interface\", 1);\n   struct c_fileinfo *finfo;\n-  const char *main_filename;\n+  const char *filename;\n \n   if (fname == (tree)-1)\n     return;\n   else if (fname == 0)\n-    main_filename = lbasename (input_filename);\n+    filename = lbasename (input_filename);\n   else\n-    main_filename = ggc_strdup (TREE_STRING_POINTER (fname));\n+    filename = ggc_strdup (TREE_STRING_POINTER (fname));\n \n-  finfo = get_fileinfo (input_filename);\n+  finfo = get_fileinfo (filename);\n \n   if (impl_file_chain == 0)\n     {\n@@ -482,7 +482,7 @@ handle_pragma_interface (cpp_reader* dfile ATTRIBUTE_UNUSED )\n \tmain_input_filename = input_filename;\n     }\n \n-  finfo->interface_only = interface_strcmp (main_filename);\n+  finfo->interface_only = interface_strcmp (filename);\n   /* If MULTIPLE_SYMBOL_SPACES is set, we cannot assume that we can see\n      a definition in another file.  */\n   if (!MULTIPLE_SYMBOL_SPACES || !finfo->interface_only)\n@@ -502,7 +502,7 @@ static void\n handle_pragma_implementation (cpp_reader* dfile ATTRIBUTE_UNUSED )\n {\n   tree fname = parse_strconst_pragma (\"implementation\", 1);\n-  const char *main_filename;\n+  const char *filename;\n   struct impl_files *ifiles = impl_file_chain;\n \n   if (fname == (tree)-1)\n@@ -511,28 +511,36 @@ handle_pragma_implementation (cpp_reader* dfile ATTRIBUTE_UNUSED )\n   if (fname == 0)\n     {\n       if (main_input_filename)\n-\tmain_filename = main_input_filename;\n+\tfilename = main_input_filename;\n       else\n-\tmain_filename = input_filename;\n-      main_filename = lbasename (main_filename);\n+\tfilename = input_filename;\n+      filename = lbasename (filename);\n     }\n   else\n     {\n-      main_filename = ggc_strdup (TREE_STRING_POINTER (fname));\n-      if (cpp_included (parse_in, main_filename))\n-\twarning (\"#pragma implementation for %s appears after file is included\",\n-\t\t main_filename);\n+      filename = ggc_strdup (TREE_STRING_POINTER (fname));\n+#if 0\n+      /* We currently cannot give this diagnostic, as we reach this point\n+         only after cpplib has scanned the entire translation unit, so\n+\t cpp_included always returns true.  A plausible fix is to compare\n+\t the current source-location cookie with the first source-location\n+\t cookie (if any) of the filename, but this requires completing the\n+\t --enable-mapped-location project first.  See PR 17577.  */\n+      if (cpp_included (parse_in, filename))\n+\twarning (\"#pragma implementation for %qs appears after \"\n+\t\t \"file is included\", filename);\n+#endif\n     }\n \n   for (; ifiles; ifiles = ifiles->next)\n     {\n-      if (! strcmp (ifiles->filename, main_filename))\n+      if (! strcmp (ifiles->filename, filename))\n \tbreak;\n     }\n   if (ifiles == 0)\n     {\n       ifiles = xmalloc (sizeof (struct impl_files));\n-      ifiles->filename = main_filename;\n+      ifiles->filename = filename;\n       ifiles->next = impl_file_chain;\n       impl_file_chain = ifiles;\n     }\n@@ -770,7 +778,7 @@ cxx_make_type (enum tree_code code)\n   /* Set up some flags that give proper default behavior.  */\n   if (IS_AGGR_TYPE_CODE (code))\n     {\n-      struct c_fileinfo *finfo = get_fileinfo (input_filename);\n+      struct c_fileinfo *finfo = get_fileinfo (lbasename (input_filename));\n       SET_CLASSTYPE_INTERFACE_UNKNOWN_X (t, finfo->interface_unknown);\n       CLASSTYPE_INTERFACE_ONLY (t) = finfo->interface_only;\n     }"}, {"sha": "556bc476ceb2f5a7ce364e905216d70059597289", "filename": "gcc/cp/parser.c", "status": "modified", "additions": 451, "deletions": 609, "changes": 1060, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fcp%2Fparser.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fcp%2Fparser.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fparser.c?ref=c162c75e43f4813cd30a1d4a693ce20f35a3f9fb", "patch": "@@ -39,30 +39,8 @@\n \f\n /* The lexer.  */\n \n-/* Overview\n-   --------\n-\n-   A cp_lexer represents a stream of cp_tokens.  It allows arbitrary\n-   look-ahead.\n-\n-   Methodology\n-   -----------\n-\n-   We use a circular buffer to store incoming tokens.\n-\n-   Some artifacts of the C++ language (such as the\n-   expression/declaration ambiguity) require arbitrary look-ahead.\n-   The strategy we adopt for dealing with these problems is to attempt\n-   to parse one construct (e.g., the declaration) and fall back to the\n-   other (e.g., the expression) if that attempt does not succeed.\n-   Therefore, we must sometimes store an arbitrary number of tokens.\n-\n-   The parser routinely peeks at the next token, and then consumes it\n-   later.  That also requires a buffer in which to store the tokens.\n-\n-   In order to easily permit adding tokens to the end of the buffer,\n-   while removing them from the beginning of the buffer, we use a\n-   circular buffer.  */\n+/* The cp_lexer_* routines mediate between the lexer proper (in libcpp\n+   and c-lex.c) and the C++ parser.  */\n \n /* A C++ token.  */\n \n@@ -75,149 +53,72 @@ typedef struct cp_token GTY (())\n   ENUM_BITFIELD (rid) keyword : 8;\n   /* Token flags.  */\n   unsigned char flags;\n+  /* True if this token is from a system header. */\n+  BOOL_BITFIELD in_system_header : 1;\n   /* The value associated with this token, if any.  */\n   tree value;\n   /* The location at which this token was found.  */\n   location_t location;\n } cp_token;\n \n-/* The number of tokens in a single token block.\n-   Computed so that cp_token_block fits in a 512B allocation unit.  */\n-\n-#define CP_TOKEN_BLOCK_NUM_TOKENS ((512 - 3*sizeof (char*))/sizeof (cp_token))\n-\n-/* A group of tokens.  These groups are chained together to store\n-   large numbers of tokens.  (For example, a token block is created\n-   when the body of an inline member function is first encountered;\n-   the tokens are processed later after the class definition is\n-   complete.)\n-\n-   This somewhat ungainly data structure (as opposed to, say, a\n-   variable-length array), is used due to constraints imposed by the\n-   current garbage-collection methodology.  If it is made more\n-   flexible, we could perhaps simplify the data structures involved.  */\n-\n-typedef struct cp_token_block GTY (())\n-{\n-  /* The tokens.  */\n-  cp_token tokens[CP_TOKEN_BLOCK_NUM_TOKENS];\n-  /* The number of tokens in this block.  */\n-  size_t num_tokens;\n-  /* The next token block in the chain.  */\n-  struct cp_token_block *next;\n-  /* The previous block in the chain.  */\n-  struct cp_token_block *prev;\n-} cp_token_block;\n-\n-typedef struct cp_token_cache GTY (())\n-{\n-  /* The first block in the cache.  NULL if there are no tokens in the\n-     cache.  */\n-  cp_token_block *first;\n-  /* The last block in the cache.  NULL If there are no tokens in the\n-     cache.  */\n-  cp_token_block *last;\n-} cp_token_cache;\n-\n-/* Prototypes.  */\n-\n-static cp_token_cache *cp_token_cache_new\n-  (void);\n-static void cp_token_cache_push_token\n-  (cp_token_cache *, cp_token *);\n-\n-/* Create a new cp_token_cache.  */\n-\n-static cp_token_cache *\n-cp_token_cache_new (void)\n-{\n-  return GGC_CNEW (cp_token_cache);\n-}\n-\n-/* Add *TOKEN to *CACHE.  */\n-\n-static void\n-cp_token_cache_push_token (cp_token_cache *cache,\n-\t\t\t   cp_token *token)\n-{\n-  cp_token_block *b = cache->last;\n-\n-  /* See if we need to allocate a new token block.  */\n-  if (!b || b->num_tokens == CP_TOKEN_BLOCK_NUM_TOKENS)\n-    {\n-      b = GGC_CNEW (cp_token_block);\n-      b->prev = cache->last;\n-      if (cache->last)\n-\t{\n-\t  cache->last->next = b;\n-\t  cache->last = b;\n-\t}\n-      else\n-\tcache->first = cache->last = b;\n-    }\n-  /* Add this token to the current token block.  */\n-  b->tokens[b->num_tokens++] = *token;\n-}\n-\n /* The cp_lexer structure represents the C++ lexer.  It is responsible\n    for managing the token stream from the preprocessor and supplying\n-   it to the parser.  */\n+   it to the parser.  Tokens are never added to the cp_lexer after\n+   it is created. */\n \n typedef struct cp_lexer GTY (())\n {\n   /* The memory allocated for the buffer.  Never NULL.  */\n   cp_token * GTY ((length (\"(%h.buffer_end - %h.buffer)\"))) buffer;\n   /* A pointer just past the end of the memory allocated for the buffer.  */\n   cp_token * GTY ((skip)) buffer_end;\n-  /* The first valid token in the buffer, or NULL if none.  */\n-  cp_token * GTY ((skip)) first_token;\n+  /* A pointer just past the last available token.  The tokens\n+     in this lexer are [buffer, last_token). */\n+  cp_token * GTY ((skip)) last_token;\n+\n   /* The next available token.  If NEXT_TOKEN is NULL, then there are\n      no more available tokens.  */\n   cp_token * GTY ((skip)) next_token;\n-  /* A pointer just past the last available token.  If FIRST_TOKEN is\n-     NULL, however, there are no available tokens, and then this\n-     location is simply the place in which the next token read will be\n-     placed.  If LAST_TOKEN == FIRST_TOKEN, then the buffer is full.\n-     When the LAST_TOKEN == BUFFER, then the last token is at the\n-     highest memory address in the BUFFER.  */\n-  cp_token * GTY ((skip)) last_token;\n \n   /* A stack indicating positions at which cp_lexer_save_tokens was\n      called.  The top entry is the most recent position at which we\n      began saving tokens.  The entries are differences in token\n-     position between FIRST_TOKEN and the first saved token.\n-\n-     If the stack is non-empty, we are saving tokens.  When a token is\n-     consumed, the NEXT_TOKEN pointer will move, but the FIRST_TOKEN\n-     pointer will not.  The token stream will be preserved so that it\n-     can be reexamined later.\n-\n-     If the stack is empty, then we are not saving tokens.  Whenever a\n-     token is consumed, the FIRST_TOKEN pointer will be moved, and the\n-     consumed token will be gone forever.  */\n+     position between BUFFER and the first saved token.\n+     If the stack is non-empty, we are saving tokens.  */\n   varray_type saved_tokens;\n \n-  /* The STRING_CST tokens encountered while processing the current\n-     string literal.  */\n-  varray_type string_tokens;\n-\n-  /* True if we should obtain more tokens from the preprocessor; false\n-     if we are processing a saved token cache.  */\n-  bool main_lexer_p;\n-\n   /* True if we should output debugging information.  */\n   bool debugging_p;\n \n   /* The next lexer in a linked list of lexers.  */\n   struct cp_lexer *next;\n } cp_lexer;\n \n+/* cp_token_cache is a range of tokens.  There is no need to represent\n+   allocate heap memory for it, since tokens are never removed from the\n+   lexer's array.  There is also no need for the GC to walk through\n+   a cp_token_cache, since everything in here is referenced through\n+   a lexer. */\n+\n+typedef struct cp_token_cache GTY(())\n+{\n+  /* The beginning of the token range. */\n+  cp_token * GTY((skip)) first;\n+\n+  /* Points immediately after the last token in the range. */\n+  cp_token * GTY ((skip)) last;\n+} cp_token_cache;\n+\n /* Prototypes.  */\n \n static cp_lexer *cp_lexer_new_main\n   (void);\n+static cp_lexer *cp_lexer_new_from_token_array\n+  (cp_token *, cp_token *);\n static cp_lexer *cp_lexer_new_from_tokens\n-  (struct cp_token_cache *);\n+  (cp_token_cache *tokens);\n+static void cp_lexer_destroy\n+  (cp_lexer *);\n static int cp_lexer_saving_tokens\n   (const cp_lexer *);\n static cp_token *cp_lexer_next_token\n@@ -226,13 +127,15 @@ static cp_token *cp_lexer_prev_token\n   (cp_lexer *, cp_token *);\n static ptrdiff_t cp_lexer_token_difference\n   (cp_lexer *, cp_token *, cp_token *);\n-static cp_token *cp_lexer_read_token\n-  (cp_lexer *);\n-static void cp_lexer_maybe_grow_buffer\n+static void cp_lexer_grow_buffer\n   (cp_lexer *);\n static void cp_lexer_get_preprocessor_token\n   (cp_lexer *, cp_token *);\n-static cp_token *cp_lexer_peek_token\n+static inline cp_token *cp_lexer_peek_token\n+  (cp_lexer *);\n+static void cp_lexer_peek_token_emit_debug_info\n+  (cp_lexer *, cp_token *);\n+static void cp_lexer_skip_purged_tokens\n   (cp_lexer *);\n static cp_token *cp_lexer_peek_nth_token\n   (cp_lexer *, size_t);\n@@ -248,6 +151,8 @@ static void cp_lexer_purge_token\n   (cp_lexer *);\n static void cp_lexer_purge_tokens_after\n   (cp_lexer *, cp_token *);\n+static void cp_lexer_handle_pragma\n+  (cp_lexer *);\n static void cp_lexer_save_tokens\n   (cp_lexer *);\n static void cp_lexer_commit_tokens\n@@ -271,9 +176,12 @@ static void cp_lexer_stop_debugging\n #define cp_lexer_debugging_p(lexer) 0\n #endif /* ENABLE_CHECKING */\n \n+static cp_token_cache *cp_token_cache_new\n+  (cp_token *, cp_token *);\n+\n /* Manifest constants.  */\n \n-#define CP_TOKEN_BUFFER_SIZE 5\n+#define CP_LEXER_BUFFER_SIZE 10000\n #define CP_SAVED_TOKENS_SIZE 5\n \n /* A token type for keywords, as opposed to ordinary identifiers.  */\n@@ -293,8 +201,9 @@ static void cp_lexer_stop_debugging\n #define CPP_NESTED_NAME_SPECIFIER ((enum cpp_ttype) (CPP_TEMPLATE_ID + 1))\n \n /* A token type for tokens that are not tokens at all; these are used\n-   to mark the end of a token block.  */\n-#define CPP_NONE (CPP_NESTED_NAME_SPECIFIER + 1)\n+   to represent slots in the array where there used to be a token\n+   that has now been deleted. */\n+#define CPP_PURGED (CPP_NESTED_NAME_SPECIFIER + 1)\n \n /* Variables.  */\n \n@@ -312,6 +221,12 @@ cp_lexer_new_main (void)\n   cp_lexer *lexer;\n   cp_token first_token;\n \n+  /* Tell cpplib we want CPP_PRAGMA tokens. */\n+  cpp_get_options (parse_in)->defer_pragmas = true;\n+\n+  /* Tell c_lex not to merge string constants.  */\n+  c_lex_return_raw_strings = true;\n+\n   /* It's possible that lexing the first token will load a PCH file,\n      which is a GC collection point.  So we have to grab the first\n      token before allocating any memory.  */\n@@ -321,86 +236,93 @@ cp_lexer_new_main (void)\n   /* Allocate the memory.  */\n   lexer = GGC_CNEW (cp_lexer);\n \n-  /* Create the circular buffer.  */\n-  lexer->buffer = ggc_calloc (CP_TOKEN_BUFFER_SIZE, sizeof (cp_token));\n-  lexer->buffer_end = lexer->buffer + CP_TOKEN_BUFFER_SIZE;\n-\n+  /* Create the buffer.  */\n+  lexer->buffer = ggc_calloc (CP_LEXER_BUFFER_SIZE, sizeof (cp_token));\n+  lexer->buffer_end = lexer->buffer + CP_LEXER_BUFFER_SIZE;\n+ \n   /* There is one token in the buffer.  */\n   lexer->last_token = lexer->buffer + 1;\n-  lexer->first_token = lexer->buffer;\n   lexer->next_token = lexer->buffer;\n-  memcpy (lexer->buffer, &first_token, sizeof (cp_token));\n-\n-  /* This lexer obtains more tokens by calling c_lex.  */\n-  lexer->main_lexer_p = true;\n+  *lexer->next_token = first_token;\n \n   /* Create the SAVED_TOKENS stack.  */\n   VARRAY_INT_INIT (lexer->saved_tokens, CP_SAVED_TOKENS_SIZE, \"saved_tokens\");\n \n-  /* Create the STRINGS array.  */\n-  VARRAY_TREE_INIT (lexer->string_tokens, 32, \"strings\");\n-\n #ifdef ENABLE_CHECKING  \n-  /* Assume we are not debugging.  */\n+  /* Initially we are not debugging.  */\n   lexer->debugging_p = false;\n #endif /* ENABLE_CHECKING */\n \n+  /* Get the rest of the tokens from the preprocessor. */\n+  while (lexer->last_token[-1].type != CPP_EOF)\n+    {\n+      if (lexer->last_token == lexer->buffer_end)\n+\tcp_lexer_grow_buffer (lexer);\n+      cp_lexer_get_preprocessor_token (lexer, lexer->last_token++);\n+    }\n+\n+  /* Pragma processing (via cpp_handle_deferred_pragma) may result in\n+     direct calls to c_lex.  Those callers all expect c_lex to do\n+     string constant concatenation.  */\n+  c_lex_return_raw_strings = false;\n+\n   return lexer;\n }\n \n-/* Create a new lexer whose token stream is primed with the TOKENS.\n-   When these tokens are exhausted, no new tokens will be read.  */\n+/* Create a new lexer whose token stream is primed with the tokens in\n+   the range [FIRST, LAST).  When these tokens are exhausted, no new\n+   tokens will be read.  */\n \n static cp_lexer *\n-cp_lexer_new_from_tokens (cp_token_cache *tokens)\n+cp_lexer_new_from_token_array (cp_token *first, cp_token *last)\n {\n-  cp_lexer *lexer;\n-  cp_token *token;\n-  cp_token_block *block;\n-  ptrdiff_t num_tokens;\n+  cp_lexer *lexer = GGC_CNEW (cp_lexer);\n+  cp_token *eof;\n \n-  /* Allocate the memory.  */\n-  lexer = GGC_CNEW (cp_lexer);\n+  /* Allocate a new buffer.  The reason we do this is to make sure\n+     there's a CPP_EOF token at the end.  An alternative would be to\n+     modify cp_lexer_peek_token so that it checks for end-of-buffer\n+     and returns a CPP_EOF when appropriate. */\n \n-  /* Create a new buffer, appropriately sized.  */\n-  num_tokens = 0;\n-  for (block = tokens->first; block != NULL; block = block->next)\n-    num_tokens += block->num_tokens;\n-  lexer->buffer = GGC_NEWVEC (cp_token, num_tokens);\n-  lexer->buffer_end = lexer->buffer + num_tokens;\n-\n-  /* Install the tokens.  */\n-  token = lexer->buffer;\n-  for (block = tokens->first; block != NULL; block = block->next)\n-    {\n-      memcpy (token, block->tokens, block->num_tokens * sizeof (cp_token));\n-      token += block->num_tokens;\n-    }\n-\n-  /* The FIRST_TOKEN is the beginning of the buffer.  */\n-  lexer->first_token = lexer->buffer;\n-  /* The next available token is also at the beginning of the buffer.  */\n+  lexer->buffer = GGC_NEWVEC (cp_token, (last - first) + 1);\n+  memcpy (lexer->buffer, first, sizeof (cp_token) * (last - first));\n   lexer->next_token = lexer->buffer;\n-  /* The buffer is full.  */\n-  lexer->last_token = lexer->first_token;\n+  lexer->buffer_end = lexer->last_token = lexer->buffer + (last - first);\n \n-  /* This lexer doesn't obtain more tokens.  */\n-  lexer->main_lexer_p = false;\n+  eof = lexer->buffer + (last - first);\n+  eof->type = CPP_EOF;\n+  eof->location = UNKNOWN_LOCATION;\n+  eof->value = NULL_TREE;\n+  eof->keyword = RID_MAX;\n \n   /* Create the SAVED_TOKENS stack.  */\n   VARRAY_INT_INIT (lexer->saved_tokens, CP_SAVED_TOKENS_SIZE, \"saved_tokens\");\n \n-  /* Create the STRINGS array.  */\n-  VARRAY_TREE_INIT (lexer->string_tokens, 32, \"strings\");\n-\n #ifdef ENABLE_CHECKING\n-  /* Assume we are not debugging.  */\n+  /* Initially we are not debugging.  */\n   lexer->debugging_p = false;\n-#endif /* ENABLE_CHECKING */\n-\n+#endif\n   return lexer;\n }\n \n+/* Create a new lexer whose token stream is primed with the tokens in\n+   CACHE.  When these tokens are exhausted, no new tokens will be read.  */\n+\n+static cp_lexer *\n+cp_lexer_new_from_tokens (cp_token_cache *cache)\n+{\n+  return cp_lexer_new_from_token_array (cache->first, cache->last);\n+}\n+\n+/* Frees all resources associated with LEXER. */\n+\n+static void\n+cp_lexer_destroy (cp_lexer *lexer)\n+{\n+  ggc_free (lexer->buffer);\n+  ggc_free (lexer);\n+}\n+\n /* Returns nonzero if debugging information should be output.  */\n \n #ifdef ENABLE_CHECKING\n@@ -423,31 +345,30 @@ cp_lexer_set_source_position_from_token (cp_lexer *lexer ATTRIBUTE_UNUSED ,\n   /* Ideally, the source position information would not be a global\n      variable, but it is.  */\n \n-  /* Update the line number.  */\n+  /* Update the line number and system header flag. */\n   if (token->type != CPP_EOF)\n-    input_location = token->location;\n+    {\n+      input_location = token->location;\n+      in_system_header = token->in_system_header;\n+    }\n }\n \n /* TOKEN points into the circular token buffer.  Return a pointer to\n    the next token in the buffer.  */\n \n static inline cp_token *\n-cp_lexer_next_token (cp_lexer* lexer, cp_token* token)\n+cp_lexer_next_token (cp_lexer* lexer ATTRIBUTE_UNUSED, cp_token* token)\n {\n   token++;\n-  if (token == lexer->buffer_end)\n-    token = lexer->buffer;\n   return token;\n }\n \n /* TOKEN points into the circular token buffer.  Return a pointer to\n    the previous token in the buffer.  */\n \n static inline cp_token *\n-cp_lexer_prev_token (cp_lexer* lexer, cp_token* token)\n+cp_lexer_prev_token (cp_lexer* lexer ATTRIBUTE_UNUSED, cp_token* token)\n {\n-  if (token == lexer->buffer)\n-    token = lexer->buffer_end;\n   return token - 1;\n }\n \n@@ -462,143 +383,54 @@ cp_lexer_saving_tokens (const cp_lexer* lexer)\n /* Return a pointer to the token that is N tokens beyond TOKEN in the\n    buffer.  */\n \n-static cp_token *\n-cp_lexer_advance_token (cp_lexer *lexer, cp_token *token, ptrdiff_t n)\n+static inline cp_token *\n+cp_lexer_advance_token (cp_lexer *lexer ATTRIBUTE_UNUSED,\n+\t\t\tcp_token *token, ptrdiff_t n)\n {\n-  token += n;\n-  if (token >= lexer->buffer_end)\n-    token = lexer->buffer + (token - lexer->buffer_end);\n-  return token;\n+  return token + n;\n }\n \n /* Returns the number of times that START would have to be incremented\n    to reach FINISH.  If START and FINISH are the same, returns zero.  */\n \n-static ptrdiff_t\n-cp_lexer_token_difference (cp_lexer* lexer, cp_token* start, cp_token* finish)\n+static inline ptrdiff_t\n+cp_lexer_token_difference (cp_lexer* lexer ATTRIBUTE_UNUSED,\n+\t\t\t   cp_token* start, cp_token* finish)\n {\n-  if (finish >= start)\n-    return finish - start;\n-  else\n-    return ((lexer->buffer_end - lexer->buffer)\n-\t    - (start - finish));\n+  return finish - start;\n }\n \n-/* Obtain another token from the C preprocessor and add it to the\n-   token buffer.  Returns the newly read token.  */\n-\n-static cp_token *\n-cp_lexer_read_token (cp_lexer* lexer)\n+/* If the buffer is full, make it bigger.  */\n+static void\n+cp_lexer_grow_buffer (cp_lexer* lexer)\n {\n-  cp_token *token;\n-\n-  /* Make sure there is room in the buffer.  */\n-  cp_lexer_maybe_grow_buffer (lexer);\n-\n-  /* If there weren't any tokens, then this one will be the first.  */\n-  if (!lexer->first_token)\n-    lexer->first_token = lexer->last_token;\n-  /* Similarly, if there were no available tokens, there is one now.  */\n-  if (!lexer->next_token)\n-    lexer->next_token = lexer->last_token;\n+  cp_token *old_buffer;\n+  cp_token *new_buffer;\n+  ptrdiff_t buffer_length;\n \n-  /* Figure out where we're going to store the new token.  */\n-  token = lexer->last_token;\n+  /* This function should only be called when buffer is full. */\n+  gcc_assert (lexer->last_token == lexer->buffer_end);\n \n-  /* Get a new token from the preprocessor.  */\n-  cp_lexer_get_preprocessor_token (lexer, token);\n+  /* Remember the current buffer pointer.  It will become invalid,\n+     but we will need to do pointer arithmetic involving this\n+     value.  */\n+  old_buffer = lexer->buffer;\n+  /* Compute the current buffer size.  */\n+  buffer_length = lexer->buffer_end - lexer->buffer;\n+  /* Allocate a buffer twice as big.  */\n+  new_buffer = ggc_realloc (lexer->buffer,\n+\t\t\t    2 * buffer_length * sizeof (cp_token));\n \n-  /* Increment LAST_TOKEN.  */\n-  lexer->last_token = cp_lexer_next_token (lexer, token);\n+  /* Recompute buffer positions. */\n+  lexer->buffer = new_buffer;\n+  lexer->buffer_end = new_buffer + 2 * buffer_length;\n+  lexer->last_token = new_buffer + (lexer->last_token - old_buffer);\n+  lexer->next_token = new_buffer + (lexer->next_token - old_buffer);\n \n-  /* Strings should have type `const char []'.  Right now, we will\n-     have an ARRAY_TYPE that is constant rather than an array of\n-     constant elements.\n-     FIXME: Make fix_string_type get this right in the first place.  */\n-  if ((token->type == CPP_STRING || token->type == CPP_WSTRING)\n-      && flag_const_strings)\n-    {\n-      if (c_lex_string_translate)\n-\t{\n-\t  tree value = token->value;\n-\t  tree type;\n-\n-\t  /* We might as well go ahead and release the chained\n-\t     translated string such that we can reuse its memory.  */\n-\t  if (TREE_CHAIN (value))\n-\t    value = TREE_CHAIN (token->value);\n-\n-\t  /* Get the current type.  It will be an ARRAY_TYPE.  */\n-\t  type = TREE_TYPE (value);\n-\t  /* Use build_cplus_array_type to rebuild the array, thereby\n-\t     getting the right type.  */\n-\t  type = build_cplus_array_type (TREE_TYPE (type),\n-\t\t\t\t\t TYPE_DOMAIN (type));\n-\t  /* Reset the type of the token.  */\n-\t  TREE_TYPE (value) = type;\n-\t}\n-    }\n-\n-  return token;\n-}\n-\n-/* If the circular buffer is full, make it bigger.  */\n-\n-static void\n-cp_lexer_maybe_grow_buffer (cp_lexer* lexer)\n-{\n-  /* If the buffer is full, enlarge it.  */\n-  if (lexer->last_token == lexer->first_token)\n-    {\n-      cp_token *new_buffer;\n-      cp_token *old_buffer;\n-      cp_token *new_first_token;\n-      ptrdiff_t buffer_length;\n-      size_t num_tokens_to_copy;\n-\n-      /* Remember the current buffer pointer.  It will become invalid,\n-\t but we will need to do pointer arithmetic involving this\n-\t value.  */\n-      old_buffer = lexer->buffer;\n-      /* Compute the current buffer size.  */\n-      buffer_length = lexer->buffer_end - lexer->buffer;\n-      /* Allocate a buffer twice as big.  */\n-      new_buffer = ggc_realloc (lexer->buffer,\n-\t\t\t\t2 * buffer_length * sizeof (cp_token));\n-\n-      /* Because the buffer is circular, logically consecutive tokens\n-\t are not necessarily placed consecutively in memory.\n-\t Therefore, we must keep move the tokens that were before\n-\t FIRST_TOKEN to the second half of the newly allocated\n-\t buffer.  */\n-      num_tokens_to_copy = (lexer->first_token - old_buffer);\n-      memcpy (new_buffer + buffer_length,\n-\t      new_buffer,\n-\t      num_tokens_to_copy * sizeof (cp_token));\n-      /* Clear the rest of the buffer.  We never look at this storage,\n-\t but the garbage collector may.  */\n-      memset (new_buffer + buffer_length + num_tokens_to_copy, 0,\n-\t      (buffer_length - num_tokens_to_copy) * sizeof (cp_token));\n-\n-      /* Now recompute all of the buffer pointers.  */\n-      new_first_token\n-\t= new_buffer + (lexer->first_token - old_buffer);\n-      if (lexer->next_token != NULL)\n-\t{\n-\t  ptrdiff_t next_token_delta;\n-\n-\t  if (lexer->next_token > lexer->first_token)\n-\t    next_token_delta = lexer->next_token - lexer->first_token;\n-\t  else\n-\t    next_token_delta =\n-\t      buffer_length - (lexer->first_token - lexer->next_token);\n-\t  lexer->next_token = new_first_token + next_token_delta;\n-\t}\n-      lexer->last_token = new_first_token + buffer_length;\n-      lexer->buffer = new_buffer;\n-      lexer->buffer_end = new_buffer + buffer_length * 2;\n-      lexer->first_token = new_first_token;\n-    }\n+  /* Clear the rest of the buffer.  We never look at this storage,\n+     but the garbage collector may.  */\n+  memset (lexer->last_token, 0,\n+\t  (lexer->buffer_end - lexer->last_token) * sizeof(cp_token));\n }\n \n /* Store the next token from the preprocessor in *TOKEN.  */\n@@ -609,17 +441,6 @@ cp_lexer_get_preprocessor_token (cp_lexer *lexer ATTRIBUTE_UNUSED ,\n {\n   bool done;\n \n-  /* If this not the main lexer, return a terminating CPP_EOF token.  */\n-  if (lexer != NULL && !lexer->main_lexer_p)\n-    {\n-      token->type = CPP_EOF;\n-      token->location = UNKNOWN_LOCATION;\n-      token->value = NULL_TREE;\n-      token->keyword = RID_MAX;\n-\n-      return;\n-    }\n-\n   done = false;\n   /* Keep going until we get a token we like.  */\n   while (!done)\n@@ -643,6 +464,7 @@ cp_lexer_get_preprocessor_token (cp_lexer *lexer ATTRIBUTE_UNUSED ,\n     }\n   /* Now we've got our token.  */\n   token->location = input_location;\n+  token->in_system_header = in_system_header;\n \n   /* Check to see if this token is a keyword.  */\n   if (token->type == CPP_NAME\n@@ -665,28 +487,49 @@ cp_lexer_get_preprocessor_token (cp_lexer *lexer ATTRIBUTE_UNUSED ,\n /* Return a pointer to the next token in the token stream, but do not\n    consume it.  */\n \n-static cp_token *\n-cp_lexer_peek_token (cp_lexer* lexer)\n+static inline cp_token *\n+cp_lexer_peek_token (cp_lexer *lexer)\n {\n   cp_token *token;\n \n-  /* If there are no tokens, read one now.  */\n-  if (!lexer->next_token)\n-    cp_lexer_read_token (lexer);\n+  /* Skip over purged tokens if necessary. */\n+  if (lexer->next_token->type == CPP_PURGED)\n+    cp_lexer_skip_purged_tokens (lexer);\n+\n+  if (lexer->next_token->type == CPP_PRAGMA)\n+    cp_lexer_handle_pragma (lexer);\n+\n+  token = lexer->next_token;\n \n   /* Provide debugging output.  */\n   if (cp_lexer_debugging_p (lexer))\n-    {\n-      fprintf (cp_lexer_debug_stream, \"cp_lexer: peeking at token: \");\n-      cp_lexer_print_token (cp_lexer_debug_stream, lexer->next_token);\n-      fprintf (cp_lexer_debug_stream, \"\\n\");\n-    }\n+    cp_lexer_peek_token_emit_debug_info (lexer, token);\n \n-  token = lexer->next_token;\n   cp_lexer_set_source_position_from_token (lexer, token);\n   return token;\n }\n \n+/* Emit debug output for cp_lexer_peek_token.  Split out into a\n+   separate function so that cp_lexer_peek_token can be small and\n+   inlinable. */\n+\n+static void\n+cp_lexer_peek_token_emit_debug_info (cp_lexer *lexer ATTRIBUTE_UNUSED,\n+\t\t\t\t     cp_token *token ATTRIBUTE_UNUSED)\n+{\n+  fprintf (cp_lexer_debug_stream, \"cp_lexer: peeking at token: \");\n+  cp_lexer_print_token (cp_lexer_debug_stream, token);\n+  fprintf (cp_lexer_debug_stream, \"\\n\");\n+}\n+\n+/* Skip all tokens whose type is CPP_PURGED. */\n+\n+static void cp_lexer_skip_purged_tokens (cp_lexer *lexer)\n+{\n+  while (lexer->next_token->type == CPP_PURGED)\n+    ++lexer->next_token;\n+}\n+\n /* Return true if the next token has the indicated TYPE.  */\n \n static bool\n@@ -732,23 +575,13 @@ cp_lexer_peek_nth_token (cp_lexer* lexer, size_t n)\n   /* N is 1-based, not zero-based.  */\n   gcc_assert (n > 0);\n \n-  /* Skip ahead from NEXT_TOKEN, reading more tokens as necessary.  */\n+  --n;\n   token = lexer->next_token;\n-  /* If there are no tokens in the buffer, get one now.  */\n-  if (!token)\n+  while (n != 0)\n     {\n-      cp_lexer_read_token (lexer);\n-      token = lexer->next_token;\n-    }\n-\n-  /* Now, read tokens until we have enough.  */\n-  while (--n > 0)\n-    {\n-      /* Advance to the next token.  */\n-      token = cp_lexer_next_token (lexer, token);\n-      /* If that's all the tokens we have, read a new one.  */\n-      if (token == lexer->last_token)\n-\ttoken = cp_lexer_read_token (lexer);\n+      ++token;\n+      if (token->type != CPP_PURGED)\n+\t--n;\n     }\n \n   return token;\n@@ -764,29 +597,14 @@ cp_lexer_consume_token (cp_lexer* lexer)\n {\n   cp_token *token;\n \n-  /* If there are no tokens, read one now.  */\n-  if (!lexer->next_token)\n-    cp_lexer_read_token (lexer);\n-\n-  /* Remember the token we'll be returning.  */\n-  token = lexer->next_token;\n+  /* Skip over purged tokens if necessary. */\n+  if (lexer->next_token->type == CPP_PURGED)\n+    cp_lexer_skip_purged_tokens (lexer);\n \n-  /* Increment NEXT_TOKEN.  */\n-  lexer->next_token = cp_lexer_next_token (lexer,\n-\t\t\t\t\t   lexer->next_token);\n-  /* Check to see if we're all out of tokens.  */\n-  if (lexer->next_token == lexer->last_token)\n-    lexer->next_token = NULL;\n+  if (lexer->next_token->type == CPP_PRAGMA)\n+    cp_lexer_handle_pragma (lexer);\n \n-  /* If we're not saving tokens, then move FIRST_TOKEN too.  */\n-  if (!cp_lexer_saving_tokens (lexer))\n-    {\n-      /* If there are no tokens available, set FIRST_TOKEN to NULL.  */\n-      if (!lexer->next_token)\n-\tlexer->first_token = NULL;\n-      else\n-\tlexer->first_token = lexer->next_token;\n-    }\n+  token = lexer->next_token++;\n \n   /* Provide debugging output.  */\n   if (cp_lexer_debugging_p (lexer))\n@@ -806,60 +624,54 @@ cp_lexer_consume_token (cp_lexer* lexer)\n static void\n cp_lexer_purge_token (cp_lexer *lexer)\n {\n-  cp_token *token;\n-  cp_token *next_token;\n-\n-  token = lexer->next_token;\n-  while (true)\n-    {\n-      next_token = cp_lexer_next_token (lexer, token);\n-      if (next_token == lexer->last_token)\n-\tbreak;\n-      *token = *next_token;\n-      token = next_token;\n-    }\n-\n-  lexer->last_token = token;\n-  /* The token purged may have been the only token remaining; if so,\n-     clear NEXT_TOKEN.  */\n-  if (lexer->next_token == token)\n-    lexer->next_token = NULL;\n+  cp_token *tok = lexer->next_token;\n+  tok->type = CPP_PURGED;\n+  tok->location = UNKNOWN_LOCATION;\n+  tok->value = NULL_TREE;\n+  tok->keyword = RID_MAX;\n }\n \n-/* Permanently remove all tokens after TOKEN, up to, but not\n+/* Permanently remove all tokens after TOK, up to, but not\n    including, the token that will be returned next by\n    cp_lexer_peek_token.  */\n \n static void\n-cp_lexer_purge_tokens_after (cp_lexer *lexer, cp_token *token)\n+cp_lexer_purge_tokens_after (cp_lexer *lexer, cp_token *tok)\n {\n   cp_token *peek;\n-  cp_token *t1;\n-  cp_token *t2;\n \n-  if (lexer->next_token)\n+  peek = cp_lexer_peek_token (lexer);\n+  gcc_assert (tok < peek);\n+\n+  for ( tok += 1; tok != peek; tok += 1)\n     {\n-      /* Copy the tokens that have not yet been read to the location\n-\t immediately following TOKEN.  */\n-      t1 = cp_lexer_next_token (lexer, token);\n-      t2 = peek = cp_lexer_peek_token (lexer);\n-      /* Move tokens into the vacant area between TOKEN and PEEK.  */\n-      while (t2 != lexer->last_token)\n-\t{\n-\t  *t1 = *t2;\n-\t  t1 = cp_lexer_next_token (lexer, t1);\n-\t  t2 = cp_lexer_next_token (lexer, t2);\n-\t}\n-      /* Now, the next available token is right after TOKEN.  */\n-      lexer->next_token = cp_lexer_next_token (lexer, token);\n-      /* And the last token is wherever we ended up.  */\n-      lexer->last_token = t1;\n+      tok->type = CPP_PURGED;\n+      tok->location = UNKNOWN_LOCATION;\n+      tok->value = NULL_TREE;\n+      tok->keyword = RID_MAX;\n     }\n-  else\n+}\n+\n+/* Handle a pragma token and skip over it. We need the loop because\n+   the next token might also be a pragma token. */\n+static void\n+cp_lexer_handle_pragma (cp_lexer *lexer)\n+{\n+  gcc_assert (lexer->next_token->type == CPP_PRAGMA);\n+\n+  while (lexer->next_token->type == CPP_PRAGMA)\n     {\n-      /* There are no tokens in the buffer, so there is nothing to\n-\t copy.  The last token in the buffer is TOKEN itself.  */\n-      lexer->last_token = cp_lexer_next_token (lexer, token);\n+      tree t = lexer->next_token->value;\n+      cpp_string s;\n+      s.len = TREE_STRING_LENGTH (t);\n+      s.text = (const unsigned char *) TREE_STRING_POINTER (t);\n+\n+      cp_lexer_set_source_position_from_token (lexer, lexer->next_token);\n+      cpp_handle_deferred_pragma (parse_in, &s);\n+\n+      /* Make sure we don't run this pragma twice. */\n+      cp_lexer_purge_token (lexer);\n+      cp_lexer_skip_purged_tokens (lexer);\n     }\n }\n \n@@ -873,14 +685,9 @@ cp_lexer_save_tokens (cp_lexer* lexer)\n   if (cp_lexer_debugging_p (lexer))\n     fprintf (cp_lexer_debug_stream, \"cp_lexer: saving tokens\\n\");\n \n-  /* Make sure that LEXER->NEXT_TOKEN is non-NULL so that we can\n-     restore the tokens if required.  */\n-  if (!lexer->next_token)\n-    cp_lexer_read_token (lexer);\n-\n   VARRAY_PUSH_INT (lexer->saved_tokens,\n \t\t   cp_lexer_token_difference (lexer,\n-\t\t\t\t\t      lexer->first_token,\n+\t\t\t\t\t      lexer->buffer,\n \t\t\t\t\t      lexer->next_token));\n }\n \n@@ -912,13 +719,7 @@ cp_lexer_rollback_tokens (cp_lexer* lexer)\n      tokens.  */\n   delta = VARRAY_TOP_INT(lexer->saved_tokens);\n   /* Make it the next token again now.  */\n-  lexer->next_token = cp_lexer_advance_token (lexer,\n-\t\t\t\t\t      lexer->first_token,\n-\t\t\t\t\t      delta);\n-  /* It might be the case that there were no tokens when we started\n-     saving tokens, but that there are some tokens now.  */\n-  if (!lexer->next_token && lexer->first_token)\n-    lexer->next_token = lexer->first_token;\n+  lexer->next_token = cp_lexer_advance_token (lexer, lexer->buffer, delta);\n \n   /* Stop saving tokens.  */\n   VARRAY_POP (lexer->saved_tokens);\n@@ -929,71 +730,51 @@ cp_lexer_rollback_tokens (cp_lexer* lexer)\n #ifdef ENABLE_CHECKING\n \n static void\n-cp_lexer_print_token (FILE * stream, cp_token* token)\n-{\n-  const char *token_type = NULL;\n+cp_lexer_print_token (FILE * stream, cp_token *token)\n+{\n+  /* We don't use cpp_type2name here because the parser defines\n+     a few tokens of its own.  */\n+  static const char *const token_names[] = {\n+    /* cpplib-defined token types */\n+#define OP(e, s) #e,\n+#define TK(e, s) #e,\n+    TTYPE_TABLE\n+#undef OP\n+#undef TK\n+    /* C++ parser token types - see \"Manifest constants\", above.  */\n+    \"KEYWORD\",\n+    \"TEMPLATE_ID\",\n+    \"NESTED_NAME_SPECIFIER\",\n+    \"PURGED\"\n+  };\n+  \n+  /* If we have a name for the token, print it out.  Otherwise, we\n+     simply give the numeric code.  */\n+  gcc_assert (token->type < ARRAY_SIZE(token_names));\n+  fputs (token_names[token->type], stream);\n \n-  /* Figure out what kind of token this is.  */\n+  /* For some tokens, print the associated data.  */\n   switch (token->type)\n     {\n-    case CPP_EQ:\n-      token_type = \"EQ\";\n-      break;\n-\n-    case CPP_COMMA:\n-      token_type = \"COMMA\";\n-      break;\n-\n-    case CPP_OPEN_PAREN:\n-      token_type = \"OPEN_PAREN\";\n-      break;\n-\n-    case CPP_CLOSE_PAREN:\n-      token_type = \"CLOSE_PAREN\";\n-      break;\n-\n-    case CPP_OPEN_BRACE:\n-      token_type = \"OPEN_BRACE\";\n-      break;\n-\n-    case CPP_CLOSE_BRACE:\n-      token_type = \"CLOSE_BRACE\";\n-      break;\n-\n-    case CPP_SEMICOLON:\n-      token_type = \"SEMICOLON\";\n-      break;\n-\n+    case CPP_KEYWORD:\n+      /* Some keywords have a value that is not an IDENTIFIER_NODE.\n+\t For example, `struct' is mapped to an INTEGER_CST.  */\n+      if (TREE_CODE (token->value) != IDENTIFIER_NODE)\n+\tbreak;\n+      /* else fall through */\n     case CPP_NAME:\n-      token_type = \"NAME\";\n+      fputs (IDENTIFIER_POINTER (token->value), stream);\n       break;\n \n-    case CPP_EOF:\n-      token_type = \"EOF\";\n-      break;\n-\n-    case CPP_KEYWORD:\n-      token_type = \"keyword\";\n+    case CPP_STRING:\n+    case CPP_WSTRING:\n+    case CPP_PRAGMA:\n+      fprintf (stream, \" \\\"%s\\\"\", TREE_STRING_POINTER (token->value));\n       break;\n \n-      /* This is not a token that we know how to handle yet.  */\n     default:\n       break;\n     }\n-\n-  /* If we have a name for the token, print it out.  Otherwise, we\n-     simply give the numeric code.  */\n-  if (token_type)\n-    fprintf (stream, \"%s\", token_type);\n-  else\n-    fprintf (stream, \"%d\", token->type);\n-  /* And, for an identifier, print the identifier name.  */\n-  if (token->type == CPP_NAME\n-      /* Some keywords have a value that is not an IDENTIFIER_NODE.\n-\t For example, `struct' is mapped to an INTEGER_CST.  */\n-      || (token->type == CPP_KEYWORD\n-\t  && TREE_CODE (token->value) == IDENTIFIER_NODE))\n-    fprintf (stream, \" %s\", IDENTIFIER_POINTER (token->value));\n }\n \n /* Start emitting debugging information.  */\n@@ -1014,6 +795,17 @@ cp_lexer_stop_debugging (cp_lexer* lexer)\n \n #endif /* ENABLE_CHECKING */\n \n+/* Create a new cp_token_cache, representing a range of tokens. */\n+\n+static cp_token_cache *\n+cp_token_cache_new (cp_token *first, cp_token *last)\n+{\n+  cp_token_cache *cache = GGC_NEW (cp_token_cache);\n+  cache->first = first;\n+  cache->last = last;\n+  return cache;\n+}\n+\n \f\n /* Decl-specifiers.  */\n \n@@ -1482,6 +1274,10 @@ typedef struct cp_parser GTY(())\n      alternatives.  */\n   bool in_type_id_in_expr_p;\n \n+  /* TRUE if strings in expressions should be translated to the execution\n+     character set.  */\n+  bool translate_strings_p;\n+\n   /* If non-NULL, then we are parsing a construct where new type\n      definitions are not permitted.  The string stored here will be\n      issued as an error message if a type is defined.  */\n@@ -1538,6 +1334,8 @@ static cp_parser *cp_parser_new\n \n static tree cp_parser_identifier\n   (cp_parser *);\n+static tree cp_parser_string_literal\n+  (cp_parser *, bool, bool);\n \n /* Basic concepts [gram.basic]  */\n \n@@ -1921,7 +1719,7 @@ static bool cp_parser_optional_template_keyword\n static void cp_parser_pre_parsed_nested_name_specifier\n   (cp_parser *);\n static void cp_parser_cache_group\n-  (cp_parser *, cp_token_cache *, enum cpp_ttype, unsigned);\n+  (cp_parser *, enum cpp_ttype, unsigned);\n static void cp_parser_parse_tentatively\n   (cp_parser *);\n static void cp_parser_commit_to_tentative_parse\n@@ -2136,7 +1934,7 @@ cp_parser_check_for_invalid_template_id (cp_parser* parser,\n \t  token = cp_lexer_peek_token (parser->lexer);\n \t  token = cp_lexer_prev_token (parser->lexer, token);\n \t  start = cp_lexer_token_difference (parser->lexer,\n-\t\t\t\t\t     parser->lexer->first_token,\n+\t\t\t\t\t     parser->lexer->buffer,\n \t\t\t\t\t     token);\n \t}\n       else\n@@ -2150,7 +1948,7 @@ cp_parser_check_for_invalid_template_id (cp_parser* parser,\n       if (start >= 0)\n \t{\n \t  token = cp_lexer_advance_token (parser->lexer,\n-\t\t\t\t\t  parser->lexer->first_token,\n+\t\t\t\t\t  parser->lexer->buffer,\n \t\t\t\t\t  start);\n \t  cp_lexer_purge_tokens_after (parser->lexer, token);\n \t}\n@@ -2311,18 +2109,12 @@ cp_parser_skip_to_closing_parenthesis (cp_parser *parser,\n {\n   unsigned paren_depth = 0;\n   unsigned brace_depth = 0;\n-  int saved_c_lex_string_translate = c_lex_string_translate;\n   int result;\n \n   if (recovering && !or_comma && cp_parser_parsing_tentatively (parser)\n       && !cp_parser_committed_to_tentative_parse (parser))\n     return 0;\n \n-  if (! recovering)\n-    /* If we're looking ahead, keep both translated and untranslated\n-       strings.  */\n-    c_lex_string_translate = -1;\n-\n   while (true)\n     {\n       cp_token *token;\n@@ -2380,7 +2172,6 @@ cp_parser_skip_to_closing_parenthesis (cp_parser *parser,\n       cp_lexer_consume_token (parser->lexer);\n     }\n \n-  c_lex_string_translate = saved_c_lex_string_translate;\n   return result;\n }\n \n@@ -2602,6 +2393,9 @@ cp_parser_new (void)\n   /* We are not parsing a type-id inside an expression.  */\n   parser->in_type_id_in_expr_p = false;\n \n+  /* String literals should be translated to the execution character set.  */\n+  parser->translate_strings_p = true;\n+\n   /* The unparsed function queue is empty.  */\n   parser->unparsed_functions_queues = build_tree_list (NULL_TREE, NULL_TREE);\n \n@@ -2630,6 +2424,102 @@ cp_parser_identifier (cp_parser* parser)\n   return token ? token->value : error_mark_node;\n }\n \n+/* Parse a sequence of adjacent string constants.  Returns a\n+   TREE_STRING representing the combined, nul-terminated string\n+   constant.  If TRANSLATE is true, translate the string to the\n+   execution character set.  If WIDE_OK is true, a wide string is\n+   invalid here.\n+\n+   C++98 [lex.string] says that if a narrow string literal token is\n+   adjacent to a wide string literal token, the behavior is undefined.\n+   However, C99 6.4.5p4 says that this results in a wide string literal.\n+   We follow C99 here, for consistency with the C front end.\n+\n+   This code is largely lifted from lex_string() in c-lex.c.\n+\n+   FUTURE: ObjC++ will need to handle @-strings here.  */\n+static tree\n+cp_parser_string_literal (cp_parser *parser, bool translate, bool wide_ok)\n+{\n+  tree value;\n+  bool wide = false;\n+  size_t count;\n+  struct obstack str_ob;\n+  cpp_string str, istr, *strs;\n+  cp_token *tok;\n+\n+  tok = cp_lexer_peek_token (parser->lexer);\n+  if (!cp_parser_is_string_literal (tok))\n+    {\n+      cp_parser_error (parser, \"expected string-literal\");\n+      return error_mark_node;\n+    }\n+\n+  /* Try to avoid the overhead of creating and destroying an obstac\n+     for the common case of just one string.  */\n+  if (!cp_parser_is_string_literal (cp_lexer_peek_nth_token (parser->lexer, 2)))\n+    {\n+      str.text = (const unsigned char *)TREE_STRING_POINTER (tok->value);\n+      str.len = TREE_STRING_LENGTH (tok->value);\n+      count = 1;\n+      if (tok->type == CPP_WSTRING)\n+\twide = true;\n+      cp_lexer_consume_token (parser->lexer);\n+\n+      strs = &str;\n+    }\n+  else\n+    {\n+      gcc_obstack_init (&str_ob);\n+      count = 0;\n+\n+      do\n+\t{\n+\t  count++;\n+\t  str.text = (unsigned char *)TREE_STRING_POINTER (tok->value);\n+\t  str.len = TREE_STRING_LENGTH (tok->value);\n+\t  if (tok->type == CPP_WSTRING)\n+\t    wide = true;\n+\n+\t  obstack_grow (&str_ob, &str, sizeof (cpp_string));\n+\n+\t  /* We do it this way so that, if we have to issue semantic\n+\t     errors on this string literal, the source position will\n+\t     be that of the first token of the string.  */\n+\t  tok = cp_lexer_peek_nth_token (parser->lexer, 2);\n+\t  cp_lexer_consume_token (parser->lexer);\n+\t}\n+      while (cp_parser_is_string_literal (tok));\n+\n+      strs = (cpp_string *) obstack_finish (&str_ob);\n+    }\n+\n+  if (wide && !wide_ok)\n+    {\n+      cp_parser_error (parser, \"a wide string is invalid in this context\");\n+      wide = false;\n+    }\n+\n+  if ((translate ? cpp_interpret_string : cpp_interpret_string_notranslate)\n+      (parse_in, strs, count, &istr, wide))\n+    {\n+      value = build_string (istr.len, (char *)istr.text);\n+      free ((void *)istr.text);\n+\n+      TREE_TYPE (value) = wide ? wchar_array_type_node : char_array_type_node;\n+      value = fix_string_type (value);\n+    }\n+  else\n+    /* cpp_interpret_string has issued an error.  */\n+    value = error_mark_node;\n+\n+  if (count > 1)\n+    obstack_free (&str_ob, 0);\n+\n+  return value;\n+}\n+\n+\n /* Basic concepts [gram.basic]  */\n \n /* Parse a translation-unit.\n@@ -2670,6 +2560,10 @@ cp_parser_translation_unit (cp_parser* parser)\n \t  /* Consume the EOF token.  */\n \t  cp_parser_require (parser, CPP_EOF, \"end-of-file\");\n \n+\t  /* Get rid of the token array; we don't need it any more. */\n+\t  cp_lexer_destroy (parser->lexer);\n+\t  parser->lexer = NULL;\n+\n \t  /* Finish up.  */\n \t  finish_translation_unit ();\n \n@@ -2750,11 +2644,12 @@ cp_parser_primary_expression (cp_parser *parser,\n \n     case CPP_STRING:\n     case CPP_WSTRING:\n-      token = cp_lexer_consume_token (parser->lexer);\n-      if (TREE_CHAIN (token->value))\n-\treturn TREE_CHAIN (token->value);\n-      else\n-\treturn token->value;\n+      /* ??? Should wide strings be allowed when parser->translate_strings_p\n+         is false (i.e. in attributes)?  If not, we can kill the third\n+\t argument to cp_parser_string_literal.  */\n+      return cp_parser_string_literal (parser,\n+\t\t\t\t       parser->translate_strings_p,\n+\t\t\t\t       true);\n \n     case CPP_OPEN_PAREN:\n       {\n@@ -3425,7 +3320,7 @@ cp_parser_nested_name_specifier_opt (cp_parser *parser,\n     {\n       token = cp_lexer_peek_token (parser->lexer);\n       start = cp_lexer_token_difference (parser->lexer,\n-\t\t\t\t\t parser->lexer->first_token,\n+\t\t\t\t\t parser->lexer->buffer,\n \t\t\t\t\t token);\n     }\n   else\n@@ -3596,7 +3491,7 @@ cp_parser_nested_name_specifier_opt (cp_parser *parser,\n       /* Find the token that corresponds to the start of the\n \t template-id.  */\n       token = cp_lexer_advance_token (parser->lexer,\n-\t\t\t\t      parser->lexer->first_token,\n+\t\t\t\t      parser->lexer->buffer,\n \t\t\t\t      start);\n \n       /* Reset the contents of the START token.  */\n@@ -6359,7 +6254,7 @@ cp_parser_condition (cp_parser* parser)\n \t for sure.  */\n       if (cp_parser_parse_definitely (parser))\n \t{\n-\t  bool pop_p;\n+\t  bool pop_p;\t\n \n \t  /* Create the declaration.  */\n \t  decl = start_decl (declarator, &type_specifiers,\n@@ -6374,6 +6269,7 @@ cp_parser_condition (cp_parser* parser)\n \t\t\t  initializer,\n \t\t\t  asm_specification,\n \t\t\t  LOOKUP_ONLYCONVERTING);\n+\n \t  if (pop_p)\n \t    pop_scope (DECL_CONTEXT (decl));\n \n@@ -6795,10 +6691,6 @@ cp_parser_declaration (cp_parser* parser)\n   int saved_pedantic;\n   void *p;\n \n-  /* Set this here since we can be called after\n-     pushing the linkage specification.  */\n-  c_lex_string_translate = 1;\n-\n   /* Check for the `__extension__' keyword.  */\n   if (cp_parser_extension_opt (parser, &saved_pedantic))\n     {\n@@ -6813,15 +6705,9 @@ cp_parser_declaration (cp_parser* parser)\n   /* Try to figure out what kind of declaration is present.  */\n   token1 = *cp_lexer_peek_token (parser->lexer);\n \n-  /* Don't translate the CPP_STRING in extern \"C\".  */\n-  if (token1.keyword == RID_EXTERN)\n-    c_lex_string_translate = 0;\n-\n   if (token1.type != CPP_EOF)\n     token2 = *cp_lexer_peek_nth_token (parser->lexer, 2);\n \n-  c_lex_string_translate = 1;\n-\n   /* Get the high-water mark for the DECLARATOR_OBSTACK.  */\n   p = obstack_alloc (&declarator_obstack, 0);\n \n@@ -7454,41 +7340,26 @@ cp_parser_function_specifier_opt (cp_parser* parser,\n static void\n cp_parser_linkage_specification (cp_parser* parser)\n {\n-  cp_token *token;\n   tree linkage;\n \n   /* Look for the `extern' keyword.  */\n   cp_parser_require_keyword (parser, RID_EXTERN, \"`extern'\");\n \n-  /* Peek at the next token.  */\n-  token = cp_lexer_peek_token (parser->lexer);\n-  /* If it's not a string-literal, then there's a problem.  */\n-  if (!cp_parser_is_string_literal (token))\n-    {\n-      cp_parser_error (parser, \"expected language-name\");\n-      return;\n-    }\n-  /* Consume the token.  */\n-  cp_lexer_consume_token (parser->lexer);\n+  /* Look for the string-literal.  */\n+  linkage = cp_parser_string_literal (parser, false, false);\n \n   /* Transform the literal into an identifier.  If the literal is a\n      wide-character string, or contains embedded NULs, then we can't\n      handle it as the user wants.  */\n-  if (token->type == CPP_WSTRING\n-      || (strlen (TREE_STRING_POINTER (token->value))\n-\t  != (size_t) (TREE_STRING_LENGTH (token->value) - 1)))\n+  if (strlen (TREE_STRING_POINTER (linkage))\n+      != (size_t) (TREE_STRING_LENGTH (linkage) - 1))\n     {\n       cp_parser_error (parser, \"invalid linkage-specification\");\n       /* Assume C++ linkage.  */\n-      linkage = get_identifier (\"c++\");\n+      linkage = lang_name_cplusplus;\n     }\n-  /* If the string is chained to another string, take the latter,\n-     that's the untranslated string.  */\n-  else if (TREE_CHAIN (token->value))\n-    linkage = get_identifier (TREE_STRING_POINTER (TREE_CHAIN (token->value)));\n-  /* If it's a simple string constant, things are easier.  */\n   else\n-    linkage = get_identifier (TREE_STRING_POINTER (token->value));\n+    linkage = get_identifier (TREE_STRING_POINTER (linkage));\n \n   /* We're now using the new linkage.  */\n   push_lang_context (linkage);\n@@ -8469,7 +8340,7 @@ cp_parser_template_id (cp_parser *parser,\n     {\n       next_token = cp_lexer_peek_token (parser->lexer);\n       start_of_id = cp_lexer_token_difference (parser->lexer,\n-\t\t\t\t\t       parser->lexer->first_token,\n+\t\t\t\t\t       parser->lexer->buffer,\n \t\t\t\t\t       next_token);\n     }\n   else\n@@ -8581,7 +8452,7 @@ cp_parser_template_id (cp_parser *parser,\n       /* Find the token that corresponds to the start of the\n \t template-id.  */\n       token = cp_lexer_advance_token (parser->lexer,\n-\t\t\t\t      parser->lexer->first_token,\n+\t\t\t\t      parser->lexer->buffer,\n \t\t\t\t      start_of_id);\n \n       /* Reset the contents of the START_OF_ID token.  */\n@@ -8714,7 +8585,7 @@ cp_parser_template_name (cp_parser* parser,\n \t      token = cp_lexer_peek_token (parser->lexer);\n \t      token = cp_lexer_prev_token (parser->lexer, token);\n \t      start = cp_lexer_token_difference (parser->lexer,\n-\t\t\t\t\t\t parser->lexer->first_token,\n+\t\t\t\t\t\t parser->lexer->buffer,\n \t\t\t\t\t\t token);\n \t    }\n \t  else\n@@ -8736,7 +8607,7 @@ cp_parser_template_name (cp_parser* parser,\n \t  if (start >= 0)\n \t    {\n \t      token = cp_lexer_advance_token (parser->lexer,\n-\t\t\t\t\t      parser->lexer->first_token,\n+\t\t\t\t\t      parser->lexer->buffer,\n \t\t\t\t\t      start);\n \t      cp_lexer_purge_tokens_after (parser->lexer, token);\n \t    }\n@@ -10365,7 +10236,6 @@ cp_parser_using_directive (cp_parser* parser)\n static void\n cp_parser_asm_definition (cp_parser* parser)\n {\n-  cp_token *token;\n   tree string;\n   tree outputs = NULL_TREE;\n   tree inputs = NULL_TREE;\n@@ -10386,13 +10256,17 @@ cp_parser_asm_definition (cp_parser* parser)\n       cp_lexer_consume_token (parser->lexer);\n     }\n   /* Look for the opening `('.  */\n-  cp_parser_require (parser, CPP_OPEN_PAREN, \"`('\");\n+  if (!cp_parser_require (parser, CPP_OPEN_PAREN, \"`('\"))\n+    return;\n   /* Look for the string.  */\n-  c_lex_string_translate = 0;\n-  token = cp_parser_require (parser, CPP_STRING, \"asm body\");\n-  if (!token)\n-    goto finish;\n-  string = token->value;\n+  string = cp_parser_string_literal (parser, false, false);\n+  if (string == error_mark_node)\n+    {\n+      cp_parser_skip_to_closing_parenthesis (parser, true, false,\n+\t\t\t\t\t     /*consume_paren=*/true);\n+      return;\n+    }\n+\n   /* If we're allowing GNU extensions, check for the extended assembly\n      syntax.  Unfortunately, the `:' tokens need not be separated by\n      a space in C, and so, for compatibility, we tolerate that here\n@@ -10475,9 +10349,6 @@ cp_parser_asm_definition (cp_parser* parser)\n     }\n   else\n     assemble_asm (string);\n-\n- finish:\n-  c_lex_string_translate = 1;\n }\n \n /* Declarators [gram.dcl.decl] */\n@@ -11866,18 +11737,15 @@ cp_parser_parameter_declaration (cp_parser *parser,\n \t  && TYPE_BEING_DEFINED (current_class_type))\n \t{\n \t  unsigned depth = 0;\n-\n-\t  /* Create a DEFAULT_ARG to represented the unparsed default\n-             argument.  */\n-\t  default_argument = make_node (DEFAULT_ARG);\n-\t  DEFARG_TOKENS (default_argument) = cp_token_cache_new ();\n+\t  cp_token *first_token;\n+\t  cp_token *token;\n \n \t  /* Add tokens until we have processed the entire default\n-\t     argument.  */\n+\t     argument.  We add the range [first_token, token). */\n+\t  first_token = cp_lexer_peek_token (parser->lexer);\n \t  while (true)\n \t    {\n \t      bool done = false;\n-\t      cp_token *token;\n \n \t      /* Peek at the next token.  */\n \t      token = cp_lexer_peek_token (parser->lexer);\n@@ -11945,9 +11813,13 @@ cp_parser_parameter_declaration (cp_parser *parser,\n \n \t      /* Add the token to the token block.  */\n \t      token = cp_lexer_consume_token (parser->lexer);\n-\t      cp_token_cache_push_token (DEFARG_TOKENS (default_argument),\n-\t\t\t\t\t token);\n \t    }\n+\n+\t  /* Create a DEFAULT_ARG to represented the unparsed default\n+             argument.  */\n+\t  default_argument = make_node (DEFAULT_ARG);\n+\t  DEFARG_TOKENS (default_argument)\n+\t    = cp_token_cache_new (first_token, token);\t\n \t}\n       /* Outside of a class definition, we can just parse the\n          assignment-expression.  */\n@@ -13849,11 +13721,7 @@ cp_parser_asm_specification_opt (cp_parser* parser)\n   cp_parser_require (parser, CPP_OPEN_PAREN, \"`('\");\n \n   /* Look for the string-literal.  */\n-  token = cp_parser_require (parser, CPP_STRING, \"string-literal\");\n-  if (token)\n-    asm_specification = token->value;\n-  else\n-    asm_specification = NULL_TREE;\n+  asm_specification = cp_parser_string_literal (parser, false, false);\n \n   /* Look for the `)'.  */\n   cp_parser_require (parser, CPP_CLOSE_PAREN, \"`('\");\n@@ -13887,7 +13755,6 @@ cp_parser_asm_operand_list (cp_parser* parser)\n       tree string_literal;\n       tree expression;\n       tree name;\n-      cp_token *token;\n \n       if (cp_lexer_next_token_is (parser->lexer, CPP_OPEN_SQUARE))\n \t{\n@@ -13904,16 +13771,15 @@ cp_parser_asm_operand_list (cp_parser* parser)\n       else\n \tname = NULL_TREE;\n       /* Look for the string-literal.  */\n-      token = cp_parser_require (parser, CPP_STRING, \"string-literal\");\n-      string_literal = token ? token->value : error_mark_node;\n-      c_lex_string_translate = 1;\n+      string_literal = cp_parser_string_literal (parser, false, false);\n+\n       /* Look for the `('.  */\n       cp_parser_require (parser, CPP_OPEN_PAREN, \"`('\");\n       /* Parse the expression.  */\n       expression = cp_parser_expression (parser);\n       /* Look for the `)'.  */\n       cp_parser_require (parser, CPP_CLOSE_PAREN, \"`)'\");\n-      c_lex_string_translate = 0;\n+\n       /* Add this operand to the list.  */\n       asm_operands = tree_cons (build_tree_list (name, string_literal),\n \t\t\t\texpression,\n@@ -13945,12 +13811,10 @@ cp_parser_asm_clobber_list (cp_parser* parser)\n \n   while (true)\n     {\n-      cp_token *token;\n       tree string_literal;\n \n       /* Look for the string literal.  */\n-      token = cp_parser_require (parser, CPP_STRING, \"string-literal\");\n-      string_literal = token ? token->value : error_mark_node;\n+      string_literal = cp_parser_string_literal (parser, false, false);\n       /* Add it to the list.  */\n       clobbers = tree_cons (NULL_TREE, string_literal, clobbers);\n       /* If the next token is not a `,', then the list is\n@@ -14038,8 +13902,9 @@ static tree\n cp_parser_attribute_list (cp_parser* parser)\n {\n   tree attribute_list = NULL_TREE;\n+  bool save_translate_strings_p = parser->translate_strings_p;\n \n-  c_lex_string_translate = 0;\n+  parser->translate_strings_p = false;\n   while (true)\n     {\n       cp_token *token;\n@@ -14085,7 +13950,7 @@ cp_parser_attribute_list (cp_parser* parser)\n       /* Consume the comma and keep going.  */\n       cp_lexer_consume_token (parser->lexer);\n     }\n-  c_lex_string_translate = 1;\n+  parser->translate_strings_p = save_translate_strings_p;\n \n   /* We built up the list in reverse order.  */\n   return nreverse (attribute_list);\n@@ -15121,7 +14986,8 @@ cp_parser_save_member_function_body (cp_parser* parser,\n \t\t\t\t     cp_declarator *declarator,\n \t\t\t\t     tree attributes)\n {\n-  cp_token_cache *cache;\n+  cp_token *first;\n+  cp_token *last;\n   tree fn;\n \n   /* Create the function-declaration.  */\n@@ -15139,18 +15005,18 @@ cp_parser_save_member_function_body (cp_parser* parser,\n   /* Remember it, if there default args to post process.  */\n   cp_parser_save_default_args (parser, fn);\n \n-  /* Create a token cache.  */\n-  cache = cp_token_cache_new ();\n   /* Save away the tokens that make up the body of the\n      function.  */\n-  cp_parser_cache_group (parser, cache, CPP_CLOSE_BRACE, /*depth=*/0);\n+  first = parser->lexer->next_token;\n+  cp_parser_cache_group (parser, CPP_CLOSE_BRACE, /*depth=*/0);\n   /* Handle function try blocks.  */\n   while (cp_lexer_next_token_is_keyword (parser->lexer, RID_CATCH))\n-    cp_parser_cache_group (parser, cache, CPP_CLOSE_BRACE, /*depth=*/0);\n+    cp_parser_cache_group (parser, CPP_CLOSE_BRACE, /*depth=*/0);\n+  last = parser->lexer->next_token;\n \n   /* Save away the inline definition; we will process it when the\n      class is complete.  */\n-  DECL_PENDING_INLINE_INFO (fn) = cache;\n+  DECL_PENDING_INLINE_INFO (fn) = cp_token_cache_new (first, last);\n   DECL_PENDING_INLINE_P (fn) = 1;\n \n   /* We need to know that this was defined in the class, so that\n@@ -15827,13 +15693,12 @@ cp_parser_pre_parsed_nested_name_specifier (cp_parser *parser)\n   parser->object_scope = NULL_TREE;\n }\n \n-/* Add tokens to CACHE until a non-nested END token appears.  */\n+/* Consume tokens up through a non-nested END token. */\n \n static void\n-cp_parser_cache_group_1 (cp_parser *parser,\n-\t\t\t cp_token_cache *cache,\n-\t\t\t enum cpp_ttype end,\n-\t\t\t unsigned depth)\n+cp_parser_cache_group (cp_parser *parser,\n+\t\t       enum cpp_ttype end,\n+\t\t       unsigned depth)\n {\n   while (true)\n     {\n@@ -15848,43 +15713,20 @@ cp_parser_cache_group_1 (cp_parser *parser,\n \treturn;\n       /* Consume the next token.  */\n       token = cp_lexer_consume_token (parser->lexer);\n-      /* Add this token to the tokens we are saving.  */\n-      cp_token_cache_push_token (cache, token);\n       /* See if it starts a new group.  */\n       if (token->type == CPP_OPEN_BRACE)\n \t{\n-\t  cp_parser_cache_group_1 (parser, cache, CPP_CLOSE_BRACE, depth + 1);\n+\t  cp_parser_cache_group (parser, CPP_CLOSE_BRACE, depth + 1);\n \t  if (depth == 0)\n \t    return;\n \t}\n       else if (token->type == CPP_OPEN_PAREN)\n-\tcp_parser_cache_group_1 (parser, cache, CPP_CLOSE_PAREN, depth + 1);\n+\tcp_parser_cache_group (parser, CPP_CLOSE_PAREN, depth + 1);\n       else if (token->type == end)\n \treturn;\n     }\n }\n \n-/* Convenient interface for cp_parser_cache_group_1 that makes sure we\n-   preserve string tokens in both translated and untranslated\n-   forms.  */\n-\n-static void\n-cp_parser_cache_group (cp_parser *parser,\n-\t\t\t cp_token_cache *cache,\n-\t\t\t enum cpp_ttype end,\n-\t\t\t unsigned depth)\n-{\n-  int saved_c_lex_string_translate;\n-\n-  saved_c_lex_string_translate = c_lex_string_translate;\n-  c_lex_string_translate = -1;\n-\n-  cp_parser_cache_group_1 (parser, cache, end, depth);\n-\n-  c_lex_string_translate = saved_c_lex_string_translate;\n-}\n-\n-\n /* Begin parsing tentatively.  We always save tokens while parsing\n    tentatively so that if the tentative parsing fails we can restore the\n    tokens.  */"}, {"sha": "53c4cc37f0252ff451d3576cd74f3e41252dfc6f", "filename": "gcc/cp/semantics.c", "status": "modified", "additions": 1, "deletions": 1, "changes": 2, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fcp%2Fsemantics.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c162c75e43f4813cd30a1d4a693ce20f35a3f9fb/gcc%2Fcp%2Fsemantics.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fcp%2Fsemantics.c?ref=c162c75e43f4813cd30a1d4a693ce20f35a3f9fb", "patch": "@@ -2106,7 +2106,7 @@ begin_class_definition (tree t)\n      before.  */\n   if (! TYPE_ANONYMOUS_P (t))\n     {\n-      struct c_fileinfo *finfo = get_fileinfo (input_filename);\n+      struct c_fileinfo *finfo = get_fileinfo (lbasename (input_filename));\n       CLASSTYPE_INTERFACE_ONLY (t) = finfo->interface_only;\n       SET_CLASSTYPE_INTERFACE_UNKNOWN_X\n \t(t, finfo->interface_unknown);"}]}