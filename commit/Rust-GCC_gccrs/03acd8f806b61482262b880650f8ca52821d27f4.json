{"sha": "03acd8f806b61482262b880650f8ca52821d27f4", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6MDNhY2Q4ZjgwNmI2MTQ4MjI2MmI4ODA2NTBmOGNhNTI4MjFkMjdmNA==", "commit": {"author": {"name": "Bernd Schmidt", "email": "crux@pool.informatik.rwth-aachen.de", "date": "1998-10-27T22:38:40Z"}, "committer": {"name": "Jeff Law", "email": "law@gcc.gnu.org", "date": "1998-10-27T22:38:40Z"}, "message": "THe final localized spilling patches.  See the ChangeLog for details.\n\nFrom-SVN: r23374", "tree": {"sha": "8ffd68d532362a6487d8836c0bd4a8dafa5d9bb2", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/8ffd68d532362a6487d8836c0bd4a8dafa5d9bb2"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/03acd8f806b61482262b880650f8ca52821d27f4", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/03acd8f806b61482262b880650f8ca52821d27f4", "html_url": "https://github.com/Rust-GCC/gccrs/commit/03acd8f806b61482262b880650f8ca52821d27f4", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/03acd8f806b61482262b880650f8ca52821d27f4/comments", "author": null, "committer": null, "parents": [{"sha": "e6e174e5609155eca637b5b14a3dd5cc407a415a", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/e6e174e5609155eca637b5b14a3dd5cc407a415a", "html_url": "https://github.com/Rust-GCC/gccrs/commit/e6e174e5609155eca637b5b14a3dd5cc407a415a"}], "stats": {"total": 1805, "additions": 787, "deletions": 1018}, "files": [{"sha": "4cab3de6c71dd5dbd83756a2b7dbfaf757589beb", "filename": "gcc/ChangeLog", "status": "modified", "additions": 119, "deletions": 0, "changes": 119, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/03acd8f806b61482262b880650f8ca52821d27f4/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/03acd8f806b61482262b880650f8ca52821d27f4/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=03acd8f806b61482262b880650f8ca52821d27f4", "patch": "@@ -1,3 +1,122 @@\n+Tue Oct 27 23:32:34 1998  Bernd Schmidt <crux@pool.informatik.rwth-aachen.de>\n+\n+\t* reload.h (struct insn_chain): Add need_operand_change element.\n+\t* reload1.c (new_insn_chain): Clear it.\n+\t(calculate_needs_all_insns): Set it; don't overload need_reload.\n+\t(reload_as_needed): Use it.\n+\n+\t* reload.c (find_reloads_address): Use BASE_REG_CLASS instead of\n+\treload_address_base_reg_class throughout.  Similar for INDEX_REG_CLASS\n+\tand reload_address_index_reg_class.\n+\t(find_reloads_address_1): Likewise.\n+\t* reload.h (reload_address_base_reg_class,\n+\treload_address_index_reg_class): Don't declare.\n+\t* reload1.c (reg_old_renumber, pseudo_previous_regs,\n+\tpseudo_forbidden_regs, bad_spill_regs_global): New static variables.\n+\t(used_spill_regs): Now static.\n+\t(reload_address_base_reg_class, reload_address_index_reg_class,\n+\tregs_explicitly_used, counted_for_groups, counted_for_nongroups,\n+\tbasic_block_needs, max_needs, group_size, group_mode, max_groups,\n+\tmax_nongroups, max_needs_insn, max_groups_insn, max_nongroups_insn,\n+\tforbidden_regs):\n+\tDeleted variables.\n+\t(init_reload): Delete code to compute base/index reg classes.\n+\t(reload): Delete variable J.\n+\tDelete code to manage basic_block_needs.\n+\tDon't compute regs_explicitly_used.\n+\tAllocate, initialize and free reg_old_renumber, pseudo_forbidden_regs,\n+\tpseudo_previous_regs.\n+\tInitialize bad_spill_regs_global.\n+\tDon't call order_regs_for_reload here.\n+\tDon't initialize spill_reg_order and n_spills.\n+\tDon't forbid explicitly used regs to be used for spill regs.\n+\tChange main loop to infinite loop, with explicit break statements.\n+\tMake SOMETHING_CHANGED variable local to that loop.\n+\tDon't initialize max_needs, max_groups, max_nongroups, max_needs_insn,\n+\tmax_groups_insn, max_nongroups_insn, group_size, group_mode.\n+\tMake sure spilled_speudos is cleared before calling spill_hard_reg or\n+\tnew_spill_reg.\n+\tDon't call dump_needs.\n+\tDelete code to reset potential_reload_regs.\n+\tDelete code to terminate loop conditional on the global needs variables\n+\tshowing no further needs.\n+\t(calculate_needs_all_insns): Return void.  All callers changed.\n+\tInitialize somehing_needs_elimination here, not in reload.\n+\tDelete avoid_return_reg kludge.\n+\t(calculate_needs): Lose AVOID_RETURN_REG and GLOBAL args, return void.\n+\tAll callers changed.\n+\tInitialize the group_mode and group_size elements of the arg CHAIN.\n+\tDelete code to manage basic_block_needs.\n+\tOperate on elements of CHAIN instead of global variables.\n+\tDelete avoid_return_reg kludge.\n+\t(find_tworeg_group): Lose GLOBAL arg, take CHAIN arg, return void.\n+\tAll callers changed.\n+\tOperate on elements of CHAIN instead of global variables.\n+\tDelete special SMALL_REGISTER_CLASSES code.\n+\tDelete spill_failure code; now in new_spill_reg.\n+\t(find_group): Lose GLOBAL arg, take CHAIN arg, return void.\n+\tAll callers changed.\n+\tOperate on elements of CHAIN instead of global variables.\n+\t(maybe_mark_pseudo_spilled): New static function.\n+\t(find_reload_regs): Lose GLOBAL arg, take CHAIN arg, return void.\n+\tAll callers changed.\n+\tOperate on elements of CHAIN instead of global variables.\n+\tCall order_regs_for_reload here, not in reload.\n+\tInitialize spill_reg_order and n_spills.\n+\tSimplify test whether an asm insn is involved.\n+\tDelete spill_failure code; now in new_spill_reg.\n+\tCall maybe_mark_pseudo_spilled for everything marked as live in\n+\tCHAIN.  Merge CHAIN's used_spill_regs into the global variable\n+\tused_spill_regs.\n+\t(dump_needs): Take CHAIN arg.  No longer static, to prevent the\n+\tcompiler from optimizing this function (now unused) away.\n+\tOperate on elements of CHAIN instead of global variables.\n+\t(possible_group_p): Lose MAX_GROUPS arg, take CHAIN arg.  All callers\n+\tchanged.\n+\tOperate on elements of CHAIN instead of global variables.\n+\t(count_possible_groups): Lose GROUP_SIZE, GROUP_MODE, MAX_GROUPS args,\n+\ttake CHAIN arg.  All callers changed.\n+\tOperate on elements of CHAIN instead of global variables.\n+\t(new_spill_reg): Lose MAX_NEEDS, MAX_NONGROUPS, GLOBAL args, take\n+\tCHAIN, NONGROUP args.  Return void.  All callers changed.\n+\tVerify caller isn't trying to spill a pseudo.\n+\tSimplify test for illegal reg, just use bad_spill_regs.\n+\tGenerate better error messages.\n+\tOperate on elements of CHAIN instead of global variables.\n+\tMark spilled register in CHAIN's used_spill_regs element.\n+\tDon't call spill_hard_reg.\n+\t(spill_hard_reg): Lose GLOBAL arg, return void.  All callers changed.\n+\tMark spilled hard regs in bad_spill_regs_global.\n+\tMark affected pseudos in spilled_pseudos, but don't spill them.\n+\t(ior_hard_reg_set): New static function.\n+\t(finish_spills): Return int.  All callers changed.\n+\tCompute spill_reg_order, n_spills and spill_regs here.  Also update\n+\tregs_ever_live for regs used as spills.\n+\tFor every pseudo in spilled_pseudos, spill it and mark the previous\n+\thard reg it had in pseudo_previous_regs.  Compute which hard regs\n+\tarseudo): New static function.\n+\t(order_regs_for_reload): Take CHAIN arg.  All callers changed.\n+\tInitialize bad_spill_regs from bad_spill_regs_global, then merge any\n+\thard registers explicitly used across the current insn into the set.\n+\tCompute hard_reg_n_uses taking only pseudos live across this insn\n+\tinto account.\n+\tTweak sorting of potential_reload_regs.\n+\t(compare_spill_regs): Delete function.\n+\t(reload_as_needed): Don't sort the spill_regs array, it's computed\n+\tin proper order in finish_spills.\n+\tDelete avoid_return_reg kludge.\n+\tDelete code to manage basic_block_needs.\n+\t(allocate_reload_reg): Minor speed/readability tweaks.\n+\tOperate on elements of CHAIN instead of global variables.\n+\t(choose_reload_regs): Lose AVOID_RETURN_REG arg.  All callers changed.\n+\tDelete avoid_return_reg kludge.\n+\tInitialize reload_reg_used from CHAIN's used_spill_regs element.\n+\tDelete unused label FAIL.\n+\t(reload_combine): Replce reload_address_index_reg_class with\n+\tINDEX_REGS.\n+\tDon't use used_spill_regs to determine information about lifetime of\n+\thard regs.\n+\n Tue Oct 27 13:15:02 1998  Nick Clifton  <nickc@cygnus.com>\n \t\n \t* toplev.c (display_help): Ignore empty target specific"}, {"sha": "7d15b4b95cd9cc545fdc11f5da5bbf75f8f5f370", "filename": "gcc/reload.c", "status": "modified", "additions": 20, "deletions": 41, "changes": 61, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/03acd8f806b61482262b880650f8ca52821d27f4/gcc%2Freload.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/03acd8f806b61482262b880650f8ca52821d27f4/gcc%2Freload.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freload.c?ref=03acd8f806b61482262b880650f8ca52821d27f4", "patch": "@@ -4623,7 +4623,7 @@ find_reloads_address (mode, memrefloc, ad, loc, opnum, type, ind_levels, insn)\n \treturn 0;\n \n       /* If we do not have one of the cases above, we must do the reload.  */\n-      push_reload (ad, NULL_RTX, loc, NULL_PTR, reload_address_base_reg_class,\n+      push_reload (ad, NULL_RTX, loc, NULL_PTR, BASE_REG_CLASS,\n \t\t   GET_MODE (ad), VOIDmode, 0, 0, opnum, type);\n       return 1;\n     }\n@@ -4712,7 +4712,7 @@ find_reloads_address (mode, memrefloc, ad, loc, opnum, type, ind_levels, insn)\n \t  /* Must use TEM here, not AD, since it is the one that will\n \t     have any subexpressions reloaded, if needed.  */\n \t  push_reload (tem, NULL_RTX, loc, NULL_PTR,\n-\t\t       reload_address_base_reg_class, GET_MODE (tem),\n+\t\t       BASE_REG_CLASS, GET_MODE (tem),\n \t\t       VOIDmode, 0,\n \t\t       0, opnum, type);\n \t  return 1;\n@@ -4745,15 +4745,15 @@ find_reloads_address (mode, memrefloc, ad, loc, opnum, type, ind_levels, insn)\n \t  /* Reload the displacement into an index reg.\n \t     We assume the frame pointer or arg pointer is a base reg.  */\n \t  find_reloads_address_part (XEXP (ad, 1), &XEXP (ad, 1),\n-\t\t\t\t     reload_address_index_reg_class,\n-\t\t\t\t     GET_MODE (ad), opnum, type, ind_levels);\n+\t\t\t\t     INDEX_REG_CLASS, GET_MODE (ad), opnum,\n+\t\t\t\t     type, ind_levels);\n \t}\n       else\n \t{\n \t  /* If the sum of two regs is not necessarily valid,\n \t     reload the sum into a base reg.\n \t     That will at least work.  */\n-\t  find_reloads_address_part (ad, loc, reload_address_base_reg_class,\n+\t  find_reloads_address_part (ad, loc, BASE_REG_CLASS,\n \t\t\t\t     Pmode, opnum, type, ind_levels);\n \t}\n       return 1;\n@@ -4804,8 +4804,7 @@ find_reloads_address (mode, memrefloc, ad, loc, opnum, type, ind_levels, insn)\n \t\t\t\tplus_constant (XEXP (XEXP (ad, 0), 0),\n \t\t\t\t\t       INTVAL (XEXP (ad, 1))),\n \t\t\t   XEXP (XEXP (ad, 0), 1));\n-      find_reloads_address_part (XEXP (ad, 0), &XEXP (ad, 0),\n-\t\t\t\t reload_address_base_reg_class,\n+      find_reloads_address_part (XEXP (ad, 0), &XEXP (ad, 0), BASE_REG_CLASS,\n \t\t\t\t GET_MODE (ad), opnum, type, ind_levels);\n       find_reloads_address_1 (mode, XEXP (ad, 1), 1, &XEXP (ad, 1), opnum,\n \t\t\t      type, 0, insn);\n@@ -4829,8 +4828,7 @@ find_reloads_address (mode, memrefloc, ad, loc, opnum, type, ind_levels, insn)\n \t\t\t\tXEXP (XEXP (ad, 0), 0),\n \t\t\t\tplus_constant (XEXP (XEXP (ad, 0), 1),\n \t\t\t\t\t       INTVAL (XEXP (ad, 1))));\n-      find_reloads_address_part (XEXP (ad, 1), &XEXP (ad, 1),\n-\t\t\t\t reload_address_base_reg_class,\n+      find_reloads_address_part (XEXP (ad, 1), &XEXP (ad, 1), BASE_REG_CLASS,\n \t\t\t\t GET_MODE (ad), opnum, type, ind_levels);\n       find_reloads_address_1 (mode, XEXP (ad, 0), 1, &XEXP (ad, 0), opnum,\n \t\t\t      type, 0, insn);\n@@ -4874,8 +4872,7 @@ find_reloads_address (mode, memrefloc, ad, loc, opnum, type, ind_levels, insn)\n \t  loc = &XEXP (*memrefloc, 0);\n \t}\n \n-      find_reloads_address_part (ad, loc, reload_address_base_reg_class,\n-\t\t\t\t Pmode, opnum, type,\n+      find_reloads_address_part (ad, loc, BASE_REG_CLASS, Pmode, opnum, type,\n \t\t\t\t ind_levels);\n       return 1;\n     }\n@@ -5287,19 +5284,15 @@ find_reloads_address_1 (mode, x, context, loc, opnum, type, ind_levels, insn)\n \t\t  x = XEXP (x, 0);\n \t\t  reloadnum\n \t\t    = push_reload (x, x, loc, loc,\n-\t\t\t\t   (context\n-\t\t\t\t    ? reload_address_index_reg_class\n-\t\t\t\t    : reload_address_base_reg_class),\n+\t\t\t\t   (context ? INDEX_REG_CLASS : BASE_REG_CLASS),\n \t\t\t\t    GET_MODE (x), GET_MODE (x), 0, 0,\n \t\t\t\t    opnum, RELOAD_OTHER);\n \t\t}\n \t      else\n \t\t{\n \t\t  reloadnum\n \t\t    = push_reload (x, NULL_RTX, loc, NULL_PTR,\n-\t\t\t\t   (context\n-\t\t\t\t    ? reload_address_index_reg_class\n-\t\t\t\t    : reload_address_base_reg_class),\n+\t\t\t\t   (context ? INDEX_REG_CLASS : BASE_REG_CLASS),\n \t\t\t\t   GET_MODE (x), GET_MODE (x), 0, 0,\n \t\t\t\t   opnum, type);\n \t\t  reload_inc[reloadnum]\n@@ -5345,9 +5338,7 @@ find_reloads_address_1 (mode, x, context, loc, opnum, type, ind_levels, insn)\n \t\t\t\topnum, type, ind_levels, insn);\n \n \t  reloadnum = push_reload (x, NULL_RTX, loc, NULL_PTR,\n-\t\t\t\t   (context\n-\t\t\t\t    ? reload_address_index_reg_class\n-\t\t\t\t    : reload_address_base_reg_class),\n+\t\t\t\t   (context ? INDEX_REG_CLASS : BASE_REG_CLASS),\n \t\t\t\t   GET_MODE (x), VOIDmode, 0, 0, opnum, type);\n \t  reload_inc[reloadnum]\n \t    = find_inc_amount (PATTERN (this_insn), XEXP (x, 0));\n@@ -5376,8 +5367,7 @@ find_reloads_address_1 (mode, x, context, loc, opnum, type, ind_levels, insn)\n       find_reloads_address (GET_MODE (x), loc, XEXP (x, 0), &XEXP (x, 0),\n \t\t\t    opnum, ADDR_TYPE (type), ind_levels, insn);\n       push_reload (*loc, NULL_RTX, loc, NULL_PTR,\n-\t\t   (context ? reload_address_index_reg_class\n-\t\t    : reload_address_base_reg_class),\n+\t\t   (context ? INDEX_REG_CLASS : BASE_REG_CLASS),\n \t\t   GET_MODE (x), VOIDmode, 0, 0, opnum, type);\n       return 1;\n \n@@ -5387,10 +5377,8 @@ find_reloads_address_1 (mode, x, context, loc, opnum, type, ind_levels, insn)\n \n \tif (reg_equiv_constant[regno] != 0)\n \t  {\n-\t    find_reloads_address_part (reg_equiv_constant[regno], loc, \n-\t\t\t\t       (context\n-\t\t\t\t\t? reload_address_index_reg_class\n-\t\t\t\t\t: reload_address_base_reg_class),\n+\t    find_reloads_address_part (reg_equiv_constant[regno], loc,\n+\t\t\t\t       (context ? INDEX_REG_CLASS : BASE_REG_CLASS),\n \t\t\t\t       GET_MODE (x), opnum, type, ind_levels);\n \t    return 1;\n \t  }\n@@ -5400,9 +5388,7 @@ find_reloads_address_1 (mode, x, context, loc, opnum, type, ind_levels, insn)\n \tif (reg_equiv_mem[regno] != 0)\n \t  {\n \t    push_reload (reg_equiv_mem[regno], NULL_RTX, loc, NULL_PTR,\n-\t\t\t (context\n-\t\t\t  ? reload_address_index_reg_class\n-\t\t\t  : reload_address_base_reg_class),\n+\t\t\t (context ? INDEX_REG_CLASS : BASE_REG_CLASS),\n \t\t\t GET_MODE (x), VOIDmode, 0, 0, opnum, type);\n \t    return 1;\n \t  }\n@@ -5430,9 +5416,7 @@ find_reloads_address_1 (mode, x, context, loc, opnum, type, ind_levels, insn)\n \t\t  : REGNO_MODE_OK_FOR_BASE_P (regno, mode))))\n \t  {\n \t    push_reload (x, NULL_RTX, loc, NULL_PTR,\n-\t\t\t (context\n-\t\t\t  ? reload_address_index_reg_class\n-\t\t\t  : reload_address_base_reg_class),\n+\t\t\t (context ? INDEX_REG_CLASS : BASE_REG_CLASS),\n \t\t\t GET_MODE (x), VOIDmode, 0, 0, opnum, type);\n \t    return 1;\n \t  }\n@@ -5444,9 +5428,7 @@ find_reloads_address_1 (mode, x, context, loc, opnum, type, ind_levels, insn)\n \tif (regno_clobbered_p (regno, this_insn))\n \t  {\n \t    push_reload (x, NULL_RTX, loc, NULL_PTR,\n-\t\t\t (context\n-\t\t\t  ? reload_address_index_reg_class\n-\t\t\t  : reload_address_base_reg_class),\n+\t\t\t (context ? INDEX_REG_CLASS : BASE_REG_CLASS),\n \t\t\t GET_MODE (x), VOIDmode, 0, 0, opnum, type);\n \t    return 1;\n \t  }\n@@ -5467,9 +5449,7 @@ find_reloads_address_1 (mode, x, context, loc, opnum, type, ind_levels, insn)\n \t\t     : REGNO_MODE_OK_FOR_BASE_P (regno, mode)))\n \t\t{\n \t\t  push_reload (x, NULL_RTX, loc, NULL_PTR,\n-\t\t\t       (context\n-\t\t\t\t? reload_address_index_reg_class\n-\t\t\t\t: reload_address_base_reg_class),\n+\t\t\t       (context ? INDEX_REG_CLASS : BASE_REG_CLASS),\n \t\t\t       GET_MODE (x), VOIDmode, 0, 0, opnum, type);\n \t\t  return 1;\n \t\t}\n@@ -5478,9 +5458,8 @@ find_reloads_address_1 (mode, x, context, loc, opnum, type, ind_levels, insn)\n \t     is larger than the class size, then reload the whole SUBREG.  */\n \t  else\n \t    {\n-\t      enum reg_class class = (context\n-\t\t\t\t      ? reload_address_index_reg_class\n-\t\t\t\t      : reload_address_base_reg_class);\n+\t      enum reg_class class = (context ? INDEX_REG_CLASS\n+\t\t\t\t      : BASE_REG_CLASS);\n \t      if (CLASS_MAX_NREGS (class, GET_MODE (SUBREG_REG (x)))\n \t\t  > reg_class_size[class])\n \t\t{"}, {"sha": "5606a4ee74cb5e960353c3648713e27412b7fff2", "filename": "gcc/reload.h", "status": "modified", "additions": 3, "deletions": 2, "changes": 5, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/03acd8f806b61482262b880650f8ca52821d27f4/gcc%2Freload.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/03acd8f806b61482262b880650f8ca52821d27f4/gcc%2Freload.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freload.h?ref=03acd8f806b61482262b880650f8ca52821d27f4", "patch": "@@ -50,8 +50,6 @@ extern int memory_move_secondary_cost PROTO ((enum machine_mode, enum reg_class,\n /* Maximum number of reloads we can need.  */\n #define MAX_RELOADS (2 * MAX_RECOG_OPERANDS * (MAX_REGS_PER_ADDRESS + 1))\n \n-extern enum reg_class reload_address_base_reg_class;\n-extern enum reg_class reload_address_index_reg_class;\n extern rtx reload_in[MAX_RELOADS];\n extern rtx reload_out[MAX_RELOADS];\n extern rtx reload_in_reg[MAX_RELOADS];\n@@ -205,6 +203,9 @@ struct insn_chain\n \n   /* Nonzero if find_reloads said the insn requires reloading.  */\n   unsigned int need_reload:1;\n+  /* Nonzero if find_reloads needs to be run during reload_as_needed to\n+     perform modifications on any operands.  */\n+  unsigned int need_operand_change:1;\n   /* Nonzero if eliminate_regs_in_insn said it requires eliminations.  */\n   unsigned int need_elim:1;\n   /* Nonzero if this insn was inserted by perform_caller_saves.  */"}, {"sha": "ae0eb77137175163ce538b24e6b77c0d05b69468", "filename": "gcc/reload1.c", "status": "modified", "additions": 645, "deletions": 975, "changes": 1620, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/03acd8f806b61482262b880650f8ca52821d27f4/gcc%2Freload1.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/03acd8f806b61482262b880650f8ca52821d27f4/gcc%2Freload1.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freload1.c?ref=03acd8f806b61482262b880650f8ca52821d27f4", "patch": "@@ -54,9 +54,10 @@ Boston, MA 02111-1307, USA.  */\n    called ``reload regs'', and for each place where a pseudo reg\n    must be in a hard reg, copy it temporarily into one of the reload regs.\n \n-   All the pseudos that were formerly allocated to the hard regs that\n-   are now in use as reload regs must be ``spilled''.  This means\n-   that they go to other hard regs, or to stack slots if no other\n+   Reload regs are allocated locally for every instruction that needs\n+   reloads.  When there are pseudos which are allocated to a register that\n+   has been chosen as a reload reg, such pseudos must be ``spilled''.\n+   This means that they go to other hard regs, or to stack slots if no other\n    available hard regs can be found.  Spilling can invalidate more\n    insns, requiring additional need for reloads, so we must keep checking\n    until the process stabilizes.\n@@ -117,8 +118,11 @@ static int *reg_max_ref_width;\n    constant or memory slot.  */\n static rtx *reg_equiv_init;\n \n+/* Vector to remember old contents of reg_renumber before spilling.  */\n+static short *reg_old_renumber;\n+\n /* During reload_as_needed, element N contains the last pseudo regno reloaded\n-  into hard register N.  If that pseudo reg occupied more than one register,\n+   into hard register N.  If that pseudo reg occupied more than one register,\n    reg_reloaded_contents points to that pseudo for each spill register in\n    use; all of these must remain set for an inheritance to occur.  */\n static int reg_reloaded_contents[FIRST_PSEUDO_REGISTER];\n@@ -161,30 +165,45 @@ static rtx spill_reg_stored_to[FIRST_PSEUDO_REGISTER];\n    ?!?  This is no longer accurate.  */\n static short spill_reg_order[FIRST_PSEUDO_REGISTER];\n \n-/* This reg set indicates registers that may not be used for retrying global\n-   allocation.  The registers that may not be used include all spill registers\n-   and the frame pointer (if we are using one).  */\n-HARD_REG_SET forbidden_regs;\n-\n-/* This reg set indicates registers that are not good for spill registers.\n-   They will not be used to complete groups of spill registers.  This includes\n-   all fixed registers, registers that may be eliminated, and, if\n-   SMALL_REGISTER_CLASSES is zero, registers explicitly used in the rtl.\n-\n-   (spill_reg_order prevents these registers from being used to start a\n-   group.)  */\n+/* This reg set indicates registers that can't be used as spill registers for\n+   the currently processed insn.  These are the hard registers which are live\n+   during the insn, but not allocated to pseudos, as well as fixed\n+   registers.  */\n static HARD_REG_SET bad_spill_regs;\n \n+/* These are the hard registers that can't be used as spill register for any\n+   insn.  This includes registers used for user variables and registers that\n+   we can't eliminate.  A register that appears in this set also can't be used\n+   to retry register allocation.  */\n+static HARD_REG_SET bad_spill_regs_global;\n+\n /* Describes order of use of registers for reloading\n-   of spilled pseudo-registers.  `spills' is the number of\n-   elements that are actually valid; new ones are added at the end.  */\n+   of spilled pseudo-registers.  `n_spills' is the number of\n+   elements that are actually valid; new ones are added at the end.\n+\n+   Both spill_regs and spill_reg_order are used on two occasions:\n+   once during find_reload_regs, where they keep track of the spill registers\n+   for a single insn, but also during reload_as_needed where they show all\n+   the registers ever used by reload.  For the latter case, the information\n+   is calculated during finish_spills.  */\n static short spill_regs[FIRST_PSEUDO_REGISTER];\n \n-/* This reg set indicates those registers that have been used a spill\n-   registers.  This information is used in reorg.c, to help figure out\n-   what registers are live at any point.  It is assumed that all spill_regs\n-   are dead at every CODE_LABEL.  */\n-HARD_REG_SET used_spill_regs;\n+/* This vector of reg sets indicates, for each pseudo, which hard registers\n+   may not be used for retrying global allocation because the register was\n+   formerly spilled from one of them.  If we allowed reallocating a pseudo to\n+   a register that it was already allocated to, reload might not\n+   terminate.  */\n+static HARD_REG_SET *pseudo_previous_regs;\n+\n+/* This vector of reg sets indicates, for each pseudo, which hard\n+   registers may not be used for retrying global allocation because they\n+   are used as spill registers during one of the insns in which the\n+   pseudo is live.  */\n+static HARD_REG_SET *pseudo_forbidden_regs;\n+\n+/* All hard regs that have been used as spill registers for any insn are\n+   marked in this set.  */\n+static HARD_REG_SET used_spill_regs;\n \n /* Index of last register assigned as a spill register.  We allocate in\n    a round-robin fashion.  */\n@@ -197,21 +216,6 @@ static int last_spill_reg;\n    Empty elements at the end contain -1.  */\n static short potential_reload_regs[FIRST_PSEUDO_REGISTER];\n \n-/* 1 for a hard register that appears explicitly in the rtl\n-   (for example, function value registers, special registers\n-   used by insns, structure value pointer registers).  */\n-static char regs_explicitly_used[FIRST_PSEUDO_REGISTER];\n-\n-/* Indicates if a register was counted against the need for\n-   groups.  0 means it can count against max_nongroup instead.  */\n-static HARD_REG_SET counted_for_groups;\n-\n-/* Indicates if a register was counted against the need for\n-   non-groups.  0 means it can become part of a new group.\n-   During choose_reload_regs, 1 here means don't use this reg\n-   as part of a group, even if it seems to be otherwise ok.  */\n-static HARD_REG_SET counted_for_nongroups;\n-\n /* Nonzero if indirect addressing is supported on the machine; this means\n    that spilling (REG n) does not require reloading it into a register in\n    order to do (MEM (REG n)) or (MEM (PLUS (REG n) (CONST_INT c))).  The\n@@ -237,12 +241,6 @@ static int spill_stack_slot_width[FIRST_PSEUDO_REGISTER];\n /* Record which pseudos needed to be spilled.  */\n static regset spilled_pseudos;\n \n-/* Indexed by register class and basic block number, nonzero if there is\n-   any need for a spill register of that class in that basic block.\n-   The pointer is 0 if we did stupid allocation and don't know\n-   the structure of basic blocks.  */\n-char *basic_block_needs[N_REG_CLASSES];\n-\n /* First uid used by insns created by reload in this function.\n    Used in find_equiv_reg.  */\n int reload_first_uid;\n@@ -251,34 +249,19 @@ int reload_first_uid;\n    a call-clobbered reg across calls.  */\n int caller_save_needed;\n \n-/* The register class to use for a base register when reloading an\n-   address.  This is normally BASE_REG_CLASS, but it may be different\n-   when using SMALL_REGISTER_CLASSES and passing parameters in\n-   registers.  */\n-enum reg_class reload_address_base_reg_class;\n-\n-/* The register class to use for an index register when reloading an\n-   address.  This is normally INDEX_REG_CLASS, but it may be different\n-   when using SMALL_REGISTER_CLASSES and passing parameters in\n-   registers.  */\n-enum reg_class reload_address_index_reg_class;\n-\n /* Set to 1 while reload_as_needed is operating.\n    Required by some machines to handle any generated moves differently.  */\n-\n int reload_in_progress = 0;\n \n /* These arrays record the insn_code of insns that may be needed to\n    perform input and output reloads of special objects.  They provide a\n    place to pass a scratch register.  */\n-\n enum insn_code reload_in_optab[NUM_MACHINE_MODES];\n enum insn_code reload_out_optab[NUM_MACHINE_MODES];\n \n /* This obstack is used for allocation of rtl during register elimination.\n    The allocated storage can be freed once find_reloads has processed the\n    insn.  */\n-\n struct obstack reload_obstack;\n \n /* Points to the beginning of the reload_obstack.  All insn_chain structures\n@@ -299,7 +282,7 @@ extern rtx forced_labels;\n    examine.  */\n struct insn_chain *reload_insn_chain;\n \n-/* List of insns needing reloads.  */\n+/* List of all insns needing reloads.  */\n static struct insn_chain *insns_need_reload;\n \f\n /* This structure is used to record information about register eliminations.\n@@ -361,25 +344,32 @@ static int (*offsets_at)[NUM_ELIMINABLE_REGS];\n \n static int num_labels;\n \n-struct hard_reg_n_uses { int regno; int uses; };\n+struct hard_reg_n_uses\n+{\n+  int regno;\n+  unsigned int uses;\n+};\n \f\n-static void dump_needs\t\t\tPROTO((FILE *));\n static void maybe_fix_stack_asms\tPROTO((void));\n-static int calculate_needs_all_insns\tPROTO((int));\n-static int calculate_needs\t\tPROTO((struct insn_chain *, rtx, int));\n-static int find_reload_regs\t\tPROTO((int, FILE *));\n-static int find_tworeg_group\t\tPROTO((int, int, FILE *));\n-static int find_group\t\t\tPROTO((int, int, FILE *));\n-static int possible_group_p\t\tPROTO((int, int *));\n-static void count_possible_groups\tPROTO((int *, enum machine_mode *,\n-\t\t\t\t\t       int *, int));\n+static void calculate_needs_all_insns\tPROTO((int));\n+static void calculate_needs\t\tPROTO((struct insn_chain *));\n+static void find_reload_regs\t\tPROTO((struct insn_chain *chain,\n+\t\t\t\t\t       FILE *));\n+static void find_tworeg_group\t\tPROTO((struct insn_chain *, int,\n+\t\t\t\t\t       FILE *));\n+static void find_group\t\t\tPROTO((struct insn_chain *, int,\n+\t\t\t\t\t       FILE *));\n+static int possible_group_p\t\tPROTO((struct insn_chain *, int));\n+static void count_possible_groups\tPROTO((struct insn_chain *, int));\n static int modes_equiv_for_class_p\tPROTO((enum machine_mode,\n \t\t\t\t\t       enum machine_mode,\n \t\t\t\t\t       enum reg_class));\n static void delete_caller_save_insns\tPROTO((void));\n+\n static void spill_failure\t\tPROTO((rtx));\n-static int new_spill_reg\t\tPROTO((int, int, int *, int *, int,\n-\t\t\t\t\t       FILE *));\n+static void new_spill_reg\t\tPROTO((struct insn_chain *, int, int,\n+\t\t\t\t\t       int, FILE *));\n+static void maybe_mark_pseudo_spilled\tPROTO((int));\n static void delete_dead_insn\t\tPROTO((rtx));\n static void alter_reg  \t\t\tPROTO((int, int));\n static void set_label_offsets\t\tPROTO((rtx, rtx, int));\n@@ -389,12 +379,13 @@ static void mark_not_eliminable\t\tPROTO((rtx, rtx));\n static void set_initial_elim_offsets\tPROTO((void));\n static void init_elim_table\t\tPROTO((void));\n static void update_eliminables\t\tPROTO((HARD_REG_SET *));\n-static int spill_hard_reg\t\tPROTO((int, int, FILE *, int));\n-static void finish_spills\t\tPROTO((int, FILE *));\n+static void spill_hard_reg\t\tPROTO((int, FILE *, int));\n+static int finish_spills\t\tPROTO((int, FILE *));\n+static void ior_hard_reg_set\t\tPROTO((HARD_REG_SET *, HARD_REG_SET *));\n static void scan_paradoxical_subregs\tPROTO((rtx));\n static int hard_reg_use_compare\t\tPROTO((const GENERIC_PTR, const GENERIC_PTR));\n-static void order_regs_for_reload\tPROTO((void));\n-static int compare_spill_regs\t\tPROTO((const GENERIC_PTR, const GENERIC_PTR));\n+static void count_pseudo\t\tPROTO((struct hard_reg_n_uses *, int));\n+static void order_regs_for_reload\tPROTO((struct insn_chain *));\n static void reload_as_needed\t\tPROTO((int));\n static void forget_old_reloads_1\tPROTO((rtx, rtx));\n static int reload_reg_class_lower\tPROTO((const GENERIC_PTR, const GENERIC_PTR));\n@@ -406,8 +397,9 @@ static int reload_reg_free_p\t\tPROTO((int, int, enum reload_type));\n static int reload_reg_free_before_p\tPROTO((int, int, enum reload_type, int));\n static int reload_reg_free_for_value_p\tPROTO((int, int, enum reload_type, rtx, rtx, int));\n static int reload_reg_reaches_end_p\tPROTO((int, int, enum reload_type));\n-static int allocate_reload_reg\t\tPROTO((struct insn_chain *, int, int, int));\n-static void choose_reload_regs\t\tPROTO((struct insn_chain *, rtx));\n+static int allocate_reload_reg\t\tPROTO((struct insn_chain *, int, int,\n+\t\t\t\t\t       int));\n+static void choose_reload_regs\t\tPROTO((struct insn_chain *));\n static void merge_assigned_reloads\tPROTO((rtx));\n static void emit_reload_insns\t\tPROTO((struct insn_chain *));\n static void delete_output_reload\tPROTO((rtx, int, int));\n@@ -481,64 +473,6 @@ init_reload ()\n   /* Initialize obstack for our rtl allocation.  */\n   gcc_obstack_init (&reload_obstack);\n   reload_startobj = (char *) obstack_alloc (&reload_obstack, 0);\n-\n-  /* Decide which register class should be used when reloading\n-     addresses.  If we are using SMALL_REGISTER_CLASSES, and any\n-     parameters are passed in registers, then we do not want to use\n-     those registers when reloading an address.  Otherwise, if a\n-     function argument needs a reload, we may wind up clobbering\n-     another argument to the function which was already computed.  If\n-     we find a subset class which simply avoids those registers, we\n-     use it instead.  ??? It would be better to only use the\n-     restricted class when we actually are loading function arguments,\n-     but that is hard to determine.  */\n-  reload_address_base_reg_class = BASE_REG_CLASS;\n-  reload_address_index_reg_class = INDEX_REG_CLASS;\n-  if (SMALL_REGISTER_CLASSES)\n-    {\n-      int regno;\n-      HARD_REG_SET base, index;\n-      enum reg_class *p;\n-\n-      COPY_HARD_REG_SET (base, reg_class_contents[BASE_REG_CLASS]);\n-      COPY_HARD_REG_SET (index, reg_class_contents[INDEX_REG_CLASS]);\n-      for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno++)\n-\t{\n-\t  if (FUNCTION_ARG_REGNO_P (regno))\n-\t    {\n-\t      CLEAR_HARD_REG_BIT (base, regno);\n-\t      CLEAR_HARD_REG_BIT (index, regno);\n-\t    }\n-\t}\n-      \n-      GO_IF_HARD_REG_EQUAL (base, reg_class_contents[BASE_REG_CLASS],\n-\t\t\t    baseok);\n-      for (p = reg_class_subclasses[BASE_REG_CLASS];\n-\t   *p != LIM_REG_CLASSES;\n-\t   p++)\n-\t{\n-\t  GO_IF_HARD_REG_EQUAL (base, reg_class_contents[*p], usebase);\n-\t  continue;\n-\tusebase:\n-\t  reload_address_base_reg_class = *p;\n-\t  break;\n-\t}\n-    baseok:;\n-\n-      GO_IF_HARD_REG_EQUAL (index, reg_class_contents[INDEX_REG_CLASS],\n-\t\t\t    indexok);\n-      for (p = reg_class_subclasses[INDEX_REG_CLASS];\n-\t   *p != LIM_REG_CLASSES;\n-\t   p++)\n-\t{\n-\t  GO_IF_HARD_REG_EQUAL (index, reg_class_contents[*p], useindex);\n-\t  continue;\n-\tuseindex:\n-\t  reload_address_index_reg_class = *p;\n-\t  break;\n-\t}\n-    indexok:;\n-    }\n }\n \n /* List of insn chains that are currently unused.  */\n@@ -562,6 +496,7 @@ new_insn_chain ()\n       unused_insn_chains = c->next;\n     }\n   c->is_caller_save_insn = 0;\n+  c->need_operand_change = 0;\n   c->need_reload = 0;\n   c->need_elim = 0;\n   return c;\n@@ -587,43 +522,14 @@ compute_use_by_pseudos (to, from)\n \t SET_HARD_REG_BIT (*to, r + nregs);\n      });\n }\n-\n+\f\n /* Global variables used by reload and its subroutines.  */\n \n /* Set during calculate_needs if an insn needs register elimination.  */\n static int something_needs_elimination;\n /* Set during calculate_needs if an insn needs an operand changed.  */\n int something_needs_operands_changed;\n \n-/* For each class, number of reload regs needed in that class.\n-   This is the maximum over all insns of the needs in that class\n-   of the individual insn.  */\n-static int max_needs[N_REG_CLASSES];\n-\n-/* For each class, size of group of consecutive regs\n-   that is needed for the reloads of this class.  */\n-static int group_size[N_REG_CLASSES];\n-\n-/* For each class, max number of consecutive groups needed.\n-   (Each group contains group_size[CLASS] consecutive registers.)  */\n-static int max_groups[N_REG_CLASSES];\n-\n-/* For each class, max number needed of regs that don't belong\n-   to any of the groups.  */\n-static int max_nongroups[N_REG_CLASSES];\n-\n-/* For each class, the machine mode which requires consecutive\n-   groups of regs of that class.\n-   If two different modes ever require groups of one class,\n-   they must be the same size and equally restrictive for that class,\n-   otherwise we can't handle the complexity.  */\n-static enum machine_mode group_mode[N_REG_CLASSES];\n-\n-/* Record the insn where each maximum need is first found.  */\n-static rtx max_needs_insn[N_REG_CLASSES];\n-static rtx max_groups_insn[N_REG_CLASSES];\n-static rtx max_nongroups_insn[N_REG_CLASSES];\n-\n /* Nonzero means we couldn't get enough spill regs.  */\n static int failure;\n \n@@ -651,7 +557,7 @@ reload (first, global, dumpfile)\n      int global;\n      FILE *dumpfile;\n {\n-  register int i, j;\n+  register int i;\n   register rtx insn;\n   register struct elim_table *ep;\n \n@@ -660,8 +566,6 @@ reload (first, global, dumpfile)\n   char *real_known_ptr = NULL_PTR;\n   int (*real_at_ptr)[NUM_ELIMINABLE_REGS];\n \n-  int something_changed;\n-\n   /* Make sure even insns with volatile mem refs are recognizable.  */\n   init_recog ();\n \n@@ -676,19 +580,11 @@ reload (first, global, dumpfile)\n   /* Enable find_equiv_reg to distinguish insns made by reload.  */\n   reload_first_uid = get_max_uid ();\n \n-  for (i = 0; i < N_REG_CLASSES; i++)\n-    basic_block_needs[i] = 0;\n-\n #ifdef SECONDARY_MEMORY_NEEDED\n   /* Initialize the secondary memory table.  */\n   clear_secondary_mem ();\n #endif\n \n-  /* Remember which hard regs appear explicitly\n-     before we merge into `regs_ever_live' the ones in which\n-     pseudo regs have been allocated.  */\n-  bcopy (regs_ever_live, regs_explicitly_used, sizeof regs_ever_live);\n-\n   /* We don't have a stack slot for any spill reg yet.  */\n   bzero ((char *) spill_stack_slot, sizeof spill_stack_slot);\n   bzero ((char *) spill_stack_slot_width, sizeof spill_stack_slot_width);\n@@ -735,9 +631,15 @@ reload (first, global, dumpfile)\n   bzero ((char *) reg_equiv_address, max_regno * sizeof (rtx));\n   reg_max_ref_width = (int *) xmalloc (max_regno * sizeof (int));\n   bzero ((char *) reg_max_ref_width, max_regno * sizeof (int));\n+  reg_old_renumber = (short *) xmalloc (max_regno * sizeof (short));\n+  bcopy (reg_renumber, reg_old_renumber, max_regno * sizeof (short));\n+  pseudo_forbidden_regs\n+    = (HARD_REG_SET *) xmalloc (max_regno * sizeof (HARD_REG_SET));\n+  pseudo_previous_regs\n+    = (HARD_REG_SET *) xmalloc (max_regno * sizeof (HARD_REG_SET));\n \n-  if (SMALL_REGISTER_CLASSES)\n-    CLEAR_HARD_REG_SET (forbidden_regs);\n+  CLEAR_HARD_REG_SET (bad_spill_regs_global);\n+  bzero ((char *) pseudo_previous_regs, max_regno * sizeof (HARD_REG_SET));\n \n   /* Look for REG_EQUIV notes; record what each pseudo is equivalent to.\n      Also find all paradoxical subregs and find largest such for each pseudo.\n@@ -870,83 +772,47 @@ reload (first, global, dumpfile)\n       free (reg_equiv_init);\n       free (reg_equiv_address);\n       free (reg_max_ref_width);\n+      free (reg_old_renumber);\n+      free (pseudo_previous_regs);\n+      free (pseudo_forbidden_regs);\n       return 0;\n     }\n #endif\n \n-  /* Compute the order of preference for hard registers to spill.\n-     Store them by decreasing preference in potential_reload_regs.  */\n-\n-  order_regs_for_reload ();\n-\n   maybe_fix_stack_asms ();\n \n-  /* So far, no hard regs have been spilled.  */\n-  n_spills = 0;\n-  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n-    spill_reg_order[i] = -1;\n-\n+  insns_need_reload = 0;\n+  something_needs_elimination = 0;\n+  \n   /* Initialize to -1, which means take the first spill register.  */\n   last_spill_reg = -1;\n \n-  /* On most machines, we can't use any register explicitly used in the\n-     rtl as a spill register.  But on some, we have to.  Those will have\n-     taken care to keep the life of hard regs as short as possible.  */\n-\n-  if (! SMALL_REGISTER_CLASSES)\n-    COPY_HARD_REG_SET (forbidden_regs, bad_spill_regs);\n-\n   spilled_pseudos = ALLOCA_REG_SET ();\n \n   /* Spill any hard regs that we know we can't eliminate.  */\n+  CLEAR_HARD_REG_SET (used_spill_regs);\n   for (ep = reg_eliminate; ep < &reg_eliminate[NUM_ELIMINABLE_REGS]; ep++)\n     if (! ep->can_eliminate)\n-      spill_hard_reg (ep->from, global, dumpfile, 1);\n+      spill_hard_reg (ep->from, dumpfile, 1);\n \n #if HARD_FRAME_POINTER_REGNUM != FRAME_POINTER_REGNUM\n   if (frame_pointer_needed)\n-    spill_hard_reg (HARD_FRAME_POINTER_REGNUM, global, dumpfile, 1);\n+    spill_hard_reg (HARD_FRAME_POINTER_REGNUM, dumpfile, 1);\n #endif\n-\n   finish_spills (global, dumpfile);\n \n-  if (global)\n-    for (i = 0; i < N_REG_CLASSES; i++)\n-      {\n-\tbasic_block_needs[i] = (char *) alloca (n_basic_blocks);\n-\tbzero (basic_block_needs[i], n_basic_blocks);\n-      }\n-\n   /* From now on, we need to emit any moves without making new pseudos.  */\n   reload_in_progress = 1;\n \n   /* This loop scans the entire function each go-round\n      and repeats until one repetition spills no additional hard regs.  */\n-\n-  /* This flag is set when a pseudo reg is spilled,\n-     to require another pass.  Note that getting an additional reload\n-     reg does not necessarily imply any pseudo reg was spilled;\n-     sometimes we find a reload reg that no pseudo reg was allocated in.  */\n-  something_changed = 1;\n-\n-  /* This flag is set if there are any insns that require register\n-     eliminations.  */\n-  something_needs_elimination = 0;\n-  something_needs_operands_changed = 0;\n-  while (something_changed)\n+  for (;;)\n     {\n-      HOST_WIDE_INT starting_frame_size;\n+      int something_changed;\n+      int did_spill;\n+      struct insn_chain *chain;\n \n-      something_changed = 0;\n-      bzero ((char *) max_needs, sizeof max_needs);\n-      bzero ((char *) max_groups, sizeof max_groups);\n-      bzero ((char *) max_nongroups, sizeof max_nongroups);\n-      bzero ((char *) max_needs_insn, sizeof max_needs_insn);\n-      bzero ((char *) max_groups_insn, sizeof max_groups_insn);\n-      bzero ((char *) max_nongroups_insn, sizeof max_nongroups_insn);\n-      bzero ((char *) group_size, sizeof group_size);\n-      for (i = 0; i < N_REG_CLASSES; i++)\n-\tgroup_mode[i] = VOIDmode;\n+      HOST_WIDE_INT starting_frame_size;\n \n       /* Round size of stack frame to BIGGEST_ALIGNMENT.  This must be done\n \t here because the stack size may be a part of the offset computation\n@@ -957,7 +823,7 @@ reload (first, global, dumpfile)\n       starting_frame_size = get_frame_size ();\n \n       set_initial_elim_offsets ();\n-      \n+\n       /* For each pseudo register that has an equivalent location defined,\n \t try to eliminate any eliminable registers (such as the frame pointer)\n \t assuming initial offsets for the replacement register, which\n@@ -1010,23 +876,14 @@ reload (first, global, dumpfile)\n \t\treg_equiv_memory_loc[i] = 0;\n \t\treg_equiv_init[i] = 0;\n \t\talter_reg (i, -1);\n-\t\tsomething_changed = 1;\n \t      }\n \t  }\n \n-      /* Insert code to save and restore call-clobbered hard regs\n-\t around calls.  Tell if what mode to use so that we will process\n-\t those insns in reload_as_needed if we have to.  */\n-\n       if (caller_save_needed)\n \tsetup_save_areas ();\n \n+      /* If we allocated another stack slot, redo elimination bookkeeping.  */\n       if (starting_frame_size != get_frame_size ())\n-\tsomething_changed = 1;\n-\n-      /* If we allocated another pseudo to the stack, redo elimination\n-\t bookkeeping.  */\n-      if (something_changed)\n \tcontinue;\n \n       if (caller_save_needed)\n@@ -1036,84 +893,46 @@ reload (first, global, dumpfile)\n \t  reload_firstobj = (char *) obstack_alloc (&reload_obstack, 0);\n \t}\n \n-      something_changed |= calculate_needs_all_insns (global);\n+      calculate_needs_all_insns (global);\n+\n+      CLEAR_REG_SET (spilled_pseudos);\n+      did_spill = 0;\n+\n+      something_changed = 0;\n \n       /* If we allocated any new memory locations, make another pass\n \t since it might have changed elimination offsets.  */\n       if (starting_frame_size != get_frame_size ())\n \tsomething_changed = 1;\n \n-      if (dumpfile)\n-\tdump_needs (dumpfile);\n-\n       {\n \tHARD_REG_SET to_spill;\n \tCLEAR_HARD_REG_SET (to_spill);\n \tupdate_eliminables (&to_spill);\n \tfor (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n \t  if (TEST_HARD_REG_BIT (to_spill, i))\n \t    {\n-\t      spill_hard_reg (i, global, dumpfile, 1);\n-\t      something_changed = 1;\n+\t      spill_hard_reg (i, dumpfile, 1);\n+\t      did_spill = 1;\n \t    }\n       }\n \n-      finish_spills (global, dumpfile);\n-\n-      /* If all needs are met, we win.  */\n-\n-      for (i = 0; i < N_REG_CLASSES; i++)\n-\tif (max_needs[i] > 0 || max_groups[i] > 0 || max_nongroups[i] > 0)\n-\t  break;\n-      if (i == N_REG_CLASSES && ! something_changed)\n-\tbreak;\n-\n-      /* Not all needs are met; must spill some hard regs.  */\n-\n-      /* Put all registers spilled so far back in potential_reload_regs, but\n-\t put them at the front, since we've already spilled most of the\n-\t pseudos in them (we might have left some pseudos unspilled if they\n-\t were in a block that didn't need any spill registers of a conflicting\n-\t class.  We used to try to mark off the need for those registers,\n-\t but doing so properly is very complex and reallocating them is the\n-\t simpler approach.  First, \"pack\" potential_reload_regs by pushing \n-\t any nonnegative entries towards the end.  That will leave room \n-\t for the registers we already spilled.\n-\n-\t Also, undo the marking of the spill registers from the last time\n-\t around in FORBIDDEN_REGS since we will be probably be allocating\n-\t them again below.\n-\n-\t ??? It is theoretically possible that we might end up not using one\n-\t of our previously-spilled registers in this allocation, even though\n-\t they are at the head of the list.  It's not clear what to do about\n-\t this, but it was no better before, when we marked off the needs met\n-\t by the previously-spilled registers.  With the current code, globals\n-\t can be allocated into these registers, but locals cannot.  */\n-\n-      if (n_spills)\n-\t{\n-\t  for (i = j = FIRST_PSEUDO_REGISTER - 1; i >= 0; i--)\n-\t    if (potential_reload_regs[i] != -1)\n-\t      potential_reload_regs[j--] = potential_reload_regs[i];\n-\n-\t  for (i = 0; i < n_spills; i++)\n-\t    {\n-\t      potential_reload_regs[i] = spill_regs[i];\n-\t      spill_reg_order[spill_regs[i]] = -1;\n-\t      CLEAR_HARD_REG_BIT (forbidden_regs, spill_regs[i]);\n-\t    }\n-\n-\t  n_spills = 0;\n-\t}\n+      CLEAR_HARD_REG_SET (used_spill_regs);\n+      /* Try to satisfy the needs for each insn.  */\n+      for (chain = insns_need_reload; chain != 0;\n+\t   chain = chain->next_need_reload)\n+\tfind_reload_regs (chain, dumpfile);\n \n-      something_changed |= find_reload_regs (global, dumpfile);\n       if (failure)\n \tgoto failed;\n \n-      finish_spills (global, dumpfile);\n+      if (insns_need_reload != 0 || did_spill)\n+\tsomething_changed |= finish_spills (global, dumpfile);\n \n-      if (something_changed)\n+      if (! something_changed)\n+\tbreak;\n+\n+      if (caller_save_needed)\n \tdelete_caller_save_insns ();\n     }\n \n@@ -1149,7 +968,8 @@ reload (first, global, dumpfile)\n      by generating move instructions to move the must-be-register\n      values into or out of the reload registers.  */\n \n-  if (insns_need_reload != 0 || something_needs_elimination)\n+  if (insns_need_reload != 0 || something_needs_elimination\n+      || something_needs_operands_changed)\n     reload_as_needed (global);\n \n   /* If we were able to eliminate the frame pointer, show that it is no\n@@ -1276,6 +1096,9 @@ reload (first, global, dumpfile)\n   free (reg_equiv_init);\n   free (reg_equiv_address);\n   free (reg_max_ref_width);\n+  free (reg_old_renumber);\n+  free (pseudo_previous_regs);\n+  free (pseudo_forbidden_regs);\n \n   FREE_REG_SET (spilled_pseudos);\n \n@@ -1403,29 +1226,30 @@ maybe_fix_stack_asms ()\n #endif\n }\n \n-/* Walk the insns of the current function, starting with FIRST, and collect\n-   information about the need to do register elimination and the need to\n-   perform reloads.  */\n-static int\n+\f\n+/* Walk the chain of insns, and determine for each whether it needs reloads\n+   and/or eliminations.  Build the corresponding insns_need_reload list, and\n+   set something_needs_elimination as appropriate.  */\n+static void\n calculate_needs_all_insns (global)\n      int global;\n {\n-  int something_changed = 0;\n-  rtx after_call = 0;\n-  int after_call_nregs;\n   struct insn_chain **pprev_reload = &insns_need_reload;\n-  struct insn_chain *chain;\n+  struct insn_chain **pchain;\n \n-  /* Compute the most additional registers needed by any instruction.\n-     Collect information separately for each class of regs.  */\n-  \n-  for (chain = reload_insn_chain; chain; chain = chain->next)\n+  something_needs_elimination = 0;\n+\n+  for (pchain = &reload_insn_chain; *pchain != 0; pchain = &(*pchain)->next)\n     {\n-      rtx insn = chain->insn;\n+      rtx insn;\n+      struct insn_chain *chain;\n+\n+      chain = *pchain;\n+      insn = chain->insn;\n \n-      /* If this is a label, a JUMP_INSN, or has REG_NOTES (which\n-\t might include REG_LABEL), we need to see what effects this\n-\t has on the known offsets at labels.  */\n+      /* If this is a label, a JUMP_INSN, or has REG_NOTES (which might\n+\t include REG_LABEL), we need to see what effects this has on the\n+\t known offsets at labels.  */\n \n       if (GET_CODE (insn) == CODE_LABEL || GET_CODE (insn) == JUMP_INSN\n \t  || (GET_RTX_CLASS (GET_CODE (insn)) == 'i'\n@@ -1440,55 +1264,6 @@ calculate_needs_all_insns (global)\n \t  int did_elimination = 0;\n \t  int operands_changed = 0;\n \n-\t  /* Nonzero means don't use a reload reg that overlaps\n-\t     the place where a function value can be returned.  */\n-\t  rtx avoid_return_reg = 0;\n-\n-\t  /* Set avoid_return_reg if this is an insn\n-\t     that might use the value of a function call.  */\n-\t  if (SMALL_REGISTER_CLASSES && GET_CODE (insn) == CALL_INSN)\n-\t    {\n-\t      if (GET_CODE (PATTERN (insn)) == SET)\n-\t\t{\n-\t\t  after_call = SET_DEST (PATTERN (insn));\n-\t\t  after_call_nregs = HARD_REGNO_NREGS (REGNO (after_call),\n-\t\t\t\t\t\t       GET_MODE (after_call));\n-\t\t}\n-\t      else if (GET_CODE (PATTERN (insn)) == PARALLEL\n-\t\t       && GET_CODE (XVECEXP (PATTERN (insn), 0, 0)) == SET)\n-\t\t{\n-\t\t  after_call = SET_DEST (XVECEXP (PATTERN (insn), 0, 0));\n-\t\t  after_call_nregs = HARD_REGNO_NREGS (REGNO (after_call),\n-\t\t\t\t\t\t       GET_MODE (after_call));\n-\t\t}\n-\t      else\n-\t\tafter_call = 0;\n-\t    }\n-\t  else if (SMALL_REGISTER_CLASSES && after_call != 0\n-\t\t   && !(GET_CODE (PATTERN (insn)) == SET\n-\t\t\t&& SET_DEST (PATTERN (insn)) == stack_pointer_rtx)\n-\t\t   && GET_CODE (PATTERN (insn)) != CLOBBER\n-\t\t   && GET_CODE (PATTERN (insn)) != USE)\n-\t    {\n-\t      if (reg_referenced_p (after_call, PATTERN (insn)))\n-\t\t{\n-\t\t  avoid_return_reg = after_call;\n-\t\t  if (! --after_call_nregs)\n-\t\t    after_call = 0;\n-\t\t  else\n-\t\t    {\n-\t\t      /* If INSN copies the return register in a single chunk,\n-\t\t\t clear after_call now.  */\n-\t\t      rtx set = single_set (insn);\n-\t\t      if (set && (GET_MODE_SIZE (GET_MODE (SET_DEST (set)))\n-\t\t\t\t  == GET_MODE_SIZE (GET_MODE (after_call))))\n-\t\t\tafter_call = 0;\n-\t\t    }\n-\t\t}\n-\t      else\n-\t\tafter_call = 0;\n-\t    }\n-\n \t  /* If needed, eliminate any eliminable registers.  */\n \t  if (num_eliminable)\n \t    did_elimination = eliminate_regs_in_insn (insn, 0);\n@@ -1524,7 +1299,8 @@ calculate_needs_all_insns (global)\n \t  /* Remember for later shortcuts which insns had any reloads or\n \t     register eliminations.  */\n \t  chain->need_elim = did_elimination;\n-\t  chain->need_reload = (n_reloads > 0 | operands_changed);\n+\t  chain->need_reload = n_reloads > 0;\n+\t  chain->need_operand_change = operands_changed;\n \n \t  /* Discard any register replacements done.  */\n \t  if (did_elimination)\n@@ -1542,41 +1318,36 @@ calculate_needs_all_insns (global)\n \t    {\n \t      *pprev_reload = chain;\n \t      pprev_reload = &chain->next_need_reload;\n-\t      something_changed |= calculate_needs (chain, avoid_return_reg,\n-\t\t\t\t\t\t    global);\n+\n+\t      calculate_needs (chain);\n \t    }\n \t}\n     }\n   *pprev_reload = 0;\n-  return something_changed;\n }\n \n-/* To compute the number of reload registers of each class \n-   needed for an insn, we must simulate what choose_reload_regs\n-   can do.  We do this by splitting an insn into an \"input\" and\n-   an \"output\" part.  RELOAD_OTHER reloads are used in both. \n-   The input part uses those reloads, RELOAD_FOR_INPUT reloads,\n-   which must be live over the entire input section of reloads,\n-   and the maximum of all the RELOAD_FOR_INPUT_ADDRESS and\n-   RELOAD_FOR_OPERAND_ADDRESS reloads, which conflict with the\n-   inputs.\n-\n-   The registers needed for output are RELOAD_OTHER and\n-   RELOAD_FOR_OUTPUT, which are live for the entire output\n-   portion, and the maximum of all the RELOAD_FOR_OUTPUT_ADDRESS\n-   reloads for each operand.\n+/* Compute the most additional registers needed by one instruction,\n+   given by CHAIN.  Collect information separately for each class of regs.\n+\n+   To compute the number of reload registers of each class needed for an\n+   insn, we must simulate what choose_reload_regs can do.  We do this by\n+   splitting an insn into an \"input\" and an \"output\" part.  RELOAD_OTHER\n+   reloads are used in both.  The input part uses those reloads,\n+   RELOAD_FOR_INPUT reloads, which must be live over the entire input section\n+   of reloads, and the maximum of all the RELOAD_FOR_INPUT_ADDRESS and\n+   RELOAD_FOR_OPERAND_ADDRESS reloads, which conflict with the inputs.\n+\n+   The registers needed for output are RELOAD_OTHER and RELOAD_FOR_OUTPUT,\n+   which are live for the entire output portion, and the maximum of all the\n+   RELOAD_FOR_OUTPUT_ADDRESS reloads for each operand.\n \n    The total number of registers needed is the maximum of the\n    inputs and outputs.  */\n \n-static int\n-calculate_needs (chain, avoid_return_reg, global)\n+static void\n+calculate_needs (chain)\n      struct insn_chain *chain;\n-     rtx avoid_return_reg;\n-     int global;\n {\n-  rtx insn = chain->insn;\n-  int something_changed = 0;\n   int i;\n \n   /* Each `struct needs' corresponds to one RELOAD_... type.  */\n@@ -1594,6 +1365,9 @@ calculate_needs (chain, avoid_return_reg, global)\n     struct needs out_addr_addr[MAX_RECOG_OPERANDS];\n   } insn_needs;\n \n+  bzero ((char *) chain->group_size, sizeof chain->group_size);\n+  for (i = 0; i < N_REG_CLASSES; i++)\n+    chain->group_mode[i] = VOIDmode;\n   bzero ((char *) &insn_needs, sizeof insn_needs);\n \n   /* Count each reload once in every class\n@@ -1617,16 +1391,6 @@ calculate_needs (chain, avoid_return_reg, global)\n \t      && ! reload_secondary_p[i]))\n \tcontinue;\n \n-      /* Show that a reload register of this class is needed\n-\t in this basic block.  We do not use insn_needs and\n-\t insn_groups because they are overly conservative for\n-\t this purpose.  */\n-      if (global && ! basic_block_needs[(int) class][chain->block])\n-\t{\n-\t  basic_block_needs[(int) class][chain->block] = 1;\n-\t  something_changed = 1;\n-\t}\n-\n       mode = reload_inmode[i];\n       if (GET_MODE_SIZE (reload_outmode[i]) > GET_MODE_SIZE (mode))\n \tmode = reload_outmode[i];\n@@ -1684,18 +1448,18 @@ calculate_needs (chain, avoid_return_reg, global)\n \t  /* Record size and mode of a group of this class.  */\n \t  /* If more than one size group is needed,\n \t     make all groups the largest needed size.  */\n-\t  if (group_size[(int) class] < size)\n+\t  if (chain->group_size[(int) class] < size)\n \t    {\n-\t      other_mode = group_mode[(int) class];\n+\t      other_mode = chain->group_mode[(int) class];\n \t      allocate_mode = mode;\n \n-\t      group_size[(int) class] = size;\n-\t      group_mode[(int) class] = mode;\n+\t      chain->group_size[(int) class] = size;\n+\t      chain->group_mode[(int) class] = mode;\n \t    }\n \t  else\n \t    {\n \t      other_mode = mode;\n-\t      allocate_mode = group_mode[(int) class];\n+\t      allocate_mode = chain->group_mode[(int) class];\n \t    }\n \n \t  /* Crash if two dissimilar machine modes both need\n@@ -1705,7 +1469,7 @@ calculate_needs (chain, avoid_return_reg, global)\n \t      && ! modes_equiv_for_class_p (allocate_mode,\n \t\t\t\t\t    other_mode, class))\n \t    fatal_insn (\"Two dissimilar machine modes both need groups of consecutive regs of the same class\",\n-\t\t\tinsn);\n+\t\t\tchain->insn);\n \t}\n       else if (size == 1)\n \t{\n@@ -1794,102 +1558,10 @@ calculate_needs (chain, avoid_return_reg, global)\n \t\tinsn_needs.other_addr.groups[i]);\n     }\n \n-  /* If this insn stores the value of a function call,\n-     and that value is in a register that has been spilled,\n-     and if the insn needs a reload in a class\n-     that might use that register as the reload register,\n-     then add an extra need in that class.\n-     This makes sure we have a register available that does\n-     not overlap the return value.  */\n-\n-  if (SMALL_REGISTER_CLASSES && avoid_return_reg)\n-    {\n-      int regno = REGNO (avoid_return_reg);\n-      int nregs\n-\t= HARD_REGNO_NREGS (regno, GET_MODE (avoid_return_reg));\n-      int r;\n-      int basic_needs[N_REG_CLASSES], basic_groups[N_REG_CLASSES];\n-\n-      /* First compute the \"basic needs\", which counts a\n-\t need only in the smallest class in which it\n-\t is required.  */\n-\n-      bcopy ((char *) insn_needs.other.regs[0],\n-\t     (char *) basic_needs, sizeof basic_needs);\n-      bcopy ((char *) insn_needs.other.groups,\n-\t     (char *) basic_groups, sizeof basic_groups);\n-\n-      for (i = 0; i < N_REG_CLASSES; i++)\n-\t{\n-\t  enum reg_class *p;\n-\n-\t  if (basic_needs[i] >= 0)\n-\t    for (p = reg_class_superclasses[i];\n-\t\t *p != LIM_REG_CLASSES; p++)\n-\t      basic_needs[(int) *p] -= basic_needs[i];\n-\n-\t  if (basic_groups[i] >= 0)\n-\t    for (p = reg_class_superclasses[i];\n-\t\t *p != LIM_REG_CLASSES; p++)\n-\t      basic_groups[(int) *p] -= basic_groups[i];\n-\t}\n-\n-      /* Now count extra regs if there might be a conflict with\n-\t the return value register.  */\n-\n-      for (r = regno; r < regno + nregs; r++)\n-\tif (spill_reg_order[r] >= 0)\n-\t  for (i = 0; i < N_REG_CLASSES; i++)\n-\t    if (TEST_HARD_REG_BIT (reg_class_contents[i], r))\n-\t      {\n-\t\tif (basic_needs[i] > 0)\n-\t\t  {\n-\t\t    enum reg_class *p;\n-\n-\t\t    insn_needs.other.regs[0][i]++;\n-\t\t    p = reg_class_superclasses[i];\n-\t\t    while (*p != LIM_REG_CLASSES)\n-\t\t      insn_needs.other.regs[0][(int) *p++]++;\n-\t\t  }\n-\t\tif (basic_groups[i] > 0)\n-\t\t  {\n-\t\t    enum reg_class *p;\n-\n-\t\t    insn_needs.other.groups[i]++;\n-\t\t    p = reg_class_superclasses[i];\n-\t\t    while (*p != LIM_REG_CLASSES)\n-\t\t      insn_needs.other.groups[(int) *p++]++;\n-\t\t  }\n-\t      }\n-    }\n-\n-  /* For each class, collect maximum need of any insn.  */\n-\n-  for (i = 0; i < N_REG_CLASSES; i++)\n-    {\n-      if (max_needs[i] < insn_needs.other.regs[0][i])\n-\t{\n-\t  max_needs[i] = insn_needs.other.regs[0][i];\n-\t  max_needs_insn[i] = insn;\n-\t}\n-      if (max_groups[i] < insn_needs.other.groups[i])\n-\t{\n-\t  max_groups[i] = insn_needs.other.groups[i];\n-\t  max_groups_insn[i] = insn;\n-\t}\n-      if (max_nongroups[i] < insn_needs.other.regs[1][i])\n-\t{\n-\t  max_nongroups[i] = insn_needs.other.regs[1][i];\n-\t  max_nongroups_insn[i] = insn;\n-\t}\n-    }\n-\n   /* Record the needs for later.  */\n   chain->need = insn_needs.other;\n-\n-  return something_changed;\n }\n-\n+\f\n /* Find a group of exactly 2 registers.\n \n    First try to fill out the group by spilling a single register which\n@@ -1899,9 +1571,10 @@ calculate_needs (chain, avoid_return_reg, global)\n    which are explicitly used.\n \n    Then try to create a group from any pair of registers.  */\n-static int\n-find_tworeg_group (global, class, dumpfile)\n-     int global;\n+\n+static void\n+find_tworeg_group (chain, class, dumpfile)\n+     struct insn_chain *chain;\n      int class;\n      FILE *dumpfile;\n {\n@@ -1916,65 +1589,39 @@ find_tworeg_group (global, class, dumpfile)\n \t  && ((j > 0 && (other = j - 1, spill_reg_order[other] >= 0)\n \t       && TEST_HARD_REG_BIT (reg_class_contents[class], j)\n \t       && TEST_HARD_REG_BIT (reg_class_contents[class], other)\n-\t       && HARD_REGNO_MODE_OK (other, group_mode[class])\n-\t       && ! TEST_HARD_REG_BIT (counted_for_nongroups, other)\n+\t       && HARD_REGNO_MODE_OK (other, chain->group_mode[class])\n+\t       && ! TEST_HARD_REG_BIT (chain->counted_for_nongroups, other)\n \t       /* We don't want one part of another group.\n \t\t  We could get \"two groups\" that overlap!  */\n-\t       && ! TEST_HARD_REG_BIT (counted_for_groups, other))\n+\t       && ! TEST_HARD_REG_BIT (chain->counted_for_groups, other))\n \t      || (j < FIRST_PSEUDO_REGISTER - 1\n \t\t  && (other = j + 1, spill_reg_order[other] >= 0)\n \t\t  && TEST_HARD_REG_BIT (reg_class_contents[class], j)\n \t\t  && TEST_HARD_REG_BIT (reg_class_contents[class], other)\n-\t\t  && HARD_REGNO_MODE_OK (j, group_mode[class])\n-\t\t  && ! TEST_HARD_REG_BIT (counted_for_nongroups, other)\n-\t\t  && ! TEST_HARD_REG_BIT (counted_for_groups, other))))\n+\t\t  && HARD_REGNO_MODE_OK (j, chain->group_mode[class])\n+\t\t  && ! TEST_HARD_REG_BIT (chain->counted_for_nongroups, other)\n+\t\t  && ! TEST_HARD_REG_BIT (chain->counted_for_groups, other))))\n \t{\n \t  register enum reg_class *p;\n \n \t  /* We have found one that will complete a group,\n \t     so count off one group as provided.  */\n-\t  max_groups[class]--;\n+\t  chain->need.groups[class]--;\n \t  p = reg_class_superclasses[class];\n \t  while (*p != LIM_REG_CLASSES)\n \t    {\n-\t      if (group_size [(int) *p] <= group_size [class])\n-\t\tmax_groups[(int) *p]--;\n+\t      if (chain->group_size [(int) *p] <= chain->group_size [class])\n+\t\tchain->need.groups[(int) *p]--;\n \t      p++;\n \t    }\n \n \t  /* Indicate both these regs are part of a group.  */\n-\t  SET_HARD_REG_BIT (counted_for_groups, j);\n-\t  SET_HARD_REG_BIT (counted_for_groups, other);\n+\t  SET_HARD_REG_BIT (chain->counted_for_groups, j);\n+\t  SET_HARD_REG_BIT (chain->counted_for_groups, other);\n \t  break;\n \t}\n     }\n   /* We can't complete a group, so start one.  */\n-  /* Look for a pair neither of which is explicitly used.  */\n-  if (SMALL_REGISTER_CLASSES && i == FIRST_PSEUDO_REGISTER)\n-    for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n-      {\n-\tint j, k;\n-\tj = potential_reload_regs[i];\n-\t/* Verify that J+1 is a potential reload reg.  */\n-\tfor (k = 0; k < FIRST_PSEUDO_REGISTER; k++)\n-\t  if (potential_reload_regs[k] == j + 1)\n-\t    break;\n-\tif (j >= 0 && j + 1 < FIRST_PSEUDO_REGISTER\n-\t    && k < FIRST_PSEUDO_REGISTER\n-\t    && spill_reg_order[j] < 0 && spill_reg_order[j + 1] < 0\n-\t    && TEST_HARD_REG_BIT (reg_class_contents[class], j)\n-\t    && TEST_HARD_REG_BIT (reg_class_contents[class], j + 1)\n-\t    && HARD_REGNO_MODE_OK (j, group_mode[class])\n-\t    && ! TEST_HARD_REG_BIT (counted_for_nongroups,\n-\t\t\t\t    j + 1)\n-\t    && ! TEST_HARD_REG_BIT (bad_spill_regs, j + 1)\n-\t    /* Reject J at this stage\n-\t       if J+1 was explicitly used.  */\n-\t    && ! regs_explicitly_used[j + 1])\n-\t  break;\n-      }\n-  /* Now try any group at all\n-     whose registers are not in bad_spill_regs.  */\n   if (i == FIRST_PSEUDO_REGISTER)\n     for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n       {\n@@ -1989,90 +1636,102 @@ find_tworeg_group (global, class, dumpfile)\n \t    && spill_reg_order[j] < 0 && spill_reg_order[j + 1] < 0\n \t    && TEST_HARD_REG_BIT (reg_class_contents[class], j)\n \t    && TEST_HARD_REG_BIT (reg_class_contents[class], j + 1)\n-\t    && HARD_REGNO_MODE_OK (j, group_mode[class])\n-\t    && ! TEST_HARD_REG_BIT (counted_for_nongroups, j + 1)\n+\t    && HARD_REGNO_MODE_OK (j, chain->group_mode[class])\n+\t    && ! TEST_HARD_REG_BIT (chain->counted_for_nongroups, j + 1)\n \t    && ! TEST_HARD_REG_BIT (bad_spill_regs, j + 1))\n \t  break;\n       }\n \n   /* I should be the index in potential_reload_regs\n      of the new reload reg we have found.  */\n \n-  if (i < FIRST_PSEUDO_REGISTER)\n-    return new_spill_reg (i, class, max_needs, NULL_PTR,\n-\t\t\t  global, dumpfile);\n-\n-  /* There are no groups left to spill.  */\n-  spill_failure (max_groups_insn[class]);\n-  failure = 1;\n-  return 1;\n+  new_spill_reg (chain, i, class, 0, dumpfile);\n }\n \n /* Find a group of more than 2 registers.\n    Look for a sufficient sequence of unspilled registers, and spill them all\n    at once.  */\n-static int\n-find_group (global, class, dumpfile)\n-     int global;\n+\n+static void\n+find_group (chain, class, dumpfile)\n+     struct insn_chain *chain;\n      int class;\n      FILE *dumpfile;\n {\n-  int something_changed = 0;\n   int i;\n \n   for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n     {\n-      int j, k;\n+      int j = potential_reload_regs[i];\n \n-      j = potential_reload_regs[i];\n       if (j >= 0\n-\t  && j + group_size[class] <= FIRST_PSEUDO_REGISTER\n-\t  && HARD_REGNO_MODE_OK (j, group_mode[class]))\n+\t  && j + chain->group_size[class] <= FIRST_PSEUDO_REGISTER\n+\t  && HARD_REGNO_MODE_OK (j, chain->group_mode[class]))\n \t{\n+\t  int k;\n \t  /* Check each reg in the sequence.  */\n-\t  for (k = 0; k < group_size[class]; k++)\n+\t  for (k = 0; k < chain->group_size[class]; k++)\n \t    if (! (spill_reg_order[j + k] < 0\n \t\t   && ! TEST_HARD_REG_BIT (bad_spill_regs, j + k)\n \t\t   && TEST_HARD_REG_BIT (reg_class_contents[class], j + k)))\n \t      break;\n \t  /* We got a full sequence, so spill them all.  */\n-\t  if (k == group_size[class])\n+\t  if (k == chain->group_size[class])\n \t    {\n \t      register enum reg_class *p;\n-\t      for (k = 0; k < group_size[class]; k++)\n+\t      for (k = 0; k < chain->group_size[class]; k++)\n \t\t{\n \t\t  int idx;\n-\t\t  SET_HARD_REG_BIT (counted_for_groups, j + k);\n+\t\t  SET_HARD_REG_BIT (chain->counted_for_groups, j + k);\n \t\t  for (idx = 0; idx < FIRST_PSEUDO_REGISTER; idx++)\n \t\t    if (potential_reload_regs[idx] == j + k)\n \t\t      break;\n-\t\t  something_changed |= new_spill_reg (idx, class, max_needs,\n-\t\t\t\t\t\t      NULL_PTR, global,\n-\t\t\t\t\t\t      dumpfile);\n+\t\t  new_spill_reg (chain, idx, class, 0, dumpfile);\n \t\t}\n \n \t      /* We have found one that will complete a group,\n \t\t so count off one group as provided.  */\n-\t      max_groups[class]--;\n+\t      chain->need.groups[class]--;\n \t      p = reg_class_superclasses[class];\n \t      while (*p != LIM_REG_CLASSES)\n \t\t{\n-\t\t  if (group_size [(int) *p]\n-\t\t      <= group_size [class])\n-\t\t    max_groups[(int) *p]--;\n+\t\t  if (chain->group_size [(int) *p]\n+\t\t      <= chain->group_size [class])\n+\t\t    chain->need.groups[(int) *p]--;\n \t\t  p++;\n \t\t}\n-\t      return something_changed;\n+\t      return;\n \t    }\n \t}\n     }\n   /* There are no groups left.  */\n-  spill_failure (max_groups_insn[class]);\n+  spill_failure (chain->insn);\n   failure = 1;\n-  return 1;\n }\n \n-/* Find more reload regs to satisfy the remaining need.\n+/* If pseudo REG conflicts with one of our reload registers, mark it as\n+   spilled.  */\n+static void\n+maybe_mark_pseudo_spilled (reg)\n+     int reg;\n+{\n+  int i;\n+  int r = reg_renumber[reg];\n+  int nregs;\n+\n+  if (r < 0)\n+    abort ();\n+  nregs = HARD_REGNO_NREGS (r, PSEUDO_REGNO_MODE (reg));\n+  for (i = 0; i < n_spills; i++)\n+    if (r <= spill_regs[i] && r + nregs > spill_regs[i])\n+      {\n+\tSET_REGNO_REG_SET (spilled_pseudos, reg);\n+\treturn;\n+      }\n+}\n+\n+/* Find more reload regs to satisfy the remaining need of an insn, which\n+   is given by CHAIN.\n    Do it by ascending class number, since otherwise a reg\n    might be spilled for a big class and might fail to count\n    for a smaller class even though it belongs to that class.\n@@ -2094,70 +1753,85 @@ find_group (global, class, dumpfile)\n    in counting the regs already spilled, and in choose_reload_regs.\n    It might be hard to avoid introducing bugs there.  */\n \n-static int\n-find_reload_regs (global, dumpfile)\n-     int global;\n+static void\n+find_reload_regs (chain, dumpfile)\n+     struct insn_chain *chain;\n      FILE *dumpfile;\n {\n-  int class;\n-  int something_changed = 0;\n+  int i, class;\n+  short *group_needs = chain->need.groups;\n+  short *simple_needs = chain->need.regs[0];\n+  short *nongroup_needs = chain->need.regs[1];\n+\n+  if (dumpfile)\n+    fprintf (dumpfile, \"Spilling for insn %d.\\n\", INSN_UID (chain->insn));\n+\n+  /* Compute the order of preference for hard registers to spill.\n+     Store them by decreasing preference in potential_reload_regs.  */\n+\n+  order_regs_for_reload (chain);\n+\n+  /* So far, no hard regs have been spilled.  */\n+  n_spills = 0;\n+  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n+    spill_reg_order[i] = -1;\n \n-  CLEAR_HARD_REG_SET (counted_for_groups);\n-  CLEAR_HARD_REG_SET (counted_for_nongroups);\n+  CLEAR_HARD_REG_SET (chain->used_spill_regs);\n+  CLEAR_HARD_REG_SET (chain->counted_for_groups);\n+  CLEAR_HARD_REG_SET (chain->counted_for_nongroups);\n \n   for (class = 0; class < N_REG_CLASSES; class++)\n     {\n       /* First get the groups of registers.\n \t If we got single registers first, we might fragment\n \t possible groups.  */\n-      while (max_groups[class] > 0)\n+      while (group_needs[class] > 0)\n \t{\n \t  /* If any single spilled regs happen to form groups,\n \t     count them now.  Maybe we don't really need\n \t     to spill another group.  */\n-\t  count_possible_groups (group_size, group_mode, max_groups, class);\n+\t  count_possible_groups (chain, class);\n \n-\t  if (max_groups[class] <= 0)\n+\t  if (group_needs[class] <= 0)\n \t    break;\n \n-\t  /* Groups of size 2 (the only groups used on most machines)\n+\t  /* Groups of size 2, the only groups used on most machines,\n \t     are treated specially.  */\n-\t  if (group_size[class] == 2)\n-\t    something_changed |= find_tworeg_group (global, class, dumpfile);\n+\t  if (chain->group_size[class] == 2)\n+\t    find_tworeg_group (chain, class, dumpfile);\n \t  else\n-\t    something_changed |= find_group (global, class, dumpfile);\n-\n+\t    find_group (chain, class, dumpfile);\n \t  if (failure)\n-\t    return 1;\n+\t    return;\n \t}\n \n       /* Now similarly satisfy all need for single registers.  */\n \n-      while (max_needs[class] > 0 || max_nongroups[class] > 0)\n+      while (simple_needs[class] > 0 || nongroup_needs[class] > 0)\n \t{\n-\t  int i;\n \t  /* If we spilled enough regs, but they weren't counted\n \t     against the non-group need, see if we can count them now.\n \t     If so, we can avoid some actual spilling.  */\n-\t  if (max_needs[class] <= 0 && max_nongroups[class] > 0)\n+\t  if (simple_needs[class] <= 0 && nongroup_needs[class] > 0)\n \t    for (i = 0; i < n_spills; i++)\n \t      {\n \t\tint regno = spill_regs[i];\n \t\tif (TEST_HARD_REG_BIT (reg_class_contents[class], regno)\n-\t\t    && !TEST_HARD_REG_BIT (counted_for_groups, regno)\n-\t\t    && !TEST_HARD_REG_BIT (counted_for_nongroups, regno)\n-\t\t    && max_nongroups[class] > 0)\n-\t\t{\n-\t\t  register enum reg_class *p;\n+\t\t    && !TEST_HARD_REG_BIT (chain->counted_for_groups, regno)\n+\t\t    && !TEST_HARD_REG_BIT (chain->counted_for_nongroups, regno)\n+\t\t    && nongroup_needs[class] > 0)\n+\t\t  {\n+\t\t    register enum reg_class *p;\n \n-\t\t  SET_HARD_REG_BIT (counted_for_nongroups, regno);\n-\t\t  max_nongroups[class]--;\n-\t\t  p = reg_class_superclasses[class];\n-\t\t  while (*p != LIM_REG_CLASSES)\n-\t\t    max_nongroups[(int) *p++]--;\n-\t\t}\n+\t\t    SET_HARD_REG_BIT (chain->counted_for_nongroups, regno);\n+\t\t    nongroup_needs[class]--;\n+\t\t    p = reg_class_superclasses[class];\n+\t\t    while (*p != LIM_REG_CLASSES)\n+\t\t      nongroup_needs[(int) *p++]--;\n+\t\t  }\n \t      }\n-\t  if (max_needs[class] <= 0 && max_nongroups[class] <= 0)\n+\n+\t  if (simple_needs[class] <= 0 && nongroup_needs[class] <= 0)\n \t    break;\n \n \t  /* Consider the potential reload regs that aren't\n@@ -2175,8 +1849,8 @@ find_reload_regs (global, dumpfile)\n \t\t     but it should be sufficient to make the 386 work,\n \t\t     and the problem should not occur on machines with\n \t\t     more registers.  */\n-\t\t  && (max_nongroups[class] == 0\n-\t\t      || possible_group_p (regno, max_groups)))\n+\t\t  && (nongroup_needs[class] == 0\n+\t\t      || possible_group_p (chain, regno)))\n \t\tbreak;\n \t    }\n \n@@ -2187,10 +1861,7 @@ find_reload_regs (global, dumpfile)\n \t     group even with this allocation.  */\n \n \t  if (i >= FIRST_PSEUDO_REGISTER\n-\t      && (asm_noperands (max_needs[class] > 0\n-\t\t\t\t ? max_needs_insn[class]\n-\t\t\t\t : max_nongroups_insn[class])\n-\t\t  < 0))\n+\t      && asm_noperands (chain->insn) < 0)\n \t    for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n \t      if (potential_reload_regs[i] >= 0\n \t\t  && TEST_HARD_REG_BIT (reg_class_contents[class],\n@@ -2200,48 +1871,55 @@ find_reload_regs (global, dumpfile)\n \t  /* I should be the index in potential_reload_regs\n \t     of the new reload reg we have found.  */\n \n-\t  if (i >= FIRST_PSEUDO_REGISTER)\n-\t    {\n-\t      /* There are no possible registers left to spill.  */\n-\t      spill_failure (max_needs[class] > 0 ? max_needs_insn[class]\n-\t\t\t     : max_nongroups_insn[class]);\n-\t      failure = 1;\n-\t      return 1;\n-\t    }\n-\t  else\n-\t    something_changed |= new_spill_reg (i, class, max_needs,\n-\t\t\t\t\t\tmax_nongroups, global,\n-\t\t\t\t\t\tdumpfile);\n+\t  new_spill_reg (chain, i, class, 1, dumpfile);\n+\t  if (failure)\n+\t    return;\n \t}\n     }\n-  return something_changed;\n+  \n+  /* We know which hard regs to use, now mark the pseudos that live in them\n+     as needing to be kicked out.  */\n+  EXECUTE_IF_SET_IN_REG_SET\n+    (chain->live_before, FIRST_PSEUDO_REGISTER, i,\n+     {\n+       maybe_mark_pseudo_spilled (i);\n+     });\n+  EXECUTE_IF_SET_IN_REG_SET\n+    (chain->live_after, FIRST_PSEUDO_REGISTER, i,\n+     {\n+       maybe_mark_pseudo_spilled (i);\n+     });\n+\n+  IOR_HARD_REG_SET (used_spill_regs, chain->used_spill_regs);\n }\n \n-static void\n-dump_needs (dumpfile)\n+void\n+dump_needs (chain, dumpfile)\n+     struct insn_chain *chain;\n      FILE *dumpfile;\n {\n   static char *reg_class_names[] = REG_CLASS_NAMES;\n   int i;\n+  struct needs *n = &chain->need;\n \n   for (i = 0; i < N_REG_CLASSES; i++)\n     {\n-      if (max_needs[i] > 0)\n+      if (n->regs[i][0] > 0)\n \tfprintf (dumpfile,\n-\t\t \";; Need %d reg%s of class %s (for insn %d).\\n\",\n-\t\t max_needs[i], max_needs[i] == 1 ? \"\" : \"s\",\n-\t\t reg_class_names[i], INSN_UID (max_needs_insn[i]));\n-      if (max_nongroups[i] > 0)\n+\t\t \";; Need %d reg%s of class %s.\\n\",\n+\t\t n->regs[i][0], n->regs[i][0] == 1 ? \"\" : \"s\",\n+\t\t reg_class_names[i]);\n+      if (n->regs[i][1] > 0)\n \tfprintf (dumpfile,\n-\t\t \";; Need %d nongroup reg%s of class %s (for insn %d).\\n\",\n-\t\t max_nongroups[i], max_nongroups[i] == 1 ? \"\" : \"s\",\n-\t\t reg_class_names[i], INSN_UID (max_nongroups_insn[i]));\n-      if (max_groups[i] > 0)\n+\t\t \";; Need %d nongroup reg%s of class %s.\\n\",\n+\t\t n->regs[i][1], n->regs[i][1] == 1 ? \"\" : \"s\",\n+\t\t reg_class_names[i]);\n+      if (n->groups[i] > 0)\n \tfprintf (dumpfile,\n-\t\t \";; Need %d group%s (%smode) of class %s (for insn %d).\\n\",\n-\t\t max_groups[i], max_groups[i] == 1 ? \"\" : \"s\",\n-\t\t mode_name[(int) group_mode[i]],\n-\t\t reg_class_names[i], INSN_UID (max_groups_insn[i]));\n+\t\t \";; Need %d group%s (%smode) of class %s.\\n\",\n+\t\t n->groups[i], n->groups[i] == 1 ? \"\" : \"s\",\n+\t\t mode_name[(int) chain->group_mode[i]],\n+\t\t reg_class_names[i]);\n     }\n }\n \f\n@@ -2288,15 +1966,15 @@ delete_caller_save_insns ()\n    it will still be possible to find a group if we still need one.  */\n \n static int\n-possible_group_p (regno, max_groups)\n+possible_group_p (chain, regno)\n+     struct insn_chain *chain;\n      int regno;\n-     int *max_groups;\n {\n   int i;\n   int class = (int) NO_REGS;\n \n   for (i = 0; i < (int) N_REG_CLASSES; i++)\n-    if (max_groups[i] > 0)\n+    if (chain->need.groups[i] > 0)\n       {\n \tclass = i;\n \tbreak;\n@@ -2331,28 +2009,26 @@ possible_group_p (regno, max_groups)\n       if (spill_reg_order[i] < 0\n \t  && ! TEST_HARD_REG_BIT (bad_spill_regs, i)\n \t  && spill_reg_order[i + 1] >= 0\n-\t  && ! TEST_HARD_REG_BIT (counted_for_groups, i + 1)\n-\t  && ! TEST_HARD_REG_BIT (counted_for_nongroups, i + 1))\n+\t  && ! TEST_HARD_REG_BIT (chain->counted_for_groups, i + 1)\n+\t  && ! TEST_HARD_REG_BIT (chain->counted_for_nongroups, i + 1))\n \treturn 1;\n       if (spill_reg_order[i + 1] < 0\n \t  && ! TEST_HARD_REG_BIT (bad_spill_regs, i + 1)\n \t  && spill_reg_order[i] >= 0\n-\t  && ! TEST_HARD_REG_BIT (counted_for_groups, i)\n-\t  && ! TEST_HARD_REG_BIT (counted_for_nongroups, i))\n+\t  && ! TEST_HARD_REG_BIT (chain->counted_for_groups, i)\n+\t  && ! TEST_HARD_REG_BIT (chain->counted_for_nongroups, i))\n \treturn 1;\n     }\n \n   return 0;\n }\n-\f\n+\n /* Count any groups of CLASS that can be formed from the registers recently\n    spilled.  */\n \n static void\n-count_possible_groups (group_size, group_mode, max_groups, class)\n-     int *group_size;\n-     enum machine_mode *group_mode;\n-     int *max_groups;\n+count_possible_groups (chain, class)\n+     struct insn_chain *chain;\n      int class;\n {\n   HARD_REG_SET new;\n@@ -2362,46 +2038,50 @@ count_possible_groups (group_size, group_mode, max_groups, class)\n      and mark each group off against the need for such groups.\n      But don't count them against ordinary need, yet.  */\n \n-  if (group_size[class] == 0)\n+  if (chain->group_size[class] == 0)\n     return;\n \n   CLEAR_HARD_REG_SET (new);\n \n   /* Make a mask of all the regs that are spill regs in class I.  */\n   for (i = 0; i < n_spills; i++)\n-    if (TEST_HARD_REG_BIT (reg_class_contents[class], spill_regs[i])\n-\t&& ! TEST_HARD_REG_BIT (counted_for_groups, spill_regs[i])\n-\t&& ! TEST_HARD_REG_BIT (counted_for_nongroups, spill_regs[i]))\n-      SET_HARD_REG_BIT (new, spill_regs[i]);\n+    {\n+      int regno = spill_regs[i];\n+\n+      if (TEST_HARD_REG_BIT (reg_class_contents[class], regno)\n+\t  && ! TEST_HARD_REG_BIT (chain->counted_for_groups, regno)\n+\t  && ! TEST_HARD_REG_BIT (chain->counted_for_nongroups, regno))\n+\tSET_HARD_REG_BIT (new, regno);\n+    }\n \n   /* Find each consecutive group of them.  */\n-  for (i = 0; i < FIRST_PSEUDO_REGISTER && max_groups[class] > 0; i++)\n+  for (i = 0; i < FIRST_PSEUDO_REGISTER && chain->need.groups[class] > 0; i++)\n     if (TEST_HARD_REG_BIT (new, i)\n-\t&& i + group_size[class] <= FIRST_PSEUDO_REGISTER\n-\t&& HARD_REGNO_MODE_OK (i, group_mode[class]))\n+\t&& i + chain->group_size[class] <= FIRST_PSEUDO_REGISTER\n+\t&& HARD_REGNO_MODE_OK (i, chain->group_mode[class]))\n       {\n-\tfor (j = 1; j < group_size[class]; j++)\n+\tfor (j = 1; j < chain->group_size[class]; j++)\n \t  if (! TEST_HARD_REG_BIT (new, i + j))\n \t    break;\n \n-\tif (j == group_size[class])\n+\tif (j == chain->group_size[class])\n \t  {\n \t    /* We found a group.  Mark it off against this class's need for\n \t       groups, and against each superclass too.  */\n \t    register enum reg_class *p;\n \n-\t    max_groups[class]--;\n+\t    chain->need.groups[class]--;\n \t    p = reg_class_superclasses[class];\n \t    while (*p != LIM_REG_CLASSES)\n \t      {\n-\t\tif (group_size [(int) *p] <= group_size [class])\n-\t\t  max_groups[(int) *p]--;\n+\t\tif (chain->group_size [(int) *p] <= chain->group_size [class])\n+\t\t  chain->need.groups[(int) *p]--;\n \t\tp++;\n \t      }\n \n \t    /* Don't count these registers again.  */\n-\t    for (j = 0; j < group_size[class]; j++)\n-\t      SET_HARD_REG_BIT (counted_for_groups, i + j);\n+\t    for (j = 0; j < chain->group_size[class]; j++)\n+\t      SET_HARD_REG_BIT (chain->counted_for_groups, i + j);\n \t  }\n \n \t/* Skip to the last reg in this group.  When i is incremented above,\n@@ -2437,7 +2117,7 @@ modes_equiv_for_class_p (allocate_mode, other_mode, class)\n     }\n   return 1;\n }\n-\n+\f\n /* Handle the failure to find a register to spill.\n    INSN should be one of the insns which needed this particular spill reg.  */\n \n@@ -2451,37 +2131,53 @@ spill_failure (insn)\n     fatal_insn (\"Unable to find a register to spill.\", insn);\n }\n \n-/* Add a new register to the tables of available spill-registers\n-    (as well as spilling all pseudos allocated to the register).\n+/* Add a new register to the tables of available spill-registers.\n+   CHAIN is the insn for which the register will be used; we decrease the\n+   needs of that insn.\n    I is the index of this register in potential_reload_regs.\n    CLASS is the regclass whose need is being satisfied.\n-   MAX_NEEDS and MAX_NONGROUPS are the vectors of needs,\n-    so that this register can count off against them.\n-    MAX_NONGROUPS is 0 if this register is part of a group.\n-   GLOBAL and DUMPFILE are the same as the args that `reload' got.  */\n+   NONGROUP is 0 if this register is part of a group.\n+   DUMPFILE is the same as the one that `reload' got.  */\n \n-static int\n-new_spill_reg (i, class, max_needs, max_nongroups, global, dumpfile)\n+static void\n+new_spill_reg (chain, i, class, nongroup, dumpfile)\n+     struct insn_chain *chain;\n      int i;\n      int class;\n-     int *max_needs;\n-     int *max_nongroups;\n-     int global;\n+     int nongroup;\n      FILE *dumpfile;\n {\n   register enum reg_class *p;\n-  int val;\n   int regno = potential_reload_regs[i];\n \n   if (i >= FIRST_PSEUDO_REGISTER)\n-    abort ();\t/* Caller failed to find any register.  */\n+    {\n+      spill_failure (chain->insn);\n+      failure = 1;\n+      return;\n+    }\n \n-  if (fixed_regs[regno] || TEST_HARD_REG_BIT (forbidden_regs, regno))\n+  if (TEST_HARD_REG_BIT (bad_spill_regs, regno))\n     {\n       static char *reg_class_names[] = REG_CLASS_NAMES;\n-      fatal (\"fixed or forbidden register %d (%s) was spilled for class %s.\\n\\\n-This may be due to a compiler bug or to impossible asm\\n\\\n-statements or clauses.\", regno, reg_names[regno], reg_class_names[class]);\n+\n+      if (asm_noperands (PATTERN (chain->insn)) < 0)\n+\t{\n+\t/* The error message is still correct - we know only that it wasn't\n+\t   an asm statement that caused the problem, but one of the global\n+\t   registers declared by the users might have screwed us.  */\n+\t  error (\"fixed or forbidden register %d (%s) was spilled for class %s.\",\n+\t\t regno, reg_names[regno], reg_class_names[class]);\n+\t  error (\"This may be due to a compiler bug or to impossible asm\");\n+\t  error (\"statements or clauses.\");\n+\t  fatal_insn (\"This is the instruction:\", chain->insn);\n+\t}\n+      error_for_asm (chain->insn, \"Invalid `asm' statement:\");\n+      error_for_asm (chain->insn,\n+\t\t     \"fixed or forbidden register %d (%s) was spilled for class %s.\",\n+\t\t     regno, reg_names[regno], reg_class_names[class]);\n+      failure = 1;\n+      return;\n     }\n \n   /* Make reg REGNO an additional reload reg.  */\n@@ -2490,49 +2186,26 @@ statements or clauses.\", regno, reg_names[regno], reg_class_names[class]);\n   spill_regs[n_spills] = regno;\n   spill_reg_order[regno] = n_spills;\n   if (dumpfile)\n-    fprintf (dumpfile, \"Spilling reg %d.\\n\", spill_regs[n_spills]);\n+    fprintf (dumpfile, \"Spilling reg %d.\\n\", regno);\n+  SET_HARD_REG_BIT (chain->used_spill_regs, regno);\n \n   /* Clear off the needs we just satisfied.  */\n \n-  max_needs[class]--;\n+  chain->need.regs[0][class]--;\n   p = reg_class_superclasses[class];\n   while (*p != LIM_REG_CLASSES)\n-    max_needs[(int) *p++]--;\n+    chain->need.regs[0][(int) *p++]--;\n \n-  if (max_nongroups && max_nongroups[class] > 0)\n+  if (nongroup && chain->need.regs[1][class] > 0)\n     {\n-      SET_HARD_REG_BIT (counted_for_nongroups, regno);\n-      max_nongroups[class]--;\n+      SET_HARD_REG_BIT (chain->counted_for_nongroups, regno);\n+      chain->need.regs[1][class]--;\n       p = reg_class_superclasses[class];\n       while (*p != LIM_REG_CLASSES)\n-\tmax_nongroups[(int) *p++]--;\n+\tchain->need.regs[1][(int) *p++]--;\n     }\n \n-  /* Spill every pseudo reg that was allocated to this reg\n-     or to something that overlaps this reg.  */\n-\n-  val = spill_hard_reg (spill_regs[n_spills], global, dumpfile, 0);\n-\n-  /* If there are some registers still to eliminate and this register\n-     wasn't ever used before, additional stack space may have to be\n-     allocated to store this register.  Thus, we may have changed the offset\n-     between the stack and frame pointers, so mark that something has changed.\n-     (If new pseudos were spilled, thus requiring more space, VAL would have\n-     been set non-zero by the call to spill_hard_reg above since additional\n-     reloads may be needed in that case.\n-\n-     One might think that we need only set VAL to 1 if this is a call-used\n-     register.  However, the set of registers that must be saved by the\n-     prologue is not identical to the call-used set.  For example, the\n-     register used by the call insn for the return PC is a call-used register,\n-     but must be saved by the prologue.  */\n-  if (num_eliminable && ! regs_ever_live[spill_regs[n_spills]])\n-    val = 1;\n-\n-  regs_ever_live[spill_regs[n_spills]] = 1;\n   n_spills++;\n-\n-  return val;\n }\n \f\n /* Delete an unneeded INSN and any previous insns who sole purpose is loading\n@@ -3918,7 +3591,6 @@ init_elim_table ()\n }\n \f\n /* Kick all pseudos out of hard register REGNO.\n-   If GLOBAL is nonzero, try to find someplace else to put them.\n    If DUMPFILE is nonzero, log actions taken on that file.\n \n    If CANT_ELIMINATE is nonzero, it means that we are doing this spill\n@@ -3929,21 +3601,19 @@ init_elim_table ()\n \n    Return nonzero if any pseudos needed to be kicked out.  */\n \n-static int\n-spill_hard_reg (regno, global, dumpfile, cant_eliminate)\n+static void\n+spill_hard_reg (regno, dumpfile, cant_eliminate)\n      register int regno;\n-     int global;\n      FILE *dumpfile;\n      int cant_eliminate;\n {\n-  enum reg_class class = REGNO_REG_CLASS (regno);\n-  int something_changed = 0;\n   register int i;\n \n-  SET_HARD_REG_BIT (forbidden_regs, regno);\n-\n   if (cant_eliminate)\n-    regs_ever_live[regno] = 1;\n+    {\n+      SET_HARD_REG_BIT (bad_spill_regs_global, regno);\n+      regs_ever_live[regno] = 1;\n+    }\n \n   /* Spill every pseudo reg that was allocated to this reg\n      or to something that overlaps this reg.  */\n@@ -3955,67 +3625,167 @@ spill_hard_reg (regno, global, dumpfile, cant_eliminate)\n \t    + HARD_REGNO_NREGS (reg_renumber[i],\n \t\t\t\tPSEUDO_REGNO_MODE (i))\n \t    > regno))\n-      {\n-\t/* If this register belongs solely to a basic block which needed no\n-\t   spilling of any class that this register is contained in,\n-\t   leave it be, unless we are spilling this register because\n-\t   it was a hard register that can't be eliminated.   */\n-\n-\tif (! cant_eliminate\n-\t    && basic_block_needs[0]\n-\t    && REG_BASIC_BLOCK (i) >= 0\n-\t    && basic_block_needs[(int) class][REG_BASIC_BLOCK (i)] == 0)\n-\t  {\n-\t    enum reg_class *p;\n+      SET_REGNO_REG_SET (spilled_pseudos, i);\n+}\n \n-\t    for (p = reg_class_superclasses[(int) class];\n-\t\t *p != LIM_REG_CLASSES; p++)\n-\t      if (basic_block_needs[(int) *p][REG_BASIC_BLOCK (i)] > 0)\n-\t\tbreak;\n+/* I'm getting weird preprocessor errors if I use IOR_HARD_REG_SET\n+   from within EXECUTE_IF_SET_IN_REG_SET.  Hence this awkwardness.  */\n+static void\n+ior_hard_reg_set (set1, set2)\n+     HARD_REG_SET *set1, *set2;\n+{\n+  IOR_HARD_REG_SET (*set1, *set2);\n+}\n+  \n+/* After find_reload_regs has been run for all insn that need reloads,\n+   and/or spill_hard_regs was called, this function is used to actually\n+   spill pseudo registers and try to reallocate them.  It also sets up the\n+   spill_regs array for use by choose_reload_regs.  */\n \n-\t    if (*p == LIM_REG_CLASSES)\n-\t      continue;\n-\t  }\n+static int\n+finish_spills (global, dumpfile)\n+     int global;\n+     FILE *dumpfile;\n+{\n+  struct insn_chain *chain;\n+  int something_changed = 0;\n+  int i;\n+\n+  /* Build the spill_regs array for the function.  */\n+  /* If there are some registers still to eliminate and one of the spill regs\n+     wasn't ever used before, additional stack space may have to be\n+     allocated to store this register.  Thus, we may have changed the offset\n+     between the stack and frame pointers, so mark that something has changed.\n \n+     One might think that we need only set VAL to 1 if this is a call-used\n+     register.  However, the set of registers that must be saved by the\n+     prologue is not identical to the call-used set.  For example, the\n+     register used by the call insn for the return PC is a call-used register,\n+     but must be saved by the prologue.  */\n+\n+  n_spills = 0;\n+  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n+    if (TEST_HARD_REG_BIT (used_spill_regs, i))\n+      {\n+\tspill_reg_order[i] = n_spills;\n+\tspill_regs[n_spills++] = i;\n+\tif (num_eliminable && ! regs_ever_live[i])\n+\t  something_changed = 1;\n+\tregs_ever_live[i] = 1;\n+      }\n+    else\n+      spill_reg_order[i] = -1;\n+\n+  for (i = FIRST_PSEUDO_REGISTER; i < max_regno; i++)\n+    if (REGNO_REG_SET_P (spilled_pseudos, i))\n+      {\n+\t/* Record the current hard register the pseudo is allocated to in\n+\t   pseudo_previous_regs so we avoid reallocating it to the same\n+\t   hard reg in a later pass.  */\n+\tif (reg_renumber[i] < 0)\n+\t  abort ();\n+\tSET_HARD_REG_BIT (pseudo_previous_regs[i], reg_renumber[i]);\n \t/* Mark it as no longer having a hard register home.  */\n \treg_renumber[i] = -1;\n \t/* We will need to scan everything again.  */\n \tsomething_changed = 1;\n-\tif (global)\n-\t  retry_global_alloc (i, forbidden_regs);\n-\n-\talter_reg (i, regno);\n+      }\n \n-\tif (reg_renumber[i] == -1)\n-\t  SET_REGNO_REG_SET (spilled_pseudos, i);\n+  /* Retry global register allocation if possible.  */\n+  if (global)\n+    {\n+      bzero ((char *) pseudo_forbidden_regs, max_regno * sizeof (HARD_REG_SET));\n+      /* For every insn that needs reloads, set the registers used as spill\n+\t regs in pseudo_forbidden_regs for every pseudo live across the\n+\t insn.  */\n+      for (chain = insns_need_reload; chain; chain = chain->next_need_reload)\n+\t{\n+\t  EXECUTE_IF_SET_IN_REG_SET\n+\t    (chain->live_before, FIRST_PSEUDO_REGISTER, i,\n+\t     {\n+\t       ior_hard_reg_set (pseudo_forbidden_regs + i,\n+\t\t\t\t &chain->used_spill_regs);\n+\t     });\n+\t  EXECUTE_IF_SET_IN_REG_SET\n+\t    (chain->live_after, FIRST_PSEUDO_REGISTER, i,\n+\t     {\n+\t       ior_hard_reg_set (pseudo_forbidden_regs + i,\n+\t\t\t\t &chain->used_spill_regs);\n+\t     });\n+\t}\n \n-\tif (dumpfile)\n+      /* Retry allocating the spilled pseudos.  For each reg, merge the\n+\t various reg sets that indicate which hard regs can't be used,\n+\t and call retry_global_alloc.\n+         We change spill_pseudos here to only contain pseudos that did not\n+\t get a new hard register.  */\n+      for (i = FIRST_PSEUDO_REGISTER; i < max_regno; i++)\n+\tif (reg_old_renumber[i] != reg_renumber[i])\n \t  {\n-\t    if (reg_renumber[i] == -1)\n-\t      fprintf (dumpfile, \" Register %d now on stack.\\n\\n\", i);\n-\t    else\n-\t      fprintf (dumpfile, \" Register %d now in %d.\\n\\n\",\n-\t\t       i, reg_renumber[i]);\n+\t    HARD_REG_SET forbidden;\n+\t    COPY_HARD_REG_SET (forbidden, bad_spill_regs_global);\n+\t    IOR_HARD_REG_SET (forbidden, pseudo_forbidden_regs[i]);\n+\t    IOR_HARD_REG_SET (forbidden, pseudo_previous_regs[i]);\n+\t    retry_global_alloc (i, forbidden);\n+\t    if (reg_renumber[i] >= 0)\n+\t      CLEAR_REGNO_REG_SET (spilled_pseudos, i);\n \t  }\n-      }\n-\n-  return something_changed;\n-}\n-\n-/* Clear the contents of spilled_pseudos from the life information in all\n-   insn chains.  */\n-static void\n-finish_spills (global, dumpfile)\n-     int global;\n-     FILE *dumpfile;\n-{\n-  struct insn_chain *chain;\n+    }\n \n+  /* Fix up the register information in the insn chain.\n+     This involves deleting those of the spilled pseudos which did not get\n+     a new hard register home from the live_{before,after} sets.  */\n   for (chain = reload_insn_chain; chain; chain = chain->next)\n     {\n+      HARD_REG_SET used_by_pseudos;\n+      HARD_REG_SET used_by_pseudos2;\n+\n       AND_COMPL_REG_SET (chain->live_before, spilled_pseudos);\n       AND_COMPL_REG_SET (chain->live_after, spilled_pseudos);\n+\n+      /* Mark any unallocated hard regs as available for spills.  That\n+\t makes inheritance work somewhat better.  */\n+      if (chain->need_reload)\n+\t{\n+\t  REG_SET_TO_HARD_REG_SET (used_by_pseudos, chain->live_before);\n+\t  REG_SET_TO_HARD_REG_SET (used_by_pseudos2, chain->live_after);\n+\t  IOR_HARD_REG_SET (used_by_pseudos, used_by_pseudos2);\n+\n+\t  /* Save the old value for the sanity test below.  */\n+\t  COPY_HARD_REG_SET (used_by_pseudos2, chain->used_spill_regs);\n+\n+\t  compute_use_by_pseudos (&used_by_pseudos, chain->live_before);\n+\t  compute_use_by_pseudos (&used_by_pseudos, chain->live_after);\n+\t  COMPL_HARD_REG_SET (chain->used_spill_regs, used_by_pseudos);\n+\t  AND_HARD_REG_SET (chain->used_spill_regs, used_spill_regs);\n+\n+\t  /* Make sure we only enlarge the set.  */\n+\t  GO_IF_HARD_REG_SUBSET (used_by_pseudos2, chain->used_spill_regs, ok);\n+\t  abort ();\n+\tok:;\n+\t}\n     }\n+\n+  /* Let alter_reg modify the reg rtx's for the modified pseudos.  */\n+  for (i = FIRST_PSEUDO_REGISTER; i < max_regno; i++)\n+    {\n+      int regno = reg_renumber[i];\n+      if (reg_old_renumber[i] == regno)\n+\tcontinue;\n+      \n+      alter_reg (i, reg_old_renumber[i]);\n+      reg_old_renumber[i] = regno;\n+      if (dumpfile)\n+\t{\n+\t  if (regno == -1)\n+\t    fprintf (dumpfile, \" Register %d now on stack.\\n\\n\", i);\n+\t  else\n+\t    fprintf (dumpfile, \" Register %d now in %d.\\n\\n\",\n+\t\t     i, reg_renumber[i]);\n+\t}\n+    }\n+\n+  return something_changed;\n }\n \f\n /* Find all paradoxical subregs within X and update reg_max_ref_width. \n@@ -4033,9 +3803,11 @@ scan_paradoxical_subregs (x)\n   switch (code)\n     {\n     case REG:\n+#if 0\n       if (SMALL_REGISTER_CLASSES && REGNO (x) < FIRST_PSEUDO_REGISTER\n \t  && REG_USERVAR_P (x))\n-\tSET_HARD_REG_BIT (forbidden_regs, REGNO (x));\n+\tSET_HARD_REG_BIT (bad_spill_regs_global, REGNO (x));\n+#endif\n       return;\n \n     case CONST_INT:\n@@ -4076,92 +3848,105 @@ scan_paradoxical_subregs (x)\n \f\n static int\n hard_reg_use_compare (p1p, p2p)\n-  const GENERIC_PTR p1p;\n-  const GENERIC_PTR p2p;\n-{\n-  struct hard_reg_n_uses *p1 = (struct hard_reg_n_uses *)p1p,\n-\t\t\t *p2 = (struct hard_reg_n_uses *)p2p;\n-  int tem = p1->uses - p2->uses;\n-  if (tem != 0) return tem;\n+     const GENERIC_PTR p1p;\n+     const GENERIC_PTR p2p;\n+{  \n+  struct hard_reg_n_uses *p1 = (struct hard_reg_n_uses *)p1p;\n+  struct hard_reg_n_uses *p2 = (struct hard_reg_n_uses *)p2p;\n+  int bad1 = TEST_HARD_REG_BIT (bad_spill_regs, p1->regno);\n+  int bad2 = TEST_HARD_REG_BIT (bad_spill_regs, p2->regno);\n+  if (bad1 && bad2)\n+    return p1->regno - p2->regno;\n+  if (bad1)\n+    return 1;\n+  if (bad2)\n+    return -1;\n+  if (p1->uses > p2->uses)\n+    return 1;\n+  if (p1->uses < p2->uses)\n+    return -1;\n   /* If regs are equally good, sort by regno,\n      so that the results of qsort leave nothing to chance.  */\n   return p1->regno - p2->regno;\n }\n \n+/* Used for communication between order_regs_for_reload and count_pseudo.\n+   Used to avoid counting one pseudo twice.  */\n+static regset pseudos_counted;\n+\n+/* Update the costs in N_USES, considering that pseudo REG is live.  */\n+static void\n+count_pseudo (n_uses, reg)\n+     struct hard_reg_n_uses *n_uses;\n+     int reg;\n+{\n+  int r = reg_renumber[reg];\n+  int nregs;\n+\n+  if (REGNO_REG_SET_P (pseudos_counted, reg))\n+    return;\n+  SET_REGNO_REG_SET (pseudos_counted, reg);\n+\n+  if (r < 0)\n+    abort ();\n+\n+  nregs = HARD_REGNO_NREGS (r, PSEUDO_REGNO_MODE (reg));\n+  while (nregs-- > 0)\n+    n_uses[r++].uses += REG_N_REFS (reg);  \n+}\n /* Choose the order to consider regs for use as reload registers\n    based on how much trouble would be caused by spilling one.\n    Store them in order of decreasing preference in potential_reload_regs.  */\n \n static void\n-order_regs_for_reload ()\n+order_regs_for_reload (chain)\n+     struct insn_chain *chain;\n {\n-  register unsigned int i;\n+  register int i;\n   register int o = 0;\n-  int large = 0;\n-\n   struct hard_reg_n_uses hard_reg_n_uses[FIRST_PSEUDO_REGISTER];\n \n-  CLEAR_HARD_REG_SET (bad_spill_regs);\n+  pseudos_counted = ALLOCA_REG_SET ();\n \n-  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n-    potential_reload_regs[i] = -1;\n+  COPY_HARD_REG_SET (bad_spill_regs, bad_spill_regs_global);\n \n   /* Count number of uses of each hard reg by pseudo regs allocated to it\n      and then order them by decreasing use.  */\n \n   for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n     {\n-      hard_reg_n_uses[i].uses = 0;\n+      int j;\n+\n       hard_reg_n_uses[i].regno = i;\n-    }\n+      hard_reg_n_uses[i].uses = 0;\n \n-  for (i = FIRST_PSEUDO_REGISTER; i < (unsigned) max_regno; i++)\n-    {\n-      int regno = reg_renumber[i];\n-      if (regno >= 0)\n+      /* Test the various reasons why we can't use a register for\n+\t spilling in this insn.  */\n+      if (fixed_regs[i]\n+\t  || REGNO_REG_SET_P (chain->live_before, i)\n+\t  || REGNO_REG_SET_P (chain->live_after, i))\n \t{\n-\t  int lim = regno + HARD_REGNO_NREGS (regno, PSEUDO_REGNO_MODE (i));\n-\t  while (regno < lim)\n-\t    hard_reg_n_uses[regno++].uses += REG_N_REFS (i);\n-\t}\n-      large += REG_N_REFS (i);\n-    }\n-\n-  /* Now fixed registers (which cannot safely be used for reloading)\n-     get a very high use count so they will be considered least desirable.\n-     Registers used explicitly in the rtl code are almost as bad.  */\n-\n-  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n-    {\n-      if (fixed_regs[i])\n-\t{\n-\t  hard_reg_n_uses[i].uses += 2 * large + 2;\n \t  SET_HARD_REG_BIT (bad_spill_regs, i);\n+\t  continue;\n \t}\n-      else if (regs_explicitly_used[i])\n-\t{\n-\t  hard_reg_n_uses[i].uses += large + 1;\n-\t  if (! SMALL_REGISTER_CLASSES)\n-\t    /* ??? We are doing this here because of the potential\n-\t     that bad code may be generated if a register explicitly\n-\t     used in an insn was used as a spill register for that\n-\t     insn.  But not using these are spill registers may lose\n-\t     on some machine.  We'll have to see how this works out.  */\n-\t    SET_HARD_REG_BIT (bad_spill_regs, i);\n-\t}\n-    }\n-  hard_reg_n_uses[HARD_FRAME_POINTER_REGNUM].uses += 2 * large + 2;\n-  SET_HARD_REG_BIT (bad_spill_regs, HARD_FRAME_POINTER_REGNUM);\n \n-#ifdef ELIMINABLE_REGS\n-  /* If registers other than the frame pointer are eliminable, mark them as\n-     poor choices.  */\n-  for (i = 0; i < NUM_ELIMINABLE_REGS; i++)\n-    {\n-      hard_reg_n_uses[reg_eliminate[i].from].uses += 2 * large + 2;\n-      SET_HARD_REG_BIT (bad_spill_regs, reg_eliminate[i].from);\n+      /* Now find out which pseudos are allocated to it, and update\n+\t hard_reg_n_uses.  */\n+      CLEAR_REG_SET (pseudos_counted);\n+\n+      EXECUTE_IF_SET_IN_REG_SET\n+\t(chain->live_before, FIRST_PSEUDO_REGISTER, j,\n+\t {\n+\t   count_pseudo (hard_reg_n_uses, j);\n+\t });\n+      EXECUTE_IF_SET_IN_REG_SET\n+\t(chain->live_after, FIRST_PSEUDO_REGISTER, j,\n+\t {\n+\t   count_pseudo (hard_reg_n_uses, j);\n+\t });\n     }\n-#endif\n+\n+  FREE_REG_SET (pseudos_counted);\n \n   /* Prefer registers not so far used, for use in temporary loading.\n      Among them, if REG_ALLOC_ORDER is defined, use that order.\n@@ -4172,18 +3957,21 @@ order_regs_for_reload ()\n     {\n       int regno = reg_alloc_order[i];\n \n-      if (hard_reg_n_uses[regno].uses == 0)\n+      if (hard_reg_n_uses[regno].uses == 0\n+\t  && ! TEST_HARD_REG_BIT (bad_spill_regs, regno))\n \tpotential_reload_regs[o++] = regno;\n     }\n #else\n   for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n     {\n-      if (hard_reg_n_uses[i].uses == 0 && call_used_regs[i])\n+      if (hard_reg_n_uses[i].uses == 0 && call_used_regs[i]\n+\t  && ! TEST_HARD_REG_BIT (bad_spill_regs, i))\n \tpotential_reload_regs[o++] = i;\n     }\n   for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n     {\n-      if (hard_reg_n_uses[i].uses == 0 && ! call_used_regs[i])\n+      if (hard_reg_n_uses[i].uses == 0 && ! call_used_regs[i]\n+\t  && ! TEST_HARD_REG_BIT (bad_spill_regs, i))\n \tpotential_reload_regs[o++] = i;\n     }\n #endif\n@@ -4196,21 +3984,14 @@ order_regs_for_reload ()\n      registers will be at the end of this list.  */\n \n   for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n-    if (hard_reg_n_uses[i].uses != 0)\n+    if (hard_reg_n_uses[i].uses != 0\n+\t&& ! TEST_HARD_REG_BIT (bad_spill_regs, hard_reg_n_uses[i].regno))\n+      potential_reload_regs[o++] = hard_reg_n_uses[i].regno;\n+  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)\n+    if (TEST_HARD_REG_BIT (bad_spill_regs, hard_reg_n_uses[i].regno))\n       potential_reload_regs[o++] = hard_reg_n_uses[i].regno;\n }\n \f\n-/* Used in reload_as_needed to sort the spilled regs.  */\n-\n-static int\n-compare_spill_regs (r1p, r2p)\n-     const GENERIC_PTR r1p;\n-     const GENERIC_PTR r2p;\n-{\n-  short r1 = *(short *)r1p, r2 = *(short *)r2p;\n-  return r1 - r2;\n-}\n-\n /* Reload pseudo-registers into hard regs around each insn as needed.\n    Additional register load insns are output before the insn that needs it\n    and perhaps store insns after insns that modify the reloaded pseudo reg.\n@@ -4227,8 +4008,6 @@ reload_as_needed (live_known)\n   struct insn_chain *chain;\n   register int i;\n   rtx x;\n-  rtx after_call = 0;\n-  int after_call_nregs;\n \n   bzero ((char *) spill_reg_rtx, sizeof spill_reg_rtx);\n   bzero ((char *) spill_reg_store, sizeof spill_reg_store);\n@@ -4254,20 +4033,11 @@ reload_as_needed (live_known)\n \n   num_not_at_initial_offset = 0;\n \n-  /* Order the spilled regs, so that allocate_reload_regs can guarantee to\n-     pack registers with group needs.  */\n-  if (n_spills > 1)\n-    {\n-      qsort (spill_regs, n_spills, sizeof (short), compare_spill_regs);\n-      for (i = 0; i < n_spills; i++)\n-\tspill_reg_order[spill_regs[i]] = i;\n-    }\n-\n   for (chain = reload_insn_chain; chain; chain = chain->next)\n     {\n+      rtx prev;\n       rtx insn = chain->insn;\n       rtx old_next = NEXT_INSN (insn);\n-      rtx prev;\n \n       /* If we pass a label, copy the offsets from the label information\n \t into the current offsets of each elimination.  */\n@@ -4287,54 +4057,8 @@ reload_as_needed (live_known)\n \n       else if (GET_RTX_CLASS (GET_CODE (insn)) == 'i')\n \t{\n-\t  rtx avoid_return_reg = 0;\n \t  rtx oldpat = PATTERN (insn);\n \n-\t  /* Set avoid_return_reg if this is an insn\n-\t     that might use the value of a function call.  */\n-\t  if (SMALL_REGISTER_CLASSES && GET_CODE (insn) == CALL_INSN)\n-\t    {\n-\t      if (GET_CODE (PATTERN (insn)) == SET)\n-\t\t{\n-\t\t  after_call = SET_DEST (PATTERN (insn));\n-\t\t  after_call_nregs = HARD_REGNO_NREGS (REGNO (after_call),\n-\t\t\t\t\t\t       GET_MODE (after_call));\n-\t\t}\n-\t      else if (GET_CODE (PATTERN (insn)) == PARALLEL\n-\t\t       && GET_CODE (XVECEXP (PATTERN (insn), 0, 0)) == SET)\n-\t\t{\n-\t\t  after_call = SET_DEST (XVECEXP (PATTERN (insn), 0, 0));\n-\t\t  after_call_nregs = HARD_REGNO_NREGS (REGNO (after_call),\n-\t\t\t\t\t\t       GET_MODE (after_call));\n-\t\t}\n-\t      else\n-\t\tafter_call = 0;\n-\t    }\n-\t  else if (SMALL_REGISTER_CLASSES && after_call != 0\n-\t\t   && !(GET_CODE (PATTERN (insn)) == SET\n-\t\t\t&& SET_DEST (PATTERN (insn)) == stack_pointer_rtx)\n-\t\t   && GET_CODE (PATTERN (insn)) != CLOBBER\n-\t\t   && GET_CODE (PATTERN (insn)) != USE)\n-\t    {\n-\t      if (reg_referenced_p (after_call, PATTERN (insn)))\n-\t\t{\n-\t\t  avoid_return_reg = after_call;\n-\t\t  if (! --after_call_nregs)\n-\t\t    after_call = 0;\n-\t\t  else\n-\t\t    {\n-\t\t      /* If INSN copies the return register in a single chunk,\n-\t\t\t clear after_call now.  */\n-\t\t      rtx set = single_set (insn);\n-\t\t      if (set && (GET_MODE_SIZE (GET_MODE (SET_DEST (set)))\n-\t\t\t\t  == GET_MODE_SIZE (GET_MODE (after_call))))\n-\t\t\tafter_call = 0;\n-\t\t    }\n-\t\t}\n-\t      else\n-\t\tafter_call = 0;\n-\t    }\n-\n \t  /* If this is a USE and CLOBBER of a MEM, ensure that any\n \t     references to eliminable registers have been removed.  */\n \n@@ -4365,7 +4089,8 @@ reload_as_needed (live_known)\n \t     the first pass for every insn that needs register elimination.\n \t     So the actions of find_reloads must be redone here.  */\n \n-\t  if (! chain->need_elim && ! chain->need_reload)\n+\t  if (! chain->need_elim && ! chain->need_reload\n+\t      && ! chain->need_operand_change)\n \t    n_reloads = 0;\n \t  /* First find the pseudo regs that must be reloaded for this insn.\n \t     This info is returned in the tables reload_... (see reload.h).\n@@ -4387,30 +4112,14 @@ reload_as_needed (live_known)\n \t    {\n \t      rtx next = NEXT_INSN (insn);\n \t      rtx p;\n-\t      int class;\n \n \t      prev = PREV_INSN (insn);\n \n-\t      /* If this block has not had spilling done for a\n-\t\t particular clas and we have any non-optionals that need a\n-\t\t spill reg in that class, abort.  */\n-\n-\t      for (class = 0; class < N_REG_CLASSES; class++)\n-\t\tif (basic_block_needs[class] != 0\n-\t\t    && basic_block_needs[class][chain->block] == 0)\n-\t\t  for (i = 0; i < n_reloads; i++)\n-\t\t    if (class == (int) reload_reg_class[i]\n-\t\t\t&& reload_reg_rtx[i] == 0\n-\t\t\t&& ! reload_optional[i]\n-\t\t\t&& (reload_in[i] != 0 || reload_out[i] != 0\n-\t\t\t    || reload_secondary_p[i] != 0))\n-\t\t      fatal_insn (\"Non-optional registers need a spill register\", insn);\n-\n \t      /* Now compute which reload regs to reload them into.  Perhaps\n \t\t reusing reload regs from previous insns, or else output\n \t\t load insns to reload them.  Maybe output store insns too.\n \t\t Record the choices of reload reg in reload_reg_rtx.  */\n-\t      choose_reload_regs (chain, avoid_return_reg);\n+\t      choose_reload_regs (chain);\n \n \t      /* Merge any reloads that we didn't combine for fear of \n \t\t increasing the number of spill registers needed but now\n@@ -5596,11 +5305,8 @@ allocate_reload_reg (chain, r, last_reload, noerror)\n      int noerror;\n {\n   rtx insn = chain->insn;\n-  int i;\n-  int pass;\n-  int count;\n+  int i, pass, count, regno;\n   rtx new;\n-  int regno;\n \n   /* If we put this reload ahead, thinking it is a group,\n      then insist on finding a group.  Otherwise we can grab a\n@@ -5649,32 +5355,36 @@ allocate_reload_reg (chain, r, last_reload, noerror)\n       for (count = 0; count < n_spills; count++)\n \t{\n \t  int class = (int) reload_reg_class[r];\n+\t  int regnum;\n \n-\t  i = (i + 1) % n_spills;\n+\t  i++;\n+\t  if (i >= n_spills)\n+\t    i -= n_spills;\n+\t  regnum = spill_regs[i];\n \n-\t  if ((reload_reg_free_p (spill_regs[i], reload_opnum[r],\n+\t  if ((reload_reg_free_p (regnum, reload_opnum[r],\n \t\t\t\t  reload_when_needed[r])\n \t       || (reload_in[r]\n \t\t      /* We check reload_reg_used to make sure we\n \t\t\t don't clobber the return register.  */\n-\t\t   && ! TEST_HARD_REG_BIT (reload_reg_used, spill_regs[i])\n-\t\t   && reload_reg_free_for_value_p (spill_regs[i],\n+\t\t   && ! TEST_HARD_REG_BIT (reload_reg_used, regnum)\n+\t\t   && reload_reg_free_for_value_p (regnum,\n \t\t\t\t\t\t  reload_opnum[r],\n \t\t\t\t\t\t  reload_when_needed[r],\n \t\t\t\t\t\t  reload_in[r],\n \t\t\t\t\t\t  reload_out[r], r)))\n-\t      && TEST_HARD_REG_BIT (reg_class_contents[class], spill_regs[i])\n-\t      && HARD_REGNO_MODE_OK (spill_regs[i], reload_mode[r])\n+\t      && TEST_HARD_REG_BIT (reg_class_contents[class], regnum)\n+\t      && HARD_REGNO_MODE_OK (regnum, reload_mode[r])\n \t      /* Look first for regs to share, then for unshared.  But\n \t\t don't share regs used for inherited reloads; they are\n \t\t the ones we want to preserve.  */\n \t      && (pass\n \t\t  || (TEST_HARD_REG_BIT (reload_reg_used_at_all,\n-\t\t\t\t\t spill_regs[i])\n+\t\t\t\t\t regnum)\n \t\t      && ! TEST_HARD_REG_BIT (reload_reg_used_for_inherit,\n-\t\t\t\t\t      spill_regs[i]))))\n+\t\t\t\t\t      regnum))))\n \t    {\n-\t      int nr = HARD_REGNO_NREGS (spill_regs[i], reload_mode[r]);\n+\t      int nr = HARD_REGNO_NREGS (regnum, reload_mode[r]);\n \t      /* Avoid the problem where spilling a GENERAL_OR_FP_REG\n \t\t (on 68000) got us two FP regs.  If NR is 1,\n \t\t we would reject both of them.  */\n@@ -5692,15 +5402,15 @@ allocate_reload_reg (chain, r, last_reload, noerror)\n \t\t are available here.\n \t\t Also, don't use for a group registers that are\n \t\t needed for nongroups.  */\n-\t      if (! TEST_HARD_REG_BIT (counted_for_nongroups, spill_regs[i]))\n+\t      if (! TEST_HARD_REG_BIT (chain->counted_for_nongroups, regnum))\n \t\twhile (nr > 1)\n \t\t  {\n-\t\t    regno = spill_regs[i] + nr - 1;\n+\t\t    regno = regnum + nr - 1;\n \t\t    if (!(TEST_HARD_REG_BIT (reg_class_contents[class], regno)\n \t\t\t  && spill_reg_order[regno] >= 0\n \t\t\t  && reload_reg_free_p (regno, reload_opnum[r],\n \t\t\t\t\t\treload_when_needed[r])\n-\t\t\t  && ! TEST_HARD_REG_BIT (counted_for_nongroups,\n+\t\t\t  && ! TEST_HARD_REG_BIT (chain->counted_for_nongroups,\n \t\t\t\t\t\t  regno)))\n \t\t      break;\n \t\t    nr--;\n@@ -5796,9 +5506,8 @@ allocate_reload_reg (chain, r, last_reload, noerror)\n    finding a reload reg in the proper class.  */\n \n static void\n-choose_reload_regs (chain, avoid_return_reg)\n+choose_reload_regs (chain)\n      struct insn_chain *chain;\n-     rtx avoid_return_reg;\n {\n   rtx insn = chain->insn;\n   register int i, j;\n@@ -5850,29 +5559,8 @@ choose_reload_regs (chain, avoid_return_reg)\n       CLEAR_HARD_REG_SET (reload_reg_used_in_outaddr_addr[i]);\n     }\n \n-  /* Don't bother with avoiding the return reg\n-     if we have no mandatory reload that could use it.  */\n-  if (SMALL_REGISTER_CLASSES && avoid_return_reg)\n-    {\n-      int do_avoid = 0;\n-      int regno = REGNO (avoid_return_reg);\n-      int nregs\n-\t= HARD_REGNO_NREGS (regno, GET_MODE (avoid_return_reg));\n-      int r;\n-\n-      for (r = regno; r < regno + nregs; r++)\n-\tif (spill_reg_order[r] >= 0)\n-\t  for (j = 0; j < n_reloads; j++)\n-\t    if (!reload_optional[j] && reload_reg_rtx[j] == 0\n-\t\t&& (reload_in[j] != 0 || reload_out[j] != 0\n-\t\t    || reload_secondary_p[j])\n-\t\t&&\n-\t\tTEST_HARD_REG_BIT (reg_class_contents[(int) reload_reg_class[j]], r))\n-\t      do_avoid = 1;\n-      if (!do_avoid)\n-\tavoid_return_reg = 0;\n-    }\n-\n+  IOR_COMPL_HARD_REG_SET (reload_reg_used, chain->used_spill_regs);\n+  \n #if 0  /* Not needed, now that we can always retry without inheritance.  */\n   /* See if we have more mandatory reloads than spill regs.\n      If so, then we cannot risk optimizations that could prevent\n@@ -5882,7 +5570,7 @@ choose_reload_regs (chain, avoid_return_reg)\n      unless it is equal to reload_in or reload_out, count such reloads.  */\n \n   {\n-    int tem = SMALL_REGISTER_CLASSES? (avoid_return_reg != 0): 0;\n+    int tem = 0;\n     for (j = 0; j < n_reloads; j++)\n       if (! reload_optional[j]\n \t  && (reload_in[j] != 0 || reload_out[j] != 0 || reload_secondary_p[j])\n@@ -5895,20 +5583,6 @@ choose_reload_regs (chain, avoid_return_reg)\n   }\n #endif\n \n-  /* Don't use the subroutine call return reg for a reload\n-     if we are supposed to avoid it.  */\n-  if (SMALL_REGISTER_CLASSES && avoid_return_reg)\n-    {\n-      int regno = REGNO (avoid_return_reg);\n-      int nregs\n-\t= HARD_REGNO_NREGS (regno, GET_MODE (avoid_return_reg));\n-      int r;\n-\n-      for (r = regno; r < regno + nregs; r++)\n-\tif (spill_reg_order[r] >= 0)\n-\t  SET_HARD_REG_BIT (reload_reg_used, r);\n-    }\n-\n   /* In order to be certain of getting the registers we need,\n      we must sort the reloads into order of increasing register class.\n      Then our grabbing of reload registers will parallel the process\n@@ -6419,9 +6093,6 @@ choose_reload_regs (chain, avoid_return_reg)\n       if (j == n_reloads)\n \tbreak;\n \n-#if 0\n-    fail:\n-#endif\n       /* Loop around and try without any inheritance.  */\n       /* First undo everything done by the failed attempt\n \t to allocate with inheritance.  */\n@@ -6478,7 +6149,6 @@ choose_reload_regs (chain, avoid_return_reg)\n \t{\n \t  register int r = reload_order[j];\n \t  rtx check_reg;\n-\n \t  if (reload_inherited[r] && reload_reg_rtx[r])\n \t    check_reg = reload_reg_rtx[r];\n \t  else if (reload_override_in[r]\n@@ -9700,7 +9370,7 @@ reload_combine ()\n   /* If reg+reg can be used in offsetable memory adresses, the main chunk of\n      reload has already used it where appropriate, so there is no use in\n      trying to generate it now.  */\n-  if (double_reg_address_ok && reload_address_index_reg_class != NO_REGS)\n+  if (double_reg_address_ok && INDEX_REG_CLASS != NO_REGS)\n     return;\n \n   /* To avoid wasting too much time later searching for an index register,\n@@ -9896,7 +9566,7 @@ reload_combine ()\n \t     some unknown fashion, so we have to mark the unknown use.  */\n \t  for (i = FIRST_PSEUDO_REGISTER - 1; i >= 0; --i)\n \t    {\n-\t      if (! TEST_HARD_REG_BIT (used_spill_regs, i))\n+\t      if (1)\n \t\treg_state[i].use_index = -1;\n \t    }\n \t}"}]}