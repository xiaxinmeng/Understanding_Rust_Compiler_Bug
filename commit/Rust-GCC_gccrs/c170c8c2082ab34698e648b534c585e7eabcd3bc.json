{"sha": "c170c8c2082ab34698e648b534c585e7eabcd3bc", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6YzE3MGM4YzIwODJhYjM0Njk4ZTY0OGI1MzRjNTg1ZTdlYWJjZDNiYw==", "commit": {"author": {"name": "Jim Wilson", "email": "wilson@gcc.gnu.org", "date": "1996-01-24T20:10:22Z"}, "committer": {"name": "Jim Wilson", "email": "wilson@gcc.gnu.org", "date": "1996-01-24T20:10:22Z"}, "message": "(find_dead_or_set_registers): New function.\n\n(mark_target_live_regs): Delete loop looking forward from target\nand instead call find_dead_or_set_registers.\n(fix_reg_dead_note): New function.\n(fill_slots_from_thread): Call it.\n\nFrom-SVN: r11091", "tree": {"sha": "94e19318124917df8806268ca4e0ab42ee0d820d", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/94e19318124917df8806268ca4e0ab42ee0d820d"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/c170c8c2082ab34698e648b534c585e7eabcd3bc", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c170c8c2082ab34698e648b534c585e7eabcd3bc", "html_url": "https://github.com/Rust-GCC/gccrs/commit/c170c8c2082ab34698e648b534c585e7eabcd3bc", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/c170c8c2082ab34698e648b534c585e7eabcd3bc/comments", "author": null, "committer": null, "parents": [{"sha": "8516af930204c949aebf7e4aaf9bbde13010ff92", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/8516af930204c949aebf7e4aaf9bbde13010ff92", "html_url": "https://github.com/Rust-GCC/gccrs/commit/8516af930204c949aebf7e4aaf9bbde13010ff92"}], "stats": {"total": 298, "additions": 220, "deletions": 78}, "files": [{"sha": "a9101a9be311b341a9a454ad01add9cc3062fbd0", "filename": "gcc/reorg.c", "status": "modified", "additions": 220, "deletions": 78, "changes": 298, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/c170c8c2082ab34698e648b534c585e7eabcd3bc/gcc%2Freorg.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/c170c8c2082ab34698e648b534c585e7eabcd3bc/gcc%2Freorg.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Freorg.c?ref=c170c8c2082ab34698e648b534c585e7eabcd3bc", "patch": "@@ -130,6 +130,9 @@ Boston, MA 02111-1307, USA.  */\n #include \"obstack.h\"\n #include \"insn-attr.h\"\n \n+/* Import list of registers used as spill regs from reload.  */\n+extern HARD_REG_SET used_spill_regs;\n+\n #ifdef DELAY_SLOTS\n \n #define obstack_chunk_alloc xmalloc\n@@ -252,6 +255,7 @@ static int find_basic_block\tPROTO((rtx));\n static void update_block\tPROTO((rtx, rtx));\n static int reorg_redirect_jump PROTO((rtx, rtx));\n static void update_reg_dead_notes PROTO((rtx, rtx));\n+static void fix_reg_dead_note PROTO((rtx, rtx));\n static void update_reg_unused_notes PROTO((rtx, rtx));\n static void update_live_status\tPROTO((rtx, rtx));\n static rtx next_insn_no_annul\tPROTO((rtx));\n@@ -2305,6 +2309,38 @@ update_reg_dead_notes (insn, delayed_insn)\n       }\n }\n \n+/* Called when an insn redundant with start_insn is deleted.  If there\n+   is a REG_DEAD note for the target of start_insn between start_insn\n+   and stop_insn, then the REG_DEAD note needs to be deleted since the\n+   value no longer dies there.\n+\n+   If the REG_DEAD note isn't deleted, then mark_target_live_regs may be\n+   confused into thinking the register is dead.  */\n+\n+static void\n+fix_reg_dead_note (start_insn, stop_insn)\n+     rtx start_insn, stop_insn;\n+{\n+  rtx p, link, next;\n+\n+  for (p = next_nonnote_insn (start_insn); p != stop_insn;\n+       p = next_nonnote_insn (p))\n+    for (link = REG_NOTES (p); link; link = next)\n+      {\n+\tnext = XEXP (link, 1);\n+\n+\tif (REG_NOTE_KIND (link) != REG_DEAD\n+\t    || GET_CODE (XEXP (link, 0)) != REG)\n+\t  continue;\n+\n+\tif (reg_set_p (XEXP (link, 0), PATTERN (start_insn)))\n+\t  {\n+\t    remove_note (p, link);\n+\t    return;\n+\t  }\n+      }\n+}\n+\n /* Delete any REG_UNUSED notes that exist on INSN but not on REDUNDANT_INSN.\n \n    This handles the case of udivmodXi4 instructions which optimize their\n@@ -2400,6 +2436,185 @@ next_insn_no_annul (insn)\n   return insn;\n }\n \f\n+/* A subroutine of mark_target_live_regs.  Search forward from TARGET\n+   looking for registers that are set before they are used.  These are dead. \n+   Stop after passing a few conditional jumps, and/or a small\n+   number of unconditional branches.  */\n+\n+static rtx\n+find_dead_or_set_registers (target, res, jump_target, jump_count, set, needed)\n+     rtx target;\n+     struct resources *res;\n+     rtx *jump_target;\n+     int jump_count;\n+     struct resources set, needed;\n+{\n+  HARD_REG_SET scratch;\n+  rtx insn, next;\n+  rtx jump_insn = 0;\n+  int i;\n+\n+  for (insn = target; insn; insn = next)\n+    {\n+      rtx this_jump_insn = insn;\n+\n+      next = NEXT_INSN (insn);\n+      switch (GET_CODE (insn))\n+\t{\n+\tcase CODE_LABEL:\n+\t  /* After a label, any pending dead registers that weren't yet\n+\t     used can be made dead.  */\n+\t  AND_COMPL_HARD_REG_SET (pending_dead_regs, needed.regs);\n+\t  AND_COMPL_HARD_REG_SET (res->regs, pending_dead_regs);\n+\t  CLEAR_HARD_REG_SET (pending_dead_regs);\n+\n+\t  /* All spill registers are dead at a label, so kill all of the\n+\t     ones that aren't needed also.  */\n+\t  COPY_HARD_REG_SET (scratch, used_spill_regs);\n+\t  AND_COMPL_HARD_REG_SET (scratch, needed.regs);\n+\t  AND_COMPL_HARD_REG_SET (res->regs, scratch);\n+\t  continue;\n+\n+\tcase BARRIER:\n+\tcase NOTE:\n+\t  continue;\n+\n+\tcase INSN:\n+\t  if (GET_CODE (PATTERN (insn)) == USE)\n+\t    {\n+\t      /* If INSN is a USE made by update_block, we care about the\n+\t\t underlying insn.  Any registers set by the underlying insn\n+\t\t are live since the insn is being done somewhere else.  */\n+\t      if (GET_RTX_CLASS (GET_CODE (XEXP (PATTERN (insn), 0))) == 'i')\n+\t\tmark_set_resources (XEXP (PATTERN (insn), 0), res, 0, 1);\n+\n+\t      /* All other USE insns are to be ignored.  */\n+\t      continue;\n+\t    }\n+\t  else if (GET_CODE (PATTERN (insn)) == CLOBBER)\n+\t    continue;\n+\t  else if (GET_CODE (PATTERN (insn)) == SEQUENCE)\n+\t    {\n+\t      /* An unconditional jump can be used to fill the delay slot\n+\t\t of a call, so search for a JUMP_INSN in any position.  */\n+\t      for (i = 0; i < XVECLEN (PATTERN (insn), 0); i++)\n+\t\t{\n+\t\t  this_jump_insn = XVECEXP (PATTERN (insn), 0, i);\n+\t\t  if (GET_CODE (this_jump_insn) == JUMP_INSN)\n+\t\t    break;\n+\t\t}\n+\t    }\n+\t}\n+\n+      if (GET_CODE (this_jump_insn) == JUMP_INSN)\n+\t{\n+\t  if (jump_count++ < 10)\n+\t    {\n+\t      if (simplejump_p (this_jump_insn)\n+\t\t  || GET_CODE (PATTERN (this_jump_insn)) == RETURN)\n+\t\t{\n+\t\t  next = JUMP_LABEL (this_jump_insn);\n+\t\t  if (jump_insn == 0)\n+\t\t    {\n+\t\t      jump_insn = insn;\n+\t\t      if (jump_target)\n+\t\t\t*jump_target = JUMP_LABEL (this_jump_insn);\n+\t\t    }\n+\t\t}\n+\t      else if (condjump_p (this_jump_insn)\n+\t\t       || condjump_in_parallel_p (this_jump_insn))\n+\t\t{\n+\t\t  struct resources target_set, target_res;\n+\t\t  struct resources fallthrough_res;\n+\n+\t\t  /* We can handle conditional branches here by following\n+\t\t     both paths, and then IOR the results of the two paths\n+\t\t     together, which will give us registers that are dead\n+\t\t     on both paths.  Since this is expensive, we give it\n+\t\t     a much higher cost than unconditional branches.  The\n+\t\t     cost was chosen so that we will follow at most 1\n+\t\t     conditional branch.  */\n+\n+\t\t  jump_count += 4;\n+\t\t  if (jump_count >= 10)\n+\t\t    break;\n+\n+\t\t  mark_referenced_resources (insn, &needed, 1);\n+\n+\t\t  /* For an annulled branch, mark_set_resources ignores slots\n+\t\t     filled by instructions from the target.  This is correct\n+\t\t     if the branch is not taken.  Since we are following both\n+\t\t     paths from the branch, we must also compute correct info\n+\t\t     if the branch is taken.  We do this by inverting all of\n+\t\t     the INSN_FROM_TARGET_P bits, calling mark_set_resources,\n+\t\t     and then inverting the INSN_FROM_TARGET_P bits again.  */\n+\n+\t\t  if (GET_CODE (PATTERN (insn)) == SEQUENCE\n+\t\t      && INSN_ANNULLED_BRANCH_P (this_jump_insn))\n+\t\t    {\n+\t\t      for (i = 1; i < XVECLEN (PATTERN (insn), 0); i++)\n+\t\t\tINSN_FROM_TARGET_P (XVECEXP (PATTERN (insn), 0, i))\n+\t\t\t  = ! INSN_FROM_TARGET_P (XVECEXP (PATTERN (insn), 0, i));\n+\n+\t\t      target_set = set;\n+\t\t      mark_set_resources (insn, &target_set, 0, 1);\n+\n+\t\t      for (i = 1; i < XVECLEN (PATTERN (insn), 0); i++)\n+\t\t\tINSN_FROM_TARGET_P (XVECEXP (PATTERN (insn), 0, i))\n+\t\t\t  = ! INSN_FROM_TARGET_P (XVECEXP (PATTERN (insn), 0, i));\n+\n+\t\t      mark_set_resources (insn, &set, 0, 1);\n+\t\t    }\n+\t\t  else\n+\t\t    {\n+\t\t      mark_set_resources (insn, &set, 0, 1);\n+\t\t      target_set = set;\n+\t\t    }\n+\n+\t\t  target_res = *res;\n+\t\t  COPY_HARD_REG_SET (scratch, target_set.regs);\n+\t\t  AND_COMPL_HARD_REG_SET (scratch, needed.regs);\n+\t\t  AND_COMPL_HARD_REG_SET (target_res.regs, scratch);\n+\n+\t\t  fallthrough_res = *res;\n+\t\t  COPY_HARD_REG_SET (scratch, set.regs);\n+\t\t  AND_COMPL_HARD_REG_SET (scratch, needed.regs);\n+\t\t  AND_COMPL_HARD_REG_SET (fallthrough_res.regs, scratch);\n+\n+\t\t  find_dead_or_set_registers (JUMP_LABEL (this_jump_insn),\n+\t\t\t\t\t      &target_res, 0, jump_count,\n+\t\t\t\t\t      target_set, needed);\n+\t\t  find_dead_or_set_registers (next,\n+\t\t\t\t\t      &fallthrough_res, 0, jump_count,\n+\t\t\t\t\t      set, needed);\n+\t\t  IOR_HARD_REG_SET (fallthrough_res.regs, target_res.regs);\n+\t\t  AND_HARD_REG_SET (res->regs, fallthrough_res.regs);\n+\t\t  break;\n+\t\t}\n+\t      else\n+\t\tbreak;\n+\t    }\n+\t  else\n+\t    {\n+\t      /* Don't try this optimization if we expired our jump count\n+\t\t above, since that would mean there may be an infinite loop\n+\t\t in the function being compiled.  */\n+\t      jump_insn = 0;\n+\t      break;\n+\t    }\n+\t}\n+\n+      mark_referenced_resources (insn, &needed, 1);\n+      mark_set_resources (insn, &set, 0, 1);\n+\n+      COPY_HARD_REG_SET (scratch, set.regs);\n+      AND_COMPL_HARD_REG_SET (scratch, needed.regs);\n+      AND_COMPL_HARD_REG_SET (res->regs, scratch);\n+    }\n+\n+  return jump_insn;\n+}\n+\n /* Set the resources that are live at TARGET.\n \n    If TARGET is zero, we refer to the end of the current function and can\n@@ -2670,92 +2885,18 @@ mark_target_live_regs (target, res)\n        in use.  This should happen only extremely rarely.  */\n     SET_HARD_REG_SET (res->regs);\n \n-  /* Now step forward from TARGET looking for registers that are set before\n-     they are used.  These are dead.  If we pass a label, any pending dead\n-     registers that weren't yet used can be made dead.  Stop when we pass a\n-     conditional JUMP_INSN; follow the first few unconditional branches.  */\n-\n   CLEAR_RESOURCE (&set);\n   CLEAR_RESOURCE (&needed);\n \n-  for (insn = target; insn; insn = next)\n-    {\n-      rtx this_jump_insn = insn;\n-\n-      next = NEXT_INSN (insn);\n-      switch (GET_CODE (insn))\n-\t{\n-\tcase CODE_LABEL:\n-\t  AND_COMPL_HARD_REG_SET (pending_dead_regs, needed.regs);\n-\t  AND_COMPL_HARD_REG_SET (res->regs, pending_dead_regs);\n-\t  CLEAR_HARD_REG_SET (pending_dead_regs);\n-\t  continue;\n-\n-\tcase BARRIER:\n-\tcase NOTE:\n-\t  continue;\n-\n-\tcase INSN:\n-\t  if (GET_CODE (PATTERN (insn)) == USE)\n-\t    {\n-\t      /* If INSN is a USE made by update_block, we care about the\n-\t\t underlying insn.  Any registers set by the underlying insn\n-\t\t are live since the insn is being done somewhere else.  */\n-\t      if (GET_RTX_CLASS (GET_CODE (XEXP (PATTERN (insn), 0))) == 'i')\n-\t\tmark_set_resources (XEXP (PATTERN (insn), 0), res, 0, 1);\n-\n-\t      /* All other USE insns are to be ignored.  */\n-\t      continue;\n-\t    }\n-\t  else if (GET_CODE (PATTERN (insn)) == CLOBBER)\n-\t    continue;\n-\t  else if (GET_CODE (PATTERN (insn)) == SEQUENCE)\n-\t    {\n-\t      /* An unconditional jump can be used to fill the delay slot\n-\t\t of a call, so search for a JUMP_INSN in any position.  */\n-\t      for (i = 0; i < XVECLEN (PATTERN (insn), 0); i++)\n-\t\t{\n-\t\t  this_jump_insn = XVECEXP (PATTERN (insn), 0, i);\n-\t\t  if (GET_CODE (this_jump_insn) == JUMP_INSN)\n-\t\t    break;\n-\t\t}\n-\t    }\n-\t}\n-\n-      if (GET_CODE (this_jump_insn) == JUMP_INSN)\n-\t{\n-\t  if (jump_count++ < 10\n-\t      && (simplejump_p (this_jump_insn)\n-\t\t  || GET_CODE (PATTERN (this_jump_insn)) == RETURN))\n-\t    {\n-\t      next = next_active_insn (JUMP_LABEL (this_jump_insn));\n-\t      if (jump_insn == 0)\n-\t\t{\n-\t\t  jump_insn = insn;\n-\t\t  jump_target = JUMP_LABEL (this_jump_insn);\n-\t\t}\n-\t    }\n-\t  else\n-\t    break;\n-\t}\n-\n-      mark_referenced_resources (insn, &needed, 1);\n-      mark_set_resources (insn, &set, 0, 1);\n-\n-      COPY_HARD_REG_SET (scratch, set.regs);\n-      AND_COMPL_HARD_REG_SET (scratch, needed.regs);\n-      AND_COMPL_HARD_REG_SET (res->regs, scratch);\n-    }\n+  jump_insn = find_dead_or_set_registers (target, res, &jump_target, 0,\n+\t\t\t\t\t  set, needed);\n \n   /* If we hit an unconditional branch, we have another way of finding out\n      what is live: we can see what is live at the branch target and include\n      anything used but not set before the branch.  The only things that are\n-     live are those that are live using the above test and the test below.\n-\n-     Don't try this if we expired our jump count above, since that would\n-     mean there may be an infinite loop in the function being compiled.  */\n+     live are those that are live using the above test and the test below.  */\n \n-  if (jump_insn && jump_count < 10)\n+  if (jump_insn)\n     {\n       struct resources new_resources;\n       rtx stop_insn = next_active_insn (jump_insn);\n@@ -3361,6 +3502,7 @@ fill_slots_from_thread (insn, condition, thread, opposite_thread, likely,\n \t     we did.  */\n \t  if (prior_insn = redundant_insn (trial, insn, delay_list))\n \t    {\n+\t      fix_reg_dead_note (prior_insn, insn);\n \t      if (own_thread)\n \t\t{\n \t\t  update_block (trial, thread);"}]}