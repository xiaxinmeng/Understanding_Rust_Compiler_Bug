{"sha": "5726d3760b3b0c939a3ef3001f2cc1d86c08eac7", "node_id": "MDY6Q29tbWl0MTM2NTMxMDA6NTcyNmQzNzYwYjNiMGM5MzlhM2VmMzAwMWYyY2MxZDg2YzA4ZWFjNw==", "commit": {"author": {"name": "Alan Lawrence", "email": "alan.lawrence@arm.com", "date": "2014-09-05T11:09:28Z"}, "committer": {"name": "Alan Lawrence", "email": "alalaw01@gcc.gnu.org", "date": "2014-09-05T11:09:28Z"}, "message": "[PATCH AArch64 2/2] Remove vector compare/tst __builtins\n \n\t* config/aarch64/aarch64-builtins.c (aarch64_fold_builtin): Remove code\n\thandling cmge, cmgt, cmeq, cmtst.\n\n\t* config/aarch64/aarch64-simd-builtins.def (cmeq, cmge, cmgt, cmle,\n\tcmlt, cmgeu, cmgtu, cmtst): Remove.\n\n\t* config/aarch64/arm_neon.h (vceq_*, vceqq_*, vceqz_*, vceqzq_*,\n\tvcge_*, vcgeq_*, vcgez_*, vcgezq_*, vcgt_*, vcgtq_*, vcgtz_*,\n\tvcgtzq_*, vcle_*, vcleq_*, vclez_*, vclezq_*, vclt_*, vcltq_*,\n\tvcltz_*, vcltzq_*, vtst_*, vtstq_*): Use gcc vector extensions.\n\nFrom-SVN: r214949", "tree": {"sha": "d1cdbb38ca8a4b6a9f66f0d5489d70801fe50420", "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/trees/d1cdbb38ca8a4b6a9f66f0d5489d70801fe50420"}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/git/commits/5726d3760b3b0c939a3ef3001f2cc1d86c08eac7", "comment_count": 0, "verification": {"verified": false, "reason": "unsigned", "signature": null, "payload": null}}, "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5726d3760b3b0c939a3ef3001f2cc1d86c08eac7", "html_url": "https://github.com/Rust-GCC/gccrs/commit/5726d3760b3b0c939a3ef3001f2cc1d86c08eac7", "comments_url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/5726d3760b3b0c939a3ef3001f2cc1d86c08eac7/comments", "author": null, "committer": null, "parents": [{"sha": "ddeabd3e6669f209c8c6aa831cbdb5e6dcf62d41", "url": "https://api.github.com/repos/Rust-GCC/gccrs/commits/ddeabd3e6669f209c8c6aa831cbdb5e6dcf62d41", "html_url": "https://github.com/Rust-GCC/gccrs/commit/ddeabd3e6669f209c8c6aa831cbdb5e6dcf62d41"}], "stats": {"total": 479, "additions": 173, "deletions": 306}, "files": [{"sha": "853832b20f57b629a65b2728b887bed3a4dca376", "filename": "gcc/ChangeLog", "status": "modified", "additions": 13, "deletions": 0, "changes": 13, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5726d3760b3b0c939a3ef3001f2cc1d86c08eac7/gcc%2FChangeLog", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5726d3760b3b0c939a3ef3001f2cc1d86c08eac7/gcc%2FChangeLog", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2FChangeLog?ref=5726d3760b3b0c939a3ef3001f2cc1d86c08eac7", "patch": "@@ -1,3 +1,16 @@\n+2014-09-05  Alan Lawrence  <alan.lawrence@arm.com>\n+\n+\t* config/aarch64/aarch64-builtins.c (aarch64_fold_builtin): Remove code\n+\thandling cmge, cmgt, cmeq, cmtst.\n+\n+\t* config/aarch64/aarch64-simd-builtins.def (cmeq, cmge, cmgt, cmle,\n+\tcmlt, cmgeu, cmgtu, cmtst): Remove.\n+\n+\t* config/aarch64/arm_neon.h (vceq_*, vceqq_*, vceqz_*, vceqzq_*,\n+\tvcge_*, vcgeq_*, vcgez_*, vcgezq_*, vcgt_*, vcgtq_*, vcgtz_*,\n+\tvcgtzq_*, vcle_*, vcleq_*, vclez_*, vclezq_*, vclt_*, vcltq_*,\n+\tvcltz_*, vcltzq_*, vtst_*, vtstq_*): Use gcc vector extensions.\n+\n 2014-09-05  Alan Lawrence  <alan.lawrence@arm.com>\n \n \t* config/aarch64/aarch64-builtins.c (aarch64_types_cmtst_qualifiers,"}, {"sha": "42a1e85246365e997daf75f85a8167f2c4b33db8", "filename": "gcc/config/aarch64/aarch64-builtins.c", "status": "modified", "additions": 0, "deletions": 16, "changes": 16, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5726d3760b3b0c939a3ef3001f2cc1d86c08eac7/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5726d3760b3b0c939a3ef3001f2cc1d86c08eac7/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-builtins.c?ref=5726d3760b3b0c939a3ef3001f2cc1d86c08eac7", "patch": "@@ -1281,22 +1281,6 @@ aarch64_fold_builtin (tree fndecl, int n_args ATTRIBUTE_UNUSED, tree *args,\n       BUILTIN_VALLDI (UNOP, abs, 2)\n \treturn fold_build1 (ABS_EXPR, type, args[0]);\n \tbreak;\n-      BUILTIN_VALLDI (BINOP, cmge, 0)\n-\treturn fold_build2 (GE_EXPR, type, args[0], args[1]);\n-\tbreak;\n-      BUILTIN_VALLDI (BINOP, cmgt, 0)\n-\treturn fold_build2 (GT_EXPR, type, args[0], args[1]);\n-\tbreak;\n-      BUILTIN_VALLDI (BINOP, cmeq, 0)\n-\treturn fold_build2 (EQ_EXPR, type, args[0], args[1]);\n-\tbreak;\n-      BUILTIN_VSDQ_I_DI (TST, cmtst, 0)\n-\t{\n-\t  tree and_node = fold_build2 (BIT_AND_EXPR, type, args[0], args[1]);\n-\t  tree vec_zero_node = build_zero_cst (type);\n-\t  return fold_build2 (NE_EXPR, type, and_node, vec_zero_node);\n-\t  break;\n-\t}\n       VAR1 (REINTERP_SS, reinterpretdi, 0, v1df)\n       VAR1 (REINTERP_SS, reinterpretv8qi, 0, v1df)\n       VAR1 (REINTERP_SS, reinterpretv4hi, 0, v1df)"}, {"sha": "67f05d93d90fac3ecd4101441fc7467335530c8f", "filename": "gcc/config/aarch64/aarch64-simd-builtins.def", "status": "modified", "additions": 0, "deletions": 11, "changes": 11, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5726d3760b3b0c939a3ef3001f2cc1d86c08eac7/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5726d3760b3b0c939a3ef3001f2cc1d86c08eac7/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Faarch64-simd-builtins.def?ref=5726d3760b3b0c939a3ef3001f2cc1d86c08eac7", "patch": "@@ -237,17 +237,6 @@\n   BUILTIN_VSDQ_I (SHIFTIMM, sqshl_n, 0)\n   BUILTIN_VSDQ_I (USHIFTIMM, uqshl_n, 0)\n \n-  /* Implemented by aarch64_cm<cmp><mode>.  */\n-  BUILTIN_VALLDI (BINOP, cmeq, 0)\n-  BUILTIN_VALLDI (BINOP, cmge, 0)\n-  BUILTIN_VALLDI (BINOP, cmgt, 0)\n-  BUILTIN_VALLDI (BINOP, cmle, 0)\n-  BUILTIN_VALLDI (BINOP, cmlt, 0)\n-  /* Implemented by aarch64_cm<cmp><mode>.  */\n-  BUILTIN_VSDQ_I_DI (BINOP, cmgeu, 0)\n-  BUILTIN_VSDQ_I_DI (BINOP, cmgtu, 0)\n-  BUILTIN_VSDQ_I_DI (TST, cmtst, 0)\n-\n   /* Implemented by reduc_<sur>plus_<mode>.  */\n   BUILTIN_VALL (UNOP, reduc_splus_, 10)\n   BUILTIN_VDQ (UNOP, reduc_uplus_, 10)"}, {"sha": "b33dc5cfaa09c80152bd55c766d19848dac8d9c0", "filename": "gcc/config/aarch64/arm_neon.h", "status": "modified", "additions": 160, "deletions": 279, "changes": 439, "blob_url": "https://github.com/Rust-GCC/gccrs/blob/5726d3760b3b0c939a3ef3001f2cc1d86c08eac7/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "raw_url": "https://github.com/Rust-GCC/gccrs/raw/5726d3760b3b0c939a3ef3001f2cc1d86c08eac7/gcc%2Fconfig%2Faarch64%2Farm_neon.h", "contents_url": "https://api.github.com/repos/Rust-GCC/gccrs/contents/gcc%2Fconfig%2Faarch64%2Farm_neon.h?ref=5726d3760b3b0c939a3ef3001f2cc1d86c08eac7", "patch": "@@ -13865,7 +13865,7 @@ vcalts_f32 (float32_t __a, float32_t __b)\n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vceq_f32 (float32x2_t __a, float32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmeqv2sf (__a, __b);\n+  return (uint32x2_t) (__a == __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -13877,26 +13877,25 @@ vceq_f64 (float64x1_t __a, float64x1_t __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vceq_p8 (poly8x8_t __a, poly8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_cmeqv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t (int8x8_t) __b);\n+  return (uint8x8_t) (__a == __b);\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vceq_s8 (int8x8_t __a, int8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_cmeqv8qi (__a, __b);\n+  return (uint8x8_t) (__a == __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vceq_s16 (int16x4_t __a, int16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_cmeqv4hi (__a, __b);\n+  return (uint16x4_t) (__a == __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vceq_s32 (int32x2_t __a, int32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmeqv2si (__a, __b);\n+  return (uint32x2_t) (__a == __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -13908,22 +13907,19 @@ vceq_s64 (int64x1_t __a, int64x1_t __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vceq_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_cmeqv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t (int8x8_t) __b);\n+  return (__a == __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vceq_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_cmeqv4hi ((int16x4_t) __a,\n-\t\t\t\t\t\t  (int16x4_t) __b);\n+  return (__a == __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vceq_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmeqv2si ((int32x2_t) __a,\n-\t\t\t\t\t\t  (int32x2_t) __b);\n+  return (__a == __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -13935,72 +13931,67 @@ vceq_u64 (uint64x1_t __a, uint64x1_t __b)\n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vceqq_f32 (float32x4_t __a, float32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmeqv4sf (__a, __b);\n+  return (uint32x4_t) (__a == __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vceqq_f64 (float64x2_t __a, float64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmeqv2df (__a, __b);\n+  return (uint64x2_t) (__a == __b);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vceqq_p8 (poly8x16_t __a, poly8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_cmeqv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t   (int8x16_t) __b);\n+  return (uint8x16_t) (__a == __b);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vceqq_s8 (int8x16_t __a, int8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_cmeqv16qi (__a, __b);\n+  return (uint8x16_t) (__a == __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vceqq_s16 (int16x8_t __a, int16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_cmeqv8hi (__a, __b);\n+  return (uint16x8_t) (__a == __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vceqq_s32 (int32x4_t __a, int32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmeqv4si (__a, __b);\n+  return (uint32x4_t) (__a == __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vceqq_s64 (int64x2_t __a, int64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmeqv2di (__a, __b);\n+  return (uint64x2_t) (__a == __b);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vceqq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_cmeqv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t   (int8x16_t) __b);\n+  return (__a == __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vceqq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_cmeqv8hi ((int16x8_t) __a,\n-\t\t\t\t\t\t  (int16x8_t) __b);\n+  return (__a == __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vceqq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmeqv4si ((int32x4_t) __a,\n-\t\t\t\t\t\t  (int32x4_t) __b);\n+  return (__a == __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vceqq_u64 (uint64x2_t __a, uint64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmeqv2di ((int64x2_t) __a,\n-\t\t\t\t\t\t  (int64x2_t) __b);\n+  return (__a == __b);\n }\n \n /* vceq - scalar.  */\n@@ -14034,8 +14025,7 @@ vceqd_f64 (float64_t __a, float64_t __b)\n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vceqz_f32 (float32x2_t __a)\n {\n-  float32x2_t __b = {0.0f, 0.0f};\n-  return (uint32x2_t) __builtin_aarch64_cmeqv2sf (__a, __b);\n+  return (uint32x2_t) (__a == 0.0f);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14047,30 +14037,25 @@ vceqz_f64 (float64x1_t __a)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vceqz_p8 (poly8x8_t __a)\n {\n-  poly8x8_t __b = {0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint8x8_t) __builtin_aarch64_cmeqv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t (int8x8_t) __b);\n+  return (uint8x8_t) (__a == 0);\n }\n \n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vceqz_s8 (int8x8_t __a)\n {\n-  int8x8_t __b = {0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint8x8_t) __builtin_aarch64_cmeqv8qi (__a, __b);\n+  return (uint8x8_t) (__a == 0);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vceqz_s16 (int16x4_t __a)\n {\n-  int16x4_t __b = {0, 0, 0, 0};\n-  return (uint16x4_t) __builtin_aarch64_cmeqv4hi (__a, __b);\n+  return (uint16x4_t) (__a == 0);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vceqz_s32 (int32x2_t __a)\n {\n-  int32x2_t __b = {0, 0};\n-  return (uint32x2_t) __builtin_aarch64_cmeqv2si (__a, __b);\n+  return (uint32x2_t) (__a == 0);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14082,25 +14067,19 @@ vceqz_s64 (int64x1_t __a)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vceqz_u8 (uint8x8_t __a)\n {\n-  uint8x8_t __b = {0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint8x8_t) __builtin_aarch64_cmeqv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t (int8x8_t) __b);\n+  return (__a == 0);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vceqz_u16 (uint16x4_t __a)\n {\n-  uint16x4_t __b = {0, 0, 0, 0};\n-  return (uint16x4_t) __builtin_aarch64_cmeqv4hi ((int16x4_t) __a,\n-\t\t\t\t\t\t  (int16x4_t) __b);\n+  return (__a == 0);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vceqz_u32 (uint32x2_t __a)\n {\n-  uint32x2_t __b = {0, 0};\n-  return (uint32x2_t) __builtin_aarch64_cmeqv2si ((int32x2_t) __a,\n-\t\t\t\t\t\t  (int32x2_t) __b);\n+  return (__a == 0);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14112,86 +14091,67 @@ vceqz_u64 (uint64x1_t __a)\n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vceqzq_f32 (float32x4_t __a)\n {\n-  float32x4_t __b = {0.0f, 0.0f, 0.0f, 0.0f};\n-  return (uint32x4_t) __builtin_aarch64_cmeqv4sf (__a, __b);\n+  return (uint32x4_t) (__a == 0.0f);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vceqzq_f64 (float64x2_t __a)\n {\n-  float64x2_t __b = {0.0, 0.0};\n-  return (uint64x2_t) __builtin_aarch64_cmeqv2df (__a, __b);\n+  return (uint64x2_t) (__a == 0.0f);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vceqzq_p8 (poly8x16_t __a)\n {\n-  poly8x16_t __b = {0, 0, 0, 0, 0, 0, 0, 0,\n-\t\t    0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint8x16_t) __builtin_aarch64_cmeqv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t   (int8x16_t) __b);\n+  return (uint8x16_t) (__a == 0);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vceqzq_s8 (int8x16_t __a)\n {\n-  int8x16_t __b = {0, 0, 0, 0, 0, 0, 0, 0,\n-\t\t   0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint8x16_t) __builtin_aarch64_cmeqv16qi (__a, __b);\n+  return (uint8x16_t) (__a == 0);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vceqzq_s16 (int16x8_t __a)\n {\n-  int16x8_t __b = {0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint16x8_t) __builtin_aarch64_cmeqv8hi (__a, __b);\n+  return (uint16x8_t) (__a == 0);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vceqzq_s32 (int32x4_t __a)\n {\n-  int32x4_t __b = {0, 0, 0, 0};\n-  return (uint32x4_t) __builtin_aarch64_cmeqv4si (__a, __b);\n+  return (uint32x4_t) (__a == 0);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vceqzq_s64 (int64x2_t __a)\n {\n-  int64x2_t __b = {0, 0};\n-  return (uint64x2_t) __builtin_aarch64_cmeqv2di (__a, __b);\n+  return (uint64x2_t) (__a == __AARCH64_INT64_C (0));\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vceqzq_u8 (uint8x16_t __a)\n {\n-  uint8x16_t __b = {0, 0, 0, 0, 0, 0, 0, 0,\n-\t\t    0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint8x16_t) __builtin_aarch64_cmeqv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t   (int8x16_t) __b);\n+  return (__a == 0);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vceqzq_u16 (uint16x8_t __a)\n {\n-  uint16x8_t __b = {0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint16x8_t) __builtin_aarch64_cmeqv8hi ((int16x8_t) __a,\n-\t\t\t\t\t\t  (int16x8_t) __b);\n+  return (__a == 0);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vceqzq_u32 (uint32x4_t __a)\n {\n-  uint32x4_t __b = {0, 0, 0, 0};\n-  return (uint32x4_t) __builtin_aarch64_cmeqv4si ((int32x4_t) __a,\n-\t\t\t\t\t\t  (int32x4_t) __b);\n+  return (__a == 0);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vceqzq_u64 (uint64x2_t __a)\n {\n-  uint64x2_t __b = {0, 0};\n-  return (uint64x2_t) __builtin_aarch64_cmeqv2di ((int64x2_t) __a,\n-\t\t\t\t\t\t  (int64x2_t) __b);\n+  return (__a == __AARCH64_UINT64_C (0));\n }\n \n /* vceqz - scalar.  */\n@@ -14225,7 +14185,7 @@ vceqzd_f64 (float64_t __a)\n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vcge_f32 (float32x2_t __a, float32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmgev2sf (__a, __b);\n+  return (uint32x2_t) (__a >= __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14237,19 +14197,19 @@ vcge_f64 (float64x1_t __a, float64x1_t __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vcge_s8 (int8x8_t __a, int8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_cmgev8qi (__a, __b);\n+  return (uint8x8_t) (__a >= __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vcge_s16 (int16x4_t __a, int16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_cmgev4hi (__a, __b);\n+  return (uint16x4_t) (__a >= __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vcge_s32 (int32x2_t __a, int32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmgev2si (__a, __b);\n+  return (uint32x2_t) (__a >= __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14261,22 +14221,19 @@ vcge_s64 (int64x1_t __a, int64x1_t __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vcge_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_cmgeuv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t (int8x8_t) __b);\n+  return (__a >= __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vcge_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_cmgeuv4hi ((int16x4_t) __a,\n-\t\t\t\t\t\t  (int16x4_t) __b);\n+  return (__a >= __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vcge_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmgeuv2si ((int32x2_t) __a,\n-\t\t\t\t\t\t  (int32x2_t) __b);\n+  return (__a >= __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14288,65 +14245,61 @@ vcge_u64 (uint64x1_t __a, uint64x1_t __b)\n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcgeq_f32 (float32x4_t __a, float32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmgev4sf (__a, __b);\n+  return (uint32x4_t) (__a >= __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcgeq_f64 (float64x2_t __a, float64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmgev2df (__a, __b);\n+  return (uint64x2_t) (__a >= __b);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vcgeq_s8 (int8x16_t __a, int8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_cmgev16qi (__a, __b);\n+  return (uint8x16_t) (__a >= __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vcgeq_s16 (int16x8_t __a, int16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_cmgev8hi (__a, __b);\n+  return (uint16x8_t) (__a >= __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcgeq_s32 (int32x4_t __a, int32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmgev4si (__a, __b);\n+  return (uint32x4_t) (__a >= __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcgeq_s64 (int64x2_t __a, int64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmgev2di (__a, __b);\n+  return (uint64x2_t) (__a >= __b);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vcgeq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_cmgeuv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t   (int8x16_t) __b);\n+  return (__a >= __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vcgeq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_cmgeuv8hi ((int16x8_t) __a,\n-\t\t\t\t\t\t  (int16x8_t) __b);\n+  return (__a >= __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcgeq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmgeuv4si ((int32x4_t) __a,\n-\t\t\t\t\t\t  (int32x4_t) __b);\n+  return (__a >= __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcgeq_u64 (uint64x2_t __a, uint64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmgeuv2di ((int64x2_t) __a,\n-\t\t\t\t\t\t  (int64x2_t) __b);\n+  return (__a >= __b);\n }\n \n /* vcge - scalar.  */\n@@ -14380,8 +14333,7 @@ vcged_f64 (float64_t __a, float64_t __b)\n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vcgez_f32 (float32x2_t __a)\n {\n-  float32x2_t __b = {0.0f, 0.0f};\n-  return (uint32x2_t) __builtin_aarch64_cmgev2sf (__a, __b);\n+  return (uint32x2_t) (__a >= 0.0f);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14393,22 +14345,19 @@ vcgez_f64 (float64x1_t __a)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vcgez_s8 (int8x8_t __a)\n {\n-  int8x8_t __b = {0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint8x8_t) __builtin_aarch64_cmgev8qi (__a, __b);\n+  return (uint8x8_t) (__a >= 0);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vcgez_s16 (int16x4_t __a)\n {\n-  int16x4_t __b = {0, 0, 0, 0};\n-  return (uint16x4_t) __builtin_aarch64_cmgev4hi (__a, __b);\n+  return (uint16x4_t) (__a >= 0);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vcgez_s32 (int32x2_t __a)\n {\n-  int32x2_t __b = {0, 0};\n-  return (uint32x2_t) __builtin_aarch64_cmgev2si (__a, __b);\n+  return (uint32x2_t) (__a >= 0);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14420,44 +14369,37 @@ vcgez_s64 (int64x1_t __a)\n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcgezq_f32 (float32x4_t __a)\n {\n-  float32x4_t __b = {0.0f, 0.0f, 0.0f, 0.0f};\n-  return (uint32x4_t) __builtin_aarch64_cmgev4sf (__a, __b);\n+  return (uint32x4_t) (__a >= 0.0f);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcgezq_f64 (float64x2_t __a)\n {\n-  float64x2_t __b = {0.0, 0.0};\n-  return (uint64x2_t) __builtin_aarch64_cmgev2df (__a, __b);\n+  return (uint64x2_t) (__a >= 0.0);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vcgezq_s8 (int8x16_t __a)\n {\n-  int8x16_t __b = {0, 0, 0, 0, 0, 0, 0, 0,\n-\t\t   0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint8x16_t) __builtin_aarch64_cmgev16qi (__a, __b);\n+  return (uint8x16_t) (__a >= 0);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vcgezq_s16 (int16x8_t __a)\n {\n-  int16x8_t __b = {0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint16x8_t) __builtin_aarch64_cmgev8hi (__a, __b);\n+  return (uint16x8_t) (__a >= 0);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcgezq_s32 (int32x4_t __a)\n {\n-  int32x4_t __b = {0, 0, 0, 0};\n-  return (uint32x4_t) __builtin_aarch64_cmgev4si (__a, __b);\n+  return (uint32x4_t) (__a >= 0);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcgezq_s64 (int64x2_t __a)\n {\n-  int64x2_t __b = {0, 0};\n-  return (uint64x2_t) __builtin_aarch64_cmgev2di (__a, __b);\n+  return (uint64x2_t) (__a >= __AARCH64_INT64_C (0));\n }\n \n /* vcgez - scalar.  */\n@@ -14485,7 +14427,7 @@ vcgezd_f64 (float64_t __a)\n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vcgt_f32 (float32x2_t __a, float32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmgtv2sf (__a, __b);\n+  return (uint32x2_t) (__a > __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14497,19 +14439,19 @@ vcgt_f64 (float64x1_t __a, float64x1_t __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vcgt_s8 (int8x8_t __a, int8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_cmgtv8qi (__a, __b);\n+  return (uint8x8_t) (__a > __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vcgt_s16 (int16x4_t __a, int16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_cmgtv4hi (__a, __b);\n+  return (uint16x4_t) (__a > __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vcgt_s32 (int32x2_t __a, int32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmgtv2si (__a, __b);\n+  return (uint32x2_t) (__a > __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14521,22 +14463,19 @@ vcgt_s64 (int64x1_t __a, int64x1_t __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vcgt_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_cmgtuv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t (int8x8_t) __b);\n+  return (__a > __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vcgt_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_cmgtuv4hi ((int16x4_t) __a,\n-\t\t\t\t\t\t  (int16x4_t) __b);\n+  return (__a > __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vcgt_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmgtuv2si ((int32x2_t) __a,\n-\t\t\t\t\t\t  (int32x2_t) __b);\n+  return (__a > __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14548,65 +14487,61 @@ vcgt_u64 (uint64x1_t __a, uint64x1_t __b)\n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcgtq_f32 (float32x4_t __a, float32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmgtv4sf (__a, __b);\n+  return (uint32x4_t) (__a > __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcgtq_f64 (float64x2_t __a, float64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmgtv2df (__a, __b);\n+  return (uint64x2_t) (__a > __b);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vcgtq_s8 (int8x16_t __a, int8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_cmgtv16qi (__a, __b);\n+  return (uint8x16_t) (__a > __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vcgtq_s16 (int16x8_t __a, int16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_cmgtv8hi (__a, __b);\n+  return (uint16x8_t) (__a > __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcgtq_s32 (int32x4_t __a, int32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmgtv4si (__a, __b);\n+  return (uint32x4_t) (__a > __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcgtq_s64 (int64x2_t __a, int64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmgtv2di (__a, __b);\n+  return (uint64x2_t) (__a > __b);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vcgtq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_cmgtuv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t   (int8x16_t) __b);\n+  return (__a > __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vcgtq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_cmgtuv8hi ((int16x8_t) __a,\n-\t\t\t\t\t\t  (int16x8_t) __b);\n+  return (__a > __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcgtq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmgtuv4si ((int32x4_t) __a,\n-\t\t\t\t\t\t  (int32x4_t) __b);\n+  return (__a > __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcgtq_u64 (uint64x2_t __a, uint64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmgtuv2di ((int64x2_t) __a,\n-\t\t\t\t\t\t  (int64x2_t) __b);\n+  return (__a > __b);\n }\n \n /* vcgt - scalar.  */\n@@ -14640,8 +14575,7 @@ vcgtd_f64 (float64_t __a, float64_t __b)\n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vcgtz_f32 (float32x2_t __a)\n {\n-  float32x2_t __b = {0.0f, 0.0f};\n-  return (uint32x2_t) __builtin_aarch64_cmgtv2sf (__a, __b);\n+  return (uint32x2_t) (__a > 0.0f);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14653,22 +14587,19 @@ vcgtz_f64 (float64x1_t __a)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vcgtz_s8 (int8x8_t __a)\n {\n-  int8x8_t __b = {0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint8x8_t) __builtin_aarch64_cmgtv8qi (__a, __b);\n+  return (uint8x8_t) (__a > 0);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vcgtz_s16 (int16x4_t __a)\n {\n-  int16x4_t __b = {0, 0, 0, 0};\n-  return (uint16x4_t) __builtin_aarch64_cmgtv4hi (__a, __b);\n+  return (uint16x4_t) (__a > 0);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vcgtz_s32 (int32x2_t __a)\n {\n-  int32x2_t __b = {0, 0};\n-  return (uint32x2_t) __builtin_aarch64_cmgtv2si (__a, __b);\n+  return (uint32x2_t) (__a > 0);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14680,44 +14611,37 @@ vcgtz_s64 (int64x1_t __a)\n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcgtzq_f32 (float32x4_t __a)\n {\n-  float32x4_t __b = {0.0f, 0.0f, 0.0f, 0.0f};\n-  return (uint32x4_t) __builtin_aarch64_cmgtv4sf (__a, __b);\n+  return (uint32x4_t) (__a > 0.0f);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcgtzq_f64 (float64x2_t __a)\n {\n-  float64x2_t __b = {0.0, 0.0};\n-  return (uint64x2_t) __builtin_aarch64_cmgtv2df (__a, __b);\n+    return (uint64x2_t) (__a > 0.0);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vcgtzq_s8 (int8x16_t __a)\n {\n-  int8x16_t __b = {0, 0, 0, 0, 0, 0, 0, 0,\n-\t\t   0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint8x16_t) __builtin_aarch64_cmgtv16qi (__a, __b);\n+  return (uint8x16_t) (__a > 0);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vcgtzq_s16 (int16x8_t __a)\n {\n-  int16x8_t __b = {0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint16x8_t) __builtin_aarch64_cmgtv8hi (__a, __b);\n+  return (uint16x8_t) (__a > 0);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcgtzq_s32 (int32x4_t __a)\n {\n-  int32x4_t __b = {0, 0, 0, 0};\n-  return (uint32x4_t) __builtin_aarch64_cmgtv4si (__a, __b);\n+  return (uint32x4_t) (__a > 0);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcgtzq_s64 (int64x2_t __a)\n {\n-  int64x2_t __b = {0, 0};\n-  return (uint64x2_t) __builtin_aarch64_cmgtv2di (__a, __b);\n+  return (uint64x2_t) (__a > __AARCH64_INT64_C (0));\n }\n \n /* vcgtz - scalar.  */\n@@ -14745,7 +14669,7 @@ vcgtzd_f64 (float64_t __a)\n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vcle_f32 (float32x2_t __a, float32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmgev2sf (__b, __a);\n+  return (uint32x2_t) (__a <= __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14757,19 +14681,19 @@ vcle_f64 (float64x1_t __a, float64x1_t __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vcle_s8 (int8x8_t __a, int8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_cmgev8qi (__b, __a);\n+  return (uint8x8_t) (__a <= __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vcle_s16 (int16x4_t __a, int16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_cmgev4hi (__b, __a);\n+  return (uint16x4_t) (__a <= __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vcle_s32 (int32x2_t __a, int32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmgev2si (__b, __a);\n+  return (uint32x2_t) (__a <= __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14781,22 +14705,19 @@ vcle_s64 (int64x1_t __a, int64x1_t __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vcle_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_cmgeuv8qi ((int8x8_t) __b,\n-\t\t\t\t\t\t (int8x8_t) __a);\n+  return (__a <= __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vcle_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_cmgeuv4hi ((int16x4_t) __b,\n-\t\t\t\t\t\t  (int16x4_t) __a);\n+  return (__a <= __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vcle_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmgeuv2si ((int32x2_t) __b,\n-\t\t\t\t\t\t  (int32x2_t) __a);\n+  return (__a <= __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14808,65 +14729,61 @@ vcle_u64 (uint64x1_t __a, uint64x1_t __b)\n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcleq_f32 (float32x4_t __a, float32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmgev4sf (__b, __a);\n+  return (uint32x4_t) (__a <= __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcleq_f64 (float64x2_t __a, float64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmgev2df (__b, __a);\n+  return (uint64x2_t) (__a <= __b);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vcleq_s8 (int8x16_t __a, int8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_cmgev16qi (__b, __a);\n+  return (uint8x16_t) (__a <= __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vcleq_s16 (int16x8_t __a, int16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_cmgev8hi (__b, __a);\n+  return (uint16x8_t) (__a <= __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcleq_s32 (int32x4_t __a, int32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmgev4si (__b, __a);\n+  return (uint32x4_t) (__a <= __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcleq_s64 (int64x2_t __a, int64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmgev2di (__b, __a);\n+  return (uint64x2_t) (__a <= __b);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vcleq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_cmgeuv16qi ((int8x16_t) __b,\n-\t\t\t\t\t\t   (int8x16_t) __a);\n+  return (__a <= __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vcleq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_cmgeuv8hi ((int16x8_t) __b,\n-\t\t\t\t\t\t  (int16x8_t) __a);\n+  return (__a <= __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcleq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmgeuv4si ((int32x4_t) __b,\n-\t\t\t\t\t\t  (int32x4_t) __a);\n+  return (__a <= __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcleq_u64 (uint64x2_t __a, uint64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmgeuv2di ((int64x2_t) __b,\n-\t\t\t\t\t\t  (int64x2_t) __a);\n+  return (__a <= __b);\n }\n \n /* vcle - scalar.  */\n@@ -14900,8 +14817,7 @@ vcled_f64 (float64_t __a, float64_t __b)\n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vclez_f32 (float32x2_t __a)\n {\n-  float32x2_t __b = {0.0f, 0.0f};\n-  return (uint32x2_t) __builtin_aarch64_cmlev2sf (__a, __b);\n+  return (uint32x2_t) (__a <= 0.0f);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14913,22 +14829,19 @@ vclez_f64 (float64x1_t __a)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vclez_s8 (int8x8_t __a)\n {\n-  int8x8_t __b = {0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint8x8_t) __builtin_aarch64_cmlev8qi (__a, __b);\n+  return (uint8x8_t) (__a <= 0);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vclez_s16 (int16x4_t __a)\n {\n-  int16x4_t __b = {0, 0, 0, 0};\n-  return (uint16x4_t) __builtin_aarch64_cmlev4hi (__a, __b);\n+  return (uint16x4_t) (__a <= 0);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vclez_s32 (int32x2_t __a)\n {\n-  int32x2_t __b = {0, 0};\n-  return (uint32x2_t) __builtin_aarch64_cmlev2si (__a, __b);\n+  return (uint32x2_t) (__a <= 0);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -14940,44 +14853,37 @@ vclez_s64 (int64x1_t __a)\n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vclezq_f32 (float32x4_t __a)\n {\n-  float32x4_t __b = {0.0f, 0.0f, 0.0f, 0.0f};\n-  return (uint32x4_t) __builtin_aarch64_cmlev4sf (__a, __b);\n+  return (uint32x4_t) (__a <= 0.0f);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vclezq_f64 (float64x2_t __a)\n {\n-  float64x2_t __b = {0.0, 0.0};\n-  return (uint64x2_t) __builtin_aarch64_cmlev2df (__a, __b);\n+  return (uint64x2_t) (__a <= 0.0);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vclezq_s8 (int8x16_t __a)\n {\n-  int8x16_t __b = {0, 0, 0, 0, 0, 0, 0, 0,\n-\t\t   0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint8x16_t) __builtin_aarch64_cmlev16qi (__a, __b);\n+  return (uint8x16_t) (__a <= 0);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vclezq_s16 (int16x8_t __a)\n {\n-  int16x8_t __b = {0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint16x8_t) __builtin_aarch64_cmlev8hi (__a, __b);\n+  return (uint16x8_t) (__a <= 0);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vclezq_s32 (int32x4_t __a)\n {\n-  int32x4_t __b = {0, 0, 0, 0};\n-  return (uint32x4_t) __builtin_aarch64_cmlev4si (__a, __b);\n+  return (uint32x4_t) (__a <= 0);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vclezq_s64 (int64x2_t __a)\n {\n-  int64x2_t __b = {0, 0};\n-  return (uint64x2_t) __builtin_aarch64_cmlev2di (__a, __b);\n+  return (uint64x2_t) (__a <= __AARCH64_INT64_C (0));\n }\n \n /* vclez - scalar.  */\n@@ -15005,7 +14911,7 @@ vclezd_f64 (float64_t __a)\n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vclt_f32 (float32x2_t __a, float32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmgtv2sf (__b, __a);\n+  return (uint32x2_t) (__a < __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -15017,19 +14923,19 @@ vclt_f64 (float64x1_t __a, float64x1_t __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vclt_s8 (int8x8_t __a, int8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_cmgtv8qi (__b, __a);\n+  return (uint8x8_t) (__a < __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vclt_s16 (int16x4_t __a, int16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_cmgtv4hi (__b, __a);\n+  return (uint16x4_t) (__a < __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vclt_s32 (int32x2_t __a, int32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmgtv2si (__b, __a);\n+  return (uint32x2_t) (__a < __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -15041,22 +14947,19 @@ vclt_s64 (int64x1_t __a, int64x1_t __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vclt_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_cmgtuv8qi ((int8x8_t) __b,\n-\t\t\t\t\t\t (int8x8_t) __a);\n+  return (__a < __b);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vclt_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_cmgtuv4hi ((int16x4_t) __b,\n-\t\t\t\t\t\t  (int16x4_t) __a);\n+  return (__a < __b);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vclt_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmgtuv2si ((int32x2_t) __b,\n-\t\t\t\t\t\t  (int32x2_t) __a);\n+  return (__a < __b);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -15068,65 +14971,61 @@ vclt_u64 (uint64x1_t __a, uint64x1_t __b)\n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcltq_f32 (float32x4_t __a, float32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmgtv4sf (__b, __a);\n+  return (uint32x4_t) (__a < __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcltq_f64 (float64x2_t __a, float64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmgtv2df (__b, __a);\n+  return (uint64x2_t) (__a < __b);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vcltq_s8 (int8x16_t __a, int8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_cmgtv16qi (__b, __a);\n+  return (uint8x16_t) (__a < __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vcltq_s16 (int16x8_t __a, int16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_cmgtv8hi (__b, __a);\n+  return (uint16x8_t) (__a < __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcltq_s32 (int32x4_t __a, int32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmgtv4si (__b, __a);\n+  return (uint32x4_t) (__a < __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcltq_s64 (int64x2_t __a, int64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmgtv2di (__b, __a);\n+  return (uint64x2_t) (__a < __b);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vcltq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_cmgtuv16qi ((int8x16_t) __b,\n-\t\t\t\t\t\t   (int8x16_t) __a);\n+  return (__a < __b);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vcltq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_cmgtuv8hi ((int16x8_t) __b,\n-\t\t\t\t\t\t  (int16x8_t) __a);\n+  return (__a < __b);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcltq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmgtuv4si ((int32x4_t) __b,\n-\t\t\t\t\t\t  (int32x4_t) __a);\n+  return (__a < __b);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcltq_u64 (uint64x2_t __a, uint64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmgtuv2di ((int64x2_t) __b,\n-\t\t\t\t\t\t  (int64x2_t) __a);\n+  return (__a < __b);\n }\n \n /* vclt - scalar.  */\n@@ -15160,8 +15059,7 @@ vcltd_f64 (float64_t __a, float64_t __b)\n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vcltz_f32 (float32x2_t __a)\n {\n-  float32x2_t __b = {0.0f, 0.0f};\n-  return (uint32x2_t) __builtin_aarch64_cmltv2sf (__a, __b);\n+  return (uint32x2_t) (__a < 0.0f);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -15173,22 +15071,19 @@ vcltz_f64 (float64x1_t __a)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vcltz_s8 (int8x8_t __a)\n {\n-  int8x8_t __b = {0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint8x8_t) __builtin_aarch64_cmltv8qi (__a, __b);\n+  return (uint8x8_t) (__a < 0);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vcltz_s16 (int16x4_t __a)\n {\n-  int16x4_t __b = {0, 0, 0, 0};\n-  return (uint16x4_t) __builtin_aarch64_cmltv4hi (__a, __b);\n+  return (uint16x4_t) (__a < 0);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vcltz_s32 (int32x2_t __a)\n {\n-  int32x2_t __b = {0, 0};\n-  return (uint32x2_t) __builtin_aarch64_cmltv2si (__a, __b);\n+  return (uint32x2_t) (__a < 0);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -15200,44 +15095,37 @@ vcltz_s64 (int64x1_t __a)\n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcltzq_f32 (float32x4_t __a)\n {\n-  float32x4_t __b = {0.0f, 0.0f, 0.0f, 0.0f};\n-  return (uint32x4_t) __builtin_aarch64_cmltv4sf (__a, __b);\n+  return (uint32x4_t) (__a < 0.0f);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcltzq_f64 (float64x2_t __a)\n {\n-  float64x2_t __b = {0.0, 0.0};\n-  return (uint64x2_t) __builtin_aarch64_cmltv2df (__a, __b);\n+  return (uint64x2_t) (__a < 0.0);\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vcltzq_s8 (int8x16_t __a)\n {\n-  int8x16_t __b = {0, 0, 0, 0, 0, 0, 0, 0,\n-\t\t   0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint8x16_t) __builtin_aarch64_cmltv16qi (__a, __b);\n+  return (uint8x16_t) (__a < 0);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vcltzq_s16 (int16x8_t __a)\n {\n-  int16x8_t __b = {0, 0, 0, 0, 0, 0, 0, 0};\n-  return (uint16x8_t) __builtin_aarch64_cmltv8hi (__a, __b);\n+  return (uint16x8_t) (__a < 0);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vcltzq_s32 (int32x4_t __a)\n {\n-  int32x4_t __b = {0, 0, 0, 0};\n-  return (uint32x4_t) __builtin_aarch64_cmltv4si (__a, __b);\n+  return (uint32x4_t) (__a < 0);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vcltzq_s64 (int64x2_t __a)\n {\n-  int64x2_t __b = {0, 0};\n-  return (uint64x2_t) __builtin_aarch64_cmltv2di (__a, __b);\n+  return (uint64x2_t) (__a < __AARCH64_INT64_C (0));\n }\n \n /* vcltz - scalar.  */\n@@ -24139,19 +24027,19 @@ vtrnq_u32 (uint32x4_t a, uint32x4_t b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vtst_s8 (int8x8_t __a, int8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_cmtstv8qi (__a, __b);\n+  return (uint8x8_t) ((__a & __b) != 0);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vtst_s16 (int16x4_t __a, int16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_cmtstv4hi (__a, __b);\n+  return (uint16x4_t) ((__a & __b) != 0);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vtst_s32 (int32x2_t __a, int32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmtstv2si (__a, __b);\n+  return (uint32x2_t) ((__a & __b) != 0);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -24163,22 +24051,19 @@ vtst_s64 (int64x1_t __a, int64x1_t __b)\n __extension__ static __inline uint8x8_t __attribute__ ((__always_inline__))\n vtst_u8 (uint8x8_t __a, uint8x8_t __b)\n {\n-  return (uint8x8_t) __builtin_aarch64_cmtstv8qi ((int8x8_t) __a,\n-\t\t\t\t\t\t (int8x8_t) __b);\n+  return ((__a & __b) != 0);\n }\n \n __extension__ static __inline uint16x4_t __attribute__ ((__always_inline__))\n vtst_u16 (uint16x4_t __a, uint16x4_t __b)\n {\n-  return (uint16x4_t) __builtin_aarch64_cmtstv4hi ((int16x4_t) __a,\n-\t\t\t\t\t\t  (int16x4_t) __b);\n+  return ((__a & __b) != 0);\n }\n \n __extension__ static __inline uint32x2_t __attribute__ ((__always_inline__))\n vtst_u32 (uint32x2_t __a, uint32x2_t __b)\n {\n-  return (uint32x2_t) __builtin_aarch64_cmtstv2si ((int32x2_t) __a,\n-\t\t\t\t\t\t  (int32x2_t) __b);\n+  return ((__a & __b) != 0);\n }\n \n __extension__ static __inline uint64x1_t __attribute__ ((__always_inline__))\n@@ -24190,53 +24075,49 @@ vtst_u64 (uint64x1_t __a, uint64x1_t __b)\n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vtstq_s8 (int8x16_t __a, int8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_cmtstv16qi (__a, __b);\n+  return (uint8x16_t) ((__a & __b) != 0);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vtstq_s16 (int16x8_t __a, int16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_cmtstv8hi (__a, __b);\n+  return (uint16x8_t) ((__a & __b) != 0);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vtstq_s32 (int32x4_t __a, int32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmtstv4si (__a, __b);\n+  return (uint32x4_t) ((__a & __b) != 0);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vtstq_s64 (int64x2_t __a, int64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmtstv2di (__a, __b);\n+  return (uint64x2_t) ((__a & __b) != __AARCH64_INT64_C (0));\n }\n \n __extension__ static __inline uint8x16_t __attribute__ ((__always_inline__))\n vtstq_u8 (uint8x16_t __a, uint8x16_t __b)\n {\n-  return (uint8x16_t) __builtin_aarch64_cmtstv16qi ((int8x16_t) __a,\n-\t\t\t\t\t\t   (int8x16_t) __b);\n+  return ((__a & __b) != 0);\n }\n \n __extension__ static __inline uint16x8_t __attribute__ ((__always_inline__))\n vtstq_u16 (uint16x8_t __a, uint16x8_t __b)\n {\n-  return (uint16x8_t) __builtin_aarch64_cmtstv8hi ((int16x8_t) __a,\n-\t\t\t\t\t\t  (int16x8_t) __b);\n+  return ((__a & __b) != 0);\n }\n \n __extension__ static __inline uint32x4_t __attribute__ ((__always_inline__))\n vtstq_u32 (uint32x4_t __a, uint32x4_t __b)\n {\n-  return (uint32x4_t) __builtin_aarch64_cmtstv4si ((int32x4_t) __a,\n-\t\t\t\t\t\t  (int32x4_t) __b);\n+  return ((__a & __b) != 0);\n }\n \n __extension__ static __inline uint64x2_t __attribute__ ((__always_inline__))\n vtstq_u64 (uint64x2_t __a, uint64x2_t __b)\n {\n-  return (uint64x2_t) __builtin_aarch64_cmtstv2di ((int64x2_t) __a,\n-\t\t\t\t\t\t  (int64x2_t) __b);\n+  return ((__a & __b) != __AARCH64_UINT64_C (0));\n }\n \n __extension__ static __inline uint64_t __attribute__ ((__always_inline__))"}]}