 ptx
//
// Generated by LLVM NVPTX Back-End
//

.version 3.2
.target sm_20
.address_size 64

	// .globl	internal
                                        // @internal
.visible .func  (.param .align 8 .b8 func_retval0[16]) internal(
	.param .align 8 .b8 internal_param_0[16],
	.param .align 8 .b8 internal_param_1[16]
)
{
	.reg .b64 	%rd<11>;

// BB#0:                                // %start
	ld.param.u64 	%rd1, [internal_param_0+8];
	ld.param.u64 	%rd2, [internal_param_1];
	ld.param.u64 	%rd3, [internal_param_1+8];
	ld.param.u64 	%rd4, [internal_param_0];
	mul.lo.s64 	%rd5, %rd4, %rd3;
	mul.hi.u64 	%rd6, %rd4, %rd2;
	add.s64 	%rd7, %rd6, %rd5;
	mul.lo.s64 	%rd8, %rd1, %rd2;
	add.s64 	%rd9, %rd7, %rd8;
	mul.lo.s64 	%rd10, %rd4, %rd2;
	st.param.b64	[func_retval0+0], %rd10;
	st.param.b64	[func_retval0+8], %rd9;
	ret;
}

	// .globl	foo
.visible .entry foo(
	.param .align 8 .b8 foo_param_0[16],
	.param .align 8 .b8 foo_param_1[16],
	.param .u64 foo_param_2
)                                       // @foo
{
	.reg .b64 	%rd<9>;

// BB#0:                                // %start
	ld.param.u64 	%rd1, [foo_param_0];
	ld.param.u64 	%rd2, [foo_param_0+8];
	ld.param.u64 	%rd3, [foo_param_2];
	cvta.to.global.u64 	%rd4, %rd3;
	ld.param.u64 	%rd5, [foo_param_1];
	ld.param.u64 	%rd6, [foo_param_1+8];
	{ // callseq 0
	.reg .b32 temp_param_reg;
	.param .align 8 .b8 param0[16];
	st.param.b64	[param0+0], %rd1;
	st.param.b64	[param0+8], %rd2;
	.param .align 8 .b8 param1[16];
	st.param.b64	[param1+0], %rd5;
	st.param.b64	[param1+8], %rd6;
	.param .align 8 .b8 retval0[16];
	call.uni (retval0), 
	internal, 
	(
	param0, 
	param1
	);
	ld.param.b64	%rd7, [retval0+0];
	ld.param.b64	%rd8, [retval0+8];
	} // callseq 0
	st.global.u64 	[%rd4+8], %rd8;
	st.global.u64 	[%rd4], %rd7;
	ret;
}
